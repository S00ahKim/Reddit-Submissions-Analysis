Unnamed: 0,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2015-11-10,2015,11,10,2,3s5kw9,Google releases the Tensorflow open source project,https://www.reddit.com/r/tensorflow/comments/3s5kw9/google_releases_the_tensorflow_open_source_project/,cdibona,1447089292,,4,22
1,2015-11-13,2015,11,13,6,3sl2t2,"Anyone have performance benchmarks in various configurations (CPU, GPU, combos)?",https://www.reddit.com/r/tensorflow/comments/3sl2t2/anyone_have_performance_benchmarks_in_various/,livingonthehedge,1447365054,"One of the touted benefits of TensorFlow is ""write once, run anywhere"".  Meaning you can run the same graph on different hardware.

Has anyone done a performance comparison of varous CPU and GPU combos?  

I'd love to see both training (mini-batch) and execution (one-off) benchmarks.

I don't have an Nvidia card or I would volunteer to do it myself.",4,2
2,2015-11-15,2015,11,15,12,3sutgc,K-Means Clustering with TensorFlow,https://www.reddit.com/r/tensorflow/comments/3sutgc/kmeans_clustering_with_tensorflow/,sachinrjoglekar,1447556559,,1,8
3,2015-11-16,2015,11,16,19,3t08fy,Try Tensor Flow in this online environment,https://www.reddit.com/r/tensorflow/comments/3t08fy/try_tensor_flow_in_this_online_environment/,ahmed_ajaali,1447668769,,2,11
4,2015-11-21,2015,11,21,2,3tl6r2,Recursively copying elements from one Graph to another in TensorFlow,https://www.reddit.com/r/tensorflow/comments/3tl6r2/recursively_copying_elements_from_one_graph_to/,sachinrjoglekar,1448040054,,0,1
5,2015-11-23,2015,11,23,3,3tu557,"How I succeeded in installing TensorFlow on debian, when I got: 'not a supported wheel on this platform' error?",https://www.reddit.com/r/tensorflow/comments/3tu557/how_i_succeeded_in_installing_tensorflow_on/,redgansai,1448216023,,0,1
6,2015-11-24,2015,11,24,5,3tzfbf,Can anyone help me wrap my head around implementing an Echo State Network using Tensorflow?,https://www.reddit.com/r/tensorflow/comments/3tzfbf/can_anyone_help_me_wrap_my_head_around/,jiminiminimini,1448309460,"I cannot understand how I am supposed to superclass RNNCell, initialize my weights according to specification, set some weights as untrainable, modify a weight to keep its spectral radius below one, etc.

[Here](http://stackoverflow.com/questions/33879281/how-can-i-implement-a-custom-rnn-specifically-an-esn-in-tensorflow) is my StackOverflow question about this subject.",0,1
7,2015-11-25,2015,11,25,0,3u3962,Install and Run TensorFlow on Windows,https://www.reddit.com/r/tensorflow/comments/3u3962/install_and_run_tensorflow_on_windows/,Budincsevity,1448380544,,0,1
8,2015-11-28,2015,11,28,23,3ul8nq,Self-Organizing Maps with Googles TensorFlow,https://www.reddit.com/r/tensorflow/comments/3ul8nq/selforganizing_maps_with_googles_tensorflow/,sachinrjoglekar,1448722111,,0,2
0,2015-12-3,2015,12,3,3,3v6edj,"Keras, now running on TensorFlow",https://www.reddit.com/r/tensorflow/comments/3v6edj/keras_now_running_on_tensorflow/,fhoffa,1449082567,,0,5
1,2015-12-9,2015,12,9,2,3vya92,What is TensorFlow? (Part 1),https://www.reddit.com/r/tensorflow/comments/3vya92/what_is_tensorflow_part_1/,redgansai,1449595172,,0,1
2,2015-12-12,2015,12,12,5,3wf85q,Could someone explain the logicality of these artificial intelligent algorithms the closest possible to standard programming?,https://www.reddit.com/r/tensorflow/comments/3wf85q/could_someone_explain_the_logicality_of_these/,kafeaccount,1449865343,"( *I'm an experienced programmer, from Java to PHP, nodejs to ruby, c++ to # and I also have done a lot of work with system administration and amateurish electronics.* )

(but) I can't understand the first and deepest layers of these algorithms. I just can't do. 

1.  Could I **rudely** compare *tensorflow* to an optimization of *traditional algorithm* (searching similar images by comparing files, searching pattern *x* in a database, etc.) barely as jquery is to javascript? (just a library?)

2. What exactly constitutes the layers of automation, superficial middle and deep? Traditional code? OOP or nOOP? How does it adapt so inteligentelly to different situations? Because of *1*? Is it closer to being just a complicated function ""compareImages()"" which is just really well developed and engineered?
3. Is there any **heavy-tech and demonstrative** docs I could check to understands how tensorflow works? I have gone through the website information but didn't get that much of an intelectual applaud (please do understand I don't seek an analogy to rael life about this processing, be heavily techy on me or else I won't fully understand it)

Any help regarding this would be highly appreciated :) thank you!",5,5
3,2015-12-20,2015,12,20,19,3xkfkx,"What exactly is a ""device"", mentioned in the whitepaper? (link in body)",https://www.reddit.com/r/tensorflow/comments/3xkfkx/what_exactly_is_a_device_mentioned_in_the/,kafeaccount,1450608725,"Here is the link to TF whitepaper http://download.tensorflow.org/paper/whitepaper2015.pdf

My question being: what exactly is a device that gets *reset whenever operation fails*, *passing data through devices*, (etc). **Is a device a computer/node/processing unit?** Why can't TF operate solely on one device? What makes it essential for the algorithm?",0,3
0,2016-1-5,2016,1,5,13,3zij2y,Stanford NLP's GloVe implemented in TensorFlow,https://www.reddit.com/r/tensorflow/comments/3zij2y/stanford_nlps_glove_implemented_in_tensorflow/,gradysimon,1451968534,,0,2
1,2016-1-22,2016,1,22,6,4228he,Solving XOR with a Neural Network in TensorFlow,https://www.reddit.com/r/tensorflow/comments/4228he/solving_xor_with_a_neural_network_in_tensorflow/,StephenOman,1453412862,,0,3
2,2016-1-23,2016,1,23,21,42alws,Predicting Trigonometric Waves few steps ahead with LSTMs in TensorFlow,https://www.reddit.com/r/tensorflow/comments/42alws/predicting_trigonometric_waves_few_steps_ahead/,[deleted],1453550655,[deleted],0,1
3,2016-1-24,2016,1,24,23,42g226,Predicting Trigonometric Waves few steps ahead with LSTMs in TensorFlow,https://www.reddit.com/r/tensorflow/comments/42g226/predicting_trigonometric_waves_few_steps_ahead/,sachinrjoglekar,1453646143,,3,1
0,2016-2-27,2016,2,27,0,47pj3q,Distributed TensorFlow just open-sourced,https://www.reddit.com/r/tensorflow/comments/47pj3q/distributed_tensorflow_just_opensourced/,toisanji,1456501081,,0,6
1,2016-3-8,2016,3,8,22,49ie31,Why TensorFlow will change the Game for AI,https://www.reddit.com/r/tensorflow/comments/49ie31/why_tensorflow_will_change_the_game_for_ai/,toisanji,1457442245,,0,5
0,2016-3-8,2016,3,8,22,49ie31,Why TensorFlow will change the Game for AI,https://www.reddit.com/r/tensorflow/comments/49ie31/why_tensorflow_will_change_the_game_for_ai/,toisanji,1457442245,,0,5
1,2016-3-12,2016,3,12,0,49zbxc,Beginner Tensorflow,https://www.reddit.com/r/tensorflow/comments/49zbxc/beginner_tensorflow/,ExperientialAgent,1457711400,"I am an extreme beginner, let me know if this question should go elsewhere. I'm setting up a beginner prediction model using the Prediction API spreadsheets to predict promotional tactics on overall revenue. How would you set up the following scenarios in Google Tensorflow:

1.) How would you setup variables for a sweater only sale vs. a sweater and jeans and shirt sale? Would you have an individual column for each (HasJeans, no) ? Or would you just have one column with all promotion items (Promotion, jeans shirt sweater) 

2.) We have 72 hour sales and 7-day sales. Would you just have a column for days (3,7) and one for starting day (Monday)?
",2,1
2,2016-3-12,2016,3,12,1,49zee4,"Jeff Dean talks about TensorFlow, deep learning at Google",https://www.reddit.com/r/tensorflow/comments/49zee4/jeff_dean_talks_about_tensorflow_deep_learning_at/,VikingCoder,1457712377,,0,3
3,2016-3-16,2016,3,16,3,4ajouv,Training ensembles in Tensorflow,https://www.reddit.com/r/tensorflow/comments/4ajouv/training_ensembles_in_tensorflow/,joeyglasgow,1458065923,"I was wondering if anyone had experience training ensembles in Tensorflow?

Essentially I have an architecture consisting of a number of networks of heterogeneous architecture combined as a product-of-experts and a cost which minimises the ensemble as a whole, not individual members.

I've done their classification tutorials &amp; understand how to train a single net, but I can't find how to reuse components and train an ensemble.

If anyone had experience with how to do this, or suggestions of what I might do it'd be very helpful.",0,2
4,2016-3-21,2016,3,21,18,4bbo2b,Convolution on N dims?,https://www.reddit.com/r/tensorflow/comments/4bbo2b/convolution_on_n_dims/,hapliniste,1458554029,"Hi! Is it possible to do convolutions over more than 2 dimensions with Tensorflow? like conv3d or convNd?

I think this would be useful for building conv models working on point clouds. It could also be useful to work on data that is contiguous on some dimensions (images are on two dimensions so it's logical to use conv2D).

Thanks!",4,3
5,2016-3-26,2016,3,26,13,4c002l,Dealing with labels that are relations between exemplars.,https://www.reddit.com/r/tensorflow/comments/4c002l/dealing_with_labels_that_are_relations_between/,ndufour,1458967408,"I have a rather unusual learning task that I'm having difficulty implementing in TensorFlow. Well, the net itself isn't the problem--that's relatively easy--but rather serving the net's input in an appropriate way. While the dataset consists of normal images, they do not themselves have labels. Rather, the ""labels"" are relations between images. On approach would be to serve batches of X random images and then lookup any relations between them. However, this will take an exorbitant amount of time to train: If there are n images and O(log(n)*n) defined relations (i.e., labels), out of n^2 possible relations, the probability any set of randomly chosen images will include a relation (label) is very low. 

So, I have to serve up *pairs* of images, where each pair is known to have a relation--batches consist of 2N images each. How can this be accomplished in TensorFlow? I can't simply serialize all pairs of images having relations (which would require terabytes and terabytes of duplicate data, since each image participates in many relations). 

Any thoughts would be much appreciated!",0,1
6,2016-3-30,2016,3,30,20,4cka4k,[Tested!] Hack you Mac (with Nvidia GPU) to support GPU training with Tensorflow.,https://www.reddit.com/r/tensorflow/comments/4cka4k/tested_hack_you_mac_with_nvidia_gpu_to_support/,machrisaa,1459335844,,2,3
0,2016-4-1,2016,4,1,12,4ctpxv,"TFLearn, high-level API for TensorFlow",https://www.reddit.com/r/tensorflow/comments/4ctpxv/tflearn_highlevel_api_for_tensorflow/,malleus17,1459481794,,0,4
1,2016-4-3,2016,4,3,20,4d5um6,debugging tensorflow C++,https://www.reddit.com/r/tensorflow/comments/4d5um6/debugging_tensorflow_c/,therealsam,1459683014,"I'm working on building my own tensorflow `user_ops` operation, but to understand how tensorflow executes, I would like to be able to debug the C++ side of the code (i.e. not just in Python with `pdb`) with `gdb`.

How would I go about doing this?",0,1
2,2016-4-9,2016,4,9,22,4e18vg,"Learning tensorflow + rnns but can't get my head round some things, please help!",https://www.reddit.com/r/tensorflow/comments/4e18vg/learning_tensorflow_rnns_but_cant_get_my_head/,timrabb,1460208547,"Please let me know if this is not appropriate to this sub.

I'm trying to create a lstm-rnn to generate sequences of music. The training data is a sequence of vectors of size 4, representing various features (including MIDI note) of each note in some songs to train on. 

From my reading, it looks like what I'm trying to do is have for each input sample, the output sample is the next size 4 vector (i.e. it should be trying to predict the next note given the current one, and because of the LSTMs incorporating knowledge of samples that have come before).

I'm using tflearn as I'm still very new to RNNs. I have the following code 
    
    net = tflearn.input_data(shape=[None, seqLength, 4])
    net = tflearn.lstm(net, 128, return_seq=True)
    net = tflearn.dropout(net, 0.5)
    net = tflearn.lstm(net, 128)
    net = tflearn.dropout(net, 0.5)
    net = tflearn.fully_connected(net, 4, activation='softmax')
    net = tflearn.regression(net, optimizer='adam',
                         loss='mean_square')

    # Training
    model = tflearn.DNN(net, tensorboard_verbose=3)
    model.fit(trainX, trainY, show_metric=True, batch_size=128)

Before this code I have split the trainX and trainY into sequences of length 20 (arbitrarily, but I read somewhere that training on sequences like this is a good way to do this).

This seems to be fine but I get the error
    ValueError: Cannot feed value of shape (128, 16, 4) for Tensor u'TargetsData/Y:0', which has shape '(?, 4)'

SO: my assumptions so far is that the input shape [None, seqLength, 4] is saying to TF [batchLength (which gets fed by tflearn sequentially), sequence length, feature length of sample]. What I don't understand is why it's saying the output is the wrong shape? Am I assuming wrongly with the data sequence split? When I just try to feed in all my data without splitting into sequences, so the input shape is [None, 4], TF tells me the LSTM layer expects an input shape with at least 3 dimensions. 

I can't get my head round what the shapes of the inputs and outputs should be. It feels like this should be a simple thing -- I have a set of input sequences of vectors and I want the network to try and predict the next one in the sequence. There's very little online that doesn't assume a fairly advanced level of knowledge, so I've hit a brick wall. Really appreciate any insight anyone can give!",1,3
3,2016-4-15,2016,4,15,16,4evmqe,Does the image retraining example support multi label classification?,https://www.reddit.com/r/tensorflow/comments/4evmqe/does_the_image_retraining_example_support_multi/,n00bto1337,1460704945,,0,2
4,2016-4-16,2016,4,16,15,4f0sih,GPU support (Thinkpad options),https://www.reddit.com/r/tensorflow/comments/4f0sih/gpu_support_thinkpad_options/,themoosemind,1460787594,"I am currently looking for a new notebook (a Thinkpad, probably P50 / T460 / T460p / T560). I would like to buy one which has a dedicated GPU (dGPU) for using it with TensorFlow.

Does anybody know if the following GPUs are supported by TensorFlow?

* 940MX
* M1000M
* M2000M

Are there comparisions of the performance of those 3?",1,1
5,2016-4-22,2016,4,22,6,4fvbcv,Noob with some beginner level doubts about TensorFlow,https://www.reddit.com/r/tensorflow/comments/4fvbcv/noob_with_some_beginner_level_doubts_about/,winged_elite,1461275168,"I have some very basic doubts about tensorflow. Would be very glad if somebody cleared them up.

1) I installed tensorflow using pip. Does it mean that I still have to clone the git repository?

2) I ran the demo [tensorflow MNIST model](https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html#run-a-tensorflow-demo-model) by 

    python -m tensorflow.models.image.mnist.convolutional

Does it mean that after the model completes training, the parameters are automatically stored on secondary storage? Or do we have to edit the code to include ""saver"" functions for parameters to be stored?

3) I was using the tutorial for LSTM-based [language model](https://www.tensorflow.org/versions/r0.8/tutorials/recurrent/index.html) . This article, at the [Run The Code](https://www.tensorflow.org/versions/r0.8/tutorials/recurrent/index.html#run-the-code) section, states 

&gt;We are assuming you have already installed via the pip package, have cloned the tensorflow git repository, and are in the root of the git tree. (If building from source, build the tensorflow/models/rnn/ptb:ptb_word_lm target using bazel).

I've installed using pip, but haven't cloned the git repo. Do I still have to do that? The file ptb_word_lm.py file is not present by default, and I had to create that manually by copying code from the official tensorflow git repository. I then simply ran

    python ptb_word_lm.py --data_path=/tmp/simple-examples/data/ --model small

and then it went through a number of epochs and got the perplexity down to &lt;120 and then stopped. I assumed that the model was trained(As 120 was the target for the small option). Again, are the NN parameters/weights automatically stored on secondary storage in this case?",2,3
6,2016-4-26,2016,4,26,8,4gg6zk,Can i run this in an ubuntu virtualbox on windows?,https://www.reddit.com/r/tensorflow/comments/4gg6zk/can_i_run_this_in_an_ubuntu_virtualbox_on_windows/,strategosInfinitum,1461628765,Can i run this in an ubuntu virtualbox on windows? Or does it require i boot to  to Ubuntu?,3,1
7,2016-4-27,2016,4,27,9,4gltot,What do you think about using lazy properties to structure TensorFlow models?,https://www.reddit.com/r/tensorflow/comments/4gltot/what_do_you_think_about_using_lazy_properties_to/,danijar,1461715866,,0,3
8,2016-4-30,2016,4,30,1,4h05m4,DeepMind now use Tensorflow!,https://www.reddit.com/r/tensorflow/comments/4h05m4/deepmind_now_use_tensorflow/,machrisaa,1461946785,,1,8
0,2016-5-1,2016,5,1,17,4h8bmy,MSE for matrices?,https://www.reddit.com/r/tensorflow/comments/4h8bmy/mse_for_matrices/,[deleted],1462091657,[deleted],0,1
1,2016-5-1,2016,5,1,23,4h9azw,"Tensorflow conv2d_transpose error ""Number of rows of out_backprop doesn't match computed rows""",https://www.reddit.com/r/tensorflow/comments/4h9azw/tensorflow_conv2d_transpose_error_number_of_rows/,winged_elite,1462113740,"I am creating a convolution autoencoder in tensorflow. The exact error I got is:

&gt; tensorflow.python.framework.errors.InvalidArgumentError: Conv2DBackpropInput: Number of rows of out_backprop doesn't match computed: actual = 8, computed = 12
	 [[Node: conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](conv2d_transpose/output_shape, Variable_1/read, MaxPool_1)]]

Relevant code:

    l1d = tf.nn.relu(tf.nn.conv2d_transpose(l1da, w2, [10, 12, 12, 32], strides=[1, 1, 1, 1], padding='SAME'))

where 

    w2 = tf.Variable(tf.random_normal([5, 5, 32, 64], stddev=0.01))

I checked the shape of the input to conv2d_transpose i.e. l1da and it is correct(10x8x8x64). The batch size is 10, input to this layer is in the form of 8x8x64, and the output is supposed to be 12x12x32.

What am I missing?
",2,2
2,2016-5-3,2016,5,3,2,4hip3p,Can we reduce the floating point accuracy in TensorFlow?,https://www.reddit.com/r/tensorflow/comments/4hip3p/can_we_reduce_the_floating_point_accuracy_in/,kleer001,1462209617,"Here's a bit of research: 

http://www.sciencedirect.com/science/article/pii/S1877050911001116

They say 15 bits is good enough (instead of the normal 53). 

I would love a bit of crank down in the pipeline as I only have a CPU on my 7 year old laptop to play with. GPU is great and double sexy, but I think it's overkill for my budget. But still cpu runs up to 20x slower. AAArrgh :(

**16bit variables for Tensor Flow!!!**

Unless of course I'm totally misunderstanding the issues. That's totally possible. 

**edit:** 8-bit 
",4,2
3,2016-5-3,2016,5,3,7,4hk9sy,"A curated list of awesome TensorFlow experiments, libraries, and projects. Inspired by awesome-machine-learning.",https://www.reddit.com/r/tensorflow/comments/4hk9sy/a_curated_list_of_awesome_tensorflow_experiments/,Toyjust,1462229312,,0,15
4,2016-5-6,2016,5,6,0,4i0ghz,Cross entropy turns to NaN and training accuracy falls to zero after 3000 iterations?,https://www.reddit.com/r/tensorflow/comments/4i0ghz/cross_entropy_turns_to_nan_and_training_accuracy/,luongminh97,1462462944,Does this mean the gradient exploded?,1,0
5,2016-5-7,2016,5,7,15,4i91ye,Multi-GPU training scope stuff,https://www.reddit.com/r/tensorflow/comments/4i91ye/multigpu_training_scope_stuff/,DoomyDoom,1462603767,"In the CIFAR-10 and Inception-v3 examples, there's some code like this:

        for i in xrange(FLAGS.num_gpus):
          with tf.device('/gpu:%d' % i):
            with tf.name_scope('%s_%d' % (cifar10.TOWER_NAME, i)) as scope:
              # Calculate the loss for one tower of the CIFAR model. This function
              # constructs the entire CIFAR model but shares the variables across
              # all towers.
              loss = tower_loss(scope)
    
              # Reuse variables for the next tower.
              tf.get_variable_scope().reuse_variables()

I don't have multiple GPUs so I can't test it, but wouldn't this generate an under-sharing error? I would expect something like Variable tower_1/conv1_w does not exist. ",0,1
6,2016-5-9,2016,5,9,7,4igrrt,Could training TensorFlow on a library of fractal algorithms help researchers in any field find patterns in seemingly random (or noisy) datasets?,https://www.reddit.com/r/tensorflow/comments/4igrrt/could_training_tensorflow_on_a_library_of_fractal/,Gonzo_Rick,1462747712,"Fractal algorithms underpin much of the natural world due to their simplicity and surface area optimizing/space filling properties. Unfortunately, after enough iterations, they become so complex that it can be hard to even identify their presence as being a pattern at all. I believe that training TensorFlow software on fractal algebra/geometry (as large a variety as possible) could be a very beneficial tool in recognizing patterns within seemingly random dataset. Such a tool could be invaluable to researchers and clinicians of all kinds.

I am a neuroscience researcher who knows very little about coding. I've been looking into fractal pattern recognition software in my spare time for two years now (with this idea in mind) and was ecstatic when you began developing DeepMind and released this code to the public. Unfortunately, after multiple attempts at following your directions, it's become clear to me that such a project is far out of my purview. I'm writing this in the hope that someone with the necessary skillset might find this idea intriguing enough to pursue it further, or help to point me in the right direction.

What you folks at Google are doing with deep learning is beyond revolutionary, and might just change the face of my (and probably every) field of study. But I'm rambling now, so I'll stop by saying thank you. Thank you, not only for your hard work and world changing projects, but also for keeping the rest of the community in the loop by providing these open source materials.",2,7
7,2016-5-13,2016,5,13,1,4j1gmz,Tensorflow is coming to ruby!,https://www.reddit.com/r/tensorflow/comments/4j1gmz/tensorflow_is_coming_to_ruby/,Toyjust,1463069863,,0,3
8,2016-5-18,2016,5,18,0,4jrh2t,Am I allowed to use TensorFlow in a commercial product?,https://www.reddit.com/r/tensorflow/comments/4jrh2t/am_i_allowed_to_use_tensorflow_in_a_commercial/,luongminh97,1463499173,This question suddenly occurred to me as I was thinking about commercial applications of deep learning,2,4
9,2016-5-18,2016,5,18,1,4jrsns,Need help getting tensorflow to work on docker. (Windows),https://www.reddit.com/r/tensorflow/comments/4jrsns/need_help_getting_tensorflow_to_work_on_docker/,Slapsticks,1463503013,"I've followed instructions from several different sites, reinstalled everything several times, can't get it to work.

Primarily I've been using this guide: https://caffinc.github.io/2015/11/tensorflow-windows/

http://imgur.com/fVxTa7Q

^ in the docker terminal

What am I doing wrong?


Second attempt: http://imgur.com/G2SAhxp",1,2
10,2016-5-19,2016,5,19,0,4jxadu,What is the default variable initializer in Tensorflow?,https://www.reddit.com/r/tensorflow/comments/4jxadu/what_is_the_default_variable_initializer_in/,luongminh97,1463586198,What is the default method of variable initialization used when tf.get_variable() is called without any specification for the initializer? The Docs just says 'None'.,0,1
11,2016-5-19,2016,5,19,4,4jylc1,Google supercharges machine learning tasks with TPU custom chip,https://www.reddit.com/r/tensorflow/comments/4jylc1/google_supercharges_machine_learning_tasks_with/,fhoffa,1463601276,,1,4
12,2016-5-21,2016,5,21,22,4kdh90,New Chip by Google for Tensorflow will Help Advance the Field of Machine Learning,https://www.reddit.com/r/tensorflow/comments/4kdh90/new_chip_by_google_for_tensorflow_will_help/,Toyjust,1463835846,,0,3
13,2016-5-24,2016,5,24,8,4kqwt3,Stuck in the Bazel test stage.,https://www.reddit.com/r/tensorflow/comments/4kqwt3/stuck_in_the_bazel_test_stage/,brnme,1464046251,"Hey guys, i'm trying to get tensorflow up and running to have a play with syntaxnet and parse mcparseface. I have installed all the dependencies on my thinkpad t410 running arch linux. The bazel test stage from what I understand builds the project as a whole as well as testing compatibilty of all the files/applications. However as the thinkpad doesnt have the most amazing processing power, it has been on [2,563 / 3,121] for the past hour or so. I was wondering when running the bazel test command if it is usual for mounds of output to be produced. Any insight into the bazel test functionality would be greatly appreciated.",0,1
14,2016-5-24,2016,5,24,13,4ks5es,Fizz Buzz in Tensorflow,https://www.reddit.com/r/tensorflow/comments/4ks5es/fizz_buzz_in_tensorflow/,hooked_dev,1464064685,,2,14
15,2016-5-26,2016,5,26,5,4l1rtr,Question about GPU version on Linux,https://www.reddit.com/r/tensorflow/comments/4l1rtr/question_about_gpu_version_on_linux/,valkyreking1,1464209040,"Earlier this week I installed tensorflow (and keras) on my computer.  I only installed the CPU version, since I thought that would be enough for my needs.  However, I noticed that my CNNs were taking very long to train, so I realized I need the GPU version of tensorflow.  I was wondering if just doing the install command
$ sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl
would cause any issues, since I already have the CPU version on my computer.  If so, how would I go about uninstalling the CPU version and installing the GPU version.

Thanks

",2,1
0,2016-6-3,2016,6,3,8,4m9xcb,No programming knowledge - what can I do?,https://www.reddit.com/r/tensorflow/comments/4m9xcb/no_programming_knowledge_what_can_i_do/,castles00,1464908631,"Hi all. Very interested in the possibilities here but have essentially zero programming knowledge (very, very little bit of Python). What can I do with TF? If I can't do anything yet, do you have recommendations for what to learn so that I can do some cool stuff with TF? I'm a newb and most likely an idiot, so apologies/thank you in advance =).",3,5
1,2016-6-4,2016,6,4,8,4mfotp,New to Tensorflow - trying to repurpose an MNIST multilayer network to a calculator,https://www.reddit.com/r/tensorflow/comments/4mfotp/new_to_tensorflow_trying_to_repurpose_an_mnist/,Deinos_Mousike,1464996488,"Could someone help or guide me through what I should do better in order for this to work? 

I changed the number of inputs to 2 and generated some random data, ""x1"" and ""x2"" (one number to be added to another). The idea is to use variables ""add"" and ""mul"" as the real output and base the cost (variable ""Y"") off of that, but I'm having trouble manipulating the data so it inputs properly.

I tried to make another variable with

x = tf.Variable([100 * np.random.random_sample([100]), 100 * np.random.random_sample([100]))

and a few other alternative ways, but that caused errors. Also, if there's anything else wrong in my code, please critique it! Anything helps.

Edit: made some small edits so the code makes more sense and is consistent in inputting two variables from the feed_dict into the optimizer and pred, to replace the two placeholders ""X1"" and ""X2"", however, it still doesn't work. 

Thank you.



    '''
    A Recurrent Neural Network implementation example using TensorFlow Library.
    
    Author: Deinos_Mousike
    '''
    
    import numpy as np
    import tensorflow as tf
    from tensorflow.models.rnn import rnn, rnn_cell
    # import matplotlib.pyplot as plt
    # from mpl_toolkits.mplot3d import Axes3D
    
    # Parameters
    training_iters = 1000
    n_epochs       = 1000
    batch_size     = 128
    display_step   = 100
    learning_rate  = 0.001
    
    n_observations = 100
    n_input        = 2   # Input data (Num + Num)
    n_steps        = 28  # timesteps
    n_hidden_1     = 256 # 1st layer number of features
    n_hidden_2     = 256 # 2nd layer number of features
    n_classes      = 1   # Output
    
    X  = tf.placeholder(""float"", [None, n_input])
    X1 = tf.placeholder(tf.float32)
    X2 = tf.placeholder(tf.float32)
    Y  = tf.placeholder(tf.float32)
    
    # Random input data
    x1 = 100 * np.random.random_sample([100,])
    x2 = 100 * np.random.random_sample([100,])
       
    add = tf.add(X1, X2)
    mul = tf.mul(X1, X2)
    
    weights = {
        'hidden1': tf.Variable(tf.random_normal([n_input,    n_hidden_1])),
        #'hidden2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),
        'out':     tf.Variable(tf.random_normal([n_hidden_1,  n_classes]))
    }
    
    biases = {
        'hidden1': tf.Variable(tf.random_normal([n_hidden_1])),
        #'hidden2': tf.Variable(tf.random_normal([n_hidden_2])),
        'out':     tf.Variable(tf.random_normal([n_classes]))
    }
    
    def RNN(_X1, _X2, _weights, _biases):
    
        # Layer 1.1
        layer_1 = tf.add(tf.matmul(_X1, weights['hidden1']), biases['hidden1'])
        layer_1 = tf.nn.relu(layer_1)
        # Layer 1.2
        # layer_1_2 = tf.add(tf.matmul(_X2, weights['hidden2']), biases['hidden2'])
        # layer_1_2 = tf.nn.relu(layer_1_2)
        # Hidden layer with RELU activation
        layer_2   = tf.add(tf.matmul(layer_1, weights['out']), biases['out'])
    
        output    = tf.nn.relu(layer_2)
    
        return output
    
    pred         = RNN(X1, X2, weights, biases)
    cost         = tf.reduce_sum(tf.pow(pred - Y, 2)) / (n_observations - 1)
    optimizer    = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) # Adam Optimizer
    correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(Y,1))
    
    init     = tf.initialize_all_variables()
    # initData = tf.initialize_variables(x1.all(), x2.all())
    
    with tf.Session() as sess:
        # Here we tell tensorflow that we want to initialize all
        # the variables in the graph so we can use them
        sess.run(init)
    
        # Fit all training data
        prev_training_cost = 0.0
    
        for epoch_i in range(n_epochs) :
            for (_x1) in x1:
                for (_x2) in x2:
                    print(""Input 1:"")
                    print(_x1)
                    print(""Input 2:"")
                    print(_x2)
                    print(""Add function: "")
                    print(sess.run(add, feed_dict={X1: x1, X2: x2}))
                    y =   sess.run(add, feed_dict={X1: x1, X2: x2})
                    print(y)
                    sess.run(optimizer, feed_dict={X1: _x1, X2: _x2, Y: y})
                
    
            training_cost = sess.run(
                cost, feed_dict={X: xs, Y: ys})
            print(training_cost)
    
            if epoch_i % 20 == 0:
                ax.plot(X1, X2, pred.eval(
                    feed_dict={X1: _x1, X2: _x2, Y: y}, session=sess),
                        'k', alpha=epoch_i / n_epochs)
                fig.show()
                plt.draw()
    
            # Allow the training to quit if we've reached a minimum
            if np.abs(prev_training_cost - training_cost) &lt; 0.000001:
                break
            prev_training_cost = training_cost
    ",0,3
2,2016-6-6,2016,6,6,5,4mp9s3,Tensor Builder - A light wrapper over TensorFlow that enables you to easily create complex deep neural networks using the Builder Pattern through a functional fluent immutable API.,https://www.reddit.com/r/tensorflow/comments/4mp9s3/tensor_builder_a_light_wrapper_over_tensorflow/,cgarciae,1465158834,,0,6
3,2016-6-9,2016,6,9,15,4n9iej,New to TesorFlow - NLP in TensorFlow,https://www.reddit.com/r/tensorflow/comments/4n9iej/new_to_tesorflow_nlp_in_tensorflow/,Vibhu27,1465452035,[removed],0,1
4,2016-6-10,2016,6,10,2,4nbv8o,how to run distributed tensorflow test?,https://www.reddit.com/r/tensorflow/comments/4nbv8o/how_to_run_distributed_tensorflow_test/,xyd1989,1465493087,"Is there anyone successfully run the distributed mnist example from tensorflow repository?
link here: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/dist_test

I tried to run the script dist_mnist_test.sh in script/ folder like this:
bash dist_mnist_test.sh ""grpc://localhost0:2222 grpc://localhost1:2222""

And I got error message like this:

E0609 14:53:07.430440599   62872 tcp_client_posix.c:173]     failed to connect to 'ipv4:127.0.0.1:2223': socket error: connection refused
E0609 14:53:07.445297934   62873 tcp_client_posix.c:173]     failed to connect to 'ipv4:127.0.0.1:2224': socket error: connection refused

Any idea of what's going on?
Thanks.",0,2
5,2016-6-10,2016,6,10,5,4ncndz,Graphing an ROC curve for an image recognition application,https://www.reddit.com/r/tensorflow/comments/4ncndz/graphing_an_roc_curve_for_an_image_recognition/,dthiagar,1465502767,"Hi all,

I've altered the cifar-10 code a little bit to recognize 1 specific object, and now I'd like to graph the ROC curve to evaluate the model - how would I go about doing this? I know there's a method in the sklearn module, but I'm not sure how to apply it syntactically.

More specifically, I know that the main part of the classification happens in the following line of code:
```top_k_op = tf.nn.in_top_k(logits, labels, 1)```

Where can I vary the threshold associated with the ROC curve, and then actually plot it?

Thanks for the help!",0,3
6,2016-6-10,2016,6,10,11,4ne77s,High-level Learn Module in TensorFlow,https://www.reddit.com/r/tensorflow/comments/4ne77s/highlevel_learn_module_in_tensorflow/,terrytangyuan,1465524519,,0,3
7,2016-6-14,2016,6,14,12,4nzen6,Inputting Image Data into TensorFlow for Unsupervised Deep Learning,https://www.reddit.com/r/tensorflow/comments/4nzen6/inputting_image_data_into_tensorflow_for/,mwakanosya,1465873356,,1,2
8,2016-6-14,2016,6,14,23,4o1lhq,Has anyone used SyntaxNet with a Python program?,https://www.reddit.com/r/tensorflow/comments/4o1lhq/has_anyone_used_syntaxnet_with_a_python_program/,[deleted],1465913883,[deleted],0,1
9,2016-6-16,2016,6,16,10,4ob06u,Classifying category of tweet,https://www.reddit.com/r/tensorflow/comments/4ob06u/classifying_category_of_tweet/,SomeRandomBuddy,1466042250,"Noob trigger. What's the high level heuristic of using tensorflow to categorize tweets? Say I have 100k tweets about event A. Hundred k event B. So on so forth. What CNN do I use? How often do I train it?

How do I get data into tensorflow? Can i link it to hadoop or do i only need to train data in batches (eg after new data comes in)?

Is it better to use word based or char based tokenization?

Go soft on me :)",0,1
10,2016-6-17,2016,6,17,22,4oja6u,How does Tensorflow build graphs in memory without the slow-down common in interpreted languages like python?,https://www.reddit.com/r/tensorflow/comments/4oja6u/how_does_tensorflow_build_graphs_in_memory/,criticalcontext,1466171054,"Tensorflow has the user build a graph in memory through function calls to a C interface. It then (presumably) builds an in-memory graph and passes data between internal functions until an output is found.

I created a similar system called [GoFlow](http://www.github.com/ryanpeach/goflow) where users create a graph like in LabVIEW to run normal code via function calls (I wrote this so an AI I am designing could write code or logic diagrams in-memory via function calls easily). However, the boiler-plate of this slows down simple function calls from the assembly break-neck speed of 10~ns to about 1000x measuring in 10s of ms (again, normal for an interpreted language like python).

How does Tensorflow get around this limitation? The only way I can think of is by writing the code entirely in pre-processor script and then basically compiling it.",1,5
11,2016-6-19,2016,6,19,20,4osyzf,Tensorflow:GPU Server docker image,https://www.reddit.com/r/tensorflow/comments/4osyzf/tensorflowgpu_server_docker_image/,whiteshadow13,1466336470,"Hi there,
I have been searching for a bit, but could not find an docker image for grpc_tensorflow_server with GPU support. Only found the typical tensorflow docker images exposed with jupyter. 
Anyone aware if something like this is available?",0,1
12,2016-6-24,2016,6,24,0,4phadv,TF gpu memory usage on non-evaluated tensors,https://www.reddit.com/r/tensorflow/comments/4phadv/tf_gpu_memory_usage_on_nonevaluated_tensors/,Dref360,1466695705,"Hi,
I would like to know if tensors defined but not evaluated take memory on the GPU.
My use-case is that I want to define metrics like accuracy,recall,etc.
Let's say I have my train_op and I define an accuracy op (children of my train_op so not evaluated if I call train_op)

If I do sess.run(train_op,..) does the accuracy op still gets loaded on the gpu?

Thanks",0,2
13,2016-6-26,2016,6,26,7,4pumvk,Q: Has anyone come across a model that sorts/ranks photos based on aesthetics?,https://www.reddit.com/r/tensorflow/comments/4pumvk/q_has_anyone_come_across_a_model_that_sortsranks/,bossjones,1466892218,"Hi friends,

New to this subreddit, but it's good to be here. I'm hoping to find a model that can help me sort through thousands of photos I've taken with my DSLR and help me determine which ones are the most aesthetically ""pleasing"". Having the ability to rank photos would help tremendously with figuring out which photos are worth touching up/editing in photoshop etc. I know the people over at [petapixel](http://petapixel.com/2016/05/31/trained-algorithm-predict-makes-beautiful-photo/) have done something like this and made it into an iOS app, but being able to run something like that programmatically on a arbitrary set of images would be awesome.

Thanks in advance!",0,4
14,2016-6-26,2016,6,26,21,4pxlhx,Custom Optimizer in tensorfow?,https://www.reddit.com/r/tensorflow/comments/4pxlhx/custom_optimizer_in_tensorfow/,shaleenx,1466944921,[removed],0,1
15,2016-6-27,2016,6,27,7,4pzypb,Any TensorFlow books available?,https://www.reddit.com/r/tensorflow/comments/4pzypb/any_tensorflow_books_available/,o-rka,1466978563,I like reading O'Reilly programming books but they don't have one on TensorFlow.  I e-mailed them and they don't have any plans for making one any time soon.  I found one book https://www.amazon.com/Getting-Started-TensorFlow-Giancarlo-Zaccone-ebook/dp/B01H1JD6JO/ref=sr_1_7?ie=UTF8&amp;qid=1466972535&amp;sr=8-7&amp;keywords=tENSORFLOW but couldn't find a PDF.  Can anyone recommend any books? Preferably with a PDF available. ,6,14
16,2016-6-28,2016,6,28,1,4q42po,Is there a way to get a console in windows (docker)?,https://www.reddit.com/r/tensorflow/comments/4q42po/is_there_a_way_to_get_a_console_in_windows_docker/,homestead_cyborg,1467043262,"Hi, you may already understand what I am asking. I'm hosting jupyter with the official TF docker image, and I am editing the notebook  in my browser. I often want to examine objects in the ipython console, but have yet to find a way. Anyone know if there is a way to do this? ",2,2
17,2016-6-29,2016,6,29,20,4qexsy,tf.Tensor` as a Python `bool` is not allowed,https://www.reddit.com/r/tensorflow/comments/4qexsy/tftensor_as_a_python_bool_is_not_allowed/,Vibhu27,1467198304,[removed],0,1
18,2016-6-30,2016,6,30,23,4qlz9v,Wide &amp; Deep Learning: Better Together with TensorFlow,https://www.reddit.com/r/tensorflow/comments/4qlz9v/wide_deep_learning_better_together_with_tensorflow/,fhoffa,1467297259,,0,1
0,2016-7-1,2016,7,1,17,4qqsuz,Testing a pre-trained model?,https://www.reddit.com/r/tensorflow/comments/4qqsuz/testing_a_pretrained_model/,topdog82,1467363508,"I have a reference model, (a TensorFlow implementation of AlexNet with pre-trained weights) that I wanted to test on my own personal data set of images. Do you guys know what would be the next steps?",1,2
1,2016-7-6,2016,7,6,9,4rftsl,building a graph and keeping the intermediate calculations,https://www.reddit.com/r/tensorflow/comments/4rftsl/building_a_graph_and_keeping_the_intermediate/,pragmascript,1467765069,So I am training a neural network and want to be able to display the activations of the hidden layers after the forward pass. But i want to avoid to recalculate each of them just to be able to visualize them. How could I go about returning the hidden activations from the training step without recalculating them?,1,1
2,2016-7-9,2016,7,9,13,4ryrn3,Building Machine Learning Estimator in TensorFlow,https://www.reddit.com/r/tensorflow/comments/4ryrn3/building_machine_learning_estimator_in_tensorflow/,terrytangyuan,1468038263,,0,1
3,2016-7-13,2016,7,13,5,4sj7e0,New free course on creative coding using tensorflow,https://www.reddit.com/r/tensorflow/comments/4sj7e0/new_free_course_on_creative_coding_using/,ashwinv11,1468355536,,5,11
4,2016-7-14,2016,7,14,9,4sqggb,"New to TensorFlow, having trouble building example model with bazel",https://www.reddit.com/r/tensorflow/comments/4sqggb/new_to_tensorflow_having_trouble_building_example/,NAOorNever,1468456692,"So I've been trying to go through the examples in TensorFlow and wanted to get the [retraining](https://www.tensorflow.org/versions/r0.9/how_tos/image_retraining/index.html) example working, however I ran into trouble when I try to build it. 

First, the file wasn't in the example folder. I don't think this was a huge deal as I copied the files from the github repo. However next, when I tried to build the model with bazel, I get this error

    Problem with java installation: couldn't find/access rt.jar in /usr/lib64/jvm/java-1.9.0-openjdk-1.9.0 

I found git issue about this but haven't found anyone who posted a resolution:
https://github.com/bazelbuild/bazel/issues/1068

I tried to install JRE 8 and use

    sudo update-alternatives --config java

but bazel still gives me the same JRE 9 issue. Has anyone encountered this and found a workaround? Could I be doing something wrong in switching the Java version? Any help would be greatly appreciated, thanks!",0,2
5,2016-7-18,2016,7,18,11,4td0k2,MNIST in 6 lines* using Tensorflow Slim,https://www.reddit.com/r/tensorflow/comments/4td0k2/mnist_in_6_lines_using_tensorflow_slim/,leavesofclass,1468810362,,0,3
6,2016-7-22,2016,7,22,22,4u2r42,In which case would tf.train.ExponentialMovingAverage improve the learning process?,https://www.reddit.com/r/tensorflow/comments/4u2r42/in_which_case_would/,[deleted],1469194172,[deleted],0,1
7,2016-7-25,2016,7,25,6,4uf7az,Saving hidden layer within LSTM example,https://www.reddit.com/r/tensorflow/comments/4uf7az/saving_hidden_layer_within_lstm_example/,ct999,1469396347,"Hello all,

I'm new to TensorFlow this week.  As a preliminary idea that I had with a corpus of mine, I first just want to print the hidden layers/state after each incoming input example.  I need to do this simple thing ASAP.

I'm using the [tutorial](https://www.tensorflow.org/versions/r0.9/tutorials/recurrent/index.html) example, [whose source code is found here.](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/ptb_word_lm.py)

How can I do it?  I've gone through the MNIST sample and understand the basics, along w/ Colah's nice LSTM explanation.


**Question 1:** I've tried outputting the 'state' variable which is assigned on line 122.  Is this the variable I need?  I don't see any variable named 'hidden'.

**Question 2:** does this require using TensorBoard and serializing the graph?

**Question 3:** is there any other framework/library that is easier for printing the hidden layer of an LSTM?

Thanks!
",0,2
8,2016-7-26,2016,7,26,8,4ulov0,Tensorflow 3 Ways,https://www.reddit.com/r/tensorflow/comments/4ulov0/tensorflow_3_ways/,amplifier_khan,1469490611,,0,3
9,2016-7-27,2016,7,27,11,4usc2i,Understanding neural networks with TensorFlow Playground | Google Cloud Big Data and Machine Learning Blog,https://www.reddit.com/r/tensorflow/comments/4usc2i/understanding_neural_networks_with_tensorflow/,kazunori279,1469585620,,0,4
10,2016-7-28,2016,7,28,22,4v0t59,Is there a width/height limit for inception model ?,https://www.reddit.com/r/tensorflow/comments/4v0t59/is_there_a_widthheight_limit_for_inception_model/,jseguillon,1469714068,"Hi, 
I noticed Inception model always refer to 299*299 image for both training and input. 

I wonder if anyone : 

* knows if it's possible to train a model with larger images ? 
* knows if there's a theorical limit ? 

*Disclaimer1 : i'm totally noob on deep learning but registered to next coursera session* 

*Disclaimer2 : why should i want to use larger images ? the basic idea here is to know if tensorflow could analyse a full photo (5Mpx  for example) and analyse objects in background instead of forground* 

Thanks. ",1,3
0,2016-8-2,2016,8,2,11,4vqck4,Tensorflow support for GTX1080 status,https://www.reddit.com/r/tensorflow/comments/4vqck4/tensorflow_support_for_gtx1080_status/,lbruck,1470106103,"I've read various blog posts (like http://textminingonline.com/dive-into-tensorflow-part-iii-gtx-1080-ubuntu16-04-cuda8-0-cudnn5-0-tensorflow) about how to get CUDA 8.0, CUDnn 5, and Tensorflow compiled and running on Ubuntu 16.04 with a GTX 1080.  However, as I work through the various errors (switch to gcc 4.9, add various CFLAGS, etc), I eventually run into errors that, when I look up on the TF github issues page, have comments that the configuration is known not to work (https://github.com/tensorflow/tensorflow/issues/3571).  Is this a recent regression?  I was building the tip of the mainline branch; is there a better tag that is known to work?",1,4
1,2016-8-3,2016,8,3,4,4vu7qg,"Tutorial on Image classification ""from the scratch"" ?",https://www.reddit.com/r/tensorflow/comments/4vu7qg/tutorial_on_image_classification_from_the_scratch/,[deleted],1470165060,[deleted],0,1
2,2016-8-3,2016,8,3,4,4vuaag,"Tensorflow Tutorial on Image classification ""from the scratch"" ?",https://www.reddit.com/r/tensorflow/comments/4vuaag/tensorflow_tutorial_on_image_classification_from/,Nuesjanix,1470165819,"Dear Internet people.

I want to learn about neural networks and image recognition/classification.
I already did severel Tutorials on the Tensorflow website and watched a lot Youtube tutorials.

My problem is that all tutorials that i did so far, worked with prebuilt datasets, or pretrained models.
Iam interessted in something that teaches how to build a simple neural net in Tensorflow. Including:

-decoding/implementing image data
-training/testing

Is there anything you could recommend? 

Thanks in advance",1,3
3,2016-8-3,2016,8,3,5,4vurbw,Learn to create dynamic recurrent neural networks model from raw equations with tensorflow,https://www.reddit.com/r/tensorflow/comments/4vurbw/learn_to_create_dynamic_recurrent_neural_networks/,kazi_shezan,1470171081,,0,1
4,2016-8-3,2016,8,3,22,4vylc2,Tensorflow officially support GPU running on MAC,https://www.reddit.com/r/tensorflow/comments/4vylc2/tensorflow_officially_support_gpu_running_on_mac/,machrisaa,1470232464,,5,15
5,2016-8-4,2016,8,4,13,4w2pbt,Noob with some dumb questions,https://www.reddit.com/r/tensorflow/comments/4w2pbt/noob_with_some_dumb_questions/,ssreekanth2000,1470283638,"I was trying to install tensorflow on my mac (CPU only) and I am able to import and run the test script without any issue. So I copy and pasted the iris flower classification script and tried to run it and got the following error.
/ http://imgur.com/a/Mins2
.I reinstalled the whole thing but to no avail. Any suggestions?
/Thanks",4,2
6,2016-8-5,2016,8,5,21,4wa3oi,Tensorflow crashing,https://www.reddit.com/r/tensorflow/comments/4wa3oi/tensorflow_crashing/,[deleted],1470399582,[deleted],0,1
7,2016-8-7,2016,8,7,11,4wj08m,TensorFlow - Not Just for Deep Learning,https://www.reddit.com/r/tensorflow/comments/4wj08m/tensorflow_not_just_for_deep_learning/,terrytangyuan,1470536403,,0,9
8,2016-8-9,2016,8,9,1,4wqv1t,Does anyone know how to save/load a complete model?,https://www.reddit.com/r/tensorflow/comments/4wqv1t/does_anyone_know_how_to_saveload_a_complete_model/,johsm6699,1470672199,"I would like to find some simple example code for saving a model in a way that would allow me to restore the model completely in a different session, without knowing anything at all about the model, except maybe the name of the top node of the graph (i.e. of the variable v that I would put into session.run(v,...). 

So essentially I would like the equivalent of v.save(filename) and something like vloaded = model.load(filename) so that the restored v can be used with another sess.run(vloaded) but I was unable to find anything that actually works that way. The crucial thing is that the code that loads the model should not need to know anything about the graph and just load the model as a black box that can be handed to sess.run().

Does anyone know how to do this?",1,6
9,2016-8-11,2016,8,11,7,4x4pp3,LSTM Incredibly Slow,https://www.reddit.com/r/tensorflow/comments/4x4pp3/lstm_incredibly_slow/,[deleted],1470866846,[deleted],0,1
10,2016-8-13,2016,8,13,19,4xikdv,An implementation of word2vec applied to stanford philosophy encyclopedia,https://www.reddit.com/r/tensorflow/comments/4xikdv/an_implementation_of_word2vec_applied_to_stanford/,pipado,1471084383,,0,4
11,2016-8-19,2016,8,19,19,4yi56j,Define filters and pooling of FDCNN,https://www.reddit.com/r/tensorflow/comments/4yi56j/define_filters_and_pooling_of_fdcnn/,zzw922cn,1471602190,"I am doing research on Deep CNNs ,but I don't have a efficient way to select the number of filters or number of pooling layers? Do you know any good way to set these hype-parameters in deep CNN?",1,1
12,2016-8-22,2016,8,22,2,4yw2or,Unsupervised Learning example,https://www.reddit.com/r/tensorflow/comments/4yw2or/unsupervised_learning_example/,AnimatedSnake,1471801685,"Hey guys.

First off: I've been doing the examples from the tutorial site on Tensorflow, and also the tutorials on LearningTensorflow.

The project I want to work on is about unsupervised learning. 

But I can't seem to find any real example from Tensorflow or otherwise that does it unsupervised. It seems like everything uses labels.

Any good links, ideas or hints? :-)",5,3
13,2016-8-22,2016,8,22,7,4yxhcs,Noob question about expected output when using GPU version of TF. Convergence problem.,https://www.reddit.com/r/tensorflow/comments/4yxhcs/noob_question_about_expected_output_when_using/,machinegunmax,1471818284,"I have created conda environments for both the CPU and GPU version of Tensorflow. When running the mnist example as recommended in [Run a TensorFlow demo model](https://www.tensorflow.org/versions/r0.10/get_started/os_setup.html#run-a-tensorflow-demo-model) inside my conda GPU environment, by typing

    python -m tensorflow.models.image.mnist.convolutional

I get the following output:

    I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally

    I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally

    I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally

    I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally

    I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally

    Extracting data/train-images-idx3-ubyte.gz

    Extracting data/train-labels-idx1-ubyte.gz

    Extracting data/t10k-images-idx3-ubyte.gz

    Extracting data/t10k-labels-idx1-ubyte.gz

    I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero

    I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 

    name: GeForce GTX 1080

    major: 6 minor: 1 memoryClockRate (GHz) 1.7335

    pciBusID 0000:03:00.0

    Total memory: 7.92GiB

    Free memory: 7.68GiB

    I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 

    I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 

    I tensorflow/core/common_runtime/gpu/gpu_device.cc:839] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:03:00.0)

    Initialized!

...

    Step 8500 (epoch 9.89), 4.4 ms

    Minibatch loss: 3.877, learning rate: 0.006302

    Minibatch error: 87.5%

    Validation error: 88.7%

    Test error: 89.7%


So it does not converge. When using the CPU version I get the output:

    Step 8500 (epoch 9.89), 102.3 ms

    Minibatch loss: 1.604, learning rate: 0.006302

    Minibatch error: 0.0%

    Validation error: 0.9%

    Test error: 0.7%

Presumably this is what its supposed to be. I do not know the meaning of the beginning of the output when running it on the GPU, does this mean it has successfully used my GPU?

If I had set up CUDA and CUDNN incorrectly, would the test program be able to run? 

What I'm getting at is: does this mean I have incorrectly setup CUDA and CUDNN, or is it different problem? I have heard of people getting issues when changing batch sizes and things.

I am quite new to Linux, it took me about a week to finally get the nvidia driver working on my distro. It also was quite complicated to install CUDA and CUDNN and add all the correct path environment variables etc. and all the numerous workarounds on many forums. I feel I have come so far and I am so close to getting it working on my GPU, I don't want to give up now. The graphics card I am using is GTX 1080.",1,2
14,2016-8-27,2016,8,27,19,4ztrz8,Noob questions about gen_word2vec,https://www.reddit.com/r/tensorflow/comments/4ztrz8/noob_questions_about_gen_word2vec/,lastranger8811,1472295504,"I am new to tensorflow and want to build my own version of word2vec. I read the source of word2vec and word2vec_optimized in models.embedding. I found they are using gen_word2vec. But when I read the source of gen_word2vec, I do not understand what the examples and labels actually are, which are returned by gen_word2vec.skipgram. Could anyone please tell me what they are?",0,2
15,2016-8-28,2016,8,28,18,4zyp2x,Face recognition with Tensorflow and OpenCV,https://www.reddit.com/r/tensorflow/comments/4zyp2x/face_recognition_with_tensorflow_and_opencv/,gabegabe6,1472375307,"Hy!

I worked with OpenCV and I built a little face recognition app but I used there Eigenfaces and I know that that's not the best method. So I found this tensorflow and it looks cool.

Where should I start to create a face recognizer?

I have a script where I can detect a face with Haar Cascades and than I would like to recognize that face (so I only got an image about the person's face).

I have another script where I can prepare dataset for people. Crops every face from the photo (about a person) and reduce the size of the photo to 512x512 and place the cropped faces to a folder with the persons name. So I think I'll have 40-50 photos from a person.

So my question again...How can I start to use tensorflow for this kind of recognition?",1,2
16,2016-8-29,2016,8,29,22,504wa5,TensorFlow Post  Deep Learning with TensorFlow,https://www.reddit.com/r/tensorflow/comments/504wa5/tensorflow_post_deep_learning_with_tensorflow/,redgansai,1472475891,,0,1
0,2016-9-3,2016,9,3,1,50u7o5,SPEED UP TRAINING WITH GPU-ACCELERATED TENSORFLOW TensorFlow runs up to 50% faster on the latest NVIDIA Pascal GPUs and scales across multiple GPUs within a single node. Now you can train models in hours instead of days. See the benchmarks..,https://www.reddit.com/r/tensorflow/comments/50u7o5/speed_up_training_with_gpuaccelerated_tensorflow/,NV_AI,1472835242,,2,12
1,2016-9-6,2016,9,6,2,51aerv,Creating a Deep Neural Network for image prediction,https://www.reddit.com/r/tensorflow/comments/51aerv/creating_a_deep_neural_network_for_image/,rumirama,1473095406,"I'm trying to implement a DNN for image prediction. The inputs are an image and a motion vector (e.g.: up:-1, right:3, down:4, left:-5) and the output would be the next image. For the training we would have the image, the motion vector and the correct next image (imagine like sequencial frames of a video, for instance).

I'm having troubles implementing this net and the vast majority of the things I find online are mostly for classification in specific labels. In this case there aren't any specific labels as the pixels in the output can be in different ranges of gray (if we consider a gray scale to simply).

Does anyone have any suggestions or know any tutorial?

Thank you in advance.",3,5
2,2016-9-8,2016,9,8,6,51nlu2,Learn to create dynamic recurrent neural networks model from raw equations with tensorflow,https://www.reddit.com/r/tensorflow/comments/51nlu2/learn_to_create_dynamic_recurrent_neural_networks/,[deleted],1473282724,[deleted],0,2
3,2016-9-8,2016,9,8,6,51nrsw,Inaugural London TensorFlow Meetup  Come meet us face to face,https://www.reddit.com/r/tensorflow/comments/51nrsw/inaugural_london_tensorflow_meetup_come_meet_us/,dscape,1473284643,,0,3
4,2016-9-10,2016,9,10,1,51y7vd,Understanding TensorFlow code on github,https://www.reddit.com/r/tensorflow/comments/51y7vd/understanding_tensorflow_code_on_github/,baraut,1473437822,"How do I go about reading TensorFlow code on github. I am complete beginner in open source. I have some basic questions.
Which directory should I look at? Which file should I read first? How do I connect the complete source code ?",0,4
5,2016-9-10,2016,9,10,1,51yatj,Training a Bird Classifier with Tensorflow and TFLearn,https://www.reddit.com/r/tensorflow/comments/51yatj/training_a_bird_classifier_with_tensorflow_and/,mtweak,1473438799,,0,5
6,2016-9-10,2016,9,10,14,521rmc,Understanding Tensorflow and making predictions,https://www.reddit.com/r/tensorflow/comments/521rmc/understanding_tensorflow_and_making_predictions/,IyuTifer,1473485768,"I'm just getting into Tensorflow and have a couple questions about the code on this github account.

https://github.com/brndnhrbrt/TensorFlowML/blob/master/tf_mnist.py

I would like to know how to get the raw data output, the zeros and ones, from the prediction section of this neural network. I know I can get the outputs from epoch_y on line 77 but I want to get results from predictions and not training. 

If anyone could help me out that'd be great! I was on the documentation for tensorflow and couldn't find much about prediction. If you have a python tensorflow setup on github that does something similar please point me in the right direction!",2,2
7,2016-9-14,2016,9,14,2,52lol2,My Net is almost working under Tensorflow but I am getting some unexpected outputs.,https://www.reddit.com/r/tensorflow/comments/52lol2/my_net_is_almost_working_under_tensorflow_but_i/,IyuTifer,1473787376,"You can find my net [here on github](https://github.com/brndnhrbrt/TFNN). It is working great except for its outputs in the prediction section (line 90 of NeuralNet.py). They aren't ranging between -1 and 1. It is my understanding the neural nets are supposed to stay within that range, am I wrong?

To get started with the neural net simply download off of github and run playground.py. This will generate data consisting of two numbers per set. The net will output two classes per set with a 1.0 for whichever number is bigger and a 0.0 for the smaller number.

Please let me know if you find anything wrong with my code or have any suggestions. Thanks!",3,6
8,2016-9-15,2016,9,15,20,52vm2m,Learning TensorFlow - Robert Layton,https://www.reddit.com/r/tensorflow/comments/52vm2m/learning_tensorflow_robert_layton/,Martin81,1473937340,,0,5
9,2016-9-18,2016,9,18,1,538110,Help trying to use Tensorflow with Docker..,https://www.reddit.com/r/tensorflow/comments/538110/help_trying_to_use_tensorflow_with_docker/,Mr_Dogood,1474131277,"So i have docker running and when I goto http://localhost:8888/ I see the three Tensorflow files ""1_hello_tensorflow"" etc. But when I open a new terminal and run ""import tensorflow as tf"" I get the error ""ImportError: No module named tensorflow"". Any thoughts on what I am missing here?",1,2
10,2016-9-18,2016,9,18,23,53cfuk,"using DNN to identify aes encrypted data that is random vs ASCII, I succeeded? I shouldn't have. Tell my what I'm doing wrong.",https://www.reddit.com/r/tensorflow/comments/53cfuk/using_dnn_to_identify_aes_encrypted_data_that_is/,[deleted],1474210245,[deleted],0,1
11,2016-9-19,2016,9,19,0,53chcn,"built a DNN to identify classify AES256 encrypted data. It worked a little too well, can someone tell me what I am doing wrong?",https://www.reddit.com/r/tensorflow/comments/53chcn/built_a_dnn_to_identify_classify_aes256_encrypted/,[deleted],1474210857,[deleted],2,1
12,2016-9-21,2016,9,21,0,53nsua,CUDA error when trying to train model,https://www.reddit.com/r/tensorflow/comments/53nsua/cuda_error_when_trying_to_train_model/,SR2Z,1474384124,"I have built a 3D CNN in TensorFlow.  When I run the network forwards to test the loss function and outputs, all of them return values that I would expect.  However, I have an Adadelta optimizer that minimizes my loss function.  When I try to run the optimizer, I get this:

    F tensorflow/stream_executor/cuda/cuda_dnn.cc:1485] failed to enqueue convolution on stream: CUDNN_STATUS_EXECUTION_FAILED
    Aborted

I'm trying this on my laptop with a GTX 960M, and using the maxpool3d and conv3d functions in TensorFlow for convolution and maxpooling.  Has anyone else encountered this error before?
",1,3
13,2016-9-22,2016,9,22,15,53xqqk,HDFS Support has been Added to TensorFlow,https://www.reddit.com/r/tensorflow/comments/53xqqk/hdfs_support_has_been_added_to_tensorflow/,TheTwigMaster,1474526495,,0,3
14,2016-9-25,2016,9,25,12,54dfsd,Setting up TensorFlow 0.10 with Python 2.7 or 3.5 on AWS GPU Instance,https://www.reddit.com/r/tensorflow/comments/54dfsd/setting_up_tensorflow_010_with_python_27_or_35_on/,mgalarny,1474772422,,1,7
15,2016-9-26,2016,9,26,5,54gyzd,Help me wrap my head around 1D CNN,https://www.reddit.com/r/tensorflow/comments/54gyzd/help_me_wrap_my_head_around_1d_cnn/,FFiJJ,1474835532,"Ok, so, I have this CNN which i hope I can use to predict a time series thing.
Let us, for the moment, ignore the reason as to why my samples have to have a length of 330k and just take it as a given.

    x = tf.placeholder('float', [None, 330750])
    y = tf.placeholder('float')
    nr_classes = 2
    batch_size = 64

    def conv1d(x, W):
        return tf.nn.conv2d(x, W, strides=[1,23,1,1], padding='SAME')

    def maxpool1d(x):
        return tf.nn.max_pool(x, ksize=[1,2,1,1], strides=[1,2,1,1], padding='SAME')

    def cnn(x):
        weights = {'W_conv1':tf.Variable(tf.random_normal([575,1,1,32]))
            ,'W_conv2':tf.Variable(tf.random_normal([575,1,32,64]))
            ,'W_fc':tf.Variable(tf.random_normal([157*64,1024]))
            ,'out':tf.Variable(tf.random_normal([1024, nr_classes]))}

        biases = {'b_conv1':tf.Variable(tf.random_normal([32]))
            ,'b_conv2':tf.Variable(tf.random_normal([64]))
            ,'b_fc':tf.Variable(tf.random_normal([1024]))
            ,'out':tf.Variable(tf.random_normal([nr_classes]))}

        x = tf.reshape(x, shape=[-1,330750,1,1])

        conv1 = conv1d(x, weights['W_conv1']) + biases['b_conv1']
        conv1 = maxpool1d(conv1)

        conv2 = conv1d(conv1, weights['W_conv2']) + biases['b_conv2']
        conv2 = maxpool1d(conv2)

        fc = tf.reshape(conv2, [-1, 157*64])
        fc = tf.nn.relu(tf.matmul(fc, weights['W_fc']) + biases['b_fc'])

        output = tf.matmul(fc, weights['out']) + biases['out']

        return output

What I'd like to do here is significantly increase the stride of the max_pool and possibly of the 2d but actually 1d convolution (there is a function for conv1d in tensorflow but I can't figure how to build a model using it, since every max_pool function seems to expect 4D rather vector...)

However, every time I try to fiddle with this (I'm ashamed to admit, ""experimentally found"" numbers, I get strange errors about the size of Filter not matching the size of inputs... which rather dumbfounds me, since I am unaware how said ""inputs"" are computed.

Anyway, I don't expect people to actually have the time to look at this code (though I am crossing my fingers), rather, I'm wondering if you guys could recommend a Tensorflow tutorial out there that deals with the subject of 1 dimensional convolution (or at least with the subject of nD convolution) which explains EVERYTHING in the convolution model (even if the final model ends up being simplistic), as of now the  convolution for MINST on the official TF websites is kind of blurry as to why the hell going through a convolutional layer reduces the inputs size and how that reduced size is calculated, what the ""depth"" is and why my vectors needs reshaping into a strange [-1, original_vector, 1] vector.

Sadly enough, most ""advanced"" tutorials out there go into all kinds of details I, quite frankly, don't care or even cannot understand, is there a good tutorial out there that explains CNN's for dummies which explains 'em well enough so that I can then build my own, unrelated, models ?",0,3
16,2016-9-27,2016,9,27,6,54n416,Use LSTMs on time series [TensorFlow awesome tutorial],https://www.reddit.com/r/tensorflow/comments/54n416/use_lstms_on_time_series_tensorflow_awesome/,GChe,1474926207,,0,5
17,2016-9-28,2016,9,28,11,54u6er,Tensorflow Ruby API,https://www.reddit.com/r/tensorflow/comments/54u6er/tensorflow_ruby_api/,tensorflow_rb,1475028589,"Hi Everyone,
I am the developer of [tensorflow.rb](https://github.com/somaticio/tensorflow.rb) the Ruby API for Tensorflow. 
The Ruby community has been very enthusiastic about developing a Ruby API for tensorflow (more on this [thread](https://github.com/tensorflow/tensorflow/issues/50)) and I decided to work on it. 

I faced incredible challenges along the way but I do have many interesting findings that I would like to share with you guys. The tensorflow.rb gem can be found on this [link](https://github.com/somaticio/tensorflow.rb). Aside from that, I have written three blog posts where I have given a very brief summary of the work
 
1. [Introductory blog post](https://medium.com/@Arafat./introducing-tensorflow-ruby-api-e77a477ff16e#.mhvj9ojlj)
2. [Developers blog post](https://medium.com/@Arafat./ruby-tensorflow-for-developers-2ec56b8668c5#.97tng1qqi) (This post is for rubyists and developers of other languages.)
3. [Image Recognition Tutorial](https://medium.com/@Arafat./image-recognition-in-ruby-tensorflow-df5d5c05389b#.ty1vygtrg)

The project still needs a lot of work and contributions are very welcome. I encourage everyone to read the blog posts and then install and play with Tensorflow.rb. Any comments/suggestions would be nice and you can always post your thoughts on the [gitter channel](https://gitter.im/tensorflowrb/Lobby?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge) or comment below.
",0,8
18,2016-9-28,2016,9,28,11,54uceu,Need help with basic Tensorflow program,https://www.reddit.com/r/tensorflow/comments/54uceu/need_help_with_basic_tensorflow_program/,MoreHotSauce,1475031071,"I want to make a program where I enter in a set of x1 x2 and outputs a y. All of the tensor flow tutorials I can find start with image reconition. Can someone help me by providing me either code or a tutorial on how to do this in python. thanks in advance.
edit- the x1 x2 coordinates i was planning to use would be like 1, 1 and the y would be 2 or 4, 6 and the y would be 10. I want to provide the program with data to learn from",1,1
19,2016-9-29,2016,9,29,1,54xbyc,How to feed data into Tensorflow word2vec example,https://www.reddit.com/r/tensorflow/comments/54xbyc/how_to_feed_data_into_tensorflow_word2vec_example/,FutureIsMine,1475081741,,0,2
0,2016-10-1,2016,10,1,22,55d7rf,noob question: good setup for exploring Tensorflow on Windows,https://www.reddit.com/r/tensorflow/comments/55d7rf/noob_question_good_setup_for_exploring_tensorflow/,SnackingRaccoon,1475328888,"Windows 10 user here. Not a n00b to machine learning, but total n00b to TensorFlow, and need some brushing up on my Python (so a environment supportive to doing so would be appreciated). 

If it's best, I'm more than happy to use Docker, a VM, whatever you recommend. 

How would you recommend I set myself up to start working with TF?",3,3
1,2016-10-6,2016,10,6,12,563eci,TensorFlow Friday,https://www.reddit.com/r/tensorflow/comments/563eci/tensorflow_friday/,theanosucks,1475722882,"Ladies, gentlemen, 

We are starting a new tradition called 'TensorFlow Friday' where every Friday, we talk about what we have accomplished this week using TensorFlow. We can share tips, tricks, secrets, and code. 

Pop those champagne bottles, uncork that wine, pop the lid off that beer, and get ready to have fun.

**Mods please sticky this** to remind people about #TF #TensorFlow Friday

T.G.I.T. (Thank God It's TensorFlow)",2,9
2,2016-10-7,2016,10,7,23,56bohf,Recognition of images with additional data,https://www.reddit.com/r/tensorflow/comments/56bohf/recognition_of_images_with_additional_data/,xambioa,1475851224,"Good morning everyone, first I would like to make it clear that I began to take my first steps in machine learning yesterday. I've read most basic items and attended some presentations. I will participate in a project here a few months that this technology will be applied. As a beginner I would like to ask a question that I think is silly, but I could not find answers for her.

In presentations and articles, I have seen the creation of a classifier that can classify images or data sets, but never both at the same time. For example, Iris flower data set, which is used as an example. In this data set we have the characteristics of flowers, such as petal width, but we do not have a visual representation of it. It is possible to fit both and for example, to estimate the width of the petal of a certain image?

I imagine this is a very basic question, but I could not find something suitable for a beginner.

I would be very grateful.",0,1
3,2016-10-9,2016,10,9,22,56m9sz,Can Tensorflow be used to classify pixels in satellite imagery?,https://www.reddit.com/r/tensorflow/comments/56m9sz/can_tensorflow_be_used_to_classify_pixels_in/,timex40,1476021523,"A common problem in working with satellite imagery is performing a land classification, which is determining what each pixel should be categorized as - water, vegetation, roads, etc. This is done by examining the R,G,B values (plus more if the sensor collected other spectral bands) of each pixel, and using those values to cluster them into different classification types. The spatial relationship between pixels is not considered - all classifications are based on each of the individual pixel's values. 

Reading a bit about Tensorflow I'm wondering if it could be useful in this application. 

The few examples of TF I've seen that work on image processing have been to find objects within an image (ex. Character recognition). In these cases the algorithms use vectors representing 2D image chips as inputs. And use image chips as trainging data. 

The land classification problem would be a little different in that the input would be a vector of R,G,B values of a single pixel. And individual pixels would be used as training data. 

Any thoughts on if this could work? Have there been any other TF applications that use individual pixels as the input versus image chips? ",2,5
4,2016-10-10,2016,10,10,22,56s0nd,[Optimization needed] Bubble sort using TensorFlow,https://www.reddit.com/r/tensorflow/comments/56s0nd/optimization_needed_bubble_sort_using_tensorflow/,jalFaizy,1476107141,"NOTE: Originally posted [here](https://discuss.analyticsvidhya.com/t/bubble-sort-using-tensorflow/12181)

I recently did a small implementation on Bubble sort using Tensorflow (TF). Let me give a little background story; when I did a survey on TF, I liked it very much as a deep learning library. I wanted to explore its uses on non-DL applications. And hence the codes

#########################################

	# import modules
	import tensorflow as tf

	# create interactive session
	sess = tf.InteractiveSession()

	# create unsorted array
	unsorted_array = tf.Variable([1, 4, 2, 3])
	# find length of array
	len_array = unsorted_array.get_shape()[0].value

	# initialize variables
	init = tf.initialize_all_variables()
	sess.run(init)

	cnt = 0

	# bubble sort
	for i in range(len_array):
	    isSwapped = False
	    for j in range(0, len_array - i - 1):
		
		if tf.greater(unsorted_array[j], unsorted_array[j+1]).eval():
		    # extract values
		    temp1 = unsorted_array[j].eval()
		    temp2 = unsorted_array[j + 1].eval()
		    
		    # replace unsorted array
		    unsorted_array = tf.scatter_update(unsorted_array, j, temp2)
		    unsorted_array = tf.scatter_update(unsorted_array, j+1, temp1)
		    isSwapped = True
		
		print ""After iteration"", cnt, ':', unsorted_array.eval()
		cnt += 1

	    if isSwapped: break

#########################################

When I did a performance comparison with pure numpy implementation, I found this result:

    TF time: 0.2167978286743164
    Numpy time: 0.0028018951416015625

To me, this seems a bit wrong as a conclusion. My hypothesis is that the codes not optimized. Could you suggest anything I could do to decrease speed. Or could you explain why is this time difference?",1,1
5,2016-10-10,2016,10,10,23,56s5r0,I just found a walkthrough to use Slim. Hope it can help you,https://www.reddit.com/r/tensorflow/comments/56s5r0/i_just_found_a_walkthrough_to_use_slim_hope_it/,kudaphan,1476109013,,0,3
6,2016-10-11,2016,10,11,0,56sef7,Performance of Sequence-to-Sequence Models in tensor flow on a low spec machine,https://www.reddit.com/r/tensorflow/comments/56sef7/performance_of_sequencetosequence_models_in/,ark9gm,1476111962,"I want to learn more about deep neural nets and tensor flow. I mainly want to make a machine translator same as the one on the tensor flow tutorial using RNN (Sequence-to-Sequence Models https://www.tensorflow.org/versions/r0.11/tutorials/seq2seq/index.html ). However, I only have a low spec machine with an Intel dual core CPU and 2Gb of RAM. I'm planning to buy a graphics card, maybe a geforce gtx 750 Ti to make up for the low spec CPU and RAM. I'm still a student so I can't really afford any upgrades.

So my question is this. Do you think it is possible to do the said Sequence-to-Sequence Models tutorial in tensor flow given the my lack of a good hardware? Will a new graphics card be able to make up for the low spec CPU and RAM? How many hours do you think it will take to train the model like that in the tutorial in my machine? And I would also like to know how many hours it will take to train that on a good machine.

I'm also new to Reddit and I only created an account on hopes that someone here can help me with these. Thanks",1,1
7,2016-10-11,2016,10,11,21,56xreb,cluster from camera stream and user input to classify in a second step,https://www.reddit.com/r/tensorflow/comments/56xreb/cluster_from_camera_stream_and_user_input_to/,[deleted],1476189344,[deleted],1,1
8,2016-10-12,2016,10,12,6,570jek,QueueRunner Blocked or not Running For Getting Batches from the Test Set?,https://www.reddit.com/r/tensorflow/comments/570jek/queuerunner_blocked_or_not_running_for_getting/,[deleted],1476221606,[deleted],0,1
9,2016-10-12,2016,10,12,7,570wpi,"Struggling to install TensorFlow on Amazon AWS? Use TFAMI. Open-source, free and maintained.",https://www.reddit.com/r/tensorflow/comments/570wpi/struggling_to_install_tensorflow_on_amazon_aws/,ritchieng,1476226125,"I, like others, have struggled in installing and making TensorFlow work. It took a lot of time and there were a multitude of errors. I created an AMI that is actively maintained and open-source. I hope the community can maintain one AMI where everyone can use in any region on any GPU instance. I mean, even the deep learning AMI supported by Amazon does not have TensorFlow working out of the box. I tested it on all g2 and p2 instances and you can start working on TensorFlow in less than 5 minutes by using this AMI. There's absolutely 0 configuration needed. 

TFAMI: A TensorFlow Amazon Web Service (AWS) AMI that is open, free and works. 
https://github.com/ritchieng/tensorflow-aws-ami

The Github repository has all the information, but when launching your instance, simply click ""Community AMI"" and search for ""TFAMI"".",1,8
10,2016-10-13,2016,10,13,4,575xwy,A simple design pattern for recurrent deep learning in TensorFlow,https://www.reddit.com/r/tensorflow/comments/575xwy/a_simple_design_pattern_for_recurrent_deep/,gepr,1476299947,,0,5
11,2016-10-13,2016,10,13,4,5765dt,Which is the best way to learn TensorFlow?,https://www.reddit.com/r/tensorflow/comments/5765dt/which_is_the_best_way_to_learn_tensorflow/,mighelo,1476302207,"Hi there, i would like to know which is the best way to learn  TensorFlow (tutorials, books, ...)
Thanks :)",4,10
12,2016-10-14,2016,10,14,4,57c63o,Any suggest for my senior project?,https://www.reddit.com/r/tensorflow/comments/57c63o/any_suggest_for_my_senior_project/,ibrahimsengul,1476387201,Hello. I'm a computer engineering student. I need a subject for my senior project. I'm researching but i can't find anything i like. It's about ai and image processing or both. Thanks already.,3,6
13,2016-10-14,2016,10,14,15,57f2ur,Export trained TF model to POD,https://www.reddit.com/r/tensorflow/comments/57f2ur/export_trained_tf_model_to_pod/,kw0lf,1476427170,"Is it possible to export a trained tensorflow model to a plain old data structure using its MetaGraph API? I want to use tensorflow to train a model to detect certain kinds of images and use the trained model afterwards in my C++ program without directly depending on tensorflow. I want to use tensorflow for training a model (weights and biases), export it and do the forward step (recognizing images) by myself. Is this possible in general or am I missunderstanding something?",0,1
14,2016-10-15,2016,10,15,20,57ln0c,Shapes and dynamic dimensions in TensorFlow,https://www.reddit.com/r/tensorflow/comments/57ln0c/shapes_and_dynamic_dimensions_in_tensorflow/,morgangiraud,1476530410,,0,3
15,2016-10-15,2016,10,15,23,57map2,Tensorflow - Number (Speech) Recognition from the First Part of a Number,https://www.reddit.com/r/tensorflow/comments/57map2/tensorflow_number_speech_recognition_from_the/,iamajihadi,1476542046,"I'm trying to do a research project where I guess the number people are trying to say from the first part.

Ex: One - O (the actual phonetic sound though)

How would I get started? I'm kind of familiar with Tensorflow in general, but IDK how to do this.",0,2
16,2016-10-17,2016,10,17,20,57wxho,Use .ckpt and .meta -files to make predictions with Inception in TensorFlow,https://www.reddit.com/r/tensorflow/comments/57wxho/use_ckpt_and_meta_files_to_make_predictions_with/,Nuesjanix,1476705599,"I used the Inception-library (Tensorflow/models/Inception-tutorial on github), feeding selfmade TFRecord-files to imagenet_train.py, and ended up with a 7Gb directory containing .ckpt and .meta files.

How do i use them to make actual predictions?(also evaluating, testing, testing with actual .jpg files, continue the training)

I tried the freeze_graph Script, but failed, for reasons like ""not really getting how the script works"". 

What would be the next steps?Are there dummy-friendly examples(tutorials)?",0,2
17,2016-10-18,2016,10,18,1,57ye5h,What are the steps to convert a caffe model to tensorflow model,https://www.reddit.com/r/tensorflow/comments/57ye5h/what_are_the_steps_to_convert_a_caffe_model_to/,itnabakwaas,1476723239,"Hi , I have a pre trained caffe model and I would like to convert it to tensorflow. 
Does anyone know how to do it?
Do I have to write a new tensorflow model and train it or can I somehoe train convert the models?

I tried using this , https://github.com/ethereon/caffe-tensorflow
But failed. 
Can someone write the steps for this?

",0,3
18,2016-10-18,2016,10,18,10,5814rq,Will I be able to run one Tensorflow session on my $3600 4 gpu computer build?,https://www.reddit.com/r/tensorflow/comments/5814rq/will_i_be_able_to_run_one_tensorflow_session_on/,linuxfreebird,1476753578,"https://pcpartpicker.com/user/linuxfreebird/saved/#view=RKP6hM

The link above is my computer build saved on pcpartpicker.com. I am saving up money to build this computer for $3600. I am concerned that Tensorflow will not be able to run one session optimally on 4 gpus. In terms of performance would it be better to just buy one Titan X?",6,1
19,2016-10-19,2016,10,19,5,5864x0,Am I misunderstanding dynamic_rnn?,https://www.reddit.com/r/tensorflow/comments/5864x0/am_i_misunderstanding_dynamic_rnn/,CashierHound,1476822378,"Hello all,

I am using `tf.nn.dynamic_rnn` with batches of variable sequence len and trying to select the RNN's output for the last step of each sequence. If this is unreasonable and [`dynamic_rnn`](https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#dynamic_rnn) takes care of this for me (by shifting the relevant output to the last index on a per-sequence basis), please let me know. Otherwise, here are the relevant details:

    # input_seq has shape (batch_size, max_seq_len, feat_dim), shorter seqs zero padded to max_seq_len
    input_seq = tf.placeholder(tf.float32, shape=[None, max_seq_len, feat_dim], name='input_seq') 
    input_seq_len = tf.placeholder(tf.int64, shape=[None], name='input_seq_len')
    ...
    cell = tf.nn.rnn_cell.BasicLSTMCell(100)
    output, _ = tf.nn.dynamic_rnn(cell, input_seq, sequence_length=input_seq_len, dtype=dtype) 
    
    # output has shape (batch_size, max_seq_len, 100)
    # gather only works on first dimension so we must transpose to get sequence on 0
    output_T = output.transpose(output, [1, 0, 2])
    
    # now we can gather the last entry n = len-1 for each sequence
    # gather retrieves the nth entry for every sequence producing shape (batch_size, batch_size, 100)
    output_gathered = tf.gather(output_T, input_seq_len - 1)
    
    # we need to take the diagnol along this result
    # this should discard everything but the nth entry for the relevant sequence
    # hopefully yields (batch_size, 100)
    output_last = tf.diag_part(output_gathered)

The problem with this is [`diag_part`](https://www.tensorflow.org/versions/r0.11/api_docs/python/math_ops.html#diag_part) only works for even-dim tensors, where I just want to select the diag_part along the first 2 axes. It seems like all this could be solved with [advanced indexing](https://github.com/tensorflow/tensorflow/issues/206) but I'm not sure if it's available yet. Also, the fact that I can't find anyone talking about this indicates to me that I'm inherently misunderstanding something about `dynamic_rnn`.

Any help would be greatly appreciated!",0,1
20,2016-10-20,2016,10,20,5,58cirt,Are there any people working on porting Yahoo's Open NSFW Caffe model to TF?,https://www.reddit.com/r/tensorflow/comments/58cirt/are_there_any_people_working_on_porting_yahoos/,sutrostyle,1476908098,"We tried to migrate https://github.com/yahoo/open_nsfw model to TF using https://github.com/ethereon/caffe-tensorflow .
It all worked, but we get different results from Caffe. Has anybody done this, are there people working on it?",1,3
21,2016-10-23,2016,10,23,1,58tq6j,How to compute pairwise distance between points?,https://www.reddit.com/r/tensorflow/comments/58tq6j/how_to_compute_pairwise_distance_between_points/,identicalParticle,1477152051,"I have a tensor of size [N, D] representing N total D-dimensional points.

I want to calculate a tensor of size [N,N] where the i-jth element is the Euclidean distance between point i and point j.

I feel like this is pretty standard for computing similarity matrices, so I bet there is an existing function to do it.",4,2
22,2016-10-23,2016,10,23,18,58xtxs,How to do Data Compression + Denoising?,https://www.reddit.com/r/tensorflow/comments/58xtxs/how_to_do_data_compression_denoising/,hiteshv09,1477213820,"what wud be the best way 2 implement noise reduction + data compression? Autoencoder or something else? For example, consider a satellite capturing data. This Data is compressed and sent over network bottleneck to space station. At receiving station this data is decompressed and denoised. This can work for online video streaming,drive storage etc. The aim is that like Deep Mind, this system should work for all kind of data. But let's say we start with images. Also how will the system know for a new data that what is a noise in it? Humans can easily distinguish noise.
The problem is, autoencoder is good for denoising but not good for data compression. So can we design a hybrod system. And most importantly, how to implement this?",0,4
23,2016-10-23,2016,10,23,23,58yr78,Why am I getting a high dimensionality?,https://www.reddit.com/r/tensorflow/comments/58yr78/why_am_i_getting_a_high_dimensionality/,215_215,1477232639,"I am currently trying to make a rnn network for regression purposes capable of taking in an arbitraty number of samples and output a 14 length feature vector using tensorflow. 

The network isn't running properly at the moment, for which i am trying to debug the issue.. Here is the code:

http://pastebin.com/YK9dBxwy


The code doesn't fully execute due to an error in the `cross_entropy` function. 

  Error code receving is : 
  http://pastebin.com/T2dqS3Gy


It seem to me that the output  am receiving from the RNN has a quite high dimensionality. I was only expecting a vector with 14 elements so a 1 dimensional vector. But somehow am I ending up with quite a large dimensionality? why? I guess something in my setup of the neural network must be incorrect. 


",0,3
24,2016-10-29,2016,10,29,1,59va8y,"TensorFlow Implementation: Show, Attend and Tell",https://www.reddit.com/r/tensorflow/comments/59va8y/tensorflow_implementation_show_attend_and_tell/,yunjey,1477671292,"I implemented show, attend and tell with tensorflow. 
link is here. 
https://github.com/yunjey/show-attend-and-tell-tensorflow 
I hope this gives many people to help understanding attention mechanism.",0,3
25,2016-10-29,2016,10,29,21,5a05zn,Tensorflow implementation of RBM (both BB and GB),https://www.reddit.com/r/tensorflow/comments/5a05zn/tensorflow_implementation_of_rbm_both_bb_and_gb/,devmeow,1477742906,,0,2
26,2016-10-30,2016,10,30,5,5a2cmm,Can Tensorflow Be Used to Implement the Pregel Graph Processing System?,https://www.reddit.com/r/tensorflow/comments/5a2cmm/can_tensorflow_be_used_to_implement_the_pregel/,MemeticParadigm,1477771800,"[Pregel: A System for Large-Scale Graph Processing](https://blog.acolyer.org/2015/05/26/pregel-a-system-for-large-scale-graph-processing/)

Is there anything close to an out-of-the-box way to go about this, or would it definitely involve writing a custom op? A lot more than that?

Does it make any sense to do this in Tensorflow - like, in the sense of how well the two data processing paradigms ""fit"" with each other? I mean, it feels like they are pretty damn similar, but I can't seem to figure out how one would go about implementing the basic PageRank algorithm in TensorFlow - am I just missing something obvious?",3,2
27,2016-10-30,2016,10,30,11,5a456j,Using a tensor output in gradient modification.,https://www.reddit.com/r/tensorflow/comments/5a456j/using_a_tensor_output_in_gradient_modification/,ITHNOTJUITH,1477795770,"I have a scalar output from a network,

    y=tf.matmul(hidden_1, W2) + b2

where W2 is N by 1. I want to use this in a gradient computation:

    discounted_rewards = tf.placeholder(tf.float32, (None,))
    gradients = optim.compute_gradients(loss)
    for i, (grad,var) in enumerate(gradients):
        if grad is not None:
            gradients[i] = (grad*(discounted_rewards-y), var)
            train_step = optim.apply_gradients(gradients)

This fails to run, with the error: 

    ValueError: Shapes (?, 20) and (20,) are not compatible

What is the problem here? They should both be single dimensional, so I'm not sure why there's a shape error here. If I explicitly retrieve the value of y and then manually feed it back in under a different placeholder it seems to work, but that seems like it should be unnecessary.
",0,1
0,2016-11-1,2016,11,1,17,5ai04c,RESTapi with Tensorflow serving,https://www.reddit.com/r/tensorflow/comments/5ai04c/restapi_with_tensorflow_serving/,leb_broth,1477989174,"Which REST api is the most recommended to ise with Tensorflow serving? I'm thinking to use Web2py but a little bit lost on how to invoke Tensorflow serving from a web2py frontend. My web app is just a simple vector of couple of numerical values inferencing a trained TF model. Would I still need the ""serving"" functionality for TF in my case? I really appreciate a link or an a generap explanatiion. Thanks.",2,1
1,2016-11-2,2016,11,2,10,5anbvh,Is there any documentation on how to get numerical output from FeatureColumns?,https://www.reddit.com/r/tensorflow/comments/5anbvh/is_there_any_documentation_on_how_to_get/,Megatron_McLargeHuge,1478051985,"FeatureColumns provide nice transformations like bucketization and hashing but they seem like a black box that only works with tf.learn classifiers. Is there any documented way to use them with custom-defined models, getting numerical data to feed into tensor inputs?",0,2
2,2016-11-4,2016,11,4,4,5az07u,Differentiable sorting tensors,https://www.reddit.com/r/tensorflow/comments/5az07u/differentiable_sorting_tensors/,sunrisetofu,1478203082,"hi,

I have an intermediate tensor, say of shape [10,] that Id like to sort the values before passing it off to other parts of the graph.
The hope is to have the whole graph differentiable as I will be training end to end.

The sort at every iteration will be sparse, as only 1 or 2 swaps are needed.

Anyway to hack this to make it end-to-end trainable despite the discontinuities introduced when elements in tensor are swapped?
",0,2
3,2016-11-7,2016,11,7,2,5bgzmf,Looking for info on export_meta_graph,https://www.reddit.com/r/tensorflow/comments/5bgzmf/looking_for_info_on_export_meta_graph/,claytantor,1478454730,[removed],1,1
4,2016-11-7,2016,11,7,8,5biwpg,Linear Regression with Exponential Model,https://www.reddit.com/r/tensorflow/comments/5biwpg/linear_regression_with_exponential_model/,Boozybrain,1478475904,"I can fit y=mx+b with no problem and now I'm trying to modify what I have to fit y=Ax^b+C but have yet to figure out why this isn't finding a value for B.  Also it's really slow due to the nested loop (how can I continually train on a full set of data?).  I know it's slow because I have a nested loop.  Surely I can set X,Y to the full array instead of looping through each point, right?  But I'm lost as to why it keeps giving me 0 for B.

[Code here](http://pastebin.com/zTBKt5XM)

[CSV Data here](http://pastebin.com/BMyvMnt1)",1,1
5,2016-11-8,2016,11,8,2,5bngam,Traffic in London episode II: Predicting congestion with Tensorflow,https://www.reddit.com/r/tensorflow/comments/5bngam/traffic_in_london_episode_ii_predicting/,fhoffa,1478539541,,0,3
6,2016-11-8,2016,11,8,7,5bpcgc,PCIe Bandwidth for Workstation,https://www.reddit.com/r/tensorflow/comments/5bpcgc/pcie_bandwidth_for_workstation/,Gio_Gats,1478557637,"Working on a build that's part workstation, part gaming rig, and part deep-learning research platform.  I'm trying to eliminate bottlenecks wherever possible to get the most out of my hardware.
I'm planning to put two GTX 1070s, a 10Gb/s networking card, and a NVMe SSD into the PCIe slots on a MSI X99A Gaming Pro Carbon with an Intel i7-6850K (40 PCIe lanes).  
The manual tells me I can get x8/x16/x8/x8 bandwidth out of those slots.  With those limitations, am I better off sticking with 1Gb/s networking and a SATAIII?  
I know I probably won't see much bottleneck while gaming, but what about running optimized deep learning libraries like TensorFlow?  ",1,1
7,2016-11-9,2016,11,9,1,5bu4b1,How to visualize a predicted image?,https://www.reddit.com/r/tensorflow/comments/5bu4b1/how_to_visualize_a_predicted_image/,rumirama,1478621694,"Hi there.

I'm doing a deep neural regression network with images and I would like to visually compare the image predicted with the image in the test set. I already did the net and it is working fine comparing both and giving me the test cost and accuracy, my issue is to ""extract"" the image so I can visualize the predicted image.

I'm not sure if this is a dumb question or not, but I'm struggling to do that. Does anyone have any idea/suggestion on how to visualize that predicted image? 

Thank you in advance.

 (I'm not sure if I'm making myself clear, so if you don't understand any part, please let me know)",0,2
8,2016-11-9,2016,11,9,3,5bv0cz,I wrote an introductory guide to TensorFlow for new programmers,https://www.reddit.com/r/tensorflow/comments/5bv0cz/i_wrote_an_introductory_guide_to_tensorflow_for/,CarbonFire,1478630113,,0,14
9,2016-11-10,2016,11,10,1,5c27dk,Trouble building with Bazel - couldn't connect to server,https://www.reddit.com/r/tensorflow/comments/5c27dk/trouble_building_with_bazel_couldnt_connect_to/,push_pop,1478710505,"Hi all,
Finally trying to dig into code after following work and news about Tensorflow, etc... for quite a while.

I'm currently following the instructions [here](https://github.com/tensorflow/models/tree/master/inception#getting-started) to download and convert imageNet.

So I got to the part to build the script and I execute:

    bazel build inception/download_and_preprocess_imagenet

It goes through some process for maybe an hour or two, then at the end it finally outputs:

    Error: couldn't connect to server at '/home/.../server/server.socket' after 60 seconds.

Has anyone seen this issue before? Btw, I am using the Ubuntu subsystem(14.04) build into Windows 10.
",0,2
10,2016-11-13,2016,11,13,1,5cl913,Using deep learning to remove glasses from faces,https://www.reddit.com/r/tensorflow/comments/5cl913/using_deep_learning_to_remove_glasses_from_faces/,mwakanosya,1478969873,,0,2
11,2016-11-13,2016,11,13,23,5cq2vl,What do you not like about tensorflow?,https://www.reddit.com/r/tensorflow/comments/5cq2vl/what_do_you_not_like_about_tensorflow/,holdenlee,1479046361,"What problems/inefficiencies are there with tensorflow? For example, what something that is conceptually simple, but would be clunky to write out in tensorflow? What's missing from existing high-level libraries?

I would like to develop a higher-level language that compiles down to tensorflow (esp. for the tensorflow graph). ",3,2
12,2016-11-16,2016,11,16,1,5d3g0m,Tutorial: TensorFlow saving/restoring and mixing multiple models,https://www.reddit.com/r/tensorflow/comments/5d3g0m/tutorial_tensorflow_savingrestoring_and_mixing/,morgangiraud,1479227694,,0,3
13,2016-11-16,2016,11,16,23,5d9dkh,Using LSTM for text generation,https://www.reddit.com/r/tensorflow/comments/5d9dkh/using_lstm_for_text_generation/,mp5sdk3,1479305628,"I'm trying to build some kind of text generation model where given 3 parameters, x_1, x_2 and x_3, the model will be able to generate a set of sentences ""&lt;something related to x_1&gt;&lt;eos&gt;&lt;something related to x_2&gt;&lt;eos&gt;&lt;something related to x_3&gt;&lt;eos&gt;"". The LSTM tutorial(ptb_lm.py) involves generating a sentence with no prior input. However, I want to use the three parameters to generate the sentences.
So far, I've gotten word embeddings for the words in my training data, but I'm unable to proceed forward and modify the code in ptb_lm.py. Any help in this regard is appreciated.",0,3
14,2016-11-22,2016,11,22,0,5e4gyu,Tensorflow ValueError on session.run on batch training with variable timesteps,https://www.reddit.com/r/tensorflow/comments/5e4gyu/tensorflow_valueerror_on_sessionrun_on_batch/,starsmiling,1479740938,"I would like to train RNN on tensorflow for sequential data. Since different samples have different sequence length, I want to use batch training and in each bacth samples obtain the same sequence length (timesteps). For each iteration, samples are grabbed with size [batch_size, timesteps, dim] to fed into RNN. However, since timesteps are changing between batches, I got an ValueError: setting an array element with a sequence. Can anyone helps me please? Anything is appreciated!",2,1
15,2016-11-22,2016,11,22,0,5e4p5k,TFLearn: Build HDF5 Image Dataset vs Image PreLoader,https://www.reddit.com/r/tensorflow/comments/5e4p5k/tflearn_build_hdf5_image_dataset_vs_image/,bumangues9,1479743564,"When is the best time to use either of the two options of feeding data to a training model? I thought HDF5 was meant for large datasets, but when I used it, the training took a lot longer than expected (over 4 hours for 1 epoch, 25k images, using 2 x GTX 1080).",1,3
16,2016-11-22,2016,11,22,23,5eb3k2,How do I apply shared weights to DNNs in TensorFlow?,https://www.reddit.com/r/tensorflow/comments/5eb3k2/how_do_i_apply_shared_weights_to_dnns_in/,rumirama,1479826530,,0,2
17,2016-11-23,2016,11,23,3,5ecf1t,Running optimize_for_inference on InceptionV1 results in different output tensors?,https://www.reddit.com/r/tensorflow/comments/5ecf1t/running_optimize_for_inference_on_inceptionv1/,vade,1479840691,"I have a C++ application which is able to run Tensorflow models, both Inception V1 and V3.

I am also able to successfully run both optimize_for_inference and quantize_graph on my InceptionV3 graph / protocol buffer

However, running optimize_for_inference on InceptionV1 (inception5h.zip from Tensorflow, which I believe is also referred to as GoogleNet?), results in a much much smaller graph size (17 MB versus 54 MB), but it also is no longer functional with my application.

Running the Optimized graph results in errors stating the tensor named 'output' is no longer available.

I understand optimize_for_inference makes changes to the structure of the graph removing unnecessary nodes. However, I specify my outputs as such:

    $ bazel-bin/tensorflow/python/tools/optimize_for_inference --input=/Users/vade/Documents/Repositories/Synopsis/Synopsis/Synopsis/TensorFlowAnalyzer/models/inception5h/tensorflow_inceptionV2_graph.pb --output=/Users/vade/Documents/Repositories/Synopsis/Synopsis/Synopsis/TensorFlowAnalyzer/models/inception5h/tensorflow_inceptionV2_graph_optimized.pb --input_names=input --output_names=output,softmax0

Which in my mind would keep my output tensors named the same.

Running the resulting graph (tensorflow_inceptionV2_graph_optimized.pb) through my C++ app results in this error:

     Running model failed: Not found: FetchOutputs node output: not found


How can I resolve this issue, or deduce the new output tensor name?

Thank you.",0,1
18,2016-11-23,2016,11,23,4,5ecqdt,retraining inception for single category,https://www.reddit.com/r/tensorflow/comments/5ecqdt/retraining_inception_for_single_category/,idrsa_pub,1479843940,"Hi,I'm new to deep learning, I'v managed to retrain inception for couple of categories but I'm getting unified result i.e 100% divided by all categories, what I'm looking for is to prediction how likely this image might be in X category, in other words can I retrain model for single category against everything else ?  to get output similar to google's vision API https://cloud.google.com/vision/",1,2
19,2016-11-24,2016,11,24,1,5eibbp,Is there any implementation of SSD: Single Shot Multibox Detector in Tensorflow,https://www.reddit.com/r/tensorflow/comments/5eibbp/is_there_any_implementation_of_ssd_single_shot/,kudaphan,1479920118,,0,3
20,2016-11-24,2016,11,24,4,5ej8as,TensorFlow Iris Data Demo -- How Long Should It Take?,https://www.reddit.com/r/tensorflow/comments/5ej8as/tensorflow_iris_data_demo_how_long_should_it_take/,deeayecee,1479929612,"I'm learning TensorFlow and have recreated the iris demo from the website:

https://www.tensorflow.org/versions/r0.11/tutorials/tflearn/index.html#tf-contrib-learn-quickstart

I've gotten to the 'classifier.fit' phase, running on a CPU-only machine. The training has taken at least an hour for 2000 iterations and I'm wondering if this timing is typical or if something has gone wrong with either my installation or implementation.",2,3
21,2016-11-24,2016,11,24,13,5elz14,GPU version on virtualbox?,https://www.reddit.com/r/tensorflow/comments/5elz14/gpu_version_on_virtualbox/,[deleted],1479963279,[deleted],2,1
22,2016-11-25,2016,11,25,8,5eqik2,Unstable accuracy values,https://www.reddit.com/r/tensorflow/comments/5eqik2/unstable_accuracy_values/,vin_kaushik,1480029417,"I am trying to run a binary classifier in Tensorflow. For every run of the program I get different accuracy values and this is driving me nuts. I've been tweaking parameters for hours now. 

This follows from the question I posted on SO: http://stackoverflow.com/questions/40709870/changing-accuracy-value-and-no-change-in-loss-value-in-binary-classification-usi

Please tell me how I can get a consistent accuracy every time I execute my program!",0,1
23,2016-11-26,2016,11,26,0,5etzuz,Optimizer that takes difference between buckets into account?,https://www.reddit.com/r/tensorflow/comments/5etzuz/optimizer_that_takes_difference_between_buckets/,MrFromEurope,1480086775,"I created a TensorFlow network with an result vector of 50 elements. Is it somehow possible to take into account, that e.g while learning the actual result would be bucket 34, but a prediction of bucket 35 is much better than a prediction for bucket 3.",0,1
24,2016-11-26,2016,11,26,1,5eueuq,Tensorflow: How to freeze a model and serve it with a python API,https://www.reddit.com/r/tensorflow/comments/5eueuq/tensorflow_how_to_freeze_a_model_and_serve_it/,morgangiraud,1480091942,,0,5
25,2016-11-26,2016,11,26,8,5ewczr,Installation didn't work T___T,https://www.reddit.com/r/tensorflow/comments/5ewczr/installation_didnt_work_t_t/,senpai_eric,1480114914,"I did everything correctly T__T ... went through the whole tutorial on the tensorflow.org website seemingly successful. Of course not without any major errors which I managed to fix over many hours. I've spent so long working with f***ing ubuntu... If anyone has any suggestions on how I can fix this error I would be eternally grateful

&gt;&gt;&gt; import tensorflow

Traceback (most recent call last):

  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;

  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/__init__.py"", line 23, in &lt;module&gt;

  from tensorflow.python import *

  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/__init__.py"", line 48, in &lt;module&gt;

  from tensorflow.python import pywrap_tensorflow

  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 28, in &lt;module&gt;

  _pywrap_tensorflow = swig_import_helper()

  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 24, in swig_import_helper

  _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)

  File ""/usr/lib/python3.5/imp.py"", line 242, in load_module

  return load_dynamic(name, filename, file)

  File ""/usr/lib/python3.5/imp.py"", line 342, in load_dynamic

  return _load(spec)

ImportError: libcudart.so.7.5: cannot open shared object file: No such file or directory

",1,1
26,2016-11-27,2016,11,27,3,5f0vk1,Conceptual basics with Distributed TensorFlow,https://www.reddit.com/r/tensorflow/comments/5f0vk1/conceptual_basics_with_distributed_tensorflow/,ujjwal-researcher,1480185960,"Let me describe the cluster setup first :

I have two nodes (each with 2 GPUs). I refer to them as Node A and Node B

Each node has its own SSD storage.

OAR is the cluster manager that is used.

I have gone through the Distributed TensorFlow documentation but there are some functional basics I could not understand properly and hence this question.

Consider the following situation :

a) I have copied around 600 GB of data on Node A.

b) I can use OAR to specifically ask for allocation of 4 GPUs across the two nodes.

If I want to use Distributed TensorFlow to train a model :

a) How do I specify network addresses to tf.train.ClusterSpec ? What are those network addresses ? In the documentation are names such as localhost:2222 the same names reserved for a particular node with the cluster manager ?

b) My data is copied to node A. During training will TensorFlow itself be responsible for sending this data as input to the GPU that is on node B ?

c) Will I need to manually create the TensorFlow Graph for each GPU on each node using tf.device() ?

d) If I also want to use some additional CPU nodes will I have to have their names beforehand and put them in the code ?",0,1
27,2016-11-27,2016,11,27,6,5f1s1w,Has google made any sort of announcement about supporting a GPU version on Windows?,https://www.reddit.com/r/tensorflow/comments/5f1s1w/has_google_made_any_sort_of_announcement_about/,senpai_eric,1480196726,,2,4
28,2016-11-28,2016,11,28,2,5f6itm,Implementing a linear regression for a real scenario with Tensorflow,https://www.reddit.com/r/tensorflow/comments/5f6itm/implementing_a_linear_regression_for_a_real/,wesovi,1480269510,,0,2
29,2016-11-28,2016,11,28,6,5f7qxt,Tensorflow doesn't utilize GPU after the update.,https://www.reddit.com/r/tensorflow/comments/5f7qxt/tensorflow_doesnt_utilize_gpu_after_the_update/,[deleted],1480283216,[deleted],4,4
30,2016-11-30,2016,11,30,12,5fncv1,Testing our own inputs to the MNIST tutorial,https://www.reddit.com/r/tensorflow/comments/5fncv1/testing_our_own_inputs_to_the_mnist_tutorial/,timex40,1480476872,"So I've gone through and completed the MNIST for ML Beginners tutorial (https://www.tensorflow.org/versions/r0.12/tutorials/mnist/beginners/index.html) which made sense. 

By the end of the tutorial  the model is trained using all the MNIST training data, and its accuracy has been shown to be ~92%. 

If I had another single input - say, I drew my own 28x28 pixel image and wanted to see what it would be classified as - how would I go about this? (Assuming I have already loaded the new input as a 728 element numpy array.)

Thanks for any help 


",0,2
31,2016-11-30,2016,11,30,15,5fo7ze,TensorFlow now supports Windows with the release of v0.12.0 RC0! (Both CPU and GPU builds available),https://www.reddit.com/r/tensorflow/comments/5fo7ze/tensorflow_now_supports_windows_with_the_release/,ElSarcastro,1480488584,,2,15
0,2016-12-1,2016,12,1,23,5fwrbb,Is a machine learning background relevant for TensorFlow?,https://www.reddit.com/r/tensorflow/comments/5fwrbb/is_a_machine_learning_background_relevant_for/,saturdayiscaturday,1480601704,"I'm currently going through Professor Andrew Ng's Machine Learning Course on Coursera, which I find interesting enough to continue and finish. However, I'm curious as to how much machine learning fundamental knowledge is really needed to start developing things with TensorFlow. Is it useful? Is it relevant? I'm not sure what kind of AI I want to develop yet but my curiosity is pulling me in this direction. ",4,2
1,2016-12-2,2016,12,2,2,5fxux6,Model checkpointing using meta-graphs in TensorFlow,https://www.reddit.com/r/tensorflow/comments/5fxux6/model_checkpointing_using_metagraphs_in_tensorflow/,jfsantos,1480613457,,0,2
2,2016-12-2,2016,12,2,16,5g1ydm,How to use tensorflow with custom image dataset?,https://www.reddit.com/r/tensorflow/comments/5g1ydm/how_to_use_tensorflow_with_custom_image_dataset/,alekhka,1480662054,"I want to make an experiment using DNNregresor. What I want to do is to use the DNNregressor class to make a neural network pixel to pixel regression. I am not able to find any code which illustrates opening custom images. I am getting this error when I use decode_png and sess.run key = f.key
AttributeError: 'int' object has no attribute 'key'",0,2
3,2016-12-3,2016,12,3,1,5g4ay9,"In a NN, how can one relate the pixel from an input image with the neuron (from the hidden layer) which has the ""best"" connection with?",https://www.reddit.com/r/tensorflow/comments/5g4ay9/in_a_nn_how_can_one_relate_the_pixel_from_an/,rumirama,1480697649,"Hi there

Is there a way I can use to identify which neuron in my hidden layer is having a bigger impact on a specific region of an input image?

My input image is converted to an array and I want to know the pixel distribution per each neuron, i.e. making some kind of sorting of the connection with largest weight, associating the pixel to the neuron which it shares the ""best"" connection with.

Thank you.",0,2
4,2016-12-5,2016,12,5,4,5gh0tl,Can I incrementally retrain a model?,https://www.reddit.com/r/tensorflow/comments/5gh0tl/can_i_incrementally_retrain_a_model/,Simusid,1480878272,"I'm getting started with Tensorflow and I have had great success with [this image recognition tutorial](https://www.youtube.com/watch?v=QfNvhPx5Px8).   I decided I wanted to try and classify motorcycles vs cars.   I trained a model with 700+ images and according to my test images I'm getting over 0.98 recognition.   I'm really happy with this.

The next thing I want to try is to hook up a web cam in my car to acquire real live imagery and try to detect cars/bikes in my blind spots while driving.  

So eventually I'll have tons of webcam stills.   I know I could take them all and batch retrain my model.    But is there an easier or built in way to incrementally train?   If I throw a novel image at the model and it labels as ""bike"" 0.99, is there a way to acknowledge it is correct and update the model live?   Or is the best way to just mark and save that image and do it by batch offline?

",2,3
5,2016-12-6,2016,12,6,0,5gmbzs,"Tensor flow, Docker and Visual Studios 2015?",https://www.reddit.com/r/tensorflow/comments/5gmbzs/tensor_flow_docker_and_visual_studios_2015/,mortonprod,1480950162,"Hey guys,

I have tensorflow up and running with docker on windows. I would like to develop with VS with intellisense but I'm not sure how.

**Do I need to install tensorflow locally to get this information?**

*Any ideas? Thanks in advance*",1,5
6,2016-12-7,2016,12,7,2,5gu42r,Decoupling dequeueing from gradient computation,https://www.reddit.com/r/tensorflow/comments/5gu42r/decoupling_dequeueing_from_gradient_computation/,mkmatlock,1481044940,"I'm currently trying to move away from using feeds and start using queues in order to support larger datasets. Using queues works fine for the optimizers in tensorflow, since they only evaluate the gradient once for each dequeue operation. However, I have implemented interfaces with other optimizers that perform line searches, and I need to evaluate not just the gradient, but also the loss at multiple points for the same batch. Unfortunately, with the normal queueing system each loss evaluation will execute a dequeue instead of computing for the same batch several times.

Is there a way to decouple the dequeuing operation from the gradient/loss computation in such a way that I can execute dequeue once and then execute the gradient/loss computation several times on the current batch?

Edit: Please note that my input tensors have variable length. We work with molecular data and each molecule has a different number of atoms. This is different from image data, where images are typically all scaled to a fixed size. So, for example, I think that using a tf.Variable assignment will not work because tf.Variable must have a fixed size.",1,1
7,2016-12-8,2016,12,8,2,5h178t,"TensorFlow Dev Summit: Feb 15th, 2017",https://www.reddit.com/r/tensorflow/comments/5h178t/tensorflow_dev_summit_feb_15th_2017/,vincentvanhoucke,1481131784,,0,6
8,2016-12-10,2016,12,10,9,5hhfq5,Real-time streaming predictions using Google Cloud Dataflow and Google Cloud Machine Learning,https://www.reddit.com/r/tensorflow/comments/5hhfq5/realtime_streaming_predictions_using_google_cloud/,fhoffa,1481330358,,0,2
9,2016-12-11,2016,12,11,14,5hol3t,Now tensorflow golang api can talk to tensorboard,https://www.reddit.com/r/tensorflow/comments/5hol3t/now_tensorflow_golang_api_can_talk_to_tensorboard/,helinwang,1481433613,,0,1
10,2016-12-12,2016,12,12,1,5hqtrg,save and load tensorflow tensors using tensorflow golang api,https://www.reddit.com/r/tensorflow/comments/5hqtrg/save_and_load_tensorflow_tensors_using_tensorflow/,helinwang,1481473719,,0,2
11,2016-12-13,2016,12,13,5,5hywe0,word2vec trouble loading data,https://www.reddit.com/r/tensorflow/comments/5hywe0/word2vec_trouble_loading_data/,bananastand03,1481573438,"I am trying use tensorflow's word2vec model on a dataset that I made on rap lyrics. I have the text files stored in a directory, called Everything, and then subdirectories for each artist, and in each artist's directory, I have all the .txt files that I scraped from the web. I compressed the Everything directory, and got a .zip file of everything in it. I then fed the word2vec.py file the .zip as such:

    flags.DEFINE_string(""train_data"", '/.../word2vec/Everything.zip', ""Training text file. ""
                    ""E.g., unzipped file http://mattmahoney.net/dc/text8.zip."")

train_data is then fed into a word2vec.skipgram object, it looks like, as the parameter filename.

However I am getting this error when I try to run the python script:
    
    UnicodeDecodeError: 'utf8' codec can't decode byte 0xbd in position 0: invalid start byte

I am very new to this stuff, so any help in trying to figure this out would be appreciated. From what I gather, it is something to do with my data not being a JSON, but then how would I convert my current data set into a JSON? I am doing this on Unix if it makes a difference. Thank you!",1,1
12,2016-12-13,2016,12,13,9,5i0e9y,What language does tensorflow use?,https://www.reddit.com/r/tensorflow/comments/5i0e9y/what_language_does_tensorflow_use/,ilikeover9000turtles,1481588821,"I have heard it uses both python and C++.

I would assume that python is just for the user interface right, and that everything important uses C++?",4,1
13,2016-12-13,2016,12,13,11,5i1489,Can I use Tensorflow in a game engine?,https://www.reddit.com/r/tensorflow/comments/5i1489/can_i_use_tensorflow_in_a_game_engine/,senpai_eric,1481597429,"like gamemaker, unity, etc.. ",2,1
14,2016-12-13,2016,12,13,16,5i2b8v,"Quick question: Running Tensorflow from Docker (Windows), but the very first page forces me to type a password which I don't know",https://www.reddit.com/r/tensorflow/comments/5i2b8v/quick_question_running_tensorflow_from_docker/,[deleted],1481614024,[deleted],0,1
15,2016-12-13,2016,12,13,20,5i31pe,Convolutional Autoencoders in Tensorflow,https://www.reddit.com/r/tensorflow/comments/5i31pe/convolutional_autoencoders_in_tensorflow/,pgaleone,1481627612,,0,4
16,2016-12-15,2016,12,15,7,5idift,I turned a tensorflow autoencoder into some JS UI.,https://www.reddit.com/r/tensorflow/comments/5idift/i_turned_a_tensorflow_autoencoder_into_some_js_ui/,cantdutchthis,1481752834,,3,2
17,2016-12-16,2016,12,16,5,5ijwn2,"All code from ""Machine Learning with TensorFlow"" is now available on GitHub",https://www.reddit.com/r/tensorflow/comments/5ijwn2/all_code_from_machine_learning_with_tensorflow_is/,CarbonFire,1481834018,,0,8
18,2016-12-17,2016,12,17,2,5ipn1y,"Is there any resource which someone, with no coding ability, could use to train an image recognition bot with a particular set of images?",https://www.reddit.com/r/tensorflow/comments/5ipn1y/is_there_any_resource_which_someone_with_no/,Gonzo_Rick,1481910895,"I'm really interested in TensorFlow and machine learning, but lack almost any coding experience. I'm hoping there's a web app or downloadable program out there with which someone like myself could either drag and drop labeled images or easily edit pre-written code to point to a directory of a library of such images. ",6,2
19,2016-12-17,2016,12,17,6,5iqyig,Tflearn generator training,https://www.reddit.com/r/tensorflow/comments/5iqyig/tflearn_generator_training/,[deleted],1481925005,[deleted],0,2
20,2016-12-21,2016,12,21,21,5jjqbt,trying to install tensorflow on my laptop for python3,https://www.reddit.com/r/tensorflow/comments/5jjqbt/trying_to_install_tensorflow_on_my_laptop_for/,hugokhf,1482324432,"So I am trying to install tensorflow for python 3 on my laptop, I think I did the installation for both python 2.7 and 3.

anyway, in my tensorflow folder inside my user directory, in the bin, lib and include, it only showed python 2.7?? how do I change that?

    $ python3 
    ...
    &gt;&gt;&gt; import tensorflow as tf
    &gt;&gt;&gt; hello = tf.constant('Hello, TensorFlow!')
    &gt;&gt;&gt; sess = tf.Session()
    &gt;&gt;&gt; print(sess.run(hello))
    Hello, TensorFlow!
    &gt;&gt;&gt; a = tf.constant(10)
    &gt;&gt;&gt; b = tf.constant(32)
    &gt;&gt;&gt; print(sess.run(a + b))
    42
     &gt;&gt;&gt;

I ran the above test, and it printed out 
    b'Hello, TensorFlow!'

instead of just
    Hello, TensorFlow!

does it mean I did not installed it properly?

ps I also used python3 instead of python when doing the test. python won't run as it give me Error importing Tensorflow",4,6
21,2016-12-22,2016,12,22,12,5jobne,Tfrecords guide,https://www.reddit.com/r/tensorflow/comments/5jobne/tfrecords_guide/,warmspringwinds,1482376789,,0,1
22,2016-12-22,2016,12,22,21,5jq8lf,build_image_data error,https://www.reddit.com/r/tensorflow/comments/5jq8lf/build_image_data_error/,[deleted],1482408340,[deleted],0,1
23,2016-12-23,2016,12,23,6,5jtaie,Error installing tf on windows with anaconda,https://www.reddit.com/r/tensorflow/comments/5jtaie/error_installing_tf_on_windows_with_anaconda/,fish___,1482443346,"I currently have a working installation of anaconda (with python 3.5) and I am trying to install tensorflow on my windows laptop but when I run the command to install it (in cmd) some stuff comes up then I get this single error: ""cannot remove entries from nonexistent file c:\program files\anaconda3\lib\site-packages\easy-install.pth"". How can I fix this?
Thanks, fish.",1,2
24,2016-12-23,2016,12,23,13,5jv2u1,Running tensorflow examples only uses 30% of GPU,https://www.reddit.com/r/tensorflow/comments/5jv2u1/running_tensorflow_examples_only_uses_30_of_gpu/,SillyLilBear,1482465675,"Is there a setting that would make tensorflow not fully utilize a GPU (Nvidia 1070) or is it the example.  

I tried a CIFAR and Ensemble example from the tensorflow example git hub, but the GPU never got over 31% utilization for the CIFAR and only got to 42% with the ensemble.",2,2
25,2016-12-25,2016,12,25,12,5k6kvl,Tensorflow re-using a pre-trained model crashes on add training step,https://www.reddit.com/r/tensorflow/comments/5k6kvl/tensorflow_reusing_a_pretrained_model_crashes_on/,[deleted],1482635739,[deleted],0,1
26,2016-12-25,2016,12,25,19,5k7wn4,(X-Post from /r/MachineLearning) tensorflow-qnd: Quick and Distributed TensorFlow command framework to train and evaluate models on multiple computers,https://www.reddit.com/r/tensorflow/comments/5k7wn4/xpost_from_rmachinelearning_tensorflowqnd_quick/,raviqqe,1482662299,,0,2
27,2016-12-26,2016,12,26,4,5k9lvs,ipython notebook for tensorflow (conda?),https://www.reddit.com/r/tensorflow/comments/5k9lvs/ipython_notebook_for_tensorflow_conda/,kewzha,1482692557,"Hello!

I'm trying to figure out how to use ipython notebook with tensorflow. First of all is it possible and convenient to use? Secondly, do I have to install conda? What are the pros and cons of conda (or should I use virtual env)? I have a mac, use pip, and currently do not use virtual env.

Basically I'm looking for an easier way to debug my tensorflow code, because I currently just write a bunch of print statements.

Suggestions appreciated!",1,3
28,2016-12-26,2016,12,26,4,5k9nxg,New Version of TensorFlow,https://www.reddit.com/r/tensorflow/comments/5k9nxg/new_version_of_tensorflow/,kewzha,1482693334,How stable is the new version of TensorFlow? Should I upgrade or wait?,0,1
29,2016-12-27,2016,12,27,4,5kfco5,What are slim RNNs?,https://www.reddit.com/r/tensorflow/comments/5kfco5/what_are_slim_rnns/,kewzha,1482781070,In tensorflow's rnn_cell.py there is a _SlimRNNCell class. I've never heard of slim rnns. What is this?,1,1
30,2016-12-27,2016,12,27,16,5kijxq,Basics Query - While running diagnostics for regression using tensorflow - Is it needed?,https://www.reddit.com/r/tensorflow/comments/5kijxq/basics_query_while_running_diagnostics_for/,HibernationUnLtd,1482823952,"Hello All,

**Apologies if this appears stupid**

I have been studying ML and Statistics concepts since a month and it would be helpful if someone could guide me.

While doing an regression, we have multiple tests like ANOVA, p-val, F/T - tests etc. 
Are they applicable while using tensorflow - or is it because you are using a deep learning neural network, it is not necessary?
In the example on tensorflow.org, while an SGD is run, there are no tests performed. Does a learning NN take care of it, or do we need to run them. 

If we have to run them, is there some example where I can relate.

TL;DR - I am trying to understand whether we need to run diagnostics when using TF and are the applicable - if so how.

Edit1 - Does training take care of not needing to run diagnostic tests?

",0,1
31,2016-12-28,2016,12,28,8,5kmucl,TensorFlow on Azure GPU,https://www.reddit.com/r/tensorflow/comments/5kmucl/tensorflow_on_azure_gpu/,[deleted],1482881120,[deleted],0,1
32,2016-12-28,2016,12,28,8,5kmx5o,TensorFlow on Azure GPU,https://www.reddit.com/r/tensorflow/comments/5kmx5o/tensorflow_on_azure_gpu/,lutzr,1482882024,,2,3
33,2016-12-28,2016,12,28,20,5kpvxj,Roadmap Q : C++ vs Python implementation of Tensorflow,https://www.reddit.com/r/tensorflow/comments/5kpvxj/roadmap_q_c_vs_python_implementation_of_tensorflow/,HibernationUnLtd,1482926022,"What are the features and roadmap of primarily C++ extension of TF, also python.

Thank you in advance",0,2
34,2016-12-29,2016,12,29,0,5kqvwy,Dimensionality in the optimizer loss function.,https://www.reddit.com/r/tensorflow/comments/5kqvwy/dimensionality_in_the_optimizer_loss_function/,aiapplicant,1482940605,"When passing your loss to the optimizer, what shape should you make it? For example, in batch processing, should it be [?,1] or just [1]? Simple question, I know, but I'm just wondering how it should be done because I notice you can pass any size tensor to the optimizer. What do large tensor optimizations do to performance and to convergence?",0,1
35,2016-12-31,2016,12,31,6,5l5utu,how to debug Nan loss?,https://www.reddit.com/r/tensorflow/comments/5l5utu/how_to_debug_nan_loss/,FutureIsMine,1483132408,,0,1
0,2017-1-2,2017,1,2,10,5lii30,Evolutionary Neural Networks backed by TensorFlow and pure Python,https://www.reddit.com/r/tensorflow/comments/5lii30/evolutionary_neural_networks_backed_by_tensorflow/,stuffongithub,1483320413,,0,1
1,2017-1-2,2017,1,2,21,5ll3b8,"Tash: The easy, fast TensorFlow installation/upgrade",https://www.reddit.com/r/tensorflow/comments/5ll3b8/tash_the_easy_fast_tensorflow_installationupgrade/,[deleted],1483361327,[deleted],0,4
2,2017-1-4,2017,1,4,0,5lshhh,Chest Xray image analysis using Deep learning and Transfer Learning in Tensorflow,https://www.reddit.com/r/tensorflow/comments/5lshhh/chest_xray_image_analysis_using_deep_learning_and/,ayush0016,1483457401,,0,1
3,2017-1-7,2017,1,7,9,5mhhqi,Peer-to-peer DMA with Tensorflow?,https://www.reddit.com/r/tensorflow/comments/5mhhqi/peertopeer_dma_with_tensorflow/,dinedal,1483750596,"I was reading http://kaigai.hatenablog.com/entry/2016/09/08/003556 and was curious if Tensorflow or another ML lib could do something like this? I have a NVMe enabled SSD (plugs directly into PCIe)

Can I skip overhead and just have TF read training data directly from this using the same idea as described in the post? Does it do this out of the box?",0,1
4,2017-1-8,2017,1,8,6,5mmxw4,Tutorial with image + other data,https://www.reddit.com/r/tensorflow/comments/5mmxw4/tutorial_with_image_other_data/,q2s3156a,1483824783,"Hello,

I am trying to learn Tensorflow.  I have been reading a number of tutorials and sample code for image classification.  All the ones I have found are based solely on image.

Does anyone know of an example that uses image + other data?  For example, say I am building a flower model. But I would like the input to be image plus latitude/longitude/elevation.  With the idea that certain plants can only live in certain geographies.

Can anyone point me to an example that uses more than image for an input?

thanks",1,2
5,2017-1-9,2017,1,9,3,5ms9pm,x-post from /r/vala,https://www.reddit.com/r/tensorflow/comments/5ms9pm/xpost_from_rvala/,[deleted],1483900094,[deleted],0,1
6,2017-1-9,2017,1,9,3,5msc4x,Vala bindings for TensorFlow (x-post from /r/vala),https://www.reddit.com/r/tensorflow/comments/5msc4x/vala_bindings_for_tensorflow_xpost_from_rvala/,archdria,1483900799,,0,4
7,2017-1-9,2017,1,9,4,5msk7q,Is this something tensorflow could do?,https://www.reddit.com/r/tensorflow/comments/5msk7q/is_this_something_tensorflow_could_do/,marmaladeontoast,1483903113,"I have a (very long) list of short product descriptions, ~250 characters each. Around 90% of the descriptions include a weight (eg 100g, 2L, 200ml) and a quantity (2 cans, *3, 10 packets). I also have columns for product category and price. 

There are a lot of variations on how weight and quantity are given in the description, so my attempts with regex have been limited.

I want to be able to train a model that I can feed in a row of data and get it to spit out weight and quantity values (with precision estimates).

So....Is this a good use case for tensorflow? ",1,2
8,2017-1-11,2017,1,11,7,5n8bm2,Tensorflow with inacurate data,https://www.reddit.com/r/tensorflow/comments/5n8bm2/tensorflow_with_inacurate_data/,NicoJuicy,1484089069,"I'm thinking about a project with tensorflow ( haven't got any experience yet). But i currently run into a logic problem.

I have 2 fases in learning something interesting with tensorflow, it's based on images with data.

In the first phase, i have 3 images and a measurement. Those measurements aren't precise enough.

This would be the first dataset ( it's easier and not expensive).

In the second phase, i have a more limited dataset ( 3 images and a measurement). But the data is as accurate as possible.

How would i define the difference in datasets? So it takes some sort of median in the first data set and takes the results in the second dataset very serious. So i have it right from the start.",1,1
9,2017-1-12,2017,1,12,1,5nd26i,Finding Bugs in TensorFlow with LibFuzzer,https://www.reddit.com/r/tensorflow/comments/5nd26i/finding_bugs_in_tensorflow_with_libfuzzer/,dga-dave,1484151671,,0,2
10,2017-1-12,2017,1,12,23,5nji4p,Cuda GPU question,https://www.reddit.com/r/tensorflow/comments/5nji4p/cuda_gpu_question/,WhiteHorseTito,1484229824,"Can anyone recommend a GPU strictly for tensorflow use? 
It turns out my 740sc is not cutting it and I need to upgrade without breaking the bank. I'm looking to spend ~$300 if that helps. ",10,1
11,2017-1-13,2017,1,13,14,5nox1f,Brainstorming a Horror Computer Game Using TensorFlow,https://www.reddit.com/r/tensorflow/comments/5nox1f/brainstorming_a_horror_computer_game_using/,JonoExplainsThings,1484287009,,0,2
12,2017-1-14,2017,1,14,0,5nr592,Here is a python script for viewing MNIST images and their labels,https://www.reddit.com/r/tensorflow/comments/5nr592/here_is_a_python_script_for_viewing_mnist_images/,Boozybrain,1484320617,,4,5
13,2017-1-16,2017,1,16,22,5oavlc,Haskell and TensorFlow,https://www.reddit.com/r/tensorflow/comments/5oavlc/haskell_and_tensorflow/,mohanradhakrishnan,1484573967,"Do people use Haskell Spock UI and Haskell Tensor bindings for ML projects ? Anyone using this combination ?

How does one start using TensorFlow with this combination ? Are there recommendations for machine configurations to use ? What if it is image recognition ?",2,5
14,2017-1-17,2017,1,17,0,5obany,Implementing multiple RNN in Tensorflow,https://www.reddit.com/r/tensorflow/comments/5obany/implementing_multiple_rnn_in_tensorflow/,fralbalbero,1484579403,"I am designing a neural network in Tensorflow like the one described here: http://www.hexahedria.com/2015/08/03/composing-music-with-recurrent-neural-networks/
I am focusing on the first LSTM layer only. If I understood correctly, there are N parallel RNN. Each RNN receives an input of size [batch_size, max_time, input_size], where input_size is bidimensional. Furthermore, each RNN receives input from the neighbours RNN.
How can I implement this in Tensorflow? I suppose I have to use MultiRNNCell but I can't figure out how to use it. More generally, how can I make different RNNs interact? I mean, making a RNN process the information coming from another one. Should I just append the output of a RNN to the input of another?",3,4
15,2017-1-18,2017,1,18,7,5olcuf,How are you using TensorFlow to help your life and/or others?,https://www.reddit.com/r/tensorflow/comments/5olcuf/how_are_you_using_tensorflow_to_help_your_life/,danyadevorah,1484692984,how are you using TensorFlow to help your life and/or others? might you explain how you are making a difference using TensorFlow in a way that luddites could understand? ,0,0
16,2017-1-19,2017,1,19,9,5ot91r,Can TensorFlow Accomplish This?,https://www.reddit.com/r/tensorflow/comments/5ot91r/can_tensorflow_accomplish_this/,Matrixey,1484785023,"I'm curious to know if tensor flow can learn from a list of variation of similar names (Alex, Anex,Alexx, Aalex..etc) and learn from the entire list for what I'm looking for and as I provide a name to it decide whether it matches the pattern of the list that it learnt from. For example, if I give it the name ""Alnixs"" it needs to know not to add it to the list and discard it because it does not match the list it learnt from. If this can be done, how can I approach this? Recommendations? Guidance? 
Thanks!",2,1
17,2017-1-20,2017,1,20,4,5oymru,Tensorflow model not saving or restoring properly,https://www.reddit.com/r/tensorflow/comments/5oymru/tensorflow_model_not_saving_or_restoring_properly/,FutureIsMine,1484853812,,0,2
18,2017-1-21,2017,1,21,10,5p82w5,How is TF's concept of Sessions and having variables initialized in a session beneficial performance wise?,https://www.reddit.com/r/tensorflow/comments/5p82w5/how_is_tfs_concept_of_sessions_and_having/,sj90,1484963032,"I don't have enough of a CS background to understand how TF was developed and implemented. I have read it's graph based, and each node in the graph is an operation. And a session basically executes those operations [is this a correct understanding?]

But why this kind of structure? Why having a Session is better, especially from a performance perspective? What are the drawbacks of this?

Any resources to understand this better?",1,2
19,2017-1-22,2017,1,22,22,5pgsfl,Will Google continue development in TF-Slim after it has chosen Keras?,https://www.reddit.com/r/tensorflow/comments/5pgsfl/will_google_continue_development_in_tfslim_after/,smalldata99,1485090085,"The biggest draw of TF-slim is its easier ability to get the official pretrained model from Google. But TF-Slim has quite a lot of bugs and the updates are slow, although I do see that the features (if they work) are pretty awesome.

Will Google continue development in TF-slim? Seems like it has become a natural choice to go to Keras but I'm hoping for continued development in Tf-slim for its pretrained models!",3,2
20,2017-1-23,2017,1,23,14,5pmn9x,How would you use Tensorflow to alter images? With a few example problems.,https://www.reddit.com/r/tensorflow/comments/5pmn9x/how_would_you_use_tensorflow_to_alter_images_with/,theredknight,1485150005,"I'm still learning ML Tools like scipy and Tensorflow and would love to get a grasp on how people pull off things like [neural-style](https://github.com/anishathalye/neural-style) and [neural-doodle](https://github.com/alexjc/neural-doodle).  
  
And so, I'm going to start simpler with some basic project. I've looked through their code and think I get the main idea, but haven't gotten very far beyond pseudocode. But since I'm tackling this, I thought other people might want to practice something like this as well and why not share this or toss it out as a challenge to others so we all can benefit from how to tackle ML problems. So here's my planned projects to build up to this.
  
**A Simpler Problem: Color Removal**  
What if you wanted to do something more simple? Such as replace all of the reddish color in [one image](http://sites.psu.edu/ashtonrclblog/wp-content/uploads/sites/5474/2014/03/Kool-Aid-Man.jpg) to [blue](http://i50.photobucket.com/albums/f331/theMcollection/Lionskoolaid.jpg)?  
  
In my pseudocode I have it broken down as such:  
  
1. Take in the first image and convert it to a tensor (via scipy imread as utilized [here](https://github.com/anishathalye/neural-style/blob/master/neural_style.py) ).  
2. Pick a color at random from within the image's palette.  
3. Pick an acceptable range near that color from within the image's palette.
4. Pick a color at random from within the goal image (in this case red kool aid man)'s palette.  
5. Replicate the range of red colors to a range of blue colors. 
6. Do the transformation.
7. Write the output image file.
8. Compare using PIL's image_entropy function: (ImageChops.difference(img1, img2))  
9. Try to minimize the difference, repeat until minimized.  
  
Now to fill in the pieces. Would you guys use a softmax to do this? Or does Tensorflow have [something better which is utilized for this purpose](https://www.tensorflow.org/versions/master/api_docs/python/image/) which you'd use? Would you even use Tensorflow? Or just stick to sci-kit learn?

**Project Iteration 2 - Texture exchange**  
The next iteration of the project will be replacing a texture, so exchanging hair from a dog with the bark of a tree? Could I write a tensorflow program to endlessly generate images of [Birds with Arms](http://knowyourmeme.com/memes/birds-with-arms)?  
  
Some Questions:   

* See with the texture replacement, I don't have an image I can test it against. How do you tackle that?  
* Would you use an adversarial network and feed it my generated birds with arms vs others' birds with arms like they do in [StackGAN](https://github.com/hanzhanggit/StackGAN)?  
* Does anyone have any code they can show on how to set that up besides how StackGan did it? I'm fairly certain neither neural-style or neural-doodle used an adversarial network, so I'm still working out how they did that, but I'll get to that.

Anyways, hope this breakdown is useful for someone who is learning on the road as well. I'll let you all know how it comes along and let me know if you have any suggestions or things you've tried or would try. If you want to jump in and try your hand at it, I'd love to see other's tackling this.

edit: formatting, and I accidentally a word

  
",0,5
21,2017-1-23,2017,1,23,20,5po0gb,Weekly email newsletter with TensorFlow tutorials and articles,https://www.reddit.com/r/tensorflow/comments/5po0gb/weekly_email_newsletter_with_tensorflow_tutorials/,relevate,1485169276,,0,2
22,2017-1-25,2017,1,25,2,5pxcuq,Could I use tensorflow for search/optimization problems?,https://www.reddit.com/r/tensorflow/comments/5pxcuq/could_i_use_tensorflow_for_searchoptimization/,aexolthum,1485278309,"I've recently decided to work on a problem that involves finding an optimal schedule. Without getting too specific, I will have a a schedule scoring function and I'm going to score schedules and manipulate them in order to find an optimal one.
I've been thinking of using Simmulated Annealing, does tensorflow support this algorithm/algorithms of its type?",0,7
23,2017-1-25,2017,1,25,17,5q224s,Filter responses in image style recognition,https://www.reddit.com/r/tensorflow/comments/5q224s/filter_responses_in_image_style_recognition/,[deleted],1485331667,[deleted],0,2
24,2017-1-26,2017,1,26,2,5q4k64,How to structure matrix data for TensorFlow? Sorry for the newbie question :S,https://www.reddit.com/r/tensorflow/comments/5q4k64/how_to_structure_matrix_data_for_tensorflow_sorry/,[deleted],1485365769,[deleted],0,1
25,2017-1-26,2017,1,26,6,5q5wet,Can tensorflow be used like normal python ?,https://www.reddit.com/r/tensorflow/comments/5q5wet/can_tensorflow_be_used_like_normal_python/,hyperqube12,1485378379,"I only ask this here because I've been using Tensorflow for a while now and it is completely driving me insane. 
Can someone please post equivalent Tensorflow code for elementary stuff like:

    for i in range(n):
         # do something

or

    if CONDITION:
         do something1
    else:
        do something2

and

    while CONDITION:
        do something

and also simple variable assignment like:

    A = 10
    
    B = A

This might seem like stupid simple but the documentation does not really help that much. I understand that it must be somewhat different from python code, but I need these very basic building blocks to make any kind of code work.        ",3,3
26,2017-1-28,2017,1,28,23,5qnxbh,Feeding non-placeholder variables in model (seq2seq),https://www.reddit.com/r/tensorflow/comments/5qnxbh/feeding_nonplaceholder_variables_in_model_seq2seq/,[deleted],1485615533,[deleted],0,1
27,2017-1-29,2017,1,29,0,5qo5ia,Ultra Deep Convolution,https://www.reddit.com/r/tensorflow/comments/5qo5ia/ultra_deep_convolution/,Ulysius,1485618359,"The existence of VGG-19 pretrained models has been a great help for my research. Are there instances of ever deeper models available, for example with more than 5 layers of convolution?",1,0
0,2017-2-1,2017,2,1,18,5rejp5,Debugging pointers,https://www.reddit.com/r/tensorflow/comments/5rejp5/debugging_pointers/,Tall_Josh,1485940985,"Hi all, 

I'm quite new to TF. I have written a Deep Q-Learning CNN to control a simple driving simulator. I've managed to plot the weights, biases and outputs of my fully connected layers on TensorBoard however, I'm not sure what I'm looking for. 
I've watched [this] (https://www.youtube.com/watch?v=vq2nnJ4g6N0&amp;t=2738s). It mentions a normally distributed set of weights is good. I was wondering if anyone has any other debugging tips.
Also, I'm using Relu for my activation functions but many of my 'rewards' and hence my 'qualities' output by the CNN are negative should I be using something like a Sigmoid instead?
[here are some pics of what I'm doing](https://drive.google.com/drive/folders/0B8qBMyILKQdoUWlXWU4xN2NSakU?usp=sharing)
",0,1
1,2017-2-3,2017,2,3,0,5rn81s,[seq2seq] How to to find an unnamed node,https://www.reddit.com/r/tensorflow/comments/5rn81s/seq2seq_how_to_to_find_an_unnamed_node/,Jean-Porte,1486047654,"Hello,
I'm using tensorflow legacy seq2seq and I'm wondering how I can feed to the encoder final state (which should be the decoder initial memory) in order to decode any vector without having to feed encoder input.

https://github.com/tensorflow/tensorflow/blob/cb17d1b0e2b581b5da1d9597b7929ba764749d38/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py

The node I want to feed is ""encoder_state"", defined on line 359 https://github.com/tensorflow/tensorflow/blob/cb17d1b0e2b581b5da1d9597b7929ba764749d38/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py#L359

However, it's not named and I can't find it in the graph. I guess I could rewrite the code and name it but it seems messy. Do you have any suggestion ?

Thanks",2,1
2,2017-2-3,2017,2,3,21,5rtkjz,"What are some easy, interesting TensorFlow demo ideas for advanced high school students?",https://www.reddit.com/r/tensorflow/comments/5rtkjz/what_are_some_easy_interesting_tensorflow_demo/,bongololona,1486123695,"I am giving a demo for TensorFlow to my students this week. I want to build something interesting, and easy right in front of them. Any ideas about what fits the bill? ",2,5
3,2017-2-6,2017,2,6,15,5scmph,What are the tensorflow cifar10 tutorial input/output layers?,https://www.reddit.com/r/tensorflow/comments/5scmph/what_are_the_tensorflow_cifar10_tutorial/,Happy_Prime,1486361486,"I'm relatively new to tensorflow - still trying to get a handle on everything. I'm aiming to be able to export a protobuf file from a modified version of the tutorial code in the [Deep CNN Tutorial](https://www.tensorflow.org/tutorials/deep_cnn/), with the aim of eventually importing it in a C++ program. However, I'm having difficulty identifying the appropriate input and output layers. I think it's all defined in the inference function in the cifar10.py file, but I'm not really sure. Pointers would be appreciated.",3,2
4,2017-2-6,2017,2,6,17,5sd5rt,The deepdream example doesn't show the activation's patterns,https://www.reddit.com/r/tensorflow/comments/5sd5rt/the_deepdream_example_doesnt_show_the_activations/,de-sacco,1486370790,"I am trying the deepdream example in examples/tutorials, and I'd like to show the previews of the activation patterns.
The show_graph() instruction doesn't work for me on both Safari and Chrome, the tf-graph-basic element doesn't render anything but white space. Can anybody confirm?",0,2
5,2017-2-8,2017,2,8,15,5sr6p9,Identifying one image in a group of images or video,https://www.reddit.com/r/tensorflow/comments/5sr6p9/identifying_one_image_in_a_group_of_images_or/,mohanradhakrishnan,1486536460,"I have taken many ML MOOC's and now I want  to explore this topic. Looking for some pointers to start this. My perspective is that of a coder interested in Haskell Yesod and TensorFlow bindings.

I want to identify a particular image from a group. If possible I would like to track one  person in a video. I found this https://research.googleblog.com/2017/02/advancing-research-on-video.html when I was searching.",0,1
6,2017-2-9,2017,2,9,3,5suobk,Factorization machines for recommendations systems with TensorFlow,https://www.reddit.com/r/tensorflow/comments/5suobk/factorization_machines_for_recommendations/,tschellenbach,1486580226,,0,2
7,2017-2-9,2017,2,9,10,5sx2aj,"Learn TensorFlow and Keras, 20% off for MLTrain in Atlanta",https://www.reddit.com/r/tensorflow/comments/5sx2aj/learn_tensorflow_and_keras_20_off_for_mltrain_in/,vasiloglou,1486604095,"If you want to learn how to code machine learning and AI algorithms in TensorFlow/Keras attend mltrain.cc on March 3rd and March 4th in Atlanta. On the first day you will be exposed to the fundamentals of Tensorflow and you will learn how to code your first algorithms and how to use the tf.learn package. On the second day you will get exposed to more advanced topics, such as how to do linear algebra, how to code advanced deep learning architectures and at last how to apply them in images, text and logic. You can register for both days or for each day independently. For more information visit http://www.mltrain.cc/single-post/2017/01/20/MLTrain-Atlanta-33-34-2017. Register using the code ""ATL_REDDIT"" and you will get 20% off. Ticket prices go up Friday February 10th midnight. For more information and inquires email nvasil+mltrain@gmail.com.",0,0
8,2017-2-9,2017,2,9,18,5sz4wr,What are your recommendations for a good price/performance reasonably low power nVidia system for Tensorflow?,https://www.reddit.com/r/tensorflow/comments/5sz4wr/what_are_your_recommendations_for_a_good/,eleitl,1486634225,"Something cheaper than Jetson TX1 preferably. Consumer nVidia probably.

Thanks!",8,3
9,2017-2-9,2017,2,9,20,5szkxk,[help]Can't use tensorflow on Windows 10,https://www.reddit.com/r/tensorflow/comments/5szkxk/helpcant_use_tensorflow_on_windows_10/,hapliniste,1486641248,"Hi, I'm trying to use tensorflow (GPU) on Windows 10 but can't get it to work.

I use Anaconda3 with python 3.5.2 64b as requested by tensorflow 0.12.
I've created an env in conda and installed the wheel for tensorflow-gpu (had to download and rename the file with py3-none so it would install, as recommanded on the web).

The thing is even tough TF is installed, python can't find it!

Here's the infos that I get out from installing it and trying to import it:

    (C:\Users\Alexandre\Anaconda3_p35\envs\tf) C:\Users\Alexandre\Anaconda3_p35\Scripts&gt;pip install tensorflow-gpu
    Requirement already satisfied: tensorflow-gpu in c:\users\alexandre\anaconda3_p35\lib\site-packages
    Requirement already satisfied: wheel&gt;=0.26 in c:\users\alexandre\anaconda3_p35\lib\site-packages (from tensorflow-gpu)
    Requirement already satisfied: protobuf&gt;=3.1.0 in c:\users\alexandre\anaconda3_p35\lib\site-packages (from tensorflow-gpu)
    Requirement already satisfied: numpy&gt;=1.11.0 in c:\users\alexandre\anaconda3_p35\lib\site-packages (from tensorflow-gpu)
    Requirement already satisfied: six&gt;=1.10.0 in c:\users\alexandre\anaconda3_p35\lib\site-packages (from tensorflow-gpu)
    Requirement already satisfied: setuptools in c:\users\alexandre\anaconda3_p35\lib\site-packages (from protobuf&gt;=3.1.0-&gt;tensorflow-gpu)
    Requirement already satisfied: appdirs&gt;=1.4.0 in c:\users\alexandre\anaconda3_p35\lib\site-packages (from setuptools-&gt;protobuf&gt;=3.1.0-&gt;tensorflow-gpu)
    Requirement already satisfied: packaging&gt;=16.8 in c:\users\alexandre\anaconda3_p35\lib\site-packages (from setuptools-&gt;protobuf&gt;=3.1.0-&gt;tensorflow-gpu)
    Requirement already satisfied: pyparsing in c:\users\alexandre\anaconda3_p35\lib\site-packages (from packaging&gt;=16.8-&gt;setuptools-&gt;protobuf&gt;=3.1.0-&gt;tensorflow-gpu)
    
    (C:\Users\Alexandre\Anaconda3_p35\envs\tf) C:\Users\Alexandre\Anaconda3_p35\Scripts&gt;python
    Python 3.5.2 |Continuum Analytics, Inc.| (default, Jul  5 2016, 11:41:13) [MSC v.1900 64 bit (AMD64)] on win32
    Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
    &gt;&gt;&gt; import tensorflow
    Traceback (most recent call last):
      File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
    ImportError: No module named 'tensorflow'
    &gt;&gt;&gt;    

Do you have any idea on what the problem might be? In the meantime I'll create a VM with Ubuntu and run it on CPU, but it's not a great solution...

Thank for reading!

EDIT: I tried installing the 1.0 release of TF (not the rc) and it worked well! (with pip)",9,3
10,2017-2-10,2017,2,10,2,5t17e7,TensorFlow howto: a universal approximator inside a neural net,https://www.reddit.com/r/tensorflow/comments/5t17e7/tensorflow_howto_a_universal_approximator_inside/,morgangiraud,1486659676,,1,5
11,2017-2-11,2017,2,11,23,5texwc,DTB: Dynamic Training Bench (for Tensorflow models),https://www.reddit.com/r/tensorflow/comments/5texwc/dtb_dynamic_training_bench_for_tensorflow_models/,pgaleone,1486823369,"[Dynamic Training Bench](https://github.com/galeone/dynamic-training-bench) is a tool to simplify the training, evaluation and hyperparameter tuning of Tensorflow models.

I built this tool for 4 main reasons:

1. The training phase of a ML model is almost the same for every model of a certain type
2. When we train a model we usually want to monitor some metrics and visualize some result
3. During the training phase, we want to save the best model, where the goodness of the model is given by its performance on the evaluation set, measured by some metric
4. There's a lack of engineering in the ML field

I think that this last point requires an explanation: usually, researcher builds their models and input sources as they want.
Even if different researchers uses Tensorflow, everyone follows it's own pattern:

* someone writes a huge python file with everything inside
* someone writes different scripts with different names and write somewhere how to execute it
* someone refers to some dataset that's not provided with the code and who want's to reproduce the experiment must waste its time looking for this dataset on the internet.

**In short**:  it's hard to reproduce the experiments, running the code, obtain and preprocess the datasets.
As a consequence, there are lots of people that are *wasting their time* reimplementing stuff.

DTB aim is (also) to standardize the definition of the input sources (how to obtain a dataset, how to preprocess it, how to split in train/evaluation/test) and the training procedures.
Moreover, even models should be standardized: if I'm defining a classifier I must implement a Classifier interface; if I'm defining a Regressor I must implement another interface, and so on...

I invite you to browse the [models](https://github.com/galeone/dynamic-training-bench/tree/master/models) and [inputs](https://github.com/galeone/dynamic-training-bench/tree/master/inputs) folders to find out how I defined the interfaces and their implementations.

Clearly, there's still a lot of work to do. There are lots of datasets that can be implemented, tests to do, interfaces to define and implement and so on... Moreover, even the organization of the train.py and evaluate.py file can be improved, maybe creating an interface `TrainProcess` and it's specializations like `TrainClassifier`, `TrainRegressor`, ...

I'm looking for collaborators!",0,2
12,2017-2-13,2017,2,13,1,5tm4p5,[seq2seq] En-Fr translate: Reason for using output_projection,https://www.reddit.com/r/tensorflow/comments/5tm4p5/seq2seq_enfr_translate_reason_for_using_output/,critiqjo,1486915684,"Ref: https://github.com/tensorflow/models/blob/f63a80a/tutorials/rnn/translate/seq2seq_model.py#L93-L101

It says:

&gt; If we use sampled softmax, we need an output projection.

From what I understand, output_projection is used when we do embedding. Even though both sampled softmax and embedding is done because the complete set of output labels is large, they don't have any direct (cause-effect) relation with each other, right? ...in which case lines 98-101 should come before the `if` block?

_UPDATE:_ I just found out that the seq2seq tutorial is obsolete as of v1.0. And I found an example using the new API: https://github.com/ematvey/tensorflow-seq2seq-tutorials",2,1
13,2017-2-14,2017,2,14,16,5tyss9,"This post was a hit on LinkedIn. Sharing it here, hope it helps something. I had some struggle with tensorflow documentation while getting started. So, I want to create a series of tutorials to help smart people quickly start with TF. 1st one is here, feedback will be great.",https://www.reddit.com/r/tensorflow/comments/5tyss9/this_post_was_a_hit_on_linkedin_sharing_it_here/,sankit123,1487056487,,0,13
14,2017-2-14,2017,2,14,23,5u0llo,Will there be many API changes between TensorFlow 1.0.0-rc2 and TensorFlow 1.0.0 final release?,https://www.reddit.com/r/tensorflow/comments/5u0llo/will_there_be_many_api_changes_between_tensorflow/,Franck_Dernoncourt,1487083929,(I am starting a new TensorFlow project and hesitate between 0.12 and 1.0.0-rc2),0,4
15,2017-2-15,2017,2,15,23,5u7th6,Accelerating TensorFlow training and inference using OpenCL,https://www.reddit.com/r/tensorflow/comments/5u7th6/accelerating_tensorflow_training_and_inference/,rodburns,1487170325,,1,7
16,2017-2-16,2017,2,16,8,5ub3jm,We Need to Go Deeper: A Practical Guide to Tensorflow and Inception  Initialized Capital,https://www.reddit.com/r/tensorflow/comments/5ub3jm/we_need_to_go_deeper_a_practical_guide_to/,vincechu,1487200967,,0,6
17,2017-2-16,2017,2,16,9,5ubjlr,TensorFlow Dev Summit now live streaming,https://www.reddit.com/r/tensorflow/comments/5ubjlr/tensorflow_dev_summit_now_live_streaming/,blazeAmaze,1487205762,,0,1
18,2017-2-16,2017,2,16,10,5ubox0,TensorFlow v1.0 announced!,https://www.reddit.com/r/tensorflow/comments/5ubox0/tensorflow_v10_announced/,blazeAmaze,1487207436,,0,17
19,2017-2-16,2017,2,16,12,5ucbn2,"[help] Is it possible to suppress TensorFlow wasn't designed to use ____ instructions, but these are available on your machine and could speed up CPU computations?",https://www.reddit.com/r/tensorflow/comments/5ucbn2/help_is_it_possible_to_suppress_tensorflow_wasnt/,nazisallthewaydown,1487214775,"ubuntu 16.04, python 2.7

All this gets output to the console every time I run a script:

    W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
    W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
    W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
    W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
    W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
    W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
",1,2
20,2017-2-16,2017,2,16,15,5ud7s7,How to write a new optimization technique [Help request],https://www.reddit.com/r/tensorflow/comments/5ud7s7/how_to_write_a_new_optimization_technique_help/,jrkirby,1487226550,"I have an idea for an optimization algorithm on neural nets that I want to try out.  Instead of using gradient descent to update all the weights at once, I want to try using another technique to update a single weight, or a small number of weights each iteration. I want to use the gradients, so I need back propagation.

Can someone give me some high level direction on how to attempt this with tensorflow? It seems like I would have to write a new operator (or several) in C++, but perhaps there is an easier way?

If I do have to write new operators, can someone give me direction on doing that? Are there any useful guides towards writing TF ops? It seems I just need to go to [ops/training_ops](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/training_ops.cc), to register a new function, the go to [kernels/training_ops](https://github.com/tensorflow/tensorflow/blob/a0d784bdd31b27e013a7eac58a86ba62e86db299/tensorflow/core/kernels/training_ops.cc) and implement it. Then I can use it after I compile my edited version of TF in a python script and test it out. Are there any other major steps I'm missing?",0,3
21,2017-2-17,2017,2,17,4,5uhac5,Docker issues,https://www.reddit.com/r/tensorflow/comments/5uhac5/docker_issues/,nio88,1487273810,"Hi guys,
Im a newbie in ML and tensor flow, and Im trying to follow the Tensorflow for poets tutoral. Everything goes fine but in some point randomly, when Im creating bottlenecks for my images for different categories, docker exit abruptly.
with this error:

ERRO[0330] error getting events from daemon: EOF

The number error, not always is the same, and the error not always is in the same image, sometimes is earlier and sometimes is later, I mean, sometimes container crash after processing 10 images, and another time after processing 400, but never finish :(.
Im in OSX with this version of docker Version 1.13.1-beta42 (15350).

I was searching on internet for finding people with same issue, but no luck. 

Any help is appreciated.",5,1
22,2017-2-17,2017,2,17,6,5uhu8y,[advice] TensorFlow in production,https://www.reddit.com/r/tensorflow/comments/5uhu8y/advice_tensorflow_in_production/,villasv,1487279026,"I guess most people use tf as data science experimentation or for pure academic works, but time has come to my model enter the production service at my company.

Thing is, TensorFlow Serving is quite complicated and is becoming a real pain to design a system around it. Even getting a simple model like MNIST working is quite consuming, let alone making use of its ""flexibility"" to serve something else (like a sklearn model).

What are the current best practices for serving tensorflow models (or more generally any ML model)? Is loading the serialized model from disk and running it much worse than TF Serving? What about necessary preprocessing, is it done separately?

Any directions are welcome.",5,6
23,2017-2-17,2017,2,17,10,5uj8xc,Some questions related to Tensorflow by a noob,https://www.reddit.com/r/tensorflow/comments/5uj8xc/some_questions_related_to_tensorflow_by_a_noob/,fretboard_squatter,1487293293,"1- Should I start with tensorflow on Windows or Ubuntu?

2- Will CUDA 8.0  run on Ubuntu 16.10?

3- I tried setting up tensorflow on Windows using Anaconda and CMD but got the same error message. ""...not supported on this wheel.."" I have a 64 bit Windows 10 installation so I don't understand why I am having this compatibility issue.

Any help would be hugely appreciated. Thanks in advance guys!",5,3
24,2017-2-17,2017,2,17,12,5ujugk,Trying to create an RNN for a Rubik's Cube,https://www.reddit.com/r/tensorflow/comments/5ujugk/trying_to_create_an_rnn_for_a_rubiks_cube/,OikuraZ95,1487300687,"Hi Everyone, I am trying to create an Recurrent Neural Net with LSTM for a 2x2x2 Rubiks Cube with Tensorflow. I've already made Feed-Forward networks for solving the cube (with a max scramble size of 6 moves) and achieved an solve rate of 47%. However, I want to improve that by using RNNs. However I am not entirely sure how to train the network here. The way I want this to work, is by sending in the cube state at each time step. Essentially from a scrambled state, there are a sequence of moves that lead it to a solved state. I want it to predict those moves at each step. I have the data and training the network doesn't seem too hard if I am understanding this correctly, but every RNN LSTM tutorial only gets a prediction at the end of the time-steps. I want to get a prediction at each time step and it must also effect the next incoming cube-state if that makes sense. The reason I want an LSTM network is because the previous network sometimes finds itself in bad scenarios. For example, it may get stuck on a particular cube state and do the same moves over and over again. It may simply rotate the right face and then rotate it back in the opposite direction over and over again. I actually managed to fix this by also letting the feed-forward network taking in the last action that was made into the cube (Essentially making it an RNN) and that increased my solving rate by 5%, but I would like to achieve better results. I would like your guys input and opinions on the matter. Thanks very much!!!


**TL;DR**: The model should take in the vector state of the cube and outputs a one-hot vector of what move to make. These methods have already been implemented for a feed-forward network, but how would I make it work for an LSTM based network?",2,7
25,2017-2-18,2017,2,18,6,5uou27,Is there a tutorial or class for new features in TF 1.0,https://www.reddit.com/r/tensorflow/comments/5uou27/is_there_a_tutorial_or_class_for_new_features_in/,where_is_the_mustard,1487367225,"I took the Udacity class for TF and found it really helpful. I hope they either update that class, or upload a new one.

Anyone know if this already exists?",3,7
26,2017-2-19,2017,2,19,4,5uu2ay,[Keras] Should I apply an activation function to the last layer when using binary_cross_entropy loss function?,https://www.reddit.com/r/tensorflow/comments/5uu2ay/keras_should_i_apply_an_activation_function_to/,iamiamwhoami,1487445392,,9,5
27,2017-2-20,2017,2,20,17,5v3i1h,Strange Windows TF (cpu) output,https://www.reddit.com/r/tensorflow/comments/5v3i1h/strange_windows_tf_cpu_output/,True-Chainz,1487579616,"http://imgur.com/a/YrcYA
While testing my TF install I got this strange output (see picture above). Seems like every time it accesses some file in the library it prints it out on the console.
Is this normal? If not how do I get a normal output?
Thanks for any help.",3,3
28,2017-2-20,2017,2,20,20,5v400j,Tensorflow and Django,https://www.reddit.com/r/tensorflow/comments/5v400j/tensorflow_and_django/,gautamrbharadwaj,1487589182,"When I try to run tensorflow in Django it is giving me this error and I am getting this error, can anyone tell me how to solve this error ?

Tensor(""Variable:0"", shape=(40, 20), dtype=float32_ref) must be from the same graph as Tensor(""Variable_2/read:0"", shape=(), dtype=float32)",4,1
29,2017-2-21,2017,2,21,17,5vagf2,TensorFlow Does not work in Jupyter Notebook,https://www.reddit.com/r/tensorflow/comments/5vagf2/tensorflow_does_not_work_in_jupyter_notebook/,jackbrucesimpson,1487665954,"I compiled the GPU (CuDA) enabled version of TensorFlow on my 2013 MacBook Pro (OS X Sierra).

If I import the library it works perfectly, but if I try to import it in the Jupyter Notebook, I come across a weird bug. My path info for CuDA is:

Does anyone know why this is happening? Is it a bug in TF?",6,0
30,2017-2-22,2017,2,22,2,5vcu1m,tensorflow with rstudio,https://www.reddit.com/r/tensorflow/comments/5vcu1m/tensorflow_with_rstudio/,mrchypark,1487698542,,1,1
31,2017-2-22,2017,2,22,4,5vdowt,Does anyone know of an example using multiple GPUs in Keras?,https://www.reddit.com/r/tensorflow/comments/5vdowt/does_anyone_know_of_an_example_using_multiple/,iamiamwhoami,1487706607,"I have a model that's too big to run on a single GPU. I've seen some allusions to it being possible, but I'm having trouble finding concrete examples. I've also seen some references to model parallelism vs data parallelism. I think I want model parallelism, but I'm having some trouble understanding the difference.",0,2
32,2017-2-22,2017,2,22,11,5vg5qg,models trained on gpu not loading properly on cpu only.,https://www.reddit.com/r/tensorflow/comments/5vg5qg/models_trained_on_gpu_not_loading_properly_on_cpu/,FutureIsMine,1487732000,,0,2
33,2017-2-23,2017,2,23,4,5vkukv,Using the latest tensorflow docker image? It was just updated. Here's a list of everything inside.,https://www.reddit.com/r/tensorflow/comments/5vkukv/using_the_latest_tensorflow_docker_image_it_was/,weighanchore,1487792249,,0,3
34,2017-2-23,2017,2,23,12,5vnuro,How does TensorFlow use GPUs?,https://www.reddit.com/r/tensorflow/comments/5vnuro/how_does_tensorflow_use_gpus/,real_charlie_parker,1487820681,,1,7
35,2017-2-24,2017,2,24,6,5vtfg8,http://stackoverflow.com/questions/42426960/how-does-one-train-multiple-models-in-a-single-script-in-tensorflow-when-there-a,https://www.reddit.com/r/tensorflow/comments/5vtfg8/httpstackoverflowcomquestions42426960howdoesonetra/,[deleted],1487887143,[deleted],3,0
36,2017-2-24,2017,2,24,12,5vv9fi,Why not tensorflow uses the convolve() function in Eigen to implement convolution?,https://www.reddit.com/r/tensorflow/comments/5vv9fi/why_not_tensorflow_uses_the_convolve_function_in/,sunalbert,1487907450,"I find that the convolve() function has been implemented in Eigen(eigen/unsupported/Eigen/CXX11/src/Tensor/TensorConvolution.h),but tensorflow use another function SpatialConvolution implemented in /tensorflow/core/kernels/eigen_spatial_convolutions.h. Why tensorflow uses SpatialConvolution() instead of convolve() Do the  
two functions have difference in performance?",0,2
37,2017-2-24,2017,2,24,19,5vwst5,combine layers from different trained instances of NN,https://www.reddit.com/r/tensorflow/comments/5vwst5/combine_layers_from_different_trained_instances/,deluded_soul,1487932330,"I am using tensorflow to train two instances of the same neural network with two different datasets. The network itself is quite simple with an input and output layer and 6 hidden layers (each layer is a 20 neurons followed by a non-linear activation function).

I can train the network with two different datasets and that is fine. Now, what i want to do is basically create a new network which is a combination of these two trained networks. In particular, I want the input and the first 3 layers to be from one of the trained network and the last 3 layers and the output layer to be from the other network. 

I am very new to tensorflow and have not found a way to do this. Can someone point me to the API or some way to do this sort of hybrid networks?
",0,1
38,2017-2-25,2017,2,25,0,5vy0bk,How to Truncate Backpropagation in RNN?,https://www.reddit.com/r/tensorflow/comments/5vy0bk/how_to_truncate_backpropagation_in_rnn/,brandking,1487949616,"Note: [cross-post from ML Questions.](https://www.reddit.com/r/MLQuestions/comments/5vxstw/how_to_truncate_backpropagation_in_rnn/)

Using TensorFlow I'm attempting to classify inputs based on sequences of pixels. The data set is [55,000 x 784] where 55,000 is the number of instances and 784 is the number of features (pixels).

The code I've written creates 550 batches of size 100, with each element in the batch having 784 features. The code loops over the batches feeding one batch at a time to the RNN (LSTM). The code prior to processing the data creates 8 mini-batches each having 98 features. These mini-batches are looped over and used to train the RNN, where each previous state is supplied as the initial state to the next iteration. The final output is used to classify the batch of inputs. Cross Entropy is the loss function and Gradient Clipping is not used.

Unfortunately, the ~~code~~ ~~performs~~ ~~very~~ ~~poorly~~ resulting accuracy is very low and I'd appreciate help in understanding why that is. 

From the TensorFlow truncated backpropagation example, it appears batches are split into mini-batches that are then feed into the model. The code below creates mini-batches within the model. Is this difference significant? If so, why/how? Is the mini-batch processing implementation correct? Does *last_output* need to be passed through an activation function before applying the affine transformation?

Following are pieces of code from the LSTM which encapsulates properties/functions such as inputs, labels, weights, biases, predictions, etc. 

    self._x = tf.placeholder(tf.float32, [self._batch_size, self._features])
    self._y = tf.placeholder(tf.int32, [self._batch_size, self._num_labels]) 
    ...
    output = None
    state = self._init_state

    data = tf.reshape(self._x, [self._batch_size, self._features, 1])

    # Re-batch data.
    for mini_batch in np.arange(self._mini_batches):
        if mini_batch &gt; 0:
            tf.get_variable_scope().reuse_variables()

        inputs = data[:, (mini_batch * self._mini_steps):((mini_batch + 1) * self._mini_steps), :]
        output, state = tf.nn.dynamic_rnn(self._lstm, inputs, initial_state=state, dtype=tf.float32)

    output = tf.transpose(output, [1, 0, 2])  # [mini_batch_size x batch_size x rnn_size]
    last_output = tf.gather(output, int(output.get_shape()[0] - 1))  # [batch_size x rnn_size]

    logits = tf.matmul(last_output, self._W) + self._b
    return tf.nn.softmax(logits)
    ...
    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(self.y_hat, self.y))  # Loss function.

The training setup code is available [here](http://pastebin.com/YnfaHzA9), and full model code is available [here](http://pastebin.com/3peREwt9). Essentially, I'm attempting to implement something similar to this [TensorFlow tutorial](https://www.tensorflow.org/tutorials/recurrent#truncated_backpropagation) for which the full code is available [here](https://github.com/tensorflow/models/blob/master/tutorials/rnn/ptb/ptb_word_lm.py).",5,2
39,2017-2-25,2017,2,25,1,5vyb6a,Installing TensorFlow with Anaconda,https://www.reddit.com/r/tensorflow/comments/5vyb6a/installing_tensorflow_with_anaconda/,depireux,1487952696,"I followed the instructions on [TensorFlow.org](https://www.tensorflow.org/install/install_windows), but ran into a problem. 

I installed Anaconda, which installed Python 3.6, and did the **conda create** and the **activate tensorflow**. 

Then I did the **pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.0.0-cp35-cp35m-win_x86_64.whl** and I get that it's not a supported wheel on this platform. 

Is it because Anaconda installed Python 3.6 instead of 3.5? Is there a simple work-around?

TIA!",3,3
40,2017-2-25,2017,2,25,7,5w0gqx,How does one train multiple models in a single script in TensorFlow when there are GPUs present?,https://www.reddit.com/r/tensorflow/comments/5w0gqx/how_does_one_train_multiple_models_in_a_single/,real_charlie_parker,1487974067,,0,6
41,2017-2-25,2017,2,25,7,5w0of8,How can I apply a function only to the maximal element of each row of a tensor?,https://www.reddit.com/r/tensorflow/comments/5w0of8/how_can_i_apply_a_function_only_to_the_maximal/,Imnimo,1487976312,"I have a 2D tensor, and I want to apply a function only to the maximum elements of each row. For example, if my tensor is:

[[0.5,0.7],[0.4,0.3]], and my function is to multiply by 2, then I want my result to be [[0.5,1.4],[0.8,0.3]].

My current approach is to use tf.select, like this:

tf.select( tf.equal(my_tensor,tf.reduce_max(my_tensor,axis=1) ), my_function(my_tensor), my_tensor)

The idea is to create a tensor which is the max of each row using tf.reduce_max, and then use tf.equal to create a boolean tensor which says whether each element of input is equal to its row max. This then gets passed to tf.select as a mask to determine whether the function should be applied. However, this doesn't seem to work - the max tensor is not of the same dimension as the input tensor, and I think there's some issue with broadcasting. Also, this method may run into issues if there are two equal maximal elements. I'd rather have a method that automatically breaks ties, perhaps using tf.arg_max.",0,3
42,2017-2-27,2017,2,27,23,5wgvf7,Using TensorFlow and the Raspberry Pi in cities and on farms | Opensource.com,https://www.reddit.com/r/tensorflow/comments/5wgvf7/using_tensorflow_and_the_raspberry_pi_in_cities/,DonWatkins1,1488204188,,0,1
43,2017-2-28,2017,2,28,8,5wk55a,Estimating GPU memory usage for training?,https://www.reddit.com/r/tensorflow/comments/5wk55a/estimating_gpu_memory_usage_for_training/,iamiamwhoami,1488236546,Is there a good way to estimate how much memory will be required for training a neural network in TF?,1,6
44,2017-2-28,2017,2,28,19,5wn7wu,"This Tensorflow tutorial series has been very very popular on LinkedIn. Posting it here. Hope this helps someone. I had some struggle when I started with Tensorflow. So, I am creating quick tutorials for smart programmers. Here is one to build image classifier using convolutional neural network.",https://www.reddit.com/r/tensorflow/comments/5wn7wu/this_tensorflow_tutorial_series_has_been_very/,sankit123,1488276762,,0,20
0,2017-3-2,2017,3,2,5,5wykyr,Tensorflow GPU cuda acceleration?,https://www.reddit.com/r/tensorflow/comments/5wykyr/tensorflow_gpu_cuda_acceleration/,Randomhkkid,1488400890,What sort of operations does cuda speed up when tensorflow with the gpu binaries is installed? I'm using logistical regression and a gradient descent optimiser for classification. ,3,2
1,2017-3-2,2017,3,2,17,5x25a1,MNIST tutorial on tensorflow,https://www.reddit.com/r/tensorflow/comments/5x25a1/mnist_tutorial_on_tensorflow/,SanatDutta,1488443883,"Hi,

I'm new to Tensorflow and python. I was doing the MNIST tutorial and it asked to download &amp; import the dataset using

&gt;from tensorflow.examples.tutorials.mnist import input_data

&gt;mnist = input_data.read_data_sets(""MNIST_data/"", one_hot=True)

But since the website is down, it wasn't able to download via url. I was able to download the files from waybackmachine but not sure how to import these files as input data...

The files I downloaded are:

train-images-idx3-ubyte.gz:  training set images (9912422 bytes) 

train-labels-idx1-ubyte.gz:  training set labels (28881 bytes) 

t10k-images-idx3-ubyte.gz:   test set images (1648877 bytes) 

t10k-labels-idx1-ubyte.gz:   test set labels (4542 bytes)",2,1
2,2017-3-3,2017,3,3,3,5x52lv,No charge course teaches Deep Learning with TensorFlow 1.0 hands-on,https://www.reddit.com/r/tensorflow/comments/5x52lv/no_charge_course_teaches_deep_learning_with/,reditype,1488480398,,0,23
3,2017-3-3,2017,3,3,13,5x89ut,Can multiple models be trained on a same gpu chip,https://www.reddit.com/r/tensorflow/comments/5x89ut/can_multiple_models_be_trained_on_a_same_gpu_chip/,lhyan792,1488514338,"Can I train multiple models simultaneously on a gpu with tensorflow, assuming enough memory? Whether there will be unexpected behaviors due to cross influences among models?",2,2
4,2017-3-3,2017,3,3,21,5xa1fa,"Speeding up Tensorflow in Python, low GPU utilisation?",https://www.reddit.com/r/tensorflow/comments/5xa1fa/speeding_up_tensorflow_in_python_low_gpu/,Randomhkkid,1488543727,"I've written a program to classify two authors represented through TF-IDF vectors through logistic regression using Tensorflow in Python. The program works and operates normally however when running the program using CUDA my GPU utilisation remains low, &lt;10%. I'd love to have some feedback on my code 'Tensor.py' to alleviate any bottlenecks if possible. [Linked here](https://github.com/andrewginns/idp-twitter-tensorflow) 

Edit: I'm a beginner at machine learning and tensorflow in general

Edit 2: I've implemented multithreading and queues from [here](https://blog.metaflow.fr/tensorflow-how-to-optimise-your-input-pipeline-with-queues-and-multi-threading-e7c3874157e0#.e5r6pup9q) but my code shows no improvement in execution time.
",7,8
5,2017-3-4,2017,3,4,2,5xbosv,I have two networks trained on two separate GPUs. I want to clear the memory of one GPU but not the other. Then train a new network on that GPU.,https://www.reddit.com/r/tensorflow/comments/5xbosv/i_have_two_networks_trained_on_two_separate_gpus/,iamiamwhoami,1488562319,Is there a way to do that?,1,2
6,2017-3-4,2017,3,4,2,5xbsel,Tensorflow 1.0.0 on AWS Lambda.,https://www.reddit.com/r/tensorflow/comments/5xbsel/tensorflow_100_on_aws_lambda/,ryfeus,1488563275,"Hi, Tensorflow community,

Ive ported Tensorflow 1.0.0 on AWS Lambda (python). Here is the link
[https://github.com/ryfeus/lambda-packs/tree/master/Tensorflow](https://github.com/ryfeus/lambda-packs/tree/master/Tensorflow)

Ive used image recognition as hello world code (https://www.tensorflow.org/tutorials/image_recognition). It downloads model from S3 and uses it to describe objects on the image from the provided link.

In terms of cost it uses 0.5 GB of RAM for 6 seconds which translates into 0.00005$ per run (aka recognizing one image) so for 1$ you can recognize 20000 images.

Hopefully this will be helpful for you and also I will be glad for any feedback.",2,7
7,2017-3-5,2017,3,5,5,5xj2td,MNIST w/ ADAM worked in Windows but won't in Linux.,https://www.reddit.com/r/tensorflow/comments/5xj2td/mnist_w_adam_worked_in_windows_but_wont_in_linux/,EnochLindeman,1488660708,"I just started using the tensorflow library and went through some YouTube tutorials to create an MNIST program (I also made one with the TF docs). The program works on my Windows 10 Laptop but has tons of [errors](https://ibb.co/dMLqyv) with my Linux mint machine. They are both running on Python 3.5.2 in IDLE and as far as I can tell, both with the same (newest) TF version.

Here's the Code:

            #Imports
    import tensorflow as tf
    import time, math, datetime
    from tensorflow.examples.tutorials.mnist import input_data
        #Data Definitions
    mnist = input_data.read_data_sets(""MNIST_data"", one_hot = True)

            #Graph
        #Definitions
    n_nodes_hl1 = 100
    n_nodes_hl2 = 100
    n_nodes_hl3 = 100
    data_size = 784
    n_classes = 10
    hm_cycles = 512
    batch_size = round((data_size * n_classes)/hm_cycles)
    learning_rate = 0.001
    final_output = """"
    cycle_time_l = []
    #constants

    #Variables
    hl1_w = tf.Variable(tf.random_normal([data_size, n_nodes_hl1]))
    hl1_b = tf.Variable(tf.random_normal([n_nodes_hl1]))
    hl2_w = tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2]))
    hl2_b = tf.Variable(tf.random_normal([n_nodes_hl2]))
    hl3_w = tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3]))
    hl3_b = tf.Variable(tf.random_normal([n_nodes_hl3]))
    ol_w = tf.Variable(tf.random_normal([n_nodes_hl3, n_classes]))
    ol_b = tf.Variable(tf.random_normal([n_classes]))
    #placeholders
    x = tf.placeholder('float', [None, data_size])
    y = tf.placeholder('float', [None, n_classes])
        #Computing
    def neural_network_model(data):
        hidden_layer_1 = {hl1_w,hl1_b}
        hidden_layer_2 = {hl2_w,hl2_b}
        hidden_layer_3 = {hl3_w,hl3_b}
        output_layer = {ol_w,ol_b}
        l1 = tf.add(tf.matmul(data, hl1_w), hl1_b)
        l1 = tf.nn.relu(l1)
        l2 = tf.add(tf.matmul(l1, hl2_w), hl2_b)
        l2 = tf.nn.relu(l2)
        l3 = tf.add(tf.matmul(l2, hl3_w), hl3_b)
        l3 = tf.nn.relu(l3)
        output = tf.add(tf.matmul(l3, ol_w), ol_b)
        return output
    def train_neural_network(x):
        prediction = neural_network_model(x)
        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(prediction,y))
        optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)


            #Sessions
        #Loop
        with tf.Session() as sess1:
            sess1.run(tf.global_variables_initializer())
            print('Learning from Batches of ' + str(batch_size) + ' data points for ' + str(hm_cycles) + ' Cycles.')
            for cycle in range(hm_cycles):
                cycle_time_s = time.time()
                cycle_loss = 0
                for _ in range(int(mnist.train.num_examples/batch_size)):
                    ex, ey = mnist.train.next_batch(batch_size)
                    _, c = sess1.run([optimizer, cost], feed_dict = {x: ex, y: ey})
                    cycle_loss += c
                correct = tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))
                accuracy = tf.reduce_mean(tf.cast(correct,'float'))
                percentage = 100 * accuracy.eval({x: mnist.test.images, y:mnist.test.labels})
                cycle_time_e = time.time()
                cycle_time = (cycle_time_e - cycle_time_s)
                cycle_time_l.insert(cycle, cycle_time)
                cycle_time_a = (sum(cycle_time_l)/len(cycle_time_l))
                seconds_remaining = math.floor((hm_cycles - cycle - 1)*(cycle_time_a))
                print('Cycle ' + str(cycle + 1) + ' of ' + str(hm_cycles) + ' completed in ' + str(round((cycle_time),3)) + ' seconds. Loss: ' + str(round((cycle_loss),3)) + ' | Accuracy: ' + str(round((percentage),3)) + '% | ' + str(datetime.timedelta(seconds= (seconds_remaining) )) + ' remaining')
                if cycle + 1 == hm_cycles or cycle_loss == 0 or accuracy == 1:
                    run_time = cycle_time_a * hm_cycles
                    str(datetime.timedelta(seconds=run_time))
                    rt_m, rt_s = divmod(run_time, 60)
                    rt_h, rt_m = divmod(rt_m, 60)
                    efficiency = (percentage ** 3)/(run_time)
                    print('Finished. Cycles: ' + str(hm_cycles) + ' | Batch Size: ' + str(batch_size) + ' | Time: ' + str(datetime.timedelta(seconds= (run_time) )) + ' | Final Loss: ' + str(round((cycle_loss),3)) + ' | Final Accuracy: ' + str(round((percentage),3)) + '% | Efficiency: ' + str(round((efficiency),4)))
        #Sequential
    #Create

    #Run/Close
    train_neural_network(x)


            #Output
    print(final_output)


TL;DR: What's wrong with my code? Are there compatibility issues between TF Windows and Linux?
",3,1
8,2017-3-5,2017,3,5,18,5xm1be,7 Simple Steps to Install TensorFlow on Windows (+ Screenshots),https://www.reddit.com/r/tensorflow/comments/5xm1be/7_simple_steps_to_install_tensorflow_on_windows/,[deleted],1488704969,[deleted],0,1
9,2017-3-6,2017,3,6,19,5xsm86,How to use Tensorflow from Crystal!,https://www.reddit.com/r/tensorflow/comments/5xsm86/how_to_use_tensorflow_from_crystal/,fazibear,1488797484,,2,5
10,2017-3-7,2017,3,7,11,5xxooz,Tutorial: Build Your First TensorFlow Android App,https://www.reddit.com/r/tensorflow/comments/5xxooz/tutorial_build_your_first_tensorflow_android_app/,oac,1488852743,,0,12
11,2017-3-8,2017,3,8,4,5y2s9p,Raise default pool_size for GPU PoolAllocator?,https://www.reddit.com/r/tensorflow/comments/5y2s9p/raise_default_pool_size_for_gpu_poolallocator/,oopsleon,1488914638,"Nearly every training session of mine starts out with a bunch of messages like the following:


2017-03-07 11:12:16.005711: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 542 to 596
2017-03-07 11:12:21.452368: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 32550 get requests, put_count=32312 evicted_count=2000 eviction_rate=0.0618965 and unsatisfied allocation rate=0.0709677
2017-03-07 11:12:21.452392: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 792 to 871
2017-03-07 11:12:28.344585: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 37921 get requests, put_count=38207 evicted_count=2000 eviction_rate=0.0523464 and unsatisfied allocation rate=0.0482319


So I was wondering, **is it possible and/or a good idea to just raise the default pool_size?** I should mention I am by no means any GPU expert. Someone gave a [nice related answer on StackOverflow](http://stackoverflow.com/questions/35151207/how-to-interpret-poolallocator-messages-in-tensorflow) regarding in general what is happening. I wanted to follow-up with my question but I don't have enough ""reputation points"".


It's a minor annoyance, to be sure, but if there is a quick fix it would be nice, since sometimes it can take a few minutes just for tensorflow to find a good pool_size. In case it might be useful to know, I'm training with a GTX 1080. Thanks for any help/information.

",1,4
12,2017-3-8,2017,3,8,16,5y6olf,XLA: Linear Algebra library for TensorFlow,https://www.reddit.com/r/tensorflow/comments/5y6olf/xla_linear_algebra_library_for_tensorflow/,jakekovoor,1488959307,,0,10
13,2017-3-8,2017,3,8,16,5y6oxq,Doom Bots in TensorFlow,https://www.reddit.com/r/tensorflow/comments/5y6oxq/doom_bots_in_tensorflow/,marklit,1488959479,,0,5
14,2017-3-9,2017,3,9,3,5y9khd,Beginner here,https://www.reddit.com/r/tensorflow/comments/5y9khd/beginner_here/,thecocolovesme,1488997088,"Hi everyone

I am a student in Music, however, I have tasted the professional world and it made wanna quit. 

So I decided to focus on research in music, precisely AI use in music, generative music to be more precise.

I had scientific background in highschool, right now I'm picking up Python. A friend of mine told me about Tensorflow.

Can you guys explain, in simple and common word of English, what Tensorflow actually does? Anything would help me greatly.

Thanks!",8,1
15,2017-3-9,2017,3,9,13,5ycytp,Setting up TensorFlow on AWS or Google Cloud Services,https://www.reddit.com/r/tensorflow/comments/5ycytp/setting_up_tensorflow_on_aws_or_google_cloud/,pretending2code,1489032849,"Current Skill level: I've been able to install Tensorflow on my local environment and start manipulating some simple graphs in Tensorboard.

I've been tasked with spearheading a prototype for a new department at my company. The individual who tasked me understood I knew nothing about Machine Learning and very little more than some basic RDBMS knowledge.

Earlier this week the task was to investigate the Machine Learning frameworks that exist and to construct a list of pros and cons of the current options. I spent a lot of time and uncovered a few conclusions. He was impressed. Our selection is going to be the TensorFlow framework.

Now he says he wants me to attempt to set up a TensorFlow enviornment on either AWS or Google Cloud Services if it had solid options for it and come up with an early prototype by the end of the week. (The prototype looks like it is going to require some Text Processing for Normalization. Essentially it needs to group data that looks like ""IBMcorp, I.B.M., IBM inc"" should be grouped under IBM. Any advice at what I should be looking at will also be appreciated.)

My question is should I be using an AWS server or should I attempt to use Google Cloud Services, and what advice do you have in setting that up?

TL;DR I know nothing about Machine Learning or TensorFlow, but I've been given a shot and I need some suggestions for environments on a corporate level (i.e. Google Cloud Services or AWS).",3,5
16,2017-3-10,2017,3,10,15,5ykjgj,Data input,https://www.reddit.com/r/tensorflow/comments/5ykjgj/data_input/,mlpyotr,1489126446,"I'm trying to get into TS but I have a data question.

Looking at the TS pages, it seems that the only input type the functions understand are np arrays (of: int, floats, etc). Is it possible to have some of the arrays a mix of types?
For example, R's random Forest can have features that are non-numeric (factors, etc) and the target value need not be a number.
Hope I'm being clear.
Thanks in advance",0,1
17,2017-3-11,2017,3,11,2,5ynbi2,Implementing trust region optimization ops,https://www.reddit.com/r/tensorflow/comments/5ynbi2/implementing_trust_region_optimization_ops/,ski__,1489166327,"Hi everyone. I got into NNs very recently, and as for many people, Ng's introductory course taught in Octave paved the way. The course encourages the use of ""fminunc"", which for those that are unfamiliar, is a wrapper for several unconstrained function optimization algorithms, most notably, the trust region algorithm using preconditioned conjugate vectors.

More recently, a DL researcher at Google offered to collaborate on a research idea of theirs. Having a bit of Octave experience, I prototyped a network and minimized the cost with the aforementioned algorithm. We then tried to port the same network to TensorFlow and use Gradient Descent and the network exploded in our faces with the analogue of ""segmentation fault"" in C world - NaN...

The Googler even wrote his own optimizer for the task, which I am currently fiddling with, along with some new, trial activations of my own, but I think the larger issue is that the current tensorflow library heavily relies on following gradients, when there are much more powerful optimization techniques out there.

Another set of ops worth looking into would be quasi-Newton ops (BFGS algorithm).

A short time ago, I began doing the research for MATLAB/Octave's trust region optimization method used by fminunc, and I am setting out to try and build a native tensorflow op for it. If anyone has the gory C++ knowhow of tensorflow and would like to contribute, don't hesitate to get in touch.

Cheers.",0,2
18,2017-3-11,2017,3,11,12,5yqp5t,Starting tensorflow?,https://www.reddit.com/r/tensorflow/comments/5yqp5t/starting_tensorflow/,tomgie,1489203275,"Im currently 16 and im only in geometry i dont even understand the math behind this, is there any simpler way to use tensorflow and still understand on how to use its functions and stuff?",4,4
19,2017-3-13,2017,3,13,8,5z1o7q,Tensorflow Freezing when Accessing CSV Data,https://www.reddit.com/r/tensorflow/comments/5z1o7q/tensorflow_freezing_when_accessing_csv_data/,Nightsd01,1489360793,"I am new to TensorFlow. Whenever I try to read any CSV file and call session.run() to execute and read the file, TensorFlow just freezes and doesn't do anything.

It basically just stops the moment it hits the session.read() line, but doesn't crash or anything. Been fighting with this for days, it happens with every CSV I've tried. Here is my code:


    def inputs(batch_size):
       filename_queue = tf.train.string_input_producer([""titanicData.csv""]);
       reader = tf.TextLineReader(skip_header_lines=1);
       key, value = reader.read(filename_queue);
       decoded = tf.decode_csv(value, record_defaults = [[0.0], [0.0], [0], [""""], [""""], [0.0], [0.0], [0.0], [""""], [0.0], [""""], [""""]]);

       passenger_id, survived, pclass, name, sex, age, sibsp, parch, ticket, fare, cabin, embarked = \
       tf.train.shuffle_batch(decoded, batch_size=batch_size, capacity=batch_size * 50, min_after_dequeue=batch_size);

       is_first_class = tf.to_float(tf.equal(pclass, [1]));
       is_second_class = tf.to_float(tf.equal(pclass, [2]));
       is_third_class = tf.to_float(tf.equal(pclass, [3]));
       gender = tf.to_float(tf.equal(sex, [""female""]));

       return tf.transpose(tf.stack([is_first_class, is_second_class, is_third_class, gender, age])), tf.reshape(survived, [batch_size]);

    with tf.Session() as sess:
       sess.run(tf.global_variables_initializer());
       features, survived = inputs(500);

       print(sess.run(features[1, :])); #freezes here

       sess.close();

It freezes on the line print(sess.run(features[1, :])). Even if I run sess.run(features) outside of a print statement, it still freezes on the run() command. I am running Python-3 using the latest official TensorFlow release on pip3. Any help would be very appreciated!

It seems to happen on both Mac OS &amp; Ubuntu.

EDIT: When I use a session with log_device_placement=True, this is the output I get when it freezes:

    I tensorflow/core/common_runtime/simple_placer.cc:841] truncated_normal/shape: (Const)/job:localhost/replica:0/task:0/gpu:0
    ToFloat_1/x: (Const): /job:localhost/replica:0/task:0/gpu:0
    I tensorflow/core/common_runtime/simple_placer.cc:841] ToFloat_1/x: (Const)/job:localhost/replica:0/task:0/gpu:0
    ToFloat/x: (Const): /job:localhost/replica:0/task:0/gpu:0
    I tensorflow/core/common_runtime/simple_placer.cc:841] ToFloat/x: (Const)/job:localhost/replica:0/task:0/gpu:0",5,2
20,2017-3-14,2017,3,14,1,5z5zrt,Bare bottom simplest example of machine learning in TensorFlow,https://www.reddit.com/r/tensorflow/comments/5z5zrt/bare_bottom_simplest_example_of_machine_learning/,jostmey,1489422745,,0,6
21,2017-3-14,2017,3,14,15,5zaokf,Does anyone know of an implementation of splines?,https://www.reddit.com/r/tensorflow/comments/5zaokf/does_anyone_know_of_an_implementation_of_splines/,fuckinghelldad,1489474669,"I'm trying to do regression and want to use linear interpolating splines.

Failing an implementation, can anyone outline how I can code it up myself? The idiomatic way seems to be to use some basis functions and take a weighted sum of those. Though most the weights in this sum would be zero, so this seems inefficient to me, though I'm very new to TF.",3,1
22,2017-3-15,2017,3,15,18,5zias8,[Beginner] How to read output from net?,https://www.reddit.com/r/tensorflow/comments/5zias8/beginner_how_to_read_output_from_net/,cestlefeu,1489568701,"Hi, 
I made an AutoEncoder based on the tensorflow example (I leave you the code below). My problem is that when I try to read the output of my network after several trainings, the results are always the same, even if the inputs are differents. 

Can you help me ? thanks in advance

http://pastebin.com/GU8wn76z

EDIT : here are the results after 100 epochs, 150 batches of 20 pictures
http://imgur.com/a/NGUWO",2,1
23,2017-3-16,2017,3,16,3,5zl9rj,"TensorFlow and Deep Learning without a PhD (talk by Martin Gorner, from Google Cloud Next)",https://www.reddit.com/r/tensorflow/comments/5zl9rj/tensorflow_and_deep_learning_without_a_phd_talk/,happycube,1489603558,,0,15
24,2017-3-16,2017,3,16,18,5zpp2d,[P] DyTB: don't waste your time writing boilerplate code. Let DyTB do it for you.,https://www.reddit.com/r/tensorflow/comments/5zpp2d/p_dytb_dont_waste_your_time_writing_boilerplate/,pgaleone,1489658345,,0,5
25,2017-3-17,2017,3,17,3,5zsc5g,What does 'Moving Average' do when training a neural network?,https://www.reddit.com/r/tensorflow/comments/5zsc5g/what_does_moving_average_do_when_training_a/,gchaoxue,1489688888,"I am reading the Tensorflow CIFAR-10 code and feeling confused about some 'Moving Average' related lines in the cifar10.train method. Is there any articles about what 'Moving Average' do during the neural network training? 
Thanks!",4,3
26,2017-3-17,2017,3,17,6,5ztdhe,[Beginner] How to use batch_sequences_with_states in Tensorflow?,https://www.reddit.com/r/tensorflow/comments/5ztdhe/beginner_how_to_use_batch_sequences_with_states/,jiminiminimini,1489698943,"[This example](https://www.tensorflow.org/versions/master/api_docs/python/contrib.training/splitting_sequence_inputs_into_minibatches_with_state_saving) in the documentation does not work and all the other bits and pieces required to use this method are scattered around tests, examples, comments inside the repository. I have preprocessed data of different lengths. They are currently stored as a list of numpy arrays of shape `(time, features)`. How should I format this list in order to be able to use `batch_sequences_with_states` method?",0,1
27,2017-3-18,2017,3,18,4,5zzkw8,Why does `tf.matmul` require that the matrices be of rank at least 2 in TensorFlow?,https://www.reddit.com/r/tensorflow/comments/5zzkw8/why_does_tfmatmul_require_that_the_matrices_be_of/,real_pinocchio,1489777528,,0,0
28,2017-3-18,2017,3,18,12,6027nb,Why is it so hard to make an optimizer for TensorFlow directly by subclassing Optimizer?,https://www.reddit.com/r/tensorflow/comments/6027nb/why_is_it_so_hard_to_make_an_optimizer_for/,real_pinocchio,1489808000,,2,2
29,2017-3-18,2017,3,18,13,602bnv,What does apply_gradients in TensorFlows optimizer do mathematically to the weights of the network?,https://www.reddit.com/r/tensorflow/comments/602bnv/what_does_apply_gradients_in_tensorflows/,real_pinocchio,1489809760,,0,1
30,2017-3-18,2017,3,18,13,602hvn,How to create an optimizer in Tensorflow,https://www.reddit.com/r/tensorflow/comments/602hvn/how_to_create_an_optimizer_in_tensorflow/,real_pinocchio,1489812517,,2,4
31,2017-3-18,2017,3,18,14,602kph,Can one only implement gradient descent like optimizers with the code example from processing gradients in TensorFlow?,https://www.reddit.com/r/tensorflow/comments/602kph/can_one_only_implement_gradient_descent_like/,real_pinocchio,1489813854,,0,1
32,2017-3-19,2017,3,19,20,609p69,How can I augment MNIST data and save it as seperate dataset?,https://www.reddit.com/r/tensorflow/comments/609p69/how_can_i_augment_mnist_data_and_save_it_as/,Metalwrath22,1489924186,I've been really struggling since 2-3 days and unfortunately I haven't made any real progress. I want to augment MNIST dataset (for example I want to make them italic) and feed this augmented set to my CNN using tensorflow. I managed to extract MNIST as png images and CSV files but I really don't know what I am doing. Maybe there is a tutorial where I can learn how to do this? I spent 8 hours yesterday trying to do this so any help would be appreciated. ,6,4
33,2017-3-20,2017,3,20,11,60e54l,Tensor Flow application in 3 axis cnc,https://www.reddit.com/r/tensorflow/comments/60e54l/tensor_flow_application_in_3_axis_cnc/,rlarge1,1489978485,"Just wondering if you guys think its possible to use tensor flow to create gcode for cnc cutting on a 3 axis cnc machine.  Is it feasible or just not practical.  G-code software is expensive and not very intuitive.  I have watched a talk about it from a large cnc software company about it but they didn't say much.  Just a thought any ideas would be helpful.  Ive attached a small layout of parameters to describe minimal usage.

**Outline**

define 2d object

define 2d stock material

define origin

define cutters/options 

define cutter/option shape

define cutter/option speed

establish milling constraints max cut depth, proximity to 2d object (some bits make smoother cuts and some bits leave rough material)



**Define pass and fail**

Fail:
hit/proximity to object 

hit material not removed yet over max cut depth of current tool

**success:**

successfully complete object

**best outcome:**
 shortest outcome in time",0,3
34,2017-3-21,2017,3,21,2,60hsmm,What does Snapchat need Tensorflow for?,https://www.reddit.com/r/tensorflow/comments/60hsmm/what_does_snapchat_need_tensorflow_for/,PropertyOfMatter,1490030071,"On the Tensorflow homepage, it lists a bunch of companies that are using Tensorflow.  Snapchat is one of them.  Is there any public reason for them using it, or is has it not been disclosed yet?",5,5
35,2017-3-21,2017,3,21,3,60i52s,Tensorflow scan temporal taps,https://www.reddit.com/r/tensorflow/comments/60i52s/tensorflow_scan_temporal_taps/,bfsd66,1490033452,,1,1
36,2017-3-21,2017,3,21,4,60iif1,How to get current TensorFlow name scope,https://www.reddit.com/r/tensorflow/comments/60iif1/how_to_get_current_tensorflow_name_scope/,real_pinocchio,1490036936,,1,0
37,2017-3-21,2017,3,21,4,60ilt2,What's the difference of name scope and a variable scope in tensorflow?,https://www.reddit.com/r/tensorflow/comments/60ilt2/whats_the_difference_of_name_scope_and_a_variable/,real_pinocchio,1490037822,,1,0
38,2017-3-21,2017,3,21,4,60ionh,What is the difference between name scoping and variable scoping in TensorFlow?,https://www.reddit.com/r/tensorflow/comments/60ionh/what_is_the_difference_between_name_scoping_and/,real_pinocchio,1490038592,,0,1
39,2017-3-21,2017,3,21,21,60ndg3,Is this outputshape correct?,https://www.reddit.com/r/tensorflow/comments/60ndg3/is_this_outputshape_correct/,[deleted],1490100485,[deleted],0,1
40,2017-3-22,2017,3,22,21,60u7p4,save and restore Tensorflow models quick tutorial,https://www.reddit.com/r/tensorflow/comments/60u7p4/save_and_restore_tensorflow_models_quick_tutorial/,sankit123,1490184714,,0,1
41,2017-3-23,2017,3,23,11,60z80g,Is there any tutorial available for loading a checkpointed model and adding some additional layers?,https://www.reddit.com/r/tensorflow/comments/60z80g/is_there_any_tutorial_available_for_loading_a/,axadify,1490235717,,0,6
42,2017-3-24,2017,3,24,1,612ywd,TensorFlow: Mutating variables and control flow,https://www.reddit.com/r/tensorflow/comments/612ywd/tensorflow_mutating_variables_and_control_flow/,morgangiraud,1490287221,,3,2
43,2017-3-24,2017,3,24,5,614hbf,eclipse+pydev can't find cuda library,https://www.reddit.com/r/tensorflow/comments/614hbf/eclipsepydev_cant_find_cuda_library/,yuanzheng625,1490301471,"I am trying to debug some computer vision code (say dcgan) built on top of tensorflow. I installed the tf_0.10 in virtualenv (say, py1) and I use eclipse+pydev as the IDE. The problem is that the debugger can't find the cuda library so I get the error like the following, 

ImportError: libcudart.so.8.0: cannot open shared object file: No such file or directory

On the other hand, the code works correctly on ubuntu command line and py1 in the virtualenv has no problem finding the cuda library. 

In my eclipse+pydev setup, I set a py intepreter as py1, 

by setting eclipse menu-&gt;window-&gt;preference-&gt;intepreters-&gt;python intepreter as

/home/zyuan/tensorflowr010/bin/python2.7 (where /home/zyuan/tensorflowr010 is the root of virtualenv) 

Also the system PYTHONPATH for the above intepreter is, 

/home/zyuan/tensorflowr010/lib/python2.7
/home/zyuan/tensorflowr010/lib/python2.7/lib-dynload
/home/zyuan/tensorflowr010/local/lib/python2.7/site-packages
/home/zyuan/tensorflowr010/lib/python2.7/site-packages
/home/zyuan/tensorflowr010/lib

Then I chose py1 and the intepreter for my computer vision code dcgan,

by setting dcgan -&gt; properities -&gt; pyDev-interpreter/grammer as py1 and add &gt;external Librarie /usr/local/cuda/lib64 on pyDev-PYTHONPATH

Do I miss anything else?",1,0
44,2017-3-24,2017,3,24,8,615jpo,Is it easy to train a Deep Neural Network model from scratch using Keras?,https://www.reddit.com/r/tensorflow/comments/615jpo/is_it_easy_to_train_a_deep_neural_network_model/,brandojazz,1490312328,,0,0
45,2017-3-24,2017,3,24,21,618m5g,Tensor Flow: Using trained model on unlabeled data,https://www.reddit.com/r/tensorflow/comments/618m5g/tensor_flow_using_trained_model_on_unlabeled_data/,wc01127,1490358338,"I've trained a tensorflow model on my training data. I have another set of data, the test data, which does not contain the y column and thus I want to use my model to predict what the y column will be. Surprisingly I've had trouble finding out how to do this, surely there is a way?",4,2
46,2017-3-30,2017,3,30,8,62afal,No one deserves a seizure from social media. Detect seizure inducing images using Tensor Flow,https://www.reddit.com/r/tensorflow/comments/62afal/no_one_deserves_a_seizure_from_social_media/,a36,1490831146,,1,6
47,2017-3-30,2017,3,30,22,62e2sq,MOOC for TensorFlow,https://www.reddit.com/r/tensorflow/comments/62e2sq/mooc_for_tensorflow/,skeptacus,1490882073,Is there any recent video courses for TensorFlow?,2,4
48,2017-3-31,2017,3,31,23,62lnyk,Anomaly Detection in Data Streams?,https://www.reddit.com/r/tensorflow/comments/62lnyk/anomaly_detection_in_data_streams/,Mirakoolix,1490972251,"Hi,
I try to implement some kind of anomaly detection in time series data streams (e.g. server monitoring) with neural networks. I am fairly new to the topic and have just gathered some basic information.
I think Recurrent Neural Networks match best, as they are good in extracting patterns.
Furthermore, it should be unsupervised, so I have to use an autoencoder like a Restricted Boltzmann Machine.

This is my idea so far, what I can't figure out is the concept of how to let the NN learn continuously?
With each new incoming value from the data stream, the network should classify, if the value is an anomaly or not, but also adopt, if a new pattern occurs more and more often, this pattern should not handled as an anomaly anymore.

Is this possible? Are my assumptions correct so far?",7,4
0,2017-4-3,2017,4,3,18,635r0d,Amazon Reviews - Star Prediction,https://www.reddit.com/r/tensorflow/comments/635r0d/amazon_reviews_star_prediction/,christophfritz,1491212779,"Hey everyone. I am fairly new to TensorFlow and therefore need a little bit of help. 
So I have this [csv file](https://ufile.io/e1041) of Amazon reviews with 9 features (overall is the star rating and will be predicted in the end). I tried to work with [this explanation](https://www.tensorflow.org/programmers_guide/reading_data) from the official website to read in the csv and I get the idea that every column gets converted to a tensor but how am I supposed to work with them later on? I can't stack them because they obviously have different types (int and strings) so how do I define my features and how do I work with them?
I kind of want to use the same idea that's used in [this](https://www.tensorflow.org/tutorials/wide) tutorial. 

Here's my code (mainly the one from the example):

    import tensorflow as tf

    filename_queue = tf.train.string_input_producer([""Digital_Music_5.csv""])

    reader = tf.TextLineReader(skip_header_lines=1)
    key, value = reader.read(filename_queue)

    record_defaults = [[""""], [""""], [""""], [0], [0], [""""], [1], [""""], [0]]
    reviewerID, asin, reviewerName, helpful_0, helpful_1, reviewText, overall, summary, unixReviewTime = tf.decode_csv(value, 
    record_defaults=record_defaults)
    features = tf.stack([reviewerID, asin, reviewerName, helpful_0, helpful_1, reviewText, summary, unixReviewTime]) # does not work because of the different types of tensors

    print(reviewerID)
    print(overall)

    with tf.Session() as sess:
        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(coord=coord)

        for i in range(1200):
            example, label = sess.run([features, overall])

        coord.request_stop()
        coord.join(threads)
",0,3
1,2017-4-6,2017,4,6,13,63qtkn,Can someone help me optimize this code?,https://www.reddit.com/r/tensorflow/comments/63qtkn/can_someone_help_me_optimize_this_code/,askacadthrowaway,1491453115,"[I've written something on SO] (http://stackoverflow.com/questions/43220195/tensorflow-optimizing-this-code-to-avoid-constructing-too-many-nodes). But essentially, I'm trying to run a non-convex optimization problem on TF. If I remove the part that makes it non-convex (the tf.einsum line), then it works totally fine. But if I keep that line, then it eventually eats too much of my system memory and crashes before finishing even a single iteration of the optimization procedure.

What I believe is happening is that when it's non-convex, the ""objective"" function that I defined ends up being called many, many times in the optimization process, and each time it adds new Nodes to the graph. Consequently, after enough calls, it ends up crashing. In contrast, when it's convex, it's only called a few times (maybe even once), and so there aren't enough Nodes added to the graph for it to be a problem. That's my guess anyways.

So at the bottom of my SO post is a link that I believe is related. But I'm not quite sure how to apply its principle to my code. Can anyone help me out?",1,3
2,2017-4-6,2017,4,6,22,63svtk,How the fuck do you install Tensorflow on Mac,https://www.reddit.com/r/tensorflow/comments/63svtk/how_the_fuck_do_you_install_tensorflow_on_mac/,matthewfelgate,1491485042,"Seriously, error after fucking error with this shit. Fucking impossible to decipher this shit. ",15,0
3,2017-4-7,2017,4,7,20,63zq3h,TensorFlow - A curated list of dedicated resources,https://www.reddit.com/r/tensorflow/comments/63zq3h/tensorflow_a_curated_list_of_dedicated_resources/,kapom,1491563161,,0,5
4,2017-4-8,2017,4,8,6,643e3g,DeepMind hopes its TensorFlow lib Sonnet is music to ears of AI devs  IT Breaking News,https://www.reddit.com/r/tensorflow/comments/643e3g/deepmind_hopes_its_tensorflow_lib_sonnet_is_music/,dannyeuu,1491601740,,0,2
5,2017-4-11,2017,4,11,4,64lqw1,Tensorflow question about invalid broadcasting comparisons.,https://www.reddit.com/r/tensorflow/comments/64lqw1/tensorflow_question_about_invalid_broadcasting/,azraelxii,1491852315,"I have a question about a broadcasting error. Stack overflow has failed me so far...

    import tensorflow as tf

    import pandas as pd

    url = 'http://vincentarelbundock.github.com/Rdatasets/csv/COUNT/medpar.csv'
    data=pd.read_csv(url)

    X=data[['type2', 'type3','hmo','white']]

    y=data[['los']]

    size=X.columns.shape

    B = tf.Variable(tf.random_uniform([1,size[0]]))

    a = tf.Variable(tf.zeros([1]))

    L=y * a
I am getting this error:

Invalid broadcasting comparison [&lt;tensorflow.python.ops.variables.Variable 
object at 0x000000000D7FD7B8&gt;] with block values
My end goal is to maximize this function:

    L=y * tf.log(a)+y*
    (tf.matmul(x,B))*tf.log(1+a*tf.exp(tf.matmul(x,B)))+tf.log(tf.gamma(y+1/a))-
    tf.log(tf.gamma(1/a))

but I am getting this error above in the first term. 

Can anyone help?",0,1
6,2017-4-11,2017,4,11,16,64ph2m,Ten useful tips for starting a new machine learning project at your company.,https://www.reddit.com/r/tensorflow/comments/64ph2m/ten_useful_tips_for_starting_a_new_machine/,alexvoica,1491896788,,0,5
7,2017-4-11,2017,4,11,22,64qsdm,War of the Machines: PVS-Studio vs. TensorFlow,https://www.reddit.com/r/tensorflow/comments/64qsdm/war_of_the_machines_pvsstudio_vs_tensorflow/,sofia_fateeva,1491917141,,0,2
8,2017-4-12,2017,4,12,3,64slsg,Big Picture Machine Learning: Classifying Text with Neural Networks and TensorFlow,https://www.reddit.com/r/tensorflow/comments/64slsg/big_picture_machine_learning_classifying_text/,dbrhm,1491934487,,1,9
9,2017-4-12,2017,4,12,22,64y9u0,What TF cost function can I use to optimize precision (not caring about recall) in a binary classifier NN?,https://www.reddit.com/r/tensorflow/comments/64y9u0/what_tf_cost_function_can_i_use_to_optimize/,rudyl313,1492005237,,1,2
10,2017-4-13,2017,4,13,5,650p49,"Question, I'm a techy 35 year old and I think AI is the future. How many years will it take me to learn what I need to know to use Tensorflow?",https://www.reddit.com/r/tensorflow/comments/650p49/question_im_a_techy_35_year_old_and_i_think_ai_is/,Idonteatbirdpoop,1492028180,"I'm quite technical, but little to no programming experience.  I'd pretty much be starting from scratch from a technical perspective.  How many years will I need to commit to begin using tensorflow and what sort of areas should I focus on learning?",9,13
11,2017-4-14,2017,4,14,0,65620b,Memory issues in Tensorflow?,https://www.reddit.com/r/tensorflow/comments/65620b/memory_issues_in_tensorflow/,poporing88,1492096219,"Has anyone encountered some Out of Memory issues in tensorflow badly? I am using a GTX1080 (8GB) and can only do 20 batch size + 20 epoch size for training, which is annoying since I think the model would improve by increasing the epoch size.

Other notes that may be relevant:
1. Using and inception resnet model
2. in Windows
3. Uses queues (FIFOqueue)",3,3
12,2017-4-15,2017,4,15,10,65gmpr,Trying to modify a tensorflow rnn for twitter,https://www.reddit.com/r/tensorflow/comments/65gmpr/trying_to_modify_a_tensorflow_rnn_for_twitter/,daddyhart,1492220729,"I wrote about my attempt at writing a Twitterbot with Tensorflow based on my archive of tweets.  You can read about how I did it here:
https://medium.com/@justin_hart/how-to-write-an-ai-twitterbot-30ca5fd65bc7

It works fairly well but I need to find the right parsing of the tweets for the training and modeling.  Right now... it's treating all of my tweets as one long novel.  

Here are the parameters I'm using for the training python code... could someone explain to me how I might modify it to look 140 char chunks? Or is there a better way to do this? 

parser.add_argument('--data_dir', type=str, default='data/tinyshakespeare',
                       help='data directory containing input.txt')
    parser.add_argument('--log_dir', type=str, default='logs',
                       help='directory containing tensorboard logs')
    parser.add_argument('--save_dir', type=str, default='save',
                       help='directory to store checkpointed models')
    parser.add_argument('--rnn_size', type=int, default=256,
                       help='size of RNN hidden state')
    parser.add_argument('--num_layers', type=int, default=2,
                       help='number of layers in the RNN')
    parser.add_argument('--model', type=str, default='lstm',
                       help='rnn, gru, or lstm')
    parser.add_argument('--batch_size', type=int, default=50,
                       help='minibatch size')
    parser.add_argument('--seq_length', type=int, default=25,
                       help='RNN sequence length')
    parser.add_argument('--num_epochs', type=int, default=50,
                       help='number of epochs')
    parser.add_argument('--save_every', type=int, default=1000,
                       help='save frequency')
    parser.add_argument('--grad_clip', type=float, default=5.,
                       help='clip gradients at this value')
    parser.add_argument('--learning_rate', type=float, default=0.002,
                       help='learning rate')
    parser.add_argument('--decay_rate', type=float, default=0.97,
                       help='decay rate for rmsprop')
    parser.add_argument('--gpu_mem', type=float, default=0.666,
                       help='% of gpu memory to be allocated to this process. Default is 66.6%')",0,2
13,2017-4-18,2017,4,18,5,65y81z,Convolutional neural network for learning arbitrary similarity function between two sets of text,https://www.reddit.com/r/tensorflow/comments/65y81z/convolutional_neural_network_for_learning/,priorlabs,1492461809,,0,6
14,2017-4-18,2017,4,18,20,662dcq,What is the best way of doing facial recognition using Tensorflow,https://www.reddit.com/r/tensorflow/comments/662dcq/what_is_the_best_way_of_doing_facial_recognition/,fuzzball_b,1492516763,"I am wanting to create an App that uses Tensorflow mobile, to recognize colleagues. I have followed this 5 minute tutorial

https://www.youtube.com/watch?v=QfNvhPx5Px8

and it seems to be working well for finding Darth Vader, but not so much for being able to find a specific colleague. 

The images i have used are cut out heads from different foto's, and the cut out images range from about 198x224 to about 960x1280.

The training result is about 40%, so that is not very good.

1. Is it a good idea to use the basic CNN object recognize script for face recognition? or are there better alternatives
2. Is it a good idea to cut out the heads, or should I use the original images. (I was thinking it might make sure that it pics the right person.)
3. Are images of different sizes a problem?
4. I have about 22 images per person. Would that be enough? 20 per person seems to be the minimum

p.s. Looking at the images myself I get a 100% score, so the images are clear enough

Thanks in advance.
",7,3
15,2017-4-20,2017,4,20,4,66cic1,Can't restore tensorflow session without saving all over again?,https://www.reddit.com/r/tensorflow/comments/66cic1/cant_restore_tensorflow_session_without_saving/,Kindlychung,1492630267,,0,1
16,2017-4-20,2017,4,20,20,66gyjm,live feed - from image to tf in a loop?,https://www.reddit.com/r/tensorflow/comments/66gyjm/live_feed_from_image_to_tf_in_a_loop/,d8sconz,1492686019,"I want to feed pixel values as a list to tf by scanning an image and sending the data. It's a trivial operation, but I just can't get my head around it. All tutorials and references on feeding data to tf seem to require a file to read from. I could write all the pixel value lists to a file and then read into tf from there, but I was wondering if it could just be done as a live feed - from image to tf in a loop?",2,2
17,2017-4-21,2017,4,21,5,66kkna,Melody extraction from mp3 files using tensorflow,https://www.reddit.com/r/tensorflow/comments/66kkna/melody_extraction_from_mp3_files_using_tensorflow/,servino,1492721380,"Firstly, I'd like to point out that I am a complete beginner with tensorflow or machine learning in general, having only watched some tutorials. Forgive me if this post is stupid.

Some time ago, I was struggling to find a decent melody extraction program for a personal project... the programs I tested were really innacurate and/or required a lot of setup for a single music or genre.

Since we, as humans, can detect the melody of a music pretty much automatically, I was wondering if we could use AI to perform this task.

I am completely oblivious as to what specific algorithms could make this possible, but for the training dataset we could use songs that have a corresponding arranged MIDI file - or maybe use only MIDI files and synthesize the .wav or .mp3 version to get the audio bitstream files.

Usually, in MIDI files each instrument is separated in different channels, so the melody is easily accessed to provide the correct melody output in the training dataset. And we can find lots of MIDI files for a decent dataset size.

So, I would like to hear any thoughts in this subject... is this a completely naive idea?",2,3
18,2017-4-21,2017,4,21,7,66lajg,Keeping Data in Memory,https://www.reddit.com/r/tensorflow/comments/66lajg/keeping_data_in_memory/,INDEX45,1492728405,"I am currently working with a HDF5 file that contains my dataset and like to keep the whole dataset (8GB) in memory for faster training. However, I am also developing multiple models, and loading the entire dataset every time I run my code is getting a little annoying as it takes a couple minutes.

My question is, what are some good ways of keeping this dataset loaded in memory in-between calls to python so that I can speed up my development cycle time? Any recommendations? ",1,1
19,2017-4-21,2017,4,21,20,66ooio,Mixing different graphics cards (CUDA)?,https://www.reddit.com/r/tensorflow/comments/66ooio/mixing_different_graphics_cards_cuda/,AoeAoe,1492775230,"Hi, I have an GTX 980 and I'm considering buying an another graphics card (1070/1080). Does it make sense to use two graphics cards of different performance levels concurrently? What are the caveats to consider? From docs that I've read so far [[1]](https://www.tensorflow.org/tutorials/using_gpu) it looks rather straight forward, but I'm wondering what kind of performance bottlenecks I can expect and how much manual tinkering is needed to get _some_ performance benefit out of my older card in such a setup.

Any feedback would be much appreciated.",2,1
20,2017-4-22,2017,4,22,8,66ss10,pieces of numerically identical code produce drastically different results,https://www.reddit.com/r/tensorflow/comments/66ss10/pieces_of_numerically_identical_code_produce/,irregexp,1492816912,,1,3
21,2017-4-23,2017,4,23,6,66ygs3,Anyone knows how to correctly calculate tf.nn.weighted_cross_entropy_with_logits pos_weight variable?,https://www.reddit.com/r/tensorflow/comments/66ygs3/anyone_knows_how_to_correctly_calculate/,nsx9891,1492896219,,0,1
22,2017-4-23,2017,4,23,16,6715fc,Is it right to say that tensorflow graph_defs contain both operations and values?,https://www.reddit.com/r/tensorflow/comments/6715fc/is_it_right_to_say_that_tensorflow_graph_defs/,TheMoskowitz,1492934062,"Just wanted to double check before I give out wrong information.

Checkpoints store variable values. Meta graphs store the operations.

Graph_defs store both, no?",2,3
23,2017-4-24,2017,4,24,19,6787gl,How to freeze only some weights?,https://www.reddit.com/r/tensorflow/comments/6787gl/how_to_freeze_only_some_weights/,eMPiko,1493029460,"Hey,

I am playing around with some word embeddings models and I would like to have kinda unusual setup. In my model I have weights matrix (which is basically my set of word embeddings as every row is de factio representation of one word). While training I would like to freeze some rows of this matrix while the rest of the rows is still being trained. 

The reason behind this is that I ""know"" embeddings for some words and I would like to keep these embeddings. I just want to train embeddings for the other words while the already known embeddings are preserved.

How should I approach this problem? I was thinking about two options:

1) Break the weight matrix into two matrices - one fixed and the other one trained. I am however not sure whether this is differentiable. The equation for layer would be:

h = x_f W_f + x_t  W_t

where x_f and x_t are one-hot representation for input words where F are words whose embeddings I want to have fixed while T are words whose embeddings I want to train. W_f is a matrix of fixed weights while W_t is a matrix of embeddings I am training. Can this setup be trained?

2) Tweak the loss function so it forces preservation of some weights.

What is the right approach?",3,2
24,2017-4-25,2017,4,25,2,67anf0,TensorFlow Contrib CRF,https://www.reddit.com/r/tensorflow/comments/67anf0/tensorflow_contrib_crf/,brandking,1493055929,"I am attempting to use the TensorFlow Contrib CRF implementation. Following the [contrib example](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/crf) I developed code available [here](https://pastebin.com/K9cqNJdg). 

Unfortunately, my code performs very poorly (as compared to CRFSuite). The code I wrote differs from the example in a couple of areas: 

1. The ""features"" are pre-trained word embeddings (of size 100) 
2.  All the sequences are padded to the largest sequence length.

I would appreciate help in understanding why my code performs so poorly, and what -- if any -- bugs exist in my code.",0,1
25,2017-4-26,2017,4,26,1,67hksv,Streaming computation in tensorflow,https://www.reddit.com/r/tensorflow/comments/67hksv/streaming_computation_in_tensorflow/,quadraticalgebra,1493137028,"Hi!

I'm evaluating using Tensorflow to run video processing pipelines. This would involve reading video files from disk frame by frame, running some ops on them, then writing back the video. I'm planning on using queues to allow running several threads in parallel, so my code would look something like this:

    frame = queue_in.dequeue()
    output = queue_out.enqueue(some_other_op(some_op(frame)))
    
    # I can do the following in several threads if I want to
    with tf.Session():
        output.run()

(assuming other threads are in charge of loading frames into queue_in and out of queue_out).

I have two questions about this:

* In general, is there a real advantage to using TF queues instead of using my own (Python) queues and placeholders? Is is much faster?
* Assume `some_op` runs on CPU, and `some_other_op` runs on GPU, but they both fill up the CPU/GPU on the machine. In that case I want no more than one computation running on the CPU and GPU at a time, but I'd like computations to run in a pipelined fashion (i.e., the CPU op and GPU op should both be working at the same time, on two consecutive inputs).

I may have missed easy answers to these questions in the documentation, any pointers are appreciated!

Thanks :)",0,2
26,2017-4-26,2017,4,26,11,67l8tt,Photo Editing with Generative Adversarial Networks (TF + DIGITS: Part 2),https://www.reddit.com/r/tensorflow/comments/67l8tt/photo_editing_with_generative_adversarial/,harrism,1493172881,,0,4
27,2017-4-27,2017,4,27,3,67q13a,Live Webinar: Leave your mark on the future: General AI Challenge + Creative AI,https://www.reddit.com/r/tensorflow/comments/67q13a/live_webinar_leave_your_mark_on_the_future/,gretayld,1493230993,,0,2
28,2017-4-28,2017,4,28,23,682sv0,"TensorFlow: A proposal of good practices for files, folders and models architecture",https://www.reddit.com/r/tensorflow/comments/682sv0/tensorflow_a_proposal_of_good_practices_for_files/,morgangiraud,1493388058,,1,5
29,2017-4-28,2017,4,28,23,682tk5,Anyone had problems running Python and TF via a bash script?,https://www.reddit.com/r/tensorflow/comments/682tk5/anyone_had_problems_running_python_and_tf_via_a/,jackbrucesimpson,1493388247,"I've been using Keras with the TensorFlow/CUDA backend without any problems on macOS Sierra in the Jupyter Notebooks and by running my Python code directly.

However, I've noticed that if I try to run my Python programs via a bash script, TensorFlow fails to load:

    File ""/usr/local/lib/python2.7/site-packages/keras/__init__.py"", line 3, in &lt;module&gt;
        from . import activations
      File ""/usr/local/lib/python2.7/site-packages/keras/activations.py"", line 3, in &lt;module&gt;
        from . import backend as K
      File ""/usr/local/lib/python2.7/site-packages/keras/backend/__init__.py"", line 73, in &lt;module&gt;
        from .tensorflow_backend import *
      File ""/usr/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py"", line 1, in &lt;module&gt;
        import tensorflow as tf
      File ""/usr/local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in &lt;module&gt;
        from tensorflow.python import *
      File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 51, in &lt;module&gt;
        from tensorflow.python import pywrap_tensorflow
      File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 52, in &lt;module&gt;
        raise ImportError(msg)
    ImportError: Traceback (most recent call last):
      File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 41, in &lt;module&gt;
        from tensorflow.python.pywrap_tensorflow_internal import *
      File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in &lt;module&gt;
        _pywrap_tensorflow_internal = swig_import_helper()
      File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
        _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
    ImportError: dlopen(/usr/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 10): Library not loaded: @rpath/libcublas.8.0.dylib
      Referenced from: /usr/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
      Reason: image not found

    Failed to load the native TensorFlow runtime.


I don't understand why this error is happening, I've set the right environmental variables in my .bash_profile file:

    export CUDA_HOME=/usr/local/cuda
    export DYLD_LIBRARY_PATH=""$DYLD_LIBRARY_PATH:$CUDA_HOME/lib""
    export PATH=""$CUDA_HOME/bin:$PATH""",0,1
30,2017-4-29,2017,4,29,1,683ugi,Had a problem with model restoring in tensorflow recently. Posting it here in case someone has the experience to tell me where my code is wrong.,https://www.reddit.com/r/tensorflow/comments/683ugi/had_a_problem_with_model_restoring_in_tensorflow/,Harawaldr,1493398225,,3,5
31,2017-4-30,2017,4,30,1,68a8fh,Tensorflow import error: TypeError: __init__() got an unexpected keyword argument 'syntax',https://www.reddit.com/r/tensorflow/comments/68a8fh/tensorflow_import_error_typeerror_init_got_an/,MasterJohnboy,1493483531,"I recently installed tensor flow for python2.7 using PIP on MacOS and when I try to import tensorflow I get this error back.


&gt;
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in &lt;module&gt;
    from tensorflow.python import *
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 54, in &lt;module&gt;
    from tensorflow.core.framework.graph_pb2 import *
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py"", line 16, in &lt;module&gt;
    from tensorflow.core.framework import node_def_pb2 as tensorflow_dot_core_dot_framework_dot_node__def__pb2
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/node_def_pb2.py"", line 16, in &lt;module&gt;
    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/attr_value_pb2.py"", line 16, in &lt;module&gt;
    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/tensor_pb2.py"", line 16, in &lt;module&gt;
    from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/resource_handle_pb2.py"", line 22, in &lt;module&gt;
    serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""m\n\x0eResourceHandle\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tB4\n\x18org.tensorflow.frameworkB\x13ResourceHandleProtoP\x01\xf8\x01\x01\x62\x06proto3')
TypeError: __init__() got an unexpected keyword argument 'syntax'

I think it may be an issue with protobuf when i do pip show protobuf i get:

&gt;
Johns-MacBook-Air:~ John$ pip show protobuf
Name: protobuf
Version: 3.2.0
Summary: Protocol Buffers
Home-page: https://developers.google.com/protocol-buffers/
Author: protobuf@googlegroups.com
Author-email: protobuf@googlegroups.com
License: New BSD License
Location: /usr/local/lib/python2.7/site-packages
Requires: six, setuptools


but when i do protoc --version:

Johns-MacBook-Air:~ John$ protoc --version
libprotoc 2.6.1
although this last one i saw on some forum post on installing protobuf so I'm not sure if its relevant.

If anyone has any input to this problem i would be grateful.",2,2
32,2017-4-30,2017,4,30,2,68ae43,[P] Image classification for 8 popular CNNs from a single program,https://www.reddit.com/r/tensorflow/comments/68ae43/p_image_classification_for_8_popular_cnns_from_a/,ug96,1493485258,,0,1
0,2017-5-2,2017,5,2,6,68osjy,How to use Magenta and Tensorflow to generate music in a free Google Cloud instance,https://www.reddit.com/r/tensorflow/comments/68osjy/how_to_use_magenta_and_tensorflow_to_generate/,tftutorial,1493673182,,0,5
1,2017-5-3,2017,5,3,7,68wel0,"Caption This, with TensorFlow (link to forkable GitHub repo included)",https://www.reddit.com/r/tensorflow/comments/68wel0/caption_this_with_tensorflow_link_to_forkable/,jonbruner,1493764325,,2,5
2,2017-5-4,2017,5,4,2,691sxh,Any free EC2 AMIs available with Tensorflow 1.0+ for GPU instances?,https://www.reddit.com/r/tensorflow/comments/691sxh/any_free_ec2_amis_available_with_tensorflow_10/,rudyl313,1493832489,Does anyone know of a public AMI that comes with Tensorflow 1.0+ preinstalled for the GPU instances?,3,1
3,2017-5-4,2017,5,4,7,693obf,Deep Learning with Emojis (not Math),https://www.reddit.com/r/tensorflow/comments/693obf/deep_learning_with_emojis_not_math/,fhoffa,1493850441,,1,8
4,2017-5-5,2017,5,5,3,699ajb,shared tensorflow weights gradients not being updated,https://www.reddit.com/r/tensorflow/comments/699ajb/shared_tensorflow_weights_gradients_not_being/,[deleted],1493922077,[deleted],0,2
5,2017-5-5,2017,5,5,18,69dm1s,Very simple seq2seq code?,https://www.reddit.com/r/tensorflow/comments/69dm1s/very_simple_seq2seq_code/,adammathias,1493975561,"For a course I'm teaching:

I'm looking for an example of sequence-to-sequence code that just takes text as input.  

The input can be either two text files of the same length, or a single file with two columns.

I don't necessarily care about optimisations like tokenisation.

See also: [Simple seq2seq example in TensorFlow?](https://www.reddit.com/r/MachineLearning/comments/43fw8s/simple_seq2seq_example_in_tensorflow/)",5,3
6,2017-5-6,2017,5,6,13,69jgbv,where to start if I only have webdev knowledge?,https://www.reddit.com/r/tensorflow/comments/69jgbv/where_to_start_if_i_only_have_webdev_knowledge/,dbsopinion,1494045369,"I've been trying to watch some videos about Tensorflow, but there are many terms mentioned that I'm unfamiliar with. Where do I start? Thanks",3,1
7,2017-5-6,2017,5,6,19,69kko2,Curated Tensorflow Code Resources,https://www.reddit.com/r/tensorflow/comments/69kko2/curated_tensorflow_code_resources/,[deleted],1494067131,[deleted],2,4
8,2017-5-7,2017,5,7,8,69oazq,No convergence on five letters?,https://www.reddit.com/r/tensorflow/comments/69oazq/no_convergence_on_five_letters/,blenderbill,1494114038,"I wrote a tensorflow program in python that generates random words based on the dictionary.  It works fine for four, six, seven and nine letter words, but generates semi-random blobs of text for five and eight letter words.  Any ideas on what could cause this?",3,2
9,2017-5-8,2017,5,8,0,69rr71,Any tutorials on implementing t-SNE in TensorFlow (not just visualizing)?,https://www.reddit.com/r/tensorflow/comments/69rr71/any_tutorials_on_implementing_tsne_in_tensorflow/,o-rka,1494170034,,0,5
10,2017-5-8,2017,5,8,7,69u8y5,How does one open a tensorboard port in Linux?,https://www.reddit.com/r/tensorflow/comments/69u8y5/how_does_one_open_a_tensorboard_port_in_linux/,real_pinocchio,1494196252,,0,3
11,2017-5-9,2017,5,9,3,69ztqm,Total Beginner question on training images,https://www.reddit.com/r/tensorflow/comments/69ztqm/total_beginner_question_on_training_images/,gorobotgorobot,1494267036,"I want to build a model to recognize a picture is of a kitchen. I have thousands of images of kitchens and all I want to know is whether a new image is a kitchen or not. A binary decision. I don't want to train it to recognize ovens or dishwashers I want it to figure out those features itself. But the question is what do I use to train for the negative set of ""not a kitchen"". For my input these could be any image possible. Do I just feed a model random images of ""not kitchens"" or is there a model that I just train for ""find images like this one""

Sorry if dumb question.",5,2
12,2017-5-11,2017,5,11,4,6af2bz,TensorFlow on Android: Can't get all library functions to load,https://www.reddit.com/r/tensorflow/comments/6af2bz/tensorflow_on_android_cant_get_all_library/,cappitak,1494444987,"I've been following [this](https://omid.al/posts/2017-02-20-Tutorial-Build-Your-First-Tensorflow-Android-App.html) tutorial. I used the nightly builds instead of creating my own.  I'm able to create a new TensorFlowInferenceInterface and that's about it. Afterwards I'm only able to run, feed, fetch, getStatString, graph, graphOperation, and close. Obviously, something is not importing correctly. Has anyone had this problem or been able to solve it?",1,3
13,2017-5-13,2017,5,13,5,6atyw0,"Which tool can I use create NNs visually, and visualize the data as it flows through it?",https://www.reddit.com/r/tensorflow/comments/6atyw0/which_tool_can_i_use_create_nns_visually_and/,dbsopinion,1494622770,,6,32
14,2017-5-13,2017,5,13,6,6au7au,An in-depth look at Googles first Tensor Processing Unit (TPU) | Google Cloud Big Data and Machine Learning Blog | Google Cloud Platform,https://www.reddit.com/r/tensorflow/comments/6au7au/an_indepth_look_at_googles_first_tensor/,[deleted],1494625255,[deleted],0,1
15,2017-5-13,2017,5,13,6,6au96k,An in-depth look at Google's first Tensor Processing Unit (TPU) | Google Cloud Big Data and Machine Learning Blog | Google Cloud Platform,https://www.reddit.com/r/tensorflow/comments/6au96k/an_indepth_look_at_googles_first_tensor/,kazunori279,1494625855,,0,2
16,2017-5-15,2017,5,15,16,6b8x5u,Implementing contrastive loss for cosine similarity in tensorflow.,https://www.reddit.com/r/tensorflow/comments/6b8x5u/implementing_contrastive_loss_for_cosine/,FutureIsMine,1494831697,,0,1
17,2017-5-22,2017,5,22,0,6ch222,Deep Learning library for TensorFlow for building end to end models and experiments.,https://www.reddit.com/r/tensorflow/comments/6ch222/deep_learning_library_for_tensorflow_for_building/,pipado,1495380059,,2,5
18,2017-5-22,2017,5,22,7,6cjjul,How to suggest to a user based on his actions that he would likely to like an artist using Tensorflow ?,https://www.reddit.com/r/tensorflow/comments/6cjjul/how_to_suggest_to_a_user_based_on_his_actions/,_calm_down_,1495406989,"Hello guys, I'm beginner in AI in general and Tensorflow is the best bet for this task I think, well my use case I think it's simple, I have set of data contains events that have been gathered from user interactions in a website, for example reading articles that has been tagged with artists, or he usually checkout the artist page, or frequently comment on artist songs, based on those actions I want to suggest to him that he would likely to follow or like this artist, What AI algorithm I should use ? and if there are examples done with Tensorflow or any guidance would helpful",2,0
19,2017-5-22,2017,5,22,17,6cm0t6,Live now! BigQuery and Cloud ML Engine for large-scale neural network predictions,https://www.reddit.com/r/tensorflow/comments/6cm0t6/live_now_bigquery_and_cloud_ml_engine_for/,krishnachytanya,1495441623,,0,4
20,2017-5-22,2017,5,22,22,6cn725,Weights matrix/vector in linear model with logistic regession,https://www.reddit.com/r/tensorflow/comments/6cn725/weights_matrixvector_in_linear_model_with/,christophfritz,1495459286,"Hey everyone. I have a quick question regarding the tutorial on [tensorflow.org](https://www.tensorflow.org/tutorials/wide). 
I get the architecture and everything but is there a way to get the weights matrix/vector and the biases after training (using the LinearClassifier)? 
Because it would be quite interesting how they changed.",0,3
21,2017-5-23,2017,5,23,0,6cny4n,"Political footprints are computed using machine learning technologies, which allows for a systematic and more objective political analysis.",https://www.reddit.com/r/tensorflow/comments/6cny4n/political_footprints_are_computed_using_machine/,CBruchansky,1495467130,,0,2
22,2017-5-23,2017,5,23,20,6cu3t6,Finding vehicle setups in racing to optimize lap times,https://www.reddit.com/r/tensorflow/comments/6cu3t6/finding_vehicle_setups_in_racing_to_optimize_lap/,BodetGrrla,1495539644,"Don't know really where to start and don't even know whether tensor flow is a well-suited tool for my problem.

Problem:

1. Racing vehicle has many components which can be modified: dampers, springs, suspension geometry, angle of attack of a front/rear wing, ...

2. I want to be faster

3. I don't want to run many tests

So I want to put all the variable in a vector/matrix/tensor and run it through a neural net which should put out a theoretical time. In the next step it should tweak with those inputs in order to optimize my lap times.

To train the neural net I have a ton of logged telemetry (motec)",2,1
23,2017-5-24,2017,5,24,13,6d01n6,The problem of option of reshape,https://www.reddit.com/r/tensorflow/comments/6d01n6/the_problem_of_option_of_reshape/,LizaiGao,1495601455,"when i reshape the samples, the value of it is modified, why?",1,1
24,2017-5-24,2017,5,24,18,6d16at,What is the key component that makes AI considerate of language syntax?,https://www.reddit.com/r/tensorflow/comments/6d16at/what_is_the_key_component_that_makes_ai/,dbsopinion,1495619954,"I've seen machine learning applications that produce text ""In the style of"" (e.g. in the style of lord of the rings texts), but the text doesn't actually make much sense, if any. How would I go about it, If I wanted to constrain the resulting text to only contain words from the dictionary, and only words that follow the strict rules of syntax?

P.S while I'm curious about the answer regarding the english language, I'd also like to figure out more broadly how to apply syntax rules that for languages other than english.",3,1
25,2017-5-24,2017,5,24,23,6d2d2t,Meaning of input_size paramener for tf.contrib.rnn.DropoutWrapper,https://www.reddit.com/r/tensorflow/comments/6d2d2t/meaning_of_input_size_paramener_for/,dipspb,1495635046,"Hi!

I trying to use dropout feature in RNN training and have a question about tf.contrib.rnn.DropoutWrapper. What the idea of input_size parameter value that is required to be defined for variational dropout while training RNNs?

What do I need to provide as input_size value? Is it a number of features? Or maybe is it amount of samples in a training vector?

Thank you in advance!",4,2
26,2017-5-25,2017,5,25,12,6d758p,Non image based tutorial,https://www.reddit.com/r/tensorflow/comments/6d758p/non_image_based_tutorial/,mlpyotr,1495682949,"I'm attempting to use tensorflow with my own data. Simple csv file. Can't seem to find non image based examples. Trying to use tflearn for simplicity but that word has a different meaning in this field. 

Any case, thanks for helpful comments",3,3
27,2017-5-25,2017,5,25,17,6d8ei7,TensorFlow macOS pre-built binary with SSE and AVX optimizations,https://www.reddit.com/r/tensorflow/comments/6d8ei7/tensorflow_macos_prebuilt_binary_with_sse_and_avx/,Dragonbourbon,1495702019,,4,9
28,2017-5-27,2017,5,27,13,6dlxja,TensorFlow GPU CUDA CUDDN errors,https://www.reddit.com/r/tensorflow/comments/6dlxja/tensorflow_gpu_cuda_cuddn_errors/,McCossum,1495860950,,1,1
29,2017-5-28,2017,5,28,7,6dqbha,An image classifier built with Tensorflow.,https://www.reddit.com/r/tensorflow/comments/6dqbha/an_image_classifier_built_with_tensorflow/,amdsouza92,1495922686,,0,6
30,2017-5-29,2017,5,29,18,6dzaqs,Keras 2.x using TF backend: error sharing weights across sessions,https://www.reddit.com/r/tensorflow/comments/6dzaqs/keras_2x_using_tf_backend_error_sharing_weights/,[deleted],1496049533,[deleted],0,3
31,2017-5-30,2017,5,30,5,6e2iff,Understanding Tensorflow using Go,https://www.reddit.com/r/tensorflow/comments/6e2iff/understanding_tensorflow_using_go/,pgaleone,1496088101,,0,11
32,2017-5-31,2017,5,31,20,6eegym,Can't even instantiate a model [python],https://www.reddit.com/r/tensorflow/comments/6eegym/cant_even_instantiate_a_model_python/,[deleted],1496231885,[deleted],0,1
0,2017-6-4,2017,6,4,15,6f5zow,Recurrent neural net in TensorFlow. I've got stuck. Could anyone fix it?,https://www.reddit.com/r/tensorflow/comments/6f5zow/recurrent_neural_net_in_tensorflow_ive_got_stuck/,HarambeTownley,1496557327,,0,0
1,2017-6-6,2017,6,6,2,6ffnhh,Sequence-to-sequence implementation using tf.contrib.seq2seq.BeamSearchDecoder,https://www.reddit.com/r/tensorflow/comments/6ffnhh/sequencetosequence_implementation_using/,uwanggood,1496683616,,0,2
2,2017-6-6,2017,6,6,8,6fi2ao,HELP! Understanding TensorFlow?,https://www.reddit.com/r/tensorflow/comments/6fi2ao/help_understanding_tensorflow/,samiejg,1496705973,"I've watched a ton of different Youtube videos on TensorFlow, as well as following along with some tutorials on there too. But I'm still having a difficult time understanding how it works.

Just feeling frustrated with myself now (and feeling dumb). I'm sure part of it is because I'm only an amateur when it comes to programming... and not having a College/University level English comprehension, nor that of a Computer Science graduate and the verbiage they use.

I hear a lot of talk about TensorFlow being comparable to AI, and I just don't understand that at all... and I wonder if I did understand it, if maybe the rest would just ""click"" for me.

The part I'm not understanding is how you can throw in a few files with data, and somehow TensorFlow can train off the data. Like... how does TensorFlow know what's correct when it's training?

Like one example is the TensorFlow chatbot stuff which was posted by Siraj Raval on Youtube. Apparently you can just have a couple files full of random data phrases/responses/text and somehow TensorFlow can train off that? And then become some sort of super-functional AI chatbot? Just not getting it :( and it doesn't help that it's not working for me.. but sounds like I'm not the only one because there are others reporting completely gibberish responses from the bot (even after days of training).

Any suggestions/thoughts? Aside from going to university or being smarter? :P",5,1
3,2017-6-6,2017,6,6,21,6flgy7,How to evaluate tf-slim network using native tensorflow!,https://www.reddit.com/r/tensorflow/comments/6flgy7/how_to_evaluate_tfslim_network_using_native/,princedhiman,1496752438,"Can somebody please help me in evaluating tf-slim trained network using native tensorflow. 
My deployment server doesn't support tf-slim.",3,2
4,2017-6-7,2017,6,7,13,6fr6j6,Creating bottlenecks takes forever?,https://www.reddit.com/r/tensorflow/comments/6fr6j6/creating_bottlenecks_takes_forever/,mushm0m,1496809234,"Hi guys,

I'm new to TF and I'm following this tutorial: https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/index.html#4

However I have my own dataset. I have roughly 400K images spread across 100 classes.

I'm now at the step of retraining the final layer of the network. I'm noticing that the retrain script generates a bottleneck file for every image, sequentially (there's no multi-threading). I'm on a machine with 1 GPU and 8 CPUs, if that matters. At the pace this is taking, I'd estimate that it would take ~20 hours to create all the bottleneck files. 

This is really slow - is there anything I can do?

EDIT: I've checked my CPU usage and it does appear that all 8 CPUs are being used quite heavily, actually. Is there anything else I can do to cut down on time (besides reducing images)",6,2
5,2017-6-7,2017,6,7,15,6frnph,Stuck at one small error since the past 2 days. Please help?,https://www.reddit.com/r/tensorflow/comments/6frnph/stuck_at_one_small_error_since_the_past_2_days/,rjmessibarca,1496816112,"I was following tensorflow from sentdex tutorials but got stuck on [this](https://pythonprogramming.net/data-size-example-tensorflow-deep-learning-tutorial/) tutorial. Basically, I did everything as mentioned there, and also downloaded the `model.ckpt` and `lexicon.pickle` file from there.

&amp;nbsp;

However when I run the `test_neural_network()`, I get the following error:

`InvalidArgumentError (see above for traceback): Expected to restore a tensor of type float, got a tensor of type int32 instead: tensor_name = Variable`

&amp;nbsp;

I have tried googling it since the past 2 days and even posted the question on stack overflow, but have not got any answer.

&amp;nbsp;

This is my last hope. Please help",3,2
6,2017-6-7,2017,6,7,16,6fry5e,Help estimator for distribution,https://www.reddit.com/r/tensorflow/comments/6fry5e/help_estimator_for_distribution/,Cz1975,1496820670,"I am trying to look for resources on how to build an estimator for a bi-modal distribution. An example of what I want to do:

My distribution looks similar to this -b, -a, 0 , a, b. The histogram is centered on 0.

X0=[0.2, 0.1, 0, 0.5, 0.2] y=[1] Weight is to the right, things will go up.

X1=[0.2, 0.5, 0, 0.1, 0.2] y=[-1] Weight is to the left, things will go down.



Xn

After working through a 300p book about tensorflow I do not feel any closer to a solution. Any pointers on where to look on building a graph would be greatly appreciated.
",0,1
7,2017-6-8,2017,6,8,3,6fv7tc,Building Tensorflow Graphs Inside of Functions,https://www.reddit.com/r/tensorflow/comments/6fv7tc/building_tensorflow_graphs_inside_of_functions/,FiniteDelight,1496859004,"I'm learning Tensorflow and am trying to properly structure my code. I (more or less) know how to build graphs either bare or as class methods, but I'm trying to figure out how best to structure the code. I've tried the simple example:

    def build_graph():                
        g = tf.Graph()     
        with g.as_default():                       
            a = tf.placeholder(tf.int8)
            b = tf.add(a, tf.constant(1, dtype=tf.int8))
        return g   

    graph = build_graph()
    with tf.Session(graph=graph) as sess:
        feed = {a: 3}      
        print(sess.run(b, feed_dict=feed))

which should just print out 4. However, when I do that, I get the error:

    Cannot interpret feed_dict key as Tensor: Tensor 
    Tensor(""Placeholder:0"", dtype=int8) is not an element of this
    graph.

I'm pretty sure this is because the placeholder inside the function `build_graph` is private, but shouldn't the with `tf.Session(graph=graph)` take care of that? If not, what exactly does the `tf.Session(graph=)` keyword argument do? Is there a better way of using a feed dict in a situation like this?
",0,2
8,2017-6-8,2017,6,8,8,6fx8nu,Does the CPU/chipset matter much if you're using a good GPU?,https://www.reddit.com/r/tensorflow/comments/6fx8nu/does_the_cpuchipset_matter_much_if_youre_using_a/,kyledrake,1496878279,"I'm about to throw a 1080 Ti into an older sandy bridge machine. I was looking at upgrading to kaby lake for this, but I can't find any evidence that I actually need to, and TensorFlow doesn't really cite CPU requirements or recommendations.

I wanted to ask if anyone had any insights/opinions/experience on throwing fast new GPUs into older machines, and if you thought there might be bottleneck issues caused by that. The impression I'm getting is that for the most part, most of the heavy lifting is being done on the GPU and the CPU/bus performance isn't as important. The correct answer is probably ""it depends on what you're doing"", but I wanted to see if anyone had any good anecdotal evidence before I dropped a bunch of $ on new parts I might not need. Thanks!",3,1
9,2017-6-8,2017,6,8,9,6fxlxg,Tensorboard 'Site cannot be found'?,https://www.reddit.com/r/tensorflow/comments/6fxlxg/tensorboard_site_cannot_be_found/,mushm0m,1496882350,"I just followed this Tensorflow tutorial, doing the final retraining step on a classification problem (but using my own dataset): https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#3

I used a very large dataset so I let the training run overnight. Now it's completed, and I didn't see how it performed as I wasn't at the computer.

I need to visualize the results, so I tried:

    :/tf_files# tensorboard --logdir training_summaries --debug  
    Starting TensorBoard 47 at http://0.0.0.0:6006
    (Press CTRL+C to quit)

There are no additional messages in terminal.

But when I visit http://0.0.0.0:6006 it does not load, and says This site cant be reached

0.0.0.0 refused to connect.
Search Google for 6006
ERR_CONNECTION_REFUSED

What did I do wrong? How do I visualize the results?",1,1
10,2017-6-8,2017,6,8,21,6g0nj8,defaultcontext: Tiny Python util for creating tensorflow-like context managers for default instances of classes,https://www.reddit.com/r/tensorflow/comments/6g0nj8/defaultcontext_tiny_python_util_for_creating/,hidden-markov,1496925116,,0,1
11,2017-6-10,2017,6,10,0,6g938x,How can I see histograms of weights and/or gradients (I'm looking for vanishing gradients) in an iPython notebook?,https://www.reddit.com/r/tensorflow/comments/6g938x/how_can_i_see_histograms_of_weights_andor/,TheMoskowitz,1497021885,"Haven't used the visual features of tensorflow at all so any code examples would be great, thanks.",0,3
12,2017-6-10,2017,6,10,3,6ga603,Started my career.,https://www.reddit.com/r/tensorflow/comments/6ga603/started_my_career/,dhanush_ramuk,1497031853,Just installed tensorflow in my windows machine and I think I may have started my career but it's too soon to tell.,0,0
13,2017-6-10,2017,6,10,5,6gb4on,One hot encoding,https://www.reddit.com/r/tensorflow/comments/6gb4on/one_hot_encoding/,mlpyotr,1497040968,"Is there a programmatic way to get back the encoding after using a one hot encoding function? 

I'm assuming people in (insert w/e company) don't just train models to get accuracy numbers and move on. The models have to be saved and useable for actually future classification. If so, how do they retrieve the encodings? 

It seems that a lot of the examples just worry about doing OHC for training, validation but don't worry about the ""let's make it useable"" part.

Thanks for any clarification!",2,0
14,2017-6-10,2017,6,10,6,6gbdeh,Google Announces Tensorflow Lite: A Neural Network Library for Mobile Phones,https://www.reddit.com/r/tensorflow/comments/6gbdeh/google_announces_tensorflow_lite_a_neural_network/,Dutchcheesehead,1497043390,,0,23
15,2017-6-12,2017,6,12,4,6gn8cs,How to install Tensorflow on Windows 10?,https://www.reddit.com/r/tensorflow/comments/6gn8cs/how_to_install_tensorflow_on_windows_10/,trillykins,1497208700,"Guide on the official site says to just use pip, but Tensorflow is not on pip.

&gt; Could not find a version that satisfies the requirement tensorflow (from versions: ) No matching distribution found for tensorflow

Looking on the internet, it seems like the issue has persisted for almost a year now, so I can only assume the site just hasn't been updated. I'm using the latest version of Python 3.6.x and Pip is up-to-date. Tried 3.5 because it says it only supports 3.5.x, but same story. 

Anyone know how you're supposed to install it now? ",12,2
16,2017-6-12,2017,6,12,4,6gncak,Using TFRecords as inputs to a CNN in Python,https://www.reddit.com/r/tensorflow/comments/6gncak/using_tfrecords_as_inputs_to_a_cnn_in_python/,MekaMuffin,1497209861,"Hello all. So currently, I want to use TFRecords (tensorflow - python) containing image data and image labels in a dictionary. More specifically, I want to use this data to train a CNN (Convolutional Neural Network) for the SVHN 32x32 image dataset. What is the best way to go about doing this? As of now, I have trained a CNN with the 32x32 SVHN image dataset using .bin files as inputs. I used the tensorflow cifar10 code and changed the input to be the SVHN images and the classes to be integers from 0-9. To clarify, instead of using .bin files as inputs, I want to use a TFRecord containing training image data and labels. How would I do this? Thanks in advance for your help!",0,1
17,2017-6-12,2017,6,12,5,6gnjjb,Is there a way to partially load a tensor into memory? Or is my computer just a potato,https://www.reddit.com/r/tensorflow/comments/6gnjjb/is_there_a_way_to_partially_load_a_tensor_into/,ronsap123,1497211989,"Hey everyone I'm just getting into tensorflow and yesterday I implemented my first generative adversarial network. And there is a dense layer there that goes from 25600 to 40000 computational units. The last one being a 200200 image. It seems my computer can't handle that, it says that there is not enough memory for a tensor with a size of[25600, 40000]. Am I not supposed to load it at once into memory? Am I doing something wrong? Or is my computer really is that bad. (Dual core i5, intel graphics, 8 gb ram, sad I know)",3,1
18,2017-6-12,2017,6,12,16,6gqvbx,"Upgrading AWS ""Deep Learning AMI Ubuntu Version"" to TensorFlow 1.1.0 with GPU support",https://www.reddit.com/r/tensorflow/comments/6gqvbx/upgrading_aws_deep_learning_ami_ubuntu_version_to/,adamw1pl,1497254387,,0,7
19,2017-6-12,2017,6,12,18,6gr9k0,Tensorflow: Error when trying to import,https://www.reddit.com/r/tensorflow/comments/6gr9k0/tensorflow_error_when_trying_to_import/,Anonymous1893,1497261441,"So I was trying to import tensorflow for the first time, and this monstrosity came up...

&gt;Traceback (most recent call last):
&gt;  File ""C:\Users\Azhaan Haq\Anaconda3\envs\tensorflow\lib\site-&gt;packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
&gt;    return importlib.import_module(mname)
&gt;  File ""C:\Users\Azhaan Haq\Anaconda3\envs\tensorflow\lib\importlib\__init__.py"", line 126, in import_module
&gt;    return _bootstrap._gcd_import(name[level:], package, level)
&gt;  File ""&lt;frozen importlib._bootstrap&gt;"", line 986, in _gcd_import
&gt;  File ""&lt;frozen importlib._bootstrap&gt;"", line 969, in _find_and_load
&gt;  File ""&lt;frozen importlib._bootstrap&gt;"", line 958, in _find_and_load_unlocked
&gt;  File ""&lt;frozen importlib._bootstrap&gt;"", line 666, in _load_unlocked
&gt;  File ""&lt;frozen importlib._bootstrap&gt;"", line 577, in module_from_spec
&gt;  File ""&lt;frozen importlib._bootstrap_external&gt;"", line 919, in create_module
&gt;  File ""&lt;frozen importlib._bootstrap&gt;"", line 222, in _call_with_frames_removed
&gt;ImportError: DLL load failed: The specified module could not be found.
&gt;
&gt;During handling of the above exception, another exception occurred:
&gt;
&gt;Traceback (most recent call last):
&gt;  File ""C:\Users\Azhaan Haq\Anaconda3\envs\tensorflow\lib\site-&gt;packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in &lt;module&gt;
&gt;    from tensorflow.python.pywrap_tensorflow_internal import *
&gt;  File ""C:\Users\Azhaan Haq\Anaconda3\envs\tensorflow\lib\site-&gt;packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in &lt;module&gt;
&gt;    _pywrap_tensorflow_internal = swig_import_helper()
&gt;  File ""C:\Users\Azhaan Haq\Anaconda3\envs\tensorflow\lib\site-&gt;packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
&gt;    return importlib.import_module('_pywrap_tensorflow_internal')
&gt;  File ""C:\Users\Azhaan Haq\Anaconda3\envs\tensorflow\lib\importlib\__init__.py"", line 126, in import_module
&gt;    return _bootstrap._gcd_import(name[level:], package, level)
&gt;ImportError: No module named '_pywrap_tensorflow_internal'
&gt;
&gt;During handling of the above exception, another exception occurred:
&gt;
&gt;Traceback (most recent call last):
&gt;  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
&gt;  File ""C:\Users\Azhaan Haq\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\__init__.py"", line 24, in &lt;module&gt;
&gt;    from tensorflow.python import *
&gt;  File ""C:\Users\Azhaan Haq\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\__init__.py"", line 51, &gt;in &lt;module&gt;
&gt;    from tensorflow.python import pywrap_tensorflow
&gt;  File ""C:\Users\Azhaan Haq\Anaconda3\envs\tensorflow\lib\site-&gt;packages\tensorflow\python\pywrap_tensorflow.py"", line 52, in &lt;module&gt;
&gt;    raise ImportError(msg)
&gt;ImportError: Traceback (most recent call last):
&gt;  File ""C:\Users\Azhaan Haq\Anaconda3\envs\tensorflow\lib\site-&gt;packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
&gt;    return importlib.import_module(mname)
&gt;  File ""C:\Users\Azhaan Haq\Anaconda3\envs\tensorflow\lib\importlib\__init__.py"", line 126, in import_module
&gt;    return _bootstrap._gcd_import(name[level:], package, level)
&gt;  File ""&lt;frozen importlib._bootstrap&gt;"", line 986, in _gcd_import
&gt;  File ""&lt;frozen importlib._bootstrap&gt;"", line 969, in _find_and_load
&gt;  File ""&lt;frozen importlib._bootstrap&gt;"", line 958, in _find_and_load_unlocked
&gt;  File ""&lt;frozen importlib._bootstrap&gt;"", line 666, in _load_unlocked
&gt;  File ""&lt;frozen importlib._bootstrap&gt;"", line 577, in module_from_spec
&gt;  File ""&lt;frozen importlib._bootstrap_external&gt;"", line 919, in create_module
&gt;  File ""&lt;frozen importlib._bootstrap&gt;"", line 222, in _call_with_frames_removed
&gt;ImportError: DLL load failed: The specified module could not be found.
&gt;
&gt;During handling of the above exception, another exception occurred:
&gt;
&gt;Traceback (most recent call last):
&gt;  File ""C:\Users\Azhaan Haq\Anaconda3\envs\tensorflow\lib\site-&gt;packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in &lt;module&gt;
&gt;    from tensorflow.python.pywrap_tensorflow_internal import *
&gt;  File ""C:\Users\Azhaan Haq\Anaconda3\envs\tensorflow\lib\site-&gt;packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in &lt;module&gt;
&gt;    _pywrap_tensorflow_internal = swig_import_helper()
&gt;  File ""C:\Users\Azhaan Haq\Anaconda3\envs\tensorflow\lib\site-&gt;packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
&gt;    return importlib.import_module('_pywrap_tensorflow_internal')
&gt;  File ""C:\Users\Azhaan Haq\Anaconda3\envs\tensorflow\lib\importlib\__init__.py"", line 126, in import_module
&gt;    return _bootstrap._gcd_import(name[level:], package, level)
&gt;ImportError: No module named '_pywrap_tensorflow_internal'
&gt;
&gt;
&gt;Failed to load the native TensorFlow runtime.
&gt;
&gt;See https://www.tensorflow.org/install/install_sources#common_installation_problems
&gt;
&gt;for some common reasons and solutions.  Include the entire stack trace
&gt;above this error message when asking for help.**
&gt;

*ImportError: DLL load failed: The specified module could not be found.*

This was, as far as I know, the first error that comes up

I was using an Anaconda Environment if that helps
Thanks",2,1
20,2017-6-14,2017,6,14,19,6h6jxt,Ive got problens with rnns. In what form do I input a seqeuce?,https://www.reddit.com/r/tensorflow/comments/6h6jxt/ive_got_problens_with_rnns_in_what_form_do_i/,HarambeTownley,1497434849,"I want it to learn 1,2,3,4,5... But I don't know in what format should the sequence be?

Python 3.5",0,3
21,2017-6-15,2017,6,15,1,6h8fy1,Easy Question,https://www.reddit.com/r/tensorflow/comments/6h8fy1/easy_question/,WooxJr,1497456173,"I'm just getting started with Tensorflow: 

Using the example they give on the website, I initialize and print: 

node1 = tf.constant(3.0)
node2 = tf.constant(4.0)
print node1
print node2

and I get 

Tensor(""Const:0"", shape=(), dtype=float32)
Tensor(""Const_1:0"", shape=(), dtype=float32)

I'm just wondering: What's Const and what's Const_1?

I understand that I need to evaluate the nodes to actually get 3 and 4 but what am I looking at when I print the nodes themselves and what is ""const""?
Thanks!
",2,1
22,2017-6-15,2017,6,15,11,6hc7t5,Question about activating tensor flow,https://www.reddit.com/r/tensorflow/comments/6hc7t5/question_about_activating_tensor_flow/,WooxJr,1497493231,"I'm still rather new to this, so it might seem like quite a stupid question:

Before I use tensor flow do I always need to do this: ""source ~/tensorflow/bin/activate"" when I open a new shell? 

I usually do that then do python filename.py

Is there a way to have tensor flow always ""activated"" in terminal (not sure what you call it). 

Thanks!",5,1
23,2017-6-15,2017,6,15,23,6hf9lp,Easy q - Does this look like overfitting?,https://www.reddit.com/r/tensorflow/comments/6hf9lp/easy_q_does_this_look_like_overfitting/,[deleted],1497536177,[deleted],0,1
24,2017-6-16,2017,6,16,1,6hfxon,Tensor Flow Optimizers,https://www.reddit.com/r/tensorflow/comments/6hfxon/tensor_flow_optimizers/,WooxJr,1497542546,"Okay I think I know the answer but I'm sure someone can clarify. 

For reference, I'm looking at this program:
http://web.stanford.edu/class/cs20si/lectures/notes_03.pdf

More specifically, the lines: 

loss  =  tf . square ( Y  -  Y_predicted ,  name = ""loss"")

optimizer  =  tf . train . GradientDescentOptimizer ( learning_rate = 0.001 ). minimize ( loss)


Not a deep question, but what I'm wondering is how does the optimizer know what to optimize with respect to? Here we have two variables, so since loss is a ""function"" (don't know if that's what we call it) of two variables, does it automatically know to minimize ""loss"" by changing those two variables (taking the gradient etc..)

Thanks!",1,1
25,2017-6-16,2017,6,16,1,6hfy51,A new easy-to-use open source project which contains tutorials on how to implement different models using TensorFLow.,https://www.reddit.com/r/tensorflow/comments/6hfy51/a_new_easytouse_open_source_project_which/,irsina,1497542657,,0,3
26,2017-6-16,2017,6,16,17,6hl6zv,TensorFlow 1.2.0 has been released!,https://www.reddit.com/r/tensorflow/comments/6hl6zv/tensorflow_120_has_been_released/,archdria,1497600442,,1,15
27,2017-6-16,2017,6,16,22,6hmgzt,Google Released MobileNets: Efficient Pre-Trained Tensorflow Computer Vision Models,https://www.reddit.com/r/tensorflow/comments/6hmgzt/google_released_mobilenets_efficient_pretrained/,Dutchcheesehead,1497619210,,0,6
28,2017-6-17,2017,6,17,0,6hn8xu,Question about batches,https://www.reddit.com/r/tensorflow/comments/6hn8xu/question_about_batches/,WooxJr,1497627168,"For reference, I'm looking at the code in: http://web.stanford.edu/class/cs20si/lectures/notes_03.pdf

I'm a little confused on the difference between n_epochs and n_batches? 

Specifically I'm looking at: 

...
n_batches  =   int ( MNIST . train . num_examples / batch_size)


for  i  in  range ( n_epochs ):   # train the model n_epochs times


for  _  in  range ( n_batches ):
...


What I don't get is the need for epochs. Why can't we just say batch_size = 100, then num_batches = amount of data/batch_size then just iterate over num_batches so that we use all the training data?",1,1
29,2017-6-17,2017,6,17,14,6hromu,"So I've been wondering, the new Kurzgesagt video about AI talks about Bots that use Freelancers to learn what tasks they do to eventually replace that entire job. Are there any real examples of this?",https://www.reddit.com/r/tensorflow/comments/6hromu/so_ive_been_wondering_the_new_kurzgesagt_video/,thisisRio,1497675874,,2,0
30,2017-6-17,2017,6,17,15,6hs0t5,Cheapest iPhone I can buy to test TF?,https://www.reddit.com/r/tensorflow/comments/6hs0t5/cheapest_iphone_i_can_buy_to_test_tf/,mushm0m,1497681483,"Hey guys, I'm attempting to make an iOS app that relies on TensorFlow for image recognition. Sadly I don't have an iPhone, so I need to buy one for testing purposes.

I'd like to buy the oldest/cheapest iPhone that could still feasibly run TensorFlow to do image recognition from the camera without too many issues. 

I'm wondering if an iPhone 4/4s would be OK, or if I need a 5 (or newer than a 5)?",3,4
31,2017-6-18,2017,6,18,7,6hwaze,Image Segmentation using deconvolution layer in Tensorflow,https://www.reddit.com/r/tensorflow/comments/6hwaze/image_segmentation_using_deconvolution_layer_in/,psangrene,1497739041,,0,1
32,2017-6-18,2017,6,18,19,6hz3fq,Using Tensorflow-gpu with Keras,https://www.reddit.com/r/tensorflow/comments/6hz3fq/using_tensorflowgpu_with_keras/,trillykins,1497783493,"I have gotten Tensorflow up and running on Windows 10 using Python 3.5.2 and made a CNN. Problem is, it's very slow because it is using my CPU instead of my Nvidia GTX 1070 GPU. I have already installed tensorflow-gpu, but it is not registering my GPU for some reason.

When I run this: 

    from tensorflow.python.client import device_lib
    device_lib.list_local_devices() 

It only shows ` ""/cpu:0""`.

Anyone have any suggestions? I've tried following the installation steps mention in [this thread](https://github.com/fchollet/keras/issues/5776), but that didn't change anything. If I install tensorflow, then install Keras, uninstall and re-install Tensorflow-GPU, Tensorflow is not found at all when running the code. If I install Tensorflow and then Tensforflow-GPU, it still only uses the CPU.",5,2
33,2017-6-19,2017,6,19,5,6i1z4t,Question on Tensorflow seq2seq implementation,https://www.reddit.com/r/tensorflow/comments/6i1z4t/question_on_tensorflow_seq2seq_implementation/,hassanzadeh,1497819186,"Hi everyone,
The following code snippet is from Tensorflow github page for an RNN decoder of a seq2seq model. What I don't understand is the part that tries to reuse the variables. I'm not sure what exactly are we reusing here and why, any help?
    
    with variable_scope.variable_scope(scope or ""rnn_decoder""):
      state = initial_state
      outputs = []
      prev = None
      for i, inp in enumerate(decoder_inputs):
        if loop_function is not None and prev is not None:
          with variable_scope.variable_scope(""loop_function"", reuse=True):
            inp = loop_function(prev, i)
        if i &gt; 0:
          variable_scope.get_variable_scope().reuse_variables()
        output, state = cell(inp, state)
        outputs.append(output)
        if loop_function is not None:
          prev = output
    return outputs, state",9,2
34,2017-6-19,2017,6,19,8,6i2tqv,seq2seq with dynamic rnn,https://www.reddit.com/r/tensorflow/comments/6i2tqv/seq2seq_with_dynamic_rnn/,hassanzadeh,1497828893,"Hi Everyone,
It looks like the seq2seq model in tf is written with the static_rnn, but my input and output seq len is not determined, is there any implementation of that with dynamic_rnn?
Also, I see from the implementation that in order to have the encoder vs decoder cell weights untied, in the decoder the reuse flag is set to one from the second step, however, according to the latest release of the TF, the scope is cached and reused at every step, which means that the current implementation for the untied version is similar to the tied one, am I right?",1,1
35,2017-6-19,2017,6,19,13,6i45fn,Using 3D Convolutional Neural Networks for Speaker Verification,https://www.reddit.com/r/tensorflow/comments/6i45fn/using_3d_convolutional_neural_networks_for/,irsina,1497845495,,2,5
36,2017-6-20,2017,6,20,1,6i7cub,question on re-training the final layer of inception5h (and question on its structure),https://www.reddit.com/r/tensorflow/comments/6i7cub/question_on_retraining_the_final_layer_of/,hugokhf,1497888280,"
So I am looking into retraining the inception5h model that is used in the TFClassify demo: 

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/README.md

I want to retrain the final layer to add a new label as the output. However, from my research in the internet, it seems that it is impossible to retrain the 5h model as it is quantized and some of the layers have been stripped out to make it run more effeciently in the mobile. So have anyone around here tried retraining the 5h model??


Also, I am looking into the exact structure of inception5h or how it is made. From what I understand, it has the exact same structure as inceptionv3, but I cannot find any documentation as to what was done to it to make it more mobile efficient. Can anyone point me to a direction where I can look it up? thanks. Are there tutorials showing how to convert a v3 model into a 5h model?

thanks in advance",0,1
37,2017-6-20,2017,6,20,13,6ibofk,Any reason why the GPU wouldn't be used when running this?,https://www.reddit.com/r/tensorflow/comments/6ibofk/any_reason_why_the_gpu_wouldnt_be_used_when/,ERLindeman,1497931495,"I have CUDA v8.0, cuDNNv5.1, Python3.5.2, tensorflow-gpu installed with pip(3), code run with IDLE; PC has 13-6100, GTX 1050 Ti, with CPU only the first cycle reports about an hour remaining. 

If there is anything else I need to attach please let me know. (I assume I need a log from somewhere, but I can't seem to figure it out)

            #Imports
    import tensorflow as tf
    import time, math, datetime
    from tensorflow.examples.tutorials.mnist import input_data
        #Data Definitions
    mnist = input_data.read_data_sets(""MNIST_data"", one_hot = True)

            #Graph
        #Definitions
    n_nodes_hl1 = 100
    n_nodes_hl2 = 100
    n_nodes_hl3 = 100
    data_size = 784
    n_classes = 10
    hm_cycles = 512
    batch_size = round((data_size * n_classes)/hm_cycles)
    learning_rate = 0.001
    final_output = """"
    cycle_time_l = []
    #constants

    #Variables
    hl1_w = tf.Variable(tf.random_normal([data_size, n_nodes_hl1]))
    hl1_b = tf.Variable(tf.random_normal([n_nodes_hl1]))
    hl2_w = tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2]))
    hl2_b = tf.Variable(tf.random_normal([n_nodes_hl2]))
    hl3_w = tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3]))
    hl3_b = tf.Variable(tf.random_normal([n_nodes_hl3]))
    ol_w = tf.Variable(tf.random_normal([n_nodes_hl3, n_classes]))
    ol_b = tf.Variable(tf.random_normal([n_classes]))
    #placeholders
    x = tf.placeholder('float', [None, data_size])
    y = tf.placeholder('float', [None, n_classes])
        #Computing
    def neural_network_model(data):
        hidden_layer_1 = {hl1_w,hl1_b}
        hidden_layer_2 = {hl2_w,hl2_b}
        hidden_layer_3 = {hl3_w,hl3_b}
        output_layer = {ol_w,ol_b}
        l1 = tf.add(tf.matmul(data, hl1_w), hl1_b)
        l1 = tf.nn.relu(l1)
        l2 = tf.add(tf.matmul(l1, hl2_w), hl2_b)
        l2 = tf.nn.relu(l2)
        l3 = tf.add(tf.matmul(l2, hl3_w), hl3_b)
        l3 = tf.nn.relu(l3)
        output = tf.add(tf.matmul(l3, ol_w), ol_b)
        return output
    def train_neural_network(x):
        prediction = neural_network_model(x)
        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))
        optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)


            #Sessions
        #Loop
        with tf.Session() as sess1:
            sess1.run(tf.global_variables_initializer())
            print('Learning from Batches of ' + str(batch_size) + ' data points for ' + str(hm_cycles) + ' Cycles.')
            for cycle in range(hm_cycles):
                cycle_time_s = time.time()
                cycle_loss = 0
                for _ in range(int(mnist.train.num_examples/batch_size)):
                    ex, ey = mnist.train.next_batch(batch_size)
                    _, c = sess1.run([optimizer, cost], feed_dict = {x: ex, y: ey})
                    cycle_loss += c
                correct = tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))
                accuracy = tf.reduce_mean(tf.cast(correct,'float'))
                percentage = 100 * accuracy.eval({x: mnist.test.images, y:mnist.test.labels})
                cycle_time_e = time.time()
                cycle_time = (cycle_time_e - cycle_time_s)
                cycle_time_l.insert(cycle, cycle_time)
                cycle_time_a = (sum(cycle_time_l)/len(cycle_time_l))
                seconds_remaining = math.floor((hm_cycles - cycle - 1)*(cycle_time_a))
                print('Cycle ' + str(cycle + 1) + ' of ' + str(hm_cycles) + ' completed in ' + str(round((cycle_time),3)) + ' seconds. Loss: ' + str(round((cycle_loss),3)) + ' | Accuracy: ' + str(round((percentage),3)) + '% | ' + str(datetime.timedelta(seconds= (seconds_remaining) )) + ' remaining')
                if cycle + 1 == hm_cycles or cycle_loss == 0 or accuracy == 1:
                    run_time = cycle_time_a * hm_cycles
                    str(datetime.timedelta(seconds=run_time))
                    rt_m, rt_s = divmod(run_time, 60)
                    rt_h, rt_m = divmod(rt_m, 60)
                    efficiency = (percentage ** 3)/(run_time)
                    print('Finished. Cycles: ' + str(hm_cycles) + ' | Batch Size: ' + str(batch_size) + ' | Time: ' + str(datetime.timedelta(seconds= (run_time) )) + ' | Final Loss: ' + str(round((cycle_loss),3)) + ' | Final Accuracy: ' + str(round((percentage),3)) + '% | Efficiency: ' + str(round((efficiency),4)))
        #Sequential
    #Create

    #Run/Close
    train_neural_network(x)


            #Output
    print(final_output)
",4,1
38,2017-6-20,2017,6,20,23,6iefns,Loss Does Change?,https://www.reddit.com/r/tensorflow/comments/6iefns/loss_does_change/,FiniteDelight,1497969633,"TL;DR: I can't find my mistake when using the Tensorflow optimizer to train an extremely small neural net. The loss either doesn't move or moves once then gets stuck (it seems to really like the value 0.693147 which is ln(2)...).

Issue and Code: I'm trying to implement the 12-net part of the cascade classifier in Li et al (here) in Tensorflow. It's an extremely simple net, but nothing I try seems to get it training.

    import tensorflow as tf
    import tensorflow.contrib.slim as slim
    import cv2
    import numpy as np


    input_tensor = tf.placeholder(tf.float32, shape=[1, 12, 12, 3])
    input_label = tf.placeholder(tf.float16, shape=[1, 2])
    conv_1 = slim.conv2d(input_tensor, 16, (3, 3), scope='conv1')
    pool_1 = slim.max_pool2d(conv_1, (3, 3), 2, scope='pool1')
    flatten = slim.flatten(pool_1)
    fully_con = slim.fully_connected(flatten, 16, scope='full_con')
    fully_con_2 = slim.fully_connected(fully_con, 2, scope='output')
    probs = tf.nn.softmax(fully_con_2)
    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=input_label, logits=fully_con_2))
    optimizer = tf.train.GradientDescentOptimizer(learning_rate=.001).minimize(loss)

This defines the net. It takes in a (for now, single) 12x12 image and label, does a single 3x3 convolution with stride 1 and 16 filters, a 3x3 max pool with stride 2, then fully connects to 16 features, and finally makes a binary classification. I am able to perform a forward pass through the code, so I don't think the issue is here. This is my training loop - I have 3 12x12 images (2 faces, 1 tree) and just alternately feed them to the optimizer (clearly not best training practice, but I'm just trying to get it to work):

    if __name__ == '__main__':
        im = cv2.imread('resized.jpg').reshape(1, 12, 12, 3).astype('float16')
        im2 = cv2.imread('resized2.jpg').reshape(1, 12, 12, 3).astype('float16')
        im3 = cv2.imread('resize3.jpg').reshape(1, 12, 12, 3).astype('float16')
        im_lab_1 = np.array([[0, 1]], dtype='float16')
        im_lab_2 = np.array([[0, 1]], dtype='float16')
        im_lab_3 = np.array([[1, 0]], dtype='float16')

        with tf.Session() as sess:
            sess.run(tf.global_variables_initializer())
            print(sess.run(loss, feed_dict={input_tensor: im3, input_label: im_lab_3}))
            for i in range(50000):
                 if i % 3 == 0:
                    # _, l = sess.run([optimizer, loss], feed_dict=feed1)
                    # print(l)
                    optimizer.run(feed_dict={input_tensor: im, input_label: im_lab_1})
                 elif i % 4 == 0:
                    # _, l = sess.run([optimizer, loss], feed_dict=feed2)
                    # print(l)
                    optimizer.run(feed_dict={input_tensor: im2, input_label: im_lab_2})
                 elif i % 5 == 0:
                    optimizer.run(feed_dict={input_tensor: im3, input_label: im_lab_3})
            print(sess.run(loss, feed_dict={input_tensor: im3, input_label: im_lab_3}))

I've tried both optimizer.run(...) and the commented out sess.run([optimizer, loss]...). The first sess.run(loss...) seems to spit out something correct, but after that, the loss gets stuck and never moves again. Clearly, I'm doing something wrong here, and any help would be appreciated!
",7,2
39,2017-6-22,2017,6,22,22,6itjuq,"Looking for knowledgeable TensorFlow enthusiast, possible paid gig, thanks guys! &lt;3",https://www.reddit.com/r/tensorflow/comments/6itjuq/looking_for_knowledgeable_tensorflow_enthusiast/,heyguysitsdaniel,1498138886,"Hey TensorFlow reddit community, hope you guys are having a good day.

Pardon my directness guys. I neither program nor do I know the true extent of what TensorFlow is capable of.

Right now is a truly exciting time for finding out though.

I'm looking for a consultant, someone knowledgeable about what TensorFlow is truly capable of. I have investors eagerly waiting for these answers (I know that kind of sounds pretentious, but it's true, haha). If things go the right way, some kind of business venture would hopefully follow. 

**I know this is very vague and sounds kind of shady. :P** 

I agree, I don't trust me re-reading this shit post, haha. But I'd just like a conversation at this point. If anyone could point me in the right direction in who to ask, or just wants to chat about it, I would be extremely appreciative! 

thank you in advance for helping me realize some business dreams here guys!

**Thanks guys! Have a good day!** ",0,0
40,2017-6-24,2017,6,24,3,6j35cv,Using Deep Learning to Reconstruct High-Resolution Audio &amp; TensorFlow contribution,https://www.reddit.com/r/tensorflow/comments/6j35cv/using_deep_learning_to_reconstruct_highresolution/,mwakanosya,1498243115,,0,3
41,2017-6-24,2017,6,24,4,6j3afc,"Swift, Perfect and Tensorflow",https://www.reddit.com/r/tensorflow/comments/6j3afc/swift_perfect_and_tensorflow/,perfectlysoft,1498244443,"Hello all! 

After months of work, we have reached a milestone with our Server Side Swift (Perfect) implementation of Tensorflow. It works!

https://github.com/PerfectlySoft/Perfect-TensorFlow

We'd really appreciate some enterprising devs with Tensorflow experience to come give Server Side Swift a try and make suggestions on how we can improve the project. Maybe even join the Perfect community while you are at it!

We are truly excited for some feedback! It's been a huge effort.

Join Slack at http://Perfect.ly to discuss live.

Thanks!",2,3
42,2017-6-24,2017,6,24,10,6j5kk4,Trouble with tf.contrib.learn.learn_runner.run,https://www.reddit.com/r/tensorflow/comments/6j5kk4/trouble_with_tfcontriblearnlearn_runnerrun/,[deleted],1498268967,[deleted],0,1
43,2017-6-24,2017,6,24,12,6j5xgl,"A question about ""trainable"" in Tensorflow",https://www.reddit.com/r/tensorflow/comments/6j5xgl/a_question_about_trainable_in_tensorflow/,WooxJr,1498273628,"I've noticed in tutorials that when we declare global_step, e.g., 
""global_step = tf.Variable(initial_value=0,
                          name='global_step', trainable=False)"" 
we set trainable to false. What I'm wondering is: is this necessary, or just a good habit? Say the loss function depends only on a matrix and a bias (W and b), then the optimization would only try to change those two variables when taking a step in the direction of the gradient, no? 

Basically, what I'm wondering is: why do we need to specify that it's not trainable if the value we are minimizing doesn't even depend on it? ",1,1
44,2017-6-24,2017,6,24,22,6j82fe,Any blog post or tutorial regarding the model creation for Android tensorflow demo?,https://www.reddit.com/r/tensorflow/comments/6j82fe/any_blog_post_or_tutorial_regarding_the_model/,me_random_123,1498309663,"I am specifically talking about https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/src/org/tensorflow/demo/StylizeActivity.java

The model they have used here covers 26 styles and the size is in KBs. 

All the posts that I have seen online or on Github can create only one style, and even after quantization, the size for that model of just one style is at least 1 MB. 

Has Google posted how they trained the model, or is there any other post regarding this? Thanks",1,1
45,2017-6-25,2017,6,25,9,6jbfzs,Does anybody know how to install tensorflow on a headless Raspberry Pi 3 running 32 bit Kali Linux?,https://www.reddit.com/r/tensorflow/comments/6jbfzs/does_anybody_know_how_to_install_tensorflow_on_a/,madogson,1498349519,"I have been grinding at this for about 2 hours now. Numerous tutorials, many roadblocks and too many 'architecture not supported' messages to count have led me nowhere. Really hope someone will come by and at least take pity on me.",6,1
46,2017-6-26,2017,6,26,3,6jfwa1,Deep Learning with TensorFlow in Python,https://www.reddit.com/r/tensorflow/comments/6jfwa1/deep_learning_with_tensorflow_in_python/,psangrene,1498415532,,0,12
47,2017-6-27,2017,6,27,0,6jlvfw,Novel Deep Atrous CNN Architecture for Sentiment Analysis  Tensorflow Implementation,https://www.reddit.com/r/tensorflow/comments/6jlvfw/novel_deep_atrous_cnn_architecture_for_sentiment/,gvssvg,1498491787,,0,3
48,2017-6-27,2017,6,27,1,6jm9a5,AWS vs. New Laptop for Tensorflow GPU?,https://www.reddit.com/r/tensorflow/comments/6jm9a5/aws_vs_new_laptop_for_tensorflow_gpu/,ragnarkar,1498495316,"I haven't gotten a new computer since 2012 when I got a Macbook with only a 1 GB GPU which frequently runs out of memory when running even most toy Tensorflow examples I find online.

As a newbie who is still learning the ropes, I'm wondering if it's worthwhile to invest in a new computer just to run Tensorflow on the GPU or it makes more economical sense to get a AWS account with GPU support and pay as I go.  Thanks.",8,3
49,2017-6-27,2017,6,27,4,6jnd2j,Need some help with retraining inception v3,https://www.reddit.com/r/tensorflow/comments/6jnd2j/need_some_help_with_retraining_inception_v3/,Thebroser,1498505438,"My experience with tensorflow involves successfully using the MNIST data set, and a positive and negative string program. I decided to try and give inception a try and downloaded to windows the models from github but whenever I try to run inception_train.py I keep getting the error ""No module named 'inception' "" and I am not sure how to fix it. Tensorflow was installed natively with pip, and I am using python 3.5, as well as CUDA 8.0 and CudNN 5.1 with an nvidia 960m.",1,1
50,2017-6-27,2017,6,27,15,6jqy13,TensorFlow vs Pytorch,https://www.reddit.com/r/tensorflow/comments/6jqy13/tensorflow_vs_pytorch/,yoniker,1498545318,"Hi guys!

So I've been playing around for a few weeks with both frameworks.
I know that TF has an amazing PR thanks to Google, and many people use it,including researchers (academic articles).

But I've found TF's API to be absolutely TERRIBLE and awkward (not intuitive at all), 
while I was able to implement my ideas easily using PyTorch.
So I want to know your honest opinion-which one is your favorite and why?",9,3
51,2017-6-27,2017,6,27,23,6jt39x,Getting Started with TensorFlow,https://www.reddit.com/r/tensorflow/comments/6jt39x/getting_started_with_tensorflow/,verystrangecloud,1498574292,"Hey there guys,

I am currently a student who only has some basic familiarity with objected orientated programming (Java and some Arduino coding; so very little programming knowledge) Any recommendations on tutorials for Tensorflow and Python language tutorials?",6,7
52,2017-6-29,2017,6,29,21,6k85bm,"tfgo: Tensorflow + Go, the gopher way",https://www.reddit.com/r/tensorflow/comments/6k85bm/tfgo_tensorflow_go_the_gopher_way/,pgaleone,1498740941,,0,2
53,2017-6-29,2017,6,29,22,6k8bj2,"Looking for expert: loss distribution functions, matrix math, discontinuous nonlinear systems of equations, comparative geometry =&gt; [tensor math] _AND_ how to profile and optimize CPU time, unrolling and parallelizing to achieve maximum speed.",https://www.reddit.com/r/tensorflow/comments/6k8bj2/looking_for_expert_loss_distribution_functions/,gar37bic,1498742838,"I'm posting for a friend. He's the only person he can find who can do this, and he doesn't have time. I believe it to be a paid gig. PM if you are _very good_. You need to understand the math to, for example, use L'Hopital's Rule. This involves Tensor RT2.",0,0
54,2017-6-30,2017,6,30,1,6k9gdg,Denoising Autoencoder output,https://www.reddit.com/r/tensorflow/comments/6k9gdg/denoising_autoencoder_output/,AlloraQuesto,1498753521,"Good evening,

I've a question on denoising autoencoder created with tensorflow, for a project i need to create this ANN and use it for determinate anomaly detection on a data series and this part it's ok.
The question is: the output of a autoencoder is the reconstruction error, is it possible return the column/s (or features) who have the anomaly? 
Can someone help me? Thanks!",0,1
55,2017-6-30,2017,6,30,7,6kbwow,"The harder it is, the easier it is",https://www.reddit.com/r/tensorflow/comments/6kbwow/the_harder_it_is_the_easier_it_is/,iamdamned,1498775663,,1,24
56,2017-6-30,2017,6,30,11,6kd9d0,Training a CNN with probability labels,https://www.reddit.com/r/tensorflow/comments/6kd9d0/training_a_cnn_with_probability_labels/,shadow12348,1498790981,"I'm trying to do simple regression on images and ran into a dead end figuring out how to pick a point on the sigmoid curve in the output layer of a CNN. The training data is a large set of images and each image has a score associated with it between [0,8] that corresponds to how good it looks (Based on some other irrelevant metric). Now, if I was to use this data to train a CNN and scale [0,8] to [0,1], I'd like to be able to give in a random image later and expect the network to return to me a value between 0 and 1 that corresponds to the score of that image. In Tensorflow particularly how do I achieve this?

Any help is appreciated, thanks!",2,1
57,2017-6-30,2017,6,30,17,6kelct,"I don't understand ""Getting Started"" guide on TensorFlow. Please suggest some basic Machine Learning and Tensor Flow fundamentals (I am an SOC Firmware R&amp;D Engineer)",https://www.reddit.com/r/tensorflow/comments/6kelct/i_dont_understand_getting_started_guide_on/,user0user,1498809969,,4,1
0,2017-7-3,2017,7,3,5,6kvcba,Anyone used tfdbg on an ipython notebook?,https://www.reddit.com/r/tensorflow/comments/6kvcba/anyone_used_tfdbg_on_an_ipython_notebook/,TheMoskowitz,1499026355,I could really use an example to look at it. Not sure how to manage it.,1,4
1,2017-7-3,2017,7,3,17,6kysps,Tensorflow Plugin for Sublime Text editor,https://www.reddit.com/r/tensorflow/comments/6kysps/tensorflow_plugin_for_sublime_text_editor/,baptisteArnaud,1499072307,"Hey guys, I coded a Tensorflow plugin for Sublime Text. You can check it out here:
https://github.com/baptisteArnaud/Sublime-Tensorflow

It also has been accepted into the Tensorflow community projects:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/community/welcome.md",1,18
2,2017-7-3,2017,7,3,21,6kzmcx,Using your tensorflow model with golang,https://www.reddit.com/r/tensorflow/comments/6kzmcx/using_your_tensorflow_model_with_golang/,nilsmagnus,1499085252,,0,4
3,2017-7-3,2017,7,3,22,6kzspu,Has anyone worked with TensorFrames?,https://www.reddit.com/r/tensorflow/comments/6kzspu/has_anyone_worked_with_tensorframes/,zythologist,1499087483,"Hi,
I'm currently working with Spark, its DataFrames and MLLib.
I'd like to try to work with TensorFlow and I stumbled upon [TensorFrames](https://github.com/databricks/tensorframes/), which might allow me to bind the two worlds at once.

I'm currently working on a 5-computers cluster and the data I work with can't stay in the memory of a single node.

Has somebody here already tried TensorFrames ?
Is it mature enough to work with DataFrames ?
Would it be better to start from scratch with TensorFlow ?

Thanks
",0,1
4,2017-7-4,2017,7,4,4,6l27tb,Using second momentum as part of new cost function?,https://www.reddit.com/r/tensorflow/comments/6l27tb/using_second_momentum_as_part_of_new_cost_function/,PK_thundr,1499111513,"Hi everyone! I'm currently trying to take Adam's second order moment term, v_t, and use that as an additional term in my cost function. How can I implement something like this:

    Cost = Cross Entropy + v_t*some_function(weights)

Can this be accomplished within python? Or do I have to write my own C++ code to accomplish this? Also is this easily accomplished in a framework like Keras? Thanks!

-P",1,1
5,2017-7-4,2017,7,4,6,6l2vc2,Raving trouble (re)installing tensorflow on Ubuntu. Cannot find 'libcudnn.so.5',https://www.reddit.com/r/tensorflow/comments/6l2vc2/raving_trouble_reinstalling_tensorflow_on_ubuntu/,beckettman,1499118011,"I swear I did this about 5 months ago and had it all working.

Comp Specs:
- Intel i7 6700K
- GTX 1080
- 500Gb SSD (2)
- Ubuntu 16.04

I installed CUDA 8.0 and went to 'install' the cudnn library.  I downloaded the extra cudnn package and for some reason I cannot remember how to get that all hooked up becase I get: 

""ImportError: libcudnn.so.5: cannot open shared object file: No such file or directory""

I have installed tensorflow using Anaconda but I cannot get it to notice where I have placed the cudnn files.

I'm still a bit green when it comes to linux and I can't figure out how to get the library noticed.  I have tried the instructions on the nvidia website and tried the instructions here:

https://stackoverflow.com/questions/42013316/after-building-tensorflow-from-source-seeing-libcudart-so-and-libcudnn-errors

Any help would be greatly appreciated.  Thank you  :)",4,3
6,2017-7-5,2017,7,5,17,6lcrhz,Identifying 4 categories of words in a string.,https://www.reddit.com/r/tensorflow/comments/6lcrhz/identifying_4_categories_of_words_in_a_string/,roverelk,1499243222,"Hi guys,

working with OCR recognition, and been able to extract text from a picture.

What I need: To identify 3 numbers (equipment, serial and part).

Problem1: There is more than these 3 numbers/words in any given picture, hence the 4th category ""N/A"".
Problem2: The numbers may contain numbers, letter and some other characters like ""-"" and ""/"".

My solution1: Word2vec. (But never used it before.)
My solution2: CNN, where every word is represented as an array with char-values.

I do have a database with previously registered numbers, hence it could be solved by table lookup, but it would be great to also recognize similar numbers for future-proofing.

Does anyone have some guidens or maybe some example code? Much appreciated!",1,2
7,2017-7-5,2017,7,5,19,6ld4hy,TensorFlow Tutorial with an interesting use-case on naval mine identifier,https://www.reddit.com/r/tensorflow/comments/6ld4hy/tensorflow_tutorial_with_an_interesting_usecase/,pooja_edureka,1499249275,,0,0
8,2017-7-6,2017,7,6,11,6lirz5,training a neural network on pairs of before and after images,https://www.reddit.com/r/tensorflow/comments/6lirz5/training_a_neural_network_on_pairs_of_before_and/,bonyfish,1499307519,"I'm interested in the possibility of training a NN on pairs of before and after images with the goal of having the NN be able to take an unseen before picture and draw/render/modify it to be an after picture.

For example, imagine before pictures of empty plates and after pictures of the same plates, from the same angles, but with different kinds of food on the plates.  Eventually the neural net should be able to take a picture of an empty plate and modify that picture such that the plate has food drawn on it.

Of course lots of tensorflow articles are for image recognition and classification problems, but those don't seem to fit this need.

I've also taken a look at generative adversarial networks (GANs) but those seem to start from images initialized by white noise and create something completely unique.  This is not quite what I'm looking for.

Any suggestions/techniques would be great to learn about.",2,1
9,2017-7-7,2017,7,7,3,6lnl6c,Different behaviour when using python for loop and tensorflow's while_loop,https://www.reddit.com/r/tensorflow/comments/6lnl6c/different_behaviour_when_using_python_for_loop/,d3fenestrator,1499364406,"So I decided to implement my own version of im2text. First version used for loop to build decoder part of the graph - I defined some fixed maximal length and put decoding part in body of function. However, this is not optimal as my output is going to have many different lengths. In order to deal with it, I decided to implement decoder using TF's while_loop. I know that there's raw_rnn, but I had some trouble with it and finally decided to go as low-level as I possibly could. 

To my surprise, first implementation ( python for ) worked much, much better, to the point of loss being around .3 on 5000th iteration, while ( pun not intended ) latter couldn't break through 2.7. 

Here's the code
while - https://pastebin.com/wjKP6yEB
for - https://pastebin.com/xmxgQM6b

I will be very grateful for help.",0,4
10,2017-7-7,2017,7,7,7,6lp8mt,Why do I have to execute dpkg -i cuda.deb and apt-get install cuda?,https://www.reddit.com/r/tensorflow/comments/6lp8mt/why_do_i_have_to_execute_dpkg_i_cudadeb_and/,spline_reticulator,1499378830,"So to install CUDA it seems like I have to do

    dpkg -i cuda.deb | apt-get update | apt-get install cuda

This seems weird to me. I thought dpkg -i is supposed to take care of the installation. Why do I have to do apt-get install afterwards. Conversely

    dpkg -i cudann.deb

seems to correctly install cudann.",1,2
11,2017-7-7,2017,7,7,10,6lqkq1,Keras: Deep Learning library for Theano and TensorFlow,https://www.reddit.com/r/tensorflow/comments/6lqkq1/keras_deep_learning_library_for_theano_and/,psangrene,1499392797,,0,0
12,2017-7-7,2017,7,7,17,6lsg02,Using a tflearn generated network,https://www.reddit.com/r/tensorflow/comments/6lsg02/using_a_tflearn_generated_network/,Master-Obvious,1499417810,So I've trained my network using image data inputted through hfd5. Now I want to use the network in day to day operation. How do I go about formatting the image into the same format that the network was trained on?,3,1
13,2017-7-7,2017,7,7,22,6ltimv,Tensorflow trolled advertisement,https://www.reddit.com/r/tensorflow/comments/6ltimv/tensorflow_trolled_advertisement/,graes11,1499432795,,0,0
14,2017-7-9,2017,7,9,9,6m4lbf,How to use load_csv_without_header with target_dtype as a String value,https://www.reddit.com/r/tensorflow/comments/6m4lbf/how_to_use_load_csv_without_header_with_target/,supamonkey2000,1499561085,"So I want to load a csv file that has no header. All the data in the csv is text. I can't figure out how to use

tf.contrib.learn.datasets.base.load_csv_without_header(filename=TRAINING,target_dtype=""""""I want this to be a string"""""",features_dtype=""""""This too"""""")

but it always throws errors. I've used *dtypes.string*, *np.string* (which doesn't exist), *tf.string*, and a bunch of casting but most of the tf.*cast thing here* need an ""x"" value.

**How can I import my csv file (with strings!)?** I don't mind using a different method.

I would also prefer if the strings could be converted to a different format (like float32, or similar. Is that possible?) and then convert them back at the end.",0,1
15,2017-7-9,2017,7,9,22,6m7eav,Output layer dimension in Keras [x-post /r/mlquestions],https://www.reddit.com/r/tensorflow/comments/6m7eav/output_layer_dimension_in_keras_xpost_rmlquestions/,Boozybrain,1499606456,"I'm using Tensorflow as the backend so I figured I would as this here too:

I'm building a simple MLP that I want to train on N timesteps of 2 samples with an embedded lag of 22 timesteps, so my input shape is (2,22,N).   The output is a scalar, so my target array is (1,N).  My ultra simple MLP is the following:

    model = Sequential()
    model.add(Dense(2,input_shape=(None,N)))
    model.add(Dense(28,activation='sigmoid'))
    model.add(Dense(1,kernel_initializer='normal'))
    model.compile(loss='mean_squared_error', optimizer='adam')
    model.fit(inputs,targets,epochs=10,validation_split=0.1,shuffle=True, verbose=1, batch_size=32)


But I keep getting an error with the output layer:

    ValueError: Error when checking model target: expected dense_3 to have 3 dimensions, but got array with shape (20000, 1)


And I'm not sure why.  My last layer is a single node, so why is it expecting a 3D target?",0,1
16,2017-7-10,2017,7,10,1,6m88en,"Unable to install Tensorflow on Ubuntu using pip - ""No matching distribution found""",https://www.reddit.com/r/tensorflow/comments/6m88en/unable_to_install_tensorflow_on_ubuntu_using_pip/,ThatOneGuyFromLondon,1499616454,"I am trying to install Tensorflow on Ubuntu 15.10, using Python pip. When running pip search for tensorflow, it shows all the correct packages, however when running pip install, I get

    No matching distribution found for tensorflow

Has anyone experienced anything similar? How do I fix it?",7,3
17,2017-7-10,2017,7,10,5,6m9use,Homography in tensorflow,https://www.reddit.com/r/tensorflow/comments/6m9use/homography_in_tensorflow/,kindoblue,1499633140,,3,2
18,2017-7-10,2017,7,10,12,6mbtv8,A comprehensive and organized collection of resources for TensorFlow,https://www.reddit.com/r/tensorflow/comments/6mbtv8/a_comprehensive_and_organized_collection_of/,irsina,1499655640,,0,7
19,2017-7-10,2017,7,10,13,6mcba8,Can one operation be called by the other operation in C++ level?,https://www.reddit.com/r/tensorflow/comments/6mcba8/can_one_operation_be_called_by_the_other/,anericanohuang,1499661912,"I am now trying to build a custom operation in c++ level that may need matrix multiplication , matrix concatenation...etc. I found it difficult to write from scratch(maybe I am newbie...so I couldn't). Is it possible to call matmul operation inside my custom operation?

Thanks...

",0,1
20,2017-7-10,2017,7,10,22,6mehya,Networks are like onions: Practical Deep Learning with TensorFlow,https://www.reddit.com/r/tensorflow/comments/6mehya/networks_are_like_onions_practical_deep_learning/,gretayld,1499693976,,0,1
21,2017-7-11,2017,7,11,13,6mjtxw,Convolutional Neural Net Classifier: how to ignore labels from loss function?,https://www.reddit.com/r/tensorflow/comments/6mjtxw/convolutional_neural_net_classifier_how_to_ignore/,ThiagoOR,1499745906,"I want to classify images in ""Buy"", ""Sell"" or ""Do nothing"", like this:
[1,0] -&gt; Buy
[0,1] -&gt; Sell
[0,0] -&gt; Do nothing

My train data contains just [1,0] and [0,1] labels. So, my CNN needs to learn something like this:

If my train label is [0,1], and the CNN predict [0,1] -&gt; excellent!
If my train label is [0,1], and the CNN predict [1,0] -&gt; bad!
If my train label is [0,1], and the CNN predict [0,0] -&gt; good! (or don't contabilize in the loss function)

How can I do this in tensorflow?

Thanks for your attention.",0,1
22,2017-7-11,2017,7,11,13,6mk2ys,How to use TensorFlow transfer learning to create an image classifications engine,https://www.reddit.com/r/tensorflow/comments/6mk2ys/how_to_use_tensorflow_transfer_learning_to_create/,davidhung,1499749106,,0,5
23,2017-7-11,2017,7,11,17,6mkulm,Newbie here! Need a bit of help in deciding wether to install the CPU or the GPU version,https://www.reddit.com/r/tensorflow/comments/6mkulm/newbie_here_need_a_bit_of_help_in_deciding_wether/,vallsin,1499760564,So i'm very new to the machine learning and deep learning field and i only recently have been thinking of using tensorflow. Now i have a i7 6700hq processor @2.60hz and a 960m Nvidia graphic card with 4GB Memory. I'm confused whether i should install the Gpu version or the cpu version and which one would ensure faster training times in my case?  ,2,2
24,2017-7-11,2017,7,11,23,6mmec6,stupid question but how do I index tensors in tensorflow?,https://www.reddit.com/r/tensorflow/comments/6mmec6/stupid_question_but_how_do_i_index_tensors_in/,[deleted],1499781788,[deleted],1,0
25,2017-7-12,2017,7,12,3,6mo0x9,Options for distributing Tensorflow computation across multiple EC2 instances?,https://www.reddit.com/r/tensorflow/comments/6mo0x9/options_for_distributing_tensorflow_computation/,spline_reticulator,1499796527,"Has anyone worked on this before? I've seen allusions to this in [TensorflowOnSpark](https://github.com/yahoo/TensorFlowOnSpark), [Distributed Tensorflow](https://www.tensorflow.org/deploy/distributed), and [Kubernetes](https://medium.com/intuitionmachine/kubernetes-gpus-tensorflow-8696232862ca). From the examples out there I'm having some trouble comparing the functionality of these different options. Does anyone have any thoughts on the issue?",3,1
26,2017-7-12,2017,7,12,6,6mpga6,Google's plan to best Amazon rests on one piece of software,https://www.reddit.com/r/tensorflow/comments/6mpga6/googles_plan_to_best_amazon_rests_on_one_piece_of/,Rugby11,1499809260,,0,3
27,2017-7-12,2017,7,12,10,6mqv43,"""Convolutional Neural Networks"" naming",https://www.reddit.com/r/tensorflow/comments/6mqv43/convolutional_neural_networks_naming/,[deleted],1499824157,[deleted],2,0
28,2017-7-13,2017,7,13,11,6mytnp,What does 'Moving Average' do when training a neural network? and difference between using Moving Average and Batch normalization during the training.,https://www.reddit.com/r/tensorflow/comments/6mytnp/what_does_moving_average_do_when_training_a/,nlkim00,1499913558,"I have started the tensorflow based on the object detection API. In their code, the Moving Average is operated with the optimizer parts.  

https://github.com/tensorflow/models/blob/master/object_detection/builders/optimizer_builder.py#L24-L66

I am wonder the main role of 'Moving Average'. I think that it is a process that updates the weight in stably from the noisy minibatch.

But it's not clear to me that what is the difference between ""using moving average process"" and ""using batch normalization"".

Very Thanks 
",2,5
29,2017-7-13,2017,7,13,13,6mzem4,Tensorflow and Blender - General advice with inputs &amp; specific cases like this,https://www.reddit.com/r/tensorflow/comments/6mzem4/tensorflow_and_blender_general_advice_with_inputs/,Beazlebubba,1499920598,"Hello - I've been working on an animation project in blender for some time, and would like to use ML and specifically Tensorflow to help automate animation tasks, and general research/ fiddling.  Blender already uses python, and the marriage seems right for many applications.  There are also data sets that are readily available for research.  Instead of having a network teach itself to walk.  It's like to approach it by using motion capture libraries like Carnegie Mellon's to train and apply it to any other character rig in my show.  I'd like to apply something like [this research](https://www.youtube.com/watch?v=Ul0Gilv5wvY).  It would also be great to use OpenCV or just audio as in this [recent UW example with Obama] (https://www.youtube.com/watch?v=MVBe6_o4cMI) to lip sync my character models.

My general question is how to best set up inputs such as armature position, and character mesh along with audio/ video data  and pack it into tensors that tensorflow can use.  Thanks for reading if you made it this far.",2,6
30,2017-7-14,2017,7,14,4,6n3tb0,Tensorflow crashes with ValueError at the end of the first training step,https://www.reddit.com/r/tensorflow/comments/6n3tb0/tensorflow_crashes_with_valueerror_at_the_end_of/,supamonkey2000,1499973106,"My GitHub for the code: github.com/supamonkey2000/jm-uofa   . The project folder is imgpredict.

Hello. I am building my own Tensorflow program to detect what animal is in an image. I am using my own dataset of around 1200 images (although this will hugely increase in the future). I can successfully load and train against every image.

My problem is at the very end of the training For loop, specifically at ""sess.run(train_step....)"" command. For some reason it can't get past the very first training step without giving me this error at the end:

ValueError: Cannot feed value of shape (1,) for Tensor 'Placeholder_1:0', which has shape '(?, 1)'

Does anyone know why this error is showing up? Feel free to run my code, but be aware the GitHub download is ~450 Megabytes.

Thanks in advance!",1,2
31,2017-7-15,2017,7,15,6,6nbvom,TensorFlow Tutorial For Beginners,https://www.reddit.com/r/tensorflow/comments/6nbvom/tensorflow_tutorial_for_beginners/,gcdes,1500066194,,0,15
32,2017-7-15,2017,7,15,9,6ncv96,"We just released TensorPort, a user friendly cloud platform for TensorFlow, enjoy!",https://www.reddit.com/r/tensorflow/comments/6ncv96/we_just_released_tensorport_a_user_friendly_cloud/,GoodAILab,1500077136,,0,6
33,2017-7-15,2017,7,15,13,6ne5qo,Lip Reading - Cross Audio-Visual Recognition using 3D Convolutional Neural Networks,https://www.reddit.com/r/tensorflow/comments/6ne5qo/lip_reading_cross_audiovisual_recognition_using/,irsina,1500094320,,0,1
34,2017-7-16,2017,7,16,3,6nhlzd,Visualizing large graphs in tensorboard,https://www.reddit.com/r/tensorflow/comments/6nhlzd/visualizing_large_graphs_in_tensorboard/,tartavull,1500144648,,3,1
35,2017-7-16,2017,7,16,4,6nhu4a,Unique tf.Sessions for each instantiation of a TF based class,https://www.reddit.com/r/tensorflow/comments/6nhu4a/unique_tfsessions_for_each_instantiation_of_a_tf/,Greendogo,1500147067,"I have a question which I posted last night on Stack Overflow.  If anyone has any ideas about how to solve my issue, let me know!
Link:
https://stackoverflow.com/questions/45113950/tensorflow-tracker-class-crashing-when-creating-second-instantiation-sessions",0,1
36,2017-7-17,2017,7,17,12,6nqpkt,Reusing weights like in Caffe?,https://www.reddit.com/r/tensorflow/comments/6nqpkt/reusing_weights_like_in_caffe/,bourbondog,1500263284,"I'm trying to reuse weights from an already existing model but it seems like it's not really possible.

Caffe simply copies over the weights for whatever layers exist in the protoxt and the caffemodel file.

With tensorflow, the saver.Restore expects every single variable to exist in the checkpoint - this isn't possible when trying to use a pre-trained network + minor tweaks of your own. is it possible to:

- Specify which nodes to load (just like in saver.save)
- Load an existing graph and remove certain nodes (I can easily add them - removing nodes seems to be hard?)",2,3
37,2017-7-18,2017,7,18,1,6nu8zh,Which nvidia drivers should I use for an EC2 p2.xlarge instance to run CUDA and Tensorflow?,https://www.reddit.com/r/tensorflow/comments/6nu8zh/which_nvidia_drivers_should_i_use_for_an_ec2/,spline_reticulator,1500309704,,6,7
38,2017-7-18,2017,7,18,23,6o136w,Seq2seq prediction of temperature,https://www.reddit.com/r/tensorflow/comments/6o136w/seq2seq_prediction_of_temperature/,fabian_fabian,1500388029,"Does anyone have a good example on how to predict a series of numeric values (e.g. temperature) pased on a sequence of other values like current, outside temperature etc.?

",1,5
39,2017-7-20,2017,7,20,11,6odj1i,Need help with saving tensorflow checkpoints,https://www.reddit.com/r/tensorflow/comments/6odj1i/need_help_with_saving_tensorflow_checkpoints/,matwhet,1500519383,"Helloo.. I'm currently working on a convolutional neural network that trains on batches of images.

But during each iteration where the model saves a checkpoint, an error randomly occurs sometimes on the fourth iteration sometimes on the 2nd iteration.

The stack is 

Unknown error: Failed to rename: 

C:\Users\(name)\Desktop\neuralnet\checkpoints\checkpoint.tmpdc(random string of letters and numbers) 

To

C:\Users\(name)\Desktop\neuralnet\checkpoints\checkpoint

Access denied

input/output error


I have already checked the permission/security for the folder, but it's all owned by me so I'm not sure why this error keeps randomly popping out and stopping the training altogether.

Any help is greatly appreciated. ",0,3
40,2017-7-20,2017,7,20,20,6ofqpj,Issue with Rank 4 and feed_dict,https://www.reddit.com/r/tensorflow/comments/6ofqpj/issue_with_rank_4_and_feed_dict/,Goliath2,1500551705,"Here is my placeholder:
X = tf.placeholder(""float"", shape=(1, 1, 1, 5),  name=""data"") 

here is the feed_dict:
feed_dict= {X: [ [1], [1], np.array([[nest[epoch], tree[epoch], veg[epoch], longitude[epoch], lat[epoch]]]), [1]] , Y: occupancy[epoch]})

However it is throwing this error, even when move position of the np.array in the feed, or the 5 within the shape of the placeholder:

ValueError: could not broadcast input array from shape (5) into shape (1)

Bit of background:
Trying to make convolutional network from raw data rather than an image. 
Any help would be appreciated, thanks :)",2,0
41,2017-7-22,2017,7,22,4,6oqfcj,Is there a method to check if a certain attribute is in tf.hparams?,https://www.reddit.com/r/tensorflow/comments/6oqfcj/is_there_a_method_to_check_if_a_certain_attribute/,[deleted],1500667197,[deleted],0,1
42,2017-7-23,2017,7,23,1,6ovyv4,"[Noob] I installed both the pip and conda versions of tensorflow, do I now have two copies on my machine?",https://www.reddit.com/r/tensorflow/comments/6ovyv4/noob_i_installed_both_the_pip_and_conda_versions/,linkuei-teaparty,1500741848,"I'm new to machine learning and ended up installing tensorflow through pip first, then installed anaconda and installed it again through conda. Will I now have two versions of tensor flow? How do I check and how should I clean it up?",6,7
43,2017-7-24,2017,7,24,15,6p6r9f,Is Google Tensorflow Object Detection API the easiest way to implement image recognition?,https://www.reddit.com/r/tensorflow/comments/6p6r9f/is_google_tensorflow_object_detection_api_the/,pandasareblank,1500879368,,0,1
44,2017-7-24,2017,7,24,22,6p88o2,unsupervised text clustering using deep learning Tensor flow. what is the best approach?,https://www.reddit.com/r/tensorflow/comments/6p88o2/unsupervised_text_clustering_using_deep_learning/,amit_unix,1500901581,"unsupervised text clustering using deep learning  Tensor flow. what is the best approach? lets say i have 5000 plain questions and answers. i want to do unsupervised text clustering, so that if some one asks the new question,it should tell the right cluster to refer",1,1
45,2017-7-25,2017,7,25,6,6pbgmb,Lost with trying to understand how TensorFlow receives and processes input,https://www.reddit.com/r/tensorflow/comments/6pbgmb/lost_with_trying_to_understand_how_tensorflow/,JustinQueeber,1500930984,"I have recently begun studying Deep Learning and Neural Networks. I am confident in my understanding of the theory of RNNs - I have even coded my own very simple one from scratch.

However, I am now trying to become familiar with the TensorFlow API in order to implement my future NNs with it. Although I am confident with the theory behind NNs, I am struggling to grasp the intricacies of TensorFlow and what it does behind the scenes.

As my first project in Tensorflow I am attempting to write a RNN which takes fixed length ascending or descending sequences as inputs, and then classifies each as either ascending or descending. This is the code I have written until I reached my first error:

    from __future__ import print_function
    import tensorflow as tf
    import random

    numSequences = 10000
    sequenceLength = 5
    maxNumber = 100
    hiddenDimension = 16
    numClasses = 2

    def generate_data():
        data, labels = [], []
        for _ in range(numSequences):
            type = (0 if random.random() &lt; 0.5 else 1)
            temp = []
            if type == 0:
                labels.append([1, 0])
                temp.append(random.randint(0, maxNumber - sequenceLength + 1))
                for i in range(1, sequenceLength):
                    temp.append(random.randint(temp[i - 1] + 1, maxNumber - sequenceLength + i + 1))
            if type == 1:
                labels.append([0, 1])
                temp.append(random.randint(0 + sequenceLength - 1, maxNumber))
                for i in range(1, sequenceLength):
                    temp.append(random.randint(0 + sequenceLength - i - 1, temp[i - 1] - 1))
            data.append(temp)
        return data, labels

    x = tf.placeholder(tf.int32, [None, sequenceLength])
    y = tf.placeholder(tf.int32, [None, numClasses])

    W = tf.Variable(tf.random_normal([sequenceLength, numClasses]))
    b = tf.Variable(tf.random_normal([numClasses]))

    RNNCell = tf.contrib.rnn.BasicRNNCell(hiddenDimension)
    outputs, states = tf.contrib.rnn.static_rnn(RNNCell, x, dtype=tf.int32)

The input is a list of lists/sequnces of integers such as `[[1, 2, 3], [9, 8, 7]]` and the labels/outputs will be one-hot vectors of length 2 with the a 1 as the first digit corresponding to the input sequence being ascending, and the second being descending. 

Here are some queries I have:

1. Is the one-hot vector necessary? I have seen plenty of examples that use them, but if there are only 2 output possibilities, can I just output a single 1x1 tensor of 0 (descending) or 1 (ascending)?

2. Are my dimensions for the `x` and `y` placeholders ok? My input tensor will just be a single column vector, each row corresponding to each element of the sequence, and the output another column vector of length 2 (the one-hot vector)

3. This code is giving an error at the last line stating that the inputs to the `static_RNN` must be sequences - how is my `sequenceLength x 1` tensor not a sequence, and what shape does it need to be in order to be considered a sequence?

4. In all the theoretical explanations of RNNs, as well as coded examples (and the first RNN I coded) without using TensorFlow, there are 3 (or more depending on the amount of layers) weighted matrices - one transforming the input into the hidden state, one transforming the hidden state to output, and one transforming the hidden state from one time step into the next. Why is it that any RNN example using TensorFlow only has one of these matrices defined? And have I defined the correct one above (`sequenceLength x numClasses`)?

5. I haven't come to it yet, but I have seen examples of the training loop such as the one below. I understand this code as:

* each loop of in `range(num_epochs)` is one full forward and back propagation of the training data - so these loops are repeatedly training the network on the same dataset
* Each batch is some subset of the training data. After each, the variables are tuned in order to reduce the loss. So if we were to use my ascending/descending sequences example: say there are 10,000 sequences in the training data and 10 batches, this loop would iterate over 1,000 sequences, then adjust the variables, and repeat 10 times, each on a different 1,000 sequences, for each epoch.

Does all of this seem correct, or am I misunderstanding anything?

    for epoch_idx in range(num_epochs):
    x,y = generateData()
    _current_state = np.zeros((batch_size, state_size))

    print(""New data, epoch"", epoch_idx)

        for batch_idx in range(num_batches):
            start_idx = batch_idx * truncated_backprop_length
            end_idx = start_idx + truncated_backprop_length

            batchX = x[:,start_idx:end_idx]
            batchY = y[:,start_idx:end_idx]

            _total_loss, _train_step, _current_state, _predictions_series = sess.run(
                [total_loss, train_step, current_state, predictions_series],
                feed_dict={
                    batchX_placeholder:batchX,
                    batchY_placeholder:batchY,
                    init_state:_current_state
                })

            loss_list.append(_total_loss)

            if batch_idx%100 == 0:
                print(""Step"",batch_idx, ""Loss"", _total_loss)
                plot(loss_list, _predictions_series, batchX, batchY)

",3,6
46,2017-7-26,2017,7,26,21,6pnn2p,[Noob] Tensorflow: get accuracy of graph prediction.,https://www.reddit.com/r/tensorflow/comments/6pnn2p/noob_tensorflow_get_accuracy_of_graph_prediction/,SanatDutta,1501071494,"Hi guys,

I'm following [this](https://github.com/dennybritz/cnn-text-classification-tf/) project.

It uses CNNs for text classification. It's working good but it only does prediction but does not output the prediction accuracy.

The developer used Tensorflow graph model for predictions

    predictions = graph.get_operation_by_name(""output/predictions"").outputs[0]
    batches = data_helpers.batch_iter(list(x_test), FLAGS.batch_size, 1, shuffle=False)
    all_predictions = []
    for x_test_batch in batches:
        batch_predictions = sess.run(predictions, {input_x: x_test_batch, dropout_keep_prob: 1.0})
        all_predictions = np.concatenate([all_predictions, batch_predictions])

This only does prediction but does not show prediction accuracy.",2,1
47,2017-7-27,2017,7,27,6,6pr58s,Taking derivative of Keras model wrt to inputs is returning all zeros,https://www.reddit.com/r/tensorflow/comments/6pr58s/taking_derivative_of_keras_model_wrt_to_inputs_is/,spline_reticulator,1501103363,https://stackoverflow.com/questions/45337371/taking-derivative-of-keras-model-wrt-to-inputs-is-returning-all-zeros,0,2
48,2017-7-27,2017,7,27,10,6pspoo,Simplifying pretrained Inception v3 model,https://www.reddit.com/r/tensorflow/comments/6pspoo/simplifying_pretrained_inception_v3_model/,MountairAir,1501119032,Is there a way to remove many of the pretrained categories in order to speed up computations for a more narrow use case? Or am I better off building my own?,2,2
49,2017-7-27,2017,7,27,22,6pvss8,[Noob] Direction to train from a queue,https://www.reddit.com/r/tensorflow/comments/6pvss8/noob_direction_to_train_from_a_queue/,tapoo,1501160958,"Hi,

I'm looking for a way to train my model by using a constant stream of data (kafaka).

Situation:
System A is a system that generates images and their labels and pushes the result as a json on a queue.
System B (Tensorflow) would listen to the queue and pick up the image + their label as they come in. It's not a batch, but they could be accumulated as a batch.

Specification:
I don't want the image size to be fixed. 
The JSON would contain the array of bytes, the size of the img (ex 16x16) and the actual label within the image.

What direction would you guy take to build the training architecture.

It's my first project using tensorflow, so any example is more than welcome.

Thanks
",0,1
50,2017-7-28,2017,7,28,2,6pxjff,[Noob] Tensorflow NN prediction isn't working,https://www.reddit.com/r/tensorflow/comments/6pxjff/noob_tensorflow_nn_prediction_isnt_working/,synetic707,1501176733,"I'm using the Zoo Animal Classification dataset provided by UCI Machine Learning on Kaggle to classify animals given 17 features. Even though my code doesn't give any errors and therefore runs, it fails to predict Animals.. Can anyone take a quick look at it?
I published it on Kaggle

https://www.kaggle.com/syneic707/predicting-animals-with-tensorflow/  
 
result:

    
    Training the model...
    Epoch 100 | Loss: 7.54446
    Epoch 200 | Loss: 5.69088
    Epoch 300 | Loss: 5.28574
    Epoch 400 | Loss: 5.16394
    Epoch 500 | Loss: 5.08839
    Epoch 600 | Loss: 5.03129
    Epoch 700 | Loss: 4.98246
    Epoch 800 | Loss: 4.93903
    Epoch 900 | Loss: 4.90002
    Epoch 1000 | Loss: 4.86421
    Epoch 1100 | Loss: 4.83435
    Epoch 1200 | Loss: 4.80722
    Epoch 1300 | Loss: 4.78233
    Epoch 1400 | Loss: 4.75914
    Epoch 1500 | Loss: 4.73704
    
    Trying to predict Buffolo (Index 6) ...

    [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
       0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
       0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
       0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
       0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
       0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]    
Thank you",8,1
51,2017-7-28,2017,7,28,3,6pxtve,Seq2seq for NLP: encoder-decoder framework for Tensorflow,https://www.reddit.com/r/tensorflow/comments/6pxtve/seq2seq_for_nlp_encoderdecoder_framework_for/,psangrene,1501179193,,0,2
52,2017-7-28,2017,7,28,22,6q3mrd,I wrote code for feed forward NN in tensorflow but the network is not predicting class correctly. Rather all the predictions are for same class (for test data and training data both). Can someone please help in cross verifying if the code is correct or not?,https://www.reddit.com/r/tensorflow/comments/6q3mrd/i_wrote_code_for_feed_forward_nn_in_tensorflow/,mayankj08,1501246910,,0,2
53,2017-7-29,2017,7,29,1,6q4rnl,Cost function always returns 1. What can I do?,https://www.reddit.com/r/tensorflow/comments/6q4rnl/cost_function_always_returns_1_what_can_i_do/,KayJersch,1501257877,"I have a problem with which I wrestle since months but can't fix. 
This is the code I wrote:
    import tensorflow as tf
    import numpy as np
    import matplotlib.image as mpimg
    import glob

    x = []
    y = []

    for filename in glob.glob('trainig_data/*.jpg'):
        im = mpimg.imread(filename)
        x.append(im)
        y.append(1)
        if len(x) == 20:
            break

    x_p = tf.placeholder(tf.uint8)
    y_p = tf.placeholder(tf.float32)

    epochs = 5
    batch_size = 5

    weights = [tf.Variable(tf.random_normal([5,5,3,32],0.1)),
               tf.Variable(tf.random_normal([5,5,32,64],0.1)),
               tf.Variable(tf.random_normal([5,5,64,128],0.1)),
               tf.Variable(tf.random_normal([75*75*128,1064],0.1)),
               tf.Variable(tf.random_normal([1064,1],0.1))]

    def CNN(x, weights):
        output = tf.nn.conv2d(x, weights[0], [1,1,1,1], 'SAME')
        output = tf.nn.relu(output)
        output = tf.nn.conv2d(output, weights[1], [1,2,2,1], 'SAME')
        output = tf.nn.relu(output)
        output = tf.nn.conv2d(output, weights[2], [1,2,2,1], 'SAME')
        output = tf.nn.relu(output)
        output = tf.reshape(output, [-1,75*75*128])
        output = tf.matmul(output, weights[3])
        output = tf.nn.relu(output)
        output = tf.matmul(output, weights[4])
        output = tf.reduce_sum(output)
        return output

    sess = tf.Session()
    prediction = CNN(tf.cast(x_p, tf.float32), weights)
    cost = tf.square(tf.reduce_mean(prediction-y_p))
    train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)
    init = tf.global_variables_initializer()

    sess.run(init)

    for e in range(epochs):
        print('epoch:', e+1)
        for i in range(int(len(x)/batch_size)):
            start = i*batch_size
            end = start+batch_size
            batch_x = x[start:end]
            batch_y = y[start:end]
            _, c = sess.run([train,cost],feed_dict={x_p:batch_x,
                                                     y_p:batch_y})
            print('batch loss:', c)

And this is the unwanted output:
    epoch: 1

    batch loss: 2.09739e+29

    batch loss: 1.0

    batch loss: 1.0

    batch loss: 1.0

    epoch: 2

    batch loss: 1.0

    batch loss: 1.0

    batch loss: 1.0

    batch loss: 1.0

    epoch: 3

    batch loss: 1.0

    batch loss: 1.0

    batch loss: 1.0

    batch loss: 1.0

    epoch: 4

    batch loss: 1.0

    batch loss: 1.0

    batch loss: 1.0

    batch loss: 1.0

    epoch: 5

    batch loss: 1.0

    batch loss: 1.0

    batch loss: 1.0

    batch loss: 1.0

Can anyone tell me how to solve this problem?

PS. Yes I did ask on Stackoverflow... twice",1,2
54,2017-7-29,2017,7,29,22,6qaucy,FaceRank - Rank Face by CNN Model based on TensorFlow,https://www.reddit.com/r/tensorflow/comments/6qaucy/facerank_rank_face_by_cnn_model_based_on/,fendouai,1501333312,"Privacy

Because of privacythe training images dataset is not provided. maybe some carton images will be given later.

Dataset

130 pictures with size 128*128 from web with tag image: 1-3.jpg means rank 1,3st train pic you can add your own pics to the resize_images folder
Model

Model is CNN based on TensorFlow based on : https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/convolutional_network.py

Run

After you installed TensorFlow ,just run train_model.py.

train the model
save the model to model dir
Test

After you run the train_model.py ,just run the run_model.py to test.

Download

The model is trained can be download at http://www.tensorflownews.com/

github:https://github.com/fendouai/FaceRank",2,5
55,2017-7-31,2017,7,31,22,6qo9pz,I made an overview of the changes in Tensorflow version 1.3,https://www.reddit.com/r/tensorflow/comments/6qo9pz/i_made_an_overview_of_the_changes_in_tensorflow/,Dutchcheesehead,1501506262,,1,4
56,2017-7-31,2017,7,31,22,6qoefb,Time difference between dual core cpu and 10 series gpu,https://www.reddit.com/r/tensorflow/comments/6qoefb/time_difference_between_dual_core_cpu_and_10/,angularion,1501507707,"I was looking to buy a new laptop and prefer something portable. So XPS 13 and 15 are the 2 I am looking at. 

I just started learning tensorflow and found that it has gpu support. So what machine would u prefer for a beginner?
An XPS 15 with GTX 1050 4gb ddr5 or the XPS 13 would do just fine?",2,2
0,2017-8-1,2017,8,1,14,6qu496,TF code for computing smith normal form?,https://www.reddit.com/r/tensorflow/comments/6qu496/tf_code_for_computing_smith_normal_form/,quietearthus,1501564106,"Is there any tensorflow code available to compute the smith normal form? I am running some topological computations but computing a 10kx10k matrix on a cpu is not really feasible with a ton of graphs.

Thanks!",1,1
1,2017-8-1,2017,8,1,23,6qwj9n,Any alternative for tf.split(),https://www.reddit.com/r/tensorflow/comments/6qwj9n/any_alternative_for_tfsplit/,manselta,1501597356,"Hi, would you know any alternative to tf.split() that wouldn't force me to use the num parameter.

The idea is tu use dynamic Tensors. However, split doesn't accept dynamic Tensors. It needs to know the input and output shapes.",1,1
2,2017-8-2,2017,8,2,6,6qzayl,k-fold cross validation in TensorFlow?,https://www.reddit.com/r/tensorflow/comments/6qzayl/kfold_cross_validation_in_tensorflow/,MKazemHN,1501621710,I was wondering if there are any implementations of k-fold cross validation in TensorFlow that I could get my hands on or any suggestions on how to implement it in python.,2,2
3,2017-8-2,2017,8,2,18,6r35kb,"Enoying ""unknown error"" from hell, what's the cause of those warning(?) messages?",https://www.reddit.com/r/tensorflow/comments/6r35kb/enoying_unknown_error_from_hell_whats_the_cause/,swentso,1501667954,"Hi,  I'm getting plenty of enoying ""unknown error"" messages while training my model, that don't seem to have an actual impact apart from being annoying.
The model is [endernewton's](https://github.com/endernewton/tf-faster-rcnn). I might have done some changes to the scripts, but not the model

So, where the hell does this error come from? I found no doc on this on the internet apart from [this useless page](https://www.tensorflow.org/api_docs/python/tf/errors/UnknownError) in TF doc.


    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    iter: 10 / 1000, total loss: 15.886613
    >>> rpn_loss_cls: 1.009092
    >>> rpn_loss_box: 2.369402
    >>> loss_cls: 0.812885
    >>> loss_box: 11.695234
    >>> lr: 0.000100
    speed: 43.938s / iter  |  batch_time: 223.758659124
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
    unknown error
",1,0
4,2017-8-3,2017,8,3,2,6r5vhs,Feeding SSD Mobilenet with high resolution images?,https://www.reddit.com/r/tensorflow/comments/6r5vhs/feeding_ssd_mobilenet_with_high_resolution_images/,josealb,1501695657,"I'm trying to detect small objects in high resolution images. The problem is when I feed these images into an pre trained imagenet model from the Object Detection API the training is very slow and the process ends up getting killed.

What is the best workaround for this? Is there any network that natively works with high resolution images? Should I split the images?",3,2
5,2017-8-3,2017,8,3,5,6r6xjt,AttributeError: module 'tensorflow.contrib.seq2seq' has no attribute 'prepare_attention' Error,https://www.reddit.com/r/tensorflow/comments/6r6xjt/attributeerror_module_tensorflowcontribseq2seq/,katanablade99,1501704490,"Completely new to tensorflow and was looking at guides for chatbots. While building the graph training I keep getting this error.
I not sure what it is referring and looking online only tells me some part of my code is no longer available in tensorflow anymore 

Thanks for the help ",0,0
6,2017-8-3,2017,8,3,13,6ra13j,Online Training Certification,https://www.reddit.com/r/tensorflow/comments/6ra13j/online_training_certification/,arogyalokesh,1501735386,,0,1
7,2017-8-3,2017,8,3,19,6rbcxv,Why is tf.gradients returning [None],https://www.reddit.com/r/tensorflow/comments/6rbcxv/why_is_tfgradients_returning_none/,KayJersch,1501755620,"I'm trying to make my own deep dream algorithm with this code:
    import tensorflow as tf
    import matplotlib.pyplot as plt
    import numpy as np
    import inception
    
    img = tf.Variable(tf.random_normal([1,1920,1080,3]))
    
    net = inception.get_inception_model()
    tf.import_graph_def(net['graph_def'], name='inception')
    graph = tf.get_default_graph()
    sess = tf.Session()
    layer = graph.get_tensor_by_name('inception/softmax2:0')
    gradient = tf.gradients(tf.reduce_mean(layer), img)
    softmax =     sess.graph.get_tensor_by_name('inception/softmax2:0')
    iters = 1440
    init = tf.global_variables_initializer()
    
    sess.run(init)
    for i in range(iters):
        print(i+1)
        prediction = sess.run(softmax, \
                              {'inception/input:0': sess.run(img)})
        grad = sess.run(gradient[0])
        img += grad
        plt.imshow(sess.run(img[0]))
        plt.savefig('output/'+str(i+1)+'.png')
        plt.close('all')
But the tf.gradients function is just returning [None]. How do I fix this bug?

PS. I am using the Inception helper function by Parag K Mital https://github.com/pkmital/CADL/blob/master/session-4/libs/inception.py",2,4
8,2017-8-5,2017,8,5,2,6rm0ga,Trouble with 1 hidden layer neural net with L2 regularization,https://www.reddit.com/r/tensorflow/comments/6rm0ga/trouble_with_1_hidden_layer_neural_net_with_l2/,missingJacket,1501867482,"Hey guys! I'm fairly new to Tensorflow and machine learning and am looking for some help with my program.

Right now, I'm trying to make a basic neural network with one hidden layer, and compare its accuracy before and after L2 reg. I'm feeding pseudo-random data into the network. The network seems to be converging slowly both with and without l2 reg. Furthermore, the loss change to nan when I add a second hidden layer.

Here is my code https://github.com/BreeCat10/L2Regularizatiom/blob/master/L2Testing.py

Thanks so much for any advice!",7,3
9,2017-8-6,2017,8,6,1,6rsslo,Why is normal Gradient Descent running faster than Mini Batch on MNIST?,https://www.reddit.com/r/tensorflow/comments/6rsslo/why_is_normal_gradient_descent_running_faster/,missingJacket,1501951681,"I'm fairly new to machine learning and need help figuring this out. It could be a coding mistake or my own misunderstanding. I'm comparing normal gradient descent to mini batch gradient descent on MNIST. It seems that my gradient descent program is running faster and is less accurate, while my mini batch is slower and more accurate. Isn't this supposed to be the other way around? I'm using all of MNIST to train.

Here's each of them
https://github.com/BreeCat10/TensorflowProjects/blob/master/MiniBatchGD
https://github.com/BreeCat10/TensorflowProjects/blob/master/GD

I might just be confused on what the two are or how to implement each. Hopefully someone can peek at my code and give me some insight. Thank you for any feedback!",4,1
10,2017-8-6,2017,8,6,2,6rt6p5,Let's say you could split a tensorflow graph across an unlimited amount of GPUs what practical application would use this for?,https://www.reddit.com/r/tensorflow/comments/6rt6p5/lets_say_you_could_split_a_tensorflow_graph/,spline_reticulator,1501955686,,1,3
11,2017-8-6,2017,8,6,7,6ruuga,How can you implement closed loop feedback in a network?,https://www.reddit.com/r/tensorflow/comments/6ruuga/how_can_you_implement_closed_loop_feedback_in_a/,Arisngr,1501973415,"I want to play with closed loop networks (e.g. where layer 2 feeds into layer 1, and the next activation of layer 1 is influenced by both layer 2 at t-1 and some external input). I haven't found a simple way to do this (and am admittedly completely new to tensorflow). Any help would be greatly appreciated!",3,2
12,2017-8-8,2017,8,8,15,6sbmil,Accessing data from tf.string inside custom op,https://www.reddit.com/r/tensorflow/comments/6sbmil/accessing_data_from_tfstring_inside_custom_op/,bro224,1502172480,,0,3
13,2017-8-9,2017,8,9,9,6shyhp,Is it possible to feed back estimations as training?,https://www.reddit.com/r/tensorflow/comments/6shyhp/is_it_possible_to_feed_back_estimations_as/,th4tgen,1502239722,"I've got a small untagged dataset that I want to manually verify estimations on and feed it back as training, is there any way to do this?",0,1
14,2017-8-9,2017,8,9,15,6sjrxk,Who uses TensorFlow Serving in production?,https://www.reddit.com/r/tensorflow/comments/6sjrxk/who_uses_tensorflow_serving_in_production/,rabotai,1502261729,I made a quick search and only ZenDesk surfaced (https://medium.com/zendesk-engineering/how-zendesk-serves-tensorflow-models-in-production-751ee22f0f4b). Does anybody know something about other companies?,0,5
15,2017-8-10,2017,8,10,9,6spuhq,Issue installing TensorFlow on Raspberry Pi. Link is to the guide I'm following,https://www.reddit.com/r/tensorflow/comments/6spuhq/issue_installing_tensorflow_on_raspberry_pi_link/,phblue,1502325960,,3,3
16,2017-8-11,2017,8,11,23,6t1d03,Can't install for my life...,https://www.reddit.com/r/tensorflow/comments/6t1d03/cant_install_for_my_life/,Tally914,1502460387,"On a couple of separate occasions I've tried to install tensorflow-gpu and can't get get it running.

I've tried video tutorials and online instructions (including the official ones) but I have to be missing something. 

Here's what I've done:

Installed Visual Studio 2017 and all of the C++ compilers that come with it.

Install cudnn folder to my C drive and add it's bin to my path variable.

I have a 1080ti that had updated drivers going in to all of this.

Installed in Anaconda using pip ignore installed upgrade command. Did this for both tensorflow-gpu and tensorflow-gpu. 

CUDA toolkit 8.0 - I'm convinced this is where the error is. I install the relevant path variables, but the below is going wrong.

First, it says that it can not detect the device with it's drivers during installation. Then after that it says it can't detect VS, even though it was just installed. Finally, after it's installed, the CUDA folder disappears. 

Does anyone else have this problem? How is it solved?

The above leaves me with cpu version working fine and gpu version completely not detected. I just get a 'no module' when I disable the CPU version and no GPU detected when I don't.",2,10
17,2017-8-13,2017,8,13,15,6tdme0,What's the time complexity of tf.concat?,https://www.reddit.com/r/tensorflow/comments/6tdme0/whats_the_time_complexity_of_tfconcat/,fuckinghelldad,1502605052,,0,3
18,2017-8-13,2017,8,13,21,6texli,ValueError: setting an array element with a sequence.,https://www.reddit.com/r/tensorflow/comments/6texli/valueerror_setting_an_array_element_with_a/,KayJersch,1502628476,"I have tried to make a generative adversarial network and stumbled over a really annoying error.
Here's my code (And yes I know it's really far from perfect):

    import tensorflow as tf
    import numpy as np
    import matplotlib.image as mpimg
    import glob
    import montage

    d_epochs = 10
    g_epochs = 10

    x = tf.placeholder(tf.float32)
    y = tf.placeholder(tf.float32)

    batch_size = 9

    x_train = []
    y_train = []

    for filename in glob.glob('trainig_data/*.jpg'):
        im = mpimg.imread(filename)
        x_train.append(im)
        y_train.append(1.0)

    gen_seed = np.random.rand(396)

    g_input = 1
    g_hidden1 = 100
    g_hidden2 = 100
    g_hidden3 = 300
    
    g_weights = [tf.Variable(tf.random_normal([g_input,                                                                                                                                                                         g_hidden1])),
                     tf.Variable(tf.random_normal([g_hidden1, g_hidden2])),
                     tf.Variable(tf.random_normal([g_hidden2, g_hidden3])),
                     tf.Variable(tf.random_normal([5,5,3,3])),
                     tf.Variable(tf.random_normal([5,5,3,3])),
                     tf.Variable(tf.random_normal([5,5,3,3]))]

    def generator(x, weights):
        output=tf.matmul([[x]], weights[0])
        output=tf.nn.relu(output)
        output=tf.matmul(output, weights[1])
        output=tf.nn.relu(output)
        output=tf.matmul(output, weights[2])
        output=tf.nn.relu(output)
        output=tf.reshape(output, [-1,100,100,3])
        output=tf.nn.conv2d(output, weights[3], [1,1,1,1], 'SAME')
        output=tf.nn.relu(output)
        output=tf.nn.conv2d(output, weights[4], [1,1,1,1], 'SAME')
        output=tf.nn.relu(output)
        output=tf.nn.conv2d(output, weights[5], [1,1,1,1], 'SAME')
        return output

    d_weights = [tf.Variable(tf.random_normal([5,5,3,3])),
                 tf.Variable(tf.random_normal([5,5,3,3])),
                 tf.Variable(tf.random_normal([5,5,3,3])),
                 tf.Variable(tf.random_normal([1875, 100])),
                 tf.Variable(tf.random_normal([100, 100])),
                 tf.Variable(tf.random_normal([100, 2]))]

    def discriminator(x, weights):
        output=tf.nn.conv2d(x, weights[0], [1,1,1,1], 'SAME')
        output=tf.nn.relu(output)
        output=tf.nn.conv2d(output, weights[1], [1,2,2,1], 'SAME')
        output=tf.nn.relu(output)
        output=tf.nn.conv2d(output, weights[2], [1,2,2,1], 'SAME')
        output=tf.nn.relu(output)
        output=tf.reshape(output, [1*25*25*3])
        output=tf.matmul([output], weights[3])
        output=tf.nn.relu(output)
        output=tf.matmul(output, weights[4])
        output=tf.nn.relu(output)
        output=tf.matmul(output, weights[5])
        output=tf.reduce_mean(output)
        return(output)

    prediction = discriminator(x, d_weights)
    loss = -tf.reduce_sum(y * tf.log(prediction + 1e-12))
    optimizer = tf.train.AdamOptimizer().minimize(loss)
    g_optimizer = tf.train.AdamOptimizer().minimize(-prediction)

    saver = tf.train.Saver()
    init = tf.global_variables_initializer()

    with tf.Session() as sess:
        sess.run(init)
        for e in range(d_epochs):
            for b in range(int(len(x_train)/batch_size)):
                start = b*batch_size
                end = start+batch_size
                batch_x = x_train[start:end]
                batch_y = y_train[start:end]
                _, c = sess.run([optimizer,loss],feed_dict={y:batch_y, x:batch_x})
                print(c)
        saver.save(sess, '/saved/discriminator.ckpt')

        file = 0
        for e in range(g_epochs):
            for b in range(int(len(gen_seed)/batch_size)):
                file += 1
                preds = []
                fake = []
                start = b*batch_size
                end = start+batch_size
                batch = gen_seed[start:end]
                for i in batch:
                    fake.append(sess.run(generator(i, g_weights)))
                sess.run([prediction, loss, optimizer, g_optimizer], feed_dict={x:fake, y:np.zeros(fake.shape)})
                montage(fake[0:100], 'output/'+str(file)+'.png')
        saver.save(sess, '/saved/generator.ckpt')

And for some reason I am getting this error:

    Traceback (most recent call last):
      File ""D:\Kay\Tensorflow\Session 5\GAN\GAN.py"", line 92, in     <module>
        _, c = sess.run([optimizer,loss],feed_dict={y:batch_y, x:batch_x})
      File             ""C:\Users\Katharina\AppData\Local\Programs\Python\Python35\lib    \site-packages\tensorflow\python\client\session.py"", line 789,     in run
        run_metadata_ptr)
      File     ""C:\Users\Katharina\AppData\Local\Programs\Python\Python35\lib    \site-packages\tensorflow\python\client\session.py"", line 968,     in _run
        np_val = np.asarray(subfeed_val, dtype=subfeed_dtype)
      File ""C:\Users\Katharina\AppData\Local\Programs\Python\Python35\lib    \site-packages\numpy\core\numeric.py"", line 531, in asarray
        return array(a, dtype, copy=False, order=order)
    ValueError: setting an array element with a sequence.

Can someone tell me how to fix this error?

PS. if you see other problems in my code please let me know.",4,1
19,2017-8-14,2017,8,14,0,6tfpoi,Question about image classification,https://www.reddit.com/r/tensorflow/comments/6tfpoi/question_about_image_classification/,emilepetrone,1502638375,"I just went through the ""[Tensorflow for Poets](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/)"" tutorial on image classification. It was incredibly helpful and much easier than I expected - highly recommend!

However, I have a question on using Tensorflow for image classification given my use case. I'm thinking of setting up a Tensorflow project to process images of watch models. My concern is that if the images aren't of a high enough resolution, the images will be too blurry to get an accurate classification on something where the differences are so minute (even before you throw in things like scratches and wear/tear). 

If I have 2 images of different resolution but are similar, will the model be accurate enough to differentiate minute differences on a watch face?

Here would be examples:

 * [Watch 1](https://d2ok2xewd7jb6a.cloudfront.net/timepieces/photos/a79c9267f3b0f046d8d524a7950380ca2923bd4a.jpg)
 * [Watch 2]
(https://d2ok2xewd7jb6a.cloudfront.net/timepieces/photos/98c61a8ed443e44692862152603b6883ddaeca27.jpg)

I can train the model with accurate data (eg what a given watch model should be), however because the details will be so fine between the photos, I am wondering if I am embarking on a project that may not be able to solve my problem. 

Do you think this is a good project for image classification? This is my first time using Tensorflow, so I just want to make sure this is a good use case for the tool.

Thanks!",1,1
20,2017-8-14,2017,8,14,16,6tl07p,Problems creating a SessionRunHook for early stopping,https://www.reddit.com/r/tensorflow/comments/6tl07p/problems_creating_a_sessionrunhook_for_early/,Scunyorpe,1502697400,"One of the [basic tutorials](https://www.tensorflow.org/get_started/monitors) on the TensorFlow homepage uses a ValidationMonitor to implement early stopping. However, since monitors are deprecated, I wanted to try implementing it as a SessionRunHook instead. I have two problems:

* The training session does not stop when my hook requests stopping
* There has got to be a better way to get the loss tensor than to hard code the name after finding it in the graph on TensorBoard

The hook is sent as an `eval_hooks` item to an Experiment.

    class EarlyStoppingHook(session_run_hook.SessionRunHook):
      def __init__(self):
        self._best_loss = None
        logging.info(""Create EarlyStoppingHook"")
    
      def before_run(self, run_context):
        graph = run_context.session.graph
        tensor_name = ""dnn/regression_head/mean_squared_loss/loss:0""
        loss_tensor = graph.get_tensor_by_name(tensor_name)
        return session_run_hook.SessionRunArgs(loss_tensor)
    
      def after_run(self, run_context, run_values):
        last_loss = run_values.results
        logging.info(""EarlyStoppingHook: Current loss is "" + str(last_loss))
        logging.info(""EarlyStoppingHook: Best loss is "" + str(self._best_loss))
        if self._best_loss is None:
          self._best_loss = last_loss
        elif last_loss > self._best_loss:
          logging.info(""EarlyStoppingHook: Request early stop"")
          run_context.request_stop()
        else:
          self._best_loss = last_loss",1,3
21,2017-8-15,2017,8,15,5,6tpc8w,Lack of backward compatibility,https://www.reddit.com/r/tensorflow/comments/6tpc8w/lack_of_backward_compatibility/,as646,1502743661,"Does this annoy anyone else? Between renaming functions and removing others entirely, it seems prolific. As I find it necessary to work on different machines, some of which have different versions of tensorflow, it is really starting to annoy me.

",5,2
22,2017-8-15,2017,8,15,19,6ttd2l,Get Paid to Build Machine Learning Models w/ Macgyver,https://www.reddit.com/r/tensorflow/comments/6ttd2l/get_paid_to_build_machine_learning_models_w/,tim_macgyver,1502794246,,8,0
23,2017-8-17,2017,8,17,0,6u2o7f,[Question] Tensorboard not corrrectly logging precision and recall metrics,https://www.reddit.com/r/tensorflow/comments/6u2o7f/question_tensorboard_not_corrrectly_logging/,elvaz,1502896292,"I am using Tensorboard to log cross-entropy and accuracy successfully, however precision and recall graphs are completely wrong when logged with tf.metrics.recall and tf.metrics.precicion.

My problem is a six class classification problem. I know from manual calculations outside of Tensorboard that precision should be ~99% at 80% recall, however the graphs recorded by Tensorboard show flat 16% precision at 100% recall.

The precision stat logged is curiously close to 1/6th which corresponds roughly to random selection of my six output nodes.

The code is below:

    def classifier_graph(x, y, learning_rate=0.1):
            """"""
                    Build graph for classification, given our input layer x and
                    output layer, y.
            """"""

            with tf.name_scope('classifier'):
                    with tf.name_scope('model'):
                            W = tf.Variable(tf.zeros([xdim, ydim]), name='W')
                            b = tf.Variable(tf.zeros([ydim]), name='b')
                            y_ = tf.matmul(x, W) + b

                    with tf.name_scope('cross_entropy'):
                            diff = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_)
                            cross_entropy = tf.reduce_mean(diff)
                            summary = tf.summary.scalar('cross_entropy', cross_entropy)

                    with tf.name_scope('train'):
                            #cross_entropy = tf.reduce_mean(-tf.reduce_sum(y * tf.log(y_), reduction_indices=[1]), name='cross_en$
                            train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)
                            #minimise cross_entropy via GD

                    with tf.name_scope('accuracy'):
                            with tf.name_scope('correct_prediction'):
                                    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))
                            with tf.name_scope('accuracy'):
                                    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
                                    tf.summary.scalar('accuracy', accuracy)


                    with tf.name_scope('metrics'):
                            _, recall = tf.metrics.recall(y, y_ )
                            _, precision = tf.metrics.precision(y, y_)

                            v_rec = tf.summary.scalar('recall', recall)
                            v_prec = tf.summary.scalar('precision', precision)

            metrics = tf.summary.merge_all()

            return [W, b, y_, cross_entropy, train_step, metrics]



    def train_classifier(insamples, outsamples, batch_size, iterations, feature_set_index=1, model=None, device=""/gpu:0""):

        x = tf.placeholder(tf.float32, [None, xdim], name='x') # None indications arbitrary first dimension
        y = tf.placeholder(tf.float32, [None, ydim], name='y')

        W, b, y_, cross_entropy, train_step, metrics  = classifier_graph(x, y)

        with tf.Session(config=config) as sess, tf.device(device):

            init = tf.global_variables_initializer()
            init_l = tf.local_variables_initializer()

            sess.run(init)
            sess.run(init_l)

            file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())

            all_classifier_results, all_models, all_err, all_recall, all_precision = [],[],[],[],[]

            t = 0
            while t &lt; iterations:
                batch_x, batch_y = batch_feed(insamples, batch_size, feature_set_index)
                t += 1
                _, err, metrics_str, = sess.run([train_step, cross_entropy, metrics], feed_dict={x: batch_x, y: batch_y })

                all_err.append(err)

                file_writer.add_summary(metrics_str,t)

        return 'Done'

Any ideas on why this might be? Thanks. x, y and y_ are all numpy arrays.",5,1
24,2017-8-17,2017,8,17,9,6u6c47,Index Out Of Range,https://www.reddit.com/r/tensorflow/comments/6u6c47/index_out_of_range/,TheDeadCrafter,1502929329,"X = np.array([i[0] for i in training_data]).reshape(-1,len(training_data[0][0]),1)

keeps returning list index out of range. Help??",1,1
25,2017-8-17,2017,8,17,15,6u893y,TensorFlow-Bitcoin-Robot,https://www.reddit.com/r/tensorflow/comments/6u893y/tensorflowbitcoinrobot/,fendouai,1502952518,"A Bitcoin trade robot based on Tensorflow LSTM model.Just for fun.

https://github.com/TensorFlowNews/TensorFlow-Bitcoin-Robot

Into

A Bitcoin trade robot based on Tensorflow LSTM model.Just for fun.

DataSet

The data is got from btctrade.com with requests.It includes 50 trades of Bitcoin. get_trades.py will get the trades and show you with a picture.

Model

rnn_predicter.py uses LSTM model.It use 10 trades as input ,if the next price is bigger than the 10st one ,the result is [1,0,0],if the next price is smaller than the 10st one ,the result is [0,0,1],if the next price is equal as 10st one ,the result is [0,1,0].

So,the [1,0,0] means that the price of Bitcoin will be higher.

Result

https://github.com/TensorFlowNews/TensorFlow-Bitcoin-Robot/blob/master/training_result.md

More

FaceRank - Rank Face by CNN Model based on TensorFlow (add keras version). https://github.com/fendouai/FaceRank

Blog

http://www.tensorflownews.com/

Update

model saver

data saver",2,5
26,2017-8-18,2017,8,18,22,6uhtx3,How to do neural net fitting with tensorflow?,https://www.reddit.com/r/tensorflow/comments/6uhtx3/how_to_do_neural_net_fitting_with_tensorflow/,TonalDrump,1503063119,"I have data set with 3 numeric inputs and 1 numeric output. I want to create a machine learned neural net fit in tensorflow (like I can do in matlab) so that when the user gives 3 numeric inputs to the neural network, it predicts the 1 numeric output. Sounds simple but the data is not linear in nature and in matlab it required training algorithm such as ""Levinberg-Marquardt"" and others. How can I do this in tensorflow? Is it even possible? I need help getting started. Thanks.",1,3
27,2017-8-19,2017,8,19,2,6ujbbv,Building Convolutional Neural Networks with Tensorflow,https://www.reddit.com/r/tensorflow/comments/6ujbbv/building_convolutional_neural_networks_with/,psangrene,1503076907,,0,5
28,2017-8-19,2017,8,19,9,6ulxau,Discrete GPU,https://www.reddit.com/r/tensorflow/comments/6ulxau/discrete_gpu/,jcp2010,1503102100,"I'm looking at getting a laptop with a GTX 1050. I know there's a GPU optimized version of tensorflow that is supposed to be much faster than cpu only. Will it cause problems with running tensorflow if I set the 1050 to only operate at certain times, like while plugged in? If so, what can I do to avoid the issues? Should I install both, or run CPU version only and forgo the speed bump of the GPU? ",4,1
29,2017-8-20,2017,8,20,15,6uuah0,Object Detection API,https://www.reddit.com/r/tensorflow/comments/6uuah0/object_detection_api/,SArham,1503210378,"Currently, I am using faster_rcnn v1 model for the classification on 11 classes. 

The GPU is a 1050 Ti with 4Gb memory.

So, I have about 8500 labelled images with images/class ranging from 2500 to 300. The problem is that when I have the model trained for 200,000 steps, It classified some of the objects as only a specific class even though it was a different object class. 

The label images have quite a bit of variation in each class but  not enough for one class to envelope the other classes. The images are large but the model image resizer is limited to 400px max as it starts giving CUDA OOM error above this limit.

I tried retraining the model from scratch again for 40,000 steps for checking and this time, it was another class which enveloped all the other classes.

The labelling was done in labelImg and was correct.

The csv intermediary file was also correct.

The labels start from 1 and not 0.

The training subset has 8000 images while the testing has only 500 though.

Batch size has been decreased to 1 image/batch.

Hyper parameters have not been changed.

What can be possible source of error and if this is not enough information to troubleshoot it, ask for more?",0,1
30,2017-8-21,2017,8,21,2,6uwxg0,Training on Ubuntu and transferring to Raspberry Pi,https://www.reddit.com/r/tensorflow/comments/6uwxg0/training_on_ubuntu_and_transferring_to_raspberry/,rhysdg,1503249370,"Hi there!

It's my first time posting on this sub so hello to you all and I hope you're all well!

I'll get straight to the point. I've been working on a Raspberry Pi robot for a few months now and it has all the bell and whistles - autonomy, voice recognition and command etc. I've just installed Tensorflow on the Pi and my Ubuntu laptop and was hoping to outsource training of the final Inception layer to my laptop in order to gain the extra processing power etc.

My question is this? Once I'm done with a round of training would it be as simple as transferring the bottlenecks directory and the retrained graph and retrained labels to the Tensorflow directory on the Raspberry Pi? This seems to be my understanding of the situation but I thought it best to check just in case I'm missing something.

Thanks for reading this and I look forward to your replies!",2,6
31,2017-8-21,2017,8,21,8,6uz51z,What's the simplest possible code to train a directory on paired images?,https://www.reddit.com/r/tensorflow/comments/6uz51z/whats_the_simplest_possible_code_to_train_a/,abcd_z,1503272078,"When I build code from scratch I start as small as possible then extend the functionality one step at a time.  What would be the smallest possible Python code that would load two directories of images, pair the images with the same names from each directory (they will all be paired in this manner ahead of time), train from one to another, and save the results of the training (the predicted output) to another directory?  I'm not even worrying about layers at this point; I just want to make sure I have basic input/output working first.

I've looked around and nobody has any tutorials I can ~~steal from~~ learn from for paired image to image training.  It's always ""image classification with a final softmax layer,"" which doesn't really help me, autoencoders, which only use one image, or the source code for GAN networks, which are too complex for me to wrap my head around.",6,4
32,2017-8-22,2017,8,22,14,6v9005,Visual Studio Code TensorFlow Snippets https://github.com/vahidk/tensorflow-snippets,https://www.reddit.com/r/tensorflow/comments/6v9005/visual_studio_code_tensorflow_snippets/,[deleted],1503380223,[deleted],1,8
33,2017-8-22,2017,8,22,21,6vatpa,ChatGirl is an AI ChatBot based on TensorFlow Seq2Seq Model.,https://www.reddit.com/r/tensorflow/comments/6vatpa/chatgirl_is_an_ai_chatbot_based_on_tensorflow/,fendouai,1503406692,"Introduction

[Under developing,it is not working well yet.But you can just train,and run it.] 
ChatGirl is an AI ChatBot based on TensorFlow Seq2Seq Model.

TensorFlowNews

TensorFlow CNN Model Project:https://github.com/fendouai/FaceRank

TensorFlow LSTM Model Project:https://github.com/TensorFlowNews/TensorFlow-Bitcoin-Robot

TensorFlow Seq2Seq Model Project:https://github.com/fendouai/ChatGirl

Data

twitter dataset:

https://github.com/suriyadeepan/datasets

Train

You need to add a model folder to save the model. Train_Model.py

Run

Run_model.py

Tool

idx2w,w2idx:You can use this tool to change word to id;or change id to word. You can get the demo from hello.py.

Result

Result.md(the train result is too long,here is part of the result.)

Blog

http://www.tensorflownews.com/

RoadMap

dataset
model
[under developing]",0,7
34,2017-8-24,2017,8,24,6,6vm8mj,Strange network connection running Inception,https://www.reddit.com/r/tensorflow/comments/6vm8mj/strange_network_connection_running_inception/,greenbluewhite,1503524341,"I was running Inception-v3 on some images and I noticed that the system monitor showed network activity.  Firing up wireshark, I see it making a very quick connection to 'fastly.com', which appears to be a CDN.  In fact if I disconnect the network, the program will not run at all - it hangs.  Does anyone know what this is?

I was running the 'label_image.py' program, on Ubuntu 16.04 Linux, using a local 'retrained_graph.pb' so it did not need to download anything.",0,1
35,2017-8-24,2017,8,24,8,6vmx6g,"Error while importing TF, can't find MKL DLL",https://www.reddit.com/r/tensorflow/comments/6vmx6g/error_while_importing_tf_cant_find_mkl_dll/,SmArtilect,1503531013,"I installed tensorflow as instructed here
https://www.tensorflow.org/install/install_windows

I have windows 7, Anaconda 4.4.0, python 3.5.3, running on CPU

When I import tensorflow it outputs the following into the Anaconda Prompt console

Intel MKL FATAL ERROR: Cannot load mkl_intel_thread.dll.

and error window comes up saying

python.exe - Entry Point Not Found
The procedure entry point mkl_aa_fw_init_workdivision could not be located in the dynamic link library mkl_core.dll

I find no mention of such error on Google, weird thing is this error didn't occur about two months ago when I had same setup, I didn't change anything but now I get this error, I reinstalled anaconda and everything, still having it. Can you help?",0,1
36,2017-8-24,2017,8,24,14,6vottm,SavedModelBuilder,https://www.reddit.com/r/tensorflow/comments/6vottm/savedmodelbuilder/,Amphagory,1503552958,"Have you used the SavedModelBuilder to save your model and use it for prediction? If so, please share any documents, examples or links you have found helpful. ",0,1
37,2017-8-25,2017,8,25,1,6vs0ck,Problems with multiple inputs,https://www.reddit.com/r/tensorflow/comments/6vs0ck/problems_with_multiple_inputs/,Pewtas,1503592212,"Hi there,    
I have a problem where mit data looks like this    
--------Timestep 0--------(Timestep n-1)---------(Timestep n)    
E1=[0.0,4,3,'a','d']---E1=[35.0,7,3,'f','j']---E1=[36.0,2,5,'a','o']    
E2=[0.0,2,4,'a','w']---E2=[35.0,9,4,'a','o']--E2=[36.0,7,2,'b','p']    
E3=[0.0,7,1,'b','h']---E3=[35.0,3,7,'d','k']--E3=[36.0,4,8,'x','i']    
...
    
As you can see i have a time distributed problem. I just made up this sample data to show you the problem which is in a CSV format for each timestep. so the first column of each E is a timestep 0.00-36.0 and the rest of the features are mixed with continous and categorical data.    
I have made a simple tf.estimator.LinearClassifier NN for each of the E's  for each timestep. That's all good and works. My problem now is i need to group the outputs of each timestep E1-E3 so that there is only 1 ouput for each timestep because after that i want to put the outputs of timestep 0 - timestep n into a LSTM since the order matters for my given case.    
I thought about concatenating all the E's into one tensor so it's is easier to handle but since i don't have 3 E's like in this example but more like 1000 for each timestep i don't know if this would be practical plus i don't know how i would handle the multiple columns with the same label.    
Hopefully someone can give me an answer to my problem. If anything is unclear i am happy to explain it in more detail.",1,1
38,2017-8-25,2017,8,25,4,6vt8zw,Run tensorflow on desktop from laptop?,https://www.reddit.com/r/tensorflow/comments/6vt8zw/run_tensorflow_on_desktop_from_laptop/,AtHeartEngineer,1503603258,"I've been looking at the [distributed tensorflow](https://www.tensorflow.org/deploy/distributed) guide and I am not really understanding what goes where.

Basically, I have a macbook that I want to do development on (running arch) and I have a windows desktop with a 1080ti.

I hate windows, I want my dev environment and convenience of my laptop but I want to use my gaming rig to do the heavy lifting.

I've done: 

`tf.train.Server.create_local_server()` on my desktop and I've ran `with tf.Session(""grpc://10.0.0.153:60394"", config=tf.ConfigProto(log_device_placement=True)) as sess:` on this [example](https://github.com/nlintz/TensorFlow-Tutorials/blob/master/04_modern_net.py).

I can see the task assignment on the windows desktop but I am using very little of my GPU or even my CPUs.

Any ideas?!",5,5
39,2017-8-25,2017,8,25,15,6vwqys,Am I doing something very wrong? Is it possible that two sets of variables are being created?,https://www.reddit.com/r/tensorflow/comments/6vwqys/am_i_doing_something_very_wrong_is_it_possible/,ThatGuyFromMexico,1503642302,"Hi. 

Long shot, but worth the try.

I am trying to train a model. Everything goes fine.

I created a tensor for validation but when I run it I get garbage results. ""OK, the model overfits"" I thought. But I realized that no matter what data I use for validation, I always get bad results.

I did something to test: I provided the same data for training and for validation. This means I should get the same results for validation... but I'm still getting bad results.

Is is possible that I'm using two different sets of variables and the ones used on validation are never trained, therefore giving poor results? Is there any other possible explanation?

Any help or hint will be greatly appreciated.

Thank you.

The code is more or less like this:

    def calculate_loss_cpu(n_classes):

        ...

        images, lengths, labels, encoded_labels, reshaped_sparsed_labels = get_data_batch(queue,
                                                                                      batch_size,
                                                                                      image_height,
                                                                                      image_width,
                                                                                      field_delim)

        
        y = forward(images, n_classes)

        seq_lengths = # some function to get lengths
        loss = tf.nn.ctc_loss(reshaped_sparsed_labels, y, seq_lengths)
        loss = tf.reduce_mean(loss)
        decoded = decode(y, seq_lengths, greedy=False, beam_width=3)
        error_rate = ler(decoded, reshaped_sparsed_labels)

        return optimizer.minimize(loss), loss, error_rate, decoded, labels            


    def calculate_validation_loss(n_classes):

        ...
        tf.get_variable_scope().reuse_variables() # If I don't put this, forward complains that variables already exist
        images, lengths, labels, encoded_labels, reshaped_sparsed_labels = get_data_batch(queue,
                                                                                      batch_size,
                                                                                      image_height,
                                                                                      image_width,
                                                                                      field_delim)

    
        y = forward(images, n_classes, is_training)

        # Basically the same as above
    
        return loss, error_rate, decoded, labels


    # Define tensors
    # Training
    gradient_op, loss, error_rate, train_decoded, train_labels = calculate_loss(n_classes)
    
    # Validation
    val_loss, val_error_rate, val_decoded, val_labels = calculate_validation_loss(n_classes)


    ...

    for batch in range(n_batches):
        _, l, label_error_rate, decoded_training, gt_train = sess.run([gradient_op,
                                                                                   loss,
                                                                                   error_rate,
                                                                                   train_decoded,
                                                                                   train_labels])

    # Validating
    for batch in range(valid_n_batches):
        vl, val_ler, decoded_sequences, gt_val = sess.run([val_loss,
                                                                       val_error_rate,
                                                                       val_decoded,
                                                                       val_labels])",0,3
40,2017-8-26,2017,8,26,11,6w386j,Help with neural network for research,https://www.reddit.com/r/tensorflow/comments/6w386j/help_with_neural_network_for_research/,clxyder,1503715813,"Hey guys! I started doing some research with a professor recently and found myself with the task of creating a model of a hysteresis, not delving too much into what that is, it works sort of a like a lithium battery with charge and discharge cycles.  I am here looking for help as to why I cant get it to run properly. Any help is much appreciated! https://github.com/clxyder/DLHyster",0,1
41,2017-8-26,2017,8,26,12,6w3e3z,Testing tensorflow Image Recognition with few demo image,https://www.reddit.com/r/tensorflow/comments/6w3e3z/testing_tensorflow_image_recognition_with_few/,neonez,1503717868,,1,2
42,2017-8-27,2017,8,27,23,6wcfsy,tensorflow book suggestion,https://www.reddit.com/r/tensorflow/comments/6wcfsy/tensorflow_book_suggestion/,keyholepossums,1503844100,any book around that covers latest tensorflow API r1.3,2,4
43,2017-8-28,2017,8,28,5,6weg83,Parallelizing VGG-16 outputs,https://www.reddit.com/r/tensorflow/comments/6weg83/parallelizing_vgg16_outputs/,millenniumpianist,1503864643,"I have basic code that takes in an image URL, fetches the image, and uses VGG-16 to get a 4096-dimensional representation.

    def convert_url(url, sess, end_points):   
      im = get_image(url)
      return sess.run(end_points['vgg_16/fc7'], 
        feed_dict={input_tensor: im})

I'm running this on a dataset of &gt;50,000 images. It takes a little more than one second per iteration, which is intolerably slow. I want to therefore parallelize this process, as there's no dependence whatsoever from one image to the next.

However, I'm not sure how to do that. I don't think the `multiprocessing` module works because you can't pass in a tensorflow session. And I couldn't figure out how to implement it from the documentation on distributed tensorflow. 

I'm running this on my laptop so it's not really distributed, so I'm not sure how to do it. I was thinking about using `multiprocessing` and simply giving each process its own session but I'm not sure how to do that.

Can anyone help?


----


edit: So I think that's what the `initializer` argument for the `multiprocessing.Pool` class is for. Here's the code I have now.

    def convert_url(_id, url):   
      im = get_image(url)
      return _id, sess.run(end_points['vgg_16/fc7'], feed_dict={input_tensor: im})

    def init():
      global sess;
      sess = tf.Session()

    with Pool(processes=3,initializer=init) as pool:
      results = pool.starmap(convert_url, list(id_img_dict.items())[0:5])

So I'm just trying to run this for 5 items in my original data (from `id_img_dict`), but it's not working. It gets hung up at a certain point. [Here's a screenshot of the exception trace when I manually end it.] (http://imgur.com/a/zwC9L)
",1,1
44,2017-8-28,2017,8,28,18,6wiaoe,Tensorflow GAN code is really slow,https://www.reddit.com/r/tensorflow/comments/6wiaoe/tensorflow_gan_code_is_really_slow/,KayJersch,1503912169,"I tried to build a generative adversarial network by copy and pasting the code from [Siraj Ravals](https://www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A) [github repo](https://github.com/llSourcell/Generative_Adversarial_networks_LIVE) (check him out, he's cool) and reprogramming it to work with the CelebA dataset. The code runs just fine, but the problem is that it's really really slow (in fact it's so slow, that based on a quick calculation it would take 5.7 YEARS to fully train the network on my PC!). So I wanted to ask if someone can help me making the code faster

    import tensorflow as tf
    import numpy as np
    import datetime
    import matplotlib.pyplot as plt
    import matplotlib.image as mpimg
    import glob
    
    x_train = []
    
    for filename in glob.glob('trainig_data/*.jpg'):
        im = mpimg.imread(filename)
        x_train.append(im)
        if len(x_train) == 10000:
            break
    
    def discriminator(x_image, reuse=False):
        if (reuse):
            tf.get_variable_scope().reuse_variables()
        d_w1 = tf.get_variable('d_w1', [5, 5, 3, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))
        d_b1 = tf.get_variable('d_b1', [32], initializer=tf.constant_initializer(0))
        d1 = tf.nn.conv2d(input=x_image, filter=d_w1, strides=[1, 1, 1, 1], padding='SAME')
        d1 = d1 + d_b1
        d1 = tf.nn.relu(d1)
        d1 = tf.nn.avg_pool(d1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')
        d_w2 = tf.get_variable('d_w2', [5, 5, 32, 64], initializer=tf.truncated_normal_initializer(stddev=0.02))
        d_b2 = tf.get_variable('d_b2', [64], initializer=tf.constant_initializer(0))
        d2 = tf.nn.conv2d(input=d1, filter=d_w2, strides=[1, 1, 1, 1], padding='SAME')
        d2 = d2 + d_b2
        d2 = tf.nn.relu(d2)
        d2 = tf.nn.avg_pool(d2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')
        d_w3 = tf.get_variable('d_w3', [2060800, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))
        d_b3 = tf.get_variable('d_b3', [1024], initializer=tf.constant_initializer(0))
        d3 = tf.reshape(d2, [-1, 2060800])
        d3 = tf.matmul(d3, d_w3)
        d3 = d3 + d_b3
        d3 = tf.nn.relu(d3)
        d_w4 = tf.get_variable('d_w4', [1024, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))
        d_b4 = tf.get_variable('d_b4', [1], initializer=tf.constant_initializer(0))
        d4 = tf.matmul(d3, d_w4) + d_b4
        return d4
    
    def generator(batch_size, z_dim):
        z = tf.truncated_normal([batch_size, z_dim], mean=0, stddev=1, name='z')
        g_w1 = tf.get_variable('g_w1', [z_dim, 116412], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))
        g_b1 = tf.get_variable('g_b1', [116412], initializer=tf.truncated_normal_initializer(stddev=0.02))
        g1 = tf.matmul(z, g_w1) + g_b1
        g1 = tf.reshape(g1, [-1, 218, 178, 3])
        g1 = tf.contrib.layers.batch_norm(g1, epsilon=1e-5, scope='bn1')
        g1 = tf.nn.relu(g1)
        g_w2 = tf.get_variable('g_w2', [5, 5, 3, z_dim/2], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))
        g_b2 = tf.get_variable('g_b2', [z_dim/2], initializer=tf.truncated_normal_initializer(stddev=0.02))
        g2 = tf.nn.conv2d(g1, g_w2, strides=[1, 2, 2, 1], padding='SAME')
        g2 = g2 + g_b2
        g2 = tf.contrib.layers.batch_norm(g2, epsilon=1e-5, scope='bn2')
        g2 = tf.nn.relu(g2)
        g2 = tf.image.resize_images(g2, [218, 178])
        g_w3 = tf.get_variable('g_w3', [5, 5, z_dim/2, z_dim/4], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))
        g_b3 = tf.get_variable('g_b3', [z_dim/4], initializer=tf.truncated_normal_initializer(stddev=0.02))
        g3 = tf.nn.conv2d(g2, g_w3, strides=[1, 2, 2, 1], padding='SAME')
        g3 = g3 + g_b3
        g3 = tf.contrib.layers.batch_norm(g3, epsilon=1e-5, scope='bn3')
        g3 = tf.nn.relu(g3)
        g3 = tf.image.resize_images(g3, [218, 178])
        g_w4 = tf.get_variable('g_w4', [5, 5, z_dim/4, 3], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))
        g_b4 = tf.get_variable('g_b4', [1], initializer=tf.truncated_normal_initializer(stddev=0.02))
        g4 = tf.nn.conv2d(g3, g_w4, strides=[1, 2, 2, 1], padding='SAME')
        g4 = g4 + g_b4
        g4 = tf.sigmoid(g4)
        return g4
    
    sess = tf.Session()
    
    batch_size = 50
    z_dimensions = 100
    x_placeholder = tf.placeholder(""float"", shape = [None,218,178,3], name='x_placeholder')
    Gz = generator(batch_size, z_dimensions)
    Dx = discriminator(x_placeholder)
    Dg = discriminator(Gz, reuse=True)
    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.ones_like(Dg)))
    d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dx, labels=tf.fill([batch_size, 1], 0.9)))
    d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.zeros_like(Dg)))
    d_loss = d_loss_real + d_loss_fake
    
    tvars = tf.trainable_variables()
    
    d_vars = [var for var in tvars if 'd_' in var.name]
    g_vars = [var for var in tvars if 'g_' in var.name]
    
    with tf.variable_scope(tf.get_variable_scope(), reuse=False) as scope:
        d_trainer_fake =         tf.train.GradientDescentOptimizer(0.001).minimize(d_loss_fake, var_list=d_vars)
        d_trainer_real = tf.train.GradientDescentOptimizer(0.001).minimize(d_loss_real, var_list=d_vars)
        g_trainer = tf.train.GradientDescentOptimizer(0.0001).minimize(g_loss, var_list=g_vars)
        tf.summary.scalar('Generator_loss', g_loss)
        tf.summary.scalar('Discriminator_loss_real', d_loss_real)
        tf.summary.scalar('Discriminator_loss_fake', d_loss_fake)
        d_real_count_ph = tf.placeholder(tf.float32)
        d_fake_count_ph = tf.placeholder(tf.float32)
        g_count_ph = tf.placeholder(tf.float32)
        tf.summary.scalar('d_real_count', d_real_count_ph)
        tf.summary.scalar('d_fake_count', d_fake_count_ph)
        tf.summary.scalar('g_count', g_count_ph)
        d_on_generated = tf.reduce_mean(discriminator(generator(batch_size, z_dimensions)))
        d_on_real = tf.reduce_mean(discriminator(x_placeholder))
        tf.summary.scalar('d_on_generated_eval', d_on_generated)
        tf.summary.scalar('d_on_real_eval', d_on_real)
        images_for_tensorboard = generator(batch_size, z_dimensions)
        tf.summary.image('Generated_images', images_for_tensorboard, 10)
        merged = tf.summary.merge_all()
        logdir = ""tensorboard/gan/""
        writer = tf.summary.FileWriter(logdir, sess.graph)
        print(logdir)
    
        saver = tf.train.Saver()
    
    sess.run(tf.global_variables_initializer())
    
    gLoss = 0
    dLossFake, dLossReal = 1, 1
    d_real_count, d_fake_count, g_count = 0, 0, 0
    for i in range(50000):
        print(""TRAINING STEP"", i, ""AT"", datetime.datetime.now())
        for b in range(int(len(x_train)/batch_size)):
            start = b*batch_size
            end = start+batch_size
            real_image_batch = x_train[start:end]
            if dLossFake &gt; 0.6:
                _, dLossReal, dLossFake, gLoss = sess.run([d_trainer_fake, d_loss_real, d_loss_fake, g_loss],
                                                        {x_placeholder: real_image_batch})
                d_fake_count += 1
            if gLoss &gt; 0.5:
                _, dLossReal, dLossFake, gLoss = sess.run([g_trainer, d_loss_real, d_loss_fake, g_loss],
                                                        {x_placeholder: real_image_batch})
                g_count += 1
    
            if dLossReal &gt; 0.45:
                _, dLossReal, dLossFake, gLoss = sess.run([d_trainer_real, d_loss_real, d_loss_fake, g_loss],
                                                        {x_placeholder: real_image_batch})
                d_real_count += 1
            if i % 10 == 0:
                summary = sess.run(merged, {x_placeholder: real_image_batch, d_real_count_ph: d_real_count,
                                        d_fake_count_ph: d_fake_count, g_count_ph: g_count})
                writer.add_summary(summary, i)
                d_real_count, d_fake_count, g_count = 0, 0, 0
    
            if i % 10 == 0:
                images = sess.run(generator(3, z_dimensions))
                d_result = sess.run(discriminator(x_placeholder), {x_placeholder: images})
                for j in range(3):
                    print(""Discriminator classification"", d_result[j])
                    im = images[j, :, :, 0]
                    plt.imshow(im)
                    plt.savefig('output/'+str(i)+'-'+str(j)+'.png')
                    plt.close('all')
    
            if i % 5000 == 0:
                save_path = saver.save(sess, ""saved/pretrained_gan.ckpt"", global_step=i)
                print(""saved to %s"" % save_path)",6,2
45,2017-8-28,2017,8,28,23,6wjl4j,"Accidentally installed tensorflow CPU version along GPU version, now TF import does not work?",https://www.reddit.com/r/tensorflow/comments/6wjl4j/accidentally_installed_tensorflow_cpu_version/,PK_thundr,1503929105,"Hi guys I accidentally installed the CPU version tensorflow when trying to upgrade my tensorflow-gpu install. I ran:
&gt; pip install -U tensorflow

Realizing my mistake, I updated tensorflow-gpu, 
&gt; pip install -U tensorflow-gpu

and then uninstalled the cpu tensorflow version.
&gt; pip uninstall install tensorflow 

Now any attempt to import tensorflow fails
&gt;  Traceback (most recent call last):
&gt;   File ""&lt;input&gt;"", line 1, in &lt;module&gt;
&gt;   File ""/home/prad/Downloads/pycharm-community-2017.1.1/helpers/pydev/_pydev_bundle/pydev_import_hook.py"", line 21, in do_import
&gt;     module = self._system_import(name, *args, **kwargs)
&gt;   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 24, in &lt;module&gt;
&gt;     from tensorflow.python import *
&gt;   File ""/home/prad/Downloads/pycharm-community-2017.1.1/helpers/pydev/_pydev_bundle/pydev_import_hook.py"", line 21, in do_import
&gt;     module = self._system_import(name, *args, **kwargs)
&gt;   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 49, in &lt;module&gt;
&gt;     from tensorflow.python import pywrap_tensorflow
&gt;   File ""/home/prad/Downloads/pycharm-community-2017.1.1/helpers/pydev/_pydev_bundle/pydev_import_hook.py"", line 21, in do_import
&gt;     module = self._system_import(name, *args, **kwargs)
&gt;   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 52, in &lt;module&gt;
&gt;     raise ImportError(msg)
&gt; ImportError: Traceback (most recent call last):
&gt;   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 41, in &lt;module&gt;
&gt;     from tensorflow.python.pywrap_tensorflow_internal import *
&gt;   File ""/home/prad/Downloads/pycharm-community-2017.1.1/helpers/pydev/_pydev_bundle/pydev_import_hook.py"", line 21, in do_import
&gt;     module = self._system_import(name, *args, **kwargs)
&gt;   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in &lt;module&gt;
&gt;     _pywrap_tensorflow_internal = swig_import_helper()
&gt;   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
&gt;     _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
&gt; ImportError: /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: cudnnConvolutionBiasActivationForward
&gt; Failed to load the native TensorFlow runtime.
&gt; See https://www.tensorflow.org/install/install_sources#common_installation_problems
&gt; for some common reasons and solutions.  Include the entire stack trace
&gt; above this error message when asking for help.
&gt; 

Any and all help is appreciated, thanks!",2,0
46,2017-8-29,2017,8,29,7,6wmt4e,Saving numpy arrays to TFRecords,https://www.reddit.com/r/tensorflow/comments/6wmt4e/saving_numpy_arrays_to_tfrecords/,as646,1503957921,"Just wondering what convention on this is, all the examples I can find online are for images, and nothing for time-series.

If I have a sequence of vectors, do I load each dimension into a separate feature, each time-step into a separate feature, or do I change the shape of the 2D array into 1D and save it in a single feature, to be converted back when loading the file?",1,1
47,2017-8-29,2017,8,29,8,6wnd76,Training a model doing conditional backprop on some output nodes,https://www.reddit.com/r/tensorflow/comments/6wnd76/training_a_model_doing_conditional_backprop_on/,fuckme,1503963540,"Im a bit of a newbie here, but Im trying to build a model that does multiple things. 
First its trying to see if a action will be successful, and secondly its trying to see when the optimal time would be for a successful transaction. 

My approach is to first train the net on success/non-success. (Sigmoid single node)

I was then planning on adding a set of softmax nodes to get day of week (and another set for hour of day) and doing another round of backprop with only the successful actions. 

Im concerned that it will screw up the initial success/fail node if I do backprop again. 

Is this the correct approach?

Is there a better way than going through the data twice in two large batches like that?

Ideally Id like a single pass where the softmaxs only get activated on a successful action (I think)


",3,2
48,2017-8-30,2017,8,30,13,6wwsm0,TF and Jupyter is killing me (won't import),https://www.reddit.com/r/tensorflow/comments/6wwsm0/tf_and_jupyter_is_killing_me_wont_import/,IronFires,1504066910,"Hi All,

I'm trying to get TF to import into a jupyter workbook and it has given me the same error on two different machines so I must be doing something wrong.  Any help is appreciated!

OS: Windows 10
Python:  Anaconda

Procedure:

1. Install Anaconda

2. Install latest Nvidia drivers

3. Install Cuda toolkit 8.0 

4. Install CuDnn (which seems to consist of copying the three files from the CuDNN zip file into the Cuda folders
5. Open an Anaconda prompt and create an environment called 'tensorflow'  by typing ""conda create -n tensorflow python 3.6""
6. Activating the tensorflow environment (""activate tensorflow"")
7. Installing Tensorflow-GPU  (""pip install --ignore-installed --upgrade tensorflow-gpu"")

8. Opening Jupyter (""jupyter workbook"")

9. Once in a new workbook ""import tensorflow as tf""

Results:

---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
c:\programdata\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in swig_import_helper()
     17         try:
---&gt; 18             return importlib.import_module(mname)
     19         except ImportError:

c:\programdata\anaconda3\envs\tensorflow\lib\importlib\__init__.py in import_module(name, package)
    125             level += 1
--&gt; 126     return _bootstrap._gcd_import(name[level:], package, level)
    127 

c:\programdata\anaconda3\envs\tensorflow\lib\importlib\_bootstrap.py in _gcd_import(name, package, level)

c:\programdata\anaconda3\envs\tensorflow\lib\importlib\_bootstrap.py in _find_and_load(name, import_)

c:\programdata\anaconda3\envs\tensorflow\lib\importlib\_bootstrap.py in _find_and_load_unlocked(name, import_)

c:\programdata\anaconda3\envs\tensorflow\lib\importlib\_bootstrap.py in _load_unlocked(spec)

c:\programdata\anaconda3\envs\tensorflow\lib\importlib\_bootstrap.py in module_from_spec(spec)

c:\programdata\anaconda3\envs\tensorflow\lib\importlib\_bootstrap_external.py in create_module(self, spec)

c:\programdata\anaconda3\envs\tensorflow\lib\importlib\_bootstrap.py in _call_with_frames_removed(f, *args, **kwds)

ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

ModuleNotFoundError                       Traceback (most recent call last)
c:\programdata\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in &lt;module&gt;()
     40     sys.setdlopenflags(_default_dlopen_flags | ctypes.RTLD_GLOBAL)
---&gt; 41   from tensorflow.python.pywrap_tensorflow_internal import *
     42   from tensorflow.python.pywrap_tensorflow_internal import __version__

c:\programdata\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in &lt;module&gt;()
     20             return importlib.import_module('_pywrap_tensorflow_internal')
---&gt; 21     _pywrap_tensorflow_internal = swig_import_helper()
     22     del swig_import_helper

c:\programdata\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in swig_import_helper()
     19         except ImportError:
---&gt; 20             return importlib.import_module('_pywrap_tensorflow_internal')
     21     _pywrap_tensorflow_internal = swig_import_helper()

c:\programdata\anaconda3\envs\tensorflow\lib\importlib\__init__.py in import_module(name, package)
    125             level += 1
--&gt; 126     return _bootstrap._gcd_import(name[level:], package, level)
    127 

ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
&lt;ipython-input-1-41389fad42b5&gt; in &lt;module&gt;()
----&gt; 1 import tensorflow as tf

c:\programdata\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\__init__.py in &lt;module&gt;()
     22 
     23 # pylint: disable=wildcard-import
---&gt; 24 from tensorflow.python import *
     25 # pylint: enable=wildcard-import
     26 

c:\programdata\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\__init__.py in &lt;module&gt;()
     47 import numpy as np
     48 
---&gt; 49 from tensorflow.python import pywrap_tensorflow
     50 
     51 # Protocol buffers

c:\programdata\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in &lt;module&gt;()
     50 for some common reasons and solutions.  Include the entire stack trace
     51 above this error message when asking for help."""""" % traceback.format_exc()
---&gt; 52   raise ImportError(msg)
     53 
     54 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long

ImportError: Traceback (most recent call last):
  File ""c:\programdata\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""c:\programdata\anaconda3\envs\tensorflow\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""&lt;frozen importlib._bootstrap&gt;"", line 978, in _gcd_import
  File ""&lt;frozen importlib._bootstrap&gt;"", line 961, in _find_and_load
  File ""&lt;frozen importlib._bootstrap&gt;"", line 950, in _find_and_load_unlocked
  File ""&lt;frozen importlib._bootstrap&gt;"", line 648, in _load_unlocked
  File ""&lt;frozen importlib._bootstrap&gt;"", line 560, in module_from_spec
  File ""&lt;frozen importlib._bootstrap_external&gt;"", line 922, in create_module
  File ""&lt;frozen importlib._bootstrap&gt;"", line 205, in _call_with_frames_removed
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\programdata\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in &lt;module&gt;
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""c:\programdata\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in &lt;module&gt;
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""c:\programdata\anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""c:\programdata\anaconda3\envs\tensorflow\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

",2,1
49,2017-8-30,2017,8,30,15,6wxcpe,Creating my own ReLu gradient.,https://www.reddit.com/r/tensorflow/comments/6wxcpe/creating_my_own_relu_gradient/,Henry4athene,1504074683,"Hello, I am a student that is just picking up tensorflow and python in general. I am messing around and trying to implement my own back prop algorithm for programming practice and learning. I currently I am stuck on how to implement a ReLuPrime function. I have found solutions with numpy but it seems like it does not work with tensorflow. 

Specifically, I'd like to pass in a tensor and return a new tensor where the element is 0 if the original is less than 0 and 1 if it was greater than 0. 

Any help is appreciated!",3,1
50,2017-8-30,2017,8,30,23,6wzofl,Are you using TF with a language that isn't python? Would you like to?,https://www.reddit.com/r/tensorflow/comments/6wzofl/are_you_using_tf_with_a_language_that_isnt_python/,bpiel,1504105070,"I'm writing language bindings for tensorflow (in clojure, but that doesn't matter for this). For anyone who is using TF with python, but have another language they'd prefer, what would it take to get you to switch?

It would be extremely helpful to get answers to the follow questions. thanks!

- What languages and libraries (if any) do you currently use for machine learning work (TF or otherwise)?
- Do you do ML at work, as a hobby, or both?
- What concerns do you have (if any) about using another language with TF?
- What would you need to see from an alternate-language TF library in order to consider using it? Specific cases or features would be great.
- Tangent: Do you use any tools for running experiments and keeping track of the results? (like this https://neptune.deepsense.io/versions/1.5/)
",3,6
51,2017-8-31,2017,8,31,8,6x39mq,Voice recognition,https://www.reddit.com/r/tensorflow/comments/6x39mq/voice_recognition/,[deleted],1504137054,[deleted],0,0
52,2017-8-31,2017,8,31,10,6x3q7q,RectLabel - An image annotation tool to label images for bounding box object detection.,https://www.reddit.com/r/tensorflow/comments/6x3q7q/rectlabel_an_image_annotation_tool_to_label/,ryouchinsa,1504141904,,4,2
53,2017-8-31,2017,8,31,12,6x4b72,Question about speech recognition,https://www.reddit.com/r/tensorflow/comments/6x4b72/question_about_speech_recognition/,Another_Screenname,1504148542,I want to mess around with Tensorflow for my Graduate project. It would be nice to make my own speech recognition as well as voice recognition (something to distinguish users based on their voice). How practical is it to use Tensorflow for something like this?,0,1
54,2017-8-31,2017,8,31,16,6x5has,Free eBook: Getting Started with TensorFlow (PDF/ePub/Mobi),https://www.reddit.com/r/tensorflow/comments/6x5has/free_ebook_getting_started_with_tensorflow/,PacktStaff,1504165377,,0,8
0,2017-9-1,2017,9,1,14,6xchqf,"Awesome Chatbot Projects,Corpus,Papers,Tutorials.",https://www.reddit.com/r/tensorflow/comments/6xchqf/awesome_chatbot_projectscorpuspaperstutorials/,fendouai,1504242809,,0,2
1,2017-9-2,2017,9,2,1,6xft0v,Deep Learning From Scratch: Theory and Implementation,https://www.reddit.com/r/tensorflow/comments/6xft0v/deep_learning_from_scratch_theory_and/,deepideas,1504284664,,0,8
2,2017-9-2,2017,9,2,6,6xhjpb,How to convert checkpoint files to pb file?,https://www.reddit.com/r/tensorflow/comments/6xhjpb/how_to_convert_checkpoint_files_to_pb_file/,Amphagory,1504300691,"I do not want to retrain my models which I saved as a checkpoint (.meta, .data, .index), so I was wondering if any one had code or elaborate on a walk through to convert my checkpoint files to .pb file.

Bonus Points:  checkpoint files to tensorflow serving",1,2
3,2017-9-3,2017,9,3,15,6xros6,Object detection and distance estimation?,https://www.reddit.com/r/tensorflow/comments/6xros6/object_detection_and_distance_estimation/,emmanuel-p,1504420038,"I have a dataset with 1000s of labeled images, only one class (cars) and also their respective distances from the camera at the moment the pictures were taken.

Id like to train a TensorFlow (Keras or Caffe examples would also be okay) model to detect other cars (this I already know how to), but also to try and predict their distances from the camera as accurately as possible given what was learned from the dataset.

Any thoughts?

Thanks!",1,2
4,2017-9-3,2017,9,3,19,6xsfs6,"New to tensorflow, trying to implement a two layer network but not working",https://www.reddit.com/r/tensorflow/comments/6xsfs6/new_to_tensorflow_trying_to_implement_a_two_layer/,hyoruki,1504434248,"Hello, I've just started learning tensorflow on my own, and have tried to implement a two layered network but I cant seem to get it to work. Could you guys possibly point out what I'm currently doing wrong in my code below? Thank you. 

    # Hidden layer and output layer
    hidden_node = 20
    output_node = 10

    # Weights and biases for layer one
    layer1_weight = tf.Variable(tf.zeros([784, hidden_node]))
    layer1_bias = tf.Variable(tf.zeros([hidden_node]))
    # Weights and biases for layer two
    layer2_weight = tf.Variable(tf.zeros(hidden_node, output_node))
    layer2_bias = tf.Variable(tf.zeros([output_node]))

    # Hidden and output layer
    input = tf.matmul(mnist_dataset, layer1_weight) + layer1_bias
    hidden = tf.nn.relu(input)
    ouput= tf.matmul(hidden, layer2_weight) + layer2_bias
    output_layer = tf.nn.softmax(output)

    scores = tf.placeholder(tf.float32, [None, output_node])
    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits
                                (output_layer, mnist_labels))
    # Optimizer.
    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)",3,1
5,2017-9-4,2017,9,4,4,6xv6zk,Tensorboard Embeddings Demo: Holographic Embeddings (HolE),https://www.reddit.com/r/tensorflow/comments/6xv6zk/tensorboard_embeddings_demo_holographic/,laxatives,1504466746,,1,4
6,2017-9-5,2017,9,5,17,6y6q71,Just ported TF Object Detection Library to ROS(Robot Operating System) which can continuously detect the objects and publishes the detections as ROS messages,https://www.reddit.com/r/tensorflow/comments/6y6q71/just_ported_tf_object_detection_library_to/,cagbal,1504601275,,0,11
7,2017-9-6,2017,9,6,1,6y998p,"Upgraded Nvidia Drivers, Tensorflow Error",https://www.reddit.com/r/tensorflow/comments/6y998p/upgraded_nvidia_drivers_tensorflow_error/,EntropicalGetaway,1504630117,"I recently upgraded nvidia drivers, and now when trying to import tensorflow I receive the following error:

ImportError: libcuda.so.1: cannot open shared object file: No such file or directory

Failed to load the native TensorFlow runtime.

How can I fix this? Thanks!",4,1
8,2017-9-6,2017,9,6,16,6ye9ie,Free eBook: TensorFlow Machine Learning Cookbook (PDF/ePub/Mobi),https://www.reddit.com/r/tensorflow/comments/6ye9ie/free_ebook_tensorflow_machine_learning_cookbook/,PacktStaff,1504684617,,0,1
9,2017-9-7,2017,9,7,23,6ynkrv,best practice gpu cluster?,https://www.reddit.com/r/tensorflow/comments/6ynkrv/best_practice_gpu_cluster/,GabbaGandalf,1504794857,"Hello tensorflow community,

(Im aware of the tensorflow tf.train.ClusterSpec class etc. and the distributed tutorial)
So lets assume I have a single cluster node with 8 GPUs.


I want to know what is the best practice to manage this node?
Are there any schedulers in order to reserve computation time/sessions (in order to handle more than one user on the node)? 
",0,1
10,2017-9-9,2017,9,9,17,6z0p0o,really stuck - how do i export models for android ?,https://www.reddit.com/r/tensorflow/comments/6z0p0o/really_stuck_how_do_i_export_models_for_android/,sandys1,1504946680,"hi guys,
so we have implemented a specific machine learning algorithm and trained it on cloud-ml engine on tensorflow. We have launched the model there and tested it a couple of times.

Where we are very confused is how to export the model so that it can be used on android tensorflow or on our desktop for prediction.

The problem is that there is very less coherent info on how to do this (https://stackoverflow.com/questions/38947658/tensorflow-saving-into-loading-a-graph-from-a-file)

 Options include:    
1. freezing - https://github.com/tensorflow/tensorflow/issues/12319    
2. savedmodelbuilder - https://github.com/tensorflow/tensorflow/issues/12750  (which doesnt look to load on android)    
3. convert_variables_to_constants - https://github.com/tensorflow/models/issues/38 (not sure if this saves with all the values)    
4. tf.train.export_meta_graph - https://www.tensorflow.org/api_guides/python/meta_graph (is this the same as freezing) ?    
5. optimize_for_inference - https://github.com/thtrieu/darkflow/issues/286 . However, they wrote their own [save function] (https://github.com/thtrieu/darkflow/blob/479c83e14559fd5eceb9a9f612503b29a67fac5c/darkflow/net/build.py#L156) and [graph function](https://github.com/thtrieu/darkflow/blob/e4ab7c8bfbb1da3e7455047d5e8c8bae086125da/darkflow/net/help.py#L155)

Basically, we are all super confused on how to do this.

Even worse is the fact that in one case, we are using the Tensorflow high level estimator framework (https://www.tensorflow.org/extend/estimators) to do this. When we do this, we are even more stuck on how to save this model. Basically, we are here - https://github.com/tensorflow/tensorflow/issues/3340#issuecomment-302146136

Ultimately, we are badly stuck on how to export the whole model, graph, metadata, constants, variables in one shot to be usable on different platforms. 

we have just migrated from caffe2 to tensorflow and we didnt expect to get stuck on exporting of models :(",3,2
11,2017-9-10,2017,9,10,8,6z4xgh,Best way to learn tensorflow?,https://www.reddit.com/r/tensorflow/comments/6z4xgh/best_way_to_learn_tensorflow/,2ick,1504999007,I've been taking the Andrew NG course on deep learning. He teaches deep learning theory but not how to use tf. How did you learn it and what do you think is the best way to learn it?,5,6
12,2017-9-12,2017,9,12,10,6zjvaa,I have a question about resize_images,https://www.reddit.com/r/tensorflow/comments/6zjvaa/i_have_a_question_about_resize_images/,asustamepanteon,1505180045,"I have a model that will be trained on random patches (the input is really big).

And in a section of my model I need to do an upscale to a resulting tensor. 

My model's input dimensions are [None,None,None,1] (batch,height,width,channels), which specifies that those dimensions are dynamic. 

But, I'm getting an error... resize_images doesn't allow a [None,None] output size (obviously), is there a way to get around that?",0,1
13,2017-9-13,2017,9,13,0,6znru1,I'm having some gpu problems... only 2GB nvidia 1050 but can't get MNIST Multilayer CNN to run without OOM errors. Is there a way to limit the memory requirement?,https://www.reddit.com/r/tensorflow/comments/6znru1/im_having_some_gpu_problems_only_2gb_nvidia_1050/,marmaladeontoast,1505230993,"For reference I'm following the second part of the tutorial [here](https://www.tensorflow.org/get_started/mnist/pros). The first part works fine.

And the error I get when running the code is:

2017-09-12 17:24:26.215800: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 1.37GiB
2017-09-12 17:24:26.215825: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                  1485438976
InUse:                  1472471808
MaxInUse:               1472471808
NumAllocs:                  166561
MaxAllocSize:           1388489984

2017-09-12 17:24:26.215950: W tensorflow/core/common_runtime/bfc_allocator.cc:277] ***************************************************************************xxxxxxxxxxxxxxxxxxxxxxxxx
2017-09-12 17:24:26.215981: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[10000,32,28,28]
",8,3
14,2017-9-13,2017,9,13,19,6ztq8o,TensorFlow CPU power priorities,https://www.reddit.com/r/tensorflow/comments/6ztq8o/tensorflow_cpu_power_priorities/,ElSarcastro,1505299142,"Hello everyone!

I am upgrading my CPU/MB on my workstation and I'm slightly perplexed in what I should prioritize when choosing which CPU to take:
* AMD ThreadRipper 1950X - has more cores and higher multi threaded performance 
* Intel 7900X - has faster single threaded performance (as well as AVX-512)

I'm mostly plan to do image recognition with several 1080ti's, there is also a VM with linux running in the background.  

The problem is I cant seem to find anywhere what tensorflow favors in this scenario - faster multi core or faster single core performance.

If anyone has any suggestions, I would be very grateful.
Thank you",0,2
15,2017-9-14,2017,9,14,1,6zvn7z,Training model based on a pb file,https://www.reddit.com/r/tensorflow/comments/6zvn7z/training_model_based_on_a_pb_file/,Kindlychung,1505319815,"Here is an old question from SO: https://stackoverflow.com/questions/45773982/retrain-neural-network-after-loading-from-pb-file

It never got much reponse there, so I will try my luck here.

Basically, I have a pb file that someone else has produced, and would like to improve the model based on that. I figured that this should be possible, but didn't find any information on how to do it. 

Any help is appreciated. Thanks. ",0,2
16,2017-9-14,2017,9,14,17,700ycf,Is tensorflow possible to be installed on openBSD ?,https://www.reddit.com/r/tensorflow/comments/700ycf/is_tensorflow_possible_to_be_installed_on_openbsd/,verumnosliberat,1505377877,"openBSD is my personal preference for a production O/S and I thinking seriously to add some tensorflow processing on it, but I don't see it supported anywhere and freeBSD seems not working. Anyone having any experience in this ?",0,1
17,2017-9-14,2017,9,14,22,702a79,Would TensorFlow/ML be able to speech-recognize such noisy audio captcha?,https://www.reddit.com/r/tensorflow/comments/702a79/would_tensorflowml_be_able_to_speechrecognize/,gintrux,1505396469,"I'm trying to beat this audio captcha for educational purposes. I have the library that is generating such captchas, so that means I could generate a really big dataset for training model.

Here is the sample of ultra-noisy audio captcha: https://instaud.io/1fUf

Because I have 0 experience with machine learning &amp; tensorflow yet, my question is for those who already know it - would it work or is the audio captcha too noisy?",1,1
18,2017-9-15,2017,9,15,9,706c25,Trouble using a numpy randomly generated data-set in a neural network,https://www.reddit.com/r/tensorflow/comments/706c25/trouble_using_a_numpy_randomly_generated_dataset/,missingJacket,1505434742,"Hello all! I've been working with neural networks for a project and seem to have run into a problem.

I've gotten a simple, 1 hidden layer neural network to work properly with randomly created data using numpy.random.rand. However, since this only outputs small number, I tried to use numpy.random.uniform instead.However, for some reason this made the calculated loss super high, and eventually would cause a value error in the program.

No other code was changed, and I'm having trouble understanding what the problem is.

Here are the two programs:
https://github.com/BreeCat10/TensorflowProjects/blob/master/Regression
https://github.com/BreeCat10/TensorflowProjects/blob/master/Uniform%20Regression

Any help is appreciated!",4,1
19,2017-9-16,2017,9,16,2,70b99t,How to use tensorflow on web?,https://www.reddit.com/r/tensorflow/comments/70b99t/how_to_use_tensorflow_on_web/,setkyar,1505495689,"Hi, My background is from web development. I read a bit about tensorflow and I saw tensorflow for poets. I follow the tutorial via Google code lab and it work pretty well. But, my problem is how I can use that on web? Is there any video tutorials or articles?",4,2
20,2017-9-17,2017,9,17,7,70ju7p,Why does this code converge with the Adam optimizer but not a normal Gradient Descent optimizer?,https://www.reddit.com/r/tensorflow/comments/70ju7p/why_does_this_code_converge_with_the_adam/,missingJacket,1505600824,"Hey guys! I've been trying to understand neural networks and became confused when trying out different optimizers.

I built a 1 hidden layer neural network then ran a normal gradient descent optimizer on it. For some reason, with this optimizer the neural network would not converge and a really high error was returned. Weirdly enough, when I used the adam optimizer instead, it converged and worked like normal. Why is this? Is there a way to get the normal gradient descent optimizer working?

Here is my code: https://github.com/BreeCat10/TensorflowProjects/blob/master/CustomData

Right now the normal gradient descent is commented out and the adam optimizer is being used.",1,4
21,2017-9-17,2017,9,17,10,70ksd5,Count Boxes with Object Detection,https://www.reddit.com/r/tensorflow/comments/70ksd5/count_boxes_with_object_detection/,dl_mutiny,1505611976,"I've looked up and down on the TensorFlow API documentation. I can't seem to find how to count the number of boxes/objects that are detected. Below is my edit of the object_detection_tutorial.ipynb. I don't need to output the image, I just need to print the number of detected objects so I removed some matplotlib sections.

    ####
    import numpy as np
    import os
    import six.moves.urllib as urllib
    import sys
    import tarfile
    import tensorflow as tf
    import zipfile

    from collections import defaultdict
    from io import StringIO
    from matplotlib import pyplot as plt
    from PIL import Image




    # This is needed to display the images.
    #get_ipython().magic('matplotlib inline')

    # This is needed since the notebook is stored in the object_detection folder.
    sys.path.append("".."")



    from utils import label_map_util

    from utils import visualization_utils as vis_util



    # What model to download.
    MODEL_NAME = 'test_inference_graph'

    # Path to frozen detection graph. This is the actual model that is used for the object detection.
    PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'

    # List of the strings that is used to add correct label for each box.
    PATH_TO_LABELS = os.path.join('training', 'object-detection.pbtxt')

    NUM_CLASSES = 1





    detection_graph = tf.Graph()
    with detection_graph.as_default():
      od_graph_def = tf.GraphDef()
      with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:
        serialized_graph = fid.read()
        od_graph_def.ParseFromString(serialized_graph)
        tf.import_graph_def(od_graph_def, name='')




    label_map = label_map_util.load_labelmap(PATH_TO_LABELS)
    categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)
    category_index = label_map_util.create_category_index(categories)


    def load_image_into_numpy_array(image):
      (im_width, im_height) = image.size
      return np.array(image.getdata()).reshape(
          (im_height, im_width, 3)).astype(np.uint8)



    # For the sake of simplicity we will use only 2 images:
    # image1.jpg
    # image2.jpg
    # If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.
    PATH_TO_TEST_IMAGES_DIR = 'test_images'
    #TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'IMG_{}.PNG'.format(i)) for i in range(7464, 7483) ]
    TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'test-latest.jpg') ]

    # Size, in inches, of the output images.
    #IMAGE_SIZE = (20, 16)



    with detection_graph.as_default():
      with tf.Session(graph=detection_graph) as sess:
        # Definite input and output Tensors for detection_graph
        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')
        # Each box represents a part of the image where a particular object was detected.
        detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')
        # Each score represent how level of confidence for each of the objects.
        # Score is shown on the result image, together with the class label.
        detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')
        detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')
        num_detections = detection_graph.get_tensor_by_name('num_detections:0')
        for image_path in TEST_IMAGE_PATHS:
          image = Image.open(image_path)
          # the array based representation of the image will be used later in order to prepare the
          # result image with boxes and labels on it.
          image_np = load_image_into_numpy_array(image)
          # Expand dimensions since the model expects images to have shape: [1, None, None, 3]
          image_np_expanded = np.expand_dims(image_np, axis=0)
          # Actual detection.
          (boxes, scores, classes, num) = sess.run(
              [detection_boxes, detection_scores, detection_classes, num_detections],
              feed_dict={image_tensor: image_np_expanded})
 
    '''
         # Visualization of the results of a detection.
          vis_util.visualize_boxes_and_labels_on_image_array(
              image_np,
              np.squeeze(boxes),
              np.squeeze(classes).astype(np.int32),
              np.squeeze(scores),
              category_index,
              use_normalized_coordinates=True,
              line_thickness=1)
          plt.figure(figsize=IMAGE_SIZE)
          plt.imshow(image_np)
    '''
    ###Below always print 1
    print(boxes.shape[0])",0,1
22,2017-9-18,2017,9,18,1,70oif0,Unanswered Problem: TF doesn't update variables. (wts initialized randomly),https://www.reddit.com/r/tensorflow/comments/70oif0/unanswered_problem_tf_doesnt_update_variables_wts/,HarambeTownley,1505665826,,0,1
23,2017-9-18,2017,9,18,3,70pev1,Anyone know of a good alternative to the official Tensorflow documentation?!,https://www.reddit.com/r/tensorflow/comments/70pev1/anyone_know_of_a_good_alternative_to_the_official/,omaraltaher,1505674425, I find it is missing a lot of information. Thanks,5,7
24,2017-9-19,2017,9,19,1,70wa8m,Tensorflow Tutorial : Part 1  Introduction,https://www.reddit.com/r/tensorflow/comments/70wa8m/tensorflow_tutorial_part_1_introduction/,psangrene,1505753343,,0,5
25,2017-9-19,2017,9,19,8,70z14o,Does anyone know of an example of someone training a Keras model with distributed tensorflow (i.e. with a parameter server and workers)?,https://www.reddit.com/r/tensorflow/comments/70z14o/does_anyone_know_of_an_example_of_someone/,iamiamwhoami,1505778355,,0,6
26,2017-9-19,2017,9,19,19,7124uy,Accessing similarly named tf.Variable objects outside of their name_scope,https://www.reddit.com/r/tensorflow/comments/7124uy/accessing_similarly_named_tfvariable_objects/,[deleted],1505817986,[deleted],0,1
27,2017-9-19,2017,9,19,20,712bax,Many issues with installing on Windows / Ubuntu with GPU support,https://www.reddit.com/r/tensorflow/comments/712bax/many_issues_with_installing_on_windows_ubuntu/,milesred,1505820416,"Hi, I'm sure this has been posted before and I'm sorry for that! I have spent three frustrating days trying to install on Ubuntu 16.04 and Windows 10 with no luck.

I'm able to install on OSX and Ubuntu with CPU support only easily (10m installation), but havent been able to get anything to work with GPUs.

If anyone can find a tutorial with up to date versions (or just specific versions named) I'd appreciate it. I have gone through about 10-20 different tutorials and none work.

the main issue seems to be about installing CUDA; which version, which parameters, what PATH to set etc. 

I was able to get TensorFlow to install on Ubuntu, but without GPU support.

I couldn't get TensorFlow to run on Windows due to issues with CUDA. I also couldn't get CUDA files to compile / test CUDA due to issues with Visual Studio versioning (again, couldn't find a tutorial for CUDA that didn't include VS).

Thanks in advance.

Windows 10 Pro / Ubuntu 16.04
i7-6700k
32GB RAM
NVIDIA GeForce GTX 970",5,3
28,2017-9-20,2017,9,20,7,716okr,Input from a generator function using queues,https://www.reddit.com/r/tensorflow/comments/716okr/input_from_a_generator_function_using_queues/,[deleted],1505860077,[deleted],0,1
29,2017-9-21,2017,9,21,1,71c946,"Code labs tensorflow for poets problem: ""The name 'import/input' refers to an Operation not in the graph.""",https://www.reddit.com/r/tensorflow/comments/71c946/code_labs_tensorflow_for_poets_problem_the_name/,celte22,1505925018,"I was following the codelabs tensorflow for poets tutorial (https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#4) the training worked fine but when I runned the script to evaluate a image:

    python -m scripts.label_image \
        --graph=tf_files/retrained_graph.pb  \
        --image=tf_files/flower_photos/daisy/21652746_cc379e0eea_m.jpg

I got the following error: 

    The name 'import/input' refers to an Operation not in the graph.

I looked around and it has something to do with chosing the input and output layer, the script label_image.py has 'input' and 'output' set as default. The architecture I'm using is 'inception_v3'.

Does anyone know how to fix it?",1,0
30,2017-9-21,2017,9,21,22,71j7lu,Density clustering in Tensorflow.,https://www.reddit.com/r/tensorflow/comments/71j7lu/density_clustering_in_tensorflow/,Ait0r7,1506001513,"Hi, I'm experimenting with point clouds segmentation in tensorflow. Right now I'm doing my clustering using DBSCAN in sklearn.cluster. 

Is there an alternative to this clustering method in tensorflow?  Or any other method existing in tensorflow that allow us to cluster data without knowing the number of actual clusters?",4,2
31,2017-9-22,2017,9,22,1,71kfvq,How to deploy tensorflow to run locally,https://www.reddit.com/r/tensorflow/comments/71kfvq/how_to_deploy_tensorflow_to_run_locally/,josealb,1506012508,"I have trained a Tensorflow model for a computer vision task.

I can run it in Jupyter Notebook and it works fine.

Now I want to integrate this model with a software I will be distributing.

What is the best way to do this? Ideally Tensorflow's dependencies would just be installed with our software and then you would be able to run the software and the model in your CPU or GPU.

How can I achieve this? Most of what I find is about serving models online

Thanks!",1,4
32,2017-9-22,2017,9,22,4,71lev8,"Program fails evaluating model, with very little feedback",https://www.reddit.com/r/tensorflow/comments/71lev8/program_fails_evaluating_model_with_very_little/,linus_rules,1506020718,"I am learning to use Tensorflow. I grabbed an example from github and changed some things. After running the program successfully, I added an additional sentence, with an evaluation of the trained model. Then, the program failed. See the gist for details about the abort message
[MNIST with TensorFlow](https://gist.github.com/DanielBerns/7b572698450e0f68d334fcff04652d02)


Look for the message ""Program aborts at the following line""

How can I correct this problem? ",1,1
33,2017-9-23,2017,9,23,12,71vx1x,Why is distributed tensorflow built on top of rpc?,https://www.reddit.com/r/tensorflow/comments/71vx1x/why_is_distributed_tensorflow_built_on_top_of_rpc/,iamiamwhoami,1506136105,,2,2
34,2017-9-23,2017,9,23,18,71xet8,How can I do tf.image.rot90 on parts of a 4D tensor containing image data?,https://www.reddit.com/r/tensorflow/comments/71xet8/how_can_i_do_tfimagerot90_on_parts_of_a_4d_tensor/,PhysicsNovice,1506160135,,0,2
35,2017-9-26,2017,9,26,15,72ihd8,Building a seq2seq with dynamic_rnns,https://www.reddit.com/r/tensorflow/comments/72ihd8/building_a_seq2seq_with_dynamic_rnns/,themathstudent,1506406103,,0,3
36,2017-9-27,2017,9,27,11,72pdc5,Combining multiple GPUs to create a one monster GPU,https://www.reddit.com/r/tensorflow/comments/72pdc5/combining_multiple_gpus_to_create_a_one_monster/,redditor_gds,1506479235,"I am just wondering if TensorFlow already has a feature to combine multiple GPUs and use it as one single GPU. I already saw a [ycombinator](https://news.ycombinator.com/item?id=11399277) thread discussing on doing it in AWS and so far I haven't really found whether TensorFlow also provides this feature.

Any feedback is very much appreciated.
 ",8,2
37,2017-9-28,2017,9,28,1,72t9g6,Evaluation average cost in mini-batch,https://www.reddit.com/r/tensorflow/comments/72t9g6/evaluation_average_cost_in_minibatch/,the_code_bender,1506528335,"I am modelling my tensorflow code with the [MonitoredTrainingSession](https://www.tensorflow.org/api_docs/python/tf/train/MonitoredTrainingSession) in TF and using a [LoggingTensorHook](https://www.tensorflow.org/api_docs/python/tf/train/LoggingTensorHook) to print the training cost every X iterations. I am using the Dataset class to load the data and separate into mini-batches, as well as setting up the epochs.

My code is very similar to what can be found in the [Using high-level APIs](https://www.tensorflow.org/programmers_guide/datasets) in the Importing Data article.
Using the same terminology of the example, if I use the *loss* variable to in the logging hook, it will print the loss upon the mini-batch and not the whole average across all batches. How can I model this average with tf variables to have this expected behavior?",0,1
38,2017-9-28,2017,9,28,3,72u4qv,"How should I implement this very ""conditional"" loss function in tensorflow?",https://www.reddit.com/r/tensorflow/comments/72u4qv/how_should_i_implement_this_very_conditional_loss/,ronsap123,1506535856,"Okay so here's the idea. I have a neural network that gets as an input a set of 15 numbers and needs to predict 15 different numbers. The thing is, that statistically there can be up to 10 other possible outputs. So then I thought to build it like this:

-Add another input neuron

-Propagate the net 10 times with the same input but each time add 0.1 to the extra input node I added , thus getting 10 varying results. (sameinput,0) (sameinput,0.1) (sameinput, 0.2) etc.. 

What I need is a cost function that will be able to find the option that was least wrong from the 10 outputted and backpropagate only this option. Now it's very difficult.
Because I get 10 output tensors all of shape (-1, 15) for each of the 10 iterations.. 

And I need for each particular row check in which tensor it had the least amount of error and backpropagate only this loss back to the net. 

Any tips or tools for such complex conditional loss functions?",3,1
39,2017-9-28,2017,9,28,10,72wu6g,Is it possible to pass different sized arrays to a model?,https://www.reddit.com/r/tensorflow/comments/72wu6g/is_it_possible_to_pass_different_sized_arrays_to/,Youseikun,1506561504,"Still learning TF, and about NNs in general. I have an idea for a project, but from what I've seen online all arrays must line up, so [[2,3,2],[1,2,3]], and not [1,[2,3],[1,2,3],10]. Are there any work arounds, or a better way to send/format the data? ",4,3
0,2017-10-5,2017,10,5,5,74ar49,Deconvolutions from a research paper,https://www.reddit.com/r/tensorflow/comments/74ar49/deconvolutions_from_a_research_paper/,2ndFace,1507147230,"Hello All,

I am attempting to reproduce a neural network found in a research paper. Here is the link to an image of the architecture: https://imgur.com/a/q084C

On the right deconvolutions are shown with a number next to them. I was interested to know what the ""2x,"" ""4x,"" ""8x,"" and ""16x"" represented. Thank you.",2,1
1,2017-10-5,2017,10,5,8,74c1ns,Tensorflow for Windows? Which IDE?,https://www.reddit.com/r/tensorflow/comments/74c1ns/tensorflow_for_windows_which_ide/,leechlamp,1507159258,"So this guy managed to create a self-driving AI in GTAV:

https://www.youtube.com/watch?v=b5xpXecR3LY

But I am not sure he did it in windows. He actually has an entire series on deep learning in his youtube account but I am not sure which program to use to import Tensorflow to do these kinds of things. I am pretty confused. 

All I want is to make a Tensorflow AI play Skyrim all by itself and just let it run. Then after that I wanna make something more complex: Train an AI to watch other players play a game in order to learn from them and come up with its own ideas so I don't have to wait weeks for results, if that's even possible. 
",10,8
2,2017-10-7,2017,10,7,15,74tc31,Questions about mean squared error loss.,https://www.reddit.com/r/tensorflow/comments/74tc31/questions_about_mean_squared_error_loss/,Xyoloswag420blazeitX,1507357592,"I am using a convolutional neural network to augment input images. I am feeding in 64x64 matrices representing patches of the images and seeing how well the prediction compares to a known augmented paired image.

For my cost, I am using tf.losses.mean_squared_error. 

My question is simply what the above function outputs. Is it truly outputting the mean, or the sum of the pixel-wise errors? ",1,1
3,2017-10-8,2017,10,8,1,74w0b7,What is the best way to deal with Latitude/Longitude? (New to NN and Tensorflow),https://www.reddit.com/r/tensorflow/comments/74w0b7/what_is_the_best_way_to_deal_with/,grillorafael,1507395492,"Hey guys,


I know that we have to feed everything between 0 and 1 (ideally). What is the chosen method that people use to transform geographical coordinates?",6,8
4,2017-10-8,2017,10,8,20,751amz,7 ways to run TF in parallel,https://www.reddit.com/r/tensorflow/comments/751amz/7_ways_to_run_tf_in_parallel/,mo3194,1507463946,,0,1
5,2017-10-9,2017,10,9,6,754jtj,Implementing LCRN,https://www.reddit.com/r/tensorflow/comments/754jtj/implementing_lcrn/,HaziqRazali,1507498184,"I am trying to implement figure 1 of paper: 
Long-term Recurrent Convolutional Networks for
Visual Recognition and Description https://arxiv.org/pdf/1411.4389.pdf but I am completely lost.

I went through the lstm tutorials but it did not help me because the input were already 1 dimensional and in the right format. This architecture requires me to convolve each N frames in a sequence before passing them to the LSTM. How can I do this ?

What I currently do is build the CNN and invoke it N times for N frames. ",6,2
6,2017-10-10,2017,10,10,9,75dcs0,Trouble launching Tensorflow debugger?,https://www.reddit.com/r/tensorflow/comments/75dcs0/trouble_launching_tensorflow_debugger/,killingtime1,1507594489,"I'm on windows and trying to debug a line of code in a RNN model

(it's a call to tf.nn.lookup_embedding).

I wrapped my session in the debugger as in the docs but nothing happens? Is it supposed to auto launch? The docs says something about a build dependency?

Thanks",0,1
7,2017-10-10,2017,10,10,22,75h3wx,PyTorch vs. TensorFlow: 1 month summary,https://www.reddit.com/r/tensorflow/comments/75h3wx/pytorch_vs_tensorflow_1_month_summary/,Sig_Luna,1507642891,,0,1
8,2017-10-11,2017,10,11,2,75iqty,NumPy Array To Tensorflow Tensor And Back,https://www.reddit.com/r/tensorflow/comments/75iqty/numpy_array_to_tensorflow_tensor_and_back/,seabass,1507657493,,0,6
9,2017-10-11,2017,10,11,5,75ju49,"Multihot encoding in tensoflow (google cloud machine learning, tf estimator api)",https://www.reddit.com/r/tensorflow/comments/75ju49/multihot_encoding_in_tensoflow_google_cloud/,andrewm4894,1507666720,"I have a feature like a post tag. So for each observation the post_tag feature might be a selection of tags like ""oscars,brad-pitt,awards"". I'd like to be able to pass this as a feature to a tensorflow model build using the estimator api running on google cloud machine learning (as per this example but adapted for my own problem).

I'm just not sure how to transform this into a multi-hot encoded feature in tensorflow. I'm trying to get something similar to MultiLabelBinarizer in sklearn ideally.

So say i have data like:

id,post_tag

1,[oscars,brad-pitt,awards]

2,[oscars,film,reviews]

3,[matt-damon,bourne]


I want to featurize it, as part of preprocessing within tensorflow, as:


id,post_tag_oscars,post_tag_brad_pitt,post_tag_awards,post_tag_film,post_tag_reviews,post_tag_matt_damon,post_tag_bourne

1,1,1,1,0,0,0,0

2,1,0,0,1,1,0,0

3,0,0,0,0,0,1,1",3,1
10,2017-10-13,2017,10,13,3,75yra6,Confused about saving/restoring trained weights and biases in Tensorflow,https://www.reddit.com/r/tensorflow/comments/75yra6/confused_about_savingrestoring_trained_weights/,Xyoloswag420blazeitX,1507831208,,0,5
11,2017-10-13,2017,10,13,13,762e2g,"This article mentions a training set of data for a bunch of checkers games. I can't seem to find the database he is talking about, does anyone know where that data is?",https://www.reddit.com/r/tensorflow/comments/762e2g/this_article_mentions_a_training_set_of_data_for/,[deleted],1507867891,[deleted],0,1
12,2017-10-14,2017,10,14,2,766fb7,LSTM setting/resetting the state when using a variable batch size,https://www.reddit.com/r/tensorflow/comments/766fb7/lstm_settingresetting_the_state_when_using_a/,JustinQueeber,1507916503,"I have built this LSTM class:

    import tensorflow as tf
    import Constants


    class LSTM():

        def __init__(self,
                     inputShape,
                     outputShape,
                     numLayers=Constants.numLayers,
                     numHidden=Constants.numHidden,
                     learningRate=Constants.learningRate,
                     forgetBias=Constants.forgetBias):
            self.inputs = tf.placeholder(tf.float32, [None] + inputShape)
            self.labels = tf.placeholder(tf.float32, [None] + outputShape)
            self.inputTensors = tf.unstack(self.inputs, axis=1)
            self.weights = tf.Variable(tf.random_normal([numHidden] + outputShape))
            self.bias = tf.Variable(tf.random_normal(outputShape))
            layers = [tf.contrib.rnn.LSTMCell(numHidden, forget_bias=forgetBias, state_is_tuple=True)] * numLayers
            self.cell = tf.contrib.rnn.MultiRNNCell(layers, state_is_tuple=True)
            self.optimiser = tf.train.GradientDescentOptimizer(learningRate)
            self.forgetBias = forgetBias
            self.batchDict = None
            self.outputs = None
            self.finalStates = None
            self.predictions = None
            self.loss = None
            self.accuracy = None
            self.optimise = None
            self.session = tf.Session()
            self.__buildGraph()

        def __buildGraph(self):
            outputs, finalStates = tf.nn.static_rnn(self.cell, self.inputTensors, dtype=tf.float32)
            predictions = tf.add(tf.matmul(outputs[-1], self.weights), self.bias)
            self.predictions = tf.minimum(tf.maximum(predictions, 0), 1)
            self.loss = tf.losses.mean_squared_error(predictions=self.predictions, labels=self.labels)
            self.accuracy = tf.reduce_mean(1 - tf.abs(self.labels - self.predictions) / 1.0)
            self.optimise = self.optimiser.minimize(self.loss)
            self.session.run(tf.global_variables_initializer())

        def __execute(self, operation):
            return self.session.run(operation, self.batchDict)

        def setBatch(self, inputs, labels):
            self.batchDict = {self.inputs: inputs, self.labels: labels}

        def batchLabels(self):
            return self.__execute(self.labels)

        def batchPredictions(self):
            return self.__execute(self.predictions)

        def batchLoss(self):
            return self.__execute(self.loss)

        def batchAccuracy(self):
            return self.__execute(self.accuracy)

        def processBatch(self):
            self.__execute(self.optimise)

        def kill(self):
            self.session.close()

and I run it like so:

    import DataWorker
    import Constants
    from Model import LSTM

    inputShape = [Constants.sequenceLength, DataWorker.numFeatures]
    outputShape = [1]

    LSTM = LSTM(inputShape, outputShape)

    # #############################################
    # TRAINING
    # #############################################
    for epoch in range(Constants.numEpochs):
        print(""***** EPOCH:"", epoch + 1, ""*****\n"")
        IDPointer, TSPointer = 0, 0
        epochComplete = False
        batchNum = 0
        while not epochComplete:
            batchNum += 1
            batchX, batchY, IDPointer, TSPointer, epochComplete = DataWorker.generateBatch(IDPointer, TSPointer)
            LSTM.setBatch(batchX, batchY)
            LSTM.processBatch()
            if batchNum % Constants.printStep == 0 or epochComplete:
                print(""Batch:\t\t"", batchNum)
                print(""Last Pred:\t"", LSTM.batchPredictions()[-1][0])
                print(""Last Label:\t"", LSTM.batchLabels()[-1][0])
                print(""Loss:\t\t"", LSTM.batchLoss())
                print(""Accuracy:\t"", str(""%.2f"" % (LSTM.batchAccuracy() * 100) + ""%\n""))

    # #############################################
    # TESTING
    # #############################################
    testX, testY = DataWorker.generateTestBatch()
    LSTM.setBatchDict(testX, testY)
    testAccuracy = LSTM.batchAccuracy()
    print(""Testing Accuracy:"", str(""%.2f"" % (testAccuracy * 100) + ""%""))

    LSTM.kill()

&amp;nbsp;

This all works well as it should. However, I am using time series data which consists of financial stocks spanning over ranges of timestamps far greater than the number of time steps that my LSTM is unrolled for - `Constants.sequenceLength`. Because of this, it takes many sequential batches for a single stock t be processed, and so the state/memory of my LSTM needs to be passed between batches. As well as this, after a batch that completes the lifespan of an ID, the next batch would be passing in a new ID from the initial timestamp of my dataset, and so I would want to reset the memory.

[I can find many questions asking something similar, and all of the answers are adequate](https://stackoverflow.com/questions/38441589/rnn-initial-state/41239965#41239965), however, none seem to address the issue of using variable batch sizes - batch sizes initialised to `None` and then inferred when a batch is passed in. My batches are usually a constant size, but do change under certain circumstances and I cannot change this. How can I have control over passing the state between batches, as well as resetting the state, if I have not specified the batch size?",0,3
13,2017-10-14,2017,10,14,19,76barm,Non python language for tensorflow,https://www.reddit.com/r/tensorflow/comments/76barm/non_python_language_for_tensorflow/,Mittalmailbox,1507975636,"Hi Everyone,

I am web developer interested in tensorflow. I know python is goto language for it. I work with JavaScript and Go mostly, there are binding available for these languages but does not support all functionality.

Will these languages (go/JavaScript) have full support in near future?",1,1
14,2017-10-15,2017,10,15,0,76cnrz,FoG: A Compute Platform for tensorflow,https://www.reddit.com/r/tensorflow/comments/76cnrz/fog_a_compute_platform_for_tensorflow/,redditor_gds,1507994120,"Hi Guys,

We are building a distributed compute platform based on GPUs for training machine learning models and for inference. We have release our alpha version and would love if you guys can try it out and give us comments.

Currently our system supports tensor flow based programs.

You can visit our system at https://fog.greenedge.io/",1,5
15,2017-10-15,2017,10,15,8,76fl6w,message me if I can hire you to urgently do a tensorflow task,https://www.reddit.com/r/tensorflow/comments/76fl6w/message_me_if_i_can_hire_you_to_urgently_do_a/,[deleted],1508024216,[deleted],2,1
16,2017-10-16,2017,10,16,4,76kz7n,Neural Net only output's one and has 0 loss,https://www.reddit.com/r/tensorflow/comments/76kz7n/neural_net_only_outputs_one_and_has_0_loss/,BeastjungleNA,1508094711,"Heyo, I have the following neural net but I am not sure why I can only get an output of 1's as a vector it is a binary classification of 1 or 0 and I am not sure exactly how to fix this. I appreciate any help I have been looking online and reading tensorflow docs.
 
    import pandas as pd
    import numpy as np
    from sklearn.svm import LinearSVC
    from sklearn import neighbors
    from sklearn.preprocessing import LabelEncoder
    from sklearn.metrics import accuracy_score
    from sklearn.model_selection import train_test_split
    import tensorflow as tf
    
    def weight_var(shape):
        initial = tf.truncated_normal(shape, stddev = 0.15)
        return tf.Variable(initial)
    
    def bias_var(shape):
        initial = tf.constant(0.0, shape=shape)
        return tf.Variable(initial)
    
    
    
    print(""Reading data..."")
    
    train = pd.read_csv(""../Data/train.csv"")
    songs = pd.read_csv(""../Data/songs.csv"")
    
    song_cols = ['song_id', 'artist_name', 'genre_ids', 'language']
    
    y = train.target
    
    train = train.merge(songs[song_cols], on = 'song_id', how='left')
    train = train.fillna(-1)
    
    train = train.drop(['target'], axis = 1)
    cols = list(train.columns)
    
    for col in cols:
        if train[col].dtype == 'object':
            train[col] = train[col].apply(str)
            
            le = LabelEncoder()
            train_vals = list(train[col].unique())
            le.fit(train_vals)
            train[col] = le.transform(train[col])
    
    #model = neighbors.KNeighborsClassifier(15)
    features = train.columns.values
    
    for feature in features:
        mean, std = train[feature].mean(), train[feature].std()
        train.loc[:,feature] = (train[feature] - mean) / std
    
    print(train.head())
    x_train, x_test, y_train, y_test = train_test_split(train, y, test_size=0.33, random_state=42)
    x_train = x_train.as_matrix()
    y_train = np.transpose([y_train.as_matrix()])
    y_test = np.transpose([y_test.as_matrix()])
    print(""Training the model..."")
    
    ## NEURAL NET ##
    
    #PARAMS#
    
    training_epocs = 20
    training_dropout = 0.9
    display_step = 5
    n_samples = y_train.shape[0]
    batch_size = 2048
    learning_rate = 0.5
    
    input_nodes = 8
    
    #Multiplier for adjustment of layers
    
    multiplier = 1.5
    
    hidden_nodes1 = 18
    hidden_nodes2 = round(hidden_nodes1 * multiplier)
    hidden_nodes3 = round(hidden_nodes2 * multiplier)
    
    #Percent of nodes to keep during dropout
    percent_keep = tf.placeholder(tf.float32)
    
    #Input Layer
    
    x = tf.placeholder(tf.float32, [None, input_nodes])
    
    #layer 1
    
    W1 = weight_var([input_nodes, hidden_nodes1])
    b1 = bias_var([hidden_nodes1])
    y1 = tf.nn.sigmoid(tf.matmul(x, W1) + b1)
    
    #Layer 2
    
    W2 = weight_var([hidden_nodes1, hidden_nodes2])
    b2 = bias_var([hidden_nodes2])
    y2 = tf.nn.sigmoid(tf.matmul(y1, W2) + b2)
    
    #Layer 3
    
    W3 = weight_var([hidden_nodes2, hidden_nodes3])
    b3 = bias_var([hidden_nodes3])
    y3 = tf.nn.sigmoid(tf.matmul(y2, W3) + b3)
    y3 = tf.nn.dropout(y3, percent_keep)
    
    #Layer 4
    
    W4 = weight_var([hidden_nodes3, 1])
    b4 = bias_var([1])
    y4 = tf.nn.softmax(tf.matmul(y3,W4) + b4)
    
    #output
    
    out = y4
    y_ = tf.placeholder(tf.float32, [None, 1])
    
    
    
    
    #Cost Function
    
    cost = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(out),reduction_indices=[1]))
    #cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = out, labels = y_)
    #cost = tf.reduce_mean(cross_entropy)
    
    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)
    
    #total_error = tf.reduce_sum(tf.square(tf.subtract(y_, tf.reduce_mean(y_))))
    #unexplained_error = tf.reduce_sum(tf.square(tf.subtract(y_, y)))
    #correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
    
    predicted = out
    correct_pred = tf.equal(tf.round(predicted), y_)
    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))
    
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for epoch in range(training_epocs):
            for batch in range(int(n_samples/batch_size)):
                batch_x = x_train[batch*batch_size : (1+batch) * batch_size]
                batch_y = y_train[batch*batch_size : (1+batch) * batch_size]
                opt, c, acc,output = sess.run([optimizer, cost, accuracy, out], feed_dict={x: batch_x, y_ : batch_y, percent_keep: training_dropout})
                avg_c = c / batch_x.shape[0]
                if (epoch) % display_step == 0:
                   print(""Epoch: "", epoch,
                         ""Training Error: "", avg_c,
                         ""Train Loss: "", c,
                         ""Accuracy: "", acc,
                         ""Output: "", output)
                
    print(""Done"")
    
    test_error = tf.nn.l2_loss(y_, name = ""SQE"")/x_test.shape[0]
    print(""Test Error:"", test_error.eval({x: x_test.as_matrix(), y:y_test}))
    

",4,3
17,2017-10-17,2017,10,17,3,76smt3,Any Update on TFRC announcement made during GoogleI/O17?,https://www.reddit.com/r/tensorflow/comments/76smt3/any_update_on_tfrc_announcement_made_during/,SirKnightRider,1508179584,,0,1
18,2017-10-17,2017,10,17,5,76tcy8,Exponential Tensorboard,https://www.reddit.com/r/tensorflow/comments/76tcy8/exponential_tensorboard/,BeastjungleNA,1508185687,"Hello, sorry to ask but I am having an issue where every time I run my code it generates a new graph and my tensorboard is now huge not sure how to fix this other than to restart my IDE any ideas?
",3,1
19,2017-10-17,2017,10,17,6,76tyn2,"Installing TFgpu on Win7. TF 1.3 requires CUDA 8.0, which requires visual studio 2015, which requires a subscription with VS to obtain. Do I need VS2015 to get TF to work or will TF work with CUDA 9?",https://www.reddit.com/r/tensorflow/comments/76tyn2/installing_tfgpu_on_win7_tf_13_requires_cuda_80/,[deleted],1508191003,[deleted],0,1
20,2017-10-17,2017,10,17,13,76w8yk,Question about Batch Size,https://www.reddit.com/r/tensorflow/comments/76w8yk/question_about_batch_size/,FantasyBorderline,1508214834,"Currently I'm working on an age recognition model using Inception v4 and Mobilenet v1 using Adience 3D as a training dataset. I'm still confused about the Batch Size and Steps variable in the parameters. I have the Batch Size variable set to 100 and steps to 200.

Does Batch Size mean ""do evaluation every whatever steps""?",3,1
21,2017-10-19,2017,10,19,4,77957d,"Tensorflow: Saving/importing checkpoint works without error, but all imported variables have value 'none'",https://www.reddit.com/r/tensorflow/comments/77957d/tensorflow_savingimporting_checkpoint_works/,Xyoloswag420blazeitX,1508356288,,0,2
22,2017-10-20,2017,10,20,23,77mfjl,How to object recognition with sound via TF? I would like to implement a mobile app which can detect objects and say what it is. Where to start? Any tutorials?,https://www.reddit.com/r/tensorflow/comments/77mfjl/how_to_object_recognition_with_sound_via_tf_i/,raysefo,1508509755,,3,0
23,2017-10-22,2017,10,22,4,77vdd5,Search for face against list of known faces that TF has not trained against?,https://www.reddit.com/r/tensorflow/comments/77vdd5/search_for_face_against_list_of_known_faces_that/,taewoo,1508613281,"1) Is there an example (or at least an arxiv article) that shows how to search a face against a database of faces that a model has not trained on? Perhaps using eigenface or facial keypoint matching?

2) What's a good way to store a time series of detected faces (when, where in video, descriptors, etc) ? Would you guys use standard mysql table ? InfluxDB / Arctic or similar time series optimized DB?",0,1
24,2017-10-22,2017,10,22,13,77yaum,My text recognition program works,https://www.reddit.com/r/tensorflow/comments/77yaum/my_text_recognition_program_works/,bacon_mmm_69,1508646922,"...1/26 of the time!  I'd appreciate it very much if anyone could give me pointers on what I need to fix. I'm new to TensorFlow and I have no idea what is going wrong.


The code: https://pastebin.com/eFTNcNhn

Basic description:

This is a simple convolutional neural network program that takes an image of an uppercase letter and outputs the predicted character. 'x' is the input tensor for the 48x48 image generated by 'imgData(char)', and 'y' is the output to represent an uppercase character.

The cnn model is found inside 'model(x,w1,w2,w3,keep_prob)'.

Despite trying various numbers for the learning rate and epoch, the cost always converges to around 3.3.

'accuracy()' prints out the measured accuracy of the model using a test set. It always says 0.0384615. I want 'predict()' to show what probabilities of a given image to be various characters, but right now it is giving all kinds of wierd numbers.

Thanks a lot.",0,2
25,2017-10-23,2017,10,23,3,781uhv,How to use an autoencoder to visualize dimensionality reduction?,https://www.reddit.com/r/tensorflow/comments/781uhv/how_to_use_an_autoencoder_to_visualize/,o-rka,1508695732,,3,5
26,2017-10-24,2017,10,24,1,78904a,Fully convolutional neural network producing all zeros in segmentation task,https://www.reddit.com/r/tensorflow/comments/78904a/fully_convolutional_neural_network_producing_all/,Xyoloswag420blazeitX,1508777050,,0,2
27,2017-10-24,2017,10,24,2,7899bv,TensorFlow: Building Feed-Forward Neural Networks Step-by-Step,https://www.reddit.com/r/tensorflow/comments/7899bv/tensorflow_building_feedforward_neural_networks/,AhmedGadFCIT,1508779168,,0,5
28,2017-10-25,2017,10,25,3,78hlj4,Load The MNIST Dataset into TensorFlow In A One-Hot Encoded Format,https://www.reddit.com/r/tensorflow/comments/78hlj4/load_the_mnist_dataset_into_tensorflow_in_a/,seabass,1508868576,,0,3
29,2017-10-25,2017,10,25,7,78jesv,How to build this RNN ?,https://www.reddit.com/r/tensorflow/comments/78jesv/how_to_build_this_rnn/,HaziqRazali,1508884401,"I have a RNN that takes in a 2048 dimensional feature vector for the 1st 10 timesteps. At the next 10 timesteps it will use its own output, a 256 dimensional feature vector. So I am facing an issue because the RNN does not accept the 256 dimensional feature vector. I have the link to my code below and was hoping someone could provide a suggestion. I am still new to tensorflow.

This would be the sample image
https://imgur.com/a/wC0kb

https://github.com/HaziqRazali/CS-596-Video-Reconstruction/blob/master/v2.3%20(timesteps%3D10).ipynb",0,1
30,2017-10-25,2017,10,25,20,78n5za,Import error with tensorflow (line 24 in _init_.py),https://www.reddit.com/r/tensorflow/comments/78n5za/import_error_with_tensorflow_line_24_in_init_py/,Minhcht,1508932381,,0,1
31,2017-10-26,2017,10,26,0,78og6u,How can one use gradient descent find the largest circle inside of a 2D polygon,https://www.reddit.com/r/tensorflow/comments/78og6u/how_can_one_use_gradient_descent_find_the_largest/,goomba870,1508945666,"[Here's an example image](https://i.imgur.com/bVVNswe.png) that shows what I'm looking to achieve - the black circle inside of the red polygon.

The red polygon is a series of XY coordinates around the origin 0,0. I'm looking for the circle with origin X,Y and radius R that is the largest possible. 

I'm struggling a bit to figure out how to state my question mathematically. Visually it's easy - pick random points within the polygon, and expand outward until we cross a point in the polygon. Ideally I think this would mean we're touching 2 or 3 points.


I'll take any advice you have. Thanks!",19,1
32,2017-10-26,2017,10,26,2,78pc0y,Installing TensorFlow with CUDA 9.0,https://www.reddit.com/r/tensorflow/comments/78pc0y/installing_tensorflow_with_cuda_90/,avaxzat,1508953343,"When I attempt to import TensorFlow I get the following error:

&gt;ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory

Indeed, I don't have libcublas.so.8.0 anywhere on my system. Instead, I have libcublas.so.**9**.0, apparently a version too high. Creating symlinks to these newer libraries tricks TensorFlow into thinking everything is alright, but as soon as any computation is run the entire thing segfaults. Can TensorFlow be installed so that it works with this version? I'm running Arch Linux if that's relevant at all.

Any help would be greatly appreciated, I've been struggling with this installation for several hours now.",7,8
33,2017-10-26,2017,10,26,3,78phvq,Create A One Layer Feed Forward Neural Network In TensorFlow With ReLU Activation,https://www.reddit.com/r/tensorflow/comments/78phvq/create_a_one_layer_feed_forward_neural_network_in/,seabass,1508954693,,0,0
34,2017-10-27,2017,10,27,0,78wf49,Distributed TensorFlow Guide,https://www.reddit.com/r/tensorflow/comments/78wf49/distributed_tensorflow_guide/,chiraqe,1509032800,,0,2
35,2017-10-27,2017,10,27,1,78wwbd,How to install Tensorflow with Cuda toolkit v8.0 and cuDNN v6.0 ?,https://www.reddit.com/r/tensorflow/comments/78wwbd/how_to_install_tensorflow_with_cuda_toolkit_v80/,Jonsnowstorm,1509036930,"The installation guide mentions the above versions, however , Nvidia (https://developer.nvidia.com/cuda-downloads) provides Cuda v9.0 and cuDNN v7.0 ( https://developer.nvidia.com/cudnn) . 

What should I do ?",2,0
36,2017-10-27,2017,10,27,22,793diu,0.13 Input Dataset API Question,https://www.reddit.com/r/tensorflow/comments/793diu/013_input_dataset_api_question/,RadonGaming,1509112446,"EDIT: Title is wrong :( My bad

I have looked at the 1.3 Dataset [docs](https://www.tensorflow.org/programmers_guide/datasets#reading_input_data) page, which is the suggested replacement for the input pipeline from previous versions. The only suggestions I find are to load the entirety of the dataset in ( hitting the 2G GraphDef buffer ), or placeholder and feed numpyarrays.

My dataset is 50-100G of image files. The old method allowed me to define paths which would be loaded into the pipeline and fed for me. I can't seem to find any mention of this use-case in the new API.

As the docs discourage 'feeding', due to performance reasons, I'm at a loss for creating an input pipeline for images.

Additionally, I wish to sufficiently preprocess these with a combination of tf operators, and opencv2 ( unless I can wrangle tf ops to do the same job ). This will use py_func and map etc.

I am presuming this is simply me misunderstanding this newer system or the mechanics of things which integrate into it. For instance, would it be feasible to load an entire numpy array ( once .npy is made ), and use the feed placeholder approach? I'm looking for that 'on-demand' feel to the pipeline.

Any help would be greatly appreciated :)",4,3
37,2017-10-28,2017,10,28,19,799j0a,"Question: Using TensorFlow, in Python, to train a classifier from examples.",https://www.reddit.com/r/tensorflow/comments/799j0a/question_using_tensorflow_in_python_to_train_a/,mount_sumInt,1509188346,"Hi. I'm new to TensorFlow and machine learning in general. I am experienced in Python, however.

I'm trying to teach a machine from examples. I've looked through the documentation and haven't found a way to do this in TensorFlow; but only ways to optimise values. I've seen examples of doing the same thing with SciKit, but that isn't compatible with GPU computation.

I'm basically trying to turn this pseudo code into code:
    import numpy as np
    import tensorflow as tf
    
    x = np.array([""Hi. I'm Alex."", ""Hi. I'm Mark."", ""Hi. I'm Jake.""])
    y = np.array([""Hi Alex. I'm a robot."", ""Hi Mark. I'm a robot."", ""Hi Jake. I'm a robot.""])
    
    # vvv I think I need to use the session function for this. vvv
    tf.train(x, y)
    
    z = np.array([""Hi. I'm Sophie.""])
    
    prediction = tf.predict(z)
    print(prediction)
    # Prints ""Hi Sophie. I'm a robot.""

How do I do this?

Thank you. :)",2,1
38,2017-10-29,2017,10,29,19,79fr6k,Tensorflow logistic Regression,https://www.reddit.com/r/tensorflow/comments/79fr6k/tensorflow_logistic_regression/,marvpaul,1509271792,"Im trying to implement a logistic regression / classifier using Tensorflow. Basically I have two classes with some trainings data. Each time I train my costs are NaN. Any ideas how to solve this problem? 
https://github.com/marvpaul/MachineLearningPlayground/blob/master/SoftmaxFunctionTF/regression.py

Edit: 
I tried to replace my cross entropy calculation with the Tensorflow method softmax_cross_entropy_with_logits and now my costs dont decrease during training and my accuracy after training is about 50%, which means my training does not work. Any ideas what is going wrong? :/ ",9,2
39,2017-10-30,2017,10,30,6,79jbxs,Tensorflow model loading: Which weights are trained and should be used in evaluation?,https://www.reddit.com/r/tensorflow/comments/79jbxs/tensorflow_model_loading_which_weights_are/,Xyoloswag420blazeitX,1509312944,,0,4
40,2017-10-30,2017,10,30,12,79la36,Freezing a model using tf.Estimator() nets me an unusable model in Android - because RandomShuffleQueueV2 and QueueDequeueMany nodes,https://www.reddit.com/r/tensorflow/comments/79la36/freezing_a_model_using_tfestimator_nets_me_an/,FantasyBorderline,1509334533,"I have a model that is in use with `tf.Estimator()`, and after I freeze it and attempt to use it in Android, I get the infamous ""No Kernel Registered for Op"" error for ""RandomShuffleQueueV2"".

One way I've tried is to remove said nodes, but I can't optimize them for inference because the `optimize_for_inference_lib` says it's an invalid graph.

So, is there a way to freeze the graph from a tf.Estimator without freezing the RandomShuffleQueueV2 and QueueDequeueMany nodes?",0,1
41,2017-10-30,2017,10,30,23,79o1cs,Running TensorFlow on multicore devices,https://www.reddit.com/r/tensorflow/comments/79o1cs/running_tensorflow_on_multicore_devices/,sudo_O,1509373568,,0,2
42,2017-10-30,2017,10,30,23,79o2gi,tflearn GAN: generator has input dimensions from the discriminator,https://www.reddit.com/r/tensorflow/comments/79o2gi/tflearn_gan_generator_has_input_dimensions_from/,KayJersch,1509373870,"I tried to make a Generative Adversarial Network in tflearn with this code:
    from tflearn import *
    from PIL import Image
    import glob
    import numpy as np
    import random

    gen_x = []
    dis_x = []
    dis_y = []

    for filename in glob.glob('trainig_data/*.jpg'):
        im = np.asarray(Image.open(filename).resize((64,64)))
        dis_x.append(im)
        dis_y.append([1.0])
        if len(dis_x) == 10000:
            break

    gen_loss = 'categorical_crossentropy'
    gen_input = input_data([None,1])
    gen = fully_connected(gen_input,48,activation='sigmoid')
    gen = dropout(gen,0.8)
    gen = reshape(gen,[-1,4,4,3])
    gen = conv_2d(gen,32,5,activation='relu')
    gen = upsample_2d(gen,2)
    gen = conv_2d(gen,64,5,activation='relu')
    gen = upsample_2d(gen,2)
    gen = conv_2d(gen,128,5,activation='relu')
    gen = upsample_2d(gen,2)
    gen = conv_2d(gen,256,5,activation='relu')
    gen = upsample_2d(gen,2)
    gen = conv_2d(gen,3,5,activation='relu')
    gen = regression(gen[0],loss=gen_loss,batch_size=10)
    generator = DNN(gen)

    dis_input = input_data([None,64,64,3])
    dis = conv_2d(dis_input,32,5,activation='relu')
    dis = max_pool_2d(dis,2)
    dis = conv_2d(dis,64,5,activation='relu')
    dis = max_pool_2d(dis,2)
    dis = conv_2d(dis,128,5,activation='relu')
    dis = max_pool_2d(dis,2)
    dis = conv_2d(dis,256,5,activation='relu')
    dis = fully_connected(dis,256,activation='sigmoid')
    dis = dropout(dis,0.8)
    dis = fully_connected(dis,1,activation='sigmoid')
    dis = regression(dis,loss='binary_crossentropy',batch_size=10)
    discriminator = DNN(dis)

    for t in range(10):
        gen_x = []
        dis_x_fake = []
        dis_y_fake = []
        for i in range(10000):
            seed = [[random.random()]]
            gen_x.append(seed)
            image = generator.predict(seed)
            dis_x_fake.append(image)
            dis_y_fake.append([0.0])
        discriminator.fit(dis_x,dis_y,5)
        discriminator.fit(dis_x_fake,dis_y_fake,5)
        gen_loss = -discriminator.predict(generator.predict([[gen_input]]))
        generator.fit(gen_x,None,10)
    generator.save('saved/generator.tflearn')

But when I try to run the code, the python shell spits out following error:

    Traceback (most recent call last):
      File ""D:\Kay\AI\GAN\tflearn\GAN.py"", line 59, in &lt;module&gt;
        image = generator.predict(seed)
      File ""C:\Users\Katharina\AppData\Local\Programs\Python\Python35\lib\site-packages\tflearn\models\dnn.py"", line 257, in predict
        return self.predictor.predict(feed_dict)
      File ""C:\Users\Katharina\AppData\Local\Programs\Python\Python35\lib\site-packages\tflearn\helpers\evaluator.py"", line 69, in predict
        return self.session.run(self.tensors[0], feed_dict=feed_dict)
      File ""C:\Users\Katharina\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 789, in run
        run_metadata_ptr)
      File ""C:\Users\Katharina\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 975, in _run
        % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))
    ValueError: Cannot feed value of shape () for Tensor 'InputData/X:0', which has shape '(?, 128, 128, 3)'

Out of some reason the generator has the input dimensions from the discriminator and I don't know how to fix that. Can someone tell me what went wrong and how to fix it?

PS: If you see other flaws in my code, please let me know!",0,1
43,2017-10-31,2017,10,31,0,79ogjr,tf.nn.conv2dtranspose error during training,https://www.reddit.com/r/tensorflow/comments/79ogjr/tfnnconv2dtranspose_error_during_training/,Xyoloswag420blazeitX,1509377514,,0,1
44,2017-10-31,2017,10,31,21,79vdbm,How to store image as RGB array for Image Classifier?,https://www.reddit.com/r/tensorflow/comments/79vdbm/how_to_store_image_as_rgb_array_for_image/,Eilue,1509452700,"I am following a tutorial called 'Machine Learning is Fun!' (https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721) and in the image classification tutorial, I made sense of most of the codes except the first line:

`#Load the data set
``
X, Y, X_test, Y_test = pickle.load(open(""full_dataset.pkl"", ""rb""))`

I learned that pickle is a Python way of storing image into array, but I have no idea how to make my image set into a pickle so that I can use it like that.

I tried dumping image file into a new pkl I created, but somehow only image file name is stored as string, not the color RGB value.

",5,2
0,2017-11-2,2017,11,2,11,7a8o7e,Video Classification using Tensorflow,https://www.reddit.com/r/tensorflow/comments/7a8o7e/video_classification_using_tensorflow/,Erlandd,1509590245,"Is there any tutorial to make a video classification? Each video have different number of frame. I try to look in GitHub, but most of it have no documentation.",0,1
1,2017-11-2,2017,11,2,15,7a9vkz,Trying to Install Tensor Flow,https://www.reddit.com/r/tensorflow/comments/7a9vkz/trying_to_install_tensor_flow/,dm18,1509605911,"I'm Trying to install Tensorflow with GPU support on windows 10. 

when I run the test commands for tensor flow, I get the 
b'Hello, TensorFlow!'

But
sess = tf.Session() 
is throwing up the error messages

2017-11-01 23:52:10.647106: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2017-11-01 23:52:10.928709: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1030] Found device 0 with properties:
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335
pciBusID: 0000:01:00.0
totalMemory: 8.00GiB freeMemory: 6.66GiB
2017-11-01 23:52:10.928785: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)

It seems like those error messages is
Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2

Which seems like it might just be a warning that there are features in the GPU that tensor flow doesn't support. If that's the case, it doesn't seem like that's a big deal. Unless it's telling me that it can't use the GPU. 

Is this informative or a issue? 

Thanks, Totally Noob",9,1
2,2017-11-2,2017,11,2,22,7abeib,I have made a script to install and configure tensorflow-CUDA-cudNN automaticatly in any linux distribution,https://www.reddit.com/r/tensorflow/comments/7abeib/i_have_made_a_script_to_install_and_configure/,RichHS,1509628434,,4,11
3,2017-11-3,2017,11,3,2,7ada1k,Train A One Layer Feed Forward Neural Network in TensorFlow With ReLU Activation,https://www.reddit.com/r/tensorflow/comments/7ada1k/train_a_one_layer_feed_forward_neural_network_in/,seabass,1509645474,,0,1
4,2017-11-3,2017,11,3,12,7aguzx,The Official Discussion Thread,https://www.reddit.com/r/tensorflow/comments/7aguzx/the_official_discussion_thread/,[deleted],1509679634,[deleted],0,1
5,2017-11-3,2017,11,3,12,7agw4v,The Official Discussion Thread,https://www.reddit.com/r/tensorflow/comments/7agw4v/the_official_discussion_thread/,TheNASAguy,1509680027,Here you can discuss anything that doesn't require it's own post,15,3
6,2017-11-3,2017,11,3,20,7aiov3,TensorFlow 1.4 Released,https://www.reddit.com/r/tensorflow/comments/7aiov3/tensorflow_14_released/,TheNASAguy,1509707501,,0,15
7,2017-11-4,2017,11,4,3,7algb7,What's the best way to work with tensorflow on linux or windows to have the fewest problems when working on python projects needing different versions of tensorflow and other libraries?,https://www.reddit.com/r/tensorflow/comments/7algb7/whats_the_best_way_to_work_with_tensorflow_on/,[deleted],1509734916,[deleted],0,1
8,2017-11-4,2017,11,4,10,7anxdr,Is the Geforce GTX 960M sufficient for someone just getting started with Tensorflow?,https://www.reddit.com/r/tensorflow/comments/7anxdr/is_the_geforce_gtx_960m_sufficient_for_someone/,ragnarkar,1509759722,"My newest computer is a laptop from 2012, so I'm in the market for a new Laptop and several that I'm looking at all have this graphic card.  Would this be a good enough GPU for a newbie to casual user of Tensorflow?  I'd at least want it to be able to run the demos on Siraj's videos or to be able to get through the Deep Learning courses on Coursera.",14,2
9,2017-11-5,2017,11,5,8,7au0mv,Tensorflow Project,https://www.reddit.com/r/tensorflow/comments/7au0mv/tensorflow_project/,MentalGaming,1509837161,"Hi, I have a school project with raspberry pi and I want to use tensorflow on raspberry with a camera to face recognition, there are some tutorial or someone can help me? ",4,0
10,2017-11-5,2017,11,5,12,7av92p,pip is not finding tensorflow.,https://www.reddit.com/r/tensorflow/comments/7av92p/pip_is_not_finding_tensorflow/,shinn497,1509851192,"I am getting the follow message. Any idea why it isn't being found?

'Collecting tensorflow
  Could not find a version that satisfies the requirement tensorflow (from versions: )
No matching distribution found for tensorflow'

I am on OS X Yosemitie with python 3.6",5,3
11,2017-11-6,2017,11,6,1,7ayhle,How to install Tensorflow GPU Ubuntu 17.10,https://www.reddit.com/r/tensorflow/comments/7ayhle/how_to_install_tensorflow_gpu_ubuntu_1710/,PeachyDinosaur,1509898942,"Hey 
Has anyone got TensorFlow with GPU support installed on Ubuntu 17.10? Can't find a guide for this onlline any help would be great",8,2
12,2017-11-6,2017,11,6,20,7b4gd9,"Will ""pip install -U"" corrupt TF built from sources?",https://www.reddit.com/r/tensorflow/comments/7b4gd9/will_pip_install_u_corrupt_tf_built_from_sources/,barisumog,1509966070,"I built TF from sources last week (because I had cuda 9 and cudnn 7, and didn't want to downgrade). Pip lists my version as 1.4.0rc1.

Today, when I run ""pip list -o"", I see a newer version is available (1.4.0).

If I just do ""pip install -U tensorflow"", will it be able to upgrade to the newer version automatically? Or will it just mess things up? Should I re-build from sources?

Thanks in advance for any ideas.
",0,1
13,2017-11-7,2017,11,7,0,7b5nfz,Following the computation via outpus on the console?,https://www.reddit.com/r/tensorflow/comments/7b5nfz/following_the_computation_via_outpus_on_the/,hypo_hibbo,1509980488,"Hello, I am very new to tensorflow and want to work with this code, to synthesise photorealistic images:
https://github.com/CQFIO/PhotographicImageSynthesis

Training on my current setup takes really long and I would like to see, which part of the program needs the most computation..
For example, I have a rescursive function in the code and I set print commands into it, to see, how fast the computations are. However, during a session, the print commands in this function don't give me any output. Only during the initialisation, I get the outputs on the console..

Can you give me any idea, how I could ""follow"" my the code during a session?",3,1
14,2017-11-7,2017,11,7,3,7b79dw,Applying a onelayer network to a CSV file,https://www.reddit.com/r/tensorflow/comments/7b79dw/applying_a_onelayer_network_to_a_csv_file/,BaguetteMuncher,1509994604,"Hello all :)

I'm trying to classify audio by using extracted features as my input. My CSV file contains 385 entries per line where the first number is the label and the rest are features. All numbers are on scientific notation.

I have tried looking at the example at https://www.tensorflow.org/tutorials/wide but I feel rather lost. 

How would I construct my training label vector from all the first entries in each line and consequently how do I form the training data from the rest of the CSV line?

I'm thinking that;

""CSV_COLUMNS = [
    ""label"", ... ]

train_data = pd.read_csv(""data.csv"", names=CSV_COLUMNS, skipinitialspace=True)

train_labels = (int(float(train_data[""label""])))""

Might do what i am looking for.

Intuitively it feels like my problem is simpler than the one in the tutorial and it should be possible to achieve what I am looking for by removing parts of the code from the tutorial.

Any help is greatly appreciated! :)

edit: https://www.tensorflow.org/versions/master/get_started/estimator seems to be a more recent and up to date tutorial, It seems to be very closely related to what I am trying to do. I'll take a look at this tutorial also, if recall seeing any more tutorials of CSV programs feel free to link them.",0,2
15,2017-11-7,2017,11,7,12,7baiup,"Tensor flow: Weird issue when loading weights and biases. They are loaded in as their initial definition, not as updated",https://www.reddit.com/r/tensorflow/comments/7baiup/tensor_flow_weird_issue_when_loading_weights_and/,Xyoloswag420blazeitX,1510025235,,0,2
16,2017-11-8,2017,11,8,19,7bkip1,Problem with retraining inception_v3,https://www.reddit.com/r/tensorflow/comments/7bkip1/problem_with_retraining_inception_v3/,Ogofo,1510137147,"Hey guys,

recently I constructed my own dataset to solve an image classification problem for myself. I have 12 labels, and each label has between  440 - 735 images. I set the training iterations to 500, 1500 and 15000. While in the last example the training accuracy sometimes jumps to ~70%, the validation accuracy is always between 30-40%. Is this an indication that my dataset is not big enough, or do I need more training iterations or can the quality of my dataset be too low?

Any answers and help are appreciated. Thank yo very much!",3,2
17,2017-11-8,2017,11,8,23,7bls0x,Viability of USB TPUs?,https://www.reddit.com/r/tensorflow/comments/7bls0x/viability_of_usb_tpus/,eukaryote31,1510152737,"Would it be viable to build small, USB 3.0 tensorflow sticks (like Google TPUs but smaller)? I'm not sure if USB has enough bandwidth for tensorflow, but if these were possible, it would save developers a lot of time and money to buy a $100~200 tensorflow stick that uses relatively little power, than to buy a $500 GPU. It would also make portable development that much easier. Any ideas? ",5,1
18,2017-11-9,2017,11,9,23,7bts2i,TensorFlow: What Parameters to Optimize?,https://www.reddit.com/r/tensorflow/comments/7bts2i/tensorflow_what_parameters_to_optimize/,AhmedGadFCIT,1510239333,,0,5
19,2017-11-11,2017,11,11,3,7c2ze3,Getting Started,https://www.reddit.com/r/tensorflow/comments/7c2ze3/getting_started/,PoopOnMyWaffles69,1510338809,"I took a class on udemy on deep learning. It showed us how to use Keras on Tensorflow. It was fun, but I'm looking for more. I found a class on Udacity called Deep Learning with Google. It is a bit over my head because I do not feel I have a good understanding of Tensorflow yet. Especially since I used Keras. Is there a good online class or tutorials on beginner Tensorflow that anyone knows of? ",1,3
20,2017-11-11,2017,11,11,8,7c4xjk,Where to write python script for image classifiers,https://www.reddit.com/r/tensorflow/comments/7c4xjk/where_to_write_python_script_for_image_classifiers/,TrufflesnCuddles,1510357410,"I am trying to learn how to retrain an image classifier using transfer learning. I am following the steps shown in [this tutorial.] (https://www.youtube.com/watch?v=QfNvhPx5Px8)

I successfully retrained the model but I come across problems in the last step where he writes python script for classifying the newly trained model. In the video, he starts writing the code at 4:18 but does not specify where. I try writing it in the docker container but it gives me the ""no module named platform"" error and the ""NameError: name 'sys' is not defined"" error. I try writing it locally in my machine and get errors as well since I do not have the dependencies installed locally. I am not sure where to write the python code for the final step in the tutorial. 

I originally posted this question on StackOverflow [here.] (https://stackoverflow.com/questions/47231588/where-to-write-python-script-for-image-classifiers) The actual error code is formatted better there. This is my first project using tensorflow and any help is appreciated.

EDIT: spelling",5,2
21,2017-11-12,2017,11,12,3,7ca5r7,Add Metrics Reporting To Improve Your TensorFlow Neural Network Model,https://www.reddit.com/r/tensorflow/comments/7ca5r7/add_metrics_reporting_to_improve_your_tensorflow/,seabass,1510425967,,0,3
22,2017-11-12,2017,11,12,13,7cdb7r,DropConnect Implementation,https://www.reddit.com/r/tensorflow/comments/7cdb7r/dropconnect_implementation/,Mordicon,1510459994,"Has anyone tried using DropConnect in tensorflow? I have seen people talking about implementing it as `dropped = tf.nn.dropout(W, keep_prob=p) * p`. Where they undo the scaling done in the dropout function. Is this correct? It feels odd that you would scale the weights but at the same time it seems like it would cause problems at inference time when you don't do any dropout",0,2
23,2017-11-12,2017,11,12,22,7cfan7,Use Keras Pre-Trained Models With Tensorflow,https://www.reddit.com/r/tensorflow/comments/7cfan7/use_keras_pretrained_models_with_tensorflow/,zachmoshe,1510492068,,0,10
24,2017-11-13,2017,11,13,18,7cm1ll,Anyone using TFLearn? What version of a model is saved? How do you cross-validate?,https://www.reddit.com/r/tensorflow/comments/7cm1ll/anyone_using_tflearn_what_version_of_a_model_is/,bwllc,1510565525,"I'm a fairly experienced scikit-learn user, and over ten years ago I wrote my own NN code before anyone understood how to make NN's truly work.

It was pretty natural for me to try Tensorflow and the TFLearn high-level API.  TFLearn is not documented as well as scikit-learn, so I can't answer a few questions.  I'm hoping that someone here might know.

1.

I have implemented a DNN system in TFLearn which does all the usual things, training on a test set and scoring a validation set.  I added a TFLearn Callback class which allows a training run to end early if validation scores start to rise (a sign of overtraining).

When my training Session ends, if I save the DNN to disk... exactly what would I be saving?  I want to save the version of the DNN from the epoch that returned the lowest validation loss.  Is that what I get?  I have read some vague documentation about checkpoints, but I wasn't able to get a training Session to save any checkpoint files.

2.

I need to do hyperparameter optimization.  I expect that batch size will affect my training, and I'm also varying the DNN topology.  I'm planning a k-fold cross-validation for every batch size.  If I were working with any other scikit-learn model, I would use scikit-learn's sklearn.model_selection.cross_val_score function.

I tried this, and a TFLearn.DNN appears to be missing some hooks.  It appears that a model will not work with scikit-learn's cross validation system unless the estimator has a score method and a get_params method.  I am studying scikit-learn source code, and I'm attempting to add the missing methods to a DNN subclass.  I'm making some progress, but I'm not there yet.

But since these methods are missing, I have to ask why they are missing, and whether there is any documentation for constructing the interface.


Thanks to everyone for your suggestions!",1,2
25,2017-11-13,2017,11,13,21,7cmtsc,How to train Tensorflow models using GPUs,https://www.reddit.com/r/tensorflow/comments/7cmtsc/how_to_train_tensorflow_models_using_gpus/,DeviceHive,1510576932,,0,4
26,2017-11-14,2017,11,14,2,7coupx,TensorFlow: What Parameters to Optimize?,https://www.reddit.com/r/tensorflow/comments/7coupx/tensorflow_what_parameters_to_optimize/,AhmedGadFCIT,1510595683,,0,1
27,2017-11-14,2017,11,14,4,7cpr0p,Generate A Random Tensor In Tensorflow,https://www.reddit.com/r/tensorflow/comments/7cpr0p/generate_a_random_tensor_in_tensorflow/,[deleted],1510602871,[deleted],1,0
28,2017-11-14,2017,11,14,14,7ctcr8,Use graph.pb with opencv,https://www.reddit.com/r/tensorflow/comments/7ctcr8/use_graphpb_with_opencv/,Hectortilla,1510635890,"I am trying to use a retrained model with opencv using 'cv2.dnn.readNetFromTensorflow()'.

I used the tensorflow for poets guide to retrain the model. (https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0)

I know i have to remove some nodes from the graph.pb. Does someone know how to prepare the graph.pb for use with open cv?



",4,2
29,2017-11-14,2017,11,14,15,7ctp2f,How to add an external process (H5 file read -&gt; preprocessing) to an input pipeline?,https://www.reddit.com/r/tensorflow/comments/7ctp2f/how_to_add_an_external_process_h5_file_read/,ThatGuyFromMexico,1510639911,"Let me see if I can explain what I'm trying to achieve.

I have a bunch of images in an h5 file. Another member of the team created a class that basically reads the file, preprocesses the images and provides batches with a method. Everything works OK, but when I need to include that code into Tensorflow it doesn't work. What I get is that the function to read a batch is called once only and thus my code is training on the same batch of images all the time.

I've read about the [Dataset API](https://www.tensorflow.org/versions/master/programmers_guide/datasets) but I don't get how and where to create it in my workflow. The class I received from my colleague basically works like this:

- Init
- Do some preprocessing (read images from the h5 file, transform them, etc.)
- Provide a method next_batch where it loops and gets images and labels, and returns them in numpy arrays.

What I don't get is if I need to create the Dataset in the next_batch function or before. Ideally, the class should read everything into tensors and make all the transformations on them, but my colleague worked directly with numpy arrays. 

I know I need to become more proficient in TF, and would appreciate if anyone can point me to the correct direction on this one. Some links, example code, etc, would be really useful.

Thank you, and please let me know if I wasn't clear enough.",2,1
30,2017-11-14,2017,11,14,18,7cufg2,TensorFlow based android app which does image-captioning in real-time,https://www.reddit.com/r/tensorflow/comments/7cufg2/tensorflow_based_android_app_which_does/,Xe0n360,1510650372,"Check out our deep-learning based android app which captions live camera frames in real-time. 
https://github.com/neural-nuts/Cam2Caption

This app uses pre-trained model generated using
https://github.com/neural-nuts/image-caption-generator

Preview: http://gph.is/2iFzN9h",2,5
31,2017-11-14,2017,11,14,20,7cv2oo,Traffic Light Training Data Prictures,https://www.reddit.com/r/tensorflow/comments/7cv2oo/traffic_light_training_data_prictures/,snux__,1510659998,"Hi there,

im an IT Student in my second semester.

We need to write a scientific paper and our Topic is TensorFlow Traffic Light Detection.

So as you can see im new to programming and especially programming with python. But this is not my main problem. 

Right now i have 30 Images of each Traffic Light Phase (Red, Green).

But with that amount of Training data i get a green light when i let the program test a dog picture :D.

I think i need at least about 500 Pictures each.

Do anyone knows where i can get such images? Google first 5 pages are ok but then the quality of the pictures gets less  and less. So its not easy to get these amounts of Pictures.

Maybe somebody here has a folder full of Traffic lights :).

Just asking if you have any Infos.

Greetz

Phil

PS: Not Perfect London Language :)",2,1
32,2017-11-15,2017,11,15,0,7cwie9,Is it possible to train an existing pre trained model and use it on a pi,https://www.reddit.com/r/tensorflow/comments/7cwie9/is_it_possible_to_train_an_existing_pre_trained/,baconreader9000,1510675041,From what I can tell it's better to train models on a PC because of the processing power available but I want to use this model on a pi3. Can this be done and how do I got about doing this ?,10,2
33,2017-11-15,2017,11,15,5,7cyflf,Can we use tensorflow as a parallel computing framework?,https://www.reddit.com/r/tensorflow/comments/7cyflf/can_we_use_tensorflow_as_a_parallel_computing/,HarambeTownley,1510690615,"Parallel programming is difficult. Using CUDA isn't easy but using tensorflow is. Since the GPU version of tensorflow uses CUDA, couldn't we simply use tensorflow for parallel computation? Do you think that tensorflow with python can surpass c/c++ in terms of speed?",1,1
34,2017-11-15,2017,11,15,11,7d0t0d,Google releases developer preview of Tensorflow Lite (for mobile),https://www.reddit.com/r/tensorflow/comments/7d0t0d/google_releases_developer_preview_of_tensorflow/,alew3,1510711604,,0,13
35,2017-11-15,2017,11,15,13,7d1nnm,How to get a recall curve from object detection api?,https://www.reddit.com/r/tensorflow/comments/7d1nnm/how_to_get_a_recall_curve_from_object_detection/,beardedindieguy,1510720261,I tried running eval but it only includes average precision.,2,1
36,2017-11-15,2017,11,15,23,7d4fiw,Sound Classification with TensorFlow,https://www.reddit.com/r/tensorflow/comments/7d4fiw/sound_classification_with_tensorflow/,DeviceHive,1510756154,,0,12
37,2017-11-16,2017,11,16,0,7d4s0m,Reusing variables for lagging nets?,https://www.reddit.com/r/tensorflow/comments/7d4s0m/reusing_variables_for_lagging_nets/,tsorn,1510759375,"So, when using different reinforcement learning techniques it's often desirable to have two copies of a network, one which is trained and another which is periodically copied from the first and therefore lags behind. The copying is usually done by doing net2.var1.assign(net1.var2) for each trainable variable. 

When constructing these two nets, should I use reuse=True for the second net?",0,2
38,2017-11-16,2017,11,16,2,7d5jrq,Custom parameter server behavior (for Delay-Compensated ASGD),https://www.reddit.com/r/tensorflow/comments/7d5jrq/custom_parameter_server_behavior_for/,quadraticalgebra,1510766111,"I'm trying to implement [delay-compensated ASGD](https://arxiv.org/abs/1609.08326) in Tensorflow. In essence, the only differences with regular ASGD are that:

  * The parameter server must remember the last version of the parameters it's sent out to each worker, and
  * Every time the parameter server receives a gradient from a worker, it'll update the parameters with a (simple) formula that depends on this gradient, the current parameters, and the remembered parameters for that worker (i.e., those from which the worker computed the gradient).

([short and complete algorithm description](https://i.imgur.com/qGIfOYG.png))

I think I'm a little confused about Tensorflow's distributed architecture. [This StackOverflow answer](https://stackoverflow.com/a/39681502/) explains that the parameter server really does nothing, but the call to `tf.train.replica_device_setter()` tells the workers that their variables live on the parameter server. I don't think I can easily extend this approach, since the update step depends on having access to the most up-to-date step.

So is the right way to implement this by implementing something like the [`SyncReplicasOptimizer` class](https://www.tensorflow.org/api_docs/python/tf/train/SyncReplicasOptimizer)?

Thanks a lot, and sorry if I'm missing anything obvious!",0,1
39,2017-11-16,2017,11,16,14,7da9cd,csv2NN classifier using tensorflow,https://www.reddit.com/r/tensorflow/comments/7da9cd/csv2nn_classifier_using_tensorflow/,aakash257,1510809609,,0,1
40,2017-11-16,2017,11,16,15,7dahxq,"Hey guys, I am having trouble with reading files, any help would be appreciated.",https://www.reddit.com/r/tensorflow/comments/7dahxq/hey_guys_i_am_having_trouble_with_reading_files/,Relinquishthoughts,1510812509,"If this is the wrong place please let me know and I will move it.

This is the most frustrating thing I have ever come across. I can not get this to read for the life of me. Here is my code: The code stops at sess.run(x) and I have no idea how to troubleshoot it. Any tips would be helpful!

    import tensorflow as tf
    import os
    images = []
    print(os.getcwd())
    print(os.listdir())
    for file in os.listdir(""./images""):
        if file.endswith('.jpg'):
            images.append(file)
            
    filename_queue = tf.train.string_input_producer(images)
    reader = tf.WholeFileReader()
    _, image_file = reader.read(filename_queue)
    
    x = tf.Print(image_file, [image_file], message=""what the fuck I hate this"")
    sess = tf.Session()
    print('this is dumb')
    sess.run(x)
    print('fuck this') 
My biggest problem is I can't figure out where I am going wrong because I do not know how to read the variables. 

/rant",1,2
41,2017-11-16,2017,11,16,22,7dcbkt,Project on tensorflow serving,https://www.reddit.com/r/tensorflow/comments/7dcbkt/project_on_tensorflow_serving/,rahults,1510838351,"A project on tensorflow serving that I have been working on.
Requesting beta users.

Link to the project:
https://simpleintelligence.com/

A video demo:
https://www.youtube.com/watch?time_continue=1&amp;v=SJbjl7sibKI

Please do sign up, and let me know the feedbacks.
I don't have the money to scale at this point so can only grant around 50 users for now :).

If you want to help with the development of the product itself, message me.
",0,1
42,2017-11-17,2017,11,17,0,7dd1bb,Q: TensorFlow Profiler and Advisor: TFProf,https://www.reddit.com/r/tensorflow/comments/7dd1bb/q_tensorflow_profiler_and_advisor_tfprof/,RadonGaming,1510845525,"Noticed via the GitHub [repo](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/profiler) that `tfprof` exists. The ReadMe provides some quickstart; however, this doesn't work as profiler isn't an executable that produces anything. Likewise, the UI variant is non-existent ( which is the one thing I wish to use ).

I have wrapped my training loop in `with tf.contrib.tfprof.ProfileContext('./profiler/') as pctx:` as recommend, and this does indeed produce a `./profiler` output - But with no means to visualise these.

All information I've tried to find has led me nowhere, or back to the original github page. It seems that nobody has the answers I seek, hence my question:

Has anybody had experience with `tfprof` ( not to be confused with tfdbg ), and if so, has anybody got the UI as shown in the ReadMe to work. I would much rather a TensorBoard equivalent for profiling than having to insert verbose debugs throughout code.",0,2
43,2017-11-17,2017,11,17,4,7depwr,Save The State Of A TensorFlow Model With Checkpointing,https://www.reddit.com/r/tensorflow/comments/7depwr/save_the_state_of_a_tensorflow_model_with/,seabass,1510859853,,0,3
44,2017-11-17,2017,11,17,20,7dk5tp,A user friendly editor based on Tensorflow: AI Blocks,https://www.reddit.com/r/tensorflow/comments/7dk5tp/a_user_friendly_editor_based_on_tensorflow_ai/,smilefr,1510916537,"Hi everyone!

AI Blocks is a WYSIWYG interface making it easier for developers to implement models quickly, I wanted to share my tool with you, hopefully this might help someone, It has proven itself to be very useful to me.

[Screenshot](https://raw.githubusercontent.com/MrNothing/AI-Blocks/master/sc5.png)

The interface is inspired from Unity, you can attach scripts to objects in the scene, run graphs and view the output in real time. I would love to get some feedback if you have time to check it out.

Github: https://github.com/MrNothing/AI-Blocks
Releases: https://github.com/MrNothing/AI-Blocks/releases

Thank you!",4,16
45,2017-11-18,2017,11,18,0,7dlmdc,Get gradients of a specific subset of variables,https://www.reddit.com/r/tensorflow/comments/7dlmdc/get_gradients_of_a_specific_subset_of_variables/,avaxzat,1510931962,"I was wondering if there is any way in TensorFlow to compute the gradients wrt only some parts of an input tensor? Specifically, I have an input tensor x of shape [150528] and an output tensor y of shape [1000]. I also have a set S containing indices into x. I would like TF to compute the gradients of y with respect to only the components of x indexed by S, not all elements of x as this is both unnecessary and computationally intractable. All my attempts so far have all led to TF simply returning None. For example, the following two snippets lead to `None` values:

    grads = tf.gradients(y, x[S])
    grads = tf.gradients(y, tf.gather(x, S))

Any help would be greatly appreciated.",0,2
46,2017-11-18,2017,11,18,9,7dp3ok,Tensorflow dev summit 2018?,https://www.reddit.com/r/tensorflow/comments/7dp3ok/tensorflow_dev_summit_2018/,ajmssc,1510963317,"Around this time last year was when signup opened for the Tensorflow dev summit 2017 in mountain view.

Does anyone know if there will be a 2018 summit next year?",4,10
47,2017-11-19,2017,11,19,4,7dv9wt,Installing TensorFlow 1.4.0 on macOS with CUDA support,https://www.reddit.com/r/tensorflow/comments/7dv9wt/installing_tensorflow_140_on_macos_with_cuda/,crmne,1511034755,,0,1
48,2017-11-19,2017,11,19,5,7dvcps,"I've tried to implement an LSTM NN from scratch in Tensorflow for text generation. However, it is not performing very well, could any one advice me on my code?",https://www.reddit.com/r/tensorflow/comments/7dvcps/ive_tried_to_implement_an_lstm_nn_from_scratch_in/,ronsap123,1511035453,"Hello, the title pretty much says it all. I wanted to do a fun little project and as usual it went wrong and now I'm obsessed with making it work. I know it's silly and I can just use the built in LSTM feature but I want to see what went wrong.

So if you could just give suggestions or some kind of critique that's what I'm looking for.

http://txt.do/dqa46

P.S I'm sorry if this subreddit is not for these kinds of posts, If you could orient me towards a subreddit that is it'd be great.",1,1
49,2017-11-19,2017,11,19,21,7e0c0n,Introducing Olympus - An instant REST API for any AI model,https://www.reddit.com/r/tensorflow/comments/7e0c0n/introducing_olympus_an_instant_rest_api_for_any/,subbytech,1511095014,,1,1
50,2017-11-20,2017,11,20,9,7e50tp,Boltzmann Machines in TensorFlow with examples,https://www.reddit.com/r/tensorflow/comments/7e50tp/boltzmann_machines_in_tensorflow_with_examples/,monsta-hd,1511139310,,0,2
51,2017-11-21,2017,11,21,0,7e9qnj,How to use input_fn with super massive datasets?,https://www.reddit.com/r/tensorflow/comments/7e9qnj/how_to_use_input_fn_with_super_massive_datasets/,rodrigo-silveira,1511192924,"All the examples for Estimators use input_fn where the input_fn function returns the entire dataset (features + labels) from in-memory data. How would you handle the case where your training data is too big to fit in memory?

To clarify, this is the API I'm talking about https://www.tensorflow.org/get_started/input_fn ",2,2
52,2017-11-21,2017,11,21,9,7edj7d,Google Developers Blog: Introducing TensorFlow Feature Columns,https://www.reddit.com/r/tensorflow/comments/7edj7d/google_developers_blog_introducing_tensorflow/,artmast,1511223194,,0,2
53,2017-11-21,2017,11,21,11,7eemki,ELI5 Installation of Tensorflow with GPU support on Mac OSX,https://www.reddit.com/r/tensorflow/comments/7eemki/eli5_installation_of_tensorflow_with_gpu_support/,o-rka,1511233162,I would really like to install TensorFlow with GPU support on OSX El Capitan (and Sierra if possible for my personal computer).  I am completely naive to configuring hardware like this so bare with me.  Is there any way to achieve this with a preconfigured unit in conda?  Is the tensorflow-gpu different than tensorflow on pip?  Is it necessary to have a NVIDIA graphics processor? ,2,3
54,2017-11-21,2017,11,21,18,7egizf,What is the use of bounding boxes in imagenet classification task?,https://www.reddit.com/r/tensorflow/comments/7egizf/what_is_the_use_of_bounding_boxes_in_imagenet/,Sn_Shines,1511254892,I was going through imagenet scripts in models/research/slim and found they are downloading imagenet images and bounding boxes to collect data to train a classification model. Why do we need bounding boxes for classification task? Can't we just resize images and train them?,3,3
55,2017-11-21,2017,11,21,23,7eibcr,Passing PIL PngImageFile to tensorflow for image recognition,https://www.reddit.com/r/tensorflow/comments/7eibcr/passing_pil_pngimagefile_to_tensorflow_for_image/,AllHailTheCATS,1511275616,"I take an image in from the user and I want to pass it to tensorflow to determine what is in it:

     @app.route('/uploader', methods = ['GET', 'POST'])
     def upload_file():
      if request.method == 'POST':
       f = request.files['file']
       f.save(f.filename)
       i = Image.open(f)
       image_handler(i)

    def image_handler(image):
     create_graph()
     print(""Model loaded"")

    node_lookup = NodeLookup()
    print(""Node lookup loaded"")
    
    print(""Img: "")
    print(image)
    predictions = dict(run_inference_on_image(image))
    print(predictions)
    return jsonify(predictions=predictions)

image_handler() is using the functions and the NodeLookup class from the tensorflow imagenet repo found here:
https://github.com/tensorflow/models/blob/master/tutorials/image/imagenet/classify_image.py


The problem is when I run the app it will load fine, the user can select an image fine too but when they hit submit it get the following error when getting the predictions:

    Expected binary or unicode string, got &lt;PIL.PngImagePlugin.PngImageFile image mode=RGBA size=200x200 at 0x243126ABA90&gt;",0,1
56,2017-11-22,2017,11,22,9,7emrn1,Batching without adding an extra None dimension?,https://www.reddit.com/r/tensorflow/comments/7emrn1/batching_without_adding_an_extra_none_dimension/,quietearthus,1511311585,"According to the tensorflow documentation, batching is done in conjunction with an extra [None, .., .. ,..] in a placeholder for feeding multiple examples at the same time. However, I am working on a very large existing code base which will make this incredibly involved as it's designed for a sample at a time, so my question is, is there a way to batch so I can feed multiple training samples at a time without modifying the architecture? eg:

sess.run(feed_dict = {var1: var1data, var2:var2data, ...})

Where sess.run will process 16 consecutive var1data/var2data  samples at a time?

TLDR - How can I batch tensorflow data without modifying an existing architecture which is designed for one sample at a time?",0,1
57,2017-11-22,2017,11,22,13,7eo4k0,Imagine having to pay for Google Dev Package or Open Source Dev Package. Join the Battle for Net Neutrality.,https://www.reddit.com/r/tensorflow/comments/7eo4k0/imagine_having_to_pay_for_google_dev_package_or/,TheNASAguy,1511324363,,4,54
58,2017-11-22,2017,11,22,18,7epuku,Object detection repo broken,https://www.reddit.com/r/tensorflow/comments/7epuku/object_detection_repo_broken/,theoneandonlypatriot,1511344614,"If I try to train using sample configs I either get no bounding boxes or errors that seem to come from the library; for example: complaining about ""ssd feature extractor"" if I try to run an ssd mobilenet config ",0,1
59,2017-11-23,2017,11,23,1,7erzhn,Cant access the inception-2015-12-05.tgz needed for recognizing images in tensorflow,https://www.reddit.com/r/tensorflow/comments/7erzhn/cant_access_the_inception20151205tgz_needed_for/,[deleted],1511366710,[deleted],0,1
60,2017-11-23,2017,11,23,2,7esucw,Having trouble keeping shapes consistent in Python. Do the C++ bindings help?,https://www.reddit.com/r/tensorflow/comments/7esucw/having_trouble_keeping_shapes_consistent_in/,last_useful_man,1511373397,"I'm working through the Coursera Convolutional Deep Learning course (uses Python), and man, I'm having trouble getting / keeping the dimensions of my tensors correct, and, as a C++ programmer, I keep wishing that the API was templated on shape, which it seems not to be. Does, after all, using C++ help /at all/ with keeping this or other book-keeping straight, that you'd normally expect from a static language? It looks like not. 

Any other insights about using the C++ bindings vs Python?
Thanks. ",0,1
61,2017-11-23,2017,11,23,4,7etqmb,Is there a way to add classes to Inception-v3 already defined 1000 class model?,https://www.reddit.com/r/tensorflow/comments/7etqmb/is_there_a_way_to_add_classes_to_inceptionv3/,AllHailTheCATS,1511380410,I need to be able to keep the already defined classes but want to add own extra classes so it can recognize numbers from the MNIST dataset.,0,1
62,2017-11-23,2017,11,23,15,7extqq,Importing features from a CSV file,https://www.reddit.com/r/tensorflow/comments/7extqq/importing_features_from_a_csv_file/,Monicaesque,1511420311,I have a csv file with first column as labels from 0-9(1000 labels) and column 1-1023 with pixel values of 32*32 image sets. There are around 1000 images in training example. How do I manage my train_data and train_data_labels?,1,1
63,2017-11-23,2017,11,23,17,7eyar0,TensorFlow,https://www.reddit.com/r/tensorflow/comments/7eyar0/tensorflow/,ridhimasane,1511426494,,0,1
64,2017-11-23,2017,11,23,20,7ez0gl,how to use python retrain Tensorflow Inception model to add new classes on windows,https://www.reddit.com/r/tensorflow/comments/7ez0gl/how_to_use_python_retrain_tensorflow_inception/,AllHailTheCATS,1511435997,"Im currently retraining the model to recognize hand drawn images on top of the 1000 classes already trained for. Is there a python way of doing what they do with bazel? I already started dividing my photos into folders for retraining.

Tutorial: https://www.tensorflow.org/tutorials/image_retraining",2,2
65,2017-11-24,2017,11,24,0,7f0ii2,Do you need a laptop with good GPU to make good use of tensorflow?,https://www.reddit.com/r/tensorflow/comments/7f0ii2/do_you_need_a_laptop_with_good_gpu_to_make_good/,yccheok,1511452724,"Hi all,

I'm plan to go through the entire https://www.udacity.com/course/deep-learning--ud730 course. The above course does make use of TensorFlow

Recently, my old laptop spoiled, and I'm going to get a ThinkPad X1 Carbon (5th gen)

I'm an Android developer by profession, so the above laptop will suit my need.

However, I understand that for deep learning, using TensorFlow, might require a lot of GPU processing. 

The above laptop comes with Intel HD Graphics 620. 

Since it doesn't come with a dedicated GPU (Like NVIDIA), I was wondering will I face any difficulty while going through the course &amp; having obstacle when developing some useful real-world application using deep learning technique?

If so, I might change my laptop purchasing plan.

Thanks.",13,2
66,2017-11-25,2017,11,25,5,7fa524,Docker crashing on tensorflow start.,https://www.reddit.com/r/tensorflow/comments/7fa524/docker_crashing_on_tensorflow_start/,pcvision,1511555475,"Has anyone had any experience with docker containers exiting when Tensorflow starts?
I currently have it working on local in the same docker container, but on my Digital Ocean droplet, I cannot get it working.

I believe the error is occurring here:
https://github.com/jrobchin/lyterai/blob/master/app/hub/demo/keras_demo.py

I am running Tensorflow within a Django server in Docker and when I try to make a prediction I get this output:

    python_1          | 2017-11-24 20:18:24.198764: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
    python_1          | 2017-11-24 20:18:24.200163: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
    python_1          | 2017-11-24 20:18:24.200171: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
    python_1          | 2017-11-24 20:18:24.200174: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
    python_1          | 2017-11-24 20:18:24.200177: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
    project_python_1 exited with code 0
   ",0,1
67,2017-11-25,2017,11,25,7,7faxpn,CNN for Short-Term Stocks Prediction using Tensorflow,https://www.reddit.com/r/tensorflow/comments/7faxpn/cnn_for_shortterm_stocks_prediction_using/,psangrene,1511562942,,3,8
68,2017-11-25,2017,11,25,23,7ffctx,What is the release date for tensorflow 1.5?,https://www.reddit.com/r/tensorflow/comments/7ffctx/what_is_the_release_date_for_tensorflow_15/,dexter4121,1511618490,,0,0
69,2017-11-27,2017,11,27,3,7foqwa,MNIST NN: ValueError: GraphDef cannot be larger than 2GB.,https://www.reddit.com/r/tensorflow/comments/7foqwa/mnist_nn_valueerror_graphdef_cannot_be_larger/,[deleted],1511721354,[deleted],0,1
70,2017-11-27,2017,11,27,4,7foy87,The Official Feedback Thread,https://www.reddit.com/r/tensorflow/comments/7foy87/the_official_feedback_thread/,TheNASAguy,1511723123,"Here you can suggest modifications, changes or additions to this sub to make it better.",5,1
71,2017-11-27,2017,11,27,4,7fp4f9,Could use help with this,https://www.reddit.com/r/tensorflow/comments/7fp4f9/could_use_help_with_this/,ThatBulgarian,1511724613,"Hi,
I'm watching ""TensorFlow and Deep Learning without a PhD, Part 1 (Google Cloud Next '17)"" on youtube and following along but for the life of me I cant make **my** code work

[here's a google drive link to it](https://drive.google.com/file/d/1K9kRLwvqjiVVQmeWliPHKnEGw4XoOzV9/view?usp=sharing)

Basically ""mnist_1.0_softmax.py"" is the file from the video and ""MyNumberClassifier.py"" is my one with more understandable variable names such as ""image"" instead of ""X"" and ""predictedAnswer"" instead of ""Y_""

And all *should* be well **but** when it's run, it seems like the backpropagation in line 73
    session.run(trainStep,feed_dict={image: batchX, correctAnswer: batchY})) 
isnt working

So it would be amazing if someone could help :)",3,1
72,2017-11-27,2017,11,27,22,7fv2h4,Parametric tSNE implemented in Python using Tensorflow,https://www.reddit.com/r/tensorflow/comments/7fv2h4/parametric_tsne_implemented_in_python_using/,JakeTheSnake2,1511788379,,0,5
73,2017-11-28,2017,11,28,6,7fylpl,Example using keras.utils.sequence to train a model?,https://www.reddit.com/r/tensorflow/comments/7fylpl/example_using_kerasutilssequence_to_train_a_model/,spline_reticulator,1511817891,The [docs](https://keras.io/utils/#sequence) say the sequence class is preferable to generators when training models using multiprocessing. Does anyone know of such an example?,1,2
74,2017-11-28,2017,11,28,17,7g2pr7,(python) reading measurement from image. point me in a direction. (work related),https://www.reddit.com/r/tensorflow/comments/7g2pr7/python_reading_measurement_from_image_point_me_in/,naaksu,1511857376,"Hi.

I am doing measurements sometimes at clients, and i took a image with my phone from the lense of the scope i use to measure with.

[(IMAGE)](https://imgur.com/a/XwiOK)

i then got the idea to order a raspberry pi and a camera to it, wich il program to transmit the images to my laptop with wlan trough socks. so i can take measurements form places i cannot physically be in, (tight places)

assuming i can get a better detailed image as linked, would it be possible to get a measurement read from the image?

if i could make x coordinates of the lines (covering up the bottom lines to not confuse it) 

assuming a better quality image, how would i go on about this? number recognition, and train by snippets of sample data, or should i try some image recognition where my only training data is those 3different sized lines and those numbers? 

i tought id train and research until my camera arrives, would be nice to have that as added feature.

EDIT: i shoudl clarify that i am not familiar with tensorflow, at all. i did install it and playing around with it. but i think i might not choose the best aproach by my self.",3,3
75,2017-11-29,2017,11,29,1,7g5hz4,Manual locking with queues not working as expected,https://www.reddit.com/r/tensorflow/comments/7g5hz4/manual_locking_with_queues_not_working_as_expected/,quadraticalgebra,1511887962,"I'm trying to use a FIFOQueue to make a variable increment atomic. The code doesn't work, both workers return values under 200 (whereas if locking worked properly, that would be the final value of `x`, which at least one worker would see).

Here's what I'm running:

    import sys, tensorflow as tf

    cluster_spec = tf.train.ClusterSpec({
        ""parameter_server"": [""localhost:2222""],
        ""worker"": [""localhost:2223"", ""localhost:2224""]
    })
    job_name = sys.argv[1]
    task_index = int(sys.argv[2])
    server = tf.train.Server(cluster_spec, job_name=job_name, task_index=task_index)
    
    if job_name == ""parameter_server"":
        server.join()
    
    with tf.device(""/job:parameter_server/task:0""):
        x = tf.Variable(tf.zeros([1]), name=""x"")
        x_lock = tf.FIFOQueue(1, tf.bool, shared_name=""x_lock"")
    
    with tf.control_dependencies([x_lock.enqueue(True)]):
        with tf.control_dependencies([x.assign(x.read_value()+1)]):
            add_op = x_lock.dequeue()
    
    with tf.Session(server.target) as sess:
        sess.run(tf.global_variables_initializer())
        for _ in range(100):
            res = sess.run(add_op)
    
        print(res, sess.run(x))

Any hints as to what is going wrong? Thanks!",0,1
76,2017-11-30,2017,11,30,7,7ghb0r,Tensor flow: Cannot use batch normalization during testing,https://www.reddit.com/r/tensorflow/comments/7ghb0r/tensor_flow_cannot_use_batch_normalization_during/,Xyoloswag420blazeitX,1511994468,,3,1
77,2017-11-30,2017,11,30,17,7gkvhp,TensorFlow and Google Cloud ML,https://www.reddit.com/r/tensorflow/comments/7gkvhp/tensorflow_and_google_cloud_ml/,4ocmotpum,1512029801,"So im student and we at school are working at one project now, we are starting today but no one knows anything about TF and GCML, im interested in how to combine models made in TensorFlow and Google cloud ml, links and any good info in coments would be great help :)",1,1
78,2017-11-30,2017,11,30,18,7gl6x7,Use TensorFlow instead of NumPy to accelerate operations.,https://www.reddit.com/r/tensorflow/comments/7gl6x7/use_tensorflow_instead_of_numpy_to_accelerate/,EconEuler,1512034209,"Hi!

I've spent some time recently investigating how to accelerate array manipulation operations in Python. I started looking at CPU and GPU decorators such as @jit, @cuda.jit, @vectorize and so on from Numba.

When asking around I got some tips that I could use e.g. PyTorch which is a scientific computing package used for:

- Replacement for numpy to use the power of GPU's
- A deep learning research tool

Since TensorFlow has become the state of the art regarding tensor operations I was wondering if TensorFlow could be a viable option for my tasks.

By looking into the documentation I found pages such as:

https://www.tensorflow.org/versions/r0.12/api_docs/python/control_flow_ops/logical_operators

https://www.tensorflow.org/versions/r0.12/api_docs/python/math_ops/

Indicating that it would be possible.

For example right now I have a function that I use for ""sorting"" values into boxes and counting how many values are in each box. The code for this:


    def function(x, y):
        xi = np.arange(200,2500,50)
        yi = np.arange(200,2500,50)
        dx,dy = (xi[1]-xi[0])/2, (yi[1]-yi[0])/2
        grid_x = np.zeros(len(xi)*len(yi))
        grid_y = np.zeros(len(xi)*len(yi))
        grid_z_time_spend = np.zeros(len(xi)*len(yi))
        i = 0

        for col in xi:
            for row in yi:
                first_cell = np.where(((x &gt; col-dx)) &amp; (x &lt;=         
                 col+dx) &amp; ((y &gt; (row-dy))) &amp; (y &lt;=     
                 (row+dy)))
            
                grid_x[i] = col
                grid_y[i] = row
                grid_z_time_spend[i] =len(first_cell[0])
                i += 1
    
        grid_z_time_spend[grid_z_time_spend == 0] = 
        'nan'
        grid_z_perc =         
        grid_z_time_spend/
        np.nansum(grid_z_time_spend)*100
    
    return grid_x, grid_y, grid_z_perc

When I have gotten the boxes (grid_x and grid_y) I can plot them with matplotlib and add grid_z as the coloring. The reason I need to pre-process the data like this is because I have very large datasets (many times over 100GB).


So my question to the TensorFlow community would be if you think this is a good use of the package (i.e. to GPU accelerate ""numpy-like"" operations), or if I should rather try out e.g. PyTorch? I have only used TensorFlow's high level API for neural network modelling, but never used it for anything else.

Any thoughts are very appreciated!

Thanks!",10,4
0,2017-12-1,2017,12,1,19,7gu70i,tf.add returning just returning the 1st argument,https://www.reddit.com/r/tensorflow/comments/7gu70i/tfadd_returning_just_returning_the_1st_argument/,shayanrc,1512124160,"I'm just starting with learning tensorflow.

    with tf.Session() as session:
       a = tf.placeholder(tf.float32)
       b = tf.placeholder(tf.float32)
       c = a+b
       print(session.run(c, feed_dict={a:3,b:2}))

The above program should print out 5. But it just prints out what ever I put as a value for `a`. Could anyone please point out what I'm doing wrong?

EDIT:
This seems to be some sort of a configuration issue. It's only behaving this on one machine.

Some background information:

- I am using the GPU version of tensorflow.

- I have installed this using conda: conda install tensorflow-gpu. 

- I am running this on docker. 

- This works fine if I change the placeholder type to int32",0,1
1,2017-12-2,2017,12,2,1,7gvwq0,creating dynamic batch size and weights initialization in tensorflow,https://www.reddit.com/r/tensorflow/comments/7gvwq0/creating_dynamic_batch_size_and_weights/,saurabhvyas3,1512144162,"I am having issues, creating a dynamic batch size in tensorflow , basically I am training a model on my pc with batch size of 4 and saving it in some file , in separate inference file, I am restoring saved model , but for inference I require batch size = 1, now the problem is since the saved model stored network weights according to batch_size =4 , it's casing problems 

On training code side, I have tried the following :

    inputs = tf.placeholder(tf.float32, [None, None, num_features])
    targets = tf.sparse_placeholder(tf.int32)
    seq_len = tf.placeholder(tf.int32, [None])
    batch_size = tf.shape(inputs[0])[0]


    weights = {
        'out': tf.Variable(tf.random_normal([batch_size, 2 * num_hidden, 
    num_classes]))
    }
    biases = {
        'out': tf.Variable(tf.random_normal([num_classes]))
}

but it gives the following error :
    ValueError: initial_value must have a shape specified: 
    Tensor(""random_normal_1:0"", shape=(?, 256, 9), dtype=float32)

can anyone help ?",7,1
2,2017-12-2,2017,12,2,18,7h1tpo,"TFLearn, or tensorflow.contrib.learn, or tf.estimator?",https://www.reddit.com/r/tensorflow/comments/7h1tpo/tflearn_or_tensorflowcontriblearn_or_tfestimator/,bwllc,1512207593,"I've been tooling around with Tensorflow and [TFLearn](http://tflearn.org/) for a few months.  I've made some progress.  However, I was expecting to be able to construct a functioning scikit-learn type Estimator as a TFLearn.DNN().  I can fit(), and I can predict(), but I can't do cross-validation because evaluate() is failing for me.  Tensorflow is throwing...

    ValueError: Cannot use the given session to evaluate tensor: the tensor's graph is different from the session's graph. 

when I call evaluate().  I thought the whole point of the TFLearn API was to abstract things like Session management away from my code.

I have asked questions about problems I've had with TFLearn in several forums, including on [the project's GitHub page](https://github.com/tflearn/tflearn/issues).  Unfortunately I'm not getting any answers, just silence.

A few days ago, suddenly I encountered the tensorflow.contrib.learn namespace, and I'm seeing a lot of overlap between those classes and TFLearn.  And then, I found the tf.estimator class.

Finally, I just learned that tensorflow.contrib sub-packages are third-party contributions.  This leads me to wonder whether the original TFLearn is simply being absorbed into the larger Tensorflow package.  Which direction is the code flowing, and where do I find a group of interested and engaged developers?

I don't care what I use, as long as I get all the functionality of a scikit-learn estimator object.

Thanks for any guidance you can provide!",4,3
3,2017-12-3,2017,12,3,16,7h8fxz,Create Tensorflow Environment and Install packages using conda - Anaconda Navigator #explained,https://www.reddit.com/r/tensorflow/comments/7h8fxz/create_tensorflow_environment_and_install/,developerbytes,1512286211,,0,7
4,2017-12-4,2017,12,4,8,7hder1,Custom Keras Layer using TF ops,https://www.reddit.com/r/tensorflow/comments/7hder1/custom_keras_layer_using_tf_ops/,beef__,1512344962,"Hate to ask a question like this on reddit but googling has yielded nothing useful - I've just found 2 github threads where people on super old versions of tensorflow got the same error *message*, but not for the same reason im getting it.

Basically; I'm implementing this facial point paper for work; and it uses spatial softargmax (just a layer that takes in a stack of images a lot like [this](https://i.imgur.com/YILPB6H.png) - and it returns the most ""intense part"" of the image (so just the x,y coordinates of the white blob). It takes in an array with 68 of these images (all 1 channel, so the array is 100x100x68) and it gives 68 pairs of x,y coordinates for each one - these end up being the facial points.

The layer I have written in keras to do this is;

    class spatial_softArgmax(Layer):
    
    		def __init__(self, output_dim, **kwargs):
    				self.output_dim = 136#output_dim
    				super(spatial_softArgmax, self).__init__(**kwargs)

    		def build(self, input_shape):
    				# Create a trainable weight variable for this layer.
    				self.kernel = self.add_weight(name='kernel', shape=(input_shape[1], self.output_dim), initializer='uniform', trainable=True)
    					super(spatial_softArgmax, self).build(input_shape)  # Be sure to call this somewhere!

    			def call(self, x):
    					filters = x
    					temperature = 1.0
    					shape = tf.shape(filters)
    					height, width, num_channels = shape[1], shape[2], shape[3]

    					posx, posy = tf.meshgrid(tf.lin_space(-1., 1., num = height),
    																	 tf.lin_space(-1., 1., num = width),
    																	 indexing='ij')
    					posx = tf.reshape(posx, [height * width])
    					posy = tf.reshape(posy, [height * width])

    					filters = tf.reshape(tf.transpose(filters, [0, 3, 1, 2]), [-1, height * width])

    					softmax_attention = tf.nn.softmax(filters / temperature)

    					expected_x = tf.reduce_sum(posx * softmax_attention, 1, keep_dims = True)
    					expected_y = tf.reduce_sum(posy * softmax_attention, 1, keep_dims = True)

    					expected_xy = tf.concat([expected_x, expected_y], axis = 1)

    					feature_keypoints = tf.reshape(expected_xy, [-1, num_channels * 2])

    					return feature_keypoints


    			def get_config(self):
    					config = super(spatial_softArgmax, self).get_config()
    					config['output_dim'] = self.output_dim
    					config['input_shape'] = self.input_shape
    					return config

    			def compute_output_shape(self, input_shape):
    					return (input_shape[0], self.output_dim)


It isn't working though; like at all; I keep getting this error that says 'None Values not supported' - which makes me think that my layer isn't returning anything?? I dug around in the TF code a bit around where this exception is raise but didn't really find much...

If you guys see anything wrong with my layer just by glancing i'd really appreciate it if you'd let me know; I *need* to have this network training overnight tonight.",3,3
5,2017-12-4,2017,12,4,10,7he121,How does one use Hermite polynomials with Stochastic Gradient Descent (SGD)?,https://www.reddit.com/r/tensorflow/comments/7he121/how_does_one_use_hermite_polynomials_with/,real_charlie_parker,1512351213,,0,5
6,2017-12-4,2017,12,4,20,7hgq6s,Dynamic Batch_size using data.Dataset,https://www.reddit.com/r/tensorflow/comments/7hgq6s/dynamic_batch_size_using_datadataset/,senorstallone,1512386655,"I wish to increase the batch_size during train, but I'm not finding an easy way to implement this using data.Dataset pipeline. Any ideas?",2,2
7,2017-12-4,2017,12,4,21,7hgyv0,Best practice for situational model differences,https://www.reddit.com/r/tensorflow/comments/7hgyv0/best_practice_for_situational_model_differences/,Harawaldr,1512390044,"Sometimes you want your model to behave differently in a training setting versus inference setting. An obvious example of this is the keep probability when using dropout. Under training you want it to be &lt; 1, and at inference/testing it should be 1.

At the moment, I am working on a model with several parameters like this. I am wondering what is the best way to approach them. I see several possibilities:

1. I can enter all relevant parameters as placeholders. What I don't like about this is that it clutters up my feed dict.

2. I can feed one boolean value, is_training and use this to decide on parameters using tf conditionals hidden in the model definition. I have heard that tf conditionals should be avoided when possible, because they are slow.

3. I can define separate subgraphs with different parameters for different situations and do parameter sharing between them, somehow.

Are there any options I've missed? Have you had a similar design decision to make? What considerations should I take into account?

edit: typo",0,1
8,2017-12-5,2017,12,5,4,7hjlsq,is tensorflow good for log analysis? Here's what I'm trying to do,https://www.reddit.com/r/tensorflow/comments/7hjlsq/is_tensorflow_good_for_log_analysis_heres_what_im/,retinascan,1512415096,"I have servers that run jobs. 

Jobs consist of subjobs. Subjobs process data and do so in a certain amount of time. For the most part, a job takes the same amount of time given the rate of change in data is somewhat constant.

So my thought was, can I give a bunch of data to a library about jobs. Data such as 

start time, end time, of job
number of subjobs
start time, end time of subjobs
amount of data moved in each subjob

If I give ""something"" enough of this data, would it be able to identify causes for why a job might run longer in future job runs?

i.e. job X ran longer than normal because the number of subjobs was 2x the normal.

or

job X ran longer than normal because this one subjob had 3x more data than normal.

things like that.

I don't know anything about machine learning but i'm trying to understand more and apply it in a sensible way. So if my above examples are total crap, please don't hesitate to say so.

Are there projects similar to this that I can learn from?

thanks.",8,2
9,2017-12-7,2017,12,7,8,7i22g7,Application for 3D shape optimisation in optics?,https://www.reddit.com/r/tensorflow/comments/7i22g7/application_for_3d_shape_optimisation_in_optics/,PhotonWorks,1512602123,"I am working with Light Tools to design and optimise a 3D freeform shape with two active surfaces (top and bottom). I can choose the number of points I want (say top and bottom grids of 45 x 45) to define my surfaces thus allowing for better control of light rays.

Sadly, it is only limited to two freeform surfaces and it looks like there are no valid shapes able to bend the light at the sharp angles I am looking for. 

Would it be possible to teach tensorflow to recognise how different curved surfaces bend light to create more complex freeform shapes? My guess is that it will end up having 3 or more surfaces through which the light would be able to be refracted to get where I want.  ",0,2
10,2017-12-7,2017,12,7,10,7i339f,Visualize Training Results With TensorFlow summary and TensorBoard,https://www.reddit.com/r/tensorflow/comments/7i339f/visualize_training_results_with_tensorflow/,seabass,1512611961,,0,1
11,2017-12-7,2017,12,7,17,7i4yih,Google brings Core ML support to TensorFlow Lite,https://www.reddit.com/r/tensorflow/comments/7i4yih/google_brings_core_ml_support_to_tensorflow_lite/,AhmedGadFCIT,1512633753,,0,1
12,2017-12-7,2017,12,7,20,7i5uze,"Building my own tf.Estimator, how did model_params overwrite model_dir? RuntimeWarning?",https://www.reddit.com/r/tensorflow/comments/7i5uze/building_my_own_tfestimator_how_did_model_params/,bwllc,1512646940,"Hi there,

Recently I built customized deep neural net model using TFLearn, which claimed to bring deep learning to the scikit-learn estimator API.  I could train models and make predictions, but I couldn't get the scoring (evaluate) function to work, so I couldn't do cross-validation.  I tried to ask questions about TFLearn in various places, but I got no responses.

It appears that TensorFlow itself has an estimator class.  I'm trying to follow the guide at https://www.tensorflow.org/extend/estimators.  Somehow I'm managing to get variables where they don't belong.  Can anyone spot my problem?  I will post code and the output.

Note: I can see the RuntimeWarning at the top of the output.  I have found references to this warning online, but so far everyone claims it's harmless.  Maybe it is not...

**CODE**
    
    import tensorflow as tf
    from my_library import Database, l2_angle_distance
   

    def my_model_function(topology, params):

        # This function will eventually be a function factory.  This should
        # allow easy exploration of hyperparameters.  For now, this just
        # returns a single, fixed model_fn.
        
        def model_fn(features, labels, mode):

            # Input layer
            net = tf.layers.conv1d(features[""x""], topology[0], 3, activation=tf.nn.relu)
            net = tf.layers.dropout(net, 0.25)
            # The core of the network is here (convolutional layers only for now).
            for nodes in topology[1:]:
                net = tf.layers.conv1d(net, nodes, 3, activation=tf.nn.relu)
                net = tf.layers.dropout(net, 0.25)
            sh = tf.shape(features[""x""])
            net = tf.reshape(net, [sh[0], sh[1], 3, 2])
            predictions = tf.nn.l2_normalize(net, dim=3)
            
            # PREDICT EstimatorSpec
            if mode == tf.estimator.ModeKeys.PREDICT:
                return tf.estimator.EstimatorSpec(mode=mode,
                        predictions={""vectors"": predictions})

            # TRAIN or EVAL EstimatorSpec
            loss = l2_angle_distance(labels, predictions)
            optimizer = tf.train.GradientDescentOptimizer(learning_rate=params[""learning_rate""])
            train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())
            return tf.estimator.EstimatorSpec(mode, predictions, loss, train_op)
        
        return model_fn

    ##===================================================================

    window = ""whole""
    encoding = ""one_hot""
    db = Database(""/home/bwllc/Documents/Files for ML/compact"")

    traindb, testdb = db.train_test_split()
    train_features, train_labels = traindb.values(window, encoding)
    test_features, test_labels = testdb.values(window, encoding)

    # Create the model.
    tf.logging.set_verbosity(tf.logging.INFO)
    LEARNING_RATE = 0.01
    topology = (60,40,20)
    model_params = {""learning_rate"": LEARNING_RATE}
    model_fn = my_model_function(topology, model_params)
    model = tf.estimator.Estimator(model_fn, model_params)
    print(""\nmodel_dir?  No?  Why not? "", model.model_dir, ""\n"")  # This documents the error

    # Input function.
    my_input_fn = tf.estimator.inputs.numpy_input_fn({""x"" : train_features}, train_labels, shuffle=True)

    # Train the model.
    model.train(input_fn=my_input_fn, steps=20)


**OUTPUT**

    /usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
      return f(*args, **kwds)
    INFO:tensorflow:Using default config.
    INFO:tensorflow:Using config: {'_model_dir': {'learning_rate': 0.01}, '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0b55279048&gt;, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}

    model_dir?  No?  Why not?  {'learning_rate': 0.01} 

    INFO:tensorflow:Create CheckpointSaverHook.
    Traceback (most recent call last):
      File ""minimal_estimator_bug_example.py"", line 81, in &lt;module&gt;
        model.train(input_fn=my_input_fn, steps=20)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py"", line 302, in train
        loss = self._train_model(input_fn, hooks, saving_listeners)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py"", line 756, in _train_model
        scaffold=estimator_spec.scaffold)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/basic_session_run_hooks.py"", line 411, in __init__
        self._save_path = os.path.join(checkpoint_dir, checkpoint_basename)
      File ""/usr/lib/python3.6/posixpath.py"", line 78, in join
        a = os.fspath(a)
    TypeError: expected str, bytes or os.PathLike object, not dict

    ------------------
    (program exited with code: 1)
    Press return to continue


I can see exactly what went wrong, model_dir (which I left as the default) somehow bound to the value I intended for model_params.  How did this happen in my code?  I can't see it.

If anyone has advice or suggestions, I would greatly appreciate them.  Thanks!
",2,1
13,2017-12-8,2017,12,8,20,7iedum,Tensorboard can't show GRAPH and nodes,https://www.reddit.com/r/tensorflow/comments/7iedum/tensorboard_cant_show_graph_and_nodes/,GeForceKawaiiyo,1512732293,"Hello, when I'm running TF deep learning code, and doing the tensorboard visualization, everything in tensorboard, such as SCALARS, IMAGES, DISTRIBUTIONS showed well ---- except GRAPH option, which should've shown me main graph and many defined nodes, showed nothing. It happened when I opened tensorboard GRAPH and after loading a little while, It's just empty. Can anybody be kind enough to provide help? Many thanks.
BTW, if any help, the device is Ubuntu 16.04, using GPU and tf version is 1.2.0,  python 2.7, and tensorboard is newly pip installed.",1,2
14,2017-12-9,2017,12,9,7,7iilp7,Need some help due to ValueError,https://www.reddit.com/r/tensorflow/comments/7iilp7/need_some_help_due_to_valueerror/,stoptrollingmepls,1512772708,"I'm trying to run https://github.com/jmiller656/EDSR-Tensorflow on gpu but keep getting a value error when i try to test. I reinstalled cuda 8.0 with cudnn8.0 but that didn't fix the issue. The error comes during the summary writing and states that an array element can't be a sequence.

Traceback (most recent call last):
  File ""train.py"", line 18, in &lt;module&gt;
    network.train(args.iterations,args.savedir)
  File ""/media/user/Cuda/Proojects/EDSR-Tensorflow/model.py"", line 218, in train
    summary,_ = sess.run([merged,train_op],feed)
  File ""/home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 895, in run
    run_metadata_ptr)
  File ""/home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1093, in _run
    np_val = np.asarray(subfeed_val, dtype=subfeed_dtype)
  File ""/home/user/anaconda2/lib/python2.7/site-packages/numpy/core/numeric.py"", line 531, in asarray
    return array(a, dtype, copy=False, order=order)
ValueError: setting an array element with a sequence.
",1,1
15,2017-12-9,2017,12,9,15,7ila94,Google shares developer preview of TensorFlow Lite,https://www.reddit.com/r/tensorflow/comments/7ila94/google_shares_developer_preview_of_tensorflow_lite/,weetechsolution,1512801877,,0,1
16,2017-12-10,2017,12,10,6,7ipgmn,Classifying array of strings,https://www.reddit.com/r/tensorflow/comments/7ipgmn/classifying_array_of_strings/,azakhary,1512854139,"Hi,

I have bunch of data in form of arrays of strings corresponding to boolean answers. 

Example: [""aaa"", ""zzz""] = true, [""bbb"", ""ssdsd"", ""tmp""] = false

and so on.
I assume this is some kind of classification problem, and I would be thankful if you can point me in the direction of some kind of tutorial or docs for TensorFlow that solves exactly that. I am very much beginner in this. 

If there is no tutorial on this matter, then a simple ""this problem is called XXX and is usually solved with YYY method"" will be enough as well. Thank you!
",2,1
17,2017-12-11,2017,12,11,22,7j26u2,[Warning] Tensorflow wasn't compile to use SSE instruction,https://www.reddit.com/r/tensorflow/comments/7j26u2/warning_tensorflow_wasnt_compile_to_use_sse/,Auxire,1512999072,"Greetings everyone. I have similiar issue with one here : 
&gt; https://github.com/tensorflow/tensorflow/issues/7540

I got this message over and over again
&gt; The TensorFlow library wasn't compiled to use SSE instructions, but these are available on your machine and could speed up CPU computations.

Now it is solved by putting this code before importing tensorflow
&gt; import os
&gt; os.environ['TF_CPP_MIN_LOG_LEVEL']='2'

As far as I understand, the message means a warning that I can compile Tensorflow so it can use SSE instruction to speed up CPU computations. The code above simply hide this warning. 

My question is, how do I compile Tensorflow so I can use SSE instruction?",1,5
18,2017-12-12,2017,12,12,4,7j4kjd,How does TF compute convolutions?,https://www.reddit.com/r/tensorflow/comments/7j4kjd/how_does_tf_compute_convolutions/,terrrp,1513020553,"Could anybody explain and point me to a concrete convolution implementation in TF (or any clean canonical implementation)? I am curious as to which way(s) they do it based on performance. I tried to look into the code base but obviously it delegates code all over the place, and uses vendor libraries like cuda.

The ways I am aware of are:

1. Naive sum per resulting pixel

2. Parallel sum per resulting pixel (with a lot of GPU memory access optimizations probably)

3. The 'im2col' dense matrix multiplication outlined [here](http://cs231n.github.io/convolutional-networks/#conv)

4. FFT which is not helpful here",1,2
19,2017-12-12,2017,12,12,23,7jb5tl,Is TensorFlow the correct tool to try to recognize this text?,https://www.reddit.com/r/tensorflow/comments/7jb5tl/is_tensorflow_the_correct_tool_to_try_to/,Wirebraid,1513090052,"Hello,

I need to recognize the text in this image:

https://ibb.co/fJ0gVG

It's text from a Windows XP Notepad, so I'm thinking about using TensorFlow to recognize it, because I can reproduce a training image with all the characters.

I'm not here to ask for my homework, but some directions would be really useful.

Is TensorFlow the adequate tool?
Is it a doable task for a CS graduate without any NN experience?
Is there any specific topic I should Google to read and learn? Maybe some starting tutorial related with this task.

Any help is really welcome. Thanks a lot.",7,2
20,2017-12-13,2017,12,13,6,7je4x6,Tensorflow MNIST - what if my images are greyscale and not black and white?,https://www.reddit.com/r/tensorflow/comments/7je4x6/tensorflow_mnist_what_if_my_images_are_greyscale/,[deleted],1513114227,[deleted],0,1
21,2017-12-13,2017,12,13,9,7jfd4g,Tensorflow Estimator: using predict() function in separate script,https://www.reddit.com/r/tensorflow/comments/7jfd4g/tensorflow_estimator_using_predict_function_in/,doktorneergaard,1513125169,,0,2
22,2017-12-14,2017,12,14,5,7jlwpt,Getting batches from preloaded data?,https://www.reddit.com/r/tensorflow/comments/7jlwpt/getting_batches_from_preloaded_data/,SamStringTheory,1513195428,"I have data that fits entirely into memory, so I followed the guide here (https://www.tensorflow.org/versions/r0.12/how_tos/reading_data/) to load the data into tf variables. And I want to get (shuffled) batches from this data to feed into my model. What would be the easiest way to do this? The following is what I have so far, but it hangs on the last statement.


    train_X = np.arange(1, 10)
    train_Y = np.arange(11, 20)

    with tf.Session() as sess:
        data_initializer = tf.placeholder(dtype=train_X.dtype, shape=train_X.shape)
        label_initializer = tf.placeholder(dtype=train_Y.dtype, shape=train_Y.shape)
        input_data = tf.Variable(data_initializer, trainable=False, collections=[])
        input_labels = tf.Variable(label_initializer, trainable=False, collections=[])
        sess.run(input_data.initializer, feed_dict={data_initializer: train_X})
        sess.run(input_labels.initializer, feed_dict={label_initializer: train_Y})

        x, y = tf.train.slice_input_producer([input_data, input_labels], capacity=100)
        xs, ys = tf.train.batch([x, y], 5, allow_smaller_final_batch=True)
        print(sess.run(xs))",3,1
23,2017-12-14,2017,12,14,5,7jm8er,Initialize TensorFlow Variables That Depend On Other TensorFlow Variables,https://www.reddit.com/r/tensorflow/comments/7jm8er/initialize_tensorflow_variables_that_depend_on/,seabass,1513198119,,3,1
24,2017-12-14,2017,12,14,11,7jogaq,Are very low values for softmax results a problem?,https://www.reddit.com/r/tensorflow/comments/7jogaq/are_very_low_values_for_softmax_results_a_problem/,goomba870,1513217397,"I have modified the [mnist_softmax.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist_softmax.py) input to take greyscale images (0-254 per pixel) instead of the MNIST black and white images. I have also increased the number of labels to around 100 instead of the 10 that represent the 0-9 handwritten labels. Otherwise the example is mostly unchanged. Input data size and training size are about the same.

As a result I'm getting about 80% accuracy upon testing the data. Now that number isn't great by ML standards, but for just starting out it's not the worst. I've been tweaking the sample sizes, iterations, etc. but accuracy still tops out at around 80%.

One thing I noticed is that when I test an image against the trained model, even when the results are correct, the softmax results (array of 100 weights representing the labels) are extremely small, say 6.790285E-11. The max value in the softmax array, representing the winning label, is a very very small fraction larger than the rest of the array.

But still, I'm 80% accurate despite these small values. I'm assuming that transforming from [0, 1] to [0, 254] changes things a bit. My labels are still one-hot-vectors, but training and testing data has a new range.

Do you think the small softmax values are indicative of an incorrect model? I'll take any advice you have. Thanks!",2,2
25,2017-12-15,2017,12,15,13,7jxfq1,Problems running tensorflow with anaconda and pycharm.,https://www.reddit.com/r/tensorflow/comments/7jxfq1/problems_running_tensorflow_with_anaconda_and/,dyllll,1513312429,"I have had hell installing tensorflow gpu for the last few days. Finally I have made some progress. If I install exactly like the instructions say, once I activate the environment it works. I can import tensorflow and everything. However if I go to the environment in anaconda navigator and try it from there it fails with the ModuleNotFoundError: No module named '_pywrap_tensorflow_internal' error that usually points to missing dll files but I know that this is not the case. I also tried setting the environment I made when installing in pycharm but I get the same error when running. Any ideas?",7,1
26,2017-12-15,2017,12,15,18,7jyshi,Where can I go to ask really stupid tensorflow questions?,https://www.reddit.com/r/tensorflow/comments/7jyshi/where_can_i_go_to_ask_really_stupid_tensorflow/,lab_fly,1513331928,"I'm pretty proficient in python, but having a hard time moving past the tensorflow tutorials.  Where can I go to ask really stupid questions?  

Things like: I don't understand why my placeholders needs float32 dtypes, but doesn't work when I try to input float16.  That's just an example, but after tinkering around for a few days, I have tons of that type of question and I can't find the answers on SO.",3,13
27,2017-12-16,2017,12,16,3,7k1hwc,Modifying this project to allow custom datasets,https://www.reddit.com/r/tensorflow/comments/7k1hwc/modifying_this_project_to_allow_custom_datasets/,supamonkey2000,1513361756,"Using [this project](https://github.com/carpedm20/pixel-rnn-tensorflow) for a PixelRNN, I want to use my own custom dataset (i.e. 8000 16x16 jpegs). However, browsing the code makes it seem it only supports CIFAR and MNIST.

Could anyone guide me through modifying it or, if possible, modify it for me? I dont want to take too much time away from anyone, but this is for a small school project and my teacher said online help is fine, and I'm not sure where to start. I made an Issue on the project as well.

If anyone is willing to help, I would really appreciate it. Thanks!",1,1
28,2017-12-17,2017,12,17,18,7kd157,Machine Learning with Oracle JET and TensorFlow,https://www.reddit.com/r/tensorflow/comments/7kd157/machine_learning_with_oracle_jet_and_tensorflow/,brunocborges,1513504081,,0,2
29,2017-12-18,2017,12,18,1,7keoe9,How much disk space is needed for the download_and_convert_imagenet script in tf-slim?,https://www.reddit.com/r/tensorflow/comments/7keoe9/how_much_disk_space_is_needed_for_the_download/,karan_42,1513528192,This is the script: https://github.com/tensorflow/models/tree/master/research/slim#an-automated-script-for-processing-imagenet-data,4,1
30,2017-12-18,2017,12,18,6,7kgniz,Microsoft puts Tensorflow icon as my profile picture,https://www.reddit.com/r/tensorflow/comments/7kgniz/microsoft_puts_tensorflow_icon_as_my_profile/,smakosh,1513547254,,2,1
31,2017-12-18,2017,12,18,12,7kiiv5,Tencent's Blade security team find security holes in Tensorflow,https://www.reddit.com/r/tensorflow/comments/7kiiv5/tencents_blade_security_team_find_security_holes/,Knowsnothing,1513566624,,1,0
32,2017-12-19,2017,12,19,4,7knk7v,What happens if I'm running a distributed tensorflow cluster and I lose a worker?,https://www.reddit.com/r/tensorflow/comments/7knk7v/what_happens_if_im_running_a_distributed/,spline_reticulator,1513625759,Does the job stop?,3,2
33,2017-12-19,2017,12,19,6,7ko5i6,How does Google's DeepVariant encode the DNA fastq files into an image?,https://www.reddit.com/r/tensorflow/comments/7ko5i6/how_does_googles_deepvariant_encode_the_dna_fastq/,o-rka,1513630899,"I have been looking into DeepVariant and it says they use neural networks to detect SNPs. What I don't understand is how they encode the sequence and quality values into an image format . Is it 2D? To my understanding one channel is nucleotide, another is quality, and another is metadata . Is the base call channel represented by one hot encoded vectors for each nucleotide? I'm not sure if that could work or if each nucleotide would need its own channel . Did they use 2D convolutions or was this a 1D convolutional layer ? https://research.googleblog.com/2017/12/deepvariant-highly-accurate-genomes.html?m=1",3,1
34,2017-12-19,2017,12,19,7,7koory,What purpose does a normalizer serve in a loss function?,https://www.reddit.com/r/tensorflow/comments/7koory/what_purpose_does_a_normalizer_serve_in_a_loss/,notsofst,1513635650,"Going through some TensorFlow tutorials off of CognativeClass.ai, and in one of their linear regression examples, my linear regression wasn't working until I put a normalizer into the loss function.

Code here: [Link](https://gist.github.com/jswattjr/6ce427a92acdd802317aab8be939001c)

See the 'nf' variable on line 28. What does it do in line 30? It seems like adding 'nf' to both sides of the equation would accomplish nothing, but without it my results are hot garbage.",2,1
35,2017-12-19,2017,12,19,20,7ksszn,Concat two models into one big graph and finetune it,https://www.reddit.com/r/tensorflow/comments/7ksszn/concat_two_models_into_one_big_graph_and_finetune/,simonszu,1513684427,"I want to implement [this paper](https://arxiv.org/abs/1708.03474) in tensorflow. It's approach is to create two separate CNNs at first, and then concatenate them for finetuning (as you can see in figure 1a)). 

My current situation is: I have two pre-trained and saved models, each of them fed with a data queue input (so, no feed_dict and no Dataset API), and now i am off for finetuning. I want to restore them from disk and somehow concatenate them, so that i can define an optimizer which optimizes both networks. 

This is my current approach:


    # Build data input
        aug_img, is_img, it_img = finetuning_read_training_images(trainset_size=num_steps,
                                                                  batch_size=batch_size,
                                                                  cropped=cropped,
                                                                  base_folder=base_folder)
    
        # Load the graphs
        tf.reset_default_graph()
        print(""Loading ECNN graph..."")
        ecnn_graph = tf.train.import_meta_graph(os.path.join(ecnn_path, ""ecnn.meta""), clear_devices=True)
        trained_target = tf.get_default_graph().get_tensor_by_name(""E-CNN/ecnn_output/ecnn_output_convolution/BiasAdd:0"")
        augmented_icnn_input = tf.concat([is_img, trained_target], axis=2)
        icnn_graph = tf.train.import_meta_graph(os.path.join(icnn_path, ""icnn.meta""), clear_devices=True, input_map={""aug_img"": augmented_icnn_input, ""it_img"": it_img, ""is_img"": is_img})

The data input function reads 3 batches. `aug_img` is the source image, which has reflections, e.g. when photographed through a glass panel, augmented with its edge map as a 4th color channel. The ECNN graph should predict the reflection-free edge map. Tensorflow should augment the plain source image, which is stored in the `is_img` variable with the predicted reflection-free edge map, which should happen in the lines beginning with `trained_target` and `augmented_icnn_input`. The augmented image is then fed to the ICNN graph which should create a reflection-free image then, so it is given the `it_img` which is the target image. It is fed the not-augmented source image again, only for tensorboard visualization. 

But now i am unable to further proceed. I cannot concat the both tensors for creating the `augmented_icnn_input` because i get a `ValueError: Tensor(""E-CNN/ecnn_output/ecnn_output_convolution/BiasAdd:0"", shape=(?, 224, 224, 1), dtype=float32) must be from the same graph as Tensor(""batch:1"", shape=(?, 224, 224, 3), dtype=float32).`

Also i seem not to understand the input_map in combination with the data input queue correctly, since although i have had definied the  `aug_img`and other variables in the ICNN, and see them in tensorboard, i do not see them in the `variables` collection and therefore cannot map them. 

So i would like to know: Is this the correct approach to combine two subgraphs in a bigger graph? How can i solve the problem that i am unable to concat the two tensors in `augmented_icnn_input`? And why is my `input_map` not working?",0,1
36,2017-12-20,2017,12,20,0,7ktulo,Which batch normalization implementation to use?,https://www.reddit.com/r/tensorflow/comments/7ktulo/which_batch_normalization_implementation_to_use/,SamStringTheory,1513696497,"When I search for Batch Normalization in Tensorflow, I find three entries: [tf.nn.batch_normalization](https://www.tensorflow.org/api_docs/python/tf/nn/batch_normalization), [tf.layers.batch_normalization](https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization), and [tf.contrib.layers.batch_norm](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/batch_norm). What are the differences, and which one should I use?",5,2
37,2017-12-21,2017,12,21,4,7l3q2e,Difference in results between Optimizer.minimize() and tf.contrib.layers.optimize_loss(),https://www.reddit.com/r/tensorflow/comments/7l3q2e/difference_in_results_between_optimizerminimize/,Tushta,1513798080,"I'm having a strange issue (described in more detail [here](https://stackoverflow.com/questions/47908091/model-seems-to-be-overfitting-with-optimizer-minimize-but-not-tf-contrib-layer)), where my network learns properly only when I add additional dependencies to loss function in train_op. I guess I ""solved"" the problem, as in I have the code that learns, but I find this situation very worrisome: how can I know that when my network doesn't learn, it's not because I'm missing some black magic trickery in code outside of usual trickery related to network architecture itself.
",2,2
38,2017-12-21,2017,12,21,5,7l4bq8,trouble capturing retrain.py's tf.logging.info() in terminal,https://www.reddit.com/r/tensorflow/comments/7l4bq8/trouble_capturing_retrainpys_tflogginginfo_in/,mario-the-champion,1513803204,"i ve been building a python command line app to explore google's tensorflow image classification -- make it easy to download loads of images, auto-sort them, use them to retrain a classifier, which in turn makes for better sorting, retraining, etc.

one huge issue, for which i have an ugly workaround, is trouble capturing, specifically, the final test accuracy. (see https://github.com/tensorflow/tensorflow/issues/3047)

i wrote up a long version of my workaround at https://github.com/mariochampion/roboflow/issues/3 
and would love any suggestions or pointers for the better way of not tweaking someone else's file, but capturing its output properly.

thanks!",1,1
39,2017-12-21,2017,12,21,20,7l8v78,Techniques for Distributed TensorFlow,https://www.reddit.com/r/tensorflow/comments/7l8v78/techniques_for_distributed_tensorflow/,jpdowlin,1513855471,,0,3
40,2017-12-22,2017,12,22,3,7lb7g8,Kubeflow (Tensorflow on Kubernetes) online sandbox,https://www.reddit.com/r/tensorflow/comments/7lb7g8/kubeflow_tensorflow_on_kubernetes_online_sandbox/,mhausenblas,1513879633,,0,2
41,2017-12-22,2017,12,22,5,7lce5z,display data from csv file,https://www.reddit.com/r/tensorflow/comments/7lce5z/display_data_from_csv_file/,rdpyskub1,1513889926,"Hi 
I have used the code on tensorflow to load data from csv into tensorflow. The code ran ok but print function does'nt show any data. 
what are the best commands to do that?",0,1
42,2017-12-22,2017,12,22,7,7lcu3y,Python2 vs python3 gives different results!,https://www.reddit.com/r/tensorflow/comments/7lcu3y/python2_vs_python3_gives_different_results/,SamStringTheory,1513893794,"Are there any differences in the python2 vs python3 versions of Tensorflow that would give different results? My code was built for Python3, but works on Python2. However, using python2 results in losses that are ~20x greater during training. I am using a simple fully-connected neural network, nothing fancy. I don't even know how to begin debugging this.",10,4
43,2017-12-25,2017,12,25,6,7lxr1o,Kernel dying while using max_pool(),https://www.reddit.com/r/tensorflow/comments/7lxr1o/kernel_dying_while_using_max_pool/,ericonr,1514152517,"I am taking the udacity course on Deep Learning (yes, I'm aware it's Christmas), and on assignment 4 (convolutions) I hit a road block.    
It tells you to add a max_pool() operation with stride 2, instead of using strides for the convolution. However, when I use the max_pool on the second convolution, the code doesn't give any errors, it simply crashes or stops responding.    
My code is [here](https://pastebin.com/tBjJUJj6), with the three different cases.    
I suspect my problem could be my computer specs (a 3rd generation notebook i7 and 8GB RAM - the images are 28x28 and I am using a very small batch size), but I am not sure of that yet. If anyone could give any insight, I would be very thankful.",12,1
44,2017-12-25,2017,12,25,9,7lydo8,tf.reshape doesn't work with Conv1d layers?,https://www.reddit.com/r/tensorflow/comments/7lydo8/tfreshape_doesnt_work_with_conv1d_layers/,bwllc,1514160096,"Can anyone explain what I'm doing wrong here?

    import tensorflow as tf

    # fully connected: works
    fc = tf.placeholder(tf.float32, [None,12])
    fc = tf.contrib.layers.fully_connected(fc, 12)
    fc = tf.contrib.layers.fully_connected(fc, 6)
    fc = tf.reshape(fc, [-1,3,2])

    # convolutional: fails
    con = tf.placeholder(tf.float32, [None,50,4])
    con = tf.layers.Conv1D(con, 12, 3, activation=tf.nn.relu)
    con = tf.layers.Conv1D(con, 6, 3, activation=tf.nn.relu)
    con = tf.reshape(con, [-1,50,3,2])

Here's the output (I'm aware of the RuntimeWarning, and have asked about it in previous posts.  It appears before every error I've encountered in TensorFlow.  I have found posts which say that it's harmless, and I'll have to say that it can't be responsible for every error I encounter.  If you think it's important, please feel free to make me stop ignoring it.):

    /usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
      return f(*args, **kwds)
    Traceback (most recent call last):
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py"", line 468, in make_tensor_proto
        str_values = [compat.as_bytes(x) for x in proto_values]
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py"", line 468, in &lt;listcomp&gt;
        str_values = [compat.as_bytes(x) for x in proto_values]
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/compat.py"", line 65, in as_bytes
        (bytes_or_text,))
    TypeError: Expected binary or unicode string, got &lt;tensorflow.python.layers.convolutional.Conv1D object at 0x7f2cd5611a20&gt;

    During handling of the above exception, another exception occurred:

    Traceback (most recent call last):
      File ""minimal reshape example.py"", line 15, in &lt;module&gt;
        con = tf.reshape(con, [-1,50,3,2])
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py"", line 3938, in reshape
        ""Reshape"", tensor=tensor, shape=shape, name=name)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py"", line 513, in _apply_op_helper
        raise err
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py"", line 510, in _apply_op_helper
        preferred_dtype=default_dtype)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 926, in internal_convert_to_tensor
        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py"", line 229, in _constant_tensor_conversion_function
        return constant(v, dtype=dtype, name=name)
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py"", line 208, in constant
        value, dtype=dtype, shape=shape, verify_shape=verify_shape))
      File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py"", line 472, in make_tensor_proto
        ""supported type."" % (type(values), values))
    TypeError: Failed to convert object of type &lt;class 'tensorflow.python.layers.convolutional.Conv1D'&gt; to Tensor. Contents: &lt;tensorflow.python.layers.convolutional.Conv1D object at 0x7f2cd5611a20&gt;. Consider casting elements to a supported type.

So I can use tf.reshape() in a fully-connected graph, but not in a Conv1D graph.  Why not?

I've also been trying to use the third-party, high-level TensorFlow API called TFLearn, and I CAN use its equivalent function, tfl.reshape(), in both fully-connected and convolutional graphs.  (I would be using TFLearn right now if its Estimator object was functional.  However, TFLearn's DNN Estimator object is having trouble managing a tf.Session correctly. After over a month, I have yet to resolve the issue with TFLearn's developers on GitHub.)
 
I'm using TF 1.4 and Python 3.6, if it matters.  Thanks for any suggestions you can provide!",2,2
45,2017-12-25,2017,12,25,10,7lyu56,TensorFlow: A Guide to Build Artificial Neural Networks using Python,https://www.reddit.com/r/tensorflow/comments/7lyu56/tensorflow_a_guide_to_build_artificial_neural/,AhmedGadFCIT,1514166195,,0,1
46,2017-12-26,2017,12,26,7,7m44hv,Why do you need to put both the optimizer and the cost inside the sees.run?,https://www.reddit.com/r/tensorflow/comments/7m44hv/why_do_you_need_to_put_both_the_optimizer_and_the/,yoav912991,1514242432,"I'm doing ng's cnn course and this is part of the programming assignment      

    _ , temp_cost = sess.run([optimizer,cost],feed_dict={X: minibatch_X, Y: minibatch_Y})

and I don't understand why do I need to run both the optimizer and the cost here. Because when i'm defining the optimizer i'm explicitly telling it to minimize the cost. so isn't it the same way I don't need to specify to the run command every other intermediate variable in the graph separately (Z3 for example)?
   
    Z3 = forward_propagation(X,parameters)

    cost = compute_cost(Z3,Y)

    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)",1,2
47,2017-12-26,2017,12,26,22,7m7s4g,How to train a Deep Neural Network using only TensorFlow C++,https://www.reddit.com/r/tensorflow/comments/7m7s4g/how_to_train_a_deep_neural_network_using_only/,theflofly,1514295234,,0,8
48,2017-12-26,2017,12,26,23,7m8439,Properly uninstall CUDA 9.1,https://www.reddit.com/r/tensorflow/comments/7m8439/properly_uninstall_cuda_91/,EnderFuckingWiggin,1514299665,"I installed the newest version of CUDA by accident, not knowing I needed 8.0. I now want to fully uninstall it so I can install the 8.0 version, but can't seem to find a good way to do this (Windows 10). Have any of you dealt with this?",3,1
49,2017-12-27,2017,12,27,2,7m96po,How to do a multi-class classification when you know only possible classes?,https://www.reddit.com/r/tensorflow/comments/7m96po/how_to_do_a_multiclass_classification_when_you/,OlegSerov,1514311058,"Image I have some number of examples. However, I know only that these examples contain some possible feature set. E.g. some examples contain (A, B, C), others (B, D, F). I want to teach the neural network to recognize these classes separately. How do I construct a proper loss function for tensorflow?
",8,1
50,2017-12-27,2017,12,27,7,7maufz,How do you format a CSV file?,https://www.reddit.com/r/tensorflow/comments/7maufz/how_do_you_format_a_csv_file/,mdmarshmallow,1514327414,"I am completely new to TensorFlow and have only gone through the tutorials so far, so sorry if anything I say doesn't make sense. Anyways, I would like to know how I would format the header of a CSV file for TensorFlow. I looked at the Iris training data set in the tutorials but I'm still not completely sure. Thanks for the help!",4,2
51,2017-12-28,2017,12,28,0,7mfhmn,Parameter construction for tf.map_fn,https://www.reddit.com/r/tensorflow/comments/7mfhmn/parameter_construction_for_tfmap_fn/,Technomancerer,1514386978,"Very similar to this overflow post that was posted yesterday in fact: https://stackoverflow.com/questions/47984876/tensorflow-tf-map-fn-parameters

The official documentation for map_fn shows it should be capable of accepting a tuple or list of tensors, but this does not seem to be the case unless those tensors are the same shape.  Is this intended?",7,1
52,2017-12-28,2017,12,28,19,7mlu82,Serve tensorflow model in ASP.net web API,https://www.reddit.com/r/tensorflow/comments/7mlu82/serve_tensorflow_model_in_aspnet_web_api/,Starchand,1514456568,"I completed [this tensorflow-for-poets tutorial](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0) which takes some images to retrain a model, generating a retrained_graph.pb model and retrained_labels.txt

This is working and I can query my model using the python script provided in step 4.


&gt; python -m scripts.label_image \
    --graph=tf_files/retrained_graph.pb  \
    --image=tf_files/flower_photos/roses/2414954629_3708a1a04d.jpg 



I want to expose this model to an ASP.net Web API so it can be accessed from mobile app. How would I go about doing this? I looked at IronPython but haven't been about to get this working.",1,3
53,2017-12-29,2017,12,29,5,7mp03c,Multiplying outputs of one layer by the outputs of another layer,https://www.reddit.com/r/tensorflow/comments/7mp03c/multiplying_outputs_of_one_layer_by_the_outputs/,joopaloo,1514491289,"Hi,

I want all of the neurons in layer A to be multiplied by all of the neurons in layer B. (I'm trying to design a gain-field experiment.) Can a tensorflow function make this relationship between A and B?

ie. A_1_post = A_1_pre * B_1 * B_2... B_n

I also want the B projections to become optimized for this relationship with A during training.

Can this be done?",2,1
54,2017-12-29,2017,12,29,9,7mql3a,"Tensorflow custom object detection on windows 7,8,10",https://www.reddit.com/r/tensorflow/comments/7mql3a/tensorflow_custom_object_detection_on_windows_7810/,GreekGodSly,1514506142,"Is there any tutorial in here or YouTube or any other forum where they show you how to make a custom object detection api using windows , most of the tutorials I have seen are using Ubuntu , thank you.",4,1
55,2017-12-29,2017,12,29,11,7mraw6,Planning to buy a GPU [GTX1060 6GB] for TensorFlow - any quirks to expect?,https://www.reddit.com/r/tensorflow/comments/7mraw6/planning_to_buy_a_gpu_gtx1060_6gb_for_tensorflow/,bailbondshman,1514513581,"I'm planning to purchase a GTX1060 (6GB) for training ConvNets but want to know if there are any quirks to using a GPU, as I've only trained on a CPU so far.


If I I understand correctly, I just need to install the [GPU version](https://www.tensorflow.org/install/install_linux) of TensorFlow and some CUDA libs, right?


Also, I'm using an i7 920 CPU with a PCI Express 1.0 slot. Would this be a noticeable bottleneck, or would it not matter? I very much like my older hardware and would rather not replace it unless I absolutely have to :)",17,5
56,2017-12-29,2017,12,29,16,7msvbg,How would you apply a normalization function to a feature column?,https://www.reddit.com/r/tensorflow/comments/7msvbg/how_would_you_apply_a_normalization_function_to_a/,mdmarshmallow,1514532136,"Hi, I'm completely new to TensorFlow and machine learning in general so sorry if something I say doesn't make sense. I wanted to normalize a numeric feature column, and in the docs, I found the following code:

    numeric_column(
        key,
        shape=(1,),
        default_value=None,
        dtype=tf.float32,
        normalizer_fn=None
    ) 

The problem is, I don't know what to set normalizer_fn to. Does anyone have sample code I can look at? I couldn't find anything online (maybe I'm too dumb to find it). Thanks!
",3,1
57,2017-12-30,2017,12,30,7,7mxfop,"""Fully Connected"" except with half the projections",https://www.reddit.com/r/tensorflow/comments/7mxfop/fully_connected_except_with_half_the_projections/,popeldo,1514585423,"Hi,

Is there a way to connect two layers A and B such that every neuron from A projects to half of the neurons in B?

Thanks",1,2
58,2017-12-30,2017,12,30,7,7mxjc7,I'm really lost; please help?,https://www.reddit.com/r/tensorflow/comments/7mxjc7/im_really_lost_please_help/,MrAcurite,1514586432,"Howdy,

So I've been looking into using Tensorflow to train a neural network, but I've been having a lot of trouble understanding the errors that I've been getting, and how to move forward.

Here's where I'm at so far:

-I have a decent amount of training data. 10,000 sets of 30 pieces of numerical data as inputs and 1 floating point value as what I want to guess

-I'm not entirely clear how to format these data to actually input them into a neural network

-I want to put these into and train a neural network with at least two hidden layers with an arbitrary number of neurons each

-Once I have a trained neural net, I want to be able to use it as a function which takes a list of 30 floats and returns 1 float

When I tried copying and modifying an example MNIST program, I ended up with things like ""Tuple index out of range"" as an error, despite not using any tuples. I'd appreciate it greatly if someone could explain to me how to put this sort of thing together.

Note: I've been teaching this stuff to myself without any real direction. Ordinarily, learning packages involves breaking things down and picking them up one at a time, but tensorflow feels much more self-referential, having to learn like twenty different commands before you can get your first program to work.",10,0
59,2017-12-30,2017,12,30,13,7mzgcq,How do you call an already trained model from Java?,https://www.reddit.com/r/tensorflow/comments/7mzgcq/how_do_you_call_an_already_trained_model_from_java/,mdmarshmallow,1514607049,"I have a classifier I wrote using the tf.estimator API, but I want to be able to use the model to make predictions from a Java web application. How would I do that?",1,1
60,2017-12-30,2017,12,30,14,7mzvuz,Why are very few of the tensorflow samples commented?,https://www.reddit.com/r/tensorflow/comments/7mzvuz/why_are_very_few_of_the_tensorflow_samples/,JackHoYVR,1514612555,"It's surprising to me that even though it's good CompSci practise to comment code and that the majority of the ""leading"" deep learning guys are academics (so they should know better), that many of the Tensorflow samples are not commented. At all.
It's especially surprising because it's very difficult to figure out what's going on.

Can we get a change going on please - can folks please comment their code to explain what it's doing?",3,7
61,2017-12-31,2017,12,31,4,7n3h14,Diego Cavalca using a deep neural network developed with Tensorflow API (in Python) to detect objects in video.,https://www.reddit.com/r/tensorflow/comments/7n3h14/diego_cavalca_using_a_deep_neural_network/,Bluecodejs,1514661956,,0,10
62,2017-12-31,2017,12,31,5,7n3wyb,Tensorflow stuck at global_step/sec=0. I don't really now what to do.,https://www.reddit.com/r/tensorflow/comments/7n3wyb/tensorflow_stuck_at_global_stepsec0_i_dont_really/,epiclapser,1514666381,"So I was following along with the tutorial that sendtex made on object detection, specifically the part where he trained a custom classifier. I finally ran train.py, and it seemed to be working fine at first. Then it got to ""INFO: tensorflow:global_step/sec:0"", and it just kept repeating that over and over and over again. It then started saving a checkpoint file, and it's just been doing that. My guess is my GPU is just slow or something, but it's been a while. Is my hunch right? 
-Thanks in advance",0,3
63,2017-12-31,2017,12,31,18,7n7mhn,Tensorflow not Showing Up as Module on macOS + Python 2.7,https://www.reddit.com/r/tensorflow/comments/7n7mhn/tensorflow_not_showing_up_as_module_on_macos/,geekchicshipper,1514711455,"Hi guys,

So I recently installed Tensorflow for this thing I downloaded, and after much trial and error, I finally got it to install through the Homebrew installer. The problem is when I try and run the Python script and it calls on the Tensorflow module, it says such a module doesn't exist, and I can't figure out what's going on. Can someone help out?

EDIT: I fixed the problem, both with installing Tensorflow and making the program work. The main problem seemed to be that I was using Python 2.7.10 because updating to 2.7.14 let me install Tensorflow without problem. The other problem was the program was calling on v0.12.1 when I was installing v1.4.1, so by installing v0.12.1 using the binary URL I got it to work...well at least for now.",5,3
0,2018-1-1,2018,1,1,16,7ndyun,How to use facenet help!,https://www.reddit.com/r/tensorflow/comments/7ndyun/how_to_use_facenet_help/,rupax,1514791721,"I'm an absolute beginner at this, and I want to run facenet on my system. My end goal is to use facenet to recognise people from my home CCTV setup, but I cant get past the initial setup for facenet to even validate on LFW.

Could any of you help me out. Anything that you think I should read up on, or issues you ran into while running your own facenet or related technology would be great.

Thanks for your help Reddit! And have a great new year!",0,1
1,2018-1-1,2018,1,1,22,7nf2xu,Global Variables Initializer,https://www.reddit.com/r/tensorflow/comments/7nf2xu/global_variables_initializer/,sergeybok,1514812426,"Does anyone know if you initialize some variables train them, and then add to the network some other parts and run the tf.global_variables_initializer() again, does that overwrite the previous variables, or does it only initialize the uninitialized variables?",5,1
2,2018-1-4,2018,1,4,5,7nxbzp,"OS version and Tensorflow version questions, sysadmin question.",https://www.reddit.com/r/tensorflow/comments/7nxbzp/os_version_and_tensorflow_version_questions/,IronWolve,1515010479,"I have a dell R740XD with raid hardware that's not supported by Ubuntu 16.04.3 LTS, but in a few months both 16.04.4 update and 18.04 LTS will be out that supports my perc card.

I installed unreleased 18.04 LTS server with latest nvidia cuda 9.1 driver, with downloadable nvidia cuda 8 and tensorflow (pip python3), verified everything is working via test scripts.

I'd rather use an LTS, but they want Ubuntu and I normally run Centos 7 on all my servers.  

Would this be ok? 

Thoughts? Problems? 
",3,2
3,2018-1-4,2018,1,4,14,7o0sx4,"What is the syntax to predict output based on already run session, with input variable x and output variable y?",https://www.reddit.com/r/tensorflow/comments/7o0sx4/what_is_the_syntax_to_predict_output_based_on/,JackHoYVR,1515043078,"I've modified some tutorial code which basically takes a list of x float32s as input and multiplies them by 2 for y. Then I run a session to generate the predictor function for 500 epochs. This part works fine (the training). I can't, however, seem to figure out the correct syntax to feed in a list of test x's and get the graph to predict the output based on the test x's.   Here's a snippet of the final code (and the error I get at the bottom of the snippet) and a link to the entire source code (pretty short example) on github:  



xg = tf.get_default_graph()  
  

x_input = xg.get_tensor_by_name('varx:0')  
y_output = xg.get_tensor_by_name('vary:0')  
  
with tf.Session(graph=xg) as sess1:  
        x_example = [3]  
        y_prediction = sess1.run(tf.argmax(y_output),feed_dict={x_input:x_example})  
        print(y_prediction)    
## ^^^^^ ValueError: Cannot feed value of shape (1,) for Tensor 'varx:0', which has shape '(?, 1)'  
 
github link to whole code:  
https://github.com/JackHoYVR/Tensorflow-scratch/blob/master/read_csv_list_into_tf.py  

Thanks in advance to anyone with any pointers.  
",3,1
4,2018-1-5,2018,1,5,0,7o3m78,Switching To Tensorflow from CNTK,https://www.reddit.com/r/tensorflow/comments/7o3m78/switching_to_tensorflow_from_cntk/,Clevelandlandlord,1515079224,What should I read install and do to get acclimated? ,1,3
5,2018-1-5,2018,1,5,19,7oahdq,"TensorFlow Dev summit 2018 will be on March 30th, 2018",https://www.reddit.com/r/tensorflow/comments/7oahdq/tensorflow_dev_summit_2018_will_be_on_march_30th/,ajmssc,1515149421,"Signup at https://services.google.com/fb/forms/tfds-2018-save-the-date/

 https://twitter.com/TensorFlow/status/949017805667557376?s=09",0,2
6,2018-1-5,2018,1,5,23,7objv0,Tensorflow with React-native,https://www.reddit.com/r/tensorflow/comments/7objv0/tensorflow_with_reactnative/,mahesh_98,1515162908,Can Tensorflow be integrated with a React-native?  Is there any way to go about doing this?,3,2
7,2018-1-7,2018,1,7,1,7ok8wv,"Want to learn how to make your own TENSORFLOW ACCURATE IMAGE Classifier in just 5 MINUTES? Check this video out, and if you enjoy the tutorial, make sure to subscribe. :)",https://www.reddit.com/r/tensorflow/comments/7ok8wv/want_to_learn_how_to_make_your_own_tensorflow/,DiscoverAI,1515256901,,2,9
8,2018-1-7,2018,1,7,10,7onkxa,Trouble getting installed.,https://www.reddit.com/r/tensorflow/comments/7onkxa/trouble_getting_installed/,[deleted],1515288666,[deleted],0,1
9,2018-1-8,2018,1,8,0,7or78o,Mushroom Classification using Tensorflow and sklearn.,https://www.reddit.com/r/tensorflow/comments/7or78o/mushroom_classification_using_tensorflow_and/,[deleted],1515339570,[deleted],1,1
10,2018-1-8,2018,1,8,0,7ora19,[D] Mushroom Classification in Tensorflow,https://www.reddit.com/r/tensorflow/comments/7ora19/d_mushroom_classification_in_tensorflow/,_JayJohn,1515340405,Create a classifier to distinguish between mushrooms (Dataset included),2,1
11,2018-1-9,2018,1,9,1,7ozjwg,Could you offer some assessment and startup-hints for my bachelor thesis?,https://www.reddit.com/r/tensorflow/comments/7ozjwg/could_you_offer_some_assessment_and_startuphints/,mihael2039,1515428256,"Maybe some words of context: 
I'm studying business informatics and got some knowledge in programming and computer science. But I'm new to the field of AI and the use of tensorflow. I'm really interested in both, but generally find it rather hard to entry.
That's why, for my bachelor thesis, I want to create a prototype of a negotiation training assistant. There are already some existant with the use of Expert Systems. The AI is generally weak in them.
And these are operating to find an optimum solution in negotiations. As studies has shown, people are likely to decline good offers, if they are threated unfriendly. So, I want to simulate this ""socio-emotional behaviour"". 
I aim the prototype to being able to classify input text in categories as e.g. insulting or disrespectful. Depending on progress, I could lower the complexity to a bool (friendly / unfriendly). In dependence of classification, conditions will change or negotiations will getting aborted. I do not focus to hard to the conditions or negotiation scenarios, they even may be hard coded for simplicity.
I think, it is a good idea to first choosing the models and then searching / gathering / creating the needed data.

TLDR: Beginning with bachelor thesis. At the moment, I am tailoring the topic. Want to emulate human behaviour in terms of pride and emotional reactions in text-based appliance. Am curious, but unsure. Please have a look at my questions:

Here is a (very basic) draft of the project: [Link!](https://www.buechele-service.de/nextcloud/index.php/s/W0DKiZG16U0TFdE)

1. In terms of the LSTM, I can find similarities of my goal and Google Smart Reply. I can find an on-device Smart Reply as Part of Tensorflow lite, but it isn't trainable. As it is trained in a casual-communication-oriented context, I cannot use it. In the Google papers of Smart Reply, the process is being descriped solely abstract. Can I train and use it myself? Or which tensorflow model would fit to replicate it?

2. Do I need a second AI like ""Vector Representation of Words"" or the ""Sequence-to-Sequence Model"" to generate input, a LSTM can handle? Or is it wrong / overkill?

3. Does this draft make any sense to you?

4. With your experience, can you see this project in a bachelor thesis with a time of 4 months? Would you consider the goal and the project itself as realistic?

5. Which tensorflow models come to your mind, if you hear about the goal?

6. Other thoughts? Input? Further questions? Please share and let's discuss. Every interaction is highly appreciated.",2,2
12,2018-1-10,2018,1,10,3,7p9acb,Proper method to segment Tensorflow graphs - (pb) into subgraphs?,https://www.reddit.com/r/tensorflow/comments/7p9acb/proper_method_to_segment_tensorflow_graphs_pb/,vade,1515524153,"I am attempting to optimize inference in my C++ application by segmenting some graphs and chaining them together to remove redundant inference calculations.

My goal is to segment to have a main inference graph so it runs input -&gt; feature vector, and then segment each trained model to a into a smaller classifier graph which takes feature vector (calculated once with the aforementioned graph) and returns label probabilities for all my classifiers. This way I run inference once, and lighter classification n times.

Is there a tutorial for performing surgery graphs this way? DO I need to be concerned with reported tensor shapes not appearing to be correct when I use the graph_transform tool?

I train a classifier via retrain.py - resulting in a graph named CinemaNetShotSubject.pb and train a different output using the same architecture named CinemaNetShotFraming.pb

Both networks utilize the same feature vector shape as inputs to the labeling portion of the graph. 

To create the core inference graph, I run the following transform_graph call:

    bazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=""CinemaNetSubject.pb"" --out_graph=CinemaNetCore.pb --inputs='input' --outputs='input_1/BottleneckInputPlaceholder' --transforms='strip_unused_nodes(type=float, shape=""1,224,224,3"") remove_nodes(op=Identity, op=CheckNumerics) fold_constants(ignore_errors=true) fold_batch_norms fold_old_batch_norms quantize_weights remove_device sort_by_execution_order'

To then extract various classifier graphs I want to use, I run:

    bazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=CinemaNetShotFraming.pb --out_graph=CinemaNetShotFramingClassifier.pb --inputs='input_1/BottleneckInputPlaceholder' --outputs='final_result' --transforms='strip_unused_nodes(type=float, shape=""1,224,224,3"") remove_nodes(op=Identity, op=CheckNumerics) fold_constants(ignore_errors=true) fold_batch_norms fold_old_batch_norms quantize_weights remove_device sort_by_execution_order'

I am able to run my main inference operation and output a feature vector - and am able to chain to multiple classification operations. I am concerned about re-shaping and the correctness of my results.

For example - running summarize graph on my smaller classifiers indicates the input shape is 1,224,224,3 - which is not correct - the input shape should be be a feature vector in the shape of 1001 elements. 

What am I doing wrong here ha.

Thanks for any info.",0,1
13,2018-1-10,2018,1,10,23,7pfydd,Add additional variable to CNN in TF,https://www.reddit.com/r/tensorflow/comments/7pfydd/add_additional_variable_to_cnn_in_tf/,donjuan1337,1515595081,I'm looking for code examples or solutions to add additional input data to a CNN after the convolution/max layers. I've found [this](https://stackoverflow.com/questions/42556919/adding-a-variable-into-keras-tensorflow-cnn-dense-layer) from stack but the solution is based on the keras framework. The link will also clarify what I'm looking for.,2,3
14,2018-1-11,2018,1,11,3,7phnmz,What all should an hour long tensorflow tutorial for undergraduate sophomores cover?,https://www.reddit.com/r/tensorflow/comments/7phnmz/what_all_should_an_hour_long_tensorflow_tutorial/,bongololona,1515609722,"They have all completed a course in basic programming. Theoretical background on deep neural nets has been covered. I want something that will be both easy to understand, and interesting enough to hold the attention of the kids throughout the tutorial.",1,1
15,2018-1-11,2018,1,11,11,7pkwzt,Is deep learning any good for creation?,https://www.reddit.com/r/tensorflow/comments/7pkwzt/is_deep_learning_any_good_for_creation/,FateRiddle,1515637809,"Hi, I've just watched a tutorial, and all is focusing on recognizing/classification. So it feels like we only use it to ""judge"" things. I'm just curious is deep learning/machine learing good for ""creating""? By creating I mean creating something that meets certain criteria given.",6,1
16,2018-1-11,2018,1,11,12,7pld52,Do I just give up?,https://www.reddit.com/r/tensorflow/comments/7pld52/do_i_just_give_up/,jdrada18,1515642327,"Discovered Tensorflow through a different subreddit and I was intrigued. Later that night I attempted to do everything to install the program and I have failed..... 

Is this a sign to just give up? :`( ",9,0
17,2018-1-11,2018,1,11,15,7pm3e6,How to build the reward system in GANs? (Just the idea),https://www.reddit.com/r/tensorflow/comments/7pm3e6/how_to_build_the_reward_system_in_gans_just_the/,FateRiddle,1515650412,"So I just listened this interview, which is great. https://blogs.nvidia.com/blog/2017/05/17/generative-adversarial-network/

It describe the GANs system, the theory being: generator tries to generate a image of cat, and discriminator tries to give the probability of it actually looking like a cat. Each will get a score for thieir performance. So they'll work to improve themself.

But the interview said nothing about the reward system, which I think is the core of GANs. Say if A draws a dot, B said it is a cat. Apparently they are both wrong, but how does the reward system know they are both wrong? You can't manually tell it is wrong(which against the whole point of GANs), right? So how?

I believe the idea is sort of like the ""invisible hand"" in economics(as mentioned in the interview) but fail to form the analogy.",3,0
18,2018-1-11,2018,1,11,16,7pmjb6,How to connect your Tensorflow model to your website?,https://www.reddit.com/r/tensorflow/comments/7pmjb6/how_to_connect_your_tensorflow_model_to_your/,thatsfunny95,1515656195,"I'm creating an email client which would use a neural network to classify email as spam, non spam and prioritized emails. I'm planning to use a neural network built in tensorflow for this purpose. How do I connect my model in the cloud to this client?",3,1
19,2018-1-11,2018,1,11,23,7poc5f,Complete Guide to TensorFlow for Deep Learning with Python is 94% off at Udemy. Less than a day left at this pric,https://www.reddit.com/r/tensorflow/comments/7poc5f/complete_guide_to_tensorflow_for_deep_learning/,plakuciss,1515680044,,7,8
20,2018-1-13,2018,1,13,0,7pxce9,When is TensorFlow going to have Edward?,https://www.reddit.com/r/tensorflow/comments/7pxce9/when_is_tensorflow_going_to_have_edward/,o-rka,1515771495,"I'm looking forward to learning probabilistic programming with tf, keras, and edward.  I'm wondering when edward will be available through tf like keras is atm",3,1
21,2018-1-13,2018,1,13,11,7q1rgu,"Want to learn how to make your own TENSORFLOW RECURRENT NEURAL NETWORK? Check this video out, and if you enjoy it, make sure to Subscribe. :)",https://www.reddit.com/r/tensorflow/comments/7q1rgu/want_to_learn_how_to_make_your_own_tensorflow/,DiscoverAI,1515810689,,0,5
22,2018-1-13,2018,1,13,16,7q37mg,To what extent are Sonnet and tf.contrib.layers duplicating each other?,https://www.reddit.com/r/tensorflow/comments/7q37mg/to_what_extent_are_sonnet_and_tfcontriblayers/,LiverEnzymes,1515829248,"At least superficially, Sonnet seems to overlap what is going on with the still-evolving tf.contrib.layers. I found Sonnet useful for automatically handling the creation of scoped-variable names for nested modules. 

Is it fair to say that layers and Sonnet are competing frameworks that partially duplicate each other's function?  Is there any prospect for converging on a ""standard"" so we don't end up fragmented into competing libraries?  

I'd be interested in any thoughts people have on this, especially from anyone who has spent time evaluating the design decision to use one vs the other. Thanks.
",0,1
23,2018-1-14,2018,1,14,7,7q7o9v,Text classification for comma delimited CSV files?,https://www.reddit.com/r/tensorflow/comments/7q7o9v/text_classification_for_comma_delimited_csv_files/,supamonkey2000,1515881633,"I've been struggling to find a project that works with this.

Let's say I have a comma delimited CSV file, which has 2 columns: the data, and the numeric label assigned to it. For simplicity, our labels are 1 and 2. I want to train a model so that when I ""sample"" it with new text is hasn't seen before, it gives it a label of 1 or 2.

An example file:

&gt; Hey I am good text,1

&gt; Boo this is bad words,2

I searched for ""text classification tensorflow github:"" on Google, but none of the projects I found describe using your own data.

Can anyone provide a link to a project that's suits these needs? Thanks.",0,1
24,2018-1-14,2018,1,14,7,7q7vvf,TensorFlow on Android,https://www.reddit.com/r/tensorflow/comments/7q7vvf/tensorflow_on_android/,Bluecodejs,1515883683,,0,3
25,2018-1-14,2018,1,14,14,7qa59o,This is an awesome playlist for learning TensorFlow,https://www.reddit.com/r/tensorflow/comments/7qa59o/this_is_an_awesome_playlist_for_learning/,Geeks_sid,1515908686,Tensorflow Tutorials - Zero to Hero: https://www.youtube.com/playlist?list=PL7H_mLGEiY1Db2M1KtJx5pWx5gzFyGhmf,2,7
26,2018-1-15,2018,1,15,0,7qca0u,Can a third party email client classify emails using TensorFlow?,https://www.reddit.com/r/tensorflow/comments/7qca0u/can_a_third_party_email_client_classify_emails/,thatsfunny95,1515942126,Is it possible for a email client to read incoming emails from Gmail and classify them?,2,1
27,2018-1-15,2018,1,15,3,7qdkdr,How to save the model of a basic tensorflow deep MNIST tutorial?,https://www.reddit.com/r/tensorflow/comments/7qdkdr/how_to_save_the_model_of_a_basic_tensorflow_deep/,P_Andre,1515954441,"I have followed the deep mnist tutorial on the official website. I want to save it, however I am struggling to understand which variables to save and how to retrieve the model.

The tutorial can be found here https://www.tensorflow.org/get_started/mnist/pros",4,3
28,2018-1-15,2018,1,15,23,7qk519,"DIY Prisma, Fast Style Transfer app  with CoreML and TensorFlow",https://www.reddit.com/r/tensorflow/comments/7qk519/diy_prisma_fast_style_transfer_app_with_coreml/,rambossa1,1516028080,,0,8
29,2018-1-16,2018,1,16,3,7qlqfu,Contributing to Tensorflow Question,https://www.reddit.com/r/tensorflow/comments/7qlqfu/contributing_to_tensorflow_question/,zazabar,1516041598,"Hey guys,  
  
Has anyone contributed code to Tensorflow before? I'm looking to write something from a semi-recent paper that isn't included yet and I wanted to ask a couple questions about the implementation in relation to other stuff on there to ensure I meet the same standards. ",0,2
30,2018-1-16,2018,1,16,20,7qrosy,Trying to install Tensorflow on Windows 10 with Python 3.6.3,https://www.reddit.com/r/tensorflow/comments/7qrosy/trying_to_install_tensorflow_on_windows_10_with/,The0thArcana,1516101738,"Hello automators,

For the past days I've been trying to get Tensorflow to work on Windows 10 with Python 3.6.3 and it doesn't seem to be working. When I try to install tensorflow through the pip it says all requirements are met but when I try to import it in prompt it gives me

&gt; Error importing tensorflow.  Unless you are using bazel,
you should not try to import tensorflow from its source directory; please exit the tensorflow source tree, and relaunch your python interpreter
from there.

And the internet isn't telling me how to not import tensorflow from its source directory.

I tried conda create -n tensorflow python=3.5 but conda doesn't seem to work (even though I'm using the Anaconda prompt and the directory and directoy\Scripts are both in PATH)

I've tried downloading and working in 3.5 but I'm not sure how to switch versions of Python.

Lastly I tried installing: https://pypi.python.org/packages/76/7b/2048b4ecd88395ac16ab938e8675ffeda2acb60bc34f5ef63500eafafaf5/tensorflow-1.4.0-cp36-cp36m-win_amd64.whl#md5=7bdc1e94f1cb772ae5851018dc23a62e

which seems to be the correct .whl file to make tensorflow work with 3.6, but when I do I get a red:
&gt; tensorflow-1.4.0-cp36-cp36m-win_amd64.whl is not a supported wheel on this platform.

So at this point most of my google searches are purple and I come to you guys with no real idea of how to get TF going.

Any help appreciated.",4,2
31,2018-1-17,2018,1,17,1,7qtntb,Difference between tensorflow image classifier and OpenCV,https://www.reddit.com/r/tensorflow/comments/7qtntb/difference_between_tensorflow_image_classifier/,mahesh_98,1516121866,I'm a newbie to machine learning. I'm curious on how tensorflow image classifier works and how it's different from OpenCV? What are some advantages and disadvantages of both?,5,6
32,2018-1-18,2018,1,18,5,7r3wzs,Building Cross-Lingual End-to-End Product Search with Tensorflow,https://www.reddit.com/r/tensorflow/comments/7r3wzs/building_crosslingual_endtoend_product_search/,h_xiao,1516220220,,0,2
33,2018-1-20,2018,1,20,6,7rlom6,Restarting optimizer learning rate decay,https://www.reddit.com/r/tensorflow/comments/7rlom6/restarting_optimizer_learning_rate_decay/,SamStringTheory,1516397369,"Some of the optimizers such as Adam have a built-in mechanism for decay of the learning rate. Is there a way to restart this decay partway through training? The only way I can think of is to initialize a new optimizer object.

Edit: I guess I used the wrong search keywords before. I found a couple threads, have yet to test them: 

https://stackoverflow.com/questions/41533489/how-to-initialize-only-optimizer-variables-in-tensorflow

https://stackoverflow.com/questions/39607566/reset-tensorflow-optimizer",0,0
34,2018-1-21,2018,1,21,1,7rrfsn,Train an Image Classifier in 3 Minutes,https://www.reddit.com/r/tensorflow/comments/7rrfsn/train_an_image_classifier_in_3_minutes/,tim_macgyver,1516466658,,0,0
35,2018-1-21,2018,1,21,9,7ruejf,Labelbox: The most versatile data labeling tool for machine learning,https://www.reddit.com/r/tensorflow/comments/7ruejf/labelbox_the_most_versatile_data_labeling_tool/,labelbox,1516495040,,13,5
36,2018-1-21,2018,1,21,17,7rwlli,What is TensorFlow???,https://www.reddit.com/r/tensorflow/comments/7rwlli/what_is_tensorflow/,neuraltensor,1516522574,,1,0
37,2018-1-22,2018,1,22,16,7s47oe,Face Detection in Go using OpenCV and MachineBox,https://www.reddit.com/r/tensorflow/comments/7s47oe/face_detection_in_go_using_opencv_and_machinebox/,Tatta360,1516606301,,0,1
38,2018-1-23,2018,1,23,15,7sckw8,[Question] Are you able to pass PDF files as input into TensorFlow?,https://www.reddit.com/r/tensorflow/comments/7sckw8/question_are_you_able_to_pass_pdf_files_as_input/,ProjectPsygma,1516689505,,8,1
39,2018-1-25,2018,1,25,0,7snr1g,How do I test data on Retinanet?,https://www.reddit.com/r/tensorflow/comments/7snr1g/how_do_i_test_data_on_retinanet/,templeoftiger,1516807114,"I am using the Retinanet model to train a classifier with about 50 classes. Link to the model: https://github.com/fizyr/keras-retinanet

This is what I have done so far:

1. Installed the model using the suggested steps. 
2. Create a csv of my images with the recommended format for reading. 
3. Used the following script to train my model:

        # Using the installed script:
        retinanet-train csv &lt;path to csv file containing annotations&gt; &lt;path to csv file containing classes&gt;

4. The model is currently running and training with about 50 epochs and 10000 steps in each epoch. I see the losses going down and it should take about a day to finish the training. 

How do I proceed now with: 

a. Testing my model? The example given here:

An example of testing the network can be seen in this (https://github.com/fizyr/keras-retinanet/blob/master/examples/ResNet50RetinaNet.ipynb link on the website is dead, this seems appropriate) Notebook. In general, output can be retrieved from the network as follows:

        _, _, detections = model.predict_on_batch(inputs)

Where detections are the resulting detections, shaped (None, None, 4 + num_classes) (for (x1, y1, x2, y2, cls1, cls2, ...)).

Loading models can be done in the following manner:

        from keras_retinanet.models.resnet import custom_objects
        model = keras.models.load_model('/path/to/model.h5',                 
        custom_objects=custom_objects)

Execution time on NVIDIA Pascal Titan X is roughly 55msec for an image of shape 1000x600x3.

Now during the training, I did not do anything while running my model: 

Create generators for training and testing data (an example is show in keras_retinanet.preprocessing.PascalVocGenerator).

Am I missing something?

Again, sorry for the multi-fold questions and thank you for helping me out. 
",0,1
40,2018-1-25,2018,1,25,4,7spgy0,Do Something based on Object within 'Object Detection',https://www.reddit.com/r/tensorflow/comments/7spgy0/do_something_based_on_object_within_object/,noah_f,1516820749,"Using the Object Detection Example

https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb

How do I get the label from the object I was trying the following
for label in classes: 
if('name' == 'horse') do something ",0,2
41,2018-1-25,2018,1,25,17,7sut99,How to install Tensorflow 1.5.0 using official pip package | Python 3.6,https://www.reddit.com/r/tensorflow/comments/7sut99/how_to_install_tensorflow_150_using_official_pip/,Aryal007,1516869996,,5,15
42,2018-1-26,2018,1,26,22,7t4k7y,TensorFlow (inception v3) slow on Azure,https://www.reddit.com/r/tensorflow/comments/7t4k7y/tensorflow_inception_v3_slow_on_azure/,[deleted],1516974135,[deleted],3,1
43,2018-1-27,2018,1,27,12,7t9wgi,Help with first tensorflow model,https://www.reddit.com/r/tensorflow/comments/7t9wgi/help_with_first_tensorflow_model/,scottsen,1517022454,"First time trying to use TensorFlow... not going that well :)

2 main questions:

1) Why does it not do what I expect? :D  learning rate is nice and low, but it flies outta control quickly.
2) what is with reduce_sum in my err calc?  (or reduce_mean, or similiar).  What am I hoping that does?  It feels a bit weird as there is *also* the minimize(err) hanging off the GradientDescent ... so feels like 2 things trying to shrink the err.

The random inputs of 0-100 into a sigmoid is probably a bit weird, and trying to output sqrt(100) probably isn't going to go well, but... I still don't understand why it just... implodes.

Thanks for tips!

	import tensorflow as tf
	import numpy as np

	weight_initializer = tf.random_uniform_initializer()
	bias_initializer = tf.zeros_initializer()

	# hidden layer of 25
	n_neurons_1 = 25
	w_hidden_1 = tf.Variable(weight_initializer([1, n_neurons_1]))
	b_hidden_1 = tf.Variable(bias_initializer([n_neurons_1]))

	# hidden layer of 50
	n_neurons_2 = 50
	w_hidden_2 = tf.Variable(weight_initializer([n_neurons_1, n_neurons_2]))
	b_hidden_2 = tf.Variable(bias_initializer([n_neurons_2]))

	# hidden layer of 100
	n_neurons_3 = 100
	w_hidden_3 = tf.Variable(weight_initializer([n_neurons_2, n_neurons_3]))
	b_hidden_3 = tf.Variable(bias_initializer([n_neurons_3]))

	# single output layer
	w_out = tf.Variable(weight_initializer([n_neurons_3, 1]))
	b_out = tf.Variable(bias_initializer([1]))

	# create the actual layers
	start = tf.placeholder(tf.float32, shape = [None, 1])
	hidden_1 = tf.nn.sigmoid(tf.add(tf.matmul(start, w_hidden_1), b_hidden_1))
	hidden_2 = tf.nn.sigmoid(tf.add(tf.matmul(hidden_1, w_hidden_2), b_hidden_2))
	hidden_3 = tf.nn.sigmoid(tf.add(tf.matmul(hidden_2, w_hidden_3), b_hidden_3))
	out = tf.add(tf.matmul(hidden_3, w_out), b_out)

	# calculat the error (between actual output and sqrt of start.
	# wtf is reduce_mean?
	err = tf.reduce_sum(tf.squared_difference(out, tf.sqrt(start)))

	# optimizer
	opt = tf.train.GradientDescentOptimizer(.001)

	# uhh... trainer?
	train = opt.minimize(err)

	net = tf.InteractiveSession()
	net.run(tf.global_variables_initializer())

	for i in range(0,10000):
		# create random 0-100 #'s
		data_train = np.random.rand(10000, 1)
		data_train = data_train * 100

		# train with them
		net.run(train, feed_dict = { start: data_train })

		# every 100 check the results against well known values
		if i % 100 == 0:
			test = np.array([1, 4, 9, 16, 25, 36, 49, 64, 81]).reshape(9, 1)
			retval = net.run(out, feed_dict = { start: test })
			print(retval.transpose())
",2,1
44,2018-1-27,2018,1,27,18,7tbuvj,tensorflow-gpu: session.run() outputs information about my gfx-card,https://www.reddit.com/r/tensorflow/comments/7tbuvj/tensorflowgpu_sessionrun_outputs_information/,HerrMotz,1517046717,"When I run a tensorflow Session, it returns the output below and then proceeds. I don't need this when debugging. Is there a way to avoid the output?

2018-01-27 10:43:14.942391: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX
2018-01-27 10:43:15.604868: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1105] Found device 0 with properties:
name: GeForce GTX 1060 6GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:01:00.0
totalMemory: 6.00GiB freeMemory: 4.96GiB
2018-01-27 10:43:15.605618: I C:\tf_jenkins\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -&gt; (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)",1,1
45,2018-1-27,2018,1,27,23,7td3e2,Is TFLearn model definition different from Tensorflow train saver?,https://www.reddit.com/r/tensorflow/comments/7td3e2/is_tflearn_model_definition_different_from/,GasimGasimzada,1517064662,"I am trying to use a model saved via TFLearn. However, when I try to use it in Tensorflow based application (Picasso-VIZ to be exact), I get an error:

&gt; KeyError: ""The name 'Adam' refers to an Operation not in the graph.""

I thought TFLearn is just a nice,abstracted wrapper around Tensorflow. This error makes me think that TFLearn is doing something else with the model data. 

Also, I want to ask an additional question regarding this. Is it possible to save TFLearn network as Tensorflow checkpoint/model instead of its own format?",2,1
46,2018-1-28,2018,1,28,0,7tdees,Is TensorFlow right for this application?,https://www.reddit.com/r/tensorflow/comments/7tdees/is_tensorflow_right_for_this_application/,Raddafiskie,1517067987,"I'm wanting to take in a handful of dimensions about an object, all of which influence each other, and want to predict what a single dimension will be in the future. There aren't any hard facts about how each dimension influences the other, so it would need to learn this. The application is to attempt to make predictions on prices of cryptocurrencies. I know this has probably already been done, but I plan on including data that hasn't been included previously, which would be the special sauce (I hope). I would think this is a simple task of just inputing all the dimensions and letting it crunch the numbers, but it seems it's not as simple as this, or is it? Can anyone tell me if I'm completely off base, or point me in the right direction as to another framework, or program that can accomplish this? I have a background in programming, but this would be my first time working with AI/ML. Thanks!",4,1
47,2018-1-28,2018,1,28,3,7tecxi,A Guide to TensorFlow (Part-4),https://www.reddit.com/r/tensorflow/comments/7tecxi/a_guide_to_tensorflow_part4/,scmmishra,1517076187,,1,9
48,2018-1-28,2018,1,28,3,7temc2,Performance problem with version 1.5,https://www.reddit.com/r/tensorflow/comments/7temc2/performance_problem_with_version_15/,JamesLi2017,1517078469,"I have just upgraded my tensorflow lib on my Windows 7 machine (X64 with python 3.5.2) from version 1.4 to 1.5.  The new version seems work fine as before, but for most our applications, the performance has dropped about 50%.  The GPU load seems to have dropped 50% too.  

When starting tensorflow applications, tensorflow printed out the following warning message: 

C:\Program Files\Python3\lib\site-packages\h5py\__init__.py:34: FutureWarning: C
onversion of the second argument of issubdtype from `float` to `np.floating` is
deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type

I am not sure how to fix above warning.
I am wondering whether any body else had this experience and how to fix this issue.

Thanks
",1,1
49,2018-1-29,2018,1,29,1,7tl2kv,installing tensorflow in spyder for image processing,https://www.reddit.com/r/tensorflow/comments/7tl2kv/installing_tensorflow_in_spyder_for_image/,awais0,1517155756,i want to use opencv and tensorflow at the same time using anaconda. where can i find some tutorials for that?,0,1
50,2018-1-29,2018,1,29,10,7tozdd,Python Deep Learning tutorial: Create a GRU (RNN) in TensorFlow,https://www.reddit.com/r/tensorflow/comments/7tozdd/python_deep_learning_tutorial_create_a_gru_rnn_in/,psangrene,1517191147,,0,4
51,2018-1-29,2018,1,29,17,7tr04l,Java Implementation of the Object Detection API,https://www.reddit.com/r/tensorflow/comments/7tr04l/java_implementation_of_the_object_detection_api/,ZodiacKiller20,1517215299,,0,3
52,2018-1-30,2018,1,30,17,7tzorb,Video faked with A.I Deep learning wow,https://www.reddit.com/r/tensorflow/comments/7tzorb/video_faked_with_ai_deep_learning_wow/,baDoxx,1517301676,,2,4
53,2018-1-31,2018,1,31,3,7u35es,Is TensorFlow good for non-NN ML tasks like logistic regression and/or brute-force algos?,https://www.reddit.com/r/tensorflow/comments/7u35es/is_tensorflow_good_for_nonnn_ml_tasks_like/,1_21-gigawatts,1517337225,"Experienced developer but ML newb here. It seems like all the tutorials are RNNs using MNIST, but my problem doesn't need a NN. I'm currently using Pandas for logistic regression and brute-force operations on large numbers of large data series. I've tried a couple parallel worker frameworks but it runs slower, probably due to sending data across the wire. 

Is this something that TF (or Keras) would be suited for? 

I can add more detail about my problem if that would help.",1,5
54,2018-1-31,2018,1,31,4,7u3mg1,TensorFlow to turn any webcam into Microsoft Kinect,https://www.reddit.com/r/tensorflow/comments/7u3mg1/tensorflow_to_turn_any_webcam_into_microsoft/,maryanav,1517340900,,1,8
55,2018-1-31,2018,1,31,13,7u774z,My performance of LSTM model in tensorflow sometimes failed,https://www.reddit.com/r/tensorflow/comments/7u774z/my_performance_of_lstm_model_in_tensorflow/,Laurence-Lin,1517371801,"
I've referred to an LTSM time series forecasting model on web, and run on IBM stock getting an effective performance.

https://github.com/laurence-lin/IBM-stock-forecasting

But during the running of simulations, sometimes I could get normal performance, sometimes I found the error never decrease during the training epoch.

In the condition that error remain unchanged, I saw that the initial error is larger. I don't know what's wrong with my code.

Does any one know what would be the cause?

Many thanks!
",2,1
56,2018-1-31,2018,1,31,15,7u7wvj,[question] Make two sub-graphs have equal weights,https://www.reddit.com/r/tensorflow/comments/7u7wvj/question_make_two_subgraphs_have_equal_weights/,codythecoder,1517379390,"My program at the moment takes two images, passes them through two ""identical"" convolutional networks, before combining them using some fully connected layers. Order shouldn't be important, so my test data displays the images in a random order. This doesn't seem to be enough, as the convolutional networks seem to be completely different (when I display their activation). As there's no good reason to have them as different networks, I would like to manually force them to be the same weights, but I don't know how I'd go about doing this. How can I get this to work?

I can also supply code if needed, so just ask.",2,1
57,2018-1-31,2018,1,31,17,7u8ibd,Understanding how it learns,https://www.reddit.com/r/tensorflow/comments/7u8ibd/understanding_how_it_learns/,deputy1389,1517387357,"Im currently trying to learn how to use tensorflow. I am currently running the code from this https://www.tensorflow.org/tutorials/layers

How does it actually remember? I don't see an output file. Is it just in memory and has to be run each time to train it?",1,1
58,2018-1-31,2018,1,31,20,7u9ack,[N] A New subreddit for Videofakes produced via MACHINELEARNING (nonporn one,https://www.reddit.com/r/tensorflow/comments/7u9ack/n_a_new_subreddit_for_videofakes_produced_via/,baDoxx,1517398509,,2,6
0,2018-2-2,2018,2,2,1,7ujzif,Labelbox.io: January Product Update,https://www.reddit.com/r/tensorflow/comments/7ujzif/labelboxio_january_product_update/,labelbox,1517503178,,0,0
1,2018-2-3,2018,2,3,17,7uybec,I need help regarding tf serving,https://www.reddit.com/r/tensorflow/comments/7uybec/i_need_help_regarding_tf_serving/,saurabhvyas3,1517648311,"I basically want to ask 3 questions :

1. Will tf serving work on pi 3 if I use docker ? 

2. If we download the tf serving docker image , then why do we have to build tf serving again ? Can't we get a docker image which has tf serving prebuilt?

3. Can I use grpc protocol in Android/iOS mobile app , so essentially can a mobile become a tf serving client ?

",0,1
2,2018-2-3,2018,2,3,20,7uyru5,[TENSOR FLOW MACHINELEARNING] Nicolas THE ROCK Cage Movie Collection,https://www.reddit.com/r/tensorflow/comments/7uyru5/tensor_flow_machinelearning_nicolas_the_rock_cage/,baDoxx,1517656438,,2,12
3,2018-2-4,2018,2,4,0,7uzypx,Slim import name error despite updated pythonpath,https://www.reddit.com/r/tensorflow/comments/7uzypx/slim_import_name_error_despite_updated_pythonpath/,Kriel1,1517672248,"I'm currently trying to run an implementation of the Creative Adversarial Network (CAN), a Generative Adversarial Network for fine art generation (https://github.com/mlberkeley/Creative-Adversarial-Networks) on Windows. I'm using Tensorflow-GPU 1.5 (installed via pip), CUDA 9.0 and Python 3.6.

I got the seemingly common ""ImportError: No module named nets"" error (see https://github.com/tensorflow/models/issues/1842), and implemented the fix that thread (and multiple others) recommended: updating my PYTHONPATH a la:

export PYTHONPATH=$PYTHONPATH:&lt;mylocaldir&gt;:&lt;mylocaldir&gt;/slim


(I used System&gt;Edit the system environment variables). I have done this separately using both the directory where I have installed tensorflow (~/tensorflow/contrib/slim), and using the /slim directory in the CAN repo itself (~/Creative-Adversarial-Network/slim), but neither work, as I now get the following error:

from nets import cifarnet
ImportError: cannot import name 'cifarnet'

For some reason, the line above  doesn't trigger an error though.

from nets import alexnet

This works fine.

Why does that line not fail? What should I do next? Any help would be awesome!",0,1
4,2018-2-4,2018,2,4,6,7v24vm,Opening a TensorFlow .pb file,https://www.reddit.com/r/tensorflow/comments/7v24vm/opening_a_tensorflow_pb_file/,landmark_,1517692362,"How do I open a TensorFlow .pb file? The model was developed by somebody else, I need to know what the input and output labels are named.",3,3
5,2018-2-4,2018,2,4,6,7v2c3f,[TENSOR FLOW MACHINELEARNING] Deepfake Vol.2,https://www.reddit.com/r/tensorflow/comments/7v2c3f/tensor_flow_machinelearning_deepfake_vol2/,baDoxx,1517694292,,1,4
6,2018-2-4,2018,2,4,18,7v5x0c,[Tensorflow faceswap] Nicolas Cage at RAW,https://www.reddit.com/r/tensorflow/comments/7v5x0c/tensorflow_faceswap_nicolas_cage_at_raw/,baDoxx,1517737715,,1,7
7,2018-2-5,2018,2,5,2,7v7ys3,Tensor-board Graph Visualization in Jupyter Notebook,https://www.reddit.com/r/tensorflow/comments/7v7ys3/tensorboard_graph_visualization_in_jupyter/,machinelearning147,1517764383,,0,9
8,2018-2-5,2018,2,5,20,7ve256,[TENSORFLOW LEARNING] President Donald Cage Interview CNBC,https://www.reddit.com/r/tensorflow/comments/7ve256/tensorflow_learning_president_donald_cage/,baDoxx,1517828485,,2,6
9,2018-2-5,2018,2,5,21,7vej61,Tensorflow Java,https://www.reddit.com/r/tensorflow/comments/7vej61/tensorflow_java/,lalybay,1517834954,Hello im in a team that developing a ai chat with tensorflow in java. we have not found anything online for this. Is tensorflow not popular to use with java?,4,3
10,2018-2-6,2018,2,6,17,7vm1lu,Tensorflow still using old data over my model,https://www.reddit.com/r/tensorflow/comments/7vm1lu/tensorflow_still_using_old_data_over_my_model/,mohsinajmal,1517906535,"I followed this link https://towardsdatascience.com/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9 to train my own model.

Everything went fine and my custom label is shown in a live video feed as well, however, I still see tensorflow making bounds over the common world objects like it did before and showing my label on it instead. 

I used the pre-configured ssd_inception_v2_pets config file making all the necessary changes. 

Part of the code where I load the graph: 
 cap = cv2.VideoCapture(0);

        sys.path.append("".."")


        MODEL_NAME = 'masked_graph'

        # Path to frozen detection graph. This is the actual model that is used for the object detection.
        PATH_TO_CKPT = MODEL_NAME + '/graph.pb'

        # List of the strings that is used to add correct label for each box.
        PATH_TO_LABELS = os.path.join('data', 'object-detection.pbtxt')

        NUM_CLASSES = 1


        # ## Load a (frozen) Tensorflow model into memory.

        # In[6]:

        detection_graph = tf.Graph()
        with detection_graph.as_default():
            od_graph_def = tf.GraphDef()
            with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:
                serialized_graph = fid.read()
                od_graph_def.ParseFromString(serialized_graph)
                tf.import_graph_def(od_graph_def, name='')


        label_map = label_map_util.load_labelmap(PATH_TO_LABELS)
        categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)
        category_index = label_map_util.create_category_index(categories)
",8,1
11,2018-2-6,2018,2,6,19,7vml3g,[TENSORFLOW] Jennifer Connelly Nicolas Cage Interview,https://www.reddit.com/r/tensorflow/comments/7vml3g/tensorflow_jennifer_connelly_nicolas_cage/,baDoxx,1517914582,,2,0
12,2018-2-6,2018,2,6,23,7vnp8n,No module named object_detection,https://www.reddit.com/r/tensorflow/comments/7vnp8n/no_module_named_object_detection/,mtutnid,1517927730,Im trying to run the create_pascal_tf_record.py script. And I get the error above. Im running on a Windows 10 machine. TF installed through pip. There is no models directory and all the fixes tell me to run a script thats supposed to be there,4,1
13,2018-2-7,2018,2,7,19,7vv678,Cage Loves Britney [ tensor learning ],https://www.reddit.com/r/tensorflow/comments/7vv678/cage_loves_britney_tensor_learning/,baDoxx,1517998835,,0,0
14,2018-2-8,2018,2,8,17,7w3eg6,Protobufs compiled cannot import name 'preprocessor_pb2',https://www.reddit.com/r/tensorflow/comments/7w3eg6/protobufs_compiled_cannot_import_name/,[deleted],1518078041,[deleted],0,1
15,2018-2-8,2018,2,8,18,7w3s1u,Low GPU usage Faster-RCNN,https://www.reddit.com/r/tensorflow/comments/7w3s1u/low_gpu_usage_fasterrcnn/,mtutnid,1518083742,"I'm trying to train using a pretrained model and I'm following [this guide](https://towardsdatascience.com/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9). 


But I have very low GPU utilization ~10-20%. GeForceGTX 1080

What could be the cause?",2,3
16,2018-2-8,2018,2,8,22,7w4us3,Mr. Trololol Cage,https://www.reddit.com/r/tensorflow/comments/7w4us3/mr_trololol_cage/,baDoxx,1518097443,,0,0
17,2018-2-9,2018,2,9,0,7w5lwc,Deepfake Compilation [ Tensorflow ],https://www.reddit.com/r/tensorflow/comments/7w5lwc/deepfake_compilation_tensorflow/,baDoxx,1518104241,,0,1
18,2018-2-9,2018,2,9,11,7wa4ui,Deepfakes Detection,https://www.reddit.com/r/tensorflow/comments/7wa4ui/deepfakes_detection/,Amekaze,1518141651,"Since the deepfake program was developed with tensor flow. Would it correct to say that a program can be developed using tensor flow that can detect if a video was altered with deepfake? 

I'm currently learning how to use tensor and I was just wondering if this is possible. ",5,1
19,2018-2-9,2018,2,9,11,7waa47,Using TensorFlow to predict a concentration over time?,https://www.reddit.com/r/tensorflow/comments/7waa47/using_tensorflow_to_predict_a_concentration_over/,ThexLizardxKing,1518143116,"Hi all,

I'm pretty new to ML in general, and want to make sure I'm learning the right things for a project I'm working on. Say I'm trying to predict a concentration at time t, C(t). A very simple example of this would be C(t) = C(initial)*exp(-t).

Let's say I want to predict the concentration every 0.1 seconds. I was thinking I would use an LSTM (assuming my understanding of LSTMs is correct) and input C(t=0) and t=.1 to output C(t=.1), which would then be inputted with t=.2 to output C(t=.2) and so forth. Ideally, I want to train it at multiple initial concentrations (such as 1, 5, 7), then give it a new C(initial) such as 2, and have it predict the concentrations along a series of times.

I'm planning to work on something a bit more complicated than this, but I figured this would be a good starting place. Is my idea to use an LSTM the right way of going about this, or is there a better way?

I hope my explanation makes sense, let me know if it doesn't.",2,2
20,2018-2-9,2018,2,9,11,7waeez,import tensorflow as tf error (need help),https://www.reddit.com/r/tensorflow/comments/7waeez/import_tensorflow_as_tf_error_need_help/,Shmall27,1518144328,"I got an error saying ""ImportError: Could not find 'cudart64_90.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 9.0 from this URL: https://developer.nvidia.com/cuda-toolkit"" and I checked in the bin folder and I found that exact file it was looking for. Any help would be much appreciated. Thanks!",13,0
21,2018-2-9,2018,2,9,15,7wbksa,What is the exact architecture in LSTM cell model?,https://www.reddit.com/r/tensorflow/comments/7wbksa/what_is_the_exact_architecture_in_lstm_cell_model/,Laurence-Lin,1518157192,"I've been using lstm cell in tensorflow.contrib.rnn.BasicLSTMCell, and read colah's blog:

http://colah.github.io/posts/2015-08-Understanding-LSTMs/

And an implementation basis of BasicLSTMCell reference:

http://arxiv.org/abs/1409.2329

I can see introduction of some functions in LSTM, such as forget, add new, select predictions... in colah's blog. But I don't know the exact architecture in it, such as where is the neurons? Is each operator, such as multiplication, sigmoid function, ...etc stands for an neuron? Is the connections through the sequence same as connections with weight in a normal neural network?

When I initialize an LSTM, I define number of unit, I bet this is the number of neurons in a single layer? But how could I define how many layer is there?

Thanks for helping.",0,1
22,2018-2-9,2018,2,9,19,7wclfp,Cage after Dentist [ tensorflow ],https://www.reddit.com/r/tensorflow/comments/7wclfp/cage_after_dentist_tensorflow/,baDoxx,1518172356,,0,0
23,2018-2-9,2018,2,9,22,7wdjl5,Interactive supervision with TensorBoard,https://www.reddit.com/r/tensorflow/comments/7wdjl5/interactive_supervision_with_tensorboard/,ibmzrl,1518184292,,0,4
24,2018-2-10,2018,2,10,0,7wdzmj,Cage said No,https://www.reddit.com/r/tensorflow/comments/7wdzmj/cage_said_no/,baDoxx,1518188615,,0,0
25,2018-2-10,2018,2,10,4,7wftl2,"[Question] Tensorflow, tf.gradients calculation",https://www.reddit.com/r/tensorflow/comments/7wftl2/question_tensorflow_tfgradients_calculation/,HakaiShinBeerus,1518203684,"I am learning how to use Tensorflow and at this 1 particular point I am really stuck and can not make a sense around it. Imagine I have a 5 layer network and the output is represented by &lt;code&gt;output&lt;/code&gt;. Now suppose I want to find the gradient of &lt;code&gt;output&lt;/code&gt; with respect to &lt;code&gt;layer_2&lt;/code&gt;. For that purpose, the code I will write in Tensorflow will be something like:

    
    gradients_i_want = tf.gradients(output, layer_2)

Theoretically, this gradient should be calculated via chain rule. I want to ask, that whether Tensorflow calculates these gradients via chain rule or it will just take the derivative of &lt;code&gt;output&lt;/code&gt; with respect to &lt;code&gt;layer_2&lt;/code&gt;
",0,1
26,2018-2-10,2018,2,10,5,7wggco,"I need help with restoring a model which was trained using tf.estimator, and performing inference on it using a feed_dict rather than tf.data.Dataset",https://www.reddit.com/r/tensorflow/comments/7wggco/i_need_help_with_restoring_a_model_which_was/,deepaksuresh,1518208992,"I have trained a model using tf.estimator, the model was saved as .meta, .index, and .data files. I would like to restore the model and get predictions out of it by feeding images directly. The input pipeline consists of tf.data.Dataset. I can use the classifier.evaluate method in the model to get prediction for the whole dataset, but I'd like to see the prediction for individual images. That is why I'd like to use a feed_dict.
Please take a look at the question I opened on stackoverflow [here](https://stackoverflow.com/questions/48679622/restoring-a-model-trained-with-tf-estimator-and-feeding-input-through-feed-dict)
Thank you for your time",0,1
27,2018-2-10,2018,2,10,6,7wglro,Stupid Tensorflow tricks: A new take on an old (Thomson) problem,https://www.reddit.com/r/tensorflow/comments/7wglro/stupid_tensorflow_tricks_a_new_take_on_an_old/,cosmic_dozen,1518210226,,0,10
28,2018-2-10,2018,2,10,18,7wkmi0,One Cage To Bind Them All,https://www.reddit.com/r/tensorflow/comments/7wkmi0/one_cage_to_bind_them_all/,baDoxx,1518256671,,0,0
29,2018-2-10,2018,2,10,23,7wlksa,basics problem,https://www.reddit.com/r/tensorflow/comments/7wlksa/basics_problem/,specialpatrol,1518271305,"So i'm trying to get to grips with the basics here and ma faiiliing to prove something which I believe should be straight forward to myself. Here's some code:

    sess = tf.Session()

    x_data = tf.placeholder(shape=[img_size], dtype=tf.float32)
    y_target = tf.placeholder(shape=[1], dtype=tf.float32)

    # Create variable (one model parameter = A)
    A = tf.Variable(tf.random_normal(shape=[1]))

    # Add operation to graph
    my_output = tf.multiply(tf.reduce_sum(x_data), A)

    # Add L2 loss operation to graph
    loss = tf.losses.absolute_difference(my_output, y_target)

    # Initialize variables
    init = tf.global_variables_initializer()
    sess.run(init)

    # Create Optimizer
    my_opt = tf.train.GradientDescentOptimizer(0.02)
    train_step = my_opt.minimize(loss)

    # Run Loop
    for i in range(training_entries):

        input_x = data_helpers.get_image_batch(images_data, 1, i).reshape(img_size)
        output_y = data_helpers.get_result_batch(result_data, 1, i)
        sess.run(train_step, feed_dict={x_data: input_x, y_target: output_y})
        if (i+1)%25==0:
            print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)))
            print('Loss = ' + str(sess.run(loss, feed_dict={x_data: input_x, y_target: output_y})))


I have created a load of test images. They are in the form of blocks of 1024 floating point values, representing single channel images. They vary in the number of black and white pixels they have. The ""result_data"" is a corresponding float value between 0-1 which  denotes the ratio of black to white pixels in the image. I can verify the data by viewing the images in opencv and comparing the result with the result data.

So my first input data is a tensor array 1024. My target is the single float value. I have a variable 'A' which I hope to train to get me from the input to the output. If you look at ""my_output"" I sum my input data values and multiply that by A. I believe A should simply converge on 1.0/1024.0. But it doesn't, alas. I've tried making the 'A' value 1024 in size and then doing the ""reduce_sum"" in the loss function, comparing it to the output. As you may see I'm quite unconfident about the ""my_output"" part and the ""loss"" function. Although at this point I'm pretty unsure of the whole thing. 

Any advice/help much appreciated.",6,1
30,2018-2-11,2018,2,11,22,7wsvid,Any free cloud computing alternatives to use with TensorFlow?,https://www.reddit.com/r/tensorflow/comments/7wsvid/any_free_cloud_computing_alternatives_to_use_with/,rraallvv,1518357059,"I'd like to try out TensorFlow running somewhere in a cloud computing environment, are there any free alternatives.",4,3
31,2018-2-12,2018,2,12,3,7wuctc,Visual Optimization using plotly and optunity,https://www.reddit.com/r/tensorflow/comments/7wuctc/visual_optimization_using_plotly_and_optunity/,machinelearning147,1518372378,,0,2
32,2018-2-12,2018,2,12,7,7ww9he,Opinions on the Tensorbook?,https://www.reddit.com/r/tensorflow/comments/7ww9he/opinions_on_the_tensorbook/,JDF_99,1518389270,Is [the tensorbook](https://lambdal.com/products/tensorbook) just a really good way to sell a preinstalled laptop or does it actually do something a laptop with similar specs can't do? ,10,0
33,2018-2-13,2018,2,13,5,7x3p4k,[Help Needed] Adding a python function to the data loading stage,https://www.reddit.com/r/tensorflow/comments/7x3p4k/help_needed_adding_a_python_function_to_the_data/,burn_in_flames,1518466972,,0,0
34,2018-2-13,2018,2,13,19,7x8jgl,Maths operations in Tensorflow  Krunal Kapadiya  Medium,https://www.reddit.com/r/tensorflow/comments/7x8jgl/maths_operations_in_tensorflow_krunal_kapadiya/,krunal3kapadiya,1518518015,,0,1
35,2018-2-14,2018,2,14,9,7xe6vf,Any good book with practical approach to learn TF?,https://www.reddit.com/r/tensorflow/comments/7xe6vf/any_good_book_with_practical_approach_to_learn_tf/,mrm8488,1518569242,,6,1
36,2018-2-14,2018,2,14,17,7xgqg4,Looking to learn and play,https://www.reddit.com/r/tensorflow/comments/7xgqg4/looking_to_learn_and_play/,eangulus,1518598396,"Hi,

Firstly like most I guess, I learn from actually doing rather than reading a manual.

What I am looking for is some tutorials on how to get tensorflow setup and working with some real examples on doing object detection in videos.

In particular I am researching for a manufacturing business the possibility of doing live object detection using the existing security cameras. We mainly run 1080p Hikvision and use Blue Iris for the setup, and I have managed to get a constant stream of snapshots at 1 sec intervals for a 60sec loop. I did this part as most tutorials I read uses a folder of snapshots.

I am needing help on finding an example and tutorial on complete setup that will take the live video stream or folder of snapshots and output a new stream with the object detection continuiosly. Maybe even output a list of objects and timestamp of what it detected.",2,1
37,2018-2-14,2018,2,14,20,7xhbju,Cage Rampage Reloaded [ Deepfake ],https://www.reddit.com/r/tensorflow/comments/7xhbju/cage_rampage_reloaded_deepfake/,baDoxx,1518607042,,0,1
38,2018-2-15,2018,2,15,0,7xiwa7,[Help] Estimator's train function doesn't work.,https://www.reddit.com/r/tensorflow/comments/7xiwa7/help_estimators_train_function_doesnt_work/,Makenjoy,1518623165,"Very new, to tensorflow. Please forgive me.

I was trying to test the tensorflow estimators so I started with something I would think would be super simple. Build a neural network that works like an AND gate. [I used this guide for assistance.](https://developers.googleblog.com/2017/09/introducing-tensorflow-datasets.html)

When I run it, the train function just keeps running forever. (At least over 5 minutes) considering that there is a repeat count of 1 that seems like enough time.

I would love to give a more direct question, but I have no idea because no error message is outputted. So here is all of the code:

    import tensorflow as tf
    import random as random
    import numpy as np
        
    
    PATH = 'C:\Tensorflow'
    feature_names = ['Arg1','Arg2']
    
    data_And = np.array([[0,1,0,1],
                        [0,1,1,0],
                        [0,1,0,0]],dtype = int) # Generate data for AND gate
        
    def my_input_fn(data, perform_shuffle=False, repeat_count=1):
        batch_features = {'Arg1':data[0],'Arg2':data[1]}
        batch_lab els = data[2]
    
    
    return (batch_features, batch_labels)
    
    dataset = my_input_fn(data_And)
    
    feature_columns = [tf.feature_column.numeric_column(k) for k in feature_names]
    
    classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns, # The input features to our model
                                               hidden_units=[2,2],
                                               n_classes=2,
                                               model_dir=PATH)
    
    print('Test') # Prints
    
    classifier.train(input_fn=lambda: my_input_fn(data_And, False, 1)) # Stops here
    
    print('Test2') # Doesn't print   ",3,1
39,2018-2-15,2018,2,15,2,7xjkt3,Why does TensorFlow not have an easy API for multi-GPU?,https://www.reddit.com/r/tensorflow/comments/7xjkt3/why_does_tensorflow_not_have_an_easy_api_for/,ascenator,1518628562,"I would like to know why the TensorFlow API has no easy approach for multi-GPU usage (compared to Keras for example).

I understand that some complex models require the user to built his own towers and then set up his own loss functions and stuff, but most times all one has to do for multi-GPU training is splitting let's say one 128 samples batch into two 64 samples batches, compute this on two different GPUs, combine the losses and update the model with respect to the combined loss.

This is exactly what Keras does if you call:

    parallel_model = multi_gpu_model(model, gpus=2)

Afaik (don't use keras very often), this one-liner is everything one would need to train a model on multiple GPUs in parallel.

Why is there no equivalent in TensorFlow itself?",1,8
40,2018-2-15,2018,2,15,4,7xknaz,"Need help/code-review with my TF model, not learning",https://www.reddit.com/r/tensorflow/comments/7xknaz/need_helpcodereview_with_my_tf_model_not_learning/,[deleted],1518636943,[deleted],0,1
41,2018-2-15,2018,2,15,4,7xkogr,How to handle Multiple feature input for RNN in TF?,https://www.reddit.com/r/tensorflow/comments/7xkogr/how_to_handle_multiple_feature_input_for_rnn_in_tf/,samratsk,1518637212,I have a data set with 5 features and i need to predict one of the feature at time t+1. I understood on handling one feature as both input and output. Can someone give inputs on how to handle 5 features in tensor flow?,0,1
42,2018-2-15,2018,2,15,6,7xlgfr,Augmenting existing backend OPs with embedded data structure,https://www.reddit.com/r/tensorflow/comments/7xlgfr/augmenting_existing_backend_ops_with_embedded/,MurphyM,1518643466,"I'm trying to contribute an augmented CTC Decoder op that utilizes a less-conventional data structure to inform the Beam Search used as part of the decoding. I want to generate this data structure from an input SparseTensorValue in python.

Would it make more sense generate and embed the data structure within the augmented CTC Decoder op? In such an implementation, the augmented op would now take an additional SparseTensorValue as input. Alternatively, I could create a new Op that take a SparseTensorValue as input, and generates and outputs the resulting data structure?

I want my contribution to maintain modularity, as I see this data structure as something that may potentially be useful in alternative tasks such as sequence to sequence modeling. However, I also wouldn't want to clutter contrib. What would be the more appropriate approach for such a contribution?",0,1
43,2018-2-15,2018,2,15,21,7xpxbo,Prediction using TensorFlow Estimator (Quickdraw: RNN with LSTMs),https://www.reddit.com/r/tensorflow/comments/7xpxbo/prediction_using_tensorflow_estimator_quickdraw/,uridah,1518696367,"I am following this tutorial:
https://www.tensorflow.org/versions/master/tutorials/recurrent_quickdraw#training_and_evaluating_the_model
This contains a step by step description on how to convert your dataset to tfrecord format and then use training and evaluation to train a recurrent neural network.
What I am trying to figure out is that, is there a way we can test i.e. predict given a single example. For instance, a drawing of a cat. Would we need to convert our prediction sample to tfrecord before feeding it to the network?

It makes use of Estimator for training and evaluation. How can we use an Estimator to predict. Where do we need to make the changes to the model_fn.",2,3
44,2018-2-16,2018,2,16,6,7xtj2u,Network trains fine in PyTorch. Something Wrong in Tensorflow.,https://www.reddit.com/r/tensorflow/comments/7xtj2u/network_trains_fine_in_pytorch_something_wrong_in/,closedloopy,1518728567,"Hey Guys,

Posted [this](https://stackoverflow.com/questions/48796439/pytorch-network-training-tensorflow-network-is-not-cant-spot-difference) on StackOverflow, but no one responded :(

Could Really Use some help!!!

Since I don't really want to duplicate the same issue in two places I'll just link, but really hoping someone from this community has some ideas, I'm totally stumped!

In case that think above is hard to see: https://stackoverflow.com/questions/48796439/pytorch-network-training-tensorflow-network-is-not-cant-spot-difference
",2,7
45,2018-2-16,2018,2,16,10,7xvh2z,"Machine Learning for Manufacturing, Quality Control &amp;amp; Predictive Maintenance",https://www.reddit.com/r/tensorflow/comments/7xvh2z/machine_learning_for_manufacturing_quality/,jk99_datasci,1518746176,"This is a great webinar with a real Machine Learning use case that industries will be interested in. Hope you guys like it

https://youtu.be/e--v6fJi5kw",0,4
46,2018-2-17,2018,2,17,23,7y708a,[Help] How to use a trained LSTM model for prediction.,https://www.reddit.com/r/tensorflow/comments/7y708a/help_how_to_use_a_trained_lstm_model_for/,Aje404,1518878801,"I'm not an expert with Tensorflow but I get all the theory and I'm getting better at it. Looking for advice for someone with skills.

Okay, so I'm training an LSTM with a [batch size]x[time]x[features] tensor.

However, I just want to predict with a 1x[time]x[features]. 

I notice I'm making calls like lstm_network.zero_state[batch_size] in constructing my network. 
Please tell me I'm using the same set of weights across each element in batch_size? I will assume that is the case

So anyway, I want to restore the model back into memory with similar code to the class that I'm using to train the model with, and simply predict 1 element at a time. I'm confused if that will work correctly since I'll be restoring a tensor of different dimension. I'm wondering if I should ""pad"" the 1x[time]x[feature size] tensor INTO a [batch size]x[time]x[feature size] tensor and then ""gather"" the final index of the [batch_size] dimension to get the prediction I'm looking for. 

Hopefully these questions make sense - can someone point me in the right direction at least? I'm guessing my questions have an analogous form for any other type of network as well - so the question probably doesn't need to be LSTM specific",2,2
47,2018-2-18,2018,2,18,3,7y8cnd,"Want to learn how to make your own Convolutional Neural Network for ACCURATE IMAGE CLASSIFYING? Check this video out, and if you enjoy it, make sure to subscribe. :)",https://www.reddit.com/r/tensorflow/comments/7y8cnd/want_to_learn_how_to_make_your_own_convolutional/,DiscoverAI,1518891933,,0,9
48,2018-2-18,2018,2,18,3,7y8iw0,How to direct TensorFlow API to perform image manipulation?,https://www.reddit.com/r/tensorflow/comments/7y8iw0/how_to_direct_tensorflow_api_to_perform_image/,WafflesJohnny,1518893541,"Hey everyone,

I am new to TensorFlow, and I have gone through some basic tutorials online in setting up some machine learning models, training data and inputting your features.

However so far these tutorials only output statistical data. I actually want to set up some functionality to do image manipulation based on the training data and feature input.

Does TensorFlow have an API for image manipulation?",0,1
49,2018-2-18,2018,2,18,17,7yd7yk,Optimization with Tensorflow,https://www.reddit.com/r/tensorflow/comments/7yd7yk/optimization_with_tensorflow/,machinelearning147,1518944311,,0,4
50,2018-2-19,2018,2,19,7,7yhxgl,"Resources for ""Recurrent Neural Networks for Drawing Classification"" Tutorial",https://www.reddit.com/r/tensorflow/comments/7yhxgl/resources_for_recurrent_neural_networks_for/,johnjones4,1518992964,"I am teaching myself Tensorflow right now, and I was wondering if anyone has further extended the example given in the [Recurrent Neural Networks for Drawing Classification](https://www.tensorflow.org/versions/master/tutorials/recurrent_quickdraw#optional_download_the_full_quick_draw_data) tutorial which uses the *Quick Draw!* data. Specifically, I'd love to see an example of using the trained model to recognize one of the individual drawings from the dataset. Thanks!",0,3
51,2018-2-19,2018,2,19,12,7yjqgj,Stable Hypervisor + Distribution for TensorFlow work with Nvidia GPUs,https://www.reddit.com/r/tensorflow/comments/7yjqgj/stable_hypervisor_distribution_for_tensorflow/,TenseLearner,1519010516,"I have put together a headless workstation with the following specs:

**CPU**: Core i7-5930K 3.5GHz 6C/12T

**RAM**: 128 GiB DDR4-2666

**GPU**: 2 x Nvidia 1080 Ti

(Most of these are used parts collected over the last year and a half when the prices were not _that_ crazy).

I'm getting started with TensorFlow for general computer vision work, and would like to know what combination of Linux distribution and hypervisor would be the most stable and easy to maintain in the long-term?

Ideally, I would want to run multiple virtual machines on this computer to make better use of resources and for being able to have a ""clean"" workspace for each project, but can live with just a plain old sort of a system if Virtualization + Nvidia GPUs + TensorFlow don't play well together. Using Docker/LXC is also option.

My preference is for Debian/Ubuntu (as the guest(s), and possibly the host), but that's a fairly light preference.

Any advice on this will be much appreciated!",2,2
52,2018-2-20,2018,2,20,2,7yo72e,LSTM - Need help breaking down weights and biases,https://www.reddit.com/r/tensorflow/comments/7yo72e/lstm_need_help_breaking_down_weights_and_biases/,alluriharikishan,1519060375,"Hi all. I am a high level noob in tensorflow. I really appreciate if anyone can help me with the following problem. 

I built a single layer single cell LSTM model using tensorflows basicLSTM function with reuse set to AUTO_REUSE. My inputs are 2 dimensions and my output is a single dimension. Batch size is 1 as I got 1 big continuous data. Trained the model and results look fantastic. 

Now I tried implementing the trained LSTM in matlab to see if my equations are right. I extracted all the weight from the trained tensorflow model using trainable_weights sub function of basicLSTM. This gave me a 2x4 weight list and a 1x4 bias list. 

So, my question is which column of this weights and biases are input, forget, output &amp; state weights and biases??

Thanks in advance. ",1,2
53,2018-2-21,2018,2,21,3,7yy5eo,Raspberry Pi Cluster &gt; Kubernetes &gt; Tensorflow,https://www.reddit.com/r/tensorflow/comments/7yy5eo/raspberry_pi_cluster_kubernetes_tensorflow/,Gollin_K,1519151098,"I plan on doing a master study that involves research into the field of deep learning and convolutional neural networks to do stuff like style transfer's and experimenting from there. I'm looking into hardware to do this with. I'm currently doing a project with Raspberry Pi's and came by this:

https://www.youtube.com/watch?v=i_r3z1jYHAc&amp;t=343s

I did some testing before with running other people there Tensorflow projects involving style transfers and such. But I don't got a gpu at the moment so things literally took hours. So to be able to do this efficiency, when doing full time research, I would have to get at-least one decent graphics card.

From here on I have to say I'm only speculating about stuff I red online. I have never setup a Raspberry Pi cluster or a have any real experience with Kubernetes or Tensorflow. But I'm interested in using a Raspberry Pi cluster(10/20 RPI3's) to do the computing. Ive red that its possible to run Kubernetes on a RPI cluster and Ive red its possible to run TensorFlow jobs on Kubernetes. 

So in theory it should be possible right? I havent seen any projects that actually did it. Any guesses how efficient it  would be compared to a gpu, energy and cost wise? ",3,7
54,2018-2-21,2018,2,21,6,7yzrds,How to do validation?,https://www.reddit.com/r/tensorflow/comments/7yzrds/how_to_do_validation/,burn_in_flames,1519162415,"I am trying to add validation to a Tensorflow model but don't really know how to. I have tried to find examples but it seems most Tensorflow code doesn't include validation in the training loop? Why is this, and how do people monitor their training if not checking validation losses? I also want to save the images generated from the various validation batches. 

The model is https://github.com/nilboy/colorization-tf

There is a flag when creating the network for training, but if u try create a second network with that flag set false it complains that the layers already exist. And I am not sure if I can have two datasets, due to the graph logic. Any help on how this is normally achieved, or a solid example to build from would be great. I hardly every use Tensorflow so not too familiar with it or what I'm doing.",0,1
55,2018-2-21,2018,2,21,7,7z06e5,Precision/Recall Object Detection,https://www.reddit.com/r/tensorflow/comments/7z06e5/precisionrecall_object_detection/,mtutnid,1519165460,"I couldn't find a way to measure P/R in Tensorflow.

So I tried setting up [this tool](http://liris.cnrs.fr/christian.wolf/software/deteval/#underthehood), but it seems to be old and I can't get it to work.

After I install it it says that iconv.dll and zlib1.dlls are missing. 

I found out that I have to add the PATH variable for mingw. The problem then is that iconv.dll doesn't exist in the bin folder only  a iconv.exe. If I download iconv.dll separately the program loads, but crashes immediately after.",0,1
56,2018-2-23,2018,2,23,2,7zgmhg,How to apply constraint to 2D-Conv weights to make it symmetric?,https://www.reddit.com/r/tensorflow/comments/7zgmhg/how_to_apply_constraint_to_2dconv_weights_to_make/,[deleted],1519320617,[deleted],0,1
57,2018-2-23,2018,2,23,4,7zhp6e,Row wise lookup table in Tensorflow,https://www.reddit.com/r/tensorflow/comments/7zhp6e/row_wise_lookup_table_in_tensorflow/,nightshade_7,1519328589,"Currently I have a matrix in which each row is a lookup table. Corresponding to it I have a coded matrix with the same number of rows as the lookup table. e.g.

&gt; LookupTable (matrix size 100, 32)

&gt; CodedMatrix (matrix size 100, 1000)

So the lookup table values match to the corresponding row of the coded matrix. The code matrix contains numbers from 0 to 31 which have a corresponding value in the Lookup table for that specific row.

The final output of this should be 

&gt; DecodedMatrix(matrix size 100, 1000)

In which each value of the row is replaced with it's corresponding lookup output.

Currently in numpy I use a for loop, because at the end I sum up the decoded matrix along the row axis for the final output. The code looks like this

       out = sum([C[L] for C,L in zip(CodedMatrix, LookupTable)])

which is a still inefficient. But in Tensorflow I use

     nRows = tf.constant(100, name=""nRows"")
     n     = tf.Variable(tf.constant(0))

     def cond(n, out):
         return n &lt; nRows

     def body(n, out):  
         out = out + tf.gather(LookupTable[m,:], CodedMatrix[m,:])
         return n+1, out

     out = tf.while_loop(cond, body, [n, out])[1]

This execution takes a lot of time, because each time a new tensor is created and using the loop isn't very efficient.

Is there a way to do this without using while loop? Does tf.gather have any setup to do lookup like this?
",5,1
58,2018-2-23,2018,2,23,5,7zhu80,How use constraint to make weights symmetric in TensorFlow?,https://www.reddit.com/r/tensorflow/comments/7zhu80/how_use_constraint_to_make_weights_symmetric_in/,[deleted],1519329651,[deleted],0,1
59,2018-2-23,2018,2,23,8,7zjgqc,How to make a random forest predictive model for a dataset contained in a CSV file in TensorFlow?,https://www.reddit.com/r/tensorflow/comments/7zjgqc/how_to_make_a_random_forest_predictive_model_for/,1cedrake,1519342416,"Hello all. I have a big CSV file of data, where I have several columns of data involving temperature, as shown here: https://imgur.com/NxG18jo My goal is to make a predictive model for predicting the 'Ambient Temperature' column, based off the input variables of the 'Battery Temperature', 'Battery Level', 'Battery Voltage', and 'CPU Usage' columns. I can do this fairly easily in MATLAB using the regression learner, however I'm unsure of how to do a similar thing using Tensorflow. In particular, I'm interested in a random forest model. Any help would be appreciated!",7,0
60,2018-2-23,2018,2,23,12,7zl6lg,Can anyone tell me how to create a speech recognition system using tensor flow?,https://www.reddit.com/r/tensorflow/comments/7zl6lg/can_anyone_tell_me_how_to_create_a_speech/,jishnup,1519358130,,5,1
61,2018-2-23,2018,2,23,14,7zll0s,MNIST Tutorial with Tensorflow Dataset API,https://www.reddit.com/r/tensorflow/comments/7zll0s/mnist_tutorial_with_tensorflow_dataset_api/,cjalmeida,1519362210,,1,4
62,2018-2-24,2018,2,24,4,7zqrt9,Why isn't the output of the weight matrix circulant/Toeplitz?,https://www.reddit.com/r/tensorflow/comments/7zqrt9/why_isnt_the_output_of_the_weight_matrix/,74throwaway,1519414539,"Let's say I have an original image and use just *ONE* filter to blur that image for the first part of the CNN. Suppose the original image is 100x100, the filter is 5x5 and the resulting blurred image is 100x100. 

From what I understand, in order to multiply the original image and the 5x5 NN weight matrix with matrix multiplication, it would have to be sparse matrix multiplication and the weight matrix has to be a *circulant* matrix 

Yet, when I use Tensorflow, Keras, or PyTorch, and then display the weight matrix, it doesn't appear to be circulant/Toeplitz at all? Why  is this?",1,1
63,2018-2-24,2018,2,24,14,7zuiup,Thrift with Tensorflow,https://www.reddit.com/r/tensorflow/comments/7zuiup/thrift_with_tensorflow/,outsidefarmland,1519449121,"I was wondering if Thrift/Scrooge is compatible with Tensorflow. If so, is there any documentation on it?",0,1
64,2018-2-25,2018,2,25,5,7zz3l1,Get Set Go with TensorFlow,https://www.reddit.com/r/tensorflow/comments/7zz3l1/get_set_go_with_tensorflow/,machinelearning147,1519502502,,1,6
65,2018-2-25,2018,2,25,9,800wmr,Help with Android Demo compile.. Will pay!,https://www.reddit.com/r/tensorflow/comments/800wmr/help_with_android_demo_compile_will_pay/,[deleted],1519519142,[deleted],0,1
66,2018-2-25,2018,2,25,9,800zdn,Help with compiling android demo... Will pay!,https://www.reddit.com/r/tensorflow/comments/800zdn/help_with_compiling_android_demo_will_pay/,Nopo1188,1519519869,"Hi all,

I made a training model with tensorflow for poets, optimized my graph... But am having tremendous trouble with compiling it into the TF demo classify app in Android studio.

Im an android newbie, can anyone help?

I can PayPal you or Amazon gift card you for your time =) I would just need a short TeamViewer or similar demo of how to compile working app. The app I am compiling keeps crashing. PM me or reply here if you can help! ",2,1
67,2018-2-25,2018,2,25,13,80232h,Plugin to compute custom dags on TensorFlow?,https://www.reddit.com/r/tensorflow/comments/80232h/plugin_to_compute_custom_dags_on_tensorflow/,MockingBird421,1519531298,"I'm a long term TensorFlow user. I happen to have some really large custom DAGs of simple operators (addition, etc) that I need to compute and I can't find a better execution engine than TensorFlow, which has a DAG computation engine itself. However it doesn't natively support execution of custom graphs; what would it take to use it's compute engine for that?",2,1
68,2018-2-28,2018,2,28,4,80p8r4,TensorFlow setup,https://www.reddit.com/r/tensorflow/comments/80p8r4/tensorflow_setup/,uPtiKool,1519759382,"Hi all I am new to tensorflow and am looking forward to learning about TensorFlow, I needed help to get tensorflow up and running i have python 3.5.4 currently installed and was able to pip install tensorflow.  When I try to import tensorflow as tf i get this error


`Error importing tensorflow. Unless you are using bazel, you should not try to import tensorflow from `

`its source directory; please exit the tensorflow source tree, and relaunch your python interpreter from there.  `



I don't know what i am doing wrong any help would be appreciated
",6,0
69,2018-2-28,2018,2,28,12,80t0io,Need help with SVM implementation,https://www.reddit.com/r/tensorflow/comments/80t0io/need_help_with_svm_implementation/,alphanook,1519789922,"I am starting out learning TensorFlow and I am following the TensorFlow Cookbook by Nick McClure. This book has been great so far in explaining foundational concepts of TF but I have run into an issue with the SVM implementation. 

You can see the code [here](https://github.com/PacktPublishing/TensorFlow-Machine-Learning-Cookbook/blob/master/Chapter%2004/nonlinear_svm.py).

I tried to use this implementation with the linear kernel but the model fails to converge:

    my_kernel = tf.matmul(x_data, tf.transpose(x_data))
    pred_kernel = tf.matmul(x_data, tf.transpose(prediction_grid))

I am unable to figure out how the intercept term in the prediction function is applied. Is the **- tf.reduce_mean(prediction_output)** calculating the intercept?

    prediction_output = tf.matmul(tf.multiply(tf.transpose(y_target), alpha), tf.matmul(x_data, tf.transpose(prediction_grid)))
    prediction = tf.sign(prediction_output - tf.reduce_mean(prediction_output))


Any ideas? I have been struggling with this for several days.",3,1
0,2018-3-1,2018,3,1,15,8137wj,Why does it necessary for input in nn.dynamic_rnn to be an 3D tensor?,https://www.reddit.com/r/tensorflow/comments/8137wj/why_does_it_necessary_for_input_in_nndynamic_rnn/,Laurence-Lin,1519885222,"In the tensorflow document of tf.nn.dynamic_rnn, it says that the 'inputs' term states for [batch size, max time, ...]

I can understand the first two terms, while if I use input as an 2-D tensor, ex: nn.dynamic_rnn(cell, inputs = [batch size, max time])

It may cause error. What does the third term in 'inputs' stands for? I have to create an new dimension by newaxis, which confuses me when doing this.

Thanks a lot.",3,5
1,2018-3-2,2018,3,2,5,818ma8,Looking for an example,https://www.reddit.com/r/tensorflow/comments/818ma8/looking_for_an_example/,Finchlo,1519937377,"Hi,

I am looking for a basic example in Tensor flow of how to implement the following:

https://en.wikipedia.org/wiki/Collaborative_filtering

Ideally in Python.",2,1
2,2018-3-2,2018,3,2,7,819imi,TensorFlow and tf.keras: Batch Normalization to train deep networks faster,https://www.reddit.com/r/tensorflow/comments/819imi/tensorflow_and_tfkeras_batch_normalization_to/,crawles89,1519944279,,0,10
3,2018-3-2,2018,3,2,15,81cde5,TensorFlow 1.6.0 released,https://www.reddit.com/r/tensorflow/comments/81cde5/tensorflow_160_released/,makerro,1519972675,,0,24
4,2018-3-2,2018,3,2,17,81csmu,What is the network architecture of hidden layer inside an LSTM?,https://www.reddit.com/r/tensorflow/comments/81csmu/what_is_the_network_architecture_of_hidden_layer/,Laurence-Lin,1519978770,"I'm not sure what is the architecture in the hidden layer &amp; output layer? According to this blog: http://colah.github.io/posts/2015-08-Understanding-LSTMs/  and BasicLSTMCell in tensorflow, here is my assumption after reading some reference:

Hidden state: size (h,1), then input an (h,1) matrix into cell to be the (i, f, o, g) factor. If current input x have size (n,1), then we concatenate it with previous output which have size h*1, thus
input neurons may have size (n+h). Thus, the size of weight matrix may be (n+h) * h.

Output state: output of the LSTM cell, size same as hidden state, since the input to cell have size of hidden state and the calculation inside the cell is all bit-wise calculation. 

Output value: create an fully connected layer that output an value. If hidden state have size h * 1, then size of weight matrix in this layer may be h * 1. 

Thus, for an single LSTM cell which has four input channel (i, f, o, g) and the output layer, there will be 5 weight matrix that should be optimized: 4 with size h * (n+h) for hidden layer, 1 with size h*1 for output layer.

Am I correct?

I hope I can draw an detail chart for the LSTM architecture after fully understand. Thanks!",0,3
5,2018-3-4,2018,3,4,7,81teth,TensorFlow for Perl and Other Languages?,https://www.reddit.com/r/tensorflow/comments/81teth/tensorflow_for_perl_and_other_languages/,tektektektektek,1520115115,"Is there any scope in the future for TensorFlow for other languages? Right now it appears TensorFlow is only available for Python (I'm not even sure which Python).

Even a documented C binding might make it universally available.",2,0
6,2018-3-6,2018,3,6,1,8276pe,Efron partial likelihood estimator for Cox PH model,https://www.reddit.com/r/tensorflow/comments/8276pe/efron_partial_likelihood_estimator_for_cox_ph/,bydmitry,1520267606,,0,2
7,2018-3-6,2018,3,6,11,82bh5q,how to write cleaner TF code,https://www.reddit.com/r/tensorflow/comments/82bh5q/how_to_write_cleaner_tf_code/,jehan60188,1520301825,"I've put together TF code, and have training blocks similar to what's found here: https://github.com/ardiya/siamesenetwork-tensorflow/blob/master/train.py

so, isolating the network is straightforward enough- put the network and loss function in their own file as their own functions.

But the actual training seems pretty intense, in train.py, everything after line 44.  Just seems like it could be cleaner, or more object-oriented.

Are there any tensorflow programming paradigms to help shorten up code and make it easier to read?",1,3
8,2018-3-6,2018,3,6,11,82bmla,Is there a good series of tutorials about the usage of Keras? Struggling to find a good start,https://www.reddit.com/r/tensorflow/comments/82bmla/is_there_a_good_series_of_tutorials_about_the/,Navigia,1520303228,"Hey, I'm currently working with TF/Keras/OpenCV for a project and while I'm getting example codes to work and I'm able to understand how the code is structured, I often wonder *why* they choose certain parameters. For example in the model definition. How many Convolutional layers, what kind of layer, what parameters, what pool size, what kind of activation, etc?

Is there any other way than trial and error? ",5,6
9,2018-3-6,2018,3,6,20,82ecsy,No module named nets | windows 10,https://www.reddit.com/r/tensorflow/comments/82ecsy/no_module_named_nets_windows_10/,djerrund,1520335613,"Hi there,

I'm quite new to Tensorflow and Python. I've already solved many errors which I encountered when trying to get started with the Tensorflow Object Detection model, however the one I get now has been busting my brains for the past days.

I'm trying to test my installation using the ""python object_detection/builders/model_builder_test.py""

But then I get the error ""  from nets import inception_resnet_v2
ImportError: No module named 'nets' ""

After searching for answers I find many answers saying it has something to do with PYTHONPATH. Most answers say use ""export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim "" Which is code for Linux... 

I tried adding the Slim folder to my path system variable, but the errors keeps coming.

Can somebody ELI5 how I can solve this? 

",1,1
10,2018-3-6,2018,3,6,22,82f3p6,Projects with TensorFlow for beginners,https://www.reddit.com/r/tensorflow/comments/82f3p6/projects_with_tensorflow_for_beginners/,AvatarNikhil,1520343427,"especially regarding space exploration, planetary science, earth science.. etc.",0,1
11,2018-3-7,2018,3,7,0,82fsb1,Learning how to AI and Biology at the same time,https://www.reddit.com/r/tensorflow/comments/82fsb1/learning_how_to_ai_and_biology_at_the_same_time/,onidaito,1520349389,,0,2
12,2018-3-7,2018,3,7,0,82ftpm,"An awesome playlist for Tensorflow, I loved it!",https://www.reddit.com/r/tensorflow/comments/82ftpm/an_awesome_playlist_for_tensorflow_i_loved_it/,Debabrata-I,1520349699,,3,26
13,2018-3-8,2018,3,8,0,82pabv,"My tensorflow GPU performance is slower than my CPU. Is my GPU too weak, and my 8 core CPU stronger?",https://www.reddit.com/r/tensorflow/comments/82pabv/my_tensorflow_gpu_performance_is_slower_than_my/,loopuleasa,1520438224,"I have a Zbook 15 G3 laptop which has:

- CPU: [i7-6820HQ 2.7GHz (8-core)](https://www.cpubenchmark.net/cpu.php?cpu=Intel+Core+i7-6820HQ+%40+2.70GHz&amp;id=2659)
- GPU: [Nvidia Quadro M1000M](https://www.videocardbenchmark.net/gpu.php?gpu=Quadro+M1000M)

I ran a script from a pluralsight tutorial, and timed it.

I have a local tensorflow installation with pip

I have a virual env tensorflow-gpu installation within anaconda

- CPU Time to finish: 7 seconds
- GPU time to finish: 21 seconds

Thanks for the help. Trying to experiment with ML.",8,1
14,2018-3-8,2018,3,8,1,82pmst,Some ops can't be defined to handle tensors of different sizes,https://www.reddit.com/r/tensorflow/comments/82pmst/some_ops_cant_be_defined_to_handle_tensors_of/,rigabigadiga,1520440792,"Usually, I can leave the first dimension of a shape undefined, and the network will handle any batch size I want. In my current network I am using tf.zeros() and tf.tile(), which I am giving exact shapes to as arguments. I would like a graph that generalizes across different batch sizes.

I am using tf.zeros() to create the imaginary part for a tf.complex() argument number.

I am using tf.tile() because tf.matmul() doesn't support broadcasting.

I have thought about making separate graphs for different batch size, and make them share variables, but this is not the solution I want",1,3
15,2018-3-8,2018,3,8,13,82uuec,Requesting a quick benchmark,https://www.reddit.com/r/tensorflow/comments/82uuec/requesting_a_quick_benchmark/,psqueak,1520483458,"Hi! I recently wrote a little feed forward network generator. Unfortunately, I've found that actually using the generated networks is unacceptably slow and I can't see how to further trim my implementation.

I'm running `tensorflow-gpu`, but I'm actually sitting on a nvidia 650m with 512 mb of vram and cuda compute capacity 3.0.

Therefore, I was wondering if the speed was just a function of my (rather old) gpu. [I put together a tiny benchmark script](https://gist.github.com/pipsqueaker/90a5c8a97d072b3ca400f68fcfc12f26), and was hoping that you might run it and report back with your results.

The script is just 40 lines, and only depends on tensorflow and numpy (which I'm sure all of you have)- it usually takes 60-90s for me, but on occasion has taken as long as 200.

Also, if any of you see significant inefficiencies in my implementation, I'd be glad to know. I'm puzzled over why I get so much variance and why, when I use this nn repeatedly in some other code I've been writing, it actually slows down appreciably as time goes on",2,1
16,2018-3-8,2018,3,8,15,82vdc2,Simple neural network slowing down as it is queried?,https://www.reddit.com/r/tensorflow/comments/82vdc2/simple_neural_network_slowing_down_as_it_is/,psqueak,1520489459,"I recently wrote a little feed forward network generator. Unfortunately, I've found that actually using the generated networks seems to get slower and slower with time

I've put together the minimum amount of code that exhibits the issue. It requires `tensorflow` and `numpy`, but also `gym`- the minimal installation on pip should work fine.

    import tensorflow as tf
    import numpy as np
    import gym


    def ff_network(name, layer_dims):
        layer_weight_list = [None] * len(layer_dims)
        layers = [None] * len(layer_dims)
        layers[0] = tf.placeholder('float', [None, layer_dims[0]])
        layer_weight_list = [None] * (len(layer_dims) - 1)
        layer_bias_list = [None] * len(layer_weight_list)

        for i, width in enumerate(layer_dims[1:]):
            i += 1

            layer_weights = tf.get_variable(name + str(i), [layer_dims[i - 1], width])
            layer_bias = tf.get_variable(name + str(i) + ""bias"", [layer_dims[i]])
            layer = tf.matmul(layers[i - 1], layer_weights) + layer_bias

            if i != len(layer_dims) - 1:
                layer = tf.nn.sigmoid(layer)

            layer_weight_list[i - 1] = layer_weights
            layer_bias_list[i - 1] = layer_bias
            layers[i] = layer

        return layers, layer_weight_list + layer_bias_list

    def sample_trajectory(env, actor):

        done = False

        obs = env.reset()
        state_dims = len(obs)

        while not done:

            env.render()

            action = actor(obs)
            old_obs = obs
            obs, reward, done, info = env.step(action)

            # Some environments randomly switch state dimensions, coerce to avoid that
            obs = np.reshape(obs, (state_dims,))


    def go(env, scope=""scope""):

        state_dims = len(env.reset())
        action_dims = env.action_space.shape[0]
        actor_nn_dims = [state_dims, 10, action_dims]

        with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):
            actor_nn, actor_weights = ff_network(""actor_nn"", actor_nn_dims)

        with tf.Session() as sess:

            sess.run(tf.global_variables_initializer())

            act_with_noise = lambda state: \
                            sess.run(actor_nn[-1] + tf.random_normal(tf.shape(actor_nn[-1]),
                                                                stddev=.1),
                                {actor_nn[0]: [state]})

            while True:
                sample_trajectory(env, act_with_noise)

    if __name__ == ""__main__"":
        env = gym.make('Pendulum-v0')
        go(env)


If you run the above script then, at least on my machine, you'll start off OK, but given a minute or two the speed (which is reflected in the FPS of the simulation) slows to an absolute crawl.

What's most puzzling to me is that there seems to be no reason for the performance deterioration. I only create the network once, and I'm not storing anything as I loop so python-side memory leaks aren't the cause. I can rule out any issues on `gym`'s side, since if I replace the line
   
    sample_trajectory(env, actor)

with

    sample_trajectory(env, lambda s: [0])

then the simulation runs buttery smooth. This leads me to conclude that there's some persistent state between calls in Tensorflow that I'm unaware of. However I'm very new to the framework, so I have little idea what that might be or how I would fix it.

I also used cProfile to run the script for a while (140s) to the point where the FPS is nearly zero. You can view the [time-sorted log here](https://gist.github.com/pipsqueaker/695146f40de37a8d3f39bcd36347956c). There are clearly a few functions which are taking up most of the time, but they all look like rendering (expected) or Tensorflow internals (which, with my limited experience, I'm not too sure how to interpret).


Anyways, I just found this extremely odd. I could understand my neural network implementation being slow, but it seems to me that it should be equally slow on all calls. The deterioration over time indicates to me that there's something going on which I dont understand.",3,1
17,2018-3-8,2018,3,8,19,82wnk8,Installing tensorflow library wit anaconda,https://www.reddit.com/r/tensorflow/comments/82wnk8/installing_tensorflow_library_wit_anaconda/,Moni93,1520506403,"I'm using anaconda to work with python. I am working with tensorflow for a deep learning project. I needed to instal a package cladded 'tf_utils' (tensorflow utils) , the problem is that i couldn't install it with anaconda : It is from this site : https://pypi.python.org/pypi/tensorflow-utils I tried to follow all steps and replaced pip with conda , but it doesn't help alot . So any help will be appreciated .

",3,2
18,2018-3-9,2018,3,9,7,831mkr,Neural net for 34716 input variables,https://www.reddit.com/r/tensorflow/comments/831mkr/neural_net_for_34716_input_variables/,JustAnotherMe23,1520548093,"Hello! I'm making a neural net for fMRI data, which is kind of like a picture of a brain with boxels(3D pixels) to create 2 categories of people. Unfortunately, when I set up a simple net of 2 hidden layers of 20 nodes each, the cost becomes nan very quickly. I can't figure out how to include all the data with this happening. Pls help! I've limited the batching to 50 for now.

Here's the code. First time using Jupyter so not sure if this runs in terminal well:
# coding: utf-8

# In[32]:


import numpy as np
import tensorflow as tf
import math
import matplotlib.pyplot as plt


# In[33]:


#Get data
def getData(docName):
    doc = open(docName, 'r')
    data_int = doc.read()
    doc.close()
    data_int2 = data_int.split(""\n"")
    data_int2.remove("""")

    data = []
    for x in range(0, len(data_int2)):
        data.append(data_int2[x].split("",""))
    data = np.array(data)
    return(data.astype(float))

print(""starting"")
#raw_data = getData('RawData.txt')
corr_data = getData('CorrData.txt')
#filt_data = getData('FiltData.txt')
age_data = getData('Ages.txt')
shape = corr_data.shape
print(corr_data.shape)


# In[34]:


#Format data
x_train = corr_data

mean_age = age_data.mean()
y_train = np.empty([shape[0], 2])
y_train[:, 0] = np.transpose((age_data &lt; mean_age))
y_train[:, 1] = y_train[:, 0] == 0

#Define batching
class batch:
    def __init__(self, x_matrix, y_matrix):
        self.x_data = x_matrix
        self.y_data = y_matrix
        self.x_shape = x_matrix.shape
        self.y_shape = y_matrix.shape
        
    def get_random(self, size):
        order = range(0, size)
        np.random.shuffle(order)
        x_out = np.empty([size, self.x_shape[1]])
        y_out = np.empty([size, self.y_shape[1]])
        for i in range(0, size):
            row = order[i]
            x_out[i, :] = self.x_data[row, :]
            y_out[i, :] = self.y_data[row, :]
        return(x_out, y_out)

train_batch = batch(x_train, y_train)


# In[41]:


#hyperparameters
learn_rate = 0.001
epochs = 20000
print_step = 50
dropout = 1
BATCH_SIZE = 50

#Network variables
ins = 69696
outs = 2
hidden_1 = 20
hidden_2 = 20

x = tf.placeholder(tf.float32, [None, ins])
y = tf.placeholder(tf.float32, [None, outs])
drop_rate = tf.placeholder(tf.float32)

W = {
    'h1': tf.Variable(tf.truncated_normal([ins, hidden_1])),
    'h2': tf.Variable(tf.truncated_normal([hidden_1, hidden_2])),
    'out': tf.Variable(tf.truncated_normal([hidden_2, outs]))
}

b = {
    'h1': tf.Variable(tf.truncated_normal([hidden_1])),
    'h2': tf.Variable(tf.truncated_normal([hidden_2])),
    'out': tf.Variable(tf.truncated_normal([outs]))
}


# In[42]:


#Design network
def perceptron(x, W, b, dropout):
    layer_1 = tf.add(tf.matmul(x, W['h1']), b['h1'])
    layer_1 = tf.nn.sigmoid(layer_1)
    
    layer_2 = tf.add(tf.matmul(layer_1, W['h2']), b['h2'])
    layer_2 = tf.nn.sigmoid(layer_2)
    
    out_layer = tf.add(tf.matmul(layer_2, W['out']), b['out'])
    return out_layer


# In[43]:


#Evaluation methods
pred = perceptron(x, W, b, drop_rate)
cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=y))
optimizer = tf.train.AdamOptimizer(learn_rate).minimize(cost)

correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))
accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))

#Initialize network
init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init)

#Train network
collection_points = int(math.floor(epochs/print_step))
acc_history = np.empty([collection_points])
counter = 0
for i in range(0, epochs):
    batch = train_batch.get_random(50)
    sess.run(optimizer, feed_dict={
        x: batch[0],
        y: batch[1],
        drop_rate: dropout
    })
    if(i % print_step == 0):
        counter = counter + 1
        thing, acc = sess.run([W, accuracy], feed_dict={
            x: batch[0],
            y: batch[1],
            drop_rate: dropout
        })
        print(acc)
        acc_history[counter - 1] = acc",17,2
19,2018-3-9,2018,3,9,11,833706,A YouTube video or something to help conceptualize the wiring?,https://www.reddit.com/r/tensorflow/comments/833706/a_youtube_video_or_something_to_help/,dbabbitt,1520561534,"Hi Guys,

I've taken a few TensorFlow tutorials and tried to change the input data to something with different dimensions. Specifically, the MNIST handwritten digits demos (28x28 1D gray-scale pixels) to my own images (10x10 3D color pixels). It's the magic numbers inside the python functions that are giving me the TensorFlow errors. And when I change them to contain the multiples they need, I get a totally different TensorFlow error. I think I need to watch a YouTube video or something on how to conceptualize the wiring.

Do you have any suggestions? (Or maybe you can simply explain it.)

Thanks",5,3
20,2018-3-9,2018,3,9,13,833vat,Trying to translate basic example [Python],https://www.reddit.com/r/tensorflow/comments/833vat/trying_to_translate_basic_example_python/,elbiot,1520568192,"Not new to machine learning but new to Neural nets.  I am trying to start at the most basic Recurrent Neural Network and work up.  I found this [example](https://stackoverflow.com/questions/38294046/simple-recurrent-neural-network-input-shape) which needed some translating.  But now the results I get are very different.  What am I missing?

    import random
    import numpy as np
    from tensorflow.python.keras.layers import SimpleRNN, TimeDistributed, Dense
    from tensorflow.python.keras.models import Sequential

    np.random.seed(1337)

    sample_size = 256
    x_seed = [1, 0, 0, 0, 0, 0]
    y_seed = [1, 0.8, 0.6, 0, 0, 0]

    x_train = np.array([[x_seed] * sample_size]).reshape(sample_size,len(x_seed),1)
    y_train = np.array([[y_seed]*sample_size]).reshape(sample_size,len(y_seed),1)

    model=Sequential()
    model.add(SimpleRNN(50, input_shape=(len(x_seed),1), return_sequences = True))
    model.add(TimeDistributed(Dense(1, activation  =  ""sigmoid"")))
    model.compile(loss = ""mse"", optimizer = ""rmsprop"")
    model.fit(x_train, y_train, nb_epoch = 10, batch_size = 32)

    print(model.predict(np.array([[[1],[0],[0],[0],[0],[0]]])))

results in

    Epoch 1/1
    2018-03-08 21:35:36.116250: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
    256/256 [==============================]256/256 [==============================] - 1s 2ms/step - loss: 0.0974

    [[[0.66997623]
      [0.6478545 ]
      [0.5093554 ]
      [0.21203448]
      [0.21736448]
      [0.16737841]]]",0,1
21,2018-3-9,2018,3,9,20,835zp0,"Help: Inception TensorFlow looking for Session Bundle or SavedModel,but I only have inception checkpoint",https://www.reddit.com/r/tensorflow/comments/835zp0/help_inception_tensorflow_looking_for_session/,C0inMaster,1520594578,"Hello all,
Please help a tensorflow newbie.. I have installed docker image from bitnami,which includes inception. 
https://github.com/bitnami/bitnami-docker-tensorflow-inception

I can start  serving and inception containers, but I get the error below. In the instructions, I had to download the checkpoint file, which I did and I placed files in a proper directory. But I found multiple articles, that TensorFlow now requires new format ""SavedModel"", but I can't find any place to download the inception checkpoints in a new format and Tensorflow serving container, is refusing to use the old format. 

Please help me with either of the following:

1. Where can I download pre-trained checkpoints data in new format?
http://download.tensorflow.org/models/image/imagenet/inception-v3-2016-03-01.tar.gz  

2. How can I convert old format checkpoint to new SavedModel or Session Bundle ?

3. How can I configure TensorFlow to accept the older format? Maybe there is a parameter?

*My directory structure:* 

    /tmp/model-data/1/model.ckpt-157585
    /tmp/model-data/1/checkpoint

*From docker-compose.yml*
 
    volumes:
       - 'tensorflow_serving_data:/bitnami'
       - '/tmp/model-data:/bitnami/model-data'
               

*This is the error from the log when it starts: *

    ensorflow-serving_1    | 2018-03-09 10:52:47.596318: I tensorflow_serving/core/basic_manager.cc:705]   Successfully reserved resources to load servable {name: inception version: 1}
    tensorflow-serving_1    | 2018-03-09 10:52:47.596350: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: inception version: 1}
    tensorflow-serving_1    | 2018-03-09 10:52:47.596360: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: inception version: 1}
    tensorflow-serving_1    | 2018-03-09 10:52:47.596795: E tensorflow_serving/util/retrier.cc:38] Loading servable: {name: inception version: 1} failed: Not found: Session bundle or SavedModel bundle not found at specified export location

Thank you all in advance. ",3,3
22,2018-3-11,2018,3,11,22,83mqts,IMporting problem?,https://www.reddit.com/r/tensorflow/comments/83mqts/importing_problem/,jonathanshoe,1520775543,"Im trying to import? tensorflow 1.5 in my windows 10 using coda 9.0, cuDNN 7.0.5. It gives me the error when typing ""activate tf15"" into command prompt.  "" 'activate' is not recognized as an internal or external command,
operable program or batch file.""",1,0
23,2018-3-12,2018,3,12,10,83rciw,Tensorflow dimensions are not compatible?,https://www.reddit.com/r/tensorflow/comments/83rciw/tensorflow_dimensions_are_not_compatible/,carlitros1207,1520818242,"hey guys im doing a homework for my artificial intelligence class and im having an error that I cant seem to fix the error is ""ValueError: Dimensions 504 and 19 are not compatible"" anyone have any ideas of how I can fix this?

    import pandas as pd
    import tensorflow as tf
    df = pd.read_csv('vegas2.csv', header=0)
    def train_input_fn(features, labels, batch_size):
        """"""An input function for training""""""
        # Convert the inputs to a Dataset.
        dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))

        # Shuffle, repeat, and batch the examples.
        dataset = dataset.shuffle(1000).repeat().batch(batch_size)

        # Return the dataset.
        return dataset


    def load_data(y_name='Hotel name'):
        train = df
        train_x ,train_y = train ,train.pop(y_name)
    
        #train_x = df.to_dict(train_x)
        #train_x = df.as_matrix(train_x)
        return (train_x, train_y)

    def yesNo(x):
        if x==""YES"":
            return 1
        else:
            return 0
 
    def toOrd(str):
        x=0
        for l in str:
          x += ord(l)
        return int(x)

    CSV_COLUMN_NAMES = ['User country', 'Nr. reviews','Nr. hotel reviews','Helpful votes',
           'Score','Period of stay','Traveler type','Pool','Gym','Tennis court',
           'Spa','Casino','Free internet','Hotel stars','Nr. rooms',
            'User continent','Member years','Review month','Review weekday']

    df['Casino']=df['Casino'].apply(lambda x : yesNo(x))
    df['Gym']=df['Gym'].apply(lambda x : yesNo(x))
    df['Pool']=df['Pool'].apply(lambda x : yesNo(x))
    df['Tennis court']=df['Tennis court'].apply(lambda x : yesNo(x))
    df['Free internet']=df['Free internet'].apply(lambda x : yesNo(x))
    df['Spa']=df['Spa'].apply(lambda x : yesNo(x))


    column2 = ['Period of stay', 'Hotel name', 'User country', 'Traveler type', 
             'User continent', 'Review month', 'Review weekday']

    for y in column2:
        df[y]=df[y].apply(lambda x: toOrd(x))

    # Fetch the data
    (train_x, train_y) = load_data()

    # Feature columns describe how to use the input.
    my_feature_columns = []
    for key in train_x.keys():
        my_feature_columns.append(tf.feature_column.numeric_column(key=key))

    # Build 2 hidden layer DNN with 10, 10 units respectively.
    classifier = tf.estimator.DNNClassifier(
        feature_columns=my_feature_columns,
        # Two hidden layers of 10 nodes each.
        hidden_units=[10, 10],
        # The model must choose between 3 classes.
        n_classes=3)

    # Train the Model.
    classifier.train(input_fn=lambda:train_input_fn(train_x, CSV_COLUMN_NAMES ,10),steps=10)",1,1
24,2018-3-12,2018,3,12,14,83slw4,Any luck compiling TF1.6 with CUDA on a mac?,https://www.reddit.com/r/tensorflow/comments/83slw4/any_luck_compiling_tf16_with_cuda_on_a_mac/,Im_int,1520831991,,0,0
25,2018-3-13,2018,3,13,2,83wjxe,Data Quantity vs Data Quality,https://www.reddit.com/r/tensorflow/comments/83wjxe/data_quantity_vs_data_quality/,OriginalDoctorBean,1520874278,"Hi,
is there a general rule of thumb whether quality or quantity of data is preferred when training a new model?
I now both is important but sometimes you have to decide.
Or does it depend on e.g. which optimizer you use?
Thanks for any help 
",4,2
26,2018-3-14,2018,3,14,2,84666i,Humble Book Bundle: A.I. by Packt includes several books about TensorFlow,https://www.reddit.com/r/tensorflow/comments/84666i/humble_book_bundle_ai_by_packt_includes_several/,sipolsa,1520963537,,5,0
27,2018-3-14,2018,3,14,8,848nt5,Question tensorflow tutorial,https://www.reddit.com/r/tensorflow/comments/848nt5/question_tensorflow_tutorial/,anti-Casta,1520982783,"Hi guys, 

I am starting the tensorflow tutorial because I am learning how to use it. I am trying to understand the first example explained in the tutorial concerning CNNs: 

https://www.tensorflow.org/tutorials/layers

There is 1 thing I don't understand. After pooling layer 1 the output has shape [batch_size, 14, 14, 32]. The 32 are the 32 channels as a consequence of the 32 filters. This output is then fed as input to convolutional layer 2, which contains 64 filters. According to the tutorial the output of this convolutional layer has a shape [batch_size, 14, 14, 64]. 

Now, the thing I don't understand is what happened to the 32 channels of the input ? The input could have had 32 channels, 100 channels or 1000 channels but the output of the convolutional layer would always have a shape [batch_size, 14, 14, 64]. So what I am thinking is that maybe the 32 is hidden in the batch_size. I mean that batch_size at the output of the CNN is equal to the batch_size at the input multiplied with 32. Is this correct or am I wrong ? I don't see any other explanation for what happened to these 32 channels after the first pooling layer. ",3,0
28,2018-3-14,2018,3,14,22,84dhaj,Humble Book Bundle: Artificial Intelligence,https://www.reddit.com/r/tensorflow/comments/84dhaj/humble_book_bundle_artificial_intelligence/,808hunna,1521035127,"[Humble Book Bundle: Artificial Intelligence by Packt \(Parnter\)
](https://www.humblebundle.com/books/artificial-intelligence-books?partner=indiekings&amp;charity=2030222)

$1 for:

* Practical Game AI Programming
* Statistics for Machine Learning
* Machine Learning for Developers
* Machine Learning with C++
* Implementing AI to Play Games
* Three Months of Mapt Pro for $30 Coupon

Beat the average for:

* Deep Learning for Computer Vision
* Unreal Engine 4 AI Programming Essentials
* Keras Deep Learning Projects
* Neural Network Programming with Java
* Machine Learning Algorithms
* Machine Learning for OpenCV
* Tensorflow Deep Learning Solutions for Images
* Machine Learning With Go

$15 for:

* Python Artificial Intelligence Projects for Beginners
* Building Machine Learning Systems with Python
* Mastering Java Machine Learning
* Artificial Intelligence with Python
* Artificial Intelligence with Python - Deep Neural Networks
* Deep Learning with Python
* Deep Learning with Keras
* Deep Learning with TensorFlow
* Machine Learning with TensorFlow 1.x
* Machine Learning with R
* Mastering Machine Learning with Spark 2.x
* Deep Learning with R

Supports charity: Code for America",2,14
29,2018-3-14,2018,3,14,22,84di76,Creating different architectures programmatically in tensorflow,https://www.reddit.com/r/tensorflow/comments/84di76/creating_different_architectures_programmatically/,ArchFrosty,1521035350,"I am quite new to tensorflow and machine learning in general. I am currently working on a project, in which I want to generate different neural network architectures, train them and test them. 

An example of the architecture : https://imgur.com/a/X657c

Now the problem I am running into is that I don't know how to translate these architectures (sets of layers, parameters and connections generated by some other code) into actual working models in tensorflow. 

I tried looking for some tutorials but I came up with nothing. I am basically trying to come up with something like deepNEAT in tensorflow.

Can you please point me in the right direction ? Maybe some documentation I missed, or some existing similar solution ?
Any help is appreciated. 
",1,2
30,2018-3-15,2018,3,15,17,84ku4v,"Object detection training errors with Reduction axis 1 is empty in shape [9,0]",https://www.reddit.com/r/tensorflow/comments/84ku4v/object_detection_training_errors_with_reduction/,CroScorpiuS,1521101342,"Hi, I'm new to TensorFlow and I've been playing around Object Detection API, but teaching it my on stuff has proven difficult. 

I have asked this on Stack Overflow already, but with no luck, so please refer to my [post over there for details](https://stackoverflow.com/questions/49272943/reduction-axis-1-is-empty-in-shape-9-0) 

Any help would be appreciated, thank you",0,1
31,2018-3-15,2018,3,15,22,84mk4h,inception model retraining in bitnami docker container problem: ImportError: No module named tensorflow,https://www.reddit.com/r/tensorflow/comments/84mk4h/inception_model_retraining_in_bitnami_docker/,C0inMaster,1521121625,"Hi all,

I have an issue with running retraining script which has something to do with Python configuration inside the bitnami container. 
https://github.com/bitnami/bitnami-docker-tensorflow-inception/issues/4

    The error I get is:
    File ""/opt/bitnami/tensorflow-  inception/tensorflow/tensorflow/examples/image_retraining/retrain.py"", line 108, in &lt;module&gt;
    import tensorflow as tf
    ImportError: No module named tensorflow

The command I ran was this: 
     
    docker exec 7eb6fa611758 python /opt/bitnami/tensorflow-inception/tensorflow/tensorflow/examples/image_retraining/retrain.py --image_dir /tmp/images  --server=192.168.11.143:9000

The container is setup correctly, since I can run the test command successfully on with inception-client script and get back results. 

    SonicMac:tmp $ docker exec 7eb6fa611758 inception_client --server=192.168.11.143:9000 --image=./tmp/dexter.jpg
    D0315 13:17:20.952353956     336 ev_posix.c:101]                 Using polling engine: poll
    I0315 13:17:21.583798556     348   socket_utils_common_posix.c:205] Disabling AF_INET6 sockets because ::1 is not available.
    E0315 13:17:21.754727656     336 chttp2_transport.c:1810]     close_transport:   {""created"":""@1521119841.754708756"",""description"":""FD shutdown"",""file"":""src/core/lib/iomgr/ev_poll_posix.c"",""file_line"":427}
    outputs {
    key: ""classes""
    value {
      dtype: DT_STRING
      tensor_shape {
        dim {
          size: 1
        }
      dim {
        size: 5
      }
    }
    string_val: ""medicine chest, medicine cabinet""
    string_val: ""china cabinet, china closet""
    string_val: ""wardrobe, closet, press""
    string_val: ""shoe shop, shoe-shop, shoe store""
    string_val: ""dining table, board""
    }


But as soon as I try to retrain the model with a provided script I get error.

    docker exec 7eb6fa611758 python /opt/bitnami/tensorflow-inception/tensorflow/tensorflow/examples/image_retraining/retrain.py --image_dir /tmp/images  --server=192.168.11.143:9000

    File ""/opt/bitnami/tensorflow-  inception/tensorflow/tensorflow/examples/image_retraining/retrain.py"", line 108, in &lt;module&gt;
    import tensorflow as tf
    ImportError: No module named tensorflow

If I run the same script from inside container, I get same error. So this is not an issue of running the command from the host. 

I tried setting PYTHONPATH to different values, but not sure what directories to include..  Any advise on what could be causing this misconfiguration is appreciated.

The fact that inception-client command works is puzzling. As it imply that tensorflow must be setup properly.. 

Thank you all in advance for any ideas or help.
",2,2
32,2018-3-16,2018,3,16,0,84nc8k,C Bindings and TensorFlowSharp Questions,https://www.reddit.com/r/tensorflow/comments/84nc8k/c_bindings_and_tensorflowsharp_questions/,byte-muncher,1521127978,"Hello everyone,

First time posting here, but the time has come to leverage all the forums I can (been through a lot these few weeks... ._.) to see if I can get pushed in the right direction. 

I am a ML Research Intern for my uni. My professor currently would like to integrate TensorFlow into his (rather large) .NET project. I know of TensorFlow's [C Bindings](https://www.tensorflow.org/extend/language_bindings), but it seems rather limited in what it can do (no gradients, no nn library, etc.). I then looked at [TensorFlowSharp](https://github.com/migueldeicaza/TensorFlowSharp), which really is just an API built on the C Bindings of TensorFlow, which, as stated is not necessarily complete. 

I've been running around trying to find a way to come as close as I can to using TensorFlow as I've used it with Python, but interfacing with this project has been a nightmare. 

**The question**: Does anyone have an ideas on how TensorFlow best integrates with C#? 

**Follow up**: Would it be easier to write everything in Python TensorFlow, then execute it somehow from within the C# project? 

Thanks everyone in advance. ",6,0
33,2018-3-16,2018,3,16,7,84qou0,Worth getting a MX150?,https://www.reddit.com/r/tensorflow/comments/84qou0/worth_getting_a_mx150/,p0mmesbude,1521153562,"I need a new laptop and was thinking to get one with a dedicated GPU. MX150 or a predecessor. I do not have too much experience with TF and was thinking I could use it to play around / learn / prototype on it. Is it worth the cost or is the performance gain compared to CPU usage minimal? Can actually something be done on such a card or is 2gb of ram just not enough?

Thanks.",3,1
34,2018-3-16,2018,3,16,21,84uzdn,Issue with Object Detection,https://www.reddit.com/r/tensorflow/comments/84uzdn/issue_with_object_detection/,noah_f,1521202709,"Getting the Following Error when trying to run train.py

david@DeeLearning-LinuxMint ~/models1/research/object_detection $ python3 train.py --train_dir=./Images/train --pipeline_config_path=ssd_mobilenet_v1_pets.config
/home/david/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
Traceback (most recent call last):
  File ""train.py"", line 163, in &lt;module&gt;
    tf.app.run()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""train.py"", line 159, in main
    worker_job_name, is_chief, FLAGS.train_dir)
  File ""/home/david/models1/research/object_detection/trainer.py"", line 228, in train
    clones = model_deploy.create_clones(deploy_config, model_fn, [input_queue])
  File ""/home/david/models1/research/slim/deployment/model_deploy.py"", line 193, in create_clones
    outputs = model_fn(*args, **kwargs)
  File ""/home/david/models1/research/object_detection/trainer.py"", line 167, in _create_losses
    losses_dict = detection_model.loss(prediction_dict)
  File ""/home/david/models1/research/object_detection/meta_architectures/ssd_meta_arch.py"", line 474, in loss
    location_losses, cls_losses, prediction_dict, match_list)
  File ""/home/david/models1/research/object_detection/meta_architectures/ssd_meta_arch.py"", line 640, in _apply_hard_mining
    match_list=match_list)
  File ""/home/david/models1/research/object_detection/core/losses.py"", line 515, in __call__
    location_losses = tf.unstack(location_losses)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py"", line 957, in unstack
    (axis, -value_shape.ndims, value_shape.ndims))
ValueError: axis = 0 not in [0, 0)


",3,0
35,2018-3-17,2018,3,17,4,84y5nx,Protein Loops in Tensorflow,https://www.reddit.com/r/tensorflow/comments/84y5nx/protein_loops_in_tensorflow/,onidaito,1521228948,,0,6
36,2018-3-17,2018,3,17,14,851rmp,How would you recommend handling a clinical classifier where some subjects have missing data?,https://www.reddit.com/r/tensorflow/comments/851rmp/how_would_you_recommend_handling_a_clinical/,Xyoloswag420blazeitX,1521263981,"Hi all,

I'm looking to add clinical characteristics like age or certain genotypes into a CNN I currently use for treatment prediction.

Despite this, for the characteristics I want to include, at least one of them is missing in every single subject.

Is there a way to still comfortably fit these data into my model?

Specifically, I guess I would wonder if there's an implementation of tf.layers.dense that will completely ignore NaN inputs, but I have trouble believing such a thing exists.",0,1
37,2018-3-17,2018,3,17,15,8525cw,Is reusing bottlenecks for training different networks,https://www.reddit.com/r/tensorflow/comments/8525cw/is_reusing_bottlenecks_for_training_different/,jirehcwe,1521269366,"Hi there, i'm a TF beginner user. I've been following the tensorflow image retraining tutorial [here](https://www.tensorflow.org/tutorials/image_retraining).
I have trained a network of a bunch of training data (let's call this X) and created bottlenecks for the images in X.
and now I want to train **another** network on another training set that *also includes X* in the training set, can I reuse the bottleneck files?

From what i've read, bottlenecks are a preprocessing step, so technically I can? Hope someone can clarify this for me! Thanks!
",3,1
38,2018-3-17,2018,3,17,21,853fyj,Dont force classification into image categories,https://www.reddit.com/r/tensorflow/comments/853fyj/dont_force_classification_into_image_categories/,runs_with_badger,1521289873,"Im 1 day into my Tensorflow learning so just looking to have a high level, behavioural questions answered. 

Im following the [Tensorflow for Poets](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0) tutorial from Google Codelabs, but modifying it to not detect flowers, but other image categories. 

I was hoping to have it detect images relevant to my categories accurately, but also to detect when an image doesnt meet any of the trained categories. Instead, it always tries to categorise an image. 

So, is this expected behaviour from how I am implementing Tensorflow? If so, are there any suggestions to implement an other category that everything else falls into? 

Thanks for any help.",2,2
39,2018-3-17,2018,3,17,21,853iox,"Serving a re-trained model gives error: ""Serving signature key ""predict_images"" not found",https://www.reddit.com/r/tensorflow/comments/853iox/serving_a_retrained_model_gives_error_serving/,C0inMaster,1521290864,"Hi all,
I am slowly but steadily making progress with my project, while hitting every underwater rock possible. So far I was able to resolve all my issues myself, but this one really hits me and I have no ideas on where to start debugging it. 

So, I collected images for my household and retrained the inception-v3 model using provided retrain.py script.

Here is the command I ran:
 
    python ./examples/image_retraining/retrain.py --image_dir /Users/me/ML/TensorFlow/model-data/home-photos  architecture  inception_v3 final_tensor_name home print_misclassified_test_images true saved_model_dir /Users/me/ML/TensorFlow/model-data/saved-house-model  --validation_percentage 5

This command ran fine and produced a whole bunch of output including checkpoints and also ""SavedModel"" 
This were last lines of output at the end: 

    NFO:tensorflow:2018-03-17 19:40:04.126443: Step 3980: Validation accuracy = 28.0% (N=100)
    INFO:tensorflow:2018-03-17 19:40:04.595605: Step 3990: Train accuracy = 96.0%
    INFO:tensorflow:2018-03-17 19:40:04.595737: Step 3990: Cross entropy = 0.198535
    INFO:tensorflow:2018-03-17 19:40:04.643853: Step 3990: Validation accuracy = 30.0% (N=100)
    INFO:tensorflow:2018-03-17 19:40:05.060774: Step 3999: Train accuracy = 92.0%
    INFO:tensorflow:2018-03-17 19:40:05.060891: Step 3999: Cross entropy = 0.227055
    INFO:tensorflow:2018-03-17 19:40:05.110407: Step 3999: Validation accuracy = 35.0% (N=100)
    Model path:  /tmp/imagenet/classify_image_graph_def.pb
    INFO:tensorflow:Restoring parameters from /tmp/_retrain_checkpoint
    INFO:tensorflow:Final test accuracy = 67.6% (N=68)
    Model path:  /tmp/imagenet/classify_image_graph_def.pb
    INFO:tensorflow:Restoring parameters from /tmp/_retrain_checkpoint
    INFO:tensorflow:Froze 2 variables.
    Converted 2 variables to const ops.
    Model path:  /tmp/imagenet/classify_image_graph_def.pb
    INFO:tensorflow:Restoring parameters from /tmp/_retrain_checkpoint
    INFO:tensorflow:No assets to save.
    INFO:tensorflow:No assets to write.
    INFO:tensorflow:SavedModel written to: /tmp/saved_models/1/saved_model.pb

Does the above look right to you guys?  I do realize that it did not train well with validation accuracy of 35%, but I am just trying to make the workflow of retraining and serving a new model work at this time and focus on making the model itself better later.


I am using bitnami docker distribution and I was able to successfully load the ""Saved"" model into the Serving server. 

Here is the log of loading the model:

    tensorflow-inception_1  | INFO  ==&gt; Starting tensorflow-inception...
    tensorflow-serving_1    | 2018-03-17 12:23:53.486020: I   tensorflow_serving/model_servers/server_core.cc:439] Adding/updating models.
    tensorflow-serving_1    | 2018-03-17 12:23:53.486132: I tensorflow_serving/model_servers/server_core.cc:490]    (Re-)adding model: inception
    tensorflow-serving_1    | 2018-03-17 12:23:53.593314: I tensorflow_serving/core/basic_manager.cc:705]   Successfully reserved resources to load servable {name: inception version: 1}
    tensorflow-serving_1    | 2018-03-17 12:23:53.593344: I tensorflow_serving/core/loader_harness.cc:66]  Approving load for servable version {name: inception version: 1}
    tensorflow-serving_1    | 2018-03-17 12:23:53.593354: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: inception version: 1}
    tensorflow-serving_1    | 2018-03-17 12:23:53.593476: I external/org_tensorflow/tensorflow/contrib/session_bundle/bundle_shim.cc:360] Attempting to load native SavedModelBundle in bundle-shim from: /bitnami/model-data/1
    tensorflow-serving_1    | 2018-03-17 12:23:53.593598: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:236] Loading SavedModel from: /bitnami/model-data/1
    tensorflow-serving_1    | 2018-03-17 12:23:53.830639: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
    tensorflow-serving_1    | 2018-03-17 12:23:53.852548: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:155] Restoring SavedModel bundle.
    tensorflow-serving_1    | 2018-03-17 12:23:53.864172: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:190] Running LegacyInitOp on SavedModel bundle.
    tensorflow-serving_1    | 2018-03-17 12:23:53.874562: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:284] Loading SavedModel: success. Took 281052 microseconds.
    tensorflow-serving_1    | 2018-03-17 12:23:53.881662: I tensorflow_serving/core/loader_harness.cc:86] Successfully loaded servable version {name: inception version: 1}
    tensorflow-serving_1    | 2018-03-17 12:23:53.883001: I tensorflow_serving/model_servers/main.cc:290] Running ModelServer at 0.0.0.0:9000 ...

But when I try to do prediction with ""inception-client"" i get the error: 

    grpc.framework.interfaces.face.face.AbortionError:  AbortionError(code=StatusCode.FAILED_PRECONDITION, details=""Serving signature key ""predict_images"" not found."")
    E0317 12:24:30.913437817      22 chttp2_transport.c:1810]    close_transport: {""created"":""@1521289470.913411202"",""description"":""FD shutdown"",""file"":""src/core/lib/iomgr/ev_poll_posix.c"",""file_line"":427}

This the line I use to run the prediction on the image. 

    SonicMac:~me $ docker exec df9db1a017b4 inception_client --server=192.168.11.143:9000 --image=/bitnami/model-data/test-data/dexter-1.jpg


I found the definition of the signatures here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/signature_constants.py

but I don't know how to use this info. I think my ""Tensorflow Serving"" is looking for a wrong signature. Maybe I should have specified it when training?  Have no clue how though.. 


Does anybody have any idea what's going on? 
What is the ""predict_images"" signature key anyway? 

I googled this issue and found ONLY one instance on the whole internet people discussing something similar.  In that thread, it seem that the problem was a wrong version of ""serving"" server. 

I will try to build my own serving server and see if this helps, instead of using bitnami docker container. 
In the meantime, any ideas are welcome.

Thank you in advance. 



The full stack trace here:

Traceback (most recent call last):

      File ""/opt/bitnami/tensorflow-inception/bazel-bin/tensorflow_serving/example/inception_client.runfiles/tf_serving/tensorflow_serving/example/inception_client.py"", line 56, in &lt;module&gt;
        tf.app.run()
      File ""/opt/bitnami/tensorflow-inception/bazel- bin/tensorflow_serving/example/inception_client.runfiles/org_tensorflow/tensorflow/python/platform/app.py"", line 48, in run
        _sys.exit(main(_sys.argv[:1] + flags_passthrough))
      File ""/opt/bitnami/tensorflow-inception/bazel- bin/tensorflow_serving/example/inception_client.runfiles/tf_serving/tensorflow_serving/example/inception_client.py"", line 51, in main
        result = stub.Predict(request, 10.0)  # 10 secs timeout
      File ""/opt/bitnami/python/lib/python2.7/site-packages/grpc/beta/_client_adaptations.py"", line 300, in __call__
        self._request_serializer, self._response_deserializer)
      File ""/opt/bitnami/python/lib/python2.7/site-packages/grpc/beta/_client_adaptations.py"", line 198, in _blocking_unary_unary
        raise _abortion_error(rpc_error_call)
    grpc.framework.interfaces.face.face.AbortionError: AbortionError(code=StatusCode.FAILED_PRECONDITION,  details=""Serving signature key ""predict_images"" not found."")
    E0317 12:24:30.913437817      22 chttp2_transport.c:1810]    close_transport: {""created"":""@1521289470.913411202"",""description"":""FD shutdown"",""file"":""src/core/lib/iomgr/ev_poll_posix.c"",""file_line"":427}
",0,1
40,2018-3-19,2018,3,19,2,85cs3o,Using Tensorflow+Gym to and translate it to a physical object (robot?),https://www.reddit.com/r/tensorflow/comments/85cs3o/using_tensorflowgym_to_and_translate_it_to_a/,[deleted],1521395141,[deleted],0,0
41,2018-3-19,2018,3,19,3,85d06d,[HELP] How can I plot the results of an approximator?,https://www.reddit.com/r/tensorflow/comments/85d06d/help_how_can_i_plot_the_results_of_an_approximator/,SEND_ME_BROWNIES,1521397080,"Hey all, new to tensorflow and to reddit, so please forgive any rule-bending.

I have created a network to model a quadratic function in two dimensions, with both training and testing steps.  How can I generate the results of the network outside of training?  If logits is the network object, would it just be sess.run(logits, feed_dict)?

On a related note, is there a way to save the lowest-cost network I've had so far?

Thanks!",1,1
42,2018-3-20,2018,3,20,1,85kq8f,Contributing to the Java API,https://www.reddit.com/r/tensorflow/comments/85kq8f/contributing_to_the_java_api/,halfanothersdozen,1521476495,"Hello,

Our office is by and large a java shop. We have previously evaluated frameworks like deeplearning4j but are currently settling on Tensorflow for popularity/political reasons. That being said the Java API is sorely lacking in functionality. I haven't done much open source contributing before but it would both help my familiarity and use of the framework if I started helping build out the Java API.

Would one of you peeps be able to point me in the direction and lend some advice as to how and where would be best for me to start?

Thanks much.",2,4
43,2018-3-20,2018,3,20,17,85r2lu,[HELP] How to use tensorflow to create an bot that plays android games?,https://www.reddit.com/r/tensorflow/comments/85r2lu/help_how_to_use_tensorflow_to_create_an_bot_that/,logTom,1521533696,,2,0
44,2018-3-20,2018,3,20,17,85r68u,ValueError in TensorFlow for Python,https://www.reddit.com/r/tensorflow/comments/85r68u/valueerror_in_tensorflow_for_python/,_JayJohn,1521535126,"I have just started out in the world of ML so please excuse me if the answer is obvious. I'm getting a value error when trying to run the minimize function on a feed_dict.
link: https://pastebin.com/qssytbLM

(the error is appended to the code)",2,1
45,2018-3-20,2018,3,20,17,85r8na,Machine Learning Benchmark Set with IBM POWER9 and NVIDIA GPUs,https://www.reddit.com/r/tensorflow/comments/85r8na/machine_learning_benchmark_set_with_ibm_power9/,ibmzrl,1521536047,,0,9
46,2018-3-21,2018,3,21,8,85xfuo,Custom Image Transformation,https://www.reddit.com/r/tensorflow/comments/85xfuo/custom_image_transformation/,rigabigadiga,1521588089,"[SOLVED]

I am trying to perform a custom image transformation. I have the original image OLD, a matrix of the X values Xs and a matrix of Y values Ys such that:
    
    NEW[x][y] = OLD[Xs[x][y]][Ys[x][y]]

How can I take the OLD, Xs, and Ys tensors to create the NEW tensor? Additionally, how can I use different interpolation methods?

EDIT: I used tf.gather_nd()",0,2
47,2018-3-21,2018,3,21,12,85z12z,[HELP] Installing tensorflow onto mac,https://www.reddit.com/r/tensorflow/comments/85z12z/help_installing_tensorflow_onto_mac/,Noahwar97,1521602370,"Hi everyone, ive been trying to install tensorflow for a while now and ive been having a problem. Ive been useing the following code from tensorflow.org:

    $ pip install --upgrade virtualenv

but i recieve an error message as follows:

    Collecting virtualenv
    Using cached virtualenv-15.1.0-py2.py3-none-any.whl
    Installing collected packages: virtualenv 
    Exception:
    Traceback (most recent call last):
    File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/basecommand.py"", line 215, in main
         status = self.run(options, args)
    File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/commands/install.py"", line 342, in run
         prefix=options.prefix_path,
    File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_set.py"", line 784, in install
         **kwargs
    File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_install.py"", line 851, in install
         self.move_wheel_files(self.source_dir, root=root, prefix=prefix)
    File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_install.py"", line 1064, in move_wheel_files
         isolated=self.isolated,
    File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/wheel.py"", line 345, in move_wheel_files
         clobber(source, lib_dir, True)
    File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/wheel.py"", line 323, in clobber
         shutil.copyfile(srcfile, destfile)
    File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 83, in copyfile
         with open(dst, 'wb') as fdst:
    IOError: [Errno 13] Permission denied: '/Library/Python/2.7/site-packages/virtualenv.pyc'

Im not sure how to fix it and i havent had much help else where, Thank you in advance!",4,2
48,2018-3-21,2018,3,21,14,85zm6z,[HELP] Share variables across different sessions,https://www.reddit.com/r/tensorflow/comments/85zm6z/help_share_variables_across_different_sessions/,deathholes,1521608771,"I want to train a model and at the same time use the results of the model for further actions. The training can be done in the background, but I need the prediction model to be available all the time. I've got an idea to how to do this but not sure if that will work. So I'm thinking of creating separate threads/processes for prediction and training. There will be two different sessions running in each process and they will share the same variables. So, the training model can update the variables in it's own time and the prediction model can use the latest weights for better prediction. 

Is there any way to share variable across sessions or some other way to do this?",1,1
49,2018-3-21,2018,3,21,23,862jjb,"Building first TF model, checking if I'm understanding/interpreting the process correctly (Questions on rank/dimension/shape)",https://www.reddit.com/r/tensorflow/comments/862jjb/building_first_tf_model_checking_if_im/,tpcourier,1521642919,"Modeling a 6 vs 6 competitive game.

Each dimension (right term?) is a matrix, with values exclusively as either a 1 or 0 (for present or absent).

&gt; Dimension 1 - n rows, 96+ columns
&gt; D2 - n rows, 96+ columns

The teams. Only 2 teams are present in each row.

&gt; D3 - n rows, 2000+ columns
&gt; D4 - n rows, 2000+ columns

The players on each team (D3 on D1, D4 on D2). Only 6 are present in each row. Is this enough for synergies between players (Not just weighing A and B, but A WITH B) or does each player need their own matrix? If they need their own matrix, and that order of the players doesn't matter, how to account for this... symmetry?

&gt; D5 - n rows, 96+ columns

The attacking team. Only 1 team is present.

&gt; D6 - n rows, 96+ columns

The defending team.

&gt; D7 - n rows, 3 columns

Year. (2016, 2017, 2018)

&gt; D8 - n rows, 2 columns

Season type

&gt; D9 - n rows, x columns

An ""absolute date"", from column ""one"" to ""how many days long"". Similar to the player question, is this enough to ""see"" how many days are between games/matches? A way of tracking if a player is improving or getting worse?

&gt; D10 - n rows, 4 columns

Type of game.

There's also a result vector for each of the n rows, for scoring. Is it possible to make this a result matrix, for tracking multiple outcome types? (Or RV1 for one result, RV2 for another, RV3 for third, stacked on top of each other?)

Is this on the right track?",1,3
50,2018-3-22,2018,3,22,6,86626h,[QUESTION] Tensorflow classification and subclassifications of text,https://www.reddit.com/r/tensorflow/comments/86626h/question_tensorflow_classification_and/,DamagedFreight,1521667972,"Before I describe anything please know I have never used Tensorflow and I'm lost in getting started.  I'm mostly looking for some direction to get started.  

After some scripting to extract information I now have a list of dicts each containing of classification, subclassification and a list of text bodies.  The list of text bodies is a list of text/plain and/or text/html parts of an email reporting a security incident.  These were all (mostly) manually labeled with a Class and SubClass and they are my training data.  The documents list has 52176 dicts in it.

    documents = [
        {
            ""Class"": ""Infection Causing Spam"",
            ""SubClass"": ""Stealrat"",
            ""Content"": [
                {
                    ""ContentType"": ""text/plain"",
                    ""Headers"": ""Subject: Some subject\nX-Mailer: MIME-tools 5.506 (Entity 5.506)\nMIME-Version: 1.0\n\n"",
                    ""Content"": ""10.10.20.35 is sending spam\nThe spam seems related to a stealrat infection.\nInvestigate the spam source (compromised CMS website)\n- fix the issue and stop the spam source (clean and secure the website)\n- clean the server outbound mail queue, and other potential malicious files\n- remove your IP from the blacklists""
                }
            ]
        },
        {
            ""Class"": ""Fraud"",
            ""SubClass"": ""Phishing"",
            ""Content"": [
                {
                    ""ContentType: ""text/html"",
                    ""Headers"": ""Subject: sitexyz.com/bankofwhatever.php\n"",
                    ""Content"": ""&lt;p&gt;Hello&lt;/p&gt;&lt;p&gt;The site at sitexyz.com/bankofwhatever.php is a phishing site...&lt;/p&gt;""
                },
                {
                    ""ContentType: ""text/plain"",
                    ""Headers"": ""Subject: sitexyz.com/bankofwhatever.php\n"",
                    ""Content"": ""Hello\n\nThe site at sitexyz.com/bankofwhatever.php is a phishing site...\n""
                }
            ]
        }
    ]

These examples are very simple and it's usually not as obvious as these about what Class or SubClass the document should be labeled as.

Now I'm just starting to get into the Tensorflow part and I'm wondering what I must do to prepare this data to Tensorflow to learn how to predict the classification and subclassification of new reports.  I am pretty sure I'd want to use 'text/plain' over 'text/html' (or strip the HTML from the 'text/html' version if there is no plain one).

I'm thinking I need to get this data into a usable format so I can run some learning on it and then save that data to a file to add more learning later or to use the 'model?' for predictions on new reports.

Where should I go from here?  Is Tensorflow the right tool to be using at this point?",1,1
51,2018-3-22,2018,3,22,9,867a3c,[Help] Training accuracy in estimator.train_and_evaluate,https://www.reddit.com/r/tensorflow/comments/867a3c/help_training_accuracy_in_estimatortrain_and/,DDarog,1521677647,"Hi

I have a sequential keras model (modifed from the built-in vgg16), that I create an estimator from with tf.keras.estimator.model_to_estimator, then I use tf.estimator.train_and_evaluate. It outputs validation loss and accuracy, and training loss, but not training accuracy. How do I add a training accuracy metric to this setup?",0,2
52,2018-3-22,2018,3,22,19,86ailm,Tensorflow performance vs custom CUDA kernel?,https://www.reddit.com/r/tensorflow/comments/86ailm/tensorflow_performance_vs_custom_cuda_kernel/,Squirrl,1521714992,"**TL;DR:** How does the performance of Tensorflow compare to  the performance of a custom CUDA kernel on the same problem?

More specifically, I have a fairly non-linear and highly-constrained problem where I am interested in finding a feasible solution. The problem is such that a solution can always be found via gradient descent. The only external data required for the problem are the initial variable values, and the rest can be handled on the GPU without CPU involvement. The GPU is using Adam to optimize the variables based on a large number of single-sided quadratic penalties (representing constraints) and various regularizations.

During Tensorflow training, the GPU (Titan X) is running at 90-100% for a good 30 seconds before a solution is reached. I would like to speed this up, if at all possible (I need to solve _a lot_ of these problems).

Given the simplicity of the problem statement, writing a custom CUDA kernel is not out of the question, but I have no feeling for how this might improve performance having never directly compared Tensorflow vs a custom CUDA kernel on the same problem.

Could anyone provide any insights?",4,5
53,2018-3-23,2018,3,23,17,86j550,"Samples of serving various ML models in Google Cloud Machine Learning Engine using Tensorflow, Keras and Scikit-Learn, tutorials on how to use the estimator APIs to perform various ML tasks[WIP]",https://www.reddit.com/r/tensorflow/comments/86j550/samples_of_serving_various_ml_models_in_google/,coding2fun,1521794401,,0,14
54,2018-3-24,2018,3,24,5,86nt47,[N] IBM claims its machine learning library is 46x faster than TensorFlow.,https://www.reddit.com/r/tensorflow/comments/86nt47/n_ibm_claims_its_machine_learning_library_is_46x/,[deleted],1521836573,[deleted],0,1
55,2018-3-25,2018,3,25,8,86wxtn,Adding support for stateful RNN models within the TF Serving API?,https://www.reddit.com/r/tensorflow/comments/86wxtn/adding_support_for_stateful_rnn_models_within_the/,redditpirateroberts,1521934457,"I have an interesting, non-novel but seemingly generally unsolved, at least in sources I could find online, problem. The issue is basically this:

I want to persist the states of my RNN in between calls/invokations to it  via the TF Serving API. 

I have found quite a few people online talking about this problem, such as in the following links:

https://github.com/tensorflow/serving/issues/724

https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/00tipdqxRZk

https://stackoverflow.com/questions/43710693/tensorflow-serving-stateful-lstm?utm_medium=organic&amp;utm_source=google_rich_qa&amp;utm_campaign=google_rich_qa

Unfortunetly, there seems to be some discussion of the problem and discussion of a built in fix being added to TF but not being there yet, but no actual guides/examples for how to work around this problem.

The closest I have been able to find a guide for how to do this was the following in the groups.google link:

""As background for future readers, there are two broad cases to consider. The first is where you want to run an entire sequence computation, with multiple steps, each with state to preserve for the next step. This case is addressed with dynamic unrolling.""

I am not really sure how to go about implementing this at all though. I dont really want to share my code here just because it is really quite long for a Reddit post and don't expect anyone to read through it all and tell me what to do. 

Just any general tips would be awesome.

I have two files right now that I am using to deploy and use my RNN in the serving api. They are called rnn_save_model.py and rnn_client.py. rnn_save_model just creates the actual model in code and then uses SavedModelBuilder to save it to file. rnn_client then passes in some parameters to the model when I have it loaded via the following command:

    tensorflow_model_server --port=9000 --model_name=rnn --model_base_path=/tmp/rnn_model/

I am just not even sure where to add code to get the model to load a state stored to file or something as the model itself is ""created"" once in rnn_save_model and I do not see how to clearly pass in states via the rnn_client file that are then added to the graph as the file in its current state is just using a model loaded in memory and interfacing with it VS actually editing the model like would be needed to load previous state from file or something.

I really appreciate any help!",0,6
56,2018-3-27,2018,3,27,20,87hpah,[beginnner] need help in optimizing code for GPU,https://www.reddit.com/r/tensorflow/comments/87hpah/beginnner_need_help_in_optimizing_code_for_gpu/,cant-find-user-name,1522150760,"Hi!

This is the first time I am using tensorflow for a use that takes large amount of time. 

I am using a single layer nueral network with word vectors for named entity recognition task. I have written the following code for it: https://pastebin.com/LeszGRas

but the problem is, the code runs on the same speed in CPU and GPU. So, what am I doing wrong? I made sure the code was running on GPU, but the time it takes to execute an epoch is same in both CPU and GPU. 

Any help is greatly appreciated, thank you. ",13,2
57,2018-3-28,2018,3,28,16,87pws1,Beginner Question,https://www.reddit.com/r/tensorflow/comments/87pws1/beginner_question/,[deleted],1522220819,[deleted],0,1
58,2018-3-28,2018,3,28,19,87qqai,Managing version requirements?,https://www.reddit.com/r/tensorflow/comments/87qqai/managing_version_requirements/,citizenmtb,1522231793,"Hi all,

I'm currently working on a project to allow rental of GPU processing time for various tasks, one of which being machine learning purposes.

I'm discovering there seem to be many versioning requirements for Tensorflow, tflearn, Python, CUDA, cudnn and it's got me wondering how you guys usually manage the various versions?

Many of the demo scripts or even libraries require specific versions to work, so for a rental i'm assuming people are generally going to be unwilling to manage it themselves?

So, what are your experiences like with other rental services? AWS? Gcloud? Anything else?",2,2
59,2018-3-30,2018,3,30,2,882yhf,[HELP] How to Implement Phase Correlation?,https://www.reddit.com/r/tensorflow/comments/882yhf/help_how_to_implement_phase_correlation/,rigabigadiga,1522342902,"I am trying to implement this [method](https://en.wikipedia.org/wiki/Phase_correlation#Method). 

I have two main questions.
Should the corners be swapped so that high frequencies are in the middle? And how can I normalize as shown above?",0,2
60,2018-3-30,2018,3,30,11,8871ta,How can I load weights when using the tf.layers api?,https://www.reddit.com/r/tensorflow/comments/8871ta/how_can_i_load_weights_when_using_the_tflayers_api/,Xyoloswag420blazeitX,1522376331,,0,1
61,2018-3-30,2018,3,30,11,8874yu,How does I access variables that defined in name_scope?,https://www.reddit.com/r/tensorflow/comments/8874yu/how_does_i_access_variables_that_defined_in_name/,Laurence-Lin,1522377176,"I've found a sample code online, it is written like this:

def lstm():

  LSTM = BasicLSTMCell()  
  return LSTM
  with tf.name_scope('my_name_scope'):

       cell = multiRNNCell(lstm for _ in range(3))

I'm not sure if I called lstm(), I would get an single layer 'LSTM' or the multilayer 'cell'.

I don't know how does variable in name_scope work exactly, while under self defined name scope 'my_name_scope', how do I access variable 'cell'?

Thanks for helping
",2,2
62,2018-3-30,2018,3,30,21,88a4kr,"Free Tensorflow course, Over 4 Hours of video, Only 100 free copies",https://www.reddit.com/r/tensorflow/comments/88a4kr/free_tensorflow_course_over_4_hours_of_video_only/,DavidMilline,1522414580,,0,11
63,2018-3-30,2018,3,30,23,88ay8v,Instructions for installation by source,https://www.reddit.com/r/tensorflow/comments/88ay8v/instructions_for_installation_by_source/,RealMatchesMalonee,1522421934,"I am trying to install TensorFlow on my nonGPU laptop and my processor supports AVX AVX2 and FMA instructions. I've already installed bazel. I am currently working in a Unix environment. What instructions should I follow to get TensorFlow for python, and can I uninstall bazel after I've generated the pip package?",2,1
0,2018-4-1,2018,4,1,10,88ngpl,Distributed Tensorflow without sharing weights,https://www.reddit.com/r/tensorflow/comments/88ngpl/distributed_tensorflow_without_sharing_weights/,manganime1,1522547435,"Hello,

I'm working on an application where I want to run an algorithm in parallel, but I don't want to share the weights; is that possible?

I'm using 'train.replica_device_setter' currently, which is automatically placing my weights on the parameter server. Is there a way to tell it not to do that? Or will I have to stop using 'train.replica_device_setter' entirely, and define the device-ops connections myself?",3,3
1,2018-4-1,2018,4,1,11,88ntfs,[HELP] Getting Placeholder Values into python objects.,https://www.reddit.com/r/tensorflow/comments/88ntfs/help_getting_placeholder_values_into_python/,[deleted],1522551231,[deleted],0,1
2,2018-4-2,2018,4,2,0,88rhn3,tf.data: Easy-to-use input pipelines for TensorFlow - YouTube,https://www.reddit.com/r/tensorflow/comments/88rhn3/tfdata_easytouse_input_pipelines_for_tensorflow/,Olao99,1522595936,,0,16
3,2018-4-2,2018,4,2,1,88rynm,Training Performance: A users guide to converge faster (TensorFlow Dev Summit 2018) - YouTube,https://www.reddit.com/r/tensorflow/comments/88rynm/training_performance_a_users_guide_to_converge/,Olao99,1522599825,,0,6
4,2018-4-2,2018,4,2,2,88sizb,Typical tensorflow project directory structure,https://www.reddit.com/r/tensorflow/comments/88sizb/typical_tensorflow_project_directory_structure/,r0vsdal,1522604348,"I'm pretty new to Tensorflow and machine learning. Reading through tutorials I never seem to get how to structure a mid-sized project(image recognizition using CNN, training from my own set of images). Is there a standard way to do this? Any good literature covering this subject?",2,1
5,2018-4-2,2018,4,2,11,88w4ck,tensorboard bug?,https://www.reddit.com/r/tensorflow/comments/88w4ck/tensorboard_bug/,manganime1,1522636137,"https://imgur.com/a/HX3mt

Maybe I'm misinterpreting tensorboard, but for devices, the color-scheme in the legend (left of the pic) doesn't match with the color under ""Attributes"" when you press on the node.

For example, in the pic, I highlighted node ""a_2"" where under Attributes it's assigned to device ""/job:ps/task:0"" and is blue, but according to the color-scheme in the far left it's supposed to be a peachy color...",0,1
6,2018-4-3,2018,4,3,4,894de1,Feed-forward Network Giving a Max Output,https://www.reddit.com/r/tensorflow/comments/894de1/feedforward_network_giving_a_max_output/,ThexLizardxKing,1522699047,"Hey guys, 

I have a network that is predicting some time data.  The inputs are time and a constant, C, and the output is the y-value at the given time. The idea is that I train it on multiple different C values, and then predict using a new C value. For most of my data, this works with no issue. However, I have one set of data that, once trained, any C value I input above the highest trained C value gives me a constant output.

For example, I decided to train it on a single time point to try to figure out the issue. At t=45, I trained it on C = [2.0, 3.5, 5.0], which should give an output of [4.47, 8.46, 21.1]. After training, I tested on C = 6, which should output 65.3. However, I still just get a value around 21.

I've tried many different numbers of hidden layers, nodes per layer, and different activation functions, but always get the same result. Anyone have any idea on why this is happening?",0,1
7,2018-4-3,2018,4,3,11,897npj,Is there any reason to remake scikit models in tensorflow? [Beginner],https://www.reddit.com/r/tensorflow/comments/897npj/is_there_any_reason_to_remake_scikit_models_in/,Akumasade,1522721178,"I'm really new to using tensorflow, but I've done some basic machine learning using scikit-learn.  I was wondering if there were any advantages to using the tensorflow version of the models in scikit-learn(e.g. K-nearest neighbors, decision trees, logistic regression)?

Could I expect better efficiency using tensorflow?",5,2
8,2018-4-3,2018,4,3,16,89ayr3,[Help] Trying to implement an idea for GANs from a talk,https://www.reddit.com/r/tensorflow/comments/89ayr3/help_trying_to_implement_an_idea_for_gans_from_a/,Mikkelisk,1522739074,"Hey, I'm trying to learn tensorflow by implementing an idea from a talk I saw. I posted the question on (stackoverflow)[https://stackoverflow.com/questions/49600903/implementing-a-gan-with-lookahead-in-the-generator-in-tensorflow], but I got downvoted with no comments as to why.

I would appreciate it if anyone here could help me with the question as posed OR help me understand why the question is bad/unanswerable as it stands so that I can improve it.

Any help is greatly appreciated:)",4,1
9,2018-4-4,2018,4,4,7,89j8m2,Introducing TensorFlow.js: Machine Learning in Javascript,https://www.reddit.com/r/tensorflow/comments/89j8m2/introducing_tensorflowjs_machine_learning_in/,fhoffa,1522793243,,0,24
10,2018-4-4,2018,4,4,12,89lvxw,Tensorflow reshape in matrix multiply,https://www.reddit.com/r/tensorflow/comments/89lvxw/tensorflow_reshape_in_matrix_multiply/,staydreamy,1522812248,"I want to use tf.matmul(A, B) with two tensors one (A) of rank 3 with dimensions [10000, 48, 50] and the other (B) of rank 2 with dimensions [200, 2400]. I was told that I would be able to use tf.matmul if I reshape B and change the order the multiplication. I tried reshaping B to [48, 10000] but this did not work. Is there any way to do this?

edit: tensors not matrices",24,3
11,2018-4-4,2018,4,4,22,89pe7t,Style transfer using inception v1,https://www.reddit.com/r/tensorflow/comments/89pe7t/style_transfer_using_inception_v1/,nile6499,1522848143,"Hi, has anyone tried inception model for style transfer, and with Adam optimizer. I really need help, since I have 4 days left.

Thanks",2,1
12,2018-4-5,2018,4,5,2,89rrop,Is there a way to access weights and biases in tfjs layers api?,https://www.reddit.com/r/tensorflow/comments/89rrop/is_there_a_way_to_access_weights_and_biases_in/,[deleted],1522864205,[deleted],0,1
13,2018-4-6,2018,4,6,3,8a2bun,[Q] Can someone please help me with this issue. TF is telling me a variable already exists when I try to write a basic GAN.,https://www.reddit.com/r/tensorflow/comments/8a2bun/q_can_someone_please_help_me_with_this_issue_tf/,Xyoloswag420blazeitX,1522953754,,1,1
14,2018-4-6,2018,4,6,12,8a6ha2,Negative cross entropy loss then error,https://www.reddit.com/r/tensorflow/comments/8a6ha2/negative_cross_entropy_loss_then_error/,staydreamy,1522986845,"I am trying to calculate the loss using cross entropy with L2 regularization as in [A Fast and Accurate Dependency Parser using Neural Networks](http://www.aclweb.org/anthology/D14-1082). This is my code so far:

    self.loss = tf.reduce_mean(
                     tf.nn.softmax_cross_entropy_with_logits(logits=self.prediction, labels=self.train_labels)
                    )
    regularizer = tf.nn.l2_loss(weights_input)
    self.loss = tf.reduce_mean(self.loss + 1e-8 * regularizer)

However I get a negative loss at step 0 and an error at step 200:
    ValueError: Cannot feed value of shape (48,) for Tensor u'Placeholder_2:0', which has shape '(1, 48)'

Any suggestions or ideas as to what I'm doing wrong here?",8,1
15,2018-4-6,2018,4,6,13,8a6tig,Google has started a new TensorFlow YouTube channel,https://www.reddit.com/r/tensorflow/comments/8a6tig/google_has_started_a_new_tensorflow_youtube/,khashei,1522990320,,4,37
16,2018-4-7,2018,4,7,0,8aak8c,Ignore labels with -1 in softmax,https://www.reddit.com/r/tensorflow/comments/8aak8c/ignore_labels_with_1_in_softmax/,staydreamy,1523029502,"When cross entropy calculating loss, how do I ignore values of -1 in the label tensor that is passed to softmax?",3,1
17,2018-4-8,2018,4,8,11,8an42s,Ide for Tensorflow?,https://www.reddit.com/r/tensorflow/comments/8an42s/ide_for_tensorflow/,thefernandito,1523154559,"Hello friends, I'm about to start with Tensorflow (I have knowledge of Python). I would like to know if there is any Ide to work with Tensorflow and Python. Thank you.",5,2
18,2018-4-8,2018,4,8,16,8aoigh,"free AI annotation tools for images,videos and texts.",https://www.reddit.com/r/tensorflow/comments/8aoigh/free_ai_annotation_tools_for_imagesvideos_and/,Colabeler,1523172331,,0,7
19,2018-4-9,2018,4,9,4,8asg1n,Customize a CNN?,https://www.reddit.com/r/tensorflow/comments/8asg1n/customize_a_cnn/,faria324,1523216704,"1) How can I build a basic CNN with tensorflow? (This I could probably google, but the other 2 questions probably not...)

2) How can I customize it by adding a few extra features onto the end of the input vector that aren't attached to any hidden nodes, but instead are connected directly to the output node?

3) How can I build a 2nd custom CNN with 6 output nodes instead of just 1?",1,1
20,2018-4-9,2018,4,9,8,8atugy,Remove gradient clipping for observation purposes,https://www.reddit.com/r/tensorflow/comments/8atugy/remove_gradient_clipping_for_observation_purposes/,staydreamy,1523228553,"I would like to observe the effect of removing gradient clipping. I have 

    loss_val, _ = session.run([loss, optimizer], feed_dict)
    avg_loss += loss_val

However when I do 

    loss_val = session.run([loss], feed_dict)` I get the following error 
    TypeError: unsupported operand type(s) for +=: 'int' and 'list'

and when I try: loss_val = session.run(loss, feed_dict), i get the error:

    TypeError: 'numpy.float64' object is not iterable

How do I go about removing gradient clipping?",7,1
21,2018-4-9,2018,4,9,8,8au5kj,[Q] need help installing tensorflow ubuntu 17.10,https://www.reddit.com/r/tensorflow/comments/8au5kj/q_need_help_installing_tensorflow_ubuntu_1710/,leetfire666,1523231437,"Hello,

I'm trying to install tensorflow on Ubuntu 17.10 and I'm going through a combination of this guide: https://medium.com/@adakaminkure/if-youre-trying-to-install-tensorflow-on-ubuntu-17-10-703b971d98d

and https://www.tensorflow.org/install/install_linux

I'm bumping into a few issues.

1. I'm stuck at the mnist compilation step:

    $ cp -r /usr/src/cudnn_samples_v7/ $HOME

    $ cd $HOME/cudnn_samples_v7/mnistCUDNN

    $ make

    $ ./mnistCUDNN

I get the following error:

    cudnnGetVersion() : 7102 , CUDNN_VERSION from cudnn.h : 7102 (7.1.2)
    Cuda failurer version : GCC 6.4.0
    Error: unknown error
    error_util.h:93
    Aborting...

2. If I move past that and try to install tensorflow on a virtualenv:

    $ sudo apt-get install python3-pip python3-dev python-virtualenv 

    $ virtualenv --system-site-packages -p python3 ~/tensorflow

    $ source ~/tensorflow/bin/activate

    $ easy_install -U pip

    $ pip3 install --upgrade tensorflow-gpu

I notice the following in the last commands output:

    protobuf 3.5.2.post1 requires six&gt;=1.9, which is not installed.
    grpcio 1.10.1 requires six&gt;=1.5.2, which is not installed.
    absl-py 0.1.13 requires six, which is not installed.
    html5lib 0.9999999 requires six, which is not installed.
    bleach 1.5.0 requires six, which is not installed.
    tensorboard 1.7.0 requires six&gt;=1.10.0, which is not installed.
    tensorflow-gpu 1.7.0 requires six&gt;=1.10.0, which is not installed.

3. I then tried running:

    $ import tensorflow as tf

    $ hello = tf.constant(""Hello, Ada from Tensorflow"")

    $ session = tf.Session()

I get the following error:

    2018-04-08 16:33:31.297906: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
    2018-04-08 16:33:31.346416: E tensorflow/stream_executor/cuda/cuda_driver.cc:406] failed call to cuInit: CUDA_ERROR_UNKNOWN
    2018-04-08 16:33:31.346468: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:145] kernel driver does not appear to be running on this host (spacecowboy): /proc/driver/nvidia/version does not exist

----

Any idea what's going on?",5,1
22,2018-4-9,2018,4,9,11,8av1lu,Beginner question,https://www.reddit.com/r/tensorflow/comments/8av1lu/beginner_question/,thefernandito,1523239996,"To create a complex system is it possible to do it only with python and Tensorflow, or is it necessary to know other things?
Thank you very much. I'm just starting.",4,2
23,2018-4-9,2018,4,9,21,8axvm0,Problem calculating Exponential cost in tensorflow,https://www.reddit.com/r/tensorflow/comments/8axvm0/problem_calculating_exponential_cost_in_tensorflow/,ShibeForceOne,1523275345,"I'm working on a Deep Learning project and I wanted to try out the 'Exponential Cost' as described here: https://stats.stackexchange.com/a/154880.

When I tried to calculate the cost, I got a bunch of NaN's, so I decided I'd break down the calculation, when I do this:

    ee = tf.divide(tf.reduce_sum(tf.square(tf_labels - l3_act)), TAU)               # Exponential Error

    error = tf.Print(ee, [ee], 'Exponential Error 1: ')
    error = tf.exp(error)
    error = tf.Print(error, [error], 'Exponential Error 2: ')

I get a bunch of NaN's for both Exponential Error 1 and 2, also Error 2 seems to only print every 50 or so iterations...

    Exponential Error 1: [242.370331]
    Exponential Error 1: [-nan]
    Exponential Error 1: [-nan]
    Exponential Error 1: [-nan]
    Exponential Error 1: [-nan]
    ...
    Exponential Error 2: [-nan]

When I do this:

    ee = tf.divide(tf.reduce_sum(tf.square(tf_labels - l3_act)), TAU)               # Exponential Error

    error = tf.Print(ee, [ee], 'Exponential Error 1: ')
    #error = tf.exp(error)
    error = tf.Print(error, [error], 'Exponential Error 2: ')

I get a bunch of values that seem like valid numbers to feed to an exponential function.
(Example output with valid numbers)

    Exponential Error 1: [1034.56555]
    Exponential Error 2: [1034.56555]
    Exponential Error 1: [4132.28076]
    Exponential Error 2: [4132.28076]
    Exponential Error 1: [435.344666]
    Exponential Error 2: [435.344666]
    ...

TAU is defined as follows:

    TAU = tf.constant(0.1, dtype=tf.float32)

Does anyone have any idea of what's going on with my model?",3,1
24,2018-4-10,2018,4,10,1,8azs3y,convnet2d - what if 'channels in' mismatch the input data?,https://www.reddit.com/r/tensorflow/comments/8azs3y/convnet2d_what_if_channels_in_mismatch_the_input/,ME_PhD,1523291431,"The conv2d function takes in data (call it 'X') and the kernel shape (call it 'K').

X is of shape [batch_size, image_height, image_width, image_channels]

K is of shape [filter_height, filter_width, channels_in, channels_out]

Question: What happens if image_channels doesn't match with channels_in? Will it create a bug or does tensorflow deal with it somehow, and is there a time where you want them different?

If it deals with it, what happens if channels_in is not divisible by image_channels? I'm trying to understand exactly what happens in the back end.",10,1
25,2018-4-10,2018,4,10,4,8b1ea1,Tensorflow serving best practices?,https://www.reddit.com/r/tensorflow/comments/8b1ea1/tensorflow_serving_best_practices/,hijakk,1523303427,"Hello, I'm looking at deploying a bunch (100+) of relatively simple linear SVM models for doing binary text classification as a web service. They're currently in sklearn. I've been pointed towards Tensorflow serving as a potential host for this set of models, and wanted to figure out best practice for dealing with text content in TFS since all the tutorials I see are for image classification. 

Is this the right way to go about it? If I can dockerize, should I have a docker container per model? Or can I reasonably serve many/all models from a single container?",5,3
26,2018-4-10,2018,4,10,15,8b5lmz,I am getting this error while training my own dataset using the object detection API. I am getting no response on github. Thought someone here might help. More details in the link. I am trying to finish my project. Any help would be appreciated.,https://www.reddit.com/r/tensorflow/comments/8b5lmz/i_am_getting_this_error_while_training_my_own/,ZER-0-NE,1523342204,,3,2
27,2018-4-10,2018,4,10,16,8b5xvv,"In an RNN model, is batch_size of the input stands for the time scan of an unfolded RNN?",https://www.reddit.com/r/tensorflow/comments/8b5xvv/in_an_rnn_model_is_batch_size_of_the_input_stands/,Laurence-Lin,1523346851,"If I have input matrix X with shape [N, M], which means I have N input sample(these N sequences are consecutive time series data), each have M dimension. I have only one batch, batch size = N,  then while input to an RNN model, I thought the unfold RNN have time scan from t = 1 to N. Is that correct?",4,0
28,2018-4-10,2018,4,10,18,8b6b3c,Tensorflow suddenly allocating way too much GPU memory,https://www.reddit.com/r/tensorflow/comments/8b6b3c/tensorflow_suddenly_allocating_way_too_much_gpu/,nst_1234,1523352152,"Ever since yesterday all my tensorflow or keras scripts give me an error that I ran out of GPU memory. Even when I run the ""label_image.py"" [example from Tensorflow](https://www.tensorflow.org/tutorials/image_recognition) I get that error, even though that script used to work without any problems.


Here's the error I get when running ""label_image.py""

&gt;PS C:\Users\NSA&gt; cd 'c:\Users\NSA\tensorflow\tensorflow\examples\label_image'; ${env:PYTHONIOENCODING}='UTF-8'; ${env:PYTHONUNBUFFERED}='1'; &amp; 'C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\python.exe' 'C:\Users\NSA\.vscode\extensions\ms-python.python-2018.3.1\pythonFiles\PythonTools\visualstudio_py_launcher.py' 'c:\Users\NSA\tensorflow\tensorflow\examples\label_image' '50745' '34806ad9-833a-4524-8cd6-18ca4aa74f14' 'RedirectOutput,RedirectOutput' 'c:\Users\NSA\tensorflow\tensorflow\examples\label_image\label_image.py'

&gt;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will
be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters

&gt;2018-04-10 11:18:45.499948: I T:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2

&gt;2018-04-10 11:18:46.090974: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1344] Found device 0 with properties:
name: GeForce 940MX major: 5 minor: 0 memoryClockRate(GHz): 1.189
pciBusID: 0000:02:00.0
totalMemory: 2.00GiB freeMemory: 1.66GiB

&gt;2018-04-10 11:18:46.096515: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1423] Adding visible gpu devices: 0

&gt;2018-04-10 11:18:46.849567: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:

&gt;2018-04-10 11:18:46.853286: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:917]      0

&gt;2018-04-10 11:18:46.855627: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:930] 0:   N

&gt;2018-04-10 11:18:46.858081: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replic2018-04-10 11:18:51.611905: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1423] Adding visible gpu devices: 0

&gt;2018-04-10 11:18:51.616535: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:

&gt;2018-04-10 11:18:51.620123: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:917]      0

&gt;2018-04-10 11:18:51.625542: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:930] 0:   N

&gt;2018-04-10 11:18:51.628802: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1429 MB memory) -&gt; physical GPU (device: 0, name: GeForce 940MX, pci bus id: 0000:02:00.0, compute capability: 5.0)

&gt;2018-04-10 11:18:56.348615: W T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.91GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.

&gt;2018-04-10 11:18:57.480611: W T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.41GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.

&gt;2018-04-10 11:18:57.489497: W T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.69GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.

&gt;2018-04-10 11:18:57.498368: W T:\src\military uniform 0.8330358
mortarboard 0.020486064
academic gown 0.009828327
pickelhaube 0.007285705
bulletproof vest 0.00522343


I have already updated my NVIDIA drivers and reinstalled Keras, Tensorflow, cuDNN as well as CUDA. I am using Tensorflow 1.6, cuDNN 7.0.5 and CUDA 9.0 on an NVIDIA GeForce 940MX.

The out of memory occurs when executing 

    results = sess.run(output_operation.outputs[0], {
        input_operation.outputs[0]: t
    })",12,1
29,2018-4-11,2018,4,11,4,8balo6,NN with tensorflow,https://www.reddit.com/r/tensorflow/comments/8balo6/nn_with_tensorflow/,joey_php,1523388823,,3,0
30,2018-4-11,2018,4,11,7,8bc5do,Style Transfer with lbfgs.,https://www.reddit.com/r/tensorflow/comments/8bc5do/style_transfer_with_lbfgs/,nile6499,1523400101,"Style Transfer with lbfgs.
I have written a code which works with scipy.optimize.minimize()

but it doesn't seems to be working with tf.contrib.scipy.optimize()
and also it is not working with any other tf.train.optimizer.

If anyone interest below is the code.


####################################################################################
##############  USING SCIPY OPTIMIZER  ############################

####################################################################################

art_image = photo
#art_image = np.random.uniform(-1.0, +1.0, (image_size, image_size, 3))

x0 = art_image.flatten().astype('float64')
iteration=0

t0 = time.time()

with tf.Session() as sess:
    init_fn(sess)

    def eval_loss_and_grad(x):  # x0 is a 3*image_size*image_size float64 vector
        x_image = x.reshape(1,224,224,3).astype('float32')

        sess.run(input_image_float.assign(x_image))
        x_loss, x_grad = sess.run( [total_loss, total_grad])
        print(""\nEval Loss @ "", [ ""%.6f"" % l for l in x[100:106]], "" = "", x_loss)
            #print(""Eval Grad = "", [ ""%.6f"" % l for l in x_grad.flatten()[100:106]] )


        return x_loss.astype('float64'), x_grad.flatten().astype('float64')

    x0, x0_loss, state = scipy.optimize.fmin_l_bfgs_b( eval_loss_and_grad,x0, maxfun=500,maxiter=500) 

#################################################################################

############# TF.SCIPY.OPTIMIZER ##############################
#################################################################


with tf.Session() as sess:
            
            ###############################
            ## TO DO: 
            ## 1. initialize your variables
            ## 2. create writer to write your graph
    init_fn(sess)
    
    sess.run(tf.global_variables_initializer())
    sess.run(input_image_float.assign(j))

# For this kind of use case, the limited memory BFGS performs the best
    optimizer = tf.contrib.opt.ScipyOptimizerInterface(cl, method='L-BFGS-B',
                                                   options={'maxiter': 30})
#     x_loss, x_grad = sess.run( [total_loss, total_grad])
    global step
    step = 0

    def update(l):
        # Function to print loss
        global step
        if step % 10 == 0:
            print('Step {}; loss {}'.format(step, l))
        step += 1

    optimizer.minimize(sess, fetches=[cl], loss_callback=update)
    gen = sess.run(input_image_float)
#     o = sess.run(photo)


##############################################################

",1,1
31,2018-4-11,2018,4,11,8,8bcagt,GPU usage dramatically increases when I open Chrome while training... what?,https://www.reddit.com/r/tensorflow/comments/8bcagt/gpu_usage_dramatically_increases_when_i_open/,Iklowto,1523401279,"Hello everyone, 

I don't know what's happening here, but I'm definitely not upset about it. 

I am currently training an RNN and was a bit upset about my GPU usage, which was consistently between 5-15%. I tried increasing and decreasing the batch size in hopes of changing anything but to no avail. 

I finally decided on a batch size and decided to just let it do its thing while I watched some Netflix and went to bed. I drew up Tensorboard so I could peek at the progress from time to time, and when I opened the Chrome window, I could audibly hear my GPU speed up. Indeed, when I looked the task manager, the GPU usage was now consistently between 40-45%. I minimized the Chrome window, back to 5-15%. De-minimized the Chrome window, immediately back at 40-45%. What the fuck? This is great, albeit a little confusing. 

Does anyone know what is going on here? 

In case it helps: 

Batch-size: 128

Input sequence: 128 x 35 floating point values

GPU: Nvidia GTX 1060 Strix

OS: Windows 10

",9,3
32,2018-4-12,2018,4,12,17,8bon43,Tensorflow's tutorial is sucks,https://www.reddit.com/r/tensorflow/comments/8bon43/tensorflows_tutorial_is_sucks/,L_E_I,1523522006,"Have played with TensorFlow for a while by reading and revising other's code. Now I want to read tensorflows tutorial carefully and learn tensorflow comprehensively. Then I find the official tensorflow's tutorial is really sucks. For one thing, there are to many see other pages, I have to click many links in order to get understand about a code in tutorial. For other thing, tensorflow's APIs are not unified. In https://www.tensorflow.org/get_started/eager, it tells me to load CSV file by tf.data.TextLineDataset, but in other page (https://www.tensorflow.org/api_docs/python/tf/TextLineReader), it tells me to load CSV file by tf.TextLineReader. Can they unify the tutorial?",14,29
33,2018-4-13,2018,4,13,0,8br0d6,What happened to skflow and can I access it in tensorflow?,https://www.reddit.com/r/tensorflow/comments/8br0d6/what_happened_to_skflow_and_can_i_access_it_in/,Akumasade,1523546779,"I recently found out about it and wanted to use it, but the stuff in the github repo seems to have been moved to the tensorflow module. Is there a way to access it in the tensorflow python module?",1,3
34,2018-4-13,2018,4,13,1,8brlft,Tensorflow wrapping padding?,https://www.reddit.com/r/tensorflow/comments/8brlft/tensorflow_wrapping_padding/,mtutnid,1523551275,Like in numpy,1,1
35,2018-4-13,2018,4,13,4,8bsqze,Fit model to only 1 changed output,https://www.reddit.com/r/tensorflow/comments/8bsqze/fit_model_to_only_1_changed_output/,manicman1999,1523560047,"I'm trying to build a neural network to learn to play a game using Q Learning. For this, I only want to backpropogate on one output value, rather than all of them. What's the easiest way to do this?",0,2
36,2018-4-13,2018,4,13,5,8btcps,Cannot find output_graph.pb and output_labels.txt location,https://www.reddit.com/r/tensorflow/comments/8btcps/cannot_find_output_graphpb_and_output_labelstxt/,[deleted],1523564703,[deleted],0,1
37,2018-4-13,2018,4,13,18,8bxx2x,Beginner Question,https://www.reddit.com/r/tensorflow/comments/8bxx2x/beginner_question/,kujjwal002,1523612362,"Why do we need to initialize variables even though the variable has values

Like in this code


    import tensorflow as tf

    sess = tf.InteractiveSession()

    my_tensor = tf.random_uniform((4, 4), 0, 1)
    my_var = tf.Variable(initial_value=my_tensor)

    sess.run(my_var)


On execution throws an error

but if I initialize it with 

    init = tf.global_variables_initializer()
    sess.run(init)

everything works fine.

In a nutshell

What I want to ask is

What does `tf.global_variables_initializer()` do?

I previously thought that it initializes the variables that do not contain any value.

But now I am having doubts about that.

Please help with this
",0,1
38,2018-4-14,2018,4,14,4,8c1w6q,"I have written a GAN which I hoped would synthesize MRI data from a random noise vector, the generator isn't being updated. Can anyone help?",https://www.reddit.com/r/tensorflow/comments/8c1w6q/i_have_written_a_gan_which_i_hoped_would/,[deleted],1523647750,[deleted],0,1
39,2018-4-14,2018,4,14,15,8c5tst,How is dropout implemented?,https://www.reddit.com/r/tensorflow/comments/8c5tst/how_is_dropout_implemented/,ME_PhD,1523687077,"I want to know how some variables are temporarily ""disabled"". What does this mean mathematically? For example in a normal linear layer, I have a weight matrix W that maps input to output + bias vector. If I have dropout, what happens - does it make some of the elements of W and their gradients = 0 (constants of 0) for that iteration? ",7,2
40,2018-4-15,2018,4,15,2,8c8v76,Tensorflow inside for loop slow,https://www.reddit.com/r/tensorflow/comments/8c8v76/tensorflow_inside_for_loop_slow/,mtutnid,1523725616,"So i tried to follow the PDE tutorial in TF. And it seemed kindof slow so I setup a few tests. Both of these codes take more than 30 seconds on my machine. Any ideas? My solution was the last one, but there should be a better way no?

Example using  Variable as in PDE tutorial

    import tensorflow as tf
    import numpy as np
    import math

    N = 200
    u_init = np.zeros([1, N], dtype=np.float32)

    for l in range(N):
      u_init[0][l] = 1+math.sin(2 * math.pi * l / N) #1+np.random.normal(0, 0.1, N)

    sess = tf.Session()

    U = tf.Variable(u_init)
    U_ = U+1

    step = U.assign(U)
    tf.global_variables_initializer().run(session=sess)
    for i in range(100000):
      sess.run(step)

Tested code according to forum post still slow

    import tensorflow as tf
    import numpy as np
    import math

    N = 200
    u_init = np.zeros([1, N], dtype=np.float32)

    for l in range(N):
      u_init[0][l] = 1+math.sin(2 * math.pi * l / N) #1+np.random.normal(0, 0.1, N)

    sess = tf.Session()

    U = tf.placeholder(tf.float32, shape=[1, N])

    U_ = U+1

    a = sess.run(U_,feed_dict={U: u_init})

    for i in range(100000):
      a = sess.run(U_,feed_dict={U: a})



My fix works fast, but doesn't seem like a proper way to do it

    import tensorflow as tf
    import numpy as np
    import math


    N = 200
    u_init = np.zeros([1, N], dtype=np.float32)

    for l in range(N):
      u_init[0][l] = 1+math.sin(2 * math.pi * l / N) #1+np.random.normal(0, 0.1, N)

    sess = tf.Session()

    U = tf.placeholder(tf.float32, shape=[1, N])
    U_ = U+1
    for i in range(1000):
      U_ = U_+1

    a = sess.run(U_,feed_dict={U: u_init})

    for i in range(1000):
      a = sess.run(U_,feed_dict={U: a})

    print(a)



",4,2
41,2018-4-17,2018,4,17,18,8cvcac,Gan example,https://www.reddit.com/r/tensorflow/comments/8cvcac/gan_example/,mohanradhakrishnan,1523958585,"This is my first TF Gan based on other examples. I have images that I want the GAN to train on. It should generate more such images.

Does this TF code seem to be right ? It executes but does not finish. How long should it take ?
I am showing only this method because I have this doubt.

     def train():
         filenames = tf.train.string_input_producer(
             tf.train.match_filenames_once(""D:/*.png""))
         reader = tf.WholeFileReader()
         key, value = reader.read(filenames)
         batch = tf.train.batch([value], batch_size=5)
         init = (tf.global_variables_initializer(), tf.local_variables_initializer())

        with tf.Session() as sess:
            sess.run(init)
            coord = tf.train.Coordinator()
            threads = tf.train.start_queue_runners(coord=coord)

        for it in range(1): #Range is 1 for testing.
            X_batch, _ =     batch = sess.run([value])
            _, DiscriminatorLoss = sess.run([D_optimizer, Disc_loss], feed_dict={X: X_batch, Z: samplefromuniformdistribution(5, [None, 100])})
            _, GeneratorLoss = sess.run([G_optimizer, Generate_loss], feed_dict={Z: samplefromuniformdistribution(5, [None, 100])})
",1,0
42,2018-4-17,2018,4,17,21,8cw7jm,"Tensorflow-gpu takes long time before starting to compute [Windows10x64, GTX 1080]",https://www.reddit.com/r/tensorflow/comments/8cw7jm/tensorflowgpu_takes_long_time_before_starting_to/,kettenfett,1523968877,"When I run tensorflow, I get this after a *tf.Session()*:

    Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)] on win32
    Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
    &gt;&gt;&gt; import tensorflow as tf
    &gt;&gt;&gt; hello = tf.constant('Hello, TensorFlow!')
    &gt;&gt;&gt; sess = tf.Session()
    2018-04-17 13:56:44.736125: I C:\tf_jenkins\workspace\tf-nightly-windows\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
    2018-04-17 13:56:45.024692: I C:\tf_jenkins\workspace\tf-nightly-windows\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1355] Found device 0 with properties:
    name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335
    pciBusID: 0000:01:00.0
    totalMemory: 8.00GiB freeMemory: 6.60GiB
    2018-04-17 13:56:45.037254: I C:\tf_jenkins\workspace\tf-nightly-windows\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1434] Adding visible gpu devices: 0
    2018-04-17 13:58:46.118735: I C:\tf_jenkins\workspace\tf-nightly-windows\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:922] Device interconnect StreamExecutor with strength 1 edge matrix:
    2018-04-17 13:58:46.128851: I C:\tf_jenkins\workspace\tf-nightly-windows\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:928]      0
    2018-04-17 13:58:46.134459: I C:\tf_jenkins\workspace\tf-nightly-windows\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:941] 0:   N
    2018-04-17 13:58:46.140199: I C:\tf_jenkins\workspace\tf-nightly-windows\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1052] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6379 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
    &gt;&gt;&gt; print(sess.run(hello))
    b'Hello, TensorFlow!'
    &gt;&gt;&gt;

I'm running python 3.6 in conda 4.5.1.

So CUDA works, since it prints the  *'Hello, TensorFlow!'*, but before that it takes like 2minutes every time! 

When I tested this with [another wheel](https://drive.google.com/drive/folders/1lVK_ABvVHzVYKs7X5SUhcZFBgKpC41Qw) ([which is linked in this tutorial](http://www.python36.com/install-tensorflow-gpu-windows/), I did not compile it myself.) on cuda 9.1/cudnn7.0.5, i had the same issues. A NVIDIA employee [on stackoverflow](https://stackoverflow.com/questions/49770217/why-does-cuda-initialisation-take-so-long-python-vscode-anaconda-tensorflow) suggested, I may be hitting a lengthy JIT compile step, because the GTX 1080 has compute capability of 6.1, which the wheel I used may not be compiled for. 

So I tried to find wheels for tensorflow with compute capability 6.1 for windows, but [the only one I found](https://github.com/fo40225/tensorflow-windows-wheel/tree/master/1.5.0/py36/GPU/cuda91cudnn7avx2) and tested produced the same problem.

I currently have CUDA 9.0 and CuDNN 7.1.2 installed (tested on tensorflow 1.5.0, 1.7.0 and 1.8.0-dev20180329). I had the same issues with CUDA 9.1 and CuDNN 7.0.5 (tested on tensorflow 1.5.0 and 1.7.0).

The GTX 1080 is quite popular, so it should be possible to get this running right? Am I doing something wrong here, or do I just have to accept the 2min delay everytime I start my tensorflow/keras scripts?



",5,3
43,2018-4-18,2018,4,18,17,8d411x,TensorFlow barely using my GPU,https://www.reddit.com/r/tensorflow/comments/8d411x/tensorflow_barely_using_my_gpu/,nst_1234,1524039258,"What I'm trying to do is retrain VGG16 on recognizing new types of Image data using Keras with Tensorflow backend.
After I had a problem with Tensorflow/Keras wanting to allocate too much GPU memory [last week](https://www.reddit.com/r/tensorflow/comments/8b6b3c/tensorflow_suddenly_allocating_way_too_much_gpu/), I tried scaling my input images even further, and now I no longer get that error.

But the training process seems very slow to me, and after checking my GPU performance in the task manager it seems to me like my GPU is barely even being utilized. 

This is my code: https://hastebin.com/pepozayutu.py

This is the output in my console: https://hastebin.com/uhonugenej.md

And this is what my task manager looks like during training: https://imgur.com/a/jRJ66

As you can see the GPU is barely doing anything, so why is my training so slow? It's agonizing to try different setups because each training takes 20-60 min depending on number of epochs.

I have installed Tensorflow-gpu 1.7.0, cuDNN 7.0.5, CUDA 9.0 and Keras 2.1.5. I'm running an NVIDIA GeForce 940MX",4,1
44,2018-4-19,2018,4,19,0,8d6dbo,What are the most interesting github tensorflow projects you know?,https://www.reddit.com/r/tensorflow/comments/8d6dbo/what_are_the_most_interesting_github_tensorflow/,Bulbasaur2015,1524064383,total newbie,1,21
45,2018-4-19,2018,4,19,12,8dboic,Highlights of TensorFlow Developer Summit 2018,https://www.reddit.com/r/tensorflow/comments/8dboic/highlights_of_tensorflow_developer_summit_2018/,rbagdiya,1524108183,,0,1
46,2018-4-19,2018,4,19,13,8dc1ps,I have a sadly morning when I run a RNN example.,https://www.reddit.com/r/tensorflow/comments/8dc1ps/i_have_a_sadly_morning_when_i_run_a_rnn_example/,TimeHeight,1524112112,"Hello everyone.
I am a new learner for tensorflow. And I have just run two demo from https://github.com/tensorflow/tfjs-examples.
I am not understand clearly How RNN run When I run the addition-rnn demo. I just know that it can always put the previous result to the next. So that it can learn something to think which is the best result to the answer. Then the demo run good. After that I have a thought. Addition is always easier than multiply when I learn math, so I update it to a multiply. Update  'a + b' to 'a * b' and 'digits + 1' to 'digits * 2'. When I run the code, I sadly find that none of test example is correct. So I want to know if the RNN is just to guess the result and it is not suitable to accurate operations. And if there some way to improve the accuracy for the multiply.",3,0
47,2018-4-20,2018,4,20,0,8dfo83,Tensorflow Tutorial,https://www.reddit.com/r/tensorflow/comments/8dfo83/tensorflow_tutorial/,1anddy,1524153088,,0,12
48,2018-4-20,2018,4,20,17,8dm39r,Transfer Learning with Object Detection API,https://www.reddit.com/r/tensorflow/comments/8dm39r/transfer_learning_with_object_detection_api/,punkehazardo,1524213400,"I am using the Object Detection API and already have a trained model for my specific object classes. With my task, there will be more and more object classes over time. Since retraining on the combined datasets takes very long, I am interested in a way to only train the pre-trained net on the new data. I found this:
https://stackoverflow.com/questions/47591750/retrain-tensorflow-object-detection-api
But since I would need to load the checkpoint on the already trained data and train it again on a combined dataset, which contains the old data, wouldn't that lead to severe overfitting on the old data?",0,4
49,2018-4-21,2018,4,21,2,8dpm47,2D image classification accuracy with subtle differences,https://www.reddit.com/r/tensorflow/comments/8dpm47/2d_image_classification_accuracy_with_subtle/,ruru32,1524247071,"I have only been tinkering with tensorflow for a week or so now, but so far have been impressed by it. However, I am running into some accuracy issues and I want to better understand whats going on. 

Lets say I need to classify a bunch of logos. A company has the main logo and then the state initials in smaller text near it. 

So first off, there are only one of these images. I create variants using Augmentor, mostly just random 90 rotation, some skew and some distortion. 

When I train and then try to classify an logo, such as ""Big Brand Company Corp (NJ)"" it actually comes back ""Big Brand Company Corp (DC)"" with high confidence - on the incorrect one, and sometimes not even suggesting the correct one in the top 5. 

So, what I'd obviously like to do is get this right, but i'm not sure how. I've tried different tensorflow-hub modules, and increasing/varying the number of images; but nothing has really worked. 

What sort of things should I look into for increasing the accuracy of detecting differences in similar 2D images?",7,3
50,2018-4-21,2018,4,21,7,8dro04,"I created a One Shot Iterator for a csv of png's, now what?",https://www.reddit.com/r/tensorflow/comments/8dro04/i_created_a_one_shot_iterator_for_a_csv_of_pngs/,avtges,1524264100,"Howdy, so I finally got TF working to read my 4,401 png CSV. My only question is, what can I do with it?",0,1
51,2018-4-21,2018,4,21,8,8druiz,Tf.contrib.scipy.optimize(),https://www.reddit.com/r/tensorflow/comments/8druiz/tfcontribscipyoptimize/,nile6499,1524265808,"This function works but why does it evaluates function for 1 time till 5th iteration then starts multiple evaluation.
Or else if anyone can explain me about this function.",0,1
52,2018-4-22,2018,4,22,8,8dzlro,Training custom images,https://www.reddit.com/r/tensorflow/comments/8dzlro/training_custom_images/,nile6499,1524354559,"Hi, I have different folders, and name of the folders is the class name.

How should I import data for training? How should I make the pipeline?",3,1
53,2018-4-23,2018,4,23,14,8e90vk,Video classification using Cnn and then lstm,https://www.reddit.com/r/tensorflow/comments/8e90vk/video_classification_using_cnn_and_then_lstm/,nile6499,1524459704,"Hi, so I have 10 folders of videos (clip 2-10sec), and the folder name is the class name.

My first question.. do I need to divide the videos in image of t10 frame? And then train on CNN. Do I need to train till fully connected layer or till conv5?

Thank you,
Inspiring AI Master
",6,2
54,2018-4-24,2018,4,24,13,8ehr45,Does the TF 1.8 work with CUDA 9.1 at present?,https://www.reddit.com/r/tensorflow/comments/8ehr45/does_the_tf_18_work_with_cuda_91_at_present/,NWO_Propaganda,1524543616,"Thanks for any help, I'm still downloading drivers and hoping that I downloaded the correct 1.4 gig file. Happy coding &lt;3",1,2
55,2018-4-24,2018,4,24,16,8eiqod,Getting the details about the boundary of the objects in images using Tensor flow?,https://www.reddit.com/r/tensorflow/comments/8eiqod/getting_the_details_about_the_boundary_of_the/,lifehacker25,1524556373,"I am trying to build a model to detect different objects in images using the Tensor flow object detection API.

I have images some thing like this, objects placed on a white board. I Can use tensor flow to detect objects in the images, but is it possible to get the boundaries so that I can crop at particular place if I think specific image is necessary and use my Image processing technique further.

[These are some image types which I will be using for object detection](https://imgur.com/a/UyWoFdA)
",0,1
56,2018-4-24,2018,4,24,21,8ek21i,How do I code inverse of a function 'f' in tensorflow if 'f' is a composition of affine transformation with sigmoid activation only?,https://www.reddit.com/r/tensorflow/comments/8ek21i/how_do_i_code_inverse_of_a_function_f_in/,curonimous,1524573431,,1,1
57,2018-4-25,2018,4,25,2,8emdnn,Growing forest panorama simulated in TensorFlow!,https://www.reddit.com/r/tensorflow/comments/8emdnn/growing_forest_panorama_simulated_in_tensorflow/,LiveInIxora,1524592026,,2,6
58,2018-4-25,2018,4,25,4,8en673,Question about TensorFlow.js,https://www.reddit.com/r/tensorflow/comments/8en673/question_about_tensorflowjs/,rasplurker,1524597917,"I was reading about TensorFlow.js and how you can train models stricly on the client side using JS. So the point of this is that the data never hits any backend for computation and its using the computation GPU of the latop or phone right ? If that is the case, I was watching some videos on the topic and they import TennsorFlowJS using script tags that link to a CDN or using NPM to download the module ? What would be the different between both? if I use a CDN than the computation and model traning would NOT happen in the client side? since Im accessing the API through a CDN ? Im a bit confused about this concept. Thanks in advance. ",2,0
59,2018-4-25,2018,4,25,4,8en6do,20 year forest time-lapse made in TensorFlow!,https://www.reddit.com/r/tensorflow/comments/8en6do/20_year_forest_timelapse_made_in_tensorflow/,LiveInIxora,1524597957,,7,55
60,2018-4-25,2018,4,25,8,8ep500,"Why does Tensorflow's sampled_softmax_loss force you to use a bias, when experts recommend no bias be used for Word2Vec?",https://www.reddit.com/r/tensorflow/comments/8ep500/why_does_tensorflows_sampled_softmax_loss_force/,BatmantoshReturns,1524613627,"All the tensorflow implementations of Word2Vec that I have seen has a bias in the negative sampling softmax function, including on the official tensorflow website

https://www.tensorflow.org/tutorials/word2vec#vector-representations-of-words

    loss = tf.reduce_mean(
      tf.nn.nce_loss(weights=nce_weights,
                     biases=nce_biases,
                     labels=train_labels,
                     inputs=embed,
                     num_sampled=num_sampled,
                     num_classes=vocabulary_size))

This is from Google's free Deep Learning course https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/5_word2vec.ipynb

    loss = tf.reduce_mean(
        tf.nn.sampled_softmax_loss(weights=softmax_weights, biases=softmax_biases, inputs=embed,
                                   labels=train_labels, num_sampled=num_sampled, num_classes=vocabulary_size))

However, from both Andrew Ng and Richard Socher's lectures, they do not include a bias in their negative sampling softmaxes.

Even where this idea originated, Mikolov states that:

&gt; biases are not used in the neural network, as no significant improvement of performance was observed - following the Occam's razor, the solution is as simple as it needs to be.

Mikolov, T.: Statistical Language Models Based on Neural Networks, p. 29 http://www.fit.vutbr.cz/~imikolov/rnnlm/thesis.pdf

So why do the official tensorflow implementations have a bias, and why does there not seem to be an option to not include a bias in the sampled_softmax_loss function ?",0,1
61,2018-4-25,2018,4,25,11,8eqa1g,tensorflow.contrib.learn Error?,https://www.reddit.com/r/tensorflow/comments/8eqa1g/tensorflowcontriblearn_error/,exphysioguy,1524624364,"Can I not import tensorflow.contrib.learn for Linear Classifier anymore? 

I keep getting an error message. How do I use Linear Classifier now? ",0,1
62,2018-4-25,2018,4,25,20,8eswm1,Installing TensorFlow On Ubuntu - Get To Know How You Can Easily Have Your TensorFlow Up And Running!,https://www.reddit.com/r/tensorflow/comments/8eswm1/installing_tensorflow_on_ubuntu_get_to_know_how/,pooja307,1524656770,,0,8
63,2018-4-26,2018,4,26,9,8eymyn,Help need with simple CIFAR10 architecture for higher accuracy?,https://www.reddit.com/r/tensorflow/comments/8eymyn/help_need_with_simple_cifar10_architecture_for/,[deleted],1524703458,[deleted],0,1
64,2018-4-26,2018,4,26,10,8eyyg2,Help needed with simple CIFAR10 architecture to get slightly higher accuracy,https://www.reddit.com/r/tensorflow/comments/8eyyg2/help_needed_with_simple_cifar10_architecture_to/,nitred,1524706440,"I'm trying to classify CIFAR10 images using a simple CNN. So far I've only reached an accuracy of 71.8% after 10 epochs and it has already started to overfit. The only preprocessing that I do is standardize each image (individually, not batch).

Could you please make some architectural or preprocessing suggestions that will give a huge boost. I'm not looking to get state of the art results but rather an accuracy somewhere in the high 80's For reference the current benchmarks can be found [here](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).

This is the current architecture:

    with graph.as_default(), tf.device('/gpu:0'):
        ########################################################################
        # Architecture
        ########################################################################
        conv1 = tf.layers.conv2d(_batch_x, filters=128, kernel_size=5, activation=tf.nn.relu)  # 28 x 28
        conv1 = tf.layers.max_pooling2d(conv1, pool_size=2, strides=2)                         # 14 x 14
        conv1 = tf.nn.lrn(conv1, 4)

        conv2 = tf.layers.conv2d(conv1, filters=64, kernel_size=3, activation=tf.nn.relu)      # 12 x 12
        conv2 = tf.layers.max_pooling2d(conv2, pool_size=2, strides=2)                         # 6  x 6
        conv2 = tf.nn.lrn(conv2, 4)

        conv2_flat = tf.contrib.layers.flatten(conv2)                                         # flatten
        fc1 = tf.layers.dense(inputs=conv2_flat, units=102, activation=tf.nn.relu, name='fc1')
        # fc1 = tf.layers.dropout(inputs=fc1, rate=0.5, training=is_training)

        fc2 = tf.layers.dense(inputs=fc1, units=192, activation=tf.nn.relu, name='fc2')
        # fc2 = tf.layers.dropout(inputs=fc2, rate=0.5, training=is_training)

        # Linear activation because we will use sparse_softmax_cross_entropy_with_logits which does softmax for us.
        y_pred = tf.layers.dense(inputs=fc2, units=10)

        ########################################################################
        # Loss and Optimization
        ########################################################################
        _cross_entropy = tf.losses.sparse_softmax_cross_entropy(labels=_batch_y, logits=y_pred)
        _loss = tf.losses.get_total_loss()
        optimizer = tf.train.AdamOptimizer()
        _train = optimizer.minimize(_loss, global_step=_global_step)
",1,1
65,2018-4-26,2018,4,26,12,8ezm4x,How I Teach Machine to Comprehend and Answer Question using Tensorflow - Part I,https://www.reddit.com/r/tensorflow/comments/8ezm4x/how_i_teach_machine_to_comprehend_and_answer/,h_xiao,1524712869,,0,15
66,2018-4-27,2018,4,27,1,8f3xp1,"[Tensorflow] Logits change at test time, depending on the batch size",https://www.reddit.com/r/tensorflow/comments/8f3xp1/tensorflow_logits_change_at_test_time_depending/,saganspace,1524759668,"Does anyone else notice this? I realized when my accuracy changed with different batch sizes, so they're not irrelevant fluctuations.

I attach code that tests this issue. \(tested in tf v1.3\)

[https://www.dropbox.com/s/ns9j84t02zifdaa/test\_batch\_size.zip?dl=0](https://www.dropbox.com/s/ns9j84t02zifdaa/test_batch_size.zip?dl=0)

you can run: python test\_batch\_size.py \-\-batch\_size=2

and it will print the logits for the 1st frame \(which is always the same\).

Varying the batch\_size argument will lead to different logits.

CUDA\_VISIBLE\_DEVICES=\-1 python test\_batch\_size.py \-\-batch\_size=2 

also leads to different results \(cpu vs gpu\)

Do you have comments on this? How should we evaluate our models? What is the best practice?",0,2
67,2018-4-27,2018,4,27,21,8fb81s,What am i doing wrong (Tensorflow Noob).,https://www.reddit.com/r/tensorflow/comments/8fb81s/what_am_i_doing_wrong_tensorflow_noob/,Jonas_SV,1524831841,"The learner does not seem to learn anything 

    import tensorflow as tf
    import numpy as np



    I = tf.placeholder(np.float32, shape=[None, 1], name=""I"")
    L1 = tf.layers.dense(I, 5, activation=tf.nn.tanh)
    L2 = tf.layers.dense(L1, 1, activation=tf.nn.relu)


    def __loss__(predictions, labels):
        return tf.reduce_sum(tf.pow(predictions - labels, 2))


    labels = tf.placeholder(np.float32, shape=[None, 1], name=""L"")

    loss = __loss__(L2, labels)
    learner = tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(loss)

    IP = np.array([[1],[2],[3],[4]], dtype=np.float32)
    LABEL = np.array([[-1],[-2],[-3],[-4]], dtype=np.float32)


    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())

        print(sess.run(L2, {""I:0"": IP}))
        iters = 10
        while iters:
            _, l = sess.run((learner, loss), feed_dict={""I:0"": IP, ""L:0"": LABEL})

            print(l)

            iters -= 1

        print(sess.run(L2, {""I:0"": IP}))

    sess.close()



Output 

      [[0.10446054]
     [0.165672  ]
     [0.17981592]
     [0.1674025 ]]
    33.38844
    30.0
    30.0
    30.0
    30.0
    30.0
    30.0
    30.0
    30.0
    30.0
    [[0.]
     [0.]
     [0.]
     [0.]]


What am i doing wrong? :( 

And in general what is the recommended data pipeline for tensorflow, i've heard people not recommending feed_dict",3,2
68,2018-4-28,2018,4,28,4,8feijx,How well can DNN work on Abalone Dataset?,https://www.reddit.com/r/tensorflow/comments/8feijx/how_well_can_dnn_work_on_abalone_dataset/,HunterTom94,1524858723,"Hi Guys,

I am new to ML but I just  downloaded the existing estimator for iris dataset from  

**git clone https://github.com/tensorflow/models**  

and tried to modify it to accept input from the abalone dataset. I have modified the iris\_data file as well.

The model runs fine \(except the fact that n\_classes for the classifier has to be 30 in order to function\). However, even if I set the hidden\_units=\[1000, 100,100\] and **batch\_size** = 1000, after hours of training, my accuracy is still 0.12. Even though the loss is less than 1.

It does not make sense to me. Can anyone tell me some parameters that worked on this data set? Thanks very much!",2,1
69,2018-4-28,2018,4,28,6,8ff1jm,"How do you use decode_csv to get columns, where one column is a ""list""?",https://www.reddit.com/r/tensorflow/comments/8ff1jm/how_do_you_use_decode_csv_to_get_columns_where/,rjddude1,1524863172,"I have training data with few categorical values (tags). The tag values are from a predefined set of vocabularies (that can expand over time). 

A single column can have multiple ""tags"". So for instance, one of the columns  is 'User City Preferences', where the tags are predefined set of cities that the user can pick from. This column can have multiple categorical values:

    #CSV data column
    #User-City-Preference,Happiness
    Berlin|London|Budapest,0.4
    London|Toronto,0.6
    
    #Vocabulary looks like this: 
    ['Berlin', 'London', 'Budapest', 'Toronto']

If I were to convert the first column to a feature, I want the tensor to be represented like **[[1 1 0 1] [0 1 0 1]]**

When I'm using the decode_csv to convert the csv data into tensors, how do I make sure that the delimited values for the column gets parsed correctly. Essentially how do I handle a list within a csv column? 

And once I have these, and I want to use them in the wide/deep model, what type of feature column should they be converted in?

Any help would be appreciated.",1,1
70,2018-4-28,2018,4,28,11,8fgv2i,I am looking for contributors to make research on different ML architectures applied to popular data-sets.,https://www.reddit.com/r/tensorflow/comments/8fgv2i/i_am_looking_for_contributors_to_make_research_on/,rahimlis,1524881107,,2,2
71,2018-4-28,2018,4,28,14,8fi0wm,A step-by-step guide for tensorflow gpu installation on ubuntu 18.04,https://www.reddit.com/r/tensorflow/comments/8fi0wm/a_stepbystep_guide_for_tensorflow_gpu/,kekayan,1524894751,,0,19
72,2018-4-28,2018,4,28,15,8fi3zu,output shape of tensor changes when assigned to a variable,https://www.reddit.com/r/tensorflow/comments/8fi3zu/output_shape_of_tensor_changes_when_assigned_to_a/,memlimexced,1524895905,"Defined a model which takes input of shape(96,96,3) and outputs shape(128) i.e. gives an embedding of 128 size for a given image of input size. Similar to facenet

createmodel() is the function which returns the full model after constructing it. Since the model expects input in the form of (batch_size,96,96,3) I pass 3 images i.e. (3,96,96,3) so the output of the model will be of shape(1,3,128). Keeping that in mind consider the following:

    nn4_small2=createmodel()
    print(nn4_small2.outputs[0][2])

#prints Tensor(""strided_slice_11:0"", shape=(128,), dtype=float32)

    x=nn4_small2.outputs[0][2]
    print(tf.shape(x))

#prints Tensor(""Shape_6:0"", shape=(1,), dtype=int32)
Why does the shape of the output tensor change when assigned to a variable?",0,1
73,2018-4-29,2018,4,29,15,8fprxb,"Implementing a custom function inside loss, which will use model predictions as parameter and return a value to the loss function. Can anyone help me with this, please? I searched for a full day and still can't do this! it seems very simple but impossible to me.",https://www.reddit.com/r/tensorflow/comments/8fprxb/implementing_a_custom_function_inside_loss_which/,theslt,1524984395,,1,0
74,2018-4-30,2018,4,30,8,8fv9r9,EosToken,https://www.reddit.com/r/tensorflow/comments/8fv9r9/eostoken/,QoQzZ,1525044851,"EosToken500,000EOS~0EOShttp://static.eostoken.im/invite/index.html#423667,",0,0
75,2018-4-30,2018,4,30,12,8fwlgz,Negative sampling in tensorflow?,https://www.reddit.com/r/tensorflow/comments/8fwlgz/negative_sampling_in_tensorflow/,mortonjt,1525058511,"Has anyone been able to make sense of what is going underneath the hood with negative sampling?  I'm trying to implement my own negative sampler using similar techniques implemented in NCE and am finding a bit challenging to fully understand.

Right now I'm trying to make use the of the `[compute_accidental_hits](https://www.tensorflow.org/api_docs/python/tf/nn/compute_accidental_hits)` function - since it looks like most of these negative sampling techniques make use of this.  However, I'm getting a bit confused about the documentation.  For instance, it's not clear to me how the `sparse_to_dense` function will come to play here.  Or exactly how this function can help remove the contradictory effect of accidental hits.  Any thoughts on this functionality?",0,1
76,2018-4-30,2018,4,30,14,8fxafp,How do you categorize/organize trained models?,https://www.reddit.com/r/tensorflow/comments/8fxafp/how_do_you_categorizeorganize_trained_models/,IntegrateMe,1525066946,"I'm working on a project right now where the output of my model is merely a class with three values. -1, 0, or +1. Pretty standard stuff.

Over time, I found myself trying new features, different learning rates, different topologies... etc. 

I then found myself wondering, wait how would this model benefit from another dropout layer and so on, but then I would struggle to go through my git history to find out which one I was wondering about.

So the question is, how do the rest of you organize/categorize your models. What's your process for archiving models and restoring them for tensorflow?

Sorry if the question is vague, I'm new to tensorflow. DevOps by trade, so old habits die hard.",4,2
77,2018-4-30,2018,4,30,23,8fzpvk,Text Summarizer using Tensorflow,https://www.reddit.com/r/tensorflow/comments/8fzpvk/text_summarizer_using_tensorflow/,Wallflower_Paradox,1525097458,"How do we make a text summarizer using Tensorflow? I want some documentation or reference . An already made  project would be great to study. 

I got this as an assignment for . How long does it take to make it ? And, where to start? Please reply . Thanks already. ",1,2
0,2018-5-1,2018,5,1,14,8g64qj,Trouble with inputting data,https://www.reddit.com/r/tensorflow/comments/8g64qj/trouble_with_inputting_data/,ilovecheese4me,1525152813,"I am new to Tensorflow and I am having trouble with input_fn during training the model. It says I need to have a dictionary of tensors for the x value, but I do not know how to format the inputs. Any help would be appreciated.",1,2
1,2018-5-2,2018,5,2,2,8ga2jv,When is it appropriate to use multiple graphs?,https://www.reddit.com/r/tensorflow/comments/8ga2jv/when_is_it_appropriate_to_use_multiple_graphs/,vandelet_industries,1525194478,"When should multiple graphs be compiled? For instance, having a training graph and a prediction graph.

A question with more details is this:

-When are two ""processes"" (non-technical usage here) sufficiently different from each other that a second graph is warranted? For example, if I use the same graph for training and prediction, the prediction graph has extra ops in it.

- How many extra ops is too many, and how does it effect performance? If I have a loss op and an optimizer op in the graph I use for prediction, does it really matter that much if I'm not using the session to run them?

- I like the detail of compiling separate graphs, but it seems to me to be a huge pain, since there isn't a straightforward way, to the best of my knowledge, to copy a tensor to a new graph and also retain its current value. So what's the tradeoff between performance and the complexity of the code required to transfer everything over? Or does it matter, in practice, since one would probably be saving tensors in one graph and loading them in another?",1,3
2,2018-5-2,2018,5,2,4,8gb1n1,Combining a Cell with a Tensor,https://www.reddit.com/r/tensorflow/comments/8gb1n1/combining_a_cell_with_a_tensor/,risajef,1525202059,"Hi
I have a LSTMCell wich outputs 1 number every time step.
I have also an input wich is one number every time step.
Now I want this two numbers to be the input of the next LSTMCell.
Something like a zip in python.
But Tensorflow tells me I can't concatenate a Cell because it does not have the method ""get_shape"".
The whole thing should than become one model wich needs to be optimized.

Does anybody now a way how to do this?",0,1
3,2018-5-2,2018,5,2,8,8gcvjd,If anyone converted a custom trained tensorflow model to coreml i might need some help,https://www.reddit.com/r/tensorflow/comments/8gcvjd/if_anyone_converted_a_custom_trained_tensorflow/,noorhashem,1525216952,"I have custom trained the faster rcnn inception v2 tensorflow model and now i need to convert it to coreml to use it on my ios app.

I followed this 

https://hackernoon.com/integrating-tensorflow-model-in-an-ios-app-cecf30b9068d

but i was wondering should i search for my softmax op as my output tensor value in my model summary file and use its value in my output feature names? or check the last op in my model summary?

this is my model summary end : 
https://imgur.com/a/QJD0dvP

",0,2
4,2018-5-2,2018,5,2,15,8gfc0a,Can't install tensorflow 1.5 and 1.8 gives me Illegal instruction:4 on macOS- Sierra.,https://www.reddit.com/r/tensorflow/comments/8gfc0a/cant_install_tensorflow_15_and_18_gives_me/,KarlJay001,1525242700,"I'm using Python3 latest version and I use pip to install tensorflow for a tutorial:

https://www.youtube.com/watch?v=MrBzgvUNr4w&amp;list=PL2\-dafEMk2A6QKz1mrk1uIGfHkC1zZ6UU&amp;index=5

I got all the code ironed out, now I get an error when I use tensorflow 1.8.  The research says that I need to backgrade \(uninstall/ reinstall\) to version 1.5, but I can't do that because it complains about EnvironmentError.

I'm kinda stuck.  I did find version 1.5 on GitHub and downloaded the .zip, but I have no idea how to install this so that Python can use it.  The fix to go to version 1.5 came from SO where someone had the same error.  For some reason, I can't install 1.5, maybe it's pulled offline or something.

    Could not install packages due to an EnvironmentError.
    Traceback (most recent call last):
      File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_internal/commands/install.py"", line 335, in run
        use_user_site=options.use_user_site,
      File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_internal/req/__init__.py"", line 49, in install_given_reqs
        **kwargs
      File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_internal/req/req_install.py"", line 748, in install
        use_user_site=use_user_site, pycompile=pycompile,
      File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_internal/req/req_install.py"", line 961, in move_wheel_files
        warn_script_location=warn_script_location,
      File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_internal/wheel.py"", line 314, in move_wheel_files
        clobber(source, lib_dir, True)
      File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/_internal/wheel.py"", line 298, in clobber
        os.utime(destfile, (st.st_atime, st.st_mtime))
    PermissionError: [Errno 1] Operation not permitted
    Cleaning up...",5,0
5,2018-5-2,2018,5,2,20,8ggoh1,Trying to understand the math behind this simple program and my numbers don't match.,https://www.reddit.com/r/tensorflow/comments/8ggoh1/trying_to_understand_the_math_behind_this_simple/,mammalian_magistrate,1525260566,"Code is here with my output on the bottom: https://paste.ofcode.org/394bp4CMpVPF6Bqx5DD7qGx

I traced through and did the following:

* Transpose and multiply and get 0.54 initially. 
* Add bias, bringing it to 0.34 (y_pred)
* Subtract y_true and y_pred to get 0.06
* Square it to get 0.036
* reduce mean, but given it's a single value, then it's still 0.036, right? 

I'm assuming it's somewhere in the last step that I'm getting things screwed up. ",2,1
6,2018-5-3,2018,5,3,8,8glx0c,I'm struggling to deploy tensorzoom in an android app,https://www.reddit.com/r/tensorflow/comments/8glx0c/im_struggling_to_deploy_tensorzoom_in_an_android/,idrissAithafid,1525303886,"Hey tensorflows I'm idriss a second year software engineer student in Morocco.

And I have an android project it's principle goal is the zoom for impaired people.
 So for that I found an open source code on github https://github.com/machrisaa/tensorzoom

And I wanted to add to it some filters to help impaired people, especially students who struggles with the blackboard. And I want to add so many other things.

But because I'm new to tensorflow and machine learning in general, I don't know how to deploy this exact model on my app.

Note 1: I know how to deploy many models and I know the basics, but I'm struggling with this one.
Note 2: there's an app on play store that has deployed it called tensorzoom, but I don't know how :/ 

So if you can help me to get this tensorzoom working I would be grateful.",0,2
7,2018-5-3,2018,5,3,14,8go1vb,How does the LSTMCell map the input to hidden neurons in tensorflow?,https://www.reddit.com/r/tensorflow/comments/8go1vb/how_does_the_lstmcell_map_the_input_to_hidden/,Laurence-Lin,1525325360,"I'm looking the document code, in LSTM cell in order to get i,f,o,g elements we need to first map the input to hidden neuron. In the code:

https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/ops/rnn_cell_impl.py

I've seen that in 'call' function, gate input is 

math_ops.matmul(
array_ops.concat([inputs, h], 1), self._kernel)

However, I don't understand why should we concatenate input to hidden neuron. Why does this step happened?

Thanks a lot.",3,4
8,2018-5-3,2018,5,3,22,8gq7fj,What is the difference between these two approaches?,https://www.reddit.com/r/tensorflow/comments/8gq7fj/what_is_the_difference_between_these_two/,nst_1234,1525352674,"So following [this](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html) tutorial I managed to create two different approaches to building a binary image classifier using transfer learning from the imagenet dataset using the VGG16 architecture. The first as described in ""Using the bottleneck features of a pre-trained network: 90% accuracy in a minute"", getting the bottlenecks and then building a fully-connected classifier to train with those bottlenecks.
The second as described in ""Fine-tuning the top layers of a a pre-trained network"", except I froze all the layers, and then put a fully-connected classifier on top again and trained that one.

To me these two approaches should yield the same, if not very similar results. In the first approach I do not train my convolutional base at all, I just take the outputs and train a fully-connected classifier with them.


In the second aproach I freeze all layers of my convolutional base, so I do not train it at all, and then on top of that I put my fully-connected classifier which gets the outputs from the convolutional base.

But the first approach never gets better than 48-51% accuracy on my test set, whereas the second approach reaches around 75%. To me this makes little sense because I would expect both approaches to be the same.

For the record, the fully-connected classifier I build in both cases looks like this:
Flatten layer, Densely-connected layer with ReLU activation function, Dropout with 0.5 rate, Densely-connected layer with sigmoid activation.",1,1
9,2018-5-4,2018,5,4,0,8gr9s8,Does add_variable in rnn_cell create stochastic variables?,https://www.reddit.com/r/tensorflow/comments/8gr9s8/does_add_variable_in_rnn_cell_create_stochastic/,Laurence-Lin,1525361775,"In the BasicLSTMCell document, the self.kernel use add_variable function to map input + previous hidden state into an 4*hidden size array. 

self._kernel = self.add_variable(
        _WEIGHTS_VARIABLE_NAME,
shape=[input_depth + h_depth, 4 * self._num_units])

I believe that this mapping means that the [input + previous hidden output] multiply by an weight matrix of size [input + hidden size, 4*hidden size] to create an 4*hidden size array output. 

But I can't find the add_variable function in this document, only see the calling of this function. What does this add_variable function works? Can I set the stochastic variable by myself? Or where could I find the document for this function?

Thanks! 

",0,2
10,2018-5-4,2018,5,4,1,8grkk1,Bazel: Non-zero return code '255' from command - Anyone know how to solve this?,https://www.reddit.com/r/tensorflow/comments/8grkk1/bazel_nonzero_return_code_255_from_command_anyone/,FreddyShrimp,1525364152,"Trying to get the ""continuous stream of audio"" for this thing to run \(You can find it under the part of ""Streaming Accuracy""\): [https://www.tensorflow.org/versions/master/tutorials/audio\_recognition](https://www.tensorflow.org/versions/master/tutorials/audio_recognition)

However, when I do so by using the suggested command: \(Yes I do have a long audio file that is documented with the words appearing at the right time as they require for this part, saved in the right folder\)

       bazel run tensorflow/examples/speech_commands:test_streaming_accuracy -- \     --graph=/tmp/my_frozen_graph.pb \     --labels=/tmp/speech_commands_train/conv_labels.txt \     --wav=/tmp/speech_commands_train/streaming_test.wav \     --ground_truth=/tmp/speech_commands_train/streaming_test_labels.txt \     --verbose 

I get the following error:

    ERROR: Non-zero return code '255' from command: Process exited with status 255 

I tried google, but that didn't make me much wiser...

System specs:

* Macbook Pro \- late 2011
* High Sierra 10.13.4
* Bazel Version: 0.13.0\-homebrew

Anyone knows how to tackle this problem, or has had a similar issue that they solved?",0,1
11,2018-5-4,2018,5,4,1,8grnt5,Colab: An easy way to learn and use TensorFlow,https://www.reddit.com/r/tensorflow/comments/8grnt5/colab_an_easy_way_to_learn_and_use_tensorflow/,dayanruben,1525364867,,2,20
12,2018-5-4,2018,5,4,2,8gs62j,Is there any mistake in this part of the document in the MultiRNNCell?,https://www.reddit.com/r/tensorflow/comments/8gs62j/is_there_any_mistake_in_this_part_of_the_document/,Laurence-Lin,1525368834,"In the MultiRNNCell document, the call() function receive the input, and output 2 tensors: cur_input and new_state. However, to update the cur_input and new_state, it uses the 'cell' object:

for i, cell in enumerate(self._cells):
      with vs.variable_scope(""cell_%d"" % i):
        if self._state_is_tuple:
          if not nest.is_sequence(state):
            raise ValueError(
                ""Expected state to be a tuple of length %d, but received: %s"" %
                (len(self.state_size), state))
          cur_state = state[i]
        else:
          cur_state = array_ops.slice(state, [0, cur_state_pos],
                                      [-1, cell.state_size])
          cur_state_pos += cell.state_size
        cur_inp, new_state = cell(cur_inp, cur_state)
new_states.append(new_state)

This line 

cur_inp, new_state = cell(cur_inp, cur_state)

I don't see why we input [input, state] to an 'cell' object. I bet this should rather be 'call'?

Does anyone know about this?

Thanks a lot!",0,2
13,2018-5-4,2018,5,4,12,8gwdm3,What variables does global_variables_initializer() do the initialization?,https://www.reddit.com/r/tensorflow/comments/8gwdm3/what_variables_does_global_variables_initializer/,Laurence-Lin,1525405738,"

In tensorflow, after I use cell.zero_state() to initialize the cell state and hidden state, I should initialize the global variables or the RNN cell won't run.

However, I wonder how does it globalize(initialize variables range?) and what variables does it globalize(bias? weight? activation function?) ?

https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/ops/variables.py

I think the parameters that should initialize is non other than: weight, bias, activation function in each neuron.

What does the global_variables_initializer actually do?

Thanks a lot!
",1,2
14,2018-5-4,2018,5,4,22,8gzdo5,Should I initialize the variables by myself or just initialize by global_variable_initialize()?,https://www.reddit.com/r/tensorflow/comments/8gzdo5/should_i_initialize_the_variables_by_myself_or/,Laurence-Lin,1525441782,"I'm doing an time series forecasting work, while using the RNNCell in tensorflow it's not like I write the initialize variables by myself, instead it often use the function global_variable_initialize() to do this work. 

It feels strange to just call a function and initialize all the variables for me. I've heard that global_variable_initialize() retrieve a list of variables that contains: [all the weights, all the biases, all the hidden state], but it's like a black box for not knowing the variable range, and I don't use a bias when write the network by myself. 

For the tensorflow users, do you prefer to initialize variable by yourself(such as using tf.Variable)? Is there any problem or disadvantage for just call global_variable_initialize()?

Hope to know everyone's opinion, thanks!",1,2
15,2018-5-5,2018,5,5,12,8h4s8i,"Are you interested in AI and want to start learning more with Tutorials? Check out this new Subreddit, called AI Tutorials. :)",https://www.reddit.com/r/tensorflow/comments/8h4s8i/are_you_interested_in_ai_and_want_to_start/,DiscoverAI,1525489448,,0,10
16,2018-5-5,2018,5,5,13,8h59z6,Color to Greyscale conversion using a simple NN model,https://www.reddit.com/r/tensorflow/comments/8h59z6/color_to_greyscale_conversion_using_a_simple_nn/,banguru,1525495213,"So I was trying out this problem to build a model which converts RGB color values to greyscale values with tensorflow using a NN.

The architecture consists of a an input node with (?,1,3) tensor as input for a RGB values and (?,1,3) output as grey values and two hidden units with 10 nodes each ( I know I could have just used (?,1,1) shape as output tensor and use the output as RGB in greyscale image, but wanted all the values outputted from NN itself.

I trained a with RGB values and corresponding grey values from a single image with steps of around 10000 with all the pixels used as a batch.

But greyscale conversion result for a sample image turned out be very poor , sometimes it came as greenish , sometimes just pinkish etc.

I am clueless why this is happening.

Here is a snippet of the code I used.  


    import tensorflow as tf
    import cv2 as cv
    import numpy as np
    import os      
    
    MINI_BATCH = 10
    EPOCHS = 1
    STEPS = 100
    
    color = cv.imread('butterfly.jpg',cv.IMREAD_UNCHANGED)
    grey = cv.imread('butterfly.jpg',cv.IMREAD_GRAYSCALE)
    
    x = tf.placeholder(tf.float32,shape=(None,1,3))
    y = tf.placeholder(tf.float32,shape=(None,1,3))
    
    '''Define Linear Model'''
    linear_model = tf.layers.Dense(units=10)
    lm3 = tf.layers.Dense(units=10)
    lm2 = tf.layers.Dense(units=3)
    y_pred = lm2(lm3(linear_model(x)))
    
    loss = tf.losses.mean_squared_error(predictions = y_pred,labels = y)
    optimizer = tf.train.GradientDescentOptimizer(0.0001)
    train = optimizer.minimize(loss)
    
    greymerged = cv.merge([grey,grey,grey])
    
    
    colorlist = []
    greylist = []
    
    for i in range(color.shape[0]):
        for j in range(color.shape[1]):
            #print('Appending {} to colorlist'.format(np.reshape((color[i,j,:]/255.0)-0.5,(1,3))))
            colorlist.append(np.reshape((color[i,j,:]/255.0)-0.5,(1,3)))
            greylist.append(np.reshape((greymerged[i,j,:]/255.0)-0.5,(1,3)))
    
    init = tf.global_variables_initializer()
    
    sess = tf.Session()
    sess.run(init)
    
    for i in range(EPOCHS):
        colormd = np.stack(colorlist,axis=0)
        greymd = np.stack(greylist,axis=0)
    
        for k in range(STEPS):
            _,loss_value = sess.run((train,loss),feed_dict={x : colormd,y : greymd})
    
            if(k % 100 == 0):
                print(loss_value)
    
    planecolor = cv.imread('Animal.jpg',cv.IMREAD_UNCHANGED)
    
    planecolorlist = []
    
    for i in range(planecolor.shape[0]):
        for j in range(planecolor.shape[1]):
            planecolorlist.append(np.reshape(planecolor[i,j,:]/255.0,(1,3)))
    
    planecolormd = np.stack(planecolorlist,axis=0)  
    
    planegrey = sess.run(y_pred,feed_dict={x : planecolormd,y : planecolormd})
    
    planegreyinshape = np.reshape(planegrey,(planecolor.shape[0],planecolor.shape[1],3))
    planegreyinshape = np.multiply(planegreyinshape+0.5 ,255)
    planegreyinshape = planegreyinshape.astype(int)
    
    cv.imwrite(""Planegrey.jpg"",planegreyinshape)",2,0
17,2018-5-5,2018,5,5,14,8h5ify,"Image Annotation Tool for Object Detection, with support to create tfRecords!",https://www.reddit.com/r/tensorflow/comments/8h5ify/image_annotation_tool_for_object_detection_with/,redditgol,1525498184,"Image Annotation Tool for Object Detection, with support to create tfRecords!",0,5
18,2018-5-6,2018,5,6,6,8hahvw,This function is hilarious -&gt; tf.cumsum,https://www.reddit.com/r/tensorflow/comments/8hahvw/this_function_is_hilarious_tfcumsum/,gregmcclement,1525555151,"We should call the result of a cumulative sum, the jizz.",6,0
19,2018-5-7,2018,5,7,18,8hm8jy,Tensorflow for Beginners at Udemy,https://www.reddit.com/r/tensorflow/comments/8hm8jy/tensorflow_for_beginners_at_udemy/,shwetaed,1525685535,,0,1
20,2018-5-7,2018,5,7,19,8hmglr,Introduction for building Machine learning models using Tensorflow,https://www.reddit.com/r/tensorflow/comments/8hmglr/introduction_for_building_machine_learning_models/,hackintoshrao,1525688631,,0,18
21,2018-5-8,2018,5,8,0,8ho77e,test,https://www.reddit.com/r/tensorflow/comments/8ho77e/test/,tonytwotoe,1525705756,,0,0
22,2018-5-8,2018,5,8,3,8hpvgx,Antibody 1JGV CDR-H3 Loop modelling with Tensorflow Neural Net,https://www.reddit.com/r/tensorflow/comments/8hpvgx/antibody_1jgv_cdrh3_loop_modelling_with/,onidaito,1525718762,,0,7
23,2018-5-8,2018,5,8,10,8hsru8,nn.raw_rnn issue,https://www.reddit.com/r/tensorflow/comments/8hsru8/nnraw_rnn_issue/,itelnov,1525742136,How to define changeable batch_size over iteration using in raw_rnn  ?,0,2
24,2018-5-8,2018,5,8,22,8hwntf,Tensorflow on Ubuntu 18.04 with AMD GPU - tips ?,https://www.reddit.com/r/tensorflow/comments/8hwntf/tensorflow_on_ubuntu_1804_with_amd_gpu_tips/,ferlix90,1525785989,"i am trying to test ubuntu 18.04 with the latest build of Tensorflow.

i got it working on the CPU and now i am trying with on GPU ( i have an AMD Vega 64 ).

I was wondering if anyone manage to get everything working, and wanted to share some tips !

Thanks  !!!",13,4
25,2018-5-9,2018,5,9,5,8i0665,A Guide to TensorFlow Talks at Spark + AI Summit 2018,https://www.reddit.com/r/tensorflow/comments/8i0665/a_guide_to_tensorflow_talks_at_spark_ai_summit/,dmatrixjsd,1525812475,,0,1
26,2018-5-9,2018,5,9,9,8i1qtq,TF gpu warnings when running Session(). Should I be worried about any of these?,https://www.reddit.com/r/tensorflow/comments/8i1qtq/tf_gpu_warnings_when_running_session_should_i_be/,ME_PhD,1525825694,"Just installed the GPU version on my laptop (Dell XPS 15). I ran the 'hello world' test and upon `sess = tf.Session()` this comes up:

    Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2

then this weird one:

    Adding visible gpu devices: 0
2018-05-08 16:49:13.808848: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:

Are any of these problems I should be worried about? ",2,1
27,2018-5-9,2018,5,9,12,8i2thc,Single-class recognition: how it should be done?,https://www.reddit.com/r/tensorflow/comments/8i2thc/singleclass_recognition_how_it_should_be_done/,thevbob,1525835755,"Hello! 

I am trying to use TensorFlow to recognize my college's logo. We have build our own dataset with about 250 images of the logo in students uniforms.

The images are 500x500 pixels, and have the logo centered in it.

* I've selected about 10% of the images for evaluation and the rest for training.
* I've build the records, everything went all right.

I may have screwd up on configuration: I just selected ssd_mobile_v2_cocos.config and configured it prebuilt checkpoints. This is my first ANN and I dont have a single clue of what does this mean.

I decresead its batch_size from 36 to 12 since my GeForce 750Ti was running out of VRAM.

Now, after 50.000 iterations, I went on to test it: on TensorBoard Images, everything was beautiful, but on a real image, with a couple people and some logos, it marks everything as a logo!

What had I done wrong? Is it a too small dataset? Are the configurations wrong for this purpose? Is it a Feature Recognition problem in my Computer Vision script?

If someone can help me, please do so! I'll be very glad. 
",12,3
28,2018-5-9,2018,5,9,15,8i3u2h,Xavier initialization tf.get_variable(),https://www.reddit.com/r/tensorflow/comments/8i3u2h/xavier_initialization_tfget_variable/,ME_PhD,1525847459,"From docs: 

    This variable will, by default, have the dtype tf.float32 and its initial value will be randomized via tf.glorot_uniform_initializer.

How does it know the activation I'm going to use? The initialization parameters depend on the type of activation function.",3,1
29,2018-5-10,2018,5,10,1,8i79dr,"I am writing my own Estimator API, do you like it?",https://www.reddit.com/r/tensorflow/comments/8i79dr/i_am_writing_my_own_estimator_api_do_you_like_it/,FrancescoSZ,1525882694,"Hello guys,

Due to the fact that most of the time I end up write the same train loop and the same logic when I train my models and because the TensorFlow Estimator reload the graph everytime you evaluate it making impossible to do cross-validation or to just evaluate multiple times I decide to build my own. It is something like this. What do you think?

&lt;blockquote class=""imgur-embed-pub"" lang=""en"" data-id=""a/Rlri4ZX""&gt;&lt;a href=""//imgur.com/Rlri4ZX""&gt;&lt;/a&gt;&lt;/blockquote&gt;&lt;script async src=""//s.imgur.com/min/embed.js"" charset=""utf-8""&gt;&lt;/script&gt;",2,4
30,2018-5-10,2018,5,10,21,8iel52,TensorFlow Performance Profiling with StackImpact,https://www.reddit.com/r/tensorflow/comments/8iel52/tensorflow_performance_profiling_with_stackimpact/,l0g1cs,1525956294,,0,1
31,2018-5-11,2018,5,11,5,8ihv30,How to check if optimizer.compute_gradients operation has been executed in tensorflow graph?,https://www.reddit.com/r/tensorflow/comments/8ihv30/how_to_check_if_optimizercompute_gradients/,nitred,1525983050,I posted a stackoverflow question [here](https://stackoverflow.com/questions/50280724/how-to-check-if-compute-gradients-operation-has-been-executed-in-tensorflow-gr). Do let me know if you need more details?,0,2
32,2018-5-11,2018,5,11,6,8iihcm,Managing Data and Intermediate Outputs,https://www.reddit.com/r/tensorflow/comments/8iihcm/managing_data_and_intermediate_outputs/,Tally914,1525988000,"Hi all, so I have some questions I've been having trouble finding answers to. Hopefully someone here can lend me a hand!

1. Is there a way to feed data from a generator into feature columns and then a dataset? I am having some trouble figuring out how to use feature columns with data that can not fit entirely in memory (specifically coming from sql). 

2. Is there a way to get the outputs of intermediate layers from a Dnn estimator (regressor or classifier)? 

3. Is there a way to feed feature columns into a keras model? 

If anyone could help me out or link me some good resources on these I would really appreciate it. I am having trouble finding what I need in the documentation or through Google.",3,2
33,2018-5-11,2018,5,11,8,8ij4h9,Announcing Kubeflow 0.1,https://www.reddit.com/r/tensorflow/comments/8ij4h9/announcing_kubeflow_01/,idvoretskyi,1525993526,,0,5
34,2018-5-11,2018,5,11,21,8in6ok,Restoring a saved model with the golang bindings,https://www.reddit.com/r/tensorflow/comments/8in6ok/restoring_a_saved_model_with_the_golang_bindings/,Mikkelisk,1526040137,"I made a small GAN in python tensorflow and used tf.saved_model to persist the model. When I'm trying to load the model using the golang bindings, I get invalid graphdef when importing the model.
They're using the same version of tensorflow (1.8) and I'm kind of stuck on debugging beyond that. I have no idea what exactly is wrong other than it being wrong. Is there any way I can get a more thorough error log?",0,1
35,2018-5-12,2018,5,12,1,8ip9bv,Help in freezing graph,https://www.reddit.com/r/tensorflow/comments/8ip9bv/help_in_freezing_graph/,jrizzoli,1526057447,"I've created a model that given 2 integers as input it'd return a float output using tensorflow's `estimator.DNNRegressor` (here's how I generated it https://hastebin.com/ihoduleket.py )

The model is working fine, the predictions generated with the .predict function are correct, and now I wanted to freeze it in order to convert it into a tensorflow lite model for usage using the android apis.

The issue I've ran into is that I'm unable to successfully freeze it using the freeze_graph tool compiled with bazel as it gives me the following output: https://hastebin.com/hodoyapita.sql .

There are some other reports of people running into this on SO, but no one got any useful answer, do any of you have any idea?

",0,2
36,2018-5-12,2018,5,12,6,8irim5,Tensorboard launcher from file explorer,https://www.reddit.com/r/tensorflow/comments/8irim5/tensorboard_launcher_from_file_explorer/,lcswillems,1526075236,,1,3
37,2018-5-13,2018,5,13,12,8j1ckk,Alternatives to Softmax for prediction,https://www.reddit.com/r/tensorflow/comments/8j1ckk/alternatives_to_softmax_for_prediction/,sarasotadude,1526183132,"Hi,

I'm working on a CNN image classifier and am looking for alternative methods in place of predictions = tf.nn.softmax\(logits\) for making predictions \- all ideas and thoughts appreciated!

Are there any alternatives that accept logits in the manner the softmax does? I'm trying to make a comparison of multiple functions used for prediction.",5,3
38,2018-5-13,2018,5,13,15,8j22ne,High level approach to my image processing project?,https://www.reddit.com/r/tensorflow/comments/8j22ne/high_level_approach_to_my_image_processing_project/,Bresoo,1526192704,"Hi I a complete newbie to TensorFlow and OpenCV, and was hoping someone could provide some high level advice on my image problem that Im trying to solve. Im looking to engage a developer to build this for me but wanted to know the high level solution to my problem.My problem: 1 have one reference image of the room called my 'reference image'. This is taken from a fixed camera, at a particular angle, zoom and tilt.From the same camera and setup, I have 50 other images that are taken over different times of the day. We will call these 'live images. From these images, there will be some natural variation from the reference image. ie. some aspects of the image will be the same as the reference image, like the fixed walls and floor, but other aspect will be different, this could be different lighting and or people and /or objects in the room that werent in the reference image.I want some AI software to compare my live images to my reference image to confirm that each image is taken with the same camera setup, and to allow for the natural variation mentioned above for the live images. The software needs to pass the image if deemed to be the same, or fail if deemed not to be.A passed"" image is:

* Taken from the same camera and was pointing at the same angle, zoom and tilt as the reference image. A 5\-10&amp;#37; variance is acceptable from the reference image.
* it was of the same room, even with the natural variation of the image mentioned above.

A ""failed image could be any of the following:

* its an image of the same room, but the camera angle, tilt or zoom is different to the reference image.
* The image is blurred
* The image is a different room
* The image is not an image of a room at all, eg it is completely black or completely white.

Can someone confirm the way to go about building this with TensorFlow and OpenCV?Thanks",2,6
39,2018-5-14,2018,5,14,22,8jcfur,MNIST Variant failing: help requested,https://www.reddit.com/r/tensorflow/comments/8jcfur/mnist_variant_failing_help_requested/,SlothyJoe,1526306296,"Hello there! So I use to fiddle around here or there with ML and only ever really on examples. But after coming back to it for like the 5th time, I figure I should make my own and fully understand it. I'm starting with just an off shoot of the MNIST with Sign language images instead of numbers. The dimensions are 100x100 and in the directory in the code. I'll post the error I get as a comment aftewards so that I don't take up too much space:
import tensorflow as tf
import os
import cv2
import numpy as np
import glob
import itertools
from matplotlib import pyplot as plt
from PIL import Image
import warnings
warnings.filterwarnings('ignore')

Dataset= tf.data.Dataset
Iterator= tf.data.Iterator

data_directory=""/notebooks/SLMNIST/Dataset/*/*.JPG""
data=glob.glob(data_directory)
length=int(len(data)*.8)
lbls=[]
imgs=[]
temp=[]
for str in data:
    lbls.append(int(str.split(""/"")[4]))
    imgs.append(cv2.imread(str,0).flatten())

train_data=np.array(imgs[:length], dtype=np.float32)
train_labels=np.array(lbls[:length], dtype=np.int32)
val_data=np.array(imgs[length:], dtype=np.float32)
val_labels=np.array(lbls[length:], dtype=np.int32)

def cnn_model_fn(features, labels, mode):
    """"""Model function for CNN.""""""
    # Input Layer
    input_layer = tf.reshape(features[""x""], [-1, 100, 100, 1])

    # Convolutional Layer #1
    conv1 = tf.layers.conv2d(
        inputs=input_layer,
        filters=32,
        kernel_size=[5, 5],
        padding=""same"",
        activation=tf.nn.relu)

    # Pooling Layer #1
    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)
    
    # Convolutional Layer #2 and Pooling Layer #2
    conv2 = tf.layers.conv2d(
        inputs=pool1,
        filters=64,
        kernel_size=[5, 5],
        padding=""same"",
        activation=tf.nn.relu)
    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)

    # Dense Layer
    pool2_flat = tf.reshape(pool2, [-1, 10 * 10 * 64])
    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)
    dropout = tf.layers.dropout(
      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)

    # Logits Layer
    logits = tf.layers.dense(inputs=dropout, units=10)

    predictions = {
        # Generate predictions (for PREDICT and EVAL mode)
        ""classes"": tf.argmax(input=logits, axis=1),
        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the
        # `logging_hook`.
        ""probabilities"": tf.nn.softmax(logits, name=""softmax_tensor"")
    }

    if mode == tf.estimator.ModeKeys.PREDICT:
        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)

    # Calculate Loss (for both TRAIN and EVAL modes)
    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)

    # Configure the Training Op (for TRAIN mode)
    if mode == tf.estimator.ModeKeys.TRAIN:
        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)
        train_op = optimizer.minimize(
            loss=loss,
        global_step=tf.train.get_global_step())
    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)

    # Add evaluation metrics (for EVAL mode)
    eval_metric_ops = {
        ""accuracy"": tf.metrics.accuracy(
            labels=labels, predictions=predictions[""classes""])}
    
    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)

mnist_classifier = tf.estimator.Estimator(
    model_fn=cnn_model_fn, model_dir=""/tmp/slmnist_convnet_model"")    

# Set up logging for predictions
tensors_to_log = {""probabilities"": ""softmax_tensor""}
logging_hook = tf.train.LoggingTensorHook(
    tensors=tensors_to_log, every_n_iter=50)

print(train_data.shape)
print(train_labels.shape)
print(len(train_labels))

# Train the model
train_input_fn = tf.estimator.inputs.numpy_input_fn(
    x={""x"": train_data},
    y=train_labels,
    batch_size=100,
    num_epochs=None,
    shuffle=True)
x={""x"":train_data}
print(x)
print(train_labels.shape)

mnist_classifier.train(
    input_fn=train_input_fn,
    steps=20000,
    hooks=[logging_hook])    ",1,1
40,2018-5-15,2018,5,15,0,8jd3q1,unsupervised clustering of short text based on similarity - which model do you recommend me?,https://www.reddit.com/r/tensorflow/comments/8jd3q1/unsupervised_clustering_of_short_text_based_on/,juice_456,1526311324,"Hi guys

Im very new in deeplearning and have a problem..

i have a dataset of one milion rows with short text and i want to cluster them based on their similarity

my question is now which model do you recommend me to do that or a better question is if it is even possible to do that?

would really appreciate if you could give me some advise/personal experience...",4,5
41,2018-5-15,2018,5,15,5,8jfr30,"webinar= May 21, Ryan Sepassi, Sr Research Eng. at Google Brain. Topic: ""ML with Google Brains Tensor2Tensor.""",https://www.reddit.com/r/tensorflow/comments/8jfr30/webinar_may_21_ryan_sepassi_sr_research_eng_at/,AI_underscore,1526330958,[removed],0,1
42,2018-5-16,2018,5,16,2,8jnbf7,Complete Guide to Build ConvNet HTTP-Based Application using TensorFlow and Flask RESTful Python API,https://www.reddit.com/r/tensorflow/comments/8jnbf7/complete_guide_to_build_convnet_httpbased/,AhmedGadFCIT,1526404559,,0,1
43,2018-5-16,2018,5,16,7,8jpthd,Hey Im a Student at UC Irvine and I was wondering if you could help me collect data on the current state of Tensorflow tutorials (No experience with Tensorflow necessary),https://www.reddit.com/r/tensorflow/comments/8jpthd/hey_im_a_student_at_uc_irvine_and_i_was_wondering/,Tensorflow_Study,1526423480,"If you wouldn't mind filling out the form form below, its a anonymous survey that takes around 5\-10 minutes to complete.

[https://goo.gl/forms/mGPht06XQaP6z1kE2](https://goo.gl/forms/mGPht06XQaP6z1kE2)

Thank you all so much and I will post again with any interesting data",3,4
44,2018-5-17,2018,5,17,2,8jwwls,Quickest way to build an h5py file from vector representations?,https://www.reddit.com/r/tensorflow/comments/8jwwls/quickest_way_to_build_an_h5py_file_from_vector/,PM_UML_DIAGRAMS,1526492535,"I want to build an hdf5 file from vector representations that looks something like {""3"":5, ""10"":1, ""20"":1} where the key is the vector number and the value what should be assigned to it.  Anything not represented is assumed to be 0.


so if my shape were (2,20) [in reality my shape is more like (2m, 100k) and my representation above was for the one in position 0, I might have something like

[ [0,0,5,...,1,...20], [&lt;some other vector&gt;]]

The problem: it's really slow.  I tried making the dataset with h5py's create dataset and then going back in and assigning things later.  I couldn't directly modify the internal arrays so have to build new numpy arrays and then assign those.

I feel like there has to be a faster way. What gives?",0,1
45,2018-5-17,2018,5,17,22,8k4661,"Deep text summarization: on amazon reviews, github issues and news articles",https://www.reddit.com/r/tensorflow/comments/8k4661/deep_text_summarization_on_amazon_reviews_github/,tttttm,1526563011,,0,13
46,2018-5-18,2018,5,18,22,8kd7f5,Tensorflow model analysis: How to run already exported model,https://www.reddit.com/r/tensorflow/comments/8kd7f5/tensorflow_model_analysis_how_to_run_already/,chang2394,1526650492,,0,1
47,2018-5-19,2018,5,19,7,8kh1et,Tensorflow.JS question Const vs Var for tensor,https://www.reddit.com/r/tensorflow/comments/8kh1et/tensorflowjs_question_const_vs_var_for_tensor/,Aeium,1526682415,"I want to use Tensorflow as a matrix library for a webpage I am developing.

It's seems pretty attractive to use, because I want to do convolution and other per-element matrix math, and if I understand correctly Tensorflow has implemented lots of those SIMD matrix operations in webGL, which would make it possible for what I am developing to work in real time. which would be great.

I am hoping somebody here can explain to me how the performance benefit of immutable tensors works, and so I can figure out if it's possible for me to do what I want using tensorflow.

Basically, what I want to do is perform convolution on the same matrix, multiple times in a loop.

I understand that tensors are immutable, meaning the convolution operation would return a new tensor instead of working in place. That is fine. 

However, the documentation also declares all the tensors as ""const"", meaning I cannot assign the new tensor to the old reference.

Does this mean I need to unroll the loop and hardcode each iteration with a new variable?

I tried simply rebelling against that convention using this code:
    var x = tf.tensor([1, 2, 3, 4])
    x.print()
    x = tf.tensor([4,3,2,1])
    x.print()

It seems to work fine. Anyway, I am hoping someone can shed some light here. Am I about to commit some mortal tensorflow sin by not using const tensors?

I want to understand why this is the convention, so I can design this properly.",1,1
48,2018-5-19,2018,5,19,19,8kkf8g,Downloading cuDNN,https://www.reddit.com/r/tensorflow/comments/8kkf8g/downloading_cudnn/,smokebig123,1526725419,"I can't get it to download , the site is so buggy I've made multiple accounts but it always sais that there is no email associated with an account.(??) Well anyway could someone tell me how to download it with an account or mabye kindly share their download assuming it isn't to big ? Ty very much!",4,2
49,2018-5-20,2018,5,20,18,8krm9a,My Tensorflow built from source is slower than the pip installation,https://www.reddit.com/r/tensorflow/comments/8krm9a/my_tensorflow_built_from_source_is_slower_than/,iwzhzbb,1526808378,"I installed TF 1.5 on Ubuntu 18.04 and got ""Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2"", so I built 1.8 from the latest source, thinking it would improve performance, or at least not make it worse. However, running mnist\_cnn.py from the Keras examples folder, the source build actually runs much slower: around 310 seconds per epoch, compared to about 250 seconds per epoch under TF 1.5.

Did I mess up the configuration for the build, or is there something else I'm missing?",2,3
50,2018-5-21,2018,5,21,1,8ktlcm,How do you use tensorflow in production ?,https://www.reddit.com/r/tensorflow/comments/8ktlcm/how_do_you_use_tensorflow_in_production/,tonystarkco,1526832951,"I am a newcomer in the field of AI/ML and Tensorflow and I have followed the usual path: Coursera, uDemy, books, Youtube in order to learn about ML. I've been working professionally in development (Ruby/Python) for 5-6 years but never got my hands dirty with ML until now. 

I am wondering how do you guys use Tensorflow in production systems that you need predictions in a small amount of time? This might not be related but, in high-demanding implementations like e.g. self-driving cars, how do they do this? I am thinking of tensorflow being included in a python service running on a server, interacting with a database and outputting some values. Is that thinking correct? 

Does it have to do with backend computations and an API to get/post data (If http) ?",5,8
51,2018-5-21,2018,5,21,6,8kvj6z,What's the point of scopes?,https://www.reddit.com/r/tensorflow/comments/8kvj6z/whats_the_point_of_scopes/,iamiamwhoami,1526850181,It seems like they work similarly to Python namespaces. Couldn't the same thing be accomplished by putting all variables into the same scope and naming them differently?,3,4
52,2018-5-22,2018,5,22,3,8l3bsh,Learning and Using Tensor Flow,https://www.reddit.com/r/tensorflow/comments/8l3bsh/learning_and_using_tensor_flow/,Life_Liberty,1526929193,"I am pretty new to Tensor Flow and Machine Learning Libraries in general. I'd like to learn how to use Tensor Flow and implement it in a project! If someone could direct me to resources and suggest some example projects (like Hot Dog/not Hot Dog), that would be really helpful.",2,1
53,2018-5-22,2018,5,22,8,8l59g0,Very poor speed/memory performance when using tf.data for text data,https://www.reddit.com/r/tensorflow/comments/8l59g0/very_poor_speedmemory_performance_when_using/,BatmantoshReturns,1526945119,"
0
down vote
favorite
I am trying to use this code

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/5_word2vec.ipynb

But use tf.data to handle all the text data.

I am running both over Google Colaboratory using the GPU runtime option.

Here's is the original relevant code

    from __future__ import print_function
    import collections
    import math
    import numpy as np
    import os
    import random
    import tensorflow as tf
    import zipfile
    from matplotlib import pylab
    from six.moves import range
    from six.moves.urllib.request import urlretrieve
    from sklearn.manifold import TSNE
    
    url = 'http://mattmahoney.net/dc/'
    
    def maybe_download(filename, expected_bytes):
      """"""Download a file if not present, and make sure it's the right size.""""""
      if not os.path.exists(filename):
        filename, _ = urlretrieve(url + filename, filename)
      statinfo = os.stat(filename)
      if statinfo.st_size == expected_bytes:
        print('Found and verified %s' % filename)
      else:
        print(statinfo.st_size)
        raise Exception(
          'Failed to verify ' + filename + '. Can you get to it with a browser?')
      return filename
    
    filename = maybe_download('text8.zip', 31344016)
    
    def read_data(filename):
      """"""Extract the first file enclosed in a zip file as a list of words""""""
      with zipfile.ZipFile(filename) as f:
        data = tf.compat.as_str(f.read(f.namelist()[0])).split()
      return data
    
    words = read_data(filename)
    print('Data size %d' % len(words))

Here is my best attempt to alter this to use tf.data to handle the text data.

    from __future__ import print_function
    import collections
    import math
    import numpy as np
    import os
    import random
    import tensorflow as tf
    import zipfile
    from matplotlib import pylab
    from six.moves import range
    from six.moves.urllib.request import urlretrieve
    from sklearn.manifold import TSNE
    
    url = 'http://mattmahoney.net/dc/'
    
    def maybe_download(filename, expected_bytes):
      """"""Download a file if not present, and make sure it's the right size.""""""
      if not os.path.exists(filename):
        filename, _ = urlretrieve(url + filename, filename)
      statinfo = os.stat(filename)
      if statinfo.st_size == expected_bytes:
        print('Found and verified %s' % filename)
      else:
        print(statinfo.st_size)
        raise Exception(
          'Failed to verify ' + filename + '. Can you get to it with a browser?')
      return filename
    
    filename = maybe_download('text8.zip', 31344016)
    
    def read_data(filename):
      """"""Extract the first file enclosed in a zip file as a list of words""""""
      with zipfile.ZipFile(filename) as f:
        data = tf.data.Dataset.from_tensor_slices( f.read(f.namelist()[0]) )
      return data
    
    datasetTest = read_data(filename)
    Basically I changed this line from the original
    
    data = tf.compat.as_str(f.read(f.namelist()[0])).split()
    to this line
    
    data = tf.data.Dataset.from_tensor_slices( f.read(f.namelist()[0]) )

The new one doesn't split the words by space like the old line, so I had another line 

#datasetTest = datasetTest.map(lambda string: tf.string_split([string]).values) 

but I commented it out to try to pin point where the bottle neck is.

The old code runs within a minute or two. The new one can never finish executing. It usually runs for 30-40 minutes before colab says it has crashed and is restarting the runtime.

Question on stackoverflow https://stackoverflow.com/questions/50457467/very-poor-speed-memory-performance-when-using-tf-data-for-text-data",0,7
54,2018-5-23,2018,5,23,12,8lgcab,I'm having trouble downgrading to tf 1.4. If someone could explain to me what I am doing wrong I would really appreciate it.,https://www.reddit.com/r/tensorflow/comments/8lgcab/im_having_trouble_downgrading_to_tf_14_if_someone/,xib1115,1527047137,"I'm working with Unity Ml-Agents and don't have a lot of ML background knowledge. I installed tf 1.8.0 with no problems but I realized I needed 1.4 specifically. I I've tried every variation with lip to install tf 1.4 but it always says ""Collecting"" and never does anything. I have tried on conda and conda always fails with a ""not in current channels"" error. Is there a read why I can't get 1.4 anymore? I haven't found anything useful on google over the past two days. ",2,2
55,2018-5-23,2018,5,23,13,8lgfxc,AttributeError: module 'tensorflow' has no attribute 'set_random_seed',https://www.reddit.com/r/tensorflow/comments/8lgfxc/attributeerror_module_tensorflow_has_no_attribute/,xib1115,1527048191,"I keep getting this error and cannot find an explanation on google. I am running what I believe to be tf 1.4 (I say believe because anaconda navigator shows 1.8 but when I tell pip to show the version it shows 1.4, this goes back to my last post about installing 1.4). The random_seed.py is in the tensorflow module and has the correct method so I'm not sure what I'm doing wrong. ",1,1
56,2018-5-23,2018,5,23,13,8lgjct,Help Us Build the Tensorflow Wiki!,https://www.reddit.com/r/tensorflow/comments/8lgjct/help_us_build_the_tensorflow_wiki/,TheNASAguy,1527049192,"If you have a background in ML or atleast have some experience in it, PM me using message the mods.",1,38
57,2018-5-23,2018,5,23,13,8lgjyp,The Official Feedback and Discussion Thread,https://www.reddit.com/r/tensorflow/comments/8lgjyp/the_official_feedback_and_discussion_thread/,TheNASAguy,1527049360,,6,3
58,2018-5-23,2018,5,23,18,8lhwsg,TensorFlow Tutorial - Explaind in Simple Words,https://www.reddit.com/r/tensorflow/comments/8lhwsg/tensorflow_tutorial_explaind_in_simple_words/,pooja307,1527066395,,0,1
59,2018-5-23,2018,5,23,18,8lhzwa,Tensorflow - Explained in Simple Words,https://www.reddit.com/r/tensorflow/comments/8lhzwa/tensorflow_explained_in_simple_words/,pooja307,1527067551,,0,3
60,2018-5-23,2018,5,23,21,8lj4q4,A Guide to TensorFlow: Logistic Regression (Part 6),https://www.reddit.com/r/tensorflow/comments/8lj4q4/a_guide_to_tensorflow_logistic_regression_part_6/,scmmishra,1527080179,,0,6
61,2018-5-24,2018,5,24,1,8lkrxv,To all game AI makers,https://www.reddit.com/r/tensorflow/comments/8lkrxv/to_all_game_ai_makers/,SlothyJoe,1527093269,"What was the best technique you did for scraping data from your game/ finding game states? Eg end, pause, dead, etc. Any help would be appreciated! From some looking around I saw that just screen scraping was one way to go, but I didn't know how efficient this would be. Using Python and Tensorflow/ Keras if that makes any difference. ",13,7
62,2018-5-24,2018,5,24,11,8lp47e,Can't get tensorflow GPU to run,https://www.reddit.com/r/tensorflow/comments/8lp47e/cant_get_tensorflow_gpu_to_run/,blaher123,1527128306,"I have a geforce 870m and Mint version rosa. I'm trying to get tensorflow with GPU support to run but I get these error messages. 

I tensorflow/core/platform/cpu\_feature\_guard.cc:137\] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA

E tensorflow/stream\_executor/cuda/cuda\_driver.cc:406\] failed call to cuInit: CUDA\_ERROR\_UNKNOWN

2018\-05\-23 19:13:58.900181: I tensorflow/stream\_executor/cuda/cuda\_diagnostics.cc:145\] kernel driver does not appear to be running on this host \(ggg\-PGGGG\-G\): /proc/driver/nvidia/version does not exist

I've tried googling this issue and it appears that for some reason TF cannot recognize my gpu. There are several different solutions some of which I've tried but so far haven't gotten it to work like installing modprobe or running nvidia\-smi which isn't even on my computer for some reason. How could I proceed to fix this? ",10,1
63,2018-5-25,2018,5,25,1,8lu4es,Use (and train) a NN in TF-C# that was created with TF-Python,https://www.reddit.com/r/tensorflow/comments/8lu4es/use_and_train_a_nn_in_tfc_that_was_created_with/,TheRedWanderer,1527180317,"Hey everyone,

I am new to machine learning and TensorFlow, and I have a question about reusing a neural network in C#, that was created with Python.

1. Is it possible to use a NN in TensorFlowSharp, that was trained with TF in python?

2. And furthermore, is it even possible to continue training a NN generated in C#, that was originally trained in python?",2,4
64,2018-5-25,2018,5,25,2,8lucpm,Why Isnt There Universal Program For Machine Learning?,https://www.reddit.com/r/tensorflow/comments/8lucpm/why_isnt_there_universal_program_for_machine/,MicrophoneGuy,1527182051,"I am having issues installing Tensorflow.  It got to a point where I grew frustrated and almost quit entirely.  Which brings up the question, why isnt there a traditional software program that you install like any other windows program for machine learning?  If you could install Tensorflow like a normal windows program that would be outstanding.  Then just load your dataset like any other file and allow it to train.  Anyone else wish there was something like this?",8,1
65,2018-5-25,2018,5,25,2,8luns7,i am trying to download the example files but somehow i cant. please any help would be appreciated.,https://www.reddit.com/r/tensorflow/comments/8luns7/i_am_trying_to_download_the_example_files_but/,frankcohe,1527184346,    curl http://download.tensorflow.org/example\_images/flower\_photos.tgz \\     | tar xz \-C    tf\_files ,0,1
66,2018-5-25,2018,5,25,3,8lurww,"FIFOQueue insufficient elements (requested 128, current size 0) issue that I've been bashing my head against for the last 24 hours :)",https://www.reddit.com/r/tensorflow/comments/8lurww/fifoqueue_insufficient_elements_requested_128/,coolhand1,1527185215,"I've been hitting this problem in different ways for the last 24 hours and I can't seem to get past it. I would be eternally grateful if someone could help, or at least point me in the right direction to help solve. 

Stackoverflow issue with history: https://stackoverflow.com/questions/50500529/tried-to-convert-n-to-a-tensor-and-failed-error-none-values-not-supported 

Code: https://pastebin.com/TvCw0rVw

Dataset: https://storage.googleapis.com/stackquestion2/201701.csv

As much as these issues cause frustration, I gotta admit that they force you to dig deep into what your working on. I've learned more about how TF queues in the last 6 hours than I ever would have ",0,0
67,2018-5-25,2018,5,25,9,8lxm04,"Hey all, I am having a huge problem when trying to load a trained model that I developed with the tf.layers API. Can anyone check out my StackOverflow post about it please?",https://www.reddit.com/r/tensorflow/comments/8lxm04/hey_all_i_am_having_a_huge_problem_when_trying_to/,Xyoloswag420blazeitX,1527208276,"Thanks so much!

I'm more familiar with the tf.nn API, but this is way easier to develop with, although it seems impossible to restore my model!

https://stackoverflow.com/questions/50519913/failedpreconditionerror-when-attempting-to-restore-model-created-in-tf-layers-ap",0,4
68,2018-5-25,2018,5,25,13,8lywdg,Tensorflow upgrade to GPU version. How to?,https://www.reddit.com/r/tensorflow/comments/8lywdg/tensorflow_upgrade_to_gpu_version_how_to/,iamagupta,1527221068,"I have a Nvidia GPU in my laptop but downloaded tensorflow cpu version. how to upgrade to the GPU version. I have tried:
    pip install --ignore-installed --upgrade tensorflow-gpu",3,1
69,2018-5-25,2018,5,25,14,8lzfc6,"I made an install guide to setup latest release TensorFlow r1.8 on Raspberry Pi 3. Now, we can enjoy implementing deep learning on our favourite Pi.",https://www.reddit.com/r/tensorflow/comments/8lzfc6/i_made_an_install_guide_to_setup_latest_release/,DecipherTechnic,1527227097,,4,25
70,2018-5-26,2018,5,26,3,8m40r5,Can I run my testing and training with different mini batch sizes when using batch_norm?,https://www.reddit.com/r/tensorflow/comments/8m40r5/can_i_run_my_testing_and_training_with_different/,Xyoloswag420blazeitX,1527273061,,1,1
71,2018-5-28,2018,5,28,2,8mjfqy,Real time object detection,https://www.reddit.com/r/tensorflow/comments/8mjfqy/real_time_object_detection/,tanzeel29,1527443610,"I am making a real time object detector as my project . I have the following doubts :
1) how many images of each item should I take to train accurately ?
2) will the model which has earlier been  trained on different objects detect those objects if I used that to train other objects ?
3) which object detector model should I use ?
",7,5
72,2018-5-28,2018,5,28,3,8mjq3o,Baselines OpenAI,https://www.reddit.com/r/tensorflow/comments/8mjq3o/baselines_openai/,guruji93,1527446099,"I am wondering if there is study on effect of using different NN architecture for RL especially games. Currently, I'm looking at OpenAI baselines implementation where they have 4 different architecture available to choose in policies.py . I am tryingto get an insight on which one works better and why. Any thoughts /and references to read?!",0,1
73,2018-5-28,2018,5,28,6,8ml0vr,"Tensorflow for Poets leads to ""the name 'import/input' refers to an operation not in the graph."" error. None of the Github issues or Stackoverflow solutions are working.",https://www.reddit.com/r/tensorflow/comments/8ml0vr/tensorflow_for_poets_leads_to_the_name/,ArkBirdFTW,1527457696,"I was working through the Tensorflow for Poets retraining tutorial but I keep getting the ""the name 'import/input' refers to an operation not in the graph."" whenever I run label_image.py I've tried setting input_layer to Mul and Placeholder and I've fiddled with the image height and width but none of the solutions have worked they simply return ""the name 'import/Mul' refers to an operation not in the graph."" or  ""The name 'import/InceptionV3/Predictions/Reshape_1' refers to an Operation not in the graph.""",2,2
74,2018-5-28,2018,5,28,11,8mmvod,"Tensorflow release 1.8 is out! Hence, I made a crisp setup guide to Install its GPU version on Windows PC",https://www.reddit.com/r/tensorflow/comments/8mmvod/tensorflow_release_18_is_out_hence_i_made_a_crisp/,DecipherTechnic,1527475948,,7,15
75,2018-5-28,2018,5,28,21,8mpq2t,tf.keras or Tensorflow session method for Deep Learning,https://www.reddit.com/r/tensorflow/comments/8mpq2t/tfkeras_or_tensorflow_session_method_for_deep/,vidit0210,1527510754,"My name is Vidit and I have keen interest in Deep Learning. I would like to build my solid foundation in Deep Learning and Tensorflow is what I feel is the powerful framework here.

Usually I used to program with place holders ,Variables and Session now after tf.keras I'm confused what is advantage of traditional methods and what should I focus on now . Please Guide me
",1,1
76,2018-5-29,2018,5,29,1,8mra14,Please Help: Text Class &amp; Boundary Detection,https://www.reddit.com/r/tensorflow/comments/8mra14/please_help_text_class_boundary_detection/,BlueBlimp,1527524534,"I have records that I am trying to extract data from. Part of that process involves classifying text. I am using this guide to help me: https://sourcedexter.com/tensorflow-text-classification-python/.

The problem with this is that a large part of the records I am dealing with includes info that is not presented in a form with clear boundaries in the presentation of information, like this:

Name: John  Doe     SSN: 123456789      Address: Blah Blah Street, California 92019   Chief Complaint: Dehydration

In other words, there are separate listings of information on the same line, but the only indication that they are separate is the label at the beginning of them which is followed by a colon (e.g., Name:) and the spaces between them (e.g., Name: John Doe      SNN: 12345).
I need the program to analyze  Name: John and SNN: 12345 separately, not as Name: John Doe      SNN: 12345. 

How can I make tensorflow handle this boundary detection problem?

I want to eventually be able to scan in texts like this

Name: John  Doe     SSN: 123456789      Address: Blah Blah Street, California 92019   Chief Complaint: Dehydration

I then want to have tensorflow classify things like this:

INPUT:
Sent_1=John  Doe     
Sent_2=SSN: 123456789
Sent_3=Chief Complaint: Dehydration

OUTPUT:
Personal info
Personal info
Patient status


",2,2
77,2018-5-29,2018,5,29,15,8mx2ae,(re)Training the model with images using TensorFlow,https://www.reddit.com/r/tensorflow/comments/8mx2ae/retraining_the_model_with_images_using_tensorflow/,makorowy,1527577084,,0,1
78,2018-5-29,2018,5,29,23,8mzi87,Need basic tensorflow tuts,https://www.reddit.com/r/tensorflow/comments/8mzi87/need_basic_tensorflow_tuts/,scythe314,1527604033,"Can anybody recommend a good tutorial(s) to learn basic tensorflow. Can't find anything good on eg. Youtube?

",6,10
79,2018-5-30,2018,5,30,1,8n09y0,Can I use external GPU with laptop for Deep Learning?,https://www.reddit.com/r/tensorflow/comments/8n09y0/can_i_use_external_gpu_with_laptop_for_deep/,DecipherTechnic,1527609981,,0,1
80,2018-5-31,2018,5,31,15,8ng46t,How to install Tensorflow GPU with CUDA 9.2 for python on Ubuntu,https://www.reddit.com/r/tensorflow/comments/8ng46t/how_to_install_tensorflow_gpu_with_cuda_92_for/,Aryal007,1527747194,,2,14
81,2018-5-31,2018,5,31,20,8nhrah,TensorFlow 1.8 with CUDA 9.2 and cuDNN 7.1.4 performs up to 37% faster when compared to earlier versions of Tensorflow. Full results:,https://www.reddit.com/r/tensorflow/comments/8nhrah/tensorflow_18_with_cuda_92_and_cudnn_714_performs/,Aryal007,1527767237,,2,33
0,2018-6-4,2018,6,4,0,8o9ad5,"When defining a graph in Tensorflow, is there a way to run a line of code only when a session is running?",https://www.reddit.com/r/tensorflow/comments/8o9ad5/when_defining_a_graph_in_tensorflow_is_there_a/,BatmantoshReturns,1528040277,"When defining a graph, at times it may be convenient to only run certain lines when a session is being run, particularly for debugging. For example, take the following graph defined below:

    with graph.as_default(): #took out "" , tf.device('/cpu:0')""
    
      # Input data.
      train_dataset = tf.placeholder(tf.int32, shape=[batch_size])
      train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])
      valid_dataset = tf.constant(valid_examples, dtype=tf.int32)
      
      # Variables.
      embeddings = tf.Variable(
        tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))
      softmax_weights = tf.Variable(
        tf.truncated_normal([vocabulary_size, embedding_size],
                             stddev=1.0 / math.sqrt(embedding_size)))
      softmax_biases = tf.Variable(tf.zeros([vocabulary_size]))
      
      # Model.
      embed = tf.nn.embedding_lookup(embeddings, train_dataset) #train data set is
      loss = tf.reduce_mean(
        tf.nn.sampled_softmax_loss(weights=softmax_weights, biases=softmax_biases, inputs=embed,labels=train_labels, num_sampled=num_sampled, num_classes=vocabulary_size))

      # See docs on `tf.train.Optimizer.minimize()` for more details.
      optimizer = tf.train.AdagradOptimizer(1.0).minimize(loss)
      norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keepdims=True))
      normalized_embeddings = embeddings / norm
      valid_embeddings = tf.nn.embedding_lookup(
        normalized_embeddings, valid_dataset)
      similarity = tf.matmul(valid_embeddings, tf.transpose(normalized_embeddings))

I might want to print out the variable `embed` , or , create a new variable from the placeholders and print those. But, if I put a print statement for those, the code will give me an error because we have not passed any data yet to the placeholders. 

So, is there a way to only evaluate a line inside a graph only when a session is being run? Or perhaps until data is passed to the placeholders (if there is a way to some how do that without running a session)",1,3
1,2018-6-4,2018,6,4,2,8oaava,How do I only record some value every n steps in TensorBoard?,https://www.reddit.com/r/tensorflow/comments/8oaava/how_do_i_only_record_some_value_every_n_steps_in/,PKJY,1528048416,I'm recording multiple scalars in tensorboard. I want to record the loss every step \(I already got that\). But now I also want to record the accuracy and histograms of weights and biases but if I do that every step it really slows down training. How would I record those just ever 500th step for example?,5,3
2,2018-6-4,2018,6,4,6,8obt5l,"Hey r/tensorflow Im an undergraduate at UCI conducting a survey about how people learn ML, I was wondering if you could take some time to fill out my 10 question survey. Thank you all.",https://www.reddit.com/r/tensorflow/comments/8obt5l/hey_rtensorflow_im_an_undergraduate_at_uci/,Tensorflow_Study,1528060854,,0,0
3,2018-6-4,2018,6,4,9,8od9q2,Tensorflow Estimators :: Pre-Made Estimators,https://www.reddit.com/r/tensorflow/comments/8od9q2/tensorflow_estimators_premade_estimators/,machinelearning147,1528073998,,0,6
4,2018-6-5,2018,6,5,6,8okwb0,Learn TensorFlow from worldwideweb data?,https://www.reddit.com/r/tensorflow/comments/8okwb0/learn_tensorflow_from_worldwideweb_data/,drf0rd,1528146053,Im totally new to this - however is there a way to learn TensorFlow data from the worldwideweb? I have seen a lot of tutorials for image recognization but thats not what Im looking for. I hope I will find my answers. ,15,0
5,2018-6-5,2018,6,5,22,8oqr35,TensorFlow on Spark 2.3: The Best of Both Worlds,https://www.reddit.com/r/tensorflow/comments/8oqr35/tensorflow_on_spark_23_the_best_of_both_worlds/,dworms,1528204953,,0,13
6,2018-6-8,2018,6,8,12,8pgnam,How to compute loss for a classification task such as age-estimation where prediction of age 13 is better than age 100 for someone who is age 12?,https://www.reddit.com/r/tensorflow/comments/8pgnam/how_to_compute_loss_for_a_classification_task/,nitred,1528428458,"It is easy to realize that posing the age-estimation task as a naive classification task is not the best possible approach. This is because a naive classification task would treat age 12 being equally different from age 13 and age 99. Where as in reality a prediction of age 13 would be much better than a prediction of age 99 for someone who is age 12.

In the paper [Apparent Age Estimation ... 2016](https://cactus.orange-labs.fr/apparent-age-estimation/paper/Antipov_Apparent_Age_Estimation_CVPR_2016_paper.pdf) section 2.3, they mention **label distributed encoding** where the classifier is provided the information that predicting closer label values is better than farther values. The paper [Deep Label Distribution Learning ... 2016](https://arxiv.org/pdf/1611.01731.pdf) discusses this topic in particular.

Does anyone know how to implement this in tensorflow? Any help would be appreaciated!",15,3
7,2018-6-9,2018,6,9,3,8pmaqd,What is a tensor in tensorflow?,https://www.reddit.com/r/tensorflow/comments/8pmaqd/what_is_a_tensor_in_tensorflow/,amitarora5423,1528482431,,4,2
8,2018-6-9,2018,6,9,5,8pncfv,How to create a simple autoencoder on TensosrFlow js,https://www.reddit.com/r/tensorflow/comments/8pncfv/how_to_create_a_simple_autoencoder_on_tensosrflow/,MarcoEstevez,1528490165,"Hi community, I saw many good examples out there that explains autoencoders on TF (pyton) or Keras, but I did not figure out how to made this thing on javascript. Can anyone point me out on the right direction.

Here it is an example for MNST in keras,

model parameters;

    input_img = Input(shape=(784,))
    encoded = Dense(128, activation='relu')(input_img)
    encoded = Dense(64, activation='relu')(encoded)
    encoded = Dense(32, activation='relu')(encoded)
    
    decoded = Dense(64, activation='relu')(encoded)
    decoded = Dense(128, activation='relu')(decoded)
    decoded = Dense(784, activation='sigmoid')(decoded)

model creation

    autoencoder = Model(input_img, decoded)
    autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
    
    autoencoder.fit(x_train, x_train,
                    epochs=100,
                    batch_size=256,
                    shuffle=True,
                    validation_data=(x_test, x_test))

So far, I could translate easily to javascript almost all except this sentence

     autoencoder = Model(input_img, decoded)",0,2
9,2018-6-9,2018,6,9,5,8pngv9,Will TensorFlow version 2.0 contain significant changes.,https://www.reddit.com/r/tensorflow/comments/8pngv9/will_tensorflow_version_20_contain_significant/,Shaken_Earth,1528491089,"I see that TensorFlow 1.9 was released today which means the next sub-release will be either labeled 1.10 or 2.0.

Are there any rumors of what 2.0 will bring to the table? Are the changes rumored to be significant in any way?",5,14
10,2018-6-10,2018,6,10,1,8ptvi2,TensorFlow Custom Estimators,https://www.reddit.com/r/tensorflow/comments/8ptvi2/tensorflow_custom_estimators/,machinelearning147,1528561216,,1,7
11,2018-6-10,2018,6,10,2,8pukc4,Categorizing the Time Series itself,https://www.reddit.com/r/tensorflow/comments/8pukc4/categorizing_the_time_series_itself/,Aesix,1528567056,"Hello fan of ze maths. I suppose I have a philosophical question as much as it might be about the code itself. If I split a time series into three phases, say ""Before Exam, During Exam, After Exam"" by making them binary categorical (one\-hot) features (data stays in chronological order but now has \[1\] in the Pre column, \[0\] in Before and During columns as well as main the time sequence itself) for say, an lstm passthrough, am I producing 3 separate models that are then stitched together by the time it's all over? Am I extracting features in a useful way? What's the benefit?",2,1
12,2018-6-10,2018,6,10,10,8pxl2s,Splitting Batched Dataset Elements,https://www.reddit.com/r/tensorflow/comments/8pxl2s/splitting_batched_dataset_elements/,franklywang,1528594497,"Hey everyone,

I'm working with a collection of TFRecords. Each TF records is a encoded (1000, 128, 128, 10) numpy array which represents a 1000 element sampling of 128x128x10 grids of a large 10-channel image.

To load this data I'm doing the following:

ds = tf.data.TFRecordDataset(file_paths)
ds = ds.map(decode)
iterator = ds.make_initializable_iterator()
pipe_exit = iterator.get_next()

The problem here is each element of the dataset set has a batch size of 1000. I'd like to have the ability to control my batch size and to shuffle the samples from different files.

Is there any way for me to map each (1000, 128, 128, 10) element into 1000 separate (128, 128 ,10) elements in the Dataset queue?",0,1
13,2018-6-10,2018,6,10,23,8q1574,Using ssd_random_crop_pad operation in Tensorflow's Object Detection API,https://www.reddit.com/r/tensorflow/comments/8q1574/using_ssd_random_crop_pad_operation_in/,jashshah27,1528641024,"I am using Tensorflow's Object Detection API to train an Inception SSD object detection model on Cloud ML Engine and I want to use the various `data_augmentation_options` as mentioned in the [preprocessor.proto file](https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto).

The one that I am currently interested in using is `ssd_random_crop_pad` operation and changing the `min_padded_size_ratio` and the `max_padded_size_ratio`.

The documentation mentioned in preprocessor.proto says the following:

```
// Min ratio of padded image height and width to the input image's height and
  // width. Two entries per operation.
  repeated float min_padded_size_ratio = 8;

  // Max ratio of padded image height and width to the input image's height and
  // width. Two entries per operation.
repeated float max_padded_size_ratio = 9;

```
However when I supply these arguments in the config file in the format given below:

```
data_augmentation_options {
    ssd_random_crop_pad {
      operations {
        min_padded_size_ratio: (16.0, 16.0)
        max_padded_size_ratio: (16.0, 16.0)
        random_coef: 0.5
      }
    }
  }
```
I run into an error.

Can the good people of reddit please help me with the format to pass the arguments to `min_padded_size_ratio` and `max_padded_size_ratio`? 

Attaching the link to the question on [stackoverflow](https://stackoverflow.com/questions/50781103/using-ssd-random-crop-pad-operation-in-tensorflows-object-detection-api).",2,1
14,2018-6-11,2018,6,11,2,8q2azg,Sequence classification and labelling for protein loops,https://www.reddit.com/r/tensorflow/comments/8q2azg/sequence_classification_and_labelling_for_protein/,onidaito,1528651472,,0,1
15,2018-6-11,2018,6,11,16,8q7lfa,Free PDF eBook: TensorFlow Machine Learning Cookbook,https://www.reddit.com/r/tensorflow/comments/8q7lfa/free_pdf_ebook_tensorflow_machine_learning/,PacktStaff,1528701398,,0,5
16,2018-6-12,2018,6,12,0,8qankb,How to Use TensorBoard?,https://www.reddit.com/r/tensorflow/comments/8qankb/how_to_use_tensorboard/,kiarash-irandoust,1528732666,,0,3
17,2018-6-12,2018,6,12,2,8qb57b,Speech Recognition with TensorFlow,https://www.reddit.com/r/tensorflow/comments/8qb57b/speech_recognition_with_tensorflow/,tttttm,1528737420,,0,9
18,2018-6-12,2018,6,12,6,8qdap1,Help with Tensorflow error: Problem in applying an existing fix through git commit.,https://www.reddit.com/r/tensorflow/comments/8qdap1/help_with_tensorflow_error_problem_in_applying_an/,XononoX,1528753007,,1,0
19,2018-6-12,2018,6,12,12,8qfn4s,I'm a real estate photographer looking to use tensorflow object detection to replace tvs in rooms with tvs that have images on them.,https://www.reddit.com/r/tensorflow/comments/8qfn4s/im_a_real_estate_photographer_looking_to_use/,greensala,1528773198," Is this possible, or am I living in a dream world? And what might it cost for someone to create that tool? ",7,2
20,2018-6-12,2018,6,12,15,8qgwd3,Text summarization with Tensorflow seq2seq.,https://www.reddit.com/r/tensorflow/comments/8qgwd3/text_summarization_with_tensorflow_seq2seq/,ganji1055,1528786727,,1,6
21,2018-6-12,2018,6,12,16,8qh1wa,Can someone ELI5 me the difference between the LFW dataset and the AFW dataset?,https://www.reddit.com/r/tensorflow/comments/8qh1wa/can_someone_eli5_me_the_difference_between_the/,anshuman_kmr,1528788564,"The Live Faces in the Dataset which can be found [here](https://www.ics.uci.edu/~xzhu/face/) and  the AFW dataset which can be found [here](https://www.ics.uci.edu/~xzhu/face/) are two datasets that  I have found while trying to learn Facial Detection. Currently I am interning and I have been tasked on finding a suitable algorithm for facial detection. We are currently building a facial recognition application for the customers, so from my research I have found SFD is the most superior of them all but I am not sure which dataset to use for training and what purpose does either one serve.

 Please be kind , I am new to this.",0,3
22,2018-6-12,2018,6,12,18,8qhhmh,Implementing YOLO v3 in Tensorflow (TF-Slim)  Medium,https://www.reddit.com/r/tensorflow/comments/8qhhmh/implementing_yolo_v3_in_tensorflow_tfslim_medium/,Fewthp,1528794522,,1,14
23,2018-6-13,2018,6,13,3,8ql99j,Image Classifier False Positive Handling,https://www.reddit.com/r/tensorflow/comments/8ql99j/image_classifier_false_positive_handling/,anon00089,1528827453,"So I used the tensorflow demo for the flowers to create and train a fairly accurate model for classifying coins. However when I put it online for people to play with I ran into a problem. All of these models assume the person is only using images of coins for example in this case. So if someone uploads a picture of a horse or a car it still tries to classify it as a coin.

Is there any way around this easily? As in without having to train it with a huge number of items that are not coins? It seems highly inefficient but people claim to not trust the accuracy of the results if they can upload any image and it says its X coin.

Any help on this would be greatly appreciated. Im using the mobilenet model example to train my model with about 10 different folders of coin images as a test.

Thank you!",0,3
24,2018-6-13,2018,6,13,8,8qnrrg,How do I Live Train a Neural Network To Classify Images?,https://www.reddit.com/r/tensorflow/comments/8qnrrg/how_do_i_live_train_a_neural_network_to_classify/,Juice_DGGR,1528846729,"I want to make a live image classifier where you actively train a neural network what is in a picture. For example I want to feed the computer pictures of a single person and I would train the computer which of those people are male or female. Jabrils made a video ([https://youtu.be/KO7W0Qq8yUE](https://youtu.be/KO7W0Qq8yUE)) where a computer is trained to decide what text color looks better over random background colors. I want to create an image classifier similar to this except instead of training it based off of color, to train it based off of an image. The image would have two possibilities (eg; male or female) and it would be trained based off of the user's choice: (male or female). I have been trying to learn this for a while now and I haven't found a whole lot of information on the web on how to do this. If anybody could help point me in the right direction with some resources that I could use or just some information on the topic then that would be much appreciated! Thanks! (Note: this post won't make much sense unless the video is watched) Thanks again!

*Processing img jrqore52on311...*

*Processing img n1vq2kdnon311...*",11,2
25,2018-6-13,2018,6,13,19,8qra5i,Multi-GPU Tensorflow,https://www.reddit.com/r/tensorflow/comments/8qra5i/multigpu_tensorflow/,iliauk,1528884706,"I'm working on a series of comparison notebooks training DenseNet121 using high-level multi-gpu wrappers. Currently my [tensorflow](https://github.com/ilkarman/DeepLearningFrameworks/blob/master/notebooks/Tensorflow_MultiGPU.ipynb) notebook takes 22 minutes for 5 epochs, however PyTorch is 10, Gluon 8, and Chainer 14.

I wanted some help to see what I'm doing wrong and how the speed can be improved.",1,1
26,2018-6-13,2018,6,13,21,8qrwb5,"Model for detection occlusion on faces(glasses, shadows, hair, mask)",https://www.reddit.com/r/tensorflow/comments/8qrwb5/model_for_detection_occlusion_on_facesglasses/,maatzu,1528891640,"Hey. Anyone know where I can find a model for detection occlusion?  
I tried searching it on google, but couldn't find anything.",0,2
27,2018-6-14,2018,6,14,3,8quxln,Eigenvalue decomposition in Tensorflow,https://www.reddit.com/r/tensorflow/comments/8quxln/eigenvalue_decomposition_in_tensorflow/,HypoCelsus,1528915652,"I've been looking for a while for a library to do a computational physics project I'm working on with very little luck. I reckon it might be a stretch but can Tensorflow do eigenvalue/vector calculations on sparse (&lt;5% nnz) Hermitian matrices on GPUs? I've seen some threads around about this (although those threads are mainly bug tickets about it not workin'). 

Otherwise, if you guys are familiar with other GPU routines that might help that would also be appreciated.",4,2
28,2018-6-14,2018,6,14,8,8qx91d,Actually getting the prediction out?,https://www.reddit.com/r/tensorflow/comments/8qx91d/actually_getting_the_prediction_out/,atticdweller,1528933893,"I've been working on the MNIST tutorial here:
https://www.tensorflow.org/tutorials/layers

I have a model built, but have no idea how to now apply it to test against my own images. I have created some handwritten images of my own, how do I now use my own images against this model? 

All of the tutorials I see end with determining the models accuracy and then celebrating. I haven't found one that explains the usage of the models. If you can point me to a tutorial where they finish this exercise with their own handwritten image and the value of it being output that would be amazing.",10,3
29,2018-6-14,2018,6,14,14,8qzerz,Self validating option?,https://www.reddit.com/r/tensorflow/comments/8qzerz/self_validating_option/,trewert_77,1528955038,Is there an option in TensorFlow to define a directory as validation where we'd house the same directories as the training directory so that it'll self validate against the validation directory targets and retrain ?,0,1
30,2018-6-15,2018,6,15,11,8r7hjw,https://www.aiworkbox.com/lessons/create-tensorflow-name-scopes-for-tensorboard,https://www.reddit.com/r/tensorflow/comments/8r7hjw/httpswwwaiworkboxcomlessonscreatetensorflownamesco/,seabass,1529029154,,0,1
31,2018-6-15,2018,6,15,11,8r7hpb,Create TensorFlow Name Scopes For TensorBoard,https://www.reddit.com/r/tensorflow/comments/8r7hpb/create_tensorflow_name_scopes_for_tensorboard/,seabass,1529029190,,0,7
32,2018-6-15,2018,6,15,12,8r8268,This is a question regarding tf.gather operation? so please have a look at the code,https://www.reddit.com/r/tensorflow/comments/8r8268/this_is_a_question_regarding_tfgather_operation/,nile6499,1529035096,"index =  array(\[\[0, 0, 0, 1, 1, 2\]\], dtype=int32)

array = array(\[\[0.64504431, 0.0379043 , 0.38350438\], 

\[0.48966062, 0.00696901, 0.18810068\],  

\[0.30806628, 0.16443491, 0.28589765\],    

\[0.1162802 , 0.13453847, 0.01216389\],   

\[0.08474257, 0.20506575, 0.00175902\],  

\[0.12450533, 0.11357013, 0.04877977\]\])

array is 6x3 matrix

and i am trying to just take the 0th index from first row, second, and third row, 2nd index from 4, and 5th row...

I am not able to accomplish this task using tf.gather so any suggestion?

Thanks",2,1
33,2018-6-16,2018,6,16,3,8rd4ec,Tutorials on deep learning using tensorflow eager,https://www.reddit.com/r/tensorflow/comments/8rd4ec/tutorials_on_deep_learning_using_tensorflow_eager/,madalinaaa,1529086600,,2,12
34,2018-6-16,2018,6,16,6,8ree2m,"I was wondering if anyone would like collaborate with me on this project http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html, it is from fast.ai",https://www.reddit.com/r/tensorflow/comments/8ree2m/i_was_wondering_if_anyone_would_like_collaborate/,nile6499,1529096865,"I would love to collaborate with someone on this project to convert it to tensorflow environment.

Thanks",7,6
35,2018-6-16,2018,6,16,6,8renj4,A simplistic Tensorflow Lite Android Computer Vision App | Getting started with TF on mobile devices.,https://www.reddit.com/r/tensorflow/comments/8renj4/a_simplistic_tensorflow_lite_android_computer/,TheOSM,1529099089,,0,3
36,2018-6-16,2018,6,16,15,8rhpuu,"Using Tensorflow to predict pronunciation string of complex, non-English Unicode strings",https://www.reddit.com/r/tensorflow/comments/8rhpuu/using_tensorflow_to_predict_pronunciation_string/,stutterbug,1529131826,"I've spent a few days trying to figure out how to build pronunciation string builder for the Thai language, so that a word like `` (water) is phonemically transcribed to `nam`. Like English, Thai spelling is almost absurdly complicated, but unlike English it is, for the most part, very consistent and strongly rule-based. In principle, it is very possible to do this deterministically, but I suspect it should be relatively straight forward candidate for Tensorflow. Plus, I hope it would be a good way for me to start studying ML. Training data is plentiful and easy to acquire.

Given the sorts of problems below, do you think this is a reasonable challenge for an experienced programmer who's new to ML? And, maybe more importantly, do you think Tensorflow would be able to come up with something that is comparably accurate to deterministic online systems?

Example problems with Thai:

 1. Input is (I am pretty sure) composed exclusively of strings of ~74 2-byte Unicode glyphs. Strings will range in length from 2 characters to probably 10 or 12.
 2. All Thai syllables have a default ""tone"", transcribed as an accent, but certain Unicode marks will override this default tone, thus changing the accent mark.
 3. Some characters take on a radically different pronunciation depending on where they are in a syllable (e.g. `` is pronounced `n` at the end of a syllable but `r` everywhere else.
 4. Thai has ""silent"" characters that change the pronunciation of nearby characters.
 5. In a Unicode string, vowel characters can appear after or before a consonant, though it's always pronounced after (individual glyphs will always be found in the same place).

There are lots of other interesting problems, but I think this gives a good sense of the scale of the challenge.",2,3
37,2018-6-16,2018,6,16,23,8rjs1k,"Need some help, newbie here",https://www.reddit.com/r/tensorflow/comments/8rjs1k/need_some_help_newbie_here/,Hakkon8065,1529160285,"Hi, is there anyone there that could give me some directions.  
**The context:** I'm a computer science student and I'm starting to research neural networks and such, to solving some problems. The problem that I'm starting to tackle at the moment is dealing with large amounts of documents that we have in one of the departments on my university.

I got to a point, using google vision api that I can ocr the documents, but now I have to classify the data and them classify the document it self.

I'm trying to figure out how to model the data to classify and them create the model it self. Sorry if something doesn't sound natural, I'm from Brazil, English ins't my first language.",1,2
38,2018-6-17,2018,6,17,5,8rm6ob,Can someone critique my attention layer?,https://www.reddit.com/r/tensorflow/comments/8rm6ob/can_someone_critique_my_attention_layer/,iamiamwhoami,1529182320,"  Can someone critique my attention layer. Im feeding the output of an lstm to it. Like in this [paper](http://www.cs.cmu.edu/~./hovy/papers/16HLT-hierarchical-attention-networks.pdf). The code assumes the 2nd to last dimension is the temporal one. Ive been through it a few times. I cant see anything wrong with it but it intermittently causes my loss function to diverge. 
    
    from keras.layers import Layer
    import tensorflow as tf
    class Attention(Layer):
    def __init__(self, attention_dim):
        self.attention_dim = attention_dim
        super().__init__()
    def build(self, input_shape):
        self.W_w = self.add_weight(
            name = 'W_w', 
            shape = (self.attention_dim, input_shape[-1]),
            initializer = tf.random_normal,
            trainable = True).value()
        self.b_w = self.add_weight(
            name = 'b_w', 
            shape = (self.attention_dim,),
            initializer = tf.random_normal,
            trainable = True).value()
        self.u_w = self.add_weight(
            name = 'u_w', 
            shape = (self.attention_dim, ),
            initializer = tf.random_normal,
            trainable = True).value()
        super().build(input_shape)
    def call(self, h):
        u = tf.tanh( self._matmul(self.W_w, h) + self.b_w )
        numerator = tf.exp( tf.reduce_sum(self.u_w * u, axis = -1) )
        denominator = tf.exp( tf.reduce_sum(numerator, axis = -1) ) 
         = numerator / tf.expand_dims(denominator, axis = -1)
        s = tf.reduce_sum( tf.expand_dims(, axis=-1) * h, axis = -2 )
        return s
    def compute_output_shape(self, input_shape):
        return (*input_shape[0:-2], input_shape[-1])
    def get_config(self):
        return {'attention_dim' : self.attention_dim}
    def _matmul(self, W, h):
        return tf.reduce_sum( tf.expand_dims(h, axis=-2) * W , axis=-1)",0,0
39,2018-6-17,2018,6,17,5,8rm6p6,Can someone critique my attention layer?,https://www.reddit.com/r/tensorflow/comments/8rm6p6/can_someone_critique_my_attention_layer/,iamiamwhoami,1529182326,"  Can someone critique my attention layer. Im feeding the output of an lstm to it. Like in this [paper](http://www.cs.cmu.edu/~./hovy/papers/16HLT-hierarchical-attention-networks.pdf). The code assumes the 2nd to last dimension is the temporal one. Ive been through it a few times. I cant see anything wrong with it but it intermittently causes my loss function to diverge. 
    
    from keras.layers import Layer
    import tensorflow as tf
    class Attention(Layer):
    def __init__(self, attention_dim):
        self.attention_dim = attention_dim
        super().__init__()
    def build(self, input_shape):
        self.W_w = self.add_weight(
            name = 'W_w', 
            shape = (self.attention_dim, input_shape[-1]),
            initializer = tf.random_normal,
            trainable = True).value()
        self.b_w = self.add_weight(
            name = 'b_w', 
            shape = (self.attention_dim,),
            initializer = tf.random_normal,
            trainable = True).value()
        self.u_w = self.add_weight(
            name = 'u_w', 
            shape = (self.attention_dim, ),
            initializer = tf.random_normal,
            trainable = True).value()
        super().build(input_shape)
    def call(self, h):
        u = tf.tanh( self._matmul(self.W_w, h) + self.b_w )
        numerator = tf.exp( tf.reduce_sum(self.u_w * u, axis = -1) )
        denominator = tf.exp( tf.reduce_sum(numerator, axis = -1) ) 
         = numerator / tf.expand_dims(denominator, axis = -1)
        s = tf.reduce_sum( tf.expand_dims(, axis=-1) * h, axis = -2 )
        return s
    def compute_output_shape(self, input_shape):
        return (*input_shape[0:-2], input_shape[-1])
    def get_config(self):
        return {'attention_dim' : self.attention_dim}
    def _matmul(self, W, h):
        return tf.reduce_sum( tf.expand_dims(h, axis=-2) * W , axis=-1)",0,0
40,2018-6-17,2018,6,17,5,8rm79v,Can someone critique my attention layer?,https://www.reddit.com/r/tensorflow/comments/8rm79v/can_someone_critique_my_attention_layer/,iamiamwhoami,1529182483,"  Can someone critique my attention layer. Im feeding the output of an lstm to it. Like in this [paper](http://www.cs.cmu.edu/~./hovy/papers/16HLT-hierarchical-attention-networks.pdf). The code assumes the 2nd to last dimension is the temporal one. Ive been through it a few times. I cant see anything wrong with it but it intermittently causes my loss function to diverge. 
    
    from keras.layers import Layer
    import tensorflow as tf
    class Attention(Layer):
    def __init__(self, attention_dim):
        self.attention_dim = attention_dim
        super().__init__()
    def build(self, input_shape):
        self.W_w = self.add_weight(
            name = 'W_w', 
            shape = (self.attention_dim, input_shape[-1]),
            initializer = tf.random_normal,
            trainable = True).value()
        self.b_w = self.add_weight(
            name = 'b_w', 
            shape = (self.attention_dim,),
            initializer = tf.random_normal,
            trainable = True).value()
        self.u_w = self.add_weight(
            name = 'u_w', 
            shape = (self.attention_dim, ),
            initializer = tf.random_normal,
            trainable = True).value()
        super().build(input_shape)
    def call(self, h):
        u = tf.tanh( self._matmul(self.W_w, h) + self.b_w )
        numerator = tf.exp( tf.reduce_sum(self.u_w * u, axis = -1) )
        denominator = tf.exp( tf.reduce_sum(numerator, axis = -1) ) 
         = numerator / tf.expand_dims(denominator, axis = -1)
        s = tf.reduce_sum( tf.expand_dims(, axis=-1) * h, axis = -2 )
        return s
    def compute_output_shape(self, input_shape):
        return (*input_shape[0:-2], input_shape[-1])
    def get_config(self):
        return {'attention_dim' : self.attention_dim}
    def _matmul(self, W, h):
        return tf.reduce_sum( tf.expand_dims(h, axis=-2) * W , axis=-1)",2,2
41,2018-6-17,2018,6,17,22,8rr37k,Use the Pixel Visual Core for TFLite inference?,https://www.reddit.com/r/tensorflow/comments/8rr37k/use_the_pixel_visual_core_for_tflite_inference/,Randomhkkid,1529242813,"Is the PVC available to be tasked for inference in the latest TFLite builds with Android 8.1?

I can't find any tutorials or documentation on how to do so. Ideally I'd like to accelerate an app similar to 
https://codelabs.developers.google.com/codelabs/tensorflow-style-transfer-android/index.html?index=..%2F..%2Fio2017#0

",0,4
42,2018-6-18,2018,6,18,16,8rxnh4,Learn TensorFlow Image Classification &amp; How to Install TensorFlow,https://www.reddit.com/r/tensorflow/comments/8rxnh4/learn_tensorflow_image_classification_how_to/,sourceproj3cts,1529307013,,0,1
43,2018-6-19,2018,6,19,6,8s39cs,Project to quote historical books as an automatic response to any public or immoral behavior - https://github.com/BeautifulJesus/BeJesus,https://www.reddit.com/r/tensorflow/comments/8s39cs/project_to_quote_historical_books_as_an_automatic/,BeautifulJesus,1529357410,,5,4
44,2018-6-20,2018,6,20,4,8sbtfr,Sum of the elements belonging to the same class or label?,https://www.reddit.com/r/tensorflow/comments/8sbtfr/sum_of_the_elements_belonging_to_the_same_class/,nile6499,1529437365,"In pytorch we can convert tensor to numpy does this task is pretty trivial, but I am not able to find the way to sum the elements of the tensor belonging to same index.

Example: 

Tensor --&gt;

array(\[\[0.63934749, 0.59794489\],     

   \[0.31534091, 0.34968777\],  

   \[0.01611873, 0.76171234\],  

   \[0.9908411 , 0.56534975\],      

   \[0.76818513, 0.88622863\],        

   \[0.60281718, 0.6904842 \]\])

Index ---&gt; \[1,1,1,0,0,2\]

I wan to get sum of elements in Tensor corresponding to label/Index.

Thanks in advance :)",10,4
45,2018-6-20,2018,6,20,19,8sh6ud,Tensorboard loss plot spaghetti. What's going on here?,https://www.reddit.com/r/tensorflow/comments/8sh6ud/tensorboard_loss_plot_spaghetti_whats_going_on/,SeveQStorm,1529490039,"Hi everyone, 

I'm using Tensorboard to plot the loss of an algorithm. But the plot looks like this: [https://imgur.com/a/q0WMLdf](https://imgur.com/a/q0WMLdf) 

What's going on there? What am I supposedly doing wrong? 

I figured out that I apparently somehow need to provide a global step to the summary in order for it to correctly plot the loss. Without it all I get is a vertical line instead of that spaghetti, apparently because the X value (global step?) for the plot is always 0. I've tried without defining a global step counter at all. Still, only the vertical line. Actually, I don't get it... I assumed that \`tf\` would take care of such a counter by itself, inherently.

For the shown plot I've now created a global variable (simple \`int\`, not a \`tf.Variable\`), increase it by 1 every time I call \`run\` on the optimizer and feed that \`int\` to the summary. You can see the result in the linked plot. 

Maybe important: I have multiple name scopes that share the same graph but run their own (equal but distinct) optimizers, losses etc. and train distinct variables. The shown plot is from one of the name scopes. The basic global step counter that I've created is global for all name scopes, so when the algorithm of one name scope runs, it increases the global step counter and the other name scope will also see and further increase the previously increased value. ",0,3
46,2018-6-21,2018,6,21,1,8sjshj,Is tensorflow suitable for SET?,https://www.reddit.com/r/tensorflow/comments/8sjshj/is_tensorflow_suitable_for_set/,Jonas_SV,1529512726,"This paper https://arxiv.org/pdf/1707.04780.pdf really spiked My interest and id love to implement it. 

Ive used tensorflow pretty much but ive never manipulated the graph (Apart from assigning variabels) during a session before. 

My question is: Is tensorflow suitable for this kind of algorithm? Or does tensorflow work better with static graphs? :) 

And if so, how would one go about manipulating the graph during a session, removing and adding connections?

Or am i better of implementing it without tensorflow? 

",1,2
47,2018-6-21,2018,6,21,8,8sn20j,Crop a batch of images,https://www.reddit.com/r/tensorflow/comments/8sn20j/crop_a_batch_of_images/,errminator,1529537426,"I have a rank 4 tensor of 30,000 images. This tensor, X, has shape (30000,32,32,3).

I want to crop a 3 pixel margin out of each image so that X will now have shape (30000,26,26,3).

I did this by writing some native Python code to crop a single 32x32x3 image to a 26x26x3 image.

I then looped through all images in X and applied this function. This gave me a tensor with the right shape. However the input placeholder for my tensorflow graph is expecting the data to be tf.float32 and when I run my code it complains that I have uint8 encoding.

Is there a quick fix to this?

Or is there some alternative way to crop a whole batch of images that I've overlooked?

Thanks ",4,2
48,2018-6-22,2018,6,22,0,8ssnec,Land cover classification.,https://www.reddit.com/r/tensorflow/comments/8ssnec/land_cover_classification/,Demios,1529593900,"I have access to 3 bands satellite of data rasters for a city NIR - Red, NIR + Red and NDVI (which is (NIR-R)/(NIR+R)). The goal is to identify all areas with grass (that conforms to a specific spectral signature) by pixel. After identifying the land cover for grass (not trees), I'd like to create an image mask of said grass (grassy areas black, non-grassy areas white). Would tensorflow's object detection work well for this or should I be looking for more specialized alternatives? If yes, could anyone direct me towards relevant documentation and tutorials?",0,2
49,2018-6-22,2018,6,22,11,8sxr1z,Matrix multiplication of dim-4 tensor slice with dim-2 tensor,https://www.reddit.com/r/tensorflow/comments/8sxr1z/matrix_multiplication_of_dim4_tensor_slice_with/,ME_PhD,1529634370,"I have to multiply two ""tensors"": `a` and `b`. The shapes are

    a.get_shape()  --&gt; (?, 108, 192, 10)
    b.get_shape()  --&gt; (192, 16)

`a` has first dimension as ""None"" because it's the batch size.

What I need is to perform matrix multiplication of the inner two axes of `a` (so the 108 x 192) with `b` to yield a (?, 108, 16, 10) array as output, since:

    (108 , 192) x (192, 16) = (108, 16)

I can't figure it out - cannot loop since the first dimension is ""none"". Is this possible? ",2,1
50,2018-6-22,2018,6,22,16,8szjhp,How to determine the truncate time lag for BPTT in tensorflow?,https://www.reddit.com/r/tensorflow/comments/8szjhp/how_to_determine_the_truncate_time_lag_for_bptt/,Laurence-Lin,1529653736,"I've seen this document 

https://www.tensorflow.org/tutorials/recurrent

the ""num_steps"" seems to determine the truncate time lag for BPTT. In tensorflow, bptt runs for every k1 time steps and back flow k2 time steps, and k1 = k2 for tensorflow. 

However, how could I determine num_steps? If I have a input sequence with length N, will the num_steps default be set as N? 
",0,1
51,2018-6-22,2018,6,22,18,8szzrc,"Beginner question; scalar vs tensor, whats the diff ?",https://www.reddit.com/r/tensorflow/comments/8szzrc/beginner_question_scalar_vs_tensor_whats_the_diff/,DoveLux,1529659746,"I am creating this beginner note to myself and I can't figure out the dif between scalar and tensor since they both have the same output:        

//////////////////////////////////////////////////     
//What is the difference ? Both output the same.   
tf.scalar(4.5).print(); //Outputs Tensor 4.5      
tf.tensor(4.5).print(); //Outputs Tensor 4.5      
//////////////////////////////////////////////////      
	
tf.tensor([3, 7, 8]).print(); //Outputs Tensor [3, 7, 8]     
tf.tensor([[1, 5], [4, 7]]).print(); //Outputs 2 by 2 Flat Matrix.     

const Variable_1 = tf.tensor([4,7,2,1]);    
const Variable_2 = tf.tensor([20,30,40,50]);     
const total = tf.add (Variable_1, Variable_2);    
total.print(); //Outputs Tensor [24, 37, 42, 51]    
	
const subtract_result = tf.sub(Variable_2, Variable_1);     
subtract_result.print(); //Outputs Tensor [16, 23, 38, 49]     
	
const multiply_result = tf.mul(Variable_1, Variable_2);      
multiply_result.print(); //Outputs Tensor [80, 210, 80, 50]     
	
const division_result = tf.div(Variable_2, Variable_1);      
division_result.print(); //Outputs Tensor [5, 4.2857141, 20, 50]     ",5,2
52,2018-6-23,2018,6,23,0,8t28q6,Getting tensorflow-gpu to work on windows 10,https://www.reddit.com/r/tensorflow/comments/8t28q6/getting_tensorflowgpu_to_work_on_windows_10/,Stupidperson-,1529681472,"I am trying to install tensorflow-gpu 1.8 on a computer I recently built with a nvidia GPU. I have spent the last couple months studying machine learning and NN's on a laptop with no GPU so I have been using the cpu tensorflow and that worked fine. 

I have installed cuda 9.2 toolkit and cudnn 7.1, but when I run import tensorflow as tf, I get an error saying it can't find cudart64\_90.dll. From what I read, the issue is that tensorflow is hard coded to look for the 9.0 version of cuda toolkit so I just renamed cudart64\_92 to cudart64\_90. Then it couldn't find the cudnn64\_7.dll so I figured that was just my fault since that was downloaded already but in the wrong location so I extracted the cudnn zip to bin folder in the cuda 9.2 toolkit folder. Now my error message is more complicated with import errors saying ""DLL load failed: the specified module could not be found""

It seems that there's better instructions for installing tensorflow-gpu for Ubuntu, should I just figure out the dual boot stuff and use Ubuntu for my ML and tensorflow stuff? 

Any other suggestions are much appreciated.",11,4
53,2018-6-23,2018,6,23,10,8t6gh9,n00b question: why are my small images filling up so much memory on the gpu?,https://www.reddit.com/r/tensorflow/comments/8t6gh9/n00b_question_why_are_my_small_images_filling_up/,the_cat_kittles,1529716497,"im running mask rcnn training on a gtx1080 ti, its got 12gb memory. i have a very small training set of 8 images and a validation set of 3 images, all are 512x512 rgb. im using coco model- i see a warning like "" Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.03GiB""... just trying to make sense of things. i have it doing only one image at a time. what could possibly be using up all the memory? does the model itself have to sit on the gpu in some weird huge form? i get a sparse conversion warning too- maybe that has something to do with it? i feel like everything ive read suggests that i should be able to do many more images at a time. just wondering what the conceptual pieces that would inform my intuition about how much memory things take up on gpu are missing. thanks!",3,4
54,2018-6-23,2018,6,23,20,8t9ail,15 Days to Tensorflow,https://www.reddit.com/r/tensorflow/comments/8t9ail/15_days_to_tensorflow/,tensor_assassin,1529752657,"Hi guys, I will be covering from linear regression to cnn,ann,rnn,bilstm ,gan etc during the upcoming 15 days using tensorflow.Please star the repository and follow along .

[https://github.com/assassinsurvivor/15-days-to-tensorflow](https://github.com/assassinsurvivor/15-days-to-tensorflow)",0,3
55,2018-6-23,2018,6,23,21,8t9nei,"Presentation (+ code!): Deep learning with tensorflow: an introduction (tf.estimatror, tf.data)",https://www.reddit.com/r/tensorflow/comments/8t9nei/presentation_code_deep_learning_with_tensorflow/,pgaleone,1529757317,"I made this presentation for a short talk, and I think this is the perfect place where to share the slides and the related code.
The slides cover the fundamentals of doing deep learning with tensorflow, introducing the computational graph, the session, the symbolic computing ...
The second part of the presentation covers the tf.estimator + tf.data API, used to create a cat/dog classifier.

Slides: https://talks.pgaleone.eu/Deep%20Learning%20with%20Tensorflow:%20an%20introduction/tf.slide

Code: https://talks.pgaleone.eu/Deep%20Learning%20with%20Tensorflow:%20an%20introduction/py.py",0,19
56,2018-6-24,2018,6,24,5,8tcv9f,Question about update of the variable?,https://www.reddit.com/r/tensorflow/comments/8tcv9f/question_about_update_of_the_variable/,nile6499,1529787218,"I have a function named xyz

def xyz(index1,index2,unique\_indexfeatures):

xc = tf.get\_variable(shape=(10,2),trainable=False)

index1  = index1

index2 = index2

xc\_imm = tf.gather(xc,index1)

xc\_inn = tf.gather(xc,index2

diff = xc\_imm - xc\_inn

xc\_update = tf.scatter\_add(xc,unique\_index,diff\*0.5)

return xc\_update

I need to update xc using xc\_update, and how should I do? Any suggestions?

Thank you",0,1
57,2018-6-24,2018,6,24,12,8tf7mz,Looking for 1 on 1 online tutoring,https://www.reddit.com/r/tensorflow/comments/8tf7mz/looking_for_1_on_1_online_tutoring/,bmarsauto,1529811613,Looking for one on one tutoring for tensorflow. Background: BS in physics masters in computational physics. Looking to start ASAP for work. Please message me with rates and experience. ,2,0
58,2018-6-24,2018,6,24,13,8tfj00,Baby Question Alert! Is It Possible To Save This Model?,https://www.reddit.com/r/tensorflow/comments/8tfj00/baby_question_alert_is_it_possible_to_save_this/,JulianCienfuegos,1529815056,"I ran the [first example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/layers/cnn_mnist.py) but the model is not saved. It looks to me like there is a trained model called ""mnist_classifier"" that is trained and able to "".evaluate()"" test data. I've just spent about 45 minutes trying to save it and all the docs start talking about Variables and tf.Graphs and tf.Sessions and sess.run(init_all_something_or_other) and all I want to do is save this model, which at the end of the script is trained and able to classify and out to be able to be written to disk somehow.

I just installed all the CUDA dependencies and played with a few simple tutorials and experimented with the tutorial files, and am starting to run out of gas for the evening but this issue is just driving me crazy.",5,2
59,2018-6-24,2018,6,24,22,8thwv0,Is this the correct way to create a onehot feature column?,https://www.reddit.com/r/tensorflow/comments/8thwv0/is_this_the_correct_way_to_create_a_onehot/,feeling_impossible,1529848262,"I have gone through [Google's intro to machine learning course](https://developers.google.com/machine-learning/crash-course/ml-intro) and am trying to apply it to my own data.

This is the function that creates the tensors from my pandas dataframe. It should create numerical columns for everything except the features listed in onehots. Features listed in onehots should be turned into onehot features, obviously.

Is this correct?

	def construct_feature_columns(df):
		onehots = ['name', 'event']
		
		features = []
		for key in df:
			if key in onehots:
				category = tf.feature_column.categorical_column_with_vocabulary_list(key=key, vocabulary_list=df[key].unique())
				features.append(tf.feature_column.indicator_column(category))
			else:
				features.append(tf.feature_column.numeric_column(key))
				
		return(set(features))

Thanks in advance.",0,1
60,2018-6-25,2018,6,25,19,8tpejx,"TF high level APIs: tf.slim, tf.keras, tf.estimator, tf.layers, sonnet",https://www.reddit.com/r/tensorflow/comments/8tpejx/tf_high_level_apis_tfslim_tfkeras_tfestimator/,thaflow,1529922198,"Hi,

I am confused about which high level API to use, which one is deprecated and how to structure my code.

Is tf.slim still supported?

=&gt; I see it used on github a lot but can't find any official documentation on [tensorflow.org](https://tensorflow.org)

What is your take on variable sharing vs template based model building with sonnet?

tf.estimator feels clumsy. Is this the way to go in the future?",10,3
61,2018-6-26,2018,6,26,5,8ttsl7,Intuition when to use Global Average pooling?,https://www.reddit.com/r/tensorflow/comments/8ttsl7/intuition_when_to_use_global_average_pooling/,nile6499,1529958016,"I am still not sure when to use Global average pooling v/s Fully connected Network v/s Fully convolutional Network. If someone could explain me that would be awesome.  
Thanks",0,2
62,2018-6-26,2018,6,26,6,8tu77z,Tensorflow data encryption [Mobile],https://www.reddit.com/r/tensorflow/comments/8tu77z/tensorflow_data_encryption_mobile/,alex_ovechko,1529961021,,0,7
63,2018-6-26,2018,6,26,11,8twgyd,"Wondering if my goal is possible before diving down this rabbit hole, advice?",https://www.reddit.com/r/tensorflow/comments/8twgyd/wondering_if_my_goal_is_possible_before_diving/,Honj_The_Breatharian,1529981035,"TLDR: Can tensorflow measure when a fish's orentation dips to 50 degrees?

Hello, I am a student working on some research at my community college. Right now we are testing what kind of fish food the fish are most attracted to. The food sits on the bottom of the tank and the fish will come to the food, then dip down to about 50 degrees to feed. Right now we are recording the footage and manually counting each time a fish goes nearly vertical and bites at the gravel.

So after a day of the monotony, I am trying to do what every good computer science student would do and find a way to automate the process. As a disclaimer this is my first year as CS student so my knowledge is not very thorough, but im apt to learn. Upon researching possibilities, it seems tensorflow would be a good place to begin in attempting this.

The real question is, is tensorflow capable of measuring how many times a fish crosses the 50 degree threshold? And if so, do you think with enough dedication I would be capable of learning how to set something like this up within a year and a half? I appreciate all advice and input, thank you.",4,2
64,2018-6-26,2018,6,26,19,8tz1c9, uantitative ourney On Tensor Networks and the Nature of Non-Linearity,https://www.reddit.com/r/tensorflow/comments/8tz1c9/_uantitative_ourney_on_tensor_networks_and_the/,molode,1530010131,,1,0
65,2018-6-27,2018,6,27,2,8u1tis,Is there a good resource out there for TensorFlow to Movidius/NCS SDK compatibility?,https://www.reddit.com/r/tensorflow/comments/8u1tis/is_there_a_good_resource_out_there_for_tensorflow/,EQUASHNZRKUL,1530033414,Basically the title. I just want to know what sections of TensorFlow worked with Movidius and which parts didn't. ,2,1
66,2018-6-27,2018,6,27,11,8u5sid,Can I use my laptop for a convolutional neural network i am about to make?,https://www.reddit.com/r/tensorflow/comments/8u5sid/can_i_use_my_laptop_for_a_convolutional_neural/,scarletred94,1530065073,"I'm still learning about neural networks and I only have a laptop. I've heard that the requirements I needed are pretty demanding especially on the GPU. I found an alternative wherein I can train my datasets on Google Cloud or AWS, can my old laptop with a 4gb of ram, 2.1ghz cpu do the job?",7,3
67,2018-6-28,2018,6,28,19,8ui8lt,"TensorFlow.js, Machine Learning and Flappy Bird: Frontend AI Experiment",https://www.reddit.com/r/tensorflow/comments/8ui8lt/tensorflowjs_machine_learning_and_flappy_bird/,Apptension,1530183447,,0,15
68,2018-6-28,2018,6,28,23,8ujvam,Retrain neural network models optimized for mobile to recognise custom objects using TensorFlow,https://www.reddit.com/r/tensorflow/comments/8ujvam/retrain_neural_network_models_optimized_for/,jknaf,1530195768,,0,3
69,2018-6-29,2018,6,29,3,8um1w9,Julia Set generator with Low-Level API and TensorBoard,https://www.reddit.com/r/tensorflow/comments/8um1w9/julia_set_generator_with_lowlevel_api_and/,rektopular,1530210081,"Something that I've enjoyed working on in the process of exploring Python, TensorFlow, and my interest in visualizing mathematical entities.

It might be useful to some people who are looking for examples of TensorBoard implementation as well.

[https://github.com/Kektopular](https://github.com/Kektopular)

Thanks!",1,5
70,2018-6-29,2018,6,29,12,8upzuc,Reading long strings of constantly changing numbers and letters,https://www.reddit.com/r/tensorflow/comments/8upzuc/reading_long_strings_of_constantly_changing/,yohdeals,1530243339,"Hey there, I've been learning a bit about how to read license plates, and wondered if it's a close comparison build a number/letter reader that would automatically detect the characters and then input that data into an excel file.

Imagine reading the data on this site - http://www.usdebtclock.org/ 
and then inputting it occasionally (every day or so) into an excel sheet.
",4,1
71,2018-6-29,2018,6,29,13,8uqeo6,Anyone knows how to use tf.contrib.summary (aka. Summary API V2)?,https://www.reddit.com/r/tensorflow/comments/8uqeo6/anyone_knows_how_to_use_tfcontribsummary_aka/,phizaz,1530247542,"Refer to: [https://www.tensorflow.org/api\_docs/python/tf/contrib/summary](https://www.tensorflow.org/api_docs/python/tf/contrib/summary), there is quite a lack of tutorial and examples here. I have some success in eager mode usage, but not so in graph mode. If you have a tutorial or working examples please share. ",0,7
72,2018-6-30,2018,6,30,1,8uuexs,Image Correction and Enhancement with tensor flow?,https://www.reddit.com/r/tensorflow/comments/8uuexs/image_correction_and_enhancement_with_tensor_flow/,ginglis13,1530289214,"I am working on a project with the goal of improving and correction distortion and asymmetry in transmission electron microscope images. I discovered Tensorflow today, and I was curious if it could be used in my case. Are there any good programs or tutorials out there about implementing Tensorflow with images? Thanks!",2,2
73,2018-6-30,2018,6,30,23,8v22pz,Ensembling tf.estimators,https://www.reddit.com/r/tensorflow/comments/8v22pz/ensembling_tfestimators/,Henry4athene,1530367708,"I am trying to created a bagged model of many tf.estimators. I am using one of the premade estimators and would prefer to keep using it if possible. 
Currently I am simply creating many instances of an estimator and training them seperately, however when it comes to evaluating the ensemble I am having trouble. Specifically I need to get an auc score and I have been just manually averaging the prediction results of every estimator and feeding it into a tf.metric.auc() function. 

This however does not work as it gives me some error about tensors not being initialized (Yes I did create and session and run an initilizer) . So I am wondering if anyone has any experience with ensembling tf.estimators, is this method of ensembling even a good idea to begin with, or is there a better way?",0,4
0,2018-7-2,2018,7,2,0,8vags8,I made a tool to label long and repetitive videos by showing multiple clips simultaneously on screen. It's called MuViLab. What do you think?,https://www.reddit.com/r/tensorflow/comments/8vags8/i_made_a_tool_to_label_long_and_repetitive_videos/,ale152,1530457412,,1,7
1,2018-7-2,2018,7,2,12,8vfoay,Does the backpropagation through time in LSTM apply truncate bptt?,https://www.reddit.com/r/tensorflow/comments/8vfoay/does_the_backpropagation_through_time_in_lstm/,Laurence-Lin,1530503821,"In the optimizer that update the LSTM in tensorflow, does the BPTT apply truncate BPTT or full BPTT?  
If is applies truncate BPTT, how does the code decide the truncate time lag?  


Thanks a lot!  
",0,3
2,2018-7-2,2018,7,2,15,8vgi7a,4 Sequence Encoding Blocks You Must Know Besides RNN/LSTM in Tensorflow  Han Xiao Tech Blog,https://www.reddit.com/r/tensorflow/comments/8vgi7a/4_sequence_encoding_blocks_you_must_know_besides/,h_xiao,1530513246,,2,7
3,2018-7-3,2018,7,3,1,8vjrkz,Getting Started with TensorFlow.js: Linear Regression,https://www.reddit.com/r/tensorflow/comments/8vjrkz/getting_started_with_tensorflowjs_linear/,tristansokol,1530547344,,0,8
4,2018-7-3,2018,7,3,17,8vqosw,Advice about ubuntu 18.04 and tf,https://www.reddit.com/r/tensorflow/comments/8vqosw/advice_about_ubuntu_1804_and_tf/,pemens,1530608191,"Hello guys! Have been working for 1.5 year on ubuntu 16.04 with tf and full stack for AI, 

but all has an and, and system died without possible recovery. How does 18.04 and tf feels?

Don't have problems with installing all packages and libraries, processing at all? 

Thanks for it :3",5,2
5,2018-7-3,2018,7,3,20,8vre0m,Ideas for medicine,https://www.reddit.com/r/tensorflow/comments/8vre0m/ideas_for_medicine/,fatal_quantum_error,1530616679,"While learning about the use of tensorflow in retinal imaging for identification of diabethic retinopathy I was wondering if there are any other applications. Does anyone of you know of areas in medicine, where some minor/major problems could maybe be tackled by AI with tensorflow?",5,3
6,2018-7-4,2018,7,4,2,8vu1y2,Managed/hosted 1080Ti GPU rentals for ML/TenserFlow,https://www.reddit.com/r/tensorflow/comments/8vu1y2/managedhosted_1080ti_gpu_rentals_for_mltenserflow/,adopshire2016,1530638695,"Hello,

I run a sizable GPU mining farm with hundreds of 1080Ti GPUs used primarily for cryptocurrency mining.

We recently started looking into diversifying our revenue channels by introducing custom server builds with stronger CPUs and RAM and larger HDs to be attractive for machine learning. We got some interest from video rendering projects but not machine learning.

Is there any interest in this type of service? If so, what price points and hardware considerations would make this attractive?",11,4
7,2018-7-5,2018,7,5,22,8wad82,face-api.js - Analysis of usage TensorFlow.js,https://www.reddit.com/r/tensorflow/comments/8wad82/faceapijs_analysis_of_usage_tensorflowjs/,ArturSkowronski,1530796694,https://medium.com/@ArturSkowronski/github-all-stars-2-face-api-js-f3d6f135f4f7,0,9
8,2018-7-6,2018,7,6,23,8wkmjq,Some initial efforts for idris on tf,https://www.reddit.com/r/tensorflow/comments/8wkmjq/some_initial_efforts_for_idris_on_tf/,doofin,1530888293,,0,2
9,2018-7-7,2018,7,7,6,8wnvex,Load GloVe embeddings as a TensorFlow GPU Layer [NLP],https://www.reddit.com/r/tensorflow/comments/8wnvex/load_glove_embeddings_as_a_tensorflow_gpu_layer/,GChe,1530912391,,1,3
10,2018-7-7,2018,7,7,18,8wrx4d,Should I create a GUI for creating Tensorflow models?,https://www.reddit.com/r/tensorflow/comments/8wrx4d/should_i_create_a_gui_for_creating_tensorflow/,kite_and_code,1530954217,"Currently, I am evaluating some Master thesis topics. One of the proposals is:

\- Create a GUI for creating Tensorflow models with data flow graphical programming (similar to Rapidminer).

\- After the model phase, the Tensorflow code can be ejected and you can integrate it in your existing workflow.

\- Also, the library will be Open Source.

What do you think about it? Is creating your graphs from code a problem worth solving/improving? Why or why not?

I am looking forward to your suggestions!",32,10
11,2018-7-8,2018,7,8,10,8wxyiu,seq2seq model with MultiRNN and AttentionWrapper: dimension mismatch between LSTM's input and kernel,https://www.reddit.com/r/tensorflow/comments/8wxyiu/seq2seq_model_with_multirnn_and_attentionwrapper/,EthanPhan,1531012210,"\[TF 1.8\]

First of all, I know this kind of question may not appropriate in this sub but I don't know anywhere else to ask (I posted it on stackoverflow but it seem to reach no one's interest)

I'm trying to build a seq2seq model for a toy chatbot to learn tensorflow and deep learning using LSTM, sampled softmax loss, tf.contrib.seq2seq.LuongAttention, beamsearch with the internal representation of 128 dimension. I was able to train my model when there was only 1 layer of LSTM. Now I try 2 layers of LSTM using MultiRNN I get the following error while building the graph:

`ValueError: Dimensions must be equal, but are 384 and 256 for 'rnn/while/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/MatMul_2' (op: 'MatMul') with input shapes: [64,384], [256,512].`

This is my model:

`class ChatBotModel:`

`def __init__(self, inferring=False, batch_size=1, use_sample_sofmax=True):`

`""""""forward_only: if set, we do not construct the backward pass in the model.`

`""""""`

`print('Initialize new model')`

`self.inferring = inferring`

`self.batch_size = batch_size`

`self.use_sample_sofmax = use_sample_sofmax`

`def build_graph(self):`

`# INPUTS`

`self.X = tf.placeholder(tf.int32, [None, None])`

`self.Y = tf.placeholder(tf.int32, [None, None])`

`self.X_seq_len = tf.placeholder(tf.int32, [None])`

`self.Y_seq_len = tf.placeholder(tf.int32, [None])`

`self.gl_step = tf.Variable(`

`0, dtype=tf.int32, trainable=False, name='global_step')`

`single_cell = tf.nn.rnn_cell.BasicLSTMCell(128)`

`keep_prob = tf.cond(tf.convert_to_tensor(self.inferring, tf.bool), lambda: tf.constant(`

`1.0), lambda: tf.constant(0.8))`

`single_cell = tf.contrib.rnn.DropoutWrapper(`

`single_cell, output_keep_prob=keep_prob)`

`encoder_cell = tf.contrib.rnn.MultiRNNCell([single_cell for _ in range(2)])`

`# ENCODER`         

`encoder_out, encoder_state = tf.nn.dynamic_rnn(`

`cell = encoder_cell,` 

`inputs = tf.contrib.layers.embed_sequence(self.X, 10000, 128),`

`sequence_length = self.X_seq_len,`

`dtype = tf.float32)`

`# encoder_state is ((cell0_c, cell0_h), (cell1_c, cell1_h))`

`# DECODER INPUTS`

`after_slice = tf.strided_slice(self.Y, [0, 0], [self.batch_size, -1], [1, 1])`

`decoder_inputs = tf.concat( [tf.fill([self.batch_size, 1], 2), after_slice], 1)`

`# ATTENTION`

`attention_mechanism = tf.contrib.seq2seq.LuongAttention(`

`num_units = 128,` 

`memory = encoder_out,`

`memory_sequence_length = self.X_seq_len)`

`# DECODER COMPONENTS`

`Y_vocab_size = 10000`

`decoder_cell = tf.contrib.rnn.MultiRNNCell([single_cell for _ in range(2)])`

`decoder_cell = tf.contrib.seq2seq.AttentionWrapper(`

`cell = decoder_cell,`

`attention_mechanism = attention_mechanism,`

`attention_layer_size=128)`

`decoder_embedding = tf.Variable(tf.random_uniform([Y_vocab_size, 128], -1.0, 1.0))`

`projection_layer = CustomDense(Y_vocab_size)`

`if self.use_sample_sofmax:`

`softmax_weight = projection_layer.kernel`

`softmax_biases = projection_layer.bias`

`if not self.inferring:`

`# TRAINING DECODER`

`training_helper = tf.contrib.seq2seq.TrainingHelper(`

`inputs = tf.nn.embedding_lookup(decoder_embedding, decoder_inputs),`

`sequence_length = self.Y_seq_len,`

`time_major = False)`

`decoder_initial_state = decoder_cell.zero_state(self.batch_size, dtype=tf.float32).clone(`

`cell_state=encoder_state)`

`training_decoder = tf.contrib.seq2seq.BasicDecoder(`

`cell = decoder_cell,`

`helper = training_helper,`

`initial_state = decoder_initial_state,`

`output_layer = projection_layer`

`)`

`training_decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(`

`decoder = training_decoder,`

`impute_finished = True,`

`maximum_iterations = tf.reduce_max(self.Y_seq_len))`

`training_logits = training_decoder_output.rnn_output`

`# LOSS`

`softmax_loss_function = None`

`if self.use_sample_sofmax:`

`def sampled_loss(labels, logits):`

`labels = tf.reshape(labels, [-1, 1])`

`return tf.nn.sampled_softmax_loss(weights=softmax_weight,`

`biases=softmax_biases,`

`labels=labels,`

`inputs=logits,`

`num_sampled=64,`

`num_classes=10000)`

`softmax_loss_function = sampled_loss`

`masks = tf.sequence_mask(self.Y_seq_len, tf.reduce_max(self.Y_seq_len), dtype=tf.float32)`

`self.loss = tf.contrib.seq2seq.sequence_loss(logits = training_logits, targets = self.Y, weights = masks, softmax_loss_function=softmax_loss_function)`

`# BACKWARD`

`params = tf.trainable_variables()`

`gradients = tf.gradients(self.loss, params)`

`clipped_gradients, _ = tf.clip_by_global_norm(gradients, 5.0)`

`self.train_op = tf.train.AdamOptimizer().apply_gradients(zip(clipped_gradients, params), global_step=self.gl_step)`

`else:`

`encoder_states = []`

`for i in range(2):`

`if isinstance(encoder_state[i],tf.contrib.rnn.LSTMStateTuple):`

`encoder_state_c = tf.contrib.seq2seq.tile_batch(encoder_state[i].c, multiplier=2)`

`encoder_state_h = tf.contrib.seq2seq.tile_batch(encoder_state[i].h, multiplier=2)`

`encoder_state = tf.contrib.rnn.LSTMStateTuple(c=encoder_state_c, h=encoder_state_h)`

`encoder_states.append(encoder_state)`

`encoder_states = tuple(encoder_states)`

`predicting_decoder = tf.contrib.seq2seq.BeamSearchDecoder(`

`cell = decoder_cell,`

`embedding = decoder_embedding,`

`start_tokens = tf.tile(tf.constant([2], dtype=tf.int32), [self.batch_size]),`

`end_token = 3,`

`initial_state = decoder_initial_state,`

`beam_width = 2,`

`output_layer = projection_layer,`

`length_penalty_weight = 0.0)`

`predicting_decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(`

`decoder = predicting_decoder,`

`impute_finished = False,`

`maximum_iterations = 4 * tf.reduce_max(self.Y_seq_len))`

`self.predicting_logits = predicting_decoder_output.predicted_ids`

Tracing back a few lines of log and I saw that the error occurs here:

`/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py in call(self, inputs, state)`

`636` 

`637     gate_inputs = math_ops.matmul(`

`--&gt; 638         array_ops.concat([inputs, h], 1), self._kernel)`

`639     gate_inputs = nn_ops.bias_add(gate_inputs, self._bias)`

I have checked the 'h' tensor of the LSTM cell and it has the shape of \[batch\_size, 128\] so my guess is that the attention output from the previous decoding step is concatenated with the current encoder's input make the 'inputs' has the shape of \[batch\_size, 256\] then it is concatenated with 'h' tensor to form a \[batch\_size, 384\] tensor causing this error.

My question is: Isn't attention output supposed to be concatenated with the next decoder's input or I miss understanding anything? And how to fix this error.",1,7
12,2018-7-9,2018,7,9,7,8x564e,"NoodleFeet Can Now Recognize his First Object, his Favorite Stuffed Animal ""Fisty"" (using TensorFlow)!",https://www.reddit.com/r/tensorflow/comments/8x564e/noodlefeet_can_now_recognize_his_first_object_his/,spetku,1531087224,,0,18
13,2018-7-9,2018,7,9,13,8x86qg,ML patterns and tools recommendation for answering user texts,https://www.reddit.com/r/tensorflow/comments/8x86qg/ml_patterns_and_tools_recommendation_for/,prayagupd,1531110936,"I'm learning ML and see if ML fits into my problem where I am trying to answer user question.

Let's say
user asks: I am having **headache** since yesterday and **fever** as well. what shall I do?
bot: (go and read a book) and reply back a blob of relevant answer. (wondering how can I make that much intelligent)

**OR** potentially I train the bot with (pre-processed) features and target labels.

For the pre-processing, I have to extract the parameters from user texts using NLP then store the data in MySQL or somewhere and then train/evaluate from there. `treatment` actually comes another set of logs which is a mapping of `usertext to treatment`

For example,

    symptom1    | symptom2    | gender  | treatment (label: huge text)
    headache    | fever       | M       | do blah blah, and blah blah
    headache    | fever       | F       | do something, and blah blah
    ...

**What ML patterns and tools do you guys see and recommend in similar scenario as mentioned above.** I am wondering if I can use tensorflow to train and find the treatment label but it does not really feel like prediction problem. As long as I extract parameters using NLP, it feels more of if else to me. than ML, I mean I could solve it using `if (symtom1 &amp;&amp; symtom2) then treatment1` and so on.
",0,1
14,2018-7-10,2018,7,10,19,8xnr5r,How do I set is_training on resnet,https://www.reddit.com/r/tensorflow/comments/8xnr5r/how_do_i_set_is_training_on_resnet/,VirtualHat,1531218535,"I'm training a model from scratch that processes video segments.  I'm using the built in slim resnet model, but have it wired to some LSTM units.  I'm having trouble with the is_training parameter in resnet.  It seems I must set this when creating the model, but I want to be able to switch in and out of training modes while I'm training (i.e. for validation etc), is this possiable?


",2,1
15,2018-7-11,2018,7,11,0,8xpz3j,Error in Compiling the CPU Module for Python,https://www.reddit.com/r/tensorflow/comments/8xpz3j/error_in_compiling_the_cpu_module_for_python/,fifo_thekid,1531235062,"System information

Have I written custom code: No

OS Platform and Distribution: Windows 10 64bit

TensorFlow installed from: Latest master source

TensorFlow version: commit dfcec82

Python version: 3.6.5

CMake version: 3.12.0-rc2

MS C+_+ Compiler version: 19.00.24234.1

CPU model and memory: i5-4460 with 16GB of RAM

Exact command to reproduce:

1- Opening Developer Command Line as admin

2- Choosing the 65bit compiler

""C:\Program Files (x86)\Microsoft Visual Studio\2017\Enterprise\Common7\Tools\vsdevcmd\ext\vcvars.bat"" amd64

3- cd D:\opencv\tensorflow\tensorflow\contrib\cmake\build

4- cmake .. -A x64 -T host=x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=D:/opencv/swigwin-3.0.12/swig.exe -DPYTHON_EXECUTABLE=""C:/Users/FiFo/AppData/Local/Programs/Python/Python36/python.exe"" -DPYTHON_LIBRARIES=""C:/Users/FiFo/AppData/Local/Programs/Python/Python36/libs/python36.lib"" -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX2 -Dtensorflow_BUILD_CC_TESTS=OFF -Dtensorflow_BUILD_PYTHON_TESTS=OFF -Dtensorflow_BUILD_MORE_PYTHON_TESTS=OFF -Dtensorflow_BUILD_CC_EXAMPLE=ON -Dtensorflow_BUILD_PYTHON_BINDINGS=ON -Dtensorflow_BUILD_CC_TESTS=OFF -Dtensorflow_OPTIMIZE_FOR_NATIVE_ARCH=ON -Dtensorflow_ENABLE_MKL_SUPPORT=ON -Dtensorflow_ENABLE_MKLDNN_SUPPORT=ON -Dtensorflow_VERBOSE=ON -Dtensorflow_BUILD_SHARED_LIB=ON

5- MSBuild /p:Configuration=Release ALL_BUILD.vcxproj SUCCESS

6- MSBuild /p:Configuration=Release INSTALL.vcxproj SUCCESS

7- MSBuild /p:Configuration=Release tf_python_build_pip_package.vcxproj

Fails with:

Generating init.py files for Python API.

Traceback (most recent call last):

File ""D:\opencv\tensorflow\tensorflow\contrib\cmake\build\tf_python\tensorflow\python\pywrap_tensorflow_internal.py"", line 14, in swig_import_helper return importlib.import_module(mname)

File ""C:\Users\FiFo\AppData\Local\Programs\Python\Python36\lib\importlib_init_.py"", line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level)

File """", line 994, in _gcd_import File """", line 971, in _find_and_load File """", line 955, in _find_and_load_unlocked File """", line 658, in _load_unlocked File """", line 571, in module_from_spec File """", line 922, in create_module File """", line 219, in _call_with_frames_removed ImportError: DLL load failed: No foi possvel encontrar o mdulo especificado.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):

File ""D:\opencv\tensorflow\tensorflow\contrib\cmake\build\tf_python\tensorflow\python\pywrap_tensorflow.py"", line 58, in from tensorflow.python.pywrap_tensorflow_internal import *

File ""D:\opencv\tensorflow\tensorflow\contrib\cmake\build\tf_python\tensorflow\python\pywrap_tensorflow_internal.py"", line 17, in _pywrap_tensorflow_internal = swig_import_helper()

File ""D:\opencv\tensorflow\tensorflow\contrib\cmake\build\tf_python\tensorflow\python\pywrap_tensorflow_internal.py"", line 16, in swig_import_helper return importlib.import_module('pywrap_tensorflow_internal')

File ""C:\Users\FiFo\AppData\Local\Programs\Python\Python36\lib\importlib_init.py"", line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level)

ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'

Failed to load the native TensorFlow runtime.

It used to work before with version 1.8

I don't want to install the PIP version

Compilation works without any problem on Ubuntu 16.04",0,1
16,2018-7-11,2018,7,11,0,8xqe2u,A dive into the deep end of deep neural networks for recommender engines.,https://www.reddit.com/r/tensorflow/comments/8xqe2u/a_dive_into_the_deep_end_of_deep_neural_networks/,cptAwesome_070,1531237606,,0,4
17,2018-7-12,2018,7,12,21,8y9c5l,I want to experiment around with game theory where simulated actors live and interact with each other. Would TensorFlow be good for that?,https://www.reddit.com/r/tensorflow/comments/8y9c5l/i_want_to_experiment_around_with_game_theory/,dog_superiority,1531398573,"I've been perusing the TensorFlow web page a little, and it seems that a lot of the tutorials and examples have to do with image recognition stuff.  I'm wondering how suitable it would be for a game theory simulation.

What I would like to do is have a bunch of ""people"" interact with each other on a 2D board where they build stuff, trade stuff, fight each other, etc.  If they don't eat, they get hungry.  If they do that too long, they die.  That sort of thing.  I'd like to have where I can turn it on in the morning let the dudes do their thing while learning as they go, and come home from work and see how they did.  Are they all dead?  Did they all run away forever?  Did they build a futuristic society like that one episode of the Simpsons?

Basically, I am wondering if TensorFlow is something I should consider using for this.  Any pointers on where to start would be helpful.  

(BTW, I code a lot in C++, some in Python, and did Java a lot several years ago.  In case that is important)",13,0
18,2018-7-13,2018,7,13,14,8yh9ki,A complete guide for building machine learning and deep learning solutions using Tensorflow,https://www.reddit.com/r/tensorflow/comments/8yh9ki/a_complete_guide_for_building_machine_learning/,vinnyvessel,1531459481,,0,1
19,2018-7-14,2018,7,14,16,8yrmh9,how do you set weights for RNN cells?,https://www.reddit.com/r/tensorflow/comments/8yrmh9/how_do_you_set_weights_for_rnn_cells/,extra_bigass_fries,1531553572,"The TF website documentation clearly lists methods for setting weights for every type of cell, and yet, invoking them gives error ""no attribute set_weights"".",1,1
20,2018-7-15,2018,7,15,10,8yy37h,Simple Equation in TF?,https://www.reddit.com/r/tensorflow/comments/8yy37h/simple_equation_in_tf/,throwaway775849,1531617132,"For pairs of training data (x,y), how would you code this in Tensorflow?

    f(m_i, x) = y, m_i+1



",4,0
21,2018-7-15,2018,7,15,14,8yzgal,"I'm having this issue whenever I run (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data() from the tutorial. How do I fix this?",https://www.reddit.com/r/tensorflow/comments/8yzgal/im_having_this_issue_whenever_i_run_train_images/,AusCro,1531631590,,3,3
22,2018-7-15,2018,7,15,19,8z0wtk,Issues with Save and Restoring Model,https://www.reddit.com/r/tensorflow/comments/8z0wtk/issues_with_save_and_restoring_model/,stealthx9,1531651690,"Hi,

i have the following issue and i hope there is somebody out there who can help me.

I can train my model and i can see the accuracy getting better. I am saving my model every 10 epochs. 

But when i stop the learning process, and restore the model to continue learning, the accuracy suddenly drops much lower then it was when i saved the model.  (None of the Training/Testdata is changing - so i am sure it must be an issue of save and restore)

WHen somebody can hint me in the right direction i would very much appreciate it!

    
    class XModel():
        def __init__(self, num_inputs, num_outputs, hidden_layers=[30,25,15], model=''):
            self.num_inputs = num_inputs
            self.num_outputs = num_outputs
            self.model = model
            # Placeholder
            self.X = tf.placeholder(dtype=tf.float32, shape=[None, num_inputs], name=""X"")
            self.Y = tf.placeholder(dtype=tf.float32, shape=[None, num_outputs], name=""Y"")
    
            # 1ST LAYER
            self.W1 = tf.Variable(tf.random_normal([num_inputs, hidden_layers[0]]), name=""W1"")
            self.b1 = tf.Variable(tf.random_normal([hidden_layers[0]]), name=""b1"")
            # # # 2ND LAYER
            self.W2 = tf.Variable(tf.random_normal([hidden_layers[0], hidden_layers[1]]), name=""W2"")
            self.b2 = tf.Variable(tf.random_normal([hidden_layers[1]]), name=""b2"")
            # # # 2ND LAYER
            self.W3 = tf.Variable(tf.random_normal([hidden_layers[1], hidden_layers[2]]), name=""W3"")
            self.b3 = tf.Variable(tf.random_normal([hidden_layers[2]]), name=""b3"")
            # # # OUTPUT LAYER
            self.Wout = tf.Variable(tf.random_normal([hidden_layers[2], num_outputs]), name=""Wout"")
            self.bout = tf.Variable(tf.random_normal([num_outputs]), name=""bout"")
    
            self.hidden_1 = tf.nn.relu(tf.add(tf.matmul(self.X, self.W1), self.b1))
            self.hidden_2 = tf.nn.relu(tf.add(tf.matmul(self.hidden_1, self.W2), self.b2))
            self.hidden_3 = tf.nn.relu(tf.add(tf.matmul(self.hidden_2, self.W3), self.b3))
    
            self.logits = tf.add(tf.matmul(self.hidden_3, self.Wout), self.bout, name='logits')
            self.train_prediction = tf.nn.softmax(self.logits, name='train_prediction')
            self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=self.Y, logits=self.logits), name='loss')
            self.opt = tf.train.GradientDescentOptimizer(0.02).minimize(self.loss)
    
        def fit(self, train_data, train_labels, test_data, test_labels):
            saver = tf.train.Saver()
            with tf.Session() as sess:
                if os.path.exists(""{0}.index"".format(self.model)):
                    try:
                        saver.restore(sess, self.model)
                        print(""Model restored: {0}"".format(self.model))
                    except:
                        print(""Model could not be loaded, starting fresh."")
                else:
                    print(""Initializing Model"")
                    sess.run(tf.initialize_all_variables())
    
                num_epochs = 1000
                batch_size = 128
                for e in range(num_epochs):
    
                    shuffle_indices = np.random.permutation(np.arange(len(train_labels)))
                    train_data = train_data[shuffle_indices]
                    train_labels = train_labels[shuffle_indices]
    
                    # Batch Training
                    for i in range(0, len(train_labels) // batch_size):
                        batch_data = train_data[i * batch_size:(i + 1) * batch_size]
                        batch_labels = train_labels[i * batch_size:(i + 1) * batch_size]
                        _, l = sess.run([self.opt, self.loss], feed_dict={self.X: batch_data, self.Y: batch_labels})
    
                    # PrintOut Epoche Results
                    l_train, predictions_train = sess.run([self.loss, self.train_prediction],
                                                          feed_dict={self.X: train_data, self.Y: train_labels})
                    l, predictions = sess.run([self.loss, self.train_prediction], feed_dict={self.X: test_data, self.Y: test_labels})
                    print(""Ep: {0:4d}\tT_Loss: {1:8.5f}\tT_Acc: {2:4.2f}%\tTR_Loss: {3:8.5f}\tTR_Acc: {4:4.2f}%"".format(
                        e, np.sum(l), accuracy(predictions, test_labels),
                        np.sum(l_train), accuracy(predictions_train, train_labels)))
    
                    if (e &gt; 0) and (e % 10) == 0:
                        saver.save(sess, self.model)
                        print(""Model saved: {0}"".format(self.model))

loading the model:

    model = XModel(train_data.shape[1], train_labels.shape[1],model='models/netA.ckpt')
    model.fit(train_data, train_labels, test_data, test_labels)",2,5
23,2018-7-16,2018,7,16,16,8z8v88,Could I get some insights for my REINFORCE implementation ?,https://www.reddit.com/r/tensorflow/comments/8z8v88/could_i_get_some_insights_for_my_reinforce/,UpstairsCurrency,1531725453,"Hey there ! 

I'm rather a PyTorch user usually, but recently, I came to realize that some of the tools provided by Tensorflow are lacking in PyTorch, so I decided to try and implement some of my favorite algorithms in TF. 

So here I am, writing a REINFORCE agent for the classic CartPole environment. I can't spot any obvious mistake, but my agent doesn't learn anything. Could someone please help me out on this ? 

Here's the link: https://github.com/Mehd6384/QuickExperiments/blob/master/reinforce_tf.py

Thanks a lot ! 

",0,1
24,2018-7-16,2018,7,16,21,8zaga1,Shape mismatch issue with tf.js - tips?,https://www.reddit.com/r/tensorflow/comments/8zaga1/shape_mismatch_issue_with_tfjs_tips/,Berlinsk,1531743684,"Hi, I'm getting my head around tensorflow and am trying to get this CNN for timeseries analysis example by Siraj Raval working, but I keep getting this error on fit() and evaluate() that I can't get rid of.

The layer stack is a sequential setup with a conv, pool, conv, pool, dense structure.

No matter how I change the parameters of the layers, I get the following error message:

""Error: Error when checking target: expected dense\_Dense1 to have shape \[,57,10\], but got array with shape \[1,1960,1\].""

Link to project page: [https://github.com/llSourcell/Financial\_Forecasting\_with\_TensorflowJS](https://github.com/llSourcell/Financial_Forecasting_with_TensorflowJS)

The data and labels are structured as one array of 1960 entries with one dimension each.

The layer shapes look like this:

INPUT SHAPE ,1960,1 OUTPUT SHAPE ,931,8  
INPUT SHAPE ,931,8 OUTPUT SHAPE ,216,8  
INPUT SHAPE ,216,8 OUTPUT SHAPE ,212,16  
INPUT SHAPE ,212,16 OUTPUT SHAPE ,57,16  
INPUT SHAPE ,57,16 OUTPUT SHAPE ,57,10

initialised like this:

        const model = tf.sequential()
        model.add(tf.layers.conv1d({
          inputShape: [data.dates.length, 1],
          kernelSize: 100,
          filters: 8,
          strides: 2,
          activation: 'relu',
          kernelInitializer: 'VarianceScaling'
        }))
        model.add(tf.layers.maxPooling1d({
          poolSize: [500],
          strides: [2]
        }))
        model.add(tf.layers.conv1d({
          kernelSize: 5,
          filters: 16,
          strides: 1,
          activation: 'relu',
          kernelInitializer: 'VarianceScaling'
        }))
        model.add(tf.layers.maxPooling1d({
          poolSize: [100],
          strides: [2]
        }))
        model.add(tf.layers.dense({
          units: 10,
          kernelInitializer: 'VarianceScaling',
          activation: 'softmax'
        }))

If I inspect the model structure, it all seems correctly connected and I can't see anything that's off.

I'm keen on using this model for a prototype project involving timeseries data for a client, but just got stuck here.

If anyone has any tips on where to read about these kinds of issues and could point me in the right direction, I'd be very grateful.",12,4
25,2018-7-17,2018,7,17,0,8zblej,"Does the Dataset api support ""get"" without ""get_next""?",https://www.reddit.com/r/tensorflow/comments/8zblej/does_the_dataset_api_support_get_without_get_next/,st8ic,1531753248,"I have a list of numpy arrays which are my dataset. Right now I'm using `feed_dict`, but of course it is very slow so I'm looking to move to the Dataset api.  

My problem is that I don't want to iterate through the samples on every run of graph op. I want to run an operation with one sample until I'm satisfied, and then move to the next one. The problem is that the dataset api seems to only provide access to the data in the form of `get_next`, which will automatically move the iterator.  

Is there a way to only move the iterator when I'm ready, instead of every time I run an op?",3,1
26,2018-7-17,2018,7,17,17,8zja3z,Realtime JavaScript Face Tracking and Face Recognition using face-api.js MTCNN Face Detector - Medium,https://www.reddit.com/r/tensorflow/comments/8zja3z/realtime_javascript_face_tracking_and_face/,Fewthp,1531814755,,0,6
27,2018-7-17,2018,7,17,23,8zlj74,seq2seq in tensorflow.js?,https://www.reddit.com/r/tensorflow/comments/8zlj74/seq2seq_in_tensorflowjs/,LightBlueParadox,1531837295,"Hi, I'm new to machine learning so if I'm saying something stupid, you know why.

I'd like to make a chatbot using with my whatsapp chats, I used LSTM (in ml5.js), but it just replied with random answers without context.

I've read online that I should use seq2seq, but i also need to run the model in the browser.

I also want to switch to tensorflow.js, so I can learn more stuff about ML, so can i use it to train seq2seq models?",2,1
28,2018-7-17,2018,7,17,23,8zlmlr,Text Classification Models in TensorFlow,https://www.reddit.com/r/tensorflow/comments/8zlmlr/text_classification_models_in_tensorflow/,ganji1055,1531838007,"Implemented famous text classification models in TensorFlow: [https://github.com/dongjun-Lee/text-classification-models-tf](https://github.com/dongjun-Lee/text-classification-models-tf) Implemented models are 1) Word-level CNN, 2) Character-level CNN 3) VDCNN(Very Deep CNN) 4) Word-level Bidirectional RNN 5) Attention-based Bidirectional RNN, 6) RCNN

Semi-supervised Learning for Text Classification(Transfer Learning) is implemented at: [https://github.com/dongjun-Lee/transfer-learning-text-tf](https://github.com/dongjun-Lee/transfer-learning-text-tf)

Here, auto-encoder or language model is used as a pre-trained model to initialize LSTM text classification model.

I hope it helps! Thanks!",1,8
29,2018-7-18,2018,7,18,3,8znvre,How do I use heightwise and widthwise convolutional layers on tensorflow?,https://www.reddit.com/r/tensorflow/comments/8znvre/how_do_i_use_heightwise_and_widthwise/,marrrvvv,1531853263,"I am asking this question under the assumption that in the convolutional, layer defined in tf.layers.conv2d, each node uses the same weights in the filter for all of its inputs. If i am wrong about this, please correct me.

I am trying to build a CNN whose input image has certain pieces of information guaranteed to appear in certain spots of the image. I tried to do it with the convolutional layer defined in tf.layers.conv2d, but didn't accomplished what I meant to. I believe I would have more chances of succeed using a convolutional layer that uses different filters heightwise and widthwise. I tried to find said layer on the tensorflow documentation page, but I only found a depthwise implementation.

Can someone suggest me a way to do this on tensorflow?",1,1
30,2018-7-20,2018,7,20,2,9081ay,tf.estimator: How to normalize features in TensorFlow,https://www.reddit.com/r/tensorflow/comments/9081ay/tfestimator_how_to_normalize_features_in/,crawles89,1532022255,,0,8
31,2018-7-20,2018,7,20,17,90e6qi,Help with tensor containing Boolean values,https://www.reddit.com/r/tensorflow/comments/90e6qi/help_with_tensor_containing_boolean_values/,the_shape89,1532074499,"I'm trying to create an incremental classifier that will get trained on data containing n classes for some set number of epochs, then n+m classes for a set number of epochs, then n+m+k, etc, where each successive set of classes contains the previous set as a subset.

In order to do this without having to train the model, save it, manually edit the graph, re-train, repeat, I'm simply defining all the weights I will need to classify the entire set of classes, but keeping the weights corresponding to unseen classes frozen at 0 until the classifier is introduced to those classes. 

My strategy for this is to define a placeholder that is fed in an array of Boolean values defining whether or not some given set of weights are trainable. 

Relevant code below:

output\_train = tf.placeholder(tf.int32, shape = (num\_incremental\_grps), name = ""output\_train"")

.

.

.

weights = \[\]

biases = \[\]

for i in range(num\_incremental\_grps):

W = tf.Variable(tf.zeros(\[batch\_size, classes\_per\_grp\]), trainable=tf.cond(tf.equal(output\_train\[i\], tf.constant(1)),           
lambda: tf.constant(True), lambda: tf.constant(False)))

weights.append(W)

b = tf.Variable(tf.zeros(\[classes\_per\_grp\]), trainable=tf.cond(tf.equal(output\_train\[i\], tf.constant(1)), lambda:   
tf.constant(True), lambda: tf.constant(False)))

biases.append(b)

out\_weights = tf.stack(weights, axis=1).reshape((batch\_size, -1))

out\_biases = tf.stack(biases, axis=1).reshape((batch\_size, -1))

outputs = tf.identity(tf.matmul(inputs, out\_weights) + out\_biases, name='values')

.

.

.

output\_trainable = np.zeros(num\_incremental\_grps, dtype=bool)

for i in range(num\_incremental\_grps):

output\_trainable\['output':False\]

.

.

.

with tf.Session() as sess:

   init.run()

   for epoch in range(epochs):

for iteration in range(iterations):

X\_batch, y\_batch = batch.getBatch()

fd={X: X\_batch, y: y\_batch, training: True, output\_train: output\_trainable}

\_, loss\_val = sess.run(\[training\_op, loss\], feed\_dict=fd)

This returns the error message

Using a \`tf.Tensor\` as a Python \`bool\` is not allowed. Use \`if t is not None:\` instead of \`if t:\` to test if a tensor is defined,   
and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.

I've tried tinkering around with this, like making the initial placeholder datatype tf.bool instead of tf.int32, but something else seems to be going on and I have no idea what.",0,1
32,2018-7-20,2018,7,20,17,90e8tn,Question about using tensor of Boolean values,https://www.reddit.com/r/tensorflow/comments/90e8tn/question_about_using_tensor_of_boolean_values/,the_shape89,1532075269,"I'm trying to create an incremental classifier that will get trained on data containing n classes for some set number of epochs, then n+m classes for a set number of epochs, then n+m+k, etc, where each successive set of classes contains the previous set as a subset.

In order to do this without having to train the model, save it, manually edit the graph, re-train, repeat, I'm simply defining all the weights I will need to classify the entire set of classes, but keeping the weights corresponding to unseen classes frozen at 0 until the classifier is introduced to those classes.

My strategy for this is to define a placeholder that is fed in an array of Boolean values defining whether or not some given set of weights are trainable.

Relevant code below:

    output_train = tf.placeholder(tf.int32, shape = (num_incremental_grps), name = ""output_train"")
    .
    .
    .
    weights = []
    biases = []
    for i in range(num_incremental_grps):
        W = tf.Variable(tf.zeros([batch_size, classes_per_grp]),         
        trainable=tf.cond(tf.equal(output_train[i], tf.constant(1)),lambda: tf.constant(True), 
            lambda: tf.constant(False)))
        weights.append(W)
        b = tf.Variable(tf.zeros([classes_per_grp]), trainable=tf.cond(tf.equal(output_train[i], 
        tf.constant(1)), lambda:tf.constant(True), lambda: tf.constant(False)))
        biases.append(b)
    
    out_weights = tf.stack(weights, axis=1).reshape((batch_size, -1))
    out_biases = tf.stack(biases, axis=1).reshape((batch_size, -1))
    outputs = tf.identity(tf.matmul(inputs, out_weights) + out_biases, name='values')
    .
    .
    .
    output_trainable = np.zeros(num_incremental_grps, dtype=bool)
    for i in range(num_incremental_grps):
        output_trainable['output':False]
    .
    .
    .
    with tf.Session() as sess:
        init.run()
        for epoch in range(epochs):
            for iteration in range(iterations):
                X_batch, y_batch = batch.getBatch()
                fd={X: X_batch, y: y_batch, training: True, output_train: output_trainable}
                _, loss_val = sess.run([training_op, loss], feed_dict=fd)

This returns the error message

    Using a 'tf.Tensor' as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined,and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.

I've tried tinkering around with this, like making the initial placeholder datatype tf.bool instead of tf.int32, but something else seems to be going on and I have no idea what. Any help would be much appreciated.",2,1
33,2018-7-20,2018,7,20,20,90fac0,Real-time learning w/ tensorflow,https://www.reddit.com/r/tensorflow/comments/90fac0/realtime_learning_w_tensorflow/,ddzhulay,1532087101,"Hey :)  I'm just interested is there any other (better) way to train model online with new data, than storing new samples locally and retraining?",4,2
34,2018-7-21,2018,7,21,20,90osbx,A Simpe Neural network with Tensorflow-Keras using Colaboratory,https://www.reddit.com/r/tensorflow/comments/90osbx/a_simpe_neural_network_with_tensorflowkeras_using/,machinelearning147,1532174266,,0,9
35,2018-7-21,2018,7,21,22,90pg8k,"How many variable updates per batch using a convolutional layer? One per conv. x,y position of the kernel?",https://www.reddit.com/r/tensorflow/comments/90pg8k/how_many_variable_updates_per_batch_using_a/,kit_hod_jao,1532181429,"Hi, I wondered if someone could answer this question for me. I've not been able to find the answers in the documentation. 

I've got a network with two inputs of dissimilar size. One input is passed to a convolutional layer (specifically tf.nn.conv2d). The other to a non-convolutional layer (tf.layers.dense). 

My question is about balancing the learning rates of the conv and non conv layers, because this could affect the performance of my algorithm. 

For the purpose of the example let's say the output of the conv layer is:

 [b, h,w, d]

This means the conv kernel, ie the variable being learned, is applied at w * h positions per batch sample, or b * w * h times in total over a whole batch.

What I'm not clear on is how many weight updates are applied. I'm assuming that the gradients are averaged over the batch - are they averaged over the w and h as well? Or does it perform w*h updates per batch?

Depending on the answer to the above, do I need to increase the non-conv learning rate by w * h to make the two learn at the same rate?

I don't really care that they are exactly the same (I'm using Adam anyways), but I don't want to introduce a systematic bias on relative learning rate that depends on the size of the convolutional layer. 

Any help much appreciated.  Cheers!",5,4
36,2018-7-22,2018,7,22,6,90si1s,Signing With Alexa: A DIY Experiment in AI Accessibility,https://www.reddit.com/r/tensorflow/comments/90si1s/signing_with_alexa_a_diy_experiment_in_ai/,trcytony,1532206891,,0,1
37,2018-7-22,2018,7,22,12,90v4lm,Can adding dropout decrease training accuracy when the code runs well without dropout,https://www.reddit.com/r/tensorflow/comments/90v4lm/can_adding_dropout_decrease_training_accuracy/,2Ran3Sel,1532231473,"Hello!

I am testing my CNN code on CIFAR-10 images.

I used three conv layers, two maxpool layers, and one dense layer.

Without dropout, the code reaches 100% training accuracy at 300-400 epoch and shows 50-60% of testing accuracy with a new dataset- even though I'm not sure 60% of testing accuracy can be called 'working well.' --&gt; Here is the code: [https://gist.github.com/AudieLee/e4e51695df1b29ef8e34b6e3e45e9bb9](https://gist.github.com/AudieLee/e4e51695df1b29ef8e34b6e3e45e9bb9)

But when I add a dropout in a dense layer, the training accuracy decreases to around 12%(60-&gt;12%...?), a plataeu, despite hours of running. --&gt; Here is the code: [https://gist.github.com/AudieLee/ee3aaa3090eb21f0a072904ae798686d](https://gist.github.com/AudieLee/ee3aaa3090eb21f0a072904ae798686d)

Given the fact that the code runs without dropout, I thought the preprocessing and the structure themselves weren't problem, so I tried changing epoch, learning rate, strides, and keep\_prob. But none worked.

What am I supposed to do?

Thank you.",8,2
38,2018-7-22,2018,7,22,14,90vpwa,Latest TensorFlow Release 1.9 is Out! Let us upgrade,https://www.reddit.com/r/tensorflow/comments/90vpwa/latest_tensorflow_release_19_is_out_let_us_upgrade/,DecipherTechnic,1532238415,,1,15
39,2018-7-22,2018,7,22,22,90xuli,"[Q] Cross Entropy Implementation Tensorflow, Wierd Behavior.",https://www.reddit.com/r/tensorflow/comments/90xuli/q_cross_entropy_implementation_tensorflow_wierd/,Jonas_SV,1532267338,"I've implemented CEM in tensorflow https://github.com/JonasRSV/CEM_Tensorflow

While training it on the cartpole AIGym i noticed wierd behavior. 

https://imgur.com/a/oLK01Yo 
https://imgur.com/a/v4pA4PQ

After each training epoch i sample new weights for each agent using https://www.tensorflow.org/api_docs/python/tf/distributions/Normal

All agents share means and std deviation across each of their weights and after sample'ing fitnesses for all agents i take the top X percent and calculate new means and std-deviations for each weigth. 

The wierd behavior arises when i sample new std-dev and means for each weights. 

As seen on the graphs above every 2'nd sample has very high mean and variance and every 2'nd has very low mean and variance.. 

What's also interesting is that the fitness of the best agent correlates exactly to these spikes aswell.. when the mean and variance spikes so does the fitness and vice-versa.. 

Any insights as to what i've done wrong in my implementation or any other ideas would be super appreciated! :) ",4,3
40,2018-7-23,2018,7,23,8,911yfp,What are the pros and cons of the different installation methods?,https://www.reddit.com/r/tensorflow/comments/911yfp/what_are_the_pros_and_cons_of_the_different/,pgbabse,1532301011,"Hello, I want to reinstall tensorflow and wanted to know what the advantages or disadvantages between the different methods are. 

As tensorflow is an api for python, it affects the python environment.
Could someone elaborate what the difference are between:

Tensorflow/Python pip installer

Tensorflow/Python anaconda installer

Tensorflow/Python in virtual environments

Tensorflow/Python in Docker image",2,6
41,2018-7-23,2018,7,23,9,912dwq,I am new to programming and trying to install tensorflow models repo,https://www.reddit.com/r/tensorflow/comments/912dwq/i_am_new_to_programming_and_trying_to_install/,PhoebusElpollo,1532304763,"I followed the steps in the tutorial, with the python classify image.py, but i keep getting the error ImportantError: Could not find 'cudart64_90.dll. I have installed CUDA 9.0, but I can't find the cudart thing",4,4
42,2018-7-24,2018,7,24,2,918vu5,Beginner dataset for photo classification?,https://www.reddit.com/r/tensorflow/comments/918vu5/beginner_dataset_for_photo_classification/,newwenha,1532365733,"Beginner here following Google's Tensorflow tutorial. It has photo classification for 5 different types of flowers. I want to see other applications and was wondering if there is a free dataset of already sorted pictures in jpeg (boy/girl, races, animals, etc). Thanks!",4,2
43,2018-7-24,2018,7,24,12,91dxld,"Are you interested in Computer Science and want to start learning more with Tutorials? Check out this new Youtube Channel, called Discover Artificial Intelligence. :)",https://www.reddit.com/r/tensorflow/comments/91dxld/are_you_interested_in_computer_science_and_want/,ailearn12,1532403465,,0,9
44,2018-7-26,2018,7,26,13,91zb6n,Tensor back into std::vector in C++?,https://www.reddit.com/r/tensorflow/comments/91zb6n/tensor_back_into_stdvector_in_c/,magkum123,1532580940,Is anyone aware of how can I convert the data of a tensor into a std::vector efficiently? or even naively?,0,5
45,2018-7-26,2018,7,26,22,922c9w,What shape for images?,https://www.reddit.com/r/tensorflow/comments/922c9w/what_shape_for_images/,greenbluewhite,1532612390,"I am using TF with the Inception\_V3 model to recognize interesting scenes from a surveilance camera.  The raw images are about 430x240 pixels, an aspect ratio of 1.8:1.   My understanding is that Inception wants images 299x299 pixels.  My code currently resizes the images to 299x166 thus preserving the aspect ratio.  It does work, but I wonder if instead *stretching* the images vertically to 299x299 would make better use of the CNN and thus give better accuracy.  Or does it already do this internally?

So far my training material is 24,000 images in 10 categories.  16,000 of those are in the 'nothing' category, meaning that nothing interesting is in the picture - just the yard, street, trees, and shadows.  My current problem is that the shadows are being recognized as objects like ""car"", ""people walking by"" etc.  It is very good at spotting the mail truck, which is large and white, and can distinguish it from the garbage truck, which is larger and grey.",0,3
46,2018-7-28,2018,7,28,7,92gt6u,Binary classification tutorials/documentation,https://www.reddit.com/r/tensorflow/comments/92gt6u/binary_classification_tutorialsdocumentation/,imjacobclark,1532728849,"Could soembody point me in the right direction to some good quality binary classification tutorials? Ideally ones that don't focus on image classification but more on text based feature classification e.g things like the Titanic dataset. 

Thanks ",1,0
47,2018-7-28,2018,7,28,18,92kysf,Can someone please explain what is happening in the Tensorflow playground?,https://www.reddit.com/r/tensorflow/comments/92kysf/can_someone_please_explain_what_is_happening_in/,lakshaydulani,1532770696,"[playground.tensorflow.org](https://hashnode.com/util/redirect?url=https://playground.tensorflow.org/)

I am a ML beginner.  I can understand some basics in the playground like all the layers are  working to classify in different directions i.e horizontal, vertical,  slant.

But still it would be better if someone can write a post which can walkthru newbies with the basic nit bits of whats happening in there?",2,5
48,2018-7-28,2018,7,28,22,92m357,Understanding Tensorflow's tensors shape: static and dynamic,https://www.reddit.com/r/tensorflow/comments/92m357/understanding_tensorflows_tensors_shape_static/,pgaleone,1532784222,,0,1
49,2018-7-29,2018,7,29,9,92qwn7,How do I create heatmaps with TensorFlow? What do I search to develop something to get something like the middle part of the image?,https://www.reddit.com/r/tensorflow/comments/92qwn7/how_do_i_create_heatmaps_with_tensorflow_what_do/,thevbob,1532824575,,0,1
50,2018-7-29,2018,7,29,9,92qyys,Extracting 'heatmaps' with TensorFlow,https://www.reddit.com/r/tensorflow/comments/92qyys/extracting_heatmaps_with_tensorflow/,thevbob,1532825175,"Hello!   


I have successfully used a pretrained model to do object detection with tf.slim, and now I want to understand how the model works. Something I've seen that I want to do is to extract the 'heatmap', like the middle section of  the image abov.

https://i.redd.it/fby1usdo9sc11.png

What do I search in order to be able to extract something like it from the model I've used? The CNN should be specifically made and trained to export this info? I am a noob still, so I don't have the slightest idead of how this works haha  


Thanks in advance.",2,9
51,2018-7-29,2018,7,29,15,92stwd,Experimenting with Tensorflow.js,https://www.reddit.com/r/tensorflow/comments/92stwd/experimenting_with_tensorflowjs/,i_am_adl,1532844862,"Hello Everyone,

I have been experimenting on Tensorflow.js for sometime , I would like to Share my Learnings with the Community.

We know that An increasing number of developers are using TensorFlow in their machine learning projects. In March this year, the TensorFlow team at Google announced the arrival of the much-awaited JavaScript framework, TensorFlow.js (which was previously called DeepLearn.js).

Now developers can build lightweight models and run them in the browser using JavaScript. Lets understand what the need was for the development of this framework.

## History

Before going to TensorFlow.js, I would like to start off with TensorFlow.

TensorFlow was developed in 2011 at Google as their propitiatory library for Machine learning/Deep learning applications at Google. This library was open sourced in 2015 under the Apache License.

TensorFlow is built in C++, which enables the code to execute at a very low level. TensorFlow has bindings to different language like Python, R, &amp; Java. This enables TensorFlow to be used in these languages.

So, the obvious question is: what about JavaScript?

Conventionally, in JavaScript, ML/DL was performed by using an API. An API was made using some framework, and the model was deployed at the server. The client sent a request using JavaScript to get results from the server.

[Client Server Architecture](https://i.redd.it/n3p7iuiiotc11.png)

In 2017, a project called Deeplearn.js appeared, which aimed to enable ML/DL in JavaScript, without the API hassle.

But there were questions about speed. It was very well known that JavaScript code could not run on GPU. To solve this problem, WebGL was introduced. This is a browser interface to OpenGL. WebGL enabled the execution of JavaScript code on GPU.

In March 2018, the DeepLearn.js team got merged into the TensorFlow Team at Google and was renamed TensorFlow.js.

Watch the below video for further details:

[https://youtu.be/qa1OXssGBHw](https://youtu.be/qa1OXssGBHw)

## TensorFlow.js

Tensorflow.js provides two things:

* The CoreAPI, which deals with the low level code
* LayerAPI is built over the CoreAPI, and makes our lives easier by increasing the level of abstraction.

## Getting Started

There are two main ways to get TensorFlow.js in your project:

## 1. via &lt;script&gt;Tag

Add the following code to an HTML file:

    &lt;html&gt;
    &lt;head&gt;
      &lt;!-- Load TensorFlow.js --&gt;
        &lt;script src=""https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.12.0""&gt; &lt;/script&gt;
      &lt;/head&gt;
        &lt;body&gt;
          Hello
      &lt;/body&gt;
    &lt;/html&gt;

## 2. viaNPM

Add TensorFlow.js to your project using yarn or npm.

    yarn add @tensorflow/tfjs  
    npm install @tensorflow/tfjs   

In your main js file:

    import * as tf from '@tensorflow/tfjs';   

## CoreAPI

## 1. Tensors

So, what is a Tensor?

[Visual Representation of Scalar,Vector,Matrix and Tensor](https://i.redd.it/5v3orjdpotc11.jpg)

* A scalar is a single number. For example, x = 1
* A vector is an array of numbers. For example, *x*=\[1,2\]
* A matrix is a 2-D array =&gt; (\[\[1, 2\],\[3, 4\],\[5, 6\]\])
* A tensor is a \*n-\*dimensional array with *n*\&gt;2

TensorFlow.js has utility functions for common cases like Scalar, 1D, 2D, 3D and 4D tensors, as well a number of functions to initialize tensors in ways useful for machine learning.

## Code Examples

**tf.tensor():**

    // Pass an array of values to create a vector.   
    tf.tensor([1, 2, 3, 4]).print();  

**tf.scalar():**

    tf.scalar(3.14).print();   

And so on

Watch the Below Video to get a deep insight into Tensors in TensorFlow.js:

[https://youtu.be/sZrwxnIfHCo](https://youtu.be/sZrwxnIfHCo)

## 2. Variables &amp; Operations

Tensors are immutable data structures. That means their values cant be changed once they are set.

However, tf.variable()is introduced in TensorFlow.js. The real use case for tf.variable()is when we need to change the data frequently, such as when adjusting model weights in Machine Learning.

Code sample:

    const x = tf.variable(tf.tensor([1, 2, 3]));   
    x.assign(tf.tensor([4, 5, 6]));  
     x.print();   

## Operations

There are various operations in TensorFlow.js. In order to perform mathematical computation on Tensors, we use operations. Tensors are immutable, so all operations always return new Tensors and never modify input Tensors. So tf.variable()can be used in order to save memory.

Lets look into some operations:

**tf.add()Adds two** [**tf.Tensor**](https://js.tensorflow.org/api/0.12.0/#class:Tensor)**s element-wise**

    const a = tf.tensor1d([1, 2, 3, 4]);   
    const b = tf.tensor1d([10, 20, 30, 40]);  
     a.add(b).print();  // or tf.add(a, b)   

There are many operations in TensorFlow.js. You can check the [documentation](https://js.tensorflow.org/api/0.12.0/#Operations)for other operations. I will demonstrate one more operation here: **tf.matmul()**

**tf.matmul()Computes the dot product of two matrices, A \* B.**

    const a = tf.tensor2d([1, 2], [1, 2]);   
    const b = tf.tensor2d([1, 2, 3, 4], [2, 2]);  
    a.matMul(b).print();  // or tf.matMul(a, b)   

Watch the below video for deep insight into Variable and Operations:

[https://youtu.be/AP1BmP0BZmQ](https://youtu.be/AP1BmP0BZmQ)

## 3. Memory Management

Memory management is the key in Machine Learning/Deep Learning tasks, because they are generally computationally expensive.

TensorFlow.js provides two major ways to manage memory:

1. tf.dispose()
2. tf.tidy()

They both typically do the same thing, but they do it in different ways.

## tf.tidy()

This executes the provided function function and after it is executed, cleans up all intermediate tensors allocated by function except those returned by function.

tf.tidy() helps avoid memory leaks. In general, it wraps calls to operations in [tf.tidy()](https://js.tensorflow.org/api/0.12.0/#tidy) for automatic memory cleanup.

Code example:

    const y = tf.tidy(() =&gt; {
        // aa, b, and two will be cleaned up when the tidy ends.
    
        const two= tf.scalar(2); 
        const aa = tf.scalar(2); 
        const b = aa.square();
    
        console.log('numTensors (in tidy): ' + tf.memory().numTensors);
    
        // The value returned inside the tidy function will return // through the tidy,     in this case to the variable y. 
    
        return b.add(two); 
    });
    
    console.log('numTensors (outside tidy): ' + tf.memory().numTensors); y.print();
    tf.dispose()

Disposes any [tf.Tensor](https://js.tensorflow.org/api/0.12.0/#class:Tensor)s found within the mentioned object.

Code example:

    const two= tf.scalar(2);   
    two.dispose()   

## LayersAPI

Layers are the primary building block for constructing a ML/DL Model. Each layer will typically perform some computation to transform its input to its output. Under the hood, every layer uses the CoreAPI of Tensorflow.js.

Layers will automatically take care of creating and initializing the various internal variables/weights they need to function. So, basically it makes life easier by increasing the level of abstraction.

We will make a simple example feed forward network using the LayerAPI. The Feed Forward network we will build is as below:

*Processing gif cf4h6msywtc11...*

## Code:

**Index.html**

    &lt;html&gt;
    &lt;head&gt;
    &lt;title&gt;
    &lt;/title&gt;    
       &lt;script src=https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.12.0""&gt; &lt;/script&gt;
    &lt;script src=main.js type=text/javascript&gt;&lt;/script&gt;
    &lt;/head&gt;
    &lt;body&gt;
    Tensorflow JS Demo
    &lt;/body&gt;
    &lt;/html&gt;

**main.js**

    const model = tf.sequential();
    
    //config for layer
    const config_hidden = {
      inputShape:[3],
      activation:'sigmoid',
      units:4
    }
    const config_output={
      units:2,
      activation:'sigmoid'
    }
    
    //defining the hidden and output layer
    const hidden = tf.layers.dense(config_hidden);
    const output = tf.layers.dense(config_output);
    
    //adding layers to model
    model.add(hidden);
    model.add(output);
    
    //define an optimizer
    const optimize=tf.train.sgd(0.1);
    
    //config for model
    const config={
    optimizer:optimize,
    loss:'meanSquaredError'
    }
    
    //compiling the model
    model.compile(config);
    
    console.log('Model Successfully Compiled');
    
    //Dummy training data
    const x_train = tf.tensor([
      [0.1,0.5,0.1],
      [0.9,0.3,0.4],
      [0.4,0.5,0.5],
      [0.7,0.1,0.9]
    ])
    
    //Dummy training labels
    const y_train = tf.tensor([
      [0.2,0.8],
      [0.9,0.10],
      [0.4,0.6],
      [0.5,0.5]
    ])
    
    //Dummy testing data
    const x_test = tf.tensor([
      [0.9,0.1,0.5]
    ])
    
    train_data().then(function(){
      console.log('Training is Complete');
      console.log('Predictions :');
      model.predict(x_test).print();
    })
    
    async function train_data(){
      for(let i=0;i&lt;10;i++){
      const res = await model.fit(x_train,y_train,epoch=1000,batch_size=10);
       console.log(res.history.loss[0]);
      }
    }

Output:

[Output of the Code](https://i.redd.it/x5cvtzivntc11.png)

Pls watch the below videos for deep insight and code explanation:

[https://youtu.be/z2u-s3NzHhY](https://youtu.be/z2u-s3NzHhY)

[https://youtu.be/lKWUSkwOR5s](https://youtu.be/lKWUSkwOR5s)

## My take onthis

This is excellent for coders who are familiar with JavaScript and are trying to find their way in the ML/DL world!

It makes things a lot simpler for people coming from a non-ML/DL background, but who are looking to understand this field. The use cases for this are many, and I personally think its something we need at the moment.

What do you think about TensorFlow.js? Let me know in the comments section below.

**Thanks For Reading and Giving your Precious Time**",1,10
52,2018-7-30,2018,7,30,12,930hiq,Multiple choice test questionnaire,https://www.reddit.com/r/tensorflow/comments/930hiq/multiple_choice_test_questionnaire/,ccfiel,1532919613,I want to be able to check answer sheets automatically. I myself created the questionnaire so I have the control over the format of the questionnaire and the answer sheet. The questionnaire is multiple choice type and the examinees will just shade the appropriate box corresponding to their answer. My idea is to scan or take a picture of the answer sheet and use TensorFlow to identify the answers selected by the examinees. The answer sheet is printed on paper. Is TensorFlow the right tool to achieve this? Any ideas are very much welcome. ,3,0
53,2018-7-30,2018,7,30,16,931x5d,ResourceExhaustedError that makes no sense,https://www.reddit.com/r/tensorflow/comments/931x5d/resourceexhaustederror_that_makes_no_sense/,ME_PhD,1532934404,"I'm using transfer learning from VGG in TF. I stripped the last layer and made my own small ones.

    fc7 = tf.contrib.layers.fully_connected(fc6, 16)
    fc7dropped = tf.nn.dropout(fc7, keep_prob=hold_p)
    yhat = tf.nn.softmax(tf.contrib.layers.fully_connected(fc7dropped, 2, activation_fn=None))

then my loss functions:

    losses = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=yhat)
    loss = tf.reduce_mean(losses)

Trains fine. When I do
    print(session.run(loss, feed_dict={x:x_train, y:y_train, hold_p:1.0}))

It works no problem. However, when I try
    print(session.run(yhat, feed_dict={x:x_train, hold_p:1.0}))

I get 
`ResourceExhaustedError: OOM when allocating tensor of shape [4096] and type float
	 [[Node: add_13/y = Const[dtype=DT_FLOAT, value=Tensor&lt;type: float shape: [4096] values: -0.188697636 0.126556993 -0.29960382...&gt;, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]`

This makes no sense because to compute ""loss"" it must compute ""yhat"". Why would it work fine for ""loss"" but not for ""yhat""? I even lowered the batch size from 8 to 2 and I still get the same error. Can anyone figure it out?
",2,1
54,2018-7-30,2018,7,30,18,932s0q,Translation model with Dataset shape problem,https://www.reddit.com/r/tensorflow/comments/932s0q/translation_model_with_dataset_shape_problem/,albert1905,1532944705,"I'm trying to build a translation model, so I'm getting a text as input, I'm encoding him to a list of integers (the type of enocding is not important).so far so good.
let's say this is what I have so far.
&lt;class 'list'&gt;: [1645, 3, 205, 753, 753, 1332, 18, 7, 7, 24]

Now I want to do this lines:
ds = tf.data.Dataset.from_tensors(encoded_txt)
ds = ds.batch(32)
(btw why do we need the first line, just to be able to do the second?)

But from this lines I'm getting shape=(?,32) , and I don't understand why? I have a batch size of 32 and 10 numbers, why isnt it (1,32) (with paddings or something)???
This impacts me after on in the code, I really need to understand how to handle this.

btw just reshape isn't working :(

Thanks!",0,1
55,2018-7-30,2018,7,30,21,933glc,Concatenated ReLU (CReLU) the cause for slow performance?,https://www.reddit.com/r/tensorflow/comments/933glc/concatenated_relu_crelu_the_cause_for_slow/,MogwaiAllOnYourFace,1532952032,"I have implemented a semantic segmentation model, using CReLU on the first two downsampling layers, however when using CReLU inference speed drops massively.

FPS goes from approximately 42 to 12. 

CReLU doubles the number of output channels, however I take this into account and half the number of filters, such that the output is equal in dimension. It seems to me like this should be quicker, that is performing a positive and negative ReLU and concatenating them together, rather than calculating an increase in convolution filters.

I have tried looking for similar experiences but found nothing. Can anyone share any insight on this?",0,5
56,2018-7-30,2018,7,30,23,934c1b,GPU and bottlenecking?,https://www.reddit.com/r/tensorflow/comments/934c1b/gpu_and_bottlenecking/,T-O-M-52,1532959535,"Now iam I bit of a noob, I know but if I was using the GPU version of tensorflow  on a pc that has a great graphics card but just an old CPU and about 4gb of ram would my program still run fine? 
I only need the pc for tensorflow so the pc wouldn't need to be fast.
Thanks in advance.",8,1
57,2018-7-31,2018,7,31,0,934vuh,What's wrong w/ my GAN graph?,https://www.reddit.com/r/tensorflow/comments/934vuh/whats_wrong_w_my_gan_graph/,ddzhulay,1532963531,"Hey! I'm trying to train vanilla GAN without using tfgan (just for experience). I'm using minimax loss and quiet simple (not convolutional) architecture for my generator and discriminator. But after first three training steps my generator loss is nearby -1 (completely useless) and discriminator loss is almost 0. And I think that problem is in the graph, due to the fact that when I'm using tfgan.gan\_model with same generator, discriminator and loss functions I get great results. But I don't know where I've mistaken... :(",0,4
58,2018-7-31,2018,7,31,1,935puj,trying to design custom estimators,https://www.reddit.com/r/tensorflow/comments/935puj/trying_to_design_custom_estimators/,kei_kuro,1532969259,"In a pre-made Estimator, the general blueprints are:

1) define the feature\_columns

2) initialize the model using feature\_columns,

3) write an input\_fn which converts a data source such as a Dataset to a mapping of features and labels.

The feature\_columns are passed in as an argument to the pre-made Estimator. So far so good.

When I tried to make a custom Estimator, this control flow doesnt work anymore because model\_fn (step 2) requires feature\_columns (step 1) and features (step 3). Well, to be more precise, you pass in features as a parameter and use feature\_columns as a global variable or something, and the input layer requires both features and feature\_columns. I think in one tutorial they defined feature\_columns inside model\_fn, which is inconsistent with how the pre-made Estimators work.

Im planning to define a class to act as a wrapper around the Estimator. That way I can do something like:

```python
class Custom(tf.estimator.Estimator): 
    def \_\_init\_\_(self):
        self.feature\_columns = INITIALIZE HERE
        super().\_\_init\_\_(model\_fn=self.model\_fn)

    def model\_fn(self, features, labels, mode, params):
        net = input\_layer(features, self.feature\_columns)
        ...
```

Does this seem like a good idea, or am I missing something?",0,3
59,2018-7-31,2018,7,31,2,936azv,CNN Classifier tutorial,https://www.reddit.com/r/tensorflow/comments/936azv/cnn_classifier_tutorial/,imjacobclark,1532973203,"I'm looking for an example/tutorial of a CNN Classifier that does not work on images, but text based features and classifications. 

For example, I'm interested in seeing a TF CNN that works on a dataset similiar to the Titanic passengers dataset.",1,4
60,2018-7-31,2018,7,31,20,93dk5r,Tensorflow for AMD GPU?,https://www.reddit.com/r/tensorflow/comments/93dk5r/tensorflow_for_amd_gpu/,Jandevries101,1533035535,"Hey,

i have a AMD GPU is it then still possible for me to use tensorflows gpu version?

If so i know it should be done diffrent then the normal way, atleast from what i've heard.... 

any idea's?

Jan",6,1
61,2018-7-31,2018,7,31,20,93drtc,Can I get some help for the sequence prediction model lstm-based ?,https://www.reddit.com/r/tensorflow/comments/93drtc/can_i_get_some_help_for_the_sequence_prediction/,UpstairsCurrency,1533037673,"Hello, 

I'm trying to predict sequences using the LSTM modules of tensorflow, but to no avail. I can't figure out the problem and I was hoping someone could lend me a helpful hand. Here's my code: 

First I mostly create synthetic data, and prepare the dataloader


    import tensorflow as tf 
    import numpy as np 
    import matplotlib.pyplot as plt 
    plt.style.use('dark_background')

    x = np.linspace(0,30.,500)
    y = x*np.sin(x) + 2*np.sin(5*x)
    nb_steps = 20

    def load_batch(batch_size = 32): 

	    x_b = np.zeros((nb_steps,batch_size,1))
	    y_b = np.zeros((nb_steps*batch_size,1))

	    inds = np.random.randint(0, 479, (batch_size))
	    for i,ind in enumerate(inds): 
		    x_b[:,i,0] = x[ind:ind+nb_steps]
		    y_b[i*nb_steps:(i+1)*nb_steps,0] = y[ind+1:ind+nb_steps+1]

	    return x_b, y_b

Some shortcuts 


    adam = tf.train.AdamOptimizer
    layers = tf.layers
    dense = layers.dense
    lstm = tf.contrib.rnn.LSTMCell
    batch_size = 64

Then, comes the part where I create the model 


    with tf.variable_scope('data'): 

	    x_p = tf.placeholder(tf.float32, shape = [nb_steps, None, 1], name = 'x') # batch, steps, features 
	    y_p = tf.placeholder(tf.float32, shape = [None, 1], name = 'labels')

    with tf.variable_scope('network'): 

	    cell = lstm(num_units = 100)
	    outputs, states = tf.nn.dynamic_rnn(cell, x_p, dtype = tf.float32, time_major = True)


	    reshaped_outputs = tf.reshape(outputs, [-1,100])
	    projection = dense(reshaped_outputs, 1, activation = None, name = 'projection')

Just above is the part I'm the least certain of. I reshape the output of the lstm for each time step and stack them on the first axis (or do I ?). I then send the whole matrix in a linear layer. 



    with tf.variable_scope('training'): 

	    loss = tf.reduce_mean(tf.square(projection - y_p))
	    train_lstm = adam(1e-3).minimize(loss)


Afterward, the rest consits on running and plotting

  
    epochs = 1000
    batch_size = 64
    f, ax = plt.subplots(2,1)
    with tf.Session() as sess:

	    sess.run(tf.global_variables_initializer())

	    mean_loss = 0. 
	    for epoch in range(1,epochs+1): 


		    x_b,y_b = load_batch(batch_size)

		    batch_loss,_ = sess.run([loss, train_lstm], feed_dict = {x_p:x_b, y_p:y_b})

		    mean_loss += batch_loss
	
		    if epoch%100 == 0: 
			    print('Epoch: {} | Loss: {:.6f}'.format(epoch, mean_loss/100.))
			    mean_loss = 0. 

	    while True : 

		    x_b, y_b = load_batch(1)
		    pred = sess.run(projection, feed_dict = {x_p:x_b}).reshape(-1)

		    ax[0].plot(x,y, label= 'Real')
		    ax[0].plot(x_b.reshape(-1),y_b.reshape(-1), label= 'Real batch')
		    ax[0].plot(x_b.reshape(-1), pred, label = 'Pred')

		    ax[1].scatter(x_b.reshape(-1),y_b.reshape(-1), label= 'Real')
		    ax[1].scatter(x_b.reshape(-1), pred, label = 'Pred')

		    for a in ax: a.legend()

		    plt.pause(0.1)
		    input()

		    for a in ax: 
			    a.clear()

Thanks a lot ! ",1,3
0,2018-8-2,2018,8,2,5,93sw78,When in the pipeline should data be vectorized?,https://www.reddit.com/r/tensorflow/comments/93sw78/when_in_the_pipeline_should_data_be_vectorized/,kei_kuro,1533156725,"Hi, I'm trying to learn the TensorFlow API, but I'm coming from PyTorch, so some things aren't translating cleanly. If I could get some clarifications, that would be great.

I want to use the Estimator API, and let's say that I have raw data in a .csv file with ints, floats, and strings. It seems like the Dataset allows you to map a csv row into a feature, either as a tensor directly or as a feature_column, which is later converted into a tensor. At this stage, I can only perform tf operations on the string data, making more sophisticated string preprocessing difficult. Some things that would be nice are incorporating NER tagging or POS tagging from SpacyNLP for instance.

Is this just the wrong place to do any preprocessing? I can imagine it's not so hard to vectorize / preprocess in pure Python before reading it with the Dataset API, but this won't leverage TensorFlow. I'd appreciate any help! Thanks",2,1
1,2018-8-2,2018,8,2,5,93swas,Object-oriented reusable TF models using tf.data.Dataset,https://www.reddit.com/r/tensorflow/comments/93swas/objectoriented_reusable_tf_models_using/,nschejtman,1533156744,"I find many problems when trying to structure my TensorFlow model in an object oriented fashion, in particular while using tf.data.Dataset. Ideally my model exposes the following interface:

```
class MyModel:
    def fit(self, x):
        pass
    def transform(self, x):
        pass
```
Pretty straight forward. The problems come while using tf.data.Dataset.

tf.data.Dataset reads data from a variety of sources and produces Tensors as outputs. These Tensors can then be multiplied, added, etc. to the other Tensors composing your computation graph. The problem is that this couples the Tensors produced by your Dataset in your computation graph. This breaks this object-oriented interface because ideally I would like to call the fit and transform methods on different Datasets without having to construct a new computation graph every time.

Does some one have any solution to this issue?",0,1
2,2018-8-2,2018,8,2,8,93u47s,is there a beta for python 3.7?,https://www.reddit.com/r/tensorflow/comments/93u47s/is_there_a_beta_for_python_37/,whirl_and_twist,1533165643,"I don't want to downgrade my python, its already so well set-up and clean. ",4,6
3,2018-8-2,2018,8,2,11,93vf3n,Is threading in Python can make real parallelism in TensorFlow?,https://www.reddit.com/r/tensorflow/comments/93vf3n/is_threading_in_python_can_make_real_parallelism/,AlexanderYau,1533177097,"Actually in Python threading cannot make real parallelism, and in TensorFlow does it possible to make multi threads run parallel?",7,2
4,2018-8-2,2018,8,2,18,93xnt2,"Realtime gesture classification using LSTM Neural Network, quick Question",https://www.reddit.com/r/tensorflow/comments/93xnt2/realtime_gesture_classification_using_lstm_neural/,shyrzaza,1533200513,"Hey guys, I have a stupid Question...

I am doing hand gesture recognition based of EMG Data that I aquired. I set the sequence length to 40 frames, recorded some gestures, labeld the sequence according to the gesture performed. I then proceeded to train a simple LSTM Recurrent Neural Network, and I am able to do predictions quite well. However, my prediction data so far has been other 40 frame long prerecorded gestures. 
Now I want to go ahead and do real time gesture recognition and I have one big question:

Do I need to take the whole last 40 frames and put it into my Network to do the prediction EVERY frame?

Because I thought, that now I could somehow throw the data of single frames sequentially into my Network, and at each timestep I could see how high the predictionvalues are...?

I am quite new to tensorflow and machine learning, so sorry if this is a stupid question.

Love, 
shyrzaza",2,2
5,2018-8-2,2018,8,2,23,93zo1r,toco removed --quantize_weights?,https://www.reddit.com/r/tensorflow/comments/93zo1r/toco_removed_quantize_weights/,chris-paterson,1533219595,"Hey! I'm trying to reduce the size of my tflite graph and came across the `--quantize_weights` flag in `toco`. I've found that I had to roll back to Tensorflow v1.7 to get it working. I've looked around to see why it was removed but I couldn't find anything.

Does anyone know why `--quantize_weights` isn't available in Tensorflow v1.9, and if it will be added in the future?

Thanks!",0,2
6,2018-8-3,2018,8,3,1,940m66,Training and Serving ML models with tf.keras,https://www.reddit.com/r/tensorflow/comments/940m66/training_and_serving_ml_models_with_tfkeras/,derniu,1533226194,,1,10
7,2018-8-3,2018,8,3,5,942ofa,Desenvolvimento de IA [PT-BR] [ING],https://www.reddit.com/r/tensorflow/comments/942ofa/desenvolvimento_de_ia_ptbr_ing/,Ianetta,1533240071,"Bom dia/tarde/noite.  
No tenho nenhum conhecimento a respeito de IA e nem de programao, mas estou comeando a estudar...

Gostaria de desenvolver uma IA para fins que se adequem a necessidade do usurio, uma companhia, uma assistente, um buscador, ( um assistente para dominar o mundo ) tanto faz, pois o usurio que iria escolher a qual fim ser usado.

A pouco li que o TensorFlow  uma plataforma do Google Open Source, e gostaria de saber se existem outros Open Source que possam ajudar a desenvolver essa ideia.

Minha ideia  de desenvolver a IA para ser usada entre Smartphones, Tablets, Notebooks, uma IA que poderia ser usada por at mesmo 2 usurios ou mais, tendo uma interao entre os usurios a IA saberia quem ela , mas poderia conversar livremente entre os usurios, como um usurio, qualquer indicao de plataforma, comentrio ou ajuda  bem vinda, podem postar aqui suas ideia, e caso queira um contato mais imediato pode me contactar no Twitter @\_Ianetta, obrigado pela ateno de todos.

\---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

 Good morning / afternoon / evening. I do not have any knowledge about AI or programming, but I'm starting to study ... 

I would like to develop an AI for purposes that suit the user's need, a company, an assistant, a search engine, (an assistant to dominate the world) either because the user would choose which end to use. 

I barely read that TensorFlow is a Google Open Source platform, and I would like to know if there are other Open Source that can help to develop this idea. 

 My idea is to develop the AI to be used between Smartphones, Tablets, Notebooks, an AI that could be used by even 2 users or more, having an interaction between the users the AI would know who it is, but could talk freely between the users, as a user, any indication platform, comment or help is welcome, you can post your idea here, and if you want a more immediate contact you can contact me at Twitter @\_Ianetta, thanks for everyone's attention. ",0,1
8,2018-8-3,2018,8,3,5,942pa5,Step by step installation for ubuntu 16.04 and ubuntu 18.04(easiest way),https://www.reddit.com/r/tensorflow/comments/942pa5/step_by_step_installation_for_ubuntu_1604_and/,rava-dosa,1533240229,,1,0
9,2018-8-4,2018,8,4,3,94bv63,Question about Tensorflow/Tensorflow.js performance when retrieving results,https://www.reddit.com/r/tensorflow/comments/94bv63/question_about_tensorflowtensorflowjs_performance/,ootsby,1533319208,"I've been looking at a toy problem using Mobilenet on tensorflow.js. I want to be able to classify many images as fast as possible so I've been experimenting with batching under the assumption that reducing communication to and from the GPU is a good idea.

I noticed that a large chunk of time was being spent reading texture data when retrieving the prediction results. As Mobilenet produces probability outputs for 1000 classes and I'm only interested in a few of those I thought it would be a good idea to add a filter layer to the model that simply gathers the outputs I care about and only returns those as output. I thought this would all happen on the GPU and therefore be far faster.

It turns out that this makes no discernible difference AFAICT. Is this a quirk of the WebGL implementation of Tensorflow.js or is my thinking just wrong for Tensorflow on all platforms? Please clue me up!",0,2
10,2018-8-4,2018,8,4,3,94cdb9,Question understanding time series tutorial,https://www.reddit.com/r/tensorflow/comments/94cdb9/question_understanding_time_series_tutorial/,TheOneRavenous,1533322654,"Looking at RNN time series prediction tutorials and really most tutorials, the author usually creates two tensors.

One is usually ````xs =tf.tensor([data array], shape) ````

And the other is ````ys =tf.tensor([data array], shape)````

For time series is ys usually the time steps? I'm a little confused because I haven't found a good example as to how the author is splitting the data to get xs and ys. Usually the example loads some preprocessed data into the example. 

I think of ""xs"" as x-axis and ""ys"" as y-axis. Am I thinking about the data correctly. 

The data is rain Gage data and time stamps of that data.

 Example ( [{rainfall:0.4, time:8/26/18 04:04:56},...]) ",3,2
11,2018-8-4,2018,8,4,6,94dn4f,Appropriate method for time series,https://www.reddit.com/r/tensorflow/comments/94dn4f/appropriate_method_for_time_series/,Atma-n,1533331870,"Hi! I am trying to use TensorFlow to help me predict events in a time series. Lets say each day has a value, such as temperature, price or anything that varies with time and I have some attributes that is calculated from the value. For example when the moving average for two windows are crossing each other. One attribute will be if the next day is more or less than ""today"". In the example I have called it Attribute 1. Attribute 2 and 3 are just made up.

I want to use the value and the attributes to predict a value for tomorrow.

By adding and removing attributes I want to test if it is possible to predict better or worse for various time series.

What kind of algorithm should I use with tensorflow?

Thanks for any help or suggestions!

Time|Value|Attribute 1|Attribute 2|Attribute 3|

\--:|--:|:-:|:-:|:-:|

2018-01-01|10|TRUE|TRUE|FALSE|

2018-01-02|11|TRUE|FALSE|FALSE|

2018-01-03|12|TRUE|TRUE|FALSE|

2018-01-04|13|FALSE|FALSE|FALSE|

2018-01-05|12|FALSE|FALSE|FALSE|

2018-01-06|8|FALSE|FALSE|FALSE|

2018-01-07|5|TRUE|FALSE|TRUE|

2018-01-08|10|TRUE|FALSE|TRUE|

2018-01-09|15|TRUE|FALSE|TRUE|

2018-01-10|20|TRUE|FALSE|TRUE|

2018-01-11|25|FALSE|FALSE|FALSE|

2018-01-12|25|FALSE|FALSE|TRUE|

2018-01-13|25|FALSE|TRUE|FALSE|

2018-01-14|25|FALSE|TRUE|FALSE|

2018-01-15|24|FALSE|TRUE|FALSE|

2018-01-16|22|FALSE|FALSE|FALSE|

2018-01-17|20|FALSE|TRUE|TRUE|

2018-01-18|19|FALSE|TRUE|TRUE|

2018-01-19|17|FALSE|TRUE|TRUE|",3,1
12,2018-8-4,2018,8,4,22,94izcn,DDPG With Tensorflow questions and problems,https://www.reddit.com/r/tensorflow/comments/94izcn/ddpg_with_tensorflow_questions_and_problems/,Jandevries101,1533387932,"Hey reader,

\-

\-

\-

So i have been studying alot of things in reinfocrement learning and came to an conclusion that i wanna try the ddpg algorithm. i tried code from; [https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/blob/master/contents/9\_Deep\_Deterministic\_Policy\_Gradient\_DDPG/DDPG\_update2.py](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/blob/master/contents/9_Deep_Deterministic_Policy_Gradient_DDPG/DDPG_update2.py) but when using this code i had directly a million questions... i tried running it first to see if it works fine and uit worked good enough with the pendeluem example environment, but then i realized that i couldn't get my environment hooked up/working with this existing code!?.

\-

\-

\-

My environment consists atleast of reset, action and init function. the reset function should\* return pictures in 1080x720 pixels in what i believe a rgb array...? my action function consists of needing an environment and choosing based on the q values an action, i understand i will need to update that to something more suiteable for this algorithm. the actions are ""up"" ""down"" ""right"" . when for example up is called it will call a function that does his job... it is not so relevant on what the actions do (?). and in my init function i do some init things, but not really anything related to the ddpg algorithm. this environment file is first been used for normal q-learning i understand there needs to be things changed, but i don't get how/where..

\-

\-

\-

init looks like:

        def __init__(self):
            super(Environment, self).__init__()
            self.action_space = ['up', 'down', 'right']
            self.n_actions = len(self.action_space)
    #        self.n_features = 3 #this is i think needed for ddpg, don't know wich value it should be also

\-

\-

\-

Thats around everything i have in my environment... if i need more in my environment just let me know...

i know that my environment is continious states/actions and that i then need ""box"" environment to be created, but then again i have no idea how to set this up with this ddpg code i currently have.

\-

\-

\-

End goal:

\-

\-

\-

1: The AI should be build properly and should have all the ddpg aspects in his algorithm

2: The AI is attached to the environment, input as images and actions as 0, 1, 2 (0=up,1=down,2=down)

3: The AI should save his progress somewhere (like a pickle)

\-

\-

\-

At last: i can't share my environment code with you, but it doens't has anything strange in it, just a reset and step function , with reset (should\*) returning a picture. and step having the actions 0,1,2 in it, i know there should be something switched that the actions aren't chosen in step but in the algo but atleast from step it should return the action chosen right?

\-

\-

\-

Should\* : i have pictures that are timeframes from the game, there .png and are 1080x720 (will change later size) i want the ai to get so see the pictures i don't have any good ways yet to feed the pictures to the environment, but i think i've read something about array's and rgb modes?

\-

\-

\-

If you know anything about let me know on things that may help (please don't just post only links to documentations, i've read them all, explaining is allowed?), if you know all/some answers please let me know, if you could send some example code with it aswell, so i can understand it? if you really wanna help me out with live chat we can skype/discord, just send a pm with your discord/skype name so we can talk about it?

\-

\-

\-

Thanks already in advance for reading and responding!

\-

\-

\-

Jan",0,1
13,2018-8-5,2018,8,5,1,94kh2k,[Q] Why is this happening? (Normal Distribution Sampling Get Slower and Slower),https://www.reddit.com/r/tensorflow/comments/94kh2k/q_why_is_this_happening_normal_distribution/,Jonas_SV,1533400953,"Repeatedly calling sample from normal dist gets very slow.

Is this supposed to happend?

I'm running Tensorflow 1.8

Timestamp 0: 0.020380735397338867

Timestamp 100: 0.04753875732421875

Timestamp 200: 0.08234620094299316

Timestamp 300: 0.12919116020202637

Timestamp 400: 0.1656949520111084

Timestamp 500: 0.21046710014343262

Timestamp 600: 0.22464704513549805

Timestamp 700: 0.2586097717285156

Timestamp 800: 0.30599498748779297

Timestamp 900: 0.3456001281738281

\# to reproduce

import tensorflow as tf

import time

import numpy as np

scale   = tf.Variable(np.ones(4), dtype=tf.float32)

loc     = tf.Variable(np.zeros(4), dtype=tf.float32)

samples = tf.distributions.Normal(loc=loc, scale=scale)

with tf.Session() as sess:

[sess.run](https://sess.run)(tf.global\_variables\_initializer())

i = 100000

for j in range(i):

stamp = time.time()

[sess.run](https://sess.run)(samples.sample())

if j % 100 == 0:

print(""Timestamp {}: {}"".format(j, time.time() - stamp))",2,1
14,2018-8-5,2018,8,5,12,94p1xw,"Are you interested in Computer Science and want to start learning more with Tutorials? Check out this new Youtube Channel, called Discover Artificial Intelligence. :)",https://www.reddit.com/r/tensorflow/comments/94p1xw/are_you_interested_in_computer_science_and_want/,ailearn12,1533440554,,1,7
15,2018-8-6,2018,8,6,7,94vtvu,How similar is Tensorflow API of python compare to Javascript?,https://www.reddit.com/r/tensorflow/comments/94vtvu/how_similar_is_tensorflow_api_of_python_compare/,GTHell,1533508167,I'm starting to learn to Tensorflow but it would be interesting to know the similarity between the two the languages as my prefer language is Javascript but TF has a huge tutorial on Python. ,9,4
16,2018-8-6,2018,8,6,14,94yg0o,NVS 5400M is not recognized by tensorflow-gpu,https://www.reddit.com/r/tensorflow/comments/94yg0o/nvs_5400m_is_not_recognized_by_tensorflowgpu/,Nyd3r,1533531704,"anyone know how to get tf-gpu to recognie the graphics card ?

theano is able to see the card, but not tf , why ?",4,1
17,2018-8-6,2018,8,6,18,94zr9e,Complete Guide Of Tensorflow For Beginners,https://www.reddit.com/r/tensorflow/comments/94zr9e/complete_guide_of_tensorflow_for_beginners/,KiranKiller,1533546740,[removed],0,1
18,2018-8-7,2018,8,7,0,952gae,Is there any way to visualize TF.js with Tensorboard or anything similar existing tool?,https://www.reddit.com/r/tensorflow/comments/952gae/is_there_any_way_to_visualize_tfjs_with/,janixwow,1533570832,,0,3
19,2018-8-7,2018,8,7,1,952jc6,What is val_mean_absolute_error?,https://www.reddit.com/r/tensorflow/comments/952jc6/what_is_val_mean_absolute_error/,NitcombReaper3,1533571401,"I have been using tensor flow tutorials but cannot figure this out. I understand what train loss is but val loss is a bit of an unknown. I can't find anything online, so here I am asking the kind people of Reddit. ",3,1
20,2018-8-7,2018,8,7,2,953iw5,Crypto portfolio optimization with Python and Tensorflow  Matrix calculus approach,https://www.reddit.com/r/tensorflow/comments/953iw5/crypto_portfolio_optimization_with_python_and/,ledfusion,1533578150,,3,9
21,2018-8-8,2018,8,8,8,95gxdo,Python code snippets to try out a neural network to predict daily market movements by using Tensorflow,https://www.reddit.com/r/tensorflow/comments/95gxdo/python_code_snippets_to_try_out_a_neural_network/,alpacahq,1533685637,,2,7
22,2018-8-8,2018,8,8,19,95krb7,TensorFlow C API on Windows without pain.,https://www.reddit.com/r/tensorflow/comments/95krb7/tensorflow_c_api_on_windows_without_pain/,Neargye,1533723210,,1,10
23,2018-8-8,2018,8,8,23,95mowv,Trying to get a small proof of concept working with an Estimator and some feature columns. Having some resource utilization issues and could use some help.,https://www.reddit.com/r/tensorflow/comments/95mowv/trying_to_get_a_small_proof_of_concept_working/,patricktoner,1533740054,"Currently I'm having some performance issues with Estimators and Feature Columns. It's possible that I'm somehow misunderstanding how these are intended to be used, but I can't come up with an example that utilizes more than 5-10% of my CPU.

Here's the code. I'm generating a dataframe with an arbitrary number of float features (100 in this case). I then create a numeric\_column for each one of these features and then try to train it. 

It never tasks the CPU no matter what I make the batch size, the number of records, or the number of features. Smaller batches? Bigger ones? Less features? More features? Is there a dataset size that would actually use the available resources appropriately? Am I doing something fundamentally incorrect here? Is this not how I should use feature columns? 

    import tensorflow as tf
    from tensorflow.python.estimator import estimator
    from tensorflow.python.estimator.canned.linear import LinearClassifier
    from tensorflow.python.training.ftrl import FtrlOptimizer
    from tensorflow.python.training.session_run_hook import SessionRunHook, SessionRunArgs
    import pandas as pd
    import numpy as np
    from sklearn.model_selection import train_test_split
    
    device_name = ""/cpu:0""
    num_rows = 88000
    num_features = 100
    
    def train():
    
        tf.logging.set_verbosity(tf.logging.INFO)
    
        with tf.device(device_name):
    
            X = generate_data(num_rows)
            Y = X.pop(""Y"")
    
            train_X, test_X, train_Y, test_Y = train_test_split(X, Y, train_size=0.8, test_size=0.2)
    
    
            train_input_fn = tf.estimator.inputs.pandas_input_fn(
                x=train_X,
                y=train_Y,
                batch_size=10240,
                num_epochs=100,
                shuffle=True
            )
    
    
            eval_input_fn = tf.estimator.inputs.pandas_input_fn(
                x=test_X,
                y=test_Y,
                num_epochs=1,
                shuffle=False
            )
    
    
            feature_columns = []
            for i in range(num_features):
                feature_columns.append(tf.feature_column.numeric_column(""X"" + str(i)))
    
    
    
            estimator = LinearClassifier(
    
                config = tf.estimator.RunConfig(
                    save_checkpoints_secs=60,
                    model_dir=""model"",
                    session_config=tf.ConfigProto(
                    )
                ),
                optimizer=FtrlOptimizer(
                    learning_rate= 0.001,
                    l1_regularization_strength= 0.001,
                    l2_regularization_strength= 0.001
                ),
    
                feature_columns=feature_columns
            )
    
    
            train_spec = tf.estimator.TrainSpec(
                input_fn=train_input_fn,
                max_steps=200000
            )
    
            eval_spec = tf.estimator.EvalSpec(
                input_fn=eval_input_fn,
                throttle_secs=180,
                start_delay_secs=60
            )
    
            tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
    
    
    def generate_data(num_rows):
    
        columns = []
        for i in range(num_features):
            columns.append(""X"" + str(i))
    
        df = pd.DataFrame(np.random.randn(num_rows, num_features), columns=columns)
        arr = np.random.randint(0, 2, num_rows)
        df['Y'] = arr.tolist()
    
        return df
    
    
    train()",0,2
24,2018-8-9,2018,8,9,4,95p1q1,Tensorflow for beginners,https://www.reddit.com/r/tensorflow/comments/95p1q1/tensorflow_for_beginners/,richardsmith7021,1533755574,"Who wants to get deep information about Tensorflow just read that answer it had a great information. it is useful for beginners also.just check it

https://www.quora.com/What-are-the-best-course-to-learn-TensorFlow-Foundation",0,2
25,2018-8-9,2018,8,9,17,95urah,"How to determine a ""good"" geometry for a CNN",https://www.reddit.com/r/tensorflow/comments/95urah/how_to_determine_a_good_geometry_for_a_cnn/,IceGuerilla,1533804945,"I am looking for decent resources on how to pick a reasonable or even optimal:
*number of layers
*size of each layer
*order of convolution/pooling *etc* layers
for a CNN, preferably for image recognition, classification and the like. For example, how should one change these quantities based on the input image size, aspect ratio, whether it is color or grayscale *etc*.",8,2
26,2018-8-9,2018,8,9,18,95uyvi,The Complete Guide to TensorFlow for Deep Learning with Python,https://www.reddit.com/r/tensorflow/comments/95uyvi/the_complete_guide_to_tensorflow_for_deep/,jbvmt,1533807371,,1,0
27,2018-8-10,2018,8,10,1,95xpn4,How does this neural network load the parameters?,https://www.reddit.com/r/tensorflow/comments/95xpn4/how_does_this_neural_network_load_the_parameters/,Dinosaur_Boner,1533830462,"https://pastebin.com/TBJd0mJ2

The load_weights method goes throught the dictionary loaded from the data file and assigns the values to the self.parameters array. It's confusing because I only see values being assigned to the self.parameters array, but I don't see them being used at all. It works though. How are the parameters actually being loaded into the nueral network? Outside of the load_weights method, self.parameters is only used like ""self.parameters += [weights, biases]"".",2,1
28,2018-8-10,2018,8,10,4,95zj4k,Real like Pokdex built using Tensorflow,https://www.reddit.com/r/tensorflow/comments/95zj4k/real_like_pokdex_built_using_tensorflow/,the-dagger,1533842512,"Pokmon fans, heres an AI experiment that I hacked together last week.

https://play.google.com/store/apps/details?id=app.harshit.pokedex

Built using **Tensorflow Lite** and **Firebase**, It detects and identifies the Pokmon from the provided image. Would appreciate your feedback in making this even better and more accurate!

P.S. The app is fully open sourced, so youre more than welcome to submit patches, report issues, etc.

https://github.com/the-dagger/Pokidex/",6,7
29,2018-8-10,2018,8,10,22,966q51,How should i start with Image recognition using tensorflow??,https://www.reddit.com/r/tensorflow/comments/966q51/how_should_i_start_with_image_recognition_using/,Pingofdeath01,1533906105,"Hello I want to eliminate the problem of clickbait videos on youtube. Idea is that i will match the thumbnail of the video with rest of video and if somehow thumbnail matches some part of the video then it's fine otherwise they are clickbait videos. I will divide video into image at particular fps.

plzz can anyone suggest how can i implement it, i am currently in first year engineering. I am good at python and have some basic knowledge of tensorflow.",12,3
30,2018-8-10,2018,8,10,22,966yon,Electron wraped Bitcoin chart predicter with Tensorflow JS &amp; Binance API,https://www.reddit.com/r/tensorflow/comments/966yon/electron_wraped_bitcoin_chart_predicter_with/,janixwow,1533908007,"I made a simple example to run pre-trained Tensorflow JS modell in Electron, until CLI version can't use GPU under Windows 10.  


\- [https://github.com/Palabola/BinanceTensorFlowSandbox](https://github.com/Palabola/BinanceTensorFlowSandbox)  
",0,1
31,2018-8-11,2018,8,11,3,969fxq,"How to fix InvalidArgumentError (see above for traceback): Matrix size-incompatible: In[0]: [1,4], In[1]: [423,1000] Ask Question",https://www.reddit.com/r/tensorflow/comments/969fxq/how_to_fix_invalidargumenterror_see_above_for/,bharddwaj,1533925192,Not sure if this subreddit is appropriate to ask for help but this error comes up when I'm trying to use my model and I don't know what to do. Here is the link to my stackoverflow question which contains all the code: [https://stackoverflow.com/questions/51790415/how-to-fix-invalidargumenterror-see-above-for-traceback-matrix-size-incompat](https://stackoverflow.com/questions/51790415/how-to-fix-invalidargumenterror-see-above-for-traceback-matrix-size-incompat),0,2
32,2018-8-11,2018,8,11,21,96g3rq,Crypto portfolio optimization with Python and Tensorflow  Matrix calculus approach (part 2),https://www.reddit.com/r/tensorflow/comments/96g3rq/crypto_portfolio_optimization_with_python_and/,ledfusion,1533989518,,1,5
33,2018-8-11,2018,8,11,21,96g4x1,Using GIF in retrain.py for Inception v3,https://www.reddit.com/r/tensorflow/comments/96g4x1/using_gif_in_retrainpy_for_inception_v3/,Arkhaya,1533989875,"I saw that there was a GIF decoder for Tensorflow and I want to know how to be able to train the model on GIF format, if possible.

And also are there any tips on how to change the [retrain.py](https://retrain.py) to train better, like shuffle image set and grayscale, blurring, flipping etc and also how to implement them.",0,4
34,2018-8-12,2018,8,12,1,96hvgh,Conceptualizing how a model will work (comparing text files),https://www.reddit.com/r/tensorflow/comments/96hvgh/conceptualizing_how_a_model_will_work_comparing/,Kar_Athri,1534005493,"Hey, I'm knew to TensorFlow and I'm trying to build a project for a hackathon with it. After coming up with an idea, me and my team mates and having a difficult time figuring out how a specific aspect is going to work in the process as we're all knew to the tool. What we want is a model that's given a large amount of different text files as training data, and then will be able to be given a new text file and output the text file most similar to it. What I'm unsure with here is, will we need a database with all the input data or something for the model to continually access to be able to output the most similar text file? As far as I understand that should be the case, but I wanted to make sure before going down this route. Thanks. ",0,1
35,2018-8-13,2018,8,13,22,96y8wn,TensorFlow 1.10 has just been released. Heres whats new.,https://www.reddit.com/r/tensorflow/comments/96y8wn/tensorflow_110_has_just_been_released_heres_whats/,coinmonks,1534166514,,0,26
36,2018-8-14,2018,8,14,2,9707l0,Setting TF Lucid's visualized activations to music (code in comments),https://www.reddit.com/r/tensorflow/comments/9707l0/setting_tf_lucids_visualized_activations_to_music/,cosmic_dozen,1534180778,,1,2
37,2018-8-14,2018,8,14,2,970gjq,TFLite: difference between .lite and .tflite?,https://www.reddit.com/r/tensorflow/comments/970gjq/tflite_difference_between_lite_and_tflite/,acidafterglow,1534182435,"I've been working with the TFLite demo provided in the ""Tensorflow for Poets"" codelab:  
[https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0)

The models here are "".lite"" files.

But this seems to be using some old gradle dependencies which were causing conflicts with my project. So then I cloned the Tensorflow repo and tried to run the Tflite demo there (tensorflow/contrib/lite/java/demo). But this one uses "".tflite"" files....  
If I try to use my old model, the compiler gives me a buffer size inconsistency error.

If I convert the original "".pb"" file using ""*tf\_lite convert*"" command, I can run the demo with the generated .tflite file, but it doesn't work any bit as good as using the .lite file with the ""Tensorflow for Poets"" demo.

I did the conversion with this command:  
tflite\_convert \\   --output\_file=\*.tflite \\   --graph\_def\_file=\*.pb \\   --input\_arrays=input \\   --output\_arraysfinal\_result

Is there something I'm missing?",0,1
38,2018-8-14,2018,8,14,4,9719x2,When would a network take more memory on GPU?,https://www.reddit.com/r/tensorflow/comments/9719x2/when_would_a_network_take_more_memory_on_gpu/,SoFarFromHome,1534188088,"I'm currently training a (relatively simple) feedforward neural network.  When training on a Docker instance with 6gb RAM and GPU, it trains albeit very slowly.  When on a Docker instance with 12gb GPU RAM (using a Tesla K80), the tf.Session() throws out-of-memory (OOM) errors during training, usually during the first or second training step, even if I reduce the graph size moderately (reducing the network depth and width).

Any ideas on what the difference in the CPU vs. GPU implementation might be that it is more than doubling the memory requirement?  Any tips to avoid this?

For now, my only intuition is to switch to small minibatches (currently using the full 150k x 100 input stored as tf.constant, since it trains fine on CPU).",4,1
39,2018-8-14,2018,8,14,16,976er6,hanxiao/tf-nlp-blocks: A collection of frequently-used deep learning NLP blocks implemented in Tensorflow,https://www.reddit.com/r/tensorflow/comments/976er6/hanxiaotfnlpblocks_a_collection_of_frequentlyused/,h_xiao,1534232446,,0,5
40,2018-8-14,2018,8,14,19,9775ef,"How to fix ""No dashboards are active for the current data set."" for Mac OS?",https://www.reddit.com/r/tensorflow/comments/9775ef/how_to_fix_no_dashboards_are_active_for_the/,ByMAster2,1534241703,,0,0
41,2018-8-14,2018,8,14,23,978ykc,Have Tensorflow return classification value for each row,https://www.reddit.com/r/tensorflow/comments/978ykc/have_tensorflow_return_classification_value_for/,darchcruise,1534257972,"I want to know  1) if it is possible to output the classification value w tensorflow    and   2) Links and quick description of how to do it using MNIST as an example. For instance, I know how to get accuracy, but how can I submit my own pixels (photos of hand-drawn digits) and have tensorflow return ""row 1 = this is the number 8"", ""row 2 = this is the number 3"",  ""row 3 = this is the number 1"", etc..  I trying to get the same capability I got with Scikit-Learn where I would pass the input and it would return the value it should be (i.e. Titanic Dataset - male or female and age --&gt; input |  survived or died --&gt; output). Thanks",0,1
42,2018-8-15,2018,8,15,1,979rdm,Chain execution of tensorflow operations with list parameters,https://www.reddit.com/r/tensorflow/comments/979rdm/chain_execution_of_tensorflow_operations_with/,Maciekism,1534263687,"I figure it is going to be much easier for people to understand this question if i offer a little explanation of how tf works on lists. If you already know this you can skip to end of refresher

If we take a tf operation like matmul and give 2 tensors as arguments tensorflow will treat these arguments as matrices and multiply them giving a result as a tensor (i used matrix of (1,1) shape to make it easier to multiply)

`mat_a = [[3]]`

`mat_b = [[4]]`

`tf.matmul(mat_a, mat_b) = [[12]]` 

you can easily chain this operation feeding the resulting tensor into another matmul.

However if you feed a list of tensors into a matmul it will treat each element of the list as a matrix and multiply it by each element of the second list. Which is extremely useful way to multiply multiple matrices at the same time

`list_a = [mat_a, mat_b, mat_c]`

`list_b = [mat_x, mat_z, mat_y]`

`tf.matmul(list_a, list_b)  = mat_a*mat_x, mat_b*mat_z, mat_c*mat_y`

Alas the result of this operation is not a list of tensors but a tensor that contains all the tensors. 

If a tensor is fed into the matmul it is treated as a matrix not as a list so this operation cannot be easily chained.

End of refresher

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

I am trying to execute tf operations that take a list argument in succession.

Because the result of the tensorflow operations are tensors and not lists you cannot simply feed the resulting tensor into the next operation.

I have found a very useful function  [tf.create\_partitioned\_variables](https://www.tensorflow.org/api_docs/python/tf/create_partitioned_variables)  which returns a list from a tensor.

The only problem is that you need to know the shape of the tensor beforehand which is impossible when feeding a dictionary into a model

Using tf.reshape to make sure the shape is right beforehand will still end up throwing an error.

What is a proper way of chaining such operations?",1,1
43,2018-8-15,2018,8,15,1,979tfc,Tensorflow oscillating Test and Train Accuracy?,https://www.reddit.com/r/tensorflow/comments/979tfc/tensorflow_oscillating_test_and_train_accuracy/,ByMAster2,1534264083,"I have implemented a CNN with images as input and 2 classes as output. I have applied mean subtraction to the input for normalisation before giving it as input to the network. But on compiling the code multiple times, there testing accuracy seems to be too unstable as I have in the pastebins

[CODE](https://pastebin.com/6zMgmgaM)

Testing Accuracy -- &gt; 0.40
https://pastebin.com/ByV0hgfs 

Testing Accuracy -- &gt; 0.57 https://pastebin.com/e2LxssAB 

Testing Accuracy -- &gt; 0.77 https://pastebin.com/WiiGW0nS 

I am TRAINING on 1028 samples and testing on 300 samples
",1,1
44,2018-8-15,2018,8,15,2,97aj5m,TensorFlow: A new paradigm for large scale ML in distributed systems,https://www.reddit.com/r/tensorflow/comments/97aj5m/tensorflow_a_new_paradigm_for_large_scale_ml_in/,coinmonks,1534269134,,0,12
45,2018-8-15,2018,8,15,14,97fll2,I am having trouble learning Tensorflow,https://www.reddit.com/r/tensorflow/comments/97fll2/i_am_having_trouble_learning_tensorflow/,scarletred94,1534309473,"I know how convolutional neural networks work but when I am trying to make one on Tensorflow, I am having a hard time understanding the tutorials I find on the internet because most of them use MNIST database for their datasets while I have datasets of my own. I am creating a OCR for Baybayin Characters (the writing system used by Filipinos before the arrival of the Spanish) and I hope I will be able to train and test my datasets (images of handwritten Baybayin Characters) on the google cloud. Do you have any suggestions to help me on my plight?",5,2
46,2018-8-15,2018,8,15,20,97hm5v,Building Pokdex in Android using TensorFlow Lite and Firebase ML Kit,https://www.reddit.com/r/tensorflow/comments/97hm5v/building_pokdex_in_android_using_tensorflow_lite/,the-dagger,1534334124,,0,9
47,2018-8-16,2018,8,16,11,97ol2n,Failed Style Transfer(X-post /r/learnmachinelearning),https://www.reddit.com/r/tensorflow/comments/97ol2n/failed_style_transferxpost_rlearnmachinelearning/,SechetBot,1534387792,,0,3
48,2018-8-16,2018,8,16,18,97qp8h,Tensorflow for Beginners,https://www.reddit.com/r/tensorflow/comments/97qp8h/tensorflow_for_beginners/,groundtoearth,1534410367,"Devices are getting smarter thanks to machine learning and artificial intelligence, and that is definitely going to continue. Machines are going to continue getting better and evolve, making tasks easier for humans. With machine learning and AI in the picture, the role of TensorFlow is unavoidable.

TensorFlow is an open-source library that is commonly used for data flow programming. It also includes a symbolic math library that can be used for machine learning applications and neural networking. TensorFlow was built by the Google Brain Team for their internal development needs on AI and ML, before it was released to the public.

However, its currently playing a huge role in helping technology advance to the next level. This makes TensorFlow a powerful technology to learn and master and this is exactly why we have designed this no-nonsense and no-fuss course here \~  &lt;!--td {border: 1px solid #ccc;}br {mso-data-placement:same-cell;}--&gt;r/https://www.udemy.com/tensorflow-for-beginners/?couponCode=DUAUG18 ",4,0
49,2018-8-16,2018,8,16,19,97qzyh,[Help] Question regarding variable_scopes and the resulting Graph.,https://www.reddit.com/r/tensorflow/comments/97qzyh/help_question_regarding_variable_scopes_and_the/,julianCP,1534413894,"Hi,
I created a minimal example here: https://pastebin.com/TEVn6EKr     
Essentially I open a variable_scope where have multiple LSTM or Conv layers etc. Then I work with the reults of this layer(s). Much like the model that is shown in the minimal example, the tensorflow graph shows multiple DIFFERENT nodes(scopes) with the names ""reuse"", ""reuse_1"", ""reuse_2"".... I wonder if these are refering to the SAME objects. So if I train the layers in the scope ""reuse"" am I also training the objects in the scope ""reuse_1"" ... so. So I wonder if ""reuse"" and ""reuse_n""... refer to the same objects.
Here is a screenshot of the tensorboard graph: https://imgur.com/a/CFkIFUS",0,1
50,2018-8-17,2018,8,17,0,97t2ur,Object Detection with YOLOv2 + Tensorflow [UE4 Tech Demo],https://www.reddit.com/r/tensorflow/comments/97t2ur/object_detection_with_yolov2_tensorflow_ue4_tech/,humanovan,1534432006,,3,14
51,2018-8-17,2018,8,17,6,97w9ml,How do I plot validation set accuracy in tensorboard scalars?,https://www.reddit.com/r/tensorflow/comments/97w9ml/how_do_i_plot_validation_set_accuracy_in/,tensor_dude,1534454222,"I'm trying to create a scalar summary of the overall accuracy on the validation set. The problem is that, for the way I create the graph, I only grab the accuracy of a batch to put into a summary. As you can imagine this is not very useful, ideally I would plot the accuracy on the whole dataset not just a batch. Let me show you some code, most of it is coming from [this example](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py):

    correct_pred = tf.equal(tf.argmax(prediction, axis=1), tf.argmax(label, axis=1))
    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))
    tf.summary.scalar('batch_accuracy', accuracy)
    
    ...
    
    if step % 1000 == 0:
        val_step = 1
        val_acc = 0
        
        while val_step * val_batch_size &lt; val_set_size:
            valid_x, valid_y = val_set.next(val_batch_size)
            step_acc = sess.run(accuracy, feed_dict={x: valid_x, y: valid_y})
            val_acc += step_acc
            val_step += 1
        
        val_acc = val_acc / val_step
        # If I do this it will create a new summary every time this code is run
        # thus creating 'accuracy', 'accuracy_1', 'accuracy_2'
        tf.summary.scalar('accuracy', val_acc) print(""Validation set accuracy: %s"" % val_acc)

How would I go about preventing the creation of multiple summaries ?",0,1
52,2018-8-17,2018,8,17,8,97xacw,anyone wanna work on a neural network that creates its own music?,https://www.reddit.com/r/tensorflow/comments/97xacw/anyone_wanna_work_on_a_neural_network_that/,bharddwaj,1534462123,As the title says I'm looking for people who wanna work on a project to create a neural network that creates its own music. I'm a beginner who is just looking to work on this project as a learning experience.,3,2
53,2018-8-17,2018,8,17,10,97y64x,Teaching NoodleFeet to See and Recognize Mommy!,https://www.reddit.com/r/tensorflow/comments/97y64x/teaching_noodlefeet_to_see_and_recognize_mommy/,spetku,1534469563,,0,8
54,2018-8-17,2018,8,17,11,97yr4n,Just Installed Tensorflow and I am receiving this Error,https://www.reddit.com/r/tensorflow/comments/97yr4n/just_installed_tensorflow_and_i_am_receiving_this/,CountJeewb,1534474780,"Hi, so I just installed tensorflow using pip and python 3.6. Hwne i try to import tensorflow in python, I get this error.

Traceback (most recent call last):

  File ""C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\self\_check.py"", line 75, in preload\_check

ctypes.WinDLL(build\_info.cudart\_dll\_name)

  File ""C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\ctypes\\\_\_init\_\_.py"", line 348, in \_\_init\_\_

self.\_handle = \_dlopen(self.\_name, mode)

OSError: \[WinError 126\] The specified module could not be found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):

  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;

  File ""C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\\_\_init\_\_.py"", line 22, in &lt;module&gt;

from tensorflow.python import pywrap\_tensorflow  # pylint: disable=unused-import

  File ""C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\\_\_init\_\_.py"", line 49, in &lt;module&gt;

from tensorflow.python import pywrap\_tensorflow

  File ""C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow.py"", line 30, in &lt;module&gt;

self\_check.preload\_check()

  File ""C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\self\_check.py"", line 82, in preload\_check

% (build\_info.cudart\_dll\_name, build\_info.cuda\_version\_number))

ImportError: Could not find 'cudart64\_90.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 9.0 from this URL: [https://developer.nvidia.com/cuda-90-download-archive](https://developer.nvidia.com/cuda-90-download-archive)

I just installed CUDA so idea whats wrong. Anyone have any advice",6,1
55,2018-8-17,2018,8,17,16,980evm,Need help understanding tf.sequence_mask(),https://www.reddit.com/r/tensorflow/comments/980evm/need_help_understanding_tfsequence_mask/,cant-find-user-name,1534492639,"Hello all,   


I am a newbie to tensorflow. I have been studying lstms and was looking at implementing lstms for Named entity recognition. I came across this tutorial: [https://guillaumegenthial.github.io/sequence-tagging-with-tensorflow.html](https://guillaumegenthial.github.io/sequence-tagging-with-tensorflow.html)   


While I am understanding the theory, this part confuses me:

losses **=** tf**.**nn**.**sparse\_softmax\_cross\_entropy\_with\_logits(logits**=**scores, labels**=**labels)

 *# shape = (batch, sentence, nclasses)*

 mask **=** tf**.**sequence\_mask(sequence\_lengths) 

*# apply mask* 

losses **=** tf**.**boolean\_mask(losses, mask) 

loss **=** tf**.**reduce\_mean(losses)

What is tf.sequence\_mask() and tf.boolean\_mask() doing here? I looked through the documentation but I still don't understand it much. Any help would be greatly appreciated.   


TIA :) ",0,0
56,2018-8-17,2018,8,17,23,982ylo,Stuck. Can't even install properly (Windows 10),https://www.reddit.com/r/tensorflow/comments/982ylo/stuck_cant_even_install_properly_windows_10/,Alliat,1534517983,"I'm very new to TensorFlow and I'm also fairly new to Windows (I live in MacOS and Linux world). I'm trying to install TensorFlow but it looks like the install didn't take.

Sniplet from Command Prompt:

\---------------------------------------------------------------

\&gt;&gt;&gt; import tensorflow as tf

Traceback (most recent call last):

  File ""C:\\Users\\Alliat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\self\_check.py"", line 47, in preload\_check

ctypes.WinDLL(build\_info.msvcp\_dll\_name)

  File ""C:\\Users\\Alliat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\ctypes\\\_\_init\_\_.py"", line 348, in \_\_init\_\_

self.\_handle = \_dlopen(self.\_name, mode)

OSError: \[WinError 126\] The specified module could not be found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):

  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;

  File ""C:\\Users\\Alliat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\\_\_init\_\_.py"", line 22, in &lt;module&gt;

from tensorflow.python import pywrap\_tensorflow  # pylint: disable=unused-import

  File ""C:\\Users\\Alliat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\\_\_init\_\_.py"", line 49, in &lt;module&gt;

from tensorflow.python import pywrap\_tensorflow

  File ""C:\\Users\\Alliat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow.py"", line 30, in &lt;module&gt;

self\_check.preload\_check()

  File ""C:\\Users\\Alliat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\self\_check.py"", line 55, in preload\_check

% build\_info.msvcp\_dll\_name)

ImportError: Could not find 'msvcp140.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. You may install this DLL by downloading Visual C++ 2015 Redistributable Update 3 from this URL: [https://www.microsoft.com/en-us/download/details.aspx?id=53587](https://www.microsoft.com/en-us/download/details.aspx?id=53587)

\-------------------------------------------

End Sniplet from Command Prompt

I searched my computer for the msvcp140.dll file and found a few of them. I chose the one that came with the Anaconda install and created an Environment Variable for it's location and retried with no luck. Then I tried copying the file into the Python directory and trying again only to receive a different set of errors ending with: ""Failed to load the native TensorFlow runtime.""  


I'm feeling pretty stupid already. The install instructions stated the installation would only need a single pip3 command. Somehow that is too much for me to do right.

P.S. I need to have established functioning object recognition by Monday morning. So far so good, eh?",7,0
57,2018-8-18,2018,8,18,1,983ymo,Books and Courses to Learn Tensorflow,https://www.reddit.com/r/tensorflow/comments/983ymo/books_and_courses_to_learn_tensorflow/,hey_krish,1534525089,"After doing python for roughly 2 years, I've recently become interested in Tensorflow for machine learning. Does anyone have any recommendations for good books and courses to learn Tensorflow on python.",5,2
58,2018-8-18,2018,8,18,4,985bf0,"When trying the ""Hello Tensorflow"" python code i get this",https://www.reddit.com/r/tensorflow/comments/985bf0/when_trying_the_hello_tensorflow_python_code_i/,CountJeewb,1534534794,"So i just went through 12 hours of trying to install tensorflow and i finally though i had done it till i tried the ""hello tensorflow"" code which is 

    &gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt; hello = tf.constant('Hello, TensorFlow!')
&gt;&gt;&gt; sess = tf.Session()
&gt;&gt;&gt; print(sess.run(hello))


when i compiled it in python 3.6 using cmd this is what i got.

2018-08-17 15:36:59.512316: I T:\\src\\github\\tensorflow\\tensorflow\\core\\platform\\cpu\_feature\_guard.cc:141\] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2

2018-08-17 15:36:59.723277: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common\_runtime\\gpu\\gpu\_device.cc:1405\] Found device 0 with properties:

name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335

pciBusID: 0000:01:00.0

totalMemory: 8.00GiB freeMemory: 6.59GiB

2018-08-17 15:36:59.728205: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common\_runtime\\gpu\\gpu\_device.cc:1484\] Adding visible gpu devices: 0

2018-08-17 15:37:00.361005: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common\_runtime\\gpu\\gpu\_device.cc:965\] Device interconnect StreamExecutor with strength 1 edge matrix:

2018-08-17 15:37:00.364078: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common\_runtime\\gpu\\gpu\_device.cc:971\]      0

2018-08-17 15:37:00.365476: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common\_runtime\\gpu\\gpu\_device.cc:984\] 0:   N

2018-08-17 15:37:00.366971: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common\_runtime\\gpu\\gpu\_device.cc:1097\] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6360 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)

b'Hello, TensorFlow!'

is it supposed to be like this or should it be different?",7,3
59,2018-8-18,2018,8,18,15,989qr3,8 Things To Do Differently in Tensorflows Eager Execution Mode,https://www.reddit.com/r/tensorflow/comments/989qr3/8_things_to_do_differently_in_tensorflows_eager/,coinmonks,1534574614,,0,13
60,2018-8-19,2018,8,19,0,98ccin,"Elegant way to create a tensor like [0, 0, 0, 1, 1, 1, 2, 2, 2,..]?",https://www.reddit.com/r/tensorflow/comments/98ccin/elegant_way_to_create_a_tensor_like_0_0_0_1_1_1_2/,PKJY,1534605011,Anyone know a good way to do this?,5,1
61,2018-8-19,2018,8,19,8,98fxl5,"I have a multi-gpu machine but I think TF is only utilizing one, can anyone help me verify this?",https://www.reddit.com/r/tensorflow/comments/98fxl5/i_have_a_multigpu_machine_but_i_think_tf_is_only/,Xyoloswag420blazeitX,1534635083,,4,2
62,2018-8-19,2018,8,19,9,98gfjv,NoodleVision: Testing the 5th Training Session!,https://www.reddit.com/r/tensorflow/comments/98gfjv/noodlevision_testing_the_5th_training_session/,spetku,1534639751,,1,13
63,2018-8-20,2018,8,20,8,98oke8,What's the usage of normalizer_fn in tf.feature_column in TensorFlow,https://www.reddit.com/r/tensorflow/comments/98oke8/whats_the_usage_of_normalizer_fn_in_tffeature/,jingw222,1534720801,"Reading the docs, I run across this code block below from \[TensorFlow Guide\]([https://www.tensorflow.org/guide/estimators](https://www.tensorflow.org/guide/estimators)):

    # Define three numeric feature columns.
    population = tf.feature_column.numeric_column('population')
    crime_rate = tf.feature_column.numeric_column('crime_rate')
    median_education = tf.feature_column.numeric_column('median_education',
    normalizer_fn=lambda x: x - global_education_mean)

And a couple of things really confused me:

1. where does the `global_education_mean` come from? Is it a `tf.constant`, or `tf.Variable`, or some other intermediate calculation which the doc does not explicitly specify here.
2. how can I pass an arbitrary transformation function to `normalizer_fn`, which might be a little bit complicated? For example,to normalize inputs with global means and variances first and then do some value clipping, and finally get their log values.",0,2
64,2018-8-20,2018,8,20,18,98s77z,A complete guide On Tensorflow for Beginners for building machine learning and deep learning solutions using Tensorflow,https://www.reddit.com/r/tensorflow/comments/98s77z/a_complete_guide_on_tensorflow_for_beginners_for/,groundtoearth,1534758033,,0,1
65,2018-8-20,2018,8,20,20,98syu9,How Tensorflow manages batchs?,https://www.reddit.com/r/tensorflow/comments/98syu9/how_tensorflow_manages_batchs/,theslt,1534766374,"Hi. I wrote a custom layer and also a custom loss for a tensorflow model. The model gets and outputs more than one value. So in both the `CustomLayer_Function` and the `CustomLoss_Function`, i used `tf.split` to use each spliced `Tensor` as a parameter. Here comes the problem. Both  functions work well when the `batch_size` is equal to 1, but because of the `tf.split` method, functions will no longer work on batches of data.

I searched for it and did not find anything useful, So, **How Tensorflow sends batches of data points to a function (layer/loss/anything)?**

ps: My own suspicion is on the -1 dimension in tensor shape. Tensorflow documentation says the None/-1 dimension is for batches of data. But how? should i rewrite the Functions to handle this extra dimension to be compatible with batch sizes grater than 1?",4,3
66,2018-8-21,2018,8,21,1,98uwow,"Help! Fashion MNIST tutorial, I'm nowhere close to 80%, even with hundreds of passes",https://www.reddit.com/r/tensorflow/comments/98uwow/help_fashion_mnist_tutorial_im_nowhere_close_to/,Alliat,1534781309,,7,1
67,2018-8-21,2018,8,21,2,98vjx1,Transitioning from shallow learning to reward based Deep Q in Tensorflow with tabular data,https://www.reddit.com/r/tensorflow/comments/98vjx1/transitioning_from_shallow_learning_to_reward/,runedalton,1534785811,"I am in the middle of a performance and accuracy experiment between a few shallow learning algorithms and deep learning algorithms, and both need to solve the same problem and operate from a CSV based data sheet.

Now, I am trying to transition from shallow learning to a Deep Q network in Tensorflow, but have an issue getting started with it.

What I really would like, is an extremely simple reward based script, which can train itself over time based on simple tabular data, with a finite amount of actions to take and predefined rewards for each action on each sample.

Ideally, the sample format could be the following:
feature1, feature2, feature3, feature4, feature5, feature6
42, 1, 0.43, 0, 1, 57.59
11, 1, 2.09, 1, 0, 112.00

Then the actions/rewards could be defined in a separate CSV like this:
reward for action1, reward for action2, reward for action3
50, 0, -100
-30, -10, 20

Meaning if the RL algorithm takes action1 on sample1, it would gain a reward of +50, and if it takes action2 on sample2 it would suffer a -10 penalty.

Now, in shallow learning and with Scikit Learning, this is perhaps one of the simplest way to train an algorithm (perhaps with a few adjustments, as a Deep Q isnt available in shallow learning, to accommodate shallow learning algorithms like Logistic Regression etc.). So I assume there must be a super simple way to train a Reinforcement Learning or other Deep Q Learning algorithm like that in Tensorflow, but I seem unable to find any examples.

Any help would be much appreciated - even if its just a link to some example I might have missed on Google. :)

Thanks!",0,1
68,2018-8-21,2018,8,21,2,98vtua,[P] TensorFlow.js video and blog series - Deep Learning in the Browser with JavaScript,https://www.reddit.com/r/tensorflow/comments/98vtua/p_tensorflowjs_video_and_blog_series_deep/,blackHoleDetector,1534787679,"- [Click here for the video series only](https://www.youtube.com/playlist?list=PLZbbT5o_s2xr83l8w44N_g3pygvajLrJ-)  
- [Click here for the blog and video series](http://deeplizard.com/learn/playlist/PLZbbT5o_s2xr83l8w44N_g3pygvajLrJ-)

In this series, we'll learn how to deploy and run models, along with full deep learning applications, in the browser! To implement this cool capability, well use TensorFlow.js (TFJS), TensorFlows JavaScript library, which allows us to build and access models in JavaScript. Topics include client-server deep learning architectures, converting Keras models to TFJS models, serving models with Node.js, building deep learning browser applications, tensor operations, and more!",0,14
69,2018-8-21,2018,8,21,16,9918j5,How to use jpeg images as datasets on a convolutional neural network on tensorflow?,https://www.reddit.com/r/tensorflow/comments/9918j5/how_to_use_jpeg_images_as_datasets_on_a/,scarletred94,1534837853,I'm still a newbie on machine learning and i am trying to use my own image datasets (jpeg pictures of handwritten characters in Baybayin) that i obtained. However I can't find any tutorial in the internet wherein I can input those images into a convolutional neural network. I'm trying to look in Github but i can't find any specific instructions and codes that might help me.,8,7
70,2018-8-21,2018,8,21,22,9930gc,Recommendations for new image classification model,https://www.reddit.com/r/tensorflow/comments/9930gc/recommendations_for_new_image_classification_model/,jango1502,1534857130,"I am doing a project where the first thing I have to do is classify custom images to different categories, I want to use a latest model such as Inception v4 or NESnet for the classification part. The problem I am facing is that there are no tutorial on these models or good blog or something from where I can study the model to have better understanding before implementing it.

I need suggestions for
1. Whether I should use old classification models or look for the latest ones(2016-2017-...) 
2. I have a custom dataset(cuisines and food dishes images (country specific)) which I am sure is not available in Imagenet challenge, so what should be my approach for this problem",1,1
71,2018-8-22,2018,8,22,13,99a98p,Looking to retrain tensorflow inception resnet v3 on animated GIFs.,https://www.reddit.com/r/tensorflow/comments/99a98p/looking_to_retrain_tensorflow_inception_resnet_v3/,Arkhaya,1534911577,"I think there is a way but the retrain.py is giving me a problem with the tf.decode.decode_gif(). 

Has anyone come up with a solution or q method to get it working?",1,2
72,2018-8-22,2018,8,22,17,99bltp,Free eBook: Deep Learning with TensorFlow [PDF],https://www.reddit.com/r/tensorflow/comments/99bltp/free_ebook_deep_learning_with_tensorflow_pdf/,PacktStaff,1534926732,,0,1
73,2018-8-24,2018,8,24,4,99qegu,Looking for opinions on the newest release,https://www.reddit.com/r/tensorflow/comments/99qegu/looking_for_opinions_on_the_newest_release/,MarkyMark255,1535052460,"Hey all! I'm writing up an article for searchEnterpriseAI\[dot\]com on the recent 1.10 release and the upcoming 2.0 beta. I'd love to get the opinions of TensorFlow users on either/both releases, so please message me if you'd like to share your thoughts!",0,3
74,2018-8-24,2018,8,24,7,99rrvh,"My Robot, Noodle's First Peek-a-boo With Mommy",https://www.reddit.com/r/tensorflow/comments/99rrvh/my_robot_noodles_first_peekaboo_with_mommy/,spetku,1535062370,,2,20
75,2018-8-24,2018,8,24,18,99vzzu,How to import Tensorflow using python in windows 8,https://www.reddit.com/r/tensorflow/comments/99vzzu/how_to_import_tensorflow_using_python_in_windows_8/,YishuVohra,1535103361," 

Hi All, I am using Python to develop a sample project.

I am working on windows platform so please help me how i can run below command

import tensorflow I am getting lots of error while loading this particular file I installed the tensorflow using **pip install tensorflow** but its showing various errors. I look of answers on google and applied the solution but still not working Please help me, my project is stuck because of this only.

Thanks in advance.",7,0
76,2018-8-24,2018,8,24,19,99w6mh,Free PDF eBook: TensorFlow Machine Learning Cookbook,https://www.reddit.com/r/tensorflow/comments/99w6mh/free_pdf_ebook_tensorflow_machine_learning/,PacktStaff,1535105520,,0,1
77,2018-8-24,2018,8,24,22,99xl6o,Is it correct to take average of testing accuracy obtained for various test data batches?,https://www.reddit.com/r/tensorflow/comments/99xl6o/is_it_correct_to_take_average_of_testing_accuracy/,ByMAster2,1535118777,"So I am sending my test data from the **same dataset** in batches, and then I am calculating the test accuracy by finding the average of those results. But I am having second doubts about this because my testing accuracy is coming out to be greater than training accuracy

Total Number of Testing Samples = 3276

Number of Batches = 3276/40 = 81

-------------------
    for i in range(81):
            Global_Data = np.arange(0, 3276)
            batch3, batch4 = next_batch(40, Training, Class_Training)
            test = accuracy.eval(feed_dict={x: batch3, y_: batch4, keep_prob: 1.0})
            avg = avg + test 

    avg_ = (avg/81) #Calculating the average for 81 test results
    print('Testing Accuracy is ',avg_)",1,3
78,2018-8-25,2018,8,25,5,9a129f,"Image Recognition: My Robot, Noodle Thinks anyone Wearing my Glasses is Me",https://www.reddit.com/r/tensorflow/comments/9a129f/image_recognition_my_robot_noodle_thinks_anyone/,spetku,1535143793,,1,6
79,2018-8-25,2018,8,25,23,9a7bxt,How can I retrieve values of weights and biases of retrained layers after MobileNet transfer learning?,https://www.reddit.com/r/tensorflow/comments/9a7bxt/how_can_i_retrieve_values_of_weights_and_biases/,botperson,1535208819,"I've used transfer learning with MobileNet to create an image classifier, following the [Tensorflow for Poets](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/) tutorial.

What I'd like to do is create an array that stores all the weights and biases that make up the retrained layers. I'm not sure how to retrieve these values from the retrained network, or even which parts of the MobileNet are retrained.

As a secondary, but related question, how can I replace these values with my own? (i.e. have an array of values and use them as the weights and biases for the layers that were supposed to be retrained and generate a model with that)

Thank you for the help.",6,2
80,2018-8-26,2018,8,26,4,9a9mcq,How to make a predictor?,https://www.reddit.com/r/tensorflow/comments/9a9mcq/how_to_make_a_predictor/,rust4yy,1535226780,"I got taught that machine learning is `f(x) = r`, where you can supply *x* and the known corresponding *r* and it creates *f* for you, so you can use it on unknown *x* values and get a predicted value for *r*.

How do I implement this in TensorFlow? The only tutorials I found only do image classifiers etc.

Also, how do I make it so I can have multiple values e.g. *x* and *y* for lets say `f(x, y) = r`",4,0
81,2018-8-26,2018,8,26,5,9a9xn4,Free servers with 1080Ti for deep learning,https://www.reddit.com/r/tensorflow/comments/9a9xn4/free_servers_with_1080ti_for_deep_learning/,woyoru,1535229312,"There's no catch. We're on very early stage with [https://tensorpad.com](https://tensorpad.com/)  it works pretty well already but we are looking for as much feedback as possible to improve the overall experience and make the product perform better. 

We are offering free 1080Ti GPU instances for deep learning. 

Sign up at [https://dashboard.tensorpad.com/signup](https://dashboard.tensorpad.com/signup) 

\- The instances have 16GB RAM, 4 CPU cores (Ryzen Threadripper), and one 1080Ti GPU, and you can run up to two instances in parallel. Contact us if you need more. 

\- Instances run a customizable JupyterLab deployments (currently there's TensorFlow 1.10, 1.9, 1.8, 1.7 and 1.5 with Keras on CuDNN 9.0, as well as PyTorch 0.4 and prebuilt [fast.ai](https://fast.ai) instance) 

\- You can access the command line and with full root access and use at as regular Linux server 

Our goal is to lower the entry barrier for deep learning so we will work hard to make sure we support the community. We are inviting you to help us learn how we can better support researchers in the field of AI. We want to improve the product, and so we are exploring the community feedback. 

We will be providing free GPU time, reaching out to the registered users and asking for feedback. If this sounds like something that would fit you, please don't hesitate to sign up at [https://dashboard.tensorpad.com/signup](https://dashboard.tensorpad.com/signup) 

If you have any questions, feature requests or any other feedback, reach us using the chat button in dashboard, or drop an email to [support@tensorpad.com](mailto:support@tensorpad.com) 

Thanks for your attention! ",9,29
82,2018-8-26,2018,8,26,22,9afoyr,I'm new to Python and Tensorflow,https://www.reddit.com/r/tensorflow/comments/9afoyr/im_new_to_python_and_tensorflow/,xbatery,1535291808,"&amp;#x200B;

I want to implement Tensorflow in a Python trading algorithm. How  should I move forward? I've installed Tensorflow CPU with Anaconda, and  would like to start working with it now- what's next? Any courses, pdf's  etc?",4,0
83,2018-8-26,2018,8,26,23,9afpwd,Whats your take on google colab?,https://www.reddit.com/r/tensorflow/comments/9afpwd/whats_your_take_on_google_colab/,imposter3c,1535292044,I would like to hear your opinion on what you think about google CoLab? Is there a reason youll never use this free tool?,4,5
84,2018-8-27,2018,8,27,0,9ag7xq,Tensorflow Basic LSTM cell input,https://www.reddit.com/r/tensorflow/comments/9ag7xq/tensorflow_basic_lstm_cell_input/,user01052018,1535296307,"Just having a small doubt. Suppose I want to make an encoder for encoding sentences of length 5.

Example wise:- ""I am a good boy"" I will tokenize it and will convert them to some word vectors of dimension 1x 4.

`[[0 1 2 3],[4,5,6,7],[8,9,10,11][12,13,14,15],[16,17,18,19]]`

`I              am         a         good            boy`

`[[20 21 22 23],[24,25,26,27],[28,29,30,31][32,33,34,35],[36,37,38,39]]`

  `He                is          very         bad            person`

&amp;#x200B;

Now I want to codify each of these sentence.  I am confused regarding initializing the LSTM cell and how to pass the data to it. 

&amp;#x200B;

For example,

1.  Should I pass the data like this?

`[`

`[[0 1 2 3],[4,5,6,7],[8,9,10,11][12,13,14,15],[16,17,18,19]],`

`[[20 21 22 23],[24,25,26,27],[28,29,30,31][32,33,34,35],[36,37,38,39]]`

`]`

&amp;#x200B;

&amp;#x200B;

or

`[`

`[[0 1 2 3],[20,21,22,23]],`

`[[4,5,6,7],[24,25,26,27]],`

`[[8,9,10,11],[28,29,30,31]],`

`....`

`]`

&amp;#x200B;

2. Also what will be the output in this case?  ***Suppose I want to have LSTMcell with 16 hidden units.*** 

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;",0,1
85,2018-8-27,2018,8,27,2,9ah1vy,Intro to tensor flow that isn't just running other people's scripts?,https://www.reddit.com/r/tensorflow/comments/9ah1vy/intro_to_tensor_flow_that_isnt_just_running_other/,vibrunazo,1535302857,"I've done the basic MNIST tutorial on the official docs. I've done some of the YouTube videos that showed up when googling. I have done the (highly recommend here) tensor flow for poets.

But all of those share a common problem: they're basically ""A run this command to download this premade data set"". Then ""B run this script I made for you"". That's it. See those numbers on the screen? That's tensor flow. So, have you learned tensor flow yet? No I'm pretty sure I have not.

I still have no clue how to adapt what I ""learned"" to different use cases. I have no idea how to use my own data sets and solve my own problems. I was particularly interested in object detection. But even the custom object detection tutorials I found have the same problem. Literally all of them use a third party script from a guy who made a raccoon detection and just tell me to run his script with my images instead of raccoons. But that isn't teaching me *how* the API works. It just telling me to run someone else's script. I have no idea how his script loads images to form tfrecords (which is apparently something I have to understand, but I still don't).

Is there any guide, tutorial, video, whatever, that actually teaches how to use the API instead of just telling me to run other people's scripts?",5,3
86,2018-8-27,2018,8,27,5,9aijuz,Changing the batch size of a frozen graph (.pb)?,https://www.reddit.com/r/tensorflow/comments/9aijuz/changing_the_batch_size_of_a_frozen_graph_pb/,MogwaiAllOnYourFace,1535314078,"I've looked all over for this and I can't find anything but I think that may be due to me using the incorrect language so bare with me.

&amp;#x200B;

I have trained a model, and have it frozen as a .pb file - within tensorboard this is looking exactly how it should.

&amp;#x200B;

The problem I have is it is set with a variable batch size such that the input dimension is \[?,480,360,3\].

&amp;#x200B;

Now I am trying to convert to a TF Lite file, and it's having a real issue with this, and I've read that TF Lite wants a fixed batch size to optimise which is fine. It is a real time model so I want to set the batch size to 1.

&amp;#x200B;

So I am looking for a way, preferably from the command line as I'd rather avoid retraining, to change all the questions marks in the graph to ones.

&amp;#x200B;

I've looked all over, it seems like it is something that would be quite common to me so I'm confused as to why I can't find anything about it",7,5
87,2018-8-27,2018,8,27,22,9aosb6,How does my optimizer know which variables to perform gradient descent on when i call optimizer.minimize(cost.fn),https://www.reddit.com/r/tensorflow/comments/9aosb6/how_does_my_optimizer_know_which_variables_to/,ady_anr,1535375344,,3,0
88,2018-8-28,2018,8,28,2,9aqowf,Is there a way to download tensorboard plots?,https://www.reddit.com/r/tensorflow/comments/9aqowf/is_there_a_way_to_download_tensorboard_plots/,CognitiveDiagonal,1535389201,"Is there a way to download the plots that tensorboard shows in the scalar dashboard?

I've seen them used multiple times as images in presentations or blogs but I can't find an option to download them and after some googling I didn't find anything. I know I can download the csv or json with the values ploted, but given that tensorboard already plots it it'd be nice to simply download it as an image.

Thanks in advance!!",5,3
89,2018-8-29,2018,8,29,6,9b2vah,I have problems import Tensorflow with gpu backend,https://www.reddit.com/r/tensorflow/comments/9b2vah/i_have_problems_import_tensorflow_with_gpu_backend/,Dropcunts,1535490772,"I always get the same error. Can anybody help please? 

&amp;#x200B;

           _pywrap_tensorflow_internal = swig_import_helper()
          File ""C:\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 17, in swig_import_helper
            return importlib.import_module(mname)
          File ""C:\Python\Python36\lib\importlib\__init__.py"", line 126, in import_module
            return _bootstrap._gcd_import(name[level:], package, level)
        ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.
    
    
        Failed to load the native TensorFlow runtime.
    
        See https://www.tensorflow.org/install/install_sources#common_installation_problems
    
        for some common reasons and solutions.  Include the entire stack trace
        above this error message when asking for help.

&amp;#x200B;",6,2
90,2018-8-30,2018,8,30,0,9bahr0,Where can I find labled training data?,https://www.reddit.com/r/tensorflow/comments/9bahr0/where_can_i_find_labled_training_data/,WarrantyVoider,1535557984,"Hi,
im playing around with the object detection part of tensorflow and already successfully trained my first model to detect cars, so thats cool already. My plan is to detect and count cars in a webcam feed, but I noticed my results arent very pretty yet (multiple boxes around a car instead of one) and I suspect my training data isnt good enough.
I downloaded 110 images of cars via google image search, labeled them per hand and then split them up in 10 test images and 100 training images. But it seems the training doesnt want to go under 2% loss, so I guess I need more or better data. 
I assume im not the first person that wants to detect cars, and I wanna learn how to train it myself, so I dont wanna use a ready-to-use model... are there any places where I could download pre labeled training images of f.e. cars? If not, what should I take care of when labeling the images myself to get better results? simply ""more""? thanks for your time in advance

greetz",6,1
91,2018-8-30,2018,8,30,1,9baqp2,How to use Keras with tfrecords,https://www.reddit.com/r/tensorflow/comments/9baqp2/how_to_use_keras_with_tfrecords/,smokrow,1535559657,,0,11
92,2018-8-30,2018,8,30,3,9bc18c,I am almost defeated by an error in loading variables. It has persisted for months and I cannot solve it. Can anyone please look at my stackoverflow link and help me determine the issue?,https://www.reddit.com/r/tensorflow/comments/9bc18c/i_am_almost_defeated_by_an_error_in_loading/,Xyoloswag420blazeitX,1535568386,https://stackoverflow.com/questions/52084151/tensorflow-error-when-loading-model-trained-using-tf-layers-api,3,5
93,2018-8-30,2018,8,30,16,9bhmrh,Image Classification,https://www.reddit.com/r/tensorflow/comments/9bhmrh/image_classification/,jango1502,1535615247,"I am starting a new project on image classification. I have tried using transfer learning on my training dataset but didn't work well...tried changing hyperparameters too but no sign of improvement shown. Accuracy for all the epochs were exactly same and it seems the model is not training at all.

So I have thought of training a new model, a simplest CNN model with three convolutional layers with fully connected layers and pooling layers. 

I will train my model from scratch on my dataset

What should be my approach ?? Can anyone give me some suggestions ?? What model I can use to train from scratch ?? Anything good that I should know ?? ",14,1
94,2018-8-31,2018,8,31,6,9bnvve,Best way of importing scipy sparse matrices (32MB each when dense) as a dataset?,https://www.reddit.com/r/tensorflow/comments/9bnvve/best_way_of_importing_scipy_sparse_matrices_32mb/,elpaw,1535666356,"I have a folder containing 100,000 files (let's call them images), each one a sparse matrix (stored in numpy's npz format). Each image is 32MB when unsparsified.

I wish to use these as a training dataset in tensorflow(/keras).

They are too large to load completely into memory, so I would like batches of them loaded at a time. A batch of N images is randomly selected from the files on disk, then loaded, *some processing here*, fed into training session.

Does a solution for this already exist somewhere out there?",4,3
95,2018-8-31,2018,8,31,23,9btzhk,How Do I Use My Retrained Inception_v3 Model?,https://www.reddit.com/r/tensorflow/comments/9btzhk/how_do_i_use_my_retrained_inception_v3_model/,PhoebusElpollo,1535725057,"when I use the command on the website, it doesn't work, I get a bunch of errors that all end in:```
 ; No such process
         [[Node: file_reader = ReadFile[_device=""/job:localhost/replica:0/task:0/device:CPU:0""](file_reader/filename)]]
```
I did change out the image path to my own image, please help, I have been stuck on this for a while now
",8,1
0,2018-9-1,2018,9,1,18,9c1qux,How to understand the gradients in the build_backprop?,https://www.reddit.com/r/tensorflow/comments/9c1qux/how_to_understand_the_gradients_in_the_build/,Catherine_Fang,1535793214," What confuses me is `gradients`, the tensorflow docs say `[model.input]` is the input, and 
the `[loss, gradients]` is the output? If so, what the function of the `gradients /= (K.sqrt(K.mean(K.square(gradients))) + 1e-5)`. From my understanding, its value will be wiped.

    def build_backprop(model, loss):
        # Gradient of the input image with respect to the loss function
        gradients = K.gradients(loss, model.input)[0]
        # Normalize the gradients
        gradients /= (K.sqrt(K.mean(K.square(gradients))) + 1e-5)
        # Keras function to calculate the gradients and loss
        return K.function([model.input], [loss, gradients])


code link: https://github.com/waleedka/cnn-visualization/blob/master/cnn_visualization.ipynb ",0,1
1,2018-9-1,2018,9,1,23,9c3itk,Translating code from Sessions to Estimator API (for TPU),https://www.reddit.com/r/tensorflow/comments/9c3itk/translating_code_from_sessions_to_estimator_api/,jthat92,1535812777,"Hi guys!

I want to use the TPU on training my model. The code I have is basically written in low level API using Graphs and Sessions. For the TPU it is necessary to use the TPUEstimator API. Basically I have to translate my code into the Estimator API first from what I understand.

Is this the only way for now I can use the TPU? Also how much work is it to translate the code into another API? 

Maybe someone can guide me through doing it? 

Thanks for any help and suggestions!",8,2
2,2018-9-2,2018,9,2,9,9c862i,How To Modify Example Android Object Detection Model For My Model,https://www.reddit.com/r/tensorflow/comments/9c862i/how_to_modify_example_android_object_detection/,1cmanny1,1535849502,"I have a model that looks at images and draws boxes around the detected object. I followed this tutorial to do it, https://www.youtube.com/watch?v=Rgpfk6eYxJA

Now, I want to get this on Android. I'm struggling to do this, can't find an updated step by step tutorial. 

I have a working app off someones example, however I hoped that to modify it all I had to do was change out the graph.pb and the strings.txt. No such luck, of course. 

https://blog.mindorks.com/android-tensorflow-machine-learning-example-ff0e9b2654cc


Does anyone have advice, or a good tutorial to follow?",1,3
3,2018-9-3,2018,9,3,1,9cdl3v,Problems with my code that I can't figure out since few days,https://www.reddit.com/r/tensorflow/comments/9cdl3v/problems_with_my_code_that_i_cant_figure_out/,craaaft,1535907556,"Hi!

I have a problem with my tensorflow based code and already after spending hours on it I can't figure it out. Here is the link to the [stackoverflow post](https://stackoverflow.com/questions/52139076/problems-with-dimensions-for-tf-nn-sigmoid-cross-entropy-with-logits-can-not-sq)

Any help would be greatly appreciated!",3,4
4,2018-9-4,2018,9,4,8,9cqgfa,TensorFlow Lego Sorter,https://www.reddit.com/r/tensorflow/comments/9cqgfa/tensorflow_lego_sorter/,_paco3,1536018487,"This is my first adventure with a Raspberry Pi and TensorFlow.  Took me roughly 200 hours starting from Python basics and having to learn everything (from mechanical design, motors, sensors to TensorFlow).

There is a lot of opportunity for this to improve, but for now it feels great to at least close the loop on this 6 month project.

I've shared the image set and 2 evaluation runs, just in case you want to wet your feet and replicate.

Comments, ideas and suggestion welcome.  Be kind!

[https://medium.com/@pacogarcia3/tensorflow-on-raspbery-pi-lego-sorter-ab60019dcf32](https://medium.com/@pacogarcia3/tensorflow-on-raspbery-pi-lego-sorter-ab60019dcf32)

[https://www.youtube.com/watch?v=uCuQsNwX1QY](https://www.youtube.com/watch?v=uCuQsNwX1QY)

&amp;#x200B;",4,36
5,2018-9-5,2018,9,5,4,9cyt5b,In-browser machine learning with TensorFlow.JS: A tutorial to teach your browser where you are looking at,https://www.reddit.com/r/tensorflow/comments/9cyt5b/inbrowser_machine_learning_with_tensorflowjs_a/,cpury,1536088816,,0,14
6,2018-9-5,2018,9,5,20,9d5i2b,Open for Opinions about validation loss's weird behavioiur while training an Image Classifier (CNN),https://www.reddit.com/r/tensorflow/comments/9d5i2b/open_for_opinions_about_validation_losss_weird/,jango1502,1536146192,"Made a CNN classifier model to classify images under 4 categories. Number of images per category is approx 550 including validation images. The model runs and give a decent accuracy on validation data but I am not understanding the trend of the validation loss through out the training process.

Here is the output of the training. Can anyone tell me why validation loss through out the training got up and down ranging in between 0.400 - 1.300

I understand this could be happen due to overfitting but still want to be sure about it.

Epoch 1 --- Training Accuracy: 31.2%, Validation Accuracy: 25.0%, Validation Loss: 1.457

Epoch 2 --- Training Accuracy: 62.5%, Validation Accuracy: 59.4%, Validation Loss: 1.220

Epoch 3 --- Training Accuracy: 71.9%, Validation Accuracy: 68.8%, Validation Loss: 0.990

Epoch 4 --- Training Accuracy: 75.0%, Validation Accuracy: 56.2%, Validation Loss: 0.887

Epoch 5 --- Training Accuracy: 78.1%, Validation Accuracy: 71.9%, Validation Loss: 0.752

Epoch 6 --- Training Accuracy: 84.4%, Validation Accuracy: 71.9%, Validation Loss: 0.732

Epoch 7 --- Training Accuracy: 87.5%, Validation Accuracy: 65.6%, Validation Loss: 0.790

Epoch 8 --- Training Accuracy: 84.4%, Validation Accuracy: 75.0%, Validation Loss: 0.736

Epoch 9 --- Training Accuracy: 84.4%, Validation Accuracy: 68.8%, Validation Loss: 0.654

Epoch 10 --- Training Accuracy: 87.5%, Validation Accuracy: 68.8%, Validation Loss: 0.786

Epoch 11 --- Training Accuracy: 87.5%, Validation Accuracy: 71.9%, Validation Loss: 0.743

Epoch 12 --- Training Accuracy: 87.5%, Validation Accuracy: 78.1%, Validation Loss: 0.605

Epoch 13 --- Training Accuracy: 87.5%, Validation Accuracy: 68.8%, Validation Loss: 0.825

Epoch 14 --- Training Accuracy: 87.5%, Validation Accuracy: 71.9%, Validation Loss: 0.759

Epoch 15 --- Training Accuracy: 87.5%, Validation Accuracy: 81.2%, Validation Loss: 0.559

Epoch 16 --- Training Accuracy: 90.6%, Validation Accuracy: 68.8%, Validation Loss: 0.874

Epoch 17 --- Training Accuracy: 90.6%, Validation Accuracy: 75.0%, Validation Loss: 0.759

Epoch 18 --- Training Accuracy: 90.6%, Validation Accuracy: 78.1%, Validation Loss: 0.520

Epoch 19 --- Training Accuracy: 90.6%, Validation Accuracy: 65.6%, Validation Loss: 0.940

Epoch 20 --- Training Accuracy: 90.6%, Validation Accuracy: 78.1%, Validation Loss: 0.741

Epoch 21 --- Training Accuracy: 93.8%, Validation Accuracy: 75.0%, Validation Loss: 0.536

Epoch 22 --- Training Accuracy: 90.6%, Validation Accuracy: 62.5%, Validation Loss: 1.072

Epoch 23 --- Training Accuracy: 90.6%, Validation Accuracy: 78.1%, Validation Loss: 0.775

Epoch 24 --- Training Accuracy: 93.8%, Validation Accuracy: 71.9%, Validation Loss: 0.587

Epoch 25 --- Training Accuracy: 93.8%, Validation Accuracy: 59.4%, Validation Loss: 1.113

Epoch 26 --- Training Accuracy: 93.8%, Validation Accuracy: 78.1%, Validation Loss: 0.859

Epoch 27 --- Training Accuracy: 93.8%, Validation Accuracy: 78.1%, Validation Loss: 0.607

Epoch 28 --- Training Accuracy: 93.8%, Validation Accuracy: 65.6%, Validation Loss: 1.123

Epoch 29 --- Training Accuracy: 93.8%, Validation Accuracy: 75.0%, Validation Loss: 1.012

Epoch 30 --- Training Accuracy: 96.9%, Validation Accuracy: 68.8%, Validation Loss: 0.700

Epoch 31 --- Training Accuracy: 96.9%, Validation Accuracy: 68.8%, Validation Loss: 1.236

Epoch 32 --- Training Accuracy: 96.9%, Validation Accuracy: 65.6%, Validation Loss: 1.382

Epoch 33 --- Training Accuracy: 100.0%, Validation Accuracy: 68.8%, Validation Loss: 0.919

Epoch 34 --- Training Accuracy: 96.9%, Validation Accuracy: 62.5%, Validation Loss: 1.661

Epoch 35 --- Training Accuracy: 100.0%, Validation Accuracy: 65.6%, Validation Loss: 1.363

Epoch 36 --- Training Accuracy: 100.0%, Validation Accuracy: 71.9%, Validation Loss: 0.740

Epoch 37 --- Training Accuracy: 100.0%, Validation Accuracy: 71.9%, Validation Loss: 1.390

Time elapsed: 0:53:26 Accuracy on Test-Set: 70.2% (351 / 500)",2,1
7,2018-9-6,2018,9,6,2,9d8wsr,Retraining with TensorFlow Hub,https://www.reddit.com/r/tensorflow/comments/9d8wsr/retraining_with_tensorflow_hub/,kei_kuro,1536169180,"I'm new to TensorFlow, so I would really appreciate any help with this.

I would like to retrain a TF Hub module and use the re-trained embeddings for a different task. How can this be achieved?

What I'd like to do in pseudocode:

    feature_column = hub.text_embedding_column(module_spec='tfhub.dev/...', trainable=True)
    est_task1 = tf.estimator.DNNClassifier(feature_columns=[feature_column, ...], ...)
    est_task1.train(...)
    
    # use retrained weights
    est_task2 = tf.estimator.DNNClassifier(feature_columns=[feature_column, ...], ...)
    est_task2.train(...)

I'm pretty sure it doesn't work like that, though.",0,3
8,2018-9-6,2018,9,6,13,9devo9,Good tpu tutorials,https://www.reddit.com/r/tensorflow/comments/9devo9/good_tpu_tutorials/,guzguzit,1536209055,"Hey all,
I am looking for a good tutorial for using tpu using my own dataset and model. Any recommendations?",2,3
9,2018-9-6,2018,9,6,18,9dgm1o,How to build and install TensorFlow GPU/CPU for Windows from source code using bazel and Python 3.6,https://www.reddit.com/r/tensorflow/comments/9dgm1o/how_to_build_and_install_tensorflow_gpucpu_for/,amsokol,1536224842,,1,13
10,2018-9-7,2018,9,7,8,9doi90,Int to int with embedding lookup or slice?,https://www.reddit.com/r/tensorflow/comments/9doi90/int_to_int_with_embedding_lookup_or_slice/,throwaway775849,1536277159,"Is one more efficient or correct?

    embeddings = tf.constant(shape=[])

    # 1
    idx = tf.nn.embedding_lookup(embeddings, i)

    # or 2
    idx = embeddings[i]
",1,2
11,2018-9-7,2018,9,7,10,9dph2x,Iterate a tensor using for loop,https://www.reddit.com/r/tensorflow/comments/9dph2x/iterate_a_tensor_using_for_loop/,stargazer63,1536283953,"I have a tensor of shape \[100,7,7,64\]. I would like to iterate through this tensor, separate out the 100 images, later separate out the 64 filter values for that image. I guess the way to do it would be to iterate through the tensor using a for loop. I am not sure how to do it. Any pointer to the right direction is greatly appreciated.",0,2
12,2018-9-7,2018,9,7,15,9drkiq,[Tensorflow ] Tensorflow for Beginners,https://www.reddit.com/r/tensorflow/comments/9drkiq/tensorflow_tensorflow_for_beginners/,thecodingfossil,1536301466,,0,0
13,2018-9-7,2018,9,7,21,9dtoqn,Looking for example code of tf.data.Dataset,https://www.reddit.com/r/tensorflow/comments/9dtoqn/looking_for_example_code_of_tfdatadataset/,Andaarrs,1536321798,"Hey guys!

As the title says, I'm looking for code samples that incorporates the Dataset class to read tfrecord files (as produced by [this](https://github.com/tensorflow/models/blob/master/research/slim/datasets/download_and_convert_cifar10.py) for example). I'm struggling to make the reading/decoding process work for anything but simple data. My code so far is [this](https://pastebin.com/zEG4GKm9), running it produces this error:


    tensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence
             [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[&lt;unknown&gt;, [128]], output_types=[DT_UINT8, DT_INT64], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](OneShotIterator)]]
    
    Caused by op 'IteratorGetNext', defined at:
      File ""/src/image_test.py"", line 22, in &lt;module&gt;
        itr = dataset.make_one_shot_iterator().get_next()
      File ""/tensorflow/lib/site-packages/tensorflow/python/data/ops/iterator_ops.py"", line 410, in get_next
        name=name)), self._output_types,
      File ""/tensorflow/lib/site-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2107, in iterator_get_next
        output_shapes=output_shapes, name=name)
      File ""/tensorflow/lib/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
        op_def=op_def)
      File ""/tensorflow/lib/site-packages/tensorflow/python/util/deprecation.py"", line 454, in new_func
        return func(*args, **kwargs)
      File ""/tensorflow/lib/site-packages/tensorflow/python/framework/ops.py"", line 3155, in create_op
        op_def=op_def)
      File ""/tensorflow/lib/site-packages/tensorflow/python/framework/ops.py"", line 1717, in __init__
        self._traceback = tf_stack.extract_stack()

From previous experience that means the iterator is empty because no data was made available to it because the parse_fn method is not working properly.

Any advice, code samples, blog articles, git repositories or comforting words are welcome!",4,2
14,2018-9-8,2018,9,8,2,9dwjx0,"How long do I need to train, or do I need to use another model?",https://www.reddit.com/r/tensorflow/comments/9dwjx0/how_long_do_i_need_to_train_or_do_i_need_to_use/,WarrantyVoider,1536341379,,9,2
15,2018-9-8,2018,9,8,4,9dxmd8,How to Find Error after Reloading Model?,https://www.reddit.com/r/tensorflow/comments/9dxmd8/how_to_find_error_after_reloading_model/,throwaway775849,1536348153,"I trained a model to a loss of 0.01. I saved it and quit the program, but when I reload the model from the checkpoint, my loss is around 20 again. How can I find what I'm doing wrong with the reload?",0,1
16,2018-9-8,2018,9,8,6,9dylvv,How do I add labels to an already trained model? What would this be called?,https://www.reddit.com/r/tensorflow/comments/9dylvv/how_do_i_add_labels_to_an_already_trained_model/,TensorAskerJ,1536354706,"What I would like to do is take the mobilenet model provided in the examples and feed in some training images, such that the new, final model has the original mobilenet labels as well as my own. So, for example, the mobilenet_v2_1.4_224 model doesn't really handle Coca-Cola cans (it recognizes as ""pop bottle"" most of the time). I'd like to push in 500 images of Coca-cola cans as a new, additional label, while still retaining the rest of the mobilenet labels.

What would this process be called? Is there a specific name? Retraining, in the tensorflow documentation, always seems create a new model. Fine-tuning seems to be applying the learned model to a new set of labels. I think what I would try to do is resume the retraining using the mobilenet checkpoint that can be found in [https://storage.googleapis.com/mobilenet_v2/checkpoints/mobilenet_v2_1.4_224.tgz](https://storage.googleapis.com/mobilenet_v2/checkpoints/mobilenet_v2_1.4_224.tgz), but I haven't been able to find any documentation on how to accomplish this.

Apologies if this is a dumb question or if I'm just missing something in the docs.",3,3
17,2018-9-9,2018,9,9,14,9eaprn,"Humble Book Bundle: Machine Learning by O'Reilly. $641 worth of Machine Learning Books like Introduction to Machine Learning with Python, Learning TensorFlow, 1Ed, and Thoughtful Machine Learning with Python, 1Ed is 97% OFF !",https://www.reddit.com/r/tensorflow/comments/9eaprn/humble_book_bundle_machine_learning_by_oreilly/,varran,1536470644,,4,11
18,2018-9-9,2018,9,9,16,9ebe34,Eager Execution in TensorFlow : A more Pythonic way of building models,https://www.reddit.com/r/tensorflow/comments/9ebe34/eager_execution_in_tensorflow_a_more_pythonic_way/,championswimmer,1536479346,,3,17
19,2018-9-9,2018,9,9,17,9ebib5,Rocm Tensorflow Upgrade,https://www.reddit.com/r/tensorflow/comments/9ebib5/rocm_tensorflow_upgrade/,jabbaluck,1536481044, Hey i wanna do an upgrade to my pc. I want to get CPU MOBO n RAM video cards i allready have. But it comes hard to decide between an normal CPU ryzen or a threatripper. I know threatripper has 64 PCie lines that will run 16x 2 video cards n x8 other 2 cards. Would i need all this computation power for tensorflow modeling ? Any tips would be much appreciated . Thanks ,1,1
20,2018-9-9,2018,9,9,19,9ec2o0,My first ever using TF. I managed to make it x100 slower than numpy. What did I do wrong?,https://www.reddit.com/r/tensorflow/comments/9ec2o0/my_first_ever_using_tf_i_managed_to_make_it_x100/,powerexcess,1536489410,"First time ever I tried anything with tensorflow. I copy pasted and adapted a K means implementation from [here](https://codesachin.wordpress.com/2015/11/14/k-means-clustering-with-tensorflow/).
When I run it and compare the time elapsed with the default sklearn implementation I get like x100 times more time to run.
[Here](https://gist.github.com/DGeorgiadis/fdba48f086f90ec048a408cc47f576e0.js) is the code I am running:

",6,7
21,2018-9-10,2018,9,10,1,9ee37i,Which tutorial for RNN in tensorflow?,https://www.reddit.com/r/tensorflow/comments/9ee37i/which_tutorial_for_rnn_in_tensorflow/,yosoufe,1536509176,Hi. I am looking for some tutorials to make an RNN only tensorflow. Do you know any?,2,0
22,2018-9-10,2018,9,10,7,9eh1kf,I Have Python 3.7 Installed... Is There Hope?,https://www.reddit.com/r/tensorflow/comments/9eh1kf/i_have_python_37_installed_is_there_hope/,EndureTillEnd,1536531321,"I am aware that the TensorFlow does not work with 3.7; but since I already have 3.7 install and it seems that I cannot roll back Python to 3.6 (could not find a way), what can I possibly do?",18,2
23,2018-9-10,2018,9,10,23,9enj1u,Tensorflow running on FPGAs?,https://www.reddit.com/r/tensorflow/comments/9enj1u/tensorflow_running_on_fpgas/,TheElephantOrder,1536589056,"Would it make sense to have Tensorflow running on FPGAs?  Imagine, besides doing tf.device(""/gpu:0""), you can also do tf.device(""/fpga:0""). Will this be interesting or useful to you? ",4,5
24,2018-9-11,2018,9,11,7,9errjw,What other language or technology do you recommend me to interact with TensorFlow?,https://www.reddit.com/r/tensorflow/comments/9errjw/what_other_language_or_technology_do_you/,thefernandito,1536618418,"Hello friends, soy programmer Python and some time ago I started with TensorFlow, which I'm already understanding quite well.
My query is that another language or technology recommends me to learn to interact with TF.",4,0
25,2018-9-11,2018,9,11,8,9esdo9,Running Tensorflow in Docker on Kubernetes - Avoid These Issues,https://www.reddit.com/r/tensorflow/comments/9esdo9/running_tensorflow_in_docker_on_kubernetes_avoid/,spongiey,1536623238,,0,1
26,2018-9-12,2018,9,12,0,9eycgf,An invitation to join r/MachinesLearn,https://www.reddit.com/r/tensorflow/comments/9eycgf/an_invitation_to_join_rmachineslearn/,lohoban,1536678312,"(Posted with permission from moderators.)

I invite you to join new community of machine learning professionals: [r/MachinesLearn](https://www.reddit.com/r/MachinesLearn). Just in three days our community has grown from 0 to 2.5K members.

Here I will try to explain why we need a new community about AI and machine learning, and how it's different from the major existing ones, namely [r/MachineLearning](https://www.reddit.com/r/MachineLearning), [r/artificial](https://www.reddit.com/r/artificial), [r/datascience](https://www.reddit.com/r/datascience) and [r/learnmachinelearning](https://www.reddit.com/r/learnmachinelearning).

After multiple discussions with moderators of those communities, here's how we position our new subreddit.

First of all, it's a community for industry professionals. This differs us from [r/MachineLearning](https://www.reddit.com/r/MachineLearning), which is seen by many as an academic/research focused community. We assume that our typical reader is a machine learning professional, a programmer or an engineer. This differs us from [r/datascience](https://www.reddit.com/r/datascience) whose range of topics is much wider, including a much larger body of statistics, visualization, storytelling, experiment design, A/B testing, and so on. This also differs us from [r/learnmachinelearning](https://www.reddit.com/r/learnmachinelearning), which plans a merger with [r/MLQuestions](https://www.reddit.com/r/MLQuestions) to focus primarily on answering ML-related questions from subscribers. [r/MachinesLearn](https://www.reddit.com/r/MachinesLearn) only accepts posts with questions if they contain answers, even if partial, to the problem of the poster.

Finally, the main focus of [r/MachinesLearn](https://www.reddit.com/r/MachinesLearn) is sharing links to tutorials (video or with source code), packages, libraries and frameworks, DIYs and how-tos. This differs us from [r/artificial](https://www.reddit.com/r/artificial) which is often used as a platform to share AI-related news, and is seen by us as less programmer-oriented.

I hope now you see our niche. We will be happy if you join!

Thanks to r/tensorflow moderators for letting us post this announcement.",0,4
27,2018-9-12,2018,9,12,1,9ez6yi,"Android Developers looking for ways to venture into Machine Learning, I wrote a blog outlining the possible ways you, as a mobile developer start with Machine Learning without getting overwhelmed with all the Maths behind it!",https://www.reddit.com/r/tensorflow/comments/9ez6yi/android_developers_looking_for_ways_to_venture/,the-dagger,1536684167,,0,1
28,2018-9-12,2018,9,12,1,9ez73v,"Mobile Developers looking for ways to venture into Machine Learning, I wrote a blog outlining the possible ways you, as a mobile developer start with Machine Learning without getting overwhelmed with all the Maths behind it!",https://www.reddit.com/r/tensorflow/comments/9ez73v/mobile_developers_looking_for_ways_to_venture/,the-dagger,1536684197,,1,8
29,2018-9-12,2018,9,12,6,9f1gkv,live people identifier,https://www.reddit.com/r/tensorflow/comments/9f1gkv/live_people_identifier/,medical_moron,1536700555,Does anyone know a way for tensorflow to differentiate between people other than facial recognition??,0,0
30,2018-9-12,2018,9,12,7,9f268a,Differences between validation and test,https://www.reddit.com/r/tensorflow/comments/9f268a/differences_between_validation_and_test/,Good_Development,1536706022,"Hi, I'm a programmer and I'm starting with Tensorflow and DL.
Could you explain me the difference between ""validation"" and ""test"" data in a neural network?

The data of ""training"" I have clear, but I confuse with validation and test. Are not they good for the same? Are not both to contrast the training data? 

Thank you very much.",4,2
31,2018-9-12,2018,9,12,18,9f639d,Deep learning for android games,https://www.reddit.com/r/tensorflow/comments/9f639d/deep_learning_for_android_games/,logTom,1536743252,"Hi, is it somehow possible for a mediumish experienced developer to setup openai/tensorflow/alphago zero training on android games? Where should I start?",3,2
32,2018-9-13,2018,9,13,7,9fcgdd,Would anyone be kind enough to take a look at my question on Stack Overflow? I sometimes have some trouble getting views there.,https://www.reddit.com/r/tensorflow/comments/9fcgdd/would_anyone_be_kind_enough_to_take_a_look_at_my/,kds_medphys,1536791657,[https://stackoverflow.com/questions/52304339/how-can-i-ensure-the-correct-behavior-of-tf-control-dependencies-when-i-am-tra](https://stackoverflow.com/questions/52304339/how-can-i-ensure-the-correct-behavior-of-tf-control-dependencies-when-i-am-tra),3,4
33,2018-9-14,2018,9,14,10,9fnvgu,"Machine Reading Comprehension Part II: Learning to Ask &amp; Answer  Han Xiao Tech Blog - Deep Learning, Tensorflow, Machine Learning and more!",https://www.reddit.com/r/tensorflow/comments/9fnvgu/machine_reading_comprehension_part_ii_learning_to/,h_xiao,1536888744,,0,18
34,2018-9-14,2018,9,14,17,9fq8gb,Can someone suggest a good resource for debugging/diagnosing network/memory bandwidth issues?,https://www.reddit.com/r/tensorflow/comments/9fq8gb/can_someone_suggest_a_good_resource_for/,AlphaShifter,1536913185,,3,2
35,2018-9-14,2018,9,14,22,9fs44j,Predict result of a single image,https://www.reddit.com/r/tensorflow/comments/9fs44j/predict_result_of_a_single_image/,jthat92,1536932675,"Hi guys,

I got a model that I trained on the Google Cloud/TPU, but I don't know how I can predict the result for a single picture. It seems that is not that straight forward as I thought. I am having even troubles with saving the model. I just want to put a picture into the trained model and see what the result is with a single command line. 

Any tips, advices and/or how-tos?",4,1
36,2018-9-16,2018,9,16,16,9g8sxi,Tensorflow CNN - z_dim: What is it?,https://www.reddit.com/r/tensorflow/comments/9g8sxi/tensorflow_cnn_z_dim_what_is_it/,d8sconz,1537082519,"The docs say ""number of samples to take for each z"". Helpful. Interestingly that's what almost all tutorials also say, with no further attempt to explain. What's a z?",6,3
37,2018-9-17,2018,9,17,16,9gi4b2,Is there any standard book on Tensorflow?,https://www.reddit.com/r/tensorflow/comments/9gi4b2/is_there_any_standard_book_on_tensorflow/,jthat92,1537167766,"I guess I am better of with online tutorials and courses, but I often like to learn just from a book, to not sit in front of the PC for too long.

Also regarding online ressources. Besides the official documentation any stuff I should definitly check out? I recently started using ""Complete Guide to TensorFlow for Deep Learning with Python"" by Jose Portilla so I guess I should be covered, but I just want to make sure.

Any help and suggestions are greatly appreciated!",5,2
38,2018-9-17,2018,9,17,17,9gifd7,A complete guide for building machine learning and deep learning solutions using Tensorflow - 4 hours on-demand video + 8 Downloadable Resources + Full lifetime access + Access on mobile and TV + Certificate of Completion,https://www.reddit.com/r/tensorflow/comments/9gifd7/a_complete_guide_for_building_machine_learning/,thecodingfossil,1537171534,,0,1
39,2018-9-17,2018,9,17,19,9gj4zj,Tensorflow Prediction over rest api,https://www.reddit.com/r/tensorflow/comments/9gj4zj/tensorflow_prediction_over_rest_api/,krngd2,1537179899,"I have trained captcha recognition model that I want to host and access it through rest api, What is the best way to do it. Thanks any type of suggestion. ",8,8
40,2018-9-18,2018,9,18,2,9gmj6w,Has anyone managed to compile the tensorflow in python 3.7?,https://www.reddit.com/r/tensorflow/comments/9gmj6w/has_anyone_managed_to_compile_the_tensorflow_in/,laser_velociraptor,1537206515,"I need to deploy a tensorflow project on Google Cloud Functions, but this plataform only has Python 3.7 avaliable (no way to downgrade to older Python).  
[This merge request](https://github.com/tensorflow/tensorflow/pull/21202) fixes part of the problem, but I am not capable of compiling this version myself, because of other libraries (eigen and protobuff), [as seen in this issue](https://github.com/tensorflow/tensorflow/issues/20517).

So, was anyone able to compile cpu  TF for Linux and python 3.7? Could anyone share a .whl with the compiled version?",4,13
41,2018-9-18,2018,9,18,13,9grrce,Is this possible in Tensorflow? Only partially loading a model?,https://www.reddit.com/r/tensorflow/comments/9grrce/is_this_possible_in_tensorflow_only_partially/,BatmantoshReturns,1537245804,"I'm training over 1 million embeddings, which Google Colab can not handle due to lack of ram (Colab has 12.7 GB ram) if I go over an embedding of 80. 

I was wonder if somehow Tensorflow could only load the embeddings that are being trained for each batch (the input, the labels, and the negative sampling samples)? I realize that would slow down the training by a lot, but it's something I would want to try. ",1,0
42,2018-9-19,2018,9,19,3,9gx7rx,How to save a model with eager execution?,https://www.reddit.com/r/tensorflow/comments/9gx7rx/how_to_save_a_model_with_eager_execution/,Yajirobe404,1537293959,"How do I save my model object, with all of its weights?

I tried googling but the methods don't work. 

I tried tf.contrib.eager.Checkpoint() method but when I restore from it I get a checkpoint object, not a model object.

tf.contrib.eager.Saver() also did not work. It raises an exception
",4,4
43,2018-9-19,2018,9,19,7,9gzlyq,Queueing data from a numpy memmap file,https://www.reddit.com/r/tensorflow/comments/9gzlyq/queueing_data_from_a_numpy_memmap_file/,SoFarFromHome,1537310737,"I've got 4 million text entires total from about 36k users, for which I've pre-computed 512-dim embeddings (using [Google's Universal Sentence Encoder](https://alpha.tfhub.dev/google/universal-sentence-encoder/2)) and appended a 14-dim covariate vector (so 526 floats total).  

I've saved the pre-computed embeddings as a [numpy memmap](https://docs.scipy.org/doc/numpy/reference/generated/numpy.memmap.html) file, along with a dictionary which maps the user id's and dates to rows in the table and associated dates (stored as ordinal date as int), e.g. `{0: [(0, 736943), (3, 736957), (16, 873701)], ...}`.

I'm setting up an [attention-based model](https://nlp.stanford.edu/pubs/emnlp15_attn.pdf), so when in training when I want to predict the outcome for user `user_id` at ordinal day (int) `day_num`, I'd like to pass an array containing the relevant rows of shape `(?, 526)`.  To put in pseudo/broken code:

    data = np.memmap('/path/to/memmap/file', dtype='float32', mode='read', shape=(n_lines, 526))
    user_id, day_num, outcome = my_fifo_queue.dequeue()
    relevant_row_indices = [item[0] for item in map_dictionary[user_id] if item[1] &lt; day_num]
    training_matrix = data[relevant_row_indices, :]
    summary_embedding = AttentionNetwork(training_matrix)

Any suggestions on how I can intelligently queue this data in tensorflow?",7,1
44,2018-9-19,2018,9,19,20,9h49dj,Autocompletion for Tensorflow,https://www.reddit.com/r/tensorflow/comments/9h49dj/autocompletion_for_tensorflow/,jthat92,1537355795,"I would like to have autocompletion for tensorflow (python). Is there any editor that can do that? I am not well versed in all the dev environments so not sure if this is possible.
Thanks for any help!",7,2
45,2018-9-19,2018,9,19,21,9h4l5o,Batch Normalization in Eager Mode,https://www.reddit.com/r/tensorflow/comments/9h4l5o/batch_normalization_in_eager_mode/,liftoff01,1537359032,"In graph mode, if you apply the batch_norm layer, you have to explicit ""carry"" over the mean and std-dev for them to be updated. Specifically, we do this as:

    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
    with tf.control_dependencies(update_ops):
      train_op = optimizer.minimize(loss)

I was wondering if one has to repeat such a process in eager mode, if yes, then how exactly as we do not have a tf.GraphKeys.UPDATE_OPS any more. 

Thank you for the response. ",2,3
46,2018-9-20,2018,9,20,15,9hcxzy,"I was installing tensorflow with GPU support from source on windows, while building the pip package I m getting the error: Source forest creation error...(Permission denied).",https://www.reddit.com/r/tensorflow/comments/9hcxzy/i_was_installing_tensorflow_with_gpu_support_from/,nixolus,1537424984,,9,1
47,2018-9-20,2018,9,20,16,9hd7hv,Difference between tf.nn.conv2d_transpose and tf.nn.conv2d,https://www.reddit.com/r/tensorflow/comments/9hd7hv/difference_between_tfnnconv2d_transpose_and/,thisisiron,1537427993,"I often saw the use of tf.nn.conv2d, but I rarely saw the use of tf.nn.conv2d\_transpose.

&amp;#x200B;

What are the differences between tf.nn.conv2d and tf.nn.conv2d\_transpose?

&amp;#x200B;

When is tf.nn.conv2d\_transpose usually used?",8,2
48,2018-9-20,2018,9,20,16,9hdc71,TensorFlow Object Detection API Tutorial | Object Detection API | TensorFlow Tutorial | - Great Info,https://www.reddit.com/r/tensorflow/comments/9hdc71/tensorflow_object_detection_api_tutorial_object/,pooja307,1537429536,,0,1
49,2018-9-20,2018,9,20,17,9hdfl2,Question about best strategy: image deconvolution,https://www.reddit.com/r/tensorflow/comments/9hdfl2/question_about_best_strategy_image_deconvolution/,TrPhantom8,1537430746,,4,6
50,2018-9-21,2018,9,21,20,9hoy5z,How to compare data from customer tickets and know which are related using tensorflow (how to begin?),https://www.reddit.com/r/tensorflow/comments/9hoy5z/how_to_compare_data_from_customer_tickets_and/,vlodia,1537530593,"Hello, 

I am planning to use TensorFlow to create a DeepLearning tool that can classify/categorize customer tickets if they are related to one another.

Plan:

- Extract tickets and put them into a .csv (or maybe google sheets)
   - these tickets have their distinct fields to identify where they belong to (e.g customer name, description, issue, categories)
- I am planning to use TensorFlow's data API (tf.data) to feed my csv file so TF can read through it and classify which tickets are related
- Output: TF program will know which tickets are related with one another based from their distinct fields as mentioned above.

Initially, I am just planning to store everything locally
- CSV files and TensorFlow program installed and living in the same drive.

Do you think this will work? This project doesn't have to be complicated. As long as it can compare data and know they are related then it's a good start.

Please share your thoughts and suggested tutorial materials on how to accomplish this. I am planning to enroll to Udemy as well to have a good foundation (maybe you happen to know a guide that does this).

Thanks!",2,1
51,2018-9-22,2018,9,22,1,9hrgzi,Looking to create a tool to check through a DB of question/answers to answer new questions with the best available answer. Is Tensorflow a valid option?,https://www.reddit.com/r/tensorflow/comments/9hrgzi/looking_to_create_a_tool_to_check_through_a_db_of/,sitdownson,1537546485,"Hello all, I'm completely new to anything related to machine learning, and I'm curious if I could get some insight on whether a ML solution is a good idea what I'm trying to accomplish. I'm just starting to go through Jose Portilla's Udemy course on Tensorflow, but my knowledge on the subject is almost nonexistent.

To what I am trying to do...I have a database of question and answers with a couple thousand rows (note this is not really a DB, just an excel export). I want to be able to take new questions, which would be in the form of a new excel sheet, and go through each question to pick the best answer available in the Q/A database. I've considered using something like https://github.com/seatgeek/fuzzywuzzy to just find the best match essentially, but I'm curious if something like Tensorflow is a better option. Besides, I've been looking for an excuse to dive in and learn more about it.

Before I get started, I wanted to get some recommendations on whether this is even a good use case, and if so any recommendations for structure/planning around this. Please let me know if you'd like some clarification/additional detail. Also, any resources around similar topics are greatly appreciated, thanks!",6,3
52,2018-9-22,2018,9,22,16,9hxwxs,Tensorflow on rocm,https://www.reddit.com/r/tensorflow/comments/9hxwxs/tensorflow_on_rocm/,jabbaluck,1537601247,Hey guys did some one installed the latest version of rocm and tensorflow ? Im having problems installing tensorflow.. on github they send us on tensorflow main page.. but there is no tab for rocm. ,5,3
53,2018-9-23,2018,9,23,1,9i0y3b,How to modify/change extractor in MobileNet SSD?,https://www.reddit.com/r/tensorflow/comments/9i0y3b/how_to_modifychange_extractor_in_mobilenet_ssd/,anilmaddala,1537633631,"I am working with Tensorflows Object detection API. I am able to retrain and detect using MobileNet SSD V2. 

My question is how can I modify/change the extractor is the MobileNet+SSD model?",3,3
54,2018-9-23,2018,9,23,3,9i1r95,No module named nets,https://www.reddit.com/r/tensorflow/comments/9i1r95/no_module_named_nets/,TechGenius28,1537639876,"When running train.py I have been coming across an error saying no module called nets.

Please could somebody help me out.

Thanks",1,0
55,2018-9-23,2018,9,23,17,9i6w8j,TensorFlow.js Crash Course  Machine Learning For The Web  Handwriting Recognition,https://www.reddit.com/r/tensorflow/comments/9i6w8j/tensorflowjs_crash_course_machine_learning_for/,codingthesmartway,1537690396,,0,15
56,2018-9-23,2018,9,23,17,9i72mv,Help. TF-slim can not produce the same results. How could this happen?,https://www.reddit.com/r/tensorflow/comments/9i72mv/help_tfslim_can_not_produce_the_same_results_how/,xixiwho,1537692956,"I suffer from a server breakdown several days ago and lost all my data on the server. 

However the code is luckily preserved on my own computer.

After uploading my code on another server, I found that I can not produce the same results as before.

&amp;#x200B;

I'm using TF-slim resnet-v2 and finetune it for a classification purpose. Setting both train and test phases to is\_training=False. It worked well on the previous server. Got 0.95 accuracy on test set. But only got 0.80 after I changed the server.

&amp;#x200B;

I am wondering if the CUDA and cudnn version could make this happen. But I have tried reinstall them, which makes no change. Also I tried to augment data but got the same 0.8 accuracy. 

&amp;#x200B;

How could this happen? Anyone got the similar peoblem before? 

&amp;#x200B;

&amp;#x200B;",0,1
57,2018-9-24,2018,9,24,0,9i9559,Predicting a single image with TPU trained model. Pls help :(,https://www.reddit.com/r/tensorflow/comments/9i9559/predicting_a_single_image_with_tpu_trained_model/,jthat92,1537716155,"Hi!

I have this question which appears very basic to me, but since  days I can't really solve it, after reading in a lot of forums and googling. I trained a model on the TPU, but I kind of not able to do predictions on it. I just want to check some pictures if the output is right. So here I am struggling with this basic stuff.

I stumbled upon the TF Serving to do this (the PREDICT ModeKey doesnt work on the TPU for some reason). I made a stackoverflow post but until now I didnt get any responses. [Here](https://stackoverflow.com/questions/52440824/save-model-for-serving-but-valueerror-both-labels-and-logits-must-be-provided?noredirect=1#comment91847672_52440824)  it is.

Thanks a ton people! :)",0,1
58,2018-9-25,2018,9,25,6,9ilz2w,Shrink your Tensorflow.js Web Model Size with Weight Quantization,https://www.reddit.com/r/tensorflow/comments/9ilz2w/shrink_your_tensorflowjs_web_model_size_with/,kiarash-irandoust,1537823974,,1,9
59,2018-9-25,2018,9,25,23,9isdm4,Profiling Eager Code,https://www.reddit.com/r/tensorflow/comments/9isdm4/profiling_eager_code/,liftoff01,1537884100,"I was wondering if there is a tool or environment that is meant to help one optimize tensorflow code that works eagerly. So basically a profiling framework specifically designed for tensorflow and it should work on windows. 

Thank you. ",2,2
60,2018-9-26,2018,9,26,0,9itbdf,Introducing Petastorm: Uber ATG's Data Access Library for Deep Learning,https://www.reddit.com/r/tensorflow/comments/9itbdf/introducing_petastorm_uber_atgs_data_access/,selitvin,1537890696,Uber ATG has open sourced *Petastorm* data access library for deep-learning. This library enables single machine or distributed training and evaluation of deep learning models directly from datasets in *Apache Parquet* format. It is a native Python library based on *PyArrow* and is compatible with *Tensorflow* and *PyTorch*.,2,6
61,2018-9-26,2018,9,26,23,9j35f2,How to separate a DataSet?,https://www.reddit.com/r/tensorflow/comments/9j35f2/how_to_separate_a_dataset/,thefernandito,1537973316,"What is the best Python library to separate a DataSet in training, proof and testing?",2,2
62,2018-9-27,2018,9,27,4,9j5gry,Keras using arrays for labels,https://www.reddit.com/r/tensorflow/comments/9j5gry/keras_using_arrays_for_labels/,Jex_y,1537988666,"I am trying to build a python program for doing number plate recognition. The data is fine but i am having problems with the labels. Each photo has a label of an array of integers (0,34, not including Q) that represent the characters that make up the number plate so each label is an array with 8 items. Is this the way i should be doing it or is there a better way or how can i make this work. With a binary crossentropy loss it gives me this error:

    ValueError: Error when checking target: expected dense_2 to have shape (1,) but got array with shape (8,)

an example of the label is:

    [18 26 31 31 14 14 26 26]

This is my model at the moment (probably going to change):

    _________________________________________________________________
    Layer (type)                 Output Shape              Param #
    =================================================================
    dense (Dense)                (None, 1024)              8389632
    _________________________________________________________________
    dropout (Dropout)            (None, 1024)              0
    _________________________________________________________________
    dense_1 (Dense)              (None, 1)                 1025
    =================================================================
    Total params: 8,390,657
    Trainable params: 8,390,657
    Non-trainable params: 0
    _________________________________________________________________

Any help would be appreciated",0,1
63,2018-9-27,2018,9,27,5,9j6726,"Using an LSTM unrolled into multiple timesteps for training, and just a single timestep for inference",https://www.reddit.com/r/tensorflow/comments/9j6726/using_an_lstm_unrolled_into_multiple_timesteps/,JustinQueeber,1537993535," 

I have built an LSTM in TensorFlow that is unrolled into *n* timesteps and trains successfully on sequences of lengths *n*.

I would now like to use my trained model to make *m* daily predictions one by one. One way of doing this is that for each of the *m* daily predictions, I would take a sliding window of length *n*, with the final timestep taking in the input data for this day's prediction. Each day, this window of length *n* is slid over by one day.

Another way I have seen is to use an LSTM unrolled into just a single timestep for these predictions. The previous *n*  (or more or less) datapoints are passed through the single timestep  LSTM one at a time to ""warm up"" its hidden state. Then, for each of the *m*  prediction days, just the input data for this day is fed into the LSTM  and a prediction is produced from this input and from the hidden state.

Is it possible to train an LSTM in TensorFlow which is unrolled into *n*  timesteps, and then use a single timestep LSTM with the trained  parameters to make predictions? My idea would be to train the unrolled  model, save the parameters, initialize a single timestep LSTM, and  populate its parameter with the stored ones. Can this be done?",1,1
64,2018-9-27,2018,9,27,5,9j69dr,Petastorm: native Tensorflow and Pytorch API for training/evaluation from Apache Parquet store,https://www.reddit.com/r/tensorflow/comments/9j69dr/petastorm_native_tensorflow_and_pytorch_api_for/,selitvin,1537993999,"Petastorm is a new open source library that that enables training and evaluation of deep learning models directly from Apache Parquet stores. It supports both distributed and single machine scenarios. The library has native interfaces for the Tensorflow and PyTorch ML framework. It is based on PyArrow. Petastorm  was developed in Uber ATG. 

&amp;#x200B;

Here is the [github project page link](https://github.com/uber/petastorm) and an [introduction article](http://eng.uber.com/petastorm/).

&amp;#x200B;",0,1
65,2018-9-27,2018,9,27,6,9j6scz,Visualized optimizers: RMSProp vs Gradient Descent vs ADAM vs FTRL. Thoughts on the patterns?,https://www.reddit.com/r/tensorflow/comments/9j6scz/visualized_optimizers_rmsprop_vs_gradient_descent/,cosmic_dozen,1537997671,,5,30
66,2018-9-27,2018,9,27,6,9j6t2y,Oversampling in TF Estimator,https://www.reddit.com/r/tensorflow/comments/9j6t2y/oversampling_in_tf_estimator/,i_wont_enjoy_that,1537997813,"Hello everyone,

I have a very unbalanced dataset, so I want to use oversampling. I found the [imbalanced-learn library](http://imbalanced-learn.org/en/stable/) which has implemented some nice algorithms for this and want to use it with my existing custom estimator.

The problem is, that the methods don't work if there are strings in the dataset (which I have). Since I'm using an estimator, I of course also use feature\_columns to encode the strings in my data.

So I would need to get my training data back after it has been encoded by the feature columns and then I can oversample it. Is there any way to do this?

&amp;#x200B;",3,1
67,2018-9-27,2018,9,27,20,9jc3d7,Help with tensorflow-gpu.,https://www.reddit.com/r/tensorflow/comments/9jc3d7/help_with_tensorflowgpu/,HolidayWallaby,1538048231,"Hi, I'm having a lot of trouble getting tensorflow-gpu set up correctly on my machine. I have it working on my personal laptop just fine, however, cannot get it working on a better computer that I have access to.

The trouble seems to be with compatible versions of CUDA, cuDNN, and tensorflow itself. The machine in question is running Ubuntu 18.04 (I wanted 16.04 but didn't get to choose this), and 2 NVIDIA Tesla P40's.

Can anybody tell me exactly which versions of CUDA, cuDNN, and tensorflow-gpu to install so that they all play nicely together? I don't mind compiling tensorflow from source but I'd rather not.

Thanks

Edit: I should add that I do have full sudo right's on the machine.",11,2
68,2018-9-28,2018,9,28,6,9jh1jq,New to Machine Learning. Basic question about multiple inputs,https://www.reddit.com/r/tensorflow/comments/9jh1jq/new_to_machine_learning_basic_question_about/,og_Caesar,1538084672,"Before my question, I will provide a little background and explain my situation. I entered a competition with a team and our challenge relates to machine learning; this challenge focuses on theory but I want to showcase a functional model. I know a few programming languages and just learned a very very basic amount of machine learning in TensorFlow with Keras. 

I essentially want to create a low-function model that uses approx 3 inputs to predict future damage. The model would be more to show the capabilities of machine learning, and not the most accurate outputs. Is the TensorFlow environment the best for this? 

For more insight, I have a .csv file with 4 columns, three being the inputs and one being the label. As I said, the desired ouput would be amount of USD in millions.",6,5
69,2018-9-28,2018,9,28,16,9jkuuu,Tensorflow for generating art,https://www.reddit.com/r/tensorflow/comments/9jkuuu/tensorflow_for_generating_art/,JeykeyLP,1538119029,"I had this dumb idea to generate art (propably drawings) using ML. Is Tensorflow the right framework for that? And if yes, is there a similar project or tutorial out there?
Thx",6,2
70,2018-9-28,2018,9,28,21,9jmftk,Beginner's query: Estimators,https://www.reddit.com/r/tensorflow/comments/9jmftk/beginners_query_estimators/,Good_Development,1538136950,"Hi, I've been studying TensorFlow for a couple of weeks and I've already mastered the fundamental issues (tensors, variables, placeholders, etc.), I've seen that the Estimators are a fundamental part, since you can do practically everything. My question is whether, to get into TF, I should focus on the Estimators or is there some other part of the library so important. I would like to receive some advice on this. Thank you.",1,1
71,2018-9-28,2018,9,28,22,9jmr4r,[Help] tf.train.shuffle_batch parameter,https://www.reddit.com/r/tensorflow/comments/9jmr4r/help_tftrainshuffle_batch_parameter/,thisisiron,1538139739,"I readed tensorflow docs, but I only roughly understood  num\_threads, capacity, min\_after\_dequeue in the tf.train.shuffle\_batch parameter.

&amp;#x200B;

Could you explain it using an example?",0,1
72,2018-9-29,2018,9,29,19,9jvl2e,convert videos (eg. .avi) to TensorFlow's tfrecords file format,https://www.reddit.com/r/tensorflow/comments/9jvl2e/convert_videos_eg_avi_to_tensorflows_tfrecords/,whiletrue2,1538217730,,0,8
73,2018-9-30,2018,9,30,2,9jz0x0,How to backward pass a custom output gradient to a CNN layer in Tensorflow?,https://www.reddit.com/r/tensorflow/comments/9jz0x0/how_to_backward_pass_a_custom_output_gradient_to/,curious_riddler,1538243467," 

    input = tf.random_normal((1,4,1))
    conv1 = tf.layers.Conv1D(1,3,1,'VALID',activation=None)
    output = conv1(n)
    grad_weighths = backward_pass(conv1, input, nextGrad)

How do I implement the backward\_pass function in tensorflow. I don't have a loss function. But I have the next gradient. How do I calculate the gradients of weights based on the input to the layer and the next gradient?",0,2
74,2018-9-30,2018,9,30,17,9k4sy2,Have fun...,https://www.reddit.com/r/tensorflow/comments/9k4sy2/have_fun/,CaptainPonchol,1538297037,"&amp;#x200B;

![img](psnsbqzb9cp11)",0,1
75,2018-9-30,2018,9,30,17,9k4t46,Build and install TensorFlow 1.11 Python package with CUDA 10 (and cuDNN 7.3) for Windows,https://www.reddit.com/r/tensorflow/comments/9k4t46/build_and_install_tensorflow_111_python_package/,amsokol,1538297112,"I have updated my tutorial to help you to build and install TensorFlow 1.11 Python package with CUDA 10 (and cuDNN 7.3) for Windows. Enjoy:

[https://medium.com/@amsokol.com/update-1-how-to-build-and-install-tensorflow-gpu-cpu-for-windows-from-source-code-using-bazel-and-c2e86fec9ef2](https://medium.com/@amsokol.com/update-1-how-to-build-and-install-tensorflow-gpu-cpu-for-windows-from-source-code-using-bazel-and-c2e86fec9ef2)",0,11
0,2018-10-2,2018,10,2,4,9kjmue,18 Tips for Training your own Tensorflow.js Models in the Browser,https://www.reddit.com/r/tensorflow/comments/9kjmue/18_tips_for_training_your_own_tensorflowjs_models/,kiarash-irandoust,1538423060,,0,1
1,2018-10-2,2018,10,2,5,9kjs4g,"PSA: Don't ""install"" TF using docker",https://www.reddit.com/r/tensorflow/comments/9kjs4g/psa_dont_install_tf_using_docker/,CommunismDoesntWork,1538424045,"It just straight up doesn't work. It's unusable. You won't be able to develop using it at all. Maybe deployment is a different story, but for development, it is just FUBAR.",14,1
2,2018-10-2,2018,10,2,11,9kmwyf,Algorithmic trader looking for Tensorflow programmer,https://www.reddit.com/r/tensorflow/comments/9kmwyf/algorithmic_trader_looking_for_tensorflow/,GastricDisturbance,1538447692,"Hello,
I have my own trading software robot that trades for me. My problem is that it takes so long to change inputs to find the best settings. Essentially there are probably 1 million possible combinations of the 50 input variables, but im only able to find maybe 20 manually. Im looking to load up chart data through csv so i can run through all potential variables faster. Sorting through combinations and ranking them by highest profit. 

I have a small dev team but If anyone can help with utilizing tensorflow, you would get access to a money printing machine for free. 

Thank you for your time! ",7,1
3,2018-10-2,2018,10,2,21,9kqcbm,Apis - TensorFlow,https://www.reddit.com/r/tensorflow/comments/9kqcbm/apis_tensorflow/,thefernandito,1538484858,"A few weeks ago I am studying TensorFlow, I have seen that among its valuable Apis, one of the most important seems to be Estimator. What would be the other TF apis that you think I should pay more attention to?",1,1
4,2018-10-2,2018,10,2,23,9kr1cg,Cant get tensorflow-gpu to work on Ubuntu MATE 18.04,https://www.reddit.com/r/tensorflow/comments/9kr1cg/cant_get_tensorflowgpu_to_work_on_ubuntu_mate_1804/,rk39096,1538490164,[removed],0,1
5,2018-10-3,2018,10,3,5,9ku7wp,RNN Weights as Model Input?,https://www.reddit.com/r/tensorflow/comments/9ku7wp/rnn_weights_as_model_input/,blowjobtransistor,1538511533,"I'm looking at transitioning a collection of text classifiers to TF/TF Serving, but I'm not sure how to replicate some existing functionality where some of the model weights are provided as an input.  

To explain a little, all the text classifiers use the same word embeddings, which make up over 99.9% of the model parameters. For performance and cost purposes, the existing implementation keeps these embeddings in memory, and swaps out the much smaller classifier-specific weights as needed.

I can see how to do this directly via `tf.assign`, but not sure if this can be included in the computational graph and used in TF Serving / Google ML Engine.

Has anyone done something like this? Know where I should look?",0,1
6,2018-10-3,2018,10,3,11,9kx6ae,How to use time distributed cnn + lstm in a keras model?,https://www.reddit.com/r/tensorflow/comments/9kx6ae/how_to_use_time_distributed_cnn_lstm_in_a_keras/,Arkhaya,1538533958,,0,1
7,2018-10-3,2018,10,3,12,9kxndy,Saving and restoring model (Wrong predictions after restoring model),https://www.reddit.com/r/tensorflow/comments/9kxndy/saving_and_restoring_model_wrong_predictions/,Gother,1538537916,"I am trying to save, restore and predict with a model in TensorFlow. There are many answers out there already but NONE specifically target problems in production, so I believe this question will help out people seeking for a hands on approach on the topic.

So, I trained the model available on [this jupyter code](https://github.com/mithi/semantic-segmentation/blob/master/playground.ipynb) and I am now trying to save the model and predict on different images. I was able to run it and got [this result after training](https://i.stack.imgur.com/MY8HS.png).

Then I saved the model, loaded it and predicted again on the same image. [This is the result after testing on the restored model](https://i.stack.imgur.com/i90YJ.png). Obviously I am doing something wrong, either saving the model or loading it.

&amp;#x200B;

The code that I am using for saving the model is as follows:

Inside \`def run():\`

    with tf.Session() as session:
    
        # Returns the three layers, keep probability and input layer from the vgg architecture
        image_input, keep_prob, layer3, layer4, layer7 = load_vgg(session, VGG_PATH)
        
        # The resulting network architecture, adding a decoder on top of the given vgg model
        model_output = layers(layer3, layer4, layer7, NUMBER_OF_CLASSES)
        
        logits, train_op, cross_entropy_loss = optimize(model_output, correct_label, learning_rate, NUMBER_OF_CLASSES)
        # Create saver
        saver = tf.train.Saver()
        # Initilize all variables
        session.run([tf.global_variables_initializer(), tf.local_variables_initializer()])
        
        # train the neural network
        train_nn(session, EPOCHS, BATCH_SIZE, get_batches_fn,
        train_op, cross_entropy_loss, image_input,
        correct_label, keep_prob, learning_rate)
        # Save inference data
        helper.save_inference_samples(RUNS_DIRECTORY, DATA_DIRECTORY, session, IMAGE_SHAPE, logits, keep_prob, image_input)
        # Save model
        saver.save(session, ""./fcn_liquid_model"", global_step = 500)

&amp;#x200B;

Then, for loading the saved model I tried doing the following:

&amp;#x200B;

    tf.reset_default_graph:
    with tf.Session() as session:
        # Restore variables and model
        saver = tf.train.import_meta_graph(""./fcn_liquid_model-500.meta"")
        saver.restore(session, tf.train.latest_checkpoint(""./""))
        print(""Model restored."")
        # Returns the three layers, keep probability and input layer from the vgg architecture
        image_input, keep_prob, layer3, layer4, layer7 = load_vgg(session, VGG_PATH)
        
        # The resulting network architecture, adding a decoder on top of the given vgg model
        model_output = layers(layer3, layer4, layer7, NUMBER_OF_CLASSES)
        
        logits = tf.reshape(model_output, (-1, NUMBER_OF_CLASSES))
        # Initilize all variables
        session.run([tf.global_variables_initializer(), tf.local_variables_initializer()])
        helper.save_inference_samples(RUNS_DIRECTORY, DATA_DIRECTORY, session, IMAGE_SHAPE, logits, keep_prob, image_input)

And got the result previously shown. Does anyone know what is happening or how can I fix the problem? Thank you.",4,1
8,2018-10-4,2018,10,4,2,9l3cef,Adding Convolution to custom DNN estimator,https://www.reddit.com/r/tensorflow/comments/9l3cef/adding_convolution_to_custom_dnn_estimator/,Gsonderling,1538588070,"Let's say I have a custom estimator, like the one in the:
https://github.com/tensorflow/models/blob/master/samples/core/get_started/custom_estimator.py

How would I go about adding convolution layer? 
https://www.tensorflow.org/api_docs/python/tf/layers/conv1d

I assume that it's harder than just putting it right after the input layer. But apart from image specific tutorial, I can't find how to actually work with them. ",0,1
9,2018-10-4,2018,10,4,7,9l5txc,"tf.test.is_gpu_available() blocking indefinitely, using 100% CPU",https://www.reddit.com/r/tensorflow/comments/9l5txc/tftestis_gpu_available_blocking_indefinitely/,KjellJagland,1538604096,"I set up TensorFlow on Windows 10 earlier today and initially struggled with getting the GPU version to work. For some reason, I had both the tensorflow and tensorflow-gpu packages installed, which is not supposed to happen. It finally detects my GTX 970 now but `tf.test.is_gpu_available()` curiously hangs and eats up 100% of one CPU core. It doesn't return in the GPU version. It did return `False` right away in the CPU version, though. Here's some sample output:

`Python 3.6.6 (v3.6.6:4cf1f54eb7, Jun 27 2018, 03:37:03) [MSC v.1900 64 bit (AMD64)] on win32`

`Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.`

`&gt;&gt;&gt; import tensorflow as tf`

`&gt;&gt;&gt; with tf.device(""GPU:0""):`

`...     x = tf.random_uniform([1000, 1000])`

`...     print(x.device)`

`...`

`/device:GPU:0`

`&gt;&gt;&gt; tf.test.is_gpu_available()`

`2018-10-03 23:08:26.805592: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2`

`2018-10-03 23:08:27.171992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties:`

`name: GeForce GTX 970 major: 5 minor: 2 memoryClockRate(GHz): 1.253`

`pciBusID: 0000:01:00.0`

`totalMemory: 4.00GiB freeMemory: 3.31GiB`

`2018-10-03 23:08:27.184134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0`

And, well, then it just hangs indefinitely and keeps on spinning. Am I doing something wrong or is there something broken? I suppose I'd have to build it from source in order to debug this issue in Visual Studio 2017.",9,1
10,2018-10-4,2018,10,4,13,9l8nkq,Good resources on reshaping tensors?,https://www.reddit.com/r/tensorflow/comments/9l8nkq/good_resources_on_reshaping_tensors/,VegasTamborini,1538626767,"I'm taking a neural nets course at uni and I'm really struggling with the idea of reshaping tensors. I'm vaguely aware of the concept from using numpy, but I don't get how exactly it relates to tensorflow. All the resources that I've found explain the mechanics of how a tensor is reshaped without going into why that needs to happen for it to work in tensorflow. Can anyone recommend any good resources that will fill my knowledge gap?

&amp;#x200B;

Thanks",0,1
11,2018-10-4,2018,10,4,16,9l9oo5,Learn ML lifecycle and Tensorboard In Tensorflow By Building Real World AI and ML apps using #Tensorflow,https://www.reddit.com/r/tensorflow/comments/9l9oo5/learn_ml_lifecycle_and_tensorboard_in_tensorflow/,thecodingfossil,1538637415,,0,1
12,2018-10-4,2018,10,4,19,9laiio,Writing Custom Activation Functions,https://www.reddit.com/r/tensorflow/comments/9laiio/writing_custom_activation_functions/,Aesix,1538647390,"I'm struggling to find material that's very clear about how to write your own activation mapping. I've combed through the tensorflow code and found the relu/softmax/etc, but they of course use ""K"" instead of numpy and now we're walking into territory I'm trying to become familiar with... I just wanted to play with a y=mx+b formula for fun. :| ",1,1
13,2018-10-5,2018,10,5,2,9le485,Problematic binary classifier,https://www.reddit.com/r/tensorflow/comments/9le485/problematic_binary_classifier/,Zak_Wormald,1538674990,"[Link To Stack Overflow Page](https://stackoverflow.com/questions/50641866/binary-classifier-always-returns-0-5)

My classifier does not work and i have been unable to find a solution for a while now. I have made a similar model that mimics the XOR gate before but for some reason this model does not function despite it's only major difference being that it takes three inputs as opposed to two. Any help with the problem would be much appreciated as my stack overflow doesn't get much traffic. ",2,1
14,2018-10-5,2018,10,5,19,9ll3f9,Custom Keras Activation (Revisited),https://www.reddit.com/r/tensorflow/comments/9ll3f9/custom_keras_activation_revisited/,Aesix,1538735420,"After some 'constructive' criticism I've rephrased the question in shorter terms. What would be the easy way to apply an activation that requires more than the usual code, like ""f(x) = (e\^x - 1) / (e\^x)"" using Keras/TF ? (function simplified)",0,1
15,2018-10-5,2018,10,5,21,9llvu6,Keras in TensorFlow,https://www.reddit.com/r/tensorflow/comments/9llvu6/keras_in_tensorflow/,Good_Development,1538742973,"What are the advantages of using Keras as a TensorFlow api, instead of using only TF?",4,1
16,2018-10-5,2018,10,5,22,9lmbpb,Weyl tensor,https://www.reddit.com/r/tensorflow/comments/9lmbpb/weyl_tensor/,ricci-flow,1538746472,Placeholder ,0,1
17,2018-10-5,2018,10,5,22,9lmfi2,,https://www.reddit.com/r/tensorflow/comments/9lmfi2/_/,ricci-flow,1538747278,,0,1
18,2018-10-6,2018,10,6,22,9lvy21,Unable to train input as variable instead of weights (Keras and Tensorflow),https://www.reddit.com/r/tensorflow/comments/9lvy21/unable_to_train_input_as_variable_instead_of/,ronsap123,1538832570," 

I have a Keras model and I want to do some cool visiualizations with it. It's an object recognition network.

So I thought, It would be cool to input a blank image into the network and treat the image as the variable and not the weights, and then train the network to always output an icecream for example.

So I wrote the following code:

    #loading the model 
    model = load_model('model.h5')  
    #create the input image as a variable 
    w = tf.Variable(tf.zeros([1,224,224,3]))  
    
    #create the flowgraph with the variable input 
    pred = model.call(inputs=w)  
    #create the desired output distribution 
    desired = np.zeros((1000)) desired[928] = 1.0  
    err = tf.reduce_mean(tf.subtract(pred,desired)) 
    
    #create an optimizer that can only affect the inital input variable I created 
    optimizer = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(err, var_list=[w])  
    #train the network 
    for i in range(0,100):     
        _,cost = sess.run([optimizer,err])     
        print(cost) 

So I thought the code would work well, but the cost literally doesn't change. It stays in place as if it's entirely unaffected.

&amp;#x200B;

Thanks in advance",2,1
19,2018-10-8,2018,10,8,8,9m9smw,Difference between tf.contrib.data.CsvDataset and tf.contrib.data.make_csv_dataset,https://www.reddit.com/r/tensorflow/comments/9m9smw/difference_between_tfcontribdatacsvdataset_and/,tf_noo,1538954867,"Basically what the title says.

I have a csv data file that I want to read into tensorflow and then feed it into one of the pre-made estimators. From various searches I found these two functions but from the documentation, I'm not immediately sure what the difference between the two is? Would appreciate an explanation! ",1,1
20,2018-10-8,2018,10,8,10,9mafvy,How to create a video display which uses the graph.pb and the labels to display active classification for a demo?,https://www.reddit.com/r/tensorflow/comments/9mafvy/how_to_create_a_video_display_which_uses_the/,Arkhaya,1538960571,I've been trying to find a way to get a working demo to display active classification but most tutorials that are on the Internet don't really provide a proper solution. I have trained my model on inception resnet but can't seem to find any code that can help me display the active classification. ,1,1
21,2018-10-8,2018,10,8,14,9mbzle,How can I use previously-updated weights of a model?,https://www.reddit.com/r/tensorflow/comments/9mbzle/how_can_i_use_previouslyupdated_weights_of_a_model/,AlexanderYau,1538974829,"I created a network with 2 dense layers.

At every time step `t`, my code updates `W_t`, the weights of my model. However, how can I use the previously updated weights, for example, `W_t-k`, `W_t-k+1`, ..., `W_t-1` when updating `W_t` at time step `t`?",1,1
22,2018-10-9,2018,10,9,15,9mmu4c,Learn Fraud Detection with Python &amp; Tensorflow,https://www.reddit.com/r/tensorflow/comments/9mmu4c/learn_fraud_detection_with_python_tensorflow/,Slight_Role,1539066924,,0,1
23,2018-10-9,2018,10,9,17,9mnfo9,Training and freezing tensorflow graph via Java,https://www.reddit.com/r/tensorflow/comments/9mnfo9/training_and_freezing_tensorflow_graph_via_java/,geometrikal,1539074260,"I have developed a CNN classifier using tensorflow in python. It consists of augmentation using `tf.data.Dataset` and a `map` function, CNN, custom training scheduler, and freezing the graph for later use.

I created a Java program with a GUI etc for end-users to use the network for inference etc.

However, I would like to enable that same Java program to train a new network and freeze it when done. Has anyone done this before? (Could be in C# as well). In particular, is the `tf.data.Dataset` augmentation possible?

Another option would be to put the python scripts in the cloud and expose the training using an API. Are there some existing resources to help set this up?
",1,1
24,2018-10-10,2018,10,10,4,9ms56j,Does anyone know of an example use of Conv3DLSTMCell? I cannot find anything online.,https://www.reddit.com/r/tensorflow/comments/9ms56j/does_anyone_know_of_an_example_use_of/,kds_medphys,1539112768,,0,1
25,2018-10-10,2018,10,10,13,9mwaoq,Can I build a carrer in Tensorflow - how good of a bet is it for me?,https://www.reddit.com/r/tensorflow/comments/9mwaoq/can_i_build_a_carrer_in_tensorflow_how_good_of_a/,kiransaravi,1539145023,"I've recently started learning ML &amp; TF, and I liked it so much, I wanna explore more and build a career out of it - probably as a developer to start with. Given that i have over 10 yrs exp in middleware(completely unrelated technology) and in a good paying comfortable job. How good of a bet is it for me?",3,1
26,2018-10-12,2018,10,12,13,9nh7n6,2080 Ti TensorFlow GPU benchmarks: The best GPU of 2018?,https://www.reddit.com/r/tensorflow/comments/9nh7n6/2080_ti_tensorflow_gpu_benchmarks_the_best_gpu_of/,pepito_pistola,1539318412,,2,1
27,2018-10-12,2018,10,12,22,9nk5bg,Using FP16 or FP32 with TensorFlow and ObjectDetection API?,https://www.reddit.com/r/tensorflow/comments/9nk5bg/using_fp16_or_fp32_with_tensorflow_and/,punkehazardo,1539349865,"The last few days I have been reading a lot about comparisons between different GPUs and how well these GPUs perform with FP16/FP32-calculations.
Then I wanted to apply this new found knowledge to my existing setup, but I have no idea where or how.

I am using the [TensorFlow Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection). My first guess was to look through the training/eval-scripts and look for float32 initializations, but changing them all to float16 resulted in errors.

Is it even worth looking into this or is the API already working with lower precision settings? And if I wanted to switch precisions, how would I do this?",4,1
28,2018-10-13,2018,10,13,4,9nndg4,Difficult Reshaping GAN Generator Output,https://www.reddit.com/r/tensorflow/comments/9nndg4/difficult_reshaping_gan_generator_output/,StackBPoppin,1539373026,"I've implemented a GAN, and I've some okay results with it, however I'm running into a problem:

If I load all image data and keep it in the format \[batch\_size, image\_height \* image\_width\] (i.e. 2d) when using matplotlib I can see the results fine.

If I decide to use the format \[batch\_size, image\_height, image\_width, colour\_depth\] I just get random noise out of matplotlib.

To be more specific, I have a placeholder with shape \[None, 56, 100, 1\]. (Greyscale 100x56 images). I load images from a dataset using `tf.reshape(tf.image.decode_png(tf.read_file(x), 1), [56, 100, 1])`

I then try to plot them with `matplotlib plt.imshow(samples.reshape(56, 100, 1))` but all I get is noise, however when everything is 'flat' it works fine.

I guess my question is, if I have a tensor of shape \[batch\_size, image\_height, image\_width, colour\_depth\] how can I plot display the images from it?",0,1
29,2018-10-13,2018,10,13,20,9nsyma,Question about DCGAN,https://www.reddit.com/r/tensorflow/comments/9nsyma/question_about_dcgan/,TrPhantom8,1539428511,"Hello everybody! I have a question about DCGAN.
My task is a kind of image denoising: I have a synthetic dataset made of input images (noisy) and  output images (without noise). I have created a CNN which works pretty well at the task and I was wondering how to improve my model.
Does it make sense to use this trained CNN model as the generator in a GAN? Would the generator eventually become stronger?
Thank you in advance for your help! ",0,1
30,2018-10-14,2018,10,14,1,9nuuy3,How to install Tensorflow GPU with CUDA 10.0 for python on Ubuntu | Python 3.6,https://www.reddit.com/r/tensorflow/comments/9nuuy3/how_to_install_tensorflow_gpu_with_cuda_100_for/,Aryal007,1539446818,,0,1
31,2018-10-14,2018,10,14,9,9nyl2p,[Question] Row-wise euclidean distance for cost computation?,https://www.reddit.com/r/tensorflow/comments/9nyl2p/question_rowwise_euclidean_distance_for_cost/,Rigatin,1539475891,"Hi all,

&amp;#x200B;

So I'm a tensorflow newbie who's just started doing some research with applying machine learning to genome sequences. So basically there's two types of gene, one which is marked as causing antimicrobial resistance and one which doesn't and I have those in two matrices (\[m,t\] and \[n,t\] respectively). They've given me the math calculations they want me to implement, and basically I use a weight matrix (alpha \[q,t\]) to create two new matrices through matrix multiplication (so matmul(a, alpha.T)). These matrices are gamma1 and gamma2, and they want me to train the weights to that the euclidean distances between the rows of each gamma are small, but the euclidean distances between gamma 1's rows and gamma 2's rows are increased. So it works kind of like a one-layer network. I don't fully understand it myself, but that's what the professor wants (they say it's so that they can compress the data and make it more usable since the matrices are very sparse).

&amp;#x200B;

If you've followed up to that point, I'm basically wondering if there's any tensorflow methods I can use to calculate this cost, so that I end up with a single cost value which I can then minimize. For instance, for gamma1 I'd like to get a value for the distance between all the rows (think sqrt(a\^2 + b\^2)). I've been looking around and trying to find methods and ways to implement this but it hasn't been very easy for me. I've only done very simple and basic networks in the past, so something like this which I even hesitate to call a machine learning problem is posing a large issue for me.

&amp;#x200B;

Thanks for any help, in the meantime I'll keep on looking around for solutions.",1,1
32,2018-10-14,2018,10,14,21,9o2ep0,[Question] Object Detection Transfer Learning - changing the output layer,https://www.reddit.com/r/tensorflow/comments/9o2ep0/question_object_detection_transfer_learning/,alew3,1539520777,"Is it useful to do transfer learning when I change the output layer instead of the last layer? I want to use a pre-trained object detection model and retrain it to map/predict the position of the lines of a football pitch based on an image. So instead of finding a box, I want to predict the position of the corners of the pitch and the half way line. (so instead of 4 outputs, I would have 6 outputs). Any hints on the best way to go about this? As a proof of concept I'm generating synthetic data with a 3d model in Unity.",0,1
33,2018-10-15,2018,10,15,5,9o5zbf,Tensorflow Serving exporter for Prometheus,https://www.reddit.com/r/tensorflow/comments/9o5zbf/tensorflow_serving_exporter_for_prometheus/,aqny,1539548350,,0,1
34,2018-10-15,2018,10,15,17,9oatgr,Tensorflow Eager Execution Gradient Calculation slower each epoch,https://www.reddit.com/r/tensorflow/comments/9oatgr/tensorflow_eager_execution_gradient_calculation/,MCFF3000,1539591770,"Hi to all!

&amp;#x200B;

I have been implementing Temportal Ensembling for Semi-Supervised Learning by Laine et al. with eager execution and a couple of GitHub users noticed that the computations of the gradients is taking gradually more time each epoch. I don't see what is causing this. After benchmarking I could confirm this issue, but I have no idea why this should be happening. Is anyone faced this problem with `tf.GradientTape()` ? Or is this is an issue related to eager execution?

&amp;#x200B;

The code is in [https://github.com/Goldesel23/Temporal-Ensembling-for-Semi-Supervised-Learning](https://github.com/Goldesel23/Temporal-Ensembling-for-Semi-Supervised-Learning)

&amp;#x200B;

Thanks for your time!",1,1
35,2018-10-15,2018,10,15,19,9obfby,Running FNN in parallel over a dimension in Eager,https://www.reddit.com/r/tensorflow/comments/9obfby/running_fnn_in_parallel_over_a_dimension_in_eager/,liftoff01,1539598791,"I have a 3 dimensional tensor which I want to apply the same feedforward neural network to over the 2nd dimension. My current implementation is this: 
        output = []
        for nS in range(inputs.shape[1]):
            dense  = inputs[:,nS,:]
            dense = self.fc01(dense)
            dense = self.dropout(dense)
            
            for denseLayer in self.deeps:
                dense = denseLayer(dense)
                dense = self.dropout(dense)
            output.append(dense)

But I cannot help but feel there is a better way to implement this without the outer parallel loop. 

Can someone help point me down that path? ",2,1
36,2018-10-16,2018,10,16,5,9ogbds,Normalization in TensorFlow: speed is an issue,https://www.reddit.com/r/tensorflow/comments/9ogbds/normalization_in_tensorflow_speed_is_an_issue/,__me_again__,1539634278,"Has anyone else noticed this?

[https://medium.com/@mansanher/normalization-in-tensorflow-speed-is-an-issue-b8ae14336685](https://medium.com/@mansanher/normalization-in-tensorflow-speed-is-an-issue-b8ae14336685)",0,1
37,2018-10-16,2018,10,16,13,9ok886,tf-explorer: a command-line interface to explore TensorFlow checkpoints.,https://www.reddit.com/r/tensorflow/comments/9ok886/tfexplorer_a_commandline_interface_to_explore/,sharvil,1539663444,,0,1
38,2018-10-16,2018,10,16,20,9omr3a,Where can I find learning resources just for understanding Tensorflow?,https://www.reddit.com/r/tensorflow/comments/9omr3a/where_can_i_find_learning_resources_just_for/,sedgecrooked,1539689505,"I just want to understand how Tensorflow works and how to get started with it. Nothing for ML or deep learning, just about tensorflow.",0,1
39,2018-10-17,2018,10,17,2,9oprx9,Art with optimizers,https://www.reddit.com/r/tensorflow/comments/9oprx9/art_with_optimizers/,cosmic_dozen,1539710805,,1,1
40,2018-10-17,2018,10,17,5,9orf1m,"Generate TFRecord for images downloaded using EscVM/OIDv4_ToolKit, was struggling to adapt existing scripts, so wrote this, might be useful for someone",https://www.reddit.com/r/tensorflow/comments/9orf1m/generate_tfrecord_for_images_downloaded_using/,r0bertas,1539721414,,4,1
41,2018-10-17,2018,10,17,6,9os8ln,How to install Tensorflow GPU with CUDA 10.0 for python on Windows,https://www.reddit.com/r/tensorflow/comments/9os8ln/how_to_install_tensorflow_gpu_with_cuda_100_for/,Aryal007,1539727057,,0,1
42,2018-10-17,2018,10,17,14,9ovx8a,Creating a Logical AND using Tensorflow's Deep Neural Network classifier,https://www.reddit.com/r/tensorflow/comments/9ovx8a/creating_a_logical_and_using_tensorflows_deep/,AnderUstarroz,1539755751,"Hi,   
I am a seasoned Python developer, but when it comes to Tensorflow I am just a beginner,  
I was wondering if some Tensorflow expert could bring some light into the following issue:  


[https://stackoverflow.com/questions/52841015/create-a-logical-and-with-tensorflow-using-a-deep-neural-network-classifier](https://stackoverflow.com/questions/52841015/create-a-logical-and-with-tensorflow-using-a-deep-neural-network-classifier)  


&amp;#x200B;",0,1
43,2018-10-17,2018,10,17,16,9owdvh,this might be stupid,https://www.reddit.com/r/tensorflow/comments/9owdvh/this_might_be_stupid/,nagasaig9,1539760448,"is TensorFlow build on top of Keras or Keras build on top of TensorFlow..?

&amp; what is base for TensorFlow..?",5,1
44,2018-10-18,2018,10,18,2,9p0p7i,"Integrating Tensorflow into a cross-platform (Linux, Android etc) C++ framework; what's the best approach?",https://www.reddit.com/r/tensorflow/comments/9p0p7i/integrating_tensorflow_into_a_crossplatform_linux/,rumborak,1539797014,"I have a C++ framework at work that runs on a variety of platforms: Windows, Linux, Android, Raspberry Pi. I want to integrate Tensorflow as a module into it, but I'm not sure what the best approach would be. Note this is only for runtime inference, the training would happen on a normal Linux installation.

So, it seems Android is the most restrictive because only TF Lite exists for it, is that correct? Is it a reasonable conclusion that I should thus use TF Lite across the platforms to make it easy on myself? Does TF Lite exist for the non-Android platforms?",4,1
45,2018-10-18,2018,10,18,19,9p7usa,Searching for intermediate Tensorflow course,https://www.reddit.com/r/tensorflow/comments/9p7usa/searching_for_intermediate_tensorflow_course/,Appelmoesje,1539856820,"I'm a student in Software Engineering and I have a very big interest in ML for the last 2 years. I have followed a few courses on Youtube (Sentdex is my favourite) but I want to take it to the next step. Most Youtube videos don't have ""homework"" that you can make to practice yourself and most of them dont go deep in way thing are how they are in ML. 

Now I would like to improve my skills in Tensorflow but find the Tensorflow docs not very user friendly. I have seen courses on Udacity but there are paid and I don't have that kind of money to spend.

Does anyone know a course that is free (or can be watched free with a student email) that increases my Tensorflow knowlegde? Thank you very much in advance!",5,1
46,2018-10-18,2018,10,18,23,9p9s5h,Is keras the best api to work with images in Tensorflow?,https://www.reddit.com/r/tensorflow/comments/9p9s5h/is_keras_the_best_api_to_work_with_images_in/,thefernandito,1539873029,"Hello friends, I am doing my first practices with Tensorflow and I want to work with images, I see that many people use the api of keras for images. Is this the best? Thank you.",0,1
47,2018-10-19,2018,10,19,7,9pdvhg,Same code different results tensorflow coursera jupyter notebook/laptop,https://www.reddit.com/r/tensorflow/comments/9pdvhg/same_code_different_results_tensorflow_coursera/,overbit123,1539901114,"I started learning ML and playing around with tensorflow in my spare time and am struggling to determine the cause of an inconsistency I found.  When I run the CNN from the hand gesture classification in the online coursera jupyter notebook, the results are way different then when I run it from my personal laptop (mac pro python script).  All seeds and random initializes are set and are all the same.  Everything is identical until conv2d is first called and then the results are way different, and the accuracy drops by about 20% and trains way slower on my laptop.  

&amp;#x200B;

Would any redditors know why this happens?  I am disappointed I will not be able to train simple CNNs from my machine.",9,1
48,2018-10-19,2018,10,19,7,9pdw0k,Many Tensorflow benchmarks of the NVIDIA RTX 2070,https://www.reddit.com/r/tensorflow/comments/9pdw0k/many_tensorflow_benchmarks_of_the_nvidia_rtx_2070/,fsher,1539901233,,1,1
49,2018-10-19,2018,10,19,11,9pfirb,Program prerequisites?,https://www.reddit.com/r/tensorflow/comments/9pfirb/program_prerequisites/,Bizobinator,1539914490,"I assume that TensorFlow requires that you have Python already installed on your system?
",1,1
50,2018-10-19,2018,10,19,23,9pkilm,Gathering data for tensorflow,https://www.reddit.com/r/tensorflow/comments/9pkilm/gathering_data_for_tensorflow/,teaspoonasaurous,1539960603," 

Hi,

I am putting together a project that will hopefully be able to ID mountains in photos using Tensorflow. To do this I need to create a whole load of training data which I was putting together with Bing image search API. I'm not the worlds greatest at python and I was having an issue with trying to pass the names of mountain to argparse, create a directory cd into the directory and then download the images to that file.

`# import the necessary packages`

`from requests import exceptions`

`import argparse`

`import requests`

`import cv2`

`import os`

`import csv`

`def mountain():`

`with open('1,500 Mountains.csv') as csvfile:`

`readCSV = csv.reader(csvfile, delimiter=',')`

`print (readCSV)`

`def makemydir(mountain):`

`try:`

`os.makedirs()`

`except OSError:`

`pass`

`# let exception propagate if we just can't`

`# cd into the specified directory`

`os.chdir()`

`# construct the argument parser and parse the arguments`

`ap = argparse.ArgumentParser()`

`ap.add_argument(""-q"", ""--query"", required=True,`

    `help=""search query to search Bing Image API for"")` 

`ap.add_argument(""-o"", ""--output"", required=True,`

    `help=""path to output directory of images"")` 

`args = vars(ap.parse_args())`

`# set your Microsoft Cognitive Services API key along with (1) the`

`# maximum number of results for a given search and (2) the group size`

`# for results (maximum of 50 per request)`

`API_KEY = ""your key goes here""`

`MAX_RESULTS = 250`

`GROUP_SIZE = 50`

`# set the endpoint API URL`

`URL = ""`  
[`https://api.cognitive.microsoft.com/bing/v7.0/images/search`](https://api.cognitive.microsoft.com/bing/v7.0/images/search)`""`",7,1
51,2018-10-20,2018,10,20,9,9ppebm,"Are you interested in Computer Science and want to start learning more with Tutorials? Check out this new Youtube Channel, called Discover Artificial Intelligence. :)",https://www.reddit.com/r/tensorflow/comments/9ppebm/are_you_interested_in_computer_science_and_want/,ailearn12,1539993841,,0,1
52,2018-10-21,2018,10,21,16,9q1pzo,Rant: It it just me or attempting to transition to eager/keras api is painful?,https://www.reddit.com/r/tensorflow/comments/9q1pzo/rant_it_it_just_me_or_attempting_to_transition_to/,muchlakin,1540106539,"I mean, I can't even figure out how to log gradients after 3 hours of looking.

/rant

ps. This is moot if the promise tf2.0 becomes reality. Thanks to all the devs working on the future, despite the fact that the present is pretty rough.",7,1
53,2018-10-22,2018,10,22,2,9q5ilp,Loading a model and understanding its structure.,https://www.reddit.com/r/tensorflow/comments/9q5ilp/loading_a_model_and_understanding_its_structure/,sud0er,1540144099,"Hi everyone, I've spent a good amount of time trying to accomplish this but still not fully understanding how to do it...

&amp;#x200B;

I have a directory contained a pre-trained model with the following files in it:

`checkpoint`

`intent_classifier_tensorflow_embedding.ckpt.data-00000-of-00001`

`intent_classifier_tensorflow_embedding.ckpt.index`

`intent_classifier_tensorflow_embedding.ckpt.meta`

`intent_classifier_tensorflow_embedding_encoded_all_intents.pkl`

`intent_classifier_tensorflow_embedding_inv_intent_dict.pkl`

`intent_featurizer_count_vectors.pkl`

`metadata.json`

`training_data.json`

I'd like to load this model and know how many layers/nodes are contained within it and what their connections look like, along with any other useful information.

&amp;#x200B;

I've attempted to visualize it via tensorboard but unfortunately tensorboard hangs with a ""Computing PCA"" notification indefinitely.

&amp;#x200B;

There has to be any easy way to load this model and just get a print out of some of its key details, right?",2,1
54,2018-10-22,2018,10,22,5,9q6mfj,"I'm using tensorflow for numerical calculations only, no training, how to disable gradient calculations?",https://www.reddit.com/r/tensorflow/comments/9q6mfj/im_using_tensorflow_for_numerical_calculations/,identicalParticle,1540152020,"I'm worried that tensorflow is calculating gradients and slowing things down, even though I will never use them.  I want to disable all gradient calculations.  Is there a way to do this?",2,1
55,2018-10-22,2018,10,22,6,9q7elf,Resulting inference graph doesn't even identify training data,https://www.reddit.com/r/tensorflow/comments/9q7elf/resulting_inference_graph_doesnt_even_identify/,ShadowOverseer1,1540157685,"Hey everybody. I was following [this](https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10#1-install-tensorflow-gpu-15-skip-this-step-if-tensorflow-gpu-15-is-already-installed) tutorial to try to build a CNN to identify yellow cubes. I used SSDLite MobileNet version 2 as the model, followed the instructions on the tutorial, trained for around 20 minutes (until loss hit around 1.2), and then stopped training. I then built an inference graph using export_inference_graph.py, set one of the test images as test1 in the object_detection folder, and ran the image detection script included with the tutorial.

However, it would *never* find the yellow cube. I tried the majority of the testing dataset and some of the training dataset, but it never once found the cube. It did find other things, though, like paper and a tub of plastic. It's like the training never even ran (even though I could clearly see loss dropping drastically over time). 

The process is a little finicky to say the least, due to versioning issues, so there were some warnings. The inference graph exportation process said something about ""incomplete shape"" a couple times, and there was some sort of error when I pressed Ctrl+C to stop training. So it might be related to that, but I have no idea where to go from there.

Here are some images of the results:
[Image 1](blob:https://imgur.com/ed0da841-aeba-4cfd-8f05-0fc7181d38ff)
[Image 2](blob:https://imgur.com/e62fbd44-ca44-425b-a9f5-d72a6ecc6d26)

Any help would be appreciated!",0,1
56,2018-10-23,2018,10,23,13,9qlo2s,Anaconda Stuck on Windows,https://www.reddit.com/r/tensorflow/comments/9qlo2s/anaconda_stuck_on_windows/,spot4992,1540269886,"I am trying to run the following in a conda prompt to get the package:

&amp;#x200B;

conda install -c anaconda tensorflow-gpu 

&amp;#x200B;

It gets stuck on solving environment forever, just spinning. I let it sit for 30 minutes, but nothing. I am not a complete moron when it comes to python, but I just want to mess around with style transfer on my GPU, so what would be an easy fix for this problem?

&amp;#x200B;

P.S. I didn't write my own style transfer, I'm trying to run a python script (program?) I found online. This was a listed package.",5,1
57,2018-10-24,2018,10,24,4,9qs7pm,Multiple Networks?,https://www.reddit.com/r/tensorflow/comments/9qs7pm/multiple_networks/,Skippertech,1540322686,"This isn't a very technical question, but following a tutorial like this: https://towardsdatascience.com/lstm-by-example-using-tensorflow-feb0c1968537

Where we build a LSTM to predict a fable. How would you go about building say a network of these? Say for different texts, to see if there is any simularity accross storys (I would imagine the network would start to pickup tendencies of the human language in general)

Almost like if you have 5 different fables, you would have 5 different neural networks that could share information. Does that make sense?

Anyone have something they could point me in the direction of that does something like this",1,1
58,2018-10-24,2018,10,24,22,9qzp6q,"Step by step series on Machine Learning using Tensorflow, github code link attached in the comments of the videos.",https://www.reddit.com/r/tensorflow/comments/9qzp6q/step_by_step_series_on_machine_learning_using/,iamarmaan,1540388027,,0,1
59,2018-10-24,2018,10,24,22,9qzseg,"Watching live Webcast : Introduction to Tensorflow, you can join as well.",https://www.reddit.com/r/tensorflow/comments/9qzseg/watching_live_webcast_introduction_to_tensorflow/,iamarmaan,1540388684,,0,1
60,2018-10-25,2018,10,25,4,9r32qd,What does tf.estimator.clip_gradients_by_norm exactly do?,https://www.reddit.com/r/tensorflow/comments/9r32qd/what_does_tfestimatorclip_gradients_by_norm/,tarunn2799,1540410830,"new to ML and I'm following the Machine Learning crash course by Google. I understand the basic concepts involved in training and prediction of models, except for this one part where they use tf.contrib.estimator.clip\_gradients\_by\_norm before performing stochastic gradient descent. Can someone please explain what this does and how I'm supposed to determine the parameters for it in my code? (in simple terms)",0,1
61,2018-10-25,2018,10,25,10,9r5yeo,How is loss calculated?,https://www.reddit.com/r/tensorflow/comments/9r5yeo/how_is_loss_calculated/,ShadowOverseer1,1540432111,How is loss calculated in tensorflow? Does it use testing or training data to calculate the loss?,3,1
62,2018-10-25,2018,10,25,19,9r946h,Practical Image Recognition with Tensorflow,https://www.reddit.com/r/tensorflow/comments/9r946h/practical_image_recognition_with_tensorflow/,carbonteq1,1540464050,,3,1
63,2018-10-26,2018,10,26,14,9ri2zh,"TF Estimator: to continue from a saved checkpoint, do you just set `warm_start_from` to the checkpoint directory? What about initializers?",https://www.reddit.com/r/tensorflow/comments/9ri2zh/tf_estimator_to_continue_from_a_saved_checkpoint/,BatmantoshReturns,1540532876,"I've read this from the official TF documentation

&gt; warm_start_from: Optional string filepath to a checkpoint or
&gt; SavedModel to warm-start from, or a tf.estimator.WarmStartSettings
&gt; object to fully configure warm-starting. If the string filepath is
&gt; provided instead of a tf.estimator.WarmStartSettings, then all
&gt; variables are warm-started, and it is assumed that vocabularies and
&gt; tf.Tensor names are unchanged.

https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator

So it seems that if I just put in the folder with the checkpoint, it will load those weights. But I am not sure because I am not sure what they  mean by 'warm-started'. Tensorflow has never used this terminology before regarding loading models from checkpoints. 

But my best interpretation is that if you provide a `warm_start_from` with the checkpoint directory, like so, 

    estimator = tf.estimator.DNNClassifier(
        feature_columns=[categorical_feature_a_emb, categorical_feature_b_emb],
        hidden_units=[1024, 512, 256],
        warm_start_from=""/path/to/checkpoint/dir"")

Then it will initialize the weights with it. 

Also, say that when you declare the variable, you have initializers, for example

    embeddings = tf.get_variable( 'embeddings', dtype=tf.float32,
        initializer= tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0, dtype=tf.float32) )

Without a Tf estimator, you would run an initializer like so if you are training for the first time.

    tf.global_variables_initializer().run() 

Otherwise you would just load a checkpoint

    saver.restore(session, './path/to/checkpoint/dir' )

And skip the initializer. 

Is something similar happening when TF.Estimators are used?


",0,1
64,2018-10-26,2018,10,26,21,9rk5p3,Advice on using AMD GPUs,https://www.reddit.com/r/tensorflow/comments/9rk5p3/advice_on_using_amd_gpus/,jsgui,1540555779,"I know there is other info on this, but I'm asking here in case anyone has up-to-date advice or links to working and easy to install and use code.

&amp;#x200B;

Maybe I will use NVIDIA, I'm not ruling that out. I want to find out what can be done with modern (RX 480) AMD GPUs, in order to use TensorFlow to support style transfer.

&amp;#x200B;

Though it's not TensorFlow, does anyone know if Torch or other AI libraries could be used with AMD to get style transfer working well?

&amp;#x200B;

Also, free online access to NVIDIA GPUs would help, does anyone know if there are still services (such as from Google) that would provide this?

&amp;#x200B;

Please don't blame me for not googling these things first - I have done, and want to get the latest info here from the r/tensorflow community.",5,1
65,2018-10-26,2018,10,26,23,9rl7yh,Motherfucking opensource tensorflow shit makes it near impossible to use for a real case scenario,https://www.reddit.com/r/tensorflow/comments/9rl7yh/motherfucking_opensource_tensorflow_shit_makes_it/,manual_mode,1540564205,"Mother fucking cock sucker open source shit as usual!

Let me begin. I am trying to build an autoencoder and i followed a tutorial. Great! i have a CS degree and took many machine learning courses. I know what the fuck an autoencoder is and i also work where i get paid real money and use C# and professional (with support) tools. I could build one from hand but im trying to be smart and not write everything from scratch and use pre-existing tools and i chose TensorFlow to being with because I know python quite well.

However, it seems that the people who wrote this shit get boners everytime they need to include the mnist dataset into EVERY FUCKING TUTORIAL! Have you ever thought of writing a fucking tutorial where you can show people how to use their own fucking images and load that shit up the model's asshole? Have you thought that not every fucking needed dataset exists in numpy arrays?

Below is a fucking tutorial i followed but we are not interested in using fucking numbers for an autoencoder where i work. I want to be able to load my own fucking images and put that shit into an autoencoder. 

This line in particular gives off a lot of boners to the nerds who wrote this shit: (x_train, _), (x_test, _) = mnist.load_data()

But the curse of open source shit is that there is no fucking documentation on how to use this shit in an environment where we dont give a shit about mnist data! Try go to tensor flows fucking webpage and type in autoencoder... jack shit! I cant figure out how to use TensorFlow's autoencoder model using my own fucking data

Anyways here is the code for the tutorial i am using and if anyone out here reading this shit could help me out I would be very grateful.

I have a bunch of images in this path on my workstation: S:/fucking_images/thermal.0001.jpg and it goes to thermal.6343.jpg

I want to train it on an autoencoder and see my generated outputs.

The code that works from a tutorial:

# this is the size of our encoded representations
encoding_dim = 32  # 32 floats -&gt; compression of factor 24.5, assuming the input is 784 floats

# this is our input placeholder
input_img = Input(shape=(784,))
# ""encoded"" is the encoded representation of the input
encoded = Dense(encoding_dim, activation='relu')(input_img)
# ""decoded"" is the lossy reconstruction of the input
decoded = Dense(784, activation='sigmoid')(encoded)

# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)

# this model maps an input to its encoded representation
encoder = Model(input_img, encoded)

# create a placeholder for an encoded (32-dimensional) input
encoded_input = Input(shape=(encoding_dim,))
# retrieve the last layer of the autoencoder model
decoder_layer = autoencoder.layers[-1]
# create the decoder model
decoder = Model(encoded_input, decoder_layer(encoded_input))

autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')

# prepare data using MNIST database
(x_train, _), (x_test, _) = mnist.load_data()

# normalize between 0 and 1
x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print (x_train.shape)
print (x_test.shape)

# train autoencoder for n epochs
autoencoder.fit(x_train, x_train,
                epochs=30,
                batch_size=256,
                shuffle=True,
                validation_data=(x_test, x_test))

# encode and decode some digits
# note that we take them from the *test* set
encoded_imgs = encoder.predict(x_test)
decoded_imgs = decoder.predict(encoded_imgs)


n = 10  # how many digits we will display
plt.figure(figsize=(20, 4))
for i in range(n):
    # display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()

",39,1
66,2018-10-27,2018,10,27,2,9rmz53,"Why do cuDNN input tensors have a ""time_len"" dimension?",https://www.reddit.com/r/tensorflow/comments/9rmz53/why_do_cudnn_input_tensors_have_a_time_len/,KjellJagland,1540576163,"I'm currently working on a DSP predictor for audio signals using a RNN made out of LSTM or GRU cells. The TensorFlow documentation suggested that one should use the cuDNN wrappers for optimal performance, so I started out with the following cell type:

[https://www.tensorflow.org/api\_docs/python/tf/contrib/cudnn\_rnn/CudnnLSTM#\_\_call\_\_](https://www.tensorflow.org/api_docs/python/tf/contrib/cudnn_rnn/CudnnLSTM#__call__)

I had a hard time figuring out what kind of input this RNN takes. Neither the TensorFlow documentation nor the cuDNN documentation seem to explain or even mention this but the call operator takes 3D input tensors with the following dimensions:

[https://github.com/tensorflow/tensorflow/blob/r1.11/tensorflow/contrib/cudnn\_rnn/python/layers/cudnn\_rnn.py#L379](https://github.com/tensorflow/tensorflow/blob/r1.11/tensorflow/contrib/cudnn_rnn/python/layers/cudnn_rnn.py#L379)

It's different from  the way, say, the Keras LSTM and GRU implementations work but it still makes perfect sense to me. Now, the thing I found rather puzzling is the ""time"" dimension. What's that all about? Is this just a dimension added for convenience, since many LSTM networks deal with time-sensitive data, with \[x, 1, y\] and \[1, x, y\] boiling down to the same thing? Is it just an additional way of structuring batches or does it have a deeper meaning?

Some of my initial tests resulted in unexpected memory constraints and performance issues when I swapped the the first and the second dimension so I might be completely mistaken, which is why I'm asking.

Thanks for your input!",0,1
67,2018-10-27,2018,10,27,22,9rua1g,Tensorflow saving and loading model,https://www.reddit.com/r/tensorflow/comments/9rua1g/tensorflow_saving_and_loading_model/,Jandevries101,1540647244," 

I am using Python 3 to code my Tensorflow model. i have some issues surrounding the loading and saving a model. i've did research and made this function out of it:

       def SaveDing():
    
        print(checksavedmodelexists[0])
        print(""printed checksavedmodelexists"")
    
    
        my_file = Path(""C:\\Users\\Gebruiker\\Downloads\\model.ckpt.index"")
    
        if not checksavedmodelexists[0]:
    
            checksavedmodelexists[0] = True
    
            if my_file.is_file():
    
                init_op = tf.global_variables_initializer()
    
                sess = tf.Session()
    
                sess.run(init_op)
    
                saver = tf.train.Saver()
    
                saver.restore(sess, ""C:\\Users\\Gebruiker\\Downloads\\model.ckpt"")
    
                print(""Loaded in previous Saved Model!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"")
    
            else:
    
                init_op = tf.global_variables_initializer()
    
                sess = tf.Session()
    
                sess.run(init_op)
    
                print(""Made a new Saved Model File"")
    
        else: 
    
            init_op = tf.global_variables_initializer()
    
            sess = tf.Session()
    
            sess.run(init_op)
    
            print(""Made a new Saved Model File"")
    
        return sess

what it should do is check if a model already exists or not if there isn't he creates a new model file if there is he should load in a new model. so when calling it with:

            saver = tf.train.Saver()
    
            session = tf.Session()
    
            save_path = saver.save(Class.SaveDing(), ""C:\\Users\\Gebruiker\\Downloads\\model.ckpt"")

to save the training model, he DOES save the model and i get the 3 files index,meta and data, but when i run the code again and call at the END when ALL variables are created i call:

    Class.SaveDing()

so that should then LOAD all the previous values in the tf variables, so that he can start from where it left of, i don't get any errors when doing this but i can clearly see that the values that are given aren't correct and just random.

**how can i make it that it uses the previous model to train further on / what is wrong with my code?**

thanks in advance for responding",1,1
68,2018-10-28,2018,10,28,7,9ryjtf,Why is tensorflow not 'object orientated',https://www.reddit.com/r/tensorflow/comments/9ryjtf/why_is_tensorflow_not_object_orientated/,pocketMAD,1540680977,,13,1
69,2018-10-28,2018,10,28,16,9s1lic,Question: Managing large number of feature names on tabular datasets for serializing to `TFRecords` and for ingesting to `tf.data()`,https://www.reddit.com/r/tensorflow/comments/9s1lic/question_managing_large_number_of_feature_names/,krishnab75,1540713243,"Hey Folks. I am still just getting use to \`Tensorflow,\` but I had question that was more based on experience rather than technical documentation. So I have a tabular dataset with about 100 features. Now if I want to serialize that dataset to TFRecords format, I have to indicate the column name and the data type (BytesList, Int64List, FloatList). Then for ingesting that same data, I can use the \`[tf.data](https://tf.data)()\` API, but again I have to pass a parsing function that converts the different features in the TFRecords format into a format that \`Tensorflow\` will understand. So I have to indicate whether an \`tf.Example()\` is \`tf.FixedLenFeature()\` or \`tf.VarLenFeature()\`, and I have to specify its data type and name again. Finally, I have to specify more information on the same features to create the \`tf.feature\_column()\` specification for each feature. 

&amp;#x200B;

So it seems that maintaining a list of hard coded values for each of these steps is pretty redundant and really fragile--since one change in a column will break my pipeline. 

&amp;#x200B;

I was just wondering how other folks handle this problem? How do you manage importing and serializing features and keeping data integrity over the different settings for the features? For example do people use some kind of column naming convention and then sort things by bytelist, int64list, and floatlist by the naming convention? Or do they keep this data in some other csv file and pull it in when needed? Any tips or suggestions would be appreciated. 

&amp;#x200B;

&amp;#x200B;",0,1
70,2018-10-29,2018,10,29,3,9s5l5t,Loading weights one layer at a time,https://www.reddit.com/r/tensorflow/comments/9s5l5t/loading_weights_one_layer_at_a_time/,anilmaddala,1540752400,"I want to run a tensorflow model on Raspberry pi and the model size is a constraint.

Is it possible to load the weights of only one layer at a time, do the forward pass for that layer and load the weights of the next layer to do the forward pass?

This way, the RAM of the hardware device will become less of a problem. The inference might be slow but is there an option in Tensorflow to achieve this?",6,1
71,2018-10-30,2018,10,30,7,9shs5p,"For anyone looking to get into machine learning, I would advise that you don't learn the behemoth libraries like Tensorflow or Theano, but instead learn how to use a high-level API like Keras. Here's a quick video to explain what it is. Hope I was helpful!",https://www.reddit.com/r/tensorflow/comments/9shs5p/for_anyone_looking_to_get_into_machine_learning_i/,antaloaalonso,1540850736,,3,1
72,2018-10-30,2018,10,30,10,9sjc3w,Question about reading data in tensorflow,https://www.reddit.com/r/tensorflow/comments/9sjc3w/question_about_reading_data_in_tensorflow/,aditya_cplusplus,1540862205,"I have a training data set in a txt file as follows: 

**temperature, x1, y1, z1, x2, y2, z2, x3, y3, z3, potential\_energy**

potential\_energy is the label and the rest are features. I'm having difficulty in understanding how to load such data in tensorflow. According to the documentation, I tried to use the following way:

`dataset = tf.data.TextLineDataset(""features.txt"")`

`data_iterator = iter(dataset)`

`j = 0`

`for j in range(5):`

`print(next(data_iterator))`

The program displays the data, but how do I tell tensorflow that which column is the label and features etc?

Thanks

&amp;#x200B;",1,1
73,2018-10-30,2018,10,30,15,9slezg,How to train ResNet-50 on Cloud TPU with data streamed from Cloud Bigtable,https://www.reddit.com/r/tensorflow/comments/9slezg/how_to_train_resnet50_on_cloud_tpu_with_data/,fhoffa,1540881216,,0,1
74,2018-10-30,2018,10,30,22,9so0x8,Converting JPEG images on disk to TFRecords,https://www.reddit.com/r/tensorflow/comments/9so0x8/converting_jpeg_images_on_disk_to_tfrecords/,gokstudio,1540907122,"Hi Everyone,

I have a bunch of JPEGs on disk (tiny-imagenet) and I want to convert them to TFRecords to do efficient data feeding. Unfortunately, most tutorials and the TF website's [tf.data](https://tf.data) walkthrough starts with assuming you have TFRecords already but with no mention of how to create it.

  
I know that there are some code examples on how to preprocess imagenet images into TFRecords but I am specifically looking for documentations / walkthroughs on how to convert JPEGs into TFRecords.

Any suggestions?  
",3,1
0,2018-11-2,2018,11,2,23,9tkjap,Contributing to privacy-preserving ML: Crafting building blocks for secure AI,https://www.reddit.com/r/tensorflow/comments/9tkjap/contributing_to_privacypreserving_ml_crafting/,morgangiraud,1541168632,,0,1
1,2018-11-3,2018,11,3,3,9tmzmg,Contributing to privacy-preserving ML: Crafting building blocks for secure AI,https://www.reddit.com/r/tensorflow/comments/9tmzmg/contributing_to_privacypreserving_ml_crafting/,morgangiraud,1541185160,,0,1
2,2018-11-3,2018,11,3,11,9tqpiy,Error setting up tensorflow gpu,https://www.reddit.com/r/tensorflow/comments/9tqpiy/error_setting_up_tensorflow_gpu/,Yogi_DMT,1541213104,"I'm getting this error while trying to import tensorflow gpu. The files are on my path

https://imgur.com/WkoTpdF

and i do see the file it is asking for

https://imgur.com/7wGoOD3

The solution to this error seems to be that i downloaded the wrong cuda ie. cudart64_91.dll but as you can see i have the right version.

any ideas?",1,1
3,2018-11-3,2018,11,3,13,9trb7y,how can i solve this issue on implementing virtuLENV,https://www.reddit.com/r/tensorflow/comments/9trb7y/how_can_i_solve_this_issue_on_implementing/,maprogrammer,1541218730,"I have ubuntu 18.04 64 bit . i bought a hard ssd . and gpu is intel Haswall, laptob hp probook

i typed sudo apt install virtualenv on terminal

but i cant complete steps for installing and use tensorflow codes for object detection task and inpplementing algorithmsOR USING SPYDER AND NOTEBOOK

&amp;#x200B;",6,1
4,2018-11-4,2018,11,4,7,9tyh7t,What exactly are the parameters of tf.metric.mean_iou?,https://www.reddit.com/r/tensorflow/comments/9tyh7t/what_exactly_are_the_parameters_of_tfmetricmean/,pocketMAD,1541285263,"I'm somewhat new to tensorflow, but I'm really having a lot of fun learning it. I have a somewhat incomplete understanding of graphs and sessions.

 I'm part of a robotics club on the machine learning team. They have a somewhat good, somewhat shitty SSD and I'm tasked to create a model evaluation script using tf.metric. I am able to splice out a 4-dim vector from the model's output -- (x\_min, y\_min, x\_max, y\_max) -- which is the opposite corners of the single bounding box on the image. Since I have the ground truth and prediction bboxes, how do I use tf.metric.mean\_iou to utilize it?

Also, the prediction and labels are correct, I've checked.

Here is some code that I have:

    print(label) // correct ground truth (x_min, y_min, x_max, y_max)
    print(pred_bbox) // correct prediction (x_min, y_min, x_max, y_max)
    iou, conf_mat = tf.metrics.mean_iou(tf.constant(label), tf.constant(pred_bbox), 2) // 2 classes because there are only two objects I trained the model on
    sess.run(tf.local_variables_initializer())
    miou = sess.run([iou])
    print(miou)
    

This outputs '\[0.0\]' whenever I feed the program an image. Any idea what I am doing wrong? I am happy to give you more info if you ask. :) ",0,1
5,2018-11-4,2018,11,4,19,9u2fqz,How can DNNClassifier handle imbalanced data,https://www.reddit.com/r/tensorflow/comments/9u2fqz/how_can_dnnclassifier_handle_imbalanced_data/,6ixEggs,1541327847,"Hi guys, I am a newbie to TensorFlow. I am now using estimator.DNNClassifier to handle binary classification. Ive got 87% of accuracy for my test data. But in fact, 9X% for negative and only 10% for positive.

The dataset gives 70,000 training data and only ~600 of them are positive. I can get 90% accuracy by returning all 0s. But it means nothing. 

Is there a way to tackle this problem? ",4,1
6,2018-11-5,2018,11,5,2,9u52qz,ImportError,https://www.reddit.com/r/tensorflow/comments/9u52qz/importerror/,duplido,1541351835,"So I am trying to get tensorflow to run, but I always get an error that there is no module named \_pywrap\_tensorflow\_internal.

&amp;#x200B;

Googling it suggested that I am missing a PATH reference, which I don't there also isn't any missing dll mentioned in the traceback. I tried a lot of things and am out of ideas right now, maybe someone can help me ?

&amp;#x200B;

The entire traceback

Traceback (most recent call last):

  File ""C:\\Program Files (x86)\\Python35-32\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow\_internal.py"", line 18, in swig\_import\_helper

fp, pathname, description = imp.find\_module('\_pywrap\_tensorflow\_internal', \[dirname(\_\_file\_\_)\])

  File ""C:\\Program Files (x86)\\Python35-32\\lib\\[imp.py](https://imp.py)"", line 297, in find\_module

raise ImportError(\_ERR\_MSG.format(name), name=name)

ImportError: No module named '\_pywrap\_tensorflow\_internal'

&amp;#x200B;

During handling of the above exception, another exception occurred:

&amp;#x200B;

Traceback (most recent call last):

  File ""C:\\Program Files (x86)\\Python35-32\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow.py"", line 58, in &lt;module&gt;

from tensorflow.python.pywrap\_tensorflow\_internal import \*

  File ""C:\\Program Files (x86)\\Python35-32\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow\_internal.py"", line 28, in &lt;module&gt;

\_pywrap\_tensorflow\_internal = swig\_import\_helper()

  File ""C:\\Program Files (x86)\\Python35-32\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow\_internal.py"", line 20, in swig\_import\_helper

import \_pywrap\_tensorflow\_internal

ImportError: No module named '\_pywrap\_tensorflow\_internal'

&amp;#x200B;

During handling of the above exception, another exception occurred:

&amp;#x200B;

Traceback (most recent call last):

  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;

  File ""C:\\Program Files (x86)\\Python35-32\\lib\\site-packages\\tensorflow\\\_\_init\_\_.py"", line 24, in &lt;module&gt;

from tensorflow.python import \*

  File ""C:\\Program Files (x86)\\Python35-32\\lib\\site-packages\\tensorflow\\python\\\_\_init\_\_.py"", line 49, in &lt;module&gt;

from tensorflow.python import pywrap\_tensorflow

  File ""C:\\Program Files (x86)\\Python35-32\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow.py"", line 74, in &lt;module&gt;

raise ImportError(msg)

ImportError: Traceback (most recent call last):

  File ""C:\\Program Files (x86)\\Python35-32\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow\_internal.py"", line 18, in swig\_import\_helper

fp, pathname, description = imp.find\_module('\_pywrap\_tensorflow\_internal', \[dirname(\_\_file\_\_)\])

  File ""C:\\Program Files (x86)\\Python35-32\\lib\\[imp.py](https://imp.py)"", line 297, in find\_module

raise ImportError(\_ERR\_MSG.format(name), name=name)

ImportError: No module named '\_pywrap\_tensorflow\_internal'

&amp;#x200B;

During handling of the above exception, another exception occurred:

&amp;#x200B;

Traceback (most recent call last):

  File ""C:\\Program Files (x86)\\Python35-32\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow.py"", line 58, in &lt;module&gt;

from tensorflow.python.pywrap\_tensorflow\_internal import \*

  File ""C:\\Program Files (x86)\\Python35-32\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow\_internal.py"", line 28, in &lt;module&gt;

\_pywrap\_tensorflow\_internal = swig\_import\_helper()

  File ""C:\\Program Files (x86)\\Python35-32\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow\_internal.py"", line 20, in swig\_import\_helper

import \_pywrap\_tensorflow\_internal

ImportError: No module named '\_pywrap\_tensorflow\_internal'

&amp;#x200B;

&amp;#x200B;

Failed to load the native TensorFlow runtime.

&amp;#x200B;

See [https://www.tensorflow.org/install/install\_sources#common\_installation\_problems](https://www.tensorflow.org/install/install_sources#common_installation_problems)

&amp;#x200B;

for some common reasons and solutions.  Include the entire stack trace

above this error message when asking for help.",16,1
7,2018-11-5,2018,11,5,4,9u675p,Tensorflow loading and saving models not correct way?,https://www.reddit.com/r/tensorflow/comments/9u675p/tensorflow_loading_and_saving_models_not_correct/,Jandevries101,1541359235,"hi, i am not sure if this method works for saving and loading, especially since i do tf init twice.... could somebody confirm for me? (No i can't print any NN variables, please just keep it if the code is correct, thanks)

&amp;#x200B;

**For saving:**

&amp;#x200B;

1 i just create my variables

2 i do [self.sess.run](https://self.sess.run)(tf.global\_variables\_initializer()) (inside the class)

3 do some training shizzles

4 when stop training: (Outside the class) 

                init = tf.global_variables_initializer()                
                saver = tf.train.Saver()
                with tf.Session() as sess:
                    sess.run(init)
                    save_path = saver.save(sess, ""C:\\Users\\Gebruiker\\Downloads\\model.ckpt"")

&amp;#x200B;

**For Loading:**

&amp;#x200B;

1 i just create my variables

2 i do [self.sess.run](https://self.sess.run)(tf.global\_variables\_initializer()) (inside the class)

3 i call my load function (inside the class)

&amp;#x200B;

        def SaveDing(): 
    			
            print(checksavedmodelexists[0])
            my_file = Path(""C:\\Users\\Gebruiker\\Downloads\\model.ckpt.index"")   
    		
            if not checksavedmodelexists[0]: #if there is no file   
                checksavedmodelexists[0] = True            
                if my_file.is_file():            
                    saver = tf.train.Saver()                
                    with tf.Session() as sess:
                        saver.restore(sess, ""C:\\Users\\Gebruiker\\Downloads\\model.ckpt"")                
                    print(""Loaded in previous Saved Model."")                
                else:
                    print(""no previous model found, will start from here then."")                
            else:
                print(""If you see this message there may be something wrong."")        
            return sess

&amp;#x200B;

it should check if a model exists (a saved one) and then load that one in, if not it should do nothing so the algorithme can train the current model of course, very logic....

&amp;#x200B;

&amp;#x200B;

i am fairly confident that saving and loading/saving or loading is not workin, because i can see a performance drop when i try to load in the older model.  see picture: 

&amp;#x200B;

you can clearly see where i started my next run on the same model

[https://cdn.discordapp.com/attachments/455970083617898496/504351789265715210/2018-10-23\_19h25\_39.png](https://cdn.discordapp.com/attachments/455970083617898496/504351789265715210/2018-10-23_19h25_39.png)

&amp;#x200B;

the code doesn't give any errors and the prints print like they ""should""

&amp;#x200B;

i believe its something about that double init call when saving?

please let me know what you think / what the fix is

&amp;#x200B;

thanks for reading,

&amp;#x200B;

Jan

&amp;#x200B;

&amp;#x200B;",8,1
8,2018-11-5,2018,11,5,5,9u6ssx,Tensorflow 2.0: models migration and new design,https://www.reddit.com/r/tensorflow/comments/9u6ssx/tensorflow_20_models_migration_and_new_design/,pgaleone,1541363401,,9,1
9,2018-11-5,2018,11,5,18,9uc4lb,How to write a custom loss function,https://www.reddit.com/r/tensorflow/comments/9uc4lb/how_to_write_a_custom_loss_function/,MrFerixx,1541410011,"Hi everyone!

I'm pretty new to Tensorflow and I'm trying to write a simple Cross Entropy loss function. I write something that seems good to me:

`def cross_entropy(y_pred, y_true):`  
  `cross_entropy = tf.reduce_sum(y_true * tf.log(y_pred) + (tf.subtract(1.0, -y_true)) * tf.log(tf.subtract(1.0, -y_pred)), axis=[1])`  
 `return cross_entropy`

&amp;#x200B;

`loss = cross_entropy(x, y)`    
`optimizer = tf.train.GradientDescentOptimizer(0.01)`  
`train = optimizer.minimize(loss)`

&amp;#x200B;

But I get some values at the beginning and then only NaN values. What am I doing wrong?

Thank you very much in advance!

&amp;#x200B;",7,1
10,2018-11-5,2018,11,5,19,9uce4p,object detection fine tune reduce to single object,https://www.reddit.com/r/tensorflow/comments/9uce4p/object_detection_fine_tune_reduce_to_single_object/,c94jk,1541413243,"I can't find any clear documentation online. What I can do is load the protobuf file containing trained model and modify the config file to change class number - but I am unsure how to then remove the final layer, freeze the lower weights and re-append an output layer for my single class. 

&amp;#x200B;

Any pointers in the right direction would be appreciated.",4,1
11,2018-11-6,2018,11,6,0,9ue7bp,I am wondering which algorithm tf.contrib.embed_sequence() exactly uses behind the hood,https://www.reddit.com/r/tensorflow/comments/9ue7bp/i_am_wondering_which_algorithm_tfcontribembed/,Cokdewer,1541430054,"So it maps sequence of symbols (usually words) to sequence of embedding, where we pass the size of our embedding vector that we want as a result.

But, am just curious that does it use CBOW, skip-gram or just dimension reduction technique on one hot vectors behind the scene to produce embedding vectors.

",0,1
12,2018-11-7,2018,11,7,2,9uqjht,Where does the retrained model of inception v3 go after retraining on mac?,https://www.reddit.com/r/tensorflow/comments/9uqjht/where_does_the_retrained_model_of_inception_v3_go/,PhoebusElpollo,1541526498,,0,1
13,2018-11-7,2018,11,7,3,9uqpnr,Is there a way to get order of operations/variables from a trained model?,https://www.reddit.com/r/tensorflow/comments/9uqpnr/is_there_a_way_to_get_order_of/,marcotb12,1541527553,"I have a trained model that I need to convert to another format to do the inference that doesn't user tensorflow. I am probably going to convert the variables to numpy arrays and do numpy operations on them. I do not care about training. Only about inference.

Visualizing the model is hard because the model is huge and complex. What I am trying to do is read the operations/variables on from the saved model's graph. The problem is that the order is not entirely clear. 

I can use graph.get_operations() to get ops but there are so many operations that it is hard to tell which ones are for inferencing and which ones are not. Is there a way to get a computational graph from a trained model where the order of ops and what variables go into the ops for inference are clear?

What I can do now is get all ops and look at the inputs attribute, but that doesn't really narrow anything down.",2,1
14,2018-11-7,2018,11,7,22,9uzlwi,A few days ago I heard about AdaNet,https://www.reddit.com/r/tensorflow/comments/9uzlwi/a_few_days_ago_i_heard_about_adanet/,Good_Development,1541598903,"What is really AdaNet? A framework different from TensorFlow or a complementary api? Does it work together?

If someone could clarify these concepts I would appreciate it.",3,1
15,2018-11-8,2018,11,8,7,9v42tx,Video inference with queues?,https://www.reddit.com/r/tensorflow/comments/9v42tx/video_inference_with_queues/,munkeegutz,1541629375,"Hello, all!

I am trying to build a pipeline for performing inference on videos, but it looks like I'm starving the GPU of data.  I would like to build a queue which serves my model frames from a cv2.videocapture() object.  It sounds like py\_func will help me here, but I'm not super clear on how to maintain the state within that object, or how to indicate to the system that the end of the file has been reached.

This is my first foray into using tensorflow queues, so I might be getting a little over my head ;-)

Any recommendations?  Thanks in advance!",2,1
16,2018-11-8,2018,11,8,18,9v8m6m,Retraining from a frozen GraphDef,https://www.reddit.com/r/tensorflow/comments/9v8m6m/retraining_from_a_frozen_graphdef/,thibault_c,1541669492,"From a GraphDef and variables stored in a checkpoint file, [freeze\_graph](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py) converts all variables into const ops and outputs a new GraphDef.

Now,  I would like to fine-tune a pertained model but no checkpoint is provided, only the code to build the graph, and a frozen GraphDef (outputted by freeze\_graph) in a .pb file. Is there any way to do the opposite, that is, convert the const ops back to get trainable variables?",1,1
17,2018-11-8,2018,11,8,20,9v992c,"Object detection with TensorFlow.JS and YOLO (supports Tiny YOLO v1, 2, 3 and YOLO v3)",https://www.reddit.com/r/tensorflow/comments/9v992c/object_detection_with_tensorflowjs_and_yolo/,x_ash,1541676934,,2,1
18,2018-11-8,2018,11,8,22,9va24q,Help Please! iterating through a tensor aka re-sampling a tensor,https://www.reddit.com/r/tensorflow/comments/9va24q/help_please_iterating_through_a_tensor_aka/,MachinaDoctrina,1541684437,"Hi developers who know tensorflow better than I do,  

I am trying to implement a custom loss function (based on Sequential Monte Carlo aka Particle Filters) in tensorflow that includes a re-sampling routine but I can't seem to figure how to implement the indexing correctly so that it can be run within a `tf.Session()`

The equivalent python function would be:
``
    import numpy as np
    
    def resampling(w, x):
        N = w.shape[0]
        bins = np.cumsum(w)
        ind = np.arange(N)
        u = (ind + np.random.rand(N))/N
        indx = np.digitize(u, bins)
        return x[indx]
``
    
where `w` is a set of normalised weights, and `x` is a vector of states. Both `w` and `x` would be tensors, any help would be appreciated!

the crux of my problem is that I can't seem to find any ops that would allow me to iterate over one dimension of a tensor (in this case it would be a `shape = [1000, 1]`) and based on some criteria i.e what index of bins and thus `X` (as the `w` is a vector of weights of `X`) has a weight that given some sample from a Uniform distribution is `&lt;=` to some value in the `cdf := bins`. 

I hope I've explained myself clear enough, but if you need further clarification please contact me, I would really like to figure out how to do this. Also I've asked on SO but to no avail (https://stackoverflow.com/questions/53193841/implementing-sequential-monte-carlo-resampling-routine-in-tensorflow)

Cheers,
Chris
",5,1
19,2018-11-9,2018,11,9,1,9vbkyc,When tensorflow v2 is going to be released?,https://www.reddit.com/r/tensorflow/comments/9vbkyc/when_tensorflow_v2_is_going_to_be_released/,aziz_22,1541695370,,5,1
20,2018-11-9,2018,11,9,7,9vejnk,Can some 1 help me with a vgg19 pre trained model ?,https://www.reddit.com/r/tensorflow/comments/9vejnk/can_some_1_help_me_with_a_vgg19_pre_trained_model/,jabbaluck,1541715259,"Hey guys, 

&amp;#x200B;

I got a script from github and i wanna try it out .It seems it uses vgg19 and i need to give it the path of the model . I looked on internet and didnt found one allready trained. 

Could u give me  a hand with 1 model vgg19 pre trained   ?(probl in time i'll train 1 for myself but for now wanna try a script ) . 

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;",4,1
21,2018-11-10,2018,11,10,0,9vl55o,Instalation problems,https://www.reddit.com/r/tensorflow/comments/9vl55o/instalation_problems/,Folkwang,1541775850,"Hello guys. So, Ive been trying to install tensorflow both on Windows and Ubuntu, unsuccessfully.
So, does Tensorflow requires Anaconda? It only supports Python3.7, and I cant download the 3.6 version, which seems to be supported. 
Until now, I tried to follow Mike Jay yt video, and it didnt work.
So, what should I do?
",7,1
22,2018-11-10,2018,11,10,2,9vmlj3,Any tutorials on using tensorflow_probability with Keras?,https://www.reddit.com/r/tensorflow/comments/9vmlj3/any_tutorials_on_using_tensorflow_probability/,o-rka,1541785821,Im looking for tutorials on how to use both together to make probabilistic neural nets. ,2,1
23,2018-11-10,2018,11,10,23,9vupof,Tensorflow learning Help,https://www.reddit.com/r/tensorflow/comments/9vupof/tensorflow_learning_help/,vamos47,1541860300,"Hi, I trained until now using keras functional API, I want to explore tensorflow. All the tutorials i find in tensorlow.org are using tfEstimators, tfLearn, tfkeras can any one know where I can find training using tensorflow core . I am looking into how to save and restore checkpoints and how to add signatures to make it servvable. ",1,1
24,2018-11-11,2018,11,11,4,9vx4vi,Build and install TensorFlow from source with MKL DNN support and AVX enabled,https://www.reddit.com/r/tensorflow/comments/9vx4vi/build_and_install_tensorflow_from_source_with_mkl/,rewqasdfsw,1541878432,,0,1
25,2018-11-11,2018,11,11,9,9vzg63,Do I need to reload the entire model to get a new prediction?,https://www.reddit.com/r/tensorflow/comments/9vzg63/do_i_need_to_reload_the_entire_model_to_get_a_new/,infinitykick,1541896286,"Is it neccesary to reload a FrozenModel every time I want to get a result for new input? Loading the model takes over twice as long as the actual execution...

Without reloading, I get `Error: Tensor is disposed`. All sample code and tutorials I can find reload the model on every run.",0,1
26,2018-11-11,2018,11,11,18,9w2nm2,Build and install TensorFlow 1.12 Python package with CUDA 10 (and cuDNN 7.4) for Windows,https://www.reddit.com/r/tensorflow/comments/9w2nm2/build_and_install_tensorflow_112_python_package/,amsokol,1541930000,I have updated my tutorial to help you to build and install TensorFlow 1.12 Python package with CUDA 10 (and cuDNN 7.4) for Windows. Enjoy: [https://medium.com/@amsokol.com/update-2-how-to-build-and-install-tensorflow-gpu-cpu-for-windows-from-source-code-using-bazel-61c26553f7e8](https://medium.com/@amsokol.com/update-2-how-to-build-and-install-tensorflow-gpu-cpu-for-windows-from-source-code-using-bazel-61c26553f7e8),1,1
27,2018-11-12,2018,11,12,0,9w4kc1,Tensorflow sigmoid returning high values early and much,https://www.reddit.com/r/tensorflow/comments/9w4kc1/tensorflow_sigmoid_returning_high_values_early/,Jandevries101,1541949762,"hi

&amp;#x200B;

my sigmoid returns 

&amp;#x200B;

0.94659156

&amp;#x200B;

0.20719022

&amp;#x200B;

0.8733577

&amp;#x200B;

like very constant for specific actions, it's really annoying, cause it happens everytime my LR is 0.0001 and this turns in almost the first 3 steps with reward 0 for that action, why?",5,1
28,2018-11-12,2018,11,12,0,9w4tii,tensorflow or keras?,https://www.reddit.com/r/tensorflow/comments/9w4tii/tensorflow_or_keras/,bharddwaj,1541951751,Is it better to learn a high level api like keras or tensorflow? What are the benefits of knowing one as opposed to the other? ,8,1
29,2018-11-12,2018,11,12,1,9w4xw4,What do the tf hub imagenet inception v3 feature vectors mean?,https://www.reddit.com/r/tensorflow/comments/9w4xw4/what_do_the_tf_hub_imagenet_inception_v3_feature/,Zak_Wormald,1541952652,"I have written a program that takes an image and passes it through tf hub's off-the-shelf inception classifier. The classifier returns a feature vector, but i dont know which number in the vector refers to what object. For example, i have passed in a picture of a cat and the returned feature vector's maximum value is it's 1847th value, but i don't know whether a high value in the 1847th position refers  to the model finding  a cat, a dog, or anything. If anyone knows how to translate between inception's output and what that means it thinks the picture contains i would be grateful for your help.",1,1
30,2018-11-12,2018,11,12,10,9w9cf2,How to control / protect your AI models?,https://www.reddit.com/r/tensorflow/comments/9w9cf2/how_to_control_protect_your_ai_models/,taewoo,1541984625,"i work on biometrics / face recognition,..... and as with most data sensitive stuff, the customer I deal wants to in-house to not violate privacy laws &amp; regulations.  The way we charge is per use. 

&amp;#x200B;

Of course, we can do all kinds of obfuscation / compile model to binary and all that.. but at the end of the day, we have to protect our company's interest and this doesnt' give us the protection necessary.

&amp;#x200B;

How would you go about doing it? The only obvious solution is to run it as web service in virtual private cloud in servers located in THEIR countries. Any suggestions?",4,1
31,2018-11-13,2018,11,13,6,9wilgt,School project (205 features binary classification),https://www.reddit.com/r/tensorflow/comments/9wilgt/school_project_205_features_binary_classification/,sleepy3005,1542059637,"Hello,

&amp;#x200B;

I have a school project that I'm working on and I was wondering if anyone on here could give a suggestion about how I should proceed using TensorFlow. As the title states, the text training file will have many instances that have 205 features each with the class value at the last column (0/1). The features will have values with different ranges. I am supposed to use these features and produce a binary classification. I can use any algorithm and technique that I want. I'm leaning towards using Neural Networks with TensorFlow but I am open to suggestions. 

&amp;#x200B;

Thanks!",6,1
32,2018-11-13,2018,11,13,9,9wjy7o,Advanced Machine Learning with TensorFlow on Google Cloud,https://www.reddit.com/r/tensorflow/comments/9wjy7o/advanced_machine_learning_with_tensorflow_on/,skj8,1542069017,,0,1
33,2018-11-13,2018,11,13,12,9wlfhc,"Tried using tensorflows retrain.py to train An object detector on new categories. Console said it had 98% train accuracy and 50% test accuracy, yet after I tested it myself, it wasnt accurate in the least. Any idea?",https://www.reddit.com/r/tensorflow/comments/9wlfhc/tried_using_tensorflows_retrainpy_to_train_an/,pocketMAD,1542080158,,7,1
34,2018-11-13,2018,11,13,14,9wm5sg,How to read gradient of all convolution layers of a tensorflow model while training?,https://www.reddit.com/r/tensorflow/comments/9wm5sg/how_to_read_gradient_of_all_convolution_layers_of/,4joyalbin,1542086356,"What is the method to get the gradient of all convolution layers of a tensorflow model while training?

I tried to register  *RegisterGradient* () for the 'Conv2D' operators but failed with error ""two registration for gradient"".

Anyone please share me an example to get gradient of all convolution layers?",0,1
35,2018-11-13,2018,11,13,19,9wnseq,What do you think about Tensorflow 2.x compared to Tensorflow 1.x?,https://www.reddit.com/r/tensorflow/comments/9wnseq/what_do_you_think_about_tensorflow_2x_compared_to/,thisisiron,1542103269,"If the tensor flow is updated to 2.x, there will be a few changes. What about you?

i read this blog [post](https://pgaleone.eu/tensorflow/gan/2018/11/04/tensorflow-2-models-migration-and-new-design/), and i took the time to think about tensorflow.",7,1
36,2018-11-14,2018,11,14,10,9wvb6u,Correct me If I am wrong,https://www.reddit.com/r/tensorflow/comments/9wvb6u/correct_me_if_i_am_wrong/,vamos47,1542158507,I cant take a checkpoint folder from someone and turn into into a servable code as I wont have computation graph from it. I will also need the code to build the model. I should only take Save_model or frozen_graph models.,2,1
37,2018-11-14,2018,11,14,10,9wvc07,How to transform music into tensors?,https://www.reddit.com/r/tensorflow/comments/9wvc07/how_to_transform_music_into_tensors/,thefernandito,1542158680,"I am looking for a tutorial that explains how to transform music into tensors to work with tensorflow, but I have not been able to find material. If someone could give me a little explanation or direct me to a tutorial, I appreciate it.",1,1
38,2018-11-14,2018,11,14,22,9wzxz1,"Sigmoid returning high values, but why? - Support",https://www.reddit.com/r/tensorflow/comments/9wzxz1/sigmoid_returning_high_values_but_why_support/,Jandevries101,1542200894,"Hi Reader,

&amp;#x200B;

so in my (RL) Algorithme i am using the Sigmoid (also tried softmax), but when training i quickly noticed something ""strange"" in my sigmoid returns:

&amp;#x200B;

    0.9995

&amp;#x200B;

for output 1, output 1 having reward of 0, at the end of the episode more, but this action gives by default just 0 reward, whiles other other actions may be more likely to be chosen

&amp;#x200B;

the problem i am having here is that first of all that value is so darn high, i can't even consider it learned that. second issue this occurs after ca 5-10 steps only into the training sessions, with LR of only 0,0001!

&amp;#x200B;

I know you might wanna see code or something, but i'd rather know (also for others in the future) what are causes to this to occur? my state is nothing special just 7 values and i have 3 actions to choose from (the values returned by the sigmoid are very low of course since action 1 is 0.9995).

&amp;#x200B;

i am really confused by what caused this and i do understand that reward higher/lowers the value returned by sigmoid, but this goes from 0.x (random) to 0.9995 in no time, only having a reward of 0, is there something with a reward of zero that i missed out on?

&amp;#x200B;

Let me know what you think and if you know what may caused it, please let me know i am intrested to know what it is?

&amp;#x200B;

thanks for reading,

&amp;#x200B;

Jan

&amp;#x200B;

&amp;#x200B;",6,1
39,2018-11-15,2018,11,15,4,9x39bt,Tensorflow script _impl.InvalidArgumentError:,https://www.reddit.com/r/tensorflow/comments/9x39bt/tensorflow_script_implinvalidargumenterror/,jabbaluck,1542223826,"Hey guys I'm trying a script i found on github. In the past at the same point i had some batch size problems.. i lowered them down. NOW I'm getting this error .. 

 

&amp;#x200B;

python/client/session.py"", line 1312, in \_extend\_graph  
tf\_session.ExtendSession(self.\_session)  
tensorflow.python.framework.errors\_impl.InvalidArgumentError: Cannot assign a device for operation 'save/SaveV2': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.  
Registered kernels:  
device='CPU'

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

I tried to add to the script:  
tf.Session(config=tf.ConfigProto(allow\_soft\_placement=True, log\_device\_placement=True))

But it didn't change really anything .. 

I'm using tensorflow '1.11.0'.

&amp;#x200B;

do you have any clue on how to fix this ?",0,1
40,2018-11-15,2018,11,15,5,9x3u6j,Help. How can I refine this?,https://www.reddit.com/r/tensorflow/comments/9x3u6j/help_how_can_i_refine_this/,chaiboy,1542227625,"I am new to Tensorflow and Neural Networks in general so I am trying to replicate an idea I saw a while back. An AI generated list of monster names.   


What would the proper settings be to work with just a couple of words per line?

&amp;#x200B;

Any tips on what to look into would help. There is a lot of documentation out there and I'm not sure where to start.

&amp;#x200B;

Here is an example of my code:

&amp;#x200B;

gen-monster.py

    from textgenrnn import textgenrnn
    import os
    
    textgen = textgenrnn()
    
    
    textgen.train_from_file(
        'monsters.txt',
        new_model=         True,
        rnn_size=          128,
        rnn_layers=        4,
        
        rnn_bidirectional= False,
        line_delimited=    True,
    
        max_length=        60,
        max_words=         10000,
    
        num_epochs=        50,
        gen_epochs=        10,
        train_size=        0.8
        dim_embeddings=    100,
        word_level=        True,
        single_text=       False,
        validation=        True,
        name='textgenrnn')
    
    

I run the next to print out a list to a file once the previous one has run.

get-monster.py

    from textgenrnn import textgenrnn
    import os
    
    textgen = textgenrnn(weights_path='textgenrnn_weights.hdf5',
                           vocab_path='textgenrnn_vocab.json',
                           config_path='textgenrnn_config.json')
    
    textgen.generate_to_file('newmonsters-list.txt', n=1000)

&amp;#x200B;

&amp;#x200B;

the data is a text file.

monsters.txt

    Death Crone
    Flesh Crone
    Norn
    Primeval Crone
    Gorebull
    Chosen of Baphomet
    Grave Hag
    Great Cockatrice
    Griffin
    Royal Griffin
    Black Root
    Leshen
    Ancient Leshen
    Chort
    Morvudd
    Relic Morvudd
    Crypt Horror
    Drowned Dead
    Drowner
    Foglet
    Ignis Fatuus
    Devourer
    Rotfiend
    Nekker
    Nekker Warrior
    Phoocas
    Thornheart
    Thornheart Spellcaster
    Primal Wolf
    Primal Bear
    Primal Murder of Crows
    Alp
    Bruxa
    Bruxa Night Mother
    Ekimmara
    Fleder
    Garkain
    Katakan
    Nekurat
    Mula
    Ancient Vargheist
    ...
    another 3000 more assorted names

Pretty simple. When I run the training many of the names it comes up with are the same ones from the list. What would I change to have it be more creative?   


&amp;#x200B;",9,1
41,2018-11-15,2018,11,15,11,9x6u8s,convert videos (eg. .avi) to TensorFlow's tfrecords file format,https://www.reddit.com/r/tensorflow/comments/9x6u8s/convert_videos_eg_avi_to_tensorflows_tfrecords/,whiletrue2,1542248457,,0,1
42,2018-11-15,2018,11,15,16,9x957c,Tensor Flow Container Setup with Nvidia GPU Support for Ubuntu 16.04,https://www.reddit.com/r/tensorflow/comments/9x957c/tensor_flow_container_setup_with_nvidia_gpu/,nullbyte91,1542267842,,3,1
43,2018-11-15,2018,11,15,22,9xbbz5,How can i feed multiple 3D Arrays into Tensorflow?,https://www.reddit.com/r/tensorflow/comments/9xbbz5/how_can_i_feed_multiple_3d_arrays_into_tensorflow/,oneuseroranother,1542289865,"I have a training set consisting of multiple directorys with several images inside of them. Each directory represents an label. I am loading the images into 3 dimensional numpy arrays, but what is the best approach to feed these arrays into my neural network? The total size of the dataset is several GB and quite big.",0,1
44,2018-11-16,2018,11,16,4,9xem1r,Tensorflow server to .com,https://www.reddit.com/r/tensorflow/comments/9xem1r/tensorflow_server_to_com/,Throwaway_geology,1542311570,"Hello,

I am looking for help to understand how to deploy a tf DL model to a .com. I read about tf serving and how you can deploy it to production, but I don't understand how to get it on to your own dns. All the how to guides show you how to set the server up but I don't 
know how to get this to a hosting website for my .com. 

Are there any YouTube videos or guides someone could link me to with a step by step to deploy to a website? 

The best kinda guide I found was:

https://www.kubeflow.org/docs/guides/gke/gcp-e2e/

What I also don't understand is when Google says : tensorflow serving to production! Production to a local app or production to online dns? 

I want to use my model on my .com website as a business. Not interested in local apps. Old people and computer illiterate people won't understand how to use local apps, but I believe they'll understand how to navigate to a simple .com website to use my predictive model for their benefit. This is my intention. Please help me understand!! Thanks! ",0,1
45,2018-11-16,2018,11,16,6,9xfrgc,How do I remove the training-related nodes from a graph?,https://www.reddit.com/r/tensorflow/comments/9xfrgc/how_do_i_remove_the_trainingrelated_nodes_from_a/,rumborak,1542319137,"I have a model trained that I'm trying to convert to TFlite format. However, two training-related operations (\*QueueDequeueUpToV2\* and \*RandomShuffleQueueV2\*) show up as unsupported operations, and even when I allow the conversion to continue with \*tflite\_convert\*'s ""--allow-custom-ops"" flag, it eventually fails when loading it in TFLite with the same issue (i.e. unsupported operations).

&amp;#x200B;

The weird part is, as I realized I would need a way of actually pushing my data in, I used the Identity operation to mark the model's data input node as ""model\_input\_raw"". That node label I then use in \*tflite\_convert\*  to denote the input. Meaning, the actual training operations should be no-ops and automatically pruned away anyway, but clearly they are not!

&amp;#x200B;

I have tried using transform\_graph on the graph, by using the transformation ""\*remove\_nodes(op=QueueDequeueUpToV2, op=RandomShuffleQueueV2)\*"", but that does not result in any modification of the graph at all.

&amp;#x200B;

Does anybody have any ideas/suggestions?",0,1
46,2018-11-16,2018,11,16,22,9xm4mt,Tensorflow implementation of recurrent batch normalization (any bugs???),https://www.reddit.com/r/tensorflow/comments/9xm4mt/tensorflow_implementation_of_recurrent_batch/,aziz_22,1542374680,"Following my previous post in r/MachineLearning. 

I would like to get some feed-back about my implementation of the [recurrent-batch normalization](https://arxiv.org/pdf/1603.09025.pdf).

Here is my code 

&amp;#x200B;

https://i.redd.it/i1uobvw62py11.png

and here the batch\_norm function 

&amp;#x200B;

&amp;#x200B;

https://i.redd.it/dblt8vy82py11.png

Any help will be very appreciated :)",0,1
47,2018-11-17,2018,11,17,14,9xtykw,I need help with running two graphs sequentially.,https://www.reddit.com/r/tensorflow/comments/9xtykw/i_need_help_with_running_two_graphs_sequentially/,downvotedbylife,1542433128,"I'll start by saying I'm a beginner (MATLAB migrant), so this might be obvious but has had me frustrated for a couple of nights now.  

I have a previously trained and saved model [NN1]. I want to refine its functionality by training a second network [NN2], directly connected to [NN1]'s output. [NN2] will be trained with the same target samples used to train [NN1], and the training input samples would be the same ones used for [NN1], but processed through it.  
What is the correct way to go about this within TF? My first instinct was running them in separate sessions (one containing each graph), in order to use [NN1] solely as an operator of sorts for input training data inside the training loop for [NN2], but I'm not sure if this is the best approach. Are there any TF-specific advantages I can take to make this more straightforward?",3,1
48,2018-11-17,2018,11,17,15,9xucw7,Building Footprint Extraction using Deep learning.,https://www.reddit.com/r/tensorflow/comments/9xucw7/building_footprint_extraction_using_deep_learning/,girishpillai17,1542437392,"How can you extract the footprints of the building rooftops from an satellite image using computer vision, machine learning and deep learning. My aim is to just extract the buildings rooftops from the image. What should be the approach for this and what all technologies should be used to achieve the output which is shown in the image?",2,1
49,2018-11-17,2018,11,17,16,9xuj1o,Using a AMD GPU for TensorFlow - R9 285 on Fedora 29?,https://www.reddit.com/r/tensorflow/comments/9xuj1o/using_a_amd_gpu_for_tensorflow_r9_285_on_fedora_29/,Im_BrokeForever,1542439333,"Hi! I'm wondering if my AMD GPU is compatible with Tensorflow. I believe that there is support of AMD gpus according to the [ROCM project](https://rocm.github.io/install.html#supported-gpus). However, the instructions to install tensorflow seem to be only supported natively on Ubuntu, and RHEL and Centos with some extra dependencies and a ""special run-time environment"". It is possible that I could use Tensorflow with the GPU on Fedora? Thanks. 

(I do realize there's an option to include Tensorflow in a docker container, but I would prefer having it installed directly onto my host computer.) ",7,1
50,2018-11-17,2018,11,17,23,9xwkv9,ubuntu18.04 + python 3.6.5 + cuda 9.0 + tensorflow 1.12.0 install problem,https://www.reddit.com/r/tensorflow/comments/9xwkv9/ubuntu1804_python_365_cuda_90_tensorflow_1120/,pg13mvp,1542463314,"I have tried several methods setting up the environment  ( from youtube github  )

but i still can't install successfully 

&amp;#x200B;

is there any guide recommend for me?

( don't change the version of cuda 9.0 tensorflow 1.12.0 python 3.6.5",9,1
51,2018-11-18,2018,11,18,5,9xzih8,Beginner python tensorflow ml,https://www.reddit.com/r/tensorflow/comments/9xzih8/beginner_python_tensorflow_ml/,Zi6st,1542485205,"So i want to learn tensor flow ,but i dont have any python or ml knowledge.I do however know c++  but that doesnt help much.Any tips for how should i start this journey? ",3,1
52,2018-11-18,2018,11,18,10,9y21kz,How can I tell if my tensorflow is training my model?,https://www.reddit.com/r/tensorflow/comments/9y21kz/how_can_i_tell_if_my_tensorflow_is_training_my/,pocketMAD,1542504835,"I'm trying to train my object detector using model_main.py. Everything is working and there are no errors. However, when I activate tensor board, I only have access to the tensorflow graph structure. I have no access to the graphs of the mAP and loss. Is this bad? ",3,1
53,2018-11-18,2018,11,18,11,9y2fmi,"When I'm training from a MobileNet for object detection, tensor board doesn't show scalars when I train using model_main.py. This tells me it likely isn't training the network. What should I do?",https://www.reddit.com/r/tensorflow/comments/9y2fmi/when_im_training_from_a_mobilenet_for_object/,pocketMAD,1542508331,,0,1
54,2018-11-18,2018,11,18,15,9y414s,Is Tensorflow machine learning cookbook too old?,https://www.reddit.com/r/tensorflow/comments/9y414s/is_tensorflow_machine_learning_cookbook_too_old/,pg13mvp,1542524115,"I recently got the book, but when I run the sample code, I found that some function like sub() is already change into subtract().

So I'm wondering is it still ok to learn from this book or should i get another one?

If so, any other recommendations?
(I prefer book instead of video",12,1
55,2018-11-19,2018,11,19,12,9ycz07,with tf.device('/cpu:0'): identation problem?,https://www.reddit.com/r/tensorflow/comments/9ycz07/with_tfdevicecpu0_identation_problem/,pg13mvp,1542598385,"I type "" with tf.device('/cpu:0'): ""

in the front of my code 

and right tab all the codes below

&amp;#x200B;

but when i execute it shows an error massage 

"" TabError: inconsistent use of tabs and spaces in indentation ""

&amp;#x200B;

and I have no idea what's going on 

&amp;#x200B;

thanks for help!",2,1
56,2018-11-20,2018,11,20,0,9yhhv7,Facial landmark detection - in dire need of some guidance,https://www.reddit.com/r/tensorflow/comments/9yhhv7/facial_landmark_detection_in_dire_need_of_some/,ned334,1542639713,"Hi, I am just starting out with TensorFlow, but I have some prior experience with training networks for classification.  Also some theoretical background.

I have a project where I am supposed to train a resnet18 for facial landmark prediction. I understand the concept, I think: I must feed the network both images and coordinates of the eyes, as GT. The model will hopefully predict where the eyes are at on new images. 

Now, as to the implementation, I have looked at some TF source code, training resnet18 for detection and it's simple enough. Feeding the GT images + labels but I don't know how to input the images and coordinates. I don't know strictly code-wise. I looked over the first few pages of google in search of an example of resnet or any network trained like that but found none. 

I also tried to understand how to do this from the TF documentation but again, I found nothing useful for my case. 

I'm not saying there is not the info I need out there, just that I couldn't find it. 

Could you please help with some instructions of what I should read to understand what I have to do? 

I wouldn't mind raw code either but I'll take whatever I can get. 

Thanks!",0,1
57,2018-11-20,2018,11,20,3,9yjbry,How can I read a graph definition for a tensorflow model?,https://www.reddit.com/r/tensorflow/comments/9yjbry/how_can_i_read_a_graph_definition_for_a/,_D_Money_,1542651484,"I'm currently taking the [Udacity Deep Learning](https://www.udacity.com/course/deep-learning--ud730) course, and they have a graph definition of a convolutional neural net (see below). I'd be curious to read a graph definition of a larger CNN, for example MobileNet, in order to help understand how the code works. Is it possible to somehow read a .pb file or some other file and see the python graph definition of MobileNet or Inception or something? Or is there a python graph definition available of these networks that I can read?

Here is the example CNN from the Udacity course, I'm wondering if I can read a similar graph definition but for MobileNet:

    batch_size = 16
    patch_size = 5
    depth = 16
    num_hidden = 64

    graph = tf.Graph()

    with graph.as_default():

        # Input data.
        tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, num_channels))
        tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))
        tf_valid_dataset = tf.constant(valid_dataset)
        tf_test_dataset = tf.constant(test_dataset)
        
        # Variables.
        layer1_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, num_channels, depth], stddev=0.1))
        layer1_biases = tf.Variable(tf.zeros([depth]))
        layer2_weights = tf.Variable(tf.truncated_normal([patch_size, patch_size, depth, depth], stddev=0.1))
        layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))
        layer3_weights = tf.Variable(tf.truncated_normal([image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))
        layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))
        layer4_weights = tf.Variable(tf.truncated_normal([num_hidden, num_labels], stddev=0.1))
        layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))
        
        # Model.
        def model(data):
            conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')
            hidden = tf.nn.relu(conv + layer1_biases)
            conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')
            hidden = tf.nn.relu(conv + layer2_biases)
            shape = hidden.get_shape().as_list()
            reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])
            hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)
            return tf.matmul(hidden, layer4_weights) + layer4_biases
        
        # Training computation.
        logits = model(tf_train_dataset)
        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))
            
        # Optimizer.
        optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)
        
        # Predictions for the training, validation, and test data.
        train_prediction = tf.nn.softmax(logits)
        valid_prediction = tf.nn.softmax(model(tf_valid_dataset))
        test_prediction = tf.nn.softmax(model(tf_test_dataset))",0,1
58,2018-11-20,2018,11,20,4,9yk29f,Run TensorFlow Convolutional Neural Network (TF CNN) benchmarks in CPU,https://www.reddit.com/r/tensorflow/comments/9yk29f/run_tensorflow_convolutional_neural_network_tf/,raindrop_code,1542655984,,1,1
59,2018-11-20,2018,11,20,6,9ykzt7,4 Reasons to Distribute TensorFlow Processing Among Everyday Objects - DZone AI,https://www.reddit.com/r/tensorflow/comments/9ykzt7/4_reasons_to_distribute_tensorflow_processing/,cloudster314,1542661793,,2,1
60,2018-11-20,2018,11,20,11,9yniyt,Difference between model_main.py and train.py in Object Detection API?,https://www.reddit.com/r/tensorflow/comments/9yniyt/difference_between_model_mainpy_and_trainpy_in/,pocketMAD,1542679284,,0,1
61,2018-11-20,2018,11,20,17,9yqfh9,Are there any plans for a statistical programming book using tensorflow_probability?,https://www.reddit.com/r/tensorflow/comments/9yqfh9/are_there_any_plans_for_a_statistical_programming/,o-rka,1542703852,"I really want to brush up on my statistics and would love to learn the concepts again using tfp as my medium.  

",2,1
62,2018-11-20,2018,11,20,20,9yrbji,Same (?) model converges in Keras but not in Tensorflow,https://www.reddit.com/r/tensorflow/comments/9yrbji/same_model_converges_in_keras_but_not_in/,zedt,1542712994,,0,1
63,2018-11-21,2018,11,21,14,9z045p,[D] Debate on TensorFlow 2.0 API,https://www.reddit.com/r/tensorflow/comments/9z045p/d_debate_on_tensorflow_20_api/,skj8,1542776640,,0,1
64,2018-11-22,2018,11,22,4,9z6l23,Python 3.7 was released almost half a year ago and still no support...?,https://www.reddit.com/r/tensorflow/comments/9z6l23/python_37_was_released_almost_half_a_year_ago_and/,ArgonTorr,1542829513,"Tracking my python versioning is starting to become a real pain and is really interfering with my setup. Is there like not going to ever be a plan to upgrade Tensorflow to be compatible with the most recent python? IIRC the problem is that `async` is now a python standard keyword, but what's the endgame here?

&amp;#x200B;",11,1
65,2018-11-22,2018,11,22,10,9z99v5,"GPU usage is significantly higher with Session (as opposed to Model/Keras), but not faster.",https://www.reddit.com/r/tensorflow/comments/9z99v5/gpu_usage_is_significantly_higher_with_session_as/,ptrkhh,1542848467,"As the title says, I am still learning TF, and found out there seem to be two ways to create a model and train, the Keras-style and the session-style. I dont know what the real name is but anyway, here's the Keras-style

`
model = tf.keras.Sequential()
model.add(tf.keras.layers.Flatten(input_shape=(x_length,)))
for node in nodes:
     tf.keras.layers.Dense(node, activation=tf.nn.relu)
model.add(tf.keras.layers.Dense(index_length))

loss = 'mse'
metrics = ['mae']

t0 = time.time()

history = model.fit(train_x, train_y, epochs=epochs, validation_data=(validation_x, validation_y), batch_size=batch_size)

t1 = time.time()
print('Total Time:' + str(t1-t0))

`


And here's the TF one

`

batch_size = tf.placeholder(tf.int64)
x, y = tf.placeholder(tf.float32, shape=[None, x_length]), tf.placeholder(tf.float32, shape=[None, index_length])
dataset = tf.data.Dataset.from_tensor_slices((x, y)).batch(batch_size).repeat()

iter = dataset.make_initializable_iterator()
features, labels = iter.get_next()
 
net = tf.layers.dense(features, 2000, activation=tf.nn.relu)  # pass the first value from iter.get_next() as input
net = tf.layers.dense(net, 500, activation=tf.nn.relu)
net = tf.layers.dense(net, 100, activation=tf.nn.relu)
net = tf.layers.dense(net, 50, activation=tf.nn.relu)
prediction = tf.layers.dense(net, 1, activation=tf.nn.sigmoid)
loss = tf.losses.mean_squared_error(prediction, labels)  # pass the second value from iter.get_net() as label
train_op = tf.train.AdamOptimizer(learning_rate=learning_rates[0]).minimize(loss)

t0 = time.time()

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    sess.run(iter.initializer, feed_dict={x: train_x, y: train_y, batch_size: 100})
    for i in range(epochs):
        tot_loss = 0
        _, loss_value = sess.run([train_op, loss])
        sess.run(iter.initializer, feed_dict={x: validation_x, y: validation_y, batch_size: validation_x.shape[0]})

t1 = time.time()
print('Total Time:' + str(t1-t0))

`

The printout seems to be about the same, probably even faster on the Keras one, and **yet** when I monitor the GPU usage (GTX 1070), the Keras one has around 10% use, while the TF one has around 60%.


TF shows that it uses the GPU on both trainings, so its not CPU training either, I assume.
",6,1
66,2018-11-22,2018,11,22,13,9zaoje,Has anyone come across a t-SNE implementation in Tensorflow/Tensorflow Probability?,https://www.reddit.com/r/tensorflow/comments/9zaoje/has_anyone_come_across_a_tsne_implementation_in/,o-rka,1542860119,I'm still using the [sklearn version](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) and it takes a long time to run for larger datasets.  I came across a [multicore version](https://github.com/DmitryUlyanov/Multicore-TSNE) but I have trouble with dependencies sometimes.  I feel like this could be a good candidate for `TFP`. ,3,1
67,2018-11-22,2018,11,22,13,9zarzw,"Are you interested in Tensorflow and want to start learning more with Tutorials? Check out this new Youtube Channel, called Discover Artificial Intelligence. :)",https://www.reddit.com/r/tensorflow/comments/9zarzw/are_you_interested_in_tensorflow_and_want_to/,ailearn12,1542860967,,0,1
68,2018-11-22,2018,11,22,14,9zb04e,TF 2.0 preview,https://www.reddit.com/r/tensorflow/comments/9zb04e/tf_20_preview/,_spicyramen,1542862930,Is there a way to activate TF 2.0 behavior in nightly or latest release? ,0,1
69,2018-11-22,2018,11,22,14,9zbae9,Creative Applications of Deep Learning with TensorFlow,https://www.reddit.com/r/tensorflow/comments/9zbae9/creative_applications_of_deep_learning_with/,skj8,1542865344,,0,1
70,2018-11-22,2018,11,22,17,9zc7yt,Free eBook today: Building Machine Learning Projects with TensorFlow [PDF],https://www.reddit.com/r/tensorflow/comments/9zc7yt/free_ebook_today_building_machine_learning/,PacktStaff,1542874187,,0,1
71,2018-11-22,2018,11,22,20,9zdi3j,"Converting Tensorflow Graph to use Tensorflow Estimator, getting 'TypeError: data type not understood', at loss function",https://www.reddit.com/r/tensorflow/comments/9zdi3j/converting_tensorflow_graph_to_use_tensorflow/,AdditionalWay,1542887721,"I am trying to convert a working Tensorflow graph to use Tensorflow Estimator, using a custom Estimator. My model works when I was just using a model and then running it with a session. But when I try to use it with the Estimator API, it's not working. 

This is where I defined my model

    def my_model( features, labels, mode, params):
    
        train_dataset = features
        train_labels = labels
    
        batch_sizeE=params[""batch_size""]
        embedding_sizeE=params[""embedding_size""]
        num_inputsE=params[""num_inputs""]
        num_sampledE=params[""num_sampled""]
        
        print(features)
        print(labels)
    
        epochCount = tf.get_variable( 'epochCount', initializer= 0) #to store epoch count to total # of epochs are known
        update_epoch = tf.assign(epochCount, epochCount + 1)
    
        embeddings = tf.get_variable( 'embeddings', dtype=tf.float32,
            initializer= tf.random_uniform([vocabulary_size, embedding_sizeE], -1.0, 1.0, dtype=tf.float32) )
    
        softmax_weights = tf.get_variable( 'softmax_weights', dtype=tf.float32,
            initializer= tf.truncated_normal([vocabulary_size, embedding_sizeE],
                                 stddev=1.0 / math.sqrt(embedding_sizeE), dtype=tf.float32 ) )
    
        softmax_biases = tf.get_variable('softmax_biases', dtype=tf.float32,
            initializer= tf.zeros([vocabulary_size], dtype=tf.float32),  trainable=False )
    
        embed = tf.nn.embedding_lookup(embeddings, train_dataset) #train data set is
    
        embed_reshaped = tf.reshape( embed, [batch_sizeE*num_inputs, embedding_sizeE] )
    
        segments= np.arange(batch_size).repeat(num_inputs)
    
        averaged_embeds = tf.segment_mean(embed_reshaped, segments, name=None)
    
        if mode == ""train"":
        
            sSML = tf.nn.sampled_softmax_loss(weights=softmax_weights, biases=softmax_biases, inputs=averaged_embeds,
                labels=train_labels, num_sampled=64, num_classes=3096637)
    
            loss = tf.reduce_mean( sSML )
    
            optimizer = tf.train.AdagradOptimizer(1.0).minimize(loss) 
    
        saver = tf.train.Saver()

This is where I call the training

    #Define the estimator
    word2vecEstimator = tf.estimator.Estimator(
            model_fn=my_model,
            params={
                'batch_size': 16,
                'embedding_size': 10,
                'num_inputs': 3,
                'num_sampled': 128
            })
    
    word2vecEstimator.train(
        input_fn=generate_batch,
        steps=10)

And this is the error I get

    INFO:tensorflow:Calling model_fn.
    
    &lt;tf.Variable 'softmax_weights:0' shape=(3096637, 50) dtype=float32_ref&gt;
    &lt;tf.Variable 'softmax_biases:0' shape=(3096637,) dtype=float32_ref&gt;
    ---------------------------------------------------------------------------
    TypeError                                 Traceback (most recent call last)
    &lt;ipython-input-49-955f44867ee5&gt; in &lt;module&gt;()
          1 word2vecEstimator.train(
          2     input_fn=generate_batch,
    ----&gt; 3     steps=10)
    
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)
        352 
        353       saving_listeners = _check_listeners_type(saving_listeners)
    --&gt; 354       loss = self._train_model(input_fn, hooks, saving_listeners)
        355       logging.info('Loss for final step: %s.', loss)
        356       return self
    
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)
       1205       return self._train_model_distributed(input_fn, hooks, saving_listeners)
       1206     else:
    -&gt; 1207       return self._train_model_default(input_fn, hooks, saving_listeners)
       1208 
       1209   def _train_model_default(self, input_fn, hooks, saving_listeners):
    
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)
       1235       worker_hooks.extend(input_hooks)
       1236       estimator_spec = self._call_model_fn(
    -&gt; 1237           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
       1238       global_step_tensor = training_util.get_global_step(g)
       1239       return self._train_with_estimator_spec(estimator_spec, worker_hooks,
    
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _call_model_fn(self, features, labels, mode, config)
       1193 
       1194     logging.info('Calling model_fn.')
    -&gt; 1195     model_fn_results = self._model_fn(features=features, **kwargs)
       1196     logging.info('Done calling model_fn.')
       1197 
    
    &lt;ipython-input-47-95d390a50046&gt; in my_model(features, labels, mode, params)
         47 
         48         sSML = tf.nn.sampled_softmax_loss(weights=softmax_weights, biases=softmax_biases, inputs=averaged_embeds,
    ---&gt; 49             labels=train_labels, num_sampled=64, num_classes=3096637)
         50 
         51         loss = tf.reduce_mean( sSML )
    
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py in sampled_softmax_loss(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, remove_accidental_hits, partition_strategy, name, seed)
       1347       partition_strategy=partition_strategy,
       1348       name=name,
    -&gt; 1349       seed=seed)
       1350   labels = array_ops.stop_gradient(labels, name=""labels_stop_gradient"")
       1351   sampled_losses = nn_ops.softmax_cross_entropy_with_logits_v2(
    
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py in _compute_sampled_logits(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, subtract_log_q, remove_accidental_hits, partition_strategy, name, seed)
       1029   with ops.name_scope(name, ""compute_sampled_logits"",
       1030                       weights + [biases, inputs, labels]):
    -&gt; 1031     if labels.dtype != dtypes.int64:
       1032       labels = math_ops.cast(labels, dtypes.int64)
       1033     labels_flat = array_ops.reshape(labels, [-1])
    
    TypeError: data type not understood

Here is a link to the Google Colab notebook for people to run on their own. For anyone looking to execute this, this will download a data file that is ~500 mbs.

https://colab.research.google.com/drive/1LjIz04xhRi5Fsw_Q3IzoG_5KkkXI3WFE

And here is the full code, from the notebook.

    import math
    import numpy as np
    import random
    import zipfile
    import shutil
    from collections import namedtuple
    
    import os
    import pprint
    
    import tensorflow as tf
    
    import pandas as pd
    import pickle
    from numpy import genfromtxt
    
    !pip install -U -q PyDrive
    
    from google.colab import files
    from pydrive.auth import GoogleAuth
    from pydrive.drive import GoogleDrive
    from google.colab import auth
    from oauth2client.client import GoogleCredentials
    
    auth.authenticate_user()
    gauth = GoogleAuth()
    gauth.credentials = GoogleCredentials.get_application_default()
    drive = GoogleDrive(gauth)
    
    vocabulary_size = 3096637 #updated 10-25-18 3096636
    
    import gc



    dl_id = '19yha9Scxq4zOdfPcw5s6L2lkYQWenApC' #updated 10-22-18
    
    myDownload = drive.CreateFile({'id': dl_id})
    myDownload.GetContentFile('Data.npy')
    my_data = np.load('Data.npy')
    #os.remove('Data.npy')
    np.random.shuffle(my_data)
    print(my_data[0:15])
    
    data_index = 0 
    epoch_index = 0 
    recEpoch_indexA = 0 #Used to help keep store of the total number of epoches with the models
    
    def generate_batch(): 
        global data_index, epoch_index
    
        features = np.ndarray(shape=(batch_size, num_inputs), dtype=np.int32) 
        labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)
    
        n=0
        while n &lt; batch_size:
          if len(    set(my_data[data_index, 1])   ) &gt;= num_inputs:
            labels[n,0] = my_data[data_index, 0]
            features[n] = random.sample( set(my_data[data_index, 1]),  num_inputs)
            n = n+1
            data_index = (data_index + 1) % len(my_data) #may have to do something like len my_data[:]
            if data_index == 0:
              epoch_index = epoch_index + 1
              print('Completed %d Epochs' % epoch_index)
          else:
            data_index = (data_index + 1) % len(my_data)
            if data_index == 0:
              epoch_index = epoch_index + 1
              print('Completed %d Epochs' % epoch_index)
    
        return features, labels     



    def my_model( features, labels, mode, params):
    
        train_dataset = features
        train_labels = labels
    
        batch_sizeE=params[""batch_size""]
        embedding_sizeE=params[""embedding_size""]
        num_inputsE=params[""num_inputs""]
        num_sampledE=params[""num_sampled""]
        
        print(features)
        print(labels)
    
        epochCount = tf.get_variable( 'epochCount', initializer= 0) #to store epoch count to total # of epochs are known
        update_epoch = tf.assign(epochCount, epochCount + 1)
    
        embeddings = tf.get_variable( 'embeddings', dtype=tf.float32,
            initializer= tf.random_uniform([vocabulary_size, embedding_sizeE], -1.0, 1.0, dtype=tf.float32) )
    
        softmax_weights = tf.get_variable( 'softmax_weights', dtype=tf.float32,
            initializer= tf.truncated_normal([vocabulary_size, embedding_sizeE],
                                 stddev=1.0 / math.sqrt(embedding_sizeE), dtype=tf.float32 ) )
    
        softmax_biases = tf.get_variable('softmax_biases', dtype=tf.float32,
            initializer= tf.zeros([vocabulary_size], dtype=tf.float32),  trainable=False )
    
        embed = tf.nn.embedding_lookup(embeddings, train_dataset) #train data set is
    
        embed_reshaped = tf.reshape( embed, [batch_sizeE*num_inputs, embedding_sizeE] )
    
        segments= np.arange(batch_size).repeat(num_inputs)
    
        averaged_embeds = tf.segment_mean(embed_reshaped, segments, name=None)
    
        print(softmax_weights )
        print(softmax_biases )
        
        if mode == ""train"":
        
            sSML = tf.nn.sampled_softmax_loss(weights=softmax_weights, biases=softmax_biases, inputs=averaged_embeds,
                labels=train_labels, num_sampled=64, num_classes=3096637)
    
            loss = tf.reduce_mean( sSML )
    
            optimizer = tf.train.AdagradOptimizer(1.0).minimize(loss) 
    
        saver = tf.train.Saver()



    word2vecEstimator = tf.estimator.Estimator(
            model_fn=my_model,
            params={
                'batch_size': 16,
                'embedding_size': 10,
                'num_inputs': 3,
                'num_sampled': 128
            })
    
    word2vecEstimator.train(
        input_fn=generate_batch,
        steps=10)",0,1
72,2018-11-22,2018,11,22,22,9zdzgo,Help with GPU-ResourceExhaustedError,https://www.reddit.com/r/tensorflow/comments/9zdzgo/help_with_gpuresourceexhaustederror/,FrStealer,1542892298,"Hello,

I have got a memory error while training on inception_resnet_v2.
Implementation : https://github.com/davidsandberg/facenet/blob/master/src/models/inception_resnet_v2.py.

I can test in pretty well, I can calculate the loss, the embedding so I assume the error is in the gradiant calculation.  As soon as I want to train I've got a memory error:

""Limit:                 11502629683
InUse:                 11487078144
MaxInUse:              11487078144
NumAllocs:                   46485
MaxAllocSize:           4294967296""

The training code is here : https://github.com/davidsandberg/facenet/blob/master/src/facenet.py  line 168

I have got Tensorflow 1.10.1, Cuda: 7.5.17 with the graphic TITAN X (Pascal) On Ubuntu16.

I've tried different things i saw in other forum, but nothing works so far.
Thank you in advance.",6,1
73,2018-11-22,2018,11,22,23,9zed1o,A single RTX 2070 or Multiple 1070 ti ?,https://www.reddit.com/r/tensorflow/comments/9zed1o/a_single_rtx_2070_or_multiple_1070_ti/,crytoy,1542895548,"In a tensorflow workspace, would you recommend a single RTX 2070 or 2 (1070 ti) cards ?",11,1
74,2018-11-23,2018,11,23,1,9zfghe,What is the difference between Model.train_on_batch from keras and Session.run([train_optimizer]) from tensorflow?,https://www.reddit.com/r/tensorflow/comments/9zfghe/what_is_the_difference_between_modeltrain_on/,zedt,1542903763,,0,1
75,2018-11-23,2018,11,23,18,9zmteu,Huawei Matebook X Pro - Tensorflow Support and eGPU Tensorflow Support?,https://www.reddit.com/r/tensorflow/comments/9zmteu/huawei_matebook_x_pro_tensorflow_support_and_egpu/,ladiesman217-ab,1542964398,"Hey guys, is there anyone out there who has a Huawei Matebook X Pro and has installed Tensorflow on it? I'm really considering on buying the laptop but I haven't seen any posts on anyone using this laptop for machine learning applications.

I'm a university student, and I'd like to have a single portable laptop I can use on the go. The computer has the GeForce MX150, and because of this GPU there have apparently been some issues with installing CUDA 9 (which is a requirement to install Tensorflow), and it seems that the solution is to generally install CUDA 9.1 and build Tensorflow from source. ([https://devtalk.nvidia.com/default/topic/1023574/announcements/cuda-toolkit-9-is-not-available-in-geforce-mx150/](https://devtalk.nvidia.com/default/topic/1023574/announcements/cuda-toolkit-9-is-not-available-in-geforce-mx150/))

I understand the Matebook X Pro doesn't have the best GPU for machine learning, but ideally back at the dorm, I would have an eGPU and hook it up to the Matebook X Pro since it has Thunderbolt 3 to do the more hardcore machine learning. On the go though, I could run basic machine learning programs on the MX150. Also, the laptop is renowned for it's amazing specs better than a Macbook Pro and costs less than a Macbook Pro, so it's an ideal ""on the go"" laptop for other general purpose work.

So I guess to enumerate my questions:

1. Have you installed CUDA on your Huawei Matebook X Pro? If so, what version?
2. Were you able to successfully install Tensorflow?
3. Do you think it's possible to designate ML tasks on the MX150 or the eGPU (would this be as easy as a call to cudaSetDevice)? This would be helpful since on the go, I'd be running ML code on the MX150 while in my dorm I'd be running ML code exclusively on the eGPU like I mentioned before.
4. Would I have to have a separate CUDA installation for the eGPU, and if I do, would that interfere with the CUDA installation for the MX150?
5. Have you run into any problems doing any of the above, or do you have any tips/advice for what I should consider?

I don't really want to gamble on spending more than a thousand bucks to see whether or not this setup could potentially work, so I wanted to know if anyone else has done this before.

Also for some additional details, the Huawei Matebook X Pro will be running on Windows 10, and let's say the eGPU is a high-end model like the 1080 Ti.

Thanks!",1,1
76,2018-11-24,2018,11,24,8,9zt97k,FIRST style transfer,https://www.reddit.com/r/tensorflow/comments/9zt97k/first_style_transfer/,jabbaluck,1543015670,"Hey guys i just did one of my style transfers !!!

&amp;#x200B;

What do you think ??&gt;:d&lt; +

&amp;#x200B;

&amp;#x200B;

[https://www.facebook.com/photo.php?fbid=2087571774597327&amp;set=a.162418863779304&amp;type=3&amp;theater](https://www.facebook.com/photo.php?fbid=2087571774597327&amp;set=a.162418863779304&amp;type=3&amp;theater)",1,1
77,2018-11-24,2018,11,24,10,9zu0qz,Creating TFRecords from dataset with multiple annotated classes per image.,https://www.reddit.com/r/tensorflow/comments/9zu0qz/creating_tfrecords_from_dataset_with_multiple/,acidafterglow,1543021725,"I've been using a modified script from the pets example to deal with my dataset, but that was using a single class per image (and for the whole dataset too, lol).

&amp;#x200B;

Now I have bounding boxes for vehicles, tires, license plates, etc. all in a single image/annotation, but I don't know how to proceed for creating the TFRecord files since, AFAIK, it only works for a single class per image.  


Is this even the right approach to take? Either way, I'd be grateful if someone could point me out to the right resources to solve my problem.  


I'm very new (3-4\~ months) to this since it was basically slapped to my face at my job. So please let me know if any other info is needed to provide a helpful reply.",1,1
78,2018-11-25,2018,11,25,22,a08nab,Why tf.data is much better than feed_dict and how to build a simple data pipeline in 5 minutes.,https://www.reddit.com/r/tensorflow/comments/a08nab/why_tfdata_is_much_better_than_feed_dict_and_how/,dominik_schmidt,1543154125,,10,1
79,2018-11-26,2018,11,26,3,a0b1hs,"For anyone looking to get into deep learning, I would advise that you consider not learning the behemoth libraries like Tensorflow or Theano, but instead learn how to use a high-level API like Keras. Here's a quick video to explain what it is. Hope I was helpful!",https://www.reddit.com/r/tensorflow/comments/a0b1hs/for_anyone_looking_to_get_into_deep_learning_i/,antaloaalonso,1543171371,,3,1
80,2018-11-26,2018,11,26,12,a0fjbm,tf metric accuracy is zero,https://www.reddit.com/r/tensorflow/comments/a0fjbm/tf_metric_accuracy_is_zero/,hassanzadeh,1543202478,"Hello guys,

I have an acc and acc\_update\_op which I initialize with the output of tf.metric.accuracy()

when I initialize the local variables and run it, i.e. acc\_np, acc\_op\_np = [session.run](https://session.run)(\[acc,acc\_update\_op\]) I get 0 for the acc\_np. I'm confused, acc\_np was supposed to a tensor that is equal to count/total, in the computational graph, why is zero then?

of course if I run [session.run](https://session.run)(acc) for the second time I get the right accuracy, but don't I get it in the first run? After all this the main idea behind the computational graph (i.e. operations are done in proper order), is it not? what am i missing?",1,1
81,2018-11-28,2018,11,28,18,a14tsi,Free PDF eBook: TensorFlow Machine Learning Cookbook,https://www.reddit.com/r/tensorflow/comments/a14tsi/free_pdf_ebook_tensorflow_machine_learning/,PacktStaff,1543398708,,1,1
82,2018-11-29,2018,11,29,4,a198ih,TensorFlow Object Detection API in 5 clicks from Colaboratory,https://www.reddit.com/r/tensorflow/comments/a198ih/tensorflow_object_detection_api_in_5_clicks_from/,nbortolotti,1543431885,interesting approach to represent object-detection model using some clicks. [Colab-Proposal](https://medium.com/@nickbortolotti/tensorflow-object-detection-api-in-5-clicks-from-colaboratory-843b19a1edf1). ,0,1
83,2018-11-29,2018,11,29,10,a1cksr,VideoCapture of IP Camera RTSP with Digest Authentication,https://www.reddit.com/r/tensorflow/comments/a1cksr/videocapture_of_ip_camera_rtsp_with_digest/,stateofidleness,1543454306,"Hi all! New to Tensorflow and wanting to do some object detection. I have a very small working example in Python 3 with opencv, keras, and tensorflow. Ive been successful with a still image file, and also using VideoCapture(0) with local USB webcam. 

Now I simply wanted to substitute the 0 for the RTSP url to an IP camera on the LAN, but it gives me a 401 Unauthorized error. I HAVE tested inclusion of the credentials in the URL, but same error.

What is confusing, is the same exact url streams perfectly in VLC.

Ive yet to find a working example online of someone doing this with an IP camera behind digest authentication.

Additional notes:
Bosch camera
Disabling authentication is not an option
Login works fine through VLC

Has anyone managed to use the VideoCapture function with an RTSP stream using digest auth?",3,1
84,2018-11-29,2018,11,29,11,a1dah5,Pluto Open Project: author name disambiguation,https://www.reddit.com/r/tensorflow/comments/a1dah5/pluto_open_project_author_name_disambiguation/,yo__on,1543459732,"Hello reddit/tensorflow,  
[Pluto network](https://pluto.network) is a team working to break down the academic barriers, and we are offering [Scinapse](https://scinapse.io), academic search engine service.

We are putting a lot of efforts on cleansing the large database of academic records usually referred to as citation graph. Currently, the focus is on disambiguating authors using machine learning. 

We plan to OPEN this project and make anyone can participate in the project.   
If you are interested, please feel free to contact us!   
For more detail, please check the link!  
[https://medium.com/pluto-network/pluto-open-project-author-name-disambiguation-4ce956471efb](https://medium.com/pluto-network/pluto-open-project-author-name-disambiguation-4ce956471efb)",0,1
85,2018-11-29,2018,11,29,17,a1fobc,DropoutWrapper Question,https://www.reddit.com/r/tensorflow/comments/a1fobc/dropoutwrapper_question/,thisisiron,1543481397,"Could you explain about input\_keep\_prob and output\_keep\_prob?

&amp;#x200B;

You can give a brief explanation and you can add a link to your comment.",0,1
86,2018-11-29,2018,11,29,19,a1gcp8,Caveat Emptor: Broken TensorFlow &amp; Keras Integration (both Eager and Graph),https://www.reddit.com/r/tensorflow/comments/a1gcp8/caveat_emptor_broken_tensorflow_keras_integration/,Mr_Ubik,1543488902,"While all examples from the TensorFlow team have been moved to the new Keras + TF 2.0 API, and by watching/reading promotional material you might be getting the idea that you can start using these API today, well you are mistaken. We are currently trying to shed light on the following issues:

[https://github.com/tensorflow/tensorflow/issues/23873](https://github.com/tensorflow/tensorflow/issues/23873)

[https://github.com/tensorflow/tensorflow/issues/23875](https://github.com/tensorflow/tensorflow/issues/23875)

I personally hope that the mistake is on my part but it would be nice to have either eyes look into it.",1,1
87,2018-11-29,2018,11,29,22,a1h941,Question about tf.nn.bidirectional_dynamic_rnn,https://www.reddit.com/r/tensorflow/comments/a1h941/question_about_tfnnbidirectional_dynamic_rnn/,thisisiron,1543497444,"What is difference between state and output in tf.nn.bidirectional\_dynamic\_rnn ?

&amp;#x200B;

When will the state and output be used respectively? 

&amp;#x200B;

 If I look at some code, why do it use state for ""last"" and output for other?

Example.

if last:

Using state that bidirectional\_dynamic\_rnn returns

....

else:

Using output that bidirectional\_dynamic\_rnn returns

....

 

A link or a simple answer is okay.",0,1
0,2018-12-2,2018,12,2,22,a2db8z,"Tensorflow YOLO or OpenCV cascade classifier? For detecting icon, button or object on android device screen",https://www.reddit.com/r/tensorflow/comments/a2db8z/tensorflow_yolo_or_opencv_cascade_classifier_for/,ipuneetj,1543758430,"Hi,

I want to do a project which require detecting icons, buttons, text area, keyboard etc on screen of android device. I studied enough to start with OpenCV HAAR cascade classifier. But then I read somewhere for simpler objects like icon or logo, using OpenCV is not a good idea. Then I came to know about tensorflow YOLO. I haven't started learning tensorflow yet.

I am a newbie to machine learning. And I understand if I have to use tensorflow, I will have to take a dig into machine learning models which is ok! 

But I want to understand which is better for my requirements of simple object detection and why?

Thanks",4,1
1,2018-12-3,2018,12,3,0,a2dy8z,Multi Label Classification mnist,https://www.reddit.com/r/tensorflow/comments/a2dy8z/multi_label_classification_mnist/,b4shyou,1543763549,"Hi

I am trying to do a sequence detection on the mnist dataset in order to improve my tf skills. I am trying to achieve this without RNNs.

I horizontally stacked 5 images and then tried to run the classification.

Unfortunately I get very low accuracy.

Did I made  a mistake or just trained with to less data and not long enough?

Best regards

    #Create a model with 5 classifiers
    
    graph = tf.Graph()
    
    with graph.as_default():
        data = tf.placeholder(dtype=tf.float32,shape=(None, 28,140,1))
        tf_train_labels = tf.placeholder(dtype=tf.float32, shape=(None, 5,11))
        
        w1 = tf.Variable(tf.truncated_normal(shape=(3,3, 1,32), stddev=0.1))
        b1 = tf.Variable(tf.zeros(32))
        
        w2 = tf.Variable(tf.truncated_normal(shape=(3,3,32,64), stddev=0.1))
        b2 = tf.Variable(tf.constant(1., shape=[64]))
        
        w22 = tf.Variable(tf.truncated_normal(shape=(3,3,64,128), stddev=0.1))
        b22 = tf.Variable(tf.constant(1., shape=[128]))
    
    
        
        w3 = tf.Variable(tf.truncated_normal(shape=(28 // 4 * 140 // 4 * 128,1024)))
        b3 = tf.Variable(tf.constant(1., shape=[1024]))
        
        w4 = tf.Variable(tf.truncated_normal(shape=(1024,11), stddev=0.1))
        b4 = tf.Variable(tf.constant(1., shape=[11]))
        
        w5 = tf.Variable(tf.truncated_normal(shape=(1024,11), stddev=0.1))
        b5 = tf.Variable(tf.constant(1., shape=[11]))
    
        w6 = tf.Variable(tf.truncated_normal(shape=(1024,11), stddev=0.1))
        b6 = tf.Variable(tf.constant(1., shape=[11]))
        
        w7 = tf.Variable(tf.truncated_normal(shape=(1024,11), stddev=0.1))
        b7 = tf.Variable(tf.constant(1., shape=[11]))
        
        w8 = tf.Variable(tf.truncated_normal(shape=(1024,11), stddev=0.1))
        b8 = tf.Variable(tf.constant(1., shape=[11]))
        
    
        
        def model(x, w, b):
            conv= tf.nn.relu(tf.nn.conv2d(x, w1, [1,1,1,1], padding=""SAME"")+b1)
            conv = tf.nn.max_pool(conv, [1,2,2,1], [1,2,2,1], padding=""SAME"")
            conv = tf.nn.relu(tf.nn.conv2d(conv, w2, [1,1,1,1], padding=""SAME"")+b2)
            conv = tf.nn.max_pool(conv, [1,2,2,1], [1,2,2,1],padding=""SAME"")
            conv = tf.nn.relu(tf.nn.conv2d(conv, w22, [1,1,1,1], padding=""SAME"")+b22)
    
            shape = conv.get_shape().as_list()
            reshape = tf.reshape(conv, [-1, shape[1] * shape[2] * shape[3]])
            dense = tf.nn.relu(tf.matmul(reshape, w3)+b3)
            return tf.matmul(dense, w) + b
        pred1 = model(data, w4, b4)
        pred2 = model(data, w5, b5)
        pred3 = model(data, w6, b6)
        pred4 = model(data, w7, b7)
        pred5 = model(data, w8, b8)
        
        prediction = tf.stack([
                tf.nn.softmax(pred1),
                tf.nn.softmax(pred2),
                tf.nn.softmax(pred3),
                tf.nn.softmax(pred4),
                tf.nn.softmax(pred5)])
    
    
        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(
                       logits = pred1, labels = tf_train_labels[:, 0])) + \
                   tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(
                       logits = pred2, labels = tf_train_labels[:, 1])) + \
                   tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(
                       logits = pred3, labels = tf_train_labels[:, 2])) + \
                   tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(
                       logits = pred4, labels = tf_train_labels[:, 3])) + \
                   tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(
                       logits = pred5, labels = tf_train_labels[:, 4]))
    
        
        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.0001).minimize(loss)
        init = tf.global_variables_initializer()",2,1
2,2018-12-4,2018,12,4,0,a2phrm,TF FailedPreconditionError - uninitialized value Variable,https://www.reddit.com/r/tensorflow/comments/a2phrm/tf_failedpreconditionerror_uninitialized_value/,bitsofshit,1543849864,"Hi all,

Trying to diagnose error received even after resetting graph and reinit globally. What gives?
```
tf.reset_default_graph()

#x = tf.Variable(image, name='x')
arr = tf.Variable([[1,2,3],[4,5,6]],dtype= tf.int32)
arr2 = tf.constant((1,2,3))
#arr.assign_add
arr3 = tf.Variable(arr + arr2,name='arr3')

sess = tf.Session()

with sess.as_default():
    sess.run(tf.global_variables_initializer())
    #sess.run(x)
```
Here is resulting output:

 Attempting to use uninitialized value Variable
	 [[Node: Variable/read = Identity[T=DT_INT32, _class=[""loc:@Variable""], _device=""/job",1,1
3,2018-12-4,2018,12,4,13,a2x981,Zero experience with tensorflow - need an image transformation training script.,https://www.reddit.com/r/tensorflow/comments/a2x981/zero_experience_with_tensorflow_need_an_image/,HomeBrewingCoder,1543898533,"I have a need for a way to train a neural network to do an image transformation.

Lets say I have some folder 

inputs/

and some secondary folder

outputs/

each being full of images (image 1.png in inputs corresponds to 1.jpg in outputs) where the outputs is exactly the expected transformation that is required.


What would a basic POC be for this?


I know I'm a jerk for this, coming in here and having almost nothing and expecting it to be 'so simple'.  I truly do just need the absolute most basic version so I can prove that a pre-processing step will reduce the level of overtraining that is currently nuking the project we are testing.

Thanks so much  guys!

",5,1
4,2018-12-5,2018,12,5,2,a331uf,Keras Implementation of Googles new Yogi-Optimizer,https://www.reddit.com/r/tensorflow/comments/a331uf/keras_implementation_of_googles_new_yogioptimizer/,4rtemi5,1543946141,"I wrote an tf.keras implementation of a new Optimizer submitted to NeurIPS-2018 by a team from Google. It outperforms Adam under many circumstances with little to none hyperparameter-tuning.

&amp;#x200B;

Paper can be found here: [http://papers.nips.cc/paper/8186-adaptive-methods-for-nonconvex-optimization.pdf](http://papers.nips.cc/paper/8186-adaptive-methods-for-nonconvex-optimization.pdf)

Code can be found here: [https://github.com/4rtemi5/Yogi-Optimizer\_Keras](https://github.com/4rtemi5/Yogi-Optimizer_Keras)

Colab notebook can be found here: [https://colab.research.google.com/drive/1xXh2xJdGjrcZ4XjUXWaSQ2osBR09UBG6](https://colab.research.google.com/drive/1xXh2xJdGjrcZ4XjUXWaSQ2osBR09UBG6)

&amp;#x200B;

Thanks for this great contribution to the authors!",9,1
5,2018-12-5,2018,12,5,5,a34g3i,"Trying to remap a tensor of one-hot labels, how would I go about that?",https://www.reddit.com/r/tensorflow/comments/a34g3i/trying_to_remap_a_tensor_of_onehot_labels_how/,rumborak,1543954881," I have a tensor that contains labels in one-hot format: \[0 0 0 0 0 1 0 0 0 0.....\]. I am trying to remap these labels, for example wanting the mentioned tensor to be transformed into \[0 1 0 0 0 0 ....\], i.e. label 6 becomes label 2. That is, the general idea is to have a map ""6 -&gt;2, 10 -&gt; 1"" etc.

&amp;#x200B;

I looked into tf.map\_fn, tf.cond, tf.where etc, but none of these seem to do what I need. My last resort is to create a matrix that transforms the tensor that way, but is there a ""good"" way? ",0,1
6,2018-12-5,2018,12,5,18,a3amzo,What is the best way to train network using tensorflow on multiple GPU's with tf.Data API ?,https://www.reddit.com/r/tensorflow/comments/a3amzo/what_is_the_best_way_to_train_network_using/,goravk,1544000760,"It's very difficult to train a tensorflow model with multiple GPU's  and there are no clear documents/guides which mention the best way to  train it on multiple GPU's. Code used in many tutorials is outdated and it looks like estimators are the latest way in Tensorflow to do training on multiple GPU's.

But recently I came across Horovod and then to [collectiveallreduce](https://www.logicalclocks.com/goodbye-horovod-hello-tensorflow-collectiveallreduce/). And now I'm confused which is the best way to do distributed training.

Is there any other simpler API or Tensorflow estimators and Horovod  are the best ways currently available (using tf.data pipeline)?

Thanks.",5,1
7,2018-12-6,2018,12,6,4,a3fgj2,Tensorflow CPU memory allocation problem (Abandon (core dumped)),https://www.reddit.com/r/tensorflow/comments/a3fgj2/tensorflow_cpu_memory_allocation_problem_abandon/,jjrmyy,1544037067,"I created a program in python using Keras/Tensorflow. I don't have  any problem for the creation of my data and the training. However, I  have the following error when I want to **evaluate** my model:

`Using TensorFlow backend. WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4213: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version. Instructions for updating: Create a \`tf.sparse.SparseTensor\` and use \`tf.sparse.to_dense\` instead. 2018-12-05 19:20:44.932780: W tensorflow/core/framework/allocator.cc:122] Allocation of 3359939800 exceeds 10% of system memory. terminate called after throwing an instance of 'std::bad_alloc'   what():  std::bad_alloc Abandon (core dumped)`

&amp;#x200B;

It seems to be a **memory allocation problem**. I reduced  the size of my model and make smaller all the parameters but nothing has  changed. I don't know how to solve this issue.",0,1
8,2018-12-6,2018,12,6,11,a3jqor,Tensorflow Estimator API causes crash at `sampled_softmax_loss` and `nce_loss` for Tensorflow's official word2vec implentation,https://www.reddit.com/r/tensorflow/comments/a3jqor/tensorflow_estimator_api_causes_crash_at_sampled/,BatmantoshReturns,1544064698,"This is a distilled version of this unanswered question

https://stackoverflow.com/questions/53405657/converting-tensorflow-graph-to-use-tensorflow-estimator-getting-typeerror-dat

The issue is that `sampled_softmax_loss` and `nce_loss` gives an error when using Tensorflow Estimators. 

I decided to develop a Estimator based on Tensorflow's own Word2Vec implementation to 1) minimalize the problem as much as possible 2) using Tensorflow's own official implementation code to give confidence of where the problem is exactly isolated. 

Here's is Tensorflow's official basic word2vec implementation

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/word2vec/word2vec_basic.py

Here is the Google Colab notebook where I implemented this code. 

https://colab.research.google.com/drive/1nTX77dRBHmXx6PEF5pmYpkIVxj_TqT5I

Here is the Google Colab notebook where I altered the code so that it uses Tensorflow Estimator. 

https://colab.research.google.com/drive/1IVDqGwMx6BK5-Bgrw190jqHU6tt3ZR3e

For convenience, here is exact code from the notebook above where I define `model_fn`

    batch_size = 128
    embedding_size = 128  # Dimension of the embedding vector.
    skip_window = 1  # How many words to consider left and right.
    num_skips = 2  # How many times to reuse an input to generate a label.
    num_sampled = 64  # Number of negative examples to sample.
    
    def my_model( features, labels, mode, params):
    
        with tf.name_scope('inputs'):
            train_inputs = features
            train_labels = labels
    
        with tf.name_scope('embeddings'):
            embeddings = tf.Variable(
              tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))
            embed = tf.nn.embedding_lookup(embeddings, train_inputs)
    
        with tf.name_scope('weights'):
            nce_weights = tf.Variable(
              tf.truncated_normal(
                  [vocabulary_size, embedding_size],
                  stddev=1.0 / math.sqrt(embedding_size)))
        with tf.name_scope('biases'):
            nce_biases = tf.Variable(tf.zeros([vocabulary_size]))
    
        with tf.name_scope('loss'):
            loss = tf.reduce_mean(
                tf.nn.nce_loss(
                    weights=nce_weights,
                    biases=nce_biases,
                    labels=train_labels,
                    inputs=embed,
                    num_sampled=num_sampled,
                    num_classes=vocabulary_size))
    
        tf.summary.scalar('loss', loss)
    
        if mode == ""train"":
            with tf.name_scope('optimizer'):
                optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss)
    
            return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=optimizer)

And here is where I call the estimator and training 

    word2vecEstimator = tf.estimator.Estimator(
            model_fn=my_model,
            params={
                'batch_size': 16,
                'embedding_size': 10,
                'num_inputs': 3,
                'num_sampled': 128,
                'batch_size': 16
            })
    
    word2vecEstimator.train(
        input_fn=generate_batch,
        steps=10)

And this the error message I get when using Estimator

    INFO:tensorflow:Calling model_fn.
    ---------------------------------------------------------------------------
    TypeError                                 Traceback (most recent call last)
    &lt;ipython-input-22-955f44867ee5&gt; in &lt;module&gt;()
          1 word2vecEstimator.train(
          2     input_fn=generate_batch,
    ----&gt; 3     steps=10)
    
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)
        352 
        353       saving_listeners = _check_listeners_type(saving_listeners)
    --&gt; 354       loss = self._train_model(input_fn, hooks, saving_listeners)
        355       logging.info('Loss for final step: %s.', loss)
        356       return self
    
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)
       1205       return self._train_model_distributed(input_fn, hooks, saving_listeners)
       1206     else:
    -&gt; 1207       return self._train_model_default(input_fn, hooks, saving_listeners)
       1208 
       1209   def _train_model_default(self, input_fn, hooks, saving_listeners):
    
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)
       1235       worker_hooks.extend(input_hooks)
       1236       estimator_spec = self._call_model_fn(
    -&gt; 1237           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
       1238       global_step_tensor = training_util.get_global_step(g)
       1239       return self._train_with_estimator_spec(estimator_spec, worker_hooks,
    
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _call_model_fn(self, features, labels, mode, config)
       1193 
       1194     logging.info('Calling model_fn.')
    -&gt; 1195     model_fn_results = self._model_fn(features=features, **kwargs)
       1196     logging.info('Done calling model_fn.')
       1197 
    
    &lt;ipython-input-20-9d389437162a&gt; in my_model(features, labels, mode, params)
         33                 inputs=embed,
         34                 num_sampled=num_sampled,
    ---&gt; 35                 num_classes=vocabulary_size))
         36 
         37     # Add the loss value as a scalar to summary.
    
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py in nce_loss(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, remove_accidental_hits, partition_strategy, name)
       1246       remove_accidental_hits=remove_accidental_hits,
       1247       partition_strategy=partition_strategy,
    -&gt; 1248       name=name)
       1249   sampled_losses = sigmoid_cross_entropy_with_logits(
       1250       labels=labels, logits=logits, name=""sampled_losses"")
    
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py in _compute_sampled_logits(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, subtract_log_q, remove_accidental_hits, partition_strategy, name, seed)
       1029   with ops.name_scope(name, ""compute_sampled_logits"",
       1030                       weights + [biases, inputs, labels]):
    -&gt; 1031     if labels.dtype != dtypes.int64:
       1032       labels = math_ops.cast(labels, dtypes.int64)
       1033     labels_flat = array_ops.reshape(labels, [-1])
    
    TypeError: data type not understood",0,1
9,2018-12-6,2018,12,6,15,a3li65,TensorFlow.js not able to save model,https://www.reddit.com/r/tensorflow/comments/a3li65/tensorflowjs_not_able_to_save_model/,CSS_Programmer,1544078842,"I am using TensorFlow.js in node and I am not able to save my models. I have been racking my brains out trying to figure this out. According to [this](https://js.tensorflow.org/tutorials/model-save-load.html) tutorial I need to place \`require('@tensorflow/tfjs-node')\` in my dependencies and install it, which I have done. I have written the simplest code possible to save a model:

&amp;#x200B;

    var tf = require('@tensorflow/tfjs')
require('@tensorflow/tfjs-node')

// First create and save a model.
doit()
async function doit(){
 const model = tf.sequential();
 model.add(tf.layers.dense(
        { units: 1, inputShape: [10], activation: 'sigmoid' }));
 await model.save('file:///Users/powermac/Dev/rateBot/modelsave1');
}

When I run it I get this error:

    (node:2603) UnhandledPromiseRejectionWarning: Error: Cannot find any save handlers for URL 'file:///Users/powermac/Dev/rateBot/trash/modelsave1'
        at new ValueError (/Users/powermac/Dev/node_modules/@tensorflow/tfjs-layers/dist/errors.js:36:28)
        at Sequential.&lt;anonymous&gt; (/Users/powermac/Dev/node_modules/@tensorflow/tfjs-layers/dist/engine/training.js:906:39)
        at step (/Users/powermac/Dev/node_modules/@tensorflow/tfjs-layers/dist/engine/training.js:42:23)
        at Object.next (/Users/powermac/Dev/node_modules/@tensorflow/tfjs-layers/dist/engine/training.js:23:53)
        at /Users/powermac/Dev/node_modules/@tensorflow/tfjs-layers/dist/engine/training.js:17:71
        at new Promise (&lt;anonymous&gt;)
        at __awaiter (/Users/powermac/Dev/node_modules/@tensorflow/tfjs-layers/dist/engine/training.js:13:12)
        at Sequential.Model.save (/Users/powermac/Dev/node_modules/@tensorflow/tfjs-layers/dist/engine/training.js:898:16)
        at doit (/Users/powermac/Dev/rateBot/repl.js:10:17)
        at Object.&lt;anonymous&gt; (/Users/powermac/Dev/rateBot/repl.js:5:1)
    (node:2603) UnhandledPromiseRejectionWarning: Unhandled promise rejection. This error originated either by throwing inside of an async function without a catch block, or by rejecting a promise which was not handled with .catch(). (rejection id: 3)
    (node:2603) [DEP0018] DeprecationWarning: Unhandled promise rejections are deprecated. In the future, promise rejections that are not handled will terminate the Node.js process with a non-zero exit code.

I have installed the dependencies, my computer is updated (a mac), and I have node version v8.12.0 installed (which is a LTS version). I've tried using other node versions but with no success.",6,1
10,2018-12-7,2018,12,7,0,a3p44u,"Simple examples of evaluating tf.Graph, Tensos etc?",https://www.reddit.com/r/tensorflow/comments/a3p44u/simple_examples_of_evaluating_tfgraph_tensos_etc/,nobodywillobserve,1544111527,"The documentation is deliberately poisonous. Eager execution is not supported in some areas I am trying to debug. I don't want to hear about what graphs are or be taught concepts I know, I want to know what setting a variable looks like and running it in a session.   


Are there are examples written by actual humans who assume the reader knows everything except for the library? ",5,1
11,2018-12-7,2018,12,7,2,a3pvkg,What they don't tell you about scaling AI,https://www.reddit.com/r/tensorflow/comments/a3pvkg/what_they_dont_tell_you_about_scaling_ai/,woodworksio,1544116087,,1,1
12,2018-12-7,2018,12,7,6,a3sp5g,Behaviour of BatchNormalisation in keras model with random weights assigned?,https://www.reddit.com/r/tensorflow/comments/a3sp5g/behaviour_of_batchnormalisation_in_keras_model/,nobodywillobserve,1544132641,"I am doing some weird things with creating random networks and I am wondering how the BatchNormalization weight recalc is triggered/recalced. It looks like it is just on __call__ but I am *just* reading the code.

Basically, if I get the axis right I am hoping random Dense set by set_weights will sill be normed by the BatchNorm layer.

Anyone who knows this stuff know if this is all a bad idea? I am pretty must just guessing and hacking/pretty new to the details of tf.",0,1
13,2018-12-7,2018,12,7,11,a3vhhj,pip install tensorflow #on windows,https://www.reddit.com/r/tensorflow/comments/a3vhhj/pip_install_tensorflow_on_windows/,Background_Mongoose,1544150666,"If you throw ""pip install tensorflow"" in windows 7 DOS command prompt as administrator it does not work and I know there is some sort of cryptic way to do it right but I'm pressed for time and deciphering it, plus I know you guys will most likely know how to help me :)

&amp;#x200B;

thank you",11,1
14,2018-12-8,2018,12,8,4,a43bn3,Dilated 3D convolutions in TensorFlow.,https://www.reddit.com/r/tensorflow/comments/a43bn3/dilated_3d_convolutions_in_tensorflow/,RohitDulam,1544211850,[removed],0,1
15,2018-12-8,2018,12,8,14,a483ln,Can't get the hang of loops,https://www.reddit.com/r/tensorflow/comments/a483ln/cant_get_the_hang_of_loops/,psyyduck,1544247701,"    import tensorflow as tf
    import tensorflow_probability as tfp
    import numpy as np
    tfd = tfp.distributions
    
    data = tf.placeholder(dtype=tf.float32)
    mu = tf.constant([1.5,2.5,3.5], dtype=tf.float32)
    sigma  = tf.constant([1,0.75,0.5], dtype=tf.float32)
    
    allprobs = tf.Variable(tf.zeros(shape=[3], dtype=tf.float32))
    
    def body(x):    
        return allprobs[x].assign( tfd.Normal(loc=mu[x], scale=sigma[x]).log_prob(value=data[x]) )

    def condition(i):
        return i &lt; 3
    
    i = tf.Variable(tf.constant(0))
    
    result = tf.while_loop(condition, body, [i])
    
    with tf.Session() as sess:
        x_obs = [1,2,3]
        ones, testr = sess.run([zeros_op, result], feed_dict={ data: x_obs})

As you guys see, I'm trying to get a list, with [prob(1) (normal(1.5,1)) , prob(2) (normal(2.5,0.75)) , prob(3) (normal(3.5,0.5)) ]. No luck so far. Any help would be appreciated.",1,1
16,2018-12-9,2018,12,9,0,a4bqgd,DataLossError: corrupted record,https://www.reddit.com/r/tensorflow/comments/a4bqgd/datalosserror_corrupted_record/,OrrKislev,1544284097,"Hi!

I am using [https://github.com/tkarras/progressive\_growing\_of\_gans](https://github.com/tkarras/progressive_growing_of_gans), running tensorflow. and it runs very well. actually I managed to get some great results with a few different datasets.

but not I'm getting an error:  
`DataLossError (see above for traceback): corrupted record at 64793939627`

	 `[[{{node Inputs/IteratorGetNext}} = IteratorGetNext[output_shapes=[[?,?,?,?], [?,0]], output_types=[DT_UINT8, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Dataset/IteratorV2)]]`

&amp;#x200B;

I got this error after a week of the algorithm working, and after resuming using the last saved state of the network, and even after resuming the previous state of the network..  
Also I got the same error reproduced when I restarted the whole thing again - after about a week of working, at the exact same spot - after passing through 9010k images

&amp;#x200B;

I guess its not an error in the dataset becuase it happens only after working for a few days, running 9010k images, and my dataset is only 40k images

&amp;#x200B;

any idea how to debug this? how to fix it?

thaks

Orr

&amp;#x200B;",0,1
17,2018-12-9,2018,12,9,9,a4g5q4,TF 2.0 preparation,https://www.reddit.com/r/tensorflow/comments/a4g5q4/tf_20_preparation/,_spicyramen,1544314337,"Based on TensorFlow newsletter, what is the recommend way of building models:

1. Use tf.feature\_column for features (Now supported in Keras tf-nightly)
2. Remove contrib references if possible
3. Keras with tf.data.Dataset for input:
4. For model training and evaluation should we use: 

**model\_to\_estimator**\+**train\_and\_evaluate** or  **model.fit** \+ **tf.data.Dataset** ?

&amp;#x200B;",8,1
18,2018-12-10,2018,12,10,20,a4upmf,Replacing loading via feed_dict with tf.data API,https://www.reddit.com/r/tensorflow/comments/a4upmf/replacing_loading_via_feed_dict_with_tfdata_api/,ashblue21,1544439659,"I  am implementing a GAN model where my current input pipeline loads images from two domains(let's say domain A and domain B) using placeholders and feed\_dict. I cannot directly load the images into memory because I run out of memory and I use the path to the file location and opencv to read the images.  My code for this looks something like this 

    A = tf.placeholder(None,256,256,3)
    B = tf.placeholder(None,256,256,3)
    dis_loss,gan_loss = cost(A,B)  # cost(A,B) is a function defining discriminator and generator losses
    # More code
    D_solver = tf.train.AdamOptimizer(beta1 = 0.5).minimize(dis_loss, var_list=disA_var+disB_var)
    G_solver = tf.train.AdamOptimizer(beta1 = 0.5).minimize(gan_loss, var_list=genA_var+genB_var) 
    # Initialize tf Session and load a batch of images from file location,shuffle and  read the images #via open CV and load them into 2 numpy arrays of shape (batch_size,256,256,3)
    
    
    _, D_loss_curr = sess.run([D_solver, dis_loss], feed_dict={A: numpy_array_1 ,B:numpy_array_2})
    _, G_loss_curr = sess.run([G_solver, gan_loss], feed_dict={A: numpy_array_1 ,B: numpy_array_1})
    # more code
    #plot results etc

I am fairly new to Tensorflow and am a bit confused as to how to go about using the tf.data API to directly load images and eliminate the use of feed\_dict. My goal is to prefetch the next batch to maximize GPU utilization. It would be great if someone could suggest pseudocode for this. I tried using tf.image.decode\_jpeg and resizing the image, but I am not sure how to actually proceed from there. Thanks",2,1
19,2018-12-10,2018,12,10,20,a4utn6,Installing tensorflow=1.0.0 with python = 3.5 on ubuntu ?,https://www.reddit.com/r/tensorflow/comments/a4utn6/installing_tensorflow100_with_python_35_on_ubuntu/,zarooricheck,1544440779,"I've tried [https://stackoverflow.com/questions/38896424/tensorflow-not-found-using-pip](https://stackoverflow.com/questions/38896424/tensorflow-not-found-using-pip) but it doesn't seem to work. 

Can some please provide link from [https://storage.googleapis.com/tensorflow](https://storage.googleapis.com/tensorflow) to install. 

&amp;#x200B;

Thank you",9,1
20,2018-12-12,2018,12,12,19,a5gxiv,I have some question about tensorflow to javacc,https://www.reddit.com/r/tensorflow/comments/a5gxiv/i_have_some_question_about_tensorflow_to_javacc/,GabrielCPond,1544609849,"I'm doing my homework the professor ask us make a javacc file about tensorflow( tensorflow neural network ), but I could not find any example at internet, could anybody give me some hint about it?

this is the one of the tensorflow python code 

`W = tf.Variable(tf.random_normal([2, 1]))`

could anybody show me how to  translate this code to javacc .",2,1
21,2018-12-13,2018,12,13,1,a5jrqx,What is the difference between tf.nn.conv1d and tf.nn.conv2d?,https://www.reddit.com/r/tensorflow/comments/a5jrqx/what_is_the_difference_between_tfnnconv1d_and/,thisisiron,1544632726,,4,1
22,2018-12-13,2018,12,13,13,a5qbm3,Single Core Performance,https://www.reddit.com/r/tensorflow/comments/a5qbm3/single_core_performance/,wrtcdevrydy,1544676855,"Through some unfortunate circumstances, my tensorflow VM is being limited to one CPU core (SMP booting issues).

What kind of performance hit should I expect if I can't figure this out when running tensorflow (2 VMs with gt 710 and gtx 1060)",0,1
23,2018-12-13,2018,12,13,18,a5rza1,Another person with the 'kernel dies upon import' problem,https://www.reddit.com/r/tensorflow/comments/a5rza1/another_person_with_the_kernel_dies_upon_import/,HudPesjan,1544692852,"I am on windows 10 using Spyder and have step by step downgraded tensorflow from 1.7.* to 1.3.* where i can finally execute 'import tensorflow' without the kernel dying (most forums suggest the problem should allready be resolved by downgrading to 1.5.*). However it dies when I try to import anything from the keras library. I can't find any information on the version of TF that is needed for a certain version of Keras.
Thank you for your time.",2,1
24,2018-12-14,2018,12,14,16,a62i47,CUDA version for Tensorflow 1.0.0 ?,https://www.reddit.com/r/tensorflow/comments/a62i47/cuda_version_for_tensorflow_100/,zarooricheck,1544770828,"I'm setting up my system and according to [https://www.tensorflow.org/install/source#linux](https://www.tensorflow.org/install/source#linux) , does this mean that tensorflow-gpu==1.0.0 is only compatible with CUDA 8 ?

Can we run  tensorflow-gpu==1.0.0 on CUDA 10 ?

&amp;#x200B;",6,1
25,2018-12-14,2018,12,14,22,a651lp,Crack Detection Algor:,https://www.reddit.com/r/tensorflow/comments/a651lp/crack_detection_algor/,Jialongg,1544795997,"Hi all,

I have been trying to run this script:  [https://github.com/satyenrajpal/Concrete-Crack-Detection/blob/master/README.md](https://github.com/satyenrajpal/Concrete-Crack-Detection/blob/master/README.md)

However, I faced this error: ValueError: Cannot feed value of shape (64,) for Tensor 'x:0', which has shape '(?, 128, 128, 3)'

[The error log](https://i.redd.it/bgv272il19421.png)

I googled quite abit and most suggestions are to reshape the placeholder or my x\_batch y\_true\_batch. 

I tried several methods of reshaping but they simply gave me different kinds of errors.

[My attempts at reshaping the tensors or the numpy arrays](https://i.redd.it/06cieqer19421.png)

Im pretty new to tensorflow so I would really appreciate any help! Thank you in advance!!

&amp;#x200B;

I shall paste my codes below:

&amp;#x200B;

 \------------------------------------------------------------------------------------------------------------------------------------

""""""  
Code to train the model  
""""""  
import os  
import tensorflow as tf  
import numpy as np  
import time  
from datetime import timedelta  
from dataset import load\_cached  
\#from matplotlib.image import imread  
import cv2,sys,argparse  
\#Initialzing the conv and max\_pool layers  
\#####################################################  
def new\_conv\_layer(input,              # The previous layer.  
num\_input\_channels, # Num. channels in prev. layer.  
filter\_size,        # Width and height of each filter.  
num\_filters):        # Number of filters.  
 \# Shape of the filter-weights for the convolution.  
shape = \[filter\_size, filter\_size, num\_input\_channels, num\_filters\]  
 \# Create new weights aka. filters with the given shape.  
weights = tf.Variable(tf.truncated\_normal(shape, stddev=0.05))  
 \# Create new biases, one for each filter.  
biases = tf.Variable(tf.constant(0.05, shape=\[num\_filters\]))  
layer = tf.nn.conv2d(input=input,  
filter=weights,  
strides=\[1, 2, 2, 1\],  
padding='VALID')  
 \# A bias-value is added to each filter-channel.  
layer += biases  
 return layer  
\####################################################  
def max\_pool(layer,ksize,strides):  
layer = tf.nn.max\_pool(value=layer,  
ksize=ksize,  
strides = strides,  
padding = 'VALID')  
 return layer  
\####################################################  
def new\_fc\_layer(input,           # The previous layer.  
num\_inputs,      # Num. inputs from prev. layer.  
num\_outputs,     # Num. outputs  
use\_relu=True):  # Use Rectified Linear Unit (ReLU)?  
 \# Create new weights and biases.  
weights =tf.Variable(tf.truncated\_normal(\[num\_inputs, num\_outputs\], stddev=0.05))  
biases = tf.Variable(tf.constant(0.05, shape=\[num\_outputs\]))  
   
 \#Include Drop-out as well to avoid overfitting  
 \#x\_drop = tf.nn.dropout(input, keep\_prob=keep\_prob\_input)  
   
 \# Calculate the layer as the matrix multiplication of  
 \# the input and weights, and then add the bias-values.  
layer = tf.matmul(input, weights) + biases  
 \# Use ReLU?  
 if use\_relu:  
layer = tf.nn.relu(layer)  
 return layer      
\####################################################  
def flatten\_layer(layer):  
 \# Get the shape of the input layer.  
layer\_shape = layer.get\_shape()  
 \# The shape of the input layer is assumed to be:  
 \# layer\_shape == \[num\_images, img\_height, img\_width, num\_channels\]  
 \# The number of features is: img\_height \* img\_width \* num\_channels  
num\_features = layer\_shape\[1:4\].num\_elements()  
   
layer\_flat = tf.reshape(layer, \[-1, num\_features\])  
 \# The shape of the flattened layer is now:  
 \# \[num\_images, img\_height \* img\_width \* num\_channels\]  
 return layer\_flat, num\_features  
\####################################################  
   
class Model:  
 def \_\_init\_\_(self,in\_dir,save\_folder=None):  
dataset = load\_cached(cache\_path='my\_dataset\_cache.pkl', in\_dir=in\_dir)  
 self.num\_classes = dataset.num\_classes  
 \#   print(""num\_classes: "", self.num\_classes)  
image\_paths\_train, cls\_train, self.labels\_train = dataset.get\_training\_set()  
 \#   print(""img\_path\_train: "", image\_paths\_train)  
image\_paths\_test, self.cls\_test, self.labels\_test = dataset.get\_test\_set()  
 \#   print(""img\_path\_test: "", image\_paths\_test)  
   
 \##############################IMAGE PARAMETERS#####################################  
 self.img\_size = 128  
 self.num\_channels = 3  
 self.train\_batch\_size = 64  
 self.test\_batch\_size = 64  
 \###################################################################################  
   
 self.x = tf.placeholder(tf.float32, shape=\[None, self.img\_size,self.img\_size,self.num\_channels\], name='x')  
 self.x\_image = tf.reshape(self.x, \[-1, self.img\_size, self.img\_size, self.num\_channels\])  
 self.y\_true = tf.placeholder(tf.float32, shape=\[None, self.num\_classes\], name='y\_true')  
 self.y\_true\_cls = tf.argmax(self.y\_true, axis=1) #The True class Value  
 self.keep\_prob = tf.placeholder(tf.float32)  
 self.keep\_prob\_2 = tf.placeholder(tf.float32)  
 self.y\_pred\_cls = None  
 self.train\_images= self.load\_images(image\_paths\_train)  
 self.test\_images= self.load\_images(image\_paths\_test)  
 self.save\_folder=save\_folder  
 self.optimizer,self.accuracy = self.define\_model()          


def load\_images(self,image\_paths):  
 \# Load the images from disk.  
images = \[cv2.imread(path,1) for path in image\_paths\]  
   
 \# print(""image\_paths :"", image\_paths)  
 \# images = \[\]  
 \# for img in os.listdir(image\_paths):  
 \#     img\_path = os.path.join(img, image\_paths)  
 \#     image = cv2.imread(img\_path, 1)  
 \#     images.append(image)  
   
 \# Convert to a numpy array and return it in the form of \[num\_images,size,size,channel\]  
 \#print(np.asarray(images\[0\]).shape)  
 return np.asarray(images)  
   
 def define\_model(self):  
 \#Convolution Layer 1  
filter\_size1 = 10 # Convolution filters are 10 x 10   
num\_filters1 = 24 # There are 24 of these filters.  
 \# Convolutional Layer 2  
filter\_size2 = 7 # Convolution filters are 7 x 7   
num\_filters2 = 48 # There are 48 of these filters.  
   
 \# Convolutional Layer 3  
filter\_size3 = 11 # Convolution filters are 11 x 11   
num\_filters3 = 96 # There are 96 of these filters.  
 \# Fully-connected layer  
fc\_size = 96   
   
layer\_conv1 = new\_conv\_layer(input=self.x\_image,  
num\_input\_channels=self.num\_channels,  
filter\_size=filter\_size1,  
num\_filters=num\_filters1)  
 \#Max Pool Layer  
ksize1 = \[1,4,4,1\]  
strides1 = \[1,2,2,1\]  
layer\_max\_pool1 = max\_pool(layer\_conv1,ksize1,strides1)  
   
 \#Convolutional Layer 2  
layer\_conv2 = new\_conv\_layer(input=layer\_max\_pool1,  
num\_input\_channels=num\_filters1,  
filter\_size=filter\_size2,  
num\_filters=num\_filters2)  
 \#Max Pool Layer  
ksize2 = \[1,2,2,1\]  
strides2 = \[1,1,1,1\]  
layer\_max\_pool2 = max\_pool(layer\_conv2,ksize2,strides2)  
   
 \#Convolutional Layer 3  
layer\_conv3 = new\_conv\_layer(input=layer\_max\_pool2,  
num\_input\_channels=num\_filters2,  
filter\_size=filter\_size3,  
num\_filters=num\_filters3)  
 \#Flatten  
layer\_flat, num\_features = flatten\_layer(layer\_conv3)  
 \#Relu Layer  
layer\_relu = tf.nn.relu(layer\_flat)  
 \#Fully-Connected Layer1  
layer\_fc1 = new\_fc\_layer(input=layer\_relu,  
num\_inputs=num\_features,  
num\_outputs=fc\_size,  
use\_relu=True)  
   
 \#Fully-Connected Layer2  
layer\_fc2 = new\_fc\_layer(input=layer\_fc1,  
num\_inputs=fc\_size,  
num\_outputs=self.num\_classes,  
use\_relu=False)  
 \#Predict the class  
y\_pred = tf.nn.softmax(layer\_fc2)  
 self.y\_pred\_cls = tf.argmax(y\_pred, dimension=1,name=""predictions"")  
   
 \#Cost Function  
cross\_entropy = tf.nn.softmax\_cross\_entropy\_with\_logits(logits=layer\_fc2, labels=self.y\_true)  
cost = tf.reduce\_mean(cross\_entropy)  
optimizer = tf.train.AdamOptimizer(learning\_rate=1e-4).minimize(cost)  
 \#Predict  
correct\_prediction = tf.equal(self.y\_pred\_cls, self.y\_true\_cls)  
accuracy = tf.reduce\_mean(tf.cast(correct\_prediction, tf.float32))  
 return optimizer, accuracy  
   
 def random\_batch(self):  
 \# Number of images in the training-set.  
num\_images = len(self.train\_images)  
   
 \# Create a random index.  
idx = np.random.choice(num\_images,  
size=self.train\_batch\_size,  
replace=False)  
   
 \# Use the random index to select random x and y-values.  
x\_batch = self.train\_images\[idx\]  
y\_batch = self.labels\_train\[idx\]  
 return x\_batch, y\_batch  
   
 def print\_test\_accuracy(self,sess):  
   
 \# Number of images in the test-set.  
num\_test = len(self.test\_images)  
   
 \# Allocate an array for the predicted classes which  
 \# will be calculated in batches and filled into this array.  
cls\_pred = np.zeros(shape=num\_test, dtype=np.int)  
   
i = 0  
   
 while i &lt; num\_test:  
 \# The ending index for the next batch is denoted j.  
j = min(i + self.test\_batch\_size, num\_test)  
   
images = self.test\_images\[i:j\]  
   
labels = self.labels\_test\[i:j\]  
   
 \# Create a feed-dict with these images and labels.  
feed\_dict = {self.x: images,  
 self.y\_true: labels,  
 self.keep\_prob: 1,  
 self.keep\_prob: 1}  
cls\_pred\[i:j\] = sess.run(self.y\_pred\_cls, feed\_dict=feed\_dict)  
   
 \# Set the start-index for the next batch to the  
 \# end-index of the current batch.  
i = j  
   
 \# Create a boolean array whether each image is correctly classified.  
correct = (self.cls\_test == cls\_pred)  
   
 \# Classification accuracy is the number of correctly classified  
 \# images divided by the total number of images in the test-set.  
acc = float(correct.sum()) / num\_test  
   
 \# Print the accuracy.  
msg = ""Accuracy on Test-Set: {0:.1%} ({1} / {2})""  
 \#   print(msg.format(acc, correct.sum(), num\_test))  
   
 def optimize(self, num\_iterations):  
 \# Ensure we update the global variable rather than a local copy.  
 global total\_iterations  
total\_iterations = 0  
saver = tf.train.Saver()  
 \# Start-time used for printing time-usage below.  
start\_time = time.time()  
 with tf.Session() as sess:  
 \#global\_step\_int = tf.train.get\_global\_step(sess.graph)  
sess.run(tf.global\_variables\_initializer())  
   
 for i in range(total\_iterations,  
total\_iterations + num\_iterations):  
   
 \# Get a batch of training examples.  
 \# x\_batch now holds a batch of images and  
 \# y\_true\_batch are the true labels for those images.  
   
x\_batch, y\_true\_batch = self.random\_batch()  
   
print(""Debugger: x\_batch Length "", len(x\_batch))  
print(""Debugger: x\_batch Type "", type(x\_batch))  
print(""Debugger: y\_true\_batch Length "", len(y\_true\_batch))  
print(""Debugger: y\_true\_batch Type "", type(y\_true\_batch))  
print(""Debugger: self.x shape:"", self.x.shape)  
print(""Debugger: self.y\_true shape:"", self.y\_true.shape)  
print(""Debugger: self.train\_images\[0\]:"", self.train\_images)  
print(""Debugger: self.load\_images\[0\]:"", self.load\_images)  
print(""Debugger: self.x rank:"", tf.rank(self.x))  
\#               x\_batch = np.swapaxes(x\_batch, 1, 0)  
\#               y\_true\_batch = np.swapaxes(y\_true\_batch, 1, 0)  
\#                x\_batch = x\_batch.reshape(128,128,3)            #self added ###  
\#                y\_true\_batch = y\_true\_batch.reshape(128,128,3)   #self added ###  
\#                x\_batch = \[d.reshape(128,128,3) for d in self.train\_images\]            #self added ###  
\#                y\_true\_batch = \[d.reshape(128,128,3) for d in self.labels\_train\]   #self added ###  
\#                self.x=tf.placeholder(tf.float32,\[64,None\])  
\#                self.y\_true=tf.placeholder(tf.float32,\[64,None\])  
\#                feed\_dict\_train = {self.x: np.expand\_dims(x\_batch,axis=0),  
 \#                                 self.y\_true: np.expand\_dims(y\_true\_batch,axis=0)}  
feed\_dict\_train = {self.x: x\_batch,  
 self.y\_true: y\_true\_batch}  
 \#self.keep\_prob: 0.5,  
 \#self.keep\_prob: 0.5}  
   
sess.run(\[self.optimizer\], feed\_dict=feed\_dict\_train)  
   
 \# Print status every 100 iterations.  
 if i % 100 == 0:  
 \# Calculate the accuracy on the training-set.  
feed\_dict\_acc = {self.x: x\_batch,  
 self.y\_true: y\_true\_batch}  
 \#self.keep\_prob: 1,  
 \#self.keep\_prob: 1}  
acc = sess.run(self.accuracy, feed\_dict=feed\_dict\_acc)  
   
 \# Message for printing.  
msg = ""Optimization Iteration: {0:&gt;6}, Training Accuracy: {1:&gt;6.1%}""  
   
 \# Print it.  
 \#       print(msg.format(i + 1, acc))  
   
 \# Update the total number of iterations performed.  
total\_iterations += num\_iterations  
   
 \# Ending time.  
end\_time = time.time()  
 if i%100 ==0:  
 \#Calculate the accuracy on the test set every 100 iterations  
 self.print\_test\_accuracy(sess)  
   
 if i%500 == 0:  
 \#Saves every 500 iterations  
saver.save(sess, os.path.join(self.save\_folder,'model')) #Change this according to your convenience  
   
 \# Difference between start and end-times.  
time\_dif = end\_time - start\_time  
 self.print\_test\_accuracy(sess)  
 \# Print the time-usage.  
 \#    print(""Time usage: "" + str(timedelta(seconds=int(round(time\_dif)))))  
saver.save(sess, os.path.join(self.save\_folder,'model\_complete'))  
   
def parse\_arguments():  
parser = argparse.ArgumentParser(description='Training Network')  
parser.add\_argument('--in\_dir',dest='in\_dir',type=str,default='cracky')  
parser.add\_argument('--iter',dest='num\_iterations',type=int,default=1500)  
parser.add\_argument('--save\_folder',dest='save\_folder',type=str,default=os.getcwd())  
 return parser.parse\_args()  
   
def  main(args):  
args=parse\_arguments()  
num\_iterations = args.num\_iterations  
 \#print(""in\_dir: "", args.in\_dir)  
   
model = Model(args.in\_dir,args.save\_folder)  
model.optimize(num\_iterations)  
   
if \_\_name\_\_ == '\_\_main\_\_':  
main(sys.argv)  


&amp;#x200B;",1,1
26,2018-12-15,2018,12,15,3,a67pv5,"Using TensorFlow with C API on Windows, Linux and macOS without pain",https://www.reddit.com/r/tensorflow/comments/a67pv5/using_tensorflow_with_c_api_on_windows_linux_and/,Neargye,1544813907,,4,1
27,2018-12-16,2018,12,16,7,a6jeu8,How to submit my person MNIST-like image to TensorFlow? I trained on the MNIST dataset and would like to try my own handwritten digit on the neural network. Having problems with the format of the image data in TensorFlow :(,https://www.reddit.com/r/tensorflow/comments/a6jeu8/how_to_submit_my_person_mnistlike_image_to/,cudaeducation,1544911842,"I know that you can train your TensorFlow network on the part of the MNIST data, then test it on another part of the MNIST data.  That's wonderful!  But what about trying to submit an image of your own handwritten digit to the TensorFlow neural network and see if it can ""read"" the number correctly?!?!

&amp;#x200B;

Please tell me that I'm not the only person on planet earth who has thought of doing this!  It really is a simple matter, but I'm having all kinds of grief getting TensorFlow to read my image properly and have the pixel data etc. arranged in a way that gels with what you would expect from an MNIST image.

&amp;#x200B;

I sincerely hope I'm not the only person that has tried to do this.",2,1
28,2018-12-16,2018,12,16,10,a6ksrk,"For me, one of the main barriers to the world of deep learning was setting up all the tools. Here's a video that I hope will eliminate this barrier for anyone reading this. Hope you guys found it helpful!",https://www.reddit.com/r/tensorflow/comments/a6ksrk/for_me_one_of_the_main_barriers_to_the_world_of/,antaloaalonso,1544922437,,2,1
29,2018-12-17,2018,12,17,4,a6rtud,Any updates on PyMC4 and the usage with tensorflow_probability?,https://www.reddit.com/r/tensorflow/comments/a6rtud/any_updates_on_pymc4_and_the_usage_with/,o-rka,1544987438,I havent seen anyone on PyMC4 since the development from the Google Summer of Code with the schools dataset example.  Is there any updates on the API? Does anyone know if there will be a functional approach like Keras? ,0,1
30,2018-12-17,2018,12,17,16,a6xun8,Link for the ssd_mobilenetv2_oidv4 model? The one on github is broken.,https://www.reddit.com/r/tensorflow/comments/a6xun8/link_for_the_ssd_mobilenetv2_oidv4_model_the_one/,niankaki,1545033484,"I want to try out the Open Images-trained models, specifically the ssd_mobilenetv2_oidv4 model from [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#open-images-trained-models). But the clicking the link tells me that I dont have storage access.  
Anybody have a proper link?",0,1
31,2018-12-17,2018,12,17,18,a6ydsr,Should I set the filter configurations in tf.conv2d() ?,https://www.reddit.com/r/tensorflow/comments/a6ydsr/should_i_set_the_filter_configurations_in_tfconv2d/,Laurence-Lin,1545039447,"I've seen many applied conv2d function as below:  


tf.conv2d(input\_tensor, weights, ...)  


In the document, the second term is filter, but I usually see others set weight for this term.  


Shouldn't I set the filters? I'm confused about it.   


Thanks a lot!",4,1
32,2018-12-18,2018,12,18,20,a7a6at,Is using the class_weight attribute in Keras with the binaey_cross_entropy loss function the same as using a weighted binary_cross_entropy loss function?,https://www.reddit.com/r/tensorflow/comments/a7a6at/is_using_the_class_weight_attribute_in_keras_with/,justAHairyMeatBag,1545131620,"I have a multi-class multi-label problem where each sample could have multiple true labels. I'm using a sigmoid activation function at the output layer, and I'm using the binary cross entropy loss function. I'd like to weight my classes due to the heavy imbalance in the frequency of occurrence of labels.


I noticed that Keras has a 'class_weight' attribute that you can specify in the model.fit_generator() method. According to the docs, it **can be useful to tell the model to pay more attention to samples from an under-represented class.** This sounds like what I want to do. I was wondering if there's a difference between using 'class_weights + binary_cross_entropy loss' and using the weighted binary cross entropy loss defined [here](https://stats.stackexchange.com/questions/303229/why-does-keras-binary-crossentropy-loss-function-return-wrong-values/303254)?",1,1
33,2018-12-18,2018,12,18,23,a7bqrw,Keras uses class_weight attribute only for training loss and not validation loss calculation. Is there a workaround?,https://www.reddit.com/r/tensorflow/comments/a7bqrw/keras_uses_class_weight_attribute_only_for/,justAHairyMeatBag,1545145012,"I'm using the class_weight attribute of the fit_generator in Keras for my unbalanced dataset. While this is reflected clearly in my training loss, validation loss appears to be unaffected. Where before, both losses of my model were in the same neighborhood, upon using class_weights, validation loss is a 1000 times larger than my training loss.


Is there a way around this?


I've found [this](https://github.com/keras-team/keras/issues/496) and [this](https://github.com/keras-team/keras/issues/4137) stale issues on Keras' github repo.


[This](https://datascience.stackexchange.com/questions/22814/class-weighting-during-validation-in-keras) appears to be a solution, but it's using sample_weights, a different attribute that is meant to be used [per sample](https://stackoverflow.com/questions/43459317/keras-class-weight-vs-sample-weights-in-the-fit-generator).


Then there's the option to pass sample_weights as a tuple in the validation_data parameter of fit_generator, but does this mean I have to make a new weights vector each time or does it just make sense to treat sampls_weights as being the same for all samples?",0,1
34,2018-12-19,2018,12,19,11,a7hw0p,Installing tensorflow with pip3 win10,https://www.reddit.com/r/tensorflow/comments/a7hw0p/installing_tensorflow_with_pip3_win10/,raitonnin,1545184904,"Could not find a version that satisfies the requirement tensorflow (from versions: )
No matching distribution found for tensorflow
I tried googling for an answer but i didnt find anything conclusive at all nothing helped. Does anyone know why im not able to ""find the download""",2,1
35,2018-12-19,2018,12,19,12,a7ik2s,TF on Win10 with AMD GPU,https://www.reddit.com/r/tensorflow/comments/a7ik2s/tf_on_win10_with_amd_gpu/,chrninja,1545189803,"Hello Tensorflow community! I have an AMD RX580 and would be interested in using it for computations in Tensorflow. I know that only CUDA is officially supported but I have seen solutions with OpenCL and ROCm but I am rather new in Programming so I would appreciate if someone could link me to a guide. I have seen the stackoverflow question about Keras and Tensorflow. 

Thank you in advance!!",6,1
36,2018-12-19,2018,12,19,14,a7jd0e,Does anyone know how to create a TFRecord file using C++?,https://www.reddit.com/r/tensorflow/comments/a7jd0e/does_anyone_know_how_to_create_a_tfrecord_file/,krishnab75,1545196279,"I have been scouring the internet, Stack Exchange, IRC, and Github trying to find an example of someone writing some C++ code to write data to a TFRecord file. I was hoping to use C++ because I do a lot of image processing in C++ using OpenCV and switching to Python for the last step seems a bit cumbersome. 

&amp;#x200B;

I can write TFRecords files from Python no problem. The advanced is that TF has some helper functions in TF.train that let you encode int64 or Byteslists, etc. But I have found no mention of anyone doing this in C++. 

&amp;#x200B;

If anyone has any suggestions or code samples, or links to code samples, that would really be  appreciated. Thanks. ",2,1
37,2018-12-19,2018,12,19,18,a7l1w1,"In tf.reshape(), if I set the dimension value after reshape as -1, does it means that I don't specify it?",https://www.reddit.com/r/tensorflow/comments/a7l1w1/in_tfreshape_if_i_set_the_dimension_value_after/,Laurence-Lin,1545213204,"I've seen a code do this:

x = tf.placeholder()  
x\_1 = tf.reshape(x, \[-1, 28, 28, 1\])  


For an 4D image, the shape stands for \[batch size, height, width, channels\]. Here since batchsize = -1, does it means that I don't specify it previously?

Thanks.  
",5,1
38,2018-12-21,2018,12,21,5,a82csw,Can the XLA AoT compiler generate GPU accelerated code?,https://www.reddit.com/r/tensorflow/comments/a82csw/can_the_xla_aot_compiler_generate_gpu_accelerated/,_llucid_,1545339283,"I want to do some real-time computer vision workloads off a windows (or linux) desktop with an Nvidia GPU.

I'll be running it via C++ for low-latency deployment, and I'm wondering if I should just use the C++ API or go through the XLA compiler for a performance boost.

The dev summit presentation mentioned the AoT was for mobile deployment, and only generated x86/ARM binaries and C++ interface. Does that mean if I compile with a cuda-enabled windows target, I won't get any GPU acceleration?

&amp;#x200B;",0,1
39,2018-12-21,2018,12,21,12,a85v40,"eval_metric_ops in tf.estimator.EvalSpec does not work properly, or I'm missing something.",https://www.reddit.com/r/tensorflow/comments/a85v40/eval_metric_ops_in_tfestimatorevalspec_does_not/,dchatterjee172,1545362745,"@reedwm  @jmaye 

\`if mode == tf.estimator.ModeKeys.EVAL:\`

\`            a = tf.random.uniform(dtype=tf.int32, maxval=1000, shape=\[\])\`

\`            eval\_metric\_ops = {\`

 \`               ""eval\_mean\_bert\_loss"": tf.metrics.mean(total\_loss\_bert),\`

\`                ""eval\_mean\_original\_loss"": tf.metrics.mean(total\_loss\_original),\`

\`                ""eval\_mean\_loss"": tf.metrics.mean(a)}\`

\`            output\_spec = tf.estimator.EstimatorSpec(\`

\`                mode=mode,\`

\`                loss=a,\`

\`                eval\_metric\_ops=eval\_metric\_ops)\`       



\`eval\_spec = tf.estimator.EvalSpec(input\_fn=eval\_input\_fn, steps=100, start\_delay\_secs=0,

throttle\_secs=120)\`

&amp;#x200B;

\[output\]([https://imgur.com/a/lT92UoU](https://imgur.com/a/lT92UoU))       

\`INFO:tensorflow:Saving dict for global step 2000: eval\_mean\_bert\_loss = 4.9399266, eval\_mean\_loss = 483.38, eval\_mean\_original\_loss = 4.982164, global\_step = 2000, loss = 483.38

\`

how can \`loss\` and \`eval\_mean\_loss\` be exactly same? batch size is 1 here. Shouldn't \`loss\` be the value of \`a\` at 100th batch, and \`eval\_mean\_loss\` be the mean of the all 100 \`a\` ?

&amp;#x200B;

&amp;#x200B;",4,1
40,2018-12-21,2018,12,21,21,a89kva,I can't import tensorflow on jupyternotebook,https://www.reddit.com/r/tensorflow/comments/a89kva/i_cant_import_tensorflow_on_jupyternotebook/,Laurence-Lin,1545395877,"When I import tensorflow library it returns ""there are no tensorflow modules in the package""  
I've check online for helps, but most of it refers to using ananconda to install tensorflow??? 

If it's not necessary, I prefer not using ananconda, since I have python already. Does anyone know how to build tensorflow environment on jupyter notebook?  


Thanks a lot!  
",11,1
41,2018-12-22,2018,12,22,4,a8df00,"How I solved my infinite ""Solving environment"" on windows (Anaconda)",https://www.reddit.com/r/tensorflow/comments/a8df00/how_i_solved_my_infinite_solving_environment_on/,Chrupiter,1545420180,"I'm writing this because maybe someone will find it useful. Yesterday I wanted to install tensorflow on Win7-64bit through Anaconda prompt. I had just installed the latest version of Anaconda, with py3.7. So I executed  

    conda install -c conda-forge tensorflow

and waited for ""Solving environment"", and waited, and waited... After hours still nothing. So I searched online what the problem could be. Nothing I found was useful. Then I decided the create a new environment with python 3.6. And magic, I installed tensorflow with the above command without problems.

&amp;#x200B;",6,1
42,2018-12-22,2018,12,22,21,a8km3j,tf.map_fn() doesn't work as expected,https://www.reddit.com/r/tensorflow/comments/a8km3j/tfmap_fn_doesnt_work_as_expected/,ImaginaryAnon,1545483345,[removed],0,1
43,2018-12-23,2018,12,23,2,a8msae,Tensorflow not finding modules. (Windows 10),https://www.reddit.com/r/tensorflow/comments/a8msae/tensorflow_not_finding_modules_windows_10/,Tormenator1,1545500871,"Hey. I'm pretty new to TensorFlow and am trying to train my first model.  However,when I attempt to begin the training,I get the error in [this](https://imgur.com/a/3tEaTbW) screenshot. I've already manually set the path in the Windows Environment variables,and it still doesn't work,is there anything else I can do to fix this?",7,1
44,2018-12-23,2018,12,23,20,a8u0z4,just have a doubt,https://www.reddit.com/r/tensorflow/comments/a8u0z4/just_have_a_doubt/,yashwatwani28,1545564765," i can't how do we have the accuracy of training data - it should always be 100% if it is their

 i can understand  how we are getting the validation accuracy that we are just checking with the result but how can we get the testing accuracy? ",1,1
45,2018-12-24,2018,12,24,4,a8xngn,Problem with export_savedmodel in Tensorflow v1.12.0,https://www.reddit.com/r/tensorflow/comments/a8xngn/problem_with_export_savedmodel_in_tensorflow_v1120/,Fen007,1545594267,"A few days ago I asked a question on Stackoverflow about Tensorflow, which unfortunately has not been answered yet. Maybe someone has any ideas here ?",0,1
46,2018-12-24,2018,12,24,23,a95go7,Image classification for ONE CATEGORY,https://www.reddit.com/r/tensorflow/comments/a95go7/image_classification_for_one_category/,jango1502,1545662316,"I have set of food images. I want to make a model to detect whether the given test image is of food or not!!
Test images have food images as well as random images that are not food items.  

Is this task possible or not ??

Can I make a model with food images as training images and food+random images as test set?",14,1
47,2018-12-25,2018,12,25,2,a96uti,Intro To Keras U-NET - Nuclei In Divergent Images,https://www.reddit.com/r/tensorflow/comments/a96uti/intro_to_keras_unet_nuclei_in_divergent_images/,AshishKhuraishy,1545672402,,0,1
48,2018-12-26,2018,12,26,11,a9kt6k,How Neural Networks Work- Simply Explained,https://www.reddit.com/r/tensorflow/comments/a9kt6k/how_neural_networks_work_simply_explained/,ailearn12,1545792917,,0,1
49,2018-12-27,2018,12,27,3,a9r7j2,"This video goes over a model that predicts the number of views on a youtube video based on likes, dislikes, and subscribers. Really interesting",https://www.reddit.com/r/tensorflow/comments/a9r7j2/this_video_goes_over_a_model_that_predicts_the/,antaloaalonso,1545850501,,3,1
50,2018-12-27,2018,12,27,13,a9w2fy,Higher learning rate gets stuck in local minima,https://www.reddit.com/r/tensorflow/comments/a9w2fy/higher_learning_rate_gets_stuck_in_local_minima/,codythecoder,1545886394,"I'm writing a fairly basic autoencoder, but after I recently changed  the architecture I found it was outputting pure white images, sometimes after only one epoch. With a higher learning rate (0.0002 with AdamOptimizer) it would always get stuck in this local minima, but with a lower learning rate (0.00002) the learning would be successful. This seems counterintuitive to what I expect; that a higher learning rate would be less likely to get stuck in local minima, at a potential cost of accuracy, but in this case it's only the higher learning rates that get stuck.

Is this a quirk of AdamOptimizer, or would I have to link my code? Obviously I can play around with the learning rate on different datasets/output sizes, but I'd love to be able to not have to change every time I make a major modification.",2,1
51,2018-12-27,2018,12,27,21,a9ywof,"This video goes over a model that predicts the number of views on a youtube video based on likes, dislikes, and subscribers. Really interesting and educative",https://www.reddit.com/r/tensorflow/comments/a9ywof/this_video_goes_over_a_model_that_predicts_the/,antaloaalonso,1545914356,,1,1
52,2018-12-28,2018,12,28,2,aa1fx7,How to loop and add Conv features in tensorflow?,https://www.reddit.com/r/tensorflow/comments/aa1fx7/how_to_loop_and_add_conv_features_in_tensorflow/,satyapk_y12uc231,1545933532,"Basically my input is of size \[BATCH, H,W,C\] and i want to pass it through T(variable) number of convolutional layers, and T can be like 5-100 (its a hyper parameter) and all the conv kernels will be back-propped. Is there a possible way to loop around this ? ",5,1
53,2018-12-29,2018,12,29,15,aaj1tq,Can I train a bot to see if two characters are doing the same thing in two videos?,https://www.reddit.com/r/tensorflow/comments/aaj1tq/can_i_train_a_bot_to_see_if_two_characters_are/,palendrome298,1546066784,"One character jumps in one video 

Other character jumps in other video

Can I use tenserflow to tell if the movement of the two characters are doing the same jumping movement ?",2,1
54,2018-12-29,2018,12,29,19,aak6n3,Tensorflow GPU under utilization on Windows 10,https://www.reddit.com/r/tensorflow/comments/aak6n3/tensorflow_gpu_under_utilization_on_windows_10/,davidshen84,1546078921,"Hi,

&amp;#x200B;

I have GTX 1050 mobile graphic card. I have set up my tensorflow-gpu with conda, and have managed to get my tensorflow code work using GPU.

&amp;#x200B;

In the Windows Task Manager, I found my GPU has two compute engine metric, *compute\_0* and *compute\_1*. But when I try to train my NN, I found only the *compute\_0* took the workload, and the other one was always at rest.

&amp;#x200B;

This makes me wonder if:

1. My system is set up correctly.
2. My code is set up correctly.

Honestly, I am not completely sure if *compute\_0 and* compute\_1 refer to the CUDA core computation workload. Any suggestion about CUDA set up checking and hardware verification are desired.

&amp;#x200B;

https://i.redd.it/r2uba6fsx6721.png",0,1
55,2018-12-29,2018,12,29,23,aalgbp,"What's the best way to get into ML? Well, if you're looking to get your feet wet ASAP, you should consider learning APIs like Keras as opposed to backends like Tensorflow and Theano. Here's a good video that explains exactly what Keras is",https://www.reddit.com/r/tensorflow/comments/aalgbp/whats_the_best_way_to_get_into_ml_well_if_youre/,antaloaalonso,1546092375,,0,1
56,2018-12-30,2018,12,30,0,aam7se,Send me in the right direction?,https://www.reddit.com/r/tensorflow/comments/aam7se/send_me_in_the_right_direction/,gnapoleon,1546098678,"Hi all,

&amp;#x200B;

I've attempted to learn Tensorflow by going through the tutorial a couple of times but I got bored 1/3 of the way through. I learn by doing and the best way for me to comprehend something new is to scratch an itch and work through a real project.

&amp;#x200B;

I'd like to present to you a project idea and hopefully you can send me in the right direction and I can figure out what I need to learn (and maybe you can suggest good resources for that).

&amp;#x200B;

I'll present a postulate that might sound silly, completely preposterous and a dead end but indulge me. I have 1M email addresses  and can associate a binary behavior (has taken an action, has not taken an action) with each row. I am postulating that a system can learn from that set (I have more than 1M pieces of data but that's a start) and tell me if a given email address will exhibit this behavior.

&amp;#x200B;

I believe that email addresses do reveal a bit about the individual behind them. For example [bob.thorton@ibm.com](mailto:bob.thorton@ibm.com) for a given business (say an enterprise product company) will likely exhibit a different behavior than [bob.g.thorton@gmail.com](mailto:bob.g.thorton@gmail.com) as will [bobt94@aol.com](mailto:bobt94@aol.com) and others might be total duds such as [2kdjfskjdf@yahoo.ru](mailto:2kdjfskjdf@yahoo.ru)

&amp;#x200B;

As you can see, I postulate that the structure of the account (bob.thorton, bob.g.thorton, bob94, 2kdjfskjdf) as well as the domain name and possibly the tld or second level domain (.com, .ru, .co.uk, ...) are important to the learning.

&amp;#x200B;

So here are my questions:

1) Should the learning data-set be:

* email address | behavior (boolean)
   * \- i.e. will the system figure out by itself the structure of an email address and look at its different parts as it learns?
* account (bob.thorton) | full domain ([gmail.com](https://gmail.com)) | subdomain and tld (.com, .co.uk) | behavior (boolean)
* email address | account (bob.thorton) | full domain ([gmail.com](https://gmail.com)) | subdomain and tld (.com, .co.uk)  | behavior (boolean)

2) What general type of problem is this, what should I look into?

3) Is the general practice something like: learn on 75% of the data set, test prediction on the last 25% then adjust some kind of threshold to minimize what's important to me (false positive, false negatives?)

4) Is Tensorflow a good thing for me to look at for this type of problem? Or is this more appropriate for a system specialized in word analysis?

5) What should I look at first?

&amp;#x200B;

I hope you can help, I realize these are pretty open-ended questions but I tried to be as specific as possible.

&amp;#x200B;

Happy holidays to all.

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;",4,1
57,2018-12-30,2018,12,30,19,aauszo,Should I use tf.layers or tf.keras?,https://www.reddit.com/r/tensorflow/comments/aauszo/should_i_use_tflayers_or_tfkeras/,davidshen84,1546164827,"I found [this][1] comment in the `tf.layers.Layer` code, which says this class is legacy. But all the `tf.layers.*` classes that derived from this class does not have a similar comment. I know they may not want to copy this line everywhere in the code.

I wonder if in the future the `tf.layers*` namespace will become obsolete, and it is either `tf.nn` to build everything from scratch or `tf.keras` to use the high-level API.


[1]: https://github.com/tensorflow/tensorflow/blob/a6d8ffae097d0132989ae4688d224121ec6d8f35/tensorflow/python/layers/base.py#L40",5,1
58,2018-12-31,2018,12,31,4,aayp3u,The tensorflow install guide is incomplete/misleading,https://www.reddit.com/r/tensorflow/comments/aayp3u/the_tensorflow_install_guide_is/,FlipChicken,1546196898,"https://www.tensorflow.org/install/pip

This doesn't mention which version of CUDA is needed for the gpu version (It's apparently both CUDA 9 *AND* 7.7, for some reason).

Also, following the instructions somehow results in a version of PIP that thinks it's version 18 and version 8 simultaneously and complains about being out of date but won't update.

Finally, it assumes you want to create a virtual environment, but doesn't say why or how to access that environment, and I think it assumes you only want to virtually update PIP.

Could someone who's much more of an expert than I am take a look at that guide and make it less misleading?",15,1
0,2019-1-2,2019,1,2,3,abkalm,Change lstm temperature in tensorflow.js,https://www.reddit.com/r/tensorflow/comments/abkalm/change_lstm_temperature_in_tensorflowjs/,LightBlueParadox,1546366021,"Hi, I'm new to Tensorflow, I'm doing a project to predict notes from MIDI files, loading a trained Keras model to Tensorflow.js. Everything works fine and all, but I 'd like to change the temperature value.

I've read elsewhere that I should divide the logits by the temperature value.

I've tried to divide the output values but it didn't work, I think I should do that before applying the softmax function, but how?",1,1
1,2019-1-3,2019,1,3,2,abvmea,Serving Google BERT in Production using Tensorflow and ZeroMQ  Han Xiao Tech Blog,https://www.reddit.com/r/tensorflow/comments/abvmea/serving_google_bert_in_production_using/,h_xiao,1546451010,,1,1
2,2019-1-3,2019,1,3,9,ac00qq,Trying out Tensorflow JS,https://www.reddit.com/r/tensorflow/comments/ac00qq/trying_out_tensorflow_js/,immortaljoe,1546477099,,2,1
3,2019-1-3,2019,1,3,13,ac1tgf,Cannot use psnr and ssim on TF 1.7,https://www.reddit.com/r/tensorflow/comments/ac1tgf/cannot_use_psnr_and_ssim_on_tf_17/,HudPesjan,1546488906,"I am getting the error message
AttributeError: module 'tensorflow.python.ops.image_ops' has no attribute 'ssim'
Same for psnr. Any help would be greatly appreciated!",1,1
4,2019-1-5,2019,1,5,1,acjio8,"Getting ""TypeError: Expected binary or unicode string"" while running CNN model",https://www.reddit.com/r/tensorflow/comments/acjio8/getting_typeerror_expected_binary_or_unicode/,atinesh229,1546617781,"I am trying to train a simple CNN model for classifying images. I'm trying to classify images from 5 different classes. But while training I'm getting this error

&amp;#x200B;

&gt;TypeError: Expected binary or unicode string, got &lt;tf.Tensor 'Cast/x:0' shape=(17, 150, 220) dtype=float32&gt;

&amp;#x200B;

Detailed error report can be found [here](https://i.postimg.cc/FHQV5FD9/error.png)

&amp;#x200B;

Data directory structure

&amp;#x200B;

&gt;data2/train contains 5 directories corresponding to each class having 17 images of varying resolution  
&gt;  
&gt;data2/test contains 5 directories corresponding to each class having 7 images of varying resolution

&amp;#x200B;

The complete code can be accessed from [here](https://gist.github.com/atinesh-s/facaec2521f7cf9eb927ee2942337092)",7,1
5,2019-1-5,2019,1,5,6,acmnsn,ELI5 Tensorflow Tutorial Question,https://www.reddit.com/r/tensorflow/comments/acmnsn/eli5_tensorflow_tutorial_question/,krizam,1546635961,"I'm working through the [Basic Classification TensorFlow tutorial](https://www.tensorflow.org/tutorials/keras/basic_classification), and I'm able to follow along up until the ""Setup the layers"" section, particularly this chunk of code:

    model = keras.Sequential([
  keras.layers.Flatten(input_shape=(28, 28)),
  keras.layers.Dense(128, activation=tf.nn.relu),
  keras.layers.Dense(10, activation=tf.nn.softmax)
])

I get the keras.layers.Flatten layer flattens the 2D array, but the keras.layers.Dense layer is not making sense to me.  The explanation given is:

&gt;After the pixels are flattened, the network consists of a sequence of two tf.keras.layers.Dense layers. These are densely-connected, or fully-connected, neural layers. The first Dense layer has 128 nodes (or neurons). The second (and last) layer is a 10-node softmax layerthis returns an array of 10 probability scores that sum to 1. Each node contains a score that indicates the probability that the current image belongs to one of the 10 classes.

Can someone explain what the Dense layers are actually doing and how they fit in?

&amp;#x200B;",4,1
6,2019-1-7,2019,1,7,7,adaojq,Varying dimensions in a feed_dict - TensorFlow,https://www.reddit.com/r/tensorflow/comments/adaojq/varying_dimensions_in_a_feed_dict_tensorflow/,bitsofshit,1546813549,"Why is it that something like this works: 

```
with tf.Session() as session:
    x_data = [[1, 2,None],
              [4, 5, 6],
             [4, 5, 6]]
    result = session.run(y, feed_dict={x: x_data})
    print(result)
```

but the following doesn't?

```
with tf.Session() as session:
    x_data = [[1, 2],
              [4, 5, 6],
             [4, 5, 6]]
    result = session.run(y, feed_dict={x: x_data})
    print(result)
```

&gt;&gt;&gt;ValueError: setting an array element with a sequence.",6,1
7,2019-1-7,2019,1,7,14,adeesi,why does parsing CSV turns Original_String into b'Original_String',https://www.reddit.com/r/tensorflow/comments/adeesi/why_does_parsing_csv_turns_original_string_into/,Ludwig0,1546838226,"Here's the code, for example if the Sex value of an example is male then the value in the dataset becomes b'male'

&amp;#x200B;

`fareMax = analysis['Fare'].max()`

`fareMin = analysis['Fare'].min()`

`defaults = [[], [], [], [''], [''], [float(0.0)], [], [], [""""], [], [""""], ['']]`

&amp;#x200B;

`def parse_line(line):`

`vals = tf.decode_csv(line, defaults)`

`#makes lowest value a 0 rather than a 1 for feature col one-hot`

`vals[2] = vals[2] - 1`

`#normalize`

`vals[9] = (vals[9]-fareMin)/(fareMax-fareMin)`

&amp;#x200B;

`features = dict(zip(all_cols, vals))`

`for col in remove_cols:`

`features.pop(col)`

`label = features.pop('Survived')`

`return features, label`

`dataset = dataset.map(parse_line)`

`iter = dataset.make_initializable_iterator()`

`init_op = iter.initializer`

`batch = iter.get_next()`",1,1
8,2019-1-7,2019,1,7,18,adfz59,Low GPU usage when training,https://www.reddit.com/r/tensorflow/comments/adfz59/low_gpu_usage_when_training/,TheBrightman,1546852191,"Hi all,

when I'm training my model (A DQN to play Atari Games) I am trying to train it on my GPU (A gtx 960). I have correctly installed CUDA 9.0, Tensorflow-gpu and cuDNN and can verify that TF can 'see' my GPU.

However when I train my model I rarely use over **7% of my GPU** according to task manager.

Is there something I can do about this so TF uses more of my GPU an trains faster? Thanks!",5,1
9,2019-1-7,2019,1,7,20,adgu8y,During restoring model in tensor-flow does the trained weights change?,https://www.reddit.com/r/tensorflow/comments/adgu8y/during_restoring_model_in_tensorflow_does_the/,danishxr,1546860589,"So I have trained a model using tensorflow low level api. Restored the *.meta* and the .*data files. Now* to predict on new images/data I have to reload the weights again and again,for each time I want to predict. So does this change my pre trained weights value in the graph.

&amp;#x200B;",2,1
10,2019-1-7,2019,1,7,20,adgy94,Using scaled data during training causing issues in prediction,https://www.reddit.com/r/tensorflow/comments/adgy94/using_scaled_data_during_training_causing_issues/,Senior1292,1546861682,"I've built a model using Keras for a regression problem, have saved it and now need to use the model for making predictions. I have one main issue now. It is my understanding that NNs will generally be more accurate if the training data is scaled between 0 and 1, and doing so produces a much lower MSE using sklearn's MinMaxScaler, however,  I then want to use the model for prediction in a separate script, and I no longer have access to the scaler to scale the inputs and invert the scaling for the output. What is the best way around this issue? Should I import the training data and generate a scaler the first time the model is run or is there a better solution? 

&amp;#x200B;

&amp;#x200B;",2,1
11,2019-1-7,2019,1,7,21,adh8zf,Converting a TensorFlow model to Keras model,https://www.reddit.com/r/tensorflow/comments/adh8zf/converting_a_tensorflow_model_to_keras_model/,shakkeel,1546864377,Is it possible to convert a TF model to Keras model? Is there any method available in TF package for this?,2,1
12,2019-1-8,2019,1,8,1,adj5id,Training with ridiculously small learning rate still diverges,https://www.reddit.com/r/tensorflow/comments/adj5id/training_with_ridiculously_small_learning_rate/,ptrkhh,1546877596,"Here is the problem: https://imgur.com/a/w5DOt7W

I just finished a 2-day long learning on a GPU, with a ridiculously small learning rate of 2.5e-10, and somehow it still diverges. I have tried larger learning rate and they all diverged far before this one, which is I kept reducing the learning rate and increasing the epoch, but I am not sure if I should continue at this point.

The attributes are as follows:

* Optimizer: Adam
* Learning Rate: 2.5e-10
* Input: 10001 floating point numbers (words, word2vec)
* Output: Number of up to 1000 (gigabyte of SSD)
* Loss: MSE
* Metric: MAE
* Layers: Dense layers of 5000, 2000, 250

*Background: This is basically a ML model that learns from r/buildapcforme, where the user could just give their descriptions and budget, and the system generates the recommended computer setup. At the moment the output is just the SSD.*

What's particularly interesting is both the train and validation error are nearly the same (yay), but they both diverges after ~450k epoch (nay).

Alternatively, is there a way for the learning rate to be adjusted dynamically, so I could get to the ""critical point"" much sooner (basically the first 400k epoch), and then reduce the learning rate afterwards?",7,1
13,2019-1-8,2019,1,8,8,adnwlo,Tensor flow agnostic to edge platform,https://www.reddit.com/r/tensorflow/comments/adnwlo/tensor_flow_agnostic_to_edge_platform/,tinkstockman,1546904782,"Hi all!

&amp;#x200B;

Can i run tensorflow on top of Azure ML to intelligently coordinate programs?  (e.g i have an edge system in which i use Azure edge run time with Azure ML but also want to use tensorflow) I have a Non-technical background but am super fascinated by distributed / decentralized systems. 

&amp;#x200B;

Sort of confused because the documentation for greengrass and Azure edge both claim they support Tensorflow but they offer their own ML at the same time? CS background would for sure be helpful here, but the brilliant minds of reddit will have to suffice! 

&amp;#x200B;

Thanks yall! ",1,1
14,2019-1-8,2019,1,8,11,adpkge,For what applications -- if any -- would you develop your own neural network instead of using TensorFlow?,https://www.reddit.com/r/tensorflow/comments/adpkge/for_what_applications_if_any_would_you_develop/,angry_cactus,1546915099,,0,1
15,2019-1-8,2019,1,8,15,adrinl,Help with following tutorial,https://www.reddit.com/r/tensorflow/comments/adrinl/help_with_following_tutorial/,tundrat,1546929243,"I'm currently trying to do [this](https://medium.com/tensorflow/tf-jam-shooting-hoops-with-machine-learning-7a96e1236c32). And I don't think I had big issues on installing the required things and following instructions on using the scripts. But the aiming doesn't seem to work at all.  
With the randomly teleporting mode, I just get 5% in. When I'm manually moving it around with keyboard, it seems to think the goal is in a random different place. Sometimes aiming next to the goal, sometimes shooting super far away out of the court.  
Even with the default training file that was in the source code, or something I trained for 2 hours, or a few seconds. It makes no difference.",0,1
16,2019-1-8,2019,1,8,23,adul2r,Concatenate an input before Dense layer. [Keras with TF backend],https://www.reddit.com/r/tensorflow/comments/adul2r/concatenate_an_input_before_dense_layer_keras/,phoenixlads,1546957039,"So, I need to concatenate an input to the flattened layer before going in the dense layer. 

I'm using Keras with TF as backend. 

    model.add(Flatten())
aux_input = Input(shape=(1, ))
model.add(Concatenate([model, aux_input]))
model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))

&amp;#x200B;

How do I add this aux\_input to the model while doing model.fit?",3,1
17,2019-1-9,2019,1,9,1,advvsy,Can i use a python file instead of a model in Tensorflow Serving?,https://www.reddit.com/r/tensorflow/comments/advvsy/can_i_use_a_python_file_instead_of_a_model_in/,thatsadsid,1546964715,"In tensorflow serving, there is an option to use an existing model (saved by [builder.save](https://builder.save)()) that can accept input data and give predictions or output. But, i have a python file which will accept data, do some processing and return the output. Is it possible to do that?

&amp;#x200B;

I do not think i can convert my python file to an ML Object, i am wondering what are the options here. 

&amp;#x200B;

&amp;#x200B;",0,1
18,2019-1-9,2019,1,9,6,adz616,Hyperparameter Tuning CloudML,https://www.reddit.com/r/tensorflow/comments/adz616/hyperparameter_tuning_cloudml/,saikjuan,1546982899,"Hello everyone!

I've been trying to use Google CloudML to do hyperparameter tuning on the cloud. My code starts, but I can't make it work the same as in the examples. 

I see that [Google's Tutotial](https://github.com/GoogleCloudPlatform/cloudml-samples/tree/90005b4378dbc03ebeb7e53277ccbe9592292c06/census) makes CloudML create 4 folders in which it stores all the runs. This allows me to visualize the runs on Tensorboard. 

&amp;#x200B;

Do you know any other tutorial or examples in which I can use a custom estimator (using tf.layers) to run Hyperparameter tuning in CloudML?

&amp;#x200B;

Thanks in advance. 

&amp;#x200B;",3,1
19,2019-1-9,2019,1,9,11,ae24g8,Train a tensorflow lite model to detect plant diseases and integrate it in an android app,https://www.reddit.com/r/tensorflow/comments/ae24g8/train_a_tensorflow_lite_model_to_detect_plant/,navneet7k,1547000849,,0,1
20,2019-1-9,2019,1,9,12,ae2qwh,Gesture controlled 2048 using TensorFlow.js,https://www.reddit.com/r/tensorflow/comments/ae2qwh/gesture_controlled_2048_using_tensorflowjs/,jithurjacob,1547005046,,0,1
21,2019-1-9,2019,1,9,19,ae5qkw,Scaling machine learning in the cloud with Kubernetes and Kubeflow,https://www.reddit.com/r/tensorflow/comments/ae5qkw/scaling_machine_learning_in_the_cloud_with/,SoulmanIqbal,1547031148,,0,1
22,2019-1-10,2019,1,10,1,ae8ows,Combining Tfrecords and Keras,https://www.reddit.com/r/tensorflow/comments/ae8ows/combining_tfrecords_and_keras/,smokrow,1547052645,,0,1
23,2019-1-10,2019,1,10,12,aeexjz,Eager Execution Mode,https://www.reddit.com/r/tensorflow/comments/aeexjz/eager_execution_mode/,abhirammv,1547090663,"I created a model using `tf.keras` on google colab. Trained it, saved it and downloaded the model (hdf5 file) for local testing. 

During testing I noticed that one of the options is that I had to run Im eager exec to get my predictions. 

Im curious about learning the performances (time and memory) about deploying a model as an api that uses eager_exec mode to make predictions vs uses a session to make predictions. Let me know what you guys think. Thanks! ",1,1
24,2019-1-11,2019,1,11,2,aelicw,TensorflowJS bounding boxes?,https://www.reddit.com/r/tensorflow/comments/aelicw/tensorflowjs_bounding_boxes/,Muzzles56,1547142919,"Hi everyone, I'm new to learning about Tensorflow and am working with TensorflowJS (Not python) and I hope this is the right place to post this.

I have set up a project where I upload a model's JSON and weights file, then use this model to predict uploaded pictures (one at a time.) I'm wondering if it's possible for TFJS to produce bounding boxes when predicting? I can't seem to find much when googling this question.",6,1
25,2019-1-11,2019,1,11,14,aesae0,convert videos (eg. .avi) to TensorFlow's tfrecords file format,https://www.reddit.com/r/tensorflow/comments/aesae0/convert_videos_eg_avi_to_tensorflows_tfrecords/,whiletrue2,1547185639,,0,1
26,2019-1-11,2019,1,11,17,aetdzr,Retraining a pretrained model,https://www.reddit.com/r/tensorflow/comments/aetdzr/retraining_a_pretrained_model/,EmotionC12,1547195462,"Hi, I am hoping I can get some way ahead with my project.
I have completed training with the use of a pretrained model. It yields a high accuracy with the object of my choice say Object A.However, now I would like to train another object of my choice, object B. 
How do I go about training the model so that it learns how to identify object B without forgetting object A? 

Do I change the fine tune checkpoint and replace it with the checkpoint file that contains object A? 

Do I change the TF records and continue training on the model that has learned how to identify object A, modifying the config file, pbtxt and generate_tfrecords.py? 

Any help is deeply appreciated.",1,1
27,2019-1-12,2019,1,12,2,aexv5r,Tips for implementing SSD Object Detection (with TensorFlow code),https://www.reddit.com/r/tensorflow/comments/aexv5r/tips_for_implementing_ssd_object_detection_with/,sabalaba,1547228859,,1,1
28,2019-1-13,2019,1,13,4,afak9h,Estimators in TF 2.0,https://www.reddit.com/r/tensorflow/comments/afak9h/estimators_in_tf_20/,_spicyramen,1547320447,"Recently a preview of TF 2.0 was announced, we use tf.estimator.DNNLinearCombinedClassifier but there is no replacement in TF 2.0 yet, what is the best suggestion? How to build the previous Wide n Deep in this new Keras first world?",5,1
29,2019-1-14,2019,1,14,8,afpmlx,How to make Keras (TF Backend) use the GPU on the computer I built for ML?,https://www.reddit.com/r/tensorflow/comments/afpmlx/how_to_make_keras_tf_backend_use_the_gpu_on_the/,apsjdfkajlkn88n,1547423802,I just build a new Windows 10 computer and with \[these\]([**https://pcpartpicker.com/user/vartin55/saved/**](https://pcpartpicker.com/user/vartin55/saved/)**) parts**,4,1
30,2019-1-14,2019,1,14,21,afvgqh,Making a stamp that the Project idea is good to the invigilator of project based on People Tracking,https://www.reddit.com/r/tensorflow/comments/afvgqh/making_a_stamp_that_the_project_idea_is_good_to/,arya_minus,1547469893,,1,1
31,2019-1-15,2019,1,15,3,afylub,TensorFlow/Keras for Non-Python developers,https://www.reddit.com/r/tensorflow/comments/afylub/tensorflowkeras_for_nonpython_developers/,_spicyramen,1547489939,"I'm a Java/C# Developer, I have heard a lot of buzz regarding TF 2.0/Keras.

My understanding was that Keras is already integreated into TF and TF 2.0 will be a Keras-first framework.

Being a Java developer, does it mean I need to learn Python to use it? Java documentation in TF for Java Developers and samples seems to be very limited. 

[https://www.tensorflow.org/api\_docs/java/reference/org/tensorflow/package-summary](https://www.tensorflow.org/api_docs/java/reference/org/tensorflow/package-summary)

&amp;#x200B;

Today according to some research we have 21M Developers, only 10K ML Experts, if Google is serious about bringing this huge group into ML, we should make it Language agnostic. (Yes, even though Python continues to grow)

&amp;#x200B;",3,1
32,2019-1-15,2019,1,15,15,ag5hcr,TensorFlow JS - Distribute Workload to users?,https://www.reddit.com/r/tensorflow/comments/ag5hcr/tensorflow_js_distribute_workload_to_users/,MrWhatever0,1547532483,"So I have a model that i want to train to get smarter, sure i could throw it more datasets to train off of but the problem comes with machine power and time. I was wondering though, could I use Tensorflow JS to distribute the workload? Lets say I have a blog and while users read my stuff, with their permission, can use their PC's power to help train my models. Is this possible?",1,1
33,2019-1-15,2019,1,15,23,ag93e0,Pinsta Cloud- GPU Instance starting at $0.16/hr,https://www.reddit.com/r/tensorflow/comments/ag93e0/pinsta_cloud_gpu_instance_starting_at_016hr/,sarakomia,1547562920," 

Hi all!

Sara from Pinsta cloud team .We are excited to offer you **GPU instance** starting at **$0.16/hr**.

Get Jupyter Notebooks supported by powerfull GPUs.

For more info. visit out website [Pinstacloud ](https://pinstacloud.com/)

We are in beta,so limited instance. New users will get **3 hours extra**.

 Read our [blog ](https://pinstacloud.com/steps/f/steps) for more info on GPU. 

Questions/feedback are welcome.",1,1
34,2019-1-16,2019,1,16,3,agbre0,Whats coming in TensorFlow 2.0,https://www.reddit.com/r/tensorflow/comments/agbre0/whats_coming_in_tensorflow_20/,nemesis128,1547578081,[https://medium.com/tensorflow/whats-coming-in-tensorflow-2-0-d3663832e9b8](https://medium.com/tensorflow/whats-coming-in-tensorflow-2-0-d3663832e9b8),5,1
35,2019-1-17,2019,1,17,0,agm2ex,Placeholder feedict - Invalid type error,https://www.reddit.com/r/tensorflow/comments/agm2ex/placeholder_feedict_invalid_type_error/,bitsofshit,1547651578,"Seems error comes from last line of code (sess.run) , but all values going into feedict are floats? Have posted declared variables in comment as well.

InvalidArgumentError: You must feed a value for placeholder tensor 'y_3' with dtype float [[node y_3 (defined at &lt;string&gt;:4) = Placeholder[dtype=DT_FLOAT, shape=&lt;unknown&gt;, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]] Caused by op u'y_3', defined at: ...
with tf.name_scope('Loss'):
    l = 0.01     #Regularization term
    r_add = l*((W_C2 * W_C2) + (W_O2 * W_O2)) # lambda const * sum(weights^2)
    cost1 = tf.reduce_mean(-tf.reduce_sum(output*tf.log(pred), reduction_indices=1))
    learning_rate = 0.1

...

with tf.name_scope('SGD'):
    optimizer1 = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost1)

...

for epoch in range(n_epochs):
    for (x, y, r, o, c) in dataSetUse:
        x = float(x)
        y = float(y)
        r = float(r)
        o = float(o)
        c = float(c)
        sess.run(optimizer1, feed_dict={X: x, Y: y, R: r, C: c, O: o})",2,1
36,2019-1-17,2019,1,17,23,agy4hw,Looking for a very specific version of TensorFlow. Need help!,https://www.reddit.com/r/tensorflow/comments/agy4hw/looking_for_a_very_specific_version_of_tensorflow/,lickmyspaghetti,1547734274,"I have a Jetson TX2 board with aarch64 architecture, running Ubuntu OS (64bit). The on board free memory is around 5GB, and I wanted to download the GPU version of Tensorflow. 

I have CUDA 8.0 and CuDNN 5, which I had after flashing the board using Jetpack 3.0, and I tried to install TensorFlow for Python3.5.2 for my board as per the instructions provided here: https://docs.nvidia.com/deeplearning/dgx/install-tf-jetsontx2/index.html

This did not work because of mismatch in CUDA and CuDNN version (they were expecting CUDA 9.0 and CuDNN v6).

I have some important data that would be hard for me to backup and reinstall the entire OS just to upgrade the CUDA version, but am ready to do so if required.

I wanted to know if there is any specific version of TensorFlow available for my board. If it isn't, is there any CPU version of TensorFlow out there?

My second option would be to only upgrade CUDA and CuDNN using Jetpack 3.3 somehow, if this is possible. 

I had seen a couple of links where there was an option to install tf for python2, but I would prefer a solution for python3, and want to keep tf for python2 as a last resort.",3,1
37,2019-1-18,2019,1,18,5,ah1uoc,[Question] Tensorflow model to Tensorflowjs model. Visualize activations in browser.,https://www.reddit.com/r/tensorflow/comments/ah1uoc/question_tensorflow_model_to_tensorflowjs_model/,phoenixlads,1547755596,"So, I have a frozen model (mobilenet.pb). I wanted to convert this model to use in Tensorflowjs. When I run the Tensorflowjs converter, I only get weights\_manifold.json, .pb, and four shards. 

I used these models in Tensorflowjs using tf.loadFrozenModel(path-to-pb-file, path-to-weights-maifold.json). These does get me an object which has some more objects like weights, inputs, outputs. and this weights object has all the layer information. 

Further I want to visualize the activations and weights of the model. How can I do this with the current obtained model that I get. 

Or, if someone can help with visualizing the activations and weights in Tensorflow, it would be much appreciated. ",1,1
38,2019-1-18,2019,1,18,8,ah47ou,Feedict value in tf,https://www.reddit.com/r/tensorflow/comments/ah47ou/feedict_value_in_tf/,bitsofshit,1547768889,"Been stuck forever on this, problem stems from passing in a feedict to the algorithm. Claims output placeholder is not being initialized properly, which I believe comes from an incorrect return value?

Using logistic regression with 6 labels

Placeholders, weights, and bias are all assigned the following types:
```
        * X = tf.placeholder(tf.float32, name=""x"")
        * W_X1 = tf.Variable(tf.constant(1.0, shape = [1]), name='weight_x1')    
        * B1 = tf.Variable(tf.constant(1.0, shape = [1]), name='bias1')
```

    R_pred1 = tf.add(B1, 0)
    R_pred1 = tf.add(tf.multiply(X, W_X1), R_pred1)
    R_pred1 = tf.add(tf.multiply(Y, W_Y1), R_pred1)
    R_pred1 = tf.add(tf.multiply(C, W_C1), R_pred1)
    R_pred1 = tf.add(tf.multiply(O, W_O1), R_pred1)
    R_pred1 = tf.add(tf.multiply(tf.sqrt(C), W_C2), R_pred1)
    R_pred1 = tf.add(tf.multiply(tf.sqrt(O), W_O2), R_pred1)
    
    n_epochs = 2000
    
    with tf.name_scope('Loss'):
       #Regularization term 
       l = 0.01
       r_add = l*((W_C2 * W_C2) + (W_O2 * W_O2))
       cost1 = tf.reduce_sum(tf.pow(R_pred1 - R, 2)) + r_add
       
       
    learning_rate = 0.1
    
    with tf.name_scope('SGD'):
       optimizer1 = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost1)

`Traceback (most recent call last): File ""test.py"", line 256, in &lt;module&gt; training_cost1 = sess.run(cost1, feed_dict={X: dataItems[0], Y: dataItems[1], R: dataItems[2], C: dataItems[4], O: dataItems[3]})`

`...`

`Tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feeda value for placeholder tensor 'Placeholder' with dtype float and shape [?,6] [[node Placeholder (defined at test.py:135)  = Placeholderdtype=DT_FLOAT, shape=[?,6], _device=""/job:localhost/replica:0/task:0/device:CPU:0""]]`

`Caused by op u'Placeholder', defined at: File ""test.py"", line 135, in &lt;module&gt; output = tf.placeholder(tf.float32, [None, 6]) # 0-9 digits recognition=&gt; 10 classes`

As a sidenote - debugging tensorflow is about the most painful experience I've ever had, ipdb and pdb were useless in attempting to dig out the problem source.",6,1
39,2019-1-18,2019,1,18,22,ahagpn,TensorFlow.js - Gesture Controlled 2048 Game,https://www.reddit.com/r/tensorflow/comments/ahagpn/tensorflowjs_gesture_controlled_2048_game/,jithurjacob,1547818297,,1,1
40,2019-1-19,2019,1,19,6,ahf4ne,Haskell for Artificial Intelligence,https://www.reddit.com/r/tensorflow/comments/ahf4ne/haskell_for_artificial_intelligence/,maikronian,1547846242,"Haskell is good for IA? I was reading some articles and they propose Python with TensorFlow, but I want to build the algorithms from scratch, does Haskell do a good job for that?",4,1
41,2019-1-19,2019,1,19,22,ahm9n9,Trouble using tensorflow-gpu in Ubuntu 18.04,https://www.reddit.com/r/tensorflow/comments/ahm9n9/trouble_using_tensorflowgpu_in_ubuntu_1804/,atinesh229,1547906199,"I am trying to configure \`tensorflow-gpu\` in \`Ubuntu 18.04.1 LTS\`. I have followed the below steps successfully

1. Installed CUDA 10 ([https://developer.nvidia.com/cuda-downloads](https://developer.nvidia.com/cuda-downloads))
2. Installed cuDNN ([https://developer.nvidia.com/rdp/cudnn-download](https://developer.nvidia.com/rdp/cudnn-download))
3. Set cuda path in `~/.bashrc` to

`export PATH=/usr/local/cuda-10.0/bin${PATH:+:${PATH}}`

`export LD_LIBRARY_PATH=/usr/local/cuda-10.0/lib64:${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}`

4.   Installed `tensorflow_gpu` in virtual environment

    $ virtualenv --system-site-packages -p python3 tensorflow_gpu_env
    $ source tensorflow_gpu_env/bin/activate
    $ pip3 install --upgrade tensorflow-gpu

But still when I try to import tensorflow 

        $ import tensorflow as tf

I get this error

`ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory`

[Detailed Error](https://paste.ofcode.org/wesQuyDLiGD8Vux4acgw5q)",11,1
42,2019-1-20,2019,1,20,2,aho5qv,Tensorflow 2.0: Keras is not (yet) a simplified interface to Tensorflow,https://www.reddit.com/r/tensorflow/comments/aho5qv/tensorflow_20_keras_is_not_yet_a_simplified/,pgaleone,1547919389,,0,1
43,2019-1-21,2019,1,21,1,ahz8g9,"Best approach for ""magic-word""-recognition?",https://www.reddit.com/r/tensorflow/comments/ahz8g9/best_approach_for_magicwordrecognition/,goodiegoodgood,1548002499,"Hi everyone!

 I'm new to tensorflow (or any kind of machine learning really) and I want to wet my feet with a very basic project.   
I want to train a graph that is specialized in recognizing a single word out of (potentially) many or to distinguish this particular word from background noise.

Basically what is the best way to train a ""magic-word""-graph like the one (probably) used by Amazon and Google in order for their system to react to ""Ok Google"" and ""Alexa""? ",4,1
44,2019-1-21,2019,1,21,5,ai1tsr,Help with Matrix Mathematics,https://www.reddit.com/r/tensorflow/comments/ai1tsr/help_with_matrix_mathematics/,pdodd9,1548015477,"I am currently beginning to learn about Tensorflow.js and machine learning in general, and have begun the very-helpful series by The Coding Train https://www.youtube.com/playlist?list=PLRqwX-V7Uu6YIeVA3dNxbR9PYj4wV31oQ .

My question to those with experience is two-fold: have you personally found that there is value to having a good understanding of math involving matrices? And, if so, do you have any learning resources regarding it that you would recommend?

For context, while I've been programming for a while now, my knowledge of mathematics is currently pretty lacking, and I'd like to go ahead and do something about that roadblock now rather than be frustrated later, if it will be an issue.

Thanks, and please dont hesitate to provide any other insight that would be useful for someone just starting out with machine learning / tensorflow.",4,1
45,2019-1-21,2019,1,21,6,ai2ton,Does retraining preserve previous labels for object detection?,https://www.reddit.com/r/tensorflow/comments/ai2ton/does_retraining_preserve_previous_labels_for/,mahirsowad3,1548021188,"I am fairly new to tensorflow retraining and object detection. When retraining an object detection model such as ssd mobilenet or inception, it doesnt seem to detect labels that it was previously trained one during its pretraining phase. It only identifies the object I refrained on. How do I go about retraining so that it retains previous labels while still being able to detect the retrained labels, or is this even possible? 

Thanks, Appreciate all the help that I can get.",1,1
46,2019-1-21,2019,1,21,9,ai4bjt,Batch image extract tool?,https://www.reddit.com/r/tensorflow/comments/ai4bjt/batch_image_extract_tool/,sqlcook,1548030289,"Hey, i'm working on my first image recognition solution and I've extracted a lot of training images from a video. There are multiple objects that I need classify and I would need to process a lot of these screenshots and extract specific objects out. Does anyone know a good tool that allows for this with a GUI ( specifically selector + copy workflow), I wrote my own using CV2 where i iterate over images with cv2.imshow() along with setMouseCallback() event, it works but its a bit sluggish. 

Looking for a better/faster workflow for extracting images , thanks!

I'm on a Mac but if theres a good tool for Windows/Linux i could look into that as well.",5,1
47,2019-1-21,2019,1,21,16,ai7q74,how to install tensor flow which can take advantage of my nvdia graphic card ?,https://www.reddit.com/r/tensorflow/comments/ai7q74/how_to_install_tensor_flow_which_can_take/,Consiouswierdsage,1548055231,i am trying to install tensor flow gpu version or idk wat its called. i wana make tensor flow use my gpu for processing. please provide me a valid working guide or intructions . ,7,1
48,2019-1-21,2019,1,21,23,aiaf8s,Why is there a problem when loading saved weights on a model,https://www.reddit.com/r/tensorflow/comments/aiaf8s/why_is_there_a_problem_when_loading_saved_weights/,Atralb,1548079831,"Hi guys :),

&amp;#x200B;

I'm losing hope. Please if somebody could help me... I'd be very grateful

Everything is thoroughly explained here : [https://stackoverflow.com/questions/54291381/why-is-there-a-problem-when-loading-saved-weights-on-a-model](https://stackoverflow.com/questions/54291381/why-is-there-a-problem-when-loading-saved-weights-on-a-model)

&amp;#x200B;

Thanks in advance !",5,1
49,2019-1-22,2019,1,22,1,aibnkr,HELP! NaN from cost function,https://www.reddit.com/r/tensorflow/comments/aibnkr/help_nan_from_cost_function/,SqrlyWrath,1548087757,"I am quite new to tensorflow and am trying to build my first ANN. I have been following tutorials online on the structure of the network and I have most of the code setup (using the python API) but I keep getting NaN values for my cost function.

&amp;#x200B;

I am using 3 hidden layers to convert a 20 component input vector to a single output value (all floats).

&amp;#x200B;

Here is the setup and execution of the code:

[https://imgur.com/rJZZPO7](https://imgur.com/rJZZPO7)

&amp;#x200B;

Here is the cost function:

[https://imgur.com/a/oUqOwWB](https://imgur.com/a/oUqOwWB)

&amp;#x200B;

And the output when I run the code:

[https://imgur.com/a/EtpvxgA](https://imgur.com/a/EtpvxgA)

&amp;#x200B;

I've been going around in circles on this so any help would be greatly appreciated!",5,1
50,2019-1-22,2019,1,22,8,aigces,Why are there so many ways to make a NN in tf?,https://www.reddit.com/r/tensorflow/comments/aigces/why_are_there_so_many_ways_to_make_a_nn_in_tf/,Ludwig0,1548112634,"You can use estimators, keras, layers, or handmake the graph. What's the point of having so many ways?",9,1
51,2019-1-22,2019,1,22,13,aij5v9,How to get ouput of last conv layer from mobilenet on mobile device?,https://www.reddit.com/r/tensorflow/comments/aij5v9/how_to_get_ouput_of_last_conv_layer_from/,hamir_s,1548131479,"As the question suggests, I want the output (vector of size 1024) of last conv layer of mobilenet or the output of mobilenet without the softmax layer. How can I do this in the android app itself?",2,1
52,2019-1-22,2019,1,22,17,ail0c4,How to get output from internal nodes of mobilenet in Android?,https://www.reddit.com/r/tensorflow/comments/ail0c4/how_to_get_output_from_internal_nodes_of/,hamir_s,1548147392,"I want the output of last conv2d node when an image is passed to classifier. It seems that it is impossible to get an image vector from mobilenet on android.

If someone has done this or knows how to do it, please help. I have tried the following:

Tensor last\_conv\_2d =  tfLite.getOutputTensor(tfLite.getOutputIndex(""MobilenetV1/Logits/Conv2d\_1c\_1x1/Conv2D""));  
Log.*d*(""feature vector size"", ""res"" + last\_conv\_2d.numElements());

&amp;#x200B;

But I get an illegal argument exception.

java.lang.IllegalArgumentException: Input error: 'MobilenetV1/Logits/Conv2d\_1c\_1x1/Conv2D' is not a valid name for any output. Names of outputs and their indexes are {MobilenetV1/Predictions/Reshape\_1=0}

&amp;#x200B;

It seems that getting the output of the last layer is only possible (i.e. ""MobilenetV1/Predictions/Reshape\_1"") since the list shown in the exception also contains the last node name only.",0,1
53,2019-1-23,2019,1,23,9,aitlvo,Tensorflow Serving with S3 and Docker,https://www.reddit.com/r/tensorflow/comments/aitlvo/tensorflow_serving_with_s3_and_docker/,Holmes89,1548202864,"Im trying to find a way to use Tensorflow serving with the ability to add new models and new versions of models. Can I point tensorflow serving to an S3 bucket?

Also I need it to run as a container? Is this possible or do I need to implement another program to pull down the model and add it to a shared volume and ask tensorflow to update models in the file system?",3,1
54,2019-1-23,2019,1,23,22,aizozz,Why is tf.gradients returning None in this simple code?,https://www.reddit.com/r/tensorflow/comments/aizozz/why_is_tfgradients_returning_none_in_this_simple/,errminator,1548250117,,16,1
55,2019-1-24,2019,1,24,12,aj823l,"Tensorflow says ""Failed to load the native Tensorflow runtime""",https://www.reddit.com/r/tensorflow/comments/aj823l/tensorflow_says_failed_to_load_the_native/,SuperJMan64,1548299372,"(venv) C:\\&gt;python -c ""import tensorflow as tf; tf.enable\_eager\_execution(); print(tf.reduce\_sum(tf.random\_normal(\[1000, 1000\])))""

Traceback (most recent call last):

  File ""C:\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow\_internal.py"", line 18, in swig\_import\_helper

fp, pathname, description = imp.find\_module('\_pywrap\_tensorflow\_internal', \[dirname(\_\_file\_\_)\])

  File ""C:\\venv\\lib\\[imp.py](https://imp.py)"", line 296, in find\_module

raise ImportError(\_ERR\_MSG.format(name), name=name)

ImportError: No module named '\_pywrap\_tensorflow\_internal'

&amp;#x200B;

During handling of the above exception, another exception occurred:

&amp;#x200B;

Traceback (most recent call last):

  File ""C:\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow.py"", line 58, in &lt;module&gt;

from tensorflow.python.pywrap\_tensorflow\_internal import \*

  File ""C:\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow\_internal.py"", line 28, in &lt;module&gt;

\_pywrap\_tensorflow\_internal = swig\_import\_helper()

  File ""C:\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow\_internal.py"", line 20, in swig\_import\_helper

import \_pywrap\_tensorflow\_internal

ModuleNotFoundError: No module named '\_pywrap\_tensorflow\_internal'

&amp;#x200B;

During handling of the above exception, another exception occurred:

&amp;#x200B;

Traceback (most recent call last):

  File ""&lt;string&gt;"", line 1, in &lt;module&gt;

  File ""C:\\venv\\lib\\site-packages\\tensorflow\\\_\_init\_\_.py"", line 24, in &lt;module&gt;

from tensorflow.python import pywrap\_tensorflow  # pylint: disable=unused-import

  File ""C:\\venv\\lib\\site-packages\\tensorflow\\python\\\_\_init\_\_.py"", line 49, in &lt;module&gt;

from tensorflow.python import pywrap\_tensorflow

  File ""C:\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow.py"", line 74, in &lt;module&gt;

raise ImportError(msg)

ImportError: Traceback (most recent call last):

  File ""C:\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow\_internal.py"", line 18, in swig\_import\_helper

fp, pathname, description = imp.find\_module('\_pywrap\_tensorflow\_internal', \[dirname(\_\_file\_\_)\])

  File ""C:\\venv\\lib\\[imp.py](https://imp.py)"", line 296, in find\_module

raise ImportError(\_ERR\_MSG.format(name), name=name)

ImportError: No module named '\_pywrap\_tensorflow\_internal'

&amp;#x200B;

During handling of the above exception, another exception occurred:

&amp;#x200B;

Traceback (most recent call last):

  File ""C:\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow.py"", line 58, in &lt;module&gt;

from tensorflow.python.pywrap\_tensorflow\_internal import \*

  File ""C:\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow\_internal.py"", line 28, in &lt;module&gt;

\_pywrap\_tensorflow\_internal = swig\_import\_helper()

  File ""C:\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow\_internal.py"", line 20, in swig\_import\_helper

import \_pywrap\_tensorflow\_internal

ModuleNotFoundError: No module named '\_pywrap\_tensorflow\_internal'

&amp;#x200B;

&amp;#x200B;

Failed to load the native TensorFlow runtime.

&amp;#x200B;

See [https://www.tensorflow.org/install/errors](https://www.tensorflow.org/install/errors)

&amp;#x200B;

for some common reasons and solutions.  Include the entire stack trace

above this error message when asking for help.

&amp;#x200B;

I did everything the pip install guide asked of me. What is the problem? Help is appreciated.",4,1
56,2019-1-24,2019,1,24,17,ajalfy,Getting TypeError while performing operation on tensorflow objects,https://www.reddit.com/r/tensorflow/comments/ajalfy/getting_typeerror_while_performing_operation_on/,atinesh229,1548320322,"Below is the simplified version of the code, I am getting error at line \`res = input - var\`

    import tensorflow.contrib.slim as slim
    import tensorflow as tf
    
    x = tf.placeholder(tf.float32, shape=[None, 150, 220, 3], name='x')
    
    input = slim.conv2d(input,  num_outputs=96, kernel_size=11, stride=4, padding=padding, scope=scope, weights_initializer=tf.truncated_normal_initializer(stddev=0.01), biases_initializer=None, activation_fn=None)
                          	
    var 	= tf.zeros_initializer()
    
    res = input - var

**Variable types**

&gt;input type: &lt;tensorflow.python.ops.init\_ops.Zeros object at 0x7f1a017fdb38&gt;  
&gt;  
&gt;var\_type: Tensor(""conv1/Conv2D:0"", shape=(?, 35, 53, 96), dtype=float32)

&amp;#x200B;

**Error**

`TypeError: Expected float32, got &lt;tensorflow.python.ops.init_ops.Zeros object at 0x7f1a017fdb38&gt; of type 'Zeros' instead.`

&amp;#x200B;

How can I solve it, any suggestion would be helpful.",2,1
57,2019-1-24,2019,1,24,20,ajbojj,Rounding a tensorflow variable,https://www.reddit.com/r/tensorflow/comments/ajbojj/rounding_a_tensorflow_variable/,errminator,1548330744,"If I train a simple linear regression model, I can get the values for the gradient and y intercept of my line by calling print(sess.run(model.w)) where model.w is an attribute of a linear model class storing the gradient.

However it prints it with all the decimal places showing and let's suppose I want to round that, I tried print(round(sess.run(model.w)),2) but the output doesn't change. Is there a reason I can't round the value of a tensorflow object in this way? How should I do it? ",0,1
58,2019-1-24,2019,1,24,22,ajc9e4,Printing at each iteration of a tf.while_loop,https://www.reddit.com/r/tensorflow/comments/ajc9e4/printing_at_each_iteration_of_a_tfwhile_loop/,errminator,1548335452,"I've taken the simple code in the answer of this stackexchange post (https://stackoverflow.com/questions/37441140/how-to-use-tf-while-loop-in-tensorflow) and am trying to modify it so that I can see the current value of x at each iteration in the loop.

I have tried various ways with no success. I am fairly confident the solution is to be able to call sess.run(x) from within the body function. However this requires passing the session as an argument to the body function and tensorflow complains when I try this.

Can anyone help me get this to work?

Thanks ",3,1
59,2019-1-25,2019,1,25,2,ajf310,Constraining incident weights to be exactly orthogonal,https://www.reddit.com/r/tensorflow/comments/ajf310/constraining_incident_weights_to_be_exactly/,aeftimia,1548352778,"Since Tensorflow recently acquired a matrix exponentiation operation, it became relatively straightforward to implement an orthogonality constraint.  
[https://gist.github.com/aeftimia/a5249168c84bc541ace2fc4e1d22a13e](https://gist.github.com/aeftimia/a5249168c84bc541ace2fc4e1d22a13e)

The idea is you flatten your weight tensor along appropriate axes into a matrix, antisymmetrize it, and exponentiate the result to smoothly map it to ""orthogonal matrix space"". Then the orthogonal matrix is reshaped back into the original input's shape as an orthogonalized drop-in replacement.

While it's more computationally expensive than the usual regularization based techniques, you do end up using around half as many parameters per weight matrix and you're guaranteed to get orthogonal matrices throughout your training session (to the extent expm converges given its input).

I originally implemented this as a Keras Constraint, (the first link), but then converted it to a functional version that doesn't adhere to any object-oriented Keras conventions.

[https://gist.github.com/aeftimia/045d1cd04a24f9c1b78baad5b2d5b73e](https://gist.github.com/aeftimia/045d1cd04a24f9c1b78baad5b2d5b73e)  
To the best of my knowledge, the respective links aren't quite ""pull requestable"" as a new feature for either Keras or Tensorflow, so I figured I'd just drop it on Reddit and hope someone finds it useful.",0,1
60,2019-1-25,2019,1,25,15,ajmel9,"Image Generation With AI: Generative Models Tutorial with Python+Tensorflow Codes (GANs, VAE, Bayesian Classifier Sampling, Auto-Regressive Models)",https://www.reddit.com/r/tensorflow/comments/ajmel9/image_generation_with_ai_generative_models/,obsezer,1548398581,"Generative  models are a subset of unsupervised learning that generate new  sample/data by using given some training data. There are different types  of ways of modelling same distribution of training data:  Auto-Regressive models, Auto-Encoders and GANs. In this tutorial, we are  focusing theory of generative models, demonstration of generative  models, important papers, courses related generative models. It will  continue to be updated over time.

Generative  Models Tutorial with Demo: Bayesian Classifier Sampling, Variational  Auto Encoder (VAE), Generative Adversial Networks (GANs), Popular GANs  Architectures (DCGAN, CycleGAN, Pix2Pix, PixelDTGAN, SRGAN, StackGAN,  TPGAN, 3DGAN, Age-cGAN, DiscoGAN, AnoGAN, IcGAN, MidiNet, etc. ),  Auto-Regressive Models (PixelRNN, PixelCNN), Important Generative Model  Papers, Courses, etc.

**Tutorial Link**: [**https://github.com/omerbsezer/Generative\_Models\_Tutorial\_with\_Demo**](https://github.com/omerbsezer/Generative_Models_Tutorial_with_Demo)

There are lots of applications for generative models:

* Image Denoising,
* Image Enhancement,
* Image Inpainting,
* Super-resolution (upsampling): SRGAN,
* Generate 3D objects: 3DGAN, [Video](https://youtu.be/HO1LYJb818Q)
* Creating Art:  

   * Create Anime Characters
   * Transform images from one domain (say real scenery) to another domain (Monet paintings or Van Gogh):CycleGAN
   * Creating Emoji: DTN
* Pose Guided Person Image Generation
* Creating clothing images and styles from an image: PixelDTGAN
* Face Synthesis: TP-GAN
* Image-to-Image Translation: Pix2Pix  

   * Labels to Street Scene
   * Aerial to Map
   * Sketch to Realistic Image
* High-resolution Image Synthesis
* Text to image: StackGAN
* Text to Image Synthesis
* Learn Joint Distribution: CoGAN
* Transfering style (or patterns) from one domain (handbag) to another (shoe): DiscoGAN
* Texture Synthesis: MGAN
* Image Editing: IcGAN
* Face Aging: Age-cGAN
* Neural Photo Editor
* Medical (Anomaly Detection): AnoGAN
* Music Generation: MidiNet
* Video Generation

Extra: Reinforcement Learning Tutorial:

[**https://github.com/omerbsezer/Reinforcement\_learning\_tutorial\_with\_demo**](https://github.com/omerbsezer/Reinforcement_learning_tutorial_with_demo)",3,1
61,2019-1-26,2019,1,26,18,ajzjm2,Tensorflow Tutorials,https://www.reddit.com/r/tensorflow/comments/ajzjm2/tensorflow_tutorials/,errminator,1548495212,"Are there any quality tensorflow tutorials available online that teach a complete course. So far I've found some that do the basics and then stop and then others that start with advanced machine learning models and there is a huge gap in my knowledge between these. I'd like to understand more of what's going on than just importing keras and running models (also I will be doing a masters next year where tf is expected and I'd like to get a head start). 

",13,1
62,2019-1-27,2019,1,27,16,ak9z2h,Convert HTML Table into JSON data,https://www.reddit.com/r/tensorflow/comments/ak9z2h/convert_html_table_into_json_data/,avejack,1548573457,"I'm kinda new to Neural Networks and just started to learn coding them by trying some examples. Two weeks ago I was searching for an interesting challenge and I found one. But I'm about to give up because it seems to be too hard for me... But I was curious to know if anyone of you is able to solve this?  


Maybe one of you guys is able to solve this ""challenge"":  
[https://stackoverflow.com/questions/54381940/tensorflow-convert-html-table-into-json-data](https://stackoverflow.com/questions/54381940/tensorflow-convert-html-table-into-json-data)",8,1
63,2019-1-28,2019,1,28,7,akgneu,Getting AVX AVX2 on conda windows,https://www.reddit.com/r/tensorflow/comments/akgneu/getting_avx_avx2_on_conda_windows/,xdarknuno,1548628270,"Greetings,
I come here as a last resort. I currently running windows 64bit with miniconda3.

I have tried both: 
*    `conda install tensorflow` 
*    `conda install tensorflow -c intel`
*    `conda install tensorflow-mkl`.

All these seem to fail to build the  AVX AVX2 lib, as i keep getting the 
&gt;Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
 141] AVX AVX2Your CPU

Using the intel one, besides these warning i keep getting an abismal ammount of prints regarding memory usage, available gpu devices and etc.

Could anyone help me install TF CPUon conda using the AVX AVX2?

Best regards.",9,1
64,2019-1-28,2019,1,28,18,aklvjq,The battle: Tensorflow vs Pytorch,https://www.reddit.com/r/tensorflow/comments/aklvjq/the_battle_tensorflow_vs_pytorch/,vjmde,1548667792,,1,1
65,2019-1-29,2019,1,29,1,akowoa,"[Nodejs] Now, the easy-to-use Mozilla / DeepSpeech STT has been created.",https://www.reddit.com/r/tensorflow/comments/akowoa/nodejs_now_the_easytouse_mozilla_deepspeech_stt/,rjs1197,1548691929,"I created a npm that can easily use the STT of the DeepSpeech of Mozilla with the code of the nodejs. Thank you very much for staring! 

&amp;#x200B;

our repository: [https://github.com/teamthesol/node-DeepSpeech](https://github.com/teamthesol/node-DeepSpeech)

&amp;#x200B;

DeepSpeech is Mozilla's open source speech recognition using tensorflow from the Mozilla Machine Learning Team. So this is a project they created by referring to 'DeepSpeech Architecture' designed by Andrew Y. Ng and other researchers.

It was created in 2016 and is currently available in version 0.4.x. Mozilla's DeepSpeech architecture is open source, and if you're interested in speech recognition, check out DeepSpeech!

&amp;#x200B;

ps1. It is available by default on node, python, and the command line. 

ps2. The research paper on DeepSpeech Architecture can be found at [https://arxiv.org/abs/1412.5567](https://arxiv.org/abs/1412.5567)!

ps3. The project is still very poor and any contribution is welcome! ",0,1
66,2019-1-29,2019,1,29,15,akx9cx,Does Tensorflow-GPU use disk space as virtual memory when pycache runs out?,https://www.reddit.com/r/tensorflow/comments/akx9cx/does_tensorflowgpu_use_disk_space_as_virtual/,Morocco_Bama,1548743009,"I don't know much about GPU or how Tensorflow runs, but I don't have much space on my computer left, and I've noticed that even if I save models/checkpoints infrequently during training, at some point it crashes and my storage tells me I have 0 GB free.

Is Tensorflow allocating stuff to the disk when it runs, and if so is there a way to turn this off?",4,1
67,2019-1-30,2019,1,30,20,albz16,Tensorflow prediction,https://www.reddit.com/r/tensorflow/comments/albz16/tensorflow_prediction/,zinngg,1548849385,"What is the correct format for making an online prediction in a single image using Tensorflow object detection library? In the documentation, I have seen that the base64 encoded image string must have the key `instances`. In other places, I have seen that the single key is 'b64' with the format:

&amp;#x200B;

`{""b64"": ""an_encoded_string""}`

&amp;#x200B;

On another page, the format is given as :

&amp;#x200B;

`{""images"": [0.0, , 0.1], ""key"": 1}`

&amp;#x200B;

While exporting the model, the input type that I used was \`encoded\_image\_string\_tensor\`.

&amp;#x200B;

The commmand that I am using for cloud prediction is :

&amp;#x200B;

gcloud ml-engine predict --model={*MODEL\_NAME*} --version={*VERSION*} --json-instances={*IMAGE.json*}

 ",0,1
68,2019-1-31,2019,1,31,13,allkmw,Any good tutorials on data importing to tensor?,https://www.reddit.com/r/tensorflow/comments/allkmw/any_good_tutorials_on_data_importing_to_tensor/,Frank1789,1548907637,"Hi there!
I have some data sets I would like to analyse in tensorflow - consider it an excel file. :)
Turning it into a csv - ok.
Importing it into SQL DB - ok.

But importing it into a TENSOR (WTF?!?!) is the biggest pain. Documentation is a nightmare regarding this topic. Having to prepare it with python libraries and then transfer it into tensor, then the data types dont work together... really? This should be like that? 

Looking on the majority of online courses out there are so funny - all are talking about so many stuff EXCEPT data management...

Please help. ",11,1
69,2019-1-31,2019,1,31,15,almte4,Tensorflow worker on network,https://www.reddit.com/r/tensorflow/comments/almte4/tensorflow_worker_on_network/,Frank1789,1548917236,"Hi there!
I am working on MacOS which is not supporting any GPU support. But in my home network I have a Linux machine full of CUDA cards. :))
Is there any easy way to develop on my Mac and send the work to the linux machine? Maybe with just a line of code? :))
No paralisation - just one worker.
",4,1
0,2019-2-1,2019,2,1,16,alzjqf,How to get the output of certain layer of trained CNN model tensorflow,https://www.reddit.com/r/tensorflow/comments/alzjqf/how_to_get_the_output_of_certain_layer_of_trained/,atinesh229,1549005268,"I have a `CNN` model for `image classification` which I have trained over my dataset. The model goes something like this

    Convolution + Relu
    pooling
    
    Convolution + Relu
    Convolution + Relu
    pooling
    
    flat
    
    fully connected + Relu (FC1)
    fully connected + softmax (FC2)

After training, I want to get the feature vectors for an image that I input to the pre-trained model i.e. I want to get the output of `FC1` layer. Is there any way we can get it, I browsed the web but couldn't find anything useful any suggestions would be of great help guys.

&amp;#x200B;

**Training script**

[https://paste.ofcode.org/jPPAYZGeN6qpRHTNemUvhV](https://paste.ofcode.org/jPPAYZGeN6qpRHTNemUvhV)

&amp;#x200B;

**Testing script**

[https://paste.ofcode.org/dUjpW6j4yEtX86KmvZqWNT](https://paste.ofcode.org/dUjpW6j4yEtX86KmvZqWNT)

&amp;#x200B;",2,1
1,2019-2-1,2019,2,1,23,am2a3u,TensorFlow Lite classification on Android - Adding the first Machine Learning model into your mobile app,https://www.reddit.com/r/tensorflow/comments/am2a3u/tensorflow_lite_classification_on_android_adding/,frogermcs,1549029718,,0,1
2,2019-2-2,2019,2,2,4,am5ump,TensorFlow 2.0 experimental VM images for Google Compute Engine released,https://www.reddit.com/r/tensorflow/comments/am5ump/tensorflow_20_experimental_vm_images_for_google/,b0noi,1549049689,,3,1
3,2019-2-2,2019,2,2,6,am6sf5,Inserting LSTM cell using tf.contrib,https://www.reddit.com/r/tensorflow/comments/am6sf5/inserting_lstm_cell_using_tfcontrib/,schrodingershit,1549055114,"I am trying to plug a LSTM cell in the model given below but I am having difficulty doing that. I have to stick to tf.contrib by now since my code is kind of structured around. Can someone help me with that? 

    def mlp_model(input, num_outputs, scope, reuse=False, num_units=64, rnn_cell=None):
        with tf.variable_scope(scope, reuse=reuse):
            out = input
            out = layers.fully_connected(out, num_outputs=num_units, activation_fn=tf.nn.relu, weights_initializer=tf.glorot_normal_initializer(seed=10, dtype=tf.float64))
            out = layers.fully_connected(out, num_outputs=num_units, activation_fn=tf.nn.relu, weights_initializer=tf.glorot_normal_initializer(seed=5, dtype=tf.float64))
            out = layers.fully_connected(out, num_outputs=num_outputs, activation_fn=None, weights_initializer=tf.zeros_initializer(), biases_initializer=tf.zeros_initializer())
        return out",1,1
4,2019-2-2,2019,2,2,6,am73q6,Keras-- how best to deal with multidimensional input data?,https://www.reddit.com/r/tensorflow/comments/am73q6/keras_how_best_to_deal_with_multidimensional/,kds_medphys,1549056986,"Hi all, 

In short, my input data are (87,26,127,128,128). The corresponding labels are comparable in size. Each unique dataset is in the first dimension here (i.e. n=87)

I have a ton of RAM so I can fit this all into memory at once. Ideally for many reasons I'd like to train this using model.fit, but right now I can only get model.fit_generator() working.

How exactly could I structure my dataset in memory to make it automatically draw batches from these 5D inputs?",3,1
5,2019-2-2,2019,2,2,7,am7lnc,"Where is ""NCCL"" in tf 1.13 ?",https://www.reddit.com/r/tensorflow/comments/am7lnc/where_is_nccl_in_tf_113/,Heckopath,1549059986,"I built a Titan RTX machine, and it requires CUDA 10.0 ... 

And I have to install TF1.13, but ...

&amp;#x200B;

$ tensorflow.contrib has no attribute ""nccl"" 

&amp;#x200B;

I checked the release note ...

It said :  

* Moved NCCL to core.

What's this means ?

Could anyone help me ?

Many thanks ...",10,1
6,2019-2-2,2019,2,2,16,amc4a0,Docker Image with CUDA 9 support,https://www.reddit.com/r/tensorflow/comments/amc4a0/docker_image_with_cuda_9_support/,Frank1789,1549094368,"Hi there!

I just made a clean linux install and tried to get tensorflow running with GPU support (CUDA 9.1).

Unfortunately it doesn't work. Details: [https://github.com/NVIDIA/nvidia-docker/issues/912](https://github.com/NVIDIA/nvidia-docker/issues/912)

Does anybody has an idea what to do? 

PS: It is an GeForce GTX 1070 with an non AVX supporting CPU (G4400)",11,1
7,2019-2-3,2019,2,3,13,amm7ql,"Help, Tensorflow not working",https://www.reddit.com/r/tensorflow/comments/amm7ql/help_tensorflow_not_working/,uberdope87,1549167583,"Hello, I am trying to get started with tensorflow and I have it downloaded and installed to my pycharm project interpreter, but as soon as I try to import it into my python file and run it I get this error:

&amp;#x200B;

ImportError: DLL load failed: The specified procedure could not be found.

&amp;#x200B;

Any help is appreciated.",3,1
8,2019-2-3,2019,2,3,21,amp9y0,Any easy GUI using TensorFlow?,https://www.reddit.com/r/tensorflow/comments/amp9y0/any_easy_gui_using_tensorflow/,MrOaiki,1549198116,"This is probably way above my level of knowledge, but I'll give it a shot. I have structured data where say 10 variables result in the 11th. I want to feed a neural network this data, and then give it 10 variables and make it guess the 11th. Any good visual way of doing this? I've looked at Weka, but I'm thinking of a solution running on e.g AWS instead of locally.",2,1
9,2019-2-4,2019,2,4,5,amtnuj,Direct Link to Nvidia CuDNN?,https://www.reddit.com/r/tensorflow/comments/amtnuj/direct_link_to_nvidia_cudnn/,woahmyd00d,1549225935,"I would like to install Tensorflow, but I need the CuDNN SDK for python, but Nvidia's r/assholedesign requires registration to download and no matter what I try(temp emails, [etc.](https://www.reddit.com/r/assholedesign/comments/7s6t0p/wanna_download_cudnn_you_have_to_register_first/)) I can't seem to register an account to get CuDNN v10.0. If you have a working Nvidia Dev account, can you send a mirror or a [direct link](https://www.reddit.com/r/assholedesign/comments/7s6t0p/wanna_download_cudnn_you_have_to_register_first/)? Any help would be appreciated.",7,1
10,2019-2-4,2019,2,4,6,amugby,How do you open a Jupyter server in something like finder or visual studio?,https://www.reddit.com/r/tensorflow/comments/amugby/how_do_you_open_a_jupyter_server_in_something/,MalicousMonkey,1549230366,"I followed the tutorial, setup docker, started a jupyter server, and I did some testing in the python command line and everything seems to be working, and I wanted to start writing some scripts, but I cant figure out how open the directory. Bash says its something like root@randomstringofcharators but Im not sure how to actually write a script other than using echo, which is not happening",0,1
11,2019-2-4,2019,2,4,20,an0qxa,Tensorflow EBook,https://www.reddit.com/r/tensorflow/comments/an0qxa/tensorflow_ebook/,blobfish10199,1549279284,"I am looking for a tensorflow ebook 
I am fine with both PDF and ePub. I rather you provide a ePub link though",2,1
12,2019-2-5,2019,2,5,8,an81rv,Machine Learning In Node.js With TensorFlow.js,https://www.reddit.com/r/tensorflow/comments/an81rv/machine_learning_in_nodejs_with_tensorflowjs/,Nancyannh,1549324458,[http://dev.edupioneer.net/74c53f122f](http://dev.edupioneer.net/74c53f122f),1,1
13,2019-2-5,2019,2,5,11,an9k70,Noob model export question,https://www.reddit.com/r/tensorflow/comments/an9k70/noob_model_export_question/,reddits4s,1549334393,"Fairly Noob question,
I have used retrain.py to train a model based on mobilenet_v2_. I have saved the model and created the following files:

    saved_model.pb
    variables.data-00000-of-00001
    variables.index

I can use the retrained graph to successfully predict as well, so no issues there.

My question is, what else do I need to do in order to use export_inference_graph to export the model?
Thanks in advance",0,1
14,2019-2-6,2019,2,6,5,ani16u,Android: Help convert tensorflow.lite.Interpreter to FirebaseModelInterpreter,https://www.reddit.com/r/tensorflow/comments/ani16u/android_help_convert_tensorflowliteinterpreter_to/,xTeCnOxShAdOwZz,1549396824,"Hi,

I'm pretty new to Tensorflow (only started about 3 days ago), so excuse me if I sound stupid.

I've built a model using mobilenet\_1.0\_224 for recognising different images of shop-fronts, then converted it to .tflite to be used in my Android project. It works really well! I followed [this](https://medium.com/over-engineering/building-a-custom-machine-learning-model-on-android-with-tensorflow-lite-26447e53abf2) tutorial to get it working.  


However, having used looked through the Firebase ML Kit documentation for custom Tensorflow Lite models, I realise I can use Firebase for hosting my model, which is exactly what I need (different cities will need to recognise a different set of shop fronts). It seems I need to use Firebase's Tensorflow library for doing this. (I was actually already using this library, but using the old org.tensorflow.lite.Interpreter class within it, rather than the com.google.firebase.ml.custom.FirebaseModelInterpreter class). Since I was using the old one, doing `new Interpreter()` would annotate as being depreciated.

&amp;#x200B;

I'd like to switch to using Firebase' interpreter, but it seems the set up is quite different. I was wondering if anyone else was familiar with this, and would be willing to help me switch to the Firebase approach. I'd really appreciate any help with this, I'm seriously stuck! Sorry if I'm missing something obvious!

&amp;#x200B;

Thanks! Sam.",1,1
15,2019-2-6,2019,2,6,16,anodhu,Embedding lookup on sparse matrix,https://www.reddit.com/r/tensorflow/comments/anodhu/embedding_lookup_on_sparse_matrix/,aguscerdo,1549438223,"Hello, I'm changing a project and for this I need to use sparse matrices. What is the most appropriate way of doing something like embedding\_lookup (the function they use) with sparse?

Their call is: `hidden = \[tf.nn.embedding\_lookup(input\_features, node\_samples) for node\_samples in samples\]`

From GraphSAGE model code, I want to make input_features a sparse matrix
Thanks~~ 
",2,1
16,2019-2-7,2019,2,7,1,ans8pv,Possible to restore checkpoint with missing .meta file?,https://www.reddit.com/r/tensorflow/comments/ans8pv/possible_to_restore_checkpoint_with_missing_meta/,Cranial_Vault,1549469444,Google provides plenty of checkpoints on their [model zoo](https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md) but all of them lack the .meta file required to load the checkpoint and continue training.  Is there a workaround for this?,0,1
17,2019-2-8,2019,2,8,9,aoakr7,flutter_tflite now supports object detection (with SSD MobileNet and Tiny YOLOv2),https://www.reddit.com/r/tensorflow/comments/aoakr7/flutter_tflite_now_supports_object_detection_with/,x_ash,1549584877,,0,1
18,2019-2-8,2019,2,8,22,aogidw,Difference in performances of Model hosted on ML Engine vs Tensorflow Serving + Docker,https://www.reddit.com/r/tensorflow/comments/aogidw/difference_in_performances_of_model_hosted_on_ml/,zinngg,1549632519,I am new to Tensorflow and have developed a Prediction model using the Tensorflow Object detection API. I came across Tensorflow Serving used with Docker. Which of the two offers better performance? ,2,1
19,2019-2-9,2019,2,9,2,aoiwot,Problem with Embeddings inside of Checkpoint,https://www.reddit.com/r/tensorflow/comments/aoiwot/problem_with_embeddings_inside_of_checkpoint/,v3nw,1549647330,"Hello guys.

I have a problem with embeddings. I am using estimator and saving checkpoints with that.

My NER model working with pre trained embedding like GloVe. And i want to restore my checkpoint without embedding variable. Cause when i tried resume checkpoints with different embedding and vocabs, i am getting shape miss match ofc.

&amp;#x200B;

Any idea?

&amp;#x200B;",6,1
20,2019-2-9,2019,2,9,3,aojm62,How to create a custom tensorflow op without defining an implementation?,https://www.reddit.com/r/tensorflow/comments/aojm62/how_to_create_a_custom_tensorflow_op_without/,nckl,1549651357,"I want to create my own custom tensorflow op (that takes, say, two input float tensors and creates one output float tensor) called ""custom_op"" and save it to a protobuff file. Later, I want to load a library actually defining the op, load that op, and run it. Anyway to do this? 

If I just do, say, 

    import tensorflow as tf
    g = tf.Graph()
    n = tf.NodeDef(name=""op1"", op=""custom_op"")
    o = tf.Operation(n, g)

I get the error ""Op type not registered 'custom_op' in binary..."". I don't see a way to create my own OpDef object in python though. Any help greatly appreciated!",0,1
21,2019-2-9,2019,2,9,4,aokdrm,Object Detection Models question / perfomance .,https://www.reddit.com/r/tensorflow/comments/aokdrm/object_detection_models_question_perfomance/,cviperr33,1549655828,"Hello , im fairly new to tensorflow and python.I trained my first object detection model on faster\_rcnn\_inception\_v2\_coco\_2018\_01\_28 , the speed was \~200 steps / sec and the model trained fairly quickly for 3 hours dropping down to 0.018 loss.

&amp;#x200B;

Training data consist of 200 pictures for 2 objects.All of them are by size of 800x600 and size of \~27kb.

&amp;#x200B;

My Hardware is  : Ryzen 1700 @ 3.7ghz, 32gb ram @ 2993hz , gtx 1070 FE

The results were  very good like 90% accuracy on detecting a specific object on  800x600 screen that is very small like 20x20 pixels and its moving.The only issues was that inside a VM with tensorflow cpu it consumes all avaible cpu resources and the perfomance is really slow.

&amp;#x200B;

So i tried with training a lighter model like ssdlite\_mobilenet\_v2\_coco\_2018\_05\_09 but the training was really slow like 1 step /sec and for 10 hours of training it only got down to like 0.9 loss.I've noticed that training that model consumes 50% cpu and 18% gpu.Same thing with ssd\_mobilenet\_v1\_coco\_2018\_01\_28.The perfomance of detection was really bad , it could not detect object 1 and it detected object 2 few times.Atleast the cpu usage was fairly low and the perfomance was very fast but its unusable.

&amp;#x200B;

So can you guys recommend me a model from tensorflow model zoo that i can use. I want it to be atleast 100 step /sec and low cpu consumation for tensorflow-cpu.",0,1
22,2019-2-9,2019,2,9,21,aos0aj,Use DataSet to simulate and reolace RandomShuffleQueue,https://www.reddit.com/r/tensorflow/comments/aos0aj/use_dataset_to_simulate_and_reolace/,jthat92,1549716034,"I described my issue in more detail in [this StackOverflow post](https://stackoverflow.com/questions/54595256/randomshufflequeue-functionality-with-tf-data-dataset).  

Any help is greatly appreciated :)",1,1
23,2019-2-10,2019,2,10,4,aovp1x,No Bullshit Guide to Install Tensoflow GPU on Ubuntu 18.04/18.10.,https://www.reddit.com/r/tensorflow/comments/aovp1x/no_bullshit_guide_to_install_tensoflow_gpu_on/,rednafi,1549740737,"Despite having a dedicated GPU, installing tensorflow on that is one of those painful things that deterred me multiple times from running gpu accelerated scipts. After rummaging through piles of garbages on the internet, I managed to configure CUDA, CuDNN and tensorflow 1.12 on my new machine.

If you use ubuntu 10.04/18.10, here is a no bullshit guide to configure tf-gpu on ubuntu.

https://link.medium.com/K9QlufuNaU

",8,1
24,2019-2-10,2019,2,10,5,aow2jg,How do I train this using my GPU (without getting an error)?,https://www.reddit.com/r/tensorflow/comments/aow2jg/how_do_i_train_this_using_my_gpu_without_getting/,JesseOS,1549742715,"I have tried tf.ConfigProto(allow_soft_placement=True) but that just hands off the actual training to the CPU and leaves only the model building and prep to the GPU. 
Code (from chatbot-rnn)
       	import numpy as np
	import tensorflow as tf

	import argparse
	import time, datetime
	import os
	import pickle
	import sys

	from utils import TextLoader
	from model import Model

	def main():
	assert sys.version_info &gt;= (3, 3), \
	""Must be run in Python 3.3 or later. You are running {}"".format(sys.version)

	parser = argparse.ArgumentParser()
	parser.add_argument('--data_dir', type=str, default='data/scotus',
					   help='data directory containing input.txt')
	parser.add_argument('--save_dir', type=str, default='models/new_save',
					   help='directory for checkpointed models (load from here if one is already present)')
	parser.add_argument('--block_size', type=int, default=2048,
					   help='number of cells per block')
	parser.add_argument('--num_blocks', type=int, default=3,
					   help='number of blocks per layer')
	parser.add_argument('--num_layers', type=int, default=3,
					   help='number of layers')
	parser.add_argument('--model', type=str, default='gru',
					   help='rnn, gru, lstm or nas')
	parser.add_argument('--batch_size', type=int, default=40,
					   help='minibatch size')
	parser.add_argument('--seq_length', type=int, default=40,
					   help='RNN sequence length')
	parser.add_argument('--num_epochs', type=int, default=50,
					   help='number of epochs')
	parser.add_argument('--save_every', type=int, default=5000,
					   help='save frequency')
	parser.add_argument('--grad_clip', type=float, default=5.,
					   help='clip gradients at this value')
	parser.add_argument('--learning_rate', type=float, default=1e-5,
					   help='learning rate')
	parser.add_argument('--decay_rate', type=float, default=0.975,
					   help='how much to decay the learning rate')
	parser.add_argument('--decay_steps', type=int, default=100000,
					   help='how often to decay the learning rate')
	parser.add_argument('--set_learning_rate', type=float, default=-1,
					   help='reset learning rate to this value (if greater than zero)')
	args = parser.parse_args()
	train(args)

	def train(args):
	# Create the data_loader object, which loads up all of our batches, vocab dictionary, etc.
	# from utils.py (and creates them if they don't already exist).
	# These files go in the data directory.
	data_loader = TextLoader(args.data_dir, args.batch_size, args.seq_length)
	args.vocab_size = data_loader.vocab_size

	load_model = False
	if not os.path.exists(args.save_dir):
		print(""Creating directory %s"" % args.save_dir)
		os.mkdir(args.save_dir)
	elif (os.path.exists(os.path.join(args.save_dir, 'config.pkl'))):
		# Trained model already exists
		ckpt = tf.train.get_checkpoint_state(args.save_dir)
		if ckpt and ckpt.model_checkpoint_path:
			with open(os.path.join(args.save_dir, 'config.pkl'), 'rb') as f:
				saved_args = pickle.load(f)
				args.block_size = saved_args.block_size
				args.num_blocks = saved_args.num_blocks
				args.num_layers = saved_args.num_layers
				args.model = saved_args.model
				print(""Found a previous checkpoint. Overwriting model description arguments to:"")
				print("" model: {}, block_size: {}, num_blocks: {}, num_layers: {}"".format(
					saved_args.model, saved_args.block_size, saved_args.num_blocks, saved_args.num_layers))
				load_model = True

	# Save all arguments to config.pkl in the save directory -- NOT the data directory.
	with open(os.path.join(args.save_dir, 'config.pkl'), 'wb') as f:
		pickle.dump(args, f)
	# Save a tuple of the characters list and the vocab dictionary to chars_vocab.pkl in
	# the save directory -- NOT the data directory.
	with open(os.path.join(args.save_dir, 'chars_vocab.pkl'), 'wb') as f:
		pickle.dump((data_loader.chars, data_loader.vocab), f)

	# Create the model!
	print(""Building the model"")
	model = Model(args)
	print(""Total trainable parameters: {:,d}"".format(model.trainable_parameter_count()))

	# Make tensorflow less verbose; filter out info (1+) and warnings (2+) but not errors (3).
	os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

	config = tf.ConfigProto(log_device_placement=False)
	#config.gpu_options.allow_growth = True
	with tf.Session(config=config) as sess:
		tf.global_variables_initializer().run()
		saver = tf.train.Saver(model.save_variables_list(), max_to_keep=3)
		if (load_model):
			print(""Loading saved parameters"")
			saver.restore(sess, ckpt.model_checkpoint_path)
		global_epoch_fraction = sess.run(model.global_epoch_fraction)
		global_seconds_elapsed = sess.run(model.global_seconds_elapsed)
		if load_model: print(""Resuming from global epoch fraction {:.3f},""
				"" total trained time: {}, learning rate: {}"".format(
				global_epoch_fraction,
				datetime.timedelta(seconds=float(global_seconds_elapsed)),
				sess.run(model.lr)))
		if (args.set_learning_rate &gt; 0):
			sess.run(tf.assign(model.lr, args.set_learning_rate))
			print(""Reset learning rate to {}"".format(args.set_learning_rate))
		data_loader.cue_batch_pointer_to_epoch_fraction(global_epoch_fraction)
		initial_batch_step = int((global_epoch_fraction
				- int(global_epoch_fraction)) * data_loader.total_batch_count)
		epoch_range = (int(global_epoch_fraction),
				args.num_epochs + int(global_epoch_fraction))
		writer = tf.summary.FileWriter(args.save_dir, graph=tf.get_default_graph())
		outputs = [model.cost, model.final_state, model.train_op, model.summary_op]
		global_step = epoch_range[0] * data_loader.total_batch_count + initial_batch_step
		avg_loss = 0
		avg_steps = 0
		try:
			for e in range(*epoch_range):
				# e iterates through the training epochs.
				# Reset the model state, so it does not carry over from the end of the previous epoch.
				state = sess.run(model.zero_state)
				batch_range = (initial_batch_step, data_loader.total_batch_count)
				initial_batch_step = 0
				for b in range(*batch_range):
					global_step += 1
					if global_step % args.decay_steps == 0:
						# Set the model.lr element of the model to track
						# the appropriately decayed learning rate.
						current_learning_rate = sess.run(model.lr)
						current_learning_rate *= args.decay_rate
						sess.run(tf.assign(model.lr, current_learning_rate))
						print(""Decayed learning rate to {}"".format(current_learning_rate))
					start = time.time()
					# Pull the next batch inputs (x) and targets (y) from the data loader.
					x, y = data_loader.next_batch()

					# feed is a dictionary of variable references and respective values for initialization.
					# Initialize the model's input data and target data from the batch,
					# and initialize the model state to the final state from the previous batch, so that
					# model state is accumulated and carried over between batches.
					feed = {model.input_data: x, model.targets: y}
					model.add_state_to_feed_dict(feed, state)
					
					# Run the session! Specifically, tell TensorFlow to compute the graph to calculate
					# the values of cost, final state, and the training op.
					# Cost is used to monitor progress.
					# Final state is used to carry over the state into the next batch.
					# Training op is not used, but we want it to be calculated, since that calculation
					# is what updates parameter states (i.e. that is where the training happens).
					train_loss, state, _, summary = sess.run(outputs, feed)
					elapsed = time.time() - start
					global_seconds_elapsed += elapsed
					writer.add_summary(summary, e * batch_range[1] + b + 1)
					if avg_steps &lt; 100: avg_steps += 1
					avg_loss = 1 / avg_steps * train_loss + (1 - 1 / avg_steps) * avg_loss
					print(""{:,d} / {:,d} (epoch {:.3f} / {}), loss {:.3f} (avg {:.3f}), {:.3f}s"" \
						.format(b, batch_range[1], e + b / batch_range[1], epoch_range[1],
							train_loss, avg_loss, elapsed))
					# Every save_every batches, save the model to disk.
					# By default, only the five most recent checkpoint files are kept.
					if (e * batch_range[1] + b + 1) % args.save_every == 0 \
							or (e == epoch_range[1] - 1 and b == batch_range[1] - 1):
						save_model(sess, saver, model, args.save_dir, global_step,
								data_loader.total_batch_count, global_seconds_elapsed)
		except KeyboardInterrupt:
			# Introduce a line break after ^C is displayed so save message
			# is on its own line.
			print()
		finally:
			writer.flush()
			global_step = e * data_loader.total_batch_count + b
			save_model(sess, saver, model, args.save_dir, global_step,
					data_loader.total_batch_count, global_seconds_elapsed)

	def save_model(sess, saver, model, save_dir, global_step, steps_per_epoch, global_seconds_elapsed):
	global_epoch_fraction = float(global_step) / float(steps_per_epoch)
	checkpoint_path = os.path.join(save_dir, 'model.ckpt')
	print(""Saving model to {} (epoch fraction {:.3f})..."".format(checkpoint_path, global_epoch_fraction),
		end='', flush=True)
	sess.run(tf.assign(model.global_epoch_fraction, global_epoch_fraction))
	sess.run(tf.assign(model.global_seconds_elapsed, global_seconds_elapsed))
	saver.save(sess, checkpoint_path, global_step = global_step)
	print(""\rSaved model to {} (epoch fraction {:.3f}).   "".format(checkpoint_path, global_epoch_fraction))

	if __name__ == '__main__':
	main()
",10,1
25,2019-2-10,2019,2,10,12,ap01ow,Trying to install tf but it keeps giving me this when i verify. Whats wrong?,https://www.reddit.com/r/tensorflow/comments/ap01ow/trying_to_install_tf_but_it_keeps_giving_me_this/,athiestman262,1549768095,,3,1
26,2019-2-10,2019,2,10,21,ap3kkr,How to diagnose machine freezes during training?,https://www.reddit.com/r/tensorflow/comments/ap3kkr/how_to_diagnose_machine_freezes_during_training/,gonzales82,1549802498,"Ubuntu 18.04, Cuda 10, Tf 1.13rc, NVIDIA 2080Ti x 2

I have a 2 GPU desktop. I set the

    os.environ[""CUDA_VISIBLE_DEVICES""]

to either 0 or 1 for each of the two runs. Each run is a series of individual trainings (different hyperparameters). It runs for a while (even hours), but then the machine will always free.

I've also tried a single multi-gpu run using the multi_gpu_model keras function, but that failed with: 

  
    2019-02-10 13:28:23.016229: E tensorflow/stream_executor/cuda/cuda_event.cc:48] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_INSTRUCTION: an illegal instruction was encountered
    2019-02-10 13:28:23.016230: E tensorflow/stream_executor/cuda/cuda_event.cc:48] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_INSTRUCTION: an illegal instruction was encountered
    2019-02-10 13:28:23.016258: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:274] Unexpected Event status: 1
    2019-02-10 13:28:23.016264: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:274] 
    Unexpected Event status: 1
    Aborted (core dumped)

I thought it might be a heat issue, but it happens even with low temps. Anyone has any suggestions?",7,1
27,2019-2-11,2019,2,11,3,ap6tkm,Where are the backend C++ Algorithm Implementations?,https://www.reddit.com/r/tensorflow/comments/ap6tkm/where_are_the_backend_c_algorithm_implementations/,mariebks,1549824012,"I am working on a project team in college to implement object detection with 3D LiDAR point clouds on an FPGA. We have a software subteam to implement 3D convolution in C++ and a hardware subteam that will convert that C++ code to Verilog so that the algorithm can be run on an FPGA. If we can have full access to the C++ backend algorithms in Tensorflow, we will be able to convert a Tensorflow implementation into Verilog. If not, we will have to code from scratch on our own (most likely using Eigen as a supplementary libary which is C++ only and has easy access to backend functions). Where in the Github files are these functions implemented in C++? As far as I am aware, Python is merely an interface language to write code that calls functions that are truly written in C++ for speed purposes, but I am having trouble locating this backend source code. Thank you so much!",10,1
28,2019-2-11,2019,2,11,7,ap94bu,My implementation of 3 NLP models for text classification in Tensorflow and Pytorch,https://www.reddit.com/r/tensorflow/comments/ap94bu/my_implementation_of_3_nlp_models_for_text/,1991viet,1549836766,,4,1
29,2019-2-11,2019,2,11,10,apas6o,Beginner learning the awesomeness of tensor flow. What are my limits?,https://www.reddit.com/r/tensorflow/comments/apas6o/beginner_learning_the_awesomeness_of_tensor_flow/,Z3nski,1549847166,Ive just recently dived into tensor flow and want to create a small personal assistant with facial recognition technology fed from a local database of pictures. Is it also possible to link facial recognition tech with social media? What are my possibilities? Thanks in advance! ,0,1
30,2019-2-11,2019,2,11,16,apdpmu,[NEED ADVICE] can you guys tell me if this is possible using tensor flow?,https://www.reddit.com/r/tensorflow/comments/apdpmu/need_advice_can_you_guys_tell_me_if_this_is/,BlueFrenchHornThief,1549868645,"I need to detect two sets of numbers from an image. [The ones i marked in red](https://i.imgur.com/3yBHe60.jpg) what i want exactly is that I give a similar image and get the positions of those numbers or same image with those two numbers blurred out or striked down.

I am not sure if this is the right sub for my question so if you feel like i can get help in another sub please do mention it.

I tried to do it with Opencv and tesseract ocr and it it doesn't work all the time.

Thanks in advance",2,1
31,2019-2-11,2019,2,11,20,apf9wt,"[Suggestion] People, who perform a lot of experiment, how do you keep track of all the results?",https://www.reddit.com/r/tensorflow/comments/apf9wt/suggestion_people_who_perform_a_lot_of_experiment/,phoenixlads,1549883946,"So, I have to perform some experiments and I was wondering if there is any tool which can log all my parameters and corresponding results with it. I'm not aware of any such tools, and currently doing it manually by storing everything in csv. It's not as organized as I'd like it to be.

Anyone who knows any such tool which could make life easier??",6,1
32,2019-2-12,2019,2,12,4,apjsyy,TensorFlow + HDFS,https://www.reddit.com/r/tensorflow/comments/apjsyy/tensorflow_hdfs/,_spicyramen,1549912628,"My data lives mainly in HDFS, is there a recommended solution to have TensorFlow read from HDFS data and run my model? 

Only ""document"" I found is this: [https://www.tensorflow.org/deploy/hadoop](https://www.tensorflow.org/deploy/hadoop)",10,1
33,2019-2-12,2019,2,12,13,appdac,TensorFlow GPU pip installation with CUDA 9.1,https://www.reddit.com/r/tensorflow/comments/appdac/tensorflow_gpu_pip_installation_with_cuda_91/,_spicyramen,1549945790,"Seems to be that TensorFlow pip package is compiled using CUDA 9.0

My default Debian install has 9.1 by default, is there a way to get tensorflow GPU with CUDA 9.1 \_without\_ building it from source/use bazel?

What about TF 2.0 preview what CUDA version was built?

&amp;#x200B;",5,1
34,2019-2-12,2019,2,12,13,applqb,TypeError: Using a `tf.Tensor` as a Python `bool` is not allowed.,https://www.reddit.com/r/tensorflow/comments/applqb/typeerror_using_a_tftensor_as_a_python_bool_is/,AskingForAFriend1738,1549947404," 

Code: [https://paste.ee/p/ubIE6#aeQCKkVd46SwXTLOMyJ06dd2tKwgrcmK](https://paste.ee/p/ubIE6#aeQCKkVd46SwXTLOMyJ06dd2tKwgrcmK)

I am trying to define func(x) in order to use the genetic algs library here:[https://github.com/bobirdmi/genetic-algorithms/tree/master/examples](https://github.com/bobirdmi/genetic-algorithms/tree/master/examples) However, when I try and use ""sga.init\_random\_population(population\_size, params, interval)"" the code complains of me using tf.Tensors as python bools.

However, I am only referencing one bool in the entire code (Elitism) so I have no idea why this error is even showing (I don't even have tensorflow imported). Asked around others who used sga.init\_... and my inputs/setup is fine. Any suggestions would be greatly appreciated.

Full error report: [https://paste.ee/p/AvjNu#rQqL2BmqAcZxuLtOlrqDh8hCWUF5SzER](https://paste.ee/p/AvjNu#rQqL2BmqAcZxuLtOlrqDh8hCWUF5SzER)",1,1
35,2019-2-12,2019,2,12,17,apr92n,TensorFlow.js: achine learning in your browser,https://www.reddit.com/r/tensorflow/comments/apr92n/tensorflowjs_achine_learning_in_your_browser/,helpdeveu,1549960384,,0,1
36,2019-2-13,2019,2,13,3,apweh0,Tensorflow with python 3.7,https://www.reddit.com/r/tensorflow/comments/apweh0/tensorflow_with_python_37/,matzerlive,1549995719,Quick question Is tensorflow available for python 3.7 ,8,1
37,2019-2-13,2019,2,13,5,apy69a,Tensorflow help!! Can I solve this problem using Tensorflow?,https://www.reddit.com/r/tensorflow/comments/apy69a/tensorflow_help_can_i_solve_this_problem_using/,smartguid,1550005124,"Hi everyone,

I have a tensorflow program that currently takes a bunch of features related to weather and it currently predicts a temperature.  

I am having a hard time finding a answer to my question which is, would it be possible to output and upper and lower boundary for the temperature?    The idea is to predict the high and low temperature.

Is it possible to have tensorflow output a label that has two predictions?

&amp;#x200B;

Please let me know if you need more info.",7,1
38,2019-2-13,2019,2,13,17,aq4lmb,Machine Learning  Building a Pet Detector in 30 minutes using Tensorflow,https://www.reddit.com/r/tensorflow/comments/aq4lmb/machine_learning_building_a_pet_detector_in_30/,TomJinZn,1550047963,,0,1
39,2019-2-14,2019,2,14,7,aqcqbp,Any good courses on learning Tensorflow that focus on using eager execution?,https://www.reddit.com/r/tensorflow/comments/aqcqbp/any_good_courses_on_learning_tensorflow_that/,alew3,1550098567,"I have used Tensorflow in the past but headed over to Pytorch because it seemed easier to work with especially because of its dynamic vs TF static graph. Now that that TF has eager execution I want to give it a go again. Are there any courses that focus on eager execution with many practical examples?  Im especially interested in mobile / browser deployment examples.


",6,1
40,2019-2-14,2019,2,14,12,aqfcuh,TF.js How do I get the weights of my model as an array?,https://www.reddit.com/r/tensorflow/comments/aqfcuh/tfjs_how_do_i_get_the_weights_of_my_model_as_an/,CSS_Programmer,1550114926,How do I get the weights as an array? I am trying to get a more low level understanding of whats going on and I may possibly have to manipulate the weights manually in order to reshape my model after it has been created.,0,1
41,2019-2-14,2019,2,14,16,aqhg50,Are there any ASICs in development that is optimized for Tensorflow?,https://www.reddit.com/r/tensorflow/comments/aqhg50/are_there_any_asics_in_development_that_is/,xanahur,1550130971,"So, Google has their TPUs. Is there anything like that being developed that can significantly outperform GPUs? It's not clear if Intel's NNP-L1000's can be parallelized like GPUs.",5,1
42,2019-2-14,2019,2,14,22,aqk0sr,Tensorflow.js model visualisation library.,https://www.reddit.com/r/tensorflow/comments/aqk0sr/tensorflowjs_model_visualisation_library/,cstefanache,1550152794,,0,1
43,2019-2-15,2019,2,15,0,aqkmvj,reduce_sum leads to Inf or Nan,https://www.reddit.com/r/tensorflow/comments/aqkmvj/reduce_sum_leads_to_inf_or_nan/,linshiyx,1550156573,"[https://stackoverflow.com/questions/54692838/tensorflow-reduce-sum-leads-to-inf-or-nan](https://stackoverflow.com/questions/54692838/tensorflow-reduce-sum-leads-to-inf-or-nan)

\`\`\`

from tensorflow.python.ops import gen\_nn\_ops, array\_ops, math\_ops, numerics

grads = tf.gradients(loss, params) 

half\_squared\_norms = \[gen\_nn\_ops.l2\_loss(g) for g in grads\]

half\_squared\_norm = math\_ops.reduce\_sum(array\_ops.stack(half\_squared\_norms))

\`\`\`

The \`half\_squared\_norm\` fails the  \`numerics.verify\_tensor\_all\_finite\`. Do you have any ideas? Thank you!",3,1
44,2019-2-15,2019,2,15,3,aqmqvo,Help with random crops using the dataset API,https://www.reddit.com/r/tensorflow/comments/aqmqvo/help_with_random_crops_using_the_dataset_api/,aaronjl33,1550168319,"I am trying to get a different random\_crop using the dataset API. The randomized crop percentage is baked into the graph, so that should be randomized each iteration, and the actual crop is randomized each iteration, but the seed is calculated once when the graph is being created, then reused each iteration. Will this still give me the desired result? I looked into using tf.random.get\_seed() or set\_random\_seed(), but I'm not sure that'll help me. I also can't set seed from tf.random.uniform() because that will give me a tensor and the seed argument in tf.random\_crop requires an int. Since the shape of the crop will be a little different each time, it might not even matter that the seed is the same. Below is an example of my code.

Thanks for the help.

&amp;#x200B;

    def random_crop(dset, params) :
        def _random_crop(image, mask):
            img_orig_shape = image.shape
            mask_orig_shape = mask.shape
            seed = random.random()
    
            crop_percentage = tf.random.normal([],1,0.5)
            crop_percentage = tf.cond(tf.math.greater(crop_percentage, 1), lambda: tf.constant(1.0), lambda: tf.identity(crop_percentage))
            crop_percentage = tf.cond(tf.math.less(crop_percentage, 0.1), lambda: tf.constant(0.1), lambda: tf.identity(crop_percentage))
            dimension = image.shape[0].value * crop_percentage
    
            image = tf.random_crop(image, [dimension,dimension,image.shape[2]], seed=seed)
            image = tf.image.resize_images(image, img_orig_shape[:2])
    
            mask  = tf.random_crop(mask,  [dimension,dimension, mask.shape[2]], seed=seed)
            mask = tf.image.resize_images(mask, img_orig_shape[:2], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)
    
            return image,mask
        return dset.map(_random_crop)

&amp;#x200B;",0,1
45,2019-2-15,2019,2,15,4,aqnd7s,Memory-Efficient Backpropagation Through Time,https://www.reddit.com/r/tensorflow/comments/aqnd7s/memoryefficient_backpropagation_through_time/,GaiusJuliusInternets,1550171507,"Hello TF community,

I am looking for methods to train my RNN with longer sequences (video input).

I ran into this article: [https://arxiv.org/abs/1606.03401](https://arxiv.org/abs/1606.03401)

Does anyone know of a TF implementation for it? There is an implementation for a very similar idea ([here](https://medium.com/tensorflow/fitting-larger-networks-into-memory-583e3c758ff9?fbclid=IwAR3Rlh6_8iuEjiUzSF5NyneIzqtgar6xT_0iSwtbmhu0qfCPmCrwdSmq4Ks)) but it doesn't work when tf.while\_loop is involved.

I would also appreciate any other suggestions on how to improve memory usage during RNN unrolling.

Thank you :)",1,1
46,2019-2-15,2019,2,15,11,aqrzxb,"Machine Learning with Python, Jupyter, KSQL and TensorFlow",https://www.reddit.com/r/tensorflow/comments/aqrzxb/machine_learning_with_python_jupyter_ksql_and/,Gokuha,1550198983,[removed],0,1
47,2019-2-16,2019,2,16,9,ar30y7,Failing unit tests,https://www.reddit.com/r/tensorflow/comments/ar30y7/failing_unit_tests/,MarchColorDrink,1550275407,"Im following this https://www.tensorflow.org/install/source to build tensorflow (1.12rc2) on a p3.2xlarge ec2 instance (Ubuntu 18.04, python3.6, cuda 10.0, cudnn 7.3.2, bazel 0.17.2). The build goes just fine. When I run the unit tests however it fails miserably.

When running
export flags=""--config=opt --config=cuda -k""
bazel test ${flags} //tensorflow/python/...

I get loads of failures related to gpu out of memory. Bazel will run 8 tasks and at Times multiple of them will allocate  GPU memory leading to failures.

The same goes when running
bazel test -c opt -c cuda -- //tensorflow/... -//tensorflow/compiler/... -//tensorflow/contrib/lite/...

I May be able to get aroumd it if specifying local_resources to limit to one task. But that takes ages...

I guess it should be possible to run bazel build... on all cores and then switch to bazel test on just 1. But every time I try that bazel test will start from a clean slate and just build all targets anyway.

Im not sure on next steps to attempt. Ideas?",0,2
48,2019-2-16,2019,2,16,11,ar472c,Is there any necessary to have Nvidia graphics to get started with tensorflow?,https://www.reddit.com/r/tensorflow/comments/ar472c/is_there_any_necessary_to_have_nvidia_graphics_to/,sudipbhujel,1550283435,"Fact is, I have amd graphics on my machine.",10,2
49,2019-2-16,2019,2,16,15,ar6892,How is the better size image for to neuronal network convolucional ??,https://www.reddit.com/r/tensorflow/comments/ar6892/how_is_the_better_size_image_for_to_neuronal/,Aaron-Ponce-Sandoval,1550298926,"Hello its my first post I am work in the project the classification audios with spectrogram in the cnn, every audio have 2 seconds time, my doubt is how is the better size there spectogram for the clasificaction.

Thanks",0,0
50,2019-2-18,2019,2,18,1,arm8ta,Marathon Bib Identification and Recognition,https://www.reddit.com/r/tensorflow/comments/arm8ta/marathon_bib_identification_and_recognition/,kapilvarshney,1550421899,,0,6
51,2019-2-18,2019,2,18,22,arxdtd,Troubles building my input pipeline using tf.data.Dataset,https://www.reddit.com/r/tensorflow/comments/arxdtd/troubles_building_my_input_pipeline_using/,jthat92,1550497605,,0,6
52,2019-2-18,2019,2,18,23,arxkrh,Fast Fourier Transform in TensorFlow.js WebGL backend,https://www.reddit.com/r/tensorflow/comments/arxkrh/fast_fourier_transform_in_tensorflowjs_webgl/,lewuathe,1550498927,,0,1
53,2019-2-19,2019,2,19,18,as8h82,Will Google eventually switch from TensorFlow to PyTorch?,https://www.reddit.com/r/tensorflow/comments/as8h82/will_google_eventually_switch_from_tensorflow_to/,Laurenw2,1550567591,[http://on.morioh.net/60f474fa81](http://on.morioh.net/60f474fa81),6,0
54,2019-2-19,2019,2,19,18,as8pfy,TensorFlow.FSharp: TensorFlow API for F,https://www.reddit.com/r/tensorflow/comments/as8pfy/tensorflowfsharp_tensorflow_api_for_f/,helpdeveu,1550569647,,0,1
55,2019-2-19,2019,2,19,20,as9avt,Tensorflow serving object detection predict using Kubeflow,https://www.reddit.com/r/tensorflow/comments/as9avt/tensorflow_serving_object_detection_predict_using/,zinngg,1550574824,,0,4
56,2019-2-19,2019,2,19,21,asa0y4,Problems with MirroredStrategy - the GPUs don't get used by the distribute strategy,https://www.reddit.com/r/tensorflow/comments/asa0y4/problems_with_mirroredstrategy_the_gpus_dont_get/,jthat92,1550580343,,0,1
57,2019-2-20,2019,2,20,3,asddol,Some examples to help you started with Tensorflow 2.0!,https://www.reddit.com/r/tensorflow/comments/asddol/some_examples_to_help_you_started_with_tensorflow/,thibo73800,1550599761,,2,24
58,2019-2-21,2019,2,21,0,aspwrj,How to parse tensorflow labels saved as pbtxt?,https://www.reddit.com/r/tensorflow/comments/aspwrj/how_to_parse_tensorflow_labels_saved_as_pbtxt/,mehdital,1550678094,"The text file looks simple but I fail to find any explanation on what to use to load a .pbtxt label file in a structured way in python (dict for example).

&amp;#x200B;

Here is an example of label.pbtxt

answers {

  worker: 4337547990

  labels {

geometry {

polygon {

loops {

points {

x: 78.111111111111086

y: 29.222222222222246

}

points {

x: 224.72222222222217

y: 32.333333333333357

}

points {

x: 227.4444444444444

y: 127.22222222222223

}

points {

x: 84.722222222222172

y: 126.44444444444446

}

closed: true

}

}

}

  }

}

&amp;#x200B;

any python snippet would be highly appreciated",1,3
59,2019-2-21,2019,2,21,18,at151l,What is the necessity of create a variable before computation?,https://www.reddit.com/r/tensorflow/comments/at151l/what_is_the_necessity_of_create_a_variable_before/,Laurence-Lin,1550740782,"In a neural network, when defining a weight matrix, we use tf.Variable or tf.get\_variable before we run the session.   
However, why couldn't I just define the value directly by using tf.random\_normal() to get a matrix when running the session?  


Using the variable in tensorflow, I need to initialize by global\_initializer() before running, I think it took more steps in the procedure.  


Thanks!  
",6,2
60,2019-2-23,2019,2,23,13,atrbcq,Help with understanding tf.profiler.advise,https://www.reddit.com/r/tensorflow/comments/atrbcq/help_with_understanding_tfprofileradvise/,venktech,1550895947,"I tried analysing my model using tf.profiler.advise to know why my inference time is too high. I got the results which shows a list of expensive operations like 

ExpensiveOperationChecker:

top 1 operation type: Merge, cpu: 930.26ms, accelerator: 0us, total: 930.26ms (27.59%)

top 2 operation type: Switch, cpu: 562.58ms, accelerator: 0us, total: 562.58ms (16.69%)

top 3 operation type: TensorArrayWriteV3, cpu: 345.30ms, accelerator: 0us, total: 345.30ms (10.24%)

&amp;#x200B;

Anyone played with tf.profiler.advise could tell what cpu means. Does it mean the op ran in my cpu instead of gpu? 

&amp;#x200B;

I expected it to run in my gpu and I have also set CUDA\_VISIBLE\_DEVICES to 0. Is there any other way to force it to use the GPU",0,2
61,2019-2-24,2019,2,24,0,atwlfo,Any good guides on how to implement summaries into code?,https://www.reddit.com/r/tensorflow/comments/atwlfo/any_good_guides_on_how_to_implement_summaries/,TCFlow,1550936012,"I started my first class in DL about a month ago, and we're starting to implement MNIST classifiers with different architectures (such as Google's example of 1CL , 2CL , 1FC, 2FC), but I still haven't been able to figure out how summaries work in code. Every test example I've tried to make doesn't work to my favor, and I'm feeling like conquering this challenge and understanding Tensorboard more broadly is a necessary skill going forward. I also made a Stack Overflow post on this, though nobody has responded yet. Thank you for any help! [https://stackoverflow.com/questions/54836181/tensorboard-summaries-stuck-at-0](https://stackoverflow.com/questions/54836181/tensorboard-summaries-stuck-at-0)",0,2
62,2019-2-24,2019,2,24,11,au3abi,Online PPO: TensorFlow Session returns NaN,https://www.reddit.com/r/tensorflow/comments/au3abi/online_ppo_tensorflow_session_returns_nan/,nikhilraghava,1550975404,"Im trying to implement an online proximal policy optimisation model using TensorFlow to land a SpaceX rocket in a simulated gym environment. All goes well until my model starts returning NaNs and the whole thing becomes a mess and the rocket just disappears because the actions being chosen are just NaNs.

Ive tried to lower the learning rate of the actor and critic networks but it doesnt work. I've also reduced the `BATCH` number so that the PPO gets updated faster but it doesn't work too.

**Short snippet from console:**
```bash
Action Taken   [2.        1.3305835 0.9937418]
Observation    [  0.69689728  -0.46114012 -11.39961704  -0.05004346  -0.05004346
   0.74720544   3.49857114   3.05071477  -1.10276782  -9.71530186]
Reward Gained  -0.023699851569145534

Action Taken   [2.         0.62562937 1.0081608 ]
Observation    [ 0.71591491 -0.47488649 11.84026042 -0.05004346 -0.05004346  0.75886336
  3.49857114  3.07180685 -1.12458586 -9.84382414]
Reward Gained  -0.015462812448075767

Action Taken   [nan nan nan]
Observation    [        nan         nan         nan -0.05004346 -0.05004346         nan
         nan         nan         nan         nan]
Reward Gained  nan

Action Taken   [nan nan nan]
Observation    [        nan         nan         nan -0.05004346 -0.05004346         nan
         nan         nan         nan         nan]
Reward Gained  nan
```

**My code:**
```python
import gym
import numpy as np
import tensorflow as tf
import rocket_lander_gym

EP_LEN = 200
GAMMA = 0.9
SL_LR = 1e-4
CR_LR = 1e-4
BATCH = 5
ACTOR_UPDATE_STEPS = 10
CRITIC_UPDATE_STEPS = 10
STATE_DIM, ACT_DIM = 10, 3

METHOD = [
    dict(name='kl_penalty', kl_target=0.01, lam=0.5),   
    dict(name='clip', epsilon=0.2),
][1]

PRINT_DEBUG_MSG = True

class PPO:
    def __init__(self):
        self.tfsess = tf.Session()
        self.tf_state = tf.placeholder(tf.float32, [None, STATE_DIM], 'state')

        # Critic (value network)
        with tf.variable_scope('critic'):
            # Layers
            l1 = tf.layers.dense(self.tf_state, 100, tf.nn.relu)
            # Value
            self.value = tf.layers.dense(l1, 1)
            # Discounted reward: reward in the furture
            self.tf_dreward = tf.placeholder(tf.float32, [None, 1], 'discounted_reward')
            # Advantage: determine quality of action
            self.advantage = self.tf_dreward - self.value
            # Loss function: minimize the advantage over time
            # The loss function is a mean squared error
            self.loss = tf.reduce_mean(tf.square(self.advantage))
            # Gradient descent using Adam optimizer
            self.train_opt = tf.train.AdamOptimizer(CR_LR).minimize(self.loss)

        # Actor (policy network)
        pi, pi_params = self.tinynn('pi', trainable=True)
        old_pi, old_pi_params = self.tinynn('old_pi', trainable=False)

        # Sample actions from both the old and the new policy networks
        with tf.variable_scope('sample_action'):
            # Choose an action from the distribution learnt
            self.sample_operation = tf.squeeze(pi.sample(1), axis=0)
        with tf.variable_scope('update_old_pi'):
            # Choose an action from the distribution learnt
            self.update_old_pi_operation = [old_pi.assign(p) for p, old_pi in zip(pi_params, old_pi_params)]

        # Placeholder for the action and the advantage
        self.tf_action = tf.placeholder(tf.float32, [None, ACT_DIM], 'action')
        self.tf_advantage = tf.placeholder(tf.float32, [None, 1], 'advantage')

        # Compute loss function
        with tf.variable_scope('loss'):
            with tf.variable_scope('surrogate'):
                ratio = pi.prob(self.tf_advantage) / old_pi.prob(self.tf_advantage)
                surrogate = ratio * self.tf_advantage

            # KL penalty
            if METHOD['name'] == 'kl_penalty':
                # Lambda
                self.tf_lambda = tf.placeholder(tf.float32, None, 'lambda')
                # Compute KL divergence between old and new policy
                kl = tf.contrib.distributions.kl_divergence(old_pi, pi)
                # Get mean
                self.kl_mean = tf.reduce_mean(kl)
                # Compute loss using surrogate
                self.aloss = -(tf.reduce_mean(surrogate - self.tf_lambda * kl))
            else:
                self.aloss = -tf.reduce_mean(tf.minimum(surrogate, tf.clip_by_value(ratio, 1.-METHOD['epsilon'],  1.+METHOD['epsilon']) * self.tf_advantage))

        # Minimize the loss using gradient descent
        with tf.variable_scope('atrain'):
            self.atrain_operation = tf.train.AdamOptimizer(SL_LR).minimize(self.aloss)

        # Write to disk
        tf.summary.FileWriter(""log/"", self.tfsess.graph)

        # Run the session
        self.tfsess.run(tf.global_variables_initializer())


    def update(self, state, action, reward):
        self.tfsess.run(self.update_old_pi_operation)
        advantage = self.tfsess.run(self.advantage, {self.tf_state: state, self.tf_dreward: reward})

        # Update actor (policy)
        if METHOD['name'] == 'kl_penalty':
            for _ in range(ACTOR_UPDATE_STEPS):
                _, kl = self.tfsess.run([self.atrain_operation, self.kl_mean], {self.tf_state: state, self.tf_action: action, tf_advantage: advantage, self.tf_lambda: METHOD['lam']})
                if kl &gt; 4*METHOD['kl_target']:
                    break
            if kl &lt; METHOD['kl_target'] / 1.5:
                # Adaptive lambda
                METHOD['lam'] /= 2
            elif kl &gt; METHOD['kl_target'] * 1.5:
                METHOD['lam'] *= 2
            # Lambda might explode, we need to clip it
            METHOD['lam'] = np.clip(METHOD['lam'], 1e-4, 10)
        else:
            [self.tfsess.run(self.atrain_operation, {self.tf_state: state, self.tf_action: action, self.tf_advantage: advantage}) for _ in range(ACTOR_UPDATE_STEPS)]

        # Update critic (value)
        [self.tfsess.run(self.train_opt, {self.tf_state: state, self.tf_dreward: reward}) for _ in range(CRITIC_UPDATE_STEPS)]


    def tinynn(self, name, trainable):
        with tf.variable_scope(name):
            l1 = tf.layers.dense(self.tf_state, 100, tf.nn.relu, trainable=trainable)
            mu = 2 * tf.layers.dense(l1, ACT_DIM, tf.nn.tanh, trainable=trainable)
            sigma = tf.layers.dense(l1, ACT_DIM, tf.nn.softplus, trainable=trainable)
            norm_dist = tf.distributions.Normal(loc=mu, scale=sigma)
        params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=name)
        return norm_dist, params


    def choose_action(self, state):
        state = state[np.newaxis, :]
        action = self.tfsess.run(self.sample_operation, {self.tf_state: state})[0]
        return np.clip(action, -1, 1)


    def get_value(self, state):
        if state.ndim &lt; 2: state = state[np.newaxis, :]
        return self.tfsess.run(self.value, {self.tf_state: state})[0, 0]


    def train(self, env, ppo, epochs, render=True):
        # Rewards
        all_ep_r = []
        # Training loop
        for ep in range(epochs):
            # Initial state
            s = env.reset()
            # States, actions and rewards
            buffer_s, buffer_a, buffer_r = [], [], []
            # Initial reward
            ep_r = 0
            # For a single episode
            for t in range(EP_LEN):
                if render:
                    # Render the environment
                    env.render()
                # Choose best action
                a = ppo.choose_action(s)
                # State,reward,done,info
                s_, r, done, _ = env.step(a)
                if PRINT_DEBUG_MSG:
                    print(""Action Taken  "",a)
                    print(""Observation   "",s_)
                    print(""Reward Gained "",r, end='\n\n')
                # Add to buffers
                buffer_s.append(s)
                buffer_a.append(a)
                buffer_r.append((r+8)/8)    # normalize reward, find to be useful
                s = s_
                # Total reward
                ep_r += r

                # Update PPO
                if (t+1) % BATCH == 0 or t == EP_LEN - 1:
                    # Get value
                    v_s_ = ppo.get_value(s_)
                    # Discounted reward
                    discounted_r = []
                    # Update rewards
                    for r in buffer_r[::-1]:
                        v_s_ = r + GAMMA * v_s_
                        discounted_r.append(v_s_)
                    discounted_r.reverse()
                    # Buffer states actions rewards
                    bs, ba, br = np.vstack(buffer_s), np.vstack(buffer_a), np.array(discounted_r)[:, np.newaxis]
                    buffer_s, buffer_a, buffer_r = [], [], []
                    ppo.update(bs, ba, br)

                # Check if done
                if done:
                    print(""Simulation done."")
                    break
            # Close the environment
            env.close()
            if ep == 0: all_ep_r.append(ep_r)
            else: all_ep_r.append(all_ep_r[-1]*0.9 + ep_r*0.1)
        # Return all episode rewards
        return all_ep_r


if __name__ == '__main__':
    ppo = PPO()
    env = gym.make('RocketLander-v0')
    reward = ppo.train(env, ppo, 100)
    print(reward)
```

I've been stuck with this for days now. Any help would be greatly appreciated.",0,4
63,2019-2-24,2019,2,24,11,au3jpn,questions about the latest graphic card...,https://www.reddit.com/r/tensorflow/comments/au3jpn/questions_about_the_latest_graphic_card/,samueldyb,1550977149,"Recently I am working with an open source TF software that uses TF 1.12 and the according protobuf, as well as CUDA 9. I wonder if I buy the new 1660 TI would any of these software support the new hardware? any speculations?",2,2
64,2019-2-24,2019,2,24,14,au4r2c,TensorFlow 1.13.0 Released,https://www.reddit.com/r/tensorflow/comments/au4r2c/tensorflow_1130_released/,myturn19,1550985595,,6,51
65,2019-2-24,2019,2,24,19,au6r7t,Mobile intelligence  traffic signs classification with retrained MobileNet model for TensorFlow Lite,https://www.reddit.com/r/tensorflow/comments/au6r7t/mobile_intelligence_traffic_signs_classification/,frogermcs,1551003896,,0,3
66,2019-2-25,2019,2,25,18,aujbun,[Q] Practicalities of pruning in TensorFlow,https://www.reddit.com/r/tensorflow/comments/aujbun/q_practicalities_of_pruning_in_tensorflow/,Lenkz,1551086494,"Hello,

&amp;#x200B;

I was looking into doing pruning using TensorFlow, in the hopes of creating a model that would be significantly smaller than my current model.

&amp;#x200B;

So I do a simple example using the MNIST dataset. I'm using the `tensorflow.contrib.model_pruning.python` framework and it seems to work as expected, I do some sparsity and I lose accuracy. I save the model before and after pruning, but the model is actually the same size. Is it actually possible to remove some of the neurons from the network, making it have less parameters? Because otherwise my network is not really faster or smaller even though I have done pruning.",5,2
67,2019-2-25,2019,2,25,18,auje91,Progressive GAN - How to modify computation graph after loading checkpoint?,https://www.reddit.com/r/tensorflow/comments/auje91/progressive_gan_how_to_modify_computation_graph/,StackBPoppin,1551087051,"I am trying to implement the progressive GAN as outlined here: [https://arxiv.org/abs/1710.10196](https://arxiv.org/abs/1710.10196)

I have trained the first layer of both the generator and discriminator, however when adding new layers I have to do the following:

    all_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='generator') + tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='discriminator')
    dont_restore = ['discriminator/disc_3x3_7/bias:0', 'discriminator/disc_3x3_7/bias/Adam:0', 'discriminator/disc_3x3_7/bias/Adam_1:0',
                    'discriminator/disc_3x3_7/kernel:0', 'discriminator/disc_3x3_7/kernel/Adam:0', 'discriminator/disc_3x3_7/kernel/Adam_1:0',
                    'discriminator/disc_3x3_8/bias:0', 'discriminator/disc_3x3_8/bias/Adam:0', 'discriminator/disc_3x3_8/bias/Adam_1:0',
                    'discriminator/disc_3x3_8/kernel:0', 'discriminator/disc_3x3_8/kernel/Adam:0', 'discriminator/disc_3x3_8/kernel/Adam_1:0',
                    'generator/gen_3x3_3/bias:0', 'generator/gen_3x3_3/bias/Adam:0', 'generator/gen_3x3_3/bias/Adam_1:0',
                    'generator/gen_3x3_3/kernel:0', 'generator/gen_3x3_3/kernel/Adam:0', 'generator/gen_3x3_3/kernel/Adam_1:0',
                    'generator/gen_3x3_4/bias:0', 'generator/gen_3x3_4/bias/Adam:0', 'generator/gen_3x3_4/bias/Adam_1:0',
                    'generator/gen_3x3_4/kernel:0', 'generator/gen_3x3_4/kernel/Adam:0',
                    'generator/gen_3x3_4/kernel/Adam_1:0',
                    'discriminator/disc_3x3_9/kernel:0', 'discriminator/disc_3x3_9/kernel/Adam:0', 'discriminator/disc_3x3_9/kernel/Adam_1:0'
                    ]
    restore = [v for v in all_vars if v.name not in dont_restore]
    loader = tf.train.Saver(var_list=restore)
    saver = tf.train.Saver()
    
    sess = tf.Session()
    sess.run(tf.global_variables_initializer())

It works but is quite an ugly solution, the variables `disc_3x3_7, disc_3x3_8, gen_3x3_3, gen_3x3_4` are the new layers which have been added, if I don't include the `dont_restore` list then I get an error saying the checkpoint can't be loaded.

&amp;#x200B;

Is there a better way of doing this? Or at least a way to clean up this approach?

&amp;#x200B;

Thank you",2,3
68,2019-2-26,2019,2,26,9,auslsc,TensorFlow 1.13.1 Released,https://www.reddit.com/r/tensorflow/comments/auslsc/tensorflow_1131_released/,myturn19,1551140888,,5,13
69,2019-2-26,2019,2,26,15,auw3fp,Has anyone moved from PyTorch to TensorFlow?,https://www.reddit.com/r/tensorflow/comments/auw3fp/has_anyone_moved_from_pytorch_to_tensorflow/,mlvpj,1551162196,I have read about lot of people moving from TensorFlow to PyTorch. I haven't heard any one making the switch other way. Is there any one who has done it? If so why?,0,1
70,2019-2-26,2019,2,26,17,aux128,[Q] Has anyone moved from PyTorch to TensorFlow?,https://www.reddit.com/r/tensorflow/comments/aux128/q_has_anyone_moved_from_pytorch_to_tensorflow/,mlvpj,1551169160,I have read about lot of people moving from TensorFlow to PyTorch. I haven't heard any one making the switch other way. Is there any one who has done it? If so why?,6,7
71,2019-2-26,2019,2,26,18,auxfmi,Get started with Apache Spark and TensorFlow on Azure Databricks,https://www.reddit.com/r/tensorflow/comments/auxfmi/get_started_with_apache_spark_and_tensorflow_on/,MuhammadAdnano,1551172461,,0,1
72,2019-2-27,2019,2,27,3,av30nm,[Q] Weird tensor flow gpu behavior? (with tf.device),https://www.reddit.com/r/tensorflow/comments/av30nm/q_weird_tensor_flow_gpu_behavior_with_tfdevice/,thethiny,1551207195,"So I noticed that I had both tensor flow and -gpu versions installed. However, when I used to do list devices (sess) it would show me that gpu:0 is one of the devices, probably cuz I have Cuda installed correctly.
Moving on to the weird behavior:
When I wrote:
with tf.devices('/device/GPU:0')
All was working fine, but gpu usage was 0 and cpu was 100%. However when I wrote ""gpu:0"" (in small instead of caps) I got an error saying there's no device called gpu:0.
Now, I understand that this is conflict between both versions I have, that's why it can't see the gpu, but what I don't get is that why did it NOT error on me when it was in caps, but it did error when it was in low? I'm thinking maybe because GPU:0 doesn't actually exist? ",4,1
73,2019-2-27,2019,2,27,6,av55cj,Help with appropriate gather/gather_nd/batch_gather,https://www.reddit.com/r/tensorflow/comments/av55cj/help_with_appropriate_gathergather_ndbatch_gather/,identicalParticle,1551218195,"I have a tensor `I` of size `[181,256,181,4]` .  It is actually just 4 3D medical images.

I have a tensor `ind` of size `[181,256,181]`.  Each element contains the integer 0,1,2,3.

My desired output `out` is a single 3D image. At every ""voxel"" (a 3D pixel) it should contain the corresponding voxel of `I`, selected according to the value of `ind`.

That is, `out[i,j,k] = I[i,j,k,ind[i,j,k]]`.

I'm having trouble finding a way for this to work using any of the ""gather"" functions or standard slicing techniques.

Can you folks help out?

Thanks!
",3,2
74,2019-2-27,2019,2,27,15,avael9,Where are the unoptimized tensorflow 1.13.1 wheels?,https://www.reddit.com/r/tensorflow/comments/avael9/where_are_the_unoptimized_tensorflow_1131_wheels/,callmenoobile2,1551250313,I have been looking for the unoptimized versions because I am in a very precarious cloud installation postion. Cheers,0,1
75,2019-2-28,2019,2,28,2,avg5h5,Ragged tensors with tf.Records and the data api?,https://www.reddit.com/r/tensorflow/comments/avg5h5/ragged_tensors_with_tfrecords_and_the_data_api/,CommunismDoesntWork,1551289506,"I want to make a record that contains ragged tensors, and use it with the data api. Are there any code samples that show how to do this?",1,4
0,2019-3-1,2019,3,1,12,aw0854,Introducing TensorFlow Datasets,https://www.reddit.com/r/tensorflow/comments/aw0854/introducing_tensorflow_datasets/,SerkanKONAKCI,1551412460,[http://on.geeklearn.net/d40f0312a9](http://on.geeklearn.net/d40f0312a9),4,17
1,2019-3-1,2019,3,1,14,aw11nq,How do I save a Bi-LSTM layer from one computation graph and use it in another graph?,https://www.reddit.com/r/tensorflow/comments/aw11nq/how_do_i_save_a_bilstm_layer_from_one_computation/,cant-find-user-name,1551417769,"Hi, I am trying to perform Named entity recognition using Bi-LSTM-CRF network. One component of the network is a bi-lstm network, which learns character level embeddings. Since I have a lot more unlabelled data, I trained a seperate bi-lstm model on the data and learned a language model. 

I want to use the weights of this bi-lstm network to initialize the bi-lstm network in a seperate graph. How do I got about doing this? I know how to save and load tensorflow variables (I have used tf.sess.saver() for this purpose before), but I do not know how to do this for a bi-lstm network. (More specifically, tf.nn.bidirectional_dynamic_rnn with tf.contrib.rnn.LSTMCell).

Any help is very very appreciated. 
Thanks :) ",5,3
2,2019-3-1,2019,3,1,17,aw2jgj,Data Scientists: What are the biggest limitations of using Tensorboard for a team of 3 data scientists?,https://www.reddit.com/r/tensorflow/comments/aw2jgj/data_scientists_what_are_the_biggest_limitations/,treguess,1551429245,,0,0
3,2019-3-2,2019,3,2,9,awbrv0,"Problem with TensorFlow's ""Load Data"" tut.",https://www.reddit.com/r/tensorflow/comments/awbrv0/problem_with_tensorflows_load_data_tut/,caine2003,1551486614,,0,3
4,2019-3-2,2019,3,2,20,awh1ys,Confusion matrix with tensorhub,https://www.reddit.com/r/tensorflow/comments/awh1ys/confusion_matrix_with_tensorhub/,Noemi3,1551527629,Hi! I'm trying to do a confusion matrix with tensorhub of a tensorflow model with 4 input but I can't make it. Is there someone that can suggest me how can I do? Thanks so much ,2,4
5,2019-3-2,2019,3,2,21,awhadd,"Eorror when trying to install on Pi, any ideas?",https://www.reddit.com/r/tensorflow/comments/awhadd/eorror_when_trying_to_install_on_pi_any_ideas/,Redstoner7,1551529566,,3,3
6,2019-3-3,2019,3,3,16,awrwkz,What is the difference between these two code blocks?,https://www.reddit.com/r/tensorflow/comments/awrwkz/what_is_the_difference_between_these_two_code/,begooboi,1551599137,"I have two identical code blocks of gives error and other runs.

	with tf.Session as sess:
		sess.run(init_op)	
		d = {X: np.random.rand(100, 784)}
		print(sess.run(h, feed_dict=d))

This gives 

	Traceback (most recent call last):
	  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
	AttributeError: __exit__

But this code blocks which I copy pasted from a website works

	with tf.Session() as sess:
		# initialize variables
		sess.run(init_op)
		# create the dictionary:
		d = {X: np.random.rand(100, 784)}
		# feed it to placeholder a via the dict 
		print(sess.run(h, feed_dict=d))
",0,1
7,2019-3-3,2019,3,3,23,awu93c,Trouble feeding data into tensorflow graph,https://www.reddit.com/r/tensorflow/comments/awu93c/trouble_feeding_data_into_tensorflow_graph/,atinesh229,1551621908,"I have trained a neural network model on \`MNIST\` dataset using the script [mnist\_3.1\_convolutional\_bigger\_dropout.py](https://www.dropbox.com/s/mzrui1b46qx4zmz/mnist_3.1_convolutional_bigger_dropout.py?dl=0) provided in this [tutorial](https://github.com/GoogleCloudPlatform/tensorflow-without-a-phd/tree/master/tensorflow-mnist-tutorial).

&amp;#x200B;

I wanted to test the trained model on the custom dataset, hence I wrote a small script \`predict.py\` which loads the trained model and feed the data to it. I tried 2 methods for preprocessing images so that they are compatible with MNIST format.

&amp;#x200B;

* **Method 1**: Resizing the image to 28x28
* **Method 2**: Technique mentioned [here](https://www.youtube.com/watch?v=oYndcjlzwX8) is used

&amp;#x200B;

Both of these methods result in the error 

&amp;#x200B;

&gt;InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder\_2' with dtype float

&amp;#x200B;

The detailed error can be seen from [here](https://www.dropbox.com/s/zrnduvaxxi5hnbt/error.txt?dl=0)

&amp;#x200B;

\*\*[predict.py](https://predict.py)\*\*

        # Importing libraries
        from scipy.misc import imread
        import tensorflow as tf
        import numpy as np
        import cv2 as cv
        import glob
        
        from test import imageprepare
        
        files = glob.glob('data2/*.*')
        #print(files)
        
        # Method 1
        '''
        img_data = []
        for fl in files:
        	img = imageprepare(fl)
        	img = img.reshape(img.shape[0], img.shape[1], 1)
        	img_data.append(img)
        '''
        
        # Method 2
        dig_cont = [cv.imread(fl, 0) for fl in files]
        #print(len(dig_cont))
        
        img_data = []
        for i in range(len(dig_cont)):
        	img = cv.resize(dig_cont[i], (28, 28))
        	img = img.reshape(img.shape[0], img.shape[1], 1)
        	img_data.append(img)
        print(""Restoring Model ..."")
        
        sess = tf.Session()
        
        # Step-1: Recreate the network graph. At this step only graph is created.
        tf_saver = tf.train.import_meta_graph('model/model.meta')
        
        # Step-2: Now let's load the weights saved using the restore method.
        tf_saver.restore(sess, tf.train.latest_checkpoint('model'))
        
        print(""Model restored"")
        
        x = tf.get_default_graph().get_tensor_by_name('X:0')
        print('x :', x.shape)
        y = tf.get_default_graph().get_tensor_by_name('Y:0')
        print('y :', y.shape)
        
        dict_data = {x: img_data}
        
        result = sess.run(y, feed_dict=dict_data)
        print(result)
        print(result.shape)
        
        sess.close()

[test.py](https://www.dropbox.com/s/k7g28auhn6f6hoa/test.py?dl=0)",4,2
8,2019-3-4,2019,3,4,0,awv4it,Step by Step Guide to Tensorflow - A Free Video Course,https://www.reddit.com/r/tensorflow/comments/awv4it/step_by_step_guide_to_tensorflow_a_free_video/,prithvi45,1551627925,,1,26
9,2019-3-5,2019,3,5,4,axbf4p,Is it possible to export a checkpoint trained in Tensorflow 1.9 to Tensorflow 1.7 graph?,https://www.reddit.com/r/tensorflow/comments/axbf4p/is_it_possible_to_export_a_checkpoint_trained_in/,bboylayz,1551728828,"I'm new to TF and ML, so forgive me if I asked that question using the wrong terminology. I used Google Cloud to train an object detection model using Runtime 1.9, which according to this: [https://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list](https://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list), leverages Tensorflow 1.9.

&amp;#x200B;

However, I am attempting to get image detection working in a Unity project, and their TFSharp lib only supports up to TF1.7. The problem is, Google Cloud deprecated support for training a TF1.7. So unless I train on my own machines, I can only get checkpoints in 1.8 or higher.  


Long story short, I have these files:

model.ckpt-159557.data-00000-of-00003

model.ckpt-159557.data-00001-of-00003

model.ckpt-159557.data-00002-of-00003

model.ckpt-159557.index

model.ckpt-159557.meta

&amp;#x200B;

What can I do from here, if anything, to export a graph.pb (or even better, bytes, since Unity requires a .bytes file) that is ""trained using Tensorflow 1.7?""",0,1
10,2019-3-5,2019,3,5,10,axfc6f,Anaconda Spyder import tensorflow as tf not working,https://www.reddit.com/r/tensorflow/comments/axfc6f/anaconda_spyder_import_tensorflow_as_tf_not/,SuperJMan64,1551749859,"So I installed Anaconda and tensorflow Spyder, but I can't get import tensorflow as tf to work. There are a lot of different answers and so I just wanted to figure out the one I want. This is the error:

&amp;#x200B;

In \[9\]: runfile('C:/Users/jedwa/Anaconda3/envs/tensorflow/lib/imp.py', wdir='C:/Users/jedwa/Anaconda3/envs/tensorflow/lib')

Traceback (most recent call last):

&amp;#x200B;

  File ""&lt;ipython-input-9-a50a85bb1782&gt;"", line 1, in &lt;module&gt;

runfile('C:/Users/jedwa/Anaconda3/envs/tensorflow/lib/imp.py', wdir='C:/Users/jedwa/Anaconda3/envs/tensorflow/lib')

&amp;#x200B;

  File ""C:\\Users\\jedwa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\spyder\_kernels\\customize\\[spydercustomize.py](https://spydercustomize.py)"", line 786, in runfile

execfile(filename, namespace)

&amp;#x200B;

  File ""C:\\Users\\jedwa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\spyder\_kernels\\customize\\[spydercustomize.py](https://spydercustomize.py)"", line 110, in execfile

exec(compile([f.read](https://f.read)(), filename, 'exec'), namespace)

&amp;#x200B;

  File ""C:/Users/jedwa/Anaconda3/envs/tensorflow/lib/imp.py"", line 1, in &lt;module&gt;

import tensorflow as tf;

&amp;#x200B;

  File ""C:\\Users\\jedwa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\\_\_init\_\_.py"", line 24, in &lt;module&gt;

from tensorflow.python import pywrap\_tensorflow  # pylint: disable=unused-import

&amp;#x200B;

  File ""C:\\Users\\jedwa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\\_\_init\_\_.py"", line 49, in &lt;module&gt;

from tensorflow.python import pywrap\_tensorflow

&amp;#x200B;

  File ""C:\\Users\\jedwa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow.py"", line 74, in &lt;module&gt;

raise ImportError(msg)

&amp;#x200B;

ImportError: Traceback (most recent call last):

  File ""C:\\Users\\jedwa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow.py"", line 58, in &lt;module&gt;

from tensorflow.python.pywrap\_tensorflow\_internal import \*

  File ""C:\\Users\\jedwa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow\_internal.py"", line 28, in &lt;module&gt;

\_pywrap\_tensorflow\_internal = swig\_import\_helper()

  File ""C:\\Users\\jedwa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap\_tensorflow\_internal.py"", line 24, in swig\_import\_helper

\_mod = imp.load\_module('\_pywrap\_tensorflow\_internal', fp, pathname, description)

  File ""C:\\Users\\jedwa\\Anaconda3\\envs\\tensorflow\\lib\\[imp.py](https://imp.py)"", line 243, in load\_module

  File ""C:\\Users\\jedwa\\Anaconda3\\envs\\tensorflow\\lib\\[imp.py](https://imp.py)"", line 343, in load\_dynamic

ImportError: DLL load failed: The specified module could not be found.

&amp;#x200B;

&amp;#x200B;

Failed to load the native TensorFlow runtime.

&amp;#x200B;

See [https://www.tensorflow.org/install/errors](https://www.tensorflow.org/install/errors)

&amp;#x200B;

for some common reasons and solutions.  Include the entire stack trace

above this error message when asking for help.",4,3
11,2019-3-5,2019,3,5,14,axhlbn,"When making an Xcode app with tflite, is there an option to actually take the phot, and then get the prediction?",https://www.reddit.com/r/tensorflow/comments/axhlbn/when_making_an_xcode_app_with_tflite_is_there_an/,jimmothytheunicorn,1551764724,"I need it that way, all I have is the instant detector at the corner of the screen...",0,1
12,2019-3-5,2019,3,5,15,axhvqv,Hyperbolic N-Space embeddings,https://www.reddit.com/r/tensorflow/comments/axhvqv/hyperbolic_nspace_embeddings/,kousun12,1551766794,"I still think hyperbolic geometry is hasn't been appreciated enough in the ML world, following the first few papers by [facebook research](https://papers.nips.cc/paper/7213-poincare-embeddings-for-learning-hierarchical-representations). Here's an implementation of some basic functions to support the Poincare model for word embeddings in TF. Lorentz model coming eventually...

[https://github.com/kousun12/tf\_hyperbolic](https://github.com/kousun12/tf_hyperbolic)",0,2
13,2019-3-6,2019,3,6,7,axrgdd,Gradient boosted trees in TensorFlow,https://www.reddit.com/r/tensorflow/comments/axrgdd/gradient_boosted_trees_in_tensorflow/,crawles89,1551826577,,4,13
14,2019-3-6,2019,3,6,8,axrj1l,Create tensor with averages of each column?,https://www.reddit.com/r/tensorflow/comments/axrj1l/create_tensor_with_averages_of_each_column/,Yogi_DMT,1551826973,I have a numpy array with data that has a few columns. Is there an easy way to get a tensor in which each value of a particular column is the average of that column's original values.,2,1
15,2019-3-6,2019,3,6,18,axx5oi,How do you run a copy of a model on each GPU for inference?,https://www.reddit.com/r/tensorflow/comments/axx5oi/how_do_you_run_a_copy_of_a_model_on_each_gpu_for/,ttocs167,1551866259,"I am trying to speed up prediction for a semantic segmentation task by running half the data through one GPU and half through the other, however I can' seem to figure out how. I feel like it should be simpler than I'm finding t to be.

How do I define two sessions running the same model onto different GPUs? I have some segmentation models I have trained and I would like to run through large folders of images for prediction, however I can't seem to figure out how to run two copies of the models in parallel each running half a dataset. I'm not very familiar with the behavour of sessions or graphs when it comes to multiple devices and I naiively assumed I could do something like this around the run command:

    ...
    for i, d in enumerate(['\gpu:0', '\gpu:1']):
        with tf.device(d):
            output = sess.run(network, feed_dict={net_input: image_batch[i]})
    ...

With the session already defined above and the model already loaded, however the ""with tf.device()"" blocks are simply ignored and only half of the batch is ran on the first device. 

After some reading it seems that the ""with tf.device"" blocks have to cover the actual definition of the operations that go into the ""session.run()"" function, however if I nest the loading of the network in these blocks I get an error saying the weights already exist and that you cannot redefine them with the same name.

My question is, what do I need to do to be able to run half of my batches through a copy of the model on one GPU whilst running the other half through the other? I want to avoid running two scripts each creating a session on a GPU. I'm not very familiar with device placement and, to my suprise, I can't seem to find any information about this online.

Sorry if I haven't been clear enough, I can offer more information or code snippets if required but I want to keep it general.",3,1
16,2019-3-7,2019,3,7,0,ay085o,Why is batch normalization getting removed so as other features in the next update of TF?,https://www.reddit.com/r/tensorflow/comments/ay085o/why_is_batch_normalization_getting_removed_so_as/,Jandevries101,1551887173,"Hi,

&amp;#x200B;

So i came accros that Batch Normalization and other features are getting removed in the next big update and that their ""replacement"" is keras features, but why and is it compatible with my existing tensorflow network, meaning i can just do a keras.layer.etc to my tensorflow based network?

&amp;#x200B;

Jan",4,5
17,2019-3-7,2019,3,7,10,ay6s1s,Training RNN with GPU causes loud coil whine noise,https://www.reddit.com/r/tensorflow/comments/ay6s1s/training_rnn_with_gpu_causes_loud_coil_whine_noise/,Corpio03,1551921866,"Hello, for the first time that I use my GPU \[Notebook GTX 1060\] to train my RNN, I noticed that it was making  some sort of loud coil whine noises that keep going on and off at each batch.

Is it normal or it will damage the GPU over time?  or should I ignore it?

I am completely new to deep learning and tensorflow so I don't know much about this.

Please tell me what to do.

Thanks.

&amp;#x200B;",18,1
18,2019-3-7,2019,3,7,10,ay6zr8,Is it possible to collect y-outputs from train sessions?,https://www.reddit.com/r/tensorflow/comments/ay6zr8/is_it_possible_to_collect_youtputs_from_train/,Snowybluesky,1551923193,"I am new to tensorflow, sorry if I sound stupid\*

&amp;#x200B;

I am testing a linear-regression model, and I want to see how predicted-y values (per each x) change over training. 

Currently, I have this which successfully trains my model:

&amp;#x200B;

**y = Wx + B**                              \#where W, x, and B are all nodes

**for \_ in range(100):**

**session.run****(fetches=train\_step, feed\_dict={x:x\_train, y:y\_train})**

&amp;#x200B;

I want to view the predicted y values from each x\_train data at each training iteration, so I added the line in the for loop but it does not work:

**print(****sesssion.run****(fetches=y\_out))**

&amp;#x200B;

&amp;#x200B;

**Is it possible to look at every y-out value per x-trainer data (per iteration) as you train a model?**

&amp;#x200B;",4,3
19,2019-3-7,2019,3,7,19,ayb7ne,Where can I find exactly how Tensorflow does matrix multiplication?,https://www.reddit.com/r/tensorflow/comments/ayb7ne/where_can_i_find_exactly_how_tensorflow_does/,stoarmy,1551954730,"Hi everyone.I am searching a code part that does sparse matrix multiplication. For example, I want to do a matrix multiplication, and in doing so, I use the tf.matmul operation inside the tensorflow. And, i want to optimize matrix mulptiplication in tf. However, I cannot reach where the matrix Multiplication is made exactly in tf_matmul. Is there any people who can help me to do this ?

",3,1
20,2019-3-7,2019,3,7,23,ayd55y,"Comprehensive Deep Learning Git Codebook, Video Tutorials and Projects",https://www.reddit.com/r/tensorflow/comments/ayd55y/comprehensive_deep_learning_git_codebook_video/,nalinee_choudhary,1551968726,"&amp;#x200B;

https://i.redd.it/8fl6yf1ggpk21.jpg

**Comprehensive** **Deep Learning tutorials** [(Free Video Tutorials)](https://www.edyoda.com/course/1429) [(Github codebook)](https://github.com/zekelabs/AI101-DeepLearning)  


**Build Deep Learning Projects (Complete Video Series for FREE )**  


**1.** [Making your RL Projects in 20 Minutes](https://www.edyoda.com/course/1421)  


**2.** [Style Transfer, Face Generation using GANs in 20 minutes](https://www.edyoda.com/course/1418)  


**3.** [Language and Machine Learning in 20 minutes](https://www.edyoda.com/course/1419)  


**4.** [AI Project - Web application for Object Identification](https://www.edyoda.com/course/1185)  


**5.** [Dog Breed Prediction](https://www.edyoda.com/course/1336)  


**Free** **Video Series for Beginners to advanced users**  


**1.** [Machine Learning - Mastering NumPy](https://www.edyoda.com/course/1263)  


**2.** [Machine Learning using Tensorflow](https://www.edyoda.com/course/99)  


**3.** [Step by step guide to Tensorflow](https://www.edyoda.com/course/1429)  


**4.** [Introduction to Neural Networks](https://www.edyoda.com/course/1417)  


**5.** [Knowledge Graphs, Deep Learning and Reasoning](https://www.edyoda.com/course/1420)",4,15
21,2019-3-8,2019,3,8,2,ayfguq,TensorFlow can now run on 12 edge hardware,https://www.reddit.com/r/tensorflow/comments/ayfguq/tensorflow_can_now_run_on_12_edge_hardware/,richharms,1551981177,,0,20
22,2019-3-8,2019,3,8,4,aygbva,Using Tensorflow on Windows. A coppie of questions.,https://www.reddit.com/r/tensorflow/comments/aygbva/using_tensorflow_on_windows_a_coppie_of_questions/,xDevi69,1551985585,"Do I need Python knowledge? 
Where do I find tutorials explained step by step from Zero?",0,1
23,2019-3-8,2019,3,8,4,aygg6e,"Started using TensorFlow on Windows, Here to ask a couple of questions.",https://www.reddit.com/r/tensorflow/comments/aygg6e/started_using_tensorflow_on_windows_here_to_ask_a/,xDevi69,1551986194,"Do I need python Knowledge?
Where can I find good tutorials? I can't understand tutorials on the official website.",5,2
24,2019-3-8,2019,3,8,5,ayh568,Tensorflow2.0 Alpha-Preview Released!!,https://www.reddit.com/r/tensorflow/comments/ayh568/tensorflow20_alphapreview_released/,shawnmanuel000,1551989802,,0,27
25,2019-3-8,2019,3,8,9,ayjv77,MultiCUDA: Multiple Versions of CUDA on One Machine,https://www.reddit.com/r/tensorflow/comments/ayjv77/multicuda_multiple_versions_of_cuda_on_one_machine/,Klajv,1552004727,,0,0
26,2019-3-8,2019,3,8,11,ayl5kp,"Error message ""there is no module named tensorflow.data""",https://www.reddit.com/r/tensorflow/comments/ayl5kp/error_message_there_is_no_module_named/,Laurence-Lin,1552012920,"As title, when I want to import tensorflow.data.Iterator and do:  


from [tensorflow.data](https://tensorflow.data) import Iterator

&amp;#x200B;

It shows the error message. However, inside the code I could use the function:  


tf.data.Iterator()

&amp;#x200B;

I wonder what is the problem?",0,1
27,2019-3-9,2019,3,9,1,aysdn0,TensorFlow Dev Summit Recap -- Mobile/Edge,https://www.reddit.com/r/tensorflow/comments/aysdn0/tensorflow_dev_summit_recap_mobileedge/,austin_kodra,1552063614,"Hi everyone! Obviously lots of cool news and updates coming out of this year's summit. Here's a rundown of all the mobile/edge bits from the Summit, just in case you missed any of it. (Disclosure -- I do manage/edit this blog, but I thought this might be useful or helpful for some folks here). Also, would love to hear any thoughts/comments/reactions to all the news included:

[https://heartbeat.fritz.ai/tensorflow-dev-summit-2019-the-mobile-bits-79704e81ad9](https://heartbeat.fritz.ai/tensorflow-dev-summit-2019-the-mobile-bits-79704e81ad9)",0,2
28,2019-3-9,2019,3,9,2,aysqy8,TensorFlow Dev Summit 2019-ML Roundup,https://www.reddit.com/r/tensorflow/comments/aysqy8/tensorflow_dev_summit_2019ml_roundup/,mwitiderrick,1552065554,,0,13
29,2019-3-9,2019,3,9,4,ayu7ei,Google Open-Sources Lingvo Framework for Sequence-To-Sequence Modeling,https://www.reddit.com/r/tensorflow/comments/ayu7ei/google_opensources_lingvo_framework_for/,Yuqing7,1552073169,,0,3
30,2019-3-9,2019,3,9,21,az2y5p,Does Tensorflow/Keras needs internet when doing machine learning prediction?,https://www.reddit.com/r/tensorflow/comments/az2y5p/does_tensorflowkeras_needs_internet_when_doing/,masterbruno11,1552133930,Like image recognition or handwritten reading?,13,2
31,2019-3-9,2019,3,9,23,az3xyq,Variational Autoencoders with Tensorflow Probability Layers,https://www.reddit.com/r/tensorflow/comments/az3xyq/variational_autoencoders_with_tensorflow/,AndyMerskinon,1552141256,[http://tech.learn4startup.com/437a26f4c5](http://tech.learn4startup.com/437a26f4c5),0,6
32,2019-3-9,2019,3,9,23,az4ahg,"Encountered this error ""libcublas.so.10.0: cannot open shared object file: No such file or directory"" after trying to install Tensorflow on my computer.",https://www.reddit.com/r/tensorflow/comments/az4ahg/encountered_this_error_libcublasso100_cannot_open/,bananaskywalker,1552143544,"This has been the second of my two unsucessful attempts to install Tensorflow.  Earlier I tried installing it with CUDA 9.0 but I never found a file for Cuda in my **/usr/local** directory. I then followed this [tutorial](https://medium.com/@taylordenouden/installing-tensorflow-gpu-on-ubuntu-18-04-89a142325138) but with Cuda 10.1 (basically the runfile method)  I did manage to follow the exact steps but even then whenever I type nvcc --version, I get this

    nvcc: NVIDIA (R) Cuda compiler driver
    Copyright (c) 2005-2017 NVIDIA Corporation
    Built on Fri_Nov__3_21:07:56_CDT_2017
    Cuda compilation tools, release 9.1, V9.1.85

I do not understand why. I checked for answers online on stackoverflow and I learnt that the PATH and LD\_LIBRARY\_PATH must point to the correct directory which they do.

Here is the output of echo $PATH

    /home/anshuman/Downloads/bin:/home/anshuman/anaconda3/bin:/usr/class/cs143/cool/bin:~/get-shit-done/get-shit-done.sh:/home/anshuman/.local/bin:/home/anshuman/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/anshuman/Documents/PCAP/.openmpi/bin:/home/anshuman/Documents/PCAP/bin:/usr/local/m4/bin/:/home/anshuman/bin:/usr/local/cuda-10.1/bin:/usr/lib/x86_64-linux-gnu/libcublas.so.10

I even found the file libcublas.so.10.0 in **/usr/lib/x86\_64-linux-gnu**  directory and I added the location to both the variables. 

It might be a redundant question but I just need to figure out how to remove CUDA 9.1 without removing 10.1. The solutions I have found on StackExchange generally seem to say that the PATH variable must be updated to point to the right place, which it has. ",11,4
33,2019-3-10,2019,3,10,0,az4o33,Introducing TensorFlow Federated,https://www.reddit.com/r/tensorflow/comments/az4o33/introducing_tensorflow_federated/,RonEng909,1552145898,[http://tech.learn4startup.com/2bcb323498](http://tech.learn4startup.com/2bcb323498),0,0
34,2019-3-10,2019,3,10,3,az6o4s,Tensorflow 2 + Anaconda + VSCode + Ubuntu 18 = Python Lint: 'tensorflow' has no 'keras' member,https://www.reddit.com/r/tensorflow/comments/az6o4s/tensorflow_2_anaconda_vscode_ubuntu_18_python/,alew3,1552157370,"I was setting up Tensorflow 2 alpha with a virtual environment under Anaconda and VS Code to test it out. The code runs fine on the terminal, but the linting isn't working properly on VS Code even after selecting the correct python interpreter.

For example. 

tf.keras.models.Sequential gives the error: Module 'tensorflow' has no 'keras' member

Any ideas?",1,0
35,2019-3-10,2019,3,10,15,azcuew,Can't download CuDNN,https://www.reddit.com/r/tensorflow/comments/azcuew/cant_download_cudnn/,i4hh,1552197751,"I'm trying to get started with twnsorfow-gpu on my Ubuntu 18, 1080ti, 1070ti, CUDA 10 setup.

I registered at the Nvidia developer website with my Google account, received a verification email, the link didn't work and only took me to the login page. Reset password link doesn't work. Signing up with just email/pass doesn't work.

I tied Chrome and Firefox, both latest versions.

Is there another way to download CuDNN? Does anyone here have an account and can share the installers I need?


Thanks in advance",12,5
36,2019-3-11,2019,3,11,9,azmbhs,Any advice to avoid nan costs while training without increasing precision?,https://www.reddit.com/r/tensorflow/comments/azmbhs/any_advice_to_avoid_nan_costs_while_training/,downvotedbylife,1552262437,"I should start by saying I'm new to Tensorflow. I'll try to keep it short:  
I'm working over someone else's code for solving a commonly ill-posed problem (think of it as a form of deconvolution), and it's been working rather well so far. I'm running into a problem where increasing the network depth (in the form of discrete convolutional layers with set input/output dimensions) starts giving me nan loss errors during training. Lowering the network depth decreases the initial loss and converges faster, increasing it increases initial loss and converges at a similar rate but requires more epochs. This is to be expected and is part of my current study.  

The initial loss for my edge case (max network depth I can train without getting nans) gives some pretty big loss numbers in the first iteration, which made me think the culprit was that for the deeper networks, losses (and consequently weights) were too big for single precision. Changing all the tf variables to float64 fixed it, and it's converging as we speak. However, training times after this change climbed to unreasonable levels (~25 minutes per epoch, more than twice what I was getting with float32).  

I've tried lowering the learning rate and batch sizes, which made no difference and still produced nan values on the first epoch's loss. Is there any other change I could make that would let me get away with training at float32 (or lower, but I don't have high hopes for that). Will clipping the output values from my loss calculation allow the network to converge at all?",7,2
37,2019-3-11,2019,3,11,19,azrsi9,A Quick guide to save and restore model Tensorflow,https://www.reddit.com/r/tensorflow/comments/azrsi9/a_quick_guide_to_save_and_restore_model_tensorflow/,AI_Sangam,1552299809,,0,5
38,2019-3-11,2019,3,11,22,azt9fs,Keras to save model when tensorflow is used as backend,https://www.reddit.com/r/tensorflow/comments/azt9fs/keras_to_save_model_when_tensorflow_is_used_as/,mental_ape101,1552309736,Can we use keras to save our model even though we have used tensorflow as backend in entire functionality of our model?,1,1
39,2019-3-12,2019,3,12,0,azv0w7,My anaconda's tensorflow-gpu inference process is slower than base tensorflow,https://www.reddit.com/r/tensorflow/comments/azv0w7/my_anacondas_tensorflowgpu_inference_process_is/,nyamuk91,1552319626,"I'm running this sample code [here](https://github.com/tensorflow/models/blob/master/tutorials/image/imagenet/classify_image.py) on a number of images. I have 2 environments in my anaconda, one is using ""tensorflow-gpu"" and another one is using ""tensorflow"". When running the code on tensorflow-gpu environment, the average time taken for the inference process on 10 images is around 25 seconds while when it's running on base tensorflow, the average time taken is only 23 seconds.   
  
I also got this message when I'm running the GPU version:  
&gt; 2019-03-11 23:37:00.674207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
&gt; 2019-03-11 23:37:00.677725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
&gt; 2019-03-11 23:37:00.681750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0
&gt; 2019-03-11 23:37:00.685463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N
&gt; 2019-03-11 23:37:00.687898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6368 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)  
  
My spec is:  

* CPU: i7 8700  
* RAM: 16GB  
* GPU: GTX 1080  
",4,3
40,2019-3-12,2019,3,12,1,azvnyz,AttributeError: 'Sequential' object has no attribute 'total_loss',https://www.reddit.com/r/tensorflow/comments/azvnyz/attributeerror_sequential_object_has_no_attribute/,Kaen_No_Mai,1552322933,"I'm currently dying trying to figure out this problem, I'm using tensorflow-gpu v1.13.1.  I'm trying to make a binary classifier to classify a file as malicious or not.  X\_train, y\_train, X\_test, and y\_test are all large numpy arrays.  

&amp;#x200B;

`import tensorflow as tf`  
`import numpy as np`  
`import ember`  
`import random`  
`X_train, y_train, X_test, y_test = ember.read_vectorized_features(""C:\\Users\Cody\Desktop\synopsys\data\ember"")`  
`metadata_dataframe = ember.read_metadata(""C:\\Users\Cody\Desktop\synopsys\data\ember"")`  


`#load training set`  
`def loadTrainSet(X_train, y_train, number):`  
`x = np.split(X_train, 100)`  
`y = np.split(y_train, 100)`  
`features = tf.convert_to_tensor(x[number], dtype=tf.float32)`  
`labels = tf.convert_to_tensor(y[number], dtype=tf.float32)`  
 `return features, labels`  


`#load testing set`  
`def loadTestSet():`  
`X_test_tf = tf.convert_to_tensor(X_test, np.float32)`  
`y_test_tf = tf.convert_to_tensor(y_test, np.float32)`  
 `return X_test_tf, y_test_tf`  


`#create compiled keras model`  
`def createModel():`  
`model = tf.keras.models.Sequential()`  
 `#ADD L2 REGULARIZATION LATER`  
 `model.add(tf.keras.layers.Dense(7351, activation=tf.nn.relu))`  
 `'''model.add(tf.keras.layers.Dropout(0.2))`  
`model.add(tf.keras.layers.Dense(4096, activation=tf.nn.relu))'''`  
 `model.add(tf.keras.layers.Dropout(0.2))`  
`model.add(tf.keras.layers.Dense(4096, activation=tf.nn.relu))`  
`model.add(tf.keras.layers.Dropout(0.2))`  
`model.add(tf.keras.layers.Dense(4096, activation=tf.nn.relu))`  
`model.add(tf.keras.layers.Dropout(0.2))`  
`model.add(tf.keras.layers.Dense(2048, activation=tf.nn.relu))`  
`model.add(tf.keras.layers.Dropout(0.2))`  
`model.add(tf.keras.layers.Dense(2048, activation=tf.nn.relu))`  
`model.add(tf.keras.layers.Dropout(0.2))`  
`model.add(tf.keras.layers.Dense(2048, activation=tf.nn.relu))`  
`model.add(tf.keras.layers.Dropout(0.2))`  
`model.add(tf.keras.layers.Dense(1024, activation=tf.nn.relu))`  
`model.add(tf.keras.layers.Dropout(0.2))`  
`model.add(tf.keras.layers.Dense(1024, activation=tf.nn.relu))`  
`model.add(tf.keras.layers.Dropout(0.2))`  
`model.add(tf.keras.layers.Dense(1024, activation=tf.nn.relu))`  
`model.add(tf.keras.layers.Dropout(0.2))`  
`model.add(tf.keras.layers.Dense(1024, activation=tf.nn.relu))`  
`model.add(tf.keras.layers.Dropout(0.2))`  
`model.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid))`  
 `#adam metrhod for stochastic gradient descent`  
 `model.compile(optimizer='adam',`  
 `loss='categorical_crossentropy',`  
 `metrics=['accuracy'])`  
 `return model`  


`def generate_arrays(features, labels, batch_size):`  
`batch_features=np.zeros((batch_size, 7351), dtype=np.float32)`  
`batch_labels=np.zeros((batch_size, 1), dtype=np.float32)`  
 `while True:`  
 `for i in range(batch_size):`  
`index=random.choice(900000,1)`  
`batch_features=X_train[index]`  
`batch_labels=y_train[index]`  
 `yield batch_features, batch_labels`  


`print('creating model')`  
`model=createModel()`  
`print('training model')`  
`model.fit_generator(generate_arrays(X_train, y_train, 500), epochs=10, steps_per_epoch=1800)`  
`print('testing model')`  
`X_test_tf, y_test_tf = loadTestSet()`  
`model.evaluate(X_test_tf, y_test_tf)`

&amp;#x200B;

I keep getting the error: 

Traceback (most recent call last):

  File ""C:/Users/Cody/Desktop/synopsys/train.py"", line 76, in &lt;module&gt;

model.fit\_generator(generate\_arrays(X\_train, y\_train, 500), epochs=10, steps\_per\_epoch=1800)

  File ""C:\\Users\\Cody\\AppData\\Local\\conda\\conda\\envs\\emberenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\[training.py](https://training.py)"", line 1426, in fit\_generator

initial\_epoch=initial\_epoch)

  File ""C:\\Users\\Cody\\AppData\\Local\\conda\\conda\\envs\\emberenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training\_generator.py"", line 125, in model\_iteration

model, mode, class\_weight=class\_weight)

  File ""C:\\Users\\Cody\\AppData\\Local\\conda\\conda\\envs\\emberenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training\_generator.py"", line 427, in \_make\_execution\_function

model.\_make\_fit\_function()

  File ""C:\\Users\\Cody\\AppData\\Local\\conda\\conda\\envs\\emberenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\[training.py](https://training.py)"", line 1926, in \_make\_fit\_function

'\_fit\_function', \[self.total\_loss\] + metrics\_tensors)

AttributeError: 'Sequential' object has no attribute 'total\_loss'

&amp;#x200B;

Does anyone have any suggestions?  I'm completely lost, there's barely any documentation on this at all.  ",1,1
41,2019-3-12,2019,3,12,4,azxu8b,Still No Saving for Subclassed Keras Models? TF2.0,https://www.reddit.com/r/tensorflow/comments/azxu8b/still_no_saving_for_subclassed_keras_models_tf20/,kiunthmo,1552333773,"I've been playing around with TF2.0, I'd actually like to switch to it. But why is there no model saving for subclassed models? 

If I have to start using Keras, I should be able to save after training.",0,1
42,2019-3-12,2019,3,12,7,azzpl7,I made a YouTube tutorial for getting started with Tensorflow 2.0!,https://www.reddit.com/r/tensorflow/comments/azzpl7/i_made_a_youtube_tutorial_for_getting_started/,shawnmanuel000,1552342880,"Hey guys, I uploaded a short video on how to get started with Tensorflow 2.0 to create your own custom neural network using both the High level keras API as well as the lower level building blocks.

Here's the link: [https://www.youtube.com/watch?v=fQCKxzHvYnw](https://www.youtube.com/watch?v=fQCKxzHvYnw)

Let me know if there are any other aspects of Tensorflow that you'd like a tutorial for",9,27
43,2019-3-12,2019,3,12,17,b05gsp,Unknown command line flag error,https://www.reddit.com/r/tensorflow/comments/b05gsp/unknown_command_line_flag_error/,GoBacksIn,1552380501,"FLAGS.meta\_dir = 'meta/' + FLAGS.cipher + '-{}/'.format(m)

has occur 

Traceback (most recent call last):

  File ""C:/Users/ML/Downloads/crypto-rnn-master/main.py"", line 82, in &lt;module&gt;

FLAGS.meta\_dir = 'meta/' + FLAGS.cipher + '/' # directory to save loss history, figures, etc.

  File ""C:\\Users\\ML\\Anaconda3\\envs\\me\\lib\\site-packages\\tensorflow\\python\\platform\\[flags.py](https://flags.py)"", line 88, in \_\_setattr\_\_

return self.\_\_dict\_\_\['\_\_wrapped'\].\_\_setattr\_\_(name, value)

  File ""C:\\Users\\ML\\Anaconda3\\envs\\me\\lib\\site-packages\\absl\\flags\\\_flagvalues.py"", line 499, in \_\_setattr\_\_

return self.\_set\_unknown\_flag(name, value)

  File ""C:\\Users\\ML\\Anaconda3\\envs\\me\\lib\\site-packages\\absl\\flags\\\_flagvalues.py"", line 375, in \_set\_unknown\_flag

raise \_exceptions.UnrecognizedFlagError(name, value)

absl.flags.\_exceptions.UnrecognizedFlagError: Unknown command line flag 'meta\_dir'

&amp;#x200B;

i used code as raw in 

[https://github.com/greydanus/crypto-rnn](https://github.com/greydanus/crypto-rnn)

&amp;#x200B;",0,1
44,2019-3-13,2019,3,13,3,b0ba5s,[help wanted] Embedding a Python interpreter in tfgo - Tensorflow Python API support,https://www.reddit.com/r/tensorflow/comments/b0ba5s/help_wanted_embedding_a_python_interpreter_in/,pgaleone,1552415730,,0,1
45,2019-3-13,2019,3,13,5,b0cewe,Scaling the A3C algorithm to multiple machines using Tensorflow.JS,https://www.reddit.com/r/tensorflow/comments/b0cewe/scaling_the_a3c_algorithm_to_multiple_machines/,naifmeh,1552421344,,1,1
46,2019-3-13,2019,3,13,11,b0ge7m,How Neural Networks Work- Simply Explained,https://www.reddit.com/r/tensorflow/comments/b0ge7m/how_neural_networks_work_simply_explained/,ailearn12,1552442591,,0,20
47,2019-3-13,2019,3,13,16,b0j1yh,Where is configure.py,https://www.reddit.com/r/tensorflow/comments/b0j1yh/where_is_configurepy/,monkeyunited,1552461181,"I apologize. I know this is very low level questions but I'm genuinely stuck.

Using the instruction from [https://www.tensorflow.org/install/source\_windows](https://www.tensorflow.org/install/source_windows), at the step of configure the build, where can I get the [configure.py](https://configure.py) file?

I install everything that was asked beforehand but none of those include a [configure.py](https://configure.py).

I'm super new to python but I'm really just clueless. ",2,1
48,2019-3-13,2019,3,13,17,b0jn0p,tf.gradients returns None for gradient with self for integer variable,https://www.reddit.com/r/tensorflow/comments/b0jn0p/tfgradients_returns_none_for_gradient_with_self/,souljaboy764,1552466375,"I was playing around with tf.gradients and got gradients as None for the below code:

&amp;#x200B;

    &gt;&gt;&gt; x = tf.Variable(10) # integer type
    &gt;&gt;&gt; tf.gradients(x,x)
    [None]
    &gt;&gt;&gt; sess.run(tf.gradients(x,x))
    Traceback (most recent call last):
      File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
      File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 929, in run
        run_metadata_ptr)
      File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1137, in _run
        self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)
      File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 471, in __init__
        self._fetch_mapper = _FetchMapper.for_fetch(fetches)
      File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 261, in for_fetch
        return _ListFetchMapper(fetch)
      File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 370, in __init__
        self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches]
      File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 258, in for_fetch
        type(fetch)))
    TypeError: Fetch argument None has invalid type &lt;type 'NoneType'&gt;
    &gt;&gt;&gt; x = tf.Variable(10.0) # float type
    &gt;&gt;&gt; tf.gradients(x,x)
    [&lt;tf.Tensor 'gradients_6/Fill:0' shape=() dtype=float32&gt;]
    &gt;&gt;&gt; sess.run(tf.gradients(x,x))
    [1.0]

The environment is Python 2.7 with tensorflow 1.12

&amp;#x200B;

I'm not able to understand why this happens. shouldn't it be the same for both the cases of float and int?",4,1
49,2019-3-13,2019,3,13,18,b0jz0c,TensorFlow for JavaScript,https://www.reddit.com/r/tensorflow/comments/b0jz0c/tensorflow_for_javascript/,HazelMadsen,1552469350,[https://www.youtube.com/watch?v=A1EA7VgZt9I](https://www.youtube.com/watch?v=A1EA7VgZt9I),0,0
50,2019-3-13,2019,3,13,20,b0kuxn,"From Keras to C++, a practical example of Tensorflow C API based deployment",https://www.reddit.com/r/tensorflow/comments/b0kuxn/from_keras_to_c_a_practical_example_of_tensorflow/,aljabr0,1552476335,"This small demo project is about deploying deep learning models on embedded platforms. The techniques exposed here have been particularly useful to me in the deployment of deep learning models in industrial applications. We start with a simple example model, trained with **Tensorflow + Keras**. In the end, we'll freeze the model and export a GraphDef that can be loaded and executed through the **Tensorflow C API** (without Python).
[https://github.com/aljabr0/from-keras-to-c](https://github.com/aljabr0/from-keras-to-c)
",0,13
51,2019-3-14,2019,3,14,0,b0ngi6,"What is the difference between neural networks made with tf,tf.nn, tf.keras and tf.layers?",https://www.reddit.com/r/tensorflow/comments/b0ngi6/what_is_the_difference_between_neural_networks/,begooboi,1552491858,"I have seen in tensorflow we can make neural networks with tf.nn, tf.keras and tf.layers. We can also make neural networks from scratch using tensorflow lower level api.

What is the difference between neural networks made with  tf,tf.nn, tf.keras and tf.layers? 

Is there any training speed difference between these four methods? 

If we consider training a model , Is one of these methods  is superior to other?

Why there is this many methods?",8,15
52,2019-3-14,2019,3,14,1,b0o2l3,TensorFlow Serving with Docker  an end-to-end example!,https://www.reddit.com/r/tensorflow/comments/b0o2l3/tensorflow_serving_with_docker_an_endtoend_example/,jingw222,1552494981,,0,4
53,2019-3-14,2019,3,14,10,b0ul60,How can I un-freeze variables from a restored model checkpoint?,https://www.reddit.com/r/tensorflow/comments/b0ul60/how_can_i_unfreeze_variables_from_a_restored/,Morocco_Bama,1552528749,"I have a network that I'm freezing some of the weights in in early epochs of training. When I restore the model from a checkpoint, how can I change those variables to ""trainable""?",0,1
54,2019-3-14,2019,3,14,12,b0v9kj,A relaxing game built in Tensoflow,https://www.reddit.com/r/tensorflow/comments/b0v9kj/a_relaxing_game_built_in_tensoflow/,jcheng91,1552533038,[removed],0,1
55,2019-3-14,2019,3,14,12,b0vfnn,Disconnect display from GPU?,https://www.reddit.com/r/tensorflow/comments/b0vfnn/disconnect_display_from_gpu/,nicksvr4,1552534105,"Probably a stupid question, but I have dual GPUs now (GTX 970, GTX2080Ti). Should I disconnect all displays from the 2080Ti when using it with TF? Just disable the display driver?",8,2
56,2019-3-14,2019,3,14,16,b0xar2,"Tensorflow prediciton error, invalidArgumentError: assertion failed: [Unable to decode bytes as JPEG, PNG, GIF, or BMP]",https://www.reddit.com/r/tensorflow/comments/b0xar2/tensorflow_prediciton_error_invalidargumenterror/,MALEK1997,1552547688,"I trained a Tensorflow Ssd object-detection model using Google object-detection Api and i exported the trained model using the provided ""export\_inference\_graph.py"" script as ""Saved\_model.pb"" file with ""encoded\_image\_string\_tensor"" as input type, however when i tried to make prediction to the model, i got the following error:

&amp;#x200B;

`tensorflow.python.framework.errors_impl.InvalidArgumentError: assertion failed: [Unable to decode bytes as JPEG, PNG, GIF, or BMP]`

&amp;#x200B;

 loaded the model into a graph as follow:

&amp;#x200B;

`with tf.Session() as sess:     tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], saved_model_file)     graph = tf.get_default_graph()`

&amp;#x200B;

And made the prediction as follow:

&amp;#x200B;

`# Convert the image into base64 encoded string img = Image.open(IMAGE_PATH)     resized_img = img.resize((300, 300), Image.ANTIALIAS) binary_io = io.BytesIO() resized_img.save(binary_io, ""JPEG"")  bytes_string_image = base64.b64encode(binary_io.getvalue()).decode(""utf-8"") # Define the input and output placeholder tensors input_tensor = graph.get_tensor_by_name('encoded_image_string_tensor:0') tensor_dict = {} for key in ['num_detections', 'detection_boxes', 'detection_scores', 'detection_classes']:         tensor_name = key + ':0'         tensor_dict[key] = graph.get_tensor_by_name(tensor_name) # Finally, do the prediciton output_dict = sess.run(tensor_dict, feed_dict={                            input_tensor: bytes_string_image})`

&amp;#x200B;",7,2
57,2019-3-15,2019,3,15,1,b12l8g,How we improved Tenserflow Serving performance by over 70%,https://www.reddit.com/r/tensorflow/comments/b12l8g/how_we_improved_tenserflow_serving_performance_by/,GeneticGenesis,1552581881,,2,9
58,2019-3-15,2019,3,15,3,b13kw2,"Build AI that works offline with Coral Dev Board, Edge TPU, and TensorFlow Lite",https://www.reddit.com/r/tensorflow/comments/b13kw2/build_ai_that_works_offline_with_coral_dev_board/,dayanruben,1552586646,,30,22
59,2019-3-15,2019,3,15,23,b1fs6d,Edge TPU: Hands-On with Googles Coral USB Accelerator,https://www.reddit.com/r/tensorflow/comments/b1fs6d/edge_tpu_handson_with_googles_coral_usb/,rdeepc,1552661051,,7,21
60,2019-3-16,2019,3,16,8,b1lx4l,Is it possible to fix the input size of a model when you freeze it?,https://www.reddit.com/r/tensorflow/comments/b1lx4l/is_it_possible_to_fix_the_input_size_of_a_model/,Boozybrain,1552693514,Or would I need to fine tune it with a fixed input size to save the weights based on the size I choose?,0,2
61,2019-3-17,2019,3,17,5,b1woqu,Multi-class Image Recognition,https://www.reddit.com/r/tensorflow/comments/b1woqu/multiclass_image_recognition/,916swift,1552766835,"Does anyone have any recommendations on where to start for building a multiclass model for image recognition on your own data?

I have some basic knowledge of Tensorflow, but most of my experience is on a pretrained model. 

For what I am working, I have created the training/testing sets in the different classes

&amp;#x200B;",3,2
62,2019-3-17,2019,3,17,6,b1xg1f,"I ranked the Best TensorFlow Courses on the internet, based on your reviews",https://www.reddit.com/r/tensorflow/comments/b1xg1f/i_ranked_the_best_tensorflow_courses_on_the/,skj8,1552770977,,4,36
63,2019-3-17,2019,3,17,14,b223vq,tf.nn.conv2d in numpy or scipy?,https://www.reddit.com/r/tensorflow/comments/b223vq/tfnnconv2d_in_numpy_or_scipy/,Morocco_Bama,1552801830,"As part of an embedded project, I have a network that I trained and saved in Tensorflow, and now I'm re-loading the variables in a Numpy/Scipy-based model. I'm trying to convert the following Tensorflow lines:

    # input shape: (1, 224, 224, 1)
    
    weight1 = tf.Variable([3,3,1,16],stddev)
    conv1 = tf.nn.conv2d(input,w,[1,1,1,1])
    
    # conv1 shape: (1, 224, 224, 16)
    
    weight2 = tf.Variable([3,3,16,32],stddev)
    conv2 = tf.nn.conv2d(conv2,w,[1,1,1,1])
    
    # conv2 shape: (1, 224, 224, 32)

I know that tensorflow's conv2d is not an actual convolution, and that for np.convolve the axes have to be flipped for two or three-dimensional weights. But how does this translate for a four-dimensional weight?

    # I tried with numpy and scipy, both fail
    # from numpy import convolve
    from scipy.ndimage.filters import convolve
    
    conv1 = convolve(input, weight1[::-1])
    
    # conv1 shape: (1, 224, 224, 1)
    
    conv2 = convolve(conv1, weight2[::-1])
    
    # conv2 shape: (1, 224, 224, 16)

&amp;#x200B;",0,2
64,2019-3-17,2019,3,17,22,b25dxi,Has anyone here worked with Tensorflow Lite?,https://www.reddit.com/r/tensorflow/comments/b25dxi/has_anyone_here_worked_with_tensorflow_lite/,gitmonk,1552830946,"I need to make an Android application that detects faces and compares them to a database of previously registered faces.

I've done some projects involving Tensorflow, including a GAN. And I'm currently working on 3D reconstruction of colored facial images. However, I am completely new to Android development and using the Tensorflow Lite tool.hah

Could anyone here give me good advice? I really do not expect anyone to do my job for me, I just need to be directed to the right path.

If this posting is inappropriate for the sub, where could I post it properly?

Thank you.",15,11
65,2019-3-18,2019,3,18,1,b26mvr,How do I use Object detection API to find threat in surveillance video,https://www.reddit.com/r/tensorflow/comments/b26mvr/how_do_i_use_object_detection_api_to_find_threat/,ragupal,1552838609," i am trying to do my PG course project i managed to detect object with object detection  API  of tensorflow but how do I approach  my model further to detect threat  in the scenario   
Any suggestions/tutorial  will be highly appreciated for detecting threat in the video 

PS :  I have dataset of various threats like theft, fight,  public knockouts and physical assault ",3,2
66,2019-3-18,2019,3,18,22,b2inr9,error when using tf.metrics.mean_per_class_accuracy,https://www.reddit.com/r/tensorflow/comments/b2inr9/error_when_using_tfmetricsmean_per_class_accuracy/,Dahnaman,1552915231,"tf.metrics.mean_per_class_accuracy(
    labels,
    predictions,
    num_classes,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)

I dont understand what a ground truth label is. I tried putting labels=X_test, predictions=y_test, num_classes=4

But got the AttributeError: 'list' object has no attribute 'get_shape'

I know my labels and predictions are wrong but what exactly do I have to input in?",1,1
67,2019-3-18,2019,3,18,23,b2jd0t,Working with TensorFlow 2.0 Alpha,https://www.reddit.com/r/tensorflow/comments/b2jd0t/working_with_tensorflow_20_alpha/,mwitiderrick,1552919278,,0,3
68,2019-3-19,2019,3,19,5,b2ni64,What is the difference between saving model as pb vs as a checkpoint file,https://www.reddit.com/r/tensorflow/comments/b2ni64/what_is_the_difference_between_saving_model_as_pb/,etmhpe,1552940275,"I am saving my model as a checkpoint file like

`saver.save(sess, checkpoint_prefix, global_step=current_step)`  
and I am also saving my model as a pb file like

`tf.train.write_graph(sess.graph.as_graph_def(), checkpoint_prefix, ""graph""+str(nn)+"".pb"", as_text=False)`  


is this just two different ways of saving a model? i.e. are both methods saving the graph and the weights which can then be restored?",4,13
69,2019-3-19,2019,3,19,13,b2soe8,CUDA + CuDNN + Python versions for TF 2.0?,https://www.reddit.com/r/tensorflow/comments/b2soe8/cuda_cudnn_python_versions_for_tf_20/,clanleader,1552968365,"I'm thinking of diving into the alpha so the new syntax and API doesn't take me by surprise, however every time I install or upgrade TF it takes me a long time to get everything up and running correctly, making sure I have the correct versions of CUDA, CuDNN and Python installed. Not to mention my Internet connection is in the third world, so downloading a 2GB CUDA file is a project in and of itself that can take days.

I'm therefore wondering that if I were to install TF 2.0 Alpha right now, would the current configuration, setup and required versions of everything (CUDA, CuDNN, Python) match those at release and allow me to do a simple pip --upgrade to the release version of Tensorflow 2 without needing to upgrade anything or make other changes?",7,0
70,2019-3-20,2019,3,20,2,b30imf,Qn on image brightening vs normalization (xpost from /r/keras,https://www.reddit.com/r/tensorflow/comments/b30imf/qn_on_image_brightening_vs_normalization_xpost/,simpleharmonicmotion,1553017869,"Quick question on whether we have conflicting effects. Consider a case where I take image.jpg then brighten it to get the augmented example image\_brightened.jpg. Now to improve training, I normalize the tensors for both images. Do the two tensors look alike? Do they collapse to the same example thus diluting the value of doing this in the first place?

&amp;#x200B;

Cheers

shm",2,1
71,2019-3-20,2019,3,20,3,b30qpg,using tf.data API for own dataset,https://www.reddit.com/r/tensorflow/comments/b30qpg/using_tfdata_api_for_own_dataset/,FreddyShrimp,1553018939,"I'm trying to create my own dataset (of images) such that I can call methods such as `my_data.train.next_batch(batch_size)` 

However, I think the tensorflow website is pretty vague. I checked stackoverflow but it doesn't cover my problem.

&amp;#x200B;

Can somebody help pls?",4,4
72,2019-3-20,2019,3,20,10,b362rl,The program blocked when I load and run a saved model,https://www.reddit.com/r/tensorflow/comments/b362rl/the_program_blocked_when_i_load_and_run_a_saved/,vincent341,1553046635," 

I run into a problem when I try to load a saved model written in tensorflow. The code is available [here](https://drive.google.com/file/d/18ldea5pls_AaykEEKfBLRC0SrPgFrfa_/view?usp=sharing)(code1). The code loads a pretrained model and uses the pretrained model to compute results with different inputs. The saved model files are available [here](http://vision.is.tohoku.ac.jp/~liushuang/tank2fieldGAN/model/). Actually the saved model was obtained by training a network which is a variation of [pix2pixgan](https://github.com/affinelayer/pix2pix-tensorflow)(code2).

The toy example is like 
&gt;&gt;
    myinput_np, mytarget_np, bbox = my_readimg_np('test2.jpg')
    #load  gan graph
    saver = tf.train.import_meta_graph(checkpoint_path + ""model-210000.meta"")
    gan_graph = tf.get_default_graph()
    convert_targets = gan_graph.get_tensor_by_name(""convert_inputs/convert_image:0"")
    myinputs_p = tf.placeholder(tf.float32, shape=[1, 256, 256, 4]) 
    mytargets_p = tf.placeholder(tf.float32, shape=[1, 256, 256, 3])
    with tf.Session() as sess:
        saver.restore(sess, tf.train.latest_checkpoint(checkpoint_path))
        #coord = tf.train.Coordinator()
        #threads = tf.train.start_queue_runners(sess=sess, coord=coord)
        #load gan weights
        results = sess.run(convert_targets, feed_dict={myinputs_p: myinput_np, mytargets_p: mytarget_np})
        print(convert_targets.name)
        print (results)

When I run code1 to load the pretrained model and compute results with inputs, the program seems blocked/suspend. The program is running but there isn't any output on the screen when ""results= sess.run()"" runs.

Some guys guessed it may be caused by the read pipeline of tensorlow and suggested to add

    coord = tf.train.Coordinator() 
    threads = tf.train.start_queue_runners(sess=sess, coord=coord). 

After adding these two lines, I got the error ""*Process finished with exit code -1073741819 (0xC0000005)*"".

Could you please help me about it? Your help is of great importance to me. Thanks very much in advance.",0,1
73,2019-3-20,2019,3,20,13,b37pmy,Get started with Apache Spark and TensorFlow on Azure Databricks,https://www.reddit.com/r/tensorflow/comments/b37pmy/get_started_with_apache_spark_and_tensorflow_on/,GlennMulligan,1553056922,,0,2
74,2019-3-20,2019,3,20,15,b38rup,Such an impressive document!,https://www.reddit.com/r/tensorflow/comments/b38rup/such_an_impressive_document/,Gerry_Goe,1553064822,"&amp;#x200B;

https://i.redd.it/670co3jg18n21.png",4,6
75,2019-3-20,2019,3,20,16,b398m4,coloring the Tensorflow object detection Bounding Boxes,https://www.reddit.com/r/tensorflow/comments/b398m4/coloring_the_tensorflow_object_detection_bounding/,8222Tamil,1553068544,i'm doing custom object Detection using SSD Mobilenet V1.I'm getting output with some accuracy.I want  to fill the bounding box with black [color.how](https://color.how) to do that..what to change in visualisation\_utils.py.need help..Thanks in advance!!,0,1
76,2019-3-20,2019,3,20,21,b3bp79,Which do you prefer estimator or fit function in Keras?,https://www.reddit.com/r/tensorflow/comments/b3bp79/which_do_you_prefer_estimator_or_fit_function_in/,thisisiron,1553086710,"If you prefer an estimator, which do you use tf.keras.estimator.model_to_estimator () or tf.estimator.inputs.numpy_input_fn()?

Let me know your opinion.",3,3
77,2019-3-20,2019,3,20,22,b3bv8s,"Doubts on how to proceed with retinanet implementation, can someone help me out?",https://www.reddit.com/r/tensorflow/comments/b3bv8s/doubts_on_how_to_proceed_with_retinanet/,nsiddhu,1553087669,,0,1
78,2019-3-21,2019,3,21,5,b3hcp3,TensorFlow VPS,https://www.reddit.com/r/tensorflow/comments/b3hcp3/tensorflow_vps/,ThrowAway9592795,1553115479,"Hello.
Can you please suggest me any good VPS supporting (python) TensorFlow?
Thanks.",1,1
79,2019-3-21,2019,3,21,11,b3kva0,How To Install and Use TensorFlow on Ubuntu 18.04?,https://www.reddit.com/r/tensorflow/comments/b3kva0/how_to_install_and_use_tensorflow_on_ubuntu_1804/,Sophia102z,1553134199,[removed],0,1
80,2019-3-21,2019,3,21,11,b3kvw9,How To Install and Use TensorFlow on Ubuntu 18.04?,https://www.reddit.com/r/tensorflow/comments/b3kvw9/how_to_install_and_use_tensorflow_on_ubuntu_1804/,JJohnson0x,1553134296,[http://on.morioh.net/8841ac0019](http://on.morioh.net/8841ac0019),0,1
81,2019-3-21,2019,3,21,11,b3kwou,How To Install and Use TensorFlow on Ubuntu 18.04?,https://www.reddit.com/r/tensorflow/comments/b3kwou/how_to_install_and_use_tensorflow_on_ubuntu_1804/,Nancyannh,1553134421,[http://on.geeklearn.net/5033f5a1b0](http://on.geeklearn.net/5033f5a1b0),0,0
82,2019-3-21,2019,3,21,12,b3loov,Are there calculations behind the convnet() function in tensorflow,https://www.reddit.com/r/tensorflow/comments/b3loov/are_there_calculations_behind_the_convnet/,cocobananaohhohh,1553139034,Are there calculations behind the convnet() function in tensorflow that show weights and bias being used?,0,1
83,2019-3-21,2019,3,21,21,b3pwsa,batch_normalization training/test behavior,https://www.reddit.com/r/tensorflow/comments/b3pwsa/batch_normalization_trainingtest_behavior/,lateautumntear,1553171148,"Dear all,

I've been using ```slim``` for a while and I would like to switch to ```tf.layers``` implementation. I know there is an issue when testing a trained network with ```slim.batch_norm```. In this case you are obliged to use the ```slim.learning.create_train_op``` to minimize the optimizer otherwise, the traditional ```opt.minimize(loss)``` does not work when the flag *is_training* in batch norm is set as *False*.

It seems to me that the same issue appears in ```tf.layers```, apparently the solution is to do something like this:

```
self.opt = tf.train.AdamOptimizer(learning_rate=0.00001)
self.trainable_vars = tf.trainable_variables()
update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
with tf.control_dependencies(update_ops):
    self.train_op = self.opt.minimize(self.loss, var_list=self.trainable_vars)
```

Is there someone who can explain to me why I need to use the ```update_ops``` instead of creating the train_op directly? 

Is there a more intuitive way to generate the training operator?",0,1
84,2019-3-22,2019,3,22,0,b3rnn1,Some questions about Convolutional Layers in Tensorflow,https://www.reddit.com/r/tensorflow/comments/b3rnn1/some_questions_about_convolutional_layers_in/,Jehovacoin,1553181035,"Okay so I have been recently looking at working with the convolutional layers provided in tensorflow, but I'm having trouble figuring out if the filters are static or dynamic. If they change with the rest of the weights, how is that done? If they don't change, then how are the filters decided? Is it randomly, or are they generated from a seed of some sort? If I apply 2 identical conv2d layers, one with 10 filters and one with 20 filters, are the first 10 filters going to be identical for both layers?

Sorry if these questions are easily answered elsewhere. I have been having trouble finding a direct answer about this in the documentation, and parsing through the source code is exhausting.",4,3
85,2019-3-22,2019,3,22,0,b3ryhf,How to choose epsilon greedy value when training regression NN,https://www.reddit.com/r/tensorflow/comments/b3ryhf/how_to_choose_epsilon_greedy_value_when_training/,Cwlrs,1553182552,"Hi,

&amp;#x200B;

I'm training a deep NN for connect four, and I'm wondering if there's any ballpark figure for what the epsilon greedy value should be at the start of training, middle, and end? Basically, what I found with some initital training, was that the AI could play strong moves (for a bit) if the human played in the middle (strong moves) but didn't have any defences if the human played bad moves initially, straight upwards to make 4 in a row.

&amp;#x200B;

I think this is because it only trained against initial strong moves at the start, and is not familiar with facing unusual moves.

&amp;#x200B;

I am re running the program with 50% random moves (was 10% random moves before) for the start of the training, and plan on reducing it in the future. But I'm not sure if it's better to start with like 80% random, then 50%, then 20%, or some other combination. Obviously it depends on how long it takes for the NN to learn certain aspects of the game as well...",0,1
86,2019-3-22,2019,3,22,4,b3ujar,Analyzing tf.function to discover AutoGraph strengths and subtleties - part 1,https://www.reddit.com/r/tensorflow/comments/b3ujar/analyzing_tffunction_to_discover_autograph/,pgaleone,1553195018,,0,1
87,2019-3-22,2019,3,22,4,b3uzf9,Can someone explain the application of Tensorflow Probability,https://www.reddit.com/r/tensorflow/comments/b3uzf9/can_someone_explain_the_application_of_tensorflow/,krishnab75,1553197204,"I saw the talk on Tensorflow Probability in the latest set of Dev Summit talks on Youtube. But I was still just trying to understand what the purpose or application of Tensorflow probability was? I think even the authors of the package mentioned that the name Tensorflow Probability sounded a bit confusing. 

&amp;#x200B;

So is the purpose of Tensorflow Probability to do Bayesian analysis in Tensorflow? Like is it meant to be a replacement for other software like STAN/BUGS/JAGS--namely other MCMC samplers. So would we use Tensorflow probability to estimate bayesian hierarchical model and get posterior distributions on the parameters? If that is the case, does Tensorflow Probability perform any better than these other STAN/BUGS/JAGS--has anyone done any benchmarks. 

&amp;#x200B;

Or is Tensorflow Probability about getting posterior distributions from graphical models--like markov random fields?  

&amp;#x200B;

I was hoping someone could explain the application of this new and interesting looking package.  

&amp;#x200B;

&amp;#x200B;",3,16
88,2019-3-22,2019,3,22,5,b3va78,Can someone help me in understanding cross validation in tensorflow?,https://www.reddit.com/r/tensorflow/comments/b3va78/can_someone_help_me_in_understanding_cross/,Sonius94,1553198677,"I am new to tensorflow so I am 100% sure how to read tensorflow code. I found the following model:

[https://github.com/jimmyyfeng/TD-LSTM/blob/master/td\_lstm.py](https://github.com/jimmyyfeng/TD-LSTM/blob/master/td_lstm.py)

This model is using train and test data.

I learned that I should split my dataset as followed (example):

80% train data, 20% test data

The test data should never change if I want to train different valies like learning rate for my model.

The train data I split again on each iteration step into train data and validation data for again like 80/20.

Now my question: Is the model on that github repository doing the same?Will it split the training data on each iteration and not learn from the test data?

If now: How could I achieve this. I want that the model not learns from test data and splits the training data for training and validation on each step instead? Can someone explain me how to if its not the case?

&amp;#x200B;

&amp;#x200B;

Posted the question on stackoverflow, too: [https://stackoverflow.com/questions/55287877/do-this-tensorflow-models-implemented-cross-validation](https://stackoverflow.com/questions/55287877/do-this-tensorflow-models-implemented-cross-validation)",2,1
89,2019-3-23,2019,3,23,4,b49c4u,Error reshaping during linear classifier training,https://www.reddit.com/r/tensorflow/comments/b49c4u/error_reshaping_during_linear_classifier_training/,thenerdbutton,1553283080,"I'm pretty new to tensorflow but I went through a bunch of the lessons and practice exercises on Google's ML Crash Course and decided to give it a shot. 

I'm trying to train a linear classifier but keep getting this error:

""InvalidArgumentError (see above for traceback): Input to reshape is a tensor with 1000 values, but the requested shape has 500
         [[node linear/linear_model/linear_model/linear_model/FGPG/Reshape (defined at C:\Users\reach\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_estimator\python\estimator\canned\linear.py:345) ]]"" 

The error shows up right after the shuffle buffer is filled (with a massive traceback stack). I've done some googling and it looks like everyone is getting this when training NNs. I'm trying to use a linear classifier so I'm not sure what's going on, or how to fix it. None of the example vectors I'm using are 500 or 1000 long (I have like 10 features that are all floats, and I've tried training sets from size 5000 to 35000, all giving this error). 

Any idea what could be going on, or how to fix it? Thanks so much!",0,1
90,2019-3-23,2019,3,23,4,b49fc6,Computer freezes then CudNN Crashes when running two models at once?,https://www.reddit.com/r/tensorflow/comments/b49fc6/computer_freezes_then_cudnn_crashes_when_running/,eigenvergle42,1553283533,"Hi, I've noticed what's described in the title for awhile but just recently got a 2nd GPU to try running to models at once and I'm having the same issue. Here's a code snippet:

&amp;#x200B;

  with tf.device('/GPU:1'):

self.model = LookaheadGAN(rdata.shape\[2\], hdata.shape\[2\])

&amp;#x200B;

i = 0

config = tf.ConfigProto()

config.allow\_soft\_placement = True

saver = tf.train.Saver()

&amp;#x200B;

with tf.device('/GPU:1'):

with tf.Session(config=config) as session:

init = tf.initialize\_all\_variables()

[session.run](https://session.run)(init)

while i &lt; 3000000:

rdata, hdata, target = self.data.get\_train\_batch(batch\_size)

\_, gl, rms = [session.run](https://session.run)(\[self.model.gen\_step, self.model.gen\_loss, self.model.rms\_debug\]...

&amp;#x200B;

If I change both with statements to GPU:0 and run another process concurrently, it will freeze for a minute and pump out an error similar to the following:

&amp;#x200B;

UnknownError (see above for traceback): Fail to find the dnn implementation.

\[\[node cudnn\_lstm\_2/cudnn\_lstm\_2/CudnnRNNCanonicalToParams (defined at C:\\Users\\msfti\\source\\repos\\MLHelpers\\MLHelpers\\Lookahead\\[LookaheadGAN.py:83](https://LookaheadGAN.py:83)) \]\]

\[\[node cudnn\_lstm/cudnn\_lstm/CudnnRNNCanonicalToParams (defined at C:\\Users\\msfti\\source\\repos\\MLHelpers\\MLHelpers\\Lookahead\\[LookaheadGAN.py:63](https://LookaheadGAN.py:63)) \]\]

&amp;#x200B;

Has anyone encountered anything like this? Thanks

",8,6
91,2019-3-24,2019,3,24,0,b4kcpf,Collection of high rated online courses to Learn Tensorflow,https://www.reddit.com/r/tensorflow/comments/b4kcpf/collection_of_high_rated_online_courses_to_learn/,gandhiN,1553354803,,3,14
92,2019-3-24,2019,3,24,2,b4li05,Are you building Convolutional Neural Networks on TensorFlow?,https://www.reddit.com/r/tensorflow/comments/b4li05/are_you_building_convolutional_neural_networks_on/,treguess,1553360749,Here are three examples: https://missinglink.ai/guides/deep-learning-frameworks/building-convolutional-neural-networks-tensorflow-three-examples/,0,1
93,2019-3-24,2019,3,24,21,b4vw1x,I have a problem training my object detection model. mAP equals -1. help appreciated.,https://www.reddit.com/r/tensorflow/comments/b4vw1x/i_have_a_problem_training_my_object_detection/,2ringo,1553430987,"Hey guys,

I have a problem training my object detection model in tensorflow. I am using the ""ssd\_mobilenet\_v2"" from the tensorflow model zoo pretrained on the COCO dataset. I am training it on my own dataset. However, the loss is decreasing but the mAP always shows the value -1. Anyone had the same problem? I really do appreciate your help! :)",3,3
94,2019-3-25,2019,3,25,8,b53dbe,Problem with training a multi-hot encoded model (maybe overfitting),https://www.reddit.com/r/tensorflow/comments/b53dbe/problem_with_training_a_multihot_encoded_model/,Corpio03,1553471428,"Hello,

I have been recently working on a project to create a model that will try to learn how to play a video-game on it's own.

The idea is to record the game frames and which keys I am pressing in each specific frame then the model will try to predict the keys to press.

so the training data is something like this:

  \[ \[ frame , keys\] , \[ frame , keys\] , \[ frame , keys\]......\] 

as a start I choosed a Driving Simulator game and I encoded the keys like this :

W =  \[1,0,0,0\] (forwards)

S = \[0,1,0,0\] (backwards)

Q = \[0,0,1,0\] (left)

D= \[0,0,0,1\] (right)

then I encoded them in a multi-hot vector , for example if the script detects that I am pressing ""W"" and ""Q"" the output

 will be like this :  \[1,0,1,0\] which is forwards-left .

I did record some data which I focused mostly on \[1,0,0,0\] , \[1,0,1,0\] and \[1,0,0,1\] and I balanced it to be 1500 frames of each kind.

I tried 2 types of models (CNN and RNN) both models that have an output layer with 4 nodes, ""sigmoid"" activation function and the ""Binary\_Crossentropy"" as loss function.

 The issue is that when I tested them the prediction was always ""W""  \[1,0,0,0\] only.

At first I thought that it didn't accept the Multi-Hot encoding so I did a small record where I only pressed ""W"" and ""D"" to make it \[1,0,0,1\] and it actually worked perfectly the model was outputting  \[1,0,0,1\] all the  time .

The 2 models gave me the same result ,so I don't know if the issue is that I didn't give it enough data? or is it taking the

vector \[1,0,0,0\] as an average since it exists in the other combinations? 

&amp;#x200B;

I am still a beginner in machine learning and tensorflow so I will appreciate any kind of help.

Thanks in advance.

&amp;#x200B;

&amp;#x200B;",2,5
95,2019-3-25,2019,3,25,10,b54j4v,"resembles SAGER NP8961, 2, 3 / CLEVO P960ED, F, N",https://www.reddit.com/r/tensorflow/comments/b54j4v/resembles_sager_np8961_2_3_clevo_p960ed_f_n/,rebcabin-r,1553478094,"CLAIMER: I am a scientist and a purchaser of high-end machines. I have no stake in any computer supplier. I'm just a user / amateur devops / professional developer / professional physicist.

The chassis strongly resembles the SAGER / CLEVO models in the title. SAGER / CLEVO is an OEM supplier of high-end gaming machines. Alienware used them for a while (maybe still do, but I don't buy Alienware stuff any more). I don't know more than this, for example, I don't know whether SAGER and CLEVO are the same company, though they seem to offer the same products with different model numbers (I've never seen a SAGER that didn't have a corresponding CLEVO and vice versa); I don't know whether SAGER and / or CLEVO consider themselves a ""BRAND"" or just an OEM, etc. I have owned a few high-end machines that I traced back to SAGER / CLEVO (looking for parts), and have mixed positive experience. The are not as robust as Lenovos, for example, but they're pretty lightweight and perform well most of the time. I have a SAGER 8950 now, which freezes every couple of weeks or so and won't respond to the power button. I have to let the battery drain down to reboot it. My Alienware died in a blaze of unrepairable GPU death two days after the warranty expired. However, they SCREAM. My current SAGER 8950 32G runs about 18500 on Geekbench, compared to a Lenovo P72 64G, which runs at 21000 Geekbench and cost $7,000. 

Bottom line: I would buy another SAGER, even rebranded, but I would expect it to be finicky and short-lived. I would value the software stack as maintained by Lambda and would strongly consider buying a Lambda, even if they confirmed it's a SAGER, because I easily spend dollar-equivalent time to the difference between a raw SAGER box and a Lambda maintaining software instead of doing real work, and I hate debugging crossed software dependencies! 

You can buy SAGERs here [https://www.xoticpc.com/custom-gaming-laptops-notebooks-gaming-laptops-ct-118-96-98/custom-gaming-laptops-notebooks-clevo-sager-notebooks-ct-95-51-162.html](https://www.xoticpc.com/custom-gaming-laptops-notebooks-gaming-laptops-ct-118-96-98/custom-gaming-laptops-notebooks-clevo-sager-notebooks-ct-95-51-162.html) amongst other places. ",4,1
96,2019-3-25,2019,3,25,22,b5apn5,Number of layers in model architecture?,https://www.reddit.com/r/tensorflow/comments/b5apn5/number_of_layers_in_model_architecture/,NonsphericalFirmness,1553520577,"Hi, Ive used transfer learning on the model ""ssdlite\_mobilenet\_v2\_coco"" from the TensorFlow detection model zoo to train my own dataset. 

Is there any way to find the number of hidden layers in this model? 

&amp;#x200B;

*I wish something like this would exist:*  [*https://www.mathworks.com/help/deeplearning/ref/analyzenetwork.html*](https://www.mathworks.com/help/deeplearning/ref/analyzenetwork.html)

&amp;#x200B;",0,1
97,2019-3-26,2019,3,26,0,b5bzwt,Can I go straight to learning tf 2?,https://www.reddit.com/r/tensorflow/comments/b5bzwt/can_i_go_straight_to_learning_tf_2/,easylifeforme,1553527413,"I'm curious on what your thoughts are for learning tf 2 without knowing tf 1. I've played around with tf 1 but only other people's code never truly diving into it. Is there a lot of value to be gained by trying to learn, the harder to personally understand, tf 1 while 2 is still being developed?",12,7
98,2019-3-26,2019,3,26,5,b5g7ce,Using Tensorflow.js to run a movement game in the browser. Any feedback?,https://www.reddit.com/r/tensorflow/comments/b5g7ce/using_tensorflowjs_to_run_a_movement_game_in_the/,SameDifference,1553547020,,2,29
99,2019-3-26,2019,3,26,7,b5h4p7,quantizing yolo and SSD to custom fixed point data types,https://www.reddit.com/r/tensorflow/comments/b5h4p7/quantizing_yolo_and_ssd_to_custom_fixed_point/,rafeey,1553551386,"I want to quantize yolo and SSD to custom fixed point data types to study the effect on accuracy. Can anyone who've done that please guide me how to do that?  
I've tried tflite converter but it gives error on custom nets like yolo. Plus it only supports int8 conversion. Is there any other way to do it?",0,1
100,2019-3-26,2019,3,26,21,b5owb3,TFRecords ?,https://www.reddit.com/r/tensorflow/comments/b5owb3/tfrecords/,RemoteReindeer,1553602107,"Hi, 

If I understand well, TFRecords files are read with the help of a protocol buffer.

I have multiples Examples inside my TFRecord. To access a specific Example inside this TFRecord, do I have to read all the previous Example in it (since it's a buffer), or is there a way to access it directly ?",8,2
101,2019-3-26,2019,3,26,22,b5q1km,"alexnet classification while training, showing no signs of training",https://www.reddit.com/r/tensorflow/comments/b5q1km/alexnet_classification_while_training_showing_no/,jango1502,1553608757,"My classification model classify given images in three categories. I trained the model with 7000 images in each category.

During the training:
. Model first starts with 33.3% validation and training accuracy.
. Training and validation loss also kind of remains constant during initial epochs
. After 80-100 epochs, the model shows variation in *validation loss* and *training loss* and thus the training and validation accuracy also start to change.
. At 185 epochs model gives 95% training accuracy and 85% validation accuracy.

(So in short my model stays at 33% training and validation accuracy for a while and then after many epochs accuracies start to change. If my training dataset is even less, this constant intial training and validation accuracy stays almost constant for less number of epochs than training the model with larger dataset.)


Now, I did not change any code in the algorithm but just providing a bigger dataset for training.

Right now, each category has 11k images (I worked on the dataset myself, making sure no image goes to wrong category.) 

Problem: 

.Its 300+ epochs now but that 33% has not changed yet! 
.Fix training loss and validation loss for last 295 epochs.
I did not even double the training set, just 1.5 times it is.



.Is this common? 
Should I keep the training go and see when does it change? (why!? Bcos each epoch takes 256sec on my Gpu system, so in one day it runs 300-350 epochs only)  
Or should I do some other checks??


Any suggestions??

",2,1
102,2019-3-27,2019,3,27,14,b60g49,Implementing autoencoder in TensorFlow 2.0,https://www.reddit.com/r/tensorflow/comments/b60g49/implementing_autoencoder_in_tensorflow_20/,afagarap,1553664139,,9,18
103,2019-3-27,2019,3,27,20,b636ml,"This video goes over a model that predicts the number of views on a youtube video based on likes, dislikes, and subscribers. Really interesting and educational. Do check it out",https://www.reddit.com/r/tensorflow/comments/b636ml/this_video_goes_over_a_model_that_predicts_the/,antaloaalonso,1553685238,,0,1
104,2019-3-27,2019,3,27,21,b63wwd,"Introduction to TensorFlow for AI, Machine Learning, and Deep Learning",https://www.reddit.com/r/tensorflow/comments/b63wwd/introduction_to_tensorflow_for_ai_machine/,frenchdic,1553689934,,0,1
105,2019-3-28,2019,3,28,0,b65qx5,Possible subtitles for Tensorflow 2,https://www.reddit.com/r/tensorflow/comments/b65qx5/possible_subtitles_for_tensorflow_2/,MrAcurite,1553701015,"Tensorflow 2: Electric Boogaloo

Tensorflow 2: Propagation Strikes Back

Tensorflow 2: Traceback of the Clones

Tensorflow 2: The Wrath of GANN

Tensorflow 2: Redemption

Tensorflow 2: This Time It's Perceptive",5,4
106,2019-3-28,2019,3,28,11,b6dl6l,Variational Autoencoders with Tensorflow Probability Layers,https://www.reddit.com/r/tensorflow/comments/b6dl6l/variational_autoencoders_with_tensorflow/,GariSingh,1553741840,,0,13
107,2019-3-30,2019,3,30,3,b71653,Speed up spectrogram computation with tensorflow,https://www.reddit.com/r/tensorflow/comments/b71653/speed_up_spectrogram_computation_with_tensorflow/,ronald_sumbayak,1553885756,"I don't know if it's okay to post a link to stackoverflow here (please tell me if I should copy paste the question here instead), but you can find the details there:

[https://stackoverflow.com/q/55419515/5447454](https://stackoverflow.com/q/55419515/5447454)

&amp;#x200B;

In short, I am currently trying to compute spectrogram of all 1-second clip from audio files (which is extracted from video) using \` tensorflow.contrib.framework.python.ops.audio\_ops.audio\_spectrogram\` function, but it takes a really long time (it might takes days or even weeks, looking at my data size).

&amp;#x200B;

Is there any way to speed up this computation?",0,2
108,2019-3-30,2019,3,30,5,b725ta,How we improved Tensorflow Serving performance by over 70%,https://www.reddit.com/r/tensorflow/comments/b725ta/how_we_improved_tensorflow_serving_performance_by/,masroorhasan,1553890742,Infrastructure perspective: An overview of techniques on optimizing model server and client to reduce latency of prediction pipeline. ,3,6
109,2019-3-30,2019,3,30,6,b730ms,error when starting training: InvalidArgumentError: logits and labels must have the same first dimension,https://www.reddit.com/r/tensorflow/comments/b730ms/error_when_starting_training_invalidargumenterror/,granular2,1553895180,"I get an error `InvalidArgumentError: logits and labels must have the same first dimension, got logits shape [25088,10] and labels shape [32] 	 [[{{node loss_10/output_1_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]`

    # TensorFlow and tf.keras
    import tensorflow as tf
    from tensorflow import keras
    
    (training_images, training_labels), (test_images, test_labels) = keras.datasets.fashion_mnist.load_data()
    
    training_images = training_images.reshape(training_images.shape[0], 28, 28, 1)
    
    training_images = training_images / 255.0
    test_images = test_images / 255.0
    
    model = keras.Sequential()
    model.add( keras.layers.Conv2D(filters=64, kernel_size=(4,4), padding='same',
                                   activation='relu'))
    model.add(keras.layers.Dense(10, activation=tf.nn.softmax))
    
    model.compile(optimizer='adam', 
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
                   
    print(training_images.shape)
    print(training_labels.shape)
    
    model.fit(training_images, training_labels, epochs=3)

\# shapes printed

(60000, 28, 28, 1)   
(60000,)

&amp;#x200B;

What is wrong?

Thanks",2,2
110,2019-3-30,2019,3,30,15,b77z7c,"TensorFlow is dead, long live TensorFlow!",https://www.reddit.com/r/tensorflow/comments/b77z7c/tensorflow_is_dead_long_live_tensorflow/,ConfidentMushroom,1553926641,,4,41
111,2019-3-30,2019,3,30,18,b79gjq,Starting pointers?,https://www.reddit.com/r/tensorflow/comments/b79gjq/starting_pointers/,throughdaylight,1553939250,"Hello,

First, a bit of a background - Im a hardware engineer by trade. Ive seldom used Python, but I dont mind learning it over next few days. 

I wanted to repurpose my old android phone, such that I can use its rear camera to capture video feed and post process it to detect cars that pass by our neighborhood street and perhaps also register its directional flow (and tabulate it in a spreadsheet).

Is it too difficult to implement? Where can I get started? What are the things I need to learn or grasp before I can undertake such a project? Do I need a super beefy hardware to implement this project?

Thanks for reading.",0,1
112,2019-3-30,2019,3,30,21,b7ao1l,"By default, tensorflow supports 8-bit quantization, is there a way to implement 4-bit quantization?",https://www.reddit.com/r/tensorflow/comments/b7ao1l/by_default_tensorflow_supports_8bit_quantization/,saurav_97,1553948474,,4,0
0,2019-4-1,2019,4,1,10,b7vd7r,TF2 Image Augmentation with Keras,https://www.reddit.com/r/tensorflow/comments/b7vd7r/tf2_image_augmentation_with_keras/,alew3,1554080942,"I'm training a model for image categorical classification, it is working fine and I'm using tf.data.Dataset to improve the performance of loading the images. 

I'm confused on how to do train/test image augmentation to further improve the performance of the model.

I haven't been able to figure out how to mix the Keras model.fit\_generator with a TF.data.Dataset.",4,5
1,2019-4-1,2019,4,1,14,b7xqjb,A Neural Network for any Image Dataset in TensorFlow 2.0,https://www.reddit.com/r/tensorflow/comments/b7xqjb/a_neural_network_for_any_image_dataset_in/,shawnmanuel000,1554095544,"Hey guys, a few people had requested that I make a tutorial on how to upload your own images to create your own neural network images classifier so here's the YouTube tutorial video I made for that using TensorFlow 2.0  (also to save the weights after training). 

[https://www.youtube.com/watch?v=bNntsCOdFxg](https://www.youtube.com/watch?v=bNntsCOdFxg)",0,13
2,2019-4-1,2019,4,1,16,b7yxkl,9 Things You Should Know About TensorFlow,https://www.reddit.com/r/tensorflow/comments/b7yxkl/9_things_you_should_know_about_tensorflow/,Ratlifford,1554103430,[http://on.geeklearn.net/6b44d9c382](http://on.geeklearn.net/6b44d9c382),2,6
3,2019-4-1,2019,4,1,20,b816kw,"TensorFlow is dead, long live TensorFlow!",https://www.reddit.com/r/tensorflow/comments/b816kw/tensorflow_is_dead_long_live_tensorflow/,AndyMerskinon,1554118914,[http://on.geeklearn.net/c80d7d9620](http://on.geeklearn.net/c80d7d9620),0,0
4,2019-4-1,2019,4,1,20,b817iq,Introducing TensorFlow 2.0,https://www.reddit.com/r/tensorflow/comments/b817iq/introducing_tensorflow_20/,Newsomome,1554119070,[https://www.youtube.com/watch?v=QVumdZ6bZa0](https://www.youtube.com/watch?v=QVumdZ6bZa0),0,0
5,2019-4-2,2019,4,2,2,b85tsp,AI Chip Startup Inches Forward with $800 Million in Series A,https://www.reddit.com/r/tensorflow/comments/b85tsp/ai_chip_startup_inches_forward_with_800_million/,KeponeFactory,1554140865,,3,12
6,2019-4-2,2019,4,2,17,b8gng0,How to check the data in the iterator?,https://www.reddit.com/r/tensorflow/comments/b8gng0/how_to_check_the_data_in_the_iterator/,Laurence-Lin,1554195230,"I've use an iterator for the training dataset, but now my training accuracy for each epoch remains zero, so I would like to check if the data is correctly get from the iterator. While I'm using:  

training\_batch = iterator.get\_next()

I get a tuple of tensor representing a single batch of dataset. How could I check the element in the 'training\_batch', such like print the size or show a single image sample in it?  


Thanks a lot!",2,1
7,2019-4-3,2019,4,3,5,b8ocnh,CNN having dimension problems,https://www.reddit.com/r/tensorflow/comments/b8ocnh/cnn_having_dimension_problems/,916swift,1554236362,"I was able to create and compile a basic CNN model, however whenever I try to pass in the training data, I get the following error:

 ValueError: Error when checking input: expected input\_1 to have 4 dimensions, but got array with shape (3475, 256, 256)     

&amp;#x200B;

&amp;#x200B;

Currently I expanded the dimensions with numpy as shown below, although it didnt seem to work:

TrX = np.expand\_dims(Train\_X, 3)

TeX = np.expand\_dims(Test\_X, 3)

&amp;#x200B;

&amp;#x200B;

Also within the definition for the model, I have the input as follows:

inputs = tf.keras.layers.Input(shape = params\[""input\_shape""\])

&amp;#x200B;

""input shape"" in parameters is as follows:

""input\_shape"": (256,256,1)

&amp;#x200B;

Any advice on how to resolve the error is greatly appreciated 

&amp;#x200B;",9,6
8,2019-4-3,2019,4,3,16,b8utg9,How to determine the amount of RAM required to load a tensorflow model?,https://www.reddit.com/r/tensorflow/comments/b8utg9/how_to_determine_the_amount_of_ram_required_to/,cant-find-user-name,1554276036,"Hi all,

I would like to determine the amount of RAM required to load a model and get predictions. The use case is that I have a VM instance and I'd like to load my tf models into it and expose API calls for others to get predictions. So to knowing if enough RAM is left in the machine, I'd need to know how much RAM my model needs. 

Please let me know if there is a programmatic way or any other way to do that. 

Thanks in advance :) ",3,2
9,2019-4-4,2019,4,4,0,b8z9t5,Need some help creating a custom layer in TF2.0,https://www.reddit.com/r/tensorflow/comments/b8z9t5/need_some_help_creating_a_custom_layer_in_tf20/,Jehovacoin,1554304660,"I'm trying to implement a simple capsnet model in TF2.0, but I'm not very experienced with TF at all. So far, I have added a few conv2d layers, and a reshape layer, but I need to add a squash function now. The issue is that tf.norm() will send me to NaN land since I'm squashing entire vectors, so I have to use a custom squash function. 

Since I am doing this all inside of a keras.models.Sequential model, I wasn't sure how to get the output after the first couple of layers so I just decided to make the squash function its own layer in the model. It looks like this right now:

    class SquashLayer(tf.keras.layers.Layer):
	    def __init__(self, output_units):
		    super(SquashLayer, self).__init__()
		    self.output_units = output_units

	    def build(self, input_shape):
		    self.kernel = self.add_variable(
			  'kernel', [input_shape[-1], self.output_units])

	    def call(self, input):
		    squared_norm = tf.reduce_sum(tf.square(input), axis=-1, keepdims=True)
		    safe_norm = tf.sqrt(squared_norm + 1e-7)
		    squash_factor = squared_norm / (1. + squared_norm)
		    unit_vector = input / safe_norm
		    return squash_factor * unit_vector

Then I just pass it into my model like this:

    model = keras.models.Sequential([
	keras.layers.InputLayer(input_shape=(28, 28, 1)),
	keras.layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation=tf.nn.relu, name='conv1'),
	keras.layers.Conv2D(filters=256, kernel_size=9, strides=2, padding='valid', activation=tf.nn.relu, name='conv2'),
	keras.layers.Reshape((-1, caps1_n_caps, caps1_n_dims)),
	SquashLayer()
	])

I feel like this is probably completely and totally wrong, so I'm looking for some input on the best way to go about this. Should I be using a keras.Model for this at all, or should I use the new eager execution feature to just pass the tensors through the layers manually? If it's okay to use the SquashLayer() that I have implemented, then what do I pass through as an argument so that I get the proper output to pass into the next layer?",1,2
10,2019-4-4,2019,4,4,5,b92y0k,How does tf.function work? Weird behaviors and bad performance analysis,https://www.reddit.com/r/tensorflow/comments/b92y0k/how_does_tffunction_work_weird_behaviors_and_bad/,pgaleone,1554321853,,0,1
11,2019-4-4,2019,4,4,6,b945n9,Train model with all data or just the newest data ?,https://www.reddit.com/r/tensorflow/comments/b945n9/train_model_with_all_data_or_just_the_newest_data/,TheCur,1554327794,"Hi Guys,

I'm building a neural network to play connect 4 using reinforcement learning. At the moment after every game  that data is appended to a list which is then used to train the model using model.fit in tflearn. After every game appending to this list, as a result this lost gets big over time and I'm passing in this whole list every time to model.fit(). As hundreds of games are played this lost gets big very quickly as a result slowing down the training process. 

My question is , do I have to pass in all training data every time to model.fit () or can I just use the newest data that it hasn't been trained on yet ? Thanks in advance ",4,1
12,2019-4-4,2019,4,4,8,b950yo,"Has anyone ran TensorFlow on a raspberry pi 0? I have a trained model but am having a hard time getting TensorFlow onto the pi, thank in advance for the advice!",https://www.reddit.com/r/tensorflow/comments/b950yo/has_anyone_ran_tensorflow_on_a_raspberry_pi_0_i/,e10101010,1554332441,,4,6
13,2019-4-4,2019,4,4,13,b98368,Can you run tensorflow on python in anaconda?,https://www.reddit.com/r/tensorflow/comments/b98368/can_you_run_tensorflow_on_python_in_anaconda/,tropicalpersonality,1554351187,"Im writing a python program and am looking to call and run a tensorflow model that looks at a given image file at a certain time returning a percentage match. If so, how? 


I used this tutorial to set up my tensorflow model

https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10",4,0
14,2019-4-4,2019,4,4,13,b98crk,How to Image Classification with TensorFlow 2.0?,https://www.reddit.com/r/tensorflow/comments/b98crk/how_to_image_classification_with_tensorflow_20/,Barbara9119,1554353058,[http://dev.edupioneer.net/b20f57989d](http://dev.edupioneer.net/b20f57989d),0,2
15,2019-4-4,2019,4,4,14,b98la0,YARN infrastructure or move to Cloud,https://www.reddit.com/r/tensorflow/comments/b98la0/yarn_infrastructure_or_move_to_cloud/,_spicyramen,1554354727,"My current company invested in Hadoop clusters and now we want to experiment in Machine Learning and Deep Learning, any recommendations to get started? I have heard a lot of KubeFlow but not sure if it makes sense in a Hadoop environment",0,1
16,2019-4-4,2019,4,4,20,b9bnvx,Why is this code slowing down so much?,https://www.reddit.com/r/tensorflow/comments/b9bnvx/why_is_this_code_slowing_down_so_much/,grappling_hook,1554378376,"I'm trying to implement Polyak averaging for a soft actor-critic RL model. This requires me to do a weighted average of the weights of two networks. I've noticed that these lines of code get progressively slower and slower as training progresses. Since this code is run very frequently (for each action), it's slowing down training time massively. Any idea why this is going on, and how I can fix it? I thought that perhaps there are new variables being added to the session so maybe lookup is taking longer because of that, but it seems like the number of variables stays constant. 

    target_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='target_value_network')
    value_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='value_network')
    sess.run([v_t.assign(v_t * (1. - soft_tau) + v * soft_tau) for v_t, v in zip(target_params, value_params)])

&amp;#x200B;",7,2
17,2019-4-5,2019,4,5,1,b9ergc,I built tensorflow.,https://www.reddit.com/r/tensorflow/comments/b9ergc/i_built_tensorflow/,earee,1554394489," ***That took longer then I expected.***

Target //tensorflow/tools/pip\_package:build\_pip\_package up-to-date:  
 bazel-bin/tensorflow/tools/pip\_package/build\_pip\_package  
INFO: Elapsed time: 73182.034s, Critical Path: 1047.75s  
INFO: 12163 processes: 12163 local.  
INFO: Build completed successfully, 12997 total actions

***(73182secs/60secs)/60mins =20.32 hours..***

***I had estimated it at 24 hours but still the longest build I have ever witnessed.***

***I wonder if it works....***

root@c0d1f21f53c9:\~# python -c ""import tensorflow as tf; print(tf.\_\_version\_\_)""  
1.13.1  
root@c0d1f21f53c9:\~#

***It works!... but I wanted version 2.0..***

root@c0d1f21f53c9:/tensorflow\_src# git status  
On branch master  
Your branch is up-to-date with 'origin/master'.  
nothing to commit, working directory clean  
root@c0d1f21f53c9:/tensorflow\_src# git branch  
 dev  
\* master  
root@c0d1f21f53c9:/tensorflow\_src# git checkout dev  
Checking out files: 100% (3021/3021), done.  
Switched to branch 'dev'  
Your branch is up-to-date with 'origin/r2.0'.

root@c0d1f21f53c9:/tensorflow\_src# bazel build --config=opt //tensorflow/tools/pip\_package:build\_pip\_package  
Starting local Bazel server and connecting to it...

***Just wait for this to finish building..***",7,4
18,2019-4-5,2019,4,5,10,b9kxdv,Question for a friend regarding building TensorFlow,https://www.reddit.com/r/tensorflow/comments/b9kxdv/question_for_a_friend_regarding_building/,SirVaksghn,1554426481,"Had a friend trying to build TensorFlow on his machine and banging his head against the wall. Told him I'd ask around and see if I could find the soln somwhere. Could you guys help him out:

**Does anyone know where he can obtain a wheel for Tensorflow 1.12.0 compiled for GPU and Python3, with minimum compute capability 3.0?**
",1,5
19,2019-4-5,2019,4,5,13,b9mwfg,Introduction to Tensorflow for Java,https://www.reddit.com/r/tensorflow/comments/b9mwfg/introduction_to_tensorflow_for_java/,CoreyEnzym,1554439325,[removed],0,1
20,2019-4-5,2019,4,5,13,b9mx37,Introduction to Tensorflow for Java,https://www.reddit.com/r/tensorflow/comments/b9mx37/introduction_to_tensorflow_for_java/,Usama9012,1554439461,[http://on.geeklearn.net/4322c03e42](http://on.geeklearn.net/4322c03e42),3,7
21,2019-4-6,2019,4,6,0,b9smu4,When do you prefer pre-made estimator to keras or lightgbm?,https://www.reddit.com/r/tensorflow/comments/b9smu4/when_do_you_prefer_premade_estimator_to_keras_or/,SubstantialSwimmer4,1554478343,"I tried to make use of pre-made estimator (DNN, BoostedTree, and wide-n-deep). But in my experience, evaluated scores are worse than the models' I made by keras or GBDT such as lightgbm. When do you choose to employ pre-made estimator?",0,1
22,2019-4-6,2019,4,6,7,b9xvpm,How to tune a tensorflow linear classifier model?,https://www.reddit.com/r/tensorflow/comments/b9xvpm/how_to_tune_a_tensorflow_linear_classifier_model/,19264180,1554505079,"I'm new to tensorflow and I built a classification model using the tf linear classifier. I want to tune the model but not sure how to go about it. Have read up ray and tune but don't understand it.
Any help will be so much appreciated.",2,1
23,2019-4-6,2019,4,6,9,b9z1fg,How Neural Networks Work- Simply Explained by a Machine Learning Engineer,https://www.reddit.com/r/tensorflow/comments/b9z1fg/how_neural_networks_work_simply_explained_by_a/,ailearn12,1554512377,,3,14
24,2019-4-6,2019,4,6,20,ba3api,can not import name autograph error,https://www.reddit.com/r/tensorflow/comments/ba3api/can_not_import_name_autograph_error/,cmps299mme,1554549303,"Hi, im trying to run the following code locally on a linux machine. All necessary programs were downloaded and in theory everything must run. However, we are getting the following error: ""from tensorflow.contrib import autograph""  


This is the code we are trying to run (this run on the cloud):  [https://colab.research.google.com/drive/1hSq\_D5s9FWs2MH6BNyf6cTRBXEGcYO\_D#scrollTo=kFWZi57amziK&amp;forceEdit=true&amp;offline=true&amp;sandboxMode=true](https://colab.research.google.com/drive/1hSq_D5s9FWs2MH6BNyf6cTRBXEGcYO_D#scrollTo=kFWZi57amziK&amp;forceEdit=true&amp;offline=true&amp;sandboxMode=true)   


the error occurs in:

1- Patch tranformation: (error on last line)

&gt;  for i in range(2):  
&gt;  
&gt;  print(""Test image with random transform: %s"" % (i+1))  
&gt;  
&gt;  `test_random_transform(min_scale=0.25, max_scale=2.0, max_rotation=22.5)`

  

  2- when calling metamodule():

&gt;\#@ MetaModel  
&gt;  
&gt;  
&gt;  
&gt;class MetaModel():  
&gt;  
&gt;  def \_\_init\_\_(self, verbose=True, peace\_mask=None, peace\_mask\_overlay=0.0):  
&gt;  
&gt;[self.nc](https://self.nc) = {m: ModelContainer(m, verbose=verbose, peace\_mask=peace\_mask, peace\_mask\_overlay=peace\_mask\_overlay) for m in MODEL\_NAMES}  
&gt;  
&gt;self.\_patch = np.zeros(PATCH\_SHAPE)  
&gt;  
&gt;self.patch\_shape = PATCH\_SHAPE  
&gt;  
&gt;  
&gt;  
&gt;  def patch(self, new\_patch=None):  
&gt;  
&gt;""""""Retrieve or set the adversarial patch.  
&gt;  
&gt;  
&gt;  
&gt;new\_patch: The new patch to set, or None to get current patch.  
&gt;  
&gt;  
&gt;  
&gt;Returns: Itself if it set a new patch, or the current patch.""""""  
&gt;  
&gt;if new\_patch is None:  
&gt;  
&gt;return self.\_patch  
&gt;  
&gt;  
&gt;  
&gt;self.\_patch = new\_patch  
&gt;  
&gt;return self  
&gt;  
&gt;  
&gt;  
&gt;  def reset\_patch(self):  
&gt;  
&gt;""""""Reset the adversarial patch to all zeros.""""""  
&gt;  
&gt;self.patch(np.zeros(self.patch\_shape))  
&gt;  
&gt;  
&gt;  
&gt;  def train\_step(self, model=None, steps=1, images=None, target\_ys=None, learning\_rate=5.0, scale=None, \*\*kwargs):  
&gt;  
&gt;""""""Train the model for \`steps\` steps.  
&gt;  
&gt;  
&gt;  
&gt;Args:  
&gt;  
&gt;images: A batch of images to train on, it loads one if not present.  
&gt;  
&gt;target\_ys: Onehot target vector, defaults to TARGET\_ONEHOT  
&gt;  
&gt;learning\_rate: Learning rate for this train step.  
&gt;  
&gt;scale: Either a scalar value for the exact scale, or a (min, max) tuple for the scale range.  
&gt;  
&gt;  
&gt;  
&gt;Returns: Loss on the target ys.""""""  
&gt;  
&gt;  
&gt;  
&gt;  
&gt;  
&gt;if model is not None:  
&gt;  
&gt;to\_train = \[[self.nc](https://self.nc)\[model\]\]  
&gt;  
&gt;else:  
&gt;  
&gt;to\_train = self.nc.values()  
&gt;  
&gt;  
&gt;  
&gt;losses = \[\]  
&gt;  
&gt;for mc in to\_train:  
&gt;  
&gt;mc.patch(self.patch())  
&gt;  
&gt;for i in xrange(steps):   
&gt;  
&gt;loss = mc.train\_step(images, target\_ys, learning\_rate, scale=scale, \*\*kwargs)  
&gt;  
&gt;losses.append(loss)  
&gt;  
&gt;self.patch(mc.patch())  
&gt;  
&gt;return np.mean(losses)  
&gt;  
&gt;  
&gt;  
&gt;  def inference\_batch(self, model, images=None, target\_ys=None, scale=None):  
&gt;  
&gt;""""""Report loss and label probabilities, and patched images for a batch.  
&gt;  
&gt;  
&gt;  
&gt;Args:  
&gt;  
&gt;images: A batch of images to train on, it loads if not present.  
&gt;  
&gt;target\_ys: The target\_ys for loss calculation, TARGET\_ONEHOT if not present.  
&gt;  
&gt;scale: Either a scalar value for the exact scale, or a (min, max) tuple for the scale range.  
&gt;  
&gt;""""""  
&gt;  
&gt;  
&gt;  
&gt;mc = [self.nc](https://self.nc)\[model\]  
&gt;  
&gt;mc.patch(self.patch())  
&gt;  
&gt;return mc.inference\_batch(images, target\_ys, scale=scale)  
&gt;  
&gt;  
&gt;  
&gt;print(""Creating MetaModel..."")  
&gt;  
&gt;`MM = MetaModel()`  


if you have any ideas about what is going wrong or what we should do please comment below  
Thank you in advance",0,0
25,2019-4-7,2019,4,7,1,ba60ik,AttributeError: module 'tensorflow.contrib.seq2seq' has no attribute 'prepare_attention'!!,https://www.reddit.com/r/tensorflow/comments/ba60ik/attributeerror_module_tensorflowcontribseq2seq/,nsrfriends,1554567869,"Hi, I am building a chatbot , and counter with this error of seq2seq model! Can anyone let me know how to counter this issue? Well i am using Python 3.7 and Tensor-flow version 1.13.1. Please !!  ",1,2
26,2019-4-7,2019,4,7,5,ba8luj,How to use Tensorboard Projector Embeddings Visualization in TF2 Keras,https://www.reddit.com/r/tensorflow/comments/ba8luj/how_to_use_tensorboard_projector_embeddings/,alew3,1554582706,"I couldn't find any documentation of how to use embeddings for projector visualization in TF2. If I try and use a embedding parameter within tf.keras.callbacks.TensorBoard

I get the message:

Embeddings will be ignored in TensorFlow 2.0 for the \`TensorBoard\` Callback.",3,1
27,2019-4-7,2019,4,7,23,bah16x,[Question] about Keras model,https://www.reddit.com/r/tensorflow/comments/bah16x/question_about_keras_model/,Loutchiano,1554648930,"Hello everyone, I am trying to understand a Keras code and I need some help on a part related to models.

I am reading a GAN [code](https://github.com/eriklindernoren/Keras-GAN/blob/master/gan/gan.py) and I don't understand why the author seems to use both Sequential and Functionnal model in the build\_generator function :

`model = Sequential()`

`model.add(some_layers)`

`noise = Input(shape=(self.latent_dim,))`

`img = model(noise)`

`return Model(noise, img)`

He first create a Sequential model, adds layers, then create an Input layer ""noise"".  He passes this input into model to connect it I guess. Finally he returns what seems to be a functionnal model. 

&amp;#x200B;",2,0
28,2019-4-8,2019,4,8,9,bangal,Scanning Unique Codes,https://www.reddit.com/r/tensorflow/comments/bangal/scanning_unique_codes/,Mlearly1209,1554685018,"Similar to the Coca-Cola promotion, our promotional marketing agency is looking for a developer who can develop a program using tensorflow to read unique codes found on caps. Anyone have any contacts or sources who could help our company accomplish this project?",8,2
29,2019-4-8,2019,4,8,20,baseoh,2 categories or many categories?,https://www.reddit.com/r/tensorflow/comments/baseoh/2_categories_or_many_categories/,eamh4,1554721427,"Hi all, 

&amp;#x200B;

new to this sub but been learning a lot! 

&amp;#x200B;

I have trained an algorithm to detect dogs (doesnt have to decipher between breeds, just detect/confirm/deny). I trained it using two categories: dog, not dog where the latter category contained everything from anime, buildings to flowers. 

&amp;#x200B;

From your experience, would I be better off training the not dog category as one big one, or multiple small ones? 

&amp;#x200B;

Thank you! ",1,1
30,2019-4-9,2019,4,9,1,bavmzg,Time Series Formatting,https://www.reddit.com/r/tensorflow/comments/bavmzg/time_series_formatting/,cuckoostep,1554739702,"I am creating an LSTM model using Keras and TensorFlow for a [univariate time series dataset](https://archive.ics.uci.edu/ml/datasets/News+Popularity+in+Multiple+Social+Media+Platforms) with 144 timestamps. Each row is a separate instance of a news subject and each timestamp records its ""level of popularity"" at that time. My question is how can I feed the set as several hundred separate subjects with 144 steps to forecast unseen subjects?",1,1
31,2019-4-9,2019,4,9,3,bax06h,Cluster-**** Installing Tensorflow-gpu On Eluktronics Windows 10.0,https://www.reddit.com/r/tensorflow/comments/bax06h/cluster_installing_tensorflowgpu_on_eluktronics/,sstovall19,1554746655,"I have jumped into the Deep Learning fray and quickly got tensorflow/keras up and running on my Eluktronics p950 (7th gen, 1070), but have not been able to install tensorflow-gpu. WSL isnt workable, and I was told by the vendor neither is dual-boot Linux. So Ive spent a week trying to install it on Windows 10.0 using several recipes, but still end up with a cant load runtime error as soon as I import tensorflow as tf. Does anyone have any ideas??",7,2
32,2019-4-9,2019,4,9,5,bayujf,Can the loss be a promise/take time?,https://www.reddit.com/r/tensorflow/comments/bayujf/can_the_loss_be_a_promisetake_time/,MalicousMonkey,1554756018,"I am using Tensorflow.js. I want to make an AI that learns to play pong, but I am not sure what to use as the loss/cost function. Obviously it will be how well the neural network does at pong, but I am not sure how to put that into a single function. Is it possible for it to be a promise that returns when the AI fails?",2,1
33,2019-4-9,2019,4,9,5,baz1fr,"[Question] Tensorflow inference run time high on first data point, decreases on subsequent data points. How to reduce?",https://www.reddit.com/r/tensorflow/comments/baz1fr/question_tensorflow_inference_run_time_high_on/,naboo_random,1554756974,"I am running inference using one of the models from tensorflow's object detection module. I'm looping over my test images in the same session, and doing session.run(). However, on profiling these runs, I realize the first run always has a higher time as compared to the subsequent runs.

I found an answer [here](https://stackoverflow.com/questions/45063489/first-tf-session-run-performs-dramatically-different-from-later-runs-why), as to why that happens, but there was no solution on how to fix.

I'm deploying the object detection inference pipeline on an intel i7 CPU. The time for one session.run(), for 1,2,3, and 4th image looks something like (in seconds):

1.  84.7132628
2. 1.495621681
3. 1.505012751
4. 1.501652718

Just a background on what all I have tried:

* I tried using the TFRecords approach tensorflow gave as a sample \[here\]([https://github.com/tensorflow/models/blob/master/research/object\_detection/g3doc/oid\_inference\_and\_evaluation.md](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/oid_inference_and_evaluation.md])). I hoped it would work better because it doesn't use a feed\_dict. But since more I/O operations are involved, I'm not sure it'll be ideal. I tried making it work without writing to the disk, but always got some error regarding the encoding of the image.
* I tried using the tensorflow datasets to feed the data, but I wasn't sure how to provide the input, since the during inference I need to provide input for ""image tensor"" key in the graph. Any ideas how to use this to provide input to a frozen graph?

Any help will be greatly appreciated!

TLDR: Looking to reduce the run time of inference for the first image - for deployment purposes.",4,6
34,2019-4-9,2019,4,9,6,baze1r,CNN parameters,https://www.reddit.com/r/tensorflow/comments/baze1r/cnn_parameters/,916swift,1554758777,"Anyone have recommendations for where to get information about how to determine parameters for CNNs?

&amp;#x200B;

Mainly interested in how to get numbers for batch sizes, number of conv filters, when to use non-standard kernel sizes, and dropout ratios

&amp;#x200B;

thanks in advance",4,5
35,2019-4-9,2019,4,9,8,bb0xew,C (not C++) implementation of Tensorflow for Time-series forcasting,https://www.reddit.com/r/tensorflow/comments/bb0xew/c_not_c_implementation_of_tensorflow_for/,bot_trig,1554767200,"I'm looking for documentation, books and examples on tensorflow implementation in C language. Specifically examples of code written in C using tf at an intermediate to high level. I am struggling to find anything online as google is basically flooded with shitty Medium articles which start with ""to use tensorflow, you have to learn to code first!"".  If anyone can provide me with some solid resources, that would be very appreciated.",0,0
36,2019-4-9,2019,4,9,16,bb4tma,Increase Accuracy of SSD-Mobilenet-v1,https://www.reddit.com/r/tensorflow/comments/bb4tma/increase_accuracy_of_ssdmobilenetv1/,8222Tamil,1554793413,I want to process around 1 hour video in object detection API.but using FasterRCNN i attain the accuracy but it takes high inference [time.by](https://time.by) using SSD-Mobilenet-v1 i attain time but accuracy is not good.Want to know the possible ways to fine tune SSD-mobilenet-V1 or else how to develop a tf model from Scracth..,2,2
37,2019-4-9,2019,4,9,21,bb74lg,What competes with TF Lite for on device inference?,https://www.reddit.com/r/tensorflow/comments/bb74lg/what_competes_with_tf_lite_for_on_device_inference/,bartturner,1554811600,"I am curious on what others options there are for deploying models on a device that compete with TF Lite?

I am aware of Core ML but that is limited to Apple as far as I am aware.

Thanks for any help in advance!",8,8
38,2019-4-9,2019,4,9,22,bb81hb,Test,https://www.reddit.com/r/tensorflow/comments/bb81hb/test/,MalicousMonkey,1554817064,Test,1,0
39,2019-4-10,2019,4,10,1,bb9v0k,What kind of GAN should I use?,https://www.reddit.com/r/tensorflow/comments/bb9v0k/what_kind_of_gan_should_i_use/,mwendten,1554826610,"I'm writing my masters thesis, where I want to apply a GAN to a structural problem for civil engineering.

I have two black and white images as input, and the output is likewise a black and white image of almost the same size

&amp;#x200B;

What kind of GAN or other generative model, would be optimal for such a problem?

&amp;#x200B;

For those interested, the input images are forces applied to a design domain, where the pixel color is the strength of the force. As it is a 2D problem, each of the two input images are channels for each direction (up-down, left-right). The output image is a density map, that shows an optimal way to put an amount of material for maximum stiffness of the structure.",10,1
40,2019-4-10,2019,4,10,5,bbd2r4,The Rise of Generative Adversarial Networks,https://www.reddit.com/r/tensorflow/comments/bbd2r4/the_rise_of_generative_adversarial_networks/,kailashahirwar12,1554842440,,1,14
41,2019-4-10,2019,4,10,7,bbe3wz,Has Anyone Gotten Tensorflow-gpu To Run On a GTX 1070 Max-Q Driver??,https://www.reddit.com/r/tensorflow/comments/bbe3wz/has_anyone_gotten_tensorflowgpu_to_run_on_a_gtx/,sstovall19,1554847749,"After failing to get tensorflow-gpu to install on my Eluktronics Clevo-based laptop, I realized the GeForce GTX 1070 Max-Q driver (418.96) may be the issue. It does not appear in the NVIDIA CUDA driver downloads. Has anyone gotten tensorflow-gpu to run on a MAX-Q??",13,2
42,2019-4-10,2019,4,10,8,bbesai,Could I use Tensorflow to solve this?,https://www.reddit.com/r/tensorflow/comments/bbesai/could_i_use_tensorflow_to_solve_this/,MaNcHaSsS,1554851510,"Hello,

I am completely new to Tensorflow and would like to know if it could help me speed up a task I have to do on a daily basis and finally start learning TF.

I get something between 60 to 80 daily reports consisting of about 80 words each. Most of them, not all, have some data I need. Not always written the same way but generally contains the same words and structure.

Report example A:

Gathered 35 kg of x fruit with 8 men and X tools

Example B:

Gathered with 10 men and Y tools 46 Kg of Z vegetables.

Example C:

Waiting for better climate to restart labor.

Not really the reports I get, but it gives the general idea.
Most reports have structure similar to A.

From this reports I need to pull the  X Kg of gathered fruit.

Would this be a good opportunity for me to get started on Tensorflow? Could you point me in the right direction?",3,1
43,2019-4-10,2019,4,10,20,bbkvf7,Python-Script for installing all dependencies needed for running inference on new PC,https://www.reddit.com/r/tensorflow/comments/bbkvf7/pythonscript_for_installing_all_dependencies/,2ringo,1554895630,"Hey guys,

in a current project I need to set up tensorflow to run inference on a new Windows system.

Since I want to give the possibility to my customer to set it up on other systems too without deeper knowledge of tensorflow and its needed dependencies, I was wondering if I could write a simple python-script, which installs all needed dependencies.

And if so, what would be the best way to install the dependencies? e.g. via pip, conda, etc. ?

I really appreciate your help!",6,2
44,2019-4-10,2019,4,10,23,bbmrf9,Tensorflow for playing board game optimally.,https://www.reddit.com/r/tensorflow/comments/bbmrf9/tensorflow_for_playing_board_game_optimally/,08np08,1554907010,"I'm curious if anyone has used tensorflow to play board games like Cantan, Ticket to ride, ECT optimally. I know it has been used for chess and go but I'm interested in games with more than two people.",4,2
45,2019-4-11,2019,4,11,12,bbv583,Where to find resources for learning low-level API in tensorflow 2.0,https://www.reddit.com/r/tensorflow/comments/bbv583/where_to_find_resources_for_learning_lowlevel_api/,Clap4jack12,1554951919,So Ive become pretty comfortable with high level APIs in tensor flow.  Does anyone know where I can find content for low level APIs?  Ideally this would be in,3,3
46,2019-4-11,2019,4,11,12,bbve2f,"[Question] Tensorflow object detection retraining, confidence score really low",https://www.reddit.com/r/tensorflow/comments/bbve2f/question_tensorflow_object_detection_retraining/,naboo_random,1554953562,"Hi, 

I am trying to retrain the tensorflow object detection model - faster r cnn ( pretrained on iNaturalist) data. However, after training for around 60k steps ( where the total loss stabilizes), if I run an evaluation the confidence scores of my detections are too low, of the order of e-5. 

&amp;#x200B;

The original model has around 2k classes. I'm training on 4 classes - almost equal distribution, with around 900 samples. The data augmentation option is ""random\_horizontal\_flip"".

&amp;#x200B;

Should I be increasing the number of samples I have? Maybe have more augmentation options?

&amp;#x200B;

Any help will be appreciated! Thanks!",3,1
47,2019-4-11,2019,4,11,16,bbx7bh,Source for pre-frozen tensorflow-graphs?,https://www.reddit.com/r/tensorflow/comments/bbx7bh/source_for_prefrozen_tensorflowgraphs/,goodiegoodgood,1554969438,"Hi everyone, 

I""m doing my BCS right now and starting to dip my toes into tensorflow. As the easter-holidays are right arround the corner I wanted to write some simple apps and use pre-frozen tensorflow models in order to get a ''feel'' for machine learning. 

Are there any sites where I can download simple prefrozen models (simple letter recignition, hotwordrecognition etc)?",2,2
48,2019-4-11,2019,4,11,18,bbxtpf,Meet No OpKernel error when loading tensorflow model to cpp.,https://www.reddit.com/r/tensorflow/comments/bbxtpf/meet_no_opkernel_error_when_loading_tensorflow/,xianf,1554975162,"Hi,guys.

I try to load my model to cpp, so I clone the tensorflow source code from github, and run the build\_all\_linux.sh to make tensorflow become a static lib.

And then, I try to use it to load my tensorflow model which is transformed from ckpt to a pb file.  I can create the session and ReadBinaryProto, but when I try to create the session with graph ,it fails and return this message:

&gt;Invalid argument: No OpKernel was registered to support Op 'Sin' with these attrs.  Registered devices: \[CPU\], Registered kernels:  
&gt;  
&gt;  &lt;no registered kernels&gt;  
&gt;  
&gt;  
&gt;  
&gt;\[\[{{node parallel\_0/rnnsearch\_0/add\_timing\_signal/Sin}} = Sin\[T=DT\_FLOAT, \_device=""/cpu:0""\](parallel\_0/rnnsearch\_0/add\_timing\_signal/mul\_2)\]\]

I can find the Sin op kernel in the math\_ops.cc from the source code of tensorflow, but it still return this error. I am struggling with this problem for a few days, anybody knows how to solve it?

Any help is appreciate! Thx!",0,1
49,2019-4-11,2019,4,11,21,bbzhda,TensorFlow 2.0 - Introductory Tutorial,https://www.reddit.com/r/tensorflow/comments/bbzhda/tensorflow_20_introductory_tutorial/,bhavesh91,1554986990,,1,41
50,2019-4-12,2019,4,12,0,bc1645,Reusing Variable Fails even in a new Graph,https://www.reddit.com/r/tensorflow/comments/bc1645/reusing_variable_fails_even_in_a_new_graph/,hassanzadeh,1554996272,"Hey Guys,

I'm experiencing something that I do not expect. I have created some variable before now I create a new Graph (by calling tf.Graph()), hence I should be allowed to define the same variable again but it fails saying that this variable is already defined. I know it was defined before but I'm creating new Graph, this is unexpected, can you tell why it complains? Here the code:

with tf.Graph().as\_default():

print(tf.get\_default\_graph().as\_graph\_def().node)

with tf.variable\_scope(""model\_test""):

t1 = tf.contrib.layers.fully\_connected(first\_annot\_tf, num\_features//5, activation\_fn=None, 

weights\_initializer=tf.contrib.layers.xavier\_initializer(), 

reuse=False, scope='wing\_layer1',

weights\_regularizer=tf.contrib.layers.l2\_regularizer(0.001))

t2 = tf.contrib.layers.fully\_connected(first\_annot\_tf, num\_features//5, activation\_fn=None, 

weights\_initializer=tf.contrib.layers.xavier\_initializer(), 

reuse=True, scope='wing\_layer1',

weights\_regularizer=tf.contrib.layers.l2\_regularizer(0.001))    

print(t1,t2,t1==t2)",0,1
51,2019-4-12,2019,4,12,0,bc1c41,Variable is not reused,https://www.reddit.com/r/tensorflow/comments/bc1c41/variable_is_not_reused/,hassanzadeh,1554997128,"Hey,

I'm trying to reuse a variable defined by  tf.contrib.layers.fully\_connected, but it looks like tf create new variable for each, do you know why?

&amp;#x200B;

with tf.Graph().as\_default() as graph:

with tf.variable\_scope(""model\_test""):

t1 = tf.contrib.layers.fully\_connected(first\_annot\_tf, num\_features//5, activation\_fn=None, 

weights\_initializer=tf.contrib.layers.xavier\_initializer(), 

reuse=False, scope='g3/wing\_layer1',

weights\_regularizer=tf.contrib.layers.l2\_regularizer(0.001))

t2 = tf.contrib.layers.fully\_connected(first\_annot\_tf, num\_features//5, activation\_fn=None, 

weights\_initializer=tf.contrib.layers.xavier\_initializer(), 

reuse=True,scope='g3/wing\_layer1',

weights\_regularizer=tf.contrib.layers.l2\_regularizer(0.001))",0,1
52,2019-4-12,2019,4,12,6,bc55ba,Using tensorflow.js to recognize credit card forms on html pages,https://www.reddit.com/r/tensorflow/comments/bc55ba/using_tensorflowjs_to_recognize_credit_card_forms/,BrownSol,1555016635,"Hi there,

&amp;#x200B;

I was wondering what the difficulty would be to recognize credit card forms on html pages in-browser using tensorflow.js. I'm trying to gauge how hard of a problem this would be to solve, and where one might begin. Ultimately the ideal scnario would be navigating to a page, checking/recognizing a credit card form on a page, and then returning the HTML DOM elements that are a part of the form.",1,1
53,2019-4-12,2019,4,12,8,bc6mrh,What is the difference between Inception_v3 (Slim) and Inception_V3,https://www.reddit.com/r/tensorflow/comments/bc6mrh/what_is_the_difference_between_inception_v3_slim/,KyleIsWinnin,1555024820,"Hi everyone,

I am getting a bit confused as to what it means to have a tensorflow slim model. I have already trained a model with two classes and am trying to use the [code provided by Google](https://github.com/tf-coreml/tf-coreml) to convert to coreml. There are specific models that can be used and almost all of them have (Slim) attached to it like [Inception v3 (Slim)](https://storage.googleapis.com/download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz). I know I can use a different config file to get me a trained Inception\_v3 model, but I am unsure if it would meet the requirement of Slim. Could anyone provide insight on what it means to be a (Slim) model? I know TF Slim exists as a less verbose version of TF but does it actually output a different type of model? If so is there any reading as to how to train a model using TFRecords in slim?",0,0
54,2019-4-12,2019,4,12,9,bc7hsc,"First project in Tensorflow.JS. Still a work in progress, but is pretty impressive for a first.",https://www.reddit.com/r/tensorflow/comments/bc7hsc/first_project_in_tensorflowjs_still_a_work_in/,MrPLotor,1555030102,,0,0
55,2019-4-13,2019,4,13,3,bchbue,Need some help building my first custom Keras convolution layer,https://www.reddit.com/r/tensorflow/comments/bchbue/need_some_help_building_my_first_custom_keras/,roset_ta,1555095229,"Hello,

I need to implement a Keras custom convolution layer, where there will be a kernel performing convolution (conv2d) on input image (linear kernel) and another one performing a non linear computation on the input image. 
The output function will be the sum of those two kernels results.

So far I have only used Keras for training models, but I have never built a custom layer before, so this is really new to me and I don't really understand how my weights will be updated.

I understand from Keras documentation that I need to initialize the two kernels in build function and then define call function, where I will implement the computations I mentioned . But how do I update the kernels? Do I need to extend Conv2d class, or Layer class?

I need some advice to get started. Any example always appreciated. Thank you guys",5,1
56,2019-4-13,2019,4,13,6,bcjbn7,Visualizing Tensorflow networks,https://www.reddit.com/r/tensorflow/comments/bcjbn7/visualizing_tensorflow_networks/,Radeusgd,1555105867,"Hi! I'm working on Tensorflow bindings for Luna (http://luna-lang.org/). 

We allow you to build ML models by connecting visual components together  every component can define a new network layer and its dependencies. The API is highly inspired by Keras functional API.

[Here you can find an example of what it looks like](https://imgur.com/a/rmcZiZv)

Luna has the ability to display visualizations below its components, so you could inspect the look of your network on each step (after adding the first layer, adding the second layer, etc). We want to provide interactive visualizations of the network you've built so far. I'd love to ask you what visualizations you would find the most helpful during building neural networks? 

We were initially thinking about something [like that](http://www.mghpcc.org/neural-networks-earthquakes/neuralnetworkforhelen/)  so you could see the structure of your network, the weights and activation functions, but we are very open for discussion here. We want to create something that would be helpful while building various kinds of networks.

Which features do you think are most important to visualize? The weights? The activations on each layer? Something else entirely?",5,14
57,2019-4-13,2019,4,13,8,bck4r5,Machine Learning with TensorFlow and PyTorch on Apache Hadoop using Cloud Dataproc,https://www.reddit.com/r/tensorflow/comments/bck4r5/machine_learning_with_tensorflow_and_pytorch_on/,_spicyramen,1555110495,,0,1
58,2019-4-13,2019,4,13,9,bcl5ke,Help with custom training loops in tensorflow 2.0 / tf.Keras,https://www.reddit.com/r/tensorflow/comments/bcl5ke/help_with_custom_training_loops_in_tensorflow_20/,venktech,1555117004,"I m writing a custom training loop in tf 2.0 as I have multiple complex set of inputs and custom loss function computations. I followed the procedure of custom model creation by extending the keras Model class and calling it within the tf.GradientTape scope. ([from here](https://www.tensorflow.org/alpha/guide/keras/training_and_evaluation)) I could get the gradients for the weights but I get a warning that gradients are not available for the bias terms. I tried initializing the layers with bias\_initializer and also tried passed training=True but doesn't work. . I also tried model.compile() but I don't think it has to be called for custom training loops. Can someone experienced in TF2 please help me out if I m missing out something

The exact error is,

W0412 02:56:32.653809 140529035499264 optimizer\_v2.py:928\] Gradients does not exist for variables \['assoc\_model/conv1\_bbox/bias:0', 'assoc\_model/dense/bias:0', 'assoc\_model/dense\_1/bias:0', 'assoc\_model/batch\_normalization\_v2/gamma:0', 'assoc\_model/batch\_normalization\_v2/beta:0', 'assoc\_model/conv2d/bias:0', 'assoc\_model/dense\_2/bias:0', 'assoc\_model/dense\_3/bias:0', 'assoc\_model/batch\_normalization\_v2\_1/gamma:0', 'assoc\_model/batch\_normalization\_v2\_1/beta:0', 'assoc\_model/dense\_4/bias:0', 'assoc\_model/conv2d\_1/bias:0', 'assoc\_model/conv2d\_2/bias:0'\] when minimizing the loss.",3,2
59,2019-4-13,2019,4,13,20,bcpkh6,Reconstruction loss on regression type of Variational Autoencoder,https://www.reddit.com/r/tensorflow/comments/bcpkh6/reconstruction_loss_on_regression_type_of/,pangs4m,1555154927,"I'm currently working on a variation of Variational Autoencoder in a sequential setting, where the task is to fit/recover a sequence of real-valued observation data (hence it is a regression problem). 

&amp;#x200B;

I have built my model using \`tf.keras\` with eager execution enabled, and tensorflow\_probability (tfp). Following VAE concept, the generative net emits the distribution parameters of the observation data, which I model as multivariate normal. Therefore the outputs are mean and logvar of the predicted distribution. 

&amp;#x200B;

Regarding training process, the first component of the loss is reconstruction error. That is the log likelihood of the true observation, given the predicted (parameters) distribution from the generative net. Here, I use \`tfp.distributions\`, since it is fast and handy. 

&amp;#x200B;

However, after training is done, marked by a considerably low loss value, it turns out that my model seems not to learn anything. The predicted value from the model is just barely flat across the time dimension (recall that the problem is sequential).

&amp;#x200B;

Nevertheless, for the sake of sanity check, when I \*\*replace log likelihood with MSE loss\*\* (which is not justifiable while working on VAE), it yields very good data fitting. So I conclude that there must be something wrong with this log likelihood term. Is there anyone having some clue and/or solution for this?

&amp;#x200B;

I have considered replacing the log likelihood with cross-entropy loss, but I think that is not applicable in my case, since my problem is regression and the data can't be normalized into \[0,1\] range.

&amp;#x200B;

I also have tried to implement annealed KL term (i.e. weighing the KL term with constant &lt; 1) when using the log likelihood as the reconstruction loss. But it also didn't work.

&amp;#x200B;

Here is my code snippet of the original (using log likelihood as reconstruction error) loss function:

&amp;#x200B;

`import tensorflow as tf`

`tfe = tf.contrib.eager`

`tf.enable_eager_execution()`



`import tensorflow_probability as tfp`

`tfd = tfp.distributions`



`def loss(model, inputs):`

`outputs, _ = SSM_model(model, inputs)`



`#allocate the corresponding output component`

`infer_mean = outputs[:,:,:latent_dim]  #mean of latent variable from  inference net`

`infer_logvar = outputs[:,:,latent_dim : (2 * latent_dim)]`

`trans_mean = outputs[:,:,(2 * latent_dim):(3 * latent_dim)] #mean of latent variable from transition net`

`trans_logvar = outputs[:,:, (3 * latent_dim):(4 * latent_dim)]`

`obs_mean = outputs[:,:,(4 * latent_dim):((4 * latent_dim) + output_obs_dim)] #mean of observation from  generative net`

`obs_logvar = outputs[:,:,((4 * latent_dim) + output_obs_dim):]`

`target = inputs[:,:,2:4]`



`#transform logvar to std`

`infer_std = tf.sqrt(tf.exp(infer_logvar))`

`trans_std = tf.sqrt(tf.exp(trans_logvar))`

`obs_std = tf.sqrt(tf.exp(obs_logvar))`



`#computing loss at each time step`

`time_step_loss = []`

`for i in range(tf.shape(outputs)[0].numpy()):`

`#distribution of each module`

`infer_dist = tfd.MultivariateNormalDiag(infer_mean[i],infer_std[i])`

`trans_dist = tfd.MultivariateNormalDiag(trans_mean[i],trans_std[i])`

`obs_dist = tfd.MultivariateNormalDiag(obs_mean[i],obs_std[i])`



`#log likelihood of observation`

`likelihood = obs_dist.prob(target[i]) #shape = 1D = batch_size`

`likelihood = tf.clip_by_value(likelihood, 1e-37, 1)`

`log_likelihood = tf.log(likelihood)`



`#KL of (q|p)`

`kl = tfd.kl_divergence(infer_dist, trans_dist) #shape = batch_size`



`#the loss`

`loss = - log_likelihood + kl`

`time_step_loss.append(loss)`



`time_step_loss = tf.convert_to_tensor(time_step_loss)`        

`overall_loss = tf.reduce_sum(time_step_loss)`

`overall_loss = tf.cast(overall_loss, dtype='float32')`



`return overall_loss`",0,1
60,2019-4-14,2019,4,14,1,bcs9qm,Agent Simulation in Tensorflow,https://www.reddit.com/r/tensorflow/comments/bcs9qm/agent_simulation_in_tensorflow/,mkal001,1555172939,"Hello devs
I am trying to simulate open AI gym environment in Google colab but it's not working . so does the tensor flow 2.0 has anything like open AI gym to simulate agents ?",2,4
61,2019-4-14,2019,4,14,9,bcxge1,Get started with TensorFlow's High-Level APIs,https://www.reddit.com/r/tensorflow/comments/bcxge1/get_started_with_tensorflows_highlevel_apis/,GeraldNwakpu,1555203190,[https://www.youtube.com/watch?v=4mBbAq5clzw](https://www.youtube.com/watch?v=4mBbAq5clzw),1,10
62,2019-4-14,2019,4,14,22,bd2miu,Updates from Coral: A new compiler and much more. No longer restricted to certain TF Lite models,https://www.reddit.com/r/tensorflow/comments/bd2miu/updates_from_coral_a_new_compiler_and_much_more/,bartturner,1555247700,,1,10
63,2019-4-15,2019,4,15,5,bd77fj,1 How Convolutional Neural Networks Work: An Intuitive Approach,https://www.reddit.com/r/tensorflow/comments/bd77fj/1_how_convolutional_neural_networks_work_an/,ailearn12,1555273877,,1,12
64,2019-4-15,2019,4,15,20,bdewrm,Data Engineering Conference in Europe 2019,https://www.reddit.com/r/tensorflow/comments/bdewrm/data_engineering_conference_in_europe_2019/,thiagoavadore,1555328076,"Hey!

I am organizing a conference in Amsterdam on October 30th. One of the tracks is in my area, **Data Engineering**, and we will have **Holden Karau** hosting it... our [Call for Papers is open](https://sessionize.com/itnext-summit-2019/), so I decided to share here! Come to lovely Amsterdam to LEARN. SHARE. CONNECT. on the [ITNEXT Summit 2019](https://www.itnextsummit.com/)!

&amp;#x200B;

I know plenty of `tensorflow` enthusiasts have something to share! :-)",0,2
65,2019-4-15,2019,4,15,22,bdfvsf,Identifying dog breed with neural networks: from Keras to TensorFlow Android app,https://www.reddit.com/r/tensorflow/comments/bdfvsf/identifying_dog_breed_with_neural_networks_from/,atomlib_com,1555334335,,2,23
66,2019-4-15,2019,4,15,22,bdg81m,Why tf.map_fn is so slow? Any best practice?,https://www.reddit.com/r/tensorflow/comments/bdg81m/why_tfmap_fn_is_so_slow_any_best_practice/,AlexanderYau,1555336348,tf.map\_fn is so slow when using self-defined loss function to compute the loss.,7,2
67,2019-4-15,2019,4,15,22,bdg8rq,Cosine similarity between last hidden state and each embedding vector,https://www.reddit.com/r/tensorflow/comments/bdg8rq/cosine_similarity_between_last_hidden_state_and/,yeahalrightbroguy,1555336461,"Hi all

I've been trying to implement the paper [Neural Attention Models for Sequence Classification: Analysis and Application to Key Term Extraction and Dialogue Act Detection](https://arxiv.org/abs/1604.00077) but am struggling to work out how to generate the required cosinesimilarity between context vector and embedding vectors as shown [here](https://i.vgy.me/kXhcnh.jpg). 

I've been able to achieve the desired calculation in a for loop by manually calculating the distance for each word vector for each batch, but I get issues when computing the gradients in eager mode or trying to fit the model with model.fit.

I would really appreciate any advice or hear if others have tried anything similar.

Thanks legends.",0,1
68,2019-4-16,2019,4,16,5,bdktcu,Recurrent Neural Networks: Algorithms and Applications,https://www.reddit.com/r/tensorflow/comments/bdktcu/recurrent_neural_networks_algorithms_and/,ailearn12,1555359026,,0,0
69,2019-4-16,2019,4,16,5,bdkvqj,Developing a Robust Face Generative Adversarial Network with Tensorflow,https://www.reddit.com/r/tensorflow/comments/bdkvqj/developing_a_robust_face_generative_adversarial/,ailearn12,1555359361,,0,1
70,2019-4-16,2019,4,16,18,bdruvi,Using TfRecords to feed my model,https://www.reddit.com/r/tensorflow/comments/bdruvi/using_tfrecords_to_feed_my_model/,Basylisk,1555406729,"Hello, I have started to use Tensorflow for a school project and through the various tutorials available I have more or less a grip of whats going on in a neural network. My goal is to benchmark different models for the project.

Now, I am trying to build my own image classifier, with my own datas. I am using Google Collab (GPU acceleration and 12GB or RAM) as my own PC isnt powerful enough to handle my data.

Here's my situation :

* I have 15000 images 256\*256 of training data and around 2000 256\*256 of testing data.
* Those images are organized in a main folder containing 2 foders (Train, Valiadtion), and each of them have a subfolder for each class (I have two classes ""2"" and ""3"" - those are not and written digits data-).

&amp;#x200B;

My first approach was to load my training data in a numpy array do some rescaling operations (rgb2gray). Then I would do :

(original shape is 256,256,3, aim is 256,256,1)

&gt;training\_data = training\_data / 255.0

which apparently is commonly done (MNIST tutorial). This would be okay when I was working with samples of data (500 images), but now (15000images) it just overload the RAM and crash my environment.

&amp;#x200B;

My second approach is to use tfRecords. I successfully splited my training data in 2 tfRecords files. But now I can't find a reliable source about how to feed them into my model.

I have tried to parse them into Tensorflow Datasets, but then I cant find how to use those datasets...

&amp;#x200B;

So my questions are :

* Can you link me to a proper example of feeding tfRecords into my model ?
* Is it possible to rework my model to accept 256,256,3 ? I have tried to change the input\_shape of the first layer, but then the accuracy would be 0)

&amp;#x200B;

Here is some models that I have tried :

&gt;model = keras.models.Sequential()  
&gt;  
&gt;model.add(keras.layers.Flatten(input\_shape=(256,256)))  
&gt;  
&gt;model.add(keras.layers.BatchNormalization())  
&gt;  
&gt;model.add(keras.layers.Dense(2, W\_regularizer=keras.regularizers.l2(0.02)))  
&gt;  
&gt;model.add(keras.layers.BatchNormalization())  
&gt;  
&gt;model.add(keras.layers.Activation('softmax'))  
&gt;  
&gt;  
&gt;  
&gt;model.compile(keras.optimizers.Adam(lr=1e-5),  
&gt;  
&gt;loss = 'sparse\_categorical\_crossentropy',  
&gt;  
&gt;metrics=\['accuracy'\])

&amp;#x200B;

&gt;model = keras.models.Sequential()  
&gt;  
&gt;model.add(keras.layers.Flatten(input\_shape=(256,256)))  
&gt;  
&gt;model.add(keras.layers.Dense(128, activation='relu'))  
&gt;  
&gt;model.add(keras.layers.Dense(2, activation='softmax'))  
&gt;  
&gt;model.compile(keras.optimizers.Adam(lr=1e-5), loss ='sparse\_categorical\_crossentropy', metrics=\['accuracy'\])

&amp;#x200B;

&gt;model = tf.keras.Sequential(\[  
&gt;  
&gt;tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu,  
&gt;  
&gt;input\_shape=(1, 256, 256), data\_format='channels\_first'),  
&gt;  
&gt;tf.keras.layers.MaxPooling2D((2, 2), strides=2),  
&gt;  
&gt;tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu),  
&gt;  
&gt;tf.keras.layers.MaxPooling2D((2, 2), strides=2),  
&gt;  
&gt;tf.keras.layers.Flatten(),  
&gt;  
&gt;tf.keras.layers.Dense(128, activation=tf.nn.relu),  
&gt;  
&gt;tf.keras.layers.Dense(2,  activation=tf.nn.softmax)  
&gt;  
&gt;\])  
&gt;  
&gt;model.compile(optimizer='adam', loss ='sparse\_categorical\_crossentropy', metrics=\['accuracy'\])

&amp;#x200B;

&amp;#x200B;

This was a bit longer than expected, thanks to everyone who will take their time to read it.",2,5
71,2019-4-17,2019,4,17,4,bdy5ic,Google Coral Edge TPU vs NVIDIA Jetson Nano: A quick deep dive into EdgeAI performance,https://www.reddit.com/r/tensorflow/comments/bdy5ic/google_coral_edge_tpu_vs_nvidia_jetson_nano_a/,bartturner,1555443292,,12,18
72,2019-4-17,2019,4,17,20,be6lxx,How do I keep existing classifications when doing transfer learning?,https://www.reddit.com/r/tensorflow/comments/be6lxx/how_do_i_keep_existing_classifications_when_doing/,josh2k44,1555500221,"I just started using TensorFlow and doing transfer learning. I'm using MobileNet as a base model, and training my own datasets. However, with all the tutorials I have found, the predictions are restricted to the 'new' classifications. So for example, if I train a range of flowers, I cannot see predictions for cars, pens, bikes, etc. which I would be able to see on the MobileNet model.

&amp;#x200B;

How do I merge my dataset training model with the ImageNet model as a base and create a new set of labels with both classifications?",4,2
73,2019-4-17,2019,4,17,20,be6vdl,Potentially silly question: Does having a GPU speed up training FC layers?,https://www.reddit.com/r/tensorflow/comments/be6vdl/potentially_silly_question_does_having_a_gpu/,cdf-giant,1555502099,"I have a pre-trained CNN frontend that doesn't need to be trained anymore, and I am interested in putting a 1000 unit FC layer followed by a logits layer after it (20 classes). According to my intuition, this would train just as fast on my macbook as compared to my office's workstation (2x1080ti). Is this correct?",1,1
74,2019-4-17,2019,4,17,22,be7lfh,Build a Simple Neural Network with TensorFlow 2.0 in Google Colab,https://www.reddit.com/r/tensorflow/comments/be7lfh/build_a_simple_neural_network_with_tensorflow_20/,bhavesh91,1555506460,,0,26
75,2019-4-17,2019,4,17,23,be8awv,GPU Decisions with not much money,https://www.reddit.com/r/tensorflow/comments/be8awv/gpu_decisions_with_not_much_money/,starbucksresident,1555510464,"Ok, I am (think VERY) poor... so for most of my work I use a floydhub remote K80 (cheap) or Google TPU's (v2 preempted) which are also cheap, but now I need a local GPU to train small (think ResNet50 size in small batches).

&amp;#x200B;

My PC (a decade old Workstation, Dell T5400/16GB Dual Xeon) can only handle 225W max for the GPU card (2x6 pin = 150W + 75W via PCI) so I am limited in cheaper older fast cards, otherwise, I'd buy that cheap $80 (CC3) GTX 690 beast ... (but it's 300W), my impression is the GTX 690 could even give the 1060 a run for its money.

&amp;#x200B;

I narrowed my choice down to (UK prices in USD, things not cheap here):

&amp;#x200B;

GTX 1060/3 $160

GTX 970/4  $130

GTX 780 Ti/4  $125

&amp;#x200B;

They seem to perform about the same, and all are at least CC3.5 so no tf build from scratch, which given the state of bazel I'd like to avoid.

Any reason one is far better than the other, yes 1060 is newer,  likely less used, lower power, but 3GB, not 4GB, the other two computationally seem about the same as the 1060 (perhaps 10% difference).  

They all come with a year warranty if they fail.

Thanks!",5,2
76,2019-4-18,2019,4,18,6,bedbps,Help building a new tensor,https://www.reddit.com/r/tensorflow/comments/bedbps/help_building_a_new_tensor/,venktech,1555536713,"Hi.. I have a requirement to create a new tensor with shape say \[1,25600,1,num\_targets\].. The tensor should be initialized to zeros and I need to assign a value (computed from two similar tensors a and b with different feature values) on certain locations x and y of the spatial and channel dimensions. I have a loop with indices for these two dimensions where I will set the value but I cannot have the assignment in a loop because assignments are not supported in tensors. Can someone give me some ideas on how I could approach this problem.. 

&amp;#x200B;

More info: 

The two feature tensors a and b have shapes a: \[1(batch), 512(features) ,1 (dummy) ,num\_targets(channels) \]   b:\[1 (batch),25600 (spatial location in 1D array) ,512 (features) ,1 (channels)\]",0,1
77,2019-4-18,2019,4,18,17,bej1fl,Question about Dimension error.,https://www.reddit.com/r/tensorflow/comments/bej1fl/question_about_dimension_error/,AnEccentricScientist,1555575471,"While converting Tensorflow model Inception to Intel movidius NCS graph it gives an error of Nonetype. 

From our understanding this stems from the fact that dimension 1 of tensors should be 1 for movidius and non Nonetype but how should we change this in code if this is the reason ?",0,1
78,2019-4-18,2019,4,18,18,bejmgw,Start with tensorflow or tensorflow 2.0?,https://www.reddit.com/r/tensorflow/comments/bejmgw/start_with_tensorflow_or_tensorflow_20/,eligejjjj,1555580777,"Hi!! I am a beginner in programming (learning python) and I am very interested on AI area. I watched some videos about tensorflow and just realize that already exist tensorflow 2.0. So,  what should I start with? Someone have recommendations of free courses to start?",20,13
79,2019-4-18,2019,4,18,21,bekqfr,TensorFlow Cheat Sheet,https://www.reddit.com/r/tensorflow/comments/bekqfr/tensorflow_cheat_sheet/,ValVish,1555589120,,0,0
80,2019-4-19,2019,4,19,0,bemx9w,Error when calculating losses differently for different output nodes (indexing tensors and adding up losses in a for loop),https://www.reddit.com/r/tensorflow/comments/bemx9w/error_when_calculating_losses_differently_for/,justAHairyMeatBag,1555601481,"I'm using the tf.Keras for a multi-label classification task and I have a custom loss function that requires me to use binary cross entropy (bce) on different output nodes.

If I have y_true = [1,0,1,1,0] and y_pred = [1,0,1,0,1], bce would be calculated as **loss = -((y_true * K.log(y_pred)) + ((1 - y_true) * K.log(1 - y_pred)))**.

In my case, I want to calculate bce as **loss = - some_variable * ((y_true[some_indices] * K.log(y_pred[[some_indices]])) + ((1 - y_true[[some_indices]]) * K.log(1 - y_pred[[some_indices]])))** for a list of different indices. Basically, if I have 10 output nodes, I want to calculate bce losses for nodes [0,1,2], [3,5,7], [4,6,8,9].

        for l, indices in enumerate(2d_list_of_indices):
            loss += -some_variable[l] * ((K.gather(y_true, indices) * K.log(K.gather(y_pred, indices))) + ((1 - K.gather(y_true, indices)) * K.log(1 - K.gather(y_pred, indices))))


But this throws the following error:

    ValueError: Dimensions must be equal, but are 2 and 4 for 'loss/dense_1_loss/add_5' (op: 'Add') with input shapes: [2,4042], [4,4042].


I'm not sure what to do to get this to work. Could someone help me figure out what I'm doing wrong?",0,1
81,2019-4-19,2019,4,19,0,ben51x,Help Required: Sharing Variable across multi level scopes,https://www.reddit.com/r/tensorflow/comments/ben51x/help_required_sharing_variable_across_multi_level/,schrodingershit,1555602613,,0,1
82,2019-4-20,2019,4,20,1,bf1hc3,Radeon VII vs RTX 2080TI for ML? Which to choose...,https://www.reddit.com/r/tensorflow/comments/bf1hc3/radeon_vii_vs_rtx_2080ti_for_ml_which_to_choose/,protechig,1555693158,"I'm looking to upgrade my GPU on my computer and would like to know how a 2080TI compares to a Radeon VII from a TensorFlow perspective? I currently have a GTX 1080 which is more than powerful enough for what I do (meaning I play a simple video game maybe once a week), but I know there are better options for ML. I can't really find any benchmarks of the two cards side-by-side. I know the Radeon VII is slower than the RTX but is \~$500 cheaper and has 16GB of HBM memory vs 11GB of GDDR. 

&amp;#x200B;

Does anyone have some real-world experience comparing these cards?",14,3
83,2019-4-20,2019,4,20,7,bf58kp,Comparing audio files,https://www.reddit.com/r/tensorflow/comments/bf58kp/comparing_audio_files/,MissValeska,1555713072,"Is it possible to make an AI that can compare any two speech audio files together and identify if they are equivalent, e.g, contain the same general message? I know that you can train an AI to compare any audio file to a specific set of categories, but is that all? I would like to give it a source speech audio file and then another recorded by someone else and see if they're saying the same thing as a binary thing or even percentage thing.",4,8
84,2019-4-20,2019,4,20,18,bfanrl,How can I make my own convolution operation in tf?,https://www.reddit.com/r/tensorflow/comments/bfanrl/how_can_i_make_my_own_convolution_operation_in_tf/,roset_ta,1555754349,"Hello,

Where can I find the source code of TensorFlow where the tf.nn.conv2d is executed? Specifically I'm looking for the part where the kernel is sliding with respect to the strides. 


I want to implement the function y(x) = (xT * W * x) + b, as a custom convolution operation,  where:

xT is an image patch of shape (n,n) reshaped as a vector (1,n^2)
W is a matrix of weights with shape (n^2,n^2)
x is the image patch again, reshaped as (n^2,1)
b is the bias

So the result would be a matrix with the sums of the convolution of the kernel on every (n,n) image patch.

Thank you",7,2
85,2019-4-21,2019,4,21,0,bfdmfm,How to find input and output tensors for my neural network?,https://www.reddit.com/r/tensorflow/comments/bfdmfm/how_to_find_input_and_output_tensors_for_my/,jimmothytheunicorn,1555775546,"Where would this be found. Its an inception graph, 42 layer convolutional. Where are the input output tensors?",3,2
86,2019-4-21,2019,4,21,3,bffm3r,TensorFlow World call for proposals ends Apr 23,https://www.reddit.com/r/tensorflow/comments/bffm3r/tensorflow_world_call_for_proposals_ends_apr_23/,ewilderj,1555786066,"Hey folks, the [TensorFlow World](https://conferences.oreilly.com/tensorflow/tf-ca) conference will be held by O'Reilly Media, in Santa Clara, CA, USA, this October 28-31, and we're seeking talk proposals from practitioners.  Please consider [submitting a proposal](https://conferences.oreilly.com/tensorflow/tf-ca/public/cfp/732) highlighting your work.",1,2
87,2019-4-21,2019,4,21,5,bfgsk5,This video goes over a breast cancer diagnosis model that uses neural networks. Really interesting,https://www.reddit.com/r/tensorflow/comments/bfgsk5/this_video_goes_over_a_breast_cancer_diagnosis/,antaloaalonso,1555792630,,0,23
88,2019-4-21,2019,4,21,15,bfm3py,Programming language for tensorflow,https://www.reddit.com/r/tensorflow/comments/bfm3py/programming_language_for_tensorflow/,itsmevikash,1555828773,Which Language is good for beginners on tensorflow,2,1
89,2019-4-22,2019,4,22,0,bfptof,Major training slowdown after moving from TF 1.13 to TF 2.0,https://www.reddit.com/r/tensorflow/comments/bfptof/major_training_slowdown_after_moving_from_tf_113/,SupportVectorMachine,1555859697,"I recently made the switch from 1.13 to 2.0a on both my home and office computers (Ubuntu 18.04 with Nvidia GTX 1080 Ti GPUs). I've noticed on both machines that the same models, same data, and same batch sizes run over ten times slower in 2.0.

A couple of stray points:

* I had previously primarily used Keras (standalone with TensorFlow backend) for rapid sandboxing of ideas, and I now use tensorflow.keras in its place. 
* I've tested with eager execution both enabled and disabled with no noticeable difference.

Has anyone else had a similar experience? Anything obvious I'm missing?

(As this is a general issue as of to a specific error, sharing code doesn't seem all that useful here.)",5,9
90,2019-4-22,2019,4,22,4,bfsqur,Tensorflow object_detection_tutorial error,https://www.reddit.com/r/tensorflow/comments/bfsqur/tensorflow_object_detection_tutorial_error/,_dark_light_,1555875832,"Using this tutorial 

https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10#6-run-the-training

I've done everything to get tensorflow to run but when I get to the final test at part 2g I get the following error: ModuleNotFoundError: No module named 'tensorflow'

I don't understand how i can get this issue. Any insight to solving this would be greatly appreciated.

https://imgur.com/a/cD5QJET",1,2
91,2019-4-22,2019,4,22,20,bg0xes,TensorFlow 2.0 Cheat Sheet,https://www.reddit.com/r/tensorflow/comments/bg0xes/tensorflow_20_cheat_sheet/,__Tia__,1555932226,"Hi guys, 

Here is a TensorFlow cheat sheet you may found useful [https://www.altoros.com/visuals/tensorflow-cheat-sheet](https://www.altoros.com/visuals/tensorflow-cheat-sheet/?utm_campaign=ai_training_smm_organic&amp;utm_source=reddit&amp;utm_medium=social). 

I'm also looking for any other papers with quick code samples. I would be very grateful if you could share some in comments. Thanks!",6,0
92,2019-4-22,2019,4,22,23,bg2rte,Trained tensorflow model moved to another directory cannot be loaded,https://www.reddit.com/r/tensorflow/comments/bg2rte/trained_tensorflow_model_moved_to_another/,atinesh229,1555943480,"I have trained a `tensorflow` model and moved the trained model files (`checkpoint`, `model.data-00000-of-00001`, `model.index`, `model.meta`) to another directory, Now if I try to load the model I get this error

    ValueError: Can't load save_path when it is None.

If I load the model without moving it to another directory it works fine. I looked at this [post](https://stackoverflow.com/questions/50391464/load-tensorflow-model-from-moved-directory) but it didn't work

&amp;#x200B;

**Code**

    import tensorflow as tf
    sess = tf.Session()
    tf_saver = tf.train.import_meta_graph('model/model.meta')
    tf_saver.restore(sess, tf.train.latest_checkpoint('model'))",5,1
93,2019-4-23,2019,4,23,1,bg4cos,How to keep kernel tensor to a specific form during backpropagation?,https://www.reddit.com/r/tensorflow/comments/bg4cos/how_to_keep_kernel_tensor_to_a_specific_form/,roset_ta,1555951756,"Hello, 

I'm implementing a custom Keras layer, where I need my kernel to be in an upper triangular form.

So far, I have randomly initialized the kernel in `tf.add_weight' and then transformed it to an upper triangular form using `tf.matrix_band_part`.

But how can I be sure that it will stay that way during backpropagation? Do I need to create a custom kernel constraint? Or TensorFlow will keep it in that form? Thanks!",6,3
94,2019-4-23,2019,4,23,5,bg783p,"Could someone please look at my code, which tries to classify a movie as positive or negative based on the IMDB dataset. I get 88% accuracy on the test data, but I feel like I am missing something.",https://www.reddit.com/r/tensorflow/comments/bg783p/could_someone_please_look_at_my_code_which_tries/,AnhedonicHermit,1555966262,"This is one of the introductory tasks for learning keras, more details available here: https://www.tensorflow.org/tutorials/keras/basic_text_classification. It uses the IMDB  dataset which is preloaded in keras.

My code is here: https://pastebin.com/grYPfmNB

I tried different combination of hidden layers and neurons in each layer, but the performance I get from no hidden layers and 1 epoch is as good as any other combination. This cannot be right. Please look over my code and tell me what I am doing wrong.",7,5
95,2019-4-23,2019,4,23,16,bgdoef,Dummy variable tensorflow,https://www.reddit.com/r/tensorflow/comments/bgdoef/dummy_variable_tensorflow/,nothingveryserious,1556005960,"Dear all,

I am new to tensorflow. I have a series of dummy variables in my data frame. That is several columns of ones and zeroes.

When constructing my graph, what is the appropriate method to classify these cases?

tf.feature_column.categorical_column_with_identity(col, num_buckets=2))",0,1
96,2019-4-23,2019,4,23,20,bgf87t,Tensorflow Dual GPU usage - effective power?,https://www.reddit.com/r/tensorflow/comments/bgf87t/tensorflow_dual_gpu_usage_effective_power/,starbucksresident,1556018795,"&amp;#x200B;

[The Single underpowered MSI GTX 760 4GB Twin Frozr](https://i.redd.it/44fgnx0hzzt21.jpg)

&amp;#x200B;

So, the effective power is likely around 50% of a 1060 (or so the benchmarks tell me, likely way off and much more underpowered)  - *however*  \- if I add a second card (from the 7 series, so same driver and can co-exist)  will I achieve roughly 1060 performance *and* 8GB? I am hoping it may be not really as good, but still close?

&amp;#x200B;

By the way the machine is an old Dell 5400 (2007) with E5430 Xeon and 16GB - as such (and with the CC 3.0 of the card) I managed to build Tensorflow 1.13 with no  SSE4/AVX instructions *and* CC 3.0 (took around 7 hrs to build on this old machine) and it works fine.

So, if you have ancient equipment you can still run the latest 1.13 in GPU mode. 

&amp;#x200B;

I will post here (community wheels) later today:

[TensorFlow 1.13, GPU (CC 3.0) (CUDA 10.0, cuDNN 7.4), Without SSE4/AVX, Python 3.6, Ubuntu 18.04](https://github.com/yaroslavvb/tensorflow-community-wheels/issues/107)",2,2
97,2019-4-24,2019,4,24,0,bghilt,How to use Tensorflow to compute per-sample gradient and reduce them with an arbitrary function?,https://www.reddit.com/r/tensorflow/comments/bghilt/how_to_use_tensorflow_to_compute_persample/,nnet--,1556032322,,0,1
98,2019-4-24,2019,4,24,0,bghvy9,Exporting to a keras tf 2.0 model to c++,https://www.reddit.com/r/tensorflow/comments/bghvy9/exporting_to_a_keras_tf_20_model_to_c/,Envenger,1556034221," 

I have trained a keras tensorflow model in python I want to export the model in some manner and make it run in c++.  
I  am getting multiple ways and doing it and I don't know which is the  current method of doing it as most of the posts I see are a few years  old and the processes are very different from each other.

What should I follow for what I am looking to achieve.

[https://www.tensorflow.org/tfx/serving/serving\_basic](https://www.tensorflow.org/tfx/serving/serving_basic)  
[https://medium.com/@hamedmp/exporting-trained-tensorflow-models-to-c-the-right-way-cf24b609d183](https://medium.com/@hamedmp/exporting-trained-tensorflow-models-to-c-the-right-way-cf24b609d183)",2,2
99,2019-4-24,2019,4,24,6,bglqtc,"TensorFlow, PyTorch or MXNet? A comprehensive evaluation on NLP &amp; CV tasks with Titan RTX",https://www.reddit.com/r/tensorflow/comments/bglqtc/tensorflow_pytorch_or_mxnet_a_comprehensive/,gwen0927,1556053691,,1,18
100,2019-4-24,2019,4,24,14,bgqu49,How do tf.nn.conv2d create more feature map by small amount of filters?,https://www.reddit.com/r/tensorflow/comments/bgqu49/how_do_tfnnconv2d_create_more_feature_map_by/,Laurence-Lin,1556083730,"In LeNet, the second convolution layer have 6 filters, and wanted to create 16 feature maps by combining several output of feature maps from these 6 filters(3, 4, 5 feature map), and by combination we get total 16 feature maps. 

Does the tf.nn.conv2d(in\_channel, out\_channel) do the combination automatically? 

If I have in\_channels = 6 for previous layer output, out\_channel = 16 for current feature maps output, then will it combine different pair of feature maps within this function?",1,1
101,2019-4-24,2019,4,24,15,bgrf00,How could I create a edge filter for practice?,https://www.reddit.com/r/tensorflow/comments/bgrf00/how_could_i_create_a_edge_filter_for_practice/,Laurence-Lin,1556088333,"I would like to do edge detection(or other convolution that could show the effect on an image), and I create a filter by tf.constant by myself, which is 3\*3 size. However, in the tf.nn.conv2d(input, filter) function, filter parameters take in size of \[height, width, in\_channel, out\_channel\] that has rank4 as the filter's size. How could I create an filter by myself that could test the effect of convolution on an image? I don't want to do by tf.truncate\_normal, the output of convolution is strange and meaningless.  


Thanks a lot!",2,1
102,2019-4-24,2019,4,24,18,bgsdy8,How to feed Tensor to feed_dict?,https://www.reddit.com/r/tensorflow/comments/bgsdy8/how_to_feed_tensor_to_feed_dict/,dcopz,1556096875,"I just knowing that I cannot feed Tensor to feed_dict. any idea?

TypeError: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles",5,1
103,2019-4-24,2019,4,24,20,bgt9ks,Can I use the TensorFlow Object Detection API for semantic/panoptic segmentation?,https://www.reddit.com/r/tensorflow/comments/bgt9ks/can_i_use_the_tensorflow_object_detection_api_for/,EmielBoss,1556104069,"I wish to implement [Panoptic FPN](https://arxiv.org/abs/1901.02446) (which adds an extra branch to Mask R-CNN for semantic segmentation) using TensorFlow, and use pre-trained models for its ResNet-FPN backbone. However, I am add a crossroads: do I use TensorFlow's Keras API, or the [TensorFlow Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection)? Is the latter even capable of semantic segmentation? What do you recommend?",0,1
104,2019-4-25,2019,4,25,1,bgwru9,importing barcode dataset for training purpose,https://www.reddit.com/r/tensorflow/comments/bgwru9/importing_barcode_dataset_for_training_purpose/,mkal001,1556123625,"&amp;#x200B;

I have a dataset of barcode images in which each image barcode.jpg has a corresponding text file barcode.jpg.txt containing the unique number of that barcode. Does there exist any method to import this dataset as tf-dataset.",6,2
105,2019-4-25,2019,4,25,2,bgxj76,"Sepcnn problem, I have no learning.",https://www.reddit.com/r/tensorflow/comments/bgxj76/sepcnn_problem_i_have_no_learning/,babaladeo,1556127409,,0,1
106,2019-4-25,2019,4,25,2,bgxnio,SepCnn classifiers does not learn anything.,https://www.reddit.com/r/tensorflow/comments/bgxnio/sepcnn_classifiers_does_not_learn_anything/,babalinobaba,1556128013,"https://developers.google.com/machine-learning/guides/text-classification/step-1


I have tested every SepCnn machine combination in the tutorial above, and for any epoch (200 it's the maximum that I have tried, deactivating earlyStoping) I have 50% val_accuracy for binary tasks and 20% for the 5 category example.

I downloaded the whole eng-edu-master repo and run it without any changes and I get the same results. What could I have been doing wrong?

I'm running tensorflow-gpu==2.0.0-alpha0 

Nvidia GTX1070; driver = 418.56 cuda = 10.1

Intel i7-8700K 3.70GHz 

Ubuntu 18.04 

24gb RAM.",0,1
107,2019-4-25,2019,4,25,3,bgy8ol,Need suggestions for an approach to object detection in very large images,https://www.reddit.com/r/tensorflow/comments/bgy8ol/need_suggestions_for_an_approach_to_object/,Owz182,1556130976,"I need to count objects in 7360x4912 images. I have trained the a faster-rcnn from Google's model zoo on a training data set, which I made by chopping up my 7360x4912 images in to 64 920x614 images. I should note my machine doesn't have enough memory to train on the large images themselves. But the model training has gone well as far as I can tell, and I'm able to detect the objects of interest in the smaller images, but not when I try to detect objects in the full 7360x4912 images. I think this is because the faster-rcnn is resizing before prediction, and the objects of interest end up being too small/poor resolution to detect.

&amp;#x200B;

So I'm trying to come up with an approach that involves, for every prediction, replicating the chopping process, so each large image gets cut to 64 smaller ones, the model detects the objects in each one, and then I take the total count across all 64. However, sometimes the objects fall on the image edge, and so are either not detected, or detected twice, once each at the boundary of the smaller chopped images. This makes my final count inaccurate. I wondered if anyone might have suggestions for an approach to dealing with this.

&amp;#x200B;

I had thought maybe about performing the chopping process multiple times for each large image, but with a random offset each time so the objects will fall in different parts of the smaller images. Then I would take some kind of mean estimate from all the counts of all the offset smaller images. The issue here is I'm upping the number of predictions to be made for each large image, bloating the run time significantly.

&amp;#x200B;

Is this the approach you would take or do you think there's some more efficient way to do this?",3,4
108,2019-4-25,2019,4,25,13,bh4oeq,Develop an object detection model from scratch,https://www.reddit.com/r/tensorflow/comments/bh4oeq/develop_an_object_detection_model_from_scratch/,8222Tamil,1556168112,"Is it possible to create a object detection model like ssd mobilenet ,Faster Rcnn Resnet.If [yes.How](https://yes.How) to approach ?",5,2
109,2019-4-26,2019,4,26,3,bhccnz,How Do Open Source Deep Learning Frameworks Stack Up?,https://www.reddit.com/r/tensorflow/comments/bhccnz/how_do_open_source_deep_learning_frameworks_stack/,pmz,1556218363,,0,1
110,2019-4-26,2019,4,26,4,bhcjex,Training converges on cpu but diverges when I switch to gpu?,https://www.reddit.com/r/tensorflow/comments/bhcjex/training_converges_on_cpu_but_diverges_when_i/,iamiamwhoami,1556219317,"I can give more specifics as I start to diagnose the issue more, but I'm getting this really weird behavior where training converges when I test with cpu but diverges when I move over to a gpu. Has anyone seen anything like this?",5,5
111,2019-4-26,2019,4,26,5,bhdexn,Image recognition with tensorflow,https://www.reddit.com/r/tensorflow/comments/bhdexn/image_recognition_with_tensorflow/,13016,1556223909,"Hey r/tensorflow, I'm totally new to tensorflow but am supposed to create an image recognition software (for example classifying whether or not there is a car in the given image). Is this possible with tensorflow? If so how manageable would this be for someone with no prior experience (except python of course)? Thank you so much for your help!",6,4
112,2019-4-26,2019,4,26,7,bhf05z,None for gradient ValueError,https://www.reddit.com/r/tensorflow/comments/bhf05z/none_for_gradient_valueerror/,roset_ta,1556232442,"Hello,

I implemented a layer in Keras and when trying to fit the model containing the custom layer I get the following error:


`ValueError: An operation hasNonefor gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.`


The main tf ops I'm using are 
`tf.multiply`,
`tf.matmul`
`tf.reduce_sum`
`tf.extract_image_patches`


Is any of those not differentiable?

When I predict a given image, the result I get is as expected. But I cannot fit the model and I don't know what to look for. Any ideas?",0,1
113,2019-4-26,2019,4,26,17,bhjve5,What happens when GPU ran out of memory ?,https://www.reddit.com/r/tensorflow/comments/bhjve5/what_happens_when_gpu_ran_out_of_memory/,RemoteReindeer,1556266468,"\&gt; 2019-04-26 10:08:19.209261: W tensorflow/core/common\_runtime/bfc\_allocator.cc:211\] Allocator (GPU\_0\_bfc) ran out of memory trying to allocate 3.96GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.

&amp;#x200B;

Apart from the obvious, that my GPU memory is full, what happens exactly ? I can still train even if I'm allocating 1.6x the max memory of my GPU.",7,4
114,2019-4-27,2019,4,27,0,bhnb0v,Protobuf with Tensorflow Issue.,https://www.reddit.com/r/tensorflow/comments/bhnb0v/protobuf_with_tensorflow_issue/,FrStealer,1556290997,"Hello,

I've got an issue with Tensorflow and Protobuf on Ubuntu16, python3.4 and I'm really confused.

After Tensorflow 1.13.1 installation, I can't import Tensorflow directly because I'm missing the library google (he can't import google). I then installed protobuf 3.7.0 (the version tensorflow wants) with pip3.4, but he doesn't quite detect it.

After importing, I've got the error message :

&gt;  
&gt;  
&gt;\[libprotobuf FATAL external/protobuf\_archive/src/google/protobuf/stubs/common.cc:68\] This program requires version 3.7.0 of the Protocol Buffer runtime library, but the installed version is 3.6.1.  Please update your library.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in ""google/protobuf/descriptor.pb.cc"".)  
&gt;  
&gt;terminate called after throwing an instance of 'google::protobuf::FatalException'  
&gt;  
&gt;  what():  This program requires version 3.7.0 of the Protocol Buffer runtime library, but the installed version is 3.6.1.  Please update your library.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in ""google/protobuf/descriptor.pb.cc"".)  
&gt;  
&gt;Abandon (core dumped)

&amp;#x200B;

However, I've got the right version of protobuf

     pip3.4 show protobuf

&gt;  
&gt;  
&gt;Name: protobuf  
&gt;  
&gt;Version: 3.7.0  
&gt;  
&gt;Summary: Protocol Buffers  
&gt;  
&gt;Home-page: [https://developers.google.com/protocol-buffers/](https://developers.google.com/protocol-buffers/)  
&gt;  
&gt;Author: None  
&gt;  
&gt;Author-email: None  
&gt;  
&gt;License: 3-Clause BSD License  
&gt;  
&gt;Location: /usr/local/lib/python3.4/site-packages  
&gt;  
&gt;Requires: setuptools, six  
&gt;  
&gt;Required-by: tensorflow, tensorflow-tensorboard, tensorflow-gpu, tensorboard, kraken

    
    protoc --version gives me ""libprotoc 3.7.0""
    

I also purged every Protobuf library on my computer before the new installation with apt. 

&amp;#x200B;

I'm quite confused and any idea would be much appreciated !

&amp;#x200B;

Thanks in advance.",4,1
115,2019-4-27,2019,4,27,0,bhnfhv,"LSTM with more than one feature will train, but issue at prediction time",https://www.reddit.com/r/tensorflow/comments/bhnfhv/lstm_with_more_than_one_feature_will_train_but/,landsquid0,1556291642,[https://stackoverflow.com/q/55835696/4783594](https://stackoverflow.com/q/55835696/4783594),1,0
116,2019-4-27,2019,4,27,4,bhqboi,Multi-GPU inference on Object Detection Model,https://www.reddit.com/r/tensorflow/comments/bhqboi/multigpu_inference_on_object_detection_model/,jpapon,1556306581,"Hi all,

&amp;#x200B;

I'm trying to find out what's going on here. I'm using a model from the object detection zoo:

[http://download.tensorflow.org/models/object\_detection/faster\_rcnn\_inception\_resnet\_v2\_atrous\_coco\_2018\_01\_28.tar.gz](http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz)

I'm using the frozen inference graph.

I find myself unable to change what device the model runs on - I've tried using:

    with tf.device ('/gpu:3') 
        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')
        boxes = detection_graph.get_tensor_by_name('detection_boxes:0')
        scores = detection_graph.get_tensor_by_name('detection_scores:0')
        classes = detection_graph.get_tensor_by_name('detection_classes:0')
        num_detections = detection_graph.get_tensor_by_name('num_detections:0')
        (boxes, scores, classes, num_detections) = sess.run([boxes, scores, classes, num_detections], feed_dict={image_tensor: image_np_expanded})

but no matter what I do, inference still runs on gpu:0. Tensorflow sees all of my devices, but also just seems to ignore all of my tf.device commands.

If I manually set it using, e.g., 

    config = tf.ConfigProto()
    config.gpu_options.visible_device_list=""3""
    sess = tf.Session(graph=detection_graph, config=config)

Then I get the following error:

    Check failed: cuda_gpu_id.value() == result.first-&gt;second (0 vs. 3)
    Mapping the same TfGpuId to a different CUDA GPU id. 
    TfGpuId: 0 Existing mapped CUDA GPU id: 3 CUDA GPU id being tried to map to: 0

Environment variables don't change it either... what could be going on here?",0,0
117,2019-4-27,2019,4,27,6,bhrube,Question about data size,https://www.reddit.com/r/tensorflow/comments/bhrube/question_about_data_size/,JimothyDoe,1556314947,"Before i start i am sorry if this question is asked every 2 days, i am new to this. 
So i have been wondering if say i have been training a model for a few days and by now it can recognise a pattern with promising accuracy, so if i let it train to the point that the model file is around 10 gb, will the process of recognising a small sized image be slower due to the model file size?
And if so is there a way that the user can choose what is saved in the actual model file, modifying the source code wouldn't be out of the question.
Also it take a lot of power for tensorflow to recognise the patterns, say i had it running on a raspberry pi, would it be smart to keep tensorflow running on a raspberry pi or should i the raspberry pi as a recording device that transfers the data to a more powerful device in real time",6,2
118,2019-4-27,2019,4,27,8,bht57p,Problem installing Tensorflow for pycharm IDE in Ubuntu on Jetson Nano,https://www.reddit.com/r/tensorflow/comments/bht57p/problem_installing_tensorflow_for_pycharm_ide_in/,Ryzen120,1556322723,"Hello, 

As the title says, I just received my new jetson nano in the mail and got to setting it up. It runs on a modified version of ubuntu 18.04. I have recently installed Pycharm via the command terminal and it functions properly with normal python code. I recently have attempted to install Tensorflow ( my first time ever) and followed Tensorflows instructions via their site and Nvidias for the Nano specifically. Upon installation via the pycharm IDE however, I get the error which is posted in this link.

http://imgur.com/gallery/CpZ4TfW

If anyone has any suggestions or can help, that would be greatly appreciated! Also if you need more information, I can also do that as well. In the event the picture sucks for some reason, the error code is basically saying exit code (1), module not found.

Thanks!",9,3
119,2019-4-27,2019,4,27,9,bhtkxr,Has anyone used Tensorflow Transform with xgboost?,https://www.reddit.com/r/tensorflow/comments/bhtkxr/has_anyone_used_tensorflow_transform_with_xgboost/,elliott34,1556325384,"Problem we're running into described here: [https://github.com/tensorflow/transform/issues/114](https://github.com/tensorflow/transform/issues/114)

&amp;#x200B;

Are we saving the wrong graph?",0,5
120,2019-4-27,2019,4,27,15,bhw8um,Error appeared when I use tensorboard,https://www.reddit.com/r/tensorflow/comments/bhw8um/error_appeared_when_i_use_tensorboard/,Laurence-Lin,1556345517,"When I use tensorboard in command line: tensorboard --logdir PATHNAME, an error appeared:

OSError: Errno22: invalid argument

After search solution online, some says that it is due to the bug in Python version before 3.6.7, so I download the newest version of Python 3.7 and installed it, but when I run it again same error message reappeared. I've seen the error message, the tensorboard file direction is located in Anaconda file path, and the python version within anaconda is Python 3.6.5. 

Should I upgrade anaconda too? Will it also upgrade the python version in anaconda?

Thanks for helping!",1,1
121,2019-4-27,2019,4,27,21,bhyhqx,Tensorflow 2.0 custom training values,https://www.reddit.com/r/tensorflow/comments/bhyhqx/tensorflow_20_custom_training_values/,wongong,1556367226,"Hi!

Im trying to implement policy gradient for continuous action with tensorflow 2.0

But here, I have a problem. 

for custom training,

I use this part.

grads = gt.gradient(objective, self.model.trainable\_variables)

self.optimizer.apply\_gradients(zip(grads, self.model.trainable\_variables)

&amp;#x200B;

but what if I have another tf.Variable which is not included in model.trainable variables but want to train?

I tried just do 

grads = gt.gradient(objective, self.model.trainable\_variables+ tf.expand\_dims(\[self.std\],axis = 0))

self.optimizer.apply\_gradients(zip(grads, self.model.trainable\_variables+ tf.expand\_dims(\[self.std\],axis = 0)))

but it is not working.

&amp;#x200B;

help me out!",2,1
122,2019-4-27,2019,4,27,21,bhyo09,"Error Encoding Network, generate images without minimizing the alternating latent space or adversarial training!",https://www.reddit.com/r/tensorflow/comments/bhyo09/error_encoding_network_generate_images_without/,RRoundTable,1556368662,"Hi, ML redditors all around the world! 

This is an unofficial implementation of Error Encoding Networks which is originally developed by Facebook AI Research using Keras.

To alleviate the necessity of GPU resources, the smaller network is used by reducing the size of an input image.

If you are interested in EEN, click this link and check the results.

Thanks :)",0,1
123,2019-4-28,2019,4,28,0,bi09r6,Image Recognition with Tensorflow,https://www.reddit.com/r/tensorflow/comments/bi09r6/image_recognition_with_tensorflow/,13016,1556379488,"Hey guys, I've spent a couple of days learning the basic principles behind tensorflow. Now I want to create an image classifier. My problem is that every tutorial I encountered so far explained how to classify images that have a predefined theme (for example animals or flowers). But what do I have to do if I want to, for example, have an image classifier that tells me wheter or not a given image has a cog wheel in it or not?",6,2
124,2019-4-28,2019,4,28,4,bi2rok,Is there a way I can just flatten the last two dimensions of a tensor when the tensor has two dimensions of unknown size?,https://www.reddit.com/r/tensorflow/comments/bi2rok/is_there_a_way_i_can_just_flatten_the_last_two/,iamiamwhoami,1556394122,"So I have a tensor of 

     shape=(?, 3, ?, 2, 100)

The zeroth dimension is batch_size. The first is number of time steps. The second is a little hard to explain but it also indexes time but in a different way from the first. The last two dimensions are my features. I want to flatten the last two dimension so that

     shape=(?, 3, ?, 200)

I've tried tf.reshape and K.flatten. However they throw an error because of the two unknown dimension sizes. Anyone have an idea on how to proceed?",2,4
125,2019-4-28,2019,4,28,14,bi811j,Recurrent Neural Networks: Algorithms and Applications,https://www.reddit.com/r/tensorflow/comments/bi811j/recurrent_neural_networks_algorithms_and/,Bobber123yxz,1556429299,,2,14
126,2019-4-28,2019,4,28,21,bial8r,Error when trying to train model (cast string to float),https://www.reddit.com/r/tensorflow/comments/bial8r/error_when_trying_to_train_model_cast_string_to/,SmoothyMoves,1556453332,"Explanation in here: https://stackoverflow.com/questions/55883985/tensorflow-model-training-with-cast-string-to-float-is-not-supported-error?noredirect=1#comment98429390_55883985

Any ideas?",6,0
127,2019-4-28,2019,4,28,23,bic31n,"Interested in Artificial Intelligence, Machine Learning, Computer Vision, or NLP? Check out this channel for excellent, well-explained, video tutorials.",https://www.reddit.com/r/tensorflow/comments/bic31n/interested_in_artificial_intelligence_machine/,Bobber123yxz,1556463583,,2,7
128,2019-4-29,2019,4,29,0,biccse,when is the negative sign applied for gradient descent?,https://www.reddit.com/r/tensorflow/comments/biccse/when_is_the_negative_sign_applied_for_gradient/,wongongv,1556465170,"I have a question about tensorflow custom training. 
For example, let's say Im using cross_entropy_with_softmax and adam optimizer. For this to be a gradient descent, you need to apply negative sign somewhere. When does tensorflow applies it?
The reason I want to know this is to do gradient ascent with custom loss. It seems like negative sign is applied in Adam optimizer. Is it right?

Thank you!",1,1
129,2019-4-29,2019,4,29,5,bifswf,"Trying to install TF 2.0 gpu, am I doing something wrong?",https://www.reddit.com/r/tensorflow/comments/bifswf/trying_to_install_tf_20_gpu_am_i_doing_something/,Biddls,1556484157,,34,0
130,2019-4-30,2019,4,30,4,bityfo,Ultimate Guide to TensorFlow 2.0 in Python,https://www.reddit.com/r/tensorflow/comments/bityfo/ultimate_guide_to_tensorflow_20_in_python/,pmz,1556567940,,1,0
131,2019-4-30,2019,4,30,9,bix5yv,Told to update my cudNN despite it being the latest update,https://www.reddit.com/r/tensorflow/comments/bix5yv/told_to_update_my_cudnn_despite_it_being_the/,A_Random_Lantern,1556585779,I'm using CUDA 9.0 with v7.5.1 which is the latest update yet tensorflow is telling me to update it. I'm not getting this so any help would be appreciated,4,1
132,2019-4-30,2019,4,30,21,bj304m,object detection API training loss is not going down!,https://www.reddit.com/r/tensorflow/comments/bj304m/object_detection_api_training_loss_is_not_going/,aniketmaurya,1556629173,"I am trying to train custom dataset with Tensorflow object detection API.  I have hand annotated calculation area in tax receipts. But the training loss doesn't seem to reduce below 0.18

I have attached the prediction images. Please help!

https://i.redd.it/1zc9r2v1gev21.png",14,0
0,2019-5-1,2019,5,1,15,bjdu18,My tensorboard cannot show scalar but only graph,https://www.reddit.com/r/tensorflow/comments/bjdu18/my_tensorboard_cannot_show_scalar_but_only_graph/,Laurence-Lin,1556690596,"I shutdown the training after several epochs because I saw the poor training results, but when I run:

tensorboard --logdir = PATH  
In the browser I could only see graph but no scalar. 

&amp;#x200B;

https://i.redd.it/m9wabd0uijv21.png

But in the online cloud machine floydhub, I could see my scalar variable while training. How could I see the scalar on tensorboard?",6,1
1,2019-5-1,2019,5,1,16,bjecgk,Simplest Example of AUC ROC Curve | Machine Learning Tutorial | Machine Learning For Beginners,https://www.reddit.com/r/tensorflow/comments/bjecgk/simplest_example_of_auc_roc_curve_machine/,bhavesh91,1556695227,,0,0
2,2019-5-1,2019,5,1,18,bjf0o5,Improving confidence in results,https://www.reddit.com/r/tensorflow/comments/bjf0o5/improving_confidence_in_results/,josh2k44,1556701979,"Ive trained my image classification model based on MobileNet. I used a combination of ImageNet and images from the web using different APIs. The model is guessing the correct objects but the confidence is low (20-30%) with some items like mobile phones at 80-90%.

Where do I go from here improving the confidence of certain objects?",1,2
3,2019-5-2,2019,5,2,8,bjo1hq,Is it known what the convolutional layers correspond to?,https://www.reddit.com/r/tensorflow/comments/bjo1hq/is_it_known_what_the_convolutional_layers/,PiratePersonRawr,1556753247,"I know that some layers correspond to edges and further layers in the ML correspond to simple shapes and so on. Is it known how many layers are needed for each thing? If I want to match letters, I need lines, edge recognition, but also more complicated shapes like circles and triangles. I also need shapes made of shapes, which is ideally each letter, but maybe there are more steps in between I'm not sure. Does anyone know exactly how many conv layers are needed for edge detection, for circle detection, and so on?",4,2
4,2019-5-2,2019,5,2,22,bjv9ee,Image Recognition with Tensorflow Part 3,https://www.reddit.com/r/tensorflow/comments/bjv9ee/image_recognition_with_tensorflow_part_3/,13016,1556805553,"Hello again,
this is my third post on this sub concering image recognition. I have now followed a tutorial and been able to run an image classifier with keras. It does not yet give me the right answer but at least it does work. My question is - if I always just run my code with one image to test inserted it takes a lot of time. I think this part is called the training and should not be necessary to be run every time. How can I just use the trained CNN to see if it correctly reads the images I want to be tested?",4,11
5,2019-5-3,2019,5,3,0,bjw57q,Implement reinforcement learning algorithm with pure tensor style (without feeding) in tensorflow?,https://www.reddit.com/r/tensorflow/comments/bjw57q/implement_reinforcement_learning_algorithm_with/,fredericgo,1556810283,"0

I am having problems implementing reinforcement learning (RL) algorithms with pure tensor style in tensorflow. The idea comes from the implementation of Deepmind's [IMPALA](https://arxiv.org/abs/1802.01561). The authors use tf.py\_func() to convert the emulator into tensorflow ops. The code is written in a pure tensor style without fetches and feeds.  As an exercise, I am trying to train the games in gym and trying to convert the code to other RL algorithms. However, I have very bad results in last few weeks and need someone's help.

My code to run the gym's games in my [repo](https://github.com/fredericgo/ppo_pure_tensor). Currently, they are policy gradient (PG) and proximal policy optimization (PPO).

I am not sure if I get right with PG. In ""CartPole-v0"" score finally converges to 200. But for ""LunarLander-v2"" it is weird. The algorithm first learns something, but after a while the episodic return dropped drastically down to a wrong place and never come back. Moreover, my PPO does not learn anything at all. ([see pictures here](https://github.com/fredericgo/ppo_pure_tensor/tree/master/images))

My implementations are here: [PG](https://github.com/fredericgo/ppo_pure_tensor/blob/master/pg_discrete.py), and [PPO](https://github.com/fredericgo/ppo_pure_tensor/blob/master/ppo_discrete.py).

I expect that the outcomes of the pure-tensor code to match those of the conventional ones with tensorflow fetches and feeds. As a reference: [PG conventional](https://github.com/fredericgo/ppo_pure_tensor/blob/master/conventional/pg.py) and [PPO conventional](https://github.com/fredericgo/ppo_pure_tensor/blob/master/conventional/ppo.py).",0,2
6,2019-5-3,2019,5,3,3,bjyc6m,Installed the wrong version of tensorflow and I can't change it to the GPU version,https://www.reddit.com/r/tensorflow/comments/bjyc6m/installed_the_wrong_version_of_tensorflow_and_i/,Biddls,1556821652,"So i installed TF 2.0 for CPU fine gives the error about CPU instruction set that's fine.

I then do pip show tensorflow

Name: tensorflow

Version: 2.0.0a0

and then when I run a simple mnist character recognition example code it uses my CPU not GPU (RTX 2080) (looking at % usage on HWmonitor)

So how do I force install the GPU version? I have installed py python 3.6, Cuda 10.0 and cuDNN etc.

Manny thx",4,2
7,2019-5-3,2019,5,3,7,bk0t08,Conv3d in Mobile (Android),https://www.reddit.com/r/tensorflow/comments/bk0t08/conv3d_in_mobile_android/,tgps26,1556834752,"Hello guys,

I've recently created a model using Keras for action recognition using Conv3d and MaxPool3D layers, which I would  like to deploy in android now. However, it seems to me that these  operations are not yet developed for tensorflow-lite. I've also checked their roadmap but couldn't find any info regarding ETA for the implementation of this feature..

&amp;#x200B;

I'm still new at this but would this mean that I'd have to completely change my  model (and drop the 3D model) in order to deploy it in mobile or is there any workaround?

&amp;#x200B;

Really appreciate your attention and any help I could get",3,7
8,2019-5-3,2019,5,3,23,bk94lj,How do I initialize tf.global_variables_initializer() with version 2.0?,https://www.reddit.com/r/tensorflow/comments/bk94lj/how_do_i_initialize_tfglobal_variables/,Behinddasticks,1556893846,"`# Evaluate the graph`

&amp;#x200B;

`init = tf.global_variables_initializer()`

&amp;#x200B;

`with tf.Session() as sess:`

[`init.run`](https://init.run)`()`

`result = e.eval()`

`print(result)`

&amp;#x200B;

`--------------------------------------------------------------------------- AttributeError                            Traceback (most recent call last) &lt;ipython-input-10-8779ad453922&gt; in &lt;module&gt;       1 # Evaluate the graph       2 ----&gt; 3 init = tf.global_variables_initializer()       4       5 with tf.Session() as sess: AttributeError: module 'tensorflow' has no attribute 'global_variables_initializer'`   


Thanks",4,3
9,2019-5-3,2019,5,3,23,bk98zj,"[Project] Tensorflow implementation of ""Handwritten Indic Character Recognition using Capsule Networks"" [ASPCON 2018]",https://www.reddit.com/r/tensorflow/comments/bk98zj/project_tensorflow_implementation_of_handwritten/,CodeMusicFreak,1556894546,,0,0
10,2019-5-4,2019,5,4,21,bkkkai,TensorFlow layer in Keras model?,https://www.reddit.com/r/tensorflow/comments/bkkkai/tensorflow_layer_in_keras_model/,roset_ta,1556972276,"Hello,

I need to make a Keras Sequential (or functional) model with some Keras layers. Is it possible to include in that model a tf custom layer too? I'm not very familiar with TensorFlow and it would be easier for me to use `model.fit` and `model.compile` Keras functions to control my model.

So far, I have tried wrapping the custom tf layer in a Lambda Keras layer, but I get an out of memory error, so I don't really understand if it is even possible.

[Here](https://github.com/srcarrel/QuadraticConvolutions/blob/master/Nonlinear%20vs%20Linear%20Convolution%20(Fashion%20MNIST).ipynb) is the TensorFlow layer I need to include. (It is the `quadratic_layer` function).

Thank you",12,4
11,2019-5-5,2019,5,5,3,bknyei,How to Train GPT-2 model from scratch,https://www.reddit.com/r/tensorflow/comments/bknyei/how_to_train_gpt2_model_from_scratch/,Vaiku2718,1556993360,,3,2
12,2019-5-6,2019,5,6,11,bl6fok,Help a newcomer merge 2 concepts,https://www.reddit.com/r/tensorflow/comments/bl6fok/help_a_newcomer_merge_2_concepts/,popcornondemand,1557110199,"I've been following [sentdex's tutorial](https://pythonprogramming.net/chatbot-deep-learning-python-tensorflow/) to make a simple chatbot to mess around with. Then I found [this guide](https://chatbotsmagazine.com/contextual-chat-bots-with-tensorflow-4391749d0077) on having a pre made set of responses for different intents. I'm quite new to tensorflow so I don't know all the details just yet. Any way to merge these 2 concepts?

I *think* the second guide is about making 2 training files based on the intents, then training a model to them. If this is true, I was planning on training my AI with this training file and my main ""train.from/train.to"" files. If someone could clarify the best way to merge these 2 ideas that would be just swell.",0,1
13,2019-5-6,2019,5,6,12,bl72es,Guide: How to setup the Coral Dev Board using Windows only,https://www.reddit.com/r/tensorflow/comments/bl72es/guide_how_to_setup_the_coral_dev_board_using/,23f34ef32,1557113994,,0,2
14,2019-5-6,2019,5,6,19,blamb3,Saving weights/convolutional outputs and overlaying them onto input images,https://www.reddit.com/r/tensorflow/comments/blamb3/saving_weightsconvolutional_outputs_and/,Doraguniru92,1557139957,"Hey all,

&amp;#x200B;

I'm trying to save weights/convolutional layer outputs from a model and overlay them on top of the input images or image to be classified.

So far I've tried this: 

&amp;#x200B;

**init = tf.global\_variables\_initializer()**

&amp;#x200B;

**epochs = 100**

&amp;#x200B;

**# Add ops to save and restore all the variables.**

**saver = tf.train.Saver()**

&amp;#x200B;

**with tf.Session() as sess:**

[**sess.run**](https://sess.run)**(init)**

&amp;#x200B;

**for i in range(epochs):**

&amp;#x200B;

**batch\_x, batch\_y = mnist.train.next\_batch(50)**

&amp;#x200B;

[**sess.run**](https://sess.run)**(**

**train,**

**feed\_dict={**

**x: batch\_x,**

**y\_true: batch\_y})**



**# Save the variables to disk.**

**save\_path =** [**saver.save**](https://saver.save)**(sess, ""/tmp/model.ckpt"")**



**# delete the current graph**

**tf.reset\_default\_graph()**

&amp;#x200B;

**# Add ops to save and restore all the variables.**

**saver = tf.train.Saver()**

&amp;#x200B;

**# Later, launch the model, use the saver to restore variables from disk, and**

**# do some work with the model.**

**with tf.Session() as sess:**

  **# Restore variables from disk.**

  **saver.restore(sess, ""/tmp/model.ckpt"")**

&amp;#x200B;

But I get an error saying ""No variables to save"".

&amp;#x200B;

Any help is appreciated, thanks.",1,1
15,2019-5-6,2019,5,6,21,blbbro,Combining multiple event files from Tensorboard,https://www.reddit.com/r/tensorflow/comments/blbbro/combining_multiple_event_files_from_tensorboard/,yolandasquatpump,1557144444,"Hey everybody!

&amp;#x200B;

I've been doing some work, where I'm continuing training after periods of 24h and every time I create a new event-file. I'm attempting to combine these different rounds into one single event file, so I can access that in tensorboard. Loading multiple runs in Tensorborad doesn't work that well, since using 'WALL' on the horizontal axis creates gaps in the plots. Is there an way to do this? Thanks!",0,3
16,2019-5-7,2019,5,7,7,bliecp,Best way to learn Tensorflow 2.0?,https://www.reddit.com/r/tensorflow/comments/bliecp/best_way_to_learn_tensorflow_20/,aniketmaurya,1557180385,I am new to Tensorflow. What is the best way to learn Tensorflow?,6,13
17,2019-5-7,2019,5,7,8,bljh4d,Any idea what CUDA version TF 2.0 release will require?,https://www.reddit.com/r/tensorflow/comments/bljh4d/any_idea_what_cuda_version_tf_20_release_will/,clanleader,1557186223,"I'm aiming to set everything up so that when TF 2.0 is released I won't need to restart my computer or do many other adjustments (I'm using Win10 currently). I realize the alpha 2.0 requires CUDA 10.0, but I'm curious whether the release will require 10.0 or 10.1 - Does anyone know for sure?

Thanks.",2,2
18,2019-5-7,2019,5,7,12,bllo0i,what is tf.nn.l2_normalize do?,https://www.reddit.com/r/tensorflow/comments/bllo0i/what_is_tfnnl2_normalize_do/,begooboi,1557198950,"In calculating attention this code uses tf.nn.l2_normalize(output, dim=1) What is it? Is this batch normalizaton? I have heard about l1 and l2 loss do they have anything in common?

    def attention(self, query, key, value):
        # Equation 1 in Vaswani et al. (2017)
        #   Scaled dot product between Query and Keys
        output = tf.matmul(query, key, transpose_b=True) / (tf.cast(tf.shape(query)[2], tf.float32) ** 0.5)
        #   Softmax to get attention weights
        attention_weights = tf.nn.softmax(output)
        #   Multiply weights by Values
        weighted_sum = tf.matmul(attention_weights, value)
        # Following Figure 1 and Section 3.1 in Vaswani et al. (2017)
        #   Residual connection ie. add weighted sum to original query
        output = weighted_sum + query
        #   Layer normalization
        output = tf.nn.l2_normalize(output, dim=1)
        return output, attention_weights",4,1
19,2019-5-7,2019,5,7,15,blnbhb,Is there difference to flatten a layer by tf.reshape and tf.layers.flatten ?,https://www.reddit.com/r/tensorflow/comments/blnbhb/is_there_difference_to_flatten_a_layer_by/,Laurence-Lin,1557210599,"As title, I have a batch of data with size \[batch, height, width, channels\], and I want to reshape it into \[batch, height\*width\*channels\]

I can do:

tf.reshape(x, \[batch size, -1\])

or 

tf.layers.flatten(x)

However, will these two method reshape the tensor in same way? I mean if they would both reshape the tensor, and make each sample in the tensor flatten into same dimension, so that the values in different samples don't mix together.",2,1
20,2019-5-8,2019,5,8,2,blt5wi,Vega 64 + TensorFlow 2.0? Issues with ROCm; HELP,https://www.reddit.com/r/tensorflow/comments/blt5wi/vega_64_tensorflow_20_issues_with_rocm_help/,CarlosAcm,1557248407,"I have been following the instructions from [the github page](https://github.com/RadeonOpenCompute/ROCm) to install ROCm with no luck. I am a newbie to Linux and TF, so any help is appreciated.

&amp;#x200B;

I am running into two issues. The first one is that after loading the rocm.gpg.key, the echo deb \[arch=amd64... code does not do anything. I loaded the key and saved it as a file and then used the sudo apt-key add command (it just said OK, so I think I did add the key). I am on a VM running Ubuntu 16.04.6. Because the github also mentioned that Vega 10 works with Kerner 4.18, I updated to that, now showing (making me question whether I did it correctly or not): Linux ubuntu 4.18.0-041800-generic #201808122131 SMP Sun Aug 12 21:33:20 UTC 2018 x86\_64 x86\_64 x86\_64 GNU/Linux

&amp;#x200B;

The second issue is that these instructions are suited for TF 1.13, not 2.0.  I found [this discussion](https://github.com/ROCmSoftwarePlatform/tensorflow-upstream/issues/362) that links to a cloud.docker page that supposedly has it, but I do not know how to use this. I installed docker.io and tried to run the command ""docker pull rocm/tensorflow:tf2.0-alpha0-preview"" with no luck due to a permission denied message.

&amp;#x200B;

I started getting into ML close the the release of TensorFlow 2.0 and really want to use it for learning. I also don't want to go out and get a non-AMD GPU for tutorials and practicing when I have a working Vega 64. Thanks in advance!",9,1
21,2019-5-8,2019,5,8,3,bluah1,textgenrnn - How can I continue training a model with new input data?,https://www.reddit.com/r/tensorflow/comments/bluah1/textgenrnn_how_can_i_continue_training_a_model/,IllIlllllIIllIllllII,1557253829,"Hi,

I am new to TF and python so maybe this turns out to be a really easy thing.

So I've read [this article](https://minimaxir.com/2018/05/text-neural-networks) on how to train a RNN with [textgenrnn](https://github.com/minimaxir/textgenrnn). Title, basically: I have created a model with input data. Now I have more input data for the model, how can I feed it to him?",4,2
22,2019-5-8,2019,5,8,4,blv3pz,Text to vector using tensorflow( no keras),https://www.reddit.com/r/tensorflow/comments/blv3pz/text_to_vector_using_tensorflow_no_keras/,sheneon91,1557257798,"Hi team,
Fairly new to tensor flow ( though I have worked on keras).
I am told to convert text to vectors using tensorflow.
I read online that the best way to do it is to use word2vec for it.
I did that and got my results, also there is basic one hot method which was not favored much online.
Any other way I am missing?
Also, my lead on the project told me to just build a encoder which converts a sequence to a vector.
I don't have to build an entire encoder decoder but just the encoder part.
Is word2vec the same ?",2,1
23,2019-5-8,2019,5,8,14,bm1i3t,TensorFlow Tutorial for Beginners,https://www.reddit.com/r/tensorflow/comments/bm1i3t/tensorflow_tutorial_for_beginners/,deepak-kumar-singh,1557294182,"Tensor flow is a distributed computing tool, which allows colossus neural networks to train over a distributed server. Tensor flow is a product of the Google brain team, and Google used tensor flow for its internal use.

[https://www.tutorialandexample.com/tensorflow-tutorial](https://www.tutorialandexample.com/tensorflow-tutorial)

\#History\_of\_TensorFlow

\#Products\_build\_using\_TensorFlow

\#Applications\_of\_TensorFlow

https://i.redd.it/nibprsehdxw21.png",1,0
24,2019-5-8,2019,5,8,16,bm2g7o,Top TensorFlow tutorials- curated list,https://www.reddit.com/r/tensorflow/comments/bm2g7o/top_tensorflow_tutorials_curated_list/,singhpankaj99,1557301824,Curated [list of Top 11 Tensor flow](http://blog.quickcode.co/top-tutorials-to-learn-tensorflow-for-beginners/?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=reddit?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=redditPostTensorFlow&amp;utm_term=TensorFlow) tutorials online.,3,12
25,2019-5-8,2019,5,8,20,bm460b,Creating a TensorFlow DNN in C++ Part 1,https://www.reddit.com/r/tensorflow/comments/bm460b/creating_a_tensorflow_dnn_in_c_part_1/,EvoNext,1557315458,,0,12
26,2019-5-8,2019,5,8,21,bm4fmo,Can't understand model.predict output,https://www.reddit.com/r/tensorflow/comments/bm4fmo/cant_understand_modelpredict_output/,SYtor,1557317159,"I making text classifier using these guides:

 [https://www.tensorflow.org/tutorials/keras/basic\_text\_classification](https://www.tensorflow.org/tutorials/keras/basic_text_classification) 

 [https://www.tensorflow.org/alpha/tutorials/text/text\_classification\_rnn](https://www.tensorflow.org/alpha/tutorials/text/text_classification_rnn) 

In second guide there is example of predict function. It returns single value, that as I understand if &gt; 0.5 =&gt; class marked as 1, &lt; 0.5 =&gt; class marked as 0

I've tried to run predict function on my own data and on example from first guide like this

`print(model.predict(train_data[0]))`

but output contains list  \[ \[0.00000000e+00\]  \[6.75022602e-05\] .... \]

Should I get average or what? For my own data it returns list with length = 3245 of list that contains single value",5,1
27,2019-5-9,2019,5,9,0,bm6py9,Tensorflow vs Tensorflow.js,https://www.reddit.com/r/tensorflow/comments/bm6py9/tensorflow_vs_tensorflowjs/,slovakyan,1557329752,Im new to ML. Which one should I start learning tensorflow or tensorflow.js?,7,1
28,2019-5-9,2019,5,9,10,bmdznp,Tensorflow object detection api,https://www.reddit.com/r/tensorflow/comments/bmdznp/tensorflow_object_detection_api/,invinciblesunglasses,1557366833,"I'm working on a traffic sign recognition bachelor project and I have to run it on an android device. I just finished training using tensorflow object detection api and Faster RCNN , however I can't figure out what to do after I'm done with training the model. I read about freezing the graph but I can't find detailed tutorials for beginners so if anyone knows any good resources or can help I would be very grateful. Thanks in advance.",1,3
29,2019-5-9,2019,5,9,11,bmec1l,Advice on which model to use for given problem.,https://www.reddit.com/r/tensorflow/comments/bmec1l/advice_on_which_model_to_use_for_given_problem/,UysofSpades,1557368863,"I tried my luck at /r/learnmachinelearning with no luck...I hope this is an appropriate sub to post this. If not please kindly redirect me.  Thank you

I currently work in R&amp;amp;amp;D at my current employment, and my team and I are getting on board with ML applications. At the moment we are all very experienced programmers (Python/c++) but we are very new to ML concepts. We quickly realized that ML is a very broad topic, so we bought a few books (Machine Learning with Tensorflow and Deep Learning with Python) we are also currently doing some Coursera free classes that revolve around ML. One of my favorite books so far is Machine Learning with Tensorflow. It gives you the 50,000 and 10,000 ft field of view for the different approaches to using ML to solve a specific problem. 

So to make a long story short, my team and I feel that we have a very basic grasp of some of the concepts used to solve problems (regression, classification, clustering, and Markov models) we would like to deviate away from the sample datasets and begin working on small projects here and there that ML can be utilized. One such project is the reason I am here. 

I am kindly requesting the opinion and advice of potentially more experienced folks here on what subtopic of supervised, or unsupervised, would be more appropriate. 

In a nut shell we have certain mechanical tools that require heat calibration files. So far they are done manually and it is a very tedious work. To make matter simple, we accomplish this by essentially setting our tools in a massive oven and start recording on certain sensors at different temperatures. At the end we use an overall average at each recorded temperature to be put into our heat calibration file. 

It looks something like this:

Tmp value
* 40, 233
* 40, 231
.
.
* 95, 130
* 95, 128
* 95, 135


And we continue for 10 discrete temp values.  Our goal is trying to find the most optimal value at a certain temperature within a range of 0F to 250F. Our current method gives us a measly 10 points of final data, and a linear regression analysis is constructed to interpolate the missing values. We feel this can be optimally redone using ML we were thinking if we should use
Regression to model this trend ( we have millions of datapoints) or would this be more better solved of we push it through a clustering unsupervised model?

I would love thoughts and suggestions. Thank you.",11,1
30,2019-5-9,2019,5,9,16,bmgo98,Need help with loading a tensorflow model in java,https://www.reddit.com/r/tensorflow/comments/bmgo98/need_help_with_loading_a_tensorflow_model_in_java/,BlueFrenchHornThief,1557386382,"I have created a tensorflow image classifier model using AutoML and then exported it to .pb format and .tflite format. According to the docs we can load tflite files in android but the website doesnt say anythin about normal java applications. I tried a sample code that i found on github that loads a inceptionh5 model and infers results in java. I modified it a bit to load my model but it isn't working. 

&amp;#x200B;

How can i load and infer my model in java using either tflite or pb model?",0,3
31,2019-5-10,2019,5,10,1,bmm5i3,"Download a free Early Release copy of ""Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow"" from O'Reilly (e-mail address required)",https://www.reddit.com/r/tensorflow/comments/bmm5i3/download_a_free_early_release_copy_of_handson/,jonjohns65,1557420639,,9,53
32,2019-5-10,2019,5,10,5,bmoo83,Detector: Tensorflow Lite on the Raspberry Pi 3b+,https://www.reddit.com/r/tensorflow/comments/bmoo83/detector_tensorflow_lite_on_the_raspberry_pi_3b/,whistlesnort,1557433035,"Detector is a video pipeline application for the [Raspberry Pi 3b+](https://www.raspberrypi.org/products/raspberry-pi-3-model-b-plus/) with real time object detection. Objects are identified in the output video with bounding boxes. Object detection is provided by [Tensorflow Lite](https://www.tensorflow.org/lite) running the [COCO SSD MobileNet v1](https://www.tensorflow.org/lite/models/object_detection/overview) model. The resulting video can be saved to an H264 elemental stream file or served up via RTSP. The application is written in C++. The RTSP implementation source was adapted from [Live555](http://www.live555.com/).

Installation, build and usage instructions can be found [here](https://gitlab.com/tylerjbrooks/detector#detector).",8,1
33,2019-5-10,2019,5,10,10,bmrz8f,[P] Keras BERT for Medical Question Answer Retrieval using Tensorflow 2.0 ! With GPT-2 for Answer Generator. Pip installable. Weights/Data readily available. Reduced version for Google Colab instantly available in premade notebook.,https://www.reddit.com/r/tensorflow/comments/bmrz8f/p_keras_bert_for_medical_question_answer/,BatmantoshReturns,1557450524,,0,8
34,2019-5-10,2019,5,10,13,bmtzxo,Save model with metadata?,https://www.reddit.com/r/tensorflow/comments/bmtzxo/save_model_with_metadata/,geometrikal,1557463120,"I'm working on a project where we create a lot of trained models. We save the models using `tensorflow.python.tools.freeze_graph.py`  for use in some java and C# programs, and also create an xml file with details about the model, such as the input / output tensor names and sizes, class names, what pre-processing is expected, etc. These two files are then shared with people.

I would like to store the data in the XML within the graph pb itself. Is this possible, and if so, how to go about it?

Also I'm thinking about porting some of the custom parts to Keras, to make it easier for others to work with. As far as I'm aware I still have to use freeze\_graph.py to get a pb file?",0,2
35,2019-5-10,2019,5,10,16,bmvhvo,Inside TensorFlow: tf.data - TF Input Pipeline,https://www.reddit.com/r/tensorflow/comments/bmvhvo/inside_tensorflow_tfdata_tf_input_pipeline/,LazarLjubenovicat,1557474653,[https://www.youtube.com/watch?v=91A0CJrmd-o](https://www.youtube.com/watch?v=91A0CJrmd-o),0,2
36,2019-5-11,2019,5,11,1,bn0nhh,Should i learn TenserFlow now or wait for a 2.0 stable release?,https://www.reddit.com/r/tensorflow/comments/bn0nhh/should_i_learn_tenserflow_now_or_wait_for_a_20/,Flamyngoo,1557507033,"Hi all! I wanted to get into ML and AI stuff in general so i was looking for those popular frameworks and of course everything was TenserFlow but i saw people saying that the new version will be much different and it would be more similar to PyTorch (another one i heard many times), so my question is, if i wanted to learn TF, should i wait for a stale 2.0 release, use the alphas of 2, or maybe learn PyTorch and then migrate to TF when 2 releases? or just learn the one that is stable now.",8,2
37,2019-5-11,2019,5,11,7,bn4o5i,How to design functions that work in TensorFlow 2.0 eager and graph mode,https://www.reddit.com/r/tensorflow/comments/bn4o5i/how_to_design_functions_that_work_in_tensorflow/,pgaleone,1557526945,,3,8
38,2019-5-11,2019,5,11,21,bnbc8o,Getting Started with TensorFlow 2.0 (Google I/O'19) by Josh Gordon and Paige Bailey,https://www.reddit.com/r/tensorflow/comments/bnbc8o/getting_started_with_tensorflow_20_google_io19_by/,asuagar,1557576240,,0,37
39,2019-5-12,2019,5,12,2,bnenfw,Tokenizer and Nietzsche,https://www.reddit.com/r/tensorflow/comments/bnenfw/tokenizer_and_nietzsche/,snake11235,1557595950,"Hey guys,

I'm playing with tf and text generation task.  I was able successfully to master classical Nietzsche example. Now I'm trying it with using Tokenizer.  Things looked good, I was able to start fitting process, and even it converged , but I ended up in following result:

    Epoch 1/60
    200256/200281 [============================&gt;.] - ETA: 0s - loss: 2.1613 - acc: 0.3707
    Input: a
    Output:
    yyyyyyyyyyyyyyyyyyyyyyyyyyyyyy

Please look at my notebook. I've been fighting with this issue for a few days. Thanks in advance

[https://colab.research.google.com/drive/1uUZ-hZAnJBU8o841K6T51gnKfEbCB3JX](https://colab.research.google.com/drive/1uUZ-hZAnJBU8o841K6T51gnKfEbCB3JX)",1,1
40,2019-5-12,2019,5,12,9,bnj1p9,TF2 + Image Augmentation + tf.data.Dataset,https://www.reddit.com/r/tensorflow/comments/bnj1p9/tf2_image_augmentation_tfdatadataset/,alew3,1557620882,"I'm finding the tf.image transformations very limited compared to other ML libraries, and when I try to use Tensor Flow Addons Image, my Kernel crashes.

Any tips on how doing image augmentation with TF2 ? (Random Crop, Zoom, Warp, Affine..).",0,2
41,2019-5-12,2019,5,12,23,bnp8vg,How I can create a DataSet from a Tensorflow model?,https://www.reddit.com/r/tensorflow/comments/bnp8vg/how_i_can_create_a_dataset_from_a_tensorflow_model/,einerixcode,1557669617,"Hello,

I programming with the [ML.NET](https://ML.NET) Image Classification. for Classification I need a Dataset for this. Like this 

Can everyone here help? 

https://i.redd.it/34hju8xudsx21.png",0,0
42,2019-5-13,2019,5,13,3,bnsaje,Image Classification with Tensorflow 2.0,https://www.reddit.com/r/tensorflow/comments/bnsaje/image_classification_with_tensorflow_20/,aniketmaurya,1557685905,"TF 2.0 is coming out with some major changes. It is going to be more pythonic and with tight integration of Keras now it will focus on simplicity and ease of use.

I've written a blog on Medium titled- ""Image Classification with TF 2.0"".",12,11
43,2019-5-13,2019,5,13,6,bnu4w3,tf.einsum with different tensor shapes,https://www.reddit.com/r/tensorflow/comments/bnu4w3/tfeinsum_with_different_tensor_shapes/,roset_ta,1557694955,"Hello,

Can someone explain to me what the following `tf.einsum` operation does?


`V = tf.einsum('abcid,abcjd,dijo-&gt;abcdo', input, input, W)`


input is a tensor of shape (64,32,32,9,3)
W is a tensor of shape (3,9,9,32)


I tried printing the result in a script with random tensors, but got an error because of different shapes of the three tensors. But it works in the tf model I found it. Is it performing dot product ?",6,0
44,2019-5-13,2019,5,13,18,bo1b8y,Call For Machine Learning Models,https://www.reddit.com/r/tensorflow/comments/bo1b8y/call_for_machine_learning_models/,makereven,1557740007,"Developers around the world could submit trained ML models to Model Play. The models should be TensorFlow Lite models and can be compiled to run on the Google Coral Dev Board. Once the model is verified, it will be considered as a qualified model and published on Model Play.

**Rewards**

1PICO-PI-IMX7-START KIT$179

The top 20 participants who submitted the ML model(passed our verification) will get this development board\*1;

2Google Coral USB Accelerator$74.99

Submit 3 ML models (passed our verification) will get 1 Coral USB Accelerator; (Top 100 only)

3Google Coral Dev Board$149.99

Submit 9 ML models (passed our verification) will get 1 Coral Dev Board; (Top 50 only)

&amp;#x200B;

Model Play is a global platform for discovering, sharing, and experiencing easy to use machine learning models. Its compatible with Google Coral Dev Board, with a fast, simple, and small control tool in Model Play app that works with AI hardware.

In Model Play, developers can submit their own trained ML models, subscribe to and download models of their own interest, or retrain models with inspiring and helping developers bring AI into more applications from prototype to product.

&amp;#x200B;

Developers cansetmodelsaspaidorfreefor other users to download and get earnings by the models.(For modelsoffered through ModelPlay, the transaction fee is equivalent to 30% of the price. You receive 70% of the payment. The remaining 30% goes to the distribution partner and operating fees.Paid by PayPal)

**How to Submit**

Submit ML models here[https://model.gravitylink.com/upload-model](https://model.gravitylink.com/upload-model)

(Please refer to this page to see the detailed model requirement)

Model Play offers an open, free, sharing platform, connects you with millions of global AI developers. Now, join Model Play and share your AI ideas and models!",4,0
45,2019-5-13,2019,5,13,23,bo44a2,Is it possible to obtain the pixel coordinate from an object's bounding box using object_detection?,https://www.reddit.com/r/tensorflow/comments/bo44a2/is_it_possible_to_obtain_the_pixel_coordinate/,bolom_sounga,1557757422,"Hi all,

I am using the object_detection code provided in the /research folder and I was able to make it work with my own dataset. However I wanted to know the pixel coordinates of the bounding boxes so I can translate it to my (still in progress) robot pickup arm. I'm trying to make something pickup things from the floor and I am a bit lost as to where I should look at to get the pixel coordinate because I want to translate pixel coordinate to real-space coordinates on an imaginary X-Y grid so i can send the arm to that location.

Thanks!",4,0
46,2019-5-13,2019,5,13,23,bo4hql,The model saved by tensorflow saver is too large,https://www.reddit.com/r/tensorflow/comments/bo4hql/the_model_saved_by_tensorflow_saver_is_too_large/,Laurence-Lin,1557759340,"The tensorflow saver tf.train.Saver() help saves trained model which contains four files:

checkpoint

model.meta

model.index

model.data-00000-of-00001

However, the fourth saved file is too large, which reached 2.9GB. If I want to restore the pre-trained model, these file is disturbing and make me hard to do it on my local computer.   
My question is:

1. Is the fourth file 'model.data-00000-of-00001' necessary to restore the model?
2. What is the reasonable model size of these file? My model is alexnet, and I don't think there should be this large for all variables included within it.  


I expect to test the pre-trained model on my local computer, but in this way I have to test on cloud GPU machine. Thanks for advice!",8,0
47,2019-5-14,2019,5,14,0,bo4ohw,"[HELP] TensorflowJS, how to increase model.fit reliability",https://www.reddit.com/r/tensorflow/comments/bo4ohw/help_tensorflowjs_how_to_increase_modelfit/,WideWorry,1557760209,"Hi,

The problem is that my modell training is work quite good in most of the time and reach Loss/Val loss: \~ 1.4-e8, but it is usually happen that my Loss / Validation Loss stuck at \~5-e6 with the same shuffled training set (50x5 Epoch).  I got \~ 50.000 long tensor arrays, with normalized values.Should I use some dropout layer? Actually I didn't really find any TensorflowJS example how to even use dropout layer with dense layers.

\`\`\`\`

const model = tf.sequential();const optimizer = tf.train.adam();const loss = tf.losses.meanSquaredError;

&amp;#x200B;

model.add(tf.layers.dense({units: 16,inputShape: \[2\],activation: ""elu"",useBias: true}));model.add(tf.layers.dense({units: 16,activation: ""elu"",useBias: true}));model.add(tf.layers.dense({units: 1,activation: ""elu"",useBias: true}));model.compile({optimizer,loss});

&amp;#x200B;

\`\`\`\`

&amp;#x200B;

With the following training:\`\`\`\`

config = {verbose: 1,shuffle: true,epochs: 50,batchSize: 4096,validationSplit: 0.05,stepsPerEpoch: 2,validationSteps: 2,classWeight: 10};

this.model.fit(input\_ts, output\_ts, config);\`\`\`\`",2,1
48,2019-5-14,2019,5,14,4,bo80iv,Bundle of Books on AI and ML with TensorFlow are now discounted,https://www.reddit.com/r/tensorflow/comments/bo80iv/bundle_of_books_on_ai_and_ml_with_tensorflow_are/,MichaelHiggins3,1557775864,,3,4
49,2019-5-14,2019,5,14,9,bobk23,Tensorflow module for the Godot engine (open source game engine),https://www.reddit.com/r/tensorflow/comments/bobk23/tensorflow_module_for_the_godot_engine_open/,ca3games,1557793253,,3,19
50,2019-5-14,2019,5,14,12,bodk4n,Introductory Literature,https://www.reddit.com/r/tensorflow/comments/bodk4n/introductory_literature/,Trien-4,1557804603,"Hello, sorry if posts like these arent welcome. Just curious if any of you here have any introductory literature you recommend? Any help would be appreciated. Thanks!",0,1
51,2019-5-14,2019,5,14,13,boe2gx,Running TensorFlow on AWS Lambda using Serverless,https://www.reddit.com/r/tensorflow/comments/boe2gx/running_tensorflow_on_aws_lambda_using_serverless/,GeraldNwakpu,1557807790,[http://tech.learn4startup.com/8e2de43d4c](http://tech.learn4startup.com/8e2de43d4c),0,4
52,2019-5-14,2019,5,14,14,boek76,High-Level APIs in TensorFlow 2.0,https://www.reddit.com/r/tensorflow/comments/boek76/highlevel_apis_in_tensorflow_20/,qadenza,1557811214,[https://www.youtube.com/watch?v=vTF-Aeej62w](https://www.youtube.com/watch?v=vTF-Aeej62w),1,0
53,2019-5-14,2019,5,14,17,bog84x,Huge accuracy loss while predicting from an image classifier,https://www.reddit.com/r/tensorflow/comments/bog84x/huge_accuracy_loss_while_predicting_from_an_image/,jango1502,1557823102,"I am using 2011 alexnet, trained without any dropout layer, no batch_normalization is used in any layer as well as no other sort of regularization....just to check whether my predict function is correct or not! 

If I predict the model keeping:
1. training = False 
It gives biased result amongst three categories ( model has trained to classify three categories, and in this case its giving 0 for almost any image)

2. Training = True 

Just to check what the model will predict when I keep training is True, model gives almost 33% accuracy on the prediction (with slightly dominance towards the correct category, for e.g if 0 is correct category for 1000 pictures, model predict 400 correctly 0 300 -&gt; 1 and 300 -&gt; 2)

My question is, Is my input to the classifier while training and while prediction are not similar ?
Or 
When I am restoring the model, can be a deciding factor here ? 

I will show the code...its just too big so first I just asked the question to know if something similar happened to anyone before ?",0,1
54,2019-5-15,2019,5,15,0,bokbet,Python Tensorflow tf.concat raising strange error when concatenating 2 tensors,https://www.reddit.com/r/tensorflow/comments/bokbet/python_tensorflow_tfconcat_raising_strange_error/,mikeVell,1557847419,"I don't know if this is the appropriate subreddit or if i should post it in the python subreddit also but when attempting to run my implementation for my thesis i get this strange error.

&amp;#x200B;

    Traceback (most recent call last):
      File ""D:\School\Last_Year\thesis_actual\thesis\thesis_prototype\implementation.py"", line 314, in &lt;module&gt;
        new_tensor = tf.concat([tensor,array_tensor],axis=2)
      File ""D:\School\Last_Year\thesis_actual\thesis\thesis_prototype\venv\lib\site-packages\tensorflow\python\util\dispatch.py"", line 180, in wrapper
        return target(*args, **kwargs)
      File ""D:\School\Last_Year\thesis_actual\thesis\thesis_prototype\venv\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 1271, in concat
        return gen_array_ops.concat_v2(values=values, axis=axis, name=name)
      File ""D:\School\Last_Year\thesis_actual\thesis\thesis_prototype\venv\lib\site-packages\tensorflow\python\ops\gen_array_ops.py"", line 1378, in concat_v2
        _six.raise_from(_core._status_to_exception(e.code, message), None)
      File ""&lt;string&gt;"", line 3, in raise_from
    tensorflow.python.framework.errors_impl.InvalidArgumentError: ConcatOp : Expected concatenating dimensions in the range [0, 0), but got 2 [Op:ConcatV2] name: concat

The code that is causing this error is below.   


    new_validation = copy.deepcopy(validation)
    float_validation = [[]]
    for data in new_validation:
        new_ident = float(data[0])
        new_converted_values = []
        for values in data[1][0]:
            new_converted_values.append(float(values))
        new_converted_values = np.asarray(new_converted_values)
        float_validation.append((new_ident,new_converted_values))
    float_validation.pop(0)
    
    
    tensor = None
    array_tensor = None
    dummy_tensor = tf.convert_to_tensor(0.0,dtype=tf.float32)
    dummy_tensor_2 = tf.convert_to_tensor(0.0,dtype=tf.float32)
    dataset = tf.data.Dataset.from_tensors(tensors=(dummy_tensor,dummy_tensor_2))
    for row in float_validation:
        print(row[0])
        tensor = tf.convert_to_tensor(row[0], dtype=tf.float32)
        array_tensor = tf.convert_to_tensor(row[1],dtype=tf.float32)
        new_tensor = tf.concat([tensor,array_tensor],axis=2)
        # dataset = dataset.concatenate(tf.data.Dataset.from_tensors(tensors=(tensor,array_tensor)))
        dataset = dataset.concatenate(tf.data.Dataset.from_tensors(tensors=(new_tensor)))",4,1
55,2019-5-15,2019,5,15,2,bolssw,"Reimplementations of several generative models in Tensorflow 2.0 (VAE, DCGAN, WPGAN-GP, Seq2Seq, VAEGAN, GAIA, spectrogramming iterator/inversion) with links to self-contained colab notebooks.",https://www.reddit.com/r/tensorflow/comments/bolssw/reimplementations_of_several_generative_models_in/,timburg,1557854502,,0,23
56,2019-5-15,2019,5,15,14,bou2j0,Can anyone help out in creating video dataset loader using tensorflow?,https://www.reddit.com/r/tensorflow/comments/bou2j0/can_anyone_help_out_in_creating_video_dataset/,sayooj_bala,1557899744,I have been trying to reproduce papers using tensorflow. But the issue is I always face problems in creating dataloaders for custom dataset. I generally get through this  by searching github repos. But i wanna start implementing custom data loaders from scratch on my own. Can anyone of you provide links or some great tutorials or even if any book is available to clearly get an idea of creating my own custom dataloaders in tensorflow. Specifically it would be great if you could send me some video dataloader codes links which I should refer for my current project.,6,2
57,2019-5-15,2019,5,15,16,bouqgk,numpy spacing equivalent,https://www.reddit.com/r/tensorflow/comments/bouqgk/numpy_spacing_equivalent/,RemoteReindeer,1557904537,"Hello.

&amp;#x200B;

I'm looking for a function similar to the [numpy.spacing](https://docs.scipy.org/doc/numpy/reference/generated/numpy.spacing.html) in tensorflow. The numpy function isn't compatible with tensorflow (np.spacing(0, dtype=np.float32) + 0 = 0).",1,3
58,2019-5-16,2019,5,16,1,bozw8e,Beginner question about joint distributions in TensorFlow Probability,https://www.reddit.com/r/tensorflow/comments/bozw8e/beginner_question_about_joint_distributions_in/,xalelax,1557936851,"Hi! I am learning TensorFlow Probability and as a test I would like to do the following thing:

&amp;#x200B;

I want to generate 2D random samples (x,y) for which

  \* x is uniformly distributed from 1 to 10

  \* y is a normal with mean x and standard deviation x 

&amp;#x200B;

Now, I could define x = tfd.Uniform(low=1, high=10) and then inside a for loop sample this distribution, and then build the y distribution as y =  tfd.Normal(loc=x, scale=x) (here, tfd = tfp.distributions); somehow this approach does not seem correct to me.

&amp;#x200B;

I am sure there is a cleaner way to do this without building a  tfd.Normal for each sample; am I wrong? How would you do it? 

&amp;#x200B;

Many thanks in advance!",6,1
59,2019-5-16,2019,5,16,4,bp25mx,Sharing wisdom on the data ingestion workflow,https://www.reddit.com/r/tensorflow/comments/bp25mx/sharing_wisdom_on_the_data_ingestion_workflow/,krishnab75,1557947785,"Hey Folks. I was hoping people could share some wisdom on the managing the data ingestion workflow. 

&amp;#x200B;

**So here is the challenge.** You get a new imagery segmentation dataset--both images and labels. Of course there is a lot of preprocessing required to get the data read to run in tensorflow, but the question is how to best to handle ingesting the data into Tensorflow--with the augmentations. I am trying to find the right balance between keeping the interfaces simple and debuggable, versus premature optimization.

&amp;#x200B;

My sense is to use Method 2 below. But I am still relatively new to the Tensorflow world, so I don't have a clear sense of how other people manage their workflows. Hence I was hoping someone could suggest any improvements or better ways to do stuff.

&amp;#x200B;

**Method 1: Bunch of image files**

There seem to be two reliable ways to do this. (I will explain why other methods seem so problematic.) First, I could pre-process the images and the labels and then save those individuals files to different directories on the computer. There is probably a lot of preprocessing required, especially to get the label format converted to masks, etc. Now that I have the individual files, I would import those files into tf.Keras using the \`flow\_from\_directory\` method. The advantage here is that I can use the data augmentation tools in keras \`ImageDataGenerator\` to augment the images before training some small batches.  I can use the \`flow\_from\_directory\` method to run the \`model.fit\_generator()\` method and train the model.

&amp;#x200B;

The advantage of this approach is that it creates individual files that are easy to look at. So I can see that the masks and such look good. The problem is that I have huge number of files to track, and I have to make sure that the file names match between image and label. The disadvantage is that I would likely do the augmentations in \`tf.Keras\`, otherwise the number of files created would be really huge. So the augmentations will slow down training. 

&amp;#x200B;

**Method 2: Direct to TFRecords**

The second reliable way seems to be preprocessing all of the data and pushing it into a TFRecords file right away, including the augmentations. In this case, I would pre-process the images and labels, implement the augmentations in the pre-processing pipeline, and then write the augmented images and labels to the TFRecords format. Then I could simply import the TFRecords data as a \`tf.Dataset\` and with a simple parse function create the batches. Then i could pass the batches to the \`tf.Keras\` \`[model.fit](https://model.fit)()\` function by passing the \`tf.Dataset\` or corresponding iterator (though the iterator might not be needed anymore). 

&amp;#x200B;

The advantage of this method is that it limits the number of files to track--since I just have a few TFRecords to worry about. Also, I have a better guarantee that the labels and images match--as long I check that the TFRecords writing was done correctly. I can also just implement all of the augmentations while generating the TFRecords files, so that will accelerate the training process. The hardest thing about this approach is that it is hard to read TFRecords files, so it is harder to catch errors, etc. But there is one consolation--the code to import the TFRecords file and parse it has to be written anyway. So you can just test the validity of the TFRecords data by just ingesting it and then writing some matplotlib commands to plot the image and masks and make sure they align.

&amp;#x200B;

Now, there are a bunch of other ways to do the same thing, but they all seem to either add a lot of complexity without much benefit. Let me review a few of these, just for completeness.

&amp;#x200B;

1. Create a tf.Dataset from tensor\_slices. So I could pre-process all the labels and images into separate files. Then I could take all of the file paths and use \`tensor\_from\_slices\` to create a new dataset. Then I would need to manually write a bunch of augmentation functions in tensorflow and \`.map()\` these onto each example. Finally I could create the batches and run the training. The problem with this is that the \`tensor\_from\_slices\` approach seems a lot more complicated than the keras \`flow\_from\_directory\` approach, so I would probably use that anyway. Plus the advantage of flow\_from\_directory approach is that I can use the ImageDataGenerator for augmentation and don't have to reinvent the wheel and write my own augmentation functions. 
2. Create a TFRecords file without any augmentations. Then ingest the dataset with the tf.Dataset api and then manually write the augmentation functions in tensorflow and then again \`.map()\` them to the tf.Dataset. This again seems more complex than it needs to be, since you again have to reinvent the wheel and write a bunch of augmentation functions that are already implemented in Keras. 

&amp;#x200B;

As a caveat, don't get me wrong, I don't mind writing my own augmentation functions. In my past workflows I have done that and it works fine. But having all of those augmentation function really clutters up my jupyter notebook, and creates lots dependencies between code that can break later; meaning, that I have to write the augmentation functions, then write additional functions that wrap all the augmentations into a single function for the \`.map()\` function, and more. 

&amp;#x200B;

So if I am totally off and totally overthinking this, then please let me know. How does everyone else handle this initial workflow.",5,1
60,2019-5-16,2019,5,16,4,bp2e8d,"Notebooks for my ""Deep Learning with TensorFlow 2 and Keras"" course",https://www.reddit.com/r/tensorflow/comments/bp2e8d/notebooks_for_my_deep_learning_with_tensorflow_2/,asuagar,1557948932,,0,1
61,2019-5-16,2019,5,16,4,bp2f28,"Notebooks for ""Deep Learning with TensorFlow 2 and Keras"" by Aurlien Geron",https://www.reddit.com/r/tensorflow/comments/bp2f28/notebooks_for_deep_learning_with_tensorflow_2_and/,asuagar,1557949046,,1,33
62,2019-5-17,2019,5,17,19,bppnmj,Quantum Simulator Gets TensorFlow Backend,https://www.reddit.com/r/tensorflow/comments/bppnmj/quantum_simulator_gets_tensorflow_backend/,ebb101,1558089887,"Quantum simulator Qubiter now has a native TensorFlow backend.

For details, you can check out the blog post on it here: [https://wp.me/pjqkF-38S](https://wp.me/pjqkF-38S)

You can check out Qubiter here: [https://github.com/artiste-qb-net/qubiter](https://github.com/artiste-qb-net/qubiter)",0,1
63,2019-5-18,2019,5,18,7,bpxili,How should I approach this problem?,https://www.reddit.com/r/tensorflow/comments/bpxili/how_should_i_approach_this_problem/,Viidas42,1558131239,"Hi.
So I have a problem that needs to be solved as I'm new to tensorflow and machine learning I thought this would be a good place to start. 

I have a bunch of inputs.
Each input has data in the form of an array. 
Example data is distanceFromRoad and temperature altitude and so on and so forth. The data is all independent. 
I want to teach a model using this data but the problem comes in when I don't have outputs. 
Well I do but each input will always have an output of 100 percent or 1.0.
So each input with that inputs data had a probability of an event occurring there but that event did happen there so probability is 1
This is a classification problem. 
Either it happened or it didn't happen. 
Problem is I don't have data for where it didn't happen. 
How would I train the model to predict if the event has a probability of occurring at a position where inputs match a pattern?",5,2
64,2019-5-18,2019,5,18,17,bq1qsc,How to Generate Game of Thrones Characters Using StyleGAN,https://www.reddit.com/r/tensorflow/comments/bq1qsc/how_to_generate_game_of_thrones_characters_using/,iyaja,1558169028,,0,1
65,2019-5-20,2019,5,20,4,bql4po,Developing a Robust Face Generative Adversarial Network with Tensorflow,https://www.reddit.com/r/tensorflow/comments/bql4po/developing_a_robust_face_generative_adversarial/,ailearn12,1558295089,,0,7
66,2019-5-20,2019,5,20,4,bql5sg,How Neural Networks Work- Simply Explained,https://www.reddit.com/r/tensorflow/comments/bql5sg/how_neural_networks_work_simply_explained/,ailearn12,1558295240,,1,3
67,2019-5-20,2019,5,20,5,bqln3k,Machine Learning and Data Science with Kaggle,https://www.reddit.com/r/tensorflow/comments/bqln3k/machine_learning_and_data_science_with_kaggle/,ailearn12,1558297755,,0,11
68,2019-5-20,2019,5,20,6,bqmc0m,ML Ops: Deploy TensorFlow models with Istio on Kubernetes,https://www.reddit.com/r/tensorflow/comments/bqmc0m/ml_ops_deploy_tensorflow_models_with_istio_on/,masroorhasan,1558301317,"Machine Learning (ML) operational challenges have evolved with the development of ML and infrastructure frameworks and tools. Recently worked on and wrote up a post on setting up a ML (TensorFlow) *serving* infrastructure on a Kubernetes environment and managing deployments by leveraging Istio's traffic management features. The post goes over the following:

1. Setting up an infrastructure stack with Kubernetes, Istio and TensorFlow Serving
2. Deploying TensorFlow models on Istio-enabled cluster by performing staged rollouts
3. Handle model upgrades and deployments with canary style deployments
4. Automating canary rollouts with Flagger K8s operator

[https://medium.com/@masroor.hasan/deploy-tensorflow-models-with-istio-on-kubernetes-dd0b2bd3e388](https://medium.com/@masroor.hasan/deploy-tensorflow-models-with-istio-on-kubernetes-dd0b2bd3e388)

Would love to hear any feedback or how anyone else sets up their ML serving infrastructure!",0,1
69,2019-5-20,2019,5,20,7,bqmry5,Bunch of Machine Learning books including TensorFlow are on sale now,https://www.reddit.com/r/tensorflow/comments/bqmry5/bunch_of_machine_learning_books_including/,RodneyKelly,1558303599,,3,7
70,2019-5-20,2019,5,20,8,bqngjq,Does anyone else find the links at the top of the TF documentation website annoying?,https://www.reddit.com/r/tensorflow/comments/bqngjq/does_anyone_else_find_the_links_at_the_top_of_the/,clanleader,1558307303,"Every time I go to change tabs whilst reading the online documentation a drop down menu appears, sometimes stuck in place, and to continue scrolling on the documentation I have to move away from that. I find this incredibly annoying when following a tutorial. Tensorflow is the only website I've encountered that does this. Is it just me?",0,5
71,2019-5-20,2019,5,20,11,bqp8cs,Making a pipeline / Feeding data to Tensorflow,https://www.reddit.com/r/tensorflow/comments/bqp8cs/making_a_pipeline_feeding_data_to_tensorflow/,DataStructuresGenius,1558317918,"Recently I have scraped some images for an image identifier and I want to feed it to Tensorflow the same way the MNIST data is fed with TF 2.0. There are also google api's of data sets, like the flower datasets, that have methods where you just input a url in a method and TF processes that. Is there a way that I can do something similar in either scenario for a custom dataset?",3,5
72,2019-5-20,2019,5,20,15,bqs0pc,where to but Google coral products? Here it is!,https://www.reddit.com/r/tensorflow/comments/bqs0pc/where_to_but_google_coral_products_here_it_is/,makereven,1558334338,,4,0
73,2019-5-20,2019,5,20,16,bqsced,Want to get started with Tensorflow,https://www.reddit.com/r/tensorflow/comments/bqsced/want_to_get_started_with_tensorflow/,Eitamr,1558336701,"Hi!  


I want to start using Tensorflow (mainly for image recognition using genetic algorithm).  
I already know golang and C#.  
I wanted to ask the following:  
1)Should I learn python?  
2)I am going to buy Server to my house , does Tensorflow image support clustering well? or should I run single container?  
3)Is it preferable to buy 2 strong graphic cards(2060) or 1 2080?  
Thanks!",6,6
74,2019-5-21,2019,5,21,0,bqwzsr,How do I export a small model without using freeze graph?,https://www.reddit.com/r/tensorflow/comments/bqwzsr/how_do_i_export_a_small_model_without_using/,veqtor,1558366117,"Currently freeze\_graph is broken for keras and other embedding layers, so I cannot use it, but my model is 1GB when exported which is much too big to work in production (we need to spawn up small nodes that can do inference more or less on the fly and loading a 1GB model is too slow)

&amp;#x200B;

IDK what to do, I've spent weeks developing this model so my boss is breathing down my neck, I'm thinking I will use PyTorch in the future... :/",5,2
75,2019-5-21,2019,5,21,1,bqxii6,What's the rule of thumb for deciding the NN's nodes number / layers number / hyperparameters?,https://www.reddit.com/r/tensorflow/comments/bqxii6/whats_the_rule_of_thumb_for_deciding_the_nns/,tmpxyz,1558368542,"I'm just getting into the machine learning and am playing with basic algorithms on openAI gym envs.

The q-learning/sarsa is quite straightforward, but the NN is kinda hard to grasp. 

For example, the [Cartpole](https://gym.openai.com/envs/CartPole-v1/) with [6, 6] hidden layers performs extremely bad, while [24, 24] kinda works well.

Is there some guideline for NN besides trial and fail?",2,2
76,2019-5-21,2019,5,21,3,bqzdc7,Images of different size as input to Keras CNN,https://www.reddit.com/r/tensorflow/comments/bqzdc7/images_of_different_size_as_input_to_keras_cnn/,roset_ta,1558377196,"Hello,


This is a noob question. Is it possible to give images of different sizes as input to a CNN in Keras?

I have some images in the form of numpy arrays, with various shapes. Normally I know I need to read the images as numpy arrays, possibly concatenate them to one single numpy array (x_train) and define the input shape for the CNN, for example (32,32,1). But how to do that for different image sizes? Thanks",21,5
77,2019-5-21,2019,5,21,8,br2q9v,Image Classification with Tensorflow 2.0,https://www.reddit.com/r/tensorflow/comments/br2q9v/image_classification_with_tensorflow_20/,mycall,1558393489,,2,28
78,2019-5-21,2019,5,21,9,br3ch8,Prefetching,https://www.reddit.com/r/tensorflow/comments/br3ch8/prefetching/,isthisathrowawaay,1558396958,Training with large 3d images so loading each batch takes an enormously long time. I seem to get significant speedup if I just load an entire chunk of my dataset into memory  and then take slices versus using a conventional generator approach. Is there a better way?,0,1
79,2019-5-21,2019,5,21,13,br67a7,My implementation of 7 knowledge distillation methods by Tensorflow,https://www.reddit.com/r/tensorflow/comments/br67a7/my_implementation_of_7_knowledge_distillation/,sseung0703,1558414542,[removed],0,1
80,2019-5-22,2019,5,22,10,briuei,Error: no operation named input in the graph,https://www.reddit.com/r/tensorflow/comments/briuei/error_no_operation_named_input_in_the_graph/,jimmothy_theunicorn,1558489554," 

I am running tensorflow with react native. I have a retrained Inception V3 graph. I used a GitHub repo example to test if a model other than my own would work, and it functioned perfectly well. When I attempt to use my own model, I get the Error:

&gt;""No Operation named \[input\] in the graph""

Dev InfoPython 3.5  
, react-Native 0.59  
, tensorflow 1.4  
, protobuf 3.0.1

Here is the recognition code:

    async recognizeImage() { try {   const tfImageRecognition = new TfImageRecognition({     model:require('./assets/retrained_graph.pb'),     labels: require('./assets/retrained_labels.txt') })    const results = await tfImageRecognition.recognize({     image: this.image   }) }",2,1
81,2019-5-22,2019,5,22,17,brm1k5,"Inspecting TensorFlow Lite image classification model  Think, mobile!",https://www.reddit.com/r/tensorflow/comments/brm1k5/inspecting_tensorflow_lite_image_classification/,frogermcs,1558512871,,0,9
82,2019-5-23,2019,5,23,9,brwoi9,"TF2 Quantization, uint16 works, but not uint8",https://www.reddit.com/r/tensorflow/comments/brwoi9/tf2_quantization_uint16_works_but_not_uint8/,alew3,1558572474,"I have been testing TensorflowJS and quantization of models with TF2 Nightly.

After I train a model in Tensorflow, I can convert it to uint8 and uint16

uint16 works fine, but uint8 just doesn't work. I was expecting it to be less precise, but the predictions are totally wrong. Anybody have experiece with this?

I'm running the following commands to quantize and convert model:

tfjs.converters.save\_keras\_model(model, ""models\_tfjs/q16"",quantization\_dtype=np.uint16)

tfjs.converters.save\_keras\_model(model, ""models\_tfjs/q8"",quantization\_dtype=np.uint8)",0,1
83,2019-5-23,2019,5,23,12,bryctz,Do TFLite models usually contain fewer operations?,https://www.reddit.com/r/tensorflow/comments/bryctz/do_tflite_models_usually_contain_fewer_operations/,goppox,1558582460,"I was wondering if a `tflite` model should contain fewer operations than the original `tf` model. Clearly, `tflite` models are smaller in size, but I believe that's (mostly) because of the use of `FlatBuffers`. But does `tflite_convert` perform any form of optimisation that reduces the number of operations?",0,1
84,2019-5-23,2019,5,23,15,brzolx,The super-simple guide to installing TensorFlow-GPU on Windows 10,https://www.reddit.com/r/tensorflow/comments/brzolx/the_supersimple_guide_to_installing_tensorflowgpu/,sfsdfd,1558593999,"I installed TensorFlow on one machine (a Mac). It installed perfectly, and ran well, right up to the point where I needed to switch to a GPU for training deeper nets.

My Mac has a GPU... by AMD. Apparently, TensorFlow-GPU really isn't built for AMD GPUs, because it's meant to run through CUDA which is NVIDIA-only, and you can get around it by installing some kind of middleware and - ... long story short, it didn't work.

I also have a Windows machine with a powerful NVIDIA GPU (EVGA 1080). Not as convenient - it's across the room, so I have to terminal-services into it - but acceptable if I just use it for training.

So I embarked on the path of installing tensorflow-gpu, which was super-simple except for the fact that it didn't work because the current pile of software dependencies is broken, and has been broken since *at least last October*.

For posterity, here are my notes.

===

Windows 10 TensorFlow Nvidia GPU Setup

* Step 1. Find this guide:
  https://towardsdatascience.com/installing-tensorflow-with-cuda-cudnn-and-gpu-support-on-windows-10-60693e46e781

* Step 2. Install Python 3:

	https://www.python.org/downloads/

* Step 3. Download and install Microsoft Visual Studio Express:

	https://visualstudio.microsoft.com/vs/express/

* Step 4. Download and install the Nvidia CUDA Toolkit:

	https://developer.nvidia.com/cuda-toolkit

* Step 5. Download Nvidia cuDNN:

	https://developer.nvidia.com/cudnn

    Unzip it (it will contain only three files) and put them here:

	cudnn64_7.dll

		C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\bin

	cudnn.h

		C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\include

	cudnn.lib

		C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\lib\x64

* Step 6. Verify environment variables:

	Access Control Panel (via search... note: don't run Settings; Windows 10 tries to force you into that, but it doesn't have the right interface)

	System / Advanced System Settings / Environment Variables
	
	Ensure that Path includes the bin and libnvvp subfolders of the NVIDIA folder above, as well as Python37 (before any other Python interpreters if others are installed)

	Apparently it helps to put add this to Path:
		C:\Users\[username]\AppData\Roaming\Python\Python37\Scripts into 

	Ensure that CUDA_PATH and CUDA_PATH_V10_1 are present and set to the base folders above

* Step 7. Upgrade pip:

	pip3 install --user --upgrade pip

* Step 8. Install tensorflow-gpu:

	pip3 install --user tensorflow-gpu

* Step 9. All done, time to test python install

        python -c ""import tensorflow""

* Step 10. Encounter lengthy error message ending in:

  ImportError: DLL load failed: The specified module could not be found.
  
* Step 11. Google error message and find 130-comment-long complaint thread on GitHub started last year, with lots of ""this worked for me"" solutions that involve downgrading tensorflow or downgrading Python, etc. ... closed without resolution... find lots of other threads started more recently and also closed without resolution

	https://github.com/tensorflow/tensorflow/issues/22794

* Step 12. Summary:

	TensorFlow-GPU 2.0 does not work with CUDA v10.1. Options:
	
	(a) Downgrade CUDA 10.1 to 10.0. Move those files out of the CUDA folder, uninstall CUDA 10.1 (all five packages) via control panel, download CUDA 10.0 from the Archival section of Nvidia, reinstall it, reset environment paths, move files back into folder. No guarantees about compatibility with up-to-date cards or... anything, really.
	
	(b) Build TensorFlow-GPU from source using a lengthy and painful process that will probably break halfway through and leave your libraries in an inconsistent state.
	
	(c) Dump Python, install Anaconda as an alternative interpreter that may or may not work the same, and download tensorflow-gpu from there.
	
	(d) Abandon this project until somebody fixes their shit and this whole shitty architecture starts working again.

===

I'm going with option (d) for now.",38,16
85,2019-5-23,2019,5,23,22,bs2wa7,In need of an Explanation! Can TensorFlow do this? What resources to learn towards my goal?,https://www.reddit.com/r/tensorflow/comments/bs2wa7/in_need_of_an_explanation_can_tensorflow_do_this/,Saik1992,1558617796,"Hey tensorflow subreddit! I'm currently developing a web app for a game and I've got this Idea for a feature.

&amp;#x200B;

Bit of corner data: The game is a MMORPG and - as in many other MMORPGS - you can use Skills in Combat. Now there's alot of Theorycrafting on that matter and I've had the Idea to see what a ML Algorithm could come up with - and how effective it might be.  


There's quite a bit of Info to count in. First off, each Skill has a individual amount of Damage it does before actual damage calculations taking gear into concern - that's named potency. Then it has a Cooldown. Some skills are buffs which will change either Skills over a timeframe or an Amount of Skills followed after. That's the VERY basics.  


I'd like that AI to take those values into consideration and come up with a x seconds timeframe that has the highest Potency. So, with all that Info, where would I start learning? Can I do this with TensorFlow? I've seen Videos, namely from Coding Bullet, where he makes a game and teaches a ML Algorithm to play it - where do I start to get to there?  


ML still feels very mysterious to me (I've done a Google's ML Crash Course already but that doesnt really crack the mystery)",1,0
86,2019-5-24,2019,5,24,0,bs4ane,Docker: TensorFlow Ubuntu18.04 Universal (GPU/CPU),https://www.reddit.com/r/tensorflow/comments/bs4ane/docker_tensorflow_ubuntu1804_universal_gpucpu/,gasparka,1558625154,"Notable Upgrades:

1. Python 3.6.7
   1. Support ""f-strings"" ([PEP498](https://www.python.org/dev/peps/pep-0498/))
   2. Support variable annotations ([PEP526](https://www.python.org/dev/peps/pep-0526/))
   3. Support Data Classes ([PEP557](https://www.python.org/dev/peps/pep-0557/))
2. Support GPU and CPU in single image (credits to @tillahoffmann)

Train MNIST on CPU:

    docker run gasparka/tensorflow-ubuntu18.04-universal

Train MNIST on GPU:

    docker run --runtime=nvidia gasparka/tensorflow-ubuntu18.04-universal

[https://hub.docker.com/r/gasparka/tensorflow-ubuntu18.04-universal/](https://hub.docker.com/r/gasparka/tensorflow-ubuntu18.04-universal/)",1,13
87,2019-5-24,2019,5,24,5,bs7oy2,Running 2 Neural Networks on the browser with TensorflowJS + ThreeJS model with shaders. Code and live demo included.,https://www.reddit.com/r/tensorflow/comments/bs7oy2/running_2_neural_networks_on_the_browser_with/,alew3,1558642429,,1,0
88,2019-5-24,2019,5,24,5,bs7rf7,"Applied case with image data sourced from MS Azure, k-means for cleanup",https://www.reddit.com/r/tensorflow/comments/bs7rf7/applied_case_with_image_data_sourced_from_ms/,jpwalton,1558642781,,0,3
89,2019-5-24,2019,5,24,5,bs7rhw,How to read and respond to tflite from model perspective?,https://www.reddit.com/r/tensorflow/comments/bs7rhw/how_to_read_and_respond_to_tflite_from_model/,andyalbert,1558642792,"I'm new to Tensorflow and Keras, I've managed to train a model successfully, now I want to save it and use it on Android using tflite.

However, I can't find any topic talking about how to read and write input from the model perspective, they all talk about how to send and receive from the device, but what about the model? I need to preprocess the data and send it when it's done, I do that using reading from files, how can I change it so that it read and write to the mobile interpreter for tf?",0,1
90,2019-5-24,2019,5,24,11,bsbotv,Creating Chatbots Tutorial Using TensorFlow 2.0,https://www.reddit.com/r/tensorflow/comments/bsbotv/creating_chatbots_tutorial_using_tensorflow_20/,qadenza,1558665937,**You will learn how to build a transformer chatbot using TensorFlow 2.0** [http://dev.edupioneer.net/7a67366fa6](http://dev.edupioneer.net/7a67366fa6),4,9
91,2019-5-24,2019,5,24,18,bsexfg,submit your trained models and get coral dev board as reward!,https://www.reddit.com/r/tensorflow/comments/bsexfg/submit_your_trained_models_and_get_coral_dev/,makereven,1558691455," yep, it's a reward competition, submit your trained models

**Model Play is now calling for ML models. Submit your ML models and earn revenue** **per download on Model Play**

**Rewards**

1PICO-PI-IMX7-START KIT$179

The top 20 participants who submitted the ML model(passed our verification) will get this development board\*1;

2Google Coral USB Accelerator$74.99

Submit 3 ML models (passed our verification) will get 1 Coral USB Accelerator; (Top 100 only)

3Google Coral Dev Board$149.99

Submit 9 ML models (passed our verification) will get 1 Coral Dev Board; (Top 50 only)

Developers around the world could submit trained ML models to Model Play. The models should be TensorFlow Lite models and can be compiled to run on the Google Coral Dev Board.",2,7
92,2019-5-24,2019,5,24,22,bsh4x5,How to pre process the inputs for tf lite,https://www.reddit.com/r/tensorflow/comments/bsh4x5/how_to_pre_process_the_inputs_for_tf_lite/,andyalbert,1558705633,"I've trained my model on colab, now I'll convert the model to tflite file, but I've to pre process the data before sending it to the model, the preprocessing is using cv2 and PIL, what should I do then? As these libraries isn't easy to be found on Java",0,1
93,2019-5-24,2019,5,24,23,bshitf,Setting up TensorFlow on AWS Lambda for serverless apps.,https://www.reddit.com/r/tensorflow/comments/bshitf/setting_up_tensorflow_on_aws_lambda_for/,The_Real_Slim_Shady_,1558707721,,0,2
94,2019-5-25,2019,5,25,5,bslvei,Balancing GPU memory and processing usage?,https://www.reddit.com/r/tensorflow/comments/bslvei/balancing_gpu_memory_and_processing_usage/,SlimShabby,1558729958,"I'm training a GAN for images and have implemented mixed precision. This halves my memory usage and also the impact of instructions as they're 16 bit floats now. I now notice that only half of my GPU is active. My memory is filled by increasing my batch size, but I take it that I need an even bigger batch size to reach 100% GPU utilization. Is there another way to up the GPU utilization and shorten my training?  
Another thing is that halving the width and height and increasing the batch size by factor 4, does not seem to yield a factor 4 of images processed per second. How come?  
Side question: is tensorflow supposed to utilize 40% of all my CPU cores, even though I'm only running on GPU?",0,1
95,2019-5-25,2019,5,25,8,bsns01,How to convert binary protobuf to text,https://www.reddit.com/r/tensorflow/comments/bsns01/how_to_convert_binary_protobuf_to_text/,jimmothytheunicorn,1558739934,"I have a graph def model, and it reads as a binary file. How do I convert to text? I can answer any questions in comments... thanks!",0,3
96,2019-5-25,2019,5,25,15,bsrnv5,Tensorflow 2 (alpha) available on CoCalc,https://www.reddit.com/r/tensorflow/comments/bsrnv5/tensorflow_2_alpha_available_on_cocalc/,phatsphere,1558767394,,2,3
97,2019-5-25,2019,5,25,17,bss56t,Stylizer: Image to Image transformation experiments,https://www.reddit.com/r/tensorflow/comments/bss56t/stylizer_image_to_image_transformation_experiments/,suyash93,1558771631,[removed],0,1
98,2019-5-25,2019,5,25,17,bssa8t,Advice on import Tensorflow into Processing.py?,https://www.reddit.com/r/tensorflow/comments/bssa8t/advice_on_import_tensorflow_into_processingpy/,Popup4t4,1558772945,"I'm quite new to the whole ML scene but im trying to eventually create a Neural Net to produce commands in a game produced in Processing to start. First problem: I can't import tensor flow into processing for some reason.

Error: 

&amp;#x200B;

ImportError: No module named tensorflow

processing.app.SketchException: ImportError: No module named tensorflow

	at jycessing.mode.run.SketchRunner.convertPythonSketchError([SketchRunner.java:242](https://SketchRunner.java:242))

	at jycessing.mode.run.SketchRunner.lambda$2([SketchRunner.java:119](https://SketchRunner.java:119))

	at [java.lang.Thread.run](https://java.lang.Thread.run)([Thread.java:748](https://Thread.java:748))

&amp;#x200B;

Ideally I would be able to use Processing's functions in an IDE like PyCharm which I am familiar with, but ill lean whichever way is easiest to combine the two. If anyone has any advice I'd really appreciate it.",1,1
99,2019-5-26,2019,5,26,0,bsvxfw,Stylizer: Image to Image transformation experiments,https://www.reddit.com/r/tensorflow/comments/bsvxfw/stylizer_image_to_image_transformation_experiments/,suyash93,1558799145,,0,1
100,2019-5-26,2019,5,26,2,bsxg3n,Bunch of books on Machine Learning with TensorFlow are on sale for 48h more,https://www.reddit.com/r/tensorflow/comments/bsxg3n/bunch_of_books_on_machine_learning_with/,MichaelHiggins3,1558807191,,0,1
101,2019-5-26,2019,5,26,3,bsxgz0,Bunch of books on Machine Learning with TensorFlow are being discounted for 48hours more,https://www.reddit.com/r/tensorflow/comments/bsxgz0/bunch_of_books_on_machine_learning_with/,PhyllisErrico,1558807315,,1,8
102,2019-5-26,2019,5,26,10,bt29k7,Question about tf.assign,https://www.reddit.com/r/tensorflow/comments/bt29k7/question_about_tfassign/,Zizzy1110,1558834261,"Hi all, I'm new to tensorflow and need some help about using tf.assign() function to assign values of one tf.Variable to another one. 

For example, if I want to assign the value of 'B' to 'A'. I know that if we use:

assign\_op = tf.assign(A, B)

We also have to run:

tf.Session().run(assign\_op) to update the value.

&amp;#x200B;

My question is, what if we use:

A = tf.assign(A, B)?

Do we still need other commands to update the value? I appreciate your help!",2,1
103,2019-5-26,2019,5,26,15,bt4qjh,How to use shared_embeddings in tf2,https://www.reddit.com/r/tensorflow/comments/bt4qjh/how_to_use_shared_embeddings_in_tf2/,thinkdoom,1558851734,"[shared\_embeddings](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/shared_embeddings) not surport eager mode,  so i call it with @tf.function,  but still throw exception: 

ValueError: Variable color\_color2\_color3\_shared\_embedding already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO\_REUSE in VarScope?

How to fix it to make the code runable in tf2.

    import tensorflow as tf
    from tensorflow import feature_column
    
    @tf.function
    def shared_embedding_column_with_hash_bucket():
        color_data = {'color': [[2], [5], [-1], [0]],
                      'color2': [[2, 2], [5, 5], [0, -1], [0, 0]],
                      'color3': [[2,2,2], [5,5,5], [-1,-1,-1], [0,0,0]]
                     }
        color_column = feature_column.categorical_column_with_hash_bucket('color', 5, dtype=tf.int32)
        color_column2 = feature_column.categorical_column_with_hash_bucket('color2', 5, dtype=tf.int32)
        color_column3 = feature_column.categorical_column_with_hash_bucket('color3', 5, dtype=tf.int32)
        color_column_embed = tf.feature_column.shared_embeddings([color_column, color_column2, color_column3], 4, combiner='sum')
        print(color_column_embed)
        print(type(color_column_embed))
        print('use input_layer' + '_' * 40)
        df =  tf.keras.layers.DenseFeatures(color_column_embed)(color_data)
        return df
    
    dense = shared_embedding_column_with_hash_bucket()
    print(dense)",0,1
104,2019-5-26,2019,5,26,20,bt6vip,This video goes over a breast cancer diagnosis model that uses neural networks (implemented in python),https://www.reddit.com/r/tensorflow/comments/bt6vip/this_video_goes_over_a_breast_cancer_diagnosis/,antaloaalonso,1558870188,,2,14
105,2019-5-27,2019,5,27,1,bta1ym,TF Benchmark Suggestions,https://www.reddit.com/r/tensorflow/comments/bta1ym/tf_benchmark_suggestions/,ir88ed,1558888905,"Our group has built a rig with three GPUs in it.  While I am quite familiar with the hardware side of things, I am a novice when it comes to TF, and am still learning.  We have a collaborator who will be running the ML on this box, but I would like to test it out to make sure there are no issues when he throws heavy workloads at it.  I have successfully installed tensorflow GPU, and have run the cifar10\_multi\_gpu\_train.py training on the three gpus.  In nvidia-smi, I only see about 40% utilization of each of the GPUs and am getting 50-60k examples/sec.    Is there a more demanding benchmark that will utilize 100% of the gpus?",10,3
106,2019-5-27,2019,5,27,3,btblep,"[TFJS] My NodeJS implementation of the TensorflowJS, with many examples and Python like structure.",https://www.reddit.com/r/tensorflow/comments/btblep/tfjs_my_nodejs_implementation_of_the_tensorflowjs/,WideWorry,1558896692,"Hi,   
I would like to share my TensorflowJS implementation under NodeJS, I didn't really find any implementation on Github which follow the simplicity of the Python/Keras implementation.  My idea were to separate the Modell compile to be able copy Keras modells as fast it is possible.    


[https://github.com/Palabola/StockML-TF](https://github.com/Palabola/StockML-TF)  


I will add Sample datas later and other Modells as I have progression. I hope it will improve a bit the NodeJS usage of the Tensorflow which is great and easely outperform the competitors in speed.",1,6
107,2019-5-27,2019,5,27,4,btc6pk,What is the difference between the targets and goals of Swift for Tensorflow and Tensorflow 2.0?,https://www.reddit.com/r/tensorflow/comments/btc6pk/what_is_the_difference_between_the_targets_and/,RealMatchesMalonee,1558899590,Seems to me that Swift for Tensorflow is the next step in the evolution of Tensorflow. Can anyone explain which groups the two libraries target?,1,3
108,2019-5-27,2019,5,27,4,btc7vz,Implementing K-Means Clustering From Scratch: Simply Explained,https://www.reddit.com/r/tensorflow/comments/btc7vz/implementing_kmeans_clustering_from_scratch/,Bobber123yxz,1558899742,,0,2
109,2019-5-27,2019,5,27,11,btgdkl,Getting TensorFlow to work on IBM Power9 (linux-ppc64le),https://www.reddit.com/r/tensorflow/comments/btgdkl/getting_tensorflow_to_work_on_ibm_power9/,GirofleeAn206,1558922950,"My university let me use a recently purchased power9 HPC and I'm trying to run my project on it. Tried to install TensorFlow-GPU using Anaconda and Pip but it installed a very old version of TF (see [here](https://anaconda.org/anaconda/tensorflow-gpu)) and is basically useless (no batch normalization, no leaky ReLU, etc. 

Is there any hope of installing the latest tf on the power9 or is this beast basically useless for deep learning. Or do you know another lib that is power9 friendly?

Many thanks to those who can help me.",12,4
110,2019-5-27,2019,5,27,16,btj0qc,is it difficult to train a TF Lite model how much time should i cost?,https://www.reddit.com/r/tensorflow/comments/btj0qc/is_it_difficult_to_train_a_tf_lite_model_how_much/,makereven,1558941608,"i just wanna get someone for me to train models, it seems that they have less interest in it. so ,is it difficult to train a TF Lite model?",3,0
111,2019-5-27,2019,5,27,16,btj607,custom loss function with canned estimators,https://www.reddit.com/r/tensorflow/comments/btj607/custom_loss_function_with_canned_estimators/,nothingveryserious,1558942732,"Dear all,

&amp;#x200B;

I am new to tensorflow. My questions is: how can I add a custom loss function to a canned estimator like DNNLinearCombinedRegressor.

&amp;#x200B;

Thank you in advance for your help",0,2
112,2019-5-27,2019,5,27,18,btk2lv,[TF 2.0a] Batch Normalization updates whenever model(training=True) is called,https://www.reddit.com/r/tensorflow/comments/btk2lv/tf_20a_batch_normalization_updates_whenever/,amimaster,1558950096,"Hello,

I'm working on some GAN implementation so I decided moving from tensorflow 1.12 to 2.0a in order to benefit from a simpler and more straight-forward implementation.

&amp;#x200B;

Since I'm always worried if my BatchNormalization layers are behaving properly, I made some checks with a dummy example:

&amp;#x200B;

    train_data = tf.random.normal([32, 10], mean=10, stddev=25)
    # mean: 8.811788558959961, var: 616.1270751953125
    test_data = tf.random.normal([32, 10], mean=50, stddev=5)
    # mean: 49.93635559082031, var: 22.78847885131836
    
    # Model
    in_ = tf.keras.layers.Input(shape=[10])
    out = tf.keras.layers.BatchNormalization()(in_)
    stdmodel = tf.keras.Model(in_, out)
    
    train_before = stdmodel(train_data, training=False)
    # mean: 8.80738639831543, var: 615.5115356445312 &lt;-- They changed a bit already
    test_before = stdmodel(test_data, training=False)
    # mean: 49.91140365600586, var: 22.765710830688477 &lt;-- They changed a bit already
    train_true = stdmodel(train_data, training=True)
    # mean: 0.0, var: 0.9999982714653015 &lt;-- This makes sense, using the batch stats
    train_after = stdmodel(train_data, training=False)
    # mean: 2.4086639881134033, var: 47.2713508605957 &lt;-- Changed a lot, without explicit training
    test_after = stdmodel(test_data, training=False)
    # mean: 13.998141288757324, var: 3.8077361583709717 &lt;-- Changed a lot, without explicit training
    ...
    # Statistics after running stdmodel(train_data, training=True) for 10000 steps:
    # Train - mean: 1.5109777677935199e-06, var: 1.0000026226043701 
    # Test - mean: 1.7048790454864502, var: 0.11329631507396698
    
    # However, alpha and gamma haven't been trained yet:
    stdmodel.trainable_variables
    [&lt;tf.Variable 'batch_normalization_v2/gamma:0' shape=(10,) dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)&gt;,
     &lt;tf.Variable 'batch_normalization_v2/beta:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)&gt;]
    

&amp;#x200B;

What happens when one calls a BatchNormalization layer with training=True? I thought that updates are performed only during the actual training phase and not every time the model is called, such that the ""trainable"" flag was only telling ""use batch statistics"" vs ""use learned statistics"".

&amp;#x200B;

Is also relevant that the mean and averages changed a bit even without calling the model with training=True?

&amp;#x200B;

One last thing: The BatchNormalization layer in tf2.0 also takes as input a python boolean flag ""trainable"". I also tried using that but it seems to just override the flag passed in Model(). Am I Right?",2,3
113,2019-5-27,2019,5,27,20,btktr8,Need help with implementing a custom loss function batch wise,https://www.reddit.com/r/tensorflow/comments/btktr8/need_help_with_implementing_a_custom_loss/,cant-find-user-name,1558955979,"Hey all!

I am trying to implement a custom loss function. For a given tensor and an index, I am trying to find sum of absolute differences of every element from before the index to every element after the index, weighted by a constant for each pair. 

For example say the tensor is x = \[1, 2, 3, 4, 5\] and the index is 2 and the weights are \[\[a, b\], \[c, d\], \[e, f\]\]. The loss for this would be 

    a*(1-4)+b*(1-5)+c*(2-4)+d*(2-5)+e*(3-4)+f*(3-5)

I have figured out a way to do this. My approach is something like this:

    left = x[:index]
    right = x[index:]
    diff = tf.subtract(left[..., None] , tf.transpose(right[..., None]))
    weighted_diff = tf.multiply(weights, tf.abs(diff))
    req = tf.reduce_sum(weighted_diff)

and this works, from what I can see so far.

&amp;#x200B;

But the problem is, I am going to get the tensors (the x's) in batches. How do I calculate a loss like that on individual tensor of the batch and sum them up? 

Will doing tf.unstack() and then using a for loop to sum the losses work? Is it an efficient approach?

&amp;#x200B;

Any help is very appreciated, thank you in advance :)",6,3
114,2019-5-28,2019,5,28,3,btph8b,Some Question about Eager Execution in tf 2.0,https://www.reddit.com/r/tensorflow/comments/btph8b/some_question_about_eager_execution_in_tf_20/,Murphy_Huang,1558981771,"Not knowing much of the details, I am just curious about eager execution in tf 2.0. 

In previous version, eager execution is not compatible with `tf.estimator.Estimator`. I wonder whether in this version, these two things could work together. Debugging inside estimator with tf Debugger is too tortuous.",0,1
115,2019-5-28,2019,5,28,14,btw5jl,Training where the correct answer depends upon the the predicted answer by the model,https://www.reddit.com/r/tensorflow/comments/btw5jl/training_where_the_correct_answer_depends_upon/,Envenger,1559021321," I have been learning tensorflow 2.0 with keras for a few weeks now and have gotten a good idea on it.

 I am trying to do a simple thing, but I was not able to find any  details on doing it well. Mostly I have been doing research with  different shaped model and doing different functionalities.

I am making a regression based model that doesn't have single correct answer.  
 i.e. Its answer kind of depends upon the prediction given by the neural network and to edit it close to what I am looking for.

For example for a certain problem,   
 The correct result is say  2 and 4

Suppose the neural networks predicts 1.5 or 2.5, I want to correct it to 4.  
 But if the neural network predicts 3.5 or 4.5 I want to correct it to 4.

 What is the best way to do something like this. I took a look at the  generator, but it doesn't look like it cannot give out the result after  prediction.

I method I thought thought about is to predict a  large set of numbers first and use those predictions results to make a  training data for the next execution an continue doing it.

Is there any way to dynamically give a y\_train value just as the y\_predict value comes out?",5,3
116,2019-5-28,2019,5,28,16,btx26x,Create TensorFlow 'Dataset' with multiple data sources,https://www.reddit.com/r/tensorflow/comments/btx26x/create_tensorflow_dataset_with_multiple_data/,k0nstantin0s,1559028436,,0,2
117,2019-5-28,2019,5,28,21,btzks8,Model.fit not accepting my dataset for some reason,https://www.reddit.com/r/tensorflow/comments/btzks8/modelfit_not_accepting_my_dataset_for_some_reason/,mikeVell,1559047363,"    valid_dataset = tf.data.Dataset.from_tensors(tensors=(tensor_list))

    model.fit(test_dataset,
 epochs=10,
 validation_data=tf.compat.v1.data.make_one_shot_iterator(valid_dataset),
 batch_size=4,
 validation_steps=None,
 steps_per_epoch=None)

the method is returning the below error 

    Traceback (most recent call last):
      File ""D:\School\Last_Year\thesis_actual\thesis\thesis_prototype\implementation.py"", line 365, in &lt;module&gt;
        steps_per_epoch=None)
      File ""D:\School\Last_Year\thesis_actual\thesis\thesis_prototype\venv\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 819, in fit
        steps_name='validation_steps')
      File ""D:\School\Last_Year\thesis_actual\thesis\thesis_prototype\venv\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 2510, in _standardize_user_data
        exception_prefix='input')
      File ""D:\School\Last_Year\thesis_actual\thesis\thesis_prototype\venv\lib\site-packages\tensorflow\python\keras\engine\training_utils.py"", line 296, in standardize_input_data
        standardize_single_array(x, shape) for (x, shape) in zip(data, shapes)
      File ""D:\School\Last_Year\thesis_actual\thesis\thesis_prototype\venv\lib\site-packages\tensorflow\python\keras\engine\training_utils.py"", line 296, in &lt;listcomp&gt;
        standardize_single_array(x, shape) for (x, shape) in zip(data, shapes)
      File ""D:\School\Last_Year\thesis_actual\thesis\thesis_prototype\venv\lib\site-packages\tensorflow\python\keras\engine\training_utils.py"", line 227, in standardize_single_array
        if (x.shape is not None and len(x.shape) == 1 and
    AttributeError: 'EagerIterator' object has no attribute 'shape'

I tried my best to configure the method according to the documentation presented in tensorflow version: 1.14.1-dev20190318.

&amp;#x200B;

Is there any advise so i may solve this issue ?",4,4
118,2019-5-28,2019,5,28,22,btzs7x,TF serving using REST API,https://www.reddit.com/r/tensorflow/comments/btzs7x/tf_serving_using_rest_api/,8222Tamil,1559048639,"Want to deploy tensorflow model in production ,have successfully deployed it in grpc client using docker [setup.Now](https://setup.Now) i want to deploy my object detection model using REST Api.i tried official documentation method its bit complicated and not able to understand that.Any tutorial or github link for better understanding..",1,1
119,2019-5-28,2019,5,28,23,bu0v2q,model structure help,https://www.reddit.com/r/tensorflow/comments/bu0v2q/model_structure_help/,Biddls,1559054665,"okay, so I have a data set of sets of numbers all sets of numbers are of uniform length.

so like

\[2, 4, 8, 2, 3, 9, 4, 5, 3, 4, 1, 3, 8, 1, 1, 3, 2, 2, 2, 1, 5, 5, 2, 3, 104\] 

...

\[3, 0, 8, 10, 1, 2, 3, 2, 6, 2, 4, 4, 5, 4, 3, 3, 6, 2, 2, 2, 2, 5, 5, 0, 128\]

the last number is a total for all numbers after it (not important)

so I can't figure out what model I should use so that for each X value index it gives me a corresponding Y value (values stored at index). many thx. so the data is stored in a python array (had to do a tone fo preprocessing how and what would be the best method to store it in? thx",0,1
120,2019-5-29,2019,5,29,0,bu1nmi,How to add bucketized_column to keras model.,https://www.reddit.com/r/tensorflow/comments/bu1nmi/how_to_add_bucketized_column_to_keras_model/,nothingveryserious,1559058797,"I am new to TensorFlow and some times I have difficulty in how to integrate keras with the remaining TensorFlow framework.

That being said I am currently trying to bucketize a continuous variable and add it to a keras model that I build.

Any help on how to best achieve this?

Thanks in advance for your help",2,1
121,2019-5-29,2019,5,29,1,bu1yyw,Testing TensorFlow Lite image classification model | ThinkMobile.dev,https://www.reddit.com/r/tensorflow/comments/bu1yyw/testing_tensorflow_lite_image_classification/,frogermcs,1559060337,,0,5
122,2019-5-29,2019,5,29,9,bu7uai,Tensorflow Mobility Data,https://www.reddit.com/r/tensorflow/comments/bu7uai/tensorflow_mobility_data/,BinaryBeeBop,1559089635,"Does anyone know if there is a library of training data for visual recog of mobility when using a people counter? As in using a standard people counter off a video feed that can also recognize those in wheelchairs, walkers, canes, etc ?  

Can't find one so wanted to see if anyone could point me in the right direction before I start going down the rabbit hole of finding some",0,3
123,2019-5-29,2019,5,29,18,buclma,Problems Installing Tensorflow on RHEL CentOS7,https://www.reddit.com/r/tensorflow/comments/buclma/problems_installing_tensorflow_on_rhel_centos7/,MagicElyas,1559123135,"I am having a hard time when I try to install Tensorflow with gpu support in CentOS7. I have tried the PIP installation and it won't work because of my cpu aparently does not support AVX instructions (XEON X3430) and i am trying to build it from source, following this guide:  [https://github.com/tensorflow/tensorflow/issues/22053](https://github.com/tensorflow/tensorflow/issues/22053)

The problem comes when i try to execute this statement on bash :

\&gt;  bazel build -c opt --config=cuda //tensorflow/tools/pip\_package:build\_pip\_package

Some time passes and after 4 to 10 seconds i get this error

&amp;#x200B;

\+ git -C /root/.cache/bazel/\_bazel\_root/b48a0d5d102143bb62e0e5ac3d09b5cd/external/io\_bazel\_rules\_docker fetch origin 251f6a68b439744094faff800cd029798edf9faa:251f6a68b439744094faff800cd029798edf9faa

Unknown option: -C

&amp;#x200B;

I have found out that git recognizes -c but apparently -C is not the same.

I would appreciate if someone of this community offers me help because I am getting desperate",2,4
124,2019-5-29,2019,5,29,19,bud0v1,Tensorflow federated on Raspberry Pi,https://www.reddit.com/r/tensorflow/comments/bud0v1/tensorflow_federated_on_raspberry_pi/,HATHER2019,1559126360,"I am working on a research project based on edge computing and machine learning. It involves installation and setting up of tensor flow federated on multiple raspberry Pi's. Until now, I have not come  across any tutorial for installation of tensor flow federated on a raspberry Pi. Looking forward to tutorials on tensor flow federated.",3,2
125,2019-5-30,2019,5,30,2,buhh7e,Is there a docker for tensorflow2 alpha?,https://www.reddit.com/r/tensorflow/comments/buhh7e/is_there_a_docker_for_tensorflow2_alpha/,spyder313,1559150499,I see tf1 is available on docket but dont see a tf2 alpha image yet. Any one know if there is a tf2 version available on docker?,5,11
126,2019-5-30,2019,5,30,6,bukci8,Concatenate two Keras models outputs in new model,https://www.reddit.com/r/tensorflow/comments/bukci8/concatenate_two_keras_models_outputs_in_new_model/,roset_ta,1559164660,"Hello,


I have two Keras models A and B. I trained both models and saved their weights in two .hdf5 files. Now I need to concatenate their outputs in a third model C, that is use their outputs in fusion. How can I do that? I tried building  models A and B again, loading their weights, and concatenate them in a Concatenate layer of model C. But I get


ValueError: You are trying to load a weight file containing 1 layers into a model with 36 layers.",0,1
127,2019-5-30,2019,5,30,6,bukd58,Advice on getting linear output from CNN,https://www.reddit.com/r/tensorflow/comments/bukd58/advice_on_getting_linear_output_from_cnn/,HairyBoots,1559164754,"I have been going through tutorials on picture classification with keras and have gotten good results.

I want to change the model to predict the count of likes on a social site that a picture will get but I can't figure how to model the final layer.

Should I use a linear output, a large number of classification nodes (one per like) or something else?",2,1
128,2019-5-30,2019,5,30,10,bunfqi,RL best practices for SOTA implementations?,https://www.reddit.com/r/tensorflow/comments/bunfqi/rl_best_practices_for_sota_implementations/,clanleader,1559181283,"I'm learning RL, and as part of that am manually coding my own agents from scratch. The only abstractions I'm using are tf.gradient for the backpropagation and Gym for the environments. 

I want to as much as possible refine my own implementations so that I can gain a solid understanding of RL and also so that if I wish to customize anything I can very easily do it. I've looked at all the agent libraries for TF and I have no desire whatsoever attempting to decipher the ""magic"" of how their APIs link to their source code and understanding the source code. AI Baselines especially I've heard horror stories about their codebase and just skimming the source I don't feel like investing any effort into understanding how it's implemented. Why would I? I have my own custom implementations which, although slow and no doubt riddled with numerous bugs, I at least can customize exactly how I want and I understand how each and every part of it is working which is great for theoretical understanding (eg: If I want to change the loss from MSE to just squared I can just edit loss = ((Q_sa - y ** 2)/2 and remove the division of 2) All my classes are as simple as that). Since I want to understand RL and its implementation, not spend my time learning magical complicated libraries, high level abstractions which confer no theoretical understanding, and various APIs, I want to find the easiest to use agents library that will require no study on my part, just a simple API command to use an agent, set its hyperparemters, and interact with its environment. The reason I want to do this is to compare the performance to my own custom implementations to see how far off I am from SOTA implementations, and edit my implementations as much as possible to be like SOTA algorithms but in a manner that I can fully understand each part. I've found 3 such libraries and I have some questions about my perceived strengths and weaknesses of each -

1) AI Baselines
2) AI Stable Baselines
3) TF Agents

From what I can gather, 1) AI Baselines is supposed to be the fastest, most cutting edge SOTA implementation. Its source code however is horrid. 2) AI Stable Baselines addresses the horrid source code by apparently making it much easier to understand and edit. My fear is whether or not performance/efficiency may be slightly sacrificed, since my goal is only to compare a one-line command speed test against  my own implementation vs the library implementation, not to understand the source code of any library. 3) TF agents. This is supposedly created by TensorFlow themselves, yet as I saw someone mention here in a comment, DeepMind and Brain aren't using it. So if they can't trust it why should I?

So in your opinion, what is the most efficient library to use for the fastest, cutting edge SOTA implementation with the simplest API that I can learn with the least time investment to quickly compare SOTA implementations to my own?",0,1
129,2019-5-30,2019,5,30,13,bup1yc,"I created a Conv2D model using TensorFlow Keras, I need help converting it into CoreML model",https://www.reddit.com/r/tensorflow/comments/bup1yc/i_created_a_conv2d_model_using_tensorflow_keras_i/,Prudvi_k,1559191775,I tried all sorts of things. I just can't seem to understand the blog posts I've come across. My model took some time to train and I downloaded the model\_weights.h5 and saved\_model.json files after the training. Anyone please help me convert these into a CoreML Model.,4,1
130,2019-5-30,2019,5,30,18,bur0qq,What is the recommended way to save the model after training?,https://www.reddit.com/r/tensorflow/comments/bur0qq/what_is_the_recommended_way_to_save_the_model/,Laurence-Lin,1559208096," 

Now,  I'm bothered by the huge amount of model (2.9GB) saved directly by  tf.train.Saver, that is saved EVERYTHING of the model in the graph. I've  looked for methods online, and here are solutions I found:

Many suggests that saving in HDF5 data format. I've briefly looked for it, now I've these options:

1. Do  by tf.keras.models.save\_model(), most of the suggestions tell me to do  with keras, however I'm not using keras package right now, just using  tensorflow instead. I would like to save in more general way in case  I've various data type such as float32. Can I save model by this  function while using tensorflow only? Another question, can I save  WEIGHTS only but not a whole model architecture? I don't understand why I  should save the model architecture, to me it's just wasting the memory  and meaningless.
2. Use  h5py package directly. This means I need to do by hand to create a  dataset to store the weight of my model, ex. file =  h5py.File('model.h5', 'w') and then write the weight into file as key  and value. The problem is that I seems to have to spend more time  understanding how to use h5py in detail, and I don't know how to load in  weight after saving h5py. It seems to cost more time to get hand on  this.
3. Can't  I just use tf.train.Saver to save WEIGHT ONLY? Maybe my search keyword  is not that explicit, but I always found code that saves EVERYTHING and  don't seems to care for the large size model.

Any advice is welcome, thank you for helping!!",7,6
131,2019-5-31,2019,5,31,2,buvw0b,ValueError: You are trying to load a weight file containing 1 layers into a model with 36 layers.,https://www.reddit.com/r/tensorflow/comments/buvw0b/valueerror_you_are_trying_to_load_a_weight_file/,roset_ta,1559236930,"Hello,

I'm having trouble understanding what this error could  mean. 

I have trained two Keras models A and B independently and saved their weights in .hdf5 files, using Keras checkpoint callback.

Now I need to train another model C where I will use models A and B outputs in fusion, i.e. concatenate them. But since I have saved the weights, I want to use the pretrained versions of models A and B.

So, I build the models again, load their weights, and freeze all layers except for the output layers. I create model C with Keras functional API and I add a Concatenate layer, where the outputs of models A and B are given as inputs.. 

If I don' t load the weights of models A and B, the training starts. But when I use them, I get the error.

Any ideas? I 'm missing something. Maybe I should have saved the trained models and not the weights?",3,7
132,2019-5-31,2019,5,31,8,bv0cfk,Model Parallel Training with TF Keras,https://www.reddit.com/r/tensorflow/comments/bv0cfk/model_parallel_training_with_tf_keras/,Bsuwirjo,1559260167,"I am currently trying to train a large neural network \~30k outputs. I have to GPU's with 8gbs of ram. I've read that model parallel training is possible through tensorflow but I havnt been able to find a good example. Would somebody be able to point me in the right direction of an example using tensorflow keras and model parallel training? The model I am trying to train is pretty simple, just two fully connected hidden layers and then the output layer. But I can't figure out for the life of me how to split the model across two gpus.",6,1
133,2019-5-31,2019,5,31,17,bv4szx,The 10 Important Updates from TensorFlow 2.0,https://www.reddit.com/r/tensorflow/comments/bv4szx/the_10_important_updates_from_tensorflow_20/,Rogers911z,1559289882,[http://dev.edupioneer.net/1e0a34234e](http://dev.edupioneer.net/1e0a34234e),0,10
134,2019-5-31,2019,5,31,21,bv6vy9,Can we join efforts to convert Object Detection API to version 2.0 ?,https://www.reddit.com/r/tensorflow/comments/bv6vy9/can_we_join_efforts_to_convert_object_detection/,life_vortex,1559305559,"Although the title expresses the intention of this post, here is some contextual elaboration.

&amp;#x200B;

There are features in object detection API which are not easily understood by most people. An example, is evaluating while training on which there are loads of conflicting issues on GitHub. Efficient multi-GPU training is another issue ever since the API moved on to model\_main.py which uses estimator.train\_and\_evaluate which does not resonate well with the HOROVOD scaling library.

In short, object detection API has become slightly messy and it's a pity since it is an API with a beautiful start.

The migration to TF 2.0 offers us a chance to revamp it in a lot of ways. Above all, it offers us a very good look into the API as well as the utility of TF2.0 to write a huge project. 

Can we discuss and come up with a coordinated effort to do this ?  I am really interested in doing this, but if others would like to get involved and offer suggestions, it will make it so much more worthwhile.",0,2
135,2019-5-31,2019,5,31,21,bv735w,tf.keras.experimental.export_saved_model error: __init__() missing 1 required positional argument: 'feature_columns',https://www.reddit.com/r/tensorflow/comments/bv735w/tfkerasexperimentalexport_saved_model_error_init/,nothingveryserious,1559306767,"   

I am trying to save my model in a .pb or .pbtxt format using  tf.keras.experimental.export\_saved\_model(model, saved\_model\_dir)  as  described in the following tutorial:

[https://github.com/GoogleCloudPlatform/data-science-on-gcp/blob/master/updates/cloudml/flights\_model\_tf2.ipynb](https://github.com/GoogleCloudPlatform/data-science-on-gcp/blob/master/updates/cloudml/flights_model_tf2.ipynb)

but I get the error:

**init**() missing 1 required positional argument: 'feature\_columns'

Thank you in advance for your help. Code below:

    
    training_history = model.fit(train_ds, 
                        validation_data=val_ds,
                        epochs=epochs, 
                        callbacks=[EarlyStopping(patience=patience), tensorboard_callback ])
    
    now=str(datetime.datetime.now()).replace(':','_').replace(' ','_').replace('.','_')
    
    saved_model_dir=""saved_models/""+now
    
    tf.keras.experimental.export_saved_model(model, saved_model_dir)
    
    #I get the following error:
    
    TypeError: __init__() missing 1 required positional argument: 'feature_columns'",3,1
136,2019-5-31,2019,5,31,22,bv7bv7,When to use tf.stop_gradient() with tf.nn.softmax_cross_entropy ?,https://www.reddit.com/r/tensorflow/comments/bv7bv7/when_to_use_tfstop_gradient_with_tfnnsoftmax/,Laurence-Lin,1559308188,"In tf.nn.softmax\_cross\_entropy\_with\_logits\_v2, it says that I should set label to tf.stop\_gradient if I don't want to calculate the gradient for label. I thought I should do it because label is fixed labels, and I don't need label's gradient when doing BP. But after I set labels = tf.stop\_gradient(label), I found the output accuracy fixed at a low level and failed to converge.

Should I set label to stop gradient with this new version of softmax cross entropy loss?",0,1
137,2019-5-31,2019,5,31,22,bv7d1m,[Help] Transfer Learning for PoseNet,https://www.reddit.com/r/tensorflow/comments/bv7d1m/help_transfer_learning_for_posenet/,jackersson,1559308373,"Hi,   


Researching human pose estimation for mobile.   
Found Project: [https://www.tensorflow.org/lite/models/pose\_estimation/overview](https://www.tensorflow.org/lite/models/pose_estimation/overview)  
Also there is a JS implementation: [https://github.com/tensorflow/tfjs-models/tree/master/posenet](https://github.com/tensorflow/tfjs-models/tree/master/posenet)  
There is model called PoseNet and I want to retrain it on additional data. But can't find any Documentation on how it was trained or how to perform transfer learning on this model)   


If you've already worked with it share some information ;) Thanks in advance",2,2
0,2019-6-1,2019,6,1,18,bvj6jb,Image Recognition in Python with TensorFlow and Keras,https://www.reddit.com/r/tensorflow/comments/bvj6jb/image_recognition_in_python_with_tensorflow_and/,pmz,1559382789,,1,18
1,2019-6-2,2019,6,2,7,bvqm91,How to deploy tensor flow trained model as a rest api,https://www.reddit.com/r/tensorflow/comments/bvqm91/how_to_deploy_tensor_flow_trained_model_as_a_rest/,undefinedNANString,1559429102,"Basically, I want a rest api for a sentiment analysis tensor flow model.

You post data to it, and it tells you how your text is emotionally. But how do I deploy this as a rest api
 


Note : I'm definitely a Python noob, but I'm very strong with JS so I need simple steps.",5,8
2,2019-6-2,2019,6,2,16,bvv551,Cheapest device for video inference.,https://www.reddit.com/r/tensorflow/comments/bvv551/cheapest_device_for_video_inference/,sup3rnoova,1559462338,"I want to make a small tractor like autonomous vehicle that would pick vegetables based on their ripeness (that's supposed to determine tensorflow). Which device should I use for this? Do I need something like a Jetson Nano or would an RPI3 do this. The vehicle would be moving pretty slowly so it may not need something faster. Keep in mind i'm in Europe so prices will differ.    

Thanks.",4,1
3,2019-6-2,2019,6,2,19,bvvx0e,why is everyone using anaconda and the notebook?,https://www.reddit.com/r/tensorflow/comments/bvvx0e/why_is_everyone_using_anaconda_and_the_notebook/,datnell,1559470136,what is wrong with using only the python idle?,9,3
4,2019-6-2,2019,6,2,20,bvwi1r,AttributeError: module 'tensorflow._api.v1.nn' has no attribute 'seq2seq' Issue. How would I fix this issue?,https://www.reddit.com/r/tensorflow/comments/bvwi1r/attributeerror_module_tensorflow_apiv1nn_has_no/,TechGenius28,1559475589,,2,2
5,2019-6-3,2019,6,3,1,bvyy0b,Variable-length sequences with LSTM network using Keras and eager execution,https://www.reddit.com/r/tensorflow/comments/bvyy0b/variablelength_sequences_with_lstm_network_using/,gentlewaterboarding,1559491707,"I've been struggling with this for two days now, and finally found a solution that works as expected. It's been incredibly annoying, so much that I've wanted to abandon the ""new tensorflow"" (with eager execution) altogether, and I just wanted to know if it's supposed to work like this. Also writing this up in case someone else has the same problem.

The problem: a sequence-to-sequence task with variable-length sentences; specifically machine translation. So each batch has sentences of different length. I went with what I understand is the standard approach:

- Pad the sequences with zeros up to a maximum length
- Disregard the zeros when computing the loss

However, one problem remains. I'm using an encoder-decoder architecture, and want to obtain the encoder states corresponding to the end of the sentences, *not* including the padding. With the default behavior, translations differ when different lengths of padding are used, because the Encoder LSTM has to propagate the state for many padding time-steps. 

The old solution: Simply use dynamic_rnn to run your LSTM cell and provide the sequence_length argument and it just works. dynamic_rnn is however deprecated now. 

[From what I've stumbled upon](https://github.com/tensorflow/community/issues/36), the new Keras-way is to use a Masking layer or similar. Simply have the network apply a mask to ignore parts of the input. It seems simple enough, but no matter what I tried, the mask doesn't have any effect.

So I'm wondering if masking doesn't actually work with eager execution? 

First attempt:

    class Encoder(tf.keras.Model):
        def __init__(self, vocab_size, embedding_dim, units, batch_size):
            # ... instantiate stuff
        
        def call(self, x, hidden):
        
            # The embedding layer has mask_zero=True, so it should automatically create a mask.
            # I've also tried adding a Masking layer before the embedding layer:
            # x = self.mask(x)

            x = self.embedding(x)
        
            outputs, final_state = self.gru(x, initial_state = hidden)
        
            return outputs, final_state

But in order to get it to work, I have to manually define and provide the mask to the GRU layer. 

    class Encoder(tf.keras.Model):
        def __init__(self, vocab_size, embedding_dim, units, batch_size):
            # ... instantiate stuff
        
        def call(self, x, hidden):

            mask = tf.not_equal(x, 0)
        
            x = self.embedding(x)
        
            outputs, final_state = self.gru(x, initial_state = hidden, mask=mask)
        
            return outputs, final_state

This meets my needs, but I don't know why it's necessary. Anyone know?",17,10
6,2019-6-3,2019,6,3,7,bw2z6x,AI Best Practices Blog,https://www.reddit.com/r/tensorflow/comments/bw2z6x/ai_best_practices_blog/,ThinkCritically,1559513396,"Hi everyone.

I am currently working on a blog at https://ralphabrooks.com . It would be interesting to get feedback on this work in progress. Right now, I see the blog as being something that could hold AI recipes or snippets or a general guide as to best practices.

For example, right now I am working on how to classify positive, negative, and ""unimportant"" sentiment for blogs / tweets, etc. It would be nice one day to be able to provide to the community some type of reference that could say ""for X type of problem, quick snippets of code are here here here and the best practices to this type of problem are X, Y, and Z.""

What are your thoughts? In terms of baby steps or actionable, steps, what type of interesting blog posts would you be interested in seeing?",0,1
7,2019-6-3,2019,6,3,7,bw35wf,Feedback Requested on AI Best Practices Blog - What TensorFlow or NLP questions are keeping you up at night?,https://www.reddit.com/r/tensorflow/comments/bw35wf/feedback_requested_on_ai_best_practices_blog_what/,ThinkCritically,1559514488,,2,1
8,2019-6-3,2019,6,3,22,bwar77,Running several predicts using the same session.,https://www.reddit.com/r/tensorflow/comments/bwar77/running_several_predicts_using_the_same_session/,adriacabeza,1559569082,"Hi, I'm trying to run inference on a tensorflow model but I cannot use the standard option of encapsulating everything on a session environment and start inference there,  since there are some processes before each prediction and I need to modulate everything in classes.  I've tried to set a self.session attribute in order to always use the same session and not having to open one each time I am running predict. However, I do get CPU performance even though the log\_device\_placement tells me GPU. How could I solve my problem.

`class Net:`

`def __init__(self, model):`  
`tf_config = tf.ConfigProto(log_device_placement=False)  # afegir lo de log device placement`  
 `tf_config.gpu_options.allow_growth = True`  
 `tf_config.gpu_options.per_process_gpu_memory_fraction = 0.7`  
 `tf_config.gpu_options.visible_device_list = '0'  # only see the gpu 0`  
 `os.environ[""CUDA_VISIBLE_DEVICES""] = ""0""`  
 `self.session = tf.Session(config=tf_config)`

&amp;#x200B;

`def init_net(self, model):`  
 `with self.session.as_default():`  
 `with gfile.FastGFile(model, 'rb') as f:`  
`graph_def = tf.GraphDef()`  
`graph_def.ParseFromString(f.read())`  
`net = graph_def`  
 `return net`  


`def predict(self,inputs):`  
 `with self.session.as_default():`  
 `with tf.device('/GPU:0'):`  
`tf.import_graph_def(self.net, name='')`  
`res = self.session.run('dense_2/Softmax:0', feed_dict = {'input_1:0': inputs})`  
 `return res`",2,1
9,2019-6-4,2019,6,4,0,bwbmm4,Python Programming Tutorial | Full Python Course for Beginners 2019,https://www.reddit.com/r/tensorflow/comments/bwbmm4/python_programming_tutorial_full_python_course/,JJohnson0x,1559574025,[https://www.youtube.com/watch?v=3k2BZ8l9-zk](https://www.youtube.com/watch?v=3k2BZ8l9-zk),0,13
10,2019-6-4,2019,6,4,0,bwc8ln,Tensor Multiplication Question,https://www.reddit.com/r/tensorflow/comments/bwc8ln/tensor_multiplication_question/,TLO_Is_Overrated,1559577212,"Hi,

I have a Rank 2 tensor (a matrix) and I am looking to multiply it with a Rank 3 tensor.

Given the following sample tensors below:

h_1 = Tensor(""GatherV2:0"", shape=(15, 50), dtype=float64, device=/device:GPU:0)
h_2 = Tensor(""GatherV2_1:0"", shape=(50, 15, 4), dtype=float64, device=/device:GPU:0)

I would like a result of the shape:

(15, 4)

I am trying to multiply these tensors together using tensordot. 

If I had a single sample the dimensions of these problems would be: 

h_1 = (1,50)
h_2 = (50,4)

With the result of (1,4) from the multiplication.

I am struggling to get the output shape I desire, which I think is due to my lack of knowledge of the axes. With:

mult = tf.tensordot(h_1, h_2, axes = [[1],[0]]) resulting in:

Tensor(""Tensordot:0"", shape=(22, 22, 4), dtype=float64, device=/device:GPU:0)

And everything else throwing dimensionality errors.

I've read https://www.tensorflow.org/api_docs/python/tf/tensordot and can't seem to figure out how to get what I want using a rank 2 and rank 3 tensor.

Is what I'm doing possible, or are there any ideas?

Thank you.",3,1
11,2019-6-4,2019,6,4,2,bwdc7o,How to create a custom Embedding Layer?,https://www.reddit.com/r/tensorflow/comments/bwdc7o/how_to_create_a_custom_embedding_layer/,honeybooboo1989,1559582752,"So, there are tons of materials/tutorial out online to have an embedding layer for NLP problems. However, I would like to create a custom Embedding layer for other types of data which I cannot find any working example. Can someone help me about it?",1,1
12,2019-6-5,2019,6,5,10,bwx6ce,Revolutionizing Medical Diagnosis with Tensorflow Deep Learning | Ankit Gupta |TED Talk,https://www.reddit.com/r/tensorflow/comments/bwx6ce/revolutionizing_medical_diagnosis_with_tensorflow/,jimscott1232,1559699954,,0,9
13,2019-6-5,2019,6,5,22,bx2txq,"TensorFlow to CoreML conversion and model inspection  Think, mobile!",https://www.reddit.com/r/tensorflow/comments/bx2txq/tensorflow_to_coreml_conversion_and_model/,frogermcs,1559742896,,0,1
14,2019-6-6,2019,6,6,1,bx4bkr,Bunch of books on STEM including TensorFlow are discounted heavily!,https://www.reddit.com/r/tensorflow/comments/bx4bkr/bunch_of_books_on_stem_including_tensorflow_are/,RebekahPagan,1559750888,,9,10
15,2019-6-6,2019,6,6,6,bx7y20,I need help with replicating a tensorflow NN from a code fragment and diagram.,https://www.reddit.com/r/tensorflow/comments/bx7y20/i_need_help_with_replicating_a_tensorflow_nn_from/,Nightysin,1559768882,"Hello,

this is my first experience with tensorflow, so please be patient. I need to replicate the neural net described in [this Article.](https://medium.com/capital-one-tech/reasonable-doubt-get-onto-the-top-35-mnist-leaderboard-by-quantifying-aleatoric-uncertainty-a8503f134497)

There is no source code given for this, however. There are a few rough descriptions of what they coded given within [this diagram](https://cdn-images-1.medium.com/max/1400/1*mRM8bwjlYQwM4GOH-40gEg.png) and [this code fragment.](https://cdn-images-1.medium.com/max/1600/0*tKQXorfp3ahz5ZNx) Also they said that the rest of the code is a pretty standard two-layer convolutional neural network, with max pooling and dropout.

I tried to combine all these things into this mess of code:

    import tensorflow as tf
    import tensorflow_probability as tfp

    mnist = tf.keras.datasets.mnist

    (x_train, y_train),(x_test, y_test) = mnist.load_data()
    x_train, x_test = x_train / 255.0, x_test / 255.0

    inputs = tf.keras.layers.Input(shape=(28, 28))
    flatten = tf.keras.layers.Flatten()(inputs)
    dense1 = tf.keras.layers.Dense(512, activation=tf.nn.relu)(flatten)
    dropout = tf.keras.layers.Dropout(0.2)(dense1)
    dense2 = tf.keras.layers.Dense(10, activation=tf.nn.softmax)(dropout)

    #this model without the reparametrization works
    model_no_reparam = tf.keras.models.Model(inputs=inputs, outputs=dense2)

    locs = tf.keras.layers.Dense(units=10, name=""means"")(dense2)

    scales = tf.keras.layers.Dense(units=10, name=""std_devs"", 
    activation=tf.nn.softplus)(dense2)

    dist = tfp.distributions.Normal(loc=locs, scale=scales)

    num_sample = 1000
    logits = dist.sample([num_sample], name=""logits"")

    logits = tf.transpose(logits, [1,0,2])

    #How/ Where to get original labels?
     labels = tf.tile(labels[:, tf.newaxis], [1, num_sample])

    #I know outputs=logits cannot work since logits arent a layer 
    #but how do I make a model without an ouput layer?
    model = tf.keras.models.Model(inputs = inputs, outputs=logits)

    model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])

    model.fit(x_train, y_train, epochs=5)
    model.evaluate(x_test, y_test)

Now, don't get me wrong I know that there are a hundred things wrong with this:

 - The article uses raw tf, and I use keras which makes things pretty awkward but keras seems to be the best practice as far as I can tell.

 - I mix and match between keras and non keras because I couldn't find how to do some of these things in keras (the normal distribution, transpose, tiling)

 - I have no idea how to get the MNIST labels from the data, but I need them to make the tiled labels

 - I have no idea how I combine the logits and the tiled labels into an output layer. It's not shown in the code fragments but I assume they did something like tf.nn.softmax_cross_entropy_with_logits which I don't think I can with keras.

I would really appreciate some help with this. Would it maybe be better to just drop keras and try to do it like they did with raw tf?

thanks in advance",1,0
16,2019-6-6,2019,6,6,9,bx9xid,"PoseNet for iOS, Android and Flutter using TensorFlow Lite",https://www.reddit.com/r/tensorflow/comments/bx9xid/posenet_for_ios_android_and_flutter_using/,x_ash,1559779813,,0,4
17,2019-6-6,2019,6,6,10,bxaqet,Model quantization,https://www.reddit.com/r/tensorflow/comments/bxaqet/model_quantization/,_spicyramen,1559784558,Is there native way to do it in TF without TensorRT? Model will be using Nvidia T4.,1,3
18,2019-6-6,2019,6,6,22,bxgrm9,No training configuration found in save file: the model was *not* compiled. Compile it manually.,https://www.reddit.com/r/tensorflow/comments/bxgrm9/no_training_configuration_found_in_save_file_the/,clanleader,1559827925,"How to I specifically suppress this error? I'm not using model.compile, I'm manually iterating the weights myself via a custom gradient. I want to get rid of this specific message without suppressing potentially other error messages. This is for TF2 alpha.

As I side note, why does TF2 try so hard to abstract everything away? It's as if the moment we want to manually do something it will raise alarm bells and recommend we use a ""keras method"". How is anyone supposed to learn anything if we don't do things ourselves first? In reference to this particular issue, I'm doing some custom reinforcement learning, so this assumption that I just want a supervised ""model.fit"" is quite arrogant on the part of TF.",2,1
19,2019-6-7,2019,6,7,0,bxi6mx,System passed 'you must feed a value for placeholder' when no placeholder existed,https://www.reddit.com/r/tensorflow/comments/bxi6mx/system_passed_you_must_feed_a_value_for/,Laurence-Lin,1559835712,"Here is my code:  


v = tf.convert\_to\_tensor(stock, dtype = tf.float32)

init = v\[0\].eval(session = tf.Session())

&amp;#x200B;

v1 = tf.Variable(init, dtype = tf.float32)

sess = tf.Session()

[sess.run](https://sess.run)(tf.global\_variables\_initializer())",2,0
20,2019-6-7,2019,6,7,6,bxm7hi,Importing a metagraph without using the placeholders used at training time,https://www.reddit.com/r/tensorflow/comments/bxm7hi/importing_a_metagraph_without_using_the/,yoopiyoop1,1559856275,"I am trying to restore a tensorflow metagraph with its weights that I have found online (I do not have access to the code for the graph definition).

The restored graph takes two placeholders as input and spits an image. At inference I can do:

    estimator =tf.train.import_meta_graph('{}.meta'.format('./oldgraph.ckpt')) input_tensor1 = tf.get_collection('input_tensor1')[0] input_tensor2 = tf.get_collection('input_tensor2')[0] output = tf.get_collection('output')[0] with tf.Session() as sess:      estimator.restore(sess, './oldgraph.ckpt')      np_output = sess.run(output, { input_tensor1: data1, input_tensor2: data2}) 

However in my case I am at training time, and 'estimator' can be looked at a blackbox in my pipeline. As such, the inputs to the restored graph are not placeholders anymore but tensors coming from my pipeline (which means I cannot use sess.run anymore)

My question is two folds, 1) how can I replace the placeholders with tensors. 2) If I manage to solve this would my gradients flow through estimator down to the beginning of my pipeline?",0,1
21,2019-6-7,2019,6,7,8,bxnry9,Fine-tuned BERT model is way over 250MB Google AI Platform limit?,https://www.reddit.com/r/tensorflow/comments/bxnry9/finetuned_bert_model_is_way_over_250mb_google_ai/,echan00,1559864967,"I have a fine-tuned google bert model that has been exported from the estimator. My model is around 900KB but the variables are 680MB large. 

This is way over the 250MB Google AI Platform limit for serving models, my question is whether this is typical for fine-tuned bert models? I have looked through everything I found online ([https://medium.com/google-cloud/optimizing-tensorflow-models-for-serving-959080e9ddbf](https://medium.com/google-cloud/optimizing-tensorflow-models-for-serving-959080e9ddbf)) but would be great if someone could give me some pointers.",4,8
22,2019-6-7,2019,6,7,9,bxo97x,AMP working on 1.14.0rc0 or nightly?,https://www.reddit.com/r/tensorflow/comments/bxo97x/amp_working_on_1140rc0_or_nightly/,WickedGrey,1559867894,"I've been having no luck getting automatic mixed precision training working using either the release candidate or nightly.

&amp;#x200B;

Has anyone gotten it to work without using the NVIDIA docker images?

&amp;#x200B;

I'm using a 2080 Ti, can see logging messages about graph\_rewrite, but there's no performance boost vs. fp32.",1,1
23,2019-6-7,2019,6,7,11,bxp83u,What does tf.GraphKeys.REGULARIZATION_LOSSES return actually?,https://www.reddit.com/r/tensorflow/comments/bxp83u/what_does_tfgraphkeysregularization_losses_return/,Laurence-Lin,1559873981,"I've seen many use tf.get\_collection(tf.GraphKeys.REGULARIZATION\_LOSSES to collection the regularization loss, and add to loss by :  


`regu_loss = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)`

`total loss = tf.add_n([loss] + regu_loss)`

However, 'loss' is only shape \[1\] that computed by a whole batch. As for regu\_loss, in my understanding it should be(l2 regularization for example):

`constant coefficient * sum(square(regularized variables))`  
Which is only shape \[1\], why should the total loss be added by add\_n?

And when I add them directly, it returns a list of losses, which differ from what I expected with shape \[1\]. 

What does REGULARIZATION\_LOSSES return actually?",2,1
24,2019-6-7,2019,6,7,11,bxpjwm,TensorFlow.js Crash Course  Machine Learning For The Web  Handwriting Recognition,https://www.reddit.com/r/tensorflow/comments/bxpjwm/tensorflowjs_crash_course_machine_learning_for/,raikundalia,1559876016,,1,0
25,2019-6-7,2019,6,7,14,bxr51z,Will the variables created stored after program is finished?,https://www.reddit.com/r/tensorflow/comments/bxr51z/will_the_variables_created_stored_after_program/,Laurence-Lin,1559886894,"I'm currently running a code:

x = tf.Variable(0, tf.float32)

y = tf.Variable(1, tf.float32)

&amp;#x200B;

print(tf.global\_variables())  


However, the tf.global\_variables return many variables other than x &amp; y. Why would this happen? How could I remove the unwanted variables created in the past?

Another similar question, every time I use tf.get\_variable(), the IDE tell me that the name already existed, but in the current code I haven't create variable of same name before. It seems that the previous created variable may be stored somewhere that every time I use get\_variable function, it detects and shows error.",2,1
26,2019-6-7,2019,6,7,21,bxu5ew,Music timestamp prediction,https://www.reddit.com/r/tensorflow/comments/bxu5ew/music_timestamp_prediction/,_cab13_,1559911306,"Hey

&amp;#x200B;

I'm quite new to tensorflow. Made my way throught the tutorial last week, and now I am planning on making a nn which takes a waveform image (plotted) and predict a timestamp in it.

&amp;#x200B;

How am I supposed to make the output of my model a timestamp ?",3,3
27,2019-6-8,2019,6,8,2,bxx1es,Tensorflow 2 beta,https://www.reddit.com/r/tensorflow/comments/bxx1es/tensorflow_2_beta/,alew3,1559927006,,0,16
28,2019-6-8,2019,6,8,6,bxzstd,Google Announces TensorFlow 2.0 Beta,https://www.reddit.com/r/tensorflow/comments/bxzstd/google_announces_tensorflow_20_beta/,Yuqing7,1559941333,,3,47
29,2019-6-8,2019,6,8,7,by0o9a,Problems installing tensorflow in pycharm,https://www.reddit.com/r/tensorflow/comments/by0o9a/problems_installing_tensorflow_in_pycharm/,ats678,1559946067,"Hello guys, I want to start working on machine learning however Ive been trying to install tensorflow on pycharm for the entire day( Im kinda giving up lol). Ive been getting the same error with every possible solution: could not find a version that satisfies the requirement tensorflow.... Anyone knows why? Ive been working with python 3.7.2, the new pycharm version with the anaconda plugin and windows 10",0,1
30,2019-6-8,2019,6,8,11,by353y,Approach to loading TF graphs in your own c++ application (Linux),https://www.reddit.com/r/tensorflow/comments/by353y/approach_to_loading_tf_graphs_in_your_own_c/,nicetryho,1559961843,"I want the ability to load a tf graph and confg file in my own c++ application. On a high level, what are the steps to achieve this on a Linux build ? Do I just build TF from source and include ?",0,1
31,2019-6-8,2019,6,8,13,by3ys7,The Machine Learning Crash Course  Part 2: Linear Regression,https://www.reddit.com/r/tensorflow/comments/by3ys7/the_machine_learning_crash_course_part_2_linear/,GlennMulligan,1559967593,,0,1
32,2019-6-9,2019,6,9,3,byb2eo,TensorFlow for C# (aka Gradient),https://www.reddit.com/r/tensorflow/comments/byb2eo/tensorflow_for_c_aka_gradient/,lostmsu,1560019049,"TL;DR; Over the past 2 years I've made a .NET binding to the full TensorFlow Python API, including Keras, tf.contrib, and, basically,  everything else. It's called Gradient, its on NuGet, and you can read  the guide here: [https://github.com/losttech/Gradient/#getting-started](https://github.com/losttech/Gradient/#getting-started) 

&amp;#x200B;

Unlike TensorFlowSharp and TensorFlow.NET, which only provide access to low-level API (e.g. no Keras, missing many optimizers, basically &gt;50% of TensorFlow), Gradient exposes full Python API at the cost of requiring Python runtime (from my limited understanding it is similar to how Swift for TensorFlow works).

&amp;#x200B;

My dogfooding on top of this project included:

1. Making GPT-2-based song lyrics generator end-to-end in C# (training and serving). [Website: Make a song](http://billion.dev.losttech.software:2095/), [write-up](https://habr.com/post/453232/), and [source on GitHub](https://github.com/losttech/BillionSongs)
2. Participating in a couple of Kaggle competitions. [Partial write-up](https://habr.com/post/437174/).
3. Making a [bunch of samples](https://github.com/losttech/Gradient-Samples/) for C# (mostly), F# and even Visual Basic (sic !).

Not open source, but free for personal use or low income startups (under $1M/y).",2,11
33,2019-6-9,2019,6,9,21,byjwzh,Help me install Tensorflow,https://www.reddit.com/r/tensorflow/comments/byjwzh/help_me_install_tensorflow/,notooth1,1560084831,"Hi everyone,

Please help me install Tensorflow. Here is the error:

&gt;$ pip3.6 install tensorflow  
&gt;  
&gt;Collecting tensorflow  
&gt;  
&gt;  ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)  
&gt;  
&gt;ERROR: No matching distribution found for tensorflow

My system is: OpenBSD 6.5, Python 3.6 64bit.",17,0
34,2019-6-10,2019,6,10,16,byv1ez,TensorFlow.js Crash Course  Machine Learning For The Web  Getting Started,https://www.reddit.com/r/tensorflow/comments/byv1ez/tensorflowjs_crash_course_machine_learning_for/,GlennMulligan,1560152883,,0,11
35,2019-6-10,2019,6,10,17,byv4or,Convert Dataset back into Numpy Array in TF2,https://www.reddit.com/r/tensorflow/comments/byv4or/convert_dataset_back_into_numpy_array_in_tf2/,mazy1998,1560153642,"I have some code in TensorFlow 2 using datasets and dataset.map.

Essentially I am passing an array(""dataset1"") of the binary arrays such as \[\[1,0,0,1\], \[1,0,1,1\]....\[1,1,0,0\] \] and mapping it these to its corresponding decimal value. 

    @tf.function
    def binaryToDecimal(bits):
        return bits[3]*8.+bits[2]*4.+bits[1]*2.+bits[0]*1.
    
    dataset2 = dataset1.map(binaryToDecimal)

I don't need to view dataset1 because I created it myself, but I want to view the results of dataset2. 

    print(dataset2)
    &gt;&gt;&lt;MapDataset shapes: (), types: tf.float32&gt;

Printing doesn't help and I can't find any tutorial to convert a dataset to a numpy array.

I anyone has any suggestions do let me know.

Thanks in advanced.",1,1
36,2019-6-10,2019,6,10,19,byvzrm,Tensorflow upgrade not working,https://www.reddit.com/r/tensorflow/comments/byvzrm/tensorflow_upgrade_not_working/,PileWaltzDriver,1560160900,"I'm using windows 10 python 3.7.   
Currently it's showing i have tensorflow version 1.12.0

when i run pip install tensorflow --upgrade, it's running a bunch of stuff saying requirement already satisfied  
when i run pip install tensorflow==2.0.0-beta0, it's showing -

""Could not find a version that satisfies the requirement tensorflow==2.0.0-beta0 (from versions: )

No matching distribution found for tensorflow==2.0.0-beta0""

Please help.",0,1
37,2019-6-11,2019,6,11,2,bz0bfd,I've created a neural network that learns to play snake in the browser! ,https://www.reddit.com/r/tensorflow/comments/bz0bfd/ive_created_a_neural_network_that_learns_to_play/,CROEWENS,1560186079,,4,15
38,2019-6-11,2019,6,11,2,bz0lg8,"Automate testing of TensorFlow Lite model implementation  Think, mobile!",https://www.reddit.com/r/tensorflow/comments/bz0lg8/automate_testing_of_tensorflow_lite_model/,frogermcs,1560187414,,0,1
39,2019-6-11,2019,6,11,18,bzaa7b,TFRecord Viewer,https://www.reddit.com/r/tensorflow/comments/bzaa7b/tfrecord_viewer/,m-s-01,1560245234,"[https://github.com/sulc/tfrecord-viewer](https://github.com/sulc/tfrecord-viewer) 

If you sometimes need to check annotations for object detection/classification in your TFRecords, I made a simple web-based viewer for that. (So you can run it on the server and browse on your local machine).

https://i.redd.it/1hdxc9je4p331.png",0,8
40,2019-6-11,2019,6,11,18,bzafq1,How to monetize a dataset on iExec (and keep ownership over it),https://www.reddit.com/r/tensorflow/comments/bzafq1/how_to_monetize_a_dataset_on_iexec_and_keep/,jbrg,1560246467,,0,1
41,2019-6-12,2019,6,12,1,bzem7b,Dimension/Shape Problems with Lamba Layer,https://www.reddit.com/r/tensorflow/comments/bzem7b/dimensionshape_problems_with_lamba_layer/,Nightysin,1560270456,"Hello,

I am trying to implement a Lamba Layer that takes two previous dense layers, interprets one as mean, and the other one as standard deviations for a normal distribution, which is then polled 1000 times. These polls are then interpreted as logits and used with labels that have been tiled 1000, in order to correct for aleatoric uncertainty. I am trying to adapt the technique described in [this article](https://medium.com/capital-one-tech/reasonable-doubt-get-onto-the-top-35-mnist-leaderboard-by-quantifying-aleatoric-uncertainty-a8503f134497) (it has a diagram and a code fragment if that helps).

My code looks like this:

    import tensorflow as tf
    import tensorflow_probability as tfp
    import numpy as np

    data = tf.keras.datasets.mnist
    num_sample = 1000

    (x_train, y_train), (x_test, y_test) = data.load_data()
    x_train, x_test = x_train / 255.0, x_test / 255.0


    def reparam(tensors):
        loc = tensors[0]
        scale = tensors[1]
        dist = tfp.distributions.Normal(loc=loc, scale=scale)
        return tf.transpose(dist.sample([num_sample], name=""logits""), [1, 0, 2])


    inputs = tf.keras.layers.Input(shape=(28, 28))
    flatten = tf.keras.layers.Flatten()(inputs)
    dense1 = tf.keras.layers.Dense(512, activation=tf.nn.relu)(flatten)
    dropout = tf.keras.layers.Dropout(0.2)(dense1)
    dense2 = tf.keras.layers.Dense(10, activation=tf.nn.softmax)(dropout)

    locs = tf.keras.layers.Dense(units=10, name=""means"")(dense2)

    scales = tf.keras.layers.Dense(units=10, name=""std_devs"", activation=tf.nn.softplus)(dense2)

    repar = tf.keras.layers.Lambda(reparam)([locs, scales])

    model = tf.keras.models.Model(inputs=inputs, outputs=repar)

    model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

    y_train = np.tile(y_train[:, tf.newaxis], [1, num_sample])

    model.fit(x_train, y_train, epochs=5)
    model.evaluate(x_test, y_test)

When I execute this, however I get: ""Can not squeeze dim[1], expected a dimension of 1, got 1000""

As far as I can tell all the dimensions make sense, though:

The Lambda layer has shape=(?, 1000, 10) as expected, which means the automatic inference of the shape of the lamba layer is working correctly, meaning I don't have to supply a shape function to the lambda layer.

And the labels have shape = (60000, 1000) which is also as expected.

I dont understand where this error is originating from, and I would appreciate any piece of advice.

thanks in advance",0,1
42,2019-6-12,2019,6,12,5,bzhnzx,Tensorflow/serving struggles,https://www.reddit.com/r/tensorflow/comments/bzhnzx/tensorflowserving_struggles/,spyder313,1560284618,"Struggling to understand the workflow here for tf serving.

Official docs say to docker pull tensorflow/serving. But they also say to git clone https://github.com/tensorflow/serving.git

1. Which one should I use? I assume the git version is so I can build my own custom serving image?

2 When I pull the official image from docker and run the container, why cant I access the root? Is it because I havent built it properly yet?",4,3
43,2019-6-12,2019,6,12,7,bzivvj,Bunch of books on STEM including TensorFlow are now on sale for $15,https://www.reddit.com/r/tensorflow/comments/bzivvj/bunch_of_books_on_stem_including_tensorflow_are/,ShirleyMoore3,1560290829,,1,0
44,2019-6-12,2019,6,12,14,bznaff,funny project building with coral dev board!,https://www.reddit.com/r/tensorflow/comments/bznaff/funny_project_building_with_coral_dev_board/,makereven,1560318121,,0,0
45,2019-6-12,2019,6,12,15,bznlz9,Tensorflow 2.0 Beta: Model.fit() throws ValueError: Arguments and signature arguments do not match: 56 57,https://www.reddit.com/r/tensorflow/comments/bznlz9/tensorflow_20_beta_modelfit_throws_valueerror/,YM_Industries,1560320518,"I'm new to machine learning. I'm trying to make a simple RNN in Tensorflow 2.0 but I'm hitting a snag. I've reduced it to a minimal example that reproduces the problem. The goal of this minimal example is for the RNN to learn to output 1.0 repeatedly.


    import os
    Import sys
    import math
    from random import shuffle
    import numpy as np
    import tensorflow as tf
    from time import time as time
    
    epochs = 200
    batch_size = 32
    chunk_length = 64
    features = 10
    
    def main():
        train_dataset = np.zeros([batch_size, chunk_length, features]) + 1
        test_dataset = np.zeros([batch_size, chunk_length, features]) + 1
    
        with tf.device('/gpu:0'):
            model = tf.keras.Sequential([
                tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(
                    64, return_sequences=True)),
                tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),
                tf.keras.layers.Dense(64, activation='relu'),
                tf.keras.layers.Dense(1, activation='sigmoid')
            ])
            model.compile(loss='mean_absolute_error',
                optimizer='adam',
                metrics=['accuracy'])
    
            history = model.fit(train_dataset, batch_size=batch_size, epochs=epochs)
    
            test_loss, test_acc = model.evaluate(test_dataset)
    
            print('Test Loss: {}'.format(test_loss))
            print('Test Accuracy: {}'.format(test_acc))
    
    if __name__ == '__main__':
        main()


When I run this I get `ValueError: Arguments and signature arguments do not match: 56 57`. If I comment out the last layer, I get `ValueError: Arguments and signature arguments do not match: 50 51`. If I comment out the last two layers I get `ValueError: Arguments and signature arguments do not match: 44 45`.

I have tried modifying all of the constants I provide (epochs, batch_size, chunk_length, and features) but these have no effect on the error. I also tried removing the element-wise addition of 1 to the numpy arrays, but this also has no effect.

Is this a bug in TensorFlow or am I doing something stupid?",0,2
46,2019-6-12,2019,6,12,16,bzo7fb,Introduction to Multilayer Neural Networks with TensorFlows Keras API,https://www.reddit.com/r/tensorflow/comments/bzo7fb/introduction_to_multilayer_neural_networks_with/,GlennMulligan,1560325035,,0,1
47,2019-6-12,2019,6,12,17,bzom2z,TensorFlow Keras weight shape weirdness,https://www.reddit.com/r/tensorflow/comments/bzom2z/tensorflow_keras_weight_shape_weirdness/,veqtor,1560328390,"Hi, I've been trying to implement ""stylegan"" in Keras but got stuck at trying to create the trainable constant, normally Keras doesn't act this weird for me but... Well, have a look, none else seems to have figured this out (looked for Keras stylegan code). This seems very unnerving if it's some limitation of Keras layer weights  


[https://colab.research.google.com/drive/10LxahkY7KLixSAxDEm6-kyJiRq6XzxVM](https://colab.research.google.com/drive/10LxahkY7KLixSAxDEm6-kyJiRq6XzxVM)

&amp;#x200B;

Is it really reasonable for something as simple as this to not work as expected?",1,5
48,2019-6-13,2019,6,13,0,bzsa62,"model.fit() throws OverflowError: ""Python int too large to convert to C long""",https://www.reddit.com/r/tensorflow/comments/bzsa62/modelfit_throws_overflowerror_python_int_too/,Wofsauge,1560351687,"Hey,  
Im currently making my first project with TensorFlow and i got everything up to the *model.fit()* function to work. Im loading a .CSV file which contains 5000 datapairs with 7 values each. The prediction function works as well. But  when i try to execute the *model.fit()* function in any kind of setting, it throws the error **OverflowError: Python int too large to convert to C long**. But the dataset im using does only contain floats that range around -+100.0, so nothing that could even remotely cause such an issue.  

Does anyone know how i could fix that issue?

Here is my code so far:
https://pastebin.com/pzqjnzyH 

Here are some lines from the datafile:  
https://pastebin.com/YkAhufHS",3,1
49,2019-6-13,2019,6,13,0,bzsdfu,"Variable name conflict error keeps occur, how could I reset the environment to solve this?",https://www.reddit.com/r/tensorflow/comments/bzsdfu/variable_name_conflict_error_keeps_occur_how/,Laurence-Lin,1560352146,"If I run the variable in same environment repeatedly, when using same variables it may show ValueError: variable name already exists  
Initially I tried to set reuse = True in tf.variable\_scope, but now this problem even showed up in the optimizer variables. I'm going to set variable scope for optimizer, but this solution seems stupid to me.

&amp;#x200B;

How could I reset the environment, so I could use get\_variable() everytime I run the code without error?",0,2
50,2019-6-13,2019,6,13,2,bzu0fw,Framework based on Tensorflow,https://www.reddit.com/r/tensorflow/comments/bzu0fw/framework_based_on_tensorflow/,aniketmaurya,1560360264,"Hi everyone!! I am thinking to develop a framework (like [fastai](https://fast.ai)) on top of  Tensorflow for faster project development and prototyping. I need people who have an understanding of Tensorflow. A sample of this project can be found at my git repo: [tf\_assist](https://github.com/aniketmaurya/tf_assist).

If anyone is interested then please contact me at [theaniketmaurya@gmail.com](mailto:theaniketmaurya@gmail.com)",6,0
51,2019-6-13,2019,6,13,4,bzvdak,Install IoT Edge on the Jetson TX2 running JetPack version 4.2,https://www.reddit.com/r/tensorflow/comments/bzvdak/install_iot_edge_on_the_jetson_tx2_running/,mycall,1560366877,,0,1
52,2019-6-13,2019,6,13,5,bzw007,A Quest for high altitute,https://www.reddit.com/r/tensorflow/comments/bzw007/a_quest_for_high_altitute/,Exarillion,1560369914,"Hello fellow warriors and welcome to this post. I was given a quest. The quest is to find a tensor flow model to detect objects from high altitute (\~500 ft.) But I am a just a newbie and currently strugling with finding an efficient model. We are preaparing a DL project for a festival and our model sholud be fast and accurate *""as all models should be"".* I wonder if you could recomend a model or atleast provide me a starting point.

Thank you all.",4,3
53,2019-6-13,2019,6,13,9,bzyt8d,tf.contrib.layers (TF v1.x) in TensorFlow 2.0 install,https://www.reddit.com/r/tensorflow/comments/bzyt8d/tfcontriblayers_tf_v1x_in_tensorflow_20_install/,sfsdfd,1560384592,"I'm using TensorFlow 2.0.0 and am trying to run some TensorFlow 1.x code. I've done the obvious things:

    import tensorflow.compat.v1 as tf
    tf.disable_v2_behavior()

...and my TF code for declaring variables and such runs fine, but there's a lot of stuff missing:

    tf.contrib.optimizers.adam_optimizer
    tf.contrib.layers.fully_connected
    tf.contrib.layers.flatten

I've discovered that tf.contrib is not available in TF 2.0. I also found a vague reference to ""using some add-ons"" to address the missing chunk of the library, without any suggestion as to which add-ons, where to find them, etc.

Any suggestions? Or do I just abandon my TF 1.x code?",4,3
54,2019-6-14,2019,6,14,3,c09l73,Google TensorNetwork Library Dramatically Accelerates ML &amp; Physics Tasks,https://www.reddit.com/r/tensorflow/comments/c09l73/google_tensornetwork_library_dramatically/,Yuqing7,1560451069,,1,16
55,2019-6-14,2019,6,14,4,c09wxy,"Resource Exhausted with bigger data set, even after reduced parameters and batch size",https://www.reddit.com/r/tensorflow/comments/c09wxy/resource_exhausted_with_bigger_data_set_even/,dr-qt,1560452636,"TF 2.0a on a laptop 1050ti 4gig

I increased the data set from ~4500 to ~20000 and my network no longer trains. Reducing the parameters also didnt help. 

After a long process of filling up the shuffle buffer, TF crashes as it gets going with training. 

Is there a setting the will force TF to preload less material? Is something else causing the issue?",6,2
56,2019-6-14,2019,6,14,9,c0dch5,2019 Google Gravity Games - Autonomously Steering a Gravity-Powered Soapbox Car,https://www.reddit.com/r/tensorflow/comments/c0dch5/2019_google_gravity_games_autonomously_steering_a/,csapidus,1560470614,"**Hi, friends!**

Quite excited to be here. I have taken AI/ML courses online but have not actually delved into TF. I am hoping this project will change that. I am trying to steer a gravity-powered soapbox car down a hill with no curves for the 2019 Georgia Google Gravity Games. I am currently equipped with a PI 3 B+, a PI specific camera, a servo motor, the soapbox car itself, and two Corral USB Accelerators.

The environment: is interesting. The lane is linear (no curves), bounded on one-side by double yellow lines, and the other side by haystacks. Photos below:

[https://live.staticflickr.com/65535/48044607306\_1607d599d3\_b.jpg](https://live.staticflickr.com/65535/48044607306_1607d599d3_b.jpg)

[https://live.staticflickr.com/65535/48044639918\_1a0e435886\_b.jpg](https://live.staticflickr.com/65535/48044639918_1a0e435886_b.jpg)

[https://live.staticflickr.com/65535/48044691477\_c6c2c534f1\_b.jpg](https://live.staticflickr.com/65535/48044691477_c6c2c534f1_b.jpg)

&amp;#x200B;

**My approach:**

1. train a model to recognize haystacks and yellow lines, using photos of the track from the 2017 and 2018 Gravity games, and images of haystacks pulled off the internet. 
2. compute (somehow) the mid-line between the haystacks and the yellow lines. use this as a cross-track for the soapbox car to follow
3. calculate cross-track error (CTE) and use a PID loop to minimize by steering (heading output)
4. submit heading to servo motor to actuate alignment of vehicle

Feedback welcome! 

If anyone is interested in assisting with this project (I am using it to teach my high-school cousin the basics), please let me know; we will take all the help we can get, and we will be sure to denote your contribution somehow. There is not a financial prize for winning - it's all in the spirit of learning and fun.

See: [http://www.gagravitygames.com/](http://www.gagravitygames.com/)",0,1
57,2019-6-14,2019,6,14,19,c0ib6l,TFlite in Java,https://www.reddit.com/r/tensorflow/comments/c0ib6l/tflite_in_java/,psychic_star,1560506464,I have a TFlite model and would like to call it using Java. What is the best approach to do it?,4,1
58,2019-6-14,2019,6,14,20,c0j2pm,Cpu optimised tensorflow wheel packages,https://www.reddit.com/r/tensorflow/comments/c0j2pm/cpu_optimised_tensorflow_wheel_packages/,deathholes,1560512291,"Is there a website from I can download cpu optimised wheel packages for tensorflow?
I tried compiling it from sources but was not able to compile it. 
I have to install these on multiple machines so I'm looking for wheel packages and not brainstorm to debug compilation on multiple machines.
Thanks",2,3
59,2019-6-15,2019,6,15,4,c0o46l,Getting layers in a tensorflow graph,https://www.reddit.com/r/tensorflow/comments/c0o46l/getting_layers_in_a_tensorflow_graph/,itsmerandymarch,1560540011,"First of all I should mention I'm a tensorflow noob. Last time I used tensorflow was long ago, and it was only for a very short time before moving to pytorch.

I'm looking for a simple way to know what layers a tensorflow graph contains. It should be very easy, since as far as I know (correct me if I'm wrong) the graph is static.

In pytorch it would be something like going over all sub-modules in model.modules(), and checking if it is of type torch.nn.Conv2d for example. How would you know if a tensorflow graph contains a convolutional layer?",7,2
60,2019-6-15,2019,6,15,12,c0sz87,How do I Properly Shape a 2x1 Matrix for my basic Neural Net?,https://www.reddit.com/r/tensorflow/comments/c0sz87/how_do_i_properly_shape_a_2x1_matrix_for_my_basic/,MapleButterBear,1560569748," I am trying to create a basic neural network model in Keras that will learn to add positive numbers together and am having trouble with shaping the training data to fit the model. I detail the issues in this post here for brevity:

 [https://stackoverflow.com/questions/56606583/how-do-i-correctly-shape-my-data-for-my-nn-model](https://stackoverflow.com/questions/56606583/how-do-i-correctly-shape-my-data-for-my-nn-model)

&amp;#x200B;

Thanks so much in advance!",2,4
61,2019-6-15,2019,6,15,17,c0v33z,Install TensorFlow 2.0 in Colab,https://www.reddit.com/r/tensorflow/comments/c0v33z/install_tensorflow_20_in_colab/,roseindianet,1560586577,,0,1
62,2019-6-16,2019,6,16,11,c155x6,fit_generator does not behave as expected,https://www.reddit.com/r/tensorflow/comments/c155x6/fit_generator_does_not_behave_as_expected/,roset_ta,1560652134,"Hello, 

I am trying to debug a model I built on Keras and I think that I have a problem with fit_generator. I made a custom data generator to read training data from a database and return them for training with batch_size = 1, since my data have various sizes. Same for validation data.


Problem is that when training my model, it reaches accuracy ~0.98 and loss ~0.002 from the first epoch. It keeps improving for max 2 more epochs and then gets stuck, does not learn anything. 


I tried to train on only 20 samples to get a better idea about what's wrong. Noticed that for the 20 samples and 1 epoch training the model behaves well, considering the predictions. But when I get much more training samples, like 2000, the predictions of fscore etc. become literally zero and my visualization are far from expected.



I think there is something wrong with my generator. Right now I expect fit_generator to take as input 1 image and its label (1 batch), and after finishing take the next image. But the problem I mentioned above seems to me like somehow fit_gemerator does not read the data as supposed. Any ideas? 

This is that part of my code:



    def gen(dataset, batch_size):
        while True:
            for batch in range (0, dataset.nb_samples, batch_size):
                x,y = read_one_sample(batch)
                # resize, etc.
                yield(x,y)

    training_dataset = ... # create instance of database
    train_gen = gen(dataset, batch_size=1)
    # same for val generator

    model.fit_generator(train_gen, steps_per_epoch = training_dataset.nb_samples, validation_data = val_gen, validation_steps = val_dataset.nb_samples, epochs=eppchs)",7,2
63,2019-6-17,2019,6,17,0,c1b2w8,I have some doubts about the use of TensorFlow on Android,https://www.reddit.com/r/tensorflow/comments/c1b2w8/i_have_some_doubts_about_the_use_of_tensorflow_on/,winokt,1560698705,"Hi guys.

&amp;#x200B;

For several days I've been looking for a solution to my problem.

I trained a CycleGAN, taken from a project on GitHub, based on TensorFlow. I created the .pb model to perform the inference operations and actually everything works. My problem now is to move the .pb model to Android. I can't use TensorFlow Lite because it has a limited subset of operations and my model is too complex.

&amp;#x200B;

I do not understand what I have to do.

&amp;#x200B;

How do I make inferences about Android? How do I import and use my .pb file? All the online tutorials are too simple for my model, which is more complex.

&amp;#x200B;

Who can help me understand the steps to take?",4,2
64,2019-6-17,2019,6,17,3,c1cycp,Bunch of TensorFlow books are now discounted for only one day!,https://www.reddit.com/r/tensorflow/comments/c1cycp/bunch_of_tensorflow_books_are_now_discounted_for/,ShirleyMoore3,1560708703,"It's all in one bundle and most of the books are on Science, Math, Enginering etc. You don't want to miss out on deals like this.

&amp;#x200B;

Check it here:",4,0
65,2019-6-17,2019,6,17,20,c1m81i,Recommended maximum size input layer,https://www.reddit.com/r/tensorflow/comments/c1m81i/recommended_maximum_size_input_layer/,vratiner,1560769562,"At which order of magnitude the number of elements in the input  vector of a Tensorflow neural network becomes computationally  impracticable when using low specs (e.g. 2.60GHz &amp; 6GB RAM)?

For example, I know that 1,000 input cells are ok, but what about 100K? Or 1M?",0,1
66,2019-6-17,2019,6,17,23,c1ocjm,Is it possible to update one particular value in hashtable in Tensorflow,https://www.reddit.com/r/tensorflow/comments/c1ocjm/is_it_possible_to_update_one_particular_value_in/,honeybooboo1989,1560782643,"The code below first creates a toy dataset with variation specific to each ID. Here I have one categorical variable with various categories. Essentially, what I am trying to do is:

#start of algorithm
    #new instance comes in
    #look up ID in a lookup table, and extract corresponding bias. if the ID is not present, insert it and initialize bias
    #forward and backward pass
    #store updated bias in lookup table
#end of algorithm

  
    import numpy as np
    id_val = np.array([""a"",""a"",""a"",""a"",   ""b"",""b"",""b"",""b"",    ""c"",""c"",""c"",""c"",    ""d"",""d"",""d"",""d""   , ""e"",""e"",""e"",""e""]).reshape(-1,1)
    id_a = np.array([1,1,1,1,   0,0,0,0,    0,0,0,0,    0,0,0,0   , 0,0,0,0])
    id_b = np.array([0,0,0,0,   1,1,1,1,    0,0,0,0,    0,0,0,0   , 0,0,0,0])
    id_c = np.array([0,0,0,0,   0,0,0,0,    1,1,1,1,    0,0,0,0   , 0,0,0,0])
    id_d = np.array([0,0,0,0,   0,0,0,0,    0,0,0,0,    1,1,1,1   , 0,0,0,0])
    id_e = np.array([0,0,0,0,   0,0,0,0,    0,0,0,0,    0,0,0,0   , 1,1,1,1,])
    X_val = np.random.normal(size=20).reshape(-1,1) #one variable, 20 rows
    cte_X = np.matrix(np.column_stack((X_val,id_a,id_b,id_c,id_d,id_e))) #combine cte and X, and id
    y_val = X_val*5.4675 + (id_val == ""a"")*1.2  + (id_val == ""b"")*2.3  + (id_val == ""c"")*3.4  + (id_val == ""d"")*4.4  + (id_val == ""e"")*5.5


So first I want to see whether linear regression module of `scikit learn` finds the parameters:

    #Which parameter values does vanilla linear regression find?
    from sklearn import linear_model
    # specify model
    # we set fit_intercept to false because we manually added the 1 vector
    reg = linear_model.LinearRegression(fit_intercept=False) 
    #fit regression and extract coefficients
    reg.fit(cte_X,y).coef_  
    #array([5.4675, 1.2   , 2.3   , 3.4   , 4.4   , 5.5   ]) #recovers the right parameters


It looks go so far. Then I do a basic linear regression where I compute the gradients by hand:

    #create the weight update function
    def update_weights(idval, w, b, X, y, learn_rate, lookupkey, lookupvalue):
        w_deriv = 0
        b_deriv = 0

        #look up id and corresponding b in table
        #store id in table if does not exist
        location = lookupkey.index(idval) if idval in lookupkey else -1
        if location == -1:
            lookupkey = lookupkey + [idval]
            randval = np.random.uniform(low=-15,high=15)
            lookupvalue = lookupvalue + [randval]
            b = randval
        else:
            b = lookupvalue[location]
    
        # Calculate partial derivatives
        w_deriv = np.sum((2) * ((w * X + b) - y) * X)
        b_deriv = np.sum((2) * ((w * X + b) - y))
        
        # We subtract because the derivatives point in
        # direction of steepest ascent
        w = w - learn_rate * w_deriv
        b = b - learn_rate * b_deriv
        
        # Store new b in table

        lookupvalue[location] = b

        return w, lookupvalue, lookupkey

    
    #randomly initialize w and b
    np.random.seed(seed=17299) 
    w_init = np.random.uniform(low=-15,high=15)
    b_init = np.random.uniform(low=-15,high=15)
    print(w_init)
    print(b_init)
    
    #define function to update weights
    def weight_update_loop(id, learn_rate, b=b_init, w=w_init):
        lookupkey = [] 
        lookupvalue = []
        for epochs in range(100):
                for i in range(len(X_val)):
                    w, lookupvalue, lookupkey = update_weights(idval = id_val[i], w=w, b=b, X=X_val[i,], y=y_val[i,], learn_rate=learn_rate, lookupkey=lookupkey, lookupvalue=lookupvalue)
                    #print(i)
                    #print(b)
                    #print(w)
                #print(epochs)        
        return w, lookupvalue, lookupkey               
    

    w, lookupvalue, lookupkey = weight_update_loop(id= id_val, learn_rate=0.1)   

    print(w)
    #5.4675
    print(lookupkey)
    #[array(['a'], dtype='&lt;U1'), array(['b'], dtype='&lt;U1'), array(['c'], dtype='&lt;U1'), array(['d'], dtype='&lt;U1'), array(['e'], dtype='&lt;U1')]
    print(lookupvalue)
    #[1.1999999999999997, 2.299999999999999, 3.4000000000000004, 4.4, 5.499999999999999]

Yes, that works too! Now I want to do all these in low-level Tensorflow, where i started to have troubles with. Here, I am creating a look-up table using `MutableHashTable` function... 

    X = tf.placeholder(dtype=tf.float32,shape=[None,1], name=""input_placeholder"")
    idx = tf.placeholder(tf.string,shape=[None,1], name=""id_placeholder"")
    y = tf.placeholder(dtype=tf.float32,shape=[None,1],name=""output_placeholder"")
    
    keys_val = tf.constant(['a', 'b', 'c', 'd', 'e'], dtype=tf.string)
    values_val=tf.Variable(tf.random_uniform(shape=[5,], minval=-15, maxval=15, dtype=tf.float32), name=""bias"")
    table = tf.contrib.lookup.MutableHashTable(key_dtype=tf.string, value_dtype=tf.float32, default_value=-1)
    insert_op = table.insert(keys_val, values_val)
    
    n=1
    w = tf.Variable(tf.random_uniform([n,1], -15, 15), name=""weights"")
    b = table.lookup(idx)
    
    y_pred = tf.add(tf.matmul(X, w), b)
    mse = tf.reduce_mean(tf.square(y_pred - y)) / (2 * n) 
    
    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)
    training_op = optimizer.minimize(mse)
    
    with tf.Session() as sess:
        tf.global_variables_initializer().run()
        sess.run(insert_op)
    
        print(sess.run(table.lookup(keys_val)))
        #[-5.4031067  8.661993  13.505377  -3.1402836  6.1885357]
        for epoch in range(100):
            for i in range(len(X_val)):
                Xbatch = X_val[i,].reshape(-1,1)
                ybatch = y_val[i,].reshape(-1,1)
                idbatch = id_val[i,].reshape(-1,1)
            sess.run(training_op, feed_dict = {X: Xbatch, y: ybatch, idx:idbatch})
    
        print(tf.get_default_graph().get_tensor_by_name('bias:0').eval())
        #[-7.8466415 14.649717   7.9616146 -5.0120754  0.884614 ]
        print(tf.get_default_graph().get_tensor_by_name('weights:0').eval())
        #[[-11.078339]]

However, it is not working... I cannot update the hashtable in Tensorflow. Does anyone help me about it?",2,1
67,2019-6-18,2019,6,18,18,c1zzce,i'm rich? show off,https://www.reddit.com/r/tensorflow/comments/c1zzce/im_rich_show_off/,makereven,1560849132,"&amp;#x200B;

https://i.redd.it/tlvibf6a03531.jpg

*Processing img l3dz2g4a03531...*",8,0
68,2019-6-19,2019,6,19,0,c23fog,No OpKernel was registered to support Op 'TensorArrayWriteV3',https://www.reddit.com/r/tensorflow/comments/c23fog/no_opkernel_was_registered_to_support_op/,winokt,1560870774,"I can't make inference on Android Studio because I get this error.

&amp;#x200B;

Any idea?",0,2
69,2019-6-19,2019,6,19,9,c29xcx,SSD Network's loss won't converge,https://www.reddit.com/r/tensorflow/comments/c29xcx/ssd_networks_loss_wont_converge/,tdoe321,1560902893,"I recently have started working on using the tensorflow object detection api to retrain the coco networks on my custom dataset. I've only had luck with training RCNN models. I retrained the model zoo's **faster_rcnn_inception_v2_coco** and had no issues. However, the RCNN models are too slow for my purposes because I'm running it on an embedded system. [This screenshot](https://github.com/Tdoe4321/Reddit_Question/blob/master/Loss.png) is from my **ssd_inception_v2_coco** model's tensorboard output, but every SSD model that I trained (and I trained about 14) looks basically the exact same. For reference, [here's my mAP](https://github.com/Tdoe4321/Reddit_Question/blob/master/mAP.png).

I attached my [pipeline.config](https://github.com/Tdoe4321/Reddit_Question/blob/master/pipeline.config) in a temporary github repo with some of the types of pictures I'm trying to train on. 

I'm using the default pipeline.configs from the model zoo for both the SSD models and the RCNN model. So far, I've tried limiting my dataset to just one label, messing with commenting out little bits from the pipeline.config, and generally giving it what I think is easy data. I also have been able to follow the [running locally](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_locally.md) instructions with the oxford pets dataset and was able to train just fine with that SSD network. 

Basically, I'm wondering two things:
1. Why would the same annotated images quickly and incredibly accurately converge on a RCNN, but not an SSD?
2. Any ideas as to how I can improve my SSD model?",0,2
70,2019-6-20,2019,6,20,4,c2l4n9,Best course of action for a Faster-RCNN implementation,https://www.reddit.com/r/tensorflow/comments/c2l4n9/best_course_of_action_for_a_fasterrcnn/,DanMan259,1560970878,"I have a faster-rcnn caffe model that I am using, and was looking to transfer to the tensorflow object detection api. What would be the suggested method for translating the model from one caffe to the tensorflow.",0,2
71,2019-6-20,2019,6,20,5,c2lwgv,tf.keras vs tf.python.keras,https://www.reddit.com/r/tensorflow/comments/c2lwgv/tfkeras_vs_tfpythonkeras/,avgMLenthusiast,1560974556,Can anyone explain the difference between the two?,14,5
72,2019-6-20,2019,6,20,6,c2n5eo,Tensorflow Error,https://www.reddit.com/r/tensorflow/comments/c2n5eo/tensorflow_error/,akkatips,1560980597,"I've been struggling with this error for a while now and I am clueless on how to resolve this:

 **from** tensorflow\_estimator**.**python**.**estimator**.**tpu**.**tpu\_estimator **import** TPUEstimator 

 **ImportError**: cannot import name 'TPUEstimator' 

&amp;#x200B;

Tried installing it directly and get this error:

 **ERROR**: Could not find a version that satisfies the requirement tensorflow\_estimator.python.estimator.estimator\_lib (from versions: none) 

**ERROR**: No matching distribution found for tensorflow\_estimator.python.estimator.estimator\_lib 

&amp;#x200B;

Completely stumped. Any help would be much appreciated.",2,1
73,2019-6-20,2019,6,20,14,c2s0ws,Restoring the Generator of a GAN from Tensorflow Model,https://www.reddit.com/r/tensorflow/comments/c2s0ws/restoring_the_generator_of_a_gan_from_tensorflow/,Kilerpoyo,1561008595,"&amp;#x200B;

Im trying to restore the trained Generator of a Generative Adversarial Network using a Tensorflow Model (the metagraph and the checkpoint)

Im new to tensorflow and python, so Im not sure if what Im doing is making sense. have already tried importing the metagraph from the meta file and restoring the variables from checkpoint, but im not sure what to do next. My goal is to restore the trained Generator from the last checkpoint and then use it to generate new data from noise input.

Heres a link to a drive containing the model files:[https://drive.google.com/drive/folders/1MaELMC4aOroSQlMJ32J3\_ff3wxiBT\_Fq?usp=sharing](https://drive.google.com/drive/folders/1MaELMC4aOroSQlMJ32J3_ff3wxiBT_Fq?usp=sharing)

So far I have tried the following and it seems to be loading the graph:

    # import the graph from the file  imported_graph = tf.train.import_meta_graph(""../../models/model-9.meta"")   # list all the tensors in the graph  for tensor in tf.get_default_graph().get_operations():      print (tensor.name)   # run the session with tf.Session() as sess: # restore the saved vairable     imported_graph.restore(sess, ""../../models/model-9"")  

However, Im not sure what to do next. Is it possible to run only the trained generator using this files? How can I acces it? Has anybody here done something similar?",0,1
74,2019-6-20,2019,6,20,21,c2vegl,Workflow for training a model on data distributed across multiple nodes ?,https://www.reddit.com/r/tensorflow/comments/c2vegl/workflow_for_training_a_model_on_data_distributed/,life_vortex,1561033665,"So, I've been thinking of training a network (enough to fit on one V100 GPU) on a huge amount of data (\~392 TB). 

The important points are the following :

&amp;#x200B;

a) I have access to one storage node which is big enough to store all of this data in one place.

&amp;#x200B;

b) I have access to nearly 128 GPU nodes (each with V100 GPUs), each one of which has 1TB of SSD storage space.

&amp;#x200B;

c) The RAM available in each compute node is 192 GB.

&amp;#x200B;

&amp;#x200B;

What is a good and efficient workflow to follow for problems like this ?",5,7
75,2019-6-21,2019,6,21,0,c2x9wp,"TOWARD A CONTAINERIZED NVIDIA CUDA, TENSORFLOW AND OPENCV",https://www.reddit.com/r/tensorflow/comments/c2x9wp/toward_a_containerized_nvidia_cuda_tensorflow_and/,aarong-reddit,1561043831,,0,0
76,2019-6-21,2019,6,21,0,c2xamg,"[Project] Tensorflow implementation of ""Zero-Shot Knowledge Distillation in Deep Networks""",https://www.reddit.com/r/tensorflow/comments/c2xamg/project_tensorflow_implementation_of_zeroshot/,sseung0703,1561043928,[removed],0,1
77,2019-6-21,2019,6,21,0,c2xccb,Tensorboard Visual explaination?,https://www.reddit.com/r/tensorflow/comments/c2xccb/tensorboard_visual_explaination/,Jandevries101,1561044172,"Hi everyone,

&amp;#x200B;

I am curious what my tensorboard is showing exactly, because to me, it looks a little bit messy, is it my setup? So what does this all mean and how would i be able to detect wrong setups or issues on it? For example what does ""cond"" stand for and why do i have so many? i am using a DDPG algorithm.

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

https://i.redd.it/l93t74y74j531.png

&amp;#x200B;

Thanks for helping

&amp;#x200B;

Jan",0,1
78,2019-6-21,2019,6,21,2,c2yq0t,I want to make a bot which will learn of user's comments dataset. How can I make it?,https://www.reddit.com/r/tensorflow/comments/c2yq0t/i_want_to_make_a_bot_which_will_learn_of_users/,DazzlingBelt7,1561050818,"I want to parse a bit of reddit and make a big csv lists with comments and it's replies. Like:

&amp;#x200B;

|comment|reply|||
|:-|:-|:-|:-|
| Do you mean keras vs tf.keras?|  No. You can import layers module using|||
|  Wow . What is the data?|  Autonomous driving data gathered from all over the world|||

So which neural net techniuqes can I use to do that? I want to make a bot when user send his message it goes to net's input and gets reply as output.",3,1
79,2019-6-21,2019,6,21,2,c2yuly,Is there any framework which makes using of tensorflow as simple as AWS ML?,https://www.reddit.com/r/tensorflow/comments/c2yuly/is_there_any_framework_which_makes_using_of/,DazzlingBelt7,1561051437,In aws ML you can just upload ur csv select typles of it and your model will be ready. Is there any self hosted things like AWS's one?,2,2
80,2019-6-21,2019,6,21,12,c35jpe,Tensorflow restore model and retrain - ValueError : Duplicate node name in graph,https://www.reddit.com/r/tensorflow/comments/c35jpe/tensorflow_restore_model_and_retrain_valueerror/,ITMSEC,1561087856,"I am trying to restore the trained model and retrain it with some additional operations.

I have 2 python files, lets say

1. train.py - To train and save the model
2. retrain.py - Load the trained model, add new elements in graph and retrain

&amp;#x200B;

**train.py**

    def train():
        # 1 NN
        Xinp1 = tf.placeholder(""float"", [None, 2], name=""Xinp1"")
        Xhidden1 = tf.layers.dense(Xinp1, units=16 , 
                    kernel_initializer=tf.initializers.he_uniform(), 
                    activation=tf.nn.relu, name=""X_hidden1"")
        Xout1 = tf.layers.dense(X_hidden5, units=1, 
     kernel_initializer=tf.initializers.he_uniform(),activation=tf.nn.sigmoid, name=""X_out"")
    
        Xout1 = tf.identity(Xout, name=""Xout1"")
    
        #2 NN
        Xinp2 = tf.placeholder(""float"", [None, 2], name=""Xinp2"")
        Xhidden2 = tf.layers.dense(Xinp2, units=16 , 
                    kernel_initializer=tf.initializers.he_uniform(), 
                    activation=tf.nn.relu, name=""X_hidden2"")
        Xout2 = tf.layers.dense(X_hidden2, units=1, 
    kernel_initializer=tf.initializers.he_uniform(),activation=tf.nn.sigmoid, name=""X_out2"")
    
        Xout2 = tf.identity(Xout2, name=""Xout2"")
    
        Xout1_label = tf.placeholder(""float"", [None,1], name=""Xout1_label"")
        Xout2_label = tf.placeholder(""float"", [None,1],name=""Xout2_label"")
    
    
        learning_rate = 1e-2
        # Define loss and optimizer
        loss_op1 = tf.losses.absolute_difference(Xout1_label, Xout1)
        loss_op2 = tf.losses.absolute_difference(Xout2_label, Xout2)
    
    
    
        # debug gradients
        trainables = tf.trainable_variables()
        print (""trainables"", trainables)
        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, epsilon=0.1)
    
        train_op1 = optimizer.minimize(loss_op1)
        train_op2 = optimizer.minimize(loss_op2)
    
        with tf.Session() as sess:
              sess.run(tf.global_variables_initializer())
              saver = tf.train.Saver()
              for _ in range(100):
                   _, c1, summary = sess.run([train_op1, loss_op1, merged_summary_op], feed_dict={
                Xinp1: X1,
                Xinp2: X2,
                Xout1_label: X1label,
                Xout2_label: X2label
                })    
                   _, c2, summary = sess.run([train_op2, loss_op2, merged_summary_op], feed_dict={
                Xinp1: X1,
                Xinp2: X2,
                Xout1_label: X1label,
                Xout2_label: X2label
                })        
              saver.save(sess, 'Model/trained.ckpt')
              sess.close()

&amp;#x200B;

As an output, I got following files

1. checkpoint
2. trained.ckpt.data-00000-of-00001
3. trained.ckpt.index
4. trained.ckpt.meta

&amp;#x200B;

**retrain.py**

    def retrain():
         with tf.Session() as sess:
               saver = tf.train.import_meta_graph('Model/trained.ckpt.meta')
               saver.restore(sess, 'Model/trained.ckpt')
               graph = tf.get_default_graph()
               Xinp1 = graph.get_tensor_by_name('Xinp1:0')
               Xout1 = graph.get_tensor_by_name('Xout1:0')
               Xinp2 = graph.get_tensor_by_name('Xinp2:0')
               Xout2 = graph.get_tensor_by_name('Xout2:0') 
    
               # I want to add some additional nodes
               T1 = tf.placeholder(""float"", [None, 1], name=""T1"")
               T2 = tf.placeholder(""float"", [None, 1], name=""T2"")
               Add1 = tf.add(tf.multiply(Xout1, tf.subtract(T1, T2)), T2, name=""Add1_out"")
    
               T3 = tf.placeholder(""float"", [None, 1], name=""T3"")
               Add2 = tf.multiply(tf.multiply(T3,tf.subtract(Add1, 300)),tf.multiply(radial_length,0.000001), name=""Add2_out"")
    
               Addlabel = tf.placeholder(""float"", [None, 1], name=""Addlabel"")
    
               loss_op = tf.losses.mean_squared_error(Addlabel, Add2)
    
               # debug gradients
               trainables = tf.trainable_variables()
               print (""trainables"", trainables)
               optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, epsilon=0.1)
               train_op = optimizer.minimize(loss_op)
    
               sess.run(tf.global_variables_initializer())
               #training starts
               # Here I except weights of 1 NN and 2 NN are learned during the training
               for _ in range(100):
                   _, c, summary = sess.run([train_op, loss_op, merged_summary_op], feed_dict={
                   Xinp1 : NewX1,
                   Xinp2 : NewX2,
                   T1 : T1inp,
                   T2 : T2inp,
                   T3 : T3inp,
                   Addlabel : Addtarget               
                    }) 

I am expecting the **retrain.py** to adjust the weights associated with 1 NN and 2 NN during the training.

But now while running the **retrain.py**, I am getting the following error

&amp;#x200B;

    Traceback (most recent call last):
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1659, in _create_c_op
        c_op = c_api.TF_FinishOperation(op_desc)
    tensorflow.python.framework.errors_impl.InvalidArgumentError: Duplicate node name in graph: 'X_hidden1/kernel/Adam'
    
    During handling of the above exception, another exception occurred:
    
    Traceback (most recent call last):
      File ""/home/itmsec/Documents/tipclearance/src/TTG_tensorflowv14.py"", line 493, in &lt;module&gt;
        restore_and_retrain(BDD)
      File ""/home/itmsec/Documents/tipclearance/src/TTG_tensorflowv14.py"", line 244, in restore_and_retrain
        train_op = optimizer.minimize(loss_op)
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py"", line 413, in minimize
        name=name)
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py"", line 595, in apply_gradients
        self._create_slots(var_list)
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/adam.py"", line 135, in _create_slots
        self._zeros_slot(v, ""m"", self._name)
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py"", line 1153, in _zeros_slot
        new_slot_variable = slot_creator.create_zeros_slot(var, op_name)
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py"", line 183, in create_zeros_slot
        colocate_with_primary=colocate_with_primary)
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py"", line 157, in create_slot_with_initializer
        dtype)
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py"", line 65, in _create_slot_var
        validate_shape=validate_shape)
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py"", line 1479, in get_variable
        aggregation=aggregation)
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py"", line 1220, in get_variable
        aggregation=aggregation)
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py"", line 547, in get_variable
        aggregation=aggregation)
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py"", line 499, in _true_getter
        aggregation=aggregation)
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py"", line 911, in _get_single_variable
        aggregation=aggregation)
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py"", line 213, in __call__
        return cls._variable_v1_call(*args, **kwargs)
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py"", line 176, in _variable_v1_call
        aggregation=aggregation)
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py"", line 155, in &lt;lambda&gt;
        previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py"", line 2495, in default_variable_creator
        expected_shape=expected_shape, import_scope=import_scope)
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py"", line 217, in __call__
        return super(VariableMetaclass, cls).__call__(*args, **kwargs)
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py"", line 1395, in __init__
        constraint=constraint)
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py"", line 1509, in _init_from_args
        name=name)
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py"", line 79, in variable_op_v2
        shared_name=shared_name)
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py"", line 1425, in variable_v2
        shared_name=shared_name, name=name)
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
        op_def=op_def)
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
        return func(*args, **kwargs)
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3300, in create_op
        op_def=op_def)
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1823, in __init__
        control_input_ops)
      File ""/home/itmsec/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1662, in _create_c_op
        raise ValueError(str(e))
    ValueError: Duplicate node name in graph: 'X_hidden1/kernel/Adam'",3,2
81,2019-6-21,2019,6,21,19,c38v6s,Deep Learning With TensorFlow,https://www.reddit.com/r/tensorflow/comments/c38v6s/deep_learning_with_tensorflow/,carbonteq1,1561112347,,0,1
82,2019-6-21,2019,6,21,20,c39918,How to sample tensor values given probabilities for each value in tensorflow?,https://www.reddit.com/r/tensorflow/comments/c39918/how_to_sample_tensor_values_given_probabilities/,Shanghoosh,1561115259,"We need to sample values from one tensor regarding to another tensor that contains probabilities. Lets say, we have two tensors t1,t2 of shape (?,3), and want to find another tensor t3 of shape (?,1) that contains a sample of each row in t1 regarding to probabilities in t2.",0,1
83,2019-6-21,2019,6,21,23,c3bm4f,Performance boosts in Tensorflow JS Version 1.0+,https://www.reddit.com/r/tensorflow/comments/c3bm4f/performance_boosts_in_tensorflow_js_version_10/,TheOneRavenous,1561129099,"Just wanted to make sure people knew that Tensorflow JS saw dramatic performance boost in both speed and memory management. I know it's not the preferred training code base like python but for making POC and web apps it's awesome.

I saw a between 2/3 - 3/4 reduction in training time. From 1 hour down to 20-25min. 

[https://github.com/tensorflow/tfjs/releases/tag/v1.0.0](https://github.com/tensorflow/tfjs/releases/tag/v1.0.0)",2,10
84,2019-6-22,2019,6,22,1,c3cste,Tensorflow - How to convert feature_column to vector ?,https://www.reddit.com/r/tensorflow/comments/c3cste/tensorflow_how_to_convert_feature_column_to_vector/,Leobenk,1561134514,"I am building a `Array[feature_column]` but I need to pass my dataframe to a custom estimator which take `tf.placeholder` as input. 

Is there a way to pass my dataframe through something to convert my `feature_column` to the raw `placeholder` ?",2,1
85,2019-6-22,2019,6,22,1,c3cy3i,Tensorflow Array[Object] column to feature_column?,https://www.reddit.com/r/tensorflow/comments/c3cy3i/tensorflow_arrayobject_column_to_feature_column/,Leobenk,1561135168,"One of the column of my dataframe is an array of an object. The object have only two keys, the key and the value. The keys are String and the Values are unbounded double.

For instance:

```
[ {""key"": ""thisIsKey1"", ""value"": 0.1} , {""key"": ""thisIsKey2"", ""value"": 0.5} , ... ]
```

So at the end of the day, it should become a very sparse vector of type:

```
[ 0, 0, ..., 0, 0, 0.1, 0, ..., 0, 0.5, 0, 0, ... ] 
```

Where the index is represented by the string key and the value is the corresponding value. 

The quantity of Keys might be large. 

Is there one of the easy `tf.feature_column` which would work ? 

Or a series of step to serialize it in an efficient way ?

I am trying to make this project using TF2.0 so it is up to date. If the solution is supported on TF2.0, it would be even better !

Thanks.",0,1
86,2019-6-22,2019,6,22,16,c3mzqu,How to I use a Dataset directly as input for a Estimator,https://www.reddit.com/r/tensorflow/comments/c3mzqu/how_to_i_use_a_dataset_directly_as_input_for_a/,jeepartb,1561190108,"I have a Dataset of images parsed from labeled directories, but how would I directly send this as input to the Estimator without using an input function?",2,1
87,2019-6-23,2019,6,23,2,c3s6ry,"How do I create neural networks, as given below, in tensorflow (where one part of input is connected to hidden layers while others are directly connected to output layer)?",https://www.reddit.com/r/tensorflow/comments/c3s6ry/how_do_i_create_neural_networks_as_given_below_in/,imcgr,1561223380,,10,13
88,2019-6-23,2019,6,23,9,c3wwe1,"Sort of new to this, how would I train an object detector on top of an existing inference graph?",https://www.reddit.com/r/tensorflow/comments/c3wwe1/sort_of_new_to_this_how_would_i_train_an_object/,isademigod,1561249783,"Say I'm using the default profile for Faster RCNN Inception V2, with the 90 classes it comes with, and I want to add a new object to its inference graph, but I don't have the original data it was trained on. 

How, with my own dataset and tfrecords, can I add another object to the detection graph? 

I've already trained a frozen inference graph with this dataset, can I merge the two?

Sorry if this is a noob question, I only recently discovered a love for this, and jumped in the deep end with only the basics of python.",0,1
89,2019-6-24,2019,6,24,3,c48w2v,Is there a better way to compute the gradient while training a model?,https://www.reddit.com/r/tensorflow/comments/c48w2v/is_there_a_better_way_to_compute_the_gradient/,myoldemail,1561313686,,2,1
90,2019-6-24,2019,6,24,4,c4a3t4,Finding similarity between 2 sentence,https://www.reddit.com/r/tensorflow/comments/c4a3t4/finding_similarity_between_2_sentence/,wohoody,1561317871,"What is best way to find similarity between 2 sentence? Structured based similarity, not mean based.",6,1
91,2019-6-24,2019,6,24,6,c4cduc,Do placeholders exist in tensorflowjs?,https://www.reddit.com/r/tensorflow/comments/c4cduc/do_placeholders_exist_in_tensorflowjs/,louisgoals,1561325596,"If they don't, is there anything to replace them?",1,0
92,2019-6-24,2019,6,24,21,c4mw47,I can't import all keras package at a same time,https://www.reddit.com/r/tensorflow/comments/c4mw47/i_cant_import_all_keras_package_at_a_same_time/,Laurence-Lin,1561379348,"If I do:

&amp;#x200B;

from tensorflow.keras import \*

&amp;#x200B;

The compiler returns:  


 'unable to detect undefined names'  


But I can import the packages under keras if I import them separately. How could I solve the problem?",2,1
93,2019-6-25,2019,6,25,3,c4swwy,TensorFlow on Microcontroller for Accelerometer?,https://www.reddit.com/r/tensorflow/comments/c4swwy/tensorflow_on_microcontroller_for_accelerometer/,FamiliarPermission,1561400642,"I've found examples for voice and images, but I have yet to find an example for detecting gestures using an accelerometer for TensorFlow on a microcontroller (uTensor?).  


Someone else must have already done this before...",0,2
94,2019-6-25,2019,6,25,9,c4yms9,Tiny Machine Learning on the Edge with TensorFlow Lite Running on SAMD51,https://www.reddit.com/r/tensorflow/comments/c4yms9/tiny_machine_learning_on_the_edge_with_tensorflow/,blinka_friendlysnake,1561420899,,0,26
95,2019-6-25,2019,6,25,15,c53m6m,Using Jupyter Notebook with Tensorboard on SSH server,https://www.reddit.com/r/tensorflow/comments/c53m6m/using_jupyter_notebook_with_tensorboard_on_ssh/,jeepartb,1561442917,"How would I load tensorboard while in a Jupyter notebook? For reference, I am trying to use tensorboard on a tf.estimator.",1,1
96,2019-6-25,2019,6,25,19,c56d1h,How to decode an image on the GPU while training a network in Keras?,https://www.reddit.com/r/tensorflow/comments/c56d1h/how_to_decode_an_image_on_the_gpu_while_training/,ale152,1561458143,,0,0
97,2019-6-26,2019,6,26,0,c59zbo,Neural Machine Translation With Attention Mechanism: Step-by-step Guide,https://www.reddit.com/r/tensorflow/comments/c59zbo/neural_machine_translation_with_attention/,Victor_Stakh,1561475526,,0,1
98,2019-6-26,2019,6,26,1,c5awhl,Resnet-18,https://www.reddit.com/r/tensorflow/comments/c5awhl/resnet18/,roboticsR,1561479348,"Hello Guys,

&amp;#x200B;

I'm creating an encoder-decoder network loosely based on resnet--18 for the encoder part. But I can't actually find any resnet-18 pre-trained models out there do I need to train it from scratch or I'm I not looking at the places I should.",6,1
99,2019-6-26,2019,6,26,8,c5hr3q,Rant on tensorflow 2.0,https://www.reddit.com/r/tensorflow/comments/c5hr3q/rant_on_tensorflow_20/,HarambeTownley,1561506515," Yesterday  I decided to finally upgrade to tf2.0 from my tf1.11. Needless to say I  also had reinstall CUDA and CuDNN because I use gpu version. After  upgrade ALL my older code is deprecated.

But  you might say ""oh tf provided you with convertors blah blah"" - that  sounds cool and shit and for many cases the problem isn't that big but  we all know machine learning is NOT about code. IT'S ABOUT MODELS. I had  built a model using tf.contrib.layers which I trained for HOURS. And  now you say ""we're dropping tf.contrib"" - wtf? So now my model which I  created in tensorflow core but used tf.contrib.layers for Xavier  Initialization is deprecated now? You say I should use keras like  tf.initializers now? WHY? My goddamn model, which I saved after hours of  training, was saved with tf.contrib.layers. I tried replacing  tf1.contrib.layers.xavier\_initializer() with  tf2.initializers.GlorotUniform() but that just causes shit ton of more  errors. SO WHAT TF AM I SUPPOSED TO DO WITH THIS KERAS LAYER? I can't  load my older model and run it. Am I supposed to re-train all my models?

I  understand we have to move on, especially that newer models are dynamic  so eager had to be the way forward. But why tf would you deprecate all  my models and code but only provide convertors for code? Also I have so  many files, Am I supposed to run tf convertor on all of them and then  check which among those are working and then fix the ones that aren't?",8,2
100,2019-6-26,2019,6,26,10,c5izws,Set custom CUDA path?,https://www.reddit.com/r/tensorflow/comments/c5izws/set_custom_cuda_path/,colonel_farts,1561512605,"Im working on a server, so dont have permissions to just cp the relevant files to /user/lib. Basically there are several different CUDA installations on this server, and even when I load the correct module, my usr/lib/cudnn.h is the wrong version. I know where the correct install is located, is there a way in tensorflow to specify a custom path to CUDA? Or specifically cuDNN?",4,2
101,2019-6-26,2019,6,26,18,c5nqj4,Get softmax layer activations from TF Zoo pretrained models,https://www.reddit.com/r/tensorflow/comments/c5nqj4/get_softmax_layer_activations_from_tf_zoo/,ambodi,1561541527,I need to get values of the softmax layer activations for the data that Mobilenet V1 was trained on (COCO training set). Is it possible to get that from the checkpoints or frozen graph files that come from the Zoo models somehow?,1,2
102,2019-6-26,2019,6,26,23,c5q7bg,Convolutional Neural Networks: An Intuitive Approach,https://www.reddit.com/r/tensorflow/comments/c5q7bg/convolutional_neural_networks_an_intuitive/,jimscott1232,1561557807,,1,3
103,2019-6-27,2019,6,27,0,c5qvit,"""Using Kubernetes for Machine Learning Frameworks"" with Arun Gupta (53min talk from GOTO Chicago 2019)",https://www.reddit.com/r/tensorflow/comments/c5qvit/using_kubernetes_for_machine_learning_frameworks/,goto-con,1561561314,,1,3
104,2019-6-27,2019,6,27,10,c5zbg7,How to build image datasets quickly,https://www.reddit.com/r/tensorflow/comments/c5zbg7/how_to_build_image_datasets_quickly/,ats678,1561599740,"Hello guys, I have a project on my mind based on image recognition. The only thing is that I dont know how I can make image datasets in a quick/autonomous way without getting every single picture manually.. Ive tried using beautifulsoup and webscraping but failed miserably. Can anyone suggest me a different solution or maybe just give me some advices. That would be really appreciated!",16,7
105,2019-6-28,2019,6,28,6,c6az1r,Build TensorFlow Lite model with Firebase AutoML Vision Edge | thinkmobile.dev,https://www.reddit.com/r/tensorflow/comments/c6az1r/build_tensorflow_lite_model_with_firebase_automl/,frogermcs,1561669253,,1,3
106,2019-6-28,2019,6,28,10,c6dqdw,How does the Udacity and Coursera TF 2 courses compare?,https://www.reddit.com/r/tensorflow/comments/c6dqdw/how_does_the_udacity_and_coursera_tf_2_courses/,tlalco,1561684261,"Im wondering what each course is good for.

[https://www.udacity.com/course/intro-to-tensorflow-for-deep-learning--ud187](https://www.udacity.com/course/intro-to-tensorflow-for-deep-learning--ud187)

[https://www.coursera.org/specializations/tensorflow-in-practice](https://www.coursera.org/specializations/tensorflow-in-practice?utm_medium=email&amp;utm_source=marketing&amp;utm_campaign=9rwAsJOfEemdOAf9ya7Q1g)",3,14
107,2019-6-28,2019,6,28,13,c6fi1b,"libtensorflow 1.14.0 for the Nvidia Jetson, OS X and Linux with AVX2 support",https://www.reddit.com/r/tensorflow/comments/c6fi1b/libtensorflow_1140_for_the_nvidia_jetson_os_x_and/,lastzer0,1561694855,"I'd like to share our ""TensorFlow for C"" binaries as compiling alone took 12 hours plus I had to try 4 different compiler versions and create a pull request for tensorflow (was merged today):

&amp;#x200B;

[https://dl.photoprism.org/tensorflow/](https://dl.photoprism.org/tensorflow/)  


The build for the  Jetson Nano includes full GPU support. The TX and AGX might need slightly different settings depending on the GPU architecture. Raspberry Pi should work if you disable CUDA and maybe change the -march parameter.  


GCC 4.x was the only compiler that worked reliably. However it does not optimize for the latest CPUs. 7.x up to 8.3.0 have a confirmed bug (fixed in 8.3.1, which was not available for Ubuntu yet). There are other dependencies like Java and Python required in specific versions. I've also shared our config and Dockerfile if you want to try on your own.",0,1
108,2019-6-28,2019,6,28,17,c6hu5o,How to perform gradient accumulation WITH distributed training in TF 2.0 / 1.14.0-eager and custom training loop (gradient tape)?,https://www.reddit.com/r/tensorflow/comments/c6hu5o/how_to_perform_gradient_accumulation_with/,veqtor,1561711828,"Background: I have a model and I'm trying to port it to TF 2.0 to get some sweet eager execution, but I just can't seem to figure out how to do distributed training (4 GPU's) AND perform gradient accumulation at the same time.

Problem:

* I need to be able to use a custom training loop with gradient tape because I have a complex multi-model problem (several input models and output models training together), I do not need 2nd order gradients
* With the size of my model (moderate, something like a medium sized transformer) I can't get a batch size larger than \~32 with 4 GPU's which is the largest instance I can get get a hold of, sadly, these are really old 11GB K80's because Azure seems to think that GPU's that Google doesn't even give away for free anymore are good enough...........
* I have a dataset that require very large batches because I have to account for very big imbalance (I'm also using weighting and focal loss ofc), thus I need to perform 4-8 steps of gradient accumulation to smooth out the gradients.

I've read distributed training loops guide and managed to implement it:  
[https://www.tensorflow.org/beta/tutorials/distribute/training\_loops](https://www.tensorflow.org/beta/tutorials/distribute/training_loops)

I've also implemented gradient accumulation in TF 2.0 for custom training loops and tf.keras:  
[https://colab.research.google.com/drive/1yaeRMAwhGkm1voaPp7EtFpSLF33EKhTc](https://colab.research.google.com/drive/1yaeRMAwhGkm1voaPp7EtFpSLF33EKhTc)

&amp;#x200B;

Question on Stack Overflow if you want to earn some points

[https://stackoverflow.com/questions/56793932/how-to-perform-gradient-accumulation-with-distributed-training-in-tf-2-0-1-14](https://stackoverflow.com/questions/56793932/how-to-perform-gradient-accumulation-with-distributed-training-in-tf-2-0-1-14)",0,1
109,2019-6-28,2019,6,28,22,c6jwop,Is re-using the batch dimension for something else a feature or a bug in TF 2.0?,https://www.reddit.com/r/tensorflow/comments/c6jwop/is_reusing_the_batch_dimension_for_something_else/,Dobias,1561726806,"`tensorflow-1.14.0` complains about the following minimal example

```python3
import numpy as np
import tensorflow.keras.backend as k
from tensorflow.keras.layers import Input, Conv2D, Lambda
from tensorflow.keras.models import Model

def custom_reshape(inputs):
    return k.reshape(inputs, (-1, 8, 8, 3))

inputs = Input(shape=(8, 8, 6))
x = Lambda(custom_reshape)(inputs)
x = Conv2D(32, (3, 3))(x)
model = Model(inputs=inputs, outputs=x)
model.compile(loss='mean_squared_error', optimizer='nadam')
print(model.summary())
batch_size = 10
result = model.predict(np.ones((batch_size, 8, 8, 6)), batch_size=batch_size)
print(result.shape)
```

with `ValueError: could not broadcast input array from shape (20,6,6,32) into shape (10,6,6,32)`.

`tensorflow==2.0.0-beta1` however happily runs it and prints `(20, 6, 6, 32)`.

Is this an intended feature (""misusing"" the batch dimension of a convolution layer that way), or a glitch in TF 2.0?",2,2
110,2019-6-28,2019,6,28,23,c6kyrw,How to update partial row in an embedding matrix?,https://www.reddit.com/r/tensorflow/comments/c6kyrw/how_to_update_partial_row_in_an_embedding_matrix/,prudhvirajd,1561732711,"Hello,

I am working on a project where the some of the word embeddings are known and the others are initialized randomly, and when training, I would like to only update the randomly initialized embedding rows and freeze the known rows. How do I do this in tensorflow, if there is a way?",1,2
111,2019-6-29,2019,6,29,12,c6tlg7,Have can I use Tensorflow to fill in packet loss on video files?,https://www.reddit.com/r/tensorflow/comments/c6tlg7/have_can_i_use_tensorflow_to_fill_in_packet_loss/,tvl92,1561777211,"Basically Ive never used Tensorflow and must use it for a course I need to pass before graduation. I have a project where I must run videos that have a sections of pixels missing from the video and run it through Tensorflow and train it to learn to fill in whats missing. Is this possible and how is the process of setting it up? 

Any recommendations or advice or sources would really help. This accelerated course really is giving me a hard time",0,1
112,2019-6-29,2019,6,29,14,c6v5gu,A Brief Introduction About TensorFlow,https://www.reddit.com/r/tensorflow/comments/c6v5gu/a_brief_introduction_about_tensorflow/,javatpoints,1561787050,,0,1
113,2019-6-29,2019,6,29,15,c6vhcf,Tensorflow 2.0 Question,https://www.reddit.com/r/tensorflow/comments/c6vhcf/tensorflow_20_question/,dundir,1561789408,"Hey there, I'm just beginning to get started with AI/ML. 

I was going through the standard hello world tutorial located [here](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/tutorials/quickstart/beginner.ipynb#scrollTo=hiH7AC-NTniF).

I ran through it on my local system but the accuracy following the exact same steps/data was much lower over the same epochs (~87%).

Should I expect different hardware to provide different results where the data and algorithm over the same iteration of epochs are constant?

I hope I didn't mess up my setup somehow. If there is a better place to ask these type of questions, please let me know.",0,1
114,2019-6-29,2019,6,29,21,c6yaqt,"After TF2, can we quietly forget TF1 ever happened?",https://www.reddit.com/r/tensorflow/comments/c6yaqt/after_tf2_can_we_quietly_forget_tf1_ever_happened/,clanleader,1561810719,"Like many other non-geniuses and non-PhD engineers, the entire graph model of TF1 completely turned me away from using TF for anything more than cookie-cutter supervised learning problems. Especially compared to PyTorch, the framework completely sucked for anyone that doesn't naturally swim in math and graphs intuition (ie: the majority of users). As an amateur, instead of attempting to implement theoretical concepts from various ML papers, I was instead battling graph spaces. 

TF2 looks elegant, beautiful, and simple. I'm hoping a plethora of books and tutorials teaching advanced AI concepts using it as a backbone are soon written. 

My question is, do you think we could soon discard of all the TF1 literature and courses, or will they forever remain a permanent stain within the TensorFlow ecosphere? I just think TF as a whole would do very well if it could completely move on and quietly forget that TF1 ever happened. Combined with vast parallelization via the cloud &amp; TPUs, it could eclipse PyTorch. But the awful default graph model of TF1 must be forgotten completely for it to remain attractive to anyone but the brightest of ML minds.

Will TF be like Python 2 and Python 3, dragging on with two separate versions for over a decade? Or can we all just agree to close our eyes to the horrid mess that was TF1 and pretend it never happened and now move on and finally treat TF2 as the standard and only TF?",12,12
115,2019-6-29,2019,6,29,22,c6yosp,Keep getting an error when I try to load a model.h5 on google colab,https://www.reddit.com/r/tensorflow/comments/c6yosp/keep_getting_an_error_when_i_try_to_load_a/,roundof1995,1561813284,"I made a pre-trained model and to reduce the compilation time I'm trying to load the file, with this command.

model.load_model('newmodel.h5',compile=FALSE)

but I keep getting this error 'Sequential' object has no attribute 'load_model'",0,1
116,2019-6-29,2019,6,29,22,c6yz2e,Question about Random Forest,https://www.reddit.com/r/tensorflow/comments/c6yz2e/question_about_random_forest/,TheWipyk,1561815050,"Hi guys! 

I have [this](https://drive.google.com/open?id=1qlJU5vuXehomT2VhyngqvgwC7UOkm8RI) data set, on which I'd like to use the Random Forest. My question is, how will the algorithm know which columns are predictors and which one is the target variable? I did not see any explicit ways of doing so. 

For my data, the first column is the target variable, the rest are predictors. Fortunately all my predictors are multi-class ( B, C and D are numbers, the rest are -1, 0, +1). 

&amp;#x200B;

Thanks :)",1,0
117,2019-6-30,2019,6,30,14,c79g5x,I got Tensorflow to control my 24/7 live beach camera (installed one the island of Koh Phangan in Thailand),https://www.reddit.com/r/tensorflow/comments/c79g5x/i_got_tensorflow_to_control_my_247_live_beach/,ethan1el,1561871699,,19,29
118,2019-6-30,2019,6,30,17,c7auic,How to install TensorFlow,https://www.reddit.com/r/tensorflow/comments/c7auic/how_to_install_tensorflow/,_spicyramen,1561883010,"I know of the following methods:
Pipy package via pip install 
Bazel build
Docker container
Pre built VM
Any other method?",3,0
119,2019-6-30,2019,6,30,20,c7byeo,What is tensorflow.python.data.ops.dataset_ops._OptionsDataset?,https://www.reddit.com/r/tensorflow/comments/c7byeo/what_is_tensorflowpythondataopsdataset_ops/,Madhu34,1561893280,"I am using the Transformer code from tensorflow - [https://www.tensorflow.org/beta/tutorials/text/transformer](https://www.tensorflow.org/beta/tutorials/text/transformer)

In this code, the dataset used is loaded like this -

    examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,                                as_supervised=True) train_examples, val_examples = examples['train'], examples['validation']

When I check the type of train\_examples using :

    type(train_examples)

I get the following as output -

    tensorflow.python.data.ops.dataset_ops._OptionsDataset

Now I just wanted to change some entries of the dataset that is the sentences, but I am not able to as I don't understand the type.

I am able to iterate over it using :

    for data in train_examples: print(data,type(data))

And type of data is -

    &lt;class 'tuple'&gt;

Finally what I want is to replace some of these tuples with my own data. Can someone tell me how to do this or give me some details about this typetensorflow.python.data.ops.dataset\_ops.\_OptionsDataset  
.",2,2
120,2019-6-30,2019,6,30,23,c7etec,How to use GPU when doing image analysis?,https://www.reddit.com/r/tensorflow/comments/c7etec/how_to_use_gpu_when_doing_image_analysis/,NanoVash,1561904978,"I'm trying to run ImageAI on images that I have an it takes more than 10 seconds to run on a single image.

It took about the same time when I knew it was running on CPU, so it is obviously not running on GPU.

However, I installed tensorflow-gpu hoping it would use that instead. How can I make it so ImageAI and similar libraries use the GPU?",9,6
0,2019-7-2,2019,7,2,4,c7yw94,I'm having some troubles with my first TF AI,https://www.reddit.com/r/tensorflow/comments/c7yw94/im_having_some_troubles_with_my_first_tf_ai/,ph04,1562009544,"basically, i wanted to try to build an AI to generate some text based on the original italian version of the ""Divine Comedy"".

the problem is that i've never built anything with TF on my own so i stole the code from a TF tutorial from here   [https://www.tensorflow.org/tutorials/sequences/text\_generation](https://www.tensorflow.org/tutorials/sequences/text_generation). this is the script i came out with, it's basically the same thing [https://gist.github.com/ph04/0084a1478079f138667a8bf7e2b78623](https://gist.github.com/ph04/0084a1478079f138667a8bf7e2b78623), except for the fact that i tried to thange every single possile editable or tweakable thing but no matter what i do i always end up with the same results (which you can see in the picture down below)

i know it seems like 14 epochs were not enough to change, but trust me it sticks on the same values

LOSS: \~2.4

ACC: \~0.02

i really need to know what am i missing, since i've also tried to wait all 200 epochs, change everything i could, i generated text with those weights many times but had always the same results because, you know, no loss change, no better AI performance.

 [https://gist.github.com/ph04/331de1e1ff2b23a415fef4604ca3ccc3](https://gist.github.com/ph04/331de1e1ff2b23a415fef4604ca3ccc3) generator script

&amp;#x200B;

(also sorry for the broken codes but they were tests, i think the main parts are pretty much understandable)

https://i.redd.it/3x4r74zztq731.png",15,6
1,2019-7-2,2019,7,2,10,c832sr,Bunch of Web Development books including TensorFlow's are now discounted!,https://www.reddit.com/r/tensorflow/comments/c832sr/bunch_of_web_development_books_including/,PatAllman,1562031296,,7,0
2,2019-7-2,2019,7,2,20,c882k0,"Best way to convert traditional images into MNIST format, for testing purposes on a CNN trained by MNIST dataset?",https://www.reddit.com/r/tensorflow/comments/c882k0/best_way_to_convert_traditional_images_into_mnist/,Fengax,1562066681,"I have just trained my first CNN network by using the MNIST dataset, it is the most famous handwriting dataset. However, instead of using their testing images, I want to **utilize my own 28x28 testing images.**

The rationale behind this, is that I want to make a handwriting recognition program, so obviously I need a way to convert traditional image format to the one-dimensional MNIST format, so that the CNN can read it.

What is the best way to accomplish this task?",8,4
3,2019-7-3,2019,7,3,0,c8aa4h,"Does TFRecord file have to contain the original image, or can it contain a reference?",https://www.reddit.com/r/tensorflow/comments/c8aa4h/does_tfrecord_file_have_to_contain_the_original/,neuronet,1562079739,"I am learning the tf object detection API, and working with images that are *very* large (often 10kpixel by 20kpixel). The point of this research is to do high-res object tracking, so we do not want to downscale and then track, but to do full resolution tracking (we often have a hundred objects in our images that need to be tracked).  

The problem is using the standard TFRecord construction, where you literally include the image itself as a feature, by the time we reach a dozen training images we will have prohibitively large TFRecord files. 

Is there a way to build the record files/do transfer learning in a way that the record files only need to include a pointer to/reference to the original file? Or do I need to just create a bunch of TFRecord files, maybe one for each image, or one every N images?",7,1
4,2019-7-3,2019,7,3,2,c8cec1,What does the output of Keras model.predict mean?,https://www.reddit.com/r/tensorflow/comments/c8cec1/what_does_the_output_of_keras_modelpredict_mean/,roset_ta,1562090067,"Hello,


I'm working on an image segmentation problem where each image of my test set has a counterpart binary mask. So, the ground truth masks are one - hot encoded, so each pixel is either 0 or 1. 

I used Keras model.predict to evaluate my model. My question is about the predicted masks I get, since each pixel is a value between 0 and 1. What do these values mean? Are they the probabilities of each pixel belonging to the class of interest (i.e. being the segmented object) ? And if so, how do I know the class the model predicted for each pixel value?",2,3
5,2019-7-3,2019,7,3,7,c8g071,Trying out TF2.0 Keras - error on model.fit(),https://www.reddit.com/r/tensorflow/comments/c8g071/trying_out_tf20_keras_error_on_modelfit/,ME_PhD,1562106408,"I'm playing around with the new Keras API and want to fit -4x\^3 + 2x\^2 -x + 5 . The program should optimize the variable ""w"" to the value \[-4, 2, -1, 5\] .

Here's my code which can run the model.predict(x) without problems, but [model.fit](https://model.fit)() doesn't work:

    import tensorflow as tf
    import numpy as np
    
    # making ""training set""
    def f(x, w):
        return w[0] * x**3 + w[1] * x**2 + w[2] * x + w[3]
    
    coeffs = [-4, 2, -1, 5]
    x_train = np.linspace(0, 5, 100)
    y_train = f(x_train, coeffs)
    
    # Model:
    x = tf.keras.layers.Input(shape=(), dtype=tf.float32)
    w = tf.Variable(np.zeros(4, dtype=np.float32))
    yhat = w[0] * x**3 + w[1] * x**2 + w[2] * x + w[3]
    model = tf.keras.Model(inputs=x, outputs=yhat)
    model.compile(loss='mse', optimizer='adam')
    
    model.predict(x_train) # works fine
    model.fit(x_train, y_train, epochs=100) 
    # ValueError: operands could not be broadcast together with shapes (32,) (4,) (32,)",1,2
6,2019-7-3,2019,7,3,9,c8h75w,[Beginner] How can I add independent values to an InceptionV3 CNN model?,https://www.reddit.com/r/tensorflow/comments/c8h75w/beginner_how_can_i_add_independent_values_to_an/,NingaMEW,1562113010,"I'm using a slightly-modified version of the InceptionV3 CNN model to create a self-driving AI.  To collect data, I record myself playing the game, and every frame records the image of the game on my screen, and the state of a few inputs on my game controller (turn, throttle, and break).  Each value ranges from 0 to 1.

The model takes in an X value, which is the screen, and a Y value, which contains the values for each control for that frame.

The problem is that when I use the prediction function after training my AI, it returns a balanced array which adds up to 1.  It's not treating the inputs separately, but as a whole.

&amp;#x200B;

[INPUT CONTROLS ARRAY](https://i.redd.it/4svlz8aqdz731.png)

The input controls array is paired with the screen for each frame.

The left variable is turn; .5 would represent straight, 0 left, and 1 right.  Middle variable is throttle intensity, right is brake intensity. 

[OUTPUT ARRAY](https://i.redd.it/rg3mj60udz731.png)

&amp;#x200B;

Sorry I'm such a noob at this.",9,1
7,2019-7-3,2019,7,3,12,c8iu85,Beginner Question on Hardware,https://www.reddit.com/r/tensorflow/comments/c8iu85/beginner_question_on_hardware/,BMXnotFIX,1562122957,"I am brand new to TensorFlow and ml in general. I have a couple options on what to use to run it and was wondering which would be best. The first option would be a Windows machine with an i7 8700k, gtx 1080 gpu, and 16gb of ddr4. The second option, which I assume would make the most sense, is my homelab server which is a Dell r710 (I can technically run any OS via virtualization, but I would be using Ubuntu most likely as I am more familiar with the Python api.).

&amp;#x200B;

Now, I'm assuming the r710 would be best suited due to it's more workhorse characteristics, but I read that gaming oriented CPU/GPUs actually worked in TensorFlow's favor due to hyperthreading/parallel processing, so I figured I'd double check with the community.",8,1
8,2019-7-3,2019,7,3,12,c8j07y,Any resources for learning Tensorflow for Deep Learning.,https://www.reddit.com/r/tensorflow/comments/c8j07y/any_resources_for_learning_tensorflow_for_deep/,pradeep_sinngh,1562123990,,2,0
9,2019-7-3,2019,7,3,21,c8npjv,Need more tutorials in TensorFlow sub classing,https://www.reddit.com/r/tensorflow/comments/c8npjv/need_more_tutorials_in_tensorflow_sub_classing/,begooboi,1562158265,I love keras and I have worked with its sequential and functional api but not the sub classing api. I searched the web and there is not much tutiorials explaing sub classing in keras or tf.keras. Even if it exists the example codes or explanations would be complex. I find this method more flexible and powerful than sequential or functional api's.,1,1
10,2019-7-3,2019,7,3,23,c8orum,Tensorflow Keras Layer Reshape: Is this a bug?,https://www.reddit.com/r/tensorflow/comments/c8orum/tensorflow_keras_layer_reshape_is_this_a_bug/,Mushoz,1562164247,"The following sample code doesn't work for me, and I am suspecting it's a bug. Could someone please confirm my suspicion? Or am I doing something wrong?

&amp;#x200B;

    import tensorflow as tf
    import numpy as np
    
    def Model():
        
        x = tf.keras.layers.Input((4,4,3)) # 4x4 image with 3 channels
        y = tf.keras.layers.Conv2DTranspose(3, 4, 2, padding='same') (x) # Creates a 8x8 images with 3 channels by upsampling with stride 2
        
        linear = tf.keras.layers.Dense(8*8*3) (x) # Linear transformation of the input
        linear = tf.keras.layers.Reshape([8, 8, 3]) (linear) # Reshapes the output of the linear transformation to the same shape as the upsampled image
        y = tf.keras.layers.Add() ([y, linear]) # adds them together
        
        return tf.keras.models.Model(inputs=x, outputs=y)
    
    # model
    model = Model()
    
    # input data
    array_range = np.random.randn(128, 4, 4,  3).astype(np.float32)
    dataset = tf.data.Dataset.from_tensor_slices(array_range).batch(8)
    iterator = dataset.make_one_shot_iterator()
    next_element = iterator.get_next()
    dataset_output = model(next_element)
    
    # session
    sess = tf.Session()
    sess.run(tf.global_variables_initializer())
    
    # evaluate
    print(sess.run(dataset_output))
    print(sess.run(dataset_output))

&amp;#x200B;

As far as I can tell, the dimensions as correct. Reshape works correctly in regular feed forward models. But when used within a skip connection as is done in the sample connection, I am getting the following error:

&amp;#x200B;

    Input to reshape is a tensor with 24576 values, but the requested shape has 1536",3,2
11,2019-7-4,2019,7,4,1,c8pz7o,TensorFlow Lite Ported to Arduino by Adafruit,https://www.reddit.com/r/tensorflow/comments/c8pz7o/tensorflow_lite_ported_to_arduino_by_adafruit/,blinka_friendlysnake,1562170381,,1,20
12,2019-7-4,2019,7,4,3,c8rqzi,noob trying to install Tensorflow for a class - getting error message?,https://www.reddit.com/r/tensorflow/comments/c8rqzi/noob_trying_to_install_tensorflow_for_a_class/,highc1157,1562178838,"i have python 3.7

in CMD i ran 'pip install tensorflow'

generated this after a bunch of installs happened :

t**ensorboard 1.14.0 has requirement setuptools&gt;=41.0.0, but you'll have setuptools 40.8.0 which is incompatible**",3,0
13,2019-7-4,2019,7,4,7,c8uu44,Tensorflow Broke My Oculus,https://www.reddit.com/r/tensorflow/comments/c8uu44/tensorflow_broke_my_oculus/,sstovall19,1562193998,I did a lot of nvidia-related things to my Windows 10 GeForce GTX-1070 MAX-Q Laptop to get Tensorflow-gpu to work but now my previously working Oculus rig gives me black screen in the headset. Any thoughts?,4,0
14,2019-7-5,2019,7,5,6,c984bk,Eigenvalue tasks in Tensorflow?,https://www.reddit.com/r/tensorflow/comments/c984bk/eigenvalue_tasks_in_tensorflow/,HypoCelsus,1562276754,"Hello all    
I am looking for a library that can find the eigenvalues of a matrix that has the following characteristics:    
* Sparse (&lt;5% non-zero entries)    
* Complex + Hermitian (equal to its conjugate transpose)    
It ain't exactly what TF is about but I've tried MAGMA  with no luck. Maybe something new has come along since I've looked around last.",1,2
15,2019-7-5,2019,7,5,7,c98r65,Should I learn TF1 or TF2?,https://www.reddit.com/r/tensorflow/comments/c98r65/should_i_learn_tf1_or_tf2/,AnomalyNexus,1562280528,"Right at the start of my TF journey so opted for TF1 on the assumption that there will be better resources and guides available.

This thread has made me second-guess that thinking though:

https://www.reddit.com/r/tensorflow/comments/c6yaqt/after_tf2_can_we_quietly_forget_tf1_ever_happened/

Get the basics on TF1 first or dive straight into TF2 and potentially struggle with incompatible tutorials?",6,2
16,2019-7-5,2019,7,5,8,c991ht,TF vs LuaTorch,https://www.reddit.com/r/tensorflow/comments/c991ht/tf_vs_luatorch/,hassanzadeh,1562282328,"Hey Guys,

I had two set of legacy codes one which does a 1D CNN and the other that does 1D CNN + 2 layers of LSTM. I recently changed that into Tensorflow, the logic is similar, but my torch code runs 10 times faster while using only ONE cpu, my TF runs on 8 cpu and yet is about 10 times slower for the 2nd model and about 5 times slower for the first one. 

Is that what it is really supposed to be? The running time difference is huge. 

&amp;#x200B;

Thanks",2,1
17,2019-7-5,2019,7,5,14,c9ce4m,TensorFlow.js Bringing Machine Learning to the Web and Beyond,https://www.reddit.com/r/tensorflow/comments/c9ce4m/tensorflowjs_bringing_machine_learning_to_the_web/,RosemaryRol,1562306245, [https://morioh.com/p/d3f3aa2a604f](https://morioh.com/p/d3f3aa2a604f),0,1
18,2019-7-5,2019,7,5,19,c9eaek,Linkedin Opensources Avro2TF: An Open Source Deep learning tool for Feature Transformation for TensorFlow,https://www.reddit.com/r/tensorflow/comments/c9eaek/linkedin_opensources_avro2tf_an_open_source_deep/,bhavinjawade,1562321365,,0,12
19,2019-7-6,2019,7,6,11,c9ofji,Urgent help needed. I'm required to learn TensorFlow and basically all of DL superficially in 3 DAYS. Please help me do this!,https://www.reddit.com/r/tensorflow/comments/c9ofji/urgent_help_needed_im_required_to_learn/,anotheraccount97,1562380012," I got an internship through my university's 6 month industrial experience program where I was allowed to brag/overstate with fake Skills in order to get allotted a decent organization. I know Soft Dev (Java,DSA etc etc), Python somewhat.

&amp;#x200B;

They've given me a deep learning profile on the basis of my mention of Tensorflow, Keras etc. Now the intern starts on Monday(3 days from now), so I'll need to learn it superficially so that my manager doesn't get the hint that I was lying. In the course of first week, I wish to learn as much as possible, and then with the ongoing internship of 6 months, I'll try to do my best to become an expert in the same.

&amp;#x200B;

Please help me by stating exact resources, short courses that I can binge upon, and links of videos of workshops/bootcamps that I can go through this Sat/Sun/Mon to gain a presentable knowledge of the DL field, also some ML (I don't know ML too, extremely sorry for the disrespect to this beautiful field). How do I go about this humongous task? It's a question upon my career. Apologies and Thanks.",25,0
20,2019-7-7,2019,7,7,2,c9w7zy,Is there a way to do this without a loop?,https://www.reddit.com/r/tensorflow/comments/c9w7zy/is_there_a_way_to_do_this_without_a_loop/,ronsap123,1562434400,"Suppose I have two tensors:

Tensor A of shape (10, 100, 32)

Tensor B of shape (10, 32)

&amp;#x200B;

Now I do something like this:

&amp;#x200B;

result = \[\]

for i in range(0,10):

result.append(  dot(B\[i\],A\[i\].transpose() )

&amp;#x200B;

Is there a way to get this result without a for loop?",6,3
21,2019-7-7,2019,7,7,19,ca5md8,Can anyone please help me to solve this problem,https://www.reddit.com/r/tensorflow/comments/ca5md8/can_anyone_please_help_me_to_solve_this_problem/,Pratik668,1562496909,"Create a Variable that will contain an array of numbers. Create a Variable ""n"" that will contain a number. 

 Now, create a Session. Run it for 10 iteration. At every iteration, take a value as input from user. 

Use that input to modify the value of ""n"" .

 Then modify the \[n % len(array)\] th index of the array node value by multiplying the previous value with n.

 Example: arr = \[1, 2, 3\] 

n = 0,  Inside Loop:  1st iteration: 

n = 2 (input by user) 

index = n % len(arr) =&gt; 2 % 3 =&gt; 2 

Therefore, arr\[2\] = arr\[2\] \* n =&gt; 2\*2 =&gt; 4   

 Updated value of arr = \[1, 4, 3",2,1
22,2019-7-8,2019,7,8,0,ca7w1f,TensorFlow 2.x C++ API - are any changes planned from TensorFlow 1.x C++ API?,https://www.reddit.com/r/tensorflow/comments/ca7w1f/tensorflow_2x_c_api_are_any_changes_planned_from/,cdahms,1562512525,"As we all know by now, the TensorFlow 2.x Python interface is moving away from old-school TensorFlow with sessions to Keras as the default, which we pretty much all feel is a good change.

My question is, is there any change to this effect planned for the TensorFlow 2.x C++ interface?

Currently I'm training TensorFlow graphs in Python and inferencing them in C++ (the inferencing has to be done from a product written in C++ so this is a necessity). The C++ TensorFlow inferencing code I've developed is based on the TensorFlow GitHub C++ examples, especially this one:

[https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/label\_image/main.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/label_image/main.cc)

Referring to the TensorFlow webpage for the C++ API as of when I'm writing this (June 2019):

[https://www.tensorflow.org/guide/extend/cc](https://www.tensorflow.org/guide/extend/cc)

They are still using sessions in the C++ explanation, whereas all the Python examples on the TensorFlow site now use the Keras interface.

Also, all the articles I can find about TensorFlow 2.x mention moving away from sessions towards the Keras interface, but none ever mention C++ specifically or have any C++ examples to this effect.

Based on this, I'm inclined to believe at this time that when TensorFlow 2.x gets past Beta into the regular releases that the C++ interface will still be old-school session based. Can anybody confirm or deny this is correct? Is there any official word on staying with sessions vs. moving away from sessions from Google for the C++ interface specifically?",0,8
23,2019-7-8,2019,7,8,7,cad6ok,Need help exporting retrained MobileNetV2 web,https://www.reddit.com/r/tensorflow/comments/cad6ok/need_help_exporting_retrained_mobilenetv2_web/,NebulousGoat,1562540132,"Hello,

I am currently in the process of retraining the ssd_mobilenet_v2_coco from the [tensorflow zoo examples](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models). In order to do so I created record files out of tf.Examples for my test and train images by following this [tutorial](https://medium.com/object-detection-using-tensorflow-and-coco-pre/object-detection-using-tensorflow-and-coco-pre-trained-models-5d8386019a8). With the only difference being that I am using `model_main.py` instead of the legacy `train.py`, since I ran into the same issues with the legacy version and was hoping the new version would fix them. 

The issue comes when trying to convert one of the trained checkpoints, or the final model to tfjs. 

Running `export_inference_graph.py --input_type=image_tensor ...` on the generated `model.chkpt-???` files creates a saved_model where all the BatchNorm tensors are empty. This works fine in Python and I'm able to extract the num_detections, scores, boxes, and classes after feeding in an image. However, running the tfjs converter leaves in all the `is_training : true` data, resulting in the web model to crash as it tries to utilize the empty BatchNorm tensors. 

If I try using the saved_model that `model_main.py` produces after reaching the max number of training steps I run into a different issue. The converted model.json file still contains all the is_training data, but the expected input is now a tf_example instead of an image_tensor. I can't seem to find any documentation that talks about how to transform an html img into a tf_example, so I am unsure of where to go from here. 

Most issues reported on github that are similar claim to have been fixed, or don't have any purported solution. I'd prefer to somehow work around my already trained model, without needing to retrain the whole thing. 

Any help will be greatly appreciated. 

---

It should be noted that running the `tensorflowjs_converter` on the model straight from the zoo example works without issue and is able to make predictions in the web. Just that introducing tf.Examples to retrain it seems to have removed that ability and somehow mucked up the final model.json file. 

Also I'm running tensorflow 1.13.1, and the converter issues are present in both 0.8.6 and 1.2.2.1.",1,2
24,2019-7-8,2019,7,8,14,cagsu2,A Beginners Guide to Tensorflow,https://www.reddit.com/r/tensorflow/comments/cagsu2/a_beginners_guide_to_tensorflow/,javatpoints,1562562352,,0,1
25,2019-7-8,2019,7,8,22,cakuir,"AdaBoost, Simplest Example",https://www.reddit.com/r/tensorflow/comments/cakuir/adaboost_simplest_example/,bhavesh91,1562591500,,0,3
26,2019-7-9,2019,7,9,2,canxi3,Tensorflow Graph Construction Optimization,https://www.reddit.com/r/tensorflow/comments/canxi3/tensorflow_graph_construction_optimization/,timsua,1562606425,"The graph construction process for my model is taking ~4 minutes at the moment, which is super annoying. Does anyone know any tips or tricks for debugging the actual graph construction process of tensorflow? Are there common ""best practices"" that you are aware of?",2,1
27,2019-7-9,2019,7,9,4,caprrn,"I started recreating the This Person Does Not Exist project, generating faces with a GAN. I had to write nearly everything from scratch!",https://www.reddit.com/r/tensorflow/comments/caprrn/i_started_recreating_the_this_person_does_not/,Fear_UnOwn,1562614545,,14,21
28,2019-7-9,2019,7,9,6,carkjn,TensorflowJS Math Operations?,https://www.reddit.com/r/tensorflow/comments/carkjn/tensorflowjs_math_operations/,Simusid,1562622934,"I'm writing my first TFJS demo app.    I have a well trained cats/dogs binary classifier that I've converted using the converter.    I can load the model and pass images from an iphone or android camera for classification.   Unfortunately, the results are terrible.    My model was trained using a keras ImageDataGenerator with samplewise\_center and samplewise\_std\_normalization both set to true.   I'm now pretty sure I need to do the same normalization in my app.   

&amp;#x200B;

I see tf.math.reduce\_mean and reduce\_std in the full API.   In the JS API I see ts.mean but no ts.std.    Do I need to calculate this from scratch?",0,1
29,2019-7-9,2019,7,9,9,catmbw,This video goes over a breast cancer diagnosis model that uses neural networks (implemented in python),https://www.reddit.com/r/tensorflow/comments/catmbw/this_video_goes_over_a_breast_cancer_diagnosis/,antaloaalonso,1562633403,,0,1
30,2019-7-10,2019,7,10,1,cb38bo,How to get text and numeric labels into correct format for regression?,https://www.reddit.com/r/tensorflow/comments/cb38bo/how_to_get_text_and_numeric_labels_into_correct/,colonel_farts,1562690160,"Using TF 2.0 beta.

&amp;#x200B;

I have a pandas dataframe consisting of lines of text and an associated numeric score. I know what I need to do is convert each line of text into an array of integers, pass that into an embedding layer, then through the rest of the network, and have my last layer be a single output with ReLU. Then I can optimize MSE of the output against the true numeric score associated with that text. 

&amp;#x200B;

Problem is, this sounds easier than it is proving to be to implement. 

I'm trying to loosely follow this tutorial: [https://www.tensorflow.org/beta/tutorials/load\_data/text](https://www.tensorflow.org/beta/tutorials/load_data/text)

I can't seem to appropriate this part of the code for my purposes:

&amp;#x200B;

def labeler(example, index):  
 return example, tf.cast(index, tf.int64)   
labeled\_data\_sets = \[\]  
for i, file\_name in enumerate(FILE\_NAMES):  
 lines\_dataset = tf.data.TextLineDataset(os.path.join(parent\_dir, file\_name))  
 labeled\_dataset = lines\_dataset.map(lambda ex: labeler(ex, i))  
 labeled\_data\_sets.append(labeled\_dataset)

&amp;#x200B;

I can get a TextLineDataset from my text, but I need to label each with the associated numeric score, rather than 0,1,2 like in this tutorial. 

&amp;#x200B;

Any ideas? Thanks in advance.",0,1
31,2019-7-10,2019,7,10,1,cb3ar6,Debugging Question,https://www.reddit.com/r/tensorflow/comments/cb3ar6/debugging_question/,CanadianColours,1562690475,"I was wondering if there was a way to profile the number of Matrix multiplies a model is using on a forward pass.

Additionally, if it's possible to see processor network traffic.",0,2
32,2019-7-10,2019,7,10,3,cb4n02,Help! 4 GPUs Out of Memory for medium sized model.,https://www.reddit.com/r/tensorflow/comments/cb4n02/help_4_gpus_out_of_memory_for_medium_sized_model/,helpmymodel,1562696393,"I am trying to figure out why I get OOM errors when trying to run my CNN-LSTM model on 4 16GB Nvidia gpus.

&amp;#x200B;

My input size is (batch\_size,4,240,576,23). I have no trouble loading the data into memory using a generator so I only load in one batch at a time. The trouble is when I attempt to call the train\_on\_batch function for my model. The model in question only has \~800,000 numbers of parameters. I have tried many different ways of using the GPU but I always end up getting a OOM error even if I decrease my batch size as low as 4.

I have tried using multi\_gpu\_model and Mirror Variable strategy and neither work, any batch size over 4 fails.

&amp;#x200B;

I want to get a batch size of 16 and it shouldn't take 10 secs to train on one image. I shouldn't have to use all 4 gpus either, preferably one or two.

&amp;#x200B;

What should I do? Any help is much appreciated.

&amp;#x200B;

&amp;#x200B;

Details

OS: Red Hat Enterprise 7.5

Using Keras 2.2.4

Tensorflow,tensorflow-gpu: 1.13.1",10,6
33,2019-7-10,2019,7,10,3,cb4qgj,Question About Number of Nodes from Layer to Layer,https://www.reddit.com/r/tensorflow/comments/cb4qgj/question_about_number_of_nodes_from_layer_to_layer/,sammybh123,1562696810,"I am a beginner with respect to TF, but have a technical background. I was reading though the basic classification guide on the TF website (https://www.tensorflow.org/tutorials/keras/basic_classification), and I had a questions about how to determine the amount of nodes in layers.

After flattening, the number of nodes for one of the images in the guide above is 784. The next layer is a relu layer that has 128 nodes. 

My questions are: How did we determine that 128 was the best number of nodes to use? My understanding of relu in this context was that it outputted its input, provided the value is positive. If that is the case, how does the number of nodes decrease by a fixed amount every time an image is processed by this layer?

Thanks in advance for your help, and please let me know if I need to clarify my questions!",2,3
34,2019-7-10,2019,7,10,4,cb58gx,Tensorflow and Keras For Neural Networks and Deep Learning,https://www.reddit.com/r/tensorflow/comments/cb58gx/tensorflow_and_keras_for_neural_networks_and_deep/,dhakadeal,1562699018,,0,1
35,2019-7-10,2019,7,10,11,cbaham,Introduction to Machine Learning with TensorFlow.js,https://www.reddit.com/r/tensorflow/comments/cbaham/introduction_to_machine_learning_with_tensorflowjs/,Dorothy109zxy,1562724446, [https://morioh.com/p/d53a9bde1027](https://morioh.com/p/d53a9bde1027),1,2
36,2019-7-11,2019,7,11,0,cbi52w,"How to use a pre-trained tensorflow model ""out-of-the-box""?",https://www.reddit.com/r/tensorflow/comments/cbi52w/how_to_use_a_pretrained_tensorflow_model/,Sinbad_07,1562772585,"   

I am trying to use a pre-trained tensorflow model to be used in  object detection. Specifically, I am looking at the  faster\_rcnn\_inception\_v2\_coco model as many of the objects I would like  to detect are in the COCO dataset. Am I able to use this model out of  the box, or are they more so like templates to train on? Also, how would  I go about testing these then. I am still very new to Tensorflow and  appreciate any help I can get. Thanks!",8,8
37,2019-7-11,2019,7,11,6,cbn0m4,Help needed in converting queues to regular placeholders,https://www.reddit.com/r/tensorflow/comments/cbn0m4/help_needed_in_converting_queues_to_regular/,nlpredditproject,1562795475,"Hi,

&amp;#x200B;

I've been following this tutorial : [https://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/](https://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/) 

It is using queues for generating the inputs and the targets (next word in text). How can I do the same trick of generating the sliced data, just with placeholders instead of the used queue ?

&amp;#x200B;

Thanks",1,1
38,2019-7-11,2019,7,11,19,cbu8ve,Tensorflow probability layers during training,https://www.reddit.com/r/tensorflow/comments/cbu8ve/tensorflow_probability_layers_during_training/,chaosbambi,1562841860,"Hi I am currently exploring variational autoencoders with tensorflow probability. I understand that instead of the distribution, a sampled tensor is used during training, but how does keras calculate the gradient? Is it a reparametrization trick?",3,2
39,2019-7-11,2019,7,11,20,cbupek,Looking for best reference to learn tensorflow :),https://www.reddit.com/r/tensorflow/comments/cbupek/looking_for_best_reference_to_learn_tensorflow/,cedzkii,1562845109,,7,2
40,2019-7-11,2019,7,11,20,cburer,Mask RCNN predicted class values and logits do not match,https://www.reddit.com/r/tensorflow/comments/cburer/mask_rcnn_predicted_class_values_and_logits_do/,ambodi,1562845462,"I am using the ""mask\_rcnn\_inception\_v2\_coco\_2018\_01\_28"" model downloaded from Zoo model ([https://github.com/tensorflow/models/blob/master/research/object\_detection/g3doc/detection\_model\_zoo.md](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md)).

I am trying to access the tensors that are holding the logits for  each class for the image that is fed to the model. I found out that **SecondStageBoxPredictor/Reshape\_1** is holding those values, however when comparing them with **detection\_classes**,  I realized that the values do not match. I want to first find out where  are the correct logits and then document this as it is useful to have  these documented correctly.

&amp;#x200B;

    with tf.Session(graph=tf.Graph()) as sess:
        tf.saved_model.loader.load(sess, ['serve'], GRAPH_PB_PATH)
        graph = tf.get_default_graph()
    
        image = Image.open(IMAGE_PATH)
        (im_width, im_height) = image.size
        image_np = np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)
        image_np_expanded = np.expand_dims(image_np, axis=0)
        
        image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')
    
        tensor_dict = {}
        
        tensor_dict['SecondStageBoxPredictor/Reshape_1:0'] = graph.get_tensor_by_name('SecondStageBoxPredictor/Reshape_1:0')
        tensor_dict['detection_classes:0'] = graph.get_tensor_by_name('detection_classes:0')
        
        output_dict = sess.run(tensor_dict,
                                 feed_dict={image_tensor: image_np_expanded})

Btw, the same goes with the following tensors:

&amp;#x200B;

    tensor_dict['Reshape_12'] = graph.get_tensor_by_name('Reshape_12:0')
    tensor_dict['scale_logits'] = graph.get_tensor_by_name('scale_logits:0')
    tensor_dict['convert_scores'] = graph.get_tensor_by_name('convert_scores:0')
    tensor_dict['BatchMultiClassNonMaxSuppression_1/map/TensorArrayStack_2/TensorArrayGatherV3'] = graph.get_tensor_by_name('BatchMultiClassNonMaxSuppression_1/map/TensorArrayStack_2/TensorArrayGatherV3:0')
    
    for i in range(0, 92):
            np.argmax(output_dict['Reshape_12'][i])
            np.argmax(output_dict['scale_logits'][0][i])
            np.argmax(output_dict['convert_scores'][0][i])
            np.argmax(output_dict['BatchMultiClassNonMaxSuppression_1/map/TensorArrayStack_2/TensorArrayGatherV3'])

Does anyone have an idea why that is the case and how to find the correct logits per class?",0,1
41,2019-7-12,2019,7,12,1,cbxcr7,How to solve this question using tensorflow ?,https://www.reddit.com/r/tensorflow/comments/cbxcr7/how_to_solve_this_question_using_tensorflow/,Pratik668,1562860903,"Create a Variable that will contain an array of numbers. Create a Variable ""n"" that will contain a number.

Now, create a Session. Run it for 10 iteration. At every iteration, take a value as input from user.

Use that input to modify the value of ""n"" .

Then modify the \[n % len(array)\] th index of the array node value by multiplying the previous value with n.

Example: arr = \[1, 2, 3\]

n = 0,  Inside Loop:  1st iteration:

n = 2 (input by user)

index = n % len(arr) =&gt; 2 % 3 =&gt; 2

Therefore, arr\[2\] = arr\[2\] \* n =&gt; 2\*2 =&gt; 4

Updated value of arr = \[1, 4, 3\]",3,0
42,2019-7-12,2019,7,12,1,cbxtv1,Why is my tensorflow model so stupid? (minimal multilayer perceptron),https://www.reddit.com/r/tensorflow/comments/cbxtv1/why_is_my_tensorflow_model_so_stupid_minimal/,alteer,1562863104,"I built a simple multilayer perceptron to solve an XOR problem. I was hoping it would consistently converge on 100% accuracy after a few epochs (2000- which seems like a lot for a domain size of 8), but often the accuracy is still &lt; 100%! Am I missing something?

    from tensorflow.keras import layers
    from itertools import product
    import numpy as np
    
    # Data
    X = np.array(list(product([0,1], repeat=3)))
    y = np.array([a ^ b ^ c for a, b, c in X])
    
    # Define the Model
    INPUT_UNITS = 3
    HIDDEN_LAYER_UNITS  = 5
    OUTPUT_UNITS = 2
    
    model = tf.keras.Sequential()
    model.add(layers.Input(INPUT_UNITS))
    model.add(layers.Dense(HIDDEN_LAYER_UNITS, tf.nn.relu))
    model.add(layers.Dense(HIDDEN_LAYER_UNITS, tf.nn.relu))
    model.add(layers.Dense(HIDDEN_LAYER_UNITS, tf.nn.relu))
    
    model.add(layers.Dense(OUTPUT_UNITS, tf.nn.softmax))
    
    # Specify Train, Test, and Predict
    N_EPOCHS = 200
    model.compile(loss='sparse_categorical_crossentropy', optimizer='Nadam', metrics=['accuracy'])
    history = model.fit(x=X,  
        epochs=N_EPOCHS, 
        y=y,
        verbose=0)
    
    model.evaluate(X, y)
    
    predicted = np.argmax(model.predict(x=X), axis=1)
    print(f""Predicted: {predicted}"")
    print(f""Actual: {y}"")",4,3
43,2019-7-12,2019,7,12,7,cc22nx,"What is the optimal eGPU for running Tensorflow on macOS, let's say for a 500 budget and 1000 budget?",https://www.reddit.com/r/tensorflow/comments/cc22nx/what_is_the_optimal_egpu_for_running_tensorflow/,HenslerSoftware,1562882771,,7,2
44,2019-7-12,2019,7,12,7,cc2egq,Lottery Scratcher GAN network using tensorflow and pix2pix,https://www.reddit.com/r/tensorflow/comments/cc2egq/lottery_scratcher_gan_network_using_tensorflow/,skryshtafovychReal,1562884430,,4,3
45,2019-7-12,2019,7,12,18,cc8g1w,What is the optimal eGPU for running Tensorflow on Ubuntu?,https://www.reddit.com/r/tensorflow/comments/cc8g1w/what_is_the_optimal_egpu_for_running_tensorflow/,HenslerSoftware,1562922378,"After posting a request for any eGPU devices with the capability of working with Tensorflow on macOS, it loos as though limitations set by Apple are causing issues.

So I am now looking towards a Ubuntu option.

What are the best benchmarked eGPU devices that work with Tensorflow on Ubuntu with the a maximum budget of 200 and a maximum of 500?",10,4
46,2019-7-13,2019,7,13,1,ccd6zs,How to get submodel' s weights from .hd5 file?,https://www.reddit.com/r/tensorflow/comments/ccd6zs/how_to_get_submodel_s_weights_from_hd5_file/,roset_ta,1562949460,"Hello,


I have a pretrained Keras model saved as a .hd5 file. The model consists of two submodels and a fusion module, where the submodels have been trained independently and then their outputs were used in fusion.
 Is it possible that I only extract the weights for one of the submodels from that file? How can I do that in keras?",0,2
47,2019-7-13,2019,7,13,20,ccoii7,"How to automatically ""fit domain to data"" in Tensorboard",https://www.reddit.com/r/tensorflow/comments/ccoii7/how_to_automatically_fit_domain_to_data_in/,Roboserg,1563018862,Basically you have to press this button ([https://puu.sh/DSha5/1d4d77e9cf.png](https://puu.sh/DSha5/1d4d77e9cf.png)) over and over again during training to fir the graph to the screen. There should be a way to do this problematically / automatically.,7,2
48,2019-7-14,2019,7,14,0,ccqwum,How to count the number of elements in variable in Tensor Flow,https://www.reddit.com/r/tensorflow/comments/ccqwum/how_to_count_the_number_of_elements_in_variable/,Pratik668,1563033580," Suppose I have variable A = tf.Variable(\[1,2,3,4\], dtype=tf.float32) and I want to count the no of elements in it. so the output becomes   count = 4 

how to do this with tensorflow ?",4,3
49,2019-7-14,2019,7,14,2,ccruf1,TypeError: Input 'x' of 'LogicalOr' Op has type float32 that does not match expected type of bool,https://www.reddit.com/r/tensorflow/comments/ccruf1/typeerror_input_x_of_logicalor_op_has_type/,geek_ki01100100,1563038519,"I'm using tf.where in a subroutine with the single argument x that is used in a Keras Lambda layer but keep on getting this error which google showed no matches for

    Traceback (most recent call last):
      File ""viz.py"", line 70, in &lt;module&gt;
        model = model_setup()
      File ""viz.py"", line 51, in model_setup
        scaled_img = Lambda(lambda x: DifferentiableRound(x)/255)(Lambda(scale(0,255))(img))
      File ""/usr/local/lib/python3.5/dist-packages/keras/engine/base_layer.py"", line 457, in __call__
        output = self.call(inputs, **kwargs)
      File ""/usr/local/lib/python3.5/dist-packages/keras/layers/core.py"", line 687, in call
        return self.function(inputs, **arguments)
      File ""viz.py"", line 51, in &lt;lambda&gt;
        scaled_img = Lambda(lambda x: DifferentiableRound(x)/255)(Lambda(scale(0,255))(img))
      File ""viz.py"", line 36, in DifferentiableRound
        return where(cond, (x - tan(K.sin((1 / 1 + 7 ^ (-1 * tan(2 * x)))))), (x - tan(K.sin((1 / 1 + 7 ^ (-1 * tan(2 * x))))) - 0.5))
      File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py"", line 894, in r_binary_op_wrapper
        return func(x, y, name=name)
      File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py"", line 1165, in logical_xor
        gen_math_ops.logical_or(x, y),
      File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py"", line 4484, in logical_or
        ""LogicalOr"", x=x, y=y, name=name)
      File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py"", line 533, in _apply_op_helper
        (prefix, dtypes.as_dtype(input_arg.type).name))
    TypeError: Input 'x' of 'LogicalOr' Op has type float32 that does not match expected type of bool.",0,1
50,2019-7-14,2019,7,14,12,ccye98,KerasTPUModel has no attribute '_ckpt_saved_model',https://www.reddit.com/r/tensorflow/comments/ccye98/kerastpumodel_has_no_attribute_ckpt_saved_model/,rish-16,1563074977,"Hey everyone,

I'm trying to train a NMT model on a TPU on Colab and when I called `tpu_model.fit(...)` it gives me the error in &lt;TITLE&gt;.

My model is a standard LSTM and I've already done the whole connecting thing with the TPU_COLAB_ADDR and whatnot. That's all set.

Has anyone been through this? Any help would be greatly appreciated!
Cheers!",6,3
51,2019-7-14,2019,7,14,14,ccznui,"Looking for buddies to figure out Tensorflow's Tensor2Tensor library. One of the most prominent TF libraries out there, developed jointly by Google Brain and Google Research.",https://www.reddit.com/r/tensorflow/comments/ccznui/looking_for_buddies_to_figure_out_tensorflows/,AdditionalWay,1563083923,,1,5
52,2019-7-14,2019,7,14,15,cczwsy,Issues with installing Tensorflow,https://www.reddit.com/r/tensorflow/comments/cczwsy/issues_with_installing_tensorflow/,UpmaPesarattu,1563085962,"I am trying to install on Ubuntu 18.0.4 TF using instructions [here](https://www.tensorflow.org/install/gpu) (gpu);  I am installing stable version and not 2.0 beta.

I am able to install all the nvidia drivers (checked the installation), CUDA libraries (verified them), and development libraries i.e., I was able to successfully complete the following instruction on the page
    
    # Install development and runtime libraries (~4GB)
    sudo apt-get install --no-install-recommends \
        cuda-10-0 \
        libcudnn7=7.6.0.64-1+cuda10.0  \
        libcudnn7-dev=7.6.0.64-1+cuda10.0
    
But moving forward, the next step of installing TensorRT is failing i.e., the following command

    # Install TensorRT. Requires that libcudnn7 is installed above.
    sudo apt-get update &amp;&amp; \        
            sudo apt-get install -y --no-install-recommends libnvinfer-dev=5.1.5-1+cuda10.0

The  error message I see is this:

---

The following packages have unmet dependencies:
 libnvinfer-dev : Depends: libnvinfer5 (= 5.1.5-1+cuda10.0) but 5.1.5-1+cuda10.1 is to be installed

---

1. It appears that libnvinfer-dev depends on libnvinfer5. But I cannot locate where is this libnvinfer5 package. 
2. I've actually installed cuda10.0 (I found that pre-build Tensorflow libraries use 10.0 and there are issues with 10.1). So it's confusing why the message says cuda10.1 is to be installed. Can anyone provide some clarity what's going on here.

Next steps.

Though instructions to install TensorRT are provided on Tensorflow website (link [here](https://www.tensorflow.org/install/gpu)), I found that they are also available on developer page of Nvidia (requires login):  https://developer.nvidia.com/nvidia-tensorrt-5x-download.

I've downloaded ubuntu18 CUDA package from the above page (~800 MB download). Having seen MANY MANY posts on issues with version conflicts, I am quite apprehensive to install this package. So I am looking for advice here.

Questions

1. Are instructions provided on Tensorflow [page](https://www.tensorflow.org/install/gpu)  specifc to installing TensorRT inadequate? Or any packages missing from the repo. Can I download them from elsewhere?
2. Can I install TensorRT from Nvidia dev page?",0,1
53,2019-7-14,2019,7,14,17,cd0jlw,Need some HELP with tf.argmax,https://www.reddit.com/r/tensorflow/comments/cd0jlw/need_some_help_with_tfargmax/,slmde,1563091311,"Here is my code:

 

`def build_model():`  
`main_input=Input(shape=(64,),name='main_input')`  
`x=Dense(64,activation='sigmoid',name='hidden_1')(main_input)`  
`second_input=Input(shape=(32,),name='second_input')`  
`x2=Dense(32,activation='softmax',name='hidden_2')(second_input)`  
`x2=tf.argmax(x2)`  
`y=tf.keras.layers.concatenate([x,x2])`  
 `return Model(inputs=[main_input,second_input],outputs=y)`

&amp;#x200B;

And an error happened:

A \`Concatenate\` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: \[(None, 64), (32,)\]

&amp;#x200B;

I'd like to know how can I concatenate a tensor with a label index",1,1
54,2019-7-15,2019,7,15,1,cd4uih,Does anyone know how to convert NVIDIA's StyleGAN to tflite?,https://www.reddit.com/r/tensorflow/comments/cd4uih/does_anyone_know_how_to_convert_nvidias_stylegan/,Ashar7,1563121204,I want to use [NVIDIA's StyleGAN](https://github.com/NVlabs/stylegan) in firebase. They provide a pickle file for the network but I don't have much experience in tensorflow so I couldn't convert their model to tflite. Can anyone help me here?,0,1
55,2019-7-15,2019,7,15,4,cd6z58,Annotated simple word2vec in Tensorflow 2 [Feedback Please!],https://www.reddit.com/r/tensorflow/comments/cd6z58/annotated_simple_word2vec_in_tensorflow_2/,RedPillDevil,1563131978,,0,1
56,2019-7-15,2019,7,15,4,cd73jp,Simple annotated word2vec using Tensorflow 2 [Feedback please!],https://www.reddit.com/r/tensorflow/comments/cd73jp/simple_annotated_word2vec_using_tensorflow_2/,richardanaya,1563132581,[https://github.com/richardanaya/word2vec-tensorflow2/blob/master/word2vec.ipynb](https://github.com/richardanaya/word2vec-tensorflow2/blob/master/word2vec.ipynb),1,1
57,2019-7-15,2019,7,15,5,cd7mq0,Not able to install Object Identification API on Google Collab notebook,https://www.reddit.com/r/tensorflow/comments/cd7mq0/not_able_to_install_object_identification_api_on/,learningeveryday111,1563135227,"Hello!
I followed all the steps on the installation page of the object detection API (and changed the PYTHONPATH) too but the main_builder_test.py file is not running. The error that pops up is that nets module is not found. Has anyone worked with object detection on google collab earlier? Can you help me out? Ill share my code then (its only 6 standard lines though)",6,2
58,2019-7-15,2019,7,15,11,cdbyna,How to test MAML?,https://www.reddit.com/r/tensorflow/comments/cdbyna/how_to_test_maml/,dcopz,1563159002,"I successfully reproduce this repo [https://github.com/dragen1860/MAML-TensorFlow/](https://github.com/dragen1860/MAML-TensorFlow/) about Meta Learning. Now, I'm confusing how test this model with only forward network with weight from n-shot training. Does anyone have idea?

Thanks",0,1
59,2019-7-15,2019,7,15,19,cdfn5d,Unable to import Tensorflow while SSH.,https://www.reddit.com/r/tensorflow/comments/cdfn5d/unable_to_import_tensorflow_while_ssh/,FrStealer,1563185441,"Hello,

&amp;#x200B;

I can import tensorflow (with python3.4, CUDA 10.0) on my main computer.

However when i connect with ssh, i get the error: 

    ImportError: libcusolver.so.10.0: cannot open shared object file: No such file or directory
    

He does not find my CUDA path, but on my main computer i indicate it, with `export LD_LIBRARY_PATH=/usr/local/cuda-10.0/lib64/` and that works when i am directly on my main computer but when i connect through ssh, it does not.

&amp;#x200B;

I don't see why, i thought connected to ssh meant i was working on the computer directly so i should not have these problem. 

&amp;#x200B;

Maybe this is not the place to post because it might be a ssh problem but if someone worked with Tensorflow on ssh, i would be glad to have some advice !

&amp;#x200B;

Thank you in advance",6,2
60,2019-7-15,2019,7,15,23,cdi7nu,"I get out of memory error when making prediction with network, but code still seems to work.",https://www.reddit.com/r/tensorflow/comments/cdi7nu/i_get_out_of_memory_error_when_making_prediction/,ml_runway,1563201304,"I am using the TF object detection API, have trained up my network on some new data, and when I run even the smallest image for prediction, get an error like:
    2019-07-15 10:20:01.104556: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 2.83G (3037544448 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
    2019-07-15 10:20:01.855784: W tensorflow/core/common_runtime/bfc_allocator.cc:211] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.58GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.

Then things keep going and the image is correctly sorted out. I'm using the faster_rcnn_resnet101_pets model from the google models zoo, and RTX-2070 graphics card with Ubuntu 18. 

I'm not sure how to fix this error, or whether I should be worried about it, or if I need to try with a better graphics card, or??? I'm pretty new to tensorflow and gpu computation in general, so any general pointers to things I might read/absorb/learn would be super helpful. Does it mean the GPU is too small, so it is starting to use the CPU?",7,3
61,2019-7-16,2019,7,16,1,cdjq3i,Unusual audio recognition - how to get started?,https://www.reddit.com/r/tensorflow/comments/cdjq3i/unusual_audio_recognition_how_to_get_started/,ehowardhill,1563208620,"I'm experienced with Python but very new to Machine Learning and more specifically, Tensorflow. I've already run a few tutorials, so I understand some concepts, but not enough to take care of what I'm looking to complete.

Essentially I'm building a phoneme recognizer, but not like most speech-to-text programs. I have recorded a set of audio and separated it into numpy arrays that are 1024 items in size. My intention was to be able to categorize and label these, so that if I spoke into my computer, it could isolate a 1024-item-size numpy array and identify the label of whichever preexisting recorded chunk I have stored on my computer.

It works like so:

1. Template audio (44100hz) is recorded and separated into lists of size 1024.
2. Each one is associated with an individual number, even if multiple lists are nearly identical.
3. Microphone input comes in and is compared to the existing values.
4. The label of the most similar audio clip is returned to the user.

My main issue is that I have no idea where to begin, or even if any of the Tensorflow modules I've come across in tutorials are optimized for a project like this. I'm not asking for anyone to write this for me, I just want an idea of how to get started on my own.

Thank you all so much for checking this out!",3,1
62,2019-7-16,2019,7,16,2,cdk9rn,"Tensorflow + CSharp. I want to build simply library to train, and predict images.",https://www.reddit.com/r/tensorflow/comments/cdk9rn/tensorflow_csharp_i_want_to_build_simply_library/,flumoo,1563210930,,4,2
63,2019-7-16,2019,7,16,13,cdsebg,Best mAP model for object detection on fairly small dataset with class imbalance,https://www.reddit.com/r/tensorflow/comments/cdsebg/best_map_model_for_object_detection_on_fairly/,ski233,1563251861,"I was wondering what model people recommend (trying to maximize mAP where speed is not a concern) for object detection with roughly 20 classes on a small dataset of roughly 12 thousand images with fairly high class imbalance. Ive tried Retinanet50 with mAP of 33 and Retinanet101 with mAP of 36. Models Im considering trying in the future are as follows (Id love to test them all but as these models take a long time to train Im trying to not waste too much training time):
YOLOv3
SNIPER
NASnet
Faster R-CNN
Mask-R-CNN

What models (or strategies) do people recommend for this scenario to try to maximize mAP?",4,2
64,2019-7-16,2019,7,16,21,cdwhc2,"This video goes over a model that predicts the number of views on a youtube video based on likes, dislikes, and subscribers. Really interesting and educative",https://www.reddit.com/r/tensorflow/comments/cdwhc2/this_video_goes_over_a_model_that_predicts_the/,antaloaalonso,1563280642,,0,13
65,2019-7-17,2019,7,17,1,cdzjxt,r/tensorflow,https://www.reddit.com/r/tensorflow/comments/cdzjxt/rtensorflow/,shwetashri,1563295449,"I want to practice transfer learning on some datasets, please help me with some pointers where I can find such example .",4,0
66,2019-7-17,2019,7,17,5,ce2ebb,"Audio training dataset for the four Alexa hot words: Alexa, Echo, Amazon, Computer",https://www.reddit.com/r/tensorflow/comments/ce2ebb/audio_training_dataset_for_the_four_alexa_hot/,jonsmirl,1563308194,"I've built a custom hot word engine and I'd like to train it for the four Alexa keywords. I've search all over and I can't locate a training dataset for these words.  Surely this must exist somewhere, can someone give me a pointer?",0,1
67,2019-7-17,2019,7,17,10,ce6dux,Make a Face Generative Adversarial Network in 15 MINUTES!,https://www.reddit.com/r/tensorflow/comments/ce6dux/make_a_face_generative_adversarial_network_in_15/,alwayslearningnewai,1563328149,,0,8
68,2019-7-17,2019,7,17,13,ce7zs2,Gradient accumulation and batchnorm in tensorflow,https://www.reddit.com/r/tensorflow/comments/ce7zs2/gradient_accumulation_and_batchnorm_in_tensorflow/,dchatterjee172,1563337577,"So, I implemented gradient accumulation, so that I can simulate a bigger batch size. Batch size 64, subdivision 8. But the moving mean and variance are still updated based on the statistics of a very small batch. And I believe that causing my validation IOU to go crazy. 

&amp;#x200B;

[batch size 64 subdivision8](https://i.redd.it/cunu2q6fjsa31.png)

training iou does not flactuate this much.

any ideas?

is there any way I can update the moving mean and variance after combining statistics of multiple batches?",9,2
69,2019-7-17,2019,7,17,22,cecl1a,Convolutional Neural Networks for Beginners,https://www.reddit.com/r/tensorflow/comments/cecl1a/convolutional_neural_networks_for_beginners/,alwayslearningnewai,1563368759,,0,19
70,2019-7-18,2019,7,18,0,ceenlm,TensorFlow Extended (TFX): Machine Learning Pipelines,https://www.reddit.com/r/tensorflow/comments/ceenlm/tensorflow_extended_tfx_machine_learning_pipelines/,ConnieGCarr,1563378668,[https://www.youtube.com/watch?v=wOk2vfjfcDw](https://www.youtube.com/watch?v=wOk2vfjfcDw),0,2
71,2019-7-18,2019,7,18,3,cegy8k,Easily swapping encoders in a network,https://www.reddit.com/r/tensorflow/comments/cegy8k/easily_swapping_encoders_in_a_network/,ptlil,1563389055,"Hi everyone,

The project I'm working on involves a single RL agent trained on multiple environments. I want to have multiple encoders: one for each environment (as the environments have different features), while having a controller network that is the same for all environments. Essentially I want to easily swap out the encoders for training on different environments.

Is there an easy way to do this? I've been thinking about simply feeding the outputs of the encoders to the controller, and feeding zeros into encoders not currently in use, but I'm sure there's a better solution.

Has anyone done something similar?",1,1
72,2019-7-18,2019,7,18,5,cei3ec,Any book to learn machine learning?,https://www.reddit.com/r/tensorflow/comments/cei3ec/any_book_to_learn_machine_learning/,datnell,1563394226,"I'm tempted to buy this one: [https://www.amazon.fr/gp/product/1491962291/ref=ox\_sc\_act\_title\_1?smid=A2VSCSN8IXFNBL&amp;psc=1](https://www.amazon.fr/gp/product/1491962291/ref=ox_sc_act_title_1?smid=A2VSCSN8IXFNBL&amp;psc=1)  


But it is from 2017 and I'm afraid it may be a little bit outdated.  


Any recommandation?",9,3
73,2019-7-18,2019,7,18,8,ceku92,How to deploy a TensorFlow model as a JSON API in 6 lines of code,https://www.reddit.com/r/tensorflow/comments/ceku92/how_to_deploy_a_tensorflow_model_as_a_json_api_in/,ospillinger,1563407384,,0,8
74,2019-7-18,2019,7,18,15,cep0s1,Gogle coral board image classification and transfer learning demos with Captain America and BB-8,https://www.reddit.com/r/tensorflow/comments/cep0s1/gogle_coral_board_image_classification_and/,makereven,1563432810,"&amp;#x200B;

https://i.redd.it/tz8ah3gqe0b31.gif",2,1
75,2019-7-19,2019,7,19,15,cf47me,"Create a ""simple"" image recognition app in JavaScript ?",https://www.reddit.com/r/tensorflow/comments/cf47me/create_a_simple_image_recognition_app_in/,burton6666,1563518900,"I am trying to create a small app that picks out relevant fields on invoices using OCR. I have got the OCR part to work pretty well but then realized that the invoices that I want to read differ a lot in layout so it gets difficult to know where the relevant parts is located. 

&amp;#x200B;

As all invoices uses different templates I was thinking it would be much simpler if I could just detect the different layout templates which probably is &lt; 10 instead of detecting each company specific invoice 100+.

&amp;#x200B;

Is there some simple way to train to detect if I place invoices of same templates in different folders and then train a application to  recognize what template a new invoice uses?",3,2
76,2019-7-19,2019,7,19,19,cf615w,"For me, one of the main barriers to the world of deep learning was setting up all the tools. Here's a video that I hope will eliminate this barrier. Hope you guys found it helpful!",https://www.reddit.com/r/tensorflow/comments/cf615w/for_me_one_of_the_main_barriers_to_the_world_of/,antaloaalonso,1563533217,,0,27
77,2019-7-19,2019,7,19,23,cf851f,How to train an NN using more than one dataset which is not in the same machine and can't be merged?,https://www.reddit.com/r/tensorflow/comments/cf851f/how_to_train_an_nn_using_more_than_one_dataset/,sezaru,1563546058,"Hello,

&amp;#x200B;

I have 2 data-sets (A and B) that I want to use as one train/eval/test data-set to train my neural network with \[1\] . The problem is that these data-sets are from separated institutions and confidential data. So I can access then locally but can't simply copy then and join then to do the training.

&amp;#x200B;

My question is, is it possible, and if yes, what is the best way, to start my train with data-set A and then get the generated model and train with the data-set B?

&amp;#x200B;

Does this even works and/or does it have some constrains or problems compared to directly train with both data-sets merged?

&amp;#x200B;

One way I was thinking on doing it was with checkpoints, I would do one epoch in one data-set, get the checkpoint, and do the another epoch in the other data-set and so on. I'm not so sure if this would work or if it's the best way to do it though.

&amp;#x200B;

I'm totally open to suggestions.

Thanks in advance.

&amp;#x200B;

\[1\] To be more specific I want to use bert pre\_trainning.py to generate a a NLP domain-specific model using both data-sets.",10,5
78,2019-7-20,2019,7,20,0,cf8pdl,using only one gpu in a multi gpu machine without similar vram,https://www.reddit.com/r/tensorflow/comments/cf8pdl/using_only_one_gpu_in_a_multi_gpu_machine_without/,smashedshanky,1563548966,"I have a 2080ti and a 1080 running together, they work fine in my machine since I can run games where the games use all 11gb of the 2080ti VRAM.

&amp;#x200B;

When I try to train models using tensorflow CUDA 10, for some reason tensorflow allocates only the vram\_MIN(gpu:0,gpu:1) even after I add os.environ\['CUDA\_VISIBLE\_DEVICES'\]=""0"" I have also tried gpu\_growth it still only allocates up to 8g no matter what I try. Is there something I am missing?",2,1
79,2019-7-20,2019,7,20,0,cf95i9,"One dataset, three sets of labels. How to organize my input to predict three outputs?",https://www.reddit.com/r/tensorflow/comments/cf95i9/one_dataset_three_sets_of_labels_how_to_organize/,colonel_farts,1563551141,"Ive been beating my head against the wall for a few days over this. Basically I have a column of text in pandas, and three other columns that represent features of this text, indexed by integer. 

Feature1 is 0-15, Feature2 is 0-4, feature3 is 0-4

All I want to do is have my x data be the text, and my y data be [feat1,feat2,feat3], corresponding to the three softmax outputs of my tf.keras model. 

I cant get the data in the proper format!! Ive tried data.Dataset.from_tensor_slices, Ive tried feeding in numpy arrays, Ive tried making each column its own tensor. Nothing. 

Link to my stackoverflow question which has some code snippets: https://stackoverflow.com/questions/57104485/how-to-structure-input-tensor-to-get-three-different-softmax-outputs-at-the-end",3,1
80,2019-7-20,2019,7,20,0,cf99nw,When is the complete tensorflow 2.0 releasing for use?,https://www.reddit.com/r/tensorflow/comments/cf99nw/when_is_the_complete_tensorflow_20_releasing_for/,AbinavR,1563551720,I am a pytorch user but have seen that tensorflow 2.0 has better features for debugging and now that the keras interface and eager execution has become the norm I would like to use it for my thesis.,2,1
81,2019-7-20,2019,7,20,1,cf9env,"AshPy: TensorFlow 2.0 library for distributed training, evaluation, model selection, and fast prototyping.",https://www.reddit.com/r/tensorflow/comments/cf9env/ashpy_tensorflow_20_library_for_distributed/,pgaleone,1563552383,,0,1
82,2019-7-20,2019,7,20,2,cfaphe,"""Q2 next year"" - TF2 release",https://www.reddit.com/r/tensorflow/comments/cfaphe/q2_next_year_tf2_release/,clanleader,1563558484,"So obviously this deadline was missed. Is there any word from Google or any other source as to when TF2 will be released? I'm not really interested in the beta but rather the actual release or an RC since that is the time that proper tutorials and an ecosystem can be built around it once everyone has a more solid idea of what the final version will look like.

So does anyone know when TF2 will officially release?",0,1
83,2019-7-20,2019,7,20,6,cfd7pr,MKT.js,https://www.reddit.com/r/tensorflow/comments/cfd7pr/mktjs/,loaiabdalslam,1563570587,"# (MKT)[https://github.com/loaiabdalslam/MKT]

![MKT.JS](https://github.com/loaiabdalslam/MKT/raw/master/media/mkt.jpg)

![mkt](https://img.shields.io/npm/dw/@mkt-eg/mkt.svg)
![mkt](https://img.shields.io/github/stars/loaiabdalslam/MKT.svg?style=social)
![mkt](https://img.shields.io/github/forks/loaiabdalslam/MTK.svg?style=social)
![mkt](https://img.shields.io/github/last-commit/loaiabdalslam/mkt.svg)

MKT.js is an Exchange Price Service , Stocks , Cryptocurrency,Stock prediction and more \
This package contains hundreds of currencies, cryptocurrencies and stocks prices.\
6,096 coin , 283,037 TRADING PAIRS , 31 News Provider It also works with the TensorFlow  Read more here [Read more about crypto-compare service](https://min-api.cryptocompare.com/faq)
for market forecasting / stock prediction using RNN and also works on the visualizing of stocks data using canvas.js

## Dependencies
- Neural Networks (brain.js)
- Tensorflow Framework (tensorflow.js)
- Data visualization (canvas.js)
- Main Api ( min-api.cryptocompare.com )


###  Get started : 
#### 1 -  Get Full details response (multiaple fsym &amp; tsym)

```
const { MKT } = require('@mkt-eg/mkt')

const mkt = new MKT(
  'bbbc22c3a13c74456a6d4bb7ba5745476ebfdc81c867fc240258122b78eb6a6f'
)
const data = mkt
  .exchange({
    fsym: 'BTC',
    tsyms: 'USD',
    type: 'full'
  })
  .then(response =&gt; {
    console.log(JSON.stringify(response.data))
  })
  .catch(error =&gt; {
    console.log(error)
  })
  
// JSON OUTPUT 
/* 
{
   ""RAW"":{
      ""BTC"":{
         ""USD"":{
            ""TYPE"":""5"",
            ""MARKET"":""CCCAGG"",
            ""FROMSYMBOL"":""BTC"",
            ""TOSYMBOL"":""USD"",
            ""FLAGS"":""2"",
            ""PRICE"":9885.11,
            ""LASTUPDATE"":1563398729,
            ""LASTVOLUME"":0.1,
            ""LASTVOLUMETO"":986.6100000000001,
            ""LASTTRADEID"":""379345663"",
            ""VOLUMEDAY"":93692.97987050914,
            ""VOLUMEDAYTO"":893517565.3549776,
            ""VOLUME24HOUR"":104598.9946433591,
            ""VOLUME24HOURTO"":997000834.8997525,
            ""OPENDAY"":9423.44,
            ""HIGHDAY"":9982.24,
            ""LOWDAY"":9086.51,
            ""OPEN24HOUR"":9649.99,
            ""HIGH24HOUR"":9988.35,
            ""LOW24HOUR"":9076.48,
            ""LASTMARKET"":""Bitfinex"",
            ""VOLUMEHOUR"":2210.51459713301,
            ""VOLUMEHOURTO"":21755061.31969251,
            ""OPENHOUR"":9692.2,
            ""HIGHHOUR"":9943.53,
            ""LOWHOUR"":9663.39,
            ""TOPTIERVOLUME24HOUR"":101424.52271706509,
            ""TOPTIERVOLUME24HOURTO"":966363837.9391046,
            ""CHANGE24HOUR"":235.1200000000008,
            ""CHANGEPCT24HOUR"":2.436479208786753,
            ""CHANGEDAY"":461.6700000000001,
            ""CHANGEPCTDAY"":4.899166334162472,
            ""SUPPLY"":17823212,
            ""MKTCAP"":176184411173.32,
            ""TOTALVOLUME24H"":720083.9899007804,
            ""TOTALVOLUME24HTO"":7081137716.36884,
            ""TOTALTOPTIERVOLUME24H"":425384.18596477184,
            ""TOTALTOPTIERVOLUME24HTO"":4168740744.7056427,
            ""IMAGEURL"":""/media/19633/btc.png""
         }
      }
   },
   ""DISPLAY"":{
      ""BTC"":{
         ""USD"":{
            ""FROMSYMBOL"":"""",
            ""TOSYMBOL"":""$"",
            ""MARKET"":""CryptoCompare Index"",
            ""PRICE"":""$ 9,885.11"",
            ""LASTUPDATE"":""Just now"",
            ""LASTVOLUME"":"" 0.1000"",
            ""LASTVOLUMETO"":""$ 986.61"",
            ""LASTTRADEID"":""379345663"",
            ""VOLUMEDAY"":"" 93,693.0"",
            ""VOLUMEDAYTO"":""$ 893,517,565.4"",
            ""VOLUME24HOUR"":"" 104,599.0"",
            ""VOLUME24HOURTO"":""$ 997,000,834.9"",
            ""OPENDAY"":""$ 9,423.44"",
            ""HIGHDAY"":""$ 9,982.24"",
            ""LOWDAY"":""$ 9,086.51"",
            ""OPEN24HOUR"":""$ 9,649.99"",
            ""HIGH24HOUR"":""$ 9,988.35"",
            ""LOW24HOUR"":""$ 9,076.48"",
            ""LASTMARKET"":""Bitfinex"",
            ""VOLUMEHOUR"":"" 2,210.51"",
            ""VOLUMEHOURTO"":""$ 21,755,061.3"",
            ""OPENHOUR"":""$ 9,692.20"",
            ""HIGHHOUR"":""$ 9,943.53"",
            ""LOWHOUR"":""$ 9,663.39"",
            ""TOPTIERVOLUME24HOUR"":"" 101,424.5"",
            ""TOPTIERVOLUME24HOURTO"":""$ 966,363,837.9"",
            ""CHANGE24HOUR"":""$ 235.12"",
            ""CHANGEPCT24HOUR"":""2.44"",
            ""CHANGEDAY"":""$ 461.67"",
            ""CHANGEPCTDAY"":""4.90"",
            ""SUPPLY"":"" 17,823,212.0"",
            ""MKTCAP"":""$ 176.18 B"",
            ""TOTALVOLUME24H"":"" 720.08 K"",
            ""TOTALVOLUME24HTO"":""$ 7.08 B"",
            ""TOTALTOPTIERVOLUME24H"":"" 425.38 K"",
            ""TOTALTOPTIERVOLUME24HTO"":""$ 4.17 B"",
            ""IMAGEURL"":""/media/19633/btc.png""
         }
      }
   }
}


*/

```

#### 2 -  Get Single price response (Single Ftsym only)

```
const { MKT } = require('@mkt-eg/mkt')

const mkt = new MKT(
  'bbbc22c3a13c74456a6d4bb7ba5745476ebfdc81c867fc240258122b78eb6a6f'
)
const data = mkt
  .exchange({
    fsym: 'BTC', // Single Fysm only 
    tsyms: 'USD,EGP', // Multiaple Tsyms is allowed
    type: 'single'
  })
  .then(response =&gt; {
    console.log(JSON.stringify(response.data))
  })
  .catch(error =&gt; {
    console.log(error)
  })

// JSON OUTPUT 

{
   ""USD"":9888.01,
   ""EGP"":182256.26
}

```

#### 3 -  Get Multiaple price response 

```
const { MKT } = require('@mkt-eg/mkt')

const mkt = new MKT(
  'bbbc22c3a13c74456a6d4bb7ba5745476ebfdc81c867fc240258122b78eb6a6f'
)
const data = mkt
  .exchange({
    fsym: 'BTC,ETH', // Single Fysm only 
    tsyms: 'USD,EGP', // Multiaple Tsyms is allowed
    type: 'multi'
  })
  .then(response =&gt; {
    console.log(JSON.stringify(response.data))
  })
  .catch(error =&gt; {
    console.log(error)
  })

// JSON OUTPUT 

{
   ""BTC"":{
      ""USD"":9906.65,
      ""EGP"":182256.26
   },
   ""ETH"":{
      ""USD"":215.27,
      ""EGP"":3964.07
   }
}

```


#### 3 - Historical Day/hour/minute OHLCV
Get open, high, low, close, volumefrom and volumeto from the daily historical data.The values are based on 00:00 GMT time. It uses BTC conversion if data is not available because the coin is not trading in the specified currency. If you want to get all the available historical data, you can use limit=2000 and keep going back in time using the toTs param. You can then keep requesting batches using: &amp;limit=2000&amp;toTs={the earliest timestamp received}.

 * apiType parms : 'day' or 'hour' or 'minute'
 * you can left some parameter empty its okay 
 * to know more about Request Params please read [Here](https://min-api.cryptocompare.com/documentation?key=Historical&amp;cat=dataHistoday) 

```
const MKT = new module.exports.MKT('bbbc22c3a13c74456a6d4bb7ba5745476ebfdc81c867fc240258122b78eb6a6f')
MKT.historical({
  sympolPrice: 'true',
  e: 'CCCAGG',
  fsym: 'BTC',
  tsyms: 'USD',
  type: 'single',
  aggregate: '1',
  aggregatePredictableTimePeriods: true,
  limit: 100,
  allData: 'false',
  extraParams: 'NotAvailable',
  sign: 'false',
  apiType: 'hour'
}).then((results)=&gt;{
 console.log(results.data)
})

// JSON OUTPUT 
/*
{
   ""Response"":""Success"",
   ""Type"":100,
   ""Aggregated"":false,
   ""Data"":[
      {
         ""time"":1563526800,
         ""close"":10358.27,
         ""high"":10406.85,
         ""low"":10277.92,
         ""open"":10376.84,
         ""volumefrom"":2507.84,
         ""volumeto"":25941945.52
      },
      {
         ""time"":1563530400,
         ""close"":10342.75,
         ""high"":10402.72,
         ""low"":10271.27,
         ""open"":10358.27,
         ""volumefrom"":2464.21,
         ""volumeto"":25476339.6
      },
      {
         ""time"":1563534000,
         ""close"":10297.03,
         ""high"":10412.81,
         ""low"":10287.51,
         ""open"":10342.75,
         ""volumefrom"":2049.12,
         ""volumeto"":21172424.41
      },
      {
         ""time"":1563537600,
         ""close"":10506.18,
         ""high"":10654.99,
         ""low"":10234.52,
         ""open"":10297.03,
         ""volumefrom"":5671.63,
         ""volumeto"":59565785.39
      },
      {
         ""time"":1563541200,
         ""close"":10319.53,
         ""high"":10510.44,
         ""low"":10135.16,
         ""open"":10506.18,
         ""volumefrom"":7043.95,
         ""volumeto"":72409649.25
      },
      {
         ""time"":1563544800,
         ""close"":10341.37,
         ""high"":10425.08,
         ""low"":10284.69,
         ""open"":10319.53,
         ""volumefrom"":1326,
         ""volumeto"":13724171.79
      }
   ],
   ""TimeTo"":1563544800,
   ""TimeFrom"":1563526800,
   ""FirstValueInArray"":true,
   ""ConversionType"":{
      ""type"":""direct"",
      ""conversionSymbol"":""""
   },
   ""RateLimit"":{

   },
   ""HasWarning"":false
}

*/

```




## Some of the ideas I put forward and you can get started:
- Add processing of natural languages to increase confidence in prices that have been predicted 
- Add simulation of the investment process and the development of some strategies of trades.
- Monitor the markets and manufacture a global dashboard.
- add simples and examples using MKT.JSfdaf


## contributions
- For the first contributor you can delete the file and be the first shareholder (I left it to you)
- For the rest, if you think of an idea, you should make pull request and apply it immediately.


Author : Loaii abdalslam",0,3
84,2019-7-20,2019,7,20,10,cfg2fh,Vram questions,https://www.reddit.com/r/tensorflow/comments/cfg2fh/vram_questions/,Stanley_C,1563585961,"I have some questions about Vram when using 2 gpu in tensorflow. 

If  I have gpu a with a\_vram gbs of Vram and gpu b with b\_vram, with a\_vram &gt; b\_vram, how much effective Vram do I get? Is it limited by b\_vram, or is it b\_vram+a\_vram?",0,1
85,2019-7-20,2019,7,20,12,cfh1cu,"Training on 2 GPUS, which method to use",https://www.reddit.com/r/tensorflow/comments/cfh1cu/training_on_2_gpus_which_method_to_use/,Stanley_C,1563592080,"[https://github.com/tmulc18/Distributed-TensorFlow-Guide/blob/master/Multiple-GPUs-Single-Machine/dist\_mult\_gpu\_sing\_mach.py](https://github.com/tmulc18/Distributed-TensorFlow-Guide/blob/master/Multiple-GPUs-Single-Machine/dist_mult_gpu_sing_mach.py)

This first post shows turning multiple gpus into a ""server"" for ubuntu. First, however, would I implement this on windows? Second, how would I use this ""server"" for training on a normal tensorflow training script? Third, how do I use the distributed training method without splitting my training data into 2 batches? Also, I will be using 2060 and a 1060, so I would like to know how I can adapt a script to automatically feed as much data into the gpu without making large changes to the define graph and training part. Basically, I'm asking about how to add another device to the for loop for the training section and have tensorflow automatically split the data and train on each gpu without large refits to the script. Finally, which method is quicker to implement and setup and quicker?

&amp;#x200B;

\- Thank you",0,1
86,2019-7-21,2019,7,21,0,cfmsn3,How to find something in an image,https://www.reddit.com/r/tensorflow/comments/cfmsn3/how_to_find_something_in_an_image/,suguuss,1563635218,"Hi ! 

&amp;#x200B;

I want to build a Face Detection Neural Network, but I'm not sure this is the best for me as I am very inexperienced in the subject. It will be a goal for later.

&amp;#x200B;

Right now after following some videos I managed to build a Cats vs Dogs detector, you just give him an image and it will tell you if there's a cat or a dog in the image. 

&amp;#x200B;

My CNN knows there's a cat or a dog in the image but how can i make it find the dog/cat ? Let's say i want to put a rectangle on him how do I find the animal ?",8,14
87,2019-7-21,2019,7,21,10,cftnwe,PC restarts when under high GPU load using small minibatches vs fine using slightly larger minibatch,https://www.reddit.com/r/tensorflow/comments/cftnwe/pc_restarts_when_under_high_gpu_load_using_small/,smashedshanky,1563673148,"running a 2080ti standalone with 850watt psu gold rated, when training a keras sequential model I notice that after certain amount of epochs my PC will reset and restart over. I do not notice this while using say batch size of 512 compared to using a batch size of 128, seems to happen when I set batch size to 128.

&amp;#x200B;

I also noticed that while the GPU is under heavy load from tf, I hear distinct \*CLICK\*..\*CLICK\* noise from the GPU for each batch it completes at the end I hear a accumulated \*CLICK\* noise. I assume this is literally me hearing the gpu power regulator or the massive amounts of transistors switching on and off (Not the fan, made sure check leaving the fan off for a few seconds and still heard the noise)

&amp;#x200B;

Is it my power supply not being efficient enough at higher power load, I thought gold standard was sufficient enough.

&amp;#x200B;

I even have a hybrid EVGA gpu (2080ti xc hybrid) and temps look good (checking with nvidia-smi -l 1)

&amp;#x200B;

Any thoughts as to why this is happening?",11,2
88,2019-7-22,2019,7,22,1,cg15j1,Constrain weights to sum to 1,https://www.reddit.com/r/tensorflow/comments/cg15j1/constrain_weights_to_sum_to_1/,Algogator,1563728026,"Hello

I have a question similar to [https://stackoverflow.com/questions/49858920/tensorflow-weight-constraint](https://stackoverflow.com/questions/49858920/tensorflow-weight-constraint)

I need a way to constrain the values in a Variable so that during learning they always sum to 1

So I was thinking about doing something like this 

X = X / tf.reduce\_sum( X )",4,2
89,2019-7-22,2019,7,22,15,cg9q9v,Python vs C++ API?,https://www.reddit.com/r/tensorflow/comments/cg9q9v/python_vs_c_api/,imhere4youbby,1563777615,Is one more efficient than the other?,2,5
90,2019-7-22,2019,7,22,23,cgdogt,What does following syntax mean - function()(parameter) ?,https://www.reddit.com/r/tensorflow/comments/cgdogt/what_does_following_syntax_mean_functionparameter/,Shushrut,1563804613," I recently started learning deep learning with tensorflow and came across following line :

`a = Bidirectional(LSTM(n_a, return_sequences=True))(X)`

What does it mean ?

And how it is any different from

`a = Bidirectional(X, LSTM(n_a, return_sequences=True))`",5,1
91,2019-7-23,2019,7,23,0,cgetkq,faster-rcnn I get different results depending on the size of the image I crop (exact same image subset),https://www.reddit.com/r/tensorflow/comments/cgetkq/fasterrcnn_i_get_different_results_depending_on/,ml_runway,1563810162,"Depending on the size of the image, I either get two objects or one object recognized. There is a little blemish in my picture that has a little dog shape that is recognized as dog when I crop the image to 650x650, but when I use 1500x1500, it does not. In each case, the large and crystal-clear dog is recognized as dog. I am not changing the resolution, or downscaling.

I am using object detection api, resnet network. 

Could this be because an anchor is in the middle of the blemish in the 650x650 case but not the 1500x1500 case?",2,2
92,2019-7-23,2019,7,23,7,cgjvxo,TPU training is difficult,https://www.reddit.com/r/tensorflow/comments/cgjvxo/tpu_training_is_difficult/,rish-16,1563833661,"Hey everyone! 

Recently, I've been asked by some of you through DM to write a tutorial on training TensorFlow models on Cloud TPUs on Google Colab. 

TPU training is deemed to be this daunting task that's only meant for wizards. That's not the case!

Here, I distill TPU training into 4 very simple steps that anyone with any ML proficiency can follow and get their models to be faster, and more superior in performance.

Check it out here and if you like it, please do give it some . It means a lot to me so that I can continue writing good content for beginners!

https://link.medium.com/InBcsRYAxY",14,7
93,2019-7-23,2019,7,23,10,cgm6p7,Suggestions on using TensorFlow for action prediction,https://www.reddit.com/r/tensorflow/comments/cgm6p7/suggestions_on_using_tensorflow_for_action/,dingin93,1563845913,"Hey everyone, first time poster here. I am currently developing (more as a learning experience than a serious project) an RTS game and using TensorFlow for it's AI. 

We are using the world state (numerical values that represent current resources, units and buildings) as the input values and the output values as the desired world state. We have the same amount of inputs as outputs. Each output value represents the new value of the input stats (eg. more gold, more peasants, less wood, etc).

Here is the current model we are implementing in tensorflow:

    neuralnet = Sequential()
    neuralnet.add(Dense(output_dim = 13, init = 'uniform', activation = 'relu', input_dim = 13))  
    neuralnet.add(Dense(output_dim = 13, init = 'uniform', activation = 'relu'))  
    neuralnet.add(Dense(output_dim = 13, init = 'uniform', activation = 'sigmoid')) 
    optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0); 
    neuralnet.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['mean_absolute_error', 'mean_squared_error']) 

We are training this network using recorded world states saved as snapshots from real players. We are using these snapshots as inputs, and their next snapshot as ouputs (eg. if the input is the snapshot n, its output would be the snapshot n+1). For testing we are using this code to simulate a match:

    simulation_outputs = []  
    for i in range(1,100):     
        output_pred = neuralnet.predict(initial_state)     
        initial_state = output_pred     
        denorm_output = sc.inverse_transform(output_pred)     
        simulation_outputs.append(denorm_output) 

We expect the output numbers to be (almost) always incremental, but after a few of these outputs are reached, the numbers start stagnating until they come to a full stop. Is there a reason for this? Or is it expected behaviour?

We need to know which should be the best way to model the network to accomplish this task and prevent the match progression to stagnate like this.

Any kind of help or suggestion would be welcomed

Thanks!",1,2
94,2019-7-23,2019,7,23,18,cgqdf1,Not able to use tensorflow_datasets,https://www.reddit.com/r/tensorflow/comments/cgqdf1/not_able_to_use_tensorflow_datasets/,shwetashri,1563874152,"I am not able to import the tensorflow datasets. I installed tensorflow dataset using pip install tensorflow-datasets , but the statement import tensorflow\_datasets as tfdsgives error. 

Please help to resolve I am totally stuck.",6,2
95,2019-7-23,2019,7,23,23,cgtgz5,How do you train a multi-output network on only a single output at a time?,https://www.reddit.com/r/tensorflow/comments/cgtgz5/how_do_you_train_a_multioutput_network_on_only_a/,alteer,1563892956,"I'm going through the Deep Q Network paper from a few years ago:  
 [https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf](https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf)   


&gt;This part caught my attention. We instead use an architecture in which there is a separate output unit for each possible action, and only the state representation is an input to the neural network. The outputs correspond to the predicted Q-values of the individual actions for the input state.

&amp;#x200B;

The problem is that we can only explore one action at a time. What black magic can you use to train on only one output at a time?  


Faking the other outputs by predicting them with the network and feeding them back in doesn't seem plausible, as it would affect the optimizer.",8,4
96,2019-7-24,2019,7,24,18,ch5sf5,What is up with the total lack of documentation,https://www.reddit.com/r/tensorflow/comments/ch5sf5/what_is_up_with_the_total_lack_of_documentation/,somejob,1563959382,"I'm a junior machine learning engineer and a major part of the job is transfer learning models for custom object detection for deployment to android devices. 

I've been stuck trying to implement a model on device for about 3 weeks now and it's holding up our deployment. The fairly sparse Medium article from 3 tf developers walks through training and converting a model on Google cloud services  (which of course, is a premium feature) using Linux and seems to be the only real official documentation for mobile deployments. Am I wrong in thinking the documentation for tf in general and tflite in particular is shite? To get started I thankfully found a github repo that basically steps through every process in training a model in Windows, but now I'm stuck using both Windows and Linux  (or rather, documenting this cross-OS pipeline for other engineers in the future) without any real documentation for tensorflow. Am I dumb or is this the case?",16,6
97,2019-7-24,2019,7,24,18,ch61pv,Introducing TensorFlow Addons,https://www.reddit.com/r/tensorflow/comments/ch61pv/introducing_tensorflow_addons/,Azzu98,1563961314,,0,26
98,2019-7-24,2019,7,24,18,ch65fv,"Google Coral Edge TPU limited edition, not fake!",https://www.reddit.com/r/tensorflow/comments/ch65fv/google_coral_edge_tpu_limited_edition_not_fake/,makereven,1563962073,"&amp;#x200B;

*Processing img grmf0a2o48c31...*",1,0
99,2019-7-24,2019,7,24,22,ch877g,Should I install tensorflow-gpu and delete regular tensorflow?,https://www.reddit.com/r/tensorflow/comments/ch877g/should_i_install_tensorflowgpu_and_delete_regular/,NanoVash,1563974962,"I built an application that uses tensorflow-gpu to make use of an NVIDIA GPU, however someone that uses my systems reports that occasionally the GPU is used and that occasionally the CPU is used.

Could it be an issue that I have both tensorflow-gpu and tensorflow installed? Should I uninstall regular tensorflow?

I'd really appreciate any explanation regarding to how these packages work.",2,1
100,2019-7-24,2019,7,24,23,ch8pwc,Why is TensorFlow 1.14 slower than TensorFlow 1.13?,https://www.reddit.com/r/tensorflow/comments/ch8pwc/why_is_tensorflow_114_slower_than_tensorflow_113/,yaoyaowd,1563977688,"I recently tried TensorFlow 1.14 because I want to use the mix precision training. But I noticed some of my previous models become 50% slower than before. Then I tried the demo custom estimator model here:

[https://github.com/tensorflow/models/blob/master/samples/core/get\_started/custom\_estimator.py](https://github.com/tensorflow/models/blob/master/samples/core/get_started/custom_estimator.py)

&amp;#x200B;

It looks like TensorFlow 1.13 is at least 10% faster than TensorFlow 1.14. Do you have similar experience? Any hints on which feature or which bug may cause this regression?",5,1
101,2019-7-24,2019,7,24,23,ch93wl,Total Beginner: Learn Tensorflow 1 or go straight to 2 Beta?,https://www.reddit.com/r/tensorflow/comments/ch93wl/total_beginner_learn_tensorflow_1_or_go_straight/,Warhost,1563979607,"Hi,

&amp;#x200B;

I was wondering what you guys think is the best way of getting the hang with Tensorflow for a total ML beginner. I noticed that they are advertising their new v2 Beta everywhere, so what is actually the best way of starting out? There is probably much more material on v1, however v2 is supposed to be simpler overall to pick up.

Cheers",3,1
102,2019-7-25,2019,7,25,2,chav0h,Tensorflow Docs PDF,https://www.reddit.com/r/tensorflow/comments/chav0h/tensorflow_docs_pdf/,ketanIP,1563987793,Can anybody tell me link to download TENSOR FLOW ( Python ) Docs. PDF ???,3,0
103,2019-7-25,2019,7,25,14,chjkap,Can't reuse LSTM cell from after loading a model using saver,https://www.reddit.com/r/tensorflow/comments/chjkap/cant_reuse_lstm_cell_from_after_loading_a_model/,hassanzadeh,1564032995,"I have a simple LSTM model stored by a saver. Now, if I load the graph and create a scope with the same name to reuse LSTM cell, I get the following error:

&amp;#x200B;

ValueError: Variable Recurrent\_Layers/rnn/multi\_rnn\_cell/cell\_0/basic\_lstm\_cell/kernel does not exist, or was not created with tf.get\_variable(). Did you mean to set reuse=tf.AUTO\_REUSE in VarScope?

Here is my code:

&amp;#x200B;



with tf.Graph().as\_default() as graph:

meta\_files = glob.glob(f'./\*meta')

new\_saver = tf.train.import\_meta\_graph(meta\_files\[0\])



with tf.variable\_scope('Recurrent\_Layers', reuse=True):

fw = tf.nn.rnn\_cell.MultiRNNCell(\[BasicLSTMCell(n) for n in \[30,20\]\])

relu1= tf.Variable(tf.constant(\[1,2,3,4,5,6,7,8\], shape=\[2,2,2\], dtype=tf.float32))

lstm\_out\_, \_ = tf.nn.dynamic\_rnn(cell=fw, inputs=relu1, dtype=tf.float32)

&amp;#x200B;

&amp;#x200B;

But I can reuse it in the original model (i.e. the one which is saved), it is just when I store it, load it into another graph and try to reuse it fails. Is that a bug in saver?",1,1
104,2019-7-25,2019,7,25,15,chk2ce,learn tensorflow or stay with keras,https://www.reddit.com/r/tensorflow/comments/chk2ce/learn_tensorflow_or_stay_with_keras/,m4nik1,1564036539,I want to learn more about facial recognition but it's mostly in TensorFlow and I know mostly Keras. Should I learn TensorFlow or are is there code out there that relates to facial recognition.,6,2
105,2019-7-25,2019,7,25,17,chl667,Is it possible to write a customize pooling function(op) in Tensorflow?,https://www.reddit.com/r/tensorflow/comments/chl667/is_it_possible_to_write_a_customize_pooling/,McVeigh1983,1564044953,"Hi all, we've develop a new algorithm so we need a customized pooling function to be implemented.

I know a new op could be written in C++, but unfortunately I don't know how to.

So here I ask, is it possible to add a python written customized pooling function into the graph, and it would update the weight also?

Thank you for your idea in advanced.

Jack",1,1
106,2019-7-25,2019,7,25,18,chlddd,Tensorflow not working with Anaconda Prompt and Jupyter Notebook.,https://www.reddit.com/r/tensorflow/comments/chlddd/tensorflow_not_working_with_anaconda_prompt_and/,chirayushya,1564046482,"I installed tensorflow through anaconda with following command:
 
conda create -n tensorflow_gpuenv tensorflow-gpu

When I import tensorflow in jupyter I get the following error: ModuleNotFoundError: No module named 'tensorflow'",2,2
107,2019-7-25,2019,7,25,20,chmp0g,C api signal processing?,https://www.reddit.com/r/tensorflow/comments/chmp0g/c_api_signal_processing/,nicetryho,1564055732,"Hey all, Ive done some work using a binding over the current c api to run some networks and its been working great. I just have one question, does the c api support the functions in pythons tf.signal ? Reading the documentation I see that only the core tf libraries are included and I assumed that included signal. Can I use those functions through the c api ?",0,1
108,2019-7-25,2019,7,25,23,chomd7,How to utilize a gpu without cuda,https://www.reddit.com/r/tensorflow/comments/chomd7/how_to_utilize_a_gpu_without_cuda/,ski233,1564065926,"I am looking for a way to utilize a computers gpu without using cuda (or any installable software). The reason for this is I have an application where the neural network runs on a users computer and I cant assume they will have the knowledge/ spend the time and effort to install CUDA. I see that it is possible to utilize the gpu using WebGL but from my reading, it sounds like due to other limitations with this approach it is not actually faster than using cpu. Does anyone know how to do this maybe using openGL or some other way to do it?",11,3
109,2019-7-26,2019,7,26,6,chtujt,How to add one value from a Tensor,https://www.reddit.com/r/tensorflow/comments/chtujt/how_to_add_one_value_from_a_tensor/,c2dog430,1564090250,"Say I have a rank 1 tensor a=[1,2,3] and another rank 1 tensor b=[4,5,6] now I want to add just the first elements of the tensors so I am left with a final tensor c = [5,2,3]

What is the best way to do this?",4,1
110,2019-7-26,2019,7,26,12,chxrhf,Tensorflow Tutorial - Modelling with Tensorflow 2.0,https://www.reddit.com/r/tensorflow/comments/chxrhf/tensorflow_tutorial_modelling_with_tensorflow_20/,Amber3825,1564112200, [https://morioh.com/p/5ff6e81919a3](https://morioh.com/p/5ff6e81919a3),0,4
111,2019-7-26,2019,7,26,13,chxzu2,DCGANS Tensor Flow Tutorial Issue,https://www.reddit.com/r/tensorflow/comments/chxzu2/dcgans_tensor_flow_tutorial_issue/,Theotherguy151,1564113671,"I'm having trouble with the DCGANS Tensor Flow Tutorial

 [https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/contrib/eager/python/examples/generative\_examples/dcgan.ipynb](https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/contrib/eager/python/examples/generative_examples/dcgan.ipynb) 

I'm using Pycharm and for some reason by the time I get to the run the Code I keep encountering errors

&amp;#x200B;

=============================================================================================

&amp;#x200B;

Here's The Error:

WARNING: Logging before flag parsing goes to stderr.

W0725 22:56:49.102968 14656 deprecation\_wrapper.py:119\] From C:/Users/Dickbutt69/Desktop/DCGANS/DCGANS.py:2: The name tf.enable\_eager\_execution is deprecated. Please use tf.compat.v1.enable\_eager\_execution instead.

&amp;#x200B;

2019-07-25 22:56:51.644654: I tensorflow/core/platform/cpu\_feature\_guard.cc:142\] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2

W0725 22:56:51.868099 14656 deprecation\_wrapper.py:119\] From C:/Users/Dickbutt69/Desktop/DCGANS/DCGANS.py:89: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

&amp;#x200B;

W0725 22:56:51.868099 14656 deprecation\_wrapper.py:119\] From C:/Users/Dickbutt69/Desktop/DCGANS/DCGANS.py:106: The name tf.random\_normal is deprecated. Please use tf.random.normal instead.

&amp;#x200B;

W0725 22:56:52.859696 14656 lazy\_loader.py:50\] 

The TensorFlow contrib module will not be included in TensorFlow 2.0.

For more information, please see:

  \* [https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md](https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md)

  \* [https://github.com/tensorflow/addons](https://github.com/tensorflow/addons)

  \* [https://github.com/tensorflow/io](https://github.com/tensorflow/io) (for I/O related ops)

If you depend on functionality not listed there, please file an issue.

&amp;#x200B;

W0725 22:56:53.554222 14656 deprecation\_wrapper.py:119\] From C:\\Users\\Dickbutt69\\AppData\\Local\\Continuum\\anaconda3\\envs\\DCGANS\\lib\\site-packages\\tensorflow\\python\\autograph\\converters\\[directives.py:117](https://directives.py:117): The name tf.losses.sigmoid\_cross\_entropy is deprecated. Please use tf.compat.v1.losses.sigmoid\_cross\_entropy instead.

&amp;#x200B;

W0725 22:56:53.599102 14656 [deprecation.py:323](https://deprecation.py:323)\] From C:\\Users\\Dickbutt69\\AppData\\Local\\Continuum\\anaconda3\\envs\\DCGANS\\lib\\site-packages\\tensorflow\\python\\ops\\nn\_impl.py:180: add\_dispatch\_support.&lt;locals&gt;.wrapper (from tensorflow.python.ops.array\_ops) is deprecated and will be removed in a future version.

Instructions for updating:

Use tf.where in 2.0, which has the same broadcast rule as np.where

================================================================================================

Is there a solution to this?

Is anyone else having issues with it?",1,2
112,2019-7-26,2019,7,26,19,ci11h3,Trying to use YOLO9000,https://www.reddit.com/r/tensorflow/comments/ci11h3/trying_to_use_yolo9000/,whatevererer098,1564135955,"Howdy people, I'm trying to use yolo9000 weights. when i try loading them using this function :  

flow --model cfg/yolo-new.cfg --load bin/yolo-new.weights --demo videofile.avi 

I get AssertionError: Over-read bin/yolo9000.weights

I read online that the problem lies in a different between the .weight file and the .cfg file. Some sort of mismatch. 

Do you know how to fix this? or Better yet does any of you have the working yolo9000 weights and cfg files? if so can you please somehow share them via google drive or something?",1,8
113,2019-7-27,2019,7,27,0,ci4bo0,How to use the Omniglot TensorFlow Dataset,https://www.reddit.com/r/tensorflow/comments/ci4bo0/how_to_use_the_omniglot_tensorflow_dataset/,mathhelpermann,1564155083,"I am new to the TensorFlow Datasets and I am trying to do some one-shot learning with the Omniglot dataset. I have done this in PyTorch, but my collaborators use TensorFlow so here I am.

The Omniglot dataset has structure: 

`Class-&gt;subclass-&gt;examples`

I am trying to create a DataLoader that will generate pairs of examples and label 0 if they are from the same subclass and 1 if they are from different subclasses. 

&amp;#x200B;

The the `get_batch(...)` function here:  [https://github.com/hlamba28/One-Shot-Learning-with-Siamese-Networks/blob/master/Siamese%20on%20Omniglot%20Dataset.ipynb](https://github.com/hlamba28/One-Shot-Learning-with-Siamese-Networks/blob/master/Siamese%20on%20Omniglot%20Dataset.ipynb) pretty much implements exactly what I am trying to do but does so without using the TensorFlow datasets.

&amp;#x200B;

I have figured out how the TensorFlow structures the Omniglot dataset 

`omni_train = tfds.load(name=""omniglot"", split=tfds.Split.TRAIN)`

outputs:

 `&lt;_OptionsDataset shapes: {image: (105, 105, 3), alphabet: (), alphabet_char_id: (), label: ()}, types: {image: tf.uint8, alphabet: tf.int64, alphabet_char_id: tf.int64, label: tf.int64}&gt;`

So ideally I would sample random alphabets and if label matches for both I label the pair 0 else I label it 1. But I can't seem to figure out how use the TensorFlow dataset in this way. Does anyone have any tips or even know if it's possible?",0,1
114,2019-7-29,2019,7,29,23,cjbqcv,"My Model Wont Learn, Please Help",https://www.reddit.com/r/tensorflow/comments/cjbqcv/my_model_wont_learn_please_help/,SteamSaajj,1564409339,"Thanks for clicking on this post, as the title is saying my neural network is failing to learn the task i am giving it, and i'm not sure why could you help me? 

Heres some details.

Im trying to get the network to output a number between 0 and 1 (0 corresponding to left, 0.25 to right, 0.5 to up and 1 to down), to achieve this i am giving it some other data (its current position 0 to 1, if the grid above, left, right and below are walls or paths, 0 being walls, 1 paths, and where the goal position is. In conclusion all values are between 0 and 1.

For context i want to  be able to use this to make an ai that can navigate random mazes/obstacle courses.

An example of train\_X = (0.5675, 1, 0, 1, 0 0.95), train\_y = 0.5

&amp;#x200B;

Heres my code, sorry if its not neat. 

&amp;#x200B;

import numpy as np

import pandas as pd

import tensorflow as tf

from tensorflow.keras.models import Sequential

from tensorflow.keras.layers import Dense

model = Sequential()

&amp;#x200B;

\#add model layers

model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu, input\_shape=(6,)))

model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))

model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))

model.add(Dense(1, activation=tf.nn.sigmoid))

&amp;#x200B;

\#compile model using mse as a measure of model performance

model.compile(optimizer=""adam"", loss='mean\_squared\_error', metrics=\[""mean\_absolute\_error""\])

&amp;#x200B;

data = pd.read\_csv(""C:\\\\Users\\\\James\\\\PycharmProjects\\\\Tensor\\\\Maze\\\\all\_moves.csv"")

data.iloc\[np.random.permutation(len(data))\]

dropped\_cols = \[0, 1, 2, 3\]

&amp;#x200B;

train\_x = data.drop(data.columns\[dropped\_cols\], axis=1)

train\_y = data.iloc\[:, 3\]

&amp;#x200B;

train\_x = train\_x.to\_numpy()

train\_y = train\_y.to\_numpy()

&amp;#x200B;

\#print(""Move mean: "", train\_y.mean())

\#print(""Move mode: "", train\_y.mode())

\#print(""Move median: "", train\_y.median())

&amp;#x200B;

\#train model

\#[model.fit](https://model.fit)(train\_x, train\_y, validation\_split=0.2, epochs=30, callbacks=\[early\_stopping\_monitor\], verbose=2)

[model.fit](https://model.fit)(train\_x, train\_y, validation\_split=0.1, epochs=90, verbose=2, batch\_size=24)

&amp;#x200B;

[model.save](https://model.save)(""model\_8.h5"")

&amp;#x200B;

The reason i drop columns 0, 1, 2 and 3 is becuase of the way i get my data. Just not 0, 1 and 2 are row numbers and 3 is what train y is.

I have a fealing its todo with activation types but im not sure, thanks in advance.

&amp;#x200B;

Some Logs:

Train on 1032750 samples, validate on 114750 samples

Epoch 1/50

1032750/1032750 - 83s - loss: 0.0680 - mean\_absolute\_error: 0.2267 - val\_loss: 0.0679 - val\_mean\_absolute\_error: 0.2266

Epoch 2/50

1032750/1032750 - 82s - loss: 0.0679 - mean\_absolute\_error: 0.2264 - val\_loss: 0.0680 - val\_mean\_absolute\_error: 0.2277

Epoch 3/50

1032750/1032750 - 80s - loss: 0.0679 - mean\_absolute\_error: 0.2264 - val\_loss: 0.0679 - val\_mean\_absolute\_error: 0.2265

Epoch 4/50

1032750/1032750 - 80s - loss: 0.0679 - mean\_absolute\_error: 0.2264 - val\_loss: 0.0679 - val\_mean\_absolute\_error: 0.2256

Epoch 5/50

1032750/1032750 - 80s - loss: 0.0679 - mean\_absolute\_error: 0.2263 - val\_loss: 0.0679 - val\_mean\_absolute\_error: 0.2265

Epoch 6/50

1032750/1032750 - 79s - loss: 0.0679 - mean\_absolute\_error: 0.2263 - val\_loss: 0.0679 - val\_mean\_absolute\_error: 0.2268

Epoch 7/50

1032750/1032750 - 80s - loss: 0.0679 - mean\_absolute\_error: 0.2263 - val\_loss: 0.0679 - val\_mean\_absolute\_error: 0.2262

Epoch 8/50

1032750/1032750 - 80s - loss: 0.0679 - mean\_absolute\_error: 0.2263 - val\_loss: 0.0679 - val\_mean\_absolute\_error: 0.2264

Epoch 9/50

1032750/1032750 - 85s - loss: 0.0679 - mean\_absolute\_error: 0.2263 - val\_loss: 0.0679 - val\_mean\_absolute\_error: 0.2264

Epoch 10/50",8,1
115,2019-7-29,2019,7,29,23,cjbt2y,Practical Introduction to Neural Networks - Image prediction,https://www.reddit.com/r/tensorflow/comments/cjbt2y/practical_introduction_to_neural_networks_image/,rishi_devan,1564409710,,0,3
116,2019-7-30,2019,7,30,1,cjdu9o,Multiclassification-Keras,https://www.reddit.com/r/tensorflow/comments/cjdu9o/multiclassificationkeras/,nicetryho,1564418859,"How do I process the input data so that each feature in the matrix is a class ? I have 3 classes, have loaded the data from csvs into 3 column vectors that each correspond to each class of data. I have no idea how to feed my model these 3 vectors and train it on them so it knows each vector is another class, help !!",6,1
117,2019-7-30,2019,7,30,6,cjhvyu,"""Learning TensorFlow"" for $1 on the Machine Learning and Data Analysis ebook bundle",https://www.reddit.com/r/tensorflow/comments/cjhvyu/learning_tensorflow_for_1_on_the_machine_learning/,zackentertainment,1564436392,,0,1
118,2019-7-30,2019,7,30,8,cjiz5h,Tensor Variables wont save in spyder,https://www.reddit.com/r/tensorflow/comments/cjiz5h/tensor_variables_wont_save_in_spyder/,MauriceTheMonster,1564441455,"Hi, I have only started looking at tensorflow today and I began a tutorial. I used the first code in the tutorial to check if it was working in spyder. My problem is that the print function wont print x1 or x2 or results and the constants are not saved in the variable finder. Does anyone know how to fix this??

Here's the code:

&amp;#x200B;

import tensorflow as tf

\# Initialise constants

x1 = tf.constant(\[1, 2, 3, 4\])

x2 = tf.constant(\[5, 6, 7, 8\])

&amp;#x200B;

result = tf.multiply(x1,x2)

print(result)",4,0
119,2019-7-30,2019,7,30,9,cjjnzv,Prune Pretrained models without checkpoint,https://www.reddit.com/r/tensorflow/comments/cjjnzv/prune_pretrained_models_without_checkpoint/,Stanley_C,1564444861,How would I prune a model without a checkpoint?,1,3
120,2019-7-30,2019,7,30,9,cjk8zv,Is there any working guide/tutorial to run quantization-aware training in TF2?,https://www.reddit.com/r/tensorflow/comments/cjk8zv/is_there_any_working_guidetutorial_to_run/,jingw222,1564447883,,2,2
121,2019-7-30,2019,7,30,16,cjok1x,Converting .pb to .tflite in Windows,https://www.reddit.com/r/tensorflow/comments/cjok1x/converting_pb_to_tflite_in_windows/,somejob,1564473411,"I've successfully transfer learned and deployed a model to Android using a weird Windows -&gt; Linux -&gt; Windows pipeline, but have been tasked with documenting the process and converting the pipeline to run just on Windows. Obviously Windows has no ""make"" command as in the semi-official Medium post on the subject so I'm exploring using Cygwin to perform this, has anybody done something similar?",2,1
122,2019-7-30,2019,7,30,17,cjolrc,"Dynamic/static outputs are not same, why?",https://www.reddit.com/r/tensorflow/comments/cjolrc/dynamicstatic_outputs_are_not_same_why/,gecicihesap17,1564473759,"Link for better viewing: [https://stats.stackexchange.com/questions/419778/dynamic-static-outputs-are-not-same-why](https://stats.stackexchange.com/questions/419778/dynamic-static-outputs-are-not-same-why)

I am trying to implement a  patch creation function with using tensorflow's extract\_image\_patches function but dynamic output shape is not same as my expectation. 

Let me tell briefly what it does. Input shape is supposed to be 

6000x4000. We first find its greatest common denominator. It turns out it is 3. then we pass '64' argument to our function to create patches with size of 3x64,2x64=192,128. This returns us 31x31 distinct patches. Everything works ok with static output, but when it comes to dynamic output things are not ok. I could not find which part caused a different dynamic output. 









\#       input\_shape\_inbuild:  (None, 6000, 4000, 1)

\#         ---LAYER---

\#         Input Size: (None, 6000, 4000, 1)

\#         Patch Size: (x,y) = 192, 128

\#         Aspect ratio: (3, 2)

&amp;#x200B;



!wget [https://www.fujifilm.com/products/digital\_cameras/x/fujifilm\_x\_pro2/sample\_images/img/index/ff\_x\_pro2\_001.JPG](https://www.fujifilm.com/products/digital_cameras/x/fujifilm_x_pro2/sample_images/img/index/ff_x_pro2_001.JPG)

img = cv2.imread('ff\_x\_pro2\_001.JPG', 0)  

img = tf.reshape(img, \[1,img.shape\[0\],img.shape\[1\],1\])   

   







\*\*\*tensorflow takes images as (y, x)

so a 6000x4000 im is given as tf.func(4000, 6000)





\# Here I define custom layer in tensorflow.

class create\_patches(Layer):



def \_\_init\_\_(self, patchMultiplier):

super(create\_patches, self).\_\_init\_\_()

self.patchMultiplier = patchMultiplier





def build(self, input\_shape):



print('input\_shape\_inbuild: ', input\_shape)

def aspect\_ratio(width, height):

\#find greatest common divider of input\_shape

def gcd(x, y):

while y != 0:

(x, y) = (y, x % y)

return x



r = gcd(width, height)

x = int(width/r)

y = int(height/r)

return x, y



self.aspect\_ratio = aspect\_ratio(input\_shape\[1\], input\_shape\[2\])

self.patchSize\_x = self.aspect\_ratio\[0\] \* self.patchMultiplier

self.patchSize\_y = self.aspect\_ratio\[1\] \* self.patchMultiplier





def call(self, inputs):



print('---LAYER---')



print('Input Size:', inputs.\_keras\_shape)



print('Patch Size: (x,y) = {}, {}'.format(self.patchSize\_x, self.patchSize\_y))



print('Aspect ratio: {}'.format(self.aspect\_ratio))



print('---LAYER---')

\#call tf.extract\_image\_patches to return it.

out = tf.extract\_image\_patches(images=inputs, 

ksizes=\[1, self.patchSize\_y, self.patchSize\_x, 1\], 

strides=\[1, self.patchSize\_y, self.patchSize\_x, 1\], 

rates=\[1, 1, 1, 1\], 

padding='VALID')





return out



def compute\_output\_shape(self, input\_shape):



""""""

ksize\_cols = patchSize\_x

ksize\_rows = patchSize\_y

""""""



\#output shape=\[batch, out\_rows, out\_cols, ksize\_rows \* ksize\_cols \* depth\]



""""""

shape = (self.patchSize\_x, self.patchSize\_y, 

(input\_shape\[1\]/self.patchSize\_x) \* (input\_shape\[2\]/self.patchSize\_y))

""""""



shape =(input\_shape\[0\],

input\_shape\[1\]/self.patchSize\_x, # patch row count

input\_shape\[2\]/self.patchSize\_y, # patch col count

self.patchSize\_x \* self.patchSize\_y) # patch pixel count





return shape









\#here is input with 6000x4000 pixels.

input\_shape\_1 = Input(shape=(6000, 4000, 1))

\#here I fed input to my custom layer.

x1 = create\_patches(64)(input\_shape\_1)

print('Output shape: ', x1.shape)



\# here I build a model to see static output

f = K.function(\[input\_shape\_1\], \[x1\])







import numpy as np

\#result = f(\[np.random.randint(256, size=(1,4000,6000,1))\])

result = f(\[img\])





\#print(result)

result = np.array(result)



\# \[batch, out\_rows, out\_cols, ksize\_rows \* ksize\_cols \* depth\]

\# Result shape:  (1, 1, 125, 125, 1536) 

print('Result shape: ', result.shape, '\\n\\n')



\#print(result\[:, :, :, 0\].shape)



\#here is output I get. 





input\_shape\_inbuild:  (None, 6000, 4000, 1)

\---LAYER---

Input Size: (None, 6000, 4000, 1)

Patch Size: (x,y) = 192, 128

Aspect ratio: (3, 2)

\---LAYER---

Output shape:  (?, 46, 20, 24576)

Result shape:  (1, 1, 31, 31, 24576) 

\#####Result Shape is as I expected but at output shape I could not resolve where 46 and 20 come from. Could you tell me why it is like this?",0,0
123,2019-7-31,2019,7,31,4,cjwfxk,How to quantize resnet101?,https://www.reddit.com/r/tensorflow/comments/cjwfxk/how_to_quantize_resnet101/,bwsyn,1564513620,"I'm trying to get an int8 version of resnet101.tflite but I have the following questions:

1. There is only a fp32 version of resnet101 at [https://www.tensorflow.org/lite/guide/hosted\_models](https://www.tensorflow.org/lite/guide/hosted_models). Is there a way to convert this tflite model to an int8 tflite model?
2. I know you can convert a 'saved model' to a tflite model but I can't find a 'saved model' at [https://github.com/tensorflow/models/tree/master/official/resnet](https://github.com/tensorflow/models/tree/master/official/resnet). Is there a pretrained ''saved model' of resnet101?
3. TensorFlow also has model checkpoints. If I have a resnet101.ckpt, how do I convert it to a .tflite model?

Please help me. TensorFlow is so complicated that I feel I'm getting brain damage.",4,6
124,2019-7-31,2019,7,31,7,cjze8v,Confused by the (official) documentation.. am I missing something?,https://www.reddit.com/r/tensorflow/comments/cjze8v/confused_by_the_official_documentation_am_i/,mexiKobe,1564526536,"I'm learning Tensorflow right now and I recently was looking at [the documentation for `tf.Session()` specifically the `run()` method](https://www.tensorflow.org/api_docs/python/tf/Session#run), and I was hoping someone could help me better navigate the official documentation because I was very confused. 

I ultimately called `sess.run([optimizer, cost], feed_dict = {x:batch_x, y:batch_y})` with optimizer and cost being the appropriate tf objects, and it seems impossible to figure out these were valid parameters by scanning the documentation, which I linked to above. Where (or how) is this use case listed? It lists the method `run(fetches, feed_dict=None, options=None, run_metadata=None)` but it's not clear to me where [tf.train.AdamOptimizer, tf.nn.softmax_cross_entropy_with_logits] fits in here based on the descriptions of any of these parameters...",9,1
125,2019-7-31,2019,7,31,13,ck3mui,How to convert PSP(Pyramid Scene Parsing Network) net to TensorFlow lite.,https://www.reddit.com/r/tensorflow/comments/ck3mui/how_to_convert_psppyramid_scene_parsing_network/,srinu1746,1564548606,I was unable to convert psp net to Tensorflow Lite.Can anyone help me out,0,1
126,2019-7-31,2019,7,31,18,ck5wqf,"Export trained model to production (Target platform is PC, offline).",https://www.reddit.com/r/tensorflow/comments/ck5wqf/export_trained_model_to_production_target/,Michael496445,1564563889,"This topic may have been asked so many times, but after hours of seaching i just got lot of fragments and still have no clue how to implement.

My project is audio related and has complicated AutoEncoder structure. 

The most hardcore way is that i implement all the forward layers in C/C++, export the trained model in the form of numpy ziped array, and finally eject those weights to self-made C/C++ layers. 

Another way is building required environment on target PC, so that scripts can be run with no problem. However, this means the app must be written in python so that everything stays in python.

One more option is tensorflow serving, but instead of providing web service, i need the server run and serve locally to address running offline problem. So far i believe this option is the most appropriate. 

Have anyone of you successfully export complicated and trained model to other plateform like PC, phone? Which is the best way to my scenario?

Thanks a lot",0,1
127,2019-7-31,2019,7,31,21,ck84m8,Multi labal classification in tensorflow lite,https://www.reddit.com/r/tensorflow/comments/ck84m8/multi_labal_classification_in_tensorflow_lite/,ConcealedImages,1564577651,"Hello, 

I really want to deploy a model which classifies images on 2 or more labels. But, I am not sure how to do this with tensorflow lite. Can someone point me to some resources?  An example of multi label classification could be  if I want to classify whether a given image is a vegetable or fruit, and also what type of vegetable or fruit. Is it possible on google ML kit and Firebase?",0,1
128,2019-7-31,2019,7,31,22,ck8skq,What type of model is used to create deep fakes?,https://www.reddit.com/r/tensorflow/comments/ck8skq/what_type_of_model_is_used_to_create_deep_fakes/,WilkinsMicawbers,1564581194,I'm doing a general study of machine learning and am coming up short finding information on how deepfakes are created. Is there any publicly available information on what models were used to make deepfakes?,4,6
0,2019-8-1,2019,8,1,16,ckkxet,"Introducing tf-explain, Interpretability for TensorFlow 2.0",https://www.reddit.com/r/tensorflow/comments/ckkxet/introducing_tfexplain_interpretability_for/,raphaelmeudec,1564643171,,1,30
1,2019-8-2,2019,8,2,1,ckqh7x,Relationship between RAM speed and CAS latency in TF performance on Ryzen 3900x?,https://www.reddit.com/r/tensorflow/comments/ckqh7x/relationship_between_ram_speed_and_cas_latency_in/,cosmic_cow_ck,1564676142,"Hi all, I'm building a rig to be used in large part for distributed computing and machine learning. Ryzen 3900x, Nvidia 2080ti, and all SSD to prevent I/O bottlenecks.  I'm trying to untangle the mysteries of RAM performance and how they'll affect the performance of the app(s) I'm planning to build, which will incorporate TensorFlow as well as some hombrew machine learning stuff. I'm planning to go with a 64GB kit. 

In real world performance, I suspect that CAS latency doesn't have much of an impact on TF and other Deep Learning/ML approaches since you're typically dealing with pretty large chunks of data, so my guess is that, say, 3600MHz ram of any CAS latency would work out better than tightly timed 3200cl14, for example, but that's just a hunch from my fairly surface-level understanding of how RAM timings and whatnot work. 

I will be doing some gaming on this rig and have a monitor that can take basically whatever I throw at it (1440p 144z, OC up to 165hz), but I'm more concerned with the machine learning side of things as far as performance is concerned.

Any assistance in understanding this stuff, and would be very greatly appreciated.",4,1
2,2019-8-2,2019,8,2,5,ckthxu,Implementing a SumOfGaussians layer in Keras2.0,https://www.reddit.com/r/tensorflow/comments/ckthxu/implementing_a_sumofgaussians_layer_in_keras20/,zachmoshe,1564689734,"Following is my new blog post. This time I played a bit with the new beta version of TF and implemented a simple model where y is the sum of K gaussians which parameters are learned.

[http://zachmoshe.com/2019/08/01/sum-of-gaussians-layer-with-keras-2.0.html](http://zachmoshe.com/2019/08/01/sum-of-gaussians-layer-with-keras-2.0.html)",1,4
3,2019-8-2,2019,8,2,6,ckuv2i,About to start using data augmentation for cnn training. Here's my workflow: any suggestions/advice? Not sure what I'm doing...,https://www.reddit.com/r/tensorflow/comments/ckuv2i/about_to_start_using_data_augmentation_for_cnn/,ml_runway,1564696095,"I am training a faster-rcnn to recognize clowns, using the object detection api. I have a lot of training images of clowns, and have drawn bounding boxes and saved them in associated xml file in Pascal VOC format (that contains information about the image, bounding boxes, their labels -- basically the output of labelimg).

My next step is I want to augment my training data.  I am new to tensorflow and cnns and am looking for any advice/feedback.

My goal here is to use imgaug (https://imgaug.readthedocs.io/en/latest/) to augment my training data. This also returns an appropriate bounding box. Hence I can create a new xml file (i.e., changing the image path and bounding boxes, but leaving the labels and everything else the same).

This way I can end up with a new set of image/xml file pairs to be part of my training data for my network.

Does this seem like a decent plan? If so, should I generate new augmented datasets every time I train my network, or just run through the augmentation procedure once generate N augmented images, and just have this be my new training data? Whatever I do, I will be generating TFRecord files to feed to my network for training as I'm using the object detection api. No big deal, just trying to give details of my workflow in case anyone has advice...",3,0
4,2019-8-3,2019,8,3,1,cl60t4,Tons of Jupyter Notebooks to learn TensorFlow 2 for Computer Vision,https://www.reddit.com/r/tensorflow/comments/cl60t4/tons_of_jupyter_notebooks_to_learn_tensorflow_2/,Aldream,1564761710,,1,1
5,2019-8-3,2019,8,3,1,cl67w4,Tons of Jupyter Notebooks to learn TensorFlow 2 for Computer Vision,https://www.reddit.com/r/tensorflow/comments/cl67w4/tons_of_jupyter_notebooks_to_learn_tensorflow_2/,Aldream,1564762596,,3,12
6,2019-8-3,2019,8,3,2,cl7hqw,"[D] Do you have an idea for a machine learning library or framework that you'll probably never get around to making, and wish someone else would make it?",https://www.reddit.com/r/tensorflow/comments/cl7hqw/d_do_you_have_an_idea_for_a_machine_learning/,BatmantoshReturns,1564768446,"I'm going to a 2 day machine learning hackathon. 2 days isn't a lot of time to train a brand new model, so I'm hoping to make something that would assist other ML people. 2 days will probably just be enough time for a prototype with core functionality.

If it makes a difference, I'll be working in Pytorch.",4,2
7,2019-8-3,2019,8,3,12,cle9ou,"Decomposition of Time Series into Trend, Seasonality &amp; Residual from Scratch",https://www.reddit.com/r/tensorflow/comments/cle9ou/decomposition_of_time_series_into_trend/,bhavesh91,1564804147,,0,1
8,2019-8-3,2019,8,3,15,clfmog,Store file inside protobuf of froxen network?,https://www.reddit.com/r/tensorflow/comments/clfmog/store_file_inside_protobuf_of_froxen_network/,geometrikal,1564813554,Is there anyway to store a file (e.g. some xml metadata) or other metadata (input / output tensor ops) inside a frozen graph's protobuf?,2,1
9,2019-8-3,2019,8,3,23,cljhh0,How to train 1 model to detect multiple classes using multiple datasets,https://www.reddit.com/r/tensorflow/comments/cljhh0/how_to_train_1_model_to_detect_multiple_classes/,ski233,1564843376,Id like to see if its possible to train a single model using multiple datasets for object detection. Im currently using keras-retinanet for object detection on a custom dataset of roughly 6000 images. I have about 20 classes right now but I would like to add more classes however I dont want to have to go annotate every instance of the new class in my existing dataset so that all current instances dont count  as negative examples. What is the best way to add new classes without having to relabel the entire training dataset and just labeling a 1000 or so new images with the new class.,12,9
10,2019-8-4,2019,8,4,3,clly32,[D]Load trained model,https://www.reddit.com/r/tensorflow/comments/clly32/dload_trained_model/,vratiner,1564856406,"Currently I am loading a previously trained model using

`with tf.Session() as sess:`  
`saver.restore(sess, tf.train.latest_checkpoint('./'))`  


which loads the file recorded in the file ""checkpoint"" that was created when saving the model. However, the file ""checkpoint"" always refers to the last trained model, so if I want to load another model I have to manually edit the ""checkpoint"" file to change the model name.

My question is, how can I restore a trained model different from the last one I created, without manually editing the ""checkpoint"" file?",0,1
11,2019-8-4,2019,8,4,7,clouw0,Problem using tensorboard,https://www.reddit.com/r/tensorflow/comments/clouw0/problem_using_tensorboard/,Ste29ebasta,1564871726,"Hi, I hope i can ask you about an exercise, i'm new in this subreddit.

I'm currently learning tensorflow and i have tried to do a very simple exercise, I created 2 ReLU and applied them to an input X and summed the results. Then i saved the variables and tried to create a tensorboard graph. I know it doesn't make sense and i could have done the exercise writing a cleaner code, but it's just to learn how to use tf.

The reason i'm writing here is i can't show the graph on tensorboard, could you help me? I tried to do this exercise using google colab, so i know i can't use tensorboard directly, but i have to use ngrok, but i'm doing something wrong and i can't understand what...

&amp;#x200B;

This is the python book, it is very short  :)

&amp;#x200B;

[https://colab.research.google.com/drive/135MzZV-1nP7xPNl\_yrJKzQpT1vf4Clb7](https://colab.research.google.com/drive/135MzZV-1nP7xPNl_yrJKzQpT1vf4Clb7)",2,1
12,2019-8-4,2019,8,4,8,clpe3q,Unity Ml-Agents ?,https://www.reddit.com/r/tensorflow/comments/clpe3q/unity_mlagents/,Stanley_C,1564874775,"Is this the right place to post Unity Ml-agents questions?

I tried posting on the Machine Learning subreddit, but no one really responds.",0,6
13,2019-8-4,2019,8,4,22,clw6dq,"Sample from logits, but ignore certain classes.",https://www.reddit.com/r/tensorflow/comments/clw6dq/sample_from_logits_but_ignore_certain_classes/,scrapeslimeforfun,1564924510,"`tf.random.categorical` will sample a distribution based on logits. For example, `tf.random.categorical(np.array([[0, 0], [1, 0]], dtype='float32'), 5)` may produce:

    array([[0, 0, 0, 0, 1],
           [1, 0, 1, 0, 0]])&gt;

The problem that I have is the neural network outputs logits corresponding to actions, but certain actions are not always allowed. Is there a way so that if the input is \`\[500, 1, 0\]\` and \`\[0, 1, 1\]\`, then it will ignore the \`0\`th class and only ever output \`1\`s and \`0\`s?",1,1
14,2019-8-4,2019,8,4,22,clwc5w,Jetson Nano or Raspberry Pi for object detection?,https://www.reddit.com/r/tensorflow/comments/clwc5w/jetson_nano_or_raspberry_pi_for_object_detection/,sirajuddin97,1564925545,"Hi, I'm learning TensorFlow and I'm planning to build an autonomous RC car using TensorFlow for object detection. I am currently deciding whether to buy a Jetson Nano or a Raspberry Pi (Pi 4 or Pi Zero) for the machine learning part of my project? The cost is not a problem, I'm thinking more about performance and reliability to process proper object detection. I am also planning to use ROS (Robot Operating System) and learn more about this operating system. Is this achievable on a Jetson Nano? 

I appreciate all your help. Thanks in advance!",5,1
15,2019-8-5,2019,8,5,13,cm6b4u,Newer versions? At 6:30 has anyone looked into this recently?,https://www.reddit.com/r/tensorflow/comments/cm6b4u/newer_versions_at_630_has_anyone_looked_into_this/,cbat971,1564979215,,1,3
16,2019-8-5,2019,8,5,14,cm6zte,TensorFlow Tutorial for Beginners - TutorialAndExample,https://www.reddit.com/r/tensorflow/comments/cm6zte/tensorflow_tutorial_for_beginners/,pavan_kumar_sharma,1564983726,,1,1
17,2019-8-5,2019,8,5,15,cm7ljp,What does an input specified after a keras layers means?,https://www.reddit.com/r/tensorflow/comments/cm7ljp/what_does_an_input_specified_after_a_keras_layers/,Laurence-Lin,1564988077,"For example, in this tutorial page:

[https://www.tensorflow.org/api\_docs/python/tf/keras/Input](https://www.tensorflow.org/api_docs/python/tf/keras/Input)  


It use y = Dense(shape)(x), while x is an tensor placeholder. 

What does this line means? Does this means that y tensor take x tensor as input?

It's not explain clear in official website, thanks!",3,1
18,2019-8-5,2019,8,5,17,cm8795,"tflite_convert a Keras h5 model which has a custom loss function results in a ValueError, even if I add it in the Keras losses import",https://www.reddit.com/r/tensorflow/comments/cm8795/tflite_convert_a_keras_h5_model_which_has_a/,JarsOfJam-Scheduler,1564992659,"I have written a SRGAN implementation. In the entry point class of the Python program, I declare a function which returns a mean square using the VGG19 model:

`# &lt;!--- COST FUNCTION ---&gt;`

`def build_vgg19_loss_network(ground_truth_image, predicted_image):`

`loss_model = Vgg19Loss.define_loss_model(high_resolution_shape)`

`return mean(square(loss_model(ground_truth_image) - loss_model(predicted_image)))`



`import keras.losses`

`keras.losses.build_vgg19_loss_network = build_vgg19_loss_network`

`# &lt;!--- /COST FUNCTION ---&gt;`

&amp;#x200B;

(\`Vgg19Loss\` class shown further below)

&amp;#x200B;

As you can see, I have added this custom loss function in the import \`keras.losses\`. Why? Because I thought it could solve the following problem...: When I execute the command \`tflite\_convert --output\_file=srgan.tflite --keras\_model\_file=srgan.h5\`, the Python interpreter raises this error:

&amp;#x200B;

\&gt; raise ValueError('Unknown ' + printable\_module\_name + ':' + object\_name) ValueError: Unknown loss function:build\_vgg19\_loss\_network

&amp;#x200B;

However, it didn't solve the problem. Any other solution which could work?

&amp;#x200B;

Here is the \`Vgg19Loss\` class:

&amp;#x200B;

`from keras import Model`

`from keras.applications import VGG19`





`class Vgg19Loss:`

`def __init__(self):`

`pass`



`@staticmethod`

`def define_loss_model(high_resolution_shape):`

`model_vgg19 = VGG19(False, 'imagenet', input_shape=high_resolution_shape)`

`model_vgg19.trainable = False`

`for l in model_vgg19.layers:`

`l.trainable = False`

`loss_model = Model(model_vgg19.input, model_vgg19.get_layer('block5_conv4').output)`

`loss_model.trainable = False`

`return loss_model`",1,1
19,2019-8-5,2019,8,5,18,cm8msu,Transformer with Python and TensorFlow 2.0  Attention Layers,https://www.reddit.com/r/tensorflow/comments/cm8msu/transformer_with_python_and_tensorflow_20/,RubiksCodeNMZ,1564996070,,4,17
20,2019-8-5,2019,8,5,18,cm8wbk,What is the difference between model.output and model.outputs?,https://www.reddit.com/r/tensorflow/comments/cm8wbk/what_is_the_difference_between_modeloutput_and/,Laurence-Lin,1564998088,"For an resnet50 model in keras.applications, there are output in official website:

model.outputs, which is a list of outputs. However, it seems to be another output model.output, which is an tensor. What's the difference between them?

List can't be used as input of some keras layer like globalAveragePooling2D.",0,1
21,2019-8-5,2019,8,5,20,cm9oz1,I kept getting error 'Dense' object has no attribute 'op',https://www.reddit.com/r/tensorflow/comments/cm9oz1/i_kept_getting_error_dense_object_has_no/,Laurence-Lin,1565003936,"I'm creating a resnet and using keras.models.Model(input tensor, output tensor)

However this error message shows up, and after searching online I found it may be caused by the update keras version. Some solutions suggests that downgrade the keras will make success, but I would prefer another method. To downgrade the package version in order to use a function seems dumb and unconvenient, what is my other function requires newest version of keras?

My current keras version is 2.2.4 on jupyter notebook, hope someone could help with my problem . Thanks!",4,2
22,2019-8-5,2019,8,5,21,cmajfb,Best way to analyse a software's logs with Machine Learning?,https://www.reddit.com/r/tensorflow/comments/cmajfb/best_way_to_analyse_a_softwares_logs_with_machine/,jvelez2210,1565009183," 

Hey guys!

I am new to Tensor Flow and I would appreciate if someone could point me in the right direction, in order to create a program that extracts the logs from the database in the cloud, and analyse them with Machine Learning in order to find unusual behaviours.

What kind of pre-made Tensorflow or Keras model is the best for this kind of problem?

Is supervised learning the best approach to solving this problem?

Thanks in advance,

Jos Velez",2,1
23,2019-8-6,2019,8,6,3,cmendt,"Is there an object detection model, which can learn spatial information between instances?",https://www.reddit.com/r/tensorflow/comments/cmendt/is_there_an_object_detection_model_which_can/,2ringo,1565028893,"Hey guys,
i am wondering, if there is a model that can learn spatial information between instances. e.g. a hat has a high propability to be detected above a face. Is it possible for some models to use this kind of information? 
And if yes, are there also models already implemented in Keras?
I really appreciate your help. :)",3,4
24,2019-8-6,2019,8,6,23,cmr43r,"How can I filter and balance a Windowed TensHow can I filter and balance a Windowed Tensorflow dataset with a binary classification label, based on the label?orflow dataset with a binary classification label, based on the label?",https://www.reddit.com/r/tensorflow/comments/cmr43r/how_can_i_filter_and_balance_a_windowed_tenshow/,slingshoota,1565100860,"I have an unbalanced tensorflow windowed dataset with labels (over 90% negative examples) which I am trying to balance by filtering. I am having trouble filtering as my windowed dataset with labels does not fall under the cases I have come across in my searches, or the tensorflow documentation.

I'm working on a model to predict a binary classification based on time series data. I start with a time series dataframe with a number of columns (price, volume, etc.) where each row is one minute.

Currently I am still stuck on filtering the different labels. My next step after filtering would be to get the size of both filtered datasets, find the smaller size (n), and then concatenate the smaller dataset with (n) elements from the bigger dataset, after shuffling the bigger dataset. This way I would have a balanced dataset with an equal number of 1 and 0 labels. If you have a better Idea I would be happy to hear it.

**EXPLAINING MY CODE:** DFrame is a pandas dataframe with columns such as price, volume, etc., and each row is a different minute, with the first row being the earliest/oldest time period. The last column of DFrame is the classifier 0 or 1.

I then create a tensorflow dataset from slices with the first input being all the DFrame columns except for the label which is in the last column, and the second input (the label) being the last column which is the classifier.

I then use the window function to create windows of size (hindsight) which is currently 512, meaning (If i'm not mistaken) it takes the previous 511 minutes as well as the current minute and uses this as a rolling window to associate with the label of the current minute. So my understanding is that x is then an array of 512 arrays, from the row of the current minute to the row of 511 minutes ago, and the y is the label of the current minute. So x is an array of 512 arrays (rows for each minute, from the dataframe), and y is just one integer, 1 or 0.

Ideally I would like to be able to apply the same balancing logic to a multiclass classification problem, where I essentially add additional labels for additional price movement ranges.

The error comes from the filter. The model seems to run without that, and even trains my keras model. as explained I would actually want to add more code after the filter once I get it working to balance the dataset but I need to filter it first.

    tensor= tf.data.Dataset.from_tensor_slices((tf.constant(DFrame[DFrame.columns.values[:-1]].values), tf.constant(DFrame[DFrame.columns.values[-1]].values)))
    tensor = tensor.window(hindsight,1,1,True)
    tensor = tensor.shuffle(1000)
    tensor = tensor.filter(lambda x,y: tf.equal(y, 0))
    tensor = tensor.flat_map(lambda x,y:tf.data.Dataset.zip((x.batch(hindsight), y.batch(1))))
    tensor = tensor.batch(Batch_size).prefetch(1)
    
    TypeError: Failed to convert object of type &lt;class 'tensorflow.python.data.ops.dataset_ops._VariantDataset'&gt; to Tensor. Contents: &lt;_VariantDataset shapes: (), types: tf.int64&gt;. Consider casting elements to a supported type.",0,2
25,2019-8-7,2019,8,7,0,cmrzqj,"How can I filter and balance a Windowed Tensorflow dataset with a binary classification label, based on the label?",https://www.reddit.com/r/tensorflow/comments/cmrzqj/how_can_i_filter_and_balance_a_windowed/,slingshoota,1565105162,"I have an unbalanced tensorflow windowed dataset with labels (over 90% negative examples) which I am trying to balance by filtering. I am having trouble filtering as my windowed dataset with labels does not fall under the cases I have come across in my searches, or the tensorflow documentation.

I'm working on a model to predict a binary classification based on time series data. I start with a time series dataframe with a number of columns (price, volume, etc.) where each row is one minute.

Currently I am still stuck on filtering the different labels. My next step after filtering would be to get the size of both filtered datasets, find the smaller size (n), and then concatenate the smaller dataset with (n) elements from the bigger dataset, after shuffling the bigger dataset. This way I would have a balanced dataset with an equal number of 1 and 0 labels. If you have a better Idea I would be happy to hear it.

**EXPLAINING MY CODE:** DFrame is a pandas dataframe with columns such as price, volume, etc., and each row is a different minute, with the first row being the earliest/oldest time period. The last column of DFrame is the classifier 0 or 1.

I then create a tensorflow dataset from slices with the first input being all the DFrame columns except for the label which is in the last column, and the second input (the label) being the last column which is the classifier.

I then use the window function to create windows of size (hindsight) which is currently 512, meaning (If i'm not mistaken) it takes the previous 511 minutes as well as the current minute and uses this as a rolling window to associate with the label of the current minute. So my understanding is that x is then an array of 512 arrays, from the row of the current minute to the row of 511 minutes ago, and the y is the label of the current minute. So x is an array of 512 arrays (rows for each minute, from the dataframe), and y is just one integer, 1 or 0.

Ideally I would like to be able to apply the same balancing logic to a multiclass classification problem, where I essentially add additional labels for additional price movement ranges.

The error comes from the filter. The model seems to run without that, and even trains my keras model. as explained I would actually want to add more code after the filter once I get it working to balance the dataset but I need to filter it first.

    tensor= tf.data.Dataset.from_tensor_slices((tf.constant(DFrame[DFrame.columns.values[:-1]].values), tf.constant(DFrame[DFrame.columns.values[-1]].values)))
    tensor = tensor.window(hindsight,1,1,True)
    tensor = tensor.shuffle(1000)
    tensor = tensor.filter(lambda x,y: tf.equal(y, 0))
    tensor = tensor.flat_map(lambda x,y:tf.data.Dataset.zip((x.batch(hindsight), y.batch(1))))
    tensor = tensor.batch(Batch_size).prefetch(1)
    
    TypeError: Failed to convert object of type &lt;class 'tensorflow.python.data.ops.dataset_ops._VariantDataset'&gt; to Tensor. Contents: &lt;_VariantDataset shapes: (), types: tf.int64&gt;. Consider casting elements to a supported type.",2,1
26,2019-8-7,2019,8,7,1,cmt637,can I use tensorflow from an nvidia 1060 6 GB FROM a VM (win 10 host)? anything I need to know/do?,https://www.reddit.com/r/tensorflow/comments/cmt637/can_i_use_tensorflow_from_an_nvidia_1060_6_gb/,remotepie0,1565110653,"Hi,  (terminology: host means the bare metals computer that boots for example I am runnign windows 10, that's what I booted into - guest is the computer within a VM like if I run a vm and install linux within it then linux is the guest OS.)

I'm curious if I would have any detriment from running my machine learning stuff on tensorflow but from within a VM within my host, Windows 10.  I have a 6 GB nvidia 1060 card.  I can imagine the VM either can, or can't, just directly pass through the stuff that needs on the card.

What do I need to know?

1.  i.e. what VM can I use (such as Parallels Desktop 14, Oracle VM Virtualbox, VMware Fusion and Workstation?)

2.  Do I need to configure anything special to make the pass-through work properly?

3.  I use windows 10 as the host, but since I am learning about machine learning for the first time I am curious about what guest(s) would be appropriate - also windows 10, or is linux much better?  Which Linux?

I have 16 GB of RAM on the host computer and heard that deep learning doesn't take much ram, so I plan to just give 4 GB to my guest machine.

If this setup is unlikely to work well please let me know.  I suppose I can run the things I'm learning about directly on my host comptuer.  The reason I would not like to do this is to keep from adding things to my computer as I install all the tooling I would use.  For example I woudl prefer not to install python and tensorflow on my (host) computer, just within the guest.  Additionally, I kind of have the idea that later I could upload my guest to the cloud and scale out my learning algorithms without configuring anything else, almost like if I had it as a docker thing.  but this could be kind of stupid.

please let me know what I need to know to use tensorflow.  thanks.",6,2
27,2019-8-7,2019,8,7,6,cmw745,Improving Performance with Pose Estimation,https://www.reddit.com/r/tensorflow/comments/cmw745/improving_performance_with_pose_estimation/,eco_bach,1565125673,"My Pose Estimation demo works but getting 1 frame every 2-4 seconds with canned  1080p video!

Here are my specs

hardware + driver

GeForce GTX 960M
Driver version 431.60
Intel Core i7 6700HQ CPU 2.6 GHz
15.87 GB RAM

Software
Windows 10
CUDA 10.0
Python 3.6.8
tensorflow 1.14.0


Questions
1. I had to comment out the line

import tensorflow.contrib.tensoort as trt

to avoid compile errors.

Could this be causing my performance issues?

2. I have both tensorflow and tensorflow-gpu installed. How do I know which one I am running?

3. What other steps should I take to help troubleshoot performance?",1,0
28,2019-8-7,2019,8,7,9,cmymyj,TF not using GPU,https://www.reddit.com/r/tensorflow/comments/cmymyj/tf_not_using_gpu/,AnomalyNexus,1565137602,"Slightly stuck as to why my TF isn't using the GPU, despite being able to see it.  Looking at taskmanager it just ramps up the CPU to 100.

**tf.test.is_gpu_available()**

    2019-08-07 00:55:18.368708: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
    2019-08-07 00:55:18.376387: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library nvcuda.dll
    2019-08-07 00:55:18.486204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:
    name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705
    pciBusID: 0000:01:00.0
    2019-08-07 00:55:18.494578: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
    2019-08-07 00:55:18.501806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
    2019-08-07 00:55:19.320593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
    2019-08-07 00:55:19.326742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0
    2019-08-07 00:55:19.330434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N
    2019-08-07 00:55:19.335187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:0 with 2107 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)
    

**device_lib.list_local_devices()** shows the same plus this:

    [name: ""/device:CPU:0""
    device_type: ""CPU""
    memory_limit: 268435456
    locality {
    }
    incarnation: 15561824217549069569
    , name: ""/device:GPU:0""
    device_type: ""GPU""
    memory_limit: 2209624883
    locality {
      bus_id: 1
      links {
      }
    }
    incarnation: 6125462996487256078
    physical_device_desc: ""device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1""
    ]

Any ideas? 

Maybe a version mismatch? TF2 GPU beta, CUDA 10.1 and CudNN 7.6.",10,8
29,2019-8-8,2019,8,8,5,cnbgcy,"convert video data (.avi, .mp4 etc.) to TensorFlow tfrecords",https://www.reddit.com/r/tensorflow/comments/cnbgcy/convert_video_data_avi_mp4_etc_to_tensorflow/,whiletrue2,1565211003,,0,10
30,2019-8-8,2019,8,8,8,cndby0,How to interact with model in C++ Program,https://www.reddit.com/r/tensorflow/comments/cndby0/how_to_interact_with_model_in_c_program/,tobias1012,1565220087,"i have a trained model in python that i want to interact with in a QT program written in C++, it's important that the end user have the trained model and not contacting a server, what is the best approach to this?",4,4
31,2019-8-8,2019,8,8,17,cnimo2,Gui or command line OS,https://www.reddit.com/r/tensorflow/comments/cnimo2/gui_or_command_line_os/,iacoposk8,1565251690,"Hello everyone! is there a big difference in training times if I launch my operating system (ubuntu) with the graphical interface or only with the command line?  
thank you",1,1
32,2019-8-8,2019,8,8,20,cnkhw1,"[P] Conditional Density Estimation Python Package and Large Benchmark with Neural Networks (MDN, KMN, Normalizing Flow) and Non-/Semi-parametric estimators",https://www.reddit.com/r/tensorflow/comments/cnkhw1/p_conditional_density_estimation_python_package/,whiletrue2,1565264194,,0,2
33,2019-8-8,2019,8,8,20,cnkihw,"[P] Implemented MPPI (Model Predictive Path Integral) in Python with OpenAI Gym pendulum environment (paper: ""Information Theoretic MPC for Model-Based Reinforcement Learning"", Williams et al., 2017)",https://www.reddit.com/r/tensorflow/comments/cnkihw/p_implemented_mppi_model_predictive_path_integral/,whiletrue2,1565264282,,1,5
34,2019-8-8,2019,8,8,22,cnlsny,Tensorflow and Keras For Neural Networks and Deep Learning,https://www.reddit.com/r/tensorflow/comments/cnlsny/tensorflow_and_keras_for_neural_networks_and_deep/,luckyluck123luck,1565271014,,0,1
35,2019-8-8,2019,8,8,22,cnm1dw,"Cats vs. Dogs classification hangs at 50%, thinks everything's a dog (ConvNet)",https://www.reddit.com/r/tensorflow/comments/cnm1dw/cats_vs_dogs_classification_hangs_at_50_thinks/,BowDown097,1565272195,"The details:
As mentioned in the title, this is a ConvNet classifying cats vs. dogs, using a dataset made by myself with different image sizes, to give myself a challenge resized to 80x60 and grayscaled. To attempt to solve this issue, I've tried changing the learning rate, testing parameters in layers of the model like kernel_regularizer, adding layers, removing layers, changing the # of filters in the layers, and yet it still thinks everything's a dog.

Testing the model with MNIST (slightly modified so it works) produces a different result, but still not what's expected. Has an accuracy of ~10%. With other cats vs. dogs datasets of the same nature, the result is the same; 50% accuracy and everything's a dog. So, I've concluded the problem's with the model.

The code:
https://pastebin.com/DszbeJjt

If you haven't guessed already, I'm quite new at this, so I'm wondering.. is there a good way to debug the issue with my model? How could I figure out why it doesn't properly learn, or could somebody point out why this is?",9,8
36,2019-8-9,2019,8,9,18,cnzzvg,How do you think about HUAWEI's Harmony OS? Android replacement?,https://www.reddit.com/r/tensorflow/comments/cnzzvg/how_do_you_think_about_huaweis_harmony_os_android/,makereven,1565343161,"At today's Huawei Developer Conference, the company's Consumer Business Group CEO Richard Yu surprised the audience by unveiling ""Harmony OS,"" which is said to be faster and safer than Android.",2,0
37,2019-8-10,2019,8,10,0,co3vfn,Tensorflow 2.0 / Ubuntu 18.04 LTS / RTX 2070 Super / CUDA not enabled,https://www.reddit.com/r/tensorflow/comments/co3vfn/tensorflow_20_ubuntu_1804_lts_rtx_2070_super_cuda/,nQFbsxw,1565364293,"**GPU:** RTX 2070S FE

**Operating System &amp; Version:**  Ubuntu 18.04.03 LTS

**GPU Drivers:** nvidia-driver-430

**Tensorflow Version:**   tensorflow-gpu==2.0.0-beta1

**Description of Problem:**

I'm having trouble getting tensorflow-gpu to run correctly.

Installation process [here](https://www.tensorflow.org/install/gpu), worked without problems (only change I did was using driver 430 instead of 418 (earliest driver that officially supports the 2070S. i tried 418, but the GPU is not detected, as expected).

When actually running a model, it breaks down with errors. Here an error for a model with an LSTM Layer:

    UnknownError:  [_Derived_]  Fail to find the dnn implementation.
    	 [[{{node CudnnRNN}}]]
    	 [[bidirectional/StatefulPartitionedCall_1]]
    	 [[Adam/Adam/update/mul_4/_36]] [Op:__inference_keras_scratch_graph_3260]

Then I noticed that the 2070S is [not listed](https://developer.nvidia.com/cuda-gpus) on the list of CUDA enabled devices.

Now I'm wondering if anyone got tensorflow / CUDA running on a 2070S or if I did something wrong..",18,5
38,2019-8-10,2019,8,10,3,co6dwf,Music Classification,https://www.reddit.com/r/tensorflow/comments/co6dwf/music_classification/,CharlesAverill20,1565375151,"Hello!

I'm a band student, and a concept that I heard from a band director states that every song ever written can fit into one of two categories: ""Love"" or ""Pirates"". I've found that the theory holds up pretty well, however there are some songs that fit into both groups or are on the fence. I wanted to create a classifier that will output something like ""Love: 40% Pirates: 60%"", however my TF experience is strictly limited to image processing. Are there any projects that have already been started that can put me on the right path? If not, what are some first steps I could take?

&amp;#x200B;

Thank you!",10,6
39,2019-8-10,2019,8,10,5,co7s9w,TensorFlow vs TensorFlow Lite for Feature Extraction,https://www.reddit.com/r/tensorflow/comments/co7s9w/tensorflow_vs_tensorflow_lite_for_feature/,LucidSnow,1565381368,I want to be able to identify and extract specific features from objects recognized. Would TensorFlow Lite be able to do this or do i need to use the full TensorFlow?,4,7
40,2019-8-11,2019,8,11,1,cokigz,Pre-trained person model,https://www.reddit.com/r/tensorflow/comments/cokigz/pretrained_person_model/,Snoocto,1565456122,"Anyone knows where I can find a good pre trained model for person detection and also for tflite ?   


Thanks",0,1
41,2019-8-11,2019,8,11,2,cokn5g,New subreddit specifically for TensorFlow.js (JavaScript/browser version of TensorFlow) - /r/TensorFlowJS,https://www.reddit.com/r/tensorflow/comments/cokn5g/new_subreddit_specifically_for_tensorflowjs/,wildcamp,1565456755,,0,2
42,2019-8-11,2019,8,11,3,colt4k,I am new to tensorflow .. and I don't understand the layers very well,https://www.reddit.com/r/tensorflow/comments/colt4k/i_am_new_to_tensorflow_and_i_dont_understand_the/,LAVIAN_FOX,1565462265,"So you have tensorflow.keras.layers then you specify the layers you wanna add to the neural network buy I don't understand them

What is a flatten layer,
A dense layer,
A dropout layer?

In terms of a neural network..",4,8
43,2019-8-12,2019,8,12,10,cp5caa,DNN Classifier to tflite,https://www.reddit.com/r/tensorflow/comments/cp5caa/dnn_classifier_to_tflite/,creativekinase,1565572506,"Having some trouble converting my model to a tflite (and freezing it first).

Does anyone have code that converts a DNN classifier to tflite?",0,1
44,2019-8-12,2019,8,12,12,cp6rcn,Neural network inference pipeline for videos in Tensorflow,https://www.reddit.com/r/tensorflow/comments/cp6rcn/neural_network_inference_pipeline_for_videos_in/,alseambusher,1565580201,"Just as we saw a huge influx of images in the past decade or so, we are now seeing a lot of videos being produced on social media. The need to understand and moderate videos using machine learning has never been greater.

In this post, I will show you how to build an efficient pipeline to processes videos in Tensorflow.

https://lifepluslinux.blogspot.com/2019/08/neural-network-inference-pipeline-for.html",2,12
45,2019-8-12,2019,8,12,18,cpa010,Tensorflow Object Detection API not labeling anything at all,https://www.reddit.com/r/tensorflow/comments/cpa010/tensorflow_object_detection_api_not_labeling/,NahiyanAlamgir,1565601888,"I've trained a model ([faster\_rcnn\_inception\_v2\_coco](http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz)) to detect car registration plates, with over 340 images (equipped with labels, totaling 100+ MB). Training continued for around 11-12 hours on my MacBook Pro. As you can guess, I used TensorFlow CPU, version 1.14. You can see the graphs below as shown on the Tensorboard:

[Tensorboard graphs.](https://i.redd.it/akhh2r9sizf31.png)

The problem is that when I run the tests, none of them show any labels; not a single label can seen on any of the test images. I tried testing with training images too, still no label; it's unable to detect any object. I can run the example code provided with Tensorflow just fine; even tried using the same code with modifications, but it made no difference.  


Can someone guess what could go wrong here? Do I need to continue the training for few more days?",10,2
46,2019-8-13,2019,8,13,6,cpj6ic,NVIDIA Jetson Nano Developer Kit,https://www.reddit.com/r/tensorflow/comments/cpj6ic/nvidia_jetson_nano_developer_kit/,HenslerSoftware,1565646496,"Has anyone had success training an object detection model on the [NVIDIA Jetson Nano Developer Kit](https://developer.nvidia.com/embedded/jetson-nano-developer-kit)?

How much of a power boot would this give over just using a CPU to train a model?",9,16
47,2019-8-13,2019,8,13,8,cpkhvg,[D] Best method to get tensorflow2 questions answered,https://www.reddit.com/r/tensorflow/comments/cpkhvg/d_best_method_to_get_tensorflow2_questions/,davidkwho,1565652515,"I am doing academic research in deep-learning.  Since April, I have been building models in tensorflow2, such that I can train resnets, implement custom layers/models and compute custom gradient and loss functions in both eager and graph mode.   At this point, I wanted to tackle more tricky issues.  

In particular, I posted this question on stack overflow (see below).  I have no response so far, not even an upvote or a me\_too comment.  I was wondering whether 1) that is the right place to get help, 2) is tensorflow2 in a such a premature state that no one is really looking seriously at it for training/deployment, and 3) are all academic researchers doing their work in pytorch so that I am pretty much on my own.

Any words of wisdom are much appreciated, thanks!

 [https://stackoverflow.com/questions/57421766/plotting-subclassed-model-in-tensorflow-2-0-beta](https://stackoverflow.com/questions/57421766/plotting-subclassed-model-in-tensorflow-2-0-beta)",1,2
48,2019-8-13,2019,8,13,13,cpo3jy,Direct Graphic Input and Real Time Commands,https://www.reddit.com/r/tensorflow/comments/cpo3jy/direct_graphic_input_and_real_time_commands/,enlighten2011,1565670746,"Is it possible for TensorFlow to be applied in a way similar to AlphaZero? 

If it can't then the rest of my question(s) is invalid. It's not really games that interest me, but let me try to describe my thought process for why I want to learn TensorFlow and what I think it can do. In a broad sense I feel like TensorFlow should be able to analyze direct graphics card input, right? If so, I feel like it should be easier than coding it to employ true computer vision using external optics since that would have a 3d axis to deal with and the camera would be a separate interface.

Second, can TensorFlow utilize graphic data to output data in real time? 

Also, how well, if at all, does TensorFlow interface with external or 3d party programs, and are the processes I described difficult to implement?

Of course I could be wrong in understanding how AlphaZero works as well. Maybe, since chess is simple it doesn't need to take-in visual inputs and can simply read chess as code without translating visual data into code. If that's the case, can TensorFlow read memory and other aspects of programs in a similar way?",0,1
49,2019-8-13,2019,8,13,23,cpu49t,Is object detection better at image classification than image classification?,https://www.reddit.com/r/tensorflow/comments/cpu49t/is_object_detection_better_at_image/,ski233,1565707561,"I read in an article that object segmentation can do object detection better than object detection algorithms. I assume this is because there is more detailed information in the annotation images. I was wondering if this is true for object detection and multiclass image classification as well. If you just take the label and quantity of each label from object detection, does it perform better than multiclass image classification?",10,6
50,2019-8-14,2019,8,14,20,cq89hx,Nvidia Super GPUs vs Ti,https://www.reddit.com/r/tensorflow/comments/cq89hx/nvidia_super_gpus_vs_ti/,blezt,1565781477,Has anyone seen comparisons of the new Super GPUs vs the older Ti models? I'm building a new rig based around a Ryzen 9 3900x and I want to know which GPU I should buy. I would like the most Bang for my Buck. I'm debating between the 2080 Super and the 1080 Ti. Anyone have any opinions or performance graphs? Thanks!,8,1
51,2019-8-14,2019,8,14,20,cq8ntc,Plotting TensorFlow.js Activation Functions,https://www.reddit.com/r/tensorflow/comments/cq8ntc/plotting_tensorflowjs_activation_functions/,wildcamp,1565783949,,0,3
52,2019-8-14,2019,8,14,23,cqako6,Quick question about Model.Predict (sequential model),https://www.reddit.com/r/tensorflow/comments/cqako6/quick_question_about_modelpredict_sequential_model/,HoustonWarlock,1565793583," LSTM with a one step phase shift.

When I provide a batch of test data (in my case batch size 12) to use for inference. The output creates an equivalent 12 batch size output. 

I thought the last part of my prediction is the actual prediction. But when I graph the prediction it looks like the entire set of 12 is a prediction on the provided batch. Is that correct?

If I want a single step should I be providing an input of 1 batch size?",6,1
53,2019-8-15,2019,8,15,0,cqbbjo,Optimizing tensorflow lite,https://www.reddit.com/r/tensorflow/comments/cqbbjo/optimizing_tensorflow_lite/,Snoocto,1565796903,"Hello,  I've just a question for object detection tflite. 
If my model has only one object, the dtection will be more speedly?",0,2
54,2019-8-15,2019,8,15,1,cqbz95,Object detection 2.0,https://www.reddit.com/r/tensorflow/comments/cqbz95/object_detection_20/,somejob,1565799738,Am I correct in saying object detection is currently not supported in TF2.x? Tried to set a model training earlier today and apparently the contrib folder is gone?,2,1
55,2019-8-15,2019,8,15,4,cqej0v,Is it worth learning TensorFlow 1 now that 2 is on the horizon?,https://www.reddit.com/r/tensorflow/comments/cqej0v/is_it_worth_learning_tensorflow_1_now_that_2_is/,Flamyngoo,1565810726,"Hi all! I wanted to get into TF and AI, Machine Learning in general but every course uses still the ""first"" TensorFlow of course, i heard 2 is quite different so would learning 1 even be worth it? Or maybe should i learn PyTorch or Keras for now until 2 matures a bit?",10,6
56,2019-8-15,2019,8,15,19,cqnuyk,C development with tensorflow,https://www.reddit.com/r/tensorflow/comments/cqnuyk/c_development_with_tensorflow/,jregalad-o,1565863754,"Why is there such poor documentation on the tensorflow C api?   
I know TF was primarily developed to be used with a python front end. Nevertheless C remains a very important language in many areas. I've been hard at work trying to understand the C api, but I can only go so far without code examples and proper documentation.  
So far, this gist is the most complete guide into using the C api.  
[https://gist.github.com/asimshankar/7c9f8a9b04323e93bb217109da8c7ad2](https://gist.github.com/asimshankar/7c9f8a9b04323e93bb217109da8c7ad2)",3,5
57,2019-8-16,2019,8,16,0,cqrftp,2070 vs 2060 Super and a question about batch sizes and memory,https://www.reddit.com/r/tensorflow/comments/cqrftp/2070_vs_2060_super_and_a_question_about_batch/,hardonchairs,1565883252,"The 2060 Super is apparently identical to the 2070 except for 2 out of every 36 CUDA cores being disabled and the clock speed being bumped up to compensate. In terms of tensorflow, is it better or have the cores or to have the clock speed? Or is the trade off pretty well recognized by tensorflow?

Question 2: If my training with batch sizes of 2 takes up about 3GB of GPU ram, can I expect batch sizes of 4 to take up ~6GB of ram or is it not a linear or consistent change in memory usage? I am using [ImageAI](https://github.com/OlafenwaMoses/ImageAI) custom object detection so I am not sure if ""batch sizes"" translates literally over to tensorflow.",15,8
58,2019-8-16,2019,8,16,8,cqxty0,Tips on improving handwritten digits recognization?,https://www.reddit.com/r/tensorflow/comments/cqxty0/tips_on_improving_handwritten_digits_recognization/,bharddwaj,1565911388,"[https://github.com/bharddwaj/recognize\_handwritten\_digits](https://github.com/bharddwaj/recognize_handwritten_digits)

So in order to use a model trained on MNIST to recognize 'real' handwritten digits I did some preprocessing on images to make it look like an MNIST image itself; this way I can utilize the dataset and model. It works when i take the picture with my macbook camera close up, but when i used my phone camera I believe that the shadows/shadow removal mess up the picture. Was wondering what you guys think of this and/or if you had any tips to make the program better.",1,1
59,2019-8-16,2019,8,16,8,cqy9r6,Where did the TensorFlow CNN Models Go?,https://www.reddit.com/r/tensorflow/comments/cqy9r6/where_did_the_tensorflow_cnn_models_go/,LucidSnow,1565913548,"[http://download.tensorflow.org/models/object\_detection/](http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz)

Where can I download the latest CNN models that were at this location?",2,2
60,2019-8-16,2019,8,16,20,cr57s1,GPU RAM,https://www.reddit.com/r/tensorflow/comments/cr57s1/gpu_ram/,starbucksresident,1565955909,"I have read the docs but am I correct in my assumption?

GPU 0 default but will use RAM of other GPU s?

So a 1060/6 and I add a 1050ti/4 can I effectively have 10gb RAM transparent to the code?

And still using the 1060 only computationally and slowed only by the 1050 VRAM access?",7,1
61,2019-8-16,2019,8,16,22,cr6i9v,[Testing] I did some naive test to bencmark my Models and it worked out very well,https://www.reddit.com/r/tensorflow/comments/cr6i9v/testing_i_did_some_naive_test_to_bencmark_my/,WideWorry,1565962810,"Hi,

I'm working a small project, which aimed to use Tensorflow for algoritmich trading as an enhancement or as a signal provider. I'm also using TensorflowJS Node, so don't be surprised that I will show codes writen in JS not in Py.

I had that problem that my Datas which are Timeseries mostly too noisy for getting any usefull result, but I also didn't trust much into my models that much.  
So I made a simple test to check which is my LSTM models could recognise an Ascending/Descending samples better.  
**My generator :**

\`\`\`  
 function create\_test\_data(count) {  
 let trade\_signals = \[\];  
 for (let i = 0; i &lt; count; i++) {  
 let rand = Math.random();  
 let buy\_in = \[\];  
 let hardening = 43124 \* Math.random();  
 if (rand &gt; 0.5) {  
 // Ascending  
 for (let k = 1; k &lt;= 11; k++) {  
 buy\_in.push(hardening + k \* Math.random() \* hardening);  
}  
} else {  
 // Descending  
 for (let k = 11; k &gt;= 1; k--) {  
 buy\_in.push(hardening - k \* Math.random() \* hardening);  
}  
}  
 trade\_signals.push({ buy\_price: 500, sell\_price: 1000 \* rand, buy\_in });  
  }  
 return \[trade\_signals\];  
}

\`\`\`  
**The Generated datas after MinMaxNormalization:**  
\`\`\`  
Test sample data:  {

  input: \[

\[ 0.06610051616063199 \],

\[ 0.18295973580639677 \],

\[ 0 \],

\[ 0.23400581891562033 \],

\[ 0.0013755938976750912 \],

\[ 0.2946169309488579 \],

\[ 0.583958052956012 \],

\[ 0.20029171242264848 \],

\[ 0.35248159617919556 \],

\[ 1 \],

\[ 0.9363863421672338 \]

  \],

  output: \[ 1, 0 \],

}

\`\`\`  
As you can see they aren't so clean like a 0,1,2,3,4,... but they definielty bring the ascending/descending attributions.  


Let's take a look on the code and structure of the models here:  
\- [https://github.com/stockmlbot/NodeTFJS/blob/master/src/tf\_models/tf\_models.js](https://github.com/stockmlbot/NodeTFJS/blob/master/src/tf_models/tf_models.js)  
*These models were selected and reimplemented into TFJS after I find them in various Python projects where they suposed to work.*  


After few Benchmark the results are the following (Examples are cherry picked):  


**1.** **lstm\_hibrid:** loss=0.0260 val\_loss=0.0213 Example out of sample datas: Pred: \[0.000006,0.999994\]  Real: \[0, 1\] **Passed!**  
**2. lstm\_hidden\_cells:** loss=0.0174 val\_loss=0.0268 Example out of sample datas: Pred: \[0.014, 0.985\]  Real: \[0, 1\] **Passed!**  
**3.** **lstm:** loss=5.94e-3 val\_loss=0.160  Example out of sample datas: Pred: \[0.734,0.265\] Real: \[0,1\] **Fail!**  
Conclusion:  
So, **lstm\_hibrid** and **lstm\_hidden\_cells** worked pretty much the same however the lstm\_hibrid seems get some advantage from the extra dense layers and never misstaken on the out of sample datas, but both can provide acceptable result. At learning speed lstm\_hidden\_cells  is a bit faster.  
The **lstm** model seems got some serious problem with overfitting, on out of sample datas it provide only garbage predictions.  


**Source code of the whole project:**  
\- [https://github.com/stockmlbot/NodeTFJS](https://github.com/stockmlbot/NodeTFJS)",0,1
62,2019-8-17,2019,8,17,8,cree6e,Turning data (API) into article (text),https://www.reddit.com/r/tensorflow/comments/cree6e/turning_data_api_into_article_text/,wj14,1565998647,"The end result I'm aiming for is to give the program some stats from a sports game and then for it to produce a 300 word match report.

I know how to scrape and compile match reports from various games with the matching statistics. However, I'm trying to program a way using tensor flow that the AI can understand the transition from the statistics to producing a match report on them, having learnt from the previous transitioning examples.

Has anyone done this already, using tensor flow and can point me in the right directions...",3,4
63,2019-8-18,2019,8,18,3,crpl23,Machine Learning in JavaScript with TensorFlow.js,https://www.reddit.com/r/tensorflow/comments/crpl23/machine_learning_in_javascript_with_tensorflowjs/,inspiredDeveloper,1566064874,,1,3
64,2019-8-18,2019,8,18,17,crytb3,Which memory does TensorFlow consume when training?,https://www.reddit.com/r/tensorflow/comments/crytb3/which_memory_does_tensorflow_consume_when_training/,groudonRamsay,1566117650,"Hello, I have a Jetson Nano and I've been trying to train using the legacy [train.py](https://train.py). I can't help but notice that I very often see logs where it runs out of memory because I only have a couple hundred MBs left and it's trying to allocate memory for a tensor that's 1+ GB. 

I installed official TF-gpu, and this might be a dumb question, but doesn't that mean that when training, TF uses the GPU Memory and not the RAM?",10,5
65,2019-8-19,2019,8,19,16,csdr7i,Transformer with Python and TensorFlow 2.0  Encoder &amp; Decoder,https://www.reddit.com/r/tensorflow/comments/csdr7i/transformer_with_python_and_tensorflow_20_encoder/,RubiksCodeNMZ,1566199828,,3,19
66,2019-8-19,2019,8,19,22,csgy2s,"Breast cancer diagnosis with neural networks, implemented with Keras and written in Python",https://www.reddit.com/r/tensorflow/comments/csgy2s/breast_cancer_diagnosis_with_neural_networks/,antaloaalonso,1566220588,,0,1
67,2019-8-19,2019,8,19,23,cshx5v,Tensorflow Use Locally on IoT Devices Versus in The Cloud,https://www.reddit.com/r/tensorflow/comments/cshx5v/tensorflow_use_locally_on_iot_devices_versus_in/,cloudster314,1566225385,"Curious to get feedback on trends to run Tensorflow locally on embedded devices.  I wrote down some surprising findings of the submissions for a consumer camera dev contest.  Not sure if people used Tensorflow on the camera because they wanted to learn Tensorflow or because it was the best way to solve the problem.  The challenge was to run some type of app on the camera, it was unrelated to AI/ML, but there were a lot of people that built AI/ML apps into the camera.  

[https://dzone.com/articles/when-to-use-opencv-and-tensorflow-locally-versus-i](https://dzone.com/articles/when-to-use-opencv-and-tensorflow-locally-versus-i)",0,1
68,2019-8-20,2019,8,20,1,csjaz1,How to identify most important weights for a particular class in multilabel classification,https://www.reddit.com/r/tensorflow/comments/csjaz1/how_to_identify_most_important_weights_for_a/,Studdml,1566231513,"Dear all,

I wanted to know if it is possible to identify the most important weights of an MNIST classifier regarding a particular class?  The Model is build on a simple Lenet CNN architecture with native tensorflow.

Now, after having the trained model, I would like to know which  weights are most important for class ""0"" etc. Or which neurons are most responding to class ""0"".

With that knowledge I would like to modify the weight storage manually to remove learned features about a particular class.

By now I went through all weight values and dropped them one by one and observed any changes in classification accuracy. But I think there must be a way better solution to it.

Thanks",3,3
69,2019-8-20,2019,8,20,6,csnfm0,A repository to access 3D-CNN architectural codes in TF 2.0 (Pre-trained models and training and testing codes coming soon),https://www.reddit.com/r/tensorflow/comments/csnfm0/a_repository_to_access_3dcnn_architectural_codes/,life_vortex,1566248930,"I have begun training a number of 3D-CNN architectures in TF2.0 and I intend to provide the pre-trained models along with fully functional training and evaluation codes in TF2.0.

Over the next 2 weeks, you can expect a trained I3D model fully functional in TF 2.0.

[https://github.com/indranaut/3DCNNs.git](https://github.com/indranaut/3DCNNs.git)",4,5
70,2019-8-20,2019,8,20,12,cssfzw,Object Detection Question,https://www.reddit.com/r/tensorflow/comments/cssfzw/object_detection_question/,pablodelgrande,1566273174,"So I've been tinkering with the object detection stuff with tensorflow, from this github:
https://github.com/tensorflow/models/tree/master/research/object_detection

It's really slick and I've been working on using it to detect deer in trailcam photos.  I understand most of what's going on in the jupyter notebook.

I trained using about 500 photos I annotated, some off of google and some from previous data I had off the trailcams in question.

I'm getting a lot of images, with and without deer, where it boxes the entire image.  Here's an example:
https://imgur.com/a/fjIe3Hm

I'm still REALLY new at this and am a far cry from an expert, but I'm trying to understand what could cause this.  I'm not sure if it's poor training data, poor model, or the image I'm trying to detect objects in is of poor quality.  I'm just looking for a direction to go in.

Any Help is appreciated.",2,1
71,2019-8-20,2019,8,20,14,cst6v9,"Coral summer updates: Post-training quant support, TF Lite delegate, and new models!",https://www.reddit.com/r/tensorflow/comments/cst6v9/coral_summer_updates_posttraining_quant_support/,makereven,1566280083," The compiler has been updated to version 2.0, adding support for models built using post-training quantization[only when using full integer quantization](https://www.tensorflow.org/lite/performance/post_training_quantization#full_integer_quantization_of_weights_and_activations) (previously, we required quantization-aware training)and fixing a few bugs. 

here: [https://developers.googleblog.com/2019/08/coral-summer-updates-post-training.html](https://developers.googleblog.com/2019/08/coral-summer-updates-post-training.html)",1,1
72,2019-8-20,2019,8,20,16,csu1j1,TensorFlow Lite for Raspberry Pi 3,https://www.reddit.com/r/tensorflow/comments/csu1j1/tensorflow_lite_for_raspberry_pi_3/,dvali,1566285191,"I'm really struggling here. I've seen several statements to the effect that this IS officially supported but have yet to find a guide that I can get through without impassable errors.

Has anyone managed to find a comprehensive guide that actually works for building TF Lite for the Pi? The downloadable PIP package on the official site doesn't work. In particular, I need to build the inferencer to be usable in C. I did manage, I think to get libtensorflow-lite.a built but then couldn't find any documentation on how to actually make any use of it. For example, where are the header files?

I don't have much experience with building things like this - I've mainly used python in the last and things like this haven't been necessary.

Please note that for technical reasons we would very strongly prefer to use TensorFlow Lite only, not the full package. Any help at all will be much appreciated.",3,1
73,2019-8-20,2019,8,20,20,cswu0a,what is the error here?,https://www.reddit.com/r/tensorflow/comments/cswu0a/what_is_the_error_here/,ph04,1566299303,"`model = tf.keras.Sequential([`  
`tf.keras.layers.Conv2D(32, (3, 3), input_shape=(1, 240, 240), activation=""relu""),`  
`tf.keras.layers.Conv2D(64, (3, 3), activation=""relu""),`  
`tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),`  
`tf.keras.layers.Conv2D(64, (3, 3), activation=""relu""),`  
`tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),`  
`tf.keras.layers.Dropout(0.5),`  
`tf.keras.layers.Flatten(),`  
`tf.keras.layers.Dense(128, activation=""relu""),`  
`tf.keras.layers.Dropout(0.5),`  
`tf.keras.layers.Dense(1, activation=""softmax"")`  
 `])`

in my keras.json there's ""channels\_last"" set. if i set ""channels\_first"" it says i'm missing a dimension, but if i add one (so it should be 4 dims) it says it finds 5 dimensions

no matter what i do i always and up with this

https://i.redd.it/g1irwu336lh31.png",32,3
74,2019-8-20,2019,8,20,23,cszu38,classificator and spam detector,https://www.reddit.com/r/tensorflow/comments/cszu38/classificator_and_spam_detector/,paulred70,1566311627,"Hi, my need is to create a classifier that can detect if a text is a sources code (c#, c++, python) or spam (not  source code),  well my first idea is to use a naive Bayes spam filter but I'd like something like a classifier where I pass a huge number of sources and no spam examples... in a few words: an automatic classifier.

I'd like to do in python and tensorflow

thanks",3,2
75,2019-8-21,2019,8,21,5,ct5ynn,Best way to combine multiple datasets into one multilabel image classification model,https://www.reddit.com/r/tensorflow/comments/ct5ynn/best_way_to_combine_multiple_datasets_into_one/,ski233,1566334260,"I want to make a multilabel image classification model that can detect many different labels. For each label, I can get at least 5000 positive examples and 5000 negative examples. However, my question is how can I use data in this format to train a multilabel image classifier. Part of the challenge is, for example, I can download 10,000 images of a hand and know that they are positive examples but then if I want to detect a shoe as well, I dont know how many of those hand photos might have also had a shoe in them. Im trying to make a model this way because I will have a fairly high amount of labels and need to be continuously adding new labels. What is the best way to go about doing this?",15,4
76,2019-8-21,2019,8,21,7,ct75ac,Better to use one big model or tree of models for image classification using tree structure,https://www.reddit.com/r/tensorflow/comments/ct75ac/better_to_use_one_big_model_or_tree_of_models_for/,ski233,1566338819,"I saw in Yolo9000, they have a tree like structure of their labeling. For example, it can see that barrack obama is leader. If it didnt detect he was leader, it would say something like male person or person if it couldnt tell that. I have a use case with labels like this that are in a tree structure. Would it be better to have one giant model capable of detecting 100+ classes or to have an initial model that sorts into submodels that are better suited to specific tasks. For example, it finds a person which will initiate it to then run a model that knows how to distinguish features in people to output a result.",1,1
77,2019-8-21,2019,8,21,7,ct7t3y,(1.9.x) creating/mutating batch data inside graph?,https://www.reddit.com/r/tensorflow/comments/ct7t3y/19x_creatingmutating_batch_data_inside_graph/,thats_DR_chalupa_2u,1566341765,"I'm implementing a GNN, using *dynamic_rnn* for my state transition function. I compute state transitions, one node at a time, following the order in a traversal. At each node, I stack the states, node features, and edges features pertaining to the 'current' node, as well as its neighbors, and feed it to the state-transition function. Each node has a different *dynamic_rnn* instance with weights copied between them after accumulating gradients. This obviously is not optimal, but I did not want to yet deal with the mess of figuring out how to compute gradients on a single instance that observes multiple disparate sequences (is that even possible without doing a bunch of external tracking and computation?) Also, my graphs have single-digit number of nodes.


**The (Main) Problem:** the input batches to each *dynamic_rnn* need to be assembled dynamically, from within the graph! I need to gather the outputs of the other *dynamic_rnn*s at each step of each sequence, based on the corresponding mask.


//


A few things I've considered:


1.) Feeding in one step of each sequence at a time, instead of batching sequences. *I anticipate this will have horrible performance, and computing gradients might be extremely complicated*.

2.) Using variables to form the batches. *I'm not sure if this would work with how dynamic_rnn handles batches*.

3.) Reorganizing for eager execution. *I've not yet used this mode in TF, and I have a feeling some things may not work as I need them*.


I have a feeling the solution will involve forgoing batching, and controlling the computation for a single training example via multiple runs, but I'm interested to hear what ideas others have.",5,1
78,2019-8-21,2019,8,21,10,ct9eta,Help on creating reinforcment NN,https://www.reddit.com/r/tensorflow/comments/ct9eta/help_on_creating_reinforcment_nn/,Stanley_C,1566349362,"Hi! I would like advice on starting off project to modify(or from scratch) on how to create a reinforcment Neural Network.

I would like to get help on how to create reinforcments learning NN that takes inputs like drag coefficient and stability derivatives and learns to create an airfoil with those properties. I'm not sure how to set up or train such a network so that during the training session, I plug in random inputs and it eventually learns to output a point cloud to those numbers. 

Second, how do I use a custom error calculations with a exe? I know the command and I know how use pandas to extract the data, but I'm not sure how to use those numbers for error calculations. I want to calculate error based on standard devations form the input, and I would appreciate help.

&amp;#x200B;

https://i.redd.it/dumlbfj9ajh31.jpg",0,0
79,2019-8-21,2019,8,21,13,ctbx2n,Use external programs for loss calculations,https://www.reddit.com/r/tensorflow/comments/ctbx2n/use_external_programs_for_loss_calculations/,Stanley_C,1566362618,"Hi,

How do I use an external exe for loss calculations?  I know how to read the values from the txts, but I'm not sure how to calculate standard deviation from the input to determine loss",6,1
80,2019-8-21,2019,8,21,18,ctem9r,How to Patch GPSR Routing Protocol Using NS2 Tutorial,https://www.reddit.com/r/tensorflow/comments/ctem9r/how_to_patch_gpsr_routing_protocol_using_ns2/,flyhighwithai,1566381229,,0,1
81,2019-8-21,2019,8,21,22,ctgp68,Preprocess Images in a tensorflow dataset,https://www.reddit.com/r/tensorflow/comments/ctgp68/preprocess_images_in_a_tensorflow_dataset/,piadodjanho,1566393318,"I'm using Tensorflow Dataset on Google Colab with TPU.

I'm having an issue when trying `map` to a preprocess function in a dataset.

    train_ds = train_ds.map(preprocess_data, num_parallel_calls=tf.data.experimental.AUTOTUNE)

I produces the error:

    ValueError: operands could not be broadcast together with remapped shapes [original-&gt;remapped]: (3,2) and requested shape (0,2)

[The notebook](https://colab.research.google.com/drive/16BRp3XzHDqcad6PiweseW2s35cmagk-f).

Does anyone know why and how to fix it?",0,4
82,2019-8-22,2019,8,22,1,ctj764,TensorBoard Empty Scalar Hider: Chrome Extension of hiding empty scalar/panes,https://www.reddit.com/r/tensorflow/comments/ctj764/tensorboard_empty_scalar_hider_chrome_extension/,Jasonnor,1566404873,,0,1
83,2019-8-22,2019,8,22,2,ctjp2z,Reinforcement learning help,https://www.reddit.com/r/tensorflow/comments/ctjp2z/reinforcement_learning_help/,Stanley_C,1566407031,"Hi, can someone link a guide on how to create an input to output NN for reinforcement, this is related to my last post. I want to have my NN learn to take numerical inputs, and output a point cloud that my external program evaluates,   and the NN learns to match input values and output. I would appreciate help, in forms of repos, tutorials, or replies.",4,0
84,2019-8-22,2019,8,22,8,ctowrv,does TF use something akin to SSA for backprop?,https://www.reddit.com/r/tensorflow/comments/ctowrv/does_tf_use_something_akin_to_ssa_for_backprop/,thats_DR_chalupa_2u,1566429821,"I'm manually feeding an LSTM one step at a time (so batch dimensions are \[1, 1, feature\_dimension\]). After each step, I save the state to the variable that is providing the LSTM its 'initial' states, then feed the next step.  


What I'm wondering is, how does the auto-diff engine know where each of the assignments to the variable came from, so that it can continue backprop? I would've thought that the variable would be treated as a constant, but instead, it successfully traces back to the LSTM in the previous time step!  


Is this a particular case, when a variable only has one source/edge for assignment? Or is there some additional information that's stored in the forward pass, that allows for assignment sources to be identified during backprop?",0,3
85,2019-8-22,2019,8,22,15,cttm9r,Exposing Digital Image Forgeries Detection,https://www.reddit.com/r/tensorflow/comments/cttm9r/exposing_digital_image_forgeries_detection/,flyhighwithai,1566456338,,0,1
86,2019-8-22,2019,8,22,18,ctv42v,"Hybrid Biometric Using Face, Eye and Fingerprint",https://www.reddit.com/r/tensorflow/comments/ctv42v/hybrid_biometric_using_face_eye_and_fingerprint/,flyhighwithai,1566467132,,0,4
87,2019-8-22,2019,8,22,20,ctw5x2,Wideband Spectrum Sensing for Cognitive Radios,https://www.reddit.com/r/tensorflow/comments/ctw5x2/wideband_spectrum_sensing_for_cognitive_radios/,flyhighwithai,1566473812,,0,1
88,2019-8-22,2019,8,22,22,ctx5uw,Emotion Detection Implementation Explanation MATLAB,https://www.reddit.com/r/tensorflow/comments/ctx5uw/emotion_detection_implementation_explanation/,flyhighwithai,1566479115,,0,1
89,2019-8-23,2019,8,23,3,cu1rpl,Tensorboard scalars smooth and stepped,https://www.reddit.com/r/tensorflow/comments/cu1rpl/tensorboard_scalars_smooth_and_stepped/,tomas1808,1566499734,"

[I have two plots](https://imgur.com/4Es8kmF), left is accuracy and right is cross entropy loss. 
Each has data for training and validation sets. For some reason the validation data looks all steppy, while the training data looks smooth. 

Any idea why this could be happening? 

The two lines of code (PyTorch) responsible for logging the data are:

    writer.add_scalars('Train/Loss', {'train_epoch_loss': train_epoch_loss, 'val_epoch_loss': val_epoch_loss}, epoch)
    writer.add_scalars('Train/Accuracy', {'train_epoch_acc': train_epoch_acc, 'val_epoch_acc': val_epoch_acc}, epoch)    


Thanks!",4,3
90,2019-8-23,2019,8,23,19,cubz6s,Security Reliability in Cognitive Radio Implementation in Matlab,https://www.reddit.com/r/tensorflow/comments/cubz6s/security_reliability_in_cognitive_radio/,flyhighwithai,1566555899,,0,1
91,2019-8-23,2019,8,23,21,cudaa1,Detect and Extract Object from camera,https://www.reddit.com/r/tensorflow/comments/cudaa1/detect_and_extract_object_from_camera/,brasileirinho42,1566563813,"Hi everyone! I'm using Tensorflow to detect objects from camera, my goal is detect, take a picture and extract only the detected object. Can you say if it is possible to do that? I'm really stuck, thank you in advance :)",0,1
92,2019-8-23,2019,8,23,21,cudetv,Can I detect and extract from the Camera only the detected object using Tensorflow-js?,https://www.reddit.com/r/tensorflow/comments/cudetv/can_i_detect_and_extract_from_the_camera_only_the/,brasileirinho42,1566564483,"Hi everyone! I'm using Tensorflow-js to detect objects from camera, my goal is detect, take a picture and extract only the detected object. Can you say if it is possible to do that? I'm really stuck, thank you in advance :)",2,1
93,2019-8-23,2019,8,23,22,cudktj,"Serverless serving with Flask, startup of model takes very long",https://www.reddit.com/r/tensorflow/comments/cudktj/serverless_serving_with_flask_startup_of_model/,Henry__Gondorff,1566565346,"*Excuse my lack of experience, though I would say I am quite experienced with the theory of deep learning itself, I lack specific experience with cloud-stuff. My question relates specifically to tensorflow but has some docker and cloud aspects to it. If this is the wrong forum to ask this question, please refer me to the an appropriate one.*

*I am not a computer scientist and come from a deeply theoretical background so I might not use some terminology correctly.*

I have a tensorflow model that I serve as a REST-API with FLASK. Everything runs nicely. Once the flask app is fully loaded, a request takes roughly &lt;500 ms which is okay, overall I'm really happy with it. I need a GPU on my cloud instance since I have to ensure that the time until the API answers to a request does not exceed 2 seconds.  

Now the number of requests to this model differ very much depending on the time and day. There are days with barely any requests, there are days with several thousand requests. So I thought, I could save a lot of money by making my application serverless (like AWS lambda). For most serverless applications you have to pack your application in a docker container, which I did anyway. The problem now is the following: the serverless function is triggered by a HTTP request, which then starts the Docker image. Until the API is ready to server the request, roughly 10 seconds are gone. 

This is due to the fact that importing tensorflow and loading the models in Python takes really long. Just try the following in your shell:

    time python3 -c 'import tensorflow'

 My question is, **how can I prevent this and startup my docker image faster with tensorflow models?**

I feel like this should be a common problem but I can't find a solution to it. I am also not quite sure if the solution to this problem lies in tensorflow or docker.",7,14
94,2019-8-25,2019,8,25,0,cuutg6,Tensorflow and Keras For Neural Networks and Deep Learning,https://www.reddit.com/r/tensorflow/comments/cuutg6/tensorflow_and_keras_for_neural_networks_and_deep/,discountcouponusa,1566660796,,0,1
95,2019-8-25,2019,8,25,17,cv604t,TFRecord Command Line Browser,https://www.reddit.com/r/tensorflow/comments/cv604t/tfrecord_command_line_browser/,canonicalwisdom,1566721335,"Hi guys,

[https://github.com/terrykong/tfrecord-browser](https://github.com/terrykong/tfrecord-browser)

As a little side project I thought it would be neat to try and write a command line tool for browsing the TFRecord format. If you think this is cool, try it out! Or least me feedback, I'd love to try and accommodate your use case!",1,8
96,2019-8-26,2019,8,26,16,cvkyi8,Kidney segmentation Implementation of Ultrasound Images Neural Network,https://www.reddit.com/r/tensorflow/comments/cvkyi8/kidney_segmentation_implementation_of_ultrasound/,flyhighwithai,1566805905,,0,1
97,2019-8-26,2019,8,26,19,cvlz54,TensorFlow Futurewarning,https://www.reddit.com/r/tensorflow/comments/cvlz54/tensorflow_futurewarning/,Akaleth_Illuvatar,1566813701,"TL;DR FutureWarning when importing tensorflow (1.14.0), supposedly a problem with the numpy version, but the proposed fixes don't help.

&amp;#x200B;

When setting up TensorFlow(1.14.0) on my Windows 10 laptop, I get a bunch of ""FutureWarnings"". I'm using PyCharm as IDE and Anaconda to manage packages. I am following the setup as described in [this](https://www.youtube.com/watch?v=ujTCoH21GlA) video. When running:

&gt;import tensorflow

I get the following result:

&gt;Anaconda\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\framework\\[dtypes.py:516](https://dtypes.py:516): FutureWarning:  
&gt;  
&gt;Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
&gt;  
&gt;\_np\_qint8 = np.dtype(\[(""qint8"", np.int8, 1)\])  
&gt;  
&gt;\~\\[dtypes.py:517](https://dtypes.py:517): FutureWarning:  
&gt;  
&gt;Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
&gt;  
&gt;  \_np\_quint8 = np.dtype(\[(""quint8"", np.uint8, 1)\])  
&gt;  
&gt;\~\\[dtypes.py:518](https://dtypes.py:518): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
&gt;  
&gt;  \_np\_qint16 = np.dtype(\[(""qint16"", np.int16, 1)\])  
&gt;  
&gt;\~\\[dtypes.py:519](https://dtypes.py:519): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
&gt;  
&gt;  \_np\_quint16 = np.dtype(\[(""quint16"", np.uint16, 1)\])  
&gt;  
&gt;\~\\[dtypes.py:520](https://dtypes.py:520): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
&gt;  
&gt;  \_np\_qint32 = np.dtype(\[(""qint32"", np.int32, 1)\])  
&gt;  
&gt;\~\\[dtypes.py:525](https://dtypes.py:525): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
&gt;  
&gt;  np\_resource = np.dtype(\[(""resource"", np.ubyte, 1)\])  
&gt;  
&gt;Anaconda\\envs\\tensor\\lib\\site-packages\\tensorboard\\compat\\tensorflow\_stub\\[dtypes.py:541](https://dtypes.py:541): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
&gt;  
&gt;  \_np\_qint8 = np.dtype(\[(""qint8"", np.int8, 1)\])  
&gt;  
&gt;\~\\[dtypes.py:542](https://dtypes.py:542): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
&gt;  
&gt;  \_np\_quint8 = np.dtype(\[(""quint8"", np.uint8, 1)\])  
&gt;  
&gt;\~\\[dtypes.py:543](https://dtypes.py:543): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
&gt;  
&gt;  \_np\_qint16 = np.dtype(\[(""qint16"", np.int16, 1)\])  
&gt;  
&gt;\~\\[dtypes.py:544](https://dtypes.py:544): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
&gt;  
&gt;  \_np\_quint16 = np.dtype(\[(""quint16"", np.uint16, 1)\])  
&gt;  
&gt;\~\\[dtypes.py:545](https://dtypes.py:545): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
&gt;  
&gt;  \_np\_qint32 = np.dtype(\[(""qint32"", np.int32, 1)\])  
&gt;  
&gt;\~\\[dtypes.py:550](https://dtypes.py:550): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
&gt;  
&gt;  np\_resource = np.dtype(\[(""resource"", np.ubyte, 1)\])  
&gt;  
&gt;Process finished with exit code 0

After some looking around, it seemed that this error was caused by the version of numpy I was using, as suggested [here](https://github.com/tensorflow/tensorflow/issues/30427), [here](https://github.com/tensorflow/tensorflow/issues/21939), and [here](https://github.com/tensorflow/tensorflow/issues/31249). However, setting back my numpy to the recommended version (1.16.4) did not do anything. I tried setting it back to other versions such as 1.16.0 and 1.15.0, but none of this seemed to work.

Does anyone have an idea of how to get rid of these warnings?",4,1
98,2019-8-26,2019,8,26,20,cvmnl0,Disease Prediction Using Machine Learning | Anova + PCA | SVM,https://www.reddit.com/r/tensorflow/comments/cvmnl0/disease_prediction_using_machine_learning_anova/,flyhighwithai,1566818193,,0,1
99,2019-8-26,2019,8,26,20,cvmuek,Type error: resize_images() got an unexpected keyword argument 'preserve_aspect_ratio',https://www.reddit.com/r/tensorflow/comments/cvmuek/type_error_resize_images_got_an_unexpected/,hasithz,1566819321,,0,1
100,2019-8-26,2019,8,26,20,cvmyc3,Classify Small Data Using Active Learning,https://www.reddit.com/r/tensorflow/comments/cvmyc3/classify_small_data_using_active_learning/,flyhighwithai,1566819974,,0,1
101,2019-8-26,2019,8,26,22,cvntc4,3D capsule GAN Tensorflow Explanation | +91-7307399944 For Query | CapsNet Tensorflow 3d AI,https://www.reddit.com/r/tensorflow/comments/cvntc4/3d_capsule_gan_tensorflow_explanation/,deepinsightofai,1566824681,,0,1
102,2019-8-27,2019,8,27,5,cvtn8k,Load graph for inference in TF 2.0,https://www.reddit.com/r/tensorflow/comments/cvtn8k/load_graph_for_inference_in_tf_20/,aniketmaurya,1566851414,How do I load a graph (.pb) for inference in Tensorflow 2.0?,0,3
103,2019-8-27,2019,8,27,12,cvyuye,Questions about CNN NN design help,https://www.reddit.com/r/tensorflow/comments/cvyuye/questions_about_cnn_nn_design_help/,Stanley_C,1566876913,"Hi!

I'm trying to create a quick Machine Learning example. In the folder, I have attached all my referenced files. Basically, I have manually coded a dataset: in the x(planned for input neurons while training), I have a multiple 5 lengths integer sequences that increment by 1. Then in the y(the output that we want the NN to generate), I have the same sequences, except each sequence has the length of 6. I have stored both x and y in tfrecord and numpy array files. Could someone help me start my mini project?(I've completed a Udemy course on ML, but it wasn't very useful for me)

&amp;#x200B;

[https://drive.google.com/drive/folders/1iOf69YAC\_ek5P5odRTQe5uAeXibUkD7V?usp=sharing](https://drive.google.com/drive/folders/1iOf69YAC_ek5P5odRTQe5uAeXibUkD7V?usp=sharing)",5,2
104,2019-8-27,2019,8,27,15,cw0l31,Simulated Annealing Based Wireless Sensor Network Localization | WSN,https://www.reddit.com/r/tensorflow/comments/cw0l31/simulated_annealing_based_wireless_sensor_network/,deepinsightofai,1566887800,,1,0
105,2019-8-27,2019,8,27,17,cw1kg0,"convert video data (.avi, .mp4 etc.) to TensorFlow tfrecords",https://www.reddit.com/r/tensorflow/comments/cw1kg0/convert_video_data_avi_mp4_etc_to_tensorflow/,whiletrue2,1566895046,,9,12
106,2019-8-28,2019,8,28,12,cwfarm,Looking for repo with a good multilabel image classifier,https://www.reddit.com/r/tensorflow/comments/cwfarm/looking_for_repo_with_a_good_multilabel_image/,ski233,1566963101,"Im wanting to do multilabel image classification. I found one model on github and tried it but was rather underwhelmed by the accuracy. From just looking on github, there are only a few (3-4) multilabel image classifiers even available. Does anyone have a repository they would recommend that I could try? Or should I just try to design my own model? Or should I just abandon the multilabel image classifier model idea and just use a slower object detection model that requires more time for image annotations?",4,5
107,2019-8-28,2019,8,28,17,cwhrrr,Creating a custom metric for a model,https://www.reddit.com/r/tensorflow/comments/cwhrrr/creating_a_custom_metric_for_a_model/,Korr4K,1566979836,"Hi everyone, I'm pretty new to tf and am having a lot of trouble debugging the code. I currently have a working image classification model and I wanted to implement different metrics to use them to evaluate my test data set.

The first metric would be to compare the indices obtained from argmax of y\_true and y\_pred to see if both are above a certain threshold. Having 10 classes the idea is to divide them into the first and second half. I tried this code:

\-----------------------------------------------------------------------------------------------

 def custom\_binary\_accuracy(y\_true, y\_pred):

  
  y\_true\_index = K.argmax(y\_true, axis=-1)  
  y\_pred\_index = K.argmax(y\_pred, axis=-1)

  
  y\_true\_bool = K.greater(y\_true\_index, 4)  
  y\_pred\_bool = K.greater(y\_pred\_index, 4)

  
  matches = K.cast(K.equal(y\_true\_bool, y\_pred\_bool), 'int32')

  
  return K.mean(matches)

\-----------------------------------------------------------------------------------------------

I load my pre-trained model, compile it with the new metric, launch the evaluate\_generator but the accuracy is always 0. I'm probably doing a very stupid mistake but tf is not helping me finding out where it is

Any help?",0,1
108,2019-8-28,2019,8,28,19,cwispw,I recently switched to TF 2.0 RC. And Im looking for some help,https://www.reddit.com/r/tensorflow/comments/cwispw/i_recently_switched_to_tf_20_rc_and_im_looking/,Fallen-Zero,1566987343,"After switching for TF 2.0, Im struggling to find a the correct way to implement a NN with Low-Level API as I used to do it in TF 1.0, since sessions and placeholders are now deprecated. Back in TF 1.0, you define the forward pass function, the cost function and optimizer, and you let it run in a session and see the results at the end. 
Im struggling to do that with TF 2.0 with the Low Level API and NOT in tf.keras

Any help or advice would be appreciated. Thanks in advance.",2,1
109,2019-8-28,2019,8,28,22,cwkjlz,Is there a clean way to use Keras callbacks in custom TF training loops?,https://www.reddit.com/r/tensorflow/comments/cwkjlz/is_there_a_clean_way_to_use_keras_callbacks_in/,adelredjimi,1566997511,"I'm working on research project where writing custom training loops in Tensorflow is easier than using `keras.Model.fit()`. However, I miss handy callbacks such as EarlyStopping, ReduceLROnPlateau, TensorBoard. I had to rewrite some stuff from scratch.",2,3
110,2019-8-28,2019,8,28,22,cwkuw6,Tensorflow 2.0 implementations of Interpretability Methods,https://www.reddit.com/r/tensorflow/comments/cwkuw6/tensorflow_20_implementations_of_interpretability/,raphaelmeudec,1566999097,,0,12
111,2019-8-28,2019,8,28,23,cwln00,Does Tensorflow 2.0 support GPUDirect?,https://www.reddit.com/r/tensorflow/comments/cwln00/does_tensorflow_20_support_gpudirect/,SilverSeaworthiness9,1567002841,"Would I be able to dramatically advance training speed on a 3 node Network with Mellanox Connect X 5 VPI cards and Tesla V100s by utilizing GPUDirect in Tensorflow 2? If so, how do I enable that feature?",0,3
112,2019-8-29,2019,8,29,9,cwteh3,Is this Idea Viable with TensorFlow,https://www.reddit.com/r/tensorflow/comments/cwteh3/is_this_idea_viable_with_tensorflow/,aklosk,1567038576,"I'm worked in Dev-Ops for 10 years, ready to take the step into deep-learning.

For us shallow folks, how do we determine if an application idea is viable for tensorflow or currently available deep learning algos? Would anyone be willing to DM me to discuss a potential application that I hope to develop?",2,4
113,2019-8-29,2019,8,29,20,cwziou,Quantization aware training with Tensorflow 2.0,https://www.reddit.com/r/tensorflow/comments/cwziou/quantization_aware_training_with_tensorflow_20/,I_love_Icecream,1567077727,Could anyone help me understand how to make an edgetpu compatible model with tensorflow. I am using Keras api if that helps. I have tried converting with TFLiteConverter and using post training quantization. it does not compile with edgetpu.,0,7
114,2019-8-30,2019,8,30,8,cx8pzi,"I'm getting a No module named '_pywrap_tensorflow_internal' error, but the .so file is there.",https://www.reddit.com/r/tensorflow/comments/cx8pzi/im_getting_a_no_module_named_pywrap_tensorflow/,kiwilifter,1567121091,"&gt;ImportError: No module named '\_pywrap\_tensorflow\_internal'

I was having problems installing tensorflow, I read a few posts and figured out it was a python version support issue which I found a fix for. But now when I try to run an AI program I downloaded from github I get the above error. I took a look in the tensorflow python subdiretory and there is an .so file with that name.

I'm doing this on a Windows 10 system.

Thanks in advance.",0,3
115,2019-8-30,2019,8,30,14,cxcu9k,deepfakes face swapping video from a single image without training for any face keras tensorflow,https://www.reddit.com/r/tensorflow/comments/cxcu9k/deepfakes_face_swapping_video_from_a_single_image/,PuzzledProgrammer3,1567144583,"Generative adversarial networks integrating modules from FUNIT and SPADE for face-swapping

github: [https://github.com/shaoanlu/fewshot-face-translation-GAN](https://github.com/shaoanlu/fewshot-face-translation-GAN)

inference only takes a few minutes on a k80 in google colab vs weeks or days of training for a face pair

demo elon musk and taylor swift

&amp;#x200B;

![video](0ftst3zuzij31)",7,17
116,2019-8-30,2019,8,30,23,cxi2r6,C api on fashion-mnist training.,https://www.reddit.com/r/tensorflow/comments/cxi2r6/c_api_on_fashionmnist_training/,jregalad-o,1567177119,"I would really appreciate ant help.   
[https://stackoverflow.com/questions/57728956/how-to-provide-training-data-to-tf-sessionrun-from-c-api-h](https://stackoverflow.com/questions/57728956/how-to-provide-training-data-to-tf-sessionrun-from-c-api-h)  


Trying to train the model from the Tf tutorial using the C api with no success.   


Specially while feeding training data and labels to SessionRun()",0,2
117,2019-8-31,2019,8,31,3,cxl8k8,tf.data.Dataset shuffle is weirdly slow,https://www.reddit.com/r/tensorflow/comments/cxl8k8/tfdatadataset_shuffle_is_weirdly_slow/,hassanzadeh,1567191370,"Hey Guys,

I'm having a small dataset of around 60K rows. I'm using [tf.data](https://tf.data) api for fetching data and I shuffle it before batching with a buffer size of 60K. Say I want to do this with pandas, it takes only a few seconds if not milliseconds, now with TF, this takes ages! Just look at the console prints:

why is that? what's wrong with TF?

https://i.redd.it/bm5vcrvzumj31.png",4,1
118,2019-8-31,2019,8,31,4,cxlgrg,How to load submodel's weights from a full model's weight file in Keras?,https://www.reddit.com/r/tensorflow/comments/cxlgrg/how_to_load_submodels_weights_from_a_full_models/,roset_ta,1567192396,"Hello,


I have a pretrained model saved in a .hd5 file. I don't have the training code for this model, so I don't know how it was saved. What I know is that it contains two branches in it and I need to extract their weights, i.e. save them in  .hdf5 files, load them and use them to make some predictions.


I have tried iterating over the full model's layers and using the `model.save_weights(directory)` function of Keras when I find the submodels I need. The problem is that when I load them by `model.load_weights(directory, by_name=True)` I don't get the expected predictions on the evaluation, they are really weird. Of course, since I only save the weights and not the architecture, I also build the model again before loading the weights. What may be wrong? Is there a difference between .hd5 and .hdf5 files? And does loading depend on the way the model was saved?",0,3
119,2019-8-31,2019,8,31,5,cxm4cd,Tensor to numpy in TF 2.0?,https://www.reddit.com/r/tensorflow/comments/cxm4cd/tensor_to_numpy_in_tf_20/,Runninganddogs979,1567195407,"Hi all!

So I need to use output weights from a layer in cv2 operations, but to do that I need it to be in numpy form. I can not for the life of me figure out how to convert a tensor to a numpy array in TF 2.0, any tips?",8,3
120,2019-8-31,2019,8,31,5,cxmhpn,TF 2.0 compatible with TFX yet?,https://www.reddit.com/r/tensorflow/comments/cxmhpn/tf_20_compatible_with_tfx_yet/,AlphonseWestwood,1567197151,I had heard that there were some incompatibility issues from a previous video I watched on production grade ML. Learning TF 2.0 right now as well as airflow &amp; kubeflow. Please let me know if Im wrong and they are in fact compatible right now.,1,6
121,2019-8-31,2019,8,31,19,cxuizx,Tensorflow 2.0 : Combining model.add_loss and keras losses function in training doesn't work,https://www.reddit.com/r/tensorflow/comments/cxuizx/tensorflow_20_combining_modeladd_loss_and_keras/,51616,1567247825,"I read about TensorFlow 2.0 [tutorial](https://www.tensorflow.org/beta/guide/keras/custom_layers_and_models) in VAE section. I follow the tutorial but the model doesn't work as expected despite running the notebook directly from given [Google Colab](https://colab.research.google.com/github/tensorflow/docs/blob/r2.0rc/site/en/r2/guide/keras/custom_layers_and_models.ipynb). The result actually is the same as in the tutorial (i.e. loss value is very similar) but if you look at the output you'll see that the model can't reconstruct the input at all (i.e. output the same image for all inputs). This seems to be a mistake from the tutorial itself when combining `model.add_loss()` and `keras.losses`.

[Original code](https://imgur.com/3rTAOrZ)

I changed MSE loss to BinaryCrossentropy but the result is still the same.

Later I tried compute the BinaryCrossentropy loss explicitly in my forward pass then use `model.add_loss()` in addition with the KL-divergence loss

[Use only model.add_loss() to calculate the loss](https://imgur.com/VVOROCI)

This way the model can actually learn the data and the output seems good enough.

So I have a question about `model.add_loss()` and losses as a function that takes `(y_true, y_pred)` (i.e. `keras.losses`). The updated code works only if it can calculate losses in forward pass (e.g. kl-divergence or reconstruction loss), how can I combine `model.add_loss()` and `keras.losses` correctly in the case where the model need ground truth of the output (e.g. denoise VAE).",0,4
0,2019-9-1,2019,9,1,10,cy3mit,Convert tensor to eager tensor in tf 2.0,https://www.reddit.com/r/tensorflow/comments/cy3mit/convert_tensor_to_eager_tensor_in_tf_20/,Runninganddogs979,1567299669,"Hi all!

So I'm pulling a layer out of aa Deeplab v3+ model and I need to eventually convert it to a np array. Unfortunately the layer is of type Tensor and not EagerTensor so I am not able to access the .numpy() method. All code was done in TF 2.0 alpha. Any suggestions?",1,0
1,2019-9-1,2019,9,1,11,cy4hp9,I need some assistance!,https://www.reddit.com/r/tensorflow/comments/cy4hp9/i_need_some_assistance/,Quilldino2,1567304752,"I recently have been trying to get into coding with python because I eventually would like to create an AI; however when I import tensorflow into either my command prompt running Python 3.6 or PyCharm with interpreter 3.6 I get an error. I am also using miniconda.

&amp;#x200B;

&amp;#x200B;

C:\\Users\\StRUT\\Miniconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\framework\\[dtypes.py:516](https://dtypes.py:516): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  \_np\_qint8 = np.dtype(\[(""qint8"", np.int8, 1)\])

C:\\Users\\StRUT\\Miniconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\framework\\[dtypes.py:517](https://dtypes.py:517): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  \_np\_quint8 = np.dtype(\[(""quint8"", np.uint8, 1)\])

C:\\Users\\StRUT\\Miniconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\framework\\[dtypes.py:518](https://dtypes.py:518): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  \_np\_qint16 = np.dtype(\[(""qint16"", np.int16, 1)\])

C:\\Users\\StRUT\\Miniconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\framework\\[dtypes.py:519](https://dtypes.py:519): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  \_np\_quint16 = np.dtype(\[(""quint16"", np.uint16, 1)\])

C:\\Users\\StRUT\\Miniconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\framework\\[dtypes.py:520](https://dtypes.py:520): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  \_np\_qint32 = np.dtype(\[(""qint32"", np.int32, 1)\])

C:\\Users\\StRUT\\Miniconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\framework\\[dtypes.py:525](https://dtypes.py:525): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  np\_resource = np.dtype(\[(""resource"", np.ubyte, 1)\])

C:\\Users\\StRUT\\Miniconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorboard\\compat\\tensorflow\_stub\\[dtypes.py:541](https://dtypes.py:541): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  \_np\_qint8 = np.dtype(\[(""qint8"", np.int8, 1)\])

C:\\Users\\StRUT\\Miniconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorboard\\compat\\tensorflow\_stub\\[dtypes.py:542](https://dtypes.py:542): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  \_np\_quint8 = np.dtype(\[(""quint8"", np.uint8, 1)\])

C:\\Users\\StRUT\\Miniconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorboard\\compat\\tensorflow\_stub\\[dtypes.py:543](https://dtypes.py:543): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  \_np\_qint16 = np.dtype(\[(""qint16"", np.int16, 1)\])

C:\\Users\\StRUT\\Miniconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorboard\\compat\\tensorflow\_stub\\[dtypes.py:544](https://dtypes.py:544): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  \_np\_quint16 = np.dtype(\[(""quint16"", np.uint16, 1)\])

C:\\Users\\StRUT\\Miniconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorboard\\compat\\tensorflow\_stub\\[dtypes.py:545](https://dtypes.py:545): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  \_np\_qint32 = np.dtype(\[(""qint32"", np.int32, 1)\])

C:\\Users\\StRUT\\Miniconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorboard\\compat\\tensorflow\_stub\\[dtypes.py:550](https://dtypes.py:550): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  np\_resource = np.dtype(\[(""resource"", np.ubyte, 1)\])

\---------------------------------------------------------------------------------------------------------------------------------

I hope someone can help with this issue because the past 4 days I have had a different issue that seems to have been fixed, but then another one come right up. 

Thanks in advance!",6,1
2,2019-9-2,2019,9,2,21,cyo4mo,Changing a pixel in an image using tensorflow,https://www.reddit.com/r/tensorflow/comments/cyo4mo/changing_a_pixel_in_an_image_using_tensorflow/,ninji3,1567425986,"I asked a question on SO over the weekend but it didn't get much attention, so I am posting it again here in the hope that someone might know of a way to do this.

[Stack Overflow: How to replace pixel value as a tensorflow operation?](https://stackoverflow.com/questions/57733053/how-to-replace-pixel-value-as-a-tensorflow-operation)

You can find the details there.

To give you a quick summary: I am currently using `tf.py_func()` to change the value of a pixel in an image. This slows down my code substantially. Is there a clever way to do this in tensorflow?",4,3
3,2019-9-3,2019,9,3,2,cys6xq,"AI Cheatsheets - Now learn Tensorflow, Keras, Pytorch, Dask, Pandas, Numpy, Scipy, Pyspark, R Studio, Matplotlib and many more in an interactive manner",https://www.reddit.com/r/tensorflow/comments/cys6xq/ai_cheatsheets_now_learn_tensorflow_keras_pytorch/,kailashahirwar12,1567445820,,0,43
4,2019-9-3,2019,9,3,4,cytn3r,Back-propagation Demystified [Part 3] | Computational Graphs in TensorFlow,https://www.reddit.com/r/tensorflow/comments/cytn3r/backpropagation_demystified_part_3_computational/,msminhas93,1567452179,,0,1
5,2019-9-3,2019,9,3,6,cyvc6y,How would I identify circuit damage using tensorflow?,https://www.reddit.com/r/tensorflow/comments/cyvc6y/how_would_i_identify_circuit_damage_using/,skellerone,1567459696,"Hi all,

I've set myself a small project of making a neural network in tensorflow that will identify images of circuits, and I've used the basic model and image loading tutorials to do so thus far. However, I want to be able to at some point give this model a damaged circuit, and have it recognize the damage. What would be the best way of doing this?

(I figured the easiest way would be simply to highlight images which are below a certain confidence rating once the network has been optimized, but it would also be nice to produce some kind of image highlighting the particular area the model had difficulty matching, for reference, which would need something a little more elaborate...)",4,0
6,2019-9-3,2019,9,3,7,cyw2cj,Custom Text Classification for multiple classes,https://www.reddit.com/r/tensorflow/comments/cyw2cj/custom_text_classification_for_multiple_classes/,charManpie,1567463122,"Hello,

I am looking for a tutorial on how to build a custom model for Text Classification with multiple classes. I have used image recognition and object detection for training and prediction. 'tensorflow for poets' example was very simple. I am looking for something similar, preparing data, training and prediction.

 [https://www.tensorflow.org/beta/tutorials/text/text\_classification\_rnn](https://www.tensorflow.org/beta/tutorials/text/text_classification_rnn)   
 [https://www.tensorflow.org/hub/tutorials/text\_classification\_with\_tf\_hub](https://www.tensorflow.org/hub/tutorials/text_classification_with_tf_hub) 

Both of these links were helpful, I am not sure how can I use this tutorial to train different data and specify multiple labels and test them afterwards. Similar to the image recognition tensorflow for poets

Thank you so much in advance.",1,1
7,2019-9-3,2019,9,3,8,cywoll,Get output layer from Deeplab model,https://www.reddit.com/r/tensorflow/comments/cywoll/get_output_layer_from_deeplab_model/,Runninganddogs979,1567466170,"Hi all!

So I need to grab out a layer from the deeplab v3+ model that has the same dims as the output picture but with number of categories as the channels not RGB. How do I find this??",0,1
8,2019-9-3,2019,9,3,19,cz2x1k,How to use tensorboard visualizations for custom training loops in TF2.0,https://www.reddit.com/r/tensorflow/comments/cz2x1k/how_to_use_tensorboard_visualizations_for_custom/,Bowserwolf1,1567505780,"If i was writing the model in pure keras, i'd probably just use tensorboard as a callback in [model.fit](https://model.fit), and in tensorflow 1.x, id use tensorboard the normal way by using the session object. but in tf2.0 there is no graph object, so i cant throw that to tensorboard as a argument. 

&amp;#x200B;

i;m trying to rain a dcgan and the training loop i've written is custom, and i dont want to go the hassle of converting it to work with the kears [model.fit](https://model.fit) logic. Is there any way i could get the tensorboard visualization in this kind of a train loop ? 

&amp;#x200B;

this is my training loop

    for epoch in range(n_epochs):
            for batch in train_dataset:
                DCGAN.train(batch)
                print(""one iteration"")
            print(
                f""for epoch {epoch} gen_loss is {avg_gen_loss.result()} disc_loss is {avg_disc_loss.result()}"")
     
    
    # main training loop 

and tihs is the train function 

    @tf.function
        def train(self, images):
            for _ in range(PARAMS['n_looping_factor']):# train discriminator for n_looping_factor loops
                noise = tf.random.normal(
                    shape=[self.batch_size, 100], mean=0, stddev=1.0, dtype=tf.float32)
                with tf.GradientTape() as disc_tape:
                    gen_images = self.generator(noise) # generate fake images
                    
                    real_pred = self.discriminator(images)
                    generated_pred = self.discriminator(tf.zeros_like(gen_images)) 
                    
                    discriminator_loss = self.discriminator_loss(
                        real_pred, generated_pred)
                    
                    avg_disc_loss.update_state(discriminator_loss) # update avg_loss for this batch
                disc_gradients = disc_tape.gradient(
                    discriminator_loss, self.discriminator.trainable_variables)
                self.disc_optimizer.apply_gradients(
                    (zip(disc_gradients, self.discriminator.trainable_variables)))
    
            # train generator once
            noise = tf.random.normal(
                shape=[self.batch_size, 100], mean=0, stddev=1.0, dtype=tf.float32)
            with tf.GradientTape() as gen_tape:
                gen_images = self.generator(noise)
                generated_pred = self.discriminator(gen_images)
                generator_loss = self.generator_loss(generated_pred)
                avg_gen_loss.update_state(generator_loss)
            gen_gradients = gen_tape.gradient(
                generator_loss, self.generator.trainable_variables)
            self.gen_optimizer.apply_gradients(
                zip(gen_gradients, self.generator.trainable_variables))
    

Any help wpuld be appreciated, thanks in advance!",0,1
9,2019-9-3,2019,9,3,20,cz3l03,Kubeflow (on premise) TFX pipelines,https://www.reddit.com/r/tensorflow/comments/cz3l03/kubeflow_on_premise_tfx_pipelines/,valerianomanassero,1567510107,"I just started a new repo with my first two pipelines for TFX on Kubeflow (on premise).

[https://github.com/valeriano-manassero/tfx-kubeflow-pipelines](https://github.com/valeriano-manassero/tfx-kubeflow-pipelines)

Since I found difficult times with docs about Kubeflow on premise and TFX pipeines for images I'm sharing this hoping for good feedbacks. I will try to continue improve it.

Any suggestion is appreciated!",0,6
10,2019-9-4,2019,9,4,3,cz91c1,Using multimodal data as input (continuous/discrete),https://www.reddit.com/r/tensorflow/comments/cz91c1/using_multimodal_data_as_input_continuousdiscrete/,McDinkelfurz,1567536548,"Is there an optimal strategy for combining continuous data columns with discrete data columns to use as input for a neural network? By which I mean, if you have continuous data alongside binary data or columns of integers, is there a way to process the data other than just standardizing it?",2,2
11,2019-9-4,2019,9,4,6,czawpl,Data Science Specialization from Johns Hopkins University,https://www.reddit.com/r/tensorflow/comments/czawpl/data_science_specialization_from_johns_hopkins/,internetdigitalentre,1567544922,[removed],0,1
12,2019-9-4,2019,9,4,8,czcnq9,Simple and useful guide for TensorFlow,https://www.reddit.com/r/tensorflow/comments/czcnq9/simple_and_useful_guide_for_tensorflow/,MarceloLopezUru,1567553210,[removed],0,1
13,2019-9-4,2019,9,4,12,czfhua,Is the first layer of sequenctial keras dense layer a hidden layer?,https://www.reddit.com/r/tensorflow/comments/czfhua/is_the_first_layer_of_sequenctial_keras_dense/,begooboi,1567568080,"I need to create a three layer neural network with this config

    input_dim=2
    hidden_dim=2
    output_dim=1

and wrote my model this way

    model = Sequential()
    # Input layer
    model.add(Dense(output_dim=3, input_dim=2))
    # Hidden layer
    model.add(Dense(2)
    # Output layer
    model.add(Dense(1))

My expected weight matrix is  [2x2],[2x1] with W^ih and W^ho respectively. But the weight matrix I got was this


    &gt;&gt;&gt;for i in model.get_weights():
        print(""\n"",i)


     [[ 0.02314293 -0.74796295  0.4222021 ]
     [-0.5900725   0.6331698  -0.30411077]]

     [0. 0. 0.]

     [[-0.6382148  -0.21151215]
     [-0.81804264 -0.4383769 ]
     [-0.32733858 -1.0314355 ]]

     [0. 0.]

     [[1.2613355]
     [1.377251 ]]

     [0.]

I know zero matrix are biases but its the first weight matrix, that is,

     [[ 0.02314293 -0.74796295  0.4222021 ]
     [-0.5900725   0.6331698  -0.30411077]]

which confuses me.
Is the first layer of my model `model.add(Dense(output_dim=3, input_dim=2))` is not an ""input layer"" alone but ""input+hidden layer""? and my model is actually a four layer network instead of three?",2,2
14,2019-9-4,2019,9,4,22,czkoyj,Hyperparameter Tuning for lo-level Tensorflow code,https://www.reddit.com/r/tensorflow/comments/czkoyj/hyperparameter_tuning_for_lolevel_tensorflow_code/,honeybooboo1989,1567602761,"Hello everyone,

I was curious about how people are doing hyperparameter tuning for a neural network which was written in low-level Tensorflow. I am still using Tensorflow 1.0 not Keras or anything else. I want to tune hyperparameters, I look for some documentations/resources online and cannot come up with anything (I know tuning methods but I am looking for a specific packages).

For example,  Tensorflow has `HParams` plugin designed for Tensorflow 2.0 and Keras. 
https://www.tensorflow.org/tensorboard/r2/hyperparameter_tuning_with_hparams

Can you give me direction and/or a GitHub Repo or something?",0,1
15,2019-9-4,2019,9,4,22,czkt7l,Hyperparameter Tuning for low-level Tensorflow code,https://www.reddit.com/r/tensorflow/comments/czkt7l/hyperparameter_tuning_for_lowlevel_tensorflow_code/,honeybooboo1989,1567603366,"Hello everyone,

I was curious about how people are doing hyperparameter tuning for a neural network which was written in low-level Tensorflow. I am still using Tensorflow 1.0 not Keras or anything else. I want to tune hyperparameters, I look for some documentations/resources online and cannot come up with anything (I know tuning methods but I am looking for a specific packages).

For example,  Tensorflow has `HParams` plugin designed for Tensorflow 2.0 and Keras. 
https://www.tensorflow.org/tensorboard/r2/hyperparameter_tuning_with_hparams

Can you give me direction and/or a GitHub Repo or something?",0,1
16,2019-9-4,2019,9,4,23,czl9c7,Rubik's cube solving TensorFlow model with Lego EV3 MindCub3r robot support,https://www.reddit.com/r/tensorflow/comments/czl9c7/rubiks_cube_solving_tensorflow_model_with_lego/,antondesaintbon,1567605611,"hey reddit!

Created this very simple dense feedforward model for a project with my kid to build a cube solving robot. It can reliably solve either virtual cubes or real ones when connected to Lego MindCub3r robot and it takes only few hours to train on an average PC without GPU accelerators.

This is a good way to get kids interested in robotics and machine learning so if you have or work with kids and wanna get involved check it out at [https://github.com/antbob/qub3rt](https://github.com/antbob/qub3rt)",1,11
17,2019-9-5,2019,9,5,2,czo5x7,Why is tensorflow so hard to install?,https://www.reddit.com/r/tensorflow/comments/czo5x7/why_is_tensorflow_so_hard_to_install/,Technerder,1567618978,"I'd like to start off by saying that I am not a novice at programming or in using Linux/windows machines.

&amp;#x200B;

Every time I've tried to install tensorflow, whether on a laptop, raspberry pi 3 or desktop machine, I've never been able to successfully install it. I've had the install on my desktop machine (with Debian 10) and it froze everything (overnight) to the point where I needed to hard restart it. I've had run-ins where the linux installation docs told me to install bazel without stating that tensorflow didn't support the latest version (The build told me I needed to downgrade, which then lead to the comuter hanging). I've had issues with my raspberry pi hanging and no longer responding to any ssh commands until I hard restarted it. 

Over my \~6 years of programming I have never run into a library which has been harder to install. I understand that this is a massive project in the machine learning scene, written in multiple languages with thousands of contributors, but I still don't understand why it is so hard to install.",17,9
18,2019-9-5,2019,9,5,5,czqjaa,Multiple inputs and multiple output in keras lstm,https://www.reddit.com/r/tensorflow/comments/czqjaa/multiple_inputs_and_multiple_output_in_keras_lstm/,sheneon91,1567630001,"Hi all,
I have a use case where I have sequences on one hand as an Input and I was using lstm to predict an output variable ( binary classification model).
Now there is a request to also predict the time when the event will happen. 
I have the time component in my data but now the model would be
Multiple input and multiple outputs.
One output is classification and other is regression.
Currently I have built my architecture where I have an embedding layer which goes to lstm for the sequences and then I add another input layer for some extra features.
Pretty much confused now regarding how to add this time sequence after the embedding layer and before lstm. Also the shapes have to be the same too else it's giving me an error.
Any help would be appreciated.",1,1
19,2019-9-5,2019,9,5,6,czr0ms,TF2 Keras vs Estimators?,https://www.reddit.com/r/tensorflow/comments/czr0ms/tf2_keras_vs_estimators/,UysofSpades,1567632190,"Wanted to hear the opinions of the community here regarding some API usage. My first exposure to ML, in general, fell upon the Keras API. It was intuitive and left out a lot of the meat for quick prototyping of models. However, as my career progressed, I was met with more challenging problems, than the \_forecast weather tutorial\_ or \_iris species classification\_. I started experimenting with slight variations of recent studies that implemented abstract and complicated models in a variety of use cases in all industries. I quickly realized, as \_easy\_ as Keras is to pick up, it doesn't allow me to set up complicated models in an efficient way, namely the way GAN networks are structured [isn't as efficient.](https://github.com/keras-team/keras/issues/5312) Anyways, not bashing Keras, I still love it, but I started to personally experience some of the \_downsides\_ that a few experienced folks mentioned with the limitations. With this and coupled with the fact, that most studies I have read implemented TensorFlow via the low-level API calls, it forced me to dig deeper into the inner workings to see what goes on behind the scenes of Keras. I can confidently say that I have more questions now, than when I started, lol. Anyways my projects required that I build models that are scalable and relatively easily implemented at a production-level scale. Interestingly enough, I \_accidently\_ stumbled unto Estimators. I am surprised they don't get enough attention, seeing that every mother and their cousin has some article on medium on how to use ML.

&amp;#x200B;

Further reading on Estimators showed me that it is used also as a high-level API, and very similar to Keras. Google also advises that if one is to use Tensorflow in a production level setting, then they recommend using the Estimator API as [it scales easily, allows for multi-distribution, and easier cross-platform functionality.](https://www.tensorflow.org/guide/premade_estimators) However, with the release of TF2 and the complete integration of Keras into the library, and the fact that TF seems to have gone through a complete overhaul, I am at a lost yet again. The documentation is minimal at best around TF2, and I can't trust Medium articles, as it seems the majority is written by beginners themselves.

&amp;#x200B;

I'd like to open the floor to the community of people who has a little more knowledge of how vastly different TF2 actually is (in practice). Also people who have used Estimators instead, what are the pros and cons around this? Has the entire battlegrounds just changed with TF2? It is almost a trivial decision to go with one or the other?

&amp;#x200B;

Thank you for your time.",9,7
20,2019-9-5,2019,9,5,12,czv98t,Docker service replicas in same node with multiple GPU's,https://www.reddit.com/r/tensorflow/comments/czv98t/docker_service_replicas_in_same_node_with/,vikash_kaushal,1567653273,"Hi all! I've been working on tensorflow for some months now, and I've been using docker as a service for hosting tf models using the rest api on a GPU machine. My doubt is whether it is possible to run two docker services on the same node but in two seperate GPU's? If possible, how? I have a machine with multiple GPU's and would like each replica of the service to use one GPU seperately! 
Thanks in advance!",2,1
21,2019-9-5,2019,9,5,16,czxgdp,Style Transfer AI Tensorflow | Neural Style Transfer AI,https://www.reddit.com/r/tensorflow/comments/czxgdp/style_transfer_ai_tensorflow_neural_style/,OliviaWillson,1567667715,,0,1
22,2019-9-5,2019,9,5,17,czy6fq,"Neural Structured Learning (NSL) in TensorFlow, good to know that!",https://www.reddit.com/r/tensorflow/comments/czy6fq/neural_structured_learning_nsl_in_tensorflow_good/,makereven,1567673505,"Tensorflow team released an article about Neural Structured Learning in TensorFlow, an easy-to-use framework that both novice and advanced developers can use for training neural networks with structured signals.

here is the full content:  [https://medium.com/tensorflow/introducing-neural-structured-learning-in-tensorflow-5a802efd7afd](https://medium.com/tensorflow/introducing-neural-structured-learning-in-tensorflow-5a802efd7afd)",2,12
23,2019-9-5,2019,9,5,20,czz9hz,Can we pass a list of no. Of hidden neurons in tf.layers.dense() once instead of one neuron per layer,https://www.reddit.com/r/tensorflow/comments/czz9hz/can_we_pass_a_list_of_no_of_hidden_neurons_in/,sahiluppal4k,1567681220,,0,1
24,2019-9-5,2019,9,5,21,d00dif,Avoiding the vanishing gradients problem by adding random noise and batch normalization,https://www.reddit.com/r/tensorflow/comments/d00dif/avoiding_the_vanishing_gradients_problem_by/,afagarap,1567687756,,1,2
25,2019-9-5,2019,9,5,22,d012n3,using multiscale ssim as loss function,https://www.reddit.com/r/tensorflow/comments/d012n3/using_multiscale_ssim_as_loss_function/,hypo_hibbo,1567691391,"Hi, I am doing a project with image processing. I already successfully applied tf.image.ssim for my loss function. Now I would like to test results for the ms ssim.

My network generates 64x64 gray value image patches and therefore the loss calculated by comparing these patches with ground truth patches of the same size.

This is basically my loss:

&amp;#x200B;

          def custom_loss(y_true,y_pred)
                def SSIM_loss(y_true, y_pred):
                    return tf.image.ssim_multiscale(y_true, y_pred,1)
                # Return a function
                return SSIM_loss(y_true, y_pred)

I get this warning:

    InvalidArgumentError: Computed output size would be negative: -2 [input_size: 8, effective_filter_size: 11, stride: 1]
    	 [[{{node loss_3/subtract_8_loss/MS-SSIM/Scale3/depthwise_1}}]]
    	 [[{{node loss_3/mul}}]]

I don't understand what the probleme is. SSIM works fine. 

Thanks for your help!",1,1
26,2019-9-6,2019,9,6,5,d06pmo,Question about adding TensorFlow to a NodeJS application,https://www.reddit.com/r/tensorflow/comments/d06pmo/question_about_adding_tensorflow_to_a_nodejs/,devdaesun,1567717018,"I have a side project that Im working on and a feature requires text analysis. Im thinking of doing this with TensorFlow.

Would I be able to implement TensorFlow right into my NodeJS application? Or would it be better practice to create a separate application to make API calls from TensorFlow to NodeJS?

I will be using TensorFlow.js for this.",6,4
27,2019-9-6,2019,9,6,16,d0dljr,How to test a deeplab v3+ model trained using tf's research repository?,https://www.reddit.com/r/tensorflow/comments/d0dljr/how_to_test_a_deeplab_v3_model_trained_using_tfs/,shreshths,1567756349,"I used the deeplab rep for training my models and validatiing on Val set. What I can't figure out is a way to test my model on new images?
I'm not a pro at tf so maybe this is stupid but please help !",0,1
28,2019-9-7,2019,9,7,4,d0lfbi,Please help me understand how Tensorflow's 2d convolutional layer handles multi-channel inputs?,https://www.reddit.com/r/tensorflow/comments/d0lfbi/please_help_me_understand_how_tensorflows_2d/,ManBearHybrid,1567798540,"For convolution layers with 2D inputs (e.g. grayscale images), I understand how the kernel will be scanned over the rows and columns to produce a  2D feature map.  Now I'm trying to specify multi-channel inputs, like for RGB images. According to the [keras documentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Conv2D)  for a conv2d layer, your input shape should be a tuple of the shape (samples, rows, cols, channels). So if we run the model on a single RGB  input image of 128 x 128 pixels, it will have to be reshaped to (1, 128,  128, 3). This is fine.

But the  documentation also says that the output will have the shape (samples, filters, new\_rows, new\_cols). This is as I expected for a 2D image, but  what happens to the 3rd dimension of multi-channel images? I tried to build such a simple one-layer model in Python as follows:

    import tensorflow as tf 
    ImgInputs = tf.keras.Input(shape=(128, 128, 3), name='img_input') 
    Conv1 = tf.keras.layers.Conv2D(
         filters=16,
         kernel_size=(4, 4), 
         strides=(1,1), 
         padding='same', 
         activation='relu')(ImgInputs) 
    model = tf.keras.Model(inputs=ImgInputs, outputs=Conv1) 
    optimizer = tf.keras.optimizers.Adam(lr=0.001) 
    model.compile(optimizer, loss='mse',metrics=['accuracy']) 
    
    model.summary() # print summary 

This runs without a problem. Since the kernel and stride for such a layer must be applied as 2D vectors (according to the docs), what happens to the channels? I would have guessed that the output ""depth"" would be equal to the number of kernels (16 in our case) multiplied by the number of channels (3), so 16 x 3 = 48. Put another way, I would have guessed that the output is the stacked result of multiple 2D convolutional layers, one for each channel (or some variation of this).

But when I build it and try it, the output is just (\[number of samples\] x 128 x 128 x 16) - the depth of each sample's output is just number of kernels, regardless of how many channels are provided. So it appears that the model is aggregating the channels somehow, but I'm not sure how. Can someone help me understand or point me to a resource that can explain it?",3,2
29,2019-9-7,2019,9,7,15,d0ssow,Image recognition model in LSTM | Image classification |TensorFlow | LSTM For Thesis,https://www.reddit.com/r/tensorflow/comments/d0ssow/image_recognition_model_in_lstm_image/,OliviaWillson,1567839233,,0,1
30,2019-9-7,2019,9,7,23,d0wbjj,Stochastic vs Batch vs Mini-Batch Gradient Descent in Python,https://www.reddit.com/r/tensorflow/comments/d0wbjj/stochastic_vs_batch_vs_minibatch_gradient_descent/,bhavesh91,1567864880,,0,10
31,2019-9-8,2019,9,8,4,d10jrc,How to access at 1 element of a dataset,https://www.reddit.com/r/tensorflow/comments/d10jrc/how_to_access_at_1_element_of_a_dataset/,Ste29ebasta,1567885035,"I'm using tf.data.Dataset to manage my data, but i have some problem using the map function, could you help me pls?

    def load_image(path):
        image = tf.read_file(path)

        image = tf.image.decode_jpeg(image, channels=3)
        image = tf.cast(image, tf.float32) / 255.0  # normalize to [0,1] range
    return image

    path_ds = tf.data.Dataset.from_tensor_slices((all_image_paths, all_image_labels, 
                                                                        all_image_classes))
    image_ds = path_ds.map(load_image, num_parallel_calls=AUTOTUNE) 


in order to make it work i have to write:

    def load_image(path,a,b):

and then ignore a and b, but what i'm asking you is how can i pass to my function just the paths that i have stored in my dataset?",0,1
32,2019-9-8,2019,9,8,5,d11i38,How to access at 1 class of my tf.dataset?,https://www.reddit.com/r/tensorflow/comments/d11i38/how_to_access_at_1_class_of_my_tfdataset/,Ste29ebasta,1567889610,"I'm using tf.data.Dataset to manage my data, but i have some problem using the map function, could you help me pls?

    def load_image(path):
        image = tf.read_file(path)

        image = tf.image.decode_jpeg(image, channels=3)
        image = tf.cast(image, tf.float32) / 255.0  # normalize to [0,1] range
    return image

    path_ds = tf.data.Dataset.from_tensor_slices((all_image_paths, all_image_labels, 
                                                                        all_image_classes))
    image_ds = path_ds.map(load_image, num_parallel_calls=AUTOTUNE) 


in order to make it work i have to write:

    def load_image(path,a,b):

and then ignore a and b, but what i'm asking you is how can i pass to my function just the paths that i have stored in my dataset?",0,1
33,2019-9-8,2019,9,8,9,d13ykz,[AI application] AirGesture - Let's play game without keyboard,https://www.reddit.com/r/tensorflow/comments/d13ykz/ai_application_airgesture_lets_play_game_without/,1991viet,1567902075,,4,67
34,2019-9-8,2019,9,8,21,d1aaqa,XLA:CPU with basic convolutional neural network?,https://www.reddit.com/r/tensorflow/comments/d1aaqa/xlacpu_with_basic_convolutional_neural_network/,skellerone,1567945698,"I made a simple sequential neural network this week which works with 3 basic convolutional layers. It looks a little like the following:

&amp;#x200B;

model = models.Sequential()  
model.add(layers.Conv2D(32, (3, 3), activation='relu', input\_shape=(28, 28, 1)))  
model.add(layers.MaxPooling2D((2, 2)))  
model.add(layers.Conv2D(64, (3, 3), activation='relu'))  
model.add(layers.MaxPooling2D((2, 2)))  
model.add(layers.Conv2D(64, (3, 3), activation='relu'))

model.add(layers.Flatten())  
model.add(layers.Dense(64, activation='relu'))  
model.add(layers.Dense(10, activation='softmax'))

&amp;#x200B;

When I try to run this, my computer mentions XLA:CPU not being activated, which it looks like would make my model run faster with my GPU were I to compile my code beforehand with tf.xla.experimental.compile. However, when I try this, a number of issues come up when I try to fit my model, specifically related to the Conv2D layers. I assume jit\_scope would allow me to specify which values are to be compiled by XLA and which aren't, but how would I use this? Would I need to define the 2D convolution layers myself in order to specify which values can use XLA?",0,2
35,2019-9-9,2019,9,9,16,d1njtv,How to integrate of TensorFlow Model in Angular Application?,https://www.reddit.com/r/tensorflow/comments/d1njtv/how_to_integrate_of_tensorflow_model_in_angular/,RubiksCodeNMZ,1568013390,,0,0
36,2019-9-9,2019,9,9,21,d1qk5a,Neural Network Based Optimal Control in Astrodynamics using TF,https://www.reddit.com/r/tensorflow/comments/d1qk5a/neural_network_based_optimal_control_in/,Gereshes,1568033899,,0,16
37,2019-9-10,2019,9,10,13,d22qee,How to add inference to NN,https://www.reddit.com/r/tensorflow/comments/d22qee/how_to_add_inference_to_nn/,Stanley_C,1568090228," [https://github.com/tensorflow/docs/blob/r1.14/site/en/tutorials/estimators/cnn.ipynb](https://github.com/tensorflow/docs/blob/r1.14/site/en/tutorials/estimators/cnn.ipynb) 

How do I add code that lets me import a 28x28 greyscale image into my trained model with Numpy, and generate a prediction?",3,2
38,2019-9-10,2019,9,10,18,d2541w,How do I persist notebooks in the Jupyter docker container?,https://www.reddit.com/r/tensorflow/comments/d2541w/how_do_i_persist_notebooks_in_the_jupyter_docker/,pragmojo,1568107410,"Hello,

I'm new here, hope I'm posting this in the appropriate place.

I'm trying to get started with the [Jupyter docker image](https://www.tensorflow.org/install/docker):

    tensorflow/tensorflow:latest-py3-jupyter

Everything is working great, but I would like to use the container and store any notebooks I create on my host filesystem.  By default this image comes pre-installed with the official tutorial notebooks, and all changes are lost when stopping/restarting the container.

Does anyone know how to host the notebooks on my own filesystem?  I would assume I need to map a directory somehow with the `--volume` flag.  I've tried `/notebooks` since this is used by s4tf but it doesn't seem to work with the python version.",2,2
39,2019-9-10,2019,9,10,22,d27t05,Important Things to Know About Tensorflow 2.0,https://www.reddit.com/r/tensorflow/comments/d27t05/important_things_to_know_about_tensorflow_20/,atomlib_com,1568123467,,0,3
40,2019-9-11,2019,9,11,0,d291zi,Combining CSV files into one big dataset or tensor,https://www.reddit.com/r/tensorflow/comments/d291zi/combining_csv_files_into_one_big_dataset_or_tensor/,nikosz_boldis,1568128941,"Hi fellow tensorflow users,

I am having all of my features saved as independent CSV files matrices of our customers and their columns. Each of it is in the same dimensions. My task is to combine all of these .csv files into one big dataset or tensor, possibly keep it 3d.(cusomers,groups,features). The features are my .csv files. 

Maybe this is not the best practice I just started with tensorflow but this is how we need our data now.

 I would like to ask you if it is possible and if yes how. Thank you.",7,7
41,2019-9-11,2019,9,11,14,d2l1pc,Update to MNIST inference,https://www.reddit.com/r/tensorflow/comments/d2l1pc/update_to_mnist_inference/,Stanley_C,1568178607,"Hi,

Here is my notebook, it is only slightly modified from the example one:  [https://github.com/itisyeetimetoday/mnist\_predict/blob/master/cnn.ipynb](https://github.com/itisyeetimetoday/mnist_predict/blob/master/cnn.ipynb). I tried to add a section for the model to predict which digit a single image from the dataset is, but I get this:  &lt;generator object Estimator.predict at 0x000002694B54B728&gt;   
 Could someone help me fix my error?",3,1
42,2019-9-12,2019,9,12,2,d2u7an,High-performance TensorFlow library for quantitative finance (0.0.1-dev6 Release),https://www.reddit.com/r/tensorflow/comments/d2u7an/highperformance_tensorflow_library_for/,open_risk,1568224752,,0,10
43,2019-9-12,2019,9,12,11,d3106p,Retraining: Failed to load the native TensorFlow runtime.,https://www.reddit.com/r/tensorflow/comments/d3106p/retraining_failed_to_load_the_native_tensorflow/,wymco,1568253732,"Hi,

I am working on a project to retrain an image classification model; I have been following this tutorial: [https://www.tensorflow.org/hub/tutorials/image\_retraining](https://www.tensorflow.org/hub/tutorials/image_retraining)

However, when I reached the section to run ""python retrain.py --image\_dir \~/flower\_photos"" I ended up with the error below. I am helpless at this point.Any assistance would be appreciated

&amp;#x200B;

`Traceback (most recent call last):`

  `File ""/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in &lt;module&gt;`

`from tensorflow.python.pywrap_tensorflow_internal import *`

  `File ""/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in &lt;module&gt;`

`_pywrap_tensorflow_internal = swig_import_helper()`

  `File ""/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper`

`_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)`

  `File ""/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/imp.py"", line 242, in load_module`

`return load_dynamic(name, filename, file)`

  `File ""/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/imp.py"", line 342, in load_dynamic`

`return _load(spec)`

`ImportError: dlopen(/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: _SecKeyCopyExternalRepresentation`

  `Referenced from: /Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.1.dylib`

  `Expected in: /System/Library/Frameworks/Security.framework/Versions/A/Security`

 `in /Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.1.dylib`

&amp;#x200B;

`During handling of the above exception, another exception occurred:`

&amp;#x200B;

`Traceback (most recent call last):`

  `File ""`[`retrain.py`](https://retrain.py)`"", line 131, in &lt;module&gt;`

`import tensorflow as tf`

  `File ""/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/__init__.py"", line 28, in &lt;module&gt;`

`from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import`

  `File ""/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/__init__.py"", line 49, in &lt;module&gt;`

`from tensorflow.python import pywrap_tensorflow`

  `File ""/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in &lt;module&gt;`

`raise ImportError(msg)`

`ImportError: Traceback (most recent call last):`

  `File ""/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in &lt;module&gt;`

`from tensorflow.python.pywrap_tensorflow_internal import *`

  `File ""/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in &lt;module&gt;`

`_pywrap_tensorflow_internal = swig_import_helper()`

  `File ""/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper`

`_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)`

  `File ""/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/imp.py"", line 242, in load_module`

`return load_dynamic(name, filename, file)`

  `File ""/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/imp.py"", line 342, in load_dynamic`

`return _load(spec)`

`ImportError: dlopen(/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: _SecKeyCopyExternalRepresentation`

  `Referenced from: /Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.1.dylib`

  `Expected in: /System/Library/Frameworks/Security.framework/Versions/A/Security`

 `in /Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.1.dylib`

`Failed to load the native TensorFlow runtime.`

`See` [`https://www.tensorflow.org/install/errors`](https://www.tensorflow.org/install/errors)

`for some common reasons and solutions.  Include the entire stack trace`

`above this error message when asking for help.`",0,1
44,2019-9-13,2019,9,13,3,d3c43x,Introduction of pre-trained models in the field of Computer Vision,https://www.reddit.com/r/tensorflow/comments/d3c43x/introduction_of_pretrained_models_in_the_field_of/,frontnetcoin,1568312776,,0,4
45,2019-9-13,2019,9,13,6,d3exul,Using Tensorflow of non-machine learning data processing tasks,https://www.reddit.com/r/tensorflow/comments/d3exul/using_tensorflow_of_nonmachine_learning_data/,jasonjerksit,1568324453,"I have a highly parallel image processing task that I want to  process as quickly as possible. Basically each column in this 'image' will independently have many operations applied to it e.g. fft, ifft , polynomial fitting... My question is , is tensorflow the right tool for something like this or would writing this in CUDA be more appropriate. It seems to me that tensorflow should be useful for any kind of large data processing pipeline but all examples online involve iterative optimization.",10,8
46,2019-9-13,2019,9,13,7,d3ff06,"Cross post from r/deeplearning, can anyone here help?",https://www.reddit.com/r/tensorflow/comments/d3ff06/cross_post_from_rdeeplearning_can_anyone_here_help/,FullMetalMahnmut,1568326528,,0,1
47,2019-9-13,2019,9,13,13,d3jvj7,Regression with Numpy questions,https://www.reddit.com/r/tensorflow/comments/d3jvj7/regression_with_numpy_questions/,Stanley_C,1568348122,"Hi,

I want to do the regression with the attached files, where nn\_inputs.npy are the inputs and nn\_outputs.npy are the values that I want to be predicted. Could someone point towards a repo or some code that have multiple x-axes for inputs and multiple y-axes for outputs? 

Thank you for your time.

&amp;#x200B;

Files: 

[https://drive.google.com/drive/folders/1-uwB5qH8UyOSxINrNE5UTDSUyRANu9LL?usp=sharing](https://drive.google.com/drive/folders/1-uwB5qH8UyOSxINrNE5UTDSUyRANu9LL?usp=sharing)",3,1
48,2019-9-14,2019,9,14,14,d41d6p,Principal Component Analysis (PCA) from Scratch in Python,https://www.reddit.com/r/tensorflow/comments/d41d6p/principal_component_analysis_pca_from_scratch_in/,bhavesh91,1568440438,,3,11
49,2019-9-15,2019,9,15,8,d4clr6,Converting Single Variable Polynomial DNN Regression to Multivariate Polynomial DNN Regression,https://www.reddit.com/r/tensorflow/comments/d4clr6/converting_single_variable_polynomial_dnn/,Stanley_C,1568502791,"Note: I'm giving credit to Tathagat Dasgupta for the base code that I'm trying to modify

My repo and progress:  [https://github.com/itisyeetimetoday/reggression/blob/master/tensorflow\_reg\_data.py](https://github.com/itisyeetimetoday/reggression/blob/master/tensorflow_reg_data.py) 

I added a section that turns my input and output arrays in 44 separate arrays, x\_0\_train, x\_0\_test, y\_0\_train, y\_0\_test, etc for each of the 22 variables(11 for input and 11 for output). The program uses  tf.estimator.DNNRegressor, which takes a parameter called feature\_columns. However, I'm confused about how to define a feature column with more than 1 variable.

Thank you for your help.",2,2
50,2019-9-15,2019,9,15,17,d4htnd,Tensorflow - Retraining errors with hidden files,https://www.reddit.com/r/tensorflow/comments/d4htnd/tensorflow_retraining_errors_with_hidden_files/,wymco,1568535844,"I  am retraining a tensorflow model to classify images, but this time it  seems there are some hidden files in my folders that breaking the  application. I am wondering how I can skip these files when my  application is running; The original code is from this:

[https://github.com/tensorflow/hub/blob/master/examples/image\_retraining/retrain.py](https://github.com/tensorflow/hub/blob/master/examples/image_retraining/retrain.py)

Is there anything that I can do?

`Traceback (most recent call last):`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1356, in _do_call`

`return fn(*args)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1341, in _run_fn`

`options, feed_dict, fetch_list, target_list, run_metadata)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1429, in _call_tf_sessionrun`

`run_metadata)`

`tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected image (JPEG, PNG, or GIF), got unknown format starting with '\000\005\026\007\000\002\000\000Mac OS X'`

`[[{{node DecodeJpeg}}]]`

`During handling of the above exception, another exception occurred:`

`Traceback (most recent call last):`

`File ""retrain.py"", line 364, in create_bottleneck_file`

`resized_input_tensor, bottleneck_tensor)`

`File ""retrain.py"", line 332, in run_bottleneck_on_image`

`{image_data_tensor: image_data})`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 950, in run`

`run_metadata_ptr)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1173, in _run`

`feed_dict_tensor, options, run_metadata)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1350, in _do_run`

`run_metadata)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1370, in _do_call`

`raise type(e)(node_def, op, message)`

`tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected image (JPEG, PNG, or GIF), got unknown format starting with '\000\005\026\007\000\002\000\000Mac OS X'`

`[[node DecodeJpeg (defined at retrain.py:936) ]]`

`Errors may have originated from an input operation.`

`Input Source operations connected to node DecodeJpeg:`

`DecodeJPGInput (defined at retrain.py:935)`

`Original stack trace for 'DecodeJpeg':`

`File ""retrain.py"", line 1349, in &lt;module&gt;`

`tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/platform/app.py"", line 40, in run`

`_run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/absl/app.py"", line 299, in run`

`_run_main(main, args)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main`

`sys.exit(main(argv))`

`File ""retrain.py"", line 1040, in main`

`jpeg_data_tensor, decoded_image_tensor = add_jpeg_decoding(module_spec)`

`File ""retrain.py"", line 936, in add_jpeg_decoding`

`decoded_image = tf.image.decode_jpeg(jpeg_data, channels=input_depth)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/ops/gen_image_ops.py"", line 1211, in decode_jpeg`

`dct_method=dct_method, name=name)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper`

`op_def=op_def)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func`

`return func(*args, **kwargs)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 3616, in create_op`

`op_def=op_def)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 2005, in __init__`

`self._traceback = tf_stack.extract_stack()`

`During handling of the above exception, another exception occurred:`

`Traceback (most recent call last):`

`File ""retrain.py"", line 1349, in &lt;module&gt;`

`tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/platform/app.py"", line 40, in run`

`_run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/absl/app.py"", line 299, in run`

`_run_main(main, args)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main`

`sys.exit(main(argv))`

`File ""retrain.py"", line 1054, in main`

`bottleneck_tensor, FLAGS.tfhub_module)`

`File ""retrain.py"", line 470, in cache_bottlenecks`

`resized_input_tensor, bottleneck_tensor, module_name)`

`File ""retrain.py"", line 412, in get_or_create_bottleneck`

`bottleneck_tensor)`

`File ""retrain.py"", line 367, in create_bottleneck_file`

`str(e)))`

`RuntimeError: Error during processing file marks/Egba/._eba6.jpg (Expected image (JPEG, PNG, or GIF), got unknown format starting with '\000\005\026\007\000\002\000\000Mac OS X'`

`[[node DecodeJpeg (defined at retrain.py:936) ]]`

`Errors may have originated from an input operation.`

`Input Source operations connected to node DecodeJpeg:`

`DecodeJPGInput (defined at retrain.py:935)`

`Original stack trace for 'DecodeJpeg':`

`File ""retrain.py"", line 1349, in &lt;module&gt;`

`tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/platform/app.py"", line 40, in run`

`_run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/absl/app.py"", line 299, in run`

`_run_main(main, args)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main`

`sys.exit(main(argv))`

`File ""retrain.py"", line 1040, in main`

`jpeg_data_tensor, decoded_image_tensor = add_jpeg_decoding(module_spec)`

`File ""retrain.py"", line 936, in add_jpeg_decoding`

`decoded_image = tf.image.decode_jpeg(jpeg_data, channels=input_depth)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/ops/gen_image_ops.py"", line 1211, in decode_jpeg`

`dct_method=dct_method, name=name)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper`

`op_def=op_def)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func`

`return func(*args, **kwargs)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 3616, in create_op`

`op_def=op_def)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 2005, in __init__`

`self._traceback = tf_stack.extract_stack()`

`)`",0,0
51,2019-9-16,2019,9,16,19,d4yq6z,I probably implemented Glow and RealNVP with Tensorflow 2.0.0rc0 and Tensorflow Probability 0.8.0rc0!,https://www.reddit.com/r/tensorflow/comments/d4yq6z/i_probably_implemented_glow_and_realnvp_with/,MeguruMokke,1568629454,"If you have any advice, please let me know via comment.

[https://github.com/MokkeMeguru/glow-realnvp-tutorial](https://github.com/MokkeMeguru/glow-realnvp-tutorial)

&amp;#x200B;

 example output

https://i.redd.it/8xnlso62nxm31.png",0,8
52,2019-9-16,2019,9,16,23,d518oq,Typical RAM requirement for Deep Q Learning?,https://www.reddit.com/r/tensorflow/comments/d518oq/typical_ram_requirement_for_deep_q_learning/,callahman,1568643265,"I'm new to Reinforcement modeling, so this definitely could be a problem with my model.

After about 10k training steps I'm maxing out my 16gb RAM. I recently built a simple LSTM model that's pretty similar in terms of layer &amp; node count, but it didn't have this memory issue.

Is there something intrinsic to Deep Q that causes this memory consumption? What should 'typical' memory consumption look like?

Thanks!

Ps - Any opinions on what cloud resource too use for data storage/training as an individual?",3,2
53,2019-9-17,2019,9,17,1,d531j5,Loading model trained with the c api,https://www.reddit.com/r/tensorflow/comments/d531j5/loading_model_trained_with_the_c_api/,jregalad-o,1568651152,"Hi, I am going nuts over this and I feel I am running out of options. I hope I can find some help here.  


I am using the C api to train TF models created and exported from python. I can successfully create a model using tf.keras and export it with keras.experimental.export\_saved\_model(). Afterwards I can successfully load the model in my C program and train it given the configuration I used when creating the model.  


Trained model generates a checkpoint file which I can load in my C program to resume training or serve predictions.   


Unfortunately I am unable to reload the trained model in python. Model loads ok with keras.load\_from\_saved\_model(), this loads an untrained model, and when trying to load weights wither via model.load\_weights() or the tf.train.Checkpoint things just don't work.  


A post about this can be found in:  
[https://stackoverflow.com/questions/57944786/load-trained-keras-tensorflow-model-into-python](https://stackoverflow.com/questions/57944786/load-trained-keras-tensorflow-model-into-python)",9,3
54,2019-9-18,2019,9,18,13,d5sw3j,Why is the Linux installation so much larger than Windows?,https://www.reddit.com/r/tensorflow/comments/d5sw3j/why_is_the_linux_installation_so_much_larger_than/,Th3OnlyN00b,1568782662,"I'm not sure what I'm doing wrong, but when I run \`pip install tensorflow -t ./\` (install in local directory) on windows the entire thing is 142 mb. On linux however, it is about 607 mb. Why is there such a large size difference, and is there any way to reduce it?",1,3
55,2019-9-18,2019,9,18,18,d5vhl1,Raise a flag based on an array sequence,https://www.reddit.com/r/tensorflow/comments/d5vhl1/raise_a_flag_based_on_an_array_sequence/,tonystarkco,1568800694,"I have some dynamically generated sequences of integers inside an Array, like: 

\[ 123, 231, 2212, 1234, 121, 12 \]    
\[ 32, 334, 2314, 664, 12, 5667, 3454, 245 \] 

Some of the sequences raise a flag. I want to predict whenever a flag will be raised based on a trained model with continuously stored sequences of the past. 

I am working on NodeJS. 

Can someone advice where do I start?",2,1
56,2019-9-18,2019,9,18,22,d5y44r,Save keras Model with additional MetaGraphDef?,https://www.reddit.com/r/tensorflow/comments/d5y44r/save_keras_model_with_additional_metagraphdef/,jregalad-o,1568814793,"Does anybody know how to export a tf keras model with an additional MetaGraphDef?  


I want to have a MetaGraphDef with tag 'train' in order to train with c\_aip .h",0,1
57,2019-9-19,2019,9,19,1,d60lst,Master the Most Important Deep Learning Frameworks (Tensorflow &amp; Keras) for Python Data Science,https://www.reddit.com/r/tensorflow/comments/d60lst/master_the_most_important_deep_learning/,onsumocom,1568825549,,0,1
58,2019-9-19,2019,9,19,2,d60wq9,"What kind of interview questions I need to prepare for tensorflow? Remembering all API is very tough . Please help me here .I am currently doing a challenge from kaggle using tf , will that suffice or there is sometime more I should focus on.",https://www.reddit.com/r/tensorflow/comments/d60wq9/what_kind_of_interview_questions_i_need_to/,shwetashri,1568826833,,1,0
59,2019-9-19,2019,9,19,2,d61jur,Converting dnn regression to multi variable dnn regression,https://www.reddit.com/r/tensorflow/comments/d61jur/converting_dnn_regression_to_multi_variable_dnn/,Stanley_C,1568829529,"Note: I didn't write the code, here is the code I'm trying to modify this https://gist.github.com/balzer82/b5cac8fb214e0b52efa0ea7b8a058681 and my repository is here.
https://github.com/itisyeetimetoday/reggression

Ive modified the repo to load in all 11 input variables and all 11 output variables in 2 numpy arrays. 
I'm currently trying to convert a singular variable regression to a multi-variable DNN regression. Line 76 in regressor_full.py always returns an error about incompatible shape. I've changed the input to the shape of 11, however, I don't know to change the output layer to 11 too.

Line 76 : feature_columns = [tf.feature_column.numeric_column('X', shape=(11,))]
However, I'm sure that the input and output tensors aren't the only 2 things that have to be changed. Could you guys help me with adapting the repo? Thank you",0,1
60,2019-9-19,2019,9,19,15,d6ac2v,Architecture of TensorFlow,https://www.reddit.com/r/tensorflow/comments/d6ac2v/architecture_of_tensorflow/,nehapandey01,1568876184,,0,4
61,2019-9-20,2019,9,20,12,d6osdh,Learn Machine Learning Zero to Hero!,https://www.reddit.com/r/tensorflow/comments/d6osdh/learn_machine_learning_zero_to_hero/,Rogers911z,1568948560,[https://www.youtube.com/watch?v=yIR\_bMInPGo](https://www.youtube.com/watch?v=yIR_bMInPGo),2,0
62,2019-9-20,2019,9,20,12,d6p5bs,Textgenrnn - Interactive Mode Not Working Properly,https://www.reddit.com/r/tensorflow/comments/d6p5bs/textgenrnn_interactive_mode_not_working_properly/,PoeticGoodKitty,1568950519,"So I'm trying to use textgenrnn's interactive mode using `textgen.generate(interactive=True, top_n=5)` but the options appear as letters instead of words, so I can't use it properly.

    Controls:
    	s: stop.	x: backspace.	o: write your own.
    
    Options:
    	1:  
    	2: t
    	3: s
    	4: a
    	5: i
    
    Progress: 
    
    Your choice?

What am I doing wrong?",0,1
63,2019-9-20,2019,9,20,18,d6s9f2,issue with CORS,https://www.reddit.com/r/tensorflow/comments/d6s9f2/issue_with_cors/,Neofelis_,1568970817,"I've began to learn tensorflow for a week and just implement some model which come from the official website.
My website isn't on a server for now and when I run my page I still have one error in relation with CORS.

What should I do..?
I'm still learning web programming so I have no idea what I have to do

Thank",4,0
64,2019-9-21,2019,9,21,23,d7b4qu,Hands-On Neural Networks with TensorFlow 2.0 - book OUT NOW!,https://www.reddit.com/r/tensorflow/comments/d7b4qu/handson_neural_networks_with_tensorflow_20_book/,pgaleone,1569075898,,4,14
65,2019-9-25,2019,9,25,0,d8p0z8,Which way to proceed for distributed learning under tensorflow?,https://www.reddit.com/r/tensorflow/comments/d8p0z8/which_way_to_proceed_for_distributed_learning/,shahriar49,1569340077," I see a bunch of different methods in many web sites and Tensorflow guides to proceed for implementing a distributed learning example but can not clear my mind on them. Let me be simple and clear: I have model created under keras, have setup the TF\_CONFIG to have a chief, a worker, a ps, and an evaluator server, and I assume that the below code should do the job:

    runConfig = tf.estimator.RunConfig(session_config=config,
                            	   model_dir=log_dir,
                     		   save_summary_steps=1,
                     		   save_checkpoints_steps=train_steps)
    estimator = tf.keras.estimator.model_to_estimator(model, model_dir=log_dir, config=runConfig) 
    train_spec = tf.estimator.TrainSpec(input_fn=lambda: read_datasets(...), max_steps=epochs*train_steps) eval_spec = tf.estimator.EvalSpec(input_fn=lambda: read_datasets(...), steps=None) tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec) 

And then I can see the performance graphs and values on Tensorboard. My understanding from the web resources and discussions I had on forums is that the code for all servers are exactly the same except the TF\_CONFIG part, and just one copy of training data is needed to be placed in a shared folder, and one shared directory is set to save model parameters and checkpoints, and the chief is going to synchronize everything on splitting the data between workers and saving the model and summaries. But I am not sure of this picture. My tests show that the workers need to access dataset otherwise the code returns an error, but if they also read the dataset, how global batch splitting is synchronized?

In addition, I see pages about distribution strategy and its implications on keras and estimators, which make me so much confused. Do I really need all of these strategy stuff, or just above code is sufficient? What about the input\_fn? I assumed that the chief is taking care of data split but in the tensorflow documentation ([https://www.tensorflow.org/guide/distribute\_strategy](https://www.tensorflow.org/guide/distribute_strategy)) it says different things for keras and estimator implementation, and my application is a keras model encapsulated in an estimator! What should I do?",0,1
66,2019-9-25,2019,9,25,1,d8pb79,Combining map and padded_batch in tensorlow,https://www.reddit.com/r/tensorflow/comments/d8pb79/combining_map_and_padded_batch_in_tensorlow/,shahriar49,1569341317, To increase the performance on input pipeline tensorflow documentation recommends using tf.contrib.data.map\_and\_batch instead of separate .map and  .batch functions ([https://www.tensorflow.org/guide/performance/datasets](https://www.tensorflow.org/guide/performance/datasets)). But how to combine .map and .padded\_batch functions in input pipeline?,0,2
67,2019-9-25,2019,9,25,1,d8phxn,Is distributed learning feasible for my application?,https://www.reddit.com/r/tensorflow/comments/d8phxn/is_distributed_learning_feasible_for_my/,shahriar49,1569342120," I am running a LSTM network to classify a huge database of remote sensing sequences to their respective landcovers. Code is developed on Tensorflow/Keras and I am trying models with 3 to 7 layers, each having 16 to 64 LSTM cells. Due to huge data size (around 13.5M sample sequences), I am interested to do my model training in distributed mode by data parallelization over multiple GPUs or multiple PCs. However, my tries by now have not resulted in any improvement over single system version and I am thinking if it is feasible at all or not.

My understanding from data parallelism under Tensorflow/Keras is that there are different workers, a chief, and a parameter server (ps). Model parameters are stored in ps and communicated with workers and chief, and each worker works on a partition of the whole data. Each worker should get the model parameters from ps at the start of each data batch processing, do all the forward and backward propagation and calculate the weight updates and send them back to ps, where the updated model parameters are calculated by chief and stored. Therefore, each worker should read the model parameters before each batch processing.

My simulation batch size is 1024, therefore there are about 13K batches in one epoch of data. Training of a model with 87,000 parameters took 412 seconds in my one-gpu system, which means about 30 ms per batch. A more complex model with 1M parameters took 1900 seconds to process one epoch, which means about 146 ms per batch.

Now that I look at the numbers, I am in doubt if data parallelism is helpful. If two GPUs or CPUs want to communicate 100K or 1M parameters, can it be so fast to be done in a few milliseconds to be negligible? My experiments on a two-GPU system (which even doesn't require data transmission over network) resulted in batch processing time of twice single-GPU. Can it be attributed to the small batch processing time and the data communication overhead on top of that? If it is, does it mean that my model is not as complex as necessary for distributed learning?",2,3
68,2019-9-25,2019,9,25,2,d8qfte,Distributed training on different computer configurations in Tensorflow,https://www.reddit.com/r/tensorflow/comments/d8qfte/distributed_training_on_different_computer/,shahriar49,1569346162,"If I have one PC with 2 RTX 2080 Ti GPU and one PC with 1 GTX 1080 Ti GPU, what is the best approach to use them with maximum utilization for doing a distributed learning of a keras model in tensorflow? I am inclined to encapsulate keras model in an estimator class but then I don't know how to define the above GPU configuration in TF\_CONFIG dictionary.",0,1
69,2019-9-25,2019,9,25,2,d8qox2,RunConfig distribute parameters,https://www.reddit.com/r/tensorflow/comments/d8qox2/runconfig_distribute_parameters/,shahriar49,1569347282,"As train\_distribute and eval\_distribute parameters are optional in tf.estimator.RunConfig, what will happen if we don't specify them? Are they required to run the model properly in distributed configuration?",0,1
70,2019-9-25,2019,9,25,3,d8r2kw,"EstimatorSpec, TrainSpec, EvalSpec, ... what it is for?",https://www.reddit.com/r/tensorflow/comments/d8r2kw/estimatorspec_trainspec_evalspec_what_it_is_for/,shahriar49,1569348909,"My understanding after reading tensorflow guides about estimator class is that it requires a model\_fn that defines what estimator does in each mode of operation, so it is like a function. Then I don't understand the term and meaning and purpose of adding another thing named EstimatorSpec and returning it at the end of model\_fn. If the model\_fn is run by estimator, why do we need this complex notation? Same thing with TrainSpec and EvalSpec: Having input\_fn definition, why we need these things? I think I can not get the real purpose and meaning of these stuff, and the tensorflow documentation is really not helping to grasp the concepts.

Anybody has a simple but precise explanation of these concepts?",3,2
71,2019-9-25,2019,9,25,11,d8x02c,Working with a TFRecord that represents a SparseTensor,https://www.reddit.com/r/tensorflow/comments/d8x02c/working_with_a_tfrecord_that_represents_a/,MLnewbie22,1569377830,"I'm working with a TFRecord where all the feature engineering has already been done for me. The TFRecord has in it a set of records, where each record has `indices`, `values`, and `length` in byte string to represent the original SparseTensor. I'm trying to parse this TFRecord so that I can get it to work with the `tf.estimator.LinearClassifier` object, but I can't seem to get it to work. Here's what I'm working with: 

**TFRecord:** 

    features {
      feature {
        key: ""indices""
        value {
          int64_list {
            value: 0
            ...
            value: 117
          }
        }
      }
      feature {
        key: ""length""
        value {
          int64_list {
            value: 131
          }
        }
      }
      feature {
        key: ""values""
        value {
          float_list {
            value: 0.0
            ...
            value: 1.0
          }
        }
      }
    }

This is a little weird because the non-zero features themselves which are the indices are being saved as a single feature. This is confusing me quite a bit!! 

**The inputs:**

    # inputs 
    tf_record = 'file.tfrecords'
    feature_names = ['feature1', 'feature2', 'feature3', ..., 'feature130'] 

**My TFRecord parser function:** 

    # TFRecord parser function
    def parse_function(example_proto):
    
        # create a dict of the description of the features
        sparse_feature_description = {'sparse': tf.SparseFeature(
                        index_key=['indices'],
                        value_key='values',
                        dtype=tf.float32,
                        size=[num_features])
            
        }
        # parse the input tf.Example proto using the dictionary above
        all_features = tf.parse_single_example(example_proto, sparse_feature_description)['sparse']
        features = tf.sparse.slice(all_features, [1], [num_features])
        label = tf.sparse.to_dense(tf.sparse.slice(all_features, [0],[1]))
    
        return features, label

This returns a Dataset with records of features and labels... not sure if this is correct. 

**My input function:** 

    def input_fn(tf_record):
        return tf.data.TFRecordDataset(filenames = tf_record).map(parse_function)

**Feature Columns:**

    feature_columns = [tf.feature_column.numeric_column(k) for k in feature_names[1:]]

**Model:**

    classifier = tf.estimator.LinearClassifier(
        feature_columns=feature_columns)
    classifier.train(
        input_fn = lambda: input_fn2(train_file2))

But I get an error: 

    ValueError: features should be a dictionary of `Tensor`s. Given type: &lt;class 'tensorflow.python.framework.sparse_tensor.SparseTensor'&gt;

And I'm not sure what this refers to and unfortunately, this is my first time trying to use TensorFlow. 

**My main questions:** 

* Is this the correct workflow when dealing with a TFRecord that is saved as a SparseTensor? 
   * If not, is there a better way to deal with TFRecords saved as SparseTensors? 
* What is the `ValueError` reffering to?",3,4
72,2019-9-26,2019,9,26,7,d9ac46,help with implementing custom loss on the integral of outputs (tensorflow / keras),https://www.reddit.com/r/tensorflow/comments/d9ac46/help_with_implementing_custom_loss_on_the/,progmayo,1569449237,"Hi guys! I'd really appreciate help in a problem I ran into.

**The goal**

I want to implement a custom loss in keras which is an integral on the outputs.Using the notations of keras, custom loss functions are of the form

    def custom_loss(y_true, y_pred):

Where y\_true are the labels and y\_pred are the models' predictions. I also have the inputs X at hand (using a wrapper function around the custom\_loss). This input is of the same shape as the labels / predictions.Using these notations, the loss I wish to impose looks something along the lines of:

&amp;#x200B;

https://i.redd.it/9dj3gotn1so31.png

Where f(x) is some function that's irrelevant to this discussion. Note that y\_true are irrelevant to the loss function (and that's ok. I have multiple loss functions, don't worry ;) )

Now x and y\_pred are simply arrays of 1XL for some length L.

For those familiar with scipy.integrate, this integral very easily calculated using the trapz function:

    trapz(y_pred*f(X), X)

&amp;#x200B;

**The problem /technical difficulty**

I'll describe the attempts I've made thus far, and the errors I faced in their implementation:

1. Used tensorflow.py\_function to wrap scipy.integrate.trapzThis returned an error where keras did not know how to calculate the derivative. I'm guessing keras precompiles derivative functions to use in the SGD optimizer?
2. Copied a function I found that implements trapz using keras / tf functions:

&amp;#x200B;

    def trapezoidal_integral_approx(t, y):
        return math_ops.reduce_sum(
                math_ops.multiply(t[1:] - t[:-1],
                                  (y[1:] + y[:-1]) / 2.), 
                name='trapezoidal_integral_approx')

This returned some weird error that I didn't understand:

&gt;tensorflow.python.framework.errors\_impl.InvalidArgumentError: Can not squeeze dim\[0\], expected a dimension of 1, got 1401  
&gt;  
&gt;\[\[{{node loss\_3/encoder\_output\_loss/weighted\_loss/Squeeze}}\]\]

&amp;#x200B;

3. Using tf.contrib.integrate.odeint: [https://www.tensorflow.org/api\_docs/python/tf/contrib/integrate/odeint](https://www.tensorflow.org/api_docs/python/tf/contrib/integrate/odeint)This function just seems unintuitive and not suited for my needs (not trapz). I did not fully try to implement this method, and if someone suggests it, I can give it a try, but it does not accept two arrays as I need it to.

&amp;#x200B;

**Bottom line**

I'd appreciate help in my particular problem,  or a link to some code / example that attempts something similar (loss function that is comprised of an integral on y\_true or y\_pred or something along those lines).

&amp;#x200B;

# Thank you very very much in advance to anyone willing to help :)",3,1
73,2019-9-26,2019,9,26,10,d9d2ze,Get the size of the intersection between 2 sets (custom loss function),https://www.reddit.com/r/tensorflow/comments/d9d2ze/get_the_size_of_the_intersection_between_2_sets/,thezaza101,1569463084,"I'm trying to implement a custom loss function for a image  segmentation model. I'm having trouble figuring out how to get the size  of the intersection between 2 sets.

The code i have so far is :

    def SSCLoss(y_true, y_pred):
   y_true = K.flatten(y_true)
   y_pred = K.flatten(y_pred)
   yTestUn, idx = tf.unique(y_true)
   yPredUn, idx = tf.unique(y_pred)
   maxLen = tf.math.maximum(tf.size(yTestUn), tf.size(yPredUn))
   numEqual = tf.size(tf.sets.set_intersection(tf.dtypes.cast(yTestUn,tf.uint16), tf.dtypes.cast(yPredUn,tf.uint16)))
 return tf.math.subtract(tf.constant(1), tf.math.divide(numEqual, maxLen))

I keep getting the error  `ValueError: Shape must be at least rank 2 but is rank 1 for 'loss/activation_1_loss/DenseToDenseSetOperation' (op: 'DenseToDenseSetOperation') with input shapes: [?], [?].` 

Any idea whats going on here?

 The non-TensorFlow implementation of this function is: 

    def SSC(y_true, y_pred):
 if (y_true.ndim &gt; 1):
      y_true = np.array(y_true).ravel()
 if (y_pred.ndim &gt; 1):
      y_pred = np.array(y_pred).ravel()

      yTestUn = pd.Series(y_true).unique()
   yPredUn = pd.Series(y_pred).unique()
   maxLen = float(max(len(yTestUn), len(yPredUn)))
   numEqual = float(len(set(list(yTestUn)) - (set(list(yTestUn)) - set(list(yPredUn)))))
 return 1 - float(numEqual / maxLen)

formula is:

&amp;#x200B;

![gif](fts03jqzhuo31)",0,2
74,2019-9-26,2019,9,26,13,d9et7o,where can I find exmples of Tensorflow on Raspberry pi,https://www.reddit.com/r/tensorflow/comments/d9et7o/where_can_i_find_exmples_of_tensorflow_on/,vaibhavkumar049,1569472729,"Once surfing through net I stumbled upon a repo on github where there were examples of tensorflow on raspberry pi but now I am not able to find it. Mind it, it was official repo.  Can anyone post the link here",0,6
75,2019-9-26,2019,9,26,22,d9jdt1,GPU server for feedback!,https://www.reddit.com/r/tensorflow/comments/d9jdt1/gpu_server_for_feedback/,skazakov,1569503160," Greetings everyone,  


My name is Sergey, I'm from Hostkey ([hostkey.com](http://hostkey.com/)).   
We are looking for a way to improve our services for Tensorflow users and make their lives a bit easier. We started deploying GPU servers with Tensorflow pre-installed, but we are sure that we can do more.   
We would like to offer one of our servers for one Tensorflow user as a free-of-charge test, this certain someone can use this GPU server to train its models or another AI/ML purposes. However, there is one condition: after the test is over, we would like to receive detailed feedback of our services - what did you like about it, what's our flaws, what else can we do to help users from Tensorflow community, etc...  
If you would like to participate, kindly send a short description of your project and technical requirements to [dasafyev@hostkey.com](mailto:dasafyev@hostkey.com) , we will choose one lucky person and contact him via email. 

Thank you",1,0
76,2019-9-26,2019,9,26,23,d9kj10,Converting Tensorflow Model into Keras Model,https://www.reddit.com/r/tensorflow/comments/d9kj10/converting_tensorflow_model_into_keras_model/,UysofSpades,1569508737,"Hello. I am trying to convert some open source code that was written in the TensorFlow API into Keras API. I am getting the correct input and output shapes for each layer, however, it complains when I try to do a test on the model itself. Please excuse the code, I simplified a lot for brevity.

&amp;#x200B;

Here is the tensorflow API:
```python
        hidden_units_g = 100
        num_generated_features = 1
        seq_length = 30
        batch_size = 28
        latent_dim = 5

        W_out_G = tf.get_variable(name='W_out_G', shape=[hidden_units_g, num_generated_features], initializer=W_out_G_initializer)
        b_out_G = tf.get_variable(name='b_out_G', shape=num_generated_features, initializer=b_out_G_initializer)
        
        # shape: (28, 30, 5)
        inputs = tf.random_normal(shape=(batch_size, seq_length, latent_dim))

        cell = LSTMCell(num_units=hidden_units_g,
                           state_is_tuple=True,
                           initializer=lstm_initializer,
                           bias_start=bias_start,
                           reuse=reuse)

        # rnn_output shape: (28, 30, 100)
        rnn_outputs, rnn_states = tf.nn.dynamic_rnn(
            cell=cell,
            dtype=tf.float32,
            sequence_length=[seq_length]*batch_size,
            inputs=inputs)

        # reshape shape: (840, 100)
        rnn_outputs_2d = tf.reshape(rnn_outputs, [-1, hidden_units_g])

        # shape: ( 840, 1)
        logits_2d = tf.matmul(rnn_outputs_2d, W_out_G) + b_out_G

        # shape: (840, 1)
        output_2d = tf.nn.tanh(logits_2d)

        # shape: (28, 30, 1)
        output_3d = tf.reshape(output_2d, [-1, seq_length, num_generated_features])

```

Here is my attempt to recreate this in Keras:

```python
gen = tf.keras.models.Sequential([
    tf.keras.layers.LSTM(100, input_shape=(30, 5), return_sequences=False),
    #tf.keras.layers.Dense(1, activation='tanh'),
    tf.keras.layers.Dense(1, activation='tanh'),
    tf.keras.layers.Reshape(target_shape=(30, 1))
])
Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 100)               42400     
_________________________________________________________________
dense (Dense)                (None, 1)                 101       
_________________________________________________________________
reshape (Reshape)            (None, 30, 1)             0         
=================================================================
Total params: 42,501
Trainable params: 42,501
Non-trainable params: 0
```

Also applying `tf.keras.utils.plot_model()` confirms that my input/output shapes are exactly the same. However when I try to do a mock test using: `np.random.randn(28, 30, 5)` I get an error saying that it fails to reshape the output of dense, it expects 840 values, but only saw 28. 

Is there a way to print out the actual batch shapes as it moves through the model in keras?

Thank you",4,4
77,2019-9-27,2019,9,27,2,d9mytj,How to perform im2col in tensorflow2?,https://www.reddit.com/r/tensorflow/comments/d9mytj/how_to_perform_im2col_in_tensorflow2/,ashish421,1569519378,I want to implement convolution as a matrix multiplication separately. Is there any way to perform im2col in tensorflow 2?,1,0
78,2019-9-27,2019,9,27,21,d9zlsa,Issue with training multilabel image classifier,https://www.reddit.com/r/tensorflow/comments/d9zlsa/issue_with_training_multilabel_image_classifier/,ski233,1569586847,"I followed this tutorial: [https://medium.com/@vijayabhaskar96/multi-label-image-classification-tutorial-with-keras-imagedatagenerator-cd541f8eaf24](https://medium.com/@vijayabhaskar96/multi-label-image-classification-tutorial-with-keras-imagedatagenerator-cd541f8eaf24)

and wrote some of my code for multilabel classification. I had it working with one-hot encoding on a small scale but I had to move to option 2 mentioned in the article because I have 6000 classes and therefore one hot was not viable. I managed to train the network and it said 99% accuracy and 83% f1 score. However, when I'm trying to test the network, for every image it's outputting some combination of only 3 labels when there are 6000 possible labels. I wondered if maybe the code to test the model was incorrect. I tried using the code mentioned in the post and it doesn't work:

test\_generator.reset()

pred = model.predict\_generator(test\_generator, steps=STEP\_SIZE\_TEST, verbose=1);

pred\_bool = (pred &gt; 0.5)

&amp;#x200B;

 Regardless of this code, I have some code that is getting the output, but it's still the same issue with only outputting a couple labels. Does anyone have an idea as to why this might be happening and how to fix it.",10,12
79,2019-9-28,2019,9,28,1,da2xt0,How do I add additional x variables to a windowed tensorflow.data.dataset without windowing these additional x variables?,https://www.reddit.com/r/tensorflow/comments/da2xt0/how_do_i_add_additional_x_variables_to_a_windowed/,slingshoota,1569602135,"I'm currently working with time series data using tensorflow.data.dataset.

After I use the window function on the dataset, I would like to add additional data points beyond the window size.

This is because if I have data with a frequency of one minute (for example), and the window size is a few hundred minutes (a few hours), I would still like to consider data from a week, a few weeks, a few months and perhaps even years ago. Obviously increasing the window size to span a few years is out of the question when dealing with minute frequency data.

Currently, I have the lagged data (from a few weeks and months beyond the window) included in each row of the data frame before turning it into a tensorflow dataset, so it is already being considered. The issue is that if I have windowed data with 100 minutes of data per window, I also have 100 data points from (for example) two weeks ago per sample, even though I only want one. This is redundant data and computationally expensive.

I start with a dataframe and turn this into a tensorflow dataset. Of course the y variables in the dataframe are not windowed, and I would like to set it up so that a few of the x variables of my choice are not windowed either, but taken as x variables along with the windowed data.

I hope this conveys what I'm trying to do and that some of you tensorflow ninjas out there can help me out. I'm more than happy to clarify anything from my side. Thanks for your attention either way!

  
`variables = (tf.constant(dataframe[dataframe.columns.values[:-p['LabelCount']]].values), tf.constant(dataframe[dataframe.columns.values[-p['LabelCount']:]].values))`  
`tensor = tf.data.Dataset.from_tensor_slices(variables)`  
`tensor = tensor.window(p['hindsight'],1,1,True)`  
`tensor = tensor.flat_map(lambda x,y: tf.data.Dataset.zip((x.batch(p['hindsight']), y)))`",0,1
80,2019-9-28,2019,9,28,3,da4p23,TensorBoard 1.14.0 not updating Scalars after launching,https://www.reddit.com/r/tensorflow/comments/da4p23/tensorboard_1140_not_updating_scalars_after/,times_of_change,1569609962,I'm doing hyperparameter tuning with TensorFlow keras on Windows (no GPU) and my TensorBoard refreshes but doesn't update the graph with new values as they come in once I launch the TensorBoard session. Anyone knows what is happening and what I need to do?,3,3
81,2019-9-28,2019,9,28,9,da90og,Interfacing with the model creates an error.,https://www.reddit.com/r/tensorflow/comments/da90og/interfacing_with_the_model_creates_an_error/,Stanley_C,1569630715,"Hi,

When I run my code I get this error:  nvalidArgumentError (see above for traceback): Input to reshape is a tensor with 11 values, but the requested shape has 121  
    \[\[node dnn/input\_from\_feature\_columns/input\_layer/X/Reshape (defined at regressor\_full.py:177) \]\]  


During handling of the above exception, another exception occurred:  


Traceback (most recent call last):  
 File ""regressor\_full.py"", line 206, in &lt;module&gt;  
  a = np.array(0,0,0,0,0,0,0,0,0,0,0)  
ValueError: only 2 non-keyword arguments accepted.

I'm trying to interface with the model, however, I get that the request shape is even though the model with trained with 11 input and 11 output neurons. 

My repo:  [https://github.com/itisyeetimetoday/reggression](https://github.com/itisyeetimetoday/reggression)",0,1
82,2019-9-29,2019,9,29,0,dahdth,How can I trust you?,https://www.reddit.com/r/tensorflow/comments/dahdth/how_can_i_trust_you/,afagarap,1569684283,"Hello, everyone! I have just published a new article focusing on an intuitive (hopefully) explanation of trust score for model predictions.

&amp;#x200B;

Here is a friendly link to the article. Happy reading!

[https://towardsdatascience.com/how-can-i-trust-you-fb433a06256c?source=friends\_link&amp;sk=0af208dc53be2a326d2407577184686b](https://towardsdatascience.com/how-can-i-trust-you-fb433a06256c?source=friends_link&amp;sk=0af208dc53be2a326d2407577184686b)",2,12
83,2019-9-29,2019,9,29,5,dallh2,Tensorflow lite on android newbie questions,https://www.reddit.com/r/tensorflow/comments/dallh2/tensorflow_lite_on_android_newbie_questions/,Abdalnassir,1569703425,"I am new to tensorflow and I have some questions that I could not find an answer for using google so I am hoping the good people here can answer them for me (All regarding tensorflow lite):

1. For image labeling, how many label can tensorflow lite handle on android device?
2. What is the preferred or optimal tflite model size?
3. How many images to use per label for training the model?
4. What course (preferably on udemy) do you suggest to learn more about using tflite for image labeling?",0,1
84,2019-9-29,2019,9,29,13,daqjs4,Question regarding training model using Jupyter/Google Colab,https://www.reddit.com/r/tensorflow/comments/daqjs4/question_regarding_training_model_using/,MrMegaGamerz,1569730899,"I'm actually using Google Colab (which I read is the same as Jupyter), because of the built-in Tensorflow/Keras. 

[I'm trying to recreate this GitHub project](https://github.com/gentaiscool/lstm-attention) and I have a few questions. I've never used Colab or Juypter and I'm wondering:

1) How to deal with multiple files. I need to run the main file, but what do I do with the other .py files? Do I need to have it open in the notepad or can I simply have then uploaded in the same folder? 

2) I'm getting an error when I run the main file which says: 

    ipykernel_launcher.py: error: no such option: -f
    An exception has occurred, use %tb to see the full traceback.

    SystemExit: 2

Does anyone know what that is/how to fix it? 


I'm new to AI training and Google Colab in general so any help is appreciated.",2,1
85,2019-9-29,2019,9,29,13,daqs3a,Creating a hybrid tensor?,https://www.reddit.com/r/tensorflow/comments/daqs3a/creating_a_hybrid_tensor/,[deleted],1569732449,[deleted],0,1
86,2019-9-29,2019,9,29,13,daqvc1,Creating hybrid sparse tensors,https://www.reddit.com/r/tensorflow/comments/daqvc1/creating_hybrid_sparse_tensors/,EthanPhan,1569733079,"I'm porting a model from pytorch to tensorflow. Pytorch has type of tensor called hybrid sparse which mean only the first few dimensions are sparse, the last dimensions can be dense. Is there any thing like that in tensorflow? I've checked tf.sparse.SparseTensor api and it doesn't support hybrid tensor. How can i get around this?",0,1
87,2019-9-29,2019,9,29,17,dasjas,"Teaching ML, should I upgrade from TF 1.13 to TF 2.0?",https://www.reddit.com/r/tensorflow/comments/dasjas/teaching_ml_should_i_upgrade_from_tf_113_to_tf_20/,bwllc,1569745649,"Over the summer I taught a Deep Learning course using TensorFlow 1.13.  I had the students using mostly the Keras API.  There was no official textbook for the course.  However, I referred the students to [Hands-On Machine Learning with Scikit-Learn and TensorFlow](http://shop.oreilly.com/product/0636920052289.do), and I was confident that what they might read there would allow them to produce code that worked with the software stack that I had them install.

I am scheduled to teach the course again next spring.  I am debating whether to switch over to the TF 2.x branch and I would like to solicit the opinions of people here.  My thoughts are as follows so far.

Pro: students will learn the latest API.

Con: I don't know the latest API yet myself, or how much has changed.  Finding working example code could be harder because TF 2.0 is new.

Ambivalent: I've read that in TF 2.0, eager execution is the default.  I know that some student of mine will press Enter, start evaluating a large data set, and perhaps (if there is no terminal feedback) think that the system has hanged.  I might even do that myself.

 Please feel free to influence my thoughts on any of this.  Thanks!",10,8
88,2019-9-30,2019,9,30,7,db1zfj,Issue with multilabel image classification when using specific dataset,https://www.reddit.com/r/tensorflow/comments/db1zfj/issue_with_multilabel_image_classification_when/,ski233,1569794572,"I'm having an issue where with one specific dataset, my training for multilabel image classification is returning \[class1 and or class2 and or class 3\] (only 3 classes for every image) when there are 13 possible classes. I originally had 6000 classes and lowered the number of classes to see if that was the issue and apparently it was not. Also, I know it is not an issue with the model because I used the exact same code to train a model with a different dataset in the exact same form in the csv file and it worked with 20 classes. My only clue to the difference between the 2 datasets is that in the one where it fails, it gets this warning message: ""Palette images with Transparency expressed in bytes should be converted to RGBA images"". So I started wondering if this is the issue and went into the dataset that works and all the images were pngs and i had scaled them down to 300x300 using PIL so in the dataset that doesnt work I did both of these things and I'm still getting this warning message and its not working. I couldn't find much about this warning message online in the context of keras. The warning occurs inside of the fit\_generator function so it's not in my code. I'm not entirely sure this warning is whats causing my bad output but I suspect it might be so if anybody knows how to fix this, please let me know",6,1
89,2019-9-30,2019,9,30,13,db699s,"Text extraction, use image or text for training",https://www.reddit.com/r/tensorflow/comments/db699s/text_extraction_use_image_or_text_for_training/,burton6666,1569816781,I want to try to extract text from scanned images of invoices. I was thinking that I would first use tesseract or similar software to extract the text and then use the text-files to train a model using tensorflow. But I started thinking about if it is possible to do all steps directly in tensorflow?,3,3
90,2019-9-30,2019,9,30,21,dbashp,TensorFlow for Deep Learning: From Linear Regression to Reinforcement Learning is 31% off,https://www.reddit.com/r/tensorflow/comments/dbashp/tensorflow_for_deep_learning_from_linear/,Krourstage,1569846389,,2,9
91,2019-9-30,2019,9,30,23,dbc30i,5 Important Changes Coming with TensorFlow 2.0,https://www.reddit.com/r/tensorflow/comments/dbc30i/5_important_changes_coming_with_tensorflow_20/,CodeTutorials,1569852519,,0,5
0,2019-10-1,2019,10,1,14,dbonxr,[CFP] Got expertise to share with the Data Science and AI community in India?,https://www.reddit.com/r/tensorflow/comments/dbonxr/cfp_got_expertise_to_share_with_the_data_science/,yourdigitalvoice,1569907641,"[ODSC India](https://india.odsc.com) are looking for speakers for their 2020 conference in Bengaluru, India. If you've got an innovative application of TensorFlow or cutting edge insights into data science or AI, you should check it out. It's a great way to engage with the community and share your knowledge! **Proposal submissions close on October 9:** [https://confng.in/ySfDg6gX](https://confng.in/ySfDg6gX)

Conference Focus Areas:

* AI for Engineers
* Open Data Science
* Data Visualization
* Machine Learning &amp; Deep Learning
* Data Science at Scale
* Data Science Kick Start
* Math Behind AI
* AI for Good
* Data Management
* DataOps

Conference dates: 16-19 September, 2020",0,1
1,2019-10-1,2019,10,1,23,dbucf7,Tensorflow installation problems,https://www.reddit.com/r/tensorflow/comments/dbucf7/tensorflow_installation_problems/,porssimies,1569940862,"I this is not a correct place to ask for the support then please tell me what is.

\---

I am following the installation instructions found at [https://www.tensorflow.org/install](https://www.tensorflow.org/install)

I have removed all the earlier Python versions and installed the latest Python into my machine.

I am getting a ""Fatal Python error: initsite: Failed to import the site module"" while trying to install the latest version of Tensorflow into my Windows 10 machine (see below).

So what is the f problem ?

    C:\Trading\devel\tests\python\tf&gt;python --version
    Python 3.7.4
    
    C:\Trading\devel\tests\python\tf&gt;pip3 --version
    pip 19.2.3 from c:\users\kyttj\appdata\local\programs\python\python37\lib\sit
    e-packages\pip (python 3.7)
    
    C:\Trading\devel\tests\python\tf&gt;virtualenv --version
    16.7.5
    
    C:\Trading\devel\tests\python\tf&gt;virtualenv --system-site-packages -p python ./v
    env
    Running virtualenv with interpreter C:\Users\Kyttj\AppData\Local\Programs\Pyt
    hon\Python37\python.exe
    Already using interpreter C:\Users\Kyttj\AppData\Local\Programs\Python\Python
    37\python.exe
    Using base prefix 'C:\\Users\\Kyttj\\AppData\\Local\\Programs\\Python\\Python
    37'
    New python executable in C:\Trading\devel\tests\python\tf\venv\Scripts\python.ex
    e
    Fatal Python error: initsite: Failed to import the site module
    Traceback (most recent call last):
      File ""C:\Trading\devel\tests\python\tf\venv\lib\site.py"", line 769, in &lt;module
    &gt;
        main()
      File ""C:\Trading\devel\tests\python\tf\venv\lib\site.py"", line 747, in main
        paths_in_sys = addusersitepackages(paths_in_sys)
      File ""C:\Trading\devel\tests\python\tf\venv\lib\site.py"", line 345, in adduser
    sitepackages
        addsitedir(USER_SITE, known_paths)
      File ""C:\Trading\devel\tests\python\tf\venv\lib\site.py"", line 202, in addsite
    dir
        addpackage(sitedir, name, known_paths)
      File ""C:\Trading\devel\tests\python\tf\venv\lib\site.py"", line 170, in addpack
    age
        exec(line)
      File ""&lt;string&gt;"", line 1, in &lt;module&gt;
      File ""C:\Trading\devel\tests\python\tf\venv\lib\importlib\util.py"", line 14, i
    n &lt;module&gt;
        from contextlib import contextmanager
    ModuleNotFoundError: No module named 'contextlib'
    ERROR: The executable C:\Trading\devel\tests\python\tf\venv\Scripts\python.exe i
    s not functioning
    ERROR: It thinks sys.prefix is 'c:\\trading\\devel\\tests\\python\\tf' (should b
    e 'c:\\trading\\devel\\tests\\python\\tf\\venv')
    ERROR: virtualenv is not compatible with this system or executable
    Note: some Windows users have reported this error when they installed Python for
     ""Only this user"" or have multiple versions of Python installed. Copying the app
    ropriate PythonXX.dll to the virtualenv Scripts/ directory may fix this problem.
    
    
    C:\Trading\devel\tests\python\tf&gt;",0,1
2,2019-10-2,2019,10,2,9,dc2dx3,Tensorflow implementation for Dynamic Time Warping,https://www.reddit.com/r/tensorflow/comments/dc2dx3/tensorflow_implementation_for_dynamic_time_warping/,psyyduck,1569975068,"I've rewritten this Dynamic Time Warping [implementation](https://github.com/wannesm/dtaidistance/blob/master/dtaidistance/dtw.py) from normal python into Tensorflow. But it's really slow -- much slower than pre-computing distances and loading them into Tensorflow as data. I can't figure out why it's slow or how to improve it. 

I have also tried converting other DTW implementations with autograph, with no success. Any suggestions?


```
def tfDTW(s1, s2):
  r = tf.cast(tf.shape(s1)[0], tf.int32)
  c = tf.cast(tf.shape(s2)[0], tf.int32)
  window = tf.math.reduce_max([r,c])
  max_step = max_dist = 1e7
  penalty = psi = tf.constant(0, dtype=tf.float64)
  length =  tf.math.reduce_min([c + 1, tf.math.abs(r - c) + 2 * (window - 1) + 1 + 1 + 1])
  indices = [0,-1]
  dtw = tf.one_hot(indices, depth = length,
             on_value=0.0, off_value=1e7,
             axis=-1)  # output: [2,length]
  dtw=tf.cast(dtw, tf.float64)
  last_under_max_dist = tf.constant(0)
  skip = tf.constant(0)
  i0 = tf.constant(1)
  i1 = tf.constant(0)
  psi_shortest = 1e7
  #
  #
  def condition1(i, r, dtw, i0, i1, skip, last_under_max_dist):
    return tf.less(i, r)
  def body1(i, r, dtw, i0, i1, skip, last_under_max_dist):
    #
    #
    prev_last_under_max_dist = tf.cond(tf.equal(last_under_max_dist, -1), lambda: tf.cast(tf.constant(1e7), tf.int32), lambda: last_under_max_dist)
    last_under_max_dist = tf.constant(-1)
    skipp = skip
    skip = tf.reduce_max([0, i - tf.reduce_max([0, r - c]) - window + 1])
    i0 = 1 - i0
    i1 = 1 - i1
    dtw = tf.cond(tf.equal(i1, 0), lambda: tf.concat([tf.fill([1, length], tf.constant(1e7, dtype=tf.float64)), [dtw[1]]], 0), lambda: tf.concat([[dtw[0]], tf.fill([1, length], tf.constant(1e7, dtype=tf.float64))], 0) ) #dtw[i1, :] = np.inf
    j_start = tf.reduce_max([0, i - tf.reduce_max([0, r - c]) - window + 1])
    j_end = tf.reduce_min([c, i + tf.reduce_max([0, c - r]) + window])
    skip = tf.constant(0) #tf.cond(tf.equal(dtw.get_shape()[1], c+1), lambda: 0, lambda: skip )
    #if psi != 0 and j_start == 0 and i &lt; psi:            dtw[i1, 0] = 0 #psi always ==0    
    def condition2(j, dtw, j_start, j_end, last_under_max_dist, prev_last_under_max_dist, skip, skipp):
      return tf.math.logical_and(tf.greater(j, j_start-1), tf.less(j,j_end))    
    def body2(j, dtw, j_start, j_end, last_under_max_dist, prev_last_under_max_dist, skip, skipp):
      d = (tf.gather(s1, i) - tf.gather(s2, j))*(tf.gather(s1, i) - tf.gather(s2, j))
      d = tf.cast(d, tf.float64)
      minval = tf.cast(tf.math.reduce_min([dtw[i0, j - skipp],
                                           dtw[i0, j + 1 - skipp] + penalty,
                                           dtw[i1, j - skip] + penalty]), tf.float64)
      indices = tf.cond(tf.equal(i1, 0), lambda: tf.stack([j + 1 - skip, -1] ), lambda: tf.stack([-1, j + 1 - skip]) )
      minusdtw = tf.one_hot(indices, depth = length,
                            on_value=-1*dtw[i1, j + 1 - skip], off_value=tf.constant(0.0, dtype=tf.float64),
                            axis=-1)     # output: [2,length]
      replacement = tf.one_hot(indices, depth = length,
                               on_value=tf.reduce_min([d + minval, 1e7]), off_value=tf.constant(0.0, dtype=tf.float64),
                               axis=-1)  # output: [2,length]
      dtw = dtw + minusdtw + replacement
      last_under_max_dist = j
      return tf.add(j, 1), dtw, j_start, j_end, last_under_max_dist, prev_last_under_max_dist, skip, skipp    
    #
    b = tf.while_loop(condition2, body2, [j_start, dtw, j_start, j_end, last_under_max_dist, prev_last_under_max_dist, skip, skipp ],
                      [j_start.get_shape(), tf.TensorShape((2,None)), j_start.get_shape(), j_end.get_shape(), last_under_max_dist.get_shape(), prev_last_under_max_dist.get_shape(), skip.get_shape(), skipp.get_shape() ])
    return tf.add(i, 1), r, b[1], i0, i1, skip, b[4]
  #
  a = tf.while_loop(condition1, body1, [tf.constant(0), r, dtw, i0, i1, skip, tf.constant(0) ],
                    [tf.constant(0).get_shape(), r.get_shape(), tf.TensorShape((None,None)), i0.get_shape(), i1.get_shape(), skip.get_shape(), tf.constant(0).get_shape() ])
  maindtw = a[2]
  d = tf.math.sqrt(maindtw [a[4]][ tf.reduce_min([c, c + window - 1]) - skip])
  return d


import tensorflow as tf
import tensorflow_probability as tfp
import numpy as np
tfd = tfp.distributions

graph = tf.Graph()
sess = tf.InteractiveSession()

s1 = tf.constant([10, 0, 1, 2, 1, 0, 1, 0, 0,14,22])
s2 = tf.constant([10, 1, 2, 0, 0, 0, 0])
tfDTW(s1, s2).eval() #26.13426869074396
```",6,7
3,2019-10-2,2019,10,2,10,dc2zxo,Issue with TF Gradient Boosting Trees Local Interoperability,https://www.reddit.com/r/tensorflow/comments/dc2zxo/issue_with_tf_gradient_boosting_trees_local/,MistBornDragon,1569978061,"In reference to https://www.tensorflow.org/tutorials/estimator/boosted_trees_model_understanding[Gradient Boosted Trees Model Link](https://www.tensorflow.org/tutorials/estimator/boosted_trees_model_understanding). I found that when I try to replicate the local interoperability; I can do everything but...  the DFC Pandas dataframe will show the index numbers and not the features.  

Anyone know how to remediate this?",0,1
4,2019-10-2,2019,10,2,10,dc3hyn,How hard to transition from keras to tensorflow?,https://www.reddit.com/r/tensorflow/comments/dc3hyn/how_hard_to_transition_from_keras_to_tensorflow/,rtkaratekid,1569980507,"I'm considering this because the changes to XLA compiled GPU work is really cool, but the keras wrapper has made it a nightmare for me. I've got a four-gpu rig at work for our POC and while tensorflow can detect and run these four XLA\_GPUs, keras seems to not be able to despite all the stackoverflow and github reports I've perused. This is almost my way of throwing in the towel, and I reeeeeally don't want to have to start considering pytorch...

I'm running Tensorflow 2.0, cuda 10.1, cudnn 7.6.4. Other gpu-based tools (eg hashcat) and other gpu functionalities are fine.",7,2
5,2019-10-2,2019,10,2,13,dc5hmt,tf.math.argmax not working the way I expect it to,https://www.reddit.com/r/tensorflow/comments/dc5hmt/tfmathargmax_not_working_the_way_i_expect_it_to/,bharddwaj,1569991325,"&amp;#x200B;

[I'm not getting the value of the index with the greatest value. I thought it was because the numbers were all less than 1 and the function was treating them as ints so i multiplied each number by 10, but unfortunately I still get the same result. Anyone know what the problem is? p.s. loaded model is tf.keras.models.load\_model\(\\""name.h5\\""\) if that information is needed](https://i.redd.it/v7cv6wz542q31.png)",2,0
6,2019-10-2,2019,10,2,20,dc8rlq,TensorFlow Federated Tutorial,https://www.reddit.com/r/tensorflow/comments/dc8rlq/tensorflow_federated_tutorial/,thelectrician,1570014996,"Hello fellow tensorflowers,

I am looking for a tensorflow federated tutorial other than the ones in the tensorflow website. Especially a built from scratch one would be great. Somehow I am not able to grasp 'federated' part from the ones in the website.

Thanks for reading this and possible answers.",2,7
7,2019-10-3,2019,10,3,18,dcoqcm,Ist it possible to run interference of a GAN (e.g. StyleGAN) directly on a mobile phone?,https://www.reddit.com/r/tensorflow/comments/dcoqcm/ist_it_possible_to_run_interference_of_a_gan_eg/,2ringo,1570096774,"Hey guys,

I was wondering if it is possible to implement a GAN directly on a mobile phone without using a Server? 
I am asking because I wasn't able to find TensorflowLite implementations of GANs in general and there is no TensorflowLite GAN example.
I really appreciate your help!",3,7
8,2019-10-4,2019,10,4,1,dcsx6q,GithubIssuePrioritizer Project,https://www.reddit.com/r/tensorflow/comments/dcsx6q/githubissueprioritizer_project/,bharddwaj,1570118561,"What do you guys think of this project that I worked on? 

link to github: [https://github.com/bharddwaj/GithubIssuePrioritizer](https://github.com/bharddwaj/GithubIssuePrioritizer)",0,0
9,2019-10-4,2019,10,4,1,dcsy7c,How realistic is it to port a Python program developed on Scikit-Learn to TensorFlow?,https://www.reddit.com/r/tensorflow/comments/dcsy7c/how_realistic_is_it_to_port_a_python_program/,o-rka,1570118676,"In particular it uses the cross validation function, logistic regression, and decision trees.  The cross validation is really important because it gives specific cross validation pairs.",6,0
10,2019-10-4,2019,10,4,11,dd0xxo,XLA AOT compilation,https://www.reddit.com/r/tensorflow/comments/dd0xxo/xla_aot_compilation/,srohit0,1570154711,"Has tensorflow team abandoned the idea of AOT compilation? 

Github code at  [https://github.com/tensorflow/tensorflow/tree/master/tensorflow/compiler/aot](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/compiler/aot)  shows minimal updates in past 2 years?

Was there a technical reason to abandon this approach or is it just resources diverted to tensorflow2.0  to compete with pyTorch?",0,4
11,2019-10-5,2019,10,5,0,dd8mv9,Hugging Face Implements SOTA Transformer Architectures for PyTorch and TensorFlow 2.0,https://www.reddit.com/r/tensorflow/comments/dd8mv9/hugging_face_implements_sota_transformer/,Yuqing7,1570201730,,0,8
12,2019-10-5,2019,10,5,0,dd8twk,How to run tensorflow python scripts on web server?,https://www.reddit.com/r/tensorflow/comments/dd8twk/how_to_run_tensorflow_python_scripts_on_web_server/,HistoricalTouch0,1570202620,"Hi, I'm thinking about running tensorflow python scripts on my web server together with trained model, ss there anything I shall setup first?",3,0
13,2019-10-5,2019,10,5,10,ddgy1r,"TPUEstimator not logging ""train_examples/sec"" to events",https://www.reddit.com/r/tensorflow/comments/ddgy1r/tpuestimator_not_logging_train_examplessec_to/,Allong12,1570240051,"I've recently gotten into developing Tensorflow on Google Clouds TPU hardware, and am currently trying to benchmark and tune an existing codebase, but I am currently stumped by this issue.

When I run the TPUEstimator.train function, every thing runs as expect except doesn't output any summaries or scalars, even the ones I assumed were builtin such as  `train_examples/sec`  or `train_global_step/sec.` And what really gets me is that looking over the logs of my past few hundred runs, I found exactly one that does contain these metrics, and I have no way of discovering what was different about that run.

I do not believe this has anything to do with setting  `tf.logging.set_verbosity(tf.logging.INFO)` because they don't show up in my events.out.tfevents file either",1,1
14,2019-10-5,2019,10,5,15,ddjkj5,Master the Most Important Deep Learning Frameworks (Tensorflow &amp; Keras) for Python Data Science,https://www.reddit.com/r/tensorflow/comments/ddjkj5/master_the_most_important_deep_learning/,DanielrMinor,1570256993,,0,1
15,2019-10-5,2019,10,5,21,ddmgx4,"Implemented Flappy Bird using TensorFlow.js in browser, yes yes yes in BROWSER !!! Demo included, Code included !!!",https://www.reddit.com/r/tensorflow/comments/ddmgx4/implemented_flappy_bird_using_tensorflowjs_in/,pointless-ai,1570277577,,0,10
16,2019-10-6,2019,10,6,4,ddrx2w,How to build and install TensorFlow 2.0 GPU/CPU wheel for Python 3.7 for Windows from source code using bazel,https://www.reddit.com/r/tensorflow/comments/ddrx2w/how_to_build_and_install_tensorflow_20_gpucpu/,amsokol,1570303360,,0,18
17,2019-10-6,2019,10,6,20,de1vpo,Extract Features for an Image from a Pretrained CNN,https://www.reddit.com/r/tensorflow/comments/de1vpo/extract_features_for_an_image_from_a_pretrained/,ihababdk,1570360139,"Hi Guys , 

Im working on a Computer Vision project which at one point requires to represent an input image with a feature vector, to do so , one of the proposed methods is by using the feature vector extracted from a pretrained CNN , namely **Inception-V4 pretrained on the ImageNet Dataset.** Assuming that I downloaded the pretrained CNN , how do I go on to extract a feature vector for an input image ( TF with python )

Thanks!",7,6
18,2019-10-7,2019,10,7,16,deg8xn,Continue training on SavedModel or load checkpoint from SavedModel,https://www.reddit.com/r/tensorflow/comments/deg8xn/continue_training_on_savedmodel_or_load/,davislf2,1570434099,"In tensorflow 1.14, it's obvious that tf.compat.v1.train.init\_from\_checkpoint can load ckpt to continue training (or to warm start). However, I couldn't find any corresponding approaches in [SavedModel](https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/saved_model), and [tf.estimator.WarmStartSetting](https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/estimator/WarmStartSettings) only supports ckpt as well. It's weird for me because [this answer](https://stackoverflow.com/questions/42216208/should-tensorflow-users-prefer-savedmodel-over-checkpoint-or-graphdef) mentioned that there should be a checkpoint stored in SavedModel. Does anyone know:

1. How to load checkpoint in SavedModel? or
2. How to warm start training on SavedModel?",0,3
19,2019-10-7,2019,10,7,22,dej9zd,Visualizing a Neural Network Created Using Tensor Flow Controlling an Interplanetary Spacecraft Trajectory,https://www.reddit.com/r/tensorflow/comments/dej9zd/visualizing_a_neural_network_created_using_tensor/,Gereshes,1570454067,,9,80
20,2019-10-7,2019,10,7,22,dejb6k,How does tensorflow manage memory allocation for tensors? Before computation starts or during computation?,https://www.reddit.com/r/tensorflow/comments/dejb6k/how_does_tensorflow_manage_memory_allocation_for/,wzchz_0,1570454238,"I'm pretty new to TensorFlow. I am very interested to know how TF allocates memory for tensors or other data when starting `session.run()`. Does it allocate the memory for all data all at once before actually starting the computation? Or dynamically in the runtime and allocate the memory only when a tensor is encountered?

For example, a graph is created with a few operations which have inputs and outputs like tensors a, b, c, ..., y, z. When [`session.run`](https://session.run)`()` starts, does all a, b, c, ..., y, z are allocated to the required memory before any computation starts? Or during the runtime when each one of them is encountered?",0,2
21,2019-10-8,2019,10,8,6,depovu,Free Book: Getting Started with TensorFlow 2.0,https://www.reddit.com/r/tensorflow/comments/depovu/free_book_getting_started_with_tensorflow_20/,psangrene,1570482011,,0,1
22,2019-10-8,2019,10,8,9,desgah,Use the ImageDataGenerator!,https://www.reddit.com/r/tensorflow/comments/desgah/use_the_imagedatagenerator/,TuringCompletex64,1570494783,,0,2
23,2019-10-9,2019,10,9,3,df3xev,Problems using tf.estimator.inputs.pandas_input_fn(),https://www.reddit.com/r/tensorflow/comments/df3xev/problems_using_tfestimatorinputspandas_input_fn/,WiseAfro27,1570558798,"I'm trying to use tf.estimator.inputs.pandas\_input\_fn() to define my inputs but i get the message:

    AttributeError: module 'tensorflow_core.estimator' has no attribute 'inputs'",6,2
24,2019-10-9,2019,10,9,7,df7p0c,"Beginner Training Model, Head Start?",https://www.reddit.com/r/tensorflow/comments/df7p0c/beginner_training_model_head_start/,CuriousKindo88,1570574560,"Hello, so I am following this tutorial online to get started in Tensorflow since the Tensorflow documentation is not clear to new beginners.

One of the challenges that I see common is to train a model to differentiate between legitimate reviews and random reviews. Here is a CSV file:

[https://raw.githubusercontent.com/dtsclife93/rawfiles/master/areviews.csv](https://raw.githubusercontent.com/dtsclife93/rawfiles/master/areviews.csv)

In this CSV, there is a column for the written review and a column showing if it was a legitimate review (1 = legit review, 0 = not legitimate)

Whats the best way to train the model to be able to detect legit reviews from non-legit reviews and can I use this trained model to input my own review and Tensorflow outputs a 1 or 0.",2,5
25,2019-10-9,2019,10,9,8,df8c28,How to set the value of a Variable?,https://www.reddit.com/r/tensorflow/comments/df8c28/how_to_set_the_value_of_a_variable/,jorbs2,1570577343,"In C++, how can I set the value of a tensorflow::ops::Variable like https://stackoverflow.com/questions/58295061/how-to-initialize-a-tensorflow-variable-with-a-multi-dimensional-array?",0,1
26,2019-10-9,2019,10,9,9,df9gj0,Retrieving labels from indices in multilabel image classification,https://www.reddit.com/r/tensorflow/comments/df9gj0/retrieving_labels_from_indices_in_multilabel/,ski233,1570582327,"I'm having an issue of getting back the correct labels in multilabel image classification. 

I'm using this for my prediction code:

        
    categories = list(test_generator.class_indices.keys())
    for x, y_pred, y_true in generator_with_true_classes(model, test_generator):
            #idx corresponds to the batch size and current prediction is of shape [batchsize, numlabels]
            predicted_labels = [];
            for idx, current_prediction in enumerate(y_pred):
                for index in range(current_prediction.size):
                    if current_prediction[index] &gt;= 0.4:
                        predicted_labels.append(categories[index])
            print(""predicted labels: "" + str(predicted_labels))
            true_labels = [];
            for idx, current_prediction in enumerate(y_true):
                for index in range(current_prediction.size):
                    if current_prediction[index] &gt;= 0.4:
                        true_labels.append(categories[index])
            print(""true labels: "" + str(true_labels))
            input(""press enter for next"")

and this for the generator and referenced function above:

        test_datagen=ImageDataGenerator(rescale=1./255.)
        df = pd.read_csv('dataset_test.csv', encoding='utf-8')
        df[""labels""]=df[""labels""].apply(lambda x:x.split("",""))
        test_generator=test_datagen.flow_from_dataframe(
        dataframe=df,
        directory="""",
        x_col=""Filepaths"",
        y_col=""labels"",
        batch_size=1,
        seed=42,
        shuffle=False,
        class_mode=""categorical"",
        classes=json_array,
        target_size=(200,200))
    
    def load_data_custom(df):
        
        returnX = []
        returnY = []
        
        for i in range(len(df)):
            
            item = df.loc[i][0]
            current_label = np.array((df.loc[i])[1:])
            
            #path = os.path.join('images', item)
            #list_of_imgs = [os.path.join(path, file) for file in os.listdir(path)]
            #train_set = list_of_imgs[:30]
            #val_set = list_of_imgs[30:40]
            #test_set = list_of_imgs[40:]
            #thisFile = open(item)
            
            img = cv2.resize(cv2.cvtColor(cv2.imread(item, 1), cv2.COLOR_BGR2RGB), (224, 224))
            returnX.append(img)
            returnY.append(current_label)
           
        return (np.array(returnX), np.array(returnY))

My issue is that the predictions output a one hot encoding and I need to translate this back into the labels from the csv file. However, when I pass the labels in as an array, the ImageDataGenerator is changing the order of them so if I use the index of the one hot encoding with my array of labels, the indices are incorrect. So, I tried using the indices from test\_generator.class\_indices as I found online but this is not giving the correct indices either and the labels output from this actually are different every time I run prediction on the same images.",2,2
27,2019-10-10,2019,10,10,4,dflsgv,binary cross entropy with from_logits True failing training,https://www.reddit.com/r/tensorflow/comments/dflsgv/binary_cross_entropy_with_from_logits_true/,ski233,1570648256,"I'm training a multilabel image classifier using binary cross entropy for the loss function (its just a modified resnet50 with an added FC128 layer and a sigmoid final layer). However, I was reading that I really should be using binary cross entropy with from\_logits=True in this scenario but when I have tried this, the accuracy starts incredibly low and then the loss stops decreasing at a relatively high value. Does anyone know why this might be happening and how to fix it?",1,1
28,2019-10-10,2019,10,10,6,dfo37c,Tensorboard limit IP access,https://www.reddit.com/r/tensorflow/comments/dfo37c/tensorboard_limit_ip_access/,Kionairis,1570658053,"Hi,

I've been using Tensorboard to visualise some deep learning results.

I've been using the command ""tensorboard --logdir logdir"" and then accessing through Chrome. 
However, the issue listed here: 
https://github.com/tensorflow/tensorboard/issues/2387
implies that my local host server is visible by default to the web. This is altered in tf 2.0+, but how can I alter this in tensorflow 1.x. 

I'm also not sure of the possible security implications of not changing this, would a password be needed to access this or my underlying PC from the web? My username + pass I use to log on to my laptop?

I'm hoping there is some flag command I can pass to tensor-board that will only listen to connections from the local machine, but finding the possible flags to pass to tensorboard isn't easy from the googling I've done.

Thanks for any help.",3,7
29,2019-10-10,2019,10,10,17,dfutru,How to determine the memory usage of a control input in TensorFlow?,https://www.reddit.com/r/tensorflow/comments/dfutru/how_to_determine_the_memory_usage_of_a_control/,wzchz_0,1570694946,"Just as the name says, how can I determine the size of a control input in TensorFlow?",8,2
30,2019-10-10,2019,10,10,22,dfy3i4,A way to load all cuds libraries before inference?,https://www.reddit.com/r/tensorflow/comments/dfy3i4/a_way_to_load_all_cuds_libraries_before_inference/,UysofSpades,1570714527,"So I have a model running on live streaming data - one little annoying about the setup is that once the program starts and it begins its first prediction, the program hangs for a couple of seconds as its loading all the necessary cuda libraries. Is there a way to explicitly open those libraries in the very beginning of a program so this loading doesnt happen at initial prediction time?",2,1
31,2019-10-11,2019,10,11,14,dgajzq,MNIST Dataset in CNN,https://www.reddit.com/r/tensorflow/comments/dgajzq/mnist_dataset_in_cnn/,nehapandey01,1570771846,,0,1
32,2019-10-11,2019,10,11,22,dgf0mx,Super Serial- making TFRecords easy,https://www.reddit.com/r/tensorflow/comments/dgf0mx/super_serial_making_tfrecords_easy/,Markemus,1570799735,"[https://gist.github.com/markemus/74ba47d0b58f91d7aa7885341ed3b1b8](https://gist.github.com/markemus/74ba47d0b58f91d7aa7885341ed3b1b8)

I wrote a small module adapting [this tutorial](https://www.tensorflow.org/tutorials/load_data/tfrecord) to make serializing datasets easier. Instead of engineering features individually when saving and loading, feature shapes and dtypes are determined from the dataset and stored in a .header file. Reading and writing is as simple as calling `save(dataset, *paths)` and `load(*paths)`.

Some gotchas:

1. saving must be done in eager mode (not sure how that will work in TF2).
2. datasets must be flat dictionaries of tensors with no nesting, e.g. `ds = {""data"": tensor, ""data2"": tensor, ""labels"": tensor}`
3. data must fit in memory during the initial write.

Constraints 2 and 3 can be removed with additional code, but I think eager mode is a hard constraint. Hopefully this helps someone!",2,7
33,2019-10-12,2019,10,12,4,dgk5ld,"[HELP] How to ""Add"" into model/graph",https://www.reddit.com/r/tensorflow/comments/dgk5ld/help_how_to_add_into_modelgraph/,vaibhavkumar049,1570822811,"I have an encoder and 3 decoders, I am passing my encoder output to 3 decoders and calculating loss individuaLLY and adding all loss then computing gradient wrt to total\_loss , but for total loss I am doing   
\`total\_loss=lossa+lossb+lossc\` 

but when I compute gradients across all variables it is giving me output None, I guess total\_loss is not the correct way  of doing it , How can I do it correctly",3,3
34,2019-10-12,2019,10,12,20,dgtyqf,How to build tensorflow-gpu 1.14 c++ in Visual Studio 2017 (MSVC 2017) ?,https://www.reddit.com/r/tensorflow/comments/dgtyqf/how_to_build_tensorflowgpu_114_c_in_visual_studio/,waterRocket8236,1570879922,"I am trying to install tensorflow-gpu 1.14 version in VS 2017 community edition for C++ use. But I am unable to do it as the building with bazel part is really confusing. I am relatively new to tensorflow c++ installation and use. If anyone did this please help me. 

Help Appreciated.",7,5
35,2019-10-12,2019,10,12,22,dgvdl2,How can I extract weights as an array in tensorflow?,https://www.reddit.com/r/tensorflow/comments/dgvdl2/how_can_i_extract_weights_as_an_array_in/,Zizzy1110,1570888155,"Hi all. In keras, I was using the code ""agent.model.get\_weights()"" to extract all the weights from a network. Is there a similar way to do so in tensorflow? I appreciate any help!",5,2
36,2019-10-13,2019,10,13,3,dgyzdl,AdamW implementation,https://www.reddit.com/r/tensorflow/comments/dgyzdl/adamw_implementation/,roset_ta,1570905222,"Hello,


Is there any safe to use implementation of AdamW for Keras? The one I found on github has an open issue claiming that the weight decay can only be set globally for all layer weights.",1,1
37,2019-10-13,2019,10,13,7,dh1pms,Has anyone used the gradient boosted decision tree api in Tensorflow?,https://www.reddit.com/r/tensorflow/comments/dh1pms/has_anyone_used_the_gradient_boosted_decision/,mattfirstorderlabs,1570918164,How is the performance? How well does it scale to multiple machines?,0,5
38,2019-10-13,2019,10,13,13,dh642o,Using Keras on top of Tensorflow and loading previously saved model gives TypeError,https://www.reddit.com/r/tensorflow/comments/dh642o/using_keras_on_top_of_tensorflow_and_loading/,DeepestSeas,1570942003,"Error given is:

 TypeError: Unexpected keyword argument passed to optimizer: name 

&amp;#x200B;

How model was saved:

    from tensorflow.python.keras.models import Sequential
    model = Sequential()
    //model layers
    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    model.fit(X, y, batch_size=32, epochs=500)
    model.save('SavedModel')

How I loaded the model

    from tensorflow.python.keras.models import load_model
    
    model = load_model('SavedModel')
    prediction = model.predict(X)

Error was thrown on the load\_model line.

&amp;#x200B;

I have searched all over the internet, and it all said it was a version issue, but I am using the same version to load the model as I saved the model with, both keras and tensorflow. Does anyone know whats going on?",2,3
39,2019-10-13,2019,10,13,16,dh7dp6,What is the reason for early saturation of values in case of CNN before the last activation layer?,https://www.reddit.com/r/tensorflow/comments/dh7dp6/what_is_the_reason_for_early_saturation_of_values/,pranav2109,1570951179,I have been trying to implement a CNN which is a combination of 3 convolution layers followed by 3 fully connected layers for feature extraction for an actor in an RL algorithm. The last activation is tanh. But I observed that for all the action prediction the tanh always predicts values close to the extreme i.e -1 or 1 leading to the very bad performance of the agent and no learning on its part. My implementation is TensorFlow based.,1,3
40,2019-10-13,2019,10,13,20,dh9dmk,Do checkpoints save the number of epoch?,https://www.reddit.com/r/tensorflow/comments/dh9dmk/do_checkpoints_save_the_number_of_epoch/,KijutsushiB,1570965980,"Hello! I've reading the CycleGAN tutorial on TF's site and it occurred to me that the optimizer has beta\_1=0.5 which means that the first half of the epochs have 2e-4 learning rate and then it starts to decay. However, if we stop training at one point and resume it through a checkpoint, how will the optimizer understand that it is on the second half of the epochs in order to change the learning rate? Do the checkpoints contain this information? Thanks.",5,1
41,2019-10-14,2019,10,14,2,dhdmih,"In the tf easy demo, why do you scale the mninsst image numbers from 0 to 1?",https://www.reddit.com/r/tensorflow/comments/dhdmih/in_the_tf_easy_demo_why_do_you_scale_the_mninsst/,TheUltimateSalesman,1570987973,"""Scale these values to a range of 0 to 1 before feeding them to the neural network model. To do so, divide the values by 255. It's important that the *training set* and the *testing set* be preprocessed in the same way""  

Why was the testing set zero to one?",7,2
42,2019-10-14,2019,10,14,18,dho8ot,"Tensorflow 2.0 Docker Container, Failed to get convolution algorithm",https://www.reddit.com/r/tensorflow/comments/dho8ot/tensorflow_20_docker_container_failed_to_get/,nQFbsxw,1571045862,"I'm trying to run a notebook with binary classification computer vision model build with tensorflow. The neural net has some convolutional layers. Unfortunately the notebook runs only fine when I use tensorflow container without gpu support, but when I try to run it in an gpu assisted tensorflow container `history = model.fit_generator(...)` fails with the following error:

    Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]

**jupyter notebook log:**

    2019-10-13 20:36:49.873285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1),
     but there must be at least one NUMA node, so returning NUMA node zero
    2019-10-13 20:36:49.873615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device
    :GPU:0 with 7367 MB memory) -&gt; physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:06:00.0, compute capability: 7.5)
    2019-10-13 20:36:52.358936: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
    2019-10-13 20:36:53.525440: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR

Because I use tensorflow in a container pulled from the official tensorflow docker repository all dependencies should be compatible and I have no idea why it fails.

**the setup:**

\- RTX 2070 Super

\- fresh ubuntu 18.04 install

\- nvidia-driver-435

\- docker-ce

\- [NVIDIA Container Toolkit](https://github.com/NVIDIA/nvidia-docker)

\- run one of the containers below

**gpu assisted tensorflow container (training fails):**

`sudo docker run --gpus all -it -p 8888:8888 --hostname &lt;hostip&gt; --rm tensorflow/tensorflow:2.0.0-gpu-py3-jupyter`

**tensorflow container without gpu support (works)**

`sudo docker run --gpus all -it -p 8888:8888 --hostname &lt;hostip&gt; --rm tensorflow/tensorflow:nightly-py3-jupyter`

Has someone an idea why I get this error and what might fixes it? I tried it also with the most recent gpu images in the repository..

Here is the notebook:

[https://colab.research.google.com/drive/1Aem8Fhqifa1B6OGJjReDuZt2dJJ0ruFR](https://colab.research.google.com/drive/1Aem8Fhqifa1B6OGJjReDuZt2dJJ0ruFR)",7,7
43,2019-10-14,2019,10,14,21,dhpopq,Tensorflow! need help,https://www.reddit.com/r/tensorflow/comments/dhpopq/tensorflow_need_help/,starship_912,1571055141,"Hi All, I am very new to Tensorflow. I managed to train a pretrain model for custom object detection. 

Now, all I want some example to train a model from scratch without using any pretrained model to detected an object in an image.

I am searching for last 2weeks I am not able to fine, everywhere they are using pretrained  model. Can someone help me to point out some example.

If it is not correct place to ask this question, please point me where to ask.

&amp;#x200B;

Thanks in advance",6,1
44,2019-10-15,2019,10,15,18,di5hyn,Is it a good practice to overwrite fit() ?,https://www.reddit.com/r/tensorflow/comments/di5hyn/is_it_a_good_practice_to_overwrite_fit/,MrPuj,1571132506,"Hi everyone,

I'm trying to learn tensorflow 2.0 and I'd like to follow good coding practices. I like to create my most complex models by subclassing the tf.keras.Model class. While it gives access to a fit method, I still see a lot of codes implementing a separate training function when the losses are getting complex to manage with Model.add\_loss etc ... I would also like to create my own custom training step, but I would prefer to do it inside the model to stay coherent with the keras API. Is it a good practice or will I break anything by doing so ? I don't undertand why a lot of codes use a separate training function.",1,3
45,2019-10-16,2019,10,16,1,diapgi,Run keras model prediction in c++,https://www.reddit.com/r/tensorflow/comments/diapgi/run_keras_model_prediction_in_c/,fkcm75,1571158409,"I want to Predict my Keras model in c++.

I have the following Layers:
Dropout
MaxPooling
Conv2DTranapose
Conv2D
Batchnormalisation

How can I realize this? I use Tensorflow 1.14 and keras. But i can also use for predicition tensorflow 2.0",2,6
46,2019-10-16,2019,10,16,4,didap3,How-to Get Started with Machine Learning on Arduino,https://www.reddit.com/r/tensorflow/comments/didap3/howto_get_started_with_machine_learning_on_arduino/,gvarisco,1571168937,,2,22
47,2019-10-16,2019,10,16,9,dihehq,Not C# (like Not Hotdog from Silicon Valley): deep convolutional neural network with TensorFlow,https://www.reddit.com/r/tensorflow/comments/dihehq/not_c_like_not_hotdog_from_silicon_valley_deep/,lostmsu,1571186562,,0,1
48,2019-10-16,2019,10,16,10,dihxds,C# or NOT: training a conv net with C# + TensorFlow to detect programming languages,https://www.reddit.com/r/tensorflow/comments/dihxds/c_or_not_training_a_conv_net_with_c_tensorflow_to/,lostmsu,1571189094,,0,1
49,2019-10-16,2019,10,16,17,dimkio,Can I use a single optimizer for different models?,https://www.reddit.com/r/tensorflow/comments/dimkio/can_i_use_a_single_optimizer_for_different_models/,PmMeYourBugs,1571216386,"In PyTorch the variables to train are passed to the constructor of an optimizer, but TF 2.0 doesn't need that. Instead, the \`apply\_gradients\` method takes a list of pairs of grads and vars. Does that mean I can use a single optimizer for different variables by passing the appropriate grads\_and\_vars list?

I am aware that the TF tutorials don't do it this way, they use different optimizers for different models (eg: DCGAN). Is that done only for readability?",1,2
50,2019-10-16,2019,10,16,22,dipocj,"Hey guys, I trained an object detection model to detect weapons. Feel free to test it out or use it in your projects. It can detect 6 types of guns and holstered pistols!",https://www.reddit.com/r/tensorflow/comments/dipocj/hey_guys_i_trained_an_object_detection_model_to/,isademigod,1571234252,,17,25
51,2019-10-17,2019,10,17,0,dirbmp,Best hardware for object detection?,https://www.reddit.com/r/tensorflow/comments/dirbmp/best_hardware_for_object_detection/,forobitcoin,1571241585,"Hi,

&amp;#x200B;

I need help to decide wich hard to use: Intel stick, Nvidia Jetson nano, Google Stick, Google Coral.

The goal its to make a custom object detection for vehicles and other for bugs.

&amp;#x200B;

Wich its the recommended for this use case? the power consumption its not a problem.

&amp;#x200B;

Thanks",2,1
52,2019-10-17,2019,10,17,4,diutf0,"convert video data (.avi, .mp4 etc.) to TensorFlow tfrecords",https://www.reddit.com/r/tensorflow/comments/diutf0/convert_video_data_avi_mp4_etc_to_tensorflow/,whiletrue2,1571255928,,0,3
53,2019-10-17,2019,10,17,21,dj5m1e,ONNX to Keras model converter,https://www.reddit.com/r/tensorflow/comments/dj5m1e/onnx_to_keras_model_converter/,nerox8664,1571314893,,0,3
54,2019-10-17,2019,10,17,21,dj5qwe,Modifying model weights manually,https://www.reddit.com/r/tensorflow/comments/dj5qwe/modifying_model_weights_manually/,delpotroswrist,1571315620,"I'm using an inception\_v3 module from the tf.contrib nets and loading weights from a checkpoints. For some analysis, I need to randomize the weights of certain layers manually. Can someone point me to tutorials on how to access and modify these weights? Any help would be appreciated, thanks in advance",3,3
55,2019-10-17,2019,10,17,21,dj61j7,Keras runtime is faster than TFLite on RPi4?!,https://www.reddit.com/r/tensorflow/comments/dj61j7/keras_runtime_is_faster_than_tflite_on_rpi4/,Jesper89,1571317130,"I trained a model in the Keras API and did inference on the Raspberry Pi 4. The model size is about 20 mb and each forward pass is about 50 ms. 
Trying to optimize inference I converted the model to TFLite. The model size is now 2 mb but each forward pass is about 70 ms. I would have expected it to be much faster. 

Does anyone has experience with this for the RPi?",0,1
56,2019-10-18,2019,10,18,1,dj8hc0,Getting Logstic Regression weights in TensorFlow,https://www.reddit.com/r/tensorflow/comments/dj8hc0/getting_logstic_regression_weights_in_tensorflow/,MLnewbie22,1571328315,"I'm trying to look at the values of coefficients from the latest checkpoint, but am running into some issues with identifying which values I want to actually extract. Here's the code that i'm using from: [https://stackoverflow.com/questions/38218174/how-do-i-find-the-variable-names-and-values-that-are-saved-in-a-checkpoint](https://stackoverflow.com/questions/38218174/how-do-i-find-the-variable-names-and-values-that-are-saved-in-a-checkpoint)

    import tensorflow as tf
    from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_file
    
    latest_ckp = tf.train.latest_checkpoint('model_dir')
    print_tensors_in_checkpoint_file(latest_ckp, all_tensors=True, tensor_name='')

This gives me a list of `tensor_name`'s such as the following: 

* `global_step` : total number of batches the model has seen so far 
* `linear/linear_model/feature/weights`
* `linear/linear_model/feature/weights/part_0/Ftrl`
* `linear/linear_model/feature/weights/part_0/Ftrl_1`

Out of these weights, which one should I be looking at and what's the difference between them?",3,1
57,2019-10-18,2019,10,18,22,djncob,TensorFlow Graphics tutorials,https://www.reddit.com/r/tensorflow/comments/djncob/tensorflow_graphics_tutorials/,sergeybok,1571404509,"Hi all, I was wondering if anyone knows if there are any proper tutorials for the new [tensorflow graphics](https://www.tensorflow.org/graphics) library. They provide some on the github but those are confusing as hell and don't even show how to do the simplest thing which is how to render an image given a mesh, camera position, and light source. Does anyone know which function does that because I've been looking at the source code and found the rasterize functions but I know that's not the same as fully rendering and am not a graphics expert enough to trust myself to build a renderer from the tools they have provided myself.",0,17
58,2019-10-20,2019,10,20,10,dkd2cu,How to write multiple TFRecord files in parallel?,https://www.reddit.com/r/tensorflow/comments/dkd2cu/how_to_write_multiple_tfrecord_files_in_parallel/,enerrio,1571535465,"Is there an efficient way to write multiple TFRecord files in parallel? I've tried using multiprocessing library to write several TFRecord files in parallel like below:

    pool = mp.Pool(processes=2)
    num_files_per_record = 100
    results = [pool.apply_async(write_tfrecord, args=(i, train_files[(i*num_files_per_record):(i+1)*num_files_per_record])) for i in range(50)]
    g = [res.wait() for res in results]
    pool.close()

However this code block hangs forever... Any help is appreciated!",5,4
59,2019-10-21,2019,10,21,8,dkro5b,Best GPU for a monte-carlo expectation,https://www.reddit.com/r/tensorflow/comments/dkro5b/best_gpu_for_a_montecarlo_expectation/,psyyduck,1571613758,"I'm using the function [monte_carlo.expectation](https://www.tensorflow.org/probability/api_docs/python/tfp/monte_carlo/expectation) with 2000+ samples and the distribution being sampled from has ~1M+ parameters. Right now the model needs 25+GB. 

Is there any way around this? What GPUs would you all recommend for this task? It's looking like my choices are 1) analytically work out the expectation (impossible), 2) make the tensorflow code more efficient (??), or 3) get the Quadro RTX 8000 ($6000) ...",9,6
60,2019-10-21,2019,10,21,11,dku1mm,Obtaining tensor int32 value,https://www.reddit.com/r/tensorflow/comments/dku1mm/obtaining_tensor_int32_value/,BrightTux,1571625758,"Hi all,   
I would appreciate some guidance in creating tf.examples while in graph mode. I've gone through the examples in: [https://www.tensorflow.org/tutorials/load\_data/tfrecord](https://www.tensorflow.org/tutorials/load_data/tfrecord?fbclid=IwAR3aFKmm91mD0kODchQdkSRZkp0LnvWlJ6IiSsrO6W-OemGYY6bz5pOIBks)  


My goal is to create tf.data.Dataset API for some datasets. One of the features that i would like to encode within the serialized data is the original image's width and height.  
I am able to serialize static values .. but i'm unable to serialize 'tensor' values. Here's my codes:  


[https://pastebin.com/rh1LMjb1](https://pastebin.com/rh1LMjb1?fbclid=IwAR2kTiBYcdbJ-qmia-qtDW3ibQIM10LpVGyhten7ReOeV-D08M4FPmG1Ipg)  


Error: TypeError: &lt;tf.Tensor 'strided\_slice\_1:0' shape=() dtype=int32&gt; has type Tensor, but expected one of: int, long

I've tried using tf.io.serialize\_tensorand other operations, but i'm still getting a tensor object .. I have no problem getting the values using tf.print()

Appreciate any form of guidance. Thanks :)",2,1
61,2019-10-21,2019,10,21,23,dl1255,Simple number sequence prediction tensorflow.js example?,https://www.reddit.com/r/tensorflow/comments/dl1255/simple_number_sequence_prediction_tensorflowjs/,davew111,1571666806,"Hi All, I am looking for a simple tensorflow.js example for number sequence prediction and I can't find one.

Trained with a sequence like this:  \[1,2,3,4,1,2,3,4,1,2,3,4\] 

And expected results like this: \[2,3,4,1,2,3,4,1,2,3,4,1\]

The pattern is obvious:

If I pass it 1, it should predict 2

If I pass it 2, it should predict 3

If I pass it 3,  it should predict 4

if I pass it 4, it should predict 1

Can anyone point me to sample code of this, or something similar? Any help would be much appreciated.",6,4
62,2019-10-22,2019,10,22,2,dl3nc2,TensorFlow Serving: Batch Prediction with Variable Length Features,https://www.reddit.com/r/tensorflow/comments/dl3nc2/tensorflow_serving_batch_prediction_with_variable/,MLnewbie22,1571677999,"I'm requesting predictions by hitting POST https://ml.googleapis.com/v1/{name=projects/\*\*}:predict  
 which works if I send a single instance in the format:

    {   ""instances"": [     {json_object_1}   ] } 

But when I try to send multiple instances with the format:

    {   ""instances"": [     {json_object_1},     {json_object_2},     ...   ] } 

I get shape errors that look like:

    {'error': ""Prediction failed: Error processing input: Argument must be a dense tensor:  [[u'Brad Traversy', u'S\\xe9bastien Goasguen'], [u'William Rothwell', u'Brian Foster', u'William McKnight']]  - got shape [2], but wanted [2, 2].""} 

This seems to be due to the fact that the second example in the batch has a different feature length than the first example. In the error above, the first example has 2 features values, and second one has 3 feature values.

Here is my serving input function (no transformations) :

       def serving_input_fn():          inputs = {             'feature1': tf.compat.v1.placeholder(shape = [None], dtype = tf.string),             'feature2': tf.compat.v1.placeholder(shape = [None], dtype = tf.string),             'feature3': tf.compat.v1.placeholder(shape = [None], dtype = tf.string),             ...          }          return tf.estimator.export.ServingInputReceiver(features = inputs, receiver_tensors = inputs) 

I'm using tf.feature\_column.categorical\_column\_with\_hash\_bucket  
 and tf.feature\_column.crossed\_column  
 as my feature columns.

Does anyone know how to accept variable length features in the serving input function?",1,3
63,2019-10-24,2019,10,24,6,dm67j5,Deep Learning Specialization - Master Deep Learning &amp; Break into Artificial Intelligence (New career &amp; earnings opportunities),https://www.reddit.com/r/tensorflow/comments/dm67j5/deep_learning_specialization_master_deep_learning/,internetdigitalentre,1571866590,[removed],0,1
64,2019-10-24,2019,10,24,9,dm8pmj,BERT implementation / tutorial on Tensorflow 2,https://www.reddit.com/r/tensorflow/comments/dm8pmj/bert_implementation_tutorial_on_tensorflow_2/,deraniel38,1571877634,"Hi,

Is there a BERT implementation (ideally with a tutorial) in Tensorflow 2?

Thanks!",11,10
65,2019-10-24,2019,10,24,13,dmbdgm,Help with TensorFlow classification,https://www.reddit.com/r/tensorflow/comments/dmbdgm/help_with_tensorflow_classification/,DavidB-TPW,1571891723,"Hello all,

I am entirely new to TensorFlow and have never worked with it before, and I am finding it very overwhelming to do what I would think should be somewhat straightforward tasks (at least, as far as machine learning is concerned). The project that I am working on is related to text comparison using n-grams, and I want to use a training set of these n-grams to analyze other n-grams using K-Means with Chi Square Distance. Without knowing anything about TensorFlow, looking at the official documentation as well as online tutorials has not been helpful.

If I am being honest, I was expecting trying to use TensorFlow for this to be as simple as:

* Specify the desired analysis method and distance function as well as any necessary parameters (K)
* Specify your training data
* Specify your input data
* Get distance calculation

How would I go about starting this?  Thank you in advance.",0,3
66,2019-10-24,2019,10,24,14,dmbwcv,Plz help me !!!How can i install tensorflow in python 3.7.3 in windows 10...I m getting this error,https://www.reddit.com/r/tensorflow/comments/dmbwcv/plz_help_me_how_can_i_install_tensorflow_in/,Hamitdes,1571895014,,7,0
67,2019-10-24,2019,10,24,18,dmdscw,Why does my program crash my PC?,https://www.reddit.com/r/tensorflow/comments/dmdscw/why_does_my_program_crash_my_pc/,LarkRanger,1571908327,"Hello all,

I'm fairly new to TF and have used some tutorials to build a program for some image processing.

I finally got it ""running"" but then I get this giant error message. followed always by my PC crashing.

I have \`tensorflow-gpu\` and \`keras-gpu\` installed. I don't have anything in the code to specify I'm using the GPU but it is my understanding from this message that TF is attempting to use the GPU regardless. I'm dumbfounded as to why it's not working and why it's so bad my PC crashes completely every time (blue screen that doesn't recover unless restarted).

      WARNING:tensorflow:From C:\Users\OfirL1Wmiconda3\envAtensorflow\lib\site-packages\tensorflow\pythoWramework\opdeflibrary.py:263: colocate with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
      Instructions for updating:
      Colocations handled automatically by placer.
      2019-10-24 11:40:59.562669: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
      2019-10-24 11:40:59.944642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties:
      name: GeForce GT 730 major: 3 minor: 5 memoryClockRate(GHz): 0.9015 
      pciBuslD: 0000:01:00.0
      totalMemory: 2.00GiB freeMemory: 1.65Gi8
      2019-10-24 11:40:59.957934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
      2019-10-24 11:41:06.728253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
      2019-10-24 11:41:06.731392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:998] 0
      2019-10-24 11:41:06.733331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0: N
      2019-10-24 11:41:06.754272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1415 MB memory) -&gt; physical GPU (device: 0, name: GeForce GT 730, pci bus id: 0000:01:00.0, compute capability: 3.5)

I don't know if it's the graphics card that messes up ( which it has in the past, it's quite cheap) or something else. Would love to have some feedback on this.

Using:

* Python 3.6
* PyCharm
* tensorflow/tensorflow-gpu 1.13.1
* keras/keras-gpu 2.2.4
* NVIDIA GeForce GT 730",2,0
68,2019-10-24,2019,10,24,21,dmfjuu,Statically Link Tensorflow 2.0 in C++,https://www.reddit.com/r/tensorflow/comments/dmfjuu/statically_link_tensorflow_20_in_c/,noarts,1571919349,"Hey, I really need your help, since there doesn't seem to be any info on this on the internet.

I need to statically link TF 2.0 into my C++ program, and for this I first need to compile it as a .a file. How would I go about doing this?",1,6
69,2019-10-25,2019,10,25,7,dmo2ww,Detect Toxic Language with Twilio Chat and Tensorflow.js,https://www.reddit.com/r/tensorflow/comments/dmo2ww/detect_toxic_language_with_twilio_chat_and/,lizziepika,1571956485,,3,12
70,2019-10-26,2019,10,26,2,dn0hjv,Applying weight normalization layer in TF 2?,https://www.reddit.com/r/tensorflow/comments/dn0hjv/applying_weight_normalization_layer_in_tf_2/,enerrio,1572023510,"How can I use the weight normalization wrapper from `tensorflow_addons` package inside a model that subclasses `tf.keras.Model`?

I tried something like this:

    import tensorflow as tf
    import tensorflow_addons as tfa
    
    class myModel(tf.keras.Model):
        def __init__(self):
            super(myModel, self).__init__()
            self.conv1 = tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu')
            #self.conv1 = tfa.layers.WeightNormalization(tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu')) # Also doesn't work
            
        def call(x):
            out = tfa.layers.WeightNormalization(self.conv1(x))
            return out

But when I run `myModel(np.zeros((1, 256, 256, 3), dtype=np.float32))` I get an assertion error: 

    File ""//anaconda3/envs/new/lib/python3.6/site-packages/tensorflow_addons/layers/wrappers.py"", line 59, in __init__
        super(WeightNormalization, self).__init__(layer, **kwargs)
      File ""//anaconda3/envs/new/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/wrappers.py"", line 51, in __init__
        assert isinstance(layer, Layer)
    AssertionError

Any ideas?",3,2
71,2019-10-26,2019,10,26,8,dn5l2f,Has anybody trained a model using photorealistic renders?,https://www.reddit.com/r/tensorflow/comments/dn5l2f/has_anybody_trained_a_model_using_photorealistic/,GrimDarkDev,1572045513,I was wondering if anybody had any success training using sample data generated from ray tracing? And if so were you able to translate this to the real world easily?,22,8
72,2019-10-26,2019,10,26,12,dn8ntf,Where do I find good resource for image classification training?,https://www.reddit.com/r/tensorflow/comments/dn8ntf/where_do_i_find_good_resource_for_image/,FateRiddle,1572061576,"Hi, I'm pretty new here, maybe because I don't know what to search, I could find any good website or resource for image classification training. I'm gonna retrain a model with a script provided by a github project, but I also need like 1000 pictures for each object.

How do you usually get those images? Taking photo yourself, search image online or do we have some specific website for this?",2,1
73,2019-10-26,2019,10,26,18,dnbgwb,I still do not understand this person's saying.,https://www.reddit.com/r/tensorflow/comments/dnbgwb/i_still_do_not_understand_this_persons_saying/,JonathanSum777,1572080877,"We were doing a time series forecasting. 

source:  [https://www.coursera.org/learn/tensorflow-sequences-time-series-and-prediction/discussions/all/threads/6MhsNeRWEem-MQ4PuCAsjg](https://www.coursera.org/learn/tensorflow-sequences-time-series-and-prediction/discussions/all/threads/6MhsNeRWEem-MQ4PuCAsjg) 

https://i.redd.it/79xrc7awpuu31.png",0,2
74,2019-10-26,2019,10,26,21,dndj7j,Setting initial state in custom RNN cell,https://www.reddit.com/r/tensorflow/comments/dndj7j/setting_initial_state_in_custom_rnn_cell/,ScriptKiddz,1572094724,"Hey,
I'm currently working on a custom RNN cell. The custom part is that next to the hidden state (```shape=(units)```) I also carry around a matrix (```shape=(units, units)```) in the cell state. It works fine, but now I am interested in initialising the matrix as a identity matrix. I tried different method of supplying a ```initial_state``` to the call method, but every time it seems there is a problem with how I supply it and an error of the type
```python
ValueError: An `initial_state` was passed that is not compatible with `cell.state_size`. Received `state_spec`=ListWrapper([InputSpec(shape=(50,), ndim=1), InputSpec(shape=(50, 50), ndim=2)]); however `cell.state_size` is [TensorShape([50]), TensorShape([50, 50])]
```
is thrown.

Here is how I set up the cell state:
```python
    self.state_size = NoDependency([TensorShape([self.units]), TensorShape([self.units, self.units])]) 
```
and this is how I try to initialise them when calling:
```python
    x = rnn_layer(x, initial_state = [tf.zeros(50), tf.eye(50)]).
```
Thanks in advance for any help!",0,2
75,2019-10-26,2019,10,26,23,dnepgm,Why separate the target value (MPG) from features,https://www.reddit.com/r/tensorflow/comments/dnepgm/why_separate_the_target_value_mpg_from_features/,harshamohan,1572100826,"Hi Guys!

I have been reading about Tensor Flow lately and want to build a simple prediction model, but this point confuses me or I am not realizing something here.

Why do we remove the target value from the features? Would the target value (MPG) be helpful in training in the model? 

https://www.tensorflow.org/tutorials/keras/regression#split_features_from_labels 

Thanks!

Harsha",1,0
76,2019-10-26,2019,10,26,23,dney0z,Compiling TensorFlow from source code when compiler is in non-standard location,https://www.reddit.com/r/tensorflow/comments/dney0z/compiling_tensorflow_from_source_code_when/,life_vortex,1572101997,[https://medium.com/@ujjwalaryan/compiling-tensorflow-from-the-source-when-your-compiler-is-in-a-non-standard-location-194fecc92153](https://medium.com/@ujjwalaryan/compiling-tensorflow-from-the-source-when-your-compiler-is-in-a-non-standard-location-194fecc92153),0,0
77,2019-10-27,2019,10,27,5,dnj1qa,HELP: Encoder decoder model,https://www.reddit.com/r/tensorflow/comments/dnj1qa/help_encoder_decoder_model/,vaibhavkumar049,1572120558,"I am trying to build an encoder-decoder model. encoder as CNN and decoder as RNN or LSTM, so should I pass my image into CNN and then flatten it out and then pass to decoder? or complete channels to decoder?",6,4
78,2019-10-27,2019,10,27,8,dnlcua,"Trying to run Tensorflow session but says ""module 'tensorflow' has no attribute 'Session'""",https://www.reddit.com/r/tensorflow/comments/dnlcua/trying_to_run_tensorflow_session_but_says_module/,TYLER_DURDEN_JIMMY,1572131447," module 'tensorflow' has no attribute 'Session' ; 

Im puting this in Jupyter 

So here is what I have in my 1st cell:

import tensorflow as tf

x = tf.Variable(3, name=""x"")

y = tf.Variable(4, name=""y"")

f = x\*x\*y + y + 2

Next cell:

sess = tf.Session()  \*Where error is occurring

[sess.run](https://sess.run)(x.initializer)

[sess.run](https://sess.run)(y.initializer)

result = [sess.run](https://sess.run)(f)

print(result)

Attribute Error:  module 'tensorflow' has no attribute 'Session'   
 

I have no idea why its doing this. Ive looked on stackoverflow, already updated my tensorflow-gpu and currently have Python 3.7.4

Any help would be awesome thanks!",5,1
79,2019-10-27,2019,10,27,9,dnmdj5,Weird accuracy on sample code,https://www.reddit.com/r/tensorflow/comments/dnmdj5/weird_accuracy_on_sample_code/,sidnfhej,1572136955,"So I got tensorflow running yesterday and ran [this sample code](https://www.tensorflow.org/tutorials/images/classification) and my accuracy seems fine for the first epoch, but then it goes to 1 and drops to .5. It's odd behavior and as a TF noob I don't understand what's happening.

Code output:
```
Total training cat images: 1000
Total training dog images: 1000
Total validation cat images: 500
Total validation dog images: 500
---------------------------------
Total training images: 2000
Total validation images: 1000
Found 2000 images belonging to 2 classes.
Found 1000 images belonging to 2 classes.
2019-10-25 23:27:28.527702: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2019-10-25 23:27:28.538658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-25 23:27:28.539326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.733
pciBusID: 0000:01:00.0
2019-10-25 23:27:28.539581: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 23:27:28.540530: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 23:27:28.541493: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 23:27:28.541740: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 23:27:28.542683: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 23:27:28.543484: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 23:27:28.545931: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-10-25 23:27:28.546086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-25 23:27:28.546615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-25 23:27:28.547056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-10-25 23:27:28.547335: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-10-25 23:27:28.552269: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz
2019-10-25 23:27:28.552869: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5632dcc730d0 executing computations on platform Host. Devices:
2019-10-25 23:27:28.552901: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2019-10-25 23:27:28.601610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-25 23:27:28.602154: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5632dcb62b60 executing computations on platform CUDA. Devices:
2019-10-25 23:27:28.602170: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1060, Compute Capability 6.1
2019-10-25 23:27:28.602365: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-25 23:27:28.602835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.733
pciBusID: 0000:01:00.0
2019-10-25 23:27:28.602902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 23:27:28.602928: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2019-10-25 23:27:28.602957: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2019-10-25 23:27:28.602969: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2019-10-25 23:27:28.602980: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2019-10-25 23:27:28.603003: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2019-10-25 23:27:28.603032: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-10-25 23:27:28.603091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-25 23:27:28.603654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-25 23:27:28.604157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-10-25 23:27:28.604220: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2019-10-25 23:27:28.605118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-10-25 23:27:28.605129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2019-10-25 23:27:28.605152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2019-10-25 23:27:28.605406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-25 23:27:28.605900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-10-25 23:27:28.606374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5411 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)
Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 150, 150, 16)      448       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 75, 75, 16)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 75, 75, 32)        4640      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 37, 37, 32)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 37, 37, 64)        18496     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 18, 18, 64)        0         
_________________________________________________________________
flatten (Flatten)            (None, 20736)             0         
_________________________________________________________________
dense (Dense)                (None, 512)               10617344  
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 513       
=================================================================
Total params: 10,641,441
Trainable params: 10,641,441
Non-trainable params: 0
_________________________________________________________________
Epoch 1/15
2019-10-25 23:27:29.514766: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-10-25 23:27:30.606605: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
1999/2000 [============================&gt;.] - ETA: 0s - loss: 0.0412 - accuracy: 0.9798     
Epoch 00001: saving model to trainingCheckpoints/cp.ckpt
2000/2000 [==============================] - 1238s 619ms/step - loss: 0.0411 - accuracy: 0.9798 - val_loss: 1.9841 - val_accuracy: 0.7300
Epoch 2/15
1999/2000 [============================&gt;.] - ETA: 0s - loss: 8.8165e-06 - accuracy: 1.0000   
Epoch 00002: saving model to trainingCheckpoints/cp.ckpt
2000/2000 [==============================] - 1265s 632ms/step - loss: 8.8136e-06 - accuracy: 1.0000 - val_loss: 2.1716 - val_accuracy: 0.7290
Epoch 3/15
1999/2000 [============================&gt;.] - ETA: 0s - loss: 1.6085e-06 - accuracy: 1.0000   
Epoch 00003: saving model to trainingCheckpoints/cp.ckpt
2000/2000 [==============================] - 1262s 631ms/step - loss: 1.6081e-06 - accuracy: 1.0000 - val_loss: 2.2919 - val_accuracy: 0.7300
Epoch 4/15
1999/2000 [============================&gt;.] - ETA: 0s - loss: 3.9983e-07 - accuracy: 1.0000   
Epoch 00004: saving model to trainingCheckpoints/cp.ckpt
2000/2000 [==============================] - 1258s 629ms/step - loss: 3.9974e-07 - accuracy: 1.0000 - val_loss: 2.3884 - val_accuracy: 0.7300
Epoch 5/15
1999/2000 [============================&gt;.] - ETA: 0s - loss: 9.4587e-08 - accuracy: 1.0000   
Epoch 00005: saving model to trainingCheckpoints/cp.ckpt
2000/2000 [==============================] - 1246s 623ms/step - loss: 9.4558e-08 - accuracy: 1.0000 - val_loss: 2.4653 - val_accuracy: 0.7290
Epoch 6/15
1999/2000 [============================&gt;.] - ETA: 0s - loss: 1.5035e-08 - accuracy: 1.0000   
Epoch 00006: saving model to trainingCheckpoints/cp.ckpt
2000/2000 [==============================] - 1246s 623ms/step - loss: 1.5029e-08 - accuracy: 1.0000 - val_loss: 2.5288 - val_accuracy: 0.7280
Epoch 7/15
1999/2000 [============================&gt;.] - ETA: 0s - loss: 1.3738e-09 - accuracy: 1.0000   
Epoch 00007: saving model to trainingCheckpoints/cp.ckpt
2000/2000 [==============================] - 1252s 626ms/step - loss: 1.3735e-09 - accuracy: 1.0000 - val_loss: 2.5750 - val_accuracy: 0.7230
Epoch 8/15
1999/2000 [============================&gt;.] - ETA: 0s - loss: 7.3145e-11 - accuracy: 1.0000   
Epoch 00008: saving model to trainingCheckpoints/cp.ckpt
2000/2000 [==============================] - 1223s 611ms/step - loss: 7.3109e-11 - accuracy: 1.0000 - val_loss: 2.6125 - val_accuracy: 0.7240
Epoch 9/15
1999/2000 [============================&gt;.] - ETA: 0s - loss: 2.3295e-12 - accuracy: 1.0000   
Epoch 00009: saving model to trainingCheckpoints/cp.ckpt
2000/2000 [==============================] - 1168s 584ms/step - loss: 2.3283e-12 - accuracy: 1.0000 - val_loss: 2.6299 - val_accuracy: 0.7250
Epoch 10/15
1999/2000 [============================&gt;.] - ETA: 0s - loss: 6.9884e-13 - accuracy: 1.0000   
Epoch 00010: saving model to trainingCheckpoints/cp.ckpt
2000/2000 [==============================] - 1164s 582ms/step - loss: 6.9850e-13 - accuracy: 1.0000 - val_loss: 2.6467 - val_accuracy: 0.7250
Epoch 11/15
1999/2000 [============================&gt;.] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000   
Epoch 00011: saving model to trainingCheckpoints/cp.ckpt
2000/2000 [==============================] - 1166s 583ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.6628 - val_accuracy: 0.7250
Epoch 12/15
1999/2000 [============================&gt;.] - ETA: 0s - loss: 4.6589e-13 - accuracy: 1.0000   
Epoch 00012: saving model to trainingCheckpoints/cp.ckpt
2000/2000 [==============================] - 1169s 584ms/step - loss: 4.6567e-13 - accuracy: 1.0000 - val_loss: 2.6900 - val_accuracy: 0.7280
Epoch 13/15
1999/2000 [============================&gt;.] - ETA: 0s - loss: 4.3519 - accuracy: 0.7177       
Epoch 00013: saving model to trainingCheckpoints/cp.ckpt
2000/2000 [==============================] - 1172s 586ms/step - loss: 4.3535 - accuracy: 0.7176 - val_loss: 7.7116 - val_accuracy: 0.5000
Epoch 14/15
1999/2000 [============================&gt;.] - ETA: 0s - loss: 7.7118 - accuracy: 0.5000   
Epoch 00014: saving model to trainingCheckpoints/cp.ckpt
2000/2000 [==============================] - 1157s 579ms/step - loss: 7.7119 - accuracy: 0.5000 - val_loss: 7.7108 - val_accuracy: 0.5000
Epoch 15/15
1999/2000 [============================&gt;.] - ETA: 0s - loss: 7.7103 - accuracy: 0.5000   
Epoch 00015: saving model to trainingCheckpoints/cp.ckpt
2000/2000 [==============================] - 1162s 581ms/step - loss: 7.7105 - accuracy: 0.5000 - val_loss: 7.7141 - val_accuracy: 0.5000
```",4,1
80,2019-10-27,2019,10,27,22,dntay1,Help: Installing Tensorflow on Windows 10,https://www.reddit.com/r/tensorflow/comments/dntay1/help_installing_tensorflow_on_windows_10/,Raj_CSH,1572183342,"I have been trying to install tensorflow for countless hours on windows through pip and anaconda with the guide listed on the website, but nothing is working. I'm really stuck. I'm using python 3.8.0.",15,0
81,2019-10-28,2019,10,28,0,dnv0pp,problem with running object_detection_tutorial.ipynb file in windows 10 using gpu,https://www.reddit.com/r/tensorflow/comments/dnv0pp/problem_with_running_object_detection/,smukh98,1572190704,"hey all,

I started with tensorflow object detection api  and wanted to run the object detection tutorial file in jupyter .

But no results would show up and i havent edited the code .Only a message to show that jupyter notebook kernel has stopped working. Has it happened with anyone else.

&amp;#x200B;

Following are the details:

**System information**
What is the top-level directory of the model you are using:
\\models\\research\\object\_detection\\

\*\*Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\*\*NO, trying to use object\_detection\_tutorial.ipynb

**OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Windows 10

\*\*TensorFlow installed from (source or binary):\*\*installed using pip(pip install tensorflow-gpu)

\*\*TensorFlow version (use command below):\*\*v2.0.0

\*\*Bazel version (if compiling from source):\*\*N/A

\*\*CUDA/cuDNN version:\*\*CUDA Version 10.0.130cuDNN: 7.6.4

\*\*GPU model and memory:\*\*GeForce GTX 1050 4 GB dedicated, 3.9 GB shared

\*\*Exact command to reproduce:\*\*runt the object\_detection\_tutorial.ipynb file

**Describe the problem**
it got stuck at the loop where the image results were meant to be shown i.e.:-

for image\_path in TEST\_IMAGE\_PATHS: show\_inference(detection\_model, image\_path)

.It stayed here until the jupyter notebook dispalyed a message saying kernel has died.When tried to run it in anaconda prompt ,the following was displayed at the end after which the no images were shown and the process ended.

&gt;W tensorflow/stream\_executor/cuda/redzone\_allocator.cc:312\] Internal: Invoking ptxas not supported on WindowsRelying on driver to perform ptx compilation. This message will be only logged once.

Please look into this matter.

&amp;#x200B;

&amp;#x200B;

Thanks in advance",0,1
82,2019-10-28,2019,10,28,6,dnzrey,[Project] Fast SRGAN in Tensorflow 2.0,https://www.reddit.com/r/tensorflow/comments/dnzrey/project_fast_srgan_in_tensorflow_20/,abnormdist,1572213362,"Hey there,

&amp;#x200B;

So I've been wanting to create a Fast version of the image super resolution GAN. This is for scenarios when you may not have high speed internet, but can leverage your laptop GPU for streaming low res videos synthetical upsampled to larger resolutions. It is written in tensorflow 2: [Fast SRGAN](https://github.com/HasnainRaz/Fast-SRGAN)",0,3
83,2019-10-28,2019,10,28,7,do01ho,How to Code Neat Machine Learning Pipelines,https://www.reddit.com/r/tensorflow/comments/do01ho/how_to_code_neat_machine_learning_pipelines/,GChe,1572214743,,1,5
84,2019-10-28,2019,10,28,9,do1lnn,Tensorflow is way slower on my new laptop,https://www.reddit.com/r/tensorflow/comments/do1lnn/tensorflow_is_way_slower_on_my_new_laptop/,CaptSoban,1572222828,"I recently bought a new laptop that is way more powerful than my older one, and I tried running the same algorithm on it. The learing was litterally 1000 times slower, each sample was taking 1ms, compared to the other, which takes 1us instead. I was using keras aswell. 

I know it's not python because I compared the python performance aswell. Did someone ever have a similar problem? If so, how can I solve it?",0,1
85,2019-10-28,2019,10,28,10,do29rj,Tensorflow 2.0.0 way slower than 1.14.0,https://www.reddit.com/r/tensorflow/comments/do29rj/tensorflow_200_way_slower_than_1140/,CaptSoban,1572226572,"I recently bought a new laptop, and I tried running the same algorithm that I was writing on my old computer. I installed python, tensorflow and all the other librairies that I needed without paying attention to the version of tensorflow that pip installed. 

The performance was terrible, every sample was litterally taking 1000x more time to process. After doing some digging, I reinstalled the older version, and everything was working fine.

Is there a reason why it happens?",0,1
86,2019-10-28,2019,10,28,11,do2ycj,Installing tensorflow with GPU support on windows 10 - Need help,https://www.reddit.com/r/tensorflow/comments/do2ycj/installing_tensorflow_with_gpu_support_on_windows/,EbryJoss,1572230268,"Hi everyone

&amp;#x200B;

Over the past few days I've been trying to install tensorflow with gpu support. I'm trying to build the library from source using bazel.

I'm using windows 10. My PC has a GTX 1070 and AMD Ryzen 5 2600.

I've tried different combinations of Python, TF, CUDA, cuDNN and bazel. I always get stuck on the final step - building from source using bazel. 

So to save myself going through the entire process another dozen times, I'm wondering if anyone has successfully installed tensorflow-gpu by following this guide?",3,0
87,2019-10-29,2019,10,29,1,doaxh6,where can i get a Tensorflow 2.0 pre trained model,https://www.reddit.com/r/tensorflow/comments/doaxh6/where_can_i_get_a_tensorflow_20_pre_trained_model/,nigamelastic,1572278908,"Hello since in tensorflow 2.0 we can save and load a model and then work on it to custom train it? I cant find the tutorials on object detection for 2.0 so all links are much appreciated .  
 

What i already know:  
1) I am a noob done very lil in ML(not professionally), and made the text and image classification from the official tf guide

2)i have seen a few tutorials but only on version 1.x with object detection and offcourse the official repo here :  [https://github.com/tensorflow/models/blob/master/research/object\_detection](https://github.com/tensorflow/models/blob/master/research/object_detection)",2,1
88,2019-10-29,2019,10,29,3,dod2h6,Tensorflow 2.0 on ubuntu 18.04 server,https://www.reddit.com/r/tensorflow/comments/dod2h6/tensorflow_20_on_ubuntu_1804_server/,capricornfati,1572287862,"Hello guys!

I have been setting up a pc with nvdia gpu to study DL. I and two of my friends are going to use this pc by connecting on vnc server. 

My question is that how should I install tf so that my friends can use it on their own accounts. ( they are not sudo er, I am the admin)? If I install via anaconda it will lead me to create a virtual env. If I do this way, how are they going to use tf on via anaconda?

I hope that my question is clear :)
Thank you.",7,6
89,2019-10-30,2019,10,30,2,dot7eu,Request for assistance on how I can modify this code on Bayesian Neural Network Regression to suit Binary Classification,https://www.reddit.com/r/tensorflow/comments/dot7eu/request_for_assistance_on_how_i_can_modify_this/,elvindavin,1572370578,"Here is the code and the full link just in case someone may like to have an in depth understanding of the code.

    class BayesianDenseRegression(tf.keras.Model):
        """"""A multilayer Bayesian neural network regression
        
        Parameters
        ----------
        dims : List[int]
            List of units in each layer
        name : str
            Name for the network
            
        Attributes
        ----------
        losses : tensorflow.Tensor
            Sum of the KullbackLeibler divergences between
            the posterior distributions and their priors, 
            over all layers in the network
            
        Methods
        -------
        call : tensorflow.Tensor
            Perform the forward pass of the data through
            the network, predicting both means and stds
        log_likelihood : tensorflow.Tensor
            Compute the log likelihood of y given x
        samples : tensorflow.Tensor
            Draw multiple samples from the predictive distribution
        """"""    
        
        
        def __init__(self, dims, name=None):
            
            super(BayesianDenseRegression, self).__init__(name=name)
            
            # Multilayer fully-connected neural network to predict mean
            self.loc_net = BayesianDenseNetwork(dims)
            
            # Variational distribution variables for observation error
            self.std_alpha = tf.Variable([10.0], name='std_alpha')
            self.std_beta = tf.Variable([10.0], name='std_beta')
    
        
        def call(self, x, sampling=True):
            """"""Perform forward pass, predicting both means + stds""""""
            
            # Predict means
            loc_preds = self.loc_net(x, sampling=sampling)
        
            # Predict std deviation
            posterior = tfd.Gamma(self.std_alpha, self.std_beta)
            transform = lambda x: tf.sqrt(tf.math.reciprocal(x))
            N = x.shape[0]
            if sampling:
                std_preds = transform(posterior.sample([N]))
            else:
                std_preds = tf.ones([N, 1])*transform(posterior.mean())
        
            # Return mean and std predictions
            return tf.concat([loc_preds, std_preds], 1)
        
        
        def log_likelihood(self, x, y, sampling=True):
            """"""Compute the log likelihood of y given x""""""
            
            # Compute mean and std predictions
            preds = self.call(x, sampling=sampling)
            
            # Return log likelihood of true data given predictions
            return tfd.Normal(preds[:,0], preds[:,1]).log_prob(y[:,0])
        
        
        @tf.function
        def sample(self, x):
            """"""Draw one sample from the predictive distribution""""""
            preds = self.call(x)
            return tfd.Normal(preds[:,0], preds[:,1]).sample()
        
        
        def samples(self, x, n_samples=1):
            """"""Draw multiple samples from the predictive distribution""""""
            samples = np.zeros((x.shape[0], n_samples))
            for i in range(n_samples):
                samples[:,i] = self.sample(x)
            return samples
        
        
        @property
        def losses(self):
            """"""Sum of the KL divergences between priors + posteriors""""""
                    
            # Loss due to network weights
            net_loss = self.loc_net.losses
    
            # Loss due to std deviation parameter
            posterior = tfd.Gamma(self.std_alpha, self.std_beta)
            prior = tfd.Gamma(10.0, 10.0)
            std_loss = tfd.kl_divergence(posterior, prior)
    
            # Return the sum of both
            return net_loss + std_loss
    

NB: The link to the full code:  [https://brendanhasz.github.io/2019/07/23/bayesian-density-net.html](https://brendanhasz.github.io/2019/07/23/bayesian-density-net.html)",0,0
90,2019-10-30,2019,10,30,3,dotjpf,Are Tensorflow Feature Columns going to go away?,https://www.reddit.com/r/tensorflow/comments/dotjpf/are_tensorflow_feature_columns_going_to_go_away/,krishnab75,1572372045,"I was reading Aurelien Geron's new version of the *Hands-On Machine Learning ... v2.0* and he says that the Tensorflow Feature Columns API will likely be superseded by Keras Preprocessing Layers. I just wanted to know how true this is, since I can't seem to find any announcements or even discussions about this. Here is the actual quote from his book below. 

&amp;#x200B;

&gt;The TensorFlow team is working on providing a set of standard Keras preprocessing layers. They will probably be available by the time you read this; however, the API may change slightly by then, so please refer to the notebook for this chapter if anything behaves unexpectedly. This new API will likely **supersede** the existing Feature Columns API, which is harder to use and less intuitive (if you want to learn more about the Feature Columns API anyway, please check out the notebook for this chapter).\[bolding is my own\]

&amp;#x200B;

I don't want to start down the road developing models with Feature Columns if they will all break in a month or two. Does anyone else have any knowledge or insight into this? Does not seem like the preprocessing layers are any where near as mature as the Feature Columns api, so was just wondering where Google and Keras are with this.",2,1
91,2019-10-30,2019,10,30,4,doupm2,[Book] Facebook Page of Generative Adversarial Networks Projects by Kailash Ahirwar,https://www.reddit.com/r/tensorflow/comments/doupm2/book_facebook_page_of_generative_adversarial/,kailashahirwar12,1572376856,[removed],0,1
92,2019-10-30,2019,10,30,9,dozdgv,De-normalisation,https://www.reddit.com/r/tensorflow/comments/dozdgv/denormalisation/,GeorgeFree2018,1572396705,"I've finally got around to building my first model in Tensorflow today. It's a multivariate time series where the data is normalised. I opted to use tf.math.l2_normalize for this. Because I've normalised the training data, and therefore the validation data, also, the output of my model is normalised but I would like to get a de-normalised value out - real world.

How would I go about this? I presume this is relatively common?",1,3
93,2019-10-30,2019,10,30,10,dozyt6,Applying a function to a list of lists,https://www.reddit.com/r/tensorflow/comments/dozyt6/applying_a_function_to_a_list_of_lists/,psyyduck,1572399466,"Hi all, I can't for the life of me figure out how to do this when the lists have variable lengths

```
lambdaFunc = lambda x: CUSTOM_FN(x) #custom fn is something like tf.reduce_mean

test = np.array([ [1,2,3],[4,5] ]) #Data, from a python function that does batching

tf.map_fn(lambdaFunc, test) #TypeError: Expected binary or unicode string, got [1, 2, 3]

```",7,1
94,2019-10-30,2019,10,30,13,dp1ppk,"Tensorflow 2.0 Custom Loss Functions, Adding a Regularizer",https://www.reddit.com/r/tensorflow/comments/dp1ppk/tensorflow_20_custom_loss_functions_adding_a/,4thofthe4th,1572408508,"I'm looking to construct a custom loss function in Tensorflow 2.0 where I add my own regularization for the weights. For example, a function r such that my loss function is something of the form:

L(y,x) + r(w)

where 'w' represents the weights. In Tensorflow 1.0 this is fairly straightforward as the weights are initialized using tf.get\_variable and then passed to tf.nn.conv2d as the filter; so I need only call these weights in my loss function. However, in Tensorflow 2.0 with Keras, my understanding is that one can use tensorflow.keras.layers.Conv2D to directly construct the layers and so it isn't too clear to me where the weights are saved as a trainable variable. Or would I need to write a custom regularizer for tf.keras.regularizer?",0,3
95,2019-10-30,2019,10,30,20,dp5pdm,Why not deployment by code generation?,https://www.reddit.com/r/tensorflow/comments/dp5pdm/why_not_deployment_by_code_generation/,jerha202,1572436650,"I'm an embedded systems engineer who wants to use TensorFlow to train a model for some advanced sensor signal processing. While I like TF's modelling and exploration capabilities, I'm surprised by how complicated it is to deploy the trained model (the inference) - at least for microcontrollers. I'm fully aware of TensorFlow Lite, but it only supports a subset of operations, and getting it all up and running is cumbersome, to say the least.

In many modelling tools for embedded systems, this problem is typically solved by code generation. (Don't confuse this with machine learning models that generate code, that's not what I mean). I mean a tool that takes the trained model and generates a C/Java/Swift/Python/whatever file containing a function that takes the input vector, runs the inference on it and returns the output vector. No libraries, no dependencies, just a plain file with standard code, all weights and everything included, ready to be compiled together with my target project.

Why doesn't this exist for TensorFlow? Why haven't I even found anyone asking for it? Am I the only one who needs this? What am I missing?",10,8
96,2019-10-31,2019,10,31,1,dp99m1,What are the return values for model.evaluate(),https://www.reddit.com/r/tensorflow/comments/dp99m1/what_are_the_return_values_for_modelevaluate/,Noahwar97,1572453715,"What does model.evaluate() return? On the tensorflow website, for the beginners basic image classification section. It says that it returns both loss and accuracy but my code doesnt work when I try to run it. Any help fixing this would be greatly appreciated 


https://www.tensorflow.org/tutorials/keras/classification",0,1
97,2019-10-31,2019,10,31,6,dpd1c2,TensorFlow Enterprise,https://www.reddit.com/r/tensorflow/comments/dpd1c2/tensorflow_enterprise/,_spicyramen,1572470319,,0,14
98,2019-10-31,2019,10,31,10,dpg3a1,How to get training time per epoch using TPUEstimator?,https://www.reddit.com/r/tensorflow/comments/dpg3a1/how_to_get_training_time_per_epoch_using/,ejayshun,1572483623,"Feel free to read this [post](https://stackoverflow.com/questions/58634188/how-to-get-training-time-for-each-epoch-using-tpuestimator).

I am unsure how to obtain the training time for each epoch. Currently, I have a TPUEstimator object that I train with **estimator.train()**, but I just get back global steps and loss without time:  https://i.stack.imgur.com/IkD5H.png


I'm trying to replicate the output found [here](https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/mnist_tpuestimator.ipynb): https://i.stack.imgur.com/gDTzd.png


I feel like maybe I have to set logging output from Tensorflow. However, I'm unsure how to do that.",0,2
0,2019-11-1,2019,11,1,19,dq2k8b,Can anyone please help me with adding a crf_forward() layer to a Sequential model?,https://www.reddit.com/r/tensorflow/comments/dq2k8b/can_anyone_please_help_me_with_adding_a_crf/,Microbot_,1572605366,"Hello everyone,

I am trying to use tensor flow 2 to develop a simple model for naked entity recognition. For that I have been using a Sequential model and then added layers to it. I want to add crf layer at the end inorder to get the output but I am not sure how to do that. If it was with keras I know what to do , like ill first define a model and then add layers to it. Then ill create a crf object from CRF class and then Pass my model to the object. I am not sure how to do this.

I have tried following similar way as to create a crf object but I get an error saying ""missing three required position al arguments"".
Can anyone please help me how to implekent crf in tensor flow model? Thank you.",2,2
1,2019-11-1,2019,11,1,20,dq35u7,Getting started with tensorflow JS project,https://www.reddit.com/r/tensorflow/comments/dq35u7/getting_started_with_tensorflow_js_project/,StressedOutBox,1572609088,"So, I'm looking to get started with a JS project. I'm looking to create a gesture based image recognition tool where if I preform X gesture it would preform Y action. However, I'm not quite sure how it works. So from my current understanding, I'll need to take pictures of me preforming that gesture and than have the dataset be used to detect the said gesture? 

&amp;#x200B;

Could someone also provide me a place where I can get started because this is quite confusing for a beginner like me.",2,5
2,2019-11-2,2019,11,2,8,dqcc2a,"Possible to add tf.signal.mfccs_from_log_mel_spectrograms as a custom ""preprocessing""-layer""?",https://www.reddit.com/r/tensorflow/comments/dqcc2a/possible_to_add_tfsignalmfccs_from_log_mel/,goodiegoodgood,1572651197,"I've been getting my feet wet with Tensorflow in the last weeks, and have build some sequential models. I would like to add the mfcc-converison *into the model* as a first layer, is that possible? 

It would be really nice if I could feed the network raw sound-data (PCM) and convert it to mfcc before it reaches the CNN-layer.  
Thanks in advance for any help :)",4,2
3,2019-11-2,2019,11,2,17,dqh8lg,Starting point for a continous sign language recognition in tensorflow.js?,https://www.reddit.com/r/tensorflow/comments/dqh8lg/starting_point_for_a_continous_sign_language/,R1BNC,1572681659,"Hi, I need some advise to start my project, it is a sign language recognition (not per letter) but per word/phrase. I want to start this project in tensorflow.js? Will that be possible?

Is video captioning is a good starting point or just a gesture classification?

The datasets will be a person performing the  sign languages per word/phrase ( I may need to create my own since no one has done this before). What is the best method to use? 3D CNN (will this work with TF.js?) 

I found a github, it is the alexa sign language recognition but the author said that he used K nearest neighbors, but it is only limited to few data set. I would want just the basic sign language words. I am just beginning tensorflow.

Thank You",0,7
4,2019-11-3,2019,11,3,9,dqtd05,How do I operate an older version of tensorflow when I am already running on tf 2.0?,https://www.reddit.com/r/tensorflow/comments/dqtd05/how_do_i_operate_an_older_version_of_tensorflow/,TYLER_DURDEN_JIMMY,1572742202,"Im trying to run on tf 1.14 because the lab I will be working in has been coding on tf 1. However, when I am using Jupyter Notebook, stuck with tf 2.0. Any suggestions?",11,2
5,2019-11-4,2019,11,4,5,dr61p6,Input function - struggling to work with variable-length arrays/lists,https://www.reddit.com/r/tensorflow/comments/dr61p6/input_function_struggling_to_work_with/,wuthuong,1572812264,"Hi there, I have a dataset with a number of different shapes and sizes that I want to use to train a model.

The data is in a pandas dataframe. Some of the features are lists containing a variable amount of string items. For example one data point could look like this: \['item1', 'item2', 'item3'\] while another may look like: \['item1'\] or sometimes even : \[\] 

From what I have gathered, I need to use from\_generator for that specific column to build a dataset. I have done this by defining a very simple generator function:

  def array\_generator(dataframe\_column):

for i in dataframe\_column:

yield (i)

And then: 

new\_ds = tf.data.Dataset.from\_generator(lambda: array\_generator(dataframe\[column\_name\]), (tf.string), (tf.TensorShape(\[None\])))

My thinking was that the tf.TensorShape(\[None\]) would take care of the variable-length aspect of my data, but when I go ahead and turn it into an iterator and use next it flags an error.

new\_ds = new\_ds.batch(10).take(1).\_\_iter\_\_()

next(new\_ds)

 InvalidArgumentError: Cannot batch tensors with different shapes in component 0. First element had shape \[1\] and element 1 had shape \[3\]. \[Op:IteratorGetNextSync\] 

Appreciate if someone can offer advice and show me where I am going wrong with this. Thanks in advance!",9,3
6,2019-11-5,2019,11,5,4,drmg2n,Use custom imageset in tutorial,https://www.reddit.com/r/tensorflow/comments/drmg2n/use_custom_imageset_in_tutorial/,ZerxXxes,1572894754,"Hi, I am reading through the tutorials and want to try the [DCGAN](https://www.tensorflow.org/tutorials/generative/dcgan) but with a custom image-set.

As I understand it the 

    tf.keras.datasets.mnist.load_data()

function will return the images as some kind of numpy arrays?

I have a folder of png-images, how can I process them to the same kind of arrays as the rest of the code expects?",2,1
7,2019-11-5,2019,11,5,6,dronx6,Why does uint8 quantized model take longer to infer one image than original model?,https://www.reddit.com/r/tensorflow/comments/dronx6/why_does_uint8_quantized_model_take_longer_to/,Phat_N_Sassy33,1572903477,"Hello!

I recently trained a CNN on MNIST. I used quantization aware training and then quantized to a uint8 model using the tf-lite converter. Can anyone explain why the average time to run .predict on the original model is shorter than running .invoke on the quantized model? This is against my intuition because I assumed the quantized model would run faster because it uses integer math instead of floating point math.

Thanks!",4,1
8,2019-11-5,2019,11,5,7,drp8tm,Nice article on tensorflow 2 and Learning Rates,https://www.reddit.com/r/tensorflow/comments/drp8tm/nice_article_on_tensorflow_2_and_learning_rates/,shawemuc,1572905905,,1,6
9,2019-11-5,2019,11,5,15,drvkw0,Why UNet inference time grows when I add more classes for segmentation?,https://www.reddit.com/r/tensorflow/comments/drvkw0/why_unet_inference_time_grows_when_i_add_more/,gogasius,1572936799,"I don't understand why inference time grows. I trained UNet with mobilenetv2 backbone for single class segmentation and got ~0.02 inference time for 512x512 rgb image. I added output classes for same model and got ~0.024 time for 6 classes and also tested time for 100 classes with ~0.1 result. I measured time in python tf 1.14 and using C API but both results are comparable. 

The problem is that I don't understand why inference time grows and how to avoid it if it is possible. I thought that the number of output classes should not influence inference time significantly because the model remains the same and only last layer changes, so the number of performed operations should not increase too much. So is this normal or I have some hardware or code problems?

My computer configuration is: i7-6700k, 64 GB RAM, geforce GTX 1080.",2,2
10,2019-11-5,2019,11,5,18,drx2dn,Tensorboard flush crashes?,https://www.reddit.com/r/tensorflow/comments/drx2dn/tensorboard_flush_crashes/,Jandevries101,1572947697,"In tensorboard/tensorboardx I am facing a crash in my run without an Error. Its weird And the run Just stops/freezes, script doesnt end But it Also doesnt give me an Error. I calculated that this happens around 40% of my runs so Its not always But it happens to often. 

I also found out that the moment of crash is at the flush time of tensorboard of 2 minutes into the run aka 120 seconds. Are there any known issues of tensorboard freezing your script? I think it may have something to do that Its unable to write the event files. On a crash it shows that he has written the files in a map, But if youd try to delete them it would Say the file is still in use, thus making me think it crashed mid writing. 

Does anyone have an idea?",0,1
11,2019-11-5,2019,11,5,22,drz4fk,Why does TensorFlow not provide AVX2/FMA implementations out of the box in the default wheel?,https://www.reddit.com/r/tensorflow/comments/drz4fk/why_does_tensorflow_not_provide_avx2fma/,Dobias,1572960422,"When working without a GPU, one quickly runs into `Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA` messages. To improve performance, it's helpful to find and install a wheel that was compiled with those CPU instructions (or compile manually).

Since the library should work on older CPU architectures too, it, of course, does not make sense to only support new CPUs.

Would it be possible for the TensorFlow binaries to have pre-compiled versions of the core algorithms for multiple CPU-instruction sets and then dynamically dispatch (adjusting some function pointers) after checking for the available CPU while starting up? I'm not familiar with how the library is built, but from an ivory-tower perspective, it sounds like a good solution to me.",5,3
12,2019-11-5,2019,11,5,23,drzt1p,How did TensorFlow increase its convolution-on-CPU performance that much between versions 1.13.2 and 1.15.0?,https://www.reddit.com/r/tensorflow/comments/drzt1p/how_did_tensorflow_increase_its_convolutiononcpu/,Dobias,1572963773,"I've noticed, TensorFlow has become a lot faster. I verified using the following test code:

    # conv2d_performance_test.py
    import datetime

    import numpy as np
    import tensorflow as tf
    from tensorflow.keras.layers import Input, Conv2D
    from tensorflow.keras.models import Model

    inputs = Input(shape=(1024, 1024, 3))
    x = Conv2D(128, (3, 3))(inputs)
    model = Model(inputs=inputs, outputs=x)
    model.compile(loss='categorical_crossentropy', optimizer='nadam')

    data_in = np.random.normal(size=(1, 1024, 1024, 3))
    model.predict(data_in)
    print(f'tensorflow=={tf.__version__}')
    for _ in range(5):
        start_time = datetime.datetime.now()
        model.predict(data_in)
        duration = datetime.datetime.now() - start_time
        print('Forward pass took {} s.'.format(duration.total_seconds()))

Running with different TensorFlow versions:

    sudo pip3 uninstall tensorflow -y
    sudo pip3 install tensorflow==1.13.1
    CUDA_VISIBLE_DEVICES='' taskset --cpu-list 1 python3 conv2d_performance_test.py
    sudo pip3 uninstall tensorflow -y
    sudo pip3 install tensorflow==1.13.2
    CUDA_VISIBLE_DEVICES='' taskset --cpu-list 1 python3 conv2d_performance_test.py
    sudo pip3 uninstall tensorflow -y
    sudo pip3 install tensorflow==1.14.0
    CUDA_VISIBLE_DEVICES='' taskset --cpu-list 1 python3 conv2d_performance_test.py
    sudo pip3 uninstall tensorflow -y
    sudo pip3 install tensorflow==1.15.0
    CUDA_VISIBLE_DEVICES='' taskset --cpu-list 1 python3 conv2d_performance_test.py
    sudo pip3 uninstall tensorflow -y
    sudo pip3 install tensorflow==2.0.0
    CUDA_VISIBLE_DEVICES='' taskset --cpu-list 1 python3 conv2d_performance_test.py

Results (on an Intel Core i5-6600 CPU @ 3.30GHz):

    tensorflow==1.13.1
    Forward pass took 0.949945 s.
    Forward pass took 0.952494 s.
    Forward pass took 0.948515 s.
    Forward pass took 0.950895 s.
    Forward pass took 0.96188 s.

    tensorflow==1.13.2
    Forward pass took 0.943243 s.
    Forward pass took 0.947731 s.
    Forward pass took 0.942158 s.
    Forward pass took 0.94615 s.
    Forward pass took 0.946767 s.

    tensorflow==1.14.0
    Forward pass took 0.758585 s.
    Forward pass took 0.75338 s.
    Forward pass took 0.749206 s.
    Forward pass took 0.74818 s.
    Forward pass took 0.74659 s.

    tensorflow==1.15.0
    Forward pass took 0.518368 s.
    Forward pass took 0.520312 s.
    Forward pass took 0.517211 s.
    Forward pass took 0.520846 s.
    Forward pass took 0.51732 s.

    tensorflow==2.0.0
    Forward pass took 0.59772 s.
    Forward pass took 0.597734 s.
    Forward pass took 0.595437 s.
    Forward pass took 0.595418 s.
    Forward pass took 0.587147 s.

`0.95 s` to `0.59 s` is pretty amazing progress to me!

Since I'm maintaining [a library](https://github.com/Dobiasd/frugally-deep) that also needs fast convolution on CPU, I'm very interested in learning what the TensorFlow developers did to achieve that. The commit history of the TensorFlow repository is very long, so I was hoping for somebody who can point me in the right direction. :D",7,16
13,2019-11-6,2019,11,6,2,ds2rkj,Training tensor2tensor on my own dataset?,https://www.reddit.com/r/tensorflow/comments/ds2rkj/training_tensor2tensor_on_my_own_dataset/,kausarahmad,1572976261,"I'm working on a project where I'm required to train T2T on a custom dataset.

I've looked at tensor2tensor's own brief documentation ([https://tensorflow.github.io/tensor2tensor/new\_problem.html](https://tensorflow.github.io/tensor2tensor/new_problem.html)) on how to do this. I have also browsed the short amount of implementations available online which are either unclear or incomplete.

As you can infer by now, I haven't found a very clear solution yet. Why is there a general lack of discussion about this? Have any of you trained t2t on your own dataset?",0,4
14,2019-11-6,2019,11,6,3,ds3d7g,Creating a Machine Learning Framework on the top of Tensorflow,https://www.reddit.com/r/tensorflow/comments/ds3d7g/creating_a_machine_learning_framework_on_the_top/,Kaljit,1572978778,"Hey Wizards, I am creating a Machine Learning a Framework on the top of Tensorflow to accelerate the compute involved on GPUs. Any suggestions are welcome!!!!

Here's the GitHub link of my code: 

 [https://github.com/kaljitism/TensorML](https://github.com/kaljitism/TensorML)",2,0
15,2019-11-6,2019,11,6,12,dsals2,How to incorporate preprocessing pipeline into Tensorflow serving?,https://www.reddit.com/r/tensorflow/comments/dsals2/how_to_incorporate_preprocessing_pipeline_into/,EthanPhan,1573011437,"I've just fine-tuned a text classification model using DistilBertT from HuggingFace. Now I want to serve my model with tensorflow serving but the problem is I don't know how to add the preprocessing pipeline ( tokenization, truncating , etc) into the server. 1 solution that I know is using another service for data preprocessing but It's not an elegant solution. Any idea how to solve this? can I use tf.Transform to construct a pipeline with arbitrary python code?",4,1
16,2019-11-6,2019,11,6,17,dsdpk7,Detecting hand-marked video clips with TensorFlow,https://www.reddit.com/r/tensorflow/comments/dsdpk7/detecting_handmarked_video_clips_with_tensorflow/,smlaccount,1573030725,,0,6
17,2019-11-6,2019,11,6,22,dsgmj1,Help with tensorboard,https://www.reddit.com/r/tensorflow/comments/dsgmj1/help_with_tensorboard/,Ste29ebasta,1573048539,"Hi, i'm trying to learn tensorboard and tensorflow probability, so for this reason i was looking at the examples page and in particular at this tutorial:

 [https://github.com/tensorflow/probability/blob/master/tensorflow\_probability/examples/cifar10\_bnn.py](https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/cifar10_bnn.py) 

&amp;#x200B;

I understood more or less the ratio, but i cannot show its results on tensorboard, could you help me please? :)",3,1
18,2019-11-7,2019,11,7,2,dsjrn6,"Help with an error: ""Allocator (GPU_0_bfc) ran out of memory trying to allocate when using pure tensorflow vs no error on more complex model on keras """,https://www.reddit.com/r/tensorflow/comments/dsjrn6/help_with_an_error_allocator_gpu_0_bfc_ran_out_of/,lior_A_,1573062169,"Hi,

I'm trying to implement things I wrote in keras in tensorflow 1.14 but the thing is I get ""ran out of memory"" error but the thing is I used more complex models in keras(tf backend) with the same GPU (nvidia geforce 1050ti) and I don't get this error with the same batch size and dataset, can anyone explain why is that?

I've attached a link to my question in stackoverflow(no one have yet responded to this question)

how can I solve it without reducing my batch size?

thanks!",3,2
19,2019-11-7,2019,11,7,7,dsnit4,Tensorboard freezing script without errors?,https://www.reddit.com/r/tensorflow/comments/dsnit4/tensorboard_freezing_script_without_errors/,Jandevries101,1573078159,"Hi,

In my code I am Just using the most basic tensorboard writing code And it works fine, however it freezes the code usually around flush time. Its either tje first if not later into the run. The code stops without any shown errors And When I try to delete the event file it says there still in use. How is this possible And what is causing it?

Thanks",0,2
20,2019-11-8,2019,11,8,1,dt047k,What should i learn next?,https://www.reddit.com/r/tensorflow/comments/dt047k/what_should_i_learn_next/,gokulPRO,1573144230," I started learning sci-kit learn in python,then i started Tensorflow-Gpu. I managed to learn linear regression,non linear regression,CNN,And some neural networks with Keras. I am now actually interested in making an AI that can play games.I came to know about reinforcement learning in Tensorflow with deep-Q-learning and Genetic Algorithim . What is the difference in their usage and advantages?Which should i learn first or should i learn anything before this as an prerequisite.And also is there any other way to make an AI that can play games like snake,Mario where the AI needs to survive and gain points.",4,1
21,2019-11-8,2019,11,8,21,dtevo0,Tf.session running once,https://www.reddit.com/r/tensorflow/comments/dtevo0/tfsession_running_once/,afiqarifen95,1573216782,"I'm currently learning TensorFlow as my hobby and very new to Python.
I'm trying to do a project when a camera snaps a picture and goes to the TensorFlow directory, (the Object detection andtf.sessionalready done running).
It will detect the new image without running thetf.sessionagain. I don't want to use real-time object detection. Thank you for the help!",2,1
22,2019-11-9,2019,11,9,3,dtjq6a,Shape != int_shape,https://www.reddit.com/r/tensorflow/comments/dtjq6a/shape_int_shape/,decrement--,1573238568,"Im trying to debug this backend code, and I have a tensor of shape (None, 10, 16, None)

When I call int_shape, I get that, but if I call array_ops.shape(x), all I get is (None, None, None, None)

Anyone know why this is?",2,1
23,2019-11-9,2019,11,9,4,dtkjf1,Tensorflow with an AMD GPU in 2019/2020,https://www.reddit.com/r/tensorflow/comments/dtkjf1/tensorflow_with_an_amd_gpu_in_20192020/,mobo392,1573241927,"Does anyone have a link to someone describing their experience with tensorflow on a recent AMD GPU on Linux? Eg, the Radeon VII.

I already have an AMD RX 580 in the machine for display, this new GPU would be added for solely compute purposes. Ideally it would be a step-by-step guide to installing the drivers, dependencies, etc.",12,1
24,2019-11-9,2019,11,9,7,dtncxn,Help Installing tensorflow,https://www.reddit.com/r/tensorflow/comments/dtncxn/help_installing_tensorflow/,WesReynolds,1573253759,"I am using Python 3.7 in Visual Studio Code.

I (thought) I installed tensorflow. When I import tensorflow, I get no compiler errors. However I am having trouble accessing some of the methods. 

Here is my code:

import tensorflow as tf
tf.placeholder(tf.float32, ([None, 784])

I dont get a compiler error for tf.float32
I only get an error for tf.placeholder()

Any ideas why?",3,1
25,2019-11-9,2019,11,9,15,dtsa8s,Cost is exploding! Can anyone help me with this code. I am trying to implement a basic logistic regression code using tensorflow.,https://www.reddit.com/r/tensorflow/comments/dtsa8s/cost_is_exploding_can_anyone_help_me_with_this/,_-K1L4-_,1573280372," `import tensorflow as tf`

`import numpy as np`

&amp;#x200B;

`(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data(path='mnist.npz')`

`x_train,x_test = tf.reshape(x_train,[len(x_train),784]),tf.reshape(x_test,[len(x_test),784])`

`y_train,y_test = tf.one_hot(y_train,10),tf.one_hot(y_test,10)`

&amp;#x200B;

`learning_rate = 0.001`

`training_epochs = 25`

`batch_size = 100`

`total_batch = int(60000/batch_size)`

`display_step = 1`

&amp;#x200B;

`#tf Graph Input`

&amp;#x200B;

`x = tf.placeholder(tf.float64,[None,784])`

`y = tf.placeholder(tf.float64,[None,10])`

&amp;#x200B;

`W = tf.Variable(np.random.randn(784,10))`

`b = tf.Variable(np.random.randn(1,10))`

&amp;#x200B;

`pred = tf.nn.softmax(tf.add(tf.matmul(x,W),b))`

&amp;#x200B;

`cost = tf.reduce_mean(-tf.reduce_sum(tf.multiply(y,tf.log(pred)),1))`

&amp;#x200B;

`optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)`

&amp;#x200B;

`init = tf.global_variables_initializer()`

&amp;#x200B;

`with tf.Session() as sess:`

[`sess.run`](https://sess.run)`(init)`

`X_train,X_test =` [`sess.run`](https://sess.run)`(x_train).astype('float64'),`[`sess.run`](https://sess.run)`(x_test).astype('float64')`

`Y_train,Y_test =` [`sess.run`](https://sess.run)`(y_train).astype('float64'),`[`sess.run`](https://sess.run)`(y_test).astype('float64')`



`for epoch in range(training_epochs):`

`avg_cost = 0`

`for i in range(total_batch):`

`batch_x,batch_y = X_train[i*batch_size:(i+1)*batch_size],Y_train[i*batch_size:(i+1)*batch_size]`



`_,c =` [`sess.run`](https://sess.run)`([optimizer,cost],feed_dict = {x:batch_x,y:batch_y})`



`avg_cost += c/total_batch`







`print(""Optimization Finished!"")`",3,1
26,2019-11-10,2019,11,10,11,du5fhe,Tensorflow 1.13.1 packages do not match the hashes?,https://www.reddit.com/r/tensorflow/comments/du5fhe/tensorflow_1131_packages_do_not_match_the_hashes/,doopdooperofdopping,1573351688,"I'm having an issue with pip3 installing tensorflow version 1.13.1 onto a Raspberry Pi Zero W. It is an Linux armv6l.

Keep getting ""Packages do not match the hashes"".

What can I do to resolve this?",2,1
27,2019-11-10,2019,11,10,12,du6ib1,How can I keep the gradient of my tensor when converting from a tf.float32 to tf.int32?,https://www.reddit.com/r/tensorflow/comments/du6ib1/how_can_i_keep_the_gradient_of_my_tensor_when/,kashiman290,1573357879,"Hi everyone! I am currently trying to build a neural network that requires the use of a tf.gather function from the output of a float32 type tensor. However, the problem is that I lose my gradients through the model after using tf.cast, which I am sure is something that many people have come across before. My question is, how can I take a tf.float32 type Tensor, and change its datatype to a tf.int32 tensor such that I can use it in tensorflow functions that require integer inputs, such as tf.linspace or tf.gather? An extremely simplified example of what I am doing is seen below:

sin_tensor = tf.sin(x)

sin_tensor = tf.math.round(sin_tensor)

sin_tensor = tf.cast(sin_tensor, tf.int32)

tf.gather(other_input, sin_tensor)

The problem comes from the sin_tensor = tf.cast(sin_tensor, tf.int32). Is there any way I can get around this problem? Thanks!",2,1
28,2019-11-10,2019,11,10,13,du6muq,Tensorflow 1.14 / Ubuntu 18.04 LTS / RTX 2070 Super / CUDA 10.0,https://www.reddit.com/r/tensorflow/comments/du6muq/tensorflow_114_ubuntu_1804_lts_rtx_2070_super/,bonie10,1573358620,"**GPU:** RTX 2070S 

**Operating System &amp; Version:**  Ubuntu 18.04.03 LTS

**GPU Drivers:** nvidia-driver-430

**Tensorflow Version:**  tensorflow-gpu==1.14

**Description of Problem:**

I have been trying to install tensorflow for the past week and haven't been successful. I have wiped out my system 3 times now and I am starting from scratch one more time. Has anyone had a success installation with the RTX SUPER gpu? I am using PyCharm with python3 for the env. to install tensorflow. Any other env. suggestions? It seems like there is not much support out there for this relatively new gpu. There is no nvidia supported driver for this gpu is listed in the ndvidia website, is that an issue?. Any help would be greatly appreciate it! A step by step tutorial would be amazing!

Thank you very much.",15,1
29,2019-11-10,2019,11,10,17,du8tw1,TF is eating all my ram when training nmt example,https://www.reddit.com/r/tensorflow/comments/du8tw1/tf_is_eating_all_my_ram_when_training_nmt_example/,supercatfishpro,1573373538,"I'm following along with [this example](https://www.tensorflow.org/tutorials/text/nmt_with_attention) 
With some minor differences (I'm using my own input dataset)

Everything has gone fairly smoothly until i get to the actual training.
It seems like my training function just starts allocating memory until my computer crashes :/ (I've tried a few times while looking at my system monitor)
I found a [github issue where a guy was experienceing something similar](https://github.com/tensorflow/tensorflow/issues/32707) but it seemed like it was because his train_step function didnt have a @tf.function...
I'm not really sure what could be causing this, so any help could be appreciated. (I'll also link some of the code below)

A few extra notes. I'm running this in a jupyter notebook (i can't imagine that would be the cause), and my dataset has roughly 4x more unique tokens than the dataset used in the tutorial.

@tf.function
def train_step(inp, targ, enc_hidden):
  loss = 0

  with tf.GradientTape() as tape:
    enc_output, enc_hidden = encoder(inp, enc_hidden)

    dec_hidden = enc_hidden

    dec_input = tf.expand_dims([target_tokenizer.word_index['&lt;start&gt;']] * BATCH_SIZE, 1)

    # Teacher forcing - feeding the target as the next input
    print(f'Passing encoder outputs: {targ.shape[1]}')
    for t in range(1, targ.shape[1]):
      # passing enc_output to the decoder
      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)

      loss += loss_function(targ[:, t], predictions)

      # using teacher forcing
      dec_input = tf.expand_dims(targ[:, t], 1)

    batch_loss = (loss / int(targ.shape[1]))
    variables = encoder.trainable_variables + decoder.trainable_variables
    gradients = tape.gradient(loss, variables)
    optimizer.apply_gradients(zip(gradients, variables))
    return batch_loss

    EPOCHS = 10
    
    for epoch in range(EPOCHS):
      start = time.time()
    
      enc_hidden = encoder.initialize_hidden_state()
      total_loss = 0
      print(f'Beginning epoch {epoch + 1}')
      for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):
        batch_loss = train_step(inp, targ, enc_hidden)
        total_loss += batch_loss
        print(f'batch: {batch}, loss: {batch_loss}')
        if batch % 25 == 0:
            print(f'Epoch {epoch + 1} Batch {batch} Loss {round(batch_loss.numpy(), 4)}')
      # save model (checkpoint) every 2 epochs
      if (epoch + 1) % 2 == 0:
        checkpoint.save(file_prefix = checkpoint_prefix)
    
      print(f'Epoch {epoch + 1} Loss {round(total_loss / steps_per_epoch, 4)}')
      print(f'Time taken for 1 epoch {time.time() - start} sec\n')
    

Thanks in advance",6,1
30,2019-11-11,2019,11,11,6,duhhx9,Anyone got experience with running TF models that require multiple eg Google Corals?,https://www.reddit.com/r/tensorflow/comments/duhhx9/anyone_got_experience_with_running_tf_models_that/,beemar,1573420254,I trying to find some motherboard where I could host multiple Corals and run parallel or multiple models but no luck so far. Any pointers appreciated!,3,1
31,2019-11-11,2019,11,11,12,dum4hh,Best way to handle negative sampling in Tensorflow 2.0 with Keras,https://www.reddit.com/r/tensorflow/comments/dum4hh/best_way_to_handle_negative_sampling_in/,BatmantoshReturns,1573441253,"Tensorflow released an official guide to implementing word2vec in TF 2.0 Keras

https://www.tensorflow.org/tutorials/text/word_embeddings

However, it's missing negative sampling, which is very important in word2vec, which is unfortunate, because the original tensorflow has some great candidate sampling functions. 

My best guess on what to do is augment the model,

    model = keras.Sequential([
      layers.Embedding(encoder.vocab_size, embedding_dim),
      layers.GlobalAveragePooling1D(),
      layers.Dense(1, activation='sigmoid')
    ])

Perhaps use the functional API instead of the sequential API. 

I see that the c++ TF 2.0 has candidate sampling ops https://www.tensorflow.org/api_docs/cc/group/candidate-sampling-ops

Can these be incorporated into Keras?",0,1
32,2019-11-11,2019,11,11,19,duqjla,Transfer Learning with TensorFlow 2,https://www.reddit.com/r/tensorflow/comments/duqjla/transfer_learning_with_tensorflow_2/,RubiksCodeNMZ,1573467677,,0,1
33,2019-11-11,2019,11,11,20,dur38o,Learning TensorFlow: A Guide to Building Deep Learning Systems now 54% off,https://www.reddit.com/r/tensorflow/comments/dur38o/learning_tensorflow_a_guide_to_building_deep/,Wasoness70,1573471331,,1,1
34,2019-11-11,2019,11,11,23,dusu2u,Creating a multiclass CNN: data in csv,https://www.reddit.com/r/tensorflow/comments/dusu2u/creating_a_multiclass_cnn_data_in_csv/,mich2000222,1573481186,"Hello

I'm trying to create a CNN for image classification. I have a total of 8 classes. An image can belong to more than one class. 

Right now, I have separated a training set, validation set and test set. I have already preprocessed my images (resize) and saved them in two different folders. One folder contains the subfolders ''train'', ''valid'' and ''test'' (and the other one contains the subfolders ''train'', ''valid'' and ''test'' which each contain subfolders for the eight classes with the corresponding images in it, but because an image can belong to multiple classes some images are in multiple folders).

I have a csv file ''train_csv.csv'' that contains the filenames and the labels, a row can look like this:
    [''100.jpg'',0,0,1,0,0,1,0,0]
This row is about image ''100.jpg'' and the image belongs to class 3 and 6.

How can I best load in the images and labels into my CNN using Tensorflow 2?

Thanks in advance.",2,1
35,2019-11-12,2019,11,12,6,duz8wu,Embedding nodes with custom loss function,https://www.reddit.com/r/tensorflow/comments/duz8wu/embedding_nodes_with_custom_loss_function/,palestitch,1573507279,"Hi everyone,

as the title describes I am trying to create a model which takes as input a node with some attributes and embeds it. I couldn't find much on how to this, my current approach is using softmax as the output function and using that as the embedding after seeing that suggestion on Stackoverflow. 
Do you know of a better way to do this?
My second question is more technical. I am building my NN with keras and I would like to use a custom loss function which takes in two tensors instead of a y_data and y_pred. Is there a a way to do this? 

Please let me know if anything is unclear, I'd gladly give more details if that would help solve my problems.
Thank you so much in advance,

Stitch",0,1
36,2019-11-12,2019,11,12,13,dv4lx2,Football Frenzy ,https://www.reddit.com/r/tensorflow/comments/dv4lx2/football_frenzy_/,ojhpjhh5,1573531523,,1,1
37,2019-11-12,2019,11,12,18,dv7jye,Change operations in Graph and then execute model with changes,https://www.reddit.com/r/tensorflow/comments/dv7jye/change_operations_in_graph_and_then_execute_model/,AkinoJoy,1573550003,"Hello everyone. Im trying to change some operations in graph in simple model and then execute predict function. But operations list in graph doesn't change at all, so, predict value doesn't change also. However, in API documentation for Graph Google says:

"" get\_operations()  


Return the list of operations in the graph.

**You can modify the operations in place, but modifications to the list such as inserts/delete have no effect on the list of operations known to the graph.**""

My code:

    import tensorflow as tf
    import numpy as np
    
    mnist = tf.keras.datasets.mnist
    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    x_train, x_test = x_train / 255.0, x_test / 255.0
    
    g = tf.Graph()
    
    
    @tf.function
    def custom_operation(x):
        return x*0
    
    
    with g.as_default():
        m = tf.keras.models.Sequential(
            [
                tf.keras.layers.Flatten(input_shape=(28, 28)),
                tf.keras.layers.Dense(128, activation=""relu""),
                tf.keras.layers.Dropout(0.2),
                tf.keras.layers.Dense(10, activation=""softmax""),
            ]
        ) 
        m.compile(
            optimizer=""adam"", loss=""sparse_categorical_crossentropy"", metrics=[""accuracy""]
        )
        m.fit(x_train, y_train, epochs=5)
        m.evaluate(x_test, y_test, verbose=2)
        m.summary()
        previous_predict = np.argmax(m.predict(x_test[0, tf.newaxis]))
        
        print('Y value for simple model: {0} predicted value: {1}'.format(y_test[0], previous_predict))
        previous_operations = m._graph.get_operations()  
    
        operations = m._graph.get_operations()
        i_max = len(operations)
        i = 0
        while i &lt; i_max:
            if operations[i].type == 'Mul':
                operations[i] = custom_operation(0)
            i += 1
        post_pred = np.argmax(m.predict(x_test[0, tf.newaxis]))
        m.summary()
    
        print('Y value with changed operations: {0} predicted value: {1}'.format(y_test[0], post_pred))
        post_operations = m._graph.get_operations()

And as we can see ""previous\_operations"" and ""post\_operations"" are equal, however, ""operations"" has custom operation in right place.

So, I need to find way to change operations in Graph and then execute predict function in model with changed graph. And I have to do it without sessions. Is it even possible to do?

P.S. Im so sorry for my English.",0,1
38,2019-11-12,2019,11,12,18,dv7ma7,TensorFlow vs Caffe - Javatpoint,https://www.reddit.com/r/tensorflow/comments/dv7ma7/tensorflow_vs_caffe_javatpoint/,nehapandey01,1573550446,,0,1
39,2019-11-12,2019,11,12,20,dv8gwd,A great and thorough explanation of Convolutional Neural Networks,https://www.reddit.com/r/tensorflow/comments/dv8gwd/a_great_and_thorough_explanation_of_convolutional/,antaloaalonso,1573556438,,2,1
40,2019-11-13,2019,11,13,12,dvlygb,Out of Memory (But It Allocates Less Than I Have),https://www.reddit.com/r/tensorflow/comments/dvlygb/out_of_memory_but_it_allocates_less_than_i_have/,spot4992,1573617073,"So I get the following message:

W tensorflow/core/common\_runtime/bfc\_allocator.cc:215\] Allocator (GPU\_0\_bfc) ran out of memory trying to allocate 3.96GiB

While I realize this is not an error, I am confused. An earlier output of the same script is:

freeMemory: 9.11GiB

So why is it running out of memory when there is another 5 GiB to go?",13,1
41,2019-11-13,2019,11,13,14,dvn4a6,"Docker container ""latest-gpu-py3"" having trouble installing cuDNN/dlib",https://www.reddit.com/r/tensorflow/comments/dvn4a6/docker_container_latestgpupy3_having_trouble/,gnuforlyfe,1573623396,"I'm trying to install https://github.com/davisking/dlib on a Tensorflow Docker container invoked via `docker run --gpus all -it --rm tensorflow/tensorflow:latest-gpu-py3`. Tensorflow itself runs find and CUDA is not an issue. I am having major problems trying to install cuDNN so that I can use dlib.

Here is my compilation error message:

` -- Found CUDA: /usr/local/cuda (found suitable version ""10.0"", minimum required is ""7.5"") 
-- Looking for cuDNN install...
-- Found cuDNN: /usr/lib/x86_64-linux-gnu/libcudnn.so
-- Building a CUDA test project to see if your compiler is compatible with CUDA...
-- Checking if you have the right version of cuDNN installed.
-- Enabling CUDA support for dlib.  DLIB WILL USE CUDA
-- C++11 activated.
CMake Error: The following variables are used in this project, but they are set to NOTFOUND.
Please set them or make sure they are set and tested correctly in the CMake files:
CUDA_cublas_LIBRARY (ADVANCED)
    linked by target ""dlib"" in directory /home/project/dlib/dlib
CUDA_curand_LIBRARY (ADVANCED)
    linked by target ""dlib"" in directory /home/project/dlib/dlib
CUDA_cusolver_LIBRARY (ADVANCED)
    linked by target ""dlib"" in directory /home/project/dlib/dlib`

-- Configuring incomplete, errors occurred!
See also ""/home/project/dlib/build/CMakeFiles/CMakeOutput.log"".
See also ""/home/project/dlib/build/CMakeFiles/CMakeError.log"".
make: *** No targets specified and no makefile found.  Stop.

I am currently using this method of installing cuDNN:

(from host):

`sudo docker cp libcudnn7_7.6.5.32-1+cuda10.0_amd64.deb c7f1e218bc6f:/ &amp;&amp; sudo docker cp libcudnn7-dev_7.6.5.32-1+cuda10.0_amd64.deb c7f1e218bc6f:/ &amp;&amp; sudo docker cp libcudnn7-doc_7.6.5.32-1+cuda10.0_amd64.deb c7f1e218bc6f:/`

`#note: c7e21....is just the container ID, it will be different every time I open a new container`

(on container):

`sudo docker cp libcudnn7_7.6.5.32-1+cuda10.0_amd64.deb c7f1e218bc6f:/ &amp;&amp; sudo docker cp libcudnn7-dev_7.6.5.32-1+cuda10.0_amd64.deb c7f1e218bc6f:/ &amp;&amp; sudo docker cp libcudnn7-doc_7.6.5.32-1+cuda10.0_amd64.deb c7f1e218bc6f:/
`

When I don't install cuDNN this way, Cmake does NOT detect CUDA and therefore does NOT compile dlib with GPU support.",1,1
42,2019-11-13,2019,11,13,14,dvn7bk,How to Size Up GPU Need for External Dev Board,https://www.reddit.com/r/tensorflow/comments/dvn7bk/how_to_size_up_gpu_need_for_external_dev_board/,___sy___,1573623885,"Hey there -- I'm trying to figure out which dev board to use for some inference task I have. 

First, a bit of context: I've previously trained and saved three cnn nets on a Nvidia 1080ti. I'm now looking to perform inference on an external device using those 3 networks at a frame rate of about 5-10 fps. The external device itself is for an aerial application so it's very weight limited ( but no limits on power).

I was planning on using Tensorflow Lite to prep the nets before porting them. Beyond that, I've been looking at both Colab and Jetson, but I'm not entirely sure what is the smallest/lightest board I can get away with given that the 3 networks need to run in parallel. 

**Does anyone know if there is a good heuristic for sizing up the size of the GPU I will need on the dev board?** For example, how do I calculate my GPU memory needs? Thanks!!",0,1
43,2019-11-13,2019,11,13,17,dvou79,Trouble installing tensorflow in a VDI environment,https://www.reddit.com/r/tensorflow/comments/dvou79/trouble_installing_tensorflow_in_a_vdi_environment/,Everlast7,1573634038,"I wonder if anyone has experienced any problems installing tensorflow in a Citrix VDI environment?

I am just unable to get it installed. Somehow my VDI machine set up is making the setup process not find the appropriate tensorflow version.

Any advice is appreciated.
Thanks",2,1
44,2019-11-13,2019,11,13,23,dvsrlk,Tensorflow 2.0 InaccessibleTensorError,https://www.reddit.com/r/tensorflow/comments/dvsrlk/tensorflow_20_inaccessibletensorerror/,Cha-Dao_Tech,1573656434,"I'm prety new to Tensorflow and am just starting out, so I'm kinda confused half the time.   
Here is a Problem that I am struggling with right now.  
It is effectivley copy pasted from my Stackoverflow post, so I've provided the link to that too.  


So I'm trying to load Array Data from TFRecords. But I'm getting a Error Message while trying to parse the file Path into the Array.

If I just call t= functions.parse\_TFR\_to\_tens(filenames) with one single file path, everything works out fine, but if it is being called inside of ""process\_path"" The Error message appears. 

I have no clue what is going on, and couldn't fix the problem. after all the Function in itself works, so what am I missing? 

functions:

def \_parse\_image\_function(example\_proto):

image\_feature\_description = {

'feature3': tf.io.FixedLenFeature(\[\], tf.string),

}

&amp;#x200B;

return tf.io.parse\_single\_example(example\_proto, image\_feature\_description)

&amp;#x200B;

def parse\_TFR\_to\_tens(file\_name):

raw\_dataset = tf.data.TFRecordDataset(file\_name)

parsed\_image\_dataset = raw\_dataset.map(\_parse\_image\_function)

s = \[\]

for image\_features in parsed\_image\_dataset:

image\_raw = tf.io.parse\_tensor(image\_features\['feature3'\], out\_type=tf.float64)

s.append(image\_raw)

t = tf.stack(s)

return t

&amp;#x200B;

def process\_path(file\_path,verbose=False):

parts = tf.strings.split(file\_path, '/')

label = 0

print(parts\[-2\])

&amp;#x200B;

pd = settings.pd

l = 0

for p in pd:

if parts\[-2\] == p:

label = 1

\#return tf.io.read\_file(file\_path), label

t = parse\_TFR\_to\_tens(file\_path)

return t, label

&amp;#x200B;

def create\_ds(sets=\[True,True,True\], snaps=3, mode=1,verbose=False):

sets = settings.settings\[""sets""\]

snaps= settings.settings\[""snaps""\]

mode = settings.settings\[""mode""\]

verbose = settings.settings\[""verbose""\]

ds=\[\]

if sets\[0\]:

path = globstringPET(sets=sets,snaps=snaps,mode=mode)

list\_ds = tf.data.Dataset.list\_files(path)

labeled\_ds\_PET = list\_ds.map(process\_path)

ds.append(labeled\_ds\_PET)

if sets\[1\]:

path = globstringMRT(sets=sets, snaps=snaps, mode=mode)

list\_ds = tf.data.Dataset.list\_files(path)

labeled\_ds\_MRT = list\_ds.map(process\_path)

ds.append(labeled\_ds\_MRT)

if verbose: print(""Sets: "",ds)

first = True

for d in ds:

if first:

labeled\_ds = d

first = False

else:

labeled\_ds.concatenate(d)

&amp;#x200B;

return labeled\_ds, list\_ds

&amp;#x200B;

&amp;#x200B;

The Error Message:

&amp;#x200B;

/misc/no\_backup/d1325/CNNMEL/functions.py:257 process\_path  \*

t = parse\_TFR\_to\_tens(file\_path)

/misc/no\_backup/d1325/CNNMEL/functions.py:144 parse\_TFR\_to\_tens  \*

t = tf.stack(s)

/no\_backup/d1325/.local/lib/python3.6/site-packages/tensorflow\_core/python/util/dispatch.py:180 wrapper

return target(\*args, \*\*kwargs)

/no\_backup/d1325/.local/lib/python3.6/site-packages/tensorflow\_core/python/ops/array\_ops.py:1165 stack

return gen\_array\_ops.pack(values, axis=axis, name=name)

/no\_backup/d1325/.local/lib/python3.6/site-packages/tensorflow\_core/python/ops/gen\_array\_ops.py:6304 pack

""Pack"", values=values, axis=axis, name=name)

/no\_backup/d1325/.local/lib/python3.6/site-packages/tensorflow\_core/python/framework/op\_def\_library.py:793 \_apply\_op\_helper

op\_def=op\_def)

/no\_backup/d1325/.local/lib/python3.6/site-packages/tensorflow\_core/python/framework/func\_graph.py:544 create\_op

inp = self.capture(inp)

/no\_backup/d1325/.local/lib/python3.6/site-packages/tensorflow\_core/python/framework/func\_graph.py:603 capture

% (tensor, tensor.graph, self))

&amp;#x200B;

InaccessibleTensorError: The tensor 'Tensor(""ParseTensor:0"", dtype=float64)' cannot be accessed here: it is defined in another function or code block. Use return values, explicit Python locals or TensorFlow collections to access it. Defined in: FuncGraph(name=reduce\_reduce\_body, id=139628601725840); accessed from: FuncGraph(name=Dataset\_map\_process\_path, id=139630684432872).",8,1
45,2019-11-15,2019,11,15,2,dwd1tv,whats happed in the last year? data scientist getting back into it,https://www.reddit.com/r/tensorflow/comments/dwd1tv/whats_happed_in_the_last_year_data_scientist/,philmtl,1573753758,"pretty much i was working in data science end of 2018,  and was stuck making a python 2.7 environment since it was not compatible with python 3.0. i got hired in BI Dev have not touched TS or anything data science-related since. 

&amp;#x200B;

so what changed in a year?

just i want to be up to date for interviews ect. 

new tools or features?",3,1
46,2019-11-15,2019,11,15,13,dwlsjr,Problems with Tensorflow 1.14 and Titan X (pascal) - running on CPU?,https://www.reddit.com/r/tensorflow/comments/dwlsjr/problems_with_tensorflow_114_and_titan_x_pascal/,geometrikal,1573793535,"Anyone having problems with their Titan X (pascal) and Tensorflow 1.14?

I've got two machines - one with a 2080 Ti at home and one with a Titan X (pascal) at work. I've been doing most development at home on the 2080 Ti (CNN image classification) using TF 1.14 (1.15 has an issue) with no problems.

I upgraded the work one from TF 1.13.1 to 1.14  (using conda) and started getting weird issues where training would just freeze or stopping the training (in PyCharm) would not kill the underlying python process. 

So I did a new environment and new install (conda) and for some reason training is progressing as though it is running on CPU. It doesn't say that though, it spits out all the usual text about setting up GPU device, and even fills the GPU memory, but \_GPU usage is 0%\_ and the training speed is the same as CPU. 

Reverting to 1.13 works. I'm kinda stumped. Got the latest NVIDIA drivers and CUDA 10.0 installed... Any ideas? Been trying different permutations for two days now with no luck.",0,1
47,2019-11-15,2019,11,15,16,dwnfd0,Model not found while running run_in_docker.sh in Tensorflow Serving,https://www.reddit.com/r/tensorflow/comments/dwnfd0/model_not_found_while_running_run_in_dockersh_in/,davislf2,1573803678,"I followed [a suggested solution for issue #325 on sentencepiece](https://github.com/google/sentencepiece/issues/325#issuecomment-547610907) and changed some parts to adapt to RHEL. However, I got errors in the last step. This is my script:
```
CWD=$(pwd)
GPROTOBUF_URL=https://github.com/protocolbuffers/protobuf/releases/download/v3.7.0/protobuf-cpp-3.7.0.tar.gz

compile_gprotobuf () {
    sudo yum install autoconf automake libtool curl make gcc-c++ unzip &amp;&amp; # gcc-c++ instead of (Ubuntu) g++
    wget $GPROTOBUF_URL &amp;&amp;
    fname=protobuf-cpp-3.7.0.tar.gz &amp;&amp;
    tar xvzf $fname &amp;&amp; rm $fname &amp;&amp;
    cd protobuf-3.7.0 &amp;&amp;
    ./configure CXXFLAGS=""-D_GLIBCXX_USE_CXX11_ABI=0"" &amp;&amp;
    make &amp;&amp;
    make check &amp;&amp;
    sudo make install &amp;&amp;
    sudo ldconfig # refresh shared library cache. 
    cd $CWD
}

build_tensorflow_serving_and_sentencepiece () {
    git clone -b 'r1.14' --single-branch --depth 1 https://github.com/tensorflow/serving.git &amp;&amp;
    mkdir -p serving/tensorflow_serving/custom_ops/sentencepiece_processor &amp;&amp;
    git clone https://github.com/google/sentencepiece.git serving/tensorflow_serving/custom_ops/sentencepiece_processor/sentencepiece &amp;&amp;
    sudo yum install gcc gcc-c++ kernel-devel &amp;&amp; # instead of (Ubuntu) sudo apt-get install build-essential
    sudo yum install cmake &amp;&amp; 
    sudo yum provides */pkg-config &amp;&amp;
    sudo yum install google-perftools google-perftools-devel &amp;&amp; # (Ubuntu) sudo apt-get install libgoogle-perftools-dev &amp;&amp;
    cd serving/tensorflow_serving/custom_ops/sentencepiece_processor/sentencepiece &amp;&amp;
    mkdir build &amp;&amp;
    cd build &amp;&amp;

    cmake -DSPM_USE_BUILTIN_PROTOBUF=OFF -DSPM_ENABLE_TENSORFLOW_SHARED=ON .. &amp;&amp;
    make -j $(nproc) &amp;&amp;
    sudo make install &amp;&amp;
    sudo ldconfig -v &amp;&amp;

    cd $CWD &amp;&amp;
    # cp ./build ./serving/tensorflow_serving/custom_ops/sentencepiece_processor/build &amp;&amp; # I can't find this BUILD directory
    sed -i.bak '/@org_tensorflow\/\/tensorflow\/contrib:contrib_ops_op_lib/a\    ""\/\/tensorflow_serving\/custom_ops\/sentencepiece_processor:sentencepiece_processor_ops"",' ./serving/tensorflow_serving/model_servers/BUILD &amp;&amp;
    sed -i '/name = ""tensorflow_model_server"",/a\    linkopts = [""-Wl,--allow-multiple-definition"", ""-Wl,-rpath,/usr/lib""],' ./serving/tensorflow_serving/model_servers/BUILD

    wget https://copr.fedorainfracloud.org/coprs/vbatts/bazel/repo/epel-7/vbatts-bazel-epel-7.repo
    sudo cp vbatts-bazel-epel-7.repo /etc/yum.repos.d/vbatts-bazel-epel-7.repo
    sudo yum install bazel
    # https://docs.bazel.build/versions/master/install-redhat.html

    cd serving &amp;&amp; 
    tools/run_in_docker.sh bazel build tensorflow_serving/model_servers:tensorflow_model_server
}

main () {
    echo ""Workdir: ${CWD}""
    compile_gprotobuf
    build_tensorflow_serving_and_sentencepiece
}

main
```

I removed `--max_idle_secs` because it gives me an error `ERROR: Unrecognized option: --max_idle_secs=60`. But this script still cause a problem in `Fetching @org_tensorflow`, which shows
```
ERROR: error loading package '': in /my_path/serving/tensorflow_serving/workspace.bzl: Encountered error while reading extension file 'tensorflow/workspace.bzl': no such package '@org_tensorflow//tensorflow': java.io.IOException: Error downloading [https://mirror.bazel.build/github.com/tensorflow/tensorflow/archive/87989f69597d6b2d60de8f112e1e3cea23be7298.tar.gz, https://github.com/tensorflow/tensorflow/archive/87989f69597d6b2d60de8f112e1e3cea23be7298.tar.gz] to /my_path/serving/.cache/_bazel_opc/3fa7ae51721c1323b37adf18f7a53821/external/org_tensorflow/87989f69597d6b2d60de8f112e1e3cea23be7298.tar.gz: All mirrors are down: []
```

I tried several methods to change the `http_proxy` (Use `HTTP_PROXY`, download the tar.gz file and put it in the dir, `--action_env=HTTP_PROXY=$HTTP_PROXY`, ...), but none of them worked.

Finally, I changed the image from `IMAGE=""tensorflow/serving:nightly-devel""` to `IMAGE=""tensorflow/serving:1.14.0""` in `run_in_docker.sh`, and it doesn't require `bazel fetch`.

However, it shows this error: `unknown argument: bash`, and also `FileSystemStoragePathSource encountered a filesystem access error: Could not find base path /models/model for servable model.` Does anyone have any idea how I can assign the correct model base? Thanks.",0,1
48,2019-11-16,2019,11,16,9,dwzpmf,Is there a place for newbie questions?,https://www.reddit.com/r/tensorflow/comments/dwzpmf/is_there_a_place_for_newbie_questions/,tamman2000,1573864940,"Is there a weekly thread for simple questions or anything like that?  


If not:  
I have a dataset that is images and scalar features associated with said images.  I would like to use both for my model, but I can't seem to find documentation on how to go about this.  Everything I can find is using either image data or a feature vector...  how can I use both together?  


Thanks in advance!",7,1
49,2019-11-16,2019,11,16,15,dx33g0,[question] I'm getting errors when trying to run TF,https://www.reddit.com/r/tensorflow/comments/dx33g0/question_im_getting_errors_when_trying_to_run_tf/,dikbum,1573884159,"I've been dying here, I was able to build the GPT2 project on my laptop but now when I try and build it on my PC I'm unable to, and have no idea why. 

I need to run `tensorflow-gpu==1.12`

Here's my specs:

* Windows 10, 64 bit 
* Python 3.6.6
* NVIDIA GPU Computing Toolkit\\CUDA\\v10.1

&amp;#x200B;

![img](biuoh9ilnzy31 ""CPU
"")

[2x \(sli\) GPU](https://preview.redd.it/l6z4z6wqnzy31.png?width=293&amp;format=png&amp;auto=webp&amp;s=8b27d3d6eb5e3585f24fd6b11fd5bd928358e86f)

[All the python packages](https://preview.redd.it/0x2k3zlgnzy31.png?width=312&amp;format=png&amp;auto=webp&amp;s=c22bbf903da43b1dd393b6bdb75fae1787d04c74)

[All the GPT2 requirements](https://preview.redd.it/ycr8582cnzy31.png?width=473&amp;format=png&amp;auto=webp&amp;s=2922ef094b2e4f8c54f7517202df83f76c39fb76)

And the error I'm getting:

`&gt;&gt;&gt;py import tensorflow as tf`

`C:\Users\user\AppData\Local\Programs\Python\Python36\python.exe: can't open file 'import': [Errno 2] No such file or directory`

`PS C:\Users\user\Documents\Development\machineLearning\gpt-2&gt; py .\src\interactive_conditional_samples.py`

`Traceback (most recent call last):`

  `File ""C:\Users\user\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in &lt;module&gt;`

`from tensorflow.python.pywrap_tensorflow_internal import *`

  `File ""C:\Users\user\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in &lt;module&gt;`

`_pywrap_tensorflow_internal = swig_import_helper()`

  `File ""C:\Users\user\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper`

`_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)`

  `File ""C:\Users\user\AppData\Local\Programs\Python\Python36\lib\`[`imp.py`](https://imp.py)`"", line 243, in load_module`

`return load_dynamic(name, filename, file)`

  `File ""C:\Users\user\AppData\Local\Programs\Python\Python36\lib\`[`imp.py`](https://imp.py)`"", line 343, in load_dynamic`

`return _load(spec)`

`ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.`

`During handling of the above exception, another exception occurred:`

`Failed to load the native TensorFlow runtime.`

I can't figure this out. Please help!",6,1
50,2019-11-16,2019,11,16,18,dx50fm,Saving a model with multiple branches,https://www.reddit.com/r/tensorflow/comments/dx50fm/saving_a_model_with_multiple_branches/,ssd123456789,1573898399,"In keas, for a model with multiple input branches that I concatenate later, do I need to save all model weights separately or can I just save the model weights where I combine everything?",1,1
51,2019-11-17,2019,11,17,1,dx8yk8,"[Question] Many of the official tutorials are still written in TensorFlow 1.x, does anyone know if there's an upgrade plan?",https://www.reddit.com/r/tensorflow/comments/dx8yk8/question_many_of_the_official_tutorials_are_still/,Ninjakannon,1573921539,"Will these be migrated to 2.x or marked as old? I would be happy to update the occasional tutorial to the latest version, if contributions are welcome, but I can't find any information about the intentions here.",3,1
52,2019-11-17,2019,11,17,2,dx9qht,Help for tensor slice assignment,https://www.reddit.com/r/tensorflow/comments/dx9qht/help_for_tensor_slice_assignment/,Swecar,1573925121,"I'm new to tensorflow and I need to write a custom flattening method where I want the channel index to be the slowest varying ""index"" in the flattened tensor. 

To do this I tried converting the tensor to a numpy array, which were quite to manage and the rest of the algorithm wasn't hard to implement. This worked well when I was manually inputting images through the network but when I wanted to train the model using this things broke.

Apparently [model.fit](https://model.fit)() firstly sends a tensor of shape (None, Width, Height, Channel) which my code didn't like since after converting to a numpy array it got the shape (1,) and my assignments width = width = input\_shape\[1\] got index out of bounds error.

Someone mentioned that I should write my layer entirely using tensorflow operations instead which seemed to be fine until I needed to assign tensors to a subset of a tensor axis; i.e. finalTensor\[ i , a : b \] = otherTensor.

I found `tensor_strided_slice_update` in `tensorflow_core` but I can't get it to work. 

To start out i created `tens = tf.zeros([2,3,4])` to which I wanted to assign the middle the tensor `array2 = tf.ones([3])` by using the indices `begin=tf.constant([0,0,2])`, `end = tf.constant([0,2,2])`, and stride `stride = tf.constant([0,1,0])` thinking that this would walk along the second axis at position 2 with a step length of 1. But stride can't be non-zero, so I don't know how to use this.

Any help would be appreciated! (This test case is a inserting along a whole axis but I would like an answer for the more general case, unfortunately the documentation is rather dense...)",8,1
53,2019-11-17,2019,11,17,15,dxiyd9,Installing Tensorflow-GPU on Ubuntu(Dual Boot along with Windows),https://www.reddit.com/r/tensorflow/comments/dxiyd9/installing_tensorflowgpu_on_ubuntudual_boot_along/,_-K1L4-_,1573970620,"Can someone please guide me in installing tensorflow-gpu in ubuntu(Dual boot alongside Windows). 

The last time I installed it, it showed numa node zero error while running the script.

Thanks in advance.",7,1
54,2019-11-17,2019,11,17,21,dxm7ep,How to get tensor values in a tensorflow estimator?,https://www.reddit.com/r/tensorflow/comments/dxm7ep/how_to_get_tensor_values_in_a_tensorflow_estimator/,ReasonablyBadass,1573995222,"A tensorflow estimator is wrapped around my code.

* Which prevents me from accessing tensor values by starting a session.
* The estimator get\_variable\_value function needs an existing checkpoint...which doesn't exist yet because the code can't run while I can't access the tensor.
* I don't see a way to get the estimator session itself to run an evaluation.
* The numpy() attribute does not work because due to the estimator the code won't run in Eager Execution mode.",0,1
55,2019-11-17,2019,11,17,23,dxmxle,passing argument to loss function during training,https://www.reddit.com/r/tensorflow/comments/dxmxle/passing_argument_to_loss_function_during_training/,progmayo,1573999644,"Hi guys. Couldn't find a suitable solution online for this, and I'd appreciate help in this matter.

Basically, as the title says, I want to pass a dynamic argument to my loss function during training, that isn't part of the training data. The return value of the loss function depends on this argument of course.

Here are some workarounds I've thought of. Perhaps one of these is the 'correct' way of implementing this, but to me they seemed like workarounds, and not real solutions.

1. Have this argument be an additional input to my network.
2. Pass it as part of my training data, and slice the data accordingly in the loss function to separate this parameter and the ""real"" training data

**Thank you very much in advance for any help.**",1,1
56,2019-11-18,2019,11,18,0,dxnnq2,I am getting an error while running the RNN LSTM model,https://www.reddit.com/r/tensorflow/comments/dxnnq2/i_am_getting_an_error_while_running_the_rnn_lstm/,gokulPRO,1574003622,"Everything was working fine.I was able to use tensorflow gpu in running CNN models,linear regression models etc.I was learning RNN with Tensorflow  in [https://www.tensorflow.org/guide/keras/rnn](https://www.tensorflow.org/guide/keras/rnn) .I ran the following code in my jupyter notebook:-

#  CODE:-

    batch_size = 64
# Each MNIST image batch is a tensor of shape (batch_size, 28, 28).
# Each input sequence will be of size (28, 28) (height is treated like time).
input_dim = 28

units = 64
output_size = 10 # labels are from 0 to 9

# Build the RNN model
def build_model(allow_cudnn_kernel=True):
 # CuDNN is only available at the layer level, and not at the cell level.
 # This means `LSTM(units)` will use the CuDNN kernel,
 # while RNN(LSTMCell(units)) will run on non-CuDNN kernel.
 if allow_cudnn_kernel:
 # The LSTM layer with default options uses CuDNN.
  lstm_layer = tf.keras.layers.LSTM(units, input_shape=(None, input_dim))
 else:
 # Wrapping a LSTMCell in a RNN layer will not use CuDNN.
  lstm_layer = tf.keras.layers.RNN(
    tf.keras.layers.LSTMCell(units),
    input_shape=(None, input_dim))
 model = tf.keras.models.Sequential([
   lstm_layer,
   tf.keras.layers.BatchNormalization(),
   tf.keras.layers.Dense(output_size, activation='softmax')]
 )
 return model
    mnist = tf.keras.datasets.mnist
    
    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    x_train, x_test = x_train / 255.0, x_test / 255.0
    sample, sample_label = x_train[0], y_train[0]
    model = build_model(allow_cudnn_kernel=True)
    
    model.compile(loss='sparse_categorical_crossentropy', 
                  optimizer='sgd',
                  metrics=['accuracy'])
    model.fit(x_train, y_train,
              validation_data=(x_test, y_test),
              batch_size=batch_size,
              epochs=5)

# The output and the error was:-

    Train on 60000 samples, validate on 10000 samples
    Epoch 1/5
       64/60000 [..............................] - ETA: 4:27:04
    ---------------------------------------------------------------------------
    UnknownError                              Traceback (most recent call last)
    &lt;ipython-input-6-58e50c3dedff&gt; in &lt;module&gt;()
          2           validation_data=(x_test, y_test),
          3           batch_size=batch_size,
    ----&gt; 4           epochs=5)
    
    ~\AppData\Roaming\Python\Python35\site-packages\tensorflow_core\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
        726         max_queue_size=max_queue_size,
        727         workers=workers,
    --&gt; 728         use_multiprocessing=use_multiprocessing)
        729 
        730   def evaluate(self,
    
    ~\AppData\Roaming\Python\Python35\site-packages\tensorflow_core\python\keras\engine\training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
        322                 mode=ModeKeys.TRAIN,
        323                 training_context=training_context,
    --&gt; 324                 total_epochs=epochs)
        325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)
        326 
    
    ~\AppData\Roaming\Python\Python35\site-packages\tensorflow_core\python\keras\engine\training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
        121         step=step, mode=mode, size=current_batch_size) as batch_logs:
        122       try:
    --&gt; 123         batch_outs = execution_function(iterator)
        124       except (StopIteration, errors.OutOfRangeError):
        125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?
    
    ~\AppData\Roaming\Python\Python35\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py in execution_function(input_fn)
         84     # `numpy` translates Tensors to values in Eager mode.
         85     return nest.map_structure(_non_none_constant_value,
    ---&gt; 86                               distributed_function(input_fn))
         87 
         88   return execution_function
    
    ~\AppData\Roaming\Python\Python35\site-packages\tensorflow_core\python\eager\def_function.py in __call__(self, *args, **kwds)
        455 
        456     tracing_count = self._get_tracing_count()
    --&gt; 457     result = self._call(*args, **kwds)
        458     if tracing_count == self._get_tracing_count():
        459       self._call_counter.called_without_tracing()
    
    ~\AppData\Roaming\Python\Python35\site-packages\tensorflow_core\python\eager\def_function.py in _call(self, *args, **kwds)
        518         # Lifting succeeded, so variables are initialized and we can run the
        519         # stateless function.
    --&gt; 520         return self._stateless_fn(*args, **kwds)
        521     else:
        522       canon_args, canon_kwds = \
    
    ~\AppData\Roaming\Python\Python35\site-packages\tensorflow_core\python\eager\function.py in __call__(self, *args, **kwargs)
       1821     """"""Calls a graph function specialized to the inputs.""""""
       1822     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
    -&gt; 1823     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
       1824 
       1825   @property
    
    ~\AppData\Roaming\Python\Python35\site-packages\tensorflow_core\python\eager\function.py in _filtered_call(self, args, kwargs)
       1139          if isinstance(t, (ops.Tensor,
       1140                            resource_variable_ops.BaseResourceVariable))),
    -&gt; 1141         self.captured_inputs)
       1142 
       1143   def _call_flat(self, args, captured_inputs, cancellation_manager=None):
    
    ~\AppData\Roaming\Python\Python35\site-packages\tensorflow_core\python\eager\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
       1222     if executing_eagerly:
       1223       flat_outputs = forward_function.call(
    -&gt; 1224           ctx, args, cancellation_manager=cancellation_manager)
       1225     else:
       1226       gradient_name = self._delayed_rewrite_functions.register()
    
    ~\AppData\Roaming\Python\Python35\site-packages\tensorflow_core\python\eager\function.py in call(self, ctx, args, cancellation_manager)
        509               inputs=args,
        510               attrs=(""executor_type"", executor_type, ""config_proto"", config),
    --&gt; 511               ctx=ctx)
        512         else:
        513           outputs = execute.execute_with_cancellation(
    
    ~\AppData\Roaming\Python\Python35\site-packages\tensorflow_core\python\eager\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
         65     else:
         66       message = e.message
    ---&gt; 67     six.raise_from(core._status_to_exception(e.code, message), None)
         68   except TypeError as e:
         69     keras_symbolic_tensors = [
    
    c:\users\gokul adethya\appdata\local\programs\python\python35\lib\site-packages\six.py in raise_from(value, from_value)
    
    UnknownError:  [_Derived_]  Fail to find the dnn implementation.
    	 [[{{node CudnnRNN}}]]
    	 [[sequential/lstm/StatefulPartitionedCall]] [Op:__inference_distributed_function_3409]
    
    Function call stack:
    distributed_function -&gt; distributed_function -&gt; distributed_function

# Configurations:-

    tensorflow-gpu version -- 2.0.0
    CUDA version - v10.0

I searched for the reason and found  [https://github.com/keras-team/keras/issues/10634](https://github.com/keras-team/keras/issues/10634) .The solutions were by either upgrading the cuddnn version or by  

    allow_growth = True 

I seems to be not working.I don't know if i did that correct too.Can anybody help me with this.",4,1
57,2019-11-18,2019,11,18,0,dxnuw1,Multiple predictions in a single model,https://www.reddit.com/r/tensorflow/comments/dxnuw1/multiple_predictions_in_a_single_model/,Cjbconnor,1574004588,"I'm trying to use a CNN model to predict more than one value based on the input image. I have my model set up correctly (I think) but I get an error every time I try and train it. The error I get is: `ValueError: too many values to unpack (expected 3)`. How can I build my model to predict multiple values?



    def decode_img(img):
      img = tf.image.decode_png(img, channels=3)
      img = tf.image.convert_image_dtype(img, tf.float32)
      return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])
    
    def process_path(file_path):
        parts = tf.strings.split(file_path, '_')
        file = tf.io.read_file(file_path)
        img = decode_img(file)
        return img, (tf.strings.split(parts[0], '/')[5], parts[1], parts[2], parts[3], tf.strings.split(parts[4], '.p')[0])
    
    def prepare_for_training(ds, cache=False, shuffle_buffer_size=1000):
      if cache:
        if isinstance(cache, str):
          ds = ds.cache(cache)
        else:
          ds = ds.cache()
    
      ds = ds.shuffle(buffer_size=shuffle_buffer_size)
      ds = ds.repeat()
      ds = ds.batch(BATCH_SIZE)
      ds = ds.prefetch(buffer_size=AUTOTUNE)
    
      return ds
    
    data_dir = pathlib.Path(""/home/connor/capstone/train3/"")
    image_count = len(list(data_dir.glob('*.png')))
    print(image_count)
    image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)
    BATCH_SIZE = 4
    IMG_HEIGHT = 1024
    IMG_WIDTH = 1024
    STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)
    
    list_ds = tf.data.Dataset.list_files(""/home/connor/capstone/train3/*.png"")
    
    labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)
    train_ds = prepare_for_training(labeled_ds)
    
    model = models.Sequential()
    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.Conv2D(64, (3, 3), activation='relu'))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.Conv2D(64, (3, 3), activation='relu'))
    model.add(layers.Flatten())
    model.add(layers.Dense(64, activation='relu'))
    model.add(layers.Dense(5, activation='softmax'))
    model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['mae'])
    
    model.fit(train_ds, epochs=2, steps_per_epoch=STEPS_PER_EPOCH)",1,1
58,2019-11-18,2019,11,18,7,dxtsn2,What types of problems will be more useful to use PyMC4 than TensorFlow Probability?,https://www.reddit.com/r/tensorflow/comments/dxtsn2/what_types_of_problems_will_be_more_useful_to_use/,o-rka,1574029950,"Im a big fan in PyMC3 and also a fan of TensorFlow.  I was very excited to see that PyMC4 would be using TensorFlow for the backend.  I was less enthused when I saw the new stylistic changes, though I understand why they used these changes since the graph paradigms are different between theano and TensorFlow.

Looking at TensorFlow Probability it looks pretty powerful and especially with the canned estimators.

Can someone explain a situation where it would make more sense to use PyMC4 than just a TensorFlow probability?",1,1
59,2019-11-18,2019,11,18,17,dy0n5y,Transfer Learning with TensorFlow 2  Model Fine Tuning,https://www.reddit.com/r/tensorflow/comments/dy0n5y/transfer_learning_with_tensorflow_2_model_fine/,RubiksCodeNMZ,1574067003,,0,1
60,2019-11-18,2019,11,18,23,dy47oi,Beginner - Installing Tensorflow ?,https://www.reddit.com/r/tensorflow/comments/dy47oi/beginner_installing_tensorflow/,Kappa7862,1574088977,"I did !pip install tensorflow, but when I run:

%tensorflow\_version 1.x

It says: 

UsageError: Line magic function \`%tensorflow\_version\` not found.

What does did mean and how to solve? #Python",3,1
61,2019-11-19,2019,11,19,0,dy4h8y,Virtual GPUs in TF 1.x,https://www.reddit.com/r/tensorflow/comments/dy4h8y/virtual_gpus_in_tf_1x/,antonkollmats,1574090227,"Hi,  


TensorFlow 2.0 provides the means for mocking a multi-GPU machine via the tf.config.experimental.VirtualDeviceConfiguration class. This allows for easy experimentation with the various distribution strategies of TensorFlow.  


I'm looking for a way to do the same with TensorFlow 1.x, so if anyone has some advice that'd be much appreciated.   


I have made attempts to use the tf.compat.v2 implementation in 1.15 to no avail. I'm also open to broader solutions such as mocking the GPU on the OS level somehow.

&amp;#x200B;

Thanks.",0,1
62,2019-11-19,2019,11,19,2,dy5vwm,Unsupervised Learning Tutorial for Tensorflow 2?,https://www.reddit.com/r/tensorflow/comments/dy5vwm/unsupervised_learning_tutorial_for_tensorflow_2/,Noahwar97,1574096444,"I started learning TensorFlow 2 from a video at free code camp as well as a few others but no one mentions how to use unsupervised learning. I searched the tutorial section of TensorFlow and couldn't find anything that said ""Unsupervised"". Any tips on where i can find a tutorial for this?",7,1
63,2019-11-19,2019,11,19,7,dyajkl,How are you parallelising image augmentation with TF2.0 on Windows?,https://www.reddit.com/r/tensorflow/comments/dyajkl/how_are_you_parallelising_image_augmentation_with/,geometrikal,1574115344,"Due to python GIL, parallel processing is a bit more difficult on Windows and Keras fit doesnt support multiprocessing with a generator. So I implement augmentation using tf.contrib.image  and the map function of Dataset. 

However tf.contrib.image got moved to tf.addons with TF2 and is not currently implemented for Windows, so Im stuck on TF1.x. 

What are some other strategies for performing parallel augmentation I could try?",0,1
64,2019-11-20,2019,11,20,5,dypuqk,Feed data into a deployed model in Tensorflow 2.0,https://www.reddit.com/r/tensorflow/comments/dypuqk/feed_data_into_a_deployed_model_in_tensorflow_20/,AndreaCatania,1574193825,"I'm checking the new features of Tensorflow 2.0, and I saw that the `placeholder`s got deprecated. Now is possible to use directly a python object.

```python
# Define the SummatorModule that sum the submitted value with the previously
# submitted one
class SummatorModule(tf.Module):
    def __init__(self):
        super(SummatorModule, self).__init__()
        self.a = tf.Variable(tf.zeros(shape=(1, 1)), name='a')

    @tf.function
    def __call__(self, x):
        self.a.assign(self.a + x)
        return self.a
```
As you can see here: `self.a.assign(self.a + x)`, I'm summing `self.a` (which is a __named__ `Variable`) with `x` (I assume that under the hood it is converted to a __unnamed__ `Variable`).

Let's suppose that I deploy this model into the application; so I need to feed the data into the model, but since `x` doesn't have a name I can't take the operation as I was able to do before with `placeholder`. So how can I feed the data into a deployed model in Tensorflow 2.0?

Probably even TF 2.0 server APIs got changed, but I'm not able to find anything about it; I hope that you can clean out my doubts.",2,1
65,2019-11-20,2019,11,20,9,dytmm9,Is TF suitable for my timeseries project?,https://www.reddit.com/r/tensorflow/comments/dytmm9/is_tf_suitable_for_my_timeseries_project/,CorerMaximus,1574209388,"I'm currently trying to explore whether Tensorflow and RNNs are the correct for my timeseries problem and was looking for some input to that end before jumping in with both feet. I'm looking for something that is/can deal with the following; and was wondering what is and is not possible: 

* Deals with missing data/ allows adding new features/signals
* Deals with seasonality seasonality
* Allows what-if analysis (i.e.- change a predictor variable and see the effect it has)
* Incremental training (feed in new data and update the model)
* Transfer learning: Generalize the effect of predictor variables enough that the model can be applied to data that has a very different shape/ subset of time, but still retains a similar effect of predictor variables.
* Is able to derive that some weights shift in importance over time. i.e.- a variable is perhaps only useful during 1 month of the year.",2,1
66,2019-11-20,2019,11,20,15,dyxzk2,How to use GPU in Google Colab when using Tensorflow 2.0,https://www.reddit.com/r/tensorflow/comments/dyxzk2/how_to_use_gpu_in_google_colab_when_using/,alwinaind,1574230772,"I want to run my notebook with GPU on Colab, and when I use the function

`tf.test.gpu_device_name()` it returns `''`.

However, when I reset all of my runtimes and use tensorflow 1.15.0 and call the same function it returns 

`'/device:GPU:0'`",6,1
67,2019-11-20,2019,11,20,15,dyy3cn,Twitch Score Finder - Looking for a teammate,https://www.reddit.com/r/tensorflow/comments/dyy3cn/twitch_score_finder_looking_for_a_teammate/,Migleytime,1574231437,"I am a student studying Computer Science and have some experience with computer vision at my internship and enjoy doing programming projects to learn more. I want to use TensorFlow to analyze different video game screens and gather data such as kills, scores and other stats. I was thinking this could be applied to Twitch streams to gather data of their current scores in games. I enjoy working on projects in teams, which is why I am looking for a teammate who would be interested in joining me on this project. Let me know if you're interested!",4,1
68,2019-11-20,2019,11,20,21,dz1k37,TensorFlow Emotion Text Detector,https://www.reddit.com/r/tensorflow/comments/dz1k37/tensorflow_emotion_text_detector/,timedjama5262,1574253752,"I am new to TensorFlow and TensorFlow serving and tried to create a newbie app from it and that is an emotion text detector. Used docker and TensorFlow/serving docker image as base image to create my very own.  Please check out and maybe help me state out some of the things I can improve on. Thanks, [https://github.com/jama5262/tensorflow-emotion-text-detector](https://github.com/jama5262/tensorflow-emotion-text-detector)

[https://github.com/jama5262/tensorflow-emotion-text-detector/blob/react-client/gif/image1.gif](https://github.com/jama5262/tensorflow-emotion-text-detector/blob/react-client/gif/image1.gif)",0,1
69,2019-11-21,2019,11,21,5,dz7kan,tensorflow lite raspberian image,https://www.reddit.com/r/tensorflow/comments/dz7kan/tensorflow_lite_raspberian_image/,cajun1689,1574280586,anyone have base raspberian image with tensorflow lite compiled and installed on it? for those of us who are beginners?,1,1
70,2019-11-21,2019,11,21,6,dz8m5p,Merging two Layers of different shapes.,https://www.reddit.com/r/tensorflow/comments/dz8m5p/merging_two_layers_of_different_shapes/,Research_point,1574285613,"I'M performing pruning (removing unimportant filters within each convolution layer) on the network shown. After pruning, conv2d\_7 output shape is \[None,7,7,32\]  and conv2d\_8 output shape is \[None,7,7,15\]. I would like to know what is the best way in tensorflow to merge two layer of different shape. Thanks

https://preview.redd.it/fx7h93j0uwz31.png?width=1363&amp;format=png&amp;auto=webp&amp;s=d323d11110d85122bc4650bfcd2ff25aab0a2cb3",6,1
71,2019-11-21,2019,11,21,8,dza3d5,Can I specify which steps the exporter will export a saved model?,https://www.reddit.com/r/tensorflow/comments/dza3d5/can_i_specify_which_steps_the_exporter_will/,MLn00bie22,1574291949,"In the `export/exporter` folder of a TensorFlow job, there are a series of saved models with timestamps. Here's an example of what the exporter directory looks like: 

    |export/
     exporter/
          1574213833/
          1574213867/
          1574213901/
          1574213935/
          1574213970/

Can we control at which steps these saved models will be saved? I know in the `tf.estimator.LatestExporter` there is a field called `exports_to_keep` but that doesn't help me understand at which step these saved models were saved. I've run my model for 10,000 steps, and would like to extract the model at 1,000 steps (other than re-running the job). Is there a way to specify the LatestExporter to create a saved model for every 1,000 steps or so? 

[https://www.tensorflow.org/versions/r1.15/api\_docs/python/tf/estimator/LatestExporter](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/estimator/LatestExporter)

It does seem like we can use the checkpoints and convert the checkpoints into a saved model, but it seems a little bit more involved. I'm about to give it a try, but wanted to ask around and see if saving the model at specific steps was possible. 

[https://blog.metaflow.fr/tensorflow-how-to-freeze-a-model-and-serve-it-with-a-python-api-d4f3596b3adc](https://blog.metaflow.fr/tensorflow-how-to-freeze-a-model-and-serve-it-with-a-python-api-d4f3596b3adc)

Thanks!",0,1
72,2019-11-21,2019,11,21,14,dzertr,Not a valid application,https://www.reddit.com/r/tensorflow/comments/dzertr/not_a_valid_application/,Gaba1504,1574315059,"Hi! whenever i try use tensorflow in any project i get this long error:

C:\\Users\\sebas\\AppData\\Local\\Programs\\Python\\Python36-32\\python.exe ""C:/Users/sebas/OneDrive/Desktop/coding/Python/Tumor detection/engine/app.py""

`Traceback (most recent call last):`

  `File ""C:/Users/sebas/OneDrive/Desktop/coding/Python/Tumor detection/engine/app.py"", line 1, in &lt;module&gt;`

`import tensorflow.keras`

  `File ""C:\Users\sebas\AppData\Roaming\Python\Python36\site-packages\tensorflow\__init__.py"", line 98, in &lt;module&gt;`

`from tensorflow_core import *`

  `File ""C:\Users\sebas\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\__init__.py"", line 40, in &lt;module&gt;`

`from` [`tensorflow.python.tools`](https://tensorflow.python.tools) `import module_util as _module_util`

  `File ""&lt;frozen importlib._bootstrap&gt;"", line 971, in _find_and_load`

  `File ""&lt;frozen importlib._bootstrap&gt;"", line 947, in _find_and_load_unlocked`

  `File ""C:\Users\sebas\AppData\Roaming\Python\Python36\site-packages\tensorflow\__init__.py"", line 50, in __getattr__`

`module = self._load()`

  `File ""C:\Users\sebas\AppData\Roaming\Python\Python36\site-packages\tensorflow\__init__.py"", line 44, in _load`

`module = _importlib.import_module(self.__name__)`

  `File ""C:\Users\sebas\AppData\Local\Programs\Python\Python36-32\lib\importlib\__init__.py"", line 126, in import_module`

`return _bootstrap._gcd_import(name[level:], package, level)`

  `File ""C:\Users\sebas\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\python\__init__.py"", line 47, in &lt;module&gt;`

`import numpy as np`

  `File ""C:\Users\sebas\AppData\Roaming\Python\Python36\site-packages\numpy\__init__.py"", line 140, in &lt;module&gt;`

`from . import _distributor_init`

  `File ""C:\Users\sebas\AppData\Roaming\Python\Python36\site-packages\numpy\_distributor_init.py"", line 26, in &lt;module&gt;`

`WinDLL(os.path.abspath(filename))`

  `File ""C:\Users\sebas\AppData\Local\Programs\Python\Python36-32\lib\ctypes\__init__.py"", line 348, in __init__`

`self._handle = _dlopen(self._name, mode)`

`OSError: [WinError 193] %1 is not a valid Win32 application`

&amp;#x200B;

Im running python 3.6

and here is my code: 

`import tensorflow.keras`  
`from PIL import Image`  
`import numpy as np`  


`np.set_printoptions(suppress=True)`  


`model = tensorflow.keras.models.load_model('keras_model.h5')`  


`data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)`  


`path = input(""Enter path to MRI scan: "")`  
`image = Image.open(path)`  


`image = image.resize((224, 224))`  
`image_array = np.asarray(image)`  


`normalized_image_array = image_array / 255.0`  
`data[0] = normalized_image_array`  


`prediction = model.predict(data)`  
`print(prediction)`  


`this error occurs with any tensor flow project,` 

&amp;#x200B;

Then model im using is a simple one trained from teachable machine",6,1
73,2019-11-21,2019,11,21,20,dzi42v,Pretrained model prediction CPU vs GPU,https://www.reddit.com/r/tensorflow/comments/dzi42v/pretrained_model_prediction_cpu_vs_gpu/,ihababdk,1574336571,"Hey guys

Im working on a project that uses a pretrained CNN (Inception pretrained on imagenet) and I want to do feature vector extraction with this model (Prediction function) , how much would it differ if I ran the model prediction using the CPU or GPU , and would I need a GPU-Specific model or library to use the GPU ?  


Sorry if my question is broad and vague.

Thanks!",1,1
74,2019-11-22,2019,11,22,0,dzkqi1,Using iPad Pro NPU for training,https://www.reddit.com/r/tensorflow/comments/dzkqi1/using_ipad_pro_npu_for_training/,fucilator_3000,1574349560,"Hi Guys!


I'm currently using TensorFlow with my MacBook Pro and Google Colab.  

I was wondering if it would possible to use the computational power of the 2019 iPad Pro (in particular the NPU) to carry out the training phase.  

Does it make sense to do it? Will I have any limitations?

Thank you in advance!",7,1
75,2019-11-22,2019,11,22,1,dzlzfe,I am trying to load a hub.Module in Colab but there is problem with the localhost container?,https://www.reddit.com/r/tensorflow/comments/dzlzfe/i_am_trying_to_load_a_hubmodule_in_colab_but/,ReasonablyBadass,1574354593,"I am trying to use the hub BERT module but I get the following error:

&gt;FailedPreconditionError: Error while reading resource variable module/bert/encoder/layer\_6/output/LayerNorm/beta   
&gt;  
&gt;from Container: localhost. This could mean that the variable was uninitialized.   
&gt;  
&gt;Not found: Container localhost does not exist. (  
&gt;  
&gt;Could not find resource: localhost/module/bert/encoder/layer\_6/output/LayerNorm/beta) 	   
&gt;  
&gt;\[\[node module\_apply\_tokens/bert/encoder/layer\_6/output/LayerNorm/batchnorm/ReadVariableOp (defined at /usr/local/lib/python3.6/dist-packages/tensorflow\_core/python/framework/ops.py:1748) \]\]

I have found no solution online to this problem that worked. 

I have tried to set 

&gt;os.environ\['TFHUB\_CACHE\_DIR'\] = ""my directory""

But that made no difference.

Has anyone seen this error before?",1,1
76,2019-11-22,2019,11,22,13,dzvny5,Create action based on when a object class leaves the frame,https://www.reddit.com/r/tensorflow/comments/dzvny5/create_action_based_on_when_a_object_class_leaves/,cajun1689,1574395869,"hey guys im writting a python code to open a cover when my dog is present and need it to close after a certain amount of time once the go is no longer detected. i have this 

`# Check the class of the top detected object by looking at classes[0][0].`

`# If the top detected object is a cat (17) or a dog (18) (or a teddy bear (88) for test purposes),`

`# find its center coordinates by looking at the boxes[0][0] variable.`

`# boxes[0][0] variable holds coordinates of detected objects as (ymin, xmin, ymax, xmax)`

`if ((int(classes[0][0] == 18)) and (pause == 0)):`

`x = int(((boxes[0][0][1]+boxes[0][0][3])/2)*IM_WIDTH)`

`y = int(((boxes[0][0][0]+boxes[0][0][2])/2)*IM_HEIGHT)`

`# Draw a circle at center of object`

[`cv2.circle`](https://cv2.circle)`(frame,(x,y), 5, (75,13,180), -1)`





`# If object is in inside box, increment inside counter variable`

`if ((x &gt; TL_food[0]) and (x &lt; BR_food[0]) and (y &gt; TL_food[1]) and (y &lt; BR_food[1])):`

`dog_counter = dog_counter + 1`

and then

`# If dog has been detected inside for more than 10 frames, set detected_dog flag`

`# and send a text to the phone.`

`if dog_counter &gt; 10:`

`detected_dog = True`

`dog = true`

`if gate_open == False`

`for i in range(200):`

`kit.stepper1.onestep(direction=stepper.BACKWARD,style=stepper.MICROSTEP)`

`gate_open = True`

`#message = client.messages.create(`

`#   body = 'Your pet wants outside!',`

`#  from_=twilio_number,`

`#  to=my_number`

`# )`

`dog_counter = 0`

`#outside_counter = 0`

`# Pause pet detection by setting ""pause"" flag`

`pause = 1`

&amp;#x200B;

&amp;#x200B;

	`if (detected_dog == False) and (gate_open == true)`

		`for i in range(200):`

`kit.stepper1.onestep(style=stepper.MICROSTEP)`

`gate_open = False`

&amp;#x200B;

My problem is i dont understand tensorflow enough to know how to code when the dog is no longer in the frame",2,1
77,2019-11-22,2019,11,22,19,dzzcne,Dockerized Tensorflow and reactJS-flask emotion text detector,https://www.reddit.com/r/tensorflow/comments/dzzcne/dockerized_tensorflow_and_reactjsflask_emotion/,timedjama5262,1574419533,,0,1
78,2019-11-22,2019,11,22,22,e00ool,Is there any text on the internals of TF ?,https://www.reddit.com/r/tensorflow/comments/e00ool/is_there_any_text_on_the_internals_of_tf/,SecondEpoch,1574427774,"I've been trying to read through the Tensorflow codebase  to understand how it works inside, and honestly I find it a bit complex and intimidating. Are there any articles that gives a high level overview of how the framework is organised ? It would help any potential code contributors.",1,1
79,2019-11-23,2019,11,23,5,e0796a,What's the loss function used in the LinearEstimator class?,https://www.reddit.com/r/tensorflow/comments/e0796a/whats_the_loss_function_used_in_the/,iamiamwhoami,1574456325,"I'm trying replicate results I'm getting using the estimator api in Keras, and I can't find this info.",0,1
80,2019-11-23,2019,11,23,11,e0brzy,Multilabel image classifier outputting almost the same probabilities for each class independent of image,https://www.reddit.com/r/tensorflow/comments/e0brzy/multilabel_image_classifier_outputting_almost_the/,ski233,1574476721,"I have a multilabel image classification model that I had refined and had working. However, now I'm trying to use this model with a different dataset (where at the moment most images only have one label). However, during training, the f1 score goes incredibly low and never increases and if I do prediction, the output probabilities for each class are almost the same no matter what image I input. I'm using XCeption base model with a sigmoid final layer with binary\_crossentropy and adam optimizer. I tried using resnet50 with the same approach and it is producing the same issue. I've tried everything I can think of to fix this but I'm not getting anywhere. Any help would be greatly appreciated and I can post any more information that anyone thinks might be helpful.",38,1
81,2019-11-23,2019,11,23,16,e0ejz9,Installation of TensorFlow Through pip - Javatpoint,https://www.reddit.com/r/tensorflow/comments/e0ejz9/installation_of_tensorflow_through_pip_javatpoint/,nehapandey01,1574492950,,0,1
82,2019-11-23,2019,11,23,17,e0fcgn,Free or trial Cloud Computing for TensorFlow,https://www.reddit.com/r/tensorflow/comments/e0fcgn/free_or_trial_cloud_computing_for_tensorflow/,fucilator_3000,1574498641,"Hi guys! I'm actually using Google CoLab which is free.

Is there any other similar solution with trial period?

I know Google Cloud Drive but 300$ can't be used for ML :(",4,1
83,2019-11-23,2019,11,23,18,e0fo47,Can anyone explain how to use a sigmoid layer in tensorflow is,https://www.reddit.com/r/tensorflow/comments/e0fo47/can_anyone_explain_how_to_use_a_sigmoid_layer_in/,Ravenclaw6706,1574501052,Ive been trying to use a sigmoid layer but I dont know how.,3,1
84,2019-11-23,2019,11,23,19,e0ggji,"TensorFlow 1.0 vs 2.0, Part 3: tf.keras",https://www.reddit.com/r/tensorflow/comments/e0ggji/tensorflow_10_vs_20_part_3_tfkeras/,staged_blue,1574506597,,0,1
85,2019-11-23,2019,11,23,20,e0go6i,Video Semantic Search in Large Scale using GNES and Tensorflow 2.0,https://www.reddit.com/r/tensorflow/comments/e0go6i/video_semantic_search_in_large_scale_using_gnes/,h_xiao,1574508050,,0,1
86,2019-11-23,2019,11,23,22,e0hryr,"Tensorflow.JS, sigmoid activation layer.",https://www.reddit.com/r/tensorflow/comments/e0hryr/tensorflowjs_sigmoid_activation_layer/,Ravenclaw6706,1574515336,How do I use sigmoid activation layers in tensorflow.js,3,1
87,2019-11-24,2019,11,24,17,e0vu7m,How to use TensorFlow Queue API to speed up performance for custom data?,https://www.reddit.com/r/tensorflow/comments/e0vu7m/how_to_use_tensorflow_queue_api_to_speed_up/,madebymaze,1574583329,"I am using TensorFlow 1.13. I am training my simple NN model to train on simple imagery data.

I have been using feed_dict to pass data to the graph, however, I have found it extremely slow as CPU and GPU are running in sequence. Hence, I wanted to speed up this process by introducing parallelism aspect to the pipeline in order to speed up the performance.

I have successfully implemented TensorFlow Queue API but it doesn't show a lot of improvements (just .1% faster). Therefore, I don't think I am using the full potentials of TensorFlow Queue API.

I didn't use TensorFlow Data API because it requires TFRecords as an input, which isn't what I want to do. I just want to pass the imagery data with their labels to the graph and apply training on them.

**I think these areas might cause slow performance, but I don't know how to fix them:**

 - Enqueuing is happening then training starts.
 - A single thread handles enqueue and the main thread handles dequeuing.
 - Waiting for the enqueue thread to stop.

Here is my code:

* Shared functions for feed_dict :
```
def mini_batches(X, Y, mini_batch_size = 64, seed = 0):
   ...
def create_placeholders(n_x, n_y):
    X = tf.placeholder(tf.float32, name = ""Placeholder_1"",shape=[n_x,None])
    Y = tf.placeholder(tf.float32, name = ""Placeholder_2"",shape=[n_y,None])
    return X, Y
def initialize_parameters():
   ...
def forward_propagation(X, parameters):
   ...
def compute_cost(Z3, Y):
    logits = tf.transpose(Z3)
    labels = tf.transpose(Y)
    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))
    return cost
```
* Queue functions:
```
def set_queue(n_x, n_y, X, Y, capacity):
    q = tf.PaddingFIFOQueue(capacity=capacity, dtypes=[tf.float32, tf.float32], shapes=[(n_x,None),(n_y,None)], name=""q"", shared_name=""shared_q"")
    en = q.enqueue((X, Y))
    de = q.dequeue()
    q_size = q.size()
    close_q = q.close()

def set_tf_vars():
    en_epoch = tf.Variable(initial_value=0, trainable=False, dtype=tf.int32)
    inc_en_epoch = tf.assign(en_epoch, en_epoch + 1, use_locking=True)
    return en_epoch, inc_en_epoch

def enqueue_thread(coord, sess, X, Y, en, en_epoch, inc_en_epoch, q_size, X_data, Y_data, lock, seed, num_epochs, m, minibatch_size):
        while not coord.should_stop():
          lock.acquire()
          currepoch = sess.run(en_epoch)
          queue_size = sess.run(q_size)
          thread_name = threading.current_thread().name
          if sess.run(en_epoch) &lt; num_epochs:
              num_minibatches = int(m / minibatch_size)
              seed = seed + 1
              minibatches = mini_batches(X_data, Y_data, minibatch_size, seed)
              for minibatch in minibatches:
                  (minibatch_X, minibatch_Y) = minibatch
                  sess.run(en, feed_dict={X:minibatch_X, Y:minibatch_Y})
              sess.run(inc_en_epoch)
              nextepoch = sess.run(en_epoch)
              queue_size = sess.run(q_size)
          else:
              coord.request_stop()
              break
          lock.release()
```

* My implementation of TensorFlow Queue API:
```
def model_queue(X_train, Y_train, X_test, Y_test, capacity, learning_rate = 0.0001,
          num_epochs = 100, minibatch_size = 32, print_cost = True):
    ops.reset_default_graph()
    sess = tf.InteractiveSession()
    coord = tf.train.Coordinator() ##

    tf.set_random_seed(1)
    seed = 3

    (n_x, m) = X_train.shape
    n_y = Y_train.shape[0]
    costs = []

    X, Y = create_placeholders(n_x, n_y)
    parameters = initialize_parameters()
    Z3 = forward_propagation(X, parameters)
    cost = compute_cost(Z3, Y)
    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)

    # create a queue
    q, en, de, q_size, close_q = set_queue(n_x, n_y, X, Y, capacity) ##
    
    # create tensorflow variables to be used in enqueue_threading
    en_epoch, inc_en_epoch = set_tf_vars() ##

    init = tf.global_variables_initializer()
    sess.run(init)

    # create a locker to control the thread
    lock = threading.Lock() ##
    threads = [threading.Thread(target=enqueue_thread, args=(coord, sess, X, Y, en, en_epoch, inc_en_epoch, q_size, X_train, Y_train, lock, seed, num_epochs, m, minibatch_size,))] ##
    
    # start the enqueue_thread
    for t in threads: t.start() ##

    # main thread will be responsible of dequeuing of data and applying training
    for epoch in range(num_epochs):
        epoch_cost = 0.
        num_minibatches = int(m / minibatch_size)
        ##
        for _ in range(num_minibatches):
            minibatch_X, minibatch_Y = sess.run(de) ##
            _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})
            epoch_cost += minibatch_cost / num_minibatches
        if print_cost == True and epoch % 10 == 0:
            print (""Cost after epoch %i: %f"" % (epoch, epoch_cost))
        if print_cost == True and epoch % 5 == 0:
            costs.append(epoch_cost)
    parameters = sess.run(parameters)
    correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, ""float""))
    t_acc = accuracy.eval({X: X_train, Y: Y_train})
    T_acc = accuracy.eval({X: X_test, Y: Y_test})
    print (""Train Accuracy:"", t_acc)
    print (""Test Accuracy:"", T_acc)
    coord.request_stop()
    coord.join(threads)
    sess.run(close_q)
    sess.close()
    return parameters, t_acc, T_acc
```",4,1
88,2019-11-24,2019,11,24,19,e0ws7d,How to use bias and weights,https://www.reddit.com/r/tensorflow/comments/e0ws7d/how_to_use_bias_and_weights/,Ravenclaw6706,1574590498,"Im leaning how to use tensorflow.js, and I am not sure how to use weight and biases",4,1
89,2019-11-25,2019,11,25,5,e13y07,Datasets from numpy arrays,https://www.reddit.com/r/tensorflow/comments/e13y07/datasets_from_numpy_arrays/,Ste29ebasta,1574626618,"I'm trying to create a Dataset object in tensorflow 1.14 (I have some legacy code that i can't change for this specific project) starting from numpy arrays, but everytime i try i get everything copied on my graph and for this reason when i create an event log file it is huge (719 MB in this case).

&amp;#x200B;

Originally i tried using this function ""tf.data.Dataset.from\_tensor\_slices()"", but it didn't work, then i read it is a common problem and someone suggested me to try with generators, thus i tried with the following code, but again i got a huge event file (719 MB again)

&amp;#x200B;

\`\`\`

def fetch\_batch(x, y, batch):

i = 0

while i &lt; batch:

yield (x\[i,:,:,:\], y\[i\])

i +=1

&amp;#x200B;

train, test = tf.keras.datasets.fashion\_mnist.load\_data()

images, labels = train  

images = images/255

&amp;#x200B;

training\_dataset = tf.data.Dataset.from\_generator(fetch\_batch, 

args=\[images, np.int32(labels), batch\_size\], output\_types=(tf.float32, tf.int32), 

output\_shapes=(tf.TensorShape(features\_shape), tf.TensorShape(labels\_shape)))

&amp;#x200B;

file\_writer = tf.summary.FileWriter(""/content"", graph=tf.get\_default\_graph())

\`\`\`

&amp;#x200B;

I know in this case I could use tensorflow\_datasets API and it would be easier, but this is a more general question, and it involves how to create datasets in general, not only using the mnist one.

Could you explain to me what am i doing wrong? Thank you",15,1
90,2019-11-25,2019,11,25,17,e1d2lf,"Tensorflow conda install guide points to Tf v1, not v2.",https://www.reddit.com/r/tensorflow/comments/e1d2lf/tensorflow_conda_install_guide_points_to_tf_v1/,Fenr-i-r,1574670125,"This link for installing Tensorflow in conda: https://www.tensorflow.org/install/pip?lang=python3#conda points to TF1. I'm not sure how to recommend an edit to point it to v2, at https://anaconda.org/anaconda/tensorflow-gpu (or https://anaconda.org/anaconda/tensorflow).

Can someone tell me how, or suggest the change themselves?
Cheers",3,1
91,2019-11-25,2019,11,25,18,e1dmz7,Problem with GPT-2 (Raspi),https://www.reddit.com/r/tensorflow/comments/e1dmz7/problem_with_gpt2_raspi/,Chris-CR,1574673934,"I got some errors while testing GPT-2
It says something with Tensorflow, so I thought it could belong here...

[Link to Github Issue](https://github.com/rish-16/gpt2client/issues/21)",7,1
92,2019-11-25,2019,11,25,18,e1dx47,Deep Learning for Programmers Ebook,https://www.reddit.com/r/tensorflow/comments/e1dx47/deep_learning_for_programmers_ebook/,RubiksCodeNMZ,1574675827,,2,1
93,2019-11-26,2019,11,26,5,e1lvz9,Implementing custom models into tensorflow js,https://www.reddit.com/r/tensorflow/comments/e1lvz9/implementing_custom_models_into_tensorflow_js/,TechGenius28,1574712786,"I would like to create a website that can classify different types of cars. I have manage to get the website working to use the mobile net model, but I would like to use a custom model that I trained in google colab. Does anyone know how I could achieve this?",1,1
94,2019-11-26,2019,11,26,11,e1qxv9,Is there a way to algorithmically trade with google colon?,https://www.reddit.com/r/tensorflow/comments/e1qxv9/is_there_a_way_to_algorithmically_trade_with/,Coffee4thewin,1574733810,"I want to try trading some paper stocks and maybe some really money one day(a long way off)

Whats the best way to write code in jupyter notebooks and algorithmically trade?",9,1
95,2019-11-26,2019,11,26,18,e1vnk4,Upgrading to TF2. Am I being forced into containers? What might I lose?,https://www.reddit.com/r/tensorflow/comments/e1vnk4/upgrading_to_tf2_am_i_being_forced_into/,bwllc,1574760703,"I use my home PC for a lot of scientific computing tasks, with Tensorflow being one of these.  I'm a native Linux user.  I typically upgrade my Ubuntu distro within weeks of a new release.  I do this because, while I have compiled applications I need from source, it's painful.  Upgraded repositories of many apps are immediately accessible from Canonical when you upgrade Ubuntu.

I've been running Tensorflow 1.x for about 18 months.  I never succeeded in installing Bazel and compiling from source.  I always get warnings from Tensorflow that I'm not taking advantage of vectorized operations that my CPU has available.   
 However, I did manage to install CUDA and cuDNN, and use my NVidia 970 GPU for Tensorflow.  I upgraded 3 or 4 times.

This week I decided to install Ubuntu 19.10, the newest version; and, to switch to Tensorflow 2.0.  I just tried my usual methods for installation, and they failed.  I'll admit that I don't always fully understand the multiple versions of Python which end up on a modern Linux system.  I may have installed everything that I need this time -- but I sent something to the wrong place.  It's so hard to keep track.

The Tensorflow 2.0 documentation strongly advises you to install Docker and run Tensorflow in a container.  Apparently, this solves a lot of installation problems.  Does it?

Up to now, my Python setup has been very direct, and I use it in ways that others may not.  For many people, Tensorboard output might provide enough real-time information for them.  In my case, I learned a lot about the model architecture in one project by writing a Keras Callback which periodically graphed the predictions of a regression as the model trained.  This was much more important to me than simply graphing the model weights.  I had Tensorflow and Matplotlib running together in a single program.  I like having every line of code in my lightweight IDE (Geany) and to be able to modify it without thinking about where it is.

I'm not familiar with containers.  I have worked with virtual machines.  If I wanted to run Tensorflow, Matplotlib, and Geany the way that I'm doing now, would all of that software go inside the container?  Would I be looking at an annoying, small, screen-inside-a-screen display when I'm doing my development?

If the logical thing to do is to have only Tensorflow inside the container, how would it communicate outside the container?  Can that communication be reasonably fast and responsive?

I've done multiprocessing in Python before.  I've used the /tmp folder in the Linux file hierarchy to pass data between programs.  These aren't impossible tasks for me, I'm just wondering how cumbersome this will be.

Thanks for your insights.",6,1
96,2019-11-26,2019,11,26,19,e1w4xp,[Project] My implementation of 9 knowledge distillation methods by Tensorflow2.0 and benchmark results,https://www.reddit.com/r/tensorflow/comments/e1w4xp/project_my_implementation_of_9_knowledge/,sseung0703,1574763921,[removed],0,1
97,2019-11-26,2019,11,26,19,e1wfcr,Use tfhub module as video feature extractor,https://www.reddit.com/r/tensorflow/comments/e1wfcr/use_tfhub_module_as_video_feature_extractor/,WiIzaaa,1574765899,"Hi! I am trying to use [this module](https://tfhub.dev/deepmind/i3d-kinetics-600/1) as a video feature extractor and I was wondering if it was possible to use an intermediate layer instead of the default ""logits"". 

I've tried to use their repo and compile the modle using their weights but their code hasn't been ported to TF2 :(

Any idea would be welcome. Thanks a lot and have a good day!",1,1
98,2019-11-27,2019,11,27,0,e1zbyp,"currently doing Bootcamp, can TS replace scikit-learn?",https://www.reddit.com/r/tensorflow/comments/e1zbyp/currently_doing_bootcamp_can_ts_replace/,philmtl,1574781630,"in 2018 i got certified in DS with python and used Scikit-learn for most of my models. As im going through this Bootcamp they are applying TS for many of the same uses i would use Scikit-learn for. 

ex classification, linear regression, and forecasting. 

i thought TS was mainly for image recognition, but im see it can do more. 

yes i understand its better to know both, but if i were to focus on one to get a job which is more in demand?",8,1
99,2019-11-27,2019,11,27,17,e2dar5,tensorflow 2.0 with compute capability 3.0,https://www.reddit.com/r/tensorflow/comments/e2dar5/tensorflow_20_with_compute_capability_30/,AlanRoofies,1574844471,"Hello, 

I have a GT 740 2GB and i want to use it with tensorflow but i need to build tf with compute capability 3.0 and it is not working 

is there a dockerized automatique builder or maybe someone can share an already built version",6,1
100,2019-11-27,2019,11,27,20,e2ers6,"Learn more about the performance of distributed TensorFlow in a multi-node and multi-GPU configuration, running on an Amazon EC2 cluster. Download the research paper",https://www.reddit.com/r/tensorflow/comments/e2ers6/learn_more_about_the_performance_of_distributed/,benjamin_brook,1574853882,,0,1
101,2019-11-27,2019,11,27,20,e2eyap,Training a Boltzmann machine with Tensorflow 2,https://www.reddit.com/r/tensorflow/comments/e2eyap/training_a_boltzmann_machine_with_tensorflow_2/,fori1to10,1574855078,"I am trying to find a tutorial or some documentation on how to train a Boltzmann machine (restricted or deep) with Tensorflow. All the resources I've found are for Tensorflow 1, and it's difficult for a beginner to understand what I need to modify.

Can someone suggest something?",0,1
102,2019-11-27,2019,11,27,23,e2h0a8,Is it possible to retrain a model in tensorflow-cpu if the original model was trained in tensorflow-gpu,https://www.reddit.com/r/tensorflow/comments/e2h0a8/is_it_possible_to_retrain_a_model_in/,begooboi,1574866131,I want to do some part of training in a gpu and other in cpu. If I use `pip install tensorflow-gpu` for training a model in gpu machine and then transfer the same model in a different cpu only machine with `pip install tensorflow` (same versions). Will the gpu trained model be able to train in cpu machine? or it will cause problems?,4,1
103,2019-11-28,2019,11,28,4,e2kw96,Nan Predictions from Sequential Model,https://www.reddit.com/r/tensorflow/comments/e2kw96/nan_predictions_from_sequential_model/,yus0359_2,1574881498,"So I'm new to tensorflow, and I built a model to classify some random data. The model fit works and evaluate work, but when I try to predict with the fitted model I get a bunch of NAN values. The 'label' field is binary, 1 r 0. What am I doing wrong?

&amp;#x200B;

\`import tensorflow as tf  
import pandas as pd  
from sklearn.model\_selection import train\_test\_split  
import copy as cp  
import pickle as pkl  


with open('data.pkl', 'rb') as f:  
df = pkl.load(f)  


del df\['dif'\]  
del df\['start'\]  
del df\['line\_speed'\]  
del df\['time'\]  


train, test = train\_test\_split(df, test\_size=0.2, stratify=df\['line'\])  


x\_train = cp.deepcopy(train)  
del x\_train\['label'\]  
x\_train = x\_train.values.tolist()  
y\_train = cp.deepcopy(train\['label'\]).values.tolist()  
x\_test = cp.deepcopy(test)  
del x\_test\['label'\]  
x\_test = x\_test.values.tolist()  
y\_test = cp.deepcopy(test\['label'\]).values.tolist()  


\# sess = tf.Session()  
model = tf.keras.models.Sequential(\[  
tf.keras.layers.Dense(443, activation='sigmoid'),  
 tf.keras.layers.Dense(2 \* 443, activation='sigmoid'),  
 tf.keras.layers.Dense(2 \* 443, activation='sigmoid'),  
 tf.keras.layers.Dropout(0.2),  
 tf.keras.layers.Dense(1, activation='sigmoid')  
\])  


model.compile(optimizer='adam',  
 loss=tf.losses.binary\_crossentropy,  
 metrics=\['accuracy'\])  


model.fit(x\_train, y\_train, epochs=5, batch\_size=2\*64)  
model.evaluate(x\_test,  y\_test, verbose=2)  


y = model.predict(x\_test, verbose=2)  
print(y)  


confusion = tf.math.confusion\_matrix(labels=y\_test, predictions=y, num\_classes=1)\`",0,1
104,2019-11-28,2019,11,28,4,e2lr5u,What is the technology behind tensorboard?,https://www.reddit.com/r/tensorflow/comments/e2lr5u/what_is_the_technology_behind_tensorboard/,jfk9720,1574884662,"I really like the tensorboard function and was thinking about implementing a watered down version (html based visualisation etc.) for a project of mine. But I cannot find anything like it, except for the TensorBoard code itself of course, so I was wondering is there a name for tensorboard-like solutions?",5,1
105,2019-11-28,2019,11,28,12,e2s3pr,TensorFlowLiteSwift support for GPU?,https://www.reddit.com/r/tensorflow/comments/e2s3pr/tensorflowliteswift_support_for_gpu/,john-c34,1574912141,"I'm working on deploying a model on an  iOS device using swift and tflite, however I need to speed up the inference time. Naturally, my initial thought was to utilize the device's GPU, however it seems that tflite-gpu is only supported with Objective-C.

Will TensorFlowLiteSwift support GPU usage anytime soon?

Thanks

0",0,1
106,2019-11-28,2019,11,28,20,e2wlsu,Tensorflow 2.0 (Keras) Show Labels ?,https://www.reddit.com/r/tensorflow/comments/e2wlsu/tensorflow_20_keras_show_labels/,m4ctep,1574939169,"Hello ,

&amp;#x200B;

i created an Keras Model with [https://teachablemachine.withgoogle.com/train](https://teachablemachine.withgoogle.com/train) .

&amp;#x200B;

I Test the Code With :

    import cv2 # import opencv
    import tensorflow.keras as keras
    import numpy as np
    
    webcam = cv2.VideoCapture(0)
    model = keras.models.load_model('keras_model.h5')
    
    data_for_model = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)
    
    # This function proportionally resizes the image from your webcam to 224 pixels high
    def image_resize(image, height, inter = cv2.INTER_AREA):
        dim = None
        (h, w) = image.shape[:2]
        r = height / float(h)
        dim = (int(w * r), height)
        resized = cv2.resize(image, dim, interpolation = inter)
        return resized
    
    # this function crops to the center of the resize image
    def cropTo(img):
        size = 224
        height, width = img.shape[:2]
    
        sideCrop = (width - 224) // 2
        return img[:,sideCrop:(width - sideCrop)]
    
    while True:
        ret, img = webcam.read()
        if ret:
            #same as the cropping process in TM2
            img = image_resize(img, height=224)
            img = cropTo(img)
    
            # flips the image
            img = cv2.flip(img, 1)
    
            #normalize the image and load it into an array that is the right format for keras
            normalized_img = (img.astype(np.float32) / 127.0) - 1
            data_for_model[0] = normalized_img
     
            #run inference
            prediction = model.predict(data_for_model)
    
            print(prediction)
    
            cv2.imshow('webcam', img)
            if cv2.waitKey(1) == 27:
                break
    
    cv2.destroyAllWindows()
    
    The Result is :
    
    [[0.58780265 0.06445915 0.18077235 0.16696586]
    
    i heave a labels.txt file in the zip archive with The Labels :
    
    0 dog
    1 cat
    2 hamster
    3 bird 
     
    
    How Can i show the Results with the Labels Text ?",4,1
107,2019-11-29,2019,11,29,11,e3838c,"Doing a NLP project for the Tensorflow 2.0 Hackathon, and looking for teammates.",https://www.reddit.com/r/tensorflow/comments/e3838c/doing_a_nlp_project_for_the_tensorflow_20/,AdditionalWay,1574993568,"We are looking to this hackathon. We are a team of 3, looking or 1 or 2 other people. 

We are looking to do some tricky things in Keras, so deep Keras experience is a huge plus.",6,1
108,2019-11-29,2019,11,29,21,e3e340,Status of LSTM/GRU Support for TF Lite in TF 2.0?,https://www.reddit.com/r/tensorflow/comments/e3e340/status_of_lstmgru_support_for_tf_lite_in_tf_20/,craaaft,1575030132,"Does anyone know the state of full support of LSTM/GRU for TFLite in TF2.0? In the [roadmap](https://www.tensorflow.org/lite/guide/roadmap) it should be implemented by end of 2019 which is near, and I couldn't find any news besides the workarounds that seem to work very suboptimally....

Any dev here that works on it maybe here and could share the status?",0,1
109,2019-11-29,2019,11,29,22,e3esu5,"This video goes over a breast cancer diagnosis model that uses neural networks, implemented in Python.",https://www.reddit.com/r/tensorflow/comments/e3esu5/this_video_goes_over_a_breast_cancer_diagnosis/,antaloaalonso,1575034466,,2,1
110,2019-11-29,2019,11,29,23,e3fji9,Making a tensorflow model,https://www.reddit.com/r/tensorflow/comments/e3fji9/making_a_tensorflow_model/,StressedOutBox,1575038409,"Hey there,

So i'm going to be making a tensorflow project based on gestures but these gestures will be ones that will require movement. So I'll need to use videos instead of images..

So, Is it possible to make a tensorflow model based on videos and how could I do this?",6,1
111,2019-11-30,2019,11,30,17,e3sxlx,Keras model keeps getting stuck on first epoch,https://www.reddit.com/r/tensorflow/comments/e3sxlx/keras_model_keeps_getting_stuck_on_first_epoch/,MSute,1575101249,I have been trying to build an image classification model using transfer learning and it keeps getting stuck on the first epoch,5,1
112,2019-11-30,2019,11,30,22,e3w3wp,Tensorflow suitable for hobbyist project?,https://www.reddit.com/r/tensorflow/comments/e3w3wp/tensorflow_suitable_for_hobbyist_project/,negro_scholarship,1575119701,"I am working on a simple project.  I have 600 frames of an animation.  I would like to take a folder full of style images, and then perform a neural style transfer on each of these 600 frames using said style images.  I thought Tensorflow would be perfect for this, since I do have a bit of experience with Python, but I am having a hell of a time getting it working.

I am following the guide here - [https://www.tensorflow.org/tutorials/generative/style\_transfer](https://www.tensorflow.org/tutorials/generative/style_transfer) and this is the code I am using:

    from __future__ import absolute_import, division, print_function, unicode_literals
    import tensorflow as tf
    import IPython.display as display
    
    import matplotlib.pyplot as plt
    import matplotlib as mpl
    mpl.rcParams['figure.figsize'] = (12,12)
    mpl.rcParams['axes.grid'] = False
    
    import numpy as np
    import PIL.Image
    import time
    import functools
    def tensor_to_image(tensor):
      tensor = tensor*255
      tensor = np.array(tensor, dtype=np.uint8)
      if np.ndim(tensor)&gt;3:
        assert tensor.shape[0] == 1
        tensor = tensor[0]
      return PIL.Image.fromarray(tensor)
    
    content_path = tf.keras.utils.get_file('YellowLabradorLooking_new.jpg', 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg')
    
    # https://commons.wikimedia.org/wiki/File:Vassily_Kandinsky,_1913_-_Composition_7.jpg
    style_path = tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg')
    
    def load_img(path_to_img):
      max_dim = 512
      img = tf.io.read_file(path_to_img)
      img = tf.image.decode_image(img, channels=3)
      img = tf.image.convert_image_dtype(img, tf.float32)
    
      shape = tf.cast(tf.shape(img)[:-1], tf.float32)
      long_dim = max(shape)
      scale = max_dim / long_dim
    
      new_shape = tf.cast(shape * scale, tf.int32)
    
      img = tf.image.resize(img, new_shape)
      img = img[tf.newaxis, :]
      return img
    
    def imshow(image, title=None):
      if len(image.shape) &gt; 3:
        image = tf.squeeze(image, axis=0)
    
      plt.imshow(image)
      if title:
        plt.title(title)
        
    content_image = load_img(content_path)
    style_image = load_img(style_path)
    
    plt.subplot(1, 2, 1)
    imshow(content_image, 'Content Image')
    
    plt.subplot(1, 2, 2)
    imshow(style_image, 'Style Image')
    
    
    import tensorflow_hub as hub
    hub_module = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/1')
    stylized_image = hub_module(tf.constant(content_image), tf.constant(style_image))[0]
    tensor_to_image(stylized_image)
    
    x = tf.keras.applications.vgg19.preprocess_input(content_image*255)
    x = tf.image.resize(x, (224, 224))
    vgg = tf.keras.applications.VGG19(include_top=True, weights='imagenet')
    prediction_probabilities = vgg(x)
    prediction_probabilities.shape
    
    predicted_top_5 = tf.keras.applications.vgg19.decode_predictions(prediction_probabilities.numpy())[0]
    [(class_name, prob) for (number, class_name, prob) in predicted_top_5]
    
    vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')
    
    print()
    for layer in vgg.layers:
      print(layer.name)
    
    # Content layer where will pull our feature maps
    content_layers = ['block5_conv2'] 
    
    # Style layer of interest
    style_layers = ['block1_conv1',
                    'block2_conv1',
                    'block3_conv1', 
                    'block4_conv1', 
                    'block5_conv1']
    
    num_content_layers = len(content_layers)
    num_style_layers = len(style_layers)
    
    def vgg_layers(layer_names):
      """""" Creates a vgg model that returns a list of intermediate output values.""""""
      # Load our model. Load pretrained VGG, trained on imagenet data
      vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')
      vgg.trainable = False
      
      outputs = [vgg.get_layer(name).output for name in layer_names]
    
      model = tf.keras.Model([vgg.input], outputs)
      return model
    
    style_extractor = vgg_layers(style_layers)
    style_outputs = style_extractor(style_image*255)
    
    #Look at the statistics of each layer's output
    for name, output in zip(style_layers, style_outputs):
      print(name)
      print(""  shape: "", output.numpy().shape)
      print(""  min: "", output.numpy().min())
      print(""  max: "", output.numpy().max())
      print(""  mean: "", output.numpy().mean())
      print()
    
    def gram_matrix(input_tensor):
      result = tf.linalg.einsum('bijc,bijd-&gt;bcd', input_tensor, input_tensor)
      input_shape = tf.shape(input_tensor)
      num_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32)
      return result/(num_locations)
    
    class StyleContentModel(tf.keras.models.Model):
      def __init__(self, style_layers, content_layers):
        super(StyleContentModel, self).__init__()
        self.vgg =  vgg_layers(style_layers + content_layers)
        self.style_layers = style_layers
        self.content_layers = content_layers
        self.num_style_layers = len(style_layers)
        self.vgg.trainable = False
    
      def call(self, inputs):
        ""Expects float input in [0,1]""
        inputs = inputs*255.0
        preprocessed_input = tf.keras.applications.vgg19.preprocess_input(inputs)
        outputs = self.vgg(preprocessed_input)
        style_outputs, content_outputs = (outputs[:self.num_style_layers], 
                                          outputs[self.num_style_layers:])
    
        style_outputs = [gram_matrix(style_output)
                         for style_output in style_outputs]
    
        content_dict = {content_name:value 
                        for content_name, value 
                        in zip(self.content_layers, content_outputs)}
    
        style_dict = {style_name:value
                      for style_name, value
                      in zip(self.style_layers, style_outputs)}
        
        return {'content':content_dict, 'style':style_dict}
    
    extractor = StyleContentModel(style_layers, content_layers)
    
    results = extractor(tf.constant(content_image))
    
    style_results = results['style']
    
    print('Styles:')
    for name, output in sorted(results['style'].items()):
      print(""  "", name)
      print(""    shape: "", output.numpy().shape)
      print(""    min: "", output.numpy().min())
      print(""    max: "", output.numpy().max())
      print(""    mean: "", output.numpy().mean())
      print()
    
    print(""Contents:"")
    for name, output in sorted(results['content'].items()):
      print(""  "", name)
      print(""    shape: "", output.numpy().shape)
      print(""    min: "", output.numpy().min())
      print(""    max: "", output.numpy().max())
      print(""    mean: "", output.numpy().mean())
    
    style_targets = extractor(style_image)['style']
    content_targets = extractor(content_image)['content']
    
    image = tf.Variable(content_image)
    
    def clip_0_1(image):
      return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)
    
    opt = tf.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1)
    
    style_weight=1e-2
    content_weight=1e4
    
    def style_content_loss(outputs):
        style_outputs = outputs['style']
        content_outputs = outputs['content']
        style_loss = tf.add_n([tf.reduce_mean((style_outputs[name]-style_targets[name])**2) 
                               for name in style_outputs.keys()])
        style_loss *= style_weight / num_style_layers
    
        content_loss = tf.add_n([tf.reduce_mean((content_outputs[name]-content_targets[name])**2) 
                                 for name in content_outputs.keys()])
        content_loss *= content_weight / num_content_layers
        loss = style_loss + content_loss
        return loss
    
    @tf.function()
    def train_step(image):
      with tf.GradientTape() as tape:
        outputs = extractor(image)
        loss = style_content_loss(outputs)
    
      grad = tape.gradient(loss, image)
      opt.apply_gradients([(grad, image)])
      image.assign(clip_0_1(image))
    
    train_step(image)
    train_step(image)
    train_step(image)
    tensor_to_image(image)
    
    import time
    start = time.time()
    
    epochs = 10
    steps_per_epoch = 100
    
    step = 0
    for n in range(epochs):
      for m in range(steps_per_epoch):
        step += 1
        train_step(image)
        print(step, end='')
      display.clear_output(wait=True)
      display.display(tensor_to_image(image))
      print(""Train step: {}"".format(step))
      
    end = time.time()
    print(""Total time: {:.1f}"".format(end-start))
    
    

&amp;#x200B;

And here is Python's output after running this code:

    input_2
    block1_conv1
    block1_conv2
    block1_pool
    block2_conv1
    block2_conv2
    block2_pool
    block3_conv1
    block3_conv2
    block3_conv3
    block3_conv4
    block3_pool
    block4_conv1
    block4_conv2
    block4_conv3
    block4_conv4
    block4_pool
    block5_conv1
    block5_conv2
    block5_conv3
    block5_conv4
    block5_pool
    block1_conv1
      shape:  (1, 336, 512, 64)
      min:  0.0
      max:  835.5257
      mean:  33.97525
    
    block2_conv1
      shape:  (1, 168, 256, 128)
      min:  0.0
      max:  4625.8857
      mean:  199.82687
    
    block3_conv1
      shape:  (1, 84, 128, 256)
      min:  0.0
      max:  8789.24
      mean:  230.78099
    
    block4_conv1
      shape:  (1, 42, 64, 512)
      min:  0.0
      max:  21566.133
      mean:  791.24005
    
    block5_conv1
      shape:  (1, 21, 32, 512)
      min:  0.0
      max:  3189.2544
      mean:  59.179478
    
    Styles:
       block1_conv1
        shape:  (1, 64, 64)
        min:  0.0055228467
        max:  28014.568
        mean:  263.79025
    
       block2_conv1
        shape:  (1, 128, 128)
        min:  0.0
        max:  61479.504
        mean:  9100.95
    
       block3_conv1
        shape:  (1, 256, 256)
        min:  0.0
        max:  545623.44
        mean:  7660.9766
    
       block4_conv1
        shape:  (1, 512, 512)
        min:  0.0
        max:  4320501.5
        mean:  134288.86
    
       block5_conv1
        shape:  (1, 512, 512)
        min:  0.0
        max:  110005.38
        mean:  1487.0381
    
    Contents:
       block5_conv2
        shape:  (1, 26, 32, 512)
        min:  0.0
        max:  2410.8796
        mean:  13.764152
    123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100[2K
    [2K
    &lt;PIL.Image.Image image mode=RGB size=512x422 at 0x12E858099E8&gt;
    Train step: 100
    101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200[2K
    [2K
    &lt;PIL.Image.Image image mode=RGB size=512x422 at 0x12E858152E8&gt;
    Train step: 200
    201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300[2K
    [2K
    &lt;PIL.Image.Image image mode=RGB size=512x422 at 0x12E85820BA8&gt;
    Train step: 300
    301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400[2K
    [2K
    &lt;PIL.Image.Image image mode=RGB size=512x422 at 0x12E85824F60&gt;
    Train step: 400
    401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500[2K
    [2K
    &lt;PIL.Image.Image image mode=RGB size=512x422 at 0x12E857EEFD0&gt;
    Train step: 500
    501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600[2K
    [2K
    &lt;PIL.Image.Image image mode=RGB size=512x422 at 0x12EE137FB00&gt;
    Train step: 600
    601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700[2K
    [2K
    &lt;PIL.Image.Image image mode=RGB size=512x422 at 0x12E857EEFD0&gt;
    Train step: 700
    701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800[2K
    [2K
    &lt;PIL.Image.Image image mode=RGB size=512x422 at 0x12EE137FB00&gt;
    Train step: 800
    801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869870871872873874875876877878879880881882883884885886887888889890891892893894895896897898899900[2K
    [2K
    &lt;PIL.Image.Image image mode=RGB size=512x422 at 0x12E857EEFD0&gt;
    Train step: 900
    9019029039049059069079089099109119129139149159169179189199209219229239249259269279289299309319329339349359369379389399409419429439449459469479489499509519529539549559569579589599609619629639649659669679689699709719729739749759769779789799809819829839849859869879889899909919929939949959969979989991000[2K
    [2K
    &lt;PIL.Image.Image image mode=RGB size=512x422 at 0x12EE137FB00&gt;
    Train step: 1000
    Total time: 13161.4
    &gt;&gt;&gt; 
    

So a few things - I am thinking that ""display.display(tensor\_to\_image(image))"" is supposed to display the transformed image?  Well, it doesn't - instead it prints a pointer or something?  Also, it seems like this one transform took an extremely long time!  If I have to wait this long for each of the 600 frames I need to apply the NST to, it doesn't seem feasible.

Anyone have any suggestions here?  Is Tensorflow perhaps the wrong tool to use here, should I be using something like PyTorch instead?",4,1
113,2019-11-30,2019,11,30,23,e3wv98,Tensorflow 2.0  tf.data.Dataset vs tf.keras.Model.fit() Batching,https://www.reddit.com/r/tensorflow/comments/e3wv98/tensorflow_20_tfdatadataset_vs_tfkerasmodelfit/,OftenPerspicacious,1575123122,"The docs for tf.keras.Model.fit() say not to specify a batch_size argument if you are using a Dataset, generator, etc., because these create their own batches.

Looking at the shapes of the input tensors within the call() function of my subclassed tf.keras.Model, it seems that using the Dataset batches will force your Model to deal with the batching (i.e., the full batch is passed at once), whereas setting the batch size using fit() will pass a single element of the batch to your model.

Is that correct? I'm asking because I'm having problems with tf.keras.backend's batch_dot() and sum() that seem to be a product of using tf.data.Dataset to load Iris data. A similar architecture that doesn't use TF's Dataset, but calls model.fit() sets a batch size, but doesn't generate these errors. The models use custom weight vectors (defined in the model's .build() function) that don't have a ""batch_size"" 'placeholder' (e.g., None), but this only seems to be an issue with tf.data.Dataset's batching, not model.fit().

My main questions are:

1) Do you have to explicitly handle the batched inputs using tf.data.Dataset's batching, but can assume that's not necessary with model.fit()'s batching?

2) How does the batching work for each case? I haven't been able to find much online about this.",2,1
