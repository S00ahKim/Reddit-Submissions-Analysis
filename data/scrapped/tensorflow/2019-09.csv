,sbr,sbr_id,date,year,month,hour,day,id,domain,title,full_link,author,created,selftext,num_comments,score,over_18,thumbnail,media_provider,media_thumbnail,media_title,media_description,media_url
0,tensorflow,t5_3alkk,2019-9-1,2019,9,1,10,cy3mit,self.tensorflow,Convert tensor to eager tensor in tf 2.0,https://www.reddit.com/r/tensorflow/comments/cy3mit/convert_tensor_to_eager_tensor_in_tf_20/,Runninganddogs979,1567299669,"Hi all!

So I'm pulling a layer out of aa Deeplab v3+ model and I need to eventually convert it to a np array. Unfortunately the layer is of type Tensor and not EagerTensor so I am not able to access the .numpy() method. All code was done in TF 2.0 alpha. Any suggestions?",1,0,False,self,,,,,
1,tensorflow,t5_3alkk,2019-9-1,2019,9,1,11,cy4hp9,self.tensorflow,I need some assistance!,https://www.reddit.com/r/tensorflow/comments/cy4hp9/i_need_some_assistance/,Quilldino2,1567304752,"I recently have been trying to get into coding with python because I eventually would like to create an AI; however when I import tensorflow into either my command prompt running Python 3.6 or PyCharm with interpreter 3.6 I get an error. I am also using miniconda.

&amp;#x200B;

&amp;#x200B;

C:\\Users\\StRUT\\Miniconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\framework\\[dtypes.py:516](https://dtypes.py:516): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  \_np\_qint8 = np.dtype(\[(""qint8"", np.int8, 1)\])

C:\\Users\\StRUT\\Miniconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\framework\\[dtypes.py:517](https://dtypes.py:517): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  \_np\_quint8 = np.dtype(\[(""quint8"", np.uint8, 1)\])

C:\\Users\\StRUT\\Miniconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\framework\\[dtypes.py:518](https://dtypes.py:518): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  \_np\_qint16 = np.dtype(\[(""qint16"", np.int16, 1)\])

C:\\Users\\StRUT\\Miniconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\framework\\[dtypes.py:519](https://dtypes.py:519): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  \_np\_quint16 = np.dtype(\[(""quint16"", np.uint16, 1)\])

C:\\Users\\StRUT\\Miniconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\framework\\[dtypes.py:520](https://dtypes.py:520): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  \_np\_qint32 = np.dtype(\[(""qint32"", np.int32, 1)\])

C:\\Users\\StRUT\\Miniconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\framework\\[dtypes.py:525](https://dtypes.py:525): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  np\_resource = np.dtype(\[(""resource"", np.ubyte, 1)\])

C:\\Users\\StRUT\\Miniconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorboard\\compat\\tensorflow\_stub\\[dtypes.py:541](https://dtypes.py:541): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  \_np\_qint8 = np.dtype(\[(""qint8"", np.int8, 1)\])

C:\\Users\\StRUT\\Miniconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorboard\\compat\\tensorflow\_stub\\[dtypes.py:542](https://dtypes.py:542): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  \_np\_quint8 = np.dtype(\[(""quint8"", np.uint8, 1)\])

C:\\Users\\StRUT\\Miniconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorboard\\compat\\tensorflow\_stub\\[dtypes.py:543](https://dtypes.py:543): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  \_np\_qint16 = np.dtype(\[(""qint16"", np.int16, 1)\])

C:\\Users\\StRUT\\Miniconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorboard\\compat\\tensorflow\_stub\\[dtypes.py:544](https://dtypes.py:544): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  \_np\_quint16 = np.dtype(\[(""quint16"", np.uint16, 1)\])

C:\\Users\\StRUT\\Miniconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorboard\\compat\\tensorflow\_stub\\[dtypes.py:545](https://dtypes.py:545): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  \_np\_qint32 = np.dtype(\[(""qint32"", np.int32, 1)\])

C:\\Users\\StRUT\\Miniconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorboard\\compat\\tensorflow\_stub\\[dtypes.py:550](https://dtypes.py:550): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.

  np\_resource = np.dtype(\[(""resource"", np.ubyte, 1)\])

\---------------------------------------------------------------------------------------------------------------------------------

I hope someone can help with this issue because the past 4 days I have had a different issue that seems to have been fixed, but then another one come right up. 

Thanks in advance!",6,1,False,self,,,,,
2,tensorflow,t5_3alkk,2019-9-2,2019,9,2,21,cyo4mo,self.tensorflow,Changing a pixel in an image using tensorflow,https://www.reddit.com/r/tensorflow/comments/cyo4mo/changing_a_pixel_in_an_image_using_tensorflow/,ninji3,1567425986,"I asked a question on SO over the weekend but it didn't get much attention, so I am posting it again here in the hope that someone might know of a way to do this.

[Stack Overflow: How to replace pixel value as a tensorflow operation?](https://stackoverflow.com/questions/57733053/how-to-replace-pixel-value-as-a-tensorflow-operation)

You can find the details there.

To give you a quick summary: I am currently using `tf.py_func()` to change the value of a pixel in an image. This slows down my code substantially. Is there a clever way to do this in tensorflow?",4,3,False,self,,,,,
3,tensorflow,t5_3alkk,2019-9-3,2019,9,3,2,cys6xq,aicheatsheets.com,"AI Cheatsheets - Now learn Tensorflow, Keras, Pytorch, Dask, Pandas, Numpy, Scipy, Pyspark, R Studio, Matplotlib and many more in an interactive manner",https://www.reddit.com/r/tensorflow/comments/cys6xq/ai_cheatsheets_now_learn_tensorflow_keras_pytorch/,kailashahirwar12,1567445820,,0,43,False,https://b.thumbs.redditmedia.com/rwvOGi8rOEJSSnJz2Q3Br0NzNtKBzc5qhXyUnb-3HkQ.jpg,,,,,
4,tensorflow,t5_3alkk,2019-9-3,2019,9,3,4,cytn3r,expoundai.wordpress.com,Back-propagation Demystified [Part 3] | Computational Graphs in TensorFlow,https://www.reddit.com/r/tensorflow/comments/cytn3r/backpropagation_demystified_part_3_computational/,msminhas93,1567452179,,0,1,False,https://b.thumbs.redditmedia.com/gizJ7QZlDR-le-Hh7SxfCHZnJFRtoLRdr8-O9JJMyEY.jpg,,,,,
5,tensorflow,t5_3alkk,2019-9-3,2019,9,3,6,cyvc6y,self.tensorflow,How would I identify circuit damage using tensorflow?,https://www.reddit.com/r/tensorflow/comments/cyvc6y/how_would_i_identify_circuit_damage_using/,skellerone,1567459696,"Hi all,

I've set myself a small project of making a neural network in tensorflow that will identify images of circuits, and I've used the basic model and image loading tutorials to do so thus far. However, I want to be able to at some point give this model a damaged circuit, and have it recognize the damage. What would be the best way of doing this?

(I figured the easiest way would be simply to highlight images which are below a certain confidence rating once the network has been optimized, but it would also be nice to produce some kind of image highlighting the particular area the model had difficulty matching, for reference, which would need something a little more elaborate...)",4,0,False,self,,,,,
6,tensorflow,t5_3alkk,2019-9-3,2019,9,3,7,cyw2cj,self.tensorflow,Custom Text Classification for multiple classes,https://www.reddit.com/r/tensorflow/comments/cyw2cj/custom_text_classification_for_multiple_classes/,charManpie,1567463122,"Hello,

I am looking for a tutorial on how to build a custom model for Text Classification with multiple classes. I have used image recognition and object detection for training and prediction. 'tensorflow for poets' example was very simple. I am looking for something similar, preparing data, training and prediction.

 [https://www.tensorflow.org/beta/tutorials/text/text\_classification\_rnn](https://www.tensorflow.org/beta/tutorials/text/text_classification_rnn)   
 [https://www.tensorflow.org/hub/tutorials/text\_classification\_with\_tf\_hub](https://www.tensorflow.org/hub/tutorials/text_classification_with_tf_hub) 

Both of these links were helpful, I am not sure how can I use this tutorial to train different data and specify multiple labels and test them afterwards. Similar to the image recognition tensorflow for poets

Thank you so much in advance.",1,1,False,self,,,,,
7,tensorflow,t5_3alkk,2019-9-3,2019,9,3,8,cywoll,self.tensorflow,Get output layer from Deeplab model,https://www.reddit.com/r/tensorflow/comments/cywoll/get_output_layer_from_deeplab_model/,Runninganddogs979,1567466170,"Hi all!

So I need to grab out a layer from the deeplab v3+ model that has the same dims as the output picture but with number of categories as the channels not RGB. How do I find this??",0,1,False,self,,,,,
8,tensorflow,t5_3alkk,2019-9-3,2019,9,3,19,cz2x1k,self.tensorflow,How to use tensorboard visualizations for custom training loops in TF2.0,https://www.reddit.com/r/tensorflow/comments/cz2x1k/how_to_use_tensorboard_visualizations_for_custom/,Bowserwolf1,1567505780,"If i was writing the model in pure keras, i'd probably just use tensorboard as a callback in [model.fit](https://model.fit), and in tensorflow 1.x, id use tensorboard the normal way by using the session object. but in tf2.0 there is no graph object, so i cant throw that to tensorboard as a argument. 

&amp;#x200B;

i;m trying to rain a dcgan and the training loop i've written is custom, and i dont want to go the hassle of converting it to work with the kears [model.fit](https://model.fit) logic. Is there any way i could get the tensorboard visualization in this kind of a train loop ? 

&amp;#x200B;

this is my training loop

    for epoch in range(n_epochs):
            for batch in train_dataset:
                DCGAN.train(batch)
                print(""one iteration"")
            print(
                f""for epoch {epoch} gen_loss is {avg_gen_loss.result()} disc_loss is {avg_disc_loss.result()}"")
     
    
    # main training loop 

and tihs is the train function 

    @tf.function
        def train(self, images):
            for _ in range(PARAMS['n_looping_factor']):# train discriminator for n_looping_factor loops
                noise = tf.random.normal(
                    shape=[self.batch_size, 100], mean=0, stddev=1.0, dtype=tf.float32)
                with tf.GradientTape() as disc_tape:
                    gen_images = self.generator(noise) # generate fake images
                    
                    real_pred = self.discriminator(images)
                    generated_pred = self.discriminator(tf.zeros_like(gen_images)) 
                    
                    discriminator_loss = self.discriminator_loss(
                        real_pred, generated_pred)
                    
                    avg_disc_loss.update_state(discriminator_loss) # update avg_loss for this batch
                disc_gradients = disc_tape.gradient(
                    discriminator_loss, self.discriminator.trainable_variables)
                self.disc_optimizer.apply_gradients(
                    (zip(disc_gradients, self.discriminator.trainable_variables)))
    
            # train generator once
            noise = tf.random.normal(
                shape=[self.batch_size, 100], mean=0, stddev=1.0, dtype=tf.float32)
            with tf.GradientTape() as gen_tape:
                gen_images = self.generator(noise)
                generated_pred = self.discriminator(gen_images)
                generator_loss = self.generator_loss(generated_pred)
                avg_gen_loss.update_state(generator_loss)
            gen_gradients = gen_tape.gradient(
                generator_loss, self.generator.trainable_variables)
            self.gen_optimizer.apply_gradients(
                zip(gen_gradients, self.generator.trainable_variables))
    

Any help wpuld be appreciated, thanks in advance!",0,1,False,self,,,,,
9,tensorflow,t5_3alkk,2019-9-3,2019,9,3,20,cz3l03,self.tensorflow,Kubeflow (on premise) TFX pipelines,https://www.reddit.com/r/tensorflow/comments/cz3l03/kubeflow_on_premise_tfx_pipelines/,valerianomanassero,1567510107,"I just started a new repo with my first two pipelines for TFX on Kubeflow (on premise).

[https://github.com/valeriano-manassero/tfx-kubeflow-pipelines](https://github.com/valeriano-manassero/tfx-kubeflow-pipelines)

Since I found difficult times with docs about Kubeflow on premise and TFX pipeines for images I'm sharing this hoping for good feedbacks. I will try to continue improve it.

Any suggestion is appreciated!",0,6,False,self,,,,,
10,tensorflow,t5_3alkk,2019-9-4,2019,9,4,3,cz91c1,self.tensorflow,Using multimodal data as input (continuous/discrete),https://www.reddit.com/r/tensorflow/comments/cz91c1/using_multimodal_data_as_input_continuousdiscrete/,McDinkelfurz,1567536548,"Is there an optimal strategy for combining continuous data columns with discrete data columns to use as input for a neural network? By which I mean, if you have continuous data alongside binary data or columns of integers, is there a way to process the data other than just standardizing it?",2,2,False,self,,,,,
11,tensorflow,t5_3alkk,2019-9-4,2019,9,4,6,czawpl,self.tensorflow,Data Science Specialization from Johns Hopkins University,https://www.reddit.com/r/tensorflow/comments/czawpl/data_science_specialization_from_johns_hopkins/,internetdigitalentre,1567544922,[removed],0,1,False,self,,,,,
12,tensorflow,t5_3alkk,2019-9-4,2019,9,4,8,czcnq9,self.tensorflow,Simple and useful guide for TensorFlow,https://www.reddit.com/r/tensorflow/comments/czcnq9/simple_and_useful_guide_for_tensorflow/,MarceloLopezUru,1567553210,[removed],0,1,False,self,,,,,
13,tensorflow,t5_3alkk,2019-9-4,2019,9,4,12,czfhua,self.tensorflow,Is the first layer of sequenctial keras dense layer a hidden layer?,https://www.reddit.com/r/tensorflow/comments/czfhua/is_the_first_layer_of_sequenctial_keras_dense/,begooboi,1567568080,"I need to create a three layer neural network with this config

    input_dim=2
    hidden_dim=2
    output_dim=1

and wrote my model this way

    model = Sequential()
    # Input layer
    model.add(Dense(output_dim=3, input_dim=2))
    # Hidden layer
    model.add(Dense(2)
    # Output layer
    model.add(Dense(1))

My expected weight matrix is  [2x2],[2x1] with W^ih and W^ho respectively. But the weight matrix I got was this


    &gt;&gt;&gt;for i in model.get_weights():
        print(""\n"",i)


     [[ 0.02314293 -0.74796295  0.4222021 ]
     [-0.5900725   0.6331698  -0.30411077]]

     [0. 0. 0.]

     [[-0.6382148  -0.21151215]
     [-0.81804264 -0.4383769 ]
     [-0.32733858 -1.0314355 ]]

     [0. 0.]

     [[1.2613355]
     [1.377251 ]]

     [0.]

I know zero matrix are biases but its the first weight matrix, that is,

     [[ 0.02314293 -0.74796295  0.4222021 ]
     [-0.5900725   0.6331698  -0.30411077]]

which confuses me.
Is the first layer of my model `model.add(Dense(output_dim=3, input_dim=2))` is not an ""input layer"" alone but ""input+hidden layer""? and my model is actually a four layer network instead of three?",2,2,False,self,,,,,
14,tensorflow,t5_3alkk,2019-9-4,2019,9,4,22,czkoyj,self.tensorflow,Hyperparameter Tuning for lo-level Tensorflow code,https://www.reddit.com/r/tensorflow/comments/czkoyj/hyperparameter_tuning_for_lolevel_tensorflow_code/,honeybooboo1989,1567602761,"Hello everyone,

I was curious about how people are doing hyperparameter tuning for a neural network which was written in low-level Tensorflow. I am still using Tensorflow 1.0 not Keras or anything else. I want to tune hyperparameters, I look for some documentations/resources online and cannot come up with anything (I know tuning methods but I am looking for a specific packages).

For example,  Tensorflow has `HParams` plugin designed for Tensorflow 2.0 and Keras. 
https://www.tensorflow.org/tensorboard/r2/hyperparameter_tuning_with_hparams

Can you give me direction and/or a GitHub Repo or something?",0,1,False,self,,,,,
15,tensorflow,t5_3alkk,2019-9-4,2019,9,4,22,czkt7l,self.tensorflow,Hyperparameter Tuning for low-level Tensorflow code,https://www.reddit.com/r/tensorflow/comments/czkt7l/hyperparameter_tuning_for_lowlevel_tensorflow_code/,honeybooboo1989,1567603366,"Hello everyone,

I was curious about how people are doing hyperparameter tuning for a neural network which was written in low-level Tensorflow. I am still using Tensorflow 1.0 not Keras or anything else. I want to tune hyperparameters, I look for some documentations/resources online and cannot come up with anything (I know tuning methods but I am looking for a specific packages).

For example,  Tensorflow has `HParams` plugin designed for Tensorflow 2.0 and Keras. 
https://www.tensorflow.org/tensorboard/r2/hyperparameter_tuning_with_hparams

Can you give me direction and/or a GitHub Repo or something?",0,1,False,self,,,,,
16,tensorflow,t5_3alkk,2019-9-4,2019,9,4,23,czl9c7,self.tensorflow,Rubik's cube solving TensorFlow model with Lego EV3 MindCub3r robot support,https://www.reddit.com/r/tensorflow/comments/czl9c7/rubiks_cube_solving_tensorflow_model_with_lego/,antondesaintbon,1567605611,"hey reddit!

Created this very simple dense feedforward model for a project with my kid to build a cube solving robot. It can reliably solve either virtual cubes or real ones when connected to Lego MindCub3r robot and it takes only few hours to train on an average PC without GPU accelerators.

This is a good way to get kids interested in robotics and machine learning so if you have or work with kids and wanna get involved check it out at [https://github.com/antbob/qub3rt](https://github.com/antbob/qub3rt)",1,11,False,self,,,,,
17,tensorflow,t5_3alkk,2019-9-5,2019,9,5,2,czo5x7,self.tensorflow,Why is tensorflow so hard to install?,https://www.reddit.com/r/tensorflow/comments/czo5x7/why_is_tensorflow_so_hard_to_install/,Technerder,1567618978,"I'd like to start off by saying that I am not a novice at programming or in using Linux/windows machines.

&amp;#x200B;

Every time I've tried to install tensorflow, whether on a laptop, raspberry pi 3 or desktop machine, I've never been able to successfully install it. I've had the install on my desktop machine (with Debian 10) and it froze everything (overnight) to the point where I needed to hard restart it. I've had run-ins where the linux installation docs told me to install bazel without stating that tensorflow didn't support the latest version (The build told me I needed to downgrade, which then lead to the comuter hanging). I've had issues with my raspberry pi hanging and no longer responding to any ssh commands until I hard restarted it. 

Over my \~6 years of programming I have never run into a library which has been harder to install. I understand that this is a massive project in the machine learning scene, written in multiple languages with thousands of contributors, but I still don't understand why it is so hard to install.",17,9,False,self,,,,,
18,tensorflow,t5_3alkk,2019-9-5,2019,9,5,5,czqjaa,self.tensorflow,Multiple inputs and multiple output in keras lstm,https://www.reddit.com/r/tensorflow/comments/czqjaa/multiple_inputs_and_multiple_output_in_keras_lstm/,sheneon91,1567630001,"Hi all,
I have a use case where I have sequences on one hand as an Input and I was using lstm to predict an output variable ( binary classification model).
Now there is a request to also predict the time when the event will happen. 
I have the time component in my data but now the model would be
Multiple input and multiple outputs.
One output is classification and other is regression.
Currently I have built my architecture where I have an embedding layer which goes to lstm for the sequences and then I add another input layer for some extra features.
Pretty much confused now regarding how to add this time sequence after the embedding layer and before lstm. Also the shapes have to be the same too else it's giving me an error.
Any help would be appreciated.",1,1,False,self,,,,,
19,tensorflow,t5_3alkk,2019-9-5,2019,9,5,6,czr0ms,self.tensorflow,TF2 Keras vs Estimators?,https://www.reddit.com/r/tensorflow/comments/czr0ms/tf2_keras_vs_estimators/,UysofSpades,1567632190,"Wanted to hear the opinions of the community here regarding some API usage. My first exposure to ML, in general, fell upon the Keras API. It was intuitive and left out a lot of the meat for quick prototyping of models. However, as my career progressed, I was met with more challenging problems, than the \_forecast weather tutorial\_ or \_iris species classification\_. I started experimenting with slight variations of recent studies that implemented abstract and complicated models in a variety of use cases in all industries. I quickly realized, as \_easy\_ as Keras is to pick up, it doesn't allow me to set up complicated models in an efficient way, namely the way GAN networks are structured [isn't as efficient.](https://github.com/keras-team/keras/issues/5312) Anyways, not bashing Keras, I still love it, but I started to personally experience some of the \_downsides\_ that a few experienced folks mentioned with the limitations. With this and coupled with the fact, that most studies I have read implemented TensorFlow via the low-level API calls, it forced me to dig deeper into the inner workings to see what goes on behind the scenes of Keras. I can confidently say that I have more questions now, than when I started, lol. Anyways my projects required that I build models that are scalable and relatively easily implemented at a production-level scale. Interestingly enough, I \_accidently\_ stumbled unto Estimators. I am surprised they don't get enough attention, seeing that every mother and their cousin has some article on medium on how to use ML.

&amp;#x200B;

Further reading on Estimators showed me that it is used also as a high-level API, and very similar to Keras. Google also advises that if one is to use Tensorflow in a production level setting, then they recommend using the Estimator API as [it scales easily, allows for multi-distribution, and easier cross-platform functionality.](https://www.tensorflow.org/guide/premade_estimators) However, with the release of TF2 and the complete integration of Keras into the library, and the fact that TF seems to have gone through a complete overhaul, I am at a lost yet again. The documentation is minimal at best around TF2, and I can't trust Medium articles, as it seems the majority is written by beginners themselves.

&amp;#x200B;

I'd like to open the floor to the community of people who has a little more knowledge of how vastly different TF2 actually is (in practice). Also people who have used Estimators instead, what are the pros and cons around this? Has the entire battlegrounds just changed with TF2? It is almost a trivial decision to go with one or the other?

&amp;#x200B;

Thank you for your time.",9,7,False,self,,,,,
20,tensorflow,t5_3alkk,2019-9-5,2019,9,5,12,czv98t,self.tensorflow,Docker service replicas in same node with multiple GPU's,https://www.reddit.com/r/tensorflow/comments/czv98t/docker_service_replicas_in_same_node_with/,vikash_kaushal,1567653273,"Hi all! I've been working on tensorflow for some months now, and I've been using docker as a service for hosting tf models using the rest api on a GPU machine. My doubt is whether it is possible to run two docker services on the same node but in two seperate GPU's? If possible, how? I have a machine with multiple GPU's and would like each replica of the service to use one GPU seperately! 
Thanks in advance!",2,1,False,self,,,,,
21,tensorflow,t5_3alkk,2019-9-5,2019,9,5,16,czxgdp,youtube.com,Style Transfer AI Tensorflow | Neural Style Transfer AI,https://www.reddit.com/r/tensorflow/comments/czxgdp/style_transfer_ai_tensorflow_neural_style/,OliviaWillson,1567667715,,0,1,False,https://b.thumbs.redditmedia.com/k7bQxYgDqpRw4dIrVgNYrL7_F491QfgbhcVT0ahfnxg.jpg,,,,,
22,tensorflow,t5_3alkk,2019-9-5,2019,9,5,17,czy6fq,self.tensorflow,"Neural Structured Learning (NSL) in TensorFlow, good to know that!",https://www.reddit.com/r/tensorflow/comments/czy6fq/neural_structured_learning_nsl_in_tensorflow_good/,makereven,1567673505,"Tensorflow team released an article about Neural Structured Learning in TensorFlow, an easy-to-use framework that both novice and advanced developers can use for training neural networks with structured signals.

here is the full content:  [https://medium.com/tensorflow/introducing-neural-structured-learning-in-tensorflow-5a802efd7afd](https://medium.com/tensorflow/introducing-neural-structured-learning-in-tensorflow-5a802efd7afd)",2,12,False,self,,,,,
23,tensorflow,t5_3alkk,2019-9-5,2019,9,5,20,czz9hz,self.tensorflow,Can we pass a list of no. Of hidden neurons in tf.layers.dense() once instead of one neuron per layer,https://www.reddit.com/r/tensorflow/comments/czz9hz/can_we_pass_a_list_of_no_of_hidden_neurons_in/,sahiluppal4k,1567681220,,0,1,False,self,,,,,
24,tensorflow,t5_3alkk,2019-9-5,2019,9,5,21,d00dif,medium.com,Avoiding the vanishing gradients problem by adding random noise and batch normalization,https://www.reddit.com/r/tensorflow/comments/d00dif/avoiding_the_vanishing_gradients_problem_by/,afagarap,1567687756,,1,2,False,default,,,,,
25,tensorflow,t5_3alkk,2019-9-5,2019,9,5,22,d012n3,self.tensorflow,using multiscale ssim as loss function,https://www.reddit.com/r/tensorflow/comments/d012n3/using_multiscale_ssim_as_loss_function/,hypo_hibbo,1567691391,"Hi, I am doing a project with image processing. I already successfully applied tf.image.ssim for my loss function. Now I would like to test results for the ms ssim.

My network generates 64x64 gray value image patches and therefore the loss calculated by comparing these patches with ground truth patches of the same size.

This is basically my loss:

&amp;#x200B;

          def custom_loss(y_true,y_pred)
                def SSIM_loss(y_true, y_pred):
                    return tf.image.ssim_multiscale(y_true, y_pred,1)
                # Return a function
                return SSIM_loss(y_true, y_pred)

I get this warning:

    InvalidArgumentError: Computed output size would be negative: -2 [input_size: 8, effective_filter_size: 11, stride: 1]
    	 [[{{node loss_3/subtract_8_loss/MS-SSIM/Scale3/depthwise_1}}]]
    	 [[{{node loss_3/mul}}]]

I don't understand what the probleme is. SSIM works fine. 

Thanks for your help!",1,1,False,self,,,,,
26,tensorflow,t5_3alkk,2019-9-6,2019,9,6,5,d06pmo,self.tensorflow,Question about adding TensorFlow to a NodeJS application,https://www.reddit.com/r/tensorflow/comments/d06pmo/question_about_adding_tensorflow_to_a_nodejs/,devdaesun,1567717018,"I have a side project that Im working on and a feature requires text analysis. Im thinking of doing this with TensorFlow.

Would I be able to implement TensorFlow right into my NodeJS application? Or would it be better practice to create a separate application to make API calls from TensorFlow to NodeJS?

I will be using TensorFlow.js for this.",6,4,False,self,,,,,
27,tensorflow,t5_3alkk,2019-9-6,2019,9,6,16,d0dljr,self.tensorflow,How to test a deeplab v3+ model trained using tf's research repository?,https://www.reddit.com/r/tensorflow/comments/d0dljr/how_to_test_a_deeplab_v3_model_trained_using_tfs/,shreshths,1567756349,"I used the deeplab rep for training my models and validatiing on Val set. What I can't figure out is a way to test my model on new images?
I'm not a pro at tf so maybe this is stupid but please help !",0,1,False,self,,,,,
28,tensorflow,t5_3alkk,2019-9-7,2019,9,7,4,d0lfbi,self.tensorflow,Please help me understand how Tensorflow's 2d convolutional layer handles multi-channel inputs?,https://www.reddit.com/r/tensorflow/comments/d0lfbi/please_help_me_understand_how_tensorflows_2d/,ManBearHybrid,1567798540,"For convolution layers with 2D inputs (e.g. grayscale images), I understand how the kernel will be scanned over the rows and columns to produce a  2D feature map.  Now I'm trying to specify multi-channel inputs, like for RGB images. According to the [keras documentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Conv2D)  for a conv2d layer, your input shape should be a tuple of the shape (samples, rows, cols, channels). So if we run the model on a single RGB  input image of 128 x 128 pixels, it will have to be reshaped to (1, 128,  128, 3). This is fine.

But the  documentation also says that the output will have the shape (samples, filters, new\_rows, new\_cols). This is as I expected for a 2D image, but  what happens to the 3rd dimension of multi-channel images? I tried to build such a simple one-layer model in Python as follows:

    import tensorflow as tf 
    ImgInputs = tf.keras.Input(shape=(128, 128, 3), name='img_input') 
    Conv1 = tf.keras.layers.Conv2D(
         filters=16,
         kernel_size=(4, 4), 
         strides=(1,1), 
         padding='same', 
         activation='relu')(ImgInputs) 
    model = tf.keras.Model(inputs=ImgInputs, outputs=Conv1) 
    optimizer = tf.keras.optimizers.Adam(lr=0.001) 
    model.compile(optimizer, loss='mse',metrics=['accuracy']) 
    
    model.summary() # print summary 

This runs without a problem. Since the kernel and stride for such a layer must be applied as 2D vectors (according to the docs), what happens to the channels? I would have guessed that the output ""depth"" would be equal to the number of kernels (16 in our case) multiplied by the number of channels (3), so 16 x 3 = 48. Put another way, I would have guessed that the output is the stacked result of multiple 2D convolutional layers, one for each channel (or some variation of this).

But when I build it and try it, the output is just (\[number of samples\] x 128 x 128 x 16) - the depth of each sample's output is just number of kernels, regardless of how many channels are provided. So it appears that the model is aggregating the channels somehow, but I'm not sure how. Can someone help me understand or point me to a resource that can explain it?",3,2,False,self,,,,,
29,tensorflow,t5_3alkk,2019-9-7,2019,9,7,15,d0ssow,youtube.com,Image recognition model in LSTM | Image classification |TensorFlow | LSTM For Thesis,https://www.reddit.com/r/tensorflow/comments/d0ssow/image_recognition_model_in_lstm_image/,OliviaWillson,1567839233,,0,1,False,https://b.thumbs.redditmedia.com/oo3PMkrXCE9EIFLW764RZroYyERvL25F18eRtCqmeRg.jpg,,,,,
30,tensorflow,t5_3alkk,2019-9-7,2019,9,7,23,d0wbjj,youtu.be,Stochastic vs Batch vs Mini-Batch Gradient Descent in Python,https://www.reddit.com/r/tensorflow/comments/d0wbjj/stochastic_vs_batch_vs_minibatch_gradient_descent/,bhavesh91,1567864880,,0,10,False,https://b.thumbs.redditmedia.com/awixHma0j_U0zHbgweNX86A54Uoa-NZm9m1A6GAUAwk.jpg,,,,,
31,tensorflow,t5_3alkk,2019-9-8,2019,9,8,4,d10jrc,self.tensorflow,How to access at 1 element of a dataset,https://www.reddit.com/r/tensorflow/comments/d10jrc/how_to_access_at_1_element_of_a_dataset/,Ste29ebasta,1567885035,"I'm using tf.data.Dataset to manage my data, but i have some problem using the map function, could you help me pls?

    def load_image(path):
        image = tf.read_file(path)

        image = tf.image.decode_jpeg(image, channels=3)
        image = tf.cast(image, tf.float32) / 255.0  # normalize to [0,1] range
    return image

    path_ds = tf.data.Dataset.from_tensor_slices((all_image_paths, all_image_labels, 
                                                                        all_image_classes))
    image_ds = path_ds.map(load_image, num_parallel_calls=AUTOTUNE) 


in order to make it work i have to write:

    def load_image(path,a,b):

and then ignore a and b, but what i'm asking you is how can i pass to my function just the paths that i have stored in my dataset?",0,1,False,self,,,,,
32,tensorflow,t5_3alkk,2019-9-8,2019,9,8,5,d11i38,self.tensorflow,How to access at 1 class of my tf.dataset?,https://www.reddit.com/r/tensorflow/comments/d11i38/how_to_access_at_1_class_of_my_tfdataset/,Ste29ebasta,1567889610,"I'm using tf.data.Dataset to manage my data, but i have some problem using the map function, could you help me pls?

    def load_image(path):
        image = tf.read_file(path)

        image = tf.image.decode_jpeg(image, channels=3)
        image = tf.cast(image, tf.float32) / 255.0  # normalize to [0,1] range
    return image

    path_ds = tf.data.Dataset.from_tensor_slices((all_image_paths, all_image_labels, 
                                                                        all_image_classes))
    image_ds = path_ds.map(load_image, num_parallel_calls=AUTOTUNE) 


in order to make it work i have to write:

    def load_image(path,a,b):

and then ignore a and b, but what i'm asking you is how can i pass to my function just the paths that i have stored in my dataset?",0,1,False,self,,,,,
33,tensorflow,t5_3alkk,2019-9-8,2019,9,8,9,d13ykz,/r/tensorflow/comments/d13ykz/ai_application_airgesture_lets_play_game_without/,[AI application] AirGesture - Let's play game without keyboard,https://www.reddit.com/r/tensorflow/comments/d13ykz/ai_application_airgesture_lets_play_game_without/,1991viet,1567902075,,4,67,False,default,,,,,
34,tensorflow,t5_3alkk,2019-9-8,2019,9,8,21,d1aaqa,self.tensorflow,XLA:CPU with basic convolutional neural network?,https://www.reddit.com/r/tensorflow/comments/d1aaqa/xlacpu_with_basic_convolutional_neural_network/,skellerone,1567945698,"I made a simple sequential neural network this week which works with 3 basic convolutional layers. It looks a little like the following:

&amp;#x200B;

model = models.Sequential()  
model.add(layers.Conv2D(32, (3, 3), activation='relu', input\_shape=(28, 28, 1)))  
model.add(layers.MaxPooling2D((2, 2)))  
model.add(layers.Conv2D(64, (3, 3), activation='relu'))  
model.add(layers.MaxPooling2D((2, 2)))  
model.add(layers.Conv2D(64, (3, 3), activation='relu'))

model.add(layers.Flatten())  
model.add(layers.Dense(64, activation='relu'))  
model.add(layers.Dense(10, activation='softmax'))

&amp;#x200B;

When I try to run this, my computer mentions XLA:CPU not being activated, which it looks like would make my model run faster with my GPU were I to compile my code beforehand with tf.xla.experimental.compile. However, when I try this, a number of issues come up when I try to fit my model, specifically related to the Conv2D layers. I assume jit\_scope would allow me to specify which values are to be compiled by XLA and which aren't, but how would I use this? Would I need to define the 2D convolution layers myself in order to specify which values can use XLA?",0,2,False,self,,,,,
35,tensorflow,t5_3alkk,2019-9-9,2019,9,9,16,d1njtv,rubikscode.net,How to integrate of TensorFlow Model in Angular Application?,https://www.reddit.com/r/tensorflow/comments/d1njtv/how_to_integrate_of_tensorflow_model_in_angular/,RubiksCodeNMZ,1568013390,,0,0,False,https://b.thumbs.redditmedia.com/GlN5z6p4FrKbTd3mYm_7rjIn5NKTobtW6tcSMsfh6ps.jpg,,,,,
36,tensorflow,t5_3alkk,2019-9-9,2019,9,9,21,d1qk5a,gereshes.com,Neural Network Based Optimal Control in Astrodynamics using TF,https://www.reddit.com/r/tensorflow/comments/d1qk5a/neural_network_based_optimal_control_in/,Gereshes,1568033899,,0,16,False,https://b.thumbs.redditmedia.com/sEg3BALIWQk8HtJXAHZLFep92AEko3URDCyXmWY0RTw.jpg,,,,,
37,tensorflow,t5_3alkk,2019-9-10,2019,9,10,13,d22qee,self.tensorflow,How to add inference to NN,https://www.reddit.com/r/tensorflow/comments/d22qee/how_to_add_inference_to_nn/,Stanley_C,1568090228," [https://github.com/tensorflow/docs/blob/r1.14/site/en/tutorials/estimators/cnn.ipynb](https://github.com/tensorflow/docs/blob/r1.14/site/en/tutorials/estimators/cnn.ipynb) 

How do I add code that lets me import a 28x28 greyscale image into my trained model with Numpy, and generate a prediction?",3,2,False,self,,,,,
38,tensorflow,t5_3alkk,2019-9-10,2019,9,10,18,d2541w,self.tensorflow,How do I persist notebooks in the Jupyter docker container?,https://www.reddit.com/r/tensorflow/comments/d2541w/how_do_i_persist_notebooks_in_the_jupyter_docker/,pragmojo,1568107410,"Hello,

I'm new here, hope I'm posting this in the appropriate place.

I'm trying to get started with the [Jupyter docker image](https://www.tensorflow.org/install/docker):

    tensorflow/tensorflow:latest-py3-jupyter

Everything is working great, but I would like to use the container and store any notebooks I create on my host filesystem.  By default this image comes pre-installed with the official tutorial notebooks, and all changes are lost when stopping/restarting the container.

Does anyone know how to host the notebooks on my own filesystem?  I would assume I need to map a directory somehow with the `--volume` flag.  I've tried `/notebooks` since this is used by s4tf but it doesn't seem to work with the python version.",2,2,False,self,,,,,
39,tensorflow,t5_3alkk,2019-9-10,2019,9,10,22,d27t05,habr.com,Important Things to Know About Tensorflow 2.0,https://www.reddit.com/r/tensorflow/comments/d27t05/important_things_to_know_about_tensorflow_20/,atomlib_com,1568123467,,0,3,False,default,,,,,
40,tensorflow,t5_3alkk,2019-9-11,2019,9,11,0,d291zi,self.tensorflow,Combining CSV files into one big dataset or tensor,https://www.reddit.com/r/tensorflow/comments/d291zi/combining_csv_files_into_one_big_dataset_or_tensor/,nikosz_boldis,1568128941,"Hi fellow tensorflow users,

I am having all of my features saved as independent CSV files matrices of our customers and their columns. Each of it is in the same dimensions. My task is to combine all of these .csv files into one big dataset or tensor, possibly keep it 3d.(cusomers,groups,features). The features are my .csv files. 

Maybe this is not the best practice I just started with tensorflow but this is how we need our data now.

 I would like to ask you if it is possible and if yes how. Thank you.",7,7,False,self,,,,,
41,tensorflow,t5_3alkk,2019-9-11,2019,9,11,14,d2l1pc,self.tensorflow,Update to MNIST inference,https://www.reddit.com/r/tensorflow/comments/d2l1pc/update_to_mnist_inference/,Stanley_C,1568178607,"Hi,

Here is my notebook, it is only slightly modified from the example one:  [https://github.com/itisyeetimetoday/mnist\_predict/blob/master/cnn.ipynb](https://github.com/itisyeetimetoday/mnist_predict/blob/master/cnn.ipynb). I tried to add a section for the model to predict which digit a single image from the dataset is, but I get this:  &lt;generator object Estimator.predict at 0x000002694B54B728&gt;   
 Could someone help me fix my error?",3,1,False,self,,,,,
42,tensorflow,t5_3alkk,2019-9-12,2019,9,12,2,d2u7an,github.com,High-performance TensorFlow library for quantitative finance (0.0.1-dev6 Release),https://www.reddit.com/r/tensorflow/comments/d2u7an/highperformance_tensorflow_library_for/,open_risk,1568224752,,0,10,False,default,,,,,
43,tensorflow,t5_3alkk,2019-9-12,2019,9,12,11,d3106p,self.tensorflow,Retraining: Failed to load the native TensorFlow runtime.,https://www.reddit.com/r/tensorflow/comments/d3106p/retraining_failed_to_load_the_native_tensorflow/,wymco,1568253732,"Hi,

I am working on a project to retrain an image classification model; I have been following this tutorial: [https://www.tensorflow.org/hub/tutorials/image\_retraining](https://www.tensorflow.org/hub/tutorials/image_retraining)

However, when I reached the section to run ""python retrain.py --image\_dir \~/flower\_photos"" I ended up with the error below. I am helpless at this point.Any assistance would be appreciated

&amp;#x200B;

`Traceback (most recent call last):`

  `File ""/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in &lt;module&gt;`

`from tensorflow.python.pywrap_tensorflow_internal import *`

  `File ""/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in &lt;module&gt;`

`_pywrap_tensorflow_internal = swig_import_helper()`

  `File ""/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper`

`_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)`

  `File ""/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/imp.py"", line 242, in load_module`

`return load_dynamic(name, filename, file)`

  `File ""/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/imp.py"", line 342, in load_dynamic`

`return _load(spec)`

`ImportError: dlopen(/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: _SecKeyCopyExternalRepresentation`

  `Referenced from: /Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.1.dylib`

  `Expected in: /System/Library/Frameworks/Security.framework/Versions/A/Security`

 `in /Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.1.dylib`

&amp;#x200B;

`During handling of the above exception, another exception occurred:`

&amp;#x200B;

`Traceback (most recent call last):`

  `File ""`[`retrain.py`](https://retrain.py)`"", line 131, in &lt;module&gt;`

`import tensorflow as tf`

  `File ""/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/__init__.py"", line 28, in &lt;module&gt;`

`from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import`

  `File ""/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/__init__.py"", line 49, in &lt;module&gt;`

`from tensorflow.python import pywrap_tensorflow`

  `File ""/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in &lt;module&gt;`

`raise ImportError(msg)`

`ImportError: Traceback (most recent call last):`

  `File ""/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in &lt;module&gt;`

`from tensorflow.python.pywrap_tensorflow_internal import *`

  `File ""/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in &lt;module&gt;`

`_pywrap_tensorflow_internal = swig_import_helper()`

  `File ""/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper`

`_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)`

  `File ""/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/imp.py"", line 242, in load_module`

`return load_dynamic(name, filename, file)`

  `File ""/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/imp.py"", line 342, in load_dynamic`

`return _load(spec)`

`ImportError: dlopen(/Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: _SecKeyCopyExternalRepresentation`

  `Referenced from: /Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.1.dylib`

  `Expected in: /System/Library/Frameworks/Security.framework/Versions/A/Security`

 `in /Users/Youssoufj/Projects/tensorf/retrain/september/retraining/mlocad/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.1.dylib`

`Failed to load the native TensorFlow runtime.`

`See` [`https://www.tensorflow.org/install/errors`](https://www.tensorflow.org/install/errors)

`for some common reasons and solutions.  Include the entire stack trace`

`above this error message when asking for help.`",0,1,False,self,,,,,
44,tensorflow,t5_3alkk,2019-9-13,2019,9,13,3,d3c43x,frontnet.eu,Introduction of pre-trained models in the field of Computer Vision,https://www.reddit.com/r/tensorflow/comments/d3c43x/introduction_of_pretrained_models_in_the_field_of/,frontnetcoin,1568312776,,0,4,False,default,,,,,
45,tensorflow,t5_3alkk,2019-9-13,2019,9,13,6,d3exul,self.tensorflow,Using Tensorflow of non-machine learning data processing tasks,https://www.reddit.com/r/tensorflow/comments/d3exul/using_tensorflow_of_nonmachine_learning_data/,jasonjerksit,1568324453,"I have a highly parallel image processing task that I want to  process as quickly as possible. Basically each column in this 'image' will independently have many operations applied to it e.g. fft, ifft , polynomial fitting... My question is , is tensorflow the right tool for something like this or would writing this in CUDA be more appropriate. It seems to me that tensorflow should be useful for any kind of large data processing pipeline but all examples online involve iterative optimization.",10,8,False,self,,,,,
46,tensorflow,t5_3alkk,2019-9-13,2019,9,13,7,d3ff06,self.deeplearning,"Cross post from r/deeplearning, can anyone here help?",https://www.reddit.com/r/tensorflow/comments/d3ff06/cross_post_from_rdeeplearning_can_anyone_here_help/,FullMetalMahnmut,1568326528,,0,1,False,default,,,,,
47,tensorflow,t5_3alkk,2019-9-13,2019,9,13,13,d3jvj7,self.tensorflow,Regression with Numpy questions,https://www.reddit.com/r/tensorflow/comments/d3jvj7/regression_with_numpy_questions/,Stanley_C,1568348122,"Hi,

I want to do the regression with the attached files, where nn\_inputs.npy are the inputs and nn\_outputs.npy are the values that I want to be predicted. Could someone point towards a repo or some code that have multiple x-axes for inputs and multiple y-axes for outputs? 

Thank you for your time.

&amp;#x200B;

Files: 

[https://drive.google.com/drive/folders/1-uwB5qH8UyOSxINrNE5UTDSUyRANu9LL?usp=sharing](https://drive.google.com/drive/folders/1-uwB5qH8UyOSxINrNE5UTDSUyRANu9LL?usp=sharing)",3,1,False,self,,,,,
48,tensorflow,t5_3alkk,2019-9-14,2019,9,14,14,d41d6p,youtu.be,Principal Component Analysis (PCA) from Scratch in Python,https://www.reddit.com/r/tensorflow/comments/d41d6p/principal_component_analysis_pca_from_scratch_in/,bhavesh91,1568440438,,3,11,False,default,,,,,
49,tensorflow,t5_3alkk,2019-9-15,2019,9,15,8,d4clr6,self.tensorflow,Converting Single Variable Polynomial DNN Regression to Multivariate Polynomial DNN Regression,https://www.reddit.com/r/tensorflow/comments/d4clr6/converting_single_variable_polynomial_dnn/,Stanley_C,1568502791,"Note: I'm giving credit to Tathagat Dasgupta for the base code that I'm trying to modify

My repo and progress:  [https://github.com/itisyeetimetoday/reggression/blob/master/tensorflow\_reg\_data.py](https://github.com/itisyeetimetoday/reggression/blob/master/tensorflow_reg_data.py) 

I added a section that turns my input and output arrays in 44 separate arrays, x\_0\_train, x\_0\_test, y\_0\_train, y\_0\_test, etc for each of the 22 variables(11 for input and 11 for output). The program uses  tf.estimator.DNNRegressor, which takes a parameter called feature\_columns. However, I'm confused about how to define a feature column with more than 1 variable.

Thank you for your help.",2,2,False,self,,,,,
50,tensorflow,t5_3alkk,2019-9-15,2019,9,15,17,d4htnd,self.tensorflow,Tensorflow - Retraining errors with hidden files,https://www.reddit.com/r/tensorflow/comments/d4htnd/tensorflow_retraining_errors_with_hidden_files/,wymco,1568535844,"I  am retraining a tensorflow model to classify images, but this time it  seems there are some hidden files in my folders that breaking the  application. I am wondering how I can skip these files when my  application is running; The original code is from this:

[https://github.com/tensorflow/hub/blob/master/examples/image\_retraining/retrain.py](https://github.com/tensorflow/hub/blob/master/examples/image_retraining/retrain.py)

Is there anything that I can do?

`Traceback (most recent call last):`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1356, in _do_call`

`return fn(*args)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1341, in _run_fn`

`options, feed_dict, fetch_list, target_list, run_metadata)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1429, in _call_tf_sessionrun`

`run_metadata)`

`tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected image (JPEG, PNG, or GIF), got unknown format starting with '\000\005\026\007\000\002\000\000Mac OS X'`

`[[{{node DecodeJpeg}}]]`

`During handling of the above exception, another exception occurred:`

`Traceback (most recent call last):`

`File ""retrain.py"", line 364, in create_bottleneck_file`

`resized_input_tensor, bottleneck_tensor)`

`File ""retrain.py"", line 332, in run_bottleneck_on_image`

`{image_data_tensor: image_data})`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 950, in run`

`run_metadata_ptr)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1173, in _run`

`feed_dict_tensor, options, run_metadata)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1350, in _do_run`

`run_metadata)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1370, in _do_call`

`raise type(e)(node_def, op, message)`

`tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected image (JPEG, PNG, or GIF), got unknown format starting with '\000\005\026\007\000\002\000\000Mac OS X'`

`[[node DecodeJpeg (defined at retrain.py:936) ]]`

`Errors may have originated from an input operation.`

`Input Source operations connected to node DecodeJpeg:`

`DecodeJPGInput (defined at retrain.py:935)`

`Original stack trace for 'DecodeJpeg':`

`File ""retrain.py"", line 1349, in &lt;module&gt;`

`tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/platform/app.py"", line 40, in run`

`_run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/absl/app.py"", line 299, in run`

`_run_main(main, args)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main`

`sys.exit(main(argv))`

`File ""retrain.py"", line 1040, in main`

`jpeg_data_tensor, decoded_image_tensor = add_jpeg_decoding(module_spec)`

`File ""retrain.py"", line 936, in add_jpeg_decoding`

`decoded_image = tf.image.decode_jpeg(jpeg_data, channels=input_depth)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/ops/gen_image_ops.py"", line 1211, in decode_jpeg`

`dct_method=dct_method, name=name)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper`

`op_def=op_def)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func`

`return func(*args, **kwargs)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 3616, in create_op`

`op_def=op_def)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 2005, in __init__`

`self._traceback = tf_stack.extract_stack()`

`During handling of the above exception, another exception occurred:`

`Traceback (most recent call last):`

`File ""retrain.py"", line 1349, in &lt;module&gt;`

`tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/platform/app.py"", line 40, in run`

`_run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/absl/app.py"", line 299, in run`

`_run_main(main, args)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main`

`sys.exit(main(argv))`

`File ""retrain.py"", line 1054, in main`

`bottleneck_tensor, FLAGS.tfhub_module)`

`File ""retrain.py"", line 470, in cache_bottlenecks`

`resized_input_tensor, bottleneck_tensor, module_name)`

`File ""retrain.py"", line 412, in get_or_create_bottleneck`

`bottleneck_tensor)`

`File ""retrain.py"", line 367, in create_bottleneck_file`

`str(e)))`

`RuntimeError: Error during processing file marks/Egba/._eba6.jpg (Expected image (JPEG, PNG, or GIF), got unknown format starting with '\000\005\026\007\000\002\000\000Mac OS X'`

`[[node DecodeJpeg (defined at retrain.py:936) ]]`

`Errors may have originated from an input operation.`

`Input Source operations connected to node DecodeJpeg:`

`DecodeJPGInput (defined at retrain.py:935)`

`Original stack trace for 'DecodeJpeg':`

`File ""retrain.py"", line 1349, in &lt;module&gt;`

`tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/platform/app.py"", line 40, in run`

`_run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/absl/app.py"", line 299, in run`

`_run_main(main, args)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main`

`sys.exit(main(argv))`

`File ""retrain.py"", line 1040, in main`

`jpeg_data_tensor, decoded_image_tensor = add_jpeg_decoding(module_spec)`

`File ""retrain.py"", line 936, in add_jpeg_decoding`

`decoded_image = tf.image.decode_jpeg(jpeg_data, channels=input_depth)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/ops/gen_image_ops.py"", line 1211, in decode_jpeg`

`dct_method=dct_method, name=name)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper`

`op_def=op_def)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func`

`return func(*args, **kwargs)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 3616, in create_op`

`op_def=op_def)`

`File ""/home/youssoufj/Coding/ocad/venv/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 2005, in __init__`

`self._traceback = tf_stack.extract_stack()`

`)`",0,0,False,self,,,,,
51,tensorflow,t5_3alkk,2019-9-16,2019,9,16,19,d4yq6z,self.tensorflow,I probably implemented Glow and RealNVP with Tensorflow 2.0.0rc0 and Tensorflow Probability 0.8.0rc0!,https://www.reddit.com/r/tensorflow/comments/d4yq6z/i_probably_implemented_glow_and_realnvp_with/,MeguruMokke,1568629454,"If you have any advice, please let me know via comment.

[https://github.com/MokkeMeguru/glow-realnvp-tutorial](https://github.com/MokkeMeguru/glow-realnvp-tutorial)

&amp;#x200B;

 example output

https://i.redd.it/8xnlso62nxm31.png",0,8,False,https://b.thumbs.redditmedia.com/sLsxjQnucgW9sndKyT829MC-NAE4BlJMbjnJ3wofi_o.jpg,,,,,
52,tensorflow,t5_3alkk,2019-9-16,2019,9,16,23,d518oq,self.tensorflow,Typical RAM requirement for Deep Q Learning?,https://www.reddit.com/r/tensorflow/comments/d518oq/typical_ram_requirement_for_deep_q_learning/,callahman,1568643265,"I'm new to Reinforcement modeling, so this definitely could be a problem with my model.

After about 10k training steps I'm maxing out my 16gb RAM. I recently built a simple LSTM model that's pretty similar in terms of layer &amp; node count, but it didn't have this memory issue.

Is there something intrinsic to Deep Q that causes this memory consumption? What should 'typical' memory consumption look like?

Thanks!

Ps - Any opinions on what cloud resource too use for data storage/training as an individual?",3,2,False,self,,,,,
53,tensorflow,t5_3alkk,2019-9-17,2019,9,17,1,d531j5,self.tensorflow,Loading model trained with the c api,https://www.reddit.com/r/tensorflow/comments/d531j5/loading_model_trained_with_the_c_api/,jregalad-o,1568651152,"Hi, I am going nuts over this and I feel I am running out of options. I hope I can find some help here.  


I am using the C api to train TF models created and exported from python. I can successfully create a model using tf.keras and export it with keras.experimental.export\_saved\_model(). Afterwards I can successfully load the model in my C program and train it given the configuration I used when creating the model.  


Trained model generates a checkpoint file which I can load in my C program to resume training or serve predictions.   


Unfortunately I am unable to reload the trained model in python. Model loads ok with keras.load\_from\_saved\_model(), this loads an untrained model, and when trying to load weights wither via model.load\_weights() or the tf.train.Checkpoint things just don't work.  


A post about this can be found in:  
[https://stackoverflow.com/questions/57944786/load-trained-keras-tensorflow-model-into-python](https://stackoverflow.com/questions/57944786/load-trained-keras-tensorflow-model-into-python)",9,3,False,self,,,,,
54,tensorflow,t5_3alkk,2019-9-18,2019,9,18,13,d5sw3j,self.tensorflow,Why is the Linux installation so much larger than Windows?,https://www.reddit.com/r/tensorflow/comments/d5sw3j/why_is_the_linux_installation_so_much_larger_than/,Th3OnlyN00b,1568782662,"I'm not sure what I'm doing wrong, but when I run \`pip install tensorflow -t ./\` (install in local directory) on windows the entire thing is 142 mb. On linux however, it is about 607 mb. Why is there such a large size difference, and is there any way to reduce it?",1,3,False,self,,,,,
55,tensorflow,t5_3alkk,2019-9-18,2019,9,18,18,d5vhl1,self.tensorflow,Raise a flag based on an array sequence,https://www.reddit.com/r/tensorflow/comments/d5vhl1/raise_a_flag_based_on_an_array_sequence/,tonystarkco,1568800694,"I have some dynamically generated sequences of integers inside an Array, like: 

\[ 123, 231, 2212, 1234, 121, 12 \]    
\[ 32, 334, 2314, 664, 12, 5667, 3454, 245 \] 

Some of the sequences raise a flag. I want to predict whenever a flag will be raised based on a trained model with continuously stored sequences of the past. 

I am working on NodeJS. 

Can someone advice where do I start?",2,1,False,self,,,,,
56,tensorflow,t5_3alkk,2019-9-18,2019,9,18,22,d5y44r,self.tensorflow,Save keras Model with additional MetaGraphDef?,https://www.reddit.com/r/tensorflow/comments/d5y44r/save_keras_model_with_additional_metagraphdef/,jregalad-o,1568814793,"Does anybody know how to export a tf keras model with an additional MetaGraphDef?  


I want to have a MetaGraphDef with tag 'train' in order to train with c\_aip .h",0,1,False,self,,,,,
57,tensorflow,t5_3alkk,2019-9-19,2019,9,19,1,d60lst,udemy.com,Master the Most Important Deep Learning Frameworks (Tensorflow &amp; Keras) for Python Data Science,https://www.reddit.com/r/tensorflow/comments/d60lst/master_the_most_important_deep_learning/,onsumocom,1568825549,,0,1,False,default,,,,,
58,tensorflow,t5_3alkk,2019-9-19,2019,9,19,2,d60wq9,self.tensorflow,"What kind of interview questions I need to prepare for tensorflow? Remembering all API is very tough . Please help me here .I am currently doing a challenge from kaggle using tf , will that suffice or there is sometime more I should focus on.",https://www.reddit.com/r/tensorflow/comments/d60wq9/what_kind_of_interview_questions_i_need_to/,shwetashri,1568826833,,1,0,False,self,,,,,
59,tensorflow,t5_3alkk,2019-9-19,2019,9,19,2,d61jur,self.tensorflow,Converting dnn regression to multi variable dnn regression,https://www.reddit.com/r/tensorflow/comments/d61jur/converting_dnn_regression_to_multi_variable_dnn/,Stanley_C,1568829529,"Note: I didn't write the code, here is the code I'm trying to modify this https://gist.github.com/balzer82/b5cac8fb214e0b52efa0ea7b8a058681 and my repository is here.
https://github.com/itisyeetimetoday/reggression

Ive modified the repo to load in all 11 input variables and all 11 output variables in 2 numpy arrays. 
I'm currently trying to convert a singular variable regression to a multi-variable DNN regression. Line 76 in regressor_full.py always returns an error about incompatible shape. I've changed the input to the shape of 11, however, I don't know to change the output layer to 11 too.

Line 76 : feature_columns = [tf.feature_column.numeric_column('X', shape=(11,))]
However, I'm sure that the input and output tensors aren't the only 2 things that have to be changed. Could you guys help me with adapting the repo? Thank you",0,1,False,self,,,,,
60,tensorflow,t5_3alkk,2019-9-19,2019,9,19,15,d6ac2v,javatpoint.com,Architecture of TensorFlow,https://www.reddit.com/r/tensorflow/comments/d6ac2v/architecture_of_tensorflow/,nehapandey01,1568876184,,0,4,False,default,,,,,
61,tensorflow,t5_3alkk,2019-9-20,2019,9,20,12,d6osdh,self.tensorflow,Learn Machine Learning Zero to Hero!,https://www.reddit.com/r/tensorflow/comments/d6osdh/learn_machine_learning_zero_to_hero/,Rogers911z,1568948560,[https://www.youtube.com/watch?v=yIR\_bMInPGo](https://www.youtube.com/watch?v=yIR_bMInPGo),2,0,False,self,,,,,
62,tensorflow,t5_3alkk,2019-9-20,2019,9,20,12,d6p5bs,self.tensorflow,Textgenrnn - Interactive Mode Not Working Properly,https://www.reddit.com/r/tensorflow/comments/d6p5bs/textgenrnn_interactive_mode_not_working_properly/,PoeticGoodKitty,1568950519,"So I'm trying to use textgenrnn's interactive mode using `textgen.generate(interactive=True, top_n=5)` but the options appear as letters instead of words, so I can't use it properly.

    Controls:
    	s: stop.	x: backspace.	o: write your own.
    
    Options:
    	1:  
    	2: t
    	3: s
    	4: a
    	5: i
    
    Progress: 
    
    Your choice?

What am I doing wrong?",0,1,False,self,,,,,
63,tensorflow,t5_3alkk,2019-9-20,2019,9,20,18,d6s9f2,self.tensorflow,issue with CORS,https://www.reddit.com/r/tensorflow/comments/d6s9f2/issue_with_cors/,Neofelis_,1568970817,"I've began to learn tensorflow for a week and just implement some model which come from the official website.
My website isn't on a server for now and when I run my page I still have one error in relation with CORS.

What should I do..?
I'm still learning web programming so I have no idea what I have to do

Thank",4,0,False,self,,,,,
64,tensorflow,t5_3alkk,2019-9-21,2019,9,21,23,d7b4qu,pgaleone.eu,Hands-On Neural Networks with TensorFlow 2.0 - book OUT NOW!,https://www.reddit.com/r/tensorflow/comments/d7b4qu/handson_neural_networks_with_tensorflow_20_book/,pgaleone,1569075898,,4,14,False,default,,,,,
65,tensorflow,t5_3alkk,2019-9-25,2019,9,25,0,d8p0z8,self.tensorflow,Which way to proceed for distributed learning under tensorflow?,https://www.reddit.com/r/tensorflow/comments/d8p0z8/which_way_to_proceed_for_distributed_learning/,shahriar49,1569340077," I see a bunch of different methods in many web sites and Tensorflow guides to proceed for implementing a distributed learning example but can not clear my mind on them. Let me be simple and clear: I have model created under keras, have setup the TF\_CONFIG to have a chief, a worker, a ps, and an evaluator server, and I assume that the below code should do the job:

    runConfig = tf.estimator.RunConfig(session_config=config,
                            	   model_dir=log_dir,
                     		   save_summary_steps=1,
                     		   save_checkpoints_steps=train_steps)
    estimator = tf.keras.estimator.model_to_estimator(model, model_dir=log_dir, config=runConfig) 
    train_spec = tf.estimator.TrainSpec(input_fn=lambda: read_datasets(...), max_steps=epochs*train_steps) eval_spec = tf.estimator.EvalSpec(input_fn=lambda: read_datasets(...), steps=None) tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec) 

And then I can see the performance graphs and values on Tensorboard. My understanding from the web resources and discussions I had on forums is that the code for all servers are exactly the same except the TF\_CONFIG part, and just one copy of training data is needed to be placed in a shared folder, and one shared directory is set to save model parameters and checkpoints, and the chief is going to synchronize everything on splitting the data between workers and saving the model and summaries. But I am not sure of this picture. My tests show that the workers need to access dataset otherwise the code returns an error, but if they also read the dataset, how global batch splitting is synchronized?

In addition, I see pages about distribution strategy and its implications on keras and estimators, which make me so much confused. Do I really need all of these strategy stuff, or just above code is sufficient? What about the input\_fn? I assumed that the chief is taking care of data split but in the tensorflow documentation ([https://www.tensorflow.org/guide/distribute\_strategy](https://www.tensorflow.org/guide/distribute_strategy)) it says different things for keras and estimator implementation, and my application is a keras model encapsulated in an estimator! What should I do?",0,1,False,self,,,,,
66,tensorflow,t5_3alkk,2019-9-25,2019,9,25,1,d8pb79,self.tensorflow,Combining map and padded_batch in tensorlow,https://www.reddit.com/r/tensorflow/comments/d8pb79/combining_map_and_padded_batch_in_tensorlow/,shahriar49,1569341317, To increase the performance on input pipeline tensorflow documentation recommends using tf.contrib.data.map\_and\_batch instead of separate .map and  .batch functions ([https://www.tensorflow.org/guide/performance/datasets](https://www.tensorflow.org/guide/performance/datasets)). But how to combine .map and .padded\_batch functions in input pipeline?,0,2,False,self,,,,,
67,tensorflow,t5_3alkk,2019-9-25,2019,9,25,1,d8phxn,self.tensorflow,Is distributed learning feasible for my application?,https://www.reddit.com/r/tensorflow/comments/d8phxn/is_distributed_learning_feasible_for_my/,shahriar49,1569342120," I am running a LSTM network to classify a huge database of remote sensing sequences to their respective landcovers. Code is developed on Tensorflow/Keras and I am trying models with 3 to 7 layers, each having 16 to 64 LSTM cells. Due to huge data size (around 13.5M sample sequences), I am interested to do my model training in distributed mode by data parallelization over multiple GPUs or multiple PCs. However, my tries by now have not resulted in any improvement over single system version and I am thinking if it is feasible at all or not.

My understanding from data parallelism under Tensorflow/Keras is that there are different workers, a chief, and a parameter server (ps). Model parameters are stored in ps and communicated with workers and chief, and each worker works on a partition of the whole data. Each worker should get the model parameters from ps at the start of each data batch processing, do all the forward and backward propagation and calculate the weight updates and send them back to ps, where the updated model parameters are calculated by chief and stored. Therefore, each worker should read the model parameters before each batch processing.

My simulation batch size is 1024, therefore there are about 13K batches in one epoch of data. Training of a model with 87,000 parameters took 412 seconds in my one-gpu system, which means about 30 ms per batch. A more complex model with 1M parameters took 1900 seconds to process one epoch, which means about 146 ms per batch.

Now that I look at the numbers, I am in doubt if data parallelism is helpful. If two GPUs or CPUs want to communicate 100K or 1M parameters, can it be so fast to be done in a few milliseconds to be negligible? My experiments on a two-GPU system (which even doesn't require data transmission over network) resulted in batch processing time of twice single-GPU. Can it be attributed to the small batch processing time and the data communication overhead on top of that? If it is, does it mean that my model is not as complex as necessary for distributed learning?",2,3,False,self,,,,,
68,tensorflow,t5_3alkk,2019-9-25,2019,9,25,2,d8qfte,self.tensorflow,Distributed training on different computer configurations in Tensorflow,https://www.reddit.com/r/tensorflow/comments/d8qfte/distributed_training_on_different_computer/,shahriar49,1569346162,"If I have one PC with 2 RTX 2080 Ti GPU and one PC with 1 GTX 1080 Ti GPU, what is the best approach to use them with maximum utilization for doing a distributed learning of a keras model in tensorflow? I am inclined to encapsulate keras model in an estimator class but then I don't know how to define the above GPU configuration in TF\_CONFIG dictionary.",0,1,False,self,,,,,
69,tensorflow,t5_3alkk,2019-9-25,2019,9,25,2,d8qox2,self.tensorflow,RunConfig distribute parameters,https://www.reddit.com/r/tensorflow/comments/d8qox2/runconfig_distribute_parameters/,shahriar49,1569347282,"As train\_distribute and eval\_distribute parameters are optional in tf.estimator.RunConfig, what will happen if we don't specify them? Are they required to run the model properly in distributed configuration?",0,1,False,self,,,,,
70,tensorflow,t5_3alkk,2019-9-25,2019,9,25,3,d8r2kw,self.tensorflow,"EstimatorSpec, TrainSpec, EvalSpec, ... what it is for?",https://www.reddit.com/r/tensorflow/comments/d8r2kw/estimatorspec_trainspec_evalspec_what_it_is_for/,shahriar49,1569348909,"My understanding after reading tensorflow guides about estimator class is that it requires a model\_fn that defines what estimator does in each mode of operation, so it is like a function. Then I don't understand the term and meaning and purpose of adding another thing named EstimatorSpec and returning it at the end of model\_fn. If the model\_fn is run by estimator, why do we need this complex notation? Same thing with TrainSpec and EvalSpec: Having input\_fn definition, why we need these things? I think I can not get the real purpose and meaning of these stuff, and the tensorflow documentation is really not helping to grasp the concepts.

Anybody has a simple but precise explanation of these concepts?",3,2,False,self,,,,,
71,tensorflow,t5_3alkk,2019-9-25,2019,9,25,11,d8x02c,self.tensorflow,Working with a TFRecord that represents a SparseTensor,https://www.reddit.com/r/tensorflow/comments/d8x02c/working_with_a_tfrecord_that_represents_a/,MLnewbie22,1569377830,"I'm working with a TFRecord where all the feature engineering has already been done for me. The TFRecord has in it a set of records, where each record has `indices`, `values`, and `length` in byte string to represent the original SparseTensor. I'm trying to parse this TFRecord so that I can get it to work with the `tf.estimator.LinearClassifier` object, but I can't seem to get it to work. Here's what I'm working with: 

**TFRecord:** 

    features {
      feature {
        key: ""indices""
        value {
          int64_list {
            value: 0
            ...
            value: 117
          }
        }
      }
      feature {
        key: ""length""
        value {
          int64_list {
            value: 131
          }
        }
      }
      feature {
        key: ""values""
        value {
          float_list {
            value: 0.0
            ...
            value: 1.0
          }
        }
      }
    }

This is a little weird because the non-zero features themselves which are the indices are being saved as a single feature. This is confusing me quite a bit!! 

**The inputs:**

    # inputs 
    tf_record = 'file.tfrecords'
    feature_names = ['feature1', 'feature2', 'feature3', ..., 'feature130'] 

**My TFRecord parser function:** 

    # TFRecord parser function
    def parse_function(example_proto):
    
        # create a dict of the description of the features
        sparse_feature_description = {'sparse': tf.SparseFeature(
                        index_key=['indices'],
                        value_key='values',
                        dtype=tf.float32,
                        size=[num_features])
            
        }
        # parse the input tf.Example proto using the dictionary above
        all_features = tf.parse_single_example(example_proto, sparse_feature_description)['sparse']
        features = tf.sparse.slice(all_features, [1], [num_features])
        label = tf.sparse.to_dense(tf.sparse.slice(all_features, [0],[1]))
    
        return features, label

This returns a Dataset with records of features and labels... not sure if this is correct. 

**My input function:** 

    def input_fn(tf_record):
        return tf.data.TFRecordDataset(filenames = tf_record).map(parse_function)

**Feature Columns:**

    feature_columns = [tf.feature_column.numeric_column(k) for k in feature_names[1:]]

**Model:**

    classifier = tf.estimator.LinearClassifier(
        feature_columns=feature_columns)
    classifier.train(
        input_fn = lambda: input_fn2(train_file2))

But I get an error: 

    ValueError: features should be a dictionary of `Tensor`s. Given type: &lt;class 'tensorflow.python.framework.sparse_tensor.SparseTensor'&gt;

And I'm not sure what this refers to and unfortunately, this is my first time trying to use TensorFlow. 

**My main questions:** 

* Is this the correct workflow when dealing with a TFRecord that is saved as a SparseTensor? 
   * If not, is there a better way to deal with TFRecords saved as SparseTensors? 
* What is the `ValueError` reffering to?",3,4,False,self,,,,,
72,tensorflow,t5_3alkk,2019-9-26,2019,9,26,7,d9ac46,self.tensorflow,help with implementing custom loss on the integral of outputs (tensorflow / keras),https://www.reddit.com/r/tensorflow/comments/d9ac46/help_with_implementing_custom_loss_on_the/,progmayo,1569449237,"Hi guys! I'd really appreciate help in a problem I ran into.

**The goal**

I want to implement a custom loss in keras which is an integral on the outputs.Using the notations of keras, custom loss functions are of the form

    def custom_loss(y_true, y_pred):

Where y\_true are the labels and y\_pred are the models' predictions. I also have the inputs X at hand (using a wrapper function around the custom\_loss). This input is of the same shape as the labels / predictions.Using these notations, the loss I wish to impose looks something along the lines of:

&amp;#x200B;

https://i.redd.it/9dj3gotn1so31.png

Where f(x) is some function that's irrelevant to this discussion. Note that y\_true are irrelevant to the loss function (and that's ok. I have multiple loss functions, don't worry ;) )

Now x and y\_pred are simply arrays of 1XL for some length L.

For those familiar with scipy.integrate, this integral very easily calculated using the trapz function:

    trapz(y_pred*f(X), X)

&amp;#x200B;

**The problem /technical difficulty**

I'll describe the attempts I've made thus far, and the errors I faced in their implementation:

1. Used tensorflow.py\_function to wrap scipy.integrate.trapzThis returned an error where keras did not know how to calculate the derivative. I'm guessing keras precompiles derivative functions to use in the SGD optimizer?
2. Copied a function I found that implements trapz using keras / tf functions:

&amp;#x200B;

    def trapezoidal_integral_approx(t, y):
        return math_ops.reduce_sum(
                math_ops.multiply(t[1:] - t[:-1],
                                  (y[1:] + y[:-1]) / 2.), 
                name='trapezoidal_integral_approx')

This returned some weird error that I didn't understand:

&gt;tensorflow.python.framework.errors\_impl.InvalidArgumentError: Can not squeeze dim\[0\], expected a dimension of 1, got 1401  
&gt;  
&gt;\[\[{{node loss\_3/encoder\_output\_loss/weighted\_loss/Squeeze}}\]\]

&amp;#x200B;

3. Using tf.contrib.integrate.odeint: [https://www.tensorflow.org/api\_docs/python/tf/contrib/integrate/odeint](https://www.tensorflow.org/api_docs/python/tf/contrib/integrate/odeint)This function just seems unintuitive and not suited for my needs (not trapz). I did not fully try to implement this method, and if someone suggests it, I can give it a try, but it does not accept two arrays as I need it to.

&amp;#x200B;

**Bottom line**

I'd appreciate help in my particular problem,  or a link to some code / example that attempts something similar (loss function that is comprised of an integral on y\_true or y\_pred or something along those lines).

&amp;#x200B;

# Thank you very very much in advance to anyone willing to help :)",3,1,False,https://b.thumbs.redditmedia.com/RoqmAmODue5qdA1SRxCisdBtuBs2U0JsBfmj05UZotE.jpg,,,,,
73,tensorflow,t5_3alkk,2019-9-26,2019,9,26,10,d9d2ze,self.tensorflow,Get the size of the intersection between 2 sets (custom loss function),https://www.reddit.com/r/tensorflow/comments/d9d2ze/get_the_size_of_the_intersection_between_2_sets/,thezaza101,1569463084,"I'm trying to implement a custom loss function for a image  segmentation model. I'm having trouble figuring out how to get the size  of the intersection between 2 sets.

The code i have so far is :

    def SSCLoss(y_true, y_pred):
   y_true = K.flatten(y_true)
   y_pred = K.flatten(y_pred)
   yTestUn, idx = tf.unique(y_true)
   yPredUn, idx = tf.unique(y_pred)
   maxLen = tf.math.maximum(tf.size(yTestUn), tf.size(yPredUn))
   numEqual = tf.size(tf.sets.set_intersection(tf.dtypes.cast(yTestUn,tf.uint16), tf.dtypes.cast(yPredUn,tf.uint16)))
 return tf.math.subtract(tf.constant(1), tf.math.divide(numEqual, maxLen))

I keep getting the error  `ValueError: Shape must be at least rank 2 but is rank 1 for 'loss/activation_1_loss/DenseToDenseSetOperation' (op: 'DenseToDenseSetOperation') with input shapes: [?], [?].` 

Any idea whats going on here?

 The non-TensorFlow implementation of this function is: 

    def SSC(y_true, y_pred):
 if (y_true.ndim &gt; 1):
      y_true = np.array(y_true).ravel()
 if (y_pred.ndim &gt; 1):
      y_pred = np.array(y_pred).ravel()

      yTestUn = pd.Series(y_true).unique()
   yPredUn = pd.Series(y_pred).unique()
   maxLen = float(max(len(yTestUn), len(yPredUn)))
   numEqual = float(len(set(list(yTestUn)) - (set(list(yTestUn)) - set(list(yPredUn)))))
 return 1 - float(numEqual / maxLen)

formula is:

&amp;#x200B;

![gif](fts03jqzhuo31)",0,2,False,self,,,,,
74,tensorflow,t5_3alkk,2019-9-26,2019,9,26,13,d9et7o,self.tensorflow,where can I find exmples of Tensorflow on Raspberry pi,https://www.reddit.com/r/tensorflow/comments/d9et7o/where_can_i_find_exmples_of_tensorflow_on/,vaibhavkumar049,1569472729,"Once surfing through net I stumbled upon a repo on github where there were examples of tensorflow on raspberry pi but now I am not able to find it. Mind it, it was official repo.  Can anyone post the link here",0,6,False,self,,,,,
75,tensorflow,t5_3alkk,2019-9-26,2019,9,26,22,d9jdt1,self.tensorflow,GPU server for feedback!,https://www.reddit.com/r/tensorflow/comments/d9jdt1/gpu_server_for_feedback/,skazakov,1569503160," Greetings everyone,  


My name is Sergey, I'm from Hostkey ([hostkey.com](http://hostkey.com/)).   
We are looking for a way to improve our services for Tensorflow users and make their lives a bit easier. We started deploying GPU servers with Tensorflow pre-installed, but we are sure that we can do more.   
We would like to offer one of our servers for one Tensorflow user as a free-of-charge test, this certain someone can use this GPU server to train its models or another AI/ML purposes. However, there is one condition: after the test is over, we would like to receive detailed feedback of our services - what did you like about it, what's our flaws, what else can we do to help users from Tensorflow community, etc...  
If you would like to participate, kindly send a short description of your project and technical requirements to [dasafyev@hostkey.com](mailto:dasafyev@hostkey.com) , we will choose one lucky person and contact him via email. 

Thank you",1,0,False,self,,,,,
76,tensorflow,t5_3alkk,2019-9-26,2019,9,26,23,d9kj10,self.tensorflow,Converting Tensorflow Model into Keras Model,https://www.reddit.com/r/tensorflow/comments/d9kj10/converting_tensorflow_model_into_keras_model/,UysofSpades,1569508737,"Hello. I am trying to convert some open source code that was written in the TensorFlow API into Keras API. I am getting the correct input and output shapes for each layer, however, it complains when I try to do a test on the model itself. Please excuse the code, I simplified a lot for brevity.

&amp;#x200B;

Here is the tensorflow API:
```python
        hidden_units_g = 100
        num_generated_features = 1
        seq_length = 30
        batch_size = 28
        latent_dim = 5

        W_out_G = tf.get_variable(name='W_out_G', shape=[hidden_units_g, num_generated_features], initializer=W_out_G_initializer)
        b_out_G = tf.get_variable(name='b_out_G', shape=num_generated_features, initializer=b_out_G_initializer)
        
        # shape: (28, 30, 5)
        inputs = tf.random_normal(shape=(batch_size, seq_length, latent_dim))

        cell = LSTMCell(num_units=hidden_units_g,
                           state_is_tuple=True,
                           initializer=lstm_initializer,
                           bias_start=bias_start,
                           reuse=reuse)

        # rnn_output shape: (28, 30, 100)
        rnn_outputs, rnn_states = tf.nn.dynamic_rnn(
            cell=cell,
            dtype=tf.float32,
            sequence_length=[seq_length]*batch_size,
            inputs=inputs)

        # reshape shape: (840, 100)
        rnn_outputs_2d = tf.reshape(rnn_outputs, [-1, hidden_units_g])

        # shape: ( 840, 1)
        logits_2d = tf.matmul(rnn_outputs_2d, W_out_G) + b_out_G

        # shape: (840, 1)
        output_2d = tf.nn.tanh(logits_2d)

        # shape: (28, 30, 1)
        output_3d = tf.reshape(output_2d, [-1, seq_length, num_generated_features])

```

Here is my attempt to recreate this in Keras:

```python
gen = tf.keras.models.Sequential([
    tf.keras.layers.LSTM(100, input_shape=(30, 5), return_sequences=False),
    #tf.keras.layers.Dense(1, activation='tanh'),
    tf.keras.layers.Dense(1, activation='tanh'),
    tf.keras.layers.Reshape(target_shape=(30, 1))
])
Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 100)               42400     
_________________________________________________________________
dense (Dense)                (None, 1)                 101       
_________________________________________________________________
reshape (Reshape)            (None, 30, 1)             0         
=================================================================
Total params: 42,501
Trainable params: 42,501
Non-trainable params: 0
```

Also applying `tf.keras.utils.plot_model()` confirms that my input/output shapes are exactly the same. However when I try to do a mock test using: `np.random.randn(28, 30, 5)` I get an error saying that it fails to reshape the output of dense, it expects 840 values, but only saw 28. 

Is there a way to print out the actual batch shapes as it moves through the model in keras?

Thank you",4,4,False,self,,,,,
77,tensorflow,t5_3alkk,2019-9-27,2019,9,27,2,d9mytj,self.tensorflow,How to perform im2col in tensorflow2?,https://www.reddit.com/r/tensorflow/comments/d9mytj/how_to_perform_im2col_in_tensorflow2/,ashish421,1569519378,I want to implement convolution as a matrix multiplication separately. Is there any way to perform im2col in tensorflow 2?,1,0,False,self,,,,,
78,tensorflow,t5_3alkk,2019-9-27,2019,9,27,21,d9zlsa,self.tensorflow,Issue with training multilabel image classifier,https://www.reddit.com/r/tensorflow/comments/d9zlsa/issue_with_training_multilabel_image_classifier/,ski233,1569586847,"I followed this tutorial: [https://medium.com/@vijayabhaskar96/multi-label-image-classification-tutorial-with-keras-imagedatagenerator-cd541f8eaf24](https://medium.com/@vijayabhaskar96/multi-label-image-classification-tutorial-with-keras-imagedatagenerator-cd541f8eaf24)

and wrote some of my code for multilabel classification. I had it working with one-hot encoding on a small scale but I had to move to option 2 mentioned in the article because I have 6000 classes and therefore one hot was not viable. I managed to train the network and it said 99% accuracy and 83% f1 score. However, when I'm trying to test the network, for every image it's outputting some combination of only 3 labels when there are 6000 possible labels. I wondered if maybe the code to test the model was incorrect. I tried using the code mentioned in the post and it doesn't work:

test\_generator.reset()

pred = model.predict\_generator(test\_generator, steps=STEP\_SIZE\_TEST, verbose=1);

pred\_bool = (pred &gt; 0.5)

&amp;#x200B;

 Regardless of this code, I have some code that is getting the output, but it's still the same issue with only outputting a couple labels. Does anyone have an idea as to why this might be happening and how to fix it.",10,12,False,self,,,,,
79,tensorflow,t5_3alkk,2019-9-28,2019,9,28,1,da2xt0,self.tensorflow,How do I add additional x variables to a windowed tensorflow.data.dataset without windowing these additional x variables?,https://www.reddit.com/r/tensorflow/comments/da2xt0/how_do_i_add_additional_x_variables_to_a_windowed/,slingshoota,1569602135,"I'm currently working with time series data using tensorflow.data.dataset.

After I use the window function on the dataset, I would like to add additional data points beyond the window size.

This is because if I have data with a frequency of one minute (for example), and the window size is a few hundred minutes (a few hours), I would still like to consider data from a week, a few weeks, a few months and perhaps even years ago. Obviously increasing the window size to span a few years is out of the question when dealing with minute frequency data.

Currently, I have the lagged data (from a few weeks and months beyond the window) included in each row of the data frame before turning it into a tensorflow dataset, so it is already being considered. The issue is that if I have windowed data with 100 minutes of data per window, I also have 100 data points from (for example) two weeks ago per sample, even though I only want one. This is redundant data and computationally expensive.

I start with a dataframe and turn this into a tensorflow dataset. Of course the y variables in the dataframe are not windowed, and I would like to set it up so that a few of the x variables of my choice are not windowed either, but taken as x variables along with the windowed data.

I hope this conveys what I'm trying to do and that some of you tensorflow ninjas out there can help me out. I'm more than happy to clarify anything from my side. Thanks for your attention either way!

  
`variables = (tf.constant(dataframe[dataframe.columns.values[:-p['LabelCount']]].values), tf.constant(dataframe[dataframe.columns.values[-p['LabelCount']:]].values))`  
`tensor = tf.data.Dataset.from_tensor_slices(variables)`  
`tensor = tensor.window(p['hindsight'],1,1,True)`  
`tensor = tensor.flat_map(lambda x,y: tf.data.Dataset.zip((x.batch(p['hindsight']), y)))`",0,1,False,self,,,,,
80,tensorflow,t5_3alkk,2019-9-28,2019,9,28,3,da4p23,self.tensorflow,TensorBoard 1.14.0 not updating Scalars after launching,https://www.reddit.com/r/tensorflow/comments/da4p23/tensorboard_1140_not_updating_scalars_after/,times_of_change,1569609962,I'm doing hyperparameter tuning with TensorFlow keras on Windows (no GPU) and my TensorBoard refreshes but doesn't update the graph with new values as they come in once I launch the TensorBoard session. Anyone knows what is happening and what I need to do?,3,3,False,self,,,,,
81,tensorflow,t5_3alkk,2019-9-28,2019,9,28,9,da90og,self.tensorflow,Interfacing with the model creates an error.,https://www.reddit.com/r/tensorflow/comments/da90og/interfacing_with_the_model_creates_an_error/,Stanley_C,1569630715,"Hi,

When I run my code I get this error:  nvalidArgumentError (see above for traceback): Input to reshape is a tensor with 11 values, but the requested shape has 121  
    \[\[node dnn/input\_from\_feature\_columns/input\_layer/X/Reshape (defined at regressor\_full.py:177) \]\]  


During handling of the above exception, another exception occurred:  


Traceback (most recent call last):  
 File ""regressor\_full.py"", line 206, in &lt;module&gt;  
  a = np.array(0,0,0,0,0,0,0,0,0,0,0)  
ValueError: only 2 non-keyword arguments accepted.

I'm trying to interface with the model, however, I get that the request shape is even though the model with trained with 11 input and 11 output neurons. 

My repo:  [https://github.com/itisyeetimetoday/reggression](https://github.com/itisyeetimetoday/reggression)",0,1,False,self,,,,,
82,tensorflow,t5_3alkk,2019-9-29,2019,9,29,0,dahdth,self.tensorflow,How can I trust you?,https://www.reddit.com/r/tensorflow/comments/dahdth/how_can_i_trust_you/,afagarap,1569684283,"Hello, everyone! I have just published a new article focusing on an intuitive (hopefully) explanation of trust score for model predictions.

&amp;#x200B;

Here is a friendly link to the article. Happy reading!

[https://towardsdatascience.com/how-can-i-trust-you-fb433a06256c?source=friends\_link&amp;sk=0af208dc53be2a326d2407577184686b](https://towardsdatascience.com/how-can-i-trust-you-fb433a06256c?source=friends_link&amp;sk=0af208dc53be2a326d2407577184686b)",2,12,False,self,,,,,
83,tensorflow,t5_3alkk,2019-9-29,2019,9,29,5,dallh2,self.tensorflow,Tensorflow lite on android newbie questions,https://www.reddit.com/r/tensorflow/comments/dallh2/tensorflow_lite_on_android_newbie_questions/,Abdalnassir,1569703425,"I am new to tensorflow and I have some questions that I could not find an answer for using google so I am hoping the good people here can answer them for me (All regarding tensorflow lite):

1. For image labeling, how many label can tensorflow lite handle on android device?
2. What is the preferred or optimal tflite model size?
3. How many images to use per label for training the model?
4. What course (preferably on udemy) do you suggest to learn more about using tflite for image labeling?",0,1,False,self,,,,,
84,tensorflow,t5_3alkk,2019-9-29,2019,9,29,13,daqjs4,self.tensorflow,Question regarding training model using Jupyter/Google Colab,https://www.reddit.com/r/tensorflow/comments/daqjs4/question_regarding_training_model_using/,MrMegaGamerz,1569730899,"I'm actually using Google Colab (which I read is the same as Jupyter), because of the built-in Tensorflow/Keras. 

[I'm trying to recreate this GitHub project](https://github.com/gentaiscool/lstm-attention) and I have a few questions. I've never used Colab or Juypter and I'm wondering:

1) How to deal with multiple files. I need to run the main file, but what do I do with the other .py files? Do I need to have it open in the notepad or can I simply have then uploaded in the same folder? 

2) I'm getting an error when I run the main file which says: 

    ipykernel_launcher.py: error: no such option: -f
    An exception has occurred, use %tb to see the full traceback.

    SystemExit: 2

Does anyone know what that is/how to fix it? 


I'm new to AI training and Google Colab in general so any help is appreciated.",2,1,False,self,,,,,
85,tensorflow,t5_3alkk,2019-9-29,2019,9,29,13,daqs3a,self.tensorflow,Creating a hybrid tensor?,https://www.reddit.com/r/tensorflow/comments/daqs3a/creating_a_hybrid_tensor/,[deleted],1569732449,[deleted],0,1,False,default,,,,,
86,tensorflow,t5_3alkk,2019-9-29,2019,9,29,13,daqvc1,self.tensorflow,Creating hybrid sparse tensors,https://www.reddit.com/r/tensorflow/comments/daqvc1/creating_hybrid_sparse_tensors/,EthanPhan,1569733079,"I'm porting a model from pytorch to tensorflow. Pytorch has type of tensor called hybrid sparse which mean only the first few dimensions are sparse, the last dimensions can be dense. Is there any thing like that in tensorflow? I've checked tf.sparse.SparseTensor api and it doesn't support hybrid tensor. How can i get around this?",0,1,False,self,,,,,
87,tensorflow,t5_3alkk,2019-9-29,2019,9,29,17,dasjas,self.tensorflow,"Teaching ML, should I upgrade from TF 1.13 to TF 2.0?",https://www.reddit.com/r/tensorflow/comments/dasjas/teaching_ml_should_i_upgrade_from_tf_113_to_tf_20/,bwllc,1569745649,"Over the summer I taught a Deep Learning course using TensorFlow 1.13.  I had the students using mostly the Keras API.  There was no official textbook for the course.  However, I referred the students to [Hands-On Machine Learning with Scikit-Learn and TensorFlow](http://shop.oreilly.com/product/0636920052289.do), and I was confident that what they might read there would allow them to produce code that worked with the software stack that I had them install.

I am scheduled to teach the course again next spring.  I am debating whether to switch over to the TF 2.x branch and I would like to solicit the opinions of people here.  My thoughts are as follows so far.

Pro: students will learn the latest API.

Con: I don't know the latest API yet myself, or how much has changed.  Finding working example code could be harder because TF 2.0 is new.

Ambivalent: I've read that in TF 2.0, eager execution is the default.  I know that some student of mine will press Enter, start evaluating a large data set, and perhaps (if there is no terminal feedback) think that the system has hanged.  I might even do that myself.

 Please feel free to influence my thoughts on any of this.  Thanks!",10,8,False,self,,,,,
88,tensorflow,t5_3alkk,2019-9-30,2019,9,30,7,db1zfj,self.tensorflow,Issue with multilabel image classification when using specific dataset,https://www.reddit.com/r/tensorflow/comments/db1zfj/issue_with_multilabel_image_classification_when/,ski233,1569794572,"I'm having an issue where with one specific dataset, my training for multilabel image classification is returning \[class1 and or class2 and or class 3\] (only 3 classes for every image) when there are 13 possible classes. I originally had 6000 classes and lowered the number of classes to see if that was the issue and apparently it was not. Also, I know it is not an issue with the model because I used the exact same code to train a model with a different dataset in the exact same form in the csv file and it worked with 20 classes. My only clue to the difference between the 2 datasets is that in the one where it fails, it gets this warning message: ""Palette images with Transparency expressed in bytes should be converted to RGBA images"". So I started wondering if this is the issue and went into the dataset that works and all the images were pngs and i had scaled them down to 300x300 using PIL so in the dataset that doesnt work I did both of these things and I'm still getting this warning message and its not working. I couldn't find much about this warning message online in the context of keras. The warning occurs inside of the fit\_generator function so it's not in my code. I'm not entirely sure this warning is whats causing my bad output but I suspect it might be so if anybody knows how to fix this, please let me know",6,1,False,self,,,,,
89,tensorflow,t5_3alkk,2019-9-30,2019,9,30,13,db699s,self.tensorflow,"Text extraction, use image or text for training",https://www.reddit.com/r/tensorflow/comments/db699s/text_extraction_use_image_or_text_for_training/,burton6666,1569816781,I want to try to extract text from scanned images of invoices. I was thinking that I would first use tesseract or similar software to extract the text and then use the text-files to train a model using tensorflow. But I started thinking about if it is possible to do all steps directly in tensorflow?,3,3,False,self,,,,,
90,tensorflow,t5_3alkk,2019-9-30,2019,9,30,21,dbashp,facebook.com,TensorFlow for Deep Learning: From Linear Regression to Reinforcement Learning is 31% off,https://www.reddit.com/r/tensorflow/comments/dbashp/tensorflow_for_deep_learning_from_linear/,Krourstage,1569846389,,2,9,False,https://b.thumbs.redditmedia.com/BZutjB5GqsXnaDehfFVwnj_e3JNk9iaXvdaH6Ckr0yI.jpg,,,,,
91,tensorflow,t5_3alkk,2019-9-30,2019,9,30,23,dbc30i,medium.com,5 Important Changes Coming with TensorFlow 2.0,https://www.reddit.com/r/tensorflow/comments/dbc30i/5_important_changes_coming_with_tensorflow_20/,CodeTutorials,1569852519,,0,5,False,https://b.thumbs.redditmedia.com/qK6SHSKIo6TmqKnhmCAQbdV-eYq_r_pMpQfaSJj6ukw.jpg,,,,,
