,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2018-4-1,2018,4,1,10,88ngpl,Distributed Tensorflow without sharing weights,https://www.reddit.com/r/tensorflow/comments/88ngpl/distributed_tensorflow_without_sharing_weights/,manganime1,1522547435,"Hello,

I'm working on an application where I want to run an algorithm in parallel, but I don't want to share the weights; is that possible?

I'm using 'train.replica_device_setter' currently, which is automatically placing my weights on the parameter server. Is there a way to tell it not to do that? Or will I have to stop using 'train.replica_device_setter' entirely, and define the device-ops connections myself?",3,3
1,2018-4-1,2018,4,1,11,88ntfs,[HELP] Getting Placeholder Values into python objects.,https://www.reddit.com/r/tensorflow/comments/88ntfs/help_getting_placeholder_values_into_python/,[deleted],1522551231,[deleted],0,1
2,2018-4-2,2018,4,2,0,88rhn3,tf.data: Easy-to-use input pipelines for TensorFlow - YouTube,https://www.reddit.com/r/tensorflow/comments/88rhn3/tfdata_easytouse_input_pipelines_for_tensorflow/,Olao99,1522595936,,0,16
3,2018-4-2,2018,4,2,1,88rynm,Training Performance: A users guide to converge faster (TensorFlow Dev Summit 2018) - YouTube,https://www.reddit.com/r/tensorflow/comments/88rynm/training_performance_a_users_guide_to_converge/,Olao99,1522599825,,0,6
4,2018-4-2,2018,4,2,2,88sizb,Typical tensorflow project directory structure,https://www.reddit.com/r/tensorflow/comments/88sizb/typical_tensorflow_project_directory_structure/,r0vsdal,1522604348,"I'm pretty new to Tensorflow and machine learning. Reading through tutorials I never seem to get how to structure a mid-sized project(image recognizition using CNN, training from my own set of images). Is there a standard way to do this? Any good literature covering this subject?",2,1
5,2018-4-2,2018,4,2,11,88w4ck,tensorboard bug?,https://www.reddit.com/r/tensorflow/comments/88w4ck/tensorboard_bug/,manganime1,1522636137,"https://imgur.com/a/HX3mt

Maybe I'm misinterpreting tensorboard, but for devices, the color-scheme in the legend (left of the pic) doesn't match with the color under ""Attributes"" when you press on the node.

For example, in the pic, I highlighted node ""a_2"" where under Attributes it's assigned to device ""/job:ps/task:0"" and is blue, but according to the color-scheme in the far left it's supposed to be a peachy color...",0,1
6,2018-4-3,2018,4,3,4,894de1,Feed-forward Network Giving a Max Output,https://www.reddit.com/r/tensorflow/comments/894de1/feedforward_network_giving_a_max_output/,ThexLizardxKing,1522699047,"Hey guys, 

I have a network that is predicting some time data.  The inputs are time and a constant, C, and the output is the y-value at the given time. The idea is that I train it on multiple different C values, and then predict using a new C value. For most of my data, this works with no issue. However, I have one set of data that, once trained, any C value I input above the highest trained C value gives me a constant output.

For example, I decided to train it on a single time point to try to figure out the issue. At t=45, I trained it on C = [2.0, 3.5, 5.0], which should give an output of [4.47, 8.46, 21.1]. After training, I tested on C = 6, which should output 65.3. However, I still just get a value around 21.

I've tried many different numbers of hidden layers, nodes per layer, and different activation functions, but always get the same result. Anyone have any idea on why this is happening?",0,1
7,2018-4-3,2018,4,3,11,897npj,Is there any reason to remake scikit models in tensorflow? [Beginner],https://www.reddit.com/r/tensorflow/comments/897npj/is_there_any_reason_to_remake_scikit_models_in/,Akumasade,1522721178,"I'm really new to using tensorflow, but I've done some basic machine learning using scikit-learn.  I was wondering if there were any advantages to using the tensorflow version of the models in scikit-learn(e.g. K-nearest neighbors, decision trees, logistic regression)?

Could I expect better efficiency using tensorflow?",5,2
8,2018-4-3,2018,4,3,16,89ayr3,[Help] Trying to implement an idea for GANs from a talk,https://www.reddit.com/r/tensorflow/comments/89ayr3/help_trying_to_implement_an_idea_for_gans_from_a/,Mikkelisk,1522739074,"Hey, I'm trying to learn tensorflow by implementing an idea from a talk I saw. I posted the question on (stackoverflow)[https://stackoverflow.com/questions/49600903/implementing-a-gan-with-lookahead-in-the-generator-in-tensorflow], but I got downvoted with no comments as to why.

I would appreciate it if anyone here could help me with the question as posed OR help me understand why the question is bad/unanswerable as it stands so that I can improve it.

Any help is greatly appreciated:)",4,1
9,2018-4-4,2018,4,4,7,89j8m2,Introducing TensorFlow.js: Machine Learning in Javascript,https://www.reddit.com/r/tensorflow/comments/89j8m2/introducing_tensorflowjs_machine_learning_in/,fhoffa,1522793243,,0,24
10,2018-4-4,2018,4,4,12,89lvxw,Tensorflow reshape in matrix multiply,https://www.reddit.com/r/tensorflow/comments/89lvxw/tensorflow_reshape_in_matrix_multiply/,staydreamy,1522812248,"I want to use tf.matmul(A, B) with two tensors one (A) of rank 3 with dimensions [10000, 48, 50] and the other (B) of rank 2 with dimensions [200, 2400]. I was told that I would be able to use tf.matmul if I reshape B and change the order the multiplication. I tried reshaping B to [48, 10000] but this did not work. Is there any way to do this?

edit: tensors not matrices",24,3
11,2018-4-4,2018,4,4,22,89pe7t,Style transfer using inception v1,https://www.reddit.com/r/tensorflow/comments/89pe7t/style_transfer_using_inception_v1/,nile6499,1522848143,"Hi, has anyone tried inception model for style transfer, and with Adam optimizer. I really need help, since I have 4 days left.

Thanks",2,1
12,2018-4-5,2018,4,5,2,89rrop,Is there a way to access weights and biases in tfjs layers api?,https://www.reddit.com/r/tensorflow/comments/89rrop/is_there_a_way_to_access_weights_and_biases_in/,[deleted],1522864205,[deleted],0,1
13,2018-4-6,2018,4,6,3,8a2bun,[Q] Can someone please help me with this issue. TF is telling me a variable already exists when I try to write a basic GAN.,https://www.reddit.com/r/tensorflow/comments/8a2bun/q_can_someone_please_help_me_with_this_issue_tf/,Xyoloswag420blazeitX,1522953754,,1,1
14,2018-4-6,2018,4,6,12,8a6ha2,Negative cross entropy loss then error,https://www.reddit.com/r/tensorflow/comments/8a6ha2/negative_cross_entropy_loss_then_error/,staydreamy,1522986845,"I am trying to calculate the loss using cross entropy with L2 regularization as in [A Fast and Accurate Dependency Parser using Neural Networks](http://www.aclweb.org/anthology/D14-1082). This is my code so far:

    self.loss = tf.reduce_mean(
                     tf.nn.softmax_cross_entropy_with_logits(logits=self.prediction, labels=self.train_labels)
                    )
    regularizer = tf.nn.l2_loss(weights_input)
    self.loss = tf.reduce_mean(self.loss + 1e-8 * regularizer)

However I get a negative loss at step 0 and an error at step 200:
    ValueError: Cannot feed value of shape (48,) for Tensor u'Placeholder_2:0', which has shape '(1, 48)'

Any suggestions or ideas as to what I'm doing wrong here?",8,1
15,2018-4-6,2018,4,6,13,8a6tig,Google has started a new TensorFlow YouTube channel,https://www.reddit.com/r/tensorflow/comments/8a6tig/google_has_started_a_new_tensorflow_youtube/,khashei,1522990320,,4,37
16,2018-4-7,2018,4,7,0,8aak8c,Ignore labels with -1 in softmax,https://www.reddit.com/r/tensorflow/comments/8aak8c/ignore_labels_with_1_in_softmax/,staydreamy,1523029502,"When cross entropy calculating loss, how do I ignore values of -1 in the label tensor that is passed to softmax?",3,1
17,2018-4-8,2018,4,8,11,8an42s,Ide for Tensorflow?,https://www.reddit.com/r/tensorflow/comments/8an42s/ide_for_tensorflow/,thefernandito,1523154559,"Hello friends, I'm about to start with Tensorflow (I have knowledge of Python). I would like to know if there is any Ide to work with Tensorflow and Python. Thank you.",5,2
18,2018-4-8,2018,4,8,16,8aoigh,"free AI annotation tools for images,videos and texts.",https://www.reddit.com/r/tensorflow/comments/8aoigh/free_ai_annotation_tools_for_imagesvideos_and/,Colabeler,1523172331,,0,7
19,2018-4-9,2018,4,9,4,8asg1n,Customize a CNN?,https://www.reddit.com/r/tensorflow/comments/8asg1n/customize_a_cnn/,faria324,1523216704,"1) How can I build a basic CNN with tensorflow? (This I could probably google, but the other 2 questions probably not...)

2) How can I customize it by adding a few extra features onto the end of the input vector that aren't attached to any hidden nodes, but instead are connected directly to the output node?

3) How can I build a 2nd custom CNN with 6 output nodes instead of just 1?",1,1
20,2018-4-9,2018,4,9,8,8atugy,Remove gradient clipping for observation purposes,https://www.reddit.com/r/tensorflow/comments/8atugy/remove_gradient_clipping_for_observation_purposes/,staydreamy,1523228553,"I would like to observe the effect of removing gradient clipping. I have 

    loss_val, _ = session.run([loss, optimizer], feed_dict)
    avg_loss += loss_val

However when I do 

    loss_val = session.run([loss], feed_dict)` I get the following error 
    TypeError: unsupported operand type(s) for +=: 'int' and 'list'

and when I try: loss_val = session.run(loss, feed_dict), i get the error:

    TypeError: 'numpy.float64' object is not iterable

How do I go about removing gradient clipping?",7,1
21,2018-4-9,2018,4,9,8,8au5kj,[Q] need help installing tensorflow ubuntu 17.10,https://www.reddit.com/r/tensorflow/comments/8au5kj/q_need_help_installing_tensorflow_ubuntu_1710/,leetfire666,1523231437,"Hello,

I'm trying to install tensorflow on Ubuntu 17.10 and I'm going through a combination of this guide: https://medium.com/@adakaminkure/if-youre-trying-to-install-tensorflow-on-ubuntu-17-10-703b971d98d

and https://www.tensorflow.org/install/install_linux

I'm bumping into a few issues.

1. I'm stuck at the mnist compilation step:

    $ cp -r /usr/src/cudnn_samples_v7/ $HOME

    $ cd $HOME/cudnn_samples_v7/mnistCUDNN

    $ make

    $ ./mnistCUDNN

I get the following error:

    cudnnGetVersion() : 7102 , CUDNN_VERSION from cudnn.h : 7102 (7.1.2)
    Cuda failurer version : GCC 6.4.0
    Error: unknown error
    error_util.h:93
    Aborting...

2. If I move past that and try to install tensorflow on a virtualenv:

    $ sudo apt-get install python3-pip python3-dev python-virtualenv 

    $ virtualenv --system-site-packages -p python3 ~/tensorflow

    $ source ~/tensorflow/bin/activate

    $ easy_install -U pip

    $ pip3 install --upgrade tensorflow-gpu

I notice the following in the last commands output:

    protobuf 3.5.2.post1 requires six&gt;=1.9, which is not installed.
    grpcio 1.10.1 requires six&gt;=1.5.2, which is not installed.
    absl-py 0.1.13 requires six, which is not installed.
    html5lib 0.9999999 requires six, which is not installed.
    bleach 1.5.0 requires six, which is not installed.
    tensorboard 1.7.0 requires six&gt;=1.10.0, which is not installed.
    tensorflow-gpu 1.7.0 requires six&gt;=1.10.0, which is not installed.

3. I then tried running:

    $ import tensorflow as tf

    $ hello = tf.constant(""Hello, Ada from Tensorflow"")

    $ session = tf.Session()

I get the following error:

    2018-04-08 16:33:31.297906: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
    2018-04-08 16:33:31.346416: E tensorflow/stream_executor/cuda/cuda_driver.cc:406] failed call to cuInit: CUDA_ERROR_UNKNOWN
    2018-04-08 16:33:31.346468: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:145] kernel driver does not appear to be running on this host (spacecowboy): /proc/driver/nvidia/version does not exist

----

Any idea what's going on?",5,1
22,2018-4-9,2018,4,9,11,8av1lu,Beginner question,https://www.reddit.com/r/tensorflow/comments/8av1lu/beginner_question/,thefernandito,1523239996,"To create a complex system is it possible to do it only with python and Tensorflow, or is it necessary to know other things?
Thank you very much. I'm just starting.",4,2
23,2018-4-9,2018,4,9,21,8axvm0,Problem calculating Exponential cost in tensorflow,https://www.reddit.com/r/tensorflow/comments/8axvm0/problem_calculating_exponential_cost_in_tensorflow/,ShibeForceOne,1523275345,"I'm working on a Deep Learning project and I wanted to try out the 'Exponential Cost' as described here: https://stats.stackexchange.com/a/154880.

When I tried to calculate the cost, I got a bunch of NaN's, so I decided I'd break down the calculation, when I do this:

    ee = tf.divide(tf.reduce_sum(tf.square(tf_labels - l3_act)), TAU)               # Exponential Error

    error = tf.Print(ee, [ee], 'Exponential Error 1: ')
    error = tf.exp(error)
    error = tf.Print(error, [error], 'Exponential Error 2: ')

I get a bunch of NaN's for both Exponential Error 1 and 2, also Error 2 seems to only print every 50 or so iterations...

    Exponential Error 1: [242.370331]
    Exponential Error 1: [-nan]
    Exponential Error 1: [-nan]
    Exponential Error 1: [-nan]
    Exponential Error 1: [-nan]
    ...
    Exponential Error 2: [-nan]

When I do this:

    ee = tf.divide(tf.reduce_sum(tf.square(tf_labels - l3_act)), TAU)               # Exponential Error

    error = tf.Print(ee, [ee], 'Exponential Error 1: ')
    #error = tf.exp(error)
    error = tf.Print(error, [error], 'Exponential Error 2: ')

I get a bunch of values that seem like valid numbers to feed to an exponential function.
(Example output with valid numbers)

    Exponential Error 1: [1034.56555]
    Exponential Error 2: [1034.56555]
    Exponential Error 1: [4132.28076]
    Exponential Error 2: [4132.28076]
    Exponential Error 1: [435.344666]
    Exponential Error 2: [435.344666]
    ...

TAU is defined as follows:

    TAU = tf.constant(0.1, dtype=tf.float32)

Does anyone have any idea of what's going on with my model?",3,1
24,2018-4-10,2018,4,10,1,8azs3y,convnet2d - what if 'channels in' mismatch the input data?,https://www.reddit.com/r/tensorflow/comments/8azs3y/convnet2d_what_if_channels_in_mismatch_the_input/,ME_PhD,1523291431,"The conv2d function takes in data (call it 'X') and the kernel shape (call it 'K').

X is of shape [batch_size, image_height, image_width, image_channels]

K is of shape [filter_height, filter_width, channels_in, channels_out]

Question: What happens if image_channels doesn't match with channels_in? Will it create a bug or does tensorflow deal with it somehow, and is there a time where you want them different?

If it deals with it, what happens if channels_in is not divisible by image_channels? I'm trying to understand exactly what happens in the back end.",10,1
25,2018-4-10,2018,4,10,4,8b1ea1,Tensorflow serving best practices?,https://www.reddit.com/r/tensorflow/comments/8b1ea1/tensorflow_serving_best_practices/,hijakk,1523303427,"Hello, I'm looking at deploying a bunch (100+) of relatively simple linear SVM models for doing binary text classification as a web service. They're currently in sklearn. I've been pointed towards Tensorflow serving as a potential host for this set of models, and wanted to figure out best practice for dealing with text content in TFS since all the tutorials I see are for image classification. 

Is this the right way to go about it? If I can dockerize, should I have a docker container per model? Or can I reasonably serve many/all models from a single container?",5,3
26,2018-4-10,2018,4,10,15,8b5lmz,I am getting this error while training my own dataset using the object detection API. I am getting no response on github. Thought someone here might help. More details in the link. I am trying to finish my project. Any help would be appreciated.,https://www.reddit.com/r/tensorflow/comments/8b5lmz/i_am_getting_this_error_while_training_my_own/,ZER-0-NE,1523342204,,3,2
27,2018-4-10,2018,4,10,16,8b5xvv,"In an RNN model, is batch_size of the input stands for the time scan of an unfolded RNN?",https://www.reddit.com/r/tensorflow/comments/8b5xvv/in_an_rnn_model_is_batch_size_of_the_input_stands/,Laurence-Lin,1523346851,"If I have input matrix X with shape [N, M], which means I have N input sample(these N sequences are consecutive time series data), each have M dimension. I have only one batch, batch size = N,  then while input to an RNN model, I thought the unfold RNN have time scan from t = 1 to N. Is that correct?",4,0
28,2018-4-10,2018,4,10,18,8b6b3c,Tensorflow suddenly allocating way too much GPU memory,https://www.reddit.com/r/tensorflow/comments/8b6b3c/tensorflow_suddenly_allocating_way_too_much_gpu/,nst_1234,1523352152,"Ever since yesterday all my tensorflow or keras scripts give me an error that I ran out of GPU memory. Even when I run the ""label_image.py"" [example from Tensorflow](https://www.tensorflow.org/tutorials/image_recognition) I get that error, even though that script used to work without any problems.


Here's the error I get when running ""label_image.py""

&gt;PS C:\Users\NSA&gt; cd 'c:\Users\NSA\tensorflow\tensorflow\examples\label_image'; ${env:PYTHONIOENCODING}='UTF-8'; ${env:PYTHONUNBUFFERED}='1'; &amp; 'C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\python.exe' 'C:\Users\NSA\.vscode\extensions\ms-python.python-2018.3.1\pythonFiles\PythonTools\visualstudio_py_launcher.py' 'c:\Users\NSA\tensorflow\tensorflow\examples\label_image' '50745' '34806ad9-833a-4524-8cd6-18ca4aa74f14' 'RedirectOutput,RedirectOutput' 'c:\Users\NSA\tensorflow\tensorflow\examples\label_image\label_image.py'

&gt;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python36_64\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will
be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters

&gt;2018-04-10 11:18:45.499948: I T:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2

&gt;2018-04-10 11:18:46.090974: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1344] Found device 0 with properties:
name: GeForce 940MX major: 5 minor: 0 memoryClockRate(GHz): 1.189
pciBusID: 0000:02:00.0
totalMemory: 2.00GiB freeMemory: 1.66GiB

&gt;2018-04-10 11:18:46.096515: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1423] Adding visible gpu devices: 0

&gt;2018-04-10 11:18:46.849567: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:

&gt;2018-04-10 11:18:46.853286: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:917]      0

&gt;2018-04-10 11:18:46.855627: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:930] 0:   N

&gt;2018-04-10 11:18:46.858081: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replic2018-04-10 11:18:51.611905: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1423] Adding visible gpu devices: 0

&gt;2018-04-10 11:18:51.616535: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:

&gt;2018-04-10 11:18:51.620123: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:917]      0

&gt;2018-04-10 11:18:51.625542: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:930] 0:   N

&gt;2018-04-10 11:18:51.628802: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1429 MB memory) -&gt; physical GPU (device: 0, name: GeForce 940MX, pci bus id: 0000:02:00.0, compute capability: 5.0)

&gt;2018-04-10 11:18:56.348615: W T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.91GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.

&gt;2018-04-10 11:18:57.480611: W T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.41GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.

&gt;2018-04-10 11:18:57.489497: W T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.69GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.

&gt;2018-04-10 11:18:57.498368: W T:\src\military uniform 0.8330358
mortarboard 0.020486064
academic gown 0.009828327
pickelhaube 0.007285705
bulletproof vest 0.00522343


I have already updated my NVIDIA drivers and reinstalled Keras, Tensorflow, cuDNN as well as CUDA. I am using Tensorflow 1.6, cuDNN 7.0.5 and CUDA 9.0 on an NVIDIA GeForce 940MX.

The out of memory occurs when executing 

    results = sess.run(output_operation.outputs[0], {
        input_operation.outputs[0]: t
    })",12,1
29,2018-4-11,2018,4,11,4,8balo6,NN with tensorflow,https://www.reddit.com/r/tensorflow/comments/8balo6/nn_with_tensorflow/,joey_php,1523388823,,3,0
30,2018-4-11,2018,4,11,7,8bc5do,Style Transfer with lbfgs.,https://www.reddit.com/r/tensorflow/comments/8bc5do/style_transfer_with_lbfgs/,nile6499,1523400101,"Style Transfer with lbfgs.
I have written a code which works with scipy.optimize.minimize()

but it doesn't seems to be working with tf.contrib.scipy.optimize()
and also it is not working with any other tf.train.optimizer.

If anyone interest below is the code.


####################################################################################
##############  USING SCIPY OPTIMIZER  ############################

####################################################################################

art_image = photo
#art_image = np.random.uniform(-1.0, +1.0, (image_size, image_size, 3))

x0 = art_image.flatten().astype('float64')
iteration=0

t0 = time.time()

with tf.Session() as sess:
    init_fn(sess)

    def eval_loss_and_grad(x):  # x0 is a 3*image_size*image_size float64 vector
        x_image = x.reshape(1,224,224,3).astype('float32')

        sess.run(input_image_float.assign(x_image))
        x_loss, x_grad = sess.run( [total_loss, total_grad])
        print(""\nEval Loss @ "", [ ""%.6f"" % l for l in x[100:106]], "" = "", x_loss)
            #print(""Eval Grad = "", [ ""%.6f"" % l for l in x_grad.flatten()[100:106]] )


        return x_loss.astype('float64'), x_grad.flatten().astype('float64')

    x0, x0_loss, state = scipy.optimize.fmin_l_bfgs_b( eval_loss_and_grad,x0, maxfun=500,maxiter=500) 

#################################################################################

############# TF.SCIPY.OPTIMIZER ##############################
#################################################################


with tf.Session() as sess:
            
            ###############################
            ## TO DO: 
            ## 1. initialize your variables
            ## 2. create writer to write your graph
    init_fn(sess)
    
    sess.run(tf.global_variables_initializer())
    sess.run(input_image_float.assign(j))

# For this kind of use case, the limited memory BFGS performs the best
    optimizer = tf.contrib.opt.ScipyOptimizerInterface(cl, method='L-BFGS-B',
                                                   options={'maxiter': 30})
#     x_loss, x_grad = sess.run( [total_loss, total_grad])
    global step
    step = 0

    def update(l):
        # Function to print loss
        global step
        if step % 10 == 0:
            print('Step {}; loss {}'.format(step, l))
        step += 1

    optimizer.minimize(sess, fetches=[cl], loss_callback=update)
    gen = sess.run(input_image_float)
#     o = sess.run(photo)


##############################################################

",1,1
31,2018-4-11,2018,4,11,8,8bcagt,GPU usage dramatically increases when I open Chrome while training... what?,https://www.reddit.com/r/tensorflow/comments/8bcagt/gpu_usage_dramatically_increases_when_i_open/,Iklowto,1523401279,"Hello everyone, 

I don't know what's happening here, but I'm definitely not upset about it. 

I am currently training an RNN and was a bit upset about my GPU usage, which was consistently between 5-15%. I tried increasing and decreasing the batch size in hopes of changing anything but to no avail. 

I finally decided on a batch size and decided to just let it do its thing while I watched some Netflix and went to bed. I drew up Tensorboard so I could peek at the progress from time to time, and when I opened the Chrome window, I could audibly hear my GPU speed up. Indeed, when I looked the task manager, the GPU usage was now consistently between 40-45%. I minimized the Chrome window, back to 5-15%. De-minimized the Chrome window, immediately back at 40-45%. What the fuck? This is great, albeit a little confusing. 

Does anyone know what is going on here? 

In case it helps: 

Batch-size: 128

Input sequence: 128 x 35 floating point values

GPU: Nvidia GTX 1060 Strix

OS: Windows 10

",9,3
32,2018-4-12,2018,4,12,17,8bon43,Tensorflow's tutorial is sucks,https://www.reddit.com/r/tensorflow/comments/8bon43/tensorflows_tutorial_is_sucks/,L_E_I,1523522006,"Have played with TensorFlow for a while by reading and revising other's code. Now I want to read tensorflows tutorial carefully and learn tensorflow comprehensively. Then I find the official tensorflow's tutorial is really sucks. For one thing, there are to many see other pages, I have to click many links in order to get understand about a code in tutorial. For other thing, tensorflow's APIs are not unified. In https://www.tensorflow.org/get_started/eager, it tells me to load CSV file by tf.data.TextLineDataset, but in other page (https://www.tensorflow.org/api_docs/python/tf/TextLineReader), it tells me to load CSV file by tf.TextLineReader. Can they unify the tutorial?",14,29
33,2018-4-13,2018,4,13,0,8br0d6,What happened to skflow and can I access it in tensorflow?,https://www.reddit.com/r/tensorflow/comments/8br0d6/what_happened_to_skflow_and_can_i_access_it_in/,Akumasade,1523546779,"I recently found out about it and wanted to use it, but the stuff in the github repo seems to have been moved to the tensorflow module. Is there a way to access it in the tensorflow python module?",1,3
34,2018-4-13,2018,4,13,1,8brlft,Tensorflow wrapping padding?,https://www.reddit.com/r/tensorflow/comments/8brlft/tensorflow_wrapping_padding/,mtutnid,1523551275,Like in numpy,1,1
35,2018-4-13,2018,4,13,4,8bsqze,Fit model to only 1 changed output,https://www.reddit.com/r/tensorflow/comments/8bsqze/fit_model_to_only_1_changed_output/,manicman1999,1523560047,"I'm trying to build a neural network to learn to play a game using Q Learning. For this, I only want to backpropogate on one output value, rather than all of them. What's the easiest way to do this?",0,2
36,2018-4-13,2018,4,13,5,8btcps,Cannot find output_graph.pb and output_labels.txt location,https://www.reddit.com/r/tensorflow/comments/8btcps/cannot_find_output_graphpb_and_output_labelstxt/,[deleted],1523564703,[deleted],0,1
37,2018-4-13,2018,4,13,18,8bxx2x,Beginner Question,https://www.reddit.com/r/tensorflow/comments/8bxx2x/beginner_question/,kujjwal002,1523612362,"Why do we need to initialize variables even though the variable has values

Like in this code


    import tensorflow as tf

    sess = tf.InteractiveSession()

    my_tensor = tf.random_uniform((4, 4), 0, 1)
    my_var = tf.Variable(initial_value=my_tensor)

    sess.run(my_var)


On execution throws an error

but if I initialize it with 

    init = tf.global_variables_initializer()
    sess.run(init)

everything works fine.

In a nutshell

What I want to ask is

What does `tf.global_variables_initializer()` do?

I previously thought that it initializes the variables that do not contain any value.

But now I am having doubts about that.

Please help with this
",0,1
38,2018-4-14,2018,4,14,4,8c1w6q,"I have written a GAN which I hoped would synthesize MRI data from a random noise vector, the generator isn't being updated. Can anyone help?",https://www.reddit.com/r/tensorflow/comments/8c1w6q/i_have_written_a_gan_which_i_hoped_would/,[deleted],1523647750,[deleted],0,1
39,2018-4-14,2018,4,14,15,8c5tst,How is dropout implemented?,https://www.reddit.com/r/tensorflow/comments/8c5tst/how_is_dropout_implemented/,ME_PhD,1523687077,"I want to know how some variables are temporarily ""disabled"". What does this mean mathematically? For example in a normal linear layer, I have a weight matrix W that maps input to output + bias vector. If I have dropout, what happens - does it make some of the elements of W and their gradients = 0 (constants of 0) for that iteration? ",7,2
40,2018-4-15,2018,4,15,2,8c8v76,Tensorflow inside for loop slow,https://www.reddit.com/r/tensorflow/comments/8c8v76/tensorflow_inside_for_loop_slow/,mtutnid,1523725616,"So i tried to follow the PDE tutorial in TF. And it seemed kindof slow so I setup a few tests. Both of these codes take more than 30 seconds on my machine. Any ideas? My solution was the last one, but there should be a better way no?

Example using  Variable as in PDE tutorial

    import tensorflow as tf
    import numpy as np
    import math

    N = 200
    u_init = np.zeros([1, N], dtype=np.float32)

    for l in range(N):
      u_init[0][l] = 1+math.sin(2 * math.pi * l / N) #1+np.random.normal(0, 0.1, N)

    sess = tf.Session()

    U = tf.Variable(u_init)
    U_ = U+1

    step = U.assign(U)
    tf.global_variables_initializer().run(session=sess)
    for i in range(100000):
      sess.run(step)

Tested code according to forum post still slow

    import tensorflow as tf
    import numpy as np
    import math

    N = 200
    u_init = np.zeros([1, N], dtype=np.float32)

    for l in range(N):
      u_init[0][l] = 1+math.sin(2 * math.pi * l / N) #1+np.random.normal(0, 0.1, N)

    sess = tf.Session()

    U = tf.placeholder(tf.float32, shape=[1, N])

    U_ = U+1

    a = sess.run(U_,feed_dict={U: u_init})

    for i in range(100000):
      a = sess.run(U_,feed_dict={U: a})



My fix works fast, but doesn't seem like a proper way to do it

    import tensorflow as tf
    import numpy as np
    import math


    N = 200
    u_init = np.zeros([1, N], dtype=np.float32)

    for l in range(N):
      u_init[0][l] = 1+math.sin(2 * math.pi * l / N) #1+np.random.normal(0, 0.1, N)

    sess = tf.Session()

    U = tf.placeholder(tf.float32, shape=[1, N])
    U_ = U+1
    for i in range(1000):
      U_ = U_+1

    a = sess.run(U_,feed_dict={U: u_init})

    for i in range(1000):
      a = sess.run(U_,feed_dict={U: a})

    print(a)



",4,2
41,2018-4-17,2018,4,17,18,8cvcac,Gan example,https://www.reddit.com/r/tensorflow/comments/8cvcac/gan_example/,mohanradhakrishnan,1523958585,"This is my first TF Gan based on other examples. I have images that I want the GAN to train on. It should generate more such images.

Does this TF code seem to be right ? It executes but does not finish. How long should it take ?
I am showing only this method because I have this doubt.

     def train():
         filenames = tf.train.string_input_producer(
             tf.train.match_filenames_once(""D:/*.png""))
         reader = tf.WholeFileReader()
         key, value = reader.read(filenames)
         batch = tf.train.batch([value], batch_size=5)
         init = (tf.global_variables_initializer(), tf.local_variables_initializer())

        with tf.Session() as sess:
            sess.run(init)
            coord = tf.train.Coordinator()
            threads = tf.train.start_queue_runners(coord=coord)

        for it in range(1): #Range is 1 for testing.
            X_batch, _ =     batch = sess.run([value])
            _, DiscriminatorLoss = sess.run([D_optimizer, Disc_loss], feed_dict={X: X_batch, Z: samplefromuniformdistribution(5, [None, 100])})
            _, GeneratorLoss = sess.run([G_optimizer, Generate_loss], feed_dict={Z: samplefromuniformdistribution(5, [None, 100])})
",1,0
42,2018-4-17,2018,4,17,21,8cw7jm,"Tensorflow-gpu takes long time before starting to compute [Windows10x64, GTX 1080]",https://www.reddit.com/r/tensorflow/comments/8cw7jm/tensorflowgpu_takes_long_time_before_starting_to/,kettenfett,1523968877,"When I run tensorflow, I get this after a *tf.Session()*:

    Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)] on win32
    Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
    &gt;&gt;&gt; import tensorflow as tf
    &gt;&gt;&gt; hello = tf.constant('Hello, TensorFlow!')
    &gt;&gt;&gt; sess = tf.Session()
    2018-04-17 13:56:44.736125: I C:\tf_jenkins\workspace\tf-nightly-windows\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
    2018-04-17 13:56:45.024692: I C:\tf_jenkins\workspace\tf-nightly-windows\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1355] Found device 0 with properties:
    name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335
    pciBusID: 0000:01:00.0
    totalMemory: 8.00GiB freeMemory: 6.60GiB
    2018-04-17 13:56:45.037254: I C:\tf_jenkins\workspace\tf-nightly-windows\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1434] Adding visible gpu devices: 0
    2018-04-17 13:58:46.118735: I C:\tf_jenkins\workspace\tf-nightly-windows\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:922] Device interconnect StreamExecutor with strength 1 edge matrix:
    2018-04-17 13:58:46.128851: I C:\tf_jenkins\workspace\tf-nightly-windows\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:928]      0
    2018-04-17 13:58:46.134459: I C:\tf_jenkins\workspace\tf-nightly-windows\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:941] 0:   N
    2018-04-17 13:58:46.140199: I C:\tf_jenkins\workspace\tf-nightly-windows\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1052] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6379 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
    &gt;&gt;&gt; print(sess.run(hello))
    b'Hello, TensorFlow!'
    &gt;&gt;&gt;

I'm running python 3.6 in conda 4.5.1.

So CUDA works, since it prints the  *'Hello, TensorFlow!'*, but before that it takes like 2minutes every time! 

When I tested this with [another wheel](https://drive.google.com/drive/folders/1lVK_ABvVHzVYKs7X5SUhcZFBgKpC41Qw) ([which is linked in this tutorial](http://www.python36.com/install-tensorflow-gpu-windows/), I did not compile it myself.) on cuda 9.1/cudnn7.0.5, i had the same issues. A NVIDIA employee [on stackoverflow](https://stackoverflow.com/questions/49770217/why-does-cuda-initialisation-take-so-long-python-vscode-anaconda-tensorflow) suggested, I may be hitting a lengthy JIT compile step, because the GTX 1080 has compute capability of 6.1, which the wheel I used may not be compiled for. 

So I tried to find wheels for tensorflow with compute capability 6.1 for windows, but [the only one I found](https://github.com/fo40225/tensorflow-windows-wheel/tree/master/1.5.0/py36/GPU/cuda91cudnn7avx2) and tested produced the same problem.

I currently have CUDA 9.0 and CuDNN 7.1.2 installed (tested on tensorflow 1.5.0, 1.7.0 and 1.8.0-dev20180329). I had the same issues with CUDA 9.1 and CuDNN 7.0.5 (tested on tensorflow 1.5.0 and 1.7.0).

The GTX 1080 is quite popular, so it should be possible to get this running right? Am I doing something wrong here, or do I just have to accept the 2min delay everytime I start my tensorflow/keras scripts?



",5,3
43,2018-4-18,2018,4,18,17,8d411x,TensorFlow barely using my GPU,https://www.reddit.com/r/tensorflow/comments/8d411x/tensorflow_barely_using_my_gpu/,nst_1234,1524039258,"What I'm trying to do is retrain VGG16 on recognizing new types of Image data using Keras with Tensorflow backend.
After I had a problem with Tensorflow/Keras wanting to allocate too much GPU memory [last week](https://www.reddit.com/r/tensorflow/comments/8b6b3c/tensorflow_suddenly_allocating_way_too_much_gpu/), I tried scaling my input images even further, and now I no longer get that error.

But the training process seems very slow to me, and after checking my GPU performance in the task manager it seems to me like my GPU is barely even being utilized. 

This is my code: https://hastebin.com/pepozayutu.py

This is the output in my console: https://hastebin.com/uhonugenej.md

And this is what my task manager looks like during training: https://imgur.com/a/jRJ66

As you can see the GPU is barely doing anything, so why is my training so slow? It's agonizing to try different setups because each training takes 20-60 min depending on number of epochs.

I have installed Tensorflow-gpu 1.7.0, cuDNN 7.0.5, CUDA 9.0 and Keras 2.1.5. I'm running an NVIDIA GeForce 940MX",4,1
44,2018-4-19,2018,4,19,0,8d6dbo,What are the most interesting github tensorflow projects you know?,https://www.reddit.com/r/tensorflow/comments/8d6dbo/what_are_the_most_interesting_github_tensorflow/,Bulbasaur2015,1524064383,total newbie,1,21
45,2018-4-19,2018,4,19,12,8dboic,Highlights of TensorFlow Developer Summit 2018,https://www.reddit.com/r/tensorflow/comments/8dboic/highlights_of_tensorflow_developer_summit_2018/,rbagdiya,1524108183,,0,1
46,2018-4-19,2018,4,19,13,8dc1ps,I have a sadly morning when I run a RNN example.,https://www.reddit.com/r/tensorflow/comments/8dc1ps/i_have_a_sadly_morning_when_i_run_a_rnn_example/,TimeHeight,1524112112,"Hello everyone.
I am a new learner for tensorflow. And I have just run two demo from https://github.com/tensorflow/tfjs-examples.
I am not understand clearly How RNN run When I run the addition-rnn demo. I just know that it can always put the previous result to the next. So that it can learn something to think which is the best result to the answer. Then the demo run good. After that I have a thought. Addition is always easier than multiply when I learn math, so I update it to a multiply. Update  'a + b' to 'a * b' and 'digits + 1' to 'digits * 2'. When I run the code, I sadly find that none of test example is correct. So I want to know if the RNN is just to guess the result and it is not suitable to accurate operations. And if there some way to improve the accuracy for the multiply.",3,0
47,2018-4-20,2018,4,20,0,8dfo83,Tensorflow Tutorial,https://www.reddit.com/r/tensorflow/comments/8dfo83/tensorflow_tutorial/,1anddy,1524153088,,0,12
48,2018-4-20,2018,4,20,17,8dm39r,Transfer Learning with Object Detection API,https://www.reddit.com/r/tensorflow/comments/8dm39r/transfer_learning_with_object_detection_api/,punkehazardo,1524213400,"I am using the Object Detection API and already have a trained model for my specific object classes. With my task, there will be more and more object classes over time. Since retraining on the combined datasets takes very long, I am interested in a way to only train the pre-trained net on the new data. I found this:
https://stackoverflow.com/questions/47591750/retrain-tensorflow-object-detection-api
But since I would need to load the checkpoint on the already trained data and train it again on a combined dataset, which contains the old data, wouldn't that lead to severe overfitting on the old data?",0,4
49,2018-4-21,2018,4,21,2,8dpm47,2D image classification accuracy with subtle differences,https://www.reddit.com/r/tensorflow/comments/8dpm47/2d_image_classification_accuracy_with_subtle/,ruru32,1524247071,"I have only been tinkering with tensorflow for a week or so now, but so far have been impressed by it. However, I am running into some accuracy issues and I want to better understand whats going on. 

Lets say I need to classify a bunch of logos. A company has the main logo and then the state initials in smaller text near it. 

So first off, there are only one of these images. I create variants using Augmentor, mostly just random 90 rotation, some skew and some distortion. 

When I train and then try to classify an logo, such as ""Big Brand Company Corp (NJ)"" it actually comes back ""Big Brand Company Corp (DC)"" with high confidence - on the incorrect one, and sometimes not even suggesting the correct one in the top 5. 

So, what I'd obviously like to do is get this right, but i'm not sure how. I've tried different tensorflow-hub modules, and increasing/varying the number of images; but nothing has really worked. 

What sort of things should I look into for increasing the accuracy of detecting differences in similar 2D images?",7,3
50,2018-4-21,2018,4,21,7,8dro04,"I created a One Shot Iterator for a csv of png's, now what?",https://www.reddit.com/r/tensorflow/comments/8dro04/i_created_a_one_shot_iterator_for_a_csv_of_pngs/,avtges,1524264100,"Howdy, so I finally got TF working to read my 4,401 png CSV. My only question is, what can I do with it?",0,1
51,2018-4-21,2018,4,21,8,8druiz,Tf.contrib.scipy.optimize(),https://www.reddit.com/r/tensorflow/comments/8druiz/tfcontribscipyoptimize/,nile6499,1524265808,"This function works but why does it evaluates function for 1 time till 5th iteration then starts multiple evaluation.
Or else if anyone can explain me about this function.",0,1
52,2018-4-22,2018,4,22,8,8dzlro,Training custom images,https://www.reddit.com/r/tensorflow/comments/8dzlro/training_custom_images/,nile6499,1524354559,"Hi, I have different folders, and name of the folders is the class name.

How should I import data for training? How should I make the pipeline?",3,1
53,2018-4-23,2018,4,23,14,8e90vk,Video classification using Cnn and then lstm,https://www.reddit.com/r/tensorflow/comments/8e90vk/video_classification_using_cnn_and_then_lstm/,nile6499,1524459704,"Hi, so I have 10 folders of videos (clip 2-10sec), and the folder name is the class name.

My first question.. do I need to divide the videos in image of t10 frame? And then train on CNN. Do I need to train till fully connected layer or till conv5?

Thank you,
Inspiring AI Master
",6,2
54,2018-4-24,2018,4,24,13,8ehr45,Does the TF 1.8 work with CUDA 9.1 at present?,https://www.reddit.com/r/tensorflow/comments/8ehr45/does_the_tf_18_work_with_cuda_91_at_present/,NWO_Propaganda,1524543616,"Thanks for any help, I'm still downloading drivers and hoping that I downloaded the correct 1.4 gig file. Happy coding &lt;3",1,2
55,2018-4-24,2018,4,24,16,8eiqod,Getting the details about the boundary of the objects in images using Tensor flow?,https://www.reddit.com/r/tensorflow/comments/8eiqod/getting_the_details_about_the_boundary_of_the/,lifehacker25,1524556373,"I am trying to build a model to detect different objects in images using the Tensor flow object detection API.

I have images some thing like this, objects placed on a white board. I Can use tensor flow to detect objects in the images, but is it possible to get the boundaries so that I can crop at particular place if I think specific image is necessary and use my Image processing technique further.

[These are some image types which I will be using for object detection](https://imgur.com/a/UyWoFdA)
",0,1
56,2018-4-24,2018,4,24,21,8ek21i,How do I code inverse of a function 'f' in tensorflow if 'f' is a composition of affine transformation with sigmoid activation only?,https://www.reddit.com/r/tensorflow/comments/8ek21i/how_do_i_code_inverse_of_a_function_f_in/,curonimous,1524573431,,1,1
57,2018-4-25,2018,4,25,2,8emdnn,Growing forest panorama simulated in TensorFlow!,https://www.reddit.com/r/tensorflow/comments/8emdnn/growing_forest_panorama_simulated_in_tensorflow/,LiveInIxora,1524592026,,2,6
58,2018-4-25,2018,4,25,4,8en673,Question about TensorFlow.js,https://www.reddit.com/r/tensorflow/comments/8en673/question_about_tensorflowjs/,rasplurker,1524597917,"I was reading about TensorFlow.js and how you can train models stricly on the client side using JS. So the point of this is that the data never hits any backend for computation and its using the computation GPU of the latop or phone right ? If that is the case, I was watching some videos on the topic and they import TennsorFlowJS using script tags that link to a CDN or using NPM to download the module ? What would be the different between both? if I use a CDN than the computation and model traning would NOT happen in the client side? since Im accessing the API through a CDN ? Im a bit confused about this concept. Thanks in advance. ",2,0
59,2018-4-25,2018,4,25,4,8en6do,20 year forest time-lapse made in TensorFlow!,https://www.reddit.com/r/tensorflow/comments/8en6do/20_year_forest_timelapse_made_in_tensorflow/,LiveInIxora,1524597957,,7,55
60,2018-4-25,2018,4,25,8,8ep500,"Why does Tensorflow's sampled_softmax_loss force you to use a bias, when experts recommend no bias be used for Word2Vec?",https://www.reddit.com/r/tensorflow/comments/8ep500/why_does_tensorflows_sampled_softmax_loss_force/,BatmantoshReturns,1524613627,"All the tensorflow implementations of Word2Vec that I have seen has a bias in the negative sampling softmax function, including on the official tensorflow website

https://www.tensorflow.org/tutorials/word2vec#vector-representations-of-words

    loss = tf.reduce_mean(
      tf.nn.nce_loss(weights=nce_weights,
                     biases=nce_biases,
                     labels=train_labels,
                     inputs=embed,
                     num_sampled=num_sampled,
                     num_classes=vocabulary_size))

This is from Google's free Deep Learning course https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/5_word2vec.ipynb

    loss = tf.reduce_mean(
        tf.nn.sampled_softmax_loss(weights=softmax_weights, biases=softmax_biases, inputs=embed,
                                   labels=train_labels, num_sampled=num_sampled, num_classes=vocabulary_size))

However, from both Andrew Ng and Richard Socher's lectures, they do not include a bias in their negative sampling softmaxes.

Even where this idea originated, Mikolov states that:

&gt; biases are not used in the neural network, as no significant improvement of performance was observed - following the Occam's razor, the solution is as simple as it needs to be.

Mikolov, T.: Statistical Language Models Based on Neural Networks, p. 29 http://www.fit.vutbr.cz/~imikolov/rnnlm/thesis.pdf

So why do the official tensorflow implementations have a bias, and why does there not seem to be an option to not include a bias in the sampled_softmax_loss function ?",0,1
61,2018-4-25,2018,4,25,11,8eqa1g,tensorflow.contrib.learn Error?,https://www.reddit.com/r/tensorflow/comments/8eqa1g/tensorflowcontriblearn_error/,exphysioguy,1524624364,"Can I not import tensorflow.contrib.learn for Linear Classifier anymore? 

I keep getting an error message. How do I use Linear Classifier now? ",0,1
62,2018-4-25,2018,4,25,20,8eswm1,Installing TensorFlow On Ubuntu - Get To Know How You Can Easily Have Your TensorFlow Up And Running!,https://www.reddit.com/r/tensorflow/comments/8eswm1/installing_tensorflow_on_ubuntu_get_to_know_how/,pooja307,1524656770,,0,8
63,2018-4-26,2018,4,26,9,8eymyn,Help need with simple CIFAR10 architecture for higher accuracy?,https://www.reddit.com/r/tensorflow/comments/8eymyn/help_need_with_simple_cifar10_architecture_for/,[deleted],1524703458,[deleted],0,1
64,2018-4-26,2018,4,26,10,8eyyg2,Help needed with simple CIFAR10 architecture to get slightly higher accuracy,https://www.reddit.com/r/tensorflow/comments/8eyyg2/help_needed_with_simple_cifar10_architecture_to/,nitred,1524706440,"I'm trying to classify CIFAR10 images using a simple CNN. So far I've only reached an accuracy of 71.8% after 10 epochs and it has already started to overfit. The only preprocessing that I do is standardize each image (individually, not batch).

Could you please make some architectural or preprocessing suggestions that will give a huge boost. I'm not looking to get state of the art results but rather an accuracy somewhere in the high 80's For reference the current benchmarks can be found [here](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).

This is the current architecture:

    with graph.as_default(), tf.device('/gpu:0'):
        ########################################################################
        # Architecture
        ########################################################################
        conv1 = tf.layers.conv2d(_batch_x, filters=128, kernel_size=5, activation=tf.nn.relu)  # 28 x 28
        conv1 = tf.layers.max_pooling2d(conv1, pool_size=2, strides=2)                         # 14 x 14
        conv1 = tf.nn.lrn(conv1, 4)

        conv2 = tf.layers.conv2d(conv1, filters=64, kernel_size=3, activation=tf.nn.relu)      # 12 x 12
        conv2 = tf.layers.max_pooling2d(conv2, pool_size=2, strides=2)                         # 6  x 6
        conv2 = tf.nn.lrn(conv2, 4)

        conv2_flat = tf.contrib.layers.flatten(conv2)                                         # flatten
        fc1 = tf.layers.dense(inputs=conv2_flat, units=102, activation=tf.nn.relu, name='fc1')
        # fc1 = tf.layers.dropout(inputs=fc1, rate=0.5, training=is_training)

        fc2 = tf.layers.dense(inputs=fc1, units=192, activation=tf.nn.relu, name='fc2')
        # fc2 = tf.layers.dropout(inputs=fc2, rate=0.5, training=is_training)

        # Linear activation because we will use sparse_softmax_cross_entropy_with_logits which does softmax for us.
        y_pred = tf.layers.dense(inputs=fc2, units=10)

        ########################################################################
        # Loss and Optimization
        ########################################################################
        _cross_entropy = tf.losses.sparse_softmax_cross_entropy(labels=_batch_y, logits=y_pred)
        _loss = tf.losses.get_total_loss()
        optimizer = tf.train.AdamOptimizer()
        _train = optimizer.minimize(_loss, global_step=_global_step)
",1,1
65,2018-4-26,2018,4,26,12,8ezm4x,How I Teach Machine to Comprehend and Answer Question using Tensorflow - Part I,https://www.reddit.com/r/tensorflow/comments/8ezm4x/how_i_teach_machine_to_comprehend_and_answer/,h_xiao,1524712869,,0,15
66,2018-4-27,2018,4,27,1,8f3xp1,"[Tensorflow] Logits change at test time, depending on the batch size",https://www.reddit.com/r/tensorflow/comments/8f3xp1/tensorflow_logits_change_at_test_time_depending/,saganspace,1524759668,"Does anyone else notice this? I realized when my accuracy changed with different batch sizes, so they're not irrelevant fluctuations.

I attach code that tests this issue. \(tested in tf v1.3\)

[https://www.dropbox.com/s/ns9j84t02zifdaa/test\_batch\_size.zip?dl=0](https://www.dropbox.com/s/ns9j84t02zifdaa/test_batch_size.zip?dl=0)

you can run: python test\_batch\_size.py \-\-batch\_size=2

and it will print the logits for the 1st frame \(which is always the same\).

Varying the batch\_size argument will lead to different logits.

CUDA\_VISIBLE\_DEVICES=\-1 python test\_batch\_size.py \-\-batch\_size=2 

also leads to different results \(cpu vs gpu\)

Do you have comments on this? How should we evaluate our models? What is the best practice?",0,2
67,2018-4-27,2018,4,27,21,8fb81s,What am i doing wrong (Tensorflow Noob).,https://www.reddit.com/r/tensorflow/comments/8fb81s/what_am_i_doing_wrong_tensorflow_noob/,Jonas_SV,1524831841,"The learner does not seem to learn anything 

    import tensorflow as tf
    import numpy as np



    I = tf.placeholder(np.float32, shape=[None, 1], name=""I"")
    L1 = tf.layers.dense(I, 5, activation=tf.nn.tanh)
    L2 = tf.layers.dense(L1, 1, activation=tf.nn.relu)


    def __loss__(predictions, labels):
        return tf.reduce_sum(tf.pow(predictions - labels, 2))


    labels = tf.placeholder(np.float32, shape=[None, 1], name=""L"")

    loss = __loss__(L2, labels)
    learner = tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(loss)

    IP = np.array([[1],[2],[3],[4]], dtype=np.float32)
    LABEL = np.array([[-1],[-2],[-3],[-4]], dtype=np.float32)


    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())

        print(sess.run(L2, {""I:0"": IP}))
        iters = 10
        while iters:
            _, l = sess.run((learner, loss), feed_dict={""I:0"": IP, ""L:0"": LABEL})

            print(l)

            iters -= 1

        print(sess.run(L2, {""I:0"": IP}))

    sess.close()



Output 

      [[0.10446054]
     [0.165672  ]
     [0.17981592]
     [0.1674025 ]]
    33.38844
    30.0
    30.0
    30.0
    30.0
    30.0
    30.0
    30.0
    30.0
    30.0
    [[0.]
     [0.]
     [0.]
     [0.]]


What am i doing wrong? :( 

And in general what is the recommended data pipeline for tensorflow, i've heard people not recommending feed_dict",3,2
68,2018-4-28,2018,4,28,4,8feijx,How well can DNN work on Abalone Dataset?,https://www.reddit.com/r/tensorflow/comments/8feijx/how_well_can_dnn_work_on_abalone_dataset/,HunterTom94,1524858723,"Hi Guys,

I am new to ML but I just  downloaded the existing estimator for iris dataset from  

**git clone https://github.com/tensorflow/models**  

and tried to modify it to accept input from the abalone dataset. I have modified the iris\_data file as well.

The model runs fine \(except the fact that n\_classes for the classifier has to be 30 in order to function\). However, even if I set the hidden\_units=\[1000, 100,100\] and **batch\_size** = 1000, after hours of training, my accuracy is still 0.12. Even though the loss is less than 1.

It does not make sense to me. Can anyone tell me some parameters that worked on this data set? Thanks very much!",2,1
69,2018-4-28,2018,4,28,6,8ff1jm,"How do you use decode_csv to get columns, where one column is a ""list""?",https://www.reddit.com/r/tensorflow/comments/8ff1jm/how_do_you_use_decode_csv_to_get_columns_where/,rjddude1,1524863172,"I have training data with few categorical values (tags). The tag values are from a predefined set of vocabularies (that can expand over time). 

A single column can have multiple ""tags"". So for instance, one of the columns  is 'User City Preferences', where the tags are predefined set of cities that the user can pick from. This column can have multiple categorical values:

    #CSV data column
    #User-City-Preference,Happiness
    Berlin|London|Budapest,0.4
    London|Toronto,0.6
    
    #Vocabulary looks like this: 
    ['Berlin', 'London', 'Budapest', 'Toronto']

If I were to convert the first column to a feature, I want the tensor to be represented like **[[1 1 0 1] [0 1 0 1]]**

When I'm using the decode_csv to convert the csv data into tensors, how do I make sure that the delimited values for the column gets parsed correctly. Essentially how do I handle a list within a csv column? 

And once I have these, and I want to use them in the wide/deep model, what type of feature column should they be converted in?

Any help would be appreciated.",1,1
70,2018-4-28,2018,4,28,11,8fgv2i,I am looking for contributors to make research on different ML architectures applied to popular data-sets.,https://www.reddit.com/r/tensorflow/comments/8fgv2i/i_am_looking_for_contributors_to_make_research_on/,rahimlis,1524881107,,2,2
71,2018-4-28,2018,4,28,14,8fi0wm,A step-by-step guide for tensorflow gpu installation on ubuntu 18.04,https://www.reddit.com/r/tensorflow/comments/8fi0wm/a_stepbystep_guide_for_tensorflow_gpu/,kekayan,1524894751,,0,19
72,2018-4-28,2018,4,28,15,8fi3zu,output shape of tensor changes when assigned to a variable,https://www.reddit.com/r/tensorflow/comments/8fi3zu/output_shape_of_tensor_changes_when_assigned_to_a/,memlimexced,1524895905,"Defined a model which takes input of shape(96,96,3) and outputs shape(128) i.e. gives an embedding of 128 size for a given image of input size. Similar to facenet

createmodel() is the function which returns the full model after constructing it. Since the model expects input in the form of (batch_size,96,96,3) I pass 3 images i.e. (3,96,96,3) so the output of the model will be of shape(1,3,128). Keeping that in mind consider the following:

    nn4_small2=createmodel()
    print(nn4_small2.outputs[0][2])

#prints Tensor(""strided_slice_11:0"", shape=(128,), dtype=float32)

    x=nn4_small2.outputs[0][2]
    print(tf.shape(x))

#prints Tensor(""Shape_6:0"", shape=(1,), dtype=int32)
Why does the shape of the output tensor change when assigned to a variable?",0,1
73,2018-4-29,2018,4,29,15,8fprxb,"Implementing a custom function inside loss, which will use model predictions as parameter and return a value to the loss function. Can anyone help me with this, please? I searched for a full day and still can't do this! it seems very simple but impossible to me.",https://www.reddit.com/r/tensorflow/comments/8fprxb/implementing_a_custom_function_inside_loss_which/,theslt,1524984395,,1,0
74,2018-4-30,2018,4,30,8,8fv9r9,EosToken,https://www.reddit.com/r/tensorflow/comments/8fv9r9/eostoken/,QoQzZ,1525044851,"EosToken500,000EOS~0EOShttp://static.eostoken.im/invite/index.html#423667,",0,0
75,2018-4-30,2018,4,30,12,8fwlgz,Negative sampling in tensorflow?,https://www.reddit.com/r/tensorflow/comments/8fwlgz/negative_sampling_in_tensorflow/,mortonjt,1525058511,"Has anyone been able to make sense of what is going underneath the hood with negative sampling?  I'm trying to implement my own negative sampler using similar techniques implemented in NCE and am finding a bit challenging to fully understand.

Right now I'm trying to make use the of the `[compute_accidental_hits](https://www.tensorflow.org/api_docs/python/tf/nn/compute_accidental_hits)` function - since it looks like most of these negative sampling techniques make use of this.  However, I'm getting a bit confused about the documentation.  For instance, it's not clear to me how the `sparse_to_dense` function will come to play here.  Or exactly how this function can help remove the contradictory effect of accidental hits.  Any thoughts on this functionality?",0,1
76,2018-4-30,2018,4,30,14,8fxafp,How do you categorize/organize trained models?,https://www.reddit.com/r/tensorflow/comments/8fxafp/how_do_you_categorizeorganize_trained_models/,IntegrateMe,1525066946,"I'm working on a project right now where the output of my model is merely a class with three values. -1, 0, or +1. Pretty standard stuff.

Over time, I found myself trying new features, different learning rates, different topologies... etc. 

I then found myself wondering, wait how would this model benefit from another dropout layer and so on, but then I would struggle to go through my git history to find out which one I was wondering about.

So the question is, how do the rest of you organize/categorize your models. What's your process for archiving models and restoring them for tensorflow?

Sorry if the question is vague, I'm new to tensorflow. DevOps by trade, so old habits die hard.",4,2
77,2018-4-30,2018,4,30,23,8fzpvk,Text Summarizer using Tensorflow,https://www.reddit.com/r/tensorflow/comments/8fzpvk/text_summarizer_using_tensorflow/,Wallflower_Paradox,1525097458,"How do we make a text summarizer using Tensorflow? I want some documentation or reference . An already made  project would be great to study. 

I got this as an assignment for . How long does it take to make it ? And, where to start? Please reply . Thanks already. ",1,2
