,sbr,sbr_id,date,year,month,hour,day,id,domain,title,full_link,author,created,selftext,num_comments,score,over_18,thumbnail,media_provider,media_thumbnail,media_title,media_description,media_url
0,tensorflow,t5_3alkk,2018-12-2,2018,12,2,22,a2db8z,self.tensorflow,"Tensorflow YOLO or OpenCV cascade classifier? For detecting icon, button or object on android device screen",https://www.reddit.com/r/tensorflow/comments/a2db8z/tensorflow_yolo_or_opencv_cascade_classifier_for/,ipuneetj,1543758430,"Hi,

I want to do a project which require detecting icons, buttons, text area, keyboard etc on screen of android device. I studied enough to start with OpenCV HAAR cascade classifier. But then I read somewhere for simpler objects like icon or logo, using OpenCV is not a good idea. Then I came to know about tensorflow YOLO. I haven't started learning tensorflow yet.

I am a newbie to machine learning. And I understand if I have to use tensorflow, I will have to take a dig into machine learning models which is ok! 

But I want to understand which is better for my requirements of simple object detection and why?

Thanks",4,1,False,self,,,,,
1,tensorflow,t5_3alkk,2018-12-3,2018,12,3,0,a2dy8z,self.tensorflow,Multi Label Classification mnist,https://www.reddit.com/r/tensorflow/comments/a2dy8z/multi_label_classification_mnist/,b4shyou,1543763549,"Hi

I am trying to do a sequence detection on the mnist dataset in order to improve my tf skills. I am trying to achieve this without RNNs.

I horizontally stacked 5 images and then tried to run the classification.

Unfortunately I get very low accuracy.

Did I made  a mistake or just trained with to less data and not long enough?

Best regards

    #Create a model with 5 classifiers
    
    graph = tf.Graph()
    
    with graph.as_default():
        data = tf.placeholder(dtype=tf.float32,shape=(None, 28,140,1))
        tf_train_labels = tf.placeholder(dtype=tf.float32, shape=(None, 5,11))
        
        w1 = tf.Variable(tf.truncated_normal(shape=(3,3, 1,32), stddev=0.1))
        b1 = tf.Variable(tf.zeros(32))
        
        w2 = tf.Variable(tf.truncated_normal(shape=(3,3,32,64), stddev=0.1))
        b2 = tf.Variable(tf.constant(1., shape=[64]))
        
        w22 = tf.Variable(tf.truncated_normal(shape=(3,3,64,128), stddev=0.1))
        b22 = tf.Variable(tf.constant(1., shape=[128]))
    
    
        
        w3 = tf.Variable(tf.truncated_normal(shape=(28 // 4 * 140 // 4 * 128,1024)))
        b3 = tf.Variable(tf.constant(1., shape=[1024]))
        
        w4 = tf.Variable(tf.truncated_normal(shape=(1024,11), stddev=0.1))
        b4 = tf.Variable(tf.constant(1., shape=[11]))
        
        w5 = tf.Variable(tf.truncated_normal(shape=(1024,11), stddev=0.1))
        b5 = tf.Variable(tf.constant(1., shape=[11]))
    
        w6 = tf.Variable(tf.truncated_normal(shape=(1024,11), stddev=0.1))
        b6 = tf.Variable(tf.constant(1., shape=[11]))
        
        w7 = tf.Variable(tf.truncated_normal(shape=(1024,11), stddev=0.1))
        b7 = tf.Variable(tf.constant(1., shape=[11]))
        
        w8 = tf.Variable(tf.truncated_normal(shape=(1024,11), stddev=0.1))
        b8 = tf.Variable(tf.constant(1., shape=[11]))
        
    
        
        def model(x, w, b):
            conv= tf.nn.relu(tf.nn.conv2d(x, w1, [1,1,1,1], padding=""SAME"")+b1)
            conv = tf.nn.max_pool(conv, [1,2,2,1], [1,2,2,1], padding=""SAME"")
            conv = tf.nn.relu(tf.nn.conv2d(conv, w2, [1,1,1,1], padding=""SAME"")+b2)
            conv = tf.nn.max_pool(conv, [1,2,2,1], [1,2,2,1],padding=""SAME"")
            conv = tf.nn.relu(tf.nn.conv2d(conv, w22, [1,1,1,1], padding=""SAME"")+b22)
    
            shape = conv.get_shape().as_list()
            reshape = tf.reshape(conv, [-1, shape[1] * shape[2] * shape[3]])
            dense = tf.nn.relu(tf.matmul(reshape, w3)+b3)
            return tf.matmul(dense, w) + b
        pred1 = model(data, w4, b4)
        pred2 = model(data, w5, b5)
        pred3 = model(data, w6, b6)
        pred4 = model(data, w7, b7)
        pred5 = model(data, w8, b8)
        
        prediction = tf.stack([
                tf.nn.softmax(pred1),
                tf.nn.softmax(pred2),
                tf.nn.softmax(pred3),
                tf.nn.softmax(pred4),
                tf.nn.softmax(pred5)])
    
    
        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(
                       logits = pred1, labels = tf_train_labels[:, 0])) + \
                   tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(
                       logits = pred2, labels = tf_train_labels[:, 1])) + \
                   tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(
                       logits = pred3, labels = tf_train_labels[:, 2])) + \
                   tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(
                       logits = pred4, labels = tf_train_labels[:, 3])) + \
                   tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(
                       logits = pred5, labels = tf_train_labels[:, 4]))
    
        
        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.0001).minimize(loss)
        init = tf.global_variables_initializer()",2,1,False,self,,,,,
2,tensorflow,t5_3alkk,2018-12-4,2018,12,4,0,a2phrm,self.tensorflow,TF FailedPreconditionError - uninitialized value Variable,https://www.reddit.com/r/tensorflow/comments/a2phrm/tf_failedpreconditionerror_uninitialized_value/,bitsofshit,1543849864,"Hi all,

Trying to diagnose error received even after resetting graph and reinit globally. What gives?
```
tf.reset_default_graph()

#x = tf.Variable(image, name='x')
arr = tf.Variable([[1,2,3],[4,5,6]],dtype= tf.int32)
arr2 = tf.constant((1,2,3))
#arr.assign_add
arr3 = tf.Variable(arr + arr2,name='arr3')

sess = tf.Session()

with sess.as_default():
    sess.run(tf.global_variables_initializer())
    #sess.run(x)
```
Here is resulting output:

 Attempting to use uninitialized value Variable
	 [[Node: Variable/read = Identity[T=DT_INT32, _class=[""loc:@Variable""], _device=""/job",1,1,False,self,,,,,
3,tensorflow,t5_3alkk,2018-12-4,2018,12,4,13,a2x981,self.tensorflow,Zero experience with tensorflow - need an image transformation training script.,https://www.reddit.com/r/tensorflow/comments/a2x981/zero_experience_with_tensorflow_need_an_image/,HomeBrewingCoder,1543898533,"I have a need for a way to train a neural network to do an image transformation.

Lets say I have some folder 

inputs/

and some secondary folder

outputs/

each being full of images (image 1.png in inputs corresponds to 1.jpg in outputs) where the outputs is exactly the expected transformation that is required.


What would a basic POC be for this?


I know I'm a jerk for this, coming in here and having almost nothing and expecting it to be 'so simple'.  I truly do just need the absolute most basic version so I can prove that a pre-processing step will reduce the level of overtraining that is currently nuking the project we are testing.

Thanks so much  guys!

",5,1,False,self,,,,,
4,tensorflow,t5_3alkk,2018-12-5,2018,12,5,2,a331uf,self.tensorflow,Keras Implementation of Googles new Yogi-Optimizer,https://www.reddit.com/r/tensorflow/comments/a331uf/keras_implementation_of_googles_new_yogioptimizer/,4rtemi5,1543946141,"I wrote an tf.keras implementation of a new Optimizer submitted to NeurIPS-2018 by a team from Google. It outperforms Adam under many circumstances with little to none hyperparameter-tuning.

&amp;#x200B;

Paper can be found here: [http://papers.nips.cc/paper/8186-adaptive-methods-for-nonconvex-optimization.pdf](http://papers.nips.cc/paper/8186-adaptive-methods-for-nonconvex-optimization.pdf)

Code can be found here: [https://github.com/4rtemi5/Yogi-Optimizer\_Keras](https://github.com/4rtemi5/Yogi-Optimizer_Keras)

Colab notebook can be found here: [https://colab.research.google.com/drive/1xXh2xJdGjrcZ4XjUXWaSQ2osBR09UBG6](https://colab.research.google.com/drive/1xXh2xJdGjrcZ4XjUXWaSQ2osBR09UBG6)

&amp;#x200B;

Thanks for this great contribution to the authors!",9,1,False,self,,,,,
5,tensorflow,t5_3alkk,2018-12-5,2018,12,5,5,a34g3i,self.tensorflow,"Trying to remap a tensor of one-hot labels, how would I go about that?",https://www.reddit.com/r/tensorflow/comments/a34g3i/trying_to_remap_a_tensor_of_onehot_labels_how/,rumborak,1543954881," I have a tensor that contains labels in one-hot format: \[0 0 0 0 0 1 0 0 0 0.....\]. I am trying to remap these labels, for example wanting the mentioned tensor to be transformed into \[0 1 0 0 0 0 ....\], i.e. label 6 becomes label 2. That is, the general idea is to have a map ""6 -&gt;2, 10 -&gt; 1"" etc.

&amp;#x200B;

I looked into tf.map\_fn, tf.cond, tf.where etc, but none of these seem to do what I need. My last resort is to create a matrix that transforms the tensor that way, but is there a ""good"" way? ",0,1,False,self,,,,,
6,tensorflow,t5_3alkk,2018-12-5,2018,12,5,18,a3amzo,self.tensorflow,What is the best way to train network using tensorflow on multiple GPU's with tf.Data API ?,https://www.reddit.com/r/tensorflow/comments/a3amzo/what_is_the_best_way_to_train_network_using/,goravk,1544000760,"It's very difficult to train a tensorflow model with multiple GPU's  and there are no clear documents/guides which mention the best way to  train it on multiple GPU's. Code used in many tutorials is outdated and it looks like estimators are the latest way in Tensorflow to do training on multiple GPU's.

But recently I came across Horovod and then to [collectiveallreduce](https://www.logicalclocks.com/goodbye-horovod-hello-tensorflow-collectiveallreduce/). And now I'm confused which is the best way to do distributed training.

Is there any other simpler API or Tensorflow estimators and Horovod  are the best ways currently available (using tf.data pipeline)?

Thanks.",5,1,False,self,,,,,
7,tensorflow,t5_3alkk,2018-12-6,2018,12,6,4,a3fgj2,self.tensorflow,Tensorflow CPU memory allocation problem (Abandon (core dumped)),https://www.reddit.com/r/tensorflow/comments/a3fgj2/tensorflow_cpu_memory_allocation_problem_abandon/,jjrmyy,1544037067,"I created a program in python using Keras/Tensorflow. I don't have  any problem for the creation of my data and the training. However, I  have the following error when I want to **evaluate** my model:

`Using TensorFlow backend. WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4213: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version. Instructions for updating: Create a \`tf.sparse.SparseTensor\` and use \`tf.sparse.to_dense\` instead. 2018-12-05 19:20:44.932780: W tensorflow/core/framework/allocator.cc:122] Allocation of 3359939800 exceeds 10% of system memory. terminate called after throwing an instance of 'std::bad_alloc'   what():  std::bad_alloc Abandon (core dumped)`

&amp;#x200B;

It seems to be a **memory allocation problem**. I reduced  the size of my model and make smaller all the parameters but nothing has  changed. I don't know how to solve this issue.",0,1,False,self,,,,,
8,tensorflow,t5_3alkk,2018-12-6,2018,12,6,11,a3jqor,self.tensorflow,Tensorflow Estimator API causes crash at `sampled_softmax_loss` and `nce_loss` for Tensorflow's official word2vec implentation,https://www.reddit.com/r/tensorflow/comments/a3jqor/tensorflow_estimator_api_causes_crash_at_sampled/,BatmantoshReturns,1544064698,"This is a distilled version of this unanswered question

https://stackoverflow.com/questions/53405657/converting-tensorflow-graph-to-use-tensorflow-estimator-getting-typeerror-dat

The issue is that `sampled_softmax_loss` and `nce_loss` gives an error when using Tensorflow Estimators. 

I decided to develop a Estimator based on Tensorflow's own Word2Vec implementation to 1) minimalize the problem as much as possible 2) using Tensorflow's own official implementation code to give confidence of where the problem is exactly isolated. 

Here's is Tensorflow's official basic word2vec implementation

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/word2vec/word2vec_basic.py

Here is the Google Colab notebook where I implemented this code. 

https://colab.research.google.com/drive/1nTX77dRBHmXx6PEF5pmYpkIVxj_TqT5I

Here is the Google Colab notebook where I altered the code so that it uses Tensorflow Estimator. 

https://colab.research.google.com/drive/1IVDqGwMx6BK5-Bgrw190jqHU6tt3ZR3e

For convenience, here is exact code from the notebook above where I define `model_fn`

    batch_size = 128
    embedding_size = 128  # Dimension of the embedding vector.
    skip_window = 1  # How many words to consider left and right.
    num_skips = 2  # How many times to reuse an input to generate a label.
    num_sampled = 64  # Number of negative examples to sample.
    
    def my_model( features, labels, mode, params):
    
        with tf.name_scope('inputs'):
            train_inputs = features
            train_labels = labels
    
        with tf.name_scope('embeddings'):
            embeddings = tf.Variable(
              tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))
            embed = tf.nn.embedding_lookup(embeddings, train_inputs)
    
        with tf.name_scope('weights'):
            nce_weights = tf.Variable(
              tf.truncated_normal(
                  [vocabulary_size, embedding_size],
                  stddev=1.0 / math.sqrt(embedding_size)))
        with tf.name_scope('biases'):
            nce_biases = tf.Variable(tf.zeros([vocabulary_size]))
    
        with tf.name_scope('loss'):
            loss = tf.reduce_mean(
                tf.nn.nce_loss(
                    weights=nce_weights,
                    biases=nce_biases,
                    labels=train_labels,
                    inputs=embed,
                    num_sampled=num_sampled,
                    num_classes=vocabulary_size))
    
        tf.summary.scalar('loss', loss)
    
        if mode == ""train"":
            with tf.name_scope('optimizer'):
                optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss)
    
            return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=optimizer)

And here is where I call the estimator and training 

    word2vecEstimator = tf.estimator.Estimator(
            model_fn=my_model,
            params={
                'batch_size': 16,
                'embedding_size': 10,
                'num_inputs': 3,
                'num_sampled': 128,
                'batch_size': 16
            })
    
    word2vecEstimator.train(
        input_fn=generate_batch,
        steps=10)

And this the error message I get when using Estimator

    INFO:tensorflow:Calling model_fn.
    ---------------------------------------------------------------------------
    TypeError                                 Traceback (most recent call last)
    &lt;ipython-input-22-955f44867ee5&gt; in &lt;module&gt;()
          1 word2vecEstimator.train(
          2     input_fn=generate_batch,
    ----&gt; 3     steps=10)
    
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)
        352 
        353       saving_listeners = _check_listeners_type(saving_listeners)
    --&gt; 354       loss = self._train_model(input_fn, hooks, saving_listeners)
        355       logging.info('Loss for final step: %s.', loss)
        356       return self
    
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)
       1205       return self._train_model_distributed(input_fn, hooks, saving_listeners)
       1206     else:
    -&gt; 1207       return self._train_model_default(input_fn, hooks, saving_listeners)
       1208 
       1209   def _train_model_default(self, input_fn, hooks, saving_listeners):
    
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)
       1235       worker_hooks.extend(input_hooks)
       1236       estimator_spec = self._call_model_fn(
    -&gt; 1237           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
       1238       global_step_tensor = training_util.get_global_step(g)
       1239       return self._train_with_estimator_spec(estimator_spec, worker_hooks,
    
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _call_model_fn(self, features, labels, mode, config)
       1193 
       1194     logging.info('Calling model_fn.')
    -&gt; 1195     model_fn_results = self._model_fn(features=features, **kwargs)
       1196     logging.info('Done calling model_fn.')
       1197 
    
    &lt;ipython-input-20-9d389437162a&gt; in my_model(features, labels, mode, params)
         33                 inputs=embed,
         34                 num_sampled=num_sampled,
    ---&gt; 35                 num_classes=vocabulary_size))
         36 
         37     # Add the loss value as a scalar to summary.
    
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py in nce_loss(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, remove_accidental_hits, partition_strategy, name)
       1246       remove_accidental_hits=remove_accidental_hits,
       1247       partition_strategy=partition_strategy,
    -&gt; 1248       name=name)
       1249   sampled_losses = sigmoid_cross_entropy_with_logits(
       1250       labels=labels, logits=logits, name=""sampled_losses"")
    
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py in _compute_sampled_logits(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, subtract_log_q, remove_accidental_hits, partition_strategy, name, seed)
       1029   with ops.name_scope(name, ""compute_sampled_logits"",
       1030                       weights + [biases, inputs, labels]):
    -&gt; 1031     if labels.dtype != dtypes.int64:
       1032       labels = math_ops.cast(labels, dtypes.int64)
       1033     labels_flat = array_ops.reshape(labels, [-1])
    
    TypeError: data type not understood",0,1,False,self,,,,,
9,tensorflow,t5_3alkk,2018-12-6,2018,12,6,15,a3li65,self.tensorflow,TensorFlow.js not able to save model,https://www.reddit.com/r/tensorflow/comments/a3li65/tensorflowjs_not_able_to_save_model/,CSS_Programmer,1544078842,"I am using TensorFlow.js in node and I am not able to save my models. I have been racking my brains out trying to figure this out. According to [this](https://js.tensorflow.org/tutorials/model-save-load.html) tutorial I need to place \`require('@tensorflow/tfjs-node')\` in my dependencies and install it, which I have done. I have written the simplest code possible to save a model:

&amp;#x200B;

    var tf = require('@tensorflow/tfjs')
require('@tensorflow/tfjs-node')

// First create and save a model.
doit()
async function doit(){
 const model = tf.sequential();
 model.add(tf.layers.dense(
        { units: 1, inputShape: [10], activation: 'sigmoid' }));
 await model.save('file:///Users/powermac/Dev/rateBot/modelsave1');
}

When I run it I get this error:

    (node:2603) UnhandledPromiseRejectionWarning: Error: Cannot find any save handlers for URL 'file:///Users/powermac/Dev/rateBot/trash/modelsave1'
        at new ValueError (/Users/powermac/Dev/node_modules/@tensorflow/tfjs-layers/dist/errors.js:36:28)
        at Sequential.&lt;anonymous&gt; (/Users/powermac/Dev/node_modules/@tensorflow/tfjs-layers/dist/engine/training.js:906:39)
        at step (/Users/powermac/Dev/node_modules/@tensorflow/tfjs-layers/dist/engine/training.js:42:23)
        at Object.next (/Users/powermac/Dev/node_modules/@tensorflow/tfjs-layers/dist/engine/training.js:23:53)
        at /Users/powermac/Dev/node_modules/@tensorflow/tfjs-layers/dist/engine/training.js:17:71
        at new Promise (&lt;anonymous&gt;)
        at __awaiter (/Users/powermac/Dev/node_modules/@tensorflow/tfjs-layers/dist/engine/training.js:13:12)
        at Sequential.Model.save (/Users/powermac/Dev/node_modules/@tensorflow/tfjs-layers/dist/engine/training.js:898:16)
        at doit (/Users/powermac/Dev/rateBot/repl.js:10:17)
        at Object.&lt;anonymous&gt; (/Users/powermac/Dev/rateBot/repl.js:5:1)
    (node:2603) UnhandledPromiseRejectionWarning: Unhandled promise rejection. This error originated either by throwing inside of an async function without a catch block, or by rejecting a promise which was not handled with .catch(). (rejection id: 3)
    (node:2603) [DEP0018] DeprecationWarning: Unhandled promise rejections are deprecated. In the future, promise rejections that are not handled will terminate the Node.js process with a non-zero exit code.

I have installed the dependencies, my computer is updated (a mac), and I have node version v8.12.0 installed (which is a LTS version). I've tried using other node versions but with no success.",6,1,False,self,,,,,
10,tensorflow,t5_3alkk,2018-12-7,2018,12,7,0,a3p44u,self.tensorflow,"Simple examples of evaluating tf.Graph, Tensos etc?",https://www.reddit.com/r/tensorflow/comments/a3p44u/simple_examples_of_evaluating_tfgraph_tensos_etc/,nobodywillobserve,1544111527,"The documentation is deliberately poisonous. Eager execution is not supported in some areas I am trying to debug. I don't want to hear about what graphs are or be taught concepts I know, I want to know what setting a variable looks like and running it in a session.   


Are there are examples written by actual humans who assume the reader knows everything except for the library? ",5,1,False,self,,,,,
11,tensorflow,t5_3alkk,2018-12-7,2018,12,7,2,a3pvkg,towardsdatascience.com,What they don't tell you about scaling AI,https://www.reddit.com/r/tensorflow/comments/a3pvkg/what_they_dont_tell_you_about_scaling_ai/,woodworksio,1544116087,,1,1,False,default,,,,,
12,tensorflow,t5_3alkk,2018-12-7,2018,12,7,6,a3sp5g,self.tensorflow,Behaviour of BatchNormalisation in keras model with random weights assigned?,https://www.reddit.com/r/tensorflow/comments/a3sp5g/behaviour_of_batchnormalisation_in_keras_model/,nobodywillobserve,1544132641,"I am doing some weird things with creating random networks and I am wondering how the BatchNormalization weight recalc is triggered/recalced. It looks like it is just on __call__ but I am *just* reading the code.

Basically, if I get the axis right I am hoping random Dense set by set_weights will sill be normed by the BatchNorm layer.

Anyone who knows this stuff know if this is all a bad idea? I am pretty must just guessing and hacking/pretty new to the details of tf.",0,1,False,self,,,,,
13,tensorflow,t5_3alkk,2018-12-7,2018,12,7,11,a3vhhj,self.tensorflow,pip install tensorflow #on windows,https://www.reddit.com/r/tensorflow/comments/a3vhhj/pip_install_tensorflow_on_windows/,Background_Mongoose,1544150666,"If you throw ""pip install tensorflow"" in windows 7 DOS command prompt as administrator it does not work and I know there is some sort of cryptic way to do it right but I'm pressed for time and deciphering it, plus I know you guys will most likely know how to help me :)

&amp;#x200B;

thank you",11,1,False,self,,,,,
14,tensorflow,t5_3alkk,2018-12-8,2018,12,8,4,a43bn3,self.tensorflow,Dilated 3D convolutions in TensorFlow.,https://www.reddit.com/r/tensorflow/comments/a43bn3/dilated_3d_convolutions_in_tensorflow/,RohitDulam,1544211850,[removed],0,1,False,self,,,,,
15,tensorflow,t5_3alkk,2018-12-8,2018,12,8,14,a483ln,self.tensorflow,Can't get the hang of loops,https://www.reddit.com/r/tensorflow/comments/a483ln/cant_get_the_hang_of_loops/,psyyduck,1544247701,"    import tensorflow as tf
    import tensorflow_probability as tfp
    import numpy as np
    tfd = tfp.distributions
    
    data = tf.placeholder(dtype=tf.float32)
    mu = tf.constant([1.5,2.5,3.5], dtype=tf.float32)
    sigma  = tf.constant([1,0.75,0.5], dtype=tf.float32)
    
    allprobs = tf.Variable(tf.zeros(shape=[3], dtype=tf.float32))
    
    def body(x):    
        return allprobs[x].assign( tfd.Normal(loc=mu[x], scale=sigma[x]).log_prob(value=data[x]) )

    def condition(i):
        return i &lt; 3
    
    i = tf.Variable(tf.constant(0))
    
    result = tf.while_loop(condition, body, [i])
    
    with tf.Session() as sess:
        x_obs = [1,2,3]
        ones, testr = sess.run([zeros_op, result], feed_dict={ data: x_obs})

As you guys see, I'm trying to get a list, with [prob(1) (normal(1.5,1)) , prob(2) (normal(2.5,0.75)) , prob(3) (normal(3.5,0.5)) ]. No luck so far. Any help would be appreciated.",1,1,False,self,,,,,
16,tensorflow,t5_3alkk,2018-12-9,2018,12,9,0,a4bqgd,self.tensorflow,DataLossError: corrupted record,https://www.reddit.com/r/tensorflow/comments/a4bqgd/datalosserror_corrupted_record/,OrrKislev,1544284097,"Hi!

I am using [https://github.com/tkarras/progressive\_growing\_of\_gans](https://github.com/tkarras/progressive_growing_of_gans), running tensorflow. and it runs very well. actually I managed to get some great results with a few different datasets.

but not I'm getting an error:  
`DataLossError (see above for traceback): corrupted record at 64793939627`

	 `[[{{node Inputs/IteratorGetNext}} = IteratorGetNext[output_shapes=[[?,?,?,?], [?,0]], output_types=[DT_UINT8, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Dataset/IteratorV2)]]`

&amp;#x200B;

I got this error after a week of the algorithm working, and after resuming using the last saved state of the network, and even after resuming the previous state of the network..  
Also I got the same error reproduced when I restarted the whole thing again - after about a week of working, at the exact same spot - after passing through 9010k images

&amp;#x200B;

I guess its not an error in the dataset becuase it happens only after working for a few days, running 9010k images, and my dataset is only 40k images

&amp;#x200B;

any idea how to debug this? how to fix it?

thaks

Orr

&amp;#x200B;",0,1,False,self,,,,,
17,tensorflow,t5_3alkk,2018-12-9,2018,12,9,9,a4g5q4,self.tensorflow,TF 2.0 preparation,https://www.reddit.com/r/tensorflow/comments/a4g5q4/tf_20_preparation/,_spicyramen,1544314337,"Based on TensorFlow newsletter, what is the recommend way of building models:

1. Use tf.feature\_column for features (Now supported in Keras tf-nightly)
2. Remove contrib references if possible
3. Keras with tf.data.Dataset for input:
4. For model training and evaluation should we use: 

**model\_to\_estimator**\+**train\_and\_evaluate** or  **model.fit** \+ **tf.data.Dataset** ?

&amp;#x200B;",8,1,False,self,,,,,
18,tensorflow,t5_3alkk,2018-12-10,2018,12,10,20,a4upmf,self.tensorflow,Replacing loading via feed_dict with tf.data API,https://www.reddit.com/r/tensorflow/comments/a4upmf/replacing_loading_via_feed_dict_with_tfdata_api/,ashblue21,1544439659,"I  am implementing a GAN model where my current input pipeline loads images from two domains(let's say domain A and domain B) using placeholders and feed\_dict. I cannot directly load the images into memory because I run out of memory and I use the path to the file location and opencv to read the images.  My code for this looks something like this 

    A = tf.placeholder(None,256,256,3)
    B = tf.placeholder(None,256,256,3)
    dis_loss,gan_loss = cost(A,B)  # cost(A,B) is a function defining discriminator and generator losses
    # More code
    D_solver = tf.train.AdamOptimizer(beta1 = 0.5).minimize(dis_loss, var_list=disA_var+disB_var)
    G_solver = tf.train.AdamOptimizer(beta1 = 0.5).minimize(gan_loss, var_list=genA_var+genB_var) 
    # Initialize tf Session and load a batch of images from file location,shuffle and  read the images #via open CV and load them into 2 numpy arrays of shape (batch_size,256,256,3)
    
    
    _, D_loss_curr = sess.run([D_solver, dis_loss], feed_dict={A: numpy_array_1 ,B:numpy_array_2})
    _, G_loss_curr = sess.run([G_solver, gan_loss], feed_dict={A: numpy_array_1 ,B: numpy_array_1})
    # more code
    #plot results etc

I am fairly new to Tensorflow and am a bit confused as to how to go about using the tf.data API to directly load images and eliminate the use of feed\_dict. My goal is to prefetch the next batch to maximize GPU utilization. It would be great if someone could suggest pseudocode for this. I tried using tf.image.decode\_jpeg and resizing the image, but I am not sure how to actually proceed from there. Thanks",2,1,False,self,,,,,
19,tensorflow,t5_3alkk,2018-12-10,2018,12,10,20,a4utn6,self.tensorflow,Installing tensorflow=1.0.0 with python = 3.5 on ubuntu ?,https://www.reddit.com/r/tensorflow/comments/a4utn6/installing_tensorflow100_with_python_35_on_ubuntu/,zarooricheck,1544440779,"I've tried [https://stackoverflow.com/questions/38896424/tensorflow-not-found-using-pip](https://stackoverflow.com/questions/38896424/tensorflow-not-found-using-pip) but it doesn't seem to work. 

Can some please provide link from [https://storage.googleapis.com/tensorflow](https://storage.googleapis.com/tensorflow) to install. 

&amp;#x200B;

Thank you",9,1,False,self,,,,,
20,tensorflow,t5_3alkk,2018-12-12,2018,12,12,19,a5gxiv,self.tensorflow,I have some question about tensorflow to javacc,https://www.reddit.com/r/tensorflow/comments/a5gxiv/i_have_some_question_about_tensorflow_to_javacc/,GabrielCPond,1544609849,"I'm doing my homework the professor ask us make a javacc file about tensorflow( tensorflow neural network ), but I could not find any example at internet, could anybody give me some hint about it?

this is the one of the tensorflow python code 

`W = tf.Variable(tf.random_normal([2, 1]))`

could anybody show me how to  translate this code to javacc .",2,1,False,self,,,,,
21,tensorflow,t5_3alkk,2018-12-13,2018,12,13,1,a5jrqx,self.tensorflow,What is the difference between tf.nn.conv1d and tf.nn.conv2d?,https://www.reddit.com/r/tensorflow/comments/a5jrqx/what_is_the_difference_between_tfnnconv1d_and/,thisisiron,1544632726,,4,1,False,self,,,,,
22,tensorflow,t5_3alkk,2018-12-13,2018,12,13,13,a5qbm3,self.tensorflow,Single Core Performance,https://www.reddit.com/r/tensorflow/comments/a5qbm3/single_core_performance/,wrtcdevrydy,1544676855,"Through some unfortunate circumstances, my tensorflow VM is being limited to one CPU core (SMP booting issues).

What kind of performance hit should I expect if I can't figure this out when running tensorflow (2 VMs with gt 710 and gtx 1060)",0,1,False,self,,,,,
23,tensorflow,t5_3alkk,2018-12-13,2018,12,13,18,a5rza1,self.tensorflow,Another person with the 'kernel dies upon import' problem,https://www.reddit.com/r/tensorflow/comments/a5rza1/another_person_with_the_kernel_dies_upon_import/,HudPesjan,1544692852,"I am on windows 10 using Spyder and have step by step downgraded tensorflow from 1.7.* to 1.3.* where i can finally execute 'import tensorflow' without the kernel dying (most forums suggest the problem should allready be resolved by downgrading to 1.5.*). However it dies when I try to import anything from the keras library. I can't find any information on the version of TF that is needed for a certain version of Keras.
Thank you for your time.",2,1,False,self,,,,,
24,tensorflow,t5_3alkk,2018-12-14,2018,12,14,16,a62i47,self.tensorflow,CUDA version for Tensorflow 1.0.0 ?,https://www.reddit.com/r/tensorflow/comments/a62i47/cuda_version_for_tensorflow_100/,zarooricheck,1544770828,"I'm setting up my system and according to [https://www.tensorflow.org/install/source#linux](https://www.tensorflow.org/install/source#linux) , does this mean that tensorflow-gpu==1.0.0 is only compatible with CUDA 8 ?

Can we run  tensorflow-gpu==1.0.0 on CUDA 10 ?

&amp;#x200B;",6,1,False,self,,,,,
25,tensorflow,t5_3alkk,2018-12-14,2018,12,14,22,a651lp,self.tensorflow,Crack Detection Algor:,https://www.reddit.com/r/tensorflow/comments/a651lp/crack_detection_algor/,Jialongg,1544795997,"Hi all,

I have been trying to run this script:  [https://github.com/satyenrajpal/Concrete-Crack-Detection/blob/master/README.md](https://github.com/satyenrajpal/Concrete-Crack-Detection/blob/master/README.md)

However, I faced this error: ValueError: Cannot feed value of shape (64,) for Tensor 'x:0', which has shape '(?, 128, 128, 3)'

[The error log](https://i.redd.it/bgv272il19421.png)

I googled quite abit and most suggestions are to reshape the placeholder or my x\_batch y\_true\_batch. 

I tried several methods of reshaping but they simply gave me different kinds of errors.

[My attempts at reshaping the tensors or the numpy arrays](https://i.redd.it/06cieqer19421.png)

Im pretty new to tensorflow so I would really appreciate any help! Thank you in advance!!

&amp;#x200B;

I shall paste my codes below:

&amp;#x200B;

 \------------------------------------------------------------------------------------------------------------------------------------

""""""  
Code to train the model  
""""""  
import os  
import tensorflow as tf  
import numpy as np  
import time  
from datetime import timedelta  
from dataset import load\_cached  
\#from matplotlib.image import imread  
import cv2,sys,argparse  
\#Initialzing the conv and max\_pool layers  
\#####################################################  
def new\_conv\_layer(input,              # The previous layer.  
num\_input\_channels, # Num. channels in prev. layer.  
filter\_size,        # Width and height of each filter.  
num\_filters):        # Number of filters.  
 \# Shape of the filter-weights for the convolution.  
shape = \[filter\_size, filter\_size, num\_input\_channels, num\_filters\]  
 \# Create new weights aka. filters with the given shape.  
weights = tf.Variable(tf.truncated\_normal(shape, stddev=0.05))  
 \# Create new biases, one for each filter.  
biases = tf.Variable(tf.constant(0.05, shape=\[num\_filters\]))  
layer = tf.nn.conv2d(input=input,  
filter=weights,  
strides=\[1, 2, 2, 1\],  
padding='VALID')  
 \# A bias-value is added to each filter-channel.  
layer += biases  
 return layer  
\####################################################  
def max\_pool(layer,ksize,strides):  
layer = tf.nn.max\_pool(value=layer,  
ksize=ksize,  
strides = strides,  
padding = 'VALID')  
 return layer  
\####################################################  
def new\_fc\_layer(input,           # The previous layer.  
num\_inputs,      # Num. inputs from prev. layer.  
num\_outputs,     # Num. outputs  
use\_relu=True):  # Use Rectified Linear Unit (ReLU)?  
 \# Create new weights and biases.  
weights =tf.Variable(tf.truncated\_normal(\[num\_inputs, num\_outputs\], stddev=0.05))  
biases = tf.Variable(tf.constant(0.05, shape=\[num\_outputs\]))  
   
 \#Include Drop-out as well to avoid overfitting  
 \#x\_drop = tf.nn.dropout(input, keep\_prob=keep\_prob\_input)  
   
 \# Calculate the layer as the matrix multiplication of  
 \# the input and weights, and then add the bias-values.  
layer = tf.matmul(input, weights) + biases  
 \# Use ReLU?  
 if use\_relu:  
layer = tf.nn.relu(layer)  
 return layer      
\####################################################  
def flatten\_layer(layer):  
 \# Get the shape of the input layer.  
layer\_shape = layer.get\_shape()  
 \# The shape of the input layer is assumed to be:  
 \# layer\_shape == \[num\_images, img\_height, img\_width, num\_channels\]  
 \# The number of features is: img\_height \* img\_width \* num\_channels  
num\_features = layer\_shape\[1:4\].num\_elements()  
   
layer\_flat = tf.reshape(layer, \[-1, num\_features\])  
 \# The shape of the flattened layer is now:  
 \# \[num\_images, img\_height \* img\_width \* num\_channels\]  
 return layer\_flat, num\_features  
\####################################################  
   
class Model:  
 def \_\_init\_\_(self,in\_dir,save\_folder=None):  
dataset = load\_cached(cache\_path='my\_dataset\_cache.pkl', in\_dir=in\_dir)  
 self.num\_classes = dataset.num\_classes  
 \#   print(""num\_classes: "", self.num\_classes)  
image\_paths\_train, cls\_train, self.labels\_train = dataset.get\_training\_set()  
 \#   print(""img\_path\_train: "", image\_paths\_train)  
image\_paths\_test, self.cls\_test, self.labels\_test = dataset.get\_test\_set()  
 \#   print(""img\_path\_test: "", image\_paths\_test)  
   
 \##############################IMAGE PARAMETERS#####################################  
 self.img\_size = 128  
 self.num\_channels = 3  
 self.train\_batch\_size = 64  
 self.test\_batch\_size = 64  
 \###################################################################################  
   
 self.x = tf.placeholder(tf.float32, shape=\[None, self.img\_size,self.img\_size,self.num\_channels\], name='x')  
 self.x\_image = tf.reshape(self.x, \[-1, self.img\_size, self.img\_size, self.num\_channels\])  
 self.y\_true = tf.placeholder(tf.float32, shape=\[None, self.num\_classes\], name='y\_true')  
 self.y\_true\_cls = tf.argmax(self.y\_true, axis=1) #The True class Value  
 self.keep\_prob = tf.placeholder(tf.float32)  
 self.keep\_prob\_2 = tf.placeholder(tf.float32)  
 self.y\_pred\_cls = None  
 self.train\_images= self.load\_images(image\_paths\_train)  
 self.test\_images= self.load\_images(image\_paths\_test)  
 self.save\_folder=save\_folder  
 self.optimizer,self.accuracy = self.define\_model()          


def load\_images(self,image\_paths):  
 \# Load the images from disk.  
images = \[cv2.imread(path,1) for path in image\_paths\]  
   
 \# print(""image\_paths :"", image\_paths)  
 \# images = \[\]  
 \# for img in os.listdir(image\_paths):  
 \#     img\_path = os.path.join(img, image\_paths)  
 \#     image = cv2.imread(img\_path, 1)  
 \#     images.append(image)  
   
 \# Convert to a numpy array and return it in the form of \[num\_images,size,size,channel\]  
 \#print(np.asarray(images\[0\]).shape)  
 return np.asarray(images)  
   
 def define\_model(self):  
 \#Convolution Layer 1  
filter\_size1 = 10 # Convolution filters are 10 x 10   
num\_filters1 = 24 # There are 24 of these filters.  
 \# Convolutional Layer 2  
filter\_size2 = 7 # Convolution filters are 7 x 7   
num\_filters2 = 48 # There are 48 of these filters.  
   
 \# Convolutional Layer 3  
filter\_size3 = 11 # Convolution filters are 11 x 11   
num\_filters3 = 96 # There are 96 of these filters.  
 \# Fully-connected layer  
fc\_size = 96   
   
layer\_conv1 = new\_conv\_layer(input=self.x\_image,  
num\_input\_channels=self.num\_channels,  
filter\_size=filter\_size1,  
num\_filters=num\_filters1)  
 \#Max Pool Layer  
ksize1 = \[1,4,4,1\]  
strides1 = \[1,2,2,1\]  
layer\_max\_pool1 = max\_pool(layer\_conv1,ksize1,strides1)  
   
 \#Convolutional Layer 2  
layer\_conv2 = new\_conv\_layer(input=layer\_max\_pool1,  
num\_input\_channels=num\_filters1,  
filter\_size=filter\_size2,  
num\_filters=num\_filters2)  
 \#Max Pool Layer  
ksize2 = \[1,2,2,1\]  
strides2 = \[1,1,1,1\]  
layer\_max\_pool2 = max\_pool(layer\_conv2,ksize2,strides2)  
   
 \#Convolutional Layer 3  
layer\_conv3 = new\_conv\_layer(input=layer\_max\_pool2,  
num\_input\_channels=num\_filters2,  
filter\_size=filter\_size3,  
num\_filters=num\_filters3)  
 \#Flatten  
layer\_flat, num\_features = flatten\_layer(layer\_conv3)  
 \#Relu Layer  
layer\_relu = tf.nn.relu(layer\_flat)  
 \#Fully-Connected Layer1  
layer\_fc1 = new\_fc\_layer(input=layer\_relu,  
num\_inputs=num\_features,  
num\_outputs=fc\_size,  
use\_relu=True)  
   
 \#Fully-Connected Layer2  
layer\_fc2 = new\_fc\_layer(input=layer\_fc1,  
num\_inputs=fc\_size,  
num\_outputs=self.num\_classes,  
use\_relu=False)  
 \#Predict the class  
y\_pred = tf.nn.softmax(layer\_fc2)  
 self.y\_pred\_cls = tf.argmax(y\_pred, dimension=1,name=""predictions"")  
   
 \#Cost Function  
cross\_entropy = tf.nn.softmax\_cross\_entropy\_with\_logits(logits=layer\_fc2, labels=self.y\_true)  
cost = tf.reduce\_mean(cross\_entropy)  
optimizer = tf.train.AdamOptimizer(learning\_rate=1e-4).minimize(cost)  
 \#Predict  
correct\_prediction = tf.equal(self.y\_pred\_cls, self.y\_true\_cls)  
accuracy = tf.reduce\_mean(tf.cast(correct\_prediction, tf.float32))  
 return optimizer, accuracy  
   
 def random\_batch(self):  
 \# Number of images in the training-set.  
num\_images = len(self.train\_images)  
   
 \# Create a random index.  
idx = np.random.choice(num\_images,  
size=self.train\_batch\_size,  
replace=False)  
   
 \# Use the random index to select random x and y-values.  
x\_batch = self.train\_images\[idx\]  
y\_batch = self.labels\_train\[idx\]  
 return x\_batch, y\_batch  
   
 def print\_test\_accuracy(self,sess):  
   
 \# Number of images in the test-set.  
num\_test = len(self.test\_images)  
   
 \# Allocate an array for the predicted classes which  
 \# will be calculated in batches and filled into this array.  
cls\_pred = np.zeros(shape=num\_test, dtype=np.int)  
   
i = 0  
   
 while i &lt; num\_test:  
 \# The ending index for the next batch is denoted j.  
j = min(i + self.test\_batch\_size, num\_test)  
   
images = self.test\_images\[i:j\]  
   
labels = self.labels\_test\[i:j\]  
   
 \# Create a feed-dict with these images and labels.  
feed\_dict = {self.x: images,  
 self.y\_true: labels,  
 self.keep\_prob: 1,  
 self.keep\_prob: 1}  
cls\_pred\[i:j\] = sess.run(self.y\_pred\_cls, feed\_dict=feed\_dict)  
   
 \# Set the start-index for the next batch to the  
 \# end-index of the current batch.  
i = j  
   
 \# Create a boolean array whether each image is correctly classified.  
correct = (self.cls\_test == cls\_pred)  
   
 \# Classification accuracy is the number of correctly classified  
 \# images divided by the total number of images in the test-set.  
acc = float(correct.sum()) / num\_test  
   
 \# Print the accuracy.  
msg = ""Accuracy on Test-Set: {0:.1%} ({1} / {2})""  
 \#   print(msg.format(acc, correct.sum(), num\_test))  
   
 def optimize(self, num\_iterations):  
 \# Ensure we update the global variable rather than a local copy.  
 global total\_iterations  
total\_iterations = 0  
saver = tf.train.Saver()  
 \# Start-time used for printing time-usage below.  
start\_time = time.time()  
 with tf.Session() as sess:  
 \#global\_step\_int = tf.train.get\_global\_step(sess.graph)  
sess.run(tf.global\_variables\_initializer())  
   
 for i in range(total\_iterations,  
total\_iterations + num\_iterations):  
   
 \# Get a batch of training examples.  
 \# x\_batch now holds a batch of images and  
 \# y\_true\_batch are the true labels for those images.  
   
x\_batch, y\_true\_batch = self.random\_batch()  
   
print(""Debugger: x\_batch Length "", len(x\_batch))  
print(""Debugger: x\_batch Type "", type(x\_batch))  
print(""Debugger: y\_true\_batch Length "", len(y\_true\_batch))  
print(""Debugger: y\_true\_batch Type "", type(y\_true\_batch))  
print(""Debugger: self.x shape:"", self.x.shape)  
print(""Debugger: self.y\_true shape:"", self.y\_true.shape)  
print(""Debugger: self.train\_images\[0\]:"", self.train\_images)  
print(""Debugger: self.load\_images\[0\]:"", self.load\_images)  
print(""Debugger: self.x rank:"", tf.rank(self.x))  
\#               x\_batch = np.swapaxes(x\_batch, 1, 0)  
\#               y\_true\_batch = np.swapaxes(y\_true\_batch, 1, 0)  
\#                x\_batch = x\_batch.reshape(128,128,3)            #self added ###  
\#                y\_true\_batch = y\_true\_batch.reshape(128,128,3)   #self added ###  
\#                x\_batch = \[d.reshape(128,128,3) for d in self.train\_images\]            #self added ###  
\#                y\_true\_batch = \[d.reshape(128,128,3) for d in self.labels\_train\]   #self added ###  
\#                self.x=tf.placeholder(tf.float32,\[64,None\])  
\#                self.y\_true=tf.placeholder(tf.float32,\[64,None\])  
\#                feed\_dict\_train = {self.x: np.expand\_dims(x\_batch,axis=0),  
 \#                                 self.y\_true: np.expand\_dims(y\_true\_batch,axis=0)}  
feed\_dict\_train = {self.x: x\_batch,  
 self.y\_true: y\_true\_batch}  
 \#self.keep\_prob: 0.5,  
 \#self.keep\_prob: 0.5}  
   
sess.run(\[self.optimizer\], feed\_dict=feed\_dict\_train)  
   
 \# Print status every 100 iterations.  
 if i % 100 == 0:  
 \# Calculate the accuracy on the training-set.  
feed\_dict\_acc = {self.x: x\_batch,  
 self.y\_true: y\_true\_batch}  
 \#self.keep\_prob: 1,  
 \#self.keep\_prob: 1}  
acc = sess.run(self.accuracy, feed\_dict=feed\_dict\_acc)  
   
 \# Message for printing.  
msg = ""Optimization Iteration: {0:&gt;6}, Training Accuracy: {1:&gt;6.1%}""  
   
 \# Print it.  
 \#       print(msg.format(i + 1, acc))  
   
 \# Update the total number of iterations performed.  
total\_iterations += num\_iterations  
   
 \# Ending time.  
end\_time = time.time()  
 if i%100 ==0:  
 \#Calculate the accuracy on the test set every 100 iterations  
 self.print\_test\_accuracy(sess)  
   
 if i%500 == 0:  
 \#Saves every 500 iterations  
saver.save(sess, os.path.join(self.save\_folder,'model')) #Change this according to your convenience  
   
 \# Difference between start and end-times.  
time\_dif = end\_time - start\_time  
 self.print\_test\_accuracy(sess)  
 \# Print the time-usage.  
 \#    print(""Time usage: "" + str(timedelta(seconds=int(round(time\_dif)))))  
saver.save(sess, os.path.join(self.save\_folder,'model\_complete'))  
   
def parse\_arguments():  
parser = argparse.ArgumentParser(description='Training Network')  
parser.add\_argument('--in\_dir',dest='in\_dir',type=str,default='cracky')  
parser.add\_argument('--iter',dest='num\_iterations',type=int,default=1500)  
parser.add\_argument('--save\_folder',dest='save\_folder',type=str,default=os.getcwd())  
 return parser.parse\_args()  
   
def  main(args):  
args=parse\_arguments()  
num\_iterations = args.num\_iterations  
 \#print(""in\_dir: "", args.in\_dir)  
   
model = Model(args.in\_dir,args.save\_folder)  
model.optimize(num\_iterations)  
   
if \_\_name\_\_ == '\_\_main\_\_':  
main(sys.argv)  


&amp;#x200B;",1,1,False,https://b.thumbs.redditmedia.com/_I75kkEUYxAwojNtJ7WigAvF28I3BekrryspDa17JKU.jpg,,,,,
26,tensorflow,t5_3alkk,2018-12-15,2018,12,15,3,a67pv5,github.com,"Using TensorFlow with C API on Windows, Linux and macOS without pain",https://www.reddit.com/r/tensorflow/comments/a67pv5/using_tensorflow_with_c_api_on_windows_linux_and/,Neargye,1544813907,,4,1,False,default,,,,,
27,tensorflow,t5_3alkk,2018-12-16,2018,12,16,7,a6jeu8,self.tensorflow,How to submit my person MNIST-like image to TensorFlow? I trained on the MNIST dataset and would like to try my own handwritten digit on the neural network. Having problems with the format of the image data in TensorFlow :(,https://www.reddit.com/r/tensorflow/comments/a6jeu8/how_to_submit_my_person_mnistlike_image_to/,cudaeducation,1544911842,"I know that you can train your TensorFlow network on the part of the MNIST data, then test it on another part of the MNIST data.  That's wonderful!  But what about trying to submit an image of your own handwritten digit to the TensorFlow neural network and see if it can ""read"" the number correctly?!?!

&amp;#x200B;

Please tell me that I'm not the only person on planet earth who has thought of doing this!  It really is a simple matter, but I'm having all kinds of grief getting TensorFlow to read my image properly and have the pixel data etc. arranged in a way that gels with what you would expect from an MNIST image.

&amp;#x200B;

I sincerely hope I'm not the only person that has tried to do this.",2,1,False,self,,,,,
28,tensorflow,t5_3alkk,2018-12-16,2018,12,16,10,a6ksrk,youtube.com,"For me, one of the main barriers to the world of deep learning was setting up all the tools. Here's a video that I hope will eliminate this barrier for anyone reading this. Hope you guys found it helpful!",https://www.reddit.com/r/tensorflow/comments/a6ksrk/for_me_one_of_the_main_barriers_to_the_world_of/,antaloaalonso,1544922437,,2,1,False,https://b.thumbs.redditmedia.com/vwun5p_gPdiCEPyrR83GlPnAufX3LusqRzYQUUkqIHA.jpg,,,,,
29,tensorflow,t5_3alkk,2018-12-17,2018,12,17,4,a6rtud,self.tensorflow,Any updates on PyMC4 and the usage with tensorflow_probability?,https://www.reddit.com/r/tensorflow/comments/a6rtud/any_updates_on_pymc4_and_the_usage_with/,o-rka,1544987438,I havent seen anyone on PyMC4 since the development from the Google Summer of Code with the schools dataset example.  Is there any updates on the API? Does anyone know if there will be a functional approach like Keras? ,0,1,False,self,,,,,
30,tensorflow,t5_3alkk,2018-12-17,2018,12,17,16,a6xun8,self.tensorflow,Link for the ssd_mobilenetv2_oidv4 model? The one on github is broken.,https://www.reddit.com/r/tensorflow/comments/a6xun8/link_for_the_ssd_mobilenetv2_oidv4_model_the_one/,niankaki,1545033484,"I want to try out the Open Images-trained models, specifically the ssd_mobilenetv2_oidv4 model from [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#open-images-trained-models). But the clicking the link tells me that I dont have storage access.  
Anybody have a proper link?",0,1,False,self,,,,,
31,tensorflow,t5_3alkk,2018-12-17,2018,12,17,18,a6ydsr,self.tensorflow,Should I set the filter configurations in tf.conv2d() ?,https://www.reddit.com/r/tensorflow/comments/a6ydsr/should_i_set_the_filter_configurations_in_tfconv2d/,Laurence-Lin,1545039447,"I've seen many applied conv2d function as below:  


tf.conv2d(input\_tensor, weights, ...)  


In the document, the second term is filter, but I usually see others set weight for this term.  


Shouldn't I set the filters? I'm confused about it.   


Thanks a lot!",4,1,False,self,,,,,
32,tensorflow,t5_3alkk,2018-12-18,2018,12,18,20,a7a6at,self.tensorflow,Is using the class_weight attribute in Keras with the binaey_cross_entropy loss function the same as using a weighted binary_cross_entropy loss function?,https://www.reddit.com/r/tensorflow/comments/a7a6at/is_using_the_class_weight_attribute_in_keras_with/,justAHairyMeatBag,1545131620,"I have a multi-class multi-label problem where each sample could have multiple true labels. I'm using a sigmoid activation function at the output layer, and I'm using the binary cross entropy loss function. I'd like to weight my classes due to the heavy imbalance in the frequency of occurrence of labels.


I noticed that Keras has a 'class_weight' attribute that you can specify in the model.fit_generator() method. According to the docs, it **can be useful to tell the model to pay more attention to samples from an under-represented class.** This sounds like what I want to do. I was wondering if there's a difference between using 'class_weights + binary_cross_entropy loss' and using the weighted binary cross entropy loss defined [here](https://stats.stackexchange.com/questions/303229/why-does-keras-binary-crossentropy-loss-function-return-wrong-values/303254)?",1,1,False,self,,,,,
33,tensorflow,t5_3alkk,2018-12-18,2018,12,18,23,a7bqrw,self.tensorflow,Keras uses class_weight attribute only for training loss and not validation loss calculation. Is there a workaround?,https://www.reddit.com/r/tensorflow/comments/a7bqrw/keras_uses_class_weight_attribute_only_for/,justAHairyMeatBag,1545145012,"I'm using the class_weight attribute of the fit_generator in Keras for my unbalanced dataset. While this is reflected clearly in my training loss, validation loss appears to be unaffected. Where before, both losses of my model were in the same neighborhood, upon using class_weights, validation loss is a 1000 times larger than my training loss.


Is there a way around this?


I've found [this](https://github.com/keras-team/keras/issues/496) and [this](https://github.com/keras-team/keras/issues/4137) stale issues on Keras' github repo.


[This](https://datascience.stackexchange.com/questions/22814/class-weighting-during-validation-in-keras) appears to be a solution, but it's using sample_weights, a different attribute that is meant to be used [per sample](https://stackoverflow.com/questions/43459317/keras-class-weight-vs-sample-weights-in-the-fit-generator).


Then there's the option to pass sample_weights as a tuple in the validation_data parameter of fit_generator, but does this mean I have to make a new weights vector each time or does it just make sense to treat sampls_weights as being the same for all samples?",0,1,False,self,,,,,
34,tensorflow,t5_3alkk,2018-12-19,2018,12,19,11,a7hw0p,self.tensorflow,Installing tensorflow with pip3 win10,https://www.reddit.com/r/tensorflow/comments/a7hw0p/installing_tensorflow_with_pip3_win10/,raitonnin,1545184904,"Could not find a version that satisfies the requirement tensorflow (from versions: )
No matching distribution found for tensorflow
I tried googling for an answer but i didnt find anything conclusive at all nothing helped. Does anyone know why im not able to ""find the download""",2,1,False,self,,,,,
35,tensorflow,t5_3alkk,2018-12-19,2018,12,19,12,a7ik2s,self.tensorflow,TF on Win10 with AMD GPU,https://www.reddit.com/r/tensorflow/comments/a7ik2s/tf_on_win10_with_amd_gpu/,chrninja,1545189803,"Hello Tensorflow community! I have an AMD RX580 and would be interested in using it for computations in Tensorflow. I know that only CUDA is officially supported but I have seen solutions with OpenCL and ROCm but I am rather new in Programming so I would appreciate if someone could link me to a guide. I have seen the stackoverflow question about Keras and Tensorflow. 

Thank you in advance!!",6,1,False,self,,,,,
36,tensorflow,t5_3alkk,2018-12-19,2018,12,19,14,a7jd0e,self.tensorflow,Does anyone know how to create a TFRecord file using C++?,https://www.reddit.com/r/tensorflow/comments/a7jd0e/does_anyone_know_how_to_create_a_tfrecord_file/,krishnab75,1545196279,"I have been scouring the internet, Stack Exchange, IRC, and Github trying to find an example of someone writing some C++ code to write data to a TFRecord file. I was hoping to use C++ because I do a lot of image processing in C++ using OpenCV and switching to Python for the last step seems a bit cumbersome. 

&amp;#x200B;

I can write TFRecords files from Python no problem. The advanced is that TF has some helper functions in TF.train that let you encode int64 or Byteslists, etc. But I have found no mention of anyone doing this in C++. 

&amp;#x200B;

If anyone has any suggestions or code samples, or links to code samples, that would really be  appreciated. Thanks. ",2,1,False,self,,,,,
37,tensorflow,t5_3alkk,2018-12-19,2018,12,19,18,a7l1w1,self.tensorflow,"In tf.reshape(), if I set the dimension value after reshape as -1, does it means that I don't specify it?",https://www.reddit.com/r/tensorflow/comments/a7l1w1/in_tfreshape_if_i_set_the_dimension_value_after/,Laurence-Lin,1545213204,"I've seen a code do this:

x = tf.placeholder()  
x\_1 = tf.reshape(x, \[-1, 28, 28, 1\])  


For an 4D image, the shape stands for \[batch size, height, width, channels\]. Here since batchsize = -1, does it means that I don't specify it previously?

Thanks.  
",5,1,False,self,,,,,
38,tensorflow,t5_3alkk,2018-12-21,2018,12,21,5,a82csw,self.tensorflow,Can the XLA AoT compiler generate GPU accelerated code?,https://www.reddit.com/r/tensorflow/comments/a82csw/can_the_xla_aot_compiler_generate_gpu_accelerated/,_llucid_,1545339283,"I want to do some real-time computer vision workloads off a windows (or linux) desktop with an Nvidia GPU.

I'll be running it via C++ for low-latency deployment, and I'm wondering if I should just use the C++ API or go through the XLA compiler for a performance boost.

The dev summit presentation mentioned the AoT was for mobile deployment, and only generated x86/ARM binaries and C++ interface. Does that mean if I compile with a cuda-enabled windows target, I won't get any GPU acceleration?

&amp;#x200B;",0,1,False,self,,,,,
39,tensorflow,t5_3alkk,2018-12-21,2018,12,21,12,a85v40,self.tensorflow,"eval_metric_ops in tf.estimator.EvalSpec does not work properly, or I'm missing something.",https://www.reddit.com/r/tensorflow/comments/a85v40/eval_metric_ops_in_tfestimatorevalspec_does_not/,dchatterjee172,1545362745,"@reedwm  @jmaye 

\`if mode == tf.estimator.ModeKeys.EVAL:\`

\`            a = tf.random.uniform(dtype=tf.int32, maxval=1000, shape=\[\])\`

\`            eval\_metric\_ops = {\`

 \`               ""eval\_mean\_bert\_loss"": tf.metrics.mean(total\_loss\_bert),\`

\`                ""eval\_mean\_original\_loss"": tf.metrics.mean(total\_loss\_original),\`

\`                ""eval\_mean\_loss"": tf.metrics.mean(a)}\`

\`            output\_spec = tf.estimator.EstimatorSpec(\`

\`                mode=mode,\`

\`                loss=a,\`

\`                eval\_metric\_ops=eval\_metric\_ops)\`       



\`eval\_spec = tf.estimator.EvalSpec(input\_fn=eval\_input\_fn, steps=100, start\_delay\_secs=0,

throttle\_secs=120)\`

&amp;#x200B;

\[output\]([https://imgur.com/a/lT92UoU](https://imgur.com/a/lT92UoU))       

\`INFO:tensorflow:Saving dict for global step 2000: eval\_mean\_bert\_loss = 4.9399266, eval\_mean\_loss = 483.38, eval\_mean\_original\_loss = 4.982164, global\_step = 2000, loss = 483.38

\`

how can \`loss\` and \`eval\_mean\_loss\` be exactly same? batch size is 1 here. Shouldn't \`loss\` be the value of \`a\` at 100th batch, and \`eval\_mean\_loss\` be the mean of the all 100 \`a\` ?

&amp;#x200B;

&amp;#x200B;",4,1,False,self,,,,,
40,tensorflow,t5_3alkk,2018-12-21,2018,12,21,21,a89kva,self.tensorflow,I can't import tensorflow on jupyternotebook,https://www.reddit.com/r/tensorflow/comments/a89kva/i_cant_import_tensorflow_on_jupyternotebook/,Laurence-Lin,1545395877,"When I import tensorflow library it returns ""there are no tensorflow modules in the package""  
I've check online for helps, but most of it refers to using ananconda to install tensorflow??? 

If it's not necessary, I prefer not using ananconda, since I have python already. Does anyone know how to build tensorflow environment on jupyter notebook?  


Thanks a lot!  
",11,1,False,self,,,,,
41,tensorflow,t5_3alkk,2018-12-22,2018,12,22,4,a8df00,self.tensorflow,"How I solved my infinite ""Solving environment"" on windows (Anaconda)",https://www.reddit.com/r/tensorflow/comments/a8df00/how_i_solved_my_infinite_solving_environment_on/,Chrupiter,1545420180,"I'm writing this because maybe someone will find it useful. Yesterday I wanted to install tensorflow on Win7-64bit through Anaconda prompt. I had just installed the latest version of Anaconda, with py3.7. So I executed  

    conda install -c conda-forge tensorflow

and waited for ""Solving environment"", and waited, and waited... After hours still nothing. So I searched online what the problem could be. Nothing I found was useful. Then I decided the create a new environment with python 3.6. And magic, I installed tensorflow with the above command without problems.

&amp;#x200B;",6,1,False,self,,,,,
42,tensorflow,t5_3alkk,2018-12-22,2018,12,22,21,a8km3j,self.tensorflow,tf.map_fn() doesn't work as expected,https://www.reddit.com/r/tensorflow/comments/a8km3j/tfmap_fn_doesnt_work_as_expected/,ImaginaryAnon,1545483345,[removed],0,1,False,self,,,,,
43,tensorflow,t5_3alkk,2018-12-23,2018,12,23,2,a8msae,self.tensorflow,Tensorflow not finding modules. (Windows 10),https://www.reddit.com/r/tensorflow/comments/a8msae/tensorflow_not_finding_modules_windows_10/,Tormenator1,1545500871,"Hey. I'm pretty new to TensorFlow and am trying to train my first model.  However,when I attempt to begin the training,I get the error in [this](https://imgur.com/a/3tEaTbW) screenshot. I've already manually set the path in the Windows Environment variables,and it still doesn't work,is there anything else I can do to fix this?",7,1,False,self,,,,,
44,tensorflow,t5_3alkk,2018-12-23,2018,12,23,20,a8u0z4,self.tensorflow,just have a doubt,https://www.reddit.com/r/tensorflow/comments/a8u0z4/just_have_a_doubt/,yashwatwani28,1545564765," i can't how do we have the accuracy of training data - it should always be 100% if it is their

 i can understand  how we are getting the validation accuracy that we are just checking with the result but how can we get the testing accuracy? ",1,1,False,self,,,,,
45,tensorflow,t5_3alkk,2018-12-24,2018,12,24,4,a8xngn,self.tensorflow,Problem with export_savedmodel in Tensorflow v1.12.0,https://www.reddit.com/r/tensorflow/comments/a8xngn/problem_with_export_savedmodel_in_tensorflow_v1120/,Fen007,1545594267,"A few days ago I asked a question on Stackoverflow about Tensorflow, which unfortunately has not been answered yet. Maybe someone has any ideas here ?",0,1,False,self,,,,,
46,tensorflow,t5_3alkk,2018-12-24,2018,12,24,23,a95go7,self.tensorflow,Image classification for ONE CATEGORY,https://www.reddit.com/r/tensorflow/comments/a95go7/image_classification_for_one_category/,jango1502,1545662316,"I have set of food images. I want to make a model to detect whether the given test image is of food or not!!
Test images have food images as well as random images that are not food items.  

Is this task possible or not ??

Can I make a model with food images as training images and food+random images as test set?",14,1,False,self,,,,,
47,tensorflow,t5_3alkk,2018-12-25,2018,12,25,2,a96uti,codecampanion.blogspot.com,Intro To Keras U-NET - Nuclei In Divergent Images,https://www.reddit.com/r/tensorflow/comments/a96uti/intro_to_keras_unet_nuclei_in_divergent_images/,AshishKhuraishy,1545672402,,0,1,False,default,,,,,
48,tensorflow,t5_3alkk,2018-12-26,2018,12,26,11,a9kt6k,youtube.com,How Neural Networks Work- Simply Explained,https://www.reddit.com/r/tensorflow/comments/a9kt6k/how_neural_networks_work_simply_explained/,ailearn12,1545792917,,0,1,False,https://b.thumbs.redditmedia.com/lAiMzjTyr2KqqhRGgJUVMzQdwU2_M_RzNgdeOAGU2eY.jpg,,,,,
49,tensorflow,t5_3alkk,2018-12-27,2018,12,27,3,a9r7j2,youtube.com,"This video goes over a model that predicts the number of views on a youtube video based on likes, dislikes, and subscribers. Really interesting",https://www.reddit.com/r/tensorflow/comments/a9r7j2/this_video_goes_over_a_model_that_predicts_the/,antaloaalonso,1545850501,,3,1,False,https://b.thumbs.redditmedia.com/5jjO2lkQVL7ColtqLT4ZeJoZvNLKXRVa9BgFVt-_50Y.jpg,,,,,
50,tensorflow,t5_3alkk,2018-12-27,2018,12,27,13,a9w2fy,self.tensorflow,Higher learning rate gets stuck in local minima,https://www.reddit.com/r/tensorflow/comments/a9w2fy/higher_learning_rate_gets_stuck_in_local_minima/,codythecoder,1545886394,"I'm writing a fairly basic autoencoder, but after I recently changed  the architecture I found it was outputting pure white images, sometimes after only one epoch. With a higher learning rate (0.0002 with AdamOptimizer) it would always get stuck in this local minima, but with a lower learning rate (0.00002) the learning would be successful. This seems counterintuitive to what I expect; that a higher learning rate would be less likely to get stuck in local minima, at a potential cost of accuracy, but in this case it's only the higher learning rates that get stuck.

Is this a quirk of AdamOptimizer, or would I have to link my code? Obviously I can play around with the learning rate on different datasets/output sizes, but I'd love to be able to not have to change every time I make a major modification.",2,1,False,self,,,,,
51,tensorflow,t5_3alkk,2018-12-27,2018,12,27,21,a9ywof,youtube.com,"This video goes over a model that predicts the number of views on a youtube video based on likes, dislikes, and subscribers. Really interesting and educative",https://www.reddit.com/r/tensorflow/comments/a9ywof/this_video_goes_over_a_model_that_predicts_the/,antaloaalonso,1545914356,,1,1,False,https://b.thumbs.redditmedia.com/5jjO2lkQVL7ColtqLT4ZeJoZvNLKXRVa9BgFVt-_50Y.jpg,,,,,
52,tensorflow,t5_3alkk,2018-12-28,2018,12,28,2,aa1fx7,self.tensorflow,How to loop and add Conv features in tensorflow?,https://www.reddit.com/r/tensorflow/comments/aa1fx7/how_to_loop_and_add_conv_features_in_tensorflow/,satyapk_y12uc231,1545933532,"Basically my input is of size \[BATCH, H,W,C\] and i want to pass it through T(variable) number of convolutional layers, and T can be like 5-100 (its a hyper parameter) and all the conv kernels will be back-propped. Is there a possible way to loop around this ? ",5,1,False,self,,,,,
53,tensorflow,t5_3alkk,2018-12-29,2018,12,29,15,aaj1tq,self.tensorflow,Can I train a bot to see if two characters are doing the same thing in two videos?,https://www.reddit.com/r/tensorflow/comments/aaj1tq/can_i_train_a_bot_to_see_if_two_characters_are/,palendrome298,1546066784,"One character jumps in one video 

Other character jumps in other video

Can I use tenserflow to tell if the movement of the two characters are doing the same jumping movement ?",2,1,False,self,,,,,
54,tensorflow,t5_3alkk,2018-12-29,2018,12,29,19,aak6n3,self.tensorflow,Tensorflow GPU under utilization on Windows 10,https://www.reddit.com/r/tensorflow/comments/aak6n3/tensorflow_gpu_under_utilization_on_windows_10/,davidshen84,1546078921,"Hi,

&amp;#x200B;

I have GTX 1050 mobile graphic card. I have set up my tensorflow-gpu with conda, and have managed to get my tensorflow code work using GPU.

&amp;#x200B;

In the Windows Task Manager, I found my GPU has two compute engine metric, *compute\_0* and *compute\_1*. But when I try to train my NN, I found only the *compute\_0* took the workload, and the other one was always at rest.

&amp;#x200B;

This makes me wonder if:

1. My system is set up correctly.
2. My code is set up correctly.

Honestly, I am not completely sure if *compute\_0 and* compute\_1 refer to the CUDA core computation workload. Any suggestion about CUDA set up checking and hardware verification are desired.

&amp;#x200B;

https://i.redd.it/r2uba6fsx6721.png",0,1,False,self,,,,,
55,tensorflow,t5_3alkk,2018-12-29,2018,12,29,23,aalgbp,youtube.com,"What's the best way to get into ML? Well, if you're looking to get your feet wet ASAP, you should consider learning APIs like Keras as opposed to backends like Tensorflow and Theano. Here's a good video that explains exactly what Keras is",https://www.reddit.com/r/tensorflow/comments/aalgbp/whats_the_best_way_to_get_into_ml_well_if_youre/,antaloaalonso,1546092375,,0,1,False,https://b.thumbs.redditmedia.com/VeOOWnBsA49wJCtCan9jcEGRYYS_UxVWwAmiJ07YSPM.jpg,,,,,
56,tensorflow,t5_3alkk,2018-12-30,2018,12,30,0,aam7se,self.tensorflow,Send me in the right direction?,https://www.reddit.com/r/tensorflow/comments/aam7se/send_me_in_the_right_direction/,gnapoleon,1546098678,"Hi all,

&amp;#x200B;

I've attempted to learn Tensorflow by going through the tutorial a couple of times but I got bored 1/3 of the way through. I learn by doing and the best way for me to comprehend something new is to scratch an itch and work through a real project.

&amp;#x200B;

I'd like to present to you a project idea and hopefully you can send me in the right direction and I can figure out what I need to learn (and maybe you can suggest good resources for that).

&amp;#x200B;

I'll present a postulate that might sound silly, completely preposterous and a dead end but indulge me. I have 1M email addresses  and can associate a binary behavior (has taken an action, has not taken an action) with each row. I am postulating that a system can learn from that set (I have more than 1M pieces of data but that's a start) and tell me if a given email address will exhibit this behavior.

&amp;#x200B;

I believe that email addresses do reveal a bit about the individual behind them. For example [bob.thorton@ibm.com](mailto:bob.thorton@ibm.com) for a given business (say an enterprise product company) will likely exhibit a different behavior than [bob.g.thorton@gmail.com](mailto:bob.g.thorton@gmail.com) as will [bobt94@aol.com](mailto:bobt94@aol.com) and others might be total duds such as [2kdjfskjdf@yahoo.ru](mailto:2kdjfskjdf@yahoo.ru)

&amp;#x200B;

As you can see, I postulate that the structure of the account (bob.thorton, bob.g.thorton, bob94, 2kdjfskjdf) as well as the domain name and possibly the tld or second level domain (.com, .ru, .co.uk, ...) are important to the learning.

&amp;#x200B;

So here are my questions:

1) Should the learning data-set be:

* email address | behavior (boolean)
   * \- i.e. will the system figure out by itself the structure of an email address and look at its different parts as it learns?
* account (bob.thorton) | full domain ([gmail.com](https://gmail.com)) | subdomain and tld (.com, .co.uk) | behavior (boolean)
* email address | account (bob.thorton) | full domain ([gmail.com](https://gmail.com)) | subdomain and tld (.com, .co.uk)  | behavior (boolean)

2) What general type of problem is this, what should I look into?

3) Is the general practice something like: learn on 75% of the data set, test prediction on the last 25% then adjust some kind of threshold to minimize what's important to me (false positive, false negatives?)

4) Is Tensorflow a good thing for me to look at for this type of problem? Or is this more appropriate for a system specialized in word analysis?

5) What should I look at first?

&amp;#x200B;

I hope you can help, I realize these are pretty open-ended questions but I tried to be as specific as possible.

&amp;#x200B;

Happy holidays to all.

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;",4,1,False,self,,,,,
57,tensorflow,t5_3alkk,2018-12-30,2018,12,30,19,aauszo,self.tensorflow,Should I use tf.layers or tf.keras?,https://www.reddit.com/r/tensorflow/comments/aauszo/should_i_use_tflayers_or_tfkeras/,davidshen84,1546164827,"I found [this][1] comment in the `tf.layers.Layer` code, which says this class is legacy. But all the `tf.layers.*` classes that derived from this class does not have a similar comment. I know they may not want to copy this line everywhere in the code.

I wonder if in the future the `tf.layers*` namespace will become obsolete, and it is either `tf.nn` to build everything from scratch or `tf.keras` to use the high-level API.


[1]: https://github.com/tensorflow/tensorflow/blob/a6d8ffae097d0132989ae4688d224121ec6d8f35/tensorflow/python/layers/base.py#L40",5,1,False,self,,,,,
58,tensorflow,t5_3alkk,2018-12-31,2018,12,31,4,aayp3u,self.tensorflow,The tensorflow install guide is incomplete/misleading,https://www.reddit.com/r/tensorflow/comments/aayp3u/the_tensorflow_install_guide_is/,FlipChicken,1546196898,"https://www.tensorflow.org/install/pip

This doesn't mention which version of CUDA is needed for the gpu version (It's apparently both CUDA 9 *AND* 7.7, for some reason).

Also, following the instructions somehow results in a version of PIP that thinks it's version 18 and version 8 simultaneously and complains about being out of date but won't update.

Finally, it assumes you want to create a virtual environment, but doesn't say why or how to access that environment, and I think it assumes you only want to virtually update PIP.

Could someone who's much more of an expert than I am take a look at that guide and make it less misleading?",15,1,False,self,,,,,
