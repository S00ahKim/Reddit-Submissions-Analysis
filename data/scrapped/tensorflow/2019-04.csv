,sbr,sbr_id,date,year,month,hour,day,id,domain,title,full_link,author,created,selftext,num_comments,score,over_18,thumbnail,media_provider,media_thumbnail,media_title,media_description,media_url
0,tensorflow,t5_3alkk,2019-4-1,2019,4,1,10,b7vd7r,self.tensorflow,TF2 Image Augmentation with Keras,https://www.reddit.com/r/tensorflow/comments/b7vd7r/tf2_image_augmentation_with_keras/,alew3,1554080942,"I'm training a model for image categorical classification, it is working fine and I'm using tf.data.Dataset to improve the performance of loading the images. 

I'm confused on how to do train/test image augmentation to further improve the performance of the model.

I haven't been able to figure out how to mix the Keras model.fit\_generator with a TF.data.Dataset.",4,5,False,self,,,,,
1,tensorflow,t5_3alkk,2019-4-1,2019,4,1,14,b7xqjb,self.tensorflow,A Neural Network for any Image Dataset in TensorFlow 2.0,https://www.reddit.com/r/tensorflow/comments/b7xqjb/a_neural_network_for_any_image_dataset_in/,shawnmanuel000,1554095544,"Hey guys, a few people had requested that I make a tutorial on how to upload your own images to create your own neural network images classifier so here's the YouTube tutorial video I made for that using TensorFlow 2.0  (also to save the weights after training). 

[https://www.youtube.com/watch?v=bNntsCOdFxg](https://www.youtube.com/watch?v=bNntsCOdFxg)",0,13,False,self,,,,,
2,tensorflow,t5_3alkk,2019-4-1,2019,4,1,16,b7yxkl,self.tensorflow,9 Things You Should Know About TensorFlow,https://www.reddit.com/r/tensorflow/comments/b7yxkl/9_things_you_should_know_about_tensorflow/,Ratlifford,1554103430,[http://on.geeklearn.net/6b44d9c382](http://on.geeklearn.net/6b44d9c382),2,6,False,self,,,,,
3,tensorflow,t5_3alkk,2019-4-1,2019,4,1,20,b816kw,self.tensorflow,"TensorFlow is dead, long live TensorFlow!",https://www.reddit.com/r/tensorflow/comments/b816kw/tensorflow_is_dead_long_live_tensorflow/,AndyMerskinon,1554118914,[http://on.geeklearn.net/c80d7d9620](http://on.geeklearn.net/c80d7d9620),0,0,False,self,,,,,
4,tensorflow,t5_3alkk,2019-4-1,2019,4,1,20,b817iq,self.tensorflow,Introducing TensorFlow 2.0,https://www.reddit.com/r/tensorflow/comments/b817iq/introducing_tensorflow_20/,Newsomome,1554119070,[https://www.youtube.com/watch?v=QVumdZ6bZa0](https://www.youtube.com/watch?v=QVumdZ6bZa0),0,0,False,self,,,,,
5,tensorflow,t5_3alkk,2019-4-2,2019,4,2,2,b85tsp,nextplatform.com,AI Chip Startup Inches Forward with $800 Million in Series A,https://www.reddit.com/r/tensorflow/comments/b85tsp/ai_chip_startup_inches_forward_with_800_million/,KeponeFactory,1554140865,,3,12,False,https://b.thumbs.redditmedia.com/AQk2y6Q7Lf2id3siseSLIJCfnuQoUq4C_dM89BWBMUI.jpg,,,,,
6,tensorflow,t5_3alkk,2019-4-2,2019,4,2,17,b8gng0,self.tensorflow,How to check the data in the iterator?,https://www.reddit.com/r/tensorflow/comments/b8gng0/how_to_check_the_data_in_the_iterator/,Laurence-Lin,1554195230,"I've use an iterator for the training dataset, but now my training accuracy for each epoch remains zero, so I would like to check if the data is correctly get from the iterator. While I'm using:  

training\_batch = iterator.get\_next()

I get a tuple of tensor representing a single batch of dataset. How could I check the element in the 'training\_batch', such like print the size or show a single image sample in it?  


Thanks a lot!",2,1,False,self,,,,,
7,tensorflow,t5_3alkk,2019-4-3,2019,4,3,5,b8ocnh,self.tensorflow,CNN having dimension problems,https://www.reddit.com/r/tensorflow/comments/b8ocnh/cnn_having_dimension_problems/,916swift,1554236362,"I was able to create and compile a basic CNN model, however whenever I try to pass in the training data, I get the following error:

 ValueError: Error when checking input: expected input\_1 to have 4 dimensions, but got array with shape (3475, 256, 256)     

&amp;#x200B;

&amp;#x200B;

Currently I expanded the dimensions with numpy as shown below, although it didnt seem to work:

TrX = np.expand\_dims(Train\_X, 3)

TeX = np.expand\_dims(Test\_X, 3)

&amp;#x200B;

&amp;#x200B;

Also within the definition for the model, I have the input as follows:

inputs = tf.keras.layers.Input(shape = params\[""input\_shape""\])

&amp;#x200B;

""input shape"" in parameters is as follows:

""input\_shape"": (256,256,1)

&amp;#x200B;

Any advice on how to resolve the error is greatly appreciated 

&amp;#x200B;",9,6,False,self,,,,,
8,tensorflow,t5_3alkk,2019-4-3,2019,4,3,16,b8utg9,self.tensorflow,How to determine the amount of RAM required to load a tensorflow model?,https://www.reddit.com/r/tensorflow/comments/b8utg9/how_to_determine_the_amount_of_ram_required_to/,cant-find-user-name,1554276036,"Hi all,

I would like to determine the amount of RAM required to load a model and get predictions. The use case is that I have a VM instance and I'd like to load my tf models into it and expose API calls for others to get predictions. So to knowing if enough RAM is left in the machine, I'd need to know how much RAM my model needs. 

Please let me know if there is a programmatic way or any other way to do that. 

Thanks in advance :) ",3,2,False,self,,,,,
9,tensorflow,t5_3alkk,2019-4-4,2019,4,4,0,b8z9t5,self.tensorflow,Need some help creating a custom layer in TF2.0,https://www.reddit.com/r/tensorflow/comments/b8z9t5/need_some_help_creating_a_custom_layer_in_tf20/,Jehovacoin,1554304660,"I'm trying to implement a simple capsnet model in TF2.0, but I'm not very experienced with TF at all. So far, I have added a few conv2d layers, and a reshape layer, but I need to add a squash function now. The issue is that tf.norm() will send me to NaN land since I'm squashing entire vectors, so I have to use a custom squash function. 

Since I am doing this all inside of a keras.models.Sequential model, I wasn't sure how to get the output after the first couple of layers so I just decided to make the squash function its own layer in the model. It looks like this right now:

    class SquashLayer(tf.keras.layers.Layer):
	    def __init__(self, output_units):
		    super(SquashLayer, self).__init__()
		    self.output_units = output_units

	    def build(self, input_shape):
		    self.kernel = self.add_variable(
			  'kernel', [input_shape[-1], self.output_units])

	    def call(self, input):
		    squared_norm = tf.reduce_sum(tf.square(input), axis=-1, keepdims=True)
		    safe_norm = tf.sqrt(squared_norm + 1e-7)
		    squash_factor = squared_norm / (1. + squared_norm)
		    unit_vector = input / safe_norm
		    return squash_factor * unit_vector

Then I just pass it into my model like this:

    model = keras.models.Sequential([
	keras.layers.InputLayer(input_shape=(28, 28, 1)),
	keras.layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation=tf.nn.relu, name='conv1'),
	keras.layers.Conv2D(filters=256, kernel_size=9, strides=2, padding='valid', activation=tf.nn.relu, name='conv2'),
	keras.layers.Reshape((-1, caps1_n_caps, caps1_n_dims)),
	SquashLayer()
	])

I feel like this is probably completely and totally wrong, so I'm looking for some input on the best way to go about this. Should I be using a keras.Model for this at all, or should I use the new eager execution feature to just pass the tensors through the layers manually? If it's okay to use the SquashLayer() that I have implemented, then what do I pass through as an argument so that I get the proper output to pass into the next layer?",1,2,False,self,,,,,
10,tensorflow,t5_3alkk,2019-4-4,2019,4,4,5,b92y0k,pgaleone.eu,How does tf.function work? Weird behaviors and bad performance analysis,https://www.reddit.com/r/tensorflow/comments/b92y0k/how_does_tffunction_work_weird_behaviors_and_bad/,pgaleone,1554321853,,0,1,False,default,,,,,
11,tensorflow,t5_3alkk,2019-4-4,2019,4,4,6,b945n9,self.tensorflow,Train model with all data or just the newest data ?,https://www.reddit.com/r/tensorflow/comments/b945n9/train_model_with_all_data_or_just_the_newest_data/,TheCur,1554327794,"Hi Guys,

I'm building a neural network to play connect 4 using reinforcement learning. At the moment after every game  that data is appended to a list which is then used to train the model using model.fit in tflearn. After every game appending to this list, as a result this lost gets big over time and I'm passing in this whole list every time to model.fit(). As hundreds of games are played this lost gets big very quickly as a result slowing down the training process. 

My question is , do I have to pass in all training data every time to model.fit () or can I just use the newest data that it hasn't been trained on yet ? Thanks in advance ",4,1,False,self,,,,,
12,tensorflow,t5_3alkk,2019-4-4,2019,4,4,8,b950yo,self.tensorflow,"Has anyone ran TensorFlow on a raspberry pi 0? I have a trained model but am having a hard time getting TensorFlow onto the pi, thank in advance for the advice!",https://www.reddit.com/r/tensorflow/comments/b950yo/has_anyone_ran_tensorflow_on_a_raspberry_pi_0_i/,e10101010,1554332441,,4,6,False,self,,,,,
13,tensorflow,t5_3alkk,2019-4-4,2019,4,4,13,b98368,self.tensorflow,Can you run tensorflow on python in anaconda?,https://www.reddit.com/r/tensorflow/comments/b98368/can_you_run_tensorflow_on_python_in_anaconda/,tropicalpersonality,1554351187,"Im writing a python program and am looking to call and run a tensorflow model that looks at a given image file at a certain time returning a percentage match. If so, how? 


I used this tutorial to set up my tensorflow model

https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10",4,0,False,self,,,,,
14,tensorflow,t5_3alkk,2019-4-4,2019,4,4,13,b98crk,self.tensorflow,How to Image Classification with TensorFlow 2.0?,https://www.reddit.com/r/tensorflow/comments/b98crk/how_to_image_classification_with_tensorflow_20/,Barbara9119,1554353058,[http://dev.edupioneer.net/b20f57989d](http://dev.edupioneer.net/b20f57989d),0,2,False,self,,,,,
15,tensorflow,t5_3alkk,2019-4-4,2019,4,4,14,b98la0,self.tensorflow,YARN infrastructure or move to Cloud,https://www.reddit.com/r/tensorflow/comments/b98la0/yarn_infrastructure_or_move_to_cloud/,_spicyramen,1554354727,"My current company invested in Hadoop clusters and now we want to experiment in Machine Learning and Deep Learning, any recommendations to get started? I have heard a lot of KubeFlow but not sure if it makes sense in a Hadoop environment",0,1,False,self,,,,,
16,tensorflow,t5_3alkk,2019-4-4,2019,4,4,20,b9bnvx,self.tensorflow,Why is this code slowing down so much?,https://www.reddit.com/r/tensorflow/comments/b9bnvx/why_is_this_code_slowing_down_so_much/,grappling_hook,1554378376,"I'm trying to implement Polyak averaging for a soft actor-critic RL model. This requires me to do a weighted average of the weights of two networks. I've noticed that these lines of code get progressively slower and slower as training progresses. Since this code is run very frequently (for each action), it's slowing down training time massively. Any idea why this is going on, and how I can fix it? I thought that perhaps there are new variables being added to the session so maybe lookup is taking longer because of that, but it seems like the number of variables stays constant. 

    target_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='target_value_network')
    value_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='value_network')
    sess.run([v_t.assign(v_t * (1. - soft_tau) + v * soft_tau) for v_t, v in zip(target_params, value_params)])

&amp;#x200B;",7,2,False,self,,,,,
17,tensorflow,t5_3alkk,2019-4-5,2019,4,5,1,b9ergc,self.tensorflow,I built tensorflow.,https://www.reddit.com/r/tensorflow/comments/b9ergc/i_built_tensorflow/,earee,1554394489," ***That took longer then I expected.***

Target //tensorflow/tools/pip\_package:build\_pip\_package up-to-date:  
 bazel-bin/tensorflow/tools/pip\_package/build\_pip\_package  
INFO: Elapsed time: 73182.034s, Critical Path: 1047.75s  
INFO: 12163 processes: 12163 local.  
INFO: Build completed successfully, 12997 total actions

***(73182secs/60secs)/60mins =20.32 hours..***

***I had estimated it at 24 hours but still the longest build I have ever witnessed.***

***I wonder if it works....***

root@c0d1f21f53c9:\~# python -c ""import tensorflow as tf; print(tf.\_\_version\_\_)""  
1.13.1  
root@c0d1f21f53c9:\~#

***It works!... but I wanted version 2.0..***

root@c0d1f21f53c9:/tensorflow\_src# git status  
On branch master  
Your branch is up-to-date with 'origin/master'.  
nothing to commit, working directory clean  
root@c0d1f21f53c9:/tensorflow\_src# git branch  
 dev  
\* master  
root@c0d1f21f53c9:/tensorflow\_src# git checkout dev  
Checking out files: 100% (3021/3021), done.  
Switched to branch 'dev'  
Your branch is up-to-date with 'origin/r2.0'.

root@c0d1f21f53c9:/tensorflow\_src# bazel build --config=opt //tensorflow/tools/pip\_package:build\_pip\_package  
Starting local Bazel server and connecting to it...

***Just wait for this to finish building..***",7,4,False,self,,,,,
18,tensorflow,t5_3alkk,2019-4-5,2019,4,5,10,b9kxdv,self.tensorflow,Question for a friend regarding building TensorFlow,https://www.reddit.com/r/tensorflow/comments/b9kxdv/question_for_a_friend_regarding_building/,SirVaksghn,1554426481,"Had a friend trying to build TensorFlow on his machine and banging his head against the wall. Told him I'd ask around and see if I could find the soln somwhere. Could you guys help him out:

**Does anyone know where he can obtain a wheel for Tensorflow 1.12.0 compiled for GPU and Python3, with minimum compute capability 3.0?**
",1,5,False,self,,,,,
19,tensorflow,t5_3alkk,2019-4-5,2019,4,5,13,b9mwfg,self.tensorflow,Introduction to Tensorflow for Java,https://www.reddit.com/r/tensorflow/comments/b9mwfg/introduction_to_tensorflow_for_java/,CoreyEnzym,1554439325,[removed],0,1,False,self,,,,,
20,tensorflow,t5_3alkk,2019-4-5,2019,4,5,13,b9mx37,self.tensorflow,Introduction to Tensorflow for Java,https://www.reddit.com/r/tensorflow/comments/b9mx37/introduction_to_tensorflow_for_java/,Usama9012,1554439461,[http://on.geeklearn.net/4322c03e42](http://on.geeklearn.net/4322c03e42),3,7,False,self,,,,,
21,tensorflow,t5_3alkk,2019-4-6,2019,4,6,0,b9smu4,self.tensorflow,When do you prefer pre-made estimator to keras or lightgbm?,https://www.reddit.com/r/tensorflow/comments/b9smu4/when_do_you_prefer_premade_estimator_to_keras_or/,SubstantialSwimmer4,1554478343,"I tried to make use of pre-made estimator (DNN, BoostedTree, and wide-n-deep). But in my experience, evaluated scores are worse than the models' I made by keras or GBDT such as lightgbm. When do you choose to employ pre-made estimator?",0,1,False,self,,,,,
22,tensorflow,t5_3alkk,2019-4-6,2019,4,6,7,b9xvpm,self.tensorflow,How to tune a tensorflow linear classifier model?,https://www.reddit.com/r/tensorflow/comments/b9xvpm/how_to_tune_a_tensorflow_linear_classifier_model/,19264180,1554505079,"I'm new to tensorflow and I built a classification model using the tf linear classifier. I want to tune the model but not sure how to go about it. Have read up ray and tune but don't understand it.
Any help will be so much appreciated.",2,1,False,self,,,,,
23,tensorflow,t5_3alkk,2019-4-6,2019,4,6,9,b9z1fg,youtube.com,How Neural Networks Work- Simply Explained by a Machine Learning Engineer,https://www.reddit.com/r/tensorflow/comments/b9z1fg/how_neural_networks_work_simply_explained_by_a/,ailearn12,1554512377,,3,14,False,https://b.thumbs.redditmedia.com/lAiMzjTyr2KqqhRGgJUVMzQdwU2_M_RzNgdeOAGU2eY.jpg,,,,,
24,tensorflow,t5_3alkk,2019-4-6,2019,4,6,20,ba3api,self.tensorflow,can not import name autograph error,https://www.reddit.com/r/tensorflow/comments/ba3api/can_not_import_name_autograph_error/,cmps299mme,1554549303,"Hi, im trying to run the following code locally on a linux machine. All necessary programs were downloaded and in theory everything must run. However, we are getting the following error: ""from tensorflow.contrib import autograph""  


This is the code we are trying to run (this run on the cloud):  [https://colab.research.google.com/drive/1hSq\_D5s9FWs2MH6BNyf6cTRBXEGcYO\_D#scrollTo=kFWZi57amziK&amp;forceEdit=true&amp;offline=true&amp;sandboxMode=true](https://colab.research.google.com/drive/1hSq_D5s9FWs2MH6BNyf6cTRBXEGcYO_D#scrollTo=kFWZi57amziK&amp;forceEdit=true&amp;offline=true&amp;sandboxMode=true)   


the error occurs in:

1- Patch tranformation: (error on last line)

&gt;  for i in range(2):  
&gt;  
&gt;  print(""Test image with random transform: %s"" % (i+1))  
&gt;  
&gt;  `test_random_transform(min_scale=0.25, max_scale=2.0, max_rotation=22.5)`

  

  2- when calling metamodule():

&gt;\#@ MetaModel  
&gt;  
&gt;  
&gt;  
&gt;class MetaModel():  
&gt;  
&gt;  def \_\_init\_\_(self, verbose=True, peace\_mask=None, peace\_mask\_overlay=0.0):  
&gt;  
&gt;[self.nc](https://self.nc) = {m: ModelContainer(m, verbose=verbose, peace\_mask=peace\_mask, peace\_mask\_overlay=peace\_mask\_overlay) for m in MODEL\_NAMES}  
&gt;  
&gt;self.\_patch = np.zeros(PATCH\_SHAPE)  
&gt;  
&gt;self.patch\_shape = PATCH\_SHAPE  
&gt;  
&gt;  
&gt;  
&gt;  def patch(self, new\_patch=None):  
&gt;  
&gt;""""""Retrieve or set the adversarial patch.  
&gt;  
&gt;  
&gt;  
&gt;new\_patch: The new patch to set, or None to get current patch.  
&gt;  
&gt;  
&gt;  
&gt;Returns: Itself if it set a new patch, or the current patch.""""""  
&gt;  
&gt;if new\_patch is None:  
&gt;  
&gt;return self.\_patch  
&gt;  
&gt;  
&gt;  
&gt;self.\_patch = new\_patch  
&gt;  
&gt;return self  
&gt;  
&gt;  
&gt;  
&gt;  def reset\_patch(self):  
&gt;  
&gt;""""""Reset the adversarial patch to all zeros.""""""  
&gt;  
&gt;self.patch(np.zeros(self.patch\_shape))  
&gt;  
&gt;  
&gt;  
&gt;  def train\_step(self, model=None, steps=1, images=None, target\_ys=None, learning\_rate=5.0, scale=None, \*\*kwargs):  
&gt;  
&gt;""""""Train the model for \`steps\` steps.  
&gt;  
&gt;  
&gt;  
&gt;Args:  
&gt;  
&gt;images: A batch of images to train on, it loads one if not present.  
&gt;  
&gt;target\_ys: Onehot target vector, defaults to TARGET\_ONEHOT  
&gt;  
&gt;learning\_rate: Learning rate for this train step.  
&gt;  
&gt;scale: Either a scalar value for the exact scale, or a (min, max) tuple for the scale range.  
&gt;  
&gt;  
&gt;  
&gt;Returns: Loss on the target ys.""""""  
&gt;  
&gt;  
&gt;  
&gt;  
&gt;  
&gt;if model is not None:  
&gt;  
&gt;to\_train = \[[self.nc](https://self.nc)\[model\]\]  
&gt;  
&gt;else:  
&gt;  
&gt;to\_train = self.nc.values()  
&gt;  
&gt;  
&gt;  
&gt;losses = \[\]  
&gt;  
&gt;for mc in to\_train:  
&gt;  
&gt;mc.patch(self.patch())  
&gt;  
&gt;for i in xrange(steps):   
&gt;  
&gt;loss = mc.train\_step(images, target\_ys, learning\_rate, scale=scale, \*\*kwargs)  
&gt;  
&gt;losses.append(loss)  
&gt;  
&gt;self.patch(mc.patch())  
&gt;  
&gt;return np.mean(losses)  
&gt;  
&gt;  
&gt;  
&gt;  def inference\_batch(self, model, images=None, target\_ys=None, scale=None):  
&gt;  
&gt;""""""Report loss and label probabilities, and patched images for a batch.  
&gt;  
&gt;  
&gt;  
&gt;Args:  
&gt;  
&gt;images: A batch of images to train on, it loads if not present.  
&gt;  
&gt;target\_ys: The target\_ys for loss calculation, TARGET\_ONEHOT if not present.  
&gt;  
&gt;scale: Either a scalar value for the exact scale, or a (min, max) tuple for the scale range.  
&gt;  
&gt;""""""  
&gt;  
&gt;  
&gt;  
&gt;mc = [self.nc](https://self.nc)\[model\]  
&gt;  
&gt;mc.patch(self.patch())  
&gt;  
&gt;return mc.inference\_batch(images, target\_ys, scale=scale)  
&gt;  
&gt;  
&gt;  
&gt;print(""Creating MetaModel..."")  
&gt;  
&gt;`MM = MetaModel()`  


if you have any ideas about what is going wrong or what we should do please comment below  
Thank you in advance",0,0,False,self,,,,,
25,tensorflow,t5_3alkk,2019-4-7,2019,4,7,1,ba60ik,self.tensorflow,AttributeError: module 'tensorflow.contrib.seq2seq' has no attribute 'prepare_attention'!!,https://www.reddit.com/r/tensorflow/comments/ba60ik/attributeerror_module_tensorflowcontribseq2seq/,nsrfriends,1554567869,"Hi, I am building a chatbot , and counter with this error of seq2seq model! Can anyone let me know how to counter this issue? Well i am using Python 3.7 and Tensor-flow version 1.13.1. Please !!  ",1,2,False,self,,,,,
26,tensorflow,t5_3alkk,2019-4-7,2019,4,7,5,ba8luj,self.tensorflow,How to use Tensorboard Projector Embeddings Visualization in TF2 Keras,https://www.reddit.com/r/tensorflow/comments/ba8luj/how_to_use_tensorboard_projector_embeddings/,alew3,1554582706,"I couldn't find any documentation of how to use embeddings for projector visualization in TF2. If I try and use a embedding parameter within tf.keras.callbacks.TensorBoard

I get the message:

Embeddings will be ignored in TensorFlow 2.0 for the \`TensorBoard\` Callback.",3,1,False,self,,,,,
27,tensorflow,t5_3alkk,2019-4-7,2019,4,7,23,bah16x,self.tensorflow,[Question] about Keras model,https://www.reddit.com/r/tensorflow/comments/bah16x/question_about_keras_model/,Loutchiano,1554648930,"Hello everyone, I am trying to understand a Keras code and I need some help on a part related to models.

I am reading a GAN [code](https://github.com/eriklindernoren/Keras-GAN/blob/master/gan/gan.py) and I don't understand why the author seems to use both Sequential and Functionnal model in the build\_generator function :

`model = Sequential()`

`model.add(some_layers)`

`noise = Input(shape=(self.latent_dim,))`

`img = model(noise)`

`return Model(noise, img)`

He first create a Sequential model, adds layers, then create an Input layer ""noise"".  He passes this input into model to connect it I guess. Finally he returns what seems to be a functionnal model. 

&amp;#x200B;",2,0,False,self,,,,,
28,tensorflow,t5_3alkk,2019-4-8,2019,4,8,9,bangal,self.tensorflow,Scanning Unique Codes,https://www.reddit.com/r/tensorflow/comments/bangal/scanning_unique_codes/,Mlearly1209,1554685018,"Similar to the Coca-Cola promotion, our promotional marketing agency is looking for a developer who can develop a program using tensorflow to read unique codes found on caps. Anyone have any contacts or sources who could help our company accomplish this project?",8,2,False,self,,,,,
29,tensorflow,t5_3alkk,2019-4-8,2019,4,8,20,baseoh,self.tensorflow,2 categories or many categories?,https://www.reddit.com/r/tensorflow/comments/baseoh/2_categories_or_many_categories/,eamh4,1554721427,"Hi all, 

&amp;#x200B;

new to this sub but been learning a lot! 

&amp;#x200B;

I have trained an algorithm to detect dogs (doesnt have to decipher between breeds, just detect/confirm/deny). I trained it using two categories: dog, not dog where the latter category contained everything from anime, buildings to flowers. 

&amp;#x200B;

From your experience, would I be better off training the not dog category as one big one, or multiple small ones? 

&amp;#x200B;

Thank you! ",1,1,False,self,,,,,
30,tensorflow,t5_3alkk,2019-4-9,2019,4,9,1,bavmzg,self.tensorflow,Time Series Formatting,https://www.reddit.com/r/tensorflow/comments/bavmzg/time_series_formatting/,cuckoostep,1554739702,"I am creating an LSTM model using Keras and TensorFlow for a [univariate time series dataset](https://archive.ics.uci.edu/ml/datasets/News+Popularity+in+Multiple+Social+Media+Platforms) with 144 timestamps. Each row is a separate instance of a news subject and each timestamp records its ""level of popularity"" at that time. My question is how can I feed the set as several hundred separate subjects with 144 steps to forecast unseen subjects?",1,1,False,self,,,,,
31,tensorflow,t5_3alkk,2019-4-9,2019,4,9,3,bax06h,self.tensorflow,Cluster-**** Installing Tensorflow-gpu On Eluktronics Windows 10.0,https://www.reddit.com/r/tensorflow/comments/bax06h/cluster_installing_tensorflowgpu_on_eluktronics/,sstovall19,1554746655,"I have jumped into the Deep Learning fray and quickly got tensorflow/keras up and running on my Eluktronics p950 (7th gen, 1070), but have not been able to install tensorflow-gpu. WSL isnt workable, and I was told by the vendor neither is dual-boot Linux. So Ive spent a week trying to install it on Windows 10.0 using several recipes, but still end up with a cant load runtime error as soon as I import tensorflow as tf. Does anyone have any ideas??",7,2,False,self,,,,,
32,tensorflow,t5_3alkk,2019-4-9,2019,4,9,5,bayujf,self.tensorflow,Can the loss be a promise/take time?,https://www.reddit.com/r/tensorflow/comments/bayujf/can_the_loss_be_a_promisetake_time/,MalicousMonkey,1554756018,"I am using Tensorflow.js. I want to make an AI that learns to play pong, but I am not sure what to use as the loss/cost function. Obviously it will be how well the neural network does at pong, but I am not sure how to put that into a single function. Is it possible for it to be a promise that returns when the AI fails?",2,1,False,self,,,,,
33,tensorflow,t5_3alkk,2019-4-9,2019,4,9,5,baz1fr,self.tensorflow,"[Question] Tensorflow inference run time high on first data point, decreases on subsequent data points. How to reduce?",https://www.reddit.com/r/tensorflow/comments/baz1fr/question_tensorflow_inference_run_time_high_on/,naboo_random,1554756974,"I am running inference using one of the models from tensorflow's object detection module. I'm looping over my test images in the same session, and doing session.run(). However, on profiling these runs, I realize the first run always has a higher time as compared to the subsequent runs.

I found an answer [here](https://stackoverflow.com/questions/45063489/first-tf-session-run-performs-dramatically-different-from-later-runs-why), as to why that happens, but there was no solution on how to fix.

I'm deploying the object detection inference pipeline on an intel i7 CPU. The time for one session.run(), for 1,2,3, and 4th image looks something like (in seconds):

1.  84.7132628
2. 1.495621681
3. 1.505012751
4. 1.501652718

Just a background on what all I have tried:

* I tried using the TFRecords approach tensorflow gave as a sample \[here\]([https://github.com/tensorflow/models/blob/master/research/object\_detection/g3doc/oid\_inference\_and\_evaluation.md](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/oid_inference_and_evaluation.md])). I hoped it would work better because it doesn't use a feed\_dict. But since more I/O operations are involved, I'm not sure it'll be ideal. I tried making it work without writing to the disk, but always got some error regarding the encoding of the image.
* I tried using the tensorflow datasets to feed the data, but I wasn't sure how to provide the input, since the during inference I need to provide input for ""image tensor"" key in the graph. Any ideas how to use this to provide input to a frozen graph?

Any help will be greatly appreciated!

TLDR: Looking to reduce the run time of inference for the first image - for deployment purposes.",4,6,False,self,,,,,
34,tensorflow,t5_3alkk,2019-4-9,2019,4,9,6,baze1r,self.tensorflow,CNN parameters,https://www.reddit.com/r/tensorflow/comments/baze1r/cnn_parameters/,916swift,1554758777,"Anyone have recommendations for where to get information about how to determine parameters for CNNs?

&amp;#x200B;

Mainly interested in how to get numbers for batch sizes, number of conv filters, when to use non-standard kernel sizes, and dropout ratios

&amp;#x200B;

thanks in advance",4,5,False,self,,,,,
35,tensorflow,t5_3alkk,2019-4-9,2019,4,9,8,bb0xew,self.tensorflow,C (not C++) implementation of Tensorflow for Time-series forcasting,https://www.reddit.com/r/tensorflow/comments/bb0xew/c_not_c_implementation_of_tensorflow_for/,bot_trig,1554767200,"I'm looking for documentation, books and examples on tensorflow implementation in C language. Specifically examples of code written in C using tf at an intermediate to high level. I am struggling to find anything online as google is basically flooded with shitty Medium articles which start with ""to use tensorflow, you have to learn to code first!"".  If anyone can provide me with some solid resources, that would be very appreciated.",0,0,False,self,,,,,
36,tensorflow,t5_3alkk,2019-4-9,2019,4,9,16,bb4tma,self.tensorflow,Increase Accuracy of SSD-Mobilenet-v1,https://www.reddit.com/r/tensorflow/comments/bb4tma/increase_accuracy_of_ssdmobilenetv1/,8222Tamil,1554793413,I want to process around 1 hour video in object detection API.but using FasterRCNN i attain the accuracy but it takes high inference [time.by](https://time.by) using SSD-Mobilenet-v1 i attain time but accuracy is not good.Want to know the possible ways to fine tune SSD-mobilenet-V1 or else how to develop a tf model from Scracth..,2,2,False,self,,,,,
37,tensorflow,t5_3alkk,2019-4-9,2019,4,9,21,bb74lg,self.tensorflow,What competes with TF Lite for on device inference?,https://www.reddit.com/r/tensorflow/comments/bb74lg/what_competes_with_tf_lite_for_on_device_inference/,bartturner,1554811600,"I am curious on what others options there are for deploying models on a device that compete with TF Lite?

I am aware of Core ML but that is limited to Apple as far as I am aware.

Thanks for any help in advance!",8,8,False,self,,,,,
38,tensorflow,t5_3alkk,2019-4-9,2019,4,9,22,bb81hb,self.tensorflow,Test,https://www.reddit.com/r/tensorflow/comments/bb81hb/test/,MalicousMonkey,1554817064,Test,1,0,False,self,,,,,
39,tensorflow,t5_3alkk,2019-4-10,2019,4,10,1,bb9v0k,self.tensorflow,What kind of GAN should I use?,https://www.reddit.com/r/tensorflow/comments/bb9v0k/what_kind_of_gan_should_i_use/,mwendten,1554826610,"I'm writing my masters thesis, where I want to apply a GAN to a structural problem for civil engineering.

I have two black and white images as input, and the output is likewise a black and white image of almost the same size

&amp;#x200B;

What kind of GAN or other generative model, would be optimal for such a problem?

&amp;#x200B;

For those interested, the input images are forces applied to a design domain, where the pixel color is the strength of the force. As it is a 2D problem, each of the two input images are channels for each direction (up-down, left-right). The output image is a density map, that shows an optimal way to put an amount of material for maximum stiffness of the structure.",10,1,False,self,,,,,
40,tensorflow,t5_3alkk,2019-4-10,2019,4,10,5,bbd2r4,blog.usejournal.com,The Rise of Generative Adversarial Networks,https://www.reddit.com/r/tensorflow/comments/bbd2r4/the_rise_of_generative_adversarial_networks/,kailashahirwar12,1554842440,,1,14,False,default,,,,,
41,tensorflow,t5_3alkk,2019-4-10,2019,4,10,7,bbe3wz,self.tensorflow,Has Anyone Gotten Tensorflow-gpu To Run On a GTX 1070 Max-Q Driver??,https://www.reddit.com/r/tensorflow/comments/bbe3wz/has_anyone_gotten_tensorflowgpu_to_run_on_a_gtx/,sstovall19,1554847749,"After failing to get tensorflow-gpu to install on my Eluktronics Clevo-based laptop, I realized the GeForce GTX 1070 Max-Q driver (418.96) may be the issue. It does not appear in the NVIDIA CUDA driver downloads. Has anyone gotten tensorflow-gpu to run on a MAX-Q??",13,2,False,self,,,,,
42,tensorflow,t5_3alkk,2019-4-10,2019,4,10,8,bbesai,self.tensorflow,Could I use Tensorflow to solve this?,https://www.reddit.com/r/tensorflow/comments/bbesai/could_i_use_tensorflow_to_solve_this/,MaNcHaSsS,1554851510,"Hello,

I am completely new to Tensorflow and would like to know if it could help me speed up a task I have to do on a daily basis and finally start learning TF.

I get something between 60 to 80 daily reports consisting of about 80 words each. Most of them, not all, have some data I need. Not always written the same way but generally contains the same words and structure.

Report example A:

Gathered 35 kg of x fruit with 8 men and X tools

Example B:

Gathered with 10 men and Y tools 46 Kg of Z vegetables.

Example C:

Waiting for better climate to restart labor.

Not really the reports I get, but it gives the general idea.
Most reports have structure similar to A.

From this reports I need to pull the  X Kg of gathered fruit.

Would this be a good opportunity for me to get started on Tensorflow? Could you point me in the right direction?",3,1,False,self,,,,,
43,tensorflow,t5_3alkk,2019-4-10,2019,4,10,20,bbkvf7,self.tensorflow,Python-Script for installing all dependencies needed for running inference on new PC,https://www.reddit.com/r/tensorflow/comments/bbkvf7/pythonscript_for_installing_all_dependencies/,2ringo,1554895630,"Hey guys,

in a current project I need to set up tensorflow to run inference on a new Windows system.

Since I want to give the possibility to my customer to set it up on other systems too without deeper knowledge of tensorflow and its needed dependencies, I was wondering if I could write a simple python-script, which installs all needed dependencies.

And if so, what would be the best way to install the dependencies? e.g. via pip, conda, etc. ?

I really appreciate your help!",6,2,False,self,,,,,
44,tensorflow,t5_3alkk,2019-4-10,2019,4,10,23,bbmrf9,self.tensorflow,Tensorflow for playing board game optimally.,https://www.reddit.com/r/tensorflow/comments/bbmrf9/tensorflow_for_playing_board_game_optimally/,08np08,1554907010,"I'm curious if anyone has used tensorflow to play board games like Cantan, Ticket to ride, ECT optimally. I know it has been used for chess and go but I'm interested in games with more than two people.",4,2,False,self,,,,,
45,tensorflow,t5_3alkk,2019-4-11,2019,4,11,12,bbv583,self.tensorflow,Where to find resources for learning low-level API in tensorflow 2.0,https://www.reddit.com/r/tensorflow/comments/bbv583/where_to_find_resources_for_learning_lowlevel_api/,Clap4jack12,1554951919,So Ive become pretty comfortable with high level APIs in tensor flow.  Does anyone know where I can find content for low level APIs?  Ideally this would be in,3,3,False,self,,,,,
46,tensorflow,t5_3alkk,2019-4-11,2019,4,11,12,bbve2f,self.tensorflow,"[Question] Tensorflow object detection retraining, confidence score really low",https://www.reddit.com/r/tensorflow/comments/bbve2f/question_tensorflow_object_detection_retraining/,naboo_random,1554953562,"Hi, 

I am trying to retrain the tensorflow object detection model - faster r cnn ( pretrained on iNaturalist) data. However, after training for around 60k steps ( where the total loss stabilizes), if I run an evaluation the confidence scores of my detections are too low, of the order of e-5. 

&amp;#x200B;

The original model has around 2k classes. I'm training on 4 classes - almost equal distribution, with around 900 samples. The data augmentation option is ""random\_horizontal\_flip"".

&amp;#x200B;

Should I be increasing the number of samples I have? Maybe have more augmentation options?

&amp;#x200B;

Any help will be appreciated! Thanks!",3,1,False,self,,,,,
47,tensorflow,t5_3alkk,2019-4-11,2019,4,11,16,bbx7bh,self.tensorflow,Source for pre-frozen tensorflow-graphs?,https://www.reddit.com/r/tensorflow/comments/bbx7bh/source_for_prefrozen_tensorflowgraphs/,goodiegoodgood,1554969438,"Hi everyone, 

I""m doing my BCS right now and starting to dip my toes into tensorflow. As the easter-holidays are right arround the corner I wanted to write some simple apps and use pre-frozen tensorflow models in order to get a ''feel'' for machine learning. 

Are there any sites where I can download simple prefrozen models (simple letter recignition, hotwordrecognition etc)?",2,2,False,self,,,,,
48,tensorflow,t5_3alkk,2019-4-11,2019,4,11,18,bbxtpf,self.tensorflow,Meet No OpKernel error when loading tensorflow model to cpp.,https://www.reddit.com/r/tensorflow/comments/bbxtpf/meet_no_opkernel_error_when_loading_tensorflow/,xianf,1554975162,"Hi,guys.

I try to load my model to cpp, so I clone the tensorflow source code from github, and run the build\_all\_linux.sh to make tensorflow become a static lib.

And then, I try to use it to load my tensorflow model which is transformed from ckpt to a pb file.  I can create the session and ReadBinaryProto, but when I try to create the session with graph ,it fails and return this message:

&gt;Invalid argument: No OpKernel was registered to support Op 'Sin' with these attrs.  Registered devices: \[CPU\], Registered kernels:  
&gt;  
&gt;  &lt;no registered kernels&gt;  
&gt;  
&gt;  
&gt;  
&gt;\[\[{{node parallel\_0/rnnsearch\_0/add\_timing\_signal/Sin}} = Sin\[T=DT\_FLOAT, \_device=""/cpu:0""\](parallel\_0/rnnsearch\_0/add\_timing\_signal/mul\_2)\]\]

I can find the Sin op kernel in the math\_ops.cc from the source code of tensorflow, but it still return this error. I am struggling with this problem for a few days, anybody knows how to solve it?

Any help is appreciate! Thx!",0,1,False,self,,,,,
49,tensorflow,t5_3alkk,2019-4-11,2019,4,11,21,bbzhda,youtu.be,TensorFlow 2.0 - Introductory Tutorial,https://www.reddit.com/r/tensorflow/comments/bbzhda/tensorflow_20_introductory_tutorial/,bhavesh91,1554986990,,1,41,False,https://a.thumbs.redditmedia.com/1BWMcMX90l2IzWPXJ0XTJPDTmNY7zuDMOKl2J00_bB8.jpg,,,,,
50,tensorflow,t5_3alkk,2019-4-12,2019,4,12,0,bc1645,self.tensorflow,Reusing Variable Fails even in a new Graph,https://www.reddit.com/r/tensorflow/comments/bc1645/reusing_variable_fails_even_in_a_new_graph/,hassanzadeh,1554996272,"Hey Guys,

I'm experiencing something that I do not expect. I have created some variable before now I create a new Graph (by calling tf.Graph()), hence I should be allowed to define the same variable again but it fails saying that this variable is already defined. I know it was defined before but I'm creating new Graph, this is unexpected, can you tell why it complains? Here the code:

with tf.Graph().as\_default():

print(tf.get\_default\_graph().as\_graph\_def().node)

with tf.variable\_scope(""model\_test""):

t1 = tf.contrib.layers.fully\_connected(first\_annot\_tf, num\_features//5, activation\_fn=None, 

weights\_initializer=tf.contrib.layers.xavier\_initializer(), 

reuse=False, scope='wing\_layer1',

weights\_regularizer=tf.contrib.layers.l2\_regularizer(0.001))

t2 = tf.contrib.layers.fully\_connected(first\_annot\_tf, num\_features//5, activation\_fn=None, 

weights\_initializer=tf.contrib.layers.xavier\_initializer(), 

reuse=True, scope='wing\_layer1',

weights\_regularizer=tf.contrib.layers.l2\_regularizer(0.001))    

print(t1,t2,t1==t2)",0,1,False,self,,,,,
51,tensorflow,t5_3alkk,2019-4-12,2019,4,12,0,bc1c41,self.tensorflow,Variable is not reused,https://www.reddit.com/r/tensorflow/comments/bc1c41/variable_is_not_reused/,hassanzadeh,1554997128,"Hey,

I'm trying to reuse a variable defined by  tf.contrib.layers.fully\_connected, but it looks like tf create new variable for each, do you know why?

&amp;#x200B;

with tf.Graph().as\_default() as graph:

with tf.variable\_scope(""model\_test""):

t1 = tf.contrib.layers.fully\_connected(first\_annot\_tf, num\_features//5, activation\_fn=None, 

weights\_initializer=tf.contrib.layers.xavier\_initializer(), 

reuse=False, scope='g3/wing\_layer1',

weights\_regularizer=tf.contrib.layers.l2\_regularizer(0.001))

t2 = tf.contrib.layers.fully\_connected(first\_annot\_tf, num\_features//5, activation\_fn=None, 

weights\_initializer=tf.contrib.layers.xavier\_initializer(), 

reuse=True,scope='g3/wing\_layer1',

weights\_regularizer=tf.contrib.layers.l2\_regularizer(0.001))",0,1,False,self,,,,,
52,tensorflow,t5_3alkk,2019-4-12,2019,4,12,6,bc55ba,self.tensorflow,Using tensorflow.js to recognize credit card forms on html pages,https://www.reddit.com/r/tensorflow/comments/bc55ba/using_tensorflowjs_to_recognize_credit_card_forms/,BrownSol,1555016635,"Hi there,

&amp;#x200B;

I was wondering what the difficulty would be to recognize credit card forms on html pages in-browser using tensorflow.js. I'm trying to gauge how hard of a problem this would be to solve, and where one might begin. Ultimately the ideal scnario would be navigating to a page, checking/recognizing a credit card form on a page, and then returning the HTML DOM elements that are a part of the form.",1,1,False,self,,,,,
53,tensorflow,t5_3alkk,2019-4-12,2019,4,12,8,bc6mrh,self.tensorflow,What is the difference between Inception_v3 (Slim) and Inception_V3,https://www.reddit.com/r/tensorflow/comments/bc6mrh/what_is_the_difference_between_inception_v3_slim/,KyleIsWinnin,1555024820,"Hi everyone,

I am getting a bit confused as to what it means to have a tensorflow slim model. I have already trained a model with two classes and am trying to use the [code provided by Google](https://github.com/tf-coreml/tf-coreml) to convert to coreml. There are specific models that can be used and almost all of them have (Slim) attached to it like [Inception v3 (Slim)](https://storage.googleapis.com/download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz). I know I can use a different config file to get me a trained Inception\_v3 model, but I am unsure if it would meet the requirement of Slim. Could anyone provide insight on what it means to be a (Slim) model? I know TF Slim exists as a less verbose version of TF but does it actually output a different type of model? If so is there any reading as to how to train a model using TFRecords in slim?",0,0,False,self,,,,,
54,tensorflow,t5_3alkk,2019-4-12,2019,4,12,9,bc7hsc,i.redd.it,"First project in Tensorflow.JS. Still a work in progress, but is pretty impressive for a first.",https://www.reddit.com/r/tensorflow/comments/bc7hsc/first_project_in_tensorflowjs_still_a_work_in/,MrPLotor,1555030102,,0,0,False,https://b.thumbs.redditmedia.com/zvm-U8QjCQyT-1tGRTI-eMQbn3WmmDobGcqwjr87Arw.jpg,,,,,
55,tensorflow,t5_3alkk,2019-4-13,2019,4,13,3,bchbue,self.tensorflow,Need some help building my first custom Keras convolution layer,https://www.reddit.com/r/tensorflow/comments/bchbue/need_some_help_building_my_first_custom_keras/,roset_ta,1555095229,"Hello,

I need to implement a Keras custom convolution layer, where there will be a kernel performing convolution (conv2d) on input image (linear kernel) and another one performing a non linear computation on the input image. 
The output function will be the sum of those two kernels results.

So far I have only used Keras for training models, but I have never built a custom layer before, so this is really new to me and I don't really understand how my weights will be updated.

I understand from Keras documentation that I need to initialize the two kernels in build function and then define call function, where I will implement the computations I mentioned . But how do I update the kernels? Do I need to extend Conv2d class, or Layer class?

I need some advice to get started. Any example always appreciated. Thank you guys",5,1,False,self,,,,,
56,tensorflow,t5_3alkk,2019-4-13,2019,4,13,6,bcjbn7,self.tensorflow,Visualizing Tensorflow networks,https://www.reddit.com/r/tensorflow/comments/bcjbn7/visualizing_tensorflow_networks/,Radeusgd,1555105867,"Hi! I'm working on Tensorflow bindings for Luna (http://luna-lang.org/). 

We allow you to build ML models by connecting visual components together  every component can define a new network layer and its dependencies. The API is highly inspired by Keras functional API.

[Here you can find an example of what it looks like](https://imgur.com/a/rmcZiZv)

Luna has the ability to display visualizations below its components, so you could inspect the look of your network on each step (after adding the first layer, adding the second layer, etc). We want to provide interactive visualizations of the network you've built so far. I'd love to ask you what visualizations you would find the most helpful during building neural networks? 

We were initially thinking about something [like that](http://www.mghpcc.org/neural-networks-earthquakes/neuralnetworkforhelen/)  so you could see the structure of your network, the weights and activation functions, but we are very open for discussion here. We want to create something that would be helpful while building various kinds of networks.

Which features do you think are most important to visualize? The weights? The activations on each layer? Something else entirely?",5,14,False,self,,,,,
57,tensorflow,t5_3alkk,2019-4-13,2019,4,13,8,bck4r5,youtube.com,Machine Learning with TensorFlow and PyTorch on Apache Hadoop using Cloud Dataproc,https://www.reddit.com/r/tensorflow/comments/bck4r5/machine_learning_with_tensorflow_and_pytorch_on/,_spicyramen,1555110495,,0,1,False,https://b.thumbs.redditmedia.com/R1uypwmOg7ZSyAxnK9f_X-YcdU-2_oVCpsgiKHBGLqI.jpg,,,,,
58,tensorflow,t5_3alkk,2019-4-13,2019,4,13,9,bcl5ke,self.tensorflow,Help with custom training loops in tensorflow 2.0 / tf.Keras,https://www.reddit.com/r/tensorflow/comments/bcl5ke/help_with_custom_training_loops_in_tensorflow_20/,venktech,1555117004,"I m writing a custom training loop in tf 2.0 as I have multiple complex set of inputs and custom loss function computations. I followed the procedure of custom model creation by extending the keras Model class and calling it within the tf.GradientTape scope. ([from here](https://www.tensorflow.org/alpha/guide/keras/training_and_evaluation)) I could get the gradients for the weights but I get a warning that gradients are not available for the bias terms. I tried initializing the layers with bias\_initializer and also tried passed training=True but doesn't work. . I also tried model.compile() but I don't think it has to be called for custom training loops. Can someone experienced in TF2 please help me out if I m missing out something

The exact error is,

W0412 02:56:32.653809 140529035499264 optimizer\_v2.py:928\] Gradients does not exist for variables \['assoc\_model/conv1\_bbox/bias:0', 'assoc\_model/dense/bias:0', 'assoc\_model/dense\_1/bias:0', 'assoc\_model/batch\_normalization\_v2/gamma:0', 'assoc\_model/batch\_normalization\_v2/beta:0', 'assoc\_model/conv2d/bias:0', 'assoc\_model/dense\_2/bias:0', 'assoc\_model/dense\_3/bias:0', 'assoc\_model/batch\_normalization\_v2\_1/gamma:0', 'assoc\_model/batch\_normalization\_v2\_1/beta:0', 'assoc\_model/dense\_4/bias:0', 'assoc\_model/conv2d\_1/bias:0', 'assoc\_model/conv2d\_2/bias:0'\] when minimizing the loss.",3,2,False,self,,,,,
59,tensorflow,t5_3alkk,2019-4-13,2019,4,13,20,bcpkh6,self.tensorflow,Reconstruction loss on regression type of Variational Autoencoder,https://www.reddit.com/r/tensorflow/comments/bcpkh6/reconstruction_loss_on_regression_type_of/,pangs4m,1555154927,"I'm currently working on a variation of Variational Autoencoder in a sequential setting, where the task is to fit/recover a sequence of real-valued observation data (hence it is a regression problem). 

&amp;#x200B;

I have built my model using \`tf.keras\` with eager execution enabled, and tensorflow\_probability (tfp). Following VAE concept, the generative net emits the distribution parameters of the observation data, which I model as multivariate normal. Therefore the outputs are mean and logvar of the predicted distribution. 

&amp;#x200B;

Regarding training process, the first component of the loss is reconstruction error. That is the log likelihood of the true observation, given the predicted (parameters) distribution from the generative net. Here, I use \`tfp.distributions\`, since it is fast and handy. 

&amp;#x200B;

However, after training is done, marked by a considerably low loss value, it turns out that my model seems not to learn anything. The predicted value from the model is just barely flat across the time dimension (recall that the problem is sequential).

&amp;#x200B;

Nevertheless, for the sake of sanity check, when I \*\*replace log likelihood with MSE loss\*\* (which is not justifiable while working on VAE), it yields very good data fitting. So I conclude that there must be something wrong with this log likelihood term. Is there anyone having some clue and/or solution for this?

&amp;#x200B;

I have considered replacing the log likelihood with cross-entropy loss, but I think that is not applicable in my case, since my problem is regression and the data can't be normalized into \[0,1\] range.

&amp;#x200B;

I also have tried to implement annealed KL term (i.e. weighing the KL term with constant &lt; 1) when using the log likelihood as the reconstruction loss. But it also didn't work.

&amp;#x200B;

Here is my code snippet of the original (using log likelihood as reconstruction error) loss function:

&amp;#x200B;

`import tensorflow as tf`

`tfe = tf.contrib.eager`

`tf.enable_eager_execution()`



`import tensorflow_probability as tfp`

`tfd = tfp.distributions`



`def loss(model, inputs):`

`outputs, _ = SSM_model(model, inputs)`



`#allocate the corresponding output component`

`infer_mean = outputs[:,:,:latent_dim]  #mean of latent variable from  inference net`

`infer_logvar = outputs[:,:,latent_dim : (2 * latent_dim)]`

`trans_mean = outputs[:,:,(2 * latent_dim):(3 * latent_dim)] #mean of latent variable from transition net`

`trans_logvar = outputs[:,:, (3 * latent_dim):(4 * latent_dim)]`

`obs_mean = outputs[:,:,(4 * latent_dim):((4 * latent_dim) + output_obs_dim)] #mean of observation from  generative net`

`obs_logvar = outputs[:,:,((4 * latent_dim) + output_obs_dim):]`

`target = inputs[:,:,2:4]`



`#transform logvar to std`

`infer_std = tf.sqrt(tf.exp(infer_logvar))`

`trans_std = tf.sqrt(tf.exp(trans_logvar))`

`obs_std = tf.sqrt(tf.exp(obs_logvar))`



`#computing loss at each time step`

`time_step_loss = []`

`for i in range(tf.shape(outputs)[0].numpy()):`

`#distribution of each module`

`infer_dist = tfd.MultivariateNormalDiag(infer_mean[i],infer_std[i])`

`trans_dist = tfd.MultivariateNormalDiag(trans_mean[i],trans_std[i])`

`obs_dist = tfd.MultivariateNormalDiag(obs_mean[i],obs_std[i])`



`#log likelihood of observation`

`likelihood = obs_dist.prob(target[i]) #shape = 1D = batch_size`

`likelihood = tf.clip_by_value(likelihood, 1e-37, 1)`

`log_likelihood = tf.log(likelihood)`



`#KL of (q|p)`

`kl = tfd.kl_divergence(infer_dist, trans_dist) #shape = batch_size`



`#the loss`

`loss = - log_likelihood + kl`

`time_step_loss.append(loss)`



`time_step_loss = tf.convert_to_tensor(time_step_loss)`        

`overall_loss = tf.reduce_sum(time_step_loss)`

`overall_loss = tf.cast(overall_loss, dtype='float32')`



`return overall_loss`",0,1,False,self,,,,,
60,tensorflow,t5_3alkk,2019-4-14,2019,4,14,1,bcs9qm,self.tensorflow,Agent Simulation in Tensorflow,https://www.reddit.com/r/tensorflow/comments/bcs9qm/agent_simulation_in_tensorflow/,mkal001,1555172939,"Hello devs
I am trying to simulate open AI gym environment in Google colab but it's not working . so does the tensor flow 2.0 has anything like open AI gym to simulate agents ?",2,4,False,self,,,,,
61,tensorflow,t5_3alkk,2019-4-14,2019,4,14,9,bcxge1,self.tensorflow,Get started with TensorFlow's High-Level APIs,https://www.reddit.com/r/tensorflow/comments/bcxge1/get_started_with_tensorflows_highlevel_apis/,GeraldNwakpu,1555203190,[https://www.youtube.com/watch?v=4mBbAq5clzw](https://www.youtube.com/watch?v=4mBbAq5clzw),1,10,False,self,,,,,
62,tensorflow,t5_3alkk,2019-4-14,2019,4,14,22,bd2miu,developers.googleblog.com,Updates from Coral: A new compiler and much more. No longer restricted to certain TF Lite models,https://www.reddit.com/r/tensorflow/comments/bd2miu/updates_from_coral_a_new_compiler_and_much_more/,bartturner,1555247700,,1,10,False,https://a.thumbs.redditmedia.com/9BB2YJ9h4Xs95yi9yiRfizIJoFTSq5LhInr5t5wU944.jpg,,,,,
63,tensorflow,t5_3alkk,2019-4-15,2019,4,15,5,bd77fj,youtube.com,1 How Convolutional Neural Networks Work: An Intuitive Approach,https://www.reddit.com/r/tensorflow/comments/bd77fj/1_how_convolutional_neural_networks_work_an/,ailearn12,1555273877,,1,12,False,default,,,,,
64,tensorflow,t5_3alkk,2019-4-15,2019,4,15,20,bdewrm,self.tensorflow,Data Engineering Conference in Europe 2019,https://www.reddit.com/r/tensorflow/comments/bdewrm/data_engineering_conference_in_europe_2019/,thiagoavadore,1555328076,"Hey!

I am organizing a conference in Amsterdam on October 30th. One of the tracks is in my area, **Data Engineering**, and we will have **Holden Karau** hosting it... our [Call for Papers is open](https://sessionize.com/itnext-summit-2019/), so I decided to share here! Come to lovely Amsterdam to LEARN. SHARE. CONNECT. on the [ITNEXT Summit 2019](https://www.itnextsummit.com/)!

&amp;#x200B;

I know plenty of `tensorflow` enthusiasts have something to share! :-)",0,2,False,self,,,,,
65,tensorflow,t5_3alkk,2019-4-15,2019,4,15,22,bdfvsf,habr.com,Identifying dog breed with neural networks: from Keras to TensorFlow Android app,https://www.reddit.com/r/tensorflow/comments/bdfvsf/identifying_dog_breed_with_neural_networks_from/,atomlib_com,1555334335,,2,23,False,https://b.thumbs.redditmedia.com/EkhVYjsJ8fdjRe-ME3EWnIc8N8m5_sEfI_punl0_lFE.jpg,,,,,
66,tensorflow,t5_3alkk,2019-4-15,2019,4,15,22,bdg81m,self.tensorflow,Why tf.map_fn is so slow? Any best practice?,https://www.reddit.com/r/tensorflow/comments/bdg81m/why_tfmap_fn_is_so_slow_any_best_practice/,AlexanderYau,1555336348,tf.map\_fn is so slow when using self-defined loss function to compute the loss.,7,2,False,self,,,,,
67,tensorflow,t5_3alkk,2019-4-15,2019,4,15,22,bdg8rq,self.tensorflow,Cosine similarity between last hidden state and each embedding vector,https://www.reddit.com/r/tensorflow/comments/bdg8rq/cosine_similarity_between_last_hidden_state_and/,yeahalrightbroguy,1555336461,"Hi all

I've been trying to implement the paper [Neural Attention Models for Sequence Classification: Analysis and Application to Key Term Extraction and Dialogue Act Detection](https://arxiv.org/abs/1604.00077) but am struggling to work out how to generate the required cosinesimilarity between context vector and embedding vectors as shown [here](https://i.vgy.me/kXhcnh.jpg). 

I've been able to achieve the desired calculation in a for loop by manually calculating the distance for each word vector for each batch, but I get issues when computing the gradients in eager mode or trying to fit the model with model.fit.

I would really appreciate any advice or hear if others have tried anything similar.

Thanks legends.",0,1,False,self,,,,,
68,tensorflow,t5_3alkk,2019-4-16,2019,4,16,5,bdktcu,youtube.com,Recurrent Neural Networks: Algorithms and Applications,https://www.reddit.com/r/tensorflow/comments/bdktcu/recurrent_neural_networks_algorithms_and/,ailearn12,1555359026,,0,0,False,default,,,,,
69,tensorflow,t5_3alkk,2019-4-16,2019,4,16,5,bdkvqj,youtube.com,Developing a Robust Face Generative Adversarial Network with Tensorflow,https://www.reddit.com/r/tensorflow/comments/bdkvqj/developing_a_robust_face_generative_adversarial/,ailearn12,1555359361,,0,1,False,https://b.thumbs.redditmedia.com/8Ma8mDgR0x-wJqmje0u1C-bXqw2XZW21bluzaf2vVLE.jpg,,,,,
70,tensorflow,t5_3alkk,2019-4-16,2019,4,16,18,bdruvi,self.tensorflow,Using TfRecords to feed my model,https://www.reddit.com/r/tensorflow/comments/bdruvi/using_tfrecords_to_feed_my_model/,Basylisk,1555406729,"Hello, I have started to use Tensorflow for a school project and through the various tutorials available I have more or less a grip of whats going on in a neural network. My goal is to benchmark different models for the project.

Now, I am trying to build my own image classifier, with my own datas. I am using Google Collab (GPU acceleration and 12GB or RAM) as my own PC isnt powerful enough to handle my data.

Here's my situation :

* I have 15000 images 256\*256 of training data and around 2000 256\*256 of testing data.
* Those images are organized in a main folder containing 2 foders (Train, Valiadtion), and each of them have a subfolder for each class (I have two classes ""2"" and ""3"" - those are not and written digits data-).

&amp;#x200B;

My first approach was to load my training data in a numpy array do some rescaling operations (rgb2gray). Then I would do :

(original shape is 256,256,3, aim is 256,256,1)

&gt;training\_data = training\_data / 255.0

which apparently is commonly done (MNIST tutorial). This would be okay when I was working with samples of data (500 images), but now (15000images) it just overload the RAM and crash my environment.

&amp;#x200B;

My second approach is to use tfRecords. I successfully splited my training data in 2 tfRecords files. But now I can't find a reliable source about how to feed them into my model.

I have tried to parse them into Tensorflow Datasets, but then I cant find how to use those datasets...

&amp;#x200B;

So my questions are :

* Can you link me to a proper example of feeding tfRecords into my model ?
* Is it possible to rework my model to accept 256,256,3 ? I have tried to change the input\_shape of the first layer, but then the accuracy would be 0)

&amp;#x200B;

Here is some models that I have tried :

&gt;model = keras.models.Sequential()  
&gt;  
&gt;model.add(keras.layers.Flatten(input\_shape=(256,256)))  
&gt;  
&gt;model.add(keras.layers.BatchNormalization())  
&gt;  
&gt;model.add(keras.layers.Dense(2, W\_regularizer=keras.regularizers.l2(0.02)))  
&gt;  
&gt;model.add(keras.layers.BatchNormalization())  
&gt;  
&gt;model.add(keras.layers.Activation('softmax'))  
&gt;  
&gt;  
&gt;  
&gt;model.compile(keras.optimizers.Adam(lr=1e-5),  
&gt;  
&gt;loss = 'sparse\_categorical\_crossentropy',  
&gt;  
&gt;metrics=\['accuracy'\])

&amp;#x200B;

&gt;model = keras.models.Sequential()  
&gt;  
&gt;model.add(keras.layers.Flatten(input\_shape=(256,256)))  
&gt;  
&gt;model.add(keras.layers.Dense(128, activation='relu'))  
&gt;  
&gt;model.add(keras.layers.Dense(2, activation='softmax'))  
&gt;  
&gt;model.compile(keras.optimizers.Adam(lr=1e-5), loss ='sparse\_categorical\_crossentropy', metrics=\['accuracy'\])

&amp;#x200B;

&gt;model = tf.keras.Sequential(\[  
&gt;  
&gt;tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu,  
&gt;  
&gt;input\_shape=(1, 256, 256), data\_format='channels\_first'),  
&gt;  
&gt;tf.keras.layers.MaxPooling2D((2, 2), strides=2),  
&gt;  
&gt;tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu),  
&gt;  
&gt;tf.keras.layers.MaxPooling2D((2, 2), strides=2),  
&gt;  
&gt;tf.keras.layers.Flatten(),  
&gt;  
&gt;tf.keras.layers.Dense(128, activation=tf.nn.relu),  
&gt;  
&gt;tf.keras.layers.Dense(2,  activation=tf.nn.softmax)  
&gt;  
&gt;\])  
&gt;  
&gt;model.compile(optimizer='adam', loss ='sparse\_categorical\_crossentropy', metrics=\['accuracy'\])

&amp;#x200B;

&amp;#x200B;

This was a bit longer than expected, thanks to everyone who will take their time to read it.",2,5,False,self,,,,,
71,tensorflow,t5_3alkk,2019-4-17,2019,4,17,4,bdy5ic,medium.com,Google Coral Edge TPU vs NVIDIA Jetson Nano: A quick deep dive into EdgeAI performance,https://www.reddit.com/r/tensorflow/comments/bdy5ic/google_coral_edge_tpu_vs_nvidia_jetson_nano_a/,bartturner,1555443292,,12,18,False,default,,,,,
72,tensorflow,t5_3alkk,2019-4-17,2019,4,17,20,be6lxx,self.tensorflow,How do I keep existing classifications when doing transfer learning?,https://www.reddit.com/r/tensorflow/comments/be6lxx/how_do_i_keep_existing_classifications_when_doing/,josh2k44,1555500221,"I just started using TensorFlow and doing transfer learning. I'm using MobileNet as a base model, and training my own datasets. However, with all the tutorials I have found, the predictions are restricted to the 'new' classifications. So for example, if I train a range of flowers, I cannot see predictions for cars, pens, bikes, etc. which I would be able to see on the MobileNet model.

&amp;#x200B;

How do I merge my dataset training model with the ImageNet model as a base and create a new set of labels with both classifications?",4,2,False,self,,,,,
73,tensorflow,t5_3alkk,2019-4-17,2019,4,17,20,be6vdl,self.tensorflow,Potentially silly question: Does having a GPU speed up training FC layers?,https://www.reddit.com/r/tensorflow/comments/be6vdl/potentially_silly_question_does_having_a_gpu/,cdf-giant,1555502099,"I have a pre-trained CNN frontend that doesn't need to be trained anymore, and I am interested in putting a 1000 unit FC layer followed by a logits layer after it (20 classes). According to my intuition, this would train just as fast on my macbook as compared to my office's workstation (2x1080ti). Is this correct?",1,1,False,self,,,,,
74,tensorflow,t5_3alkk,2019-4-17,2019,4,17,22,be7lfh,youtu.be,Build a Simple Neural Network with TensorFlow 2.0 in Google Colab,https://www.reddit.com/r/tensorflow/comments/be7lfh/build_a_simple_neural_network_with_tensorflow_20/,bhavesh91,1555506460,,0,26,False,https://a.thumbs.redditmedia.com/6rk6_m2z-cEMUbOpChacCp2YAlDoiohz46p6JsYNFZ0.jpg,,,,,
75,tensorflow,t5_3alkk,2019-4-17,2019,4,17,23,be8awv,self.tensorflow,GPU Decisions with not much money,https://www.reddit.com/r/tensorflow/comments/be8awv/gpu_decisions_with_not_much_money/,starbucksresident,1555510464,"Ok, I am (think VERY) poor... so for most of my work I use a floydhub remote K80 (cheap) or Google TPU's (v2 preempted) which are also cheap, but now I need a local GPU to train small (think ResNet50 size in small batches).

&amp;#x200B;

My PC (a decade old Workstation, Dell T5400/16GB Dual Xeon) can only handle 225W max for the GPU card (2x6 pin = 150W + 75W via PCI) so I am limited in cheaper older fast cards, otherwise, I'd buy that cheap $80 (CC3) GTX 690 beast ... (but it's 300W), my impression is the GTX 690 could even give the 1060 a run for its money.

&amp;#x200B;

I narrowed my choice down to (UK prices in USD, things not cheap here):

&amp;#x200B;

GTX 1060/3 $160

GTX 970/4  $130

GTX 780 Ti/4  $125

&amp;#x200B;

They seem to perform about the same, and all are at least CC3.5 so no tf build from scratch, which given the state of bazel I'd like to avoid.

Any reason one is far better than the other, yes 1060 is newer,  likely less used, lower power, but 3GB, not 4GB, the other two computationally seem about the same as the 1060 (perhaps 10% difference).  

They all come with a year warranty if they fail.

Thanks!",5,2,False,self,,,,,
76,tensorflow,t5_3alkk,2019-4-18,2019,4,18,6,bedbps,self.tensorflow,Help building a new tensor,https://www.reddit.com/r/tensorflow/comments/bedbps/help_building_a_new_tensor/,venktech,1555536713,"Hi.. I have a requirement to create a new tensor with shape say \[1,25600,1,num\_targets\].. The tensor should be initialized to zeros and I need to assign a value (computed from two similar tensors a and b with different feature values) on certain locations x and y of the spatial and channel dimensions. I have a loop with indices for these two dimensions where I will set the value but I cannot have the assignment in a loop because assignments are not supported in tensors. Can someone give me some ideas on how I could approach this problem.. 

&amp;#x200B;

More info: 

The two feature tensors a and b have shapes a: \[1(batch), 512(features) ,1 (dummy) ,num\_targets(channels) \]   b:\[1 (batch),25600 (spatial location in 1D array) ,512 (features) ,1 (channels)\]",0,1,False,self,,,,,
77,tensorflow,t5_3alkk,2019-4-18,2019,4,18,17,bej1fl,self.tensorflow,Question about Dimension error.,https://www.reddit.com/r/tensorflow/comments/bej1fl/question_about_dimension_error/,AnEccentricScientist,1555575471,"While converting Tensorflow model Inception to Intel movidius NCS graph it gives an error of Nonetype. 

From our understanding this stems from the fact that dimension 1 of tensors should be 1 for movidius and non Nonetype but how should we change this in code if this is the reason ?",0,1,False,self,,,,,
78,tensorflow,t5_3alkk,2019-4-18,2019,4,18,18,bejmgw,self.tensorflow,Start with tensorflow or tensorflow 2.0?,https://www.reddit.com/r/tensorflow/comments/bejmgw/start_with_tensorflow_or_tensorflow_20/,eligejjjj,1555580777,"Hi!! I am a beginner in programming (learning python) and I am very interested on AI area. I watched some videos about tensorflow and just realize that already exist tensorflow 2.0. So,  what should I start with? Someone have recommendations of free courses to start?",20,13,False,self,,,,,
79,tensorflow,t5_3alkk,2019-4-18,2019,4,18,21,bekqfr,altoros.com,TensorFlow Cheat Sheet,https://www.reddit.com/r/tensorflow/comments/bekqfr/tensorflow_cheat_sheet/,ValVish,1555589120,,0,0,False,https://a.thumbs.redditmedia.com/iewIUvGVkDRUjQAPXK6eyfp82YnRYjTT6eNLViPBbN0.jpg,,,,,
80,tensorflow,t5_3alkk,2019-4-19,2019,4,19,0,bemx9w,self.tensorflow,Error when calculating losses differently for different output nodes (indexing tensors and adding up losses in a for loop),https://www.reddit.com/r/tensorflow/comments/bemx9w/error_when_calculating_losses_differently_for/,justAHairyMeatBag,1555601481,"I'm using the tf.Keras for a multi-label classification task and I have a custom loss function that requires me to use binary cross entropy (bce) on different output nodes.

If I have y_true = [1,0,1,1,0] and y_pred = [1,0,1,0,1], bce would be calculated as **loss = -((y_true * K.log(y_pred)) + ((1 - y_true) * K.log(1 - y_pred)))**.

In my case, I want to calculate bce as **loss = - some_variable * ((y_true[some_indices] * K.log(y_pred[[some_indices]])) + ((1 - y_true[[some_indices]]) * K.log(1 - y_pred[[some_indices]])))** for a list of different indices. Basically, if I have 10 output nodes, I want to calculate bce losses for nodes [0,1,2], [3,5,7], [4,6,8,9].

        for l, indices in enumerate(2d_list_of_indices):
            loss += -some_variable[l] * ((K.gather(y_true, indices) * K.log(K.gather(y_pred, indices))) + ((1 - K.gather(y_true, indices)) * K.log(1 - K.gather(y_pred, indices))))


But this throws the following error:

    ValueError: Dimensions must be equal, but are 2 and 4 for 'loss/dense_1_loss/add_5' (op: 'Add') with input shapes: [2,4042], [4,4042].


I'm not sure what to do to get this to work. Could someone help me figure out what I'm doing wrong?",0,1,False,self,,,,,
81,tensorflow,t5_3alkk,2019-4-19,2019,4,19,0,ben51x,stackoverflow.com,Help Required: Sharing Variable across multi level scopes,https://www.reddit.com/r/tensorflow/comments/ben51x/help_required_sharing_variable_across_multi_level/,schrodingershit,1555602613,,0,1,False,https://b.thumbs.redditmedia.com/axDKHPjaklzq2xETW8RUlfyEH23qZPX8KlapAuoDrxU.jpg,,,,,
82,tensorflow,t5_3alkk,2019-4-20,2019,4,20,1,bf1hc3,self.tensorflow,Radeon VII vs RTX 2080TI for ML? Which to choose...,https://www.reddit.com/r/tensorflow/comments/bf1hc3/radeon_vii_vs_rtx_2080ti_for_ml_which_to_choose/,protechig,1555693158,"I'm looking to upgrade my GPU on my computer and would like to know how a 2080TI compares to a Radeon VII from a TensorFlow perspective? I currently have a GTX 1080 which is more than powerful enough for what I do (meaning I play a simple video game maybe once a week), but I know there are better options for ML. I can't really find any benchmarks of the two cards side-by-side. I know the Radeon VII is slower than the RTX but is \~$500 cheaper and has 16GB of HBM memory vs 11GB of GDDR. 

&amp;#x200B;

Does anyone have some real-world experience comparing these cards?",14,3,False,self,,,,,
83,tensorflow,t5_3alkk,2019-4-20,2019,4,20,7,bf58kp,self.tensorflow,Comparing audio files,https://www.reddit.com/r/tensorflow/comments/bf58kp/comparing_audio_files/,MissValeska,1555713072,"Is it possible to make an AI that can compare any two speech audio files together and identify if they are equivalent, e.g, contain the same general message? I know that you can train an AI to compare any audio file to a specific set of categories, but is that all? I would like to give it a source speech audio file and then another recorded by someone else and see if they're saying the same thing as a binary thing or even percentage thing.",4,8,False,self,,,,,
84,tensorflow,t5_3alkk,2019-4-20,2019,4,20,18,bfanrl,self.tensorflow,How can I make my own convolution operation in tf?,https://www.reddit.com/r/tensorflow/comments/bfanrl/how_can_i_make_my_own_convolution_operation_in_tf/,roset_ta,1555754349,"Hello,

Where can I find the source code of TensorFlow where the tf.nn.conv2d is executed? Specifically I'm looking for the part where the kernel is sliding with respect to the strides. 


I want to implement the function y(x) = (xT * W * x) + b, as a custom convolution operation,  where:

xT is an image patch of shape (n,n) reshaped as a vector (1,n^2)
W is a matrix of weights with shape (n^2,n^2)
x is the image patch again, reshaped as (n^2,1)
b is the bias

So the result would be a matrix with the sums of the convolution of the kernel on every (n,n) image patch.

Thank you",7,2,False,self,,,,,
85,tensorflow,t5_3alkk,2019-4-21,2019,4,21,0,bfdmfm,self.tensorflow,How to find input and output tensors for my neural network?,https://www.reddit.com/r/tensorflow/comments/bfdmfm/how_to_find_input_and_output_tensors_for_my/,jimmothytheunicorn,1555775546,"Where would this be found. Its an inception graph, 42 layer convolutional. Where are the input output tensors?",3,2,False,self,,,,,
86,tensorflow,t5_3alkk,2019-4-21,2019,4,21,3,bffm3r,self.tensorflow,TensorFlow World call for proposals ends Apr 23,https://www.reddit.com/r/tensorflow/comments/bffm3r/tensorflow_world_call_for_proposals_ends_apr_23/,ewilderj,1555786066,"Hey folks, the [TensorFlow World](https://conferences.oreilly.com/tensorflow/tf-ca) conference will be held by O'Reilly Media, in Santa Clara, CA, USA, this October 28-31, and we're seeking talk proposals from practitioners.  Please consider [submitting a proposal](https://conferences.oreilly.com/tensorflow/tf-ca/public/cfp/732) highlighting your work.",1,2,False,self,,,,,
87,tensorflow,t5_3alkk,2019-4-21,2019,4,21,5,bfgsk5,youtube.com,This video goes over a breast cancer diagnosis model that uses neural networks. Really interesting,https://www.reddit.com/r/tensorflow/comments/bfgsk5/this_video_goes_over_a_breast_cancer_diagnosis/,antaloaalonso,1555792630,,0,23,False,default,,,,,
88,tensorflow,t5_3alkk,2019-4-21,2019,4,21,15,bfm3py,self.tensorflow,Programming language for tensorflow,https://www.reddit.com/r/tensorflow/comments/bfm3py/programming_language_for_tensorflow/,itsmevikash,1555828773,Which Language is good for beginners on tensorflow,2,1,False,self,,,,,
89,tensorflow,t5_3alkk,2019-4-22,2019,4,22,0,bfptof,self.tensorflow,Major training slowdown after moving from TF 1.13 to TF 2.0,https://www.reddit.com/r/tensorflow/comments/bfptof/major_training_slowdown_after_moving_from_tf_113/,SupportVectorMachine,1555859697,"I recently made the switch from 1.13 to 2.0a on both my home and office computers (Ubuntu 18.04 with Nvidia GTX 1080 Ti GPUs). I've noticed on both machines that the same models, same data, and same batch sizes run over ten times slower in 2.0.

A couple of stray points:

* I had previously primarily used Keras (standalone with TensorFlow backend) for rapid sandboxing of ideas, and I now use tensorflow.keras in its place. 
* I've tested with eager execution both enabled and disabled with no noticeable difference.

Has anyone else had a similar experience? Anything obvious I'm missing?

(As this is a general issue as of to a specific error, sharing code doesn't seem all that useful here.)",5,9,False,self,,,,,
90,tensorflow,t5_3alkk,2019-4-22,2019,4,22,4,bfsqur,self.tensorflow,Tensorflow object_detection_tutorial error,https://www.reddit.com/r/tensorflow/comments/bfsqur/tensorflow_object_detection_tutorial_error/,_dark_light_,1555875832,"Using this tutorial 

https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10#6-run-the-training

I've done everything to get tensorflow to run but when I get to the final test at part 2g I get the following error: ModuleNotFoundError: No module named 'tensorflow'

I don't understand how i can get this issue. Any insight to solving this would be greatly appreciated.

https://imgur.com/a/cD5QJET",1,2,False,self,,,,,
91,tensorflow,t5_3alkk,2019-4-22,2019,4,22,20,bg0xes,self.tensorflow,TensorFlow 2.0 Cheat Sheet,https://www.reddit.com/r/tensorflow/comments/bg0xes/tensorflow_20_cheat_sheet/,__Tia__,1555932226,"Hi guys, 

Here is a TensorFlow cheat sheet you may found useful [https://www.altoros.com/visuals/tensorflow-cheat-sheet](https://www.altoros.com/visuals/tensorflow-cheat-sheet/?utm_campaign=ai_training_smm_organic&amp;utm_source=reddit&amp;utm_medium=social). 

I'm also looking for any other papers with quick code samples. I would be very grateful if you could share some in comments. Thanks!",6,0,False,self,,,,,
92,tensorflow,t5_3alkk,2019-4-22,2019,4,22,23,bg2rte,self.tensorflow,Trained tensorflow model moved to another directory cannot be loaded,https://www.reddit.com/r/tensorflow/comments/bg2rte/trained_tensorflow_model_moved_to_another/,atinesh229,1555943480,"I have trained a `tensorflow` model and moved the trained model files (`checkpoint`, `model.data-00000-of-00001`, `model.index`, `model.meta`) to another directory, Now if I try to load the model I get this error

    ValueError: Can't load save_path when it is None.

If I load the model without moving it to another directory it works fine. I looked at this [post](https://stackoverflow.com/questions/50391464/load-tensorflow-model-from-moved-directory) but it didn't work

&amp;#x200B;

**Code**

    import tensorflow as tf
    sess = tf.Session()
    tf_saver = tf.train.import_meta_graph('model/model.meta')
    tf_saver.restore(sess, tf.train.latest_checkpoint('model'))",5,1,False,self,,,,,
93,tensorflow,t5_3alkk,2019-4-23,2019,4,23,1,bg4cos,self.tensorflow,How to keep kernel tensor to a specific form during backpropagation?,https://www.reddit.com/r/tensorflow/comments/bg4cos/how_to_keep_kernel_tensor_to_a_specific_form/,roset_ta,1555951756,"Hello, 

I'm implementing a custom Keras layer, where I need my kernel to be in an upper triangular form.

So far, I have randomly initialized the kernel in `tf.add_weight' and then transformed it to an upper triangular form using `tf.matrix_band_part`.

But how can I be sure that it will stay that way during backpropagation? Do I need to create a custom kernel constraint? Or TensorFlow will keep it in that form? Thanks!",6,3,False,self,,,,,
94,tensorflow,t5_3alkk,2019-4-23,2019,4,23,5,bg783p,self.tensorflow,"Could someone please look at my code, which tries to classify a movie as positive or negative based on the IMDB dataset. I get 88% accuracy on the test data, but I feel like I am missing something.",https://www.reddit.com/r/tensorflow/comments/bg783p/could_someone_please_look_at_my_code_which_tries/,AnhedonicHermit,1555966262,"This is one of the introductory tasks for learning keras, more details available here: https://www.tensorflow.org/tutorials/keras/basic_text_classification. It uses the IMDB  dataset which is preloaded in keras.

My code is here: https://pastebin.com/grYPfmNB

I tried different combination of hidden layers and neurons in each layer, but the performance I get from no hidden layers and 1 epoch is as good as any other combination. This cannot be right. Please look over my code and tell me what I am doing wrong.",7,5,False,self,,,,,
95,tensorflow,t5_3alkk,2019-4-23,2019,4,23,16,bgdoef,self.tensorflow,Dummy variable tensorflow,https://www.reddit.com/r/tensorflow/comments/bgdoef/dummy_variable_tensorflow/,nothingveryserious,1556005960,"Dear all,

I am new to tensorflow. I have a series of dummy variables in my data frame. That is several columns of ones and zeroes.

When constructing my graph, what is the appropriate method to classify these cases?

tf.feature_column.categorical_column_with_identity(col, num_buckets=2))",0,1,False,self,,,,,
96,tensorflow,t5_3alkk,2019-4-23,2019,4,23,20,bgf87t,self.tensorflow,Tensorflow Dual GPU usage - effective power?,https://www.reddit.com/r/tensorflow/comments/bgf87t/tensorflow_dual_gpu_usage_effective_power/,starbucksresident,1556018795,"&amp;#x200B;

[The Single underpowered MSI GTX 760 4GB Twin Frozr](https://i.redd.it/44fgnx0hzzt21.jpg)

&amp;#x200B;

So, the effective power is likely around 50% of a 1060 (or so the benchmarks tell me, likely way off and much more underpowered)  - *however*  \- if I add a second card (from the 7 series, so same driver and can co-exist)  will I achieve roughly 1060 performance *and* 8GB? I am hoping it may be not really as good, but still close?

&amp;#x200B;

By the way the machine is an old Dell 5400 (2007) with E5430 Xeon and 16GB - as such (and with the CC 3.0 of the card) I managed to build Tensorflow 1.13 with no  SSE4/AVX instructions *and* CC 3.0 (took around 7 hrs to build on this old machine) and it works fine.

So, if you have ancient equipment you can still run the latest 1.13 in GPU mode. 

&amp;#x200B;

I will post here (community wheels) later today:

[TensorFlow 1.13, GPU (CC 3.0) (CUDA 10.0, cuDNN 7.4), Without SSE4/AVX, Python 3.6, Ubuntu 18.04](https://github.com/yaroslavvb/tensorflow-community-wheels/issues/107)",2,2,False,self,,,,,
97,tensorflow,t5_3alkk,2019-4-24,2019,4,24,0,bghilt,stackoverflow.com,How to use Tensorflow to compute per-sample gradient and reduce them with an arbitrary function?,https://www.reddit.com/r/tensorflow/comments/bghilt/how_to_use_tensorflow_to_compute_persample/,nnet--,1556032322,,0,1,False,default,,,,,
98,tensorflow,t5_3alkk,2019-4-24,2019,4,24,0,bghvy9,self.tensorflow,Exporting to a keras tf 2.0 model to c++,https://www.reddit.com/r/tensorflow/comments/bghvy9/exporting_to_a_keras_tf_20_model_to_c/,Envenger,1556034221," 

I have trained a keras tensorflow model in python I want to export the model in some manner and make it run in c++.  
I  am getting multiple ways and doing it and I don't know which is the  current method of doing it as most of the posts I see are a few years  old and the processes are very different from each other.

What should I follow for what I am looking to achieve.

[https://www.tensorflow.org/tfx/serving/serving\_basic](https://www.tensorflow.org/tfx/serving/serving_basic)  
[https://medium.com/@hamedmp/exporting-trained-tensorflow-models-to-c-the-right-way-cf24b609d183](https://medium.com/@hamedmp/exporting-trained-tensorflow-models-to-c-the-right-way-cf24b609d183)",2,2,False,self,,,,,
99,tensorflow,t5_3alkk,2019-4-24,2019,4,24,6,bglqtc,medium.com,"TensorFlow, PyTorch or MXNet? A comprehensive evaluation on NLP &amp; CV tasks with Titan RTX",https://www.reddit.com/r/tensorflow/comments/bglqtc/tensorflow_pytorch_or_mxnet_a_comprehensive/,gwen0927,1556053691,,1,18,False,https://b.thumbs.redditmedia.com/rOdS3CV9KkMjqKW3Wdwv4CueX5H1rQHXEHk43FkW3To.jpg,,,,,
100,tensorflow,t5_3alkk,2019-4-24,2019,4,24,14,bgqu49,self.tensorflow,How do tf.nn.conv2d create more feature map by small amount of filters?,https://www.reddit.com/r/tensorflow/comments/bgqu49/how_do_tfnnconv2d_create_more_feature_map_by/,Laurence-Lin,1556083730,"In LeNet, the second convolution layer have 6 filters, and wanted to create 16 feature maps by combining several output of feature maps from these 6 filters(3, 4, 5 feature map), and by combination we get total 16 feature maps. 

Does the tf.nn.conv2d(in\_channel, out\_channel) do the combination automatically? 

If I have in\_channels = 6 for previous layer output, out\_channel = 16 for current feature maps output, then will it combine different pair of feature maps within this function?",1,1,False,self,,,,,
101,tensorflow,t5_3alkk,2019-4-24,2019,4,24,15,bgrf00,self.tensorflow,How could I create a edge filter for practice?,https://www.reddit.com/r/tensorflow/comments/bgrf00/how_could_i_create_a_edge_filter_for_practice/,Laurence-Lin,1556088333,"I would like to do edge detection(or other convolution that could show the effect on an image), and I create a filter by tf.constant by myself, which is 3\*3 size. However, in the tf.nn.conv2d(input, filter) function, filter parameters take in size of \[height, width, in\_channel, out\_channel\] that has rank4 as the filter's size. How could I create an filter by myself that could test the effect of convolution on an image? I don't want to do by tf.truncate\_normal, the output of convolution is strange and meaningless.  


Thanks a lot!",2,1,False,self,,,,,
102,tensorflow,t5_3alkk,2019-4-24,2019,4,24,18,bgsdy8,self.tensorflow,How to feed Tensor to feed_dict?,https://www.reddit.com/r/tensorflow/comments/bgsdy8/how_to_feed_tensor_to_feed_dict/,dcopz,1556096875,"I just knowing that I cannot feed Tensor to feed_dict. any idea?

TypeError: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles",5,1,False,self,,,,,
103,tensorflow,t5_3alkk,2019-4-24,2019,4,24,20,bgt9ks,self.tensorflow,Can I use the TensorFlow Object Detection API for semantic/panoptic segmentation?,https://www.reddit.com/r/tensorflow/comments/bgt9ks/can_i_use_the_tensorflow_object_detection_api_for/,EmielBoss,1556104069,"I wish to implement [Panoptic FPN](https://arxiv.org/abs/1901.02446) (which adds an extra branch to Mask R-CNN for semantic segmentation) using TensorFlow, and use pre-trained models for its ResNet-FPN backbone. However, I am add a crossroads: do I use TensorFlow's Keras API, or the [TensorFlow Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection)? Is the latter even capable of semantic segmentation? What do you recommend?",0,1,False,self,,,,,
104,tensorflow,t5_3alkk,2019-4-25,2019,4,25,1,bgwru9,self.tensorflow,importing barcode dataset for training purpose,https://www.reddit.com/r/tensorflow/comments/bgwru9/importing_barcode_dataset_for_training_purpose/,mkal001,1556123625,"&amp;#x200B;

I have a dataset of barcode images in which each image barcode.jpg has a corresponding text file barcode.jpg.txt containing the unique number of that barcode. Does there exist any method to import this dataset as tf-dataset.",6,2,False,self,,,,,
105,tensorflow,t5_3alkk,2019-4-25,2019,4,25,2,bgxj76,developers.google.com,"Sepcnn problem, I have no learning.",https://www.reddit.com/r/tensorflow/comments/bgxj76/sepcnn_problem_i_have_no_learning/,babaladeo,1556127409,,0,1,False,default,,,,,
106,tensorflow,t5_3alkk,2019-4-25,2019,4,25,2,bgxnio,self.tensorflow,SepCnn classifiers does not learn anything.,https://www.reddit.com/r/tensorflow/comments/bgxnio/sepcnn_classifiers_does_not_learn_anything/,babalinobaba,1556128013,"https://developers.google.com/machine-learning/guides/text-classification/step-1


I have tested every SepCnn machine combination in the tutorial above, and for any epoch (200 it's the maximum that I have tried, deactivating earlyStoping) I have 50% val_accuracy for binary tasks and 20% for the 5 category example.

I downloaded the whole eng-edu-master repo and run it without any changes and I get the same results. What could I have been doing wrong?

I'm running tensorflow-gpu==2.0.0-alpha0 

Nvidia GTX1070; driver = 418.56 cuda = 10.1

Intel i7-8700K 3.70GHz 

Ubuntu 18.04 

24gb RAM.",0,1,False,self,,,,,
107,tensorflow,t5_3alkk,2019-4-25,2019,4,25,3,bgy8ol,self.tensorflow,Need suggestions for an approach to object detection in very large images,https://www.reddit.com/r/tensorflow/comments/bgy8ol/need_suggestions_for_an_approach_to_object/,Owz182,1556130976,"I need to count objects in 7360x4912 images. I have trained the a faster-rcnn from Google's model zoo on a training data set, which I made by chopping up my 7360x4912 images in to 64 920x614 images. I should note my machine doesn't have enough memory to train on the large images themselves. But the model training has gone well as far as I can tell, and I'm able to detect the objects of interest in the smaller images, but not when I try to detect objects in the full 7360x4912 images. I think this is because the faster-rcnn is resizing before prediction, and the objects of interest end up being too small/poor resolution to detect.

&amp;#x200B;

So I'm trying to come up with an approach that involves, for every prediction, replicating the chopping process, so each large image gets cut to 64 smaller ones, the model detects the objects in each one, and then I take the total count across all 64. However, sometimes the objects fall on the image edge, and so are either not detected, or detected twice, once each at the boundary of the smaller chopped images. This makes my final count inaccurate. I wondered if anyone might have suggestions for an approach to dealing with this.

&amp;#x200B;

I had thought maybe about performing the chopping process multiple times for each large image, but with a random offset each time so the objects will fall in different parts of the smaller images. Then I would take some kind of mean estimate from all the counts of all the offset smaller images. The issue here is I'm upping the number of predictions to be made for each large image, bloating the run time significantly.

&amp;#x200B;

Is this the approach you would take or do you think there's some more efficient way to do this?",3,4,False,self,,,,,
108,tensorflow,t5_3alkk,2019-4-25,2019,4,25,13,bh4oeq,self.tensorflow,Develop an object detection model from scratch,https://www.reddit.com/r/tensorflow/comments/bh4oeq/develop_an_object_detection_model_from_scratch/,8222Tamil,1556168112,"Is it possible to create a object detection model like ssd mobilenet ,Faster Rcnn Resnet.If [yes.How](https://yes.How) to approach ?",5,2,False,self,,,,,
109,tensorflow,t5_3alkk,2019-4-26,2019,4,26,3,bhccnz,i-programmer.info,How Do Open Source Deep Learning Frameworks Stack Up?,https://www.reddit.com/r/tensorflow/comments/bhccnz/how_do_open_source_deep_learning_frameworks_stack/,pmz,1556218363,,0,1,False,default,,,,,
110,tensorflow,t5_3alkk,2019-4-26,2019,4,26,4,bhcjex,self.tensorflow,Training converges on cpu but diverges when I switch to gpu?,https://www.reddit.com/r/tensorflow/comments/bhcjex/training_converges_on_cpu_but_diverges_when_i/,iamiamwhoami,1556219317,"I can give more specifics as I start to diagnose the issue more, but I'm getting this really weird behavior where training converges when I test with cpu but diverges when I move over to a gpu. Has anyone seen anything like this?",5,5,False,self,,,,,
111,tensorflow,t5_3alkk,2019-4-26,2019,4,26,5,bhdexn,self.tensorflow,Image recognition with tensorflow,https://www.reddit.com/r/tensorflow/comments/bhdexn/image_recognition_with_tensorflow/,13016,1556223909,"Hey r/tensorflow, I'm totally new to tensorflow but am supposed to create an image recognition software (for example classifying whether or not there is a car in the given image). Is this possible with tensorflow? If so how manageable would this be for someone with no prior experience (except python of course)? Thank you so much for your help!",6,4,False,self,,,,,
112,tensorflow,t5_3alkk,2019-4-26,2019,4,26,7,bhf05z,self.tensorflow,None for gradient ValueError,https://www.reddit.com/r/tensorflow/comments/bhf05z/none_for_gradient_valueerror/,roset_ta,1556232442,"Hello,

I implemented a layer in Keras and when trying to fit the model containing the custom layer I get the following error:


`ValueError: An operation hasNonefor gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.`


The main tf ops I'm using are 
`tf.multiply`,
`tf.matmul`
`tf.reduce_sum`
`tf.extract_image_patches`


Is any of those not differentiable?

When I predict a given image, the result I get is as expected. But I cannot fit the model and I don't know what to look for. Any ideas?",0,1,False,self,,,,,
113,tensorflow,t5_3alkk,2019-4-26,2019,4,26,17,bhjve5,self.tensorflow,What happens when GPU ran out of memory ?,https://www.reddit.com/r/tensorflow/comments/bhjve5/what_happens_when_gpu_ran_out_of_memory/,RemoteReindeer,1556266468,"\&gt; 2019-04-26 10:08:19.209261: W tensorflow/core/common\_runtime/bfc\_allocator.cc:211\] Allocator (GPU\_0\_bfc) ran out of memory trying to allocate 3.96GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.

&amp;#x200B;

Apart from the obvious, that my GPU memory is full, what happens exactly ? I can still train even if I'm allocating 1.6x the max memory of my GPU.",7,4,False,self,,,,,
114,tensorflow,t5_3alkk,2019-4-27,2019,4,27,0,bhnb0v,self.tensorflow,Protobuf with Tensorflow Issue.,https://www.reddit.com/r/tensorflow/comments/bhnb0v/protobuf_with_tensorflow_issue/,FrStealer,1556290997,"Hello,

I've got an issue with Tensorflow and Protobuf on Ubuntu16, python3.4 and I'm really confused.

After Tensorflow 1.13.1 installation, I can't import Tensorflow directly because I'm missing the library google (he can't import google). I then installed protobuf 3.7.0 (the version tensorflow wants) with pip3.4, but he doesn't quite detect it.

After importing, I've got the error message :

&gt;  
&gt;  
&gt;\[libprotobuf FATAL external/protobuf\_archive/src/google/protobuf/stubs/common.cc:68\] This program requires version 3.7.0 of the Protocol Buffer runtime library, but the installed version is 3.6.1.  Please update your library.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in ""google/protobuf/descriptor.pb.cc"".)  
&gt;  
&gt;terminate called after throwing an instance of 'google::protobuf::FatalException'  
&gt;  
&gt;  what():  This program requires version 3.7.0 of the Protocol Buffer runtime library, but the installed version is 3.6.1.  Please update your library.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed in ""google/protobuf/descriptor.pb.cc"".)  
&gt;  
&gt;Abandon (core dumped)

&amp;#x200B;

However, I've got the right version of protobuf

     pip3.4 show protobuf

&gt;  
&gt;  
&gt;Name: protobuf  
&gt;  
&gt;Version: 3.7.0  
&gt;  
&gt;Summary: Protocol Buffers  
&gt;  
&gt;Home-page: [https://developers.google.com/protocol-buffers/](https://developers.google.com/protocol-buffers/)  
&gt;  
&gt;Author: None  
&gt;  
&gt;Author-email: None  
&gt;  
&gt;License: 3-Clause BSD License  
&gt;  
&gt;Location: /usr/local/lib/python3.4/site-packages  
&gt;  
&gt;Requires: setuptools, six  
&gt;  
&gt;Required-by: tensorflow, tensorflow-tensorboard, tensorflow-gpu, tensorboard, kraken

    
    protoc --version gives me ""libprotoc 3.7.0""
    

I also purged every Protobuf library on my computer before the new installation with apt. 

&amp;#x200B;

I'm quite confused and any idea would be much appreciated !

&amp;#x200B;

Thanks in advance.",4,1,False,self,,,,,
115,tensorflow,t5_3alkk,2019-4-27,2019,4,27,0,bhnfhv,self.tensorflow,"LSTM with more than one feature will train, but issue at prediction time",https://www.reddit.com/r/tensorflow/comments/bhnfhv/lstm_with_more_than_one_feature_will_train_but/,landsquid0,1556291642,[https://stackoverflow.com/q/55835696/4783594](https://stackoverflow.com/q/55835696/4783594),1,0,False,self,,,,,
116,tensorflow,t5_3alkk,2019-4-27,2019,4,27,4,bhqboi,self.tensorflow,Multi-GPU inference on Object Detection Model,https://www.reddit.com/r/tensorflow/comments/bhqboi/multigpu_inference_on_object_detection_model/,jpapon,1556306581,"Hi all,

&amp;#x200B;

I'm trying to find out what's going on here. I'm using a model from the object detection zoo:

[http://download.tensorflow.org/models/object\_detection/faster\_rcnn\_inception\_resnet\_v2\_atrous\_coco\_2018\_01\_28.tar.gz](http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz)

I'm using the frozen inference graph.

I find myself unable to change what device the model runs on - I've tried using:

    with tf.device ('/gpu:3') 
        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')
        boxes = detection_graph.get_tensor_by_name('detection_boxes:0')
        scores = detection_graph.get_tensor_by_name('detection_scores:0')
        classes = detection_graph.get_tensor_by_name('detection_classes:0')
        num_detections = detection_graph.get_tensor_by_name('num_detections:0')
        (boxes, scores, classes, num_detections) = sess.run([boxes, scores, classes, num_detections], feed_dict={image_tensor: image_np_expanded})

but no matter what I do, inference still runs on gpu:0. Tensorflow sees all of my devices, but also just seems to ignore all of my tf.device commands.

If I manually set it using, e.g., 

    config = tf.ConfigProto()
    config.gpu_options.visible_device_list=""3""
    sess = tf.Session(graph=detection_graph, config=config)

Then I get the following error:

    Check failed: cuda_gpu_id.value() == result.first-&gt;second (0 vs. 3)
    Mapping the same TfGpuId to a different CUDA GPU id. 
    TfGpuId: 0 Existing mapped CUDA GPU id: 3 CUDA GPU id being tried to map to: 0

Environment variables don't change it either... what could be going on here?",0,0,False,self,,,,,
117,tensorflow,t5_3alkk,2019-4-27,2019,4,27,6,bhrube,self.tensorflow,Question about data size,https://www.reddit.com/r/tensorflow/comments/bhrube/question_about_data_size/,JimothyDoe,1556314947,"Before i start i am sorry if this question is asked every 2 days, i am new to this. 
So i have been wondering if say i have been training a model for a few days and by now it can recognise a pattern with promising accuracy, so if i let it train to the point that the model file is around 10 gb, will the process of recognising a small sized image be slower due to the model file size?
And if so is there a way that the user can choose what is saved in the actual model file, modifying the source code wouldn't be out of the question.
Also it take a lot of power for tensorflow to recognise the patterns, say i had it running on a raspberry pi, would it be smart to keep tensorflow running on a raspberry pi or should i the raspberry pi as a recording device that transfers the data to a more powerful device in real time",6,2,False,self,,,,,
118,tensorflow,t5_3alkk,2019-4-27,2019,4,27,8,bht57p,self.tensorflow,Problem installing Tensorflow for pycharm IDE in Ubuntu on Jetson Nano,https://www.reddit.com/r/tensorflow/comments/bht57p/problem_installing_tensorflow_for_pycharm_ide_in/,Ryzen120,1556322723,"Hello, 

As the title says, I just received my new jetson nano in the mail and got to setting it up. It runs on a modified version of ubuntu 18.04. I have recently installed Pycharm via the command terminal and it functions properly with normal python code. I recently have attempted to install Tensorflow ( my first time ever) and followed Tensorflows instructions via their site and Nvidias for the Nano specifically. Upon installation via the pycharm IDE however, I get the error which is posted in this link.

http://imgur.com/gallery/CpZ4TfW

If anyone has any suggestions or can help, that would be greatly appreciated! Also if you need more information, I can also do that as well. In the event the picture sucks for some reason, the error code is basically saying exit code (1), module not found.

Thanks!",9,3,False,self,,,,,
119,tensorflow,t5_3alkk,2019-4-27,2019,4,27,9,bhtkxr,self.tensorflow,Has anyone used Tensorflow Transform with xgboost?,https://www.reddit.com/r/tensorflow/comments/bhtkxr/has_anyone_used_tensorflow_transform_with_xgboost/,elliott34,1556325384,"Problem we're running into described here: [https://github.com/tensorflow/transform/issues/114](https://github.com/tensorflow/transform/issues/114)

&amp;#x200B;

Are we saving the wrong graph?",0,5,False,self,,,,,
120,tensorflow,t5_3alkk,2019-4-27,2019,4,27,15,bhw8um,self.tensorflow,Error appeared when I use tensorboard,https://www.reddit.com/r/tensorflow/comments/bhw8um/error_appeared_when_i_use_tensorboard/,Laurence-Lin,1556345517,"When I use tensorboard in command line: tensorboard --logdir PATHNAME, an error appeared:

OSError: Errno22: invalid argument

After search solution online, some says that it is due to the bug in Python version before 3.6.7, so I download the newest version of Python 3.7 and installed it, but when I run it again same error message reappeared. I've seen the error message, the tensorboard file direction is located in Anaconda file path, and the python version within anaconda is Python 3.6.5. 

Should I upgrade anaconda too? Will it also upgrade the python version in anaconda?

Thanks for helping!",1,1,False,self,,,,,
121,tensorflow,t5_3alkk,2019-4-27,2019,4,27,21,bhyhqx,self.tensorflow,Tensorflow 2.0 custom training values,https://www.reddit.com/r/tensorflow/comments/bhyhqx/tensorflow_20_custom_training_values/,wongong,1556367226,"Hi!

Im trying to implement policy gradient for continuous action with tensorflow 2.0

But here, I have a problem. 

for custom training,

I use this part.

grads = gt.gradient(objective, self.model.trainable\_variables)

self.optimizer.apply\_gradients(zip(grads, self.model.trainable\_variables)

&amp;#x200B;

but what if I have another tf.Variable which is not included in model.trainable variables but want to train?

I tried just do 

grads = gt.gradient(objective, self.model.trainable\_variables+ tf.expand\_dims(\[self.std\],axis = 0))

self.optimizer.apply\_gradients(zip(grads, self.model.trainable\_variables+ tf.expand\_dims(\[self.std\],axis = 0)))

but it is not working.

&amp;#x200B;

help me out!",2,1,False,self,,,,,
122,tensorflow,t5_3alkk,2019-4-27,2019,4,27,21,bhyo09,self.tensorflow,"Error Encoding Network, generate images without minimizing the alternating latent space or adversarial training!",https://www.reddit.com/r/tensorflow/comments/bhyo09/error_encoding_network_generate_images_without/,RRoundTable,1556368662,"Hi, ML redditors all around the world! 

This is an unofficial implementation of Error Encoding Networks which is originally developed by Facebook AI Research using Keras.

To alleviate the necessity of GPU resources, the smaller network is used by reducing the size of an input image.

If you are interested in EEN, click this link and check the results.

Thanks :)",0,1,False,self,,,,,
123,tensorflow,t5_3alkk,2019-4-28,2019,4,28,0,bi09r6,self.tensorflow,Image Recognition with Tensorflow,https://www.reddit.com/r/tensorflow/comments/bi09r6/image_recognition_with_tensorflow/,13016,1556379488,"Hey guys, I've spent a couple of days learning the basic principles behind tensorflow. Now I want to create an image classifier. My problem is that every tutorial I encountered so far explained how to classify images that have a predefined theme (for example animals or flowers). But what do I have to do if I want to, for example, have an image classifier that tells me wheter or not a given image has a cog wheel in it or not?",6,2,False,self,,,,,
124,tensorflow,t5_3alkk,2019-4-28,2019,4,28,4,bi2rok,self.tensorflow,Is there a way I can just flatten the last two dimensions of a tensor when the tensor has two dimensions of unknown size?,https://www.reddit.com/r/tensorflow/comments/bi2rok/is_there_a_way_i_can_just_flatten_the_last_two/,iamiamwhoami,1556394122,"So I have a tensor of 

     shape=(?, 3, ?, 2, 100)

The zeroth dimension is batch_size. The first is number of time steps. The second is a little hard to explain but it also indexes time but in a different way from the first. The last two dimensions are my features. I want to flatten the last two dimension so that

     shape=(?, 3, ?, 200)

I've tried tf.reshape and K.flatten. However they throw an error because of the two unknown dimension sizes. Anyone have an idea on how to proceed?",2,4,False,self,,,,,
125,tensorflow,t5_3alkk,2019-4-28,2019,4,28,14,bi811j,youtube.com,Recurrent Neural Networks: Algorithms and Applications,https://www.reddit.com/r/tensorflow/comments/bi811j/recurrent_neural_networks_algorithms_and/,Bobber123yxz,1556429299,,2,14,False,default,,,,,
126,tensorflow,t5_3alkk,2019-4-28,2019,4,28,21,bial8r,self.tensorflow,Error when trying to train model (cast string to float),https://www.reddit.com/r/tensorflow/comments/bial8r/error_when_trying_to_train_model_cast_string_to/,SmoothyMoves,1556453332,"Explanation in here: https://stackoverflow.com/questions/55883985/tensorflow-model-training-with-cast-string-to-float-is-not-supported-error?noredirect=1#comment98429390_55883985

Any ideas?",6,0,False,self,,,,,
127,tensorflow,t5_3alkk,2019-4-28,2019,4,28,23,bic31n,youtube.com,"Interested in Artificial Intelligence, Machine Learning, Computer Vision, or NLP? Check out this channel for excellent, well-explained, video tutorials.",https://www.reddit.com/r/tensorflow/comments/bic31n/interested_in_artificial_intelligence_machine/,Bobber123yxz,1556463583,,2,7,False,default,,,,,
128,tensorflow,t5_3alkk,2019-4-29,2019,4,29,0,biccse,self.tensorflow,when is the negative sign applied for gradient descent?,https://www.reddit.com/r/tensorflow/comments/biccse/when_is_the_negative_sign_applied_for_gradient/,wongongv,1556465170,"I have a question about tensorflow custom training. 
For example, let's say Im using cross_entropy_with_softmax and adam optimizer. For this to be a gradient descent, you need to apply negative sign somewhere. When does tensorflow applies it?
The reason I want to know this is to do gradient ascent with custom loss. It seems like negative sign is applied in Adam optimizer. Is it right?

Thank you!",1,1,False,self,,,,,
129,tensorflow,t5_3alkk,2019-4-29,2019,4,29,5,bifswf,i.redd.it,"Trying to install TF 2.0 gpu, am I doing something wrong?",https://www.reddit.com/r/tensorflow/comments/bifswf/trying_to_install_tf_20_gpu_am_i_doing_something/,Biddls,1556484157,,34,0,False,default,,,,,
130,tensorflow,t5_3alkk,2019-4-30,2019,4,30,4,bityfo,rubikscode.net,Ultimate Guide to TensorFlow 2.0 in Python,https://www.reddit.com/r/tensorflow/comments/bityfo/ultimate_guide_to_tensorflow_20_in_python/,pmz,1556567940,,1,0,False,default,,,,,
131,tensorflow,t5_3alkk,2019-4-30,2019,4,30,9,bix5yv,self.tensorflow,Told to update my cudNN despite it being the latest update,https://www.reddit.com/r/tensorflow/comments/bix5yv/told_to_update_my_cudnn_despite_it_being_the/,A_Random_Lantern,1556585779,I'm using CUDA 9.0 with v7.5.1 which is the latest update yet tensorflow is telling me to update it. I'm not getting this so any help would be appreciated,4,1,False,self,,,,,
132,tensorflow,t5_3alkk,2019-4-30,2019,4,30,21,bj304m,self.tensorflow,object detection API training loss is not going down!,https://www.reddit.com/r/tensorflow/comments/bj304m/object_detection_api_training_loss_is_not_going/,aniketmaurya,1556629173,"I am trying to train custom dataset with Tensorflow object detection API.  I have hand annotated calculation area in tax receipts. But the training loss doesn't seem to reduce below 0.18

I have attached the prediction images. Please help!

https://i.redd.it/1zc9r2v1gev21.png",14,0,False,https://b.thumbs.redditmedia.com/pcD4YXdm1NOpW4qlJsLalOuItLTVSraXZJeQIMm12uw.jpg,,,,,
