,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2018-10-2,2018,10,2,4,9kjmue,18 Tips for Training your own Tensorflow.js Models in the Browser,https://www.reddit.com/r/tensorflow/comments/9kjmue/18_tips_for_training_your_own_tensorflowjs_models/,kiarash-irandoust,1538423060,,0,1
1,2018-10-2,2018,10,2,5,9kjs4g,"PSA: Don't ""install"" TF using docker",https://www.reddit.com/r/tensorflow/comments/9kjs4g/psa_dont_install_tf_using_docker/,CommunismDoesntWork,1538424045,"It just straight up doesn't work. It's unusable. You won't be able to develop using it at all. Maybe deployment is a different story, but for development, it is just FUBAR.",14,1
2,2018-10-2,2018,10,2,11,9kmwyf,Algorithmic trader looking for Tensorflow programmer,https://www.reddit.com/r/tensorflow/comments/9kmwyf/algorithmic_trader_looking_for_tensorflow/,GastricDisturbance,1538447692,"Hello,
I have my own trading software robot that trades for me. My problem is that it takes so long to change inputs to find the best settings. Essentially there are probably 1 million possible combinations of the 50 input variables, but im only able to find maybe 20 manually. Im looking to load up chart data through csv so i can run through all potential variables faster. Sorting through combinations and ranking them by highest profit. 

I have a small dev team but If anyone can help with utilizing tensorflow, you would get access to a money printing machine for free. 

Thank you for your time! ",7,1
3,2018-10-2,2018,10,2,21,9kqcbm,Apis - TensorFlow,https://www.reddit.com/r/tensorflow/comments/9kqcbm/apis_tensorflow/,thefernandito,1538484858,"A few weeks ago I am studying TensorFlow, I have seen that among its valuable Apis, one of the most important seems to be Estimator. What would be the other TF apis that you think I should pay more attention to?",1,1
4,2018-10-2,2018,10,2,23,9kr1cg,Cant get tensorflow-gpu to work on Ubuntu MATE 18.04,https://www.reddit.com/r/tensorflow/comments/9kr1cg/cant_get_tensorflowgpu_to_work_on_ubuntu_mate_1804/,rk39096,1538490164,[removed],0,1
5,2018-10-3,2018,10,3,5,9ku7wp,RNN Weights as Model Input?,https://www.reddit.com/r/tensorflow/comments/9ku7wp/rnn_weights_as_model_input/,blowjobtransistor,1538511533,"I'm looking at transitioning a collection of text classifiers to TF/TF Serving, but I'm not sure how to replicate some existing functionality where some of the model weights are provided as an input.  

To explain a little, all the text classifiers use the same word embeddings, which make up over 99.9% of the model parameters. For performance and cost purposes, the existing implementation keeps these embeddings in memory, and swaps out the much smaller classifier-specific weights as needed.

I can see how to do this directly via `tf.assign`, but not sure if this can be included in the computational graph and used in TF Serving / Google ML Engine.

Has anyone done something like this? Know where I should look?",0,1
6,2018-10-3,2018,10,3,11,9kx6ae,How to use time distributed cnn + lstm in a keras model?,https://www.reddit.com/r/tensorflow/comments/9kx6ae/how_to_use_time_distributed_cnn_lstm_in_a_keras/,Arkhaya,1538533958,,0,1
7,2018-10-3,2018,10,3,12,9kxndy,Saving and restoring model (Wrong predictions after restoring model),https://www.reddit.com/r/tensorflow/comments/9kxndy/saving_and_restoring_model_wrong_predictions/,Gother,1538537916,"I am trying to save, restore and predict with a model in TensorFlow. There are many answers out there already but NONE specifically target problems in production, so I believe this question will help out people seeking for a hands on approach on the topic.

So, I trained the model available on [this jupyter code](https://github.com/mithi/semantic-segmentation/blob/master/playground.ipynb) and I am now trying to save the model and predict on different images. I was able to run it and got [this result after training](https://i.stack.imgur.com/MY8HS.png).

Then I saved the model, loaded it and predicted again on the same image. [This is the result after testing on the restored model](https://i.stack.imgur.com/i90YJ.png). Obviously I am doing something wrong, either saving the model or loading it.

&amp;#x200B;

The code that I am using for saving the model is as follows:

Inside \`def run():\`

    with tf.Session() as session:
    
        # Returns the three layers, keep probability and input layer from the vgg architecture
        image_input, keep_prob, layer3, layer4, layer7 = load_vgg(session, VGG_PATH)
        
        # The resulting network architecture, adding a decoder on top of the given vgg model
        model_output = layers(layer3, layer4, layer7, NUMBER_OF_CLASSES)
        
        logits, train_op, cross_entropy_loss = optimize(model_output, correct_label, learning_rate, NUMBER_OF_CLASSES)
        # Create saver
        saver = tf.train.Saver()
        # Initilize all variables
        session.run([tf.global_variables_initializer(), tf.local_variables_initializer()])
        
        # train the neural network
        train_nn(session, EPOCHS, BATCH_SIZE, get_batches_fn,
        train_op, cross_entropy_loss, image_input,
        correct_label, keep_prob, learning_rate)
        # Save inference data
        helper.save_inference_samples(RUNS_DIRECTORY, DATA_DIRECTORY, session, IMAGE_SHAPE, logits, keep_prob, image_input)
        # Save model
        saver.save(session, ""./fcn_liquid_model"", global_step = 500)

&amp;#x200B;

Then, for loading the saved model I tried doing the following:

&amp;#x200B;

    tf.reset_default_graph:
    with tf.Session() as session:
        # Restore variables and model
        saver = tf.train.import_meta_graph(""./fcn_liquid_model-500.meta"")
        saver.restore(session, tf.train.latest_checkpoint(""./""))
        print(""Model restored."")
        # Returns the three layers, keep probability and input layer from the vgg architecture
        image_input, keep_prob, layer3, layer4, layer7 = load_vgg(session, VGG_PATH)
        
        # The resulting network architecture, adding a decoder on top of the given vgg model
        model_output = layers(layer3, layer4, layer7, NUMBER_OF_CLASSES)
        
        logits = tf.reshape(model_output, (-1, NUMBER_OF_CLASSES))
        # Initilize all variables
        session.run([tf.global_variables_initializer(), tf.local_variables_initializer()])
        helper.save_inference_samples(RUNS_DIRECTORY, DATA_DIRECTORY, session, IMAGE_SHAPE, logits, keep_prob, image_input)

And got the result previously shown. Does anyone know what is happening or how can I fix the problem? Thank you.",4,1
8,2018-10-4,2018,10,4,2,9l3cef,Adding Convolution to custom DNN estimator,https://www.reddit.com/r/tensorflow/comments/9l3cef/adding_convolution_to_custom_dnn_estimator/,Gsonderling,1538588070,"Let's say I have a custom estimator, like the one in the:
https://github.com/tensorflow/models/blob/master/samples/core/get_started/custom_estimator.py

How would I go about adding convolution layer? 
https://www.tensorflow.org/api_docs/python/tf/layers/conv1d

I assume that it's harder than just putting it right after the input layer. But apart from image specific tutorial, I can't find how to actually work with them. ",0,1
9,2018-10-4,2018,10,4,7,9l5txc,"tf.test.is_gpu_available() blocking indefinitely, using 100% CPU",https://www.reddit.com/r/tensorflow/comments/9l5txc/tftestis_gpu_available_blocking_indefinitely/,KjellJagland,1538604096,"I set up TensorFlow on Windows 10 earlier today and initially struggled with getting the GPU version to work. For some reason, I had both the tensorflow and tensorflow-gpu packages installed, which is not supposed to happen. It finally detects my GTX 970 now but `tf.test.is_gpu_available()` curiously hangs and eats up 100% of one CPU core. It doesn't return in the GPU version. It did return `False` right away in the CPU version, though. Here's some sample output:

`Python 3.6.6 (v3.6.6:4cf1f54eb7, Jun 27 2018, 03:37:03) [MSC v.1900 64 bit (AMD64)] on win32`

`Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.`

`&gt;&gt;&gt; import tensorflow as tf`

`&gt;&gt;&gt; with tf.device(""GPU:0""):`

`...     x = tf.random_uniform([1000, 1000])`

`...     print(x.device)`

`...`

`/device:GPU:0`

`&gt;&gt;&gt; tf.test.is_gpu_available()`

`2018-10-03 23:08:26.805592: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2`

`2018-10-03 23:08:27.171992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties:`

`name: GeForce GTX 970 major: 5 minor: 2 memoryClockRate(GHz): 1.253`

`pciBusID: 0000:01:00.0`

`totalMemory: 4.00GiB freeMemory: 3.31GiB`

`2018-10-03 23:08:27.184134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0`

And, well, then it just hangs indefinitely and keeps on spinning. Am I doing something wrong or is there something broken? I suppose I'd have to build it from source in order to debug this issue in Visual Studio 2017.",9,1
10,2018-10-4,2018,10,4,13,9l8nkq,Good resources on reshaping tensors?,https://www.reddit.com/r/tensorflow/comments/9l8nkq/good_resources_on_reshaping_tensors/,VegasTamborini,1538626767,"I'm taking a neural nets course at uni and I'm really struggling with the idea of reshaping tensors. I'm vaguely aware of the concept from using numpy, but I don't get how exactly it relates to tensorflow. All the resources that I've found explain the mechanics of how a tensor is reshaped without going into why that needs to happen for it to work in tensorflow. Can anyone recommend any good resources that will fill my knowledge gap?

&amp;#x200B;

Thanks",0,1
11,2018-10-4,2018,10,4,16,9l9oo5,Learn ML lifecycle and Tensorboard In Tensorflow By Building Real World AI and ML apps using #Tensorflow,https://www.reddit.com/r/tensorflow/comments/9l9oo5/learn_ml_lifecycle_and_tensorboard_in_tensorflow/,thecodingfossil,1538637415,,0,1
12,2018-10-4,2018,10,4,19,9laiio,Writing Custom Activation Functions,https://www.reddit.com/r/tensorflow/comments/9laiio/writing_custom_activation_functions/,Aesix,1538647390,"I'm struggling to find material that's very clear about how to write your own activation mapping. I've combed through the tensorflow code and found the relu/softmax/etc, but they of course use ""K"" instead of numpy and now we're walking into territory I'm trying to become familiar with... I just wanted to play with a y=mx+b formula for fun. :| ",1,1
13,2018-10-5,2018,10,5,2,9le485,Problematic binary classifier,https://www.reddit.com/r/tensorflow/comments/9le485/problematic_binary_classifier/,Zak_Wormald,1538674990,"[Link To Stack Overflow Page](https://stackoverflow.com/questions/50641866/binary-classifier-always-returns-0-5)

My classifier does not work and i have been unable to find a solution for a while now. I have made a similar model that mimics the XOR gate before but for some reason this model does not function despite it's only major difference being that it takes three inputs as opposed to two. Any help with the problem would be much appreciated as my stack overflow doesn't get much traffic. ",2,1
14,2018-10-5,2018,10,5,19,9ll3f9,Custom Keras Activation (Revisited),https://www.reddit.com/r/tensorflow/comments/9ll3f9/custom_keras_activation_revisited/,Aesix,1538735420,"After some 'constructive' criticism I've rephrased the question in shorter terms. What would be the easy way to apply an activation that requires more than the usual code, like ""f(x) = (e\^x - 1) / (e\^x)"" using Keras/TF ? (function simplified)",0,1
15,2018-10-5,2018,10,5,21,9llvu6,Keras in TensorFlow,https://www.reddit.com/r/tensorflow/comments/9llvu6/keras_in_tensorflow/,Good_Development,1538742973,"What are the advantages of using Keras as a TensorFlow api, instead of using only TF?",4,1
16,2018-10-5,2018,10,5,22,9lmbpb,Weyl tensor,https://www.reddit.com/r/tensorflow/comments/9lmbpb/weyl_tensor/,ricci-flow,1538746472,Placeholder ,0,1
17,2018-10-5,2018,10,5,22,9lmfi2,,https://www.reddit.com/r/tensorflow/comments/9lmfi2/_/,ricci-flow,1538747278,,0,1
18,2018-10-6,2018,10,6,22,9lvy21,Unable to train input as variable instead of weights (Keras and Tensorflow),https://www.reddit.com/r/tensorflow/comments/9lvy21/unable_to_train_input_as_variable_instead_of/,ronsap123,1538832570," 

I have a Keras model and I want to do some cool visiualizations with it. It's an object recognition network.

So I thought, It would be cool to input a blank image into the network and treat the image as the variable and not the weights, and then train the network to always output an icecream for example.

So I wrote the following code:

    #loading the model 
    model = load_model('model.h5')  
    #create the input image as a variable 
    w = tf.Variable(tf.zeros([1,224,224,3]))  
    
    #create the flowgraph with the variable input 
    pred = model.call(inputs=w)  
    #create the desired output distribution 
    desired = np.zeros((1000)) desired[928] = 1.0  
    err = tf.reduce_mean(tf.subtract(pred,desired)) 
    
    #create an optimizer that can only affect the inital input variable I created 
    optimizer = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(err, var_list=[w])  
    #train the network 
    for i in range(0,100):     
        _,cost = sess.run([optimizer,err])     
        print(cost) 

So I thought the code would work well, but the cost literally doesn't change. It stays in place as if it's entirely unaffected.

&amp;#x200B;

Thanks in advance",2,1
19,2018-10-8,2018,10,8,8,9m9smw,Difference between tf.contrib.data.CsvDataset and tf.contrib.data.make_csv_dataset,https://www.reddit.com/r/tensorflow/comments/9m9smw/difference_between_tfcontribdatacsvdataset_and/,tf_noo,1538954867,"Basically what the title says.

I have a csv data file that I want to read into tensorflow and then feed it into one of the pre-made estimators. From various searches I found these two functions but from the documentation, I'm not immediately sure what the difference between the two is? Would appreciate an explanation! ",1,1
20,2018-10-8,2018,10,8,10,9mafvy,How to create a video display which uses the graph.pb and the labels to display active classification for a demo?,https://www.reddit.com/r/tensorflow/comments/9mafvy/how_to_create_a_video_display_which_uses_the/,Arkhaya,1538960571,I've been trying to find a way to get a working demo to display active classification but most tutorials that are on the Internet don't really provide a proper solution. I have trained my model on inception resnet but can't seem to find any code that can help me display the active classification. ,1,1
21,2018-10-8,2018,10,8,14,9mbzle,How can I use previously-updated weights of a model?,https://www.reddit.com/r/tensorflow/comments/9mbzle/how_can_i_use_previouslyupdated_weights_of_a_model/,AlexanderYau,1538974829,"I created a network with 2 dense layers.

At every time step `t`, my code updates `W_t`, the weights of my model. However, how can I use the previously updated weights, for example, `W_t-k`, `W_t-k+1`, ..., `W_t-1` when updating `W_t` at time step `t`?",1,1
22,2018-10-9,2018,10,9,15,9mmu4c,Learn Fraud Detection with Python &amp; Tensorflow,https://www.reddit.com/r/tensorflow/comments/9mmu4c/learn_fraud_detection_with_python_tensorflow/,Slight_Role,1539066924,,0,1
23,2018-10-9,2018,10,9,17,9mnfo9,Training and freezing tensorflow graph via Java,https://www.reddit.com/r/tensorflow/comments/9mnfo9/training_and_freezing_tensorflow_graph_via_java/,geometrikal,1539074260,"I have developed a CNN classifier using tensorflow in python. It consists of augmentation using `tf.data.Dataset` and a `map` function, CNN, custom training scheduler, and freezing the graph for later use.

I created a Java program with a GUI etc for end-users to use the network for inference etc.

However, I would like to enable that same Java program to train a new network and freeze it when done. Has anyone done this before? (Could be in C# as well). In particular, is the `tf.data.Dataset` augmentation possible?

Another option would be to put the python scripts in the cloud and expose the training using an API. Are there some existing resources to help set this up?
",1,1
24,2018-10-10,2018,10,10,4,9ms56j,Does anyone know of an example use of Conv3DLSTMCell? I cannot find anything online.,https://www.reddit.com/r/tensorflow/comments/9ms56j/does_anyone_know_of_an_example_use_of/,kds_medphys,1539112768,,0,1
25,2018-10-10,2018,10,10,13,9mwaoq,Can I build a carrer in Tensorflow - how good of a bet is it for me?,https://www.reddit.com/r/tensorflow/comments/9mwaoq/can_i_build_a_carrer_in_tensorflow_how_good_of_a/,kiransaravi,1539145023,"I've recently started learning ML &amp; TF, and I liked it so much, I wanna explore more and build a career out of it - probably as a developer to start with. Given that i have over 10 yrs exp in middleware(completely unrelated technology) and in a good paying comfortable job. How good of a bet is it for me?",3,1
26,2018-10-12,2018,10,12,13,9nh7n6,2080 Ti TensorFlow GPU benchmarks: The best GPU of 2018?,https://www.reddit.com/r/tensorflow/comments/9nh7n6/2080_ti_tensorflow_gpu_benchmarks_the_best_gpu_of/,pepito_pistola,1539318412,,2,1
27,2018-10-12,2018,10,12,22,9nk5bg,Using FP16 or FP32 with TensorFlow and ObjectDetection API?,https://www.reddit.com/r/tensorflow/comments/9nk5bg/using_fp16_or_fp32_with_tensorflow_and/,punkehazardo,1539349865,"The last few days I have been reading a lot about comparisons between different GPUs and how well these GPUs perform with FP16/FP32-calculations.
Then I wanted to apply this new found knowledge to my existing setup, but I have no idea where or how.

I am using the [TensorFlow Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection). My first guess was to look through the training/eval-scripts and look for float32 initializations, but changing them all to float16 resulted in errors.

Is it even worth looking into this or is the API already working with lower precision settings? And if I wanted to switch precisions, how would I do this?",4,1
28,2018-10-13,2018,10,13,4,9nndg4,Difficult Reshaping GAN Generator Output,https://www.reddit.com/r/tensorflow/comments/9nndg4/difficult_reshaping_gan_generator_output/,StackBPoppin,1539373026,"I've implemented a GAN, and I've some okay results with it, however I'm running into a problem:

If I load all image data and keep it in the format \[batch\_size, image\_height \* image\_width\] (i.e. 2d) when using matplotlib I can see the results fine.

If I decide to use the format \[batch\_size, image\_height, image\_width, colour\_depth\] I just get random noise out of matplotlib.

To be more specific, I have a placeholder with shape \[None, 56, 100, 1\]. (Greyscale 100x56 images). I load images from a dataset using `tf.reshape(tf.image.decode_png(tf.read_file(x), 1), [56, 100, 1])`

I then try to plot them with `matplotlib plt.imshow(samples.reshape(56, 100, 1))` but all I get is noise, however when everything is 'flat' it works fine.

I guess my question is, if I have a tensor of shape \[batch\_size, image\_height, image\_width, colour\_depth\] how can I plot display the images from it?",0,1
29,2018-10-13,2018,10,13,20,9nsyma,Question about DCGAN,https://www.reddit.com/r/tensorflow/comments/9nsyma/question_about_dcgan/,TrPhantom8,1539428511,"Hello everybody! I have a question about DCGAN.
My task is a kind of image denoising: I have a synthetic dataset made of input images (noisy) and  output images (without noise). I have created a CNN which works pretty well at the task and I was wondering how to improve my model.
Does it make sense to use this trained CNN model as the generator in a GAN? Would the generator eventually become stronger?
Thank you in advance for your help! ",0,1
30,2018-10-14,2018,10,14,1,9nuuy3,How to install Tensorflow GPU with CUDA 10.0 for python on Ubuntu | Python 3.6,https://www.reddit.com/r/tensorflow/comments/9nuuy3/how_to_install_tensorflow_gpu_with_cuda_100_for/,Aryal007,1539446818,,0,1
31,2018-10-14,2018,10,14,9,9nyl2p,[Question] Row-wise euclidean distance for cost computation?,https://www.reddit.com/r/tensorflow/comments/9nyl2p/question_rowwise_euclidean_distance_for_cost/,Rigatin,1539475891,"Hi all,

&amp;#x200B;

So I'm a tensorflow newbie who's just started doing some research with applying machine learning to genome sequences. So basically there's two types of gene, one which is marked as causing antimicrobial resistance and one which doesn't and I have those in two matrices (\[m,t\] and \[n,t\] respectively). They've given me the math calculations they want me to implement, and basically I use a weight matrix (alpha \[q,t\]) to create two new matrices through matrix multiplication (so matmul(a, alpha.T)). These matrices are gamma1 and gamma2, and they want me to train the weights to that the euclidean distances between the rows of each gamma are small, but the euclidean distances between gamma 1's rows and gamma 2's rows are increased. So it works kind of like a one-layer network. I don't fully understand it myself, but that's what the professor wants (they say it's so that they can compress the data and make it more usable since the matrices are very sparse).

&amp;#x200B;

If you've followed up to that point, I'm basically wondering if there's any tensorflow methods I can use to calculate this cost, so that I end up with a single cost value which I can then minimize. For instance, for gamma1 I'd like to get a value for the distance between all the rows (think sqrt(a\^2 + b\^2)). I've been looking around and trying to find methods and ways to implement this but it hasn't been very easy for me. I've only done very simple and basic networks in the past, so something like this which I even hesitate to call a machine learning problem is posing a large issue for me.

&amp;#x200B;

Thanks for any help, in the meantime I'll keep on looking around for solutions.",1,1
32,2018-10-14,2018,10,14,21,9o2ep0,[Question] Object Detection Transfer Learning - changing the output layer,https://www.reddit.com/r/tensorflow/comments/9o2ep0/question_object_detection_transfer_learning/,alew3,1539520777,"Is it useful to do transfer learning when I change the output layer instead of the last layer? I want to use a pre-trained object detection model and retrain it to map/predict the position of the lines of a football pitch based on an image. So instead of finding a box, I want to predict the position of the corners of the pitch and the half way line. (so instead of 4 outputs, I would have 6 outputs). Any hints on the best way to go about this? As a proof of concept I'm generating synthetic data with a 3d model in Unity.",0,1
33,2018-10-15,2018,10,15,5,9o5zbf,Tensorflow Serving exporter for Prometheus,https://www.reddit.com/r/tensorflow/comments/9o5zbf/tensorflow_serving_exporter_for_prometheus/,aqny,1539548350,,0,1
34,2018-10-15,2018,10,15,17,9oatgr,Tensorflow Eager Execution Gradient Calculation slower each epoch,https://www.reddit.com/r/tensorflow/comments/9oatgr/tensorflow_eager_execution_gradient_calculation/,MCFF3000,1539591770,"Hi to all!

&amp;#x200B;

I have been implementing Temportal Ensembling for Semi-Supervised Learning by Laine et al. with eager execution and a couple of GitHub users noticed that the computations of the gradients is taking gradually more time each epoch. I don't see what is causing this. After benchmarking I could confirm this issue, but I have no idea why this should be happening. Is anyone faced this problem with `tf.GradientTape()` ? Or is this is an issue related to eager execution?

&amp;#x200B;

The code is in [https://github.com/Goldesel23/Temporal-Ensembling-for-Semi-Supervised-Learning](https://github.com/Goldesel23/Temporal-Ensembling-for-Semi-Supervised-Learning)

&amp;#x200B;

Thanks for your time!",1,1
35,2018-10-15,2018,10,15,19,9obfby,Running FNN in parallel over a dimension in Eager,https://www.reddit.com/r/tensorflow/comments/9obfby/running_fnn_in_parallel_over_a_dimension_in_eager/,liftoff01,1539598791,"I have a 3 dimensional tensor which I want to apply the same feedforward neural network to over the 2nd dimension. My current implementation is this: 
        output = []
        for nS in range(inputs.shape[1]):
            dense  = inputs[:,nS,:]
            dense = self.fc01(dense)
            dense = self.dropout(dense)
            
            for denseLayer in self.deeps:
                dense = denseLayer(dense)
                dense = self.dropout(dense)
            output.append(dense)

But I cannot help but feel there is a better way to implement this without the outer parallel loop. 

Can someone help point me down that path? ",2,1
36,2018-10-16,2018,10,16,5,9ogbds,Normalization in TensorFlow: speed is an issue,https://www.reddit.com/r/tensorflow/comments/9ogbds/normalization_in_tensorflow_speed_is_an_issue/,__me_again__,1539634278,"Has anyone else noticed this?

[https://medium.com/@mansanher/normalization-in-tensorflow-speed-is-an-issue-b8ae14336685](https://medium.com/@mansanher/normalization-in-tensorflow-speed-is-an-issue-b8ae14336685)",0,1
37,2018-10-16,2018,10,16,13,9ok886,tf-explorer: a command-line interface to explore TensorFlow checkpoints.,https://www.reddit.com/r/tensorflow/comments/9ok886/tfexplorer_a_commandline_interface_to_explore/,sharvil,1539663444,,0,1
38,2018-10-16,2018,10,16,20,9omr3a,Where can I find learning resources just for understanding Tensorflow?,https://www.reddit.com/r/tensorflow/comments/9omr3a/where_can_i_find_learning_resources_just_for/,sedgecrooked,1539689505,"I just want to understand how Tensorflow works and how to get started with it. Nothing for ML or deep learning, just about tensorflow.",0,1
39,2018-10-17,2018,10,17,2,9oprx9,Art with optimizers,https://www.reddit.com/r/tensorflow/comments/9oprx9/art_with_optimizers/,cosmic_dozen,1539710805,,1,1
40,2018-10-17,2018,10,17,5,9orf1m,"Generate TFRecord for images downloaded using EscVM/OIDv4_ToolKit, was struggling to adapt existing scripts, so wrote this, might be useful for someone",https://www.reddit.com/r/tensorflow/comments/9orf1m/generate_tfrecord_for_images_downloaded_using/,r0bertas,1539721414,,4,1
41,2018-10-17,2018,10,17,6,9os8ln,How to install Tensorflow GPU with CUDA 10.0 for python on Windows,https://www.reddit.com/r/tensorflow/comments/9os8ln/how_to_install_tensorflow_gpu_with_cuda_100_for/,Aryal007,1539727057,,0,1
42,2018-10-17,2018,10,17,14,9ovx8a,Creating a Logical AND using Tensorflow's Deep Neural Network classifier,https://www.reddit.com/r/tensorflow/comments/9ovx8a/creating_a_logical_and_using_tensorflows_deep/,AnderUstarroz,1539755751,"Hi,   
I am a seasoned Python developer, but when it comes to Tensorflow I am just a beginner,  
I was wondering if some Tensorflow expert could bring some light into the following issue:  


[https://stackoverflow.com/questions/52841015/create-a-logical-and-with-tensorflow-using-a-deep-neural-network-classifier](https://stackoverflow.com/questions/52841015/create-a-logical-and-with-tensorflow-using-a-deep-neural-network-classifier)  


&amp;#x200B;",0,1
43,2018-10-17,2018,10,17,16,9owdvh,this might be stupid,https://www.reddit.com/r/tensorflow/comments/9owdvh/this_might_be_stupid/,nagasaig9,1539760448,"is TensorFlow build on top of Keras or Keras build on top of TensorFlow..?

&amp; what is base for TensorFlow..?",5,1
44,2018-10-18,2018,10,18,2,9p0p7i,"Integrating Tensorflow into a cross-platform (Linux, Android etc) C++ framework; what's the best approach?",https://www.reddit.com/r/tensorflow/comments/9p0p7i/integrating_tensorflow_into_a_crossplatform_linux/,rumborak,1539797014,"I have a C++ framework at work that runs on a variety of platforms: Windows, Linux, Android, Raspberry Pi. I want to integrate Tensorflow as a module into it, but I'm not sure what the best approach would be. Note this is only for runtime inference, the training would happen on a normal Linux installation.

So, it seems Android is the most restrictive because only TF Lite exists for it, is that correct? Is it a reasonable conclusion that I should thus use TF Lite across the platforms to make it easy on myself? Does TF Lite exist for the non-Android platforms?",4,1
45,2018-10-18,2018,10,18,19,9p7usa,Searching for intermediate Tensorflow course,https://www.reddit.com/r/tensorflow/comments/9p7usa/searching_for_intermediate_tensorflow_course/,Appelmoesje,1539856820,"I'm a student in Software Engineering and I have a very big interest in ML for the last 2 years. I have followed a few courses on Youtube (Sentdex is my favourite) but I want to take it to the next step. Most Youtube videos don't have ""homework"" that you can make to practice yourself and most of them dont go deep in way thing are how they are in ML. 

Now I would like to improve my skills in Tensorflow but find the Tensorflow docs not very user friendly. I have seen courses on Udacity but there are paid and I don't have that kind of money to spend.

Does anyone know a course that is free (or can be watched free with a student email) that increases my Tensorflow knowlegde? Thank you very much in advance!",5,1
46,2018-10-18,2018,10,18,23,9p9s5h,Is keras the best api to work with images in Tensorflow?,https://www.reddit.com/r/tensorflow/comments/9p9s5h/is_keras_the_best_api_to_work_with_images_in/,thefernandito,1539873029,"Hello friends, I am doing my first practices with Tensorflow and I want to work with images, I see that many people use the api of keras for images. Is this the best? Thank you.",0,1
47,2018-10-19,2018,10,19,7,9pdvhg,Same code different results tensorflow coursera jupyter notebook/laptop,https://www.reddit.com/r/tensorflow/comments/9pdvhg/same_code_different_results_tensorflow_coursera/,overbit123,1539901114,"I started learning ML and playing around with tensorflow in my spare time and am struggling to determine the cause of an inconsistency I found.  When I run the CNN from the hand gesture classification in the online coursera jupyter notebook, the results are way different then when I run it from my personal laptop (mac pro python script).  All seeds and random initializes are set and are all the same.  Everything is identical until conv2d is first called and then the results are way different, and the accuracy drops by about 20% and trains way slower on my laptop.  

&amp;#x200B;

Would any redditors know why this happens?  I am disappointed I will not be able to train simple CNNs from my machine.",9,1
48,2018-10-19,2018,10,19,7,9pdw0k,Many Tensorflow benchmarks of the NVIDIA RTX 2070,https://www.reddit.com/r/tensorflow/comments/9pdw0k/many_tensorflow_benchmarks_of_the_nvidia_rtx_2070/,fsher,1539901233,,1,1
49,2018-10-19,2018,10,19,11,9pfirb,Program prerequisites?,https://www.reddit.com/r/tensorflow/comments/9pfirb/program_prerequisites/,Bizobinator,1539914490,"I assume that TensorFlow requires that you have Python already installed on your system?
",1,1
50,2018-10-19,2018,10,19,23,9pkilm,Gathering data for tensorflow,https://www.reddit.com/r/tensorflow/comments/9pkilm/gathering_data_for_tensorflow/,teaspoonasaurous,1539960603," 

Hi,

I am putting together a project that will hopefully be able to ID mountains in photos using Tensorflow. To do this I need to create a whole load of training data which I was putting together with Bing image search API. I'm not the worlds greatest at python and I was having an issue with trying to pass the names of mountain to argparse, create a directory cd into the directory and then download the images to that file.

`# import the necessary packages`

`from requests import exceptions`

`import argparse`

`import requests`

`import cv2`

`import os`

`import csv`

`def mountain():`

`with open('1,500 Mountains.csv') as csvfile:`

`readCSV = csv.reader(csvfile, delimiter=',')`

`print (readCSV)`

`def makemydir(mountain):`

`try:`

`os.makedirs()`

`except OSError:`

`pass`

`# let exception propagate if we just can't`

`# cd into the specified directory`

`os.chdir()`

`# construct the argument parser and parse the arguments`

`ap = argparse.ArgumentParser()`

`ap.add_argument(""-q"", ""--query"", required=True,`

    `help=""search query to search Bing Image API for"")` 

`ap.add_argument(""-o"", ""--output"", required=True,`

    `help=""path to output directory of images"")` 

`args = vars(ap.parse_args())`

`# set your Microsoft Cognitive Services API key along with (1) the`

`# maximum number of results for a given search and (2) the group size`

`# for results (maximum of 50 per request)`

`API_KEY = ""your key goes here""`

`MAX_RESULTS = 250`

`GROUP_SIZE = 50`

`# set the endpoint API URL`

`URL = ""`  
[`https://api.cognitive.microsoft.com/bing/v7.0/images/search`](https://api.cognitive.microsoft.com/bing/v7.0/images/search)`""`",7,1
51,2018-10-20,2018,10,20,9,9ppebm,"Are you interested in Computer Science and want to start learning more with Tutorials? Check out this new Youtube Channel, called Discover Artificial Intelligence. :)",https://www.reddit.com/r/tensorflow/comments/9ppebm/are_you_interested_in_computer_science_and_want/,ailearn12,1539993841,,0,1
52,2018-10-21,2018,10,21,16,9q1pzo,Rant: It it just me or attempting to transition to eager/keras api is painful?,https://www.reddit.com/r/tensorflow/comments/9q1pzo/rant_it_it_just_me_or_attempting_to_transition_to/,muchlakin,1540106539,"I mean, I can't even figure out how to log gradients after 3 hours of looking.

/rant

ps. This is moot if the promise tf2.0 becomes reality. Thanks to all the devs working on the future, despite the fact that the present is pretty rough.",7,1
53,2018-10-22,2018,10,22,2,9q5ilp,Loading a model and understanding its structure.,https://www.reddit.com/r/tensorflow/comments/9q5ilp/loading_a_model_and_understanding_its_structure/,sud0er,1540144099,"Hi everyone, I've spent a good amount of time trying to accomplish this but still not fully understanding how to do it...

&amp;#x200B;

I have a directory contained a pre-trained model with the following files in it:

`checkpoint`

`intent_classifier_tensorflow_embedding.ckpt.data-00000-of-00001`

`intent_classifier_tensorflow_embedding.ckpt.index`

`intent_classifier_tensorflow_embedding.ckpt.meta`

`intent_classifier_tensorflow_embedding_encoded_all_intents.pkl`

`intent_classifier_tensorflow_embedding_inv_intent_dict.pkl`

`intent_featurizer_count_vectors.pkl`

`metadata.json`

`training_data.json`

I'd like to load this model and know how many layers/nodes are contained within it and what their connections look like, along with any other useful information.

&amp;#x200B;

I've attempted to visualize it via tensorboard but unfortunately tensorboard hangs with a ""Computing PCA"" notification indefinitely.

&amp;#x200B;

There has to be any easy way to load this model and just get a print out of some of its key details, right?",2,1
54,2018-10-22,2018,10,22,5,9q6mfj,"I'm using tensorflow for numerical calculations only, no training, how to disable gradient calculations?",https://www.reddit.com/r/tensorflow/comments/9q6mfj/im_using_tensorflow_for_numerical_calculations/,identicalParticle,1540152020,"I'm worried that tensorflow is calculating gradients and slowing things down, even though I will never use them.  I want to disable all gradient calculations.  Is there a way to do this?",2,1
55,2018-10-22,2018,10,22,6,9q7elf,Resulting inference graph doesn't even identify training data,https://www.reddit.com/r/tensorflow/comments/9q7elf/resulting_inference_graph_doesnt_even_identify/,ShadowOverseer1,1540157685,"Hey everybody. I was following [this](https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10#1-install-tensorflow-gpu-15-skip-this-step-if-tensorflow-gpu-15-is-already-installed) tutorial to try to build a CNN to identify yellow cubes. I used SSDLite MobileNet version 2 as the model, followed the instructions on the tutorial, trained for around 20 minutes (until loss hit around 1.2), and then stopped training. I then built an inference graph using export_inference_graph.py, set one of the test images as test1 in the object_detection folder, and ran the image detection script included with the tutorial.

However, it would *never* find the yellow cube. I tried the majority of the testing dataset and some of the training dataset, but it never once found the cube. It did find other things, though, like paper and a tub of plastic. It's like the training never even ran (even though I could clearly see loss dropping drastically over time). 

The process is a little finicky to say the least, due to versioning issues, so there were some warnings. The inference graph exportation process said something about ""incomplete shape"" a couple times, and there was some sort of error when I pressed Ctrl+C to stop training. So it might be related to that, but I have no idea where to go from there.

Here are some images of the results:
[Image 1](blob:https://imgur.com/ed0da841-aeba-4cfd-8f05-0fc7181d38ff)
[Image 2](blob:https://imgur.com/e62fbd44-ca44-425b-a9f5-d72a6ecc6d26)

Any help would be appreciated!",0,1
56,2018-10-23,2018,10,23,13,9qlo2s,Anaconda Stuck on Windows,https://www.reddit.com/r/tensorflow/comments/9qlo2s/anaconda_stuck_on_windows/,spot4992,1540269886,"I am trying to run the following in a conda prompt to get the package:

&amp;#x200B;

conda install -c anaconda tensorflow-gpu 

&amp;#x200B;

It gets stuck on solving environment forever, just spinning. I let it sit for 30 minutes, but nothing. I am not a complete moron when it comes to python, but I just want to mess around with style transfer on my GPU, so what would be an easy fix for this problem?

&amp;#x200B;

P.S. I didn't write my own style transfer, I'm trying to run a python script (program?) I found online. This was a listed package.",5,1
57,2018-10-24,2018,10,24,4,9qs7pm,Multiple Networks?,https://www.reddit.com/r/tensorflow/comments/9qs7pm/multiple_networks/,Skippertech,1540322686,"This isn't a very technical question, but following a tutorial like this: https://towardsdatascience.com/lstm-by-example-using-tensorflow-feb0c1968537

Where we build a LSTM to predict a fable. How would you go about building say a network of these? Say for different texts, to see if there is any simularity accross storys (I would imagine the network would start to pickup tendencies of the human language in general)

Almost like if you have 5 different fables, you would have 5 different neural networks that could share information. Does that make sense?

Anyone have something they could point me in the direction of that does something like this",1,1
58,2018-10-24,2018,10,24,22,9qzp6q,"Step by step series on Machine Learning using Tensorflow, github code link attached in the comments of the videos.",https://www.reddit.com/r/tensorflow/comments/9qzp6q/step_by_step_series_on_machine_learning_using/,iamarmaan,1540388027,,0,1
59,2018-10-24,2018,10,24,22,9qzseg,"Watching live Webcast : Introduction to Tensorflow, you can join as well.",https://www.reddit.com/r/tensorflow/comments/9qzseg/watching_live_webcast_introduction_to_tensorflow/,iamarmaan,1540388684,,0,1
60,2018-10-25,2018,10,25,4,9r32qd,What does tf.estimator.clip_gradients_by_norm exactly do?,https://www.reddit.com/r/tensorflow/comments/9r32qd/what_does_tfestimatorclip_gradients_by_norm/,tarunn2799,1540410830,"new to ML and I'm following the Machine Learning crash course by Google. I understand the basic concepts involved in training and prediction of models, except for this one part where they use tf.contrib.estimator.clip\_gradients\_by\_norm before performing stochastic gradient descent. Can someone please explain what this does and how I'm supposed to determine the parameters for it in my code? (in simple terms)",0,1
61,2018-10-25,2018,10,25,10,9r5yeo,How is loss calculated?,https://www.reddit.com/r/tensorflow/comments/9r5yeo/how_is_loss_calculated/,ShadowOverseer1,1540432111,How is loss calculated in tensorflow? Does it use testing or training data to calculate the loss?,3,1
62,2018-10-25,2018,10,25,19,9r946h,Practical Image Recognition with Tensorflow,https://www.reddit.com/r/tensorflow/comments/9r946h/practical_image_recognition_with_tensorflow/,carbonteq1,1540464050,,3,1
63,2018-10-26,2018,10,26,14,9ri2zh,"TF Estimator: to continue from a saved checkpoint, do you just set `warm_start_from` to the checkpoint directory? What about initializers?",https://www.reddit.com/r/tensorflow/comments/9ri2zh/tf_estimator_to_continue_from_a_saved_checkpoint/,BatmantoshReturns,1540532876,"I've read this from the official TF documentation

&gt; warm_start_from: Optional string filepath to a checkpoint or
&gt; SavedModel to warm-start from, or a tf.estimator.WarmStartSettings
&gt; object to fully configure warm-starting. If the string filepath is
&gt; provided instead of a tf.estimator.WarmStartSettings, then all
&gt; variables are warm-started, and it is assumed that vocabularies and
&gt; tf.Tensor names are unchanged.

https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator

So it seems that if I just put in the folder with the checkpoint, it will load those weights. But I am not sure because I am not sure what they  mean by 'warm-started'. Tensorflow has never used this terminology before regarding loading models from checkpoints. 

But my best interpretation is that if you provide a `warm_start_from` with the checkpoint directory, like so, 

    estimator = tf.estimator.DNNClassifier(
        feature_columns=[categorical_feature_a_emb, categorical_feature_b_emb],
        hidden_units=[1024, 512, 256],
        warm_start_from=""/path/to/checkpoint/dir"")

Then it will initialize the weights with it. 

Also, say that when you declare the variable, you have initializers, for example

    embeddings = tf.get_variable( 'embeddings', dtype=tf.float32,
        initializer= tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0, dtype=tf.float32) )

Without a Tf estimator, you would run an initializer like so if you are training for the first time.

    tf.global_variables_initializer().run() 

Otherwise you would just load a checkpoint

    saver.restore(session, './path/to/checkpoint/dir' )

And skip the initializer. 

Is something similar happening when TF.Estimators are used?


",0,1
64,2018-10-26,2018,10,26,21,9rk5p3,Advice on using AMD GPUs,https://www.reddit.com/r/tensorflow/comments/9rk5p3/advice_on_using_amd_gpus/,jsgui,1540555779,"I know there is other info on this, but I'm asking here in case anyone has up-to-date advice or links to working and easy to install and use code.

&amp;#x200B;

Maybe I will use NVIDIA, I'm not ruling that out. I want to find out what can be done with modern (RX 480) AMD GPUs, in order to use TensorFlow to support style transfer.

&amp;#x200B;

Though it's not TensorFlow, does anyone know if Torch or other AI libraries could be used with AMD to get style transfer working well?

&amp;#x200B;

Also, free online access to NVIDIA GPUs would help, does anyone know if there are still services (such as from Google) that would provide this?

&amp;#x200B;

Please don't blame me for not googling these things first - I have done, and want to get the latest info here from the r/tensorflow community.",5,1
65,2018-10-26,2018,10,26,23,9rl7yh,Motherfucking opensource tensorflow shit makes it near impossible to use for a real case scenario,https://www.reddit.com/r/tensorflow/comments/9rl7yh/motherfucking_opensource_tensorflow_shit_makes_it/,manual_mode,1540564205,"Mother fucking cock sucker open source shit as usual!

Let me begin. I am trying to build an autoencoder and i followed a tutorial. Great! i have a CS degree and took many machine learning courses. I know what the fuck an autoencoder is and i also work where i get paid real money and use C# and professional (with support) tools. I could build one from hand but im trying to be smart and not write everything from scratch and use pre-existing tools and i chose TensorFlow to being with because I know python quite well.

However, it seems that the people who wrote this shit get boners everytime they need to include the mnist dataset into EVERY FUCKING TUTORIAL! Have you ever thought of writing a fucking tutorial where you can show people how to use their own fucking images and load that shit up the model's asshole? Have you thought that not every fucking needed dataset exists in numpy arrays?

Below is a fucking tutorial i followed but we are not interested in using fucking numbers for an autoencoder where i work. I want to be able to load my own fucking images and put that shit into an autoencoder. 

This line in particular gives off a lot of boners to the nerds who wrote this shit: (x_train, _), (x_test, _) = mnist.load_data()

But the curse of open source shit is that there is no fucking documentation on how to use this shit in an environment where we dont give a shit about mnist data! Try go to tensor flows fucking webpage and type in autoencoder... jack shit! I cant figure out how to use TensorFlow's autoencoder model using my own fucking data

Anyways here is the code for the tutorial i am using and if anyone out here reading this shit could help me out I would be very grateful.

I have a bunch of images in this path on my workstation: S:/fucking_images/thermal.0001.jpg and it goes to thermal.6343.jpg

I want to train it on an autoencoder and see my generated outputs.

The code that works from a tutorial:

# this is the size of our encoded representations
encoding_dim = 32  # 32 floats -&gt; compression of factor 24.5, assuming the input is 784 floats

# this is our input placeholder
input_img = Input(shape=(784,))
# ""encoded"" is the encoded representation of the input
encoded = Dense(encoding_dim, activation='relu')(input_img)
# ""decoded"" is the lossy reconstruction of the input
decoded = Dense(784, activation='sigmoid')(encoded)

# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)

# this model maps an input to its encoded representation
encoder = Model(input_img, encoded)

# create a placeholder for an encoded (32-dimensional) input
encoded_input = Input(shape=(encoding_dim,))
# retrieve the last layer of the autoencoder model
decoder_layer = autoencoder.layers[-1]
# create the decoder model
decoder = Model(encoded_input, decoder_layer(encoded_input))

autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')

# prepare data using MNIST database
(x_train, _), (x_test, _) = mnist.load_data()

# normalize between 0 and 1
x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print (x_train.shape)
print (x_test.shape)

# train autoencoder for n epochs
autoencoder.fit(x_train, x_train,
                epochs=30,
                batch_size=256,
                shuffle=True,
                validation_data=(x_test, x_test))

# encode and decode some digits
# note that we take them from the *test* set
encoded_imgs = encoder.predict(x_test)
decoded_imgs = decoder.predict(encoded_imgs)


n = 10  # how many digits we will display
plt.figure(figsize=(20, 4))
for i in range(n):
    # display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()

",39,1
66,2018-10-27,2018,10,27,2,9rmz53,"Why do cuDNN input tensors have a ""time_len"" dimension?",https://www.reddit.com/r/tensorflow/comments/9rmz53/why_do_cudnn_input_tensors_have_a_time_len/,KjellJagland,1540576163,"I'm currently working on a DSP predictor for audio signals using a RNN made out of LSTM or GRU cells. The TensorFlow documentation suggested that one should use the cuDNN wrappers for optimal performance, so I started out with the following cell type:

[https://www.tensorflow.org/api\_docs/python/tf/contrib/cudnn\_rnn/CudnnLSTM#\_\_call\_\_](https://www.tensorflow.org/api_docs/python/tf/contrib/cudnn_rnn/CudnnLSTM#__call__)

I had a hard time figuring out what kind of input this RNN takes. Neither the TensorFlow documentation nor the cuDNN documentation seem to explain or even mention this but the call operator takes 3D input tensors with the following dimensions:

[https://github.com/tensorflow/tensorflow/blob/r1.11/tensorflow/contrib/cudnn\_rnn/python/layers/cudnn\_rnn.py#L379](https://github.com/tensorflow/tensorflow/blob/r1.11/tensorflow/contrib/cudnn_rnn/python/layers/cudnn_rnn.py#L379)

It's different from  the way, say, the Keras LSTM and GRU implementations work but it still makes perfect sense to me. Now, the thing I found rather puzzling is the ""time"" dimension. What's that all about? Is this just a dimension added for convenience, since many LSTM networks deal with time-sensitive data, with \[x, 1, y\] and \[1, x, y\] boiling down to the same thing? Is it just an additional way of structuring batches or does it have a deeper meaning?

Some of my initial tests resulted in unexpected memory constraints and performance issues when I swapped the the first and the second dimension so I might be completely mistaken, which is why I'm asking.

Thanks for your input!",0,1
67,2018-10-27,2018,10,27,22,9rua1g,Tensorflow saving and loading model,https://www.reddit.com/r/tensorflow/comments/9rua1g/tensorflow_saving_and_loading_model/,Jandevries101,1540647244," 

I am using Python 3 to code my Tensorflow model. i have some issues surrounding the loading and saving a model. i've did research and made this function out of it:

       def SaveDing():
    
        print(checksavedmodelexists[0])
        print(""printed checksavedmodelexists"")
    
    
        my_file = Path(""C:\\Users\\Gebruiker\\Downloads\\model.ckpt.index"")
    
        if not checksavedmodelexists[0]:
    
            checksavedmodelexists[0] = True
    
            if my_file.is_file():
    
                init_op = tf.global_variables_initializer()
    
                sess = tf.Session()
    
                sess.run(init_op)
    
                saver = tf.train.Saver()
    
                saver.restore(sess, ""C:\\Users\\Gebruiker\\Downloads\\model.ckpt"")
    
                print(""Loaded in previous Saved Model!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"")
    
            else:
    
                init_op = tf.global_variables_initializer()
    
                sess = tf.Session()
    
                sess.run(init_op)
    
                print(""Made a new Saved Model File"")
    
        else: 
    
            init_op = tf.global_variables_initializer()
    
            sess = tf.Session()
    
            sess.run(init_op)
    
            print(""Made a new Saved Model File"")
    
        return sess

what it should do is check if a model already exists or not if there isn't he creates a new model file if there is he should load in a new model. so when calling it with:

            saver = tf.train.Saver()
    
            session = tf.Session()
    
            save_path = saver.save(Class.SaveDing(), ""C:\\Users\\Gebruiker\\Downloads\\model.ckpt"")

to save the training model, he DOES save the model and i get the 3 files index,meta and data, but when i run the code again and call at the END when ALL variables are created i call:

    Class.SaveDing()

so that should then LOAD all the previous values in the tf variables, so that he can start from where it left of, i don't get any errors when doing this but i can clearly see that the values that are given aren't correct and just random.

**how can i make it that it uses the previous model to train further on / what is wrong with my code?**

thanks in advance for responding",1,1
68,2018-10-28,2018,10,28,7,9ryjtf,Why is tensorflow not 'object orientated',https://www.reddit.com/r/tensorflow/comments/9ryjtf/why_is_tensorflow_not_object_orientated/,pocketMAD,1540680977,,13,1
69,2018-10-28,2018,10,28,16,9s1lic,Question: Managing large number of feature names on tabular datasets for serializing to `TFRecords` and for ingesting to `tf.data()`,https://www.reddit.com/r/tensorflow/comments/9s1lic/question_managing_large_number_of_feature_names/,krishnab75,1540713243,"Hey Folks. I am still just getting use to \`Tensorflow,\` but I had question that was more based on experience rather than technical documentation. So I have a tabular dataset with about 100 features. Now if I want to serialize that dataset to TFRecords format, I have to indicate the column name and the data type (BytesList, Int64List, FloatList). Then for ingesting that same data, I can use the \`[tf.data](https://tf.data)()\` API, but again I have to pass a parsing function that converts the different features in the TFRecords format into a format that \`Tensorflow\` will understand. So I have to indicate whether an \`tf.Example()\` is \`tf.FixedLenFeature()\` or \`tf.VarLenFeature()\`, and I have to specify its data type and name again. Finally, I have to specify more information on the same features to create the \`tf.feature\_column()\` specification for each feature. 

&amp;#x200B;

So it seems that maintaining a list of hard coded values for each of these steps is pretty redundant and really fragile--since one change in a column will break my pipeline. 

&amp;#x200B;

I was just wondering how other folks handle this problem? How do you manage importing and serializing features and keeping data integrity over the different settings for the features? For example do people use some kind of column naming convention and then sort things by bytelist, int64list, and floatlist by the naming convention? Or do they keep this data in some other csv file and pull it in when needed? Any tips or suggestions would be appreciated. 

&amp;#x200B;

&amp;#x200B;",0,1
70,2018-10-29,2018,10,29,3,9s5l5t,Loading weights one layer at a time,https://www.reddit.com/r/tensorflow/comments/9s5l5t/loading_weights_one_layer_at_a_time/,anilmaddala,1540752400,"I want to run a tensorflow model on Raspberry pi and the model size is a constraint.

Is it possible to load the weights of only one layer at a time, do the forward pass for that layer and load the weights of the next layer to do the forward pass?

This way, the RAM of the hardware device will become less of a problem. The inference might be slow but is there an option in Tensorflow to achieve this?",6,1
71,2018-10-30,2018,10,30,7,9shs5p,"For anyone looking to get into machine learning, I would advise that you don't learn the behemoth libraries like Tensorflow or Theano, but instead learn how to use a high-level API like Keras. Here's a quick video to explain what it is. Hope I was helpful!",https://www.reddit.com/r/tensorflow/comments/9shs5p/for_anyone_looking_to_get_into_machine_learning_i/,antaloaalonso,1540850736,,3,1
72,2018-10-30,2018,10,30,10,9sjc3w,Question about reading data in tensorflow,https://www.reddit.com/r/tensorflow/comments/9sjc3w/question_about_reading_data_in_tensorflow/,aditya_cplusplus,1540862205,"I have a training data set in a txt file as follows: 

**temperature, x1, y1, z1, x2, y2, z2, x3, y3, z3, potential\_energy**

potential\_energy is the label and the rest are features. I'm having difficulty in understanding how to load such data in tensorflow. According to the documentation, I tried to use the following way:

`dataset = tf.data.TextLineDataset(""features.txt"")`

`data_iterator = iter(dataset)`

`j = 0`

`for j in range(5):`

`print(next(data_iterator))`

The program displays the data, but how do I tell tensorflow that which column is the label and features etc?

Thanks

&amp;#x200B;",1,1
73,2018-10-30,2018,10,30,15,9slezg,How to train ResNet-50 on Cloud TPU with data streamed from Cloud Bigtable,https://www.reddit.com/r/tensorflow/comments/9slezg/how_to_train_resnet50_on_cloud_tpu_with_data/,fhoffa,1540881216,,0,1
74,2018-10-30,2018,10,30,22,9so0x8,Converting JPEG images on disk to TFRecords,https://www.reddit.com/r/tensorflow/comments/9so0x8/converting_jpeg_images_on_disk_to_tfrecords/,gokstudio,1540907122,"Hi Everyone,

I have a bunch of JPEGs on disk (tiny-imagenet) and I want to convert them to TFRecords to do efficient data feeding. Unfortunately, most tutorials and the TF website's [tf.data](https://tf.data) walkthrough starts with assuming you have TFRecords already but with no mention of how to create it.

  
I know that there are some code examples on how to preprocess imagenet images into TFRecords but I am specifically looking for documentations / walkthroughs on how to convert JPEGs into TFRecords.

Any suggestions?  
",3,1
