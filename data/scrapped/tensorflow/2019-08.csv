,sbr,sbr_id,date,year,month,hour,day,id,domain,title,full_link,author,created,selftext,num_comments,score,over_18,thumbnail,media_provider,media_thumbnail,media_title,media_description,media_url
0,tensorflow,t5_3alkk,2019-8-1,2019,8,1,16,ckkxet,blog.sicara.com,"Introducing tf-explain, Interpretability for TensorFlow 2.0",https://www.reddit.com/r/tensorflow/comments/ckkxet/introducing_tfexplain_interpretability_for/,raphaelmeudec,1564643171,,1,30,False,default,,,,,
1,tensorflow,t5_3alkk,2019-8-2,2019,8,2,1,ckqh7x,self.tensorflow,Relationship between RAM speed and CAS latency in TF performance on Ryzen 3900x?,https://www.reddit.com/r/tensorflow/comments/ckqh7x/relationship_between_ram_speed_and_cas_latency_in/,cosmic_cow_ck,1564676142,"Hi all, I'm building a rig to be used in large part for distributed computing and machine learning. Ryzen 3900x, Nvidia 2080ti, and all SSD to prevent I/O bottlenecks.  I'm trying to untangle the mysteries of RAM performance and how they'll affect the performance of the app(s) I'm planning to build, which will incorporate TensorFlow as well as some hombrew machine learning stuff. I'm planning to go with a 64GB kit. 

In real world performance, I suspect that CAS latency doesn't have much of an impact on TF and other Deep Learning/ML approaches since you're typically dealing with pretty large chunks of data, so my guess is that, say, 3600MHz ram of any CAS latency would work out better than tightly timed 3200cl14, for example, but that's just a hunch from my fairly surface-level understanding of how RAM timings and whatnot work. 

I will be doing some gaming on this rig and have a monitor that can take basically whatever I throw at it (1440p 144z, OC up to 165hz), but I'm more concerned with the machine learning side of things as far as performance is concerned.

Any assistance in understanding this stuff, and would be very greatly appreciated.",4,1,False,self,,,,,
2,tensorflow,t5_3alkk,2019-8-2,2019,8,2,5,ckthxu,self.tensorflow,Implementing a SumOfGaussians layer in Keras2.0,https://www.reddit.com/r/tensorflow/comments/ckthxu/implementing_a_sumofgaussians_layer_in_keras20/,zachmoshe,1564689734,"Following is my new blog post. This time I played a bit with the new beta version of TF and implemented a simple model where y is the sum of K gaussians which parameters are learned.

[http://zachmoshe.com/2019/08/01/sum-of-gaussians-layer-with-keras-2.0.html](http://zachmoshe.com/2019/08/01/sum-of-gaussians-layer-with-keras-2.0.html)",1,4,False,self,,,,,
3,tensorflow,t5_3alkk,2019-8-2,2019,8,2,6,ckuv2i,self.tensorflow,About to start using data augmentation for cnn training. Here's my workflow: any suggestions/advice? Not sure what I'm doing...,https://www.reddit.com/r/tensorflow/comments/ckuv2i/about_to_start_using_data_augmentation_for_cnn/,ml_runway,1564696095,"I am training a faster-rcnn to recognize clowns, using the object detection api. I have a lot of training images of clowns, and have drawn bounding boxes and saved them in associated xml file in Pascal VOC format (that contains information about the image, bounding boxes, their labels -- basically the output of labelimg).

My next step is I want to augment my training data.  I am new to tensorflow and cnns and am looking for any advice/feedback.

My goal here is to use imgaug (https://imgaug.readthedocs.io/en/latest/) to augment my training data. This also returns an appropriate bounding box. Hence I can create a new xml file (i.e., changing the image path and bounding boxes, but leaving the labels and everything else the same).

This way I can end up with a new set of image/xml file pairs to be part of my training data for my network.

Does this seem like a decent plan? If so, should I generate new augmented datasets every time I train my network, or just run through the augmentation procedure once generate N augmented images, and just have this be my new training data? Whatever I do, I will be generating TFRecord files to feed to my network for training as I'm using the object detection api. No big deal, just trying to give details of my workflow in case anyone has advice...",3,0,False,self,,,,,
4,tensorflow,t5_3alkk,2019-8-3,2019,8,3,1,cl60t4,self.tensorflow,Tons of Jupyter Notebooks to learn TensorFlow 2 for Computer Vision,https://www.reddit.com/r/tensorflow/comments/cl60t4/tons_of_jupyter_notebooks_to_learn_tensorflow_2/,Aldream,1564761710,,1,1,False,self,,,,,
5,tensorflow,t5_3alkk,2019-8-3,2019,8,3,1,cl67w4,github.com,Tons of Jupyter Notebooks to learn TensorFlow 2 for Computer Vision,https://www.reddit.com/r/tensorflow/comments/cl67w4/tons_of_jupyter_notebooks_to_learn_tensorflow_2/,Aldream,1564762596,,3,12,False,default,,,,,
6,tensorflow,t5_3alkk,2019-8-3,2019,8,3,2,cl7hqw,self.tensorflow,"[D] Do you have an idea for a machine learning library or framework that you'll probably never get around to making, and wish someone else would make it?",https://www.reddit.com/r/tensorflow/comments/cl7hqw/d_do_you_have_an_idea_for_a_machine_learning/,BatmantoshReturns,1564768446,"I'm going to a 2 day machine learning hackathon. 2 days isn't a lot of time to train a brand new model, so I'm hoping to make something that would assist other ML people. 2 days will probably just be enough time for a prototype with core functionality.

If it makes a difference, I'll be working in Pytorch.",4,2,False,self,,,,,
7,tensorflow,t5_3alkk,2019-8-3,2019,8,3,12,cle9ou,youtu.be,"Decomposition of Time Series into Trend, Seasonality &amp; Residual from Scratch",https://www.reddit.com/r/tensorflow/comments/cle9ou/decomposition_of_time_series_into_trend/,bhavesh91,1564804147,,0,1,False,https://b.thumbs.redditmedia.com/-gjNWPU7SAMIKPMYCzBm5hKd7QC0IjrStvyjJmPX68A.jpg,,,,,
8,tensorflow,t5_3alkk,2019-8-3,2019,8,3,15,clfmog,self.tensorflow,Store file inside protobuf of froxen network?,https://www.reddit.com/r/tensorflow/comments/clfmog/store_file_inside_protobuf_of_froxen_network/,geometrikal,1564813554,Is there anyway to store a file (e.g. some xml metadata) or other metadata (input / output tensor ops) inside a frozen graph's protobuf?,2,1,False,self,,,,,
9,tensorflow,t5_3alkk,2019-8-3,2019,8,3,23,cljhh0,self.tensorflow,How to train 1 model to detect multiple classes using multiple datasets,https://www.reddit.com/r/tensorflow/comments/cljhh0/how_to_train_1_model_to_detect_multiple_classes/,ski233,1564843376,Id like to see if its possible to train a single model using multiple datasets for object detection. Im currently using keras-retinanet for object detection on a custom dataset of roughly 6000 images. I have about 20 classes right now but I would like to add more classes however I dont want to have to go annotate every instance of the new class in my existing dataset so that all current instances dont count  as negative examples. What is the best way to add new classes without having to relabel the entire training dataset and just labeling a 1000 or so new images with the new class.,12,9,False,self,,,,,
10,tensorflow,t5_3alkk,2019-8-4,2019,8,4,3,clly32,self.tensorflow,[D]Load trained model,https://www.reddit.com/r/tensorflow/comments/clly32/dload_trained_model/,vratiner,1564856406,"Currently I am loading a previously trained model using

`with tf.Session() as sess:`  
`saver.restore(sess, tf.train.latest_checkpoint('./'))`  


which loads the file recorded in the file ""checkpoint"" that was created when saving the model. However, the file ""checkpoint"" always refers to the last trained model, so if I want to load another model I have to manually edit the ""checkpoint"" file to change the model name.

My question is, how can I restore a trained model different from the last one I created, without manually editing the ""checkpoint"" file?",0,1,False,self,,,,,
11,tensorflow,t5_3alkk,2019-8-4,2019,8,4,7,clouw0,self.tensorflow,Problem using tensorboard,https://www.reddit.com/r/tensorflow/comments/clouw0/problem_using_tensorboard/,Ste29ebasta,1564871726,"Hi, I hope i can ask you about an exercise, i'm new in this subreddit.

I'm currently learning tensorflow and i have tried to do a very simple exercise, I created 2 ReLU and applied them to an input X and summed the results. Then i saved the variables and tried to create a tensorboard graph. I know it doesn't make sense and i could have done the exercise writing a cleaner code, but it's just to learn how to use tf.

The reason i'm writing here is i can't show the graph on tensorboard, could you help me? I tried to do this exercise using google colab, so i know i can't use tensorboard directly, but i have to use ngrok, but i'm doing something wrong and i can't understand what...

&amp;#x200B;

This is the python book, it is very short  :)

&amp;#x200B;

[https://colab.research.google.com/drive/135MzZV-1nP7xPNl\_yrJKzQpT1vf4Clb7](https://colab.research.google.com/drive/135MzZV-1nP7xPNl_yrJKzQpT1vf4Clb7)",2,1,False,self,,,,,
12,tensorflow,t5_3alkk,2019-8-4,2019,8,4,8,clpe3q,self.tensorflow,Unity Ml-Agents ?,https://www.reddit.com/r/tensorflow/comments/clpe3q/unity_mlagents/,Stanley_C,1564874775,"Is this the right place to post Unity Ml-agents questions?

I tried posting on the Machine Learning subreddit, but no one really responds.",0,6,False,self,,,,,
13,tensorflow,t5_3alkk,2019-8-4,2019,8,4,22,clw6dq,self.tensorflow,"Sample from logits, but ignore certain classes.",https://www.reddit.com/r/tensorflow/comments/clw6dq/sample_from_logits_but_ignore_certain_classes/,scrapeslimeforfun,1564924510,"`tf.random.categorical` will sample a distribution based on logits. For example, `tf.random.categorical(np.array([[0, 0], [1, 0]], dtype='float32'), 5)` may produce:

    array([[0, 0, 0, 0, 1],
           [1, 0, 1, 0, 0]])&gt;

The problem that I have is the neural network outputs logits corresponding to actions, but certain actions are not always allowed. Is there a way so that if the input is \`\[500, 1, 0\]\` and \`\[0, 1, 1\]\`, then it will ignore the \`0\`th class and only ever output \`1\`s and \`0\`s?",1,1,False,self,,,,,
14,tensorflow,t5_3alkk,2019-8-4,2019,8,4,22,clwc5w,self.tensorflow,Jetson Nano or Raspberry Pi for object detection?,https://www.reddit.com/r/tensorflow/comments/clwc5w/jetson_nano_or_raspberry_pi_for_object_detection/,sirajuddin97,1564925545,"Hi, I'm learning TensorFlow and I'm planning to build an autonomous RC car using TensorFlow for object detection. I am currently deciding whether to buy a Jetson Nano or a Raspberry Pi (Pi 4 or Pi Zero) for the machine learning part of my project? The cost is not a problem, I'm thinking more about performance and reliability to process proper object detection. I am also planning to use ROS (Robot Operating System) and learn more about this operating system. Is this achievable on a Jetson Nano? 

I appreciate all your help. Thanks in advance!",5,1,False,self,,,,,
15,tensorflow,t5_3alkk,2019-8-5,2019,8,5,13,cm6b4u,youtu.be,Newer versions? At 6:30 has anyone looked into this recently?,https://www.reddit.com/r/tensorflow/comments/cm6b4u/newer_versions_at_630_has_anyone_looked_into_this/,cbat971,1564979215,,1,3,False,https://a.thumbs.redditmedia.com/FkYTugnAzrEKJI2s6xe9XXERaXEACaqhZ1xu_N2xlb0.jpg,,,,,
16,tensorflow,t5_3alkk,2019-8-5,2019,8,5,14,cm6zte,tutorialandexample.com,TensorFlow Tutorial for Beginners - TutorialAndExample,https://www.reddit.com/r/tensorflow/comments/cm6zte/tensorflow_tutorial_for_beginners/,pavan_kumar_sharma,1564983726,,1,1,False,default,,,,,
17,tensorflow,t5_3alkk,2019-8-5,2019,8,5,15,cm7ljp,self.tensorflow,What does an input specified after a keras layers means?,https://www.reddit.com/r/tensorflow/comments/cm7ljp/what_does_an_input_specified_after_a_keras_layers/,Laurence-Lin,1564988077,"For example, in this tutorial page:

[https://www.tensorflow.org/api\_docs/python/tf/keras/Input](https://www.tensorflow.org/api_docs/python/tf/keras/Input)  


It use y = Dense(shape)(x), while x is an tensor placeholder. 

What does this line means? Does this means that y tensor take x tensor as input?

It's not explain clear in official website, thanks!",3,1,False,self,,,,,
18,tensorflow,t5_3alkk,2019-8-5,2019,8,5,17,cm8795,self.tensorflow,"tflite_convert a Keras h5 model which has a custom loss function results in a ValueError, even if I add it in the Keras losses import",https://www.reddit.com/r/tensorflow/comments/cm8795/tflite_convert_a_keras_h5_model_which_has_a/,JarsOfJam-Scheduler,1564992659,"I have written a SRGAN implementation. In the entry point class of the Python program, I declare a function which returns a mean square using the VGG19 model:

`# &lt;!--- COST FUNCTION ---&gt;`

`def build_vgg19_loss_network(ground_truth_image, predicted_image):`

`loss_model = Vgg19Loss.define_loss_model(high_resolution_shape)`

`return mean(square(loss_model(ground_truth_image) - loss_model(predicted_image)))`



`import keras.losses`

`keras.losses.build_vgg19_loss_network = build_vgg19_loss_network`

`# &lt;!--- /COST FUNCTION ---&gt;`

&amp;#x200B;

(\`Vgg19Loss\` class shown further below)

&amp;#x200B;

As you can see, I have added this custom loss function in the import \`keras.losses\`. Why? Because I thought it could solve the following problem...: When I execute the command \`tflite\_convert --output\_file=srgan.tflite --keras\_model\_file=srgan.h5\`, the Python interpreter raises this error:

&amp;#x200B;

\&gt; raise ValueError('Unknown ' + printable\_module\_name + ':' + object\_name) ValueError: Unknown loss function:build\_vgg19\_loss\_network

&amp;#x200B;

However, it didn't solve the problem. Any other solution which could work?

&amp;#x200B;

Here is the \`Vgg19Loss\` class:

&amp;#x200B;

`from keras import Model`

`from keras.applications import VGG19`





`class Vgg19Loss:`

`def __init__(self):`

`pass`



`@staticmethod`

`def define_loss_model(high_resolution_shape):`

`model_vgg19 = VGG19(False, 'imagenet', input_shape=high_resolution_shape)`

`model_vgg19.trainable = False`

`for l in model_vgg19.layers:`

`l.trainable = False`

`loss_model = Model(model_vgg19.input, model_vgg19.get_layer('block5_conv4').output)`

`loss_model.trainable = False`

`return loss_model`",1,1,False,self,,,,,
19,tensorflow,t5_3alkk,2019-8-5,2019,8,5,18,cm8msu,rubikscode.net,Transformer with Python and TensorFlow 2.0  Attention Layers,https://www.reddit.com/r/tensorflow/comments/cm8msu/transformer_with_python_and_tensorflow_20/,RubiksCodeNMZ,1564996070,,4,17,False,https://b.thumbs.redditmedia.com/IjmKL0Z4ylyzOgmOnvBuKFQ7c_pNOljyW94LD-KIwZM.jpg,,,,,
20,tensorflow,t5_3alkk,2019-8-5,2019,8,5,18,cm8wbk,self.tensorflow,What is the difference between model.output and model.outputs?,https://www.reddit.com/r/tensorflow/comments/cm8wbk/what_is_the_difference_between_modeloutput_and/,Laurence-Lin,1564998088,"For an resnet50 model in keras.applications, there are output in official website:

model.outputs, which is a list of outputs. However, it seems to be another output model.output, which is an tensor. What's the difference between them?

List can't be used as input of some keras layer like globalAveragePooling2D.",0,1,False,self,,,,,
21,tensorflow,t5_3alkk,2019-8-5,2019,8,5,20,cm9oz1,self.tensorflow,I kept getting error 'Dense' object has no attribute 'op',https://www.reddit.com/r/tensorflow/comments/cm9oz1/i_kept_getting_error_dense_object_has_no/,Laurence-Lin,1565003936,"I'm creating a resnet and using keras.models.Model(input tensor, output tensor)

However this error message shows up, and after searching online I found it may be caused by the update keras version. Some solutions suggests that downgrade the keras will make success, but I would prefer another method. To downgrade the package version in order to use a function seems dumb and unconvenient, what is my other function requires newest version of keras?

My current keras version is 2.2.4 on jupyter notebook, hope someone could help with my problem . Thanks!",4,2,False,self,,,,,
22,tensorflow,t5_3alkk,2019-8-5,2019,8,5,21,cmajfb,self.tensorflow,Best way to analyse a software's logs with Machine Learning?,https://www.reddit.com/r/tensorflow/comments/cmajfb/best_way_to_analyse_a_softwares_logs_with_machine/,jvelez2210,1565009183," 

Hey guys!

I am new to Tensor Flow and I would appreciate if someone could point me in the right direction, in order to create a program that extracts the logs from the database in the cloud, and analyse them with Machine Learning in order to find unusual behaviours.

What kind of pre-made Tensorflow or Keras model is the best for this kind of problem?

Is supervised learning the best approach to solving this problem?

Thanks in advance,

Jos Velez",2,1,False,self,,,,,
23,tensorflow,t5_3alkk,2019-8-6,2019,8,6,3,cmendt,self.tensorflow,"Is there an object detection model, which can learn spatial information between instances?",https://www.reddit.com/r/tensorflow/comments/cmendt/is_there_an_object_detection_model_which_can/,2ringo,1565028893,"Hey guys,
i am wondering, if there is a model that can learn spatial information between instances. e.g. a hat has a high propability to be detected above a face. Is it possible for some models to use this kind of information? 
And if yes, are there also models already implemented in Keras?
I really appreciate your help. :)",3,4,False,self,,,,,
24,tensorflow,t5_3alkk,2019-8-6,2019,8,6,23,cmr43r,self.tensorflow,"How can I filter and balance a Windowed TensHow can I filter and balance a Windowed Tensorflow dataset with a binary classification label, based on the label?orflow dataset with a binary classification label, based on the label?",https://www.reddit.com/r/tensorflow/comments/cmr43r/how_can_i_filter_and_balance_a_windowed_tenshow/,slingshoota,1565100860,"I have an unbalanced tensorflow windowed dataset with labels (over 90% negative examples) which I am trying to balance by filtering. I am having trouble filtering as my windowed dataset with labels does not fall under the cases I have come across in my searches, or the tensorflow documentation.

I'm working on a model to predict a binary classification based on time series data. I start with a time series dataframe with a number of columns (price, volume, etc.) where each row is one minute.

Currently I am still stuck on filtering the different labels. My next step after filtering would be to get the size of both filtered datasets, find the smaller size (n), and then concatenate the smaller dataset with (n) elements from the bigger dataset, after shuffling the bigger dataset. This way I would have a balanced dataset with an equal number of 1 and 0 labels. If you have a better Idea I would be happy to hear it.

**EXPLAINING MY CODE:** DFrame is a pandas dataframe with columns such as price, volume, etc., and each row is a different minute, with the first row being the earliest/oldest time period. The last column of DFrame is the classifier 0 or 1.

I then create a tensorflow dataset from slices with the first input being all the DFrame columns except for the label which is in the last column, and the second input (the label) being the last column which is the classifier.

I then use the window function to create windows of size (hindsight) which is currently 512, meaning (If i'm not mistaken) it takes the previous 511 minutes as well as the current minute and uses this as a rolling window to associate with the label of the current minute. So my understanding is that x is then an array of 512 arrays, from the row of the current minute to the row of 511 minutes ago, and the y is the label of the current minute. So x is an array of 512 arrays (rows for each minute, from the dataframe), and y is just one integer, 1 or 0.

Ideally I would like to be able to apply the same balancing logic to a multiclass classification problem, where I essentially add additional labels for additional price movement ranges.

The error comes from the filter. The model seems to run without that, and even trains my keras model. as explained I would actually want to add more code after the filter once I get it working to balance the dataset but I need to filter it first.

    tensor= tf.data.Dataset.from_tensor_slices((tf.constant(DFrame[DFrame.columns.values[:-1]].values), tf.constant(DFrame[DFrame.columns.values[-1]].values)))
    tensor = tensor.window(hindsight,1,1,True)
    tensor = tensor.shuffle(1000)
    tensor = tensor.filter(lambda x,y: tf.equal(y, 0))
    tensor = tensor.flat_map(lambda x,y:tf.data.Dataset.zip((x.batch(hindsight), y.batch(1))))
    tensor = tensor.batch(Batch_size).prefetch(1)
    
    TypeError: Failed to convert object of type &lt;class 'tensorflow.python.data.ops.dataset_ops._VariantDataset'&gt; to Tensor. Contents: &lt;_VariantDataset shapes: (), types: tf.int64&gt;. Consider casting elements to a supported type.",0,2,False,self,,,,,
25,tensorflow,t5_3alkk,2019-8-7,2019,8,7,0,cmrzqj,self.tensorflow,"How can I filter and balance a Windowed Tensorflow dataset with a binary classification label, based on the label?",https://www.reddit.com/r/tensorflow/comments/cmrzqj/how_can_i_filter_and_balance_a_windowed/,slingshoota,1565105162,"I have an unbalanced tensorflow windowed dataset with labels (over 90% negative examples) which I am trying to balance by filtering. I am having trouble filtering as my windowed dataset with labels does not fall under the cases I have come across in my searches, or the tensorflow documentation.

I'm working on a model to predict a binary classification based on time series data. I start with a time series dataframe with a number of columns (price, volume, etc.) where each row is one minute.

Currently I am still stuck on filtering the different labels. My next step after filtering would be to get the size of both filtered datasets, find the smaller size (n), and then concatenate the smaller dataset with (n) elements from the bigger dataset, after shuffling the bigger dataset. This way I would have a balanced dataset with an equal number of 1 and 0 labels. If you have a better Idea I would be happy to hear it.

**EXPLAINING MY CODE:** DFrame is a pandas dataframe with columns such as price, volume, etc., and each row is a different minute, with the first row being the earliest/oldest time period. The last column of DFrame is the classifier 0 or 1.

I then create a tensorflow dataset from slices with the first input being all the DFrame columns except for the label which is in the last column, and the second input (the label) being the last column which is the classifier.

I then use the window function to create windows of size (hindsight) which is currently 512, meaning (If i'm not mistaken) it takes the previous 511 minutes as well as the current minute and uses this as a rolling window to associate with the label of the current minute. So my understanding is that x is then an array of 512 arrays, from the row of the current minute to the row of 511 minutes ago, and the y is the label of the current minute. So x is an array of 512 arrays (rows for each minute, from the dataframe), and y is just one integer, 1 or 0.

Ideally I would like to be able to apply the same balancing logic to a multiclass classification problem, where I essentially add additional labels for additional price movement ranges.

The error comes from the filter. The model seems to run without that, and even trains my keras model. as explained I would actually want to add more code after the filter once I get it working to balance the dataset but I need to filter it first.

    tensor= tf.data.Dataset.from_tensor_slices((tf.constant(DFrame[DFrame.columns.values[:-1]].values), tf.constant(DFrame[DFrame.columns.values[-1]].values)))
    tensor = tensor.window(hindsight,1,1,True)
    tensor = tensor.shuffle(1000)
    tensor = tensor.filter(lambda x,y: tf.equal(y, 0))
    tensor = tensor.flat_map(lambda x,y:tf.data.Dataset.zip((x.batch(hindsight), y.batch(1))))
    tensor = tensor.batch(Batch_size).prefetch(1)
    
    TypeError: Failed to convert object of type &lt;class 'tensorflow.python.data.ops.dataset_ops._VariantDataset'&gt; to Tensor. Contents: &lt;_VariantDataset shapes: (), types: tf.int64&gt;. Consider casting elements to a supported type.",2,1,False,self,,,,,
26,tensorflow,t5_3alkk,2019-8-7,2019,8,7,1,cmt637,self.tensorflow,can I use tensorflow from an nvidia 1060 6 GB FROM a VM (win 10 host)? anything I need to know/do?,https://www.reddit.com/r/tensorflow/comments/cmt637/can_i_use_tensorflow_from_an_nvidia_1060_6_gb/,remotepie0,1565110653,"Hi,  (terminology: host means the bare metals computer that boots for example I am runnign windows 10, that's what I booted into - guest is the computer within a VM like if I run a vm and install linux within it then linux is the guest OS.)

I'm curious if I would have any detriment from running my machine learning stuff on tensorflow but from within a VM within my host, Windows 10.  I have a 6 GB nvidia 1060 card.  I can imagine the VM either can, or can't, just directly pass through the stuff that needs on the card.

What do I need to know?

1.  i.e. what VM can I use (such as Parallels Desktop 14, Oracle VM Virtualbox, VMware Fusion and Workstation?)

2.  Do I need to configure anything special to make the pass-through work properly?

3.  I use windows 10 as the host, but since I am learning about machine learning for the first time I am curious about what guest(s) would be appropriate - also windows 10, or is linux much better?  Which Linux?

I have 16 GB of RAM on the host computer and heard that deep learning doesn't take much ram, so I plan to just give 4 GB to my guest machine.

If this setup is unlikely to work well please let me know.  I suppose I can run the things I'm learning about directly on my host comptuer.  The reason I would not like to do this is to keep from adding things to my computer as I install all the tooling I would use.  For example I woudl prefer not to install python and tensorflow on my (host) computer, just within the guest.  Additionally, I kind of have the idea that later I could upload my guest to the cloud and scale out my learning algorithms without configuring anything else, almost like if I had it as a docker thing.  but this could be kind of stupid.

please let me know what I need to know to use tensorflow.  thanks.",6,2,False,self,,,,,
27,tensorflow,t5_3alkk,2019-8-7,2019,8,7,6,cmw745,self.tensorflow,Improving Performance with Pose Estimation,https://www.reddit.com/r/tensorflow/comments/cmw745/improving_performance_with_pose_estimation/,eco_bach,1565125673,"My Pose Estimation demo works but getting 1 frame every 2-4 seconds with canned  1080p video!

Here are my specs

hardware + driver

GeForce GTX 960M
Driver version 431.60
Intel Core i7 6700HQ CPU 2.6 GHz
15.87 GB RAM

Software
Windows 10
CUDA 10.0
Python 3.6.8
tensorflow 1.14.0


Questions
1. I had to comment out the line

import tensorflow.contrib.tensoort as trt

to avoid compile errors.

Could this be causing my performance issues?

2. I have both tensorflow and tensorflow-gpu installed. How do I know which one I am running?

3. What other steps should I take to help troubleshoot performance?",1,0,False,self,,,,,
28,tensorflow,t5_3alkk,2019-8-7,2019,8,7,9,cmymyj,self.tensorflow,TF not using GPU,https://www.reddit.com/r/tensorflow/comments/cmymyj/tf_not_using_gpu/,AnomalyNexus,1565137602,"Slightly stuck as to why my TF isn't using the GPU, despite being able to see it.  Looking at taskmanager it just ramps up the CPU to 100.

**tf.test.is_gpu_available()**

    2019-08-07 00:55:18.368708: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
    2019-08-07 00:55:18.376387: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library nvcuda.dll
    2019-08-07 00:55:18.486204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:
    name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705
    pciBusID: 0000:01:00.0
    2019-08-07 00:55:18.494578: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
    2019-08-07 00:55:18.501806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
    2019-08-07 00:55:19.320593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
    2019-08-07 00:55:19.326742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0
    2019-08-07 00:55:19.330434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N
    2019-08-07 00:55:19.335187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:0 with 2107 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)
    

**device_lib.list_local_devices()** shows the same plus this:

    [name: ""/device:CPU:0""
    device_type: ""CPU""
    memory_limit: 268435456
    locality {
    }
    incarnation: 15561824217549069569
    , name: ""/device:GPU:0""
    device_type: ""GPU""
    memory_limit: 2209624883
    locality {
      bus_id: 1
      links {
      }
    }
    incarnation: 6125462996487256078
    physical_device_desc: ""device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1""
    ]

Any ideas? 

Maybe a version mismatch? TF2 GPU beta, CUDA 10.1 and CudNN 7.6.",10,8,False,self,,,,,
29,tensorflow,t5_3alkk,2019-8-8,2019,8,8,5,cnbgcy,github.com,"convert video data (.avi, .mp4 etc.) to TensorFlow tfrecords",https://www.reddit.com/r/tensorflow/comments/cnbgcy/convert_video_data_avi_mp4_etc_to_tensorflow/,whiletrue2,1565211003,,0,10,False,https://b.thumbs.redditmedia.com/VW8y5QsjQgHM0KUowot32ISdJDwFd92hhfcruIcAkQM.jpg,,,,,
30,tensorflow,t5_3alkk,2019-8-8,2019,8,8,8,cndby0,self.tensorflow,How to interact with model in C++ Program,https://www.reddit.com/r/tensorflow/comments/cndby0/how_to_interact_with_model_in_c_program/,tobias1012,1565220087,"i have a trained model in python that i want to interact with in a QT program written in C++, it's important that the end user have the trained model and not contacting a server, what is the best approach to this?",4,4,False,self,,,,,
31,tensorflow,t5_3alkk,2019-8-8,2019,8,8,17,cnimo2,self.tensorflow,Gui or command line OS,https://www.reddit.com/r/tensorflow/comments/cnimo2/gui_or_command_line_os/,iacoposk8,1565251690,"Hello everyone! is there a big difference in training times if I launch my operating system (ubuntu) with the graphical interface or only with the command line?  
thank you",1,1,False,self,,,,,
32,tensorflow,t5_3alkk,2019-8-8,2019,8,8,20,cnkhw1,self.MachineLearning,"[P] Conditional Density Estimation Python Package and Large Benchmark with Neural Networks (MDN, KMN, Normalizing Flow) and Non-/Semi-parametric estimators",https://www.reddit.com/r/tensorflow/comments/cnkhw1/p_conditional_density_estimation_python_package/,whiletrue2,1565264194,,0,2,False,default,,,,,
33,tensorflow,t5_3alkk,2019-8-8,2019,8,8,20,cnkihw,self.MachineLearning,"[P] Implemented MPPI (Model Predictive Path Integral) in Python with OpenAI Gym pendulum environment (paper: ""Information Theoretic MPC for Model-Based Reinforcement Learning"", Williams et al., 2017)",https://www.reddit.com/r/tensorflow/comments/cnkihw/p_implemented_mppi_model_predictive_path_integral/,whiletrue2,1565264282,,1,5,False,default,,,,,
34,tensorflow,t5_3alkk,2019-8-8,2019,8,8,22,cnlsny,udemy.com,Tensorflow and Keras For Neural Networks and Deep Learning,https://www.reddit.com/r/tensorflow/comments/cnlsny/tensorflow_and_keras_for_neural_networks_and_deep/,luckyluck123luck,1565271014,,0,1,False,default,,,,,
35,tensorflow,t5_3alkk,2019-8-8,2019,8,8,22,cnm1dw,self.tensorflow,"Cats vs. Dogs classification hangs at 50%, thinks everything's a dog (ConvNet)",https://www.reddit.com/r/tensorflow/comments/cnm1dw/cats_vs_dogs_classification_hangs_at_50_thinks/,BowDown097,1565272195,"The details:
As mentioned in the title, this is a ConvNet classifying cats vs. dogs, using a dataset made by myself with different image sizes, to give myself a challenge resized to 80x60 and grayscaled. To attempt to solve this issue, I've tried changing the learning rate, testing parameters in layers of the model like kernel_regularizer, adding layers, removing layers, changing the # of filters in the layers, and yet it still thinks everything's a dog.

Testing the model with MNIST (slightly modified so it works) produces a different result, but still not what's expected. Has an accuracy of ~10%. With other cats vs. dogs datasets of the same nature, the result is the same; 50% accuracy and everything's a dog. So, I've concluded the problem's with the model.

The code:
https://pastebin.com/DszbeJjt

If you haven't guessed already, I'm quite new at this, so I'm wondering.. is there a good way to debug the issue with my model? How could I figure out why it doesn't properly learn, or could somebody point out why this is?",9,8,False,self,,,,,
36,tensorflow,t5_3alkk,2019-8-9,2019,8,9,18,cnzzvg,self.tensorflow,How do you think about HUAWEI's Harmony OS? Android replacement?,https://www.reddit.com/r/tensorflow/comments/cnzzvg/how_do_you_think_about_huaweis_harmony_os_android/,makereven,1565343161,"At today's Huawei Developer Conference, the company's Consumer Business Group CEO Richard Yu surprised the audience by unveiling ""Harmony OS,"" which is said to be faster and safer than Android.",2,0,False,self,,,,,
37,tensorflow,t5_3alkk,2019-8-10,2019,8,10,0,co3vfn,self.tensorflow,Tensorflow 2.0 / Ubuntu 18.04 LTS / RTX 2070 Super / CUDA not enabled,https://www.reddit.com/r/tensorflow/comments/co3vfn/tensorflow_20_ubuntu_1804_lts_rtx_2070_super_cuda/,nQFbsxw,1565364293,"**GPU:** RTX 2070S FE

**Operating System &amp; Version:**  Ubuntu 18.04.03 LTS

**GPU Drivers:** nvidia-driver-430

**Tensorflow Version:**   tensorflow-gpu==2.0.0-beta1

**Description of Problem:**

I'm having trouble getting tensorflow-gpu to run correctly.

Installation process [here](https://www.tensorflow.org/install/gpu), worked without problems (only change I did was using driver 430 instead of 418 (earliest driver that officially supports the 2070S. i tried 418, but the GPU is not detected, as expected).

When actually running a model, it breaks down with errors. Here an error for a model with an LSTM Layer:

    UnknownError:  [_Derived_]  Fail to find the dnn implementation.
    	 [[{{node CudnnRNN}}]]
    	 [[bidirectional/StatefulPartitionedCall_1]]
    	 [[Adam/Adam/update/mul_4/_36]] [Op:__inference_keras_scratch_graph_3260]

Then I noticed that the 2070S is [not listed](https://developer.nvidia.com/cuda-gpus) on the list of CUDA enabled devices.

Now I'm wondering if anyone got tensorflow / CUDA running on a 2070S or if I did something wrong..",18,5,False,self,,,,,
38,tensorflow,t5_3alkk,2019-8-10,2019,8,10,3,co6dwf,self.tensorflow,Music Classification,https://www.reddit.com/r/tensorflow/comments/co6dwf/music_classification/,CharlesAverill20,1565375151,"Hello!

I'm a band student, and a concept that I heard from a band director states that every song ever written can fit into one of two categories: ""Love"" or ""Pirates"". I've found that the theory holds up pretty well, however there are some songs that fit into both groups or are on the fence. I wanted to create a classifier that will output something like ""Love: 40% Pirates: 60%"", however my TF experience is strictly limited to image processing. Are there any projects that have already been started that can put me on the right path? If not, what are some first steps I could take?

&amp;#x200B;

Thank you!",10,6,False,self,,,,,
39,tensorflow,t5_3alkk,2019-8-10,2019,8,10,5,co7s9w,self.tensorflow,TensorFlow vs TensorFlow Lite for Feature Extraction,https://www.reddit.com/r/tensorflow/comments/co7s9w/tensorflow_vs_tensorflow_lite_for_feature/,LucidSnow,1565381368,I want to be able to identify and extract specific features from objects recognized. Would TensorFlow Lite be able to do this or do i need to use the full TensorFlow?,4,7,False,self,,,,,
40,tensorflow,t5_3alkk,2019-8-11,2019,8,11,1,cokigz,self.tensorflow,Pre-trained person model,https://www.reddit.com/r/tensorflow/comments/cokigz/pretrained_person_model/,Snoocto,1565456122,"Anyone knows where I can find a good pre trained model for person detection and also for tflite ?   


Thanks",0,1,False,self,,,,,
41,tensorflow,t5_3alkk,2019-8-11,2019,8,11,2,cokn5g,reddit.com,New subreddit specifically for TensorFlow.js (JavaScript/browser version of TensorFlow) - /r/TensorFlowJS,https://www.reddit.com/r/tensorflow/comments/cokn5g/new_subreddit_specifically_for_tensorflowjs/,wildcamp,1565456755,,0,2,False,default,,,,,
42,tensorflow,t5_3alkk,2019-8-11,2019,8,11,3,colt4k,self.tensorflow,I am new to tensorflow .. and I don't understand the layers very well,https://www.reddit.com/r/tensorflow/comments/colt4k/i_am_new_to_tensorflow_and_i_dont_understand_the/,LAVIAN_FOX,1565462265,"So you have tensorflow.keras.layers then you specify the layers you wanna add to the neural network buy I don't understand them

What is a flatten layer,
A dense layer,
A dropout layer?

In terms of a neural network..",4,8,False,self,,,,,
43,tensorflow,t5_3alkk,2019-8-12,2019,8,12,10,cp5caa,self.tensorflow,DNN Classifier to tflite,https://www.reddit.com/r/tensorflow/comments/cp5caa/dnn_classifier_to_tflite/,creativekinase,1565572506,"Having some trouble converting my model to a tflite (and freezing it first).

Does anyone have code that converts a DNN classifier to tflite?",0,1,False,self,,,,,
44,tensorflow,t5_3alkk,2019-8-12,2019,8,12,12,cp6rcn,self.tensorflow,Neural network inference pipeline for videos in Tensorflow,https://www.reddit.com/r/tensorflow/comments/cp6rcn/neural_network_inference_pipeline_for_videos_in/,alseambusher,1565580201,"Just as we saw a huge influx of images in the past decade or so, we are now seeing a lot of videos being produced on social media. The need to understand and moderate videos using machine learning has never been greater.

In this post, I will show you how to build an efficient pipeline to processes videos in Tensorflow.

https://lifepluslinux.blogspot.com/2019/08/neural-network-inference-pipeline-for.html",2,12,False,self,,,,,
45,tensorflow,t5_3alkk,2019-8-12,2019,8,12,18,cpa010,self.tensorflow,Tensorflow Object Detection API not labeling anything at all,https://www.reddit.com/r/tensorflow/comments/cpa010/tensorflow_object_detection_api_not_labeling/,NahiyanAlamgir,1565601888,"I've trained a model ([faster\_rcnn\_inception\_v2\_coco](http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz)) to detect car registration plates, with over 340 images (equipped with labels, totaling 100+ MB). Training continued for around 11-12 hours on my MacBook Pro. As you can guess, I used TensorFlow CPU, version 1.14. You can see the graphs below as shown on the Tensorboard:

[Tensorboard graphs.](https://i.redd.it/akhh2r9sizf31.png)

The problem is that when I run the tests, none of them show any labels; not a single label can seen on any of the test images. I tried testing with training images too, still no label; it's unable to detect any object. I can run the example code provided with Tensorflow just fine; even tried using the same code with modifications, but it made no difference.  


Can someone guess what could go wrong here? Do I need to continue the training for few more days?",10,2,False,self,,,,,
46,tensorflow,t5_3alkk,2019-8-13,2019,8,13,6,cpj6ic,self.tensorflow,NVIDIA Jetson Nano Developer Kit,https://www.reddit.com/r/tensorflow/comments/cpj6ic/nvidia_jetson_nano_developer_kit/,HenslerSoftware,1565646496,"Has anyone had success training an object detection model on the [NVIDIA Jetson Nano Developer Kit](https://developer.nvidia.com/embedded/jetson-nano-developer-kit)?

How much of a power boot would this give over just using a CPU to train a model?",9,16,False,self,,,,,
47,tensorflow,t5_3alkk,2019-8-13,2019,8,13,8,cpkhvg,self.tensorflow,[D] Best method to get tensorflow2 questions answered,https://www.reddit.com/r/tensorflow/comments/cpkhvg/d_best_method_to_get_tensorflow2_questions/,davidkwho,1565652515,"I am doing academic research in deep-learning.  Since April, I have been building models in tensorflow2, such that I can train resnets, implement custom layers/models and compute custom gradient and loss functions in both eager and graph mode.   At this point, I wanted to tackle more tricky issues.  

In particular, I posted this question on stack overflow (see below).  I have no response so far, not even an upvote or a me\_too comment.  I was wondering whether 1) that is the right place to get help, 2) is tensorflow2 in a such a premature state that no one is really looking seriously at it for training/deployment, and 3) are all academic researchers doing their work in pytorch so that I am pretty much on my own.

Any words of wisdom are much appreciated, thanks!

 [https://stackoverflow.com/questions/57421766/plotting-subclassed-model-in-tensorflow-2-0-beta](https://stackoverflow.com/questions/57421766/plotting-subclassed-model-in-tensorflow-2-0-beta)",1,2,False,self,,,,,
48,tensorflow,t5_3alkk,2019-8-13,2019,8,13,13,cpo3jy,self.tensorflow,Direct Graphic Input and Real Time Commands,https://www.reddit.com/r/tensorflow/comments/cpo3jy/direct_graphic_input_and_real_time_commands/,enlighten2011,1565670746,"Is it possible for TensorFlow to be applied in a way similar to AlphaZero? 

If it can't then the rest of my question(s) is invalid. It's not really games that interest me, but let me try to describe my thought process for why I want to learn TensorFlow and what I think it can do. In a broad sense I feel like TensorFlow should be able to analyze direct graphics card input, right? If so, I feel like it should be easier than coding it to employ true computer vision using external optics since that would have a 3d axis to deal with and the camera would be a separate interface.

Second, can TensorFlow utilize graphic data to output data in real time? 

Also, how well, if at all, does TensorFlow interface with external or 3d party programs, and are the processes I described difficult to implement?

Of course I could be wrong in understanding how AlphaZero works as well. Maybe, since chess is simple it doesn't need to take-in visual inputs and can simply read chess as code without translating visual data into code. If that's the case, can TensorFlow read memory and other aspects of programs in a similar way?",0,1,False,self,,,,,
49,tensorflow,t5_3alkk,2019-8-13,2019,8,13,23,cpu49t,self.tensorflow,Is object detection better at image classification than image classification?,https://www.reddit.com/r/tensorflow/comments/cpu49t/is_object_detection_better_at_image/,ski233,1565707561,"I read in an article that object segmentation can do object detection better than object detection algorithms. I assume this is because there is more detailed information in the annotation images. I was wondering if this is true for object detection and multiclass image classification as well. If you just take the label and quantity of each label from object detection, does it perform better than multiclass image classification?",10,6,False,self,,,,,
50,tensorflow,t5_3alkk,2019-8-14,2019,8,14,20,cq89hx,self.tensorflow,Nvidia Super GPUs vs Ti,https://www.reddit.com/r/tensorflow/comments/cq89hx/nvidia_super_gpus_vs_ti/,blezt,1565781477,Has anyone seen comparisons of the new Super GPUs vs the older Ti models? I'm building a new rig based around a Ryzen 9 3900x and I want to know which GPU I should buy. I would like the most Bang for my Buck. I'm debating between the 2080 Super and the 1080 Ti. Anyone have any opinions or performance graphs? Thanks!,8,1,False,self,,,,,
51,tensorflow,t5_3alkk,2019-8-14,2019,8,14,20,cq8ntc,tech.courses,Plotting TensorFlow.js Activation Functions,https://www.reddit.com/r/tensorflow/comments/cq8ntc/plotting_tensorflowjs_activation_functions/,wildcamp,1565783949,,0,3,False,https://b.thumbs.redditmedia.com/Lcyw9D8r4s-mK-lDhnvZUS04mTkDOvJwxAxwXse44nQ.jpg,,,,,
52,tensorflow,t5_3alkk,2019-8-14,2019,8,14,23,cqako6,self.tensorflow,Quick question about Model.Predict (sequential model),https://www.reddit.com/r/tensorflow/comments/cqako6/quick_question_about_modelpredict_sequential_model/,HoustonWarlock,1565793583," LSTM with a one step phase shift.

When I provide a batch of test data (in my case batch size 12) to use for inference. The output creates an equivalent 12 batch size output. 

I thought the last part of my prediction is the actual prediction. But when I graph the prediction it looks like the entire set of 12 is a prediction on the provided batch. Is that correct?

If I want a single step should I be providing an input of 1 batch size?",6,1,False,self,,,,,
53,tensorflow,t5_3alkk,2019-8-15,2019,8,15,0,cqbbjo,self.tensorflow,Optimizing tensorflow lite,https://www.reddit.com/r/tensorflow/comments/cqbbjo/optimizing_tensorflow_lite/,Snoocto,1565796903,"Hello,  I've just a question for object detection tflite. 
If my model has only one object, the dtection will be more speedly?",0,2,False,self,,,,,
54,tensorflow,t5_3alkk,2019-8-15,2019,8,15,1,cqbz95,self.tensorflow,Object detection 2.0,https://www.reddit.com/r/tensorflow/comments/cqbz95/object_detection_20/,somejob,1565799738,Am I correct in saying object detection is currently not supported in TF2.x? Tried to set a model training earlier today and apparently the contrib folder is gone?,2,1,False,self,,,,,
55,tensorflow,t5_3alkk,2019-8-15,2019,8,15,4,cqej0v,self.tensorflow,Is it worth learning TensorFlow 1 now that 2 is on the horizon?,https://www.reddit.com/r/tensorflow/comments/cqej0v/is_it_worth_learning_tensorflow_1_now_that_2_is/,Flamyngoo,1565810726,"Hi all! I wanted to get into TF and AI, Machine Learning in general but every course uses still the ""first"" TensorFlow of course, i heard 2 is quite different so would learning 1 even be worth it? Or maybe should i learn PyTorch or Keras for now until 2 matures a bit?",10,6,False,self,,,,,
56,tensorflow,t5_3alkk,2019-8-15,2019,8,15,19,cqnuyk,self.tensorflow,C development with tensorflow,https://www.reddit.com/r/tensorflow/comments/cqnuyk/c_development_with_tensorflow/,jregalad-o,1565863754,"Why is there such poor documentation on the tensorflow C api?   
I know TF was primarily developed to be used with a python front end. Nevertheless C remains a very important language in many areas. I've been hard at work trying to understand the C api, but I can only go so far without code examples and proper documentation.  
So far, this gist is the most complete guide into using the C api.  
[https://gist.github.com/asimshankar/7c9f8a9b04323e93bb217109da8c7ad2](https://gist.github.com/asimshankar/7c9f8a9b04323e93bb217109da8c7ad2)",3,5,False,self,,,,,
57,tensorflow,t5_3alkk,2019-8-16,2019,8,16,0,cqrftp,self.tensorflow,2070 vs 2060 Super and a question about batch sizes and memory,https://www.reddit.com/r/tensorflow/comments/cqrftp/2070_vs_2060_super_and_a_question_about_batch/,hardonchairs,1565883252,"The 2060 Super is apparently identical to the 2070 except for 2 out of every 36 CUDA cores being disabled and the clock speed being bumped up to compensate. In terms of tensorflow, is it better or have the cores or to have the clock speed? Or is the trade off pretty well recognized by tensorflow?

Question 2: If my training with batch sizes of 2 takes up about 3GB of GPU ram, can I expect batch sizes of 4 to take up ~6GB of ram or is it not a linear or consistent change in memory usage? I am using [ImageAI](https://github.com/OlafenwaMoses/ImageAI) custom object detection so I am not sure if ""batch sizes"" translates literally over to tensorflow.",15,8,False,self,,,,,
58,tensorflow,t5_3alkk,2019-8-16,2019,8,16,8,cqxty0,self.tensorflow,Tips on improving handwritten digits recognization?,https://www.reddit.com/r/tensorflow/comments/cqxty0/tips_on_improving_handwritten_digits_recognization/,bharddwaj,1565911388,"[https://github.com/bharddwaj/recognize\_handwritten\_digits](https://github.com/bharddwaj/recognize_handwritten_digits)

So in order to use a model trained on MNIST to recognize 'real' handwritten digits I did some preprocessing on images to make it look like an MNIST image itself; this way I can utilize the dataset and model. It works when i take the picture with my macbook camera close up, but when i used my phone camera I believe that the shadows/shadow removal mess up the picture. Was wondering what you guys think of this and/or if you had any tips to make the program better.",1,1,False,self,,,,,
59,tensorflow,t5_3alkk,2019-8-16,2019,8,16,8,cqy9r6,self.tensorflow,Where did the TensorFlow CNN Models Go?,https://www.reddit.com/r/tensorflow/comments/cqy9r6/where_did_the_tensorflow_cnn_models_go/,LucidSnow,1565913548,"[http://download.tensorflow.org/models/object\_detection/](http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz)

Where can I download the latest CNN models that were at this location?",2,2,False,self,,,,,
60,tensorflow,t5_3alkk,2019-8-16,2019,8,16,20,cr57s1,self.tensorflow,GPU RAM,https://www.reddit.com/r/tensorflow/comments/cr57s1/gpu_ram/,starbucksresident,1565955909,"I have read the docs but am I correct in my assumption?

GPU 0 default but will use RAM of other GPU s?

So a 1060/6 and I add a 1050ti/4 can I effectively have 10gb RAM transparent to the code?

And still using the 1060 only computationally and slowed only by the 1050 VRAM access?",7,1,False,self,,,,,
61,tensorflow,t5_3alkk,2019-8-16,2019,8,16,22,cr6i9v,self.tensorflow,[Testing] I did some naive test to bencmark my Models and it worked out very well,https://www.reddit.com/r/tensorflow/comments/cr6i9v/testing_i_did_some_naive_test_to_bencmark_my/,WideWorry,1565962810,"Hi,

I'm working a small project, which aimed to use Tensorflow for algoritmich trading as an enhancement or as a signal provider. I'm also using TensorflowJS Node, so don't be surprised that I will show codes writen in JS not in Py.

I had that problem that my Datas which are Timeseries mostly too noisy for getting any usefull result, but I also didn't trust much into my models that much.  
So I made a simple test to check which is my LSTM models could recognise an Ascending/Descending samples better.  
**My generator :**

\`\`\`  
 function create\_test\_data(count) {  
 let trade\_signals = \[\];  
 for (let i = 0; i &lt; count; i++) {  
 let rand = Math.random();  
 let buy\_in = \[\];  
 let hardening = 43124 \* Math.random();  
 if (rand &gt; 0.5) {  
 // Ascending  
 for (let k = 1; k &lt;= 11; k++) {  
 buy\_in.push(hardening + k \* Math.random() \* hardening);  
}  
} else {  
 // Descending  
 for (let k = 11; k &gt;= 1; k--) {  
 buy\_in.push(hardening - k \* Math.random() \* hardening);  
}  
}  
 trade\_signals.push({ buy\_price: 500, sell\_price: 1000 \* rand, buy\_in });  
  }  
 return \[trade\_signals\];  
}

\`\`\`  
**The Generated datas after MinMaxNormalization:**  
\`\`\`  
Test sample data:  {

  input: \[

\[ 0.06610051616063199 \],

\[ 0.18295973580639677 \],

\[ 0 \],

\[ 0.23400581891562033 \],

\[ 0.0013755938976750912 \],

\[ 0.2946169309488579 \],

\[ 0.583958052956012 \],

\[ 0.20029171242264848 \],

\[ 0.35248159617919556 \],

\[ 1 \],

\[ 0.9363863421672338 \]

  \],

  output: \[ 1, 0 \],

}

\`\`\`  
As you can see they aren't so clean like a 0,1,2,3,4,... but they definielty bring the ascending/descending attributions.  


Let's take a look on the code and structure of the models here:  
\- [https://github.com/stockmlbot/NodeTFJS/blob/master/src/tf\_models/tf\_models.js](https://github.com/stockmlbot/NodeTFJS/blob/master/src/tf_models/tf_models.js)  
*These models were selected and reimplemented into TFJS after I find them in various Python projects where they suposed to work.*  


After few Benchmark the results are the following (Examples are cherry picked):  


**1.** **lstm\_hibrid:** loss=0.0260 val\_loss=0.0213 Example out of sample datas: Pred: \[0.000006,0.999994\]  Real: \[0, 1\] **Passed!**  
**2. lstm\_hidden\_cells:** loss=0.0174 val\_loss=0.0268 Example out of sample datas: Pred: \[0.014, 0.985\]  Real: \[0, 1\] **Passed!**  
**3.** **lstm:** loss=5.94e-3 val\_loss=0.160  Example out of sample datas: Pred: \[0.734,0.265\] Real: \[0,1\] **Fail!**  
Conclusion:  
So, **lstm\_hibrid** and **lstm\_hidden\_cells** worked pretty much the same however the lstm\_hibrid seems get some advantage from the extra dense layers and never misstaken on the out of sample datas, but both can provide acceptable result. At learning speed lstm\_hidden\_cells  is a bit faster.  
The **lstm** model seems got some serious problem with overfitting, on out of sample datas it provide only garbage predictions.  


**Source code of the whole project:**  
\- [https://github.com/stockmlbot/NodeTFJS](https://github.com/stockmlbot/NodeTFJS)",0,1,False,self,,,,,
62,tensorflow,t5_3alkk,2019-8-17,2019,8,17,8,cree6e,self.tensorflow,Turning data (API) into article (text),https://www.reddit.com/r/tensorflow/comments/cree6e/turning_data_api_into_article_text/,wj14,1565998647,"The end result I'm aiming for is to give the program some stats from a sports game and then for it to produce a 300 word match report.

I know how to scrape and compile match reports from various games with the matching statistics. However, I'm trying to program a way using tensor flow that the AI can understand the transition from the statistics to producing a match report on them, having learnt from the previous transitioning examples.

Has anyone done this already, using tensor flow and can point me in the right directions...",3,4,False,self,,,,,
63,tensorflow,t5_3alkk,2019-8-18,2019,8,18,3,crpl23,tech.courses,Machine Learning in JavaScript with TensorFlow.js,https://www.reddit.com/r/tensorflow/comments/crpl23/machine_learning_in_javascript_with_tensorflowjs/,inspiredDeveloper,1566064874,,1,3,False,default,,,,,
64,tensorflow,t5_3alkk,2019-8-18,2019,8,18,17,crytb3,self.tensorflow,Which memory does TensorFlow consume when training?,https://www.reddit.com/r/tensorflow/comments/crytb3/which_memory_does_tensorflow_consume_when_training/,groudonRamsay,1566117650,"Hello, I have a Jetson Nano and I've been trying to train using the legacy [train.py](https://train.py). I can't help but notice that I very often see logs where it runs out of memory because I only have a couple hundred MBs left and it's trying to allocate memory for a tensor that's 1+ GB. 

I installed official TF-gpu, and this might be a dumb question, but doesn't that mean that when training, TF uses the GPU Memory and not the RAM?",10,5,False,self,,,,,
65,tensorflow,t5_3alkk,2019-8-19,2019,8,19,16,csdr7i,rubikscode.net,Transformer with Python and TensorFlow 2.0  Encoder &amp; Decoder,https://www.reddit.com/r/tensorflow/comments/csdr7i/transformer_with_python_and_tensorflow_20_encoder/,RubiksCodeNMZ,1566199828,,3,19,False,https://b.thumbs.redditmedia.com/ZxqB98EjUL-_X0HLm_Eo4Pp4m2b2z9sM7qoXn3CrZGg.jpg,,,,,
66,tensorflow,t5_3alkk,2019-8-19,2019,8,19,22,csgy2s,youtube.com,"Breast cancer diagnosis with neural networks, implemented with Keras and written in Python",https://www.reddit.com/r/tensorflow/comments/csgy2s/breast_cancer_diagnosis_with_neural_networks/,antaloaalonso,1566220588,,0,1,False,default,,,,,
67,tensorflow,t5_3alkk,2019-8-19,2019,8,19,23,cshx5v,self.tensorflow,Tensorflow Use Locally on IoT Devices Versus in The Cloud,https://www.reddit.com/r/tensorflow/comments/cshx5v/tensorflow_use_locally_on_iot_devices_versus_in/,cloudster314,1566225385,"Curious to get feedback on trends to run Tensorflow locally on embedded devices.  I wrote down some surprising findings of the submissions for a consumer camera dev contest.  Not sure if people used Tensorflow on the camera because they wanted to learn Tensorflow or because it was the best way to solve the problem.  The challenge was to run some type of app on the camera, it was unrelated to AI/ML, but there were a lot of people that built AI/ML apps into the camera.  

[https://dzone.com/articles/when-to-use-opencv-and-tensorflow-locally-versus-i](https://dzone.com/articles/when-to-use-opencv-and-tensorflow-locally-versus-i)",0,1,False,self,,,,,
68,tensorflow,t5_3alkk,2019-8-20,2019,8,20,1,csjaz1,self.tensorflow,How to identify most important weights for a particular class in multilabel classification,https://www.reddit.com/r/tensorflow/comments/csjaz1/how_to_identify_most_important_weights_for_a/,Studdml,1566231513,"Dear all,

I wanted to know if it is possible to identify the most important weights of an MNIST classifier regarding a particular class?  The Model is build on a simple Lenet CNN architecture with native tensorflow.

Now, after having the trained model, I would like to know which  weights are most important for class ""0"" etc. Or which neurons are most responding to class ""0"".

With that knowledge I would like to modify the weight storage manually to remove learned features about a particular class.

By now I went through all weight values and dropped them one by one and observed any changes in classification accuracy. But I think there must be a way better solution to it.

Thanks",3,3,False,self,,,,,
69,tensorflow,t5_3alkk,2019-8-20,2019,8,20,6,csnfm0,self.tensorflow,A repository to access 3D-CNN architectural codes in TF 2.0 (Pre-trained models and training and testing codes coming soon),https://www.reddit.com/r/tensorflow/comments/csnfm0/a_repository_to_access_3dcnn_architectural_codes/,life_vortex,1566248930,"I have begun training a number of 3D-CNN architectures in TF2.0 and I intend to provide the pre-trained models along with fully functional training and evaluation codes in TF2.0.

Over the next 2 weeks, you can expect a trained I3D model fully functional in TF 2.0.

[https://github.com/indranaut/3DCNNs.git](https://github.com/indranaut/3DCNNs.git)",4,5,False,self,,,,,
70,tensorflow,t5_3alkk,2019-8-20,2019,8,20,12,cssfzw,self.tensorflow,Object Detection Question,https://www.reddit.com/r/tensorflow/comments/cssfzw/object_detection_question/,pablodelgrande,1566273174,"So I've been tinkering with the object detection stuff with tensorflow, from this github:
https://github.com/tensorflow/models/tree/master/research/object_detection

It's really slick and I've been working on using it to detect deer in trailcam photos.  I understand most of what's going on in the jupyter notebook.

I trained using about 500 photos I annotated, some off of google and some from previous data I had off the trailcams in question.

I'm getting a lot of images, with and without deer, where it boxes the entire image.  Here's an example:
https://imgur.com/a/fjIe3Hm

I'm still REALLY new at this and am a far cry from an expert, but I'm trying to understand what could cause this.  I'm not sure if it's poor training data, poor model, or the image I'm trying to detect objects in is of poor quality.  I'm just looking for a direction to go in.

Any Help is appreciated.",2,1,False,self,,,,,
71,tensorflow,t5_3alkk,2019-8-20,2019,8,20,14,cst6v9,self.tensorflow,"Coral summer updates: Post-training quant support, TF Lite delegate, and new models!",https://www.reddit.com/r/tensorflow/comments/cst6v9/coral_summer_updates_posttraining_quant_support/,makereven,1566280083," The compiler has been updated to version 2.0, adding support for models built using post-training quantization[only when using full integer quantization](https://www.tensorflow.org/lite/performance/post_training_quantization#full_integer_quantization_of_weights_and_activations) (previously, we required quantization-aware training)and fixing a few bugs. 

here: [https://developers.googleblog.com/2019/08/coral-summer-updates-post-training.html](https://developers.googleblog.com/2019/08/coral-summer-updates-post-training.html)",1,1,False,self,,,,,
72,tensorflow,t5_3alkk,2019-8-20,2019,8,20,16,csu1j1,self.tensorflow,TensorFlow Lite for Raspberry Pi 3,https://www.reddit.com/r/tensorflow/comments/csu1j1/tensorflow_lite_for_raspberry_pi_3/,dvali,1566285191,"I'm really struggling here. I've seen several statements to the effect that this IS officially supported but have yet to find a guide that I can get through without impassable errors.

Has anyone managed to find a comprehensive guide that actually works for building TF Lite for the Pi? The downloadable PIP package on the official site doesn't work. In particular, I need to build the inferencer to be usable in C. I did manage, I think to get libtensorflow-lite.a built but then couldn't find any documentation on how to actually make any use of it. For example, where are the header files?

I don't have much experience with building things like this - I've mainly used python in the last and things like this haven't been necessary.

Please note that for technical reasons we would very strongly prefer to use TensorFlow Lite only, not the full package. Any help at all will be much appreciated.",3,1,False,self,,,,,
73,tensorflow,t5_3alkk,2019-8-20,2019,8,20,20,cswu0a,self.tensorflow,what is the error here?,https://www.reddit.com/r/tensorflow/comments/cswu0a/what_is_the_error_here/,ph04,1566299303,"`model = tf.keras.Sequential([`  
`tf.keras.layers.Conv2D(32, (3, 3), input_shape=(1, 240, 240), activation=""relu""),`  
`tf.keras.layers.Conv2D(64, (3, 3), activation=""relu""),`  
`tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),`  
`tf.keras.layers.Conv2D(64, (3, 3), activation=""relu""),`  
`tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),`  
`tf.keras.layers.Dropout(0.5),`  
`tf.keras.layers.Flatten(),`  
`tf.keras.layers.Dense(128, activation=""relu""),`  
`tf.keras.layers.Dropout(0.5),`  
`tf.keras.layers.Dense(1, activation=""softmax"")`  
 `])`

in my keras.json there's ""channels\_last"" set. if i set ""channels\_first"" it says i'm missing a dimension, but if i add one (so it should be 4 dims) it says it finds 5 dimensions

no matter what i do i always and up with this

https://i.redd.it/g1irwu336lh31.png",32,3,False,https://b.thumbs.redditmedia.com/73rlus7DAwb7enTe-Yli52eFLN-dDhbulJnpB3Yw4ww.jpg,,,,,
74,tensorflow,t5_3alkk,2019-8-20,2019,8,20,23,cszu38,self.tensorflow,classificator and spam detector,https://www.reddit.com/r/tensorflow/comments/cszu38/classificator_and_spam_detector/,paulred70,1566311627,"Hi, my need is to create a classifier that can detect if a text is a sources code (c#, c++, python) or spam (not  source code),  well my first idea is to use a naive Bayes spam filter but I'd like something like a classifier where I pass a huge number of sources and no spam examples... in a few words: an automatic classifier.

I'd like to do in python and tensorflow

thanks",3,2,False,self,,,,,
75,tensorflow,t5_3alkk,2019-8-21,2019,8,21,5,ct5ynn,self.tensorflow,Best way to combine multiple datasets into one multilabel image classification model,https://www.reddit.com/r/tensorflow/comments/ct5ynn/best_way_to_combine_multiple_datasets_into_one/,ski233,1566334260,"I want to make a multilabel image classification model that can detect many different labels. For each label, I can get at least 5000 positive examples and 5000 negative examples. However, my question is how can I use data in this format to train a multilabel image classifier. Part of the challenge is, for example, I can download 10,000 images of a hand and know that they are positive examples but then if I want to detect a shoe as well, I dont know how many of those hand photos might have also had a shoe in them. Im trying to make a model this way because I will have a fairly high amount of labels and need to be continuously adding new labels. What is the best way to go about doing this?",15,4,False,self,,,,,
76,tensorflow,t5_3alkk,2019-8-21,2019,8,21,7,ct75ac,self.tensorflow,Better to use one big model or tree of models for image classification using tree structure,https://www.reddit.com/r/tensorflow/comments/ct75ac/better_to_use_one_big_model_or_tree_of_models_for/,ski233,1566338819,"I saw in Yolo9000, they have a tree like structure of their labeling. For example, it can see that barrack obama is leader. If it didnt detect he was leader, it would say something like male person or person if it couldnt tell that. I have a use case with labels like this that are in a tree structure. Would it be better to have one giant model capable of detecting 100+ classes or to have an initial model that sorts into submodels that are better suited to specific tasks. For example, it finds a person which will initiate it to then run a model that knows how to distinguish features in people to output a result.",1,1,False,self,,,,,
77,tensorflow,t5_3alkk,2019-8-21,2019,8,21,7,ct7t3y,self.tensorflow,(1.9.x) creating/mutating batch data inside graph?,https://www.reddit.com/r/tensorflow/comments/ct7t3y/19x_creatingmutating_batch_data_inside_graph/,thats_DR_chalupa_2u,1566341765,"I'm implementing a GNN, using *dynamic_rnn* for my state transition function. I compute state transitions, one node at a time, following the order in a traversal. At each node, I stack the states, node features, and edges features pertaining to the 'current' node, as well as its neighbors, and feed it to the state-transition function. Each node has a different *dynamic_rnn* instance with weights copied between them after accumulating gradients. This obviously is not optimal, but I did not want to yet deal with the mess of figuring out how to compute gradients on a single instance that observes multiple disparate sequences (is that even possible without doing a bunch of external tracking and computation?) Also, my graphs have single-digit number of nodes.


**The (Main) Problem:** the input batches to each *dynamic_rnn* need to be assembled dynamically, from within the graph! I need to gather the outputs of the other *dynamic_rnn*s at each step of each sequence, based on the corresponding mask.


//


A few things I've considered:


1.) Feeding in one step of each sequence at a time, instead of batching sequences. *I anticipate this will have horrible performance, and computing gradients might be extremely complicated*.

2.) Using variables to form the batches. *I'm not sure if this would work with how dynamic_rnn handles batches*.

3.) Reorganizing for eager execution. *I've not yet used this mode in TF, and I have a feeling some things may not work as I need them*.


I have a feeling the solution will involve forgoing batching, and controlling the computation for a single training example via multiple runs, but I'm interested to hear what ideas others have.",5,1,False,self,,,,,
78,tensorflow,t5_3alkk,2019-8-21,2019,8,21,10,ct9eta,self.tensorflow,Help on creating reinforcment NN,https://www.reddit.com/r/tensorflow/comments/ct9eta/help_on_creating_reinforcment_nn/,Stanley_C,1566349362,"Hi! I would like advice on starting off project to modify(or from scratch) on how to create a reinforcment Neural Network.

I would like to get help on how to create reinforcments learning NN that takes inputs like drag coefficient and stability derivatives and learns to create an airfoil with those properties. I'm not sure how to set up or train such a network so that during the training session, I plug in random inputs and it eventually learns to output a point cloud to those numbers. 

Second, how do I use a custom error calculations with a exe? I know the command and I know how use pandas to extract the data, but I'm not sure how to use those numbers for error calculations. I want to calculate error based on standard devations form the input, and I would appreciate help.

&amp;#x200B;

https://i.redd.it/dumlbfj9ajh31.jpg",0,0,False,self,,,,,
79,tensorflow,t5_3alkk,2019-8-21,2019,8,21,13,ctbx2n,self.tensorflow,Use external programs for loss calculations,https://www.reddit.com/r/tensorflow/comments/ctbx2n/use_external_programs_for_loss_calculations/,Stanley_C,1566362618,"Hi,

How do I use an external exe for loss calculations?  I know how to read the values from the txts, but I'm not sure how to calculate standard deviation from the input to determine loss",6,1,False,self,,,,,
80,tensorflow,t5_3alkk,2019-8-21,2019,8,21,18,ctem9r,youtube.com,How to Patch GPSR Routing Protocol Using NS2 Tutorial,https://www.reddit.com/r/tensorflow/comments/ctem9r/how_to_patch_gpsr_routing_protocol_using_ns2/,flyhighwithai,1566381229,,0,1,False,default,,,,,
81,tensorflow,t5_3alkk,2019-8-21,2019,8,21,22,ctgp68,self.tensorflow,Preprocess Images in a tensorflow dataset,https://www.reddit.com/r/tensorflow/comments/ctgp68/preprocess_images_in_a_tensorflow_dataset/,piadodjanho,1566393318,"I'm using Tensorflow Dataset on Google Colab with TPU.

I'm having an issue when trying `map` to a preprocess function in a dataset.

    train_ds = train_ds.map(preprocess_data, num_parallel_calls=tf.data.experimental.AUTOTUNE)

I produces the error:

    ValueError: operands could not be broadcast together with remapped shapes [original-&gt;remapped]: (3,2) and requested shape (0,2)

[The notebook](https://colab.research.google.com/drive/16BRp3XzHDqcad6PiweseW2s35cmagk-f).

Does anyone know why and how to fix it?",0,4,False,self,,,,,
82,tensorflow,t5_3alkk,2019-8-22,2019,8,22,1,ctj764,github.com,TensorBoard Empty Scalar Hider: Chrome Extension of hiding empty scalar/panes,https://www.reddit.com/r/tensorflow/comments/ctj764/tensorboard_empty_scalar_hider_chrome_extension/,Jasonnor,1566404873,,0,1,False,default,,,,,
83,tensorflow,t5_3alkk,2019-8-22,2019,8,22,2,ctjp2z,self.tensorflow,Reinforcement learning help,https://www.reddit.com/r/tensorflow/comments/ctjp2z/reinforcement_learning_help/,Stanley_C,1566407031,"Hi, can someone link a guide on how to create an input to output NN for reinforcement, this is related to my last post. I want to have my NN learn to take numerical inputs, and output a point cloud that my external program evaluates,   and the NN learns to match input values and output. I would appreciate help, in forms of repos, tutorials, or replies.",4,0,False,self,,,,,
84,tensorflow,t5_3alkk,2019-8-22,2019,8,22,8,ctowrv,self.tensorflow,does TF use something akin to SSA for backprop?,https://www.reddit.com/r/tensorflow/comments/ctowrv/does_tf_use_something_akin_to_ssa_for_backprop/,thats_DR_chalupa_2u,1566429821,"I'm manually feeding an LSTM one step at a time (so batch dimensions are \[1, 1, feature\_dimension\]). After each step, I save the state to the variable that is providing the LSTM its 'initial' states, then feed the next step.  


What I'm wondering is, how does the auto-diff engine know where each of the assignments to the variable came from, so that it can continue backprop? I would've thought that the variable would be treated as a constant, but instead, it successfully traces back to the LSTM in the previous time step!  


Is this a particular case, when a variable only has one source/edge for assignment? Or is there some additional information that's stored in the forward pass, that allows for assignment sources to be identified during backprop?",0,3,False,self,,,,,
85,tensorflow,t5_3alkk,2019-8-22,2019,8,22,15,cttm9r,youtube.com,Exposing Digital Image Forgeries Detection,https://www.reddit.com/r/tensorflow/comments/cttm9r/exposing_digital_image_forgeries_detection/,flyhighwithai,1566456338,,0,1,False,default,,,,,
86,tensorflow,t5_3alkk,2019-8-22,2019,8,22,18,ctv42v,youtube.com,"Hybrid Biometric Using Face, Eye and Fingerprint",https://www.reddit.com/r/tensorflow/comments/ctv42v/hybrid_biometric_using_face_eye_and_fingerprint/,flyhighwithai,1566467132,,0,4,False,https://b.thumbs.redditmedia.com/U8MS-CHkqK4VbgXIxY2vrNk22mPG1MGJFL3lfyY0JTA.jpg,,,,,
87,tensorflow,t5_3alkk,2019-8-22,2019,8,22,20,ctw5x2,youtube.com,Wideband Spectrum Sensing for Cognitive Radios,https://www.reddit.com/r/tensorflow/comments/ctw5x2/wideband_spectrum_sensing_for_cognitive_radios/,flyhighwithai,1566473812,,0,1,False,https://b.thumbs.redditmedia.com/CH_1c0-dXKYAf2qeEFHWbrioORcH9nL33Fyx3Ft-8Pw.jpg,,,,,
88,tensorflow,t5_3alkk,2019-8-22,2019,8,22,22,ctx5uw,youtube.com,Emotion Detection Implementation Explanation MATLAB,https://www.reddit.com/r/tensorflow/comments/ctx5uw/emotion_detection_implementation_explanation/,flyhighwithai,1566479115,,0,1,False,default,,,,,
89,tensorflow,t5_3alkk,2019-8-23,2019,8,23,3,cu1rpl,self.tensorflow,Tensorboard scalars smooth and stepped,https://www.reddit.com/r/tensorflow/comments/cu1rpl/tensorboard_scalars_smooth_and_stepped/,tomas1808,1566499734,"

[I have two plots](https://imgur.com/4Es8kmF), left is accuracy and right is cross entropy loss. 
Each has data for training and validation sets. For some reason the validation data looks all steppy, while the training data looks smooth. 

Any idea why this could be happening? 

The two lines of code (PyTorch) responsible for logging the data are:

    writer.add_scalars('Train/Loss', {'train_epoch_loss': train_epoch_loss, 'val_epoch_loss': val_epoch_loss}, epoch)
    writer.add_scalars('Train/Accuracy', {'train_epoch_acc': train_epoch_acc, 'val_epoch_acc': val_epoch_acc}, epoch)    


Thanks!",4,3,False,self,,,,,
90,tensorflow,t5_3alkk,2019-8-23,2019,8,23,19,cubz6s,youtube.com,Security Reliability in Cognitive Radio Implementation in Matlab,https://www.reddit.com/r/tensorflow/comments/cubz6s/security_reliability_in_cognitive_radio/,flyhighwithai,1566555899,,0,1,False,https://b.thumbs.redditmedia.com/I6SKdPHBy0vAawahT7b8ULRRj9MnDu1Jj1iUU6-ybTQ.jpg,,,,,
91,tensorflow,t5_3alkk,2019-8-23,2019,8,23,21,cudaa1,self.tensorflow,Detect and Extract Object from camera,https://www.reddit.com/r/tensorflow/comments/cudaa1/detect_and_extract_object_from_camera/,brasileirinho42,1566563813,"Hi everyone! I'm using Tensorflow to detect objects from camera, my goal is detect, take a picture and extract only the detected object. Can you say if it is possible to do that? I'm really stuck, thank you in advance :)",0,1,False,self,,,,,
92,tensorflow,t5_3alkk,2019-8-23,2019,8,23,21,cudetv,self.tensorflow,Can I detect and extract from the Camera only the detected object using Tensorflow-js?,https://www.reddit.com/r/tensorflow/comments/cudetv/can_i_detect_and_extract_from_the_camera_only_the/,brasileirinho42,1566564483,"Hi everyone! I'm using Tensorflow-js to detect objects from camera, my goal is detect, take a picture and extract only the detected object. Can you say if it is possible to do that? I'm really stuck, thank you in advance :)",2,1,False,self,,,,,
93,tensorflow,t5_3alkk,2019-8-23,2019,8,23,22,cudktj,self.tensorflow,"Serverless serving with Flask, startup of model takes very long",https://www.reddit.com/r/tensorflow/comments/cudktj/serverless_serving_with_flask_startup_of_model/,Henry__Gondorff,1566565346,"*Excuse my lack of experience, though I would say I am quite experienced with the theory of deep learning itself, I lack specific experience with cloud-stuff. My question relates specifically to tensorflow but has some docker and cloud aspects to it. If this is the wrong forum to ask this question, please refer me to the an appropriate one.*

*I am not a computer scientist and come from a deeply theoretical background so I might not use some terminology correctly.*

I have a tensorflow model that I serve as a REST-API with FLASK. Everything runs nicely. Once the flask app is fully loaded, a request takes roughly &lt;500 ms which is okay, overall I'm really happy with it. I need a GPU on my cloud instance since I have to ensure that the time until the API answers to a request does not exceed 2 seconds.  

Now the number of requests to this model differ very much depending on the time and day. There are days with barely any requests, there are days with several thousand requests. So I thought, I could save a lot of money by making my application serverless (like AWS lambda). For most serverless applications you have to pack your application in a docker container, which I did anyway. The problem now is the following: the serverless function is triggered by a HTTP request, which then starts the Docker image. Until the API is ready to server the request, roughly 10 seconds are gone. 

This is due to the fact that importing tensorflow and loading the models in Python takes really long. Just try the following in your shell:

    time python3 -c 'import tensorflow'

 My question is, **how can I prevent this and startup my docker image faster with tensorflow models?**

I feel like this should be a common problem but I can't find a solution to it. I am also not quite sure if the solution to this problem lies in tensorflow or docker.",7,14,False,self,,,,,
94,tensorflow,t5_3alkk,2019-8-25,2019,8,25,0,cuutg6,udemy.com,Tensorflow and Keras For Neural Networks and Deep Learning,https://www.reddit.com/r/tensorflow/comments/cuutg6/tensorflow_and_keras_for_neural_networks_and_deep/,discountcouponusa,1566660796,,0,1,False,default,,,,,
95,tensorflow,t5_3alkk,2019-8-25,2019,8,25,17,cv604t,self.tensorflow,TFRecord Command Line Browser,https://www.reddit.com/r/tensorflow/comments/cv604t/tfrecord_command_line_browser/,canonicalwisdom,1566721335,"Hi guys,

[https://github.com/terrykong/tfrecord-browser](https://github.com/terrykong/tfrecord-browser)

As a little side project I thought it would be neat to try and write a command line tool for browsing the TFRecord format. If you think this is cool, try it out! Or least me feedback, I'd love to try and accommodate your use case!",1,8,False,self,,,,,
96,tensorflow,t5_3alkk,2019-8-26,2019,8,26,16,cvkyi8,youtube.com,Kidney segmentation Implementation of Ultrasound Images Neural Network,https://www.reddit.com/r/tensorflow/comments/cvkyi8/kidney_segmentation_implementation_of_ultrasound/,flyhighwithai,1566805905,,0,1,False,https://b.thumbs.redditmedia.com/e8NvfdoM7wPXuPgski0a4nbqpAFDTyN6UMlwHDbdiMc.jpg,,,,,
97,tensorflow,t5_3alkk,2019-8-26,2019,8,26,19,cvlz54,self.tensorflow,TensorFlow Futurewarning,https://www.reddit.com/r/tensorflow/comments/cvlz54/tensorflow_futurewarning/,Akaleth_Illuvatar,1566813701,"TL;DR FutureWarning when importing tensorflow (1.14.0), supposedly a problem with the numpy version, but the proposed fixes don't help.

&amp;#x200B;

When setting up TensorFlow(1.14.0) on my Windows 10 laptop, I get a bunch of ""FutureWarnings"". I'm using PyCharm as IDE and Anaconda to manage packages. I am following the setup as described in [this](https://www.youtube.com/watch?v=ujTCoH21GlA) video. When running:

&gt;import tensorflow

I get the following result:

&gt;Anaconda\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\framework\\[dtypes.py:516](https://dtypes.py:516): FutureWarning:  
&gt;  
&gt;Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
&gt;  
&gt;\_np\_qint8 = np.dtype(\[(""qint8"", np.int8, 1)\])  
&gt;  
&gt;\~\\[dtypes.py:517](https://dtypes.py:517): FutureWarning:  
&gt;  
&gt;Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
&gt;  
&gt;  \_np\_quint8 = np.dtype(\[(""quint8"", np.uint8, 1)\])  
&gt;  
&gt;\~\\[dtypes.py:518](https://dtypes.py:518): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
&gt;  
&gt;  \_np\_qint16 = np.dtype(\[(""qint16"", np.int16, 1)\])  
&gt;  
&gt;\~\\[dtypes.py:519](https://dtypes.py:519): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
&gt;  
&gt;  \_np\_quint16 = np.dtype(\[(""quint16"", np.uint16, 1)\])  
&gt;  
&gt;\~\\[dtypes.py:520](https://dtypes.py:520): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
&gt;  
&gt;  \_np\_qint32 = np.dtype(\[(""qint32"", np.int32, 1)\])  
&gt;  
&gt;\~\\[dtypes.py:525](https://dtypes.py:525): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
&gt;  
&gt;  np\_resource = np.dtype(\[(""resource"", np.ubyte, 1)\])  
&gt;  
&gt;Anaconda\\envs\\tensor\\lib\\site-packages\\tensorboard\\compat\\tensorflow\_stub\\[dtypes.py:541](https://dtypes.py:541): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
&gt;  
&gt;  \_np\_qint8 = np.dtype(\[(""qint8"", np.int8, 1)\])  
&gt;  
&gt;\~\\[dtypes.py:542](https://dtypes.py:542): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
&gt;  
&gt;  \_np\_quint8 = np.dtype(\[(""quint8"", np.uint8, 1)\])  
&gt;  
&gt;\~\\[dtypes.py:543](https://dtypes.py:543): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
&gt;  
&gt;  \_np\_qint16 = np.dtype(\[(""qint16"", np.int16, 1)\])  
&gt;  
&gt;\~\\[dtypes.py:544](https://dtypes.py:544): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
&gt;  
&gt;  \_np\_quint16 = np.dtype(\[(""quint16"", np.uint16, 1)\])  
&gt;  
&gt;\~\\[dtypes.py:545](https://dtypes.py:545): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
&gt;  
&gt;  \_np\_qint32 = np.dtype(\[(""qint32"", np.int32, 1)\])  
&gt;  
&gt;\~\\[dtypes.py:550](https://dtypes.py:550): FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.  
&gt;  
&gt;  np\_resource = np.dtype(\[(""resource"", np.ubyte, 1)\])  
&gt;  
&gt;Process finished with exit code 0

After some looking around, it seemed that this error was caused by the version of numpy I was using, as suggested [here](https://github.com/tensorflow/tensorflow/issues/30427), [here](https://github.com/tensorflow/tensorflow/issues/21939), and [here](https://github.com/tensorflow/tensorflow/issues/31249). However, setting back my numpy to the recommended version (1.16.4) did not do anything. I tried setting it back to other versions such as 1.16.0 and 1.15.0, but none of this seemed to work.

Does anyone have an idea of how to get rid of these warnings?",4,1,False,self,,,,,
98,tensorflow,t5_3alkk,2019-8-26,2019,8,26,20,cvmnl0,youtube.com,Disease Prediction Using Machine Learning | Anova + PCA | SVM,https://www.reddit.com/r/tensorflow/comments/cvmnl0/disease_prediction_using_machine_learning_anova/,flyhighwithai,1566818193,,0,1,False,https://b.thumbs.redditmedia.com/8pZbzeummpSyRivbsIONsfnYl6RaPYvmwAuBP77Pp0s.jpg,,,,,
99,tensorflow,t5_3alkk,2019-8-26,2019,8,26,20,cvmuek,reddit.com,Type error: resize_images() got an unexpected keyword argument 'preserve_aspect_ratio',https://www.reddit.com/r/tensorflow/comments/cvmuek/type_error_resize_images_got_an_unexpected/,hasithz,1566819321,,0,1,False,default,,,,,
100,tensorflow,t5_3alkk,2019-8-26,2019,8,26,20,cvmyc3,youtube.com,Classify Small Data Using Active Learning,https://www.reddit.com/r/tensorflow/comments/cvmyc3/classify_small_data_using_active_learning/,flyhighwithai,1566819974,,0,1,False,default,,,,,
101,tensorflow,t5_3alkk,2019-8-26,2019,8,26,22,cvntc4,youtube.com,3D capsule GAN Tensorflow Explanation | +91-7307399944 For Query | CapsNet Tensorflow 3d AI,https://www.reddit.com/r/tensorflow/comments/cvntc4/3d_capsule_gan_tensorflow_explanation/,deepinsightofai,1566824681,,0,1,False,default,,,,,
102,tensorflow,t5_3alkk,2019-8-27,2019,8,27,5,cvtn8k,self.tensorflow,Load graph for inference in TF 2.0,https://www.reddit.com/r/tensorflow/comments/cvtn8k/load_graph_for_inference_in_tf_20/,aniketmaurya,1566851414,How do I load a graph (.pb) for inference in Tensorflow 2.0?,0,3,False,self,,,,,
103,tensorflow,t5_3alkk,2019-8-27,2019,8,27,12,cvyuye,self.tensorflow,Questions about CNN NN design help,https://www.reddit.com/r/tensorflow/comments/cvyuye/questions_about_cnn_nn_design_help/,Stanley_C,1566876913,"Hi!

I'm trying to create a quick Machine Learning example. In the folder, I have attached all my referenced files. Basically, I have manually coded a dataset: in the x(planned for input neurons while training), I have a multiple 5 lengths integer sequences that increment by 1. Then in the y(the output that we want the NN to generate), I have the same sequences, except each sequence has the length of 6. I have stored both x and y in tfrecord and numpy array files. Could someone help me start my mini project?(I've completed a Udemy course on ML, but it wasn't very useful for me)

&amp;#x200B;

[https://drive.google.com/drive/folders/1iOf69YAC\_ek5P5odRTQe5uAeXibUkD7V?usp=sharing](https://drive.google.com/drive/folders/1iOf69YAC_ek5P5odRTQe5uAeXibUkD7V?usp=sharing)",5,2,False,self,,,,,
104,tensorflow,t5_3alkk,2019-8-27,2019,8,27,15,cw0l31,youtube.com,Simulated Annealing Based Wireless Sensor Network Localization | WSN,https://www.reddit.com/r/tensorflow/comments/cw0l31/simulated_annealing_based_wireless_sensor_network/,deepinsightofai,1566887800,,1,0,False,https://b.thumbs.redditmedia.com/yBphDiYMW31D0CuMKfZNn6D8UpRg7joyrlJK3b-L-TE.jpg,,,,,
105,tensorflow,t5_3alkk,2019-8-27,2019,8,27,17,cw1kg0,github.com,"convert video data (.avi, .mp4 etc.) to TensorFlow tfrecords",https://www.reddit.com/r/tensorflow/comments/cw1kg0/convert_video_data_avi_mp4_etc_to_tensorflow/,whiletrue2,1566895046,,9,12,False,https://b.thumbs.redditmedia.com/VW8y5QsjQgHM0KUowot32ISdJDwFd92hhfcruIcAkQM.jpg,,,,,
106,tensorflow,t5_3alkk,2019-8-28,2019,8,28,12,cwfarm,self.tensorflow,Looking for repo with a good multilabel image classifier,https://www.reddit.com/r/tensorflow/comments/cwfarm/looking_for_repo_with_a_good_multilabel_image/,ski233,1566963101,"Im wanting to do multilabel image classification. I found one model on github and tried it but was rather underwhelmed by the accuracy. From just looking on github, there are only a few (3-4) multilabel image classifiers even available. Does anyone have a repository they would recommend that I could try? Or should I just try to design my own model? Or should I just abandon the multilabel image classifier model idea and just use a slower object detection model that requires more time for image annotations?",4,5,False,self,,,,,
107,tensorflow,t5_3alkk,2019-8-28,2019,8,28,17,cwhrrr,self.tensorflow,Creating a custom metric for a model,https://www.reddit.com/r/tensorflow/comments/cwhrrr/creating_a_custom_metric_for_a_model/,Korr4K,1566979836,"Hi everyone, I'm pretty new to tf and am having a lot of trouble debugging the code. I currently have a working image classification model and I wanted to implement different metrics to use them to evaluate my test data set.

The first metric would be to compare the indices obtained from argmax of y\_true and y\_pred to see if both are above a certain threshold. Having 10 classes the idea is to divide them into the first and second half. I tried this code:

\-----------------------------------------------------------------------------------------------

 def custom\_binary\_accuracy(y\_true, y\_pred):

  
  y\_true\_index = K.argmax(y\_true, axis=-1)  
  y\_pred\_index = K.argmax(y\_pred, axis=-1)

  
  y\_true\_bool = K.greater(y\_true\_index, 4)  
  y\_pred\_bool = K.greater(y\_pred\_index, 4)

  
  matches = K.cast(K.equal(y\_true\_bool, y\_pred\_bool), 'int32')

  
  return K.mean(matches)

\-----------------------------------------------------------------------------------------------

I load my pre-trained model, compile it with the new metric, launch the evaluate\_generator but the accuracy is always 0. I'm probably doing a very stupid mistake but tf is not helping me finding out where it is

Any help?",0,1,False,self,,,,,
108,tensorflow,t5_3alkk,2019-8-28,2019,8,28,19,cwispw,self.tensorflow,I recently switched to TF 2.0 RC. And Im looking for some help,https://www.reddit.com/r/tensorflow/comments/cwispw/i_recently_switched_to_tf_20_rc_and_im_looking/,Fallen-Zero,1566987343,"After switching for TF 2.0, Im struggling to find a the correct way to implement a NN with Low-Level API as I used to do it in TF 1.0, since sessions and placeholders are now deprecated. Back in TF 1.0, you define the forward pass function, the cost function and optimizer, and you let it run in a session and see the results at the end. 
Im struggling to do that with TF 2.0 with the Low Level API and NOT in tf.keras

Any help or advice would be appreciated. Thanks in advance.",2,1,False,self,,,,,
109,tensorflow,t5_3alkk,2019-8-28,2019,8,28,22,cwkjlz,self.tensorflow,Is there a clean way to use Keras callbacks in custom TF training loops?,https://www.reddit.com/r/tensorflow/comments/cwkjlz/is_there_a_clean_way_to_use_keras_callbacks_in/,adelredjimi,1566997511,"I'm working on research project where writing custom training loops in Tensorflow is easier than using `keras.Model.fit()`. However, I miss handy callbacks such as EarlyStopping, ReduceLROnPlateau, TensorBoard. I had to rewrite some stuff from scratch.",2,3,False,self,,,,,
110,tensorflow,t5_3alkk,2019-8-28,2019,8,28,22,cwkuw6,blog.sicara.com,Tensorflow 2.0 implementations of Interpretability Methods,https://www.reddit.com/r/tensorflow/comments/cwkuw6/tensorflow_20_implementations_of_interpretability/,raphaelmeudec,1566999097,,0,12,False,default,,,,,
111,tensorflow,t5_3alkk,2019-8-28,2019,8,28,23,cwln00,self.tensorflow,Does Tensorflow 2.0 support GPUDirect?,https://www.reddit.com/r/tensorflow/comments/cwln00/does_tensorflow_20_support_gpudirect/,SilverSeaworthiness9,1567002841,"Would I be able to dramatically advance training speed on a 3 node Network with Mellanox Connect X 5 VPI cards and Tesla V100s by utilizing GPUDirect in Tensorflow 2? If so, how do I enable that feature?",0,3,False,self,,,,,
112,tensorflow,t5_3alkk,2019-8-29,2019,8,29,9,cwteh3,self.tensorflow,Is this Idea Viable with TensorFlow,https://www.reddit.com/r/tensorflow/comments/cwteh3/is_this_idea_viable_with_tensorflow/,aklosk,1567038576,"I'm worked in Dev-Ops for 10 years, ready to take the step into deep-learning.

For us shallow folks, how do we determine if an application idea is viable for tensorflow or currently available deep learning algos? Would anyone be willing to DM me to discuss a potential application that I hope to develop?",2,4,False,self,,,,,
113,tensorflow,t5_3alkk,2019-8-29,2019,8,29,20,cwziou,self.tensorflow,Quantization aware training with Tensorflow 2.0,https://www.reddit.com/r/tensorflow/comments/cwziou/quantization_aware_training_with_tensorflow_20/,I_love_Icecream,1567077727,Could anyone help me understand how to make an edgetpu compatible model with tensorflow. I am using Keras api if that helps. I have tried converting with TFLiteConverter and using post training quantization. it does not compile with edgetpu.,0,7,False,self,,,,,
114,tensorflow,t5_3alkk,2019-8-30,2019,8,30,8,cx8pzi,self.tensorflow,"I'm getting a No module named '_pywrap_tensorflow_internal' error, but the .so file is there.",https://www.reddit.com/r/tensorflow/comments/cx8pzi/im_getting_a_no_module_named_pywrap_tensorflow/,kiwilifter,1567121091,"&gt;ImportError: No module named '\_pywrap\_tensorflow\_internal'

I was having problems installing tensorflow, I read a few posts and figured out it was a python version support issue which I found a fix for. But now when I try to run an AI program I downloaded from github I get the above error. I took a look in the tensorflow python subdiretory and there is an .so file with that name.

I'm doing this on a Windows 10 system.

Thanks in advance.",0,3,False,self,,,,,
115,tensorflow,t5_3alkk,2019-8-30,2019,8,30,14,cxcu9k,self.tensorflow,deepfakes face swapping video from a single image without training for any face keras tensorflow,https://www.reddit.com/r/tensorflow/comments/cxcu9k/deepfakes_face_swapping_video_from_a_single_image/,PuzzledProgrammer3,1567144583,"Generative adversarial networks integrating modules from FUNIT and SPADE for face-swapping

github: [https://github.com/shaoanlu/fewshot-face-translation-GAN](https://github.com/shaoanlu/fewshot-face-translation-GAN)

inference only takes a few minutes on a k80 in google colab vs weeks or days of training for a face pair

demo elon musk and taylor swift

&amp;#x200B;

![video](0ftst3zuzij31)",7,17,False,self,,,,,
116,tensorflow,t5_3alkk,2019-8-30,2019,8,30,23,cxi2r6,self.tensorflow,C api on fashion-mnist training.,https://www.reddit.com/r/tensorflow/comments/cxi2r6/c_api_on_fashionmnist_training/,jregalad-o,1567177119,"I would really appreciate ant help.   
[https://stackoverflow.com/questions/57728956/how-to-provide-training-data-to-tf-sessionrun-from-c-api-h](https://stackoverflow.com/questions/57728956/how-to-provide-training-data-to-tf-sessionrun-from-c-api-h)  


Trying to train the model from the Tf tutorial using the C api with no success.   


Specially while feeding training data and labels to SessionRun()",0,2,False,self,,,,,
117,tensorflow,t5_3alkk,2019-8-31,2019,8,31,3,cxl8k8,self.tensorflow,tf.data.Dataset shuffle is weirdly slow,https://www.reddit.com/r/tensorflow/comments/cxl8k8/tfdatadataset_shuffle_is_weirdly_slow/,hassanzadeh,1567191370,"Hey Guys,

I'm having a small dataset of around 60K rows. I'm using [tf.data](https://tf.data) api for fetching data and I shuffle it before batching with a buffer size of 60K. Say I want to do this with pandas, it takes only a few seconds if not milliseconds, now with TF, this takes ages! Just look at the console prints:

why is that? what's wrong with TF?

https://i.redd.it/bm5vcrvzumj31.png",4,1,False,self,,,,,
118,tensorflow,t5_3alkk,2019-8-31,2019,8,31,4,cxlgrg,self.tensorflow,How to load submodel's weights from a full model's weight file in Keras?,https://www.reddit.com/r/tensorflow/comments/cxlgrg/how_to_load_submodels_weights_from_a_full_models/,roset_ta,1567192396,"Hello,


I have a pretrained model saved in a .hd5 file. I don't have the training code for this model, so I don't know how it was saved. What I know is that it contains two branches in it and I need to extract their weights, i.e. save them in  .hdf5 files, load them and use them to make some predictions.


I have tried iterating over the full model's layers and using the `model.save_weights(directory)` function of Keras when I find the submodels I need. The problem is that when I load them by `model.load_weights(directory, by_name=True)` I don't get the expected predictions on the evaluation, they are really weird. Of course, since I only save the weights and not the architecture, I also build the model again before loading the weights. What may be wrong? Is there a difference between .hd5 and .hdf5 files? And does loading depend on the way the model was saved?",0,3,False,self,,,,,
119,tensorflow,t5_3alkk,2019-8-31,2019,8,31,5,cxm4cd,self.tensorflow,Tensor to numpy in TF 2.0?,https://www.reddit.com/r/tensorflow/comments/cxm4cd/tensor_to_numpy_in_tf_20/,Runninganddogs979,1567195407,"Hi all!

So I need to use output weights from a layer in cv2 operations, but to do that I need it to be in numpy form. I can not for the life of me figure out how to convert a tensor to a numpy array in TF 2.0, any tips?",8,3,False,self,,,,,
120,tensorflow,t5_3alkk,2019-8-31,2019,8,31,5,cxmhpn,self.tensorflow,TF 2.0 compatible with TFX yet?,https://www.reddit.com/r/tensorflow/comments/cxmhpn/tf_20_compatible_with_tfx_yet/,AlphonseWestwood,1567197151,I had heard that there were some incompatibility issues from a previous video I watched on production grade ML. Learning TF 2.0 right now as well as airflow &amp; kubeflow. Please let me know if Im wrong and they are in fact compatible right now.,1,6,False,self,,,,,
121,tensorflow,t5_3alkk,2019-8-31,2019,8,31,19,cxuizx,self.tensorflow,Tensorflow 2.0 : Combining model.add_loss and keras losses function in training doesn't work,https://www.reddit.com/r/tensorflow/comments/cxuizx/tensorflow_20_combining_modeladd_loss_and_keras/,51616,1567247825,"I read about TensorFlow 2.0 [tutorial](https://www.tensorflow.org/beta/guide/keras/custom_layers_and_models) in VAE section. I follow the tutorial but the model doesn't work as expected despite running the notebook directly from given [Google Colab](https://colab.research.google.com/github/tensorflow/docs/blob/r2.0rc/site/en/r2/guide/keras/custom_layers_and_models.ipynb). The result actually is the same as in the tutorial (i.e. loss value is very similar) but if you look at the output you'll see that the model can't reconstruct the input at all (i.e. output the same image for all inputs). This seems to be a mistake from the tutorial itself when combining `model.add_loss()` and `keras.losses`.

[Original code](https://imgur.com/3rTAOrZ)

I changed MSE loss to BinaryCrossentropy but the result is still the same.

Later I tried compute the BinaryCrossentropy loss explicitly in my forward pass then use `model.add_loss()` in addition with the KL-divergence loss

[Use only model.add_loss() to calculate the loss](https://imgur.com/VVOROCI)

This way the model can actually learn the data and the output seems good enough.

So I have a question about `model.add_loss()` and losses as a function that takes `(y_true, y_pred)` (i.e. `keras.losses`). The updated code works only if it can calculate losses in forward pass (e.g. kl-divergence or reconstruction loss), how can I combine `model.add_loss()` and `keras.losses` correctly in the case where the model need ground truth of the output (e.g. denoise VAE).",0,4,False,self,,,,,
