,sbr,sbr_id,date,year,month,hour,day,id,domain,title,full_link,author,created,selftext,num_comments,score,over_18,thumbnail,media_provider,media_thumbnail,media_title,media_description,media_url
0,tensorflow,t5_3alkk,2017-10-5,2017,10,5,5,74ar49,self.tensorflow,Deconvolutions from a research paper,https://www.reddit.com/r/tensorflow/comments/74ar49/deconvolutions_from_a_research_paper/,2ndFace,1507147230,"Hello All,

I am attempting to reproduce a neural network found in a research paper. Here is the link to an image of the architecture: https://imgur.com/a/q084C

On the right deconvolutions are shown with a number next to them. I was interested to know what the ""2x,"" ""4x,"" ""8x,"" and ""16x"" represented. Thank you.",2,1,False,self,,,,,
1,tensorflow,t5_3alkk,2017-10-5,2017,10,5,8,74c1ns,self.tensorflow,Tensorflow for Windows? Which IDE?,https://www.reddit.com/r/tensorflow/comments/74c1ns/tensorflow_for_windows_which_ide/,leechlamp,1507159258,"So this guy managed to create a self-driving AI in GTAV:

https://www.youtube.com/watch?v=b5xpXecR3LY

But I am not sure he did it in windows. He actually has an entire series on deep learning in his youtube account but I am not sure which program to use to import Tensorflow to do these kinds of things. I am pretty confused. 

All I want is to make a Tensorflow AI play Skyrim all by itself and just let it run. Then after that I wanna make something more complex: Train an AI to watch other players play a game in order to learn from them and come up with its own ideas so I don't have to wait weeks for results, if that's even possible. 
",10,8,False,self,,,,,
2,tensorflow,t5_3alkk,2017-10-7,2017,10,7,15,74tc31,self.tensorflow,Questions about mean squared error loss.,https://www.reddit.com/r/tensorflow/comments/74tc31/questions_about_mean_squared_error_loss/,Xyoloswag420blazeitX,1507357592,"I am using a convolutional neural network to augment input images. I am feeding in 64x64 matrices representing patches of the images and seeing how well the prediction compares to a known augmented paired image.

For my cost, I am using tf.losses.mean_squared_error. 

My question is simply what the above function outputs. Is it truly outputting the mean, or the sum of the pixel-wise errors? ",1,1,False,self,,,,,
3,tensorflow,t5_3alkk,2017-10-8,2017,10,8,1,74w0b7,self.tensorflow,What is the best way to deal with Latitude/Longitude? (New to NN and Tensorflow),https://www.reddit.com/r/tensorflow/comments/74w0b7/what_is_the_best_way_to_deal_with/,grillorafael,1507395492,"Hey guys,


I know that we have to feed everything between 0 and 1 (ideally). What is the chosen method that people use to transform geographical coordinates?",6,8,False,self,,,,,
4,tensorflow,t5_3alkk,2017-10-8,2017,10,8,20,751amz,slideshare.net,7 ways to run TF in parallel,https://www.reddit.com/r/tensorflow/comments/751amz/7_ways_to_run_tf_in_parallel/,mo3194,1507463946,,0,1,False,default,,,,,
5,tensorflow,t5_3alkk,2017-10-9,2017,10,9,6,754jtj,self.tensorflow,Implementing LCRN,https://www.reddit.com/r/tensorflow/comments/754jtj/implementing_lcrn/,HaziqRazali,1507498184,"I am trying to implement figure 1 of paper: 
Long-term Recurrent Convolutional Networks for
Visual Recognition and Description https://arxiv.org/pdf/1411.4389.pdf but I am completely lost.

I went through the lstm tutorials but it did not help me because the input were already 1 dimensional and in the right format. This architecture requires me to convolve each N frames in a sequence before passing them to the LSTM. How can I do this ?

What I currently do is build the CNN and invoke it N times for N frames. ",6,2,False,self,,,,,
6,tensorflow,t5_3alkk,2017-10-10,2017,10,10,9,75dcs0,self.tensorflow,Trouble launching Tensorflow debugger?,https://www.reddit.com/r/tensorflow/comments/75dcs0/trouble_launching_tensorflow_debugger/,killingtime1,1507594489,"I'm on windows and trying to debug a line of code in a RNN model

(it's a call to tf.nn.lookup_embedding).

I wrapped my session in the debugger as in the docs but nothing happens? Is it supposed to auto launch? The docs says something about a build dependency?

Thanks",0,1,False,self,,,,,
7,tensorflow,t5_3alkk,2017-10-10,2017,10,10,22,75h3wx,medium.com,PyTorch vs. TensorFlow: 1 month summary,https://www.reddit.com/r/tensorflow/comments/75h3wx/pytorch_vs_tensorflow_1_month_summary/,Sig_Luna,1507642891,,0,1,False,https://b.thumbs.redditmedia.com/W5ONLZQ6bHgWZHerg3b1CRv-SNVBoDD9ETu3MHFGnXk.jpg,,,,,
8,tensorflow,t5_3alkk,2017-10-11,2017,10,11,2,75iqty,aiworkbox.com,NumPy Array To Tensorflow Tensor And Back,https://www.reddit.com/r/tensorflow/comments/75iqty/numpy_array_to_tensorflow_tensor_and_back/,seabass,1507657493,,0,6,False,https://a.thumbs.redditmedia.com/TdZb3fuVYyXCv-OeMZG0TF9EKQ0lAGWKCxE7hGx5oQ8.jpg,,,,,
9,tensorflow,t5_3alkk,2017-10-11,2017,10,11,5,75ju49,self.tensorflow,"Multihot encoding in tensoflow (google cloud machine learning, tf estimator api)",https://www.reddit.com/r/tensorflow/comments/75ju49/multihot_encoding_in_tensoflow_google_cloud/,andrewm4894,1507666720,"I have a feature like a post tag. So for each observation the post_tag feature might be a selection of tags like ""oscars,brad-pitt,awards"". I'd like to be able to pass this as a feature to a tensorflow model build using the estimator api running on google cloud machine learning (as per this example but adapted for my own problem).

I'm just not sure how to transform this into a multi-hot encoded feature in tensorflow. I'm trying to get something similar to MultiLabelBinarizer in sklearn ideally.

So say i have data like:

id,post_tag

1,[oscars,brad-pitt,awards]

2,[oscars,film,reviews]

3,[matt-damon,bourne]


I want to featurize it, as part of preprocessing within tensorflow, as:


id,post_tag_oscars,post_tag_brad_pitt,post_tag_awards,post_tag_film,post_tag_reviews,post_tag_matt_damon,post_tag_bourne

1,1,1,1,0,0,0,0

2,1,0,0,1,1,0,0

3,0,0,0,0,0,1,1",3,1,False,self,,,,,
10,tensorflow,t5_3alkk,2017-10-13,2017,10,13,3,75yra6,stackoverflow.com,Confused about saving/restoring trained weights and biases in Tensorflow,https://www.reddit.com/r/tensorflow/comments/75yra6/confused_about_savingrestoring_trained_weights/,Xyoloswag420blazeitX,1507831208,,0,5,False,https://b.thumbs.redditmedia.com/_Lpukp9O_gzszjxlZYCxhivyIglM8MWLgHBIj_Yfriw.jpg,,,,,
11,tensorflow,t5_3alkk,2017-10-13,2017,10,13,13,762e2g,self.tensorflow,"This article mentions a training set of data for a bunch of checkers games. I can't seem to find the database he is talking about, does anyone know where that data is?",https://www.reddit.com/r/tensorflow/comments/762e2g/this_article_mentions_a_training_set_of_data_for/,[deleted],1507867891,[deleted],0,1,False,default,,,,,
12,tensorflow,t5_3alkk,2017-10-14,2017,10,14,2,766fb7,self.tensorflow,LSTM setting/resetting the state when using a variable batch size,https://www.reddit.com/r/tensorflow/comments/766fb7/lstm_settingresetting_the_state_when_using_a/,JustinQueeber,1507916503,"I have built this LSTM class:

    import tensorflow as tf
    import Constants


    class LSTM():

        def __init__(self,
                     inputShape,
                     outputShape,
                     numLayers=Constants.numLayers,
                     numHidden=Constants.numHidden,
                     learningRate=Constants.learningRate,
                     forgetBias=Constants.forgetBias):
            self.inputs = tf.placeholder(tf.float32, [None] + inputShape)
            self.labels = tf.placeholder(tf.float32, [None] + outputShape)
            self.inputTensors = tf.unstack(self.inputs, axis=1)
            self.weights = tf.Variable(tf.random_normal([numHidden] + outputShape))
            self.bias = tf.Variable(tf.random_normal(outputShape))
            layers = [tf.contrib.rnn.LSTMCell(numHidden, forget_bias=forgetBias, state_is_tuple=True)] * numLayers
            self.cell = tf.contrib.rnn.MultiRNNCell(layers, state_is_tuple=True)
            self.optimiser = tf.train.GradientDescentOptimizer(learningRate)
            self.forgetBias = forgetBias
            self.batchDict = None
            self.outputs = None
            self.finalStates = None
            self.predictions = None
            self.loss = None
            self.accuracy = None
            self.optimise = None
            self.session = tf.Session()
            self.__buildGraph()

        def __buildGraph(self):
            outputs, finalStates = tf.nn.static_rnn(self.cell, self.inputTensors, dtype=tf.float32)
            predictions = tf.add(tf.matmul(outputs[-1], self.weights), self.bias)
            self.predictions = tf.minimum(tf.maximum(predictions, 0), 1)
            self.loss = tf.losses.mean_squared_error(predictions=self.predictions, labels=self.labels)
            self.accuracy = tf.reduce_mean(1 - tf.abs(self.labels - self.predictions) / 1.0)
            self.optimise = self.optimiser.minimize(self.loss)
            self.session.run(tf.global_variables_initializer())

        def __execute(self, operation):
            return self.session.run(operation, self.batchDict)

        def setBatch(self, inputs, labels):
            self.batchDict = {self.inputs: inputs, self.labels: labels}

        def batchLabels(self):
            return self.__execute(self.labels)

        def batchPredictions(self):
            return self.__execute(self.predictions)

        def batchLoss(self):
            return self.__execute(self.loss)

        def batchAccuracy(self):
            return self.__execute(self.accuracy)

        def processBatch(self):
            self.__execute(self.optimise)

        def kill(self):
            self.session.close()

and I run it like so:

    import DataWorker
    import Constants
    from Model import LSTM

    inputShape = [Constants.sequenceLength, DataWorker.numFeatures]
    outputShape = [1]

    LSTM = LSTM(inputShape, outputShape)

    # #############################################
    # TRAINING
    # #############################################
    for epoch in range(Constants.numEpochs):
        print(""***** EPOCH:"", epoch + 1, ""*****\n"")
        IDPointer, TSPointer = 0, 0
        epochComplete = False
        batchNum = 0
        while not epochComplete:
            batchNum += 1
            batchX, batchY, IDPointer, TSPointer, epochComplete = DataWorker.generateBatch(IDPointer, TSPointer)
            LSTM.setBatch(batchX, batchY)
            LSTM.processBatch()
            if batchNum % Constants.printStep == 0 or epochComplete:
                print(""Batch:\t\t"", batchNum)
                print(""Last Pred:\t"", LSTM.batchPredictions()[-1][0])
                print(""Last Label:\t"", LSTM.batchLabels()[-1][0])
                print(""Loss:\t\t"", LSTM.batchLoss())
                print(""Accuracy:\t"", str(""%.2f"" % (LSTM.batchAccuracy() * 100) + ""%\n""))

    # #############################################
    # TESTING
    # #############################################
    testX, testY = DataWorker.generateTestBatch()
    LSTM.setBatchDict(testX, testY)
    testAccuracy = LSTM.batchAccuracy()
    print(""Testing Accuracy:"", str(""%.2f"" % (testAccuracy * 100) + ""%""))

    LSTM.kill()

&amp;nbsp;

This all works well as it should. However, I am using time series data which consists of financial stocks spanning over ranges of timestamps far greater than the number of time steps that my LSTM is unrolled for - `Constants.sequenceLength`. Because of this, it takes many sequential batches for a single stock t be processed, and so the state/memory of my LSTM needs to be passed between batches. As well as this, after a batch that completes the lifespan of an ID, the next batch would be passing in a new ID from the initial timestamp of my dataset, and so I would want to reset the memory.

[I can find many questions asking something similar, and all of the answers are adequate](https://stackoverflow.com/questions/38441589/rnn-initial-state/41239965#41239965), however, none seem to address the issue of using variable batch sizes - batch sizes initialised to `None` and then inferred when a batch is passed in. My batches are usually a constant size, but do change under certain circumstances and I cannot change this. How can I have control over passing the state between batches, as well as resetting the state, if I have not specified the batch size?",0,3,False,self,,,,,
13,tensorflow,t5_3alkk,2017-10-14,2017,10,14,19,76barm,self.tensorflow,Non python language for tensorflow,https://www.reddit.com/r/tensorflow/comments/76barm/non_python_language_for_tensorflow/,Mittalmailbox,1507975636,"Hi Everyone,

I am web developer interested in tensorflow. I know python is goto language for it. I work with JavaScript and Go mostly, there are binding available for these languages but does not support all functionality.

Will these languages (go/JavaScript) have full support in near future?",1,1,False,self,,,,,
14,tensorflow,t5_3alkk,2017-10-15,2017,10,15,0,76cnrz,self.tensorflow,FoG: A Compute Platform for tensorflow,https://www.reddit.com/r/tensorflow/comments/76cnrz/fog_a_compute_platform_for_tensorflow/,redditor_gds,1507994120,"Hi Guys,

We are building a distributed compute platform based on GPUs for training machine learning models and for inference. We have release our alpha version and would love if you guys can try it out and give us comments.

Currently our system supports tensor flow based programs.

You can visit our system at https://fog.greenedge.io/",1,5,False,self,,,,,
15,tensorflow,t5_3alkk,2017-10-15,2017,10,15,8,76fl6w,self.tensorflow,message me if I can hire you to urgently do a tensorflow task,https://www.reddit.com/r/tensorflow/comments/76fl6w/message_me_if_i_can_hire_you_to_urgently_do_a/,[deleted],1508024216,[deleted],2,1,False,default,,,,,
16,tensorflow,t5_3alkk,2017-10-16,2017,10,16,4,76kz7n,self.tensorflow,Neural Net only output's one and has 0 loss,https://www.reddit.com/r/tensorflow/comments/76kz7n/neural_net_only_outputs_one_and_has_0_loss/,BeastjungleNA,1508094711,"Heyo, I have the following neural net but I am not sure why I can only get an output of 1's as a vector it is a binary classification of 1 or 0 and I am not sure exactly how to fix this. I appreciate any help I have been looking online and reading tensorflow docs.
 
    import pandas as pd
    import numpy as np
    from sklearn.svm import LinearSVC
    from sklearn import neighbors
    from sklearn.preprocessing import LabelEncoder
    from sklearn.metrics import accuracy_score
    from sklearn.model_selection import train_test_split
    import tensorflow as tf
    
    def weight_var(shape):
        initial = tf.truncated_normal(shape, stddev = 0.15)
        return tf.Variable(initial)
    
    def bias_var(shape):
        initial = tf.constant(0.0, shape=shape)
        return tf.Variable(initial)
    
    
    
    print(""Reading data..."")
    
    train = pd.read_csv(""../Data/train.csv"")
    songs = pd.read_csv(""../Data/songs.csv"")
    
    song_cols = ['song_id', 'artist_name', 'genre_ids', 'language']
    
    y = train.target
    
    train = train.merge(songs[song_cols], on = 'song_id', how='left')
    train = train.fillna(-1)
    
    train = train.drop(['target'], axis = 1)
    cols = list(train.columns)
    
    for col in cols:
        if train[col].dtype == 'object':
            train[col] = train[col].apply(str)
            
            le = LabelEncoder()
            train_vals = list(train[col].unique())
            le.fit(train_vals)
            train[col] = le.transform(train[col])
    
    #model = neighbors.KNeighborsClassifier(15)
    features = train.columns.values
    
    for feature in features:
        mean, std = train[feature].mean(), train[feature].std()
        train.loc[:,feature] = (train[feature] - mean) / std
    
    print(train.head())
    x_train, x_test, y_train, y_test = train_test_split(train, y, test_size=0.33, random_state=42)
    x_train = x_train.as_matrix()
    y_train = np.transpose([y_train.as_matrix()])
    y_test = np.transpose([y_test.as_matrix()])
    print(""Training the model..."")
    
    ## NEURAL NET ##
    
    #PARAMS#
    
    training_epocs = 20
    training_dropout = 0.9
    display_step = 5
    n_samples = y_train.shape[0]
    batch_size = 2048
    learning_rate = 0.5
    
    input_nodes = 8
    
    #Multiplier for adjustment of layers
    
    multiplier = 1.5
    
    hidden_nodes1 = 18
    hidden_nodes2 = round(hidden_nodes1 * multiplier)
    hidden_nodes3 = round(hidden_nodes2 * multiplier)
    
    #Percent of nodes to keep during dropout
    percent_keep = tf.placeholder(tf.float32)
    
    #Input Layer
    
    x = tf.placeholder(tf.float32, [None, input_nodes])
    
    #layer 1
    
    W1 = weight_var([input_nodes, hidden_nodes1])
    b1 = bias_var([hidden_nodes1])
    y1 = tf.nn.sigmoid(tf.matmul(x, W1) + b1)
    
    #Layer 2
    
    W2 = weight_var([hidden_nodes1, hidden_nodes2])
    b2 = bias_var([hidden_nodes2])
    y2 = tf.nn.sigmoid(tf.matmul(y1, W2) + b2)
    
    #Layer 3
    
    W3 = weight_var([hidden_nodes2, hidden_nodes3])
    b3 = bias_var([hidden_nodes3])
    y3 = tf.nn.sigmoid(tf.matmul(y2, W3) + b3)
    y3 = tf.nn.dropout(y3, percent_keep)
    
    #Layer 4
    
    W4 = weight_var([hidden_nodes3, 1])
    b4 = bias_var([1])
    y4 = tf.nn.softmax(tf.matmul(y3,W4) + b4)
    
    #output
    
    out = y4
    y_ = tf.placeholder(tf.float32, [None, 1])
    
    
    
    
    #Cost Function
    
    cost = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(out),reduction_indices=[1]))
    #cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = out, labels = y_)
    #cost = tf.reduce_mean(cross_entropy)
    
    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)
    
    #total_error = tf.reduce_sum(tf.square(tf.subtract(y_, tf.reduce_mean(y_))))
    #unexplained_error = tf.reduce_sum(tf.square(tf.subtract(y_, y)))
    #correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
    
    predicted = out
    correct_pred = tf.equal(tf.round(predicted), y_)
    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))
    
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for epoch in range(training_epocs):
            for batch in range(int(n_samples/batch_size)):
                batch_x = x_train[batch*batch_size : (1+batch) * batch_size]
                batch_y = y_train[batch*batch_size : (1+batch) * batch_size]
                opt, c, acc,output = sess.run([optimizer, cost, accuracy, out], feed_dict={x: batch_x, y_ : batch_y, percent_keep: training_dropout})
                avg_c = c / batch_x.shape[0]
                if (epoch) % display_step == 0:
                   print(""Epoch: "", epoch,
                         ""Training Error: "", avg_c,
                         ""Train Loss: "", c,
                         ""Accuracy: "", acc,
                         ""Output: "", output)
                
    print(""Done"")
    
    test_error = tf.nn.l2_loss(y_, name = ""SQE"")/x_test.shape[0]
    print(""Test Error:"", test_error.eval({x: x_test.as_matrix(), y:y_test}))
    

",4,3,False,self,,,,,
17,tensorflow,t5_3alkk,2017-10-17,2017,10,17,3,76smt3,tensorflow.org,Any Update on TFRC announcement made during GoogleI/O17?,https://www.reddit.com/r/tensorflow/comments/76smt3/any_update_on_tfrc_announcement_made_during/,SirKnightRider,1508179584,,0,1,False,https://b.thumbs.redditmedia.com/HVwjmyyofiHoA1llQluj5DX0jY4DEsDMW0m2uYmhQww.jpg,,,,,
18,tensorflow,t5_3alkk,2017-10-17,2017,10,17,5,76tcy8,self.tensorflow,Exponential Tensorboard,https://www.reddit.com/r/tensorflow/comments/76tcy8/exponential_tensorboard/,BeastjungleNA,1508185687,"Hello, sorry to ask but I am having an issue where every time I run my code it generates a new graph and my tensorboard is now huge not sure how to fix this other than to restart my IDE any ideas?
",3,1,False,self,,,,,
19,tensorflow,t5_3alkk,2017-10-17,2017,10,17,6,76tyn2,self.tensorflow,"Installing TFgpu on Win7. TF 1.3 requires CUDA 8.0, which requires visual studio 2015, which requires a subscription with VS to obtain. Do I need VS2015 to get TF to work or will TF work with CUDA 9?",https://www.reddit.com/r/tensorflow/comments/76tyn2/installing_tfgpu_on_win7_tf_13_requires_cuda_80/,[deleted],1508191003,[deleted],0,1,False,default,,,,,
20,tensorflow,t5_3alkk,2017-10-17,2017,10,17,13,76w8yk,self.tensorflow,Question about Batch Size,https://www.reddit.com/r/tensorflow/comments/76w8yk/question_about_batch_size/,FantasyBorderline,1508214834,"Currently I'm working on an age recognition model using Inception v4 and Mobilenet v1 using Adience 3D as a training dataset. I'm still confused about the Batch Size and Steps variable in the parameters. I have the Batch Size variable set to 100 and steps to 200.

Does Batch Size mean ""do evaluation every whatever steps""?",3,1,False,self,,,,,
21,tensorflow,t5_3alkk,2017-10-19,2017,10,19,4,77957d,stackoverflow.com,"Tensorflow: Saving/importing checkpoint works without error, but all imported variables have value 'none'",https://www.reddit.com/r/tensorflow/comments/77957d/tensorflow_savingimporting_checkpoint_works/,Xyoloswag420blazeitX,1508356288,,0,2,False,https://b.thumbs.redditmedia.com/xps9AQ9F1b4A_HjIyXBOPW4VpRfTG2JQwzARc6Ihnus.jpg,,,,,
22,tensorflow,t5_3alkk,2017-10-20,2017,10,20,23,77mfjl,self.tensorflow,How to object recognition with sound via TF? I would like to implement a mobile app which can detect objects and say what it is. Where to start? Any tutorials?,https://www.reddit.com/r/tensorflow/comments/77mfjl/how_to_object_recognition_with_sound_via_tf_i/,raysefo,1508509755,,3,0,False,self,,,,,
23,tensorflow,t5_3alkk,2017-10-22,2017,10,22,4,77vdd5,self.tensorflow,Search for face against list of known faces that TF has not trained against?,https://www.reddit.com/r/tensorflow/comments/77vdd5/search_for_face_against_list_of_known_faces_that/,taewoo,1508613281,"1) Is there an example (or at least an arxiv article) that shows how to search a face against a database of faces that a model has not trained on? Perhaps using eigenface or facial keypoint matching?

2) What's a good way to store a time series of detected faces (when, where in video, descriptors, etc) ? Would you guys use standard mysql table ? InfluxDB / Arctic or similar time series optimized DB?",0,1,False,self,,,,,
24,tensorflow,t5_3alkk,2017-10-22,2017,10,22,13,77yaum,self.tensorflow,My text recognition program works,https://www.reddit.com/r/tensorflow/comments/77yaum/my_text_recognition_program_works/,bacon_mmm_69,1508646922,"...1/26 of the time!  I'd appreciate it very much if anyone could give me pointers on what I need to fix. I'm new to TensorFlow and I have no idea what is going wrong.


The code: https://pastebin.com/eFTNcNhn

Basic description:

This is a simple convolutional neural network program that takes an image of an uppercase letter and outputs the predicted character. 'x' is the input tensor for the 48x48 image generated by 'imgData(char)', and 'y' is the output to represent an uppercase character.

The cnn model is found inside 'model(x,w1,w2,w3,keep_prob)'.

Despite trying various numbers for the learning rate and epoch, the cost always converges to around 3.3.

'accuracy()' prints out the measured accuracy of the model using a test set. It always says 0.0384615. I want 'predict()' to show what probabilities of a given image to be various characters, but right now it is giving all kinds of wierd numbers.

Thanks a lot.",0,2,False,self,,,,,
25,tensorflow,t5_3alkk,2017-10-23,2017,10,23,3,781uhv,stackoverflow.com,How to use an autoencoder to visualize dimensionality reduction?,https://www.reddit.com/r/tensorflow/comments/781uhv/how_to_use_an_autoencoder_to_visualize/,o-rka,1508695732,,3,5,False,https://b.thumbs.redditmedia.com/oglKFGLuGV--Y548k63-F0yVeq-oWAckDiz2O3z_ovM.jpg,,,,,
26,tensorflow,t5_3alkk,2017-10-24,2017,10,24,1,78904a,stackoverflow.com,Fully convolutional neural network producing all zeros in segmentation task,https://www.reddit.com/r/tensorflow/comments/78904a/fully_convolutional_neural_network_producing_all/,Xyoloswag420blazeitX,1508777050,,0,2,False,https://b.thumbs.redditmedia.com/fzRQQzsi39CIrnL8Dbjt33B0Kv8mOq2UHpm3eX-J4kM.jpg,,,,,
27,tensorflow,t5_3alkk,2017-10-24,2017,10,24,2,7899bv,kdnuggets.com,TensorFlow: Building Feed-Forward Neural Networks Step-by-Step,https://www.reddit.com/r/tensorflow/comments/7899bv/tensorflow_building_feedforward_neural_networks/,AhmedGadFCIT,1508779168,,0,5,False,default,,,,,
28,tensorflow,t5_3alkk,2017-10-25,2017,10,25,3,78hlj4,aiworkbox.com,Load The MNIST Dataset into TensorFlow In A One-Hot Encoded Format,https://www.reddit.com/r/tensorflow/comments/78hlj4/load_the_mnist_dataset_into_tensorflow_in_a/,seabass,1508868576,,0,3,False,https://b.thumbs.redditmedia.com/eBaG7ovRzFvgQTtlZLLWqHQ7uYU7EYQUqSMA6D3nO8k.jpg,,,,,
29,tensorflow,t5_3alkk,2017-10-25,2017,10,25,7,78jesv,self.tensorflow,How to build this RNN ?,https://www.reddit.com/r/tensorflow/comments/78jesv/how_to_build_this_rnn/,HaziqRazali,1508884401,"I have a RNN that takes in a 2048 dimensional feature vector for the 1st 10 timesteps. At the next 10 timesteps it will use its own output, a 256 dimensional feature vector. So I am facing an issue because the RNN does not accept the 256 dimensional feature vector. I have the link to my code below and was hoping someone could provide a suggestion. I am still new to tensorflow.

This would be the sample image
https://imgur.com/a/wC0kb

https://github.com/HaziqRazali/CS-596-Video-Reconstruction/blob/master/v2.3%20(timesteps%3D10).ipynb",0,1,False,self,,,,,
30,tensorflow,t5_3alkk,2017-10-25,2017,10,25,20,78n5za,stackoverflow.com,Import error with tensorflow (line 24 in _init_.py),https://www.reddit.com/r/tensorflow/comments/78n5za/import_error_with_tensorflow_line_24_in_init_py/,Minhcht,1508932381,,0,1,False,https://b.thumbs.redditmedia.com/fErYWtzUe5ZfWkC40S4k-ar55vFRLhAt_he3kGuvlFE.jpg,,,,,
31,tensorflow,t5_3alkk,2017-10-26,2017,10,26,0,78og6u,self.tensorflow,How can one use gradient descent find the largest circle inside of a 2D polygon,https://www.reddit.com/r/tensorflow/comments/78og6u/how_can_one_use_gradient_descent_find_the_largest/,goomba870,1508945666,"[Here's an example image](https://i.imgur.com/bVVNswe.png) that shows what I'm looking to achieve - the black circle inside of the red polygon.

The red polygon is a series of XY coordinates around the origin 0,0. I'm looking for the circle with origin X,Y and radius R that is the largest possible. 

I'm struggling a bit to figure out how to state my question mathematically. Visually it's easy - pick random points within the polygon, and expand outward until we cross a point in the polygon. Ideally I think this would mean we're touching 2 or 3 points.


I'll take any advice you have. Thanks!",19,1,False,self,,,,,
32,tensorflow,t5_3alkk,2017-10-26,2017,10,26,2,78pc0y,self.tensorflow,Installing TensorFlow with CUDA 9.0,https://www.reddit.com/r/tensorflow/comments/78pc0y/installing_tensorflow_with_cuda_90/,avaxzat,1508953343,"When I attempt to import TensorFlow I get the following error:

&gt;ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory

Indeed, I don't have libcublas.so.8.0 anywhere on my system. Instead, I have libcublas.so.**9**.0, apparently a version too high. Creating symlinks to these newer libraries tricks TensorFlow into thinking everything is alright, but as soon as any computation is run the entire thing segfaults. Can TensorFlow be installed so that it works with this version? I'm running Arch Linux if that's relevant at all.

Any help would be greatly appreciated, I've been struggling with this installation for several hours now.",7,8,False,self,,,,,
33,tensorflow,t5_3alkk,2017-10-26,2017,10,26,3,78phvq,aiworkbox.com,Create A One Layer Feed Forward Neural Network In TensorFlow With ReLU Activation,https://www.reddit.com/r/tensorflow/comments/78phvq/create_a_one_layer_feed_forward_neural_network_in/,seabass,1508954693,,0,0,False,https://b.thumbs.redditmedia.com/OdfIJd1NBl1JnYIQBMzusA8iKLAH_emFVc0KBeIy8ow.jpg,,,,,
34,tensorflow,t5_3alkk,2017-10-27,2017,10,27,0,78wf49,github.com,Distributed TensorFlow Guide,https://www.reddit.com/r/tensorflow/comments/78wf49/distributed_tensorflow_guide/,chiraqe,1509032800,,0,2,False,https://b.thumbs.redditmedia.com/UT-3-JQIC39uxDgngs-4d_A-qCztUWDdCdFcK3YIs9w.jpg,,,,,
35,tensorflow,t5_3alkk,2017-10-27,2017,10,27,1,78wwbd,self.tensorflow,How to install Tensorflow with Cuda toolkit v8.0 and cuDNN v6.0 ?,https://www.reddit.com/r/tensorflow/comments/78wwbd/how_to_install_tensorflow_with_cuda_toolkit_v80/,Jonsnowstorm,1509036930,"The installation guide mentions the above versions, however , Nvidia (https://developer.nvidia.com/cuda-downloads) provides Cuda v9.0 and cuDNN v7.0 ( https://developer.nvidia.com/cudnn) . 

What should I do ?",2,0,False,self,,,,,
36,tensorflow,t5_3alkk,2017-10-27,2017,10,27,22,793diu,self.tensorflow,0.13 Input Dataset API Question,https://www.reddit.com/r/tensorflow/comments/793diu/013_input_dataset_api_question/,RadonGaming,1509112446,"EDIT: Title is wrong :( My bad

I have looked at the 1.3 Dataset [docs](https://www.tensorflow.org/programmers_guide/datasets#reading_input_data) page, which is the suggested replacement for the input pipeline from previous versions. The only suggestions I find are to load the entirety of the dataset in ( hitting the 2G GraphDef buffer ), or placeholder and feed numpyarrays.

My dataset is 50-100G of image files. The old method allowed me to define paths which would be loaded into the pipeline and fed for me. I can't seem to find any mention of this use-case in the new API.

As the docs discourage 'feeding', due to performance reasons, I'm at a loss for creating an input pipeline for images.

Additionally, I wish to sufficiently preprocess these with a combination of tf operators, and opencv2 ( unless I can wrangle tf ops to do the same job ). This will use py_func and map etc.

I am presuming this is simply me misunderstanding this newer system or the mechanics of things which integrate into it. For instance, would it be feasible to load an entire numpy array ( once .npy is made ), and use the feed placeholder approach? I'm looking for that 'on-demand' feel to the pipeline.

Any help would be greatly appreciated :)",4,3,False,self,,,,,
37,tensorflow,t5_3alkk,2017-10-28,2017,10,28,19,799j0a,self.tensorflow,"Question: Using TensorFlow, in Python, to train a classifier from examples.",https://www.reddit.com/r/tensorflow/comments/799j0a/question_using_tensorflow_in_python_to_train_a/,mount_sumInt,1509188346,"Hi. I'm new to TensorFlow and machine learning in general. I am experienced in Python, however.

I'm trying to teach a machine from examples. I've looked through the documentation and haven't found a way to do this in TensorFlow; but only ways to optimise values. I've seen examples of doing the same thing with SciKit, but that isn't compatible with GPU computation.

I'm basically trying to turn this pseudo code into code:
    import numpy as np
    import tensorflow as tf
    
    x = np.array([""Hi. I'm Alex."", ""Hi. I'm Mark."", ""Hi. I'm Jake.""])
    y = np.array([""Hi Alex. I'm a robot."", ""Hi Mark. I'm a robot."", ""Hi Jake. I'm a robot.""])
    
    # vvv I think I need to use the session function for this. vvv
    tf.train(x, y)
    
    z = np.array([""Hi. I'm Sophie.""])
    
    prediction = tf.predict(z)
    print(prediction)
    # Prints ""Hi Sophie. I'm a robot.""

How do I do this?

Thank you. :)",2,1,False,self,,,,,
38,tensorflow,t5_3alkk,2017-10-29,2017,10,29,19,79fr6k,self.tensorflow,Tensorflow logistic Regression,https://www.reddit.com/r/tensorflow/comments/79fr6k/tensorflow_logistic_regression/,marvpaul,1509271792,"Im trying to implement a logistic regression / classifier using Tensorflow. Basically I have two classes with some trainings data. Each time I train my costs are NaN. Any ideas how to solve this problem? 
https://github.com/marvpaul/MachineLearningPlayground/blob/master/SoftmaxFunctionTF/regression.py

Edit: 
I tried to replace my cross entropy calculation with the Tensorflow method softmax_cross_entropy_with_logits and now my costs dont decrease during training and my accuracy after training is about 50%, which means my training does not work. Any ideas what is going wrong? :/ ",9,2,False,self,,,,,
39,tensorflow,t5_3alkk,2017-10-30,2017,10,30,6,79jbxs,stackoverflow.com,Tensorflow model loading: Which weights are trained and should be used in evaluation?,https://www.reddit.com/r/tensorflow/comments/79jbxs/tensorflow_model_loading_which_weights_are/,Xyoloswag420blazeitX,1509312944,,0,4,False,https://b.thumbs.redditmedia.com/FLE9J3BxcGKlKltplhN1znmhYv2TAy4-qzxw1baDjNQ.jpg,,,,,
40,tensorflow,t5_3alkk,2017-10-30,2017,10,30,12,79la36,self.tensorflow,Freezing a model using tf.Estimator() nets me an unusable model in Android - because RandomShuffleQueueV2 and QueueDequeueMany nodes,https://www.reddit.com/r/tensorflow/comments/79la36/freezing_a_model_using_tfestimator_nets_me_an/,FantasyBorderline,1509334533,"I have a model that is in use with `tf.Estimator()`, and after I freeze it and attempt to use it in Android, I get the infamous ""No Kernel Registered for Op"" error for ""RandomShuffleQueueV2"".

One way I've tried is to remove said nodes, but I can't optimize them for inference because the `optimize_for_inference_lib` says it's an invalid graph.

So, is there a way to freeze the graph from a tf.Estimator without freezing the RandomShuffleQueueV2 and QueueDequeueMany nodes?",0,1,False,self,,,,,
41,tensorflow,t5_3alkk,2017-10-30,2017,10,30,23,79o1cs,stackoverflow.com,Running TensorFlow on multicore devices,https://www.reddit.com/r/tensorflow/comments/79o1cs/running_tensorflow_on_multicore_devices/,sudo_O,1509373568,,0,2,False,https://b.thumbs.redditmedia.com/01X962nQntweF-bcFimzYQohS1DUyVIzvWskv710HNY.jpg,,,,,
42,tensorflow,t5_3alkk,2017-10-30,2017,10,30,23,79o2gi,self.tensorflow,tflearn GAN: generator has input dimensions from the discriminator,https://www.reddit.com/r/tensorflow/comments/79o2gi/tflearn_gan_generator_has_input_dimensions_from/,KayJersch,1509373870,"I tried to make a Generative Adversarial Network in tflearn with this code:
    from tflearn import *
    from PIL import Image
    import glob
    import numpy as np
    import random

    gen_x = []
    dis_x = []
    dis_y = []

    for filename in glob.glob('trainig_data/*.jpg'):
        im = np.asarray(Image.open(filename).resize((64,64)))
        dis_x.append(im)
        dis_y.append([1.0])
        if len(dis_x) == 10000:
            break

    gen_loss = 'categorical_crossentropy'
    gen_input = input_data([None,1])
    gen = fully_connected(gen_input,48,activation='sigmoid')
    gen = dropout(gen,0.8)
    gen = reshape(gen,[-1,4,4,3])
    gen = conv_2d(gen,32,5,activation='relu')
    gen = upsample_2d(gen,2)
    gen = conv_2d(gen,64,5,activation='relu')
    gen = upsample_2d(gen,2)
    gen = conv_2d(gen,128,5,activation='relu')
    gen = upsample_2d(gen,2)
    gen = conv_2d(gen,256,5,activation='relu')
    gen = upsample_2d(gen,2)
    gen = conv_2d(gen,3,5,activation='relu')
    gen = regression(gen[0],loss=gen_loss,batch_size=10)
    generator = DNN(gen)

    dis_input = input_data([None,64,64,3])
    dis = conv_2d(dis_input,32,5,activation='relu')
    dis = max_pool_2d(dis,2)
    dis = conv_2d(dis,64,5,activation='relu')
    dis = max_pool_2d(dis,2)
    dis = conv_2d(dis,128,5,activation='relu')
    dis = max_pool_2d(dis,2)
    dis = conv_2d(dis,256,5,activation='relu')
    dis = fully_connected(dis,256,activation='sigmoid')
    dis = dropout(dis,0.8)
    dis = fully_connected(dis,1,activation='sigmoid')
    dis = regression(dis,loss='binary_crossentropy',batch_size=10)
    discriminator = DNN(dis)

    for t in range(10):
        gen_x = []
        dis_x_fake = []
        dis_y_fake = []
        for i in range(10000):
            seed = [[random.random()]]
            gen_x.append(seed)
            image = generator.predict(seed)
            dis_x_fake.append(image)
            dis_y_fake.append([0.0])
        discriminator.fit(dis_x,dis_y,5)
        discriminator.fit(dis_x_fake,dis_y_fake,5)
        gen_loss = -discriminator.predict(generator.predict([[gen_input]]))
        generator.fit(gen_x,None,10)
    generator.save('saved/generator.tflearn')

But when I try to run the code, the python shell spits out following error:

    Traceback (most recent call last):
      File ""D:\Kay\AI\GAN\tflearn\GAN.py"", line 59, in &lt;module&gt;
        image = generator.predict(seed)
      File ""C:\Users\Katharina\AppData\Local\Programs\Python\Python35\lib\site-packages\tflearn\models\dnn.py"", line 257, in predict
        return self.predictor.predict(feed_dict)
      File ""C:\Users\Katharina\AppData\Local\Programs\Python\Python35\lib\site-packages\tflearn\helpers\evaluator.py"", line 69, in predict
        return self.session.run(self.tensors[0], feed_dict=feed_dict)
      File ""C:\Users\Katharina\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 789, in run
        run_metadata_ptr)
      File ""C:\Users\Katharina\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 975, in _run
        % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))
    ValueError: Cannot feed value of shape () for Tensor 'InputData/X:0', which has shape '(?, 128, 128, 3)'

Out of some reason the generator has the input dimensions from the discriminator and I don't know how to fix that. Can someone tell me what went wrong and how to fix it?

PS: If you see other flaws in my code, please let me know!",0,1,False,self,,,,,
43,tensorflow,t5_3alkk,2017-10-31,2017,10,31,0,79ogjr,stackoverflow.com,tf.nn.conv2dtranspose error during training,https://www.reddit.com/r/tensorflow/comments/79ogjr/tfnnconv2dtranspose_error_during_training/,Xyoloswag420blazeitX,1509377514,,0,1,False,https://a.thumbs.redditmedia.com/hRYFPgEppQaHk9RraBRszWIt8lvSWQ25iIynN185Qc4.jpg,,,,,
44,tensorflow,t5_3alkk,2017-10-31,2017,10,31,21,79vdbm,self.tensorflow,How to store image as RGB array for Image Classifier?,https://www.reddit.com/r/tensorflow/comments/79vdbm/how_to_store_image_as_rgb_array_for_image/,Eilue,1509452700,"I am following a tutorial called 'Machine Learning is Fun!' (https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721) and in the image classification tutorial, I made sense of most of the codes except the first line:

`#Load the data set
``
X, Y, X_test, Y_test = pickle.load(open(""full_dataset.pkl"", ""rb""))`

I learned that pickle is a Python way of storing image into array, but I have no idea how to make my image set into a pickle so that I can use it like that.

I tried dumping image file into a new pkl I created, but somehow only image file name is stored as string, not the color RGB value.

",5,2,False,self,,,,,
