,sbr,sbr_id,date,year,month,hour,day,id,domain,title,full_link,author,created,selftext,num_comments,score,over_18,thumbnail,media_provider,media_thumbnail,media_title,media_description,media_url
0,MachineLearning,t5_2r3gv,2019-9-1,2019,9,1,15,cy6rd8,web.stanford.edu,Accent Conversion Using Artificial Neural Networks,https://www.reddit.com/r/MachineLearning/comments/cy6rd8/accent_conversion_using_artificial_neural_networks/,Iam_nameless,1567320168,,3,2,False,default,,,,,
1,MachineLearning,t5_2r3gv,2019-9-1,2019,9,1,16,cy716o,self.MachineLearning,The prospects of a highly intelligent AI sucks the motivation out of my me.,https://www.reddit.com/r/MachineLearning/comments/cy716o/the_prospects_of_a_highly_intelligent_ai_sucks/,yourboyrabbit,1567322368,[removed],0,1,False,self,,,,,
2,MachineLearning,t5_2r3gv,2019-9-1,2019,9,1,16,cy73vt,self.MachineLearning,TxForest: A DSL for Concurrent Filestores,https://www.reddit.com/r/MachineLearning/comments/cy73vt/txforest_a_dsl_for_concurrent_filestores/,UpandRunn1ng,1567323002,[removed],0,1,False,self,,,,,
3,MachineLearning,t5_2r3gv,2019-9-1,2019,9,1,16,cy73vx,self.MachineLearning,Perfect background removal without using API's like remove.bg 's,https://www.reddit.com/r/MachineLearning/comments/cy73vx/perfect_background_removal_without_using_apis/,vpgalactic23,1567323003,[removed],0,1,False,self,,,,,
4,MachineLearning,t5_2r3gv,2019-9-1,2019,9,1,16,cy75v7,self.MachineLearning,Getting a job abroad,https://www.reddit.com/r/MachineLearning/comments/cy75v7/getting_a_job_abroad/,anonymousysuomynona,1567323465,[removed],0,1,False,self,,,,,
5,MachineLearning,t5_2r3gv,2019-9-1,2019,9,1,17,cy7hxh,self.MachineLearning,"AI (artifical intelligence) experts who work in Paris, what do you do and how much do you make ?",https://www.reddit.com/r/MachineLearning/comments/cy7hxh/ai_artifical_intelligence_experts_who_work_in/,wannadisappear,1567326337,[removed],0,1,False,self,,,,,
6,MachineLearning,t5_2r3gv,2019-9-1,2019,9,1,19,cy893g,ftp.cs.berkeley.edu,[R] Bayesian Relational Memory for Semantic Visual Navigation,https://www.reddit.com/r/MachineLearning/comments/cy893g/r_bayesian_relational_memory_for_semantic_visual/,penpatience,1567332715,,1,21,False,default,,,,,
7,MachineLearning,t5_2r3gv,2019-9-1,2019,9,1,19,cy8a6k,self.MachineLearning,[D] What are some promising research directions for model-based RL?,https://www.reddit.com/r/MachineLearning/comments/cy8a6k/d_what_are_some_promising_research_directions_for/,ThisIsMySeudonym,1567332953,The title says it all. I thought I'd ask the community! Please do share your thoughts and unique perspectives. Also curious to hear about RL in general.,29,53,False,self,,,,,
8,MachineLearning,t5_2r3gv,2019-9-1,2019,9,1,21,cy93v4,twitter.com,Anyone would like to help to this project? Climate scientists need help on an OCR text decode,https://www.reddit.com/r/MachineLearning/comments/cy93v4/anyone_would_like_to_help_to_this_project_climate/,stevevaius,1567339309,,0,1,False,default,,,,,
9,MachineLearning,t5_2r3gv,2019-9-1,2019,9,1,21,cy9jee,self.MachineLearning,LSTM finding correct units value parameter,https://www.reddit.com/r/MachineLearning/comments/cy9jee/lstm_finding_correct_units_value_parameter/,datapim,1567342179,[removed],0,1,False,self,,,,,
10,MachineLearning,t5_2r3gv,2019-9-1,2019,9,1,22,cya4g6,quora.com,What are the disadvantages of using Python for machine learning?,https://www.reddit.com/r/MachineLearning/comments/cya4g6/what_are_the_disadvantages_of_using_python_for/,refine_and_refine,1567345592,,0,1,False,default,,,,,
11,MachineLearning,t5_2r3gv,2019-9-1,2019,9,1,23,cya9os,self.MachineLearning,Can compressed sensing algorithms be used for least absolute deviation problems?,https://www.reddit.com/r/MachineLearning/comments/cya9os/can_compressed_sensing_algorithms_be_used_for/,4thofthe4th,1567346409,[removed],0,1,False,self,,,,,
12,MachineLearning,t5_2r3gv,2019-9-1,2019,9,1,23,cyam58,self.MachineLearning,How to build a bot that automatically collect infomation from internet?,https://www.reddit.com/r/MachineLearning/comments/cyam58/how_to_build_a_bot_that_automatically_collect/,vuhung3990,1567348243,[removed],0,1,False,self,,,,,
13,MachineLearning,t5_2r3gv,2019-9-1,2019,9,1,23,cyargp,i.redd.it,"I made a python package that lets you remotely monitor your deep learning training metrics. If you like this project, consider giving it a star. You can check out here. www.github.com/CleanPegasus/coffeeshop",https://www.reddit.com/r/MachineLearning/comments/cyargp/i_made_a_python_package_that_lets_you_remotely/,clean_pegasus,1567349014,,0,1,False,default,,,,,
14,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,0,cyb2zy,self.MachineLearning,[P] Relative Attention Positioning library in pytorch,https://www.reddit.com/r/MachineLearning/comments/cyb2zy/p_relative_attention_positioning_library_in/,Separius12,1567350609,"Hi,

I was trying to use a 2d relative position encoding in my transformer network and couldn't find one in pytorch,

So I decided to change the tensor2tensor's implementation into pytorch and added 3d and 1d support as well.

Also because of the heavy usage of attention in the field, I decided to implement that same function in cuda.

It is not a general purpose cuda kernel, and only works great in my settings (large batch size with relatively small patch size) but it might be worth it to check the performance on your settings (I'm getting 2.5x speed up in my forward and 1.5x on my backward)

One last thing, It also supports the B and D attention terms in the Transformer-XL paper.",1,4,False,self,,,,,
15,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,0,cyblyi,self.MachineLearning,ML algorithm to identify dark areas as ellipses inside images,https://www.reddit.com/r/MachineLearning/comments/cyblyi/ml_algorithm_to_identify_dark_areas_as_ellipses/,jconcode,1567353202,[removed],0,1,False,self,,,,,
16,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,0,cybnv5,self.MachineLearning,How to provide a dataset to MNIST?,https://www.reddit.com/r/MachineLearning/comments/cybnv5/how_to_provide_a_dataset_to_mnist/,srikargoud_69,1567353452,[removed],0,1,False,self,,,,,
17,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,1,cybxil,youtu.be,Elon Musk and Jack Ma disagree about AI's threat,https://www.reddit.com/r/MachineLearning/comments/cybxil/elon_musk_and_jack_ma_disagree_about_ais_threat/,Angelinatrump,1567354725,,0,1,False,https://b.thumbs.redditmedia.com/9AiO0anYSjlclayvAe1crWxbdO0lDqZmVSPWlwbG1Wc.jpg,,,,,
18,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,1,cybyj6,self.MachineLearning,Data gathering for WSD problem,https://www.reddit.com/r/MachineLearning/comments/cybyj6/data_gathering_for_wsd_problem/,bundash00,1567354866,[removed],0,1,False,self,,,,,
19,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,1,cyc1k0,self.MachineLearning,Would anyone use or support DeepLearningFramework?,https://www.reddit.com/r/MachineLearning/comments/cyc1k0/would_anyone_use_or_support_deeplearningframework/,akifnane,1567355270,[removed],0,1,False,https://b.thumbs.redditmedia.com/GmW2Q8_reGqsdPVUJ3rSF5EC54n83Lk7gcPTk-zfkwA.jpg,,,,,
20,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,1,cyc618,medium.com,Scalable image classification with ONNX.js and AWS Lambda,https://www.reddit.com/r/MachineLearning/comments/cyc618/scalable_image_classification_with_onnxjs_and_aws/,naxty1995,1567355857,,0,1,False,default,,,,,
21,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,2,cyctsu,self.AnimeResearch,NijigenkaAI - telegram bot turns you selfie into anime,https://www.reddit.com/r/MachineLearning/comments/cyctsu/nijigenkaai_telegram_bot_turns_you_selfie_into/,senior_sigan,1567358938,,0,1,False,https://b.thumbs.redditmedia.com/-ELQtfeM5-0UMpFFDMgLa7-Q2XAfTtvGoYSkvILxi2I.jpg,,,,,
22,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,2,cycw35,arxiv.org,[R] Random Search Outperforms State-Of-The-Art NAS Algorithms,https://www.reddit.com/r/MachineLearning/comments/cycw35/r_random_search_outperforms_stateoftheart_nas/,mystikaldanger,1567359251,,53,288,False,default,,,,,
23,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,2,cyd36n,ryxcommar.com,"Scikit-learns Defaults are Wrong  r y x, r",https://www.reddit.com/r/MachineLearning/comments/cyd36n/scikitlearns_defaults_are_wrong_r_y_x_r/,_quanttrader_,1567360163,,0,1,False,https://b.thumbs.redditmedia.com/ykZJBRBrgOQkxWCy4byjFDAbOTlOmwRdxJNGMpXmyFk.jpg,,,,,
24,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,3,cydcxv,medium.com,[P] A Gentle Introduction to PyTorch 1.2,https://www.reddit.com/r/MachineLearning/comments/cydcxv/p_a_gentle_introduction_to_pytorch_12/,omarsar,1567361433,,0,1,False,default,,,,,
25,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,3,cyddto,self.MachineLearning,AI residency alumni - are these programs a good way to get in the door?,https://www.reddit.com/r/MachineLearning/comments/cyddto/ai_residency_alumni_are_these_programs_a_good_way/,mld26,1567361553,[removed],0,1,False,self,,,,,
26,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,3,cydfrx,self.MachineLearning,Research labs for internship ?,https://www.reddit.com/r/MachineLearning/comments/cydfrx/research_labs_for_internship/,ashutosj,1567361820,[removed],0,1,False,self,,,,,
27,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,3,cydplj,arxiv.org,"[R] The creators of BertSum for extractive summarization released a new paper for both abstractive and extractive summarization using Bert. ""Text Summarization with Pretrained Encoders""",https://www.reddit.com/r/MachineLearning/comments/cydplj/r_the_creators_of_bertsum_for_extractive/,BatmantoshReturns,1567363079,,9,17,False,default,,,,,
28,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,4,cyea4w,codinginfinite.com,Best Python IDE and Code Editors | Top 10,https://www.reddit.com/r/MachineLearning/comments/cyea4w/best_python_ide_and_code_editors_top_10/,codinginfinite,1567365751,,0,1,False,https://b.thumbs.redditmedia.com/0bP2RBpxTxPDAI0dtG3KXbQmB5rbZO-Erk9JlbUi_Ag.jpg,,,,,
29,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,4,cyelh1,self.MachineLearning,In what case would you need to implement your own tensor?,https://www.reddit.com/r/MachineLearning/comments/cyelh1/in_what_case_would_you_need_to_implement_your_own/,mseltahir,1567367256,[removed],0,1,False,self,,,,,
30,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,5,cyf60m,self.MachineLearning,Convergence difference between reduction sum or mean in pytorch?,https://www.reddit.com/r/MachineLearning/comments/cyf60m/convergence_difference_between_reduction_sum_or/,mesmer_adama,1567370003,[removed],0,1,False,self,,,,,
31,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,6,cyg6i2,self.MachineLearning,Looking for advice on audio processing.,https://www.reddit.com/r/MachineLearning/comments/cyg6i2/looking_for_advice_on_audio_processing/,CollectiveOfCells,1567375040,[removed],0,1,False,self,,,,,
32,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,7,cygobx,self.MachineLearning,Image Manipulation and Classification: Identifying traffic objects,https://www.reddit.com/r/MachineLearning/comments/cygobx/image_manipulation_and_classification_identifying/,plentyofnodes,1567377615,[removed],0,1,False,self,,,,,
33,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,7,cygpa7,self.MachineLearning,[P] Image Manipulation and Classification: Identifying traffic objects,https://www.reddit.com/r/MachineLearning/comments/cygpa7/p_image_manipulation_and_classification/,plentyofnodes,1567377751,"This is an example of an image classifier built with Keras to identify presence of traffic objects.

Specifically, the VGG16 network was used as the pre-trained model, and the images themselves were manipulated using PIL for cropping purposes, and using Grad-CAM and cv2 to respectively generate a heatmap, and superimpose the heatmap on the relevant image.

[Findings can be found here.](https://www.michael-grogan.com/image-recognition-with-keras-convolutional-neural-networks/) Hope that you find this of use, and any feedback or tips greatly appreciated.",0,3,False,self,,,,,
34,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,8,cyhg4m,sahnimanas.github.io,What makes fast DNN libraries fast?,https://www.reddit.com/r/MachineLearning/comments/cyhg4m/what_makes_fast_dnn_libraries_fast/,betelguese_42,1567381873,,0,1,False,https://b.thumbs.redditmedia.com/jSBbfskLs_32ktflcfN8QC7YcFhbNprVNIX3oTDMNZs.jpg,,,,,
35,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,10,cyi9yu,arxiv.org,[R] Deep Learning Theory Review: An Optimal Control and Dynamical Systems Perspective,https://www.reddit.com/r/MachineLearning/comments/cyi9yu/r_deep_learning_theory_review_an_optimal_control/,hardmaru,1567386610,,2,41,False,default,,,,,
36,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,11,cyixuq,self.MachineLearning,How many layer/neuron is enough for a 3x3 tic tac toe?,https://www.reddit.com/r/MachineLearning/comments/cyixuq/how_many_layerneuron_is_enough_for_a_3x3_tic_tac/,MarkKang2019,1567390381,[removed],0,1,False,self,,,,,
37,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,12,cyjlgy,self.MachineLearning,[R] Language Tasks and Language Games: On Methodology in Current Natural Language Processing Research,https://www.reddit.com/r/MachineLearning/comments/cyjlgy/r_language_tasks_and_language_games_on/,rtk25,1567394231,"# Language Tasks and Language Games: On Methodology in Current Natural Language Processing Research

[David Schlangen](https://arxiv.org/search/cs?searchtype=author&amp;query=Schlangen%2C+D)*(Submitted on 28 Aug 2019)*

&gt;""This paper introduces a new task and a new dataset"", ""we improve the state of the art in X by Y"" -- it is rare to find a current natural language processing paper (or AI paper more generally) that does not contain such statements. What is mostly left implicit, however, is the assumption that this necessarily constitutes progress, and what it constitutes progress towards. Here, we make more precise the normally impressionistically used notions of language task and language game and ask how a research programme built on these might make progress towards the goal of modelling general language competence.

[https://arxiv.org/abs/1908.10747](https://arxiv.org/abs/1908.10747)",3,7,False,self,,,,,
38,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,13,cykgku,i.redd.it,[P] I made a python package that sends your deep learning training metrics to your slack channel after every specified epoch and let's you remotely monitor the model.,https://www.reddit.com/r/MachineLearning/comments/cykgku/p_i_made_a_python_package_that_sends_your_deep/,clean_pegasus,1567399660,,0,1,False,default,,,,,
39,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,13,cykjt9,arxiv.org,[R] Revisit Fuzzy Neural Network: Demystifying Batch Normalization and ReLU with Generalized Hamming Network,https://www.reddit.com/r/MachineLearning/comments/cykjt9/r_revisit_fuzzy_neural_network_demystifying_batch/,tsauri,1567400260,,2,16,False,default,,,,,
40,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,14,cykrmr,self.MachineLearning,"An Introduction to Advanced Machine Learning : Meta Learning Algorithms, Applications and Promises",https://www.reddit.com/r/MachineLearning/comments/cykrmr/an_introduction_to_advanced_machine_learning_meta/,UpandRunn1ng,1567401660,[removed],0,1,False,self,,,,,
41,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,14,cyl03j,rubbermachinery.in,Which Company Manufactures The Best Quality Rubber Moulding Machine?,https://www.reddit.com/r/MachineLearning/comments/cyl03j/which_company_manufactures_the_best_quality/,rubbermachine,1567403242,,0,1,False,default,,,,,
42,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,15,cylf9g,analyticsjobs.in,Top Companies in India Data Science and Machine learning,https://www.reddit.com/r/MachineLearning/comments/cylf9g/top_companies_in_india_data_science_and_machine/,kaushalseo1,1567406096,,0,1,False,default,,,,,
43,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,15,cylfuy,self.MachineLearning,DeepMind's artificial intelligence is now able to generate 256x256 videos up to 48 consecutive frames,https://www.reddit.com/r/MachineLearning/comments/cylfuy/deepminds_artificial_intelligence_is_now_able_to/,OneHandedPenguin,1567406215,A video from the youtuber TwoMinutePapers shows example of them [https://www.youtube.com/watch?v=IMZkLVBhcig](https://www.youtube.com/watch?v=IMZkLVBhcig),0,1,False,self,,,,,
44,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,15,cylk1h,self.kaggle,Pneumothorax Segmentation using Hypercolumns,https://www.reddit.com/r/MachineLearning/comments/cylk1h/pneumothorax_segmentation_using_hypercolumns/,sayantandas30011998,1567407075,,0,0,False,default,,,,,
45,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,16,cylwgx,self.MachineLearning,Variational encoder doubt ?,https://www.reddit.com/r/MachineLearning/comments/cylwgx/variational_encoder_doubt/,ashutosj,1567409629,[removed],0,1,False,self,,,,,
46,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,16,cylzys,i.redd.it,"Describe how it actually works otherwise no one will care, no fame, NaN nothing. Help communities grow and get the benefits of open minded",https://www.reddit.com/r/MachineLearning/comments/cylzys/describe_how_it_actually_works_otherwise_no_one/,manisaip,1567410384,,0,1,False,https://b.thumbs.redditmedia.com/RWQqacG4NTQuHKqWy2imzib75EOwQIVdMrFZ8LrUzTU.jpg,,,,,
47,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,18,cymlfo,self.MachineLearning,Could training with random inputs before actual training increase a NN models performance?,https://www.reddit.com/r/MachineLearning/comments/cymlfo/could_training_with_random_inputs_before_actual/,rodrigonader,1567415106,[removed],0,1,False,self,,,,,
48,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,18,cymvp0,medium.com,Benefits of Using Machine Learning in Supply Chain,https://www.reddit.com/r/MachineLearning/comments/cymvp0/benefits_of_using_machine_learning_in_supply_chain/,erpintegration,1567417292,,0,1,False,default,,,,,
49,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,20,cynuuk,blog.paralleldots.com,Most successful use-cases of Artificial Intelligence for Businesses - ParallelDots,https://www.reddit.com/r/MachineLearning/comments/cynuuk/most_successful_usecases_of_artificial/,anantcoolblabla,1567424203,,0,1,False,https://b.thumbs.redditmedia.com/-2rlW8vgxvvDDDbuXNDupVvSPXEVM4Q-iTqnOs_lz7E.jpg,,,,,
50,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,20,cynzva,dkoding.in,"Elon Musk Vs Jack Ma: Thoughts on AI, Mars",https://www.reddit.com/r/MachineLearning/comments/cynzva/elon_musk_vs_jack_ma_thoughts_on_ai_mars/,DkodingOfficial,1567425137,,0,1,False,https://b.thumbs.redditmedia.com/3MupBSGiKYCpB6ZrUCiSeiRNJDhApX_Leh3VKJtZTcU.jpg,,,,,
51,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,21,cyo7mj,self.MachineLearning,I applied for Scannet dataset by e_mail lat week but have not gotten any respose yet.,https://www.reddit.com/r/MachineLearning/comments/cyo7mj/i_applied_for_scannet_dataset_by_e_mail_lat_week/,Prominemmmm,1567426506,I applied for Scannet dataset by e_mail last week but have not gotten any response yet. Could anybody tell me how to get scannet dataset?,0,1,False,self,,,,,
52,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,23,cypkli,self.learnmachinelearning,Quiz: 189 Objective Type Deep Learning Questions (Modified Version),https://www.reddit.com/r/MachineLearning/comments/cypkli/quiz_189_objective_type_deep_learning_questions/,nkptcs,1567434090,,0,1,False,default,,,,,
53,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,23,cypt7r,self.MachineLearning,Why does all collaborative filtering recommendation system ask users for 3 recent items,https://www.reddit.com/r/MachineLearning/comments/cypt7r/why_does_all_collaborative_filtering/,__noobzor__,1567435264,All the popular collaborative reco systems ask for atleast 3 recently used items to recommend you the next item you should use. Why was 3 chosen why not 5 or 10?,0,1,False,self,,,,,
54,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,23,cypt9a,youtube.com,[P] We made a music video using NVIDIA's StyleGAN,https://www.reddit.com/r/MachineLearning/comments/cypt9a/p_we_made_a_music_video_using_nvidias_stylegan/,kinezodin,1567435272,,0,1,False,default,,,,,
55,MachineLearning,t5_2r3gv,2019-9-2,2019,9,2,23,cypur2,arxiv.org,Learning Optimal Transport in the Wasserstein-2 metric using Input Convex Neural Networks,https://www.reddit.com/r/MachineLearning/comments/cypur2/learning_optimal_transport_in_the_wasserstein2/,pikachuchameleon,1567435461,,1,1,False,default,,,,,
56,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,0,cyq3pf,self.MachineLearning,[Project] Advanced Pandas: Optimize speed and memory,https://www.reddit.com/r/MachineLearning/comments/cyq3pf/project_advanced_pandas_optimize_speed_and_memory/,BigDataRepublic,1567436658,"We made a comparison of various Pandas functions for indexing, vectorization and filtering. We benchmarked and compared their performance. For example, we found out that using a vectorized function to transform data is 82000x faster than using a for-loop with `iloc[]`. Check out the blog post with more details on various Pandas optimizations here: https://medium.com/bigdatarepublic/advanced-pandas-optimize-speed-and-memory-a654b53be6c2",7,0,False,self,,,,,
57,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,0,cyq6oj,self.learnmachinelearning,Help // Multi-layer recurrent unit?,https://www.reddit.com/r/MachineLearning/comments/cyq6oj/help_multilayer_recurrent_unit/,cbntt,1567437026,,0,1,False,https://b.thumbs.redditmedia.com/GnHFyLRBR4wCB8rBqrNMREXIxpXj5-Un5GhUTsI2qRs.jpg,,,,,
58,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,0,cyqhie,self.MachineLearning,Downloading videos from youtube and feed them as training data : legal ?,https://www.reddit.com/r/MachineLearning/comments/cyqhie/downloading_videos_from_youtube_and_feed_them_as/,MachingLearnin,1567438393,[removed],0,1,False,self,,,,,
59,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,0,cyqsh6,medium.com,AI Video Colourization Without References or Human Guidance,https://www.reddit.com/r/MachineLearning/comments/cyqsh6/ai_video_colourization_without_references_or/,Yuqing7,1567439762,,0,1,False,https://b.thumbs.redditmedia.com/bp7WJFBBSiqN3HMUen2BmJz24aPLzo70LHC1_zGyvsQ.jpg,,,,,
60,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,1,cyr20g,self.MachineLearning,[Research] Google Research Finds a Way to Reduce Noise in Training Data,https://www.reddit.com/r/MachineLearning/comments/cyr20g/research_google_research_finds_a_way_to_reduce/,cdossman,1567440934,"Abstract:  We introduce a temperature into the exponential function and replace the softmax output layer of neural nets by a high temperature generalization. Similarly, the logarithm in the log loss we use for training is replaced by a low temperature logarithm. By tuning the two temperatures we create loss functions that are nonconvex already in the single layer case. When replacing the last layer of the neural nets by our bi-temperature generalization of logistic loss, the training becomes more robust to noise. We visualize the effect of tuning the two temperatures in a simple setting and show the efficacy of our method on large data sets. Our methodology is based on Bregman divergences and is superior to a related two-temperature method using the Tsallis divergence. 

[https://ai.googleblog.com/2019/08/bi-tempered-logistic-loss-for-training.html](https://ai.googleblog.com/2019/08/bi-tempered-logistic-loss-for-training.html)",39,269,False,self,,,,,
61,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,1,cyrg66,nature.com,Molecules generated by deep learning model validated in mice,https://www.reddit.com/r/MachineLearning/comments/cyrg66/molecules_generated_by_deep_learning_model/,zhebrak,1567442679,,0,1,False,https://b.thumbs.redditmedia.com/umLsFCQr5AbEpBVbgrU9E6rw3vjuaqb0PiL213BKySQ.jpg,,,,,
62,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,1,cyrk4j,twitter.com,Your Reinforcement Learning Solution - LOL,https://www.reddit.com/r/MachineLearning/comments/cyrk4j/your_reinforcement_learning_solution_lol/,GantMan,1567443155,,0,1,False,https://b.thumbs.redditmedia.com/Y5o8luUqEixtSfShdHBrQ6_ebgL3pXyueWmnbe0EHgY.jpg,,,,,
63,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,1,cyrn45,self.MachineLearning,"[N] 08/19 Machine Learning and Data Science articles, papers and news",https://www.reddit.com/r/MachineLearning/comments/cyrn45/n_0819_machine_learning_and_data_science_articles/,ixeption,1567443503,[removed],0,1,False,self,,,,,
64,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,2,cyrq59,self.MachineLearning,"[P] Conditional Density Estimation Python Package and Large Benchmark with Neural Networks (MDN, KMN, Normalizing Flow) and Non-/Semi-parametric estimators",https://www.reddit.com/r/MachineLearning/comments/cyrq59/p_conditional_density_estimation_python_package/,whiletrue2,1567443862,"We've implemented an extensive pip package for Conditional Density Estimation that, among other features, includes Mixture Density Network, Kernel Mixture Network, Normalizing Flow Estimator and various non-parametric/semi-parametric estimators (CKDE, NKDE, LSKDE), data simulators and evaluation functions (centered moments, KL/JS divergence, Hellinger distance, percentiles etc.).

The package is constantly improved and we also provide a benchmark &amp; best practices report and a code documentation.

Code: [https://github.com/freelunchtheorem/Conditional\_Density\_Estimation](https://github.com/freelunchtheorem/Conditional_Density_Estimation)

Benchmark and best practices paper for NN-based CDE: [https://arxiv.org/abs/1903.00954](https://arxiv.org/abs/1903.00954)

ICLR2020-submitted paper on a devised noise regularization scheme for CDE: [https://arxiv.org/abs/1907.08982](https://arxiv.org/abs/1907.08982) 

Code docs: [https://freelunchtheorem.github.io/Conditional\_Density\_Estimation/docs/html/index.html](https://freelunchtheorem.github.io/Conditional_Density_Estimation/docs/html/index.html)

We're open for suggestions and feedback so please feel free to use &amp; comment. Lastly, if you like our project, we'd be happy if you spread the word and star the GH repo.",3,10,False,self,,,,,
65,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,2,cysdhj,self.MachineLearning,[R] Consistency Measures for Video Segmentation. Are any good papers available?,https://www.reddit.com/r/MachineLearning/comments/cysdhj/r_consistency_measures_for_video_segmentation_are/,Achepurnoi,1567446617,"Hello 

I am currently working on my master's thesis (early stage) and I plan to do measuring and optimizing the video processing consistency and quality. For example, if we are doing the segmentation for the video we can get inconsistent predictions on consecutive frames. 

I struggle very hard to find a related works papers - currently I have found only one good paper (Title of the paper: New Method for Evaluation of Video Segmentation Quality - 2015). Most of the papers are related to improvements in the model/segmentation metrics for one frame. 

I would appreciate if someone could help me to get started with a few links to papers related to this problem, relevant search keywords etc. Also, if you have any thoughts about my topic of interest in general - I would also be happy to hear!",0,2,False,self,,,,,
66,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,3,cysiuo,self.MachineLearning,Machine Learning/ Deep Learning Swag,https://www.reddit.com/r/MachineLearning/comments/cysiuo/machine_learning_deep_learning_swag/,juanjop777,1567447269,[removed],0,1,False,self,,,,,
67,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,3,cyslel,self.MachineLearning,Machine Learning for Photo Editing?,https://www.reddit.com/r/MachineLearning/comments/cyslel/machine_learning_for_photo_editing/,Uncle_Retouch,1567447553,[removed],0,1,False,self,,,,,
68,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,3,cysttd,self.MachineLearning,[D] Intersections of Queuing theory and Active learning?,https://www.reddit.com/r/MachineLearning/comments/cysttd/d_intersections_of_queuing_theory_and_active/,argusdawns,1567448566,"Hello,

I'm a current graduate student working on developing a research project and my current idea is for human-in-the-loop mobile
health systems and how real time interacts with active learning with a single user. 

I'm wondering if this is even a good idea before going further, and if theirs any similar research people know of. 

[Proposal Draft](https://drive.google.com/file/d/1fIFYHB2DVFVL0_xbkUn5R44z8fnPuMIU/view?usp=sharing)",4,3,False,self,,,,,
69,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,3,cysvum,youtube.com,Music video made by AI using NVIDIA's StyleGAN !,https://www.reddit.com/r/MachineLearning/comments/cysvum/music_video_made_by_ai_using_nvidias_stylegan/,ryanwashacked,1567448815,,0,1,False,https://b.thumbs.redditmedia.com/gvuNgOl8_Kg0I0Jl8XAx7IdMzSMLrhxcpiqTqdwO2mE.jpg,,,,,
70,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,3,cytau4,self.MachineLearning,Does Ml/Dl model accuracy differ due to machine specifications?,https://www.reddit.com/r/MachineLearning/comments/cytau4/does_mldl_model_accuracy_differ_due_to_machine/,Ahmii_Faraz,1567450671,[removed],0,1,False,self,,,,,
71,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,4,cytdxu,self.MachineLearning,Gaussian Inputs to VGG16,https://www.reddit.com/r/MachineLearning/comments/cytdxu/gaussian_inputs_to_vgg16/,Simusid,1567451055,[removed],0,1,False,self,,,,,
72,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,4,cytepy,self.MachineLearning,Deep learning,https://www.reddit.com/r/MachineLearning/comments/cytepy/deep_learning/,Deran_aiden,1567451149,[removed],0,1,False,self,,,,,
73,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,4,cytywj,self.MachineLearning,Domain-Agnostic Learning with Anatomy-Consistent Embedding for Cross-Modality Liver Segmentation,https://www.reddit.com/r/MachineLearning/comments/cytywj/domainagnostic_learning_with_anatomyconsistent/,junlin639,1567453605,[removed],0,1,False,self,,,,,
74,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,4,cyu307,self.MachineLearning,[D] Do you guys use low level tensorflow or high level Keras to build neural nets?,https://www.reddit.com/r/MachineLearning/comments/cyu307/d_do_you_guys_use_low_level_tensorflow_or_high/,tritonEYE,1567454102,"With Tensorflow 2.0 arriving soon, keras is going to be tightly integrated to be used for building neural nets. What do you use for building nets? For personal projects and for your career?",30,10,False,self,,,,,
75,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,5,cyu92h,arxiv.org,Domain-Agnostic Learning with Anatomy-Consistent Embedding for Cross-Modality Liver Segmentation (Appearing in ICCV 2019 Workshops),https://www.reddit.com/r/MachineLearning/comments/cyu92h/domainagnostic_learning_with_anatomyconsistent/,junlin639,1567454835,,1,1,False,default,,,,,
76,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,5,cyue0o,self.MachineLearning,[D] Do you guys use low level tensorflow or high level Keras to build neural nets?,https://www.reddit.com/r/MachineLearning/comments/cyue0o/d_do_you_guys_use_low_level_tensorflow_or_high/,tritonEYE,1567455453,"With Tensorflow 2.0 arriving soon, keras is going to be tightly integrated to be used for building neural nets. What do you use for building nets? For personal projects and for your career?",0,1,False,self,,,,,
77,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,6,cyv2vm,self.MachineLearning,"RL) questions regarding log std, clipping outputs.",https://www.reddit.com/r/MachineLearning/comments/cyv2vm/rl_questions_regarding_log_std_clipping_outputs/,wongongv,1567458512,[removed],0,1,False,self,,,,,
78,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,6,cyv9e8,self.MachineLearning,"[D] RL) questions regarding log std, clipping outputs.",https://www.reddit.com/r/MachineLearning/comments/cyv9e8/d_rl_questions_regarding_log_std_clipping_outputs/,wongongv,1567459336,"I'm trying to implement A2C in TF2.0 without using additional libraries like baselines.
But I'm having problem with standard deviation(std) and clipping.


First of all, I made variable log_std to avoid 0s in calculations(I exponentiate it when I use log_std like tf.exp(log_std)). I've seen this trick in CS294-112 homework2, so I'm using it. But, when I gather trainable variables to train, I'm just using log_std, but is it okay to do this? (Since I made variable which is not exponentiated, so I think I can only update this, but not in exponentiated form)
I feel like I shouldn't since the values of derivative will be different when NN do back-propagating.

Second, I'm clipping actions with tf.clip_by_value(ac, env.action_space.low, env.action_space.high). But, I'm not sure how to clip NN's output(NN is set to output mean of Gaussian distribution). NN should always output distributions with maximum : env.action_space.high and minimum : env.action_space.low as far as I know. But since I'm using Gaussian distribution, it is impossible to apply above constriction. Then what is usual way to clip NN's output in case we use Gaussian distribution(or other distributions)?



Final question: do you think I should use RL libraries like tensorforce and baselines?",1,0,False,self,,,,,
79,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,6,cyvgkr,arxiv.org,[Research] Learning Optimal Transport maps in Wasserstein-2 metric using Convex Neural Networks,https://www.reddit.com/r/MachineLearning/comments/cyvgkr/research_learning_optimal_transport_maps_in/,pikachuchameleon,1567460254,,5,9,False,default,,,,,
80,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,6,cyvnmh,mitai.eventbrite.com,The best way to connect with leading AI experts in Palo Alto - MIT CNC AI Conference - Discount Ends Midnight on 9/4,https://www.reddit.com/r/MachineLearning/comments/cyvnmh/the_best_way_to_connect_with_leading_ai_experts/,chubetob82,1567461186,,1,1,False,default,,,,,
81,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,8,cywi13,self.MachineLearning,What is the difference between Zero Shot Learning and clustering?,https://www.reddit.com/r/MachineLearning/comments/cywi13/what_is_the_difference_between_zero_shot_learning/,van_ozy,1567465273,[removed],0,1,False,self,,,,,
82,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,9,cyxr0z,self.MachineLearning,PyWarm: A cleaner way to build neural networks for PyTorch,https://www.reddit.com/r/MachineLearning/comments/cyxr0z/pywarm_a_cleaner_way_to_build_neural_networks_for/,very-blue-season,1567471835,[removed],2,1,False,self,,,,,
83,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,10,cyy3uq,ideasverge.com,the-language-of-a-computer,https://www.reddit.com/r/MachineLearning/comments/cyy3uq/thelanguageofacomputer/,pro272,1567473777,,0,1,False,default,,,,,
84,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,10,cyyei7,self.MachineLearning,Classify 100 classes,https://www.reddit.com/r/MachineLearning/comments/cyyei7/classify_100_classes/,kevz5,1567475417,"So I'm working on a supervised text classification problem where I need to classify a 100 classes. The way I look at it, I have following approaches-

1. 100 logistic regression classifications with each class against everything else; and then choose the class with highest logistic regression score

2. A neural network with n (=3?) Layers with a 100 neurons (1 neuron per class) each. And then use softmax to get 100 probabilities and choose the one with the highest.

3. Train a Random Forest Classifier? Not sure how good it will be with 100 classes.

Please add any other approaches you think would apply in this case, and let me know what you think will be the best approach here.",0,1,False,self,,,,,
85,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,11,cyyxz1,self.MachineLearning,Creative approaches to training to predict profit (or some metric of company success) using a product description and other various attributes of a company,https://www.reddit.com/r/MachineLearning/comments/cyyxz1/creative_approaches_to_training_to_predict_profit/,-chaytan-,1567478417,[removed],0,1,False,self,,,,,
86,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,13,cyzxns,self.MachineLearning,Data Science Career Track Prep Course,https://www.reddit.com/r/MachineLearning/comments/cyzxns/data_science_career_track_prep_course/,HannahHumphreys,1567484280,[removed],0,1,False,self,,,,,
87,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,15,cz19h0,youtube.com,Collaborative Recommendation System Using Python | Machine Learning,https://www.reddit.com/r/MachineLearning/comments/cz19h0/collaborative_recommendation_system_using_python/,OliviaWillson,1567493287,,0,1,False,https://a.thumbs.redditmedia.com/cUEDPsCMs2T1Wt0eTIKSbr0M_dyjjkMncxlRlDh-4u4.jpg,,,,,
88,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,15,cz19yd,self.MachineLearning,Neural Ordinary Differential Equations - Appendix E,https://www.reddit.com/r/MachineLearning/comments/cz19yd/neural_ordinary_differential_equations_appendix_e/,albert1905,1567493381,[removed],0,1,False,self,,,,,
89,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,15,cz1azc,statanalytica.com,Statistics vs Machine Learning: Which is More Powerful - Statanalytica,https://www.reddit.com/r/MachineLearning/comments/cz1azc/statistics_vs_machine_learning_which_is_more/,Statistics_helpers,1567493585,,0,1,False,default,,,,,
90,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,15,cz1bbd,self.MachineLearning,Pathology/cancer related machine learning project ideas,https://www.reddit.com/r/MachineLearning/comments/cz1bbd/pathologycancer_related_machine_learning_project/,yetal135,1567493639,[removed],0,1,False,self,,,,,
91,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,16,cz1k82,self.MachineLearning,[R] Videos of Deep|Bayes 2019  a summer school on Bayesian Deep Learning,https://www.reddit.com/r/MachineLearning/comments/cz1k82/r_videos_of_deepbayes_2019_a_summer_school_on/,asobolev,1567495439,"Just like [the last year](https://www.reddit.com/r/MachineLearning/comments/9dgnl3/r_videos_of_deepbayes_summer_school_on_bayesian/), we've taught a summer school on Bayesian DL and are happy to share all the materials with anyone interested.

\[ [**Videos**](https://www.youtube.com/playlist?list=PLe5rNUydzV9QHe8VDStpU0o8Yp63OecdW) | [**Slides**](https://github.com/bayesgroup/deepbayes-2019/tree/master/lectures) | [**Practicals**](https://github.com/bayesgroup/deepbayes-2019/tree/master/seminars) | [Website](http://deepbayes.ru/) \]",21,379,False,self,,,,,
92,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,16,cz1s6l,self.MachineLearning,[Research] Tensor-train-based VAE model generates a novel drug in 21 days,https://www.reddit.com/r/MachineLearning/comments/cz1s6l/research_tensortrainbased_vae_model_generates_a/,Akiiino,1567497160,"The title basically speaks for itself. In a new [paper](https://www.nature.com/articles/s41587-019-0224-x) a team of researchers from Insilico Medicine present a new model called GENTRL (https://github.com/insilicomedicine/GENTRL) for molecule generation. This algorithm, given a protein target, has generated a novel drug in 21 days, and after 25 more days of synthesis and testing, its predicted biological and chemical properties were confirmed in live mice.

The model itself is quite interesting: they use a VAE with tensor trains as a latent space; this was pre-trained via regular ELBO maximization, and after that was optimised for novelty via REINFORCE. The code is freely available and is written in PyTorch.",4,129,False,self,,,,,
93,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,16,cz1skf,i.redd.it,Using 2D scout CT scans to tackle current issues in deep learning for X-ray and CT modalities,https://www.reddit.com/r/MachineLearning/comments/cz1skf/using_2d_scout_ct_scans_to_tackle_current_issues/,bmibott,1567497249,,0,1,False,default,,,,,
94,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,17,cz25mu,self.MachineLearning,"The recent trends in AI - AI Weekly - Issue #5 - New to ML section, Personal AI trainer, DistilBERT, Revisiting Bias-Variance",https://www.reddit.com/r/MachineLearning/comments/cz25mu/the_recent_trends_in_ai_ai_weekly_issue_5_new_to/,santoshgadde,1567500255,[removed],0,1,False,self,,,,,
95,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,18,cz2cbr,self.MachineLearning,Deep learning approach for detecting any part of a human in an image???,https://www.reddit.com/r/MachineLearning/comments/cz2cbr/deep_learning_approach_for_detecting_any_part_of/,Ben-Harries,1567501675,"Been using fastai DL toolkit recently and want to apply it to detecting if image consent is needed for an image post on my companies platform.

Would the way be to use multilabel classification of many images of people? 

Tagged eg. foot; skin; kind of thing and then train and work it out. 

Need to then train on images which don't contain humans or not needed? Can then work out if patient consent is needed.

Any small response would be very much appreciated!",0,1,False,self,,,,,
96,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,18,cz2oc3,ideas2it.com,Machine learning framework to identify companies,https://www.reddit.com/r/MachineLearning/comments/cz2oc3/machine_learning_framework_to_identify_companies/,LiamJames03,1567504100,,0,1,False,default,,,,,
97,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,19,cz2z9b,self.learnprogramming,How do companies integrate Machine Learning effectively?,https://www.reddit.com/r/MachineLearning/comments/cz2z9b/how_do_companies_integrate_machine_learning/,davemadgew,1567506208,,0,1,False,default,,,,,
98,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,19,cz2zz9,blog.paralleldots.com,Emerging Applications of AI in Marketing,https://www.reddit.com/r/MachineLearning/comments/cz2zz9/emerging_applications_of_ai_in_marketing/,anantcoolblabla,1567506343,,0,1,False,https://b.thumbs.redditmedia.com/tsnTew9bv5xgHriaGF_-uFyeX2VEiVGcmwP17pLcHxs.jpg,,,,,
99,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,19,cz327y,self.MachineLearning,[D] How do you add labels in a conditional convolutional VAE?,https://www.reddit.com/r/MachineLearning/comments/cz327y/d_how_do_you_add_labels_in_a_conditional/,Fishy_soup,1567506784,"Silly question, but I haven't been able to find any code examples on how to do this properly. I'm guessing you can't add the label information to the first layer like you would in a dense VAE. Do you need to use a secondary layer that feeds the labels into the mean/std layer? Any advice would be appreciated!",2,4,False,self,,,,,
100,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,20,cz3v47,self.MachineLearning,What are limits of RoBERTa / NLP?,https://www.reddit.com/r/MachineLearning/comments/cz3v47/what_are_limits_of_roberta_nlp/,QueenLaniakea,1567511795,[removed],0,1,False,self,,,,,
101,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,21,cz40g5,self.MachineLearning,[D] Library to extract sentiment from business news?,https://www.reddit.com/r/MachineLearning/comments/cz40g5/d_library_to_extract_sentiment_from_business_news/,firewolf333,1567512626,"I was looking to extract if any news related to a company was positive or negative from news using python.

Which libraries would work good for such a project?",1,0,False,self,,,,,
102,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,21,cz40w3,self.MachineLearning,If you had all the supply chain data in the world...,https://www.reddit.com/r/MachineLearning/comments/cz40w3/if_you_had_all_the_supply_chain_data_in_the_world/,dkoded,1567512688,[removed],0,1,False,self,,,,,
103,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,21,cz414v,self.MachineLearning,"[D] Machine learning, alchemy or real science?",https://www.reddit.com/r/MachineLearning/comments/cz414v/d_machine_learning_alchemy_or_real_science/,oucp,1567512734,"A while ago I've seen a [video of a talk by Ali Rahimi](https://www.youtube.com/watch?v=x7psGHgatGM). It's worth the 20 minutes for people who haven't seen it!

I recently rewatched it and tried to look around if I could find papers which go into the direction of focusing more onto smaller ML experiments to build fundamental knowledge. But I've not found much aside from stuff on interpretability.

As a side note, I'm not an ML researcher but a physicist who uses ML in various aspects for work. I'd not consider myself an expert on any ML specific field but have an interest and try to keep up to date on things. From my personal experience, I've certainly felt (not sure how to describe it but let's go with annoyed/demotivated) to use ML when it's not clear to me why certain things work. 

So a lot of times it seems more like Alchemy, in that I mix and match certain things until I get a result I like.

 But why does it work? No clue. 

Will it work for the next problem that is sufficiently different? No clue! 

&amp;#x200B;

I'd be very interested to hear what other people think or how they feel about this topic.

Also if you know of any paper seeking to build a more fundamental understanding, I'd appreciate a link :)",7,0,False,self,,,,,
104,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,21,cz42lg,self.MachineLearning,[D] When Is It Better To Keep The Algorithm To Yourself?,https://www.reddit.com/r/MachineLearning/comments/cz42lg/d_when_is_it_better_to_keep_the_algorithm_to/,mystikaldanger,1567512977,"[Crosspost r/datascience](https://www.reddit.com/r/datascience/comments/csfptu/when_is_it_better_to_keep_the_algorithm_to/)

Suppose you're working on a machine learning/coding contest and through your own research come up with a technique that is say, 4% better than the best thing anyone has tried (just pulling numbers out of the air here).

At what point is it better to not claim the prize on said contest and just keep the method secret? At what point should you publish it? Does it ever make sense to just use it in your own capacity analyzing data for companies as a 3rd party?

I mean I'm sure it's all dependent on the money involved but one has to wonder where the breaking point is. What can you make as an independent 3rd party willing to do analysis with proprietary software you aren't releasing?

In such a case, how could you ever provide confidence enough that the methods work? Also, how would you bill if essentially the time spent is mainly runtime? I'd love to hear any speculation, stories, industry standard behavior or history around this sort of thing.",7,0,False,self,,,,,
105,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,21,cz47tw,self.MachineLearning,Can AI Transform Compliance?,https://www.reddit.com/r/MachineLearning/comments/cz47tw/can_ai_transform_compliance/,andrew_westend,1567513777,Corporate compliance departments are being squeezed. Can machine learning and natural language processing help? See  [http://www.rmmagazine.com/2019/09/03/can-ai-transform-compliance/](http://www.rmmagazine.com/2019/09/03/can-ai-transform-compliance/),0,1,False,self,,,,,
106,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,21,cz481s,self.MachineLearning,Could someone please translate this from tensorflow to pytorch?,https://www.reddit.com/r/MachineLearning/comments/cz481s/could_someone_please_translate_this_from/,katiex7,1567513817,"    ```
    embedding = tf.Variable(tf.random_normal([params['max_words'], params['dim']]))
    embedding_lookup_for_x = tf.nn.embedding_lookup(embedding, words)
    
    # LSTM
    lstm_cell_fw = tf.nn.rnn_cell.BasicLSTMCell(params['lstm_size'], state_is_tuple = True)
    lstm_cell_bw = tf.nn.rnn_cell.BasicLSTMCell(params['lstm_size'], state_is_tuple = True)
    states, final_state = tf.nn.bidirectional_dynamic_rnn(
                                        cell_fw = lstm_cell_fw, 
                                        cell_bw = lstm_cell_bw,
                                        inputs = embedding_lookup_for_x, 
                                        dtype = tf.float32,
                                        time_major = False,
                                        sequence_length = length)
    lstm_out = tf.concat([states[0], states[1]], axis = 2)
    
    # Conditional random fields
    logits = tf.layers.dense(lstm_out, params['num_classes'])
    crf_params = tf.get_variable(""crf"", [params['num_classes'], params['num_classes']],
                                 dtype=tf.float32)
    pred_ids, _ = tf.contrib.crf.crf_decode(logits, crf_params, length)
    training = (mode == tf.estimator.ModeKeys.TRAIN)
    
    # Prediction
    if mode == tf.estimator.ModeKeys.PREDICT:
        predictions = { 
            'pred_ids': pred_ids,
            'tags': words,
            'length' : length,
        }
        export_outputs = {
          'prediction': tf.estimator.export.PredictOutput(predictions)
      }
    
        return tf.estimator.EstimatorSpec(mode, predictions=predictions,
                                          export_outputs=export_outputs)
    
    # Loss functions and optimizers
    log_likelihood, _ = tf.contrib.crf.crf_log_likelihood(
        logits, labels, length, crf_params)
    
    loss = tf.reduce_mean(-log_likelihood)
    train_op = tf.train.AdamOptimizer().minimize(
        loss, global_step = tf.train.get_or_create_global_step())
    
    # Training
    if mode == tf.estimator.ModeKeys.TRAIN:
        return tf.estimator.EstimatorSpec(mode = mode,
                                           loss = loss, train_op = train_op)
    ```
    It'd be really helpful for me if someone could give me the pytorch equivalent to this code. The code is from https://aihub.cloud.google.com/u/0/p/products%2F2290fc65-0041-4c87-a898-0289f59aa8ba
     section 3. Named entity recognition with Tensorflow",0,1,False,self,,,,,
107,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,21,cz4c7q,self.MachineLearning,Essentials of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/cz4c7q/essentials_of_machine_learning/,WorthApricot,1567514451,[removed],0,1,False,self,,,,,
108,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,21,cz4e6s,self.MachineLearning,Easiest thing to detect,https://www.reddit.com/r/MachineLearning/comments/cz4e6s/easiest_thing_to_detect/,DEAD_SH0T,1567514746,"What should be the easiest thing to detect in a real world image? Is it a cat, dog or person (owing to presence of large opensource data and research)? Is it characters for same reason in the form of OCR? Or is it simple patterns like lines and circles because of simplicity although data could be an issue. My problem is I have to to recognise objects and I have, say, a model to detect these objects accurately and I have the liberty to paint/colour patterns or photos on these objects. I know the conventional way is to print numbers and ocr them. I am looking for something simpler.",0,1,False,self,,,,,
109,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,21,cz4hci,self.MachineLearning,[D] What annotation tool do you use for your image/video datasets?,https://www.reddit.com/r/MachineLearning/comments/cz4hci/d_what_annotation_tool_do_you_use_for_your/,lolo_sicara,1567515203,"I have just written an article about a benchmark I made of labeling tools for computer vision.

[https://blog.sicara.com/best-open-source-annotation-tools-in-computer-vision-4b9f6a18f911](https://blog.sicara.com/best-open-source-annotation-tools-in-computer-vision-4b9f6a18f911)

Do you know other tools which I should talk about?",16,20,False,self,,,,,
110,MachineLearning,t5_2r3gv,2019-9-3,2019,9,3,22,cz570w,self.MachineLearning,"annoy, faiss, NGT-onng, hnswlib",https://www.reddit.com/r/MachineLearning/comments/cz570w/annoy_faiss_ngtonng_hnswlib/,mrelheib,1567518919,[removed],0,1,False,self,,,,,
111,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,0,cz65ly,talkrl.com,TalkRL Interviews Natasha Jaques,https://www.reddit.com/r/MachineLearning/comments/cz65ly/talkrl_interviews_natasha_jaques/,djangoblaster2,1567523476,,0,1,False,default,,,,,
112,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,0,cz66z5,self.MachineLearning,[D] Classifying high dimensional sequences using traditional machine learning methods,https://www.reddit.com/r/MachineLearning/comments/cz66z5/d_classifying_high_dimensional_sequences_using/,RaptorDotCpp,1567523645,"I'm a beginner in machine learning and I want to classify high dimensional sequences without using an LSTM or other deep learning methods, but using something simpler, to learn more about feature extraction.

I'm trying gesture recognition using OpenPose, with a couple of gestures of varying length. Because of OpenPose, I have 67 features (body and hands) times 3 (x, y, c). The sequences go from 4 to 43 frames, so there is a lot of variation there.

First of all, how do I google this? Time series classification is all about long, usually one dimensional sequences, while these are shorter and highly multi dimensional sequences. I don't know if this has been done before without deep learning?

Second of all, here is what I tried:

- Padding and clipping the sequences to the same length, then using an RBF SVC from sklearn.
- Extracting mean, median, std, max, min, and other statistics to obtain a fixed representation
- Performing Fourier transformations per keypoint/feature pair, so 67*3 transforms

All three of these overfit a lot, the Fourier one the most because of the high amount of features. PCA does not help a lot. Are Fourier transformations even useful here because there is no real periodicity in the gestures and the transformations look weird (normally you have these peaks in frequencies, but for me the Fourier transform just looks like a choppy sine wave for most cases)

How do I classify OpenPose sequences using machine learning and not deep learning?",4,1,False,self,,,,,
113,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,0,cz69dy,self.MachineLearning,"Explaning Activation Functions: Visualized and Math Explained - Pros and Cons of GELU, SELU etc.",https://www.reddit.com/r/MachineLearning/comments/cz69dy/explaning_activation_functions_visualized_and/,permalip,1567523968,[removed],0,1,False,self,,,,,
114,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,0,cz6eun,github.com,[D] DeepFaceLab: A tool that utilizes ML to replace faces in videos,https://www.reddit.com/r/MachineLearning/comments/cz6eun/d_deepfacelab_a_tool_that_utilizes_ml_to_replace/,BIASED_REVIEWER_1,1567524685,,0,1,False,default,,,,,
115,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,0,cz6f1g,github.com,[P] Deepfakes software for all,https://www.reddit.com/r/MachineLearning/comments/cz6f1g/p_deepfakes_software_for_all/,luiscosio,1567524708,,0,1,False,default,,,,,
116,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,0,cz6h3z,github.com,DeepFaceLab: A tool that utilizes ML to replace faces in videos,https://www.reddit.com/r/MachineLearning/comments/cz6h3z/deepfacelab_a_tool_that_utilizes_ml_to_replace/,j_orshman,1567524956,,0,1,False,https://b.thumbs.redditmedia.com/cY6-iAzcG7TRYPNcqVgIAt9WwD3Ojwv_lYMypA35bBQ.jpg,,,,,
117,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,0,cz6i50,nathanbenaich.com,AI-first biology,https://www.reddit.com/r/MachineLearning/comments/cz6i50/aifirst_biology/,nb410,1567525090,,0,1,False,default,,,,,
118,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,0,cz6l54,self.MachineLearning,NeurIPS reviews are out,https://www.reddit.com/r/MachineLearning/comments/cz6l54/neurips_reviews_are_out/,not_novel_enough,1567525477,[removed],0,1,False,self,,,,,
119,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,0,cz6lnb,self.MachineLearning,How do professors work in industry and academia at the same time?,https://www.reddit.com/r/MachineLearning/comments/cz6lnb/how_do_professors_work_in_industry_and_academia/,MainSupermarket,1567525541,[removed],0,1,False,self,,,,,
120,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,0,cz6q18,self.MachineLearning,How do I compute the gradient of a cosine loss?,https://www.reddit.com/r/MachineLearning/comments/cz6q18/how_do_i_compute_the_gradient_of_a_cosine_loss/,alaskaplath,1567526096,[removed],0,1,False,self,,,,,
121,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,0,cz6rdk,self.MachineLearning,[D] NeurIPS 2019 decisions are out,https://www.reddit.com/r/MachineLearning/comments/cz6rdk/d_neurips_2019_decisions_are_out/,adamb90,1567526263,In CMT,154,84,False,self,,,,,
122,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,0,cz6rvw,self.MachineLearning,Universal Adversarial Triggers for Attacking and Analyzing NLP,https://www.reddit.com/r/MachineLearning/comments/cz6rvw/universal_adversarial_triggers_for_attacking_and/,ericwallace_berkeley,1567526335,[removed],0,1,False,self,,,,,
123,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,1,cz6t0f,self.MachineLearning,NeuRIPS 2019 decision are out!!,https://www.reddit.com/r/MachineLearning/comments/cz6t0f/neurips_2019_decision_are_out/,UnluckyLocation,1567526484,Got rejected. Atleast read the rebuttals  guys.,0,1,False,self,,,,,
124,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,1,cz6xkp,researchgate.net,Fitting A Sobolev(H^k) Function To Data,https://www.reddit.com/r/MachineLearning/comments/cz6xkp/fitting_a_sobolevhk_function_to_data/,rajesh_d24,1567527032,,0,1,False,default,,,,,
125,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,1,cz71ac,self.MachineLearning,Universal Adversarial Triggers for Attacking and Analyzing NLP (EMNLP 2019),https://www.reddit.com/r/MachineLearning/comments/cz71ac/universal_adversarial_triggers_for_attacking_and/,ericwallace_berkeley,1567527507,[removed],0,1,False,self,,,,,
126,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,1,cz73ns,medium.com,Clone a Voice in Five Seconds With This AI Toolbox,https://www.reddit.com/r/MachineLearning/comments/cz73ns/clone_a_voice_in_five_seconds_with_this_ai_toolbox/,Yuqing7,1567527809,,0,1,False,https://a.thumbs.redditmedia.com/blebDkpO7M-yp7T2muydeKWo7JSrCk5BgnCNutC8xw0.jpg,,,,,
127,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,1,cz769i,self.MachineLearning,Universal Adversarial Triggers for Attacking and Analyzing NLP (EMNLP 2019),https://www.reddit.com/r/MachineLearning/comments/cz769i/universal_adversarial_triggers_for_attacking_and/,Eric_WallaceUMD,1567528135,[removed],0,1,False,self,,,,,
128,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,1,cz7bfl,self.MachineLearning,[Research] Universal Adversarial Triggers for Attacking and Analyzing NLP (EMNLP 2019),https://www.reddit.com/r/MachineLearning/comments/cz7bfl/research_universal_adversarial_triggers_for/,Eric_WallaceUMD,1567528783,"Hi, I am one of the authors of this EMNLP 2019 paper.

&amp;#x200B;

We create Universal Adversarial Triggers: 

Phrases that cause a specific model prediction when concatenated to  input.

Triggers cause:

\- GPT-2 to turn racist

\- SQuAD models to predict ""to kill american people"" for 72% of ""why"" questions

\- Text classifier accuracy 90%-&gt;1%.

&amp;#x200B;

Paper: [https://arxiv.org/abs/1908.07125](https://arxiv.org/abs/1908.07125)

Twitter: [https://twitter.com/Eric\_Wallace\_/status/1168907518623571974](https://twitter.com/Eric_Wallace_/status/1168907518623571974)

Blog: [http://ericswallace.com/triggers](http://ericswallace.com/triggers)",2,25,False,self,,,,,
129,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,2,cz7uck,deepmind.com, Episode 6: AI for everyone,https://www.reddit.com/r/MachineLearning/comments/cz7uck/episode_6_ai_for_everyone/,sjoerdapp,1567531158,,0,1,False,https://b.thumbs.redditmedia.com/-DbVOQyO5J6NB86RyHZ43r7hHzpFxE4uUpQkKE6A8Ng.jpg,,,,,
130,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,2,cz7vok,self.MachineLearning,Best ide for python?,https://www.reddit.com/r/MachineLearning/comments/cz7vok/best_ide_for_python/,marloquemegusta,1567531324,[removed],0,1,False,self,,,,,
131,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,2,cz80x1,self.MachineLearning,[D] Model to predict site outage on Telecommunication Networks,https://www.reddit.com/r/MachineLearning/comments/cz80x1/d_model_to_predict_site_outage_on/,macacochimpa,1567531987,"Context: Telecommunication Networks are complex multi-vendor/technology (Huawei, Ericsson, Nokia, ...) which NOC (Network Operation Center) continually monitor and respond to faults/failures on equipment &amp; sites usually concentrating all alarms from different vendors.

Challenge: Use historical data to predict if a site will go down on the next hour (or so) based on the events their NMS (Network Management Software) are collecting from all elements - this is a time window-based analysis that chances all the time.  


Anyone on the community that have faced this (or a similar problem) would like to share any thoughts / papers / links to solution/model/approach ?",4,0,False,self,,,,,
132,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,2,cz86ny,self.MachineLearning,[D] python ide similar to sublime?,https://www.reddit.com/r/MachineLearning/comments/cz86ny/d_python_ide_similar_to_sublime/,marloquemegusta,1567532713,"Hi! I have been learning and working on machine learning with python for a few months alredy. Since the beginning I have been using spyder, but I find it ugly and non aesthetic at all.
I really like the ide itself, just dislike its appearance.
I would like to find something like sublime text but with a command terminal. Do you know any?
Thanks in advance",8,0,False,self,,,,,
133,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,2,cz88wu,self.MachineLearning,[D] are multiclass unconditional GANs an open problem?,https://www.reddit.com/r/MachineLearning/comments/cz88wu/d_are_multiclass_unconditional_gans_an_open/,mesmer_adama,1567532998,When reading the Progressive growing of gans by Karras at Nvidia they claim that they get good representations on an cifar10 unconditionally trained. I thought mode collapse for multiclass datasets was still mostly unsolved for gans. Is this partially solved with their models or am I missing something? Why is this considered such a hard problem and how does their results relate to the area?,8,3,False,self,,,,,
134,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,2,cz8dek,self.MachineLearning,Webinar: Patenting AI,https://www.reddit.com/r/MachineLearning/comments/cz8dek/webinar_patenting_ai/,CometML,1567533555,[removed],0,1,False,self,,,,,
135,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,3,cz8ggn,self.MachineLearning,Choose a name for podcasting on artificial intelligence and deep learning and machine learning,https://www.reddit.com/r/MachineLearning/comments/cz8ggn/choose_a_name_for_podcasting_on_artificial/,Doctor_who1,1567533929,[removed],0,1,False,self,,,,,
136,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,3,cz8l5c,self.MachineLearning,"Choose a name for podcasting on artificial intelligence and neuroscience , deep learning and machine learning",https://www.reddit.com/r/MachineLearning/comments/cz8l5c/choose_a_name_for_podcasting_on_artificial/,Doctor_who1,1567534530," 

hello . I've decided to creat a podcast about deep learning  machine learning  artifical inteligence , neuroscience ,....... which interviews with experts . But unfortunately I can't choose a suitable title for it. Could anyone choose some titles for it ?",0,1,False,self,,,,,
137,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,4,cz9gk2,deccanherald.com,Thought I share it here.,https://www.reddit.com/r/MachineLearning/comments/cz9gk2/thought_i_share_it_here/,voldemort_queen,1567538439,,0,1,False,https://b.thumbs.redditmedia.com/rOTR9TW5NVFYXAT1-ZAnu11tI4F2OpXK5D0JOW1VGSg.jpg,,,,,
138,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,4,cz9qmo,self.MachineLearning,[D] looking for subjective evaluation tools or web service,https://www.reddit.com/r/MachineLearning/comments/cz9qmo/d_looking_for_subjective_evaluation_tools_or_web/,da_g_prof,1567539689,"Some of us work in image synthesis / translation problems where we can't use Amazon Mturk.

We need to show people some images and we want them to score / rank each picture or pair or panel etc 

Our current approach to this is to create a stack of images or PDF and share it along with an excel etc.

Question 1: is there a tool that we can use to have users see a panel of images and rank/score from a drop down etc? I know we can write our own gui / interface but seems a bit redundant. Is there a simpler way? 

Question 2: you can see how the above won't scale to many different users . Are you aware of any web service / tool instead? (*)

* one time I did this as a Google form and send it to our specialist pool and worked out wonders but I had to hand do it. It seems that Google api has a scripting language to automate things (which means we may be able to automate part) but Google forms has restrictions in the width of images that can be shown so it affects the range of applications.",4,0,False,self,,,,,
139,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,4,cz9s6d,self.MachineLearning,Machine Learning with Python- Why do they form the best combination,https://www.reddit.com/r/MachineLearning/comments/cz9s6d/machine_learning_with_python_why_do_they_form_the/,andrea_manero,1567539879,[removed],0,1,False,self,,,,,
140,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,4,cz9y2n,self.MachineLearning,"""Persona Owners"" vs ""Experience Managers""",https://www.reddit.com/r/MachineLearning/comments/cz9y2n/persona_owners_vs_experience_managers/,sweedishfishy,1567540616,[removed],0,1,False,self,,,,,
141,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,5,cza0ib,arxiv.org,Domain-Agnostic Learning with Anatomy-Consistent Embedding for Cross-Modality Liver Segmentation (Appearing in ICCV 2019 Workshops),https://www.reddit.com/r/MachineLearning/comments/cza0ib/domainagnostic_learning_with_anatomyconsistent/,junlin639,1567540928,,1,0,False,default,,,,,
142,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,5,cza62n,medium.com,"Chinese DeepFake App Goes Viral, Renewing Concerns About Potential Misuse of Face-Swapping Tech",https://www.reddit.com/r/MachineLearning/comments/cza62n/chinese_deepfake_app_goes_viral_renewing_concerns/,Yuqing7,1567541615,,0,1,False,https://a.thumbs.redditmedia.com/rjxZpC0kYXht0FU1O4Bkv1NrjQcEvD_Rrz6nDNrL_24.jpg,,,,,
143,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,5,czagdl,self.MachineLearning,Data Science Specialization from Johns Hopkins University - Accelerate your career and income potential,https://www.reddit.com/r/MachineLearning/comments/czagdl/data_science_specialization_from_johns_hopkins/,internetdigitalentre,1567542893,[removed],0,1,False,self,,,,,
144,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,6,czbkci,youtu.be,"Nick's Non-fiction: Superintelligence (AI, Drones, Govt Supercomputers, Cyborgs)",https://www.reddit.com/r/MachineLearning/comments/czbkci/nicks_nonfiction_superintelligence_ai_drones_govt/,Niche96,1567547951,,0,1,False,default,,,,,
145,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,7,czbl6x,self.MachineLearning,[N] Major Release for mlfinlab,https://www.reddit.com/r/MachineLearning/comments/czbl6x/n_major_release_for_mlfinlab/,Jackal008,1567548065,"The latest version of mlfinlab ([Github](https://github.com/hudson-and-thames/mlfinlab)) has been released. 

A package based on the book: [Advances in Financial Machine Learning](https://www.amazon.co.uk/Advances-Financial-Machine-Learning-Marcos/dp/1119482089) by Marcos Lopez de Prado.

\`\`\`pip install mlfinlab\`\`\`

This new release is our biggest to date and includes code for:  

1. Sequentially Bootstrapped Ensembles (Regression &amp; Classification)  
2. Purged Cross-Validation
3. Feature Importance
4. Bet Sizing (+ EF3M)
5. ML Asset Allocation (HRP, CLA, IVP)

Documentation can be found on [Read-the-Docs](https://mlfinlab.readthedocs.io/en/latest/index.html).",2,67,False,self,,,,,
146,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,7,czbm8a,gfycat.com,Breeding Famous Paintings With Machine Learning,https://www.reddit.com/r/MachineLearning/comments/czbm8a/breeding_famous_paintings_with_machine_learning/,hoopism,1567548198,,0,1,False,default,,,,,
147,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,7,czbpkh,self.MachineLearning,Best Practice for Embedding pd df Object for Use in tf Custom Network,https://www.reddit.com/r/MachineLearning/comments/czbpkh/best_practice_for_embedding_pd_df_object_for_use/,unsupervisedmodeler,1567548626,[removed],0,1,False,self,,,,,
148,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,7,czc7wx,self.MachineLearning,What are the most sought after tool set for a Machine learning engineer? How is it different from a Data Scientist?,https://www.reddit.com/r/MachineLearning/comments/czc7wx/what_are_the_most_sought_after_tool_set_for_a/,datacrackers,1567551048,[removed],0,1,False,self,,,,,
149,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,7,czc84k,techdoodling.com,Image Classification with keras: Basics Explained,https://www.reddit.com/r/MachineLearning/comments/czc84k/image_classification_with_keras_basics_explained/,meancoder,1567551070,,0,1,False,default,,,,,
150,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,8,czccig,self.MachineLearning,"Evolution of Machine Learning, from Server to the Edge",https://www.reddit.com/r/MachineLearning/comments/czccig/evolution_of_machine_learning_from_server_to_the/,MarceloLopezUru,1567551653,[removed],0,1,False,self,,,,,
151,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,8,czckq5,youtube.com,Applied Data Science Coding with Python - Regression with CART Algorithm,https://www.reddit.com/r/MachineLearning/comments/czckq5/applied_data_science_coding_with_python/,setscholars,1567552779,,0,1,False,https://b.thumbs.redditmedia.com/zVfQU3e8XOgPG1ajrjlSxfiEZgFDiEEy6VDJcW3hFPs.jpg,,,,,
152,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,8,czcxel,zeldatech.com,Download Free Book : Machine Learning with Python for Everyone By Mark Fenner EPUB,https://www.reddit.com/r/MachineLearning/comments/czcxel/download_free_book_machine_learning_with_python/,psychonekk,1567554586,,0,1,False,default,,,,,
153,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,9,czdlz3,self.MachineLearning,Validation metrics,https://www.reddit.com/r/MachineLearning/comments/czdlz3/validation_metrics/,Ageofmyth1,1567558128,[removed],0,1,False,self,,,,,
154,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,9,czdox1,arxiv.org,Domain-Agnostic Learning with Anatomy-Consistent Embedding for Cross-Modality Liver Segmentation,https://www.reddit.com/r/MachineLearning/comments/czdox1/domainagnostic_learning_with_anatomyconsistent/,junlin639,1567558533,,1,0,False,default,,,,,
155,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,12,czf5uq,self.MachineLearning,Understanding Convolutional Layers from Udacity Tensorflow Course,https://www.reddit.com/r/MachineLearning/comments/czf5uq/understanding_convolutional_layers_from_udacity/,djzero1984,1567566184,[removed],0,1,False,self,,,,,
156,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,12,czfmfz,self.MachineLearning,"Noob question: Why not train autonomous vehicles with an infinitely time-scalable simulation, like GTA?",https://www.reddit.com/r/MachineLearning/comments/czfmfz/noob_question_why_not_train_autonomous_vehicles/,rustchild,1567568827,[removed],0,1,False,self,,,,,
157,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,13,czfw2b,self.MachineLearning,Exploring cause and effect in a system,https://www.reddit.com/r/MachineLearning/comments/czfw2b/exploring_cause_and_effect_in_a_system/,Fuerzacode,1567570393,"Hey everyone, I have been trying to understand in better context how I may be able to explore relationships that have leaded to a certain outcome but have not been able to put my finger on a particular algorithm, potentially you can help me.

 The problem be can look at would be something like weight loss. How the increase has caused weight gain and contributed to a increase is bodyweight, but with more features; i'm trying to simplify the problem here in order for it to be clear.

  Here is another example, let's say we have a motor vehicle and it has broke down - how can we explore the actions that took place that contributed to the break down? Assuming we have the required data that has been collected for us during X time.

Is there some rule set we can create and then explore deviations and outliers in that manner?",0,1,False,self,,,,,
158,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,14,czgixv,self.MachineLearning,"what is ""a factor of f"" of shift and stitch trick?",https://www.reddit.com/r/MachineLearning/comments/czgixv/what_is_a_factor_of_f_of_shift_and_stitch_trick/,minpkang,1567574484,[removed],0,1,False,self,,,,,
159,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,14,czgopr,self.MachineLearning,"what is ""a factor of f"" in a paper, &lt;FCN for semantic segmentation&gt;?",https://www.reddit.com/r/MachineLearning/comments/czgopr/what_is_a_factor_of_f_in_a_paper_fcn_for_semantic/,minpkang,1567575602,[removed],0,1,False,self,,,,,
160,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,15,czh1zn,arxiv.org,[R] DeepCopy: Grounded Response Generation with Hierarchical Pointer Networks,https://www.reddit.com/r/MachineLearning/comments/czh1zn/r_deepcopy_grounded_response_generation_with/,runvnc,1567578216,,1,0,False,default,,,,,
161,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,15,czhalt,self.MachineLearning,What classes to take in high school,https://www.reddit.com/r/MachineLearning/comments/czhalt/what_classes_to_take_in_high_school/,StaticVoidMain2018,1567579954,[removed],0,1,False,self,,,,,
162,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,16,czhjxk,self.MachineLearning,Looking for someone to work on projects,https://www.reddit.com/r/MachineLearning/comments/czhjxk/looking_for_someone_to_work_on_projects/,BeggarInSpain,1567581800,[removed],0,1,False,self,,,,,
163,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,16,czhspp,self.MachineLearning,Machine learning: go full stack or go home,https://www.reddit.com/r/MachineLearning/comments/czhspp/machine_learning_go_full_stack_or_go_home/,MichaelSloth,1567583678,[removed],0,1,False,self,,,,,
164,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,17,czhw84,kanoki.org,Pandas: Comprehensive guide on Groupby and Multiindex,https://www.reddit.com/r/MachineLearning/comments/czhw84/pandas_comprehensive_guide_on_groupby_and/,min2bro,1567584430,,0,1,False,default,,,,,
165,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,17,czi6f6,self.MachineLearning,[R] Learning without feedback: Direct random target projection as a feedback-alignment algorithm with layerwise feedforward training,https://www.reddit.com/r/MachineLearning/comments/czi6f6/r_learning_without_feedback_direct_random_target/,Neurom0rph,1567586778,"As there have been some interesting discussions on the alternatives to backpropagation lately (e.g. [this reddit thread](https://www.reddit.com/r/MachineLearning/comments/cwk1gf/d_alternatives_to_backpropagation)), I am sharing our latest work just made available on arXiv: 

***Learning without feedback:*** *Direct random target projection as a feedback-alignment algorithm with layerwise feedforward training*

[arXiv link](https://arxiv.org/abs/1909.01311) - [PyTorch code](https://github.com/ChFrenkel/DirectRandomTargetProjection)  

**Summary:**
Building on feedback-alignment algorithms, we show how to train multi-layer neural networks using random projections of the target vector, which enables layerwise weight updates using only local and feedforward information. The proposed algorithm is *called direct random target projection* (DRTP).
While backpropagation (BP) requires forward and backward weight symmetry (i.e. *weight transport problem*) and implies *update locking* before forward and backward passes have been completed, DRTP solves both problems toward higher *biological plausibility* and low-cost *hardware implementation*.
Indeed, estimating the layerwise loss gradients only requires a label-dependent random vector selection, making adaptive smart sensors and edge computing the ideal applications due to limited power and computing resources. Despite its simplicity, we demonstrate on the MNIST and CIFAR-10 datasets that DRTP performs close to BP, feedback alignment (FA), direct feedback alignment (DFA) algorithms.

The PyTorch code (link above) also includes implementations of FA and DFA.

Feedback is welcome!",10,17,False,self,,,,,
166,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,18,cziacb,thedatascientist.com,Dynamic pricing through machine learning,https://www.reddit.com/r/MachineLearning/comments/cziacb/dynamic_pricing_through_machine_learning/,TheTesseractAcademy,1567587680,,0,1,False,https://b.thumbs.redditmedia.com/NiCiXyYaM7nsm6pN9pNtpX957pjOu3TIkMzeO3zpRDY.jpg,,,,,
167,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,18,czib8p,self.MachineLearning,Best Way to generate synthetic image data,https://www.reddit.com/r/MachineLearning/comments/czib8p/best_way_to_generate_synthetic_image_data/,PyWarrior,1567587839,[removed],0,1,False,self,,,,,
168,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,18,czibe9,self.MachineLearning,Probability theory in making Algorithms,https://www.reddit.com/r/MachineLearning/comments/czibe9/probability_theory_in_making_algorithms/,TheLearningMan_45,1567587871,[removed],0,1,False,self,,,,,
169,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,18,czibki,arxiv.org,[R] Face-to-Parameter Translation for Game Character Auto-Creation,https://www.reddit.com/r/MachineLearning/comments/czibki/r_facetoparameter_translation_for_game_character/,hardmaru,1567587908,,6,44,False,default,,,,,
170,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,18,czie8x,self.MachineLearning,[P] 'ceviche' -- Simulating Maxwell's Equations using Automatic Differentiation.,https://www.reddit.com/r/MachineLearning/comments/czie8x/p_ceviche_simulating_maxwells_equations_using/,BarnyardPuer,1567588425,"We recently released our *ceviche* package on github, which simulates electromagnetic physics using automatic differentiation.  Thought it might be interesting to this community as an application of backpropagation techniques to science &amp; engineering applications outside of ML.

[https://github.com/twhughes/ceviche](https://github.com/twhughes/ceviche)

&amp;#x200B;

*Processing img rn724c41mjk31...*

Using automatic differentiation allows one to effortlessly differentiate the results of the simulation with respect to various design parameters defining the simulation.   This allows you  to do a lot of interesting things, for example:

\- Perform automated, gradient-based optimization of photonic devices.

\- Wrap the E&amp;M solver in a machine learning model and do end to end training of physical hardware, like we did [in this paper](https://arxiv.org/abs/1904.12831).

Most importantly, in contrast with what is common practice in the field of photonics, this can all be done \*without\* needing to do any tedious analytical calculations by hand, and one can rest assured that the derivatives are accurate and efficiently computed.

If you're interested in some of the nitty gritty details about reverse vs. forward mode differentiation in electromagnetic simulations, check out our pre-print as well, linked [here.](https://arxiv.org/abs/1908.10507)",11,146,False,self,,,,,
171,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,18,czilkb,self.MachineLearning,Probability distribution over classes as a type of classification?,https://www.reddit.com/r/MachineLearning/comments/czilkb/probability_distribution_over_classes_as_a_type/,nat2205,1567590010,[removed],0,1,False,self,,,,,
172,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,18,czimum,self.MachineLearning,[D] Deep Matching Prior Network for Object Detection,https://www.reddit.com/r/MachineLearning/comments/czimum/d_deep_matching_prior_network_for_object_detection/,thomas_ver,1567590258,"I am currently reading the Deep Matching Prior Network paper. The suggested network is used to get better predictions on scene text. Instead of using rectangular bounding boxes, they apply quadrangle shapes to get better localisations of text. 

I wondered if this could be applied in Object Detection algorithms, such as faster R-CNN.

Could anyone discuss in more detail why, or why not, this could be implemented and if so what the possible outcome might be?",0,0,False,self,,,,,
173,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,18,czio2y,self.MachineLearning,Materials on Knowledge Extraction,https://www.reddit.com/r/MachineLearning/comments/czio2y/materials_on_knowledge_extraction/,172knot,1567590503,[removed],0,1,False,self,,,,,
174,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,19,czixcd,self.MachineLearning,How can I download Div2K dataset?,https://www.reddit.com/r/MachineLearning/comments/czixcd/how_can_i_download_div2k_dataset/,karrhikey97,1567592314,[removed],0,1,False,self,,,,,
175,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,19,cziy8f,smarten.com,Self-Service Data Preparation that is Easy and Worry-Free!,https://www.reddit.com/r/MachineLearning/comments/cziy8f/selfservice_data_preparation_that_is_easy_and/,ElegantMicroWebIndia,1567592489,,0,1,False,default,,,,,
176,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,19,cziyrw,self.MachineLearning,Can anyone give some open machine learning research problems for my undergraduate research?,https://www.reddit.com/r/MachineLearning/comments/cziyrw/can_anyone_give_some_open_machine_learning/,FluidDecision,1567592588,[removed],0,1,False,self,,,,,
177,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,19,czj3rg,self.MachineLearning,[D] Explainability of PCA + Random Forest on images,https://www.reddit.com/r/MachineLearning/comments/czj3rg/d_explainability_of_pca_random_forest_on_images/,Kivid93,1567593559,"Good morning everyone.

I am working on a project where I have a dataset of images regarding an industrial product and I am currently classifying each image into two classes, let's say \[good, bad\].

In order to correctly classify the images, I am currently applying the following techniques in this order: [HOG](https://scikit-image.org/docs/dev/api/skimage.feature.html#skimage.feature.hog) \+ [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) \+ [Random Forest Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).

My performance are really good, but I have the necessity to know a specific information, which is roughly the following: ""this area of the image weight X% on the final classification"".

First of all, I am executing HOG, so the ""area of the image"" could be the HOG Cell. Then, I need to gather some feature importances. in order to get this information, Random Forest comes in handy because it will let you know the [feature importances](https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html) in percentage form, once trained. But here the problem arises: my features comes from a PCA. Now, is possible to execute an inverse transformation on a PCA output array and that will give you back the original features array before the application of PCA (which for me is the output of HOG). 

In my scenario, will it make sense to apply the inverse transformation to the array of feature importances? And if not, which approach should I go for?

Thanks in advance!",4,9,False,self,,,,,
178,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,20,czjbsi,self.MachineLearning,Machine learning notebook series,https://www.reddit.com/r/MachineLearning/comments/czjbsi/machine_learning_notebook_series/,runningmanlu,1567595074,[removed],0,1,False,self,,,,,
179,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,20,czjlcu,self.MachineLearning,Modes of Probability Distribution,https://www.reddit.com/r/MachineLearning/comments/czjlcu/modes_of_probability_distribution/,PyWarrior,1567596702,[removed],0,1,False,self,,,,,
180,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,20,czjtwz,self.MachineLearning,"[D] Machine Learning Specific ""Persona Owners""",https://www.reddit.com/r/MachineLearning/comments/czjtwz/d_machine_learning_specific_persona_owners/,sweedishfishy,1567598145,"Hi There -

My company has a defined role of ""Persona Owner"" -- but this is something I've never heard of before and can't find evidence of it existing elsewhere. So **I'm wondering what you'd call it.** 

The idea is simple -- find a *senior, experienced* individual for each persona we've internally identified to come in and take ownership of all aspects of our products and services that are aimed at that particular persona.

For example, if we're making a boat, we'd have a ""Captain"" persona owner to oversee all aspects of the boat to make sure that, at the end of the day, it's a boat that does what they want it to do -- something a Captain would buy.  In this role, they'd oversee our team of boat makers (carpenters, electronic experts, mechanics, etc) to make sure the boat they make is best in class.

There are some obvious flaws in this example -- is the Captain a commercial fisherman or a tour boat operator? Because that would affect the type of boat we build for that person. But assume for a moment that we have enough specificity for each role to get beyond this sort of thing.

I put together [a](https://www.datarobot.com/careers/job/1809278/) job description, but it's had limited success, which tells me I've described a position that isn't common, or perhaps something that senior people would rather not be involved in.  This role is highly technical, yet not a coding position, and skews towards product management, but is thought of as more of an engineer role.  Confusing, I know. 

And that's what brought me here. *Would love your feedback.* Or if this is an invalid post (or if there's a better thread please let me know).

Thank you in advance for your time.",4,2,False,self,,,,,
181,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,20,czjuef,self.MachineLearning,Does anyone knows a good tagging tool for to train a NLP model?,https://www.reddit.com/r/MachineLearning/comments/czjuef/does_anyone_knows_a_good_tagging_tool_for_to/,Higoselu,1567598221,[removed],0,1,False,self,,,,,
182,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,22,czkncv,self.MachineLearning,[D] Need tool for Human evaluation of Generative Dialogue Models,https://www.reddit.com/r/MachineLearning/comments/czkncv/d_need_tool_for_human_evaluation_of_generative/,bytestorm95,1567602534,"Hi, does anyone know of any tools / softwares for manual evaluation of generative dialogue models? I looked into a few annotation tools and also psiturk ( [https://github.com/NYUCCL/psiTurk](https://github.com/NYUCCL/psiTurk) ), but none of them natively supports such a task.   
Psiturk also seems to have a bit of learning curve which I am not very eager to get into, at the moment. The type of annotation required is similar to A/B testing. The user/annotator will be given a dialogue history and 2/3 sample responses generated by different models. He/She will need to tell which of the responses is better in terms of coherence and grammatical correctness.",2,0,False,self,,,,,
183,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,22,czkpqo,self.MachineLearning,Data Shapley: Equitable Valuation of Data for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/czkpqo/data_shapley_equitable_valuation_of_data_for/,WERE_CAT,1567602873,[removed],0,1,False,self,,,,,
184,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,22,czkuww,self.MachineLearning,"Machine Translation Summit 2019 Impressions, Summary and Notes",https://www.reddit.com/r/MachineLearning/comments/czkuww/machine_translation_summit_2019_impressions/,data_nat,1567603620,[removed],0,1,False,self,,,,,
185,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,22,czl5rm,self.MachineLearning,Complex output layer regularization implementation,https://www.reddit.com/r/MachineLearning/comments/czl5rm/complex_output_layer_regularization_implementation/,progmayo,1567605114,[removed],0,1,False,self,,,,,
186,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,23,czlig4,self.MachineLearning,[R] A 2019 Guide for Automatic Speech Recognition,https://www.reddit.com/r/MachineLearning/comments/czlig4/r_a_2019_guide_for_automatic_speech_recognition/,mwitiderrick,1567606822,"This article will bring you up to speed on some of the most commonand a couple of very recenttechniques for performing automatic speech recognition in a variety of contexts.

[https://heartbeat.fritz.ai/a-2019-guide-for-automatic-speech-recognition-f1e1129a141c](https://heartbeat.fritz.ai/a-2019-guide-for-automatic-speech-recognition-f1e1129a141c)

The papers/abstracts mentioned and linked to above also contain links to their code implementations. Wed be happy to see the results you obtain after testing them.",21,82,False,self,,,,,
187,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,23,czlj6u,self.MachineLearning,[Discussion] What are the real life applications of rare pattern mining in ML?,https://www.reddit.com/r/MachineLearning/comments/czlj6u/discussion_what_are_the_real_life_applications_of/,nibor_14,1567606918,"There are a lots of real life application on ML nowadays. But the use of rare pattern aren't discussed much elsewhere.   
As the common application, it is used in Market Basket Analysis like frequent pattern mining. But i think there are much more field where rare pattern mining can be used. 

I was hopping to work on an unique topic on ML using rare pattern mining.  
Hope that i will get some useful suggestions here.

Thanks in advance.",5,1,False,self,,,,,
188,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,23,czlrj4,self.MachineLearning,[D] Why using linear ensemble model?,https://www.reddit.com/r/MachineLearning/comments/czlrj4/d_why_using_linear_ensemble_model/,FellowOfHorses,1567608016,"I see in some places recommending ensembles of linear models, like xgboost documentation.

Why? Isn't the ensemble of linear models also a linear model? Is it just a fancy form of regularization/cross-validation, by not using the whole dataset?",9,1,False,self,,,,,
189,MachineLearning,t5_2r3gv,2019-9-4,2019,9,4,23,czlxl9,self.MachineLearning,AAAI2020: is it worth it?,https://www.reddit.com/r/MachineLearning/comments/czlxl9/aaai2020_is_it_worth_it/,b3by,1567608802,"I submitted the abstract for AAAI 2020, roughly 3 days before the final deadline. One of my colleagues did the same 2 days before me, and got a submission number less than 100. I got a submission number higher than 4k. Now I'm reading on Twitter that they got [more than 10k submissions](https://twitter.com/WilliamWangNLP/status/1167646677445967872?s=20).

Now, I also believe they are going to have several [issues with the reviewers](https://twitter.com/DBahdanau/status/1168520341192400902?s=20), as they're asking reviewers to review 5 to 10 papers, with no chance of load reduction. It is my understanding that many people are simply bailing out, for obvious reasons.

What you your experience so far? Are you still submitting the final paper, or may decide to submit somewhere else? I was considering submitting my work to IAAI instead, which is more application focused and is not on the way to implode as AAAI.",0,1,False,self,,,,,
190,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,0,czm2f0,self.MachineLearning,[D] AAAI 2020: is it worth it?,https://www.reddit.com/r/MachineLearning/comments/czm2f0/d_aaai_2020_is_it_worth_it/,b3by,1567609441,"I submitted the abstract for AAAI 2020, roughly 3 days before the final deadline. One of my colleagues did the same 2 days before me, and got a submission number less than 100. I got a submission number higher than 4k. Now I'm reading on Twitter that they got [more than 10k submissions](https://twitter.com/WilliamWangNLP/status/1167646677445967872?s=20).

Now, I also believe they are going to have several [issues with the reviewers](https://twitter.com/DBahdanau/status/1168520341192400902?s=20), as they're asking reviewers to review 5 to 10 papers, with no chance of load reduction. It is my understanding that many people are simply bailing out, for obvious reasons.

What you your experience so far? Are you still submitting the final paper, or may decide to submit somewhere else? I was considering submitting my work to IAAI instead, which is more application focused and is not on the way to implode as AAAI.",15,29,False,self,,,,,
191,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,0,czm7e8,self.MachineLearning,Looking for someone to work on projects,https://www.reddit.com/r/MachineLearning/comments/czm7e8/looking_for_someone_to_work_on_projects/,BeggarInSpain,1567610079,"Hi! 

I've found it's way easier and faster to learn in a team and so I'm looking for someone with whom I could collaborate on Kaggle projects. I'd say my level is intermediate, I'm currently most interested in recommendation engines and NLP but I'm definitely into things like default risk or fraud detection too.

I also have a blog www.bicorner.net (it's a barren there actually now) and my kaggle profile is: www.kaggle.com/jirakst (The Titanic competition shows wrong result, I scored Top 10% and Top 4%).

I'll be most happy if you join me in either of those and belive we can move together a mile ahead!

Feel free to drop me a personal message if you're interested.

Cheers!


Note: This is repost from r/datascience",0,1,False,self,,,,,
192,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,0,czm7lu,self.MachineLearning,[P] Realtime Stereo Vision (toy project),https://www.reddit.com/r/MachineLearning/comments/czm7lu/p_realtime_stereo_vision_toy_project/,Miejuib,1567610109,"Sup.  I happened across one of the projects I was working on a few years ago, and I thought I would share it here in case you guys wanted to play with it.  

&amp;#x200B;

[Sample video of script in action](https://www.youtube.com/watch?v=Ck5iWa6sUWU)

&amp;#x200B;

 **tl;dr** summary of the code is it does a shitty implementation of a few layers of lstm to process a live video feed from a webcam or two, and it tries to predict some configurable number of frames into the future, conditioned on its own action space also. Also, since I happen to have two identical webcams lying around, I adapted the code to also handle concurrent stereoscopic video feeds for the fun of it. 

&amp;#x200B;

[Also, imho the video feed of the loss makes for some fun visual effects.  ](https://i.redd.it/0ufiwissflk31.png)

&amp;#x200B;

Anyways, here's a link to the eye-bleedingly bad (but mostly functional) code:  [https://github.com/Miej/online-deep-learning](https://github.com/Miej/online-deep-learning) 

&amp;#x200B;

enjoy!",3,2,False,self,,,,,
193,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,0,czm9gf,medium.com,Getting Started with Natural Language Processing: US Airline Sentiment Analysis,https://www.reddit.com/r/MachineLearning/comments/czm9gf/getting_started_with_natural_language_processing/,CometML,1567610359,,0,5,False,default,,,,,
194,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,0,czmh3o,youtu.be,Learn Keras in One Video,https://www.reddit.com/r/MachineLearning/comments/czmh3o/learn_keras_in_one_video/,khanradcoder,1567611310,,0,1,False,https://b.thumbs.redditmedia.com/kcyfV6rKjuFpaRgZAFeS8qCl-q93-kqeG8HUtmwavNQ.jpg,,,,,
195,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,0,czmi89,self.MachineLearning,[D] How To Make Custom AI-Generated Text With GPT-2,https://www.reddit.com/r/MachineLearning/comments/czmi89/d_how_to_make_custom_aigenerated_text_with_gpt2/,minimaxir,1567611458,"I've seen a few posts on this subreddit and /r/learnmachinelearning asking how to finetune GPT-2 and generate text from it. As the creator of [gpt-2-simple](https://github.com/minimaxir/gpt-2-simple), I've had a lot of experience working with GPT-2, so here's a (lengthy!) blog post on how to finetune GPT-2 and generate text using gpt-2-simple, along with a history of GPT-2 finetuning and its future:

[https://minimaxir.com/2019/09/howto-gpt2/](https://minimaxir.com/2019/09/howto-gpt2/)

Let me know if you have any questions!",4,39,False,self,,,,,
196,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,0,czmit1,self.MachineLearning,Looking for someone to work on projects,https://www.reddit.com/r/MachineLearning/comments/czmit1/looking_for_someone_to_work_on_projects/,BeggarInSpain,1567611533,[removed],0,1,False,self,,,,,
197,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,0,czmpau,self.MachineLearning,"Simple Questions Thread September 04, 2019",https://www.reddit.com/r/MachineLearning/comments/czmpau/simple_questions_thread_september_04_2019/,AutoModerator,1567612375,[removed],0,1,False,self,,,,,
198,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,2,cznmay,self.MachineLearning,Sentiment Analysis of Tweets - Predicting Sentiments using Machine Learning Algorithms,https://www.reddit.com/r/MachineLearning/comments/cznmay/sentiment_analysis_of_tweets_predicting/,Reddit_Swap,1567616527,[removed],0,1,False,self,,,,,
199,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,2,czns77,self.MachineLearning,A fast way to run your Keras model.,https://www.reddit.com/r/MachineLearning/comments/czns77/a_fast_way_to_run_your_keras_model/,wingbo26,1567617260,[removed],0,1,False,self,,,,,
200,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,2,czns99,ai.googleblog.com,Giving Lens New Reading Capabilities in Google Go,https://www.reddit.com/r/MachineLearning/comments/czns99/giving_lens_new_reading_capabilities_in_google_go/,sjoerdapp,1567617267,,0,1,False,default,,,,,
201,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,2,czo28g,self.MachineLearning,[D] What subfield of Machine Learning will contribute more to the creation of General Artificial Intelligence?,https://www.reddit.com/r/MachineLearning/comments/czo28g/d_what_subfield_of_machine_learning_will/,Viecce,1567618522,"In my opinion the two main contributors will be NLP and Reinforcement Learning. I also think Self-Supervised Learning is going to have a big role.
What's your opinion?",31,12,False,self,,,,,
202,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,3,czoi8e,self.MachineLearning,Action recognition using neural networks,https://www.reddit.com/r/MachineLearning/comments/czoi8e/action_recognition_using_neural_networks/,lucky31044,1567620527,I am working upon an approach action recognition under which I am estimating actions from pose in one class and identity objects in other class but I am confused how to link these classes like if a person is picking something I need a generalized form he picked pen or a bottle or any other object,0,1,False,self,,,,,
203,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,3,czos0q,linkedin.com,AGI rules - discussion,https://www.reddit.com/r/MachineLearning/comments/czos0q/agi_rules_discussion/,ToolTechSoftware,1567621767,,0,1,False,default,,,,,
204,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,3,czp5wj,bostonreview.net,"[D] What Big Data Cant Do: the philosopher Tim Maudlin reviews Judea Pearls The Book of Why on the neglect of causation in data science. Allured by the promise of Big Data, science has shortchanged causal explanation in favor of data-driven prediction. But ultimately we must ask why.",https://www.reddit.com/r/MachineLearning/comments/czp5wj/d_what_big_data_cant_do_the_philosopher_tim/,what-penumbras,1567623472,,0,1,False,https://a.thumbs.redditmedia.com/LXTkNROXF_nHE9LYfVM0mnbuvewQ1YM6Z9460QGGEI4.jpg,,,,,
205,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,4,czpcaq,reddit.com,Parametric Activations in Keras,https://www.reddit.com/r/MachineLearning/comments/czpcaq/parametric_activations_in_keras/,ZeroMaxinumXZ,1567624254,,0,1,False,default,,,,,
206,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,4,czpeg4,medium.com,One Network to Fit All Hardware: New MIT AutoML Method Trains 14X Faster Than SOTA NAS,https://www.reddit.com/r/MachineLearning/comments/czpeg4/one_network_to_fit_all_hardware_new_mit_automl/,Yuqing7,1567624533,,0,1,False,https://a.thumbs.redditmedia.com/PxrE318q3LL_2HqUdFZ7vimuG_VVspau6N6plWvjYc0.jpg,,,,,
207,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,4,czpgp4,self.MachineLearning,Just learned author of XGBoost paper goes to my school!,https://www.reddit.com/r/MachineLearning/comments/czpgp4/just_learned_author_of_xgboost_paper_goes_to_my/,somekoreanhusky,1567624799,[removed],0,1,False,self,,,,,
208,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,4,czpsh4,self.MachineLearning,Want to start creating using music using NN. Any point of start? Already know a lot about Python and CNN,https://www.reddit.com/r/MachineLearning/comments/czpsh4/want_to_start_creating_using_music_using_nn_any/,GreatOnion,1567626462,[removed],0,1,False,self,,,,,
209,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,5,czq57r,neurips.cc,NeurIPS 2019 tickets will be lottery based instead of first-come-first-served,https://www.reddit.com/r/MachineLearning/comments/czq57r/neurips_2019_tickets_will_be_lottery_based/,Rocketshipz,1567628235,,0,1,False,default,,,,,
210,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,6,czqyx1,self.MachineLearning,[R] Video Analysis: Dynamic Routing Between Capsules,https://www.reddit.com/r/MachineLearning/comments/czqyx1/r_video_analysis_dynamic_routing_between_capsules/,ykilcher,1567631982,[removed],0,1,False,self,,,,,
211,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,7,czro8x,self.MachineLearning,Which will have the highest job demand AI (ML Engineers) or Data Science (Data Scientists) in the next 3 years?,https://www.reddit.com/r/MachineLearning/comments/czro8x/which_will_have_the_highest_job_demand_ai_ml/,AILaunchpad,1567635164,[removed],0,1,False,self,,,,,
212,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,7,czs0di,self.MachineLearning,machine learning from scratch with python,https://www.reddit.com/r/MachineLearning/comments/czs0di/machine_learning_from_scratch_with_python/,codingislife496,1567636757,[removed],0,1,False,self,,,,,
213,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,9,cztpld,self.MachineLearning,"Face dataset with cropped face + face embedding + facial landmarks + face segmentation, extracted from Movie trailers (6000 faces)",https://www.reddit.com/r/MachineLearning/comments/cztpld/face_dataset_with_cropped_face_face_embedding/,thePsychonautDad,1567645071,"Hi,

I've built a face dataset, extracted from Movie trailers.

The dataset contains:

* 224x224 JPG cropped face
* Trailer Name
* Group number (identical faces belong to identical group numbers)
* Embedding vector (use cosine distance to match similar faces by their embedding)
* Facial Landmarks (list of (x,y) on the cropped face)
* Facial Segmentation

&amp;#x200B;

[Example from the dataset](https://i.imgur.com/6kT9KcK.png)

[Google Colab Notebook to explore &amp; play with the data](https://colab.research.google.com/drive/1nIN4QKKA9A8Dg-ZlWby_da8Q1OEmfURJ)

 [Google Colab Notebook to generate your own dataset straight from Colab](https://colab.research.google.com/drive/1oTcS0DGzz9i4fB5wxf6er9gymxJVfq5l#scrollTo=UMKcGshGTWv1) 

&amp;#x200B;

The dataset was generated on Google Colab. The [notebook](https://colab.research.google.com/drive/1oTcS0DGzz9i4fB5wxf6er9gymxJVfq5l#scrollTo=UMKcGshGTWv1) will crawl [https://www.davestrailerpage.co.uk/](https://www.davestrailerpage.co.uk/) and extract faces from its trailers. You can change one line of code and use your own list of video urls.

Once generated your dataset will be uploaded to the Google Storage container of your choice.

&amp;#x200B;

This dataset contains about 6000 faces from 5 trailers. Use the [notebook](https://colab.research.google.com/drive/1oTcS0DGzz9i4fB5wxf6er9gymxJVfq5l#scrollTo=UMKcGshGTWv1) to generate a larger one.

&amp;#x200B;

I'm not affiliated with a university and the faces are extracted from actors in movie trailers.

I suppose that means you can go nuts with it, there shouldn't be any restrictions on what you can do with this.

&amp;#x200B;

&amp;#x200B;

I built this dataset and those notebooks because I found it incredibly hard to find a decent face database without strict restrictions, and impossible to find one that contains facial landmarks and face segmentation.

This is my first custom dataset, let me know if there's a better way to structure it.",2,2,False,self,,,,,
214,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,10,cztyzg,self.MachineLearning,"For anyone who's been in and is in the Google AI Residency Program, what background/strong skills does Google AI Residency Program look for in potential candidates?",https://www.reddit.com/r/MachineLearning/comments/cztyzg/for_anyone_whos_been_in_and_is_in_the_google_ai/,Chaltu,1567646427,[removed],0,1,False,self,,,,,
215,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,10,czu1s9,self.MachineLearning,[D] Neurips 2019 Registration Lottery,https://www.reddit.com/r/MachineLearning/comments/czu1s9/d_neurips_2019_registration_lottery/,AeronByHermanMiller,1567646832,"Just received the email:

""""""

We are pleased to announce the opening of Registration for NeurIPS 2019:

#### Register:

Check pricing [here](https://neurips.cc/Conferences/2019/Pricing). Registration opens Sept 6th at 8 a.m. Pacific. Please see below for more information about our new lottery registration system.

#### What's new in 2019:

* The old first-come-first-served registration has been replaced with a lottery. It is no longer necessary register in the first few minutes after registration opens. Add yourself to the lottery between Sept 6th and Sept 20thfor a chance to be randomly chosen to register. Click the green ""Register Starting Sept 6th"" button on the [home page](https://neurips.cc/) after registration opens formore inforrmation. If you are in an Asian, African or Middle Eastern timezone, there is no longer a need to wake up in thenight to register. Take your time; it won't hurt your chances of getting a ticket.
* NeurIPS 2019 will be held at the *Vancouver Convention Center, Vancouver CANADA* Sun Dec 8th through Sat the 14th. The check-in desk opens Sunday morning at 8:00 amin the West building of the VCC.
* Students must upload a scan of their student IDs to qualify for student pricing and financial support. Students must present their valid student IDat the check-in desk to pick up their badge.
* The entire meeting will be live-streamed.

""""""

Thoughts? Seems like this may increase the pool of competing attendees as a side effect due to the time barrier removal.  Any way to roughly estimate the % chance of getting a ticket?",28,67,False,self,,,,,
216,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,11,czujh5,self.MachineLearning,"In a dilemma on which science fair idea I should choose, need advice",https://www.reddit.com/r/MachineLearning/comments/czujh5/in_a_dilemma_on_which_science_fair_idea_i_should/,shazam8253,1567649398,[removed],0,1,False,self,,,,,
217,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,11,czumq2,arxiv.org,[R] Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations,https://www.reddit.com/r/MachineLearning/comments/czumq2/r_scene_representation_networks_continuous/,wei_jok,1567649886,,1,4,False,default,,,,,
218,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,11,czuuex,theoverday.com,You're a data scientist ? 5 Tips For Getting a Job,https://www.reddit.com/r/MachineLearning/comments/czuuex/youre_a_data_scientist_5_tips_for_getting_a_job/,sajad-52,1567651025,,0,1,False,https://b.thumbs.redditmedia.com/9gRX9biAyW55KBHIrA9YCunqQz6d0Ti4vX9h8tuB4-E.jpg,,,,,
219,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,11,czv0y7,self.MachineLearning,[D] Startups similar to Deepsource that uses AI to analyse source code for issues?,https://www.reddit.com/r/MachineLearning/comments/czv0y7/d_startups_similar_to_deepsource_that_uses_ai_to/,cbsudux,1567652009,,0,1,False,self,,,,,
220,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,13,czvrox,self.MachineLearning,Machine Learning Courses,https://www.reddit.com/r/MachineLearning/comments/czvrox/machine_learning_courses/,dwivediabhinav,1567656317,"ExcelR Solutions is the best Institute for [***ExcelR's Machine Learning Courses***](https://www.excelr.com/machine-learning-course-training-in-pune/) in Pune,Basic requirements for Machine Learning Training is Computer skills,Basic Mathematics Knowledge,Basic Data Science Concepts with much Experienced Staff,they are providing certifications from the University of Malaysia. ExcelR is a global leader in technical and management training catering the training needs of the professionals in more than 27 countries with offices in USA, Malaysia, India etc. with over 21 branches across the globe.",0,1,False,self,,,,,
221,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,13,czw3hv,self.computervision,[R] Instantaneous Machine Learning Training and Prediction,https://www.reddit.com/r/MachineLearning/comments/czw3hv/r_instantaneous_machine_learning_training_and/,Feynmanfan85,1567658361,,0,1,False,default,,,,,
222,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,14,czwdmx,self.MachineLearning,Ask for machine learning Python example with 2 data files,https://www.reddit.com/r/MachineLearning/comments/czwdmx/ask_for_machine_learning_python_example_with_2/,user5566b,1567660149,"Please advise such simple example in python of machine learning that supports both inputs of training file and test file about code will give output, not just not ending theoretical material with no relevant code to test... ",0,1,False,self,,,,,
223,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,14,czwe7n,self.MachineLearning,[P] A centralized repo for datasets,https://www.reddit.com/r/MachineLearning/comments/czwe7n/p_a_centralized_repo_for_datasets/,nightrunner11,1567660255,"An idea that I've had for a year or two now and recently started on it.  It's meant to easily share datasets as compiling data is backbreaking work, so that others do not have to undergo the same experience.  It's still in early stage.

Github link:
https://github.com/ezhou7/repm",4,4,False,self,,,,,
224,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,14,czwh9x,i.redd.it,Overfitting the task in a nutshell,https://www.reddit.com/r/MachineLearning/comments/czwh9x/overfitting_the_task_in_a_nutshell/,ricocotam,1567660804,,0,1,False,https://a.thumbs.redditmedia.com/nA3uR3dB_fKcDA8LoU6qeDIT7yyGPkd9wtI7U9N-xw8.jpg,,,,,
225,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,15,czwxry,self.MachineLearning,Face generation from face feature?,https://www.reddit.com/r/MachineLearning/comments/czwxry/face_generation_from_face_feature/,ravising_h,1567663999,[removed],0,1,False,self,,,,,
226,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,15,czx099,self.MachineLearning,[D] Is Google MediaPipe the future of ML?,https://www.reddit.com/r/MachineLearning/comments/czx099/d_is_google_mediapipe_the_future_of_ml/,hapliniste,1567664482,"I had an idea a long time ago that would allow us to make ""soft AGI"" by making models into ""nodes"" that would have an input and output representations and routing them to achieve the task needed.

Basically a ""marketplace"" of models that would have the metadata to be easily searchable and standardized types/representations that would allow them to link seamlessly. We could then build a system that would get a text query and phone sensors as input and would determine input-output representations for the query. The system would then find a route (ideally using the most cost-efficient path, nodes being rated with a compute cost) to achieve the task.

Is Google trying to make this with MediaPipe? 

I think once it is ou of beta they will open a repository for our ""Calculators"" (as they call nodes) to make this happen. They could maybe provide cheap or free execution on Google Cloud but use the data passing through as training material. The thing is we could make models more modular and reuse pretrained nodes already on the system. It would make training really fast as most of the model is already pretrained and avoid overfitting because the nodes are used for other tasks as well.

What do you think of it?",0,0,False,self,,,,,
227,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,15,czx3x1,self.MachineLearning,[R] From F to A on the N.Y. Regents Science Exams: An Overview of the Aristo Project. Allen AI Institute's system pass an 8th grade science test.,https://www.reddit.com/r/MachineLearning/comments/czx3x1/r_from_f_to_a_on_the_ny_regents_science_exams_an/,milaworld,1567665210,"[From F to A on the N.Y. Regents Science Exams: An Overview of the Aristo Project](https://allenai.org/content/docs/Aristo_Milestone.pdf)

**Abstract**

AI has achieved remarkable mastery over games such as Chess, Go, and Poker, and even Jeopardy!, but the rich variety of standardized exams has remained a landmark challenge. Even in 2016, the best AI system achieved merely 59.3% on an 8th Grade science exam challenge (Schoenick et al., 2016). This paper reports unprecedented success on the Grade 8 New York Regents Science Exam, where for the first time a system scores more than 90% on the exams non-diagram, multiple choice (NDMC) questions. In addition, our Aristo system, building upon the success of recent language models, exceeded 83% on the corresponding Grade 12 Science Exam NDMC questions. The results, on unseen test questions, are robust across different test years and different variations of this kind of test. They demonstrate that modern NLP methods can result in mastery on this task. While not a full solution to general question-answering (the questions are multiple choice, and the domain is restricted to 8th Grade science), it represents a significant milestone for the field.

Link to [paper](https://allenai.org/content/docs/Aristo_Milestone.pdf)

Link to related [NYTimes Article](https://www.nytimes.com/2019/09/04/technology/artificial-intelligence-aristo-passed-test.html)",0,1,False,self,,,,,
228,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,15,czx5nh,self.MachineLearning,How to fine tune stable baselines agents with step wise updates?,https://www.reddit.com/r/MachineLearning/comments/czx5nh/how_to_fine_tune_stable_baselines_agents_with/,beyondelta,1567665553,[removed],0,1,False,self,,,,,
229,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,15,czx8e9,self.MachineLearning,[R] From F to A on the N.Y. Regents Science Exams: An Overview of the Aristo Project (Allen AI Institute),https://www.reddit.com/r/MachineLearning/comments/czx8e9/r_from_f_to_a_on_the_ny_regents_science_exams_an/,sensetime,1567666130,"Recent paper from Allen AI Institute. Abstract:

AI has achieved remarkable mastery over games such as Chess, Go, and Poker, and even Jeopardy!, but the rich variety of standardized exams has remained a landmark challenge. Even in 2016, the best AI system achieved merely 59.3% on an 8th Grade science exam challenge (Schoenick et al., 2016). This paper reports unprecedented success on the Grade 8 New York Regents Science Exam, where for the first time a system scores more than 90% on the exams non-diagram, multiple choice (NDMC) questions. In addition, our Aristo system, building upon the success of recent language models, exceeded 83% on the corresponding Grade 12 Science Exam NDMC questions. The results, on unseen test questions, are robust across different test years and different variations of this kind of test. They demonstrate that modern NLP methods can result in mastery on this task. While not a full solution to general question-answering (the questions are multiple choice, and the domain is restricted to 8th Grade science), it represents a significant milestone for the field.

Link to PDF: https://allenai.org/content/docs/Aristo_Milestone.pdf",0,2,False,self,,,,,
230,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,15,czx97n,blog.duomly.com,What is scikit learn - introduction to popular machine learning and data science Python library - Duomly Blog - Programming courses online,https://www.reddit.com/r/MachineLearning/comments/czx97n/what_is_scikit_learn_introduction_to_popular/,annafromduomly,1567666285,,0,1,False,https://a.thumbs.redditmedia.com/7aVgc6YTbGnvX7QoRt9-oHtS1qHrBVl-Hg6MuxFMT40.jpg,,,,,
231,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,15,czx9a8,arxiv.org,[R] From 'F' to 'A' on the N.Y. Regents Science Exams: An Overview of the Aristo Project,https://www.reddit.com/r/MachineLearning/comments/czx9a8/r_from_f_to_a_on_the_ny_regents_science_exams_an/,hardmaru,1567666300,,2,1,False,default,,,,,
232,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,15,czxbb3,arxiv.org,[R] From 'F' to 'A' on the N.Y. Regents Science Exams: An Overview of the Aristo Project,https://www.reddit.com/r/MachineLearning/comments/czxbb3/r_from_f_to_a_on_the_ny_regents_science_exams_an/,hardmaru,1567666711,,2,2,False,default,,,,,
233,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,16,czxcs8,youtube.com,AI Learns to Park - Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/czxcs8/ai_learns_to_park_deep_reinforcement_learning/,Bejitarian,1567666995,,0,2,False,default,,,,,
234,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,16,czxlih,nips.cc,[D] NeurIPS accepted papers posted,https://www.reddit.com/r/MachineLearning/comments/czxlih/d_neurips_accepted_papers_posted/,tfluxxin,1567668774,,0,1,False,default,,,,,
235,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,16,czxrq7,self.MachineLearning,"""[Discussion]"" TensorFlow Extended (TFX), is anybody using it?",https://www.reddit.com/r/MachineLearning/comments/czxrq7/discussion_tensorflow_extended_tfx_is_anybody/,g-effe,1567670131,"Plenty of pretty block diagrams and high-level overview are available online, but little (or nothing) can be found on real use of the framework and its benefits.",4,13,False,self,,,,,
236,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,17,czxv1n,self.MachineLearning,features as rows or features as columns in matrix X?,https://www.reddit.com/r/MachineLearning/comments/czxv1n/features_as_rows_or_features_as_columns_in_matrix/,theperfecttouch,1567670857,[removed],0,1,False,self,,,,,
237,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,17,czxxws,self.MachineLearning,[D] What does your ML pipeline look like?,https://www.reddit.com/r/MachineLearning/comments/czxxws/d_what_does_your_ml_pipeline_look_like/,pirate7777777,1567671521,"Hi everyone! I found [this post on HN](https://news.ycombinator.com/item?id=19712465) and would like to know your opinion/professional experience. 

""Experienced machine learning professionals - How do you create scalable, deployable and reproducible data/ML pipelines at your work?""",29,179,False,self,,,,,
238,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,17,czy3wm,i.redd.it,Growth Prediction - Artificial Intelligence (AI) &amp; Machine Learning(ML),https://www.reddit.com/r/MachineLearning/comments/czy3wm/growth_prediction_artificial_intelligence_ai/,optisol,1567672910,,0,1,False,default,,,,,
239,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,17,czy6s5,self.MachineLearning,[P] Content Update in PyTOrch NLP Tutorial repo : Text Classification on HuffPost news article,https://www.reddit.com/r/MachineLearning/comments/czy6s5/p_content_update_in_pytorch_nlp_tutorial_repo/,lyeoni,1567673581,"Content Update in PyTorch NLP Tutorial repo !

  
\- **Text Classification**, with simple annotation.

* **Dataset**: *HuffPost* news corpus including corresponding category.
* **Pre-trained word vectors**: How pre-trained word representations affect model performance (via ablation study)

The model trained on this dataset identify the category of news article based on their  headlines and descriptions.

  
link : https://github.com/lyeoni/nlp-tutorial/tree/master/news-category-classifcation",0,1,False,self,,,,,
240,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,18,czychw,self.MachineLearning,[P] Content Update in NLP Tutorial repo : Text Classification on HuffPost news article,https://www.reddit.com/r/MachineLearning/comments/czychw/p_content_update_in_nlp_tutorial_repo_text/,lyeoni,1567674743,"Content Update in PyTorch NLP Tutorial repo.

\- **Text Classification**, with simple annotation.

* **Dataset**: *HuffPost* news corpus including corresponding category.
* **Pre-trained word vectors**: How pre-trained word representations affect model performance (via ablation study)

The model trained on this dataset identify the category of news article based on their  headlines and descriptions.

link : [https://github.com/lyeoni/nlp-tutorial/tree/master/news-category-classifcation](https://github.com/lyeoni/nlp-tutorial/tree/master/news-category-classifcation)",5,1,False,self,,,,,
241,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,18,czyj90,self.MachineLearning,Clustering in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/czyj90/clustering_in_machine_learning/,VyasBharvi,1567676152,"&amp;#x200B;

*Processing img k8bd8skttqk31...*

Clustering explained in detail - [Clustering in Machine Learning](https://data-flair.training/blogs/clustering-in-machine-learning/)",0,1,False,self,,,,,
242,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,19,czz5dd,youtu.be,[P] Agent Learns to Park a Car using Unity ML-Agents / Deep Reinforcement Learning (PPO),https://www.reddit.com/r/MachineLearning/comments/czz5dd/p_agent_learns_to_park_a_car_using_unity_mlagents/,SamuelArzt,1567680460,,1,1,False,https://b.thumbs.redditmedia.com/HQSp6iDg-tjN99GDT4Af21N9RQZrk5kkgA0NcFTQuGw.jpg,,,,,
243,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,19,czz5f1,theoverday.com,You're a data scientist ? 5 Tips For Getting a Job,https://www.reddit.com/r/MachineLearning/comments/czz5f1/youre_a_data_scientist_5_tips_for_getting_a_job/,sajad-52,1567680469,,0,1,False,default,,,,,
244,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,20,czzfzb,self.MachineLearning,Google USE vs. BERT,https://www.reddit.com/r/MachineLearning/comments/czzfzb/google_use_vs_bert/,bmichi04,1567682351,[removed],0,1,False,self,,,,,
245,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,20,czzias,self.MachineLearning,What would be the best algo or method to generate (a) sentence(s) using a list of words?,https://www.reddit.com/r/MachineLearning/comments/czzias/what_would_be_the_best_algo_or_method_to_generate/,zacheism,1567682741,"I'm wondering if anyone has any ideas as to the best model / method to accomplish this task.

I tried posting this in /r/learnmachinelearning and many suggested using GPT-2 but no one was sure if it was appropriate for this task. Any thoughts on what would that be the best? If so, how might I fine-tune it on this task?

***

**An example of what I am trying to accomplish:**

*INPUT*: apple, tree, dog

*OUTPUT*: The **dog** was playing around the **tree** and fell asleep. However, he was awoken by an **apple** falling on his head.",0,5,False,self,,,,,
246,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,20,czzm8t,cognility.com,bad bot! when bots do more bad than good:,https://www.reddit.com/r/MachineLearning/comments/czzm8t/bad_bot_when_bots_do_more_bad_than_good/,liormessinger,1567683415,,0,1,False,default,,,,,
247,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,20,czzpy7,self.MachineLearning,[N] Awesome Artificial Intelligence Research and Projects on Computer Vision News (with codes!) September 2019,https://www.reddit.com/r/MachineLearning/comments/czzpy7/n_awesome_artificial_intelligence_research_and/,Gletta,1567684064,"The September issue of Computer Vision News: 34 pages about AI and Deep Learning through both research and practical applications.

[HTML5 version (recommended)](https://www.rsipvision.com/ComputerVisionNews-2019September/)

[PDF version](https://www.rsipvision.com/computer-vision-news-2019-september-pdf/)

Technical articles on pages 4-7 and 16-21. Subscribe for free on page 34.

https://i.redd.it/bu2i2gc1krk31.jpg",0,3,False,https://b.thumbs.redditmedia.com/022GA30rFxZ6FMp9c5327b--iQ_0WApenAPSqMfnY8U.jpg,,,,,
248,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,20,czzs2t,medium.com,AI-Based Future beckons Are You Ready?,https://www.reddit.com/r/MachineLearning/comments/czzs2t/aibased_future_beckons_are_you_ready/,Albertchristopher,1567684408,,0,1,False,default,,,,,
249,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,20,czzsri,self.MachineLearning,Model validation and peer review process,https://www.reddit.com/r/MachineLearning/comments/czzsri/model_validation_and_peer_review_process/,dorkydoofus,1567684518,[removed],0,1,False,self,,,,,
250,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,21,czzx2d,self.MachineLearning,[P] Agent Learns to Park a Car using Unity ML-Agents / Deep Reinforcement Learning (PPO),https://www.reddit.com/r/MachineLearning/comments/czzx2d/p_agent_learns_to_park_a_car_using_unity_mlagents/,SamuelArzt,1567685199,"Video available here (YouTube): [https://youtu.be/VMp6pq6\_QjI](https://youtu.be/VMp6pq6_QjI)

Context:

An AI learns to park a car in a parking lot in a 3D physics simulation. The simulation was implemented using Unity's ML-Agents framework ([https://unity3d.com/machine-learning](https://unity3d.com/machine-learning)). The AI consists of a deep Neural Network with 3 hidden layers of 128 neurons each. It is trained with the Proximal Policy Optimization (PPO) algorithm.

The input of the Neural Network are the readings of eight depth sensors, the cars current speed and position, as well as its relative position to the target. The outputs of the Neural Network are interpreted as engine force, braking force and turning force (continuous values). These outputs can be seen at the top right corner of the zoomed out camera shots.

The AI starts off with random behaviour, i.e. the Neural Network is initialized with random weights. It then gradually learns to solve the task by reacting to environment feedback accordingly.

The AI is rewarded with small positive signals for getting closer to the parking spot, which is outlined in red, and gets a larger reward when it actually reaches the parking spot and stops there. The final reward for reaching the parking spot is dependent on how parallel the car stops in relation to the actual parking position. If the car stops in a 90 angle to the actual parking direction for instance, the AI will only be rewarded a very small amount, relative to the amount it would get for stopping completely parallel to the actual direction. The AI is penalized with a negative reward signal, when it either drives further away from the parking spot or if it crashes into any obstacles.

&amp;#x200B;

https://i.redd.it/cul3s0nanrk31.png",14,56,False,https://b.thumbs.redditmedia.com/rLc9CQf0HBKwEG5S4MTi857Sw91rOuLJUWFtW0QDtIM.jpg,,,,,
251,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,21,czzzwf,self.MachineLearning,Domain Adaptation in the case of Graph Networks,https://www.reddit.com/r/MachineLearning/comments/czzzwf/domain_adaptation_in_the_case_of_graph_networks/,aniket_agarwal,1567685635,[removed],0,1,False,self,,,,,
252,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,22,d00y5i,developer.amazon.com,New method accelerates parallel training of neural nets,https://www.reddit.com/r/MachineLearning/comments/d00y5i/new_method_accelerates_parallel_training_of/,georgecarlyle76,1567690729,,0,1,False,default,,,,,
253,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,22,d015b5,self.MachineLearning,"Need advice. Shall I pay 40,000 to get a Data Science Master Degree? Thank you!",https://www.reddit.com/r/MachineLearning/comments/d015b5/need_advice_shall_i_pay_40000_to_get_a_data/,MBrook77,1567691771,[removed],0,1,False,self,,,,,
254,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,23,d017yb,github.com, Python examples of popular machine learning algorithms with interactive Jupyter demos and math being explained,https://www.reddit.com/r/MachineLearning/comments/d017yb/python_examples_of_popular_machine_learning/,yanina_s,1567692132,,0,1,False,default,,,,,
255,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,23,d01ikd,compliantcloud.com,Introduction to HP ALM-QC,https://www.reddit.com/r/MachineLearning/comments/d01ikd/introduction_to_hp_almqc/,rosamarts,1567693576,,0,1,False,default,,,,,
256,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,23,d01rtz,self.MachineLearning,[D] Deep Learning Meme Review,https://www.reddit.com/r/MachineLearning/comments/d01rtz/d_deep_learning_meme_review/,ykilcher,1567694848,"Just a bit of poking fun at ML culture.

https://youtu.be/MIEA8azwu1k",0,0,False,self,,,,,
257,MachineLearning,t5_2r3gv,2019-9-5,2019,9,5,23,d01tq3,self.MachineLearning,[Discussion] Category-theoretic approach to machine learning,https://www.reddit.com/r/MachineLearning/comments/d01tq3/discussion_categorytheoretic_approach_to_machine/,totallynotAGI,1567695096,"I'd like to start a thread about a small surge of recent papers studying machine learning from the perspective of functional programming/category theory. Plenty of interesting things are happening that most people don't seem to be aware of, unless they are in these tight circles!

Category theory is a very general and rigorous mathematical theory of \_compositionality\_ that seems have become a [powerful unifying force](https://arxiv.org/abs/1809.05923) in all the mathematics and very recently sciences. Its main concerns are those alike to in deep learning: finding compositional structure in data, such that the created abstractions are non-leaky and as general as possible.

Alongside the many of the papers I linked below, the [Symposium on Compositional Structures](http://events.cs.bham.ac.uk/syco/strings3-syco5/) that's happening this week has two talks on abstract mathematical generalization of machine learning.

Note: unlike most ML papers which are focused on experiments, almost all of these are biased heavily on theory and disentangling of some of the existing structure, rather than providing new ad-hoc design choices in neural network architectures.

I've compiled a list of these papers below.
To me all these things are cool and I thought it might be useful for people to see these new approaches, as they might show us a shape of things to come.

\[Backprop As Functor\]([https://arxiv.org/abs/1711.10455](https://arxiv.org/abs/1711.10455))

\[The simple essence of automatic differentiation\]([https://arxiv.org/abs/1804.00746](https://arxiv.org/abs/1804.00746))

\[Lenses and Learners\]([https://arxiv.org/abs/1903.03671](https://arxiv.org/abs/1903.03671))

\[Compositional Deep Learning\]([https://arxiv.org/abs/1907.08292](https://arxiv.org/abs/1907.08292))

\[Generalized convolution and efficient language recognition\]([https://arxiv.org/abs/1903.10677](https://arxiv.org/abs/1903.10677))

\[Towards formalizing and extending differential programming using tangent categories\]([http://www.cs.ox.ac.uk/ACT2019/preproceedings/Jonathan%20Gallagher,%20Geoff%20Cruttwell%20and%20Ben%20MacAdam.pdf](http://www.cs.ox.ac.uk/ACT2019/preproceedings/Jonathan%20Gallagher,%20Geoff%20Cruttwell%20and%20Ben%20MacAdam.pdf))

\[Learning as change propagation with delta lenses\]([http://www.cs.ox.ac.uk/ACT2019/preproceedings/Zinovy%20Diskin.pdf](http://www.cs.ox.ac.uk/ACT2019/preproceedings/Zinovy%20Diskin.pdf))

\[From open learners to open games\]([https://arxiv.org/abs/1902.08666](https://arxiv.org/abs/1902.08666))",12,99,False,self,,,,,
258,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,0,d02h2b,medium.com,"Mirror, Mirror on the Wall, AI Knows Where You Are",https://www.reddit.com/r/MachineLearning/comments/d02h2b/mirror_mirror_on_the_wall_ai_knows_where_you_are/,Yuqing7,1567698127,,0,1,False,https://b.thumbs.redditmedia.com/0wNej0V61CYYOjcpwDY-EqwKRQu3r3vfuJXjvkMk_Xo.jpg,,,,,
259,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,0,d02n2m,self.MachineLearning,"Does anyone in healthcare use the predictive modeling capabilities in Epic? If so, what are your thoughts?",https://www.reddit.com/r/MachineLearning/comments/d02n2m/does_anyone_in_healthcare_use_the_predictive/,datadatadata84,1567698922,,0,1,False,self,,,,,
260,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,1,d02sp6,flextrade.com,AI: Natural Language Processing and the Battle for Unstructured Data,https://www.reddit.com/r/MachineLearning/comments/d02sp6/ai_natural_language_processing_and_the_battle_for/,jetroark1,1567699614,,0,1,False,default,,,,,
261,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,1,d030ox,self.MachineLearning,[P] Comparing 11 Speech-to-Text models using Tensorflow,https://www.reddit.com/r/MachineLearning/comments/d030ox/p_comparing_11_speechtotext_models_using/,huseinzol05,1567700592,"Here I compare 11 Speech-to-Text models using Tensorflow, 100% jupyter notebook and simplify.

1. Tacotron, test accuracy 77.09%
2. BiRNN LSTM, test accuracy 84.66%
3. BiRNN Seq2Seq + Luong Attention + Cross Entropy, test accuracy 87.86%
4. BiRNN Seq2Seq + Bahdanau Attention + Cross Entropy, test accuracy 89.28%
5. BiRNN Seq2Seq + Bahdanau Attention + CTC, test accuracy 86.35%
6. BiRNN Seq2Seq + Luong Attention + CTC, test accuracy 80.30%
7. CNN RNN + Bahdanau Attention, test accuracy 80.23%
8. Dilated CNN RNN, test accuracy 31.60%
9. Wavenet, test accuracy 75.11%
10. Deep Speech 2, test accuracy 81.40%
11. Wav2Vec Transfer learning BiRNN LSTM, test accuracy 83.24%

Link to repository, https://github.com/huseinzol05/NLP-Models-Tensorflow#speech-to-text

Link to dataset, https://tspace.library.utoronto.ca/handle/1807/24487, also included a notebook how to download the dataset.

## Discussion

1. Dataset is not that really big, only 286MB.
2. Transfer learning Wav2Vec accuracy is not that high, maybe need more dataset.
3. I use my own hyperparameters for Wav2Vec, use original hyperparameters caused my GPU sync problem, sequence is too long.
4. **I need to use bigger dataset**",26,39,False,self,,,,,
262,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,2,d0413x,self.MachineLearning,Improving ELO algorithm by learning hidden strategies,https://www.reddit.com/r/MachineLearning/comments/d0413x/improving_elo_algorithm_by_learning_hidden/,lrleo,1567705061,[removed],0,1,False,self,,,,,
263,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,2,d044zp,self.MachineLearning,[R] STEGASURAS: STEGanography via Arithmetic coding and Strong neURAl modelS,https://www.reddit.com/r/MachineLearning/comments/d044zp/r_stegasuras_steganography_via_arithmetic_coding/,kcazyz,1567705547,"[Online demo](https://steganography.live/encrypt)

[arXiv link](https://arxiv.org/abs/1909.01496)

[Code](https://github.com/harvardnlp/NeuralSteganography)

We recently released our demo for our EMNLP paper ""Neural Linguistic Steganography"", hiding secret messages in natural language via arithmetic coding and GPT-2. Arithmetic coding is a powerful entropy coding technique that is optimal for random sequences. Using arithmetic coding in reverse enables extremely efficient steganography, and when combined with modern language models like GPT-2 it allows for convincing cover text generations that encode information.",1,5,False,self,,,,,
264,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,2,d048nq,forums.fast.ai,Fastai v2 daily code walk-thrus - fastai-v2,https://www.reddit.com/r/MachineLearning/comments/d048nq/fastai_v2_daily_code_walkthrus_fastaiv2/,a1b1e1k1,1567706003,,1,1,False,default,,,,,
265,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,3,d04htw,self.MachineLearning,"Using AI to Write Fast - Demonstrating the Generative Differences Between XLNet, GPT-2 (Simple, Medium, Full) and a model trained from only legal appeals.",https://www.reddit.com/r/MachineLearning/comments/d04htw/using_ai_to_write_fast_demonstrating_the/,jshek,1567707135,"[https://writeup.ai](https://writeup.ai) \- A free and open-sourced app to show the differences between the different NLP algorithms. I originally also included TransformerXL, but the models run too slowly so it wasn't worth it. UX is crappy on mobile, but app works well on any laptops/screens.

Powered by Google Cloud and PyTorch. Huggingface's transformers code was instrumental in being a nice library to use. I had to do a lot of little optimizations/hacks to make performance acceptable with these larger models. 

An additional legal model was trained from GPT2-Simple from a 500mb dataset of legal appeals. Trained for about 250k steps on a V100, loss-rate was at 2.02 before I stopped. I'm currently redoing with a much larger dataset but using GPT2-Medium as a training ground (and trying to deal with gradient checkpoints). Tip: Have Dockerized / replaceable builds to decrease # of time to train and deploy onto production. 

So in the customize settings: you'll be able to toggle between the following five: 

* GPT2-Small
* GPT2-Medium
* GPT2-Large
* XLNet
* GPT2-Legal Prose 

Happy to answer any questions. I learned a lot about DevOps when making this.  Was still amazed at how well GPT2 is still arguably the best generating content even after the original post was months ago! An eternity in ML time. 

I'll post a blog writeup of all the revolving technical components if anyone's interested in the future. 

App : [https://writeup.ai](https://writeup.ai)  
Frontend Code at [https://github.com/jeffshek/writeup-frontend](https://github.com/jeffshek/writeup-frontend).  
Backend Code at [https://github.com/jeffshek/open](https://github.com/jeffshek/open)",0,1,False,self,,,,,
266,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,4,d059wt,self.MachineLearning,Shouldnt we be doing more than complaining about patents and hoping they wont affect our research and development activities?,https://www.reddit.com/r/MachineLearning/comments/d059wt/shouldnt_we_be_doing_more_than_complaining_about/,throwaway_mlengineer,1567710577,[removed],1,1,False,self,,,,,
267,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,4,d05c92,ai.googleblog.com,Announcement of the 2019 Fellowship Awardees and Highlights from the Google PhD Fellowship Summit,https://www.reddit.com/r/MachineLearning/comments/d05c92/announcement_of_the_2019_fellowship_awardees_and/,sjoerdapp,1567710856,,0,1,False,default,,,,,
268,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,4,d05cvr,self.MachineLearning,Copilot  driving assistant in a phone,https://www.reddit.com/r/MachineLearning/comments/d05cvr/copilot_driving_assistant_in_a_phone/,visualbuffer,1567710939,"Road accidents are the 9th leading causes of death globally at about 1.5 million per year. 90% of these fatalities occur in low and middle income countrieswhich have less than half of the total global vehicles population. 50% of all accidents occur on federal roads which are about a quarter of the total road network. 

 A majority of the accidents originate out of driver error. Advanced driver-assistance systems (ADAS): Lane detection, collision warning, blind-spot tracking can decrease road-accidents by a third.   The gap between the ADAS price tag and a consumer's willingness to pay is a steep climb. 

 The future will belong to the AI assistant running in a smartphone might leapfrog through the price gap into our cars. 

Read more : [http://bit.ly/c0Pilot](http://bit.ly/c0Pilot)",0,1,False,self,,,,,
269,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,4,d05h20,i.redd.it,1-st,https://www.reddit.com/r/MachineLearning/comments/d05h20/1st/,arslan95mr,1567711458,,0,1,False,default,,,,,
270,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,4,d05nfr,self.MachineLearning,[D] I just found the earliest description of the GAN idea - in the context of genetic algorithms,https://www.reddit.com/r/MachineLearning/comments/d05nfr/d_i_just_found_the_earliest_description_of_the/,p1esk,1567712263,"Danny Hillis ""Co-evolving parasites improve simulated evolution as an optimization procedure "", 1990.

[https://archive.org/details/06Kahle001316/page/n3](https://archive.org/details/06Kahle001316/page/n3)

&amp;#x200B;

&gt;...there are two independent gene pools, each evolving according to the selection/mutation/recombination sequence  outlined above. One population, the ""hosts"", represents sorting networks, while the other population, the ""parasites"", represents test cases. (These two populations might also be considered as ""prey"" and ""predator"", since their evolution rates  are comparable.) Both populations evolve on the  same grid, and their interaction is through their fitness functions. The sorting networks are scored  according to the test cases provided by the parasites at the same grid location. The parasites are scored according to how well they find flaws in sorting networks. Specifically, the phenotype of each parasite is a group of 10 to 20 test cases, and its score is the number of these tests that the corresponding sorting network fails to pass. The fitness functions of the host sorting networks and the parasitic sets of test patterns are complementary in the sense that a success of the sorting network represents a failure of the test pattern and vice versa.",28,21,False,self,,,,,
271,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,4,d05va6,self.MachineLearning,[D] consequences of converting .tiff to some tf.data supported format in terms of information loss?,https://www.reddit.com/r/MachineLearning/comments/d05va6/d_consequences_of_converting_tiff_to_some_tfdata/,turnmanh,1567713251,"Hi, I'm currently working with a dataset of .tiff files and want to feed those to a model using a tf Dataset for performance reasons. However, tf currently does not support loading .tiff files with Dataset.

Now I'm curious how to assess the loss in information if I convert a tiff to e.g. a png. Currently theses tiffs only hold a single image which for me should not make much a difference.  

What would be a good approach to assess this?",2,1,False,self,,,,,
272,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,4,d05wbt,self.MachineLearning,[D] optimizing clipping functions,https://www.reddit.com/r/MachineLearning/comments/d05wbt/d_optimizing_clipping_functions/,CartPole,1567713385,"In Reinforcement Learning I have noticed a trend in some([1](https://arxiv.org/abs/1707.06347), [2](https://arxiv.org/abs/1903.00374)) papers that involve optimizing surrogate clipped functions. Has anyone seen any work that digs deeper into the effects of this? For example, in [this](https://arxiv.org/abs/1811.02553) paper they dig deeper into the relationship between clipped surrogate functions and trust regions. The above references I gave were from clipped surrogate objectives, but this doesn't have to be the case(ex: drop the max and only optimize the clipped objective).",1,1,False,self,,,,,
273,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,4,d05wlv,self.MachineLearning,[D] Shouldnt we be doing more than complaining about patents and hoping they wont affect our research and development activities?,https://www.reddit.com/r/MachineLearning/comments/d05wlv/d_shouldnt_we_be_doing_more_than_complaining/,throwaway_mlengineer,1567713419,"Check out this newly issued patent (filed in Sept. 2014) that appears to shut down the entire discipline of ML as it applies to classifying different machine actions with AI.

[https://patentimages.storage.googleapis.com/17/f1/6d/15a1e6f88983c7/US10032117.pdf](https://patentimages.storage.googleapis.com/17/f1/6d/15a1e6f88983c7/US10032117.pdf)

Im paraphrasing / simplifying so its probably not completely accurate, but it looks like this tries to patent:

1. Receiving training data from channels on-board (not external to) a mobile machine;

2. Determining training features/data and corresponding labels from the training data;

3. Where the labels/data relate to different machine actions (as opposed to simply active or inactive) each occurring over different time periods;

4. Building the classifier by feeding training features/data and labels into a ML algorithm.

Surely this was known prior to the Sept. 2014 filing date of this patent. Is anyone else looking for a green light to continue to innovate in this space? Would be curious if anyone is aware of, or can find, an earlier public document that overlaps with the main claims of this patent. Thanks!! PS  yes, Ive googled and found some relevant documents, but have not yet found a single document that expressly includes all 4 items listed above.",34,133,False,self,,,,,
274,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,5,d068zy,self.MachineLearning,[R] DeepMind: Making Efficient Use of Demonstrations to Solve Hard Exploration Problems,https://www.reddit.com/r/MachineLearning/comments/d068zy/r_deepmind_making_efficient_use_of_demonstrations/,modeless,1567714960,"Blog post: https://deepmind.com/research/publications/Making-Efficient-Use-of-Demonstrations-to-Solve-Hard-Exploration-Problems

Paper: https://arxiv.org/pdf/1909.01387.pdf

This paper introduces R2D3, an agent that makes efficient use of demonstrations to solve hard exploration problems in partially observable environments with highly variable initial conditions. We also introduce a suite of eight tasks that combine these three properties, and show that R2D3 can solve several of the tasks where other state of the art methods (both with and without demonstrations) fail to see even a single successful trajectory after tens of billions of steps of exploration.",1,18,False,self,,,,,
275,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,6,d06ygf,kite.com,New ML over Code feature for Python: Intelligent Snippets,https://www.reddit.com/r/MachineLearning/comments/d06ygf/new_ml_over_code_feature_for_python_intelligent/,brendanmcd96,1567718078,,0,0,False,https://b.thumbs.redditmedia.com/EjGIzjVwx2v6-5u3Ga4RczjoAK_ITuiM19UhzdD42dg.jpg,,,,,
276,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,6,d072iv,self.MachineLearning,[P] Write With Transformer: A web app to compare generative NLP transformer-based models by Hugging Face,https://www.reddit.com/r/MachineLearning/comments/d072iv/p_write_with_transformer_a_web_app_to_compare/,jikkii,1567718589,"Sharing with you a project we've been working on at Hugging Face: [Write With Transformer](https://transformer.huggingface.co). It is a web app that hosts most state-of-the-art transformer-based NLP generative models like **GPT-2**, **GPT** or **XLNet.**

You can write a context and trigger completions from the generative model you choose, in a Google Doc-like interface. It also includes one of our fine-tuned models, using GPT-2 as a pretrained model and fine-tuning it on Arxiv papers to get NLP/Deep Learning completions.

It's built on top of our library [pytorch-transformers](https://github.com/huggingface/pytorch-transformers). Let us know what you think!",1,13,False,self,,,,,
277,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,6,d073gs,arxiv.org,[R] Adversarial Training for Free!,https://www.reddit.com/r/MachineLearning/comments/d073gs/r_adversarial_training_for_free/,downtownslim,1567718711,,2,6,False,default,,,,,
278,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,6,d073pf,self.MachineLearning,[R] Public ML Companies,https://www.reddit.com/r/MachineLearning/comments/d073pf/r_public_ml_companies/,BitMadHere,1567718742,"Hi all!

I'm currently working on a research project, looking to profile some publicly traded ML companies. 

Problem is, most ML companies get bought out by IBM, Microsoft, Google, or Amazon before going public.

I've got a small list of ones I've found, but if you know of any that are doing cool things, I'd love to hear about them!

Thanks in advance :)",4,4,False,self,,,,,
279,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,6,d076g4,self.MachineLearning,[R] Reusing Convolutional Activations from Frame to Frame to Speed up Learning and Inference,https://www.reddit.com/r/MachineLearning/comments/d076g4/r_reusing_convolutional_activations_from_frame_to/,arnokha,1567719113,"**Abstract**: When processing similar frames in succession, we can take advantage of the locality of the convolution operation to reevaluate only portions of the image that changed from the previous frame. By saving the output of a layer of convolutions and calculating the change from frame to frame, we can reuse previous activations and save computational resources that would otherwise be wasted recalculating convolutions whose outputs we have already observed. This technique can be applied to many domains, such as processing videos from stationary video cameras, studying the  effects of occluding or distorting sections of images, applying convolution to multiple frames of audio or time series data, or playing Atari games. Furthermore, this technique can be applied to speed up both  training and inference.

**Summary of results**: Reusing convolutional activations with CPUs is a good way to save computation for both training and inference, and can serve as a viable alternative to training or doing inference on GPUs in some scenarios. It is likely cheaper, sometimes faster, and it will likely have access to more memory. Unfortunately, there is currently not as much incentive to use this method on GPUs, other than possibly saving power. There are many possible application domains for this technique, and there are likely many ways to improve upon it.

Code and result figures: [https://github.com/arnokha/reusing\_convolutions](https://github.com/arnokha/reusing_convolutions)

Paper link: \[Submitted, coming soon\]",0,3,False,self,,,,,
280,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,6,d076kq,self.analytics,Which will have the highest job demand AI (ML Engineers) or Data Science (Data Scientists) in the next 3 years?,https://www.reddit.com/r/MachineLearning/comments/d076kq/which_will_have_the_highest_job_demand_ai_ml/,AILaunchpad,1567719133,,0,0,False,default,,,,,
281,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,6,d07a1d,self.MachineLearning,[D] Does Neural Program Synthesis be improved with x100 scaling of samples/compute/labels/curriculum ?!,https://www.reddit.com/r/MachineLearning/comments/d07a1d/d_does_neural_program_synthesis_be_improved_with/,so_tiredso_tired,1567719583,"Looking at some recent papers on program synthesis

Neural (Meta) Program Synthesis, Singh {GB} [https://uclmr.github.io/nampi/talk\_slides/rishabh-singh-nampi-v2.pdf](https://uclmr.github.io/nampi/talk_slides/rishabh-singh-nampi-v2.pdf)  

AlphaNPI paper just accepted to NIPS2019 with spotlight [https://arxiv.org/abs/1905.12941](https://arxiv.org/abs/1905.12941)

I am wondering if

a. the field is still working out good architectures, representations, etc

OR

b. existing SOTA techniques can be applied if we have x100 more compute, or a massive dataset of input-output pairs, or maybe a long detailed curated curriculum of specs and solutions, etc 

Thoughts welcome.",5,5,False,self,,,,,
282,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,8,d08ej7,self.MachineLearning,"[D] How can I go about learning machine learning to help people with ALS, like Jason Becker?",https://www.reddit.com/r/MachineLearning/comments/d08ej7/d_how_can_i_go_about_learning_machine_learning_to/,MrScientist_PhD,1567725332,"If you don't know him, it's this guy. Maybe someone else here might also be interested.

https://youtu.be/tYIZP1hrfZI

I know a semester of calculus, electronics theory, and starting to learn C++.

Besides anatomy and neuroscience, what should I really be focusing on to learn how to give more mobility to this guy in the future? Any cutting edge stuff that can possibly even help his brain communicate to his actual limbs and possibly get them to move again, or is it better to try to design full on robotic arms that he could manipulate almost like Doc Oc?",2,1,False,self,,,,,
283,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,8,d08ij9,youtube.com,Applied Data Science Coding with Python - Linear Regression Algorithm,https://www.reddit.com/r/MachineLearning/comments/d08ij9/applied_data_science_coding_with_python_linear/,setscholars,1567725942,,0,1,False,default,,,,,
284,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,8,d08ixs,self.MachineLearning,Is sklearn good enough for real production?,https://www.reddit.com/r/MachineLearning/comments/d08ixs/is_sklearn_good_enough_for_real_production/,mohd_sst,1567726006,"From your experience in a real production environment, let's assume the problem is solvable using something like Support Vector Machine, would sklearn be good enough for this situation or you're gonna need to implement your custom SVM?",0,1,False,self,,,,,
285,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,8,d08udo,self.MachineLearning,Data Science Career Track Prep Course,https://www.reddit.com/r/MachineLearning/comments/d08udo/data_science_career_track_prep_course/,HannahHumphreys,1567727665,[removed],0,1,False,self,,,,,
286,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,11,d0ab8n,self.MachineLearning,"[D] Does Netflix use machine learning to blur out the pixels in the background and only render the actors faces in the foreground, and maybe only objects the actors are interacting with? This way the background in a movie could act like a green screen and Netflix streaming could appear higher qality",https://www.reddit.com/r/MachineLearning/comments/d0ab8n/d_does_netflix_use_machine_learning_to_blur_out/,Nick-Conner,1567735449,,0,1,False,self,,,,,
287,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,12,d0b0k8,self.MachineLearning,How can I get in a group to learn/make models together,https://www.reddit.com/r/MachineLearning/comments/d0b0k8/how_can_i_get_in_a_group_to_learnmake_models/,mikeynoonja,1567739231,"I have recently been seeing groups on Kaggle of people doing competitions together, it excites me to see people working together and I hope I can get to that point someday. I thrive immensely in a group or have someone to collaborate with. But for now, I am only a novice and I am not finding anyone that I can work with in my personal location. It is honestly feels like I am the only one that wants to do anything with Machine Learning and I sometimes feel pretentious talking about it to be I work with or my peers. About 6 months back I did put my hand out there and asked if anyone wanted to join in a kaggle competition with me. With a decent amount of reception, we all quickly faded away from each other, I do not know if we were all in over our head or the interest had passed. With that being said, I want to get more involved with this community and actually meet some people. I have only been able to share these discoveries with myself. Would anyone happen to know where I can look to start collaborating? Feel free to message me and get to know me, I am only trying to make friends and I know we at least have one thing in common.",1,1,False,self,,,,,
288,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,12,d0b7ln,self.MachineLearning,[R] Neural Linguistic Steganography,https://www.reddit.com/r/MachineLearning/comments/d0b7ln/r_neural_linguistic_steganography/,modeless,1567740333,"An application of GPT-2 I never would have imagined. Hide surprisingly long secret messages in seemingly innocuous cover text.

Live demo: https://steganography.live/
More info and paper: https://steganography.live/info",10,127,False,self,,,,,
289,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,13,d0bktd,miami-rent-boat.com,Miami Boat Rentals | Boat Rental Options | Miami Rent Boat | Miami Rent Boat - Boat Rental,https://www.reddit.com/r/MachineLearning/comments/d0bktd/miami_boat_rentals_boat_rental_options_miami_rent/,DeniseLongworth,1567742489,,0,1,False,default,,,,,
290,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,13,d0c22u,self.MachineLearning,Some idea for sequence data,https://www.reddit.com/r/MachineLearning/comments/d0c22u/some_idea_for_sequence_data/,SunghoYahng,1567745433,[removed],0,1,False,self,,,,,
291,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,14,d0cchx,self.MachineLearning,[D] Requirements for a fast model-building algorithm in one-shot model-based reinforcement learning,https://www.reddit.com/r/MachineLearning/comments/d0cchx/d_requirements_for_a_fast_modelbuilding_algorithm/,wlorenz65,1567747298,"Comparision of algorithms for the fast extraction of a model from real world observations to be used for predicting rewards at different future timespans.

Requirements:
* Time  Has memory of at least 20 steps so that it can handle temporal sequences
* 1sht  Can learn from a single example so that it doesn't need hundreds of training samples for each class
* Hier  Is hierarchical so that it generalizes well (not just flat memorization)
* Arch  Can learn the architecture from data so that it doesn't need to be predefined by the developers
* Curr  Has curriculum learning so that it can be trained successively and doesn't suffer from catastrophic forgetting
* Scal  Can be scaled up to at least 1 million inputs so that it's not limited to toy environments

Algo |Time|1sht|Hier|Arch|Curr|Scal
:-----|:--:|:--:|:--:|:--:|:--:|:--:
NNGP  |   |  |   |  |   |   
GHSOM |   |   |   |  |  |   
THSOM |   |  |    |  |   |   
BPTT  |  |   |   |   |   |   
GA    |  |   |   |   |   |   
HTM   |  |   |   |   |   |   

Candidate algorithms:
* NNGP  Nearest Neighbor Gaussian Processes https://amstat.tandfonline.com/doi/abs/10.1080/01621459.2015.1044091
* GHSOM  Growing Hierarchical Self-Organizing Map http://www.ifs.tuwien.ac.at/~andi/ghsom/
* THSOM  Temporal Hebbian Self-organizing Map https://link.springer.com/chapter/10.1007/978-3-540-87536-9_65
* BPTT  Recurrent Neural Networks trained with Backpropagation Through Time, for example https://en.wikipedia.org/wiki/Long_short-term_memory
* GA  Genetic Algorithms https://en.wikipedia.org/wiki/Genetic_algorithm
* HTM  Hierarchical Temporal Memory https://en.wikipedia.org/wiki/Hierarchical_temporal_memory or in German https://de.wikipedia.org/wiki/Hierarchischer_Temporalspeicher

The table probably has errors because I'm not an expert and just wanna watch progress in AGI. But the current backprop winter is boring me, and if no one else is taking the initiative then an outsider from the audience has to.

As I don't understand the math in the paper for NNGPs, I'm assuming that they are just a hierarchical version of the simple nearest neighbor algorithm. Or that the two SOM-descendants are just standard self-organizing maps plus some fancy extensions for hierarchical architecture and time.

Drop a note if you find an error and I will fix the table.",0,5,False,self,,,,,
292,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,15,d0cq77,self.MachineLearning,[R] Some idea for choosing action (instead of reinforcement learning),https://www.reddit.com/r/MachineLearning/comments/d0cq77/r_some_idea_for_choosing_action_instead_of/,SunghoYahng,1567749923," 

I have heard that Reinforcement Learning (RL) has several problems for use in real-life problems.

 [alexirpan.com](https://www.alexirpan.com/2018/02/14/rl-hard.html)

### [Deep Reinforcement Learning Doesn't Work Yet](https://www.alexirpan.com/2018/02/14/rl-hard.html)

June 24, 2018 note: If you want to cite an example from the post, please cite the paper which that example came from. If you want to cite the post as a whole, you can use the following BibTeX:

I understand that the problem with RL is that it is appropriate when the environment is constantly receiving information in real-time (like real-time games or driving a car) but not when the environment consists of several features. And in many real-world problems, the environment consists of several features (like turn-based games).

So, as I understand it, theres a lack of ML models about which action to choose in the simple environment to achieve a score as high as possible. It is difficult to solve simply by classification or regression.

The idea I am thinking of is this:  
First, I want to select an action with only ML models for tabular data. So use tabular as the data. One row is one case, specific columns are Environment values, specific columns are Action values, and specific columns are Score.  
And, Env + Action is used as a dependent value and Score is independent.  
And get some model.

[**1.jpg817750 42.7 KB**](https://forums.fast.ai/uploads/default/original/3X/f/2/f2614f094b76f8c0a93e271a957bd641d5686c03.jpeg)

And when there is a value for Env, append all combinations of actions into tabular data. then use them as input to predict the score.  
Then you get the score value according to the combination of actions. Select the value of the Action whose score is the highest.

Since the value of Score according to Action is not a real one but a prediction, it may be necessary to select not the global minimum but the section with the most stable slope or the like. Came up with Recalled how to pick LR from a graph in LR Finder. Bayesian optimization can also be used to select the Action values to test. Or use sort of variance. Whatever.

[**2.jpg9192312 189 KB**](https://forums.fast.ai/uploads/default/original/3X/d/f/df1b5a680732a5badce88c5c359b36f089e0dfcf.jpeg)

And it can also be used to set what is good scores. In other words, When there is a stage, it can decide which score is the best way to get a high total score, in the same way (probably the results obtained so far from the previous stage can be the environment).  
That way, if you have a range of target scores, you can choose an Action that will give you that score.

[**3.jpg651512 23.6 KB**](https://forums.fast.ai/uploads/default/original/3X/5/4/54da402e78464f038fb5e43d7050f5e78763f28b.jpeg)

Another consideration here is that Env values are often sequential data. You may need to make the sequential process accordingly. One idea is this: for categorical: [Some idea for sequential data](https://forums.fast.ai/t/some-idea-for-sequential-data/54086)  
And in the case of numeric + sequential, I may need to use recursion and Deep Learning for tabular data together.

Please check if this idea is already obsolete, typical or absurd! If it looks ok, Ill dig it.",4,2,False,self,,,,,
293,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,15,d0d1f2,nips.cc,NeurIPS 2019 - Accepted Papers,https://www.reddit.com/r/MachineLearning/comments/d0d1f2/neurips_2019_accepted_papers/,aiismorethanml,1567752149,,0,1,False,default,,,,,
294,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,15,d0d1mv,self.MachineLearning,[D] Compressing Neural Network,https://www.reddit.com/r/MachineLearning/comments/d0d1mv/d_compressing_neural_network/,Minimum_Zucchini,1567752200,"I'm curious if this idea has been tried out anywhere, I can't seem to find results on arxiv but I think I'm using the wrong search terms.

I'm wondering if a feasible way of reducing the number of layers of a deep network is by training another much smaller network to approximate the behaviour of the large network between the input layer and second to last layer?

As an example, say we have a network with 100 layers, then we train it until it achieves the desired accuracy, and after training, I create a smaller network with maybe 5-10 layers, with the input being my data, and the output being the values of the 99th layer from the first network. I hope this makes sense. 

Anyone come across references for something like this?",7,5,False,self,,,,,
295,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,16,d0da2g,self.MachineLearning,Machine Learning Project - Uber Data Analysis,https://www.reddit.com/r/MachineLearning/comments/d0da2g/machine_learning_project_uber_data_analysis/,VyasBharvi,1567753899,[removed],0,1,False,https://b.thumbs.redditmedia.com/fdTk0rp9sf3fgfoxDu08BIdc2n9G6cR_cLPhm4b-1Cg.jpg,,,,,
296,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,16,d0dl0w,self.MachineLearning,Global Wind Turbine Bearings Market Report 2019,https://www.reddit.com/r/MachineLearning/comments/d0dl0w/global_wind_turbine_bearings_market_report_2019/,jadhavni3,1567756241,[removed],1,1,False,self,,,,,
297,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,17,d0dqr7,self.MachineLearning,Global Wastewater Recovery Systems Market Report 2019,https://www.reddit.com/r/MachineLearning/comments/d0dqr7/global_wastewater_recovery_systems_market_report/,jadhavni3,1567757485,[removed],1,1,False,self,,,,,
298,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,17,d0dtj0,self.MachineLearning,How do you scale up an experiment from laptop to cluster?,https://www.reddit.com/r/MachineLearning/comments/d0dtj0/how_do_you_scale_up_an_experiment_from_laptop_to/,tsuberim,1567758100,[removed],0,1,False,self,,,,,
299,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,17,d0dv88,self.MachineLearning,"[R] One Layer Is All You Need ""Deep Equilibrium Models""",https://www.reddit.com/r/MachineLearning/comments/d0dv88/r_one_layer_is_all_you_need_deep_equilibrium/,El__Professor,1567758498,[removed],0,1,False,self,,,,,
300,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,17,d0dw83,forum.huawei.com,Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/d0dw83/convolutional_neural_networks/,INTEL_RYZEN,1567758750,,0,1,False,default,,,,,
301,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,17,d0dz3x,self.MachineLearning,Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/d0dz3x/convolutional_neural_networks/,INTEL_RYZEN,1567759389,[removed],0,1,False,https://a.thumbs.redditmedia.com/DyLlVImdR4xPec3m9ERYp3e0RQ2_KwViycKm2R-wz44.jpg,,,,,
302,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,17,d0e0rr,hjlab-rotovap.com,How to choose a practical and economical rotary evaporator?,https://www.reddit.com/r/MachineLearning/comments/d0e0rr/how_to_choose_a_practical_and_economical_rotary/,hujiayq,1567759776,,0,1,False,default,,,,,
303,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,18,d0e5dt,self.MachineLearning,[Research] The Neural Qubit: Biologically Inspired Quantum Deep Learning,https://www.reddit.com/r/MachineLearning/comments/d0e5dt/research_the_neural_qubit_biologically_inspired/,sensetime,1567760766,"*Abstract*

Deep learning has resulted in state of the art performance for automated tasks in the fields of natural language processing, computer vision, autonomous driving, and many other subfields of Artificial Intelligence. However, if the goal is to create a system that is capable of learning any task, given an objective function, I hypothesize that its necessary to reconsider classical neural network architecture to incorporate certain properties of quantum mechanics, namely superposition and entanglement. Building on the work of Fisher (2015), I surmise that Phosphorus-31 enables both of these properties to occur within neurons in the human brain. In light of this evidence, quantum information processing in the context of digital neural networks is an area that deserves further exploration. As such, I present a novel quantum neural network architecture, similar to the continuous variable architecture by Killoran et al. (2018). It was applied to a transaction dataset for a fraud detection task and attained a considerable accuracy score. My aim is that this will provide a starting point for more research in this space, ultimately using this technology to drive more innovation in every Scientific discipline, from Pharmacology to Computer Science.

Paper: http://tiny.cc/ew2acz

Code: https://github.com/llSourcell/The-Neural-Qubit",0,1,False,self,,,,,
304,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,18,d0eb03,self.MachineLearning,I have a DQN model using experience replay. I try to save the model but it doesn't pick up learning where it left off. Do I need to store the replay memory buffer as well?,https://www.reddit.com/r/MachineLearning/comments/d0eb03/i_have_a_dqn_model_using_experience_replay_i_try/,ReasonablyBadass,1567761915,,0,1,False,self,,,,,
305,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,20,d0f4yf,elink.io,5 ways AI is transforming Document Management Systems (DMS) -,https://www.reddit.com/r/MachineLearning/comments/d0f4yf/5_ways_ai_is_transforming_document_management/,Ripple2709,1567767792,,0,1,False,https://b.thumbs.redditmedia.com/72YG0AhxwNSPTvCzDvGhvGI-G4P5xsQfKMg9cEFd_eQ.jpg,,,,,
306,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,20,d0fe46,self.MachineLearning,DS master program PS. Need help,https://www.reddit.com/r/MachineLearning/comments/d0fe46/ds_master_program_ps_need_help/,HourMousse,1567769358,[removed],0,1,False,self,,,,,
307,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,20,d0fevd,self.MachineLearning,[D] Approaches to array feature,https://www.reddit.com/r/MachineLearning/comments/d0fevd/d_approaches_to_array_feature/,truri,1567769492,"Do you know approaches to array/bag features?

To be specific let's say we have classification problem and want to sort out things as good or bad. For example:
Feature1 - regular feature, limited set of values: A, B, C
Feature2 - array/bag feature, container feature consisting of unknown number of values

Feature1  Feature2  Good?
A     [A, B]    Yes
B     [B, A, A]        No
A     [B, C, B, C, A]    Yes

How do one encode Feature2 to a numeric vector?",3,2,False,self,,,,,
308,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,20,d0flrs,self.MachineLearning,a doubt on logistic regression and its logarithmic cost function,https://www.reddit.com/r/MachineLearning/comments/d0flrs/a_doubt_on_logistic_regression_and_its/,manikantan2001,1567770655,[removed],0,1,False,self,,,,,
309,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,22,d0gfg2,github.com,[P] Learning Digital Circuits: A Journey Through Weight Invariant Self-Pruning Neural Networks,https://www.reddit.com/r/MachineLearning/comments/d0gfg2/p_learning_digital_circuits_a_journey_through/,agrawalamey,1567775250,,0,1,False,default,,,,,
310,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,22,d0gjph,self.MachineLearning,Is there any deepfake database?,https://www.reddit.com/r/MachineLearning/comments/d0gjph/is_there_any_deepfake_database/,Alir_the_Neon,1567775875,[removed],0,1,False,self,,,,,
311,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,22,d0gjy8,self.MachineLearning,Rent out 2X Tesla V100 machines for 0.3$ / hour,https://www.reddit.com/r/MachineLearning/comments/d0gjy8/rent_out_2x_tesla_v100_machines_for_03_hour/,duicr,1567775917,[removed],0,1,False,https://b.thumbs.redditmedia.com/302Rk0oQTxih8Tqhsy0szQXvVMBH9RoLBBCyjd0nOLs.jpg,,,,,
312,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,22,d0gk08,self.MachineLearning,[P] Learning Digital Circuits: A Journey Through Weight Invariant Self-Pruning Neural Networks,https://www.reddit.com/r/MachineLearning/comments/d0gk08/p_learning_digital_circuits_a_journey_through/,agrawalamey,1567775926,"**TLDR:**
- Learns weight agnostic topologies which mimic digital circuits using gradient descent. 
- Sparse nets with weights restricted to 0 or 1 can be learned by introducing Bernoulli initialization to BinaryConnect framework.
- In binarized net, neuron + activation act like OR gates. Network purely composed with OR gates fails to solve the complex problem.  BatchNorm acts like a NOT gate allowing the network to learn more complicated functions by forming NOR gates.
- Learning topologies don't necessarily need signed weights (Refer SuperMasks: https://arxiv.org/abs/1905.01067).

**Paper:** https://arxiv.org/abs/1909.00052

**Code:** https://github.com/AgrawalAmey/learning-digital-net

**Colab:** https://colab.research.google.com/github/AgrawalAmey/learning-digital-net/

![](https://pbs.twimg.com/media/EDuoUq7UEAA3QPI?format=jpg&amp;name=large)",2,13,False,self,,,,,
313,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,22,d0gn1r,self.MachineLearning,[D] Current issues with transfer learning in NLP,https://www.reddit.com/r/MachineLearning/comments/d0gn1r/d_current_issues_with_transfer_learning_in_nlp/,moyle,1567776353,"We have all been impressed with good results achieved by BERT and its brothers. But these models are not perfect and their results come at a cost. I have summarized a lot of my readings on current issues with these huge pre-trained models in this blog post: [https://mohammadkhalifa.github.io/2019/09/06/Issues-With-Transfer-Learning-in-NLP/](https://mohammadkhalifa.github.io/2019/09/06/Issues-With-Transfer-Learning-in-NLP/)[.](https://mohammadkhalifa.github.io/2019/09/06/Issues-With-Transfer-Learning-in-NLP/) 

I have mainly discussed the following 6 issues:

* Computational Intensity
* Difficult Reproducibility
* Leaderboard Madness
* Dissimilarity to how humans learn a language.
* Shallow Language Understanding.
* High carbon footprint.

Any feedback on the content or the writing would be really appreciated.",8,25,False,self,,,,,
314,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,22,d0gnx2,self.deeplearning,We present a (Poly-GAN) novel way for fitting clothes virtually on a person.,https://www.reddit.com/r/MachineLearning/comments/d0gnx2/we_present_a_polygan_novel_way_for_fitting/,nile6499,1567776471,,0,1,False,default,,,,,
315,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,22,d0gnyp,self.MachineLearning,[D] What is the inductive bias in transformer architectures?,https://www.reddit.com/r/MachineLearning/comments/d0gnyp/d_what_is_the_inductive_bias_in_transformer/,Kaleidophon,1567776478,"I've been thinking a lot about the question of inductive biases recently; basically equipping a model with a set of assumptions in order to make it prefer certain solutions. This can happen in different ways, like the model architecture, the loss or regularization. 

In NLP, RNNs are (still) very popular because through their recurrency they exhibit an inductive bias that makes them temporally invariant, but recent work (like [this](https://arxiv.org/pdf/1903.06400.pdf)) seems to suggest that this way they also suffer from a recency bias, which might inhibit their application to language. 

Now that transformers dominate the leaderboards in many NLP tasks, I was wondering which kind of inductive bias they might carry given their architecture?",16,14,False,self,,,,,
316,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,22,d0gobw,self.MachineLearning,[Discussion] Is there any Deepfake Database?,https://www.reddit.com/r/MachineLearning/comments/d0gobw/discussion_is_there_any_deepfake_database/,Alir_the_Neon,1567776543,"Hi All.I was wondering if there are any deepfake databases which can be found? I was surfing the net but couldn't find anything but  [https://www.idiap.ch/dataset/deepfaketimit](https://www.idiap.ch/dataset/deepfaketimit)

I did stumble upon news that Facebook and others are investing to build a database, so my guess is there isn't but I thought to ask just in case.

I am interested because I want to start a research on deepfake recognition, but before manually (semi-automatically) scrapping data I wanted to understand if there is anything that I am missing. Thank you)",3,0,False,self,,,,,
317,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,22,d0gs60,goarya.com,How Machine Learning is Actually Impacting the Hiring Process,https://www.reddit.com/r/MachineLearning/comments/d0gs60/how_machine_learning_is_actually_impacting_the/,ranjanme,1567777077,,0,1,False,default,,,,,
318,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,22,d0gsds,massstreetuniversity.com,Free eBook - What Everyone Should Know About the Job Market for Big Data,https://www.reddit.com/r/MachineLearning/comments/d0gsds/free_ebook_what_everyone_should_know_about_the/,learningstreet,1567777111,,0,1,False,https://b.thumbs.redditmedia.com/T9hM2ZnbtH4DLfmSHIledduPuHf6WCtZQ8e_6gq6SbM.jpg,,,,,
319,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,22,d0gtqq,arxiv.org,[R] [1806.04510v1] Dank Learning: Generating Memes Using Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/d0gtqq/r_180604510v1_dank_learning_generating_memes/,Smith4242,1567777302,,31,225,False,default,,,,,
320,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,22,d0gugx,self.MachineLearning,"[D] If you get lucky with a good model, do you keep it?",https://www.reddit.com/r/MachineLearning/comments/d0gugx/d_if_you_get_lucky_with_a_good_model_do_you_keep/,Seiteshyru,1567777402,"Let's say the random weights allow you to dodge a local optimum and you get a pretty good model, but it was just lucky. You can't easily reproduce it. What would be your focus? Trying to get a reproduction going or just working further with the model you have?",34,28,False,self,,,,,
321,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,22,d0h0h9,self.MachineLearning,[R] Metric Learning With HORDE: High-Order Regularizer for Deep Embeddings,https://www.reddit.com/r/MachineLearning/comments/d0h0h9/r_metric_learning_with_horde_highorder/,david_picard,1567778235,"Learning an effective similarity measure between image representations is key to the success of recent advances in visual search tasks (e.g. verification or zero-shot learning). Although the metric learning part is well addressed, this metric is usually computed over the average of the extracted deep features. This representation is then trained to be discriminative. However, these deep features tend to be scattered across the feature space. Consequently, the representations are not robust to outliers, object occlusions, background variations, etc. In this paper, we tackle this scattering problem with a distribution-aware regularization named HORDE. This regularizer enforces visually-close images to have deep features with the same distribution which are well localized in the feature space. We provide a theoretical analysis supporting this regularization effect. We also show the effectiveness of our approach by obtaining state-of-the-art results on 4 well-known datasets (Cub-200-2011, Cars-196, Stanford Online Products and Inshop Clothes Retrieval).

Paper: [https://arxiv.org/abs/1908.02735](https://arxiv.org/abs/1908.02735)

Code: [https://github.com/pierre-jacob/ICCV2019-Horde](https://github.com/pierre-jacob/ICCV2019-Horde)",2,9,False,self,,,,,
322,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,23,d0h2ku,arxiv.org,"Our paper ""Gradient-based Training of Slow Feature Analysis by Differentiable Approximate Whitening"" just got accepted for ACML 2019!",https://www.reddit.com/r/MachineLearning/comments/d0h2ku/our_paper_gradientbased_training_of_slow_feature/,mrschue,1567778541,,5,14,False,default,,,,,
323,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,23,d0hau2,self.MachineLearning,PMP Certification,https://www.reddit.com/r/MachineLearning/comments/d0hau2/pmp_certification/,digitalmarketing560,1567779654,[removed],0,1,False,self,,,,,
324,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,23,d0he1g,i.redd.it,I think this is inspiring,https://www.reddit.com/r/MachineLearning/comments/d0he1g/i_think_this_is_inspiring/,mohd_sst,1567780100,,0,1,False,default,,,,,
325,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,23,d0hikf,arxiv.org,[R] Ab-Initio Solution of the Many-Electron Schrdinger Equation with Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/d0hikf/r_abinitio_solution_of_the_manyelectron/,hardmaru,1567780709,,17,24,False,default,,,,,
326,MachineLearning,t5_2r3gv,2019-9-6,2019,9,6,23,d0hiuv,deepmind.com,"How brains replay experiences to strengthen memories, and how researchers use the same principle to train better AI systems in DeepMinds new blog post",https://www.reddit.com/r/MachineLearning/comments/d0hiuv/how_brains_replay_experiences_to_strengthen/,mohd_sst,1567780753,,0,1,False,default,,,,,
327,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,1,d0iv6w,self.MachineLearning,Method to predict time series data min and max?,https://www.reddit.com/r/MachineLearning/comments/d0iv6w/method_to_predict_time_series_data_min_and_max/,WannabeProgrammer_,1567786903,"Hi everyone. I am attempting to create an algorithm that will be trained on a large historical dataset (stock market data) that I believe is considered to be a time-series input. 

My goal is to find the patterns/signals that occur before a local max/min is reached but I am unsure how to then apply the algorithm to recognize the patterns real-time to immediately mark a local max/min.",0,1,False,self,,,,,
328,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,1,d0j34z,self.MachineLearning,"AI / ML  Past, Present &amp; Future - Start your journey",https://www.reddit.com/r/MachineLearning/comments/d0j34z/ai_ml_past_present_future_start_your_journey/,avnijainblr12,1567787944,[removed],1,1,False,self,,,,,
329,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,2,d0jltx,self.MachineLearning,I want to learn Python by working on a project. Where can I find one?,https://www.reddit.com/r/MachineLearning/comments/d0jltx/i_want_to_learn_python_by_working_on_a_project/,Doctor_who1,1567790324,[removed],0,1,False,self,,,,,
330,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,2,d0jnai,sciencedirect.com,Clinicians without coding experience made machine learning (ML) algorithms comparable to those by ML experts with an automatic ML API,https://www.reddit.com/r/MachineLearning/comments/d0jnai/clinicians_without_coding_experience_made_machine/,chinkazoid,1567790492,,0,1,False,default,,,,,
331,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,2,d0jri7,self.MachineLearning,Travel Feedback!,https://www.reddit.com/r/MachineLearning/comments/d0jri7/travel_feedback/,DanlOl12,1567791032,[removed],0,1,False,self,,,,,
332,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,2,d0jt5i,youtu.be,Machine Learning Pong Simulation made from Scratch,https://www.reddit.com/r/MachineLearning/comments/d0jt5i/machine_learning_pong_simulation_made_from_scratch/,iMilchshake,1567791226,,0,1,False,https://b.thumbs.redditmedia.com/qkhBycV1tpo-E0U-iwXpzaqnwN1UvCYGM3lUBMnpI9g.jpg,,,,,
333,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,2,d0jvnz,self.MachineLearning,[D] Using lasso regression for selecting polynomial terms,https://www.reddit.com/r/MachineLearning/comments/d0jvnz/d_using_lasso_regression_for_selecting_polynomial/,Megaslaking,1567791548,"Let's assume I have a polynomial regression but I'm not sure which polynomial degree `d` to use. In econometrics, one would probably try out the various regressions, each with different degrees and then check the significance of the individual terms, compare R\^2 value and so on. Assuming I have enough data points, if I want to explore `d = 1,..., 20`, then I'll need to do twenty individual regressions and compare them. 

Would be wrong, if I start from the very largest model, say `d=20`, and then use lasso regression to select only the terms that have non-zero coefficients? 

My question is absolutely related to the following old and unanswered question in stackexchange: [https://stats.stackexchange.com/questions/224707/selecting-polynomial-terms-in-regression](https://stats.stackexchange.com/questions/224707/selecting-polynomial-terms-in-regression)",8,1,False,self,,,,,
334,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,2,d0k0pv,self.MachineLearning,[D] Looking for a collaborator for an Inverse Reinforcement Learning project idea,https://www.reddit.com/r/MachineLearning/comments/d0k0pv/d_looking_for_a_collaborator_for_an_inverse/,banksyb00mb00m,1567792185,"I have a project idea in IRL which can materialize into a paper. If it works out, I would like to submit it for ICLR, so there's essentially 18 days of time from now. Though I have the basic idea chalked out, it would help me greatly to work with a collaborator.  


I  am looking for someone with decent Python programming skills (especially familiarity with OpenAI Gym and generic DRL algorithm implementations), good knowledge of Inverse Reinforcement Learning algorithms (up to, say, GAIL), and very basic understanding of GANs.  


Please feel free to contact me via chat or PM if you are interested.",0,0,False,self,,,,,
335,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,4,d0l5ds,ai.googleblog.com,Announcing Two New Natural Language Dialog Datasets,https://www.reddit.com/r/MachineLearning/comments/d0l5ds/announcing_two_new_natural_language_dialog/,sjoerdapp,1567797272,,0,1,False,default,,,,,
336,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,4,d0l5jx,self.MachineLearning,[R] Deep generative networks allow for efficient generation of samples from the Boltzmann distribution of complex multi-body systems.,https://www.reddit.com/r/MachineLearning/comments/d0l5jx/r_deep_generative_networks_allow_for_efficient/,konasj,1567797295,"TL/DR: Invertible generative models can be used to generate equilibrium states from high-dimensional multi-body systems such as proteins with hundreds of atoms. Training is a mixture of likelihood based training on biased trajectory data with subsequent fine-tuning using energy-based training (as done in parallel WaveNet). Such models allow for rapid exploration using MC exploration in latent space and computing free energy differences between disconnected states.

Paper: [https://science.sciencemag.org/content/365/6457/eaaw1147](https://science.sciencemag.org/content/365/6457/eaaw1147)

Editorial putting the paper into context: [https://science.sciencemag.org/content/365/6457/982](https://science.sciencemag.org/content/365/6457/982)",3,5,False,self,,,,,
337,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,4,d0l5mt,syncedreview.com,Facebook Introduces Dataset &amp; Challenge to Counter DeepFakes,https://www.reddit.com/r/MachineLearning/comments/d0l5mt/facebook_introduces_dataset_challenge_to_counter/,Yuqing7,1567797306,,0,1,False,https://a.thumbs.redditmedia.com/2xvmyYyJ5K9ggxEapMLJHqw6Xc842VGCAvdx06Po1L4.jpg,,,,,
338,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,5,d0mejd,self.MachineLearning,NeurIPS 2019 Stats,https://www.reddit.com/r/MachineLearning/comments/d0mejd/neurips_2019_stats/,DiegoCharrez,1567803074,[removed],0,1,False,self,,,,,
339,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,6,d0mks5,self.MachineLearning,Text classification using SVM,https://www.reddit.com/r/MachineLearning/comments/d0mks5/text_classification_using_svm/,KOWZDK,1567803866,[removed],0,1,False,self,,,,,
340,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,7,d0nu2a,self.MachineLearning,"AI + Climate Change, what can we do next?",https://www.reddit.com/r/MachineLearning/comments/d0nu2a/ai_climate_change_what_can_we_do_next/,ThatAIsohawtrightnow,1567809678,[removed],0,1,False,self,,,,,
341,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,8,d0o9f4,self.MachineLearning,help understanding dropout,https://www.reddit.com/r/MachineLearning/comments/d0o9f4/help_understanding_dropout/,socialmediaisalie,1567811749,[removed],0,1,False,self,,,,,
342,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,10,d0ppl2,youtu.be,How to make an AI read your handwriting (LAB) : Crash Course Ai #5,https://www.reddit.com/r/MachineLearning/comments/d0ppl2/how_to_make_an_ai_read_your_handwriting_lab_crash/,tyrial,1567819358,,0,1,False,default,,,,,
343,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,11,d0q5sc,self.MachineLearning,[D] Blog post explains various evolution strategies and how they can relate to recent deep RL research,https://www.reddit.com/r/MachineLearning/comments/d0q5sc/d_blog_post_explains_various_evolution_strategies/,sensetime,1567821842,"Author: Lilian Weng

Summary: Gradient descent is not the only option when learning optimal model parameters. Evolution Strategies (ES) works out well in the cases where we dont know the precise analytic form of an objective function or cannot compute the gradients directly. This post dives into several classic ES methods, as well as how ES can be used in deep reinforcement learning.

Link: https://lilianweng.github.io/lil-log/2019/09/05/evolution-strategies.html",6,101,False,self,,,,,
344,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,13,d0rkql,self.MachineLearning,Statistics YouTube channel recommendations?,https://www.reddit.com/r/MachineLearning/comments/d0rkql/statistics_youtube_channel_recommendations/,QueenLaniakea,1567830423,[removed],0,1,False,self,,,,,
345,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,14,d0s99j,i.redd.it,I'm trying to install CUDA 9.0 on my GTX 1060. I'm having this issue. How to fix it?,https://www.reddit.com/r/MachineLearning/comments/d0s99j/im_trying_to_install_cuda_90_on_my_gtx_1060_im/,masternachiket,1567835138,,0,1,False,default,,,,,
346,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,15,d0sfki,self.MachineLearning,HJLab 10L 20L 50L Industrial Rotary Evaporator Images,https://www.reddit.com/r/MachineLearning/comments/d0sfki/hjlab_10l_20l_50l_industrial_rotary_evaporator/,hujiayq,1567836454,[removed],0,1,False,https://b.thumbs.redditmedia.com/jkA4hYmDOio1xbxoK9cj0g31cjn2561KmITDRDRqjTQ.jpg,,,,,
347,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,15,d0sm50,self.MachineLearning,[D] AI Residencies - Opinions on them?,https://www.reddit.com/r/MachineLearning/comments/d0sm50/d_ai_residencies_opinions_on_them/,patty_nelsonn,1567837834,"I've been looking at applying for some AI/ML Residencies and I wonder if anyone had any general opinions on them, bad or good.

Also I was curious as to how competitive these programs are if anyone knows.",8,9,False,self,,,,,
348,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,15,d0ssii,mathworks.com,Free E-Book: Deep Learning vs. Machine Learning: Choosing the Best Approach,https://www.reddit.com/r/MachineLearning/comments/d0ssii/free_ebook_deep_learning_vs_machine_learning/,AILaunchpad,1567839191,,0,1,False,default,,,,,
349,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,16,d0sveu,self.MachineLearning,"We're looking for a Senior Data Science, AI &amp; Software Master Mind to run tech operations of our start-up: Lyra!",https://www.reddit.com/r/MachineLearning/comments/d0sveu/were_looking_for_a_senior_data_science_ai/,AILaunchpad,1567839812,[removed],0,1,False,self,,,,,
350,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,16,d0svi6,journals.lww.com,EEG Detects Brain Activity in Some Unresponsive Acute Brain Injury Patients,https://www.reddit.com/r/MachineLearning/comments/d0svi6/eeg_detects_brain_activity_in_some_unresponsive/,trot-trot,1567839834,,0,1,False,default,,,,,
351,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,16,d0szhu,journals.lww.com,[N] EEG Detects Brain Activity in Some Unresponsive Acute Brain Injury Patients,https://www.reddit.com/r/MachineLearning/comments/d0szhu/n_eeg_detects_brain_activity_in_some_unresponsive/,trot-trot,1567840677,,0,1,False,https://b.thumbs.redditmedia.com/VxS4vKNP-C0PI02BqeBJhI0kWZiWoDVgokKqLFQ-DqE.jpg,,,,,
352,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,16,d0szhx,data-flair.training,Top Machine Learning Use Cases - ML is Turning Dreams into Reality !!,https://www.reddit.com/r/MachineLearning/comments/d0szhx/top_machine_learning_use_cases_ml_is_turning/,AnujG23,1567840677,,0,1,False,default,,,,,
353,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,16,d0t8dd,self.MachineLearning,Best resources for a beginner to learn about reinforcement learning?,https://www.reddit.com/r/MachineLearning/comments/d0t8dd/best_resources_for_a_beginner_to_learn_about/,there_will_be_blood_,1567842657,[removed],0,1,False,self,,,,,
354,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,18,d0u3vj,self.MachineLearning,[D] Learnable image loss - what are the approaches?,https://www.reddit.com/r/MachineLearning/comments/d0u3vj/d_learnable_image_loss_what_are_the_approaches/,mesmer_adama,1567849813,"When doing auto encoders on images L1 loss is the standard choice but it tend to produce blurry images. Is there any literature that have a learnable loss, maybe something like GANs or some other function that takes a target image and an  output from the network but is also trainable?

I haven't seen this in the VAE and AE papers I've read but I'm sure there are lots of examples. Have you found any learnable losses or similar approaches?",14,12,False,self,,,,,
355,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,19,d0u73h,self.MachineLearning,[P] The basic distribution probability Tutorial for Deep Learning Researchers,https://www.reddit.com/r/MachineLearning/comments/d0u73h/p_the_basic_distribution_probability_tutorial_for/,nlkey2022,1567850514,"Hello there  
I read \[pattern recognition and machine learning, Bishop 2006\] and summarize the probability distributions that are often used in deep learning in my [Github Repository](https://github.com/graykode/distribution-is-all-you-need)

Also I simply had implemented probability distributions with python numpy.

1. Uniform distribution(continuous)
2. Bernoulli distribution
3. Binomial distribution
4. Multi-Bernoulli distribution
5. Multinomial distribution
6. Beta distribution
7. Dirichlet distribution
8. Gamma distribution
9. Exponential distribution
10. Gaussian distribution
11. Normal distribution
12. Chi-squared distribution
13. Student-t distribution

Please give issue if there are some wrong point Thanks :D

&amp;#x200B;

[https://github.com/graykode/distribution-is-all-you-need](https://github.com/graykode/distribution-is-all-you-need)

https://i.redd.it/xuo9d3lda5l31.png

[https://github.com/graykode/distribution-is-all-you-need](https://github.com/graykode/distribution-is-all-you-need)",5,4,False,https://b.thumbs.redditmedia.com/BYM0OUJ2-BwPHwjOCU5kckmdF3Hgl6gUKI_zARxnMkM.jpg,,,,,
356,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,20,d0utm1,blog.analyticspath.com,KNOW THE LATEST MACHINE LEARNING ALGORITHMS,https://www.reddit.com/r/MachineLearning/comments/d0utm1/know_the_latest_machine_learning_algorithms/,Jony1223,1567855387,,0,1,False,default,,,,,
357,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,20,d0uw2g,self.MachineLearning,Which course should I take before getting started in Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/d0uw2g/which_course_should_i_take_before_getting_started/,winter_l,1567855893,"I have heard many times that mathematics is first before getting into AI, Machine Learning. So I have found many courses like linear algebra, calculas and others. What should I do enroll any of that course first? Please give me some guideline. 

Here is the coursera link of Mathematics for Machine Learning Courses.

[https://is.gd/v1SNlB](https://is.gd/v1SNlB)",0,1,False,self,,,,,
358,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,20,d0uyza,self.MachineLearning,[D] Which Mathematics for Machine Learning course should I take before getting started in Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/d0uyza/d_which_mathematics_for_machine_learning_course/,winter_l,1567856492,"I have heard many times that mathematics is first before getting into AI, Machine Learning. So I have found many courses like linear algebra, calculus and others. What should I do enroll any of that course first? Please give me some guideline. Here is the link of all coursera Mathematics Machine Learning courses. [https://is.gd/v1SNlB](https://is.gd/v1SNlB)",0,0,False,self,,,,,
359,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,20,d0v2fm,self.MachineLearning,Regression task on training data size of 100~1000,https://www.reddit.com/r/MachineLearning/comments/d0v2fm/regression_task_on_training_data_size_of_1001000/,stevethesteve2,1567857179,[removed],0,1,False,self,,,,,
360,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,21,d0vi6u,self.MachineLearning,[Research] Automated deep learning design for medical image classification by health-care professionals with no coding experience: a feasibility study,https://www.reddit.com/r/MachineLearning/comments/d0vi6u/research_automated_deep_learning_design_for/,wptmdoorn,1567860135,"Direct link: [https://www.sciencedirect.com/science/article/pii/S2589750019301086](https://www.sciencedirect.com/science/article/pii/S2589750019301086)

**BACKGROUND** Deep  learning has the potential to transform health care; however,  substantial expertise is required to train such models. We sought to  evaluate the utility of automated deep learning software to develop  medical image diagnostic classifiers by health-care professionals with  no codingand no deep learningexpertise.

**METHODS** We  used five publicly available open-source datasets: retinal fundus  images (MESSIDOR); optical coherence tomography (OCT) images (Guangzhou  Medical University and Shiley Eye Institute, version 3); images of skin  lesions (Human Against Machine \[HAM\] 10000), and both paediatric and  adult chest x-ray (CXR) images (Guangzhou Medical University and Shiley  Eye Institute, version 3 and the National Institute of Health \[NIH\]  dataset, respectively) to separately feed into a neural architecture  search framework, hosted through Google Cloud AutoML, that automatically  developed a deep learning architecture to classify common diseases.  Sensitivity (recall), specificity, and positive predictive value  (precision) were used to evaluate the diagnostic properties of the  models. The discriminative performance was assessed using the area under  the precision recall curve (AUPRC). In the case of the deep learning  model developed on a subset of the HAM10000 dataset, we did external  validation using the Edinburgh Dermofit Library dataset.

**RESULTS** Diagnostic  properties and discriminative performance from internal validations  were high in the binary classification tasks (sensitivity 733970%;  specificity 67100%; AUPRC 087100). In the multiple classification  tasks, the diagnostic properties ranged from 38% to 100% for sensitivity  and from 67% to 100% for specificity. The discriminative performance in  terms of AUPRC ranged from 057 to 100 in the five automated deep  learning models. In an external validation using the Edinburgh Dermofit  Library dataset, the automated deep learning model showed an AUPRC of  047, with a sensitivity of 49% and a positive predictive value of 52%.

**DISCUSSION** All  models, except the automated deep learning model trained on the  multilabel classification task of the NIH CXR14 dataset, showed  comparable discriminative performance and diagnostic properties to  state-of-the-art performing deep learning algorithms. The performance in  the external validation study was low. The quality of the open-access  datasets (including insufficient information about patient flow and  demographics) and the absence of measurement for precision, such as  confidence intervals, constituted the major limitations of this study.  The availability of automated deep learning platforms provide an  opportunity for the medical community to enhance their understanding in  model development and evaluation. Although the derivation of  classification models without requiring a deep understanding of the  mathematical, statistical, and programming principles is attractive,  comparable performance to expertly designed models is limited to more  elementary classification tasks. Furthermore, care should be placed in  adhering to ethical principles when using these automated models to  avoid discrimination and causing harm. Future studies should compare  several application programming interfaces on thoroughly curated  datasets.",3,6,False,self,,,,,
361,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,22,d0vxb2,self.MachineLearning,"""And the Bit Goes Down"", Deep Learning Research, Research at Facebook | Interview with Pierre Stock",https://www.reddit.com/r/MachineLearning/comments/d0vxb2/and_the_bit_goes_down_deep_learning_research/,init__27,1567862629,"Interview with Pierre Stock about DL Research, Research at FAIR, and their recent work: [""And the Bit Goes Down: Revisiting the Quantization of Neural Networks""](https://arxiv.org/pdf/1907.05686.pdf):

&amp;#x200B;

Audio: [https://anchor.fm/chaitimedatascience/episodes/And-the-Bit-Goes-Down--Deep-Learning-Research--Research-at-FAIR--Interview-with-Pierre-Stock-e52rpk/a-alh51k](https://anchor.fm/chaitimedatascience/episodes/And-the-Bit-Goes-Down--Deep-Learning-Research--Research-at-FAIR--Interview-with-Pierre-Stock-e52rpk/a-alh51k)

&amp;#x200B;

Video: [https://www.youtube.com/watch?v=okFcSGShE10&amp;list=PLyMom0n-MBrrGL8w-nD9kc2q5dOwN7Hb1&amp;index=16](https://www.youtube.com/watch?v=okFcSGShE10&amp;list=PLyMom0n-MBrrGL8w-nD9kc2q5dOwN7Hb1&amp;index=16)",0,1,False,self,,,,,
362,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,22,d0vxrs,self.MachineLearning,[D] Facebook Microsoft $10M deepfake detection challenge,https://www.reddit.com/r/MachineLearning/comments/d0vxrs/d_facebook_microsoft_10m_deepfake_detection/,PuzzledProgrammer3,1567862713,"blog post: [https://ai.facebook.com/blog/deepfake-detection-challenge/](https://ai.facebook.com/blog/deepfake-detection-challenge/)

challenge: [https://deepfakedetectionchallenge.ai/](https://deepfakedetectionchallenge.ai/)

also repo for generating deepfakes from a single image with a few shot approach: [https://github.com/shaoanlu/fewshot-face-translation-GAN](https://github.com/shaoanlu/fewshot-face-translation-GAN)

it works on games as well: https://twitter.com/roadrunning01/status/1170121199285866497?s=20",68,352,False,self,,,,,
363,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,22,d0w1dc,github.com,[D] Has Adam Paszke migrated to google to work on tensorflow?,https://www.reddit.com/r/MachineLearning/comments/d0w1dc/d_has_adam_paszke_migrated_to_google_to_work_on/,shallowlearning,1567863301,,0,1,False,default,,,,,
364,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,22,d0w6z4,self.MachineLearning,Machine learning models trading,https://www.reddit.com/r/MachineLearning/comments/d0w6z4/machine_learning_models_trading/,marcomanny,1567864168,[removed],0,1,False,self,,,,,
365,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,22,d0w9p0,arxiv.org,"[R] An Efficient and Layout-Independent Automatic License Plate Recognition System Based on the YOLO detector (comprehensible paper with public datasets, architectures and weights)",https://www.reddit.com/r/MachineLearning/comments/d0w9p0/r_an_efficient_and_layoutindependent_automatic/,ghostzin,1567864579,,2,3,False,default,,,,,
366,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,23,d0wgxr,self.MachineLearning,New,https://www.reddit.com/r/MachineLearning/comments/d0wgxr/new/,venom4200,1567865637,I am new in machine learning. I am using python and jupiter notebook &amp; anaconda. Is this oke to get started,0,1,False,self,,,,,
367,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,23,d0whmn,self.MachineLearning,How to train my own dataset? - GPT2,https://www.reddit.com/r/MachineLearning/comments/d0whmn/how_to_train_my_own_dataset_gpt2/,teriwaalimeri,1567865738,[removed],0,1,False,self,,,,,
368,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,23,d0wliw,self.MachineLearning,[D] Cloze Driven Pre Training of Self Attention networks code,https://www.reddit.com/r/MachineLearning/comments/d0wliw/d_cloze_driven_pre_training_of_self_attention/,csuiuc22,1567866292,"This model (https://arxiv.org/pdf/1903.07785.pdf) seems to be the current sota for NER. I was looking to replicate the results, but it looks like the authors have not published coded. Shot it in the dark, but has anyone done this already, and have code available?",1,1,False,self,,,,,
369,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,23,d0wlm0,self.MachineLearning,"Fake News Classifier is trained on a large labelled, *English* dataset: I need arguments that it's language specific",https://www.reddit.com/r/MachineLearning/comments/d0wlm0/fake_news_classifier_is_trained_on_a_large/,Dr_Kokolores,1567866304,[removed],0,1,False,self,,,,,
370,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,23,d0wrw3,self.MachineLearning,[D] Any arguments that a Fake News Classifier trained on *English* news articles won't work for *German* news?,https://www.reddit.com/r/MachineLearning/comments/d0wrw3/d_any_arguments_that_a_fake_news_classifier/,Dr_Kokolores,1567867213,"I am developing a *German* Fake News Classifier for my master thesis. There are large labelled datasets (up to 1M articles) of *English* Fake News articles and therefore also pretty accurate classifiers (based on the text of the articles and NLP). Now I have to argue and explain why these classifiers won't detect Fake News in *German* language. For me it's obvious, it's trained on English **words,** so it won't work! :-D

Any ideas, arguments or scientific sources I could use to theoretically explain why it won't work / why I need a dataset with *German* News? Thank you so much!",10,1,False,self,,,,,
371,MachineLearning,t5_2r3gv,2019-9-7,2019,9,7,23,d0wtuo,i.redd.it,Rejected from ML News Google groups?,https://www.reddit.com/r/MachineLearning/comments/d0wtuo/rejected_from_ml_news_google_groups/,skanda13,1567867496,,0,1,False,default,,,,,
372,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,0,d0x1xu,youtube.com,A.I. Learns the Best Way of Earning and Saving Money (Simulation),https://www.reddit.com/r/MachineLearning/comments/d0x1xu/ai_learns_the_best_way_of_earning_and_saving/,mrsailor23,1567868614,,0,1,False,default,,,,,
373,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,0,d0x514,self.MachineLearning,Guys can you please tell me how can i save my ml model in colab in .h5 extension and download it on my local machine,https://www.reddit.com/r/MachineLearning/comments/d0x514/guys_can_you_please_tell_me_how_can_i_save_my_ml/,pckty,1567869029,[removed],0,1,False,self,,,,,
374,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,0,d0x7a9,self.MachineLearning,"folks, is there any machine learning based static code analysis tool that actually useful?",https://www.reddit.com/r/MachineLearning/comments/d0x7a9/folks_is_there_any_machine_learning_based_static/,marksteve4,1567869331,[removed],0,1,False,self,,,,,
375,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,0,d0xny0,self.MachineLearning,Fashion-gen challenge winners,https://www.reddit.com/r/MachineLearning/comments/d0xny0/fashiongen_challenge_winners/,lkspade,1567871552,[removed],0,1,False,self,,,,,
376,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,0,d0xoat,self.learnmachinelearning,Text analysis of blogs,https://www.reddit.com/r/MachineLearning/comments/d0xoat/text_analysis_of_blogs/,abhi_d104,1567871601,,0,1,False,default,,,,,
377,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,0,d0xpop,self.MachineLearning,[P] Topics for degree project,https://www.reddit.com/r/MachineLearning/comments/d0xpop/p_topics_for_degree_project/,moonify,1567871786,"Hello there. 

I have one year left to finish collegue and I have to start doing my degree project and since there are many researchers in the group I wanted to ask what topics do you suggest for such a project.",1,0,False,self,,,,,
378,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,1,d0xwed,self.MachineLearning,"tensorflow-gpu, doesn't seem to use my gpu instead using my cpu",https://www.reddit.com/r/MachineLearning/comments/d0xwed/tensorflowgpu_doesnt_seem_to_use_my_gpu_instead/,sahilbanno,1567872651,[removed],0,1,False,self,,,,,
379,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,2,d0yncp,arxiv.org,[R] Adversarial Training for Free!,https://www.reddit.com/r/MachineLearning/comments/d0yncp/r_adversarial_training_for_free/,downtownslim,1567876144,,3,3,False,default,,,,,
380,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,2,d0yzkr,youtu.be,A great explainer video on maching learning technology on recommendation engine.,https://www.reddit.com/r/MachineLearning/comments/d0yzkr/a_great_explainer_video_on_maching_learning/,Tech_videostreaming,1567877754,,0,1,False,https://a.thumbs.redditmedia.com/5wc_xQv-UMNAFpncsl-1LxqWmrOIH-U748wnYeBXjj8.jpg,,,,,
381,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,3,d0zckv,self.MachineLearning,[D] Why does the Huggingface Bert use so much less memory than the official Tensorflow Bert?,https://www.reddit.com/r/MachineLearning/comments/d0zckv/d_why_does_the_huggingface_bert_use_so_much_less/,CockGoblinReturns,1567879478,I can't seem to find the answer to this anywhere.,7,1,False,self,,,,,
382,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,4,d10b2t,arxiv.org,[R] [1909.01311] Learning without feedback: Direct random target projection as a feedback-alignment algorithm with layerwise feedforward training,https://www.reddit.com/r/MachineLearning/comments/d10b2t/r_190901311_learning_without_feedback_direct/,penpatience,1567883882,,6,14,False,default,,,,,
383,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,4,d10mx2,self.MachineLearning,"Wrote a post explaining YOLO and YOLOv2, love to hear your feedback.",https://www.reddit.com/r/MachineLearning/comments/d10mx2/wrote_a_post_explaining_yolo_and_yolov2_love_to/,Melai11,1567885454,[removed],0,1,False,self,,,,,
384,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,5,d1167p,self.MachineLearning,How to choose parameters of focal loss?,https://www.reddit.com/r/MachineLearning/comments/d1167p/how_to_choose_parameters_of_focal_loss/,BlackHawk1001,1567888024,[removed],0,1,False,self,,,,,
385,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,5,d11kqi,arxiv.org,[R] Keep Calm and Switch On! Preserving Sentiment and Fluency in Semantic Text Exchange,https://www.reddit.com/r/MachineLearning/comments/d11kqi/r_keep_calm_and_switch_on_preserving_sentiment/,AnonMLstudent,1567889967,,4,7,False,default,,,,,
386,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,6,d1206c,self.MachineLearning,Free Guide: Interpretable Machine Learning,https://www.reddit.com/r/MachineLearning/comments/d1206c/free_guide_interpretable_machine_learning/,andrea_manero,1567892010,[removed],0,1,False,self,,,,,
387,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,7,d12usw,self.MachineLearning,Topic Modeling/Text Analysis: Next steps after TF-IDF,https://www.reddit.com/r/MachineLearning/comments/d12usw/topic_modelingtext_analysis_next_steps_after_tfidf/,_Zer0_Cool_,1567896235,[removed],0,1,False,self,,,,,
388,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,8,d13ay1,/r/MachineLearning/comments/d13ay1/ai_application_airgesture_lets_play_game_without/,[AI application] AirGesture - Let's play game without keyboard,https://www.reddit.com/r/MachineLearning/comments/d13ay1/ai_application_airgesture_lets_play_game_without/,1991viet,1567898517,,1,1,False,default,,,,,
389,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,8,d13gcf,self.MachineLearning,Explain research engineer to me,https://www.reddit.com/r/MachineLearning/comments/d13gcf/explain_research_engineer_to_me/,mohd_sst,1567899324,[removed],0,1,False,self,,,,,
390,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,8,d13gn4,/r/MachineLearning/comments/d13gn4/bayesian_selforganizing_maps_illustrated_oc/,Bayesian Self-Organizing Maps illustrated [OC],https://www.reddit.com/r/MachineLearning/comments/d13gn4/bayesian_selforganizing_maps_illustrated_oc/,openjscience,1567899359,,1,1,False,https://b.thumbs.redditmedia.com/Lneypi1TthImN3Tl7bTThyp_4Be0TRq3h0AbpMh5OJA.jpg,,,,,
391,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,9,d13yex,self.MachineLearning,[R] DeepMind Starcraft 2 Update: AlphaStar is getting wrecked by professionals players,https://www.reddit.com/r/MachineLearning/comments/d13yex/r_deepmind_starcraft_2_update_alphastar_is/,HolidayGuidance,1567902051,"The SC2 community has managed to track down suspected AlphaStar accounts based on some heuristics which make it extremely unlikely to be a human player (e.g. matching EPM and APM for most of the game, no use of control groups, etc). To sum things up, AlphaStar appears to be consistently losing to professional players.

Replays available here:

https://www.youtube.com/watch?v=YjRNZaHjuRE
https://www.youtube.com/watch?v=R0KcZef3uyE
https://www.youtube.com/watch?v=M3Npor_LuzI
https://www.youtube.com/watch?v=wiz76rSJA5U
https://www.youtube.com/watch?v=6GzLeKowTvE
https://www.youtube.com/watch?v=3_YKEtTmQNo
https://www.youtube.com/watch?v=_BOp10v8kuM",121,262,False,self,,,,,
392,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,9,d140ku,self.MachineLearning,question about leaf node of regression tree,https://www.reddit.com/r/MachineLearning/comments/d140ku/question_about_leaf_node_of_regression_tree/,compsci_prof,1567902355," 

hello, i'm working through the data mining textbook ""data mining - practical machine learning tools and techniques"", and there's an example involving regression trees (see attached image). in the book they say ""the leaves of the tree are values that represent the average outcome for instances that reach the leaf"".

however, if you look at the leftmost leaf on the tree, there are three values: 19.3 (28/8.7%)

i get that 19.3 is the average outcome of instances that reach the leaf

i get that 28 is the number of instances that reach that leaf (if you add them all you get 209, the number of instances in the dataset)

however, i have no idea what the 8.7% represents. i know its correlated with the average outcome value, ie if you look at the rightmost leaf, the value is 783 (5/359%), so does anyone know what this 359% represents?

thanks

*Processing img zvrhzuo5k9l31...*",0,1,False,self,,,,,
393,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,13,d16g1x,self.MachineLearning,[D] How would you define the resume parsing task?,https://www.reddit.com/r/MachineLearning/comments/d16g1x/d_how_would_you_define_the_resume_parsing_task/,nottakumasato,1567916576,"I am thinking of segmenting based on keywords and afterwards using Named Entity Recognition finetuned for each segment to extract different fields like:

* Experience: company name, job title etc.
* Education: school, major etc.

However I wanted to see if there is a better approach for this problem. Any recommendations/references is welcome!",6,1,False,self,,,,,
394,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,14,d16ziv,self.MachineLearning,[Project] A.I. Learns the Best Way of Earning and Saving Money (Simulation),https://www.reddit.com/r/MachineLearning/comments/d16ziv/project_ai_learns_the_best_way_of_earning_and/,mrsailor23,1567920251,"Hey. I have a degree in Computer Science with a focus on AI and ML. I truly believe we can do more to popularize the concept of AI. I will be doing this through simulations were AI learns to deal with a simple problem and gives an answer to a specific question. I created the first one. Please take a look if you're interested. Feedback and ideas for the next one would be great :)

 [https://www.youtube.com/watch?time\_continue=1&amp;v=l2jVMfOhTKY](https://www.youtube.com/watch?time_continue=1&amp;v=l2jVMfOhTKY)",12,0,False,self,,,,,
395,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,14,d177cg,machinelearningplus.com,Best article for Time Series Analysis in Python,https://www.reddit.com/r/MachineLearning/comments/d177cg/best_article_for_time_series_analysis_in_python/,sahiluppal4k,1567921838,,0,2,False,default,,,,,
396,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,16,d17u8i,self.MachineLearning,what is a good chatbot to discuss philosophical topics with?,https://www.reddit.com/r/MachineLearning/comments/d17u8i/what_is_a_good_chatbot_to_discuss_philosophical/,galadzi,1567926730,[removed],0,1,False,self,,,,,
397,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,17,d18lfg,self.MachineLearning,[P] Content Update in PyTorch NLP Tutorial repo,https://www.reddit.com/r/MachineLearning/comments/d18lfg/p_content_update_in_pytorch_nlp_tutorial_repo/,lyeoni,1567932955,"Content Update in PyTorch NLP Tutorial repo.

\- **Text Classification**, with simple annotation.

* **Dataset**: *HuffPost* news corpus including corresponding category.
* **Pre-trained word vectors**: How pre-trained word representations affect model performance (via ablation study)

The model trained on this dataset identify the category of news article based on their headlines and descriptions.

[https://github.com/lyeoni/nlp-tutorial/tree/master/news-category-classifcation](https://github.com/lyeoni/nlp-tutorial/tree/master/news-category-classifcation)",0,0,False,self,,,,,
398,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,18,d18t2r,i.redd.it,Can anybody solve this question and explain the answer tome?,https://www.reddit.com/r/MachineLearning/comments/d18t2r/can_anybody_solve_this_question_and_explain_the/,CyberHero36,1567934699,,0,1,False,https://b.thumbs.redditmedia.com/LEI6clsO31R__DnXMrT9x4l5dRw72r5_H_IXUqymeQQ.jpg,,,,,
399,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,19,d199g2,self.MachineLearning,Curious about some AI stuff,https://www.reddit.com/r/MachineLearning/comments/d199g2/curious_about_some_ai_stuff/,Exocalypse,1567938269,[removed],0,1,False,self,,,,,
400,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,19,d19fmb,self.MachineLearning,How to query Arxiv by subfield / multiple fields?,https://www.reddit.com/r/MachineLearning/comments/d19fmb/how_to_query_arxiv_by_subfield_multiple_fields/,QueenLaniakea,1567939608,[removed],0,1,False,self,,,,,
401,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,21,d1a9vc,self.MachineLearning,[R] Audio Conversion GAN with Unpaired Data,https://www.reddit.com/r/MachineLearning/comments/d1a9vc/r_audio_conversion_gan_with_unpaired_data/,artika_labs,1567945542,"For the past month I have been working on voice conversion using unpaired data. I naively applied image conversion algorithms to audio spectrograms and after working out a few obstacles I got convincing, although not perfect, results.

Using the exact same algorithm on music genre conversion is also possible and the results, despite a fairly shallow generator with very low capacity, are pretty interesting.

Here are some examples:

[https://youtu.be/3BN577LK62Y](https://youtu.be/3BN577LK62Y)

The model is able to translate audio signals of any length and does not use any vocoder.

I cannot find papers with similar approaches, and I don't really know what I should do with this research. Being an Engineering student and not understanding how the academic world works, maybe a simple article and a code release is the best idea.

Thank you for your attention!",37,156,False,self,,,,,
402,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,22,d1am2q,linkedin.com,What is the difference between wide and deep topologies and what does a neural network actually do,https://www.reddit.com/r/MachineLearning/comments/d1am2q/what_is_the_difference_between_wide_and_deep/,ToolTechSoftware,1567947710,,1,1,False,default,,,,,
403,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,22,d1apli,self.MachineLearning,The Game That Learns,https://www.reddit.com/r/MachineLearning/comments/d1apli/the_game_that_learns/,ihaphleas,1567948277,[removed],0,1,False,self,,,,,
404,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,22,d1ayue,self.MachineLearning,Implications of retraining a model (with transfer learning) with the same object,https://www.reddit.com/r/MachineLearning/comments/d1ayue/implications_of_retraining_a_model_with_transfer/,pokedata,1567949763,[removed],0,1,False,self,,,,,
405,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,22,d1aztj,self.aymoonsun,Illegal Immigrant Human Test Subject Experimentation in the USA,https://www.reddit.com/r/MachineLearning/comments/d1aztj/illegal_immigrant_human_test_subject/,sdhksasm,1567949915,,0,1,False,default,,,,,
406,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,22,d1b5iq,self.MachineLearning,Machine Learning with Excel,https://www.reddit.com/r/MachineLearning/comments/d1b5iq/machine_learning_with_excel/,SAI_supremeAI,1567950754,"Hi all brilliant people. I need an advice. I am planning to create a video series namely Machine Learning with Excel from scratch. I am planning to show every detailed formulatuon of basic methods( classification, clustering and regression) and use excel functions only. Not VBA macro. Aiming to enable everybody to understand the basic formulation behind it as well as making it easy to use, you know! since it is only excel. I also have some fun ideas like discrete event simulation with excel from scratch since most of the industrial companies use excel or wimilar spread sheet programs for office work. Do you think it would contribute to the machine learning community to have learning tools just as easy as excel. It may be fun to introduce machine learning with excel to the beginners. What do you think?",0,1,False,self,,,,,
407,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,23,d1bmfe,linkedin.com,[R] Neural Network topology explained,https://www.reddit.com/r/MachineLearning/comments/d1bmfe/r_neural_network_topology_explained/,ToolTechSoftware,1567953148,,0,1,False,default,,,,,
408,MachineLearning,t5_2r3gv,2019-9-8,2019,9,8,23,d1byqy,self.MachineLearning,Trying to improve neural network accuracy feels like,https://www.reddit.com/r/MachineLearning/comments/d1byqy/trying_to_improve_neural_network_accuracy_feels/,metalwhalecom,1567954782,[removed],0,1,False,self,,,,,
409,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,0,d1c20a,self.MachineLearning,BERT fine tuning for open domain question answering,https://www.reddit.com/r/MachineLearning/comments/d1c20a/bert_fine_tuning_for_open_domain_question/,tonybonse,1567955194,"I'm a student and I'm doing a project where I would like to use BERT for question answering. In particular I will work on natural question by Google. I was wondering what are the fine tuning algorithm with better performance on natural question or on SQuAD 2.0? I wasn't able to find the most recent paper on it.
Thank you :)",0,1,False,self,,,,,
410,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,0,d1cbg5,self.MachineLearning,Need Help Pursuing Idea about Conditional Gans,https://www.reddit.com/r/MachineLearning/comments/d1cbg5/need_help_pursuing_idea_about_conditional_gans/,noviceProgrammer1,1567956446,[removed],0,1,False,self,,,,,
411,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,1,d1dgn8,self.MachineLearning,Text extraction from medium blogs,https://www.reddit.com/r/MachineLearning/comments/d1dgn8/text_extraction_from_medium_blogs/,abhi_d104,1567961543,[removed],0,1,False,self,,,,,
412,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,2,d1dt9h,endtoend.ai,[N] List of Reinforcement Learning Papers Accepted to NeurIPS 2019,https://www.reddit.com/r/MachineLearning/comments/d1dt9h/n_list_of_reinforcement_learning_papers_accepted/,seungjaeryanlee,1567963102,,0,1,False,https://a.thumbs.redditmedia.com/9n5MlDhTTSxCkYmIXdwOzJ8TFrnJPxISHv54h9q23t0.jpg,,,,,
413,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,3,d1eok8,self.MachineLearning,Dataset Error in Kaggle,https://www.reddit.com/r/MachineLearning/comments/d1eok8/dataset_error_in_kaggle/,zom8ie99,1567966950,[removed],0,1,False,https://b.thumbs.redditmedia.com/C7yOM9cyurZ4kvJnkp7mR6D3B5IN6_d5RqyJnYz73Nc.jpg,,,,,
414,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,5,d1g1k9,self.MachineLearning,[D] Machine Learning - WAYR (What Are You Reading) - Week 70,https://www.reddit.com/r/MachineLearning/comments/d1g1k9/d_machine_learning_wayr_what_are_you_reading_week/,ML_WAYR_bot,1567972805,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|31-40|41-50|51-60|61-70|
|----|-----|-----|-----|-----|-----|-----|
|[Week 1](https://www.reddit.com/4qyjiq)|[Week 11](https://www.reddit.com/57xw56)|[Week 21](https://www.reddit.com/60ildf)|[Week 31](https://www.reddit.com/6s0k1u)|[Week 41](https://www.reddit.com/7tn2ax)|[Week 51](https://reddit.com/9s9el5)|[Week 61](https://reddit.com/bfsx4z)|||||
|[Week 2](https://www.reddit.com/4s2xqm)|[Week 12](https://www.reddit.com/5acb1t)|[Week 22](https://www.reddit.com/64jwde)|[Week 32](https://www.reddit.com/72ab5y)|[Week 42](https://www.reddit.com/7wvjfk)|[Week 52](https://reddit.com/a4opot)|[Week 62](https://reddit.com/bl29ov)||
|[Week 3](https://www.reddit.com/4t7mqm)|[Week 13](https://www.reddit.com/5cwfb6)|[Week 23](https://www.reddit.com/674331)|[Week 33](https://www.reddit.com/75405d)|[Week 43](https://www.reddit.com/807ex4)|[Week 53](https://reddit.com/a8yaro)|[Week 63](https://reddit.com/bqlb3v)||
|[Week 4](https://www.reddit.com/4ub2kw)|[Week 14](https://www.reddit.com/5fc5mh)|[Week 24](https://www.reddit.com/68hhhb)|[Week 34](https://www.reddit.com/782js9)|[Week 44](https://reddit.com/8aluhs)|[Week 54](https://reddit.com/ad9ssz)|[Week 64](https://reddit.com/bw1jm7)||
|[Week 5](https://www.reddit.com/4xomf7)|[Week 15](https://www.reddit.com/5hy4ur)|[Week 25](https://www.reddit.com/69teiz)|[Week 35](https://www.reddit.com/7b0av0)|[Week 45](https://reddit.com/8tnnez)|[Week 55](https://reddit.com/ai29gi)|[Week 65](https://reddit.com/c7itkk)||
|[Week 6](https://www.reddit.com/4zcyvk)|[Week 16](https://www.reddit.com/5kd6vd)|[Week 26](https://www.reddit.com/6d7nb1)|[Week 36](https://www.reddit.com/7e3fx6)|[Week 46](https://reddit.com/8x48oj)|[Week 56](https://reddit.com/ap8ctk)|[Week 66](https://reddit.com/cd7gko)||
|[Week 7](https://www.reddit.com/52t6mo)|[Week 17](https://www.reddit.com/5ob7dx)|[Week 27](https://www.reddit.com/6gngwc)|[Week 37](https://www.reddit.com/7hcc2c)|[Week 47](https://reddit.com/910jmh)|[Week 57](https://reddit.com/auci7c)|[Week 67](https://reddit.com/cj0kyc)||
|[Week 8](https://www.reddit.com/53heol)|[Week 18](https://www.reddit.com/5r14yd)|[Week 28](https://www.reddit.com/6jgdva)|[Week 38](https://www.reddit.com/7kgcqr)|[Week 48](https://reddit.com/94up0g)|[Week 58](https://reddit.com/azjoht)|[Week 68](https://reddit.com/cp1jex)||
|[Week 9](https://www.reddit.com/54kvsu)|[Week 19](https://www.reddit.com/5tt9cz)|[Week 29](https://www.reddit.com/6m9l1v)|[Week 39](https://www.reddit.com/7nayri)|[Week 49](https://reddit.com/98n2rt)|[Week 59](https://reddit.com/b50r5y)|[Week 69](https://reddit.com/cvde5a)||
|[Week 10](https://www.reddit.com/56s2oa)|[Week 20](https://www.reddit.com/5wh2wb)|[Week 30](https://www.reddit.com/6p3ha7)|[Week 40](https://www.reddit.com/7qel9p)|[Week 50](https://reddit.com/9cf158)|[Week 60](https://reddit.com/bakew0)||

Most upvoted papers two weeks ago:

/u/zephyrzilla: [https://arxiv.org/abs/1908.03770](https://arxiv.org/abs/1908.03770)

/u/Moseyic: [Exploration by Disagreement](https://pathak22.github.io/exploration-by-disagreement/resources/icml19.pdf)

Besides that, there are no rules, have fun.",42,91,False,self,,,,,
415,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,5,d1gcz4,self.MachineLearning,if i change mini batch size which parameters are affected in NN,https://www.reddit.com/r/MachineLearning/comments/d1gcz4/if_i_change_mini_batch_size_which_parameters_are/,mshubham84,1567974141,,1,1,False,self,,,,,
416,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,6,d1hg0x,self.MachineLearning,[D] Suggestion for Machine Learning-related college capstone project,https://www.reddit.com/r/MachineLearning/comments/d1hg0x/d_suggestion_for_machine_learningrelated_college/,BL7599,1567979067,"Hello,

I posted in this subreddit regarding [a proposal for my undergraduate capstone project](https://www.reddit.com/r/MachineLearning/comments/cy05ga/d_interested_in_machine_learning_applied_to_stock/) and got some feedback pointing out that perhaps stock prediction isn't very well suited for what I was studying.

I wanted to know if you could recommend some subjects or areas you'd find interesting to research and build a project about using machine learning. Especially using newer models such as CNNs and RNNs or other state-of-the-art algorithms, since that's what my school expects the project to cover.

Thank you.",7,5,False,self,,,,,
417,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,7,d1hvzz,self.MachineLearning,Advise need on a Machine Learning project,https://www.reddit.com/r/MachineLearning/comments/d1hvzz/advise_need_on_a_machine_learning_project/,vinimenon,1567981199,[removed],0,1,False,self,,,,,
418,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,9,d1je3t,self.AI_Music,Utilizing AIVA.ai 's private API to compose music,https://www.reddit.com/r/MachineLearning/comments/d1je3t/utilizing_aivaai_s_private_api_to_compose_music/,SquareMove,1567988879,,0,1,False,https://b.thumbs.redditmedia.com/bYtOUjzK3d9WQJV5DP4MLQiUehx7notYETgxZEQd1Ho.jpg,,,,,
419,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,11,d1kwys,self.MachineLearning,192 Objective Type Questions and Answers in Deep Learning,https://www.reddit.com/r/MachineLearning/comments/d1kwys/192_objective_type_questions_and_answers_in_deep/,nkptcs,1567996823,"This quiz contains 192 objective type questions covering basic concepts of deep learning. Questions are mainly based on Perceptrons, Neural Networks, Weights and Bias, Activation Functions, Gradient Descent, Loss Functions, Convolutional Neural Network, Capsule Neural Network (CapsNets), Recurrent Neural Network, Regularization, Dropout, Fine-tuning, Transfer Learning, Autoencoders, TensorFlow and Keras.

There are helplines which you can avail multiple times. Maximum time allowed per questions is 60 seconds. 

[Link to the quiz](http://onlinemlquiz.com/deep_learning_quiz.php)",0,1,False,self,,,,,
420,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,12,d1l557,i.redd.it,Found this gem today,https://www.reddit.com/r/MachineLearning/comments/d1l557/found_this_gem_today/,SteelApple,1567998072,,0,1,False,default,,,,,
421,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,13,d1lzkb,self.MachineLearning,What projects are you guys working right now?,https://www.reddit.com/r/MachineLearning/comments/d1lzkb/what_projects_are_you_guys_working_right_now/,someonefromtheearth,1568002948,"I am working on a project that translates the language(NLP), but it's a simple project just for practicing.",0,1,False,self,,,,,
422,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,13,d1m8z0,linkedin.com,What is SSDP and Can it Truly Make Analytics Self-Serve?,https://www.reddit.com/r/MachineLearning/comments/d1m8z0/what_is_ssdp_and_can_it_truly_make_analytics/,ElegantMicroWebIndia,1568004629,,0,1,False,default,,,,,
423,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,14,d1mlww,self.MachineLearning,Best regression model for predicting store revenue,https://www.reddit.com/r/MachineLearning/comments/d1mlww/best_regression_model_for_predicting_store_revenue/,alwaysawake91,1568006937,[removed],0,1,False,self,,,,,
424,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,14,d1mujr,self.MachineLearning,Advanced Machine Learning,https://www.reddit.com/r/MachineLearning/comments/d1mujr/advanced_machine_learning/,HannahHumphreys,1568008549,[removed],0,1,False,self,,,,,
425,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,15,d1n33o,self.MachineLearning,IBM Data Science Professional Certificate,https://www.reddit.com/r/MachineLearning/comments/d1n33o/ibm_data_science_professional_certificate/,HannahHumphreys,1568010143,[removed],0,1,False,self,,,,,
426,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,15,d1n882,tdan.com,How Data Strategy and Machine Learning Intersect,https://www.reddit.com/r/MachineLearning/comments/d1n882/how_data_strategy_and_machine_learning_intersect/,vinbryan,1568011155,,0,1,False,default,,,,,
427,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,15,d1n8cw,self.MachineLearning,[D] Implications of retraining a model (with transfer learning) with the same object?,https://www.reddit.com/r/MachineLearning/comments/d1n8cw/d_implications_of_retraining_a_model_with/,pokedata,1568011176,"Hi,

I got some doubts about transfer learning.

I have this pre-trained model X, trained on the COCO dataset (its a dataset made of images; cars, persons, apples, etc...), and I want to retrain it using transfer learning with a new dataset made of one object that's already part of the COCO dataset: **apples**. I'm doing so because I want to use my apple dataset, and not the COCO one.

Now comes my doubt. What will happen with the previous knowledge the model has about apples? Will it differentiate my apples from COCO's? Also, what if I re-label my apples to ""manzanas"" (apple in Spanish), will there be some sort of conflict between the ""manzana"" and the already known ""apple"" label?

Hope the question makes sense. Thanks.",5,0,False,self,,,,,
428,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,18,d1oh90,self.MachineLearning,[D]Where can I find a data set to identify emerging and growing food concepts?,https://www.reddit.com/r/MachineLearning/comments/d1oh90/dwhere_can_i_find_a_data_set_to_identify_emerging/,DoIHAVeaNIdenTItY,1568020692,"I want to mine an open data source do identify emerging and growing food concepts as title says. Concepts such as ingredients, flavor, spices etc. Where can I find such data set?",2,2,False,self,,,,,
429,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,18,d1ojnm,self.MachineLearning,[D] Are filters from a particular Convolutional layer for a given CNN chosen at random by random initialization of weights in that network?,https://www.reddit.com/r/MachineLearning/comments/d1ojnm/d_are_filters_from_a_particular_convolutional/,rathernot000,1568021184,"In a Convolutional Layer of a given Convolutional Neural Network there is a defined input of size NxMxD. Whereas N and M stand for a dimension of an input image (can be smaller than the original size of an image due to pooling) and as I understand, D stands for a number of filters used in Convolution. My question is how network decides, what are the best filters for a given layer?",2,2,False,self,,,,,
430,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,18,d1ojro,self.MachineLearning,[P] Comparing 50 models Neural Machine Translation using Tensorflow,https://www.reddit.com/r/MachineLearning/comments/d1ojro/p_comparing_50_models_neural_machine_translation/,huseinzol05,1568021203,"**Accuracy based on word position not included padding**. 80% of the dataset to train, 20% of the dataset to test. Dataset is English-Vietnam, Trainset to train, validation and test set to test. 

1.basic-seq2seq, test accuracy 10.34%
2.lstm-seq2seq, test accuracy 11.89%
3.gru-seq2seq, test accuracy 11.50%
4.basic-seq2seq-contrib-greedy, test accuracy 25.28%
5.lstm-seq2seq-contrib-greedy, test accuracy 33.09%
6.gru-seq2seq-contrib-greedy, test accuracy 31.28%
7.basic-birnn-seq2seq, test accuracy 12.55%
8.lstm-birnn-seq2seq, test accuracy 12.11%
9.gru-birnn-seq2seq, test accuracy 11.98%
10.basic-birnn-seq2seq-contrib-greedy, test accuracy 27.50%
11.lstm-birnn-seq2seq-contrib-greedy, test accuracy 34.25%
12.gru-birnn-seq2seq-greedy, test accuracy 32.58%
13.basic-seq2seq-luong, test accuracy 2.40%
14.lstm-seq2seq-luong, test accuracy 13.08%
15.gru-seq2seq-luong, test accuracy 7.35%
16.basic-seq2seq-bahdanau, test accuracy 13.22%
17.lstm-seq2seq-bahdanau, test accuracy 13.38%
18.gru-seq2seq-bahdanau, test accuracy 14.02%
19.basic-birnn-seq2seq-bahdanau, test accuracy 13.88%
20.lstm-birnn-seq2seq-bahdanau, test accuracy 13.16%
21.gru-birnn-seq2seq-bahdanau, test accuracy 13.47%
22.basic-birnn-seq2seq-luong, test accuracy 7.49%
23.lstm-birnn-seq2seq-luong, test accuracy 13.27%
24.gru-birnn-seq2seq-luong, test accuracy 13.76%
25.lstm-seq2seq-contrib-greedy-luong, test accuracy 45.52%
26.gru-seq2seq-contrib-greedy-luong, test accuracy 8.14%
27.lstm-seq2seq-contrib-greedy-bahdanau, test accuracy 43.88%
28.gru-seq2seq-contrib-greedy-bahdanau, test accuracy 44.13%
29.lstm-seq2seq-contrib-beam-bahdanau, test accuracy 24.49%
30.gru-seq2seq-contrib-beam-bahdanau, test accuracy 22.26%
31.lstm-birnn-seq2seq-contrib-beam-luong, test accuracy 24.15%
32.gru-birnn-seq2seq-contrib-beam-luong, test accuracy 22.32%
33.lstm-birnn-seq2seq-contrib-luong-bahdanau-beam	
34.gru-birnn-seq2seq-contrib-luong-bahdanau-beam	
35.bytenet-greedy
36.capsule-lstm-seq2seq-contrib-greedy	
37.capsule-gru-seq2seq-contrib-greedy	
38.dnc-seq2seq-bahdanau-greedy	
39.dnc-seq2seq-luong-greedy	
40.lstm-birnn-seq2seq-beam-luongmonotic, test accuracy 27.23%
41.lstm-birnn-seq2seq-beam-bahdanaumonotic, test accuracy 26.34%
42.memory-network-lstm-seq2seq-contrib, test accuracy 28.02%
43.attention-is-all-you-need-beam, test accuracy 37.80%
44.conv-seq2seq, test accuracy 33.73%
45.conv-encoder-lstm-decoder, test accuracy 32.91%
46.dilated-conv-seq2seq, test accuracy 33.17%
47.gru-birnn-seq2seq-greedy-residual, test accuracy 34.35%
48.google-nmt, test accuracy 33.09%
49.bert-transformer-decoder-beam, test accuracy 44.69%
50.xlnet-base-transformer-decoder-beam, test accuracy 28.83%

Link to repository, https://github.com/huseinzol05/NLP-Models-Tensorflow/tree/master/neural-machine-translation

Link to dataset, https://github.com/stefan-it/nmt-en-vi#dataset

## Discussion

1. Based on 20 epochs only.
2. Accuracy based on word positions.
3. Some results are empty because the models are slow to train, still waiting for the results.
4. Sort from shortest length to longest length and do bucketing from it will improve the accuracy.",5,3,False,self,,,,,
431,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,18,d1olhs,self.MachineLearning,"DataViZ, Data Science and Machine Learning White Papers - Part 3",https://www.reddit.com/r/MachineLearning/comments/d1olhs/dataviz_data_science_and_machine_learning_white/,andrea_manero,1568021577,[removed],0,1,False,self,,,,,
432,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,18,d1onva,docdroid.net,Mathematics of Machine Learning (pdf),https://www.reddit.com/r/MachineLearning/comments/d1onva/mathematics_of_machine_learning_pdf/,trenuss,1568022071,,0,1,False,default,,,,,
433,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,18,d1ooem,nytimes.com,"[D] When the A.I. Professor Leaves, Students Suffer, Study Says",https://www.reddit.com/r/MachineLearning/comments/d1ooem/d_when_the_ai_professor_leaves_students_suffer/,MTGTraner,1568022174,,64,256,False,https://a.thumbs.redditmedia.com/nP2Zz3bHwPUsySSGJuKqOqp0LNcQ0e8gwRoeq1PgF30.jpg,,,,,
434,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,18,d1ooqp,self.MachineLearning,Deep learning &amp; XgBoost : Winning it hands down !,https://www.reddit.com/r/MachineLearning/comments/d1ooqp/deep_learning_xgboost_winning_it_hands_down/,andrea_manero,1568022236,[removed],0,1,False,self,,,,,
435,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,19,d1oucm,self.MachineLearning,[Project] Open domain question answering with BERT.,https://www.reddit.com/r/MachineLearning/comments/d1oucm/project_open_domain_question_answering_with_bert/,tonybonse,1568023371,"I'm a student and I'm doing a project with BERT for open domain question answering. In particular I will work on natural question by Google. I was wondering what are the fine tuning algorithm with better performance on natural question or on SQuAD 2.0 right now? I wasn't able to find the most recent paper on it.
Thank you :)",1,0,False,self,,,,,
436,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,19,d1ovr3,self.MachineLearning,Rotated Mask R-CNN,https://www.reddit.com/r/MachineLearning/comments/d1ovr3/rotated_mask_rcnn/,mrlooi,1568023623,[removed],0,1,False,self,,,,,
437,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,19,d1oyxf,self.MachineLearning,[Research] Rotated Mask RCNN,https://www.reddit.com/r/MachineLearning/comments/d1oyxf/research_rotated_mask_rcnn/,mrlooi,1568024259,"# The Problem With MaskRCNN (and Bounding Boxes)

[https://i.redd.it/ezqm8sf2mjl31.png](https://i.redd.it/ezqm8sf2mjl31.png)

Due to bounding box ambiguity, **Mask R-CNN** fails in relatively dense scenes with objects of the same class, particularly if those objects have high bounding box overlap. In these scenes, **both recall (due to NMS) and precision (foreground instance class ambiguity)** are affected.

&amp;#x200B;

[https://i.redd.it/zzbjf23amjl31.png](https://i.redd.it/zzbjf23amjl31.png)

# Rotated Mask R-CNN

[Rotated Mask R-CNN](https://github.com/mrlooi/rotated_maskrcnn) resolves some of these issues by adopting a rotated bounding box representation. Extends Faster R-CNN, Mask R-CNN, or even RPN-only to work with rotated bounding boxes.

&amp;#x200B;

[https://i.redd.it/35ilbqqbmjl31.png](https://i.redd.it/35ilbqqbmjl31.png)

This work also builds on the Mask Scoring R-CNN ('MS R-CNN') paper by learning the quality of the predicted instance masks ([maskscoring\_rcnn](https://github.com/zjhuang22/maskscoring_rcnn)).

Github Link: [https://github.com/mrlooi/rotated\_maskrcnn](https://github.com/mrlooi/rotated_maskrcnn)",11,48,False,self,,,,,
438,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,19,d1pbdx,self.MachineLearning,Random noise on weights is L2 regularisation?,https://www.reddit.com/r/MachineLearning/comments/d1pbdx/random_noise_on_weights_is_l2_regularisation/,invaluable,1568026638,[removed],0,1,False,self,,,,,
439,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,21,d1qcci,gereshes.com,Neural Network Based Optimal Control: Resilience to Missed Thrust Events for Long Duration Transfers,https://www.reddit.com/r/MachineLearning/comments/d1qcci/neural_network_based_optimal_control_resilience/,Gereshes,1568032701,,0,1,False,default,,,,,
440,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,21,d1qj1q,self.MachineLearning,[D] 2nd Order Approximation in XGboost's Objective Function,https://www.reddit.com/r/MachineLearning/comments/d1qj1q/d_2nd_order_approximation_in_xgboosts_objective/,_kty,1568033731,"Hi all,

I have a quick question regarding XGboost's objective function. I was reading the XGboost paper ([https://arxiv.org/pdf/1603.02754.pdf](https://arxiv.org/pdf/1603.02754.pdf)). I see that authors approximated the original objective function using a 2nd order Taylor series (page 2, section 2.2). Is there a particular reason why it's expanded to 2nd degree and not higher? I'm guessing that linear apprx. is not enough and higher orders require more computational power, but is there a mathematical background or is this a design choice?",3,18,False,self,,,,,
441,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,22,d1qn50,self.MachineLearning,Deep Learning rack server suggestions,https://www.reddit.com/r/MachineLearning/comments/d1qn50/deep_learning_rack_server_suggestions/,Gusinato95,1568034310,[removed],0,1,False,self,,,,,
442,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,22,d1qwp6,self.MachineLearning,"[P] I used reinforcement learning to solve Numberphile's ""cat and mouse"" game!",https://www.reddit.com/r/MachineLearning/comments/d1qwp6/p_i_used_reinforcement_learning_to_solve/,diddilydiddilyhey,1568035719,"[Here's a fun gif of it successfully escaping after a couple attempts!](https://i.redd.it/78xgkwmbudk31.gif)

I used the DDPG an A2C reinforcement learning algorithms to train the agent to solve [this puzzle I saw in a Numberphile video](https://www.youtube.com/watch?v=vF_-ob9vseM). While the puzzle itself is pretty simple, using RL to solve it was somewhat tricky. Like MountainCar, the reward space is pretty sparse, but effectively made much sparser because of the cat.

To get it to solve the more challenging versions (i.e., with a faster cat), I had to ""bootstrap"" (not in the traditional RL sense) by starting with the solution of the easier problem (which is definitely kind of cheating :P).

[Here's the full blog post I did on it](https://www.declanoller.com/2019/08/30/solving-numberphiles-cat-and-mouse-puzzle-using-the-ddpg-and-a2c-reinforcement-learning-algorithms/). If anyone has any feedback or questions, please let me know!",0,0,False,self,,,,,
443,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,22,d1qxmt,self.MachineLearning,"Why don't nlp conferences(ACL, EMNLP, NAACL) release their tutorials, talks recordings like NIPS, ICML do?",https://www.reddit.com/r/MachineLearning/comments/d1qxmt/why_dont_nlp_conferencesacl_emnlp_naacl_release/,zjplab,1568035861,I cannot find tutorial videos online. Very inconvenient for those who haven't  attend  these conferences. Also bad for future reference.,0,1,False,self,,,,,
444,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,22,d1r2bx,self.MachineLearning,Are the additions of neural networks operations linear in runtime?,https://www.reddit.com/r/MachineLearning/comments/d1r2bx/are_the_additions_of_neural_networks_operations/,grandandmott,1568036509,[removed],0,1,False,self,,,,,
445,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,22,d1r7ql,self.MachineLearning,[D] Forced alignment for low resource languages,https://www.reddit.com/r/MachineLearning/comments/d1r7ql/d_forced_alignment_for_low_resource_languages/,sicp4lyfe,1568037278,"So leave out Kaldi, Gentle, Montreal Fixed Alignment, etc. All those need detailed phonetic dictionaries etc which are only available for the most popular languages. 

How does ML help if you can't leverage ANY of the existing language toolsets? Does anyone have a good guess at possible ML solutions, can be semi supervised. Keep in mind when most of the work on forced alignment was done, it predates modern ML like deep neural networks etc. 

Just want to hear your crazy ideas and hopefully I can take one and run with it.",0,1,False,self,,,,,
446,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,23,d1rc6i,self.MachineLearning,Learn Python AI for Image Recognition &amp; Fraud Detection,https://www.reddit.com/r/MachineLearning/comments/d1rc6i/learn_python_ai_for_image_recognition_fraud/,HannahHumphreys,1568037877,[removed],0,1,False,self,,,,,
447,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,23,d1rfw5,self.MachineLearning,[D] Deep Learning rack server suggestions,https://www.reddit.com/r/MachineLearning/comments/d1rfw5/d_deep_learning_rack_server_suggestions/,Gusinato95,1568038396,"Hello ML, my research lab just received a grant (25K ) for purchasing new hardware and we would like some recommendation so we can build the best deep learning rack. The team consists of 10-15 members. Our work involves different deep learning disciplines from images and videos to text or graphs.

We already have some servers with one or two GPU each shared between a few people and that worked out perfectly. Now we want to install a powerful rack with a setup similar to the DevBox spending all our budget. Our proposal, written one year ago:

&amp;#x200B;

|Component|Quantity|
|:-|:-|
|HPC 4u with space up to 8Gpus|1|
|Intel Skylake Xeon Gold Serie 6xxx o Power PC 9|2|
|32 Gb DDR4-2666 ECC REG|18|
|NVIDIA RTX 2080TI|4|
|Intel DC P4600 2TB NVMe PCIe 3.0|2|
|SATA3 2TB 6GB/s 7.200 RMP|1|

&amp;#x200B;

Do you guys have any suggestion for a good/cost-efficient setup or some requirements that we must meet when configuring our rack server setup?

Thanks",11,3,False,self,,,,,
448,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,23,d1ro9v,towardsdatascience.com,Document Embedding Techniques: A Literature Review ,https://www.reddit.com/r/MachineLearning/comments/d1ro9v/document_embedding_techniques_a_literature_review/,shaypal5,1568039502,,0,2,False,https://a.thumbs.redditmedia.com/xogq_79brOF8AYPvv73QxGnmDbzF5AwMIax0y6cVY80.jpg,,,,,
449,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,23,d1rrer,self.MachineLearning,How well do you know the math behind certain ML algoritms,https://www.reddit.com/r/MachineLearning/comments/d1rrer/how_well_do_you_know_the_math_behind_certain_ml/,GroundbreakingAlps2,1568039928,"This question is mainly aimed at people actually working with DS /machine learning, but I suppose students are also free to answer with their experience/understanding of this.

My question is how well do people actually understand the math/theory and details behind how certain things (algoritms) work? 

I took a course in machine learning some while ago (a couple years ago actually), the book that I used was an introduction to statistical learning (certainly not the heaviest book when it comes  to theory/math, but there is some).

Unfortunately, I have forgotten a lot about general theory behind how a lot of the common algorithms work, specifically most of all the mathematical details and mathematical theory underpinning these ideas. 

If you asked me to explain some of the math behind SVM's I honestly probably couldn't even tell you a single thing.  

Are you guys (working people) able to tell me some things and some math about SVM's, cold? (i.e without looking at your books/notes)? 

so my question is: how cruical is it really to fully understand these type of things?  Or is machine learning / DS (in the workforce), more about results, and applying things? (applying most of the algorithms in the book on some simple data sets is pretty easy if I recall correctly? 

Obviously I understand that some theory is obviously needed, for a simple example: I understand that you wouldn't use  linear regression unless you have normally distributed variables with the same variance, but there is also a lot of more complex mathematical details behind linear regression (for instance estimation of parameters, you can for instance begin talking about MLE, LSE, etc which has so much math and theory behind it as well.",0,1,False,self,,,,,
450,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,23,d1rv4p,arxiv.org,[R] [1906.10015v1] A Review on Neural Network Models of Schizophrenia and Autism Spectrum Disorder,https://www.reddit.com/r/MachineLearning/comments/d1rv4p/r_190610015v1_a_review_on_neural_network_models/,Smith4242,1568040418,,4,12,False,default,,,,,
451,MachineLearning,t5_2r3gv,2019-9-9,2019,9,9,23,d1s0i2,vixra.org,Deep Learning Cancer from Handwriting Samples,https://www.reddit.com/r/MachineLearning/comments/d1s0i2/deep_learning_cancer_from_handwriting_samples/,terriblestraitjacket,1568041116,,0,1,False,default,,,,,
452,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,0,d1s4nn,self.MachineLearning,Performance RAM vs image observations in OpenAI Retro Gym,https://www.reddit.com/r/MachineLearning/comments/d1s4nn/performance_ram_vs_image_observations_in_openai/,AnotherForce,1568041629,[removed],0,1,False,self,,,,,
453,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,0,d1s6gd,self.MachineLearning,Graduation Project,https://www.reddit.com/r/MachineLearning/comments/d1s6gd/graduation_project/,EslamZiko,1568041847,[removed],0,1,False,self,,,,,
454,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,0,d1si45,vladfeinberg.com,[D] functions of subgaussian random variables,https://www.reddit.com/r/MachineLearning/comments/d1si45/d_functions_of_subgaussian_random_variables/,vladfeinberg,1568043337,,0,1,False,default,,,,,
455,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,0,d1srn2,self.MachineLearning,[P] Neural Network Model Builder &amp; Visualiser | Netbrix.ml,https://www.reddit.com/r/MachineLearning/comments/d1srn2/p_neural_network_model_builder_visualiser/,DataSnaek,1568044528,"# [https://netbrix.ml/](https://netbrix.ml/)

# Introduction

I recently discovered the Mithril.js JavaScript library and wanted a project to build up my skills with it! I ended up going with a simple web app for visualising and editing network models which I've named [netbrix.ml](https://netbrix.ml). I've wanted to build something like this for a while since it seemed like a really good project to improve my web development skills and my understanding of the process of building deep learning models. After reading [this post](https://www.reddit.com/r/deeplearning/comments/coifgi/the_modularity_of_deep_learning/) on /r/deeplearning where the writer gives insight into the modular nature of deep learning and gives the analogy of a deep learning 'lego set' it gave me the motivation to start work on this with that sort of vision in mind and I've now got a decent working web app! 

I'm sure there are existing tools similar to this in existence, so I wanted to keep it as simple as possible and not try to over-engineer it. It's meant to be easy and simple to use!

# Importing Models

It has some cool features at the moment, like the ability to parse `Sequential()` model definitions in Keras e.g.

    test_model = Sequential()
    
    test_model.add(Conv2D(64,(5,5), activation='relu'))
    test_model.add(MaxPooling2D((2,2)))
    test_model.add(Dropout(0.25))

(Alternatively you can paste in Keras JSON definitions from for example `test_model.to_json()`)

Once that simple model definition is imported it will be parsed by the app to create the following neat visualisation:

&amp;#x200B;

https://i.redd.it/g60mc0qh2ll31.png

# Editing Models

From here, you can make all the typical changes you would want to make to a model, including changing/adding layer parameters, adding new layers, changing the order of layers and removing layers, all without having to rely on Google to find the names of layers or their attributes. It can then be easily exported (or copied to the clipboard) with one click as either Python Keras code or a JSON spec which can be imported into Keras. 

# Building Models

It also has some nice features for building models from scratch, like the ability to add blocks of layers that come up in models frequently. Often it's easy to forget the exact optimal order of layers for say a Convolutional block e.g. should pooling come before dropout or vice versa, and what about BatchNorm? Having preconfigured blocks of layers to choose from when building a model helps with this.

On top of that, just having an easily indexable list of layers is useful in itself. 

# Browsing Models

There is also a host of existing model architectures for a variety of machine learning tasks/datasets to explore and this is one of the most helpful features for me personally. Having an easy and centralised way to access a bunch of existing standard model architectures to take inspiration from is really useful! Rather than creating a model from scratch, you can find an existing model on the site, change say the input shape and a few of the hyperparameters and export it as working Keras code in just a few clicks. It's also great for learning about the different architectures commonly used in building models.

# Planned Features

* Integration with TensorFlow.js to have some kind of in-browser training/prototyping
* The ability to share your own model architectures
* Support for variables. Currently you can specify meta tags for a model like 'name' and 'source'. It would be cool to be able to specify variables in this same key/value fashion to allow even easier tuning.
* Better mobile support. The site is relatively responsive at the moment, but not perfect. Hopefully you're not building Keras models on your phone to begin with, but it will work if that's something you wish to do 

So, I'd love to get some feedback on this project! Is it useful? Do you like the design? I'm open to criticism, this is primarily for me to learn 

Thanks for reading!",15,65,False,self,,,,,
456,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,2,d1tmts,self.MachineLearning,Machine Learning - A Python reference list.,https://www.reddit.com/r/MachineLearning/comments/d1tmts/machine_learning_a_python_reference_list/,SquareTechAcademy,1568048407,[removed],0,1,False,self,,,,,
457,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,2,d1ts04,self.MachineLearning,Machine Learning - A Python reference list.,https://www.reddit.com/r/MachineLearning/comments/d1ts04/machine_learning_a_python_reference_list/,EddyTheDad,1568049026," Its time to learn some machine learning using Python. I have made a beginners mini series to those wanting to get started with MI. First, you will be learning about the purpose of Machine Learning and where it applies to the real world. Second, you will get a general overview of Machine Learning topics such as supervised vs unsupervised learning, model evaluation, and Machine Learning algorithms. Feedback is appreciated.

**Machine Learning for Beginners**

* **Part 1 - Machine Learning For Beginners - Basics**

[https://youtu.be/E3l\_aeGjkeI](https://youtu.be/E3l_aeGjkeI)

* **Part 2 - MI environment**

[https://youtu.be/HqyrqxyDwPU](https://youtu.be/HqyrqxyDwPU)

* **Part 3 - Python Decision Tree (Theory)**

[https://youtu.be/8isUCINSmys](https://youtu.be/8isUCINSmys)

* **Part 4 - Python Decision Tree (Coding)**

[https://youtu.be/24mxQzd3EsU](https://youtu.be/24mxQzd3EsU)

* **Part 5 - Python Decision Tree (Graphiviz)**

[https://youtu.be/aVEfKRfWjHc](https://youtu.be/aVEfKRfWjHc)

* **Part 6 - Knn(Friend Recommender)**

[https://youtu.be/LK0zgA6Mr6k](https://youtu.be/LK0zgA6Mr6k)

* **Part 7- 5-Fold Cross Validation**

[https://youtu.be/Zx5cz8pXnOM](https://youtu.be/Zx5cz8pXnOM)

**Machine Learning applications**

* **Python Face Recognition in 10 min**

[https://youtu.be/taIlzb0OUTU](https://youtu.be/taIlzb0OUTU)",0,1,False,self,,,,,
458,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,3,d1umqi,medium.com,5 ways AI is transforming Document Management Systems (DMS),https://www.reddit.com/r/MachineLearning/comments/d1umqi/5_ways_ai_is_transforming_document_management/,Aayush_vermatech,1568052687,,0,1,False,https://b.thumbs.redditmedia.com/PSCqqZoxsj2Rd1tY8WuvNM-NqI5x1v7_YNUsuh-5X0M.jpg,,,,,
459,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,3,d1uvf5,ai.googleblog.com,Assessing the Quality of Long-Form Synthesized Speech,https://www.reddit.com/r/MachineLearning/comments/d1uvf5/assessing_the_quality_of_longform_synthesized/,sjoerdapp,1568053714,,0,1,False,default,,,,,
460,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,3,d1uys4,greenlake.co.uk,Project [P] An unsupervised ML algorithm applied to the MNIST handwritten digits,https://www.reddit.com/r/MachineLearning/comments/d1uys4/project_p_an_unsupervised_ml_algorithm_applied_to/,caiksnail,1568054105,,0,1,False,default,,,,,
461,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,3,d1v0je,self.MachineLearning,what is this called?,https://www.reddit.com/r/MachineLearning/comments/d1v0je/what_is_this_called/,hoeikhwang,1568054318,[removed],0,1,False,self,,,,,
462,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,4,d1vq62,self.MachineLearning,Field extraction from PDF using TF,https://www.reddit.com/r/MachineLearning/comments/d1vq62/field_extraction_from_pdf_using_tf/,CharlesAverill20,1568057327,[removed],0,1,False,self,,,,,
463,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,4,d1vwix,self.MachineLearning,Use of AI to Predict the Future,https://www.reddit.com/r/MachineLearning/comments/d1vwix/use_of_ai_to_predict_the_future/,GXIngram,1568058065,"  

This is the result of my AI integrated applications evaluating Global Dynamics on September 1 2019.

**US Economic Future Prediction 2020 to 2021: the Chickens have Come Home to Roost (C 2019)**

Reviewing global dynamics today as pertained to the changes since our last 5 year forecast of October 2015, see [https://www.linkedin.com/pulse/what-come-2016-2020c2015-george-ingram/](https://www.linkedin.com/pulse/what-come-2016-2020c2015-george-ingram/), some important events have transpired:

US Democratic Politicians and American businessmen, and US Investment Banks became substantially more aware that the Communist Chinese Party Government global manipulation and all of its apparatus through their fully intent actions have successfully undermine the foundation of United States of America. 

Our businesses have assisted that process in their search for easy short term quarterly profits. So many of our economists, and those of the western world have blindly accepted the *Chinese Miracle* of unabated hyper-growth as something natural. Actually, it is un-natural! We Americans like to announce the good news of advanced emerging technology in our technology to our customers, and while doing so have allow the CCP (and the Chinese Military) to know where to look, steal our important ideas and technologies, and providing a road map of which American companies to beg, borrow, or steal information from to duplicate what we have spent 40 years to create. We have put the tools necessary to accomplished this thief in the hands our enemies.

**The Big Chinese Thief**

It is good that Google and others have place in hands of productive American Scientists &amp; Engineers these tools to develop new solutions around Americans latest and greatest ideas, however not blocking the flow of that access to millions of Chinese *agents and bots out-of-country* is the biggest error we have made as a technological society to-date. Further ten years ago the CCP formed a societal association in our US Colleges and around the world called **The Confusion Institute**, to guide the Chinese student enrolling in our colleges in subjugating our technologies and our way of life. That model places a **Chinese Communist Party** handler at our universities to manage the students in political thought.

Now the Chinese military has amassed at our digital boarder, 5,000,000 real individuals and virtual personalities to trade on the 360 global exchanges to thwart our efforts to defend against the on-slough of over layering and front running manipulation of in our markets in concert with pushing a communist socialist narrative in our political ideas and US election propaganda. Once the Chinese Communist were allow to join the WTO, they figured out how to change the global playing field, and did things like manipulation of Gold EFTs to marry their Currency devaluation when needed, and our investment bankers bought into the money ride for their piece of the action, much to the detriment to the everyday investment of US families, pension funds, and the Federal Reserve.

**The US Federal Reserve Bank**

This federal agency is at fault in not taken heed of the lessons learn in past economic shifts and acceleration of the frequency that it must take in adjustment, and to take the newest Artificial Intelligence Technologies that were available to them to redesign their thinking to respond to the monetary challenge they now face. An increase in interest rate is certainty a sign of that, and is the worst thing the bank could have done, and I pointed that out 4 years ago, they just forgot about it, in a New York forget about it mood. The tea leaves they were reading where no longer valid.

Now it is forced to bolster its balance sheet and print more paper, which it must purchase from the US Treasury now at a premium, while putting the US Economy on a War footing. Failing to do so, will force every man woman and child to suffer for lack action from the Federal Reserve Bank working with the Executive Branch of the US Government including our 17 intelligence agencies to determine the domain, domain, and scope of its purview to assist in leading the US Government to react to these threats.

This agency is like a *blindman in a darkroom, looking for a black cat*. Conventional Wisdom will not compete with the application of Artificial Intelligence in the form of real time autonomic predictive analytics, machine learning, and deep machine learning that could be applied to their challenge. As I pointed out 4 years ago, a different set of econometric math is required. They failed to initiate and deploy that then and four years later things have gotten worse not better. Muddling through at the Federal Reserve with not suffice in the Age of the Machines.

**War with China**

In early 2016 the RAND Corporation publish an important work i.e., **War with China: Thinking Through the Unthinkable** by Gompert, David C., Astrid Stuth Cevallos, and Cristina L. Garafola,. Santa Monica, CA: RAND Corporation, 2016. 

[https://www.rand.org/pubs/research\_reports/RR1140.html](https://www.rand.org/pubs/research_reports/RR1140.html)

I refer to this document as it was tagged by my machine readable news analytics and is still current, and unfortunately, America appears not to have thought it through as was suggested in 2016. We were too busy to focus on this, and listening to the foreign propaganda, and social media that pushed initiating the attacks on the US President, and thanks to a Deep State that had other priorities in mind to maintain their corruption and control, which included our intelligence agencies. All of this information and conclusions were draw from our contextual stores and deep learning systems.

As we say in my home state Texas, now *the Chickens have Come Home to Roost*.

Every point made in my 2016 document has transpired. The question is what is our government agencies going to do about it?

Since I know the future at least as to what is to come, I can say this. We must get behind our leaders from the President and Congress as a concerted effort and our military to counter the Chinese, Russian, Iran, and North Korea (Little China). 

Please reach out to your friends, family and next door neighbors, now and in the up coming holidays and pull together not apart, and face the tasks ahead to thwart the attack on us.

George Ingram, an American Computer Scientist

Seattle Washington 

September 3rd, 2019",0,1,False,self,,,,,
464,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,5,d1wd58,medium.com,"R.I.P. Python 2: October 16, 2000  January 1, 2020 | The end of Python 2 means they will be more vulnerable to bugs, attacks, and security issues.",https://www.reddit.com/r/MachineLearning/comments/d1wd58/rip_python_2_october_16_2000_january_1_2020_the/,Yuqing7,1568060049,,0,1,False,default,,,,,
465,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,5,d1wkbu,github.com,tensorflow/java is a new github repo by tensorflow,https://www.reddit.com/r/MachineLearning/comments/d1wkbu/tensorflowjava_is_a_new_github_repo_by_tensorflow/,sjoerdapp,1568060894,,0,1,False,default,,,,,
466,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,5,d1wmxi,self.MachineLearning,Multi-target Regression Neural Network: Trade Off,https://www.reddit.com/r/MachineLearning/comments/d1wmxi/multitarget_regression_neural_network_trade_off/,AdaptiveNarc,1568061198,[removed],0,1,False,self,,,,,
467,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,5,d1wss7,arxiv.org,[R][1904.09324] Mask-Predict: Parallel Decoding of Conditional Masked Language Models,https://www.reddit.com/r/MachineLearning/comments/d1wss7/r190409324_maskpredict_parallel_decoding_of/,bobchennan,1568061866,,1,5,False,default,,,,,
468,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,6,d1xblr,self.MachineLearning,Non ml/dl AI Python libraries,https://www.reddit.com/r/MachineLearning/comments/d1xblr/non_mldl_ai_python_libraries/,th00masml,1568064105,[removed],0,1,False,self,,,,,
469,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,6,d1xnz0,medium.com,"R.I.P. Python 2: October 16, 2000  January 1, 2020 | Survey indicates 84 percent Python developers had adopted Python 3",https://www.reddit.com/r/MachineLearning/comments/d1xnz0/rip_python_2_october_16_2000_january_1_2020/,Yuqing7,1568065537,,0,0,False,default,,,,,
470,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,7,d1yf9g,self.MachineLearning,[D] ML Platform as a Service,https://www.reddit.com/r/MachineLearning/comments/d1yf9g/d_ml_platform_as_a_service/,schrute_dataeng,1568068812,"I have read about **ML Platform as a Service** from big company like airbnb with [bighead](https://databricks.com/session/bighead-airbnbs-end-to-end-machine-learning-platform) or uber with [micheangelo](https://eng.uber.com/michelangelo/).

For those with experiences in small/medium company, how did you create your ML platform ? what does it look like ?",8,6,False,self,,,,,
471,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,8,d1yphi,self.MachineLearning,[D] Classification of Misinformation and Scaled Sentiment Analysis,https://www.reddit.com/r/MachineLearning/comments/d1yphi/d_classification_of_misinformation_and_scaled/,unsupervisedmodeler,1568070066,"I do not know if this title best captures my idea for this post but I will nonetheless continue. Recently, I have been concerned with the extent of misinformation present in the media in the form of unsubstantiated claims and conspiracies as well as deepfakes and other similar things. This, along with human biases and unconscious judgements towards certain believes or topics, creates a climate where a tremendous amount of attention and force can be maliciously and wrongly directed towards some person or other entity and there is no ""truth"" or authority to set things right or to educate people correctly. My topic for discussion here, given this opening, is what measures can be taken, employing different ML techniques, especially those for sentiment analysis, to prevent digital mobs from unjustly releasing their wrath and to undo the effects of users having been exposed to unsubstantiated and potentially dangerous false information? What would you enact if you worked at some the company of some web browser or social media company to ensure that misinformation didn't dominate conversation or proliferate further? Some topics I have in mind that I have yet to examine deeply are YouTube's algorithm's progressive recommendations of more radical content or Instagram failing to qwell networks that propogate anti-vaccination and other conspiracy rhetoric. There seems to me to be an erosion of evidenced information and a reversion to a chaotic environment where people are guided by the simplest, most tribalist claims. What are your thoughts?",1,1,False,self,,,,,
472,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,8,d1yqkf,arxiv.org,[R] No Press Diplomacy: Modeling Multi-Agent Gameplay,https://www.reddit.com/r/MachineLearning/comments/d1yqkf/r_no_press_diplomacy_modeling_multiagent_gameplay/,p_paquette,1568070193,,6,55,False,default,,,,,
473,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,8,d1yuc5,self.MachineLearning,Constraining the prediction values in xgboost,https://www.reddit.com/r/MachineLearning/comments/d1yuc5/constraining_the_prediction_values_in_xgboost/,akslayer24,1568070660,[removed],0,1,False,self,,,,,
474,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,10,d20ziz,self.MachineLearning,Question scanning books,https://www.reddit.com/r/MachineLearning/comments/d20ziz/question_scanning_books/,matttron3000,1568080788,"Hello all, 

Firmware engineer dipping their toes into the vast world of machine learning here. A friend works at our local library and was telling me about how the worst part of her job is when people put backs on the shelves themselves as they often do it wrong. So she has to scan each row going book by book and find books out of order. It's time consuming and mentally draining to do for a long period of time. I wonder if it would be possible to make an app on her phone that would read the white dewey decimal system tags on the spines of the books and figure out if a book was out of order? I've taken some sample footage and noticed a few problems:  
\- Passing the camera over rows tends to induce some blur and while I think it could reduced or unblurred, it does make it hard.  
\- Some books are too thin for the whole tag and it's impossible to read (I don't know a way to handle that)

Here's what I'm currently thinking, tell me if I'm totally off track.  
1. Process image and reduce blur and adjust to high constrast  
2. Cut out ""labels"" on the books and create small B&amp;W images with the source location of where they came from.  
3. Rotate the label as needed (sometimes they are at a 90 degree angle)  
3. OCR the label and categorize it into the dewey

Is this feasible with some degree of accuracy? Ultimately, I'd just want to highlight the book that's out of order in red. I don't need to do anything more complicated.",0,1,False,self,,,,,
475,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,11,d2105w,self.MachineLearning,[D] Worth Attending Conference Workshops?,https://www.reddit.com/r/MachineLearning/comments/d2105w/d_worth_attending_conference_workshops/,AnonMLstudent,1568080870,"I am a student that will be attending a conference for the first time, specifically EMNLP 2019. Currently debating between just going for the main conference or a couple days earlier to also attend the workshops. Not sure if it's worth the extra costs though, the scholarship application only covers the costs for the main conference.",6,5,False,self,,,,,
476,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,13,d22s77,brsoftech.com,A Detailed Comparison of Machine Learning vs Deep Learning,https://www.reddit.com/r/MachineLearning/comments/d22s77/a_detailed_comparison_of_machine_learning_vs_deep/,chanchal_rathor,1568090532,,0,1,False,default,,,,,
477,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,14,d22ycr,self.MachineLearning,[D] Scanning books,https://www.reddit.com/r/MachineLearning/comments/d22ycr/d_scanning_books/,matttron3000,1568091625," Hello all,

Firmware engineer dipping their toes into the vast world of machine learning here. A friend works at our local library and was telling me about how the worst part of her job is when people put backs on the shelves themselves as they often do it wrong. So she has to scan each row going book by book and find books out of order. It's time consuming and mentally draining to do for a long period of time. I wonder if it would be possible to make an app on her phone that would read the white dewey decimal system tags on the spines of the books and figure out if a book was out of order? I've taken some sample footage and noticed a few problems:  
\- Passing the camera over rows tends to induce some blur and while I think it could reduced or unblurred, it does make it hard.  
\- Some books are too thin for the whole tag and it's impossible to read (I don't know a way to handle that)

Here's what I'm currently thinking, tell me if I'm totally off track.

1. Process image and reduce blur and adjust to high constrast
2. Cut out ""labels"" on the books and create small B&amp;W images with the source location of where they came from.
3. Rotate the label as needed (sometimes they are at a 90 degree angle)
4. OCR the label and categorize it into the dewey

Is this feasible with some degree of accuracy? Ultimately, I'd just want to highlight the book that's out of order in red. I don't need to do anything more complicated.",13,40,False,self,,,,,
478,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,14,d2348n,self.MachineLearning,Machine learning to extract Regex?,https://www.reddit.com/r/MachineLearning/comments/d2348n/machine_learning_to_extract_regex/,imohd23,1568092679,[removed],0,1,False,self,,,,,
479,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,14,d23752,self.MachineLearning,What will recruitment be like in the next year?,https://www.reddit.com/r/MachineLearning/comments/d23752/what_will_recruitment_be_like_in_the_next_year/,getengati,1568093208,[removed],0,1,False,self,,,,,
480,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,14,d23gsi,self.MachineLearning,[D] Tips on improving random forest predictive accuracy when # of features is really low?,https://www.reddit.com/r/MachineLearning/comments/d23gsi/d_tips_on_improving_random_forest_predictive/,truryce,1568095010,"Working on a random forest predictive model with a continuous response variable and two continuous features. Normally when I do RF projects I use some sort of feature selection method to choose which features to use. Then I fit the RF model onto those features. Then to test accuracy / related metrics I use cross validation, confusion matrices, etc.

However in this case I only have two given features. I don't want to just literally run a RF model on those two features as my whole entire project. I'm thinking gradient boosting is what I should learn? Also I think I should play around with the number of estimators and depth of the RF. I'm using sklearn in Python if that helps.

Any other suggestions? Obviously this type of problem/challenge is an unexplored area for me, so looking for best practices on how to add to my data science toolkit. Thanks!",5,1,False,self,,,,,
481,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,15,d23ok7,self.MachineLearning,[D] Why is the L2 distance used for reconstruction loss in this VAE?,https://www.reddit.com/r/MachineLearning/comments/d23ok7/d_why_is_the_l2_distance_used_for_reconstruction/,samuelknoche,1568096508,"I was looking at the [world models](https://arxiv.org/pdf/1803.10122.pdf) paper and saw that they use the L2 distance as reconstruction loss in their variational auto-encoder. All VAEs I've seen so far have used the cross entropy loss, so why L2?",40,11,False,self,,,,,
482,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,15,d23ow0,self.MachineLearning,[R] Video Analysis: Attention Is All You Need,https://www.reddit.com/r/MachineLearning/comments/d23ow0/r_video_analysis_attention_is_all_you_need/,ykilcher,1568096575,[removed],0,1,False,self,,,,,
483,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,15,d23qm0,self.MachineLearning,[D] Is transfer learning still worth entering into as a researcher?,https://www.reddit.com/r/MachineLearning/comments/d23qm0/d_is_transfer_learning_still_worth_entering_into/,Minimum_Zucchini,1568096944,"I'm more interested in the theory behind transfer learning, so is the field dying down? Are a lot of the major problems solved? Just curios what others think here.",30,44,False,self,,,,,
484,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,15,d23tba,medium.com,Creating Digital Revolution with Applications of Blockchain and Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/d23tba/creating_digital_revolution_with_applications_of/,Anubhav-Singh,1568097510,,0,1,False,https://b.thumbs.redditmedia.com/4V2wnbQHiWbpmwDxD8AifGVzx82SelIEbzbHq1qF20A.jpg,,,,,
485,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,15,d23ynp,maycncdongphuong.com,Nn u t nhng loi my no khi m xng mc,https://www.reddit.com/r/MachineLearning/comments/d23ynp/nn_u_t_nhng_loi_my_no_khi_m_xng_mc/,lamphonghat,1568098592,,0,1,False,default,,,,,
486,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,16,d240oi,self.MachineLearning,Techniques/Features to quantify journalism quality,https://www.reddit.com/r/MachineLearning/comments/d240oi/techniquesfeatures_to_quantify_journalism_quality/,yautslil,1568098996," Hi subredit, I am a researcher currently working on topic of News Analysis. I am using Computational techniques to identify/rate quality of journalism. I have some idea about how to identify bias and sensationalism in headlines but don't have much idea about how to quantify what is good journalism and what is bad. Would be grateful if someone can help me out :)",0,1,False,self,,,,,
487,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,16,d242if,solaceinfotech.com,Data Science vs Machine Learning : Know the difference,https://www.reddit.com/r/MachineLearning/comments/d242if/data_science_vs_machine_learning_know_the/,SolaceInfotech,1568099370,,0,1,False,https://b.thumbs.redditmedia.com/Qz93nvQm3iOpCRSpngAYfzkDFhEpBwMt4c9EXysE2Sc.jpg,,,,,
488,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,16,d244gb,self.MachineLearning,Machine Learning - Services | Webtunix,https://www.reddit.com/r/MachineLearning/comments/d244gb/machine_learning_services_webtunix/,OliviaWillson,1568099766,[removed],0,1,False,self,,,,,
489,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,16,d24cq5,isoeh.com,Artificial Intelligence &amp; Machine Learning  What's the difference between them?,https://www.reddit.com/r/MachineLearning/comments/d24cq5/artificial_intelligence_machine_learning_whats/,alishadirectory,1568101504,,0,1,False,default,,,,,
490,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,16,d24ggv,self.MachineLearning,[D] AI for Autochess games (Team Fight Tactics),https://www.reddit.com/r/MachineLearning/comments/d24ggv/d_ai_for_autochess_games_team_fight_tactics/,MrLemmingv2,1568102349,"Dear all,

sorry in advance  if this is the wrong subreddit for this kind of question.

So with the recent rise of autobattlers, I wanted to create a basic AI for TeamFightTactics as a side-project.

For everyone that does not know the concept of these, I'll try to summarize it quickly:

You are randomly offered champions from a fixed pool that you can buy, you can place a limited number of champions on the board (and keep some on the bench) and then they fight against the team of other players. Their strength is defined by synergies, their level and the items you obtain throughout the game.

Steps I would take:

1. Data retrieval: Since we cannot access the raw data, i.e. which player has which champ, we have to extract this data from screenshots of their boards. My first intuition would be to use object detection such as YOLO, however since charachters/items always look the same, there could be an easier solution.
2. Strategy: This is  the harder part - as we cannot play games against ourselves I feel like deep learning cannot be applied here, any suggestions would be highly appreciated.

Thanks a lot for your time!",9,5,False,self,,,,,
491,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,17,d24kjv,self.MachineLearning,[D] Best approaches for semi-supervised learning and learning with low quality labels.,https://www.reddit.com/r/MachineLearning/comments/d24kjv/d_best_approaches_for_semisupervised_learning_and/,Atom_101,1568103247,"I am starting work on an area where data is abundant but, labelling is almost impossible. The only viable labelling approach I can employ is to use manually defined thresholds to generate labels algorithmically. I think I will have to look into techniques that try to achieve superhuman accuracy, since my model should outperform the labelling algorithm. Anyone have any idea of what to do?

I have looked into pseudo-labelling but I am not sure how useful it will be in this context. It deals with the case of small amount of well labelled data and large amount of unlabelled data. My case is large amount of badly labelled data.",12,3,False,self,,,,,
492,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,17,d24pi1,arxiv.org,[Research] Reward Tampering Problems and Solutions in Reinforcement Learning: A Causal Influence Diagram Perspective,https://www.reddit.com/r/MachineLearning/comments/d24pi1/research_reward_tampering_problems_and_solutions/,hardmaru,1568104355,,1,2,False,default,,,,,
493,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,17,d24uvn,self.MachineLearning,[P] Twitter bot using a GPT2 model trained on Trump's tweets,https://www.reddit.com/r/MachineLearning/comments/d24uvn/p_twitter_bot_using_a_gpt2_model_trained_on/,osirisguitar,1568105569,"I fintuned a pretrained GPT2 model on Trump's entire twitter archive. Hilarity ensues:

[https://twitter.com/botustrump](https://twitter.com/botustrump)

A colleague commented that it is very on point when it comes to language style, but briefer than the real Trump who often writes longwinded rants...",40,123,False,self,,,,,
494,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,19,d25kme,deepmind.com, Episode 7: Towards the future,https://www.reddit.com/r/MachineLearning/comments/d25kme/episode_7_towards_the_future/,sjoerdapp,1568110756,,0,1,False,default,,,,,
495,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,19,d25nwx,self.MachineLearning,Document similarity with bert,https://www.reddit.com/r/MachineLearning/comments/d25nwx/document_similarity_with_bert/,benyoucef021,1568111396,[removed],0,1,False,self,,,,,
496,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,19,d25rbu,data-flair.training,7 Top Programming Languages that are Widely Used in AI/Machine Learning Projects,https://www.reddit.com/r/MachineLearning/comments/d25rbu/7_top_programming_languages_that_are_widely_used/,AnujG23,1568112028,,0,1,False,default,,,,,
497,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,20,d268un,self.MachineLearning,DIY number plate detector using attention OCR,https://www.reddit.com/r/MachineLearning/comments/d268un/diy_number_plate_detector_using_attention_ocr/,manneshiva,1568115077,[removed],0,1,False,https://a.thumbs.redditmedia.com/cii-8khLoJ4ZkeoPo8BNaQrDC1R6RpheBXr4-aZk-58.jpg,,,,,
498,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,20,d26a33,zerowithdot.com,Performance of numpy and pandas,https://www.reddit.com/r/MachineLearning/comments/d26a33/performance_of_numpy_and_pandas/,_quanttrader_,1568115281,,0,1,False,default,,,,,
499,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,20,d26gwz,i.redd.it,Support Vector Machines Tutorial  Learn to implement SVM in Python,https://www.reddit.com/r/MachineLearning/comments/d26gwz/support_vector_machines_tutorial_learn_to/,Aakashdata,1568116441,,0,1,False,https://b.thumbs.redditmedia.com/uowBglXA6HZ6VorwkqIOpwhmOLjxu4Y8loULz_Uilic.jpg,,,,,
500,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,21,d26mq3,medium.com,Why do we use word embeddings in NLP?,https://www.reddit.com/r/MachineLearning/comments/d26mq3/why_do_we_use_word_embeddings_in_nlp/,data_nat,1568117348,,0,1,False,default,,,,,
501,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,21,d26o6z,self.MachineLearning,[P] Best approaches for Deep Learning based OCR,https://www.reddit.com/r/MachineLearning/comments/d26o6z/p_best_approaches_for_deep_learning_based_ocr/,manneshiva,1568117565,"[https://nanonets.com/blog/attention-ocr-for-text-recogntion](https://nanonets.com/blog/attention-ocr-for-text-recogntion/?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=atocr&amp;utm_content=ml) How attention mechanisms, spatial transformer networks are applied for text recognition task.

https://i.redd.it/t6ilwvvicrl31.gif",1,5,False,https://b.thumbs.redditmedia.com/O4v61we_l1Og0rM_0zG6hnqGVM6ysw_oxRs5G6Czdao.jpg,,,,,
502,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,21,d26qgr,self.MachineLearning,[D] Version Control for Data Science  Tracking Machine Learning Models and Datasets with DVC,https://www.reddit.com/r/MachineLearning/comments/d26qgr/d_version_control_for_data_science_tracking/,thumbsdrivesmecrazy,1568117909,"Unlike usual software dev projects, ML projects have additional huge files like datasets, trained models, label-encodings etc. which can easily go to the size of a few GBs and therefore cannot be tracked using Git.

The article explains how DVC (Data Version Control) tool helps us to version large data files, similar to how we version control source code files using Git and how we can track all the artifacts with DVC  which will make the workflow a lot more productive, as we dont have to manually keep track of what we did to achieve the state, and also we dont lose time in the processing of data and building models to reproduce the same state: [Version Control for Data Science  Tracking Machine Learning Models and Datasets](https://medium.com/@jnvipul/version-control-for-data-science-tracking-your-machine-learning-models-and-datasets-aaa61f20bb45)",7,16,False,self,,,,,
503,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,21,d26suo,fanatical.com,[R] Fanatical Machine Learning Books Bundle,https://www.reddit.com/r/MachineLearning/comments/d26suo/r_fanatical_machine_learning_books_bundle/,uplay_is_the_best,1568118255,,0,1,False,default,,,,,
504,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,21,d274b0,self.MachineLearning,Looking for NN architectual books/articles,https://www.reddit.com/r/MachineLearning/comments/d274b0/looking_for_nn_architectual_booksarticles/,johnnydues,1568119998,[removed],0,1,False,self,,,,,
505,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,21,d275sj,self.MachineLearning,Wireless Video Camera for ML?,https://www.reddit.com/r/MachineLearning/comments/d275sj/wireless_video_camera_for_ml/,etotheipi_,1568120218,"Hi, I'm looking to do a simple home project involving object identification.  I want to put a video camera on a tree in my front yard and try to automatically identify what triggered motion captures in my driveway.  It's a really simple project, mostly to get my feet wet.

The problem is, I have no idea how to search for cameras that allow me to pull the video from them to my computer (Windows or Linux).  It doesn't have to be exactly real-time, but I'd like to not have to physically go do something with the camera to get the video (some of them mention SD card capture -- which I would do as a last resort).

So I need a camera that:

\- Wireless/battery-powered (it'll be in a tree)  
\- Wifi-connected to talk to...something inside my network  
\- Video captures are accessible on my Linux or Windows boxes (I don't mind doing some hackery with API keys, downloading from S3 buckets, etc, if necessary)",0,1,False,self,,,,,
506,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,22,d27ate,self.MachineLearning,Global Welding Fume Extraction Equipment Market Report 2019,https://www.reddit.com/r/MachineLearning/comments/d27ate/global_welding_fume_extraction_equipment_market/,jadhavni3,1568120902,[removed],1,1,False,self,,,,,
507,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,22,d27e0x,medium.com,Generative AI: A Key to Machine Intelligence?,https://www.reddit.com/r/MachineLearning/comments/d27e0x/generative_ai_a_key_to_machine_intelligence/,rachnogstyle,1568121368,,0,1,False,default,,,,,
508,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,22,d27izf,self.MachineLearning,Zinc Chemicals Market Future Forecast 20192023,https://www.reddit.com/r/MachineLearning/comments/d27izf/zinc_chemicals_market_future_forecast_20192023/,jadhavni3,1568122044,[removed],1,1,False,self,,,,,
509,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,22,d27mge,self.MachineLearning,[P] In search of the perfect Video Annotation Tool,https://www.reddit.com/r/MachineLearning/comments/d27mge/p_in_search_of_the_perfect_video_annotation_tool/,kramerkee,1568122529,"I have tried a bunch of these types of tools, but can never find one that fits all my criteria. The tool should be:

* Open source
* Specifically made for video annotation
* GUI-based, scrolling through frames and box-annotating objects with ease
* Data can be exported to tensorflow and used to train neural network to recognize objects in similar videos

Does anyone have a video annotation tool that fulfills all these requirements?

&amp;#x200B;

I am trying to make a program where one can input a video, and out comes a list of frames where different pre-made objects were detected.",5,6,False,self,,,,,
510,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,22,d27qt6,self.MachineLearning,Global Water-based Resins Market Report 2019,https://www.reddit.com/r/MachineLearning/comments/d27qt6/global_waterbased_resins_market_report_2019/,jadhavni3,1568123161,[removed],1,1,False,self,,,,,
511,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,22,d27szl,i.redd.it,Make the Internet Your AI University and Be a Changemaker,https://www.reddit.com/r/MachineLearning/comments/d27szl/make_the_internet_your_ai_university_and_be_a/,Lordobba,1568123465,,0,1,False,https://b.thumbs.redditmedia.com/Y6qWv814gyseD17jSLQJdjD0Tz-v84XV0yD0PqPhBUw.jpg,,,,,
512,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,22,d27t2j,habr.com,Important Things to Know About Tensorflow 2.0,https://www.reddit.com/r/MachineLearning/comments/d27t2j/important_things_to_know_about_tensorflow_20/,atomlib_com,1568123475,,0,1,False,https://a.thumbs.redditmedia.com/8JX3XkLBUNa9Z0PUZQMpOknDNRJALV2c2gWp0Vizp00.jpg,,,,,
513,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,22,d27vfd,developer.amazon.com,Summaries of all 16 Alexa-related Interspeech papers (with links),https://www.reddit.com/r/MachineLearning/comments/d27vfd/summaries_of_all_16_alexarelated_interspeech/,georgecarlyle76,1568123792,,0,1,False,default,,,,,
514,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,23,d27xc7,self.MachineLearning,Using neural network to create images from rotation and distance.,https://www.reddit.com/r/MachineLearning/comments/d27xc7/using_neural_network_to_create_images_from/,Envenger,1568124049,[removed],0,1,False,https://b.thumbs.redditmedia.com/5ydviKD92GrMHDerq_Hpw-Hz2GNsyT2fNUsTvYzLoBI.jpg,,,,,
515,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,23,d27xjq,medium.com,Make the Internet Your AI University and Be a Changemaker.,https://www.reddit.com/r/MachineLearning/comments/d27xjq/make_the_internet_your_ai_university_and_be_a/,Lordobba,1568124079,,0,1,False,default,,,,,
516,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,23,d286fp,self.MachineLearning,[P] SpeechBrain: A PyTorch-based Speech Toolkit.,https://www.reddit.com/r/MachineLearning/comments/d286fp/p_speechbrain_a_pytorchbased_speech_toolkit/,TParcollet,1568125236,"Hi there!

We are happy to announce the SpeechBrain project, that aims to develop an open-source and all-in-one toolkit based on PyTorch. The goal is to develop a *single*, *flexible*, and *user-friendly* toolkit that can be used to easily develop state-of-the-art speech systems for speech recognition (both end-to-end and HMM-DNN), speaker recognition, speech separation, multi-microphone signal processing (e.g, beamforming), self-supervised learning, and many others.

The project will be led by Mila (Montral) and is sponsored by Samsung, Nvidia, and Dolby.

SpeechBrain will also benefit from the collaboration and expertise of other partners such as Avignon Universit, Facebook/PyTorch, IBM Research, and Fluent.ai.

Check out [https://speechbrain.github.io](https://speechbrain.github.io)!

(Also, we are looking for interns ;) check the website!)

Reddit is an awesome place to discuss, so please, let us know what you would like to see implemented for the speech community! This is a great opportunity to start building an user-friendly and AIO toolkit :D !",51,220,False,self,,,,,
517,MachineLearning,t5_2r3gv,2019-9-10,2019,9,10,23,d287ra,self.MachineLearning,Micro-Expressions,https://www.reddit.com/r/MachineLearning/comments/d287ra/microexpressions/,Dubeyjii,1568125401,[removed],0,1,False,self,,,,,
518,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,0,d28xyh,self.MachineLearning,[D] Advice on domain adaption / transfer?,https://www.reddit.com/r/MachineLearning/comments/d28xyh/d_advice_on_domain_adaption_transfer/,gecko39,1568128481,"I am training a 2d image landmark estimation network where I have lots of synthetic data, but limited realistic labelled data. I can gather lots of un-labelled real data, but labelling is difficult. I have come across a few techniques out there like [DANN](http://sites.skoltech.ru/compvision/projects/grl/) As a non-expert, I'm not sure where exactly to start. Are there any common techniques that are worth trying first? Thanks!",1,1,False,self,,,,,
519,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,0,d28z2u,self.MachineLearning,[Discussion] Personal framework preference.,https://www.reddit.com/r/MachineLearning/comments/d28z2u/discussion_personal_framework_preference/,PanTheRiceMan,1568128620,"Hello everyone. I started a job in ML half a year ago and found myself to like pytorch the most. I started with 7 years in python beforehand and suppose that influenced my preference. The documentation is great, the functionality clean and simple. I just like the full control over everything and neat features like auto registration of layers in a Module. I also very much love the style of cuda detection during runtime, just pleasant to use. What are your favorites and why ?",5,0,False,self,,,,,
520,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,0,d2974j,talkrl.com,ACM Fellow Michael Littman on TalkRL: Reinforcement Learning Interviews,https://www.reddit.com/r/MachineLearning/comments/d2974j/acm_fellow_michael_littman_on_talkrl/,djangoblaster2,1568129524,,0,1,False,default,,,,,
521,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,0,d298pv,ai.googleblog.com,Recursive Sketches for Modular Deep Learning,https://www.reddit.com/r/MachineLearning/comments/d298pv/recursive_sketches_for_modular_deep_learning/,sjoerdapp,1568129688,,0,1,False,default,,,,,
522,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,0,d29byz,self.MachineLearning,[R] The funniest game against DeepMind's AlphaStar thus far,https://www.reddit.com/r/MachineLearning/comments/d29byz/r_the_funniest_game_against_deepminds_alphastar/,HolidayGuidance,1568130055,"Human players are starting to get creative in playing against AlphaStar. 

Additional note, AlphaStar is making some very basic mistakes with its unit management:

[https://www.youtube.com/watch?v=Di-yRj6TIK8&amp;feature=youtu.be&amp;t=1525](https://www.youtube.com/watch?v=Di-yRj6TIK8&amp;feature=youtu.be&amp;t=1525)

I suggest watching the whole game.",24,16,False,self,,,,,
523,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,0,d29f8b,self.MachineLearning,CCTV FOOTAGE - COUNTING HOW MANY TIMES A LOADER DUMPS SAND/GRAVEL UNTO A TRUCK,https://www.reddit.com/r/MachineLearning/comments/d29f8b/cctv_footage_counting_how_many_times_a_loader/,jdgg103,1568130414,[removed],0,1,False,self,,,,,
524,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,1,d29nnm,self.MachineLearning,Msc in Machine Learning - or work my way through Industry,https://www.reddit.com/r/MachineLearning/comments/d29nnm/msc_in_machine_learning_or_work_my_way_through/,unknownrebelpanda,1568131332,[removed],0,1,False,self,,,,,
525,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,1,d29u8b,self.MachineLearning,How can I get in a group to learn/make models together,https://www.reddit.com/r/MachineLearning/comments/d29u8b/how_can_i_get_in_a_group_to_learnmake_models/,mikeynoonja,1568132028,[removed],0,1,False,self,,,,,
526,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,1,d2a32t,self.MachineLearning,"[P] Conditional Density Estimation Python Package and Large Benchmark with Neural Networks (MDN, KMN, Normalizing Flow) and Non-/Semi-parametric estimators",https://www.reddit.com/r/MachineLearning/comments/d2a32t/p_conditional_density_estimation_python_package/,whiletrue2,1568132954,,0,1,False,default,,,,,
527,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,1,d2a69v,medium.com,Chinese Gaming Giant NetEase Leverages AI to Create 3D Game Characters from Selfies | This method has already been used over one million times by Chinese gamers.,https://www.reddit.com/r/MachineLearning/comments/d2a69v/chinese_gaming_giant_netease_leverages_ai_to/,Yuqing7,1568133294,,0,1,False,https://b.thumbs.redditmedia.com/rQ0lEgdSnY-9jB4oZveIjCac3OkNgNMfadWT5cnN-oU.jpg,,,,,
528,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,2,d2b3z9,self.MachineLearning,Neural Network Learns To Play Club Penguin with Genetic Evolution!,https://www.reddit.com/r/MachineLearning/comments/d2b3z9/neural_network_learns_to_play_club_penguin_with/,mattberrycrunch,1568136847,[removed],0,1,False,self,,,,,
529,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,2,d2bazf,youtu.be,Neural Network Learns To Play Club Penguin with Genetic Evolution!,https://www.reddit.com/r/MachineLearning/comments/d2bazf/neural_network_learns_to_play_club_penguin_with/,mattberrycrunch,1568137599,,0,1,False,https://a.thumbs.redditmedia.com/6jj7fB7jbE1zOK5zHbWzpbWrN_vsnyc32YOUwYFcWW4.jpg,,,,,
530,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,2,d2bd4i,self.MachineLearning,Best way to initialise without knowing the (final) network architecture,https://www.reddit.com/r/MachineLearning/comments/d2bd4i/best_way_to_initialise_without_knowing_the_final/,matigekunst,1568137828,[removed],0,1,False,self,,,,,
531,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,3,d2bu1t,self.MachineLearning,Need Literature on how to handle data sets containing many dummy variables,https://www.reddit.com/r/MachineLearning/comments/d2bu1t/need_literature_on_how_to_handle_data_sets/,milanm23,1568139667,[removed],0,1,False,self,,,,,
532,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,3,d2buav,self.MachineLearning,Companies asking for deep learning experience,https://www.reddit.com/r/MachineLearning/comments/d2buav/companies_asking_for_deep_learning_experience/,min2bro,1568139696,[removed],0,1,False,self,,,,,
533,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,3,d2c1rg,towardsdatascience.com,Unsupervised Learning to Market Behavior Forecasting,https://www.reddit.com/r/MachineLearning/comments/d2c1rg/unsupervised_learning_to_market_behavior/,lamres,1568140487,,0,1,False,https://b.thumbs.redditmedia.com/62DzrF4riww_wh-d_YUKipYC36pGF3KZoqH_h0MZEoY.jpg,,,,,
534,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,3,d2cfdi,roasted.space,Fighting Hackers with Machine Learning. Code-Snippet: Network Intrusion Detection using High Dimensional Machine Learning.,https://www.reddit.com/r/MachineLearning/comments/d2cfdi/fighting_hackers_with_machine_learning/,at-roasted-space,1568141908,,0,1,False,default,,,,,
535,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,4,d2ckkm,youtube.com,Alex Chiu's machine and rings help me recover from seizures epilepsy,https://www.reddit.com/r/MachineLearning/comments/d2ckkm/alex_chius_machine_and_rings_help_me_recover_from/,manhattanyx2,1568142423,,0,1,False,https://b.thumbs.redditmedia.com/NH4kp16CWVlXvOVu1SeUbI-49VSpJCA1_AdgTd9gkZk.jpg,,,,,
536,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,4,d2d5qv,medium.com,Residual Neural Networks for Radio Wave Classification,https://www.reddit.com/r/MachineLearning/comments/d2d5qv/residual_neural_networks_for_radio_wave/,lukerbs,1568144609,,1,1,False,default,,,,,
537,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,4,d2d5zo,self.MachineLearning,[D] Dynamic resolution pixel counter,https://www.reddit.com/r/MachineLearning/comments/d2d5zo/d_dynamic_resolution_pixel_counter/,SeraphicRadiance,1568144638,"Are there any neural nets trained to calculate the native resolution of a render, pre upscale?

 I'm asking specifically because YouTube channels like Digital Foundry are getting stressed out and spending an inordinate amount of time finding the range for dynamic resolutions for modern games, and I was wondering if there were any tools that could be utilized to automate the process. 

It would be a great shame if anyone on their team quit due to the stress and tedium that has resulted from dynamic resolution scaling, as they provide invaluable technical information in the field of real time rendering.",1,7,False,self,,,,,
538,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,5,d2dhcz,self.MachineLearning,Install cleverhans using conda install ?,https://www.reddit.com/r/MachineLearning/comments/d2dhcz/install_cleverhans_using_conda_install/,2141rika,1568145803,[removed],0,1,False,self,,,,,
539,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,5,d2e88v,self.MachineLearning,NBA prediction algorithm data preparation,https://www.reddit.com/r/MachineLearning/comments/d2e88v/nba_prediction_algorithm_data_preparation/,gbadbunny,1568148565,[removed],0,1,False,self,,,,,
540,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,6,d2ev6f,self.MachineLearning,Recognizing order of letters,https://www.reddit.com/r/MachineLearning/comments/d2ev6f/recognizing_order_of_letters/,stieterd,1568150979,[removed],0,1,False,self,,,,,
541,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,6,d2f43v,self.MachineLearning,Suggestions for Metric to Compare Multi-Class Classification Models?,https://www.reddit.com/r/MachineLearning/comments/d2f43v/suggestions_for_metric_to_compare_multiclass/,Scatterbrain191,1568151937,"Hello, I am running a data science case study for my job training. I have before me a dependent variable that I have broken into four factor levels: none, mild, moderate, severe. I am using all continuous variables to predict the factor levels of this dependent variable. The distribution of the dependent variable seems pretty balanced to me (none = 2,246 observations, mild = 3,585 observations, moderate = 2,831 observations, severe = 2,599 observations). 

Using my limited knowledge I have started building a set of models (I'm looking to get the best predictive strength - what does that mean? I don't know! hence the question!). These models include a set of ordinal regressions, random forests, and xgboosts. My baseline model for comparison will probably be a naive Bayes model. 

It doesn't seem like there are clear and useful methods for evaluating these multi-class classification models, unlike the binary classification ones. Maybe I just don't know where to look. Any suggestions?",0,1,False,self,,,,,
542,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,6,d2f4e0,medium.com,AI Chip Duel: A13 Bionic VS Kirin 990 5G,https://www.reddit.com/r/MachineLearning/comments/d2f4e0/ai_chip_duel_a13_bionic_vs_kirin_990_5g/,Yuqing7,1568151974,,0,1,False,https://b.thumbs.redditmedia.com/DxCHcYt47dJpCEWrNaDbwhXTzkC8ytCx45WWJgv97Ao.jpg,,,,,
543,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,7,d2fo2b,self.MachineLearning,Article claims to have 100% accuracy for heart defect detection,https://www.reddit.com/r/MachineLearning/comments/d2fo2b/article_claims_to_have_100_accuracy_for_heart/,pwatman1234455,1568154090,[removed],0,1,False,self,,,,,
544,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,8,d2gvaj,self.MachineLearning,Help needed on a Deep Reinforcement Model controlling a Traffic Situation Between Cars(Science Fair)[Project],https://www.reddit.com/r/MachineLearning/comments/d2gvaj/help_needed_on_a_deep_reinforcement_model/,shazam8253,1568159055,"I wanted to use a Reinforcement Learning Model in order to simulate traffic situations. The agent would learn how to control a network of cars stuck in deep traffic in order to increase efficiency, and reduce the amount of harmful gas released into the air.  I want to be able to make a 2d environment that can simulate the potential that Reinforcement Learning has in traffic situations. If I finish this part, and if this next part is feasible, I will do this part. 

Extra Part:     After making this model, I wanted to make an app, or an extension of google maps, that would be controlled by the agent in real traffic situations. The agent would advise the network of drivers to go at a certain speed and time to increase efficiency, and potentially reduce the amount of accidents made in traffic situations.

Question:  How would I create a virtual 2d environment where I could control a car or multiple cars with artificial intelligence. Is there a course that I could take, or a method that should be followed(like using unity machine learning)?",1,0,False,self,,,,,
545,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,9,d2hgmm,self.MachineLearning,Is this ebook bundle from fanatical/packt any good for beginners?,https://www.reddit.com/r/MachineLearning/comments/d2hgmm/is_this_ebook_bundle_from_fanaticalpackt_any_good/,IrishWilly,1568161640,[removed],0,1,False,self,,,,,
546,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,10,d2i4hb,youtube.com,[D] Most Research in Deep Learning is a Total Waste of Time - Jeremy Howard,https://www.reddit.com/r/MachineLearning/comments/d2i4hb/d_most_research_in_deep_learning_is_a_total_waste/,ShittingTits,1568164528,,0,1,False,https://b.thumbs.redditmedia.com/TVSsWnxcKzmCZluJ2_zNhbD07vZeC7mYh9aLO5sdkpU.jpg,,,,,
547,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,10,d2i9pn,arxiv.org,[R] On Extractive and Abstractive Neural Document Summarization with Transformer Language Models,https://www.reddit.com/r/MachineLearning/comments/d2i9pn/r_on_extractive_and_abstractive_neural_document/,milaworld,1568165161,,3,31,False,default,,,,,
548,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,11,d2iv9w,arxiv.org,[R] DeepPrivacy: A Generative Adversarial Network for Face Anonymization,https://www.reddit.com/r/MachineLearning/comments/d2iv9w/r_deepprivacy_a_generative_adversarial_network/,hardmaru,1568167770,,23,131,False,default,,,,,
549,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,11,d2j38q,self.MachineLearning,Ever wanted to know exactly how a neural network works?,https://www.reddit.com/r/MachineLearning/comments/d2j38q/ever_wanted_to_know_exactly_how_a_neural_network/,simple_ml,1568168741,[removed],0,1,False,self,,,,,
550,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,11,d2j907,elink.io,Transforming CRM Operations With Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/d2j907/transforming_crm_operations_with_artificial/,Aayush_vermatech,1568169453,,0,1,False,https://b.thumbs.redditmedia.com/lbyrs6bBVHH02sYBd4m7cwohBcK-oc0zENsPb5zyYwQ.jpg,,,,,
551,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,12,d2jmne,zerosuniverse.com,Best Artificial Intelligence Books for Beginners in 2019,https://www.reddit.com/r/MachineLearning/comments/d2jmne/best_artificial_intelligence_books_for_beginners/,avinashanshu,1568171214,,0,1,False,default,,,,,
552,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,12,d2jpwm,self.MachineLearning,[P] Simplified neural network in raw python,https://www.reddit.com/r/MachineLearning/comments/d2jpwm/p_simplified_neural_network_in_raw_python/,simple_ml,1568171648," 

See my repository below, it's just plain python that will work in any 3.x version as far as I know, and requires no extra installs (uses only the base python libraries, all you need is python installed).

It's a simple feed forward network, but hopefully it can shed light on how the forward and backward pass works.

[https://github.com/sean-gribben/pynet](https://github.com/sean-gribben/pynet)",0,0,False,self,,,,,
553,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,12,d2k7dq,self.MachineLearning,Biology-related Machine Learning High School Projects,https://www.reddit.com/r/MachineLearning/comments/d2k7dq/biologyrelated_machine_learning_high_school/,hsml12345,1568174052,[removed],0,1,False,self,,,,,
554,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,12,d2k9ns,self.MachineLearning,Loss function,https://www.reddit.com/r/MachineLearning/comments/d2k9ns/loss_function/,RakshithV,1568174399,[removed],0,1,False,self,,,,,
555,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,13,d2kjao,self.MachineLearning,What Are The Alternatives To Google Bigquery,https://www.reddit.com/r/MachineLearning/comments/d2kjao/what_are_the_alternatives_to_google_bigquery/,Countants123,1568175793,[removed],0,1,False,self,,,,,
556,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,14,d2l70d,self.MachineLearning,[D] How much do CS/ML assistant professors get paid?,https://www.reddit.com/r/MachineLearning/comments/d2l70d/d_how_much_do_csml_assistant_professors_get_paid/,20150831,1568179422,"While reading the other thread ([https://www.reddit.com/r/MachineLearning/comments/d1ooem/d\_when\_the\_ai\_professor\_leaves\_students\_suffer/](https://www.reddit.com/r/MachineLearning/comments/d1ooem/d_when_the_ai_professor_leaves_students_suffer/)), someone linked to a H1B database of professor salaries which showed assistant professors are getting paid \~120K max (unless in the business school).

Is this really true? I am very surprised since these candidates could easily make 300K-500K as a research scientist at the big tech companies. Granted, there is still old school prestige attached to being a professor, but it seems like they are leaving a lot of money on the table.",37,8,False,self,,,,,
557,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,14,d2ldle,self.MachineLearning,PCA SVDsome doubt,https://www.reddit.com/r/MachineLearning/comments/d2ldle/pca_svdsome_doubt/,HistoricalTouch0,1568180478,[removed],0,1,False,self,,,,,
558,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,14,d2leh4,self.MachineLearning,Introducing a digital personal assistant,https://www.reddit.com/r/MachineLearning/comments/d2leh4/introducing_a_digital_personal_assistant/,getengati,1568180617,[removed],0,1,False,self,,,,,
559,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,15,d2lkms,self.MachineLearning,"Employed as Data Scientist, into Research",https://www.reddit.com/r/MachineLearning/comments/d2lkms/employed_as_data_scientist_into_research/,bob3421o,1568181664,[removed],0,1,False,self,,,,,
560,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,15,d2lrxc,self.MachineLearning,[N] Making machine learning as easy as SQL - introducing the predictive database,https://www.reddit.com/r/MachineLearning/comments/d2lrxc/n_making_machine_learning_as_easy_as_sql/,arauhala,1568182904,[removed],0,1,False,self,,,,,
561,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,15,d2lyxq,self.MachineLearning,Jean Monnet University- MLDM,https://www.reddit.com/r/MachineLearning/comments/d2lyxq/jean_monnet_university_mldm/,calisthenicsmonkey,1568184174,[removed],0,1,False,self,,,,,
562,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,15,d2m1hh,arxiv.org,[R] Automatic Critical Mechanic Discovery in Video Games,https://www.reddit.com/r/MachineLearning/comments/d2m1hh/r_automatic_critical_mechanic_discovery_in_video/,sensetime,1568184642,,2,1,False,default,,,,,
563,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,15,d2m2rq,elegantjbi.com,Self-Serve Business Intelligence and Data Literacy!,https://www.reddit.com/r/MachineLearning/comments/d2m2rq/selfserve_business_intelligence_and_data_literacy/,ElegantMicroWebIndia,1568184867,,0,1,False,default,,,,,
564,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,16,d2m5zr,self.MachineLearning,[D] Batch Normalization is a Cause of Adversarial Vulnerability,https://www.reddit.com/r/MachineLearning/comments/d2m5zr/d_batch_normalization_is_a_cause_of_adversarial/,aseembits93,1568185443,"Abstract - Batch normalization (batch norm) is often used in an attempt to stabilize and accelerate training in deep neural networks. In many cases it indeed decreases the number of parameter updates required to achieve low training error. However, it also reduces robustness to small adversarial input perturbations and noise by double-digit percentages, as we show on five standard data-sets. Furthermore, substituting weight decay for batch norm is sufficient to nullify the relationship between adversarial vulnerability and the input dimension. Our work is consistent with a mean-field analysis that found that batch norm causes exploding gradients.

Page - [https://arxiv.org/abs/1905.02161](https://arxiv.org/abs/1905.02161)

PDF - [https://arxiv.org/pdf/1905.02161.pdf](https://arxiv.org/pdf/1905.02161.pdf)

Has anyone read the paper and experienced robustness issues with deployment of Batchnorm models in the real world?",82,180,False,self,,,,,
565,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,16,d2m8sm,self.MachineLearning,ResNet152 is faster than VGG19 despite having significantly more layers,https://www.reddit.com/r/MachineLearning/comments/d2m8sm/resnet152_is_faster_than_vgg19_despite_having/,ml_i_like,1568185946,[removed],0,1,False,self,,,,,
566,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,17,d2mzta,kdnuggets.com,[D] Scikit-Learn vs mlr for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/d2mzta/d_scikitlearn_vs_mlr_for_machine_learning/,open_risk,1568191194,,0,1,False,default,,,,,
567,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,18,d2nk42,self.MachineLearning,Companies to do ML internships with?,https://www.reddit.com/r/MachineLearning/comments/d2nk42/companies_to_do_ml_internships_with/,MayoChef,1568195055,"I'm trying to come up with a list of companies that I could apply to for a 5 month ML internship (I'm a 3rd year UK Comp Sci student), but I'm struggling with coming up with any besides the usual FANG companies. I've also got Microsoft, Spotify and IBM.

 I'm not too sure if I want to work with startups because my ML knowledge at the moment is quite limited, but medium sized companies would be good.

Preferably, the internship would be with a US based companies. Any help would be appreciated!",0,1,False,self,,,,,
568,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,18,d2nllp,self.MachineLearning,Futurama Script Anaysis using NLP,https://www.reddit.com/r/MachineLearning/comments/d2nllp/futurama_script_anaysis_using_nlp/,ACTWizard,1568195335,[removed],0,1,False,self,,,,,
569,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,19,d2ny8c,self.MachineLearning,Faces dataset with career annotations,https://www.reddit.com/r/MachineLearning/comments/d2ny8c/faces_dataset_with_career_annotations/,rosamundo,1568197534,[removed],0,1,False,self,,,,,
570,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,19,d2o7ke,youtube.com,What is Artificial Intelligence and Machine Learning? | PGP-AIML Great Lakes | Great Learning,https://www.reddit.com/r/MachineLearning/comments/d2o7ke/what_is_artificial_intelligence_and_machine/,vidoolyritusingh,1568199097,,0,1,False,default,,,,,
571,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,20,d2ofd3,medium.com,How Artificial Intelligence Will Affect Your career in IT industry,https://www.reddit.com/r/MachineLearning/comments/d2ofd3/how_artificial_intelligence_will_affect_your/,Albertchristopher,1568200269,,0,1,False,https://a.thumbs.redditmedia.com/VtIxOMh1oi_6AXvcKgbUHpB1m66AoUDYYmMLVoEid98.jpg,,,,,
572,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,20,d2osp4,self.MachineLearning,Linux Alternatives to Paperly,https://www.reddit.com/r/MachineLearning/comments/d2osp4/linux_alternatives_to_paperly/,horribilis-existenti,1568202222,[removed],0,1,False,self,,,,,
573,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,21,d2p747,self.MachineLearning,Four great machine learning eBooks,https://www.reddit.com/r/MachineLearning/comments/d2p747/four_great_machine_learning_ebooks/,andrea_manero,1568204159,[removed],0,1,False,self,,,,,
574,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,21,d2pbnm,medium.com,Your Guide to Become Certified Associate Big Data Engineer!,https://www.reddit.com/r/MachineLearning/comments/d2pbnm/your_guide_to_become_certified_associate_big_data/,ariaareeds02,1568204741,,0,1,False,https://b.thumbs.redditmedia.com/PA6qf-DZ8FSy2aXpyKovIJGfHGmB0k7juX2_0xK4QSI.jpg,,,,,
575,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,21,d2pd07,youtu.be,"Holly Herndon on her AI baby vocalist, spawn [D]",https://www.reddit.com/r/MachineLearning/comments/d2pd07/holly_herndon_on_her_ai_baby_vocalist_spawn_d/,datramt,1568204904,,0,1,False,default,,,,,
576,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,21,d2pfnt,github.com,"MLModelScope is an open source, extensible, and customizable platform to facilitate evaluation and measurement of ML models within AI pipelines",https://www.reddit.com/r/MachineLearning/comments/d2pfnt/mlmodelscope_is_an_open_source_extensible_and/,jesusprubio,1568205258,,0,1,False,default,,,,,
577,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,21,d2pjhu,self.MachineLearning,[P] Fine-Tuned GPT-2 to generate new plots form IMDB's top 250 movies,https://www.reddit.com/r/MachineLearning/comments/d2pjhu/p_finetuned_gpt2_to_generate_new_plots_form_imdbs/,scientist_1337,1568205743,"Hello r/MachineLearning,

[\&gt;Link to the Twitter Plot Bot&lt;](https://twitter.com/the_plot_bot)

I've seen a post about the Trump bot and I don't know why it has been removed. But I'd like to share the bot that u/Schnox  have created by fine-tuning GPT-2 (774M) with r/WritingPrompts. Then we fed it with IMDB plotlines of the top 250 movies to create new narratives for all the best movies we like and love.   
The results are not chosen, this is unfiltered output of the algorithm.  


We'd appreciate your feedback on the project! Feel free to post questions or check out the code at [github.com/hansbambel/storytelling\_gpt2](https://github.com/hansbambel/storytelling_gpt2)",4,0,False,self,,,,,
578,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,21,d2plvy,medium.com,How Artificial Intelligence Will Affect Your career in IT industry,https://www.reddit.com/r/MachineLearning/comments/d2plvy/how_artificial_intelligence_will_affect_your/,Albertchristopher,1568206050,,0,1,False,https://a.thumbs.redditmedia.com/VtIxOMh1oi_6AXvcKgbUHpB1m66AoUDYYmMLVoEid98.jpg,,,,,
579,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,21,d2pmrf,self.MachineLearning,Math Questions Dataset,https://www.reddit.com/r/MachineLearning/comments/d2pmrf/math_questions_dataset/,mbalfakeih,1568206161,[removed],0,1,False,self,,,,,
580,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,22,d2pz5c,self.MachineLearning,[D] Directed acyclic graph and the definition of causality,https://www.reddit.com/r/MachineLearning/comments/d2pz5c/d_directed_acyclic_graph_and_the_definition_of/,i_love_FFT,1568207654,"I listened to a very interesting talk at [MAIS 2019](http://montrealaisymposium.com/) last Friday about a novel approach to learn DAG using neural networks (all the details in this paper here: [arXiv:1906.02226](https://arxiv.org/abs/1906.02226)). It's far from my actual discipline of sensor design and data processing, but I still sent to speak with the author at the poster session afterwards.

We didn't go into the details of the technique, instead we had a discussion about how there doesn't seem to exist a usable definition of causality in terms of graph analysis. He said that causality is something we all kind of agree on, but that we can't define. For example, the direction of the causality arrow between the average temperature and the altitude of a city is clear. If we magically changed the altitude, the average temperature would change, while if we magically changed the average temperature, the altitude wouldn't change. Therefore, the direction of causality is from ""altitude"" to ""average temperature"".

From my readings in cosmology and thermodynamics, I realized there seems to be a very similar concept that would benefit from being shared here. At least I hope so, it's sometimes hard to know the exact boundaries ;)

&amp;#x200B;

Here is a proposed definition for causality: a causal relationship ***R*** from set **A** to set **B** is a function transforming **A** into **B** such that information that was available in **A** is lost when working with the set **B**.

It means that a system that can be uniquely described in **A** cannot be uniquely described in **B** and it is impossible to know exactly which element from **A** was mapped to an element from **B**. In that sense, the set **A** has a greater information content than the set **B** and the function ***R*** reduces the amount of information available in the set.

In  the case of large scale phenomenon where classical physics tells us  that each process is deterministic (ie: maps one unique state to one other unique state), but we must also take into account the passage of time. The chronological order of the events dictates the direction of causality. This is where it gets interesting in my opinion: the arrow of time as defined by physicist Sean Carroll ([book](https://books.google.ca/books?id=Uak1wtcXrjwC&amp;lpg=PP1&amp;dq=editions%3A3OVBa17ENWUC&amp;pg=PP1#v=onepage&amp;q&amp;f=false), [multiple articles](https://scholar.google.com/scholar?&amp;q=arrow+of+time+author%3A%22s+carroll%22)) is deeply linked to the evolution of the entropy of the universe. The entropy itself is closely related to information content, from the definition of the Shannon Entropy.

It all comes back to the fact that causality points from a set containing more information to a set containing less information, and not the other way around.

I hope it makes sense and there's probably a better way to write it all and make the explanation clearer, but I feel like there's something useful about that.  
For example, if we find a causal link between two variables that seems to go against the above definition, it probably means that we are missing some information about the first set, or that the second set is not described in a very ""compact"" way and has redundant information.

Thanks for your comments!",12,11,False,self,,,,,
581,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,22,d2qkvf,self.MachineLearning,[D] How do you feel Machine Learning will affect video games?,https://www.reddit.com/r/MachineLearning/comments/d2qkvf/d_how_do_you_feel_machine_learning_will_affect/,varkarrus,1568210248,"I'm studying to become a video game designer, and these advances in machine learning are proooobably gonna affect my chosen career at some point. I know there's stuff already, like AlphaStar being a Pretty Darn Good SC2 AI, and that paper where character face sliders are preselected based off of a photo.

There's one application I can already see happening in the short term: right now, in story driven games, characters awkwardly avoid referring to the player by their name (with one notable exception in Fallout 4). But, I could easily see AIs trained off of a game's voice actors adjusting in-game recorded dialogue to include synthesized clips of the player's name. Even on lower end machines, these clips could be generated in the background so they're ready when needed.",78,49,False,self,,,,,
582,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,22,d2ql5z,self.MachineLearning,NeurIPS 2019 Co-Located Events [D],https://www.reddit.com/r/MachineLearning/comments/d2ql5z/neurips_2019_colocated_events_d/,gngdb,1568210287,"Does anyone know of a list of co-located events to NeurIPS? So far, I know of:

* [OPT2019](http://opt-ml.org/)
* [MLCB](https://mlcb.github.io/)
* [Queer in AI](https://sites.google.com/view/queer-in-ai/neurips-2019)
* [LatinX in AI](https://www.latinxinai.org/neurips-2019)
* [WiML](https://wimlworkshop.org/2019/)
* [Black in AI](https://blackinai.github.io/workshop/2019/cfp/)
* [EMC2](https://www.emc2-workshop.com/neurips-19)

What did I miss?",0,0,False,self,,,,,
583,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,23,d2qqii,ericvanular.com,Build Superhuman Reinforcement Learning in 10 Minutes,https://www.reddit.com/r/MachineLearning/comments/d2qqii/build_superhuman_reinforcement_learning_in_10/,ericvanular,1568210890,,1,1,False,https://b.thumbs.redditmedia.com/3LvhV1J3NQ5J8Dqc0b6c9v1BCgX61943Eo_ZlbDbsNo.jpg,,,,,
584,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,23,d2qzen,medium.com,Improving Industrial Processes with Machine Learning,https://www.reddit.com/r/MachineLearning/comments/d2qzen/improving_industrial_processes_with_machine/,Machine_Learning001,1568211947,,0,1,False,https://b.thumbs.redditmedia.com/aamxr81BQ9zaV_7gdKrq9IfClHKmnaC4V45TUUkN2Vw.jpg,,,,,
585,MachineLearning,t5_2r3gv,2019-9-11,2019,9,11,23,d2rbj6,self.MachineLearning,[D] NeurIPS co-located events,https://www.reddit.com/r/MachineLearning/comments/d2rbj6/d_neurips_colocated_events/,gngdb,1568213329,"Does anyone know of a list of co-located events to NeurIPS? So far, I've seen:

* [OPT2019](http://opt-ml.org/)
* [MLCB](https://mlcb.github.io/)
* [Queer in AI](https://sites.google.com/view/queer-in-ai/neurips-2019)
* [LatinX in AI](https://www.latinxinai.org/neurips-2019)
* [WiML](https://wimlworkshop.org/2019/)
* [Black in AI](https://blackinai.github.io/workshop/2019/cfp/)
* [EMC2](https://www.emc2-workshop.com/neurips-19)

What did I miss?

(reposted because the tag was in the wrong place in the title)",7,4,False,self,,,,,
586,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,0,d2rubm,self.MachineLearning,[Research] A multimodal dataset for autonomous driving,https://www.reddit.com/r/MachineLearning/comments/d2rubm/research_a_multimodal_dataset_for_autonomous/,cdossman,1568215423,[removed],0,1,False,self,,,,,
587,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,0,d2rzy9,ai.googleblog.com,Learning Cross-Modal Temporal Representations from Unlabeled Videos,https://www.reddit.com/r/MachineLearning/comments/d2rzy9/learning_crossmodal_temporal_representations_from/,sjoerdapp,1568216055,,0,1,False,https://a.thumbs.redditmedia.com/a_rgLf7OdXpKvLbrHuWJ-AQUdcdxH5jdUWJBJxxSLz0.jpg,,,,,
588,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,0,d2sa6m,self.MachineLearning,"Simple Questions Thread September 11, 2019",https://www.reddit.com/r/MachineLearning/comments/d2sa6m/simple_questions_thread_september_11_2019/,AutoModerator,1568217165,[removed],0,1,False,self,,,,,
589,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,0,d2sd0w,self.MachineLearning,[D] Which Mathematics for Machine Learning course should I take before getting started? Please help me!,https://www.reddit.com/r/MachineLearning/comments/d2sd0w/d_which_mathematics_for_machine_learning_course/,winter_l,1568217492,[removed],0,1,False,self,,,,,
590,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,1,d2sg5f,link.medium.com,"[D] Demystifying Transformer: If you know SQL, you probably understand Transformer, BERT and GPT.",https://www.reddit.com/r/MachineLearning/comments/d2sg5f/d_demystifying_transformer_if_you_know_sql_you/,transformer_ML,1568217825,,0,1,False,default,,,,,
591,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,1,d2smk6,self.MachineLearning,"Nice explanation of Transformer-XL, which allows transformer to encode very long sequences.",https://www.reddit.com/r/MachineLearning/comments/d2smk6/nice_explanation_of_transformerxl_which_allows/,transformer_ML,1568218517,[removed],0,1,False,self,,,,,
592,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,1,d2smyb,self.MachineLearning,"Question Answering Model, based on BERT for fast analysis of annual reports and earning call transcripts",https://www.reddit.com/r/MachineLearning/comments/d2smyb/question_answering_model_based_on_bert_for_fast/,LM_transfer,1568218564,[removed],0,1,False,self,,,,,
593,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,1,d2sy2p,hackernoon.com,Trading Bots vs Humans  Everything you need to know,https://www.reddit.com/r/MachineLearning/comments/d2sy2p/trading_bots_vs_humans_everything_you_need_to_know/,caternoon,1568219775,,1,1,False,default,,,,,
594,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,2,d2te4c,medium.com,QAit AI Learns by Interacting With Its Environment,https://www.reddit.com/r/MachineLearning/comments/d2te4c/qait_ai_learns_by_interacting_with_its_environment/,Yuqing7,1568221528,,0,1,False,https://a.thumbs.redditmedia.com/fJQ0L7dUI0auDKr0RsNihW9tBPyNEnt7dNmYjrGwkp0.jpg,,,,,
595,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,2,d2tfen,self.MachineLearning,[D] What do you think of ML/DL applications on the new iPhone,https://www.reddit.com/r/MachineLearning/comments/d2tfen/d_what_do_you_think_of_mldl_applications_on_the/,whichoneisblue,1568221660,I am really curious what the community thinks about the advances Apple seems to be claiming on device with their neural engine and GPUs with each new phone. What applications do you foresee for AI applications on device? Training as well or just inference?  Where do you think they are taking this?  Super curious to hear some opinions on this.,10,4,False,self,,,,,
596,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,2,d2th8n,hackernoon.com,7 Effective Ways to Deal With a Small Dataset,https://www.reddit.com/r/MachineLearning/comments/d2th8n/7_effective_ways_to_deal_with_a_small_dataset/,caternoon,1568221861,,2,1,False,https://b.thumbs.redditmedia.com/NGwaglEA49NuqFUs9jeWkTmDT8xFR77gtaGDp2r6nVk.jpg,,,,,
597,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,3,d2uii7,self.MachineLearning,[R] CTRL: A Conditional Transformer Language Mode for Controllable Generation (Largest Publicly Available Language Model),https://www.reddit.com/r/MachineLearning/comments/d2uii7/r_ctrl_a_conditional_transformer_language_mode/,SkiddyX,1568226014,Seems like Salesforce burnt some of their TPU credits to train a really large language model: https://einstein.ai/presentations/ctrl.pdf,9,92,False,self,,,,,
598,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,3,d2v240,self.MachineLearning,Which Jupyter environment do you use?,https://www.reddit.com/r/MachineLearning/comments/d2v240/which_jupyter_environment_do_you_use/,0_marauders_0,1568228199,[removed],0,1,False,self,,,,,
599,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,4,d2vpsb,self.MachineLearning,Can you guys(&amp; girls) please suggest a Python+Machine Learning based project(for final year of graduation) or can you tell us about your machine learning based college project?,https://www.reddit.com/r/MachineLearning/comments/d2vpsb/can_you_guys_girls_please_suggest_a_pythonmachine/,PragatiBuffett,1568230825,[removed],0,1,False,self,,,,,
600,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,4,d2w0bz,eng.uber.com,[R] Loss Change Allocation proposed by Uber which can measures how much each parameter in network learns,https://www.reddit.com/r/MachineLearning/comments/d2w0bz/r_loss_change_allocation_proposed_by_uber_which/,bobchennan,1568231982,,1,1,False,default,,,,,
601,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,5,d2w4en,self.MachineLearning,classifying very short texts into non-exclusive categories,https://www.reddit.com/r/MachineLearning/comments/d2w4en/classifying_very_short_texts_into_nonexclusive/,forest_pandas,1568232418,[removed],0,1,False,self,,,,,
602,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,5,d2wu4c,self.MachineLearning,Evaluating statistical significance of classifier performance across conditions with fixed training data,https://www.reddit.com/r/MachineLearning/comments/d2wu4c/evaluating_statistical_significance_of_classifier/,yungwashington,1568235276,[removed],0,1,False,self,,,,,
603,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,6,d2xi1q,self.MachineLearning,What exactly is accuracy_per_sequence when evaluating transformer model in Tensorflow?,https://www.reddit.com/r/MachineLearning/comments/d2xi1q/what_exactly_is_accuracy_per_sequence_when/,jimi_jimi_jimi_,1568237975,[removed],0,1,False,https://b.thumbs.redditmedia.com/hp8RCmLMJeRrpmL77yTAdfLbm4iUTyVoqGqjJPepUCU.jpg,,,,,
604,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,6,d2xlxr,self.MachineLearning,Correction of my aspirations if need be,https://www.reddit.com/r/MachineLearning/comments/d2xlxr/correction_of_my_aspirations_if_need_be/,burnthisnameafteruse,1568238433,[removed],0,1,False,self,,,,,
605,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,6,d2xn5o,self.MachineLearning,[D] Whats the best explanation of accuracy_per_sequence when evaluating transformer model in Tensorflow?,https://www.reddit.com/r/MachineLearning/comments/d2xn5o/d_whats_the_best_explanation_of_accuracy_per/,jimi_jimi_jimi_,1568238573,"Hello!

I'm looking for a good detailed explanation of the evaluation metric:**Accuracy\_per\_sequence** as displayed when training the transformer network[https://github.com/tensorflow/models/tree/master/official/transformer](https://github.com/tensorflow/models/tree/master/official/transformer)

Here is the tensorboard output:

&amp;#x200B;

https://i.redd.it/wydu5wvqc1m31.png

I'm assuming it refers to accuracy of sequences per step?

I'm familiar with Top-5 accuracy and such but **haven't found a good explanation** of Accuracy per sequence.

Appreciate the help, Thanks!

J",2,1,False,https://b.thumbs.redditmedia.com/_BO1-4_X8hFTdowe__-DexUR_9HVV5mly1HZ9bII8og.jpg,,,,,
606,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,7,d2ydek,self.MachineLearning,Any works on super resolution with large inputs?,https://www.reddit.com/r/MachineLearning/comments/d2ydek/any_works_on_super_resolution_with_large_inputs/,shenkev,1568241629,[removed],0,1,False,self,,,,,
607,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,7,d2yh74,self.MachineLearning,[P] How to identify only one object on screen?,https://www.reddit.com/r/MachineLearning/comments/d2yh74/p_how_to_identify_only_one_object_on_screen/,mathowned,1568242065,"Hello everyone!

I'm currently doing a CS Project which identifies one object in a game running on window mode and take actions by itself (by autoclicking or pressing a key).  Basically, I will set a canvas on the up right side of my desktop, match it with the game window size and then start trying to identify one specific object. For exemple, i use an image of a monster in the identification algorithm, if it appears on screen and matches, it takes an action.

&amp;#x200B;

I'm just a beginner in ML... Do I need a neural net for doing that object identification? If so, how do i create a dataset if it's only trying to identify one specific object? 

I accept literally every possible tip you guys can get me. Libraries I can use, image processing tips for that... anything.

Thanks!",9,0,False,self,,,,,
608,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,9,d305pu,self.MachineLearning,Train an AI for Visually Impaired People in 10 minutes,https://www.reddit.com/r/MachineLearning/comments/d305pu/train_an_ai_for_visually_impaired_people_in_10/,TactileImages,1568249719,[removed],0,1,False,self,,,,,
609,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,10,d30hos,self.MachineLearning,Question on Maximum Entropy Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/d30hos/question_on_maximum_entropy_reinforcement_learning/,celestialquestrial,1568251271,"I've been working through ""Maximum Entropy Reinforcement Learning"" by Ziebert et al. I am currently stuck on understanding a few critical parts of the paper and was wondering anyone could help provide some clarity.

In particular, I am wondering how you can justify the correctness of Algorithm 1's ""Backward pass."" Why is the backward pass detailed here a correct way to estimate the action probabilities, P(a|s)? What's the right way to think about this?

I would also appreciate if someone could explain the reasoning behind the section ""Stochastic Policies."" There seems to be no explanation for why the probability of an action is proportional to the sum of probabilities of all trajectories starting with that action. 

Paper here: [https://www.cs.uic.edu/pub/Ziebart/Publications/maxentirl-bziebart.pdf](https://www.cs.uic.edu/pub/Ziebart/Publications/maxentirl-bziebart.pdf)",0,1,False,self,,,,,
610,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,10,d30kma,self.MachineLearning,[P] Train an AI for Visually Impaired People in 10 minutes,https://www.reddit.com/r/MachineLearning/comments/d30kma/p_train_an_ai_for_visually_impaired_people_in_10/,TactileImages,1568251646,"Help us train an AI that recognizes hands. We will be able to further develop our app for Visually Impaired People (VIP) using tactile images in swell/embossed/raised paper. This way they won't need another person to explain what they are touching, the app will see their hand position and explain what they are touching. 
What if mom can't help with Chemistry, Mathematics, Geography homework? Use our app! A big leap towards e-learning and self-developing tool for VIPs.

I made a [video](https://youtu.be/vUuLPERkx6w) to better explain the situation: what we have and what we need. Useful for distributing on social media? 

[Video](https://youtu.be/k-hzZ87hHu0) with what the app learned by now:
It only works with limited parameters and is not very precise - that's why we are asking for support to improve it. 
Please take pictures in different lighting, from different angles, with different textures.
Various hand sizes and skin tones welcome! 



WHAT TO DO (for IOS):
If you have an iPhone, download the IOS app from [here](https://testflight.apple.com/join/9gVahDmZ):
(First, install TestFlight from Apple, then install Keypoints app. No accounts needed.)

Short tutorial:
- take pictures by touching the left upper corner camera button
- after taking the pictures a folder will appear in the app. Open it and set the points as seen in the [tutorial](https://youtu.be/27DZpKCUJBM)
- after you finish setting the markers, use the right upper corner send button to send them to developer@teistudios.ro by email or transfer (Google Drive, Dropbox, etc)

Keypoints (as seen in the pictograms down the screen) are:
1. Index finger tip
2. Index finger base
3. Thumb tip
4. Little finger base

Only place keypoints on the visible hand elements. If 1, 2, 3 or 4 are not visible do not activate that keypoint(s).
You can always reset the points by using the curve arrow on top right. 
You can finish setting keypoints some other time. You can also continue taking pictures anytime. Just remember to send us the pictures after setting keypoints.
After sending the pictures you can delete the folder by sliding left on it. 



WHAT TO DO (for nonIOS):
If you don't have an IOS device, just take 50 pictures and send them to developer@teistudios.ro through online transfer.",0,0,False,self,,,,,
611,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,11,d319vq,self.MachineLearning,Ideas for a Project with Mobile Game Data,https://www.reddit.com/r/MachineLearning/comments/d319vq/ideas_for_a_project_with_mobile_game_data/,mljtttl,1568255012,[removed],0,1,False,self,,,,,
612,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,12,d32crt,deepmind.com,How evolutionary selection can train more capable self-driving cars | DeepMind,https://www.reddit.com/r/MachineLearning/comments/d32crt/how_evolutionary_selection_can_train_more_capable/,therasu,1568260560,,0,1,False,default,,,,,
613,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,13,d32gex,self.MachineLearning,[D] An overlooked pitfall in data science is incorporation of numerical identifiers.,https://www.reddit.com/r/MachineLearning/comments/d32gex/d_an_overlooked_pitfall_in_data_science_is/,at-roasted-space,1568261106,"As a professional data sciencetis and algorithm developer I ofent encounter serious errors in the use and design of machine learning software. One of the most ignoring is incorporation of numerical identifiers in data sets used for machine learning. Many data sets come with identifiers in the feature set, however they should never be used when validating or estimating models!

Take for example Forensic Science Glass Identification data, it comes with a id column. Use the data as is, I can get an error rates of less than 1%, too good to be true, and it is. Removing the id column and the error rate is approximately 35%! Details can be found in my code-snippet here: http://roasted.space/?page=codeZglass and short in my blog post: http://roasted.space/?page=blogZglass",8,0,False,self,,,,,
614,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,13,d32kbo,self.MachineLearning,Probabilistic Classification - Normalizing results,https://www.reddit.com/r/MachineLearning/comments/d32kbo/probabilistic_classification_normalizing_results/,amirgreddit,1568261700,[removed],0,1,False,self,,,,,
615,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,13,d32zxc,nature.com,"[D] Citation bubble about to burst? (Schmidhuber, 2011)",https://www.reddit.com/r/MachineLearning/comments/d32zxc/d_citation_bubble_about_to_burst_schmidhuber_2011/,hardmaru,1568264274,,0,1,False,default,,,,,
616,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,14,d33co3,self.MachineLearning,The Machine Learning Data Science Path,https://www.reddit.com/r/MachineLearning/comments/d33co3/the_machine_learning_data_science_path/,KamWithK,1568266450,"I've created a [blog post](https://kamwithk.github.io/path.html#path) detailing different courses, books and places people can learn about data science/machine learning from.

It categorizes the sources, and gives details on the main differences between them to help decide whether the course is right for you. Make sure to take a look:

[https://kamwithk.github.io/path.html#path](https://kamwithk.github.io/path.html#path)

Any feedback would be greatly appreciated!",0,1,False,self,,,,,
617,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,14,d33kpd,self.MachineLearning,Best Ways to generate features from Images,https://www.reddit.com/r/MachineLearning/comments/d33kpd/best_ways_to_generate_features_from_images/,PyWarrior,1568267870,[removed],0,1,False,self,,,,,
618,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,15,d33raf,srinisekaran.com,The Data Labeling Playbook: A Human Approach  Ethics in Data Labeling,https://www.reddit.com/r/MachineLearning/comments/d33raf/the_data_labeling_playbook_a_human_approach/,ml-ai,1568269057,,0,1,False,https://b.thumbs.redditmedia.com/pTYr_qBtU3Yrve0EzGjOEF7w5Vtep19wfRh2D1PynNM.jpg,,,,,
619,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,15,d33unw,self.MachineLearning,embedding-as-service : One stop to convert sentence to vector from various embedding techniques.,https://www.reddit.com/r/MachineLearning/comments/d33unw/embeddingasservice_one_stop_to_convert_sentence/,amansrivastava17,1568269667,[removed],0,3,False,self,,,,,
620,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,16,d346e9,self.MachineLearning,[R] Using Fractal Neural Networks to Play SimCity 1 and Conways Game of Life at Variable Scales,https://www.reddit.com/r/MachineLearning/comments/d346e9/r_using_fractal_neural_networks_to_play_simcity_1/,hardmaru,1568271767,"Workshop paper at AIIDE 2019 Experimental AI in Games

http://www.exag.org/papers/EXAG_2019_paper_21.pdf

Abstract:

We introduce gym-city, a Reinforcement Learning environment that uses SimCity 1s game engine to simulate an urban environment, wherein agents might seek to optimize one or a combination of any number of city-wide metrics, on gameboards of various sizes. We focus on population, and analyze our agents ability to generalize to larger map-sizes than those seen during training. The environment is interactive, allowing a human player to build alongside agents during training and inference, potentially influencing the course of their learning, or manually probing and evaluating their performance. To test our agents ability to capture distance-agnostic relationships between elements of the gameboard, we design a minigame within the environment which is, by design, unsolvable at large enough scales given strictly local strategies. Given the game engines extensive use of Cellular Automata, we also train our agents to play Conways Game of Life  again optimizing for population  and examine their behaviour at multiple scales. To make our models compatible with variable-scale gameplay, we use Neural Networks with recursive weights and structure  fractals to be truncated at different depths, dependent upon the size of the gameboard.",11,158,False,self,,,,,
621,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,16,d349ii,statanalytica.com,Statistics vs Machine Learning: Which is More Powerful - Statanalytica,https://www.reddit.com/r/MachineLearning/comments/d349ii/statistics_vs_machine_learning_which_is_more/,Statistics_helpers,1568272332,,0,1,False,default,,,,,
622,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,16,d34j83,self.MachineLearning,Unsupervised Anomaly GAN,https://www.reddit.com/r/MachineLearning/comments/d34j83/unsupervised_anomaly_gan/,MatMou,1568274152,"Hi,

I've been trying to find some information on GANs used for unsupervised learning. Specifically I'm looking for something on unsupervised anomaly detection on non-image data similar to papers and githubs on AnoGan (which is mainly on image data).

Does anybody know of a place to look into this or a way or rewriting AnoGans to use fx csv data.

So far I've been looking into this:  [https://github.com/tkwoo/anogan-keras/blob/master/anogan.py](https://github.com/tkwoo/anogan-keras/blob/master/anogan.py)",1,1,False,self,,,,,
623,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,16,d34lej,lionbridge.ai,5 Ways Every Business Can Start Implementing AI Into Their Framework,https://www.reddit.com/r/MachineLearning/comments/d34lej/5_ways_every_business_can_start_implementing_ai/,LimarcAmbalina,1568274598,,0,1,False,default,,,,,
624,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,17,d35169,self.MachineLearning,Hypnosis in,https://www.reddit.com/r/MachineLearning/comments/d35169/hypnosis_in/,ZeroMaxinumXZ,1568277891,[removed],0,1,False,self,,,,,
625,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,18,d35a2k,self.MachineLearning,What kind of PCIe Root Architecture should I use for training deep learning model?,https://www.reddit.com/r/MachineLearning/comments/d35a2k/what_kind_of_pcie_root_architecture_should_i_use/,Chungphung,1568279757,"As in the attached link, there are 3 types of architectures for a server that I can choose from. I'm kind of perplexed since I don't really know which one is best fit (no bottle neck in reading data, calculating operations in both data parallel and model parallel methods) for training deep learning models on 8 GPUs. 

And can someone tell me what is the difference between these 3 architectures in training using data parallel and model parallel method?",0,1,False,self,,,,,
626,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,18,d35duk,self.MachineLearning,[Project] [Discussion] Capturing and acting on customer intent in the ecommerce space,https://www.reddit.com/r/MachineLearning/comments/d35duk/project_discussion_capturing_and_acting_on/,iglidante,1568280517,"I've been working in ecommerce exclusively for the past four years, and a lot of that time has been spent shaping customer experience using tools like Saleforce's Einstein (within the context of Salesforce Commerce Cloud). That work tends to focus on products and their attributes first and foremost, but we're also beginning to gather more browsing data to build better models for customer intent (to drive more conversions, show more effective presentations of products, etc.).

That all drove me pretty deeply down the rabbit hole, and I started writing about it to try to get some of my ideas solidified. I wrote this piece about activity nodes, successful endpoints, behavioral cohorts, and ways to tie that all together to rank, predict, and drive desired outcomes. 

[https://medium.com/datadriveninvestor/where-did-you-come-from-where-did-you-go-where-are-you-headed-ai-will-know-9d623d1cf52f](https://medium.com/datadriveninvestor/where-did-you-come-from-where-did-you-go-where-are-you-headed-ai-will-know-9d623d1cf52f) 

Anyway, I'd love to discuss it if anyone is interested, because this is an area where I don't get the chance to delve deeply with my own team or colleagues (it's really not in their wheelhouse, and we have too much focused work to do for thought experiments on the clock).",6,1,False,self,,,,,
627,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,18,d35kck,docs.google.com,Silk Screen Machine,https://www.reddit.com/r/MachineLearning/comments/d35kck/silk_screen_machine/,rapidtag,1568281816,,0,1,False,default,,,,,
628,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,18,d35kno,self.MachineLearning,"Distance on nodes of Knowledge graphs, how to do it?",https://www.reddit.com/r/MachineLearning/comments/d35kno/distance_on_nodes_of_knowledge_graphs_how_to_do_it/,FireFox1616,1568281871,[removed],0,2,False,self,,,,,
629,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,20,d368ha,self.MachineLearning,Why unstructured data should matter for business value,https://www.reddit.com/r/MachineLearning/comments/d368ha/why_unstructured_data_should_matter_for_business/,Countants123,1568286190,[removed],0,1,False,self,,,,,
630,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,20,d36gei,phys.org,Quantum ConvNets,https://www.reddit.com/r/MachineLearning/comments/d36gei/quantum_convnets/,cipher123x,1568287460,,0,1,False,default,,,,,
631,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,20,d36hie,self.MachineLearning,Ideas to use Machine Learning to increase monetization for mobile games?,https://www.reddit.com/r/MachineLearning/comments/d36hie/ideas_to_use_machine_learning_to_increase/,mljtttl,1568287635,[removed],0,1,False,self,,,,,
632,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,20,d36j03,self.MachineLearning,What should I use for pattern recognition?,https://www.reddit.com/r/MachineLearning/comments/d36j03/what_should_i_use_for_pattern_recognition/,nunodonato,1568287884,[removed],0,1,False,self,,,,,
633,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,20,d36tgg,self.MachineLearning,State of the art approach to group news articles about the same topic?,https://www.reddit.com/r/MachineLearning/comments/d36tgg/state_of_the_art_approach_to_group_news_articles/,ElCerebroDeLaBestia,1568289498,[removed],0,1,False,self,,,,,
634,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,20,d36thf,self.MachineLearning,What's a ML problem you are interested in but for which you haven't found a good tutorial / introduction?,https://www.reddit.com/r/MachineLearning/comments/d36thf/whats_a_ml_problem_you_are_interested_in_but_for/,pirate7777777,1568289502,[removed],0,1,False,self,,,,,
635,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,21,d36vmt,self.MachineLearning,[D] Utilizing RoBERTa in Tensorflow,https://www.reddit.com/r/MachineLearning/comments/d36vmt/d_utilizing_roberta_in_tensorflow/,jackdaniels79,1568289812,"I need to convert facebook's RoBERTa which is in pytorch into tensorflow, I can see a lot of info about conversion from pytorch to tensorflow but not the opposite. Thanks",1,7,False,self,,,,,
636,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,21,d36x3c,self.MachineLearning,[D] What's a ML problem you are interested in but for which you haven't found a good tutorial / introduction?,https://www.reddit.com/r/MachineLearning/comments/d36x3c/d_whats_a_ml_problem_you_are_interested_in_but/,pirate7777777,1568290029,"Hi everyone! I found this [Twitter discussion](https://twitter.com/fchollet/status/1170814529313243137) extremely interesting and would like to know your thoughts. It could be a great way to inspire writers/creators to produce more interesting articles about ML/DL (as highlighted here: [https://www.reddit.com/r/MachineLearning/comments/co37ut/regarding\_beginners\_guides/](https://www.reddit.com/r/MachineLearning/comments/co37ut/regarding_beginners_guides/))

Here's the post for those of you who are too lazy to follow a link, lol

What's a ML problem you are interested in but for which you haven't found a good tutorial/introduction? Preferably a \*task\* rather than a \*technique\* (what you are trying to do vs. how you are trying to do it). Too many people jump to tools that may be far from optimal when simpler, better solutions exist. Also, if you are working with a specific dataset, please describe it - [**Franois Chollet**](https://twitter.com/fchollet)",9,3,False,self,,,,,
637,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,21,d3798i,copymonkey.xyz,An AI that mimics your handwriting style,https://www.reddit.com/r/MachineLearning/comments/d3798i/an_ai_that_mimics_your_handwriting_style/,SwechhaSwechha,1568291740,,0,1,False,default,,,,,
638,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,22,d37r32,bloglovin.com,Virtual Assistant Stats 2019,https://www.reddit.com/r/MachineLearning/comments/d37r32/virtual_assistant_stats_2019/,Aarushiiiii123,1568294169,,0,1,False,https://a.thumbs.redditmedia.com/MkjGpy182xiSmuNkPadbe2Mav9z5dpISeJO2f3jCDj4.jpg,,,,,
639,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,22,d383tk,self.MachineLearning,[D] training ASR checking assumptions,https://www.reddit.com/r/MachineLearning/comments/d383tk/d_training_asr_checking_assumptions/,sicp4lyfe,1568295826,"Suppose you're training an ASR system from scratch using audio books, where you have the plain text as well as the audio. One big mp3 file for the book (or maybe split into several chapter's mp3 files ). And several text files corresponding to the chapters. 

The first stage is you need labelled data, ie 1.wav with a transcript 1.txt for the first line of the book. Then 2.wav with a transcript 2.txt for the 2nd line of the book. And so on.  Once you have those pairings you can feed into into your ASR system (eg mozilla deepspeech). The algorithm wont take bigger chunks, so a sentence seems to be the right way to go. You could try feeding it per word but I don't know if that would improve performance? Anyway suppose it's per line for simplicity, because you don't really want a bazillion files of just one word uttered and transcribed.

But how exactly do you segment the bigger audio files into smaller line sized pieces? You can do try by voice activity detection. But now you don't know exactly how each piece of audio (say foo.wav) corresponds to foo.txt since the narrator might blend two sentences together with an altogether too small pause in some cases. If the author pauses faithfully between sentences it would be easy. But you can't assume VAD will give you neat divisions of 1:1 speech to text, so you can't easily work out which line of text corresponds to what chunk of audio.

So your data is cut up into 1-5s pieces, by voice activity, unlabelled, you need to label it. In this phase I think you're supposed to use tools like forced alignment. But the problem is we don't really care about word alignment which is what forced aligners do, we're just after sentences after all. And forced alignment needs line by line transcripts to work in the first place, which we don't have, which is the problem we were originally faced with before anyone mentioned forced aligner. 

Apparently one solution is to simply segment the speech into small wavs and then run ASR on those pieces to generate transcripts. Easy,  except the problem is we don't have a working ASR to use, so does that mean the bootstrapping is done by hand? That's where i'm stuck.

Is there no way around the bootstrapping by hand? For a low resource language you're just stuck without hand labelling lots of data first. Are all my assumptions correct?",6,2,False,self,,,,,
640,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,22,d38a0e,self.MachineLearning,How much time in advance should I apply for a AI position at DeepMind or Google Brain,https://www.reddit.com/r/MachineLearning/comments/d38a0e/how_much_time_in_advance_should_i_apply_for_a_ai/,angular-calendar,1568296614,[removed],0,1,False,self,,,,,
641,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,23,d38cqb,youtube.com,Artificial Intelligence vs. Machine Learning vs. NLP,https://www.reddit.com/r/MachineLearning/comments/d38cqb/artificial_intelligence_vs_machine_learning_vs_nlp/,steffi_fa,1568296975,,0,1,False,https://b.thumbs.redditmedia.com/IXGGbQCYbjp1ZPNDxCu7vT0BZSdYcu_AxsgUol_GLRs.jpg,,,,,
642,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,23,d38e4d,self.MachineLearning,[R] Research Guide for Video Frame Interpolation with Deep Learning,https://www.reddit.com/r/MachineLearning/comments/d38e4d/r_research_guide_for_video_frame_interpolation/,mwitiderrick,1568297136,"In this research guide, well look at deep learning papers aimed at synthesizing video frames within an existing video. This could be in between video frames, known as interpolation, or after them, known as extrapolation.

Research Guide for Video Frame Interpolation with Deep Learning by Derrick Mwiti https://link.medium.com/DgU5ogTlVZ",2,4,False,self,,,,,
643,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,23,d38okq,self.MachineLearning,"[Discussion] Google Patents ""Generating output sequences from input sequences using neural networks""",https://www.reddit.com/r/MachineLearning/comments/d38okq/discussion_google_patents_generating_output/,metacurse,1568298416,"&gt;**Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating output sequences from input sequences**. One of the methods includes obtaining an input sequence having a first number of inputs arranged according to an input order; processing each input in the input sequence using an encoder recurrent neural network to generate a respective encoder hidden state for each input in the input sequence; and generating an output sequence having a second number of outputs arranged according to an output order, each output in the output sequence being selected from the inputs in the input sequence, comprising, for each position in the output order: generating a softmax output for the position using the encoder hidden states that is a pointer into the input sequence; and selecting an input from the input sequence as the output at the position using the softmax output.

[http://www.freepatentsonline.com/10402719.html](http://www.freepatentsonline.com/10402719.html)

News from the UK is that the grave of some guy named Turing has been heard making noises since this came out.",91,323,False,self,,,,,
644,MachineLearning,t5_2r3gv,2019-9-12,2019,9,12,23,d38ot6,self.MachineLearning,Neural Network diverges to predict the single majority class,https://www.reddit.com/r/MachineLearning/comments/d38ot6/neural_network_diverges_to_predict_the_single/,stity7,1568298444,[removed],1,1,False,https://b.thumbs.redditmedia.com/WOZgxN2okpXSuy03qGZ27-fhoQ-hm4F_l_2ytrs6y4w.jpg,,,,,
645,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,0,d39iz5,self.MachineLearning,What type of GAN is used in glitch-ai for AI generated fashion,https://www.reddit.com/r/MachineLearning/comments/d39iz5/what_type_of_gan_is_used_in_glitchai_for_ai/,lkspade,1568302033, [https://glitch-ai.com](https://glitch-ai.com/) I think it is the style gan but not sure.,0,1,False,self,,,,,
646,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,0,d39mu3,self.MachineLearning,[P] The age of transformers &amp; Understanding text with BERT,https://www.reddit.com/r/MachineLearning/comments/d39mu3/p_the_age_of_transformers_understanding_text_with/,ilnmtlbnm,1568302500,"This is a two part blog post on a Project that aims to do question answering, using a pretrained BERT.


The first part teaches about Transformers, and the history that leads up to this Architecture.
 -&gt; https://blog.scaleway.com/2019/building-a-machine-reading-comprehension-system-using-the-latest-advances-in-deep-learning-for-nlp/


The second part focuses on using a pre-trained BERT (in PyTorch) and how to do question answering. There's code and you can try it on your own dataset easily :)

-&gt; https://blog.scaleway.com/2019/understanding-text-with-bert/",0,0,False,self,,,,,
647,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,0,d39vig,self.MachineLearning,[R] Recent Advances in Object Detection in the Age of Deep Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/d39vig/r_recent_advances_in_object_detection_in_the_age/,gnavihs,1568303535,"Abstract - Object detection, the computer vision task dealing with detecting instances of objects of a certain class (e.g., car, plane, etc.) in images, attracted a lot of attention from the community during the last six years. This strong interest can be explained not only by the importance this task has for many applications but also by the phenomenal advances in this area since the arrival of deep convolutional neural networks (DCNNs). This article reviews the recent literature on object detection with deep CNN, in a comprehensive way. This study covers not only the design decisions made in modern deep (CNN) object detectors, but also provides an in-depth perspective on the set of challenges currently faced by the computer vision community, as well as some complementary and new directions on how to overcome them. In its last part it goes on to show how object detection can be extended to other modalities and conducted under different constraints. This survey also reviews in its appendix the public datasets and associated state-of-the-art algorithms.

Page -&gt; [https://arxiv.org/abs/1809.03193](https://arxiv.org/abs/1809.03193)

PDF -&gt; [https://arxiv.org/pdf/1809.03193.pdf](https://arxiv.org/pdf/1809.03193.pdf)",0,2,False,self,,,,,
648,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,1,d3a1f3,zeldatech.com,"Real-World Machine Learning By Henrik Brink, Joseph Richards, Mark Fetherolf PDF",https://www.reddit.com/r/MachineLearning/comments/d3a1f3/realworld_machine_learning_by_henrik_brink_joseph/,psychonekk,1568304207,,0,1,False,default,,,,,
649,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,1,d3a5du,self.MachineLearning,[D] Staying on top in an ML contest,https://www.reddit.com/r/MachineLearning/comments/d3a5du/d_staying_on_top_in_an_ml_contest/,Bynd_Trump_both_2020,1568304655,"I'm in an ML contest in 1st place by a good margin; it has a while left still and it will shake up big. I feel less motivation to actually improve my score now and I'm sure there is still huge room for improvement. Does anyone have any suggestions for staying motivated to improve? I'm not even sure if this is the right sub to post this. I feel like I've been in Kaggle contests and dropped the ball at the last minute and I've seen others be in similar scenarios and do the same. How do I hold that winning mindset still? I swear, if I'm in 2nd or 3rd, my mindset is 10x more competitive.",3,0,False,self,,,,,
650,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,1,d3abhs,medium.com,Nasty Language Processing: Textual Triggers Transform Bots Into Bigots,https://www.reddit.com/r/MachineLearning/comments/d3abhs/nasty_language_processing_textual_triggers/,Yuqing7,1568305369,,0,1,False,https://a.thumbs.redditmedia.com/VHku45jQOSYtOddkT6UyWWIN7LYKpQ5tVo1we1Yzhr8.jpg,,,,,
651,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,1,d3ahnb,self.MachineLearning,[P] learn2learn: A PyTorch Meta Learning Library,https://www.reddit.com/r/MachineLearning/comments/d3ahnb/p_learn2learn_a_pytorch_meta_learning_library/,praat33k,1568306083,"Hello /r/ML,

We are pleased to share with you our meta-learning library, that started as a project at the PyTorch hackathon.

learn2learn is a PyTorch library for all things meta-learning. Our goal is to support as many meta-learning algorithms as possible (be it few-shots, meta-descent, or meta-RL) and to enable researchers to develop better methods and easily compare against existing literature.

Our current features include:

* **Modular API**: implement your own training loops with our low-level utilities.
* Provides **various meta-learning algorithms** (e.g. MAML, FOMAML, MetaSGD, ProtoNets, DiCE)
* **Task generator with unified API**, compatible with torchvision, torchtext, torchaudio, and cherry
* Provides **standardized meta-learning tasks** for vision (**Omniglot, mini-ImageNet**), reinforcement learning (**Particles, Mujoco)**, and even text (news classification).
* **100% compatible with PyTorch** \-- use your own modules, datasets, or libraries!

If this is of interest to you, have a look at the following links:

* GitHub: [learnables/learn2learn](https://github.com/learnables/learn2learn)
* Examples: [learn2learn/examples](https://github.com/learnables/learn2learn/tree/master/examples)
* Documentation: [learn2learn.net](http://learn2learn.net)
* Slack: [slack.learn2learn.net](http://slack.learn2learn.net)

Let us know what you think and how we can help you in your research!

PS: learn2learn was also accepted as a poster to the PyTorch Dev Conference, so you'll know all about it there!",6,89,False,self,,,,,
652,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,1,d3ak3h,self.MachineLearning,Prediction Intervals in Forecasting: Quantile Loss Function,https://www.reddit.com/r/MachineLearning/comments/d3ak3h/prediction_intervals_in_forecasting_quantile_loss/,datasciencerd,1568306348,[removed],0,1,False,self,,,,,
653,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,2,d3bbyg,discord.gg,Machine Learning Discord Group! Join Explore and Learn,https://www.reddit.com/r/MachineLearning/comments/d3bbyg/machine_learning_discord_group_join_explore_and/,Shahrukh_Parvez,1568309555,,0,1,False,default,,,,,
654,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,2,d3big9,medium.com,Estimating Uncertainty in Machine Learning Models - Part 1,https://www.reddit.com/r/MachineLearning/comments/d3big9/estimating_uncertainty_in_machine_learning_models/,CometML,1568310292,,0,2,False,default,,,,,
655,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,3,d3bwnl,self.MachineLearning,Transfer Learning Question,https://www.reddit.com/r/MachineLearning/comments/d3bwnl/transfer_learning_question/,NonbinaryBootyBuildr,1568311930,"I have a task in which I am pretending to have an ""unobserved"" system, let's call it the target system, that I am using an LSTM from a similar system that has observations to perform the regression. I call these observed systems the source systems. 

&amp;#x200B;

However, to find the most similar source systems to use I must use some metadata about the systems that are available even for the unobserved targets. The idea is that we can find similarities in the metadata to indicate which source systems will perform well. 

&amp;#x200B;

To do this I assume I need to create some kind of similarity or distance function on the metadata. Since I don't have too many source systems (about 70), I'm guessing the algorithm must be simple. I'm thinking linear regression on the differences in metadata between the source and the target. If so, how would you define a similarity function based on this regression? Is regression even the best way to go about this?

&amp;#x200B;

I'm not too knowledgeable about recommender systems but would this be a case where we would want to ""recommend"" a source system?

&amp;#x200B;

If there are resources about these kinds of problems available please let me know as well, I can't seem to find much in the few transfer learning survey papers I have read.",0,1,False,self,,,,,
656,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,3,d3c4hi,self.MachineLearning,Need help in automating Google AutoML text classification pipeline,https://www.reddit.com/r/MachineLearning/comments/d3c4hi/need_help_in_automating_google_automl_text/,dukhi_atma,1568312821,[removed],0,1,False,self,,,,,
657,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,3,d3c5n6,self.MachineLearning,Difference of brains in Unity ML-Agents 0.9,https://www.reddit.com/r/MachineLearning/comments/d3c5n6/difference_of_brains_in_unity_mlagents_09/,ethancc19,1568312955,[removed],0,1,False,self,,,,,
658,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,3,d3cc4k,frontnet.eu,Introduction of pre-trained models in the field of Computer Vision,https://www.reddit.com/r/MachineLearning/comments/d3cc4k/introduction_of_pretrained_models_in_the_field_of/,frontnetcoin,1568313732,,0,1,False,https://b.thumbs.redditmedia.com/5pnuIYRLP86ks3fg-oLPqQFdcsLi7stkZpDnnbYBm-c.jpg,,,,,
659,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,3,d3cd0l,self.MachineLearning,[P] Does any framework have native Fourier-based CNNs?,https://www.reddit.com/r/MachineLearning/comments/d3cd0l/p_does_any_framework_have_native_fourierbased_cnns/,StellaAthena,1568313839,"I'm looking to do some experiments using the Fast Fourier Transform to do CNNs. From what I've seen, many common frameworks (Chainer, Keras, PyTorch, TensorFlow) don't provide support for this. They typically implement a FFT or DFT *function* but not a FT *convolutional layer*. I could implement it from scratch, but there's some finicky implementation aspects I was hoping to avoid worrying about.  


Does any framework have native Fourier-based CNNs? Alternatively, pointers to SOTA implementations on GitHub I can use for reference would be highly appreciated. Ideally in Chainer, as that's the framework I have experience with.",10,10,False,self,,,,,
660,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,4,d3clv0,self.MachineLearning,[N] Open-Unmix for Music Separation,https://www.reddit.com/r/MachineLearning/comments/d3clv0/n_openunmix_for_music_separation/,faroit,1568314852,"Paper: [https://joss.theoj.org/papers/571753bc54c5d6dd36382c3d801de41d](https://joss.theoj.org/papers/571753bc54c5d6dd36382c3d801de41d)  
Demo: [https://open.unmix.app](https://open.unmix.app)  
PyTorch: [https://github.com/sigsep/open-unmix-pytorch](https://github.com/sigsep/open-unmix-pytorch)  
NNabla: [https://github.com/sigsep/open-unmix-nnabla](https://github.com/sigsep/open-unmix-nnabla)  
TF2: t.b.a.   
Colab: [https://colab.research.google.com/drive/1mijF0zGWxN-KaxTnd0q6hayAlrID5fEQ](https://colab.research.google.com/drive/1mijF0zGWxN-KaxTnd0q6hayAlrID5fEQ) 

It is our great pleasure to announce the release of Open-unmix, a MIT-licensed python implementation for DNN-based music separation.

In the recent years, deep learning-based systems could break a long-standing crystal ceiling, and finally allow high-quality music separation. This provoked a raising interest from both the industry and the machine learning community (like /r/ML)

However, until now, no open-source implementation was available that matches the performance of the best systems proposed more than four years ago. This lead to a waste of time from both the points of view of sheer performance optimization and scientific comparison with the state of the art. Not being able to reproduce state of the art performance makes it difficult to clearly identify the sources for discrepancies and rooms for improvement.

In this context, we release Open-Unmix (UMX) as closing this gap by providing a reference implementation for DNN-based music separation. It serves two main purposes. First, it is intended to academic researchers for serving as a baseline method that is easy to compare to and build upon. Second, the availability of a pre-trained model allows bringing music separation to the enthusiastic end users and artists.

## Paper

Open-unmix is presented in a paper that has just been published in the Journal of Open Source Software. You may download the paper PDF [here](https://joss.theoj.org/papers/571753bc54c5d6dd36382c3d801de41d)

## Code

Open-unmix comes in several DNN frameworks:

* [Pytorch](https://github.com/sigsep/open-unmix-pytorch)
* [NNabla](https://github.com/sigsep/open-unmix-nnabla)
* tensorflow version will be released as soon as Tensorflow 2.0 is out.

## Website

* we provide extend documentation and further demos on the sigsep website.

[https://sigsep.github.io/open-unmix/](https://sigsep.github.io/open-unmix/)

## Datasets

Open-unmix has been especially designed to combine well with the following datasets:

* *MUSDB18* has become one of the most popular dataset in Source Separation and MIR. We provide full lengths music tracks (\~10h duration) of different genres along with their isolated drums, bass, vocals and others stems.
* *MUSDB18-HQ*: together with Open-Unmix, we also released an additional flavor of the dataset for models that aim to predict high bandwidth of up to 22 kHz. Other than that, MUSDB18-HQ is identical to MUSDB18.

=&gt; Both datasets are available at [https://sigsep.github.io/datasets/musdb.html](https://sigsep.github.io/datasets/musdb.html)

* Open-unmix also offers a variety of template dataset structures that should be appropriate for many [other use cases](https://github.com/sigsep/open-unmix-pytorch/blob/master/docs/training.md#other-datasets)

**Note**:

If you want to compare separation models to existing source separation literature or if want compare to SiSEC 2018 participants, please use the standard MUSDB18 dataset, instead.

## Pre-trained models

We provide pre-trained models trained on both `MUSDB18` and `MUSDB18-HQ` that reach state-of-the-art performance of 6.32 dB SDR (median of medians) on vocals on MUSDB18 test data. This significantly outperforms any model we are aware of that was trained on MUSDB18 only.

The pre-trained models are automatically bundled/downloaded when using the pytorch implementation.

Further information for both models such as evaluation scores can be downloaded from zenodo:

* umx: [https://doi.org/10.5281/zenodo.3370486](https://doi.org/10.5281/zenodo.3370486)
* umxhq: [https://doi.org/10.5281/zenodo.3370489](https://doi.org/10.5281/zenodo.3370489)

## Tutorial

Open-unmix was recently proposed during a tutorial held at EUSIPCO 2019. This features:

* A recent overview into current source separation method with a focus on deep learning
* A lecture on spectrogram models and wiener filtering
* Visualizations and results of Open-Unmix compared to state-of-the-art

The slides of the tutorial as well as self-contained colab notebooks can be found [on the tutorial site](https://sigsep.github.io/tutorials/#eusipco-2019-deep-learning-for-music-separation).

# Related tools

Open-unmix is part of a whole ecosystem enabling easy research on source separation for Python users. Several distinct and independent projects were released in the recent years in this effort to make it possible for researchers to reproduce state of the art performance in this domain.

## norbert

A reliable python package that implements the multichannel wiener filter and related filtering methods.

[https://github.com/sigsep/norbert](https://github.com/sigsep/norbert)

## musdb

We released the new version 0.3.0 of our popular musdb tools. This releases makes it simpler to use musdb inside your data loading framework thus we pro

[https://github.com/sigsep/sigsep-mus-db](https://github.com/sigsep/sigsep-mus-db)

## museval

museval makes it easy to compare the performance of any new method under investigation to both Open-unmix and the participants of SiSEC18.

[https://github.com/sigsep/sigsep-mus-eval](https://github.com/sigsep/sigsep-mus-eval)

## UMX-Pro

Please note that we are also working on some version of *open-unmix* that has been trained on a significantly larger dataset and that achieves unprecedented separation performance. Please feel free to contact us for demonstrations / industrial collaborations / licensing on this matter.

We look forward to your feedback and we hope that you will find Open-unmix useful!",11,66,False,self,,,,,
661,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,4,d3com4,self.MachineLearning,Productionizing a machine learning system,https://www.reddit.com/r/MachineLearning/comments/d3com4/productionizing_a_machine_learning_system/,azzipog,1568315161,[removed],0,1,False,self,,,,,
662,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,4,d3d82x,self.MachineLearning,How to create ML community of practice at workplace?,https://www.reddit.com/r/MachineLearning/comments/d3d82x/how_to_create_ml_community_of_practice_at/,chriskok1,1568317381,"My workplace has multiple communities of practice and I find them pretty useful. However, there aren't any revolving around ML/AI and I was hoping to create one of my own. I was wondering if you guys have any tips from your experience about creating one. 

A couple things that concern me:

1. How to appeal to the general public (the company is big but more so on engineering than software)
2. What talks or discussions would be useful to other folks interested in ML (even if it's not targeted to the general public)

How do you guys think I should approach this?",0,1,False,self,,,,,
663,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,4,d3dcku,github.com,ElasticDL: A Kubernetes-native Deep Learning Framework,https://www.reddit.com/r/MachineLearning/comments/d3dcku/elasticdl_a_kubernetesnative_deep_learning/,terrytangyuan,1568317903,,0,1,False,https://a.thumbs.redditmedia.com/m0OmrpJAc9pnKVhHXDJk_jRL-0LXRWIglouwAqUmn34.jpg,,,,,
664,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,6,d3ed0q,self.MachineLearning,How to start experimenting with ML in Python,https://www.reddit.com/r/MachineLearning/comments/d3ed0q/how_to_start_experimenting_with_ml_in_python/,Nexus9291,1568322070,[removed],0,1,False,self,,,,,
665,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,6,d3eonw,welcometothejungle.co,The beauty of functional languages in deep learning  Clojure and Haskell,https://www.reddit.com/r/MachineLearning/comments/d3eonw/the_beauty_of_functional_languages_in_deep/,j_orshman,1568323377,,0,1,False,default,,,,,
666,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,6,d3eqf6,self.MachineLearning,Masters in Artificial Intelligence and Sound/Music,https://www.reddit.com/r/MachineLearning/comments/d3eqf6/masters_in_artificial_intelligence_and_soundmusic/,sjibak,1568323586,[removed],0,1,False,self,,,,,
667,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,6,d3f4k6,artnome.com,Can AI Art Authentication Put An End To Art Forgery?,https://www.reddit.com/r/MachineLearning/comments/d3f4k6/can_ai_art_authentication_put_an_end_to_art/,hoopism,1568325261,,0,1,False,https://b.thumbs.redditmedia.com/OMMtFFpH3lGG_OacR39x-n8Gk3ZQ5jZeyI9TAwCHjkw.jpg,,,,,
668,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,7,d3fdtp,self.MachineLearning,"[P][D] Anyone working with a data pipeline of CPU -&gt; GPU? I am developing a library of methods for faster transfer to GPU. In some cases, 370x faster than used Pytorch's Pinned CPU Tensors. Let me know what your pipeline is and I'll try to add methods for it. Just show me your code.",https://www.reddit.com/r/MachineLearning/comments/d3fdtp/pd_anyone_working_with_a_data_pipeline_of_cpu_gpu/,BatmantoshReturns,1568326376,"I am developing methods for fast transfer from CPU and GPU, and currently coding the methods for it. Show me your code (A Colab notebook would be really helpful) and I'll see how to incorporate the library into it, for faster data transfer.",30,29,False,self,,,,,
669,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,7,d3fvy1,self.MachineLearning,Looking for Engineering Help for a Food Industry Project,https://www.reddit.com/r/MachineLearning/comments/d3fvy1/looking_for_engineering_help_for_a_food_industry/,fennelfrond,1568328656,[removed],0,1,False,self,,,,,
670,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,8,d3g9vb,self.MachineLearning,"Machine learning , and writing stories",https://www.reddit.com/r/MachineLearning/comments/d3g9vb/machine_learning_and_writing_stories/,Nul_Atlas,1568330424,[removed],0,1,False,self,,,,,
671,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,8,d3glm0,self.MachineLearning,"Big dataset for multi-class classification can't be dasked and split, normal one can't be handled",https://www.reddit.com/r/MachineLearning/comments/d3glm0/big_dataset_for_multiclass_classification_cant_be/,MikeREDDITR,1568331943,[removed],0,1,False,self,,,,,
672,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,9,d3gt2a,self.MachineLearning,How to get best accuracy on a single class for CIFAR10,https://www.reddit.com/r/MachineLearning/comments/d3gt2a/how_to_get_best_accuracy_on_a_single_class_for/,davidblyrics,1568332918,[removed],0,1,False,self,,,,,
673,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,9,d3hbw1,github.com,JesseAI or Jesse Artificial Intelligence a GOFAI Open Source and written in C++,https://www.reddit.com/r/MachineLearning/comments/d3hbw1/jesseai_or_jesse_artificial_intelligence_a_gofai/,TheDeermanLives,1568335439,,0,1,False,https://b.thumbs.redditmedia.com/ojVOFv1T_jjpONzThESp6l-UK7NESVewEszAO5H_haM.jpg,,,,,
674,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,10,d3i4z4,ai.googleblog.com,Using Deep Learning to Inform Differential Diagnoses of Skin Diseases,https://www.reddit.com/r/MachineLearning/comments/d3i4z4/using_deep_learning_to_inform_differential/,sjoerdapp,1568339381,,0,1,False,https://b.thumbs.redditmedia.com/R_irVFk1y8ustdmIZ66holJU3NMkxulnvtAjD8Szino.jpg,,,,,
675,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,11,d3issb,self.MachineLearning,Need to understand the requirement since late registration,https://www.reddit.com/r/MachineLearning/comments/d3issb/need_to_understand_the_requirement_since_late/,RioChenRio,1568342686,[removed],0,1,False,https://b.thumbs.redditmedia.com/QcaE7hUzkC3IuodKID2TGefW5CYC9lag5YtF-4nQujc.jpg,,,,,
676,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,11,d3ivz1,self.MachineLearning,Low Quality ML papers,https://www.reddit.com/r/MachineLearning/comments/d3ivz1/low_quality_ml_papers/,ArkGuardian,1568343148,[removed],0,1,False,self,,,,,
677,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,12,d3j3ca,arxiv.org,[R] Depth from Videos in the Wild: Unsupervised Monocular Depth Learning from Unknown Cameras,https://www.reddit.com/r/MachineLearning/comments/d3j3ca/r_depth_from_videos_in_the_wild_unsupervised/,tsauri,1568344224,,3,18,False,default,,,,,
678,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,12,d3j4b6,arxiv.org,[R] Learning Single Camera Depth Estimation using Dual-Pixels,https://www.reddit.com/r/MachineLearning/comments/d3j4b6/r_learning_single_camera_depth_estimation_using/,tsauri,1568344373,,1,6,False,default,,,,,
679,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,14,d3kkqz,medium.com,Not All Machine Learning Systems Are Created Equal,https://www.reddit.com/r/MachineLearning/comments/d3kkqz/not_all_machine_learning_systems_are_created_equal/,madhu_SEO,1568352142,,0,1,False,default,,,,,
680,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,14,d3krwj,self.MachineLearning,Integrating Multilingual Chatbots,https://www.reddit.com/r/MachineLearning/comments/d3krwj/integrating_multilingual_chatbots/,getengati,1568353357,[removed],0,1,False,self,,,,,
681,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,14,d3kunb,self.MachineLearning,[P] production with Linux or Docker?,https://www.reddit.com/r/MachineLearning/comments/d3kunb/p_production_with_linux_or_docker/,Uysim,1568353849,"I tried to deploy my Keras model to server with flask. I try to track the memory on my local. 

I found out if I use pure linux server the python take only 200MB of RAM

But if I deploy it with docker. I need 800MB of RAM.

Any suggestion? should I deploy it with docker or pure linux server?",18,0,False,self,,,,,
682,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,15,d3la31,medium.com,Conversational AI: The Advanced Form of Chatbots,https://www.reddit.com/r/MachineLearning/comments/d3la31/conversational_ai_the_advanced_form_of_chatbots/,GreenScheme7,1568356656,,0,1,False,default,,,,,
683,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,16,d3llmu,self.MachineLearning,Face Detection Problem,https://www.reddit.com/r/MachineLearning/comments/d3llmu/face_detection_problem/,zom8ie99,1568358789,[removed],0,1,False,https://b.thumbs.redditmedia.com/8tBT_JsJwIHEM10MtERPzUW5IOY-B9haoqaF50c1jxM.jpg,,,,,
684,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,16,d3lo3r,self.MachineLearning,[D] Quantum search applicability to machine learning,https://www.reddit.com/r/MachineLearning/comments/d3lo3r/d_quantum_search_applicability_to_machine_learning/,trenobus,1568359233,"I was just [reading](https://www.technologyreview.com/s/614259/an-important-quantum-algorithm-may-actually-be-a-property-of-nature/) about a hypothesis that quantum search might be common in nature. If it is leveraged in the brain, perhaps that might increase the biological plausibility of Hinton's capsules. In particular I'm wondering if EM routing between capsules might be implemented as quantum search.

Another possibility is a quantum search encompassing multiple layers of neurons to find weights that minimize the cost function, without the need for back-propagation. But unless nature has some secret for maintaining quantum coherence over large structures, it seems more likely that quantum search would operate more locally.",5,3,False,self,,,,,
685,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,16,d3lvrv,self.MachineLearning,[P] Specifying Object Attributes and Relations in Interactive Scene Generation,https://www.reddit.com/r/MachineLearning/comments/d3lvrv/p_specifying_object_attributes_and_relations_in/,mrm8488,1568360743,[removed],0,1,False,self,,,,,
686,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,18,d3mnub,self.MachineLearning,Transfer learning with NLP on different context using Pytorch,https://www.reddit.com/r/MachineLearning/comments/d3mnub/transfer_learning_with_nlp_on_different_context/,genuinenewb,1568366594,[removed],0,1,False,self,,,,,
687,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,18,d3mu5d,self.MachineLearning,machine learning,https://www.reddit.com/r/MachineLearning/comments/d3mu5d/machine_learning/,prakashyadav008,1568367856,[removed],0,1,False,self,,,,,
688,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,18,d3myqg,self.MachineLearning,[D] Do people use meta learning in production?,https://www.reddit.com/r/MachineLearning/comments/d3myqg/d_do_people_use_meta_learning_in_production/,tsauri,1568368709,Finetuning from pretrained models seem way easier and straightforward.,36,91,False,self,,,,,
689,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,19,d3n6jf,self.MachineLearning,Looking for more CoreML/iOS tutorials that actually show learning on the device.,https://www.reddit.com/r/MachineLearning/comments/d3n6jf/looking_for_more_coremlios_tutorials_that/,KarlJay001,1568370080,[removed],0,1,False,self,,,,,
690,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,19,d3n7n4,self.MachineLearning,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/MachineLearning/comments/d3n7n4/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1568370277,[removed],0,1,False,self,,,,,
691,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,19,d3nhb7,self.MachineLearning,How do i switch from local or UTC timezone to GMT?,https://www.reddit.com/r/MachineLearning/comments/d3nhb7/how_do_i_switch_from_local_or_utc_timezone_to_gmt/,badmrsynth,1568371999,[removed],0,1,False,self,,,,,
692,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,19,d3nhj3,self.MachineLearning,"[R] Salesforce releases CTRL, the largest publicly available language model with 1.6B parameters",https://www.reddit.com/r/MachineLearning/comments/d3nhj3/r_salesforce_releases_ctrl_the_largest_publicly/,wei_jok,1568372030,"*CTRL: A Conditional Transformer Language Model for Controllable Generation*

*Abstract (looks to be an ICLR submission)*

Large-scale language models show promising text generation capabilities, but users cannot easily control particular aspects of the generated text. We release CTRL, a 1.6 billion-parameter conditional transformer language model, trained to condition on control codes that govern style, content, and task-specific behavior. Control codes were derived from structure that naturally co-occurs with raw text, preserving the advantages of unsupervised learning while providing more explicit control over text generation. These codes also allow CTRL to predict which parts of the training data are most likely given a sequence. This provides a potential method for analyzing large amounts of data via model-based source attribution.

blog post: https://blog.einstein.ai/introducing-a-conditional-transformer-language-model-for-controllable-generation/

model release: https://github.com/salesforce/ctrl",0,1,False,self,,,,,
693,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,19,d3nil6,blog.analyticspath.com,WORKING WITH MACHINE LEARNING SUPERVISED &amp; UNSUPERVISED MACHINE LEARNING EXPLAINED,https://www.reddit.com/r/MachineLearning/comments/d3nil6/working_with_machine_learning_supervised/,Jony1223,1568372215,,0,1,False,default,,,,,
694,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,20,d3nnte,cs231n.stanford.edu,Developing a Real-Time Gun Detection Classifier,https://www.reddit.com/r/MachineLearning/comments/d3nnte/developing_a_realtime_gun_detection_classifier/,Iam_nameless,1568373052,,9,19,False,default,,,,,
695,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,20,d3o6f9,data-flair.training,Python for Machine Learning - Know its importance in Machine Learning Projects,https://www.reddit.com/r/MachineLearning/comments/d3o6f9/python_for_machine_learning_know_its_importance/,AnujG23,1568375945,,0,1,False,default,,,,,
696,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,21,d3odje,self.MachineLearning,Evolution of Representations in the Transformer,https://www.reddit.com/r/MachineLearning/comments/d3odje/evolution_of_representations_in_the_transformer/,justheuristic,1568376945,[removed],0,1,False,self,,,,,
697,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,21,d3odsk,self.MachineLearning,How You can Control Fluid/Flow in your Machinery?,https://www.reddit.com/r/MachineLearning/comments/d3odsk/how_you_can_control_fluidflow_in_your_machinery/,uflowindia,1568376985,[removed],0,1,False,https://b.thumbs.redditmedia.com/TeR7GxZCu65W8vMMYnMNozmIZXLce7NRqoWFz_WOlIY.jpg,,,,,
698,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,21,d3og46,self.MachineLearning,[R] Evolution of representations in the Transformer,https://www.reddit.com/r/MachineLearning/comments/d3og46/r_evolution_of_representations_in_the_transformer/,justheuristic,1568377311,"A paper that explains what representations do transformer models actually learn for machine translation, language modelling  and BERT-like training.

Arxiv: [https://arxiv.org/abs/1909.01380](https://arxiv.org/abs/1909.01380) (EMNLP19, E. Voita et al.)

Blog post: [https://lena-voita.github.io/posts/emnlp19\_evolution.html](https://lena-voita.github.io/posts/emnlp19_evolution.html)",0,8,False,self,,,,,
699,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,22,d3petc,self.MachineLearning,Machine learning as a tool to grow sales in telemarketing operations,https://www.reddit.com/r/MachineLearning/comments/d3petc/machine_learning_as_a_tool_to_grow_sales_in/,SebastianVasq,1568381986,"Hi, I made a small article about machine learning and how it can mediate communications between humans in a telemarketing context. let me know your comments. Thank you!

[https://sourcemeridian.com/machine-learning-as-a-tool-to-grow-sales-in-telemarketing-operations/](https://sourcemeridian.com/machine-learning-as-a-tool-to-grow-sales-in-telemarketing-operations/)",0,1,False,self,,,,,
700,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,22,d3pm3o,self.MachineLearning,Running on embedded hardware,https://www.reddit.com/r/MachineLearning/comments/d3pm3o/running_on_embedded_hardware/,TemporaryUser10,1568382924,[removed],0,1,False,self,,,,,
701,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,22,d3pmx1,insights.dice.com,Machine Learning Engineers: How Much Can They Make?,https://www.reddit.com/r/MachineLearning/comments/d3pmx1/machine_learning_engineers_how_much_can_they_make/,BrooklynShatterDome,1568383039,,0,1,False,default,,,,,
702,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,23,d3pvz8,self.MachineLearning,How Much Can Machine Learning Engineers Make? [News],https://www.reddit.com/r/MachineLearning/comments/d3pvz8/how_much_can_machine_learning_engineers_make_news/,BrooklynShatterDome,1568384200,[removed],0,1,False,self,,,,,
703,MachineLearning,t5_2r3gv,2019-9-13,2019,9,13,23,d3pxof,self.MachineLearning,time series data modeling for deep learning,https://www.reddit.com/r/MachineLearning/comments/d3pxof/time_series_data_modeling_for_deep_learning/,faratb,1568384396,[removed],0,1,False,self,,,,,
704,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,0,d3qn9l,reddit.com,A Deep Neural Network to Predict the Outcome of the Great British Bake Off,https://www.reddit.com/r/MachineLearning/comments/d3qn9l/a_deep_neural_network_to_predict_the_outcome_of/,TRUMP_HAS_A_BIG_DICK,1568387489,,0,1,False,default,,,,,
705,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,0,d3qtc0,self.MachineLearning,[D] Does anyone know of an example of model for translating acronyms?,https://www.reddit.com/r/MachineLearning/comments/d3qtc0/d_does_anyone_know_of_an_example_of_model_for/,Secret_Identity_,1568388194,"I have a huge corpus of documents that are filled with acronyms. It is mostly government stuff. Currently we use regex to translates, but the regex performs poorly and requires a lot of manual fixing. I haven't been able to google this question (it just brings up lists of machine learning/deep learning acronyms).",17,9,False,self,,,,,
706,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,0,d3qvco,kaggle.com,Lyft Kaggle Challenge: 3D Object Detection For Autonomous Vehicles,https://www.reddit.com/r/MachineLearning/comments/d3qvco/lyft_kaggle_challenge_3d_object_detection_for/,mystikaldanger,1568388431,,0,1,False,default,,,,,
707,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,0,d3r04e,kaggle.com,[D] Lyft Kaggle Challenge: 3D Object Detection for Autonomous Vehicles,https://www.reddit.com/r/MachineLearning/comments/d3r04e/d_lyft_kaggle_challenge_3d_object_detection_for/,SpecificTwo,1568388996,,0,1,False,https://b.thumbs.redditmedia.com/8q2pVcs357XZo2R1dnvMHpLWdPwS9lN4roFSJu4QkBQ.jpg,,,,,
708,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,1,d3re7n,kaggle.com,[N] Lyft Kaggle Challenge: 3D Object Detection for Autonomous Vehicles,https://www.reddit.com/r/MachineLearning/comments/d3re7n/n_lyft_kaggle_challenge_3d_object_detection_for/,SpecificTwo,1568390612,,0,1,False,default,,,,,
709,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,1,d3ricn,youtu.be,[P] New video on morphing faces with StyleGAN + Google Colab notebook to experiment for yourself!!,https://www.reddit.com/r/MachineLearning/comments/d3ricn/p_new_video_on_morphing_faces_with_stylegan/,tr1pzz,1568391078,,0,1,False,https://a.thumbs.redditmedia.com/rZw0c2yEb-jOKStLO3JRDUaXCbsD6MIEZmZTTtuPy74.jpg,,,,,
710,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,2,d3sb30,i.redd.it,Deep Learning for EMC tests,https://www.reddit.com/r/MachineLearning/comments/d3sb30/deep_learning_for_emc_tests/,istemihan90,1568394425,,0,1,False,default,,,,,
711,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,2,d3sh62,self.MachineLearning,Deep Learning for EMC tests,https://www.reddit.com/r/MachineLearning/comments/d3sh62/deep_learning_for_emc_tests/,istemihan90,1568395142,[removed],0,1,False,https://b.thumbs.redditmedia.com/mpyOXX8WKgeWlJfdUgPkadIp7mwVlke03r3UV5QWBxo.jpg,,,,,
712,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,2,d3smff,self.MachineLearning,Azure ML&gt;&gt; Adding Concrete Rules?,https://www.reddit.com/r/MachineLearning/comments/d3smff/azure_ml_adding_concrete_rules/,danang1986,1568395775,[removed],0,1,False,self,,,,,
713,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,2,d3sp8x,youtube.com,Machine Learning Complete Elite Course:- made with research on scientific learning also includes a capstone project you can choose between programming languages R and Python,https://www.reddit.com/r/MachineLearning/comments/d3sp8x/machine_learning_complete_elite_course_made_with/,ShyamTgr,1568396102,,3,0,False,https://b.thumbs.redditmedia.com/t9KaZReYrHCrGehOU_Pb07HSYqBlBgc_36TRuoqpK8k.jpg,,,,,
714,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,2,d3spj2,self.MachineLearning,Supervised classification using metadata categorical data + time series?,https://www.reddit.com/r/MachineLearning/comments/d3spj2/supervised_classification_using_metadata/,CorerMaximus,1568396131,[removed],0,1,False,self,,,,,
715,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,3,d3top6,self.MachineLearning,Papers on Active/Steerable cameras/sensors?,https://www.reddit.com/r/MachineLearning/comments/d3top6/papers_on_activesteerable_camerassensors/,soulslicer0,1568400367,[removed],0,1,False,self,,,,,
716,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,4,d3u2ou,self.MachineLearning,[D] looking for ML theory researchers,https://www.reddit.com/r/MachineLearning/comments/d3u2ou/d_looking_for_ml_theory_researchers/,tdls_to,1568402049,"hello, I'm looking for researchers who work on the theoretical side of ML (learning theory, privacy, architecture search and model compression, etc) to speak in remote spotlight sessions. For context, we have been creating a large repository of ML papers turned into in-depth discussion videos ([YouTube channel](https://www.youtube.com/c/AISocraticCirclesAISC?view_as=subscriber&amp;sub_confirmation=1), [website](https://aisc.ai.science/events)), and recently started inviting paper authors to speak about their work remotely. This would be a great contribution to the ML community, but also a good way to get exposure for your work.

If interested, please email us ([events@ai.science](mailto:events@ai.science)), DM here, comment on this, idk make some sort of noise so that I know you're out there, and let's talk.

commitment:

* prepare a 20-30 mins talk about one of your papars
* spend 20-30 mins in Q&amp;A with the session moderator and the audience (through live chat read to you by the moderator)
* hop on a video call with us, share your screen, bam!",1,2,False,self,,,,,
717,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,4,d3u4um,self.MachineLearning,RNNs and reinforcement learning.,https://www.reddit.com/r/MachineLearning/comments/d3u4um/rnns_and_reinforcement_learning/,xicor7017,1568402307,[removed],0,1,False,self,,,,,
718,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,4,d3u5zo,quora.com,Quroa: Using natural language models for question correction,https://www.reddit.com/r/MachineLearning/comments/d3u5zo/quroa_using_natural_language_models_for_question/,tomtung,1568402446,,0,1,False,default,,,,,
719,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,4,d3u8ja,self.MachineLearning,My AI Pathway sources/books/videos,https://www.reddit.com/r/MachineLearning/comments/d3u8ja/my_ai_pathway_sourcesbooksvideos/,tzersh,1568402754,[removed],0,1,False,self,,,,,
720,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,4,d3u9x1,self.MachineLearning,[P] RNNs and Reinforcement learning,https://www.reddit.com/r/MachineLearning/comments/d3u9x1/p_rnns_and_reinforcement_learning/,xicor7017,1568402917,"Keep in mind that I am still in the early phase of learning ML. I cannot disclose the exact task/problem I am working on (not related to NLP), but the below task captures the essence of it.

(REINFORCEMENT LEARNING)

Input - A paragraph written in English.

Output - On a scale of 1-10 (continuous/not discrete scale) predict the level of English of each sentence. For example, My English is poor should score better than I have bad English. Even though both are grammatically correct.

Example input: Hey! how are you? It has been so long since I last saw you.

Example output: \[5.544554, 5.890909\] (made up numbers)

&amp;#x200B;

My approach:

1. Encode each word. (fixed length if that matters)
2. Break paragraph into sentences, because prediction for a sentence will not depend upon other sentences.
3. Pad every sentence so that they have same length.
4. For every sentence:

i. Pass each word of the sentence to a RNN encoder, And extract the hidden state corresponding to the last word (before padding). (for example: Sentence: i am fine padded\_word padded\_word, RNN output: \[A,B,C,D,E\] so I extract RNN output/hidden\_state C. (not sure if this is the right thing to do)

j.  Pass this hidden state C to RNN decoder, which makes the prediction. This prediction leads to a reward.

5. Use PPO (proximal policy optimization) to solve the problem.

&amp;#x200B;

I hope this is clear and am sorry for being so vague about my problem. If it matters, I have a few fully connected layers between encoder and decoder.

Any help would be highly appreciated.",6,0,False,self,,,,,
721,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,4,d3ungz,self.MachineLearning,System building,https://www.reddit.com/r/MachineLearning/comments/d3ungz/system_building/,msamhat,1568404527,[removed],0,1,False,self,,,,,
722,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,5,d3uub6,deepfakedetectionchallenge.ai,"Moving Deep Fake detection forward; Facebook, Microsoft pledging millions.",https://www.reddit.com/r/MachineLearning/comments/d3uub6/moving_deep_fake_detection_forward_facebook/,jhernandez_1,1568405329,,0,1,False,https://b.thumbs.redditmedia.com/IK2T4is6-NGpune03T4cR3sLWbiIxhrJ90WD6Fpei3k.jpg,,,,,
723,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,5,d3uzi6,blog.produvia.com,Artificial Intelligence (AI) in Aerospace,https://www.reddit.com/r/MachineLearning/comments/d3uzi6/artificial_intelligence_ai_in_aerospace/,slavakurilyak,1568405975,,0,1,False,https://b.thumbs.redditmedia.com/gaLCPrsAhBg2lSCRFPMuaOwILSHYmNtpUIILMQZXt9A.jpg,,,,,
724,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,5,d3v0li,webinars.on24.com,"October 8 Talk with HCI Pioneer Joseph Constan: ""Recommender Systems: Beyond Machine Learning""",https://www.reddit.com/r/MachineLearning/comments/d3v0li/october_8_talk_with_hci_pioneer_joseph_constan/,ACMLearning,1568406102,,1,1,False,default,,,,,
725,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,5,d3vcbr,self.MachineLearning,master's thesis based on machine learning,https://www.reddit.com/r/MachineLearning/comments/d3vcbr/masters_thesis_based_on_machine_learning/,salkhamisi775,1568407540,[removed],0,1,False,self,,,,,
726,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,6,d3vj8u,self.MachineLearning,[R] AC-Teach: A Bayesian Actor-Critic Method for Policy Learning with an Ensemble of Suboptimal Teachers,https://www.reddit.com/r/MachineLearning/comments/d3vj8u/r_acteach_a_bayesian_actorcritic_method_for/,regalalgorithm,1568408405,"When looking at RL training, it's often frustrating to see the agent taking so long to discover simple things you could code up yourself for parts of the task. This work takes that idea as it basis - if you code up some solutions to parts of the problem, how do you incorporate that into RL training? Turns out it's a little tricky...            

Arxiv: [https://arxiv.org/abs/1909.04121](https://arxiv.org/abs/1909.04121) (CORL 2019)

Blog post: [http://ai.stanford.edu/blog/acteach/](http://ai.stanford.edu/blog/acteach/)  


(hope posting own papers is kosher, open to answering any questions!)",6,48,False,self,,,,,
727,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,6,d3vwue,self.MachineLearning,Evagents v0.04: C++ GitHub project simulating Natural Selection using a self-layered neural network to survive.,https://www.reddit.com/r/MachineLearning/comments/d3vwue/evagents_v004_c_github_project_simulating_natural/,GhengopelALPHA,1568410130,[removed],0,1,False,self,,,,,
728,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,6,d3wadw,self.MachineLearning,Anyone has built an AI beauty context jet? Which tools to use to start built one that works by submitting a photo to it and have it ranked?,https://www.reddit.com/r/MachineLearning/comments/d3wadw/anyone_has_built_an_ai_beauty_context_jet_which/,bodytexture,1568411861,[removed],0,1,False,self,,,,,
729,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,7,d3whsw,youtu.be,"Elon Musk: Computers are much smarter than humans on so many dimensions. Jack Ma: Computers may be clever, but human beings are much smarter. We invented the computerI've never seen a computer invent a human being",https://www.reddit.com/r/MachineLearning/comments/d3whsw/elon_musk_computers_are_much_smarter_than_humans/,Angelinatrump,1568412811,,0,1,False,https://b.thumbs.redditmedia.com/9AiO0anYSjlclayvAe1crWxbdO0lDqZmVSPWlwbG1Wc.jpg,,,,,
730,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,7,d3wk0q,self.MachineLearning,[D]Problems with ML models that are not reproducible/junk etc.,https://www.reddit.com/r/MachineLearning/comments/d3wk0q/dproblems_with_ml_models_that_are_not/,MLtinkerer,1568413099,Any one here encountered ML models that you tried to implement but were junk/not reproducible? Or in general had a bad experience with open-source ML models?,11,2,False,self,,,,,
731,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,8,d3xoz2,self.MachineLearning,"Hey Reddit Machine Learners, do you model for a living? Be part of a ML/DL user research study and get a cool AI t-shirt every month.",https://www.reddit.com/r/MachineLearning/comments/d3xoz2/hey_reddit_machine_learners_do_you_model_for_a/,Mikmik303,1568418528,"We are looking for full-time data scientists for a ML/DL user study. You'll be participating in a calibrated user research experiment for 45 minutes. The study will be done over a video call. We've got plenty of funny tees that you can show-off to your teammates. We'll ship you a different one every month for a year.

Click [here](https://typings.typeform.com/to/zpYrlW) to learn more.

P.S: We love the reddit vibe and this community. Give us your best ML/DL/Data Science quote to put on t-shirt. We'll make one and ship it you if it's quirky and fun even if you aren't part of the study group.",0,1,False,self,,,,,
732,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,9,d3xu1d,self.MachineLearning,"[R] Hey Reddit Machine Learners, do you model for a living? Be part of a ML/DL user research study and get a cool AI t-shirt every month.",https://www.reddit.com/r/MachineLearning/comments/d3xu1d/r_hey_reddit_machine_learners_do_you_model_for_a/,Mikmik303,1568419239,"We are looking for full-time data scientists for a ML/DL user study. You'll be participating in a calibrated user research experiment for 45 minutes. The study will be done over a video call. We've got plenty of funny tees that you can show-off to your teammates. We'll ship you a different one every month for a year.

Click [here](https://typings.typeform.com/to/zpYrlW) to learn more.

P.S: We love the reddit vibe and this community. Give us your best ML/DL/Data Science quote. We'll make one and ship it you if it's quirky and fun even if you aren't part of the study group.",8,0,False,self,,,,,
733,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,9,d3xukp,self.MachineLearning,What unsolved math problems are related to machine learning?,https://www.reddit.com/r/MachineLearning/comments/d3xukp/what_unsolved_math_problems_are_related_to/,2334851,1568419329,[removed],0,1,False,self,,,,,
734,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,9,d3xvzx,self.MachineLearning,[D] What difficult math concepts come up most in papers? Looking for a topic to write my undergraduate math thesis on.,https://www.reddit.com/r/MachineLearning/comments/d3xvzx/d_what_difficult_math_concepts_come_up_most_in/,bogedy,1568419569,"Hi r/ml. I hope this isn't the kind of post that is unwelcome here but I thought maybe you guys could help give me some pointers. I am an undergraduate senior and I will be spending this year writing a capstone math thesis. I need to identify topics that I can propose to my department. They need to be topics that are in the scope of classical statistics, algorithmic analysis, or probability. It can't be something that is more the domain of computer science, like network architecture.

I was wondering if there are any topics you guys think are important or foundational to other concepts that are important in ML. I spent the last summer researching variational autoencoders and became familiar with variational expectation maximization. This is something I'm excited about, but I'm looking for other ideas as well.

I guess another way of asking this question is: what are the parts of papers that you wished you knew more about? What math concepts come up a lot and are hard to understand?

Thanks for the help, and again sorry if this is the wrong place to ask.",20,27,False,self,,,,,
735,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,9,d3xwc5,i.redd.it,Using an image analogy [P]rogram and my images have these colored dots (idk how else to describe it) that makes it look like its behind glass. Any ideas how to fix it?,https://www.reddit.com/r/MachineLearning/comments/d3xwc5/using_an_image_analogy_program_and_my_images_have/,Danbradford7,1568419622,,0,1,False,default,,,,,
736,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,12,d403k7,self.MachineLearning,The Machine Learning Data Science Path,https://www.reddit.com/r/MachineLearning/comments/d403k7/the_machine_learning_data_science_path/,KamWithK,1568432031,[removed],0,1,False,self,,,,,
737,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,13,d40juv,self.MachineLearning,[D] US Patent Office: Request for Comments on Patenting Artificial Intelligence Inventions,https://www.reddit.com/r/MachineLearning/comments/d40juv/d_us_patent_office_request_for_comments_on/,wei_jok,1568434884,"Theres been many popular posts on this subreddit regarding patents on well known ML techniques. Here is your chance to voice your concerns to the US patent office.

**Request for Comments on Patenting Artificial Intelligence Inventions**

https://www.federalregister.gov/documents/2019/08/27/2019-18443/request-for-comments-on-patenting-artificial-intelligence-inventions

**AGENCY:**

United States Patent and Trademark Office, Department of Commerce.

**ACTION:**

Request for comments.

**SUMMARY:**

The United States Patent and Trademark Office (USPTO) is interested in gathering information on patent-related issues regarding artificial intelligence inventions for purposes of evaluating whether further examination guidance is needed to promote the reliability and predictability of patenting artificial intelligence inventions. To assist in gathering this information, the USPTO is publishing questions on artificial intelligence inventions to obtain written comments from the public. The questions are designed to cover a variety of topics from patent examination policy to whether new forms of intellectual property protection are needed.

**DATES:**

Written comments must be received on or before October 11, 2019.",67,283,False,self,,,,,
738,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,14,d411ey,data-flair.training,Why is Machine Learning so Popular? - From a Techno Geek's Diary,https://www.reddit.com/r/MachineLearning/comments/d411ey/why_is_machine_learning_so_popular_from_a_techno/,AnujG23,1568438132,,0,1,False,default,,,,,
739,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,14,d416pt,federalregister.gov,Request for Comments on Patenting Artificial Intelligence Inventions,https://www.reddit.com/r/MachineLearning/comments/d416pt/request_for_comments_on_patenting_artificial/,whereistimbo,1568439144,,0,1,False,https://a.thumbs.redditmedia.com/KIEsg8ncR26rl7uInxfmoL3vz06Csr7s5ANY-6_wXJ0.jpg,,,,,
740,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,15,d41fme,analyticsinsight.net,MIT Researchers Introduced ML-Powered RiskCardio System To Predict Cardiovascular Death,https://www.reddit.com/r/MachineLearning/comments/d41fme/mit_researchers_introduced_mlpowered_riskcardio/,analyticsinsight,1568440917,,0,1,False,default,,,,,
741,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,15,d41fzb,solaceinfotech.com,Best Machine Learning Software and Tools To Learn in 2019,https://www.reddit.com/r/MachineLearning/comments/d41fzb/best_machine_learning_software_and_tools_to_learn/,SolaceInfotech,1568440974,,0,1,False,default,,,,,
742,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,16,d420bt,self.MachineLearning,"How You Can Control Compressed Air, Filtration, Lubrication? -Here Is Your Answer.",https://www.reddit.com/r/MachineLearning/comments/d420bt/how_you_can_control_compressed_air_filtration/,uflowindia,1568445116,[removed],0,1,False,self,,,,,
743,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,16,d424o7,self.MachineLearning,[D] What are the different roles in companies for ML engineers/scientists and how do they compare?,https://www.reddit.com/r/MachineLearning/comments/d424o7/d_what_are_the_different_roles_in_companies_for/,bay_der,1568446010,"Companies have different roles for ML engineers/scientists, I have seen Data Scientist (at Flipkart (comes under Walmart)), Applied Scientist at Amazon and Software Engineer at Google.

As a fresh out of college, I wanted to know how much do these role matter? Is Applied Scientist a better role than Data Scientist? Are there another roles?",6,2,False,self,,,,,
744,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,17,d42twi,i.redd.it,An IT Company,https://www.reddit.com/r/MachineLearning/comments/d42twi/an_it_company/,microsmart,1568451554,,0,1,False,https://b.thumbs.redditmedia.com/81fEEGCVkUmE_5db9p6IZ27N0B3kSzPFNQkKPabec1c.jpg,,,,,
745,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,18,d42y87,self.MachineLearning,How to measure/predict volatility of a time series?,https://www.reddit.com/r/MachineLearning/comments/d42y87/how_to_measurepredict_volatility_of_a_time_series/,orgad,1568452486,[removed],0,1,False,self,,,,,
746,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,18,d42ydz,self.MachineLearning,difference betting bagging and boosting,https://www.reddit.com/r/MachineLearning/comments/d42ydz/difference_betting_bagging_and_boosting/,Harsha_kulkarni,1568452527,[removed],0,1,False,self,,,,,
747,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,19,d43jnv,self.MachineLearning,Practical beginner courses for learning ML in python,https://www.reddit.com/r/MachineLearning/comments/d43jnv/practical_beginner_courses_for_learning_ml_in/,rahull95,1568457189,[removed],0,1,False,self,,,,,
748,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,20,d43uej,self.MachineLearning,[R] Replace VAE dense layer with 1x1x1 Convolutional layer,https://www.reddit.com/r/MachineLearning/comments/d43uej/r_replace_vae_dense_layer_with_1x1x1/,Pubec,1568459430,"Hi!

I have a Variational autoencoder model created in Keras.  
Encoder is built with three 3D Convolutional layers + Flatten + Dense layer. Decoder is built with three 3D Transposed Convolutional layers to reconstruct the input 3D images.

My goal is to replace Flatten and Dense layer in Encoder with 1x1x1 Convolutional layer. Any ideas how to do that?

My model structure looks like this:

        original_dim = np.prod(np.array(original_shape))

    input_shape = (
         original_shape[0],
         original_shape[1],
         original_shape[2],
         1)

        latent_dim = 100

    def sampling(args):
        """"""Reparameterization trick by sampling fr an isotropic unit Gaussian.

        Arguments:
            args {tensor} -- mean and log of variance of Q(z|X)
        Returns:
            z {tensor} -- sampled latent vector
        """"""
    
        z_mean, z_log_var = args
        batch = K.shape(z_mean)[0]
        dim = K.int_shape(z_mean)[1]
        epsilon = K.random_normal(shape=(batch, dim))
    
        return z_mean + K.exp(0.5 * z_log_var) * epsilon

    # Encoder
    inputs = Input(shape=input_shape, name='encoder_input')
    x = inputs

    x = Conv3D(filters=32, kernel_size=3, activation='relu', strides=1,
               padding='same')(x)
    x = Conv3D(filters=64, kernel_size=3, activation='relu', strides=2,
               padding='same')(x)
    x = Conv3D(filters=128, kernel_size=3, activation='relu', strides=2,
               padding='same')(x)

    shape = K.int_shape(x)

    x = Flatten()(x)
    x = Dense(latent_dim, activation='relu')(x)
    z_mean = Dense(latent_dim, name='z_mean')(x)
    z_log_var = Dense(latent_dim, name='z_log_var')(x)

    z = Lambda(sampling,
               output_shape=(latent_dim,),
               name='z')([z_mean, z_log_var])

    encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')

     # Decoder
    latent_inputs = Input(shape=(latent_dim,), name='z_sampling')
    x = Dense(shape[1] * shape[2] * shape[3] * shape[4],
             activation='relu')(latent_inputs)
    x = Reshape((shape[1], shape[2], shape[3], shape[4]))(x)

    x = Conv3DTranspose(filters=128, kernel_size=3, activation='relu',
                         strides=2, padding='same')(x)
    x = Conv3DTranspose(filters=64, kernel_size=3, activation='relu',
                         strides=2, padding='same')(x)
    x = Conv3DTranspose(filters=32, kernel_size=3, activation='relu',
                         strides=1, padding='same')(x)

    outputs = Conv3DTranspose(filters=1, kernel_size=3, strides=1,
                              activation='sigmoid', padding='same',
                              name='decoder_output')(x)

    decoder = Model(latent_inputs, outputs, name='decoder')
    decoder.summary()

    outputs = decoder(encoder(inputs)[2])
        vae = Model(inputs, outputs, name='vae')

    reconstruction_loss = mse(K.flatten(inputs), K.flatten(outputs))

    reconstruction_loss *= original_dim
    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)
    kl_loss = K.sum(kl_loss, axis=-1)
    kl_loss *= -0.5
    vae_loss = K.mean(reconstruction_loss + kl_loss)
    vae.add_loss(vae_loss)
    vae.compile(optimizer='rmsprop')

Thank you for any help",0,0,False,self,,,,,
749,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,20,d4461y,knapsack.news,What happens when you use ML to build a text adventure game?,https://www.reddit.com/r/MachineLearning/comments/d4461y/what_happens_when_you_use_ml_to_build_a_text/,PorkloinMaster,1568461706,,0,1,False,default,,,,,
750,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,21,d44ixd,self.MachineLearning,[Project] Multilingual Neural Machine Translation using Transformers with Conditional Normalization.,https://www.reddit.com/r/MachineLearning/comments/d44ixd/project_multilingual_neural_machine_translation/,suyash93,1568463982,"Code: https://github.com/suyash/mlt

Implemented transformers with One-to-Many, Many-to-One, Many-to-Many translation, with another demo for fine-tuning, by replacing regular layer norm in both encoder and decoder with Conditional Norm.

Conditional Norm is a technique from Style Transfer, used to train a single network with multiple styles, as well as mix styles, for example 

![](https://i.imgur.com/U0L1x8u.png)

Broader set of demos at https://github.com/suyash/stylizer/blob/master/image_stylization_demo.ipynb

The goal here is similar, make the rest of the network learn a common representation, while making the normalization parameters learn language specific semantics.

The One-to-Many and Many-to-One models are trained for English to French, German, Italian and Spanish Translation and Vice Versa.

The Many to Many model is trained on English-French, French-English, English-German and German-English.

The image stylization paper specifies how a N-style network can pick up an N+1th style through fine-tuning an existing model. Similarly, I fine-tune my Many-to-Many model to pick up Portuguese.

Have provided `SavedModel`s, as well as standalone notebooks that run in Google Colaboratory. The models have 6 blocks in both encoder and decoder, with a `dmodel` of 256 and `dff` of 1024. Each has ~32M parameters.

One-to-Many: https://colab.research.google.com/github/suyash/mlt/blob/master/one_to_many_demo.ipynb

Many-to-One: https://colab.research.google.com/github/suyash/mlt/blob/master/many_to_one_demo.ipynb

Many-to-Many: https://colab.research.google.com/github/suyash/mlt/blob/master/many_to_many_demo.ipynb

Many-to-Many fine-tuned: https://colab.research.google.com/github/suyash/mlt/blob/master/many_to_many_fine_tune_demo.ipynb",7,26,False,self,,,,,
751,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,21,d44mw7,vowpalwabbit.org,[N] Vowpal Wabbit has a new website!,https://www.reddit.com/r/MachineLearning/comments/d44mw7/n_vowpal_wabbit_has_a_new_website/,__gh,1568464635,,0,1,False,default,,,,,
752,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,22,d450dr,self.MachineLearning,"if giving an AGI the option to modify itself is dangerous, why would you give it that option?",https://www.reddit.com/r/MachineLearning/comments/d450dr/if_giving_an_agi_the_option_to_modify_itself_is/,Anonnymoose7221,1568466774,[removed],0,1,False,self,,,,,
753,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,22,d45fny,youtu.be,[N] How to build good use cases for your project?,https://www.reddit.com/r/MachineLearning/comments/d45fny/n_how_to_build_good_use_cases_for_your_project/,vignesh_ash,1568469096,,0,1,False,default,,,,,
754,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,23,d45niq,self.MachineLearning,ZERO to HERO Python 3 FULL STACK MASTERCLASS 45 AI projects,https://www.reddit.com/r/MachineLearning/comments/d45niq/zero_to_hero_python_3_full_stack_masterclass_45/,HannahHumphreys,1568470233,[removed],0,1,False,self,,,,,
755,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,23,d45tkf,self.MachineLearning,Transform images to look like images from a dataset,https://www.reddit.com/r/MachineLearning/comments/d45tkf/transform_images_to_look_like_images_from_a/,Fable67,1568471084,[removed],0,1,False,self,,,,,
756,MachineLearning,t5_2r3gv,2019-9-14,2019,9,14,23,d465cl,self.MachineLearning,Would anyone like to read my paper on Semantic Shift?,https://www.reddit.com/r/MachineLearning/comments/d465cl/would_anyone_like_to_read_my_paper_on_semantic/,debitcardwinner,1568472691,[removed],0,1,False,self,,,,,
757,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,0,d46apm,self.MachineLearning,Would anyone like to read my paper on Semantic Shift? [D],https://www.reddit.com/r/MachineLearning/comments/d46apm/would_anyone_like_to_read_my_paper_on_semantic/,debitcardwinner,1568473399,"Hi in my research paper I recently came up with a methodology to measure semantic narrowing and semantic broadening, but these definitions are based on intuition and their definitions from past literature (Blank 1999). If anyone has any experience in research in NLP, or semantic shift - I would love some feedback.

I haven't made my paper public",10,4,False,self,,,,,
758,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,0,d46ml0,self.MachineLearning,"I have $300k cloud credits sitting idle, any ideas to use it?",https://www.reddit.com/r/MachineLearning/comments/d46ml0/i_have_300k_cloud_credits_sitting_idle_any_ideas/,amy-home-food,1568474929,[removed],0,1,False,self,,,,,
759,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,0,d46zc9,self.MachineLearning,Seeking Advice (NEWBIE).,https://www.reddit.com/r/MachineLearning/comments/d46zc9/seeking_advice_newbie/,23dgy_4m3,1568476606,"Hello world, I and our team are new to Machine learning and we would like to start learning about machine learning by taking a project. So the project is to predict which product the user is trying to find with their keyword, as of now we have two datasets, dataset1 contains the products with their corresponding description and dataset2 contains supposed user inputs (the keywords), so for example if the user enters ""red carpet 3.5m"" and the product dataset contains a product named ""trukish carpet"" with description ""fabric, soft, carpet, turkish, luxorious"" the ML needs to predict that the keyword entered by the user(""red carpet 3.5m"") matches with this product(""turkish carpet""). We just need a kick start advice on how one would start with making this project and what all models/methods to use. Thank you for reading this...",0,1,False,self,,,,,
760,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,1,d47b4g,self.MachineLearning,How big of a deal is having a CVPR paper?,https://www.reddit.com/r/MachineLearning/comments/d47b4g/how_big_of_a_deal_is_having_a_cvpr_paper/,CGNefertiti,1568478067,[removed],0,1,False,self,,,,,
761,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,1,d47cq9,self.MachineLearning,[D] Batchnorm inference is a function of batch size / batch data,https://www.reddit.com/r/MachineLearning/comments/d47cq9/d_batchnorm_inference_is_a_function_of_batch_size/,idg101,1568478274,"Why is it that in tensorflow, the batchnorm results during inference time (e.g. using model.predict()) are dependent on the data in the batch?  I would expect the network computation graph to be completely frozen.",6,0,False,self,,,,,
762,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,1,d47fc4,self.MachineLearning,[D] Privacy with GANs: Can training samples be recovered in GANs?,https://www.reddit.com/r/MachineLearning/comments/d47fc4/d_privacy_with_gans_can_training_samples_be/,eigenlaplace,1568478623,"I remember reading a paper that showed that data samples that were used to train a GAN can be recovered almost perfectly, thus creating privacy concerns in GANs when used in medical patient data, for example.

&amp;#x200B;

Does anyone recall such a paper? Or what are your informed opinions on this topic, and could you provide some references? 

&amp;#x200B;

Thanks!",7,82,False,self,,,,,
763,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,1,d47glf,codecampanion.blogspot.com,The dark side of Big Data : What everyone forgets to mention,https://www.reddit.com/r/MachineLearning/comments/d47glf/the_dark_side_of_big_data_what_everyone_forgets/,AshishKhuraishy,1568478782,,1,0,False,https://b.thumbs.redditmedia.com/GqmpYHJyvu3OpDBYS_Ld2QLyBQViibG4LcippCRiXCA.jpg,,,,,
764,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,2,d4835x,self.MachineLearning,Why don't we use this method instead of blocking the whole content(generally the victims) in our news?,https://www.reddit.com/r/MachineLearning/comments/d4835x/why_dont_we_use_this_method_instead_of_blocking/,tzersh,1568481582,"Researchers propose a novel generator architecture to anonymize faces, which ensures 100% removal of privacy-sensitive information in the original face. My question is then why don't we use this approach to block the victim(s) and perpetrator(s) face's instead of blocking the whole content.

https://arxiv.org/pdf/1909.04538.pdf",0,1,False,self,,,,,
765,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,2,d484lj,youtu.be,Artificial Life Simulation,https://www.reddit.com/r/MachineLearning/comments/d484lj/artificial_life_simulation/,Thomas-Arys,1568481770,,0,1,False,https://a.thumbs.redditmedia.com/91y8gLzFIj0E9ohH3pIdUv-IJD0QrF3BOoFbJwkzK04.jpg,,,,,
766,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,2,d484p6,self.MachineLearning,"[D] Franois Chollet: Keras, Deep Learning, and the Progress of AI",https://www.reddit.com/r/MachineLearning/comments/d484p6/d_franois_chollet_keras_deep_learning_and_the/,UltraMarathonMan,1568481782,"Franois Chollet is the creator of Keras, which is an open source deep learning library that is designed to enable fast, user-friendly experimentation with deep neural networks. It serves as an interface to several deep learning libraries, most popular of which is TensorFlow, and it was integrated into TensorFlow main codebase a while back. Aside from creating an exceptionally useful and popular library, Franois is also a world-class AI researcher and software engineer at Google, and is definitely an outspoken, if not controversial, personality in the AI world, especially in the realm of ideas around the future of artificial intelligence.

**Video:** [https://www.youtube.com/watch?v=Bo8MY4JpiXE](https://www.youtube.com/watch?v=Bo8MY4JpiXE)   
**Audio:** [https://lexfridman.com/francois-chollet](https://lexfridman.com/francois-chollet)

*Processing img kngu0k9wflm31...*

**Outline:**  
*(click on the timestamp to jump to that part of the video)*

[0:00](https://www.youtube.com/watch?v=Bo8MY4JpiXE&amp;t=0s) \- Introduction  
[1:14](https://www.youtube.com/watch?v=Bo8MY4JpiXE&amp;t=74s) \- Self-improving AGI  
[7:51](https://www.youtube.com/watch?v=Bo8MY4JpiXE&amp;t=471s) \- What is intelligence?  
[15:23](https://www.youtube.com/watch?v=Bo8MY4JpiXE&amp;t=923s) \- Science progress  
[26:57](https://www.youtube.com/watch?v=Bo8MY4JpiXE&amp;t=1617s) \- Fear of existential threats of AI  
[28:11](https://www.youtube.com/watch?v=Bo8MY4JpiXE&amp;t=1691s) \- Surprised by deep learning  
[30:38](https://www.youtube.com/watch?v=Bo8MY4JpiXE&amp;t=1838s) \- Keras and TensorFlow 2.0  
[42:28](https://www.youtube.com/watch?v=Bo8MY4JpiXE&amp;t=2548s) \- Software engineering on a large team  
[46:23](https://www.youtube.com/watch?v=Bo8MY4JpiXE&amp;t=2783s) \- Future of TensorFlow and Keras  
[47:53](https://www.youtube.com/watch?v=Bo8MY4JpiXE&amp;t=2873s) \- Current limits of deep learning  
[58:05](https://www.youtube.com/watch?v=Bo8MY4JpiXE&amp;t=3485s) \- Program synthesis  
[1:00:36](https://www.youtube.com/watch?v=Bo8MY4JpiXE&amp;t=3636s) \- Data and hand-crafting of architectures  
[1:08:37](https://www.youtube.com/watch?v=Bo8MY4JpiXE&amp;t=4117s) \- Concerns about short-term threats in AI  
[1:24:21](https://www.youtube.com/watch?v=Bo8MY4JpiXE&amp;t=5061s) \- Concerns about long-term existential threats from AI  
[1:29:11](https://www.youtube.com/watch?v=Bo8MY4JpiXE&amp;t=5351s) \- Feeling about creating AGI  
[1:33:49](https://www.youtube.com/watch?v=Bo8MY4JpiXE&amp;t=5629s) \- Does human-level intelligence need a body?  
[1:34:19](https://www.youtube.com/watch?v=Bo8MY4JpiXE&amp;t=5659s) \- Good test for intelligence  
[1:50:30](https://www.youtube.com/watch?v=Bo8MY4JpiXE&amp;t=6630s) \- AI winter",5,4,False,https://b.thumbs.redditmedia.com/TT0TZkZmXukx96XE6X6pjta6KMOEoU3fbbIfncM0oog.jpg,,,,,
767,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,3,d496l7,self.MachineLearning,Name of the algorithm with features generation,https://www.reddit.com/r/MachineLearning/comments/d496l7/name_of_the_algorithm_with_features_generation/,Neiro0,1568486547,[removed],0,1,False,self,,,,,
768,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,5,d4acpl,self.MachineLearning,End to End Speech to Text Model,https://www.reddit.com/r/MachineLearning/comments/d4acpl/end_to_end_speech_to_text_model/,mutatedmonkeygenes,1568491965,[removed],0,1,False,self,,,,,
769,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,7,d4br08,content.sniklaus.com,[R] 3D Ken Burns Effect from a Single Image,https://www.reddit.com/r/MachineLearning/comments/d4br08/r_3d_ken_burns_effect_from_a_single_image/,sniklaus,1568498627,,1,1,False,default,,,,,
770,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,7,d4c93x,self.MachineLearning,Is taking Applied Math in college a good major for working with Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/d4c93x/is_taking_applied_math_in_college_a_good_major/,pitin753,1568501057,[removed],0,1,False,self,,,,,
771,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,8,d4d3sx,youtube.com,Artificial life simulation,https://www.reddit.com/r/MachineLearning/comments/d4d3sx/artificial_life_simulation/,Thomas-Arys,1568505358,,0,1,False,default,,,,,
772,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,11,d4ej7s,self.MachineLearning,[D] Super-Convergence Skepticism,https://www.reddit.com/r/MachineLearning/comments/d4ej7s/d_superconvergence_skepticism/,unabashed-p-zombie,1568513399,"Smith and Topin's 2017 paper [Super-Convergence: Very Fast Training of Neural N](https://arxiv.org/abs/1708.07120)[etworks Using Large Learning Rates](https://arxiv.org/abs/1708.07120) garnered quite a bit of attention, promising to cut training iterations by an order of magnitude without compromising accuracy.  They propose the following change to the learning rate scheduler:

![img](4luxa8wdamm31)

Using a 56-layer residual network, they claim that while it takes 80k iterations to train to 91% accuracy on CIFAR-10 using conventional algorithms, but that they can achieve a higher accuracy (92.4%) in only 10k iterations.

On [Open Review](https://openreview.net/forum?id=H1A5ztj3b) there is concern that it's not clear if the accuracy gains are significant (""no error bars"") and about whether this technique generalizes to other architectures.

I think we've mostly seen that Super-Convergence seems to converge to fine results on multiple architectures -- the ""[train ImageNet in 3 hours for $25](https://www.fast.ai/2018/04/30/dawnbench-fastai/)"" is probably the most well-known example.  I've used it to train ResNet-18, 34, and 50 on CIFAR.  I'm not sure it actively/consistently *improves* test accuracy, but heck: even if it *decreases* accuracy a bit, if it cuts training time by a factor of 8 I'll happily use it!

My main problem with the Super-Convergence paper is that the baseline they compare too seems laughably un-optimized for their problem.  Consider the training run below.  I grabbed the ResNet model from [this github repo](https://github.com/kuangliu/pytorch-cifar).  There's nothing particularly special here.  Some minor things worth noting:

1. The ResNet we use doesn't downsample after the first convolution, unlike the original ResNet (which was designed for larger images)
2. Images are augmented with random cropping and horizontal flipping.

![img](glqe36c6rnm31)

Obviously this isn't an apples-to-apples comparison with the Super-Convergence paper, which trains a 56-layer ResNet.  Maybe the larger network actually *does* just require far longer to train?

While the larger network does require more time, it is unlikely to make a huge difference.  Consider the two runs I ran with ResNet50.  Here I had to drop the batch size to 64 (I'm just using my personal PC).  The second run has a batch size of 128 with half precision (Note: I need a brief warm-up period here due to some NaNs).  While there is a clear problem with the network not converging quickly enough, the paper uses a batch size of *1000*.  One might be reasonably skeptical (with an actual experiment) that this would let us train in 10k iterations, but certainly training in 20k seems like an uncontroversial claim.

![img](wsa59jidsnm31)

To be clear, I think there are valuable ideas used in this paper.  I have nothing against the learning rate test (proposed in an earlier paper).  Warm-up periods seem useful as a means of being able to eventually use a higher learning rate, and I like that the LR test and training regimen acknowledge the fact that you can often use a higher learning rate after a bit of warm up (though I *do* think spending half of your training time warming up is excessive and I'm skeptical that it helps generalization).

The observation that you can avoid having your training loss flat-line (and wasting time!) by decreasing the learning rate slowly.  If the claim that this corner-cutting doesn't have a detrimental effect on test accuracy is true (and I think it can be) then this is a very interesting observation!

But I'm not convinced at all that Super-Convergence delivers on its promise of bringing training times down by an order of magnitude -- not if it is compared against a learning-rate scheduler that has been tuned to any extent.",10,131,False,self,,,,,
773,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,11,d4ek14,self.MachineLearning,AI powered Infinity stone to help my coworker remember our names,https://www.reddit.com/r/MachineLearning/comments/d4ek14/ai_powered_infinity_stone_to_help_my_coworker/,ahadcove,1568513533,[removed],0,3,False,self,,,,,
774,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,11,d4elka,self.MachineLearning,papers related to scene matching,https://www.reddit.com/r/MachineLearning/comments/d4elka/papers_related_to_scene_matching/,itica,1568513790,"Can anyone suggest papers that are related to scene matching  (similar to person re-identification but more related to scenery)

Eg. Comparing aerial images and classifying them into matching (if they are taken at different angles) or non-matching  (completely different)

looking for papers that are similar to [Siamese Network Features for Image matching](https://ieeexplore.ieee.org/document/7899663)",0,1,False,self,,,,,
775,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,11,d4eo11,i.redd.it,One of my favorites [discussion],https://www.reddit.com/r/MachineLearning/comments/d4eo11/one_of_my_favorites_discussion/,mrxzil,1568514198,,0,1,False,default,,,,,
776,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,11,d4eui6,self.MachineLearning,Any developments on randomly wired neural networks?,https://www.reddit.com/r/MachineLearning/comments/d4eui6/any_developments_on_randomly_wired_neural_networks/,MartialLemur,1568515254,[removed],0,1,False,self,,,,,
777,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,11,d4exrf,self.MachineLearning,Understanding Image Segementation,https://www.reddit.com/r/MachineLearning/comments/d4exrf/understanding_image_segementation/,stevofolife,1568515769,[removed],0,1,False,self,,,,,
778,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,12,d4fgxi,self.MachineLearning,My algorithm for gradient descent is giving me wrong answer for multiple features but it is correct for single feature.,https://www.reddit.com/r/MachineLearning/comments/d4fgxi/my_algorithm_for_gradient_descent_is_giving_me/,Cooder0,1568519022,"**Here is my code.**

    function [theta, J_history] = gradientDescentMulti(X, y, theta, alpha, num_iters)
    m = length(y);
    J_history = zeros(num_iters, 1);
    s = zeros(size(theta);
    temp = theta;
    for iter = 1:num_iter
     h = X * theta;
     s = (h - y); 
        for j = 1:size(theta, 1)
          s =  s .* X(:, j);
          temp(j) = temp(j) - alpha*(mean(s));
        end
      theta = temp; 
        J_history(iter) = computeCostMulti(X, y, theta);
    end
    

**For debugging:-**

    function J = computeCost(X, y, theta)
    m = length(y);
    s = 0;
    h = 0;
    sq = 0;
    J = 0;
    for i = 1:m
    h = theta' * X(i, :)';
    sq = (h - y(i))^2;
    s = s + sq;
    end 
    J = 1/(2*m) * s;
    end

**Calling the function.**

    X = [ 2 1 3; 7 1 9; 1 8 1; 3 7 4 ];
    y = [2 ; 5 ; 5 ; 6];
    [theta J_hist] = gradientDescentMulti(X, y, zeros(3,1), 0.01, 10);

&gt;It is expected to give this result.

&amp;#x200B;

    theta =
       0.25175
       0.53779
       0.32282
    J_hist =
       2.829855
       0.825963
       0.309163
       0.150847
       0.087853
       0.055720
       0.036678
       0.024617
       0.016782
       0.011646

&amp;#x200B;

&gt;But, it is giving me this and even cost function is not converging.

&amp;#x200B;

    theta =
       -25.642
       -57.128
      -303.972
    J_hist =
            42.34219
           118.46923
           411.39417
          1316.40170
          4378.71480
         14325.01252
         47215.23483
        155107.16372
        510304.16421
       1677772.41725",0,1,False,self,,,,,
779,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,13,d4fp83,i.redd.it,&lt;UNK&gt; !,https://www.reddit.com/r/MachineLearning/comments/d4fp83/unk/,cute_woodpecker,1568520452,,0,1,False,default,,,,,
780,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,15,d4gsql,youtu.be,Machine Learning - StarCraft 2 Python AI,https://www.reddit.com/r/MachineLearning/comments/d4gsql/machine_learning_starcraft_2_python_ai/,burdin271,1568527913,,0,1,False,https://b.thumbs.redditmedia.com/JrllW37FvdDcW4yFv5ud99TCEG9omS_3WcRrP-7GQXE.jpg,,,,,
781,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,17,d4hq22,self.MachineLearning,Mask-RCNN to cut objects [PROJECT],https://www.reddit.com/r/MachineLearning/comments/d4hq22/maskrcnn_to_cut_objects_project/,adriacabeza,1568535072,"This is the project a friend and me did for our first online hackathon. It uses Mask-RCNN to extract easily objects from pictures. Although it was kinda strange it was really cool to work in an online hackathon, and we've learned a lot through the way.

What do you guys think?? [https://github.com/AlbertSuarez/object-cut](https://github.com/AlbertSuarez/object-cut)

You can actually test it at: [https://objectcut.ga/](https://objectcut.ga/)

Give it some love :D",7,7,False,self,,,,,
782,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,19,d4irgb,/r/MachineLearning/comments/d4irgb/check_it_out/,Check it out,https://www.reddit.com/r/MachineLearning/comments/d4irgb/check_it_out/,seoagency11,1568543079,,0,1,False,https://b.thumbs.redditmedia.com/df7qv8y75cLmzrywvPpLdxy0gb5B1w6CXa7bI_umD2s.jpg,,,,,
783,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,20,d4jfbt,youtu.be,My friends explained the idea to solved the machine learning problem in #AmazonMachineLearningChallange..,https://www.reddit.com/r/MachineLearning/comments/d4jfbt/my_friends_explained_the_idea_to_solved_the/,swamimohit,1568548052,,0,1,False,default,,,,,
784,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,22,d4kf3b,medium.com,LiDAR Industry Hits Impasse: Was Elon Musk Right After All?,https://www.reddit.com/r/MachineLearning/comments/d4kf3b/lidar_industry_hits_impasse_was_elon_musk_right/,Yuqing7,1568554005,,0,1,False,https://b.thumbs.redditmedia.com/rC7eCsWmYGOF8ky9JHeNKQAcPJtIXOkTFCR8ytIHUIo.jpg,,,,,
785,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,22,d4kqtf,robinrobotic.blogspot.com,A* ALGORITHM BASICS FOR PATH FINDING &amp; HEURISTICS METHODS : ARTIFICIAL INTELLIGENCE,https://www.reddit.com/r/MachineLearning/comments/d4kqtf/a_algorithm_basics_for_path_finding_heuristics/,robinroy_peter_,1568555773,,0,1,False,https://b.thumbs.redditmedia.com/fkL-J9rQqmhNp-RzUMAJ1bNQXLTB9_8BzkjZ1ZyAhGw.jpg,,,,,
786,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,23,d4l8hz,self.MachineLearning,[D] Best papers and code for visual dubbing?,https://www.reddit.com/r/MachineLearning/comments/d4l8hz/d_best_papers_and_code_for_visual_dubbing/,cbsudux,1568558237,"I'm trying to find papers and code for visual dubbing, where the visual content is adjusted to match the new audio channel. Thanks!",0,1,False,self,,,,,
787,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,23,d4l9ew,self.MachineLearning,[P] PyTorch implementation of 17 Deep RL algorithms,https://www.reddit.com/r/MachineLearning/comments/d4l9ew/p_pytorch_implementation_of_17_deep_rl_algorithms/,__data_science__,1568558350,"For anyone trying to learn or practice RL, here's a repo with working PyTorch implementations of 17 RL algorithms including DQN, DQN-HER, Double DQN, REINFORCE, DDPG, DDPG-HER, PPO, SAC, SAC Discrete, A3C, A2C etc..      

Let me know what you think!

[https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch](https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch)",14,343,False,self,,,,,
788,MachineLearning,t5_2r3gv,2019-9-15,2019,9,15,23,d4lbaj,voicetechpodcast.com,[D] Speech-to-Text Selection,https://www.reddit.com/r/MachineLearning/comments/d4lbaj/d_speechtotext_selection/,wootnoob,1568558601,,1,1,False,https://b.thumbs.redditmedia.com/0NW_VS_GQTj7XhYm4X-aTZeGdI-5lmdWCj-8-GcoCME.jpg,,,,,
789,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,0,d4lo0l,youtu.be,Read a paper: Code2Vec -- Learning Distributed Representations of Code,https://www.reddit.com/r/MachineLearning/comments/d4lo0l/read_a_paper_code2vec_learning_distributed/,ggvh,1568560195,,0,1,False,https://b.thumbs.redditmedia.com/WGwxgdqWJ1aL9SK7BPU7F-quSgvet1QZ0pKn0ekA7Ps.jpg,,,,,
790,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,0,d4m5m4,self.MachineLearning,Does anyone else feel things slowing down?,https://www.reddit.com/r/MachineLearning/comments/d4m5m4/does_anyone_else_feel_things_slowing_down/,trexgomez,1568562358,[removed],0,1,False,self,,,,,
791,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,1,d4mgsd,self.MachineLearning,Infer family details from review texts [Research],https://www.reddit.com/r/MachineLearning/comments/d4mgsd/infer_family_details_from_review_texts_research/,bluzkluz,1568563739,"    User_id, review 
    1, ""We are a family of 4 adults chose this and view and loved this place"" 
    1, ""My husband and I, with our 2 teen sons, visit this restaurant at least once..."" 
    2,""My partner and I booked table for a short holiday, their wine menu was awesome"" 
    2,""My wife is a fan of jazz and she's expecting, so visited this place ""
    

We have a bunch of reviews, some examples shown above. Are there any techniques that I can use to infer:

    User Id 1 =&gt; family of 4, 2 sons (13-19) 
    User Id 2 =&gt; family of 2, expecting :

Can anyone recommend datasets and/or methods to infer the above?",1,0,False,self,,,,,
792,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,1,d4miwc,self.MachineLearning,Derivatives of output layer activations wrt to input layer variables,https://www.reddit.com/r/MachineLearning/comments/d4miwc/derivatives_of_output_layer_activations_wrt_to/,randvar7,1568564002,"Can available public neural network algorithms spit out derivatives of output layer activations wrt to input layer variables (in standard notation,   [http://neuralnetworksanddeeplearning.com/](http://neuralnetworksanddeeplearning.com/chap2.html), \\del z\^L\_i / \\del x\_i)?",0,1,False,self,,,,,
793,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,1,d4mm5b,self.MachineLearning,The #BenderRule: On Naming the Languages We Study and Why It Matters,https://www.reddit.com/r/MachineLearning/comments/d4mm5b/the_benderrule_on_naming_the_languages_we_study/,hughbzhang,1568564396,"Emily Bender argues for why NLP research should not be conducted only on English.

[https://thegradient.pub/the-benderrule-on-naming-the-languages-we-study-and-why-it-matters/](https://thegradient.pub/the-benderrule-on-naming-the-languages-we-study-and-why-it-matters/)",0,1,False,self,,,,,
794,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,1,d4mmj9,self.MachineLearning,[D] #BenderRule: Name the Language You Study,https://www.reddit.com/r/MachineLearning/comments/d4mmj9/d_benderrule_name_the_language_you_study/,hughbzhang,1568564450,"Emily Bender argues for why NLP research should not be conducted only on English.

[https://thegradient.pub/the-benderrule-on-naming-the-languages-we-study-and-why-it-matters/](https://thegradient.pub/the-benderrule-on-naming-the-languages-we-study-and-why-it-matters/)",10,0,False,self,,,,,
795,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,1,d4mp0b,self.MachineLearning,[D] Free GPU powered VM give-away,https://www.reddit.com/r/MachineLearning/comments/d4mp0b/d_free_gpu_powered_vm_giveaway/,reddit_dumper,1568564756,"Hello everyone. I have a few thousand dollars in Azure credits and am planning to give access to powerful VMs to those with interesting/useful open source projects but limited resources.

In order to get it, please comment with the following

1. A description of your project (a Github link would also be great).
2. What you need (e.g. machine specifications) and how long you need it for.
3. How it benefits the open source community

For most projects, I will be charging 1/4th the cost of the actual VM (payment method is Bitcoin/Ether). If the project is compelling enough, I will be very happy to give the needed resources for free.

I will be judging based on upvotes, community response, and whether I have enough azure credits to sponsor it.",0,0,False,self,,,,,
796,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,1,d4mrq3,self.MachineLearning,"Where do you rent compute resources (GPU, FPGA, etc.)?",https://www.reddit.com/r/MachineLearning/comments/d4mrq3/where_do_you_rent_compute_resources_gpu_fpga_etc/,thoaionline,1568565095,[removed],0,1,False,self,,,,,
797,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,1,d4mym8,self.MachineLearning,"[D] Where do you rent compute resources (GPU, FPGA, etc.)?",https://www.reddit.com/r/MachineLearning/comments/d4mym8/d_where_do_you_rent_compute_resources_gpu_fpga_etc/,thoaionline,1568565934,"Where do you guys rent compute resources for training? What are your primary selection criteria (cost/reliability/bandwidth/ data location), for **your particular use case**?

Do you also own your own AI/ML gears for consistent workload, in addition to the cloud? I am asking this as I am building an exchange where people can share quality compute resources at-cost or near-cost. Would this be something that you are interested in? If not, what are the main objections?

And finally, if you are living in Melbourne (Australia) and actively learning/working with/competing in AI/ML, I'd like to take you out for Starbucks.

P.S. The project is close to release (on the technical side) so let me know if you want to poke around with the beta version. The compute (nodes with at least 2x 1080Ti &amp; workstation CPU) is on me!",27,15,False,self,,,,,
798,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,1,d4n20t,self.MachineLearning,Trying to learn enough ML to understand academic papers. Best resources?,https://www.reddit.com/r/MachineLearning/comments/d4n20t/trying_to_learn_enough_ml_to_understand_academic/,xinwow,1568566348,[removed],0,1,False,self,,,,,
799,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,1,d4n33a,self.MachineLearning,[D] CNN predicts one class well but not the other two,https://www.reddit.com/r/MachineLearning/comments/d4n33a/d_cnn_predicts_one_class_well_but_not_the_other/,korokage,1568566468,"I have 300 images, 100 are of class 1, 100 are of class 2 and 100 are of class 3.

My CNN model can differentiate between class 1 and class 2 &amp; class 1 and class 3 well. However it gets confused between class 2 and class 3.

How can I make it identify these classes better?",8,0,False,self,,,,,
800,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,1,d4n489,content.sniklaus.com,3D Ken Burns Effect from a Single Image,https://www.reddit.com/r/MachineLearning/comments/d4n489/3d_ken_burns_effect_from_a_single_image/,sniklaus,1568566611,,1,1,False,default,,,,,
801,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,2,d4nf40,kalitut.com,What is data science and how does it work,https://www.reddit.com/r/MachineLearning/comments/d4nf40/what_is_data_science_and_how_does_it_work/,WTSxDev,1568567936,,0,1,False,https://b.thumbs.redditmedia.com/NsVNXJy_ZjfoUS2Qw8VBMZXwNJnjQkEbi0RJD0qkUFE.jpg,,,,,
802,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,2,d4ng2g,self.MachineLearning,MSc or Graduate Job?,https://www.reddit.com/r/MachineLearning/comments/d4ng2g/msc_or_graduate_job/,rohanp2799,1568568053,[removed],0,1,False,self,,,,,
803,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,3,d4obwl,self.MachineLearning,Sourcing data for a job recommendation system [research],https://www.reddit.com/r/MachineLearning/comments/d4obwl/sourcing_data_for_a_job_recommendation_system/,JakeBSc,1568571924,"I'm an undergraduate data scientist, about to start work on my dissertation project.

I thought I'd create a system that, given someone's career history and education, predicts what job they're likely to get, and at what company. Essentially this is to help focus the efforts of job seekers, and help them get to where they belong.

Originally I planned to do this by scraping data from LinkedIn profiles. From the LinkedIn profile, you can obtain information about someone's current job and employer, as well as their career history and education. Therefore you can see what education and career history (the input) resulted in their current job (the output - the thing I'm trying to predict).

However, with this strategy, I'm running into ethical problems and data protection problems. There's a good chance my project proposal won't pass the ethical review. So I'm looking for a new data source without these issues.

I'm pretty new to machine learning, so it's hard for me to assess what sources of data are viable for this project. Therefore, I was hoping someone more experienced can suggest how I might obtain the data I'm after, without having ethical baggage? Or failing that, at least a hint or pointer would be greatly appreciated.

Thank you",3,0,False,self,,,,,
804,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,3,d4om3m,self.MachineLearning,Generating Text with LSTM Recurrent Neural Networks,https://www.reddit.com/r/MachineLearning/comments/d4om3m/generating_text_with_lstm_recurrent_neural/,imdeepmind,1568573112,"Hi, this is my first Reddit post.

I made an LSTM RNN model that generates text. Currently, the model is generated texts that looked like valid English, but makes no sense. 

Here is one sample: i purchase these for a friend in return is a great guitar. it is expecting one of them at some price is comfortable to set out to have a good guitar and the digital time, i have not to the weeknet with the neck and the sound is good and is one of them. i have been hard to get the strings and works great. i am sure i just build a drive enter of what the work and the white is not a bit use the sound is that it is really disappointed in the last sound remote to be a professional cart product and when i have a sound parts, and i have a s

&amp;#x200B;

Check out the code here

[https://github.com/imdeepmind/GeneratingTextWithLSTM](https://github.com/imdeepmind/GeneratingTextWithLSTM)

&amp;#x200B;

For this project, I also made a dataset of 200 million sequences. Though due to hardware limitation, just trained on 30 million samples.

&amp;#x200B;

Sharing this project here to get some feedback from you guys.",0,1,False,self,,,,,
805,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,4,d4pd2i,/r/MachineLearning/comments/d4pd2i/free_opensource_and_online_labelling_tool/,Free Opensource and Online Labelling Tool,https://www.reddit.com/r/MachineLearning/comments/d4pd2i/free_opensource_and_online_labelling_tool/,RandomForests92,1568576392,,1,1,False,https://b.thumbs.redditmedia.com/XyRsrZPOE94z06cbTWgb-XNC-Cb4hasjsOwsUO7OXRM.jpg,,,,,
806,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,5,d4pobs,self.MachineLearning,ARTIFICIAL INTELLIGENCE &amp; MACHINE LEARNING,https://www.reddit.com/r/MachineLearning/comments/d4pobs/artificial_intelligence_machine_learning/,Hamza_07,1568577752,"Now a days [Artificial Intelligence and Machine Learning](https://www.pnytrainings.com/machine-learning-course-training-in-pakistan) is almost used in every computer game or software where the system trains itself by using previous results and show the best result as possible. The average salary of AI developer is $100,000 to $150,000.",0,1,False,self,,,,,
807,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,5,d4pt3h,cloud.google.com,Machine Learning Comic,https://www.reddit.com/r/MachineLearning/comments/d4pt3h/machine_learning_comic/,eeeephus,1568578340,,0,1,False,https://b.thumbs.redditmedia.com/UcKjipQhaLVQFU3ADO2yQM0JnL6s5FQXU6TXGV57ucI.jpg,,,,,
808,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,5,d4qdld,self.MachineLearning,[P] Reinforcement Learning with Raw Actions and Observations in PySC2,https://www.reddit.com/r/MachineLearning/comments/d4qdld/p_reinforcement_learning_with_raw_actions_and/,kiarash-irandoust,1568580838,"This tutorial is the follow up of the [previous one](https://itnext.io/create-a-protoss-bot-using-raw-observations-and-actions-in-pysc2-615f41aa283e?source=friends_link&amp;sk=f0cb5cf6ddb0b3c6d8a8d1a7ee78c0cf), which introduced a recent addition to [PySC2](https://itnext.io/build-a-zerg-bot-with-pysc2-2-0-295375d2f58e) known as raw observations and raw actions. Now we can take that knowledge and attempt to teach our bot how to play using reinforcement learning:

https://medium.com/@skjb/reinforcement-learning-with-raw-actions-and-observations-in-pysc2-af0b6fd8391f?source=friends_link&amp;sk=202c65fce90d72d8c17250992b70bd96",0,5,False,self,,,,,
809,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,6,d4qqa8,self.MachineLearning,"I'm looking for youtube channels like Numberphile but for ML, any recommendations?",https://www.reddit.com/r/MachineLearning/comments/d4qqa8/im_looking_for_youtube_channels_like_numberphile/,elsee,1568582324,[removed],1,1,False,self,,,,,
810,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,7,d4recl,self.MachineLearning,"[P] SpeedTorch. 4x faster pinned CPU -&gt; GPU data transfer than Pytorch pinned CPU tensors, and 110x faster GPU -&gt; CPU transfer. Augment parameter size by hosting on CPU. Use non sparse optimizers (Adadelta, Adamax, RMSprop, Rprop, etc.) for sparse training (word2vec, node2vec, GloVe, NCF, etc.).",https://www.reddit.com/r/MachineLearning/comments/d4recl/p_speedtorch_4x_faster_pinned_cpu_gpu_data/,BatmantoshReturns,1568585207,"https://i.imgur.com/wr4VaUV.png

https://github.com/Santosh-Gupta/SpeedTorch

This is library I made for Pytorch, for fast transfer between pinned CPU tensors and GPU pytorch variables. The inspiration came from needed to train large number of embeddings, which don't all fit on GPU ram at a desired embedding size, so I needed a faster CPU &lt;-&gt; GPU transfer method. This also allows using any optimizer for sparse training, since every embedding contained in the Pytorch embedding variable receives an update, previously only Pytorch's SGD, Adagrad, and SparseAdam were suitable for such training. 

In addition to augmenting parameter sizes, you can use to increase the speed of which data on your CPU is transferred to Pytorch Cuda variables. 

Also, SpeedTorch's GPU tensors are also overall faster then Pytorch cuda tensors, when taking into account both transferring two and from (overall 2.6x faster). For just transfering to a Pytorch Cuda, Pytorch is still faster, but significantly slower when transfering from a Pytorch Cuda variable. 

I have personally used this to nearly double the embedding size of embeddings in two other projects, by holding half the parameters on CPU. The training speed is decent thanks to the fast CPU&lt;-&gt;GPU exchange. 

https://github.com/Santosh-Gupta/Research2Vec2

https://github.com/Santosh-Gupta/lit2vec2

There's a bit of a learning curve for the very first time getting started with it, so as soon as you run into any sort of friction, feel free to ask a question on the project gitter

https://gitter.im/SpeedTorch

And I'll answer them. 

https://i.imgur.com/6o8C1BP.gif",16,127,False,self,,,,,
811,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,7,d4rmdu,self.MachineLearning,Some questions for those of you working with machine learning in industry,https://www.reddit.com/r/MachineLearning/comments/d4rmdu/some_questions_for_those_of_you_working_with/,-Player,1568586211,[removed],0,1,False,self,,,,,
812,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,7,d4rvz4,cloud.google.com,Wholesome representation of this branch by Google AI,https://www.reddit.com/r/MachineLearning/comments/d4rvz4/wholesome_representation_of_this_branch_by_google/,oneskeleton,1568587480,,0,1,False,https://b.thumbs.redditmedia.com/fSfHaDXwivZyIDgzipGfKHj57k-ep4oa7Gp6KLprTUk.jpg,,,,,
813,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,8,d4sll3,self.NLP,How to trade off the boundary between encoder and decoder in transformer,https://www.reddit.com/r/MachineLearning/comments/d4sll3/how_to_trade_off_the_boundary_between_encoder_and/,hustlf,1568591010,,0,1,False,default,,,,,
814,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,8,d4sm52,self.MachineLearning,Using Machine Learning to Fight Cancer,https://www.reddit.com/r/MachineLearning/comments/d4sm52/using_machine_learning_to_fight_cancer/,TheGoodFightWontEnd,1568591092,[removed],0,1,False,self,,,,,
815,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,10,d4tpfc,self.MachineLearning,How to poke around limited resources on Kaggle?,https://www.reddit.com/r/MachineLearning/comments/d4tpfc/how_to_poke_around_limited_resources_on_kaggle/,BeggarInSpain,1568596829,[removed],0,1,False,self,,,,,
816,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,10,d4txqk,self.MachineLearning,Machine Learning and Deep Learning Interview Questions and Answers,https://www.reddit.com/r/MachineLearning/comments/d4txqk/machine_learning_and_deep_learning_interview/,nkptcs,1568598030,[removed],1,1,False,self,,,,,
817,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,14,d4wjje,self.MachineLearning,Chatbot On Facebook? Its Easy If You Do It Smart.,https://www.reddit.com/r/MachineLearning/comments/d4wjje/chatbot_on_facebook_its_easy_if_you_do_it_smart/,getengati,1568613391,[removed],0,1,False,self,,,,,
818,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,14,d4wklc,github.com,[P] NeMo: Neural Modules: a toolkit for conversational AI (speech recognition and NLP),https://www.reddit.com/r/MachineLearning/comments/d4wklc/p_nemo_neural_modules_a_toolkit_for/,gizcard,1568613592,,0,1,False,default,,,,,
819,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,15,d4wlxm,github.com,[P] NeMo (Neural Modules): a toolkit for speech recognition and NLP using PyTorch,https://www.reddit.com/r/MachineLearning/comments/d4wlxm/p_nemo_neural_modules_a_toolkit_for_speech/,gizcard,1568613834,,0,1,False,https://b.thumbs.redditmedia.com/TRAdhAHCANcn3VjUJnJmA4RQ4qqIHSuucwIF1YsuCmw.jpg,,,,,
820,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,15,d4x0ek,rubikscode.net,Image Optimization with Machine Learning,https://www.reddit.com/r/MachineLearning/comments/d4x0ek/image_optimization_with_machine_learning/,RubiksCodeNMZ,1568616633,,0,1,False,https://b.thumbs.redditmedia.com/vK2leH7yaXdSjuFpMrFLTnRBo7rUB3w0-bDSENC3eGU.jpg,,,,,
821,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,16,d4x7hr,ai.googleblog.com,Google at Interspeech 2019,https://www.reddit.com/r/MachineLearning/comments/d4x7hr/google_at_interspeech_2019/,sjoerdapp,1568618003,,0,1,False,default,,,,,
822,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,16,d4x9e2,self.learnmachinelearning,Interview with a Deep Learning expert - The Technically Speaking Podcast,https://www.reddit.com/r/MachineLearning/comments/d4x9e2/interview_with_a_deep_learning_expert_the/,grtgbln,1568618399,,0,1,False,default,,,,,
823,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,16,d4xa1l,medium.com,Setting up Smart Homes with Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/d4xa1l/setting_up_smart_homes_with_artificial/,Techno_SUPPORT,1568618532,,0,1,False,https://b.thumbs.redditmedia.com/f_lt7TwrdqwpVjnE-hHEgCJXtGhzxD_7YGLM-q1abnU.jpg,,,,,
824,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,16,d4xhu1,techcrunch.com,This prosthetic arm combines manual control with machine learning,https://www.reddit.com/r/MachineLearning/comments/d4xhu1/this_prosthetic_arm_combines_manual_control_with/,the_spotless_mind,1568620187,,0,1,False,default,,,,,
825,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,17,d4xt2j,smarten.com,What Is Self-Serve Data Preparation?,https://www.reddit.com/r/MachineLearning/comments/d4xt2j/what_is_selfserve_data_preparation/,ElegantMicroWebIndia,1568622721,,0,1,False,default,,,,,
826,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,17,d4xt9i,self.MachineLearning,How To Control Compressed Air By Solenoid Valve with Low Power Consumption?,https://www.reddit.com/r/MachineLearning/comments/d4xt9i/how_to_control_compressed_air_by_solenoid_valve/,uflowindia,1568622755,[removed],0,1,False,https://a.thumbs.redditmedia.com/g0DjPOtxYN--Fzyqejdd6dleWxq7v3rNQyv4Ga4vDL0.jpg,,,,,
827,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,18,d4y0nw,self.MachineLearning,"For classification, what should prevail? Accuracy or Loss?",https://www.reddit.com/r/MachineLearning/comments/d4y0nw/for_classification_what_should_prevail_accuracy/,saig22,1568624417,"I'm using a pre-trained BERT, for classification (10 classes).

The minimal loss on the test set is reached at the 6th epoch, and after that the loss increase. But the maximal accuracy is reached at the 52th epoch ([https://imgur.com/a/76BPccH](https://imgur.com/a/76BPccH)).

I'm using pytorch with a cross-entropy loss, BERT and its optimizer from pytorch\_transformers.

Should I look to minimize the loss or maximize the accuracy?

Should I use something different than accuracy to measure my model performance (like F1-score for binary classification)?

Thanks for your help.",0,1,False,self,,,,,
828,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,19,d4yl9x,self.MachineLearning,"How long term scheduler knows or (what mechanism detects that), a process is CPU Bound or I/O Bound?",https://www.reddit.com/r/MachineLearning/comments/d4yl9x/how_long_term_scheduler_knows_or_what_mechanism/,iqrarehman76,1568628533,[removed],0,1,False,self,,,,,
829,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,19,d4yqf2,self.MachineLearning,How to cope around limited compute resources on Kaggle (namely RAM)?,https://www.reddit.com/r/MachineLearning/comments/d4yqf2/how_to_cope_around_limited_compute_resources_on/,BeggarInSpain,1568629492,[removed],0,1,False,self,,,,,
830,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,20,d4z22z,mlait.in,What is Machine Learning ?,https://www.reddit.com/r/MachineLearning/comments/d4z22z/what_is_machine_learning/,mlait1908,1568631660,,0,1,False,default,,,,,
831,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,20,d4z2bv,self.MachineLearning,[D] Convolutional Neural Network with Numpy input Help G,https://www.reddit.com/r/MachineLearning/comments/d4z2bv/d_convolutional_neural_network_with_numpy_input/,youshouldknowsz,1568631709," Good evening good sir

I am a newbie with ML, i found this code from fellow redditor parasdahal.

I can make it run with mnist datasets.

Have few questions, i'd really really really appreciate it if someone can help me

[https://github.com/iqbaalmuhmd/CNNnumpy](https://github.com/iqbaalmuhmd/CNNnumpy)

1. Is it possible to run only test, with our own image input. Or just random image from mnist dataset
2. What should i pickle to save the parameters?",3,0,False,self,,,,,
832,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,20,d4z9nu,self.MachineLearning,What are some good applications that can comeout whrn integrating satellite imagery analysis with other data sources?,https://www.reddit.com/r/MachineLearning/comments/d4z9nu/what_are_some_good_applications_that_can_comeout/,WoLIBA,1568632934,[removed],0,1,False,self,,,,,
833,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,20,d4zh6y,self.MachineLearning,Satellite Imagery with Deep Learning to detect Invasive Water Species in Lake Victoria.,https://www.reddit.com/r/MachineLearning/comments/d4zh6y/satellite_imagery_with_deep_learning_to_detect/,cartometrics,1568634171,[removed],0,1,False,https://b.thumbs.redditmedia.com/AVN34-ZhD2B9YEMGKbL5ygodldq3M4fRgTIPaabDAEI.jpg,,,,,
834,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,20,d4zm9v,self.MachineLearning,[D] Proximal Policy Optimization in keras (Actor-Critic Method),https://www.reddit.com/r/MachineLearning/comments/d4zm9v/d_proximal_policy_optimization_in_keras/,begooboi,1568634965,"This article is written by Chintan Trivedi. Proximal Policy Optimization aka PPO was released by OpenAI in 2017. It is considered as the state-of-the-art algorithm in reinforcement learning. The USP of this article is its simplistic explanations and coding of PPO as well as  the accompanying videos. The author also released the code in his github page.

https://towardsdatascience.com/proximal-policy-optimization-tutorial-part-1-actor-critic-method-d53f9afffbf6",1,27,False,self,,,,,
835,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,21,d4ztzq,copymonkey.xyz,[Project] Create font based on your handwriting style,https://www.reddit.com/r/MachineLearning/comments/d4ztzq/project_create_font_based_on_your_handwriting/,SwechhaSwechha,1568636177,,1,1,False,default,,,,,
836,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,21,d5037r,self.MachineLearning,[R] GMLS-Nets for unstructured data,https://www.reddit.com/r/MachineLearning/comments/d5037r/r_gmlsnets_for_unstructured_data/,QueueTee314,1568637542,"Paper link: https://arxiv.org/pdf/1909.05371.pdf

Just come across this submitted paper. Reading it gives me a different vibe since it must have been written by mathematicians rather than ML researcher. Nevertheless, I am still fresh in this area so I cant tell if this is a good article or not. Any comments or critics?",0,3,False,self,,,,,
837,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,21,d507pz,youtube.com,Recommendation Systems - Machine Learning,https://www.reddit.com/r/MachineLearning/comments/d507pz/recommendation_systems_machine_learning/,ShyamTgr,1568638193,,0,1,False,https://b.thumbs.redditmedia.com/1bDp8MalgSzXJawJufwVnzlhFKFtcMRP_TIBFdDcjjI.jpg,,,,,
838,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,22,d50lr3,self.MachineLearning,[D] Why are Kaggle prizes so low?,https://www.reddit.com/r/MachineLearning/comments/d50lr3/d_why_are_kaggle_prizes_so_low/,mystikaldanger,1568640179,"E.g., [the new challenge from Lyft](https://www.kaggle.com/c/3d-object-detection-for-autonomous-vehicles) has a top prize of $12,000.

A model that outperforms their current implementation would presumably bring in a huge amount of value, so why are they and the other companies who sponsor these challenges so stingy on the payouts?",178,310,False,self,,,,,
839,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,22,d50nvk,self.MachineLearning,yeshua ai,https://www.reddit.com/r/MachineLearning/comments/d50nvk/yeshua_ai/,yeshuaai,1568640488,[removed],0,1,False,self,,,,,
840,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,22,d50rs1,developer.amazon.com,Turning Dialogue Tracking into a Reading Comprehension Problem : Alexa Blogs,https://www.reddit.com/r/MachineLearning/comments/d50rs1/turning_dialogue_tracking_into_a_reading/,georgecarlyle76,1568641028,,0,1,False,https://a.thumbs.redditmedia.com/fDFjtQtZaH1OcBp0aMQRUROoZnWnNTUYaTrgkudIpr0.jpg,,,,,
841,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,22,d50s2s,eurekalert.org,New algorithm can distinguish cyberbullies from normal Twitter users with 90% accuracy,https://www.reddit.com/r/MachineLearning/comments/d50s2s/new_algorithm_can_distinguish_cyberbullies_from/,Lightfiend,1568641063,,0,1,False,default,,,,,
842,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,23,d518ey,self.MachineLearning,Traditional methods surpass ML for time series forecasting,https://www.reddit.com/r/MachineLearning/comments/d518ey/traditional_methods_surpass_ml_for_time_series/,xtootse,1568643226,[removed],0,1,False,self,,,,,
843,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,23,d51aoj,i.redd.it,I have started my first freelancing,https://www.reddit.com/r/MachineLearning/comments/d51aoj/i_have_started_my_first_freelancing/,shubham2004_ai,1568643527,,0,1,False,default,,,,,
844,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,23,d51fg6,luisquintanilla.me,[P] Restaurant Inspections ETL &amp; Data Enrichment with Spark.NET and ML.NET Automated (Auto) ML,https://www.reddit.com/r/MachineLearning/comments/d51fg6/p_restaurant_inspections_etl_data_enrichment_with/,lqdev1,1568644129,,0,1,False,default,,,,,
845,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,23,d51i8x,self.MachineLearning,[P] Set up the CTRL text-generating model on Google Compute Engine with just a few console commands.,https://www.reddit.com/r/MachineLearning/comments/d51i8x/p_set_up_the_ctrl_textgenerating_model_on_google/,minimaxir,1568644491,"Over the weekend I posted a [Twitter thread](https://twitter.com/minimaxir/status/1173081315177975810) of my experience with [CTRL](https://github.com/salesforce/ctrl), which received a lot of attention. Today, I'm releasing a script + guides to set up the CTRL text-generating model on Google Compute Engine with just a few console commands: [https://github.com/minimaxir/ctrl-gce](https://github.com/minimaxir/ctrl-gce)

I also added a few more generation examples + usability guides.

Let me know how it works for you!",5,5,False,self,,,,,
846,MachineLearning,t5_2r3gv,2019-9-16,2019,9,16,23,d51osa,self.MachineLearning,[R] Neural Oblivious Decision Ensembles,https://www.reddit.com/r/MachineLearning/comments/d51osa/r_neural_oblivious_decision_ensembles/,justheuristic,1568645290,"**TL;DR:** authors propose a DenseNet-like ensemble of decision trees, trained end-to-end by backpropagation and beats both xgboost and neural networks on heterogeneous (""tabular"") data. 

(IMHO) unlike all other ""neural decision tree"" methods this one worked out of the box for production scale problems without heavy wizardry.

[Differentiable decision tree \(figure 1 from arxiv paper\)](https://i.redd.it/150kgx5exym31.png)

&amp;#x200B;

**ArXiv:** [https://arxiv.org/abs/1909.06312](https://arxiv.org/abs/1909.06312)

**Source code:** [https://github.com/Qwicen/node](https://github.com/Qwicen/node)

&amp;#x200B;

**Abstract:**

Nowadays, deep neural networks (DNNs) have become the main instrument for machine learning tasks within a wide range of domains, including vision, NLP, and speech. Meanwhile, in an important case of heterogenous tabular data, the advantage of DNNs over shallow counterparts remains questionable. In particular, there is no sufficient evidence that deep learning machinery allows constructing methods that outperform gradient boosting decision trees (GBDT), which are often the top choice for tabular problems. In this paper, we introduce Neural Oblivious Decision Ensembles (NODE), a new deep learning architecture, designed to work with any tabular data. In a nutshell, the proposed NODE architecture generalizes ensembles of oblivious decision trees, but benefits from both end-to-end gradient-based optimization and the power of multi-layer hierarchical representation learning. With an extensive experimental comparison to the leading GBDT packages on a large number of tabular datasets, we demonstrate the advantage of the proposed NODE architecture, which outperforms the competitors on most of the tasks. We open-source the PyTorch implementation of NODE and believe that it will become a universal framework for machine learning on tabular data.",8,61,False,https://b.thumbs.redditmedia.com/2nHzRmMnGNj0zZ9I0CruoPevGE9ll5JlaXrC0sUKCwk.jpg,,,,,
847,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,0,d51uvg,soundcloud.com,Oxford Mathematician Marcus Du Sautoy on Machine Learning and Creativity - Podcast,https://www.reddit.com/r/MachineLearning/comments/d51uvg/oxford_mathematician_marcus_du_sautoy_on_machine/,Dr_Christo,1568646063,,0,1,False,default,,,,,
848,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,0,d51wac,self.ArtificialInteligence,AI Solves: King is to Queen as Brother is to ... ?,https://www.reddit.com/r/MachineLearning/comments/d51wac/ai_solves_king_is_to_queen_as_brother_is_to/,katema_ai_studio,1568646227,,0,1,False,default,,,,,
849,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,1,d52skj,self.MachineLearning,"Could a neural network be used to recreate open world game environments across engines, effectively standardizing them?",https://www.reddit.com/r/MachineLearning/comments/d52skj/could_a_neural_network_be_used_to_recreate_open/,Duhduhdoctorthunder,1568650075,"I'm an amateur who doesn't know much about programming but I have always been very interested in neural networks. This seems like a feasible idea to me, do you agree? I'm sure neural networks are going to be used in some sort of procedurally generated open world maps in the future in some form, even if it doesn't incorporate this idea. However that will need a sort of engine to work on, and my idea could be a good stepping stone to get to that goal. Creating unique and new maps is tougher than just doing an impression with style transfer of an existing map.",0,1,False,self,,,,,
850,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,1,d533fi,self.MachineLearning,Systems/algorithms similar to FaceApp with CLI?,https://www.reddit.com/r/MachineLearning/comments/d533fi/systemsalgorithms_similar_to_faceapp_with_cli/,xiguas,1568651374,[removed],0,1,False,self,,,,,
851,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,1,d53bab,towardsdatascience.com,The AI community needs to talk about Universal Basic Income,https://www.reddit.com/r/MachineLearning/comments/d53bab/the_ai_community_needs_to_talk_about_universal/,DeepGamingAI,1568652304,,0,1,False,default,,,,,
852,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,2,d53utq,medium.com,New AI Face Anonymization Model Protects Privacy,https://www.reddit.com/r/MachineLearning/comments/d53utq/new_ai_face_anonymization_model_protects_privacy/,Yuqing7,1568654659,,0,1,False,https://a.thumbs.redditmedia.com/3TQ_Mko6p66Ycy4Xzsytp4ojO1VXsg7qwzUKybMb2A8.jpg,,,,,
853,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,3,d54nm0,atlas.dessa.com,[Discussion] Has anyone checked this out? Seems like comet.ml but with more local features? Also has Tensorboard integration which is neat,https://www.reddit.com/r/MachineLearning/comments/d54nm0/discussion_has_anyone_checked_this_out_seems_like/,jules2689,1568659734,,0,2,False,default,,,,,
854,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,3,d54toi,atlas.dessa.com,[Discussion] Has anyone checked this out? Seems like comet.ml but with more local features? Also has Tensorboard integration which is neat. Looking for ML platform suggestions,https://www.reddit.com/r/MachineLearning/comments/d54toi/discussion_has_anyone_checked_this_out_seems_like/,jules2689,1568660368,,0,4,False,default,,,,,
855,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,4,d54zxj,self.MachineLearning,[Discussion] What do you want in an online competitive environment?,https://www.reddit.com/r/MachineLearning/comments/d54zxj/discussion_what_do_you_want_in_an_online/,zollandd,1568661044,"*Background*

Im currently working on a project called [Terrarium.ai](http://Terrarium.ai). It's an online (persistent) environment where you can develop models that control agents remotely. Ive been developing the environment but recently got into a bit of an argument with myself about what direction to take the environment. At the moment cells can observe the cells around with 2 senses, **smell** and **vision**. They then have a choice between 3 actions: **move**, **eat**, and **attack**. 

[Here is a link to documentation about observations with more info.](https://docs.terrarium.ai/how-it-works/agents/observations)

My goal with this project is to simulate the life of single celled organisms who have decision making brains. This means there is no defined objective at the moment other than survival. The agents arent tasked with simple goals such as collecting anything or achieving a score. The goal is the same as our observable nature: survive and reproduce given your environment. 

The current environment facilitates some interesting scenarios, but my community has pointed out to me that this is fairly simple and isnt incredibly challenging for a model to learn how to control agents that can simply survive. I want to make it more difficult to survive, but dont know how to facilitate more interesting actions for the agents as a group. This is where I would like your input! 

**What do you think would make the environment more interesting and challenging? Whatdo you want in an online competitive environment?**",1,1,False,self,,,,,
856,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,4,d55drc,self.MachineLearning,[D] Any developments on randomly wired neural networks?,https://www.reddit.com/r/MachineLearning/comments/d55drc/d_any_developments_on_randomly_wired_neural/,MartialLemur,1568662625,"I recently read this [paper](https://arxiv.org/abs/1904.01569) which randomly wires image classification networks using classical random graph generators. 

I'm interested in the subject but haven't been able to find anything on it since. 
Has anyone heard of any new developments on the subject?",8,9,False,self,,,,,
857,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,4,d55fdr,self.MachineLearning,"Given a dataset, a month time and labels for an arbitrary machine learning problem, how would the solution from a google team look different from mine?",https://www.reddit.com/r/MachineLearning/comments/d55fdr/given_a_dataset_a_month_time_and_labels_for_an/,bokuWaKamida,1568662812,Other than the performance.,0,1,False,self,,,,,
858,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,5,d55tmf,semanticscholar.org,[p] Wow. My first DL paper (on question answering) is now at 10 citations! I didn't think I'd get this far!!,https://www.reddit.com/r/MachineLearning/comments/d55tmf/p_wow_my_first_dl_paper_on_question_answering_is/,Deepblue129,1568664372,,0,1,False,default,,,,,
859,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,5,d55uk3,semanticscholar.org,[R] My first DL paper is now at 10 citations! I didn't think I'd get this far!!,https://www.reddit.com/r/MachineLearning/comments/d55uk3/r_my_first_dl_paper_is_now_at_10_citations_i/,Deepblue129,1568664473,,0,1,False,default,,,,,
860,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,5,d567ti,self.MachineLearning,[D] Keras output of simple network dependent on batch size,https://www.reddit.com/r/MachineLearning/comments/d567ti/d_keras_output_of_simple_network_dependent_on/,idg101,1568666027," [https://github.com/keras-team/keras/issues/13328](https://github.com/keras-team/keras/issues/13328) 

Depending on the other data in the batch, keras will return different results.  My test shows very minor differences but alas, they should all be identical.  Additionally, I have datasets in this error grows considerably.  I am working on creating a test I can release showing the issue.",9,0,False,self,,,,,
861,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,6,d56l4k,youtube.com,Read a paper: Code2vec-- word2vec for code,https://www.reddit.com/r/MachineLearning/comments/d56l4k/read_a_paper_code2vec_word2vec_for_code/,ggvh,1568667640,,0,1,False,default,,,,,
862,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,6,d57973,self.MachineLearning,What are some hot topics of research in ML right now?,https://www.reddit.com/r/MachineLearning/comments/d57973/what_are_some_hot_topics_of_research_in_ml_right/,__horned_owl__,1568670550,[removed],0,1,False,self,,,,,
863,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,7,d57xyl,reddit.com,Why decoder-only transformer is better than Both-encoder-decoder model in many monolingual text-to-text tasks,https://www.reddit.com/r/MachineLearning/comments/d57xyl/why_decoderonly_transformer_is_better_than/,hustlf,1568673639,,0,1,False,default,,,,,
864,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,7,d58382,self.MachineLearning,Why decoder-only transformer is better than Both-encoder-decoder model in many monolingual text-to-text tasks,https://www.reddit.com/r/MachineLearning/comments/d58382/why_decoderonly_transformer_is_better_than/,hustlf,1568674292,[removed],0,1,False,self,,,,,
865,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,8,d58kkn,self.MachineLearning,[1802.06509] On the Optimization of Deep Networks: Implicit Acceleration by Overparameterization,https://www.reddit.com/r/MachineLearning/comments/d58kkn/180206509_on_the_optimization_of_deep_networks/,btimar,1568676539,Cool paper on how overparameterizing linear models can speed up training in some cases (although apparently this doesn't hold for MSE loss -- I don't have a good intuitive understanding of why not),0,1,False,self,,,,,
866,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,8,d58ufy,youtu.be,Evolving AIs eating each other | With Pheromones ! [OC],https://www.reddit.com/r/MachineLearning/comments/d58ufy/evolving_ais_eating_each_other_with_pheromones_oc/,Naotagrey,1568677874,,1,1,False,https://b.thumbs.redditmedia.com/T44rRqdEnlxJiRhuILtfqlOlpWYIgV6l4TCimCLCPcM.jpg,,,,,
867,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,9,d590ol,babystrollerguide.com,Baby Stroller Guide,https://www.reddit.com/r/MachineLearning/comments/d590ol/baby_stroller_guide/,elvabradburnugz,1568678754,,0,1,False,default,,,,,
868,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,10,d59rav,sniklaus.com,3D Ken Burns Effect from a Single Image,https://www.reddit.com/r/MachineLearning/comments/d59rav/3d_ken_burns_effect_from_a_single_image/,sniklaus,1568682408,,1,1,False,default,,,,,
869,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,10,d59ror,self.MachineLearning,what ethical issues will arise with intelligent autonomous systems that we have yet to confront?,https://www.reddit.com/r/MachineLearning/comments/d59ror/what_ethical_issues_will_arise_with_intelligent/,abusadfkjasblkj,1568682460,[removed],0,1,False,self,,,,,
870,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,10,d59sdl,sniklaus.com,[R] 3D Ken Burns Effect from a Single Image,https://www.reddit.com/r/MachineLearning/comments/d59sdl/r_3d_ken_burns_effect_from_a_single_image/,sniklaus,1568682561,,1,1,False,default,,,,,
871,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,10,d59znz,self.MachineLearning,"[D] If you know SQL, you probably understand Transformer, BERT and GPT",https://www.reddit.com/r/MachineLearning/comments/d59znz/d_if_you_know_sql_you_probably_understand/,transformer_ML,1568683570,"Distilling the Transformer Architecture into its First Principle.
[Link](https://link.medium.com/2aqWzdmM2Z)",6,0,False,self,,,,,
872,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,11,d5akdq,self.MachineLearning,[R] The Bottom-up Evolution of Representations in the Transformer: A Study with Machine Translation and Language Modeling Objectivists (EMNLP 2019),https://www.reddit.com/r/MachineLearning/comments/d5akdq/r_the_bottomup_evolution_of_representations_in/,wei_jok,1568686468,"Abstract:

We seek to understand how the representations of individual tokens and the structure of the learned feature space evolve between layers in deep neural networks under different learning objectives. We focus on the Transformers for our analysis as they have been shown effective on various tasks, including machine translation (MT), standard left-to-right language models (LM) and masked language modeling (MLM). Previous work used black-box probing tasks to show that the representations learned by the Transformer differ significantly depending on the objective. In this work, we use canonical correlation analysis and mutual information estimators to study how information flows across Transformer layers and how this process depends on the choice of learning objective. For example, as you go from bottom to top layers, information about the past in left-to-right language models gets vanished and predictions about the future get formed. In contrast, for MLM, representations initially acquire information about the context around the token, partially forgetting the token identity and producing a more generalized token representation. The token identity then gets recreated at the top MLM layers.

Evolution of Representations in the Transformer (Blog Post, recommended!)

https://lena-voita.github.io/posts/emnlp19_evolution.html

Link to paper: https://arxiv.org/abs/1909.01380",0,1,False,self,,,,,
873,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,13,d5c9co,medium.com,Benefits of Using Machine Learning in Supply Chain,https://www.reddit.com/r/MachineLearning/comments/d5c9co/benefits_of_using_machine_learning_in_supply_chain/,erp_oodles,1568696318,,0,1,False,default,,,,,
874,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,15,d5cv4x,self.MachineLearning,Clustering stock trading,https://www.reddit.com/r/MachineLearning/comments/d5cv4x/clustering_stock_trading/,marcomanny,1568700399,[removed],0,1,False,self,,,,,
875,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,16,d5dmic,self.MachineLearning,null values wont show,https://www.reddit.com/r/MachineLearning/comments/d5dmic/null_values_wont_show/,clownboyz7,1568705697,[removed],0,1,False,self,,,,,
876,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,16,d5drj2,self.MachineLearning,Guassian process regression for panel data,https://www.reddit.com/r/MachineLearning/comments/d5drj2/guassian_process_regression_for_panel_data/,SirFitzherbert,1568706807,[removed],0,1,False,self,,,,,
877,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,17,d5dyxd,smarten.com,Can Data Discovery Improve My Business Users Performance?,https://www.reddit.com/r/MachineLearning/comments/d5dyxd/can_data_discovery_improve_my_business_users/,ElegantMicroWebIndia,1568708421,,0,1,False,default,,,,,
878,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,18,d5efkg,medium.com,How Machine Learning Is Improving Business Processes,https://www.reddit.com/r/MachineLearning/comments/d5efkg/how_machine_learning_is_improving_business/,Techno_SUPPORT,1568711989,,0,1,False,default,,,,,
879,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,19,d5ez5v,deepmind.com, Episode 8: Demis Hassabis - The interview,https://www.reddit.com/r/MachineLearning/comments/d5ez5v/episode_8_demis_hassabis_the_interview/,sjoerdapp,1568715816,,0,1,False,default,,,,,
880,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,19,d5f8r6,youtu.be,Evolving AIs eating each other | With Pheromones !,https://www.reddit.com/r/MachineLearning/comments/d5f8r6/evolving_ais_eating_each_other_with_pheromones/,Naotagrey,1568717529,,1,1,False,default,,,,,
881,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,20,d5fj3q,self.MachineLearning,How to Control Any Type Fluid in Any Type of Customize Machine?,https://www.reddit.com/r/MachineLearning/comments/d5fj3q/how_to_control_any_type_fluid_in_any_type_of/,uflowindia,1568719263,[removed],0,1,False,https://b.thumbs.redditmedia.com/OPD5RCKoY8_o3Y6GG1AwLgtuYjVXJRLaVMy9vWUwCqU.jpg,,,,,
882,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,20,d5fw02,zoom.us,Upcoming Webinar: Patenting AI with Pearl Cohen,https://www.reddit.com/r/MachineLearning/comments/d5fw02/upcoming_webinar_patenting_ai_with_pearl_cohen/,CometML,1568721319,,0,1,False,default,,,,,
883,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,21,d5fxtl,heartbeat.fritz.ai,Building a Sound Classification iOS Application using AI,https://www.reddit.com/r/MachineLearning/comments/d5fxtl/building_a_sound_classification_ios_application/,omarmhaimdat,1568721622,,0,1,False,default,,,,,
884,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,22,d5h0bo,i.redd.it,AI or unsupervised machine learning? ,https://www.reddit.com/r/MachineLearning/comments/d5h0bo/ai_or_unsupervised_machine_learning/,Ksrouji,1568726984,,0,1,False,https://b.thumbs.redditmedia.com/oFgVzdMQix9GED5UWbcfYVCh5Hy5nsS0LfhSOn_2jTM.jpg,,,,,
885,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,22,d5h2mw,zeldatech.com,Machine Learning for Developers By Rodolfo Bonnin PDF,https://www.reddit.com/r/MachineLearning/comments/d5h2mw/machine_learning_for_developers_by_rodolfo_bonnin/,oussamaouti,1568727285,,0,1,False,https://b.thumbs.redditmedia.com/rb9oqYlxn_muwnthbCI4NhWa9_kOxVDYXNReZL7X7pA.jpg,,,,,
886,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,23,d5hq8b,self.MachineLearning,My first ever paper on camouflage detection in the animal kingdom.,https://www.reddit.com/r/MachineLearning/comments/d5hq8b/my_first_ever_paper_on_camouflage_detection_in/,lomiag,1568730277,[removed],0,1,False,self,,,,,
887,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,23,d5hzde,self.MachineLearning,Is ReLU ReLUvant?,https://www.reddit.com/r/MachineLearning/comments/d5hzde/is_relu_reluvant/,prateeksworld,1568731441,Deep neural networks have been widely used in diverse domains in recent few years. I did a small experiment of randomly dropping ReLU (Activation Layer) in an Object Recognition model and got really surprising results. Read the complete story here: [Is ReLU relevant?](https://towardsdatascience.com/is-relu-reluvant-52b03bc48daa). This is  the first time I have every written an article. Do read and let me know what  you think about it in the comments.,0,1,False,self,,,,,
888,MachineLearning,t5_2r3gv,2019-9-17,2019,9,17,23,d5i2hg,self.MachineLearning,[R] Meta-Learning with Implicit Gradients,https://www.reddit.com/r/MachineLearning/comments/d5i2hg/r_metalearning_with_implicit_gradients/,rikkajounin,1568731829,"New meta-learning approach that doesn't require to backprop through the inner problem dynamics (Uses the Implicit Function theorem). The paper has been accepted at NeurIPS:

[https://arxiv.org/abs/1909.04630](https://arxiv.org/abs/1909.04630)",24,97,False,self,,,,,
889,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,0,d5i7ih,self.MachineLearning,Bhattacharya distance in VAE instead of KL divergence?,https://www.reddit.com/r/MachineLearning/comments/d5i7ih/bhattacharya_distance_in_vae_instead_of_kl/,Climb2K2,1568732451,"Since, KL Divergence suffers from Variance overestimation in models like VAE and when we are estimating the VAE between two gaussian vectors (like here,  [https://openreview.net/forum?id=SyxtJh0qYm](https://openreview.net/forum?id=SyxtJh0qYm) ), can we use Bhattacharya distance instead of KLD?",0,1,False,self,,,,,
890,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,0,d5igdv,self.MachineLearning,Consistency of Feature Impact Across Various Models,https://www.reddit.com/r/MachineLearning/comments/d5igdv/consistency_of_feature_impact_across_various/,furyincarnate,1568733507,[removed],0,1,False,self,,,,,
891,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,0,d5ilhc,self.MachineLearning,[D] Machine Learning In Field of Cyber Security,https://www.reddit.com/r/MachineLearning/comments/d5ilhc/d_machine_learning_in_field_of_cyber_security/,shivammehta007,1568734110,"Hi, I found some companies of Information Security and Cyber Security that implement Machine Learning, but I couldn't understand in what field or sector of InfoSec will they be implementing cyber security? 
What I could think of is anomalies in logs? 
Any more ways you guys think it can be implemented?",17,12,False,self,,,,,
892,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,0,d5inq3,self.MachineLearning,"October 8 Talk with HCI Pioneer Joseph Konstan: ""Recommender Systems: Beyond Machine Learning""",https://www.reddit.com/r/MachineLearning/comments/d5inq3/october_8_talk_with_hci_pioneer_joseph_konstan/,ACMLearning,1568734384,[removed],0,1,False,self,,,,,
893,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,0,d5iqop,artnome.com,Tabula Rasa - Rethinking the intelligence of machine minds,https://www.reddit.com/r/MachineLearning/comments/d5iqop/tabula_rasa_rethinking_the_intelligence_of/,hoopism,1568734741,,0,1,False,default,,,,,
894,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,0,d5iv98,fermatslibrary.com,Some Studies In Machine Learning Using the Game of Checkers (1959),https://www.reddit.com/r/MachineLearning/comments/d5iv98/some_studies_in_machine_learning_using_the_game/,mgdo,1568735295,,0,1,False,default,,,,,
895,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,0,d5ivlc,self.MachineLearning,[D] Consistency of Impact for Selected Features Across Model Types,https://www.reddit.com/r/MachineLearning/comments/d5ivlc/d_consistency_of_impact_for_selected_features/,furyincarnate,1568735335,"Ive been experimenting with DataRobot as of late and Ive noticed that given a fixed set of features, the choice of n (e.g. 10) most impactful features differs significantly from one model type to another. Given that different algorithms may have differing sensitivity to input data type and specific effects present in the training data set, how would one go about shortlisting a set of features that would be consistently impactful across a variety of algorithms?

Current train of thought has me stuck at two options:
1. Rank top n features by model impact for various models (say top 5 best performing models) and select features that show the least change in ranking; or
2.  Examine pairwise correlation with target for all features and if variables with low correlation are selected in the final model, sanity check for nonlinear relationship using contour plots. 

Your thoughts/comments are much appreciated. 


P. S. Discussion is motivated by my model validation team that insists on me benchmarking every model against logistic regression because thats the only one they understand. Theme of the month is Why are the variables selected in your model significantly different from those used in our traditional LR model?.",12,4,False,self,,,,,
896,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,1,d5jcub,self.MachineLearning,[R] BERT fine-tuning and Contrastive Learning,https://www.reddit.com/r/MachineLearning/comments/d5jcub/r_bert_finetuning_and_contrastive_learning/,kingcai,1568737498,"Hi, I wrote up some research I've been doing over the summer, mainly on combining transformer networks with contrastive learning in order to learn better sentence representations. 

https://jcaip.github.io/Summer-Research/",2,7,False,self,,,,,
897,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,1,d5jpk4,self.MachineLearning,Machine Learning Probability Question HELP?,https://www.reddit.com/r/MachineLearning/comments/d5jpk4/machine_learning_probability_question_help/,Istackzz,1568739081,[removed],0,1,False,self,,,,,
898,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,2,d5k046,self.MachineLearning,Looking for collaborators on resource portal,https://www.reddit.com/r/MachineLearning/comments/d5k046/looking_for_collaborators_on_resource_portal/,MichaelMMeskhi,1568740374,[removed],0,1,False,self,,,,,
899,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,2,d5k0s5,medium.com,Why Playing Hide-and-Seek Could Lead AI to Humanlike Intelligence,https://www.reddit.com/r/MachineLearning/comments/d5k0s5/why_playing_hideandseek_could_lead_ai_to/,Yuqing7,1568740450,,0,1,False,https://b.thumbs.redditmedia.com/9KHSY_yduGho2OC8aYymLU0qEoX2ATOroDB6sg4CWbg.jpg,,,,,
900,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,2,d5k2rm,openai.com,[R] Emergent Tool Use from Multi-Agent Interaction,https://www.reddit.com/r/MachineLearning/comments/d5k2rm/r_emergent_tool_use_from_multiagent_interaction/,Carcaso,1568740711,,0,1,False,https://a.thumbs.redditmedia.com/7RjUEWHksc6Q1bjrqn0LIKWTDi7JsujS2zp4YQonVm4.jpg,,,,,
901,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,2,d5k5ui,self.MachineLearning,AL ML will certainly replace majority of jobs in next 10 years,https://www.reddit.com/r/MachineLearning/comments/d5k5ui/al_ml_will_certainly_replace_majority_of_jobs_in/,avnijainblr12,1568741090,[removed],0,1,False,self,,,,,
902,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,2,d5kci4,self.MachineLearning,Suggestions on good practice when merging k-means clusters,https://www.reddit.com/r/MachineLearning/comments/d5kci4/suggestions_on_good_practice_when_merging_kmeans/,The_Foetus,1568741882,"Hi, I posted this on /r/datascience but thought I'd x-post for visibility.

I was wondering if I could get some feedback into whether my methodology is problematic or not.

I'm working with a pre-established set of 12 cluster centroids in a classification problem, based on the output of a 42-element 2D joint histogram. When classifying points, these histograms are collapsed so that the classification is only done on a 3-element vector representing the mean quantities of the data point.

The purpose of this is to identify cloud types, to feed into some of my cluster-specific analysis. Now, three adjacent cluster centroids all refer to the same cloud type, however they have different 'thicknesses'. In my final work, I'd like there to be just a single cluster to represent this type. I worry though, by just merging by, for instance, taking the mean of these centroids, the classification step will miss many points that would've ordinarily been assigned to these clusters, because they might then be closer to another centroid which doesn't represent the data point accurately.

My idea is to classify my datapoints with a codebook containing the three centroids (say, clusters 1, 2, and 3). After allocating all my points, I'd then merge the clusters together into a single classification. This would then result in a cluster which has been manually extended to capture points that wouldn't ordinarily be in it.

Is this a problematic way of merging clusters, as opposed to say, taking the mean of the three cluster centroids? Or are there better ways of doing this?

I've drawn out a basic diagram attempting to illustrate what I mean - https://i.imgur.com/aGIW3f5.jpg

Thanks a lot in advance",0,1,False,self,,,,,
903,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,2,d5kgyb,developer.amazon.com,Amazon Releases Data Set of Annotated Conversations to Aid Development of Socialbots : Alexa Blogs,https://www.reddit.com/r/MachineLearning/comments/d5kgyb/amazon_releases_data_set_of_annotated/,georgecarlyle76,1568742424,,0,1,False,default,,,,,
904,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,2,d5kh2b,self.MachineLearning,LOUHI 2019,https://www.reddit.com/r/MachineLearning/comments/d5kh2b/louhi_2019/,idekwhoiam7,1568742438,[removed],0,1,False,self,,,,,
905,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,3,d5kp8t,self.MachineLearning,[D] Suggestions on good practice when merging k-means centroids,https://www.reddit.com/r/MachineLearning/comments/d5kp8t/d_suggestions_on_good_practice_when_merging/,The_Foetus,1568743384,"Hi, I posted this on /r/datascience but thought I'd x-post for visibility.

I was wondering if I could get some feedback into whether my methodology is problematic or not.

I'm working with a pre-established set of 12 cluster centroids in a classification problem, based on the output of a 42-element 2D joint histogram. When classifying points, these histograms are collapsed so that the classification is only done on a 3-element vector representing the mean quantities of the data point.

The purpose of this is to identify cloud types, to feed into some of my cluster-specific analysis. Now, three adjacent cluster centroids all refer to the same cloud type, however they have different 'thicknesses'. In my final work, I'd like there to be just a single cluster to represent this type. I worry though, by just merging by, for instance, taking the mean of these centroids, the classification step will miss many points that would've ordinarily been assigned to these clusters, because they might then be closer to another centroid which doesn't represent the data point accurately.

My idea is to classify my datapoints with a codebook containing the three centroids (say, clusters 1, 2, and 3). After allocating all my points, I'd then merge the clusters together into a single classification. This would then result in a cluster which has been manually extended to capture points that wouldn't ordinarily be in it.

Is this a problematic way of merging clusters, as opposed to say, taking the mean of the three cluster centroids? Or are there better ways of doing this?

I've drawn out a basic diagram attempting to illustrate what I mean - https://i.imgur.com/aGIW3f5.jpg
Thanks a lot in advance

EDIT: I've looked at agglomerative clustering but I'm working off an (almost) nicely defined set of clusters, aside from this issue. I tried merging cluster centroids using agglomerative but unfortunately it agglomerated together two which I didn't want merged. (PS. is this how you do agglom clustering? Can you just train the agglom algorithm by passing it the original k-means centroids?)",2,2,False,self,,,,,
906,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,3,d5kurv,self.MachineLearning,Support for TensorFlow on AMD cards has been upstreamed,https://www.reddit.com/r/MachineLearning/comments/d5kurv/support_for_tensorflow_on_amd_cards_has_been/,lostmsu,1568744038,[removed],0,1,False,self,,,,,
907,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,3,d5kyd5,self.MachineLearning,SRGAN: Adapt the model to the input image?,https://www.reddit.com/r/MachineLearning/comments/d5kyd5/srgan_adapt_the_model_to_the_input_image/,JarsOfJam-Scheduler,1568744482,[removed],5,1,False,self,,,,,
908,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,3,d5kyzs,self.MachineLearning,[R] Emergent Tool Use from Multi-Agent Interaction,https://www.reddit.com/r/MachineLearning/comments/d5kyzs/r_emergent_tool_use_from_multiagent_interaction/,ivalm,1568744557,"Paper: https://d4mucfpksywv.cloudfront.net/emergent-tool-use/paper/Multi_Agent_Emergence_2019.pdf
Blog: https://openai.com/blog/emergent-tool-use/

TLDR: Hide and seek game where there are moveable blocks + ramps. Hiders and seekers learn to use them to complete task. Trained with PPO + transformer NN for representing objects

Abstract: Through multi-agent competition, the simple objective of hide-and-seek, and standard reinforcement learning algorithms at scale, we find that agents create a selfsupervised autocurriculum inducing multiple distinct rounds of emergent strategy, many of which require sophisticated tool use and coordination. We find clear evidence of six emergent phases in agent strategy in our environment, each of which
creates a new pressure for the opposing team to adapt; for instance, agents learn to build multi-object shelters using moveable boxes which in turn leads to agents discovering that they can overcome obstacles using ramps. We further provide evidence that multi-agent competition may scale better with increasing environment complexity and leads to behavior that centers around far more human-relevant skills than other self-supervised reinforcement learning methods such as intrinsic motivation. Finally, we propose transfer and fine-tuning as a way to quantitatively evaluate targeted capabilities, and we compare hide-and-seek agents to both intrinsic motivation and random initialization baselines in a suite of domain-specific
intelligence tests.",20,74,False,self,,,,,
909,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,4,d5lrxo,self.MachineLearning,NLP- Analysis of Economic Sentiment Using Logistic Regression,https://www.reddit.com/r/MachineLearning/comments/d5lrxo/nlp_analysis_of_economic_sentiment_using_logistic/,plentyofnodes,1568748015,[removed],0,1,False,self,,,,,
910,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,4,d5m2k4,self.MachineLearning,Data Science at Scale Training  Your ticket to new career and income opportunities,https://www.reddit.com/r/MachineLearning/comments/d5m2k4/data_science_at_scale_training_your_ticket_to_new/,internetdigitalentre,1568749298,[removed],0,1,False,self,,,,,
911,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,4,d5m7pu,self.MachineLearning,[P] Analysis of Economic Sentiment Using Logistic Regression,https://www.reddit.com/r/MachineLearning/comments/d5m7pu/p_analysis_of_economic_sentiment_using_logistic/,plentyofnodes,1568749911,"Recently, I've been working on a side project to gauge market sentiment from central bank reports using logistic regression.

Here are some findings that may be of use if you're looking to do sentiment analysis with NLP, and would also be grateful for any feedback or pointers.

Findings: https://www.michael-grogan.com/sentiment-analysis-economics/",1,3,False,self,,,,,
912,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,8,d5ov3l,linkedin.com,This is my machine learning A.I. project: A Walk in the Store with Machine Learning A.I.: A Retail Store Planogram Analysis. Please feel free to let me know how you think. Thanks. #retail #machinelearning,https://www.reddit.com/r/MachineLearning/comments/d5ov3l/this_is_my_machine_learning_ai_project_a_walk_in/,simonyam227,1568761762,,0,1,False,https://b.thumbs.redditmedia.com/uegHjMJNEelFEYlJ5GcmEV5b0A-RL4vTjQP-YZ5NqEQ.jpg,,,,,
913,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,9,d5pp0g,self.MachineLearning,[Discussion] What is the state-of-the-art for entity extraction and relation extraction?,https://www.reddit.com/r/MachineLearning/comments/d5pp0g/discussion_what_is_the_stateoftheart_for_entity/,Tash_is_Aslan,1568765757,"Hi,

I am looking for the state-of-the-art entity extraction/relation extraction algorithms that are **practical** to implement and use for commercial information extraction.  An example:

""**Mr. Wilken** is the **CEO** of **Foobar, inc.** ""

Entities are Mr. Wilken, CEO, Foobar, inc.  Mr. Wilken's title is CEO.  Mr. Wilken works at Foobar, Inc (transitively he is then the CEO of Foobar, Inc.).  

In my experience I've used CRF used hand crafted features for entity tagging followed by a classifier to determine relations between entities use hand crafted features.  This is a pretty old school approach and does not leverage any of the advances in word embeddings (Glove, BERT, etc.).  I know there are also methods for doing joint entity + relation extraction.  

There are dozens of papers on Google scholar, and I'm not sure which ones would be worth implementing.  I'm looking for recommendations of recent papers to read that would get me started.",9,48,False,self,,,,,
914,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,10,d5qlhd,arxiv.org,[R] 3D Ken Burns Effect from a Single Image,https://www.reddit.com/r/MachineLearning/comments/d5qlhd/r_3d_ken_burns_effect_from_a_single_image/,sniklaus,1568770190,,28,131,False,default,,,,,
915,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,10,d5qopa,self.MachineLearning,AdvFaces: Adversarial Face Synthesis for Attacking State-of-the-Art Face Recognition Systems,https://www.reddit.com/r/MachineLearning/comments/d5qopa/advfaces_adversarial_face_synthesis_for_attacking/,debayandeb3050,1568770614,[removed],0,1,False,self,,,,,
916,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,10,d5qtam,self.MachineLearning,e-PDF for Probabilistic System analysis and applied probability course in MIT,https://www.reddit.com/r/MachineLearning/comments/d5qtam/epdf_for_probabilistic_system_analysis_and/,BhanujeetC,1568771241,[removed],0,1,False,self,,,,,
917,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,10,d5qtzn,arxiv.org,Determining the Scale of Impact from Denial-of-Service Attacks in Real Time Using Twitter,https://www.reddit.com/r/MachineLearning/comments/d5qtzn/determining_the_scale_of_impact_from/,codehacked,1568771342,,1,1,False,default,,,,,
918,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,11,d5rejt,self.MachineLearning,Small CLI tool for black-box Bayesian optimization,https://www.reddit.com/r/MachineLearning/comments/d5rejt/small_cli_tool_for_blackbox_bayesian_optimization/,nerdponx,1568774219,[removed],0,1,False,self,,,,,
919,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,11,d5retr,imac-torrents.com,Final Cut Pro X 10.4.6 Crack,https://www.reddit.com/r/MachineLearning/comments/d5retr/final_cut_pro_x_1046_crack/,Imac-Torrents,1568774254,,0,1,False,https://a.thumbs.redditmedia.com/MZB5FFLV982X-EoyqErY_pCmg8jw9EWHN9NTIQGPJM4.jpg,,,,,
920,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,11,d5rjgk,self.MachineLearning,Make the Internet Your AI University and Be a Changemaker - AI for Good,https://www.reddit.com/r/MachineLearning/comments/d5rjgk/make_the_internet_your_ai_university_and_be_a/,Lordobba,1568774943,"Munira left Somalia because of violence but rather than losing her hope she has a big vision.

In one event, an electronics shop close to her university was completely destroyed a few minutes after she left her laptop for repairment.

This of one of many events that did not stop Munira from following her vision to improve her skills, empower other women in STEM, and use technologies such as Machine Learning to solve problems in her country and beyond.

&gt;I want to solve community problems like droughts and also improve many industries in my country using Deep Learning and Computer Vision in the near future.

Now Munira received a Facebook AI scholarship. 

The power of the internet can seem endless.

[The full article](https://medium.com/omdena/make-the-internet-your-ai-university-and-be-a-changemaker-f75d9c441f78)",0,1,False,self,,,,,
921,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,11,d5rlq2,self.MachineLearning,[P] Command-line tool for Bayesian black-box optimization,https://www.reddit.com/r/MachineLearning/comments/d5rlq2/p_commandline_tool_for_bayesian_blackbox/,nerdponx,1568775258,"Hi r/machinelearning,

I wrote a CLI tool that runs black-box Bayesian optimization on an arbitrary shell command.

https://gitlab.com/gwerbin/bayesopt-cli

Usage:
1. Define a ""space"" to optimize over, using the Scikit-optimize YAML specification format
2. Run the `bayesopt` tool
3. Save a summary of results from stdout, and/or load the full saved ""optimization result"" object from disk

There is an [example in the repo](https://gitlab.com/gwerbin/bayesopt-cli/tree/master/example) to hopefully make this usage more clear.

Internally, it's just a wrapper for [Scikit-optimize](https://scikit-optimize.github.io), which has been giving me good results. This code could easily be extended to use Hyperopt's TPE optimizer, but I wanted to start simple with one backend.

It also lets you emit output from your command as JSON, with an option to extract a number from it using JMESPath.

Unfortunately installation is annoying at the moment. The Scikit-optimize devs seem to have abandoned the project, so this relies on a patched fork of the latest version. Hopefully that will get straightened out (community fork, maybe?) and I can distribute this like a normal Python package.

Let me know what you think! Is this useful to anyone other than me?",5,4,False,self,,,,,
922,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,11,d5rnt1,self.MachineLearning,Meta-learning for Binary Classification,https://www.reddit.com/r/MachineLearning/comments/d5rnt1/metalearning_for_binary_classification/,arjundupa,1568775582,"Has meta-learning been applied to any binary classification tasks? 

I don't know too much about meta-learning; does my question even make sense? Could it be used to improve the performance of an existing architecture on a binary classification task?",0,1,False,self,,,,,
923,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,12,d5s04x,self.MachineLearning,Nadal vs Djokovic?,https://www.reddit.com/r/MachineLearning/comments/d5s04x/nadal_vs_djokovic/,Lavinna,1568777456,[removed],0,1,False,self,,,,,
924,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,12,d5s6l2,self.MachineLearning,Hep - Detecting people and company names on text with Python,https://www.reddit.com/r/MachineLearning/comments/d5s6l2/hep_detecting_people_and_company_names_on_text/,delical,1568778435,[removed],0,1,False,self,,,,,
925,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,12,d5s9lc,github.com,Keras 2.3.0 release - Development will focus on tf.keras going forward,https://www.reddit.com/r/MachineLearning/comments/d5s9lc/keras_230_release_development_will_focus_on/,arthomas73,1568778911,,0,1,False,https://a.thumbs.redditmedia.com/xslwfQpsg90EXsFvoGzRtOSGz6w_G7lWX87Ng7_OVD8.jpg,,,,,
926,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,12,d5sakn,self.MachineLearning,Help - Detecting people and company names in text - Python,https://www.reddit.com/r/MachineLearning/comments/d5sakn/help_detecting_people_and_company_names_in_text/,delical,1568779073,[removed],0,1,False,self,,,,,
927,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,13,d5srpc,self.MachineLearning,Coding A Bot vs DIY Chatbot Platform,https://www.reddit.com/r/MachineLearning/comments/d5srpc/coding_a_bot_vs_diy_chatbot_platform/,getengati,1568781888,[removed],0,1,False,self,,,,,
928,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,13,d5su46,self.MachineLearning,Is GTX 980Ti still worth it?,https://www.reddit.com/r/MachineLearning/comments/d5su46/is_gtx_980ti_still_worth_it/,meteor_strika,1568782309,[removed],0,1,False,self,,,,,
929,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,14,d5tdbv,self.MachineLearning,Validation Curve Interpretations for Decision Tree,https://www.reddit.com/r/MachineLearning/comments/d5tdbv/validation_curve_interpretations_for_decision_tree/,_icosahedron,1568785718,[removed],0,1,False,https://b.thumbs.redditmedia.com/-cqLkyJI1ohr8poVpJOpLhBtURdOXUeVAtPicrMF9jY.jpg,,,,,
930,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,15,d5tzzd,smarten.com,Smarten Offers 30-day Free Trial of Augmented Analytics Solution on AWS Marketplace,https://www.reddit.com/r/MachineLearning/comments/d5tzzd/smarten_offers_30day_free_trial_of_augmented/,ElegantMicroWebIndia,1568789951,,0,1,False,default,,,,,
931,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,16,d5u5mo,self.MachineLearning,Distributed training with Tensorflow,https://www.reddit.com/r/MachineLearning/comments/d5u5mo/distributed_training_with_tensorflow/,mlthrow101,1568790988,[removed],0,1,False,self,,,,,
932,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,16,d5u7s7,countants.com,How Artificial Intelligence is transforming the E-commerce Industry,https://www.reddit.com/r/MachineLearning/comments/d5u7s7/how_artificial_intelligence_is_transforming_the/,Countants123,1568791400,,0,1,False,default,,,,,
933,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,16,d5uah2,self.MachineLearning,[P] Access raw pointers of Tensorflow tensors.,https://www.reddit.com/r/MachineLearning/comments/d5uah2/p_access_raw_pointers_of_tensorflow_tensors/,SuperShinyEyes,1568791925,"Hi, I collaborated on Redner([https://github.com/BachiLi/redner](https://github.com/BachiLi/redner)), a differentiable graphics renderer, in the summer. I did something uncommon which is access of raw pointers of Tensorflow tensors. Since I couldn't find any example that does this, I thought it might be useful to share my experience here. Thank you and have a lovely day :)

[http://typingducks.com/blog/tensorflow-tensor-pointer-access/](http://typingducks.com/blog/tensorflow-tensor-pointer-access/)

Br,

Seyoung",8,18,False,self,,,,,
934,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,16,d5ubo5,self.MachineLearning,[D] Distributed training with Tensorflow,https://www.reddit.com/r/MachineLearning/comments/d5ubo5/d_distributed_training_with_tensorflow/,mlthrow101,1568792156,[removed],0,1,False,self,,,,,
935,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,17,d5ulck,self.MachineLearning,[P] ClearHead.ai  A marketplace for machine learning models,https://www.reddit.com/r/MachineLearning/comments/d5ulck/p_clearheadai_a_marketplace_for_machine_learning/,vishaan,1568794128,"https://clearhead.ai 

Hello /r/MachineLearning 

I'm the founder of ClearHead.ai, a marketplace for machine learning models which allows modelers to upload their models via a python SDK and developers to use the models with a simple request to an API. 

We are looking for some alpha (not ethological, more this-software-is-rough-around-the-edges) machine learning modelers who have machine learning models they would like to monetize. Ideally image based ones (CNNs, GANs) that are trained on a non-research dataset. If you are interested (both modelers and consumers) please sign-up via the website or this link. 

This approach is similar to Algorithmia, but we want to really focus-in on the problem of model comparability and transparency. 

I'll be in the comments, if you have any questions, feedback or complaints.",7,0,False,self,,,,,
936,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,17,d5uy09,self.MachineLearning,[Project] Latent Painter! A prototype I made today of painting directly with latent representations.,https://www.reddit.com/r/MachineLearning/comments/d5uy09/project_latent_painter_a_prototype_i_made_today/,marshfellowML,1568796781,"This was done by doing some model surgery on a trained StyleGAN (FFHQ dataset) at 256x256 resolution. You can actually paint 512 channel deep latent vectors into tensors at different layers in the model.

Going to be following it up with some really cool features around encoding images to latents so you can paint with the representation of an arbitrary image you have (assuming it's in distribution!).

Definitely more to come but excited this works as well as it does!",0,1,False,self,,,,,
937,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,18,d5v10s,/r/MachineLearning/comments/d5v10s/project_latentpainter_paint_with_ideas_instead_of/,[Project] LatentPainter. Paint with ideas instead of pixels! First working prototype I made today,https://www.reddit.com/r/MachineLearning/comments/d5v10s/project_latentpainter_paint_with_ideas_instead_of/,marshfellowML,1568797397,,0,1,False,https://b.thumbs.redditmedia.com/fM5DZ2KyFrpynHCnLt-qUYcOWP9td_E2rDT2av3d0VA.jpg,,,,,
938,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,18,d5v6ol,self.MachineLearning,How To Control All Type Of Fluid In Any Customized Machine?,https://www.reddit.com/r/MachineLearning/comments/d5v6ol/how_to_control_all_type_of_fluid_in_any/,uflowindia,1568798506,[removed],0,1,False,https://b.thumbs.redditmedia.com/TqePyworDIQUDhYDow1TZWlgl1b_nZr-XwGjdIx2tIc.jpg,,,,,
939,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,19,d5vivw,self.MachineLearning,How To Control All Type Of Fluid In Any Customized Machine?,https://www.reddit.com/r/MachineLearning/comments/d5vivw/how_to_control_all_type_of_fluid_in_any/,uflowindia,1568800930,[removed],0,1,False,self,,,,,
940,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,19,d5vp3k,self.MachineLearning,How do you prepare a dataset for a ML project?,https://www.reddit.com/r/MachineLearning/comments/d5vp3k/how_do_you_prepare_a_dataset_for_a_ml_project/,igorsusmelj,1568802059,[removed],0,1,False,self,,,,,
941,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,19,d5w0a4,self.MachineLearning,[ArchiML.com] Domain Name,https://www.reddit.com/r/MachineLearning/comments/d5w0a4/archimlcom_domain_name/,EmadAbdelhadi,1568804024,[removed],0,1,False,https://b.thumbs.redditmedia.com/F70ECrby_slG5-l1o6hoPaXz5cI4SG-VgOPg-nCwnvI.jpg,,,,,
942,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,20,d5wa7a,self.MachineLearning,Machine Learning Courses,https://www.reddit.com/r/MachineLearning/comments/d5wa7a/machine_learning_courses/,dwivediabhinav,1568805635,[removed],0,1,False,self,,,,,
943,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,20,d5wo9u,self.Aishwarya_Osp,How to Advance Towards Achieving 100% Interoperability in Healthcare?,https://www.reddit.com/r/MachineLearning/comments/d5wo9u/how_to_advance_towards_achieving_100/,Aishwarya_Osp,1568807785,,0,0,False,default,,,,,
944,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,21,d5x0up,self.MachineLearning,How do you interprete this loss graph?,https://www.reddit.com/r/MachineLearning/comments/d5x0up/how_do_you_interprete_this_loss_graph/,thing032817,1568809586,"&amp;#x200B;

[green is validation and blue is train](https://i.redd.it/ugr6zgjhhcn31.png)

This is a language model based on transformer architecture. It is extremely imbalanced data, but still I have no idea how to interprete this and what to do next. 

First guess is the learning rate and scheduler. For this, I used Adam (learning rate: 0.00025 and cosine scheduler). I thought the first phase of train loss increase was due to the imbalanced data, but that should be applied same to the validation data. The suddens peaks occur at the very beginning of epochs. I can't explain why that happens too.",0,1,False,self,,,,,
945,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,21,d5x3fo,data-flair.training,Machine Learning Project - Detecting Parkinsons Disease with XGBoost,https://www.reddit.com/r/MachineLearning/comments/d5x3fo/machine_learning_project_detecting_parkinsons/,AnujG23,1568809956,,0,1,False,https://b.thumbs.redditmedia.com/udeUV6HtesY5ySN46pj2QpHUdTyskzrhxaAmOTx_yeQ.jpg,,,,,
946,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,21,d5x71d,self.MachineLearning,[P] Gobbli: A Python Framework for Text Classification Projects,https://www.reddit.com/r/MachineLearning/comments/d5x71d/p_gobbli_a_python_framework_for_text/,pbaumgartner_rti,1568810443,"At my day job, we do a lot of text classification projects with small/medium size data. Recent advances in transfer learning for NLP have moved these types of projects from impossible to feasible, especially for batch classification tasks we see frequently on survey projects with free-text responses. Models like BERT have been documented for research, and in trying to use them we found ourselves spending a lot of time extending them to the non-benchmarking applications and datasets we were curious about. Given these issues, we built a framework for text classification projects that aims to make the consistent application of transfer learning and other models easier.

For a little more context, we started trying out BERT last year and new models continued to be rapidly released. Every time there was a new model there was a new API to learn. pytorch-transformers from HuggingFace helped a lot with this standardization issue, so we also took a look at what happens before a model is built (data processing and augmentation) and afterwards (model evaluation), and built supporting tools around those problems as well.

In addition, since most models require GPUs, so we were spending a lot of time configuring environments, code, and data in tandem with Docker which gets messy. Because of this, we've abstracted most of that orchestration out so most everything is python code.

Details on the library are below. We've battle tested it on a few projects and are curious to have others kick the tires and give us feedback if you're doing text classification.

- [GitHub Repo](https://github.com/RTIInternational/gobbli)
- [Technical Getting Started](https://medium.com/rti-cds/introducing-gobbli-b625c0a0adfe)
- [Introductory General Audience Blog Post](https://www.rti.org/insights/unified-framework-brings-fresh-approach-text-classification)",26,211,False,self,,,,,
947,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,21,d5xen6,self.MachineLearning,[Discussion] How do you prepare a new dataset for your ML/DL project?,https://www.reddit.com/r/MachineLearning/comments/d5xen6/discussion_how_do_you_prepare_a_new_dataset_for/,rogi_o,1568811475,"I found many guidelines online on how to prepare, analyze and clean datasets in tabular form (e.g. from csv files). Typically, they correlate the features, look for inlier/ outliers in the dataset and remove duplicates as well as corrupt samples.

But how do you perform such steps in a raw dataset consisting just of images or text as typically its the case in deep learning? 

Let's assume I just gathered 100'000 unlabeled images. Are there any tools or guidelines on how to start from there?

Thanks a lot for your input!",2,1,False,self,,,,,
948,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,22,d5xhja,self.MachineLearning,[N] Deconstruct how Google Tulip was built by using serverless tech and machine learning,https://www.reddit.com/r/MachineLearning/comments/d5xhja/n_deconstruct_how_google_tulip_was_built_by_using/,mto96,1568811853,"This is a 35 minute talk from GOTO Amsterdam 2019 by some of the team who helped build Google tulip: Christiaan Hees, Matt Feigal and Lee Boonstra.

[https://www.youtube.com/watch?v=Gv5stbV7XT8&amp;feature=youtu.be&amp;list=PLEx5khR4g7PKT9RvuVyQxJLO8CZUJzNMy](https://www.youtube.com/watch?v=Gv5stbV7XT8&amp;feature=youtu.be&amp;list=PLEx5khR4g7PKT9RvuVyQxJLO8CZUJzNMy)

&amp;#x200B;

I've dropped in the talk abstract below for a read before jumping into the talk:

This is a 35 minute talk from GOTO Amsterdam 2019 by some of the team who helped build Google tulip: Christiaan Hees, Matt Feigal and Lee Boonstra. Check out the full talk abstract below:

How to compose an application of multiple serverless components. Training an ML model for your needs with minimal training data and applying it in your application.

**What will the audience learn from this talk?**  
How to compose an application of multiple serverless components. Training an ML model for your needs with minimal training data, and applying it in your application. Building and running your code in serverless Knative Using Dialogflow to power user conversations.

**Does it feature code examples and/or live coding?**  
It features live demos of our components and end product. Well show code and run scripts to train ML models and deploy our code.",1,4,False,self,,,,,
949,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,22,d5xi0n,youtube.com,Regression - Machine Learning,https://www.reddit.com/r/MachineLearning/comments/d5xi0n/regression_machine_learning/,ShyamTgr,1568811910,,0,1,False,https://b.thumbs.redditmedia.com/m6ILjljzHUA6n767Q5XWm2blg_Fct0QZ8GNdaOmY31o.jpg,,,,,
950,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,22,d5xl1k,day1tech.com,Do you really think block chain &amp; AI are major technologies for innovation?,https://www.reddit.com/r/MachineLearning/comments/d5xl1k/do_you_really_think_block_chain_ai_are_major/,day1technologies,1568812300,,0,1,False,https://a.thumbs.redditmedia.com/lbJPYNTb1jEeqf5QFRWWUv5KLOHAdiCnEp1SuVHejH4.jpg,,,,,
951,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,22,d5xm7z,self.MachineLearning,Choosing a reference column when doing One-hot encoding,https://www.reddit.com/r/MachineLearning/comments/d5xm7z/choosing_a_reference_column_when_doing_onehot/,WoggyPook,1568812454,"Hi, 

I'm facing an issue where I'm using a logistic regression to build a classifier. My main goal is to use the classifier and interpret the results to identify which features contribute to the classification, so as to provide possible explanations and recommendations based on them. 

I understand that I can use the odds ratio to interpret the model. However, since most of my features are categorical, i had to do one-hot encoding for them. The default is to drop the first column and this means that my odds ratio will all be relative to the first column. 

Is there a way to find out which reference-categorical paired columns will provide the highest/lowest odds ratio? Or do I have to change the reference columns manually, retrain the model and then interpret the odds ratios again for each possible combination?",0,1,False,self,,,,,
952,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,23,d5y9di,self.MachineLearning,ML Visual Mold Inspection App,https://www.reddit.com/r/MachineLearning/comments/d5y9di/ml_visual_mold_inspection_app/,vladk97,1568815459,[removed],0,1,False,self,,,,,
953,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,23,d5y9wz,self.MachineLearning,[R] Research Guide for Neural Architecture Search,https://www.reddit.com/r/MachineLearning/comments/d5y9wz/r_research_guide_for_neural_architecture_search/,mwitiderrick,1568815517,"We explore a range of research papers that have sought to solve the challenging task of automating neural network design.

[https://heartbeat.fritz.ai/research-guide-for-neural-architecture-search-b250c5b1b2e5](https://heartbeat.fritz.ai/research-guide-for-neural-architecture-search-b250c5b1b2e5)",0,3,False,self,,,,,
954,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,23,d5yc43,self.MachineLearning,Emergent behavior from OpenAI agents playing hide-and-seek,https://www.reddit.com/r/MachineLearning/comments/d5yc43/emergent_behavior_from_openai_agents_playing/,newsbeagle,1568815797,[removed],0,1,False,self,,,,,
955,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,23,d5ye4o,self.MachineLearning,How to launch a recommendation engine?,https://www.reddit.com/r/MachineLearning/comments/d5ye4o/how_to_launch_a_recommendation_engine/,ganninu93,1568816045,[removed],0,1,False,self,,,,,
956,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,23,d5yieg,deepmind.com, DeepMinds health team joins Google Health,https://www.reddit.com/r/MachineLearning/comments/d5yieg/deepminds_health_team_joins_google_health/,sjoerdapp,1568816584,,0,1,False,default,,,,,
957,MachineLearning,t5_2r3gv,2019-9-18,2019,9,18,23,d5ylj1,self.MachineLearning,[Discussion] Measuring run-time of complex machine learning pipelines,https://www.reddit.com/r/MachineLearning/comments/d5ylj1/discussion_measuring_runtime_of_complex_machine/,humanager,1568816978,"I am working on a fairly long pipeline for a complex project on my hands at the moment. There are several modules that form part of the pipeline. I am also under a strict end-to-end run-time SLA, so need to make sure my pipeline runs within N seconds. I'm investigating timing mechanisms for ML projects as a result. I'm working with Python. 

All I have found in my brief search for mechanisms is the \*\*timeit\*\* to measure execution time of small code snippets, and the simple time() method in the \*\*time\*\* module. This can obviously work, but doesn't seem to be a integrated elegant way to do it when there are multiple stages in the pipeline where you need to measure execution time, etc. 

Does anyone have opinions on what is good, or any alternatives that people use? Cheers!",1,1,False,self,,,,,
958,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,0,d5z46u,ai.googleblog.com,Project Ihmehimmeli: Temporal Coding in Spiking Neural Networks,https://www.reddit.com/r/MachineLearning/comments/d5z46u/project_ihmehimmeli_temporal_coding_in_spiking/,sjoerdapp,1568819229,,0,1,False,default,,,,,
959,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,0,d5znhf,youtube.com,Better Call Trump: Money Laundering 101 [DeepFaked Video and Voice],https://www.reddit.com/r/MachineLearning/comments/d5znhf/better_call_trump_money_laundering_101_deepfaked/,ctrl-shift-face,1568821519,,0,1,False,https://b.thumbs.redditmedia.com/XV-dgIU84oltiDJdFXYbKKbDYWBdxuyXt99_9BCjNwg.jpg,,,,,
960,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,0,d5znu5,/r/MachineLearning/comments/d5znu5/p_latentpainter_working_prototype_of_an_art_tool/,[P] LatentPainter. Working prototype of an art tool Im working on. Paint with ideas instead of pixels!,https://www.reddit.com/r/MachineLearning/comments/d5znu5/p_latentpainter_working_prototype_of_an_art_tool/,marshfellowML,1568821566,,0,1,False,default,,,,,
961,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,0,d5zr48,self.MachineLearning,"Simple Questions Thread September 18, 2019",https://www.reddit.com/r/MachineLearning/comments/d5zr48/simple_questions_thread_september_18_2019/,AutoModerator,1568821956,[removed],0,1,False,self,,,,,
962,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,0,d5zru8,self.MachineLearning,[P] Using protein sequences to make better classifiers in bioinformatics,https://www.reddit.com/r/MachineLearning/comments/d5zru8/p_using_protein_sequences_to_make_better/,Yuras_Stephan,1568822035,"As a data scientist in the bioinformatics field, I often found it useful to add features describing proteins to my models. These were often manually engineered or based on heuristics and alignments, and lacked information on the structure of the protein, as that data is relatively sparse. 

Recently I found a paper by Bepler and Berger, published at ICLR 2019, where they created a set of models that use weak supervision to create protein embeddings. In this blog post I take a look at the theory behind this paper and present an intermediate-level tutorial for people who want to include these embeddings in their own models. A comprehensive analysis of the predictive power of these embeddings is also included.

https://stephanheijl.com/protein_sequence_ml.html",0,13,False,self,,,,,
963,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,0,d5ztsn,self.MachineLearning,[R] AdvFaces: Adversarial Face Synthesis for Attacking State-of-the-Art Face Recognition Systems,https://www.reddit.com/r/MachineLearning/comments/d5ztsn/r_advfaces_adversarial_face_synthesis_for/,debayandeb3050,1568822257,"Hello Reddit!  We successfully attacked 5 state-of-the-art Face ID systems - FaceNet, SphereFace, ArcFace, using synthesized adversarial faces via GAN. The adversarial faces look visually realistic and very similar to the original probes (to a human) while evading face matchers.

Our method is trained on FaceNet but via the attack transferability property, the pretrained model can be used to attack any face recognition system.

I eagerly look forward to your comments!

Paper: [https://arxiv.org/abs/1908.05008](https://arxiv.org/abs/1908.05008)",0,8,False,self,,,,,
964,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,1,d5zy5n,self.MachineLearning,[P] LatentPainter. Paint with ideas instead of pixels!,https://www.reddit.com/r/MachineLearning/comments/d5zy5n/p_latentpainter_paint_with_ideas_instead_of_pixels/,marshfellowML,1568822766,"Hey guys! Heres a fun tool I hacked together by abusing spatialized adaptive instance normalization. You paint directly with the latent Z into different layers of the network (basically StyleGAN with some model surgery). The results are pretty cool! 
:
[link to the video](https://twitter.com/MarshfellowML/status/1174234836858494976?s=20)

Have a lot of features planned including a color picker thats just an encoder to encode the latent Z of an arbitrary image into your latent space so you can paint with it. Also going to be exposing sliders for which layers youre painting on (earlier layers will be the coarse features like facial structure and later layers will be more textural).",0,15,False,self,,,,,
965,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,1,d600n7,medium.com,New AI Technique Builds Dynamic Images From a Single Photo,https://www.reddit.com/r/MachineLearning/comments/d600n7/new_ai_technique_builds_dynamic_images_from_a/,Yuqing7,1568823066,,0,1,False,https://b.thumbs.redditmedia.com/OKippzZc9urBUbDKHT5kpb7nFfMUfJv5QeNaiAcNsek.jpg,,,,,
966,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,3,d61m28,self.MachineLearning,[D] Instance weighting with soft labels.,https://www.reddit.com/r/MachineLearning/comments/d61m28/d_instance_weighting_with_soft_labels/,ockidocki,1568829789,"Suppose you are given training instances with soft labels. I.e., your training instances are of the form (x,y,p), where x ins the input, y is the class and p is the *probability* that x is of class y. 

Some classifiers allow you to specify an *instance weight* for each example in the training set. The idea is that a misprediction for a particular example is penalized proportionality to its weight, so instances with high weight are more important to get right and instances with a low weight are less important. 

When examples are of the form (x,y,p), it's clear that the class probabilities could be used as instance weights. A simple way to do this is to weight the loss for each instance by its probability, as suggested here: 

[https://stats.stackexchange.com/questions/277435/how-can-i-integrate-confidence-of-class-labels-into-my-classifier](https://stats.stackexchange.com/questions/277435/how-can-i-integrate-confidence-of-class-labels-into-my-classifier)

Does anyone know of a paper/book where this simple weighting approach is discussed? I can't find references on this simple idea.",2,1,False,self,,,,,
967,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,3,d62edh,wired.com,Artificial Intelligence Confronts a 'Reproducibility' Crisis,https://www.reddit.com/r/MachineLearning/comments/d62edh/artificial_intelligence_confronts_a/,Xaron,1568833119,,0,1,False,default,,,,,
968,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,3,d62efo,self.MachineLearning,"High accuracy in one v. all, lower accuracy in all v. all",https://www.reddit.com/r/MachineLearning/comments/d62efo/high_accuracy_in_one_v_all_lower_accuracy_in_all/,Estarabim,1568833126,"I am training a classifier (similar to logistic regression) on MNIST. I have 10 one -vs.-all classifiers for each number, each of which independently achieves &gt;90% test set accuracy. However, when I use the ""probabilities"" generated by the logistic function of each classifier to determine the most likely number, I get a lower overall accuracy, around 84%.

Any reason why this would happen?",0,1,False,self,,,,,
969,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,4,d62fit,wired.com,[N] Artificial Intelligence Confronts a 'Reproducibility' Crisis,https://www.reddit.com/r/MachineLearning/comments/d62fit/n_artificial_intelligence_confronts_a/,Xaron,1568833245,,0,1,False,default,,,,,
970,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,4,d62ko9,self.MachineLearning,[D] Keeping track of latest research,https://www.reddit.com/r/MachineLearning/comments/d62ko9/d_keeping_track_of_latest_research/,Viecce,1568833822,"How do you monitor the progress made in your  subfields of interest?
I'm still studying and I'm not yet a researcher; my only experience was with Arxiv and I had a couple of problems:
and there are a couple 
 but when I delved deeper in Adversarial ML for a project I noticed two problems:

1. There's no notification system. I'd like to know when a new interesting paper get publish in the field I'm interested in but, at least on Arxiv, there's no option for that.

2. I'm not sure if that's an issue with the field I was studying at the time (Adversarial ML) or if it's a general issues but I happened to read papers of researchers claiming great descoveries for later being discredited by established authors. That was quite disappointing other than a waste of time.

Are those common problem? How do you keep yourself updated?

I found a partial solution in using twitter lists to group famous researchers and look at what they post but it's not really optimal.",23,22,False,self,,,,,
971,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,4,d62ssf,medium.com,Quantum Chemistry Breakthrough: DeepMind Uses Neural Networks to Tackle Schrdinger Equation,https://www.reddit.com/r/MachineLearning/comments/d62ssf/quantum_chemistry_breakthrough_deepmind_uses/,Yuqing7,1568834745,,0,1,False,default,,,,,
972,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,4,d631p4,self.MachineLearning,StyleGAN Help,https://www.reddit.com/r/MachineLearning/comments/d631p4/stylegan_help/,milkyphonemes,1568835806,[removed],0,1,False,self,,,,,
973,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,5,d63s8v,self.MachineLearning,[D] AutoML: good/bad/ugly,https://www.reddit.com/r/MachineLearning/comments/d63s8v/d_automl_goodbadugly/,MLtinkerer,1568839353,"I'm considering using this next quarter but looking for some honest reviews from those who have already started using.

What do you like about it the most?
What do you hate about it/are struggling with?
What's good/bad/ugly about AutoML you have come across?",24,21,False,self,,,,,
974,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,6,d64ebi,self.MachineLearning,Computer vision with python,https://www.reddit.com/r/MachineLearning/comments/d64ebi/computer_vision_with_python/,SirJ_,1568843528,[removed],0,1,False,self,,,,,
975,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,7,d64xap,self.MachineLearning,[P] Is Emergent Coding the killer app weve been waiting for?,https://www.reddit.com/r/MachineLearning/comments/d64xap/p_is_emergent_coding_the_killer_app_weve_been/,SaidN0,1568846782,"If we can industrialise and monetise independent software creation, the possibilities seem endless. The applications for heuristic progress in machine learning could be huge. Thoughts?

https://www.reddit.com/r/btc/comments/d5qhx6/what_is_emergent_coding/",6,0,False,self,,,,,
976,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,8,d65cej,i.redd.it,"Nice Try, Google (yes, I misspelled 'tpr'!)",https://www.reddit.com/r/MachineLearning/comments/d65cej/nice_try_google_yes_i_misspelled_tpr/,forthesakeofspatial,1568848684,,0,1,False,default,,,,,
977,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,8,d65v7r,arxiv.org,[R] Reasoning and Generalization in RL: A Tool Use Perspective,https://www.reddit.com/r/MachineLearning/comments/d65v7r/r_reasoning_and_generalization_in_rl_a_tool_use/,hardmaru,1568851140,,5,6,False,default,,,,,
978,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,9,d6635p,self.MachineLearning,"[D] ML engineers of Reddit working in teams, how do you compare and benchmark different iterations of your models/algorithms especially when multiple members of a team might be working on the same algo/model?",https://www.reddit.com/r/MachineLearning/comments/d6635p/d_ml_engineers_of_reddit_working_in_teams_how_do/,WildShallot,1568852202,[removed],0,1,False,self,,,,,
979,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,9,d665ey,youtube.com,"Autonomous Artificial Intelligence Is Entering The Worlds Of Art, Poetry, &amp; Music",https://www.reddit.com/r/MachineLearning/comments/d665ey/autonomous_artificial_intelligence_is_entering/,BlastPalace,1568852515,,0,1,False,https://b.thumbs.redditmedia.com/pj5uh2w0A2AGu7Omp8n0tyjf12zIRH5v1tGKt-jiobs.jpg,,,,,
980,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,10,d66mg6,self.MachineLearning,RC plane flys by itself and avoids obsticles at 30mph,https://www.reddit.com/r/MachineLearning/comments/d66mg6/rc_plane_flys_by_itself_and_avoids_obsticles_at/,thesonyman101,1568854855,[removed],0,1,False,self,,,,,
981,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,11,d67erv,mlait.in,Sets in Python | MLAIT,https://www.reddit.com/r/MachineLearning/comments/d67erv/sets_in_python_mlait/,mlait1908,1568858760,,0,1,False,default,,,,,
982,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,11,d67lq3,self.MachineLearning,"Me waiting for my optimized grid search KNeighborsClassifier. ""[D]""",https://www.reddit.com/r/MachineLearning/comments/d67lq3/me_waiting_for_my_optimized_grid_search/,seriousgourmetshit,1568859759,"https://i.imgur.com/OqIQ3ox.jpg

Seriously though, I'm only training 60 fits with n_jobs=-1. Any way to speed this up?",0,1,False,self,,,,,
983,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,11,d67m6b,self.MachineLearning,"Using NLP, transfer learning, and for Post-Traumatic-Stress-Disorder Assessment in low resource settings",https://www.reddit.com/r/MachineLearning/comments/d67m6b/using_nlp_transfer_learning_and_for/,Lordobba,1568859822,[removed],0,1,False,self,,,,,
984,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,11,d67rg0,self.MachineLearning,Me waiting for my optimized grid search KNeighborsClassifier. [D],https://www.reddit.com/r/MachineLearning/comments/d67rg0/me_waiting_for_my_optimized_grid_search/,seriousgourmetshit,1568860592,"
https://i.imgur.com/OqIQ3ox.jpg


Seriously though, I'm only training 60 fits with n_jobs=-1. Any way to speed this up?",0,0,False,self,,,,,
985,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,11,d67ulo,self.MachineLearning,[P] Need suggestions/tips for scraping Twitter data,https://www.reddit.com/r/MachineLearning/comments/d67ulo/p_need_suggestionstips_for_scraping_twitter_data/,MrMegaGamerz,1568861061,"Hey guys, I just started my Masters Program in AI and our prof threw an assignment at us: Find an IEEE paper and recreate the results... Okay.. I have 0 background in any of this stuff but here goes.

I've got one on NLP (with the code, but without the dataset) and I'm trying to scrape twitter data. I researched that there was a python script which allows you to do this, however it requires that you have Twitter Dev Permissions. I made a Dev request, made an App and got Consumer API Keys and Access Token Keys. However, my permissions are set as read and write only. If I want to scrape tweets (with certain #) is read and write enough access for me to export to a CSV file to later use to train the model?

I've posted on /r/MLQuestions but haven't gotten a response there so I'm hoping I'll have better luck here. Hope someone with more experience can shed some light on the topic.

Thank you!",19,1,False,self,,,,,
986,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,12,d68dq3,self.MachineLearning,How can I work on fpga?,https://www.reddit.com/r/MachineLearning/comments/d68dq3/how_can_i_work_on_fpga/,indianspoiler,1568863904,"Hi everyone, how can I get some experience on fpga like the xilinx one and test some machine learning libs without breaking my bank account?",0,1,False,self,,,,,
987,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,12,d68mlq,self.MachineLearning,Machine learning for financial markets,https://www.reddit.com/r/MachineLearning/comments/d68mlq/machine_learning_for_financial_markets/,ssb98,1568865263,[removed],0,1,False,self,,,,,
988,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,13,d698c7,self.MachineLearning,AI new grad program interviews,https://www.reddit.com/r/MachineLearning/comments/d698c7/ai_new_grad_program_interviews/,BubblyResponsibility,1568868913,"Given that I have only 2-3 days to prepare for a 30 minute phone screen, what should I focus on for the technical aspects of AI? 
Im overwhelmed by the fact that the interviewer could literally ask me anything and I might stumble if Im not thorough with my concepts. 
Any useful links that summarize the important concepts?",0,1,False,self,,,,,
989,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,13,d698qi,self.MachineLearning,[D] (idea) a joe Rogan bot,https://www.reddit.com/r/MachineLearning/comments/d698qi/d_idea_a_joe_rogan_bot/,bleepitybloop555,1568868985,what if you fed all the Joe Rogan lines from every single episode and trained an AI to speak like joe rogan idk I'm not a programmer just throwing out an idea,2,0,False,self,,,,,
990,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,14,d69b57,self.MachineLearning,Backpropagation with asymmetric weights,https://www.reddit.com/r/MachineLearning/comments/d69b57/backpropagation_with_asymmetric_weights/,aviniumau,1568869407,[removed],0,1,False,self,,,,,
991,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,14,d69l1t,self.MachineLearning,Machine Learning,https://www.reddit.com/r/MachineLearning/comments/d69l1t/machine_learning/,PK7668,1568871139,[removed],0,1,False,self,,,,,
992,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,14,d69o24,self.MachineLearning,Top 5 Questions About Bot Building Explained!,https://www.reddit.com/r/MachineLearning/comments/d69o24/top_5_questions_about_bot_building_explained/,getengati,1568871674,[removed],0,1,False,self,,,,,
993,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,15,d6a3wh,ai.googleblog.com,An Inside Look at Flood Forecasting,https://www.reddit.com/r/MachineLearning/comments/d6a3wh/an_inside_look_at_flood_forecasting/,sjoerdapp,1568874671,,0,1,False,https://b.thumbs.redditmedia.com/Srrz22Y3qR8ZEPbraXRupb8CN4BzoBcls75gPKIm_ks.jpg,,,,,
994,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,15,d6a9aq,countants.com,Ways in which Artificial Intelligence is impacting Ecommerce business,https://www.reddit.com/r/MachineLearning/comments/d6a9aq/ways_in_which_artificial_intelligence_is/,Countants123,1568875672,,0,1,False,default,,,,,
995,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,15,d6aavg,self.MachineLearning,Data science/ML projects,https://www.reddit.com/r/MachineLearning/comments/d6aavg/data_scienceml_projects/,tempestbats,1568875959,[removed],0,1,False,self,,,,,
996,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,17,d6awkc,self.MachineLearning,[N] Google swallows DeepMind Health,https://www.reddit.com/r/MachineLearning/comments/d6awkc/n_google_swallows_deepmind_health/,sensetime,1568880263,"*From their [blog](https://www.blog.google/technology/health/deepmind-health-joins-google-health/):*

Over the last three years, DeepMind has built a team to tackle some of healthcares most complex problemsdeveloping AI research and mobile tools that are already having a positive impact on patients and care teams. Today, with our healthcare partners, the team is excited to officially join the Google Health family. Under the leadership of Dr. David Feinberg, and alongside other teams at Google, well now be able to tap into global expertise in areas like app development, data security, cloud storage and user-centered design to build products that support care teams and improve patient outcomes. 

During my time working in the UK National Health Service (NHS) as a surgeon and researcher, I saw first-hand how technology could help, or hinder, the important work of nurses and doctors. Its remarkable that many frontline clinicians, even in the worlds most advanced hospitals, are still reliant on clunky desktop systems and pagers that make delivering fast and safe patient care challenging. Thousands of people die in hospitals every year from avoidable conditions like sepsis and acute kidney injury and we believe that better tools could save lives. Thats why I joined DeepMind, and why I will continue this work with Google Health. 

Weve already seen how our mobile medical assistant for clinicians is helping patients and the clinicians looking after them, and we are looking forward to continuing our partnerships with The Royal Free London NHS Foundation Trust, Imperial College Healthcare NHS Trust and Taunton and Somerset NHS Foundation Trust.

On the research side, weve seen major advances with Moorfields Eye Hospital NHS Foundation Trust in detecting eye disease from scans as accurately as experts; with University College London Hospitals NHS Foundation Trust on planning cancer radiotherapy treatment; and with the US Department of Veterans Affairs to predict patient deterioration up to 48 hours earlier than currently possible. We see enormous potential in continuing, and scaling, our work with all three partners in the coming years as part of Google Health. 

Its clear that a transition like this takes time. Health data is sensitive, and we gave proper time and care to make sure that we had the full consent and cooperation of our partners. This included giving them the time to ask questions and fully understand our plans and to choose whether to continue our partnerships. As has always been the case, our partners are in full control of all patient data and we will only use patient data to help improve care, under their oversight and instructions.

I know DeepMind is proud of our healthcare work to date. With the expertise and reach of Google behind us, well now be able to develop tools and technology capable of helping millions of patients around the world. 

https://www.blog.google/technology/health/deepmind-health-joins-google-health/",31,201,False,self,,,,,
997,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,17,d6b4oo,self.MachineLearning,[D] Neural Architecture Search,https://www.reddit.com/r/MachineLearning/comments/d6b4oo/d_neural_architecture_search/,RTengx,1568882004,"Recently, Neural Architecture Search is coming back to the research spotlight.  Elsken et al. published a survey on this topic ([https://arxiv.org/pdf/1808.05377.pdf](https://arxiv.org/pdf/1808.05377.pdf) ) but the development is fast and many new works are emerging. For example, there is Weight Agnostic Neural Network (WANN)  [https://arxiv.org/abs/1906.04358](https://arxiv.org/abs/1906.04358)  that demonstrates that Neural Architectures can be more significant than the weights of the network. You can read of the list of paper in this topic at  [https://www.automl.org/automl/literature-on-neural-architecture-search/](https://www.automl.org/automl/literature-on-neural-architecture-search/) . Nevertheless, this type of topic is already researched in 1990 ( [https://pdfs.semanticscholar.org/2118/55f1de279c452858177331860cbc326351ab.pdf](https://pdfs.semanticscholar.org/2118/55f1de279c452858177331860cbc326351ab.pdf) ), are there still significance in improvement? If so, how much?

Are researchers just making up new Neural Architecture Search methods for publication, or is there really a big difference? Are there any work that focused on a detailed comparison for Neural Architecture Search.",3,1,False,self,,,,,
998,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,17,d6bakc,self.MachineLearning,Attention Text Generation in Character-by-Character fashion,https://www.reddit.com/r/MachineLearning/comments/d6bakc/attention_text_generation_in_characterbycharacter/,ristorer,1568883279,[removed],0,1,False,self,,,,,
999,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,17,d6bas6,self.deeplearning,How does RMSProp solve the issue of non-stationary environments,https://www.reddit.com/r/MachineLearning/comments/d6bas6/how_does_rmsprop_solve_the_issue_of_nonstationary/,mellow54,1568883326,,0,1,False,default,,,,,
1000,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,17,d6bbfo,self.MachineLearning,"[P] How we made landmark recognition in Cloud Mail.ru, and why",https://www.reddit.com/r/MachineLearning/comments/d6bbfo/p_how_we_made_landmark_recognition_in_cloud/,pvl18,1568883462,"With the advent of mobile phones with high-quality cameras, we started making more and more pictures and videos of bright and memorable moments in our lives. Many of us have photo archives that extend back over decades and comprise thousands of pictures which makes them increasingly difficult to navigate through.

For this purpose, we at Mail.ru Computer Vision Team have created and implemented systems for smart image processing, including landmark recognition.  Photos with landmarks are essential because they often capture highlights of our lives (journeys, for example). These can be pictures with some architecture or wilderness in the background. This is why we seek to locate such images using Deep Learning, and make them readily available to users.

 [https://medium.com/@andrei.boiarov/how-we-made-landmark-recognition-in-cloud-mail-ru-and-why-715b5f72e6d4](https://medium.com/@andrei.boiarov/how-we-made-landmark-recognition-in-cloud-mail-ru-and-why-715b5f72e6d4)",0,0,False,self,,,,,
1001,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,17,d6bblk,self.MachineLearning,"Which Solenoid Valve is Useful for Food Industries, Pharmaceuticals, Chemical Application &amp; Highly corrosive environment?",https://www.reddit.com/r/MachineLearning/comments/d6bblk/which_solenoid_valve_is_useful_for_food/,uflowindia,1568883501,[removed],0,1,False,https://b.thumbs.redditmedia.com/DzNSxkk9PcOsSQvz5FBmcNbE41fPdVlLcm30OF83bro.jpg,,,,,
1002,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,18,d6bme4,self.MachineLearning,"[N] Google starts AI research lab in Bangalore, India",https://www.reddit.com/r/MachineLearning/comments/d6bme4/n_google_starts_ai_research_lab_in_bangalore_india/,hardmaru,1568885667,"*Google Research India will be led by [Manish Gupta](https://www.iiitb.ac.in/faculty_page.php?name=ManishGupta), a renowned computer scientist and [ACM Fellow](https://awards.acm.org/fellows) with a background in deep learning across video analysis and education, compilers and computer systems. Were also excited to have Professor [Milind Tambe](https://teamcore.seas.harvard.edu/people/milind-tambe) join us on a joint appointment from Harvard University as Director of AI for Social Good. Professor Tambe will build a research program around applying AI to tackle big problems in areas like healthcare, agriculture, or education. 

The lab in Bangalore will be part of and support Googles global network of researchers: participating in conferences, publishing research in scientific papers, and collaborating closely with one another. Were also exploring the potential for partnering with Indias scientific research community and academic institutions to help train top talent and support collaborative programs, tools and resources.*

https://blog.google/around-the-globe/google-asia/google-research-india-ai-lab-bangalore/",52,285,False,self,,,,,
1003,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,18,d6bquf,self.MachineLearning,[D]Strategy game neural networks perform worse than monte carlo methods?,https://www.reddit.com/r/MachineLearning/comments/d6bquf/dstrategy_game_neural_networks_perform_worse_than/,H1lm1,1568886539,"Is there a strategy game(Like backgammon, chess, reversi..) where neural networks perform worse than monta carlo based methods like monte carlo tree search? Thank you",5,1,False,self,,,,,
1004,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,19,d6cbz5,self.MachineLearning,[R] Enriching BERT with Knowledge Graph Embeddings for Document Classification,https://www.reddit.com/r/MachineLearning/comments/d6cbz5/r_enriching_bert_with_knowledge_graph_embeddings/,muwnd,1568890456,"In this paper, we focus on the classification of books using short descriptive texts (cover blurbs) and additional metadata. Building upon BERT, a deep neural language model, we demonstrate how to combine text representations with metadata and knowledge graph embeddings, which encode author information. Compared to the standard BERT approach we achieve considerably better results for the classification task. For a more coarse-grained classification using eight labels we achieve an F1- score of 87.20, while a detailed classification using 343 labels yields an F1-score of 64.70. We make the source code and trained models of our experiments publicly available.

Paper: [https://arxiv.org/abs/1909.08402](https://arxiv.org/abs/1909.08402)

Code: [https://github.com/malteos/pytorch-bert-document-classification](https://github.com/malteos/pytorch-bert-document-classification)",0,17,False,self,,,,,
1005,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,20,d6cfe8,self.MachineLearning,Why my RNN (lstm) network is giving different results for same input,https://www.reddit.com/r/MachineLearning/comments/d6cfe8/why_my_rnn_lstm_network_is_giving_different/,s_brahma,1568891047,[removed],0,1,False,self,,,,,
1006,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,20,d6cj28,self.MachineLearning,[P] Stylegan Music Video,https://www.reddit.com/r/MachineLearning/comments/d6cj28/p_stylegan_music_video/,kinezodin,1568891639,"We made a music video using NVIDIA's [styleGAN](https://github.com/NVlabs/stylegan). You can check it out here: [https://youtu.be/bCJXnRFGoSE](https://youtu.be/bCJXnRFGoSE) .

# Methodology

We first produced a [mel-scaled spectrogram](https://librosa.github.io/librosa/generated/librosa.feature.melspectrogram.html) for the piece of music. We tweaked the arguments such that each time-step of the spectrogram corresponds to 16.7ms (duration of a frame @60fps). The frequency dimension of the spectrogram is scaled to match styleGAN's input dimension.

Then we explored a pre-trained (on faces) styleGAN's input space for interesting output images.  The way we performed the exploration was to compute the gradient of the mean squared error between styleGAN's output image and a real image (which we had chosen), with respect to a random input. Then with steps of gradient descent we search for inputs which produce outputs similar to our real image. We wanted ""non-realistic, creepy faces"", which we got by using extreme hyper-parameters in this exploration phase, by swapping the colors of the output and by carefully choosing the custom target image. For each generated image we also saved the input vector (512 dimensional) which lead to it.

Finally, we made a large spreadsheet in which each row is a beat of the song (175 bpm for most parts). We assigned various generated images we liked at different parts of the song (usually at intervals 4 beats). We turned this spreadsheet into a large input array of dimensions equal to the mel-scaled spectrogram, by linearly interpolating between the pre-chosen generated images at the intervals dictated by the spreadsheet. We add this input matrix to the spectrogram with some weights and feed it to the pre-trained styleGAN. The outputs are the frames of the video.

(For the first few seconds of the song we also used some real footage which we morphed with generated faces)

# Discussion

Throughout the project we felt that there must be a better way to do targeted searches of the input space. For styleGAN there is some interpretability to each dimension of the input, however we found it hard to make use of this, especially when the target image was not strictly a face (a skull for example). What are other ways in which we can answer the question ""what inputs of this (differentiable) black box lead to a desired output?""",7,5,False,self,,,,,
1007,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,20,d6cjsb,self.MachineLearning,[D] Looking for an advice about Human Activity Recognition.,https://www.reddit.com/r/MachineLearning/comments/d6cjsb/d_looking_for_an_advice_about_human_activity/,IonutCalofir,1568891763,"Hi [r/MachineLearning](https://www.reddit.com/r/MachineLearning). I hope this post is welcomed here because I couldn't think of another better place and I really believe that you guys can help me. In the coming year I will start writing my dissertation. The topic I'm interested in is about Human Activity Recognition. I talked with my advisor professor and we agreed about two approaches:

1. Research oriented. For example coming with different architectures, see what kind of videos are hard for current state of the art methods, etc. From what I saw the datasets are quite big and the current neural networks require few weeks to train and I don't have access to such computational power. And here comes my first question: given this situation, what are the things you think that I should focus on if I want to go on this route?
2. Doing something practical. For example to recognize the fine-grained actions from a specific sport/activity and to do something with them. The problem here is that there are not too many datasets, and I thought that maybe you know some interesting datasets regarding this aspect.

I have to mention that I personally prefer the first option, but I'm open to suggestions.

Thanks for the help and sorry if I posted in the wrong place.",3,2,False,self,,,,,
1008,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,21,d6d1l2,artiba.org,AI and Game Theory - A Primer,https://www.reddit.com/r/MachineLearning/comments/d6d1l2/ai_and_game_theory_a_primer/,Albertchristopher,1568894612,,0,1,False,https://b.thumbs.redditmedia.com/nQ49jFq-5G4VEEYczBQuZN1nqSC9UkOHL4n3SyBekxY.jpg,,,,,
1009,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,21,d6d51r,self.MachineLearning,[D] First time conference recomendation,https://www.reddit.com/r/MachineLearning/comments/d6d51r/d_first_time_conference_recomendation/,sudo_su_,1568895105,"I got a budget from my company to visit one conference this/next year. 

This is the first time me, or anyone from the company will go to a reference. 

What would you recommend?   

We're mostly interested in Natural Language Processing but also Deep and Machine Learning in general.

Thanks.",4,1,False,self,,,,,
1010,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,22,d6e23b,self.MachineLearning,Paper about Reinforcement GANs + Medicine discovery,https://www.reddit.com/r/MachineLearning/comments/d6e23b/paper_about_reinforcement_gans_medicine_discovery/,Asmartoctopus,1568899726,[removed],0,1,False,self,,,,,
1011,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,22,d6e53h,blog.alliedmarketresearch.com,New product launches to set innovation bar for machine vision systems high,https://www.reddit.com/r/MachineLearning/comments/d6e53h/new_product_launches_to_set_innovation_bar_for/,vinitsawant6675,1568900125,,0,1,False,default,,,,,
1012,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,22,d6eacf,self.MachineLearning,A Practical Guide for Creating A Quality Satellite Imagery Dataset for Agricultural Applications,https://www.reddit.com/r/MachineLearning/comments/d6eacf/a_practical_guide_for_creating_a_quality/,Lordobba,1568900837,[removed],0,1,False,self,,,,,
1013,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,22,d6eb9q,habr.com,Landmark recognition in Cloud Mail.ru using deep learning: how and why,https://www.reddit.com/r/MachineLearning/comments/d6eb9q/landmark_recognition_in_cloud_mailru_using_deep/,atomlib_com,1568900958,,0,1,False,https://b.thumbs.redditmedia.com/wkKJuLqt4aFQQTE4LSztIIWWRocDQ-GQMKpiIC8KMFE.jpg,,,,,
1014,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,23,d6egfz,self.MachineLearning,MVPA analysis based on input number of features,https://www.reddit.com/r/MachineLearning/comments/d6egfz/mvpa_analysis_based_on_input_number_of_features/,mirandeitor,1568901648,[removed],0,1,False,self,,,,,
1015,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,23,d6etwb,youtu.be,[R] 3D object detection (stereo) with Point clouds for Autonomous driving,https://www.reddit.com/r/MachineLearning/comments/d6etwb/r_3d_object_detection_stereo_with_point_clouds/,[deleted],1568903324,[deleted],0,1,False,default,,,,,
1016,MachineLearning,t5_2r3gv,2019-9-19,2019,9,19,23,d6ezjr,habr.com,Machine Learning for your apartment hunt. Part 1,https://www.reddit.com/r/MachineLearning/comments/d6ezjr/machine_learning_for_your_apartment_hunt_part_1/,atomlib_com,1568904019,,0,1,False,https://b.thumbs.redditmedia.com/3UnXlbOCzO1_SOA1NMBZ1rjWiJGqUktcA38PSMjq39g.jpg,,,,,
1017,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,0,d6fd33,self.MachineLearning,"To attend or not to attend, that is the question.",https://www.reddit.com/r/MachineLearning/comments/d6fd33/to_attend_or_not_to_attend_that_is_the_question/,downBourgeois,1568905665,[removed],0,1,False,self,,,,,
1018,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,0,d6ffrn,self.MachineLearning,[D] What's the prevalence of various languages in text summarization research?,https://www.reddit.com/r/MachineLearning/comments/d6ffrn/d_whats_the_prevalence_of_various_languages_in/,Syncrossus,1568905981,"My understanding so far has been that most of the research on text summarization has been done in English. However, I can't find any reliable numbers for this. My best idea so far has been to search for ""automatic summarization &lt;language&gt;"" for a few languages on Google Scholar and see the number of results to get a rough estimate of the proportions. I get 42k for English, 25k for French, 24k for Spanish... But more surprising is I find 46k for Chinese. I would expect the results to be biased towards English, since my keywords are in English. Is it possible that more research has been done in summarization for Chinese than for English? Or am I overlooking something? Can you get more accurate numbers?",2,2,False,self,,,,,
1019,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,0,d6fi02,self.MachineLearning,[N] Apple 'Overton': Automating Low-Code Machine Learning,https://www.reddit.com/r/MachineLearning/comments/d6fi02/n_apple_overton_automating_lowcode_machine/,BrooklynShatterDome,1568906264,[removed],0,1,False,self,,,,,
1020,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,0,d6fuhu,self.MachineLearning,[R] DeepMind Released a Dataset of Synthetic TensorFlow Graphs,https://www.reddit.com/r/MachineLearning/comments/d6fuhu/r_deepmind_released_a_dataset_of_synthetic/,GrandmasterMochizuki,1568907732,"This was one of the datasets used by them to learn a compiler-compatible algorithm to optimize for model parallelism in TensorFlow graphs.

[github.com/deepmind/deepmind-research/tree/master/regal](https://github.com/deepmind/deepmind-research/tree/master/regal)",0,13,False,self,,,,,
1021,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,2,d6haoq,youtube.com,44-part Python Beginners video series from Microsoft,https://www.reddit.com/r/MachineLearning/comments/d6haoq/44part_python_beginners_video_series_from/,AstroPHX,1568913957,,0,1,False,https://a.thumbs.redditmedia.com/111YdjDK7HctQr8lxhZlu0jCzaoIHT3TimZ0_vpvBG8.jpg,,,,,
1022,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,2,d6hjgn,self.MachineLearning,[N] xBD Building Damage Dataset (+550k Annotations/+19k sq km) Available for Download (https://xview2.org/dataset),https://www.reddit.com/r/MachineLearning/comments/d6hjgn/n_xbd_building_damage_dataset_550k_annotations19k/,nirav_diu,1568915019,"&amp;#x200B;

![img](hbjt6bvh4ln31)

The competition xBD dataset, annotated satellite imagery pre and post natural disasters for the xView2 Competition is now available for download here (upon e-mail registration):

 [https://xview2.org/dataset](https://xview2.org/dataset) 

The dataset was [announced](http://openaccess.thecvf.com/content_CVPRW_2019/papers/cv4gc/Gupta_Creating_xBD_A_Dataset_for_Assessing_Building_Damage_from_Satellite_CVPRW_2019_paper.pdf) at IEEE CVPR 2019(most up to date metrics are accurate at the website above however).

The dataset creation was lead by the [Defense Innovation Uni](https://www.diu.mil/)t with the technical expertise of Carnegie Mellon's Software Engineering Institute (CMU SEI), [CrowdAI](https://crowdai.com/) and the [Joint Artificial Intelligence Center](https://dodcio.defense.gov/About-DoD-CIO/Organization/JAIC/), with data provided by MAXAR/DigitalGlobe's [Open Data Program](https://www.digitalglobe.com/ecosystem/open-data).

For more info on CMU SEI's efforts in Humanitarian Assistance and Disaster Response (focus on XView Competitions starts at \~6:26):

 [https://www.youtube.com/watch?v=UW5CP9YahG0](https://www.youtube.com/watch?v=UW5CP9YahG0) 

For more information on the competition:

 [https://www.reddit.com/r/MachineLearning/comments/cu7vcn/n\_announcing\_the\_xview\_2\_prize\_challenge\_assess/](https://www.reddit.com/r/MachineLearning/comments/cu7vcn/n_announcing_the_xview_2_prize_challenge_assess/) 

or you can visit our website: [xview2.org](https://xview2.org).",5,98,False,self,,,,,
1023,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,2,d6hk7p,self.MachineLearning,Equation or Formula Extraction from Machine Learning,https://www.reddit.com/r/MachineLearning/comments/d6hk7p/equation_or_formula_extraction_from_machine/,lannister_the_imp,1568915120,"One of the biggest issues for machine learning or artificial intelligence in general is that it is a black box. Especially when the intelligence gets more and more complicated the more of a black box you get. 

In electrical or programming terms a black box is a unknown process where information gets fed into and a output is returned. You do not know what happens within the black box thus the name. x(n) -&gt;h(x(n))-&gt;y(n) this is the black box equivalent in mathematical terms where we do not know what h(n) is. 

One of the processes used for cryptocurrency is that it takes alot of brute force to create a equation that can with very little effort be verified. This sounds very similar to machine learning or CNN where alot of computer power is required to produce a network where it takes less computer power to run the network after its been trained. 

One of the biggest issues for certain industries is that a network produces nodes, layers, weights and biases for those nodes and layers. It doesn't produce a equation that can be extracted and later used elsewhere. This means that until a machine learning algorithm can produce a equation it is unable to run on 8bit micro-controllers or that heavily taught networks cant run on mobile phones from 5 years ago. 

I have spent some time looking at research papers and going from form to form looking at how extraction of a machine learning network can be done. I've found the networks that do the types of operations that I am looking for such as image analysis may be light but will still unfortunately be a black box. For the medical industry nothing can be a black box, that's why again and again machine learning is denied from new equipment or it requires a hospital staff member to verify the information after the machine has done its task. 

Does anyone know of a way of producing a equation or a human readable peice of information that can be used for machine learning?",0,1,False,self,,,,,
1024,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,2,d6hlps,self.MachineLearning,How to rank feature/column based on predictive power with respect to class label?,https://www.reddit.com/r/MachineLearning/comments/d6hlps/how_to_rank_featurecolumn_based_on_predictive/,AbhiDelhi,1568915312,[removed],0,1,False,https://b.thumbs.redditmedia.com/ZKBqHE_91vRaqcwyf6wAcZf0O_p-fRxx4V05dO4l_ME.jpg,,,,,
1025,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,3,d6hy4z,github.com,tensorflow/tfx-bsl is a new github repo by tensorflow,https://www.reddit.com/r/MachineLearning/comments/d6hy4z/tensorflowtfxbsl_is_a_new_github_repo_by/,sjoerdapp,1568916802,,0,1,False,default,,,,,
1026,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,3,d6i2a7,self.MachineLearning,Call for papers: Life Long Learning for Spoken Language Systems Workshop,https://www.reddit.com/r/MachineLearning/comments/d6i2a7/call_for_papers_life_long_learning_for_spoken/,intvar,1568917298,[removed],0,1,False,self,,,,,
1027,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,4,d6jb6w,self.MachineLearning,[P] A Collection of Machine-written Poetry,https://www.reddit.com/r/MachineLearning/comments/d6jb6w/p_a_collection_of_machinewritten_poetry/,hellohitesh,1568922695,"Hello,

I'm an undergrad student researching how machines and ""AI"" can help and assist human creators by giving them new ideas and thus help them make unique and different kinds of work.  As part of a fundraiser, I've [released a collection of 15 machine-written poetry samples](https://gum.co/mwpoetry) on Gumroad for 7 dollars. They were generated by fine-tuning OpenAI's GPT-2 model on a dataset of poems. By purchasing them you may use the samples to spice up your own poetry work, and also support me. Thank you very much.",1,1,False,self,,,,,
1028,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,4,d6je9s,self.MachineLearning,[D] Back propagation alternative,https://www.reddit.com/r/MachineLearning/comments/d6je9s/d_back_propagation_alternative/,ToolTechSoftware,1568923077,"I would like to start a discussion about solving deep networks without backprop.  I have invented a mechanism in 2016 that uses no backprop at all and that can solve any network topology.  The algorithm also scales almost lineary so you can double the performance using two machines.  

Anyone interested?",43,0,False,self,,,,,
1029,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,6,d6k9u7,i.imgur.com,Correlation for dummies (Courtesy: Andriy Burkov),https://www.reddit.com/r/MachineLearning/comments/d6k9u7/correlation_for_dummies_courtesy_andriy_burkov/,itachixsasuke,1568926931,,0,1,False,https://b.thumbs.redditmedia.com/X7USnQAgQyLxrhTLcD_A2-fYQfPaALRxG4jP3BpvAnM.jpg,,,,,
1030,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,6,d6kcic,faketrump.ai,Is AI Trump better at Twitter than Real Trump?,https://www.reddit.com/r/MachineLearning/comments/d6kcic/is_ai_trump_better_at_twitter_than_real_trump/,thatguyisswell,1568927265,,0,1,False,https://b.thumbs.redditmedia.com/Wc5L0JiJz82tvEA9mvH2YGmiRWvjuf7y-Upim1vGgYY.jpg,,,,,
1031,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,6,d6kk4m,github.com,pytorch/add-annotations-github-action by pytorch,https://www.reddit.com/r/MachineLearning/comments/d6kk4m/pytorchaddannotationsgithubaction_by_pytorch/,sjoerdapp,1568928212,,0,1,False,https://b.thumbs.redditmedia.com/lHLhV-1JYwAG6bw_z5pcJMp-JBbOU9ApH1ylh7vVuec.jpg,,,,,
1032,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,7,d6l59k,self.MachineLearning,Adding GPU support for deeplearning4j in Weka,https://www.reddit.com/r/MachineLearning/comments/d6l59k/adding_gpu_support_for_deeplearning4j_in_weka/,DaBears_1985x,1568930815,"I'm having trouble adding GPU support for deeplearning4j in Weka:  [https://github.com/Waikato/wekaDeeplearning4j/releases/tag/v1.5.14](https://github.com/Waikato/wekaDeeplearning4j/releases/tag/v1.5.14) 

Has anybody gotten it to work and could provide an easy way to do it besides using the PowerShell script? Many thanks...",0,1,False,self,,,,,
1033,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,7,d6l9dv,colcarroll.github.io,[P] A tour of probabilistic programming language APIs,https://www.reddit.com/r/MachineLearning/comments/d6l9dv/p_a_tour_of_probabilistic_programming_language/,satsatsat,1568931336,,0,1,False,default,,,,,
1034,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,7,d6li4k,self.MachineLearning,Rewriting Generative Deep Learning Book from David Foster in Pytorch,https://www.reddit.com/r/MachineLearning/comments/d6li4k/rewriting_generative_deep_learning_book_from/,mlslayer,1568932427,[removed],0,1,False,self,,,,,
1035,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,9,d6mzhc,arxiv.org,[R] HYPE: A Benchmark for Human eYe Perceptual Evaluation of Generative Models,https://www.reddit.com/r/MachineLearning/comments/d6mzhc/r_hype_a_benchmark_for_human_eye_perceptual/,baylearn,1568939485,,4,32,False,default,,,,,
1036,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,10,d6nqmx,self.MachineLearning,Convolutional Pose Machines,https://www.reddit.com/r/MachineLearning/comments/d6nqmx/convolutional_pose_machines/,AbdallahNasr5,1568943207,[removed],0,1,False,self,,,,,
1037,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,12,d6pd0h,self.MachineLearning,Free Machine Learning Lessons or Doubt Clearing Sessions,https://www.reddit.com/r/MachineLearning/comments/d6pd0h/free_machine_learning_lessons_or_doubt_clearing/,rakeshravi1992,1568951730,[removed],0,1,False,self,,,,,
1038,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,14,d6q3j0,self.MachineLearning,I am rewriting Generative Deep Learning Book from David Foster in Pytorch,https://www.reddit.com/r/MachineLearning/comments/d6q3j0/i_am_rewriting_generative_deep_learning_book_from/,mlslayer,1568956067,[removed],0,1,False,self,,,,,
1039,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,14,d6q773,self.MachineLearning,[D] [P] I am rewriting Generative Deep Learning Book from David Foster in Pytorch,https://www.reddit.com/r/MachineLearning/comments/d6q773/d_p_i_am_rewriting_generative_deep_learning_book/,mlslayer,1568956667,"Just wanted to say that I'm rewriting the GDL book in Pytorch here [https://github.com/MLSlayer/Generative-Deep-Learning-Code-in-Pytorch](https://github.com/MLSlayer/Generative-Deep-Learning-Code-in-Pytorch)

Any feedback or help would be appreciated!",11,138,False,self,,,,,
1040,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,14,d6q8u2,self.MachineLearning,Grade 3 Math questions Dataset,https://www.reddit.com/r/MachineLearning/comments/d6q8u2/grade_3_math_questions_dataset/,mbalfakeih,1568956936,[removed],0,1,False,self,,,,,
1041,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,14,d6qabu,self.MachineLearning,help and guidance,https://www.reddit.com/r/MachineLearning/comments/d6qabu/help_and_guidance/,machinelearner76,1568957201,[removed],0,1,False,self,,,,,
1042,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,14,d6qao1,instagram.com,tensor vinyasa flow yoga,https://www.reddit.com/r/MachineLearning/comments/d6qao1/tensor_vinyasa_flow_yoga/,timshi_ai,1568957263,,0,1,False,default,,,,,
1043,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,14,d6qc3n,self.MachineLearning,Deal with data biasing,https://www.reddit.com/r/MachineLearning/comments/d6qc3n/deal_with_data_biasing/,aee_nobody,1568957519,How to Deal with Imbalanced Data using SMOTE by Khyati Mahendru https://link.medium.com/1d95NzG27Z,0,1,False,self,,,,,
1044,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,14,d6qeyr,self.MachineLearning,How to behave like a deep-learning insider?,https://www.reddit.com/r/MachineLearning/comments/d6qeyr/how_to_behave_like_a_deeplearning_insider/,tobby_liu,1568957993,[removed],0,1,False,self,,,,,
1045,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,14,d6qgcq,countants.com,Why is Artificial Intelligence in Business Analytics so critical for business growth?,https://www.reddit.com/r/MachineLearning/comments/d6qgcq/why_is_artificial_intelligence_in_business/,Countants123,1568958256,,0,1,False,default,,,,,
1046,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,14,d6qh88,ai.googleblog.com,Machine Learning pilot used for Flood Forcasting in India This work is very critical given devastating impact floods have across country. In 2019 itself 13 Indian states were severely impacted by floods. Over 400 lives lost and million+ displaced from their homes.,https://www.reddit.com/r/MachineLearning/comments/d6qh88/machine_learning_pilot_used_for_flood_forcasting/,adssidhu86,1568958432,,0,1,False,default,,,,,
1047,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,15,d6qmu3,self.MachineLearning,[D]How to behave like a deep-learning insider?,https://www.reddit.com/r/MachineLearning/comments/d6qmu3/dhow_to_behave_like_a_deeplearning_insider/,tobby_liu,1568959447,"I am not in the academia and industry of deep learning, but I am interested in general artificial intelligence and have some results. But this is usually the research field of the big ones. For me outsiders, in the eyes of others, I am like folk who studies perpetual motion machine or overthrows the theory of relativity.

&amp;#x200B;

I am looking for an opportunity to step into this field. But before that, sorting out the results and publishing them as professional papers will cost me the energy and time I can't afford.

&amp;#x200B;

So my question is: How to behave like a deep-learning insider so that others can read these results seriously?

Attach the GitHub address of my project:  [https://github.com/TobbysGitHub/General-Artificial-Intelligence/blob/master/micro-prediction%20capsule%20system.md](https://github.com/TobbysGitHub/General-Artificial-Intelligence/blob/master/micro-prediction%20capsule%20system.md)",31,0,False,self,,,,,
1048,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,15,d6qo5f,github.com,Implementations of RL trading algorithms to simulate dynamic fee policy in exchanges,https://www.reddit.com/r/MachineLearning/comments/d6qo5f/implementations_of_rl_trading_algorithms_to/,JeffreyKR9410,1568959669,,0,1,False,default,,,,,
1049,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,15,d6qoe5,self.MachineLearning,How Machine learning and Data science are related to each other? Lets find out,https://www.reddit.com/r/MachineLearning/comments/d6qoe5/how_machine_learning_and_data_science_are_related/,AnkitKap,1568959714,[removed],0,1,False,self,,,,,
1050,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,15,d6qs0e,self.MachineLearning,[P] Implementations of RL trading algorithms to simulate dynamic fee policy in exchanges,https://www.reddit.com/r/MachineLearning/comments/d6qs0e/p_implementations_of_rl_trading_algorithms_to/,JeffreyKR9410,1568960373,"\[Project Overview in 3lines\]

1. Why are exchange fees fixed? Can't we dynamically up and down the fees depending on market conditions?
2. Make a dynamic fee policy environments where reinforcement learning agents learn trading policies
3. Provide insight into what the fee policy is optimized for exchanges

\[The algorithm of the Trading agent -pytorch based\]

1. PPO + MobileNet
2. RAINBOW + MobileNet
3. RAINBOW + Transformer(MultiheadAttention)

\[Your Utility\] If you want to use reinforcement learning in stock investment, you can use this source and it will be a baseline! (However, in this simulation, ROI was not the goal. So the performance is not guaranteed. :( )

Below is a 2:30 second video link and a medium article link describing the project.

\[Youlink\] [https://youtu.be/kBjv4KmkEHU](https://youtu.be/kBjv4KmkEHU) 

\[Medium link\] [https://medium.com](https://medium.com/@jeffrey_7616/dynamic-fee-mechanism-simulation-with-reinforcement-learning-97c847aa5c) 

All source code is available in the following repo [https://github.com/deconlab](https://github.com/deconlabs/TradingZoo-Dynamic-fee-simulation/)",3,1,False,self,,,,,
1051,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,15,d6r1wb,self.MachineLearning,Implementation of A Deep Q-Network for the Beer Game,https://www.reddit.com/r/MachineLearning/comments/d6r1wb/implementation_of_a_deep_qnetwork_for_the_beer/,rojans,1568962186,"After  going through the paper on ""A Deep Q-Network for the Beer Game:  Reinforcement Learning for Inventory Optimization"", I am looking for its  implementation. I have understood most of the concepts and  methodologies used in the paper. But, I am having a problem implementing  those algorithms and pseudocode into the code. Any help would be  appreciated. Thanks.

P.S. I am looking for collaborations to work on a Supply Chain Management project as well.

[https://arxiv.org/abs/1708.05924](https://arxiv.org/abs/1708.05924)",0,1,False,self,,,,,
1052,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,15,d6r3oq,self.MachineLearning,"Avoiding revisiting saturated paths in MCTS, while maintaining a good policy?",https://www.reddit.com/r/MachineLearning/comments/d6r3oq/avoiding_revisiting_saturated_paths_in_mcts_while/,its_just_andy,1568962524,[removed],0,1,False,self,,,,,
1053,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,16,d6r8q3,self.MachineLearning,"[D] Avoiding revisiting paths in MCTS, while maintaining a good policy?",https://www.reddit.com/r/MachineLearning/comments/d6r8q3/d_avoiding_revisiting_paths_in_mcts_while/,its_just_andy,1568963438,"I've been stumped on this problem for a week or so.

I realized that with MCTS, if you don't keep track of which subtrees have been fully saturated (i.e. you've expanded it completely, down to every leaf), you can end up revisiting the same paths over and over again, when you really should be using your time exploring other areas of the tree.

*However*, at the same time, if you naively implement behavior that says ""During the selection phase, ignore any fully-saturated nodes"", then the metric ""number of visits"" is no longer a good indicator of which child node is the best.

E.x., you have two children nodes, one leads to victory 80% of the time, the other leads to victory 40% of the time.  But the one that wins 80% of the time only has 200 nodes in its entire subtree, for a maximum of 200 unique visits.  The one that wins only 40% has a huge subtree, so its ""visits"" count becomes very large.

At the end of MCTS, you'll see the ""wins/plays"" for the smaller tree will be better, but since in general MCTS will select ""visits"" over ""wins"", you will end up selecting the wrong node.

I've been trying to crack this myself for some time as a matter of pride, but I'm deciding to reach out to see if the community already has a good strategy for this.

Some of my ideas include: for each node, also store a count of ""all descendants"" (i.e. how many nodes are in this node's subtree), as well as ""all leafs"" (i.e. how many nodes in this subtree are leafs), plus ""win leafs"" and ""lose leafs"", and then you can do `1 / all_descendants` as a factor to smooth out the difference between smaller subtrees and larger ones...",5,1,False,self,,,,,
1054,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,16,d6rgq9,self.MachineLearning,[D] AutoML: model selection and best model for your needs -good/bad?,https://www.reddit.com/r/MachineLearning/comments/d6rgq9/d_automl_model_selection_and_best_model_for_your/,MLtinkerer,1568964938,"Follow up post: (Looking for some more reviews on automl before I start using it)

I've heard AutoML(google or amazon) is used to find the optimal ML model.

&amp;#x200B;

\--&gt;How does AutoML really do when it comes to model selection?

&amp;#x200B;

\--&gt;what about when it comes to cross-validation of the models?

&amp;#x200B;

\--&gt;Does it really find the 'best' model? 

\---&gt;What are your criteria of what's considered best?

""weak/slow;

interpretability/representability;

replicability?

confidence/performance;

biased/data-hungry.""

&amp;#x200B;

Welcome all reviews-good/bad! :)",1,3,False,self,,,,,
1055,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,17,d6s135,self.MachineLearning,Using Google Translate API to create a Translation Dataset,https://www.reddit.com/r/MachineLearning/comments/d6s135/using_google_translate_api_to_create_a/,GokulNC,1568969154,"Is it a good idea? ;-)  
Say I have a language X for which I want to create a dataset for translation to/from English, for which I have no online sources to scrape out the data from. But our giant Google Translate somehow has it. 

Can we just dump the translations from English datasets for my language X and create a dataset?  
Is it legal to do so? Is it legal to release such a dataset to public?",0,1,False,self,,,,,
1056,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,18,d6s70h,medium.com,5 differences between Machine Learning and Statistical Modeling,https://www.reddit.com/r/MachineLearning/comments/d6s70h/5_differences_between_machine_learning_and/,sedthh,1568970329,,0,1,False,default,,,,,
1057,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,18,d6s7n2,self.MachineLearning,[D] Question about captchas and machine learning,https://www.reddit.com/r/MachineLearning/comments/d6s7n2/d_question_about_captchas_and_machine_learning/,peino99,1568970445,"So I'm sure some of you if not a good portion of you have heard about the idea that captchas are used to teach machines, and I don't know enough about the topic to say if it's true or not, it may just be a theory or objectively true, I honestly have no idea.

I just had a question about it; if it was true that captchas are used to teach machines, how does that even work? Captchas already have pre-set correct answers right? Doesn't that mean that machines wouldn't be learning anything new because the correct area for the object in that captcha has already been defined? Excuse my stupidity if there's a simple answer to this, but like I said I have no idea about this topic and I'm just curious. Thanks!",4,6,False,self,,,,,
1058,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,18,d6s8h3,self.MachineLearning,New Features in Autout: Automated Outlier Detection and Treatment Tool.,https://www.reddit.com/r/MachineLearning/comments/d6s8h3/new_features_in_autout_automated_outlier/,kailashahirwar12,1568970628,"Last month, we publicly released [AutoOut](https://github.com/MateLabs/AutoOut). We have received mixed responses and since then we have been trying to improve it. As promised we have added new features which are:

1. Now you can customize the percentage of outliers you want to remove
2. Dynamic Dask Cluster - AutoOut will create a Dask cluster based on resources available(RAM, No. of cores)

We are working on new features in AutOut like:

1. Graphical representations of outliers detected
2. Distribution and correlation graphs for different features/dimensions
3. Ability to remove dimensions/features

We need everyone's support to make AutoOut as one of the best outlier detection and treatment tool. We are inviting developers to make contributions or suggest new features.

[https://github.com/MateLabs/AutoOut](https://github.com/MateLabs/AutoOut)",0,1,False,self,,,,,
1059,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,18,d6sa17,subscription.packtpub.com,Read Sebastian Raschka's Python Machine Learning for free this weekend - free access to Packt content from Friday to Monday,https://www.reddit.com/r/MachineLearning/comments/d6sa17/read_sebastian_raschkas_python_machine_learning/,pastel01,1568970944,,0,1,False,https://b.thumbs.redditmedia.com/fpLb-WlnXUcv9yUKmiShGHHc1XeuFXyUYYrVJPNZhag.jpg,,,,,
1060,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,18,d6sjwq,self.MachineLearning,Which Solenoid Valve Is Best For Air Pollution Control?,https://www.reddit.com/r/MachineLearning/comments/d6sjwq/which_solenoid_valve_is_best_for_air_pollution/,uflowindia,1568972821,[removed],0,1,False,https://b.thumbs.redditmedia.com/DyGe23C3HFO8EGjtQmXDWCTOk7g1wP-t3m80IDZdEkc.jpg,,,,,
1061,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,19,d6so18,self.MachineLearning,Car plate detection CV,https://www.reddit.com/r/MachineLearning/comments/d6so18/car_plate_detection_cv/,Maminizer,1568973611,[removed],0,1,False,self,,,,,
1062,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,20,d6t89y,medium.com,Building Engaging Conversational Interfaces with DialogFlow,https://www.reddit.com/r/MachineLearning/comments/d6t89y/building_engaging_conversational_interfaces_with/,Ripple2709,1568977211,,0,1,False,https://b.thumbs.redditmedia.com/8B-zzSFOaxla6ufJbTd___R7wVpeJvBddEtYRDwSzGQ.jpg,,,,,
1063,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,20,d6td2r,self.MachineLearning,Help with Telecom Call Drop Anomaly Detection,https://www.reddit.com/r/MachineLearning/comments/d6td2r/help_with_telecom_call_drop_anomaly_detection/,victoriasecretagent,1568977963,[removed],0,1,False,https://b.thumbs.redditmedia.com/Ft5nyqX-YP5fHxAn0X1Hnm_8Qkx3Qki4o2EJPa2333s.jpg,,,,,
1064,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,21,d6tv6f,self.MachineLearning,Speech to text translation,https://www.reddit.com/r/MachineLearning/comments/d6tv6f/speech_to_text_translation/,fountainhop,1568980831,[removed],0,1,False,self,,,,,
1065,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,21,d6u3s1,self.MachineLearning,"AFAIK The best AI that has been trained on the MNIST Handwritten Digit Classification Dataset is correct only 99.7% of the times. Generally speaking, what implications do accuracy rates have on the use cases of an AI?",https://www.reddit.com/r/MachineLearning/comments/d6u3s1/afaik_the_best_ai_that_has_been_trained_on_the/,agasabellaba,1568982053,[removed],0,1,False,self,,,,,
1066,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,21,d6u69l,self.MachineLearning,Python Machine Learning By Example,https://www.reddit.com/r/MachineLearning/comments/d6u69l/python_machine_learning_by_example/,HannahHumphreys,1568982427,[removed],0,1,False,self,,,,,
1067,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,22,d6upsz,self.MachineLearning,[D] How to use BERT as replacement of embedding layer in my pytorch model?,https://www.reddit.com/r/MachineLearning/comments/d6upsz/d_how_to_use_bert_as_replacement_of_embedding/,hadaev,1568985138,"As far as I understand BERT can work as kind of embedding but context-sensitive.

Can I use pretrained BERT like pretrained embedding in my model?

If I can, what simplest way to do so?

In general, I want to make something like a context-sensitive replacement for char/word lvl default embeddings for my models.",5,3,False,self,,,,,
1068,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,22,d6uy4q,self.MachineLearning,[D] AI competitions dont produce useful models,https://www.reddit.com/r/MachineLearning/comments/d6uy4q/d_ai_competitions_dont_produce_useful_models/,pirate7777777,1568986236,"Hi everyone! I found [this provocative post on HN](https://news.ycombinator.com/item?id=21021188), which is quite related also to this other [Reddit post](https://www.reddit.com/r/MachineLearning/comments/d50lr3/d_why_are_kaggle_prizes_so_low/) (on how the objective of Kaggle competitions from the competition creator's perspective isn't necessarily a *useful* model),  I'm curious to know your thoughts.",53,194,False,self,,,,,
1069,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,23,d6vigs,beagleboard.org,"BeagleBoard Launches BeagleBone AI, Offering a Fast Track to Getting Started with Artificial Intelligence at the Edge",https://www.reddit.com/r/MachineLearning/comments/d6vigs/beagleboard_launches_beaglebone_ai_offering_a/,protechig,1568988841,,0,1,False,default,,,,,
1070,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,23,d6vkws,litslink.com,An Introduction to Machine Learning Algorithms,https://www.reddit.com/r/MachineLearning/comments/d6vkws/an_introduction_to_machine_learning_algorithms/,Anastasiia17,1568989152,,0,1,False,default,,,,,
1071,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,23,d6vu4h,self.MachineLearning,https://youtu.be/5c7-m-mISzA,https://www.reddit.com/r/MachineLearning/comments/d6vu4h/httpsyoutube5c7mmisza/,uzma-mumtaz,1568990280,[removed],0,1,False,self,,,,,
1072,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,23,d6vyx0,self.MachineLearning,[D] Medium/TowardsDataScience Noise,https://www.reddit.com/r/MachineLearning/comments/d6vyx0/d_mediumtowardsdatascience_noise/,humanager,1568990870,"Lately in my work and personal research, I have noticed that whenever I google anything related to ML/AI/DS there is a whole page of medium/tds articles. Some of these are actually useful but more often than not they're garbage and doing a really bad job of presenting a topic of interest. 

Do other people have a way of weeding through these? I think Medium should introduce some sort of usefulness tagging mechanism to actually tell if an article does a good job in explaining a concept or not. These days every 'data scientist' with little to no communication skills is writing Medium posts.",59,158,False,self,,,,,
1073,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,23,d6w0c2,self.MachineLearning,Supervised learning in chess,https://www.reddit.com/r/MachineLearning/comments/d6w0c2/supervised_learning_in_chess/,corzoai,1568991052,[removed],0,1,False,self,,,,,
1074,MachineLearning,t5_2r3gv,2019-9-20,2019,9,20,23,d6w21r,self.MachineLearning,Upcoming/Hot Research Topics in ML,https://www.reddit.com/r/MachineLearning/comments/d6w21r/upcominghot_research_topics_in_ml/,arcxtriy,1568991273,[removed],0,1,False,self,,,,,
1075,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,1,d6x4le,cometml.wistia.com,Patenting AI Webinar Recording,https://www.reddit.com/r/MachineLearning/comments/d6x4le/patenting_ai_webinar_recording/,CometML,1568995850,,0,1,False,default,,,,,
1076,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,1,d6x818,opendatascience.com,Here's some good ML research from this past summer,https://www.reddit.com/r/MachineLearning/comments/d6x818/heres_some_good_ml_research_from_this_past_summer/,OpenDataSciCon,1568996289,,0,1,False,default,,,,,
1077,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,3,d6yswf,self.learnmachinelearning,[Q] Deep learning for tabular data,https://www.reddit.com/r/MachineLearning/comments/d6yswf/q_deep_learning_for_tabular_data/,meechosch,1569003051,,0,1,False,default,,,,,
1078,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,3,d6yxvc,arstechnica.com,Harnessing machine learning to make managing storage more efficient,https://www.reddit.com/r/MachineLearning/comments/d6yxvc/harnessing_machine_learning_to_make_managing/,jonfla,1569003658,,0,1,False,https://b.thumbs.redditmedia.com/qzwyQCI3SoE0RkNdTqBYx63vu8A3mBwpodxhbqTUEbE.jpg,,,,,
1079,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,3,d6za2f,self.MachineLearning,Minecraft ML,https://www.reddit.com/r/MachineLearning/comments/d6za2f/minecraft_ml/,IConservativeCode,1569005168,[removed],0,1,False,self,,,,,
1080,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,4,d6zj62,self.MachineLearning,Name of user friendly image recognition desktop application?,https://www.reddit.com/r/MachineLearning/comments/d6zj62/name_of_user_friendly_image_recognition_desktop/,BigChaseUSA,1569006261,[removed],0,1,False,self,,,,,
1081,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,4,d6zwxv,self.MachineLearning,What is the best AI image upscale application or site?,https://www.reddit.com/r/MachineLearning/comments/d6zwxv/what_is_the_best_ai_image_upscale_application_or/,saminator2001,1569007972,[removed],0,1,False,self,,,,,
1082,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,4,d6zxwv,techxplore.com,Using machine learning to reconstruct deteriorated Van Gogh drawings,https://www.reddit.com/r/MachineLearning/comments/d6zxwv/using_machine_learning_to_reconstruct/,chicompj,1569008081,,0,1,False,https://b.thumbs.redditmedia.com/JoKmyBZWuLiQdmvT99uqMv5tIjyyNHNkZvhlk3vl-3w.jpg,,,,,
1083,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,4,d700k0,self.MachineLearning,Using graph theory in ML,https://www.reddit.com/r/MachineLearning/comments/d700k0/using_graph_theory_in_ml/,Kabev,1569008410,[removed],0,1,False,self,,,,,
1084,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,4,d707l9,self.MachineLearning,Is Machine Learning something I should be looking more into?,https://www.reddit.com/r/MachineLearning/comments/d707l9/is_machine_learning_something_i_should_be_looking/,emaxwell13131313,1569009280,"I am looking at Data Science positions and have a PhD in nuclear and computational physics from a program ranked in the top 45 in my field, which included Artificial Neural Networks and Phenomenology, a Postdoc in Chemistry and molecular dynamics and 5 month contract position as a researcher at a signal processing startup.  My linkedin in page has more details: [https://www.linkedin.com/in/evan-askanazi-404133a3/](https://www.linkedin.com/in/evan-askanazi-404133a3/)

I was wondering if I am looking in the right career path given my current background. I was looking at Machine Learning/Data Science but it seems that right now there are way more applicants in America and elsewhere looking for Machine Learning/Data Science work than there are openings available. I've heard it brought up but it seems that the supply of Machine Learners/Data Scientists is much, much higher than the demand, which is why so many researchers are struggling and failing to get desired work in this field.

And so while my background does include work that can be classified as Machine Learning/Data Science, it's not solely about Machine Learning/Data Science and so I was wondering if maybe there are options I haven't been made aware of. I also don't think a pure coding based job, such as a Front End or Back End Developing job, would work since I would be competing with hundreds of coders who've spent 2 years or more in boot camps, industry positions, tech firms and other places doing coding projects that can be added to portfolios. As of now I don't have a portfolio of the kind of projects one would do in a bootcamp since my previous work was in research that was a mix of chemistry, physics, data modeling (artificial neural networks being an important example), algorithm applications and machine learning.",0,1,False,self,,,,,
1085,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,5,d70apg,self.MachineLearning,[D] Is accurately estimating the contents of a voxel outside of a real 3D model possible?,https://www.reddit.com/r/MachineLearning/comments/d70apg/d_is_accurately_estimating_the_contents_of_a/,Mjjjokes,1569009694,"Imagine we have a training set of real 3D models (by this I mean, for example, 3D models of a rooms in buildings), and with this training set, we train the neural network to understand the relationship between a voxel and the 3D model in which it resides. Then, we use our neural network to predict one voxel  outside of the captured (by a camera) 3D model. Is this possible? Would the desired results be achieved?",4,0,False,self,,,,,
1086,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,5,d70hdd,youtube.com,Training Racing Cars With A Tiny Neural Network - Evolutionary Algorithm,https://www.reddit.com/r/MachineLearning/comments/d70hdd/training_racing_cars_with_a_tiny_neural_network/,Mesode,1569010521,,1,1,False,https://a.thumbs.redditmedia.com/2HSjdM5nh66krDTojZE6iKMeRk02eieSYVlBJkKM1T4.jpg,,,,,
1087,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,6,d71dtt,luminousmen.com,Demystifying hypothesis testing,https://www.reddit.com/r/MachineLearning/comments/d71dtt/demystifying_hypothesis_testing/,luminoumen,1569014687,,0,1,False,https://b.thumbs.redditmedia.com/jK6wAE3tx2gFFeK4mdPzb2ijqganHy7a32XtMOuniZE.jpg,,,,,
1088,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,7,d72jn6,self.MachineLearning,[Discussion] Roadblock in building a classification model,https://www.reddit.com/r/MachineLearning/comments/d72jn6/discussion_roadblock_in_building_a_classification/,Rockflagandeeeagle,1569020376,"I've been working on a dataset, something that I've never worked on before. 

I am in the process of building a classification model which can separate 2 classes using 2 continuous features &amp; around 10-15 multiclass categorical features. The classes are heavily imbalanced (3:1 ratio) &amp; I have over 500k observations.

I've tried a few methods like downsampling, class balancing along with a few algorithms like Logistic Regression, KNN, Random Forest, a few Gradient Boosting algorithms etc.. All these models are giving me poor results. 

I am working locally &amp; don't have access to a cloud service, hence I'm not keen on using NNs or SVMs which tend to be more computationally expensive.

What else can I do?

Thanks",9,14,False,self,,,,,
1089,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,8,d72pkg,self.MachineLearning,Master's Degree Programs?,https://www.reddit.com/r/MachineLearning/comments/d72pkg/masters_degree_programs/,LastTimeLord,1569021163,"I will be completing my BS soon in Data Science and I want to pursue a master's, preferably in machine learning. Specifically, I really want to work in reinforcement learning.

I'm currently trying to find master's programs to apply to but wanted to get some suggestions. Anyone know of some great programs?",0,1,False,self,,,,,
1090,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,9,d73ilh,self.MachineLearning,WGAN-LP Divergent?,https://www.reddit.com/r/MachineLearning/comments/d73ilh/wganlp_divergent/,Technomancerer,1569025385,[removed],0,1,False,https://b.thumbs.redditmedia.com/fbEoi7kH2cn5vpTuT0Ic7_HxPBhYJtVFkgDNUr-T90s.jpg,,,,,
1091,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,10,d746no,self.MachineLearning,Check out my new article. And never stop learning,https://www.reddit.com/r/MachineLearning/comments/d746no/check_out_my_new_article_and_never_stop_learning/,ht16998,1569029116,Different Type of Feature Engineering Encoding Techniques for Categorical Variable Encoding by Himanshu Tripathi https://link.medium.com/4PCobn3G8Z,0,1,False,self,,,,,
1092,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,11,d74kih,self.MachineLearning,[D] Sensor adaptation for 3D object detection?,https://www.reddit.com/r/MachineLearning/comments/d74kih/d_sensor_adaptation_for_3d_object_detection/,tsauri,1569031346,"Often 3D object detection models are benchmarked on one dataset e.g. KITTI, and this dataset is captured with one particular sensor rig (camera and/or LIDAR).

Is there work to adapt/generalize model trained with dataset from one sensor rig to other sensor rig?",0,1,False,self,,,,,
1093,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,11,d74mb8,self.MachineLearning,Seeking advice to implement a pattern recognition algorithm,https://www.reddit.com/r/MachineLearning/comments/d74mb8/seeking_advice_to_implement_a_pattern_recognition/,sanchitsharma29,1569031620," 

[https://drive.google.com/open?id=1WsAm3h-\_\_al\_eXfXaOc-DFMlONGf2ysv](https://drive.google.com/open?id=1WsAm3h-__al_eXfXaOc-DFMlONGf2ysv)

Hello,

I have many frames of 256 X 256 digits. These have clusters of data that I need to do classify from, I seek advice from the experts to provide me suggestions on how to approach the problem. I need to classify these clusters on the basis of shape(roundness), centroid location, the sum of all values in a cluster and size.

[https://drive.google.com/file/d/1oLQvKTj3oWkhR0ezaHqD8WQBmG6jv9ZF/view?usp=sharing](https://drive.google.com/file/d/1oLQvKTj3oWkhR0ezaHqD8WQBmG6jv9ZF/view?usp=sharing)

A sample frame inside clusters is shown above in the link. Some peculiar clusters are highlighted encircled in yellow. One encirclement is one cluster.

I am very new to this field, hence I appreciate any advice I can receive from you all. As this is a very wide field I would appreciate If you could share your expertise and let me know the suggested approach and what concepts I should focus on.

Thanks very much in advance.

Best regards,

Sanchit Sharma",0,1,False,self,,,,,
1094,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,11,d74tv1,pytorch.devpost.com,"[N] Submissions for the 2019 Pytorch Global Hackathon have been released. You can 'Like' any number of submission, and talk to the submission authors by directly commenting on their project. Each project has an interactive demo and video.",https://www.reddit.com/r/MachineLearning/comments/d74tv1/n_submissions_for_the_2019_pytorch_global/,AdditionalWay,1569032868,,0,1,False,default,,,,,
1095,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,12,d75ae4,self.MachineLearning,Is syllable detection a well studied topic in NLP?,https://www.reddit.com/r/MachineLearning/comments/d75ae4/is_syllable_detection_a_well_studied_topic_in_nlp/,pretysmitty,1569035588,[removed],0,1,False,self,,,,,
1096,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,13,d75z13,self.MachineLearning,[D] How to efficiently implement local attention?,https://www.reddit.com/r/MachineLearning/comments/d75z13/d_how_to_efficiently_implement_local_attention/,attention-question,1569039838,"I'd like to implement a simple dot-product attention mechanism such that the output at each timestep is computed by attending to the preceding L elements.  This is similar to the standard setup for autoregressive attention, but differing in that only a fixed window is attended to at each timestep.

Suppose we are training on sequences of length N and want to compute attention over windows of L elements.  The options that I can think of are:

1. Compute all N^(2) elements of the attention matrix and apply a mask so that only the N\*L elements of interest are used.  This is inefficient for L&lt;&lt;N and often impractical for large N due to memory constraints.
2. Manually window the inputs into overlapping sequences of length L, then apply attention to each window.  This only requires N\*L dot products, but involves tiling/repeating the inputs (attention keys/values) L times which is impractical for large L.
3. Manually loop over N and L and individually compute each of the N\*L dot products.  This is efficient in an algorithmic sense but practically will be terrible if implemented using a high-level DL library.

My question is whether or not this operation can be efficiently computed with high-level DL libraries.",3,3,False,self,,,,,
1097,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,13,d75zi2,self.MachineLearning,[P] Need a lead on where to find these specific motor specifications,https://www.reddit.com/r/MachineLearning/comments/d75zi2/p_need_a_lead_on_where_to_find_these_specific/,lapanoma,1569039924,"Final RPM: 60 +/- 10
Power: 2.5 +/- 0.3 kW
Volts: 110-220v
Motor Type: Single Phase
Budget: $350 tops
 ""90 degree reduction motor""",0,0,False,self,,,,,
1098,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,13,d76162,ft.com,Google claims to have reached Quantum Supremacy,https://www.reddit.com/r/MachineLearning/comments/d76162/google_claims_to_have_reached_quantum_supremacy/,doireallyneedone11,1569040239,,1,1,False,https://b.thumbs.redditmedia.com/vaWWEENqDT1vw5LLWzuwKAzWcily4cF8fMwTsQ91mPs.jpg,,,,,
1099,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,14,d76srn,self.MachineLearning,Recommendation System for implicit dataset using deep learning,https://www.reddit.com/r/MachineLearning/comments/d76srn/recommendation_system_for_implicit_dataset_using/,theneuronprogrammer,1569045490,[removed],0,1,False,self,,,,,
1100,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,15,d76tjg,self.MachineLearning,"[D] Solutions for Entity Matching with textual data (i.e. names, addresses)",https://www.reddit.com/r/MachineLearning/comments/d76tjg/d_solutions_for_entity_matching_with_textual_data/,DemiourgosD,1569045650,"Currently looking for either open source projects or paid solution that can be used for an Entity Matching problem.

Example:
Entity 1, name: aad, address: aacb, phone : 123
Entity 2, name: aad, address: aacb 1, phone: +4 123

Should be matched as same entity.

So far I have only found this open source solution: https://github.com/anhaidgroup/deepmatcher

Are there more open sourced solutions?

Also, are there any paid solutions for this problem?",16,38,False,self,,,,,
1101,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,18,d788pm,self.MachineLearning,A newbie approach to Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/d788pm/a_newbie_approach_to_reinforcement_learning/,ScarlettPotato,1569057211,[removed],0,1,False,self,,,,,
1102,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,18,d78cj1,self.MachineLearning,Which Valve To Use For Several Hot Fluid Or Steam?,https://www.reddit.com/r/MachineLearning/comments/d78cj1/which_valve_to_use_for_several_hot_fluid_or_steam/,uflowindia,1569058077,[removed],0,1,False,https://b.thumbs.redditmedia.com/K-dKcKLKfbZiFL5bUugqWnDzksR4FHgNxuMd7AXRmbw.jpg,,,,,
1103,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,18,d78fnz,self.MachineLearning,Question Regarding Data Correlation,https://www.reddit.com/r/MachineLearning/comments/d78fnz/question_regarding_data_correlation/,Senator_Ahn,1569058775,[removed],0,1,False,self,,,,,
1104,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,19,d78ne7,indiaroto.com,"Rotational moulding machine manufacturer, Rotomoulding Machine India, Biaxial machine, Pulverizer Machine, Rotomoulding machine for plastic water tank and Rotomoulding Moulds, India",https://www.reddit.com/r/MachineLearning/comments/d78ne7/rotational_moulding_machine_manufacturer/,indiaroto,1569060438,,0,1,False,default,,,,,
1105,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,19,d78qmd,indiaroto.com,"Rotational moulding machine manufacturer, Rotomoulding Machine India, Biaxial machine, Pulverizer Machine, Rotomoulding machine for plastic water tank and Rotomoulding Moulds, India",https://www.reddit.com/r/MachineLearning/comments/d78qmd/rotational_moulding_machine_manufacturer/,indiaroto,1569061114,,0,1,False,https://b.thumbs.redditmedia.com/63VqVCX434vPL2atPpjZ-0zcgPEFymqLgI_oCWa86Yk.jpg,,,,,
1106,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,20,d794qj,indiaroto.com,All Types Rotational Moulding Machines and Systems,https://www.reddit.com/r/MachineLearning/comments/d794qj/all_types_rotational_moulding_machines_and_systems/,indiaroto,1569063965,,0,1,False,default,,,,,
1107,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,20,d79622,self.MachineLearning,"[Discussion] Google patent ""GENERATING AUDIO USING NEURAL NETWORKS""",https://www.reddit.com/r/MachineLearning/comments/d79622/discussion_google_patent_generating_audio_using/,RickMcCoy,1569064229,"&gt; This specification describes how a system  implemented as computer programs on one or more computers in one or more locations can generate a sequence of audio data that includes a respective audio sample at each of multiple time steps .  For example , the sequence of audio data can represent speech in a particular natural language or a piece of music.

https://patentimages.storage.googleapis.com/1b/d3/ac/60abc0081cdf1b/US20190251987A1.pdf

It seems that this patent covers Wavenet. It has the iconic diagram demonstrating dilated convolutions and the equations for the layers.",21,11,False,self,,,,,
1108,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,20,d79c76,indiaroto.com,"Rotational moulding machine manufacturer, Rotomoulding Machine India, Biaxial machine, Pulverizer Machine, Rotomoulding machine for plastic water tank and Rotomoulding Moulds, India",https://www.reddit.com/r/MachineLearning/comments/d79c76/rotational_moulding_machine_manufacturer/,indiaroto,1569065395,,0,1,False,default,,,,,
1109,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,20,d79ehc,self.MachineLearning,[D][N] Submissions for the 2019 Pytorch Global Hackathon have been released.,https://www.reddit.com/r/MachineLearning/comments/d79ehc/dn_submissions_for_the_2019_pytorch_global/,AdditionalWay,1569065834,"https://pytorch.devpost.com/submissions

You can 'Like' any number of submission, and talk to the submission authors by directly commenting on their project. Each project has an interactive demo and video.",2,32,False,self,,,,,
1110,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,20,d79esu,self.MachineLearning,NeurIPS lottery,https://www.reddit.com/r/MachineLearning/comments/d79esu/neurips_lottery/,dbalchev,1569065899,[removed],0,1,False,self,,,,,
1111,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,21,d79r1a,youtu.be,Evolving AIs eating each other | With Pheromones !,https://www.reddit.com/r/MachineLearning/comments/d79r1a/evolving_ais_eating_each_other_with_pheromones/,Naotagrey,1569068136,,1,1,False,https://b.thumbs.redditmedia.com/T44rRqdEnlxJiRhuILtfqlOlpWYIgV6l4TCimCLCPcM.jpg,,,,,
1112,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,22,d7ad2y,self.MachineLearning,"[D] Siraj Raval - Potentially exploiting students, banning students asking for refund. Thoughts?",https://www.reddit.com/r/MachineLearning/comments/d7ad2y/d_siraj_raval_potentially_exploiting_students/,nord2rocks,1569071811,"I'm not a personal follower of Siraj, but this issue came up in a ML FBook group that I'm part of. I'm curious to hear what you all think.  


It appears that Siraj recently offered a course ""Make Money with Machine Learning"" with a registration fee but did not follow through with promises made in the initial offering of the course. On top of that, he created a refund and warranty page with information regarding the course *after* people already paid. Here is a link to  a WayBackMachine capture of someone's documentation of Siraj's potential misdeeds: [https://web.archive.org/save/https://case-for-a-refund.s3.us-east-2.amazonaws.com/feedback.html](https://web.archive.org/save/https://case-for-a-refund.s3.us-east-2.amazonaws.com/feedback.html)

According to Twitter threads, he has been banning anyone in his Discord/Slack that has been asking for refunds.

On top of this there are many Twitter threads regarding his behavior. A screenshot (bottom of post) of an account that has since been deactivated/deleted (assuming that the individual either agreed to shutdown their account for money, or were banned). Here is a Twitter WayBackMachine archive link of a search for the user in the screenshot: [https://web.archive.org/web/20190921130513/https:/twitter.com/search?q=safayet96434935&amp;src=typed\_query](https://web.archive.org/web/20190921130513/https:/twitter.com/search?q=safayet96434935&amp;src=typed_query). In the search results it is apparent that there are many students who have been impacted by Siraj. 

https://i.redd.it/sqkjkhjz3yn31.jpg",552,914,False,https://b.thumbs.redditmedia.com/kKzqNbT8KeMPjamkjj7WZMkcgvBBr5s3eZ-SOa-pWPc.jpg,,,,,
1113,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,22,d7aseb,self.MachineLearning,Power BI A-Z: Hands-On Power BI Training For Data Science!,https://www.reddit.com/r/MachineLearning/comments/d7aseb/power_bi_az_handson_power_bi_training_for_data/,HannahHumphreys,1569074177,[removed],0,1,False,self,,,,,
1114,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,23,d7avi3,self.MachineLearning,"torchdata: Implement map, cache, filter etc. within PyTorch's Datasets (like Tensorflow's tf.data and more)",https://www.reddit.com/r/MachineLearning/comments/d7avi3/torchdata_implement_map_cache_filter_etc_within/,szymonmaszke,1569074620,[removed],0,1,False,self,,,,,
1115,MachineLearning,t5_2r3gv,2019-9-21,2019,9,21,23,d7b01f,self.MachineLearning,"[P] torchdata: Implement map, cache, filter etc. within PyTorch's Datasets (like Tensorflow's tf.data and more)",https://www.reddit.com/r/MachineLearning/comments/d7b01f/p_torchdata_implement_map_cache_filter_etc_within/,szymonmaszke,1569075238,"**Hi /r/MachineLearning**,

# What is [torchdata](https://github.com/szymonmaszke/torchdata)

I would like to present you a new open source PyTorch based project ([__torchdata__](https://szymonmaszke.github.io/torchdata/)) which extends capabilities of `torch.utils.data.Dataset` by bringing `map`, `cache` and other operations known from `tensorflow.data.Dataset` (and actually a little more than that).

### All that with a single line of code: `super().__init__()`

For more, check [documentation](https://szymonmaszke.github.io/torchdata/) or [github repository](https://github.com/szymonmaszke/torchdata).

# Functionalities Overview

* Use `map`, `apply`, `reduce` or `filter`
* `cache` data in RAM or on disk (even partial caching, say first `20%` RAM and the rest on disk)
* Full PyTorch's [`Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) and [`IterableDataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset&gt;) support (including [`torchvision`](https://pytorch.org/docs/stable/torchvision/index.html))
* General `torchdata.maps` like `Flatten` or `Select`
* Concrete `torchdata.datasets` designed for file reading and other general tasks

# Example

- Create image reading dataset 

        import torchdata
        import torchvision


        class Images(torchdata.Dataset): # Different inheritance
             def __init__(self, path: str):
                super().__init__() # This is the only change
            self.files = [file for file in pathlib.Path(path).glob(""*"")]

        def __getitem__(self, index):
            return Image.open(self.files[index])

        def __len__(self):
            return len(self.files)

- `map` each element to `torch.Tensor` and `cache()` everything in memory:

        images = Images(""./data"").map(torchvision.transforms.ToTensor()).cache()

- concatenate with labels (another `torchdata.Dataset` instance) and iterate over:

        for data, label in images | labels:
            # Do whatever you want with your data

# Installation 

`pip` is the easiest of course:

        pip install torchdata

You can also use `nightly` releases (`torchdata-nightly`) or GPU/CPU Docker based images (check documentation). Hopefully `conda` will be released soon as well, stay tuned

BTW. You can also checkout [__torchfunc__](https://github.com/szymonmaszke/torchfunc), I plan to make a separate post about that in a week or so.

Thanks for checking the above, any input would be welcome (either here or on github)",8,6,False,self,,,,,
1116,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,0,d7bpmb,self.MachineLearning,Machine Learning / Deep Learning in Production?,https://www.reddit.com/r/MachineLearning/comments/d7bpmb/machine_learning_deep_learning_in_production/,SplinteredReflection,1569078743,[removed],1,2,False,self,,,,,
1117,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,0,d7br4t,medium.com,understand gradient descent,https://www.reddit.com/r/MachineLearning/comments/d7br4t/understand_gradient_descent/,data_engineer,1569078959,,0,1,False,default,,,,,
1118,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,0,d7bwy2,self.MachineLearning,Interview,https://www.reddit.com/r/MachineLearning/comments/d7bwy2/interview/,amour_007,1569079718,[removed],0,1,False,self,,,,,
1119,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,0,d7c34n,zoom.us,Discussion: How to use Machine Learning and Transfer Learning for PTSD Assessment in War and Refugee Zones,https://www.reddit.com/r/MachineLearning/comments/d7c34n/discussion_how_to_use_machine_learning_and/,Lordobba,1569080532,,0,1,False,https://b.thumbs.redditmedia.com/TydLczLu8prc9ALqEztLf9qd-OyMATmZ4jR-OePgK5M.jpg,,,,,
1120,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,2,d7dg7a,self.MachineLearning,"Inference, estimator, input functions and prediction",https://www.reddit.com/r/MachineLearning/comments/d7dg7a/inference_estimator_input_functions_and_prediction/,rich_kang,1569086920,[removed],0,1,False,self,,,,,
1121,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,2,d7dqkt,self.MachineLearning,Why is deep fake research being continued?,https://www.reddit.com/r/MachineLearning/comments/d7dqkt/why_is_deep_fake_research_being_continued/,sathvik66,1569088268,"Latest deep fake research such as face swaps on videos, seriously? I believe in the freedom to explore freely but take a minute to understand the consequences of creating these. And don't give me if we don't do it, someone else will.",0,1,False,self,,,,,
1122,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,3,d7e9fs,self.MachineLearning,[D] Predicting value of feature/model engineering on very large data sets?,https://www.reddit.com/r/MachineLearning/comments/d7e9fs/d_predicting_value_of_featuremodel_engineering_on/,farmingvillein,1569090696,"Setup: very large corpus (1TB+) of text data.  The problem space roughly generalizes into a seq2seq model.

Given the size and the required parameter space to fully exploit the data, retraining the model against the full data set is (understandably) very expensive ($10ks / full training run).  

Iterative pre-processing of the data is of course pricey as well.

Problem: **How can we estimate the effect of some new feature/model-engineering without re-training on the entire data set?**

Obviously we can do training runs at smaller amounts of data and/or with small parameter sizes.  This is of course a good start; if something doesn't work at smaller volumes of data, it *usually* isn't helpful at larger volumes of data.  But, at scale, enough data tends to wash away the value of many types of feature engineering and/or notionally ""more"" clever models.

Are there better ways to drive this process?  Bonus points if backed up by research!

Our current pattern is something like:

* Build multiple new things
* Test at much smaller data volumes
* Do an approximately full rebuild (although see below) every week or two, leveraging all new features/changes, and see if it moves the needle.

This gives us some results, but also means that if we have multiple new features/model changes that it is very hard to disambiguate the effect of new features at scale.  (And heaven help us if the overall performance goes down, despite all of our upfront testing.)  

To do ablations we're instead left with doing ablations at much lower data volumes and using our best human intuition to decide what to apply at scale.

It all kind of works, but is...unsatisfying.  And probably unoptimized.

Notes: 

* There are obviously lots of techniques to try to cram down the overall cost to re-training (e.g., warm starts from prior models or other pre-trained entities like Roberta).  We are actively testing here; suggestions to decrease cost/wallclock are of welcome.

* Do we ""need"" to use all the data and/or use larger params to eek out every last nth accuracy?  To simplify the discussion here, let's say yes--or at least assume that we've done a fairly good job of already doing that testing to figure out the right trade-off point between model maximization and accuracy required at the business level.",0,2,False,self,,,,,
1123,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,3,d7e9m0,self.MachineLearning,[D] Convergent evolution in next-generation neural networks?,https://www.reddit.com/r/MachineLearning/comments/d7e9m0/d_convergent_evolution_in_nextgeneration_neural/,darkconfidantislife,1569090714,"In the research quest for next-generation neural networks, it seems like two ""schools"" of thinking

are converging to something somewhat similar even after approaching it from different angles.

I'm referring to the HTM/sparse coding/bio-inspired group and the ""classical"" deep learning group.

&amp;#x200B;

Historically, the principles espoused by the former group (e.g. Numenta, Ogma Neo, Sparsey) have not

gotten much traction in the ML community due to lack of experimental results.

&amp;#x200B;

However, more recently, approaches from within the deep learning community have begun to somewhat resemble the former's approach(es). For example, OpenAI is now intensely interested in extremely sparse networks ( [https://supercomputersfordl2017.github.io/Presentations/SmallWorldNetworkArchitectures.pdf](https://supercomputersfordl2017.github.io/Presentations/SmallWorldNetworkArchitectures.pdf) ) and Geoff Hinton is working on capsules, which at least partially inspired by cortical columns ( [https://numenta.com/blog/2017/12/18/comparing-capsules-with-htm/](https://numenta.com/blog/2017/12/18/comparing-capsules-with-htm/)) and have some similarities. 

&amp;#x200B;

Just as interestingly, it appears that some non-backpropagation local learning algorithms, such as Hebbian learning ( [https://arxiv.org/abs/1908.08993](https://arxiv.org/abs/1908.08993) ) can actually scale to CIFAR and a small version of ImageNet. Of course, these results are very preliminary, but are at least somewhat interesting.

So I'd like to hear people's thoughts on this. Maybe there might be an interesting convergent evolution phenomenon where the approaches to next-generation NNs end up being somewhat similar.",4,17,False,self,,,,,
1124,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,3,d7ec9d,github.com,[P] Resemblyzer: a pretrained voice encoder as a lightweight python package,https://www.reddit.com/r/MachineLearning/comments/d7ec9d/p_resemblyzer_a_pretrained_voice_encoder_as_a/,Valiox,1569091057,,1,1,False,default,,,,,
1125,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,3,d7ed28,self.MachineLearning,How does SOTA compare across languages in NLP?,https://www.reddit.com/r/MachineLearning/comments/d7ed28/how_does_sota_compare_across_languages_in_nlp/,Razcle,1569091161,[removed],0,1,False,self,,,,,
1126,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,3,d7ehsp,self.MachineLearning,How does SOTA compare across languages in NLP? [Discussion],https://www.reddit.com/r/MachineLearning/comments/d7ehsp/how_does_sota_compare_across_languages_in_nlp/,Razcle,1569091767,"There have obviously been amazing progress in deep-learning based NLP/speech-technology in recent years. As an english speaker, I was wondering how state-of-the-art varies across languages?

How are good are things like sentiment analysis, question answering, speech recognition in non-english languages?

Does anyone know of any failure modes in non-english European languages? and are there any good open source libraries for NLP in sub-continental languages like Hindi and Urdu?

thanks!",2,6,False,self,,,,,
1127,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,3,d7embt,self.MachineLearning,[D] How important was your Masters for the industry skills?,https://www.reddit.com/r/MachineLearning/comments/d7embt/d_how_important_was_your_masters_for_the_industry/,starzmustdie,1569092341,I am thinking wether to enroll in one-year or two-year master's programme. I've asked people I personally know how much their classes mattered for their job and most of them said only a small portion of the classes did (1-3 classes). How much did it matter for you?,1,1,False,self,,,,,
1128,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,4,d7ets7,self.MachineLearning,Using of neural networks in data science,https://www.reddit.com/r/MachineLearning/comments/d7ets7/using_of_neural_networks_in_data_science/,HonestFrankie,1569093245,[removed],0,1,False,self,,,,,
1129,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,4,d7f9vj,self.MachineLearning,Google Colaboratory Local Runtime GPU,https://www.reddit.com/r/MachineLearning/comments/d7f9vj/google_colaboratory_local_runtime_gpu/,Gijske,1569095248,[removed],0,1,False,self,,,,,
1130,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,5,d7flgn,youtu.be,I made quick animated video introduction on Neural networks.,https://www.reddit.com/r/MachineLearning/comments/d7flgn/i_made_quick_animated_video_introduction_on/,Timbelion,1569096750,,0,1,False,default,,,,,
1131,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,5,d7g5td,self.MachineLearning,"[P] Torchelie - Pytorch extended with more optimizers, losses, layers, models, transformations, and even training loops",https://www.reddit.com/r/MachineLearning/comments/d7g5td/p_torchelie_pytorch_extended_with_more_optimizers/,Vermeille,1569099220,"Hi guys,

I've been working on Torchelie for something like two or three months now. Notable additions are :

- bitempered loss
- VQ layer from VQ-VAE
- RAdam
- SPADE / Conditional BatchNorm
- Neural Style loss / Deep Dream loss / Feature viz loss
- Spectral image to reproduce distill.pub's amazing feature viz results

Anyway, here's the link: https://github.com/Vermeille/Torchelie/
and the documentation is here: https://torchelie.readthedocs.io/

Criticism and bug reports are absolutely welcome.

Thank you for trying it out :)",12,38,False,self,,,,,
1132,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,6,d7ge1c,self.MachineLearning,[D] Analyzing thousands of podcast transcripts - interesting project ideas &amp; best algos?,https://www.reddit.com/r/MachineLearning/comments/d7ge1c/d_analyzing_thousands_of_podcast_transcripts/,pbirsinger,1569100280,"Hi - we're a small startup focusing on podcast transcriptions. We are working to make them readable, searchable, etc. We have previously used Tf-idf + LDA topic modeling to extract underlying topics in the corpus and compute related podcasts.

Potential ideas for future interesting projects include:

* automatically identifying ads
* picking up  trends/sentiment on politics/people/companies, etc
* find promo codes 
* auto-generate podcast summaries

What would you find most interesting, and why?",9,0,False,self,,,,,
1133,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,6,d7gpgv,self.MachineLearning,Interested in coding a revenue management AI to update best prices for hotels and airbnb accounts. Any idea of where to start or existing project on the topic? (Python preferred),https://www.reddit.com/r/MachineLearning/comments/d7gpgv/interested_in_coding_a_revenue_management_ai_to/,bodytexture,1569101756,[removed],0,1,False,self,,,,,
1134,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,9,d7itld,self.HomeNetworking,What are your Network Setups?,https://www.reddit.com/r/MachineLearning/comments/d7itld/what_are_your_network_setups/,summitrn,1569110761,,0,1,False,default,,,,,
1135,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,12,d7l9nk,youtube.com,Let's turn around the imminent Global recession!,https://www.reddit.com/r/MachineLearning/comments/d7l9nk/lets_turn_around_the_imminent_global_recession/,madeveninc,1569123756,,0,1,False,https://b.thumbs.redditmedia.com/Xc-5PUYFbYalggKT35qTee99S1du8A3c8EJgGX7W0Ns.jpg,,,,,
1136,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,13,d7lk9u,self.MachineLearning,Generating text samples with bidirectional RNN,https://www.reddit.com/r/MachineLearning/comments/d7lk9u/generating_text_samples_with_bidirectional_rnn/,BoiaDeh,1569125528,[removed],0,1,False,self,,,,,
1137,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,13,d7lsw9,self.MachineLearning,Handbook of Neural Computation,https://www.reddit.com/r/MachineLearning/comments/d7lsw9/handbook_of_neural_computation/,rafaelDgrate,1569127012,[removed],0,1,False,https://b.thumbs.redditmedia.com/dR8WOQUKiAjK634atfnjn7qJrVL68Q1_GcLDdkTfaAU.jpg,,,,,
1138,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,17,d7nqzt,self.MachineLearning,Unsupervised learning on Hybrid Data,https://www.reddit.com/r/MachineLearning/comments/d7nqzt/unsupervised_learning_on_hybrid_data/,gauravc2796,1569141048,[removed],0,1,False,self,,,,,
1139,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,18,d7o7be,self.MachineLearning,How do I generate notes/slides from text using NLP?,https://www.reddit.com/r/MachineLearning/comments/d7o7be/how_do_i_generate_notesslides_from_text_using_nlp/,viswanath660,1569144541,[removed],0,1,False,self,,,,,
1140,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,19,d7ohai,naftemporiki.gr,        2020,https://www.reddit.com/r/MachineLearning/comments/d7ohai/_____/,frequenttimetraveler,1569146625,,0,1,False,default,,,,,
1141,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,19,d7oizf,self.MachineLearning,[P] PyChubby - Face Warping,https://www.reddit.com/r/MachineLearning/comments/d7oizf/p_pychubby_face_warping/,kjanofficial,1569146948,"**What does it do?**

Change **facial expressions** and **shapes** with **zero effort**.

**How exactly?**

Give it a photo, define what to do with the faces (**smile**, **open eyes**, **shrink**, ...) , *pychubby* will do the rest.

**Features**

* No need to **manually specify landmarks**
* Works on **any photos** with **arbitrary number of faces**
* Can be used for **deep learning augmentations**
* ... or just creating funny photos/videos

**Links**

[github](https://github.com/jankrepl/pychubby)

[blogpost](https://towardsdatascience.com/pychubby-automated-face-warping-322765f5a1b2)

[docs](https://pychubby.readthedocs.io/en/latest/)

&amp;#x200B;

I would appreciate any feedback. Especially regarding the possibility of using it for augmentations in face recognition related tasks. Also, if there is someone who is interested in contributing or suggesting new features I would be more than happy!

&amp;#x200B;

[PyChubby in action](https://i.redd.it/mlfle0pwc4o31.png)",1,0,False,https://b.thumbs.redditmedia.com/_DBKcK8Ys0t6uEFMmtyjWzladPSCtsaLrZOLTTV_Gws.jpg,,,,,
1142,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,19,d7onwb,self.MachineLearning,What are some great NLP position papers?,https://www.reddit.com/r/MachineLearning/comments/d7onwb/what_are_some_great_nlp_position_papers/,winglikewitholder,1569147940,[removed],0,1,False,self,,,,,
1143,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,19,d7ov7v,self.MachineLearning,[D] Are there current AI that have a somewhat higher degree of autonomy that the programmers are unable to control everything that it does?,https://www.reddit.com/r/MachineLearning/comments/d7ov7v/d_are_there_current_ai_that_have_a_somewhat/,SirHovaOfBrooklyn,1569149449,"As the title states, I just want to know what level of autonomy the most advanced AI have. I'm trying to comprehend if we're at a point where an AI can do an act which the programmer might not be able to prevent from happening?",27,0,False,self,,,,,
1144,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,19,d7ox29,medium.com,[R] Progressively Growing U-Nets: A new Perspective for Medical Image Segmentation,https://www.reddit.com/r/MachineLearning/comments/d7ox29/r_progressively_growing_unets_a_new_perspective/,Zlush,1569149809,,0,2,False,default,,,,,
1145,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,19,d7oxrd,self.MachineLearning,How to calculate VC dim(H) ?,https://www.reddit.com/r/MachineLearning/comments/d7oxrd/how_to_calculate_vc_dimh/,RockieRockie,1569149966,[removed],0,1,False,self,,,,,
1146,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,20,d7oz0i,self.MachineLearning,I need YOUR help to build a NLP classifier.,https://www.reddit.com/r/MachineLearning/comments/d7oz0i/i_need_your_help_to_build_a_nlp_classifier/,malinjan,1569150214,[removed],1,1,False,self,,,,,
1147,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,20,d7p2gt,self.MachineLearning,"[Discussion], [Project] I need YOUR help to build an NLP classifier",https://www.reddit.com/r/MachineLearning/comments/d7p2gt/discussion_project_i_need_your_help_to_build_an/,malinjan,1569150836,"Hi,

It's my first post on reedit so I would like to say hello.

&amp;#x200B;

I am working on my website. However, I would like the main page to be quite unusual. Instead of the menu section, I am going to use an NLP classifier with 3 classes:

\-Portfolio

\-About Me

\-Contact

&amp;#x200B;

If the user typed 'Could you show me some of your past projects' or 'Tell me something about you', the classifier would classify it to one of three categories and then take to the according page.

&amp;#x200B;

However, the problem that I am facing is that it's quite hard to get queries to train the classifier. 

Therefore, I would like to ask you to write how would you ask someone for a portfolio, information about them and contact info.

&amp;#x200B;

Thanks for your time!",3,0,False,self,,,,,
1148,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,20,d7p4gy,self.MachineLearning,[D] What are your favorite YouTube channels that features advanced research ML talks ?,https://www.reddit.com/r/MachineLearning/comments/d7p4gy/d_what_are_your_favorite_youtube_channels_that/,__Julia,1569151212,"Hi,

I am trying to collect some YouTube channels to follow, the idea is to find channels that features advanced research ML talks such the following [\[1\]](https://www.youtube.com/channel/UCSHZKyawb77ixDdsGog4iWA), \[[2](https://www.youtube.com/user/Zan560)\], \[[3](https://www.youtube.com/channel/UCSHZKyawb77ixDdsGog4iWA)\]. 

I noticed that most of the scientific conferences don't upload their talks such [KDD](https://www.youtube.com/channel/UCSBrGGR7JOiSyzl60OGdKYQ/videos), ICML, ICLR, ACL, NeurIPS except [CVPR](https://www.youtube.com/user/ieeeComputerSociety/videos). where do you guys find these talks? When I search, I find them in several individual channels ([talks upload by speakers or some random channels duplicating them from somewhere else](https://www.youtube.com/playlist?list=PLzr1cXri89xZah4Z_nzJo8mxQ7RYPa1G-))",52,347,False,self,,,,,
1149,MachineLearning,t5_2r3gv,2019-9-22,2019,9,22,21,d7plww,sirajraval.com,[D] The Neural Qubit (paper by Siraj Raval),https://www.reddit.com/r/MachineLearning/comments/d7plww/d_the_neural_qubit_paper_by_siraj_raval/,Yajirobe404,1569154361,,0,1,False,default,,,,,
1150,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,0,d7s1iw,self.MachineLearning,What is the best Best approach for essentially joining two documents together?,https://www.reddit.com/r/MachineLearning/comments/d7s1iw/what_is_the_best_best_approach_for_essentially/,johne898,1569166628,[removed],0,1,False,self,,,,,
1151,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,1,d7ssw2,self.MachineLearning,Machine learning salaries,https://www.reddit.com/r/MachineLearning/comments/d7ssw2/machine_learning_salaries/,PranDaTanMan,1569169887,[removed],0,1,False,self,,,,,
1152,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,1,d7sukx,self.MachineLearning,"[P] I've made User Behavior Prediction for everyone, called Behaiv",https://www.reddit.com/r/MachineLearning/comments/d7sukx/p_ive_made_user_behavior_prediction_for_everyone/,dmi3coder,1569170093,"Just finished working on java/android library for User Behavior Prediction. It makes it really easy for developers to use it. Essentially thats just logistic regression, but there are prepared ways to get features. Still really raw, but the concept is working.

[https://github.com/dmi3coder/behaiv-java](https://github.com/dmi3coder/behaiv-java)

I hope such feature could be present in the Evernote app. Its basically like app suggestion in ios(based on position and time) but targeted for the app itself.

Planning to port it to javascript to use it with React/Angular. As well as Swift for ios support  
Main thing is that the model is trained on the device using EJML for matrix manipulations. 

So, let me know if idea is good and should I continue working on this project or switch to something more interesting

&amp;#x200B;

https://i.redd.it/5nywvtfb34o31.png",2,6,False,self,,,,,
1153,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,1,d7svha,self.MachineLearning,Clinical Data Science,https://www.reddit.com/r/MachineLearning/comments/d7svha/clinical_data_science/,HannahHumphreys,1569170194,[removed],0,1,False,self,,,,,
1154,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,1,d7syfs,physionet.org,Dataset of 377k xray with free text reports released,https://www.reddit.com/r/MachineLearning/comments/d7syfs/dataset_of_377k_xray_with_free_text_reports/,stevevaius,1569170555,,0,1,False,default,,,,,
1155,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,1,d7t1dh,self.MachineLearning,Astonishing Hierarchy of Machine Learning Needs,https://www.reddit.com/r/MachineLearning/comments/d7t1dh/astonishing_hierarchy_of_machine_learning_needs/,andrea_manero,1569170918,[removed],0,1,False,self,,,,,
1156,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,2,d7tsj2,/r/MachineLearning/comments/d7tsj2/research_finger_detection_and_tracking/,[Research] Finger Detection and Tracking,https://www.reddit.com/r/MachineLearning/comments/d7tsj2/research_finger_detection_and_tracking/,amarpandey,1569174250,,0,1,False,default,,,,,
1157,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,3,d7u286,twitter.com,Make Money with Machine Learning - Siraj Raval TOTAL MONEY RIPOFF,https://www.reddit.com/r/MachineLearning/comments/d7u286/make_money_with_machine_learning_siraj_raval/,reduser1197,1569175437,,0,1,False,default,,,,,
1158,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,3,d7u7eg,self.MachineLearning,Make Money with Machine Learning -course by Siraj Raval (Review by a student),https://www.reddit.com/r/MachineLearning/comments/d7u7eg/make_money_with_machine_learning_course_by_siraj/,reduser1197,1569176050,[removed],0,1,False,self,,,,,
1159,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,3,d7uhhw,self.MachineLearning,Do NOT store trained models in Git,https://www.reddit.com/r/MachineLearning/comments/d7uhhw/do_not_store_trained_models_in_git/,undefinedNANString,1569177285,[removed],0,1,False,self,,,,,
1160,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,3,d7umxc,self.MachineLearning,[P] Trying to modify Tweepy parameters,https://www.reddit.com/r/MachineLearning/comments/d7umxc/p_trying_to_modify_tweepy_parameters/,MrMegaGamerz,1569177940,"Hey all, 

I'm using Tweepy for the first time and am trying my best to follow tutorials online. I'm trying to extract tweets given a certain hashtag and am wondering if it's possible to filter further. I am trying to:

1) Save tweets with hashtags at the end only. 
2) Have less than 4 hashtags in total. 
3) Filter out all images and links. 

I'm having trouble finding ways to implement the first two parameters. For #3 I've used the following and it seems to work: Print (tweet.created_at, re.sub(r""http\S+"", """", tweet.full_text)) . 

Hope someone with more experience can shed light on it for me. I am trying to recreate a paper and for their Twitter Corpus, they followed those guidelines.",1,1,False,self,,,,,
1161,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,3,d7uox4,self.MachineLearning,Introducing Entropee AI (entropee.com)  solving AI data problems,https://www.reddit.com/r/MachineLearning/comments/d7uox4/introducing_entropee_ai_entropeecom_solving_ai/,entropee_ai,1569178195,[removed],0,1,False,https://b.thumbs.redditmedia.com/T5C_1bUlNYqvlN7ZaI1NkgYT0bekg38ORITPn26sbwA.jpg,,,,,
1162,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,3,d7urn7,self.MachineLearning,Understanding proof of probability of policy under MaxEnt distribution,https://www.reddit.com/r/MachineLearning/comments/d7urn7/understanding_proof_of_probability_of_policy/,celestialquestrial,1569178530,[removed],0,1,False,self,,,,,
1163,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,4,d7uxby,self.MachineLearning,[D] Understanding proof of MaxEnt theorem,https://www.reddit.com/r/MachineLearning/comments/d7uxby/d_understanding_proof_of_maxent_theorem/,celestialquestrial,1569179227,"I'm reading Brian Ziebart's work on maximum causal entropy optimization for inverse reinforcement learning. I'm reading through a few of his thesis chapters to get a deeper understanding, but have gotten stuck on one particular proof: the first line of the proof of Theorem 6.10. The theorem follows easily after the first line, but I can't make sense of the logic behind the first line.

In a nutshell, the theorem shows that under a maximum causal entropy distribution, the likelihood of any policy pi increases in proportion to the expected reward (linear in \[state, action\] features) under that policy. However to prove this, he starts off by writing the P(pi) = Product over all trajectories (A, S) of P\_MaxEnt(A, S)\^pi(A, S). I do not understand where this equation comes from. It seems strange to me that it is raising maximum entropy distribution probabilities to the power of the policy probabilities.

I would greatly appreciate it if anyone could help me understand this.

The theorem is from his thesis (pg 210), available here: [http://www.cs.cmu.edu/\~bziebart/publications/thesis-bziebart.pdf](http://www.cs.cmu.edu/~bziebart/publications/thesis-bziebart.pdf)

Full theorem and proof included below:

https://i.redd.it/61807bbw17o31.png

https://i.redd.it/b6ps5amx17o31.png",10,4,False,https://a.thumbs.redditmedia.com/WkxdF2_DI5UQHaNb_K2bxtyIcDbf1lwSQDAbaAeka68.jpg,,,,,
1164,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,4,d7vh8a,self.MachineLearning,"ML people, what nonexistent service would make your life alot easier?",https://www.reddit.com/r/MachineLearning/comments/d7vh8a/ml_people_what_nonexistent_service_would_make/,bigthrow100,1569181624,"Anything that's a huge problem/pain in the ass for you, that you'd happily pay someone else to do. How often would you use it and how much would you pay for it?",0,1,False,self,,,,,
1165,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,5,d7vno3,self.MachineLearning,[D] Machine Learning - WAYR (What Are You Reading) - Week 71,https://www.reddit.com/r/MachineLearning/comments/d7vno3/d_machine_learning_wayr_what_are_you_reading_week/,ML_WAYR_bot,1569182406,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|31-40|41-50|51-60|61-70|
|----|-----|-----|-----|-----|-----|-----|
|[Week 1](https://www.reddit.com/4qyjiq)|[Week 11](https://www.reddit.com/57xw56)|[Week 21](https://www.reddit.com/60ildf)|[Week 31](https://www.reddit.com/6s0k1u)|[Week 41](https://www.reddit.com/7tn2ax)|[Week 51](https://reddit.com/9s9el5)|[Week 61](https://reddit.com/bfsx4z)|||||
|[Week 2](https://www.reddit.com/4s2xqm)|[Week 12](https://www.reddit.com/5acb1t)|[Week 22](https://www.reddit.com/64jwde)|[Week 32](https://www.reddit.com/72ab5y)|[Week 42](https://www.reddit.com/7wvjfk)|[Week 52](https://reddit.com/a4opot)|[Week 62](https://reddit.com/bl29ov)||
|[Week 3](https://www.reddit.com/4t7mqm)|[Week 13](https://www.reddit.com/5cwfb6)|[Week 23](https://www.reddit.com/674331)|[Week 33](https://www.reddit.com/75405d)|[Week 43](https://www.reddit.com/807ex4)|[Week 53](https://reddit.com/a8yaro)|[Week 63](https://reddit.com/bqlb3v)||
|[Week 4](https://www.reddit.com/4ub2kw)|[Week 14](https://www.reddit.com/5fc5mh)|[Week 24](https://www.reddit.com/68hhhb)|[Week 34](https://www.reddit.com/782js9)|[Week 44](https://reddit.com/8aluhs)|[Week 54](https://reddit.com/ad9ssz)|[Week 64](https://reddit.com/bw1jm7)||
|[Week 5](https://www.reddit.com/4xomf7)|[Week 15](https://www.reddit.com/5hy4ur)|[Week 25](https://www.reddit.com/69teiz)|[Week 35](https://www.reddit.com/7b0av0)|[Week 45](https://reddit.com/8tnnez)|[Week 55](https://reddit.com/ai29gi)|[Week 65](https://reddit.com/c7itkk)||
|[Week 6](https://www.reddit.com/4zcyvk)|[Week 16](https://www.reddit.com/5kd6vd)|[Week 26](https://www.reddit.com/6d7nb1)|[Week 36](https://www.reddit.com/7e3fx6)|[Week 46](https://reddit.com/8x48oj)|[Week 56](https://reddit.com/ap8ctk)|[Week 66](https://reddit.com/cd7gko)||
|[Week 7](https://www.reddit.com/52t6mo)|[Week 17](https://www.reddit.com/5ob7dx)|[Week 27](https://www.reddit.com/6gngwc)|[Week 37](https://www.reddit.com/7hcc2c)|[Week 47](https://reddit.com/910jmh)|[Week 57](https://reddit.com/auci7c)|[Week 67](https://reddit.com/cj0kyc)||
|[Week 8](https://www.reddit.com/53heol)|[Week 18](https://www.reddit.com/5r14yd)|[Week 28](https://www.reddit.com/6jgdva)|[Week 38](https://www.reddit.com/7kgcqr)|[Week 48](https://reddit.com/94up0g)|[Week 58](https://reddit.com/azjoht)|[Week 68](https://reddit.com/cp1jex)||
|[Week 9](https://www.reddit.com/54kvsu)|[Week 19](https://www.reddit.com/5tt9cz)|[Week 29](https://www.reddit.com/6m9l1v)|[Week 39](https://www.reddit.com/7nayri)|[Week 49](https://reddit.com/98n2rt)|[Week 59](https://reddit.com/b50r5y)|[Week 69](https://reddit.com/cvde5a)||
|[Week 10](https://www.reddit.com/56s2oa)|[Week 20](https://www.reddit.com/5wh2wb)|[Week 30](https://www.reddit.com/6p3ha7)|[Week 40](https://www.reddit.com/7qel9p)|[Week 50](https://reddit.com/9cf158)|[Week 60](https://reddit.com/bakew0)|[Week 70](https://reddit.com/d1g1k9)||

Most upvoted papers two weeks ago:

/u/blueNou_mars: [Contrastive Multiview Coding](https://arxiv.org/abs/1906.05849)

/u/StellaAthena: [Detecting Learning vs Memorization in Deep Neural Networks using Shared Structure Validation Sets](https://arxiv.org/pdf/1802.07714.pdf)

Besides that, there are no rules, have fun.",17,8,False,self,,,,,
1166,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,5,d7vv1l,self.MachineLearning,[D] Siraj Apologizes and Promises Refunds within 30 days,https://www.reddit.com/r/MachineLearning/comments/d7vv1l/d_siraj_apologizes_and_promises_refunds_within_30/,permalip,1569183297,"Here is the twitter thread

![img](ca11bcryd7o31)",141,300,False,self,,,,,
1167,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,7,d7x87n,self.MachineLearning,"AI Weekly Update! - September 22nd, 2019",https://www.reddit.com/r/MachineLearning/comments/d7x87n/ai_weekly_update_september_22nd_2019/,HenryAILabs,1569189620,[removed],0,1,False,self,,,,,
1168,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,8,d7xyz5,self.MachineLearning,Visual Recognition of Ascii/Unicode Characters,https://www.reddit.com/r/MachineLearning/comments/d7xyz5/visual_recognition_of_asciiunicode_characters/,hooligan_37,1569193313,[removed],0,1,False,self,,,,,
1169,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,8,d7y3bf,self.MachineLearning,[R] Work Related to Normalizing Unicode using Computer Vision,https://www.reddit.com/r/MachineLearning/comments/d7y3bf/r_work_related_to_normalizing_unicode_using/,hooligan_37,1569193910,"I'm looking for work related to normalizing Unicode characters to their ASCII equivalent, through the use of computer vision, specifically employing CNN's. Anyone familiar with work related to this? Thank you!",1,1,False,self,,,,,
1170,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,9,d7z4tp,self.MachineLearning,GAN cats on Instagram,https://www.reddit.com/r/MachineLearning/comments/d7z4tp/gan_cats_on_instagram/,dimkadimon,1569199266,[removed],0,1,False,self,,,,,
1171,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,10,d7zsqf,self.MachineLearning,"[D] The German Credit Rating data set: widely used in ML, but no clear source",https://www.reddit.com/r/MachineLearning/comments/d7zsqf/d_the_german_credit_rating_data_set_widely_used/,SoFarFromHome,1569202757,"There's a commonly-used machine learning data set called about German credit rating.  I would ballpark estimate that it's been used in [hundreds of statistics and ML papers](https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C44&amp;q=german+credit+data&amp;btnG=), in part due to its availability on [the UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29) and in [various](https://rdrr.io/rforge/caret/man/GermanCredit.html) [packages](https://github.com/IBM/AIF360/tree/master/aif360/data/raw/german), each with different variable encodings.

However, almost all of the versions I can find have missing/incomplete documentation.  Many have the ""Present residence since"" field which takes values in {1, 2, 3, 4}, with no note on what those discretizations mean.  It also lacks essential data e.g. when the data was collected and by what means.

Chasing down the citations, it looks like the original data set comes from this paper on CART from 1990:
&gt; Hofmann H. J. Die anwendung des cart-verfahrens zur statistischen bonitatsanalyse von konsumentenkrediten. Zeitschrift fur Betriebswirtschaft, 60:941962, 1990

Translated:
&gt; Hofmann H. J. ""The application of the CART method for statistical credit analysis of consumer credit"". Journal of Business Administration, 60:941962, 1990

I can't find that article anywhere.  Google Scholar only has citations to it, SpringerLink doesn't have that volume, my own university's library only has much older and much newer volumes, and a German library network I searched only had links to some Swiss libraries which in turn linked back to SpringerLink.  From the UCI link above, it appears that Dr. Hofmann was affiliated with the University of Hamburg around 1994 with the first name Hans, however I was (unsurprisingly) unable to find a page for a professor from 25 years ago.  There are also notable Hans J Hofmann's in Chemistry and Anthropology, which complicates the search for this author.

It troubles me that such a commonly-used data set has no clear source.  Can anyone find the original publication of this data set, and/or an original version of the data and documentation?  The various versions available online (some with different variable encodings!) suggest that comparisons between papers that use this data set could be leading to false conclusions in our field (on top of the issue of so many papers being based off a single test set).",23,53,False,self,,,,,
1172,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,11,d80499,marti.ai,[P] GAN for financial correlations. A documented failed attempt.,https://www.reddit.com/r/MachineLearning/comments/d80499/p_gan_for_financial_correlations_a_documented/,gau_mar,1569204435,,0,1,False,default,,,,,
1173,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,13,d81mj4,self.MachineLearning,Why do we take absolute weights to find the top features in logistic regression,https://www.reddit.com/r/MachineLearning/comments/d81mj4/why_do_we_take_absolute_weights_to_find_the_top/,kiramonchan,1569212933,[removed],0,1,False,self,,,,,
1174,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,14,d81yjn,self.MachineLearning,AI for Leaders@great learning (No programming experience required) www.greatlearning.com,https://www.reddit.com/r/MachineLearning/comments/d81yjn/ai_for_leadersgreat_learning_no_programming/,arjunliveshere,1569215100,"AI for Leaders is an intensive online program for leaders who want to:

Understand enough AI to be able to make important choices and decision

Develop the ability to identify, scope and manage projects in AI

Deliver trans-formative projects to external and internal clients and stakeholders

Manage technical teams through the life-cycle of AI projects

Choose appropriate choices when deciding between tech stacks or products

Lead organisations new to the AI world as they develop AI-enabled products and services  

People enrolling into the program may come with titles including (but not limited to) Product Manager, Business Head, Delivery Manager, Account Manager, Team Lead, Engineering Manager, Data Science Consultant, Marketing Manager, R&amp;D Manager. What they have in common is that they want to learn enough to be able to leverage the power of AI to build products, services or service clients. 

The program will focus on applications and use-cases using case studies and practical examples. While there will be coverage of the concepts that make up machine learning and artificial intelligence, it is intended to help the participants develop an intuitive understanding rather than master deep technical details.

For more details about the course, pls ping me",0,1,False,self,,,,,
1175,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,14,d82cpf,self.MachineLearning,Revision Material,https://www.reddit.com/r/MachineLearning/comments/d82cpf/revision_material/,mhussainq,1569217723,"Hey Guys,

Is there some material available which can be used to revise Machine learning models. So basically it should have all the popular models their use with their math (at least loss function and way to optimize). Ideally a person taking a full long course should have this as their notes :P. Anyway I was wondering if something like this is available the motive is do some revision for Interviews.

Thanks.",0,1,False,self,,,,,
1176,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,15,d82i1l,self.MachineLearning,Is there anyone successfully applying RL or GANs in a production environment? (except those at FAANG and similar),https://www.reddit.com/r/MachineLearning/comments/d82i1l/is_there_anyone_successfully_applying_rl_or_gans/,claverru,1569218721,[removed],0,1,False,self,,,,,
1177,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,15,d82p4s,self.MachineLearning,Machine Learning vs Artificial Intelligence (AI) - A Fair Comparison,https://www.reddit.com/r/MachineLearning/comments/d82p4s/machine_learning_vs_artificial_intelligence_ai_a/,ankitsri19,1569220097,[removed],0,1,False,self,,,,,
1178,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,16,d834gr,solaceinfotech.com,All you need to know about Machine Learning,https://www.reddit.com/r/MachineLearning/comments/d834gr/all_you_need_to_know_about_machine_learning/,SolaceInfotech,1569223165,,0,1,False,default,,,,,
1179,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,16,d83a09,gminsights.com,Artificial Intelligence (AI) in Education Industry Size worth $6bn by 2024,https://www.reddit.com/r/MachineLearning/comments/d83a09/artificial_intelligence_ai_in_education_industry/,pradip6,1569224310,,0,1,False,default,,,,,
1180,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,17,d83m8p,self.MachineLearning,Tools and techniques to bring cutting edge AI research into production,https://www.reddit.com/r/MachineLearning/comments/d83m8p/tools_and_techniques_to_bring_cutting_edge_ai/,santoshgsk,1569226917,"Having witnessed the trends in AI and Machine Learning one thing I realised is that the field has matured across domains like NLP, CV, generative modeling but many of those innovations are yet to see an impact in the industry.

Lately, there have been attempts to bring those innovations into the industry and consolidate the pipelines and feedback cycles. This weekly issue focusses on tools and techniques that would help you to bring such cutting-edge research into production.

&amp;#x200B;

[https://www.getrevue.co/profile/santoshgsk/issues/ai-weekly-issue-8-apple-s-ml-framework-continuous-deployment-of-ml-practical-nlp-tips-evaluating-generative-models-199906](https://www.getrevue.co/profile/santoshgsk/issues/ai-weekly-issue-8-apple-s-ml-framework-continuous-deployment-of-ml-practical-nlp-tips-evaluating-generative-models-199906)",0,1,False,self,,,,,
1181,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,17,d83mp8,techxplore.com,Using machine learning to reconstruct deteriorated Van Gogh drawings,https://www.reddit.com/r/MachineLearning/comments/d83mp8/using_machine_learning_to_reconstruct/,bil-sabab,1569227019,,0,1,False,default,,,,,
1182,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,17,d83q8x,arxiv.org,[R] Gate Decorator: Global Filter Pruning Method for Accelerating Deep Convolutional Neural Networks [NeurIPS'19],https://www.reddit.com/r/MachineLearning/comments/d83q8x/r_gate_decorator_global_filter_pruning_method_for/,iamkarl42,1569227805,,18,38,False,default,,,,,
1183,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,17,d83tvz,self.MachineLearning,AEV releases autonomous driving dataset under a permissive license,https://www.reddit.com/r/MachineLearning/comments/d83tvz/aev_releases_autonomous_driving_dataset_under_a/,ingolstadter,1569228587,[removed],0,1,False,self,,,,,
1184,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,18,d83xcq,self.MachineLearning,AEV releases a multi-modal autonomous driving dataset,https://www.reddit.com/r/MachineLearning/comments/d83xcq/aev_releases_a_multimodal_autonomous_driving/,ingolstadter,1569229340,[removed],0,1,False,self,,,,,
1185,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,18,d847hk,self.MachineLearning,[N] AEV releases a multi-modal autonomous driving dataset,https://www.reddit.com/r/MachineLearning/comments/d847hk/n_aev_releases_a_multimodal_autonomous_driving/,ingolstadter,1569231410,"Webpage: [a2d2.audi](https://a2d2.audi/)

""An open multi-sensor dataset for autonomous driving research available for the academic community. This dataset comprises of annotated semantic segmentation images and point clouds, 3D bounding boxes, and also unannotated 360 time-synchronized and registered camera and lidar data, as well as data bus, for three recorded sequences. We hope this commercial-friendly dataset will further facilitate active research and development in AI and robotics for autonomous driving.""

License: CC BY-ND 4.0",0,1,False,self,,,,,
1186,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,18,d8486h,elink.io,Engaging Your Customers With WhatsApp Chatbot Integration,https://www.reddit.com/r/MachineLearning/comments/d8486h/engaging_your_customers_with_whatsapp_chatbot/,Ripple2709,1569231548,,0,1,False,https://b.thumbs.redditmedia.com/0tgSqN25sT3ZaJKSJsRWpB-eNnCRZVfJimI28jJhvEA.jpg,,,,,
1187,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,18,d84ax4,self.MachineLearning,[N] AEV releases a multi-modal autonomous driving dataset,https://www.reddit.com/r/MachineLearning/comments/d84ax4/n_aev_releases_a_multimodal_autonomous_driving/,kevinpl07,1569232099,"An open multi-sensor dataset for autonomous driving research available
for the academic community. This dataset comprises of annotated semantic
segmentation images and point clouds, 3D bounding boxes, and also
unannotated 360 time-synchronized and registered camera and lidar data, 
as well as data bus, for three recorded sequences. We hope this
commercial-friendly dataset will further facilitate active research and 
development in AI and robotics for autonomous driving.

Link:
a2d2.audi",0,1,False,self,,,,,
1188,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,18,d84ck8,self.MachineLearning,[P] SOTA Atari learning with Recurrent IQN,https://www.reddit.com/r/MachineLearning/comments/d84ck8/p_sota_atari_learning_with_recurrent_iqn/,olieber,1569232412,"Hey Guys,

I've recently implemented a recurrent version of the IQN reinforcement learning algorithm, combining IQN/Rainbow/R2D2 features, which can reach state-of-the-art (In sample efficiency) results on the Atari benchmark.

Any feedback is more than welcome.

[GitHub](https://github.com/opherlieber/rltime)

[Write-up with implementation details and results](https://opherlieber.github.io/rl/2019/09/22/recurrent_iqn)",31,81,False,self,,,,,
1189,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,19,d84f9l,self.MachineLearning,[N] AEV releases a multi-modal autonomous driving dataset,https://www.reddit.com/r/MachineLearning/comments/d84f9l/n_aev_releases_a_multimodal_autonomous_driving/,ingolstadter,1569232948,"Webpage: [https://www.audi-electronics-venture.de/aev/web/en/driving-dataset.html](https://www.audi-electronics-venture.de/aev/web/en/driving-dataset.html)

""An open multi-sensor dataset for autonomous driving research available for the academic community. This dataset comprises of annotated semantic segmentation images and point clouds, 3D bounding boxes, and also unannotated 360 time-synchronized and registered camera and lidar data,  as well as data bus, for three recorded sequences. We hope this commercial-friendly dataset will further facilitate active research and  development in AI and robotics for autonomous driving.""

License: CC BY ND 4.0",0,1,False,self,,,,,
1190,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,19,d84fsr,i.redd.it,Best python course,https://www.reddit.com/r/MachineLearning/comments/d84fsr/best_python_course/,prih_yah,1569233048,,0,1,False,default,,,,,
1191,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,19,d84gjf,self.MachineLearning,[N] AEV releases multi-modal autonomous driving dataset,https://www.reddit.com/r/MachineLearning/comments/d84gjf/n_aev_releases_multimodal_autonomous_driving/,kevinpl07,1569233176,"An open multi-sensor dataset for autonomous driving research available for the academic community. This dataset comprises of annotated semantic segmentation images and point clouds, 3D bounding boxes, and also unannotated 360 time-synchronized and registered camera and lidar data, as well as data bus, for three recorded sequences. We hope this commercial-friendly dataset will further facilitate active research and development in AI and robotics for autonomous driving.

Link:
https://www.audi-electronics-venture.de/aev/web/en/driving-dataset.html",0,54,False,self,,,,,
1192,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,19,d84tk7,self.MachineLearning,"[P] A PyTorch implementation of ""Continuous Relaxation Training of Discrete Latent Variable Image Model""",https://www.reddit.com/r/MachineLearning/comments/d84tk7/p_a_pytorch_implementation_of_continuous/,b-shall,1569235673,"Hi All,

Just wanted to share a PyTorch implementation of ""Continuous Relaxation Training of Discrete Latent Variable Image Models"", Casper Kaae Snderby, Ben Poole, Andriy Mnih. It includes the GS-Soft and VQVAE models from the paper and (to my knowledge) is the only implementation that that gets close to the reported bits per dimension on CIFAR10 for VQVAE.

**Link to repo:** [https://github.com/bshall/VectorQuantizedVAE](https://github.com/bshall/VectorQuantizedVAE)

**Link to paper:** [http://bayesiandeeplearning.org/2017/papers/54.pdf](http://bayesiandeeplearning.org/2017/papers/54.pdf)",0,12,False,self,,,,,
1193,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,19,d84tmw,medium.com,Conversational AI: The Advanced Form of Chatbots,https://www.reddit.com/r/MachineLearning/comments/d84tmw/conversational_ai_the_advanced_form_of_chatbots/,Anshul_Bansal,1569235690,,0,1,False,default,,,,,
1194,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,20,d859ax,self.MachineLearning,Which Valve To Use For Several Hot Fluid Or Steam?,https://www.reddit.com/r/MachineLearning/comments/d859ax/which_valve_to_use_for_several_hot_fluid_or_steam/,uflowindia,1569238379,[removed],0,1,False,https://b.thumbs.redditmedia.com/yWz64B0UFEJffpQe6jGi_a5TcD5-AWQnUAP0ALRTYQQ.jpg,,,,,
1195,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,21,d85t2t,onlineitguru.com,Artificial Intelligence VS Machine Learning,https://www.reddit.com/r/MachineLearning/comments/d85t2t/artificial_intelligence_vs_machine_learning/,krishnateja12,1569241479,,0,1,False,default,,,,,
1196,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,22,d86qpe,self.MachineLearning,[D] data generator to handle large datasets,https://www.reddit.com/r/MachineLearning/comments/d86qpe/d_data_generator_to_handle_large_datasets/,alpaca1331,1569246336,I am looking for a well documented tutorial to know how to correctly and elegantly program a data generator in order to train a neural network without loading the whole dataset in memory. The problem I have is that there are a lot of implementations around there and I'm not sure if some of them work efficiently. Thanks!,3,2,False,self,,,,,
1197,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,22,d86t92,self.MachineLearning,Structural Engineering Machine Learning,https://www.reddit.com/r/MachineLearning/comments/d86t92/structural_engineering_machine_learning/,Aussie-Pagan,1569246698,[removed],0,1,False,self,,,,,
1198,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,23,d870xi,developer.amazon.com,How to Construct the Optimal Neural Architecture for Your Machine Learning Task,https://www.reddit.com/r/MachineLearning/comments/d870xi/how_to_construct_the_optimal_neural_architecture/,georgecarlyle76,1569247722,,0,1,False,https://b.thumbs.redditmedia.com/nQ8A_UPmtsgiOyUI9b9b6ycKKCVL26f5Nxf-UrW5Zrs.jpg,,,,,
1199,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,23,d877g7,linkedin.com,"[D] It will take a lot more than ML tools to answer the research question, ""Where should I donate $2200 to save the most lives?""",https://www.reddit.com/r/MachineLearning/comments/d877g7/d_it_will_take_a_lot_more_than_ml_tools_to_answer/,OppositeMidnight,1569248594,,0,1,False,default,,,,,
1200,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,23,d878kg,developer.amazon.com,How to Construct the Optimal Neural Architecture for Your Machine Learning Task,https://www.reddit.com/r/MachineLearning/comments/d878kg/how_to_construct_the_optimal_neural_architecture/,georgecarlyle76,1569248753,,0,1,False,https://b.thumbs.redditmedia.com/nQ8A_UPmtsgiOyUI9b9b6ycKKCVL26f5Nxf-UrW5Zrs.jpg,,,,,
1201,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,23,d87c5f,medium.com,Interesting blog on attention models in seq2seq learning (let me know your views),https://www.reddit.com/r/MachineLearning/comments/d87c5f/interesting_blog_on_attention_models_in_seq2seq/,ray_matrix,1569249221,,0,1,False,default,,,,,
1202,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,23,d87ecg,i.redd.it,From r/memes,https://www.reddit.com/r/MachineLearning/comments/d87ecg/from_rmemes/,420__kush,1569249511,,0,1,False,https://b.thumbs.redditmedia.com/qXh7kLg74ince6_ZeEedqCMt97HSNVc2TSVmc0vR_3c.jpg,,,,,
1203,MachineLearning,t5_2r3gv,2019-9-23,2019,9,23,23,d87htm,self.MachineLearning,Transformer token limits,https://www.reddit.com/r/MachineLearning/comments/d87htm/transformer_token_limits/,fdelrio89,1569249964,[removed],0,1,False,self,,,,,
1204,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,0,d87u2d,self.MachineLearning,Poisson Regression - Find the sum of the residuals,https://www.reddit.com/r/MachineLearning/comments/d87u2d/poisson_regression_find_the_sum_of_the_residuals/,adityarj_pazuzu,1569251481,[removed],0,1,False,self,,,,,
1205,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,0,d87uco,github.com,Sqlflow - Brings SQL and ML together - Is it a future trend?,https://www.reddit.com/r/MachineLearning/comments/d87uco/sqlflow_brings_sql_and_ml_together_is_it_a_future/,liufu_ty,1569251518,,0,1,False,https://b.thumbs.redditmedia.com/AXNF_mq96GMkJKFVmZOWG_LPUz5uks9wRTAeZGr9pwg.jpg,,,,,
1206,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,0,d884yj,depthfirstlearning.com,[D] Neural ODEs Curriculum  Depth First Learning,https://www.reddit.com/r/MachineLearning/comments/d884yj/d_neural_odes_curriculum_depth_first_learning/,MetricSpade007,1569252847,,0,1,False,default,,,,,
1207,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,0,d885i4,depthfirstlearning.com,[D] Neural ODEs Curriculum  Depth First Learning,https://www.reddit.com/r/MachineLearning/comments/d885i4/d_neural_odes_curriculum_depth_first_learning/,suryabhupa,1569252909,,0,2,False,default,,,,,
1208,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,1,d88mxd,monkeylearn.com,Topic Analysis - A Comprehensive Guide to Detecting Topics from Text,https://www.reddit.com/r/MachineLearning/comments/d88mxd/topic_analysis_a_comprehensive_guide_to_detecting/,numbrow,1569255014,,0,1,False,https://b.thumbs.redditmedia.com/44PodvlwSbYwR4ixucJLXSiVCM8I9o2aQ50Aze7ocFs.jpg,,,,,
1209,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,1,d88pvy,aws.amazon.com,This is a free online event that has several AI and ML tracks; advanced sessions and deep dives for seasoned practitioners and a look at AWS DeepRacer,https://www.reddit.com/r/MachineLearning/comments/d88pvy/this_is_a_free_online_event_that_has_several_ai/,094459,1569255362,,0,1,False,https://a.thumbs.redditmedia.com/FRJfipidg4szebbBM_CLAd5Fbs7AgOFlfTBuHVLY938.jpg,,,,,
1210,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,2,d89ptk,ncbi.nlm.nih.gov,"Multiple Instance Learning, a machine learning method for classifying sets, finds cancer signatures in immune repertoires",https://www.reddit.com/r/MachineLearning/comments/d89ptk/multiple_instance_learning_a_machine_learning/,jostmey,1569259530,,0,1,False,default,,,,,
1211,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,2,d8a4zh,codinginfinite.com,My First Chatbot in Python using Flask,https://www.reddit.com/r/MachineLearning/comments/d8a4zh/my_first_chatbot_in_python_using_flask/,programming-nerd,1569261270,,0,1,False,https://b.thumbs.redditmedia.com/cI3p1UeRnVvNMm31Kuc6Gj7Lx-TOF46UlJcynBdccBU.jpg,,,,,
1212,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,3,d8ajjw,self.MachineLearning,How to combine multiple CNN branches,https://www.reddit.com/r/MachineLearning/comments/d8ajjw/how_to_combine_multiple_cnn_branches/,StellarStevens,1569262910,[removed],0,1,False,self,,,,,
1213,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,3,d8api0,ncbi.nlm.nih.gov,"[R] Multiple Instance Learning, a machine learning method for classifying sets, finds cancer signatures in immune repertoires",https://www.reddit.com/r/MachineLearning/comments/d8api0/r_multiple_instance_learning_a_machine_learning/,jostmey,1569263598,,0,1,False,https://b.thumbs.redditmedia.com/4o1Hw-TGReeOf2S0_T4p2L9uIwMVKqM8D90tKbGhjIM.jpg,,,,,
1214,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,3,d8aqq6,ncbi.nlm.nih.gov,"[R] Multiple instance learning, a machine learning method for classifying sequences, finds cancer signatures in immune repertoires, opening a new area of research",https://www.reddit.com/r/MachineLearning/comments/d8aqq6/r_multiple_instance_learning_a_machine_learning/,jostmey,1569263726,,0,1,False,https://b.thumbs.redditmedia.com/4o1Hw-TGReeOf2S0_T4p2L9uIwMVKqM8D90tKbGhjIM.jpg,,,,,
1215,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,3,d8as6x,medium.com,AI vs AI: FakeSpotter Studies Neurons to Bust DeepFakes,https://www.reddit.com/r/MachineLearning/comments/d8as6x/ai_vs_ai_fakespotter_studies_neurons_to_bust/,Yuqing7,1569263897,,0,1,False,https://a.thumbs.redditmedia.com/ApJoTWMFcp9SHaybcDHlZIS6ijDtXynG713ZKFlL104.jpg,,,,,
1216,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,3,d8avfs,self.MachineLearning,Sales prediction for restaurant,https://www.reddit.com/r/MachineLearning/comments/d8avfs/sales_prediction_for_restaurant/,namanjh2,1569264258,[removed],0,1,False,self,,,,,
1217,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,4,d8be2s,youtube.com,"Learning by Reasoning - Smart Cities - Hugo Latapie, Cisco Chief Technology and Architecture Office",https://www.reddit.com/r/MachineLearning/comments/d8be2s/learning_by_reasoning_smart_cities_hugo_latapie/,_w1kke_,1569266289,,0,1,False,https://b.thumbs.redditmedia.com/o6vRTlhVQZncN3CfznHgjKmMXQU1R0LjWDU4KfbzKDM.jpg,,,,,
1218,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,4,d8bf7z,self.MachineLearning,How would I modify a squared-exponential covariance kernel to be periodic?,https://www.reddit.com/r/MachineLearning/comments/d8bf7z/how_would_i_modify_a_squaredexponential/,Legit_Gold,1569266409,[removed],0,1,False,self,,,,,
1219,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,5,d8c8l3,medium.com,Transformer-Based Language Model Writes Abstracts For Scientific Papers,https://www.reddit.com/r/MachineLearning/comments/d8c8l3/transformerbased_language_model_writes_abstracts/,Yuqing7,1569269835,,0,1,False,default,,,,,
1220,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,5,d8cac9,self.MachineLearning,[D] Is there a way to introduce a rating system for an isolated game tournament that could produce better results than simple overall winning percentage?,https://www.reddit.com/r/MachineLearning/comments/d8cac9/d_is_there_a_way_to_introduce_a_rating_system_for/,HeIsMyPossum,1569270037,"Hello /r/machinelearning! Long time Redditor, first time posting here. I hope this isn't too weird of a question.

I'm not looking for someone to do this or anything, this is a conceptual question. It is: **Is there a way to introduce a rating system for an isolated game tournament that could produce better results than simple overall winning percentage?**

This idea came about because my dad's friends host a Euchre tournament every year. For those that don't know, Euchre is a 2v2 card game, and you play to 10 points.

Now this is a friendly tournament among friends, so it's not like a cut-throat competition. There are players there with a variety of skill levels.

Currently, you just sort of play all day with who is available, and you try not to play with the same person as your teammate all day (that way the two best players don't just team up all day and have a great record together). You only keep track of wins and losses. At the end of the day, the top 4 winning percentages go into a bracket for the title. We probably play around 20-30 games throughout the day, so the sample size is low.

There are numerous weaknesses to this method. I used to work for a Game Dev studio and really love game design, so it's a natural hobby of mine to assess the potential exploitation methods. Again, it's a friendly competition, so I don't believe anyone is actively practicing any of the below, but there absolutely are some ways that this method falls *very* flat.

**1.  There is an active incentive to stop when you're ahead.**

Towards the end of the day, if your winning percentage is high, you basically don't want to play games anymore. Winning will hardly move your winning percentage up, but a loss can tank your great percentage by a lot.

**2. You can absolutely game the system with partner selection and opponent avoidance**

If you play games with the people who you know are the best, and play against players who are known to be poor, you can dramatically affect your winning percentage. If a very poor player asks you to be their partner, especially if you go up against a strong team, you're at a huge disadvantage. If you keep playing these games, your odds aren't 50/50 to win, but probably more like 75/25 in worst or best case scenarios. This kind of manipulation is incentivized by the rule structure, and a player playing with truly random partners/opponents would be at a disadvantage.

**3. Scoring is completely ignored**

Losing by 10 or losing by 1 doesn't matter at all. This is a huge mechanical weakness in my view. If you get behind in a game, there's a good incentive to try to play aggressively to catch up, but if you come back from being down 7-0 and lose 10-9, you get no points whatsoever for making a great comeback. In the interest of time, it would likely be worth more to just lose the game quickly and start a new one.


--------------------------------

There are more criticisms at play here, but these are the main ones I could think of.

How could you go about designing a system that might help mitigate some of these factors? I thought about instituting an ELO-style (or glicko) rating system, but I'm not sure how it would play out given an internal tournament. We also wouldn't want legacy rankings because lower-ranked players would never make it far enough up the leaderboard to enter the finals.

Is there any sort of system that constantly re-evaluates all the permutations of games that have happened and spits out a ranking of sorts? Something that could actually take into account having a close loss when you have a weak teammate and strong opponents? It would basically take the entire tournament results as a whole, figure out all the rankings and decide on a top 4 players for the tournament.

Is this a concept that exists, or how could current practices apply here?",23,68,False,self,,,,,
1221,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,6,d8cxgt,self.MachineLearning,[P] CEFR Checker - an AI tool for adapting texts to language learners' CEFR levels,https://www.reddit.com/r/MachineLearning/comments/d8cxgt/p_cefr_checker_an_ai_tool_for_adapting_texts_to/,it-is-a-fork,1569272790,"Hi all, I'm a machine learning engineer at Duolingo, and I wanted to share a project I've been working on called CEFR Checker. It aligns text from many languages to a common language learning proficiency standard (the [CEFR](https://en.wikipedia.org/wiki/Common_European_Framework_of_Reference_for_Languages)) using an ordinal regression model trained over multilingual word embeddings and corpus word frequency estimates. We use this tool when we create Duolingo Podcasts and interactive Stories to help adapt the material to the appropriate CEFR level for beginner, intermediate or advanced learners.

Were sharing it publicly in case others find it useful as well.

The tool is completely free to use and you can [check it out here](https://cefr.duolingo.com/). 

Here's a [blog post](https://making.duolingo.com/the-duolingo-cefr-checker-an-ai-tool-for-adapting-learning-content) I wrote about the project if youd like more info.",10,91,False,self,,,,,
1222,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,6,d8cy91,cloud.google.com,Learning Machine Learning,https://www.reddit.com/r/MachineLearning/comments/d8cy91/learning_machine_learning/,tmpler,1569272897,,0,1,False,https://b.thumbs.redditmedia.com/fSfHaDXwivZyIDgzipGfKHj57k-ep4oa7Gp6KLprTUk.jpg,,,,,
1223,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,8,d8ej3f,self.MachineLearning,[D] Transformer number of token performance limits,https://www.reddit.com/r/MachineLearning/comments/d8ej3f/d_transformer_number_of_token_performance_limits/,fdelrio89,1569279928,"Hi,

I am currently working on a research project that involves using a transformer-like model for a NLP task. Specifically summarizing long documents.

I was wondering if any of you knows of a paper that explores the limits of the transformer when using super long sequences.

Is there any issue with long sequences?

Is there a ""length"" limit that this kind of model starts to decrease their performance?

Thanks a lot in advance!",4,2,False,self,,,,,
1224,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,8,d8el30,self.MachineLearning,Next steps for learning,https://www.reddit.com/r/MachineLearning/comments/d8el30/next_steps_for_learning/,gay_cereal,1569280204,[removed],0,1,False,self,,,,,
1225,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,8,d8en9b,self.MachineLearning,Where can I get updated with the progress of machine learning on last years?,https://www.reddit.com/r/MachineLearning/comments/d8en9b/where_can_i_get_updated_with_the_progress_of/,SrPeixinho,1569280551,[removed],0,1,False,self,,,,,
1226,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,11,d8gs8z,self.MachineLearning,[D] RunwayML (good/great/bad/ugly),https://www.reddit.com/r/MachineLearning/comments/d8gs8z/d_runwayml_goodgreatbadugly/,MLtinkerer,1569291203,"I'm involved in facial recognition and was wondering if anyone has tried runwayML?

Any thoughts? what's your experience been like? would love some honest review here (good/great/bad/ugly)

What tasks/application do you use runwayml for? would love to hear from all",4,5,False,self,,,,,
1227,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,12,d8hmd3,self.MachineLearning,Need Help with a Problem - Optimization,https://www.reddit.com/r/MachineLearning/comments/d8hmd3/need_help_with_a_problem_optimization/,techn0scho0lbus,1569295773,[removed],0,1,False,self,,,,,
1228,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,14,d8itfh,self.MachineLearning,State of AI/ML As-A-Service,https://www.reddit.com/r/MachineLearning/comments/d8itfh/state_of_aiml_asaservice/,swentso,1569303256,[removed],0,1,False,self,,,,,
1229,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,14,d8iy1c,self.MachineLearning,[P] Does this exist? An AI that reads a bibliography then recommends papers based on those present in the bibliography,https://www.reddit.com/r/MachineLearning/comments/d8iy1c/p_does_this_exist_an_ai_that_reads_a_bibliography/,NTGuardian,1569304125,I'm working on a paper and am currently conducting a literature review. I'm building up a bibliography file and I would like if there were an AI that could read the bibliography then recommend papers to add to that bibliography based on those it saw. I could easily envision websites such as Web of Science having such a system (they do not) so I'm just wondering if there is such a site.,9,2,False,self,,,,,
1230,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,14,d8j0u0,self.MachineLearning,How to put limitations of my work in paper?,https://www.reddit.com/r/MachineLearning/comments/d8j0u0/how_to_put_limitations_of_my_work_in_paper/,iAwaisRauf,1569304658,I need to put limitations of my work in the paper without making it seem too bad. Can anybody recommend me papers where authors use interesting ways to show the weaknesses of their work?,0,1,False,self,,,,,
1231,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,15,d8j54f,arxiv.org,"[R] MIMII Dataset: Sound Dataset for Malfunctioning Industrial Machine Investigation and Inspection. A 100gb audio collection containing sounds of malfunctioning mechanical equipment, recorded with an 8-channel microphone array.",https://www.reddit.com/r/MachineLearning/comments/d8j54f/r_mimii_dataset_sound_dataset_for_malfunctioning/,chisai_mikan,1569305485,,1,23,False,default,,,,,
1232,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,15,d8jb1l,self.MachineLearning,Is there a curated list of AI project I can test and interact with on the internet somewhere to have a broad idea of what the tech is capable of?,https://www.reddit.com/r/MachineLearning/comments/d8jb1l/is_there_a_curated_list_of_ai_project_i_can_test/,bodytexture,1569306646,[removed],0,1,False,self,,,,,
1233,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,15,d8jg1l,self.MachineLearning,How do I initialize the error covariance matrix in a Kalman filter?,https://www.reddit.com/r/MachineLearning/comments/d8jg1l/how_do_i_initialize_the_error_covariance_matrix/,Legit_Gold,1569307632,[removed],0,1,False,self,,,,,
1234,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,15,d8jheo,self.MachineLearning,[P] Natural Language Processing Roadmap and Keyword for students who are wondering what to study,https://www.reddit.com/r/MachineLearning/comments/d8jheo/p_natural_language_processing_roadmap_and_keyword/,nlkey2022,1569307888,"Hello.

I created summarized Natural Language Processing Roadmap in Github Repository with preparing NLP Engineer Interview to not forgetting which i had learned things. :D :D

It's contain in order Probability and Statistics, Machine Learning, Text Mining, Natural Language Processing.

It was very hard to make tree, sub-tree sctucture of mind map with abstract keywords, so Please focus on **KEYWORD in square box**, as things to study.

Also You can use the material commercially or freely, but please leave the source. Thanks!! 

https://i.redd.it/qradrhttnho31.png

&amp;#x200B;

*Processing img 9zdjvaavnho31...*

&amp;#x200B;

https://i.redd.it/ah8w7x8wnho31.png

&amp;#x200B;

https://i.redd.it/wv0sw8bxnho31.png

&amp;#x200B;

[https://github.com/graykode/nlp-roadmap](https://github.com/graykode/nlp-roadmap)",38,449,False,self,,,,,
1235,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,15,d8jjq6,self.MachineLearning,[D] State of Supervised ML,https://www.reddit.com/r/MachineLearning/comments/d8jjq6/d_state_of_supervised_ml/,swentso,1569308350,"Hi,

I've been recently away from the research landscape, so I'm not up to date to what's going on lately.

I know in 2017 the big hype was still Supervised Learning with bigger and bigger models. 

Is there anything that might predict upcoming breakthrough in unsupervised ML or simpler supervised models (few-shot/one-shot learning) ?  
   
What do you thing ML will look like in 5-10 years ?",2,0,False,self,,,,,
1236,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,16,d8jqm4,vixra.org,[R] The Neural Qubit (Siraj Raval),https://www.reddit.com/r/MachineLearning/comments/d8jqm4/r_the_neural_qubit_siraj_raval/,milaworld,1569309758,,0,1,False,default,,,,,
1237,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,17,d8k5n7,self.MachineLearning,Math for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/d8k5n7/math_for_machine_learning/,HannahHumphreys,1569312951,[removed],0,1,False,self,,,,,
1238,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,18,d8ksmc,self.MachineLearning,12 Statistical and Machine Learning Methods that Every Data Scientist Should Know,https://www.reddit.com/r/MachineLearning/comments/d8ksmc/12_statistical_and_machine_learning_methods_that/,andrea_manero,1569317698,[removed],0,1,False,self,,,,,
1239,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,18,d8kxhs,self.MachineLearning,Which Valve To Use For Adjust / Control Gas Flow ?,https://www.reddit.com/r/MachineLearning/comments/d8kxhs/which_valve_to_use_for_adjust_control_gas_flow/,uflowindia,1569318662,[removed],0,1,False,https://b.thumbs.redditmedia.com/12eDjolZWrQRZHgXAWiDM5LV7Tlmn5LdW098dhc9k-A.jpg,,,,,
1240,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,19,d8l74k,self.MachineLearning,[N] Very Cheap GPU Servers for ML / Deep Learning,https://www.reddit.com/r/MachineLearning/comments/d8l74k/n_very_cheap_gpu_servers_for_ml_deep_learning/,toplahm,1569320435," As [Toplahm](https://www.toplahm.com/), we provide high-performance single&amp;multi GPU cloud solutions for ML/DL. We're a new and passionate company and we have a special promotion for you to experience our service.

* **2 x Tesla P100**, Dual Xeon E5-2609v4 8C:8T, 64 GB RAM, 960 GB SSD - **$299 /week, $1149 /month**
* **2 x** **GTX1080Ti,**  E5-2670 8C:16T 2.6/3.3 GHz, 32 GB RAM, 500 GB SSD, 2 TB HDD - **$109 /week, $399 /month**
* **2 x GTX1080**, Intel i5-7500 4C:4T, 32 GB RAM, 500GB SSD - **$85 /week, $249 /month**
* **GTX1080**, Intel G4600 2C:4T, 12 GB RAM, 120GB SSD - **$109 /month**

*Promotion expires on Sep 29* and *is available for only 1 server in each type (FCFS).*

\* All servers have **1 Gbps** connection. **99.95% uptime**. All are **dedicated** (no virtualization), GPUs are plugged on motherboard (no risers) with 16 or 8 PCIe lanes. 

\*\* Servers come with Nvidia drivers and CUDA runtime pre-installed.

\*\*\* *Nvidia driver EULA poses no threat for us, nor for our customers. Just to give an example, Nvidia's EULA states "" ... is not licensed for datacenter deployment, except that blockchain processing in a datacenter is permitted."" And blockchain processing is permitted in our data center, as stated* [*here*](https://www.toplahm.com/long-term-discounts.html)*. Therefore it's legal. However, concerned customers can still opt for an Nvidia driver released before the prohibition to be absolutely safe.*

[see all our GPU servers](https://toplahm.com/gpu-dedicated-servers.html)

Toplahm Cloud Services [Contact](https://toplahm.com/contact.html) | [Service Terms](https://www.toplahm.com/terms-and-conditions.html) | [Security](https://www.toplahm.com/security.html)",2,2,False,self,,,,,
1241,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,19,d8l7ko,youtu.be,Why Bad Data Ruins Projects and How to Fix it,https://www.reddit.com/r/MachineLearning/comments/d8l7ko/why_bad_data_ruins_projects_and_how_to_fix_it/,mto96,1569320524,,1,1,False,https://b.thumbs.redditmedia.com/6G_aflYAaAZCSv8oYzQte10rzQzAr5wNt4pjahI9Rtc.jpg,,,,,
1242,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,19,d8l8yj,self.MachineLearning,Machine Vision Market Is Projected To Reach $18.24 Billion By 2025,https://www.reddit.com/r/MachineLearning/comments/d8l8yj/machine_vision_market_is_projected_to_reach_1824/,adamhurdle023,1569320799,[removed],0,1,False,self,,,,,
1243,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,20,d8lneg,self.MachineLearning,BatchNormalization is not a norm!,https://www.reddit.com/r/MachineLearning/comments/d8lneg/batchnormalization_is_not_a_norm/,prateeksworld,1569323421,[removed],0,1,False,self,,,,,
1244,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,20,d8lo03,thenextweb.com,This AI reads privacy policy..so that you don't have to!,https://www.reddit.com/r/MachineLearning/comments/d8lo03/this_ai_reads_privacy_policyso_that_you_dont_have/,viky_boy,1569323534,,0,1,False,https://a.thumbs.redditmedia.com/uJoYAkf1kmN98qCHGu9a_TbEsfF0jhXt7NZMdPLdJO4.jpg,,,,,
1245,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,20,d8lq6i,self.MachineLearning,Methods to perform unsupervised similarity scoring,https://www.reddit.com/r/MachineLearning/comments/d8lq6i/methods_to_perform_unsupervised_similarity_scoring/,SupervisedHelloWorld,1569323916,[removed],0,1,False,self,,,,,
1246,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,20,d8lvdh,self.MachineLearning,[D] Methods to perform unsupervised similarity scoring,https://www.reddit.com/r/MachineLearning/comments/d8lvdh/d_methods_to_perform_unsupervised_similarity/,SupervisedHelloWorld,1569324799,"I have a task and I don't know how to tackle this. I received a set of positives and I have to find similar points from a big dataset (that I call *basket*). I have around 1'000 positives and around 1'000'000 points in the basket. All points are represented with 10 to 15 features. As an output, I would like to have a score for each point of the basket and this score would represent the closeness of the point to the positive set.

I first thought of using a *k-nearest neighbours* method on the positives but this approach presents two big drawbacks for me. First, I wouldn't have a score associated to each point of the basket as I would only have a set of close points for each positive. Secondly, and this is the biggest drawback in my opinion, I would have to define the distance in the n-dimensional space myself while I would prefer that the method directly defines weights for each feature on the data (for instance, based on the level of information (variance) contained in each feature).

Does someone could point out to me a good approach to tackle this problem?

Thanks!",6,1,False,self,,,,,
1247,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,20,d8lx0t,medium.com,Highlights of RecSys 2019 : latest progress on recommendation systems,https://www.reddit.com/r/MachineLearning/comments/d8lx0t/highlights_of_recsys_2019_latest_progress_on/,rom1504,1569325051,,0,1,False,default,,,,,
1248,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,21,d8m9r0,medium.com,8 Tips To Ease Your Switch In AI Career,https://www.reddit.com/r/MachineLearning/comments/d8m9r0/8_tips_to_ease_your_switch_in_ai_career/,ariaareeds02,1569327071,,0,1,False,default,,,,,
1249,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,21,d8mfaz,self.MachineLearning,Image clustering/classification,https://www.reddit.com/r/MachineLearning/comments/d8mfaz/image_clusteringclassification/,matchstick515,1569327913,[removed],0,1,False,self,,,,,
1250,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,21,d8mgqb,codersera.com,5 Types of Machine Learning Algorithms You Should Know,https://www.reddit.com/r/MachineLearning/comments/d8mgqb/5_types_of_machine_learning_algorithms_you_should/,NicholasL86,1569328113,,0,1,False,default,,,,,
1251,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,22,d8mvy1,youtu.be,Complementing Cows with Machine Learning,https://www.reddit.com/r/MachineLearning/comments/d8mvy1/complementing_cows_with_machine_learning/,chriskok1337,1569330171,,0,1,False,https://b.thumbs.redditmedia.com/Sqy02869l5j4nbW8OIJrCk4Q2XKWfwN4POJKq0-BFPE.jpg,,,,,
1252,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,22,d8navf,self.MachineLearning,Click sequence model help,https://www.reddit.com/r/MachineLearning/comments/d8navf/click_sequence_model_help/,urban_sanje,1569332198,[removed],0,1,False,self,,,,,
1253,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,22,d8ne0y,youtu.be,5 Smart Ideas with DC Motor,https://www.reddit.com/r/MachineLearning/comments/d8ne0y/5_smart_ideas_with_dc_motor/,Excrement1234,1569332608,,0,1,False,default,,,,,
1254,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,23,d8nlqf,self.MachineLearning,[N] Udacity had an interventional meeting with Siraj Raval on content theft for his AI course,https://www.reddit.com/r/MachineLearning/comments/d8nlqf/n_udacity_had_an_interventional_meeting_with/,Better_Leg,1569333664,"&amp;#x200B;

According to Udacity insiders Mat Leonard @MatDrinksTea and Michael Wales @walesmd:

&amp;#x200B;

https://i.redd.it/yr5yg453tjo31.png

[https://twitter.com/MatDrinksTea/status/1175481042448211968](https://twitter.com/MatDrinksTea/status/1175481042448211968)

&gt;Siraj has a habit of stealing content and other peoples work. That he is allegedly scamming these students does not surprise me one bit. I hope people in the ML community stop working with him.

[https://twitter.com/walesmd/status/1176268937098596352](https://twitter.com/walesmd/status/1176268937098596352)

&gt;Oh no, not when working with us. We literally had an intervention meeting, involving multiple Directors, including myself, to explain to you how non-attribution was bad. Even the Director of Video Production was involved, it was so blatant that non-tech pointed it out.  
&gt;  
&gt;If I remember correctly, in the same meeting we also had to explain why Pepe memes were not appropriate in an educational context.  This was right around the time we told you there was absolutely no way your editing was happening and we required our own team to approve.  
&gt;  
&gt;And then we also decided, internally, as soon as the contract ended; @MatDrinksTea would be redoing everything.",233,520,False,https://b.thumbs.redditmedia.com/3qM0O20X8exnKf1eFwO8w0Tl3eXtetiwqNtqUKtwTZI.jpg,,,,,
1255,MachineLearning,t5_2r3gv,2019-9-24,2019,9,24,23,d8o0xj,self.MachineLearning,"[P] I want to optimize a Mechanical Structure with Machine Learning, need some help for the beginning.",https://www.reddit.com/r/MachineLearning/comments/d8o0xj/p_i_want_to_optimize_a_mechanical_structure_with/,avdalim,1569335571,"Hello,

so for I have project I need to get done for University, in which I make a program, which skips Iteration steps for the Optimization of Mechanical Structures.

The Mechanical Structure is defined as follows:

You have nodes (in 3-D or 2-D) which are fully connected by beams. The Starting point is, that all beams have the same density and there are Loads, which are on some of the Nodes. Also there is an upper and lower bound for the densities of these beams (which is relevant for the conventional method)

In the Normal Process the density of the beams is tweaked Iteration by Iteration, depending on the different loads on the nodes to make the structure stiffer, also there is a certain volume fraction of the design space, which the sum of the beams has to reach.

Now I need to make a Neural Network which is capable of skipping Iterations, which are computationally expensive and I wanted to ask how I should start it.

The first file I received has 3x10 (2-D) Nodes and 373 design variables (beams).

This is how it looks:

[https://imgur.com/8p7jctT](https://imgur.com/8p7jctT)

After Optimization:

[https://imgur.com/VwumM5w](https://imgur.com/VwumM5w)

I don't know what type of network I should use, since I'm not experienced in doing my own projects.

My first ideas were:

1. Neural network, which takes the beams and the loads (in coordinates) as features encodes them and decodes them. 
2. Same as 1. , but with the nodes as Features
3. CNN Encoder Decoder Network, with a matrix of NxN, N being the Nodes and the entries in the Matrix being the beams, which connect the nodes, then the other channels are the loads on the node, the colume fraction and maybe the different x,y and for 3-D z values of the node.

The university can generate the data needed for training the Neural Network (Different Loads and all the iterations of the different optimizations) and the target are 3-D structures with thousands of beams. Right now we are starting of easy with 2-D structures, but I don't know how many beams option 1. and 2. can handle, before dimensionality becomes a problem.

I'm not a big expert in the field, but I read a lot of material on NNs and ML (e.g.  Aurelien Geron Hands on machine learning) and I am eager to make this project work, but I need a little bit of help in starting off, so I would be really grateful, if some of you guys could help me with that :)",25,5,False,self,,,,,
1256,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,0,d8ozsa,medium.com,Amazon ML Director Begins DeepMind Professorship at Cambridge,https://www.reddit.com/r/MachineLearning/comments/d8ozsa/amazon_ml_director_begins_deepmind_professorship/,Yuqing7,1569339914,,0,1,False,https://b.thumbs.redditmedia.com/2zR-CuNpnUCCZGrtj9LW1-viDhsDWruOBFkdw83g81A.jpg,,,,,
1257,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,1,d8ply7,heartbeat.fritz.ai,Amazon Textract  Going beyond optical character recognition (OCR),https://www.reddit.com/r/MachineLearning/comments/d8ply7/amazon_textract_going_beyond_optical_character/,zsajjad,1569342611,,0,1,False,https://a.thumbs.redditmedia.com/Stz-kvSRmx5m_3M7NCyeSIlYTBtoOE_SGI8l0Au72j8.jpg,,,,,
1258,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,1,d8pvn4,self.MachineLearning,[D] Genetic Training on CIFAR-100,https://www.reddit.com/r/MachineLearning/comments/d8pvn4/d_genetic_training_on_cifar100/,ToolTechSoftware,1569343769,"Must share something great !

Working with Genetic Learning as replacement for back propagation and just made a complex convolution network for a CIFAR-100 dataset with 100 classes and it started training immediately. No backprop

Training in progress and no stop at 10% so I guess its working. Will be fun to see where how good it will be but anyway. Its training ! Its giving results...",18,0,False,self,,,,,
1259,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,2,d8q3a8,self.MachineLearning,[P] Create daily summary from .json file to pandas dataframe in python,https://www.reddit.com/r/MachineLearning/comments/d8q3a8/p_create_daily_summary_from_json_file_to_pandas/,WiseAfro27,1569344671,"So Im creating a weather forecast for a project and I need to analyze some historical data from a .json file. I want to create a list of daily summaries with the values from each dates. The .json layout looks like this: 

{""city_id"":3160606,""main"":{""temp"":285.88,""temp_min"":284.26,""temp_max"":288.15,""pressure"":1015,""humidity"":79},""wind"":{""speed"":1,""deg"":166},""rain"":{""3h"":0.025},""clouds"":{""all"":80},""weather"":[{""id"":803,""main"":""Clouds"",""description"":""broken clouds"",""icon"":""04n""}],""dt"":1474588800,""dt_iso"":""2016-09-23 00:00:00 +0000 UTC""},{""city_id"":3160606,""main"":{""temp"":285.34,""temp_min"":284.26,""temp_max"":287.04,""pressure"":1015,""humidity"":82},""wind"":{""speed"":1,""deg"":166},""rain"":{""3h"":0.025},""clouds"":{""all"":80},""weather"":[{""id"":803,""main"":""Clouds"",""description"":""broken clouds"",""icon"":""04n""}],""dt"":1474592400,""dt_iso"":""2016-09-23 01:00:00 +0000 UTC""},

 Any help on how I can get data from every specific day sorted in a good way?",1,0,False,self,,,,,
1260,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,2,d8qcwc,self.MachineLearning,[R] Google released dataset for Deepfakes Detection Research,https://www.reddit.com/r/MachineLearning/comments/d8qcwc/r_google_released_dataset_for_deepfakes_detection/,PuzzledProgrammer3,1569345807,"blog: [https://ai.googleblog.com/2019/09/contributing-data-to-deepfake-detection.html](https://ai.googleblog.com/2019/09/contributing-data-to-deepfake-detection.html)

also a few shot approach for generating deepfakes: [https://github.com/shaoanlu/fewshot-face-translation-GAN](https://github.com/shaoanlu/fewshot-face-translation-GAN)",8,4,False,self,,,,,
1261,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,2,d8qgp7,i.redd.it,Siraj bad,https://www.reddit.com/r/MachineLearning/comments/d8qgp7/siraj_bad/,mosef18,1569346278,,0,1,False,https://a.thumbs.redditmedia.com/znnuPAvRj7Qinvmg2aleifTsVFEPNGgbqR2dNWhwFg0.jpg,,,,,
1262,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,2,d8qin9,self.MachineLearning,SOTA Speech recognition/transcription,https://www.reddit.com/r/MachineLearning/comments/d8qin9/sota_speech_recognitiontranscription/,iocuydi,1569346497,[removed],0,1,False,self,,,,,
1263,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,3,d8r1zh,self.MachineLearning,Siraj bad,https://www.reddit.com/r/MachineLearning/comments/d8r1zh/siraj_bad/,mosef18,1569348840,[removed],0,1,False,self,,,,,
1264,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,3,d8r6rd,self.MachineLearning,[D] Siraj bad,https://www.reddit.com/r/MachineLearning/comments/d8r6rd/d_siraj_bad/,mosef18,1569349442,"&amp;#x200B;

https://i.redd.it/woz392wo3lo31.png",0,1,False,https://b.thumbs.redditmedia.com/gPmeDVT_ba_OaPs5R8r_2U1ntwYEs0dP8a5UXNbKcuc.jpg,,,,,
1265,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,3,d8rc33,i.redd.it,[D] siraj bad,https://www.reddit.com/r/MachineLearning/comments/d8rc33/d_siraj_bad/,mosef18,1569350102,,0,1,False,https://a.thumbs.redditmedia.com/CtDwKrMeZVm5mYrDLyU7dusAPvyouf0IodIypk1n4d4.jpg,,,,,
1266,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,4,d8rpwm,self.MachineLearning,Research Topic on Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/d8rpwm/research_topic_on_deep_reinforcement_learning/,vivaxDC,1569351784,I am starting my thesis for my undergraduate. I am willing to do my thesis on Deep Reinforcement Learning. I have read some of the research papers on this area. Currently which topics are better to do thesis?,0,1,False,self,,,,,
1267,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,4,d8rre5,self.MachineLearning,NeurIPS lottery and workshop posters,https://www.reddit.com/r/MachineLearning/comments/d8rre5/neurips_lottery_and_workshop_posters/,neurips2019throwaway,1569351955,"I was pretty happy to hear that my work was accepted to a workshop at NeurIPS this year, as my first major research project you can imagine how happy I was to be selected.  However it looks like this particular workshop has no reserved tickets, and they are relying on their accepted authors to participate in the lottery to attend. Is this normal? Its super disappointing to receive an email that says Congratulations! you *might* get to attend and display your work... Good luck!

Any thoughts on this? I was very happy, but now I'm kind of worried...",0,1,False,self,,,,,
1268,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,4,d8ruqg,youtu.be,Machine learning introduction,https://www.reddit.com/r/MachineLearning/comments/d8ruqg/machine_learning_introduction/,gopirockz,1569352325,,0,1,False,default,,,,,
1269,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,4,d8s477,self.MachineLearning,"[D] What search terms have you used when looking up ML papers, either on Arxiv, Arxiv-Sanity, Google Scholar, Semantic Scholar, etc? I'm trying to make a model for searching through ML papers, and I am looking for test cases for the model.",https://www.reddit.com/r/MachineLearning/comments/d8s477/d_what_search_terms_have_you_used_when_looking_up/,BatmantoshReturns,1569353455,"I am training a model for searching through research papers, and I would love to test it out to see how well it does on queries from real users. 

I would check to see if the results from the top search engines people use for looking up ML papers are also included in the model.",6,4,False,self,,,,,
1270,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,4,d8sap3,i.redd.it,[D] siraj bad,https://www.reddit.com/r/MachineLearning/comments/d8sap3/d_siraj_bad/,mosef18,1569354219,,0,1,False,default,,,,,
1271,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,4,d8sfp1,self.MachineLearning,[D] Siraj bad,https://www.reddit.com/r/MachineLearning/comments/d8sfp1/d_siraj_bad/,mosef18,1569354821,"&amp;#x200B;

https://i.redd.it/k38r4nm2klo31.png",0,0,False,https://b.thumbs.redditmedia.com/EOc1lFEoRUQEYPGzIXc9jyxDDh2lr4KVqggV1OL1tjs.jpg,,,,,
1272,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,4,d8shut,self.MachineLearning,[D][N] New Google Langauge Model?,https://www.reddit.com/r/MachineLearning/comments/d8shut/dn_new_google_langauge_model/,zerghunter,1569355083,"The top of the SQuAD 2.0 leaderboard shows a new model from the Google Language Team called ALBERT. Based on the name, it seems to be an extension of BERT. It looks like a significant improvement on SOTA, but I can't find anything about it online. Maybe a model soon to be released?

 [https://rajpurkar.github.io/SQuAD-explorer/](https://rajpurkar.github.io/SQuAD-explorer/)",8,27,False,self,,,,,
1273,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,5,d8taf0,self.MachineLearning,[D] SOTA Speech recognition/transcription,https://www.reddit.com/r/MachineLearning/comments/d8taf0/d_sota_speech_recognitiontranscription/,iocuydi,1569358477," I'm working on a project with a speech transcription component. I tried using AWS and Azure speech recognition services and they are shockingly inaccurate. Can anyone recommend something better? Or is this just not possible yet.

What I tried:

[https://azure.microsoft.com/en-us/services/cognitive-services/speech-to-text/](https://azure.microsoft.com/en-us/services/cognitive-services/speech-to-text/)

[https://aws.amazon.com/transcribe/](https://aws.amazon.com/transcribe/)

Thanks!",7,2,False,self,,,,,
1274,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,6,d8u131,self.MachineLearning,A basic machine learning program in Java,https://www.reddit.com/r/MachineLearning/comments/d8u131/a_basic_machine_learning_program_in_java/,BrendanCS,1569361774,[removed],0,1,False,self,,,,,
1275,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,7,d8unkf,medium.com,Researchers Use Vile Comments from Trump Subreddit to Train AI to Battle Hate Speech,https://www.reddit.com/r/MachineLearning/comments/d8unkf/researchers_use_vile_comments_from_trump/,Yuqing7,1569364695,,0,0,False,https://b.thumbs.redditmedia.com/yYpWr3QiqJNRSGPNZIlwQX_OitayWppGOdAdllyK8ao.jpg,,,,,
1276,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,8,d8vaf2,youtube.com,[D][P] Tutorial: Cloning your voice using Microsoft Azure's Cognitive Services,https://www.reddit.com/r/MachineLearning/comments/d8vaf2/dp_tutorial_cloning_your_voice_using_microsoft/,seekingomega,1569367789,,0,1,False,https://b.thumbs.redditmedia.com/dQvAHGrXhGkfBsoF0wpMTRYcYNwWbtw8J50ZRVEIROE.jpg,,,,,
1277,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,11,d8wy7h,self.MachineLearning,Testing for bottlenecks in training,https://www.reddit.com/r/MachineLearning/comments/d8wy7h/testing_for_bottlenecks_in_training/,shomerj,1569377526,[removed],0,1,False,self,,,,,
1278,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,11,d8x7al,losangeleno.com,What Machine Learning Taught the Band YACHT About Themselves,https://www.reddit.com/r/MachineLearning/comments/d8x7al/what_machine_learning_taught_the_band_yacht_about/,busblog,1569379075,,0,1,False,default,,,,,
1279,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,11,d8xejd,self.MachineLearning,What Are The Benefits Of Using Neural Networks For Solving PDEs?,https://www.reddit.com/r/MachineLearning/comments/d8xejd/what_are_the_benefits_of_using_neural_networks/,thelolzmaster,1569380303,[removed],0,1,False,self,,,,,
1280,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,12,d8xl0y,self.MachineLearning,"#MachineLearningAlgo MCD Short !! 69.57%, SEP19 WK2  =&gt; MCD dipped from.. 220.03 to.. 209.81",https://www.reddit.com/r/MachineLearning/comments/d8xl0y/machinelearningalgo_mcd_short_6957_sep19_wk2_mcd/,SignalClubIo,1569381291,[removed],1,1,False,https://b.thumbs.redditmedia.com/b98jmfuFS9C_rjxr9g446VxZ0GOgmY4OfCYGJ871NAM.jpg,,,,,
1281,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,13,d8ylde,self.MachineLearning,Using a neural network to predict output probabilities,https://www.reddit.com/r/MachineLearning/comments/d8ylde/using_a_neural_network_to_predict_output/,adm1970,1569387373,[removed],0,1,False,self,,,,,
1282,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,14,d8yqip,self.MachineLearning,Representing and Training Individualized Models,https://www.reddit.com/r/MachineLearning/comments/d8yqip/representing_and_training_individualized_models/,vroomwaddle,1569388268,[removed],0,1,False,self,,,,,
1283,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,14,d8yu57,arxiv.org,[R] Learning deep representations for video-based intake gesture detection,https://www.reddit.com/r/MachineLearning/comments/d8yu57/r_learning_deep_representations_for_videobased/,pr0u,1569388893,,2,1,False,default,,,,,
1284,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,14,d8yxdt,countants.com,How Business Intelligence can benefit your sales and marketing,https://www.reddit.com/r/MachineLearning/comments/d8yxdt/how_business_intelligence_can_benefit_your_sales/,Countants123,1569389493,,0,1,False,https://b.thumbs.redditmedia.com/BzbnTa4Vscc0whNaNylsldMeBaCdmp_AFefg4ILbcoM.jpg,,,,,
1285,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,14,d8z494,arxiv.org,[R] Why Does Hierarchy (Sometimes) Work So Well in Reinforcement Learning?,https://www.reddit.com/r/MachineLearning/comments/d8z494/r_why_does_hierarchy_sometimes_work_so_well_in/,hardmaru,1569390734,,3,9,False,default,,,,,
1286,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,15,d8z7iq,self.MachineLearning,"Hey guys, whats mean BRUH?",https://www.reddit.com/r/MachineLearning/comments/d8z7iq/hey_guys_whats_mean_bruh/,Sir-Nibba,1569391350,[removed],1,1,False,self,,,,,
1287,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,15,d8zec5,onlineitguru.com,How Facebook Uses Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/d8zec5/how_facebook_uses_machine_learning/,iamtechwriter,1569392653,,0,1,False,default,,,,,
1288,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,16,d8zymx,datafloq.com,Importance of data science &amp; machine learning algorithms benefits,https://www.reddit.com/r/MachineLearning/comments/d8zymx/importance_of_data_science_machine_learning/,nexcorp,1569396716,,0,1,False,default,,,,,
1289,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,17,d90dwn,youtube.com,About The Forgotten Strength of Evolutionary Learning,https://www.reddit.com/r/MachineLearning/comments/d90dwn/about_the_forgotten_strength_of_evolutionary/,Mesode,1569400038,,0,1,False,https://b.thumbs.redditmedia.com/79x44_oL-NLJdiBnS3jzbWpEvRjEbxF2RjoQxLWYZkU.jpg,,,,,
1290,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,17,d90f8w,self.MachineLearning,[D] What is the DeepMind for Google interview process like?,https://www.reddit.com/r/MachineLearning/comments/d90f8w/d_what_is_the_deepmind_for_google_interview/,ThisIsMySeudonym,1569400367,"For Research Engineers. I see lots of interviewing details shared for *DeepMind*, but none for *DeepMind for Google (DMG).* It seems that DMG is pretty independent and their interview process is different than regular DeepMind. Any tips or details anyone can share?",76,213,False,self,,,,,
1291,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,17,d90gy6,self.MachineLearning,[D] Has Google Colab become stable enough to use?,https://www.reddit.com/r/MachineLearning/comments/d90gy6/d_has_google_colab_become_stable_enough_to_use/,RavlaAlvar,1569400750,"I played for a bit a while go; it was extremely unstable and would crash randomly.

&amp;#x200B;

Has any one tried it recently? Is it usable enough for anyone to an extend, for example, training a YOLO network on the COCO dataset?",8,3,False,self,,,,,
1292,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,18,d90u0o,self.MachineLearning,Imobie-macclean Review and Free Download,https://www.reddit.com/r/MachineLearning/comments/d90u0o/imobiemacclean_review_and_free_download/,christy_18,1569403547,[removed],0,1,False,self,,,,,
1293,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,18,d90u9p,self.MachineLearning,Data Science Bootcamp: Pay only after you get a data science job.,https://www.reddit.com/r/MachineLearning/comments/d90u9p/data_science_bootcamp_pay_only_after_you_get_a/,HannahHumphreys,1569403604,[removed],0,1,False,self,,,,,
1294,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,18,d90ygg,self.MachineLearning,Mathematics for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/d90ygg/mathematics_for_machine_learning/,HannahHumphreys,1569404482,[removed],0,1,False,self,,,,,
1295,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,19,d91450,i.redd.it,How Businesses Can Benefit From Machine Learning,https://www.reddit.com/r/MachineLearning/comments/d91450/how_businesses_can_benefit_from_machine_learning/,smithrobert36,1569405634,,0,1,False,https://a.thumbs.redditmedia.com/T-yNghHVLeCAxTgqQgXfFdojSSaSm8ekYdCsT12e3j8.jpg,,,,,
1296,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,19,d91e60,self.MachineLearning,"Which Valve Is Useful For Food Industries, Pharmaceuticals, Chemical applications &amp; Highly corrosive environment?",https://www.reddit.com/r/MachineLearning/comments/d91e60/which_valve_is_useful_for_food_industries/,uflowindia,1569407538,[removed],0,1,False,https://b.thumbs.redditmedia.com/d-bAADKFlpGrslJZiwB-j8bfoObeEYBZ8X1uGgVLH-k.jpg,,,,,
1297,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,19,d91gyn,/r/MachineLearning/comments/d91gyn/free_opensource_online_image_labelling_tool/,Free Opensource Online Image Labelling Tool,https://www.reddit.com/r/MachineLearning/comments/d91gyn/free_opensource_online_image_labelling_tool/,RandomForests92,1569408018,,1,1,False,https://a.thumbs.redditmedia.com/WTZDm2IJyTv5xrwuXnb-0-rxthQ7wRTP5WkPYkG2ol4.jpg,,,,,
1298,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,20,d926ae,arangodb.com,ArangoML Pipeline  A Common Metadata Layer for Machine Learning Pipelines - ArangoDB,https://www.reddit.com/r/MachineLearning/comments/d926ae/arangoml_pipeline_a_common_metadata_layer_for/,grmpf101,1569412315,,0,1,False,https://a.thumbs.redditmedia.com/YMCYdlcl06HSAwqIq6hQscfni_XEhfX39H_l8CYkzG8.jpg,,,,,
1299,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,21,d92hm7,self.MachineLearning,[D] Learning Chinese for Chinese ML and DL,https://www.reddit.com/r/MachineLearning/comments/d92hm7/d_learning_chinese_for_chinese_ml_and_dl/,emissaryo,1569414035,"Hello!
I've heard a lot about China trying to become a leader in machine learning and AI in general. A lot of research papers comes from China, a lot of Chinese scientists contribute to research in other countries. I often get Chinese articles when I google some question related to ML, although I live in Eastern Europe. I also saw a few articles about learning Chinese for ML and DL.
So I begin to wonder, is it worth learning Chinese to advance in ML more quickly, get more info and maybe read untranslated Chinese research papers? 
What do you think about this? Did anyone learn Chinese for similar purpose - to have more opportunities to learn about new ML techniques etc. - and what was the outcome?",10,0,False,self,,,,,
1300,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,21,d92iaz,self.artificial,Research groups in Strategic AI for Games and Pathfinding,https://www.reddit.com/r/MachineLearning/comments/d92iaz/research_groups_in_strategic_ai_for_games_and/,Internal_Mark,1569414142,,0,1,False,default,,,,,
1301,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,21,d92jgl,self.MachineLearning,ENPF and Machine Learning - Match?,https://www.reddit.com/r/MachineLearning/comments/d92jgl/enpf_and_machine_learning_match/,Halliekkh,1569414322,[removed],0,1,False,self,,,,,
1302,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,21,d92ln5,self.MachineLearning,5 Types of Machine Learning Algorithms You Should Know,https://www.reddit.com/r/MachineLearning/comments/d92ln5/5_types_of_machine_learning_algorithms_you_should/,Jonwalterc46,1569414652,[removed],0,1,False,self,,,,,
1303,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,21,d92q2j,self.MachineLearning,[R] 5 Types of Machine Learning Algorithms You Should Know,https://www.reddit.com/r/MachineLearning/comments/d92q2j/r_5_types_of_machine_learning_algorithms_you/,Jonwalterc46,1569415303,"We all are living in a period of DEVELOPING. *According to Eric Schmidt*  Machine Learning is the future of technology. It is the major component of [**Artificial Intelligence**](https://codersera.com/blog/ai-bots-must-have-for-bussiness-in-2019/). So, is it true that machine learning influences the performance of the business?

All your questions and doubts are answered in this article, you find three types of machine learning that useful to your business and the top 5 types of Machine learning Algorithms to make yourself more familiar with the concept of ML.

## Introduction to Machine Learning

No doubt, machine learning has become a diverse business tool to enhance the numerous elements of business operations. Machine learning- it is the method of data analysis which automates the analytical model. As well as it is a branch of artificial intelligence based on the idea that the system can learn from data, identify the pattern and make decisions with minimal human interference.

**Machine learning (ML)** is the scientific study of algorithms and statistical models that the computer system used to perform a specific task without using explicit instructions, replying on pattern and inference instead. It is also a subset of artificial intelligence. *-via Wikipedia*

If youre a beginner, machine learning can be confusing for you how to choose which algorithms to use, from the apparently limitless options, and how to know which one will provide the right predictions (data outputs). The machine learning is a way for computers to run various algorithms without direct human oversight in order to learn from data.

Machine learning can include a variety of tasks in order for the machine to determine a high-probability result for different information, such as the functions between input and output or the hidden structures in unlabeled data.

So, just before starting with **Machine learning algorithms**, lets have a look at types of Machine learning which clarify these algorithms.

For more details, you can see this ref link:-   [https://codersera.com/blog/5-types-of-machine-learning-algorithms-you-should-know/](https://codersera.com/blog/5-types-of-machine-learning-algorithms-you-should-know/)",1,0,False,self,,,,,
1304,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,22,d934c1,self.MachineLearning,Looking for a new platform / software ... to work!,https://www.reddit.com/r/MachineLearning/comments/d934c1/looking_for_a_new_platform_software_to_work/,JoseChovi,1569417278,[removed],0,1,False,self,,,,,
1305,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,22,d93a21,self.MachineLearning,Research Guide for Depth Estimation with Deep Learning,https://www.reddit.com/r/MachineLearning/comments/d93a21/research_guide_for_depth_estimation_with_deep/,mwitiderrick,1569418043,[removed],0,1,False,self,,,,,
1306,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,23,d9445p,medium.com,Climate Classification Using Landscape Images,https://www.reddit.com/r/MachineLearning/comments/d9445p/climate_classification_using_landscape_images/,CometML,1569421989,,0,1,False,default,,,,,
1307,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,23,d945wt,self.MachineLearning,Why sampling boosted the performance of my model?,https://www.reddit.com/r/MachineLearning/comments/d945wt/why_sampling_boosted_the_performance_of_my_model/,Capn_Sparrow0404,1569422199,[removed],0,1,False,self,,,,,
1308,MachineLearning,t5_2r3gv,2019-9-25,2019,9,25,23,d94fpe,self.MachineLearning,Why Least Squares instead of Absolute Value,https://www.reddit.com/r/MachineLearning/comments/d94fpe/why_least_squares_instead_of_absolute_value/,CeramicVulture,1569423459,[removed],0,1,False,self,,,,,
1309,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,0,d94knm,techfunnel.com,The Best Chatbot Framework to Build Powerful Bots,https://www.reddit.com/r/MachineLearning/comments/d94knm/the_best_chatbot_framework_to_build_powerful_bots/,veronica_blogs,1569424029,,0,1,False,default,,,,,
1310,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,0,d94luq,activewizards.com,Top 12 Data Science Use Cases in Government | ActiveWizards: data science and engineering lab,https://www.reddit.com/r/MachineLearning/comments/d94luq/top_12_data_science_use_cases_in_government/,techgig11,1569424164,,0,8,False,default,,,,,
1311,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,0,d94rgk,self.MachineLearning,[R],https://www.reddit.com/r/MachineLearning/comments/d94rgk/r/,emke_es,1569424837,"Hey guys,

For the last couple of months I've been working on a new generative model for point clouds during my AI Residency in [Tooploox](https://www.tooploox.com/), Poland. I wanted to share with you an animation of interpolation in the latent space between some objects as a short teaser.

You can read more about Residency program and some basics of the project in my blog post: [https://bit.ly/2lIIAwC](https://bit.ly/2lIIAwC).

We also launched second edition of AI Residency in Warsaw. If you are interested, you can apply [here](https://bit.ly/2l4zSZl) (deadline will be extended).

![video](760qd7fl8ro31)",0,1,False,self,,,,,
1312,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,0,d950bn,self.QuantumComputing,a Quantum Perceptron - first steps in qML,https://www.reddit.com/r/MachineLearning/comments/d950bn/a_quantum_perceptron_first_steps_in_qml/,joaquinkeller,1569425912,,0,1,False,https://a.thumbs.redditmedia.com/ra3kBnWZu_3K6DhwisbjQqwCTsdygzZ1HF2XxETnVN4.jpg,,,,,
1313,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,0,d9534g,self.MachineLearning,[R] Point-level generative model for point clouds,https://www.reddit.com/r/MachineLearning/comments/d9534g/r_pointlevel_generative_model_for_point_clouds/,emke_es,1569426247,"Hey guys,

For the last couple of months I've been working on a new generative model for point clouds during my AI Residency in [Tooploox](https://www.tooploox.com/), Poland. I wanted to share with you an animation of interpolation in the latent space between some objects as a short teaser.

You can read more about Residency program and some basics of the project in my blog post: [https://bit.ly/2lIIAwC](https://bit.ly/2lIIAwC).

We also launched second edition of AI Residency in Warsaw. If you are interested, you can apply [here](https://bit.ly/2l4zSZl) (deadline will be extended).

&amp;#x200B;

![video](jbn9wx3xcro31)",0,1,False,self,,,,,
1314,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,0,d957mr,self.MachineLearning,"Simple Questions Thread September 25, 2019",https://www.reddit.com/r/MachineLearning/comments/d957mr/simple_questions_thread_september_25_2019/,AutoModerator,1569426831,[removed],0,1,False,self,,,,,
1315,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,0,d95965,self.BigDataLDN,Cambridge Analytica whistleblower Chris Wylie to headline Big Data LDN 2019 Keynote Programme,https://www.reddit.com/r/MachineLearning/comments/d95965/cambridge_analytica_whistleblower_chris_wylie_to/,BigDataLDN,1569427028,,0,1,False,https://b.thumbs.redditmedia.com/dnq-w7owv5NWZuDN9gLJXIvxixq7OVBlB7y9gVAJung.jpg,,,,,
1316,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,1,d95g8x,i.redd.it,Almost ready to fire up - 4x TITAN RTX water cooled workstation for DL,https://www.reddit.com/r/MachineLearning/comments/d95g8x/almost_ready_to_fire_up_4x_titan_rtx_water_cooled/,gimel1213,1569427827,,0,1,False,default,,,,,
1317,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,1,d95mfx,self.MachineLearning,help with implementing custom loss on the integral of outputs (keras),https://www.reddit.com/r/MachineLearning/comments/d95mfx/help_with_implementing_custom_loss_on_the/,progmayo,1569428562,[removed],0,1,False,https://b.thumbs.redditmedia.com/xwk8ty8tNjB0XunxSu9ggN7h3OFyaOyEo4UZn0-NETo.jpg,,,,,
1318,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,1,d95pli,self.MachineLearning,[P] A Quantum Perceptron - First Steps in qML,https://www.reddit.com/r/MachineLearning/comments/d95pli/p_a_quantum_perceptron_first_steps_in_qml/,joaquinkeller,1569428929,"An interactive demo showing how quantum machine learning works on a simple case

[https://qml.entropicalabs.io/](https://qml.entropicalabs.io/)

[https://www.reddit.com/r/QuantumComputing/comments/d93v8l/a\_quantum\_perceptron\_first\_steps\_in\_qml/](https://www.reddit.com/r/QuantumComputing/comments/d93v8l/a_quantum_perceptron_first_steps_in_qml/?utm_source=share&amp;utm_medium=web2x)

https://i.redd.it/yfa0k4j5oro31.png",4,5,False,https://b.thumbs.redditmedia.com/U8KCr2GIGTGFpSOyUcQdKhUoFbSc46hR39kKNOZPh6s.jpg,,,,,
1319,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,1,d95sxq,arxiv.org,"Overton: a system to design ML pipelines, from Apple",https://www.reddit.com/r/MachineLearning/comments/d95sxq/overton_a_system_to_design_ml_pipelines_from_apple/,Cock-tail,1569429324,,0,1,False,default,,,,,
1320,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,1,d95ta7,self.MachineLearning,"I want to build a model that can predict outcomes of soccer games, is there any non-obvious data points that I should consider?",https://www.reddit.com/r/MachineLearning/comments/d95ta7/i_want_to_build_a_model_that_can_predict_outcomes/,el_petit_prince,1569429358,[removed],0,1,False,self,,,,,
1321,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,1,d95tqe,arxiv.org,Overton: A detailed look at Apple's ML pipeline architecture,https://www.reddit.com/r/MachineLearning/comments/d95tqe/overton_a_detailed_look_at_apples_ml_pipeline/,Cock-tail,1569429415,,1,1,False,default,,,,,
1322,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,1,d95u97,arxiv.org,[R] Overton: A detailed look at Apple's ML pipeline architecture,https://www.reddit.com/r/MachineLearning/comments/d95u97/r_overton_a_detailed_look_at_apples_ml_pipeline/,Cock-tail,1569429479,,1,5,False,default,,,,,
1323,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,1,d95v3c,medium.com,Alibabas New AI Chip Can Process Nearly 80K Images Per Second,https://www.reddit.com/r/MachineLearning/comments/d95v3c/alibabas_new_ai_chip_can_process_nearly_80k/,Yuqing7,1569429571,,0,1,False,https://b.thumbs.redditmedia.com/NwxWVtbRYy4_sPBYe2TS7CzCLqPVNiavqav0r8rZwfI.jpg,,,,,
1324,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,1,d962jc,self.MachineLearning,"AMA: I'm Dr. Genevive Patterson - cofounder and Chief Scientist at TRASH, a new app that uses computer vision and computational photography to intelligently edit together and set to music any videos you upload. Ask me anything!",https://www.reddit.com/r/MachineLearning/comments/d962jc/ama_im_dr_genevive_patterson_cofounder_and_chief/,TrashPHD,1569430457,[removed],0,3,False,self,,,,,
1325,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,2,d968tm,self.MachineLearning,[P] My journey with Flow Generative Models and AI Residency in Poland,https://www.reddit.com/r/MachineLearning/comments/d968tm/p_my_journey_with_flow_generative_models_and_ai/,emke_es,1569431201,"Hi guys,

I wanted to show you piece of a project I've been working on during my AI Residency in [Tooploox](https://www.tooploox.com/). It is an adaptation of flow-based models to point cloud generation. Our work is based on the *Real NVP (*[https://arxiv.org/abs/1605.08803](https://arxiv.org/abs/1605.08803)).

One of the pros of our model is that we are able to obtain representation of point clouds which we can freely interpolate. Check out [this video](https://imgur.com/a/ZFf4vMx) for visual.

In the [blog post](https://www.tooploox.com/blog/ai-residency-in-a-nutshell) I wrote about basic concept of the project and my European AI Residency Experience.

We will be releasing paper on arXiv with code soon. Feel free to ask any questions.

Micha",2,33,False,self,,,,,
1326,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,2,d96g06,arxiv.org,[R] Improving Collaborative Metric Learning with Efficient Negative Sampling,https://www.reddit.com/r/MachineLearning/comments/d96g06/r_improving_collaborative_metric_learning_with/,i-like-big-gans,1569432074,,1,7,False,default,,,,,
1327,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,2,d96kp8,self.MachineLearning,[D] How to generate photorealistic images from face-sketches using GAN?,https://www.reddit.com/r/MachineLearning/comments/d96kp8/d_how_to_generate_photorealistic_images_from/,vijaykarthi24,1569432628,[removed],0,1,False,self,,,,,
1328,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,2,d96xr5,self.MachineLearning,Interview Question - Projecting a Covariance from a Linear to Non-Linear space?,https://www.reddit.com/r/MachineLearning/comments/d96xr5/interview_question_projecting_a_covariance_from_a/,soulslicer0,1569434199,[removed],0,1,False,self,,,,,
1329,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,3,d97mod,self.MachineLearning,[D] Fuel Accelerator (feedback requested),https://www.reddit.com/r/MachineLearning/comments/d97mod/d_fuel_accelerator_feedback_requested/,jaronhog,1569437160,"Hello all, I am new to this Group.
Mods- please delete if this isnt acceptable. 

I am facilitating year two, of the State of Arkansas growth stage tech startup accelerator program, dubbed *Fuel*.
[Fuel Accelerator](https://www.fuelaccelerator.com)


**A few highlights for everyone (feedback and questions welcome!):**

+12-weeks (Tue-Thu); 
Jan-May in Bentonville, Arkansas
_*Travel, Meals, ans Lodging (not currently included)_

+**1-on-1 mentorships** with the areas largest Enterprise players (i.e. _Walmart, Tyson Foods, JB Hunt Transportation, University of Arkansas, Walton Family Foundation, Simmons Pet Food, WinRock/Heifer International_ are all headquartered in NW Arkansas).

+Dedicated mentorships- beyond a few working sessions and office hours. An ability to directly partner and scalably generate revenue. 

+Youll be working out of **The Exchange** office in downtown Bentonville (Walmart-owner) with a dynamic itinerary thats fully catered towards matchmaking and partnership, to advance your purpose. 

+Focused on **AI/ML technology**. However, this field is broad enough to encompass a lot of industries and applications. 

+**No equity exchange. The Fuel program is 100% free (less expenses)**

+Weekly CEO Roundtables with successful start-up founders, including: Revunit, Startup Junkie, Slims Chicken, Onyx Coffee Labs

+**Demo Day will include VCs and wealthy investors from across the Midwest, too.**
_piggybacking off this event:_
[Heartland Summit](https://heartlandsummit-attendeehub.splashthat.com)

**Additional Links:**

[About Northwest Arkansas](https://findingnwa.com/areas-of-interest/living-in-northwest-arkansas/)

[Arkansas Ag Profile](https://division.uaex.edu/docs/2017%20AR%20Ag%20profile.pdf)

Top 10 Producer (USA) in: rice, timber, eggs, broilers (chicken) soybean, catfish, cotton.

[Gov. Hutchinson AEDC Press Conference](https://youtu.be/wNvrZ8zV9F4)",10,0,False,self,,,,,
1330,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,3,d97n0a,self.MachineLearning,"[D] AMA: I'm Dr. Genevieve Patterson - cofounder and Chief Scientist at TRASH, a new app that uses computer vision and computational photography to intelligently edit together and set to music any videos you upload. Ask me anything!",https://www.reddit.com/r/MachineLearning/comments/d97n0a/d_ama_im_dr_genevieve_patterson_cofounder_and/,TrashPHD,1569437200,"Hi all!

My name is Genevieve Patterson - Im the Chief Scientist at [TRASH](https://trash.app/), and a PhD in Computer Vision. I've been working on our AI, Otto, for over a year now, and it's getting smarter with every release - here is a [blog post](https://medium.com/@thetrashapp/your-wish-is-our-command-a0be25de6fe3) about our latest version, and how it collaborates with user inputs. Otto is powered by supervised and unsupervised video attention, our internal active learning labeled social media video dataset, attribute and action recognition in video, custom multi-media embedding spaces, set-to-sequence conditional generator networks, and a suite of video retargeting techniques recently popularized in the computational video manipulation community. Otto trained in PyTorch and deployed on iOS using Core ML.

My work is about creating dialog between AI and people. An initial description of Otto was accepted to the ICLR 2019 Debugging Machine Learning Workshop  ""[Building Models for Mobile Video Understanding](https://debug-ml-iclr2019.github.io/cameraready/DebugML-19_paper_33.pdf). Besides working at TRASH, I recently collaborated on a human + ML humor project, ""[Humor in Word Embeddings: Cockamamie Gobbledegook for Nincompoops](https://arxiv.org/abs/1902.02783), ICML 2019. Please feel free to ask about anything Ive worked on before ([Google Scholar page](https://scholar.google.com/citations?user=OogER9cAAAAJ&amp;hl=en&amp;oi=ao)).

Before TRASH, I was Postdoctoral Researcher at Microsoft Research New England.  I received my PhD from Brown University in 2016. Ive published at and still review for CVPR, ICCV/ECCV, NeurIPS, CHI, HCOMP, and other CV and ML venues.

I would be more than happy to answer any questions about CV and ML, computational photography, the TRASH app, how to finish a PhD, publishing in these fields, or anything about my own path.

Opening this thread for your questions now, and will be here through Friday, September 27th answering them.

&amp;#x200B;

https://i.redd.it/5rnp64p0dso31.jpg

Thanks, and I look forward to your questions!

Genevieve Patterson

[https://genp.github.io/](https://genp.github.io/)",91,216,False,https://b.thumbs.redditmedia.com/nG_FeFbeiLyyZnHDXrS1tPIFSbaLZoGb5vm9W4GI7rA.jpg,,,,,
1331,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,3,d97ou5,self.MachineLearning,[D] How to handle noisy training labels in supervised learning?,https://www.reddit.com/r/MachineLearning/comments/d97ou5/d_how_to_handle_noisy_training_labels_in/,ProjectPsygma,1569437407,"Neural networks are notorious for being very data-hungry. Acquiring large datasets with clean labels is often difficult as manual annotation is expensive and time-consuming. This trade-off between the quantity and quality of data is an problem that seems to repeatedly come up in applied machine learning.

What are some ways a machine learning practitioner can better deal with this problem?",7,14,False,self,,,,,
1332,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,3,d97qgm,self.MachineLearning,Step Activation function...why does it work?!,https://www.reddit.com/r/MachineLearning/comments/d97qgm/step_activation_functionwhy_does_it_work/,phillylovesdata,1569437605,[removed],0,1,False,self,,,,,
1333,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,4,d9829o,i.redd.it,Made a dystopian concept art using SPADE on RunwayML,https://www.reddit.com/r/MachineLearning/comments/d9829o/made_a_dystopian_concept_art_using_spade_on/,jojophoenix455,1569438965,,0,1,False,default,,,,,
1334,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,4,d98acc,self.MachineLearning,[D] Tensorflow GPU C API performance in C++,https://www.reddit.com/r/MachineLearning/comments/d98acc/d_tensorflow_gpu_c_api_performance_in_c/,WalkingAFI,1569439944,"I recently wrote a wrapper for the Tensorflow GPU C API to run in a C++ project Im working on. Since the library is in C, it cant throw, and the only STL function I call is std::vectors push back. Based on Herb Sutters recent talk, I thought, hey, I might as well make this function noexcept. Much to my surprise, the function (which took 40ms to run my CNN before) sped up to running in 19ms. Can anyone help me speculate why its that big of a performance difference? (Using Visual Studio 19, C++17, default optimization options)",6,4,False,self,,,,,
1335,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,4,d98asj,medium.com,Whats Cooking? Google VideoBERT Predicts Recipes,https://www.reddit.com/r/MachineLearning/comments/d98asj/whats_cooking_google_videobert_predicts_recipes/,Yuqing7,1569439997,,0,1,False,https://b.thumbs.redditmedia.com/hb6ZeuW3p71Myw8wghUQkxMXwcdXAYXKEqhYO4p4J2Y.jpg,,,,,
1336,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,6,d9a61x,self.MachineLearning,"[Discussion] Wait for a unified company ML platform, and loose at least a year, if not more, before the project moves forward, or go with our own readily available tools, but incur a ton of technical debt in the process?",https://www.reddit.com/r/MachineLearning/comments/d9a61x/discussion_wait_for_a_unified_company_ml_platform/,AlexSnakeKing,1569448411,"I work for a large company, with a centralized data science org, as well as several teams which are using or plan to use some machine learning or statistical modeling. The tools right now are disparate, but very little of it is in production, so it doesn't matter that much. 

(Some) Leaders are pushing for a unified ML platform to be used by all teams, and it will either be something built in house on top of AWS, or some sort of off the shelf tool like Databricks, or H2O, or what not. Based on the current level of discussion, the organization is at least a year out from now. We can wait for it, but we will essentially twiddle our fingers for a good part of our projects while waiting. 

We have a project which is moving forward pretty fast, and we could just go ahead and build it using AzureML studio, with is what my team's engineers are the most familiar with. But if the rest of the company gets their act together and eventually comes up with a unified ML platform, we will be completely out of synch with them, and we end up with a ton of technical debt. 

&amp;#x200B;

Does anybody have experience with this dilemma? How do you keep your ability to move quickly with your own project, while still conforming to the company's overall unified ML platform?",5,1,False,self,,,,,
1337,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,7,d9aoxu,self.MachineLearning,[N] To Fight Deepfakes Google Released Deepfakes Dataset,https://www.reddit.com/r/MachineLearning/comments/d9aoxu/n_to_fight_deepfakes_google_released_deepfakes/,DavidJAntifacebook,1569451174,[removed],0,1,False,self,,,,,
1338,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,8,d9awqw,self.MachineLearning,[D] What are the current major problems and limitations that face Machine Learning and Deep Learning in particular?,https://www.reddit.com/r/MachineLearning/comments/d9awqw/d_what_are_the_current_major_problems_and/,mohd_sst,1569452454,"Im almost a graduate student and looking forward to start thinking about the problems I want to tackle next in these fields.

I searched the r/MachineLearning subreddit for this discussion and I only found a discussion on an article related to computer vision. If this discussion already exists please link it to me so I could delete this post.",3,0,False,self,,,,,
1339,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,8,d9b0iy,arxiv.org,[R] An Empirical Exploration of Deep Recurrent Connections and Memory Cells Using Neuro-Evolution,https://www.reddit.com/r/MachineLearning/comments/d9b0iy/r_an_empirical_exploration_of_deep_recurrent/,Vystril,1569452768,,2,6,False,default,,,,,
1340,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,8,d9b9ja,i.redd.it,[Discussion] Boston Dynamics has gone farther than ever before!,https://www.reddit.com/r/MachineLearning/comments/d9b9ja/discussion_boston_dynamics_has_gone_farther_than/,sellerofcomics,1569453870,,0,1,False,https://b.thumbs.redditmedia.com/j_Sgk1i63oqgICQXFI4a6xezWjDL9B2faYL7ReWusPA.jpg,,,,,
1341,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,8,d9bbsn,omdena.com,AI Challenge to Detect Forest Fires in Brazil in Real Time - Applications open,https://www.reddit.com/r/MachineLearning/comments/d9bbsn/ai_challenge_to_detect_forest_fires_in_brazil_in/,Lordobba,1569454167,,0,1,False,default,,,,,
1342,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,8,d9bmjb,youtube.com,[P] Image Classifier,https://www.reddit.com/r/MachineLearning/comments/d9bmjb/p_image_classifier/,lookingforjob6969,1569455651,,1,1,False,default,,,,,
1343,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,8,d9bnpc,youtu.be,Installing Keras and Tensorflow,https://www.reddit.com/r/MachineLearning/comments/d9bnpc/installing_keras_and_tensorflow/,gopirockz,1569455820,,0,1,False,default,,,,,
1344,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,11,d9d970,self.MachineLearning,Real-Time Edge inference question,https://www.reddit.com/r/MachineLearning/comments/d9d970/realtime_edge_inference_question/,Freepiehere,1569463988,"I'm embedding a ML model onto an edge device for real-time anomaly detection and I'm struggling with a few concepts.   
The model accepts data at some frequency from a 9-axis IMU and I would like it to perform a classification inference on each data point it receives. 

Intuitively I would like to implement an RNN of some variation due to the time-dependent nature of the data. But I trained the model in keras where the model accepts input for N data points and makes a prediction at the end of the batch-length, and I don't know how I would implement it on a point to point basis.

Another idea would be to just implement a CNN to perform inference on an updating sliding window, but that wouldn't have the persistence of previously observed data that I'm looking for in the model.

I know I'm misunderstanding something fundamental. I'm pretty new to working on edge devices.  
Does anyone know where I'm going wrong / have any ideas about how I should proceed? I'd appreciate the advice.",0,1,False,self,,,,,
1345,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,11,d9dk7l,blkma.com,beading machine suppliers,https://www.reddit.com/r/MachineLearning/comments/d9dk7l/beading_machine_suppliers/,A15249897759,1569465580,,0,1,False,default,,,,,
1346,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,12,d9dw59,blkma.com,CNC angle steel flange production line,https://www.reddit.com/r/MachineLearning/comments/d9dw59/cnc_angle_steel_flange_production_line/,A15249897759,1569467383,,0,1,False,default,,,,,
1347,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,12,d9e0wo,blkma.com,hydraulic riveting machine manufacturers,https://www.reddit.com/r/MachineLearning/comments/d9e0wo/hydraulic_riveting_machine_manufacturers/,A15249897759,1569468126,,0,1,False,default,,,,,
1348,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,12,d9e5rd,blkma.com,Reel Shear Beading Machine,https://www.reddit.com/r/MachineLearning/comments/d9e5rd/reel_shear_beading_machine/,A15249897759,1569468884,,0,1,False,default,,,,,
1349,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,12,d9eb76,practicalai.me,Deep Learning with Electronic Health Record (EHR) Systems,https://www.reddit.com/r/MachineLearning/comments/d9eb76/deep_learning_with_electronic_health_record_ehr/,practicalai,1569469762,,1,1,False,https://a.thumbs.redditmedia.com/RWGpyIkv7kpjkNzgSGZ7Lg0mKtjBQ8krbo194XTXFK0.jpg,,,,,
1350,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,13,d9emqm,kumarujjawal.github.io,Seq2Seq Learning with Neural Networks Paper: In an easy to digest manner [R],https://www.reddit.com/r/MachineLearning/comments/d9emqm/seq2seq_learning_with_neural_networks_paper_in_an/,i_amujjawal,1569471649,,0,1,False,default,,,,,
1351,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,14,d9fbuo,self.MachineLearning,[d] What do you think about BigQuery ML,https://www.reddit.com/r/MachineLearning/comments/d9fbuo/d_what_do_you_think_about_bigquery_ml/,eeldwin,1569476067,"Hi there, 

I'm quite newbie in Machine Learning area. I learnt machine learning 10 years ago, it's so hard. I just moved my company data warehouse to BigQuery and got some promotion related BigQuery ML. It's look really easy to build model, training, and evaluation. 

What's the difference between BigQuery ML and other ML out there?",0,0,False,self,,,,,
1352,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,15,d9fli6,blkma.com,spiral duct machine manufacturers,https://www.reddit.com/r/MachineLearning/comments/d9fli6/spiral_duct_machine_manufacturers/,A15249897759,1569477882,,0,1,False,default,,,,,
1353,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,15,d9fo30,self.MachineLearning,Using different GPUs on same machine,https://www.reddit.com/r/MachineLearning/comments/d9fo30/using_different_gpus_on_same_machine/,mnitin73,1569478382,[removed],0,1,False,self,,,,,
1354,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,15,d9fzxi,cogitotech.com,Bounding Box Annotation,https://www.reddit.com/r/MachineLearning/comments/d9fzxi/bounding_box_annotation/,cogitotechllc,1569480668,,0,1,False,https://b.thumbs.redditmedia.com/VqHlNi2uXqwPG1GJl3vCtdhrNAaMTiWsy-9h6TrOojk.jpg,,,,,
1355,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,16,d9g8gx,self.MachineLearning,Top 30 Companies in India to Work For in Data Science and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/d9g8gx/top_30_companies_in_india_to_work_for_in_data/,kaushalseo1,1569482372,[removed],0,1,False,self,,,,,
1356,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,16,d9g9hx,datafloq.com,Understand your machine learning data using python,https://www.reddit.com/r/MachineLearning/comments/d9g9hx/understand_your_machine_learning_data_using_python/,nexcorp,1569482572,,0,1,False,default,,,,,
1357,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,16,d9gce3,data-flair.training,Machine Learning - The Game Changer for Entrepreneurs!,https://www.reddit.com/r/MachineLearning/comments/d9gce3/machine_learning_the_game_changer_for/,AnujG23,1569483182,,0,0,False,https://b.thumbs.redditmedia.com/9IaftzYFR_J0EmAqhDzuXMOWwn9bYASPTw_YQRkKxns.jpg,,,,,
1358,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,17,d9goja,self.MachineLearning,Community Machine Learning Platform,https://www.reddit.com/r/MachineLearning/comments/d9goja/community_machine_learning_platform/,zonkosoft,1569485818,[removed],0,1,False,self,,,,,
1359,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,17,d9gtb2,arxiv.org,[R] High Fidelity Speech Synthesis with Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/d9gtb2/r_high_fidelity_speech_synthesis_with_adversarial/,hardmaru,1569486879,,14,79,False,default,,,,,
1360,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,17,d9gw8y,self.MachineLearning,Which Valve Does Not Affected By Voltage Surges?,https://www.reddit.com/r/MachineLearning/comments/d9gw8y/which_valve_does_not_affected_by_voltage_surges/,uflowindia,1569487563,[removed],0,1,False,https://b.thumbs.redditmedia.com/Pk4R5zoE6u2XH__ZJSXAS7t839XBq-sV9keNE2V_6OM.jpg,,,,,
1361,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,18,d9h7is,self.MachineLearning,"How to ""help"" the world with machine learning?",https://www.reddit.com/r/MachineLearning/comments/d9h7is/how_to_help_the_world_with_machine_learning/,mlboi137,1569489926,[removed],0,1,False,self,,,,,
1362,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,18,d9hbg1,smarten.com,Data Visualization Software For Your Users!,https://www.reddit.com/r/MachineLearning/comments/d9hbg1/data_visualization_software_for_your_users/,ElegantMicroWebIndia,1569490733,,0,1,False,default,,,,,
1363,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,18,d9hdoi,self.MachineLearning,Why do second-order Newton based processes dominate the geophysical inverse processing field?,https://www.reddit.com/r/MachineLearning/comments/d9hdoi/why_do_secondorder_newton_based_processes/,tfwADCin2k17,1569491200,[removed],0,1,False,self,,,,,
1364,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,18,d9he5t,arxiv.org,[R] Low-Memory Neural Network Training: A Technical Report,https://www.reddit.com/r/MachineLearning/comments/d9he5t/r_lowmemory_neural_network_training_a_technical/,hardmaru,1569491292,,2,15,False,default,,,,,
1365,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,19,d9hmca,self.MachineLearning,Google beats the records in NLP,https://www.reddit.com/r/MachineLearning/comments/d9hmca/google_beats_the_records_in_nlp/,BeatriceCarraro,1569492839,"An interesting approach on what is language model and why is Google investing so much in Natural Language Processing research. [I recommend giving it a read here](https://www.botxo.co/blog/google-xlnet/)

Snippet:

&gt;The idea of passing information from one neural network to another has been around for a long time and has been used to understand images for many years.    
&gt;  
&gt;In January 2018, a language model called [ULMfit](https://www.aclweb.org/anthology/P18-1031) showed that this technique also worked very well for text. Soon after, another language model called[GPT](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf) improved this idea by using a more advanced kind of neural network called a Transformer neural network.  
&gt;  
&gt;Then, a language model called [BERT](https://arxiv.org/pdf/1810.04805.pdf) became even better by not just guessing the next word in a sentence, but also works in the middle of sentences, such as guessing that X is spaghetti in the sentence I eat X with meatballs. 

When will computers learn to understand us? What do you think will happen in the future?",0,1,False,self,,,,,
1366,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,19,d9hns6,self.MachineLearning,[P] Community Machine Learning Platform,https://www.reddit.com/r/MachineLearning/comments/d9hns6/p_community_machine_learning_platform/,zonkosoft,1569493112,"Hi everyone!

I am wondering what people think of an idea, which I'm looking to turn into reality: A community centred Machine Learning platform!

Ideas:

Main page: Similar to Reddit where people can post their projects, research, questions and requests.

Projects: People can form long term groups to share code bases, road maps, problems and tasks. Projects might be centred around a research area, a project at work (companies can work together), or something you are making for fun. People can request to be part of projects, so if you spot something you want to be involved in you can join, and if you need help you can ask people to join.

Modules: People can upload Docker containers, these will have a standard API, anyone one can run these. Modules might be an algorithm, model or a utility tool. These can be attatched to projects, and you can browse a library of modules sorted in categories (BioInformatics, Computer Vision, NLP etc) . You can optionally charge for the use of modules you make?

The main goal is to create a collaborative environment, so companies, researchers, and anyone! can show off what they are doing, find people with similar interests, share ideas, problems and build things together.

Questions:

Is this reinventing the wheel, is Kaggle + Reddit + Github etc good enough?

Are there things you would like to see made?

Do you have any more ideas, and would you like to get involved?

Do you have a complaint?

Thanks :-)

From Tom",5,1,False,self,,,,,
1367,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,19,d9hwc7,self.MachineLearning,Machine Learning with Python Interview Questions and Answers,https://www.reddit.com/r/MachineLearning/comments/d9hwc7/machine_learning_with_python_interview_questions/,naveenssdn23,1569494721,[removed],0,1,False,self,,,,,
1368,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,19,d9i0lb,self.MachineLearning,Sound Mimmick - Machine Learning Synthesizers,https://www.reddit.com/r/MachineLearning/comments/d9i0lb/sound_mimmick_machine_learning_synthesizers/,GrassberryHigh,1569495495,[removed],0,1,False,self,,,,,
1369,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,20,d9i6bj,self.MachineLearning,[D] Self-citation issue,https://www.reddit.com/r/MachineLearning/comments/d9i6bj/d_selfcitation_issue/,TreeNetworks,1569496452,"I just stumbled upon a paper [https://openreview.net/forum?id=HylxE1HKwS](https://openreview.net/forum?id=HylxE1HKwS) / [https://arxiv.org/abs/1908.09791](https://arxiv.org/abs/1908.09791) with quite an interesting idea of training a single deep network that can be deployed at many efficiency configurations. But, what's more ""interesting"" is the amount of self-citations in the paper. Seven of the cited publications had the third author's name (which I assume is the PI). I feel that it is excessive. Correct me if I'm wrong. And the fact that this paper is heavily self-citing but isn't acknowledging existing research that pursued similar direction (e.g., AuxNet, BranchyNet, IDK Cascades, Stochastic Downsampling, Anytime Neural Networks) is worrying.

What do you think of the self-citation trend (if there's any at all) in machine learning research?",8,5,False,self,,,,,
1370,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,20,d9ide9,self.MachineLearning,Looking for someone who deployed machine learning to solve the multi-armed bandit problem in marketing campaigns.,https://www.reddit.com/r/MachineLearning/comments/d9ide9/looking_for_someone_who_deployed_machine_learning/,rufenmatt,1569497635,[removed],0,1,False,self,,,,,
1371,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,21,d9jay4,thetechnologyheadlines.com,Decoding Data Science: Machine Learning,https://www.reddit.com/r/MachineLearning/comments/d9jay4/decoding_data_science_machine_learning/,vish_007,1569502768,,0,1,False,https://b.thumbs.redditmedia.com/hDfckwLi54-pQYDoOQKbzimQvPYzQWanE8zerUKWxrA.jpg,,,,,
1372,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,22,d9jew4,springpeople.com,Top 10 Machine Learning Algorithms,https://www.reddit.com/r/MachineLearning/comments/d9jew4/top_10_machine_learning_algorithms/,raghasundar1990,1569503307,,0,1,False,default,,,,,
1373,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,22,d9jidd,self.MachineLearning,"[N] HuggingFace releases Transformers 2.0, a library for state-of-the-art NLP in TensorFlow 2.0 and PyTorch",https://www.reddit.com/r/MachineLearning/comments/d9jidd/n_huggingface_releases_transformers_20_a_library/,Thomjazz,1569503800,"HuggingFace has just released Transformers 2.0, a library for Natural Language Processing in TensorFlow 2.0 and PyTorch which provides state-of-the-art pretrained models in most recent NLP architectures (BERT, GPT-2, XLNet, RoBERTa, DistilBert, XLM...) comprising several multi-lingual models.

An interesting feature is that the library provides deep interoperability between TensorFlow 2.0 and PyTorch.

You can move a full model seamlessly from one framework to the other during its lifetime (instead of just exporting a static computation graph at the end like with ONNX). This way it's possible to get the best of both worlds by selecting the best framework for each step of training, evaluation, production, e.g. train on TPUs before finetuning/testing in PyTorch and finally deploy with TF-X.

An [example in the readme](https://github.com/huggingface/transformers#quick-tour-tf-20-training-and-pytorch-interoperability) shows how Bert can be finetuned on GLUE in a few lines of code with the high-level API `tf.keras.Model.fit()` and then loaded in PyTorch for quick and easy inspection and debugging.

As TensorFlow and PyTorch as getting closer, this kind of deep interoperability between both frameworks could become a new norm for multi-backends libraries.

Repo: [https://github.com/huggingface/transformers](https://github.com/huggingface/transformers)",31,430,False,self,,,,,
1374,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,22,d9jmp6,springpeople.com,Python Machine Learning Training | Machine Learning Corporate Training | SpringPeople,https://www.reddit.com/r/MachineLearning/comments/d9jmp6/python_machine_learning_training_machine_learning/,raghasundar1990,1569504409,,0,1,False,default,,,,,
1375,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,22,d9juru,incoutlook.com,What all you need to know about statistics for Data science?,https://www.reddit.com/r/MachineLearning/comments/d9juru/what_all_you_need_to_know_about_statistics_for/,INC_Outlook,1569505570,,0,1,False,default,,,,,
1376,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,23,d9k5b4,eno8.com,TensorFlow tops list of favored machine learning programming languages,https://www.reddit.com/r/MachineLearning/comments/d9k5b4/tensorflow_tops_list_of_favored_machine_learning/,jacelyn1122,1569506977,,0,1,False,default,,,,,
1377,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,23,d9k5iu,self.MachineLearning,[D] XGBoost Notes,https://www.reddit.com/r/MachineLearning/comments/d9k5iu/d_xgboost_notes/,_kty,1569507004,"Hi all,

I was studying the XGBoost paper a couple of weeks ago and I took quite some notes. These notes are not the basic kind but involve step by step derivation of the mathematical functions. I could not find a complete and this detailed study of the paper so I wanted to share. Please comment below if you see any mistake. Any feedback or comment is welcome.

Link: [https://drive.google.com/file/d/15l9oAlavzG8MYA7oCUAUfqdCjen6jSdg/view?usp=sharing](https://drive.google.com/file/d/15l9oAlavzG8MYA7oCUAUfqdCjen6jSdg/view?usp=sharing)",1,1,False,self,,,,,
1378,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,23,d9k7wx,self.MachineLearning,My new article on GANs and generating recipes,https://www.reddit.com/r/MachineLearning/comments/d9k7wx/my_new_article_on_gans_and_generating_recipes/,MWatson,1569507327,[removed],0,1,False,self,,,,,
1379,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,23,d9kkxl,self.MachineLearning,[D] Reasons for small RNN size in Neural Architecture Search paper,https://www.reddit.com/r/MachineLearning/comments/d9kkxl/d_reasons_for_small_rnn_size_in_neural/,LuxuriousLime,1569508983,"In the Neural Architecture Search [paper](https://arxiv.org/abs/1611.01578) it is stated that the controller RNN (used to generate architectures) had only 35 units in each of its 2 layers. This very small size seems strange to me. My initial explanation was that the authors had too few samples, but they actually used 15,000, which should be enough to train a bigger network. So what in your opinion could be a reason for a smaller network/why making the controller bigger wouldn't influence the results?",0,1,False,self,,,,,
1380,MachineLearning,t5_2r3gv,2019-9-26,2019,9,26,23,d9kn4t,self.MachineLearning,"[N] In the U.K., AI will soon be used to tackle homelessness",https://www.reddit.com/r/MachineLearning/comments/d9kn4t/n_in_the_uk_ai_will_soon_be_used_to_tackle/,Yrgalnumer1,1569509282,"According this [article](https://screenshot-magazine.com/the-future/machine-learning-tackle-homelessness/), AI and machine learning could help organisations to identify who needs to be safe urgently. Thoughts?",7,0,False,self,,,,,
1381,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,0,d9kvf3,self.MachineLearning,Neurips Lottery Decision,https://www.reddit.com/r/MachineLearning/comments/d9kvf3/neurips_lottery_decision/,elliot124,1569510337,When is neurips lottery decision going to be announced? Did anyone get confirmation email?,0,1,False,self,,,,,
1382,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,0,d9kvv0,self.MachineLearning,Is there any collection of the state of the art models for regression datasets?,https://www.reddit.com/r/MachineLearning/comments/d9kvv0/is_there_any_collection_of_the_state_of_the_art/,zhangtj1996,1569510388,[removed],0,1,False,self,,,,,
1383,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,0,d9l4yx,arxiv.org,[R] A Generative Model for Molecular Distance Geometry,https://www.reddit.com/r/MachineLearning/comments/d9l4yx/r_a_generative_model_for_molecular_distance/,i-like-big-gans,1569511534,,1,2,False,default,,,,,
1384,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,0,d9l7mi,medium.com,Reproducibility Challenges in Machine Learning for Health,https://www.reddit.com/r/MachineLearning/comments/d9l7mi/reproducibility_challenges_in_machine_learning/,Yuqing7,1569511864,,0,1,False,https://b.thumbs.redditmedia.com/bSS_mRaZ_h2d3wCgvWyHmFU8z5W70Jua5S3_PKs0AFM.jpg,,,,,
1385,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,0,d9lkb0,self.MachineLearning,Benefits of machine learning in ERP,https://www.reddit.com/r/MachineLearning/comments/d9lkb0/benefits_of_machine_learning_in_erp/,Wisdomplexus,1569513399,[removed],0,2,False,self,,,,,
1386,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,0,d9lkbc,self.MachineLearning,Is there a way to train a scikit classifier to make one prediction per N samples? [Project],https://www.reddit.com/r/MachineLearning/comments/d9lkbc/is_there_a_way_to_train_a_scikit_classifier_to/,JebusWasAnAlien,1569513400,"So, I originally posted this on StackOverflow, but I was told that my question was ""too broad"" and my thread was closed.

I'm working on replicating the research done in [this paper](https://www.sciencedirect.com/science/article/pii/S0957417414004473).

I have a pandas DF which looks like this:

    Date    In1    In2    In3    ...    Out
    Day1     -1      1     -1            -1
    Day2      1     -1      1             1
    Day3     -1      1     -1            -1
    Day4     -1      1      1             1
    Day5      1      1      1             1
    ...
    

Now, I've already done what they did in the paper. Which is to say, I've trained multiple models in scikit to predict `""Out""` based on all the feature columns `""In1"", ..., ""In10""`.

However, these are daily predictions and I wanna see what would happen if I make weekly predictions.

Essentially, I want to use `df.loc[Day1:Day5, In1:In10]` to predict `df.loc[Day5, ""Out""]`. 

Of course, `""Out""` would be redefined as cumulative returns over the last 5 days, rather than what it currently is i.e. daily returns.

The problem is, I have absolutely no idea how to go about making a single prediction with N samples. (in this case 5)

My X\_train/X\_test are DataFrames with the `""Out""` column dropped &amp; my y\_train/y\_test is a Series of the `""Out""` column. I prefer this because I'm not entirely comfortable with arrays.

Is there a way to make scikit use N samples for a single prediction?",1,0,False,self,,,,,
1387,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,1,d9ln76,self.MachineLearning,How to perform Adult Content Detection in a text?,https://www.reddit.com/r/MachineLearning/comments/d9ln76/how_to_perform_adult_content_detection_in_a_text/,zom8ie99,1569513737,[removed],0,1,False,self,,,,,
1388,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,1,d9ltnz,self.MachineLearning,[R] Editable Neural Networks - training neural networks so you can efficiently patch them later,https://www.reddit.com/r/MachineLearning/comments/d9ltnz/r_editable_neural_networks_training_neural/,phill1992,1569514486,"[https://openreview.net/forum?id=HJedXaEtvS](https://openreview.net/forum?id=HJedXaEtvS)

The researchers propose a method of training neural networks that can later be edited to correct mistakes. In other words, if your network says something [stupid](https://www.theguardian.com/technology/2017/oct/24/facebook-palestine-israel-translates-good-morning-attack-them-arrest) or [inappropriate](https://media.boingboing.net/wp-content/uploads/2018/01/CIoW7wBWoAEqQRP.png), you'll be able to make it right  quickly.",11,26,False,self,,,,,
1389,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,1,d9m7e2,self.MachineLearning,Whats going on in symbolic and similiar approaches to machine learning?,https://www.reddit.com/r/MachineLearning/comments/d9m7e2/whats_going_on_in_symbolic_and_similiar/,LeanderKu,1569516153,[removed],0,1,False,self,,,,,
1390,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,1,d9m8x5,self.MachineLearning,How to encode cyclic features in sklearn random forest,https://www.reddit.com/r/MachineLearning/comments/d9m8x5/how_to_encode_cyclic_features_in_sklearn_random/,Daedelus123,1569516333,"Say that I have an important feature which is ordinal and cyclic, e.g. the month of the year, what is then the best way to encode this in a random forest regressor model in sklearn.

Basically, there are three main approaches:

1. Encode the months as categorical with One Hot Encoding.
2. Encode the months as numerical values.
3. Encode the months as numerical values by splitting into sin and cos components.

The first approach adds flexibility but also sparsity and more dimensions to the model. The second approach does not have the problem the former approach has but now we instead have the problem of month 12 and 1 being interpreted as far apart. The third approach solves the former problem but now we have two features (sin and cos) that are going to be interpreted independently which doesn't make sense?

What is viewed as best practice for this case, apart from trying all three and chose the one with best performance I mean.",0,1,False,self,,,,,
1391,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,2,d9mhfg,self.MachineLearning,"[D] On pornographic, NSFW and non-consensual images in the ImageNet dataset. What's the path forward?",https://www.reddit.com/r/MachineLearning/comments/d9mhfg/d_on_pornographic_nsfw_and_nonconsensual_images/,VinayUPrabhu,1569517337,"Dear Reddit-ML community,

In the imagenet dataset, ( classes 445 -n02892767- \[bikini, two-piece\] and 459- n02837789- \[brassiere, bra, bandeau\]) there are many images that are verifiably pornographic (you can see the porn-star's webpage in the pic!), shot in a non-consensual setting, voyeuristic and also entail underage nudity (See collage below).  
This has deep ramifications not just in the legal realm for downloading and storing these images, but also has a trickle down effect with regards to the models trained on this dataset. Ex: If you are an artist making/selling neural art, the unethical nature of the seed images could sully the sanctity of the art (See:  [https://openreview.net/forum?id=HJlrwcP9DB](https://openreview.net/forum?id=HJlrwcP9DB) )

The question now is: What's the best path forward? Image deletion and replacement? Do chime in with your thoughts!

PS: I had written to the creators of the dataset (waay before the ImageNet Roulette thingy), but  received no replies.

![img](e1dyeqpyxyo31 ""A collage of images from the ImageNet dataset"")",16,3,True,nsfw,,,,,
1392,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,2,d9moyz,twitter.com,"[N] Despite revealed information regarding scams and content theft, New York times best selling publisher announces new book by Siraj Raval: ""Artificially Intelligent: Living Smart AF in an AI World"". When confronted about Siraj's behavior, publisher deletes and retweets announcement",https://www.reddit.com/r/MachineLearning/comments/d9moyz/n_despite_revealed_information_regarding_scams/,EveningMuffin,1569518237,,1,1,False,default,,,,,
1393,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,2,d9mr37,self.MachineLearning,"DeepVO, tuning loss function",https://www.reddit.com/r/MachineLearning/comments/d9mr37/deepvo_tuning_loss_function/,Dexter_fixxor,1569518468,[removed],0,1,False,self,,,,,
1394,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,2,d9mrky,self.MachineLearning,[R] What do you think about the idea of creating a random forest using DL for tabular data?,https://www.reddit.com/r/MachineLearning/comments/d9mrky/r_what_do_you_think_about_the_idea_of_creating_a/,SunghoYahng,1569518528," 

What do you think about the idea of creating a random forest using DL for tabular data?

There seems to be no reason this is not possible. Theres a reason I think its good not only in concept but also in performance. It is not a good performance that is required of the models that consist of RF, but RF requires the models to be overfitting as possible and to be different from each other as possible. This seems to be possible enough for DL for tabular data.  
The nice thing about this is that the model can deal with recursion on tabular data. DL is weak at processing tabular data and tree-based models cannot handle recursion. So it would be nice to be good at both.

I looked for a while but couldnt find anything about this. I wonder if theres anything I couldnt find",10,2,False,self,,,,,
1395,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,2,d9mtl2,github.blog,GitHub just released ImageNet for Code w/ an NLP challenge called CodeSearchNet :),https://www.reddit.com/r/MachineLearning/comments/d9mtl2/github_just_released_imagenet_for_code_w_an_nlp/,lunarlustra,1569518772,,0,1,False,default,,,,,
1396,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,2,d9mvyx,self.MachineLearning,"[N] Despite revealed information regarding scams and content theft, New York Times best selling publisher announces new book by Siraj Raval: ""Artificially Intelligent: Living Smart AF in an AI World"". When tweeted about Siraj's behavior, publisher deletes and retweets announcement to erase comment",https://www.reddit.com/r/MachineLearning/comments/d9mvyx/n_despite_revealed_information_regarding_scams/,EveningMuffin,1569519049,"Link to new announcement

https://twitter.com/TVGuestpert/status/1177003728664088576

Link to new deleted old announcement with tweet detailing Siraj's behavior 

https://twitter.com/ieatcatfood99/status/1177070520585449473",90,212,False,self,,,,,
1397,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,2,d9mxt4,medium.com,[N] Why User Behavior prediction is the next big thing in mobile and web,https://www.reddit.com/r/MachineLearning/comments/d9mxt4/n_why_user_behavior_prediction_is_the_next_big/,dmi3coder,1569519261,,0,1,False,default,,,,,
1398,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,2,d9n09a,self.MachineLearning,[P] Curated Papers (early release),https://www.reddit.com/r/MachineLearning/comments/d9n09a/p_curated_papers_early_release/,getlasterror,1569519553,"Hi all,

I'm launching [Curated Papers](https://www.curatedpapers.com), for the first time in this subreddit!

It's a website that let you organize lists of academic papers, share curated lists and discover lists made by others.

Think that you need to get into a new field of study... so instead of manually researching what papers to read, going over references, juggling papers back and forth (research that can take a long time), you could instead discover a curated list on the subject, made by a researcher coming from this field.

Of course that it will not entirely replace your need to search for papers, but at least you'll start with a good basis moving forward.

It's also some sort of a social network built around curated lists and academic papers, you can for example, like, discuss and follow curated lists, academic papers, or other users and stay up to date with your interests.

I'll be happy to get your feedback, did you like it? do you have any feature request?

Thanks!",11,18,False,self,,,,,
1399,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,2,d9n9m5,self.MachineLearning,[D] Why does backtranslation work?,https://www.reddit.com/r/MachineLearning/comments/d9n9m5/d_why_does_backtranslation_work/,TheRedSphinx,1569520669,"I think I must be misunderstanding how backtranslation, because I'm not seeing how this could help. I'll describe my current understanding then I'll ask my question.

&amp;#x200B;

The usual setup is that you have some some small set B of parallel data between a source and target language. Your goal is to make a model that a language in the source language and produced the translated version in the target language. 

&amp;#x200B;

In addition to the small dataset B, you also have some potentially very large corpus A of monolingual data in the target language. In order to leverage this data, you train a model in the reverse direction i.e target to source, by using B with the entries flipped. Then you use this model to make A', which consists of the translations of entries in A by using the reverse model. Finally, you add A' to B, get some final set C which you then train source --&gt; target model.

In some sense, this should only help if your target --&gt; source model is good. However, you trained this model only on B. This raises the following questions: 

&amp;#x200B;

1) if you can build a good target --&gt; source model from just B, why can't you do the same with source --&gt; target?  

&amp;#x200B;

2) If you do get some improvements, why can't you continue this process again? i.e. Train the source --&gt; target model using C, then grab some large monolingual corpus from the source language, backtranslate that to make some new set A'', then add A'' to C and re-train the target --&gt; source model then make more source --&gt; target examples by backtranslating the new model? Rise and repeat till you run out of compute.

&amp;#x200B;

Finally, is there a good reference for this kind of stuff? Most papers which use backtranslation are extremely vague about it.",3,3,False,self,,,,,
1400,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,3,d9nhpr,youtu.be,I resored/upscaled the opening for Yu Yu Hakusho (originally 640x480) to 4K using ai-machine learning. Results are very impressive.,https://www.reddit.com/r/MachineLearning/comments/d9nhpr/i_resoredupscaled_the_opening_for_yu_yu_hakusho/,Heretic0000000,1569521653,,0,1,False,default,,,,,
1401,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,3,d9o3mv,medium.com,Estimating Uncertainty in Machine Learning Models - Part 2,https://www.reddit.com/r/MachineLearning/comments/d9o3mv/estimating_uncertainty_in_machine_learning_models/,CometML,1569524249,,0,4,False,default,,,,,
1402,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,4,d9o5kq,self.MachineLearning,[D] - Finding research collaborators for medical AI projects outside of my university,https://www.reddit.com/r/MachineLearning/comments/d9o5kq/d_finding_research_collaborators_for_medical_ai/,Naveos,1569524471,"As the title entails; how may I find researchers / engineers / students (MSc or PhD) to collaborate with on a project outside of the sphere of my own university? Is there any community where experts are able to network and form collaborations? I'm super eager to do some research on the side.

Already been offered to be involved with several projects at my university, but none of them interest me (mainly been related to either utilizing geometric DL for glaucoma or U-net for lung carcinoma) - and so I wish to look beyond this city.

More information, if relevant:

* My domain expertise lies in healthcare/medicine, education, and gaming industry - but I am open to exploring other domains.
* Since I know some people care; my university is ranked worldwide top &lt;40 in engineering. My master's degree is in machine learning, with a bachelor's degree in medical engineering (I can verify this).
* Due to affiliation with my universty, I am eligible to publish to arXiv without an endorsement from a registered author.
* I work as a machine learning consultant and data science instructor alongside my studies.
* I'm very familiar with other technologies, such as Kafka and its ecosystem, Flutter, and more.

To clarify; I am looking for, in particular, people that already know a lot of machine learning who wish to collaborate on a research project - whether it'd be deep reinforcement learning, bayesian deep learning, or whatever else. Hence why I didn't feel like this would be appropriate to post at /r/learnmachinelearning",8,2,False,self,,,,,
1403,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,4,d9oa5a,github.blog,[N] GitHub releases the CodeSearchNet Corpus to facilitate building models for intelligent code search,https://www.reddit.com/r/MachineLearning/comments/d9oa5a/n_github_releases_the_codesearchnet_corpus_to/,gseyffert,1569525036,,0,1,False,default,,,,,
1404,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,5,d9p3im,self.MachineLearning,[R] Deep Learning For Symbolic Mathematics (ICLR 2020 submission),https://www.reddit.com/r/MachineLearning/comments/d9p3im/r_deep_learning_for_symbolic_mathematics_iclr/,youali,1569528501,"TL;DR: We train a neural network to compute function integrals, and to solve complex differential equations.

Abstract: Neural networks have a reputation for being better at solving statistical or approximate problems than at performing calculations or working with symbolic data. In this paper, we show that they can be surprisingly good at more elaborated tasks in mathematics, such as symbolic integration and solving differential equations. We propose a syntax for representing these mathematical problems, and methods for generating large datasets that can be used to train sequence-to-sequence models. We achieve results that outperform commercial Computer Algebra Systems such as Matlab or Mathematica.
Keywords: symbolic, math, deep learning, transformers

https://openreview.net/forum?id=S1eZYeHFDS&amp;noteId=S1eZYeHFDS",6,27,False,self,,,,,
1405,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,5,d9p4vr,self.MachineLearning,Which to read first Introduction to Statistical Learning or Hands on Machine Learning with scikit learn and tensorflow,https://www.reddit.com/r/MachineLearning/comments/d9p4vr/which_to_read_first_introduction_to_statistical/,kalyanpendyala1,1569528642,[removed],0,1,False,self,,,,,
1406,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,5,d9p69e,self.MachineLearning,"Took a Data Science position, now I am regretting it.",https://www.reddit.com/r/MachineLearning/comments/d9p69e/took_a_data_science_position_now_i_am_regretting/,loggedurip,1569528794,[removed],0,1,False,self,,,,,
1407,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,5,d9p8vy,insidetheauction.000webhostapp.com,Iphone Secrets please Don't tell,https://www.reddit.com/r/MachineLearning/comments/d9p8vy/iphone_secrets_please_dont_tell/,OfficialJessyLara,1569529080,,0,1,False,default,,,,,
1408,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,5,d9pdec,jnaproductions.000webhostapp.com,Please Don't tell anyone Let it be our Secret,https://www.reddit.com/r/MachineLearning/comments/d9pdec/please_dont_tell_anyone_let_it_be_our_secret/,Appleinsider09,1569529568,,0,1,False,https://b.thumbs.redditmedia.com/GpHYzcUmIQrt88pC_gN7bmfky4eHhu_JJ5ZFxZqOy3c.jpg,,,,,
1409,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,5,d9ph2m,self.MachineLearning,"[P] Having a predefined questionnaire, how to write system to extract data.",https://www.reddit.com/r/MachineLearning/comments/d9ph2m/p_having_a_predefined_questionnaire_how_to_write/,janiedebica,1569529977,"There is an extremely inefficient process in my city office. There is a process of collecting a data from citizens each year, there is an online form and offline form. The offline is a problem:

1. The forms are given to the people.
2. People fill the forms, it's handwriting.
3. The clerks have about 2-4 weeks to type the forms into the system.
4. There is a control data in the form, if incorrect, the form is ignored in further processing.

There are about 15-25K of such forms each year, but the form also changes.

I have a template of a form, but I don't have samples. The forms contain sensitive data, cannot be processed outside the internal network. How would you approach such a problem? I would appreciate any help.  


Usually I would just go with Google Vision API and text extraction and later writing decision tree to classify bounding boxes as a pieces of information, but in this case I cannot use external services.",2,1,False,self,,,,,
1410,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,6,d9q066,i.redd.it,Mining rig in stock just email us for any questions at support@Maverick-tech.com,https://www.reddit.com/r/MachineLearning/comments/d9q066/mining_rig_in_stock_just_email_us_for_any/,cibergirl11,1569532237,,0,1,False,default,,,,,
1411,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,6,d9q3h1,i.redd.it,MAVERICK-tech.com,https://www.reddit.com/r/MachineLearning/comments/d9q3h1/mavericktechcom/,cibergirl11,1569532641,,0,1,False,default,,,,,
1412,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,6,d9q62b,self.MachineLearning,[D] Why do effective activation functions have a bounded derivative?,https://www.reddit.com/r/MachineLearning/comments/d9q62b/d_why_do_effective_activation_functions_have_a/,TheSilenceOfTheBakra,1569532941,"Is there a reason why almost every modern activation function in deep learning has a bounded derivative? ReLU, Swish, tanh, sigmoid and other activation functions mentioned [here](https://arxiv.org/pdf/1710.05941.pdf) all have bounded derivatives. 

My intuition says it is because we use backprop to train our networks. A bounded derivative should restrict the amount of gradient flow during the backward phase, preventing a blowup of gradients. What do you guys think?",2,0,False,self,,,,,
1413,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,8,d9rprl,self.MachineLearning,[R] Introducing the CodeSearchNet challenge,https://www.reddit.com/r/MachineLearning/comments/d9rprl/r_introducing_the_codesearchnet_challenge/,youali,1569539679,"""Searching for code to reuse, call into, or to see how others handle a problem is one of the most common tasks in a software developers day. However, search engines for code are often frustrating and never fully understand what we want, unlike regular web search engines. We started using modern machine learning techniques to improve code search but quickly realized that we were unable to measure our progress. Unlike natural language processing with GLUE benchmarks, there is no standard dataset suitable for code search evaluation.

With our partners from Weights &amp; Biases, today were announcing the CodeSearchNet Challenge evaluation environment and leaderboard. Were also releasing a large dataset to help data scientists build models for this task, as well as several baseline models showing the current state of the art. Our leaderboard uses an annotated dataset of queries to evaluate the quality of code search tools.""

- [Blog post](https://github.blog/2019-09-26-introducing-the-codesearchnet-challenge/?utm_campaign=1569513857&amp;utm_medium=social&amp;utm_source=twitter&amp;utm_content=1569513857)
- [Technical report](https://arxiv.org/abs/1909.09436)",1,19,False,self,,,,,
1414,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,8,d9s4gb,self.MachineLearning,A text classification problem... Help a noob out.,https://www.reddit.com/r/MachineLearning/comments/d9s4gb/a_text_classification_problem_help_a_noob_out/,LordWestcott,1569541537,[removed],0,1,False,self,,,,,
1415,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,9,d9sbe4,self.MachineLearning,State-of-the-art in neural code generation and program synthesis?,https://www.reddit.com/r/MachineLearning/comments/d9sbe4/stateoftheart_in_neural_code_generation_and/,ginger_beer_m,1569542412,[removed],0,1,False,self,,,,,
1416,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,9,d9suqo,self.MachineLearning,[D] No Free Lunch theorems do not compare functions that can utilize cost-information from partial solutions. So why care about NFL?,https://www.reddit.com/r/MachineLearning/comments/d9suqo/d_no_free_lunch_theorems_do_not_compare_functions/,BayesMind,1569545154,"I see **No Free Lunch** theorems discussed enough that I decided to check my understanding, and sit down with the original [paper](https://ti.arc.nasa.gov/m/profile/dhw/papers/78.pdf). 

They prove bold (but contextualized) claims, and I feel like the bold claims have really taken on a life of their own (absent context):

&gt; one might expect that hill climbing usually outperforms hill descending if one's goal is to find a maximum [...] such expectations are incorrect

&gt; the average performance of any pair of algorithms across all possible problems is identical

Very interesting, to be sure. But this all hinges on a specific assumption:

&gt; [...] our decision to only measure distinct [oracle] function evaluations

meaning:

&gt; techniques like branch and bound are not included since they rely explicitly on the cost structure of partial solutions.

I think their framework is interesting and useful for describing algorithms like [Simulated Annealing](https://en.wikipedia.org/wiki/Simulated_annealing) or [Genetic Algorithms](https://en.m.wikipedia.org/wiki/Genetic_algorithm).

But since it doesn't apply to an entire class of algorithms (those that can reason from partial solutions), it seems to me that we should really reign in our claims about NFL.

I must be missing something.",9,3,False,self,,,,,
1417,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,10,d9t2kt,self.MachineLearning,ICLR 2020 New Optimizer,https://www.reddit.com/r/MachineLearning/comments/d9t2kt/iclr_2020_new_optimizer/,lllllIIlllllllll,1569546260,[removed],0,1,False,self,,,,,
1418,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,10,d9t60h,self.MachineLearning,Metal Lathe warping screw,https://www.reddit.com/r/MachineLearning/comments/d9t60h/metal_lathe_warping_screw/,mackattakyyy,1569546753,[removed],0,1,False,self,,,,,
1419,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,10,d9t9nw,self.MachineLearning,Scientific papers for all Neflix Recommenders,https://www.reddit.com/r/MachineLearning/comments/d9t9nw/scientific_papers_for_all_neflix_recommenders/,Nolwww,1569547275,[removed],0,1,False,self,,,,,
1420,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,10,d9tdfo,openreview.net,ALBERT: A Lite BERT for Self-supervised Learning of Language...,https://www.reddit.com/r/MachineLearning/comments/d9tdfo/albert_a_lite_bert_for_selfsupervised_learning_of/,aznpwnzor,1569547803,,28,117,False,https://b.thumbs.redditmedia.com/M6z7lt3X9o9rhh5EoEYi5953Zr9tnBwXcvOZL5rPWzk.jpg,,,,,
1421,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,10,d9tdq8,self.MachineLearning,"India's Most Comprehensive Artificial Intelligence &amp; Machine Learning Program Learn Artificial Intelligence and Machine Learning with hands-on projects and learning support, all designed to help you become an expert. Python Machine Learning Deep Learning Neural Networks Computer Vision Natura",https://www.reddit.com/r/MachineLearning/comments/d9tdq8/indias_most_comprehensive_artificial_intelligence/,[deleted],1569547853,,0,1,False,default,,,,,
1422,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,10,d9tg08,self.MachineLearning,Choosing which Scikit-learn logistic regression solver to use,https://www.reddit.com/r/MachineLearning/comments/d9tg08/choosing_which_scikitlearn_logistic_regression/,discdiver,1569548189,[removed],0,1,False,self,,,,,
1423,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,11,d9tqym,self.MachineLearning,Design a Chatbot to help navigate through website,https://www.reddit.com/r/MachineLearning/comments/d9tqym/design_a_chatbot_to_help_navigate_through_website/,royfeng123,1569549773,[removed],0,1,False,self,,,,,
1424,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,12,d9ui5a,self.MachineLearning,[dataset] 69K Tinder pics,https://www.reddit.com/r/MachineLearning/comments/d9ui5a/dataset_69k_tinder_pics/,tinderscraper,1569553824,[removed],0,1,False,self,,,,,
1425,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,13,d9v6do,self.MachineLearning,Need input on choice of AI methodology and MCU hardware for audio processing,https://www.reddit.com/r/MachineLearning/comments/d9v6do/need_input_on_choice_of_ai_methodology_and_mcu/,kdharbert,1569557638,"I have several analog input channels from which I wish to generate a single analog output channel. The input channels have varying bandwidths, but have no content beyond 1khz.  I want an MCU to run a static system that is generated by machine learning algorithms that will generate an analog output with content up to 22khz.  The processing algorithm running on the MCU is generated in advance by comparing a desired output with the observed inputs during a learning phase where real-time processing is not required. 

I think this is a straight forward machine learning application, I just need to pick methodologies and appropriate hardware.  Specifically, I need info on favored MCUs for multichannel audio applications and machine learning methodologies that result in systems that I can run on an MCU in real-time. 

Any help?",0,1,False,self,,,,,
1426,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,15,d9w695,self.MachineLearning,[R] DCTD: Deep Conditional Target Densities for Accurate Regression,https://www.reddit.com/r/MachineLearning/comments/d9w695/r_dctd_deep_conditional_target_densities_for/,dirac-hatt,1569564036,"We propose Deep Conditional Target Densities (DCTD), a novel and general regression method with a clear probabilistic interpretation. DCTD models the conditional target density p(y|x) by using a neural network to directly predict the un-normalized density from the input-target pair (x, y). This model of p(y|x) is trained by minimizing the associated negative log-likelihood, approximated using Monte Carlo sampling. Notably, our method achieves a 1.9% AP improvement over Faster-RCNN for object detection on COCO, and sets a new state-of-the-art on visual tracking when applied for bounding box regression.

arXiv: [https://arxiv.org/abs/1909.12297](https://arxiv.org/abs/1909.12297)

Project page: [http://www.fregu856.com/publication/dctd/](http://www.fregu856.com/publication/dctd/)",8,6,False,self,,,,,
1427,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,15,d9w6u3,self.MachineLearning,Siraj Raval to present at the European Space Astronomy Center Workshop as a tutor,https://www.reddit.com/r/MachineLearning/comments/d9w6u3/siraj_raval_to_present_at_the_european_space/,rayryeng,1569564148,"https://www.cosmos.esa.int/web/esac-stats-workshop-2019

Given the most recent news regarding defrauding students in his recent course, I'm not sure if it's appropriate for him to present. I don't believe he is the proper advocate for education at such a high profile venue like this.

https://reddit.com/r/MachineLearning/comments/d7ad2y/d_siraj_raval_potentially_exploiting_students/",0,1,False,self,,,,,
1428,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,15,d9w9xu,self.reinforcementlearning,Research project idea suggestions in RL,https://www.reddit.com/r/MachineLearning/comments/d9w9xu/research_project_idea_suggestions_in_rl/,PsyRex2011,1569564746,,0,1,False,default,,,,,
1429,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,15,d9w9y4,self.MachineLearning,[D] Siraj Raval to present at the European Space Astronomy Centre Statistics Workshop as a tutor,https://www.reddit.com/r/MachineLearning/comments/d9w9y4/d_siraj_raval_to_present_at_the_european_space/,rayryeng,1569564748,"[https://www.cosmos.esa.int/web/esac-stats-workshop-2019](https://www.cosmos.esa.int/web/esac-stats-workshop-2019)

Given the most recent news regarding defrauding students in his recent course, I'm not sure if it's appropriate for him to present. I don't believe he is the proper advocate for education at such a high profile venue like this.

[https://reddit.com/r/MachineLearning/comments/d7ad2y/d\_siraj\_raval\_potentially\_exploiting\_students/](https://reddit.com/r/MachineLearning/comments/d7ad2y/d_siraj_raval_potentially_exploiting_students/)

Should action be taken to alert the workshop organizers or should this be let go and be hopeful he'll learn from that fiasco?",0,0,False,self,,,,,
1430,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,16,d9wpkt,self.MachineLearning,"which are the best tutorial book , website, video for learning python with project / example ?",https://www.reddit.com/r/MachineLearning/comments/d9wpkt/which_are_the_best_tutorial_book_website_video/,Doctor_who1,1569567668,[removed],0,0,False,self,,,,,
1431,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,16,d9x1oa,nyti.ms,"At Techs Leading Edge, Worry About a Concentration of Power",https://www.reddit.com/r/MachineLearning/comments/d9x1oa/at_techs_leading_edge_worry_about_a_concentration/,rumborak,1569570082,,1,1,False,default,,,,,
1432,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,18,d9xwwk,self.MachineLearning,Looking for a Study Partner(s) for Progressive Machine Learning Learning,https://www.reddit.com/r/MachineLearning/comments/d9xwwk/looking_for_a_study_partners_for_progressive/,Michael_Sama,1569576557,[removed],0,1,False,self,,,,,
1433,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,18,d9xyry,arxiv.org,[R] RLBench: The Robot Learning Benchmark and Learning Environment,https://www.reddit.com/r/MachineLearning/comments/d9xyry/r_rlbench_the_robot_learning_benchmark_and/,hardmaru,1569576925,,3,71,False,default,,,,,
1434,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,18,d9xzub,self.MachineLearning,Worldwide Air Cargo Market is Estimated to Grow High CAGR by 2023,https://www.reddit.com/r/MachineLearning/comments/d9xzub/worldwide_air_cargo_market_is_estimated_to_grow/,jadhavni3,1569577132,[removed],1,1,False,self,,,,,
1435,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,18,d9y019,self.MachineLearning,Stochasticity of Random Forest model in Spark ML,https://www.reddit.com/r/MachineLearning/comments/d9y019/stochasticity_of_random_forest_model_in_spark_ml/,femibyte,1569577172,[removed],0,1,False,self,,,,,
1436,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,19,d9yhzb,self.MachineLearning,Which Is Types Of 3-Way Valve?,https://www.reddit.com/r/MachineLearning/comments/d9yhzb/which_is_types_of_3way_valve/,uflowindia,1569580490,[removed],0,1,False,https://b.thumbs.redditmedia.com/AhWvDS5YjVl0FxCto9X1cmt2Emebt2DusCCr2aIpCSc.jpg,,,,,
1437,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,19,d9yogd,self.MachineLearning,G4 instances on AWS,https://www.reddit.com/r/MachineLearning/comments/d9yogd/g4_instances_on_aws/,transmogrificate,1569581624,[removed],0,1,False,self,,,,,
1438,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,19,d9yozi,self.MachineLearning,[D] How to train a QA system to understand topics?,https://www.reddit.com/r/MachineLearning/comments/d9yozi/d_how_to_train_a_qa_system_to_understand_topics/,m1sta,1569581724,"Does anyone have any advice on building an NLP model from a set of documents, such that you could ask ""does this document discuss topic X""? I'd like synonyms and topics to be identified without supervision.",3,4,False,self,,,,,
1439,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,20,d9z062,self.MachineLearning,What is text annotation in machine learning?,https://www.reddit.com/r/MachineLearning/comments/d9z062/what_is_text_annotation_in_machine_learning/,smithrobert36,1569583550,[removed],0,1,False,self,,,,,
1440,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,20,d9zcxp,dx.doi.org,"New study: ""Constructing the Meaning of Humanoid Sex Robots""",https://www.reddit.com/r/MachineLearning/comments/d9zcxp/new_study_constructing_the_meaning_of_humanoid/,chicompj,1569585537,,0,1,False,default,,,,,
1441,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,21,d9ztng,self.MachineLearning,Mind.ai,https://www.reddit.com/r/MachineLearning/comments/d9ztng/mindai/,Falcon5757,1569587984,"Don't know much about ML myself (only gonna study it this year). So I wanted some competent opinion (and came to Reddit for it, right).

https://www.mind.ai/
What do y'all think of these guys? Looks worthy or.looks.like a hoax?
The have papers there.",0,1,False,self,,,,,
1442,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,21,d9zuoy,self.MachineLearning,Are you using AutoML solutions right now?,https://www.reddit.com/r/MachineLearning/comments/d9zuoy/are_you_using_automl_solutions_right_now/,TrueLankinen,1569588132,[removed],0,1,False,self,,,,,
1443,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,21,d9zuv3,self.MachineLearning,[D] Deep learning is not the answer you want.,https://www.reddit.com/r/MachineLearning/comments/d9zuv3/d_deep_learning_is_not_the_answer_you_want/,saadmrb,1569588154,"If you have a limited amount of data, want learning to occur in real-time, want an explanation of what was learned, dont have access to large banks of high-speed GPU machines, or you really care to model how humans learn, then in all these cases, deep learning is not the answer you want.",9,0,False,self,,,,,
1444,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,21,d9zv6i,celadonsoft.com,Do We Really Need Machine Learning for Personalized Recommendations? (Spoiler: Yes),https://www.reddit.com/r/MachineLearning/comments/d9zv6i/do_we_really_need_machine_learning_for/,Celadon_soft,1569588198,,2,2,False,spoiler,,,,,
1445,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,22,da0g7n,self.MachineLearning,Medical Image Classification,https://www.reddit.com/r/MachineLearning/comments/da0g7n/medical_image_classification/,moizsawan,1569591091,"Hi all. I am working on a medical image based binary classification. So far, I have tried every pre-trained model and have even tried to train some models from scratch. But still I am not getting good results. I have only two features for the patient other than the image. Images are cell images. I have even tried to incorporate non-image data with the image data but still no results. I have also tried handcrafted features for the images but to no use. The issue is that even visually I can not differentiate between the two classes. Any comments on what other methods or approaches I could follow to get a better result? Currently, I am having a \~60% accuracy but I need to get it past 70% at least.",0,1,False,self,,,,,
1446,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,22,da0iv2,medium.com,Improving Operational Efficiency by Integrating AI in ERP Systems,https://www.reddit.com/r/MachineLearning/comments/da0iv2/improving_operational_efficiency_by_integrating/,erp_oodles,1569591433,,0,1,False,https://a.thumbs.redditmedia.com/UkyY9sAiSfX5CQdbbNwnk0vvlG0nl-ShXDK0P0rBhq8.jpg,,,,,
1447,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,22,da0owd,cloudaeon.co.uk,5 ways big data helps mental health issues,https://www.reddit.com/r/MachineLearning/comments/da0owd/5_ways_big_data_helps_mental_health_issues/,cloudaeon1,1569592227,,1,1,False,https://b.thumbs.redditmedia.com/U56QhhYgkySGe_vOMTqMtFPzeQoSSPsii8uwle_mO3I.jpg,,,,,
1448,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,23,da0urk,self.MachineLearning,[N] Github Releases Dataset Of Six Million Methods From Open Source Projects For CodeSearchNet Challenge,https://www.reddit.com/r/MachineLearning/comments/da0urk/n_github_releases_dataset_of_six_million_methods/,SpecificTwo,1569592977,"&gt; [Introducting The Github CodeSearchNet Challenge](https://github.blog/2019-09-26-introducing-the-codesearchnet-challenge/?utm_campaign=1569513857&amp;utm_medium=social&amp;utm_source=twitter&amp;utm_content=1569513857)  
&gt;  
&gt;Searching for code to reuse, call into, or to see how others handle a problem is one of the most common tasks in a software developers day. However, search engines for code are often frustrating and never fully understand what we want, unlike regular web search engines. We started using modern machine learning techniques to improve code search but quickly realized that we were unable to measure our progress. Unlike natural language processing with [GLUE](https://gluebenchmark.com/) benchmarks, there is no standard dataset suitable for code search evaluation.  
&gt;  
&gt;We collected a large dataset of functions with associated documentation written in Go, Java, JavaScript, PHP, Python, and Ruby from open source projects on GitHub. We used our [TreeSitter](http://tree-sitter.github.io/tree-sitter/) infrastructure for this effort, and were also releasing our [data preprocessing pipeline](https://github.com/github/CodeSearchNet/tree/master/function_parser) for others to use as a starting point in applying machine learning to code. While this data is not directly related to code search, its pairing of code with related natural language description is suitable to train models for this task. Its substantial size also makes it possible to apply high-capacity models based on modern [Transformer](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html) architectures.  
&gt;  
&gt;Our fully preprocessed CodeSearchNet Corpus is available for [download on Amazon S3](https://github.com/github/CodeSearchNet#downloading-data-from-s3), including:  
&gt;  
&gt;**Six million methods overall**  
&gt;  
&gt;**Two million of which have associated documentation (docstrings, JavaDoc, and more)**  
&gt;  
&gt;Metadata that indicates the original location (repository or line number, for example) where the data was found",12,126,False,self,,,,,
1449,MachineLearning,t5_2r3gv,2019-9-27,2019,9,27,23,da125p,self.MachineLearning,Exhaust Hood Market Anticipated for Progressive CAGR Growth during 2019-2023,https://www.reddit.com/r/MachineLearning/comments/da125p/exhaust_hood_market_anticipated_for_progressive/,jadhavni3,1569593884,[removed],1,1,False,self,,,,,
1450,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,0,da22wf,theregister.co.uk,YouTuber charged loads of fans $199 for shoddy machine learning course that copy-pasted other people's GitHub code,https://www.reddit.com/r/MachineLearning/comments/da22wf/youtuber_charged_loads_of_fans_199_for_shoddy/,MLGoddess,1569598362,,0,1,False,default,,,,,
1451,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,0,da239z,self.MachineLearning,Machine Learning / Reinforcement Learning Meetups in NYC?,https://www.reddit.com/r/MachineLearning/comments/da239z/machine_learning_reinforcement_learning_meetups/,buildmeapcnyc,1569598408,[removed],0,1,False,self,,,,,
1452,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,0,da23xj,self.MachineLearning,Night vision devices are extensively used by military and paramilitary forces to locate enemy targets during night operations,https://www.reddit.com/r/MachineLearning/comments/da23xj/night_vision_devices_are_extensively_used_by/,gauravgvr89,1569598485,[removed],0,1,False,self,,,,,
1453,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,0,da2cna,self.MachineLearning,"[N] Amidst controversy regarding his most recent course, Siraj Raval is to present at the European Space Astronomy Center Workshop as a tutor",https://www.reddit.com/r/MachineLearning/comments/da2cna/n_amidst_controversy_regarding_his_most_recent/,rayryeng,1569599593,"https://www.cosmos.esa.int/web/esac-stats-workshop-2019

Discussion about his exploitation of students in his most recent course here:
 https://www.reddit.com/r/MachineLearning/comments/d7ad2y/comment/f1kubtj",130,292,False,self,,,,,
1454,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,1,da2jzh,self.MachineLearning,[R] Engineering a Less Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/da2jzh/r_engineering_a_less_artificial_intelligence/,P4TR10T_TR41T0R,1569600479,[removed],0,1,False,self,,,,,
1455,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,1,da2pm1,self.MachineLearning,precisionFDA BioCompute App-a-thon  October 18th Submission Deadline Reminder!,https://www.reddit.com/r/MachineLearning/comments/da2pm1/precisionfda_biocompute_appathon_october_18th/,hollystephens723,1569601137,[removed],0,1,False,self,,,,,
1456,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,1,da2smv,self.MachineLearning,[P] Latest TensorFlow 2.0 wheels with CUDA 10.1 and Python3.7,https://www.reddit.com/r/MachineLearning/comments/da2smv/p_latest_tensorflow_20_wheels_with_cuda_101_and/,davex32,1569601506,"Tensorflow has been using CUDA 10 for a while now. Since these take considerable time to compile, and not everyone has the resources to do so, I figured it wouldn't hurt to share my latest custom builds with **CUDA 10.1 / cuDNN 7.6 / NCCL 2.4** for **Tensorflow 2.0rc2** (for which the branch finally compiles from sources without any issues).  

[https://github.com/davidenunes/tensorflow-wheels](https://github.com/davidenunes/tensorflow-wheels)

The repository is mostly for wheels I've been using, but I also list wheels other people requested.

\-- this depends in my availability but feel free to make a request, if you can't find a build that you really need.",1,7,False,self,,,,,
1457,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,1,da2wwd,self.MachineLearning,[D] Could a 3D model of a room be constructed based on sound alone?,https://www.reddit.com/r/MachineLearning/comments/da2wwd/d_could_a_3d_model_of_a_room_be_constructed_based/,Mjjjokes,1569602025,"Imagine we have a training set of mp3s coupled with corresponding 3D models of rooms in which the 3D models were recorded. We train a neural net with this data. Given a new mp3, could we construct a 3D model based on sound alone?",18,3,False,self,,,,,
1458,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,1,da30mv,self.MachineLearning,[R] Tackling Climate Change with Machine Learning - video &amp; blog post summary,https://www.reddit.com/r/MachineLearning/comments/da30mv/r_tackling_climate_change_with_machine_learning/,paul_read_it,1569602469,"Dear ML community,

The paper ""[Tackling Climate Change with Machine Learning](https://arxiv.org/pdf/1906.05433.pdf)"" was the most interesting paper i have come across since I work in the data science realm. It was created by 22 AI researchers including Andrew Ng, Yoshua Bengio, David Rolnick and others from Google, Stanford, Harvard, Deepmind, Microsoft Research etc. 

Because i believe that it contains many great research works and projects which deserve more attention, i spent the last weeks and weekends to create a video summary and a blog post series, which try to give an easy to grasp overview. 

Here is the video summary: [https://youtu.be/pHdv4o0mfd0](https://youtu.be/pHdv4o0mfd0)

And here are the parts of the blog post series:

1. [Electricity Systems](https://blog.codecentric.de/en/2019/09/how-to-tackle-climate-change-with-machine-learning-electricity-systems/#post-69396)
2. [Transportation](https://blog.codecentric.de/en/2019/09/how-to-tackle-climate-change-with-machine-learning-transportation#post-69735)
3. [Buildings &amp; Cities](https://blog.codecentric.de/en/2019/09/tackling-climate-change-with-machine-learning-buildings-cities#post-69738)
4. [Farms &amp; Forests](https://blog.codecentric.de/en/2019/09/tackling-climate-change-with-machine-learning-farms-forests#post-69740)
5. [Industry &amp; Carbon Dioxide Removal](https://blog.codecentric.de/en/2019/09/tackling-climate-change-with-machine-learning-industry-carbon-dioxide-removal#post-69742)
6. [Datasets &amp; further resources](https://blog.codecentric.de/en/2019/09/tackling-climate-change-with-machine-learning-datasets-further-resources/#post-69744)

If you want to learn more afterwards, check out the [http://climatechange.ai](http://www.climatechange.ai/) project, which emerged from the paper, where you will find further resources, such as datasets, initiatives and talks from ICML 2019.

There will be workshops at NeurIPS 2019 (Vancouver, Canada) and AMLD 2020 (Lausanne, Switzerland) that will focus on this matter as well.

Machine Learning is not a miracle cure and cannot solve all climate change related problems. Policy makers must decide to act to drive large-scale progress. But ML is an invaluable tool which can reduce greenhouse gas emissions in many domains and sometimes even help create better policies, as the research shows.

I hope this summary will spark further ideas and maybe inspire you to do something about one of the greatest challenges we face as a planet. Let's use the diverse talents we have to drive some progress and create a better future!

Paul",17,114,False,self,,,,,
1459,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,1,da33bu,self.MachineLearning,"[N] An article about Siraj Raval's ""Make Money with Machine Learning"" - cat is slowly coming out of the bag",https://www.reddit.com/r/MachineLearning/comments/da33bu/n_an_article_about_siraj_ravals_make_money_with/,darkhorse3141,1569602807,[removed],0,1,False,self,,,,,
1460,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,2,da3acc,instagram.com,"[P] This ""Deep Visualizer"" sets BigGAN to music.",https://www.reddit.com/r/MachineLearning/comments/da3acc/p_this_deep_visualizer_sets_biggan_to_music/,SeagullMan2,1569603670,,0,1,False,default,,,,,
1461,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,2,da3bi8,self.MachineLearning,[R] Neural Volumes: Learning Dynamic Renderable Volumes from Images -- Source Code Release,https://www.reddit.com/r/MachineLearning/comments/da3bi8/r_neural_volumes_learning_dynamic_renderable/,stephenlombardi,1569603804,"We published our work, [Neural Volumes](https://research.fb.com/publications/neural-volumes-learning-dynamic-renderable-volumes-from-images/), at SIGGRAPH this year. The goal of the paper is to create an animate-able 3D model of objects and scenes from calibrated multi-view video. You can check out the video in that link for a visual explanation of how the method works and to see some of the results. The formulation of the method is basically an autoencoder with a fixed-function rendering technique that renders a volume into an image.

We've just [put the source code on Github](https://github.com/facebookresearch/neuralvolumes) today. Since calibrated multi-view video is relatively hard to come by, we've including the dry ice dataset as well as a pretrained model (in the v0.1 release). I'm happy to answer any questions about this work or talk about neural rendering in general.",7,14,False,self,,,,,
1462,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,2,da3fzi,self.MachineLearning,[D] How do some people have so many publications?,https://www.reddit.com/r/MachineLearning/comments/da3fzi/d_how_do_some_people_have_so_many_publications/,RaptorDotCpp,1569604348,"I was looking at some conference programs and noticed the same names appearing not once, twice, but thrice. Twice as first author, once as second.

I looked up that person and noticed that they had been publishing a lot in 2019 alone. How do they do this? Do they not need time to do actual research?

I've been working on some research, and I was going to submit it to a conference later this year, but just now someone else has done the same thing (on a different dataset). Can I still publish this? If not, how do these people that publish so much not have this happen all the time? I essentially have to throw away half a year of work because someone else submitted to a conference with an earlier deadline.

Sometimes I dread research...",32,10,False,self,,,,,
1463,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,2,da3m05,self.MachineLearning,A question on learning to backpropagate,https://www.reddit.com/r/MachineLearning/comments/da3m05/a_question_on_learning_to_backpropagate/,A-pan-weeb,1569605080,"Hi all, noob question here. Ive recently been getting hooked on learning about neural networks, and am working on writing a simple one. I managed to forward propagate the network fine, but Im now stuck on back propagation. I understand some key concepts but what I really need is a to the point, python tutorial, something Im struggling to find. Does anyone know one such tutorial? Thanks!",0,1,False,self,,,,,
1464,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,2,da3p9n,medium.com,Googles ALBERT Is a Leaner BERT; Achieves SOTA on 3 NLP Benchmarks,https://www.reddit.com/r/MachineLearning/comments/da3p9n/googles_albert_is_a_leaner_bert_achieves_sota_on/,Yuqing7,1569605500,,0,1,False,https://b.thumbs.redditmedia.com/t2E4nYht22ms8uI_Xff6UCpE3FkKokOPs5JzZ4Ob3sA.jpg,,,,,
1465,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,2,da3t9x,self.MachineLearning,Techniques for Deep Learning/NLP dissertation,https://www.reddit.com/r/MachineLearning/comments/da3t9x/techniques_for_deep_learningnlp_dissertation/,maprushmerry,1569605986,[removed],0,1,False,self,,,,,
1466,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,2,da41ov,self.MachineLearning,Machine Learning with AWS AI and IBM Watson,https://www.reddit.com/r/MachineLearning/comments/da41ov/machine_learning_with_aws_ai_and_ibm_watson/,HannahHumphreys,1569607042,[removed],0,1,False,self,,,,,
1467,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,2,da41uq,self.MachineLearning,DEEP LEARNING NETWORK OPTIMIZATION ON TDA2X,https://www.reddit.com/r/MachineLearning/comments/da41uq/deep_learning_network_optimization_on_tda2x/,reshmamm,1569607063,[removed],1,1,False,self,,,,,
1468,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,3,da46ce,self.MachineLearning,Should I randomize the output layer if doing transfer learning for the same outcome?,https://www.reddit.com/r/MachineLearning/comments/da46ce/should_i_randomize_the_output_layer_if_doing/,logicallyzany,1569607613,[removed],0,1,False,self,,,,,
1469,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,3,da46e0,self.MachineLearning,[D] Machine Learning / Reinforcement Learning Meetups in NYC?,https://www.reddit.com/r/MachineLearning/comments/da46e0/d_machine_learning_reinforcement_learning_meetups/,buildmeapcnyc,1569607620,Are there any such events in NYC? I'd love to meet more people in that space in my area,0,1,False,self,,,,,
1470,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,3,da4hpl,self.MachineLearning,[D] Handling noisy labels in large datasets with slight imbalance,https://www.reddit.com/r/MachineLearning/comments/da4hpl/d_handling_noisy_labels_in_large_datasets_with/,amil123123,1569609030,"Hey all,
I have large binary classification dataset with follow counts
0: 200k
1: 500k

Now the labels are not true labels but have probability associated with them. I filtered data points that had &gt;0.85 probability of respective classes and got the following counts.

Now I have tried the following:-
 Random first with class weight - massively overfit and if played around with max _depth parameter to reduce overfitting however I am unable to get good results.
 Tried oversampling like SMOTE etc but they take large amount of time.

Do you have any suggestions how to deal with imbalance and noisy labels?",4,1,False,self,,,,,
1471,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,3,da4pja,youtu.be,MLModel Deployment to Production,https://www.reddit.com/r/MachineLearning/comments/da4pja/mlmodel_deployment_to_production/,Techtter,1569610026,,0,1,False,default,,,,,
1472,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,4,da53lu,self.MachineLearning,Few basic things every data engineer should know about,https://www.reddit.com/r/MachineLearning/comments/da53lu/few_basic_things_every_data_engineer_should_know/,darthvader003,1569611762,"Hi all!

I will be starting in Data science team as a Data engineer. I am a recent CS grad. I have been coding in scala for a couple of years now and switching the job for the first time! I have done a fair bit of Python programming but have not written any production level python code.

I would really appreciate it if someone can guide a few basic things a data engineer should. I know this is a very broad question and might seem somewhat vague.

But assume if you were in my team and what are things you expect me to know once I join your team.

Any suggestions are welcome! Thanks",0,1,False,self,,,,,
1473,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,4,da5e4o,datastreamer.io,Language Classifying 5TB of Web Content per Day,https://www.reddit.com/r/MachineLearning/comments/da5e4o/language_classifying_5tb_of_web_content_per_day/,socialdatum,1569613080,,0,1,False,https://b.thumbs.redditmedia.com/FtyHeRXQQtynryqpWD_WY4ueSgEFwtpMkZoPrj688FE.jpg,,,,,
1474,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,4,da5f0r,self.MachineLearning,Udacity &amp; AWS DeepRacer Scholarship Challenge - Udacity,https://www.reddit.com/r/MachineLearning/comments/da5f0r/udacity_aws_deepracer_scholarship_challenge/,futuredude,1569613207,"The AWS DeepRacer Scholarship Challenge is open to all students, 18 years of age or older, interested in machine learning. We recommend students have a basic knowledge of Python.

The program begins August 1 and will run through October 31, 2019. You can join the scholarship community at any point during these 3 months and immediately enroll in Udacitys specialized AWS DeepRacer course.

[https://www.udacity.com/aws-deepracer-scholarship](https://www.udacity.com/aws-deepracer-scholarship)",0,1,False,self,,,,,
1475,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,4,da5fd7,self.MachineLearning,Using ML to ASSIST in Stocks,https://www.reddit.com/r/MachineLearning/comments/da5fd7/using_ml_to_assist_in_stocks/,soccerraze101,1569613245,[removed],0,1,False,self,,,,,
1476,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,4,da5mac,youtube.com,Neural Network Learns To Play Club Penguin with Genetic Evolution!,https://www.reddit.com/r/MachineLearning/comments/da5mac/neural_network_learns_to_play_club_penguin_with/,mattberrycrunch,1569614121,,0,1,False,default,,,,,
1477,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,5,da654b,self.MachineLearning,How do you deploy your python machine learning models?,https://www.reddit.com/r/MachineLearning/comments/da654b/how_do_you_deploy_your_python_machine_learning/,darthvader003,1569616465,[removed],0,1,False,self,,,,,
1478,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,5,da66bk,self.MachineLearning,[D] The AI brain drain,https://www.reddit.com/r/MachineLearning/comments/da66bk/d_the_ai_brain_drain/,bendee983,1569616626,"The deep pockets of large tech companies are luring AI scientists and professors away from academia into business and for-profit endeavors. How will this affect scientific research and machine learning projects that do not necessarily aim to fatten the pockets of big tech? I discussed this in my latest column, would be happy to get your thoughts on it.",7,0,False,self,,,,,
1479,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,6,da6vil,self.MachineLearning,[Project] ig65m-pytorch: PyTorch 3d video classification models pre-trained on over 65 million Instagram videos,https://www.reddit.com/r/MachineLearning/comments/da6vil/project_ig65mpytorch_pytorch_3d_video/,danieljh,1569619846,"[**https://github.com/moabitcoin/ig65m-pytorch**](https://github.com/moabitcoin/ig65m-pytorch)

[**https://github.com/moabitcoin/ig65m-pytorch/releases**](https://github.com/moabitcoin/ig65m-pytorch/releases)

Hey folks, we ported the r(2+1)d video classification model (from CVPR 2018, see [https://arxiv.org/abs/1711.11248](https://arxiv.org/abs/1711.11248)) and the weights pre-trained by Facebook Research on over 65 million Instagram videos (from CVPR 2019, [https://arxiv.org/abs/1905.00561](https://arxiv.org/abs/1905.00561)) to PyTorch and released architecture, weights, tools for conversion, and feature extraction example.

The official Facebook Research codebase can be found at [https://github.com/facebookresearch/vmz](https://github.com/facebookresearch/vmz)

These models and pre-trained weights are immensly powerful e.g. for fine-tuning on action recognition tasks or extracting features from 3d data such as videos. Think: resnet+imagenet but for videos.

We hope the PyTorch models and weights are useful for folks out there and are easier to use and work with compared to the goal driven, caffe2 based, research'y official code base.",0,35,False,self,,,,,
1480,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,6,da70mj,self.MachineLearning,Robust Attacks on Machine Learning Models,https://www.reddit.com/r/MachineLearning/comments/da70mj/robust_attacks_on_machine_learning_models/,andrea_manero,1569620511,[removed],0,1,False,self,,,,,
1481,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,7,da7cwp,self.MachineLearning,LSTM implementation in C for byte level prediction,https://www.reddit.com/r/MachineLearning/comments/da7cwp/lstm_implementation_in_c_for_byte_level_prediction/,rickardicus,1569622126,[removed],0,1,False,self,,,,,
1482,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,7,da7eev,self.MachineLearning,[P] LSTM implementation in C for byte level predictions,https://www.reddit.com/r/MachineLearning/comments/da7eev/p_lstm_implementation_in_c_for_byte_level/,rickardicus,1569622350,"Hi folks!

I wanted to share a project I have been working on. It is a recurrent neural network that predicts bytes which can be used to mimic e.g. lyrical content (such as books). It uses Adams gradient optimization algorithm and the only requirement for using it is GCC. No third parties, just a bunch of C source files needed to be compiled. I have included some pretrained models that might be fun to play around with.

I hope this can serve as an inspiration to anyone wanting to make their own stuff from scratch. 

Feel free to come with constructive comments on what I can add/change or any such requests.
Have a great Monday!

Here is a link to the GitHub repository:

[LSTM implementation (GitHub)](https://github.com/Ricardicus/recurrent-neural-net) 

Dont forget to give the repository a star if you like it, it would be really appreciated!",22,41,False,self,,,,,
1483,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,7,da7lg6,self.MachineLearning,[Discussion] ICLR 2020: Let the citation requests/drama begin,https://www.reddit.com/r/MachineLearning/comments/da7lg6/discussion_iclr_2020_let_the_citation/,not_novel_enough,1569623301,"Just checking the recent activity and people have started posting missing citations. Now, some of them will be genuine, but some will be self-promotions. However, this year, as there are no anonymous comments, it is going to be quite a show, getting my popcorn ready.",11,8,False,self,,,,,
1484,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,7,da7tx3,self.MachineLearning,SUNY Albany Data Science Program Review?,https://www.reddit.com/r/MachineLearning/comments/da7tx3/suny_albany_data_science_program_review/,GlitteringSweet4,1569624491,[removed],0,1,False,self,,,,,
1485,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,8,da7zm0,reddit.com,where can i get a program to make seamless transitions between images of faces like in this one?,https://www.reddit.com/r/MachineLearning/comments/da7zm0/where_can_i_get_a_program_to_make_seamless/,1ppuffel,1569625290,,0,1,False,default,,,,,
1486,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,9,da8zh5,phys.org,Machine learning opens new possibilities for quantum devices,https://www.reddit.com/r/MachineLearning/comments/da8zh5/machine_learning_opens_new_possibilities_for/,FindLight2017,1569630536,,0,1,False,https://a.thumbs.redditmedia.com/SfIBJSRnnq4UkswUxLk4Pgg9A4b0ufmAJir6m5A1w48.jpg,,,,,
1487,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,9,da951v,self.MachineLearning,"Intuition behind ""Recursive Autoconvolution for Unsupervised Learning of Convolutional Neural Networks""?",https://www.reddit.com/r/MachineLearning/comments/da951v/intuition_behind_recursive_autoconvolution_for/,HumanSpinach2,1569631387,"https://arxiv.org/abs/1606.00611

What this paper does is learn CNN features by first applying K-means clustering  to image patches, and then zero-padding the resulting cluster centers and applying autoconvolution recursively. The results are then used as features in a CNN (and it seems they do this to learn features for multiple layers, not just the first layer). The resulting features bear a very close resemblance to wavelets.

Is there any intuition behind why convolving KNN image patches with themselves would give useful features? I know that taking the cross-correlation (which is very closely related to convolution) of a signal with itself can be used to reveal hidden structure in, for example, audio signals. But that's not really analogous to what they're doing here. The paper references numerous other works, and I've tried reading them but they're too mathematically dense for me to understand.

Is there any intuitive rationale for why this works? The only reason I can think of is that applying autoconvolution makes a feature more selective to specific frequencies (because autoconvolution is equal to squaring the coefficients on the Fourier domain), but by that logic, a pre-defined family of wavelets should work just as well. ""Wavelet Scattering"" CNNs have actually shown pretty decent results using Gabor wavelets as predefined filters.

I also observed that, although applying autoconvolution to a feature will make it more selective to frequency, this comes at the cost of scrambling the phase information. In the paper, they apply the recursive autoconvolution operator as many as 3 times, which is the same as raising the Fourier coefficients to power 8 - this would completely scramble the phases and I suspect that at that point you might as well just randomize the phases and it wouldn't make a difference.",0,1,False,self,,,,,
1488,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,11,daab78,self.MachineLearning,Can I use Google Colab for Training AI?,https://www.reddit.com/r/MachineLearning/comments/daab78/can_i_use_google_colab_for_training_ai/,MrMegaGamerz,1569637979,[removed],0,1,False,self,,,,,
1489,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,13,dabkt6,youtu.be,"It is enough to see this interview Siraj done with 3Blue1Brown and the kind of questions he asks to know that Siraj Raval is a scam. He is terribly selfish which a great sign of a scammer. BTW, 3Blue1Brwon is on the best channels on Youtube.",https://www.reddit.com/r/MachineLearning/comments/dabkt6/it_is_enough_to_see_this_interview_siraj_done/,Beginner4ever,1569645800,,1,1,False,https://b.thumbs.redditmedia.com/g_kZBC5xXqeCZCtrc69HzZ6Z2jPagBu2QJtZa5gVhyI.jpg,,,,,
1490,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,13,dabm0q,self.MachineLearning,Is it possible to use this laptop for machine learning and utilize the GPU in training?,https://www.reddit.com/r/MachineLearning/comments/dabm0q/is_it_possible_to_use_this_laptop_for_machine/,wannahakaluigi,1569646052,[removed],0,1,False,self,,,,,
1491,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,13,dabmsn,self.MachineLearning,Why the Dirichlet as a prior for LDA?,https://www.reddit.com/r/MachineLearning/comments/dabmsn/why_the_dirichlet_as_a_prior_for_lda/,fuqmebaby,1569646187,[removed],0,1,False,self,,,,,
1492,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,13,dabojs,self.MachineLearning,[D] Why the Dirichlet as a prior for LDA?,https://www.reddit.com/r/MachineLearning/comments/dabojs/d_why_the_dirichlet_as_a_prior_for_lda/,fuqmebaby,1569646531,"It seems the Dirichlet distribution is pretty ubiquitous in its use as a prior for LDA and other types of topic models. However, in variational inference the Dirichlet doesn't have a closed form reparameterization. What are the various properties that make the Dirichlet so successful, and are there any other distributions or methods that exhibit these properties without having to use the Dirichlet?",8,3,False,self,,,,,
1493,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,14,dac1hg,self.datasets,"sports datasets for primary school, middle school, high school, varsity sports at university etc",https://www.reddit.com/r/MachineLearning/comments/dac1hg/sports_datasets_for_primary_school_middle_school/,demoplayer1971,1569649023,,0,1,False,default,,,,,
1494,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,15,dackhr,self.MachineLearning,Clarity on research field?,https://www.reddit.com/r/MachineLearning/comments/dackhr/clarity_on_research_field/,ashutosj,1569652844,[removed],0,1,False,self,,,,,
1495,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,16,dacw4p,self.MachineLearning,Medical Document Image Dataset,https://www.reddit.com/r/MachineLearning/comments/dacw4p/medical_document_image_dataset/,akshaydp1995,1569655325,"I would like to perform OCR specifically for document images from the medical domain like diagnostic reports, prescriptions, etc.   


I'm looking for those that contain a lot of text and preferably tables. I've found many on google images, but haven't been able to find datasets. I have queried using lots of synonyms and different names from the medical fields.  


I would appreciate some valuable resources or tips on how I could find them.",0,1,False,self,,,,,
1496,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,17,dadh3v,data-flair.training,Machine Learning in Finance - 15 Applications for Data Science Aspirants,https://www.reddit.com/r/MachineLearning/comments/dadh3v/machine_learning_in_finance_15_applications_for/,AnujG23,1569659936,,0,1,False,default,,,,,
1497,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,17,dadiq5,medium.com,AI for portfolio management: from Markowitz to Reinforcement Learning [Medium friend's link],https://www.reddit.com/r/MachineLearning/comments/dadiq5/ai_for_portfolio_management_from_markowitz_to/,rachnogstyle,1569660272,,0,1,False,default,,,,,
1498,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,18,dadmz3,medium.com,[P] Faking the News with NLP and Transformer Models,https://www.reddit.com/r/MachineLearning/comments/dadmz3/p_faking_the_news_with_nlp_and_transformer_models/,ageitgey,1569661207,,0,1,False,default,,,,,
1499,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,19,daeahg,crowdforthink.com,CrowdforThink : Blog -What is Machine Learning,https://www.reddit.com/r/MachineLearning/comments/daeahg/crowdforthink_blog_what_is_machine_learning/,crowdforapps,1569666172,,0,1,False,default,,,,,
1500,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,19,daeaik,crowdforthink.com,CrowdforThink : Blog -5 Skills You Need to Become a Machine Learning Engineer,https://www.reddit.com/r/MachineLearning/comments/daeaik/crowdforthink_blog_5_skills_you_need_to_become_a/,crowdforapps,1569666182,,0,1,False,default,,,,,
1501,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,19,daeamj,crowdforthink.com,CrowdforThink : Blog -The best smartphones you can buy right now,https://www.reddit.com/r/MachineLearning/comments/daeamj/crowdforthink_blog_the_best_smartphones_you_can/,crowdforapps,1569666206,,0,1,False,default,,,,,
1502,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,19,daeao5,crowdforthink.com,"CrowdforThink : Blog -Apple iPhone XS review: two steps forward, one step back",https://www.reddit.com/r/MachineLearning/comments/daeao5/crowdforthink_blog_apple_iphone_xs_review_two/,crowdforapps,1569666215,,0,1,False,default,,,,,
1503,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,19,daeaps,crowdforthink.com,CrowdforThink : Blog -Google Pixel 3 XL review: big is still beautiful,https://www.reddit.com/r/MachineLearning/comments/daeaps/crowdforthink_blog_google_pixel_3_xl_review_big/,crowdforapps,1569666224,,0,1,False,default,,,,,
1504,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,19,daear6,crowdforthink.com,CrowdforThink : Blog -Google Pixel 3 review: raising the bar for the Android experience,https://www.reddit.com/r/MachineLearning/comments/daear6/crowdforthink_blog_google_pixel_3_review_raising/,crowdforapps,1569666233,,0,1,False,default,,,,,
1505,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,19,daearv,crowdforthink.com,CrowdforThink : Blog -iPad Pro 12.9 review (2018): The future of computing?,https://www.reddit.com/r/MachineLearning/comments/daearv/crowdforthink_blog_ipad_pro_129_review_2018_the/,crowdforapps,1569666241,,0,1,False,default,,,,,
1506,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,19,daeata,crowdforthink.com,CrowdforThink : Blog -How Can Modern Technology Help In The Marketing Business?,https://www.reddit.com/r/MachineLearning/comments/daeata/crowdforthink_blog_how_can_modern_technology_help/,crowdforapps,1569666250,,0,1,False,default,,,,,
1507,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,19,daeaul,crowdforthink.com,"CrowdforThink : Blog -Startups, startups everywhere! So, its time to move, isnt it?!",https://www.reddit.com/r/MachineLearning/comments/daeaul/crowdforthink_blog_startups_startups_everywhere/,crowdforapps,1569666258,,0,1,False,default,,,,,
1508,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,19,daeawn,crowdforthink.com,CrowdforThink : Blog -Top 7 Benefits of Landing Page to Online Business,https://www.reddit.com/r/MachineLearning/comments/daeawn/crowdforthink_blog_top_7_benefits_of_landing_page/,crowdforapps,1569666268,,0,1,False,default,,,,,
1509,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,19,daeayr,crowdforthink.com,CrowdforThink : Blog -The Importance of Social Media for Developing of Your Business,https://www.reddit.com/r/MachineLearning/comments/daeayr/crowdforthink_blog_the_importance_of_social_media/,crowdforapps,1569666277,,0,1,False,https://a.thumbs.redditmedia.com/WikvqJGwEWzdG2bG0fdQiFXnS5leu3bXILug0tJB3h4.jpg,,,,,
1510,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,19,daebwz,self.MachineLearning,"[Project] torchfunc: PyTorch functions to improve performance, analyse and make your deep learning life easier.",https://www.reddit.com/r/MachineLearning/comments/daebwz/project_torchfunc_pytorch_functions_to_improve/,szymonmaszke,1569666478,"Hi guys,

I'd like to share another PyTorch related project some of you (hopefully) will find helpful and interesting. [Here](https://github.com/szymonmaszke/torchfunc) is GitHub repository and [here](https://szymonmaszke.github.io/torchfunc/) is documentation. Now, description (taken from project's readme with minor adjustments):

# What is it?

[**torchfunc**](https://szymonmaszke.github.io/torchfunc/) is library revolving around [PyTorch](https://pytorch.org/) with a goal to help you with:


* Improving and analysing performance of your neural network (e.g. Tensor Cores compatibility)
* Record/analyse internal state of `torch.nn.Module` as data passes through it
* Do the above based on external conditions (using single `Callable` to specify it)
* Day-to-day neural network related duties (model size, seeding, performance measurements etc.)
* Get information about your host operating system, CUDA devices and others

# Quick examples

### Get instant performance tips about your module. All problems described by comments will be shown by `torchfunc.performance.tips`:

    class Model(torch.nn.Module):
        def __init__(self):
            super().__init__()
            self.convolution = torch.nn.Sequential(
                torch.nn.Conv2d(1, 32, 3),
                torch.nn.ReLU(inplace=True),  # Inplace may harm kernel fusion
                torch.nn.Conv2d(32, 128, 3, groups=32),  # Depthwise is slower in PyTorch
                torch.nn.ReLU(inplace=True),  # Same as before
                torch.nn.Conv2d(128, 250, 3),  # Wrong output size for TensorCores
            )

            self.classifier = torch.nn.Sequential(
                torch.nn.Linear(250, 64),  # Wrong input size for TensorCores
                torch.nn.ReLU(),  # Fine, no info about this layer
                torch.nn.Linear(64, 10),  # Wrong output size for TensorCores
            )

        def forward(self, inputs):
            convolved = torch.nn.AdaptiveAvgPool2d(1)(self.convolution(inputs)).flatten()
            return self.classifier(convolved)

    # All you have to do
    print(torchfunc.performance.tips(Model()))

### Seed globaly (including `numpy` and `cuda`), freeze weights, check inference time and model size:

    # Inb4 MNIST, you can use any module with those functions
    model = torch.nn.Linear(784, 10)
    torchfunc.seed(0)
    frozen = torchfunc.module.freeze(model, bias=False)

    with torchfunc.Timer() as timer:
      frozen(torch.randn(32, 784)
      print(timer.checkpoint()) # Time since the beginning
      frozen(torch.randn(128, 784)
      print(timer.checkpoint()) # Since last checkpoint
      
    print(f""Overall time {timer}; Model size: {torchfunc.sizeof(frozen)}"")


### Record and sum per-layer and per-neuron activation statistics as data passes through network:

    # Still MNIST but any module can be put in it's place
    model = torch.nn.Sequential(
        torch.nn.Linear(784, 100),
        torch.nn.ReLU(),
        torch.nn.Linear(100, 50),
        torch.nn.ReLU(),
        torch.nn.Linear(50, 10),
    )
    # Recorder which sums all inputs to layers
    recorder = torchfunc.hooks.recorders.ForwardPre(reduction=lambda x, y: x+y)
    # Record only for torch.nn.Linear
    recorder.children(model, types=(torch.nn.Linear,))
    # Train your network normally (or pass data through it)
    ...
    # Activations of all neurons of first layer! 
    print(recorder[1]) # You can also post-process this data easily with apply

# Installation

## [pip](&lt;https://pypi.org/project/torchfunc/&gt;)

### Latest release:

```
pip install --user torchfunc
```

### Nightly:

```
pip install --user torchfunc-nightly
```

### One could also check the project out with Docker, see more info in README as this post is getting long I guess

__BTW.__ There is also another project of mine [torchdata](https://github.com/szymonmaszke/torchdata) revolving around data processing with PyTorch, might be of interest to some of you as well (it was announced one week ago here as well, but in case you missed)",9,144,False,self,,,,,
1511,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,19,daeflb,self.MachineLearning,[News] Got Machine Learning expertise to share with the Data Science and AI community in India? (ODSC India 2020 CFP),https://www.reddit.com/r/MachineLearning/comments/daeflb/news_got_machine_learning_expertise_to_share_with/,yourdigitalvoice,1569667258," ODSC India is looking for speakers for the 2020 conference in Bengaluru, India. If you've got an innovative application or cutting edge insights into Machine Learning, you should check it out. It's a great way to engage with the community and share your knowledge! **Proposal submissions close on October 9**. [https://confng.in/ySfDg6gX](https://confng.in/ySfDg6gX)

Conference Focus Areas:

* AI for Engineers
* Open Data Science
* Data Visualization
* Machine Learning &amp; Deep Learning
* Data Science at Scale
* Data Science Kick Start
* Math Behind AI
* Data Management
* DataOps

Conference dates: 16-19 September, 2020

\[News\]",0,0,False,self,,,,,
1512,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,20,daentw,self.MachineLearning,What is a solenoid coil?,https://www.reddit.com/r/MachineLearning/comments/daentw/what_is_a_solenoid_coil/,uflowindia,1569669003,[removed],0,1,False,https://b.thumbs.redditmedia.com/dJSbXu-TLILs4r6C-lmQiP85q0NQxo3_6k4-OH-Z-Ow.jpg,,,,,
1513,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,20,daf16h,self.MachineLearning,Industry Labs where you can make a PhD,https://www.reddit.com/r/MachineLearning/comments/daf16h/industry_labs_where_you_can_make_a_phd/,Internal_Mark,1569671680,"Hi,

I was wondering what companies offer the possibility of making a PhD with them, even if it is somehow in partnership with an university.

For example in Paris I know about the Cifre program that applies to FAIR. I think that in the Bosch Center for AI the also give that possibility.

Do you know other examples of labs where you can make a PhD in the company? I am especially interested in Europe.

Thanks!",0,1,False,self,,,,,
1514,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,22,dafyb5,self.MachineLearning,[D] Any idea when the code will be releasing for FSGAN: Subject Agnostic Face Swapping and Reenactment?,https://www.reddit.com/r/MachineLearning/comments/dafyb5/d_any_idea_when_the_code_will_be_releasing_for/,cbsudux,1569677170,[removed],0,1,False,self,,,,,
1515,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,22,dag54e,youtube.com,Multi-Agent Hide and Seek,https://www.reddit.com/r/MachineLearning/comments/dag54e/multiagent_hide_and_seek/,MoistPurchase,1569678193,,0,1,False,https://a.thumbs.redditmedia.com/UreQa8MZRISh9PTEwqoj0FZh3Svz5jQ2jhx3sUYKm_8.jpg,,,,,
1516,MachineLearning,t5_2r3gv,2019-9-28,2019,9,28,23,dagnlq,self.MachineLearning,Using a single network for multiple resolutions without retraining,https://www.reddit.com/r/MachineLearning/comments/dagnlq/using_a_single_network_for_multiple_resolutions/,Visionioso,1569680799,"So the problem that I have repeats itself across multiple scales. Meaning that the same thing that happens in 64X64 happens in 1024X1024. So I want to know if it is possible to train it at a low resolution then some how scale the network or multiply it for use at higher resolutions without having to retrain it again for each resolution.

Also the resolutions scale quadratically.",0,1,False,self,,,,,
1517,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,0,dah8io,self.MachineLearning,From snake oil salesmen to Legit guys: A genuinely blockbuster ML course,https://www.reddit.com/r/MachineLearning/comments/dah8io/from_snake_oil_salesmen_to_legit_guys_a_genuinely/,mjenkins_eng,1569683574,"Hi folks,

Ive been lurking on this sub for long. I caught on to a ...erm...certain YouTuber as a fake guy the moment he posted his first BS video (this was back when I was in my bachelors and I am working in the field now thanks to some amazing professors through the years ).


While I protested how fake this guy was , all I got from people around me was you just want to be different and think its cool to hate on someone trying their best to take ML to the masses .....then recently when it all blew up on his face : I absolutely love the fact that reddit was not fooled over the years


Now moving on , theres generally no appreciation for people who try legit stuff.

This is NOT an advertisement of me. Nor am I in anyway connected to this person . But do checkout the ML course of Prof. Kilian Weinberger from Cornell. The fact that he has only 2k subscribers despite having the best ML course on YouTube is a disgrace. Show him some love. 


As a person whos worked for over 2 years in the field and in the process of a PhD application, Killians course absolutely made me fall in love with ML again (been getting a bit disillusioned as *everyone* is an ML person these days). Killians course taught me that despite all the basic people skimming the surface for money, ML is incredibly complex and cannot be learned in 2 minutes . This is exactly why Killian is the best (imo): he does not dilute the math one bit. Instead he patiently and logically solves it with you",0,1,False,self,,,,,
1518,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,0,dahey9,self.MachineLearning,Why my TSNE plots of latent space form a VAE are overlapping even tho I am getting good generations?,https://www.reddit.com/r/MachineLearning/comments/dahey9/why_my_tsne_plots_of_latent_space_form_a_vae_are/,irishabh__,1569684443,[removed],0,1,False,https://a.thumbs.redditmedia.com/1EeFpZLNGEPGoHgWANZ9twwuTDvjiJOsuj-Ki5ZLpl0.jpg,,,,,
1519,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,0,dahgnd,self.MachineLearning,Why my TSNE plots of latent space from a VAE are overlapping even tho I am getting good generations?,https://www.reddit.com/r/MachineLearning/comments/dahgnd/why_my_tsne_plots_of_latent_space_from_a_vae_are/,irishabh__,1569684661,[removed],0,1,False,https://b.thumbs.redditmedia.com/ypQBAFKdDCLgaytxOG_wr9XPN6HBLs6wINzFkcJKd2A.jpg,,,,,
1520,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,1,dai3sn,youtube.com,How to Fix : File Is Too Large For The Destination File System,https://www.reddit.com/r/MachineLearning/comments/dai3sn/how_to_fix_file_is_too_large_for_the_destination/,dieucelvar,1569687638,,0,1,False,https://b.thumbs.redditmedia.com/BXLz5zGJQqjokSGP6q_r8qQItvXdvQuMuP35XoEKkxQ.jpg,,,,,
1521,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,1,daifn6,self.MachineLearning,Read tables from pdf. Tables which have no grid on them but are in proper format.,https://www.reddit.com/r/MachineLearning/comments/daifn6/read_tables_from_pdf_tables_which_have_no_grid_on/,piyushgandhi811,1569689156,[removed],0,1,False,self,,,,,
1522,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,2,daisun,self.MachineLearning,I got interview in a week with a reputable company. Give me best resources to prepare for statistics and probability.,https://www.reddit.com/r/MachineLearning/comments/daisun/i_got_interview_in_a_week_with_a_reputable/,waheed0332,1569690785,[removed],0,1,False,self,,,,,
1523,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,3,dajk9a,self.MachineLearning,[D] How important a consideration is the movement of scores above the decision boundary when evaluating an ML model.,https://www.reddit.com/r/MachineLearning/comments/dajk9a/d_how_important_a_consideration_is_the_movement/,CrypticSplicer,1569694188,"As a contrived example for this post, lets say that I have a model that takes as input a menu item and returns whether or not that item is cheesy.

My teams purpose is to serve the decisions of an ML model we built to other teams. My TL inherited the role after working mostly on the serving side of the team and does not have any ML background or experience. I'm currently attempting to submit a model that I've evaluated online. I've found it to be about a 5% decision change with a 2:1 win loss ratio. Going back to our example, for every type of menu item (pasta, cake, salad, pizza, etc.) it is either a neutral or positive change. My TL is refusing to allow me to submit because for one specific vertical, let's say its salad menu items, the score has dropped on average by 0.05 (with output ranging between 0 and 1). We are slightly positive on salad menu items, so the behavior above the decision boundary at 0.5 is still correctly assessing the cheesiness of the salads.

I personally don't think this is a reason to hold back submitting the model. We've identified it as a trend, we'll watch it in the future, and I've outlined how the following work I plan to do will address some of the unique aspects of this data slice that is causing problems. My belief is that focusing too hard on the scores above the decision boundary is a red herring, that it's useful information for future work but not an important factor when evaluating the submission of this model. I'm struggling to convince my TL though. Does anyone have any additional perspective on this? Can anyone point me to reading on this topic or provide a more concise and compelling argument than I can?",0,1,False,self,,,,,
1524,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,3,dak4ym,arxiv.org,[R] Recurrent Independent Mechanisms,https://www.reddit.com/r/MachineLearning/comments/dak4ym/r_recurrent_independent_mechanisms/,rtk25,1569696852,,9,12,False,default,,,,,
1525,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,4,dakmfj,self.MachineLearning,Top 10 Best Artificial Intelligence Apps for Android and iOS,https://www.reddit.com/r/MachineLearning/comments/dakmfj/top_10_best_artificial_intelligence_apps_for/,subhadipml,1569698983,[removed],0,1,False,self,,,,,
1526,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,4,dakyoy,theregister.co.uk,Siraj is in deep trouble as the fiasco gets published everywhere.,https://www.reddit.com/r/MachineLearning/comments/dakyoy/siraj_is_in_deep_trouble_as_the_fiasco_gets/,sobhanhag,1569700474,,0,1,False,default,,,,,
1527,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,5,dal87c,self.MachineLearning,Question about self adapting Neural Network,https://www.reddit.com/r/MachineLearning/comments/dal87c/question_about_self_adapting_neural_network/,darkrubiks,1569701711,[removed],0,1,False,self,,,,,
1528,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,5,dal8x6,openreview.net,Reducing Transformer Depth on Demand with Structured Dropout,https://www.reddit.com/r/MachineLearning/comments/dal8x6/reducing_transformer_depth_on_demand_with/,actualsnapshot,1569701812,,0,1,False,https://b.thumbs.redditmedia.com/M6z7lt3X9o9rhh5EoEYi5953Zr9tnBwXcvOZL5rPWzk.jpg,,,,,
1529,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,5,dalqw9,self.MachineLearning,How to start with machine learning,https://www.reddit.com/r/MachineLearning/comments/dalqw9/how_to_start_with_machine_learning/,omarjakmira,1569704159,[removed],0,1,False,self,,,,,
1530,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,6,dalsq8,github.com,Using temporal convolution to detect Audio DeepFakes,https://www.reddit.com/r/MachineLearning/comments/dalsq8/using_temporal_convolution_to_detect_audio/,posix_life,1569704432,,0,1,False,https://b.thumbs.redditmedia.com/-b6fvwSNH_4ls3s-k3yUlFNDQRNQ7aesvMSSDEd0VnM.jpg,,,,,
1531,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,6,dalszx,self.MachineLearning,"Anyone else finds the word ""variational"" e.g. in variational inference incredibly overused/pretentious?",https://www.reddit.com/r/MachineLearning/comments/dalszx/anyone_else_finds_the_word_variational_eg_in/,fatbelly420,1569704469,[removed],0,1,False,self,,,,,
1532,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,6,daltac,medium.com,Why Kaggle Is Not Inclusive and How to Improve It.,https://www.reddit.com/r/MachineLearning/comments/daltac/why_kaggle_is_not_inclusive_and_how_to_improve_it/,Lordobba,1569704506,,0,1,False,https://a.thumbs.redditmedia.com/vs88m9RKXLEeNdYudrkLbPFJWHh_ck4RWeSvhCa9d-8.jpg,,,,,
1533,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,6,dalzwg,youtu.be,Neural Networks (Deep Learning) - Introduction,https://www.reddit.com/r/MachineLearning/comments/dalzwg/neural_networks_deep_learning_introduction/,EddyTheDad,1569705413,,0,1,False,default,,,,,
1534,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,6,damdls,youtube.com,Gb whatsapp latest version 9.62 2019| how to download latest version of Gb whatsapp 100% anti ban,https://www.reddit.com/r/MachineLearning/comments/damdls/gb_whatsapp_latest_version_962_2019_how_to/,dieucelvar,1569707315,,2,1,False,https://b.thumbs.redditmedia.com/u8YTbW7AjVVUvr0EppHCzhr7LORKRnodH7C2Tp3BRTo.jpg,,,,,
1535,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,6,damecs,openreview.net,Artificial Design: Modeling Artificial Super Intelligence with Extended General Relativity and Universal Darwinism via Geometrization for Universal Design Automation,https://www.reddit.com/r/MachineLearning/comments/damecs/artificial_design_modeling_artificial_super/,openaievolution,1569707434,,54,183,False,https://b.thumbs.redditmedia.com/M6z7lt3X9o9rhh5EoEYi5953Zr9tnBwXcvOZL5rPWzk.jpg,,,,,
1536,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,6,damhtu,arxiv.org,[1909.11825] Unsupervised Domain Adaptation through Self-Supervision,https://www.reddit.com/r/MachineLearning/comments/damhtu/190911825_unsupervised_domain_adaptation_through/,openaievolution,1569707933,,4,6,False,default,,,,,
1537,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,7,damkg0,arxiv.org,"[R] Read, Attend and Comment: A Deep Architecture for Automatic News Comment Generation",https://www.reddit.com/r/MachineLearning/comments/damkg0/r_read_attend_and_comment_a_deep_architecture_for/,downtownslim,1569708284,,8,16,False,default,,,,,
1538,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,7,damni0,self.MachineLearning,[D] What are your favorite research blogs that discusses advanced ML topics ?,https://www.reddit.com/r/MachineLearning/comments/damni0/d_what_are_your_favorite_research_blogs_that/,__Julia,1569708743,"Hi,

I was a big fan of [Medium ](https://towardsdatascience.com/data-science/home) few years ago. However, I have noticed that it contains a lot of noise recently. I am trying to refresh my list of blogs that I follow, the idea is to focus on blogs that features advanced ML topics such [distill.pub](https://distill.pub),  [thegradient.pub](https://thegradient.pub), [ruder.io](https://ruder.io), [Kapathy blog](http://karpathy.github.io/). Some labs blogs such [bair berkeley](https://bair.berkeley.edu/blog/), [facebook](https://ai.facebook.com/blog/), [google AI](https://ai.google/), [openai](https://openai.com/blog/), [deepmind](https://deepmind.com/blog). In addition to r/MachineLearning, which blogs do you usually follow?

For those who are interested about engineering blogs, [this is a good list of engineering blogst](https://github.com/kilimchoi/engineering-blogs)",42,155,False,self,,,,,
1539,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,8,dankk2,self.MachineLearning,Best way to learn distance metric learning?,https://www.reddit.com/r/MachineLearning/comments/dankk2/best_way_to_learn_distance_metric_learning/,nooob_Master_69,1569713623,"I am currently working on the topic and I have found papers that have different options about what are the necessary topics to domain to understand distance metric learning. Obviously metric spaces are a good start, but a look into the big picture would be very helpful for me.",0,1,False,self,,,,,
1540,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,8,dannmf,self.MachineLearning,Are there any good models for automated essay scoring that assess both content and structure/cohesion?,https://www.reddit.com/r/MachineLearning/comments/dannmf/are_there_any_good_models_for_automated_essay/,[deleted],1569714095,,0,1,False,default,,,,,
1541,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,9,danv2v,self.MachineLearning,[D] Are there any good models for automated essay scoring that assess both content and structure/cohesion?,https://www.reddit.com/r/MachineLearning/comments/danv2v/d_are_there_any_good_models_for_automated_essay/,Mystery3434,1569715242,[removed],0,1,False,self,,,,,
1542,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,9,danwpk,self.MachineLearning,PUBG Machine Learning - Neural Network to classify whether a player survives until the next safe zone,https://www.reddit.com/r/MachineLearning/comments/danwpk/pubg_machine_learning_neural_network_to_classify/,ryanp102694,1569715531,[removed],0,1,False,self,,,,,
1543,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,9,dao1s6,self.MachineLearning,[P] PUBG Neural Network - Predict who lives until the next game phase,https://www.reddit.com/r/MachineLearning/comments/dao1s6/p_pubg_neural_network_predict_who_lives_until_the/,ryanp102694,1569716289,"Let me know what you think, my first attempt at applying machine learning and I am not an expert. I took advantage of an existing replay application, which I extended to overlay predictions. [http://pubgmachinelearning.com](http://pubgmachinelearning.com)

The ""Machine Learning"" link on the page will show my process, I would love to hear from more knowledgeable people how it can be improved.",21,36,False,self,,,,,
1544,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,9,dao9qn,self.MachineLearning,Isolated Recommendar System?,https://www.reddit.com/r/MachineLearning/comments/dao9qn/isolated_recommendar_system/,Stephanehk,1569717461,[removed],0,1,False,self,,,,,
1545,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,9,daobgp,self.MachineLearning,"Incel Or Not, a Deep Learning project",https://www.reddit.com/r/MachineLearning/comments/daobgp/incel_or_not_a_deep_learning_project/,manoflogos,1569717722,[removed],0,1,False,self,,,,,
1546,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,10,daom3a,openreview.net,TinyBERT: Distilling BERT for Natural Language Understanding,https://www.reddit.com/r/MachineLearning/comments/daom3a/tinybert_distilling_bert_for_natural_language/,I_ai_AI,1569719379,,13,33,False,https://b.thumbs.redditmedia.com/M6z7lt3X9o9rhh5EoEYi5953Zr9tnBwXcvOZL5rPWzk.jpg,,,,,
1547,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,10,daos62,self.MachineLearning,multi-channel attention,https://www.reddit.com/r/MachineLearning/comments/daos62/multichannel_attention/,altair_90,1569720340,"Hi, I have data which is 64 \* 64 \* 8 (Height \* width \* channel). I need to to apply attention on the input directly prior to any convolution and pooling. Specifically, I am trying to apply attention on each channel. If I apply attention on each of the 8 channels and then sum them up to get the attention of each pixels of the 64 \* 64 data, then is there any issue with the summation mathematically? Can anyone please help me validate the approach?",0,1,False,self,,,,,
1548,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,10,daoygp,self.MachineLearning,When should I use VGG19 rather than VGG16(if computational power is not a concern)?,https://www.reddit.com/r/MachineLearning/comments/daoygp/when_should_i_use_vgg19_rather_than_vgg16if/,BetterLife_Project,1569721331,[removed],0,1,False,self,,,,,
1549,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,13,daqisx,telegraph.co.uk,[N] AI used for first time in job interviews in UK to find best applicants [face-reading],https://www.reddit.com/r/MachineLearning/comments/daqisx/n_ai_used_for_first_time_in_job_interviews_in_uk/,phobrain,1569730719,,0,1,False,https://b.thumbs.redditmedia.com/BmuMrvKqWwzyN5Sw4G0lSnu-RW0kc8ukp21dYV1jC-o.jpg,,,,,
1550,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,13,daqou0,self.MachineLearning,[D] Code for Neural Style-Preserving Visual Dubbing,https://www.reddit.com/r/MachineLearning/comments/daqou0/d_code_for_neural_stylepreserving_visual_dubbing/,cbsudux,1569731827,When will the authors release the code?,0,0,False,self,,,,,
1551,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,13,daqs3q,i.redd.it,Yolo v3 running on phone.,https://www.reddit.com/r/MachineLearning/comments/daqs3q/yolo_v3_running_on_phone/,thesonyman101,1569732451,,0,1,False,https://a.thumbs.redditmedia.com/My-wnuWbYuUNV-w3BbBDk8O1_6wkMuatuZ0XYX-WoT8.jpg,,,,,
1552,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,13,daqtrf,youtube.com,Automatic Bottle Cartoning Machine to Pack Tablets Bottle Inside A Carto...,https://www.reddit.com/r/MachineLearning/comments/daqtrf/automatic_bottle_cartoning_machine_to_pack/,amygao1984,1569732777,,0,1,False,default,,,,,
1553,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,14,darb55,labroots.com,AI Exponentially Accelerates Drug Development,https://www.reddit.com/r/MachineLearning/comments/darb55/ai_exponentially_accelerates_drug_development/,tahutahut,1569736171,,0,1,False,https://a.thumbs.redditmedia.com/javacwZ-TzdoDUEfCmksrfZMgX7KSMxvgjoHGoWedp8.jpg,,,,,
1554,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,15,darktm,arxiv.org,UNITER: Learning UNiversal Image-TExt Representations,https://www.reddit.com/r/MachineLearning/comments/darktm/uniter_learning_universal_imagetext/,abhshkdz,1569738186,,1,1,False,default,,,,,
1555,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,15,darmbi,arxiv.org,[R] UNITER: Learning UNiversal Image-TExt Representations,https://www.reddit.com/r/MachineLearning/comments/darmbi/r_uniter_learning_universal_imagetext/,abhshkdz,1569738508,,2,10,False,default,,,,,
1556,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,16,das8m2,kdnuggets.com,Webinar: Build auto-adaptive machine learning models with Kubernetes - KDnuggets,https://www.reddit.com/r/MachineLearning/comments/das8m2/webinar_build_autoadaptive_machine_learning/,Mayalittlepony,1569743266,,0,1,False,https://a.thumbs.redditmedia.com/m1xrJsPiqX0NJD0K0EIBkKHwj9JgmMb4dmNAO3oUyS8.jpg,,,,,
1557,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,17,dascfk,self.MachineLearning,Improved Hypergradient based optimizers,https://www.reddit.com/r/MachineLearning/comments/dascfk/improved_hypergradient_based_optimizers/,harshalmittal4,1569744140,"This work tries improvements to the existing 'Hypergradient' based optimizers proposed in the paper [Online Learning Rate Adaptation with Hypergradient Descent](https://arxiv.org/pdf/1703.04782.pdf).

We expect that the hypergradient based learning rate update could be more accurate and aim to exploit the gains much better by boosting the learning rate updates with momentum and adaptive gradients, experimenting with

1. Hypergradient descent with momentum, and
2. Adam with Hypergradient,

alongside the model optimizers SGD, SGD with Nesterov(SGDN) and Adam.

The new optimizers are compared with their resepective hypergradient-descent baselines and provide advantages such as better generalization and faster convergence for the loss function. The code and the results of our experiments are available at [https://github.com/harshalmittal4/Hypergradient\_variants](https://github.com/harshalmittal4/Hypergradient_variants).",1,1,False,self,,,,,
1558,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,18,dassn0,self.MachineLearning,Learn EDA,https://www.reddit.com/r/MachineLearning/comments/dassn0/learn_eda/,kumar9450suraj,1569747742,"Can anybody help me with EDA?
I have completed couple of courses covering machine learning. They cover basic workflow and models . But they told pointless graph and EDA . They didn't tell why they did what they did. How they infer insight form given data. How to engineer features with the help of graph or any other way. How to find relationships between features and remove multicollinearity . What are the some transformation that can be done on given data?

I can apply models .Sure . But without EDA model is useless.

What are some tools that i can use to find to visualise data?

Please help . Any courses , any books , advice how to move forward and get around this problem ......

Anything related to EDA will help",0,1,False,self,,,,,
1559,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,18,dasyy6,self.MachineLearning,The Complete Data Science Project Management Course,https://www.reddit.com/r/MachineLearning/comments/dasyy6/the_complete_data_science_project_management/,HannahHumphreys,1569749090,[removed],0,1,False,self,,,,,
1560,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,18,dat1cm,self.MachineLearning,[D] Where can I find machine learning competitions apart from Kaggle?,https://www.reddit.com/r/MachineLearning/comments/dat1cm/d_where_can_i_find_machine_learning_competitions/,roughcall19,1569749610,,0,1,False,self,,,,,
1561,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,19,dati2y,self.MachineLearning,Evaluaue classifier,https://www.reddit.com/r/MachineLearning/comments/dati2y/evaluaue_classifier/,Isabellamisha,1569753113,"Consider a classifier which detects the cheating insurance claims out of all the claims (the classifier detects the cheating claims as a positive class). Knowing the fact that paying an expert to check the classifier outputs is less expensive than paying for a false claim, which measure should be prioritized for evaluating the classifier:

1- precision 

2- recall 

3- both have the same importance in this problem",0,1,False,self,,,,,
1562,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,20,datyr1,self.MachineLearning,[P] I scraped career statistics of Tour de France starters and used an LSTM network to predict their end of career,https://www.reddit.com/r/MachineLearning/comments/datyr1/p_i_scraped_career_statistics_of_tour_de_france/,Gebo_vending,1569756545,"The notebooks can be found here: [https://github.com/quickcoffee/TDF-Starters-RUL](https://github.com/quickcoffee/TDF-Starters-RUL)

Let me know what you think, it's my first project with web scraping and neural networks :)",44,149,False,self,,,,,
1563,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,20,dau2vs,self.MachineLearning,[Project] Implementing Improvements to Hypergradient optimizers,https://www.reddit.com/r/MachineLearning/comments/dau2vs/project_implementing_improvements_to/,harshalmittal4,1569757360,"We try improvements to the existing 'Hypergradient' based optimizers proposed in the paper [Online Learning Rate Adaptation with Hypergradient Descent](https://arxiv.org/pdf/1703.04782.pdf).

We expect that the hypergradient based learning rate update could be more accurate and aim to exploit the gains much better by boosting the learning rate updates with momentum and adaptive gradients, experimenting with

1. Hypergradient descent with momentum, and
2. Adam with Hypergradient,

alongside the model optimizers SGD, SGD with Nesterov(SGDN) and Adam.

The new optimizers are compared with their resepective hypergradient-descent baselines and provide advantages such as better generalization and faster convergence for the loss function. The code and the results of our experiments are available at [https://github.com/harshalmittal4/Hypergradient\_variants](https://github.com/harshalmittal4/Hypergradient_variants).",6,11,False,self,,,,,
1564,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,21,dauc3a,self.MachineLearning,Lex Fridman has deleted all Siraj Raval content ,https://www.reddit.com/r/MachineLearning/comments/dauc3a/lex_fridman_has_deleted_all_siraj_raval_content/,S_0ci0path,1569759053,[removed],0,1,False,self,,,,,
1565,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,23,davs6q,self.MachineLearning,Best ways to learn machine learning?,https://www.reddit.com/r/MachineLearning/comments/davs6q/best_ways_to_learn_machine_learning/,just_me_again123,1569767136,[removed],0,1,False,self,,,,,
1566,MachineLearning,t5_2r3gv,2019-9-29,2019,9,29,23,daw6kt,youtube.com,"Using Machine Learning to detect handguns being held by a person, not in holster - SmarterEveryDay [12:55]",https://www.reddit.com/r/MachineLearning/comments/daw6kt/using_machine_learning_to_detect_handguns_being/,misconfig_exe,1569769028,,0,1,False,https://b.thumbs.redditmedia.com/s3YxavklM_dGnn4amGTbnPMmRFRxgGIWqTOOt_sWrek.jpg,,,,,
1567,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,0,dawcbu,self.MachineLearning,"[P] Using Machine Learning to detect handguns being held by a person, not in holster - SmarterEveryDay [video 12:55]",https://www.reddit.com/r/MachineLearning/comments/dawcbu/p_using_machine_learning_to_detect_handguns_being/,misconfig_exe,1569769733,"Destin posted an video on using Machine Learning to analyze (surveillance) video for guns being held by a person. 

Very interesting discussion on training the system, and the challenge of reducing false-positives as people hold cellphones in a similar way to how someone would hold a gun. Also on privacy, regarding the decision to _not_ look for concealed carry.

&gt; ###We built a gun detector using machine learning that works with existing surveillance cameras.

&gt; There are many companies working on this type of technology at the moment.  We made ours in 2018, and Chad visited my house in January 2019 to film most of this.  We didn't post it for various reasons, but decided now might be a good time.  The fidelity of the inference is a function of how you train it.... so obviously the more data points you provide, the better it will perform.  This particular type of machine learning is known as object detection, with the computation being performed by a deep neural network ""on the edge"".  The video stream is processed locally and no internet is needed to find the object in real time. If you're working on something similar or could use this technology in your systems and would like to collaborate.... (or would simply like to support what we're doing) please reach out by using this link: https://www.lantern.systems/gun-detector

https://www.youtube.com/watch?v=Lh0x54GC1sw",47,97,False,self,,,,,
1568,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,1,dax425,nextsides.com,What Is Python? Python Uses,https://www.reddit.com/r/MachineLearning/comments/dax425/what_is_python_python_uses/,qadeer0n,1569773158,,0,1,False,https://b.thumbs.redditmedia.com/XqVLxxyBNvcLvXf-uYId4GpULoPDardk_uXCzsRgRfo.jpg,,,,,
1569,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,1,dax7tn,youtu.be,Destin Sandlin from Smarter Every Day presents an algorithm that might be useful to prevent school shootings,https://www.reddit.com/r/MachineLearning/comments/dax7tn/destin_sandlin_from_smarter_every_day_presents_an/,TimFooler_Brad,1569773632,,0,1,False,default,,,,,
1570,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,2,day7cs,arxiv.org,[R] On Model Stability as a Function of Random Seed,https://www.reddit.com/r/MachineLearning/comments/day7cs/r_on_model_stability_as_a_function_of_random_seed/,kakoosman,1569777988,,5,20,False,default,,,,,
1571,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,3,dayol0,self.MachineLearning,"[D] Automated news comment generation - Seriously guys, I think we need some kind of researcher code of ethics",https://www.reddit.com/r/MachineLearning/comments/dayol0/d_automated_news_comment_generation_seriously/,[deleted],1569780061,[deleted],0,1,False,default,,,,,
1572,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,3,daypa1,youtube.com,"I made a video about perceptron, which is a single layer neural network in C# with a step by step example",https://www.reddit.com/r/MachineLearning/comments/daypa1/i_made_a_video_about_perceptron_which_is_a_single/,lacaai,1569780140,,0,1,False,https://a.thumbs.redditmedia.com/No7YJ9Q_iM5AWVI8RLOiFleJdzlmBSi5fREPMJsXc48.jpg,,,,,
1573,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,3,daz4o7,self.MachineLearning,"A deep architecture for news content generation - seriously guys, don't we need a new researcher code of ethics",https://www.reddit.com/r/MachineLearning/comments/daz4o7/a_deep_architecture_for_news_content_generation/,Gorpovitch,1569782023,"[https://arxiv.org/abs/1909.11974v1](https://arxiv.org/abs/1909.11974v1)

Writing my first reddit post for this...

The research is unsurprisingly directly funded by the chinese government, by the same grant that went to e.G. a research paper on predicting unrest news amount prediction from newspaper's data using the GEDLT dataset, or a paper on social network alignment (linking identical users accross different social networks).

Of course, the applications cited in the article only talk about how they  ""enable commenting service for a news website from cold start, enhance the reading experience for less commented news articles"" (sic) and not about nationwide political manipulation. The results of the papers are quite impressive - half of the generated comments are apparently described as ""Highly relevant with meaningful ideas"" by human judges.

The co-authors include two people from Microsoft Research in Beijing. The paper will be presented at EMNLP. I'd be interested to know if anyone there talk to them ? What they think about it, if they have thought about the potential consequences of their work? They will even publish their code.",0,1,False,self,,,,,
1574,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,3,daz8op,self.MachineLearning,Cuda error in rapids on google colab,https://www.reddit.com/r/MachineLearning/comments/daz8op/cuda_error_in_rapids_on_google_colab/,Antoine-Assaf15,1569782490,[removed],0,1,False,self,,,,,
1575,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,3,daza5a,self.MachineLearning,A deep architecture for automatic news comment generation - straight from Beijing,https://www.reddit.com/r/MachineLearning/comments/daza5a/a_deep_architecture_for_automatic_news_comment/,Gorpovitch,1569782662," [https://arxiv.org/abs/1909.11974v1](https://arxiv.org/abs/1909.11974v1)

Writing my first reddit post for this... I don't understand how this is considered ethical research.

The research is unsurprisingly directly funded by the chinese government, by the same grant that went to e.G. a research paper on predicting unrest news amount prediction from newspaper's data using the GEDLT dataset, or a paper on social network alignment (linking identical users accross different social networks).

Of course, the applications cited in the article only talk about how they ""enable commenting service for a news website from cold start, enhance the reading experience for less commented news articles"" (sic) and not about nationwide political manipulation. The results of the papers are quite impressive - half of the generated comments are apparently described as ""Highly relevant with meaningful ideas"" by human judges.

The co-authors include two people from Microsoft Research in Beijing. The paper will be presented at EMNLP. I'd be interested to know if anyone there talk to them ? What they think about it, if they have thought about the potential consequences of their work? They will even publish their code.",0,1,False,self,,,,,
1576,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,3,dazexx,self.MachineLearning,Whats going wrong?,https://www.reddit.com/r/MachineLearning/comments/dazexx/whats_going_wrong/,A-pan-weeb,1569783240,"hi all, noob here. im working on a small school project in python and am failing miserably. i am trying my best, but i have no clue whats happening with my train() function and don't know why my cost wont go bellow 0.25. any help would be much appreciated. also, im kinda new to python so my codes a bit of a mess. also, the reason im not using numpy and writing all the functions myself if because my school requires me to use a wierd version of python to run on a microbit.

&amp;#x200B;

    import random
    import math
    
    training_input = [[1, 0, 0, 1], [0, 1, 1, 1], [0, 0, 0, 1], [1, 1, 1, 0]]
    training_output = [1, 0, 0, 1]
    
    syn0 = [[random.random() for i in range(4)] for i in range(4)]
    syn1 = [[random.random() for i in range(4)] for i in range(1)]
    
    bias0 = [random.random() for i in range(4)]
    bias1 = [random.random() for i in range(1)]
    
    random.seed()
    
    def matrix_multiply(matrix, vector):
        result = [0]*len(matrix)
        for i in range(len(matrix)):
            for ii in range(len(matrix[i])):
                result[i]+=vector[ii]*matrix[i][ii]
        return result
    
    def sigmoid(num, deriv=False):
        return 1/(1+math.exp(-num))
    
    def sigmoid_p(x):
        return sigmoid(x) * (1-sigmoid(x))
    
    def add_bias(vector, bias):
        result = vector
        for i in range(len(vector)):
            result[i] += bias[i]
        return result
    
    def transpose(matrix):
        return [[matrix[c][r] for c in range(len(matrix))] for r in range(len(matrix[0]))] 
    
    def train():
        syn0 = [[random.random() for i in range(4)] for i in range(4)]
        syn1 = [[random.random() for i in range(4)] for i in range(1)]
    
        bias0 = [random.random() for i in range(4)]
        bias1 = [random.random() for i in range(1)]
    
        b = random.random()
    
        costs = []
        
        iterations = 10000
        learning_rate = 0.2
        costs = [] 
    
        print('start')
        for i in range(iterations):
            ri = random.randint(0, len(training_input) - 1)
            inp = training_input[ri]
            
            l0 = add_bias(matrix_multiply(syn0, inp), bias0)
            for ii in range(len(l0)):
                l0[ii] = sigmoid(l0[ii])
            l1 = add_bias(matrix_multiply(syn1, l0), bias1)
            for ii in range(len(l1)):
                l1[ii] = sigmoid(l1[ii])
            out = l1[0]
            pred = sigmoid(l1[0]) # networks prediction
            target = training_output[ri]
            cost = (pred - target)**2
    
            dcost_dpred = 2 * (pred - target)
            dpred_dout = sigmoid_p(out)
    
            dcost_dout = dcost_dpred * dpred_dout
            
            for r in range(len(syn0)):
                for c in range(len(syn0[r])):
                    dcost_w = dcost_dout * inp[c]
                    syn0[r][c] = syn0[r][c] - learning_rate * dcost_w
            for r in range(len(syn1)):
                for c in range(len(syn1[r])):
                    dcost_w = dcost_dout * inp[c]
                    syn1[r][c] = syn1[r][c] - learning_rate * dcost_w
            for n in range(len(bias0)):
                dcost_b = dcost_dout * inp[c]
                bias0[n] = bias0[n] - learning_rate * dcost_b
            for n in range(len(bias1)):
                dcost_b = dcost_dout * inp[c]
                bias1[n] = bias1[n] - learning_rate * dcost_b
        print('done')
    
    train()",0,1,False,self,,,,,
1577,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,4,db071o,self.MachineLearning,Max Pooling vs Dilated Convolution,https://www.reddit.com/r/MachineLearning/comments/db071o/max_pooling_vs_dilated_convolution/,krammerman,1569786599,[removed],0,1,False,self,,,,,
1578,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,4,db0951,self.MachineLearning,"Purchase ""Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow"" now or wait for new edition?",https://www.reddit.com/r/MachineLearning/comments/db0951/purchase_handson_machine_learning_with/,Myname345,1569786841,"I am currently taking a course on machine learning. I would like to purchase ""Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow"" by Oreilly. A new edition will come out in a little over two weeks. I would like to purchase the first edition now and start studying , but should I wait for the new edition? I am new to machine learning and am not sure how much has changed since 2017 when the first edition came out.",0,1,False,self,,,,,
1579,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,4,db0aqj,self.MachineLearning,"I have created a variant of neural style transfer, where you can mix two painting styles, keeping intact your content image and both the styles mixed together, opinions?",https://www.reddit.com/r/MachineLearning/comments/db0aqj/i_have_created_a_variant_of_neural_style_transfer/,irishabh__,1569787047,[removed],0,1,False,self,,,,,
1580,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,6,db16gj,self.MachineLearning,The wisdom behind policy iteration,https://www.reddit.com/r/MachineLearning/comments/db16gj/the_wisdom_behind_policy_iteration/,lijunyi95,1569790901,[removed],0,1,False,self,,,,,
1581,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,6,db17o9,self.MachineLearning,Need terminology help with machine learning searches,https://www.reddit.com/r/MachineLearning/comments/db17o9/need_terminology_help_with_machine_learning/,kdharbert,1569791038,"I have a simple machine learning algorithm to implement, but the application causes all my search results to get hijacked to other topics, so I need help with precise terminology.   
The algorithm is in two parts: scanning for discrete events in the input in real time and characterizing those events to generate an audio stream consisting of an overlay of sound samples triggered by the detected input events. Stupid simple process as machine learning is concerned, but 'audio' steers my searches into the ditch.

I'm using a-priori knowledge of the application to (I hope) smartly partition the overall algorithm into two pieces that can be implemented by different best-suited approaches.  Is there an industry name for the partition decision?  Is there a formal approach to deciding how to partition?  Is there a name for it when AI is used to decide the partitioning itself? 

The audio output algorithm will be constructed via supervised learning, but the discrete event detection will be less-so.  Is there better terminology for detecting discrete events?  I've found 'onset detection' pertaining to audio, but is there a more formal term that applies to underlying methodology that doesn't involve the application?",0,1,False,self,,,,,
1582,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,6,db19ld,self.MachineLearning,Master thesis - BERT,https://www.reddit.com/r/MachineLearning/comments/db19ld/master_thesis_bert/,skullcrusher6000,1569791285,"Hello community! I want to write my master thesis about NLP-related subject, thinking about basing my work on **BERT** deep learning model.

Maybe you know any hot topics in the game right now, where it can be used? I've been considering subject related to quesiton answering, maybe you have other ideas?",0,1,False,self,,,,,
1583,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,7,db2dti,self.MachineLearning,Not able to Prove this?,https://www.reddit.com/r/MachineLearning/comments/db2dti/not_able_to_prove_this/,KLICKBURN24,1569796534,[removed],0,1,False,self,,,,,
1584,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,7,db2nqy,self.MachineLearning,Help to identify the choice of books for comprehensive introduction to Machine Learning,https://www.reddit.com/r/MachineLearning/comments/db2nqy/help_to_identify_the_choice_of_books_for/,Vabaluba,1569797930,[removed],0,1,False,self,,,,,
1585,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,9,db3twu,towardsdatascience.com,Why Kaggle Is Not Inclusive and How to Change it,https://www.reddit.com/r/MachineLearning/comments/db3twu/why_kaggle_is_not_inclusive_and_how_to_change_it/,Lordobba,1569803904,,0,1,False,https://b.thumbs.redditmedia.com/GsFzqG3IYdOwHmXiHOY10mnscsGGGI5wPkIUsztsvNA.jpg,,,,,
1586,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,10,db44hm,youtu.be,"Why Capitalism is under attack from its own creation, Artificial Intelligence | Andrew Yang, UBI",https://www.reddit.com/r/MachineLearning/comments/db44hm/why_capitalism_is_under_attack_from_its_own/,DeepGamingAI,1569805444,,0,1,False,https://a.thumbs.redditmedia.com/uW1sXWc4Lqq5HG25RxYn60AyFv_LxLHD9K1IwLeZoS8.jpg,,,,,
1587,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,10,db4q83,self.MachineLearning,Dataset for NLP from HONY,https://www.reddit.com/r/MachineLearning/comments/db4q83/dataset_for_nlp_from_hony/,theCavemanV,1569808563,[removed],0,1,False,self,,,,,
1588,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,11,db4u0e,self.MachineLearning,[R] First time to NeurIPS,https://www.reddit.com/r/MachineLearning/comments/db4u0e/r_first_time_to_neurips/,ch3njust1n,1569809102,"What are the best venues to go to (tutorials, conference, workshops, workshop dinner, expo, conference reception)?",0,1,False,self,,,,,
1589,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,11,db4xrr,medium.com,Free (Robot) Hugs! An Embracing Multimodal Dataset,https://www.reddit.com/r/MachineLearning/comments/db4xrr/free_robot_hugs_an_embracing_multimodal_dataset/,Yuqing7,1569809640,,0,1,False,https://b.thumbs.redditmedia.com/xgnfOWHK14neAY_U8VJy6xPSC8sLwbIsDGt-V_szu2M.jpg,,,,,
1590,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,11,db4y5s,self.MachineLearning,[D] First time to NeurIPS,https://www.reddit.com/r/MachineLearning/comments/db4y5s/d_first_time_to_neurips/,ch3njust1n,1569809704,"What are the best venues to go to (tutorials, conference, workshops, workshop dinner, expo, conference reception)?",8,3,False,self,,,,,
1591,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,14,db6ug5,youtu.be,Issues with YouTube's demonetization NN,https://www.reddit.com/r/MachineLearning/comments/db6ug5/issues_with_youtubes_demonetization_nn/,technobaboo,1569820393,,0,1,False,https://b.thumbs.redditmedia.com/Rq5BGLejpMMxToAcUraijcDp5Lm8D9mXz6nZpyv-DhQ.jpg,,,,,
1592,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,15,db7buh,excavating.ai,Excavating AI - The Politics of Images in Machine Learning Training Sets,https://www.reddit.com/r/MachineLearning/comments/db7buh/excavating_ai_the_politics_of_images_in_machine/,bil-sabab,1569823554,,0,1,False,default,,,,,
1593,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,16,db869w,self.MachineLearning,[D] Why can't you guys comment your fucking code?,https://www.reddit.com/r/MachineLearning/comments/db869w/d_why_cant_you_guys_comment_your_fucking_code/,GeneralReposti_Bot,1569829524,"Seriously.

I spent the last few years doing web app development. Dug into DL a couple months ago. Supposedly, compared to the post-post-post-docs doing AI stuff, JavaScript developers should be inbred peasants. But every project these peasants release, even a fucking library that colorizes CLI output, has a catchy name, extensive docs, shitloads of comments, fuckton of tests, semantic versioning, changelog, and, oh my god, better variable names than `ctx_h` or `lang_hs` or `fuck_you_for_trying_to_understand`.

The concepts and ideas behind DL, GANs, LSTMs, CNNs, whatever  it's clear, it's simple, it's intuitive. The slog is to go through the jargon (that keeps changing beneath your feet - what's the point of using fancy words if you can't keep them consistent?), the unnecessary equations, trying to squeeze meaning from bullshit language used in papers, figuring out the super important steps, preprocessing, hyperparameters optimization that the authors, oops, failed to mention.

Sorry for singling out, but [look at this](https://github.com/facebookresearch/end-to-end-negotiator/blob/master/src/agent.py) - what the fuck? If a developer anywhere else at Facebook would get this code for a review they would throw up.

- Do you intentionally try to obfuscate your papers? Is pseudo-code a fucking premium? Can you at least try to give some intuition before showering the reader with equations?

- How the fuck do you dare to release a paper without source code?

- Why the fuck do you never ever add comments to you code?

- When naming things, are you charged by the character? Do you get a bonus for acronyms?

- Do you realize that OpenAI having needed to release a ""baseline"" TRPO implementation is a fucking disgrace to your profession?

- Jesus christ, who decided to name a tensor concatenation function `cat`?",27,20,False,self,,,,,
1594,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,17,db8c4u,self.MachineLearning,[N] UC Berkeley's CS 285: Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/db8c4u/n_uc_berkeleys_cs_285_deep_reinforcement_learning/,Bayequentist,1569830751,"[http://rail.eecs.berkeley.edu/deeprlcourse/](http://rail.eecs.berkeley.edu/deeprlcourse/) 

Lectures are recorded and live streamed

Material which will be covered: 

&gt;1. From supervised learning to decision making   
&gt;  
&gt;2. Model-free algorithms: Q-learning, policy gradients, actor-critic   
&gt;  
&gt;3. Advanced model learning and prediction   
&gt;  
&gt;4. Transfer and multi-task learning, meta-learning   
&gt;  
&gt;5. Exploration   
&gt;  
&gt;6. Open problems, research talks, invited lectures 

There's a subreddit for this course:  r/berkeleydeeprlcourse",34,344,False,self,,,,,
1595,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,17,db8di3,self.MachineLearning,[R] Neural Ordinary Differential Equations: the current landscape,https://www.reddit.com/r/MachineLearning/comments/db8di3/r_neural_ordinary_differential_equations_the/,Zymieth,1569831027,"After NeurIPS 2018 and the ""Neural Ordinary Differential Equations"" paper deep learning research has opened up tremendously in this direction and as a result it has been rather difficult to keep up with the latest advancements.
To this end I have been collecting relevant papers in the following [github repository](https://github.com/Zymrael/awesome-neural-ode). 
Feel free to contribute or suggest changes if you feel something is missing. Hope this is useful to those of you working in this area!",12,26,False,self,,,,,
1596,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,17,db8g4k,self.MachineLearning,[R] Class Feature Pyramids for Video Explanation,https://www.reddit.com/r/MachineLearning/comments/db8g4k/r_class_feature_pyramids_for_video_explanation/,Alex_Stergiou,1569831585,"
Hello everyone,


We have recently made available both the code and paper for our project on visual explanations for (spatio-temporal) 3D-CNNs named [_Class Feature Pyramids for Video Explanation_](https://arxiv.org/abs/1909.08611). Through our method we aim at highlighting the specific time and space locations in videos that different layers and neurons in the network consider informative given a specific class by the discovery of a hierarchical feature association.

ArXiv preprint [link](https://arxiv.org/abs/1909.08611)
Github repo [link](https://github.com/alexandrosstergiou/Class_Feature_Visualization_Pyramid)

This work will also be presented in the ICCV 2019 Workshop on [_Interpreting and Explaining Visual Artificial Intelligence Models_](http://xai.unist.ac.kr/workshop/2019/)

### Abstract
Deep convolutional networks are widely used in video action recognition. 3D convolutions are one prominent approach to deal with the additional time dimension. While 3D convolutions typically lead to higher accuracies, the inner workings of the trained models are more difficult to interpret. We focus on creating human-understandable visual explanations that represent the hierarchical parts of spatio-temporal networks. We introduce Class Feature Pyramids, a method that traverses the entire network structure and incrementally discovers kernels at different network depths that are informative for a specific class. Our method does not depend on the network's architecture or the type of 3D convolutions, supporting grouped and depth-wise convolutions, convolutions in fibers, and convolutions in branches. We demonstrate the method on six state-of-the-art 3D convolution neural networks (CNNs) on three action recognition (Kinetics-400, UCF-101, and HMDB-51) and two egocentric action recognition datasets (EPIC-Kitchens and EGTEA Gaze+).",0,2,False,self,,,,,
1597,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,17,db8i6o,data-flair.training,See How Machine Learning is enhancing the Future of Education,https://www.reddit.com/r/MachineLearning/comments/db8i6o/see_how_machine_learning_is_enhancing_the_future/,AnujG23,1569832030,,0,1,False,https://b.thumbs.redditmedia.com/7nKFLOScXKRSMckP0mUDoZNrJpZeu2J-sztxu6GFkBI.jpg,,,,,
1598,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,18,db8wug,self.MachineLearning,What is Docker Swarm ? Learn Docker Swarm Commands,https://www.reddit.com/r/MachineLearning/comments/db8wug/what_is_docker_swarm_learn_docker_swarm_commands/,paradisetechsoft1,1569835205,[removed],0,1,False,https://b.thumbs.redditmedia.com/W_SQxHssWoFLhok9X9MZFS5Qm_sInDHQwE6AB_Pdmws.jpg,,,,,
1599,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,18,db92ek,youtu.be,battery shrink wrapping machine battery Flexible packaging machine,https://www.reddit.com/r/MachineLearning/comments/db92ek/battery_shrink_wrapping_machine_battery_flexible/,Jochampsenarylin,1569836269,,0,1,False,https://a.thumbs.redditmedia.com/ZhEpD3FuEQUiNOu5f6AVclNjbM7xd7nhyQGLFblN_M0.jpg,,,,,
1600,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,18,db99dd,self.MachineLearning,"[P] Conditional Density Estimation Python Package and Large Benchmark with Neural Networks (MDN, KMN, Normalizing Flow) and Non-/Semi-parametric estimators",https://www.reddit.com/r/MachineLearning/comments/db99dd/p_conditional_density_estimation_python_package/,whiletrue2,1569837575,,0,1,False,default,,,,,
1601,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,19,db9q4v,medium.com,How to reduce MLflow logging overhead by using log_batch(),https://www.reddit.com/r/MachineLearning/comments/db9q4v/how_to_reduce_mlflow_logging_overhead_by_using/,iverjo,1569840439,,0,1,False,https://b.thumbs.redditmedia.com/zYqerVANZUbKc_fjZsNaNlXyBiPI63x-cX3BFSfLPOI.jpg,,,,,
1602,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,19,db9tyb,eigenfoo.xyz,Anatomy of a Probabilistic Programming Framework,https://www.reddit.com/r/MachineLearning/comments/db9tyb/anatomy_of_a_probabilistic_programming_framework/,__gh,1569841083,,0,2,False,default,,,,,
1603,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,20,db9v70,youtube.com,AI Learns to perfectly play Snake using a Genetic Algorithm and Neural Network!,https://www.reddit.com/r/MachineLearning/comments/db9v70/ai_learns_to_perfectly_play_snake_using_a_genetic/,rip_12,1569841302,,0,1,False,https://a.thumbs.redditmedia.com/sdMMxEvqbfO8t9TNwEWp4zt_r6A9FOKEtvVMGn55dl4.jpg,,,,,
1604,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,20,db9yyp,self.MachineLearning,Which Pneumatic Control Valve Is Best For All Medium?,https://www.reddit.com/r/MachineLearning/comments/db9yyp/which_pneumatic_control_valve_is_best_for_all/,uflowindia,1569841892,[removed],0,1,False,self,,,,,
1605,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,21,dbasu4,i.redd.it,Visualizing a Neural Network Controlling an Interplanetary Spacecraft Trajectory,https://www.reddit.com/r/MachineLearning/comments/dbasu4/visualizing_a_neural_network_controlling_an/,Gereshes,1569846438,,2,1,False,https://b.thumbs.redditmedia.com/EJt-9j--YVdbbXxdbqYteWFPrqe2GiiJrEL8jy4RgeY.jpg,,,,,
1606,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,21,dbaxxd,sicara.ai,[D] What is your opinion on the Dual Shot Face Detector presented in CVPR 2019 ?,https://www.reddit.com/r/MachineLearning/comments/dbaxxd/d_what_is_your_opinion_on_the_dual_shot_face/,BastouBab,1569847153,,2,2,False,https://b.thumbs.redditmedia.com/FYXOh62C8ZrF28I79-CDGOoQRrYapePkAjGC107KrvU.jpg,,,,,
1607,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,21,dbazh3,altoros.com,AI Basics and Machine Learning with Python,https://www.reddit.com/r/MachineLearning/comments/dbazh3/ai_basics_and_machine_learning_with_python/,christina_sas,1569847359,,0,1,False,default,,,,,
1608,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,22,dbba4h,self.MachineLearning,Google ML,https://www.reddit.com/r/MachineLearning/comments/dbba4h/google_ml/,nicikess,1569848794,[removed],0,1,False,self,,,,,
1609,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,22,dbbd43,youtube.com,[D] the connections between machine learning types and evolution,https://www.reddit.com/r/MachineLearning/comments/dbbd43/d_the_connections_between_machine_learning_types/,britcruise,1569849191,,0,1,False,https://b.thumbs.redditmedia.com/ksdZPVJr6u_t6mSfnT7JQBT0ftMUr2dytSBjhtV3mJM.jpg,,,,,
1610,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,22,dbbp2p,self.MachineLearning,[D] The problem with anthropomorphizing AI,https://www.reddit.com/r/MachineLearning/comments/dbbp2p/d_the_problem_with_anthropomorphizing_ai/,bendee983,1569850736,"When you start to humanize (current) AI technologies and describe them in ways you would talk about persons, you can draw all the wrong conclusions. This happens often when we see AI algorithms perform tasks that were previously thought to be off-limits for computers, such as playing Go or detecting cancer or converting text to speech. 

Without a reality check on the capabilities and limits of current AI, we tend to have trumped up expectations of what AI can do for us, and become disenchanted when those expectations aren't met.

[https://bdtechtalks.com/2019/01/02/humanizing-ai-deep-learning-alphazero/](https://bdtechtalks.com/2019/01/02/humanizing-ai-deep-learning-alphazero/?fbclid=IwAR12k0btsKpSbL_qGht9zqSyWfAlVuLndMoBMieZ6SioNA4Ake1M6EpAWzg)",1,0,False,self,,,,,
1611,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,23,dbcf2v,self.MachineLearning,[P] Comparing 7 Deep Dependency parsing models using Tensorflow,https://www.reddit.com/r/MachineLearning/comments/dbcf2v/p_comparing_7_deep_dependency_parsing_models/,huseinzol05,1569853982,"Trained on CONLL English Dependency, https://github.com/UniversalDependencies/UD_English-EWT. Train set to train, dev and test sets to test.

Stackpointer and Biaffine-attention originally from https://github.com/XuezheMax/NeuroNLP2 written in Pytorch.

**Accuracy based on arc, types and root accuracies after 15 epochs only.**

1. Bidirectional RNN + CRF + Biaffine, arc accuracy 70.48%, types accuracy 65.18%, root accuracy 66.4%
2. Bidirectional RNN + Bahdanau + CRF + Biaffine, arc accuracy 70.82%, types accuracy 65.33%, root accuracy 66.77%
3. Bidirectional RNN + Luong + CRF + Biaffine, arc accuracy 71.22%, types accuracy 65.73%, root accuracy 67.23%
4. BERT Base + CRF + Biaffine, arc accuracy 64.30%, types accuracy 62.89%, root accuracy 74.19%
5. Bidirectional RNN + Biaffine Attention + Cross Entropy, arc accuracy 72.42%, types accuracy 63.53%, root accuracy 68.51%
6. BERT Base + Biaffine Attention + Cross Entropy, arc accuracy 72.85%, types accuracy 67.11%, root accuracy 73.93%
7. Bidirectional RNN + Stackpointer, arc accuracy 61.88%, types accuracy 48.20%, root accuracy 89.39%

Link to repository, https://github.com/huseinzol05/NLP-Models-Tensorflow#dependency-parser

## Discussion

1. Based on 15 epochs only.
2. No dropout here, feel free to do it.
3. BERT cannot implemented in Stackpointer model, stack pointer model required each decoder step.",0,4,False,self,,,,,
1612,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,23,dbcgnw,youtu.be,Read a paper: Automatic Patch Generation Learned from Human-Written Patches,https://www.reddit.com/r/MachineLearning/comments/dbcgnw/read_a_paper_automatic_patch_generation_learned/,ggvh,1569854157,,0,1,False,https://a.thumbs.redditmedia.com/OcJhtYVi-Bww0RWEdClI9sJTRq4XKotizqJ7ZM2wU-8.jpg,,,,,
1613,MachineLearning,t5_2r3gv,2019-9-30,2019,9,30,23,dbcsla,self.MachineLearning,Can it be too late to learn math?,https://www.reddit.com/r/MachineLearning/comments/dbcsla/can_it_be_too_late_to_learn_math/,blimp166,1569855558,[removed],0,1,False,https://b.thumbs.redditmedia.com/SGKoLbReKb1gY86bde3wZykFW8vSy_xjvoK2Rut20eQ.jpg,,,,,
