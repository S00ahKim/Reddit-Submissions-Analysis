,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2017-12-1,2017,12,1,9,7gr28v,"[P] My implementations of neural algorithms - multilayer perceptron, neural gas, Kohonen SOM",https://www.reddit.com/r/MachineLearning/comments/7gr28v/p_my_implementations_of_neural_algorithms/,[deleted],1512088092,[deleted],0,0
1,2017-12-1,2017,12,1,9,7gr4lo,"[D] If data is the new oil, Google wants to sell you the drilling tools",https://www.reddit.com/r/MachineLearning/comments/7gr4lo/d_if_data_is_the_new_oil_google_wants_to_sell_you/,_alphamaximus_,1512088675,,0,1
2,2017-12-1,2017,12,1,11,7grr6l,[N] Accepted Papers at NIPS 2017 Workshop on Machine Learning for Creativity and Design,https://www.reddit.com/r/MachineLearning/comments/7grr6l/n_accepted_papers_at_nips_2017_workshop_on/,hardmaru,1512094468,,1,6
3,2017-12-1,2017,12,1,11,7grtm3,[D] ML labs that hire post-undergraduates for internships,https://www.reddit.com/r/MachineLearning/comments/7grtm3/d_ml_labs_that_hire_postundergraduates_for/,Flopologist,1512095139,"Hey r/MachineLearning,

I'm trying to put together a list of machine learning labs that are open to hiring post-undergraduates for a summer or a longer period of time. These can be labs at companies, universities, research institutes, government entities, etc. Personally, I'm interested in ones that (a) aren't incredibly hard to get into, and (b) are focused on research in deep learning or reinforcement learning. Either way, I think a comprehensive list would probably be appreciated by the community too. To start off, I'll list the places I know of (which unfortunately don't really satisfy (a)):

* OpenAI - You can apply at https://openai.com/jobs/ for the Fellow position. 
* MILA - You can apply at https://mila.quebec/en/admission/ for the Intern position. This is Yoshua Bengio's lab. I think it would help to speak French, though it doesn't seem to be required.
* Vector Institute - This is the brand new AI lab associated with Toronto, Guelph, and Ontario in general. There are no internship positions yet, but given the text on http://vectorinstitute.ai/#Opportunities it seems like there might be some next year or the following year.

Hopefully we can find others that might take people who aren't already very well qualified. I just sort of developed this plan, so if I find any more, I'll be sure to update this post.

To give some background, for the past three months, I've been preparing to apply to grad schools for a PhD in machine learning. I've gotten everything sorted out (GRE, letters, research experience, apps, etc.), and decided to look at some recently admitted PhD students to see how I stack up... at which point, my confidence deflated like an overcooked souffle :( I've realized that I'm really no match for these students, and that I probably don't have a fighting chance of getting in anywhere that has an RL or DL group--even at schools ranked around #40 on csrankings.org, which I thought would be safeties for me. So, after the rejections arrive, I'm planning on developing some research ideas I've had over the next six months on my own, and then applying to an internship at a lab--hence this post--and, finally, reapplying in one or two years for PhD or funded MS w/thesis programs. And I'd *definitely* appreciate any comments on the feasibility of this plan if anyone has related experience/knowledge.

Thanks!

**Update 1:** Thanks to u/chaitjo, who contributed the following ideas:

* Google Brain Residency (or AI Residency).
* Microsoft NERD AI Program.
* Personal connections with academic labs.
* Various roles at companies like Maluuba, Element AI, Vicarious, etc. (may have to be an ML developer there, instead of an intern).",14,9
4,2017-12-1,2017,12,1,11,7grvxx,FEIDA ROLL DIE PUNCHING MACHINE,https://www.reddit.com/r/MachineLearning/comments/7grvxx/feida_roll_die_punching_machine/,FEIDA_MACHINE,1512095771,,0,1
5,2017-12-1,2017,12,1,11,7gs0c8,TOROS N2 - lightweight approximate Nearest Neighbor library which runs faster even with large datasets,https://www.reddit.com/r/MachineLearning/comments/7gs0c8/toros_n2_lightweight_approximate_nearest_neighbor/,cyberbot97,1512096971,,0,1
6,2017-12-1,2017,12,1,12,7gs3cv,[R] Relation Networks for Object Detection (a fully end-to-end object detector),https://www.reddit.com/r/MachineLearning/comments/7gs3cv/r_relation_networks_for_object_detection_a_fully/,handynasty99,1512097746,,2,12
7,2017-12-1,2017,12,1,12,7gs4n5,Measure Facial Attractiveness,https://www.reddit.com/r/MachineLearning/comments/7gs4n5/measure_facial_attractiveness/,ThomasP32,1512098078,[removed],0,1
8,2017-12-1,2017,12,1,13,7gsivh,[1711.10456v1] Accelerated Gradient Descent Escapes Saddle Points Faster than Gradient Descent,https://www.reddit.com/r/MachineLearning/comments/7gsivh/171110456v1_accelerated_gradient_descent_escapes/,[deleted],1512101940,[deleted],0,1
9,2017-12-1,2017,12,1,13,7gskyr,[R] Accelerated Gradient Descent Escapes Saddle Points Faster than Gradient Descent,https://www.reddit.com/r/MachineLearning/comments/7gskyr/r_accelerated_gradient_descent_escapes_saddle/,sakares,1512102545,,2,9
10,2017-12-1,2017,12,1,13,7gsmgb,Berkeley Artificial Intelligence Research and Adobe Creative Intelligence Laboratory releases a new paper called BicycleGAN,https://www.reddit.com/r/MachineLearning/comments/7gsmgb/berkeley_artificial_intelligence_research_and/,[deleted],1512102966,[deleted],0,1
11,2017-12-1,2017,12,1,13,7gspvw,BicycleGAN : Toward Multimodal Image-to-Image Translation,https://www.reddit.com/r/MachineLearning/comments/7gspvw/bicyclegan_toward_multimodal_imagetoimage/,[deleted],1512103964,[deleted],0,1
12,2017-12-1,2017,12,1,13,7gsqux,[D] The reasons why reparameterization trick has lower variance than REINFORCE?,https://www.reddit.com/r/MachineLearning/comments/7gsqux/d_the_reasons_why_reparameterization_trick_has/,yield22,1512104275,"This has been stated or implied in many places. But I didn't see any formal proof of the argument whatsoever. Maybe I missed it or is it conditioned also on the specific reparameterization trick used so a formal proof is difficult? Other than the formal proof, what would be a good intuition for understanding this?",11,7
13,2017-12-1,2017,12,1,14,7gssje,BicycleGAN : Toward Multimodal Image-to-Image Translation,https://www.reddit.com/r/MachineLearning/comments/7gssje/bicyclegan_toward_multimodal_imagetoimage/,[deleted],1512104735,[deleted],0,1
14,2017-12-1,2017,12,1,14,7gstg6,How to train a RL agent when each turn has multiple phases?,https://www.reddit.com/r/MachineLearning/comments/7gstg6/how_to_train_a_rl_agent_when_each_turn_has/,zthoutt,1512104994,[removed],0,1
15,2017-12-1,2017,12,1,14,7gsy9b,[R] High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs,https://www.reddit.com/r/MachineLearning/comments/7gsy9b/r_highresolution_image_synthesis_and_semantic/,cherls,1512106470,,23,156
16,2017-12-1,2017,12,1,14,7gsyz8,Power hammer dies,https://www.reddit.com/r/MachineLearning/comments/7gsyz8/power_hammer_dies/,Aquaplanet681,1512106710,,0,1
17,2017-12-1,2017,12,1,15,7gt8kg,[N] 52 Machine Learning Conferences,https://www.reddit.com/r/MachineLearning/comments/7gt8kg/n_52_machine_learning_conferences/,delete99,1512109754,,5,0
18,2017-12-1,2017,12,1,15,7gtdkb,[D] Measuring dimensionality of data,https://www.reddit.com/r/MachineLearning/comments/7gtdkb/d_measuring_dimensionality_of_data/,phobrain,1512111493,"It seems to me that to study and understand how machine learning 'just works', it would be very useful to know the latent dimensionality of the data in different spaces. E.g. my grade-school attempt to figure Cartesian dimensionality and triangle inequality violations of histograms viewed as points with distances in high-dimensional spaces:

https://stackoverflow.com/questions/37855596/calculate-the-spatial-dimension-of-a-graph

I'm a little surprised that there didn't seem to be an off-the-shelf package for such analysis (sklearn.MDS didn't work except trivially, see link), but now that I am exposed to machine learning, the question seems like it would be even urgent for research at least?",11,1
19,2017-12-1,2017,12,1,16,7gtjsf,[N] Building the hardware for the next generation of artificial intelligence,https://www.reddit.com/r/MachineLearning/comments/7gtjsf/n_building_the_hardware_for_the_next_generation/,Jackal008,1512113705,,0,2
20,2017-12-1,2017,12,1,16,7gtky9,Financial time series and algos selection questions,https://www.reddit.com/r/MachineLearning/comments/7gtky9/financial_time_series_and_algos_selection/,Choubix,1512114219,[removed],0,1
21,2017-12-1,2017,12,1,17,7gtngc,Ho Fun Rice Noodle Making Machine | Commercial Rice Noodle Making Machine for Sale,https://www.reddit.com/r/MachineLearning/comments/7gtngc/ho_fun_rice_noodle_making_machine_commercial_rice/,liusherry,1512115274,[removed],1,1
22,2017-12-1,2017,12,1,17,7gtsd8,Commercial Full Automatic Electric Fresh Noodle Producing Machine,https://www.reddit.com/r/MachineLearning/comments/7gtsd8/commercial_full_automatic_electric_fresh_noodle/,liusherry,1512117534,[removed],1,1
23,2017-12-1,2017,12,1,17,7gtt10,[D] A Year in Computer Vision,https://www.reddit.com/r/MachineLearning/comments/7gtt10/d_a_year_in_computer_vision/,hlynurd,1512117829,,3,95
24,2017-12-1,2017,12,1,17,7gtv01,Any ideas for limited data in GAN?,https://www.reddit.com/r/MachineLearning/comments/7gtv01/any_ideas_for_limited_data_in_gan/,zuiaineo,1512118766,[removed],0,1
25,2017-12-1,2017,12,1,18,7gtvco,Regularization and variable selection via the elastic net,https://www.reddit.com/r/MachineLearning/comments/7gtvco/regularization_and_variable_selection_via_the/,charudatta2684,1512118922,,0,1
26,2017-12-1,2017,12,1,18,7gu06m,Satoshi Battleship Bot Challenge,https://www.reddit.com/r/MachineLearning/comments/7gu06m/satoshi_battleship_bot_challenge/,[deleted],1512121149,[deleted],0,1
27,2017-12-1,2017,12,1,20,7gub0r,[N] Satoshi Battleship Bot Challenge,https://www.reddit.com/r/MachineLearning/comments/7gub0r/n_satoshi_battleship_bot_challenge/,hlynurd,1512126073,,1,8
28,2017-12-1,2017,12,1,21,7gun87,[D] Looking for papers on treating regression as classification vs. just regression,https://www.reddit.com/r/MachineLearning/comments/7gun87/d_looking_for_papers_on_treating_regression_as/,pablo_gomez,1512131072,"I'm currently working on a paper regarding a regression problem. As suggested by many people here and also people such as Andrej Karpathy ( [source] (https://twitter.com/karpathy/status/708480082831024128)) I tried converting it to a classification problem to avoid a L2 loss function and that greatly improved performance (Note: I previously tried different data transform to make the L2 loss work, but couldn't get there). Intuitively, I would assume the loss function is less prone to having as many local minima and a less ""erratic"" shape due to the discretization compared to the L2 loss? 

However, do you know of any papers that explored the performance differences between plain regression loss functions and converting to a classification problem? 
Or, more generally, papers that analyze shortcomings of a L2 loss in a way that implies that avoiding it might be beneficial?

I read the PixelRNN paper ([pdf] (https://arxiv.org/pdf/1601.06759.pdf)), where they did something similar and am inclined to just reference it, but it seems a bit thin to just point to one paper, where this was beneficial too.

Thank you for your help. :)",27,18
29,2017-12-1,2017,12,1,21,7guq7h,[N]The Most Simple trick to Loss Weight - Buy A Digital Weight Machine and Check Your Weight Daily,https://www.reddit.com/r/MachineLearning/comments/7guq7h/nthe_most_simple_trick_to_loss_weight_buy_a/,trumtra,1512132164,,0,1
30,2017-12-1,2017,12,1,21,7guqu2,Machine learning and AI trends - what to expect in 2018?,https://www.reddit.com/r/MachineLearning/comments/7guqu2/machine_learning_and_ai_trends_what_to_expect_in/,dmitry-budko,1512132410,,0,1
31,2017-12-1,2017,12,1,21,7gurow,[N]Machine Learning with Optimus on Apache Spark,https://www.reddit.com/r/MachineLearning/comments/7gurow/nmachine_learning_with_optimus_on_apache_spark/,janemoz,1512132695,,0,1
32,2017-12-1,2017,12,1,22,7gv10x,pyro vs pymc3 vs edward,https://www.reddit.com/r/MachineLearning/comments/7gv10x/pyro_vs_pymc3_vs_edward/,roar363,1512135750,[removed],0,1
33,2017-12-1,2017,12,1,23,7gv70k,"""...this will look great in the eyes of the employer""",https://www.reddit.com/r/MachineLearning/comments/7gv70k/this_will_look_great_in_the_eyes_of_the_employer/,[deleted],1512137516,,0,1
34,2017-12-2,2017,12,2,0,7gvmgm,All NIPS2017 papers in a single .zip archive for your convenience,https://www.reddit.com/r/MachineLearning/comments/7gvmgm/all_nips2017_papers_in_a_single_zip_archive_for/,KloudStrife_ML,1512141598,,0,1
35,2017-12-2,2017,12,2,0,7gvrep,Algorithms and utils for Machine Learning in JavaScript.,https://www.reddit.com/r/MachineLearning/comments/7gvrep/algorithms_and_utils_for_machine_learning_in/,laoqiren,1512142854,,0,1
36,2017-12-2,2017,12,2,0,7gvt4l,"Modeling multi-view images to generate high-resolution, detailed and novel 3D shapes for many categories via through a single model.",https://www.reddit.com/r/MachineLearning/comments/7gvt4l/modeling_multiview_images_to_generate/,[deleted],1512143264,[deleted],0,1
37,2017-12-2,2017,12,2,1,7gvw4y,"Obtain view-invariant 3D representations and generate high-resolution, detailed and novel 3D shapes for many categories through a single model.",https://www.reddit.com/r/MachineLearning/comments/7gvw4y/obtain_viewinvariant_3d_representations_and/,[deleted],1512144021,[deleted],0,1
38,2017-12-2,2017,12,2,1,7gvya8,TOROS N2 - lightweight approximate Nearest Neighbor library which runs faster even with large datasets,https://www.reddit.com/r/MachineLearning/comments/7gvya8/toros_n2_lightweight_approximate_nearest_neighbor/,[deleted],1512144533,[deleted],0,1
39,2017-12-2,2017,12,2,1,7gvyvg,Is there a way to input specto-temporal data into a self organized map in Python/Tensoflow? [Project],https://www.reddit.com/r/MachineLearning/comments/7gvyvg/is_there_a_way_to_input_spectotemporal_data_into/,Darkni9ht,1512144677,"Apologies if this is the wrong tag... I'm new to the subreddit. 

I've have some Fourier transformed data of speech. Each speech sample (4000 ms) is represented as a certain intensity at a series of timepoints (vectors) at different frequencies (elements) and want to use this as input into a self organized map in Python/Tensorflow. The intention is to use the SOM to reduce the dimensionality of the data (to a single vector with winning neurons/best matching unit) and use that in further analysis.   

Unfortunately, I dont have access to Matlab, or statistica and I'm not a massive fan of R)...so it sort of needs to be Python/Tensorflow.   

I am aware of a few tutorials on applying SOM's to the iris dataset or a series of RGB values etc, have spent a lot of time googling, but couldn't seem to find any examples on how to deal with the time series aspect of spectral data. Additionally, I know there are published papers that do use spectral speech data in SOM's, so it is possible, but from what I have read, they dont include sufficient detail about how to deal with the time series/multidimensionality aspect of it. In short, I'm just not sure how to go about it practically. 

Would someone be able to help/give me some pointers as to how I could achieve this? 

Any help would be greatly appreciated. 

Thanks
",6,1
40,2017-12-2,2017,12,2,1,7gwa3a,How to design a TPU?,https://www.reddit.com/r/MachineLearning/comments/7gwa3a/how_to_design_a_tpu/,jk99_datasci,1512147271,[removed],0,1
41,2017-12-2,2017,12,2,2,7gwett,[D] Deep learning about grid placement optimization,https://www.reddit.com/r/MachineLearning/comments/7gwett/d_deep_learning_about_grid_placement_optimization/,Eternahl,1512148380,"Hi everyone,

A few weeks/months ago I saw a paper related to deep learning applied to the placement optimization of connectors on 3D grids from what I remember.

But unfortunately I cannot find it now that I would like to implement it. Does anyone of you have the link of this paper or some related to this?


Thank you very much for your help! ",0,5
42,2017-12-2,2017,12,2,2,7gwetx,[D] Good methods for seasonal time series classification?,https://www.reddit.com/r/MachineLearning/comments/7gwetx/d_good_methods_for_seasonal_time_series/,smthamazing,1512148381,"Hi! I have a set of highly seasonal time series (with distinct daily, weekly and monthly peaks, and also higher peaks on holidays). I have very little experience in the area. Can anybody recommend the approaches that would be most promising for clustering and/or classifying such time series?

I am thinking about using an LSTM neural network, since I already have experience with those and have successfully applied them to forecasting the same series, but I'm not sure if this is a good starting point.

Thanks!

Additional info: Basically, I have several time series for which my forecast algorithm (a neural network) works very well. There is also a huge amount of other series for which there's too little training data for the NN. For each series of this ""too little data"" set, I want to find the most similar series from the ""enough data"" set and use its data to improve the quality of the forecast.",12,12
43,2017-12-2,2017,12,2,2,7gwgpn,[D] Attention mechanisms on bounding box in images for feature extraction,https://www.reddit.com/r/MachineLearning/comments/7gwgpn/d_attention_mechanisms_on_bounding_box_in_images/,skepticforest,1512148810,"I've never implemented attention for visual tasks so I wanted to know if it would apply for my work. My work involves extracting features from a bounding box in an image but I also want to capture some contextual information as well. So far, I thought of applying blur/gradient outside the bounding box to decrease the importance but attention, in theory, also sounds good for implementing this. 

So is there any work that involves forcing attention on a bounding box beforehand? I guess one way of doing that would be to explicitly weigh the bounding box pixels much more than the outside ones, but I'm not sure how exactly I would do that. I'd love links to papers/code that can help me with this.",4,4
44,2017-12-2,2017,12,2,2,7gwhkz,AOGNets: Deep AND-OR Grammar Networks for Visual Recognition,https://www.reddit.com/r/MachineLearning/comments/7gwhkz/aognets_deep_andor_grammar_networks_for_visual/,[deleted],1512149013,[deleted],0,1
45,2017-12-2,2017,12,2,2,7gwip3,[D] Google's large scale GAN-Tuning paper unfairly dismissed WGAN,https://www.reddit.com/r/MachineLearning/comments/7gwip3/d_googles_large_scale_gantuning_paper_unfairly/,baylearn,1512149277,,19,69
46,2017-12-2,2017,12,2,2,7gwk6t,[R] AOGNets: Deep AND-OR Grammar Networks for Visual Recognition,https://www.reddit.com/r/MachineLearning/comments/7gwk6t/r_aognets_deep_andor_grammar_networks_for_visual/,viseyeon,1512149622,,0,0
47,2017-12-2,2017,12,2,2,7gwpnx,Medical image segmentation &amp; deep learning - a short paper review of second half of 2017,https://www.reddit.com/r/MachineLearning/comments/7gwpnx/medical_image_segmentation_deep_learning_a_short/,JScheinpheld,1512150891,,0,1
48,2017-12-2,2017,12,2,2,7gwq5z,[D] The ML Stack at Windfall Data,https://www.reddit.com/r/MachineLearning/comments/7gwq5z/d_the_ml_stack_at_windfall_data/,bweber,1512151009,,0,1
49,2017-12-2,2017,12,2,3,7gwsp7,[P] HoME: a Household Multimodal Environment,https://www.reddit.com/r/MachineLearning/comments/7gwsp7/p_home_a_household_multimodal_environment/,hardmaru,1512151602,,0,20
50,2017-12-2,2017,12,2,4,7gx7eo,"Obtain view-invariant 3D representations and generate high-resolution, detailed and novel 3D shapes for many categories through a single model",https://www.reddit.com/r/MachineLearning/comments/7gx7eo/obtain_viewinvariant_3d_representations_and/,[deleted],1512155035,[deleted],0,1
51,2017-12-2,2017,12,2,4,7gxdma,MCE Mostra Convegno Expocomfort Fuar,https://www.reddit.com/r/MachineLearning/comments/7gxdma/mce_mostra_convegno_expocomfort_fuar/,MekanikTesisat,1512156458,,0,1
52,2017-12-2,2017,12,2,4,7gxkdb,Does variance increase error in every scenario?,https://www.reddit.com/r/MachineLearning/comments/7gxkdb/does_variance_increase_error_in_every_scenario/,kakushka123,1512158058,[removed],0,1
53,2017-12-2,2017,12,2,4,7gxkvv,First time making a training sample,https://www.reddit.com/r/MachineLearning/comments/7gxkvv/first_time_making_a_training_sample/,r_alberts,1512158189,[removed],0,1
54,2017-12-2,2017,12,2,5,7gxv48,AI Weekly 1 Dec 2017,https://www.reddit.com/r/MachineLearning/comments/7gxv48/ai_weekly_1_dec_2017/,TomekB,1512160565,,0,1
55,2017-12-2,2017,12,2,6,7gy3uk,[R] Synthesizing 3D Shapes via Modeling Multi-View Depth Maps and Silhouettes with Deep Generative Networks,https://www.reddit.com/r/MachineLearning/comments/7gy3uk/r_synthesizing_3d_shapes_via_modeling_multiview/,Warrior--,1512162623,,0,1
56,2017-12-2,2017,12,2,6,7gy5lv,"Google, Amazon Are Offering Consulting Services for AI/ML",https://www.reddit.com/r/MachineLearning/comments/7gy5lv/google_amazon_are_offering_consulting_services/,darkconfidantislife,1512163035,,0,1
57,2017-12-2,2017,12,2,6,7gy5qh,"[N] Google, Amazon Are Offering AI/ML Consulting Services",https://www.reddit.com/r/MachineLearning/comments/7gy5qh/n_google_amazon_are_offering_aiml_consulting/,darkconfidantislife,1512163066,,12,7
58,2017-12-2,2017,12,2,6,7gybxp,[D] How do you prepare for industry ML/DL engineering interviews in if you come from an academic background?,https://www.reddit.com/r/MachineLearning/comments/7gybxp/d_how_do_you_prepare_for_industry_mldl/,RefurbishedMac,1512164611,[removed],0,1
59,2017-12-2,2017,12,2,7,7gyhf3,"[R] Embodied Question Answering - a dataset of grounded questions, end-to-end-trained reinforcement learning agents, and evaluation protocols from FB",https://www.reddit.com/r/MachineLearning/comments/7gyhf3/r_embodied_question_answering_a_dataset_of/,visarga,1512165917,,1,0
60,2017-12-2,2017,12,2,8,7gyutr,[R] Neural Motifs: Scene Graph Parsing with Global Context,https://www.reddit.com/r/MachineLearning/comments/7gyutr/r_neural_motifs_scene_graph_parsing_with_global/,rowanz,1512169387,,2,4
61,2017-12-2,2017,12,2,8,7gz09o,How does the following code replace the calculus in gradient descent with vectorization?,https://www.reddit.com/r/MachineLearning/comments/7gz09o/how_does_the_following_code_replace_the_calculus/,[deleted],1512170811,,0,1
62,2017-12-2,2017,12,2,8,7gz3fe,[N] ICLR Reviews have been posted,https://www.reddit.com/r/MachineLearning/comments/7gz3fe/n_iclr_reviews_have_been_posted/,anonDogeLover,1512171680,,44,27
63,2017-12-2,2017,12,2,8,7gz6na,"SF Bay Area devs - Join us on 12/7 for the Unity Evangelists 2017 Blow Out, where recent updates to ML-Agents will be shared and the first ever machine learning community challenge will be announced!",https://www.reddit.com/r/MachineLearning/comments/7gz6na/sf_bay_area_devs_join_us_on_127_for_the_unity/,leonchenzhy,1512172560,,0,1
64,2017-12-2,2017,12,2,11,7h00il,[P] Keras text classification library,https://www.reddit.com/r/MachineLearning/comments/7h00il/p_keras_text_classification_library/,raghakot,1512181479,,1,39
65,2017-12-2,2017,12,2,13,7h0l3c,Q Learning Explained,https://www.reddit.com/r/MachineLearning/comments/7h0l3c/q_learning_explained/,funmaster11,1512188474,,0,1
66,2017-12-2,2017,12,2,14,7h0sez,Clear step by step tutorial for Implementing Capsule Networks (By Aurlien Gron),https://www.reddit.com/r/MachineLearning/comments/7h0sez/clear_step_by_step_tutorial_for_implementing/,aavaas,1512191137,,1,1
67,2017-12-2,2017,12,2,14,7h0z90,xLearn gets over 1200 stars in one week on github,https://www.reddit.com/r/MachineLearning/comments/7h0z90/xlearn_gets_over_1200_stars_in_one_week_on_github/,aksnzhy,1512193808,,0,1
68,2017-12-2,2017,12,2,14,7h0zdx,[R] Learning to Learn without Gradient Descent by Gradient Descent,https://www.reddit.com/r/MachineLearning/comments/7h0zdx/r_learning_to_learn_without_gradient_descent_by/,Pfohlol,1512193862,,19,168
69,2017-12-2,2017,12,2,16,7h1d1m,Automated Caries Detection on Bitewing Radiographs Using Deep CNNs,https://www.reddit.com/r/MachineLearning/comments/7h1d1m/automated_caries_detection_on_bitewing/,shashankg22,1512199431,,0,1
70,2017-12-2,2017,12,2,17,7h1ir1,"DataVal Analytics successfully completed all 20 tasks of the test, known as the (20) QA bAbi tasks, with 100 per cent accuracy. #Datavalanalytics #QAbAbitasks",https://www.reddit.com/r/MachineLearning/comments/7h1ir1/dataval_analytics_successfully_completed_all_20/,Ankur310794,1512202031,,0,1
71,2017-12-2,2017,12,2,17,7h1laj,[D] The Intelligent Plant,https://www.reddit.com/r/MachineLearning/comments/7h1laj/d_the_intelligent_plant/,phobrain,1512203272,,4,13
72,2017-12-2,2017,12,2,19,7h1wqg,Batch Normalization for future frame prediction ?,https://www.reddit.com/r/MachineLearning/comments/7h1wqg/batch_normalization_for_future_frame_prediction/,I_am_a_robot_,1512209196,[removed],0,1
73,2017-12-2,2017,12,2,19,7h1xos,Arxiv Sanity Preserver  personalized arXiv aggregator and search engine,https://www.reddit.com/r/MachineLearning/comments/7h1xos/arxiv_sanity_preserver_personalized_arxiv/,abhishekchakraborty,1512209697,,0,1
74,2017-12-2,2017,12,2,20,7h29u6,Python: Playing SNAP!!!,https://www.reddit.com/r/MachineLearning/comments/7h29u6/python_playing_snap/,LeoDrysdale,1512215911,,0,1
75,2017-12-2,2017,12,2,21,7h2bd1,"[P] Remember the agent that mastered Lunar Lander? It learned to win Atari Pong without CNN, in one day, on CPU in 1200 episodes.",https://www.reddit.com/r/MachineLearning/comments/7h2bd1/p_remember_the_agent_that_mastered_lunar_lander/,[deleted],1512216566,[deleted],2,0
76,2017-12-2,2017,12,2,21,7h2g7v,[D] How do you interpret this ResNet on CIFAR-10 database?,https://www.reddit.com/r/MachineLearning/comments/7h2g7v/d_how_do_you_interpret_this_resnet_on_cifar10/,cyplus1,1512218884,"I've calculated influence score of ResNet trained with CIFAR-10 database. As a result, to recognize a horse test image, horse images were turned out to be most helpful, but dog images were turned out to be most harmful. What do you think about this result?

[the results are here](http://nbviewer.jupyter.org/github/darkonhub/darkon-examples/blob/master/cifar10-resnet/influence_cifar10_resnet.ipynb)
 ",4,6
77,2017-12-2,2017,12,2,22,7h2lew,Marketing Technology Landscape Supergraphic (2017),https://www.reddit.com/r/MachineLearning/comments/7h2lew/marketing_technology_landscape_supergraphic_2017/,pauljohngordon,1512220947,,0,1
78,2017-12-3,2017,12,3,0,7h38za,TOROS N2 - lightweight approximate Nearest Neighbor library which runs faster even with large datasets,https://www.reddit.com/r/MachineLearning/comments/7h38za/toros_n2_lightweight_approximate_nearest_neighbor/,[deleted],1512228966,[deleted],0,1
79,2017-12-3,2017,12,3,0,7h3c3s,[P] TOROS N2 - lightweight approximate Nearest Neighbor library which runs faster even with large datasets,https://www.reddit.com/r/MachineLearning/comments/7h3c3s/p_toros_n2_lightweight_approximate_nearest/,ummae,1512229909,,7,86
80,2017-12-3,2017,12,3,2,7h3r1v,[D] What is the most significant thing you've learned in the past month ?,https://www.reddit.com/r/MachineLearning/comments/7h3r1v/d_what_is_the_most_significant_thing_youve/,TeslaCarBot,1512234139,,43,18
81,2017-12-3,2017,12,3,2,7h407h,[D] degradation in NN,https://www.reddit.com/r/MachineLearning/comments/7h407h/d_degradation_in_nn/,spartan12321,1512236579,"After reading research paper with title Deep Residual Learning for Image Recognition I was looking for further research on topic of ""degradation problem"". Anyone knows any papers on cause of this or some practical guidelines?",1,2
82,2017-12-3,2017,12,3,3,7h448o,How long to train Deep learning for Action Recognition on kinetics from scratch on nvidia 1080ti,https://www.reddit.com/r/MachineLearning/comments/7h448o/how_long_to_train_deep_learning_for_action/,_royston_,1512237689,[removed],0,1
83,2017-12-3,2017,12,3,4,7h4ql3,Prof. Jitendra Malik is joined to FAIR,https://www.reddit.com/r/MachineLearning/comments/7h4ql3/prof_jitendra_malik_is_joined_to_fair/,[deleted],1512243494,[deleted],0,1
84,2017-12-3,2017,12,3,4,7h4u2c,Training a multi-class image classifier,https://www.reddit.com/r/MachineLearning/comments/7h4u2c/training_a_multiclass_image_classifier/,[deleted],1512244401,,0,1
85,2017-12-3,2017,12,3,5,7h4weo,What needs to be done?,https://www.reddit.com/r/MachineLearning/comments/7h4weo/what_needs_to_be_done/,graphicaldot,1512245021,[removed],0,1
86,2017-12-3,2017,12,3,5,7h52k1,[D] Training a multi-class image classifier,https://www.reddit.com/r/MachineLearning/comments/7h52k1/d_training_a_multiclass_image_classifier/,[deleted],1512246717,[deleted],6,0
87,2017-12-3,2017,12,3,5,7h57el,Training and Testing of DataSet on Weka,https://www.reddit.com/r/MachineLearning/comments/7h57el/training_and_testing_of_dataset_on_weka/,haxxanasghar,1512248091,,0,1
88,2017-12-3,2017,12,3,7,7h5ulo,Training a TensorFlow object classifier takes a lot of processing power! I've never seen my CPU 100% used up before.,https://www.reddit.com/r/MachineLearning/comments/7h5ulo/training_a_tensorflow_object_classifier_takes_a/,Taxi-guy,1512254717,,0,1
89,2017-12-3,2017,12,3,8,7h5yi7,"Implementation of Toy Example from DeepMind's recent ""Population Based Training"" paper",https://www.reddit.com/r/MachineLearning/comments/7h5yi7/implementation_of_toy_example_from_deepminds/,bkj__,1512255848,,0,1
90,2017-12-3,2017,12,3,8,7h64cc,Introduction to NLP for starters,https://www.reddit.com/r/MachineLearning/comments/7h64cc/introduction_to_nlp_for_starters/,[deleted],1512257459,[deleted],0,1
91,2017-12-3,2017,12,3,8,7h6a3n,[P] TopoSketch,https://www.reddit.com/r/MachineLearning/comments/7h6a3n/p_toposketch/,wei_jok,1512259072,,2,2
92,2017-12-3,2017,12,3,9,7h6gz8,[P] What is Natural Language Processing? Get started,https://www.reddit.com/r/MachineLearning/comments/7h6gz8/p_what_is_natural_language_processing_get_started/,gonesbuyo,1512261014,,0,0
93,2017-12-3,2017,12,3,9,7h6kd0,Knitting machine,https://www.reddit.com/r/MachineLearning/comments/7h6kd0/knitting_machine/,JeyarBamerni,1512262026,,0,1
94,2017-12-3,2017,12,3,9,7h6lhm,[D] When not to use deep learning,https://www.reddit.com/r/MachineLearning/comments/7h6lhm/d_when_not_to_use_deep_learning/,_alphamaximus_,1512262353,,0,1
95,2017-12-3,2017,12,3,12,7h7hp9,[P] Essential Guide to keep up with AI/ML/CV,https://www.reddit.com/r/MachineLearning/comments/7h7hp9/p_essential_guide_to_keep_up_with_aimlcv/,ukrdailo,1512272653,,6,0
96,2017-12-3,2017,12,3,12,7h7htl,Selecting parameter for RBF kernel?,https://www.reddit.com/r/MachineLearning/comments/7h7htl/selecting_parameter_for_rbf_kernel/,[deleted],1512272697,,0,1
97,2017-12-3,2017,12,3,14,7h7vrs,[D] PC build for ML Research,https://www.reddit.com/r/MachineLearning/comments/7h7vrs/d_pc_build_for_ml_research/,langfosaurus,1512277697,"Hi everybody,

I'm in the process of finalizing a PC build for doing my own ML research. I'm a 4th year undergrad in computational engineering applying to get a masters in ML. Most of my research, at the moment, focuses on deep convolutional nets and GANs. I was wondering if you could have a look through this build and see if there are any glaring errors in it so that I can address them before getting the parts:

[PCPartPicker part list](https://pcpartpicker.com/list/49spqk) / [Price breakdown by merchant](https://pcpartpicker.com/list/49spqk/by_merchant/)

Type|Item|Price
:----|:----|:----
**CPU** | [Intel - Core i5-8400 2.8GHz 6-Core Processor](https://pcpartpicker.com/product/LHYWGX/intel-core-i5-8400-28ghz-6-core-processor-bx80684i58400) | Purchased For $0.00 
**CPU Cooler** | [Cooler Master - Hyper 212 EVO 82.9 CFM Sleeve Bearing CPU Cooler](https://pcpartpicker.com/product/hmtCmG/cooler-master-cpu-cooler-rr212e20pkr2) | $28.89 @ OutletPC 
**Motherboard** | [Asus - Prime Z370-A ATX LGA1151 Motherboard](https://pcpartpicker.com/product/3MJkcf/asus-prime-z370-a-atx-lga1151-motherboard-prime-z370-a) | $167.89 @ OutletPC 
**Memory** | [G.Skill - Ripjaws V Series 32GB (2 x 16GB) DDR4-3200 Memory](https://pcpartpicker.com/product/kXbkcf/gskill-memory-f43200c16d32gvk) | $358.79 @ Newegg Marketplace 
**Storage** | [Samsung - 850 EVO-Series 500GB 2.5"" Solid State Drive](https://pcpartpicker.com/product/FrH48d/samsung-internal-hard-drive-mz75e500bam) | Purchased For $0.00 
**Storage** | [Seagate - Barracuda 3TB 3.5"" 7200RPM Internal Hard Drive](https://pcpartpicker.com/product/gwBv6h/seagate-internal-hard-drive-st3000dm001) | $78.89 @ OutletPC 
**Video Card** | [EVGA - GeForce GTX 1080 Ti 11GB SC2 Video Card](https://pcpartpicker.com/product/q438TW/evga-geforce-gtx-1080-ti-11gb-sc2-video-card-11g-p4-6593-kr) | $748.99 @ SuperBiiz 
**Case** | [NZXT - S340 (Black) ATX Mid Tower Case](https://pcpartpicker.com/product/ms6BD3/nzxt-case-cas340wb1) | $59.99 @ Newegg 
**Power Supply** | [EVGA - SuperNOVA G2 750W 80+ Gold Certified Fully-Modular ATX Power Supply](https://pcpartpicker.com/product/MfJwrH/evga-power-supply-220g20750xr) | $77.98 @ Newegg 
**Wireless Network Adapter** | [TP-Link - TL-WDN4800 PCI-Express x1 802.11a/b/g/n Wi-Fi Adapter](https://pcpartpicker.com/product/G4H323/tp-link-wireless-network-card-tlwdn4800) | $34.88 @ OutletPC 
 | *Prices include shipping, taxes, rebates, and discounts* |
 | Total (before mail-in rebates) | $1596.30
 | Mail-in rebates | -$40.00
 | **Total** | **$1556.30**
 | Generated by [PCPartPicker](http://pcpartpicker.com) 2017-12-03 00:07 EST-0500 |

",24,4
98,2017-12-3,2017,12,3,16,7h8cv5,Nepotism in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7h8cv5/nepotism_in_machine_learning/,[deleted],1512284767,,0,1
99,2017-12-3,2017,12,3,16,7h8f75,[D] Nepotism in ML,https://www.reddit.com/r/MachineLearning/comments/7h8f75/d_nepotism_in_ml/,nepowoes,1512285848,"This may be a bit of a controversial topic. I've noticed a lot of nepotism in the field that should be addressed.

At the Deep RL Symposium at NIPS this year, 7 out of the 12 contributed talks come from two groups at Berkeley. While these two groups have many papers in the symposium, there are more than 80 accepted papers in total from many different groups that could have been highlighted. The selection process for papers was double blind, but I can't help but doubt the process for picking who gets a talk. Particularly because 3 out of 6 of the symposium organizers are associated in some way with these labs.

I think it is great that RL has finally reached this level of popularity, but I also think we have to be careful about how the research is disseminated.",112,332
100,2017-12-3,2017,12,3,17,7h8lo7,[P] ICLR OpenReview Explorer: Sort/filter papers by average review score (plus some pretty charts),https://www.reddit.com/r/MachineLearning/comments/7h8lo7/p_iclr_openreview_explorer_sortfilter_papers_by/,programmerChilli,1512289073,,15,21
101,2017-12-3,2017,12,3,18,7h8uv5,[D] NIPS - Tips on conference going without tickets?,https://www.reddit.com/r/MachineLearning/comments/7h8uv5/d_nips_tips_on_conference_going_without_tickets/,ctwiz,1512294006,"Hey there! NIPS is sold out, but we wanted to still go out and meet as many people as we can and talk about what we're working on and hopefully score some awesome partnerships. 

What would the best way to do this be without tickets?",16,0
102,2017-12-3,2017,12,3,18,7h8v0t,[D] I like to run a big fat resnet when I wake up in the morning,https://www.reddit.com/r/MachineLearning/comments/7h8v0t/d_i_like_to_run_a_big_fat_resnet_when_i_wake_up/,[deleted],1512294087,[deleted],0,0
103,2017-12-3,2017,12,3,21,7h9d9e,"Basic Tutorial of Naive Bayes in python, Upvote the kaggle notebook if you find it useful",https://www.reddit.com/r/MachineLearning/comments/7h9d9e/basic_tutorial_of_naive_bayes_in_python_upvote/,ibadia2762,1512303495,[removed],0,1
104,2017-12-3,2017,12,3,21,7h9dnv,Help me with my school project please,https://www.reddit.com/r/MachineLearning/comments/7h9dnv/help_me_with_my_school_project_please/,Instict,1512303703,[removed],0,1
105,2017-12-3,2017,12,3,21,7h9e8a,Lobbying disclosures,https://www.reddit.com/r/MachineLearning/comments/7h9e8a/lobbying_disclosures/,[deleted],1512303971,[deleted],0,1
106,2017-12-3,2017,12,3,21,7h9f2p,Learning machine learning,https://www.reddit.com/r/MachineLearning/comments/7h9f2p/learning_machine_learning/,AlePec98,1512304374,[removed],0,1
107,2017-12-3,2017,12,3,21,7h9h84,Is it possible to organize this with machine learning algorithms?,https://www.reddit.com/r/MachineLearning/comments/7h9h84/is_it_possible_to_organize_this_with_machine/,[deleted],1512305388,[deleted],0,1
108,2017-12-3,2017,12,3,22,7h9jw2,[P] Convolutional Neural Networks for Sentence Classification(TextCNN) implements by Tensorflow 1.4,https://www.reddit.com/r/MachineLearning/comments/7h9jw2/p_convolutional_neural_networks_for_sentence/,DongjunLee,1512306532,,9,13
109,2017-12-3,2017,12,3,22,7h9nao,"Amazon Macie is a security service that uses machine learning to automatically discover, classify, and protect sensitive data in AWS",https://www.reddit.com/r/MachineLearning/comments/7h9nao/amazon_macie_is_a_security_service_that_uses/,[deleted],1512307912,[deleted],0,1
110,2017-12-3,2017,12,3,22,7h9pxv,Prediction with multiple Outputs,https://www.reddit.com/r/MachineLearning/comments/7h9pxv/prediction_with_multiple_outputs/,Mupuckel,1512308963,[removed],0,1
111,2017-12-3,2017,12,3,22,7h9q90,[N] Amazon Macie: A machine learning service,https://www.reddit.com/r/MachineLearning/comments/7h9q90/n_amazon_macie_a_machine_learning_service/,hlynurd,1512309098,,2,19
112,2017-12-3,2017,12,3,22,7h9qa6,ISB - capstone project invite.,https://www.reddit.com/r/MachineLearning/comments/7h9qa6/isb_capstone_project_invite/,paritosh_tiwari,1512309117,[removed],0,1
113,2017-12-3,2017,12,3,22,7h9qsp,"How to access memory, RAM, CPU and GPU over the internet in a low cost way.",https://www.reddit.com/r/MachineLearning/comments/7h9qsp/how_to_access_memory_ram_cpu_and_gpu_over_the/,microwelle1,1512309315,[removed],1,1
114,2017-12-3,2017,12,3,23,7h9vwd,Edward Witten/String theory powered artificial neural network (how to build),https://www.reddit.com/r/MachineLearning/comments/7h9vwd/edward_wittenstring_theory_powered_artificial/,ProgrammingGodJordan,1512311104,,0,1
115,2017-12-4,2017,12,4,1,7haf0l,"[D] Has anyone here ever hired a self-taught person? If so, how did it go? To those of you who are in a position to hire: what projects or accomplishments from a self-taught person would lead you to conclude that this person would very likely excel, if given a position?",https://www.reddit.com/r/MachineLearning/comments/7haf0l/d_has_anyone_here_ever_hired_a_selftaught_person/,Batmantosh,1512317132,"It seems that there's an explosion of resources for people to teach themselves machine learning. Online courses, books, bootcamps, youtube, videos, blogs, etc. 

So there's probably a lot of candidates out right now who are self-taught. I think it's important to discuss some objective measures which people can test themselves against to see if they have what it takes to excel in a career in machine learning. Not only for the candidates, but for also hiring manages to consider when evaluating potential candidates. 

I'm guessing it would be to how CS candidates are evaluated, the best way is to work on a project where they would need to utilize the same skills they would need to do in a regular work enviroment. 

To those who are in a position to hire for ML positions, I would love to hear your thoughts on this. 

",63,50
116,2017-12-4,2017,12,4,3,7hbg1u,How to code an SVM's equation including kernels?,https://www.reddit.com/r/MachineLearning/comments/7hbg1u/how_to_code_an_svms_equation_including_kernels/,sanupa,1512326871,[removed],0,1
117,2017-12-4,2017,12,4,4,7hbohu,Gradient Boosting in TensorFlow vs XGBoost,https://www.reddit.com/r/MachineLearning/comments/7hbohu/gradient_boosting_in_tensorflow_vs_xgboost/,nicolovv,1512328991,,0,1
118,2017-12-4,2017,12,4,4,7hbx6p,[P] Maximum Mean Discrepancy - Vatiational AutoEncoder in Pytorch,https://www.reddit.com/r/MachineLearning/comments/7hbx6p/p_maximum_mean_discrepancy_vatiational/,napsternxg,1512331150,,0,0
119,2017-12-4,2017,12,4,5,7hc3vf,Detecting Santa Claus using Tensorflow's Object Detection API,https://www.reddit.com/r/MachineLearning/comments/7hc3vf/detecting_santa_claus_using_tensorflows_object/,varunvohra94,1512332750,,0,2
120,2017-12-4,2017,12,4,6,7hcc2c,[D] Machine Learning - WAYR (What Are You Reading) - Week 37,https://www.reddit.com/r/MachineLearning/comments/7hcc2c/d_machine_learning_wayr_what_are_you_reading_week/,ML_WAYR_bot,1512334805,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|31-40|
|----|-----|-----|-----|
|[Week 1](https://www.reddit.com/r/MachineLearning/comments/4qyjiq/machine_learning_wayr_what_are_you_reading_week_1/)|[Week 11](https://www.reddit.com/r/MachineLearning/comments/57xw56/discussion_machine_learning_wayr_what_are_you/)|[Week 21](https://www.reddit.com/r/MachineLearning/comments/60ildf/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 31](https://www.reddit.com/r/MachineLearning/comments/6s0k1u/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 2](https://www.reddit.com/r/MachineLearning/comments/4s2xqm/machine_learning_wayr_what_are_you_reading_week_2/)|[Week 12](https://www.reddit.com/r/MachineLearning/comments/5acb1t/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 22](https://www.reddit.com/r/MachineLearning/comments/64jwde/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 32](https://www.reddit.com/r/MachineLearning/comments/72ab5y/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 3](https://www.reddit.com/r/MachineLearning/comments/4t7mqm/machine_learning_wayr_what_are_you_reading_week_3/)|[Week 13](https://www.reddit.com/r/MachineLearning/comments/5cwfb6/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 23](https://www.reddit.com/r/MachineLearning/comments/674331/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 33](https://www.reddit.com/r/MachineLearning/comments/75405d/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 4](https://www.reddit.com/r/MachineLearning/comments/4ub2kw/machine_learning_wayr_what_are_you_reading_week_4/)|[Week 14](https://www.reddit.com/r/MachineLearning/comments/5fc5mh/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 24](https://www.reddit.com/r/MachineLearning/comments/68hhhb/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 34](https://www.reddit.com/r/MachineLearning/comments/782js9/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 5](https://www.reddit.com/r/MachineLearning/comments/4xomf7/machine_learning_wayr_what_are_you_reading_week_5/)|[Week 15](https://www.reddit.com/r/MachineLearning/comments/5hy4ur/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 25](https://www.reddit.com/r/MachineLearning/comments/69teiz/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 35](https://www.reddit.com/r/MachineLearning/comments/7b0av0/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 6](https://www.reddit.com/r/MachineLearning/comments/4zcyvk/machine_learning_wayr_what_are_you_reading_week_6/)|[Week 16](https://www.reddit.com/r/MachineLearning/comments/5kd6vd/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 26](https://www.reddit.com/r/MachineLearning/comments/6d7nb1/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 36](https://www.reddit.com/r/MachineLearning/comments/7e3fx6/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 7](https://www.reddit.com/r/MachineLearning/comments/52t6mo/machine_learning_wayr_what_are_you_reading_week_7/)|[Week 17](https://www.reddit.com/r/MachineLearning/comments/5ob7dx/discussion_machine_learning_wayr_what_are_you/)|[Week 27](https://www.reddit.com/r/MachineLearning/comments/6gngwc/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 8](https://www.reddit.com/r/MachineLearning/comments/53heol/machine_learning_wayr_what_are_you_reading_week_8/)|[Week 18](https://www.reddit.com/r/MachineLearning/comments/5r14yd/discussion_machine_learning_wayr_what_are_you/)|[Week 28](https://www.reddit.com/r/MachineLearning/comments/6jgdva/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 9](https://www.reddit.com/r/MachineLearning/comments/54kvsu/machine_learning_wayr_what_are_you_reading_week_9/)|[Week 19](https://www.reddit.com/r/MachineLearning/comments/5tt9cz/discussion_machine_learning_wayr_what_are_you/)|[Week 29](https://www.reddit.com/r/MachineLearning/comments/6m9l1v/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 10](https://www.reddit.com/r/MachineLearning/comments/56s2oa/discussion_machine_learning_wayr_what_are_you/)|[Week 20](https://www.reddit.com/r/MachineLearning/comments/5wh2wb/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 30](https://www.reddit.com/r/MachineLearning/comments/6p3ha7/d_machine_learning_wayr_what_are_you_reading_week/)||

Most upvoted papers two weeks ago:

/u/akaece: [interesting paper](http://agris.fao.org/agris-search/search.do?recordID=US201301782169)

/u/sakares: [L2 Regularization versus Batch and Weight Normalization](https://arxiv.org/abs/1706.05350)

/u/Charmander35: http://www.jmlr.org/papers/v5/

Besides that, there are no rules, have fun.",14,18
121,2017-12-4,2017,12,4,7,7hczd5,[R] Dealing with low quality reviews,https://www.reddit.com/r/MachineLearning/comments/7hczd5/r_dealing_with_low_quality_reviews/,largemind,1512340776,"While the other reviews generally seem positive with well thought out criticism, one of the reviewers was late by a week, gave a very low score with a one-line cursory reasoning which basically repeats the other reviewers' comments verbatim. There is no indication that they have even read the paper. This kind of behavior seems highly unprofessional. Especially in a conference where reviews determine whether the work someone spent months or years on gets accepted.
What would you do in this situation?",16,54
122,2017-12-4,2017,12,4,7,7hd2vj,[D] Learning a Gaussian Decoder in a Variational Autoencoder,https://www.reddit.com/r/MachineLearning/comments/7hd2vj/d_learning_a_gaussian_decoder_in_a_variational/,n3ur0n,1512341717,"I have been trying to code up a Variational Autoencoder (VAE) in tensorflow. I was able to implement the version with has a Gaussian encoder network and a Bernoulli decoder as in [https://arxiv.org/abs/1312.6114].

However, I would like to work with real valued data and I have not been able to get a VAE with a Gaussian decoder to work. I have narrowed this down to the problem with my network: my network does not seem to learn the parameters of the diagonal multivariate Gaussian. Here is the code for very simple test case. Where my input data is just drawn from a normal(0,1). The network needs to learn is the mean and variance of my data. I would expect the mean to converge to 0 and variance to converge to 1. But it does not, would appreciate any insights into what might be going wrong here. 

 

    import tensorflow as tf
    import numpy as np

    tf.reset_default_graph()

    input_dim = 1
    hidden_dim = 10
    learning_rate = 0.001
    num_batches = 1000

    # Network
    x = tf.placeholder(tf.float32, (None, input_dim))

    with tf.variable_scope('Decoder'):
        h1 = tf.layers.dense(x, hidden_dim, activation=tf.nn.softplus, name='h1')
        mu = tf.layers.dense(h1, input_dim, activation=tf.nn.softplus, name='mu')
        diag_stdev = tf.layers.dense(h1, input_dim, activation=tf.nn.softplus, name='diag_stdev')
    
    # Loss: -log(p(x))
    with tf.variable_scope('Loss'):
        dist = tf.contrib.distributions.MultivariateNormalDiag(loc=mu, scale_diag=diag_stdev)
        loss = - tf.reduce_mean(tf.log(1e-10 + dist.prob(x)))
    
    # Optimizer
    train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)
    summary_writer = tf.summary.FileWriter('./log_dir', tf.get_default_graph())

    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        mu_plot = np.zeros(num_batches,)
        for i in range(num_batches): # degenerate case batch_size of 1
            input_ = np.random.multivariate_normal(mean=[0], cov=np.diag([1]), size=(1))    
            loss_ , mu_ , diag_stdev_ , _ = sess.run([loss, mu, diag_stdev, train_step],feed_dict={x: input_})
            print(""-p(x): {}, mu: {}, diag_stdev: {}"".format(loss_, mu_,diag_stdev_))   ",5,0
123,2017-12-4,2017,12,4,8,7hdakn,[D] Custom Keras Layer,https://www.reddit.com/r/MachineLearning/comments/7hdakn/d_custom_keras_layer/,beef__,1512343812,"Hate to ask a question like this on machine learning but googling has yielded nothing useful - I've just found 2 github threads where people on super old versions of tensorflow got the same error *message*, but not for the same reason im getting it.

Basically; I'm implementing this facial point paper for work; and it uses spatial softargmax (just a layer that takes in a stack of images a lot like [this](https://i.imgur.com/YILPB6H.png) - and it returns the most ""intense part"" of the image (so just the x,y coordinates of the white blob). It takes in an array with 68 of these images (all 1 channel, so the array is 100x100x68) and it gives 68 pairs of x,y coordinates for each one - these end up being the facial points.

The layer I have written in keras to do this is;

    class spatial_softArgmax(Layer):
    
    		def __init__(self, output_dim, **kwargs):
    				self.output_dim = 136#output_dim
    				super(spatial_softArgmax, self).__init__(**kwargs)

    		def build(self, input_shape):
    				# Create a trainable weight variable for this layer.
    				self.kernel = self.add_weight(name='kernel', shape=(input_shape[1], self.output_dim), initializer='uniform', trainable=True)
    					super(spatial_softArgmax, self).build(input_shape)  # Be sure to call this somewhere!

    			def call(self, x):
    					filters = x
    					temperature = 1.0
    					shape = tf.shape(filters)
    					height, width, num_channels = shape[1], shape[2], shape[3]

    					posx, posy = tf.meshgrid(tf.lin_space(-1., 1., num = height),
    																	 tf.lin_space(-1., 1., num = width),
    																	 indexing='ij')
    					posx = tf.reshape(posx, [height * width])
    					posy = tf.reshape(posy, [height * width])

    					filters = tf.reshape(tf.transpose(filters, [0, 3, 1, 2]), [-1, height * width])

    					softmax_attention = tf.nn.softmax(filters / temperature)

    					expected_x = tf.reduce_sum(posx * softmax_attention, 1, keep_dims = True)
    					expected_y = tf.reduce_sum(posy * softmax_attention, 1, keep_dims = True)

    					expected_xy = tf.concat([expected_x, expected_y], axis = 1)

    					feature_keypoints = tf.reshape(expected_xy, [-1, num_channels * 2])

    					return feature_keypoints


    			def get_config(self):
    					config = super(spatial_softArgmax, self).get_config()
    					config['output_dim'] = self.output_dim
    					config['input_shape'] = self.input_shape
    					return config

    			def compute_output_shape(self, input_shape):
    					return (input_shape[0], self.output_dim)


It isn't working though; like at all; I keep getting this error that says 'None Values not supported' - which makes me think that my layer isn't returning anything?? I dug around in the TF code a bit around where this exception is raise but didn't really find much...

If you guys see anything wrong with my layer just by glancing i'd really appreciate it if you'd let me know; I *need* to have this network training overnight tonight.",7,0
124,2017-12-4,2017,12,4,9,7hdlhf,How does one use Hermite polynomials in pytorch with Stochastic Gradient Descent (SGD)?,https://www.reddit.com/r/MachineLearning/comments/7hdlhf/how_does_one_use_hermite_polynomials_in_pytorch/,real_charlie_parker,1512346821,,0,1
125,2017-12-4,2017,12,4,10,7hdyy2,[1712.00321] Semi-Adversarial Networks: Convolutional Autoencoders for Imparting Privacy to Face Images,https://www.reddit.com/r/MachineLearning/comments/7hdyy2/171200321_semiadversarial_networks_convolutional/,mlk1245,1512350636,,0,1
126,2017-12-4,2017,12,4,10,7hdz5a,Probabilistic Torch (deep generative models that extends PyTorch),https://www.reddit.com/r/MachineLearning/comments/7hdz5a/probabilistic_torch_deep_generative_models_that/,[deleted],1512350693,[deleted],0,1
127,2017-12-4,2017,12,4,10,7he0t3,[P] Using T-SNE to Visualise how your Deep Model thinks,https://www.reddit.com/r/MachineLearning/comments/7he0t3/p_using_tsne_to_visualise_how_your_deep_model/,harvey_slash,1512351145,,2,0
128,2017-12-4,2017,12,4,11,7he85s,"ProbTorch: a library for deep generative models that extends PyTorch, similar in spirit to Edward and Pyro from researchers at U.Oxford",https://www.reddit.com/r/MachineLearning/comments/7he85s/probtorch_a_library_for_deep_generative_models/,balazshoranyi,1512353256,,0,1
129,2017-12-4,2017,12,4,11,7hebvm,[D] Intel invites Flo Rida to NIPS,https://www.reddit.com/r/MachineLearning/comments/7hebvm/d_intel_invites_flo_rida_to_nips/,Reiinakano,1512354349,,11,56
130,2017-12-4,2017,12,4,12,7hek26,Toothpick Packing Machine | Chopstick Packing Machine for Sale,https://www.reddit.com/r/MachineLearning/comments/7hek26/toothpick_packing_machine_chopstick_packing/,liusherry,1512356808,,1,1
131,2017-12-4,2017,12,4,12,7hemdl,Malaysia Rice Noodle Machine | Thai Flat Rice Noodle Machine for Sale,https://www.reddit.com/r/MachineLearning/comments/7hemdl/malaysia_rice_noodle_machine_thai_flat_rice/,liusherry,1512357498,[removed],1,1
132,2017-12-4,2017,12,4,12,7heoi2,Fresh Noodle Making Machine Features,https://www.reddit.com/r/MachineLearning/comments/7heoi2/fresh_noodle_making_machine_features/,liusherry,1512358127,[removed],1,1
133,2017-12-4,2017,12,4,12,7hesod,Optimization for Deep Learning Highlights in 2017,https://www.reddit.com/r/MachineLearning/comments/7hesod/optimization_for_deep_learning_highlights_in_2017/,balazshoranyi,1512359395,,0,2
134,2017-12-4,2017,12,4,13,7heyrw,"How to transform an image irreversibly and without any information loss, to an human unreadable one?",https://www.reddit.com/r/MachineLearning/comments/7heyrw/how_to_transform_an_image_irreversibly_and/,[deleted],1512361265,,0,1
135,2017-12-4,2017,12,4,14,7hffft,Suggestions on Capsule net pytorch implementation.,https://www.reddit.com/r/MachineLearning/comments/7hffft/suggestions_on_capsule_net_pytorch_implementation/,aliasvishnu,1512366827,[removed],0,1
136,2017-12-4,2017,12,4,16,7hfx5n,Organic fertilizer Granulation Machine,https://www.reddit.com/r/MachineLearning/comments/7hfx5n/organic_fertilizer_granulation_machine/,amylee516,1512373825,,0,1
137,2017-12-4,2017,12,4,17,7hfzb7,The Sri Lanka client order the jacket reactor for graft glue,https://www.reddit.com/r/MachineLearning/comments/7hfzb7/the_sri_lanka_client_order_the_jacket_reactor_for/,mixmachinery,1512374746,[removed],0,1
138,2017-12-4,2017,12,4,18,7hgadt,[D] What algorithm is best for nodule detection using LUNA16?,https://www.reddit.com/r/MachineLearning/comments/7hgadt/d_what_algorithm_is_best_for_nodule_detection/,song6987,1512379800,"I read a few papers and read a paper called CASED (curriculum adaptive sampling for extreme data imbalance).
The average sensitivity is very high (0.883) Do you have a paper that surpasses this?

If you know anything, please let me know. And let me know if there is a paper that has been implemented as Tensorflow or Pytorch.

CASED does not seem to be implemented in code yet.",7,8
139,2017-12-4,2017,12,4,18,7hgah3,Black in AI,https://www.reddit.com/r/MachineLearning/comments/7hgah3/black_in_ai/,translucent_person,1512379839,,1,1
140,2017-12-4,2017,12,4,19,7hgfhw,Automatic differentiation from scratch,https://www.reddit.com/r/MachineLearning/comments/7hgfhw/automatic_differentiation_from_scratch/,[deleted],1512382083,[deleted],0,1
141,2017-12-4,2017,12,4,19,7hggzj,[D] Attention models and Bidirectional RNNs Combating Vanishing Gradient,https://www.reddit.com/r/MachineLearning/comments/7hggzj/d_attention_models_and_bidirectional_rnns/,getlasterror,1512382691,"When thinking about it, adding Attention or using a Bidirectional RNN, will create shortcuts for the gradients to flow through. Much like residual connections in deep convolutional networks.

Attention will use the hidden state of each item in the sequence and directly connect it to the output. A Bidirectional RNN will allow the gradients to reach directly to the start of the sequence.

So, a question arise: How much of the efficiency achieved by attention or bidirectional RNNs comes directly from allowing the gradients to flow through?",6,28
142,2017-12-4,2017,12,4,19,7hgjsd,How to convert a Naive Bayes' email classifier to Bayesian classifier?,https://www.reddit.com/r/MachineLearning/comments/7hgjsd/how_to_convert_a_naive_bayes_email_classifier_to/,redditaddict07,1512383939,[removed],0,1
143,2017-12-4,2017,12,4,19,7hgksg,Machine Learning and AI Trends in 2018,https://www.reddit.com/r/MachineLearning/comments/7hgksg/machine_learning_and_ai_trends_in_2018/,samarpaninfotech,1512384387,,0,1
144,2017-12-4,2017,12,4,20,7hgrnw,"[N] 1st open tournament on Pareto efficient deep learning (speed, accuracy, costs) at ACM ASPLOS'18",https://www.reddit.com/r/MachineLearning/comments/7hgrnw/n_1st_open_tournament_on_pareto_efficient_deep/,mllosab,1512387253,,11,54
145,2017-12-4,2017,12,4,21,7hh0ed,Access to Data denied,https://www.reddit.com/r/MachineLearning/comments/7hh0ed/access_to_data_denied/,wonderful_teacher,1512390577,[removed],0,1
146,2017-12-4,2017,12,4,22,7hh9xq,Another accolade for Engati... now listed as a top 5 platforms - this time from our friends in Indonesia - Engati also supports Bahasa and already has paying customers in the country. What are you waiting for - lets Engati at www.engati.com,https://www.reddit.com/r/MachineLearning/comments/7hh9xq/another_accolade_for_engati_now_listed_as_a_top_5/,getengati,1512393806,,0,1
147,2017-12-4,2017,12,4,22,7hhfx3,Apache Spark with Python Course- The next generation of Big Data [FREE],https://www.reddit.com/r/MachineLearning/comments/7hhfx3/apache_spark_with_python_course_the_next/,samiali123,1512395665,,0,1
148,2017-12-4,2017,12,4,23,7hhlq9,[N]How neural networks think,https://www.reddit.com/r/MachineLearning/comments/7hhlq9/nhow_neural_networks_think/,digitalson,1512397360,,0,1
149,2017-12-4,2017,12,4,23,7hhm6z,"For those you who want to go the academic route, what advice would you give to a fledgling undergrad senior who will most likely do a masters at a below average school?",https://www.reddit.com/r/MachineLearning/comments/7hhm6z/for_those_you_who_want_to_go_the_academic_route/,riseupmeansturnup,1512397498,[removed],0,1
150,2017-12-4,2017,12,4,23,7hhn4e,Need some help with this code for tic-tac-toe. Specifically the backpropogation part.,https://www.reddit.com/r/MachineLearning/comments/7hhn4e/need_some_help_with_this_code_for_tictactoe/,Jehovacoin,1512397763,[removed],0,1
151,2017-12-4,2017,12,4,23,7hhr60,The Last 5 Years In Deep Learning,https://www.reddit.com/r/MachineLearning/comments/7hhr60/the_last_5_years_in_deep_learning/,adeshpande3,1512398930,,0,1
152,2017-12-5,2017,12,5,0,7hhvqy,Interpretable Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7hhvqy/interpretable_machine_learning/,curizzo,1512400215,,0,1
153,2017-12-5,2017,12,5,0,7hi599,[D] When to Run Bandit Tests Instead of A/B/n Tests,https://www.reddit.com/r/MachineLearning/comments/7hi599/d_when_to_run_bandit_tests_instead_of_abn_tests/,_alphamaximus_,1512402662,,0,1
154,2017-12-5,2017,12,5,1,7hi8qg,Nhng iu cn bit v my ozone,https://www.reddit.com/r/MachineLearning/comments/7hi8qg/nhng_iu_cn_bit_v_my_ozone/,leethanhhien91,1512403532,[removed],0,1
155,2017-12-5,2017,12,5,1,7hia25,Any NLP tools to extract idioms and phrase from a passage?,https://www.reddit.com/r/MachineLearning/comments/7hia25/any_nlp_tools_to_extract_idioms_and_phrase_from_a/,sammyjiang,1512403852,[removed],0,1
156,2017-12-5,2017,12,5,1,7hibfd,"Live from NIPS 2017, Deep Learning:Practice and Trends Tutorial",https://www.reddit.com/r/MachineLearning/comments/7hibfd/live_from_nips_2017_deep_learningpractice_and/,shagunsodhani,1512404185,,0,1
157,2017-12-5,2017,12,5,1,7hid3f,ML with Numpy or TensorFlow?,https://www.reddit.com/r/MachineLearning/comments/7hid3f/ml_with_numpy_or_tensorflow/,revoloution,1512404585,[removed],0,1
158,2017-12-5,2017,12,5,1,7hifto,Selective Attention - Noise As Targets (Machine Learning Video Podcast),https://www.reddit.com/r/MachineLearning/comments/7hifto/selective_attention_noise_as_targets_machine/,[deleted],1512405248,[deleted],0,1
159,2017-12-5,2017,12,5,1,7hih4q,[D] Boltzmann machines,https://www.reddit.com/r/MachineLearning/comments/7hih4q/d_boltzmann_machines/,spartan12321,1512405557,"I have started to look in boltzmann machines(RBM, DBN) as I saw it in table of contents of Deep learning(Goodfellow, Bengio, Courville)...but I didin't notice these in computer vision and NLP courses from Stanford and I can't find any important recent applications...is it even worth digging in this area?

EDIT:Yes, I too find them interesting, but to express myself differently...is it time efficient to study them, is this architecture with bigger potential than GANs etc. - the things that are hot now? In NIPS 2016 Tutorial:
Generative Adversarial Networks Ian Goodfellow writes about Boltzmann machine's shortcomings relative to GANs",35,22
160,2017-12-5,2017,12,5,1,7hihpo,"Baidu SVAIL: Deep Learning Scaling is Predictable, Empirically",https://www.reddit.com/r/MachineLearning/comments/7hihpo/baidu_svail_deep_learning_scaling_is_predictable/,gdiamos,1512405699,,1,1
161,2017-12-5,2017,12,5,2,7hings,What type of orthogonal polynomials does R use?,https://www.reddit.com/r/MachineLearning/comments/7hings/what_type_of_orthogonal_polynomials_does_r_use/,real_charlie_parker,1512407187,,0,1
162,2017-12-5,2017,12,5,2,7hir2p,Large scale transport mode classification from mobile sensor data,https://www.reddit.com/r/MachineLearning/comments/7hir2p/large_scale_transport_mode_classification_from/,xristos_forokolomvos,1512408160,,0,4
163,2017-12-5,2017,12,5,2,7hiwte,"[R]In Mammalian brain the entorhinal cortex contains grid cells which encode space information using grid like pattern. When RNN is trained to predict its position from speed and direction, such grid cells-like neurons emerge automatically",https://www.reddit.com/r/MachineLearning/comments/7hiwte/rin_mammalian_brain_the_entorhinal_cortex/,finallyifoundvalidUN,1512409464,,10,186
164,2017-12-5,2017,12,5,3,7hjdz4,NIPS 2017 papers: Add comments and ask questions to the authors,https://www.reddit.com/r/MachineLearning/comments/7hjdz4/nips_2017_papers_add_comments_and_ask_questions/,mgdo,1512413309,,0,1
165,2017-12-5,2017,12,5,3,7hjggb,Three reasons machine learning models go out of sync,https://www.reddit.com/r/MachineLearning/comments/7hjggb/three_reasons_machine_learning_models_go_out_of/,alexa_y,1512413901,,0,1
166,2017-12-5,2017,12,5,4,7hji6d,NIPS livestream,https://www.reddit.com/r/MachineLearning/comments/7hji6d/nips_livestream/,nivrams_brain,1512414297,[removed],0,1
167,2017-12-5,2017,12,5,4,7hjsdz,Small sample size problem with high data imbalance,https://www.reddit.com/r/MachineLearning/comments/7hjsdz/small_sample_size_problem_with_high_data_imbalance/,fly200,1512416561,[removed],0,1
168,2017-12-5,2017,12,5,5,7hjxpw,Automatic differentiation from scratch,https://www.reddit.com/r/MachineLearning/comments/7hjxpw/automatic_differentiation_from_scratch/,[deleted],1512417766,[deleted],0,1
169,2017-12-5,2017,12,5,5,7hk03q,Faster Machine Learning in a World with Limited Memory,https://www.reddit.com/r/MachineLearning/comments/7hk03q/faster_machine_learning_in_a_world_with_limited/,Bhima,1512418290,,0,2
170,2017-12-5,2017,12,5,5,7hk6r1,[D]How to deal with blank fragments in time series analysis?,https://www.reddit.com/r/MachineLearning/comments/7hk6r1/dhow_to_deal_with_blank_fragments_in_time_series/,yetionyo,1512419832,"Now I am going to use CNN or RNN to extract features in a time sequence, for example, a sequence related to user clicks, (Oct 10 19:20:30 click page 10,  Oct 10 19:20:35 click page 22, etc). Simply, I can represent the two clicks as 000...10.....22...000 (0 for no click). As you can see, if use one number for the action in one second, that will generate a quite long sequence with a lot of blank fragments, which is not good for RNN or CNN. But we remove all zeros, only with 10-22  we don't know the time interval between two clicks. So, can anyone give a suggestion on how to express this kind of sequence properly so that we can combine it with neural networks easily?",9,2
171,2017-12-5,2017,12,5,5,7hk8rj,[N] DeepVariant: Highly Accurate Genomes With Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/7hk8rj/n_deepvariant_highly_accurate_genomes_with_deep/,Jackal008,1512420327,,3,41
172,2017-12-5,2017,12,5,5,7hkbfl,IBM Scientists Demonstrate 10x Faster Machine Learning using GPU,https://www.reddit.com/r/MachineLearning/comments/7hkbfl/ibm_scientists_demonstrate_10x_faster_machine/,[deleted],1512420948,[deleted],0,1
173,2017-12-5,2017,12,5,6,7hkjaj,[R] Understanding unsupervised learning by predicting noise (video podcast),https://www.reddit.com/r/MachineLearning/comments/7hkjaj/r_understanding_unsupervised_learning_by/,CaHoop,1512422725,,2,9
174,2017-12-5,2017,12,5,6,7hkk40,Understanding exactly what the cell of an LSTM Neural Network is,https://www.reddit.com/r/MachineLearning/comments/7hkk40/understanding_exactly_what_the_cell_of_an_lstm/,JustinQueeber,1512422911,[removed],0,1
175,2017-12-5,2017,12,5,7,7hkw59,[N] Facebook AI Research Residency Program,https://www.reddit.com/r/MachineLearning/comments/7hkw59/n_facebook_ai_research_residency_program/,baylearn,1512425636,,11,55
176,2017-12-5,2017,12,5,7,7hkwsk,Why does the amount of recurrent layers destroy my LSTM model?,https://www.reddit.com/r/MachineLearning/comments/7hkwsk/why_does_the_amount_of_recurrent_layers_destroy/,Rijstwafel,1512425785,[removed],0,1
177,2017-12-5,2017,12,5,7,7hkyzh,What preprocessing steps do you apply?,https://www.reddit.com/r/MachineLearning/comments/7hkyzh/what_preprocessing_steps_do_you_apply/,Mellow_Naboo_Senator,1512426308,[removed],0,1
178,2017-12-5,2017,12,5,8,7hllm0,[P] SmallVis: Comparing non-linear dimension reduction techniques,https://www.reddit.com/r/MachineLearning/comments/7hllm0/p_smallvis_comparing_nonlinear_dimension/,lmcinnes,1512431745,,0,0
179,2017-12-5,2017,12,5,9,7hlp89,Weather Identification ML Idea,https://www.reddit.com/r/MachineLearning/comments/7hlp89/weather_identification_ml_idea/,connornishijima,1512432670,[removed],0,1
180,2017-12-5,2017,12,5,10,7hm1ei,[R] The makings of a smart cookie,https://www.reddit.com/r/MachineLearning/comments/7hm1ei/r_the_makings_of_a_smart_cookie/,cherls,1512435777,,7,10
181,2017-12-5,2017,12,5,10,7hm2oq,"[D] Making ConvNets classify based on the ""right"" reasons",https://www.reddit.com/r/MachineLearning/comments/7hm2oq/d_making_convnets_classify_based_on_the_right/,notevencrazy99,1512436098,"I was reading [this paper](https://arxiv.org/pdf/1710.04934v1.pdf) on image classification. And they have this interesting ""attention"" approach on which, they additionaly to minimizing a binary loss they minimize IoU on different levels of the network.

https://i.imgur.com/hSgGjjB.jpg

Is my intuition correct that this would make so that the model would classify more based on what was segmented in the training set?

For image classification problems on which the pattern being classified for is more ""discrete"", would this make so less data is required?

What is the name of this approach? Is this something very well known? Are there any famous paper on this?

",3,2
182,2017-12-5,2017,12,5,10,7hm3rh,[P] Scattertext 2.14: Interactive visualization of feature importances in text classification,https://www.reddit.com/r/MachineLearning/comments/7hm3rh/p_scattertext_214_interactive_visualization_of/,jasonskessler,1512436374,,0,7
183,2017-12-5,2017,12,5,10,7hm5to,What does double-blind review mean?,https://www.reddit.com/r/MachineLearning/comments/7hm5to/what_does_doubleblind_review_mean/,[deleted],1512436898,,0,1
184,2017-12-5,2017,12,5,11,7hmkpj,My book 'Practical Machine Learning with R and Python' on Amazon,https://www.reddit.com/r/MachineLearning/comments/7hmkpj/my_book_practical_machine_learning_with_r_and/,tvganesh,1512440940,,0,1
185,2017-12-5,2017,12,5,11,7hmpee,PyTorch 0.3.0 is out!,https://www.reddit.com/r/MachineLearning/comments/7hmpee/pytorch_030_is_out/,balazshoranyi,1512442189,,0,2
186,2017-12-5,2017,12,5,12,7hmrxh,Python library for scraping training data from Bing Image API,https://www.reddit.com/r/MachineLearning/comments/7hmrxh/python_library_for_scraping_training_data_from/,Beardo01,1512442867,,0,1
187,2017-12-5,2017,12,5,12,7hmwe9,"[P] PyTorch 0.3 is out with performance improvements, ONNX/CUDA 9/CUDNN 7 support",https://www.reddit.com/r/MachineLearning/comments/7hmwe9/p_pytorch_03_is_out_with_performance_improvements/,m_ke,1512444075,,44,190
188,2017-12-5,2017,12,5,13,7hn6hs,"[D] New to ML in general but just out of curiosity, how old is everyone/whats your background like?",https://www.reddit.com/r/MachineLearning/comments/7hn6hs/d_new_to_ml_in_general_but_just_out_of_curiosity/,LilFinger,1512446933,"I tried searching for another thread but couldn't find much information but apologies if this has been asked plenty. 

I'm just starting my masters in the field and while I'm very interested and excited about this I tend to feel anxious with every thread I come across here because I feel that I'm pretty ""behind"". So what age group are most people here? What academic backgrounds do you have? How long did it take before you felt like you're starting to know what you're doing? 

Thanks",30,1
189,2017-12-5,2017,12,5,14,7hnhfm,ISB - CBA project invite.,https://www.reddit.com/r/MachineLearning/comments/7hnhfm/isb_cba_project_invite/,paritosh_tiwari,1512450342,[removed],0,1
190,2017-12-5,2017,12,5,14,7hnpd5,A C# deep learning wrapper with CNTK backend,https://www.reddit.com/r/MachineLearning/comments/7hnpd5/a_c_deep_learning_wrapper_with_cntk_backend/,siadroid,1512452882,,0,1
191,2017-12-5,2017,12,5,15,7hnsre,Pytorch implementation of FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks,https://www.reddit.com/r/MachineLearning/comments/7hnsre/pytorch_implementation_of_flownet_20_evolution_of/,fitsumreda,1512454068,,0,1
192,2017-12-5,2017,12,5,16,7ho22l,[P] Large scale transport mode classification from mobile sensor data,https://www.reddit.com/r/MachineLearning/comments/7ho22l/p_large_scale_transport_mode_classification_from/,esurior,1512457547,,2,28
193,2017-12-5,2017,12,5,16,7ho38r,Bentonite fertilizer granulator machine,https://www.reddit.com/r/MachineLearning/comments/7ho38r/bentonite_fertilizer_granulator_machine/,amylee516,1512457990,,0,1
194,2017-12-5,2017,12,5,16,7ho8rc,Internships in the Bay Area for First Year Undergrad?,https://www.reddit.com/r/MachineLearning/comments/7ho8rc/internships_in_the_bay_area_for_first_year/,ML-GODS,1512460255,[removed],0,1
195,2017-12-5,2017,12,5,17,7hoadz,[R] Using Articial Intelligence to Augment Human Intelligence,https://www.reddit.com/r/MachineLearning/comments/7hoadz/r_using_articial_intelligence_to_augment_human/,wei_jok,1512460979,,11,27
196,2017-12-5,2017,12,5,17,7hoeuo,Rice Noodle Machine | Thai Flat Rice Noodle Machine for Sale,https://www.reddit.com/r/MachineLearning/comments/7hoeuo/rice_noodle_machine_thai_flat_rice_noodle_machine/,liusherry,1512462998,[removed],1,1
197,2017-12-5,2017,12,5,17,7hohsd,[R] A Simple Yet Efficient Rank One Update for Covariance Matrix Adaptation,https://www.reddit.com/r/MachineLearning/comments/7hohsd/r_a_simple_yet_efficient_rank_one_update_for/,[deleted],1512464386,[deleted],0,1
198,2017-12-5,2017,12,5,18,7hoiw0,Automatic differentiation from scratch,https://www.reddit.com/r/MachineLearning/comments/7hoiw0/automatic_differentiation_from_scratch/,totallynotAGI,1512464868,,1,1
199,2017-12-5,2017,12,5,18,7hol4d,Fresh Noodle Making Machine with 6 Rollers for Sale,https://www.reddit.com/r/MachineLearning/comments/7hol4d/fresh_noodle_making_machine_with_6_rollers_for/,liusherry,1512465805,[removed],1,1
200,2017-12-5,2017,12,5,18,7honrp,[N] Crowd-Acting: A New Way to Grow Large-Scale Video Datasets for Deep Learning,https://www.reddit.com/r/MachineLearning/comments/7honrp/n_crowdacting_a_new_way_to_grow_largescale_video/,nahuak,1512466931,,5,4
201,2017-12-5,2017,12,5,18,7hooja,Artificial Intelligence/ Machine Learning in Europe,https://www.reddit.com/r/MachineLearning/comments/7hooja/artificial_intelligence_machine_learning_in_europe/,gantaaa,1512467311,[removed],0,1
202,2017-12-5,2017,12,5,19,7hos89,What's the future for hardware? When will we be able to buy TPUs?,https://www.reddit.com/r/MachineLearning/comments/7hos89/whats_the_future_for_hardware_when_will_we_be/,[deleted],1512468791,,0,1
203,2017-12-5,2017,12,5,19,7hosa9,[D] What's the future for hardware? When will we be able to buy TPUs?,https://www.reddit.com/r/MachineLearning/comments/7hosa9/d_whats_the_future_for_hardware_when_will_we_be/,Valiox,1512468809,,11,2
204,2017-12-5,2017,12,5,20,7hp0pj,[P] PyTorch/Tensorflow implementations of kernel-based activation functions,https://www.reddit.com/r/MachineLearning/comments/7hp0pj/p_pytorchtensorflow_implementations_of/,scardax88,1512472285,,5,7
205,2017-12-5,2017,12,5,21,7hpa4i,[N]Using Machine Learning to Predict the Weather: Part 2,https://www.reddit.com/r/MachineLearning/comments/7hpa4i/nusing_machine_learning_to_predict_the_weather/,chris_shpak,1512475964,,0,1
206,2017-12-5,2017,12,5,21,7hpasr,Publish year on ML Papers,https://www.reddit.com/r/MachineLearning/comments/7hpasr/publish_year_on_ml_papers/,BSmartBSharp,1512476215,[removed],0,1
207,2017-12-5,2017,12,5,22,7hpryx,[P] ML Revision Notes,https://www.reddit.com/r/MachineLearning/comments/7hpryx/p_ml_revision_notes/,acbraith,1512481902,"I'm not sure if this kind of stuff is appropriate to share here, but I recently scanned all my revision notes from my masters in stats+ML and put it on my GitHub [here](https://github.com/acbraith/CSML_notes).

I personally find reading textbooks a bit boring and prefer something more condensed, hence these summary notes. Not sure how intelligible/legible they'll be to others, but I like them and maybe someone here will too. They are quite tailored to the specific exams I was taking though, meaning there is a reasonable bit of repetition and somewhat arbitrary points get highlighted.",12,94
208,2017-12-5,2017,12,5,23,7hpy9m,Evolutinary Game of Life with Genetic Algorithm,https://www.reddit.com/r/MachineLearning/comments/7hpy9m/evolutinary_game_of_life_with_genetic_algorithm/,ljmocic,1512483684,,0,1
209,2017-12-5,2017,12,5,23,7hpyls,"Caffe2, MxNet, pytorch, how I can select?",https://www.reddit.com/r/MachineLearning/comments/7hpyls/caffe2_mxnet_pytorch_how_i_can_select/,xiaojidan,1512483785,[removed],0,1
210,2017-12-5,2017,12,5,23,7hq1wg,torchvision 0.2.0 released alongside PyTorch 0.3.0,https://www.reddit.com/r/MachineLearning/comments/7hq1wg/torchvision_020_released_alongside_pytorch_030/,balazshoranyi,1512484710,,0,1
211,2017-12-6,2017,12,6,0,7hq8nx,My Best of AI articles in November!,https://www.reddit.com/r/MachineLearning/comments/7hq8nx/my_best_of_ai_articles_in_november/,martmull,1512486534,,0,1
212,2017-12-6,2017,12,6,1,7hqydg,[D] Best of AI articles in November!,https://www.reddit.com/r/MachineLearning/comments/7hqydg/d_best_of_ai_articles_in_november/,fl4v1,1512492726,,0,1
213,2017-12-6,2017,12,6,2,7hr5ce,Locality sensitive hashing inspired by fruit fly brain,https://www.reddit.com/r/MachineLearning/comments/7hr5ce/locality_sensitive_hashing_inspired_by_fruit_fly/,iamjaiyam,1512494330,[removed],0,1
214,2017-12-6,2017,12,6,2,7hr74p,[R] Convolutional Networks with Adaptive Computation Graphs,https://www.reddit.com/r/MachineLearning/comments/7hr74p/r_convolutional_networks_with_adaptive/,xternalz,1512494724,,8,13
215,2017-12-6,2017,12,6,2,7hrf2r,NIPS 2017  Day 1 Highlights,https://www.reddit.com/r/MachineLearning/comments/7hrf2r/nips_2017_day_1_highlights/,e_ameisen,1512496539,,0,1
216,2017-12-6,2017,12,6,3,7hrj3l,[R] Source Code Identifier Embeddings,https://www.reddit.com/r/MachineLearning/comments/7hrj3l/r_source_code_identifier_embeddings/,markovtsev,1512497457,,0,19
217,2017-12-6,2017,12,6,3,7hrl9u,Amazon ML vs. SageMaker - Biggest differences?,https://www.reddit.com/r/MachineLearning/comments/7hrl9u/amazon_ml_vs_sagemaker_biggest_differences/,infinitejester7,1512497950,[removed],0,1
218,2017-12-6,2017,12,6,3,7hrrdd,My code got reused by someone else,https://www.reddit.com/r/MachineLearning/comments/7hrrdd/my_code_got_reused_by_someone_else/,[deleted],1512499348,,0,1
219,2017-12-6,2017,12,6,3,7hruom,MLP with default parameters performing way worse than the SGD,https://www.reddit.com/r/MachineLearning/comments/7hruom/mlp_with_default_parameters_performing_way_worse/,h4k1m0u,1512500093,[removed],0,1
220,2017-12-6,2017,12,6,4,7hs1ig,Is it possible to label subreddit names with machine learning?,https://www.reddit.com/r/MachineLearning/comments/7hs1ig/is_it_possible_to_label_subreddit_names_with/,BRAF-V600E,1512501620,[removed],0,1
221,2017-12-6,2017,12,6,4,7hs1qe,[R] TensorFlow Distributions,https://www.reddit.com/r/MachineLearning/comments/7hs1qe/r_tensorflow_distributions/,visarga,1512501670,,0,6
222,2017-12-6,2017,12,6,4,7hs4rm,Sentiment Discovery - Unsupervised Language Modeling at scale for robust sentiment classification [NVIDIA],https://www.reddit.com/r/MachineLearning/comments/7hs4rm/sentiment_discovery_unsupervised_language/,[deleted],1512502372,[deleted],0,1
223,2017-12-6,2017,12,6,4,7hs89l,[P] Sentiment Discovery - Unsupervised Language Modeling at scale for robust sentiment classification [NVIDIA],https://www.reddit.com/r/MachineLearning/comments/7hs89l/p_sentiment_discovery_unsupervised_language/,raulpr,1512503164,,10,35
224,2017-12-6,2017,12,6,5,7hscfd,[D] Seeking advice on Udacity's Self-driving Car Nanodegree,https://www.reddit.com/r/MachineLearning/comments/7hscfd/d_seeking_advice_on_udacitys_selfdriving_car/,F1lover143,1512504129,"I have completed Andrew Ng's two courses - Machine Learning &amp; Deep Learning specialization (4 courses out of 5). 


Next I am considering enrolling in Sebastian Thrun's Self-driving car course. Do you guys think it is worth it? 


My interest area is computer vision. I would like to pursue rest of my career in it. 


Thanks.",4,2
225,2017-12-6,2017,12,6,7,7htcop,Is it possible that a KNN-model outperforms a Random Forest (RF) model no matter how much I tune the RF?,https://www.reddit.com/r/MachineLearning/comments/7htcop/is_it_possible_that_a_knnmodel_outperforms_a/,LegendSweeper,1512512624,[removed],0,1
226,2017-12-6,2017,12,6,7,7htftb,"[N] Josh Wills, Head of Data Engineering, Slack",https://www.reddit.com/r/MachineLearning/comments/7htftb/n_josh_wills_head_of_data_engineering_slack/,mlconf,1512513345,,1,0
227,2017-12-6,2017,12,6,7,7htg5f,[D]Someone copied parts of my code and changed the license,https://www.reddit.com/r/MachineLearning/comments/7htg5f/dsomeone_copied_parts_of_my_code_and_changed_the/,Ouitos,1512513432,"Hey there,

Let's get straight to the point : yesterday, NVIDIA released an open source[ pytorch implementation of flownet2](https://github.com/NVIDIA/flownet2-pytorch), which released a CUDA version of the correlation layer introduced by the paper [FlowNet](https://arxiv.org/abs/1504.06852). It turns out out that this code is protected by NVIDIA copyright while it heavily reuse parts of a code I wrote myslef 6 months ago : [FlowNet Pytorch](https://github.com/ClementPinard/FlowNetPytorch)

My goal is not to rant or to fulfil my self esteem, but to figure what to do in the most pragmatic manner in order to take the best of both worlds and make the best implementation possible.

That's not the most important part, but as a proof, here are some comparisons you can make :

[mine](https://github.com/ClementPinard/FlowNetPytorch/blob/607f99f46be3eccbd9b07c73848a68bc12156392/multiscaleloss.py#L8) - [theirs](https://github.com/NVIDIA/flownet2-pytorch/blob/master/losses.py#L46)

[mine](https://github.com/ClementPinard/FlowNetPytorch/blob/5381bd5c699b850785ab5dec6fda523b9126c912/models/FlowNetS.py#L32) - [theirs](https://github.com/NVIDIA/flownet2-pytorch/blob/master/networks/FlowNetS.py#L11)

[mine](https://github.com/ClementPinard/FlowNetPytorch/blob/5381bd5c699b850785ab5dec6fda523b9126c912/models/FlowNetS.py#L9) - [theirs](https://github.com/NVIDIA/flownet2-pytorch/blob/master/networks/submodules.py#L7)

Now as a disclaimer, I am very honoured they decided to use my code, and it is very obvious that my code is not rocket science and the main contribution of this project is not these little snippets but rather the custom layers and the pretrained weights for pytorch.

However, the fact that the README is not giving any credit for what I did feels a little uncool, especially with a [License file](https://github.com/NVIDIA/flownet2-pytorch/blob/master/LICENSE) saying that all copyright goes to NVIDIA.

My other concern is that the parts of the code that got copied were actually not very well written, and the implementation in my own repo is to my mind much better now (for example [`MulstiScaleLoss`](https://github.com/NVIDIA/flownet2-pytorch/blob/master/losses.py#L46) module is a nightmare to read and to use while pytorch gives tools for making it [much more readable](https://github.com/ClementPinard/FlowNetPytorch/blob/master/multiscaleloss.py#L15)). I could make several Pull Requests but it's not garanteed to be merged rapidly and I'd prefer to contact the author first to get things straight and make them know that all I want is the best flownet2 implementation, and as this project is already gaining a lot of stars, it would be pointless to do my own fork ^with ^blackjack ^and ^hookers

My huge mistake was maybe to not have put a License in my code in the first place, but apparently, [a default one still holds](https://help.github.com/articles/licensing-a-repository/#choosing-the-right-license).

So what would be the best to do to get to work constructively with the project authors to improve their implementation and maybe also get a little credit for the code on which they built this project ? (also, is my claim reasonable ?)

Thanks in advance for your help !

EDIT thanks for your comments, I'll contact the main committor of the repo and hopefully everything will be alright! I am glad to see that it was indeed a reasonable claim",79,101
228,2017-12-6,2017,12,6,8,7htmg8,[D] Videos from NIPS 2017,https://www.reddit.com/r/MachineLearning/comments/7htmg8/d_videos_from_nips_2017/,sksq9,1512514964,,0,1
229,2017-12-6,2017,12,6,8,7htn0s,[D] How do you prepare for industry ML/DL engineering interviews in if you come from an academic background?,https://www.reddit.com/r/MachineLearning/comments/7htn0s/d_how_do_you_prepare_for_industry_mldl/,RefurbishedMac,1512515109,[removed],0,1
230,2017-12-6,2017,12,6,8,7hu038,RESTful Inference with the TensorRT Container and NVIDIA GPU Cloud,https://www.reddit.com/r/MachineLearning/comments/7hu038/restful_inference_with_the_tensorrt_container_and/,harrism,1512518296,,0,1
231,2017-12-6,2017,12,6,9,7hu0x4,[R] Optimization for Deep Learning Highlights in 2017,https://www.reddit.com/r/MachineLearning/comments/7hu0x4/r_optimization_for_deep_learning_highlights_in/,modeless,1512518507,,4,5
232,2017-12-6,2017,12,6,9,7hu3vc,Deploying scene text recognition,https://www.reddit.com/r/MachineLearning/comments/7hu3vc/deploying_scene_text_recognition/,volvoflower,1512519270,[removed],0,1
233,2017-12-6,2017,12,6,9,7hu5uf,"If AGSI efficiency &gt; Human efficiency, then Humanity =&gt; extinct. (Writing To Prove)",https://www.reddit.com/r/MachineLearning/comments/7hu5uf/if_agsi_efficiency_human_efficiency_then_humanity/,TooRipeToTakeABite,1512519752,[removed],0,1
234,2017-12-6,2017,12,6,10,7huh4e,Using machine learning to recognize geometric shapes in an image where those shapes aren't completely obvious,https://www.reddit.com/r/MachineLearning/comments/7huh4e/using_machine_learning_to_recognize_geometric/,helpwtranslation,1512522663,[removed],0,1
235,2017-12-6,2017,12,6,10,7huhkm,"[D] To those who have ML in more than one enviroment, what were the more notable differences?",https://www.reddit.com/r/MachineLearning/comments/7huhkm/d_to_those_who_have_ml_in_more_than_one/,SGuptMachineLearning,1512522788,"For those who have done ML work in more than one enviroment (academic, corporation, startup), what were the biggest differences you've noticed? Delegation, work flow, principles, approaches, etc. ",5,2
236,2017-12-6,2017,12,6,10,7humjg,[P] Using ML to recognize geometric shapes in an image where those shapes aren't completely obvious.,https://www.reddit.com/r/MachineLearning/comments/7humjg/p_using_ml_to_recognize_geometric_shapes_in_an/,helpwtranslation,1512524127,"https://imgur.com/a/bWnkD

I was wondering if this could be a possibility with machine learning. I'm interested in learning this subject and have some ideas. This one idea to have the ability for geometric shapes to be recognized, or patterns of these shapes to be identified where human eyes may not be trained to see them. Can anyone give me an idea of what would be a way to go about this? I have a specific image in mind, but I think this could be used in many cases. Thank you to anyone who can help me in my early days of learning this incredible subject.",0,1
237,2017-12-6,2017,12,6,11,7husey,"Google's AI made its own AI, and it's better than anything ever created by humans",https://www.reddit.com/r/MachineLearning/comments/7husey/googles_ai_made_its_own_ai_and_its_better_than/,appygal,1512525719,,0,1
238,2017-12-6,2017,12,6,12,7hv773,Neural Network in JavaScript with deeplearn.js,https://www.reddit.com/r/MachineLearning/comments/7hv773/neural_network_in_javascript_with_deeplearnjs/,[deleted],1512529635,[deleted],0,1
239,2017-12-6,2017,12,6,12,7hv7ju,[P] Neural Network in JavaScript with WebGL and deeplearn.js,https://www.reddit.com/r/MachineLearning/comments/7hv7ju/p_neural_network_in_javascript_with_webgl_and/,rwieruch,1512529726,,0,9
240,2017-12-6,2017,12,6,12,7hvb3h,[D] What are vectors in ML? What is the correct way to think about them in a Cartesian plane?,https://www.reddit.com/r/MachineLearning/comments/7hvb3h/d_what_are_vectors_in_ml_what_is_the_correct_way/,[deleted],1512530771,[deleted],3,1
241,2017-12-6,2017,12,6,12,7hvb89,"[D][NIPS 2017]For those who missed NIPS , make sure to watch this talk by Ali Rahimi If you have 15 mins .(from min 57 onwards) Excellent points made !",https://www.reddit.com/r/MachineLearning/comments/7hvb89/dnips_2017for_those_who_missed_nips_make_sure_to/,finallyifoundvalidUN,1512530808,,23,74
242,2017-12-6,2017,12,6,13,7hvl8u,Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm,https://www.reddit.com/r/MachineLearning/comments/7hvl8u/mastering_chess_and_shogi_by_selfplay_with_a/,f112809,1512533746,,0,1
243,2017-12-6,2017,12,6,13,7hvoka,"""Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm"", Silver et al 2017 {DM} [AlphaGo Zero for chess &amp; shogi - defeats Stockfish!]",https://www.reddit.com/r/MachineLearning/comments/7hvoka/mastering_chess_and_shogi_by_selfplay_with_a/,gwern,1512534795,,0,2
244,2017-12-6,2017,12,6,13,7hvr19,[R] Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm,https://www.reddit.com/r/MachineLearning/comments/7hvr19/r_mastering_chess_and_shogi_by_selfplay_with_a/,douchamp,1512535572,,87,123
245,2017-12-6,2017,12,6,15,7hw94o,[D] Breaking symmetry in siamese networks,https://www.reddit.com/r/MachineLearning/comments/7hw94o/d_breaking_symmetry_in_siamese_networks/,phobrain,1512541713,"I have cases of photo pairing where order matters: I want AB, but not necessarily BA. Rather to my surprise, siamese nets do a good job of pairing of simple histograms, but symmetrically. It seems like adding a left/right bit to each training histogram would solve this, but while working a week to get data ready to train and try it, I wonder if the state of the art is such that anyone can predict how the net will respond to the unique significance of that one added bit, and for extra credit what tinkering my model might need, e.g. from this:

http://phobrain.com/pr/home/dense_pinch3.txt

Edit: I guess the net down vote confirms that ML is indeed alchemy? Pay no attention to that man behind the curtain!

https://www.youtube.com/watch?v=YWyCCJ6B2WE

It seems plausible that it might just work without tweaking the net, but I'm also considering that in the 2D conv case, it's not so easy to tack on a bit, so merging that bit after the conv gets flattened sounds plausible.  It seems odd that there are no search results for breaking siamese symmetry.",6,0
246,2017-12-6,2017,12,6,15,7hwak6,Need help,https://www.reddit.com/r/MachineLearning/comments/7hwak6/need_help/,rameshnarwal,1512542252,[removed],0,1
247,2017-12-6,2017,12,6,15,7hwcih,What is Deep Learning,https://www.reddit.com/r/MachineLearning/comments/7hwcih/what_is_deep_learning/,munishmaxtech,1512543012,,0,1
248,2017-12-6,2017,12,6,15,7hwcld,Key Algorithms in Machine Learning  Explained! Examples Will Shock You Read More,https://www.reddit.com/r/MachineLearning/comments/7hwcld/key_algorithms_in_machine_learning_explained/,Analance,1512543033,,0,1
249,2017-12-6,2017,12,6,17,7hwtc5,[N] Intel Just Launched the New Nervana Chip at their NIPS Event (a Flo Rida Concert),https://www.reddit.com/r/MachineLearning/comments/7hwtc5/n_intel_just_launched_the_new_nervana_chip_at/,ntenenz,1512550081,"Announce: https://twitter.com/ntenenz/status/938292951549206528

A familiar face on stage: https://twitter.com/ntenenz/status/938307390050635776

 

Only at NIPS...",2,3
250,2017-12-6,2017,12,6,18,7hww0o,PyTorch vs Tensorflow,https://www.reddit.com/r/MachineLearning/comments/7hww0o/pytorch_vs_tensorflow/,cloudirec,1512551256,,0,1
251,2017-12-6,2017,12,6,18,7hwygf,Tea Stick Bag Packing Machine Test Video,https://www.reddit.com/r/MachineLearning/comments/7hwygf/tea_stick_bag_packing_machine_test_video/,liusherry,1512552337,,1,1
252,2017-12-6,2017,12,6,18,7hwz92,Apriori Basket Analysis,https://www.reddit.com/r/MachineLearning/comments/7hwz92/apriori_basket_analysis/,damjanv1,1512552688,[removed],0,1
253,2017-12-6,2017,12,6,18,7hwzdq,Following up Ali Rahimi's talk at NIPS2017,https://www.reddit.com/r/MachineLearning/comments/7hwzdq/following_up_ali_rahimis_talk_at_nips2017/,metalearner,1512552743,,0,1
254,2017-12-6,2017,12,6,18,7hx1pv,Mining Old news articles,https://www.reddit.com/r/MachineLearning/comments/7hx1pv/mining_old_news_articles/,hassaanishere,1512553778,[removed],0,1
255,2017-12-6,2017,12,6,18,7hx1re,[R]Jeffrey M. Siskind  The tension between convenience and performance in automatic differentiation,https://www.reddit.com/r/MachineLearning/comments/7hx1re/rjeffrey_m_siskind_the_tension_between/,abstractcontrol,1512553801,,2,3
256,2017-12-6,2017,12,6,19,7hx8lu,Automatic Stick Tea Bag Packing Machine,https://www.reddit.com/r/MachineLearning/comments/7hx8lu/automatic_stick_tea_bag_packing_machine/,liusherry,1512556752,,1,1
257,2017-12-6,2017,12,6,20,7hxgs6,Feature vector of a tweet in a Twitter Sentiment Analysis Task.,https://www.reddit.com/r/MachineLearning/comments/7hxgs6/feature_vector_of_a_tweet_in_a_twitter_sentiment/,czechrepublic,1512560129,[removed],0,1
258,2017-12-6,2017,12,6,20,7hxjce,[D] Interpretable and ethical self-driving cars,https://www.reddit.com/r/MachineLearning/comments/7hxjce/d_interpretable_and_ethical_selfdriving_cars/,Traner,1512561130,,0,0
259,2017-12-6,2017,12,6,20,7hxk6g,Deep Learning and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7hxk6g/deep_learning_and_machine_learning/,john-fernandes,1512561463,,1,1
260,2017-12-6,2017,12,6,23,7hyc7y,How to choose Embedding of digits?,https://www.reddit.com/r/MachineLearning/comments/7hyc7y/how_to_choose_embedding_of_digits/,suneburg,1512570234,[removed],0,1
261,2017-12-6,2017,12,6,23,7hyfaa,2018 Machine Learning Predictions from the Experts Themselves,https://www.reddit.com/r/MachineLearning/comments/7hyfaa/2018_machine_learning_predictions_from_the/,AnnaOnTheWeb,1512571061,,0,1
262,2017-12-6,2017,12,6,23,7hyha3,Towards deep learning with segregated dendrites &lt;- biologically plausible credit assignment by separate synapses that receive error feedback; 3% test error on MNIST in 3-layer network,https://www.reddit.com/r/MachineLearning/comments/7hyha3/towards_deep_learning_with_segregated_dendrites/,[deleted],1512571592,[deleted],0,1
263,2017-12-6,2017,12,6,23,7hyiaz,[D] Reinforcement Learning: The quirks  Towards Data Science,https://www.reddit.com/r/MachineLearning/comments/7hyiaz/d_reinforcement_learning_the_quirks_towards_data/,Sig_Luna,1512571861,,0,0
264,2017-12-6,2017,12,6,23,7hyjf7,Looking for great demos of ML technologies,https://www.reddit.com/r/MachineLearning/comments/7hyjf7/looking_for_great_demos_of_ml_technologies/,datatatatata,1512572169,[removed],0,1
265,2017-12-7,2017,12,7,0,7hyn6l,Ali Rahimi's talk at NIPS(NIPS 2017 Test-of-time award presentation),https://www.reddit.com/r/MachineLearning/comments/7hyn6l/ali_rahimis_talk_at_nipsnips_2017_testoftime/,[deleted],1512573123,[deleted],0,1
266,2017-12-7,2017,12,7,0,7hys85,[N] Ali Rahimi's talk at NIPS(NIPS 2017 Test-of-time award presentation),https://www.reddit.com/r/MachineLearning/comments/7hys85/n_ali_rahimis_talk_at_nipsnips_2017_testoftime/,krallistic,1512574409,,91,189
267,2017-12-7,2017,12,7,0,7hyvye,On Machine Learning and Programming Languages,https://www.reddit.com/r/MachineLearning/comments/7hyvye/on_machine_learning_and_programming_languages/,one_more_minute,1512575361,,0,1
268,2017-12-7,2017,12,7,0,7hyxhg,"Simple Questions Thread December 06, 2017",https://www.reddit.com/r/MachineLearning/comments/7hyxhg/simple_questions_thread_december_06_2017/,AutoModerator,1512575731,[removed],0,1
269,2017-12-7,2017,12,7,1,7hz69j,What is Regularization in Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/7hz69j/what_is_regularization_in_machine_learning/,kailashahirwar12,1512578087,,0,1
270,2017-12-7,2017,12,7,1,7hz8nx,DeepVariant: Highly Accurate Genomes With Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/7hz8nx/deepvariant_highly_accurate_genomes_with_deep/,johnmountain,1512578643,,0,1
271,2017-12-7,2017,12,7,1,7hz936,Using Machine Learning to Predict the Weather: Part 3,https://www.reddit.com/r/MachineLearning/comments/7hz936/using_machine_learning_to_predict_the_weather/,ScottWRobinson,1512578742,,0,1
272,2017-12-7,2017,12,7,1,7hzb3b,[D] Gaining insight from bulk trajectory data,https://www.reddit.com/r/MachineLearning/comments/7hzb3b/d_gaining_insight_from_bulk_trajectory_data/,wintermute93,1512579216,"Just looking to start a discussion here about what I think is an underappreciated domain compared to the hot topics like computer vision, NLP, and so on. There's a lot of places where a company might gather a huge amount of trajectory time series data - GPS tracks of cars, cell phones locations, packages in transit, commercial shipping lanes, etc. What can we do with that? If you've worked with time series data of the form (object ID, list of locations)(giant sample size) before, what did you do? If you've seen/done a cool paper/project on this, share!

Natural starting points would be clustering into similar trajectories (I guess dynamic time warping + knn might be appropriate), trying to find anomalies, maybe predicting destinations of partial trajectories... I started thinking about this after seeing the bike sharing kaggle competition from a few years back -- surely there's much more to do here, that was just predicting demand as a function of time/location using pickup/dropoff point histories. For example, I assume Uber has the entire location history of all of their on-the-clock drivers. What are they doing with all those millions (billions?) of data points?",1,5
273,2017-12-7,2017,12,7,2,7hzf61,On Machine Learning and Programming Languages,https://www.reddit.com/r/MachineLearning/comments/7hzf61/on_machine_learning_and_programming_languages/,[deleted],1512580166,[deleted],0,1
274,2017-12-7,2017,12,7,2,7hzfdn,"Machine Learning, Data Science, Deep Learning, Artificial Intelligence A-Z Courses",https://www.reddit.com/r/MachineLearning/comments/7hzfdn/machine_learning_data_science_deep_learning/,rbagdiya,1512580211,,0,1
275,2017-12-7,2017,12,7,2,7hzik9,[P] Semi-supervised tool for image database cleaning,https://www.reddit.com/r/MachineLearning/comments/7hzik9/p_semisupervised_tool_for_image_database_cleaning/,ABIWIN,1512580907,,0,2
276,2017-12-7,2017,12,7,2,7hzodo,Overall prediction based on a labeled time series,https://www.reddit.com/r/MachineLearning/comments/7hzodo/overall_prediction_based_on_a_labeled_time_series/,CSchott90,1512582196,[removed],0,1
277,2017-12-7,2017,12,7,2,7hzqoz,Block-Sparse GPU Kernels - Small-world connected LSTMS from OpenAI,https://www.reddit.com/r/MachineLearning/comments/7hzqoz/blocksparse_gpu_kernels_smallworld_connected/,Barbas,1512582689,,0,1
278,2017-12-7,2017,12,7,3,7hzuna,Machine Learning Models for Mere Mortals,https://www.reddit.com/r/MachineLearning/comments/7hzuna/machine_learning_models_for_mere_mortals/,DeviceHive,1512583456,,0,1
279,2017-12-7,2017,12,7,3,7hzxg0,[D] On Machine Learning and Programming Languages,https://www.reddit.com/r/MachineLearning/comments/7hzxg0/d_on_machine_learning_and_programming_languages/,undefdev,1512584059,,19,110
280,2017-12-7,2017,12,7,3,7i01yl,"In highly and broad practical terms with basis in Machine Learning, how exactly would you go to develop a system that takes information in bulk and creates quizzes to evaluate students?",https://www.reddit.com/r/MachineLearning/comments/7i01yl/in_highly_and_broad_practical_terms_with_basis_in/,kafeaccount,1512585050,[removed],0,1
281,2017-12-7,2017,12,7,4,7i0aft,Question: Who are the machine learning/AI engineering (developer) service providers?,https://www.reddit.com/r/MachineLearning/comments/7i0aft/question_who_are_the_machine_learningai/,Pav0cado,1512586865,[removed],0,1
282,2017-12-7,2017,12,7,4,7i0b8i,Learning with Privacy at Scale,https://www.reddit.com/r/MachineLearning/comments/7i0b8i/learning_with_privacy_at_scale/,refine_and_refine,1512587009,,0,1
283,2017-12-7,2017,12,7,5,7i0n8d,[P]Putting together a team of developers to research ML together starting with a NN that learns to play chess with reinforcement learning by playing against itself[xpost /r/ProgrammingBuddies],https://www.reddit.com/r/MachineLearning/comments/7i0n8d/pputting_together_a_team_of_developers_to/,ChillBallin,1512590549,,0,2
284,2017-12-7,2017,12,7,5,7i0s76,Question: VAE for clustering,https://www.reddit.com/r/MachineLearning/comments/7i0s76/question_vae_for_clustering/,the_electric_fish,1512591586,[removed],0,1
285,2017-12-7,2017,12,7,5,7i0tqy,[Project] Predicting Loan Application Submission,https://www.reddit.com/r/MachineLearning/comments/7i0tqy/project_predicting_loan_application_submission/,kingcai,1512591923,,0,0
286,2017-12-7,2017,12,7,5,7i0w65,"[D] ""My SWAT team of Millennials took a good look at the numbers and the expectation of positions for 2018, here is what they came up with:""",https://www.reddit.com/r/MachineLearning/comments/7i0w65/d_my_swat_team_of_millennials_took_a_good_look_at/,ic3cub3d,1512592446,,0,0
287,2017-12-7,2017,12,7,5,7i0wqd,Difference in Squared error,https://www.reddit.com/r/MachineLearning/comments/7i0wqd/difference_in_squared_error/,NovaBlastt,1512592578,[removed],0,1
288,2017-12-7,2017,12,7,6,7i15y3,How well does a simulated neuron mimic the operations of a real neuron?,https://www.reddit.com/r/MachineLearning/comments/7i15y3/how_well_does_a_simulated_neuron_mimic_the/,anuraagreddai,1512594644,[removed],0,1
289,2017-12-7,2017,12,7,6,7i1a9x,Really Quick Questions with George Hotz,https://www.reddit.com/r/MachineLearning/comments/7i1a9x/really_quick_questions_with_george_hotz/,funmaster11,1512595600,,0,1
290,2017-12-7,2017,12,7,7,7i1jxv,[R] AutoML for large scale image classification and object detection,https://www.reddit.com/r/MachineLearning/comments/7i1jxv/r_automl_for_large_scale_image_classification_and/,glassmountain,1512597753,,0,0
291,2017-12-7,2017,12,7,7,7i1tih,[N] Topcoder and Intel Launch New Embedded Image Classification Challenge (EICC),https://www.reddit.com/r/MachineLearning/comments/7i1tih/n_topcoder_and_intel_launch_new_embedded_image/,[deleted],1512600006,[deleted],0,1
292,2017-12-7,2017,12,7,7,7i1uer,[N] Yann LeCun response to Ali Rahimi's NIPS lecture,https://www.reddit.com/r/MachineLearning/comments/7i1uer/n_yann_lecun_response_to_ali_rahimis_nips_lecture/,nickl,1512600214,,64,59
293,2017-12-7,2017,12,7,8,7i1zkd,Videos from NIPS 2017,https://www.reddit.com/r/MachineLearning/comments/7i1zkd/videos_from_nips_2017/,[deleted],1512601443,[deleted],0,1
294,2017-12-7,2017,12,7,8,7i2249,Learning with Privacy at Scale,https://www.reddit.com/r/MachineLearning/comments/7i2249/learning_with_privacy_at_scale/,tits_for_tots,1512602045,,0,1
295,2017-12-7,2017,12,7,8,7i22ck,[N] Videos from NIPS 2017,https://www.reddit.com/r/MachineLearning/comments/7i22ck/n_videos_from_nips_2017/,eref,1512602099,,1,13
296,2017-12-7,2017,12,7,8,7i2bt5,[P] CUTLASS: Fast Linear Algebra in CUDA C++,https://www.reddit.com/r/MachineLearning/comments/7i2bt5/p_cutlass_fast_linear_algebra_in_cuda_c/,kerrmudgeon,1512604489,,3,16
297,2017-12-7,2017,12,7,9,7i2fp3,Drawing on canvas using hand motion,https://www.reddit.com/r/MachineLearning/comments/7i2fp3/drawing_on_canvas_using_hand_motion/,vonum,1512605500,[removed],0,1
298,2017-12-7,2017,12,7,9,7i2k4x,How does Recursive Feature Elimination evaluate features?,https://www.reddit.com/r/MachineLearning/comments/7i2k4x/how_does_recursive_feature_elimination_evaluate/,Fender6969,1512606683,[removed],0,1
299,2017-12-7,2017,12,7,11,7i38n5,[R] Online Learning with Gated Linear Networks,https://www.reddit.com/r/MachineLearning/comments/7i38n5/r_online_learning_with_gated_linear_networks/,Kaixhin,1512613388,,7,19
300,2017-12-7,2017,12,7,11,7i3928,Data Science team cohesion,https://www.reddit.com/r/MachineLearning/comments/7i3928/data_science_team_cohesion/,[deleted],1512613510,,0,1
301,2017-12-7,2017,12,7,12,7i3huc,[R] The Godfather of AI Was Almost a Carpenter,https://www.reddit.com/r/MachineLearning/comments/7i3huc/r_the_godfather_of_ai_was_almost_a_carpenter/,[deleted],1512615948,[deleted],0,1
302,2017-12-7,2017,12,7,12,7i3ljd,DeepMinds AlphaZero crushes chess,https://www.reddit.com/r/MachineLearning/comments/7i3ljd/deepminds_alphazero_crushes_chess/,weakandsensitive,1512616971,,1,2
303,2017-12-7,2017,12,7,12,7i3mh3,[R] The Godfather of AI Was Almost a Carpenter [video],https://www.reddit.com/r/MachineLearning/comments/7i3mh3/r_the_godfather_of_ai_was_almost_a_carpenter_video/,[deleted],1512617247,[deleted],0,1
304,2017-12-7,2017,12,7,12,7i3p8x,Demo Video-Machine learning Project with Python (identify colors of object with a webcam),https://www.reddit.com/r/MachineLearning/comments/7i3p8x/demo_videomachine_learning_project_with_python/,winner_godson,1512618079,,0,1
305,2017-12-7,2017,12,7,12,7i3qit,Help deducing Bayes Net,https://www.reddit.com/r/MachineLearning/comments/7i3qit/help_deducing_bayes_net/,clovic,1512618435,,1,1
306,2017-12-7,2017,12,7,13,7i3uap,A reply to Franois Chollet on intelligence explosion,https://www.reddit.com/r/MachineLearning/comments/7i3uap/a_reply_to_franois_chollet_on_intelligence/,yiavin,1512619497,,0,1
307,2017-12-7,2017,12,7,13,7i3yn1,Build Your Own Artifical Intelligence Robot,https://www.reddit.com/r/MachineLearning/comments/7i3yn1/build_your_own_artifical_intelligence_robot/,lokeshreddy0007,1512620821,,0,1
308,2017-12-7,2017,12,7,13,7i3yt9,Demo Video-Machine learning Project with Python (identify colors of object with a webcam),https://www.reddit.com/r/MachineLearning/comments/7i3yt9/demo_videomachine_learning_project_with_python/,winner_godson,1512620874,,0,1
309,2017-12-7,2017,12,7,14,7i46qs,Semi-Adversarial Networks: Convolutional Autoencoders for Imparting Privacy to Face Images,https://www.reddit.com/r/MachineLearning/comments/7i46qs/semiadversarial_networks_convolutional/,mlk1245,1512623488,,0,1
310,2017-12-7,2017,12,7,14,7i4d0d,How to prevent Sklearn from using 100% CPU?,https://www.reddit.com/r/MachineLearning/comments/7i4d0d/how_to_prevent_sklearn_from_using_100_cpu/,linksku,1512625588,[removed],0,1
311,2017-12-7,2017,12,7,15,7i4jp3,[D] Methods/code for change detection in images?,https://www.reddit.com/r/MachineLearning/comments/7i4jp3/d_methodscode_for_change_detection_in_images/,andyandy16,1512627936,"Do you know of any useful methods/implementations for detecting change in a time series of images? (Likewise, has there been a Kaggle competitions for something like this?) I'm particularly interested in the satellite domain.

Many thanks",2,2
312,2017-12-7,2017,12,7,16,7i4pc7,[D] Neural Information Processing Systems - Videos,https://www.reddit.com/r/MachineLearning/comments/7i4pc7/d_neural_information_processing_systems_videos/,_alphamaximus_,1512630085,,0,1
313,2017-12-7,2017,12,7,16,7i4w4k,[N] The Godfather of AI Was Almost a Carpenter [video],https://www.reddit.com/r/MachineLearning/comments/7i4w4k/n_the_godfather_of_ai_was_almost_a_carpenter_video/,[deleted],1512632779,[deleted],0,1
314,2017-12-7,2017,12,7,16,7i4waq,RAVI Brand Corrugation Plant &amp; Machinery | Automatic Corrugated Box Making Machine Plant | 5 ply automatic corrugated board plant,https://www.reddit.com/r/MachineLearning/comments/7i4waq/ravi_brand_corrugation_plant_machinery_automatic/,idea_amritsar,1512632838,,1,1
315,2017-12-7,2017,12,7,17,7i4yly,[D] Results too good ?,https://www.reddit.com/r/MachineLearning/comments/7i4yly/d_results_too_good/,Seiteshyru,1512633792,"Hey all,  
I'm currently doing research with customer data. The focus is on customer churn prediction and lead scoring. Microsoft Azure is used and the results achieved are amazingly good - like storybook good. The models (Decision Jungle) achieve 99% and 93% respectively with ~ 20 features and only 40% of the data for training.  
Never did I expect to achieve such results in the real world. Is there something like the accuracy paradox that could be at work here, or am I just too inexperienced to not expect such results ?   
**Updates:**
Original data : 325,000 rows   
Train data : 230,000 rows (0.7)   
Test data : 98,000 rows (0.3)   
% of churned customers : 16  
I'm currently checking whether there is a feature that is ""unfair""  
For lead scoring there were only two features which determined the result. I dropped them and am now at 97% with a bunch of features influencing the result. Still seem pretty darn good :/  
**Thanks everyone for the help !**

Summary:  
- Check that the training and validation sets are split correctly  
- Make sure to not use unfair features  
- Handle imbalance  
- Only SMOTE with training data  
- Split data per customer",20,2
316,2017-12-7,2017,12,7,17,7i523z,"[D] ""ICLR 2017 vs arxiv-sanity"" in 2018",https://www.reddit.com/r/MachineLearning/comments/7i523z/d_iclr_2017_vs_arxivsanity_in_2018/,[deleted],1512635294,[deleted],0,1
317,2017-12-7,2017,12,7,17,7i527s,a,https://www.reddit.com/r/MachineLearning/comments/7i527s/a/,[deleted],1512635352,,0,1
318,2017-12-7,2017,12,7,17,7i52n7,[D] On Machine Learning and Programming Languages,https://www.reddit.com/r/MachineLearning/comments/7i52n7/d_on_machine_learning_and_programming_languages/,harponen,1512635540,"Some interesting thoughts about the limitations of current ML libraries (TF, PyTorch, ...) and Python in general originally posted at Julia reddit here:
https://www.reddit.com/r/Julia/comments/7hyywn/on_machine_learning_and_programming_languages/?ref=share&amp;ref_source=link


Direct link to article: https://julialang.org/blog/2017/12/ml&amp;pl


I'm not completely sure what the final conclusion is, but the fact that these peeps are (mostly) from Julia Computing and that [Julia now has capability to compile CUDA kernels on the fly](http://mikeinnes.github.io/2017/08/24/cudanative.html) is pretty interesting...

I'm pretty damn close to giving Julia and [Flux.jl](https://github.com/FluxML/Flux.jl) a serious try (I just need some *time* dammit...).

I'd like to hear some opinions about Julia+GPU computing in DL context specifically. Anyone had any interesting experiences yet?

EDIT: oh crap, didn't realize someone beat me to posting this at /r/MachineLearning...",10,9
319,2017-12-7,2017,12,7,17,7i530e,Google's AlphaZero just destroyed world's strongest chess engine after having learned chess in only 4 hours.,https://www.reddit.com/r/MachineLearning/comments/7i530e/googles_alphazero_just_destroyed_worlds_strongest/,-PewPewPanda,1512635712,,0,1
320,2017-12-7,2017,12,7,18,7i5b9a,Hot Selling Rice Noodle Steamer Machine,https://www.reddit.com/r/MachineLearning/comments/7i5b9a/hot_selling_rice_noodle_steamer_machine/,liusherry,1512639384,[removed],1,1
321,2017-12-7,2017,12,7,18,7i5bjo,ARIMA and predicted external regressors,https://www.reddit.com/r/MachineLearning/comments/7i5bjo/arima_and_predicted_external_regressors/,[deleted],1512639524,,0,1
322,2017-12-7,2017,12,7,18,7i5bsk, Semi-automatic piston pump filling machine FP-2100  www.neostarpack.com,https://www.reddit.com/r/MachineLearning/comments/7i5bsk/_semiautomatic_piston_pump_filling_machine/,neostarpack,1512639636,,0,1
323,2017-12-7,2017,12,7,19,7i5frg,ARIMA with predicted external regressors,https://www.reddit.com/r/MachineLearning/comments/7i5frg/arima_with_predicted_external_regressors/,Mr_Sinist3r,1512641204,[removed],0,1
324,2017-12-7,2017,12,7,19,7i5gek,[D] I met Yann LeCun,https://www.reddit.com/r/MachineLearning/comments/7i5gek/d_i_met_yann_lecun/,anorexic_angel_1997,1512641451,[removed],0,1
325,2017-12-7,2017,12,7,19,7i5hdd,Amazon to put machine learning under the control of more clients,https://www.reddit.com/r/MachineLearning/comments/7i5hdd/amazon_to_put_machine_learning_under_the_control/,sameenasamu,1512641833,,0,1
326,2017-12-7,2017,12,7,19,7i5hro,Introduction to R Programming,https://www.reddit.com/r/MachineLearning/comments/7i5hro/introduction_to_r_programming/,iamkeyur,1512641962,,0,1
327,2017-12-7,2017,12,7,19,7i5j5o,Cream Box Cellophane Wrapping Machine For Sale,https://www.reddit.com/r/MachineLearning/comments/7i5j5o/cream_box_cellophane_wrapping_machine_for_sale/,liusherry,1512642552,[removed],1,1
328,2017-12-7,2017,12,7,19,7i5jgj,[P] Add GloVe from scratch in Golang for Word Embeddings,https://www.reddit.com/r/MachineLearning/comments/7i5jgj/p_add_glove_from_scratch_in_golang_for_word/,aqny,1512642682,,0,0
329,2017-12-7,2017,12,7,19,7i5lys,"Is it legal to download arxiv papers, do a meta-analysis on them and share the results?",https://www.reddit.com/r/MachineLearning/comments/7i5lys/is_it_legal_to_download_arxiv_papers_do_a/,[deleted],1512643533,,0,1
330,2017-12-7,2017,12,7,19,7i5mgh,"[N]Now anyone can explore machine learning, no coding required",https://www.reddit.com/r/MachineLearning/comments/7i5mgh/nnow_anyone_can_explore_machine_learning_no/,janemoz,1512643685,,0,1
331,2017-12-7,2017,12,7,20,7i5rt9,Rolled Sugar Cone Making Machine,https://www.reddit.com/r/MachineLearning/comments/7i5rt9/rolled_sugar_cone_making_machine/,nutmachines,1512645657,,1,1
332,2017-12-7,2017,12,7,20,7i5sy5,[R]Music Generation with Azure Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7i5sy5/rmusic_generation_with_azure_machine_learning/,molode,1512646123,,0,1
333,2017-12-7,2017,12,7,20,7i5tcj,[N] Googles AI builds its own AI child and its better than anything humans have made,https://www.reddit.com/r/MachineLearning/comments/7i5tcj/n_googles_ai_builds_its_own_ai_child_and_its/,[deleted],1512646279,[deleted],2,0
334,2017-12-7,2017,12,7,20,7i5x4y,I am kindly looking for resources that will enable me to write projects such as this.,https://www.reddit.com/r/MachineLearning/comments/7i5x4y/i_am_kindly_looking_for_resources_that_will/,startingstrength123,1512647752,[removed],0,1
335,2017-12-7,2017,12,7,20,7i5xe7,"[D] ""ICLR 2017 vs arxiv vanity"" in 2018",https://www.reddit.com/r/MachineLearning/comments/7i5xe7/d_iclr_2017_vs_arxiv_vanity_in_2018/,programmerChilli,1512647821,"Edit: Sanity not vanity 
I'm sure many of you have seen this post: https://medium.com/@karpathy/iclr-2017-vs-arxiv-sanity-d1488ac5c131

Specifically, Karpathy wrote that
&gt; someone suggested the fun idea that we add up the number of citations of these papers in ICLR 2018 submitted/accepted papers, and see which ranking wins on that metric. Looking forward to that :)

Given that I had already spent the time to collate most of the necessary information for [Open Review Explorer](https://chillee.github.io/OpenReviewExplorer/index.html?conf=iclr2017), I thought that it wouldn't be too hard for me to do some basic analysis :) If you want to do some analysis yourself, check out the json files at https://github.com/Chillee/OpenReviewExplorer
#Wins for Arxiv Sanity
####Adversarial examples in the physical world (Citations: 99, Rating: 5.60)
Despite a couple of notable authors, this pretty cool paper from google and openAI was pushed to the Workshop track by ICLR. The decision: 
&gt;In light of the reviews, the main critique of this work is its lack of significance, relative to existing works in adversarial examples....The AC concludes that the potential practical applications, while not significant enough to be part of the conference proceedings, are worthy to be disseminated in the workshop. I therefore recommend submitting this work to the workshop track.


#### Adding Gradient Noise Improves Learning for Very Deep Networks (Citations: 78, Rating: 5.07)
This paper was somewhat weird in that it was apparently on ArXiv far before being submitted to ICLR (one of the criticisms). Given that, I think it's fair to give ICLR reviewers some slack on this.
####Gated-Attention Readers for Text Comprehension (Citations: 46, Ratings: 6.30)
#### Learning in Implicit Generative Models (Citations: 40, Ratings: 7.00)
#### An Analysis of Deep Neural Network Models for Practical Applications (Citations: 37, Ratings: 4.40)  


# Wins for ICLR 
####  Energy-based Generative Adversarial Networks  (Citations: 151, Rating: 7.27)
#### On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima (Citations: 91, Rating: 7.80)
####The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables (Citations: 69, Rating: 8.17)
####Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning (Citations: 53, Rating: 7.50)
#### Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer (Citations: 46, Rating: 6.67)
#### Sample Efficient Actor-Critic with  Experience Replay (Citations: 33, Rating: 6.30)


# Losses for both ICLR and Arxiv Sanity
#### Squeezenet (Citations: 226, Rating: 6.27)
Despite being the most cited paper period from ICLR 2017 (by quite some margin), it received ratings of (5,7,7) and a Reject decision. Arxiv Sanity users didn't seem to be ahead of the curve on this one either. I thought that perhaps it had been revised and submitted for another conference, but I couldn't find anything on that.

#### Revisiting Distributed Synchronous SGD (Citations: 71, Rating: 5.73)

### The Google effect
One thing I noticed looking at the [list](https://chillee.github.io/OpenReviewExplorer/?conf=iclr2017) of most cited papers is that of the top cited papers that were rejected, many had Google affiliation. Perhaps there is an anti-google bias among reviewers, or perhaps Google papers get cited more than they deserve to be.


# Word Clouds
Popular with Arxiv Sanity but not ICLR https://imgur.com/K3XuCqq 

Popular with ICLR but not Arxiv Sanity https://imgur.com/WhOnL5l

# Final Results 
Actual ICLR papers: 4419 total citations  
Papers sorted by Arxiv Sanity: 4229 total citations

So under this metric, ICLR is still doing a better job than Arxiv Sanity . Sorry Karpathy :)

PS: I realize citation counts are not the end all be all of judging a paper's importance. However, it tends to be a pretty good metric and one of the best objective ones we have.",10,12
336,2017-12-7,2017,12,7,21,7i65kv,Imbalanced classes in ConvNets,https://www.reddit.com/r/MachineLearning/comments/7i65kv/imbalanced_classes_in_convnets/,rakzah,1512650135,[removed],0,1
337,2017-12-7,2017,12,7,21,7i68vy,"[N] Weekly Machine Learning Toolset &amp; Library Roundup  Dec. 7, 2017",https://www.reddit.com/r/MachineLearning/comments/7i68vy/n_weekly_machine_learning_toolset_library_roundup/,stkim1,1512651280,,0,1
338,2017-12-7,2017,12,7,22,7i6c7v,[P]ROOT Data Center - Wholesale Provider to Implement AI and Machine Learning for Reduced Downtime Risk,https://www.reddit.com/r/MachineLearning/comments/7i6c7v/proot_data_center_wholesale_provider_to_implement/,magneticono,1512652177,,0,1
339,2017-12-7,2017,12,7,22,7i6de3,[P] On a Formal Model of Safe and Scalable Self-driving Cars : Mobileye and Intel tackle safety in AVs. Thoughts ?,https://www.reddit.com/r/MachineLearning/comments/7i6de3/p_on_a_formal_model_of_safe_and_scalable/,Hizachi,1512652437,,0,1
340,2017-12-7,2017,12,7,22,7i6ex6,"[Project] Q-Learning or Support Vector, what's the way to go for a beginner ?",https://www.reddit.com/r/MachineLearning/comments/7i6ex6/project_qlearning_or_support_vector_whats_the_way/,IMakeInfantsCry,1512652870,"So I'm studying simulation in the frame of probabilities and we were given from the get go a project to make around Machine LEarning using one of many methods suggested. 

 I'm making an anti-spam filter as my project and I was wondering which method would be better, Q learning or Support Vector machines.

 I'm totally aware I'm an absolute beginner but apparently the harder the method the better the mark will potentially be so I though I couldn't just go with Monte Carlo and I'm trying to find a compromise between easy enough that I can do it in a month and complex enough that it doesn't seem like simple maths.",3,0
341,2017-12-7,2017,12,7,22,7i6f7e,[R]10 Tips for Building Effective Machine Learning Models,https://www.reddit.com/r/MachineLearning/comments/7i6f7e/r10_tips_for_building_effective_machine_learning/,jackblun,1512652965,,0,1
342,2017-12-7,2017,12,7,23,7i6o0s,"[D] Is it legal to download arxiv papers, do a meta-analysis on them and share the results?",https://www.reddit.com/r/MachineLearning/comments/7i6o0s/d_is_it_legal_to_download_arxiv_papers_do_a/,destroy_fascists,1512655652,,12,1
343,2017-12-7,2017,12,7,23,7i6o1p,IBM scientists demonstrate 10x faster large-scale machine learning using GPUs,https://www.reddit.com/r/MachineLearning/comments/7i6o1p/ibm_scientists_demonstrate_10x_faster_largescale/,johnmountain,1512655662,,0,1
344,2017-12-7,2017,12,7,23,7i6q9w,ONNX V1 released. Now production ready.,https://www.reddit.com/r/MachineLearning/comments/7i6q9w/onnx_v1_released_now_production_ready/,balazshoranyi,1512656290,,0,1
345,2017-12-7,2017,12,7,23,7i6r4b,[D] What are some great lesser known sources of data?,https://www.reddit.com/r/MachineLearning/comments/7i6r4b/d_what_are_some_great_lesser_known_sources_of_data/,SGuptMachineLearning,1512656523,,15,10
346,2017-12-7,2017,12,7,23,7i6r7c,"[D] Alchemy, Rigour and Engineering",https://www.reddit.com/r/MachineLearning/comments/7i6r7c/d_alchemy_rigour_and_engineering/,sksq9,1512656548,,41,131
347,2017-12-7,2017,12,7,23,7i6vgz,[R]New Cray Artificial Intelligence Initiatives to Advance Deep Learning for Science and Enterprise,https://www.reddit.com/r/MachineLearning/comments/7i6vgz/rnew_cray_artificial_intelligence_initiatives_to/,dearpetra,1512657728,,0,1
348,2017-12-8,2017,12,8,0,7i75un,"[D] It looks like using a sigmoid function results in smooth boundaries than a ReLu for curved boundaries. For very curved boundaries, would a sigmoid or another curved activation function be more efficient than a ReLu?",https://www.reddit.com/r/MachineLearning/comments/7i75un/d_it_looks_like_using_a_sigmoid_function_results/,Batmantosh,1512660443,,2,1
349,2017-12-8,2017,12,8,1,7i7g5b,Transformation of SentencesNegativeEnglish Grammar,https://www.reddit.com/r/MachineLearning/comments/7i7g5b/transformation_of_sentencesnegativeenglish_grammar/,anowarul147,1512662935,,0,1
350,2017-12-8,2017,12,8,1,7i7grt,"Alternative to 'Programming the Collective Intelligence.""",https://www.reddit.com/r/MachineLearning/comments/7i7grt/alternative_to_programming_the_collective/,Quasimoto3000,1512663066,[removed],0,1
351,2017-12-8,2017,12,8,1,7i7kuy,DLVM: A modern compiler infrastructure for deep learning systems,https://www.reddit.com/r/MachineLearning/comments/7i7kuy/dlvm_a_modern_compiler_infrastructure_for_deep/,donald-pinckney,1512663988,,0,1
352,2017-12-8,2017,12,8,1,7i7r9k,[R] Seeking interviews with people working in ML,https://www.reddit.com/r/MachineLearning/comments/7i7r9k/r_seeking_interviews_with_people_working_in_ml/,jsteinhoff,1512665469,"I'm a PhD candidate researching what it's like to work in the ML industry. Almost all positions are of interest. If you might be interested in having an online chat on the topic (~30-45min), send me a message.
(Apologies if this post is out of place here. Please advise if so.)  ",1,0
353,2017-12-8,2017,12,8,1,7i7sox,[D] How does Recursive Feature Elimination work?,https://www.reddit.com/r/MachineLearning/comments/7i7sox/d_how_does_recursive_feature_elimination_work/,Fender6969,1512665798,"Am currently working on a project and this is a portion implemented using Sklearn and I understand that it is a sort of feature elimination but I am having trouble understanding how exactly it is working. I tried reading the description from the Sci-kit Learn website itself, as well as feature elimination posts from Google and I am still having trouble understanding this. Any help would be great!",3,0
354,2017-12-8,2017,12,8,2,7i7ysc,Word embeddings: how to transform text into numbers,https://www.reddit.com/r/MachineLearning/comments/7i7ysc/word_embeddings_how_to_transform_text_into_numbers/,wildcodegowrong,1512667115,,0,1
355,2017-12-8,2017,12,8,3,7i89mu,Discriminative State-Space Models: Boosted Structural Time Series Forecasting,https://www.reddit.com/r/MachineLearning/comments/7i89mu/discriminative_statespace_models_boosted/,unnamedn00b,1512669638,,0,1
356,2017-12-8,2017,12,8,3,7i8k9c,Tense learn english grammar,https://www.reddit.com/r/MachineLearning/comments/7i8k9c/tense_learn_english_grammar/,anowarul147,1512671641,,0,1
357,2017-12-8,2017,12,8,3,7i8lyp,[Discussion] Testing on a Multi-GPU system,https://www.reddit.com/r/MachineLearning/comments/7i8lyp/discussion_testing_on_a_multigpu_system/,MarviB16,1512672003,"Hi,

is there any framework which supports Multi-GPU testing?
I know that Tensorflow and Caffe2 support model/data parallelism, but i read nowhere if they support it for testing too. 
(Okay, i found [this](https://github.com/caffe2/caffe2/issues/646) for Caffe2, but i couldn't try it)
Caffe only supports data parallelism for training and PyTorch i haven't tried yet.

Does somebody here have a hint or an idea for me?

Greeting Marvin
",5,0
358,2017-12-8,2017,12,8,4,7i8yhq,"[R] Deep Learning Scaling is Predictable, Empirically - Baidu Research",https://www.reddit.com/r/MachineLearning/comments/7i8yhq/r_deep_learning_scaling_is_predictable/,jthestness,1512674910,,18,27
359,2017-12-8,2017,12,8,4,7i936f,[R] Generative Adversarial Perturbations,https://www.reddit.com/r/MachineLearning/comments/7i936f/r_generative_adversarial_perturbations/,programmerChilli,1512675981,,7,2
360,2017-12-8,2017,12,8,4,7i94ks,Intel Nervana Neural Network Processor: Architecture Update - Intel Nervana,https://www.reddit.com/r/MachineLearning/comments/7i94ks/intel_nervana_neural_network_processor/,darkconfidantislife,1512676297,,0,1
361,2017-12-8,2017,12,8,4,7i94o7,[N] Intel Nervana Neural Network Processor: Architecture Update - Intel Nervana,https://www.reddit.com/r/MachineLearning/comments/7i94o7/n_intel_nervana_neural_network_processor/,darkconfidantislife,1512676315,,8,29
362,2017-12-8,2017,12,8,6,7i9uak,[P] Vanilla web app for labeling audio files,https://www.reddit.com/r/MachineLearning/comments/7i9uak/p_vanilla_web_app_for_labeling_audio_files/,chiraqe,1512682999,,0,3
363,2017-12-8,2017,12,8,6,7i9vtq,Best ways to provision a new ML box?,https://www.reddit.com/r/MachineLearning/comments/7i9vtq/best_ways_to_provision_a_new_ml_box/,Loggerny,1512683425,[removed],0,1
364,2017-12-8,2017,12,8,7,7ia5dx,Convolutional Neural Networks in Python Tutorial,https://www.reddit.com/r/MachineLearning/comments/7ia5dx/convolutional_neural_networks_in_python_tutorial/,gcdes,1512685790,,0,1
365,2017-12-8,2017,12,8,8,7iadzp,"[P] Tutorial: Deploying a machine learning model as an API with Python, Falcon, Gunicorn, and Datmo",https://www.reddit.com/r/MachineLearning/comments/7iadzp/p_tutorial_deploying_a_machine_learning_model_as/,Wrangley,1512687865,,0,4
366,2017-12-8,2017,12,8,9,7iark0,Universal Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/7iark0/universal_adversarial_networks/,[deleted],1512691327,,0,1
367,2017-12-8,2017,12,8,9,7iatz4,"Overheard at NIPS 2017 poster session: The first thing a researcher from a *very* well funded research lab asks a grad student presenter was, So did you cite me? I mean I did pretty much the same thing as what your paper claims to do in my earlier [xyz] work ...",https://www.reddit.com/r/MachineLearning/comments/7iatz4/overheard_at_nips_2017_poster_session_the_first/,[deleted],1512691956,[deleted],0,1
368,2017-12-8,2017,12,8,9,7iaukb,"[D] Overheard at NIPS 2017 poster session: The first thing a researcher from a *very* well funded research lab asks a grad student presenter was, So did you cite me? I mean I did pretty much the same thing as what your paper claims to do in my earlier [xyz] work ...",https://www.reddit.com/r/MachineLearning/comments/7iaukb/d_overheard_at_nips_2017_poster_session_the_first/,metacurse,1512692115,,61,50
369,2017-12-8,2017,12,8,9,7iaztk,GANS are resulting in nans (losses) after training for a while. Is this normal? [Discussion],https://www.reddit.com/r/MachineLearning/comments/7iaztk/gans_are_resulting_in_nans_losses_after_training/,Moondra2017,1512693506,"I'm going through ""Learning Generative Adversial Networks"" book which was published recently. I'm using the sample code provided but I'm getting the following error:

""UserWarning: Warning: converting a masked element to nan "" , at a random training_step and then the  losses for each model are being printed as 'nans'. After that warning, GAN continues training, but the images become blank canvases. Before the error, the images were making improvements. 

The author doesn't mention anything about this error.

I made a OP on Stackoverflow with the script, but no answers there:

https://stackoverflow.com/questions/47663367/userwarning-warning-converting-a-masked-element-to-nan-when-running-gan

I tried to find contact info of the author, but no luck.

I don't know where else to post to figure out the problem. 

",6,0
370,2017-12-8,2017,12,8,9,7ib0k3,[R] Universal Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/7ib0k3/r_universal_adversarial_networks/,Confusedius,1512693689,,9,1
371,2017-12-8,2017,12,8,10,7ib59w,Petascale Deep Learning on a Single Chip,https://www.reddit.com/r/MachineLearning/comments/7ib59w/petascale_deep_learning_on_a_single_chip/,darkconfidantislife,1512694966,,0,1
372,2017-12-8,2017,12,8,10,7ib6fr,[R] Gradually Updated Neural Networks for Large-Scale Image Recognition,https://www.reddit.com/r/MachineLearning/comments/7ib6fr/r_gradually_updated_neural_networks_for/,xternalz,1512695281,,4,20
373,2017-12-8,2017,12,8,10,7ib6oa,YouTube,https://www.reddit.com/r/MachineLearning/comments/7ib6oa/youtube/,daveylessleyhff,1512695347,,0,1
374,2017-12-8,2017,12,8,10,7ib6xr,[N] Stanford Seminar - Petascale Deep Learning on a Single Chip,https://www.reddit.com/r/MachineLearning/comments/7ib6xr/n_stanford_seminar_petascale_deep_learning_on_a/,darkconfidantislife,1512695413,,10,11
375,2017-12-8,2017,12,8,12,7ibxtm,[N] Nvidia launches Titan V ($3k),https://www.reddit.com/r/MachineLearning/comments/7ibxtm/n_nvidia_launches_titan_v_3k/,ntenenz,1512702862,,79,67
376,2017-12-8,2017,12,8,12,7ibxur,"Extreme Machines, Building Mega Bridges",https://www.reddit.com/r/MachineLearning/comments/7ibxur/extreme_machines_building_mega_bridges/,Ihteram,1512702872,,0,1
377,2017-12-8,2017,12,8,12,7ibziu,"[D] OpenAI presented DOTA2 bot at NIPS symposium, still aren't publishing details...",https://www.reddit.com/r/MachineLearning/comments/7ibziu/d_openai_presented_dota2_bot_at_nips_symposium/,zergylord,1512703353,"Specifically, Ilya presented it alongside TD-Gammon and AlphaZero as milestones in learning through self-play. During the Q&amp;A I asked about the lack of details and was repeatedly told that nothing would come out until they solve 5v5.",78,108
378,2017-12-8,2017,12,8,14,7icvo6,Text Classification  Classifying product titles using Convolutional Neural Network and Word2Vec embedding,https://www.reddit.com/r/MachineLearning/comments/7icvo6/text_classification_classifying_product_titles/,codesaint,1512711460,,0,1
379,2017-12-8,2017,12,8,14,7iczfw,need suggestion about project,https://www.reddit.com/r/MachineLearning/comments/7iczfw/need_suggestion_about_project/,vindhya457,1512712569,[removed],0,1
380,2017-12-8,2017,12,8,15,7id7b5,Virtual Persons and Artificial Brains,https://www.reddit.com/r/MachineLearning/comments/7id7b5/virtual_persons_and_artificial_brains/,scitechjunkie,1512715105,,0,1
381,2017-12-8,2017,12,8,15,7idad7,[P] MAgent: A Many-Agent Reinforcement Learning Platform for Artificial Collective Intelligence,https://www.reddit.com/r/MachineLearning/comments/7idad7/p_magent_a_manyagent_reinforcement_learning/,[deleted],1512716220,[deleted],2,2
382,2017-12-8,2017,12,8,16,7idizb,[D] PSA: You can buy the AlphaGo documentary on Google Play,https://www.reddit.com/r/MachineLearning/comments/7idizb/d_psa_you_can_buy_the_alphago_documentary_on/,Phylliida,1512719305,,7,20
383,2017-12-8,2017,12,8,17,7idm03,Semi Automatic Single Mouth Cement Packing Machine Working Video,https://www.reddit.com/r/MachineLearning/comments/7idm03/semi_automatic_single_mouth_cement_packing/,liusherry,1512720439,,1,1
384,2017-12-8,2017,12,8,17,7idm5z,how do I make it big in AI when everyone else is doing it too,https://www.reddit.com/r/MachineLearning/comments/7idm5z/how_do_i_make_it_big_in_ai_when_everyone_else_is/,[deleted],1512720503,,0,1
385,2017-12-8,2017,12,8,18,7ie1os,[D] Build a Gesture Recognition System with Deep Learning (PyData Talk),https://www.reddit.com/r/MachineLearning/comments/7ie1os/d_build_a_gesture_recognition_system_with_deep/,nahuak,1512727159,,0,10
386,2017-12-8,2017,12,8,19,7ie1xq,[N] Deep Learning for Robotics - Pieter Abbeel,https://www.reddit.com/r/MachineLearning/comments/7ie1xq/n_deep_learning_for_robotics_pieter_abbeel/,visarga,1512727265,,2,12
387,2017-12-8,2017,12,8,19,7ie9kc,Automatic differentiation from scratch,https://www.reddit.com/r/MachineLearning/comments/7ie9kc/automatic_differentiation_from_scratch/,totallynotAGI,1512730536,,7,4
388,2017-12-8,2017,12,8,20,7iecfw,Gypsum Packing Machine Manufacturer,https://www.reddit.com/r/MachineLearning/comments/7iecfw/gypsum_packing_machine_manufacturer/,liusherry,1512731719,[removed],1,1
389,2017-12-8,2017,12,8,20,7iegu7,How to learn machine learning from scratch?,https://www.reddit.com/r/MachineLearning/comments/7iegu7/how_to_learn_machine_learning_from_scratch/,MCAL_Training,1512733520,,0,1
390,2017-12-8,2017,12,8,21,7iej9l,Machine Learning Hello World using Python,https://www.reddit.com/r/MachineLearning/comments/7iej9l/machine_learning_hello_world_using_python/,MCAL_Training,1512734452,,0,1
391,2017-12-8,2017,12,8,21,7ieoxf,What can I do with NLP or Image Processing?,https://www.reddit.com/r/MachineLearning/comments/7ieoxf/what_can_i_do_with_nlp_or_image_processing/,new_username_again,1512736578,[removed],0,1
392,2017-12-8,2017,12,8,22,7ievx8,Vanilla RNN Gradient Flow,https://www.reddit.com/r/MachineLearning/comments/7ievx8/vanilla_rnn_gradient_flow/,promach,1512738976,,1,1
393,2017-12-8,2017,12,8,22,7ievz1,[P]Developing and Operationalizing H2O.ai Models with Azure,https://www.reddit.com/r/MachineLearning/comments/7ievz1/pdeveloping_and_operationalizing_h2oai_models/,chris_shpak,1512738994,,0,1
394,2017-12-8,2017,12,8,22,7iew0c,Anyone experienced Fat Segmentation issue?,https://www.reddit.com/r/MachineLearning/comments/7iew0c/anyone_experienced_fat_segmentation_issue/,reddit_tl,1512739009,[removed],0,1
395,2017-12-8,2017,12,8,22,7iexw3,"[R]Real-World, Man-Machine Algorithms",https://www.reddit.com/r/MachineLearning/comments/7iexw3/rrealworld_manmachine_algorithms/,digitalson,1512739594,,0,1
396,2017-12-8,2017,12,8,23,7if664,[P] I need help with finding a dataset for a recommendation system project,https://www.reddit.com/r/MachineLearning/comments/7if664/p_i_need_help_with_finding_a_dataset_for_a/,Fe_man_,1512742117,"I am building a cross-domain recommendation system where user can get recommendations of books, movies and music based on their preferences. For this, I need a dataset where users have rated books, movies and music to train my algorithm but can't find it.
Please suggest such a dataset if you know any...",2,2
397,2017-12-8,2017,12,8,23,7if6h1,[D] Deep Mind AI Alpha Zero Sacrifices a Pawn and Cripples Stockfish for the Entire Game,https://www.reddit.com/r/MachineLearning/comments/7if6h1/d_deep_mind_ai_alpha_zero_sacrifices_a_pawn_and/,sour_losers,1512742202,,104,419
398,2017-12-8,2017,12,8,23,7if8eb,[R]Managing Machine Learning Workflows with Scikit-learn Pipelines Part 1: A Gentle Introduction,https://www.reddit.com/r/MachineLearning/comments/7if8eb/rmanaging_machine_learning_workflows_with/,jackblun,1512742752,,0,1
399,2017-12-8,2017,12,8,23,7if9au,Vi The First True Artificial Intelligence Personal Trainer,https://www.reddit.com/r/MachineLearning/comments/7if9au/vi_the_first_true_artificial_intelligence/,lokeshreddy0007,1512743009,,0,1
400,2017-12-8,2017,12,8,23,7ifgxv,[D] Hyperplanes optimally classify data when inputs are conditionally independent - Why?,https://www.reddit.com/r/MachineLearning/comments/7ifgxv/d_hyperplanes_optimally_classify_data_when_inputs/,spurra,1512745192,,2,11
401,2017-12-9,2017,12,9,0,7iflib,GPU for deep learning,https://www.reddit.com/r/MachineLearning/comments/7iflib/gpu_for_deep_learning/,Hyaxia,1512746382,[removed],0,1
402,2017-12-9,2017,12,9,0,7ifua0,Is a PhD a good choice for my career goals?,https://www.reddit.com/r/MachineLearning/comments/7ifua0/is_a_phd_a_good_choice_for_my_career_goals/,[deleted],1512748669,,0,1
403,2017-12-9,2017,12,9,0,7iful0,Machine Learning Secrets?,https://www.reddit.com/r/MachineLearning/comments/7iful0/machine_learning_secrets/,whataprophet,1512748743,[removed],0,1
404,2017-12-9,2017,12,9,0,7ifumm,Some concerns on the matching conditions between AlphaZero and Shogi engine,https://www.reddit.com/r/MachineLearning/comments/7ifumm/some_concerns_on_the_matching_conditions_between/,m000pan,1512748754,,0,1
405,2017-12-9,2017,12,9,1,7ify46,[D] is a PhD a good choice for my career goals?,https://www.reddit.com/r/MachineLearning/comments/7ify46/d_is_a_phd_a_good_choice_for_my_career_goals/,techphd_throwaway,1512749558,"(reposted with a tag in the title)

&amp;nbsp;

I'm looking for advice on whether or not doing a ML-focused PhD would be a good idea for me. The typical advice I see on more general academic sub like /r/AskAcademia is that you should do a PhD only if you want a career in research, but I decided to post here because I get the impression that there is a smoother continuum between ""research"" and ""industry"" in machine learning (and maybe even in CS more broadly) than in most other fields (please do let me know if this impression is incorrect).
 
&amp;nbsp;

Currently I'm employed as a research engineer in a great machine learning group at a university in the USA. I enjoy my job, but I don't imagine staying as an engineer here for the long term. I have a good relationship with the lab's director, and he has has offered to take me on as a PhD student (as well as to support my application to other programs, if I decide to do that).

&amp;nbsp; 

My end goal is to land a job in a research lab at an established tech company (in the USA). I would ideally like to strike a balance between interesting work and salary, and my interests are skewed towards practical applications over theory.

&amp;nbsp;

From the above paragraph, the standard response I would expect is something along the lines of this: ""do a Masters, because a Masters is about application, and a PhD is about research."" This makes sense to me, but there are a few other factors that are leading to my ambivalence:
 
&amp;nbsp;

First, I very much enjoy my research, but it's not clear if this means that I like ""doing research"", or if it means that I like ""being a research engineer."" Being an engineer (as opposed to being a student) means that even my research projects have tended to have real-world users and applications, and have tended to be highly collaborative, which I really like. I worry that becoming a PhD student (in my current group or otherwise) will strip away much of the parts that I enjoy. That being said, as things currently stand, I think I would enjoy the process of continuing my current research towards a dissertation.
 
&amp;nbsp;

Second, although I don't necessarily see myself making a career out of publishing papers, my impression is that certain leadership roles at industrial research labs are essentially reserved for PhDs, even if their primary function is not to produce publications. I worry about limiting myself, career-wise, if I skip the PhD.
 
&amp;nbsp;

So, the question is: if you were me, would you continue towards the PhD? or would you try to get industrial research roles in the near future?
 
&amp;nbsp;

Thanks for reading. I look forward to hearing your opinions.",35,7
406,2017-12-9,2017,12,9,1,7ig3m9,[P] skorch: A scikit-learn wrapper for PyTorch,https://www.reddit.com/r/MachineLearning/comments/7ig3m9/p_skorch_a_scikitlearn_wrapper_for_pytorch/,ottonemo,1512750888,,13,82
407,2017-12-9,2017,12,9,2,7iga60,Collaborate with me to build a Fantasy Football AI,https://www.reddit.com/r/MachineLearning/comments/7iga60/collaborate_with_me_to_build_a_fantasy_football_ai/,[deleted],1512752455,[deleted],0,1
408,2017-12-9,2017,12,9,2,7igd92,How OpenMined uses your idle consoles to train the next generation of AI,https://www.reddit.com/r/MachineLearning/comments/7igd92/how_openmined_uses_your_idle_consoles_to_train/,Sig_Luna,1512753170,,0,1
409,2017-12-9,2017,12,9,2,7igi2q,[Discussion] What is the best/ most successful web page segmentation approach or algorithm ?,https://www.reddit.com/r/MachineLearning/comments/7igi2q/discussion_what_is_the_best_most_successful_web/,infinitylogesh,1512754335,"I am trying to segregate different blocks (Semantic blocks like About-us, Blog post etc) in a webpage. Is there any algorithm/approach that you would recommend?.",0,1
410,2017-12-9,2017,12,9,3,7iguww,[P] MAgent: A Many-Agent Reinforcement Learning Platform for Artificial Collective Intelligence,https://www.reddit.com/r/MachineLearning/comments/7iguww/p_magent_a_manyagent_reinforcement_learning/,wnzhang,1512757362,,0,7
411,2017-12-9,2017,12,9,3,7ih0u1,[D] Machine Learning Industries outside the US,https://www.reddit.com/r/MachineLearning/comments/7ih0u1/d_machine_learning_industries_outside_the_us/,funkbf,1512758791,"I live and work in ML in Boston. I've always wanted to live/work abroad for a couple years, so my question--are there other countries in the world that have commensurately present machine learning industries? Or a non-negligible one at all? Thanks!",6,1
412,2017-12-9,2017,12,9,3,7ih1ed,[P] Collaborate with me to build a Fantasy Football AI,https://www.reddit.com/r/MachineLearning/comments/7ih1ed/p_collaborate_with_me_to_build_a_fantasy_football/,zthoutt,1512758934,,0,0
413,2017-12-9,2017,12,9,3,7ih2ay,Creating unique and colorful icons using generative adversarial networks,https://www.reddit.com/r/MachineLearning/comments/7ih2ay/creating_unique_and_colorful_icons_using/,[deleted],1512759141,[deleted],0,1
414,2017-12-9,2017,12,9,4,7ihaba,[P] Towards Automatic Icon Design Using Machine Learning  thoughts on next steps?,https://www.reddit.com/r/MachineLearning/comments/7ihaba/p_towards_automatic_icon_design_using_machine/,mosessoh,1512761098,,1,3
415,2017-12-9,2017,12,9,4,7ihbpd,"Drawings in the Cloud (introducing the Quick, Draw! dataset): implementation &amp; scaling",https://www.reddit.com/r/MachineLearning/comments/7ihbpd/drawings_in_the_cloud_introducing_the_quick_draw/,gwern,1512761408,,0,1
416,2017-12-9,2017,12,9,4,7ihhqo,"New paper: ""Ten quick tips for machine learning in computational biology""",https://www.reddit.com/r/MachineLearning/comments/7ihhqo/new_paper_ten_quick_tips_for_machine_learning_in/,DavideChicco,1512762848,,0,1
417,2017-12-9,2017,12,9,5,7ihje6,AI Weekly 8 Dec 2017,https://www.reddit.com/r/MachineLearning/comments/7ihje6/ai_weekly_8_dec_2017/,TomekB,1512763232,,0,1
418,2017-12-9,2017,12,9,5,7ihjkh,Machine Learning  Can We Please Just Agree What This Means,https://www.reddit.com/r/MachineLearning/comments/7ihjkh/machine_learning_can_we_please_just_agree_what/,psangrene,1512763271,,0,1
419,2017-12-9,2017,12,9,5,7ihxy5,CNN - Image Resizing VS Padding (keeping aspect ratio or not?),https://www.reddit.com/r/MachineLearning/comments/7ihxy5/cnn_image_resizing_vs_padding_keeping_aspect/,yoniker,1512766754,[removed],0,1
420,2017-12-9,2017,12,9,6,7ii2db,"[D] Have there been any techniques developed to emphasize minimizing or maximizing the false positives/true positives/true negatives/false negatives, over the overall accuracy ?",https://www.reddit.com/r/MachineLearning/comments/7ii2db/d_have_there_been_any_techniques_developed_to/,SGuptMachineLearning,1512767827,"There are certain cases where it's much more important to minimize or maximize the false positives/true positives/true negatives/ false negatives than the overall accuracy. 

For example, in cancer diagnostics, it's more important to reduce false negatives (the diagnostics saying you don't have cancer, when you actually do) than it is to reduce the number of false positives (diagnostics saying you do have cancer, when you don't). 

I imagine the best way to do this is via the error function. 

I've tried searching, but most of the results I get back are for optimizing particular case studies, than general ML techniques. 

Are there particular key phrases and terminology for what I'm talking about?

",16,4
421,2017-12-9,2017,12,9,6,7ii7ji,[D] An intuitive explanation of Distributional RL,https://www.reddit.com/r/MachineLearning/comments/7ii7ji/d_an_intuitive_explanation_of_distributional_rl/,Kiuhnm,1512769096,,5,31
422,2017-12-9,2017,12,9,6,7iia2n,[N] Elon Musk says Tesla is working on custom AI chips,https://www.reddit.com/r/MachineLearning/comments/7iia2n/n_elon_musk_says_tesla_is_working_on_custom_ai/,modeless,1512769734,,22,1
423,2017-12-9,2017,12,9,7,7iihym,c++ implementations of any deep learning nets you have implemented? What was your experience?,https://www.reddit.com/r/MachineLearning/comments/7iihym/c_implementations_of_any_deep_learning_nets_you/,GaussianDoubts,1512771714,[removed],0,1
424,2017-12-9,2017,12,9,7,7iipww,"Apple open sourced TuriCreate, easy Python ML generator. What do you think?",https://www.reddit.com/r/MachineLearning/comments/7iipww/apple_open_sourced_turicreate_easy_python_ml/,enzyme69,1512773821,,0,1
425,2017-12-9,2017,12,9,8,7iixf4,IBM Research: Small quantum computers and big classical data,https://www.reddit.com/r/MachineLearning/comments/7iixf4/ibm_research_small_quantum_computers_and_big/,johnmountain,1512775807,,0,1
426,2017-12-9,2017,12,9,8,7iizq4,[P] Export a Tensorflow Session to C?,https://www.reddit.com/r/MachineLearning/comments/7iizq4/p_export_a_tensorflow_session_to_c/,denotatedanonuser,1512776431,"I'm quite new to Tensorflow, so this may be a very strange question. Essentially, I want to program how a model will learn (initialize weights, optimizer, loss function, etc) and then take that and export it to C, so that it can be run on computers that may/may not have Python installed. I believe what I'm asking to export is the session so that it can be run directly in C. I don't want to export the model, as the model needs to be retrained fairly frequently (anomaly detection for tests). ",7,2
427,2017-12-9,2017,12,9,8,7ij2gg,"An interactive chat box with a Char RNN. Trained on Wikipedia, US Congress transcripts, Sherlock Holmes, Southpark and Goethe poems.",https://www.reddit.com/r/MachineLearning/comments/7ij2gg/an_interactive_chat_box_with_a_char_rnn_trained/,kleinergauss,1512777177,,0,1
428,2017-12-9,2017,12,9,9,7ij40m,"[P] Writing A Fun &amp; Simple, Easy To Follow Neural Network!",https://www.reddit.com/r/MachineLearning/comments/7ij40m/p_writing_a_fun_simple_easy_to_follow_neural/,SEFDStuff,1512777600,,0,0
429,2017-12-9,2017,12,9,9,7ij4wx,Streaming the trials for a Genetic Algorithm trying to solve for an optimal composite configuration at 7:30 PM EST,https://www.reddit.com/r/MachineLearning/comments/7ij4wx/streaming_the_trials_for_a_genetic_algorithm/,[deleted],1512777876,[deleted],0,1
430,2017-12-9,2017,12,9,10,7ijitl,Solving the Basic Game of Pong,https://www.reddit.com/r/MachineLearning/comments/7ijitl/solving_the_basic_game_of_pong/,funmaster11,1512781847,,0,1
431,2017-12-9,2017,12,9,10,7ijq9p,Optimal DNN Primitive Selection with Partitioned Boolean Quadratic Programming,https://www.reddit.com/r/MachineLearning/comments/7ijq9p/optimal_dnn_primitive_selection_with_partitioned/,[deleted],1512784157,[deleted],0,1
432,2017-12-9,2017,12,9,10,7ijqdo,[R] Optimal DNN Primitive Selection with Partitioned Boolean Quadratic Programming,https://www.reddit.com/r/MachineLearning/comments/7ijqdo/r_optimal_dnn_primitive_selection_with/,mttd,1512784194,,0,2
433,2017-12-9,2017,12,9,11,7ijtec,Looking for database with both image and time based components,https://www.reddit.com/r/MachineLearning/comments/7ijtec/looking_for_database_with_both_image_and_time/,ItsybitsyMonster,1512785103,[removed],0,1
434,2017-12-9,2017,12,9,12,7ik7ow,Custom Rig Setup,https://www.reddit.com/r/MachineLearning/comments/7ik7ow/custom_rig_setup/,dsengupta16,1512788665,[removed],0,1
435,2017-12-9,2017,12,9,12,7ikg4d,Advice for new Ph.D. students,https://www.reddit.com/r/MachineLearning/comments/7ikg4d/advice_for_new_phd_students/,shagunsodhani,1512791210,,0,1
436,2017-12-9,2017,12,9,13,7ikmio,Opinions about MXNet and Gluon,https://www.reddit.com/r/MachineLearning/comments/7ikmio/opinions_about_mxnet_and_gluon/,dsengupta16,1512793391,[removed],0,1
437,2017-12-9,2017,12,9,14,7iktpf,Are new results from Computational Learning Theory even useful these days?,https://www.reddit.com/r/MachineLearning/comments/7iktpf/are_new_results_from_computational_learning/,stefanuus,1512795948,[removed],0,1
438,2017-12-9,2017,12,9,14,7iku25,Details on Machine Learning Training in Bangalore,https://www.reddit.com/r/MachineLearning/comments/7iku25/details_on_machine_learning_training_in_bangalore/,john-fernandes,1512796065,,1,1
439,2017-12-9,2017,12,9,14,7ikvq3,[P] Esperanto grammar/spellcheck trained on Wikipedia - 1st NLP project,https://www.reddit.com/r/MachineLearning/comments/7ikvq3/p_esperanto_grammarspellcheck_trained_on/,prototypist,1512796636,,1,29
440,2017-12-9,2017,12,9,14,7ikx0k,Apple releases Turi Create on GitHub,https://www.reddit.com/r/MachineLearning/comments/7ikx0k/apple_releases_turi_create_on_github/,420weed,1512797133,[removed],0,1
441,2017-12-9,2017,12,9,14,7ikxct,[D] What are the best papers at the intersection of operating systems and machine learning research?,https://www.reddit.com/r/MachineLearning/comments/7ikxct/d_what_are_the_best_papers_at_the_intersection_of/,chris2point0,1512797258,"Whatever metric you'd like for ""best"" - papers that combine ML (particularly neural networks) with OS topics like process scheduling, memory management, file systems, etc.",2,1
442,2017-12-9,2017,12,9,14,7il1zk,Why can't I make my own cloud GPU?,https://www.reddit.com/r/MachineLearning/comments/7il1zk/why_cant_i_make_my_own_cloud_gpu/,donutholer,1512799012,[removed],0,1
443,2017-12-9,2017,12,9,16,7iliza,Apply machine learning techniques to medical signal interpretation,https://www.reddit.com/r/MachineLearning/comments/7iliza/apply_machine_learning_techniques_to_medical/,qtong2005,1512805615,[removed],0,1
444,2017-12-9,2017,12,9,17,7ilqm6,Bentonite granules making machine,https://www.reddit.com/r/MachineLearning/comments/7ilqm6/bentonite_granules_making_machine/,amylee516,1512809495,,0,1
445,2017-12-9,2017,12,9,17,7ilr2d,Detecting Diseases in Chest X-ray Using Deep Learning,https://www.reddit.com/r/MachineLearning/comments/7ilr2d/detecting_diseases_in_chest_xray_using_deep/,shashankg22,1512809750,,0,1
446,2017-12-9,2017,12,9,18,7iltkh,Weighted word-embeddings?,https://www.reddit.com/r/MachineLearning/comments/7iltkh/weighted_wordembeddings/,czechrepublic,1512810992,[removed],0,1
447,2017-12-9,2017,12,9,19,7im5uv,[R] Solving internal covariate shift in deep learning with linked neurons,https://www.reddit.com/r/MachineLearning/comments/7im5uv/r_solving_internal_covariate_shift_in_deep/,visarga,1512816858,,28,28
448,2017-12-9,2017,12,9,21,7imfc4,"[D] ""Negative labels""",https://www.reddit.com/r/MachineLearning/comments/7imfc4/d_negative_labels/,TalkingJellyFish,1512821518,"We have a nice pipeline for annotating our data (text) where the system will sometimes suggest an annotation to the annotator. When the annotater approves it, everyone is happy - we have a new annotations. 

When the annotater rejects the suggestion, we have this weaker piece of information , e.g. ""example X is not from class Y"". 
Say we were training a model with our new annotations, could we use the ""negative labels"" to train the model, what would that look like ? 
My struggle is that when working with a softmax, we output a distribution over the classes, but in a negative label, we know some class should have probability zero but know nothing about other classes. ",50,48
449,2017-12-9,2017,12,9,21,7imhxq,"""AI Challenges"" position at CNRS",https://www.reddit.com/r/MachineLearning/comments/7imhxq/ai_challenges_position_at_cnrs/,amazrs,1512822744,[removed],0,1
450,2017-12-9,2017,12,9,23,7in3l5,"Do neural networks exist that have been trained to scrape, label, and clean data? Trained to do the tedious work of building data sets?",https://www.reddit.com/r/MachineLearning/comments/7in3l5/do_neural_networks_exist_that_have_been_trained/,Motor_City_Cobra,1512831026,[removed],0,1
451,2017-12-10,2017,12,10,0,7inem3,Are You Genius IQ Test English Question 1,https://www.reddit.com/r/MachineLearning/comments/7inem3/are_you_genius_iq_test_english_question_1/,anowarul147,1512834083,,0,1
452,2017-12-10,2017,12,10,0,7ingwd,Very low KL divergence ?,https://www.reddit.com/r/MachineLearning/comments/7ingwd/very_low_kl_divergence/,HaziqRazali,1512834760,[removed],0,1
453,2017-12-10,2017,12,10,1,7inm5i,Wanting to learn more about machine learning... Could use some advice.,https://www.reddit.com/r/MachineLearning/comments/7inm5i/wanting_to_learn_more_about_machine_learning/,_BrentAureli_,1512836243,[removed],0,1
454,2017-12-10,2017,12,10,1,7inn34,A reply to Francois Chollet on intelligence explosion,https://www.reddit.com/r/MachineLearning/comments/7inn34/a_reply_to_francois_chollet_on_intelligence/,Dragon-God,1512836510,,0,1
455,2017-12-10,2017,12,10,2,7iny8p,CNN - multiple layers,https://www.reddit.com/r/MachineLearning/comments/7iny8p/cnn_multiple_layers/,sharanbr,1512839527,[removed],0,1
456,2017-12-10,2017,12,10,2,7io46o,Machine Learning for Art Valuation,https://www.reddit.com/r/MachineLearning/comments/7io46o/machine_learning_for_art_valuation/,Artnome,1512841140,,0,1
457,2017-12-10,2017,12,10,2,7io8r0,[R] Parallel Computation That Assigns Canonical Object-Based Frames of Reference (1981) &lt;- precursor of Hinton's capsules,https://www.reddit.com/r/MachineLearning/comments/7io8r0/r_parallel_computation_that_assigns_canonical/,eref,1512842348,,2,16
458,2017-12-10,2017,12,10,3,7ioawv,AlphaZero learns chess,https://www.reddit.com/r/MachineLearning/comments/7ioawv/alphazero_learns_chess/,alexeyr,1512842888,,0,1
459,2017-12-10,2017,12,10,4,7iop7o,Prioritized memory access explains planning and hippocampal replay,https://www.reddit.com/r/MachineLearning/comments/7iop7o/prioritized_memory_access_explains_planning_and/,brainlogist,1512846803,,0,1
460,2017-12-10,2017,12,10,4,7ioq1b,Is it possible to buy a standalone TPU (Tensor Processing Unit)?,https://www.reddit.com/r/MachineLearning/comments/7ioq1b/is_it_possible_to_buy_a_standalone_tpu_tensor/,[deleted],1512847028,,0,1
461,2017-12-10,2017,12,10,5,7ip3yn,[Classification] Rescaling or standardisation?,https://www.reddit.com/r/MachineLearning/comments/7ip3yn/classification_rescaling_or_standardisation/,[deleted],1512850699,,0,1
462,2017-12-10,2017,12,10,5,7ipbmf,Presentation,https://www.reddit.com/r/MachineLearning/comments/7ipbmf/presentation/,noob_pixel,1512852782,[removed],0,1
463,2017-12-10,2017,12,10,6,7ipk26,This YouTube Machine Learning channel is a hidden gem and deserves far more viewers! Let's do it!,https://www.reddit.com/r/MachineLearning/comments/7ipk26/this_youtube_machine_learning_channel_is_a_hidden/,gaspiman,1512855089,,1,1
464,2017-12-10,2017,12,10,8,7iqa0u,[D] Jeff Dean: Machine Learning for Systems,https://www.reddit.com/r/MachineLearning/comments/7iqa0u/d_jeff_dean_machine_learning_for_systems/,sksq9,1512862428,,33,227
465,2017-12-10,2017,12,10,8,7iqeu2,IBM Scientists Develop Algorithm to Accelerate Machine Learning Training,https://www.reddit.com/r/MachineLearning/comments/7iqeu2/ibm_scientists_develop_algorithm_to_accelerate/,solracor,1512863835,,1,1
466,2017-12-10,2017,12,10,9,7iqojn,[D] Is it possible to buy a standalone TPU? (Tensor Processing Unit),https://www.reddit.com/r/MachineLearning/comments/7iqojn/d_is_it_possible_to_buy_a_standalone_tpu_tensor/,Phylliida,1512866545,"Google made these TPUs that are great for ML in tensorflow, however the only way to use one is to rent one on the cloud. Is it possible to buy a physical one to use at home/in the lab? Even if this isnt possible, Im curious theoretically does anyone know much a single standalone TPU would cost if they were for sale?",31,11
467,2017-12-10,2017,12,10,10,7iqsja,Dr. Stephen Nawara Explains Why Machine Learning Struggles to Find a Home in Medical Research (x-Post from r/medicine),https://www.reddit.com/r/MachineLearning/comments/7iqsja/dr_stephen_nawara_explains_why_machine_learning/,chris_conlan,1512867744,,0,1
468,2017-12-10,2017,12,10,10,7iqsm5,How do I combine these three aspects?,https://www.reddit.com/r/MachineLearning/comments/7iqsm5/how_do_i_combine_these_three_aspects/,mount_sumInt,1512867770,[removed],0,1
469,2017-12-10,2017,12,10,10,7iqwdg,Apple open sources Turi Create. A Python package to simplify the development of custom machine learning models.,https://www.reddit.com/r/MachineLearning/comments/7iqwdg/apple_open_sources_turi_create_a_python_package/,pacmanisfun,1512868974,,0,1
470,2017-12-10,2017,12,10,12,7irimc,[p] Not sure where to start. Need help processing images and marking them appropriately.,https://www.reddit.com/r/MachineLearning/comments/7irimc/p_not_sure_where_to_start_need_help_processing/,Karmaa,1512876151,,20,42
471,2017-12-10,2017,12,10,12,7iro03,What are the absolute minimum requirements of math knowledge in order to learn how to make artificial neural networks?,https://www.reddit.com/r/MachineLearning/comments/7iro03/what_are_the_absolute_minimum_requirements_of/,8Warden12,1512877964,[removed],0,1
472,2017-12-10,2017,12,10,13,7irruo,"Google's AI teaches itself chess in 4 hours, then convincingly defeats Stockfish",https://www.reddit.com/r/MachineLearning/comments/7irruo/googles_ai_teaches_itself_chess_in_4_hours_then/,[deleted],1512879281,[deleted],0,1
473,2017-12-10,2017,12,10,13,7irtle,"[N] Google's AI teaches itself chess in 4 hours, then convincingly defeats Stockfish",https://www.reddit.com/r/MachineLearning/comments/7irtle/n_googles_ai_teaches_itself_chess_in_4_hours_then/,gamerporcupine,1512879894,,6,0
474,2017-12-10,2017,12,10,14,7irzk4,IQ Test Bangla 2,https://www.reddit.com/r/MachineLearning/comments/7irzk4/iq_test_bangla_2/,anowarul147,1512882051,,0,1
475,2017-12-10,2017,12,10,15,7isbx1,General Game Playing and Alpha Zero like learning. Looking for people to join me.,https://www.reddit.com/r/MachineLearning/comments/7isbx1/general_game_playing_and_alpha_zero_like_learning/,[deleted],1512886423,[deleted],0,1
476,2017-12-10,2017,12,10,15,7isebf,General Game Playing with AlphaZero like learning. Request for people to join me.,https://www.reddit.com/r/MachineLearning/comments/7isebf/general_game_playing_with_alphazero_like_learning/,[deleted],1512887103,[deleted],0,1
477,2017-12-10,2017,12,10,15,7isfr6,Defining the boundaries of artificial intelligence and what is thinking rationally,https://www.reddit.com/r/MachineLearning/comments/7isfr6/defining_the_boundaries_of_artificial/,sshusain,1512887595,,1,1
478,2017-12-10,2017,12,10,16,7isnft,RANIK optimizer: Mathematical Optimization for Machine Learning using insights from Physics,https://www.reddit.com/r/MachineLearning/comments/7isnft/ranik_optimizer_mathematical_optimization_for/,akanimax,1512891136,,34,0
479,2017-12-10,2017,12,10,16,7ispwj,Some conjectures about AlphaZero,https://www.reddit.com/r/MachineLearning/comments/7ispwj/some_conjectures_about_alphazero/,no_bear_so_low,1512892405,[removed],0,1
480,2017-12-10,2017,12,10,17,7isrh7,NIPS2017: Talk by a Turing award winner ignored?,https://www.reddit.com/r/MachineLearning/comments/7isrh7/nips2017_talk_by_a_turing_award_winner_ignored/,xen-m-rph,1512893205,,0,1
481,2017-12-10,2017,12,10,17,7issby,[D] Training with Batch Normalization,https://www.reddit.com/r/MachineLearning/comments/7issby/d_training_with_batch_normalization/,kmkolasinski,1512893574,"Hi, despite all the alchemy which Batch Norm does behind the covariate shift , I understand it simply as normalization layer which tries to keep all activation within some prior distribution. This is especially helpful at the beginning of the training process where badly chosen initialization may lead to vanishing or exploding signal in the network. Once the network is trained the batch norm in test time uses moving averages of estimated mean and variance of training population i.e. it applies simple linear transformation. So here are the questions which come to my mind:

* Did anyone try to compare estimated values of mean and variance, with those computes from whole training set (i.e. not by moving averages)? I'm wonder how this would affect test accuracy. Additionally, how sure can we be that those estimates are optimal for test performance?

* Secondly, once the network is trained, why don't we replace batch norm with linear transformation of form: bn(x) = gamma * x + beta, with gamma/beta being parameters used during test time and then fine tune them using regular gradient descent approach? 

I just wanted to ask experts here, before I will waste a few hours of my life on trying things which already have been done. 
",33,22
482,2017-12-10,2017,12,10,17,7isvoo,Question about minibatch backpropagation in recurrent neural nets,https://www.reddit.com/r/MachineLearning/comments/7isvoo/question_about_minibatch_backpropagation_in/,LivingWreck,1512894611,[removed],0,1
483,2017-12-10,2017,12,10,17,7isy6x,[D] How to learn distribution of aggregated data?,https://www.reddit.com/r/MachineLearning/comments/7isy6x/d_how_to_learn_distribution_of_aggregated_data/,user5647382910,1512895683,"Consider a dataset of student test scores that only shows aggregated information. E.g one data row might say that for a group for 4 students, a total of 300 points were earned on the exam, and of those students, 1 lives more than 5km from the school, 3 live closer than 5km; 2 have siblings in the school, the other 2 do not, etc. My goal is to train a model that helps me learn the features that best predict *individual* student performance and rank all students in terms of their expected contributions to my (known) buckets of scores. In other words, given many buckets of students and their aggregate scores, how can I learn a function to distribute the total bucket score (300) to a group of N students (eg for N=4, scores of 100,80,20,100). The goal is to learn what features predict high-scoring students (perhaps living close to the school) and then to use that function to predict who the high scoring students in that bucket may have been. For a real world use case, this may help a school administrator who only had access to aggregated data to learn a model to predict students to follow up on.

I know I can use a LinearRegressor or RandomForestRegressor to predict individual scores, than redistribute their predicted scores such that sum(predictions_for_bucket) == known_bucket_score, but it seems like a better approach might exist. Does anyone have any tips for solving this type of a problem? It would seem ideal if the predicted values themselves would fall within the known aggregate distribution for the known bucket scores.
",1,1
484,2017-12-10,2017,12,10,19,7it7k3,[D] Which was the website that showed arxiv papers like blogposts?,https://www.reddit.com/r/MachineLearning/comments/7it7k3/d_which_was_the_website_that_showed_arxiv_papers/,dantehorrorshow,1512900743,"I remember seeing a very nice website that converted arxiv papers into blogpost-like pages, very readable especially on mobile. I tried a lot of searches and still cannot find it, and I dont remember its name. Does anyone remember it? Thank you very much. ",11,20
485,2017-12-10,2017,12,10,19,7it8ml,[N] Not The Bots We Were Looking For,https://www.reddit.com/r/MachineLearning/comments/7it8ml/n_not_the_bots_we_were_looking_for/,spendology,1512901315,,1,1
486,2017-12-10,2017,12,10,19,7itcm8,PyTorch-Ensembler for Convolutional Neural Networks (CNN's),https://www.reddit.com/r/MachineLearning/comments/7itcm8/pytorchensembler_for_convolutional_neural/,QuantScientist,1512903452,[removed],0,1
487,2017-12-10,2017,12,10,21,7itlr5,"10. Introduction to Learning, Nearest Neighbors",https://www.reddit.com/r/MachineLearning/comments/7itlr5/10_introduction_to_learning_nearest_neighbors/,3Mo00or,1512907955,,0,1
488,2017-12-10,2017,12,10,21,7itoyj,"[P] CS:GO Aimbot based on machine learning, Dota 2 all over again",https://www.reddit.com/r/MachineLearning/comments/7itoyj/p_csgo_aimbot_based_on_machine_learning_dota_2/,Slaybesh,1512909407,,12,0
489,2017-12-10,2017,12,10,22,7itu8g,[N] Return on AI: Hedge funds embrace machine learningup to a point.,https://www.reddit.com/r/MachineLearning/comments/7itu8g/n_return_on_ai_hedge_funds_embrace_machine/,spendology,1512911706,,31,66
490,2017-12-11,2017,12,11,0,7iugyc,Quotes that will change your life,https://www.reddit.com/r/MachineLearning/comments/7iugyc/quotes_that_will_change_your_life/,NehaGarg12,1512919645,,0,1
491,2017-12-11,2017,12,11,0,7iuj0g,Video 2017 12 10 211045,https://www.reddit.com/r/MachineLearning/comments/7iuj0g/video_2017_12_10_211045/,anowarul147,1512920259,,0,1
492,2017-12-11,2017,12,11,2,7iv5v5,Do I need machine learning in a robotic hand to grab things?,https://www.reddit.com/r/MachineLearning/comments/7iv5v5/do_i_need_machine_learning_in_a_robotic_hand_to/,yalogin,1512926271,[removed],0,1
493,2017-12-11,2017,12,11,2,7iv6hf,Building a Neural Network with Backpropagation,https://www.reddit.com/r/MachineLearning/comments/7iv6hf/building_a_neural_network_with_backpropagation/,[deleted],1512926439,[deleted],0,1
494,2017-12-11,2017,12,11,3,7ivkhv,Do I need machine learning in a robotic hand to grab things?,https://www.reddit.com/r/MachineLearning/comments/7ivkhv/do_i_need_machine_learning_in_a_robotic_hand_to/,[deleted],1512929879,,0,1
495,2017-12-11,2017,12,11,3,7ivlu1,Image Localization - Retrain or Start from Scratch?,https://www.reddit.com/r/MachineLearning/comments/7ivlu1/image_localization_retrain_or_start_from_scratch/,Simusid,1512930141,[removed],0,1
496,2017-12-11,2017,12,11,3,7ivutk,Looking for 3-4 ambitious entrepreneurs for our mastermind/accountability group,https://www.reddit.com/r/MachineLearning/comments/7ivutk/looking_for_34_ambitious_entrepreneurs_for_our/,knights_86363,1512931967,[removed],0,1
497,2017-12-11,2017,12,11,3,7ivvvp,PCIe Lanes for GPU x8 vs x16,https://www.reddit.com/r/MachineLearning/comments/7ivvvp/pcie_lanes_for_gpu_x8_vs_x16/,Aklenar,1512932193,[removed],0,1
498,2017-12-11,2017,12,11,4,7iw4jc,How can one learn about Basic AI and Machine Learning with less/no technical niche?,https://www.reddit.com/r/MachineLearning/comments/7iw4jc/how_can_one_learn_about_basic_ai_and_machine/,chhetri_abisek,1512934180,[removed],0,1
499,2017-12-11,2017,12,11,4,7iwarq,[D] Do I need machine learning in a robotic hand to grab things?,https://www.reddit.com/r/MachineLearning/comments/7iwarq/d_do_i_need_machine_learning_in_a_robotic_hand_to/,yalogin,1512935777,"I am very new to ML and trying to understand where to use it and where not to. Hope this sub is kind to someone learning.

Lets say I am creating a robotic hand to grab things, where how tightly or lightly the fingers grip an item is to be determined. Different fingers might need to use different grip strength based on the shape of the item. Lets also say the alogirthm also needs to decide how many fingers to use, large items need all fingers where as small items like a pen need fewer fingers.

Now lets assume I have other ML/deep learning modules written up that tell me how heavy the object is, how thick it is and its shape. There is no ambiguity here, I need ML/deep learning. I know how strongly I have to grip the item and how many fingers to use and how much to strength I need to give to each finger.

Do I need machine learning to grab the item at this point, which is, to simplify a lot, just pulling strings of each fingers? Or is it a straight up control system that already has the inputs it needs?

How about if the problem changes a bit to account for an incorrect initial estimation of the item size/shape/weight etc? Once the fingers grip it will know if the grip is enough or not and it needs to adjust, do I need ML then? What if the weight/shape/size vary continuously, do I need ML then?
",8,1
500,2017-12-11,2017,12,11,8,7ixtrk,[D] Would AlphaZero recover the solution to Nim?,https://www.reddit.com/r/MachineLearning/comments/7ixtrk/d_would_alphazero_recover_the_solution_to_nim/,columbus8myhw,1512949044,"[Nim](https://en.wikipedia.org/wiki/Nim) has a very simple winning strategy. Therefore, any Nim engine either plays perfectly, or it does not. Do you think that, if AlphaZero were to train on Nim, it would play perfectly? Would it discover the strategy that humans already have? Or would it only play perfectly in situations it has seen before during training, and thus imperfectly in unusual situations it hasn't seen before?

In addition, Nim depends on the sizes of the initial heaps, so it might play well for small heap sizes and fail for large ones. (The human-discovered perfect strategy of course does not do this.)",21,3
501,2017-12-11,2017,12,11,10,7iyoxa,WRITING MY FIRST MACHINE LEARNING PROJECT!,https://www.reddit.com/r/MachineLearning/comments/7iyoxa/writing_my_first_machine_learning_project/,xdppthrowaway9001x,1512956482,,0,0
502,2017-12-11,2017,12,11,11,7iz51p,[D] Future prospect of Machine Learning in Rust Programming Language,https://www.reddit.com/r/MachineLearning/comments/7iz51p/d_future_prospect_of_machine_learning_in_rust/,__hotshot__,1512960436,"The title says it all. I recently came across Rust programming language, its super fast and memory safe, and people have started using this language for performance critical part of their code. There's even a doom renderer in Rust!
So in the near future, will Rust become a mainstream language for machine learning and/or scientific computing?",16,0
503,2017-12-11,2017,12,11,12,7izdm3,What to do about the new GOP tax plan?,https://www.reddit.com/r/MachineLearning/comments/7izdm3/what_to_do_about_the_new_gop_tax_plan/,jirukulapati,1512962361,,0,1
504,2017-12-11,2017,12,11,16,7j0nyt,evan reads (a subset of) NIPS papers,https://www.reddit.com/r/MachineLearning/comments/7j0nyt/evan_reads_a_subset_of_nips_papers/,[deleted],1512976617,,0,1
505,2017-12-11,2017,12,11,16,7j0qhh,Teaching AI to Run - a wrap-up of the NIPS challenge,https://www.reddit.com/r/MachineLearning/comments/7j0qhh/teaching_ai_to_run_a_wrapup_of_the_nips_challenge/,[deleted],1512977649,[deleted],0,1
506,2017-12-11,2017,12,11,16,7j0qo7,[P] Teaching AI to Run - a wrap-up of the NIPS challenge,https://www.reddit.com/r/MachineLearning/comments/7j0qo7/p_teaching_ai_to_run_a_wrapup_of_the_nips/,kidzik,1512977726,,22,118
507,2017-12-11,2017,12,11,17,7j1047,Home |,https://www.reddit.com/r/MachineLearning/comments/7j1047/home/,jaymefritzxrr,1512981870,,0,1
508,2017-12-11,2017,12,11,17,7j10rp,Jeff Dean: Machine Learning for Systems [pdf],https://www.reddit.com/r/MachineLearning/comments/7j10rp/jeff_dean_machine_learning_for_systems_pdf/,Bhima,1512982155,,0,1
509,2017-12-11,2017,12,11,18,7j16te,[R] Long Text Generation via Adversarial Training with Leaked Information,https://www.reddit.com/r/MachineLearning/comments/7j16te/r_long_text_generation_via_adversarial_training/,visarga,1512984903,,10,16
510,2017-12-11,2017,12,11,18,7j19ql,"Software engineer looking to get into machine learning. A bit overwhelmed, where do I start.",https://www.reddit.com/r/MachineLearning/comments/7j19ql/software_engineer_looking_to_get_into_machine/,w4t3rw4lk3r,1512986228,[removed],0,1
511,2017-12-11,2017,12,11,18,7j19w9,[D] A PyTorch implementation of the Mixup Paper,https://www.reddit.com/r/MachineLearning/comments/7j19w9/d_a_pytorch_implementation_of_the_mixup_paper/,leehomyc,1512986302,,4,8
512,2017-12-11,2017,12,11,19,7j1b1k,[R] Why Machine Learning Algorithms Fall Short,https://www.reddit.com/r/MachineLearning/comments/7j1b1k/r_why_machine_learning_algorithms_fall_short/,friscotime,1512986808,,0,1
513,2017-12-11,2017,12,11,19,7j1bpp,Apple's AI director on advances in machine learning for its self-driving car project,https://www.reddit.com/r/MachineLearning/comments/7j1bpp/apples_ai_director_on_advances_in_machine/,mr_j_b,1512987062,,0,1
514,2017-12-11,2017,12,11,21,7j1rpc,Understanding How to Use the Purlin Roll Forming Machine,https://www.reddit.com/r/MachineLearning/comments/7j1rpc/understanding_how_to_use_the_purlin_roll_forming/,bookmarkpool,1512993718,[removed],0,1
515,2017-12-11,2017,12,11,21,7j1sq0,"how to define the boundary of AI, how a program is thinking like human",https://www.reddit.com/r/MachineLearning/comments/7j1sq0/how_to_define_the_boundary_of_ai_how_a_program_is/,sshusain,1512994138,,1,1
516,2017-12-11,2017,12,11,21,7j1u86,How To Build A Fresh Noodle Shop?,https://www.reddit.com/r/MachineLearning/comments/7j1u86/how_to_build_a_fresh_noodle_shop/,liusherry,1512994696,[removed],1,1
517,2017-12-11,2017,12,11,22,7j23ro,[R] How a CogSci undergrad invented PageRank three years before Google  Bradley C. Love,https://www.reddit.com/r/MachineLearning/comments/7j23ro/r_how_a_cogsci_undergrad_invented_pagerank_three/,dream__tiger,1512998052,,14,9
518,2017-12-11,2017,12,11,22,7j25gq,[P] Building an Automated Image Captioning Application,https://www.reddit.com/r/MachineLearning/comments/7j25gq/p_building_an_automated_image_captioning/,beltsazar,1512998601,,1,9
519,2017-12-11,2017,12,11,22,7j26jx,[N] Associated Press: Future of Journalism Will Be Augmented Thanks to AI,https://www.reddit.com/r/MachineLearning/comments/7j26jx/n_associated_press_future_of_journalism_will_be/,spendology,1512998981,,0,1
520,2017-12-11,2017,12,11,22,7j2ays,[P] The What's Good Project,https://www.reddit.com/r/MachineLearning/comments/7j2ays/p_the_whats_good_project/,spendology,1513000418,,0,1
521,2017-12-12,2017,12,12,0,7j2p74,[D] Doubt in Pascal-VOC detection evaluation code,https://www.reddit.com/r/MachineLearning/comments/7j2p74/d_doubt_in_pascalvoc_detection_evaluation_code/,terrorlucid,1513004499,"Python version: https://github.com/rbgirshick/py-faster-rcnn/blob/master/lib/datasets/voc_eval.py#L192.
Why does they use a ""cumsum"", to get total number of tp/fp you just need to do ""sum"" right? By doing this, precision and recall won't be a single number but a list/array which shows cumulative scores through no of detections, why is this needed? I'd be delighted if someone can explain. Thanks in advance! :)

Background info: that array has 0 or 1 value (eg, for TP array, whether its a true positive or not) for each of the predicted bounding box (across all images).

PS - Official MATLAB version also does the exact same thing. You can find it here -&gt; http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCdevkit_18-May-2011.tar 'VOCdevkit/VOCcode/VOCevaldet.m'",2,0
522,2017-12-12,2017,12,12,0,7j2rxy,MangaGAN: My write up about my DCGAN implementation for generating manga and anime faces,https://www.reddit.com/r/MachineLearning/comments/7j2rxy/mangagan_my_write_up_about_my_dcgan/,[deleted],1513005223,[deleted],0,1
523,2017-12-12,2017,12,12,0,7j2sdb,I used transfer learning to recreate a scene from the matrix (song overlay should be self explanatory),https://www.reddit.com/r/MachineLearning/comments/7j2sdb/i_used_transfer_learning_to_recreate_a_scene_from/,Diddlydinkbong,1513005334,,0,1
524,2017-12-12,2017,12,12,0,7j2uoq,[R] AlphaGo Teach: Discover new and creative ways of playing Go,https://www.reddit.com/r/MachineLearning/comments/7j2uoq/r_alphago_teach_discover_new_and_creative_ways_of/,cherls,1513005957,,10,131
525,2017-12-12,2017,12,12,0,7j2v74,"[D] NIPS 2017 Summary! (unless an ""official"" one gets posted, and then remove this dreck)",https://www.reddit.com/r/MachineLearning/comments/7j2v74/d_nips_2017_summary_unless_an_official_one_gets/,thatguydr,1513006102,"Our subreddit hasn't yet had a summary from NIPS attendees about the conference. I know that sometimes we wait for blogs to start the conversation, but I don't see that as starting a particularly unbiased conversation.

Please post what you thought of NIPS, what worked and what didn't, what you learned, and what you'll expect for next year! Maybe also whether you think any conference-logistics from NIPS might be used at ICLR or ICML or KDD this year...",58,49
526,2017-12-12,2017,12,12,0,7j2vfw,[R][1712.02390] Noisy Natural Gradient as Variational Inference (NIPS 2017),https://www.reddit.com/r/MachineLearning/comments/7j2vfw/r171202390_noisy_natural_gradient_as_variational/,fixpoint,1513006166,,0,16
527,2017-12-12,2017,12,12,0,7j2xpv,"[D] Yann LeCun - My take on Ali Rahimi's ""Test of Time"" award...",https://www.reddit.com/r/MachineLearning/comments/7j2xpv/d_yann_lecun_my_take_on_ali_rahimis_test_of_time/,_alphamaximus_,1513006757,,0,1
528,2017-12-12,2017,12,12,0,7j2ytf,[D] An Addendum to Alchemy,https://www.reddit.com/r/MachineLearning/comments/7j2ytf/d_an_addendum_to_alchemy/,sour_losers,1513007052,,12,35
529,2017-12-12,2017,12,12,0,7j325a,"[D] ""sexualized events and speeches at sponsor parties &amp; sexual assault ""jokes"" at closing party"" - Hal Daume, on NIPS 2017",https://www.reddit.com/r/MachineLearning/comments/7j325a/d_sexualized_events_and_speeches_at_sponsor/,sour_losers,1513007906,,46,1
530,2017-12-12,2017,12,12,1,7j35oe,Interesting podcast about Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7j35oe/interesting_podcast_about_machine_learning/,Craftinity,1513008746,,1,1
531,2017-12-12,2017,12,12,1,7j3c7i,Keras Tensorflow tutorial: Practical guide from getting started to developing complex deep neural network,https://www.reddit.com/r/MachineLearning/comments/7j3c7i/keras_tensorflow_tutorial_practical_guide_from/,pmz,1513010361,,0,1
532,2017-12-12,2017,12,12,1,7j3dlm,[Project] Building Not Hotdog with Turi Create and Core ML  in an afternoon,https://www.reddit.com/r/MachineLearning/comments/7j3dlm/project_building_not_hotdog_with_turi_create_and/,jamesonatfritz,1513010706,,2,5
533,2017-12-12,2017,12,12,2,7j3pqy,Difference Between Classification and Regression in Machine Learning - Machine Learning Mastery,https://www.reddit.com/r/MachineLearning/comments/7j3pqy/difference_between_classification_and_regression/,rbagdiya,1513013609,,0,1
534,2017-12-12,2017,12,12,2,7j3pwv,Why does the sup norm make the results of approximation theory independent from the unknown distribution of the input data?,https://www.reddit.com/r/MachineLearning/comments/7j3pwv/why_does_the_sup_norm_make_the_results_of/,real_pinocchio,1513013650,,0,1
535,2017-12-12,2017,12,12,2,7j3sug,[N] New Book on Machine Learning Applications in Marketing - free PDF,https://www.reddit.com/r/MachineLearning/comments/7j3sug/n_new_book_on_machine_learning_applications_in/,ikatsov,1513014375,,4,0
536,2017-12-12,2017,12,12,2,7j3t9b,[D] The Case for Learned Index Structures - ML takes a big bite out of Algorithms,https://www.reddit.com/r/MachineLearning/comments/7j3t9b/d_the_case_for_learned_index_structures_ml_takes/,tshrjn,1513014480,,9,26
537,2017-12-12,2017,12,12,2,7j3tz9,Negative Labels in Adversarial Learning,https://www.reddit.com/r/MachineLearning/comments/7j3tz9/negative_labels_in_adversarial_learning/,alphabetaglamma,1513014667,[removed],0,1
538,2017-12-12,2017,12,12,2,7j3v2j,MangaGAN: My implementation of a DCGAN to generate manga and anime photos,https://www.reddit.com/r/MachineLearning/comments/7j3v2j/mangagan_my_implementation_of_a_dcgan_to_generate/,unmatchedsock31,1513014944,,0,1
539,2017-12-12,2017,12,12,3,7j42u0,"Hi,Im student (first year) of Computer Science &amp; Engineering in Spain, and I would like to focus on posting every day about my experience in this degree.",https://www.reddit.com/r/MachineLearning/comments/7j42u0/hiim_student_first_year_of_computer_science/,MadsGab,1513016620,[removed],0,1
540,2017-12-12,2017,12,12,3,7j4ayq,Solar Power Plant Consultants in India,https://www.reddit.com/r/MachineLearning/comments/7j4ayq/solar_power_plant_consultants_in_india/,Pojavsbuju2106,1513018367,,3,1
541,2017-12-12,2017,12,12,4,7j4gy3,Sugar Plant Design Consultants,https://www.reddit.com/r/MachineLearning/comments/7j4gy3/sugar_plant_design_consultants/,Pojavsbuju2106,1513019727,,1,1
542,2017-12-12,2017,12,12,4,7j4jli,"[N] John Hopkins Professor: No, Google's AI Program Can't Build Your Genome Sequence",https://www.reddit.com/r/MachineLearning/comments/7j4jli/n_john_hopkins_professor_no_googles_ai_program/,downtownslim,1513020332,,14,67
543,2017-12-12,2017,12,12,4,7j4k0a,Ethanol Plant Consultants,https://www.reddit.com/r/MachineLearning/comments/7j4k0a/ethanol_plant_consultants/,Pojavsbuju2106,1513020426,,3,1
544,2017-12-12,2017,12,12,4,7j4kzu,Coupled Learning Background,https://www.reddit.com/r/MachineLearning/comments/7j4kzu/coupled_learning_background/,[deleted],1513020653,,0,1
545,2017-12-12,2017,12,12,4,7j4n3m,[N] Prodigy annotation tool now out of beta,https://www.reddit.com/r/MachineLearning/comments/7j4n3m/n_prodigy_annotation_tool_now_out_of_beta/,syllogism_,1513021120,,23,25
546,2017-12-12,2017,12,12,4,7j4ojo,Coupled Learning Background - LLLD Workshop,https://www.reddit.com/r/MachineLearning/comments/7j4ojo/coupled_learning_background_llld_workshop/,Cjh411,1513021450,[removed],0,1
547,2017-12-12,2017,12,12,4,7j4q1l,Slop fired Boiler Power Plant,https://www.reddit.com/r/MachineLearning/comments/7j4q1l/slop_fired_boiler_power_plant/,Pojavsbuju2106,1513021789,,2,1
548,2017-12-12,2017,12,12,5,7j4ztb,"[D] ""As an ML researcher ..."" (A wish list from NIPS and after)",https://www.reddit.com/r/MachineLearning/comments/7j4ztb/d_as_an_ml_researcher_a_wish_list_from_nips_and/,ajbouh,1513023824,,10,18
549,2017-12-12,2017,12,12,5,7j579u,Project Management Consultancy services in India,https://www.reddit.com/r/MachineLearning/comments/7j579u/project_management_consultancy_services_in_india/,Pojavsbuju2106,1513025241,,3,1
550,2017-12-12,2017,12,12,6,7j5lrq,[D] Has anyone used a loss/cost function outside of log loss (cross-entropy) function for deep learning ?,https://www.reddit.com/r/MachineLearning/comments/7j5lrq/d_has_anyone_used_a_losscost_function_outside_of/,SGuptMachineLearning,1513028322,"I see a lot of variation in different types of parameters for deep learning, except the loss function is always the cross entropy. 

Is there any reason for this?",7,0
551,2017-12-12,2017,12,12,7,7j63m4,"[D] Why have consumer prediction models (NLP, personality insights, etc.) fallen so far behind other types of other ML areas in terms of publicly available information?",https://www.reddit.com/r/MachineLearning/comments/7j63m4/d_why_have_consumer_prediction_models_nlp/,8solutions,1513032631,"Sites like Facebook, Google, etc. have made a lot of headlines recently for their ability to discriminate based on all types of factors (political leanings, race, religion, age, etc.). Obviously, these companies have a lot of data to work with, but I am surprised at just how sparse the publicly available resources are in this space.

Am I just completely missing some keywords, or are there really almost no APIs or repos available for consumer predictions using NLP, interests, social media information, etc.?",11,2
552,2017-12-12,2017,12,12,8,7j687y,Machine learning researchers with no expertise in neuroscience:,https://www.reddit.com/r/MachineLearning/comments/7j687y/machine_learning_researchers_with_no_expertise_in/,[deleted],1513033796,,0,1
553,2017-12-12,2017,12,12,8,7j6bee,how to send a massege with cmd 2018,https://www.reddit.com/r/MachineLearning/comments/7j6bee/how_to_send_a_massege_with_cmd_2018/,TestamentaryGenus,1513034598,,1,1
554,2017-12-12,2017,12,12,8,7j6dct,t-SNE visualization of instagram posts,https://www.reddit.com/r/MachineLearning/comments/7j6dct/tsne_visualization_of_instagram_posts/,farr3l,1513035106,,0,1
555,2017-12-12,2017,12,12,9,7j6s4f,Do any popular stochastic optimization methods use higher order averages/moments of the gradient? Beyond using the second moment.,https://www.reddit.com/r/MachineLearning/comments/7j6s4f/do_any_popular_stochastic_optimization_methods/,PK_thundr,1513038945,[removed],0,1
556,2017-12-12,2017,12,12,10,7j6zhl,GRASS: generative recursive autoencoders for shape structures (SIGGRAPH 2017 Presentation),https://www.reddit.com/r/MachineLearning/comments/7j6zhl/grass_generative_recursive_autoencoders_for_shape/,[deleted],1513040915,[deleted],0,1
557,2017-12-12,2017,12,12,10,7j70n8,[R] GRASS: generative recursive autoencoders for shape structures (SIGGRAPH 2017 Presentation),https://www.reddit.com/r/MachineLearning/comments/7j70n8/r_grass_generative_recursive_autoencoders_for/,zergling103,1513041215,,2,2
558,2017-12-12,2017,12,12,11,7j7jj5,Organic fertilizer granulator,https://www.reddit.com/r/MachineLearning/comments/7j7jj5/organic_fertilizer_granulator/,amylee516,1513046402,,0,1
559,2017-12-12,2017,12,12,11,7j7lub,Stainless Steel Automatic Rice Noodle Making Machine,https://www.reddit.com/r/MachineLearning/comments/7j7lub/stainless_steel_automatic_rice_noodle_making/,liusherry,1513047018,[removed],1,1
560,2017-12-12,2017,12,12,12,7j7sma,Why does the sup norm make the results of approximation theory independent from the unknown distribution of the input data? math.stackexchange.com,https://www.reddit.com/r/MachineLearning/comments/7j7sma/why_does_the_sup_norm_make_the_results_of/,real_pinocchio,1513048705,,0,1
561,2017-12-12,2017,12,12,12,7j7um7,"[D] Services that convert speech to text, with the ability to handle overlapping speech from two or more people.",https://www.reddit.com/r/MachineLearning/comments/7j7um7/d_services_that_convert_speech_to_text_with_the/,Karmaa,1513049112,"I'm not sure this is even a possibility with the current services offered by Google(SPEECH) and AWS (Transcribe), I've read through their documents, but I haven't found anything that answers my question.


* Is there currently any service that is able to convert speech to text  when two or more people are talking, and distinguish the source?


For example, lets say Al and Frank are talking in turn, and at some point Al asks a question, but before he finishes his question, Frank starts talking.


Results I'd like:

Voices identified: 2

* P1(VI-1)-time: 0:00-0:01: Hi Al
* P2(VI-2)-time: 0:02-0:03: Hi Frank
* P1(VI-1)-time: 0:04-0:07: How are you doing?
* P2(VI-2)-time: 0:08-**0:13**: Im doing good Frank, how are you doing this sunny morning?
* P1(VI-1)-time: **0:12**-0:17: Great! I just found out I am going to go for a trip.
* P2(VI-2)-time: 0:18-0:24: That is great!
* P2(VI-1)-time: 0:25-0:27: I know!!


If there are currently non with that capacity, does anyone know if there are any projects in the pipelines, that might be coming down in the foreseeable future? 
",4,0
562,2017-12-12,2017,12,12,12,7j80gk,A Fun Text Generation App!,https://www.reddit.com/r/MachineLearning/comments/7j80gk/a_fun_text_generation_app/,tshrjn,1513050392,,1,1
563,2017-12-12,2017,12,12,15,7j8tv9,[N] Google's Machine Learning Is Analyzing Data From NASA's Kepler Space Telescope,https://www.reddit.com/r/MachineLearning/comments/7j8tv9/n_googles_machine_learning_is_analyzing_data_from/,gkkfacts,1513059701,,4,0
564,2017-12-12,2017,12,12,15,7j8zlx,[D] Reading a neural networks mind,https://www.reddit.com/r/MachineLearning/comments/7j8zlx/d_reading_a_neural_networks_mind/,[deleted],1513061878,[deleted],0,0
565,2017-12-12,2017,12,12,16,7j90rb,Generative Adversarial Networks  A Deep Learning Architecture,https://www.reddit.com/r/MachineLearning/comments/7j90rb/generative_adversarial_networks_a_deep_learning/,gautamrbharadwaj,1513062317,,0,1
566,2017-12-12,2017,12,12,18,7j9jkb,Machine learning business use will double by end of 2018,https://www.reddit.com/r/MachineLearning/comments/7j9jkb/machine_learning_business_use_will_double_by_end/,mr_j_b,1513070100,,0,1
567,2017-12-12,2017,12,12,18,7j9krt,[R] NIPS 2017 Notes - David Abel (Brown University),https://www.reddit.com/r/MachineLearning/comments/7j9krt/r_nips_2017_notes_david_abel_brown_university/,jakn,1513070616,,28,147
568,2017-12-12,2017,12,12,18,7j9m3n,Generative approach to model the distribution of adversarial perturbations,https://www.reddit.com/r/MachineLearning/comments/7j9m3n/generative_approach_to_model_the_distribution_of/,[deleted],1513071190,[deleted],0,1
569,2017-12-12,2017,12,12,19,7j9u2z,Capsule Network implementation (with dynamic tensorflow routing loop and tensorboard visualizations),https://www.reddit.com/r/MachineLearning/comments/7j9u2z/capsule_network_implementation_with_dynamic/,akanimax,1513073406,,0,0
570,2017-12-12,2017,12,12,19,7j9u47,ReInventing Neural Networks in C#,https://www.reddit.com/r/MachineLearning/comments/7j9u47/reinventing_neural_networks_in_c/,Byte-Master-101,1513073415,,0,1
571,2017-12-12,2017,12,12,19,7j9v5k,Using Neural Networks for Styling Data Visualisations,https://www.reddit.com/r/MachineLearning/comments/7j9v5k/using_neural_networks_for_styling_data/,[deleted],1513073820,[deleted],0,1
572,2017-12-12,2017,12,12,19,7j9zz1,[R] Detecting Diseases in Chest X-ray Using Deep Learning,https://www.reddit.com/r/MachineLearning/comments/7j9zz1/r_detecting_diseases_in_chest_xray_using_deep/,chris_shpak,1513075942,,0,1
573,2017-12-12,2017,12,12,20,7ja64f,[R] 20 lessons on bias in machine learning systems from NIPS 2017 Keynote,https://www.reddit.com/r/MachineLearning/comments/7ja64f/r_20_lessons_on_bias_in_machine_learning_systems/,trumtra,1513078449,,0,1
574,2017-12-12,2017,12,12,20,7ja6cb,[Project] How can I cluster questions done by a person in categories what i know in Azure Machine Learning Studio?,https://www.reddit.com/r/MachineLearning/comments/7ja6cb/project_how_can_i_cluster_questions_done_by_a/,MelissaSx,1513078537,[removed],0,1
575,2017-12-12,2017,12,12,20,7ja95y,Grid LSTM vs multidimensionall rnn,https://www.reddit.com/r/MachineLearning/comments/7ja95y/grid_lstm_vs_multidimensionall_rnn/,BiggusDickus123,1513079644,[removed],0,1
576,2017-12-12,2017,12,12,21,7jad5e,[R] Generative approach to model the distribution of adversarial perturbations,https://www.reddit.com/r/MachineLearning/comments/7jad5e/r_generative_approach_to_model_the_distribution/,mkreddy48,1513081082,,0,4
577,2017-12-12,2017,12,12,21,7jafi8,Quantum Supersampling,https://www.reddit.com/r/MachineLearning/comments/7jafi8/quantum_supersampling/,johnmountain,1513081967,,0,1
578,2017-12-12,2017,12,12,23,7jaymb,[P] How to Find Wally With a Neural Network,https://www.reddit.com/r/MachineLearning/comments/7jaymb/p_how_to_find_wally_with_a_neural_network/,thelole,1513088043,,1,3
579,2017-12-12,2017,12,12,23,7jayrg,What we talk about when we talk about fair AI,https://www.reddit.com/r/MachineLearning/comments/7jayrg/what_we_talk_about_when_we_talk_about_fair_ai/,[deleted],1513088086,[deleted],0,1
580,2017-12-12,2017,12,12,23,7jb43z,Major Autonomous Driving Project Requires Ph.D qualified Researchers in Germany,https://www.reddit.com/r/MachineLearning/comments/7jb43z/major_autonomous_driving_project_requires_phd/,PhDRecruiter,1513089587,[removed],0,1
581,2017-12-12,2017,12,12,23,7jb4al,What are some machine and deep learning topics that a newbie(with 1 year of exp) can research on and publish a research paper?,https://www.reddit.com/r/MachineLearning/comments/7jb4al/what_are_some_machine_and_deep_learning_topics/,aptrishu,1513089635,[removed],0,1
582,2017-12-12,2017,12,12,23,7jb4h1,Building a Convolution Neural Network to play 2048,https://www.reddit.com/r/MachineLearning/comments/7jb4h1/building_a_convolution_neural_network_to_play_2048/,[deleted],1513089684,,0,1
583,2017-12-13,2017,12,13,0,7jbhd0,BE A SPEAKER AT DATAENGCONF SF '18!,https://www.reddit.com/r/MachineLearning/comments/7jbhd0/be_a_speaker_at_dataengconf_sf_18/,furqanasghar85,1513093015,[removed],0,1
584,2017-12-13,2017,12,13,0,7jbhkz,Using adaBoost to classify good and bad loans,https://www.reddit.com/r/MachineLearning/comments/7jbhkz/using_adaboost_to_classify_good_and_bad_loans/,Fremont28,1513093073,,0,1
585,2017-12-13,2017,12,13,0,7jbi2m,AI-Assisted Fake Porn Is Here and We're All Fucked,https://www.reddit.com/r/MachineLearning/comments/7jbi2m/aiassisted_fake_porn_is_here_and_were_all_fucked/,SGDbackprop111,1513093208,,1,1
586,2017-12-13,2017,12,13,0,7jbkio,Hi,https://www.reddit.com/r/MachineLearning/comments/7jbkio/hi/,akimatkiev,1513093837,[removed],0,1
587,2017-12-13,2017,12,13,0,7jbmbj,How to make sense of your feature maps?,https://www.reddit.com/r/MachineLearning/comments/7jbmbj/how_to_make_sense_of_your_feature_maps/,[deleted],1513094306,,0,1
588,2017-12-13,2017,12,13,1,7jbxkk,Working with Missing Data in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7jbxkk/working_with_missing_data_in_machine_learning/,major_grooves,1513096991,,0,1
589,2017-12-13,2017,12,13,2,7jcenl,Edx micromasters vs Udacity AI Nanodegree vs deeplearning.ai,https://www.reddit.com/r/MachineLearning/comments/7jcenl/edx_micromasters_vs_udacity_ai_nanodegree_vs/,hjk612,1513100412,[removed],0,1
590,2017-12-13,2017,12,13,4,7jd4l5,Gradient clipping in keras,https://www.reddit.com/r/MachineLearning/comments/7jd4l5/gradient_clipping_in_keras/,Lukakux,1513105971,[removed],0,1
591,2017-12-13,2017,12,13,4,7jd52m,How do I download pre-trained models from Caffe Model Zoo?,https://www.reddit.com/r/MachineLearning/comments/7jd52m/how_do_i_download_pretrained_models_from_caffe/,stupidCSstudent,1513106078,[removed],0,1
592,2017-12-13,2017,12,13,4,7jdd78,"[R] Deep Learning for NLP, advancements and trends in 2017",https://www.reddit.com/r/MachineLearning/comments/7jdd78/r_deep_learning_for_nlp_advancements_and_trends/,[deleted],1513107974,[deleted],0,1
593,2017-12-13,2017,12,13,5,7jdijw,"[D] Loading a keras model, popping the last two layers, and saving it again ?",https://www.reddit.com/r/MachineLearning/comments/7jdijw/d_loading_a_keras_model_popping_the_last_two/,[deleted],1513109108,[deleted],2,0
594,2017-12-13,2017,12,13,5,7jdlyj,Serverless deep/machine learning in production  the pythonic  way ,https://www.reddit.com/r/MachineLearning/comments/7jdlyj/serverless_deepmachine_learning_in_production_the/,wayaai,1513109807,,0,1
595,2017-12-13,2017,12,13,5,7jdosn,"[D] Bias is not just in our datasets, it's in our conferences and community",https://www.reddit.com/r/MachineLearning/comments/7jdosn/d_bias_is_not_just_in_our_datasets_its_in_our/,baylearn,1513110478,,222,94
596,2017-12-13,2017,12,13,5,7jdtoy,"[D] Deep Learning for NLP, advancements and trends in 2017",https://www.reddit.com/r/MachineLearning/comments/7jdtoy/d_deep_learning_for_nlp_advancements_and_trends/,thesameoldstories,1513111618,,11,44
597,2017-12-13,2017,12,13,6,7je08z,MIRI: Want to get paid to spend all day learning more about ML? Apply here!,https://www.reddit.com/r/MachineLearning/comments/7je08z/miri_want_to_get_paid_to_spend_all_day_learning/,[deleted],1513113115,[deleted],0,1
598,2017-12-13,2017,12,13,6,7je2x1,"Attractive job opening at MIRI: basically, read interesting ML papers, all day every day.",https://www.reddit.com/r/MachineLearning/comments/7je2x1/attractive_job_opening_at_miri_basically_read/,yiavin,1513113744,,0,2
599,2017-12-13,2017,12,13,6,7je5bl,[Project] Distributed vector similarity server?,https://www.reddit.com/r/MachineLearning/comments/7je5bl/project_distributed_vector_similarity_server/,spurious_recollectio,1513114319,"I'm looking around for any open source distributed vector server implementation.  Something like the a distributed version of the gensim similarity server.  The use case is e.g. managing a very large database of doc2vec vectors or other embedding vectors.  It should be possible to insert vectors (in an auto-sharded way), compute similarities between a test vector and a subset of the database, access vectors by metadata, etc.  I imagine this could be implemented by adding a distributed layer over HDF5.  

This seems to be a very standard use case so I'm a bit surprised I haven't managed to find anything that does this yet.  I am considering implementing something like this myself (and probably open sourcing it) but I have no interest in re-inventing the wheel if an existing project already manages this.",3,0
600,2017-12-13,2017,12,13,6,7je6qh,Need help with filerecovery,https://www.reddit.com/r/MachineLearning/comments/7je6qh/need_help_with_filerecovery/,snwbl1nd,1513114678,[removed],0,1
601,2017-12-13,2017,12,13,6,7je8zq,Fast INT8 Inference for Autonomous Vehicles with TensorRT 3,https://www.reddit.com/r/MachineLearning/comments/7je8zq/fast_int8_inference_for_autonomous_vehicles_with/,harrism,1513115200,,0,1
602,2017-12-13,2017,12,13,6,7je9nx,Helpful new operator for feature selection,https://www.reddit.com/r/MachineLearning/comments/7je9nx/helpful_new_operator_for_feature_selection/,datascienceguru,1513115369,,0,1
603,2017-12-13,2017,12,13,7,7jej8u,[D] What does the word2vec patent prevent us from doing?,https://www.reddit.com/r/MachineLearning/comments/7jej8u/d_what_does_the_word2vec_patent_prevent_us_from/,Batmantosh,1513117701,"Can we implement word2vec in our own private companies for developing solutions?

Can a startup use word2vec to make a commercial product?

Here's the patent 

http://www.freepatentsonline.com/9037464.html",8,4
604,2017-12-13,2017,12,13,7,7jeou9,Deep Brain Chain - A Promising AI Cryptocurrency,https://www.reddit.com/r/MachineLearning/comments/7jeou9/deep_brain_chain_a_promising_ai_cryptocurrency/,SwayInHay,1513119035,[removed],0,1
605,2017-12-13,2017,12,13,7,7jeqcu,image processing accuracy - going wide vs going deep?,https://www.reddit.com/r/MachineLearning/comments/7jeqcu/image_processing_accuracy_going_wide_vs_going_deep/,AspiringGuru,1513119410,[removed],0,1
606,2017-12-13,2017,12,13,8,7jexmf,[D] What are the most current conclusions of when to use LSTMs and when to use GRUs?,https://www.reddit.com/r/MachineLearning/comments/7jexmf/d_what_are_the_most_current_conclusions_of_when/,SGuptMachineLearning,1513121242,"Most of the blog posts and videos I see about them say that there wasn't too much of a consensus on that yet, but most of those materials were made ~2 years ago. 

I was wondering what are the current findings on this topic.",18,27
607,2017-12-13,2017,12,13,8,7jf0kh,Is Cognitive Sentiment Analysis -- like the API Google offers -- better than good old-fashioned Naive Bayes?,https://www.reddit.com/r/MachineLearning/comments/7jf0kh/is_cognitive_sentiment_analysis_like_the_api/,_ahnomatopia_,1513122001,[removed],0,1
608,2017-12-13,2017,12,13,9,7jfb3n,Machine Learning Hardware for $100?,https://www.reddit.com/r/MachineLearning/comments/7jfb3n/machine_learning_hardware_for_100/,rodrigo-silveira,1513124643,[removed],0,1
609,2017-12-13,2017,12,13,9,7jfhj3,[D] Embodied Learning is Essential to Artificial Intelligence by Carlos E. Perez,https://www.reddit.com/r/MachineLearning/comments/7jfhj3/d_embodied_learning_is_essential_to_artificial/,spendology,1513126290,,0,1
610,2017-12-13,2017,12,13,10,7jfmgu,[D] Keras is now under a keras-team namespace on Github,https://www.reddit.com/r/MachineLearning/comments/7jfmgu/d_keras_is_now_under_a_kerasteam_namespace_on/,Reiinakano,1513127612,,12,25
611,2017-12-13,2017,12,13,10,7jfrpo,A couple questions on RNN's...,https://www.reddit.com/r/MachineLearning/comments/7jfrpo/a_couple_questions_on_rnns/,ashboy64,1513129097,[removed],0,1
612,2017-12-13,2017,12,13,10,7jfuly,"The (inverse) short time fourier transform module for pytorch, (Trainable)",https://www.reddit.com/r/MachineLearning/comments/7jfuly/the_inverse_short_time_fourier_transform_module/,diggerdu,1513129917,,0,1
613,2017-12-13,2017,12,13,12,7jgavx,Does object localisation improves result for an image classification problem?,https://www.reddit.com/r/MachineLearning/comments/7jgavx/does_object_localisation_improves_result_for_an/,[deleted],1513134498,,0,1
614,2017-12-13,2017,12,13,12,7jgd6z,[R] Data Distillation: Towards Omni-Supervised Learning,https://www.reddit.com/r/MachineLearning/comments/7jgd6z/r_data_distillation_towards_omnisupervised/,xternalz,1513135166,,6,4
615,2017-12-13,2017,12,13,12,7jgenk,[D] Does object localisation improves result for an image classification problem?,https://www.reddit.com/r/MachineLearning/comments/7jgenk/d_does_object_localisation_improves_result_for_an/,aivisual,1513135570," Let's say I just want to classify whether an image contains cat or not. I am not interested to know where the cat is in the image. However, if I provide bounding box and try to solve as an object detection problem rather than classification will that improve the classification result overall?",4,1
616,2017-12-13,2017,12,13,12,7jgjot,[D] How to make sense of your feature maps?,https://www.reddit.com/r/MachineLearning/comments/7jgjot/d_how_to_make_sense_of_your_feature_maps/,ceekaychng,1513136845," Hi guys, I've trained a Faster-Rcnn (with inception-resnet_v2 as feature extractor) on my own dataset. My result is not very ideal, after skimming through my detection results, I found that there is a pattern in the error. I'm really interested to look into the last layer feature map before the regression layer. The dimension of the feature maps is 17x17x384, Ive tried visualizing it layer by layer and I don't think that's a good way to do it. Hence I would like to know if there is anyway good way to analyze them. ",4,3
617,2017-12-13,2017,12,13,13,7jgvcm,[D] Pointers on modelling horse races?,https://www.reddit.com/r/MachineLearning/comments/7jgvcm/d_pointers_on_modelling_horse_races/,[deleted],1513140149,[deleted],4,1
618,2017-12-13,2017,12,13,13,7jgx4a,"What would you build a computer to utilize the Titan V with? Ideal parts or sufficient parts, or both.",https://www.reddit.com/r/MachineLearning/comments/7jgx4a/what_would_you_build_a_computer_to_utilize_the/,Motor_City_Cobra,1513140707,[removed],0,1
619,2017-12-13,2017,12,13,13,7jgxt7,Classifying handwritten digits with Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7jgxt7/classifying_handwritten_digits_with_machine/,sagar03d,1513140923,[removed],0,1
620,2017-12-13,2017,12,13,14,7jh7zx,Machine Learning Interview Questions,https://www.reddit.com/r/MachineLearning/comments/7jh7zx/machine_learning_interview_questions/,ydidichooseengnring,1513144144,[removed],0,1
621,2017-12-13,2017,12,13,15,7jhdiq,[D] Deep Learning: Practice and Trends (a NIPS 2017 tutorial),https://www.reddit.com/r/MachineLearning/comments/7jhdiq/d_deep_learning_practice_and_trends_a_nips_2017/,ntenenz,1513146039,,6,38
622,2017-12-13,2017,12,13,15,7jhec7,ELI5 Capsule Networks Limits. What are their limitations and Drawbacks? Novel Applications for them? And how still failing Adversarial Attacks? CapsNets,https://www.reddit.com/r/MachineLearning/comments/7jhec7/eli5_capsule_networks_limits_what_are_their/,[deleted],1513146343,,0,1
623,2017-12-13,2017,12,13,15,7jhg12,[D] Capsule Networks Limits. What are their limitations and Drawbacks? Novel Applications for them? And how still failing Adversarial Attacks? (CapsNets),https://www.reddit.com/r/MachineLearning/comments/7jhg12/d_capsule_networks_limits_what_are_their/,pentatomic,1513146961,"CapsNets seem very promising, but I want to open discussions about their limits and promises.

1.    What are their limitations and Drawbacks? (ELI5). They seem to be ""too good"". What are their problems? Where do they fall short? One example was in the paper and discussed here: https://www.reddit.com/r/MachineLearning/comments/7deq2z/d_eli5_the_drawbacks_of_capsules_m/, but what are others?

2. Why do they still fail Adversarial Attacks? (ELI5).
jaesik817 experimented and their results show CapsNets failed every type of basic adversarial attack. How come? How could they be structured with more resistance or improved against such attacks? https://github.com/jaesik817/adv_attack_capsnet

3. What would be Novel Applications for them? Beyond image recognition, what would they be especially good for or interesting to apply on? Object recognition sounds like a viable route. How about Speech or Music recognition? Textual/NLP analyses? Predictive models for specific types of data/applications? 

4. Also, is there any tiny example implementation of them to a toy problem from scratch? All I could find is Tensorflow and PyTorch implementations, but I want to see a toy implementation for a small problem built without a deep learning framework or not necessitating GPU or days of running. That would help understanding the algorithm, how to modify it for new examples, and playing around with it.

Thank you everyone!
",5,23
624,2017-12-13,2017,12,13,16,7jhm1t,[D] Why doesn't Batch Norm use the long term average during training,https://www.reddit.com/r/MachineLearning/comments/7jhm1t/d_why_doesnt_batch_norm_use_the_long_term_average/,NaughtyCranberry,1513149216,"This is the gist of how I think batchnorm is work, please correct me if it is not the case.

During training the activations are normalized with the mean and std of the minibatch activations and during inference a long term running average of the mean and std of the minibatches is used, typically with an alpha of 0.999.

My question is, why not use a running average during training as well? Is there not a disconnect between training and testing?
",22,4
625,2017-12-13,2017,12,13,16,7jhn0t,[N] Google opens AI Research and Development Centre in Beijing China,https://www.reddit.com/r/MachineLearning/comments/7jhn0t/n_google_opens_ai_research_and_development_centre/,wei_jok,1513149604,,17,161
626,2017-12-13,2017,12,13,16,7jhnds,Bentonite granulation machine,https://www.reddit.com/r/MachineLearning/comments/7jhnds/bentonite_granulation_machine/,amylee516,1513149752,,0,1
627,2017-12-13,2017,12,13,16,7jhsfy,Tool for quickly manually assigning labels to text (or images or other stuff)?,https://www.reddit.com/r/MachineLearning/comments/7jhsfy/tool_for_quickly_manually_assigning_labels_to/,[deleted],1513151857,,0,1
628,2017-12-13,2017,12,13,17,7jhx98,How Is Peanut Butter Made Step By Step,https://www.reddit.com/r/MachineLearning/comments/7jhx98/how_is_peanut_butter_made_step_by_step/,gelgoogcara,1513153900,,1,1
629,2017-12-13,2017,12,13,17,7jhxth,[D] Can a neural network predict it's own confidence?,https://www.reddit.com/r/MachineLearning/comments/7jhxth/d_can_a_neural_network_predict_its_own_confidence/,waleedka,1513154141,"In classification tasks I can use the class score as a measure of the network confidence. If the network classifies an image as a cat with 0.99 score then the network has high confidence in its prediction compared to an image with a 0.60 score. Is there a similar mechanism to assess the confidence of a regression output?

Intuitively, it seems that it should be doable. Say I'm building a model to predict the temperature from location and time of year. There are areas where the weather is fairly stable and there are areas where the weather changes every day. The network should be able to catch these patterns and output a ""confidence"" score in addition to the regressed temperature value. 

Has anyone encountered papers covering this?",31,11
630,2017-12-13,2017,12,13,17,7ji100,How to set up your free website with Github,https://www.reddit.com/r/MachineLearning/comments/7ji100/how_to_set_up_your_free_website_with_github/,sagar03d,1513155584,,0,1
631,2017-12-13,2017,12,13,18,7ji3lj,How to organize different research contents to form a Phd thesis?,https://www.reddit.com/r/MachineLearning/comments/7ji3lj/how_to_organize_different_research_contents_to/,scotty20172017,1513156689,[removed],0,1
632,2017-12-13,2017,12,13,18,7ji6wa,[R] Trifacta Expands Data Wrangling on the Cloud with Additional Support of Amazon Web Services and Availability on AWS Marketplace,https://www.reddit.com/r/MachineLearning/comments/7ji6wa/r_trifacta_expands_data_wrangling_on_the_cloud/,chris_shpak,1513158204,,0,1
633,2017-12-13,2017,12,13,18,7ji71j,Google slashes prices for its machine learning service as AWS steps up competition,https://www.reddit.com/r/MachineLearning/comments/7ji71j/google_slashes_prices_for_its_machine_learning/,mr_j_b,1513158273,,0,1
634,2017-12-13,2017,12,13,18,7ji94e,[R] When Traditional Programming Meets Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7ji94e/r_when_traditional_programming_meets_machine/,magneticono,1513159161,,0,1
635,2017-12-13,2017,12,13,19,7jiam4,What are the best learning ressources to build an AI for beginners,https://www.reddit.com/r/MachineLearning/comments/7jiam4/what_are_the_best_learning_ressources_to_build_an/,calrissianlando,1513159796,[removed],0,1
636,2017-12-13,2017,12,13,19,7jicrs,[R] Summarizing Sequence Data by Mining Generalizing Patterns,https://www.reddit.com/r/MachineLearning/comments/7jicrs/r_summarizing_sequence_data_by_mining/,TaXxER,1513160655,,0,1
637,2017-12-13,2017,12,13,19,7jigzw,[R] TFGAN: A Lightweight Library for Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/7jigzw/r_tfgan_a_lightweight_library_for_generative/,Jackal008,1513162518,,6,75
638,2017-12-13,2017,12,13,21,7jiy0x,[N] Tutorial session: Geometric Deep Learning on Graphs and Manifolds,https://www.reddit.com/r/MachineLearning/comments/7jiy0x/n_tutorial_session_geometric_deep_learning_on/,visarga,1513169133,,0,2
639,2017-12-13,2017,12,13,22,7jj99r,[D] Talk at ReWorkDL Summit: Common Sense Video Understanding,https://www.reddit.com/r/MachineLearning/comments/7jj99r/d_talk_at_reworkdl_summit_common_sense_video/,nahuak,1513172543,,1,0
640,2017-12-13,2017,12,13,22,7jjdgw,What is Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/7jjdgw/what_is_machine_learning/,MCAL_Training,1513173461,,0,1
641,2017-12-13,2017,12,13,23,7jjnq3,scikitlearn to android,https://www.reddit.com/r/MachineLearning/comments/7jjnq3/scikitlearn_to_android/,syam_kumar,1513176044,[removed],0,1
642,2017-12-13,2017,12,13,23,7jjnrx,200+ AI/ML Conferences in 2018.,https://www.reddit.com/r/MachineLearning/comments/7jjnrx/200_aiml_conferences_in_2018/,abusaayem,1513176064,,0,1
643,2017-12-14,2017,12,14,0,7jjryh,What we talk about when we talk about fair AI,https://www.reddit.com/r/MachineLearning/comments/7jjryh/what_we_talk_about_when_we_talk_about_fair_ai/,rhymes_with_tintin,1513177219,,0,1
644,2017-12-14,2017,12,14,0,7jjvcq,Google leads in the race to dominate artificial intelligence,https://www.reddit.com/r/MachineLearning/comments/7jjvcq/google_leads_in_the_race_to_dominate_artificial/,jonfla,1513178078,,0,1
645,2017-12-14,2017,12,14,0,7jk3cq,Tackling adversarial examples in real world,https://www.reddit.com/r/MachineLearning/comments/7jk3cq/tackling_adversarial_examples_in_real_world/,[deleted],1513180115,,0,1
646,2017-12-14,2017,12,14,0,7jk52v,"Simple Questions Thread December 13, 2017",https://www.reddit.com/r/MachineLearning/comments/7jk52v/simple_questions_thread_december_13_2017/,AutoModerator,1513180533,[removed],0,1
647,2017-12-14,2017,12,14,1,7jk9t7,Compare five baseline deep learning models on TrecQA,https://www.reddit.com/r/MachineLearning/comments/7jk9t7/compare_five_baseline_deep_learning_models_on/,zpdlzpdldpa,1513181606,,0,1
648,2017-12-14,2017,12,14,1,7jkgl6,[D] Having a hard time trying to understand GAN,https://www.reddit.com/r/MachineLearning/comments/7jkgl6/d_having_a_hard_time_trying_to_understand_gan/,LangoLango123,1513183239,"Hello, everyone.

I started to learn more about GANs, and I was trying to understand some code I found online.

I found a code from Siraj Raval with a GAN for handwritten digits using MNIST. The problem is that there is many obscure stuff in the code.

For example, the generator is a deconvolution network, but in his code he uses tf.nn.conv2d and reshape the output. How this work as a deconvolution?

Also, during training, he uses a bunch of if's to optimize the loss of the discriminator and generator. How this work as a game?

His code can be found in this link:
https://github.com/llSourcell/Generative_Adversarial_networks_LIVE/blob/master/EZGAN.ipynb",2,0
649,2017-12-14,2017,12,14,2,7jkn9w,Looking for an app that studies texts and generates similar ones,https://www.reddit.com/r/MachineLearning/comments/7jkn9w/looking_for_an_app_that_studies_texts_and/,yaniv297,1513184827,[removed],0,1
650,2017-12-14,2017,12,14,2,7jkobo,Is AlphaZero really a scientific breakthrough in AI?,https://www.reddit.com/r/MachineLearning/comments/7jkobo/is_alphazero_really_a_scientific_breakthrough_in/,[deleted],1513185077,[deleted],0,1
651,2017-12-14,2017,12,14,2,7jkoj4,[D] Is AlphaZero really a scientific breakthrough in AI?,https://www.reddit.com/r/MachineLearning/comments/7jkoj4/d_is_alphazero_really_a_scientific_breakthrough/,eref,1513185124,,68,59
652,2017-12-14,2017,12,14,2,7jkq2v,[P] Intro to Gaussian processes - Part I. For anyone who's after a more visual &amp; intuitive primer on the topic.,https://www.reddit.com/r/MachineLearning/comments/7jkq2v/p_intro_to_gaussian_processes_part_i_for_anyone/,Bridgo,1513185452,,20,155
653,2017-12-14,2017,12,14,2,7jksjc,HyperNEAT modifications,https://www.reddit.com/r/MachineLearning/comments/7jksjc/hyperneat_modifications/,KetoReddit,1513186046,[removed],0,1
654,2017-12-14,2017,12,14,2,7jkzpr,[D] Application papers and their venues,https://www.reddit.com/r/MachineLearning/comments/7jkzpr/d_application_papers_and_their_venues/,invariant_crypto,1513187781,"From the recent discussion on the ML systems workshop, which showed quite a bit of interest in this domain, I have been wondering what the right place to submit conference papers in this domain is. 

I am working on ML in computer systems, but systems conferences tend to be very conservative regarding new approaches and do not typically care until the approach is ready for real-world usage (which is reflected on the expectations on the evaluation).

For example, the Google device placement opt paper was at ICML 17 (https://arxiv.org/abs/1706.04972). My question is, from studying the paper calls and reading this year's NIPS proceedings, where do people feel, especially as reviewers, is the right place for novel work in application domains? By that I mean work on exploring/understanding approaches in a real-world system without necessarily introducing new mechanics other than interpreting a problem in this new domain in a way it has not been done before, potentially also introducing new datasets/benchmarks. Example again, the Google paper treating device allocation as a machine translation problem.

Looking at this year's NIPS, there do not seem to be many papers of this style, and understandably most reviewers might be sick of 'deep learning on x' papers where not much is to be gained for the community. 

So overall, what do people feel is the right venue, and what can make an application paper interesting?  Particularly from the perspective of PhD students who cannot make their work relevant by it being large scale and pushing the practical limits of systems.",3,4
655,2017-12-14,2017,12,14,3,7jl4l5,Conference on Multilayer networks and back propagation by Yann LeCun at Collge de France [FR],https://www.reddit.com/r/MachineLearning/comments/7jl4l5/conference_on_multilayer_networks_and_back/,[deleted],1513188901,[deleted],0,1
656,2017-12-14,2017,12,14,3,7jl6fv,Anyone read  A formal theory of common sense physiology  by Andrew S Gordon and Jerry R Hobbs? I cannot find a single review and the book seems fucking interesting,https://www.reddit.com/r/MachineLearning/comments/7jl6fv/anyone_read_a_formal_theory_of_common_sense/,[deleted],1513189339,,0,1
657,2017-12-14,2017,12,14,3,7jl963,Anyone read  A formal theory of common sense psychology by Andrew S. Gordon and Jerry R. Hobbs? I cannot find I single review and books seems very interesting,https://www.reddit.com/r/MachineLearning/comments/7jl963/anyone_read_a_formal_theory_of_common_sense/,BigthinkS,1513189977,[removed],0,1
658,2017-12-14,2017,12,14,3,7jlcsc,[R] Conference on Multilayer networks and backpropagation by Yann LeCun at Collge de France (fr),https://www.reddit.com/r/MachineLearning/comments/7jlcsc/r_conference_on_multilayer_networks_and/,actuia,1513190818,,0,1
659,2017-12-14,2017,12,14,3,7jlfcc,dotGo 2017 - Francesc Campoy Flores - Machine Learning and Go,https://www.reddit.com/r/MachineLearning/comments/7jlfcc/dotgo_2017_francesc_campoy_flores_machine/,mfrw1,1513191416,,0,1
660,2017-12-14,2017,12,14,3,7jlfgo,HELP - building GPU cluster,https://www.reddit.com/r/MachineLearning/comments/7jlfgo/help_building_gpu_cluster/,medhockey,1513191446,[removed],0,1
661,2017-12-14,2017,12,14,4,7jlk6r,r,https://www.reddit.com/r/MachineLearning/comments/7jlk6r/r/,Darhiux,1513192513,[removed],0,1
662,2017-12-14,2017,12,14,4,7jlkbt,Why is the Machine Learning community solely dependent on CUDA and not OpenCL?,https://www.reddit.com/r/MachineLearning/comments/7jlkbt/why_is_the_machine_learning_community_solely/,[deleted],1513192542,,0,1
663,2017-12-14,2017,12,14,4,7jlod2,[D] Why is the Machine Learning community solely dependent on CUDA and not OpenCL?,https://www.reddit.com/r/MachineLearning/comments/7jlod2/d_why_is_the_machine_learning_community_solely/,k3wlbuddy,1513193484,"Most of the ML frameworks have only experimental support for OpenCL. Why was CUDA the chosen API for GPU Compute? Is it  because of a fundamental design difference between both the APIs? 

Also is this dependency on CUDA going to change any time in the future? Especially with Vulkan and OpenCL merging into a single Compute API in the near future",18,3
664,2017-12-14,2017,12,14,4,7jlojz,how to setup parallel computing for R using RStudio in the aws cloud,https://www.reddit.com/r/MachineLearning/comments/7jlojz/how_to_setup_parallel_computing_for_r_using/,[deleted],1513193520,[deleted],0,1
665,2017-12-14,2017,12,14,4,7jlpnn,[D] NIPS 2017 Special: 6 Key Challenges in Deep Learning for Robotics by Pieter Abbeel,https://www.reddit.com/r/MachineLearning/comments/7jlpnn/d_nips_2017_special_6_key_challenges_in_deep/,wilsstar007,1513193783,,0,1
666,2017-12-14,2017,12,14,4,7jlqog,[R] GibbsNet: Iterative Adversarial Inference for Deep Graphical Models,https://www.reddit.com/r/MachineLearning/comments/7jlqog/r_gibbsnet_iterative_adversarial_inference_for/,bbsome,1513194017,,3,21
667,2017-12-14,2017,12,14,4,7jlrle,[D] how to setup parallel computing for R using RStudio in the aws cloud,https://www.reddit.com/r/MachineLearning/comments/7jlrle/d_how_to_setup_parallel_computing_for_r_using/,clementwalter,1513194235,,0,1
668,2017-12-14,2017,12,14,5,7jly45,[D] Software recommendations to help create ground truth/training data for few thousand images,https://www.reddit.com/r/MachineLearning/comments/7jly45/d_software_recommendations_to_help_create_ground/,SirSharpest,1513195750,"Hi all, 

&amp;nbsp; 

I'm wanting something [Like this](http://www.robots.ox.ac.uk/~szheng/imgs/sample_results_CRFasRNN_v2.png) for a project I'm currently designing to pick up on fine details in Xray scans. 

&amp;nbsp; 

I need to be able to highlight regions as basically {0,1,2} so that I can use this as my output classification. I'll be doing this for a few hundred / thousand depending how much time I have, so any suggestions would be unbelievably helpful. 

&amp;nbsp; 

Many thanks for discussions and suggestions! ",6,3
669,2017-12-14,2017,12,14,5,7jm0nu,"CUDA 9.1 Release: ""Run batched neural machine translations and sequence modeling operations on Volta Tensor cores using new APIs in cuBLAS""",https://www.reddit.com/r/MachineLearning/comments/7jm0nu/cuda_91_release_run_batched_neural_machine/,SuperFX,1513196333,,0,1
670,2017-12-14,2017,12,14,6,7jmgcj,"The first episode of our podcast, ""Machine Learning made Known."" Here, Ola, Andrew and Megan have a short interview with our Swiss machine learning engineer, Timo Rohner. He talks about Hilbert, Gdel, and Deep Learning",https://www.reddit.com/r/MachineLearning/comments/7jmgcj/the_first_episode_of_our_podcast_machine_learning/,[deleted],1513199998,[deleted],0,1
671,2017-12-14,2017,12,14,6,7jmivx,"The second episode of our podcast, ""Machine Learning made Known. Michael Jamroz - machine learning engineer talks about image generation with Deep Learning, particularly Generative Adversarial Networks",https://www.reddit.com/r/MachineLearning/comments/7jmivx/the_second_episode_of_our_podcast_machine/,Craftinity,1513200596,,0,1
672,2017-12-14,2017,12,14,7,7jmric,"The first episode of our podcast, ""Machine Learning made Known."" A short interview with Swiss machine learning engineer, Timo Rohner. He talks about Hilbert, Gdel, and Deep Learning.",https://www.reddit.com/r/MachineLearning/comments/7jmric/the_first_episode_of_our_podcast_machine_learning/,Craftinity,1513202566,,0,1
673,2017-12-14,2017,12,14,7,7jmxzl,Papers on reinforcement learning,https://www.reddit.com/r/MachineLearning/comments/7jmxzl/papers_on_reinforcement_learning/,[deleted],1513203762,,0,1
674,2017-12-14,2017,12,14,7,7jn12v,AMA: We are Noam Brown and Professor Tuomas Sandholm from Carnegie Mellon University. We built the Libratus poker AI that beat top humans earlier this year. Ask us anything!,https://www.reddit.com/r/MachineLearning/comments/7jn12v/ama_we_are_noam_brown_and_professor_tuomas/,NoamBrown,1513204433,"Hi all! We are [Noam Brown](http://www.cs.cmu.edu/~noamb/) and Professor [Tuomas Sandholm](http://www.cs.cmu.edu/~sandholm/). Earlier this year our AI [Libratus](https://video.vice.com/en_us/embed/589001f24f0d043f21139709) defeated top pros for the first time in no-limit poker (specifically heads-up no-limit Texas hold'em). We played four top humans in a 120,000 hand match that lasted 20 days, with a $200,000 prize pool divided among the pros. We beat them by a wide margin ($1.8 million at $50/$100 blinds, or about 15 BB / 100 in poker terminology), and each human lost individually to the AI. Our recent paper discussing one of the central techniques of the AI, [safe and nested subgame solving](http://www.cs.cmu.edu/~noamb/papers/17-NIPS-Safe.pdf), won a best paper award at NIPS 2017.

We are happy to answer your questions about Libratus, the competition, AI, imperfect-information games, Carnegie Mellon, life in academia for a professor or PhD student, or any other questions you might have!

We are opening this thread to questions now and will be here starting at 9AM EST on December 18th to answer them.",214,40
675,2017-12-14,2017,12,14,8,7jn8wk,[D] What unsolved (or very weakly solved) problems in AI would so much improve user experience that such a discovery would quickly spread across the world?,https://www.reddit.com/r/MachineLearning/comments/7jn8wk/d_what_unsolved_or_very_weakly_solved_problems_in/,BenRayfield,1513206355,"I want to put my research efforts where they matter, especially in realtime interactive user experience such as how in AI that learns to play games there forms a model of the game so precise it can be played as a substitute for the game itself, or other creative contexts similar dumber faster things might be applied to create new user experiences, such as predicting a users movements in a game and moving there automaticly so the user doesnt have to. Just examples.",26,3
676,2017-12-14,2017,12,14,9,7jnpke,[R] Training Set Debugging Using Trusted Items,https://www.reddit.com/r/MachineLearning/comments/7jnpke/r_training_set_debugging_using_trusted_items/,mttd,1513210044,,0,0
677,2017-12-14,2017,12,14,9,7jnref,I debate somebody who is opposed to AI in this podcast. What's your opinion?,https://www.reddit.com/r/MachineLearning/comments/7jnref/i_debate_somebody_who_is_opposed_to_ai_in_this/,matthewmcclelland,1513210483,,0,2
678,2017-12-14,2017,12,14,10,7jo3zw,"[N] AI-ON Relaunch (Proposals by Yoshua Bengio, Max Welling, and Hugo Larochelle)",https://www.reddit.com/r/MachineLearning/comments/7jo3zw/n_aion_relaunch_proposals_by_yoshua_bengio_max/,gabrielpereyra,1513213939,,3,2
679,2017-12-14,2017,12,14,10,7joc16,[D] What is the most evil application of machine learning that you can think up of?,https://www.reddit.com/r/MachineLearning/comments/7joc16/d_what_is_the_most_evil_application_of_machine/,[deleted],1513216188,,2,0
680,2017-12-14,2017,12,14,11,7joea7,[D] NIPS 2017  Notes and Thoughts,https://www.reddit.com/r/MachineLearning/comments/7joea7/d_nips_2017_notes_and_thoughts/,[deleted],1513216818,[deleted],0,2
681,2017-12-14,2017,12,14,11,7joew6,Models A/B testing in production,https://www.reddit.com/r/MachineLearning/comments/7joew6/models_ab_testing_in_production/,mark-g-s,1513216990,[removed],0,1
682,2017-12-14,2017,12,14,11,7jofeg,I made a robot that taught itself how to drive straight as my first ML project,https://www.reddit.com/r/MachineLearning/comments/7jofeg/i_made_a_robot_that_taught_itself_how_to_drive/,1ethanhansen,1513217138,[removed],0,1
683,2017-12-14,2017,12,14,12,7joy2j,Consciousness does not exist (Neural Patterns),https://www.reddit.com/r/MachineLearning/comments/7joy2j/consciousness_does_not_exist_neural_patterns/,adrp23,1513222517,,0,1
684,2017-12-14,2017,12,14,13,7jp383,[R] Machine learning predicts laboratory earthquakes,https://www.reddit.com/r/MachineLearning/comments/7jp383/r_machine_learning_predicts_laboratory_earthquakes/,merepoule,1513224079,,5,2
685,2017-12-14,2017,12,14,13,7jp6p4,[R] Understanding Dimension Reduction with Principal Component Analysis,https://www.reddit.com/r/MachineLearning/comments/7jp6p4/r_understanding_dimension_reduction_with/,coffeepants87,1513225131,,1,1
686,2017-12-14,2017,12,14,13,7jp6yu,Tackling adversarial examples in real world,https://www.reddit.com/r/MachineLearning/comments/7jp6yu/tackling_adversarial_examples_in_real_world/,[deleted],1513225215,,0,1
687,2017-12-14,2017,12,14,14,7jphff,"[D] Statistics, we have a problem.",https://www.reddit.com/r/MachineLearning/comments/7jphff/d_statistics_we_have_a_problem/,mark-v,1513228391,,504,388
688,2017-12-14,2017,12,14,15,7jprpc,Career options after a Master's in Signal Processing?,https://www.reddit.com/r/MachineLearning/comments/7jprpc/career_options_after_a_masters_in_signal/,VioletThunderX,1513232016,[removed],0,1
689,2017-12-14,2017,12,14,15,7jpu76,carpet cleaning equipment,https://www.reddit.com/r/MachineLearning/comments/7jpu76/carpet_cleaning_equipment/,MackJhone,1513232874,,0,1
690,2017-12-14,2017,12,14,15,7jpw7p,Cleaning equipment,https://www.reddit.com/r/MachineLearning/comments/7jpw7p/cleaning_equipment/,MackJhone,1513233618,,0,1
691,2017-12-14,2017,12,14,15,7jpxil,Implementing a Capsule Network,https://www.reddit.com/r/MachineLearning/comments/7jpxil/implementing_a_capsule_network/,akanimax,1513234132,,0,1
692,2017-12-14,2017,12,14,16,7jq831,[D] Can we add this to the wiki? Seems like a good learning resource: Deep Learning For Coders (course.fast.ai),https://www.reddit.com/r/MachineLearning/comments/7jq831/d_can_we_add_this_to_the_wiki_seems_like_a_good/,shill_out_guise,1513238290,,12,7
693,2017-12-14,2017,12,14,17,7jq9m7,Song Generator,https://www.reddit.com/r/MachineLearning/comments/7jq9m7/song_generator/,funmaster11,1513238941,,0,1
694,2017-12-14,2017,12,14,17,7jqcaj,Fertilizer granules making machine,https://www.reddit.com/r/MachineLearning/comments/7jqcaj/fertilizer_granules_making_machine/,amylee516,1513240166,,0,1
695,2017-12-14,2017,12,14,17,7jqd2s,100 ton hydraulic press brake with video and pictures,https://www.reddit.com/r/MachineLearning/comments/7jqd2s/100_ton_hydraulic_press_brake_with_video_and/,hinachin,1513240506,,0,1
696,2017-12-14,2017,12,14,18,7jqgy1,What are development and development-time testing datasets in Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/7jqgy1/what_are_development_and_developmenttime_testing/,czechrepublic,1513242327,[removed],0,1
697,2017-12-14,2017,12,14,18,7jqhvf,[D] AMD A10-7860K paired with Nvidia 1060 for a beginner's desktop?,https://www.reddit.com/r/MachineLearning/comments/7jqhvf/d_amd_a107860k_paired_with_nvidia_1060_for_a/,aremdonuts,1513242736,"I currently have an AMD A10-7860K desktop (without any standalone GPU) and am interested in starting with machine learning. I was initially costing a basic rig that will have an i5 CPU with an NVidia 1060 for GPU-based runs, but am now thinking of just adding the NVidia to my AMD A10 rig to save costs. Will this unit take a big performance hit if I stick with the A10?

I was looking for basic machine learning setups with an A10 and NVidia card, but the ones I found online all had Intel for the CPU and NVidia for the GPU.",7,0
698,2017-12-14,2017,12,14,18,7jqjjo,[D] Tackling adversarial examples in real world,https://www.reddit.com/r/MachineLearning/comments/7jqjjo/d_tackling_adversarial_examples_in_real_world/,nishnik,1513243530,"Today I watched a YouTube video of someone who came 3rd in the recent NIPS challenge on tackling adversarial examples.
He simply used simple tricks like adding gaussian noise, or compressing the image etc.
But then simply told that, these too can easily have adversarial examples if the attacker knows the underlying architecture.
The suggestion which came to my mind is can we have some type of trapdoor function which would be determined by some passkey and would allow both forward and backpropagation while training (the passkey is put up in the architecture itself), but publish its weights only. So one can forward propagate, but not back propagate.

Please bring forth some constructive comments!",4,2
699,2017-12-14,2017,12,14,18,7jqlkm,How Machine Learning Companies are evolving Dubai,https://www.reddit.com/r/MachineLearning/comments/7jqlkm/how_machine_learning_companies_are_evolving_dubai/,stewartcristan,1513244468,,0,1
700,2017-12-14,2017,12,14,18,7jqmpg,[N] MGMT + neural style transfer,https://www.reddit.com/r/MachineLearning/comments/7jqmpg/n_mgmt_neural_style_transfer/,[deleted],1513244969,[deleted],0,1
701,2017-12-14,2017,12,14,19,7jqr4p,"Microsoft levels up Word, Excel, and Outlook with more AI capabilities",https://www.reddit.com/r/MachineLearning/comments/7jqr4p/microsoft_levels_up_word_excel_and_outlook_with/,mr_j_b,1513246924,,0,1
702,2017-12-14,2017,12,14,21,7jr56x,Upcoming Machine Learning Training in Bangalore,https://www.reddit.com/r/MachineLearning/comments/7jr56x/upcoming_machine_learning_training_in_bangalore/,john-fernandes,1513252902,,1,1
703,2017-12-14,2017,12,14,21,7jr7px,Survey about concrete AI metrics progress timelines,https://www.reddit.com/r/MachineLearning/comments/7jr7px/survey_about_concrete_ai_metrics_progress/,Sergej_Shegurin,1513253814,[removed],0,2
704,2017-12-14,2017,12,14,21,7jr94o,Clarification needed when using Tf-Idf vectorizer as a feature for Text Sentiment Classification task.,https://www.reddit.com/r/MachineLearning/comments/7jr94o/clarification_needed_when_using_tfidf_vectorizer/,czechrepublic,1513254334,[removed],0,1
705,2017-12-14,2017,12,14,21,7jr97b,[Discussion] Which part of this song is generated by neural network (or other ML algorithms?),https://www.reddit.com/r/MachineLearning/comments/7jr97b/discussion_which_part_of_this_song_is_generated/,sonsus,1513254360,"Music link 
https://www.youtube.com/watch?v=XUs6CznN8pw

I have a question as written in the title: Which part of the song is generated and which part is not? I assumed vocals are all recorded by human and other algorithms are harnessed to produce the ensemble of background instruments to make accompaniment?

as I see his relevant repo to it, it seems not all of the implementation is opened public? 
https://github.com/llSourcell/Music_Generation

This is my first time to post here. So pls bear me if I diverse too much from the conventional way of composing a post.
",2,1
706,2017-12-14,2017,12,14,21,7jr9i5,Scopes of Machine Learning and Artificial Intelligence in Banking and Financial Services,https://www.reddit.com/r/MachineLearning/comments/7jr9i5/scopes_of_machine_learning_and_artificial/,tanmoyray01,1513254481,,0,1
707,2017-12-14,2017,12,14,21,7jrahi,"Jason's Machine Learning 101: 2 years of headbanging, so you don't have to",https://www.reddit.com/r/MachineLearning/comments/7jrahi/jasons_machine_learning_101_2_years_of/,[deleted],1513254829,[deleted],0,1
708,2017-12-14,2017,12,14,21,7jrc3j,Gfycat wants to fix your low-fidelity GIFs with machine learning,https://www.reddit.com/r/MachineLearning/comments/7jrc3j/gfycat_wants_to_fix_your_lowfidelity_gifs_with/,chlordane2501,1513255417,,0,1
709,2017-12-14,2017,12,14,21,7jren4,[Project] Classifying and visualizing with fastText and tSNE,https://www.reddit.com/r/MachineLearning/comments/7jren4/project_classifying_and_visualizing_with_fasttext/,JakeTheSnake2,1513256321,,0,2
710,2017-12-14,2017,12,14,21,7jreu9,untitled,https://www.reddit.com/r/MachineLearning/comments/7jreu9/untitled/,anowarul147,1513256391,,0,1
711,2017-12-14,2017,12,14,22,7jrgk6,"[P] Lightnet - A simple and efficient Python interface to DarkNet, a neural network library.",https://www.reddit.com/r/MachineLearning/comments/7jrgk6/p_lightnet_a_simple_and_efficient_python/,terrorlucid,1513256950,,9,27
712,2017-12-14,2017,12,14,22,7jrhew,[R] Machines: How Do They Learn and Where Are They Headed?,https://www.reddit.com/r/MachineLearning/comments/7jrhew/r_machines_how_do_they_learn_and_where_are_they/,friscotime,1513257206,,0,1
713,2017-12-14,2017,12,14,22,7jri3i,"If tensorflow can't occupy the whole cpu, will it be slowed down a lot?",https://www.reddit.com/r/MachineLearning/comments/7jri3i/if_tensorflow_cant_occupy_the_whole_cpu_will_it/,[deleted],1513257422,,0,1
714,2017-12-14,2017,12,14,22,7jrjxj,"If tensorflow can't occupy the whole GPU, will it be slowed down a lot?",https://www.reddit.com/r/MachineLearning/comments/7jrjxj/if_tensorflow_cant_occupy_the_whole_gpu_will_it/,ZefeiLi,1513258026,[removed],0,1
715,2017-12-14,2017,12,14,23,7jrrax,[R] The Case for Learned Index Structures,https://www.reddit.com/r/MachineLearning/comments/7jrrax/r_the_case_for_learned_index_structures/,reidhoch,1513260334,,1,22
716,2017-12-14,2017,12,14,23,7jrs56,"[N] Weekly Machine Learning Opensource Roundup  Dec. 14, 2017",https://www.reddit.com/r/MachineLearning/comments/7jrs56/n_weekly_machine_learning_opensource_roundup_dec/,stkim1,1513260559,,0,1
717,2017-12-14,2017,12,14,23,7jrt5k,[R ]Intermedix Data Scientists Published for Health Care Machine Learning Research,https://www.reddit.com/r/MachineLearning/comments/7jrt5k/r_intermedix_data_scientists_published_for_health/,magneticono,1513260838,,0,1
718,2017-12-14,2017,12,14,23,7jruts,[D] Automatic node placement (allocating graph nodes to multiple devices) feature in distributed tensorflow,https://www.reddit.com/r/MachineLearning/comments/7jruts/d_automatic_node_placement_allocating_graph_nodes/,JR_Young,1513261314,"I read tensorflow white papaer and found node placement which allocates graph nodes to devices without manual configuration.

https://www.reddit.com/r/MachineLearning/comments/4n6a0e/distributed_tensorflow_resource_allocation/

This post says this feature was removed because it did not perform well.
However, it was posted a year ago...

I wonder if there is progress.

Is it included in the current version of tensorflow?
As i googled, it is not... but.... I am not sure.

I am wondering if the tensorflow developer is still developing a node placement algorithm.
If so, I would like to know the details of the algorithm and when to plan to add that feature in the tensorflow.",1,1
719,2017-12-14,2017,12,14,23,7jrwiz,Consciousness does not exist. (Neural Patterns),https://www.reddit.com/r/MachineLearning/comments/7jrwiz/consciousness_does_not_exist_neural_patterns/,adrp23,1513261793,,9,1
720,2017-12-14,2017,12,14,23,7js0r1,[R] The 10 Deep Learning Methods AI Practitioners Need to Apply,https://www.reddit.com/r/MachineLearning/comments/7js0r1/r_the_10_deep_learning_methods_ai_practitioners/,jackblun,1513262970,,0,1
721,2017-12-14,2017,12,14,23,7js1md,Tutorials on Xgboost &amp; others in R,https://www.reddit.com/r/MachineLearning/comments/7js1md/tutorials_on_xgboost_others_in_r/,analytics_de,1513263209,,0,1
722,2017-12-15,2017,12,15,0,7jscz2,FluidDATA uses machine learning to make millions of audio files and videos searchable by phrase or mention,https://www.reddit.com/r/MachineLearning/comments/7jscz2/fluiddata_uses_machine_learning_to_make_millions/,nibbleshift,1513266146,[removed],0,2
723,2017-12-15,2017,12,15,0,7jsf0c,Help manipulating large datasets for CNNs,https://www.reddit.com/r/MachineLearning/comments/7jsf0c/help_manipulating_large_datasets_for_cnns/,TheFunkyPeanut,1513266676,[removed],0,1
724,2017-12-15,2017,12,15,2,7jswds,Have you ever seen such a training process? What's happening?,https://www.reddit.com/r/MachineLearning/comments/7jswds/have_you_ever_seen_such_a_training_process_whats/,borbag,1513270886,,1,1
725,2017-12-15,2017,12,15,2,7jt0wj,[D] Output variance of a deep CNN vanishes during training.,https://www.reddit.com/r/MachineLearning/comments/7jt0wj/d_output_variance_of_a_deep_cnn_vanishes_during/,_tomakko,1513271912,"I am working with a ~20 layer deep CNN whose output is a softmax over 3 classes. When I use a depth of 32 for all conv layer, i observe a smooth convergence to the expected output. 

However, when i only change the depth of all conv layers to 64, i observe the following: After initialization a reasonable amount  of variance in the outputs for different inputs is present. Then, during training the variance gradually vanishes, until it seems that only bias is learned. Apparently, the gradient w.r.t to the conv weights vanishes over time.

Does anything particular in the CNN architecture, the initialization or other things can make neural nets prone to such behavior?

",13,1
726,2017-12-15,2017,12,15,2,7jt43v,"With capsules being back in vogue recently, I thought I would share our work on disentangling transform dimensions from episodic data. This article gives a layman overview and a demo, and is followed by a more technical explanation.",https://www.reddit.com/r/MachineLearning/comments/7jt43v/with_capsules_being_back_in_vogue_recently_i/,GusRuss89,1513272646,,0,6
727,2017-12-15,2017,12,15,2,7jt6c4,"[R] Nintendo Super Smash Bros. Melee: An ""Untouchable"" Agent",https://www.reddit.com/r/MachineLearning/comments/7jt6c4/r_nintendo_super_smash_bros_melee_an_untouchable/,DolphinUser,1513273185,,6,1
728,2017-12-15,2017,12,15,3,7jto8k,"[D] Machine Learning 101 slidedeck: 2 years of headbanging, so you don't have to. (Source: Hackernews)",https://www.reddit.com/r/MachineLearning/comments/7jto8k/d_machine_learning_101_slidedeck_2_years_of/,sksq9,1513277207,,13,53
729,2017-12-15,2017,12,15,4,7jtxf9,What's the difference between a cost function and an error function?,https://www.reddit.com/r/MachineLearning/comments/7jtxf9/whats_the_difference_between_a_cost_function_and/,scorebysund,1513279254,[removed],0,1
730,2017-12-15,2017,12,15,4,7jtxsk,[N] Announcing free trials for IBM Spectrum Conductor Deep Learning Impact version 1.1,https://www.reddit.com/r/MachineLearning/comments/7jtxsk/n_announcing_free_trials_for_ibm_spectrum/,uncasripley,1513279332,"Hello /r/machinelearning,

I am one of the developers of **IBM Spectrum Conductor Deep Learning Impact**.  Since I am a frequent visitor here, I thought that some of you might be interested to learn more about and try out this new tool for deep learning.

Also,**if you have any questions about our motivations and challenges** for building an enterprise-class DL tool, **feel free to ask**.

Some of the offering highlights are: 

&gt; *  A distributed deep learning architecture that is transparent to the application developer
&gt; * Multitenant architecture for deep learning designed to run deep learning, high-performance analytics, and other long running services and frameworks on a common grid of shared resources
&gt; * Elastic, fine-grain resource allocation for deep learning workloads enables the addition and removal of resources from actively running, deep learning jobs
&gt; * Tool enhancements for data ingest, preparation, and transformation, leveraging Apache Spark as an Extract Transform Load (ETL) engine for data management
&gt; * Training visualization and runtime monitoring of accuracy and convergence
&gt; * Hyper-parameter search and optimization
&gt; * Integrated inference service to deploy models in production
&gt; * Leverages industry standard, open source, deep learning frameworks (Tensorflow and Caffe)


You can find all the information about getting started with the free trial here:
[http://www.ibm.biz/DeepLearningImpact](http://www.ibm.biz/DeepLearningImpact)

[Release Notes](https://www.ibm.com/support/knowledgecenter/SSWQ2D_1.1.0/gs/dli_release_notes.html) on IBM Knowledge Center

Thanks for your interest,

Uncas",3,1
731,2017-12-15,2017,12,15,4,7jtyeb,"The Biggest Advantage in Machine Learning Will Come From Superior Coverage, Not Superior Analysis",https://www.reddit.com/r/MachineLearning/comments/7jtyeb/the_biggest_advantage_in_machine_learning_will/,danielrm26,1513279462,,0,1
732,2017-12-15,2017,12,15,4,7ju4jv,Andrew Ng brings AI to Foxconn's Factories,https://www.reddit.com/r/MachineLearning/comments/7ju4jv/andrew_ng_brings_ai_to_foxconns_factories/,randcraw,1513280865,,0,1
733,2017-12-15,2017,12,15,5,7jue2n,logger for tensorboard,https://www.reddit.com/r/MachineLearning/comments/7jue2n/logger_for_tensorboard/,episodeyang,1513283077,,1,1
734,2017-12-15,2017,12,15,6,7jutjz,Starting a small series on implementing neural networks with functional programming in R,https://www.reddit.com/r/MachineLearning/comments/7jutjz/starting_a_small_series_on_implementing_neural/,Gumeo,1513286523,,0,2
735,2017-12-15,2017,12,15,6,7juyy6,[R] State-of-the-art Speech Recognition With Sequence-to-Sequence Models,https://www.reddit.com/r/MachineLearning/comments/7juyy6/r_stateoftheart_speech_recognition_with/,Jackal008,1513287818,,10,32
736,2017-12-15,2017,12,15,7,7jv426,[N] The year of machine-to-machine journalism,https://www.reddit.com/r/MachineLearning/comments/7jv426/n_the_year_of_machinetomachine_journalism/,spendology,1513289011,,0,1
737,2017-12-15,2017,12,15,7,7jv8st,[R] Gradient Boosting From Scratch  Simplifying a Complex Algorithm,https://www.reddit.com/r/MachineLearning/comments/7jv8st/r_gradient_boosting_from_scratch_simplifying_a/,nianhao,1513290175,,4,4
738,2017-12-15,2017,12,15,7,7jvew6,ML for finding properties,https://www.reddit.com/r/MachineLearning/comments/7jvew6/ml_for_finding_properties/,lolrealjobs,1513291729,[removed],0,1
739,2017-12-15,2017,12,15,8,7jvnqo,What games of bigger state than board-games is the game-tree well-defined for? aka a recognizer-function of 2 consecutive game-states,https://www.reddit.com/r/MachineLearning/comments/7jvnqo/what_games_of_bigger_state_than_boardgames_is_the/,[deleted],1513293851,,0,1
740,2017-12-15,2017,12,15,8,7jvo8x,Accumulation of sources from NIPS 2017,https://www.reddit.com/r/MachineLearning/comments/7jvo8x/accumulation_of_sources_from_nips_2017/,xelgana,1513293967,[removed],0,1
741,2017-12-15,2017,12,15,8,7jvqlo,[D] What games of bigger state than board-games is the game-tree well-defined for? aka a recognizer-function of 2 consecutive game-states,https://www.reddit.com/r/MachineLearning/comments/7jvqlo/d_what_games_of_bigger_state_than_boardgames_is/,[deleted],1513294478,[deleted],0,0
742,2017-12-15,2017,12,15,8,7jvsq7,Recommend me the cheapest GPU for ML,https://www.reddit.com/r/MachineLearning/comments/7jvsq7/recommend_me_the_cheapest_gpu_for_ml/,rodrigo-silveira,1513295349,[removed],0,1
743,2017-12-15,2017,12,15,10,7jwch8,Training using multiple features [Scikit Learn],https://www.reddit.com/r/MachineLearning/comments/7jwch8/training_using_multiple_features_scikit_learn/,[deleted],1513300644,,0,1
744,2017-12-15,2017,12,15,10,7jwemb,Training using multiple attributes [Scikit Learn],https://www.reddit.com/r/MachineLearning/comments/7jwemb/training_using_multiple_attributes_scikit_learn/,therealsyfer,1513301245,[removed],0,1
745,2017-12-15,2017,12,15,12,7jx5p8,T vn gip bn chn my git loi no tt nht dnh cho gia nh.,https://www.reddit.com/r/MachineLearning/comments/7jx5p8/t_vn_gip_bn_chn_my_git_loi_no_tt_nht/,vinhvu18,1513309242,,0,1
746,2017-12-15,2017,12,15,13,7jxbjc,Math primer for machine learning?,https://www.reddit.com/r/MachineLearning/comments/7jxbjc/math_primer_for_machine_learning/,IPA_slayer,1513311061,[removed],0,1
747,2017-12-15,2017,12,15,13,7jxjm4,Chicken manure fertilizer granules production line,https://www.reddit.com/r/MachineLearning/comments/7jxjm4/chicken_manure_fertilizer_granules_production_line/,amylee516,1513313689,,0,1
748,2017-12-15,2017,12,15,14,7jxly7,Why is it so important to have principled and mathematical theories for Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/7jxly7/why_is_it_so_important_to_have_principled_and/,real_charlie_parker,1513314451,,0,1
749,2017-12-15,2017,12,15,15,7jy3ga,The Best of the Machine Learning Algorithms Used in Artificial Intelligence | Arfa Software Technology Park,https://www.reddit.com/r/MachineLearning/comments/7jy3ga/the_best_of_the_machine_learning_algorithms_used/,titantwister,1513320744,,0,1
750,2017-12-15,2017,12,15,15,7jy3w1,[D] Scale of weights for weighted loss,https://www.reddit.com/r/MachineLearning/comments/7jy3w1/d_scale_of_weights_for_weighted_loss/,terrorlucid,1513320922,"Quick question. How would the scale of weights given to a weighted loss function (assume CrossEntropy) affect the performance of a standard classification task. Based on the imbalance in the dataset, we attain these weights. I'm asking for a simple scenario. Eg: Assume 5 classes are there. w1 is a set of weights obtained using some formula (eg: inverse of population)

w1 = [3, 34, 12, 100, 2]

w2 = w1 / min(w1)

w3 = w1 / max(w1)

This results in 

w2 = [  1.5,  17. ,   6. ,  50. ,   1. ]

w3 = [ 0.03,  0.34,  0.12,  1.  ,  0.02]

What effect will these 3 have? Which will work better and why?",2,2
751,2017-12-15,2017,12,15,16,7jy4me,Question from an uber driver,https://www.reddit.com/r/MachineLearning/comments/7jy4me/question_from_an_uber_driver/,[deleted],1513321227,,0,1
752,2017-12-15,2017,12,15,16,7jy69u,"xLearn: Library useful for solving machine learning problems on large-scale sparse data (liblinear, libfm or libffm)",https://www.reddit.com/r/MachineLearning/comments/7jy69u/xlearn_library_useful_for_solving_machine/,Wolf_of_Valyria,1513321865,,0,1
753,2017-12-15,2017,12,15,17,7jydlq,"What is Python Machine Learning and how to learn it? Python has become the de facto programming language of data scientists and data analysts in the field of Machine Learning and Data Science. We will also look at Python libraries like NumPy, Pandas, and SciKit-Learn.",https://www.reddit.com/r/MachineLearning/comments/7jydlq/what_is_python_machine_learning_and_how_to_learn/,MCAL_Training,1513325064,,0,1
754,2017-12-15,2017,12,15,18,7jylj6,Phd-level courses,https://www.reddit.com/r/MachineLearning/comments/7jylj6/phdlevel_courses/,[deleted],1513328730,,0,1
755,2017-12-15,2017,12,15,18,7jym1a,"Brad Carlin, the Imposteriors band member who made a joke about sexual assault at @NipsConference to an audience of ~1,000 people, posted an apology on the band's facebook page.",https://www.reddit.com/r/MachineLearning/comments/7jym1a/brad_carlin_the_imposteriors_band_member_who_made/,Hizachi,1513328948,,0,1
756,2017-12-15,2017,12,15,18,7jyq51,Evolution of the first layer of an MLP learning mnist,https://www.reddit.com/r/MachineLearning/comments/7jyq51/evolution_of_the_first_layer_of_an_mlp_learning/,[deleted],1513330885,[deleted],1,1
757,2017-12-15,2017,12,15,18,7jyqha,[P] Evolution of the weights in the first hidden layer of an MLP learning mnist.,https://www.reddit.com/r/MachineLearning/comments/7jyqha/p_evolution_of_the_weights_in_the_first_hidden/,Gumeo,1513331050,,48,260
758,2017-12-15,2017,12,15,19,7jyuow,NASA uses Google machine learning for exoplanet detection,https://www.reddit.com/r/MachineLearning/comments/7jyuow/nasa_uses_google_machine_learning_for_exoplanet/,mr_j_b,1513332862,,0,1
759,2017-12-15,2017,12,15,19,7jz0ah,List of 200 ML Conferences in 2018,https://www.reddit.com/r/MachineLearning/comments/7jz0ah/list_of_200_ml_conferences_in_2018/,spicy76,1513335342,,0,1
760,2017-12-15,2017,12,15,22,7jzl12,[D] E pur si muove - Sam Altman's blogpost relevant to recent discussions in /r/ml,https://www.reddit.com/r/MachineLearning/comments/7jzl12/d_e_pur_si_muove_sam_altmans_blogpost_relevant_to/,sour_losers,1513343289,,13,0
761,2017-12-15,2017,12,15,22,7jzo7y,[N] Key Machine Learning annoucements at AWS re:Invent '17,https://www.reddit.com/r/MachineLearning/comments/7jzo7y/n_key_machine_learning_annoucements_at_aws/,polllyyy,1513344351,,0,1
762,2017-12-15,2017,12,15,23,7jzw5i,How does AlphaGo Zero learn based off its loss function? I don't understand how the choice of loss function would lead to it becoming better at the game. Paper linked.,https://www.reddit.com/r/MachineLearning/comments/7jzw5i/how_does_alphago_zero_learn_based_off_its_loss/,Pawnbrake,1513346841,,0,1
763,2017-12-15,2017,12,15,23,7jzyef,[P] Managing our budget with Excel and machine learning,https://www.reddit.com/r/MachineLearning/comments/7jzyef/p_managing_our_budget_with_excel_and_machine/,Dutchcheesehead,1513347478,,0,0
764,2017-12-16,2017,12,16,0,7k0fa4,AI Weekly 15 Dec 2017,https://www.reddit.com/r/MachineLearning/comments/7k0fa4/ai_weekly_15_dec_2017/,TomekB,1513352292,,0,1
765,2017-12-16,2017,12,16,1,7k0mg5,Questions regarding Andrew Ng ML course on coursera,https://www.reddit.com/r/MachineLearning/comments/7k0mg5/questions_regarding_andrew_ng_ml_course_on/,[deleted],1513354089,,0,1
766,2017-12-16,2017,12,16,1,7k0mjw,gtx 980 vs 1060 for machine learning in 2018,https://www.reddit.com/r/MachineLearning/comments/7k0mjw/gtx_980_vs_1060_for_machine_learning_in_2018/,darshanbaid22,1513354111,[removed],0,1
767,2017-12-16,2017,12,16,1,7k0r1p,[D] Where can I find easy-to-read analyses of research papers?,https://www.reddit.com/r/MachineLearning/comments/7k0r1p/d_where_can_i_find_easytoread_analyses_of/,lebron_lamase,1513355227,I'm looking for blogs of sorts where people have read the complete papers and post their analysis of them which is easy to skim and decide whether I want to dive in to the actual paper.,24,6
768,2017-12-16,2017,12,16,2,7k10h0,ChemNet: A Transferable and Generalizable Deep Neural Network for Small-Molecule Property Prediction,https://www.reddit.com/r/MachineLearning/comments/7k10h0/chemnet_a_transferable_and_generalizable_deep/,johnmountain,1513357547,,0,1
769,2017-12-16,2017,12,16,2,7k11c0,5 key take-aways from Big Data Spain 2017,https://www.reddit.com/r/MachineLearning/comments/7k11c0/5_key_takeaways_from_big_data_spain_2017/,k_smith182,1513357749,,0,1
770,2017-12-16,2017,12,16,2,7k12vz,Top 20 Amazon Books for Artificial Intelligence &amp; Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7k12vz/top_20_amazon_books_for_artificial_intelligence/,favouriteblog,1513358139,,1,1
771,2017-12-16,2017,12,16,3,7k1ggt,Hardware for machine learning?,https://www.reddit.com/r/MachineLearning/comments/7k1ggt/hardware_for_machine_learning/,Bok101,1513361409,[removed],0,1
772,2017-12-16,2017,12,16,3,7k1p27,What I learned by studying fake news sites with machine learning,https://www.reddit.com/r/MachineLearning/comments/7k1p27/what_i_learned_by_studying_fake_news_sites_with/,[deleted],1513363537,[deleted],0,1
773,2017-12-16,2017,12,16,4,7k1spf,[P] What I learned by studying fake news sites with simple machine learning,https://www.reddit.com/r/MachineLearning/comments/7k1spf/p_what_i_learned_by_studying_fake_news_sites_with/,nikrgian,1513364432,,31,86
774,2017-12-16,2017,12,16,4,7k1thg,How does AlphaGo Zero learn based off its loss function? I don't understand how the choice of loss function would lead to it becoming better at the game.,https://www.reddit.com/r/MachineLearning/comments/7k1thg/how_does_alphago_zero_learn_based_off_its_loss/,Pawnbrake,1513364627,[removed],0,1
775,2017-12-16,2017,12,16,4,7k1xc7,Machine Learning Jump Start Course by MachineLabs,https://www.reddit.com/r/MachineLearning/comments/7k1xc7/machine_learning_jump_start_course_by_machinelabs/,cburgdorf,1513365597,,0,1
776,2017-12-16,2017,12,16,6,7k2nwd,[R] Super-Convergence: Very Fast Training of Residual Networks Using Large Learning Rates,https://www.reddit.com/r/MachineLearning/comments/7k2nwd/r_superconvergence_very_fast_training_of_residual/,visarga,1513372357,,11,28
777,2017-12-16,2017,12,16,6,7k2of3,"[Discussion] How does AlphaGo Zero learn based off its loss function? Help me understand how the AlpaGo Zero method promotes learning games such as Chess, Go, and Shogi.",https://www.reddit.com/r/MachineLearning/comments/7k2of3/discussion_how_does_alphago_zero_learn_based_off/,Pawnbrake,1513372497,"AlphaGo Zero paper here: https://www.gwern.net/docs/rl/2017-silver.pdf

I understand how AlphaGo Zero chooses its moves, it uses its policy network to guide a Monte Carlo Simulation, and then it evaluates the ends (leaves) of each node. Then it finds a way to average the evaluations to choose a move.

What I don't understand is what method they use for learning.  How do they mark whether the policy chose the correct paths in the Monte Carlo simulation?  Why did they chose the loss function they did? (Page 355)",13,24
778,2017-12-16,2017,12,16,6,7k2r0j,[D] What concepts have you had the most trouble with incorporating into your intuition ?,https://www.reddit.com/r/MachineLearning/comments/7k2r0j/d_what_concepts_have_you_had_the_most_trouble/,SGuptMachineLearning,1513373182,,50,29
779,2017-12-16,2017,12,16,6,7k2t7o,[R] [1711.03189] Deep Hyperspherical Learning,https://www.reddit.com/r/MachineLearning/comments/7k2t7o/r_171103189_deep_hyperspherical_learning/,bobchennan,1513373720,,1,7
780,2017-12-16,2017,12,16,6,7k2udd,[D] Architecture Dataset?,https://www.reddit.com/r/MachineLearning/comments/7k2udd/d_architecture_dataset/,beef__,1513374034,"I'm looking for literally any dataset that has anything to do with buildings or architectural design...

Preferably something that could be used to ""generate"" building designs (through an auto-encoder, GAN, etc), or at least visualizations of buildings 


maybe there's a dataset similar to google's quickdraw dataset where it's just like, pen strokes or something - but specific to buildings and a little more detailed?
",5,1
781,2017-12-16,2017,12,16,6,7k2upa,Trying to figure out best ANN approach for my data,https://www.reddit.com/r/MachineLearning/comments/7k2upa/trying_to_figure_out_best_ann_approach_for_my_data/,Case44,1513374138,[removed],0,1
782,2017-12-16,2017,12,16,6,7k2y9m,"An introduction to mapper, multiscale mapper, and TDA.",https://www.reddit.com/r/MachineLearning/comments/7k2y9m/an_introduction_to_mapper_multiscale_mapper_and/,[deleted],1513375110,[deleted],0,1
783,2017-12-16,2017,12,16,7,7k2zsy,How Banks &amp; Regulators are Applying Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7k2zsy/how_banks_regulators_are_applying_machine_learning/,elena-mesropyan,1513375493,,0,1
784,2017-12-16,2017,12,16,7,7k2zx6,'Locking' variables in an autoencoder,https://www.reddit.com/r/MachineLearning/comments/7k2zx6/locking_variables_in_an_autoencoder/,Zman420,1513375526,[removed],0,1
785,2017-12-16,2017,12,16,8,7k3c8u,"Does this simple program count as ""machine learning""?",https://www.reddit.com/r/MachineLearning/comments/7k3c8u/does_this_simple_program_count_as_machine_learning/,markmore679,1513378897,[removed],0,1
786,2017-12-16,2017,12,16,8,7k3ftq,The Unreasonable Effectiveness of Structure - Probabilistic soft logic - Lise Getoor - NIPS 2017,https://www.reddit.com/r/MachineLearning/comments/7k3ftq/the_unreasonable_effectiveness_of_structure/,ecodemo,1513379922,,0,1
787,2017-12-16,2017,12,16,8,7k3fup,What is Deep Learning? An Introduction to Deep Learning,https://www.reddit.com/r/MachineLearning/comments/7k3fup/what_is_deep_learning_an_introduction_to_deep/,sachindean,1513379932,,0,1
788,2017-12-16,2017,12,16,9,7k3og4,"[P] An introduction to mapper, multiscale mapper, and TDA [X-post /r/math]",https://www.reddit.com/r/MachineLearning/comments/7k3og4/p_an_introduction_to_mapper_multiscale_mapper_and/,NatSa9000,1513382417,,6,26
789,2017-12-16,2017,12,16,9,7k3tgf,[R] Visual to Sound: Generating Natural Sound for Videos in the Wild,https://www.reddit.com/r/MachineLearning/comments/7k3tgf/r_visual_to_sound_generating_natural_sound_for/,zergling103,1513383922,,3,7
790,2017-12-16,2017,12,16,9,7k3vy4,Signed Nvidia TITAN V from NIPS2017 on ebay!,https://www.reddit.com/r/MachineLearning/comments/7k3vy4/signed_nvidia_titan_v_from_nips2017_on_ebay/,ieee8023,1513384699,,0,1
791,2017-12-16,2017,12,16,12,7k4suf,Earth to exoplanet: Hunting for planets with machine learning,https://www.reddit.com/r/MachineLearning/comments/7k4suf/earth_to_exoplanet_hunting_for_planets_with/,strengar,1513395228,,0,1
792,2017-12-16,2017,12,16,12,7k4u4x,[P] aleju/imgaug - a extensive image augmentation library with support for bounding boxes and keypoints,https://www.reddit.com/r/MachineLearning/comments/7k4u4x/p_alejuimgaug_a_extensive_image_augmentation/,[deleted],1513395698,[deleted],0,1
793,2017-12-16,2017,12,16,12,7k4u8j,[P] aleju/imgaug - an extensive image augmentation library with support for bounding boxes and keypoints,https://www.reddit.com/r/MachineLearning/comments/7k4u8j/p_alejuimgaug_an_extensive_image_augmentation/,wassname,1513395738,,6,27
794,2017-12-16,2017,12,16,14,7k59k6,Learning machine learning,https://www.reddit.com/r/MachineLearning/comments/7k59k6/learning_machine_learning/,kirashady,1513401300,[removed],0,1
795,2017-12-16,2017,12,16,14,7k59ka,[N] Google AI Researcher Accused of Sexual Harassment,https://www.reddit.com/r/MachineLearning/comments/7k59ka/n_google_ai_researcher_accused_of_sexual/,baylearn,1513401301,,195,168
796,2017-12-16,2017,12,16,14,7k5ce2,Les Formateurs Agr&amp;eacute;&amp;eacute;s du CNFPI - Organisme de formation national - cnfpi,https://www.reddit.com/r/MachineLearning/comments/7k5ce2/les_formateurs_agreacuteeacutes_du_cnfpi/,imogeneooroswel,1513402379,,0,1
797,2017-12-16,2017,12,16,14,7k5d45,Introduction of Automatic Speech Recognition,https://www.reddit.com/r/MachineLearning/comments/7k5d45/introduction_of_automatic_speech_recognition/,munishmaxtech,1513402660,,0,1
798,2017-12-16,2017,12,16,14,7k5dpg,"Tensorflow implementation of the ""Order-Planning Neural Text Generation From Structured Data""",https://www.reddit.com/r/MachineLearning/comments/7k5dpg/tensorflow_implementation_of_the_orderplanning/,akanimax,1513402881,,0,2
799,2017-12-16,2017,12,16,15,7k5k8x,Is anyone doing work on general prediction-based unsupervised learning algorithms?,https://www.reddit.com/r/MachineLearning/comments/7k5k8x/is_anyone_doing_work_on_general_predictionbased/,PlentifulCoast,1513405609,[removed],0,1
800,2017-12-16,2017,12,16,18,7k63h3,AI project by Google,https://www.reddit.com/r/MachineLearning/comments/7k63h3/ai_project_by_google/,lokeshreddy0007,1513414912,,0,1
801,2017-12-16,2017,12,16,19,7k6dq5,A Quick Guide to Identify Twitterbots Using AI,https://www.reddit.com/r/MachineLearning/comments/7k6dq5/a_quick_guide_to_identify_twitterbots_using_ai/,shashankg22,1513420300,,0,1
802,2017-12-16,2017,12,16,20,7k6int,[D] How do you obfuscate your model before sending to client for inference?,https://www.reddit.com/r/MachineLearning/comments/7k6int/d_how_do_you_obfuscate_your_model_before_sending/,zachmoshe,1513422886,"Only relevant to use-cases where the inference runs on the device itself (mobile/browser).

If we send the client (through an API or in the APK) the model file as a 'pb' for example, we expose both the architecture and the trained weights.
I understand that any logic that is running on the client side is exposed by definition but wondering whether there are best practices to mitigate this risk?  (like uglify/obfuscation to JS code sent to browser)",37,44
803,2017-12-16,2017,12,16,20,7k6kbt,Yolo and yolo9000 class predictions,https://www.reddit.com/r/MachineLearning/comments/7k6kbt/yolo_and_yolo9000_class_predictions/,[deleted],1513423783,,0,1
804,2017-12-16,2017,12,16,20,7k6nhk,[D] Yolo and yolo9000 class predictions,https://www.reddit.com/r/MachineLearning/comments/7k6nhk/d_yolo_and_yolo9000_class_predictions/,roar363,1513425423,"I am trying to understand yolo (https://arxiv.org/abs/1506.02640) and have some confusion over the final class predictions. The original paper and presentation by the author (https://www.youtube.com/watch?v=NM6lrxy0bxs) says ""We only predict one set of class probabilities per grid cell, regardless of the number of boxes B."" However Andrew Ng's CNN course (https://www.coursera.org/learn/convolutional-neural-networks/lecture/fF3O0/yolo-algorithm) and Siraj Raval's video (https://www.youtube.com/watch?v=4eIBisqx9_g) say we predict a set of class probabilities for each bounding box. Has anyone come across this? Why the disparity? Which approach is actually used/which is better?",0,1
805,2017-12-16,2017,12,16,22,7k6z6u,[1711.00549] ML Systems Paper: Alexa Skills Kit and Amazon Lex,https://www.reddit.com/r/MachineLearning/comments/7k6z6u/171100549_ml_systems_paper_alexa_skills_kit_and/,torvoraptor,1513430620,,0,1
806,2017-12-17,2017,12,17,0,7k7m7i,"[D] DataSelfie, predict your personality treats the way FB does it ? (using ML+NPL.)",https://www.reddit.com/r/MachineLearning/comments/7k7m7i/d_dataselfie_predict_your_personality_treats_the/,swentso,1513438759,,0,17
807,2017-12-17,2017,12,17,1,7k7qdj,My list of ~20 selected deep learning papers of the year.,https://www.reddit.com/r/MachineLearning/comments/7k7qdj/my_list_of_20_selected_deep_learning_papers_of/,KloudStrife_ML,1513440065,,0,1
808,2017-12-17,2017,12,17,1,7k7rjr,Thoughts on licencing,https://www.reddit.com/r/MachineLearning/comments/7k7rjr/thoughts_on_licencing/,maybelator,1513440411,[removed],0,1
809,2017-12-17,2017,12,17,2,7k84q7,"[R] VALIS, Vote ALlocating Immune System",https://www.reddit.com/r/MachineLearning/comments/7k84q7/r_valis_vote_allocating_immune_system/,-inversed-,1513444183,,5,20
810,2017-12-17,2017,12,17,2,7k86x6,[D] Intuitive explanation of autoregressive and normalizing flows?,https://www.reddit.com/r/MachineLearning/comments/7k86x6/d_intuitive_explanation_of_autoregressive_and/,pupi1,1513444781,"Can someone give a brief intuitive explanation of the idea for Normalizing Flows (Rezende and Mohamed) and associated papers?

What I understand, this approach sets up an _invertable_ series of transformations, resulting that the probability density can be calculated as it is transformed by each step. Ok with that.

What I do not understand is the motivation. The paper says that it wants to give more expressive posteriors that better match the true posterior.  

Several confusions about this:  

1. Why is it necessary? Deep nets are powerful and should be able to transform an input distribution to a desired latent distribution (e.g. the normal distribution in VAE) if given enough layers. 

2. The term ""true posterior"" confuses me! As far as I know, the prior can be specified arbitrarily, and this changes the posterior. Why is there one posterior that is ""true"" and others are not?
I fear I do not know what posterior means, at least in this situation. ",11,11
811,2017-12-17,2017,12,17,2,7k87bx,extracting patterns from events,https://www.reddit.com/r/MachineLearning/comments/7k87bx/extracting_patterns_from_events/,sharanbr,1513444885,[removed],0,1
812,2017-12-17,2017,12,17,2,7k8bqz,Extracting event patterns in a system,https://www.reddit.com/r/MachineLearning/comments/7k8bqz/extracting_event_patterns_in_a_system/,sharanbr,1513446180,[removed],0,1
813,2017-12-17,2017,12,17,5,7k97qz,Difference between A2C and A3C in reinforcement learning?,https://www.reddit.com/r/MachineLearning/comments/7k97qz/difference_between_a2c_and_a3c_in_reinforcement/,ashboy64,1513455116,[removed],0,1
814,2017-12-17,2017,12,17,6,7k9krb,What are some novel/unique applications of Machine Learning in Electrical Engineering?,https://www.reddit.com/r/MachineLearning/comments/7k9krb/what_are_some_novelunique_applications_of_machine/,[deleted],1513458764,,0,1
815,2017-12-17,2017,12,17,6,7k9n6t,[D] What are some novel/unique applications of Machine Learning in Electrical Engineering?,https://www.reddit.com/r/MachineLearning/comments/7k9n6t/d_what_are_some_novelunique_applications_of/,mad_runner,1513459463,"Most of the literature in ML that I've come across has been heavily based in either Computer Vision, Robotics1 or NLP. Are there any other lesser known, but really exciting applications of Machine Learning in Electrical Engineering, currently being researched? Some examples would be designing chips, circuits or control algorithms (not robotics based).",25,20
816,2017-12-17,2017,12,17,6,7k9pjb,GPU Benchmarks for Maximum Cloud Efficiency in Deep Learning,https://www.reddit.com/r/MachineLearning/comments/7k9pjb/gpu_benchmarks_for_maximum_cloud_efficiency_in/,blowjobtransistor,1513460106,,0,1
817,2017-12-17,2017,12,17,7,7k9vew,Bacteria Use Brainlike Bursts of Electricity to Communicate | Quanta Magazine,https://www.reddit.com/r/MachineLearning/comments/7k9vew/bacteria_use_brainlike_bursts_of_electricity_to/,phobrain,1513461749,,1,1
818,2017-12-17,2017,12,17,7,7k9vr8,[R] Mathematics of Deep Learning,https://www.reddit.com/r/MachineLearning/comments/7k9vr8/r_mathematics_of_deep_learning/,zhamisen,1513461856,,36,197
819,2017-12-17,2017,12,17,7,7k9y54,[D] Generating dataset using street view images for commercial use,https://www.reddit.com/r/MachineLearning/comments/7k9y54/d_generating_dataset_using_street_view_images_for/,ssivri,1513462518,I have a project idea but I'm wondering how can I acquire street view panoramas without violating terms of use. Anyone came across similar situation ?,3,6
820,2017-12-17,2017,12,17,8,7kaby5,[R] MentorNet: Regularizing Very Deep Neural Networks on Corrupted Labels,https://www.reddit.com/r/MachineLearning/comments/7kaby5/r_mentornet_regularizing_very_deep_neural/,xternalz,1513466472,,27,2
821,2017-12-17,2017,12,17,8,7kac3n,[D] Benefits of quantizing and one-hot-encoding continous variables,https://www.reddit.com/r/MachineLearning/comments/7kac3n/d_benefits_of_quantizing_and_onehotencoding/,[deleted],1513466522,[deleted],1,1
822,2017-12-17,2017,12,17,8,7kaiti,Join Front end Slack community 760+ members,https://www.reddit.com/r/MachineLearning/comments/7kaiti/join_front_end_slack_community_760_members/,frontje,1513468583,[removed],0,1
823,2017-12-17,2017,12,17,9,7kare4,"[D] Generalization Theory and Deep Nets, An introduction",https://www.reddit.com/r/MachineLearning/comments/7kare4/d_generalization_theory_and_deep_nets_an/,sksq9,1513471191,,0,17
824,2017-12-17,2017,12,17,13,7kbvdq,What is Machine Translation,https://www.reddit.com/r/MachineLearning/comments/7kbvdq/what_is_machine_translation/,munishmaxtech,1513484716,,0,1
825,2017-12-17,2017,12,17,13,7kbvtf,[D] Where is the underlying graph of Google Maps?,https://www.reddit.com/r/MachineLearning/comments/7kbvtf/d_where_is_the_underlying_graph_of_google_maps/,Musashi1113,1513484878,"Well, I want to use Google Maps as a way to try out graph-related algoriths given a real-world scenario. Like using a subset of a Minimum Spanning Tree to create a set of shortest path given a source point, etc. I looked at Google's API but it doesn't provide the underlying Data Structure. Does anyone know how to use it? Is it even allowed to be used? If not, what are other options? I just wanna play with it.",6,0
826,2017-12-17,2017,12,17,14,7kc2vm,Any known terrorist data set for training?,https://www.reddit.com/r/MachineLearning/comments/7kc2vm/any_known_terrorist_data_set_for_training/,[deleted],1513487517,,0,1
827,2017-12-17,2017,12,17,15,7kcbi9,[D] Can neural networks be automatically translated to machine code?,https://www.reddit.com/r/MachineLearning/comments/7kcbi9/d_can_neural_networks_be_automatically_translated/,normally_i_lurk,1513491060,"I was just thinking: is it possible to convert a fully trained neural network into code (assembly, python, C, whatever)? I'm not talking about a network that learns to write code, but rather a closed-form solution to convert the final, trained model into a presumably faster-to-run format. The idea being that a compiler could optimize the end result so that it runs more efficiently and takes full advantage of the underlying architecture (mobile vs PC, etc). To me it seems that from a mathematical standpoint it's simply a matter of abstraction - the function maps input to output in a specific way, but the implementation doesn't really matter.  I couldn't find any resources on this idea, but I'd be interested to know if such a task would need to be performed by a trained model or if it's feasible to do manually.",11,1
828,2017-12-17,2017,12,17,17,7kcv0u,Benchmarking Modern GPUs for Maximum Cloud Cost Efficiency in Deep Learning,https://www.reddit.com/r/MachineLearning/comments/7kcv0u/benchmarking_modern_gpus_for_maximum_cloud_cost/,Bardelaz,1513500628,,0,1
829,2017-12-17,2017,12,17,19,7kd5mo,Framework for selection of Deep Learning Architectures?,https://www.reddit.com/r/MachineLearning/comments/7kd5mo/framework_for_selection_of_deep_learning/,manueslapera,1513506536,[removed],0,1
830,2017-12-17,2017,12,17,19,7kd85l,Visual to Sound: Generating Natural Sound for Videos in the Wild,https://www.reddit.com/r/MachineLearning/comments/7kd85l/visual_to_sound_generating_natural_sound_for/,savan77,1513507975,,0,1
831,2017-12-17,2017,12,17,20,7kd9d2,Auto Equalizing Audiobooks,https://www.reddit.com/r/MachineLearning/comments/7kd9d2/auto_equalizing_audiobooks/,KaineScienceman,1513508613,[removed],0,1
832,2017-12-17,2017,12,17,21,7kdj1y,New YouTube channel on Machine Learning.,https://www.reddit.com/r/MachineLearning/comments/7kdj1y/new_youtube_channel_on_machine_learning/,tr1pzz,1513513529,[removed],0,1
833,2017-12-17,2017,12,17,22,7kdony,[P] Machine Learning Cheatsheet,https://www.reddit.com/r/MachineLearning/comments/7kdony/p_machine_learning_cheatsheet/,Bhima,1513516067,,12,29
834,2017-12-17,2017,12,17,23,7kdyly,Top 10 best Machine Learning video tutorials,https://www.reddit.com/r/MachineLearning/comments/7kdyly/top_10_best_machine_learning_video_tutorials/,vickyroy576,1513519978,,0,1
835,2017-12-18,2017,12,18,1,7kepnk,Is the basic fully connected neural network the answer to every problem?,https://www.reddit.com/r/MachineLearning/comments/7kepnk/is_the_basic_fully_connected_neural_network_the/,akanimax,1513528567,"For language and text based problems, solutions based on RNNs have been the most prominent ones. Especially the Encoder-Decoder based RNNs (variants) with attention are currently the SOTA for almost all language based tasks. 

I recently came across this research work -&gt; https://arxiv.org/abs/1705.03122 where an architecture that only comprises of convolutions has surpassed the RNN based architectures. 

Now, a convNet is indeed a fully connected network with constraint of neurons in the same layer sharing weights. Would it be possible to construct a huge fully connected network that could match the performance of this convolutional seq2seq? Are we moving from complexity towards simplicity? Are there any more subtle intricacies involved here that I am oblivious to? 

I would like to know what you guys think about it.",11,0
836,2017-12-18,2017,12,18,1,7kerrg,[P] AI that can solve any Sudoku puzzle (no training data required),https://www.reddit.com/r/MachineLearning/comments/7kerrg/p_ai_that_can_solve_any_sudoku_puzzle_no_training/,zthoutt,1513529159,,19,0
837,2017-12-18,2017,12,18,2,7kf3o7,Introductory Machine Learning Course - Yaser Abu-Mostafa,https://www.reddit.com/r/MachineLearning/comments/7kf3o7/introductory_machine_learning_course_yaser/,yildiz17,1513532391,,0,1
838,2017-12-18,2017,12,18,3,7kffet,"Is Edward the best probabilistic programming language out there? The other one I found is pyro but, honestly I find pyro documentation very unreadable.",https://www.reddit.com/r/MachineLearning/comments/7kffet/is_edward_the_best_probabilistic_programming/,[deleted],1513535539,,0,1
839,2017-12-18,2017,12,18,3,7kfigp,"Is Edward the best probabilistic programming language out there? The other one I found is pyro but, honestly I find pyro documentation very unreadable.",https://www.reddit.com/r/MachineLearning/comments/7kfigp/is_edward_the_best_probabilistic_programming/,Mr__Christian_Grey,1513536335,[removed],0,1
840,2017-12-18,2017,12,18,3,7kfkap,An Algorithm for When To Try New Things,https://www.reddit.com/r/MachineLearning/comments/7kfkap/an_algorithm_for_when_to_try_new_things/,goldenorbspider,1513536821,,0,1
841,2017-12-18,2017,12,18,4,7kfxz5,[D] Entry level papers?,https://www.reddit.com/r/MachineLearning/comments/7kfxz5/d_entry_level_papers/,GreatBlitz,1513540507,"I'm a high school student (Grade 11) who has been studying ML from the Andrew Ng course for the past month or so. Are there any (please recommend 3-5, so that if I get stuck really badly with one, I can switch through, but hopefully you guys know papers which aren't that hard) entry level, but still good and meaningful research papers in the field of ML and deep learning/NN? I'm still a high school student, so I might find them fairly difficult to grasp, but hopefully with your help I can make it through. I really want to read a proper research paper, and know what innovations are actually taking place in the field, not simply learn from a course and apply. I'll be reading them in the summer of 2018, by when Iwill have finished the Andrew Ng course and tried out a few projects of my own. One of the papers i found was this:

http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf

Dropout: a simple way to prevent neural networks from overfitting, by Hinton, G.E., Krizhevsky, A., Srivastava, N., Sutskever, I., &amp; Salakhutdinov, R. (2014)

An initial reading of the first few pages didn't seem too difficult, but I haven't made it into the math parts yet.

Also, I really enjoy math so let math not be too strong a deterrent. Sure, really advanced math will go over my head, but things like matrices, vectors, basic-intermediate calculus, partial derivatives etc are all cool.

Thanks a lot!",51,78
842,2017-12-18,2017,12,18,5,7kg2is,Where can I learn what all these Greek letters are in ML notation?,https://www.reddit.com/r/MachineLearning/comments/7kg2is/where_can_i_learn_what_all_these_greek_letters/,[deleted],1513541682,,0,1
843,2017-12-18,2017,12,18,6,7kgcqr,[D] Machine Learning - WAYR (What Are You Reading) - Week 38,https://www.reddit.com/r/MachineLearning/comments/7kgcqr/d_machine_learning_wayr_what_are_you_reading_week/,ML_WAYR_bot,1513544405,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|31-40|
|----|-----|-----|-----|
|[Week 1](https://www.reddit.com/r/MachineLearning/comments/4qyjiq/machine_learning_wayr_what_are_you_reading_week_1/)|[Week 11](https://www.reddit.com/r/MachineLearning/comments/57xw56/discussion_machine_learning_wayr_what_are_you/)|[Week 21](https://www.reddit.com/r/MachineLearning/comments/60ildf/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 31](https://www.reddit.com/r/MachineLearning/comments/6s0k1u/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 2](https://www.reddit.com/r/MachineLearning/comments/4s2xqm/machine_learning_wayr_what_are_you_reading_week_2/)|[Week 12](https://www.reddit.com/r/MachineLearning/comments/5acb1t/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 22](https://www.reddit.com/r/MachineLearning/comments/64jwde/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 32](https://www.reddit.com/r/MachineLearning/comments/72ab5y/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 3](https://www.reddit.com/r/MachineLearning/comments/4t7mqm/machine_learning_wayr_what_are_you_reading_week_3/)|[Week 13](https://www.reddit.com/r/MachineLearning/comments/5cwfb6/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 23](https://www.reddit.com/r/MachineLearning/comments/674331/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 33](https://www.reddit.com/r/MachineLearning/comments/75405d/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 4](https://www.reddit.com/r/MachineLearning/comments/4ub2kw/machine_learning_wayr_what_are_you_reading_week_4/)|[Week 14](https://www.reddit.com/r/MachineLearning/comments/5fc5mh/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 24](https://www.reddit.com/r/MachineLearning/comments/68hhhb/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 34](https://www.reddit.com/r/MachineLearning/comments/782js9/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 5](https://www.reddit.com/r/MachineLearning/comments/4xomf7/machine_learning_wayr_what_are_you_reading_week_5/)|[Week 15](https://www.reddit.com/r/MachineLearning/comments/5hy4ur/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 25](https://www.reddit.com/r/MachineLearning/comments/69teiz/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 35](https://www.reddit.com/r/MachineLearning/comments/7b0av0/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 6](https://www.reddit.com/r/MachineLearning/comments/4zcyvk/machine_learning_wayr_what_are_you_reading_week_6/)|[Week 16](https://www.reddit.com/r/MachineLearning/comments/5kd6vd/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 26](https://www.reddit.com/r/MachineLearning/comments/6d7nb1/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 36](https://www.reddit.com/r/MachineLearning/comments/7e3fx6/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 7](https://www.reddit.com/r/MachineLearning/comments/52t6mo/machine_learning_wayr_what_are_you_reading_week_7/)|[Week 17](https://www.reddit.com/r/MachineLearning/comments/5ob7dx/discussion_machine_learning_wayr_what_are_you/)|[Week 27](https://www.reddit.com/r/MachineLearning/comments/6gngwc/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 37](https://www.reddit.com/r/MachineLearning/comments/7hcc2c/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 8](https://www.reddit.com/r/MachineLearning/comments/53heol/machine_learning_wayr_what_are_you_reading_week_8/)|[Week 18](https://www.reddit.com/r/MachineLearning/comments/5r14yd/discussion_machine_learning_wayr_what_are_you/)|[Week 28](https://www.reddit.com/r/MachineLearning/comments/6jgdva/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 9](https://www.reddit.com/r/MachineLearning/comments/54kvsu/machine_learning_wayr_what_are_you_reading_week_9/)|[Week 19](https://www.reddit.com/r/MachineLearning/comments/5tt9cz/discussion_machine_learning_wayr_what_are_you/)|[Week 29](https://www.reddit.com/r/MachineLearning/comments/6m9l1v/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 10](https://www.reddit.com/r/MachineLearning/comments/56s2oa/discussion_machine_learning_wayr_what_are_you/)|[Week 20](https://www.reddit.com/r/MachineLearning/comments/5wh2wb/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 30](https://www.reddit.com/r/MachineLearning/comments/6p3ha7/d_machine_learning_wayr_what_are_you_reading_week/)||

Most upvoted papers two weeks ago:

/u/PM_ME_PESTO: [Fairness Through Awareness (2011)](https://arxiv.org/abs/1104.3913)

/u/needlzor: [Statistical Comparison of Classifiers over Multiple Datasets](http://www.jmlr.org/papers/v7/demsar06a.html)

Besides that, there are no rules, have fun.",27,9
844,2017-12-18,2017,12,18,6,7kgg8p,Can machine learning be used to help solve AI safety problems?,https://www.reddit.com/r/MachineLearning/comments/7kgg8p/can_machine_learning_be_used_to_help_solve_ai/,182637777,1513545325,[removed],0,1
845,2017-12-18,2017,12,18,6,7kgmbc,[D] My DL papers of the year,https://www.reddit.com/r/MachineLearning/comments/7kgmbc/d_my_dl_papers_of_the_year/,programmerChilli,1513546933,,13,63
846,2017-12-18,2017,12,18,7,7kguxe,"Is it correct to talk about ""preventing overfitting"" when talking about dropout?",https://www.reddit.com/r/MachineLearning/comments/7kguxe/is_it_correct_to_talk_about_preventing/,tziki,1513549248,[removed],0,1
847,2017-12-18,2017,12,18,7,7kgw2v,Introduction to Neural Networks and its application in Predictive Analytics,https://www.reddit.com/r/MachineLearning/comments/7kgw2v/introduction_to_neural_networks_and_its/,sachindean,1513549562,,0,1
848,2017-12-18,2017,12,18,8,7khfmg,joshua-wu/deepfakes_faceswap - the project that's in the news for inserting faces into pornographic videos,https://www.reddit.com/r/MachineLearning/comments/7khfmg/joshuawudeepfakes_faceswap_the_project_thats_in/,wassname,1513555062,,1,1
849,2017-12-18,2017,12,18,9,7khjz4,"[D] NIPS posted ""Statement on inappropriate behavior"" and will appoint Diversity and Inclusion Chair",https://www.reddit.com/r/MachineLearning/comments/7khjz4/d_nips_posted_statement_on_inappropriate_behavior/,baylearn,1513556313,,121,52
850,2017-12-18,2017,12,18,10,7ki41k,Planing a Python library that hosts/formats all ML Datasets.,https://www.reddit.com/r/MachineLearning/comments/7ki41k/planing_a_python_library_that_hostsformats_all_ml/,[deleted],1513562160,,0,1
851,2017-12-18,2017,12,18,11,7kiajj,[D] Planing a Python library that hosts/formats all ML Datasets.,https://www.reddit.com/r/MachineLearning/comments/7kiajj/d_planing_a_python_library_that_hostsformats_all/,zbnone,1513564071,"Hi, I am planing a python library that hosts (ideally) all ML Datasets.

The goal is that you can do all of the following with one line of code each:

-Search for a dataset

-Get information on a dataset and all the available formats

-Download and initialize the dataset

-Set the format (e.g. of the output batches)

-Get a training/test/validation batch (depending on the format)

-Do pre/post-processing dependent on the format

This is the basic idea, if you know of something already in existence I would love to know about it. But all I could find are some Github Repos that have wrappers for some specific datasets.

What I want to achieve with this post is to get a general sense if this is something the community would actually need or if it is just me. And getting a rough idea of the whole picture and of what it would take to make this useful. And if someone would like to collaborate with me on this.

Workflow example: Lets say I have a project where I want to generate song lyrics and for that I have a dataset of 100k songs. I had to download that dataset manually after quite a bit of searching and when i finally had it, I needed to clean it up and format it in a usable way. And lastly, I have to write a dataset loading, augmentation and batching library to go along with it. Finally the model can be trained! But wait, there is a new paper out describing a new type of model (maybe a LSTM2.0 based, recurrent model with state of the art... blablabla) that I have to try to see if my results will improve. Now let's suppose that my original model took in the raw vectorized characters of the song lyrics and the new model takes in the whole vectorized words. This has to be adjusted, so except for the training, the majority of time spend on testing out the new model goes into rewriting my original dataset loading library or maybe even reformatting the whole data and adjusting my pre and post processing steps to fit the new format.

The idea is that you can visit the project website and search for a dataset by category, keyword, etc. or do that directly from the python terminal using the lib ""libX.search(keywords='nlp,lyrics,songs')"". Then when you want more details on the dataset and the different formations of it (vectorized characters/vectorized words/etc.) you have something like ""libX.dataset_info(dataset_name='100k_rap_lyrics_v1')"" that would return a dictionary of information, you get it. Download and initialize it, ""dataset = libX.init_dataset(dataset_name='100k_rap_lyrics_v1',path='./dataset/path')"" maybe you could also pass in a configuration parameter to e.g. specify how much memory it should take up, or if the whole thing should be loaded into memory, and if it should be split into training, test and validation sets and the percentages of samples for each of these (probably a good default would be required). Then you can set up your formation like this ""dataset.set_format(dataset.formats.vectorized_words,options={""vector_size"":10000,""pre_word_count"":8})"". That would set the format of the dataset and input output correlations returned by ""dataset.get_batch(..."". So when you write ""x,y = dataset.get_batch(batch_size=128)"" x and y would be the input and the desired output, in this case x would have this shape: [batch_size, per_word_count,vector_size] and y: [batch_size,vector_size]. More useful stuff; in pre-processing when you want to convert a sentence into a vector array ""dataset.to_vector('my sentence.')"" or back ""dataset.to_words([word_count,vector_size])"". If you would like to run it after training, ""sentence='This is the beginning'"" ""result = model.run(dataset.to_vector(sentence,length=pre_word_count))"" ""sentence += dataset.to_words(result)[0]"".

It is very important that you have a generalized set of formations, different sentence based datasets should have the same formations available to them. All word/sentence based datasets have formations for text generation, classification, sentiment analysis, etc. The same goes for something like mnist, there you would have formats for classification,generation, etc.

I realize that this is very massive project and my plan is to make it a Github based open source effort. I am sorry for the extend of this post. I don't write many posts on reddit so some tips and tricks are very welcome.",22,28
852,2017-12-18,2017,12,18,13,7kitmq,[D] Looking for task-based conversational tasks or datasets,https://www.reddit.com/r/MachineLearning/comments/7kitmq/d_looking_for_taskbased_conversational_tasks_or/,MysteriousArtifact,1513569967,"There's a lot of high-quality datasets for NLU around Question Answering, Machine Comprehension, and Summarization. Generally these datasets are evaluated with multiple-choice or something like BLEU.

However, I'm now looking for any ""gold standard"" tasks where commands are given, and the system is evaluated based on whether it performs the correct task (whether it be in a simulated environment, or against some ""correct answer"" based on the state of a world that the agent has access to).

Any thoughts about task-based evaluation for conversational agents?",0,6
853,2017-12-18,2017,12,18,14,7kj48e,[R] Exploring the ChestXray14 dataset: problems,https://www.reddit.com/r/MachineLearning/comments/7kj48e/r_exploring_the_chestxray14_dataset_problems/,wei_jok,1513573543,,7,103
854,2017-12-18,2017,12,18,14,7kj6t0,"Freelance machine learners, how do you do it?",https://www.reddit.com/r/MachineLearning/comments/7kj6t0/freelance_machine_learners_how_do_you_do_it/,[deleted],1513574404,,0,1
855,2017-12-18,2017,12,18,14,7kj8d5,Velocious Vehicles and How to Track Them,https://www.reddit.com/r/MachineLearning/comments/7kj8d5/velocious_vehicles_and_how_to_track_them/,[deleted],1513574953,[deleted],0,1
856,2017-12-18,2017,12,18,14,7kj9h3,Machine learning out of human movement data,https://www.reddit.com/r/MachineLearning/comments/7kj9h3/machine_learning_out_of_human_movement_data/,Chakiix,1513575330,[removed],0,1
857,2017-12-18,2017,12,18,14,7kja1n,"[D] Freelance machine learners, how do you do it?",https://www.reddit.com/r/MachineLearning/comments/7kja1n/d_freelance_machine_learners_how_do_you_do_it/,nivm321,1513575552,"Hi,

All freelancing folk in the subreddit, let us know-

*     Where do you find jobs?
*     How much do you charge?
*     What work do you get? What all do you deliver?
*     How do you bill? What tools do you use to track time and what all time do you track? (training time is billed?)
*     Anything you think we should know.

Thank you!
",43,84
858,2017-12-18,2017,12,18,14,7kja2v,Velocious Vehicles and How to Track ThemThe Road to becoming a Self Driving Car Engineer,https://www.reddit.com/r/MachineLearning/comments/7kja2v/velocious_vehicles_and_how_to_track_themthe_road/,unmatchedsock31,1513575563,,0,1
859,2017-12-18,2017,12,18,15,7kjjg7,Role Of Machine Learning in General Life,https://www.reddit.com/r/MachineLearning/comments/7kjjg7/role_of_machine_learning_in_general_life/,kpitsolution,1513579066,,0,1
860,2017-12-18,2017,12,18,15,7kjkka,[P] Chainer Chemistry: A Library for Deep Learning in Biology and Chemistry,https://www.reddit.com/r/MachineLearning/comments/7kjkka/p_chainer_chemistry_a_library_for_deep_learning/,baylearn,1513579509,,1,33
861,2017-12-18,2017,12,18,16,7kjnjl,[P] machine learning based of employee movement data,https://www.reddit.com/r/MachineLearning/comments/7kjnjl/p_machine_learning_based_of_employee_movement_data/,Chakiix,1513580661,"I got strange task on my uni for my home project from ML course. I got 2 datasets both based on employee movement. One in an office and second in some kind of factory. Both datasets contain data in format like (date,employeeID, x, y, z, velocity), to match these I also got map of both, factory and office, with marked places like workspace, smoke room, kitchen, machines(on factory map), WC, chill room.

And I have been given a task to find a way to use ML and implement something based on one of these datasets. 

At first I was thinking about some classification as smoker or not but based on this data it seems hard to find more groups + I am not convinced if Mall in this case would be even needed.

Then I thought of finding out best time slots to perform machine maintenance since no-one if Woking on that machine. I got 3 machines marked. I was allowed to make any assumptions as long as they are not stupid, so assuming that every time someone is close to machine means he is working on it (and ignoring the fact that some of these is probably maintenance already) there are some time slots for each when noone is there.

One more idea I had is to turn on lights 
in rooms automatically based on room's position, time and if someone is in this room usually at that hour. So if room has no windows and lets say every minute at least 3 people pass through it - lights should be on automatically as we can assume that they will turn it on anyway. Or in one room people are working 6-14 and in other 8-18 then we assume that based on some external data of sunrises the light should be on in 1st room from 6-7:30 and in 2nd from 16-18. Etc

As interesting background it was right after a class where the lecturer said that ML should not be used as default tool for anything but rather to distinguish if your problem can be solved by ML. Anyway task is a task and I have to do that :)

Does any of my ideas seem ""good enough"" or maybe could you share your ideas please? Thanks!",5,4
862,2017-12-18,2017,12,18,17,7kk0s3,[D] Someone willing to do code review of Sparse Differential Neural Computers?,https://www.reddit.com/r/MachineLearning/comments/7kk0s3/d_someone_willing_to_do_code_review_of_sparse/,dataxaar,1513586393,"I've been implementing sparse differentiable neural computers and sparse access memory from the paper [Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes](https://arxiv.org/abs/1610.09027). Though these are not really sparse yet (as in take advantage of `torch.sparse` and sparse optimizers), but they do try to replicate the possibility of having huge memories with sparse updates using scatter-gather. The repo - [https://github.com/ixaxaar/pytorch-dnc](https://github.com/ixaxaar/pytorch-dnc).

Though the code ""works"" for the very simple copy task, it could do with some **code review** as there has really been one set of eyes that has looked into it.

Also suggestions on which approximate kNN library to use to speed up things with CUDA (and preferably interops with pytorch?) would be really great!

Some of the ideas are taken from [this discussion on github](https://github.com/deepmind/dnc/issues/3) and [this one on r/MachineLearning](https://www.reddit.com/r/MachineLearning/comments/5abcd4/r161009027_scaling_memoryaugmented_neural/).

",6,13
863,2017-12-18,2017,12,18,18,7kk7jt,5 Key Artificial Intelligence Predictions For 2018: How Machine Learning Will Change Everything,https://www.reddit.com/r/MachineLearning/comments/7kk7jt/5_key_artificial_intelligence_predictions_for/,mr_j_b,1513589653,,0,1
864,2017-12-18,2017,12,18,18,7kka7j,DeepMind &amp; Android: The evolution of AI and Machine Learning for consumers begins,https://www.reddit.com/r/MachineLearning/comments/7kka7j/deepmind_android_the_evolution_of_ai_and_machine/,niharikasinghai,1513590856,,0,1
865,2017-12-18,2017,12,18,19,7kkd1y,[D] Overfeat and yolo,https://www.reddit.com/r/MachineLearning/comments/7kkd1y/d_overfeat_and_yolo/,anrod2017,1513592058,"Here is my current understanding. Overfeat is sliding window classification+localization implemented convolutionally. Yolo (object detection) divides image into say 19x19 grid and predicts (class, bounding box) for all anchor boxes per grid cell.

If stride of overfeat = length of sliding window (so that sliding windows don't overlap), and in Yolo number of anchor boxes=1, can we say Overfeat and Yolo are doing similar thing here?",2,0
866,2017-12-18,2017,12,18,20,7kkjwk,What soft of machine learning procedure/algorithm/software should I be using?,https://www.reddit.com/r/MachineLearning/comments/7kkjwk/what_soft_of_machine_learning/,[deleted],1513595074,,0,1
867,2017-12-18,2017,12,18,20,7kklnu,What sort of machine learning solution should I be adopting?,https://www.reddit.com/r/MachineLearning/comments/7kklnu/what_sort_of_machine_learning_solution_should_i/,[deleted],1513595749,,0,1
868,2017-12-18,2017,12,18,20,7kkn5c,[D] What sort of machine learning solution should I be adopting?,https://www.reddit.com/r/MachineLearning/comments/7kkn5c/d_what_sort_of_machine_learning_solution_should_i/,lucameyer,1513596361,"Hi,

I would like to automatize a procedure which involves classifying 4000-5000 Google Alerts news each week as relevant or not for further research and I am unsure what machine learning solution should I be looking into keeping in mind that:

(1) I have a basis input a file with 4 columns - see https://docs.google.com/spreadsheets/d/1dKY4k6pInEAANaOWvkgHm4ZtMOWqSyM8w-SSLuXPEzQ/edit?usp=sharing for an extract: (1A) TITLE (1B) WEBSITE (1C) EXCERPT (1D) RETAIN

(2) News are in different languages and research topics are more than one

(3) I am familiar with R programming hence any R procedure would require me less time to learn how to apply it

Basically I would like to find an algorithm that provided the content of TITLE, WEBSITE and EXCERPT will predict the correct RETAIN rule as shown in the sample input file.

Any suggestion?

Thanks,

Luca
",5,5
869,2017-12-18,2017,12,18,20,7kkna3,FREE Course - Outlier Detection Algorithms in Data Mining and Data Science,https://www.reddit.com/r/MachineLearning/comments/7kkna3/free_course_outlier_detection_algorithms_in_data/,[deleted],1513596412,,0,1
870,2017-12-18,2017,12,18,21,7kky9g,"New YouTube channel with great videos on Machine Learning! (inspired by Siraj, Two Minute Papers, ..)",https://www.reddit.com/r/MachineLearning/comments/7kky9g/new_youtube_channel_with_great_videos_on_machine/,tr1pzz,1513600641,,0,2
871,2017-12-18,2017,12,18,21,7kkzqv,[D] The joke at NIPS,https://www.reddit.com/r/MachineLearning/comments/7kkzqv/d_the_joke_at_nips/,stochastic_gradient,1513601164,"What exactly was this joke?

From what I can tell, this joke is the entirety of the ""inappropriate behavior"" that is supposed to have happened at NIPS. 

This has ushered in a series of actions from the NIPS program committee, including formalized procedures for reporting such incidents in the future.

I don't think policing inappropriate jokes is a step in a good direction. I think it is an extremist step to mitigate what should be a non-issue.

Having a conference that is nice for everyone involves being mindful of how our behavior affect other people, but it also involves being tolerant of other peoples flaws, quirks and missteps. 

Some people will make lame jokes. Pick a random respected comedian, and chances are you will hear them talk about death, mental illness, racism, the holocaust, and yes: sexual assault. The dark and painful is exactly what we make our jokes about. Telling a joke is fundamentally about taking a risk, you don't know if it will land with your audience until is told out loud. Sometimes it sounds good in your head, and sounds bad when it comes out. 

The punishment for this should not be public crucifixion. We should simply shrug our shoulders, shake our heads, and move on with our lives, like the grown ups we are.
",24,1
872,2017-12-18,2017,12,18,22,7klcz0,Videos from MLSS 2017 have been released,https://www.reddit.com/r/MachineLearning/comments/7klcz0/videos_from_mlss_2017_have_been_released/,gexaha,1513605567,,0,1
873,2017-12-18,2017,12,18,23,7kleda,"Learning ""concept embeddings"" as opposed to word embeddings - modifying word2vec's objective",https://www.reddit.com/r/MachineLearning/comments/7kleda/learning_concept_embeddings_as_opposed_to_word/,rabbit140,1513605980,[removed],0,1
874,2017-12-18,2017,12,18,23,7klkyc,How Do Machines Learn? - CGPGrey,https://www.reddit.com/r/MachineLearning/comments/7klkyc/how_do_machines_learn_cgpgrey/,Obligatory_Username,1513607979,,0,1
875,2017-12-19,2017,12,19,0,7klwui,How to explain Neural Networks in 5 minutes?,https://www.reddit.com/r/MachineLearning/comments/7klwui/how_to_explain_neural_networks_in_5_minutes/,savan77,1513611285,[removed],0,1
876,2017-12-19,2017,12,19,0,7klzly,FREE Course - Outlier Detection Algorithms in Data Mining and Data Science,https://www.reddit.com/r/MachineLearning/comments/7klzly/free_course_outlier_detection_algorithms_in_data/,[deleted],1513612021,[deleted],0,1
877,2017-12-19,2017,12,19,2,7kmp0y,"[P] - My coworker created a YouTube channel on machine learning and it's probably the best thing you'll see today (AlphaGo, RL, NN...)",https://www.reddit.com/r/MachineLearning/comments/7kmp0y/p_my_coworker_created_a_youtube_channel_on/,Pluimvee,1513618270,,12,0
878,2017-12-19,2017,12,19,2,7kms4i,[D] How Do Machines Learn? - by CGPGrey,https://www.reddit.com/r/MachineLearning/comments/7kms4i/d_how_do_machines_learn_by_cgpgrey/,Locke-It-Up,1513619029,,16,73
879,2017-12-19,2017,12,19,3,7kn0dx,"[R] gym-extensions: an extension to OpenAI Gym for auxiliary tasks (multitask learning, transfer learning, inverse reinforcement learning, etc.)",https://www.reddit.com/r/MachineLearning/comments/7kn0dx/r_gymextensions_an_extension_to_openai_gym_for/,metaAI,1513621009,,0,10
880,2017-12-19,2017,12,19,3,7kn4c3,The LocalFlow - the new chatbot platform in the tangle,https://www.reddit.com/r/MachineLearning/comments/7kn4c3/the_localflow_the_new_chatbot_platform_in_the/,Local_Flow,1513621965,[removed],0,1
881,2017-12-19,2017,12,19,3,7kn8hs,Recommender Systems in Keras,https://www.reddit.com/r/MachineLearning/comments/7kn8hs/recommender_systems_in_keras/,nipun_batra,1513622981,,0,1
882,2017-12-19,2017,12,19,4,7knbip,[R] Welcoming the Era of Deep Neuroevolution,https://www.reddit.com/r/MachineLearning/comments/7knbip/r_welcoming_the_era_of_deep_neuroevolution/,inarrears,1513623702,,100,186
883,2017-12-19,2017,12,19,5,7knv3a,CRM (Salesforce Einstein?) and Machine Learning / Data Science applied to it,https://www.reddit.com/r/MachineLearning/comments/7knv3a/crm_salesforce_einstein_and_machine_learning_data/,Sakkumitsu,1513628380,[removed],0,1
884,2017-12-19,2017,12,19,6,7ko9o0,[D] Google Research: Introducing NIMA - Neural Image Assessment,https://www.reddit.com/r/MachineLearning/comments/7ko9o0/d_google_research_introducing_nima_neural_image/,sksq9,1513631913,,3,32
885,2017-12-19,2017,12,19,6,7koeo6,Startup uses quantum computing to boost machine learning,https://www.reddit.com/r/MachineLearning/comments/7koeo6/startup_uses_quantum_computing_to_boost_machine/,jorgemf,1513633148,,0,1
886,2017-12-19,2017,12,19,7,7komix,[D] Running inference tasks on the edge,https://www.reddit.com/r/MachineLearning/comments/7komix/d_running_inference_tasks_on_the_edge/,amebaspugnosa,1513635093,"Hello all, we have trained a model based on CNNs to solve an industrial problem. The model is being served using Python webservices and Tensorflow-serving running on a common Xeon rack server.

We would like to move inference closer to the industrial application that invokes the model, in order to minimize risks of network partitions.

Does anyone have experience of using hardware that runs on edge system such us Jetson TX2 or reduced form factor PCs with Nvidia GPU on board?

Any idea?",3,6
887,2017-12-19,2017,12,19,7,7kosa5,Gaussian process tutorial ?,https://www.reddit.com/r/MachineLearning/comments/7kosa5/gaussian_process_tutorial/,iwanttodiequick,1513636514,[removed],0,1
888,2017-12-19,2017,12,19,7,7koxm2,[D] Great theses to read in Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/7koxm2/d_great_theses_to_read_in_reinforcement_learning/,bronzestick,1513637855,"I am currently on the lookout for great theses written in the field of Reinforcement Learning (or even general statistical learning). For the past few days, I have been reading Sham Kakade's thesis and have thoroughly enjoyed it. Any other recommendations? ",4,23
889,2017-12-19,2017,12,19,8,7kp0nd,Has anybody theoretically proved effectiveness of a specific machine learning method?,https://www.reddit.com/r/MachineLearning/comments/7kp0nd/has_anybody_theoretically_proved_effectiveness_of/,Curious_Pouya,1513638594,[removed],0,1
890,2017-12-19,2017,12,19,9,7kpd98,Good resources to learn math and intuition Generative Adversarial Networks?,https://www.reddit.com/r/MachineLearning/comments/7kpd98/good_resources_to_learn_math_and_intuition/,quaPok,1513641996,[removed],0,1
891,2017-12-19,2017,12,19,9,7kpdsj,[D] What are your thoughts on Unsupervised Image-to-Image Translation Networks? How do you get training data for such projects?,https://www.reddit.com/r/MachineLearning/comments/7kpdsj/d_what_are_your_thoughts_on_unsupervised/,HeuristicNinja,1513642131,,4,2
892,2017-12-19,2017,12,19,9,7kpj8r,"Deep Learning, Language and Cognition by C. Manning",https://www.reddit.com/r/MachineLearning/comments/7kpj8r/deep_learning_language_and_cognition_by_c_manning/,cognitivedemons,1513643581,,0,1
893,2017-12-19,2017,12,19,9,7kpmby,[D] Is a 2010 Macbook Pro with NVIDIA GeForce 320M 256 MB powerful enough to train on features produced by the computer vision concepts SIFT or HOG?,https://www.reddit.com/r/MachineLearning/comments/7kpmby/d_is_a_2010_macbook_pro_with_nvidia_geforce_320m/,phreak121,1513644461,"I'm planning to do a computer vision/machine learning project. The task that it will do is object detection.

As the title states I do have an Nvidia GPU but it is not CUDA-enabled, but I looked into some things and [this person](http://www.peterkuban.com/lab.php?lab=1) was able to make his GPU CUDA-enabled.

I plan to stay away from deep learning and try use more traditional techniques like SVM. So I'm just wondering whether it will be feasible to build models on my laptop or else would it take too long? ",8,1
894,2017-12-19,2017,12,19,10,7kq18g,Need advice on an upcoming ML project for work.,https://www.reddit.com/r/MachineLearning/comments/7kq18g/need_advice_on_an_upcoming_ml_project_for_work/,Canadian_Marine,1513648645,[removed],0,1
895,2017-12-19,2017,12,19,11,7kq3q2,[P] Data augmentation Random-Erasing,https://www.reddit.com/r/MachineLearning/comments/7kq3q2/p_data_augmentation_randomerasing/,zhedongzheng,1513649359,,2,1
896,2017-12-19,2017,12,19,11,7kq4tk,Titan V vs 4x 1080 Ti GPUs,https://www.reddit.com/r/MachineLearning/comments/7kq4tk/titan_v_vs_4x_1080_ti_gpus/,PM_YOUR_NIPS_PAPER,1513649676,[removed],0,1
897,2017-12-19,2017,12,19,11,7kq7gl,We extented Gatys Image style transfer to work for themes! Help us evaluate results !!,https://www.reddit.com/r/MachineLearning/comments/7kq7gl/we_extented_gatys_image_style_transfer_to_work/,[deleted],1513650415,,0,1
898,2017-12-19,2017,12,19,11,7kqb48,[Project] We extented Gatys Image style transfer to work for themes! Help us evaluate results !!,https://www.reddit.com/r/MachineLearning/comments/7kqb48/project_we_extented_gatys_image_style_transfer_to/,RoxiMax,1513651440,"Hello, We were working with Image style transfer algorithms for the semester. Now we have managed to extend Gatys (http://arxiv.org/abs/1508.06576) Image style transfer. Instead of transferring style from a single image, we are now trying to find the common theme between multiple images and using that theme to transform/stylize the input content image.

We think we were fairly successful in doing so, and need the help of reddit community! We have created a survey, where we ask to select image which you find more pleasing. One of them is produced by existing state of the art algorithms, and one of them by our new algorithm. This will help us to know if our algorithm is able to produce aesthetically pleasing images or not. Please take the following anonymous survey, I will publish results in 2 days. Thank you.

https://www.surveymonkey.com/r/FDY7NV9",5,3
899,2017-12-19,2017,12,19,11,7kqc2b,Is it ok to post an ML job here?,https://www.reddit.com/r/MachineLearning/comments/7kqc2b/is_it_ok_to_post_an_ml_job_here/,MaaDoTaa,1513651705,[removed],0,1
900,2017-12-19,2017,12,19,12,7kqhz4,Universal Style Transfer via Feature Transforms,https://www.reddit.com/r/MachineLearning/comments/7kqhz4/universal_style_transfer_via_feature_transforms/,Deep_Fried_Learning,1513653350,,0,1
901,2017-12-19,2017,12,19,12,7kqj8q,[D] The Master Algorithm,https://www.reddit.com/r/MachineLearning/comments/7kqj8q/d_the_master_algorithm/,Turin_Martell,1513653695,"I really enjoyed reading Pedro Domingos' book 'The Master Algorithm"" a while back. A link to [this project](https://alchemy.cs.washington.edu) was at the end of the book. I've never heard anything about it in the wider ML community though. How is Domingos' work viewed?",4,0
902,2017-12-19,2017,12,19,12,7kqldj,[D]How to decide whether a new feature is effective in improving the model?,https://www.reddit.com/r/MachineLearning/comments/7kqldj/dhow_to_decide_whether_a_new_feature_is_effective/,yetionyo,1513654339,"Let say we already have a data matrix N*D (N is the number of data points, and D is the number of features), and we use some algorithms (such as lightgbm) to do the predictions.

Now, we have calculated a new feature, and we want to test whether it's effective. A naive way is to concatenate the new feature with the original data matrix, then feed the N*(D+1) data matrix into the model, and decide to add or discard the new feature by comparing the model performances(accuracy, loss, etc) on validation dataset. But there are some problems:

The model performance may be related to the hyperparameters in the model. Directly adding the new feature may lead to degradation of performance, but the performance may improve through tuning the hyperparameters.
The newly added feature may be conflicted with the existing features in the data matrix, maybe after removing some features in the original data matrix, the new feature will have greatly improved the model performance.
In addition, these problems above lead to another problem: adding feature seems to be sequential process, because different orders will produce different combinations of features, so how to find the optimal order of adding new features to existing data matrix?",11,7
903,2017-12-19,2017,12,19,12,7kqoh0,[D] Best Holiday ML paper?,https://www.reddit.com/r/MachineLearning/comments/7kqoh0/d_best_holiday_ml_paper/,chiraqe,1513655263,Initial candidate is https://arxiv.org/pdf/1709.01907.pdf . ,4,4
904,2017-12-19,2017,12,19,13,7kr07i,SSC Top 5 Paragraph Exam 2018,https://www.reddit.com/r/MachineLearning/comments/7kr07i/ssc_top_5_paragraph_exam_2018/,anowarul147,1513658931,,0,1
905,2017-12-19,2017,12,19,14,7kr3kp,[D] Deep Learning in China is a highly competitive business: a professional deep learning debugger on the street.,https://www.reddit.com/r/MachineLearning/comments/7kr3kp/d_deep_learning_in_china_is_a_highly_competitive/,[deleted],1513659993,[deleted],6,30
906,2017-12-19,2017,12,19,14,7kr4ue,Pc build for machine learning,https://www.reddit.com/r/MachineLearning/comments/7kr4ue/pc_build_for_machine_learning/,ByteBunny,1513660386,[removed],0,1
907,2017-12-19,2017,12,19,16,7krqyz,Any idea how to convert a Pytorch program/ NN model to C++ for increased performance?,https://www.reddit.com/r/MachineLearning/comments/7krqyz/any_idea_how_to_convert_a_pytorch_program_nn/,sdhnshu,1513668328,[removed],0,1
908,2017-12-19,2017,12,19,16,7krswy,Is anyone using/making applications using ML/DL in the real-estate industry?,https://www.reddit.com/r/MachineLearning/comments/7krswy/is_anyone_usingmaking_applications_using_mldl_in/,sdhnshu,1513669147,[removed],0,1
909,2017-12-19,2017,12,19,17,7ks2au,Semi-supervised image classification explained,https://www.reddit.com/r/MachineLearning/comments/7ks2au/semisupervised_image_classification_explained/,[deleted],1513673217,[deleted],1,1
910,2017-12-19,2017,12,19,17,7ks2x4,[P] When to use Transfer Learning. Experimentation on different datasets in PyTorch,https://www.reddit.com/r/MachineLearning/comments/7ks2x4/p_when_to_use_transfer_learning_experimentation/,hoaphumanoid,1513673503,,3,26
911,2017-12-19,2017,12,19,18,7ks4xs,Supervised data with problematic clustering?,https://www.reddit.com/r/MachineLearning/comments/7ks4xs/supervised_data_with_problematic_clustering/,hakim131,1513674401,[removed],0,1
912,2017-12-19,2017,12,19,18,7ksa22,[R] Semi-supervised image classification explained,https://www.reddit.com/r/MachineLearning/comments/7ksa22/r_semisupervised_image_classification_explained/,tarvaina,1513676589,,17,56
913,2017-12-19,2017,12,19,18,7ksayl,Is there an energy (norm) preserving neural network architecture?,https://www.reddit.com/r/MachineLearning/comments/7ksayl/is_there_an_energy_norm_preserving_neural_network/,akanimax,1513677011,"A neural network passes an input vector through a series of ""matrix (rotations / scaling / translation) operations followed by a non-linearity"". The output vector of the neural network may or may not have the same norm as the input vector. Could you please point me to a / some neural network architecture/s that is / are able to preserve the norm of the input vector? 

If we consider the norm as a measure of the energy of the input vector / signal, what I am looking for is a neural net that can preserve the energy of the input signal. Is there any other metric that is analogous to the energy of the input signal?",21,4
914,2017-12-19,2017,12,19,18,7ksb51,untitled,https://www.reddit.com/r/MachineLearning/comments/7ksb51/untitled/,anowarul147,1513677085,,0,1
915,2017-12-19,2017,12,19,19,7ksd2v,Facebook wants to rid of engagement bait with machine learning,https://www.reddit.com/r/MachineLearning/comments/7ksd2v/facebook_wants_to_rid_of_engagement_bait_with/,mr_j_b,1513677924,,0,1
916,2017-12-19,2017,12,19,19,7ksddr,ML/DL University Project suggestion in context of Nepal?,https://www.reddit.com/r/MachineLearning/comments/7ksddr/mldl_university_project_suggestion_in_context_of/,arya_minus,1513678043,[removed],0,1
917,2017-12-19,2017,12,19,19,7kshkm,Daily Review: A Startup Uses Quantum Computing to Transform the World of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7kshkm/daily_review_a_startup_uses_quantum_computing_to/,LTP1,1513679755,,0,1
918,2017-12-19,2017,12,19,19,7kshl7,Machine Learning News Feed,https://www.reddit.com/r/MachineLearning/comments/7kshl7/machine_learning_news_feed/,mr_j_b,1513679762,,0,1
919,2017-12-19,2017,12,19,19,7ksjur,The First Step-by-Step Guide for Implementing Neural Architecture Search with Reinforcement Learning Using TensorFlow,https://www.reddit.com/r/MachineLearning/comments/7ksjur/the_first_stepbystep_guide_for_implementing/,nucijokuro,1513680748,,1,1
920,2017-12-19,2017,12,19,20,7ksn9x,[P] Machine Learning @ Teads (part 2)  Teads Engineering,https://www.reddit.com/r/MachineLearning/comments/7ksn9x/p_machine_learning_teads_part_2_teads_engineering/,chris_shpak,1513682119,,1,2
921,2017-12-19,2017,12,19,20,7ksoly,[R] NIPS 2017 Key Points &amp; Summary Notes,https://www.reddit.com/r/MachineLearning/comments/7ksoly/r_nips_2017_key_points_summary_notes/,magneticono,1513682649,,0,1
922,2017-12-19,2017,12,19,20,7ksrwo,[P] Survey of gradient based attribution/visualization techniques for deep learning models,https://www.reddit.com/r/MachineLearning/comments/7ksrwo/p_survey_of_gradient_based/,saucysassy,1513683986,,0,15
923,2017-12-19,2017,12,19,21,7ksuh7,[R] Tacotron 2: Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions,https://www.reddit.com/r/MachineLearning/comments/7ksuh7/r_tacotron_2_natural_tts_synthesis_by/,rustyryan,1513684989,,60,87
924,2017-12-19,2017,12,19,21,7kswwy,Cazena Extends Big Data as a Service Platform with New App Cloud to Accelerate Adoption of Partners [R] Machine Learning and Analytical Solutions on AWS and Azure,https://www.reddit.com/r/MachineLearning/comments/7kswwy/cazena_extends_big_data_as_a_service_platform/,digitalson,1513685949,,0,1
925,2017-12-19,2017,12,19,21,7kt1l6,[D] What are some recommended resources to get familiar with PyTorch/TensorFlow ?,https://www.reddit.com/r/MachineLearning/comments/7kt1l6/d_what_are_some_recommended_resources_to_get/,__Julia,1513687685,"What are some recommended resources to get familiar with PyTorch/TensorFlow. I usually use SKlearn to do machine learning, as I am learning how to use Deep Learning, I am trying to invest some time to learn how to use PyTorch/TensorFlow. Any good recommendations ? ",8,22
926,2017-12-19,2017,12,19,22,7ktb45,"Nintendo Super Smash Bros. Melee: An ""Untouchable"" Agent",https://www.reddit.com/r/MachineLearning/comments/7ktb45/nintendo_super_smash_bros_melee_an_untouchable/,whenmaster,1513690916,,1,0
927,2017-12-19,2017,12,19,23,7kti2p,Unsupervised Machine Learning on Rigetti 19Q with Forest 1.2,https://www.reddit.com/r/MachineLearning/comments/7kti2p/unsupervised_machine_learning_on_rigetti_19q_with/,johnmountain,1513692997,,0,1
928,2017-12-19,2017,12,19,23,7ktpng,Deep Neuroevolution: Genetic Algorithms Are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/7ktpng/deep_neuroevolution_genetic_algorithms_are_a/,Hizachi,1513695147,,0,1
929,2017-12-20,2017,12,20,2,7kuvdh,[D] Open-endedness: The last grand challenge youve never heard of,https://www.reddit.com/r/MachineLearning/comments/7kuvdh/d_openendedness_the_last_grand_challenge_youve/,Kaixhin,1513705631,,14,27
930,2017-12-20,2017,12,20,4,7kvevc,Example using LIME to explain XGBoost predictions,https://www.reddit.com/r/MachineLearning/comments/7kvevc/example_using_lime_to_explain_xgboost_predictions/,syrios12,1513710285,,0,1
931,2017-12-20,2017,12,20,5,7kvv68,[D] NLP models with output in the embedding space?,https://www.reddit.com/r/MachineLearning/comments/7kvv68/d_nlp_models_with_output_in_the_embedding_space/,ncasas,1513714110,"NLP deep learning models, like Language Models or Machine Translation models, usually output the probability distribution over the token space, normally having a softmax as last layer.

I am interested in knowing if there are any publications that propose models where the output is not a softmax but a vector in the embedding space or, alternatively, suggestions on how to do it, like what loss function to use (e.g. MSE between output and expected embedded vectors) or not to use, and why.

I have not been able to find anything in google or google scholar, that's why I resort to the knowledge of this subreddit. I would appreciate any help.",10,9
932,2017-12-20,2017,12,20,6,7kwipw,what about a tensorflow AI virtual assistant?,https://www.reddit.com/r/MachineLearning/comments/7kwipw/what_about_a_tensorflow_ai_virtual_assistant/,fr1d4y_,1513719859,[removed],0,1
933,2017-12-20,2017,12,20,8,7kx8th,Generative Adversarial Imitation Learning implementation based on open/baselines,https://www.reddit.com/r/MachineLearning/comments/7kx8th/generative_adversarial_imitation_learning/,andrewliao11,1513726414,[removed],0,1
934,2017-12-20,2017,12,20,9,7kxl02,Copyright Detection on the Blockchain Using Bayesian Algorithms,https://www.reddit.com/r/MachineLearning/comments/7kxl02/copyright_detection_on_the_blockchain_using/,YawLife,1513729597,[removed],0,1
935,2017-12-20,2017,12,20,9,7kxn2z,How to effectively keep track of experiments?,https://www.reddit.com/r/MachineLearning/comments/7kxn2z/how_to_effectively_keep_track_of_experiments/,logrech,1513730155,[removed],0,1
936,2017-12-20,2017,12,20,9,7kxsbp,[P] Aboleth - A bare-bones TensorFlow framework for Bayesian NNs,https://www.reddit.com/r/MachineLearning/comments/7kxsbp/p_aboleth_a_barebones_tensorflow_framework_for/,dsberg,1513731577,"The purpose of [Aboleth](https://github.com/data61/aboleth) is to provide a set of high performance and light weight components for building Bayesian neural nets and approximate (deep) Gaussian process computational graphs (and more). We aim for minimal abstraction over pure TensorFlow, so you can easily assign parts of the computational graph to different hardware, use your own data feeds/queues, and manage your own sessions etc.

Some features:

* Bayesian fully-connected, embedding and convolutional layers using SGVB for inference.
* Random Fourier and arc-cosine features for approximate Gaussian processes (and SVMs).
* Imputation layers with parameters that are learned as part of a model.
* Very flexible construction of networks, e.g. multiple inputs, ResNets etc.
* Compatible and inter-operable with other neural net frameworks such as [Keras](https://keras.io/).

Have a look at the [docs](http://aboleth.readthedocs.io/en/stable/?badge=stable) for more information!",4,16
937,2017-12-20,2017,12,20,11,7ky9kk,[P] PassGAN: A Deep Learning Approach for Password Guessing (code implementation),https://www.reddit.com/r/MachineLearning/comments/7ky9kk/p_passgan_a_deep_learning_approach_for_password/,brannondorsey,1513736130,,12,70
938,2017-12-20,2017,12,20,12,7kyu5v,[D] Whats a good machine learning project for an undergrad?,https://www.reddit.com/r/MachineLearning/comments/7kyu5v/d_whats_a_good_machine_learning_project_for_an/,[deleted],1513742109,[deleted],1,1
939,2017-12-20,2017,12,20,13,7kyy5t,Machine Learning is un-understandable.,https://www.reddit.com/r/MachineLearning/comments/7kyy5t/machine_learning_is_ununderstandable/,jamesjames603,1513743333,,0,1
940,2017-12-20,2017,12,20,13,7kyznp,Is there any advantage of autoregressive model for conditional image generation,https://www.reddit.com/r/MachineLearning/comments/7kyznp/is_there_any_advantage_of_autoregressive_model/,gmkim90,1513743823,[removed],0,1
941,2017-12-20,2017,12,20,13,7kz170,"[D] What up-and-coming machine learning techniques do you predict are going to be very common in the close future (for example, will be taught in a major ML course by a University/Coursera/Udacity/etc )",https://www.reddit.com/r/MachineLearning/comments/7kz170/d_what_upandcoming_machine_learning_techniques_do/,SGuptMachineLearning,1513744329,What techniques do you predict is going to be the next dropout/Relu/batch normalization/GRU/word2vec/etc.,19,7
942,2017-12-20,2017,12,20,13,7kz4zv,[D] Any work on penalizing classifications for being too accurate?,https://www.reddit.com/r/MachineLearning/comments/7kz4zv/d_any_work_on_penalizing_classifications_for/,Vystril,1513745525,"So I stumbled across a weird effect on mistake when training some CNNs on the MNIST dataset.  I had implemented the gradient of the softmax layer incorrectly (I was multiplying it by an additional output * (1 - output)), but the odd thing was that I was getting better testing predictions.

So comparing using a gradient on my softmax layer of e^x vs e^x * e^x * (1 - e^x), the latter was actually doing a fair bit better on final testing predictions. Scratching my head I plotted the gradients:

* [correct gradient](http://fooplot.com/#W3sidHlwZSI6MCwiZXEiOiIoZV54KSIsImNvbG9yIjoiIzAwMDAwMCJ9LHsidHlwZSI6MTAwMH1d)

* [incorrect gradient](http://fooplot.com/#W3sidHlwZSI6MCwiZXEiOiIoZV54KSplXngqKDEtZV54KSIsImNvbG9yIjoiIzAwMDAwMCJ9LHsidHlwZSI6MTAwMH1d)

Which when used basically forces the weights away from classifications that are too accurate, which I imagine does a pretty decent job of preventing overfitting.  The first one *does* train quicker, and *does* reach much lower error rates, however does a worse job of predictions on the test set.

I was wondering if there was any literature on anything like this out there? Can the softmax (or other output layer) be modified to penalize the neural network from being *too* accurate to help improve generalizability and reduce overfitting?",4,6
943,2017-12-20,2017,12,20,14,7kzflw,"[N] ""Twelve Days in Xinjiang: How Chinas Surveillance State Overwhelms Daily Life"" - contains important parts about using CV for surveillance and regression for threat scoring citizens",https://www.reddit.com/r/MachineLearning/comments/7kzflw/n_twelve_days_in_xinjiang_how_chinas_surveillance/,visarga,1513748976,,63,43
944,2017-12-20,2017,12,20,14,7kzh9c,What is Machine Vision,https://www.reddit.com/r/MachineLearning/comments/7kzh9c/what_is_machine_vision/,munishmaxtech,1513749508,,0,1
945,2017-12-20,2017,12,20,15,7kzjmx,untitled,https://www.reddit.com/r/MachineLearning/comments/7kzjmx/untitled/,anowarul147,1513750287,,0,1
946,2017-12-20,2017,12,20,15,7kzlh8,[P] Demo/Comparison of 7 Julia libraries that can be used for binary classification.,https://www.reddit.com/r/MachineLearning/comments/7kzlh8/p_democomparison_of_7_julia_libraries_that_can_be/,LyndonWhite,1513750933,,0,3
947,2017-12-20,2017,12,20,16,7kzvs4,Masters in Computer Science: Machine Learning.,https://www.reddit.com/r/MachineLearning/comments/7kzvs4/masters_in_computer_science_machine_learning/,Jingomoose,1513754836,[removed],0,1
948,2017-12-20,2017,12,20,16,7kzztw,[P] Real-time forecasts in Google Cloud: from market feed capture to ML predictions,https://www.reddit.com/r/MachineLearning/comments/7kzztw/p_realtime_forecasts_in_google_cloud_from_market/,fhoffa,1513756546,,0,22
949,2017-12-20,2017,12,20,17,7l03sv,Can GANs help synthesize more realistic logos in the wild?,https://www.reddit.com/r/MachineLearning/comments/7l03sv/can_gans_help_synthesize_more_realistic_logos_in/,Awholenewhorse,1513758254,[removed],0,1
950,2017-12-20,2017,12,20,17,7l06q2,How to gather data from lots of varied web sources,https://www.reddit.com/r/MachineLearning/comments/7l06q2/how_to_gather_data_from_lots_of_varied_web_sources/,QuantumQuadTrees8523,1513759557,[removed],0,1
951,2017-12-20,2017,12,20,18,7l0a8b,[N] Announcing Conference: Applied Machine Learning Days 2018,https://www.reddit.com/r/MachineLearning/comments/7l0a8b/n_announcing_conference_applied_machine_learning/,XCaellaX,1513761079,"The [Applied Machine Learning Days](https://www.appliedmldays.org/) will take place from January 27^th to 30^th, 2018, at the Swiss Tech Convention Center on [EPFL campus](https://www.epfl.ch/index.en.html), Lausanne, Switzerland. It is one of the largest machine learning &amp; AI events in Europe, focused specifically on the applications of machine learning and AI, making it particularly interesting to industry and academia.

Saturday &amp; Sunday will be hands-on, with workshops, trainings, a hackathon and tutorials. The main conference will take place on Monday and Tuesday, with a program featuring top-level speakers, a Networking Dinner, Poster Sessions and a Job Fair.


[SPEAKERS:](https://www.appliedmldays.org/speakers)

- Christopher Bishop (Microsoft)
- Joanna Bryson (Universities of Bath &amp; Princeton)
- Soumith Chintala (Facebook)
- Raia Hadsell (DeepMind)
- Jeremiah Harmsen (Google)
- Frdric Kaplan (EPFL)
- Amnon Shashua (Mobileye, Hebrew University of Jerusalem)
- Martin Vetterli (EPFL)
- Olga Russakovsky (Princeton University)
- [CrowdAI](https://www.crowdai.org/) 2017 winners


[WORKSHOPS:](https://www.appliedmldays.org/workshop_sessions)

Open Food Hackdays 2018 / Machine Learning for News: Theory, Applications and Visualisation in Python / Machine Learning with Go / The Data Ring: A canvas for Data Project / Discovering Brain Structure with Machine Learning / Financial Predictions with Machine Learning / Machine Learning Reproducibility at Scale using Open Source Tooling / Crash course in Deep Learning and PyTorch / Tensorflow Basics / Machine Learning meets Advanced Manufacturing and Materials Science / Spatial Data Science with Open Data and Social Media / Unsupervised Learning in Brain-Computer Interfaces: Theory and Practice / ""Reatching"" into the rabbithole: Should we replace politicians with algorithms? / Modeling timeseries and sequence data on AWS using Apache MXNet and Gluon / Applied Machine Learning for Anomaly Detection / Girlscoding: Teaching Computers How to Think / Artificial Intelligence for Artists


[Registration](https://www.appliedmldays.org/tickets/payment) includes breakfast, coffee breaks, lunch and refreshments.


Organizers: Professor [Martin Jaggi](https://mlo.epfl.ch/), Professor [Marcel Salath](https://www.digitalepidemiologylab.org/), Professor [Robert West](https://dlab.epfl.ch/) and [Sylvain Bernard](https://people.epfl.ch/sylvain.bernard)",14,53
952,2017-12-20,2017,12,20,18,7l0ftr,Machine learning and the spectre of the wrong solution,https://www.reddit.com/r/MachineLearning/comments/7l0ftr/machine_learning_and_the_spectre_of_the_wrong/,mr_j_b,1513763523,,0,1
953,2017-12-20,2017,12,20,19,7l0hed,Quantum Computing Is The Next Disruptive Technology,https://www.reddit.com/r/MachineLearning/comments/7l0hed/quantum_computing_is_the_next_disruptive/,mr_j_b,1513764193,,0,1
954,2017-12-20,2017,12,20,19,7l0nyq,[R] Memory Aware Synapses: Learning what (not) to forget,https://www.reddit.com/r/MachineLearning/comments/7l0nyq/r_memory_aware_synapses_learning_what_not_to/,vikkamath,1513766971,,0,21
955,2017-12-20,2017,12,20,20,7l0tvh,KL divergence more numerically stable than Cross-entropy?,https://www.reddit.com/r/MachineLearning/comments/7l0tvh/kl_divergence_more_numerically_stable_than/,car202,1513769370,[removed],0,1
956,2017-12-20,2017,12,20,20,7l0x1q,[1712.05577] Gradients explode - Deep Networks are shallow,https://www.reddit.com/r/MachineLearning/comments/7l0x1q/171205577_gradients_explode_deep_networks_are/,ihaphleas,1513770626,,3,1
957,2017-12-20,2017,12,20,21,7l18f0,[N] Inventing the Google for predictive analytics,https://www.reddit.com/r/MachineLearning/comments/7l18f0/n_inventing_the_google_for_predictive_analytics/,Jackal008,1513774762,,3,0
958,2017-12-20,2017,12,20,22,7l18ke,[R] Tacotron 2: Generating Human-like Speech from Text,https://www.reddit.com/r/MachineLearning/comments/7l18ke/r_tacotron_2_generating_humanlike_speech_from_text/,[deleted],1513774824,[deleted],0,1
959,2017-12-20,2017,12,20,22,7l1dus,[R] Getting Started with TensorFlow: A Machine Learning Tutorial,https://www.reddit.com/r/MachineLearning/comments/7l1dus/r_getting_started_with_tensorflow_a_machine/,polllyyy,1513776594,,0,1
960,2017-12-20,2017,12,20,23,7l1jn5,How can i apply SVM (or any other )classifier to segregate biodegradable and non biodegradable objects from their images ?,https://www.reddit.com/r/MachineLearning/comments/7l1jn5/how_can_i_apply_svm_or_any_other_classifier_to/,devdibyo,1513778435,[removed],0,1
961,2017-12-20,2017,12,20,23,7l1m8x,Is it me or can OpenAI Baselines be difficult to use?,https://www.reddit.com/r/MachineLearning/comments/7l1m8x/is_it_me_or_can_openai_baselines_be_difficult_to/,[deleted],1513779189,,0,1
962,2017-12-20,2017,12,20,23,7l1n9s,Forecasting Stock Prices with Linear Regression,https://www.reddit.com/r/MachineLearning/comments/7l1n9s/forecasting_stock_prices_with_linear_regression/,samayshamdasani,1513779504,,0,1
963,2017-12-20,2017,12,20,23,7l1nto,[R] MIT's automated machine learning works 100x faster than human data scientists,https://www.reddit.com/r/MachineLearning/comments/7l1nto/r_mits_automated_machine_learning_works_100x/,polllyyy,1513779676,,0,1
964,2017-12-20,2017,12,20,23,7l1oyi,[D] Any entrepreneurs here who started a business around machine learning?,https://www.reddit.com/r/MachineLearning/comments/7l1oyi/d_any_entrepreneurs_here_who_started_a_business/,Imakesensealot,1513780003,"Mind sharing your field of application, the tech stack you're using, knowledge, etc? 
Am sort of an experienced java dev looking to go the entrepreneurial route in the coming few years. Will really like some input.",14,4
965,2017-12-20,2017,12,20,23,7l1vd5,Why KL divergence?,https://www.reddit.com/r/MachineLearning/comments/7l1vd5/why_kl_divergence/,kekepa15,1513781883,[removed],0,1
966,2017-12-20,2017,12,20,23,7l1vn7,"What are some good blogs to learn Tensorflow, Keras and Pytorch ?",https://www.reddit.com/r/MachineLearning/comments/7l1vn7/what_are_some_good_blogs_to_learn_tensorflow/,Hot_Ices,1513781966,[removed],0,1
967,2017-12-21,2017,12,21,0,7l1x9l,Reading list for tensor decomposition/spectral learning,https://www.reddit.com/r/MachineLearning/comments/7l1x9l/reading_list_for_tensor_decompositionspectral/,dpeng817,1513782408,[removed],0,1
968,2017-12-21,2017,12,21,0,7l239k,[1712.05440] Nonparametric Neural Networks,https://www.reddit.com/r/MachineLearning/comments/7l239k/171205440_nonparametric_neural_networks/,ihaphleas,1513783997,,0,1
969,2017-12-21,2017,12,21,0,7l23y8,[D] Is it me or can OpenAI Baselines be difficult to use?,https://www.reddit.com/r/MachineLearning/comments/7l23y8/d_is_it_me_or_can_openai_baselines_be_difficult/,Borgut1337,1513784166,"I should preface this by saying that I think [OpenAI's Baselines repository](https://github.com/openai/baselines/) is a great thing to have in general, I think it's really important to have solid, bug-free implementations ready of all kinds of RL algorithms to use as benchmarks. In particular since [it's been shown](https://arxiv.org/abs/1709.06560) how different implementations of supposedly equivalent algorithms can have wildly different performance. 


I should also mention that I do not yet have a massive amount of experience with tensorflow or other similar frameworks, so it may really just be me who sometimes finds baselines difficult to use. But here's some of the problems I've run into so far. I've primarily been trying to dissect DQN, so that's what I'll focus on.


1. It seems difficult to plug in new network architectures. There are some options for some different architectures in [models.py](https://github.com/openai/baselines/blob/master/baselines/deepq/models.py), but not a lot. For example, it seems impossible with these functions to use different nonlinearities than relu's. I get that relu's are a good default, but if the intention is that these baselines can be used for research, I'd say there really needs to be support for something as simple as changing the nonlinearities. So, if someone wants a slightly different architecture, they have to write their own code for this. If they're gonna have to do that, it would in my opinion be useful to have some sort of documentation on what such a custom implementation should looke like. Such documentation seems to be lacking, and it doesn't seem to be so trivial to justify having no documentation either. It's not just a case of implementing a tensorflow model, careful inspection of the code reveals that it'd actually have to be a function that can be called at a later point in time to construct that model. It also shouldn't construct the complete model, because some parts of the network are only appended later on in [build_graph.py](https://github.com/openai/baselines/blob/master/baselines/deepq/build_graph.py).

2. Code for the setup of experiments is mixed in with algorithm-specific code. With the setup of experiments, I mean things like the creation of the environment, logging results, loop through the timesteps, etc. I'd personally expect to find that kind of code in a file such as [train_cartpole.py](https://github.com/openai/baselines/blob/master/baselines/deepq/experiments/train_cartpole.py). I feel like I'd expect a slightly more object-oriented design, where different RL algorithms (DQN being one of them) having a common interface with functions like act(s) to return an action for the given state s, and update(s, a, r, s'). What we get instead is that every single algorithm seems to have all kinds of experiment-specific details mixed in with the implementation of the algorithm itself. In the case of DQN, parts of the creation of the network, other setup of the algorithm, the entire training loop, and results logging are all mixed in together in a file named [simple.py](https://github.com/openai/baselines/blob/master/baselines/deepq/simple.py). If I want to compare the performance of DQN to the performance of some other algorithm, how can I be sure that they're evaluated in the same manner? 

3. Why is that file I mentioned in the point above named ""simple.py"" anyway? It seems anything but simple to me.

4. Why is the filename of the file in which a model will be saved after training hardcoded in simple.py? I may want to train and save multiple different DQN models, for instance different models for different environments. I'd like to be able to specify the model filename as parameter.

5. There is a relatively simple example for how to train DQN on Atari environments in [run_atari.py](https://github.com/openai/baselines/blob/master/baselines/deepq/experiments/run_atari.py). Just like train_cartpole, this one doesn't include any ""experiment setup"" code, just calls into simple.py for that. But there also seems to be a more complicated version in [atari/train.py](https://github.com/openai/baselines/blob/master/baselines/deepq/experiments/atari/train.py). At first glance, this seems to have a **massive** amount of code duplication from simple.py. What are the differences? I don't know, other than that the [DQN documentation](https://github.com/openai/baselines/tree/master/baselines/deepq) says that the second file has a ""more robust setup for training at scale"". I guess I'll have to compare the files line-by-line if I want to figure out what that means. I didn't do that yet, but I suspect this may be a symptom caused by the fact that algorithm and experiment-specific code are not separated; need to duplicate a lot of code if you want a slightly different experiment setup.

6. There are lots of unresolved issues and pull requests on github. For example, according to [this pull request](https://github.com/openai/baselines/pull/174), there's a bug in the implementation of Prioritized Experience Replay. That pull request has been open for two months now. I get that the authors have no obligation to address any of these, and are probably very busy with other things. However, the original [blog post](https://blog.openai.com/openai-baselines-dqn/) about the baselines repository stated that the goal of releasing this was basically to help make sure that researchers can use solid, bug-free implementations of these algorithms. Now I'm not sure, is the person who wrote that pull request correct, is the implementation indeed bugged? I'll have to spend a lot of time figuring that out first, and if it is indeed bugged, I'll also now have to create a fork of the baselines repository and implement the fix in there since I have no idea how long it's going to take till it gets merged into the main repository.


I don't mean to be overly harsh here, I do still think the idea of this repository is great and very important, and I don't know of any better alternatives. I suppose that's exactly why I felt like putting in words exactly what problems I have. I'm just curious if others share my opinion on some of these points, or if I'm just too stupid to make proper use of the repository. ",14,37
970,2017-12-21,2017,12,21,0,7l240q,[D] Anyone working on or aware of ML algorithms that detect fake video? Making a documentary about the topic!,https://www.reddit.com/r/MachineLearning/comments/7l240q/d_anyone_working_on_or_aware_of_ml_algorithms/,crazycoala,1513784179,"Hey /r/machinelearning!

I'm a filmmaker making a short documentary about fake video and am interested in talking to anyone who is working on software solutions to detect it. 

Here's an example of what machine learning can produce: https://grail.cs.washington.edu/projects/AudioToObama/ 

It's incredible tech but the implications in the future are terrifying, and it seems crucial that we have some way of detecting fake videos and verifying real ones.

If anyone is aware of any software that exists already, I'd love to check it out. I've seen some cool stuff about detecting heart beats and blood flow in video but not much past that. 

Looking forward to learning from you all! 

Thanks!",8,3
971,2017-12-21,2017,12,21,0,7l26xz,help determining what AI do i need,https://www.reddit.com/r/MachineLearning/comments/7l26xz/help_determining_what_ai_do_i_need/,fr1d4y_,1513784918,[removed],0,1
972,2017-12-21,2017,12,21,0,7l28cq,[P] How Airbnb is pushing the limits of machine learning,https://www.reddit.com/r/MachineLearning/comments/7l28cq/p_how_airbnb_is_pushing_the_limits_of_machine/,yourbasicgeek,1513785292,,7,0
973,2017-12-21,2017,12,21,0,7l28iq,"Simple Questions Thread December 20, 2017",https://www.reddit.com/r/MachineLearning/comments/7l28iq/simple_questions_thread_december_20_2017/,AutoModerator,1513785332,[removed],0,1
974,2017-12-21,2017,12,21,0,7l28nv,[P] TensorFlow implementation of 'Attention Is All You Need (2017. 6)',https://www.reddit.com/r/MachineLearning/comments/7l28nv/p_tensorflow_implementation_of_attention_is_all/,DongjunLee,1513785370,,7,26
975,2017-12-21,2017,12,21,1,7l2b6t,Needed feedback on my code for chunking data techniques in Named Entity Recognition(NER) using NLP libraries and algorithms.,https://www.reddit.com/r/MachineLearning/comments/7l2b6t/needed_feedback_on_my_code_for_chunking_data/,callMeSpacetime,1513785981,,0,1
976,2017-12-21,2017,12,21,1,7l2it9,Open-endedness: The last grand challenge youve never heard of,https://www.reddit.com/r/MachineLearning/comments/7l2it9/openendedness_the_last_grand_challenge_youve/,gradientflow,1513787859,,0,1
977,2017-12-21,2017,12,21,1,7l2jqr,Practical applications of reinforcement learning,https://www.reddit.com/r/MachineLearning/comments/7l2jqr/practical_applications_of_reinforcement_learning/,gradientflow,1513788103,,0,1
978,2017-12-21,2017,12,21,1,7l2o2o,[R] Query-Efficient Black-box Adversarial Examples,https://www.reddit.com/r/MachineLearning/comments/7l2o2o/r_queryefficient_blackbox_adversarial_examples/,[deleted],1513789181,[deleted],0,1
979,2017-12-21,2017,12,21,2,7l2oxj,[R] Partial Information Attacks on Real-world AI,https://www.reddit.com/r/MachineLearning/comments/7l2oxj/r_partial_information_attacks_on_realworld_ai/,loganengstrom,1513789377,,28,113
980,2017-12-21,2017,12,21,2,7l2vgo,The Saama blog is turning out to be a good resource on learning the nitty-gritty details of machine learning.,https://www.reddit.com/r/MachineLearning/comments/7l2vgo/the_saama_blog_is_turning_out_to_be_a_good/,[deleted],1513790907,[deleted],0,1
981,2017-12-21,2017,12,21,3,7l34io,I want to do a machine learing project as part of my academic project can any one guide or how to do a project.,https://www.reddit.com/r/MachineLearning/comments/7l34io/i_want_to_do_a_machine_learing_project_as_part_of/,vivekvittedy,1513793090,[removed],0,1
982,2017-12-21,2017,12,21,3,7l3did,[P] Few weeks ago I created a post on implementation of movie recommendation system in C. I have shared the project on GitHub now.,https://www.reddit.com/r/MachineLearning/comments/7l3did/p_few_weeks_ago_i_created_a_post_on/,new_username_again,1513795171,,1,5
983,2017-12-21,2017,12,21,3,7l3i7t,"I am training a deep learning model to rerank search engine results. Issues, PRs and suggestions are welcome!",https://www.reddit.com/r/MachineLearning/comments/7l3i7t/i_am_training_a_deep_learning_model_to_rerank/,[deleted],1513796279,[deleted],0,1
984,2017-12-21,2017,12,21,4,7l3l88,"[P] I am training a deep learning model to rerank search engine results. Issues, PRs and suggestions are welcome!",https://www.reddit.com/r/MachineLearning/comments/7l3l88/p_i_am_training_a_deep_learning_model_to_rerank/,JClub,1513796992,,6,0
985,2017-12-21,2017,12,21,4,7l3ouv,[P] Food Ingredient Reverse-Engineering Through Gradient Descent,https://www.reddit.com/r/MachineLearning/comments/7l3ouv/p_food_ingredient_reverseengineering_through/,jctestud,1513797791,,8,11
986,2017-12-21,2017,12,21,4,7l3r3h,[R] [1712.07040v1] The NarrativeQA Reading Comprehension Challenge,https://www.reddit.com/r/MachineLearning/comments/7l3r3h/r_171207040v1_the_narrativeqa_reading/,cherls,1513798323,,0,18
987,2017-12-21,2017,12,21,4,7l3rhn,Biases per node or per layer?,https://www.reddit.com/r/MachineLearning/comments/7l3rhn/biases_per_node_or_per_layer/,quaPok,1513798414,[removed],0,1
988,2017-12-21,2017,12,21,4,7l3xsn,Effectiveness of data,https://www.reddit.com/r/MachineLearning/comments/7l3xsn/effectiveness_of_data/,vinayakpahalwan,1513799939,[removed],0,1
989,2017-12-21,2017,12,21,5,7l47fa,[D] Chess with Portals and Impossible Go,https://www.reddit.com/r/MachineLearning/comments/7l47fa/d_chess_with_portals_and_impossible_go/,lymn,1513802188,"It seems to be the case that superhuman performance has been achieved in Chess and Go. However, perhaps this is only for the special cases of chess with boards that are realizable in a 2d euclidean space. We can imagine boards for these games of bounded size that admit no physically realizable analogue on our table. In the case of chess we can imagine there exists first a set S of ordered pair of edges, S = {({e,f},p) | e and f are edges on a square on the chess board, p exists in {0,1}. Edges e and f either run parallel to the line dividing the two sets of pieces or perpendicular. Let the white side of parellel lines and the left side (from the perspective of white) of perpendicular lines be labeled 1  and the black and right sides be labeled 2. If ({e,f}, 0) exists in S, then a piece that crosses edge e from side 1 emerges through edge f at side 2. if p equals 1, then crossing from side 1 causes the piece to emerge on side 1 at the receiving portal. Such a chess board could be physically realized by adding ribbon-like bridges between arbitrary edges on the chess board. A more comprehensive construction could handle bishops and the like, which travel through vertexes instead of edges.

A similar idea is possible in Go. Suppose we take the board and in addition, we specify that points on the grid that are not adjacent have an extra-dimensional adjacency relation. We imagine a set S = {{p,q} such that p and q are points on the Go board} and if {p,q} exists in S, then p and q are considered adjacent for the purpose of counting stones and territory. The dots on the physical Go board are now a 2 projection of a higher dimensional board or point cloud.

**Here's the argument.** I believe that these non-local Chess and Go variants, at least if the size of the sets S are kept small, can be played with proficiency and perhaps mastery by skilled players with minimal learning time. Furthermore, I expect that Deep Blue (or whatever is the state of the art in chess nowadays) or Alpha Go, would have to throw out their training each time to accommodate each possible board variant. The situation looks even more dire for the artificial players if set S is allowed to change over the course of the game.

I suspect the ability to adapt experience in regular Go and Chess to these non-local variants might be the difference between a machine that plays a board game and a being that understands a board game. We could imagine that set S must be found by trial and error, by queuing a chess move and seeing where the piece actually ends up, or in the case of Go if the referee removes stone formations in accordance with the adjacency represented in set S which is latent to the players.

If a machine could play Impossible Go or Chess with Portals, I would be convinced that it is really thinking, or at least really understands the games, in a way qualitatively different than that of the current state of the art for the standard games (which do not seem to think but merely compute). However, I can't really articulate what about these nonlocal games makes them more than just another computational puzzle, besides their hyper-dimensionality and seeming intractability to current methods.",10,0
990,2017-12-21,2017,12,21,5,7l4846,Should we normalise data before multi linear regression with gradient descent?,https://www.reddit.com/r/MachineLearning/comments/7l4846/should_we_normalise_data_before_multi_linear/,iwanttodiequick,1513802358,[removed],0,1
991,2017-12-21,2017,12,21,5,7l48fc,AWS Machine Learning - is it good?,https://www.reddit.com/r/MachineLearning/comments/7l48fc/aws_machine_learning_is_it_good/,JackMizel,1513802433,[removed],0,1
992,2017-12-21,2017,12,21,5,7l491g,[D] Four lessons learned while hunting for a data scientist role,https://www.reddit.com/r/MachineLearning/comments/7l491g/d_four_lessons_learned_while_hunting_for_a_data/,jmgris,1513802583,,11,11
993,2017-12-21,2017,12,21,6,7l4ejw,[D] What useful thing do RBMs learn other than association of training-data by dot-product?,https://www.reddit.com/r/MachineLearning/comments/7l4ejw/d_what_useful_thing_do_rbms_learn_other_than/,BenRayfield,1513803859,"There is something AI researchers have come to expect from RBMs, depend on the RBMs doing that, but seem unable to explain what the RBMs are doing for them, other than similarity by dot-product.

Dont just say ""interpolation between data points"" if you cant back it up with math words like vector, dot-product, permutation, sigmoid, etc.

There are some datasets which may be generated by a very simple function or simple part of the world, and an RBM can be trained on parts of that dataset, leaving out other parts, and it predicts some of other parts even though they are not similar by dot-product to anything trained.

So by what math do we define them (excluding things outside the data such as what generated them) as similar and not a mistake by the RBM?",6,0
994,2017-12-21,2017,12,21,6,7l4fmg,Could somebody explain to me the splitting criteria in a decision tree that is used for regression ?,https://www.reddit.com/r/MachineLearning/comments/7l4fmg/could_somebody_explain_to_me_the_splitting/,iwanttodiequick,1513804113,[removed],0,1
995,2017-12-21,2017,12,21,6,7l4hs7,Find your next machine learning job,https://www.reddit.com/r/MachineLearning/comments/7l4hs7/find_your_next_machine_learning_job/,[deleted],1513804635,[deleted],0,1
996,2017-12-21,2017,12,21,6,7l4qf2,Can you suggest some interesting business datasets?,https://www.reddit.com/r/MachineLearning/comments/7l4qf2/can_you_suggest_some_interesting_business_datasets/,amoun1365,1513806770,[removed],0,1
997,2017-12-21,2017,12,21,6,7l4qw4,[D] What are your personal favourite CNN / deep learning for vision papers?,https://www.reddit.com/r/MachineLearning/comments/7l4qw4/d_what_are_your_personal_favourite_cnn_deep/,NicolasGuacamole,1513806883,"Personally I've just been trying to organise my reading a little more recently so have been collecting together some of my favourite papers in this area.

I was wondering what other peoples favourites were, or what they considered most seminal (of course if they are interested in this area at all).

If anyone had any contributions it'd be great to know.",6,6
998,2017-12-21,2017,12,21,7,7l4y99,[P] Interactive Segmentation with Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/7l4y99/p_interactive_segmentation_with_convolutional/,arnaud13,1513808673,,0,2
999,2017-12-21,2017,12,21,7,7l51eq,[P] - Machine Learning Careers,https://www.reddit.com/r/MachineLearning/comments/7l51eq/p_machine_learning_careers/,jjbelt,1513809474,,0,0
1000,2017-12-21,2017,12,21,7,7l52zp,[D] Two months exploring deep learning and computer vision,https://www.reddit.com/r/MachineLearning/comments/7l52zp/d_two_months_exploring_deep_learning_and_computer/,Loggerny,1513809895,,10,13
1001,2017-12-21,2017,12,21,7,7l556f,What approaches could be used to teach a robot to make the right brush strokes to reproduce a painting?,https://www.reddit.com/r/MachineLearning/comments/7l556f/what_approaches_could_be_used_to_teach_a_robot_to/,topomorto,1513810460,[removed],0,1
1002,2017-12-21,2017,12,21,8,7l5c2k,SKlearn MLP Classifier Raw Values,https://www.reddit.com/r/MachineLearning/comments/7l5c2k/sklearn_mlp_classifier_raw_values/,Barrotenz,1513812246,[removed],0,1
1003,2017-12-21,2017,12,21,9,7l5kvr,Explanation of ML algorithms that continue to learn upon deployment?,https://www.reddit.com/r/MachineLearning/comments/7l5kvr/explanation_of_ml_algorithms_that_continue_to/,YouBleedOrange,1513814573,[removed],0,1
1004,2017-12-21,2017,12,21,9,7l5mly,[D] Applying pix2pix to The Snowman,https://www.reddit.com/r/MachineLearning/comments/7l5mly/d_applying_pix2pix_to_the_snowman/,audio-nerd,1513815027,,5,8
1005,2017-12-21,2017,12,21,11,7l6gcm,Want to get into machine learning. Don't know where to start.,https://www.reddit.com/r/MachineLearning/comments/7l6gcm/want_to_get_into_machine_learning_dont_know_where/,Airrocket,1513823578,[removed],0,1
1006,2017-12-21,2017,12,21,12,7l6tjk,What are your favourite GANs for generating fake images / text / ... ?,https://www.reddit.com/r/MachineLearning/comments/7l6tjk/what_are_your_favourite_gans_for_generating_fake/,_hypo,1513827612,[removed],0,1
1007,2017-12-21,2017,12,21,12,7l6utf,My low GPA story. Do I have any shot at a Machine learning masters program?,https://www.reddit.com/r/MachineLearning/comments/7l6utf/my_low_gpa_story_do_i_have_any_shot_at_a_machine/,third_dude,1513827994,[removed],0,1
1008,2017-12-21,2017,12,21,12,7l6vl8,What should be noticed during the use of emulsifying mahcine?,https://www.reddit.com/r/MachineLearning/comments/7l6vl8/what_should_be_noticed_during_the_use_of/,jumitop,1513828240,,1,1
1009,2017-12-21,2017,12,21,13,7l70z2,Multi-labels Neural Networks to Multi-class Neural Network,https://www.reddit.com/r/MachineLearning/comments/7l70z2/multilabels_neural_networks_to_multiclass_neural/,dare_dick,1513829966,[removed],0,1
1010,2017-12-21,2017,12,21,13,7l71s4,[R] CARLA: Open-source simulator for autonomous driving research,https://www.reddit.com/r/MachineLearning/comments/7l71s4/r_carla_opensource_simulator_for_autonomous/,downtownslim,1513830216,,4,84
1011,2017-12-21,2017,12,21,14,7l7ew6,"A complete shampoo, liquid soap production line, including what machines?",https://www.reddit.com/r/MachineLearning/comments/7l7ew6/a_complete_shampoo_liquid_soap_production_line/,jumitop,1513834554,,1,1
1012,2017-12-21,2017,12,21,14,7l7gbg,The Saama blog has become a really good place to learn about the nitty-gritty parts of ML that many resources skip.,https://www.reddit.com/r/MachineLearning/comments/7l7gbg/the_saama_blog_has_become_a_really_good_place_to/,ChallengeableDatum,1513835037,,0,1
1013,2017-12-21,2017,12,21,14,7l7ggj,IQ Test | Are you genius | 5 Simple Question EP#2,https://www.reddit.com/r/MachineLearning/comments/7l7ggj/iq_test_are_you_genius_5_simple_question_ep2/,anowarul147,1513835084,,0,1
1014,2017-12-21,2017,12,21,15,7l7lau,Google Mapss Moat: How far ahead of Apple Maps is Google Maps? (December 2017 Update),https://www.reddit.com/r/MachineLearning/comments/7l7lau/google_mapss_moat_how_far_ahead_of_apple_maps_is/,brockl33,1513836691,,0,1
1015,2017-12-21,2017,12,21,15,7l7n0f,Dependencies on Latent variables in Variational Bayes Models,https://www.reddit.com/r/MachineLearning/comments/7l7n0f/dependencies_on_latent_variables_in_variational/,arahmadi62,1513837298,[removed],0,1
1016,2017-12-21,2017,12,21,15,7l7nzj,[P] Demo Website For the Diagnosis of 176 Skin Diseases.,https://www.reddit.com/r/MachineLearning/comments/7l7nzj/p_demo_website_for_the_diagnosis_of_176_skin/,whria78,1513837637,"Hello. 

I made a automated skin disease diagnosis DEMO website based on deep learning algorithm (Model Dermatology; http://ModelDerm.com). ResNet152 and VGG19 were used as a CNN model, around 300,000 images (179 class;176 skin disorders) were used as a trainining dataset. The training images were collected from 4 university hospitals in Korea. This CNN model is the successor to my onychomycosis model (http://nail.medicalphoto.org).

The web-based test platform provides 3 differential diagnosis after analyzing image. Because there are many false positive diagnosis, the diagnosis predicted by the CNN should not be used as a confirmative diagnosis. In addition, the model has a limitation that it cannot recognize normal or unspecific lesion well, and the photograph should be taken in a bright place without shade.

I hope the differential diagnosis predicted by the CNN would help to find the final diagnosis. Thank you.
",10,7
1017,2017-12-21,2017,12,21,15,7l7o1a,How can I maintain aluminum alloy doors and windows?,https://www.reddit.com/r/MachineLearning/comments/7l7o1a/how_can_i_maintain_aluminum_alloy_doors_and/,jumitop,1513837652,,1,1
1018,2017-12-21,2017,12,21,15,7l7rbj,Poultry dung pellet production line,https://www.reddit.com/r/MachineLearning/comments/7l7rbj/poultry_dung_pellet_production_line/,amylee516,1513838865,,0,1
1019,2017-12-21,2017,12,21,15,7l7rrm,[P] Reverse Curriculum Generation for Reinforcement Learning Agents,https://www.reddit.com/r/MachineLearning/comments/7l7rrm/p_reverse_curriculum_generation_for_reinforcement/,Jackal008,1513839037,,9,20
1020,2017-12-21,2017,12,21,15,7l7ruq,"[P] k-server, part 2: continuous time mirror descent",https://www.reddit.com/r/MachineLearning/comments/7l7ruq/p_kserver_part_2_continuous_time_mirror_descent/,Jackal008,1513839074,,0,7
1021,2017-12-21,2017,12,21,15,7l7t0m,[D] Is there any website where I can find manual implementation of all ML algorithms found in scikit learn or equivalent R packages?,https://www.reddit.com/r/MachineLearning/comments/7l7t0m/d_is_there_any_website_where_i_can_find_manual/,rowanobrian,1513839506,"I use linear reg, decision trees, xgboost, random forest, MARS etc etc, i know how they work, but I feel real way to get to the core of anything is by coding. I have coded gradient descent, momentum, linear reg etc, but I am finding it a bit difficult to do for some other algorithms. 
I am fine with both R and python.
Can you direct me to any such website/collection of websites which have manual implementations of most of the machine learning algorithms.
Thanks
",9,4
1022,2017-12-21,2017,12,21,16,7l7vdq,Pistachio Nut Shell Opening Machine|Pistachio Nut Shell Opener Equipment for Sale,https://www.reddit.com/r/MachineLearning/comments/7l7vdq/pistachio_nut_shell_opening_machinepistachio_nut/,gelserena,1513840372,,1,1
1023,2017-12-21,2017,12,21,16,7l7yxg,"[D] So, who tried mixture of softmaxes on text translation or generation (optionally with Transformer)?",https://www.reddit.com/r/MachineLearning/comments/7l7yxg/d_so_who_tried_mixture_of_softmaxes_on_text/,[deleted],1513841729,[deleted],0,1
1024,2017-12-21,2017,12,21,17,7l833k,[P] Tensorflow implementation of Curriculum Adaptive Sampling for Extreme Data Imbalance (MICCAI 2017) / LUNA16 Tutorial,https://www.reddit.com/r/MachineLearning/comments/7l833k/p_tensorflow_implementation_of_curriculum/,taki0112,1513843408,,0,12
1025,2017-12-21,2017,12,21,17,7l85jn,[R] Modern Theory of Deep Learning: Why Does It Work so Well,https://www.reddit.com/r/MachineLearning/comments/7l85jn/r_modern_theory_of_deep_learning_why_does_it_work/,wjsfu,1513844411,,10,21
1026,2017-12-21,2017,12,21,18,7l8dyh,Machine Learning: An Innovation in Teenage Age,https://www.reddit.com/r/MachineLearning/comments/7l8dyh/machine_learning_an_innovation_in_teenage_age/,mr_j_b,1513848130,,0,1
1027,2017-12-21,2017,12,21,18,7l8f7q,From complexity to simplicity ...,https://www.reddit.com/r/MachineLearning/comments/7l8f7q/from_complexity_to_simplicity/,akanimax,1513848709,"I had started this discussion earlier https://www.reddit.com/r/MachineLearning/comments/7kepnk/is_the_basic_fully_connected_neural_network_the/ 
where I used the ConvolutionalSeq2seq reserach paper to support the statement. 

I am currently working on nlp and this is another research work that I encountered -&gt; https://arxiv.org/abs/1706.03762
It's the ""Attention is all you need"" paper. I am pretty sure most of the folks would have already read it (reddit :)).

With this one in the light now, what do you think? Is it possible that the fully connected neural network is itself the key? What do you think about this ""Attention is all you need"" research? According to me, dropping lstms and rnns from NLP problems and replacing them with a simpler model is indeed a seminal research work.",2,2
1028,2017-12-21,2017,12,21,18,7l8gri,is it possible to generate vector graphs from images?,https://www.reddit.com/r/MachineLearning/comments/7l8gri/is_it_possible_to_generate_vector_graphs_from/,sshidy,1513849389,[removed],0,1
1029,2017-12-21,2017,12,21,18,7l8hiy,Open data science west 2017,https://www.reddit.com/r/MachineLearning/comments/7l8hiy/open_data_science_west_2017/,stonedfox8,1513849737,,0,1
1030,2017-12-21,2017,12,21,19,7l8jrm,Automatic Cashew Nut Shelling Machine|Complete Cashew Processing Line Video,https://www.reddit.com/r/MachineLearning/comments/7l8jrm/automatic_cashew_nut_shelling_machinecomplete/,gelserena,1513850729,,1,1
1031,2017-12-21,2017,12,21,19,7l8rh6,"Centreless Polishing Machines,Tube Polishing Machine Manufacturers-Grind Master",https://www.reddit.com/r/MachineLearning/comments/7l8rh6/centreless_polishing_machinestube_polishing/,shekhart,1513853996,,0,1
1032,2017-12-21,2017,12,21,20,7l8we2,[N] Khronos Group Releases NNEF 1.0 Standard for Neural Network Exchange,https://www.reddit.com/r/MachineLearning/comments/7l8we2/n_khronos_group_releases_nnef_10_standard_for/,LiteFatSushi,1513855973,,13,17
1033,2017-12-21,2017,12,21,21,7l91tl,[N] 2017: DeepMind's year in review,https://www.reddit.com/r/MachineLearning/comments/7l91tl/n_2017_deepminds_year_in_review/,Jackal008,1513858042,,3,27
1034,2017-12-21,2017,12,21,21,7l938a,[N] StarCraft AI tournament round-robin launched today,https://www.reddit.com/r/MachineLearning/comments/7l938a/n_starcraft_ai_tournament_roundrobin_launched/,michal_sustr,1513858507,,8,38
1035,2017-12-21,2017,12,21,21,7l98l6,Almond Strip Cutting Machine|Peanut Dry Fruit Strips Cutter Machines,https://www.reddit.com/r/MachineLearning/comments/7l98l6/almond_strip_cutting_machinepeanut_dry_fruit/,gelserena,1513860403,,1,1
1036,2017-12-21,2017,12,21,22,7l9cks,I recently spoke about Tensorflow at a Ruby conference,https://www.reddit.com/r/MachineLearning/comments/7l9cks/i_recently_spoke_about_tensorflow_at_a_ruby/,tensorflow_rb,1513861752,,0,1
1037,2017-12-21,2017,12,21,22,7l9eih,How machine learning can translate chicken chatter and improve farming,https://www.reddit.com/r/MachineLearning/comments/7l9eih/how_machine_learning_can_translate_chicken/,zemcunha,1513862372,,0,1
1038,2017-12-21,2017,12,21,23,7l9pvq,Noob to machine learning,https://www.reddit.com/r/MachineLearning/comments/7l9pvq/noob_to_machine_learning/,Na-Qeeb,1513865898,[removed],0,1
1039,2017-12-21,2017,12,21,23,7l9rxe,Recommendations about machine learning and system architectures,https://www.reddit.com/r/MachineLearning/comments/7l9rxe/recommendations_about_machine_learning_and_system/,iacolippo,1513866520,[removed],0,1
1040,2017-12-21,2017,12,21,23,7l9vjb,[1712.07420] Finding Competitive Network Architectures Within a Day Using UCT,https://www.reddit.com/r/MachineLearning/comments/7l9vjb/171207420_finding_competitive_network/,pinouchon,1513867581,,0,1
1041,2017-12-22,2017,12,22,0,7l9yju,[R] Detailed notes of NIPS 2017 conference,https://www.reddit.com/r/MachineLearning/comments/7l9yju/r_detailed_notes_of_nips_2017_conference/,zephyrzilla,1513868450,,2,15
1042,2017-12-22,2017,12,22,0,7la1ez,[R] Great Deep Learning Achievements Over the Past Year,https://www.reddit.com/r/MachineLearning/comments/7la1ez/r_great_deep_learning_achievements_over_the_past/,defense1011,1513869213,,15,220
1043,2017-12-22,2017,12,22,0,7la31s,Open source alternative machine learning algorithms to neural networks,https://www.reddit.com/r/MachineLearning/comments/7la31s/open_source_alternative_machine_learning/,rodburns,1513869671,,0,1
1044,2017-12-22,2017,12,22,0,7la3ux,[R] ComboGAN: Unrestrained Scalability for Image Domain Translation,https://www.reddit.com/r/MachineLearning/comments/7la3ux/r_combogan_unrestrained_scalability_for_image/,ginsunuva,1513869898,,17,15
1045,2017-12-22,2017,12,22,0,7la9a9,"[N] Weekly Machine Learning Opensource Roundup  Dec. 21, 2017",https://www.reddit.com/r/MachineLearning/comments/7la9a9/n_weekly_machine_learning_opensource_roundup_dec/,stkim1,1513871334,,0,1
1046,2017-12-22,2017,12,22,1,7lachp,Almond Soy Milk Maker Machine|Grinding Machines Suppliers,https://www.reddit.com/r/MachineLearning/comments/7lachp/almond_soy_milk_maker_machinegrinding_machines/,gelserena,1513872137,,1,1
1047,2017-12-22,2017,12,22,1,7laclm,MTDeep: Boosting the Security of Deep Neural Nets Against Adversarial Attacks with Moving Target Defense,https://www.reddit.com/r/MachineLearning/comments/7laclm/mtdeep_boosting_the_security_of_deep_neural_nets/,Hizachi,1513872167,,0,1
1048,2017-12-22,2017,12,22,1,7lajs5,Questions to people who know about neural network.,https://www.reddit.com/r/MachineLearning/comments/7lajs5/questions_to_people_who_know_about_neural_network/,Gussebb,1513873962,[removed],0,1
1049,2017-12-22,2017,12,22,1,7lam95,When will Andrew Ng's last deeplearning.ai course be released?!,https://www.reddit.com/r/MachineLearning/comments/7lam95/when_will_andrew_ngs_last_deeplearningai_course/,AvatarUltima7,1513874567,[removed],0,1
1050,2017-12-22,2017,12,22,1,7lanku,"Caffe, Caffe2, Volta and TensorCores. Please Help",https://www.reddit.com/r/MachineLearning/comments/7lanku/caffe_caffe2_volta_and_tensorcores_please_help/,soulslicer0,1513874883,[removed],0,1
1051,2017-12-22,2017,12,22,1,7lapo2,Alternative to Udacity's Self Driving Car simulator and Microsoft AirSim?,https://www.reddit.com/r/MachineLearning/comments/7lapo2/alternative_to_udacitys_self_driving_car/,abhishekwl,1513875380,[removed],0,1
1052,2017-12-22,2017,12,22,1,7laqgr,[N] Dynet 2.0.2 released,https://www.reddit.com/r/MachineLearning/comments/7laqgr/n_dynet_202_released/,Mandrathax,1513875572,,0,8
1053,2017-12-22,2017,12,22,2,7lasl4,How do I create a confusion matrix for a neural net that classifies spam emails?,https://www.reddit.com/r/MachineLearning/comments/7lasl4/how_do_i_create_a_confusion_matrix_for_a_neural/,paathurnaxe,1513876072,[removed],0,1
1054,2017-12-22,2017,12,22,2,7lau8q,merry Christmas from agrorobot,https://www.reddit.com/r/MachineLearning/comments/7lau8q/merry_christmas_from_agrorobot/,fbnsantos,1513876483,[removed],0,1
1055,2017-12-22,2017,12,22,2,7lb1va,Where to start with feature selection?,https://www.reddit.com/r/MachineLearning/comments/7lb1va/where_to_start_with_feature_selection/,sayantabonny,1513878308,[removed],0,1
1056,2017-12-22,2017,12,22,3,7lb5n1,[D] Chainer vs PyTorch?,https://www.reddit.com/r/MachineLearning/comments/7lb5n1/d_chainer_vs_pytorch/,andyandy16,1513879224,"Both have dynamic graphs, and Chainer came first - why was PyTorch created given Chainer already existed? ",13,18
1057,2017-12-22,2017,12,22,3,7lbexe,Google + MIT: How machine learning will accelerate data management systems,https://www.reddit.com/r/MachineLearning/comments/7lbexe/google_mit_how_machine_learning_will_accelerate/,gradientflow,1513881434,,0,1
1058,2017-12-22,2017,12,22,3,7lbiol,"Thoughts on Meta Learning Shared Hierarchies, and this paper?",https://www.reddit.com/r/MachineLearning/comments/7lbiol/thoughts_on_meta_learning_shared_hierarchies_and/,jfishersolutions,1513882337,,0,1
1059,2017-12-22,2017,12,22,4,7lblwq,Can anyone point me to any open code on Deep Recurrent Q- networks for OpenAI environments?,https://www.reddit.com/r/MachineLearning/comments/7lblwq/can_anyone_point_me_to_any_open_code_on_deep/,abhik_singla,1513883092,[removed],0,1
1060,2017-12-22,2017,12,22,4,7lbrr5,Looking for a simulation study on kernel SVMs for two-group classification on data with 10-15 variables.,https://www.reddit.com/r/MachineLearning/comments/7lbrr5/looking_for_a_simulation_study_on_kernel_svms_for/,WhenIntegralsAttack,1513884487,[removed],0,1
1061,2017-12-22,2017,12,22,4,7lbtxw,[N] NVIDIAs New Policy Limits GeForce Data Center Usage: Universities and Research Centers In A Pinch,https://www.reddit.com/r/MachineLearning/comments/7lbtxw/n_nvidias_new_policy_limits_geforce_data_center/,darkconfidantislife,1513885021,,64,81
1062,2017-12-22,2017,12,22,4,7lbuhu,Generic (and fundamental) optimization problems / challenges for machine learning,https://www.reddit.com/r/MachineLearning/comments/7lbuhu/generic_and_fundamental_optimization_problems/,FontofFortunes,1513885167,[removed],0,1
1063,2017-12-22,2017,12,22,4,7lbvo5,[D] Question regarding discrete-series data prediction,https://www.reddit.com/r/MachineLearning/comments/7lbvo5/d_question_regarding_discreteseries_data/,yevbev,1513885460,Currently I am dealing with a problem where I have data that is essentially discrete-time series. The progression of the features depends on the initial starting point and previous values. The data is highly non-linearly correlated. I have been using a Kalman Filter for this problem and been able to detect outliers using the Covariance. I would like to use ML to maybe learn a non-linear relationship that the KF cannot. If I use an LSTM and train it how do I deal with the fact that I have many different runs from different starting points? ,6,1
1064,2017-12-22,2017,12,22,4,7lbzdj,How we used ML to build a self driving car from scratch,https://www.reddit.com/r/MachineLearning/comments/7lbzdj/how_we_used_ml_to_build_a_self_driving_car_from/,peteystep,1513886337,,0,1
1065,2017-12-22,2017,12,22,5,7lcah6,[R] Investigating Human Priors for Playing Video Games,https://www.reddit.com/r/MachineLearning/comments/7lcah6/r_investigating_human_priors_for_playing_video/,visarga,1513889039,,4,4
1066,2017-12-22,2017,12,22,6,7lcges,Question related to principal component analysis,https://www.reddit.com/r/MachineLearning/comments/7lcges/question_related_to_principal_component_analysis/,shWkddlfkd,1513890447,[removed],0,1
1067,2017-12-22,2017,12,22,7,7lcwun,Mastering ML with scikit learn - Gavin Hackeling (packt publishin),https://www.reddit.com/r/MachineLearning/comments/7lcwun/mastering_ml_with_scikit_learn_gavin_hackeling/,MLbeginner96,1513894479,[removed],0,1
1068,2017-12-22,2017,12,22,7,7ld4yx,Help me with ideas for master thesis in ML.,https://www.reddit.com/r/MachineLearning/comments/7ld4yx/help_me_with_ideas_for_master_thesis_in_ml/,AppelsinJuice32,1513896562,[removed],0,1
1069,2017-12-22,2017,12,22,7,7ld76p,[D] Considerations for Sensitive Data within Machine Learning Datasets,https://www.reddit.com/r/MachineLearning/comments/7ld76p/d_considerations_for_sensitive_data_within/,fhoffa,1513897142,,0,2
1070,2017-12-22,2017,12,22,8,7ldbyp,"[D] Using sklearn, giving same data to both fit() and score() and getting poor accuracy (around .55). Is this normal or am I doing something wrong?",https://www.reddit.com/r/MachineLearning/comments/7ldbyp/d_using_sklearn_giving_same_data_to_both_fit_and/,Kinoxciv,1513898375,"Here's the code:

    clf = LogisticRegression()
    
    clf.fit(x_train, y_train)
    
    accuracy = clf.score(x_train, y_train)
    
    print(accuracy)

I expected accuracy to be pretty close to 1, since I'm feeding it the exact data it's been trained on, but instead accuracy is closer to .55.

Is this normal or did I something wrong here?",6,1
1071,2017-12-22,2017,12,22,8,7ldfgz,"Is this guy completely full of shit? If not, how has no one found this? (Aang: ""Superior, precise, scalable NLU for creating natural language interfaces"")",https://www.reddit.com/r/MachineLearning/comments/7ldfgz/is_this_guy_completely_full_of_shit_if_not_how/,[deleted],1513899320,,0,1
1072,2017-12-22,2017,12,22,8,7ldj02,What are some good resources to learn image classification?,https://www.reddit.com/r/MachineLearning/comments/7ldj02/what_are_some_good_resources_to_learn_image/,chubbyostrich,1513900323,[removed],0,1
1073,2017-12-22,2017,12,22,9,7ldm39,"Is this guy completely full of shit? If not, how has no one found this? (Aang: ""Superior, precise, scalable NLU for creating natural language interfaces"")",https://www.reddit.com/r/MachineLearning/comments/7ldm39/is_this_guy_completely_full_of_shit_if_not_how/,elbrown47,1513901220,,0,1
1074,2017-12-22,2017,12,22,9,7ldnak,[R] MUSE: Multilingual Unsupervised and Supervised Embeddings,https://www.reddit.com/r/MachineLearning/comments/7ldnak/r_muse_multilingual_unsupervised_and_supervised/,ofirpress,1513901495,,1,26
1075,2017-12-22,2017,12,22,11,7leg0v,[D] Has there been any studies on of ReLu still maintains it's advantaged over tanh/sigmoid when the layers are batch normalized?,https://www.reddit.com/r/MachineLearning/comments/7leg0v/d_has_there_been_any_studies_on_of_relu_still/,SGuptMachineLearning,1513909881,"The advantage Relu has over sigmoid/tanh is that at the high/low areas of the curve, the gradients get very small. 

However, batch normalization keeps everything at the middle of the curve. Is it still better to use ReLu at this point? ",32,21
1076,2017-12-22,2017,12,22,12,7lelx2,[D] Orthogonal weights,https://www.reddit.com/r/MachineLearning/comments/7lelx2/d_orthogonal_weights/,[deleted],1513911621,[deleted],2,2
1077,2017-12-22,2017,12,22,12,7lemre,Benchmarking the Titan V (Volta) GPU with TensorFlow,https://www.reddit.com/r/MachineLearning/comments/7lemre/benchmarking_the_titan_v_volta_gpu_with_tensorflow/,sabalaba,1513911839,,0,1
1078,2017-12-22,2017,12,22,12,7les6g,how to measure multiclass classification (not binary),https://www.reddit.com/r/MachineLearning/comments/7les6g/how_to_measure_multiclass_classification_not/,minsukheo,1513913499,,0,1
1079,2017-12-22,2017,12,22,13,7lf71l,Gradient descent vs. neuroeveolution,https://www.reddit.com/r/MachineLearning/comments/7lf71l/gradient_descent_vs_neuroeveolution/,savan77,1513918113,,0,1
1080,2017-12-22,2017,12,22,14,7lfa0a,Almond Slicer Machine|Slicing Almond Machinery for Sale,https://www.reddit.com/r/MachineLearning/comments/7lfa0a/almond_slicer_machineslicing_almond_machinery_for/,gelserena,1513919085,,1,1
1081,2017-12-22,2017,12,22,14,7lfeqn,Introduction of Hop Field Neural Network,https://www.reddit.com/r/MachineLearning/comments/7lfeqn/introduction_of_hop_field_neural_network/,munishmaxtech,1513920657,,0,1
1082,2017-12-22,2017,12,22,15,7lfm9d,What should be included in an undergraduate Data Science degree program?,https://www.reddit.com/r/MachineLearning/comments/7lfm9d/what_should_be_included_in_an_undergraduate_data/,eternal-golden-braid,1513923232,[removed],0,1
1083,2017-12-22,2017,12,22,15,7lfmmw,John McCarthy's good old homepage at Stanford. Now archived.,https://www.reddit.com/r/MachineLearning/comments/7lfmmw/john_mccarthys_good_old_homepage_at_stanford_now/,norman-osborn,1513923361,,0,1
1084,2017-12-22,2017,12,22,15,7lfo0w,[R] On the Convergence of Adam and Beyond,https://www.reddit.com/r/MachineLearning/comments/7lfo0w/r_on_the_convergence_of_adam_and_beyond/,downtownslim,1513923883,,30,41
1085,2017-12-22,2017,12,22,15,7lfsp8,Organic waste composting machine,https://www.reddit.com/r/MachineLearning/comments/7lfsp8/organic_waste_composting_machine/,amylee516,1513925743,,0,1
1086,2017-12-22,2017,12,22,16,7lfwjn,Almond Cow Milk Making Machine|Grinding Machinery for Sale,https://www.reddit.com/r/MachineLearning/comments/7lfwjn/almond_cow_milk_making_machinegrinding_machinery/,gelserena,1513927194,,1,1
1087,2017-12-22,2017,12,22,16,7lfwoi,[R] Word Translation Without Parallel Data,https://www.reddit.com/r/MachineLearning/comments/7lfwoi/r_word_translation_without_parallel_data/,visarga,1513927239,,8,10
1088,2017-12-22,2017,12,22,18,7lgec1,Solar Power Plant Consultants in India AvantGarde is one of the leading engineering industries in Solar Power Plant consultants in India. #Solar #power #plant #consultants #India #AvantGarde,https://www.reddit.com/r/MachineLearning/comments/7lgec1/solar_power_plant_consultants_in_india_avantgarde/,Pojavsbuju2106,1513934673,,0,1
1089,2017-12-22,2017,12,22,18,7lgghg,"Implementation of paper ""GibbsNet: Iterative Adversarial Inference for Deep Graphical Models"" in PyTorch",https://www.reddit.com/r/MachineLearning/comments/7lgghg/implementation_of_paper_gibbsnet_iterative/,[deleted],1513935549,[deleted],0,1
1090,2017-12-22,2017,12,22,18,7lggux,15 machine learning open courses from 20 leading researchers,https://www.reddit.com/r/MachineLearning/comments/7lggux/15_machine_learning_open_courses_from_20_leading/,[deleted],1513935702,,0,1
1091,2017-12-22,2017,12,22,18,7lgh00,Non-Probabilistic/sparse Reinforcement Learning algorithms for Neural Nets ?,https://www.reddit.com/r/MachineLearning/comments/7lgh00/nonprobabilisticsparse_reinforcement_learning/,tar_paulin,1513935760,[removed],0,1
1092,2017-12-22,2017,12,22,18,7lghvw,[P] GibbsNet: Iterative Adversarial Inference for Deep Graphical Models in PyTorch,https://www.reddit.com/r/MachineLearning/comments/7lghvw/p_gibbsnet_iterative_adversarial_inference_for/,wlwkgus,1513936154,,8,10
1093,2017-12-22,2017,12,22,19,7lgjg7,Create an Algorithm-Anyone?,https://www.reddit.com/r/MachineLearning/comments/7lgjg7/create_an_algorithmanyone/,modojojo,1513936830,[removed],0,1
1094,2017-12-22,2017,12,22,19,7lgm0o,In What Ways Is Machine Learning Overrated?,https://www.reddit.com/r/MachineLearning/comments/7lgm0o/in_what_ways_is_machine_learning_overrated/,mr_j_b,1513937864,,0,1
1095,2017-12-22,2017,12,22,19,7lgn6z,What is the typical background for Google AI Residence program successful applications ?,https://www.reddit.com/r/MachineLearning/comments/7lgn6z/what_is_the_typical_background_for_google_ai/,brunoeducrsantos,1513938355,[removed],0,1
1096,2017-12-22,2017,12,22,19,7lgoin,[D] 15 machine learning courses by 20 leading researchers,https://www.reddit.com/r/MachineLearning/comments/7lgoin/d_15_machine_learning_courses_by_20_leading/,seanDL_,1513938945,[removed],4,1
1097,2017-12-22,2017,12,22,20,7lgt2p,[D] 15 Machine Learning Online Courses and Tutorials,https://www.reddit.com/r/MachineLearning/comments/7lgt2p/d_15_machine_learning_online_courses_and_tutorials/,seanDL_,1513940895,,36,143
1098,2017-12-22,2017,12,22,21,7lh0rw,Image Annotation for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7lh0rw/image_annotation_for_machine_learning/,trainingdata,1513944092,,0,1
1099,2017-12-22,2017,12,22,21,7lh11p,"3 And 5 Ply Corrugated Board Production Line, Fingerless Corrugation Machine Manufacturers &amp; Exporters",https://www.reddit.com/r/MachineLearning/comments/7lh11p/3_and_5_ply_corrugated_board_production_line/,idea_amritsar,1513944199,,1,1
1100,2017-12-22,2017,12,22,22,7lhdaq,What can the INTEL Movidius Compute stick really do?,https://www.reddit.com/r/MachineLearning/comments/7lhdaq/what_can_the_intel_movidius_compute_stick_really/,brin_tc,1513948612,[removed],0,1
1101,2017-12-22,2017,12,22,22,7lhf31,EEG data - which skills are required?,https://www.reddit.com/r/MachineLearning/comments/7lhf31/eeg_data_which_skills_are_required/,Thustrax,1513949246,[removed],0,1
1102,2017-12-22,2017,12,22,22,7lhjtp,I've tried 100 times to show my game at Reddit and never succeed,https://www.reddit.com/r/MachineLearning/comments/7lhjtp/ive_tried_100_times_to_show_my_game_at_reddit_and/,gamescodedogs,1513950843,,0,1
1103,2017-12-23,2017,12,23,0,7lhxfu,[D] What do you guys think is the most productive development IDE and plugin combo is for ML/AI work?,https://www.reddit.com/r/MachineLearning/comments/7lhxfu/d_what_do_you_guys_think_is_the_most_productive/,that_one_ai_nerd,1513954893,I used Sublime for the longest time but I want to find an environment that is less bare-bones and plugins specifically built to help out with AI development to increase my productivity. Excited to read! Thanks!,23,4
1104,2017-12-23,2017,12,23,0,7li02j,Overarching trends and applications at NIPS,https://www.reddit.com/r/MachineLearning/comments/7li02j/overarching_trends_and_applications_at_nips/,svpadd2,1513955596,,0,1
1105,2017-12-23,2017,12,23,0,7li2fn,[D] What's the best way to gain an understanding of how to properly shape and process data across a large variety of algorithms?,https://www.reddit.com/r/MachineLearning/comments/7li2fn/d_whats_the_best_way_to_gain_an_understanding_of/,that_one_ai_nerd,1513956243,"I've found that in my real world projects I do for customers, the data is so much more messy and unruly than datasets that people mess around with are, and I honestly have a harder time understanding all the different ways to process and shape and reshape data than I do huge systems with a bunch of neural networks and supporting software. Does anyone know a good resource on this, cause I can't seem to find a good explanation anywhere.

Thank you!!!",0,0
1106,2017-12-23,2017,12,23,0,7li3b2,"Suggestions for an interesting image feature project? (~5K Pinterest pins, various sizes, from ~20 folders)",https://www.reddit.com/r/MachineLearning/comments/7li3b2/suggestions_for_an_interesting_image_feature/,PullThisFinger,1513956491,,0,1
1107,2017-12-23,2017,12,23,2,7litzj,A List of Machine Learning (Ab)use Cases,https://www.reddit.com/r/MachineLearning/comments/7litzj/a_list_of_machine_learning_abuse_cases/,danielrm26,1513963450,,0,1
1108,2017-12-23,2017,12,23,2,7liwy5,[D] PyData - YouTube,https://www.reddit.com/r/MachineLearning/comments/7liwy5/d_pydata_youtube/,_alphamaximus_,1513964204,,0,1
1109,2017-12-23,2017,12,23,2,7liyzc,[D] Gabby Shklovsky - Random Forests Best Practices for the Business World,https://www.reddit.com/r/MachineLearning/comments/7liyzc/d_gabby_shklovsky_random_forests_best_practices/,_alphamaximus_,1513964686,,0,1
1110,2017-12-23,2017,12,23,3,7lj931,"Want to Make an OpenCV Face Detector in 5 MINUTES? Check out this cool video, and please SUBSCRIBE! It would help me out a lot! :)",https://www.reddit.com/r/MachineLearning/comments/7lj931/want_to_make_an_opencv_face_detector_in_5_minutes/,DiscoverAI,1513967137,,0,1
1111,2017-12-23,2017,12,23,3,7ljb60,"Deep Learning en Espaol - Aprendizaje Profundo para Visin Artificial - Facultad de Ingeniera, Uruguay",https://www.reddit.com/r/MachineLearning/comments/7ljb60/deep_learning_en_espaol_aprendizaje_profundo/,draix12,1513967668,,0,1
1112,2017-12-23,2017,12,23,3,7ljcfx,"If you were doing a ML startup, how do you charge?",https://www.reddit.com/r/MachineLearning/comments/7ljcfx/if_you_were_doing_a_ml_startup_how_do_you_charge/,taewoo,1513968003,[removed],0,1
1113,2017-12-23,2017,12,23,4,7lji6t,"[N] Google AI researcher accused of harassment, female data scientists speak of 'broken system",https://www.reddit.com/r/MachineLearning/comments/7lji6t/n_google_ai_researcher_accused_of_harassment/,urish,1513969477,,46,28
1114,2017-12-23,2017,12,23,4,7ljl3u,[D] https://blog.algorithmia.com/advanced-image-manipulation-and-data-extraction/,https://www.reddit.com/r/MachineLearning/comments/7ljl3u/d/,[deleted],1513970251,[deleted],0,1
1115,2017-12-23,2017,12,23,4,7ljqti,[N] 14 AI and machine learning conferences to attend in 2018,https://www.reddit.com/r/MachineLearning/comments/7ljqti/n_14_ai_and_machine_learning_conferences_to/,yourbasicgeek,1513971753,,5,0
1116,2017-12-23,2017,12,23,4,7ljs20,[D] Advanced Image Manipulation and Data Extraction,https://www.reddit.com/r/MachineLearning/comments/7ljs20/d_advanced_image_manipulation_and_data_extraction/,mikeyanderson,1513972077,,0,1
1117,2017-12-23,2017,12,23,5,7ljx06,AI Weekly 22 Dec 2017,https://www.reddit.com/r/MachineLearning/comments/7ljx06/ai_weekly_22_dec_2017/,TomekB,1513973357,,0,1
1118,2017-12-23,2017,12,23,5,7ljxmx,Hyperparameters for final model in Nested K-Fold Cross Validation,https://www.reddit.com/r/MachineLearning/comments/7ljxmx/hyperparameters_for_final_model_in_nested_kfold/,prettybunny252,1513973516,[removed],0,1
1119,2017-12-23,2017,12,23,6,7lk9rr,A Zero-Math Introduction to Markov Chain Monte Carlo Methods,https://www.reddit.com/r/MachineLearning/comments/7lk9rr/a_zeromath_introduction_to_markov_chain_monte/,algui91,1513976757,,0,1
1120,2017-12-23,2017,12,23,6,7lkb0s,[D] Keith Myers-Crum - sklearn Compatible Model Stacking,https://www.reddit.com/r/MachineLearning/comments/7lkb0s/d_keith_myerscrum_sklearn_compatible_model/,_alphamaximus_,1513977107,,0,1
1121,2017-12-23,2017,12,23,6,7lkb6r,[P] Using Your Idle Deep Learning Hardware for Mining,https://www.reddit.com/r/MachineLearning/comments/7lkb6r/p_using_your_idle_deep_learning_hardware_for/,risig_sag,1513977152,,4,0
1122,2017-12-23,2017,12,23,7,7lko87,Superhumanl AI for heads-up no-limit poker: Libratus beats top professionals | Science,https://www.reddit.com/r/MachineLearning/comments/7lko87/superhumanl_ai_for_headsup_nolimit_poker_libratus/,AmbrosioBembo,1513980747,,0,1
1123,2017-12-23,2017,12,23,8,7ll16p,War Robots,https://www.reddit.com/r/MachineLearning/comments/7ll16p/war_robots/,funmaster11,1513984433,,0,1
1124,2017-12-23,2017,12,23,8,7ll4jq,"Shockingly, physicists find that a biological neuron acts as ""multiple threshold units"" in one! Back to the drawing board for Deep Learning?",https://www.reddit.com/r/MachineLearning/comments/7ll4jq/shockingly_physicists_find_that_a_biological/,[deleted],1513985438,[deleted],0,1
1125,2017-12-23,2017,12,23,8,7ll6k2,"Shockingly, physicists find that a biological neuron acts as ""multiple threshold units"" in one, instead of the long standing ""sum and fire' paradigm! Back to the drawing board for Deep Learning?",https://www.reddit.com/r/MachineLearning/comments/7ll6k2/shockingly_physicists_find_that_a_biological/,ProgrammingGodJordan,1513986049,,0,1
1126,2017-12-23,2017,12,23,9,7llf2m,[D] Is it reasonable for this SVM to take 53 seconds on prediction phase?,https://www.reddit.com/r/MachineLearning/comments/7llf2m/d_is_it_reasonable_for_this_svm_to_take_53/,sk0620,1513988594,"My nonlinear gaussian kernel SVM with 2 features and 100 training examples trains in under a second but when creating a decision boundary, it takes around 53 seconds on 40,000 test examples for a decision boundary. Is that a reasonable amount of time or should I look for ways to vectorize? Here is the [code](https://github.com/SamKirkiles/machine-learning-demos/blob/master/support-vector-machine/python-linear-svm/nonlinear-svm.py) if anyone wants to run it themselves. 

Thanks!

",6,0
1127,2017-12-23,2017,12,23,9,7lljqc,[D] Does anyone have any good online tutorial / courses to recommend for reinforcement learning applied to robotics?,https://www.reddit.com/r/MachineLearning/comments/7lljqc/d_does_anyone_have_any_good_online_tutorial/,jer_pint,1513990029,,8,11
1128,2017-12-23,2017,12,23,9,7llk6u,Some Optimization: Implementing the Orthogonal Matching Pursuit (OMP) and the Basis Pursuit (BP) Algorithms with Octave / Matlab,https://www.reddit.com/r/MachineLearning/comments/7llk6u/some_optimization_implementing_the_orthogonal/,SandipanDeyUMBC,1513990170,,0,1
1129,2017-12-23,2017,12,23,9,7llkgb,[P] PyTorch Implementation of VQA Challenge 2017 Winner: Bottom-Up and Top-Down Attention for Visual Question Answering,https://www.reddit.com/r/MachineLearning/comments/7llkgb/p_pytorch_implementation_of_vqa_challenge_2017/,xiaoxiao26,1513990257,,1,78
1130,2017-12-23,2017,12,23,10,7llmcw,Data preprocessing resource recommendations,https://www.reddit.com/r/MachineLearning/comments/7llmcw/data_preprocessing_resource_recommendations/,MLbeginner96,1513990877,[removed],0,1
1131,2017-12-23,2017,12,23,10,7llmts,Crack a True/False exam,https://www.reddit.com/r/MachineLearning/comments/7llmts/crack_a_truefalse_exam/,hospitalfood1,1513991024,[removed],0,1
1132,2017-12-23,2017,12,23,14,7lmydw,Aren't some models for prediction kind of rigid?,https://www.reddit.com/r/MachineLearning/comments/7lmydw/arent_some_models_for_prediction_kind_of_rigid/,wearefarming101,1514007497,[removed],0,1
1133,2017-12-23,2017,12,23,15,7ln3xh,Introduction of Brain Computer Interface,https://www.reddit.com/r/MachineLearning/comments/7ln3xh/introduction_of_brain_computer_interface/,munishmaxtech,1514009719,,0,1
1134,2017-12-23,2017,12,23,15,7ln4hb,untitled,https://www.reddit.com/r/MachineLearning/comments/7ln4hb/untitled/,anowarul147,1514009959,,0,1
1135,2017-12-23,2017,12,23,15,7ln6da,Is It Possible For Me to Get Into Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/7ln6da/is_it_possible_for_me_to_get_into_machine_learning/,EggoManno,1514010725,[removed],0,1
1136,2017-12-23,2017,12,23,18,7lnre1,Deep learning for music generation,https://www.reddit.com/r/MachineLearning/comments/7lnre1/deep_learning_for_music_generation/,lokeshreddy07,1514020546,,0,1
1137,2017-12-23,2017,12,23,19,7lnzo6,"[P] Arraymancer, teaching Nim language digit recognition from scratch [x-post /r/programming/]",https://www.reddit.com/r/MachineLearning/comments/7lnzo6/p_arraymancer_teaching_nim_language_digit/,Karyo_Ten,1514024825,,0,30
1138,2017-12-23,2017,12,23,22,7lokro,New research on neurons science has aligned with Capsule Nets that direction matter (xpost /r/science),https://www.reddit.com/r/MachineLearning/comments/7lokro/new_research_on_neurons_science_has_aligned_with/,ipoppo,1514035055,,0,1
1139,2017-12-24,2017,12,24,1,7lph69,When a ball put inside a box has a longer diameter than the box.(What happens when we put a ball inside a box in a high dimensional world?),https://www.reddit.com/r/MachineLearning/comments/7lph69/when_a_ball_put_inside_a_box_has_a_longer/,JaejunYoo,1514046661,[removed],1,1
1140,2017-12-24,2017,12,24,1,7lpkp5,Has anyone tried the Titan V?,https://www.reddit.com/r/MachineLearning/comments/7lpkp5/has_anyone_tried_the_titan_v/,[deleted],1514047717,,0,1
1141,2017-12-24,2017,12,24,3,7lq58j,"[D] What ML publication hacks are you familiar with, and which annoy you the most?",https://www.reddit.com/r/MachineLearning/comments/7lq58j/d_what_ml_publication_hacks_are_you_familiar_with/,reservedsparrow,1514053659,"This is in line with ""When a measure becomes a target, it ceases to be a good measure.""

In ML literature (and other literature, especially academic) the measure/target is 'good reviews from reviewers'.

So which publication hacks are you familiar with, and which annoy you the most?

I'll start, motivated by a comment from https://github.com/hengyuan-hu/bottom-up-attention-vqa :

&gt; The third point is simply because we feel the two stream classifier and pre-training in the original paper is over-complicated and not necessary.

Hack: Begin complex, and do not 'waste' your time with ablation studies / trying to simplify.

Reason this improves the measure/target: Reviewers will more often complain about simplicity ('incremental research') than complexity.

Reason this sucks for everyone involved except the authors: Leads to overly complex models, with little to no understanding of which components are actually useful.

Edit: Fixed URL",63,152
1142,2017-12-24,2017,12,24,5,7lqysx,How to reduce the time it take to load a model in Kera? [Discussion],https://www.reddit.com/r/MachineLearning/comments/7lqysx/how_to_reduce_the_time_it_take_to_load_a_model_in/,Moondra2017,1514062316,"Just the import and loading a model in Keras is taking about 14 or seconds:


    import matplotlib.pyplot as plt
   import time


    start = time.time()


    from keras.models import load_model

    import numpy as np
    import cv2
    from scipy.misc import imread, imresize
    import os
    import random
    from threading import Thread, Lock
    import tensorflow as tf
    from keras import backend as K

    print('time take to load imports {:0.3f}'.format(time.time() - start))




    start = time.time()
    K.clear_session()
    lock = Lock()
    predictions = []


    path = r'E:\Keras Models\2017-12-20_10.hdf5'

    image_dir = r'C:\Users\Moondra\Desktop\DATA\Fish Images'
    os.chdir(image_dir)
    image = imread(random.choice(os.listdir(image_dir)))


    labels = os.listdir(r'C:\Users\Moondra\Desktop\FISHES_MAIN')
    model =  load_model(path)


    print('time take to load model {:0.3f}'.format(time.time() - start))


    time take to load imports 1.823
    time take to load model 12.848



Is there a way to reduce the time taken for deployment on 
cellphone devices? 

I've noticed loading tensorflow is taking about 1.4 seconds.
(The other imports are super quick)

Tensorflow : '1.4.0'

keras.version: '2.1.2'

I'm running the Inception model V3 with one extra fcc layer with 1024 nodes.

Just loading the model is taking around 12.29 seconds. 


UPDATE:

Using `model = load_model(path, compile=False)` got the time down to 
    9.251000165939331
    





",11,2
1143,2017-12-24,2017,12,24,6,7lr9m5,Where does the graph Laplacian come from?,https://www.reddit.com/r/MachineLearning/comments/7lr9m5/where_does_the_graph_laplacian_come_from/,andcomma,1514065570,[removed],0,1
1144,2017-12-24,2017,12,24,6,7lrbec,[D] Need advice for GPU purchase,https://www.reddit.com/r/MachineLearning/comments/7lrbec/d_need_advice_for_gpu_purchase/,hispanic_scholar,1514066126,"I have very little experience with computer hardware, but I've hit the critical point in my ML studies where it makes more sense for me to purchase my own GPUs.  I'm a bit confused by the different products offered by nvidia and had a few questions...

* I've only used AWS for GPUs, so I'm only familiar with the performance of the data center GPUs (K80, V100).  In my experience the V100 runs DL jobs about 3 times as fast as the K80.  I'm curious how nvidia's consumer graphics cards compare with their data center products.  In particular, how will the 1080 Ti and Titan V compare to the K80 and V100, and in general what is the difference between the consumer graphics cards and data center GPUs that merits such a large price discrepancy between the two? 

* The Titan V comes at a much much higher cost than the 1080 Ti.  If I make use of all the DL optimizations in the Volta architecture, **roughly** how many times faster will DL jobs run compared to the 1080 Ti?  In your opinion, is this worth it?

* Are there any emerging technologies or expected product announcements that might make any of the GPUs a risky purchase right now? (perhaps soon to be obsolete or due for a price cut)

Any other advice, recommendations, or personal experience is appreciated.  My use case is pretty standard, and I'm mostly interested in performance as I don't do any memory intensive tasks.",28,8
1145,2017-12-24,2017,12,24,7,7lrclj,[D] Use TF loops over feed_dict for RL training,https://www.reddit.com/r/MachineLearning/comments/7lrclj/d_use_tf_loops_over_feed_dict_for_rl_training/,vladfeinberg,1514066514,,15,5
1146,2017-12-24,2017,12,24,12,7lsw89,Faster R-CNN in PyTorch with higher mAP and 5x fewer code.,https://www.reddit.com/r/MachineLearning/comments/7lsw89/faster_rcnn_in_pytorch_with_higher_map_and_5x/,[deleted],1514084963,[deleted],0,1
1147,2017-12-24,2017,12,24,12,7lt0z8,[D] What do you consider to be the 'final boss' of machine learning,https://www.reddit.com/r/MachineLearning/comments/7lt0z8/d_what_do_you_consider_to_be_the_final_boss_of/,TeslaCarBot,1514086754,[removed],6,0
1148,2017-12-24,2017,12,24,12,7lt3gx,Sura Ekhlas,https://www.reddit.com/r/MachineLearning/comments/7lt3gx/sura_ekhlas/,anowarul147,1514087732,,0,1
1149,2017-12-24,2017,12,24,13,7ltdaw,ROLL DIE PUNCHING MACHINE WITH FLEXO PRINTING IN CUSTOMER'S FACTORY,https://www.reddit.com/r/MachineLearning/comments/7ltdaw/roll_die_punching_machine_with_flexo_printing_in/,FEIDA_MACHINE,1514091303,,0,1
1150,2017-12-24,2017,12,24,15,7ltqzk,untitled,https://www.reddit.com/r/MachineLearning/comments/7ltqzk/untitled/,anowarul147,1514096822,,0,1
1151,2017-12-24,2017,12,24,15,7lttjf,Tensorflow/Keras Implementation of Autoencoder Based Communication System(new approach to define communication System),https://www.reddit.com/r/MachineLearning/comments/7lttjf/tensorflowkeras_implementation_of_autoencoder/,immortal333,1514098025,,0,1
1152,2017-12-24,2017,12,24,15,7ltv26,A simple and efficent implementaion of Faster R-CNN in PyTorch with higher mAP and 5x fewer code.,https://www.reddit.com/r/MachineLearning/comments/7ltv26/a_simple_and_efficent_implementaion_of_faster/,[deleted],1514098731,[deleted],0,1
1153,2017-12-24,2017,12,24,16,7lu2ia,ML Conference/ICML Videos,https://www.reddit.com/r/MachineLearning/comments/7lu2ia/ml_conferenceicml_videos/,alexnetvgg,1514102336,[removed],0,1
1154,2017-12-24,2017,12,24,19,7lukk1,2018 predictions thread,https://www.reddit.com/r/MachineLearning/comments/7lukk1/2018_predictions_thread/,no_bear_so_low,1514111768,[removed],0,1
1155,2017-12-24,2017,12,24,20,7luqsc,Urgent MLA Project: Converting 2D to 3D in AutoCAD,https://www.reddit.com/r/MachineLearning/comments/7luqsc/urgent_mla_project_converting_2d_to_3d_in_autocad/,HerrPr0fess0r,1514115218,[removed],0,1
1156,2017-12-24,2017,12,24,20,7lutdc,Filbert Nut Cracker Machine|Hazelnut Cracking Equipment Suppliers,https://www.reddit.com/r/MachineLearning/comments/7lutdc/filbert_nut_cracker_machinehazelnut_cracking/,gelserena,1514116700,,1,1
1157,2017-12-24,2017,12,24,22,7lv6ky,Future of RNNs and LSTMs given rise of Causal Convolution,https://www.reddit.com/r/MachineLearning/comments/7lv6ky/future_of_rnns_and_lstms_given_rise_of_causal/,[deleted],1514122839,,0,1
1158,2017-12-24,2017,12,24,23,7lv9cp,This is how a DNN learns to extract features from MNIST images,https://www.reddit.com/r/MachineLearning/comments/7lv9cp/this_is_how_a_dnn_learns_to_extract_features_from/,[deleted],1514124026,[deleted],0,1
1159,2017-12-24,2017,12,24,23,7lvac6,[P] Twitter Sentiment Analysis using a variety of machine (and deep) learning methods,https://www.reddit.com/r/MachineLearning/comments/7lvac6/p_twitter_sentiment_analysis_using_a_variety_of/,SolitaryPenman,1514124397,,11,0
1160,2017-12-24,2017,12,24,23,7lvaxa,Visualization of how a neural network learns to extract features from MNIST images.,https://www.reddit.com/r/MachineLearning/comments/7lvaxa/visualization_of_how_a_neural_network_learns_to/,porygon93,1514124626,,1,1
1161,2017-12-24,2017,12,24,23,7lvfjn,[P] Going Deeper: Infinite Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/7lvfjn/p_going_deeper_infinite_deep_neural_networks/,meierbe8,1514126425,,27,124
1162,2017-12-25,2017,12,25,0,7lvqay,[D] Future of LSTM and GRU given rise of causal convolution?,https://www.reddit.com/r/MachineLearning/comments/7lvqay/d_future_of_lstm_and_gru_given_rise_of_causal/,radenML,1514130170,"Will LSTM and GRU dethroned given causal convolutions (WaveNet, ByteNet) can do time sequence data better?",22,42
1163,2017-12-25,2017,12,25,0,7lvs14,Deep Learning Hardware Limbo,https://www.reddit.com/r/MachineLearning/comments/7lvs14/deep_learning_hardware_limbo/,PM_YOUR_NIPS_PAPER,1514130757,,0,0
1164,2017-12-25,2017,12,25,1,7lvydy,Java Machine Learning for Image Color Reduction,https://www.reddit.com/r/MachineLearning/comments/7lvydy/java_machine_learning_for_image_color_reduction/,[deleted],1514132791,[deleted],0,1
1165,2017-12-25,2017,12,25,2,7lwc4j,Advice on autoencoding,https://www.reddit.com/r/MachineLearning/comments/7lwc4j/advice_on_autoencoding/,crossentropy,1514136792,[removed],0,1
1166,2017-12-25,2017,12,25,3,7lwmku,MIT Sloan: Intro to Machine Learning (in 360/VR),https://www.reddit.com/r/MachineLearning/comments/7lwmku/mit_sloan_intro_to_machine_learning_in_360vr/,[deleted],1514139944,[deleted],0,1
1167,2017-12-25,2017,12,25,7,7ly12m,New NVIDIA EULA prohibits Deep Learning on GeForce GPUs,https://www.reddit.com/r/MachineLearning/comments/7ly12m/new_nvidia_eula_prohibits_deep_learning_on/,[deleted],1514155781,,0,1
1168,2017-12-25,2017,12,25,7,7ly2ds,Training utilities in pytorch,https://www.reddit.com/r/MachineLearning/comments/7ly2ds/training_utilities_in_pytorch/,juxtaposicion,1514156224,[removed],0,1
1169,2017-12-25,2017,12,25,8,7ly3kg,New NVIDIA EULA prohibits Deep Learning on GeForce GPUs,https://www.reddit.com/r/MachineLearning/comments/7ly3kg/new_nvidia_eula_prohibits_deep_learning_on/,[deleted],1514156610,,0,1
1170,2017-12-25,2017,12,25,8,7ly5gi,[News] New NVIDIA EULA prohibits Deep Learning on GeForce GPUs in data centers.,https://www.reddit.com/r/MachineLearning/comments/7ly5gi/news_new_nvidia_eula_prohibits_deep_learning_on/,booooomba,1514157227,"According to German tech magazine golem.de, the new NVIDIA EULA prohibits Deep Learning applications to be run on GeForce GPUs.

Sources:

https://www.golem.de/news/treiber-eula-nvidia-untersagt-deep-learning-auf-geforces-1712-131848.html

http://www.nvidia.com/content/DriverDownload-March2009/licence.php?lang=us&amp;type=GeForce

The EULA states:

""No Datacenter Deployment. The SOFTWARE is not licensed for datacenter deployment, except that blockchain processing in a datacenter is permitted.""

EDIT: Found an English article: https://wirelesswire.jp/2017/12/62708/



",250,640
1171,2017-12-25,2017,12,25,11,7lyx32,Continuous Pork Skin|Meat|Nut Frying Machine With Factory Price For Sale,https://www.reddit.com/r/MachineLearning/comments/7lyx32/continuous_pork_skinmeatnut_frying_machine_with/,gelgoogcara,1514167344,,1,1
1172,2017-12-25,2017,12,25,11,7lz0zm,Small Capacity Peanuts Butter Production Line Manufacturer In China,https://www.reddit.com/r/MachineLearning/comments/7lz0zm/small_capacity_peanuts_butter_production_line/,gelgoogcara,1514168837,,1,1
1173,2017-12-25,2017,12,25,12,7lz6ph,Automatic Cashew Nut Shelling Unit|Complete Cashew Processing Machine,https://www.reddit.com/r/MachineLearning/comments/7lz6ph/automatic_cashew_nut_shelling_unitcomplete_cashew/,gelserena,1514171088,,1,1
1174,2017-12-25,2017,12,25,12,7lz8ce,[D] Boycott Nvidia after they banned deep learning on their GPUs in the cloud,https://www.reddit.com/r/MachineLearning/comments/7lz8ce/d_boycott_nvidia_after_they_banned_deep_learning/,[deleted],1514171752,,0,1
1175,2017-12-25,2017,12,25,12,7lz8j3,Nvidia has started the civil war on general purpose computing,https://www.reddit.com/r/MachineLearning/comments/7lz8j3/nvidia_has_started_the_civil_war_on_general/,[deleted],1514171826,[deleted],0,1
1176,2017-12-25,2017,12,25,12,7lzbb7,Which college statistics course is more useful?,https://www.reddit.com/r/MachineLearning/comments/7lzbb7/which_college_statistics_course_is_more_useful/,Go4UMD,1514172935,[removed],0,1
1177,2017-12-25,2017,12,25,14,7lzw5t,Podcasts on my mistakes in learning machine learning.,https://www.reddit.com/r/MachineLearning/comments/7lzw5t/podcasts_on_my_mistakes_in_learning_machine/,MieRobot,1514181211,,0,1
1178,2017-12-25,2017,12,25,16,7m06ce,5 Best Machine Learning API's for Data Science,https://www.reddit.com/r/MachineLearning/comments/7m06ce/5_best_machine_learning_apis_for_data_science/,lokeshreddy07,1514185765,,0,1
1179,2017-12-25,2017,12,25,16,7m07ps,"[D] Rene Vidal: 'You know your minima is a global minima if all the weights associated with one neuron are zero. If not, you can add one neuron to your network, and minimize again. Repeat until you reach a global minima'",https://www.reddit.com/r/MachineLearning/comments/7m07ps/d_rene_vidal_you_know_your_minima_is_a_global/,SGuptMachineLearning,1514186431,"From

https://youtu.be/Mdp9uC3gXUU?t=59m48s

the tl/dr is that for positive homogeneous convex functions, when the size is large enough, there are no local minimas. 

Has anyone had experience doing this? Does it work? Will this be the new big thing in ML? Btw, this only based on   positive homogeneous convex functions, so using Relu, but not tang/sigmoid

Here's the paper that the lecture if based on btw https://arxiv.org/abs/1712.04741",20,14
1180,2017-12-25,2017,12,25,17,7m0fuh,How to retrain the machine learning model when the training dataset updates?,https://www.reddit.com/r/MachineLearning/comments/7m0fuh/how_to_retrain_the_machine_learning_model_when/,anuj55149,1514190732,[removed],0,1
1181,2017-12-25,2017,12,25,21,7m125h,Sausage Vacuum Packing Machine (double chamber),https://www.reddit.com/r/MachineLearning/comments/7m125h/sausage_vacuum_packing_machine_double_chamber/,gelserena,1514203226,,1,1
1182,2017-12-25,2017,12,25,21,7m154z,Tea Packing Machine|Powder Packing Equipment Suppliers,https://www.reddit.com/r/MachineLearning/comments/7m154z/tea_packing_machinepowder_packing_equipment/,gelserena,1514204737,,1,1
1183,2017-12-25,2017,12,25,21,7m1581,Stochastic Gradient ascent for Logistic Regression,https://www.reddit.com/r/MachineLearning/comments/7m1581/stochastic_gradient_ascent_for_logistic_regression/,[deleted],1514204792,,0,1
1184,2017-12-25,2017,12,25,21,7m15ll,[n00b] I am a product manager in a company which has tons of good data and I am struggling to get started,https://www.reddit.com/r/MachineLearning/comments/7m15ll/n00b_i_am_a_product_manager_in_a_company_which/,foundmyselfa,1514205004,[removed],0,1
1185,2017-12-25,2017,12,25,21,7m16m5,[R] Top 100 Machine Learning interview questions,https://www.reddit.com/r/MachineLearning/comments/7m16m5/r_top_100_machine_learning_interview_questions/,digitalson,1514205545,,0,1
1186,2017-12-25,2017,12,25,22,7m1bsh,SHAInet - Pure Crystal Neural Network,https://www.reddit.com/r/MachineLearning/comments/7m1bsh/shainet_pure_crystal_neural_network/,[deleted],1514208069,[deleted],0,1
1187,2017-12-25,2017,12,25,22,7m1c5a,[D] Important update/fix for Distributional RL article,https://www.reddit.com/r/MachineLearning/comments/7m1c5a/d_important_updatefix_for_distributional_rl/,Kiuhnm,1514208226,"I updated [my article](https://mtomassoli.github.io/2017/12/08/distributional_rl/) about Distributional RL.

In particular, I added subsection [4.5.1](https://mtomassoli.github.io/2017/12/08/distributional_rl/#a-more-fundamental-reason) after Will Dabney, one of the authors of the papers, pointed out a mistake in subsection [4.5](https://mtomassoli.github.io/2017/12/08/distributional_rl/#why-dont-we-use-simple-regression).",1,26
1188,2017-12-25,2017,12,25,23,7m1iuo,[news] SHAInet - Pure Crystal Neural Network,https://www.reddit.com/r/MachineLearning/comments/7m1iuo/news_shainet_pure_crystal_neural_network/,Ba7a7chy,1514211153,,16,0
1189,2017-12-25,2017,12,25,23,7m1pcl,best portable air compressor,https://www.reddit.com/r/MachineLearning/comments/7m1pcl/best_portable_air_compressor/,afridisa,1514213743,,1,1
1190,2017-12-26,2017,12,26,0,7m1rei,Best Air Compressor Reviews,https://www.reddit.com/r/MachineLearning/comments/7m1rei/best_air_compressor_reviews/,afridisa,1514214488,,1,1
1191,2017-12-26,2017,12,26,0,7m1tkq,Best Air Compressor,https://www.reddit.com/r/MachineLearning/comments/7m1tkq/best_air_compressor/,afridisa,1514215253,,1,1
1192,2017-12-26,2017,12,26,0,7m1we8,best portable air compressor guide,https://www.reddit.com/r/MachineLearning/comments/7m1we8/best_portable_air_compressor_guide/,afridisa,1514216294,,1,1
1193,2017-12-26,2017,12,26,0,7m1z18,BEST AIR COMPRESSOR REVIEWS 2017,https://www.reddit.com/r/MachineLearning/comments/7m1z18/best_air_compressor_reviews_2017/,afridisa,1514217230,,1,1
1194,2017-12-26,2017,12,26,5,7m39f0,Help,https://www.reddit.com/r/MachineLearning/comments/7m39f0/help/,[deleted],1514232222,,0,1
1195,2017-12-26,2017,12,26,5,7m3hjh,[D] AlphaZero for G of GAN,https://www.reddit.com/r/MachineLearning/comments/7m3hjh/d_alphazero_for_g_of_gan/,HigherTopoi,1514234873,"Let's consider a GAN in which G is AlphaZero-like algorithm. Unlike other GAN, G of this one can directly take samples from the dataset as an input in the sense that they can be used in the tree. There are various kinds of RL problems whose evaluation cannot be easily done by a simple algorithm without using a NN. Realistic text generation (e.g. SeqGAN, LeakGAN) is one example, and this is something I'm particularly interested in. Realistic *** generation is a special subset of the above problems in the sense that infinite supply of labelled (in the sense that they are realistic or not) samples are available. Unrealistic yet close to realistic data can be easily produced by randomly perturbing samples, which are almost certainly unrealistic. Also, we can generate an unrealistic sentence from any node of the tree like this for almost certainty. So, we want to exploit the huge supply of these labelled data. 

1) Let's say, beside the reward assignment by D, we assign terminal reward 1 for each text from the dataset  (and possibly assign terminal reward 0 for perturbed ones), store all of them in the tree and start the usual MCTS-based RL. Is this a beneficial practice? iirc something like this was mentioned in a relevant literature. Since the cost of doing this per text is cheap (though storing all these texts is memory-consuming), we can use a superset of the dataset used in the subsequent training, if that's meaningful. 

2) We want the agent to be just like human rather than to surpass human. So, I think combining the supervised learning approach used in AlphaGo Zero paper, which performed like human-expert, would be helpful, especially because of our numerous data. Maybe use it for pre-training for NN and use 1) for the tree? Any thought? 

3) Even if we use subword-level action, the action counts are at least 4k, whereas there are only ~400 actions for Go. In AlphaZero applied to Go, if we let the action counts to be 4k and keep everything else as they are, how much of memory bottleneck would storing data in the tree be? If I understand correctly, AlphaZero stored in the tree the history of up to 500k of the most recent games. In general, I don't know how much memory tree requires for large action counts, so whatever answer would be helpful. 


",13,27
1196,2017-12-26,2017,12,26,10,7m4u9k,Machine learning shower thought.,https://www.reddit.com/r/MachineLearning/comments/7m4u9k/machine_learning_shower_thought/,pnloyd,1514251321,[removed],0,1
1197,2017-12-26,2017,12,26,10,7m4z2k,Combinatorial optimization with deep reinforcement learning. IPython Tutorials,https://www.reddit.com/r/MachineLearning/comments/7m4z2k/combinatorial_optimization_with_deep/,codentropy,1514253057,,0,1
1198,2017-12-26,2017,12,26,11,7m55ip,Why do you want to use aviation aluminum of drying racks?,https://www.reddit.com/r/MachineLearning/comments/7m55ip/why_do_you_want_to_use_aviation_aluminum_of/,jumitop,1514255354,[removed],1,1
1199,2017-12-26,2017,12,26,12,7m5cm3,.Do respond ASAP. please . We need suggestion for a machine learning,https://www.reddit.com/r/MachineLearning/comments/7m5cm3/do_respond_asap_please_we_need_suggestion_for_a/,heroooreh,1514257876,[removed],0,1
1200,2017-12-26,2017,12,26,13,7m5maj,What is the purpose of this compose function in Darketnet_Keras(yolo) implementation?,https://www.reddit.com/r/MachineLearning/comments/7m5maj/what_is_the_purpose_of_this_compose_function_in/,Moondra2017,1514261433,[removed],0,1
1201,2017-12-26,2017,12,26,13,7m5s6q,Playing FPS Games with Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/7m5s6q/playing_fps_games_with_deep_reinforcement_learning/,yogthos,1514263640,,0,1
1202,2017-12-26,2017,12,26,14,7m5voo,"In CheXNet, Wrong evaluation method was adopted in the comparison against radiologists on the pneumonia detection task",https://www.reddit.com/r/MachineLearning/comments/7m5voo/in_chexnet_wrong_evaluation_method_was_adopted_in/,zhaoerchao,1514264869,[removed],0,1
1203,2017-12-26,2017,12,26,15,7m64l2,What does it mean for the training data to be generated by a probability distribution over datasets,https://www.reddit.com/r/MachineLearning/comments/7m64l2/what_does_it_mean_for_the_training_data_to_be/,rjmessibarca,1514268164,[removed],0,1
1204,2017-12-26,2017,12,26,15,7m6afc,Creating Intricate Art with Neural Style Transfer,https://www.reddit.com/r/MachineLearning/comments/7m6afc/creating_intricate_art_with_neural_style_transfer/,nic_nom,1514270158,,0,1
1205,2017-12-26,2017,12,26,16,7m6gvk,Visual Analytics: Exploring #KendrickLamar on Instagram,https://www.reddit.com/r/MachineLearning/comments/7m6gvk/visual_analytics_exploring_kendricklamar_on/,shashankg22,1514272939,,0,1
1206,2017-12-26,2017,12,26,17,7m6lp4,[D] CNN-RNN-CTC vs Attention-Encoder-Decoder?,https://www.reddit.com/r/MachineLearning/comments/7m6lp4/d_cnnrnnctc_vs_attentionencoderdecoder/,xylcbd,1514275215,"for the OCR, which method is better?

CNN-RNN-CTC method 
vs 
Attention-based Sequence to Sequence method.",16,8
1207,2017-12-26,2017,12,26,17,7m6rn8,Understanding the Hidden Layer output as Neural Network learns XOR function,https://www.reddit.com/r/MachineLearning/comments/7m6rn8/understanding_the_hidden_layer_output_as_neural/,niszoig,1514278240,,1,1
1208,2017-12-26,2017,12,26,18,7m6x28,5 Key Artificial Intelligence Predictions For 2018: How Machine Learning Will Change Everything,https://www.reddit.com/r/MachineLearning/comments/7m6x28/5_key_artificial_intelligence_predictions_for/,mr_j_b,1514280993,,0,1
1209,2017-12-26,2017,12,26,19,7m6zw2,"[R] ICYMI: Recent Microsoft AI Platform Updates, Including in ONNX, Deep Learning, Video Indexer &amp; More",https://www.reddit.com/r/MachineLearning/comments/7m6zw2/r_icymi_recent_microsoft_ai_platform_updates/,molode,1514282434,,0,1
1210,2017-12-26,2017,12,26,19,7m70wc,[Question] Does anyone remember what was said about Miyazaki and his thoughts on ML at the NIPS creativity workshop?,https://www.reddit.com/r/MachineLearning/comments/7m70wc/question_does_anyone_remember_what_was_said_about/,ievalapply,1514282925,[removed],0,1
1211,2017-12-26,2017,12,26,19,7m70zd,"[N] Data Science, Machine Learning: Main Developments in 2017 and Key Trends in 2018",https://www.reddit.com/r/MachineLearning/comments/7m70zd/n_data_science_machine_learning_main_developments/,magneticono,1514282963,,0,1
1212,2017-12-26,2017,12,26,19,7m772v,[D] Max-over-time pooling vs no max-pooling for text classification?,https://www.reddit.com/r/MachineLearning/comments/7m772v/d_maxovertime_pooling_vs_no_maxpooling_for_text/,residualvalue,1514285954,"[Kim 2014](http://arxiv.org/abs/1408.5882) and [Collobert 2011](https://arxiv.org/pdf/1103.0398.pdf) argue that max-over-time pooling helps getting the words from a sentence that are most important to the semantics.

Then I read a blog post from the Googler [Lakshmanan V](https://towardsdatascience.com/how-to-do-text-classification-using-tensorflow-word-embeddings-and-cnn-edae13b3e575) on text classification. The author argues that spatial invariance isn't wanted because it's important where words are placed in a sentence. Thus he doesn't recommend maxpool.

Are there empirical studies that compares the two approaches?",17,9
1213,2017-12-26,2017,12,26,20,7m79z0,Optimize machine by implementing a neural network.,https://www.reddit.com/r/MachineLearning/comments/7m79z0/optimize_machine_by_implementing_a_neural_network/,PrinzKarneval,1514287282,[removed],0,1
1214,2017-12-26,2017,12,26,20,7m7ej9,"My favorite papers of 2017: MultiArmed Bandit, TFX, Experimentation Pitfalls and S+U Learning",https://www.reddit.com/r/MachineLearning/comments/7m7ej9/my_favorite_papers_of_2017_multiarmed_bandit_tfx/,snickmy,1514289449,,1,1
1215,2017-12-26,2017,12,26,21,7m7jab,Automatic Thai Flat Noodle Making Machine,https://www.reddit.com/r/MachineLearning/comments/7m7jab/automatic_thai_flat_noodle_making_machine/,lgsherry,1514291522,,1,1
1216,2017-12-26,2017,12,26,22,7m7q1o,[P] How to train a Deep Neural Network using only TensorFlow C++,https://www.reddit.com/r/MachineLearning/comments/7m7q1o/p_how_to_train_a_deep_neural_network_using_only/,theflofly,1514294402,,37,191
1217,2017-12-26,2017,12,26,22,7m7v4c,BEST AIR COMPRESSOR,https://www.reddit.com/r/MachineLearning/comments/7m7v4c/best_air_compressor/,afridisa,1514296459,,1,1
1218,2017-12-26,2017,12,26,23,7m7wum,BEST PORTABLE AIR COMPRESSOR,https://www.reddit.com/r/MachineLearning/comments/7m7wum/best_portable_air_compressor/,afridisa,1514297091,,1,1
1219,2017-12-26,2017,12,26,23,7m7xp8,[P] Melanoma detection model (http://melanoma.modelderm.com),https://www.reddit.com/r/MachineLearning/comments/7m7xp8/p_melanoma_detection_model/,whria78,1514297408,"Hello.

I made a melanoma diagnosis model named ""Model Melanoma"" based on deep learning algorithm (http://melanoma.modelderm.com).


ResNet152 and VGG19 were used as a CNN model, around 300,000 images (179 classes) were used as a training dataset.


The AUC (area under curve) value of this model is 0.9476 (using melanoma output/nevus output ratio) and 0.9340 (using melanoma output) with all the 407 melanocytic (76 malignant, 331 benign) test images of the Edinburgh dermofit library (https://licensing.edinburgh-innovations.ed.ac.uk/i/software/dermofit-image-library.html).
For reference, the skin cancer detection model published on nature(https://www.nature.com/articles/nature21056) showed 0.96 with 225 melanocytic (58 malignant, 167 benign) test images of the Edinburgh dermofit library.


The web-based test platform provides a miss rate or false negative rate (1-sensitivity) in the diagnosis of melanoma. 

In addition, we made 176 skin diseases diagnosis model (http://modelderm.com) and onychomycosis diagnosis model (http://nail.medicalphoto.org). The diagnostic accuracy of the onychomycosis model was better than 42 dermatologists we tested (The manuscripts are under review).

I hope the CNN would help to screening melanoma. Thank you.",20,63
1220,2017-12-26,2017,12,26,23,7m7ymu,BEST PORTABLE AIR COMPRESSOR REVIEWS AND GUIDE 2017,https://www.reddit.com/r/MachineLearning/comments/7m7ymu/best_portable_air_compressor_reviews_and_guide/,afridisa,1514297734,,1,1
1221,2017-12-26,2017,12,26,23,7m80b4,untitled,https://www.reddit.com/r/MachineLearning/comments/7m80b4/untitled/,anowarul147,1514298348,,0,1
1222,2017-12-26,2017,12,26,23,7m80dm,BEST AIR COMPRESSOR BRANDS REVIEW,https://www.reddit.com/r/MachineLearning/comments/7m80dm/best_air_compressor_brands_review/,afridisa,1514298371,,0,1
1223,2017-12-26,2017,12,26,23,7m828p,BEST PORTABLE AIR COMPRESSOR REVIEWS 2017,https://www.reddit.com/r/MachineLearning/comments/7m828p/best_portable_air_compressor_reviews_2017/,afridisa,1514299033,,2,1
1224,2017-12-27,2017,12,27,0,7m8692,Applying machine learning science to Facebook products,https://www.reddit.com/r/MachineLearning/comments/7m8692/applying_machine_learning_science_to_facebook/,[deleted],1514300415,[deleted],0,1
1225,2017-12-27,2017,12,27,0,7m86to,air compressor blog,https://www.reddit.com/r/MachineLearning/comments/7m86to/air_compressor_blog/,afridisa,1514300588,,1,1
1226,2017-12-27,2017,12,27,0,7m878l,[N] Audio samples from Google's TacoTron 2 TTS system,https://www.reddit.com/r/MachineLearning/comments/7m878l/n_audio_samples_from_googles_tacotron_2_tts_system/,distant_gradient,1514300718,,1,11
1227,2017-12-27,2017,12,27,0,7m88yq,BEST moveable compressor REVIEWS IN 2017,https://www.reddit.com/r/MachineLearning/comments/7m88yq/best_moveable_compressor_reviews_in_2017/,afridisa,1514301267,,1,1
1228,2017-12-27,2017,12,27,0,7m8b7n,BEST PORTABLE AIR COMPRESSOR REVIEWS | AIR COMPRESSOR GUIDE,https://www.reddit.com/r/MachineLearning/comments/7m8b7n/best_portable_air_compressor_reviews_air/,afridisa,1514301978,,1,1
1229,2017-12-27,2017,12,27,0,7m8e5y,Best Portable Air Comressor,https://www.reddit.com/r/MachineLearning/comments/7m8e5y/best_portable_air_comressor/,afridisa,1514302870,,1,1
1230,2017-12-27,2017,12,27,0,7m8ee5,[D] Why mere Machine Learning cannot predict Bitcoin price,https://www.reddit.com/r/MachineLearning/comments/7m8ee5/d_why_mere_machine_learning_cannot_predict/,erogol,1514302944,,23,0
1231,2017-12-27,2017,12,27,0,7m8h64,Swornim Labs | Make Machine Learn: Linear Regression - Hypothesis Simplified,https://www.reddit.com/r/MachineLearning/comments/7m8h64/swornim_labs_make_machine_learn_linear_regression/,[deleted],1514303817,[deleted],0,1
1232,2017-12-27,2017,12,27,1,7m8kec,Swornim Labs | Make Machine Learn: Linear Regression - Hypothesis Simplified,https://www.reddit.com/r/MachineLearning/comments/7m8kec/swornim_labs_make_machine_learn_linear_regression/,swornim00,1514304742,,0,1
1233,2017-12-27,2017,12,27,1,7m8pra,[R] Supervised Learning of Unsupervised Learning Rules,https://www.reddit.com/r/MachineLearning/comments/7m8pra/r_supervised_learning_of_unsupervised_learning/,downtownslim,1514306349,,4,29
1234,2017-12-27,2017,12,27,1,7m8qcy,"Are you interested in AI and want to learn more through tutorials? Check out our new Subreddit called AITutorials here, and make sure to subscribe if you're interested.",https://www.reddit.com/r/MachineLearning/comments/7m8qcy/are_you_interested_in_ai_and_want_to_learn_more/,DiscoverAI,1514306505,,0,1
1235,2017-12-27,2017,12,27,2,7m8x5i,How many of you have experience of Andrew Ng's Coursera ML course?,https://www.reddit.com/r/MachineLearning/comments/7m8x5i/how_many_of_you_have_experience_of_andrew_ngs/,[deleted],1514308386,,0,1
1236,2017-12-27,2017,12,27,3,7m97n1,Machine Learning on macOS for coreML?,https://www.reddit.com/r/MachineLearning/comments/7m97n1/machine_learning_on_macos_for_coreml/,tangoshukudai,1514311317,[removed],0,1
1237,2017-12-27,2017,12,27,4,7m9klf,"[N] Wired: All the creepy, crazy and amazing things that happened in AI in 2017",https://www.reddit.com/r/MachineLearning/comments/7m9klf/n_wired_all_the_creepy_crazy_and_amazing_things/,distant_gradient,1514314913,,1,1
1238,2017-12-27,2017,12,27,4,7m9ohi,A Guide to Scaling Machine Learning Models in Production,https://www.reddit.com/r/MachineLearning/comments/7m9ohi/a_guide_to_scaling_machine_learning_models_in/,hharkous,1514315963,,0,1
1239,2017-12-27,2017,12,27,4,7m9v0q,Forecast for hot research topics in ML in 2018,https://www.reddit.com/r/MachineLearning/comments/7m9v0q/forecast_for_hot_research_topics_in_ml_in_2018/,rachnogstyle,1514317731,,0,1
1240,2017-12-27,2017,12,27,6,7maapa,[P] Deployed my first project (MNIST) as a web app,https://www.reddit.com/r/MachineLearning/comments/7maapa/p_deployed_my_first_project_mnist_as_a_web_app/,iamwil,1514322043,"Been getting into deep learning for the better part of the last couple of months now. This time, I swung back around to deploy my first deep learning project as a web app. 
https://mnist-v11.helmspointapp.com/

Nothing huge, but you can upload images of handwritten numbers, and it just says what number it thinks it is. Just glad I'm making progress learning!",5,0
1241,2017-12-27,2017,12,27,6,7mamvc,[P] Fixed the mnist training gif based on your criticism and wrote part 2 of the blog!,https://www.reddit.com/r/MachineLearning/comments/7mamvc/p_fixed_the_mnist_training_gif_based_on_your/,Gumeo,1514325352,,9,15
1242,2017-12-27,2017,12,27,7,7mavfi,"[D] Given a set of triples of ids [func, param, return], some of the remaining triples can be derived at least statistically",https://www.reddit.com/r/MachineLearning/comments/7mavfi/d_given_a_set_of_triples_of_ids_func_param_return/,[deleted],1514327674,[deleted],0,0
1243,2017-12-27,2017,12,27,7,7maz39,[D] What are good likelihood functions?,https://www.reddit.com/r/MachineLearning/comments/7maz39/d_what_are_good_likelihood_functions/,YUNoStahp,1514328698,"Advanced beginner here that has been reading papers for some time now.

I'm trying to practice implementing algorithms but as a beginner this can be insanely hard. And one of the big obstacles I often encounter are likelihood functions. [I've just come across an example again](https://papers.nips.cc/paper/4321-an-empirical-evaluation-of-thompson-sampling.pdf). In article 2 they explain that P(theta|D) or rather P(r|a,x,theta)*P(theta) is needed for the algorithm.

But how should I approach this? I mean I have some ideas but they're mostly bad and naive. F.e. is it a good idea here to approx. the reward with the reward of the k nearest neighbours? And in general, when you guys see ""likelihood function"", what are you specifically thinking about? And how much does a good likelihood function influence the end-result?

Thanks in advance!",5,3
1244,2017-12-27,2017,12,27,8,7mb5bd,What would you do with billions of images/PDFs/videos/audio files... from the web?,https://www.reddit.com/r/MachineLearning/comments/7mb5bd/what_would_you_do_with_billions_of/,[deleted],1514330412,,0,1
1245,2017-12-27,2017,12,27,9,7mbnpw,Do I need to whiten X?,https://www.reddit.com/r/MachineLearning/comments/7mbnpw/do_i_need_to_whiten_x/,themathstudent,1514335812,,0,1
1246,2017-12-27,2017,12,27,12,7mcjja,ML R&amp;D job: Computational Photography and Computer Vision,https://www.reddit.com/r/MachineLearning/comments/7mcjja/ml_rd_job_computational_photography_and_computer/,MaaDoTaa,1514345815,,0,1
1247,2017-12-27,2017,12,27,13,7mcx6z,Tools for annotating images for object detection?,https://www.reddit.com/r/MachineLearning/comments/7mcx6z/tools_for_annotating_images_for_object_detection/,Moondra2017,1514350344,[removed],0,1
1248,2017-12-27,2017,12,27,14,7md182,here describe and learn the state-of-art overfitting overcome solutions,https://www.reddit.com/r/MachineLearning/comments/7md182/here_describe_and_learn_the_stateofart/,minsukheo,1514351717,,0,1
1249,2017-12-27,2017,12,27,14,7md3e6,FinTech - Machine Learning and Recommenders,https://www.reddit.com/r/MachineLearning/comments/7md3e6/fintech_machine_learning_and_recommenders/,vinods1975,1514352475,,0,1
1250,2017-12-27,2017,12,27,15,7mdb7l,[P] AC-GAN Learns a Biased Distribution,https://www.reddit.com/r/MachineLearning/comments/7mdb7l/p_acgan_learns_a_biased_distribution/,rui_,1514355309,,1,7
1251,2017-12-27,2017,12,27,15,7mdeh5,Purchase server for machine learning,https://www.reddit.com/r/MachineLearning/comments/7mdeh5/purchase_server_for_machine_learning/,[deleted],1514356527,,0,1
1252,2017-12-27,2017,12,27,15,7mdg9v,[D] Good server vendor for machine learning,https://www.reddit.com/r/MachineLearning/comments/7mdg9v/d_good_server_vendor_for_machine_learning/,maestrojeong,1514357234,"Hello, I'm a machine learning researcher working in a laboratory.

We are searching for a new server vendor regarding server purchase. We want a server with 4 gpus(e.g. titan xp) for research. 

Would you recommend me any server vendor?",24,8
1253,2017-12-27,2017,12,27,16,7mdku8,[D] Advances in Dense image prediction,https://www.reddit.com/r/MachineLearning/comments/7mdku8/d_advances_in_dense_image_prediction/,bbsome,1514359032,"I'm not currently doing any research in CV, but recently I'm in a need of a dense prediction model (per pixel) as part of a larger system. I'm mostly aware of using various convolution-deconvolution (a bit like autoencoders), but with skip connections and CRFs for such tasks. Are you guys aware of any other notable hacks/advances/architectures which are particularly well suited for this problems? Feel free to share any experiences in training on dense data.",14,17
1254,2017-12-27,2017,12,27,16,7mdoyq,[D] Fair and Balanced? Bias in machine learning is the intersection between technical limitations and normative questions.,https://www.reddit.com/r/MachineLearning/comments/7mdoyq/d_fair_and_balanced_bias_in_machine_learning_is/,drlukeor,1514360820,,37,52
1255,2017-12-27,2017,12,27,17,7mdwhf,Adam - momentum + y (aka. cost) terms.,https://www.reddit.com/r/MachineLearning/comments/7mdwhf/adam_momentum_y_aka_cost_terms/,akanimax,1514364265,"I had earlier posted this -&gt; https://www.reddit.com/r/MachineLearning/comments/7isnft/ranik_optimizer_mathematical_optimization_for/ 

as an update equation for mathematical optimization. It was the Newton-Raphson method for finding roots of an equation. I thought this method mostly applies for minimization in machine learning as cost is always defined as a positive real valued function. But it was pointed out to me that the update equation of newton-raphson method, which is x = x - y / dy_dx, is unstable at local minimas (where dy_dx = 0) since it makes the update burst to infinity. 

I kept playing with this equation more since it gave me the smoothest curve for what I had been trying to do -&gt; https://github.com/akanimax/my-deity/blob/master/Scripts/IDEA_2/RANIK%20optimizer.ipynb 
and, I was firm on the idea that the update equation must include the cost term (the Einstein's space-time analogy: The dimension of cost is connected with all the parameter dimensions).

Eventually, I landed on this update equation, 
x = x - ((y * dy_dx) / (y + dy_dx^2)); dy_dx = derivative of y wrt. x
link to code -&gt; https://github.com/akanimax/my-deity/blob/master/Scripts/IDEA_2/RANIK%20optimizer%202.0.ipynb
found in last section: ""Equation 2: modified from newton-raphson method"". 

To relate this update equation with the title: 
if we consider the update portion of the equation -&gt;
g(x, y) = (y * x) / (y + x^2) ; y &gt;= 0
It is quite similar to adam since there is a square gradient term in the denominator and the gradient term in the numerator. This equation doesn't use momentum (running averages) and, the learning_rate is replaced by cost (y). 

Now, in Adam, the alpha is initially manually set and is utilised as per the decay equation -&gt; lr_t &lt;- learning_rate * sqrt(1 - beta2^t) / (1 - beta1^t). WIth the equation that I have mentioned, the hypothesis is that this decay is kind of estimating the cost term itself. 

Link to the 3d curve of the g(x, y) function -&gt; https://academo.org/demos/3d-surface-plotter/?expression=(x*y)%2F(x%2B(y*y))&amp;xRange=0%2C+200&amp;yRange=-100%2C+100&amp;resolution=25

Please let me know what you think about this hypothesis and what it's implications are. I would be thankful and highly grateful if you could point me to some more relevant research so that I can move forward with this.
Thank you!",0,2
1256,2017-12-27,2017,12,27,18,7me5mu,"Interaction Networks for Learning about Objects, Relations and Physics - Pytorch Implementation",https://www.reddit.com/r/MachineLearning/comments/7me5mu/interaction_networks_for_learning_about_objects/,[deleted],1514368450,[deleted],0,1
1257,2017-12-27,2017,12,27,19,7me9s8,machine learning: Machine learning will not replace people in all jobs: Study,https://www.reddit.com/r/MachineLearning/comments/7me9s8/machine_learning_machine_learning_will_not/,mr_j_b,1514370247,,0,1
1258,2017-12-27,2017,12,27,19,7medrd,How is maximum likelihood estimation written in terms of expectation with respect to empirical distribution defined by training data? [D],https://www.reddit.com/r/MachineLearning/comments/7medrd/how_is_maximum_likelihood_estimation_written_in/,rjmessibarca,1514372060,"On page 130 of [Deep Learning Book](http://www.deeplearningbook.org/contents/ml.html); 

How is the equation 5.58 same as equation 5.59? What does equation 5.59 even mean?

As far as I know, the Expected value is with respect to a random variable. And its value is the summation of the product of all possible values that the random variable can take and its corresponding probability.",2,2
1259,2017-12-27,2017,12,27,20,7megkv,[P] QuillBot: Sophisticated paraphraser,https://www.reddit.com/r/MachineLearning/comments/7megkv/p_quillbot_sophisticated_paraphraser/,K4j85,1514373280,,11,9
1260,2017-12-27,2017,12,27,20,7mehsh,Solar Power Plant Consultants in India AvantGarde is one of the leading engineering industries in Solar Power Plant consultants in India. #Solar #power #plant #consultants #India #AvantGarde,https://www.reddit.com/r/MachineLearning/comments/7mehsh/solar_power_plant_consultants_in_india_avantgarde/,Pojavsbuju2106,1514373813,,0,1
1261,2017-12-27,2017,12,27,20,7meiky,Rotary Cum DTH Drilling Rig,https://www.reddit.com/r/MachineLearning/comments/7meiky/rotary_cum_dth_drilling_rig/,beaver_tracks,1514374206,,0,1
1262,2017-12-27,2017,12,27,20,7mej3a,Solar Roof Top Consultants in India AvantGarde is one of the leading engineering industries in Solar Roof Top Consultants in India. #solar #roof #top #consultants #India #AvantGarde,https://www.reddit.com/r/MachineLearning/comments/7mej3a/solar_roof_top_consultants_in_india_avantgarde_is/,Pojavsbuju2106,1514374414,,0,1
1263,2017-12-27,2017,12,27,20,7mele9,Sugar Plant Design Consultants in India AvantGarde is one of the leading engineering industries in Sugar Plant Design Consultants in India. #Sugar #plant #design #consultants #India #AvantGarde,https://www.reddit.com/r/MachineLearning/comments/7mele9/sugar_plant_design_consultants_in_india/,Pojavsbuju2106,1514375429,,0,1
1264,2017-12-27,2017,12,27,21,7mep07,[R] On the Effectiveness of Least Squares Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/7mep07/r_on_the_effectiveness_of_least_squares/,solololol,1514376922,,0,14
1265,2017-12-27,2017,12,27,21,7mepak,[D] Is the time and money it takes to get a Masters degree in machine learning worth it in 2018?,https://www.reddit.com/r/MachineLearning/comments/7mepak/d_is_the_time_and_money_it_takes_to_get_a_masters/,deeplearningisameme,1514377039,"With the barrier to entry being reduced to basic Python programming knowledge and learning material / deep learning crash courses everywhere you see, I'm confused whether I should go forward with my original plan of getting a masters degree in AI (computer science) from a US school. 

I already do machine learning related work in my job where I was hired based off what I learnt in my BS and through self learning with scikit learn/tensorflow and the likes. I'm really struggling to understand what the benefit of a masters degree would be to me, I had originally planned to get one as a means of entry into this field.

People with advanced degrees, do you think it's worth the money and energy to work towards a degree in today's time when all these frameworks have made access to this knowledge so widespread? What advantage would that degree offer in terms of a job in the field, other than landing a position with one of the big four which in itself is a long shot?",26,5
1266,2017-12-27,2017,12,27,22,7mf2sw,[R] A Gentle Introduction to Applied Machine Learning as a Search Problem,https://www.reddit.com/r/MachineLearning/comments/7mf2sw/r_a_gentle_introduction_to_applied_machine/,digitalson,1514382168,,0,1
1267,2017-12-27,2017,12,27,23,7mf5mj,Ice Cream Chocolate Bar Packing Machine,https://www.reddit.com/r/MachineLearning/comments/7mf5mj/ice_cream_chocolate_bar_packing_machine/,lgsherry,1514383204,,1,1
1268,2017-12-27,2017,12,27,23,7mf9xl,How to gauge my level of knowledge,https://www.reddit.com/r/MachineLearning/comments/7mf9xl/how_to_gauge_my_level_of_knowledge/,kinghodor1,1514384590,[removed],0,1
1269,2017-12-27,2017,12,27,23,7mfc45,A Tutorial on Information Maximizing Variational Autoencoders (InfoVAE),https://www.reddit.com/r/MachineLearning/comments/7mfc45/a_tutorial_on_information_maximizing_variational/,HaiBitG,1514385316,,0,1
1270,2017-12-28,2017,12,28,0,7mfimm,[R] On Monte Carlo Tree Search and Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/7mfimm/r_on_monte_carlo_tree_search_and_reinforcement/,HigherTopoi,1514387276,,2,30
1271,2017-12-28,2017,12,28,0,7mfslx,"Simple Questions Thread December 27, 2017",https://www.reddit.com/r/MachineLearning/comments/7mfslx/simple_questions_thread_december_27_2017/,AutoModerator,1514390134,[removed],0,1
1272,2017-12-28,2017,12,28,2,7mg73w,[D] Superhuman AI for heads-up no-limit poker: Libratus beats top professionals,https://www.reddit.com/r/MachineLearning/comments/7mg73w/d_superhuman_ai_for_headsup_nolimit_poker/,sksq9,1514394021,,53,188
1273,2017-12-28,2017,12,28,2,7mge4b,[P] PyTorch Implementation of Rainbow DQN for RL,https://www.reddit.com/r/MachineLearning/comments/7mge4b/p_pytorch_implementation_of_rainbow_dqn_for_rl/,xiaoxiao26,1514395802,,1,16
1274,2017-12-28,2017,12,28,3,7mgnum,"https://github.com/ilkarman/DeepLearningFrameworks compares speed and coding style (with jupyter notebooks) of Knet.jl (Julia), MXNet, Caffe2, Gluon, Chainer, CNTK , PyTorch, TensorFlow, Keras and Lasagne implementations of CNNs and RNNs.",https://www.reddit.com/r/MachineLearning/comments/7mgnum/httpsgithubcomilkarmandeeplearningframeworks/,denizyuret,1514398234,,0,1
1275,2017-12-28,2017,12,28,3,7mgqvh,"https://github.com/neulab/dynet-benchmark compares DyNet, TensorFlow, Theano and Chainer on language processing tasks such as an RNN language model, BiLSTM tagger, and a TreeLSTM. See Knet.jl (https://github.com/denizyuret/Knet.jl/tree/master/examples/dynet-benchmark) for a comparison.",https://www.reddit.com/r/MachineLearning/comments/7mgqvh/httpsgithubcomneulabdynetbenchmark_compares_dynet/,denizyuret,1514398989,,0,1
1276,2017-12-28,2017,12,28,3,7mgwz7,[Project]I implemented novelty search in the Unity engine using SharpNEAT,https://www.reddit.com/r/MachineLearning/comments/7mgwz7/projecti_implemented_novelty_search_in_the_unity/,byPasser_x2,1514400593,"Repository: https://github.com/LokiVKlokeNaAndoke/Maze_NoveltySearch_SharpNeat
Novelty search users page: http://eplex.cs.ucf.edu/noveltysearch/userspage/",8,3
1277,2017-12-28,2017,12,28,3,7mgyil,Machine Learning at Berkeley's Crash Course: Part 5 - Decision Trees and Ensemble Models,https://www.reddit.com/r/MachineLearning/comments/7mgyil/machine_learning_at_berkeleys_crash_course_part_5/,pkuznets,1514400981,,0,7
1278,2017-12-28,2017,12,28,4,7mh4o7,Uncanny Road: Collectively synthesizing a never-ending road using pix2pix HD,https://www.reddit.com/r/MachineLearning/comments/7mh4o7/uncanny_road_collectively_synthesizing_a/,icandoitbetter,1514402560,,0,1
1279,2017-12-28,2017,12,28,4,7mh504,Are there any advanced machine learning programs (using python) that can be developed and run on an average computer?,https://www.reddit.com/r/MachineLearning/comments/7mh504/are_there_any_advanced_machine_learning_programs/,tinOfBeans321,1514402645,[removed],0,1
1280,2017-12-28,2017,12,28,4,7mhbpd,Do these loss and accuracy charts look a bit weird?,https://www.reddit.com/r/MachineLearning/comments/7mhbpd/do_these_loss_and_accuracy_charts_look_a_bit_weird/,[deleted],1514404398,,0,1
1281,2017-12-28,2017,12,28,4,7mhd07,Open collaboration project: CapsNet for Graphics Rendering Optimization,https://www.reddit.com/r/MachineLearning/comments/7mhd07/open_collaboration_project_capsnet_for_graphics/,moothyknight,1514404745,,0,1
1282,2017-12-28,2017,12,28,5,7mhe0u,[P] Do these val_accuracy and val_loss charts look a bit strange?,https://www.reddit.com/r/MachineLearning/comments/7mhe0u/p_do_these_val_accuracy_and_val_loss_charts_look/,VladimirStudmuffin,1514405002,"I've been experimenting with some deep learning and have a time-series dataset that I've trying to categorize. Bit of a bamboozle. But Isn't it strange that the val_accuracy drops off and val_loss spikes early in the training, but then climbs towards the training set?

val_accuracy: https://i.imgur.com/1Dkph9D.png

val_loss: https://i.imgur.com/JaCgUtz.png

Anyone know what this means?

My model is as such:

    _________________________________________________________________
    Layer (type)                 Output Shape              Param Nums   
    ===================================================
    dense_1 (Dense)              (None, 48)                1200      
    _________________________________________________________________
    dropout_1 (Dropout)          (None, 48)                0         
    _________________________________________________________________
    dense_2 (Dense)              (None, 24)                1176      
    _________________________________________________________________
    dropout_2 (Dropout)          (None, 24)                0         
    _________________________________________________________________
    dense_3 (Dense)              (None, 24)                600       
    _________________________________________________________________
    dense_4 (Dense)              (None, 3)                 75        
    ===================================================
    Total params: 3,051
    Trainable params: 3,051
    Non-trainable params: 0
    _________________________________________________________________
    None

Edits done for formatting (ease of reading)",9,1
1283,2017-12-28,2017,12,28,5,7mhfjs,[D] Do you know examples of batch aggregate properties being used to model variable sized group properties?,https://www.reddit.com/r/MachineLearning/comments/7mhfjs/d_do_you_know_examples_of_batch_aggregate/,sitmo,1514405395,"Imagjne you have a stack of images of people and  need to predict if they are going to have a good time together. You want to use a NN but there is one problem: the number of people can be large or small. 
A popular technique to handle a variable  number of inputs is to feed all images (features) one by one to a RNN and aggregate them into states, but that's a hack: the sequential ordering of the images doesn't really matter.

One solution I came up with is to feed the stack of images to a regular NN (to extract features like maybe happy faces?, gender?, age? ) and then aggreagete the outputs (for each image) into a fixed size state, and then go from there. Aggregation can be eg taking the mean, use desity estimating, or radial basis functions. The aggregation collapses the variable batch size into a fixed size.

Is there a name for this technique where you handle unordered variable number of inputs via aggregating extracted features across a batch? Do you know of papers where this is being used? Are there other methods other than RNN?",5,3
1284,2017-12-28,2017,12,28,5,7mhfs3,"[P] PyTorch Implementation of Interaction Networks for Learning about Objects, Relations and Physics.",https://www.reddit.com/r/MachineLearning/comments/7mhfs3/p_pytorch_implementation_of_interaction_networks/,codentropy,1514405447,,3,8
1285,2017-12-28,2017,12,28,5,7mhhef,[D] Method to identify subgroups with lowest mean of some variable?,https://www.reddit.com/r/MachineLearning/comments/7mhhef/d_method_to_identify_subgroups_with_lowest_mean/,ckris292,1514405858,"I have a dataset of observations [y,X], where I need to find groups with the lowest conditional average of y|X. 

For example, one group and their averages might be (Y | X_1 = True, X_2, False) = 50 and (Y | X_2 = False, X_2 = False) = 100.

A good interpretation is that these are customers and I want to find the most valuable ones.

One idea is decision trees, but I'm not sure this yields the optimal groups for my problem. My intuition is that decision trees mainly are used for prediction, so the focus of the algorithms might be different. Another idea is a brute force search.

Can someone give point me in the right direction with some concepts (maybe just search keywords) of how this problem is solved in ML?

",6,1
1286,2017-12-28,2017,12,28,5,7mhil2,Way to Recognize Handwriting in Scanned Forms/Tables?,https://www.reddit.com/r/MachineLearning/comments/7mhil2/way_to_recognize_handwriting_in_scanned/,mopperv,1514406146,[removed],0,1
1287,2017-12-28,2017,12,28,6,7mhu1v,[R] 4 Machine Learning Trends that Made 2017,https://www.reddit.com/r/MachineLearning/comments/7mhu1v/r_4_machine_learning_trends_that_made_2017/,kriss75,1514409173,,1,1
1288,2017-12-28,2017,12,28,6,7mhu84,"Which should I choose, Artificial Intelligence Nanodegree, Machine Learning Nanodegree or Deep Learning Nanodegree?",https://www.reddit.com/r/MachineLearning/comments/7mhu84/which_should_i_choose_artificial_intelligence/,ASamir,1514409210,[removed],0,1
1289,2017-12-28,2017,12,28,6,7mi3sj,Keyword Extraction on Short Text With Machine Learning (seq2seq),https://www.reddit.com/r/MachineLearning/comments/7mi3sj/keyword_extraction_on_short_text_with_machine/,TheApeMachine,1514411749,,0,1
1290,2017-12-28,2017,12,28,7,7mi9uj,"Hey everyone, I'm new to AI. Can you guys quiz me so that I can get a feel for how much I need to learn?",https://www.reddit.com/r/MachineLearning/comments/7mi9uj/hey_everyone_im_new_to_ai_can_you_guys_quiz_me_so/,IanPrado,1514413352,[removed],0,1
1291,2017-12-28,2017,12,28,8,7minyd,TensorRT now has Python library. Boost your inference speed and hardware utilization in few lines of code.,https://www.reddit.com/r/MachineLearning/comments/7minyd/tensorrt_now_has_python_library_boost_your/,Nicolas_Weber,1514417101,,0,1
1292,2017-12-28,2017,12,28,8,7mitu7,A local hebbian rule for deep learning,https://www.reddit.com/r/MachineLearning/comments/7mitu7/a_local_hebbian_rule_for_deep_learning/,thomas_h_ward,1514418747,"This hebbian/anti-hebbian rule (see below) efficiently converges deep models in the context of a Reinforcement Learning regime. 

In a nutshell the rule says if there is no pre-synaptic spike then there will be no weight change (to preserve connections that were not responsible). Otherwise the direction of weight change will depend on whether a post-synaptic spike occured and whether there was a reward.

I have not been able to find much existing work re: local rules for deep models, however it's quite likely this rule exists elsewhere..

- Does this rule (or similiar) already exist ? Does it fall under an existing framework (eg Williams REINFORCE)?
- What are the likely shortcomings/limitations (eg scaling issues) ?


Many thanks.
 

    1a) Pre-synaptic spike = N
        -&gt; no weight change 
    1b) Pre-synaptic spike = Y
        2a) Post-synaptic spike = Y
            3a) Reward = Y
                -&gt; increase weight 
            3b) Reward = N 
                -&gt; decrease weight	
        2b) Post-synaptic spike = N
            3c) Reward = Y
                -&gt; decrease weight	
            3d) Reward = N  
                -&gt; increase weight



(ref: page 22 https://arxiv.org/pdf/1609.03348.pdf )
",6,4
1293,2017-12-28,2017,12,28,9,7mj4sk,[P] Uncanny Road,https://www.reddit.com/r/MachineLearning/comments/7mj4sk/p_uncanny_road/,wei_jok,1514421879,,8,27
1294,2017-12-28,2017,12,28,10,7mjair,1080ti EVGA with iCX - async fans,https://www.reddit.com/r/MachineLearning/comments/7mjair/1080ti_evga_with_icx_async_fans/,gurgehx,1514423513,[removed],0,1
1295,2017-12-28,2017,12,28,10,7mjgf2,CSGNet: Neural Shape Parser for Constructive Solid Geometry,https://www.reddit.com/r/MachineLearning/comments/7mjgf2/csgnet_neural_shape_parser_for_constructive_solid/,[deleted],1514425320,[deleted],0,1
1296,2017-12-28,2017,12,28,12,7mjxl4,"[D] Vote for Best of Machine Learning for 2017 -Categories include papers, talks, videos, applications, projects, reddit comments, Cross Validated - Stack Exchange posts, innovations, tools, and projects.",https://www.reddit.com/r/MachineLearning/comments/7mjxl4/d_vote_for_best_of_machine_learning_for_2017/,SGuptMachineLearning,1514430513,"Hello everyone,

I think it would be fun if we votes for best of 2017 for machine learning stuff. I thought of a few categories, feel free to make more. Here are the categories I've thought of so far.

Best paper

Best innovation (may go hand in hand with best paper \_()_/)

Best application (may go hand in hand with best paper \_()_/)

Best video

Best youtube channel

Best blog post

Best blog overall

Best course (released in 2017)

Best book (released in 2017)

Best reddit comment/post

Best Cross Validated - Stack Exchange posts

Best project

Best new tool

Anything else?",30,14
1297,2017-12-28,2017,12,28,13,7mkfyt,Rule based System,https://www.reddit.com/r/MachineLearning/comments/7mkfyt/rule_based_system/,munishmaxtech,1514436310,,0,1
1298,2017-12-28,2017,12,28,14,7mkp04,Using XGBoost for time series prediction tasks,https://www.reddit.com/r/MachineLearning/comments/7mkp04/using_xgboost_for_time_series_prediction_tasks/,kiser_soze,1514439308,,0,1
1299,2017-12-28,2017,12,28,15,7mktoi,untitled,https://www.reddit.com/r/MachineLearning/comments/7mktoi/untitled/,anowarul147,1514440925,,0,1
1300,2017-12-28,2017,12,28,16,7ml3d7,How to distinguish between two kinds of 7s?,https://www.reddit.com/r/MachineLearning/comments/7ml3d7/how_to_distinguish_between_two_kinds_of_7s/,sudeepraja,1514444532,,0,1
1301,2017-12-28,2017,12,28,16,7mlbrf,PC build for ML/DL,https://www.reddit.com/r/MachineLearning/comments/7mlbrf/pc_build_for_mldl/,ranir111,1514447993,[removed],0,1
1302,2017-12-28,2017,12,28,17,7mlbxh,Any books/articles/resources you recommend on neural networks/machine learning in general?,https://www.reddit.com/r/MachineLearning/comments/7mlbxh/any_booksarticlesresources_you_recommend_on/,sabi0,1514448065,[removed],0,1
1303,2017-12-28,2017,12,28,19,7mltg6,Franking Machines for the Arduous Mailing Process,https://www.reddit.com/r/MachineLearning/comments/7mltg6/franking_machines_for_the_arduous_mailing_process/,mailcoms4,1514456192,,0,1
1304,2017-12-28,2017,12,28,19,7mlwf4,"[P]style2paintsII: The Most Accurate, Most Natural, Most Harmonious Anime Sketch Colorization and the Best Anime Style Transfer",https://www.reddit.com/r/MachineLearning/comments/7mlwf4/pstyle2paintsii_the_most_accurate_most_natural/,q914847518,1514457573,,94,460
1305,2017-12-28,2017,12,28,19,7mlyqh,"As a game developer, am I on the right track to acquire the skills to create improved AI?",https://www.reddit.com/r/MachineLearning/comments/7mlyqh/as_a_game_developer_am_i_on_the_right_track_to/,2Radon,1514458632,[removed],0,1
1306,2017-12-28,2017,12,28,20,7mm1zk,Cloud Computing | CTO Services | Mobile Application Development Company,https://www.reddit.com/r/MachineLearning/comments/7mm1zk/cloud_computing_cto_services_mobile_application/,tetranoodle,1514460037,,0,1
1307,2017-12-28,2017,12,28,20,7mm2jj,[R][1705.08439] Thinking Fast and Slow with Deep Learning and Tree Search,https://www.reddit.com/r/MachineLearning/comments/7mm2jj/r170508439_thinking_fast_and_slow_with_deep/,ArneVogel,1514460283,,1,8
1308,2017-12-28,2017,12,28,20,7mm3kg,"Our third episode featuring Craftinity's CTO, Mattew Opala. Mattew explains what object detection is, its types and how it might be applied as a solution for different fields.",https://www.reddit.com/r/MachineLearning/comments/7mm3kg/our_third_episode_featuring_craftinitys_cto/,Craftinity,1514460733,,0,1
1309,2017-12-28,2017,12,28,20,7mm3mu,The Future of Machine Intelligence [Video],https://www.reddit.com/r/MachineLearning/comments/7mm3mu/the_future_of_machine_intelligence_video/,LTP1,1514460770,,0,1
1310,2017-12-28,2017,12,28,21,7mm9kz,Paddy Sheller Machine|Rice Hulling Huller Machinery Price,https://www.reddit.com/r/MachineLearning/comments/7mm9kz/paddy_sheller_machinerice_hulling_huller/,gelserena,1514463339,,1,1
1311,2017-12-28,2017,12,28,22,7mmlik,"[N] Weekly Machine Learning Opensource Roundup  Dec. 28, 2017",https://www.reddit.com/r/MachineLearning/comments/7mmlik/n_weekly_machine_learning_opensource_roundup_dec/,stkim1,1514467819,,0,1
1312,2017-12-28,2017,12,28,22,7mmnsz,Walnut Cracker Sheller Machine|Hazelnut Cracking Shelling Machine Manufacturers,https://www.reddit.com/r/MachineLearning/comments/7mmnsz/walnut_cracker_sheller_machinehazelnut_cracking/,gelserena,1514468649,,1,1
1313,2017-12-28,2017,12,28,23,7mmv61,DeepSymphony - extensive exploration of deep learning models for music composition (Best viewed on computer),https://www.reddit.com/r/MachineLearning/comments/7mmv61/deepsymphony_extensive_exploration_of_deep/,edwardthegreat2,1514471147,[removed],0,1
1314,2017-12-28,2017,12,28,23,7mmy7b,Small Scale Hemp Seed Shelling Hulling Machine|Coffee Bean Huller,https://www.reddit.com/r/MachineLearning/comments/7mmy7b/small_scale_hemp_seed_shelling_hulling/,gelserena,1514472102,,1,1
1315,2017-12-29,2017,12,29,0,7mn5qq,Can you explain how a matrix translates into machine learning to someone who barely understands NN at all?,https://www.reddit.com/r/MachineLearning/comments/7mn5qq/can_you_explain_how_a_matrix_translates_into/,2Radon,1514474354,[removed],0,1
1316,2017-12-29,2017,12,29,0,7mn6l1,KotlinNLP - NeuralParser | http://www.dependencyparsing.com/,https://www.reddit.com/r/MachineLearning/comments/7mn6l1/kotlinnlp_neuralparser_httpwwwdependencyparsingcom/,NLPLover,1514474593,[removed],0,1
1317,2017-12-29,2017,12,29,0,7mn8l7,Walnut Shelling Machine|Macadmia Shell Cracking Machines Manufacturer,https://www.reddit.com/r/MachineLearning/comments/7mn8l7/walnut_shelling_machinemacadmia_shell_cracking/,gelserena,1514475159,,1,1
1318,2017-12-29,2017,12,29,1,7mnn17,[Discussion]Does the generator of the conditional GAN take random noise as its input? or just conditioning img only?,https://www.reddit.com/r/MachineLearning/comments/7mnn17/discussiondoes_the_generator_of_the_conditional/,sonsus,1514479045,"Lured by wonderful and impressive applications of GANs I starting my first DL project with pix2pix model for modifying imgs. I thought I just overlooked this so far while reading other GANs but... doesnt the generator part should take its input with noise? if the model is conditioned, shouldn't it have noise concatenated with the conditioning img? 

In the paper, Image-to-Image translation with conditional adversarial networks (P.Isola et al., CVPR, 2016), the loss function for their network shows that Generator should have two inputs as it G(x,z) has two parameters. 

Could G(x,z) be easily replaced with G(x)? Sounds somewhat making sense but Im not really sure. Is there any reference of it? or just a tradition from experiences?",3,0
1319,2017-12-29,2017,12,29,1,7mns0b,Inspirations from Worms at NIPS2017,https://www.reddit.com/r/MachineLearning/comments/7mns0b/inspirations_from_worms_at_nips2017/,[deleted],1514480359,[deleted],0,1
1320,2017-12-29,2017,12,29,2,7mnuwd,[D]Inspirations from Worms at NIPS2017,https://www.reddit.com/r/MachineLearning/comments/7mnuwd/dinspirations_from_worms_at_nips2017/,wencc,1514481055,,1,12
1321,2017-12-29,2017,12,29,2,7mo0ov,Xavier Initialization Intuition,https://www.reddit.com/r/MachineLearning/comments/7mo0ov/xavier_initialization_intuition/,[deleted],1514482558,[deleted],0,1
1322,2017-12-29,2017,12,29,2,7mo313,[D] Xavier Initialization Intuition,https://www.reddit.com/r/MachineLearning/comments/7mo313/d_xavier_initialization_intuition/,whoisburbansky,1514483165,,3,6
1323,2017-12-29,2017,12,29,3,7mobgf,Football Match Predictor,https://www.reddit.com/r/MachineLearning/comments/7mobgf/football_match_predictor/,Monicaesque,1514485179,[removed],0,1
1324,2017-12-29,2017,12,29,3,7mohi3,[D] Learning to forget. Optimizing a confusion loss to remove bias.,https://www.reddit.com/r/MachineLearning/comments/7mohi3/d_learning_to_forget_optimizing_a_confusion_loss/,brannondorsey,1514486720,"A few months ago I stumbled onto an interesting idea while listening to the [TWiML &amp; AI podcast](https://twimlai.com/). It described a process by which one could attempt to introduce confusion into a network (starting at any arbitrary hidden layer) so that it couldn't learn from select biases in the training data. For example, if you were training an image classification network, and you wanted to forbid the network to learn anything about race, you could use this technique, to do so. The problem is that I can't for the life of me remember what this technique is called, or what episode of the podcast it was discussed in. 

All that I remember is that I believe that the method proposed involved choosing a layer beyond which you didn't want the network to be able to include information about the bias you were trying to remove (the layer becomes a filter of sorts), and using that layer as input to a second neural network that was optimizing a confusion loss. Provided you had labels about race, the second, auxiliary network would maximize (yes, maximize) its loss in a classification task identifying race (the characteristic you wan't the main network to forget). Therefore, the second network would learn parameters that actually don't know how to distinguish between races in images. Training a bias-removal/confusion auxiliary network in this way would cause the parameters of the filter layer to be updated such that the main network wouldn't be able to use its activation's to learn the biases you are trying to remove in downstream layers to solve the original image classification task. 

Does anyone have a clue what this method is called, or have interesting/helpful links to where I could learn more about it? Thanks!",5,0
1325,2017-12-29,2017,12,29,4,7moz4y,Best book for beginners?,https://www.reddit.com/r/MachineLearning/comments/7moz4y/best_book_for_beginners/,[deleted],1514491049,,0,1
1326,2017-12-29,2017,12,29,6,7mpebw,[D] Meta-learning,https://www.reddit.com/r/MachineLearning/comments/7mpebw/d_metalearning/,spartan12321,1514494935,"I have read a lot about neural networks (and it's application to vision and language) and statistical learning, now I realised there is area caled ""meta-learning"". Is there any site with papers that could introduce me to this field or anything that will help me to productively approach this field?",7,4
1327,2017-12-29,2017,12,29,7,7mpv21,Working with caret and svm in R,https://www.reddit.com/r/MachineLearning/comments/7mpv21/working_with_caret_and_svm_in_r/,selrok,1514499161,[removed],0,1
1328,2017-12-29,2017,12,29,9,7mqlo7,Using Q-Learning to control electric battery storage,https://www.reddit.com/r/MachineLearning/comments/7mqlo7/using_qlearning_to_control_electric_battery/,ADGEfficiency,1514506273,,0,1
1329,2017-12-29,2017,12,29,9,7mqpxi,Can AI have the ability to invent new things?,https://www.reddit.com/r/MachineLearning/comments/7mqpxi/can_ai_have_the_ability_to_invent_new_things/,AstralMove,1514507435,[removed],0,1
1330,2017-12-29,2017,12,29,9,7mqs69,"Simple ML problem, but I'm a noob.",https://www.reddit.com/r/MachineLearning/comments/7mqs69/simple_ml_problem_but_im_a_noob/,zefcfd,1514508074,[removed],0,1
1331,2017-12-29,2017,12,29,10,7mr6qx,D: What type of Asimov-style rules would robot hosts have in HBO's Westworld?,https://www.reddit.com/r/MachineLearning/comments/7mr6qx/d_what_type_of_asimovstyle_rules_would_robot/,[deleted],1514512348,,0,1
1332,2017-12-29,2017,12,29,10,7mr7j5,[R] [1712.09913] Visualizing the Loss Landscape of Neural Nets,https://www.reddit.com/r/MachineLearning/comments/7mr7j5/r_171209913_visualizing_the_loss_landscape_of/,oxydis,1514512577,,11,98
1333,2017-12-29,2017,12,29,11,7mr9no,[P] School project with neural network,https://www.reddit.com/r/MachineLearning/comments/7mr9no/p_school_project_with_neural_network/,[deleted],1514513208,[deleted],1,0
1334,2017-12-29,2017,12,29,11,7mrbkv,[D] What type of Asimov-style rules would robot hosts have in HBO's Westworld?,https://www.reddit.com/r/MachineLearning/comments/7mrbkv/d_what_type_of_asimovstyle_rules_would_robot/,[deleted],1514513778,[deleted],1,0
1335,2017-12-29,2017,12,29,12,7mrm2f,Die Roboterapocolypse ist jetzt in Deutsch! ...trained a seq2seq through 13 epochs all night and morning. Only after I started talking with it did I realize that I accidentally gave it German instead of English.,https://www.reddit.com/r/MachineLearning/comments/7mrm2f/die_roboterapocolypse_ist_jetzt_in_deutsch/,devi83,1514516881,[removed],0,1
1336,2017-12-29,2017,12,29,12,7mrpva,All about the GANs (new list),https://www.reddit.com/r/MachineLearning/comments/7mrpva/all_about_the_gans_new_list/,hollobit,1514518067,,0,1
1337,2017-12-29,2017,12,29,13,7ms5rb,[R][1712.09662] CNN Is All You Need,https://www.reddit.com/r/MachineLearning/comments/7ms5rb/r171209662_cnn_is_all_you_need/,m_ke,1514523141,,8,24
1338,2017-12-29,2017,12,29,14,7ms7vz,[P] ThunderSVM: A Fast SVM Library on GPUs and CPUs,https://www.reddit.com/r/MachineLearning/comments/7ms7vz/p_thundersvm_a_fast_svm_library_on_gpus_and_cpus/,visarga,1514523828,,7,32
1339,2017-12-29,2017,12,29,14,7msgnz,[1712.09196] The Robust Manifold Defense: Adversarial Training using Generative Models,https://www.reddit.com/r/MachineLearning/comments/7msgnz/171209196_the_robust_manifold_defense_adversarial/,alexmlamb,1514526716,,0,1
1340,2017-12-29,2017,12,29,14,7mshe4,Colloid Mill Peanut Butter Grinding Machine|Peanut Paste Making Machine,https://www.reddit.com/r/MachineLearning/comments/7mshe4/colloid_mill_peanut_butter_grinding_machinepeanut/,gelgoogcara,1514526961,,1,1
1341,2017-12-29,2017,12,29,15,7msjft,Automatic Sesame Seeds Washing And Drying Machine With Factory Price For Sale,https://www.reddit.com/r/MachineLearning/comments/7msjft/automatic_sesame_seeds_washing_and_drying_machine/,gelgoogcara,1514527671,,1,1
1342,2017-12-29,2017,12,29,16,7mst6g,Coconut Meat Dicing Machine|Cutting Machines Video,https://www.reddit.com/r/MachineLearning/comments/7mst6g/coconut_meat_dicing_machinecutting_machines_video/,gelserena,1514531324,,1,1
1343,2017-12-29,2017,12,29,16,7msvct,[D] Demystifying Face Recognition IV: Face-Aligment,https://www.reddit.com/r/MachineLearning/comments/7msvct/d_demystifying_face_recognition_iv_facealigment/,[deleted],1514532153,[deleted],0,1
1344,2017-12-29,2017,12,29,16,7mt06r,[D] Demystifying Face Recognition IV: Face-Alignment,https://www.reddit.com/r/MachineLearning/comments/7mt06r/d_demystifying_face_recognition_iv_facealignment/,melgor89,1514534128,,0,10
1345,2017-12-29,2017,12,29,17,7mt2kh,How To Package Popsicle For Sale,https://www.reddit.com/r/MachineLearning/comments/7mt2kh/how_to_package_popsicle_for_sale/,lgsherry,1514535095,,1,1
1346,2017-12-29,2017,12,29,18,7mtesr,Companies urged to embrace machine learning solutions,https://www.reddit.com/r/MachineLearning/comments/7mtesr/companies_urged_to_embrace_machine_learning/,mr_j_b,1514540623,,0,1
1347,2017-12-29,2017,12,29,20,7mtqxz,[R] New FastText paper: Advances in Pre-Training Distributed Word Representations,https://www.reddit.com/r/MachineLearning/comments/7mtqxz/r_new_fasttext_paper_advances_in_pretraining/,nickl,1514545877,,12,41
1348,2017-12-29,2017,12,29,20,7mtvcm,[Discussion] You shouldn't worry about AI - yet.,https://www.reddit.com/r/MachineLearning/comments/7mtvcm/discussion_you_shouldnt_worry_about_ai_yet/,Clockwork_Luke,1514547837,,4,0
1349,2017-12-29,2017,12,29,21,7mu35l,[R] PixelSNAIL: An Improved Autoregressive Generative Model,https://www.reddit.com/r/MachineLearning/comments/7mu35l/r_pixelsnail_an_improved_autoregressive/,HigherTopoi,1514551113,,8,17
1350,2017-12-29,2017,12,29,21,7mu43a,Three Axis Pipe | Single Axis Pipe | Bending Machine,https://www.reddit.com/r/MachineLearning/comments/7mu43a/three_axis_pipe_single_axis_pipe_bending_machine/,RapidFlowIndia1,1514551478,,0,1
1351,2017-12-29,2017,12,29,22,7mug0g,Plastic Granules Drying Machine|Grain Dryer Machine for Sale,https://www.reddit.com/r/MachineLearning/comments/7mug0g/plastic_granules_drying_machinegrain_dryer/,gelserena,1514555993,,1,1
1352,2017-12-29,2017,12,29,23,7mumt6,Analyzing credit card transactions using machine learning techniques,https://www.reddit.com/r/MachineLearning/comments/7mumt6/analyzing_credit_card_transactions_using_machine/,J3diMindTricks,1514558203,,0,1
1353,2017-12-29,2017,12,29,23,7muqe7,[OC] The State of Decentralized AI in 2018,https://www.reddit.com/r/MachineLearning/comments/7muqe7/oc_the_state_of_decentralized_ai_in_2018/,[deleted],1514559355,[deleted],0,1
1354,2017-12-30,2017,12,30,0,7muxgk,[D] Occams razor and current state of DL,https://www.reddit.com/r/MachineLearning/comments/7muxgk/d_occams_razor_and_current_state_of_dl/,roar363,1514561463,"A lot of state of art techniques that have become popular in last 10 years appear to be based on fairly simple principles. For e.g.- best optimisers we use today. Momentum, RMSProp, Adam. 
State of art in object detection- Yolov2 , RCNN, Siamese network etc. 
Do you think Occams razor is playing role here? 
It is totally possible this is just correlation and I am missing lot of say complex techniques that are popular but I am not aware of.  Whats your opinion? ",9,7
1355,2017-12-30,2017,12,30,0,7muyd1,Looking for a study companion,https://www.reddit.com/r/MachineLearning/comments/7muyd1/looking_for_a_study_companion/,purple_jarvis,1514561736,[removed],0,1
1356,2017-12-30,2017,12,30,0,7muyz2,[D] Full graduate course in Bayesian ML [videos + slides + homework],https://www.reddit.com/r/MachineLearning/comments/7muyz2/d_full_graduate_course_in_bayesian_ml_videos/,Kiuhnm,1514561921,,76,314
1357,2017-12-30,2017,12,30,0,7mv06t,Bangla Puzzle and Jokes EP#10,https://www.reddit.com/r/MachineLearning/comments/7mv06t/bangla_puzzle_and_jokes_ep10/,anowarul147,1514562268,,0,1
1358,2017-12-30,2017,12,30,0,7mv12u,[N] Machine Learning Terminology Explained: Top 8 Must-Know Concepts,https://www.reddit.com/r/MachineLearning/comments/7mv12u/n_machine_learning_terminology_explained_top_8/,gemsergio,1514562498,,2,21
1359,2017-12-30,2017,12,30,1,7mv8re,[D] Gaussian Processes tutorial,https://www.reddit.com/r/MachineLearning/comments/7mv8re/d_gaussian_processes_tutorial/,efavdb,1514564601,,1,6
1360,2017-12-30,2017,12,30,1,7mv8tw,[R] [1702.08431] Boundary Seeking GAN (now with text generation!),https://www.reddit.com/r/MachineLearning/comments/7mv8tw/r_170208431_boundary_seeking_gan_now_with_text/,transpostmeta,1514564617,,1,1
1361,2017-12-30,2017,12,30,1,7mv935,[D] Synthetic Gradients Tutorial - How to speed up Deep Learning Training (Aurlien Geron),https://www.reddit.com/r/MachineLearning/comments/7mv935/d_synthetic_gradients_tutorial_how_to_speed_up/,programmerChilli,1514564684,,11,25
1362,2017-12-30,2017,12,30,2,7mvlfj,[D] Adversarial Learning for Good: Deep Learning Blindspots (from #34c3),https://www.reddit.com/r/MachineLearning/comments/7mvlfj/d_adversarial_learning_for_good_deep_learning/,pmigdal,1514567945,,1,3
1363,2017-12-30,2017,12,30,4,7mwk68,AI Weekly 29 Dec 2017,https://www.reddit.com/r/MachineLearning/comments/7mwk68/ai_weekly_29_dec_2017/,TomekB,1514576949,,0,1
1364,2017-12-30,2017,12,30,5,7mwx1e,Modular Composition Networks for Deep RL,https://www.reddit.com/r/MachineLearning/comments/7mwx1e/modular_composition_networks_for_deep_rl/,[deleted],1514580381,[deleted],0,2
1365,2017-12-30,2017,12,30,6,7mx2bo,Solar Power Plant Consultants in India AvantGarde is one of the leading engineering industries in Solar Power Plant consultants in India. #Solar #power #plant #consultants #India #AvantGarde,https://www.reddit.com/r/MachineLearning/comments/7mx2bo/solar_power_plant_consultants_in_india_avantgarde/,Pojavsbuju2106,1514581800,,0,1
1366,2017-12-30,2017,12,30,6,7mx303,[R] Modular Composition Networks for Deep RL,https://www.reddit.com/r/MachineLearning/comments/7mx303/r_modular_composition_networks_for_deep_rl/,n00bkilla555,1514581973,,2,18
1367,2017-12-30,2017,12,30,9,7my78z,Artificial Intelligence for Kids,https://www.reddit.com/r/MachineLearning/comments/7my78z/artificial_intelligence_for_kids/,funmaster11,1514592972,,0,1
1368,2017-12-30,2017,12,30,9,7my9tj,DeepZip: Lossless Compression using Recurrent Networks,https://www.reddit.com/r/MachineLearning/comments/7my9tj/deepzip_lossless_compression_using_recurrent/,vonnik,1514593719,,0,1
1369,2017-12-30,2017,12,30,9,7myc7m,Good tagging software?,https://www.reddit.com/r/MachineLearning/comments/7myc7m/good_tagging_software/,CMDR_Supagoat,1514594413,[removed],0,1
1370,2017-12-30,2017,12,30,11,7myvwk,[D] Neural network model that creates its own labels,https://www.reddit.com/r/MachineLearning/comments/7myvwk/d_neural_network_model_that_creates_its_own_labels/,chubbyspartn,1514600344,"Has any work been do on neural networks that can generate their own labels?

The thought would be, humans can improve at games like chess without being told explicitly what good moves are. Someone can play lots of games and start to lable certain ideas as good or bad. Maybe they notice that having center control leads to more wins, and moving the same price many times leads to losses.  With this in mind I am wondering if this type of idea has implemented before, learning off of only wins and losses. If so, can this be extended to learning that isnt associateed with games?",10,0
1371,2017-12-30,2017,12,30,12,7mzabu,"[P] Text Categorization using MLP, CNN &amp; Graph CNN in TensorFlow.",https://www.reddit.com/r/MachineLearning/comments/7mzabu/p_text_categorization_using_mlp_cnn_graph_cnn_in/,[deleted],1514605053,[deleted],0,1
1372,2017-12-30,2017,12,30,13,7mzfdy,Looking for advice on how to proceed with neural networks,https://www.reddit.com/r/MachineLearning/comments/7mzfdy/looking_for_advice_on_how_to_proceed_with_neural/,[deleted],1514606717,,0,1
1373,2017-12-30,2017,12,30,13,7mzjsf,Top 5 opensource for Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/7mzjsf/top_5_opensource_for_artificial_intelligence/,lokeshreddy07,1514608254,,0,1
1374,2017-12-30,2017,12,30,14,7mzvmh,Best conferences in Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/7mzvmh/best_conferences_in_machine_learning/,recursingrecursion,1514612469,[removed],0,1
1375,2017-12-30,2017,12,30,15,7n055l,How does one design regularizers such that they match the parameters that generated the data when one has strong priors about the parameters?,https://www.reddit.com/r/MachineLearning/comments/7n055l/how_does_one_design_regularizers_such_that_they/,real_pinocchio,1514616092,,0,1
1376,2017-12-30,2017,12,30,15,7n078c,[D] Embodied Learning is Essential to Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/7n078c/d_embodied_learning_is_essential_to_artificial/,inarrears,1514616961,,6,5
1377,2017-12-30,2017,12,30,16,7n08x4,Bad Data is Really Bad for Machine Learning: Heres Some Ways to Fix It,https://www.reddit.com/r/MachineLearning/comments/7n08x4/bad_data_is_really_bad_for_machine_learning_heres/,dexlabanalytics,1514617675,,0,1
1378,2017-12-30,2017,12,30,17,7n0gej,"What are some projects for a beginner in machine learning, any idea or resources from which i can learn ?",https://www.reddit.com/r/MachineLearning/comments/7n0gej/what_are_some_projects_for_a_beginner_in_machine/,Dragonborn_negan,1514621112,[removed],0,1
1379,2017-12-30,2017,12,30,17,7n0klf,[D] seq2seq why use cross entropy loss?,https://www.reddit.com/r/MachineLearning/comments/7n0klf/d_seq2seq_why_use_cross_entropy_loss/,[deleted],1514623115,[deleted],5,2
1380,2017-12-30,2017,12,30,18,7n0oml,Cotton Seed Dryer Manufacturers,https://www.reddit.com/r/MachineLearning/comments/7n0oml/cotton_seed_dryer_manufacturers/,eairsystems,1514625175,,0,1
1381,2017-12-30,2017,12,30,18,7n0sd2,Introducing one of the best hacks in machine learning: the hashing trick,https://www.reddit.com/r/MachineLearning/comments/7n0sd2/introducing_one_of_the_best_hacks_in_machine/,pagels,1514627097,,0,1
1382,2017-12-30,2017,12,30,20,7n16x8,Platform that Makes Professional Machine Learning Developers,https://www.reddit.com/r/MachineLearning/comments/7n16x8/platform_that_makes_professional_machine_learning/,fusioninformaticsusa,1514634691,[removed],0,1
1383,2017-12-30,2017,12,30,21,7n19yb,Resources for learning Backpropagation,https://www.reddit.com/r/MachineLearning/comments/7n19yb/resources_for_learning_backpropagation/,batuhanyil,1514636135,[removed],0,1
1384,2017-12-30,2017,12,30,21,7n1chb,Word2Vec text image visualisation,https://www.reddit.com/r/MachineLearning/comments/7n1chb/word2vec_text_image_visualisation/,raduangelescu,1514637295,,0,1
1385,2017-12-31,2017,12,31,0,7n1yvo,GANs for phone camera/lens improvement,https://www.reddit.com/r/MachineLearning/comments/7n1yvo/gans_for_phone_cameralens_improvement/,fourthie,1514646367,[removed],0,1
1386,2017-12-31,2017,12,31,0,7n1z4y,Machine Learning for Universal Free Education,https://www.reddit.com/r/MachineLearning/comments/7n1z4y/machine_learning_for_universal_free_education/,masterwhois,1514646443,,0,1
1387,2017-12-31,2017,12,31,2,7n2l6q,"Now that I have a trained seq2seq conversational model, how can I retrain it with different data? I used someones seq2seq code on github, but would like to use the trained model with other types of training such as image recognition.",https://www.reddit.com/r/MachineLearning/comments/7n2l6q/now_that_i_have_a_trained_seq2seq_conversational/,devi83,1514653259,[removed],0,1
1388,2017-12-31,2017,12,31,4,7n3bkz,Is C/C++ still relevant for ML now that we have Tensorflow and Theano?,https://www.reddit.com/r/MachineLearning/comments/7n3bkz/is_cc_still_relevant_for_ml_now_that_we_have/,vandelet_industries,1514660475,[removed],0,1
1389,2017-12-31,2017,12,31,4,7n3dot,Artificial Intelligence for Kids,https://www.reddit.com/r/MachineLearning/comments/7n3dot/artificial_intelligence_for_kids/,[deleted],1514661028,[deleted],0,1
1390,2017-12-31,2017,12,31,4,7n3fnx,Techno-utopianism. We are far from having a generalized intelligent AI. Gary Marcus 12 min,https://www.reddit.com/r/MachineLearning/comments/7n3fnx/technoutopianism_we_are_far_from_having_a/,dylanoliver233,1514661581,,0,1
1391,2017-12-31,2017,12,31,4,7n3l76,[D] Finding minimal changes to a sentence to change sentiment,https://www.reddit.com/r/MachineLearning/comments/7n3l76/d_finding_minimal_changes_to_a_sentence_to_change/,covolution,1514663101,"Here is a problem I am thinking of: given a sentence with some predicted sentiment (e.g. positive), what are the fewest number of changes to the sentence needed in order to change the sentiment.  I am assuming you already have a good model that can predict the sentiment of a sentence.

A simple example is, for a movie review is this:  imagine a movie review was *this movie was good*.  The simplest way to make this sentence a negative review might be  *this movie was* **not** *good*.  I'm curious on how others may want to set up this problem.


",19,34
1392,2017-12-31,2017,12,31,6,7n44t3,Top 7 Books in Artificial Intelligence &amp; Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7n44t3/top_7_books_in_artificial_intelligence_machine/,yildiz17,1514668588,,0,1
1393,2017-12-31,2017,12,31,7,7n4j3x,[P] I made a neural net for identifying topography from satellite images,https://www.reddit.com/r/MachineLearning/comments/7n4j3x/p_i_made_a_neural_net_for_identifying_topography/,Nickolai1989,1514672630,"This was just a toy project for me to learn about convolutional neural nets. Results aren't very good, but I wonder if that's a result in and of itself?

I made a final ""paper"" and am hosting it here (page is a little slow to load, but responsive once loaded): https://nbelakovski.github.io/topography_neural_net/

I've noticed that not many people use conv nets for regression applications, so this seemed somewhat unique. Is it worth trying to formally publish this somewhere?",17,0
1394,2017-12-31,2017,12,31,7,7n4oph,Forecasting the S&amp;P 500,https://www.reddit.com/r/MachineLearning/comments/7n4oph/forecasting_the_sp_500/,minushabens,1514674226,[removed],0,1
1395,2017-12-31,2017,12,31,11,7n5szt,Applying Machine Learning and Computer Vision as a Rails Developer,https://www.reddit.com/r/MachineLearning/comments/7n5szt/applying_machine_learning_and_computer_vision_as/,Loggerny,1514686157,,0,1
1396,2017-12-31,2017,12,31,11,7n5utv,Training a neural net,https://www.reddit.com/r/MachineLearning/comments/7n5utv/training_a_neural_net/,ntdsc,1514686749,[removed],1,1
1397,2017-12-31,2017,12,31,11,7n60l4,Best Machine Learning Tools &amp; Frameworks for Mobiles,https://www.reddit.com/r/MachineLearning/comments/7n60l4/best_machine_learning_tools_frameworks_for_mobiles/,davidjames9001,1514688649,,0,1
1398,2017-12-31,2017,12,31,12,7n64m5, Call for speakers for the Decentralized AI Summit in SF on February 1st!,https://www.reddit.com/r/MachineLearning/comments/7n64m5/call_for_speakers_for_the_decentralized_ai_summit/,-ntr,1514689992,,0,1
1399,2017-12-31,2017,12,31,12,7n69h0,[D] What is the best ML paper you read in 2017 and why?,https://www.reddit.com/r/MachineLearning/comments/7n69h0/d_what_is_the_best_ml_paper_you_read_in_2017_and/,wavelander,1514691628,,47,348
1400,2017-12-31,2017,12,31,13,7n6jri,How To Create Slide Show Video Microsoft PowerPoint bangla Tutorial,https://www.reddit.com/r/MachineLearning/comments/7n6jri/how_to_create_slide_show_video_microsoft/,anowarul147,1514695021,,0,1
1401,2017-12-31,2017,12,31,13,7n6n5w,Best Machine Learning programming language,https://www.reddit.com/r/MachineLearning/comments/7n6n5w/best_machine_learning_programming_language/,lokeshreddy07,1514696166,,0,1
1402,2017-12-31,2017,12,31,15,7n6xs6,untitled,https://www.reddit.com/r/MachineLearning/comments/7n6xs6/untitled/,anowarul147,1514700171,,0,1
1403,2017-12-31,2017,12,31,15,7n6zra,[D] Seq2Seq with Beam Search,https://www.reddit.com/r/MachineLearning/comments/7n6zra/d_seq2seq_with_beam_search/,tuankhoa1996,1514700908,"I know how Beam Search work, and i know that at each step of decoder, we keep k top result and continue decode with them. The thing i want to ask is beam search is applied to the test time only or in both test and train????????",4,2
1404,2017-12-31,2017,12,31,17,7n7hht,Why is Artificial Intelligence Female?,https://www.reddit.com/r/MachineLearning/comments/7n7hht/why_is_artificial_intelligence_female/,yildiz17,1514708869,,0,1
1405,2017-12-31,2017,12,31,18,7n7pf1,"Hetero-Associative Memories for Non Experts: How ""Stories"" are memorized with Image-associations",https://www.reddit.com/r/MachineLearning/comments/7n7pf1/heteroassociative_memories_for_non_experts_how/,giuseppe_bonaccorso,1514712916,,0,1
1406,2017-12-31,2017,12,31,19,7n7uf4,Why is cost function for neural network not convex?,https://www.reddit.com/r/MachineLearning/comments/7n7uf4/why_is_cost_function_for_neural_network_not_convex/,Kaudinya,1514715654,[removed],0,1
1407,2017-12-31,2017,12,31,20,7n82db,Artificial Intelligence and Language,https://www.reddit.com/r/MachineLearning/comments/7n82db/artificial_intelligence_and_language/,alcanthro,1514719929,,1,0
1408,2017-12-31,2017,12,31,22,7n8kui,[R] Physical Adversarial Examples Against Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/7n8kui/r_physical_adversarial_examples_against_deep/,Jackal008,1514728595,,0,31
1409,2017-12-31,2017,12,31,23,7n8rie,[P] Some thoughts on Skip-Thoughts + a PyTorch implementation,https://www.reddit.com/r/MachineLearning/comments/7n8rie/p_some_thoughts_on_skipthoughts_a_pytorch/,sanyam5,1514731056,,7,12
1410,2017-12-31,2017,12,31,23,7n8sit,Mini project to do while attending Andrew Ng's Machine Learning course,https://www.reddit.com/r/MachineLearning/comments/7n8sit/mini_project_to_do_while_attending_andrew_ngs/,fly2sky95,1514731433,[removed],0,1
