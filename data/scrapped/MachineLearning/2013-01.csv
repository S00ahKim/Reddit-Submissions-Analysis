,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2013-1-1,2013,1,1,16,15rjk9,Top 100 most read R posts for 2012 (stats from R-bloggers),https://www.reddit.com/r/MachineLearning/comments/15rjk9/top_100_most_read_r_posts_for_2012_stats_from/,talgalili,1357026601,,0,1
1,2013-1-1,2013,1,1,21,15rqqa,"Alternatives to ""bag of words"" for text encoding?",https://www.reddit.com/r/MachineLearning/comments/15rqqa/alternatives_to_bag_of_words_for_text_encoding/,sanity,1357044765,"What alternatives exist for encoding text for a neural network or SVM?  Bag of words (unigrams, bigrams, trigrams, etc) seems to be the most common approach, but it seems that it is better at encoding the broad ""topic"" rather than ""meaning"" of text.

Are there approaches that preserve more or all of the text structure?",19,10
2,2013-1-2,2013,1,2,15,15tc3f,UV Coating Machine DC-330L,https://www.reddit.com/r/MachineLearning/comments/15tc3f/uv_coating_machine_dc330l/,yasonjane,1357109636,,0,1
3,2013-1-2,2013,1,2,19,15tk2w,UV Coating Machine DC-330L,https://www.reddit.com/r/MachineLearning/comments/15tk2w/uv_coating_machine_dc330l/,yasonfei,1357123703,,0,1
4,2013-1-2,2013,1,2,22,15to9t,Loss function figure explanation,https://www.reddit.com/r/MachineLearning/comments/15to9t/loss_function_figure_explanation/,[deleted],1357132307,"Hi, 

Would someone be able to explain this kind of figure http://imgur.com/q5EJc . The functions don't really need an explanation. Just more info on how to interpret this figure would be handy (maybe more explanation on the axis's and so forth).

",7,9
5,2013-1-3,2013,1,3,3,15u5lw,research papers and work being done for p &gt;&gt; n (many more features than available samples) situations,https://www.reddit.com/r/MachineLearning/comments/15u5lw/research_papers_and_work_being_done_for_p_n_many/,PlayMeWhile,1357151673,,1,1
6,2013-1-3,2013,1,3,13,15vcxw,Nips 2012 trends,https://www.reddit.com/r/MachineLearning/comments/15vcxw/nips_2012_trends/,rrenaud,1357188425,,3,25
7,2013-1-3,2013,1,3,15,15vjc2,Glue Binding Machine DC-30B,https://www.reddit.com/r/MachineLearning/comments/15vjc2/glue_binding_machine_dc30b/,yasonjane,1357194754,,0,1
8,2013-1-3,2013,1,3,21,15vvta,MCMC Convergence Explanation,https://www.reddit.com/r/MachineLearning/comments/15vvta/mcmc_convergence_explanation/,vittal,1357215773,"Hi,
Can somebody please explain what it means for a Markov Chain to have converged? Is it the situation when the transition probabilities satisfy detailed balance?

How does one know when the chain has converged?

Suppose I want to find the expectation of a function based on some probability distribution, whose partition function is hard to compute. I know that it can be approximated using samples from some MCMC method. But, what I don't understand is how do I go about collecting samples from the chain? Say, I need N samples to get a good approximation. When do I start collecting the N samples? Is it after the burn-in period? If so, can I collect N consecutive samples once the chain has converged?

Thanks in advance.",3,4
9,2013-1-4,2013,1,4,0,15w45v,Microsoft's R&amp;D,https://www.reddit.com/r/MachineLearning/comments/15w45v/microsofts_rd/,sugavaneshb,1357227960,,0,0
10,2013-1-4,2013,1,4,0,15w47e,Algorithm improvement for Coca-Cola recognition,https://www.reddit.com/r/MachineLearning/comments/15w47e/algorithm_improvement_for_cocacola_recognition/,srkiboy83,1357228003,,7,25
11,2013-1-4,2013,1,4,1,15w6bd,Why Use SVM? Easy-to-consume explanation of support vector machines,https://www.reddit.com/r/MachineLearning/comments/15w6bd/why_use_svm_easytoconsume_explanation_of_support/,[deleted],1357230138,,0,1
12,2013-1-5,2013,1,5,3,15yln1,Interior design using machine learning,https://www.reddit.com/r/MachineLearning/comments/15yln1/interior_design_using_machine_learning/,HootBack,1357322862,,8,19
13,2013-1-5,2013,1,5,3,15yopa,"r/MachineLearning, help me build a comprehensive list of Machine Learning survey papers",https://www.reddit.com/r/MachineLearning/comments/15yopa/rmachinelearning_help_me_build_a_comprehensive/,cpdomina,1357325616,,5,32
14,2013-1-5,2013,1,5,10,15zeb4,Looking for job / job preparation advice: 1 year left in a CS Master's program,https://www.reddit.com/r/MachineLearning/comments/15zeb4/looking_for_job_job_preparation_advice_1_year/,YaoPau,1357348546,"I graduated with a Master's in statistics this past June, and about a year before that I saw two things happening: 

* the top students in my program a year ahead of me weren't getting the jobs they wanted (still a really tough job market at the time), and

* I got introduced to machine learning and saw its value compared to the basic regression-based models we had learned.

I applied to CS master's programs, got into a good one and did well my first semester.  But I'm looking at most of my classmates, and they are either developers or are doing heavy research already in something like hpc and have been coding for over a decade ... and so they're on a direct path to getting a job.

Conversely, I feel like I know statistics decently well, and I know enough coding (C/Java/Python/MatLab) to get my classwork done, but I'm still fairly new to CS and not an expert at anything that translates directly to a job.  And I'm hearing that the demand and starting salaries for machine learning graduates don't match those for pure developers.

I have a year left, including a free summer where I can devote a ton of time to learning something that makes me marketable, but I'd like to get a better sense of what my options are.  For those in industry, would you recommend that I stick with machine learning?  Is there a certain skillset that would set me apart?",2,0
15,2013-1-5,2013,1,5,14,15zrpp,Please explain Support Vector Machines (SVM) like I am a 5 year old. ,https://www.reddit.com/r/MachineLearning/comments/15zrpp/please_explain_support_vector_machines_svm_like_i/,curious_thoughts,1357362189,,34,35
16,2013-1-5,2013,1,5,15,15zvhs,Computer generated jokes ,https://www.reddit.com/r/MachineLearning/comments/15zvhs/computer_generated_jokes/,roundhouse27,1357366491,,0,5
17,2013-1-5,2013,1,5,19,1604ls,What is the usual name for these kinds for methods?,https://www.reddit.com/r/MachineLearning/comments/1604ls/what_is_the_usual_name_for_these_kinds_for_methods/,utdiscant,1357382067,"Let us say we have some sensors all trying to measure the temperature in a room. Each sensor makes some measurements, but has some measurement error. Some sensors are good, some measure too high and some too low. Given a set of sensor measurements, I want to determine which of the sensors are most trustworthy, and then I want to infer the correct temperature by for example a weighted average.

Another situation is this: You are planning a scientific conference, and people have submitted a bunch of papers. Each paper is given to a set of reviewers, and they each assign a mark to the paper. Now you have a set of papers each with a set of marks. Since reviewers are not always unbiased, we want to infer the correct markings - that is we want to clean up the data.

What I want to know, is what these systems/methods are normally called. They seem to work a lot like recommender systems, but instead of predicting missing entries, they clean up actual entries. So far I have not gotten much closer than the keywords: Filtering, aggregation, truth discovery.",3,0
18,2013-1-6,2013,1,6,1,160gpm,Ad Hoc Data Analysis From The Unix Command Line,https://www.reddit.com/r/MachineLearning/comments/160gpm/ad_hoc_data_analysis_from_the_unix_command_line/,cavedave,1357404639,,5,24
19,2013-1-6,2013,1,6,10,161bti,Why Probabilistic Programming Matters,https://www.reddit.com/r/MachineLearning/comments/161bti/why_probabilistic_programming_matters/,jackhammer2022,1357435532,,14,30
20,2013-1-6,2013,1,6,15,161sxb,A question about clustering,https://www.reddit.com/r/MachineLearning/comments/161sxb/a_question_about_clustering/,[deleted],1357453671,"i would like to know if it is possible  cluster data if i dont have means, for example i have a list of latitudes and longitudes and place names for areas in my city.. i want to be able to cluster them based on areas that are close to each other... i want to know if
a. as mentioned above if i can cluster them without having any means
b. can i sort of extract means from the data i already have like place names and use them in a k means clustering algorithm

im not very sure if my question is clear enough if you would like to see the data (areas in my city) that i am talking about please mention in comments i'll link to it.",0,1
21,2013-1-7,2013,1,7,6,162v53,"""Data-driven science is a failure of imagination"" - what do you think?
",https://www.reddit.com/r/MachineLearning/comments/162v53/datadriven_science_is_a_failure_of_imagination/,talgalili,1357507350,,0,1
22,2013-1-7,2013,1,7,8,163596,Research papers and work being done in p &gt;&gt; n (many more features than samples) situations.,https://www.reddit.com/r/MachineLearning/comments/163596/research_papers_and_work_being_done_in_p_n_many/,MentalTorture,1357516240,"Hello Everyone,

First of all - I am new in this subreddit. Nice community here, lot's of useful and interesting threads, well done.

Hope this is the right place to ask questions like this.

I am looking for papers exploring the p &gt;&gt; n case in machine learning. Ideally they would contains surveys of research being done in that direction, guidelines, or anything falling under the same umbrella. Relationships between sample size, model complexity and over-fitting would also be helpful.

If someone has experience in the area and has noticed any heuristic useful tricks or general solutions that they found helpful as well.

thanks a lot,

best regards.",0,1
23,2013-1-7,2013,1,7,14,163snp,Restricted Boltzmann Machines in Python - A simple introduction.,https://www.reddit.com/r/MachineLearning/comments/163snp/restricted_boltzmann_machines_in_python_a_simple/,richardweiss,1357537036,,3,40
24,2013-1-7,2013,1,7,22,164asa,"This pic is the trifecta... Kids, stripper pole, and church.",https://www.reddit.com/r/MachineLearning/comments/164asa/this_pic_is_the_trifecta_kids_stripper_pole_and/,Psexton78156,1357566414,,0,1
25,2013-1-8,2013,1,8,9,165fua,Frustrated.. how to math + ml?,https://www.reddit.com/r/MachineLearning/comments/165fua/frustrated_how_to_math_ml/,[deleted],1357603469,"I want to learn machine learning and I think the topic is really exciting. I took some of the coursera machine learning course but I stopped because my mathematical understanding wasn't able to follow along and I felt like it was going to hurt me to have such a shallow understanding of what was going on. Can I learn machine learning and math at the same time or should I learn math first and then come back to machine learning? I've taken up to Calculus I at my university, but I feel like none of my mathematical training prepares me for ML at all.

I don't want to have to wait until I can take linear algebra, analysis, and calculus III just so I can start learning machine learning, but is it possible to do so otherwise?

My school has no machine learning class, but I'm a computer science major. Is there a step-by-step book list that can bring me up to speed on what I need to know to become a competent user of ml?",0,1
26,2013-1-8,2013,1,8,11,165pa5,"""Delta Calculation Component"" (DCC for simplicity) that provides delta calculation logic of XML document using XSLT implementation",https://www.reddit.com/r/MachineLearning/comments/165pa5/delta_calculation_component_dcc_for_simplicity/,[deleted],1357611651,,0,1
27,2013-1-8,2013,1,8,18,166bxp,Safety and Environment Tips from diamondcoredrilling.com,https://www.reddit.com/r/MachineLearning/comments/166bxp/safety_and_environment_tips_from/,jackrajiv,1357635978,,0,1
28,2013-1-9,2013,1,9,2,166wno,Hoping to get some help with WEKA classifiers,https://www.reddit.com/r/MachineLearning/comments/166wno/hoping_to_get_some_help_with_weka_classifiers/,duggym122,1357664926,"I am unsure about what classifiers to use. I haven't been able to find any guides/suggestions or even lectures online about classifier selection. My goal is to accomplish classification via ensemble learning, so if there are a few options that might approximately fit, that's fantastic. I would just hate to waste time that I need for the rest of the development process on toying with *all* of the different options. My feature vectors look like this, and this is actually test data for one of my classes (if it matters): 

    @relation AExemplars
    
    @attribute zone1 numeric
    @attribute zone2 numeric
    @attribute zone3 numeric
    @attribute zone4 numeric
    @attribute zone5 numeric
    @attribute zone6 numeric
    @attribute zone7 numeric
    @attribute zone8 numeric
    @attribute zone9 numeric
    @attribute zone10 numeric
    @attribute zone11 numeric
    @attribute zone12 numeric
    @attribute zone13 numeric
    @attribute zone14 numeric
    @attribute zone15 numeric
    @attribute zone16 numeric
    @attribute numZones numeric
    
    @data
    2,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,4
    2,2,0,0,2,0,0,0,0,0,0,0,0,0,0,0,9
    3,1,0,0,0,0,0,0,0,1,1,0,0,0,0,0,16
    4,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,9
    3,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,4
    4,0,0,0,0,0,3,0,0,0,3,0,0,0,0,0,16
    3,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,4
    5,1,0,0,4,0,0,0,0,0,0,0,0,0,0,0,9
    6,0,0,0,0,0,2,0,0,0,2,0,0,0,0,0,16
    4,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,4
    5,0,0,2,5,0,0,0,0,0,0,0,0,0,0,0,9
    9,0,0,0,0,0,1,0,0,2,0,0,0,0,0,0,16
    3,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,4
    5,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,9
    10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16
    2,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,4
    5,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9
    6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16
    0,1,2,3,0,0,0,0,0,0,0,0,0,0,0,0,4
    2,2,0,3,5,0,0,0,0,0,0,0,0,0,0,0,9
    9,0,0,0,0,2,0,0,0,0,1,0,0,0,0,0,16
    0,0,2,1,0,0,0,0,0,0,0,0,0,0,0,0,4
    2,0,0,2,2,0,0,0,0,0,0,0,0,0,0,0,9
    4,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,16
    0,1,2,1,0,0,0,0,0,0,0,0,0,0,0,0,4
    7,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,9
    8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16
    0,1,2,3,0,0,0,0,0,0,0,0,0,0,0,0,4
    6,1,0,0,5,0,0,0,0,0,0,0,0,0,0,0,9
    8,1,0,0,0,1,0,0,0,0,2,0,0,0,0,0,16
    2,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4
    4,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,9
    5,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,16
    0,0,2,1,0,0,0,0,0,0,0,0,0,0,0,0,4
    4,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,9
    6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16",8,4
29,2013-1-9,2013,1,9,2,166x39,[NLP] identifying autobiographical statements,https://www.reddit.com/r/MachineLearning/comments/166x39/nlp_identifying_autobiographical_statements/,shaggorama,1357665323,"I don't know if there's a more technical term, but by ""autobiographical"" I mean were a speaker provides a factual statement describing themselves. A naive approach I've tried is pulling out sentences that contain 1st person articles, but this is an extremely naive approach. What I'd prefer would be a method that can take phrases like ""I once worked at a power plant"" or ""My cat's name is Garfield"" and extract ""{worked at: power plant, has cat: true, cat name: Garfield}"" or something like that. I suspect this sort of nosiness generally requires targeting specific information goals (e.g. where person works, do they have pets, etc.) but I suspect there's a more generalized solution that might at least approximate what I'm talking about.

What's the state of the art for this? Does anyone have any good resources or literature they could point me to?",4,3
30,2013-1-9,2013,1,9,14,168dpt,Probability Theory - A Primer,https://www.reddit.com/r/MachineLearning/comments/168dpt/probability_theory_a_primer/,[deleted],1357708314,,0,1
31,2013-1-10,2013,1,10,22,16b9q7,"Any interesting developments on the open questions section of Bengio's ""Learning Deep Architectures for AI"" since 2009?",https://www.reddit.com/r/MachineLearning/comments/16b9q7/any_interesting_developments_on_the_open/,thefuc,1357825190,http://www.iro.umontreal.ca/~bengioy/papers/ftml.pdf,0,1
32,2013-1-12,2013,1,12,7,16ejb7,Final project reports from 2012 Stanford Machine Learning class ,https://www.reddit.com/r/MachineLearning/comments/16ejb7/final_project_reports_from_2012_stanford_machine/,srkiboy83,1357942325,,12,32
33,2013-1-12,2013,1,12,17,16ficw,"How to artificially generate/synthesize datasets to test a new method under favorable, random, and adversarial conditions?",https://www.reddit.com/r/MachineLearning/comments/16ficw/how_to_artificially_generatesynthesize_datasets/,Omega037,1357980821,"I am developing a new method and want to evaluate it under a range of condition conditions, such as favorable, random, and adversarial datasets.

However, my experience thus far has been almost entirely using real datasets that I was either given or data I collected myself.

Additionally, the required dataset is somewhat abnormal in that while the labels and features are the same for all samples, each sample belongs to a distinct ""type"" which could best be described as a cluster.  Thus, though a dataset may have 500 samples that look the same to the system, we really have 10 sets of 50 samples which each have 25 positive and 25 negative cases (assuming binary classification).

A real world example of this might be a dataset of cell images where the labels are cancer (1) or no cancer (-1), but many distinct types of cancer exist.

My current approach is the following, shown for a 1D feature vector.  Note that each time we add some simple random noise after the samples are created:

* **Favorable:** Separate the problem space into 10 blocks ([0,1], [1,2], ... [9,10]) and within each block is a probability density function (most likely gaussian) which produces samples.
  
* **Random:** Same as favorable but the without a separated problem space.  In other words, each probability density function is  located anywhere [0,10] and they may even overlap.

* **Adversarial:** Probability density functions all significantly overlap with other density functions.

Does this sound correct, or am I totally off on how I am supposed to be creating this data?

EDIT: [This](http://imgur.com/Ccdg5) is what I got for the favorable case. ",7,5
34,2013-1-13,2013,1,13,6,16gdek,How to train a classifier on probabilistic example data?,https://www.reddit.com/r/MachineLearning/comments/16gdek/how_to_train_a_classifier_on_probabilistic/,radarsat1,1358025073,"Appeal to expertise: I'm thinking about a turn-based game classification problem where my example data categorises states and moves as ""good"" or ""bad.""  Pretty standard stuff.  I'm most familiar with neural nets, but interested in trying other approaches too.

For a neural net, I guess I'd do this by labeling ""good"" as 1 and ""bad"" as 0, and then just training it on a database of good and bad moves.  (E.g. based on recorded games with moves labeled by losers and winners.)  I would then threshold the outcome to decide whether a move is good or not.

However, I'm considering an extension where I can take into account some kind of confidence level in the result.  In most cases I'm not 100% sure whether a move is good or bad, so labeling them exactly 1 or 0 doesn't seem right.  My question is, if I can estimate my confidence in ""goodness"" of a move, what techniques are out there that can take into account ""unsure"" examples?

One method that I thought of could be to have two outputs, one for ""goodness likelihood"" and one for ""badness likelihood.""  Then, for a ""good"" example I'd make ""badness = 0"" and ""goodness = confidence of a good move"", and vice-versa for ""bad"" examples.

Is this a good approach? What other methods are there, perhaps for other kinds of classifiers, for taking into account imperfectly known training data?",11,3
35,2013-1-13,2013,1,13,8,16gksn,Question: neural networks and real-valued data,https://www.reddit.com/r/MachineLearning/comments/16gksn/question_neural_networks_and_realvalued_data/,BSscience,1358031818,"New to neural networks. Can someone help me clarify something? I'm not sure how to handle real-value data. (this question is not about the learning algorithm, but about the architecture or maybe the component neurons of the neural network.)

I've seen examples of neural networks doing things like given a set of words, predict the most likely word or given some hand-written digit, recognize it. But in most cases, input data is very restricted. 

In the first case it worked in the following way. Take all the words in the english language and order them: (sun, car, yellow, is, me,..) then any word can be represented by a vector which is all entries zero for all the words you don't want to represent, and one for the word that you do. So car would be represented by the vector (0,1,0,0,...). In the example that I saw for predicting the next word, the input was given a several such vectors, and the neural network would then propagate forward through sigmoid neurons.

In the example for the hand-written digit you could have for each pixel any number between zero and one, but that's still a compact interval. This one also propagated forward by using sigmoid neurons.

I'm stressing that one example worked on binary data and the other one worked on data on a compact interval, because sigmoid neurons seem especially useful for these situations, since their output is between zero and one.

How would I go about handling on a neural network input (and output) data that can take any value. For concreteness imagine that I want to predict the value of a stock given the past 5 values of that stock. The easy question is: are sigmoid neurons ruled out because somehow it's impossible to use them for this problem, and why exactly? And if so, how does one handle such that?

Thank you for your time",33,6
36,2013-1-13,2013,1,13,13,16h3da,Proposed Machine Learning Q&amp;A Site,https://www.reddit.com/r/MachineLearning/comments/16h3da/proposed_machine_learning_qa_site/,raz3xon,1358049633,"Here's a proposed machine learning [Q&amp;A site](http://area51.stackexchange.com/proposals/41738/machine-learning) that's part of the stackexchange network. It's looking for support to get up and running, so join it [here!](http://area51.stackexchange.com/proposals/41738/machine-learning?referrer=rDdBBwSG51Ho2c1h6tMvDQ2)",5,14
37,2013-1-13,2013,1,13,14,16h9lp,Question: Where should I begin studying Intelligent Tutoring Systems (ITS) and is it a strong field to enter?,https://www.reddit.com/r/MachineLearning/comments/16h9lp/question_where_should_i_begin_studying/,saxman666,1358056182,"I have been researching ITS lately and am interested in them, possibly wanting to make a career developing them. However, I have seen many comments on how the field is dying. I would greatly appreciate insight onto the future of the field, potential career options, and how I should best start my path through it. Thank you. ",7,0
38,2013-1-14,2013,1,14,12,16j2ff,Question: For Logistic Regression are MLE and LAD the same?,https://www.reddit.com/r/MachineLearning/comments/16j2ff/question_for_logistic_regression_are_mle_and_lad/,[deleted],1358133585,"Hey folks. I'm doing a regression with a logistic link function, and I was maximizing a*p + (1-a)*(1-p) which I think is max likelihood. It occurred to me that this is the same as minimizing absolute deviation. Perhaps then I'm doing MLE wrong? or is this equivalence for logistic regression true?",3,4
39,2013-1-14,2013,1,14,23,16juw2,What does /r/MachineLearning think of the book Machine Learning for hackers? Is it a good book to get my feet wet or should I look at something else?,https://www.reddit.com/r/MachineLearning/comments/16juw2/what_does_rmachinelearning_think_of_the_book/,[deleted],1358173122,,54,45
40,2013-1-16,2013,1,16,13,16nytl,Question: What's a quick and dirty way to do community detection on a small trimmed knn graph?,https://www.reddit.com/r/MachineLearning/comments/16nytl/question_whats_a_quick_and_dirty_way_to_do/,mistermcg,1358309621,"Hey folks. I have a trimmed kNN graph with about 300 nodes and 1500 edges. Now, I know I could use R/iGraph or the modularity calculation in Gephi to do community detection, but I don't want to.

I was wondering...anyone have some recommendations for the hackiest, easiest way to do community detection on the graph? Doesn't have to be perfect...doesn't even have good. 
",4,0
41,2013-1-16,2013,1,16,18,16oecs,Sparse models,https://www.reddit.com/r/MachineLearning/comments/16oecs/sparse_models/,[deleted],1358328430,"Stupid question, but I see it pop up often... what is a sparse model ? Is it where some of the values of w are equal to 0 ? And how can a sparse model be achieved by some properties of the loss or regularization function ? My guess is that lasso gives a sparse model.",7,12
42,2013-1-16,2013,1,16,21,16ok12,Used CNC Machines in India,https://www.reddit.com/r/MachineLearning/comments/16ok12/used_cnc_machines_in_india/,NavinSharma,1358339718,,2,0
43,2013-1-17,2013,1,17,7,16pnlc,Andrew Ng Talk on Deep Learning,https://www.reddit.com/r/MachineLearning/comments/16pnlc/andrew_ng_talk_on_deep_learning/,rrenaud,1358375834,,12,70
44,2013-1-17,2013,1,17,23,16r3fr,Inquiry about Generalized Gradient Boosting.,https://www.reddit.com/r/MachineLearning/comments/16r3fr/inquiry_about_generalized_gradient_boosting/,econometrician,1358432877,"Let me preface this with a sincere thank you--I appreciate any help on this, as I've been trying to understand the GBM package in R, which uses Generalized Gradient Boosting.

I'm from a statistics background and am using more and more machine learning algorithms at work, but I don't really understand the mechanics of GBM in a regression and classification framework. I think I have an idea, and I've read a lot about it, but I still don't feel like I understand really what's going on. 

I used [this](http://cran.r-project.org/web/packages/gbm/vignettes/gbm.pdf) as a guide to understanding it, but I have some questions...

I understand that minimizing the loss function is analogous to maximizing a likelihood function (or minimizing your sum of squared errors), but I don't understand what the gradient descent really is; I think this may just be a notation thing. 

The Gradient Descent step size: please, let me know if I'm interpreting this correctly, but I think this is the different models (I'm talking about equation 2 in the paper).

When updating the estimate (i.e., equation 3) it shows here that the prediction is additive, but does that make sense? Shouldn't the prediction be averaged out incrementally? This is probably my biggest question/misunderstanding; if the model updates incrementally, adding an arbitrary amount of different functions would just lead to a very *large* predicted value (i.e., yhat_1*n = yhat_final; where n is the number predicted functions). How off base am I on this? I would imagine that this would make more sense to average the functions incrementally (i.e., (yhat_1 + yhat_2 + ... +yhat_n)/n). 


I understand that gradient descent is about decreasing the error term incrementally (equation 8), but I guess I still have questions because of what I just mentioned.

One last question is around the relative influence; these aren't really test statistics, what are they? I know they're pretty much analogous to test statistics, but I don't know how they're calculated. Can someone provide a little guidance?

If you can answer some of these questions, you are my hero, if not that's okay, too. Also, if you can provide me with more materials on gradient boosting, that'd be awesome, too, but I've been researching/reading about this for a while. I have an okay understand of it, but not a very deep one and I'd really prefer to have it so. Thanks again, everyone.

",6,7
45,2013-1-18,2013,1,18,1,16r94q,Best introduction to exponential family?,https://www.reddit.com/r/MachineLearning/comments/16r94q/best_introduction_to_exponential_family/,[deleted],1358438852,"(Small note: this is an xpost from /r/math. Only one person really offered any help and I got downvoted over there)

On the topic: I understand some of the basic concepts of it, but I would like to have better intuitions about them rather than know formulas.

For the lazy: [1] http://en.wikipedia.org/wiki/Exponential_family

For the lazier: Most distributions (gaussian, beta, dirichlet, binomial, bernoulli, etc) are in the exponential family and this allows for them to be expressed as a convenient, common algebraic form that has many useful properties.

The exponential family has become extremely useful in doing approximate inference using variational methods on graphical models (see David Blei's paper on Dynamic Topic Models for an example)

Thanks!",0,1
46,2013-1-18,2013,1,18,6,16rxn0,"ML for Reddit: 10,000 images of cats",https://www.reddit.com/r/MachineLearning/comments/16rxn0/ml_for_reddit_10000_images_of_cats/,dmdude,1358458790,,8,63
47,2013-1-18,2013,1,18,6,16ry1w,Good tutorial on Deep Belief Networks (and pre-reqs) put together by Andrew Ng and team.,https://www.reddit.com/r/MachineLearning/comments/16ry1w/good_tutorial_on_deep_belief_networks_and_prereqs/,barapa,1358459101,,5,21
48,2013-1-18,2013,1,18,18,16t5zm,Research-quality data sets,https://www.reddit.com/r/MachineLearning/comments/16t5zm/researchquality_data_sets/,[deleted],1358502752,http://bitly.com/bundles/hmason/1,0,1
49,2013-1-19,2013,1,19,2,16tosa,"A reddit recommendation system, impressive final class project for an undergrad ML class",https://www.reddit.com/r/MachineLearning/comments/16tosa/a_reddit_recommendation_system_impressive_final/,rrenaud,1358528468,,0,9
50,2013-1-19,2013,1,19,4,16ty8p,Are Hopfield neural networks used in any real world applications? Are they the best tool for anything?,https://www.reddit.com/r/MachineLearning/comments/16ty8p/are_hopfield_neural_networks_used_in_any_real/,SunnyJapan,1358536148,"Really want to know the answer to this question, but didn't have any luck using google.",1,15
51,2013-1-19,2013,1,19,6,16u8rm,Yann LeCun's proposal for a new peer review system.,https://www.reddit.com/r/MachineLearning/comments/16u8rm/yann_lecuns_proposal_for_a_new_peer_review_system/,qkdhfjdjdhd,1358544643,,25,47
52,2013-1-19,2013,1,19,8,16ufw6,What is working in Machine Learning / Data Mining really like?,https://www.reddit.com/r/MachineLearning/comments/16ufw6/what_is_working_in_machine_learning_data_mining/,dysoco,1358550521,"Hello, I'm a student who is currently in High School and got interested in Machine Learning and Data Mining: I've been programming since I was about 9 (I'm 15 now), and I always loved Mathematics: So when I found out about ML I really liked the idea and started watching lectures in Youtube and reading books (I'm starting the one by Norvig).

However, I've no idea what working in this field is like... I know it's a broad field, but I'd like to read answers from some professionals or students, what is your job like? Do you write a lot of code or just work in the theoretical side? Do you find it challenging? Did you have any expectations about this field that lately turned out to be different?.

I'd really appreciate some opinions and experiences.
Thank you.",0,1
53,2013-1-19,2013,1,19,12,16uwpk,Machine Learning &amp; Natural Language Processing,https://www.reddit.com/r/MachineLearning/comments/16uwpk/machine_learning_natural_language_processing/,ChstrCheeto4Prez,1358566949,"Any recommendations on resources regarding the co-application of these fields?

I am working on a project for scraping data (which is essentially binary) from hand-picked texts. I'm specifically interested in things like [summly](http://www.wired.com/gadgetlab/2011/12/summly-app-summarization/) - nlp that can be trained via machine learning",7,1
54,2013-1-19,2013,1,19,23,16vjhs,Question: pure math courses that are relevant to machine learning?,https://www.reddit.com/r/MachineLearning/comments/16vjhs/question_pure_math_courses_that_are_relevant_to/,blfang,1358605296,"I am thinking about doing research on machine learning in the [very distant] future, and would like to know more about what math courses are relevant to the field.

I've just taken a course on **Probability and Stochastic Processes** (covered Markov Chains, but not Hidden Markov Model), and a **intro course on Real Analysis**, but I'm trying to plan out the rest of my classes. I have more analysis courses lined up (**Fourier Analysis**, **Complex Analysis**, **Real Analysis**), as well as **Algebra**, **Graph Theory** and hopefully **Probability Theory**. Which math courses are important or essential in studying machine learning, and which are less important?

Also, I will be taking a course on **Artificial Intelligence** next fall.

I know next to nothing about machine learning, and am trying to plan ahead while learning as much as I can in preparation. Thanks!",18,27
55,2013-1-20,2013,1,20,9,16wj48,How should I analyze a time series to predict a single continuous value? ,https://www.reddit.com/r/MachineLearning/comments/16wj48/how_should_i_analyze_a_time_series_to_predict_a/,SpaceWizard,1358641653,"I have many time series of brain responses, and I want to use them to predict their associated reaction times. I also want to know how much each time point in the time series contributed to the prediction. So, for example, I want to take 100 brain responses (each about 500ms worth of brain data, and one value for reaction time) and figure out what part of that brain response is the best predictor of reaction time. How would you go about doing this?",8,8
56,2013-1-21,2013,1,21,13,16yzj4,New Gaussian Process Toolbox for Matlab,https://www.reddit.com/r/MachineLearning/comments/16yzj4/new_gaussian_process_toolbox_for_matlab/,fatbot,1358743652,,3,22
57,2013-1-22,2013,1,22,1,16ztwi,Question about libsvm training output,https://www.reddit.com/r/MachineLearning/comments/16ztwi/question_about_libsvm_training_output/,chindogubot,1358786429,"I've been using libsvm to train support vector machines, and when I train it, it produces output like:

    ........*
    optimization finished, #iter = 8594
    obj = -14403.958604, rho = 2.269881
    nSV = 6262, nBSV = 6195
    Total nSV = 6262
Can I infer anything useful from the obj and rho values?  For example, if they get closer to zero, does that mean the model is fitting the training data very well or any such thing?  I usually score the model against some separate test data to measure it, but I figured it must output these values because they are important, yet their meaning escapes me.",5,2
58,2013-1-22,2013,1,22,6,170emo,How to pick a project / what ML can do?,https://www.reddit.com/r/MachineLearning/comments/170emo/how_to_pick_a_project_what_ml_can_do/,sculler,1358802382,"I am doing an intro course on machine learning and we have to select a project, do some research, come up with results, and write a report.  Fairly basic for a graduate course.  The problem is that I am new to ML so I am having a hard time picking something.

Two ideas I have in my head are:

There's weight lifting website a few buddies are working on to help users track their workouts and to analyze it and help them improve.  At this moment it is in closed beta and soon it will go to an open beta.  They are willing to share the data as it would probably be beneficial with them that I share the results.  As users are using it it is building up a lot of data in terms of what exercises people are doing, their reps, sets, weights, and warmup/working sets.  But I am not sure what I can do with machine learning with this data.

The other project is sports.  I have a lot of access to advanced stats on hockey players in the NHL.  But again I am not sure what I can do with this data.

So how do you figure out what you want to do with data?  How can you figure out what you can do with the data?

Thanks",6,4
59,2013-1-22,2013,1,22,13,171b0n,Free Data to practice with,https://www.reddit.com/r/MachineLearning/comments/171b0n/free_data_to_practice_with/,has_a_box,1358828072,"What are some places to grab data to try out some ML with? 

or what are some great ways to produce data for free?",15,12
60,2013-1-22,2013,1,22,21,171utb,"Scikit-Learn user? Please fill in this survey! (also, 0.13 is out!)",https://www.reddit.com/r/MachineLearning/comments/171utb/scikitlearn_user_please_fill_in_this_survey_also/,GillesL,1358856422,,1,27
61,2013-1-23,2013,1,23,1,17276m,Probability Theory - A Primer,https://www.reddit.com/r/MachineLearning/comments/17276m/probability_theory_a_primer/,[deleted],1358871914,,0,1
62,2013-1-23,2013,1,23,4,172kms,"Just started using Weka, need some HW help withn'Classifying'",https://www.reddit.com/r/MachineLearning/comments/172kms/just_started_using_weka_need_some_hw_help/,[deleted],1358882533,"So this is my assignment. I havn't used Weka before, but I'm learning and just want to make sure I'm doing it right. So what I did was, open up testdata1.arff in Weka. Then I went to the 'classify' tab, hit 'choose' and chose one of the 13 classification methods and then under 'test options' I selected 'use training set'. And then a summary came up in the 'classifier output'. The car.arff had a whole bunch of data in it, and the testdata1.arff only had the 5 instances listed below in it. Why would he give us the car.arff if we're not even soppuse to use it? And what does he mean by summarize the results?


Using the Weka software, with the training data provided in car.arff (in datasets-UCI), determine the classification of the following five cars.


low,low,4,more,big,high,?


high,vhigh,3,2,small,high,?


vhigh,med,4,2,med,med,?


med,low,3,more,big,med,?


med,low,2,4,big,med,?


In order to do this, use the testdata1.arff file which has the predicted class arbitrarily set to unacc.
Use the following 13 classification methods. For each method, summarize the results (predictions etc as given by Weka).
Finally, provide a conclusive summary as to which one (in your opinion) is the most accurate.


    1. BayesNet (Bayes)
    2. NaiveBayes (Bayes)
    3. Logistic (functions)
    4. MultiLayerPerceptron (functions)
    5. IBk (lazy)
    6. LWL (lazy)
    7. Bagging (meta)
    8. Stacking (meta)
    9. InputMappedClassifier (misc)
    10. DecisionTable (Rules)
    11. ZeroR (Rules)
    12. DecisionStump (Trees)
    13. J48 (Trees)",5,0
63,2013-1-23,2013,1,23,15,173xyr,How many of you work on or use ML in industry?,https://www.reddit.com/r/MachineLearning/comments/173xyr/how_many_of_you_work_on_or_use_ml_in_industry/,BlameKanada,1358921506,"I like ML and would love a job involving it. For those of you who work in industry, what degree do you have? Do you think a Masters in CS is enough?

Describe your job too if you don't mind.

Apologies if this sort of post isn't welcome here.",0,0
64,2013-1-23,2013,1,23,17,1743ky,Graduate School: considering transferring from statistics to CS,https://www.reddit.com/r/MachineLearning/comments/1743ky/graduate_school_considering_transferring_from/,blarmine,1358929668,"I'm in a PhD program for statistics right now, but for a variety of reasons I'm not too happy.  I really like the CS approach to machine learning/data mining compared to the statistics approach.  I also can't stand linear models theory or measure theory.  The problem is I don't have much of a CS background.  I have an excellent record in undergrad in math and applied math (3.9+ in undergrad math courses) and decent record at my current stats program (3.7+ in grad stat courses).

I've keep hearing from a lot of people that there are a number of CS programs that love to accept non-traditional students (students not from a CS background).  I've taken a decent amount of probability at the grad. level, a data mining course (from stats dept), various math courses and a pattern recognition (from CS dept).

Please be blunt, how difficult would it be if I tried switching to CS from stats?",25,9
65,2013-1-24,2013,1,24,4,17533b,Probability Theory  A Primer,https://www.reddit.com/r/MachineLearning/comments/17533b/probability_theory_a_primer/,jackhammer2022,1358971186,,0,1
66,2013-1-25,2013,1,25,1,1773pu,Ideas for analysis of newspaper articles,https://www.reddit.com/r/MachineLearning/comments/1773pu/ideas_for_analysis_of_newspaper_articles/,anirudhrata,1359046363,"I have collected huge number of local newspaper articles (around 12 years). Any ideas on analysis that can be done on this data?

Edit: These are Indian newspaper articles.

Edit: What could be a good undergrad project utilizing these ideas?",13,3
67,2013-1-25,2013,1,25,17,178wii,Project Suggestions for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/178wii/project_suggestions_for_machine_learning/,machine333,1359102496,"I have a basic knowledge of machine learning. I have to do a project related to machine learning which needs to be completed in 3 months and is worth a lot of credits for my course in college.

So, I request /r/MachineLearning to kindly suggest some good and innovative projects that will be fun to do. More details on references and datasets will also be much appreciated.",7,4
68,2013-1-25,2013,1,25,23,1796uf,How do I create a bag of words for text classification?,https://www.reddit.com/r/MachineLearning/comments/1796uf/how_do_i_create_a_bag_of_words_for_text/,[deleted],1359122956,"So I have 500 positive labelled lines of text and 500 negative labelled lines of text  in two different and I have to build a naive bayes classifier for it.

My proposed course of action is as follows:

    1. Divide both the files in 5 parts each [for 5 fold cross validation]
    2. Take 1 part of both negative and positive texts, and extract a bag of words from both.
    3. Using naive bayes check for word probabilities.
    4. Get a threshold for selecting positive and negative.
    5. Run it over the rest 4 parts and check for labelling error.
    6. Change the initial taken part.

I dont know how should I go about extracting the bag of words and selecting the threshold or even if my approach is right.

I could certainly use help here and also suggestions on python libraries so that I dont have to do all of this manually.",6,2
69,2013-1-26,2013,1,26,3,179m95,2013 Machine Learning Summer School Announced,https://www.reddit.com/r/MachineLearning/comments/179m95/2013_machine_learning_summer_school_announced/,blind_swordsman,1359137398,,8,36
70,2013-1-26,2013,1,26,5,179z7u,Modelling tennis skills on serve and return with Glicko 2 pairwise comparison model,https://www.reddit.com/r/MachineLearning/comments/179z7u/modelling_tennis_skills_on_serve_and_return_with/,danielkorzekwa,1359147596,,0,11
71,2013-1-27,2013,1,27,9,17cbuz, Machine Learning Cheat Sheet (for scikit-learn),https://www.reddit.com/r/MachineLearning/comments/17cbuz/machine_learning_cheat_sheet_for_scikitlearn/,Tafkas,1359245549,,20,128
72,2013-1-28,2013,1,28,16,17f2ff,Goodnight!,https://www.reddit.com/r/MachineLearning/comments/17f2ff/goodnight/,drizzt240,1359358040,,0,0
73,2013-1-29,2013,1,29,2,17fs04,A short question regarding the cover of Bishop's PRML book,https://www.reddit.com/r/MachineLearning/comments/17fs04/a_short_question_regarding_the_cover_of_bishops/,VitosGameFive,1359394307,"Hey all, I have a short question regarding the cover of the book 'Pattern Recognition and Machine Learning'. Does anyone know whether the [cover](http://www.amazon.com/Pattern-Recognition-Learning-Information-Statistics/dp/0387310738) has anything to do with machine learning (e.g. a specific distribution or pattern), or whether it is just an artsy thing?",3,9
74,2013-1-31,2013,1,31,1,17kep5,Watson goes to college: IBM sends version of supercomputer to RPI to boost cognitive skills - The Washington Post,https://www.reddit.com/r/MachineLearning/comments/17kep5/watson_goes_to_college_ibm_sends_version_of/,doctaweeks,1359562470,,2,22
75,2013-1-31,2013,1,31,2,17kij1,Dense cohort of terms: An alternative text representation to TF-IDF and Bag-of-Words,https://www.reddit.com/r/MachineLearning/comments/17kij1/dense_cohort_of_terms_an_alternative_text/,rrenaud,1359565712,,2,15
76,2013-1-31,2013,1,31,3,17kqxp,What's the point of random cross-validation?,https://www.reddit.com/r/MachineLearning/comments/17kqxp/whats_the_point_of_random_crossvalidation/,szza,1359572270,"If I split a data set into two parts, build  predictor on one set and validate with the second, I'm confirming that some property is independent of the type of data split I'm performing. For example, if I train on 2009 data and verify with 2010 data, it leads to the inductive hypothesis that what I found is independent of time, and therefore useful for forecasting. So far so good. But if instead I use a random number to split the data, all I'm confirming is that the property is independent of a random number generator, which we would expect to be the case without doing the experiment.",24,9
77,2013-1-31,2013,1,31,4,17ksdz,WTF is Big Data?,https://www.reddit.com/r/MachineLearning/comments/17ksdz/wtf_is_big_data/,rawrsmashesboxes,1359573432,,3,0
78,2013-1-31,2013,1,31,9,17lj6t,Quick Confusion Matrix Visualization Survey - Your participation would mean a lot to us!,https://www.reddit.com/r/MachineLearning/comments/17lj6t/quick_confusion_matrix_visualization_survey_your/,hutchins_moustache,1359593482,"Hello,

I am asking you to please take about 20 minutes out of your day to participate in a survey about confusion matrix visualization for a study myself and some fellow HCDE students at the University of Washington in Seattle are working on. I strongly encourage you to participate regardless of your experience with this subject! We are hoping to publish our results at the 2013 Vis Conference.

The survey can be found at:  [http://kona.ischool.uw.edu/confusion/](http://kona.ischool.uw.edu/confusion/)

I would also ask that you please forward this message to anyone that you think would be willing to participate in this survey as we are hoping to have as many participants as possible to make our study a success! 

Thank you for your time!",0,1
79,2013-1-31,2013,1,31,23,17mowd,The perils of treating a models predictions as actual probabilities,https://www.reddit.com/r/MachineLearning/comments/17mowd/the_perils_of_treating_a_models_predictions_as/,sanity,1359643051,,2,23
