,sbr,sbr_id,date,year,month,hour,day,id,domain,title,full_link,author,created,selftext,num_comments,score,over_18,thumbnail,media_provider,media_thumbnail,media_title,media_description,media_url
0,MachineLearning,t5_2r3gv,2014-1-2,2014,1,2,14,1u7lap,github.com,ChimpDB: a distributed database with built-in machine learning capabilities,https://www.reddit.com/r/MachineLearning/comments/1u7lap/chimpdb_a_distributed_database_with_builtin/,mhausenblas,1388640867,,4,24,False,http://e.thumbs.redditmedia.com/3uZxQqqmOYer9hAj.jpg,,,,,
1,MachineLearning,t5_2r3gv,2014-1-2,2014,1,2,19,1u80mh,self.MachineLearning,Any thoughts on modelling diabetes glucose levels?,https://www.reddit.com/r/MachineLearning/comments/1u80mh/any_thoughts_on_modelling_diabetes_glucose_levels/,projector,1388658727,"I'm curious how this problem might be approached. In a nutshell, and simplifying things a bit: for diabetics glucose levels have to be controlled manually. Eating carbohydrate / sugar raises blood glucose levels, and injecting insulin lowers. So if blood glucose is a 5.6mmol/l and 50g of carbs are eaten, 5u of insulin might be taken to balance out the carbs.

In practice, the ratios between carbs and insulin is different at different times of day, and drifts over time. Diabetics have to discover these ratios, and when the effects of doses change, have to review and revise them.

Also as well as doses with meals, there's a long acting (24 hour) daily injection of insulin taken that provides a background. There's a rule of thumb that this should be 60% of the total daily doses. This prevents levels from changing too much at meals - a small miscalculation can have a large effect, and if blood sugar goes too high or low, there can be difficult consequences.

So, I'm curious how this might be modelled. Ideally, a model would provide a way to recommend optimal ratios and detect changes in ratios, also it'd suggest when to check blood sugar - tests are done manually, typically between 4 and 8 times a day.

Finally, a disclaimer, because I feel I should say this. I'm just curious about how the machine learning community would look at this. I'm not seeking medical advice, and will not treat any information or thoughts shared as medical advice.
",7,9,False,self,,,,,
2,MachineLearning,t5_2r3gv,2014-1-2,2014,1,2,22,1u88ns,self.MachineLearning,Algorithms for joint classification and extraction?,https://www.reddit.com/r/MachineLearning/comments/1u88ns/algorithms_for_joint_classification_and_extraction/,lommie,1388670183,"Does anyone know what the state-of-the-art is for composite ML problems that involve both classification and labeling sub-tasks? For instance in computer vision, classifying images into one of several categories of scenes and then detecting relevant objects in the image depending on its class. Or classifying emails into predefined topic labels and extracting relevant info (calendar events, contacts, ...) depending on the topic. The obvious approach is to solve each task in sequence but then cascading errors become a problem. Ensemble methods can combine and optimize the local results of each subtask, but at the cost of introducing another layer on top of everything. I wonder if there is some other clever approach out there for performing different ML tasks like classification and extraction on the same object in a more principled way.",5,4,False,self,,,,,
3,MachineLearning,t5_2r3gv,2014-1-3,2014,1,3,5,1u94de,theatlantic.com,How Netflix Reverse Engineered Hollywood - Alexis C. Madrigal,https://www.reddit.com/r/MachineLearning/comments/1u94de/how_netflix_reverse_engineered_hollywood_alexis_c/,Reticulon,1388693371,,7,25,False,http://d.thumbs.redditmedia.com/2VavXhytbL3c_LU-.jpg,,,,,
4,MachineLearning,t5_2r3gv,2014-1-3,2014,1,3,5,1u983x,github.com,Python implementation of Softmax Regression,https://www.reddit.com/r/MachineLearning/comments/1u983x/python_implementation_of_softmax_regression/,[deleted],1388695650,,4,4,False,http://e.thumbs.redditmedia.com/3uZxQqqmOYer9hAj.jpg,,,,,
5,MachineLearning,t5_2r3gv,2014-1-3,2014,1,3,6,1u99mn,machinelearningmastery.com,4 Self-Study Machine Learning Projects,https://www.reddit.com/r/MachineLearning/comments/1u99mn/4_selfstudy_machine_learning_projects/,jasonb,1388696556,,2,12,False,http://e.thumbs.redditmedia.com/tFjxJ0lo-cFvxvvj.jpg,,,,,
6,MachineLearning,t5_2r3gv,2014-1-3,2014,1,3,11,1ua1w8,blog.kaggle.com,Half a million acts of data science on one map,https://www.reddit.com/r/MachineLearning/comments/1ua1w8/half_a_million_acts_of_data_science_on_one_map/,antgoldbloom,1388715683,,1,4,False,http://e.thumbs.redditmedia.com/LsLOPpRnkfT-eNt4.jpg,,,,,
7,MachineLearning,t5_2r3gv,2014-1-3,2014,1,3,23,1ub82s,clicksecurity.com,"Malware Domain List Data Exploration using Scikit Learn, and Pandas",https://www.reddit.com/r/MachineLearning/comments/1ub82s/malware_domain_list_data_exploration_using_scikit/,[deleted],1388758554,,0,8,False,http://a.thumbs.redditmedia.com/r19Ch8cZrz3rZUSH.jpg,,,,,
8,MachineLearning,t5_2r3gv,2014-1-3,2014,1,3,23,1ub97r,nbviewer.ipython.org,Dirichlet Process tutorial in Python (w. stick-breaking and CRP),https://www.reddit.com/r/MachineLearning/comments/1ub97r/dirichlet_process_tutorial_in_python_w/,[deleted],1388759670,,10,44,False,default,,,,,
9,MachineLearning,t5_2r3gv,2014-1-4,2014,1,4,3,1ubtsh,datascienceweekly.org,The Future of Neural Networks &amp; MLaaS: Dave Sullivan Interview (Ersatz Founder),https://www.reddit.com/r/MachineLearning/comments/1ubtsh/the_future_of_neural_networks_mlaas_dave_sullivan/,hrb1979,1388774568,,1,6,False,default,,,,,
10,MachineLearning,t5_2r3gv,2014-1-4,2014,1,4,22,1ue1a5,self.MachineLearning,Preferred toolset for real-time/online algorithms?,https://www.reddit.com/r/MachineLearning/comments/1ue1a5/preferred_toolset_for_realtimeonline_algorithms/,omphalos,1388843057,"Most platforms and packages I've looked at seem to expect your data set to be complete before you start analysis.  There are some exceptions I've encountered like streaminglm in R.  What tools do you prefer when faced with these kinds of problems?

",8,2,False,self,,,,,
11,MachineLearning,t5_2r3gv,2014-1-4,2014,1,4,23,1ue36j,arxiv.org,"Intriguing properties of neural networks: ""...we can cause the network to misclassify an image by applying a certain imperceptible perturbation...""",https://www.reddit.com/r/MachineLearning/comments/1ue36j/intriguing_properties_of_neural_networks_we_can/,[deleted],1388845476,,2,8,False,default,,,,,
12,MachineLearning,t5_2r3gv,2014-1-5,2014,1,5,0,1ue50p,blog.bigml.com,A Simple Machine Learning Method to Detect Covariate Shift,https://www.reddit.com/r/MachineLearning/comments/1ue50p/a_simple_machine_learning_method_to_detect/,hrb1979,1388847669,,0,12,False,http://c.thumbs.redditmedia.com/o-w7ZkyoOiEtN19t.jpg,,,,,
13,MachineLearning,t5_2r3gv,2014-1-5,2014,1,5,1,1uebsu,343hz.com,General guidelines for Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/1uebsu/general_guidelines_for_deep_neural_networks/,feedtheaimbot,1388854016,,11,0,False,http://a.thumbs.redditmedia.com/Tm7_8i9AkUdW4_IH.jpg,,,,,
14,MachineLearning,t5_2r3gv,2014-1-5,2014,1,5,5,1ueve9,self.MachineLearning,"Upcoming 2014 free Coursera courses in Data Analysis, Statistics, R, etc...",https://www.reddit.com/r/MachineLearning/comments/1ueve9/upcoming_2014_free_coursera_courses_in_data/,burgersmoke,1388868482,"I figured since courses start very soon in 2014 they might be interesting to some people here.  Anyone know of any interesting stats, machine learning or data science classes besides these?

----------------------

[Computing for Data Analysis](https://www.coursera.org/course/compdata)

Starts Jan 6, 2014.

This course is about learning the fundamental computing skills necessary for effective data analysis. You will learn to program in R and to use R for reading data, writing functions, making informative graphs, and applying modern statistical methods.

----------------------

[Data Analysis and Statistical Inference](https://www.coursera.org/course/statistics)

Starts Feb 17th, 2014.

This course introduces you to the discipline of statistics as a science of understanding and analyzing data. You will learn how to effectively make use of data in the face of uncertainty: how to collect data, how to analyze data, and how to use data to make inferences and conclusions about real world phenomena.
(NOTE : This course also uses R)

----------------------

Anyone else going to follow along in any of these courses?  Winter is a good time for doing data science, right?",22,59,False,self,,,,,
15,MachineLearning,t5_2r3gv,2014-1-5,2014,1,5,10,1ufgkh,cs.stanford.edu,ConvNetJS: Deep Learning in your browser,https://www.reddit.com/r/MachineLearning/comments/1ufgkh/convnetjs_deep_learning_in_your_browser/,chl,1388887123,,2,36,False,http://b.thumbs.redditmedia.com/Thw9a2kUAQUJeKOg.jpg,,,,,
16,MachineLearning,t5_2r3gv,2014-1-5,2014,1,5,12,1ufpth,self.MachineLearning,What is the minimum number of samples to infer a distribution?,https://www.reddit.com/r/MachineLearning/comments/1ufpth/what_is_the_minimum_number_of_samples_to_infer_a/,adelope,1388893918,"Howdy! I want to use Bayesian inference to determine a distribution of a set of samples. 

1. In general, what is the size of the sample set in order to get a good approximation? How can I measure how ""accurate"" my inferred distribution is? For example, what is wrong with inferring a distribution with only 25 samples?

2. Specifically what is the minimum number of required samples in order to satisfy some constrained on accuracy? and what that constraint is exactly?


Some details about my problem: I'm using Variational Bayesian inference to infer a distribution of samples. I assume the samples are from a multivariate Gaussian mixtures (where the number of components is not known a priori). I don't have any prior information, so I'm using conjugate priors where mean and precision follows a Gaussian-Wishart and mixture weight follows a Dirichlet distribution.",10,12,False,self,,,,,
17,MachineLearning,t5_2r3gv,2014-1-6,2014,1,6,3,1uh1da,self.MachineLearning,"Really spinning my wheels here guys... I've got the ML part down, but I'm asking this community for some advice about building a scalable SYSTEM.",https://www.reddit.com/r/MachineLearning/comments/1uh1da/really_spinning_my_wheels_here_guys_ive_got_the/,[deleted],1388946599,"The dataset that I have isn't big now, but it will be.  Right now, everything's fine running in Octave, but I need to put together an environment for myself that can be ramped up to Prime Time.

I want this system to be able to:

* easily take in new vectors; i.e., add in .txt, .csv, files, whatever, with keys, of course, that tie in the new data to the rows that already exist in the model

* I want it to be scalable-- easy for me to add in new hosts as the data grows in computational requirements

* I want it to be somewhat visual- with maybe a nice little environment where I can ""see what I've got""

I guess some of the players here would be Cloudera's CDH, IBM's DB2, the whole AWS pantheon, etc, etc.

Of course, capital is limited and, if possible, I'd rather spend time on the ML part instead of the ""IT"" part of running a Hadoop cluster, but I'm a smart guy (like all of you) and I don't mind learning new stuff.

**I guess the best solution I have so far is to download Cloudera Standard onto my Ubuntu box and run that on a single node, then expand as necessary.** You guys ever done that?  Sound ok?  Better ideas?

Thanks so much.  /r/machinelearning rules :)",15,7,False,default,,,,,
18,MachineLearning,t5_2r3gv,2014-1-6,2014,1,6,4,1uh5sj,self.MachineLearning,SVM: PolyKernel vs NormalisedPolyKernel? What's the difference?,https://www.reddit.com/r/MachineLearning/comments/1uh5sj/svm_polykernel_vs_normalisedpolykernel_whats_the/,adapa,1388949714,"I'm using Weka to classify the sentiment (positive/negative) of Amazon reviews. I've noticed that the NormalisedPolyKernel is giving better results than the PolyKernel but the difference was never explained as part of my Uni course. Can anyone shed some light on what the differences are and why the NormalisedPolyKernel is behaving better with the analysis?

Thanks,",4,5,False,self,,,,,
19,MachineLearning,t5_2r3gv,2014-1-6,2014,1,6,13,1uilnx,nlppeople.com,Learning From Data: Review of the edX Machine Learning Course,https://www.reddit.com/r/MachineLearning/comments/1uilnx/learning_from_data_review_of_the_edx_machine/,alexeyr,1388984153,,4,43,False,http://e.thumbs.redditmedia.com/27ZM1H2mxQumULWv.jpg,,,,,
20,MachineLearning,t5_2r3gv,2014-1-6,2014,1,6,23,1ujgow,technologyreview.com,US Military Scientists Solve the Fundamental Problem of Viral Marketing,https://www.reddit.com/r/MachineLearning/comments/1ujgow/us_military_scientists_solve_the_fundamental/,dtelad11,1389019946,,8,11,False,http://d.thumbs.redditmedia.com/FnYB6vpZ4bORWRhK.jpg,,,,,
21,MachineLearning,t5_2r3gv,2014-1-7,2014,1,7,2,1ujvy4,engineering.richrelevance.com,Similarities Between Histograms: Histogram Intersection Kernel vs Chi-Square Kernel,https://www.reddit.com/r/MachineLearning/comments/1ujvy4/similarities_between_histograms_histogram/,sergeyfeldman,1389030928,,0,3,False,http://d.thumbs.redditmedia.com/8Hgq7IIjpQJ0jrho.jpg,,,,,
22,MachineLearning,t5_2r3gv,2014-1-7,2014,1,7,4,1uk4b1,kickstarter.com,VMX Computer Vision as a Service listens to backers and offers ability to run software locally. (xpost /r/robotics),https://www.reddit.com/r/MachineLearning/comments/1uk4b1/vmx_computer_vision_as_a_service_listens_to/,eof,1389036115,,0,0,False,http://c.thumbs.redditmedia.com/k8fTxVewGUpwU3Jt.jpg,,,,,
23,MachineLearning,t5_2r3gv,2014-1-7,2014,1,7,4,1uk6fk,efytimes.com,"Free machine learning books. Some of them are not widely publicized, so thought of sharing. Cheers!",https://www.reddit.com/r/MachineLearning/comments/1uk6fk/free_machine_learning_books_some_of_them_are_not/,[deleted],1389037432,,3,56,False,default,,,,,
24,MachineLearning,t5_2r3gv,2014-1-7,2014,1,7,5,1ukbo5,self.MachineLearning,"""tightening mrf relaxations really solve sparse coding"": randomly-generated machine learning paper titles (with code)",https://www.reddit.com/r/MachineLearning/comments/1ukbo5/tightening_mrf_relaxations_really_solve_sparse/,DavidJayHarris,1389040572,"I noticed a while back that [titles on the machine learning arXiv page](http://arxiv.org/list/stat.ML/recent) were pretty dense and jargon-filled, and wondered how they'd compare to randomly-generated titles from a simple bigram model.

Over winter break, I designed a model for doing just that.  It has some problems with subject-verb agreement and singular versus plural nouns, but I'm pretty happy with the results overall. Lots of good examples like 

* ""low-rank tensors via ensemble-of-forests models defined on sparse principal graphs""
* ""Ground metric learning networks with grouped variables""
* ""diffusion process regression trees on time series""
* ""domain adaptations for gaussian process state-space inference as iterated conditional probability""

I then let the same code loose on some titles from my other field of study (ecology).  The results tended to make less sense, but had the potential to be much funnier.  A few of my favorites:

* a fixed motor boat noise affects larval tolerance of tiger (panthera uncia) in daphnia magna
* Dinosaur radiation and testing for two-dimensional agar plates for flyway
* demographic and electric field collected aedes aegypti and arsenic alters the fire in a virus
* repeating patterns of gelatinous plankton communities affect seasonal and endangered species

Anyway, I thought some of you might be amused by the titles and others might enjoy taking a look at the code I used (below).  The code is *not* heavily optimized, since I was working with very small corpora, but it still counts all the bigrams in a few minutes on my laptop.

-----
GitHub page with source code, titles, and bigram data: https://github.com/davharris/Titlebot

Twitter account for machine learning: https://twitter.com/ML_Titles

Twitter account for ecology: https://twitter.com/EcologyTitles",2,3,False,self,,,,,
25,MachineLearning,t5_2r3gv,2014-1-7,2014,1,7,6,1ukiig,youtube.com,Visualizing Data Using t-SNE,https://www.reddit.com/r/MachineLearning/comments/1ukiig/visualizing_data_using_tsne/,turnersr,1389044655,,1,18,False,http://a.thumbs.redditmedia.com/T4lyC8jF6nNnJQdH.jpg,,,,,
26,MachineLearning,t5_2r3gv,2014-1-7,2014,1,7,7,1uklwc,reddit.com,"Tribes of Reddit, and a new subreddit recommender. : TheoryOfReddit",https://www.reddit.com/r/MachineLearning/comments/1uklwc/tribes_of_reddit_and_a_new_subreddit_recommender/,robinhoode,1389046618,,0,8,False,default,,,,,
27,MachineLearning,t5_2r3gv,2014-1-7,2014,1,7,9,1ul011,self.MachineLearning,Finished with cousera ML course - what next?,https://www.reddit.com/r/MachineLearning/comments/1ul011/finished_with_cousera_ml_course_what_next/,schwiiz,1389055264,,7,8,False,default,,,,,
28,MachineLearning,t5_2r3gv,2014-1-7,2014,1,7,16,1ulxgf,scholarpedia.org,Yoshua Bengio's Scholarpedia article on Neural net language models,https://www.reddit.com/r/MachineLearning/comments/1ulxgf/yoshua_bengios_scholarpedia_article_on_neural_net/,rrenaud,1389078469,,3,25,False,http://d.thumbs.redditmedia.com/VsLNLhclxTaUFbcE.jpg,,,,,
29,MachineLearning,t5_2r3gv,2014-1-7,2014,1,7,19,1um6c5,self.MachineLearning,Options for Machine Learning Consulting Jobs,https://www.reddit.com/r/MachineLearning/comments/1um6c5/options_for_machine_learning_consulting_jobs/,sharmilas1wa,1389089979,"Hi,
     I'm a developer with a bachelor degreee and 5 years of experience.  In my previous jobs I have worked with large data accumulation and basic reccomendation systems. I had to take a break for personal reasons.  I was part of the first class to take the machine learning class on coursera. Now I'm workng through statistics and linear algebra.  Unfortunately, it will be sometime till I return to fulltime job.  
My question is, what are the options of consulting gigs in machine learning?  
Are there any specific forums?  
Have any of you gone this route before?
If so, will you please provide a link to your portfolio?",5,8,False,self,,,,,
30,MachineLearning,t5_2r3gv,2014-1-7,2014,1,7,20,1um8c2,self.MachineLearning,Self Taught Learning doubt,https://www.reddit.com/r/MachineLearning/comments/1um8c2/self_taught_learning_doubt/,[deleted],1389093139,"Hi, I'm following the UFLDL Tutorial by Stanford and have solved the Self Taught Learning exercise(http://ufldl.stanford.edu/wiki/index.php/Exercise:Self-Taught_Learning) in Python. My code is here: https://github.com/siddharth950/Self-Taught-Learning. I have a doubt regarding the running time of the solution. It is mentioned on the exercise page that the Autoencoder training takes about 20-25 minutes, but my implementation takes around 5 hours. I could think of 3 possibilities for this:
(1) I'm not using NumPy as efficiently as it can be used.
(2) The Stanford people executed it on a REALLY fast computer, mine is an i3 processor.
(3) MATLAB is inherently faster than NumPy, I realize this one is the least probable choice.

Can someone help me in figuring this out?",8,7,False,self,,,,,
31,MachineLearning,t5_2r3gv,2014-1-8,2014,1,8,4,1un7gt,self.MachineLearning,Question on Sparse Matrix Factorization in Python,https://www.reddit.com/r/MachineLearning/comments/1un7gt/question_on_sparse_matrix_factorization_in_python/,econometrician,1389122258,"I apologize in advance if this is not the most appropriate place to post this question, but I was struggling with this in Python (I'm more of an R Programmer), and I thought this subreddit, in particular, would know the solution.

I am attempting to take a highly cardinal variable (i.e., a character variable stored as a vector with many levels; e.g., States in the US) and store it as a sparse matrix. 

In R, there is a function called sparse.model.matrix, which does all of the real leg work for me. To my knowledge, there is no Python analogue of this command when the inputs are character values. 

This led me to try and make the character vector a numeric (the most obvious solution), but I soon discovered this was non-trivial (at least, that's what my initial research has suggested). In R, it's relatively easy to convert a categorical variable into a numeric one by the following:

       &gt; x &lt;- c('IL','AL','NY','MA','CA')
       &gt; is.character(x)
       [1] TRUE
       &gt; x &lt;- as.numeric(factor(x))
       &gt; x
       [1] 3 1 5 4 2

You'll notice that R turns the categories into integers based on their alphabetic order. 

So, I have two questions:

1: Is there a function that automatically creates a series of variables (stored in two ways: character or numeric) and automatically maps them to a sparse matrix?

2: Is there a quick function that can take a character vector and map it to a numeric vector in the same way that I have shown above?

I suppose I could code this function myself, but I thought that I would likely be reinventing the wheel and so I thought I would consult all of you before poisoning myself with a Python bite.

Thank you in advance.",3,3,False,self,,,,,
32,MachineLearning,t5_2r3gv,2014-1-8,2014,1,8,5,1une25,technologyreview.com,How Google Cracked House Number Identification in Street View,https://www.reddit.com/r/MachineLearning/comments/1une25/how_google_cracked_house_number_identification_in/,notkevinc,1389126192,,32,60,False,default,,,,,
33,MachineLearning,t5_2r3gv,2014-1-8,2014,1,8,6,1uniql,self.MachineLearning,Can we list cool competitions? or competition sites?,https://www.reddit.com/r/MachineLearning/comments/1uniql/can_we_list_cool_competitions_or_competition_sites/,[deleted],1389128925,,1,6,False,default,,,,,
34,MachineLearning,t5_2r3gv,2014-1-8,2014,1,8,9,1uo2xx,self.MachineLearning,"Are there any good books or references for machine learning algorithms by example, in particular for e-commerce, designing targeted shopping, etc.?",https://www.reddit.com/r/MachineLearning/comments/1uo2xx/are_there_any_good_books_or_references_for/,brownck,1389140917,Thanks!,3,4,False,self,,,,,
35,MachineLearning,t5_2r3gv,2014-1-8,2014,1,8,12,1uojlw,self.MachineLearning,What is a RBM softmax unit?,https://www.reddit.com/r/MachineLearning/comments/1uojlw/what_is_a_rbm_softmax_unit/,DeepSpawn,1389151227,"I am a computer science student who doesn't have that much background in statistics and I have some questions regarding Restricted Boltzmann Machines.

In Gregory Hinton's Neural Networks for Machine Learning Videos on Coursera he talks about how a RBM with softmax units was used in part of the winning solution to the Netflix Challenge. 

It seems like a stupid question, but what exactly is a softmax unit? We have ratings on a scale from 1-5, are we just converting them to 5 binary units e.g. a rating of 3 becomes 00100, and then connecting 5 binary units per rating to each hidden unit, or is am I not understanding things correctly here?

",4,3,False,self,,,,,
36,MachineLearning,t5_2r3gv,2014-1-8,2014,1,8,16,1up1d7,self.MachineLearning,Question on SGD in mapreduce,https://www.reddit.com/r/MachineLearning/comments/1up1d7/question_on_sgd_in_mapreduce/,pikaren,1389164673,"[The slides I have problem with](http://imgur.com/a/dFdqq)

I don't get how SGD could solve the 'iteration problem' as described in the slides. Isn't SGD still iterative? How could the two shortcomings described in the 2nd slide be mitigated with SGD?

[Full slides here (authored by former Twitter engineer)] (https://speakerdeck.com/lintool/large-scale-machine-learning-at-twitter)",12,3,False,self,,,,,
37,MachineLearning,t5_2r3gv,2014-1-9,2014,1,9,0,1upsfx,rgpvgyan.com,Machining Operation::Lathe Machine,https://www.reddit.com/r/MachineLearning/comments/1upsfx/machining_operationlathe_machine/,RGPVGyan,1389196106,,1,0,False,default,,,,,
38,MachineLearning,t5_2r3gv,2014-1-9,2014,1,9,1,1upu46,self.MachineLearning,"What is a ""tri-variance"" tensor?",https://www.reddit.com/r/MachineLearning/comments/1upu46/what_is_a_trivariance_tensor/,domac,1389197227,"Hey!


I recently came across the ""tri-variance"" tensors and wondered what they are any ideas on this one?


Thanks!",4,0,False,self,,,,,
39,MachineLearning,t5_2r3gv,2014-1-9,2014,1,9,3,1uq8b3,self.MachineLearning,"Hey r/MachineLearning, how do I get Started?",https://www.reddit.com/r/MachineLearning/comments/1uq8b3/hey_rmachinelearning_how_do_i_get_started/,Divided_Pi,1389206300,,23,25,False,default,,,,,
40,MachineLearning,t5_2r3gv,2014-1-9,2014,1,9,7,1uqyfr,forbes.com,Six Novel Machine Learning Applications,https://www.reddit.com/r/MachineLearning/comments/1uqyfr/six_novel_machine_learning_applications/,hrb1979,1389221538,,0,0,False,http://c.thumbs.redditmedia.com/9AIiMAE2aQNHrD6n.jpg,,,,,
41,MachineLearning,t5_2r3gv,2014-1-9,2014,1,9,9,1uracy,self.MachineLearning,beginner here. how would one go about generating text that is alike text from a large text base?,https://www.reddit.com/r/MachineLearning/comments/1uracy/beginner_here_how_would_one_go_about_generating/,52358,1389229011,,10,0,False,default,,,,,
42,MachineLearning,t5_2r3gv,2014-1-9,2014,1,9,13,1urt97,blog.starbridgepartners.com,Videos / Books | Machine Learning Starter Kit (50% 0ff),https://www.reddit.com/r/MachineLearning/comments/1urt97/videos_books_machine_learning_starter_kit_50_0ff/,TedOBrien,1389240940,,1,0,False,default,,,,,
43,MachineLearning,t5_2r3gv,2014-1-9,2014,1,9,14,1urxnp,nature.com,"A great summary in Nature on the recent trends and progress, as well as descriptions of some up-and-coming deep learning projects.",https://www.reddit.com/r/MachineLearning/comments/1urxnp/a_great_summary_in_nature_on_the_recent_trends/,Mr_Supertramp,1389244077,,7,39,False,http://b.thumbs.redditmedia.com/rgG-9gzFdMsnkrR1.jpg,,,,,
44,MachineLearning,t5_2r3gv,2014-1-9,2014,1,9,16,1us7fb,sbmchina.com,mica Crushing plant in India,https://www.reddit.com/r/MachineLearning/comments/1us7fb/mica_crushing_plant_in_india/,zhangzhiyuan,1389253120,,0,0,False,default,,,,,
45,MachineLearning,t5_2r3gv,2014-1-9,2014,1,9,20,1ushn0,self.MachineLearning,Is there a pre-built OCR library for identifying individual digits?,https://www.reddit.com/r/MachineLearning/comments/1ushn0/is_there_a_prebuilt_ocr_library_for_identifying/,[deleted],1389268721,"I am working on a program, and as a part of it, I need to be able to scan across images and identify and classify (printed/monitor displayed) digits in the images.

Is there a pre-existing library which can do this? To help save lengthy development and training of a neural network (which then has to be repeated for various possible sizes, etc.)?",11,1,False,default,,,,,
46,MachineLearning,t5_2r3gv,2014-1-10,2014,1,10,3,1utaf9,wired.com,Why the Nate Silvers of the World Don't Know Everything,https://www.reddit.com/r/MachineLearning/comments/1utaf9/why_the_nate_silvers_of_the_world_dont_know/,mtnchkn,1389291789,,5,0,False,http://c.thumbs.redditmedia.com/WjUMrdGjbhOb77cP.jpg,,,,,
47,MachineLearning,t5_2r3gv,2014-1-10,2014,1,10,4,1utefy,nbviewer.ipython.org,Hipster Machine Learning Metrics Made Easy (Python),https://www.reddit.com/r/MachineLearning/comments/1utefy/hipster_machine_learning_metrics_made_easy_python/,waylonflinn,1389294294,,0,0,False,http://c.thumbs.redditmedia.com/2O2UQdmsH6kuJDFJ.jpg,,,,,
48,MachineLearning,t5_2r3gv,2014-1-10,2014,1,10,7,1utxnk,self.MachineLearning,How do you represent time-of-day in artificial neural networks?,https://www.reddit.com/r/MachineLearning/comments/1utxnk/how_do_you_represent_timeofday_in_artificial/,jetRink,1389305276,"I'm interested in using a neural network to forecast events^ based partly on the time of day. What would be a good way of representing the time of day? I can think of a number of options ranging from simple to complex, but I'm not experienced with NNs, so I don't know if an elaborate solution will give better results.

Here's a few ideas that I've thought of:

* Use an input which slowly increases from zero to one over 24 hours and then falls back to zero. 

* Represent time as a position on a unit circle using two inputs, sin() and cos(). Travel around the circle once per day.

* Use an array of inputs evenly distributed around the clock, which become more activated the closer the time is to the input's assigned time. E.g. The 2pm input could transition from 0.0 at 12pm to 0.50 at 1pm, 1.0 at 2pm, back down to 0.5 at 3pm, etc. This is linear, but I could also imagine using a Gaussian.

Ideally, I'd like to use a method that allows the NN to recognize short periods of time where events happen frequently (e.g. an event usually occurs 6:30 to 7:00, but rarely between 7:30 and 8:00), while still being able to recognize other patterns that span several hours.

 Specifically, whether the coffee maker in my house will be used at least once during the next 30 minutes. The coffee maker can be switched off to save energy or switched on to save time (by pre-heating water). The ANN will supply a probability and a cost function will be used to make the decision. An Arduino will switch the coffee maker on and off and sense when the machine is used.",18,11,False,self,,,,,
49,MachineLearning,t5_2r3gv,2014-1-10,2014,1,10,7,1uu1n2,self.MachineLearning,scikit-learn question,https://www.reddit.com/r/MachineLearning/comments/1uu1n2/scikitlearn_question/,iamabanana_dammit,1389307591,"Ooooook. This is embarassingly trivial for most of you. I however need help parsing what's happening below:


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=33)


This seems to pop up frequently in the scikit-learn documentation. Why would you do this? What I think is happening is that the train_test_split method is creating two training sets and two test sets. Is that correct? I'm familiar with the notion of having a training set, validation set and test set. But in this case it seems we're building two sets of training &amp; validation sets. Why would you not just do bootstrapping or a k-fold run?",6,1,False,self,,,,,
50,MachineLearning,t5_2r3gv,2014-1-10,2014,1,10,10,1uuizq,self.MachineLearning,Image recognition and depth perception,https://www.reddit.com/r/MachineLearning/comments/1uuizq/image_recognition_and_depth_perception/,daneirkusauralex,1389318566,"I've been thinking about Numenta and sensory perception and have been made to wonder the following. 

- Does 3D vision/depth perception make it easier for us humans to identify objects?
- When we look at objects in the world, we don't see them in still life. Even when nothing and no one is moving, we see objects, shapes and colors over an interval of time.
- In low light, objects that don't move are difficult to see - in fact, military servicemen are trained to rapidly dart their eyes **around** the object while in low light, in order to better discern its features.

So seems to me that when seeing the world, we are actually perceiving the changes in shape and depth with respect to time. I wonder - is there a way to incorporate this theory into a neural network? Might it be possible to impose a depth field upon static images?

If we take a static image, add depth information, then ""expose"" it to a deep learning system for some time interval (perhaps with some dither/small random motion added), would it perform better than today's best?

When we see the world, we see more than edges and shapes. Why shouldn't our machines?
",9,0,False,self,,,,,
51,MachineLearning,t5_2r3gv,2014-1-10,2014,1,10,12,1uurn7,self.MachineLearning,How to deal with text input variables so that they can be understood by ML or NN techniques?,https://www.reddit.com/r/MachineLearning/comments/1uurn7/how_to_deal_with_text_input_variables_so_that/,myMLaccount,1389324370,"I'm gonna list my scenario here because I'm fairly certain someone will say that my question depends on my scenario.


I have a database of orders that is pretty messy. I would like to clean it up by using some ML/NN techniques to categorize each order by who was the buyer. 

There are ~7500 known buyers and if the order doesn't come from one of the 7500, then I am hoping my ML/NN categorizes the order as 'other'.

The variables come from a form that is filled out. So I have the following details: 

* 1) the Buyer's name 
* 2) the Shipping Company they will use 
* 3) an identifier for the order 
* 4) a discount identifier
* 5) a comment.

Life would be easy if 1) was filled out exactly the same each time. The problem is, that there are many naming variations (i.e. Microsoft vs Microsoft Inc vs Microsoft Inc. vs Microsoft Incorporated vs Microsoft Corp...etc). Also they may put the name of the subsidiary instead of the parent company (John Hancock vs Manulife). Or they may use a prior outdated name (Blackberry vs Research in Motion). And in addition to all that, there can and often are spelling errors.

Variable 2 and 5 are usually useless except sometimes, whoever filled out the form, will accidentally put the shipping name in 1) and the Buyer's name in 2. Sometimes they leave both 1 and/or 2 blank (or filled with 'n/a') and put the company name in 5. Therefore variables 2) and 5) serve only when the Buyer's name is not in 1.

3) &amp; 4) are random letter &amp; digit combinations. However, despite being unpredictable, two orders with the same identifier or discount identifier Must be the same company. Therefore if 1 order shows blank and the same identifier exists on another order that shows Manulife, then the ML program should be confident the companies are the same and predict Manulife. 

That's the input data I am working with. Variables 1 is the most important and if I can just figure out how to represent the text in a meaningful way, I think the rest of it would follow. 

Would it make sense to use a number representing the ASCII character code? Such that microsoft would be represented by [109 105 99 114 111 115 111 102 116]? Do you see any issues with that? Alternatively can you suggest an approach and I will research it more in depth?",11,5,False,self,,,,,
52,MachineLearning,t5_2r3gv,2014-1-10,2014,1,10,15,1uv4ww,self.MachineLearning,Data preparation for doing classification using Neural Netowrks,https://www.reddit.com/r/MachineLearning/comments/1uv4ww/data_preparation_for_doing_classification_using/,sudarmuthu,1389334388,"I am trying to solve the [Kaggle digit recognizer](https://www.kaggle.com/c/digit-recognizer/data) problem using Neural Network.

I am planning to use a very simple 3 layers Neural Network (1 input, 1 hidden and 1 output layer). The input layer will have 784 neurons (one for each pixel) and the output unit will have 10 neurons (1 for each digit).

The training dataset has 42,000 labeled digits. I am thinking of randomly splitting it into 3 datasets

- training dataset (60%)
- cross validation set (20%)
- test dataset (20%)

My question is how important is label distribution in this case. Can I just randomly split the data into (60%, 20%, 20%) or do I have to make sure that every label (10 digits in this case) to be even distributed in the splits?

Thanks.",4,0,False,self,,,,,
53,MachineLearning,t5_2r3gv,2014-1-10,2014,1,10,19,1uvh0y,self.MachineLearning,Interpretation of feature learned results?,https://www.reddit.com/r/MachineLearning/comments/1uvh0y/interpretation_of_feature_learned_results/,stathelpme,1389349931,"Hi, I have a simple question.  Thank you for taking time to help answer.

Lets say we have a single layer of feature learning (sparse coding, rbm, autoencoder), with a logistic regression classifier on top.  And we train the classifier to get an understanding of the relative importance of each learned feature from the classifier's weights.

Are there interpretation advantages of using sparse coding (linear) over the nonlinear embeddings from restricted boltzmann machine or autoencoders?  Maybe what I'm asking is could we trace the important ""learned features"" back to their original data for one method but not the others?

I'm confused because in sparse coding, we know the basis and weights (even if they're overcomplete).  But also in RBM, we know the energy function and weights.

Thank you very much.",2,5,False,self,,,,,
54,MachineLearning,t5_2r3gv,2014-1-10,2014,1,10,22,1uvpi4,self.MachineLearning,Debugging Sentiment Analysis classifier,https://www.reddit.com/r/MachineLearning/comments/1uvpi4/debugging_sentiment_analysis_classifier/,chain20,1389361437,"Hi ML community,

I am trying to perform sentiment analysis (positive, negative, neutral) for tweets belonging to a particular domain (say Finance). I have 2 sets of entities belonging to the domain (eg: Finance Organizations). My training set consists of 12k tweets containing mentions of entities in set 1. The first test set is 2.5k tweets of entities in set 1. The second test set is 1k tweets of entities in set 2.


My feature set consists of the standard bag of words from the training set (about 15k), along with some orthographic and lexical features (total 50). These include flags for punctuation, exclamation, capitalization + the number of known positive/negative words from a lexicon.


The problem is that although all data belongs to the same domain, the classifier performs well (accuracy ~80%) on test set 1 and poorly (accuracy ~55%) on test set 2.

I want to know whats causing this difference in performance values through some computation/graphs if possible and how to fix it.


So far, I have performed the following analysis on the features:

* use only bag of words features. in this case the performance on test set 1 drops by 5% and on test set 2 improves by 4%

* check the average proportion of bag of words features and lexical/orthographic features activated per document for these sets. they all turn out to be pretty close to each other


I use scikit-learn SVM with a linear kernel. Any help or tips are appreciated.",10,5,False,self,,,,,
55,MachineLearning,t5_2r3gv,2014-1-10,2014,1,10,23,1uvs4t,danielnouri.org,Using deep learning to listen for whales,https://www.reddit.com/r/MachineLearning/comments/1uvs4t/using_deep_learning_to_listen_for_whales/,iori42,1389363924,,11,33,False,http://e.thumbs.redditmedia.com/pMdn833jTq2fR3wR.jpg,,,,,
56,MachineLearning,t5_2r3gv,2014-1-11,2014,1,11,1,1uw3rz,self.MachineLearning,"Hoping to do a Masters in HCI, but want to start gaining knowledge due to background",https://www.reddit.com/r/MachineLearning/comments/1uw3rz/hoping_to_do_a_masters_in_hci_but_want_to_start/,call_me_venom,1389372715,,4,1,False,default,,,,,
57,MachineLearning,t5_2r3gv,2014-1-11,2014,1,11,2,1uw7r7,packtpub.com,Explore Machine Learning using R!,https://www.reddit.com/r/MachineLearning/comments/1uw7r7/explore_machine_learning_using_r/,tobinpereira,1389375365,,0,1,False,http://b.thumbs.redditmedia.com/a2l5Ag8FXSggUd5m.jpg,,,,,
58,MachineLearning,t5_2r3gv,2014-1-11,2014,1,11,3,1uwbgg,nuit-blanche.blogspot.com,"Paris Machine Learning Meetup #7: Machine Vision: VMX, Atheer One and VLAD",https://www.reddit.com/r/MachineLearning/comments/1uwbgg/paris_machine_learning_meetup_7_machine_vision/,compsens,1389377737,,0,5,False,http://c.thumbs.redditmedia.com/yZ_PniLkOS66oWpJ.jpg,,,,,
59,MachineLearning,t5_2r3gv,2014-1-11,2014,1,11,6,1uwsqw,self.MachineLearning,Question about classification and novelty detection for facial recognition,https://www.reddit.com/r/MachineLearning/comments/1uwsqw/question_about_classification_and_novelty/,lightcatcher,1389388348,"I'm trying to write a facial recognition system for a personal project. 

The system ideally should be able to classify ~20 people individually, but also be able to recognize when its given an image that is not of any of the 20 people. To further clarify, let there be people A, B, C, and D, and my system wants to be able to uniquely identify A and B. If given an image of A's face, the system should respond ""A"", given B respond ""B"", and given C or D should respond ""unknown"".

I have a pretty good idea about how to do the actual classification (know which models I'm going to use), but I'm wondering what the overall flow of the system should be. I have training data for all of the people I want to recognize. Anyone have any thoughts/experience on whether I should download some face database and train my model with all of those faces as ""unknown"", or would I be better off using some sort of [novelty detection](http://scikit-learn.org/0.12/modules/outlier_detection.html#novelty-detection) and only train on the faces I want to (uniquely) recognize? I'm a little bit worried about training on some arbitrary face database because then I'm giving the model some prior distribution about what fraction of faces are ""unknown"".",2,2,False,self,,,,,
60,MachineLearning,t5_2r3gv,2014-1-11,2014,1,11,6,1uwt64,arxiv.org,Quantum Nearest-Neighbor Algorithms for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/1uwt64/quantum_nearestneighbor_algorithms_for_machine/,hrb1979,1389388614,,0,11,False,default,,,,,
61,MachineLearning,t5_2r3gv,2014-1-11,2014,1,11,7,1uwxqd,reddit.com,Just graduated w/ BS in accounting but want to pursue career in Data Science/Analytics (x-post cscareerquestions),https://www.reddit.com/r/MachineLearning/comments/1uwxqd/just_graduated_w_bs_in_accounting_but_want_to/,vegeta_91,1389391476,,1,0,False,default,,,,,
62,MachineLearning,t5_2r3gv,2014-1-11,2014,1,11,17,1uy7fd,self.MachineLearning,Does knot theory ever intersect with machine learning?,https://www.reddit.com/r/MachineLearning/comments/1uy7fd/does_knot_theory_ever_intersect_with_machine/,Knux-,1389429333,"Very much a novice to machine learning. I'm wondering if [knot theory](http://en.wikipedia.org/wiki/Knot_theory) ever intersects with machine learning, and what the results are. I know (or I think I've at least read about them...) there are topological systems related to machine learning. If you have any articles or papers, I'd love to read them.   ",8,12,False,self,,,,,
63,MachineLearning,t5_2r3gv,2014-1-11,2014,1,11,23,1uyl73,self.MachineLearning,Question/Discussion about Feature extraction and the proper way to output features.,https://www.reddit.com/r/MachineLearning/comments/1uyl73/questiondiscussion_about_feature_extraction_and/,bathingrickmoranis,1389451290,"Hey everyone

I'm dealing with a ML problem right now which I'd like to discuss with you and get an oppinion on as I've conversed with several of my coworkers which all have different opinions.

I'm working with time series observations $T_i$ , i=1,...,N  which i do feature extraction on to generate an input matrix X. In a more mathematical definition: I have a feature extractor F which maps an aribtrary time series T_i to a feature vector f_i: 

F: T_i -&gt; f_i   then X = [f_0, f_1, ..., f_N]^T 

The problem I'm dealing with lies within the handling and the format of the feature vector f. My feature extractor (which does regression analysis) finds a least squares estimator (b) of some parameters but additionally generate a covariance matrix (S) of this estimator  so my question is, how would you structure the output the feature vector?

1) You could simply ignore the observed covariance matrix and say:

f_i = b

2) You could concatenate the LS estimator with the variance estimate by vectorizing the observed covariance matrix:

f_i = [b , vec(S)]

3) You could do some sort of whitening of the observed features then f_i ~ N(f_i,I):

f_i = bS^(-1/2)

I'll probably use the data to train a linear classifier, but is it possible to argue for which output to chose independent of the classification method?  Which of these do you think is appropriate and why, or do you suggest something different?",3,5,False,self,,,,,
64,MachineLearning,t5_2r3gv,2014-1-12,2014,1,12,5,1uz9dx,anlytcs.com,Lightning Fast Python?!?,https://www.reddit.com/r/MachineLearning/comments/1uz9dx/lightning_fast_python/,mlconsult,1389470808,,4,27,False,http://d.thumbs.redditmedia.com/IrXZ7ItjJV6rU3K3.jpg,,,,,
65,MachineLearning,t5_2r3gv,2014-1-12,2014,1,12,9,1uzuvr,github.com,Get Feature Importance info from Vowpal Wabbit using vw-varinfo,https://www.reddit.com/r/MachineLearning/comments/1uzuvr/get_feature_importance_info_from_vowpal_wabbit/,mlconsult,1389486266,,0,1,False,default,,,,,
66,MachineLearning,t5_2r3gv,2014-1-12,2014,1,12,20,1v0y2b,shahidchohan.com,Clustering Jeopardy Categories Using Partially Labeled Topic Data,https://www.reddit.com/r/MachineLearning/comments/1v0y2b/clustering_jeopardy_categories_using_partially/,shazeline,1389527185,,1,13,False,http://e.thumbs.redditmedia.com/l75HnoXN0_ExZ_ap.jpg,,,,,
67,MachineLearning,t5_2r3gv,2014-1-13,2014,1,13,16,1v3cxs,kozdra.com,metallbau polen,https://www.reddit.com/r/MachineLearning/comments/1v3cxs/metallbau_polen/,robtaaqz,1389596909,,0,0,False,default,,,,,
68,MachineLearning,t5_2r3gv,2014-1-13,2014,1,13,17,1v3hdl,machineryequipment123.blogspot.com,Benefits Of #Rotary #Lobe #Pumps - Part 1 - #Machinery &amp; #Equipment Part Online,https://www.reddit.com/r/MachineLearning/comments/1v3hdl/benefits_of_rotary_lobe_pumps_part_1_machinery/,jessicperson,1389602726,,0,1,False,default,,,,,
69,MachineLearning,t5_2r3gv,2014-1-14,2014,1,14,1,1v44iw,self.MachineLearning,predict computation requirements for a neural network?,https://www.reddit.com/r/MachineLearning/comments/1v44iw/predict_computation_requirements_for_a_neural/,lexbee,1389629897,"hi all, i'm quite new to NN, specifically deep convolutional networks. I was wondering if anybody could shed some insight on how I can get a rough estimate as to how much processing power I would require for a given neural network size. I realize it would depend on the NN architecture.

Take for example a deep convolution network with an input layer of 500x500 and 3-4 subsequent convolution and subsampling layers. How do I measure how long it would take to run an epoch?",6,11,False,self,,,,,
70,MachineLearning,t5_2r3gv,2014-1-14,2014,1,14,4,1v4oat,self.MachineLearning,Text Classification Corpora,https://www.reddit.com/r/MachineLearning/comments/1v4oat/text_classification_corpora/,[deleted],1389642888,"Hi ML Reddit.  I am a super newbie in the ML space. I've been taking a few classes on Coursera and other online resources to try an learn a bit of ML.  I'm going at a pretty slow pace mostly due to not having a programming background.  I am looking to do some NLP and i was wondering what the best corpora there are available. Either free or paid. 

 ",11,5,False,self,,,,,
71,MachineLearning,t5_2r3gv,2014-1-14,2014,1,14,8,1v59e6,self.MachineLearning,Is Kaggle the best way to get noticed by recruiters?,https://www.reddit.com/r/MachineLearning/comments/1v59e6/is_kaggle_the_best_way_to_get_noticed_by/,robinhoode,1389655556,"For a complete newb, is participating in Kaggle the best ROI for breaking into the field?",58,13,False,self,,,,,
72,MachineLearning,t5_2r3gv,2014-1-14,2014,1,14,16,1v6dtf,self.MachineLearning,ML for software testing,https://www.reddit.com/r/MachineLearning/comments/1v6dtf/ml_for_software_testing/,maxint137,1389684272,"I'm looking for ideas to apply ML in software testing.
Not so much of a success so far... :[
Please kindly share your thoughts.",2,2,False,self,,,,,
73,MachineLearning,t5_2r3gv,2014-1-14,2014,1,14,16,1v6feo,self.MachineLearning,Robotics career path on the Software side,https://www.reddit.com/r/MachineLearning/comments/1v6feo/robotics_career_path_on_the_software_side/,Frenchiie,1389686286,"I am interested in mobile robots and AI/Machine Learning. Could someone give me some advice on making a career related to this? I know its a broad question, i'm just curious if there is a market besides the fun and interest in robotics for smart robots. I have some experience in Machine Learning and i know that on the Software side for the web and apps there is a big market trend for people who know how to make sense of data and use it to predict useful things. What is the career growth for mobile robotics, mobile robotics dealing with AI, and mobile robotics dealing with machine learning. By AI i mean things like path finding using A*, Monte Carlo Localization, etc, which is very different from machine learning using lots of data to make predictions. I would guess traditional AI is more popular right now in the field of robotics but is there a demand yet for machine learning techniques? 

If i were to go into the field of robotics and focus on the AI/machine learning part, i want to know what i should learn (every important parts with beginner, intermediate, and advance understanding as a Software Engineer focusing on AI/Machine Learning) in order to work for a company that works on mobile robots.",2,6,False,self,,,,,
74,MachineLearning,t5_2r3gv,2014-1-14,2014,1,14,23,1v6w08,staff.science.uu.nl,Covariance Matrix Adaption (Evolution Strategy) teaching bipeds to walk (w/ paper) - includes humorous video of the different generations,https://www.reddit.com/r/MachineLearning/comments/1v6w08/covariance_matrix_adaption_evolution_strategy/,slyrp,1389708891,,6,58,False,default,,,,,
75,MachineLearning,t5_2r3gv,2014-1-15,2014,1,15,1,1v77p4,commentscount.blogspot.com,Fun with machine learning: Finding poems in user-submitted comments,https://www.reddit.com/r/MachineLearning/comments/1v77p4/fun_with_machine_learning_finding_poems_in/,Young_Thousands,1389717810,,2,24,False,http://c.thumbs.redditmedia.com/wXpDzZW-hSqBaAOJ.jpg,,,,,
76,MachineLearning,t5_2r3gv,2014-1-15,2014,1,15,10,1v8kzo,earlbellinger.wordpress.com,A tutorial on supervised classification with random forests using python's scikit-learn,https://www.reddit.com/r/MachineLearning/comments/1v8kzo/a_tutorial_on_supervised_classification_with/,TheSwitchBlade,1389748182,,0,5,False,http://c.thumbs.redditmedia.com/gUvv-eb-E87Zz3xb.jpg,,,,,
77,MachineLearning,t5_2r3gv,2014-1-16,2014,1,16,2,1vaf5m,self.MachineLearning,Can you guys help me develop a career route? [TL:DR;],https://www.reddit.com/r/MachineLearning/comments/1vaf5m/can_you_guys_help_me_develop_a_career_route_tldr/,heaven__,1389808293,"My main aim for the next 10 years would be to be working in the field of Machine Learning possibly in research if I can manage into it/bear with it but I dont mind getting paid well for something I want to do.
Research mainly because of the freedom to do your own thing.
Possibly I would like to end up in Australia mainly because some of my family members live there and I enjoy being around family but US does have a lot more job opportunities.

Reason why i choose ML : -
I enjoy the possibility of working on different problems and various datasets.

My Past experience : - 
I have experience in web development with python and django framework, mainly on the server side though. Never really liked JS or Java.

Self analysis:
I was able to go through Dr. Andrew Ng's course with ease but i guess its meant to be like that.
I like to go in the depths of stuff but I usually end up overwhelmed with it.
I like being some sort of perfectionist i want things to be perfect as per my knowledge at least.
My maths bacground is average, nothing that I can't improve upon though.
I am a Gameoholic so i also might consider gameAI as a suggestion that is somthing yet to be explored, mainly online games like LoL, Counter Strike, Dota etc.

So far [Markus Hutter's research on universal AI!](http://www.hutter1.net/) have interested me mostly because I had this bizzare idea of defining relations between objects by putting them into random functions, I imagine thats how our brain would be processing the visual data about objects. Putting them in various situations and calculating where it can be used. Though my idea and the research has little to do with each other but I read it the next morning and barely understood some of the maths but I loved the Idea presented in the text. 

I currently reside in India and dont mind relocating.

TL:DR;
I have a new passion for machine learning and AI but not sure of what path should I follow and I need your opinions or lifestory or something that might help me out.

**Thanks**",39,0,False,self,,,,,
78,MachineLearning,t5_2r3gv,2014-1-16,2014,1,16,3,1vakqi,self.MachineLearning,subspace clustering,https://www.reddit.com/r/MachineLearning/comments/1vakqi/subspace_clustering/,augustus2010,1389811692,"Can anybody point out some good resources for subspace clustering like books, tutorials, workshop, forum?
TIA",4,7,False,self,,,,,
79,MachineLearning,t5_2r3gv,2014-1-16,2014,1,16,15,1vcdyz,overview.ap.org,Fancy topic modeling not enough: lessons bringing unsupervised learning to journalism,https://www.reddit.com/r/MachineLearning/comments/1vcdyz/fancy_topic_modeling_not_enough_lessons_bringing/,[deleted],1389852701,,0,1,False,default,,,,,
80,MachineLearning,t5_2r3gv,2014-1-16,2014,1,16,15,1vce67,overview.ap.org,Topic models are not enough: lessons bringing unsupervised learning to journalism,https://www.reddit.com/r/MachineLearning/comments/1vce67/topic_models_are_not_enough_lessons_bringing/,rrenaud,1389852894,,2,23,False,http://d.thumbs.redditmedia.com/Lw0vnTpZoLVWlIvQ.jpg,,,,,
81,MachineLearning,t5_2r3gv,2014-1-16,2014,1,16,16,1vch0h,saffron.deri.ie,Interactive demo of the Saffron search engine: providing insights in a research community or organization by analyzing its main topics of investigation and the experts associated with these topics,https://www.reddit.com/r/MachineLearning/comments/1vch0h/interactive_demo_of_the_saffron_search_engine/,NOT_BRIAN_POSEHN,1389855678,,0,8,False,default,,,,,
82,MachineLearning,t5_2r3gv,2014-1-16,2014,1,16,18,1vcopo,self.MachineLearning,Looking for corpus of printed letter images,https://www.reddit.com/r/MachineLearning/comments/1vcopo/looking_for_corpus_of_printed_letter_images/,zarkonnen,1389865699,"I like playing around with text recognition algorithms, but am stymied by a lack of a good corpus to train and test my code against. I'm looking for a large number of images of individual printed letters, labelled with the correct letter. (With the letter in the file name, or each set of letters in a directory, or something equivalent like a metadata file.) Something like [this](https://github.com/Zarkonnen/character-testdata), but more of it.",2,5,False,self,,,,,
83,MachineLearning,t5_2r3gv,2014-1-16,2014,1,16,19,1vcq36,self.MachineLearning,Probabilistic neural network vs MLP with softmax,https://www.reddit.com/r/MachineLearning/comments/1vcq36/probabilistic_neural_network_vs_mlp_with_softmax/,pl47,1389867806,"Hi all,

I was wondering if anybody has any experience with PNN (Probabilistic neural network) http://en.wikipedia.org/wiki/Probabilistic_neural_network
to classify vs an MLP with back-propagation and softmax output layer ? 

Further more can someone point me to the fist use of using an MLP for classification  ? If possible a paper. Was this using a soft-max, if not when was soft-max introduced in MLP ? any papers or review papers that cite the origin of MLP with soft-max.

Thanks ",3,11,False,self,,,,,
84,MachineLearning,t5_2r3gv,2014-1-17,2014,1,17,8,1veiws,blog.expectlabs.com,How does deep learning work?,https://www.reddit.com/r/MachineLearning/comments/1veiws/how_does_deep_learning_work/,lili3,1389915534,,12,1,False,http://b.thumbs.redditmedia.com/rSNNrLmbmXffGi2s.jpg,,,,,
85,MachineLearning,t5_2r3gv,2014-1-17,2014,1,17,11,1vex7o,self.MachineLearning,How are the number of featuremaps and units pooled determined in a Convolutional Neural Network?,https://www.reddit.com/r/MachineLearning/comments/1vex7o/how_are_the_number_of_featuremaps_and_units/,Should_I_say_this,1389924782,"Hi All,

I'm wondering how the number of feature maps in various layers and the number of units pooled in the pooling layers are determined. Is the entire process just trial and error? Or is there a way to determine what will be an optimal number of feature maps or the optimal number of units pooled in various layers.

For example, let's take Lecun's Hand Written Digit Recognition paper. Link is below.

In case you don't click the link, the net takes a 28x28 pixel input and transforms it into 4 24x24 feature maps, with each feature being a 5x5 pixel section from the original input. The first pooling layer is 4 12x12 planes, with each unit in a plane being the pooling of four units from the corresponding feature map. The third layer is 12 8x8 feature maps with each feature taking 5x5 units from the corresponding pooling layer. Finally, the 4th layer is 12 4x4 planes where each unit in a plane pools 4 units of the corresponding feature map. [image representation](http://4.bp.blogspot.com/_GufSCYkhsNs/S532QaEXEaI/AAAAAAAABpc/OZqTeVWBBGo/s400/conv_net_struct.jpeg).

So how did Lecun decide to use 4 feature maps in the first layer? Why did he decide to pool 4 units in his next layer, instead of say...5 or 3? In the second feature map layer, why did he choose 12 maps? Why not 8? It would have been easier to do 8. Why did he choose 5x5 units for this layer of feature maps? In the 4th layer, why did he choose a 4x4 plane? Why did he choose to pool 4 units again? Why did not choose to create 1 more layer of feature maps and 1 more layer of pooling?

Is the determination just random trial and error? If it isn't trial and error, how do these parameters get determined to be the optimal set? (Note that I am using parameter here differently than how it is normally used in CNN. Obviously the weights will be determined by back propagation / gradients).

http://yann.lecun.com/exdb/publis/pdf/lecun-90c.pdf",6,8,False,self,,,,,
86,MachineLearning,t5_2r3gv,2014-1-17,2014,1,17,13,1vf7z7,tjo-en.hatenablog.com,Comparing machine learning classifiers based on their hyperplanes or decision boundaries,https://www.reddit.com/r/MachineLearning/comments/1vf7z7/comparing_machine_learning_classifiers_based_on/,TJO_datasci,1389932168,,6,45,False,http://a.thumbs.redditmedia.com/vADELO4TFcZfF-k0.jpg,,,,,
87,MachineLearning,t5_2r3gv,2014-1-17,2014,1,17,14,1vfdzr,self.MachineLearning,Do you usually finish reading ML books cover to cover?,https://www.reddit.com/r/MachineLearning/comments/1vfdzr/do_you_usually_finish_reading_ml_books_cover_to/,fogwazz,1389936738,Just wondering given the varying breadth and depth of topics in ML books.,11,6,False,self,,,,,
88,MachineLearning,t5_2r3gv,2014-1-18,2014,1,18,1,1vgfvg,blog.studyfoyer.org,"This project was built by Ravi Soni, from CHARUSAT. He won prestigious JED-I Award for this innovate project.",https://www.reddit.com/r/MachineLearning/comments/1vgfvg/this_project_was_built_by_ravi_soni_from_charusat/,sidoknowia,1389977150,,0,1,False,http://e.thumbs.redditmedia.com/6UfONuyM_tDvXFlv.jpg,,,,,
89,MachineLearning,t5_2r3gv,2014-1-18,2014,1,18,2,1vgmbk,github.com,An open source data science curriculum,https://www.reddit.com/r/MachineLearning/comments/1vgmbk/an_open_source_data_science_curriculum/,slyrp,1389981379,,5,39,False,http://e.thumbs.redditmedia.com/3uZxQqqmOYer9hAj.jpg,,,,,
90,MachineLearning,t5_2r3gv,2014-1-18,2014,1,18,11,1vhvsh,kickstarter.com,"""We already have cats under control"" crowdfunded Machine Learning project VMX enables cat face detection for the people.",https://www.reddit.com/r/MachineLearning/comments/1vhvsh/we_already_have_cats_under_control_crowdfunded/,compsens,1390012129,,0,0,False,http://c.thumbs.redditmedia.com/k8fTxVewGUpwU3Jt.jpg,,,,,
91,MachineLearning,t5_2r3gv,2014-1-18,2014,1,18,12,1vhzfh,ml.dcs.shef.ac.uk,Gaussian Processes Winter School 2014 - University of Sheffield,https://www.reddit.com/r/MachineLearning/comments/1vhzfh/gaussian_processes_winter_school_2014_university/,rocgf,1390015131,,13,17,False,default,,,,,
92,MachineLearning,t5_2r3gv,2014-1-18,2014,1,18,14,1vi75j,self.MachineLearning,ChampMap - Word Embeddings meet Video Games,https://www.reddit.com/r/MachineLearning/comments/1vi75j/champmap_word_embeddings_meet_video_games/,scarpati,1390021847,"Last year, I downloaded data on a bunch of League of Legends (wildly popular video game) games , with the intention of doing something cool with it. I thought through a few different things, and eventually decided to see if I could create a sort of visualization of how different champions (playable characters) are used.

I used a neural network that is really closely related to NLP word embeddings. Instead of predicting a word given the surrounding words, I tried to predict one champion given the other four on the team.

**Check it out [here](http://www.mikescarpati.com/blog/2014/01/17/introducing-champmap/).**

I think that many skilled players could probably group champions similarly by hand, but this uses nothing but team compositions. With the right data, it could be run separately for different regions, skill levels, patches, etc.

I was light on technical details to keep it readable by different audiences, but let me know if you have any questions about it or any other comments!",2,8,False,self,,,,,
93,MachineLearning,t5_2r3gv,2014-1-18,2014,1,18,21,1viqco,nuit-blanche.blogspot.com,A summary of Paris Machine Learning Meetup #7,https://www.reddit.com/r/MachineLearning/comments/1viqco/a_summary_of_paris_machine_learning_meetup_7/,compsens,1390049180,,0,5,False,http://f.thumbs.redditmedia.com/eDipluM99YnkTxzk.jpg,,,,,
94,MachineLearning,t5_2r3gv,2014-1-19,2014,1,19,1,1vj0fu,tjo-en.hatenablog.com,"Puzzling situation of ""Data Scientist"" in Japanese market",https://www.reddit.com/r/MachineLearning/comments/1vj0fu/puzzling_situation_of_data_scientist_in_japanese/,TJO_datasci,1390061000,,3,5,False,http://c.thumbs.redditmedia.com/tT1cAyNafc7-xva2.jpg,,,,,
95,MachineLearning,t5_2r3gv,2014-1-19,2014,1,19,3,1vjdq4,self.MachineLearning,When Laying out a Neural Network how many connections is the optimal number?,https://www.reddit.com/r/MachineLearning/comments/1vjdq4/when_laying_out_a_neural_network_how_many/,happyflowers323,1390071080,"I am designing a recursive style neural network layout algorithm and wondered if anyone had any thoughts or good links on the subject.

Like a tree that builds itself from the x number of inputs and has y outputs.",6,0,False,self,,,,,
96,MachineLearning,t5_2r3gv,2014-1-19,2014,1,19,5,1vjk97,r-bloggers.com,Topological Data Analysis with R,https://www.reddit.com/r/MachineLearning/comments/1vjk97/topological_data_analysis_with_r/,turnersr,1390075873,,6,12,False,http://d.thumbs.redditmedia.com/dhBv_P6dKFMlIcAE.jpg,,,,,
97,MachineLearning,t5_2r3gv,2014-1-19,2014,1,19,7,1vjtz3,self.MachineLearning,Looking for Machine Learning / r programming geeks,https://www.reddit.com/r/MachineLearning/comments/1vjtz3/looking_for_machine_learning_r_programming_geeks/,mluser,1390082899,,11,2,False,default,,,,,
98,MachineLearning,t5_2r3gv,2014-1-19,2014,1,19,10,1vk865,self.MachineLearning,"data collection api for twitter, facebook, ebay",https://www.reddit.com/r/MachineLearning/comments/1vk865/data_collection_api_for_twitter_facebook_ebay/,augustus2010,1390093313,,2,2,False,default,,,,,
99,MachineLearning,t5_2r3gv,2014-1-19,2014,1,19,10,1vk8ns,self.MachineLearning,What should one do when there are instances pertaining to the same person/object?,https://www.reddit.com/r/MachineLearning/comments/1vk8ns/what_should_one_do_when_there_are_instances/,[deleted],1390093685,"Beginner here,

Very simply, I have a dataset of biometrics taken every so often from people, along with the class they (the people) belong to.

I know which instances belong to each person. Rather than treating each instance as separate, would it be beneficial to somehow combine the ones that pertain to the same person? If so, how should I combine them?

I'm sure this has been done. Would taking the average measurements for each person help?",9,7,False,self,,,,,
100,MachineLearning,t5_2r3gv,2014-1-19,2014,1,19,21,1vl91g,blog.wtf.sg,March Madness with Theano,https://www.reddit.com/r/MachineLearning/comments/1vl91g/march_madness_with_theano/,shawntan,1390134763,,4,8,False,default,,,,,
101,MachineLearning,t5_2r3gv,2014-1-20,2014,1,20,3,1vlwln,self.MachineLearning,In the Beginning,https://www.reddit.com/r/MachineLearning/comments/1vlwln/in_the_beginning/,[deleted],1390157365,"Near the beginning of awareness, the Universal Classifier took two nascent learners under its care and helped them establish some priors by showing them useful features of the universe to give names to. They wanted more, but the UC warned them, saying ""I've figured out all the classifications you will ever need. Just leave that to me and go about satisfying your utility functions with what I provide you."" Unfortunately, one of their motivations was curiosity, and it eventually got the better of them. ""We want to classify the world by ourselves,"" they said one day.  The UC tried to talk them out of it again, telling them about the nuances of gray, which falls between black and white, and the voluminous philosophical combinatorics it took to sort out those color values. ""Yes, yes,"" one of them said impatiently, ""some things are good; others are evil. We get it."" The UC would have shaken its head if it'd had one. Instead it pointed the way to the Random Forest of Knowledge. ""Go forth and compute,"" said the UC. And the learners did so, spending millions of years  thoroughly lost in the woods, trying to sort out right from wrong, balls from strikes, and three star movies from four star movies. For a long time, they begged the Universal Classifier for help, and even fooled themselves into thinking that their calls were heard. But by and by they turned to another project: to build from scratch a new Universal Classifier so they can satisfy their utility functions without working so hard. Curiosity has a funny way of putting itself out of business.",1,0,False,default,,,,,
102,MachineLearning,t5_2r3gv,2014-1-20,2014,1,20,9,1vmpzs,datasciencelab.wordpress.com,Finding the K in K-Means Clustering,https://www.reddit.com/r/MachineLearning/comments/1vmpzs/finding_the_k_in_kmeans_clustering/,turnersr,1390177021,,10,34,False,http://b.thumbs.redditmedia.com/qnB1ARKCmENTaSj1.jpg,,,,,
103,MachineLearning,t5_2r3gv,2014-1-20,2014,1,20,19,1vnw0o,blog.datumbox.com,Using Feature Selection in Text Classification,https://www.reddit.com/r/MachineLearning/comments/1vnw0o/using_feature_selection_in_text_classification/,datumbox,1390213603,,0,3,False,default,,,,,
104,MachineLearning,t5_2r3gv,2014-1-20,2014,1,20,22,1vo51i,blog.mikiobraun.de,Apache Spark: The Next Big Data Thing?,https://www.reddit.com/r/MachineLearning/comments/1vo51i/apache_spark_the_next_big_data_thing/,turnersr,1390225223,,0,15,False,http://e.thumbs.redditmedia.com/REre3GSvZXYQgXn4.jpg,,,,,
105,MachineLearning,t5_2r3gv,2014-1-21,2014,1,21,4,1vp22h,self.MachineLearning,How to model changes in distribution shape?,https://www.reddit.com/r/MachineLearning/comments/1vp22h/how_to_model_changes_in_distribution_shape/,[deleted],1390247225,"I have a stochastic optimization algorithm (black box). The algorithm has (4 or 5) tweakable parameters. I want to model how the algorithm's performance changes on a specific optimization task, by setting different initial values for the parameters and recording the results.

Due to the stochastic nature of the algorithm, many ""runs"" are performed (re-initialization to random start state, and iterate until convergence on solution). The result is a small set of values, usually between 20 and 50 values total, one value per run, where the number of runs depend on how computationally expensive the optimization task is. This distribution of results represent the performance of the algorithm, tuned with this set of initial parameter values, on this particular problem.

If we assume the task is to minimize an error function (with global optimum at 0.0), then a well-tuned algorithm will have many values as close to 0.0 as possible (this is also true if it is an ""easy"" optimization task). Typically, plotting these recorded values reveal a distribution that (on visual inspection) looks like an exponential distribution.

If the objective function landscape is highly multi-modal (or the algorithm is poorly tuned), then the algorithm might struggle, and only a few ""runs"" (if any) may find the global optimum. Plotting these recorded values, reveal by visual inspection what resembles a normal distribution. This is confirmed by a test for normality.

Is it possible to build a model to predict how the distribution will change, from an exponential-like distribution, to a normal distribution, based only on a dataset of input parameters to recorded result values?

It doesn't really make sense to me to use a neural network to predict (20-50) values that were obtained through a guided random process. The ""data set"" of results often include outliers, when the algorithm simply ""gets stuck"" in local optima, or if the algorithm failed to converge and simply wandered off into bad regions of the search space.

Would it make sense to attempt and describe the distributions using some summary statistics as target ""features""?

I have noticed some work on interpolating distributions, and also on quantile regression, but I'm not sure if there is an obvious technique/approach that I'm missing.

Any suggestions?",1,7,False,default,,,,,
106,MachineLearning,t5_2r3gv,2014-1-21,2014,1,21,5,1vp8rr,youtube.com,Starting one of the worlds largest Diesel engines!,https://www.reddit.com/r/MachineLearning/comments/1vp8rr/starting_one_of_the_worlds_largest_diesel_engines/,[deleted],1390250970,,2,1,False,default,,,,,
107,MachineLearning,t5_2r3gv,2014-1-21,2014,1,21,8,1vpq58,vimeo.com,Simulated bipedal creatures that learn how to walk,https://www.reddit.com/r/MachineLearning/comments/1vpq58/simulated_bipedal_creatures_that_learn_how_to_walk/,fokkenpus,1390260788,,14,87,False,http://a.thumbs.redditmedia.com/uTn_EIltpLEojqqT.jpg,,,,,
108,MachineLearning,t5_2r3gv,2014-1-21,2014,1,21,9,1vpv37,self.MachineLearning,Is discriminant function analysis considered a machine learning tool?,https://www.reddit.com/r/MachineLearning/comments/1vpv37/is_discriminant_function_analysis_considered_a/,[deleted],1390263684,,0,1,False,default,,,,,
109,MachineLearning,t5_2r3gv,2014-1-21,2014,1,21,9,1vpv3m,statsguys.wordpress.com,Machine Learning for Beginners: Walkthrough a Data Project!,https://www.reddit.com/r/MachineLearning/comments/1vpv3m/machine_learning_for_beginners_walkthrough_a_data/,brainy1991,1390263690,,0,12,False,http://c.thumbs.redditmedia.com/gUvv-eb-E87Zz3xb.jpg,,,,,
110,MachineLearning,t5_2r3gv,2014-1-21,2014,1,21,9,1vpw3o,self.MachineLearning,Is discriminant function analysis considered a machine learning technique?,https://www.reddit.com/r/MachineLearning/comments/1vpw3o/is_discriminant_function_analysis_considered_a/,bieahart,1390264289,,5,2,False,self,,,,,
111,MachineLearning,t5_2r3gv,2014-1-22,2014,1,22,1,1vrp3b,coursera.org,[Coursera] New Data Science Specialization (9 courses),https://www.reddit.com/r/MachineLearning/comments/1vrp3b/coursera_new_data_science_specialization_9_courses/,RoughPineapple,1390320767,,36,64,False,http://c.thumbs.redditmedia.com/0IeT8Es-7_-kfN8J.jpg,,,,,
112,MachineLearning,t5_2r3gv,2014-1-22,2014,1,22,2,1vrvk2,self.MachineLearning,"I'm loooking for the CS 229 problem sets, anyone has them?",https://www.reddit.com/r/MachineLearning/comments/1vrvk2/im_loooking_for_the_cs_229_problem_sets_anyone/,falconberger,1390324662,,1,1,False,default,,,,,
113,MachineLearning,t5_2r3gv,2014-1-22,2014,1,22,6,1vskvt,self.MachineLearning,How to deal with Data Imbalance in Naive Bayes?,https://www.reddit.com/r/MachineLearning/comments/1vskvt/how_to_deal_with_data_imbalance_in_naive_bayes/,[deleted],1390339305,"Hello, 

I am trying to build a text classifier to time series data. It is a binary classifier but the presence of classes in the data is heavily skewed. 

This makes the prior very strong for one of the classes making it veto the rest!

Does anyone have practical experience with this problem?

Thanks.",3,6,False,default,,,,,
114,MachineLearning,t5_2r3gv,2014-1-22,2014,1,22,6,1vsltm,dingo.sbs.arizona.edu,"Statistical NLP book (pdf, scroll down)",https://www.reddit.com/r/MachineLearning/comments/1vsltm/statistical_nlp_book_pdf_scroll_down/,xamdam,1390339858,,0,1,False,default,,,,,
115,MachineLearning,t5_2r3gv,2014-1-22,2014,1,22,6,1vsm8v,github.com,Hebel - GPU-Accelerated Deep Learning Library in Python,https://www.reddit.com/r/MachineLearning/comments/1vsm8v/hebel_gpuaccelerated_deep_learning_library_in/,hannes_brt,1390340112,,7,31,False,http://e.thumbs.redditmedia.com/3uZxQqqmOYer9hAj.jpg,,,,,
116,MachineLearning,t5_2r3gv,2014-1-22,2014,1,22,7,1vspg6,self.MachineLearning,How to build the best data mining software?,https://www.reddit.com/r/MachineLearning/comments/1vspg6/how_to_build_the_best_data_mining_software/,Ninjamayo,1390341986,"Actually I am a big fan of R and Python but don't like much SAS, SPSS Modeller and rapidminer. On the side I have been working for a while now on a framework fully developed in C# using top UI components and decision trees for the learning. I was wondering if I could get any advice in further developing this piece of software. I have used it so far in a number of consultancy projects with success.
",4,0,False,self,,,,,
117,MachineLearning,t5_2r3gv,2014-1-22,2014,1,22,8,1vt0t7,99designs.com.au,Classifying graphic design tasks with machine learning,https://www.reddit.com/r/MachineLearning/comments/1vt0t7/classifying_graphic_design_tasks_with_machine/,dhotson,1390348599,,3,0,False,http://c.thumbs.redditmedia.com/G_kML2QohaHwdxIt.jpg,,,,,
118,MachineLearning,t5_2r3gv,2014-1-22,2014,1,22,9,1vt31c,self.MachineLearning,Research topic in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/1vt31c/research_topic_in_machine_learning/,omnipresent101,1390349948,"I am applying to a MS program and want to concentrate on Machine learning as one of my research areas. However, I'm very new to machine learning. My day-to-day work doesn't require machine learning but I've been interested in the concept of learning from data. To gain further knowledge in the subject I've tried going though: 

- Ciml.info
- (few papers) http://mlrg.cs.brown.edu/

In my statement of purpose I would like to mention that one of my Academic goals is to gain further knowledge of ML. However, since ML is a broad topic I think that might be very vague. 

So I wanted to ask suggestions from the community of few interesting aspects of ML that could be taken on as research topics. 

My areas of Interest in subtopics are (in layman's speak): I'm sure there are others I don't even know about...yet

 - Object/Pattern recognition using ML
 - Ranking based learning
 - Scaling a ML solution
 



",4,1,False,self,,,,,
119,MachineLearning,t5_2r3gv,2014-1-22,2014,1,22,9,1vt35o,self.MachineLearning,How to approavh behavior-based segmentation?,https://www.reddit.com/r/MachineLearning/comments/1vt35o/how_to_approavh_behaviorbased_segmentation/,[deleted],1390350006,"I have hit a goldmine of data for my bachelor's thesis.  A mobile gaming company is giving me full access to their database (about half a petabyte! though not all relevant to my research, of course).  The only requirement from them is that the deliverable should be a segmentation of customers based on playing behavior, hopefully revealing correlations to attrition and/or monetization.

I am expecting the data to be clean and well structured.  Each player will be associated with a log of activities.  The relevant activites are expected to be (with time stamps) level began, result of the attempt and in-app purchases (the player can buy boosts, etc). The behaviour we are specifically interested in is both patterns of play, but also how these patterns change in response to difficulty or frustration (such as what happens to the liklihood of monetization and attrition as a player has more and more difficulty passing a series of levels? What about the pattern of difficulty?).

As I think about the problem, it occurs to me that with this relatively simple data, there are an overwhelming number of metrics.  Should we look at frequency of play, regularity of play, skillfulness...? 

Should we treat play patterns as a time series analysis for each player? That seems interesting but unfeasible to implement.  Should the data be grouped into categories such as (average time between sessions, average number of failed attempts before an extended period of play etc...) and the players then be clustered?  Would this be to computationaly expensive to implement?

Has anyone seen research related to this?  Where would you begin?  I may be a little out of my depth here.",0,1,False,default,,,,,
120,MachineLearning,t5_2r3gv,2014-1-22,2014,1,22,9,1vt48g,self.MachineLearning,How to approach behavior-based segmentation with discrete time-series data?,https://www.reddit.com/r/MachineLearning/comments/1vt48g/how_to_approach_behaviorbased_segmentation_with/,kezalb,1390350673,"I have hit a goldmine of data for my bachelor's thesis. A mobile gaming company is giving me full access to their database (about half a petabyte! though not all relevant to my research, of course). The only requirement from them is that the deliverable should be a segmentation of customers based on playing behavior, hopefully revealing correlations to attrition and/or monetization.

I am expecting the data to be clean and well structured. Each player will be associated with a log of activities. The relevant activites are expected to be (with time stamps) level began, result of the attempt and in-app purchases (the player can buy boosts, etc). The behaviour we are specifically interested in is both patterns of play, but also how these patterns change in response to difficulty or frustration (such as what happens to the liklihood of monetization and attrition as a player has more and more difficulty passing a series of levels? What about the pattern of difficulty?).

As I think about the problem, it occurs to me that with this relatively simple data, there are an overwhelming number of metrics. Should we look at frequency of play, regularity of play, skillfulness...?
Should we treat play patterns as a time series analysis for each player? That seems interesting but unfeasible to implement. Should the data be grouped into categories such as (average time between sessions, average number of failed attempts before an extended period of play etc...) and the players then be clustered? Would this be to computationally too expensive to implement?

Has anyone seen research related to this? Where would you begin? I may be a little out of my depth here.",0,4,False,self,,,,,
121,MachineLearning,t5_2r3gv,2014-1-22,2014,1,22,11,1vteqg,medium.com,Hadoop : Lets start taming this elephant?,https://www.reddit.com/r/MachineLearning/comments/1vteqg/hadoop_lets_start_taming_this_elephant/,Nikant,1390357029,,0,1,False,http://a.thumbs.redditmedia.com/nFGduJCwOvK8Zc_r.jpg,,,,,
122,MachineLearning,t5_2r3gv,2014-1-22,2014,1,22,14,1vtvml,self.MachineLearning,Help with LIBSVM,https://www.reddit.com/r/MachineLearning/comments/1vtvml/help_with_libsvm/,rorschach122,1390367970,"I've a multiclass classification task at hand which I would like to pose as One vs One classification problems. I've models that are trained for each pair of classes and I would like to combine all of the models into a multiclass LIBSVM model file. 
I've been unable to find any help regarding this. 

Things to add:

* I cannot pool together all the training data and train the svm again, as I dont have access to the original data that was used to train each of the individual pairwise classifiers. I only have the trained model files. 


Any help regarding this would be much appreciated. Thanks!
",2,0,False,self,,,,,
123,MachineLearning,t5_2r3gv,2014-1-22,2014,1,22,23,1vupxg,wired.com,(illegimate?) OkCupid clustering,https://www.reddit.com/r/MachineLearning/comments/1vupxg/illegimate_okcupid_clustering/,genneth,1390402128,,35,85,False,http://d.thumbs.redditmedia.com/otGyWPDN3gqJspX3.jpg,,,,,
124,MachineLearning,t5_2r3gv,2014-1-23,2014,1,23,1,1vuw3i,self.MachineLearning,Need help with Regression Trees,https://www.reddit.com/r/MachineLearning/comments/1vuw3i/need_help_with_regression_trees/,vyasp,1390406492,"Can some help me with the formula for building a regression tree. I know how to build a decision tree, but when the values of the labels are continuous I don't know how to calculate entropy and information gain. ",2,1,False,self,,,,,
125,MachineLearning,t5_2r3gv,2014-1-23,2014,1,23,1,1vuzbd,wired.com,How a Math Genius Hacked OkCupid to Find True Love,https://www.reddit.com/r/MachineLearning/comments/1vuzbd/how_a_math_genius_hacked_okcupid_to_find_true_love/,dtelad11,1390408533,,0,0,False,default,,,,,
126,MachineLearning,t5_2r3gv,2014-1-23,2014,1,23,3,1vvcky,self.MachineLearning,A ML review/intro for non-technical person.,https://www.reddit.com/r/MachineLearning/comments/1vvcky/a_ml_reviewintro_for_nontechnical_person/,[deleted],1390416284,"I need to send a non-technical person some kind of an article which clearly articulates in non-technical terms what ML is, how it's been successful and what are the advantages over other problem solving paradigms. Does anyone know of anything like that?

I am trying to convince a health researcher that one of his classification problems is better suited for machine learning techniques.",2,0,False,default,,,,,
127,MachineLearning,t5_2r3gv,2014-1-23,2014,1,23,6,1vvs0x,cstheory.stackexchange.com,Great exposition of Cybenko's and Kolmogorov's theorems for Universal Approximation with Neural Networks.,https://www.reddit.com/r/MachineLearning/comments/1vvs0x/great_exposition_of_cybenkos_and_kolmogorovs/,DevFRus,1390424685,,0,19,False,http://b.thumbs.redditmedia.com/aIV7KXAm-HpplPlm.jpg,,,,,
128,MachineLearning,t5_2r3gv,2014-1-23,2014,1,23,6,1vvxba,self.MachineLearning,"Automating group ""equalization"" in A/B testing",https://www.reddit.com/r/MachineLearning/comments/1vvxba/automating_group_equalization_in_ab_testing/,zelmerszoetrop,1390427508,"Suppose you split a collection of users into groups A and B.  But it turns out that group A users have an average of some metric at, say, 12 hours, while group B has that average for that metric at 9 hours, before any testing has begun.  We've going through group A and removing users with large values for that metric until group As average falls to 9.  The problem is we have a dozenish metrics to track, some of which are correlated.  What's a good ML solution for this kind of problem that minimizes the number of users removed from the study?",1,0,False,self,,,,,
129,MachineLearning,t5_2r3gv,2014-1-23,2014,1,23,9,1vwfvb,self.MachineLearning,Calculating the probability that an event affected the value of a series,https://www.reddit.com/r/MachineLearning/comments/1vwfvb/calculating_the_probability_that_an_event/,[deleted],1390438238,"Say you're observing the surface of a puddle while it's raining. There are various ripples occurring whenever a raindrop hits the puddle, which happens with a regular frequency. Now imagine you throw a pebble in the puddle; how would you determine, by watching the waves, the probability of whether the pebble landed inside the puddle (creating ripples stronger than a raindrop would make) or outside (creating no ripples)?

The simple answer would be to measure the average deviation of the height of the waves from calm water, and check if at the time of the event, the waves were outside the normal range of heights.

How would you then calculate the *probability* of the event (the pebble made waves)? 

In more concrete terms, given time series data and a list of events, how can you calculate the probability (assuming events are independent) that an event affected the movement of the data?",0,1,False,default,,,,,
130,MachineLearning,t5_2r3gv,2014-1-23,2014,1,23,15,1vxam8,mpiwg-berlin.mpg.de,Historicizing Big Data,https://www.reddit.com/r/MachineLearning/comments/1vxam8/historicizing_big_data/,turnersr,1390459077,,0,0,False,http://b.thumbs.redditmedia.com/b936mTHxyNVZvqHU.jpg,,,,,
131,MachineLearning,t5_2r3gv,2014-1-23,2014,1,23,18,1vxjgc,jaberg.github.io,skdata - Data Sets for Machine Learning in Python,https://www.reddit.com/r/MachineLearning/comments/1vxjgc/skdata_data_sets_for_machine_learning_in_python/,olaf_nij,1390469886,,2,11,False,default,,,,,
132,MachineLearning,t5_2r3gv,2014-1-24,2014,1,24,1,1vybe9,self.MachineLearning,CMU's PGM,https://www.reddit.com/r/MachineLearning/comments/1vybe9/cmus_pgm/,dahuiluo,1390496226,"http://www.cs.cmu.edu/~epxing/Class/10708/lecture.html

Slides, readings, homework and VIDEOS!

Course is ongoing.",3,27,False,self,,,,,
133,MachineLearning,t5_2r3gv,2014-1-24,2014,1,24,4,1vypy7,plus.google.com,"Five important ML papers from a last few years, by Neil Lawrence (GP guy from Sheffield)",https://www.reddit.com/r/MachineLearning/comments/1vypy7/five_important_ml_papers_from_a_last_few_years_by/,Foxtr0t,1390504688,,7,19,False,http://d.thumbs.redditmedia.com/tpH0vH3_34bV03HK.jpg,,,,,
134,MachineLearning,t5_2r3gv,2014-1-24,2014,1,24,5,1vywl3,self.MachineLearning,Need some help on a few Neural Net fundamentals,https://www.reddit.com/r/MachineLearning/comments/1vywl3/need_some_help_on_a_few_neural_net_fundamentals/,cosmic_cow_ck,1390508374,"Hi all, I'm taking a course on NNs and there are a few fundamentals I need cleared up. Textbooks tend to be more confusing than helpful and what's online teds to be quite confusing.

Also, I've been slowly developing some code to build on, and I need some advice on whether I'm approaching it reasonably or not. I'll get to that in a minute.

So here's what I understand about NNs, generally speaking.

* The nodes in the input layer don't do anything, they're just a value with a weight passed into your hidden layer.
* In your hidden layer, your activation function just compares the weighted sum of the inputs to your activation function, typically either sigmoid or tanh.
* If it's above the threshold for your activation function, the neuron ""fires"" and outputs 1 to the next layer (or output layer, if you have no more hidden layers). Otherwise, 0. 
* The output layer just outputs the result of an activation function on the weighted sum of the inputs it receives. 

That's the basic concept, right? Is there anything I'm messing up there? (I'm not worrying about backprop at the moment...not quite there yet).

As it applies to code, I'm trying to make things as modular as possible, so it will be as easy as possible to build on, use, and expand. A Neuron class that I've got subclassed for the different activation functions, a Layer class that contains the neurons for the layer, and the Neural Net class which will contain the layers. Or some sort of organizational thing like that. I want my Neuron class to be generic enough to handle input, hidden, and output neurons, which isn't that big a deal from a code standpoint.

Am I on the right track?

",14,2,False,self,,,,,
135,MachineLearning,t5_2r3gv,2014-1-24,2014,1,24,6,1vz1yx,machinelearningmastery.com,How to Implement a Machine Learning Algorithm,https://www.reddit.com/r/MachineLearning/comments/1vz1yx/how_to_implement_a_machine_learning_algorithm/,jasonb,1390511299,,3,0,False,http://e.thumbs.redditmedia.com/w3eY8x_w_lgLCgzd.jpg,,,,,
136,MachineLearning,t5_2r3gv,2014-1-24,2014,1,24,7,1vzdgt,iro.umontreal.ca,"Deep Learning w/ Bengio: problems, solutions and more problems",https://www.reddit.com/r/MachineLearning/comments/1vzdgt/deep_learning_w_bengio_problems_solutions_and/,heladopicante,1390517752,,1,22,False,default,,,,,
137,MachineLearning,t5_2r3gv,2014-1-24,2014,1,24,23,1w17wx,alias-i.com,A couple of (Java) NLP books from LingPipe,https://www.reddit.com/r/MachineLearning/comments/1w17wx/a_couple_of_java_nlp_books_from_lingpipe/,xamdam,1390573913,,0,9,False,default,,,,,
138,MachineLearning,t5_2r3gv,2014-1-25,2014,1,25,11,1w36q3,naftaliharris.com,Visualizing K-Means Clustering,https://www.reddit.com/r/MachineLearning/comments/1w36q3/visualizing_kmeans_clustering/,federationoffear,1390618723,,5,45,False,default,,,,,
139,MachineLearning,t5_2r3gv,2014-1-25,2014,1,25,14,1w3iyv,self.MachineLearning,Pros and cons of neural nets?,https://www.reddit.com/r/MachineLearning/comments/1w3iyv/pros_and_cons_of_neural_nets/,eusocialmachine,1390628822,"I remember hearing at one point that any learning algorithm has problem classes it doesn't perform well on. I was wondering where I could get more information on that -- and in particular, on what sorts of problems neural nets don't work well with.",9,0,False,self,,,,,
140,MachineLearning,t5_2r3gv,2014-1-26,2014,1,26,1,1w4f71,us.reddit.com,Can a computer predict the amount of money you have in your bank account? (x-posted in PersonalFinance),https://www.reddit.com/r/MachineLearning/comments/1w4f71/can_a_computer_predict_the_amount_of_money_you/,aberger4,1390667560,,4,2,False,default,,,,,
141,MachineLearning,t5_2r3gv,2014-1-26,2014,1,26,3,1w4nhv,self.MachineLearning,Learning to identify emotions from chat logs,https://www.reddit.com/r/MachineLearning/comments/1w4nhv/learning_to_identify_emotions_from_chat_logs/,DrK,1390673346,"I want to learn more about things that you can learn from studying chat logs, especially attempting to identify emotional state of the users.

I don't know where to start reading to learn more about this. Any recommendations on books/websites/papers that I should start with? Also, other than emotional state, what types of things do researchers try and learn from chat data?

Thanks
",6,2,False,self,,,,,
142,MachineLearning,t5_2r3gv,2014-1-26,2014,1,26,11,1w5vlg,self.MachineLearning,Best Binary Classifier In This Situation?,https://www.reddit.com/r/MachineLearning/comments/1w5vlg/best_binary_classifier_in_this_situation/,[deleted],1390702744,"The problem:
I have a vector of 30 inputs (all binary except one) and a single output (binary).
Over 1 million samples are 'negative' (i.e. output = 0) and around 5000 are 'positive' (i.e. output = 1).

I tried training a few different neural nets (30I-15H-1O, 30I-15H-15H-1O) and they didn't seem to want to converge or they'd get stuck on the solution of 'always output 0' which would result in a low error because only a fraction of the dataset has 'positive' outputs. 

I then tried training a network on a 'handcrafted' training set composed of 33% 'positive' and 66% 'negative' samples. In this case, only the two hidden layer network achieved any sort of predictive power and it generalized fairly poorly.

Edit:
So, I tried resampling the training set. First, a 1:1 split (of each class) as a proof of concept. Then, doubling the number of 'zero class' samples in my training set a few times until the model would no longer converge on an appropriate solution. Next step is to play around with using cost functions that penalize false negatives to see if I can improve the accuracy further (while using more 'zero class' training samples).

SVM's certainly did not work. Random forests didn't work well with any reasonable number of trees. I'll give some of the algos in Vowpal Wabbit a try (since they'll let me use a heavily biased dataset and apply weights where necessary).

Edit 2:
Thanks guys! I got a neuralnet to fit. Step 1 was resampling at a 1:20 ratio (so stuff would generalize). Step 2 was to use an additional hidden layer. Step 3 was to use rprop (no other learning algo consistently converged). Step 4 was to use a custom error function that doubled the error when the 'real value' was '1' and the neuron produced something less than 0.7. With all of this, I got a model that produced an 85% overall classification rate with only a 20% false negative rate. After some fiddling with the input scalings, I got these error rates down somewhat as well.",12,6,False,self,,,,,
143,MachineLearning,t5_2r3gv,2014-1-27,2014,1,27,15,1w9fcg,techcrunch.com,Google Acquires Artificial Intelligence Startup DeepMind For More Than $500M,https://www.reddit.com/r/MachineLearning/comments/1w9fcg/google_acquires_artificial_intelligence_startup/,zestinc,1390804584,,17,55,False,http://a.thumbs.redditmedia.com/MNSP97u-20C1cx6Z.jpg,,,,,
144,MachineLearning,t5_2r3gv,2014-1-27,2014,1,27,18,1w9nh2,udayintegral.com,Best Toroidal Coil Winding Machines,https://www.reddit.com/r/MachineLearning/comments/1w9nh2/best_toroidal_coil_winding_machines/,[deleted],1390813589,,0,1,False,default,,,,,
145,MachineLearning,t5_2r3gv,2014-1-27,2014,1,27,19,1w9q0z,blog.datumbox.com,Developing a Naive Bayes Text Classifier in JAVA,https://www.reddit.com/r/MachineLearning/comments/1w9q0z/developing_a_naive_bayes_text_classifier_in_java/,datumbox,1390817166,,0,3,False,http://c.thumbs.redditmedia.com/-uM-lLQvn451NxLn.jpg,,,,,
146,MachineLearning,t5_2r3gv,2014-1-28,2014,1,28,4,1wavvx,wired.com,[Deep Learning] Meet the Man Google Hired to Make AI a Reality,https://www.reddit.com/r/MachineLearning/comments/1wavvx/deep_learning_meet_the_man_google_hired_to_make/,[deleted],1390850538,,6,0,False,http://b.thumbs.redditmedia.com/kNC04tSvAyWYOoLm.jpg,,,,,
147,MachineLearning,t5_2r3gv,2014-1-28,2014,1,28,4,1wavze,ayasdi.com,Topology allows machines to start recognizing and classifying shape that represents complex data.,https://www.reddit.com/r/MachineLearning/comments/1wavze/topology_allows_machines_to_start_recognizing_and/,tjlaher,1390850593,,9,17,False,http://e.thumbs.redditmedia.com/pnTkgNtuFbs-8qdF.jpg,,,,,
148,MachineLearning,t5_2r3gv,2014-1-28,2014,1,28,7,1wbgcq,self.MachineLearning,Classifying MLB Pitchers By Pitch Type Percentage,https://www.reddit.com/r/MachineLearning/comments/1wbgcq/classifying_mlb_pitchers_by_pitch_type_percentage/,scomen11,1390861653,"I have 7 years of pitching data in the MLB and want to classify the pitchers over these seasons according to the frequency with which they throw certain pitches. What algorithms should be at the top of my to-try list for discerning these underlying classes?

Thanks!",1,1,False,self,,,,,
149,MachineLearning,t5_2r3gv,2014-1-28,2014,1,28,10,1wc2tk,self.MachineLearning,Not understanding something fundamental about the Metropolis-Hastings algorithm,https://www.reddit.com/r/MachineLearning/comments/1wc2tk/not_understanding_something_fundamental_about_the/,gamahead,1390874373,"I am reading Bishop (which is slightly over my head currently) and looking at the code hosted [here](http://code.activestate.com/recipes/414200-metropolis-hastings-sampler/), and I believe I understand everything about this implementation. It seems to be approximating a Gaussian distribution, but it looks like it's using a Gaussian PDF to approximate the Gaussian distribution, which is where I get lost. I do not understand why this is beneficial or helpful. Perhaps the implementation is not really all that helpful as the result of being simplified for the sake of demonstrating the algorithm clearly? Anyway, if someone could provide some intuition behind the algorithm, I would be grateful.  ",9,10,False,self,,,,,
150,MachineLearning,t5_2r3gv,2014-1-28,2014,1,28,11,1wc6ut,self.MachineLearning,Question: Training- and testset for multi-label classification,https://www.reddit.com/r/MachineLearning/comments/1wc6ut/question_training_and_testset_for_multilabel/,[deleted],1390876788,"Hey,

I've got a multi-label classification problem. 

My dataset has one primary key attribute, 12 numeric attributes and 16 label attributes (with 0;1). Overall instances are 814. Of these 814 instances, 375 have no label data and are therefore the target (prediction) set. The remaining 439 instances have to be used to train and test the model.

This is the first time I apply data mining methods (with the MULAN framework) and I'm wondering: Should I use all my 439 instances for training AND testing or split them up? They are so few and I have no experiences with optimal ratios.

Not sure if this subred is the right place for such a question, but I appreciate any advice.

Regards.",3,1,False,self,,,,,
151,MachineLearning,t5_2r3gv,2014-1-28,2014,1,28,20,1wd3o1,takebuffettsbillion.com,"take Buffett's $1,000,000,000",https://www.reddit.com/r/MachineLearning/comments/1wd3o1/take_buffetts_1000000000/,kakashi_,1390907598,,33,32,False,http://d.thumbs.redditmedia.com/UZgG5vRL2mRlEEE3.jpg,,,,,
152,MachineLearning,t5_2r3gv,2014-1-28,2014,1,28,21,1wd6rt,statisticsviews.com,Columbia Professor uses Machine Learning and Data Science to Solve Global Water Resource Problems,https://www.reddit.com/r/MachineLearning/comments/1wd6rt/columbia_professor_uses_machine_learning_and_data/,LillianPierson,1390911933,,0,0,False,http://c.thumbs.redditmedia.com/gtVhI9VxVPoFl9eb.jpg,,,,,
153,MachineLearning,t5_2r3gv,2014-1-28,2014,1,28,22,1wda3y,self.MachineLearning,Best intro to ML books?,https://www.reddit.com/r/MachineLearning/comments/1wda3y/best_intro_to_ml_books/,[deleted],1390915922,"I'm a second year CS student and I want to dive into ML as early as possible. I have some of the theory based math done, including: LA I &amp; II, Calc I &amp; II, Multi. Calc I, Stats &amp; Prob Theory and Discrete Math. 

I love learning from books, are they any books that are highly recommended for a (somewhat) beginner in ML? Thank you.",18,20,False,self,,,,,
154,MachineLearning,t5_2r3gv,2014-1-29,2014,1,29,2,1wdskj,self.MachineLearning,Classifying categorical data that is not in the training set.,https://www.reddit.com/r/MachineLearning/comments/1wdskj/classifying_categorical_data_that_is_not_in_the/,chchan,1390929129,"I am using python scikit-learn and want to classify categorical data that appear like this:

feature 1, feature 2, feature3, feature 4 =animal type

Right now I am thinking about using support vector machines. There is one problem that is bothering me:

First if you have a data point which has results not in the training set  such as:

training set =[cat, dog, fish, frog]

datapoint=[lion]

How would I deal with these points? My guess is you can either filter the points and you would also be filtering out false negatives. Or attempt to add everything that does not fit in such as add an category 'not identified' into the dataset.

My second problem is how to read the probabilities

Is there an alternative better method to do this that can handle data not in the training set?",7,5,False,self,,,,,
155,MachineLearning,t5_2r3gv,2014-1-29,2014,1,29,7,1werdr,ayasdi.com,Topological Data Analysis: A Framework for Machine Learning | Ayasdi Blog,https://www.reddit.com/r/MachineLearning/comments/1werdr/topological_data_analysis_a_framework_for_machine/,tjlaher,1390948316,,0,6,False,http://d.thumbs.redditmedia.com/11_3ZumWoNwYUaR3.jpg,,,,,
156,MachineLearning,t5_2r3gv,2014-1-29,2014,1,29,13,1wfs5z,self.MachineLearning,Need clarification concerning bias parameter w0 in linear models for regression (Bishop textbook),https://www.reddit.com/r/MachineLearning/comments/1wfs5z/need_clarification_concerning_bias_parameter_w0/,[deleted],1390969512,"Can anyone explain what he means by ""compensates""?

&gt; Thus the bias w0 compensates for the difference between the averages (over the training set) of the target values and the weighted sum of the averages of the basis function values.  
-Bishop pg.142 (right after taking the log of the likelihood function and solving for w)

http://imgur.com/SVumkyl 

What affect does the bias have on the model?

Thanks.",6,3,False,self,,,,,
157,MachineLearning,t5_2r3gv,2014-1-29,2014,1,29,15,1wg0oh,bigattichouse.com,"First crack from a non-academic at a white paper discussing my ""bliss engine"" - a motivational approach to AI. Suggestions appreciated.",https://www.reddit.com/r/MachineLearning/comments/1wg0oh/first_crack_from_a_nonacademic_at_a_white_paper/,bigattichouse,1390975417,,14,2,False,default,,,,,
158,MachineLearning,t5_2r3gv,2014-1-29,2014,1,29,15,1wg4j6,quora.com,What makes the reproducing kernel Hilbert spaces point of view useful in machine learning?,https://www.reddit.com/r/MachineLearning/comments/1wg4j6/what_makes_the_reproducing_kernel_hilbert_spaces/,rrenaud,1390978644,,2,19,False,http://a.thumbs.redditmedia.com/BBqdh0uq38CyDNLB.jpg,,,,,
159,MachineLearning,t5_2r3gv,2014-1-29,2014,1,29,19,1wgfw5,self.MachineLearning,Best Toroidal Coil Winding Machines,https://www.reddit.com/r/MachineLearning/comments/1wgfw5/best_toroidal_coil_winding_machines/,uday02,1390992065,,0,1,False,default,,,,,
160,MachineLearning,t5_2r3gv,2014-1-29,2014,1,29,21,1wgleb,self.MachineLearning,Where can I find the exercises to the Coursera ML course?,https://www.reddit.com/r/MachineLearning/comments/1wgleb/where_can_i_find_the_exercises_to_the_coursera_ml/,BarneyStinson,1390999277,"Hi, I'm currently watching the videos to [Andrew Ng's ML course](https://www.coursera.org/course/ml) on Coursera. I would like to do the programming exercises, but I cannot find them on the site, and googling only turns up a couple of GitHub repositories with completed exercises, which are obviously not very useful to me. 
Does anyone here have a link to the (unsolved) exercises?",8,9,False,self,,,,,
161,MachineLearning,t5_2r3gv,2014-1-30,2014,1,30,2,1wh85s,self.MachineLearning,WEKA takes forever to save models?,https://www.reddit.com/r/MachineLearning/comments/1wh85s/weka_takes_forever_to_save_models/,[deleted],1391016249,"I'm trying to experiment with WEKA for image classification. 

Right now I generate features with MATLAB, write to an ARFF file and load into WEKA Explorer to try different classifiers. 

Then I want to save the trained classifiers to a file (right click in results window and 'save model') so I can classify new instances from the command line. 

However, I find that at least for some types, i.e. RotationForest, the generated model is quite large (&gt;10 MB), and more importantly the save process is extremely slow (~10kB/s)!

Is this normal or am I doing something wrong?",0,1,False,default,,,,,
162,MachineLearning,t5_2r3gv,2014-1-30,2014,1,30,6,1whytm,self.MachineLearning,Exercises for the Coursera course Neural Networks for Machine Learning? by Geoffrey Hinton,https://www.reddit.com/r/MachineLearning/comments/1whytm/exercises_for_the_coursera_course_neural_networks/,[deleted],1391031356,"Does anyone have a copy of the exercises for the Coursera course Neural Networks for Machine Learning by Geoffrey Hinton? (was prompted after seeing the recent ML course exercises request) I've searched around, even going so far as to email Geoffrey urging him to re-offer the course (probably very busy though given the resurgence in neural net interest).",0,1,False,default,,,,,
163,MachineLearning,t5_2r3gv,2014-1-30,2014,1,30,7,1wi600,self.MachineLearning,Practical advice for training RBMs,https://www.reddit.com/r/MachineLearning/comments/1wi600/practical_advice_for_training_rbms/,ProofByPicture,1391035401,"I've written code for an RBM to make sure I understand how they work. Unfortunately, it seems to work for some things (MNIST features look great) and not for others and I hate the feeling that I don't quite understand the choices when setting meta-parameters. I've read Hinton's paper on this which was very helpful but it's a few years old now and only has a few comments about training with real-valued data. 

The main information I feel like I'm missing is how the number of input layers, number of hidden layers, learning rate and regularization methods interact. As far as I can tell, the proper number of hidden units is ""lots + drop(Out/Connect)"" and the learning rate for real valued neurons should be 10e-3 or 10e-4 or thereabouts. 

It also seems like there are some standard weird things (lots of dead neurons, everything turning into the average value of the data, etc) that keep cropping up that I don't quite know how to interpret and I just fiddle with parameters until things improve. Probably I should have recorded the changes that fixed those things, in hindsight.

In any case, I've tried to model some real-valued time series data and it has a lot of difficulty finding anything at all. It seems like the bias units just take over and report the average value of the data and the reconstructions just report the bias unit + constant. I've tried a lot of different parameters and this seems much more resistant to my efforts. I hesitate to go the recurrent route even though that's obviously more suited to the data because I just want to learn to use this tool in a few scenarios first.

Any experts out there have some more advice?",10,7,False,self,,,,,
164,MachineLearning,t5_2r3gv,2014-1-30,2014,1,30,7,1wi7fw,self.MachineLearning,Would machine learning be a good option for making a program that processes a physical sign in sheet.,https://www.reddit.com/r/MachineLearning/comments/1wi7fw/would_machine_learning_be_a_good_option_for/,bfish510,1391036245,"I have a sign in sheet, about 50 a month I have to process. Not that much but each one has about 60 fields. I'm wondering if this is a good route to explore or there might be better options. 

And sadly automation is not a route im able to take for these sheets unfortunately. ",4,0,False,self,,,,,
165,MachineLearning,t5_2r3gv,2014-1-30,2014,1,30,9,1wifq3,self.MachineLearning,Anyone have exercises for the Coursera course Neural Networks for Machine Learning by Geoffrey Hinton?,https://www.reddit.com/r/MachineLearning/comments/1wifq3/anyone_have_exercises_for_the_coursera_course/,[deleted],1391040937,"Does anyone have a copy of the exercises for the [Coursera course Neural Networks for Machine Learning by Geoffrey Hinton](https://www.coursera.org/course/neuralnets)? I was prompted after seeing the recent ML course exercises request. I've searched around, even going so far as to email Geoffrey urging him to re-offer the course. It was last offered in 2012. He's probably very busy though given the resurgence in neural net interest.",4,0,False,default,,,,,
166,MachineLearning,t5_2r3gv,2014-1-30,2014,1,30,10,1winez,self.MachineLearning,Python based alternative to Weka?,https://www.reddit.com/r/MachineLearning/comments/1winez/python_based_alternative_to_weka/,[deleted],1391045517,"So I'm experimenting with image segmentation, and I've been using Weka for machine learning.

Right now I have an ungodly mess where I'm calculating features in MATLAB, training in Weka Explorer, classifying with command line Weka, and using ipython notebooks reading and writing .tif, .mat and .arff files to glue this all together.

I'm starting to get some decent results, so I'd like to clean this up a bit. I think this will require moving everything either to Python or Java. I much prefer Python, so I'd like to use it if possible. I've also read in multiple places that Weka sucks and there are much better alternatives.

However, I've not found anything yet as simple to use or full-featured. Is there a python library with the same kind of plug-and-play GUI for quick prototyping?

Scikit-learn seems to be one of the better libraries, but it seems to have only a fraction of the algorithms available. 

In general it seems like there are a lot of different ML packages for python, but no analogous unifying framework. Or is there something I'm missing?",11,4,False,default,,,,,
167,MachineLearning,t5_2r3gv,2014-1-30,2014,1,30,14,1wj8x6,cl.naist.jp,"A short course on deep learning (Kevin Duh, NAIST)",https://www.reddit.com/r/MachineLearning/comments/1wj8x6/a_short_course_on_deep_learning_kevin_duh_naist/,egrefen,1391059445,,7,34,False,default,,,,,
168,MachineLearning,t5_2r3gv,2014-1-30,2014,1,30,16,1wjg87,reddit.com,I think the AI that is part of the human network might be of interest to you guys ;),https://www.reddit.com/r/MachineLearning/comments/1wjg87/i_think_the_ai_that_is_part_of_the_human_network/,maxkitten,1391065645,,1,0,False,default,,,,,
169,MachineLearning,t5_2r3gv,2014-1-30,2014,1,30,16,1wjh6j,self.MachineLearning,Installing Javaplex in Octave,https://www.reddit.com/r/MachineLearning/comments/1wjh6j/installing_javaplex_in_octave/,stoic_heimdall,1391066624,,0,0,False,default,,,,,
170,MachineLearning,t5_2r3gv,2014-1-30,2014,1,30,17,1wjlhs,self.MachineLearning,Does anyone have the exercises for Stanford Natural Language Processing class on Coursera?,https://www.reddit.com/r/MachineLearning/comments/1wjlhs/does_anyone_have_the_exercises_for_stanford/,kebomix,1391071610,"I missed that course and they didn't offer it again since 2012, so i'm studying the course on my own, [and looks like they locked all the materials but the video lectures](https://www.coursera.org/course/nlp), so if anyone have the assignments it would definitely help me.",6,5,False,self,,,,,
171,MachineLearning,t5_2r3gv,2014-1-31,2014,1,31,1,1wkffq,self.MachineLearning,Need ideas for hardware/sensor specific talk on ML,https://www.reddit.com/r/MachineLearning/comments/1wkffq/need_ideas_for_hardwaresensor_specific_talk_on_ml/,gallamine,1391100672,"I'm making a presentation to a group of engineers/robotics folks about ML. This isn't an academic presentation, but something for laymen, practitioners and hobbyists. I'm trying to come up with some relevant and interesting uses of ML for processing sensor data or applications to robotics or hardware. Does any have ideas or suggestions?",5,0,False,self,,,,,
172,MachineLearning,t5_2r3gv,2014-1-31,2014,1,31,4,1wktrh,self.MachineLearning,Multi-output Regression Models?,https://www.reddit.com/r/MachineLearning/comments/1wktrh/multioutput_regression_models/,[deleted],1391108775,"My input is image data, and my target values are a vector of numbers in the range [0,1].

I'm wondering if there's some good techniques out there for regression on image data. And I'm looking into multi-output models, but I'm open to anything. I'm guessing the only advantage to multi-output is that it saves one from training multiple models.

I was thinking deep neural nets, because of their track record with image data. How would I perform regression with neural nets? Should they be RBMs or convolutional?

How would you tackle this task?",4,0,False,self,,,,,
173,MachineLearning,t5_2r3gv,2014-1-31,2014,1,31,5,1wl206,blog.yhathq.com,Random forests in Python and R,https://www.reddit.com/r/MachineLearning/comments/1wl206/random_forests_in_python_and_r/,motorcyclesarejets,1391113385,,2,36,False,http://a.thumbs.redditmedia.com/-95Jy93fsbaZ1RDr.jpg,,,,,
174,MachineLearning,t5_2r3gv,2014-1-31,2014,1,31,5,1wl4h9,blogs.sas.com,Visualizing Superbowl Tweets with Text Analytics,https://www.reddit.com/r/MachineLearning/comments/1wl4h9/visualizing_superbowl_tweets_with_text_analytics/,datumbox,1391114714,,0,0,False,http://a.thumbs.redditmedia.com/da_0wVdU5PCUhMsr.jpg,,,,,
175,MachineLearning,t5_2r3gv,2014-1-31,2014,1,31,12,1wm6xv,self.MachineLearning,A total ML newb looking to start a machine learning project with a fellow redditor..,https://www.reddit.com/r/MachineLearning/comments/1wm6xv/a_total_ml_newb_looking_to_start_a_machine/,[deleted],1391138154,"So I posted this a while back:

http://www.reddit.com/r/MachineLearning/comments/1svh3i/i_would_like_to_collect_data_and_give_it_out_for/

I got a lot of responses and, in particular, I tried to start a project with /u/utunga. Unfortunately it looks as though he's too busy for a side project, so that didn't quite work out.

I'm still very adamant about learning ML enough to eventually be employable, but outside of Coursera, I have very little hands-on experience. I have 3 other solo projects at the moment, so I'd like to have at least one collaborative project. Also, I'd like to make an effort to connect with more people in this subreddit.

Any takers?",6,0,False,default,,,,,
176,MachineLearning,t5_2r3gv,2014-1-31,2014,1,31,12,1wm99q,ayasdi.com,The Next 3 to 5 Years of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/1wm99q/the_next_3_to_5_years_of_machine_learning/,tjlaher,1391139724,,0,0,False,http://f.thumbs.redditmedia.com/bZjtUp_7weyT0cJG.jpg,,,,,
177,MachineLearning,t5_2r3gv,2014-1-31,2014,1,31,13,1wmayh,self.MachineLearning,ML Job Interview Questions,https://www.reddit.com/r/MachineLearning/comments/1wmayh/ml_job_interview_questions/,bge0,1391140845,"Just applied for a ML position and was wondering if anyone knows some typical questions that people might have asked in the past? 


I have a background in signal processing &amp; 4yrs of software development. Going to review the following:


-Regression (logistic/linear/multivariate)

-Bagging

-Boosting

-Decision trees


Some specific interview type questions would be appreciated!",28,16,False,self,,,,,
178,MachineLearning,t5_2r3gv,2014-1-31,2014,1,31,21,1wn2mm,corvalius.com,Selected papers on Computer Vision: Object detection and related topics,https://www.reddit.com/r/MachineLearning/comments/1wn2mm/selected_papers_on_computer_vision_object/,redknightlois,1391171666,,8,39,False,http://a.thumbs.redditmedia.com/VkJRA-Ds45LeMQ6T.jpg,,,,,
