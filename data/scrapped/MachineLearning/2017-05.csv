,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2017-5-1,2017,5,1,9,68irle,Why would Amazon use item x item collaborative filtering as opposed to data mining algorithm such as FPGrowth? X-Post Datascience,https://www.reddit.com/r/MachineLearning/comments/68irle/why_would_amazon_use_item_x_item_collaborative/,o_safadinho,1493596834,[removed],0,1
1,2017-5-1,2017,5,1,9,68j0du,What are some applications of Generative Adversarial Networks?,https://www.reddit.com/r/MachineLearning/comments/68j0du/what_are_some_applications_of_generative/,art3mia,1493599715,[removed],0,1
2,2017-5-1,2017,5,1,10,68j32n,Backyard Zip Line Sales Parts and Accessories ndash Zip Line Stop,https://www.reddit.com/r/MachineLearning/comments/68j32n/backyard_zip_line_sales_parts_and_accessories/,aurooralaflinjr,1493600636,,0,1
3,2017-5-1,2017,5,1,10,68j74c,Revamp Machine learning: Artificial stem-cell to make artificial general intelligence,https://www.reddit.com/r/MachineLearning/comments/68j74c/revamp_machine_learning_artificial_stemcell_to/,ProgrammingGodJordan,1493601986,[removed],0,1
4,2017-5-1,2017,5,1,11,68jmmy,[D] How do you deploy deep learning models?,https://www.reddit.com/r/MachineLearning/comments/68jmmy/d_how_do_you_deploy_deep_learning_models/,nabusman,1493607465,"I am curious to hear how people are deploying deep learning models into API's. For instance, I was thinking of using something like ActiveMQ with workers that each have the required model loaded and predict and send back the results. Is that a viable strategy? Any other architectures that have been successful?",4,1
5,2017-5-1,2017,5,1,13,68jzk1,Response from ICML on Workshop Proposals,https://www.reddit.com/r/MachineLearning/comments/68jzk1/response_from_icml_on_workshop_proposals/,[deleted],1493612384,[removed],3,2
6,2017-5-1,2017,5,1,14,68k59q,Why do very deep neural networks degrade?,https://www.reddit.com/r/MachineLearning/comments/68k59q/why_do_very_deep_neural_networks_degrade/,RenegadeReddit,1493614851,[removed],0,1
7,2017-5-1,2017,5,1,14,68k5je,Response from ICML on Workshop Proposals,https://www.reddit.com/r/MachineLearning/comments/68k5je/response_from_icml_on_workshop_proposals/,[deleted],1493614960,[removed],0,1
8,2017-5-1,2017,5,1,14,68k5t8,[D] Response from ICML on Workshop Proposals,https://www.reddit.com/r/MachineLearning/comments/68k5t8/d_response_from_icml_on_workshop_proposals/,alexmlamb,1493615069,"Hello,

Has anyone heard back from ICML regarding acceptance of workshop proposals?

Best,

Alex.",3,9
9,2017-5-1,2017,5,1,15,68kgs1,Structured prediction is not RL,https://www.reddit.com/r/MachineLearning/comments/68kgs1/structured_prediction_is_not_rl/,[deleted],1493620453,[deleted],0,1
10,2017-5-1,2017,5,1,16,68kozl,Analysis of DNC implementation,https://www.reddit.com/r/MachineLearning/comments/68kozl/analysis_of_dnc_implementation/,bgavran,1493624825,[removed],0,1
11,2017-5-1,2017,5,1,17,68ksjk,Replay memory algorithm in Q-learning with neural network,https://www.reddit.com/r/MachineLearning/comments/68ksjk/replay_memory_algorithm_in_qlearning_with_neural/,[deleted],1493626829,[removed],0,1
12,2017-5-1,2017,5,1,18,68kxl1,Keras and Tensorflow meet protein biotechnology  testing dSPP for public release,https://www.reddit.com/r/MachineLearning/comments/68kxl1/keras_and_tensorflow_meet_protein_biotechnology/,alpine_photo,1493629743,,1,1
13,2017-5-1,2017,5,1,19,68ladw,A pretty comprehensive list of publicly available programmes trying to use machine learning in every application imaginable. Hope this is suitable here!,https://www.reddit.com/r/MachineLearning/comments/68ladw/a_pretty_comprehensive_list_of_publicly_available/,lordsword,1493636301,,0,1
14,2017-5-1,2017,5,1,20,68lbtf,Washer-Extractor Market Research Report 2017,https://www.reddit.com/r/MachineLearning/comments/68lbtf/washerextractor_market_research_report_2017/,ezio136,1493636904,,0,1
15,2017-5-1,2017,5,1,20,68lia0,[D] What's the state of the art perplexity for language models?,https://www.reddit.com/r/MachineLearning/comments/68lia0/d_whats_the_state_of_the_art_perplexity_for/,bubaonaruba,1493639505,"Interested mostly in:

* Penn Treebank
* 1B word dataset

Many thanks!",3,4
16,2017-5-1,2017,5,1,21,68lm2g,Logistic Regresion - Formula interpretation,https://www.reddit.com/r/MachineLearning/comments/68lm2g/logistic_regresion_formula_interpretation/,Nielz485,1493640990,[removed],1,1
17,2017-5-1,2017,5,1,22,68lvr2,Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/68lvr2/generative_adversarial_networks/,gautamrbharadwaj,1493644466,[removed],0,1
18,2017-5-1,2017,5,1,22,68lvtr,Machine Learning with GPS Trajectories,https://www.reddit.com/r/MachineLearning/comments/68lvtr/machine_learning_with_gps_trajectories/,ataspinar,1493644492,,0,1
19,2017-5-1,2017,5,1,22,68lyeb,NLP Research,https://www.reddit.com/r/MachineLearning/comments/68lyeb/nlp_research/,tatianafrank,1493645362,[removed],0,1
20,2017-5-1,2017,5,1,22,68lyuu,[D] GANs for text generation: progress in the last year?,https://www.reddit.com/r/MachineLearning/comments/68lyuu/d_gans_for_text_generation_progress_in_the_last/,narmio,1493645522,"I am looking to conditionally generate relatively short, relatively structured texts. Specifically, I'm trying to generate plausible recipes given a subset of required ingredients, like ""make me something with beef and potatoes"". Ultimately I'm interested in seeing if it's possible to generate plausible recipes from ingredient combinations that aren't in the database.

I had initially thought of using a conditional RNN-GAN for this, with a fixed-length (for now) list of GloVe-embedded required ingredients provided as context.  Then I found an obvious-in-hindsight post from /u/goodfellow_ian/ from a year ago explaining why that wouldn't work: https://www.reddit.com/r/MachineLearning/comments/40ldq6/generative_adversarial_networks_for_text/

Put (over-)simply: GANs are near-impossible to train in discrete output domains as the generator cannot smoothly improve. I'm fairly inexperienced at recurrent approaches, but that raises two questions for me:

1) has any progress been made since that post was written on applying adversarial training to text or other discrete domains?

and 2) Why wouldn't it work if I trained a GAN to output a non-recurrent continuous intermediary representation?  Something like the hidden layer of a recurrent autoencoder (trained on the database of real recipes, then frozen)?  This seems obvious, and I'm not an expert, so my immediate assumption is that it would fail spectacularly for some reason I have not yet grasped.  So I thought I'd ask you folks before I tried it!",17,54
21,2017-5-1,2017,5,1,22,68m400,[R] Explaining How a Deep Neural Network Trained with End-to-End Learning Steers a Car,https://www.reddit.com/r/MachineLearning/comments/68m400/r_explaining_how_a_deep_neural_network_trained/,madebyollin,1493647189,,4,19
22,2017-5-1,2017,5,1,23,68m6pa,On maintaining the scikit-learn library and sustainability of open source [AUDIO],https://www.reddit.com/r/MachineLearning/comments/68m6pa/on_maintaining_the_scikitlearn_library_and/,piskvorky,1493647987,,0,1
23,2017-5-1,2017,5,1,23,68m7g3,[R] [1704.08847] Parseval Networks: Improving Robustness to Adversarial Examples,https://www.reddit.com/r/MachineLearning/comments/68m7g3/r_170408847_parseval_networks_improving/,Mandrathax,1493648204,,8,13
24,2017-5-1,2017,5,1,23,68mfkg,Bot Evolution - An interesting display of evolution through neural networks and a genetic algorithm,https://www.reddit.com/r/MachineLearning/comments/68mfkg/bot_evolution_an_interesting_display_of_evolution/,Mike_TriHard_Cx,1493650617,,0,1
25,2017-5-2,2017,5,2,0,68mmvl,Why the beam search decoder of Tensorflow doesn't work as expected?,https://www.reddit.com/r/MachineLearning/comments/68mmvl/why_the_beam_search_decoder_of_tensorflow_doesnt/,yobichi,1493652638,[removed],0,1
26,2017-5-2,2017,5,2,0,68mqw0,[R] On Model Mismatch and Bayesian Analysis,https://www.reddit.com/r/MachineLearning/comments/68mqw0/r_on_model_mismatch_and_bayesian_analysis/,theciank,1493653734,,7,18
27,2017-5-2,2017,5,2,1,68n5lk,Microsoft presents The Explanimators - Episode 1: An Animated Guide to Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/68n5lk/microsoft_presents_the_explanimators_episode_1_an/,crescentvale,1493657697,,0,1
28,2017-5-2,2017,5,2,3,68nnau,[R] [1701.05221] Parsimonious Inference on Convolutional Neural Networks: Learning and applying on-line kernel activation rules,https://www.reddit.com/r/MachineLearning/comments/68nnau/r_170105221_parsimonious_inference_on/,darkconfidantislife,1493662371,,0,9
29,2017-5-2,2017,5,2,3,68nnij,just testing,https://www.reddit.com/r/MachineLearning/comments/68nnij/just_testing/,[deleted],1493662428,[removed],0,1
30,2017-5-2,2017,5,2,3,68nrxi,deep Learning/sorting of medical knowledge,https://www.reddit.com/r/MachineLearning/comments/68nrxi/deep_learningsorting_of_medical_knowledge/,MadScientist565,1493663585,[removed],0,1
31,2017-5-2,2017,5,2,4,68o0nj,Perceptron - Visual artificial neural network builder,https://www.reddit.com/r/MachineLearning/comments/68o0nj/perceptron_visual_artificial_neural_network/,[deleted],1493665844,[deleted],0,0
32,2017-5-2,2017,5,2,4,68o981,[D] Doubts about building a 3 GPU rig (x-post buildapc),https://www.reddit.com/r/MachineLearning/comments/68o981/d_doubts_about_building_a_3_gpu_rig_xpost_buildapc/,23lurker,1493668079,"Came across /r/machinelearning and realised you guys might know better :)

After a lot of research and reading around, this is what I understand and have a bunch of doubts.

* Applications I'm running thrive on GPU memory. Cost-benefit analysis makes the Titan overpriced for an extra 1GB. The STRIX 11GB with 3500+ CUDA cores seems like a better value. Is there any other suggestion here? 

* A 4 GPU board requires a 40 lane CPU (i.e atleast 6850k), which I'm knocking down to a 3 GPU board, hence the Taichi X99. I get 28 lanes  (6800k) and with 3 GPUs (8/8/8), will this be alright?
P.S. I know an older Xeon with 40 lanes is an option, but I may need to do CPU intensive stuff in the future, so the 6000 series seems to have better per core clock speed.

* I know the 1080 Ti doesnt officially support 3 way SLI, but I don't need the cards in SLI. I just need to access the 11GB memory for each card. I hope there wont be compatibility problems.

* The 1080 ti takes 2.5 GPU slots, would this be a problem when pugging in 3 GPUs into the Taichi X99 board?

* Cases are hard to come by where I'm getting my parts from (India) and most components are overpriced. Its a bit of a puzzle, but sourcing is possible with some delay. I've decided to go for the Air 740. Its got ample room for air cooling (avoiding water cooling altogether). This PC is going be kept in a closed room and accessed over LAN, so looks dont matter. Im not sure if this case is overkill, I'm open to suggestions.

* Adding storage later on, for now network connected.

Is there something I'm missing out on? 

Also, this rig converted is around $5000 with 3 GPUs in my area and thats around my total budget. I know it sucks, but no other choice really.



**Post a draft of your potential build here (specific parts please). [Consider formatting your parts list.](http://www.reddit.com/r/buildapc/wiki/pcpp) Don't ask to be spoonfed a build (read the rules!)**.

[PCPartPicker part list](https://pcpartpicker.com/list/73sqyf) / [Price breakdown by merchant](https://pcpartpicker.com/list/73sqyf/by_merchant/)

Type|Item|Price (US)|Price (IN)
:----|:----|:----|:----
**CPU** | [Intel Core i7-6800K 3.4GHz 6-Core Processor](https://pcpartpicker.com/product/Td98TW/intel-cpu-bx80671i76800k) | $395.22 @ Amazon | $472
**CPU Cooler** | [Noctua NH-U12DXi4 55.0 CFM CPU Cooler](https://pcpartpicker.com/product/XXK7YJ/noctua-cpu-cooler-nhu12dxi4) | $64.89 @ OutletPC | $54
**Motherboard** | [ASRock X99 Taichi ATX LGA2011-3 Motherboard](https://pcpartpicker.com/product/FGPzK8/asrock-x99-taichi-atx-lga2011-3-motherboard-x99-taichi) | $218.99 @ SuperBiiz | $310
**Memory** | [Kingston HyperX Fury Black 16GB (2 x 8GB) DDR4-2133 Memory](https://pcpartpicker.com/product/xhM323/kingston-memory-hx421c14fbk216) | $111.65 @ Amazon | $ 139
**Memory** | [Kingston HyperX Fury Black 16GB (2 x 8GB) DDR4-2133 Memory](https://pcpartpicker.com/product/xhM323/kingston-memory-hx421c14fbk216) | $111.65 @ Amazon | $ 139
**Storage** | [Samsung 850 EVO-Series 250GB 2.5"" Solid State Drive](https://pcpartpicker.com/product/3kL7YJ/samsung-internal-hard-drive-mz75e250bam) | $99.99 @ Amazon | $ 110
**Video Card** | [Asus GeForce GTX 1080 Ti 11GB STRIX GAMING Video Card](https://pcpartpicker.com/product/Z8cMnQ/asus-geforce-gtx-1080-ti-11gb-video-card-strix-gtx1080ti-o11g-gaming) (2-Way SLI) | $768.99 @ SuperBiiz | $1076
**Video Card** | [Asus GeForce GTX 1080 Ti 11GB STRIX GAMING Video Card](https://pcpartpicker.com/product/Z8cMnQ/asus-geforce-gtx-1080-ti-11gb-video-card-strix-gtx1080ti-o11g-gaming) (2-Way SLI) | $768.99 @ SuperBiiz | $1076
**Video Card** | [Asus GeForce GTX 1080 Ti 11GB STRIX GAMING Video Card](https://pcpartpicker.com/product/Z8cMnQ/asus-geforce-gtx-1080-ti-11gb-video-card-strix-gtx1080ti-o11g-gaming) (2-Way SLI) | $768.99 @ SuperBiiz | $1076
**Case** | [Corsair Air 740 ATX Full Tower Case](https://pcpartpicker.com/product/2rGj4D/corsair-air-740-atx-full-tower-case-cc-9011096-ww) | $131.99 @ Newegg | $170
**Power Supply** | [SeaSonic X Series 1250W 80+ Gold Certified Fully-Modular ATX Power Supply](https://pcpartpicker.com/product/Hk98TW/seasonic-power-supply-ss1250xm) | $189.99 @ SuperBiiz | $307
 | *Prices include shipping, taxes, rebates, and discounts* |
 | **Total** | **$3631.34** | **$4932**
 | Generated by [PCPartPicker](http://pcpartpicker.com) 2017-05-01 10:28 EDT-0400 |",29,5
33,2017-5-2,2017,5,2,4,68obp9,How to use Magenta and Tensorflow to generate music in a free Google Cloud instance,https://www.reddit.com/r/MachineLearning/comments/68obp9/how_to_use_magenta_and_tensorflow_to_generate/,[deleted],1493668754,[deleted],0,1
34,2017-5-2,2017,5,2,5,68ocs0,Assessing quality of ML learning resources,https://www.reddit.com/r/MachineLearning/comments/68ocs0/assessing_quality_of_ml_learning_resources/,[deleted],1493669036,[removed],0,1
35,2017-5-2,2017,5,2,5,68oiq7,Does Anyone know what the best deep learning libraries for video classification are?,https://www.reddit.com/r/MachineLearning/comments/68oiq7/does_anyone_know_what_the_best_deep_learning/,GrandMasterSpock,1493670576,[removed],0,1
36,2017-5-2,2017,5,2,5,68omdu,Relation between Word Embeddings and Manifold Learning?,https://www.reddit.com/r/MachineLearning/comments/68omdu/relation_between_word_embeddings_and_manifold/,svmmvs,1493671533,[removed],0,1
37,2017-5-2,2017,5,2,6,68ow0w,Best strategy for Kaggle.com's Quora Question pairs?,https://www.reddit.com/r/MachineLearning/comments/68ow0w/best_strategy_for_kagglecoms_quora_question_pairs/,Mild7intl,1493674126,[removed],0,1
38,2017-5-2,2017,5,2,7,68p5mk,The dark mystery of tensorflow and tensorboard using cross-validation in training. Weird graphs showing up,https://www.reddit.com/r/MachineLearning/comments/68p5mk/the_dark_mystery_of_tensorflow_and_tensorboard/,DavieTheAl,1493676892,[removed],0,1
39,2017-5-2,2017,5,2,7,68p9tc,[P] Predicting the next wicket in a T20 match using Neural Networks,https://www.reddit.com/r/MachineLearning/comments/68p9tc/p_predicting_the_next_wicket_in_a_t20_match_using/,Faizann24,1493678131,,0,10
40,2017-5-2,2017,5,2,8,68pnhx,Sent to Prison by a Software Program's Secret Algorithms,https://www.reddit.com/r/MachineLearning/comments/68pnhx/sent_to_prison_by_a_software_programs_secret/,quattro,1493682307,,1,1
41,2017-5-2,2017,5,2,9,68prrz,[N] ML Competition - Predicting entire sentences given the first letter of each word,https://www.reddit.com/r/MachineLearning/comments/68prrz/n_ml_competition_predicting_entire_sentences/,floppybad,1493683700,,54,45
42,2017-5-2,2017,5,2,10,68q2tt,Representational and Optimization Properties of Deep Residual Networks,https://www.reddit.com/r/MachineLearning/comments/68q2tt/representational_and_optimization_properties_of/,drlukeor,1493687113,,1,1
43,2017-5-2,2017,5,2,10,68qd0h,[D] What's a good dataset for benchmarking predictive accuracy of a classifier?,https://www.reddit.com/r/MachineLearning/comments/68qd0h/d_whats_a_good_dataset_for_benchmarking/,sanity,1493690377,[removed],0,1
44,2017-5-2,2017,5,2,12,68qsa3,Wavenet implementation not working,https://www.reddit.com/r/MachineLearning/comments/68qsa3/wavenet_implementation_not_working/,kaichogami,1493695560,,1,1
45,2017-5-2,2017,5,2,13,68r270,[D] Using seq2seq LSTM on feature sequences,https://www.reddit.com/r/MachineLearning/comments/68r270/d_using_seq2seq_lstm_on_feature_sequences/,lleewwiiss,1493699173,"I have seen seq2seq LSTM implementations be used a lot on word sequences, but could you train the input on a sequence of time windows [wt1, wt+1 ... wt+n] etc where each window contains a set of features respective to that time window for a time series? The goal would be to try output a respective sequence containing the labels for each window, where there are ~500 different possible labels.",3,7
46,2017-5-2,2017,5,2,15,68ring,Inviting Research Papers Data Science Congress 2017,https://www.reddit.com/r/MachineLearning/comments/68ring/inviting_research_papers_data_science_congress/,circuitteja,1493706291,,0,1
47,2017-5-2,2017,5,2,15,68rjt9,[D] How Feature Engineering can help you do well in a Kaggle competition - Part I,https://www.reddit.com/r/MachineLearning/comments/68rjt9/d_how_feature_engineering_can_help_you_do_well_in/,fhoffa,1493706801,,4,63
48,2017-5-2,2017,5,2,17,68rwr0,Is it too late now to do a PhD in Deep Learning ?,https://www.reddit.com/r/MachineLearning/comments/68rwr0/is_it_too_late_now_to_do_a_phd_in_deep_learning/,laituan245,1493713361,[removed],0,1
49,2017-5-2,2017,5,2,17,68rwsj,Reinforcement learning for revenue maximization.,https://www.reddit.com/r/MachineLearning/comments/68rwsj/reinforcement_learning_for_revenue_maximization/,xen-m-rph,1493713384,[removed],0,1
50,2017-5-2,2017,5,2,17,68rxjw,"Russian internet company Rambler&amp;Co released large-scale benchmark of XGBoost, Vowpal Wabbit and Spark ML on 1TB Criteo dataset",https://www.reddit.com/r/MachineLearning/comments/68rxjw/russian_internet_company_ramblerco_released/,pklemenkov,1493713783,,0,2
51,2017-5-2,2017,5,2,17,68s0bq,[P] sing Magenta and Tensorflow to generate music in a free Google Cloud instance,https://www.reddit.com/r/MachineLearning/comments/68s0bq/p_sing_magenta_and_tensorflow_to_generate_music/,[deleted],1493715200,[deleted],0,1
52,2017-5-2,2017,5,2,18,68s1kz,[P] Using Magenta and Tensorflow to generate music in a free Google Cloud instance,https://www.reddit.com/r/MachineLearning/comments/68s1kz/p_using_magenta_and_tensorflow_to_generate_music/,tftutorial,1493715810,,5,31
53,2017-5-2,2017,5,2,18,68s5kb,BerryNet - Make your home smart with Raspberry Pi,https://www.reddit.com/r/MachineLearning/comments/68s5kb/berrynet_make_your_home_smart_with_raspberry_pi/,ThisisNing,1493717782,,0,1
54,2017-5-2,2017,5,2,20,68si51,ehirler aras tamaclk - Tabanlolu Nakliyat,https://www.reddit.com/r/MachineLearning/comments/68si51/ehirler_aras_tamaclk_tabanlolu_nakliyat/,Tabanlioglunakliyat,1493723704,,0,1
55,2017-5-2,2017,5,2,21,68swgv,Rethinking Design Tools in the Age of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/68swgv/rethinking_design_tools_in_the_age_of_machine/,pjhml,1493729234,,0,1
56,2017-5-2,2017,5,2,22,68t062,Why Facebook Went All In on AI,https://www.reddit.com/r/MachineLearning/comments/68t062/why_facebook_went_all_in_on_ai/,jonfla,1493730473,,0,1
57,2017-5-2,2017,5,2,22,68t9kt,Adding a densely-connected classifier on top of the convolutional base produces crazy results.,https://www.reddit.com/r/MachineLearning/comments/68t9kt/adding_a_denselyconnected_classifier_on_top_of/,gpp8pvirginia,1493733435,[removed],0,1
58,2017-5-2,2017,5,2,23,68taba,Hi guys I've trained a Bi-directional LSTM model that attempts to play digital sheet music. It would be amazing if you guys could fill in this ONE question survey. There's a human and a robot-performed track. You need to figure out which one is the human. Thank you so much in advance!,https://www.reddit.com/r/MachineLearning/comments/68taba/hi_guys_ive_trained_a_bidirectional_lstm_model/,[deleted],1493733661,[deleted],0,1
59,2017-5-2,2017,5,2,23,68ti1p,FC-300 Automatic Chicken Poultry Fish Meat Cutting Chopping Machine with bone,https://www.reddit.com/r/MachineLearning/comments/68ti1p/fc300_automatic_chicken_poultry_fish_meat_cutting/,Elaine2008,1493735843,,0,1
60,2017-5-2,2017,5,2,23,68tkm6,"[P] Keras-like training in Pytorch, with callbacks+regularizers+initializers+constraints+metrics and a Progress Bar!",https://www.reddit.com/r/MachineLearning/comments/68tkm6/p_keraslike_training_in_pytorch_with/,boysparktrailer,1493736720,"I made the [torchsample package](https://github.com/ncullen93/torchsample) in order to abstract away the training loop in Pytorch while also providing a lot of the functionality (and more) that Keras provides. There are a ton of callbacks (all of Keras' callbacks), constraints (explicit constraints or implicit penalties), regularizers, initializers, and metrics. All of these can be selectively applied to certain layers! There is also a progress bar. 


The best part is that you don't have to change the way you define your model at all in pytorch - in that sense, this is nothing like Keras because there is ZERO sacrifice of model flexibility. Hopefully this is a cool incentive for people to try out Pytorch!


Also, torchsample includes a lot of great Data Augmentation and sampling code - including affine transforms, allowing transforms on target tensors and both input+target tensors at once. There are also some solid utility functions (e.g. th_pearsonr, th_corrcoef) and a Spatial Transformer Network module.


Here's an example:

    # define model exactly as you would otherwise
    class Network(nn.Module):
        def __init__(self):
            super(Network, self).__init__()
            self.conv1 = nn.Conv2d(1, 32, kernel_size=3)
            self.conv2 = nn.Conv2d(32, 64, kernel_size=3)
            self.fc1 = nn.Linear(1600, 128)
            self.fc2 = nn.Linear(128, 10)

        def forward(self, x):
            x = F.relu(F.max_pool2d(self.conv1(x), 2))
            x = F.relu(F.max_pool2d(self.conv2(x), 2))
            x = x.view(-1, 1600)
            x = F.relu(self.fc1(x))
            x = F.dropout(x, training=self.training)
            x = self.fc2(x)
            return F.log_softmax(x)

    model = Network()
    # pass your model to the ModuleTrainer class
    trainer = ModuleTrainer(model)

    # callbacks - a few standard ones
    callbacks = [EarlyStopping(patience=10), 
                 ReduceLROnPlateau(factor=0.5, patience=5)]

    # regularizers - L1 applied to Conv layers, L2 applied to fc layers
    regularizers = [L1Regularizer(scale=1e-3, module_filter='conv*'),
                   L2Regularizer(scale=1e-5, module_filter='fc*')]

    # constraints - explicit UnitNorm applied every 3 batches to fc layers, MaxNorm penalty to conv layers
    constraints = [UnitNorm(frequency=3, unit='batch', module_filter='fc*'),
                   MaxNorm(value=2., lagrangian=True, scale=1e-2, module_filter='conv*')]

    # inits - xavier uniform on fc layers
    initializers = [XavierUniform(bias=False, module_filter='fc*')]

    # metrics - top 3 accuracy
    metrics = [CategoricalAccuracy(top_k=3)]

    trainer.compile(loss='nll_loss',
                    optimizer='adadelta',
                    regularizers=regularizers,
                    constraints=constraints,
                    initializers=initializers,
                    metrics=metrics)

    trainer.fit(x_train, y_train, 
              validation_data=(x_test, y_test),
              nb_epoch=20, 
              batch_size=128,
              verbose=1)


You can also fit directly from Pytorch's DataLoaders!

    trainer.fit_loader(train_loader, val_loader=val_loader, nb_epoch=20)


Additionally, you have access to the standard evaluation and prediction functions:

    loss = trainer.evaluate(x_train, y_train)
    y_pred = trainer.predict(x_train)


Even more, the ModelTrainer class accepts multiple inputs, multiple targets, and even optional targets!


Again, here's the [link to the package](https://github.com/ncullen93/torchsample)",24,98
61,2017-5-3,2017,5,3,0,68tz27,Plausibly looking adversarial examples for text classification,https://www.reddit.com/r/MachineLearning/comments/68tz27/plausibly_looking_adversarial_examples_for_text/,[deleted],1493740623,[deleted],0,1
62,2017-5-3,2017,5,3,1,68u395,[N] Strange Loop 2017 Call for Presentations,https://www.reddit.com/r/MachineLearning/comments/68u395/n_strange_loop_2017_call_for_presentations/,alexdmiller,1493741714,,3,2
63,2017-5-3,2017,5,3,1,68u58i,[D] How much is ones github worth to the employer?,https://www.reddit.com/r/MachineLearning/comments/68u58i/d_how_much_is_ones_github_worth_to_the_employer/,_muon_,1493742261,"One can sometimes hear that the best way to land a job in ML (intern / junior, ofc.) is to show a potential employer one's practical skills. 
For example advice like ""Implement research papers"" comes up a lot in this context.
    
I was wondering, how much something like a personal blog can convince a well respected employer to offer me an interview? Here I ofc. assume that the blog is filled with some reasonably interesting content (e.g. paper implementations, writeups, explanations etc), not basic introductory stuff.
    
Is this something worth pursuing from a career perspective? Myabe it should be done only in spare time, as it is considered a bonus, but not as something that can convince a recruiter on its own?
    
This sub is filled with people from the best teams in the world. I would be thrilled to hear your opinions on this.

= = = = = = = = = = = = = = = = = = =
Shameless request for career advice:

I'm finishing my bachelor in CS soon. I study in EU and my Uni is far from being an Oxford, and my GPA is definatelly not 4.0

For my question to even make sense, let's assume the following:
    
* I indeed do know a lot about ML, both theory and pracitce.
    
* I can create valuable content: paper writeups, interesting albeit not groundbreaking research, kaggle solutions etc. (some of those things, like research, I have already done, but not published anywhere).
    
* I'm smart and capable enough to work at a respected tech company (otherwise all of this does not really matter)
    
My plan was:
    
* Create an awesome personal webpage, and try to land a job at a respected company after finishing up my bachelor. Perhaps after that try to get to Masters at a respected university (e.g Edinburgh)
    
* Work on that fulltime during summer. Working on weekends only won't work in my case (not enough time to build a good blog).
        
But recently I was offered a position of a junior data scientist at a data-science focused, small company. They focus on ads, which I do not find very interesting.
    
**So... is it better to**:
    
* Focus on a blog and show what I'm interested in and what exactly I can do, or
    
* Get pracitcal job experience and recommendations, even if that's only a small, not well known company?",17,6
64,2017-5-3,2017,5,3,1,68u92k,Master's in Statistics or Computer Science?,https://www.reddit.com/r/MachineLearning/comments/68u92k/masters_in_statistics_or_computer_science/,[deleted],1493743273,[removed],0,1
65,2017-5-3,2017,5,3,2,68uelh,"[N] Facebook fastText update: pre-trained vectors for 294 languages, smaller memory consumption",https://www.reddit.com/r/MachineLearning/comments/68uelh/n_facebook_fasttext_update_pretrained_vectors_for/,kluikens,1493744692,,1,51
66,2017-5-3,2017,5,3,2,68ueo0,[R] Generative Modeling with Conditional Autoencoders: Building an Integrated Cell,https://www.reddit.com/r/MachineLearning/comments/68ueo0/r_generative_modeling_with_conditional/,grjohnso,1493744713,,0,3
67,2017-5-3,2017,5,3,2,68uf3t,[D] Topics with hidden gem learning resources,https://www.reddit.com/r/MachineLearning/comments/68uf3t/d_topics_with_hidden_gem_learning_resources/,01theone,1493744824,"What are topics in ML that have a great learning resource, but that its not so easy to find from a quick google search?

I'm looking for at least of few of these kinds of topics to try and see if its possible to make finding these resources faster than through typical channels.

I'm building a proof-of-concept for a platform where users upload links to explanations of stuff, and rate and discuss them so that when you search for the topic you want to have explained to you, you will get the highest rated content returned.

[Here](https://kenrose.net/channel/2/search?query=decision+tree+chi+squared+pruning&amp;category=27) is a sample search on the site about decision tree pruning

and [here](https://kenrose.net/comparator/137/132) is an example comparison between two SVM resources",0,4
68,2017-5-3,2017,5,3,2,68unin,State of the art for clustering sparse binary data?,https://www.reddit.com/r/MachineLearning/comments/68unin/state_of_the_art_for_clustering_sparse_binary_data/,[deleted],1493747030,[removed],0,1
69,2017-5-3,2017,5,3,2,68uoy4,[P] Movie recommendations in terms of Deep Learning,https://www.reddit.com/r/MachineLearning/comments/68uoy4/p_movie_recommendations_in_terms_of_deep_learning/,tdionis,1493747406,,3,17
70,2017-5-3,2017,5,3,2,68upnb,[P] Plausibly looking adversarial examples for text classification,https://www.reddit.com/r/MachineLearning/comments/68upnb/p_plausibly_looking_adversarial_examples_for_text/,hidden-markov,1493747591,,12,8
71,2017-5-3,2017,5,3,3,68uwdo,[R] Introspective Classifier Learning: Empower Generatively,https://www.reddit.com/r/MachineLearning/comments/68uwdo/r_introspective_classifier_learning_empower/,IAmAFedora,1493749321,,1,7
72,2017-5-3,2017,5,3,3,68uypa,[R] Introspective Generative Modeling: Decide Discriminatively,https://www.reddit.com/r/MachineLearning/comments/68uypa/r_introspective_generative_modeling_decide/,IAmAFedora,1493749923,,2,0
73,2017-5-3,2017,5,3,3,68v21j,[R+D] Natural Gradient Training and the future of RNNs,https://www.reddit.com/r/MachineLearning/comments/68v21j/rd_natural_gradient_training_and_the_future_of/,[deleted],1493750816,[removed],0,1
74,2017-5-3,2017,5,3,3,68v27r,[D] Fastest way to solve linear equations?,https://www.reddit.com/r/MachineLearning/comments/68v27r/d_fastest_way_to_solve_linear_equations/,[deleted],1493750853,[deleted],3,1
75,2017-5-3,2017,5,3,3,68v4t1,[R] Natural Gradient Training and the future of RNNs,https://www.reddit.com/r/MachineLearning/comments/68v4t1/r_natural_gradient_training_and_the_future_of_rnns/,Wihanb,1493751559,"TL;DR What do you guys think about the future of RNN training? Is it gonna be about LSTM Esque methods where we try to condition the problem for better optimisation or do we leverage curvature and brute force our way through the vanishing/exploding gradient problem (Natural Gradient/ Better Optimisation Approach)? New architectures vs new optimisation?

I'm currently working on benchmarking the performance of natural gradient methods (+ Saddle Free Newton) on recurrent nets. As I get deeper into it I see how powerful these methods are, getting really good results in like 10 iterations then overfitting(without dropout, bit of a pain to implement in TF when you do multiple sess.run calls in the line search phase, ill let you guys know how these methods do with dropout). This is also on vanilla nets, Martens(1) gets pretty astounding results on some test problems with vanilla recurrent nets using his hessian free implementation. However, these methods are reasonably complex to implement and still seem to be rather unstable (needing structural damping etc due to the potentially huge updates when curvature is low).
However, I look at the work that people are putting out using LSTM's and I'm always blown away with what plain old stochastic gradient descent can do on the right problems.

So the question at the end of the day is, where should the research be focused? On conditioning our problems in ways which they become easier to solve and slightly neglecting the optimisation since SGD works amazingly for its simplicity.

So i'll quote Martins about RNN vs LSTM ""However, it is not clear if the approach of training with gradient descent and enabling long-term memorization with the specialised LSTM architecture is harnessing the true power of recurrent neural computation. In particular, gradient descent may be deficient for RNN learning in ways that are not compensated for by using LSTMs.""

The other factor to consider is that our theoretical knowledge of the loss surfaces of these problems is often far behind what we're currently implementing.(2)
So my question is, where do we go from here?
for your perusal

(1) J. Martens. Learning Recurrent Neural Networks with Hessian-Free Optimization. 2011.
(2)Swirszcz G, Czarnecki WM, Pascanu R. Local minima in training of neural networks. stat. 2017 Feb;1050:17.",3,13
76,2017-5-3,2017,5,3,5,68vkee,"ICML or IJCAI, which one to go?",https://www.reddit.com/r/MachineLearning/comments/68vkee/icml_or_ijcai_which_one_to_go/,cloudmlai,1493755655,[removed],0,1
77,2017-5-3,2017,5,3,5,68vtwz,Machine Learning Courses Online,https://www.reddit.com/r/MachineLearning/comments/68vtwz/machine_learning_courses_online/,javascripton,1493758185,,0,1
78,2017-5-3,2017,5,3,5,68vuu1,Sentiment analysis on 1.5 million tweets using word2vec and Keras,https://www.reddit.com/r/MachineLearning/comments/68vuu1/sentiment_analysis_on_15_million_tweets_using/,ahmedbesbes,1493758430,,0,1
79,2017-5-3,2017,5,3,5,68vv7k,ELFI: Python engine for likelihood free inference,https://www.reddit.com/r/MachineLearning/comments/68vv7k/elfi_python_engine_for_likelihood_free_inference/,Qkirld,1493758527,,0,1
80,2017-5-3,2017,5,3,6,68w733,[R] Deep Learning Papers Collected by Task,https://www.reddit.com/r/MachineLearning/comments/68w733/r_deep_learning_papers_collected_by_task/,dizzleblizze53,1493762193,,3,57
81,2017-5-3,2017,5,3,7,68we2e,[D] What can machine learning actually achieve in medicine?,https://www.reddit.com/r/MachineLearning/comments/68we2e/d_what_can_machine_learning_actually_achieve_in/,[deleted],1493764166,[removed],0,1
82,2017-5-3,2017,5,3,8,68wo2n,[N] The Satellite Utility Manifold,https://www.reddit.com/r/MachineLearning/comments/68wo2n/n_the_satellite_utility_manifold/,amplifier_khan,1493767230,,0,1
83,2017-5-3,2017,5,3,9,68wx5o,Looking for a pre-built or custom entry level deep learning machine,https://www.reddit.com/r/MachineLearning/comments/68wx5o/looking_for_a_prebuilt_or_custom_entry_level_deep/,z4nith,1493770094,[removed],0,1
84,2017-5-3,2017,5,3,9,68wzg8,Visual Attribute Transfer through Deep Image Analogy,https://www.reddit.com/r/MachineLearning/comments/68wzg8/visual_attribute_transfer_through_deep_image/,[deleted],1493770759,[removed],0,1
85,2017-5-3,2017,5,3,9,68x2q6,Visual Attribute Transfer through Deep Image Analogy,https://www.reddit.com/r/MachineLearning/comments/68x2q6/visual_attribute_transfer_through_deep_image/,[deleted],1493771833,[deleted],0,1
86,2017-5-3,2017,5,3,9,68x2w6,[D] Aftermarket vs Reference GPUs for long running tasks,https://www.reddit.com/r/MachineLearning/comments/68x2w6/d_aftermarket_vs_reference_gpus_for_long_running/,eraaaaaeee,1493771880,"A lot of the internet seems to be in agreement that aftermarket GPU designs have better performance and cooling than the reference cards. Most notably, aftermarket cards tend to have fan-style cooling and higher clock rates but (for gaming, at least) are likely built to run for a max of 6-8 hours at a time. Does anyone have experience on whether a reference card would last longer or have better thermal performance than an aftermarket card when used for long-running ML tasks?

Specifically, this is in reference to GeForce 10 series cards.",9,4
87,2017-5-3,2017,5,3,9,68x5ta,Visual Attribute Transfer through Deep Image Analogy,https://www.reddit.com/r/MachineLearning/comments/68x5ta/visual_attribute_transfer_through_deep_image/,[deleted],1493772787,[deleted],0,1
88,2017-5-3,2017,5,3,9,68x6aa,Visual Attribute Transfer through Deep Image Analogy,https://www.reddit.com/r/MachineLearning/comments/68x6aa/visual_attribute_transfer_through_deep_image/,[deleted],1493772949,[removed],0,1
89,2017-5-3,2017,5,3,9,68x70d,Visual Attribute Transfer through Deep Image Analogy,https://www.reddit.com/r/MachineLearning/comments/68x70d/visual_attribute_transfer_through_deep_image/,[deleted],1493773187,[deleted],0,1
90,2017-5-3,2017,5,3,11,68xjh3,"Zhengzhou Haloong Machinery Manufacturing Co., Ltd. have specilized in Servo Press machine, electric screw press machine,firebrick press,refractory brick press machine,forging press machine,CNC press,friction press reform for 37years.",https://www.reddit.com/r/MachineLearning/comments/68xjh3/zhengzhou_haloong_machinery_manufacturing_co_ltd/,pressmachine,1493777120,,0,1
91,2017-5-3,2017,5,3,11,68xogx,[1705.01088] Visual Attribute Transfer through Deep Image Analogy,https://www.reddit.com/r/MachineLearning/comments/68xogx/170501088_visual_attribute_transfer_through_deep/,[deleted],1493778729,[deleted],0,1
92,2017-5-3,2017,5,3,11,68xpnc,Visual Attribute Transfer through Deep Image Analogy,https://www.reddit.com/r/MachineLearning/comments/68xpnc/visual_attribute_transfer_through_deep_image/,[deleted],1493779134,[removed],0,1
93,2017-5-3,2017,5,3,11,68xqyu,Deep Image Analogy,https://www.reddit.com/r/MachineLearning/comments/68xqyu/deep_image_analogy/,[deleted],1493779597,[deleted],0,1
94,2017-5-3,2017,5,3,11,68xr0u,Bioinformatics - A Stack Exchange Proposal,https://www.reddit.com/r/MachineLearning/comments/68xr0u/bioinformatics_a_stack_exchange_proposal/,Emiller8800,1493779617,,0,1
95,2017-5-3,2017,5,3,12,68xu81,Aluminum foil printing machine/Aluminum foil rotogravure printing machin...,https://www.reddit.com/r/MachineLearning/comments/68xu81/aluminum_foil_printing_machinealuminum_foil/,Amanda-He,1493780693,,0,1
96,2017-5-3,2017,5,3,12,68xudk,Visual Attribute Transfer through Deep Image Analogy,https://www.reddit.com/r/MachineLearning/comments/68xudk/visual_attribute_transfer_through_deep_image/,[deleted],1493780753,[removed],0,1
97,2017-5-3,2017,5,3,12,68xv8d,Deep Image Analogy,https://www.reddit.com/r/MachineLearning/comments/68xv8d/deep_image_analogy/,[deleted],1493781037,[deleted],0,1
98,2017-5-3,2017,5,3,12,68xvki,"High Speed Tubes Line, Aluminum Collapsible Tubes Line, Aluminum Aerosol Cans Line Supplier China",https://www.reddit.com/r/MachineLearning/comments/68xvki/high_speed_tubes_line_aluminum_collapsible_tubes/,altubecan,1493781153,,1,1
99,2017-5-3,2017,5,3,12,68y020,3d food snacks papad &amp; sheet cereal pellet making machinery manufacturer,https://www.reddit.com/r/MachineLearning/comments/68y020/3d_food_snacks_papad_sheet_cereal_pellet_making/,DgSalome,1493782732,,0,1
100,2017-5-3,2017,5,3,12,68y0p1,Solventless Laminating machine/Solvent less laminating machine/ laminati...,https://www.reddit.com/r/MachineLearning/comments/68y0p1/solventless_laminating_machinesolvent_less/,Amanda-He,1493782953,,0,1
101,2017-5-3,2017,5,3,13,68y79v,XOR problem with keras,https://www.reddit.com/r/MachineLearning/comments/68y79v/xor_problem_with_keras/,215_215,1493785375,[removed],0,1
102,2017-5-3,2017,5,3,13,68y7bt,Deep Image Analogy,https://www.reddit.com/r/MachineLearning/comments/68y7bt/deep_image_analogy/,[deleted],1493785400,[deleted],0,1
103,2017-5-3,2017,5,3,13,68y7sr,[R] Deep Image Analogy,https://www.reddit.com/r/MachineLearning/comments/68y7sr/r_deep_image_analogy/,[deleted],1493785590,[deleted],0,1
104,2017-5-3,2017,5,3,13,68y8bb,[R] Deep Image Analogy,https://www.reddit.com/r/MachineLearning/comments/68y8bb/r_deep_image_analogy/,e_walker,1493785789,,112,1491
105,2017-5-3,2017,5,3,14,68yfdz,Changing input image size for inception network,https://www.reddit.com/r/MachineLearning/comments/68yfdz/changing_input_image_size_for_inception_network/,lvbu,1493788580,[removed],0,1
106,2017-5-3,2017,5,3,14,68ykz0,"Ryskamp Learning Machine, a breakthrough in ML",https://www.reddit.com/r/MachineLearning/comments/68ykz0/ryskamp_learning_machine_a_breakthrough_in_ml/,[deleted],1493791036,[removed],0,1
107,2017-5-3,2017,5,3,15,68ynen,[D] Market segmentation,https://www.reddit.com/r/MachineLearning/comments/68ynen/d_market_segmentation/,[deleted],1493792111,[deleted],1,0
108,2017-5-3,2017,5,3,15,68ynii,"[P] Ryskamp Learning Machine, a breakthrough in ML",https://www.reddit.com/r/MachineLearning/comments/68ynii/p_ryskamp_learning_machine_a_breakthrough_in_ml/,randolph_useaible,1493792163,"[Ryskamp Learning Machine (RLM)](http://useaible.com/code)

I just want to share our new project in hopes that you might be interested in trying out a new type of machine learning engine which totally redefines how ML works. We are breaking through the norms on ML in that our engine uses logical algorithms rather than a mathematical approach. Even without a GPU, the engine performs fast and is accurate in its results. To learn more about the other breakthroughs, please visit our site linked above. We also have head-to-head challenges with some popular ML engines such as Tensorflow and Encog to prove it and more challenges are currently in development.

For the source code, it is hosted in [Github](https://github.com/useaible/RyskampLearningMachine) and you will also find ample documentations on our github wiki pages. As an alternative, you can also get the RLM via [Nuget](https://www.nuget.org/packages/useAIble.RyskampLearningMachine/).

I would appreciate any feedback and would gladly assist anyone who wants to try it out.

Thank you",31,0
109,2017-5-3,2017,5,3,19,68zhgu,[D] Various ways of normalizing data,https://www.reddit.com/r/MachineLearning/comments/68zhgu/d_various_ways_of_normalizing_data/,chipcrazy,1493806856,,7,5
110,2017-5-3,2017,5,3,19,68zi5r,"[D] Modeling ""why X? because Y"" relations in ontologies",https://www.reddit.com/r/MachineLearning/comments/68zi5r/d_modeling_why_x_because_y_relations_in_ontologies/,[deleted],1493807152,[deleted],0,1
111,2017-5-3,2017,5,3,20,68zp0x,Learning to rank with Python scikit-learn,https://www.reddit.com/r/MachineLearning/comments/68zp0x/learning_to_rank_with_python_scikitlearn/,mottalrd,1493810183,,0,1
112,2017-5-3,2017,5,3,20,68zp2g,Agile Deep Learning For Modern Software Development,https://www.reddit.com/r/MachineLearning/comments/68zp2g/agile_deep_learning_for_modern_software/,teamrework,1493810199,,0,1
113,2017-5-3,2017,5,3,20,68zvp0,Are ICML tutorials/workshops worth it?,https://www.reddit.com/r/MachineLearning/comments/68zvp0/are_icml_tutorialsworkshops_worth_it/,[deleted],1493812752,[removed],0,1
114,2017-5-3,2017,5,3,21,6902x3,T-SNE perplexity,https://www.reddit.com/r/MachineLearning/comments/6902x3/tsne_perplexity/,Williamhenry94,1493815235,[removed],0,1
115,2017-5-3,2017,5,3,22,6907gk,Reading material on bet outcome prediction,https://www.reddit.com/r/MachineLearning/comments/6907gk/reading_material_on_bet_outcome_prediction/,xristos_forokolomvos,1493816703,[removed],0,1
116,2017-5-3,2017,5,3,22,6908zx,The End of Human Doctors  Understanding Automation,https://www.reddit.com/r/MachineLearning/comments/6908zx/the_end_of_human_doctors_understanding_automation/,[deleted],1493817195,[deleted],0,1
117,2017-5-3,2017,5,3,22,6909nr,[N] Talking Machines S03E01 - Ryan Adams' last episode and an interesting description of his personal experience in the field over the past 15 years,https://www.reddit.com/r/MachineLearning/comments/6909nr/n_talking_machines_s03e01_ryan_adams_last_episode/,HillbillyBoy,1493817396,,8,13
118,2017-5-3,2017,5,3,22,690b82,[D] The End of Human Doctors  Understanding Automation,https://www.reddit.com/r/MachineLearning/comments/690b82/d_the_end_of_human_doctors_understanding/,drlukeor,1493817863,,17,13
119,2017-5-3,2017,5,3,22,690bvf,What to look for in a data science + machine learning platform,https://www.reddit.com/r/MachineLearning/comments/690bvf/what_to_look_for_in_a_data_science_machine/,MajorDeeganz,1493818046,,0,1
120,2017-5-3,2017,5,3,22,690c5d,Is there any difference in representation between Tensorflow and Caffe's Image input to Conv nets ? HW / WH,https://www.reddit.com/r/MachineLearning/comments/690c5d/is_there_any_difference_in_representation_between/,[deleted],1493818137,[removed],0,1
121,2017-5-3,2017,5,3,22,690hnf,"[P] Implementation ""From Word Embeddings To Document Distances""",https://www.reddit.com/r/MachineLearning/comments/690hnf/p_implementation_from_word_embeddings_to_document/,3150,1493819812,,0,25
122,2017-5-3,2017,5,3,22,690hs0,How to mine newsfeed data and extract interactive insights in Python,https://www.reddit.com/r/MachineLearning/comments/690hs0/how_to_mine_newsfeed_data_and_extract_interactive/,ahmedbesbes,1493819850,,0,1
123,2017-5-3,2017,5,3,23,690ixs,[D] Google Brain residency requirements and interview,https://www.reddit.com/r/MachineLearning/comments/690ixs/d_google_brain_residency_requirements_and/,ppd2,1493820193,"I believe the recruitment for this year's [Google Brain Residency](https://research.google.com/teams/brain/residency/) program has finished now, and I'd love to hear from those who applied and took the interview.

In particular, the requirements on the website are extremely vague (they literally just say that they want people with some experience in STEM who are ""motivated to learn""), and apparently they even provide introductory deep learning classes, so it seems like you don't need to have a lot of experience. On the other hand, all the advice I've seen on Reddit, Hacker News, etc. seems to indicate that significant experience in machine learning is pretty much the first thing they're looking for.

So I'm curious: what do they test for during the interview? What (in your view) do they actually require?",19,99
124,2017-5-4,2017,5,4,0,690ymu,Would I need a GPU for just testing/researching new models?(Research and scaling),https://www.reddit.com/r/MachineLearning/comments/690ymu/would_i_need_a_gpu_for_just_testingresearching/,[deleted],1493824632,[removed],0,1
125,2017-5-4,2017,5,4,0,690zxy,[R] Best machine learning model for time series classification,https://www.reddit.com/r/MachineLearning/comments/690zxy/r_best_machine_learning_model_for_time_series/,ProjectPsygma,1493824993,"Hi r/MachineLearning,

I am currently perfuming some research into building a machine learning model to classify time series data. The data in question is recordings of the inductive frequency and mass of different objects every 0.1 seconds over 3 seconds, totalling at 30 rows of data per sample.

I am interested in Reddit's opinion on this; what is the most established machine learning models for classifying time series of this nature.

Thanks!

Edit: I have read a few sources that suggest Hidden Markov and Dynamic Time Warping are decent models for tackling this problem.

",9,3
126,2017-5-4,2017,5,4,0,691589,[D] How to Prevent Overfitting,https://www.reddit.com/r/MachineLearning/comments/691589/d_how_to_prevent_overfitting/,naturalespresso,1493826429,,3,2
127,2017-5-4,2017,5,4,0,6916ly,"Simple Questions Thread May 03, 2017",https://www.reddit.com/r/MachineLearning/comments/6916ly/simple_questions_thread_may_03_2017/,AutoModerator,1493826796,[removed],0,1
128,2017-5-4,2017,5,4,0,6916tw,MKR AUTOMATIONS,https://www.reddit.com/r/MachineLearning/comments/6916tw/mkr_automations/,thanvi123,1493826855,,6,1
129,2017-5-4,2017,5,4,1,691dg1,[D] Do i need GPU for research as well?(not training),https://www.reddit.com/r/MachineLearning/comments/691dg1/d_do_i_need_gpu_for_research_as_wellnot_training/,[deleted],1493828542,[deleted],8,2
130,2017-5-4,2017,5,4,1,691ef0,"[R] ""A Tutorial on Fisher Information"", Ly et al 2017",https://www.reddit.com/r/MachineLearning/comments/691ef0/r_a_tutorial_on_fisher_information_ly_et_al_2017/,gwern,1493828790,,0,29
131,2017-5-4,2017,5,4,1,691f0k,[R] Code for image face swapping and deep models for face segmentation,https://www.reddit.com/r/MachineLearning/comments/691f0k/r_code_for_image_face_swapping_and_deep_models/,hoodcrow,1493828948,,0,2
132,2017-5-4,2017,5,4,1,691hfp,"[D] For machine learning applications, what is the advantage of storing data as a nominal category variable vs dummy variables?",https://www.reddit.com/r/MachineLearning/comments/691hfp/d_for_machine_learning_applications_what_is_the/,dddenham,1493829570,"For machine learning applications, what is the advantage of storing data as a nominal category variable vs dummy variables?

For example let's say you have a variable ""Color"" with possible values ""Red"", ""Blue"", ""Green"". Is there practically any difference (again for machine learning purposes) between storing this as:

**Color**  
Red  
Green  
Green  
&amp;nbsp;  
vs  
&amp;nbsp;  

**Color_R,Color_B,Color_G**  
1,0,0  
0,0,1  
0,0,1    
&amp;nbsp;

Is the only advantage that you can use it for things like linear regression which can't parse non-numeric variables?",12,4
133,2017-5-4,2017,5,4,1,691lok,Metropolis Hastings algorithm - a python primer,https://www.reddit.com/r/MachineLearning/comments/691lok/metropolis_hastings_algorithm_a_python_primer/,napsternxg,1493830655,,0,1
134,2017-5-4,2017,5,4,2,691o47,[D] Setting up personal linux box+GPU?,https://www.reddit.com/r/MachineLearning/comments/691o47/d_setting_up_personal_linux_boxgpu/,RSchaeffer,1493831273,"Does anyone have any experience with buying and setting up a GPU-equipped linux box for training neural networks? I've been using AWS, but I just got hit with the bill and I think it might be prudent to consider long-term alternatives.",9,6
135,2017-5-4,2017,5,4,2,691pbe,Neural Style Transfer,https://www.reddit.com/r/MachineLearning/comments/691pbe/neural_style_transfer/,yashkatariya,1493831564,,0,1
136,2017-5-4,2017,5,4,3,6921ad,"[R] 3 Million Instacart Orders, Open Sourced",https://www.reddit.com/r/MachineLearning/comments/6921ad/r_3_million_instacart_orders_open_sourced/,jeremy_stanley,1493834642,,8,8
137,2017-5-4,2017,5,4,3,6923t3,"When learning Style Transfer, I got some generated negative pixel values. How can i to handle those?",https://www.reddit.com/r/MachineLearning/comments/6923t3/when_learning_style_transfer_i_got_some_generated/,dovetuna,1493835313,[removed],0,1
138,2017-5-4,2017,5,4,3,69250l,Handling Large Number of Neurons per Layer?,https://www.reddit.com/r/MachineLearning/comments/69250l/handling_large_number_of_neurons_per_layer/,kerego,1493835632,[removed],0,1
139,2017-5-4,2017,5,4,3,69268e,"[N] Peter Norvig on ""As We May Program""",https://www.reddit.com/r/MachineLearning/comments/69268e/n_peter_norvig_on_as_we_may_program/,abstractcontrol,1493835941,,3,14
140,2017-5-4,2017,5,4,3,692da9,[P] Another redditor's project analyzing player data in Rocket League,https://www.reddit.com/r/MachineLearning/comments/692da9/p_another_redditors_project_analyzing_player_data/,trashacount12345,1493837788,https://np.reddit.com/r/RocketLeague/comments/692byr/analyzing_professional_rocket_league_play_styles/,1,11
141,2017-5-4,2017,5,4,4,692r67,Paperspace launches GPU-powered virtual machines loaded with tools for data scientists,https://www.reddit.com/r/MachineLearning/comments/692r67/paperspace_launches_gpupowered_virtual_machines/,[deleted],1493841462,[deleted],0,1
142,2017-5-4,2017,5,4,4,692rlx,[N] PhD-Summer Course- Jun 5-9 2017 Machine Learning: A Computational Intelligence Approach,https://www.reddit.com/r/MachineLearning/comments/692rlx/n_phdsummer_course_jun_59_2017_machine_learning_a/,nocortex,1493841591,,0,3
143,2017-5-4,2017,5,4,5,6933zo,Data Science Digest - Issue #7,https://www.reddit.com/r/MachineLearning/comments/6933zo/data_science_digest_issue_7/,flyelephant,1493844790,,0,1
144,2017-5-4,2017,5,4,6,6936g5,[D] Adversarial training to improve image search.,https://www.reddit.com/r/MachineLearning/comments/6936g5/d_adversarial_training_to_improve_image_search/,thisBeAFakeThrowaway,1493845440,"I was recently talking to a colleague who mentioned they'd come across some work by Google engineers to improve image search robustness towards adversarial examples by themselves adversarially training networks using adversarial image examples.

Does anybody know about this body of work? I'm curious about how this would work. My colleague isn't sure where they saw this, and searching the interwebz does not return anything relevant.",4,6
145,2017-5-4,2017,5,4,6,693ehs,Where is the best place to study AI in Germany ?,https://www.reddit.com/r/MachineLearning/comments/693ehs/where_is_the_best_place_to_study_ai_in_germany/,soyDonEladio,1493847647,[removed],0,1
146,2017-5-4,2017,5,4,8,6943ms,Benchmarks | TensorFlow,https://www.reddit.com/r/MachineLearning/comments/6943ms/benchmarks_tensorflow/,ppwwyyxx,1493855227,,0,1
147,2017-5-4,2017,5,4,8,6945gf,[P] Ethical imperatives in AI and generative art,https://www.reddit.com/r/MachineLearning/comments/6945gf/p_ethical_imperatives_in_ai_and_generative_art/,pmigdal,1493855791,,0,3
148,2017-5-4,2017,5,4,9,6948qs,[P] Guide to Neural Networks in Python and SciKit Learn,https://www.reddit.com/r/MachineLearning/comments/6948qs/p_guide_to_neural_networks_in_python_and_scikit/,amitjyothie,1493856799,,2,56
149,2017-5-4,2017,5,4,11,6951wd,"Gabor Convulational Networks (Better performance than standard CNNs, Spatial transformer networks on MNIST-rot and SVHN for similar model size)",https://www.reddit.com/r/MachineLearning/comments/6951wd/gabor_convulational_networks_better_performance/,mind_juice,1493866375,,0,1
150,2017-5-4,2017,5,4,12,695516,[D] Hyper parameter tuning in CNNs,https://www.reddit.com/r/MachineLearning/comments/695516/d_hyper_parameter_tuning_in_cnns/,jshin49,1493867471,"Hi all!

I am new to Reddit and this subreddit of course, so if I am wrong with any community standards, please let me know.

So I've been working on the Kaggle Cat vs Dog challenge simply for fun, but I have been encountering no improvement whatsoever in my classifier. (https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition)

The following is what I implemented with TensorFlow (https://github.com/jshin49/cnn-cats-vs-dogs/tree/no_keras) based on this kernel in Kaggle (https://www.kaggle.com/jeffd23/dogs-vs-cats-redux-kernels-edition/catdognet-keras-convnet-starter/notebook)

I was just wondering if someone could point me out if I did anything wrong here.

Thanks!

",3,0
151,2017-5-4,2017,5,4,13,695d2z,Getting into Machine Learning!,https://www.reddit.com/r/MachineLearning/comments/695d2z/getting_into_machine_learning/,[deleted],1493870510,[removed],0,1
152,2017-5-4,2017,5,4,13,695j78,[P] Mapillary Vistas Dataset - Street-level Imagery Dataset for Teaching Machines to See,https://www.reddit.com/r/MachineLearning/comments/695j78/p_mapillary_vistas_dataset_streetlevel_imagery/,Dim25,1493872976,,0,7
153,2017-5-4,2017,5,4,13,695jks,[R][1705.00744] A Strategy for an Uncompromising Incremental Learner,https://www.reddit.com/r/MachineLearning/comments/695jks/r170500744_a_strategy_for_an_uncompromising/,[deleted],1493873131,[deleted],0,1
154,2017-5-4,2017,5,4,13,695jqu,[R] A Strategy for an Uncompromising Incremental Learner,https://www.reddit.com/r/MachineLearning/comments/695jqu/r_a_strategy_for_an_uncompromising_incremental/,procarastinizer,1493873194,,4,9
155,2017-5-4,2017,5,4,14,695lvu,Blogging platforms,https://www.reddit.com/r/MachineLearning/comments/695lvu/blogging_platforms/,MetricSpade007,1493874118,[removed],0,1
156,2017-5-4,2017,5,4,14,695lyc,[D] Blogging platforms,https://www.reddit.com/r/MachineLearning/comments/695lyc/d_blogging_platforms/,MetricSpade007,1493874145,"Do people recommend using Medium, Github Pages, Wordpress, Blogger, or something else for blogging about ML (or anything else)?

I've seen people using different styles, and I'm wondering if there's one style that people prefer, and what the pros/cons are that people have found?
",8,3
157,2017-5-4,2017,5,4,14,695rbg,Why many recent papers used Uniform noise instead of Gaussian noise as input to the generator?,https://www.reddit.com/r/MachineLearning/comments/695rbg/why_many_recent_papers_used_uniform_noise_instead/,willtwr,1493876521,[removed],0,1
158,2017-5-4,2017,5,4,15,695xl9,Could one use a NN to tune a color space conversion,https://www.reddit.com/r/MachineLearning/comments/695xl9/could_one_use_a_nn_to_tune_a_color_space/,jayakumar2,1493880159,[removed],0,1
159,2017-5-4,2017,5,4,15,695z8c,A Machine That Moves Trees So You Don't Have To Cut Them,https://www.reddit.com/r/MachineLearning/comments/695z8c/a_machine_that_moves_trees_so_you_dont_have_to/,[deleted],1493880972,[deleted],0,1
160,2017-5-4,2017,5,4,17,6969id,German Traffic Sign Recognition Benchmark: Classification using Python,https://www.reddit.com/r/MachineLearning/comments/6969id/german_traffic_sign_recognition_benchmark/,shravankumar147,1493885972,,0,1
161,2017-5-4,2017,5,4,18,696dzy,[D] Is Tensorflow the fastest deep learning library now?,https://www.reddit.com/r/MachineLearning/comments/696dzy/d_is_tensorflow_the_fastest_deep_learning_library/,feedthecreed,1493888401,,39,36
162,2017-5-4,2017,5,4,18,696e9x,3D convnets for lung cancer malignancy estimation (2nd place datascience bowl),https://www.reddit.com/r/MachineLearning/comments/696e9x/3d_convnets_for_lung_cancer_malignancy_estimation/,[deleted],1493888523,[deleted],0,1
163,2017-5-4,2017,5,4,18,696fp5,What are the prerequisites to learn deep learning?,https://www.reddit.com/r/MachineLearning/comments/696fp5/what_are_the_prerequisites_to_learn_deep_learning/,roseindianet,1493889178,,0,1
164,2017-5-4,2017,5,4,18,696fwp,3D convnets for lung cancer malignancy estimation (2nd place national datascience bowl),https://www.reddit.com/r/MachineLearning/comments/696fwp/3d_convnets_for_lung_cancer_malignancy_estimation/,[deleted],1493889280,[deleted],0,1
165,2017-5-4,2017,5,4,19,696mrz,Bringing Machine Learning to the Vacation Rental Industry,https://www.reddit.com/r/MachineLearning/comments/696mrz/bringing_machine_learning_to_the_vacation_rental/,czuriaga,1493892673,,0,1
166,2017-5-4,2017,5,4,21,6976vv,[P] Text Classification server using Tensorflow,https://www.reddit.com/r/MachineLearning/comments/6976vv/p_text_classification_server_using_tensorflow/,KangCepot,1493900891,"Hi. 

I am learning machine learning since few months, and created my first project for text classification. I call it Open Text Classification (OpenTC), it is a server for text classification using scikit-learn (for Bayes and SVM algorithms) and  Tensorflow (for CNN). The aim of this project is to have a generic text classification server that can be used for difference purposes (depend on the trained data), either as Data Leak Prevention (for this purpose, I created also ICAP server that can be used with http proxy such as squid for content filtering), or as spam scanner for spamassassin in addition to the default Bayes classifier.

The main project is hosted in Github: https://github.com/cahya-wirawan/opentc
The ICAP server: https://github.com/cahya-wirawan/opentc-icap
And the demo website of the project: http://opentc.oldjava.org/demo/

I would be very grateful for any feedback or suggestion. 
Thanks.
",2,3
167,2017-5-4,2017,5,4,21,6977tw,Wasserstein GAN and Improved Wasserstein GAN explained [slides],https://www.reddit.com/r/MachineLearning/comments/6977tw/wasserstein_gan_and_improved_wasserstein_gan/,[deleted],1493901245,[deleted],0,1
168,2017-5-4,2017,5,4,21,697aut,[P]3D convnets for lung cancer estimation (2nd place national datascience bowl),https://www.reddit.com/r/MachineLearning/comments/697aut/p3d_convnets_for_lung_cancer_estimation_2nd_place/,juliandewit,1493902285,,15,114
169,2017-5-4,2017,5,4,22,697fds,"The ""importance"" of Image Captioning for Cross-domain adaptation",https://www.reddit.com/r/MachineLearning/comments/697fds/the_importance_of_image_captioning_for/,andrewliao11,1493903780,[removed],0,1
170,2017-5-4,2017,5,4,22,697ham,[P] Exploring what a Convolutional Neural Network learns,https://www.reddit.com/r/MachineLearning/comments/697ham/p_exploring_what_a_convolutional_neural_network/,rruizen,1493904416,,1,0
171,2017-5-4,2017,5,4,23,697t1f,Blogs and sites about Machine Learning,https://www.reddit.com/r/MachineLearning/comments/697t1f/blogs_and_sites_about_machine_learning/,tasubo,1493907902,[removed],0,2
172,2017-5-4,2017,5,4,23,697utt,[R] Is Maximum Likelihood Useful for Representation Learning? tldr: You can get arbitrarily good likelihood and arbitrarily poor representation.,https://www.reddit.com/r/MachineLearning/comments/697utt/r_is_maximum_likelihood_useful_for_representation/,fhuszar,1493908396,,39,42
173,2017-5-4,2017,5,4,23,697vvs,"Q&amp;A sites and data science forums are buzzing with the same questions over and over again: Im new in data science, what language should I learn? Whats the best language for machine learning?",https://www.reddit.com/r/MachineLearning/comments/697vvs/qa_sites_and_data_science_forums_are_buzzing_with/,vjmde,1493908714,,0,1
174,2017-5-4,2017,5,4,23,697yxa,Practical Machine Learning With Event Streaming,https://www.reddit.com/r/MachineLearning/comments/697yxa/practical_machine_learning_with_event_streaming/,trstnthms,1493909574,,0,3
175,2017-5-5,2017,5,5,0,69832x,[D] Why Does BEGAN Produce Far Better Images than WGAN?,https://www.reddit.com/r/MachineLearning/comments/69832x/d_why_does_began_produce_far_better_images_than/,nickshahml,1493910704,"I'm trying to understand why [BEGAN](https://arxiv.org/pdf/1703.10717.pdf) produces better images than the Improved [WGAN](https://arxiv.org/pdf/1704.00028.pdf). 

Both claim to be optimizing the wassertsein distance, though I know there has been some debate about it. It looks like BEGAN optimizes the wasserstein distance between loss distributions whereas the Improved WGAN optimizes between sample distributions. From a theory standpoint, shouldn't WGAN produce the same quality images as BEGAN?

I feel however, that there must be some tradeoff. Is WGAN more stable? Does BEGAN suffer from mode collapse more easily? And what is the future direction of these two approaches? Big questions but just wanted to see if there was any clear explanation to this discrepancy. ",4,14
176,2017-5-5,2017,5,5,0,6983t4,[D] Machine learning build review,https://www.reddit.com/r/MachineLearning/comments/6983t4/d_machine_learning_build_review/,Freyon,1493910895,"Hello everyone, I am trying to build a PC to do research work on Machine Learning applied to computer vision (I'll soon start my Ph.D.). 

I got some freedom from my advisor to build my rig, and my idea is to start with the list below, then add another GTX 1080 and more RAM if needed.

What do you guys think about the build and the possibility for future improvement?

Thanks in advance (the prices listed are for Italy, I cry every time I have to switch the prices list from the United States).

[PCPartPicker part list](https://it.pcpartpicker.com/list/N3Pnqk) / [Price breakdown by merchant](https://it.pcpartpicker.com/list/N3Pnqk/by_merchant/)

Type|Item|Price
:----|:----|:----
**CPU** | [Intel Core i7-6700K 4.0GHz Quad-Core Processor](https://it.pcpartpicker.com/product/tdmxFT/intel-cpu-bx80662i76700k) | 310.00 
**CPU Cooler** | [Cooler Master Hyper 212 EVO 82.9 CFM Sleeve Bearing CPU Cooler](https://it.pcpartpicker.com/product/hmtCmG/cooler-master-cpu-cooler-rr212e20pkr2) | 35.00 
**Motherboard** | [MSI Z170A GAMING M7 ATX LGA1151 Motherboard](https://it.pcpartpicker.com/product/3n7CmG/msi-motherboard-z170agamingm7) | 180.00 
**Memory** | [Corsair Vengeance LPX 16GB (2 x 8GB) DDR4-3000 Memory](https://it.pcpartpicker.com/product/MYH48d/corsair-memory-cmk16gx4m2b3000c15) | 130.00 
**Storage** | [Samsung 850 EVO 500GB M.2-2280 Solid State Drive](https://it.pcpartpicker.com/product/VrH48d/samsung-internal-hard-drive-mzn5e500bw) | 160.00 
**Video Card** | [MSI GeForce GTX 1080 8GB GAMING X 8G Video Card](https://it.pcpartpicker.com/product/XC648d/msi-video-card-gtx1080gamingx8g) | 540.00 
**Case** | [Corsair Air 540 ATX Mid Tower Case](https://it.pcpartpicker.com/product/wgkD4D/corsair-case-air540) | 155.00 
**Power Supply** | [Corsair 850W 80+ Bronze Certified Semi-Modular ATX Power Supply](https://it.pcpartpicker.com/product/wqkwrH/corsair-power-supply-cp9020099na) | 100.00 
**Monitor** | [BenQ GL2460HM 24.0"" 1920x1080 60Hz Monitor](https://it.pcpartpicker.com/product/mWV48d/benq-monitor-gl2460hm) | 130.00 
 | *Prices include shipping, taxes, rebates, and discounts* |
 | **Total** | **1740.00**
 | Generated by [PCPartPicker](http://pcpartpicker.com) 2017-05-04 17:05 CEST+0200 |",13,5
177,2017-5-5,2017,5,5,0,6987sh,High-Performance Models in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/6987sh/highperformance_models_in_tensorflow/,figurelover,1493911967,,0,1
178,2017-5-5,2017,5,5,0,698cj2,[P] Data Version Control for Iterative Machine Learning - track ML processes and file dependencies using git-like commands,https://www.reddit.com/r/MachineLearning/comments/698cj2/p_data_version_control_for_iterative_machine/,thumbsdrivesmecrazy,1493913249,,6,38
179,2017-5-5,2017,5,5,1,698gox,How the TensorFlow team handles open source support,https://www.reddit.com/r/MachineLearning/comments/698gox/how_the_tensorflow_team_handles_open_source/,petewarden,1493914334,,0,1
180,2017-5-5,2017,5,5,1,698iic,Do I have a chance @ ML?,https://www.reddit.com/r/MachineLearning/comments/698iic/do_i_have_a_chance_ml/,[deleted],1493914814,[removed],0,1
181,2017-5-5,2017,5,5,1,698ins,[D] DrugAI-GAN.py: Experiments with GAN for drug like molecule generation,https://www.reddit.com/r/MachineLearning/comments/698ins/d_drugaiganpy_experiments_with_gan_for_drug_like/,gananath,1493914846,,5,5
182,2017-5-5,2017,5,5,1,698l10,Source needed: data+model-&gt;output vs. data+output-&gt;model,https://www.reddit.com/r/MachineLearning/comments/698l10/source_needed_datamodeloutput_vs_dataoutputmodel/,doktorfaustus91,1493915450,[removed],0,1
183,2017-5-5,2017,5,5,1,698n61,[1705.01462] Ternary Neural Networks with Fine-Grained Quantization,https://www.reddit.com/r/MachineLearning/comments/698n61/170501462_ternary_neural_networks_with/,[deleted],1493915993,[deleted],0,1
184,2017-5-5,2017,5,5,2,698sw9,[D] Transfer learning from observational data to causal inference,https://www.reddit.com/r/MachineLearning/comments/698sw9/d_transfer_learning_from_observational_data_to/,[deleted],1493917472,[deleted],2,6
185,2017-5-5,2017,5,5,2,6992fo,How to take the output of one model as the input of another one in Tensorflow?,https://www.reddit.com/r/MachineLearning/comments/6992fo/how_to_take_the_output_of_one_model_as_the_input/,yobichi,1493919931,[removed],0,1
186,2017-5-5,2017,5,5,4,699lzv,[D] What are people using for point cloud annotation?,https://www.reddit.com/r/MachineLearning/comments/699lzv/d_what_are_people_using_for_point_cloud_annotation/,Fuck_the_police,1493924923,"I've found myself in the lovely position of having to annotate a good number of large point clouds. I'm currently classifying points using QTM, but I am not too happy with the interface. Does anyone else who has done this before have recommendations for software?",0,1
187,2017-5-5,2017,5,5,4,699mi8,"[D] Fb introduces Parl.AI, a framework for training and evaluating AI models on a variety of openly available dialog datasets",https://www.reddit.com/r/MachineLearning/comments/699mi8/d_fb_introduces_parlai_a_framework_for_training/,evc123,1493925058,,15,89
188,2017-5-5,2017,5,5,4,699nid,"Every single Machine Learning course on the internet, ranked by your reviews",https://www.reddit.com/r/MachineLearning/comments/699nid/every_single_machine_learning_course_on_the/,SpaceSword,1493925317,,0,1
189,2017-5-5,2017,5,5,5,699zvk,Questions about Image to Image networks,https://www.reddit.com/r/MachineLearning/comments/699zvk/questions_about_image_to_image_networks/,automated_reckoning,1493928542,[removed],0,1
190,2017-5-5,2017,5,5,5,69a8f0,Public code for Face Segmentation &amp; Face Swapping in-the-wild,https://www.reddit.com/r/MachineLearning/comments/69a8f0/public_code_for_face_segmentation_face_swapping/,anhttran,1493930823,,1,2
191,2017-5-5,2017,5,5,6,69ae7i,[R] Generalize average and bilinear pooling to alpha pooling,https://www.reddit.com/r/MachineLearning/comments/69ae7i/r_generalize_average_and_bilinear_pooling_to/,MarcelSimon,1493932397,,0,4
192,2017-5-5,2017,5,5,9,69be3b,Is there a way to speed up meanshift?,https://www.reddit.com/r/MachineLearning/comments/69be3b/is_there_a_way_to_speed_up_meanshift/,taewoo,1493943175,[removed],0,1
193,2017-5-5,2017,5,5,10,69boh8,[D] Would NIPS be great for an undergraduate student?,https://www.reddit.com/r/MachineLearning/comments/69boh8/d_would_nips_be_great_for_an_undergraduate_student/,[deleted],1493946510,[deleted],4,0
194,2017-5-5,2017,5,5,11,69c4o9,My friend made a video for Generative Adversarial Networks for Style Transfer,https://www.reddit.com/r/MachineLearning/comments/69c4o9/my_friend_made_a_video_for_generative_adversarial/,Legacy_of_Karui,1493951979,,0,1
195,2017-5-5,2017,5,5,12,69ce9v,[D] Benchmarks for Few-Shot Learning in Image Classification,https://www.reddit.com/r/MachineLearning/comments/69ce9v/d_benchmarks_for_fewshot_learning_in_image/,2014mchidamb,1493955415,"What is the state of the art for image classification with ""pure"" few-shot learning? Essentially, I'm looking for work on the following problem: given a few images (or just one) of several image classes as training data, classify a test set. It seems to me that recent work in few-shot learning (i.e. matching networks) is more interested in the problem of learning similarity metrics. For example, in the matching networks setting, there is a given support set provided with each test example that is used for assisting with labeling. ",8,14
196,2017-5-5,2017,5,5,15,69d1tp,[P] Tensorflow Resources,https://www.reddit.com/r/MachineLearning/comments/69d1tp/p_tensorflow_resources/,chipcrazy,1493965294,,15,87
197,2017-5-5,2017,5,5,15,69d35u,Seldon Core v1.4.4 released with Kubernetes Deployments and Cloud SQL support,https://www.reddit.com/r/MachineLearning/comments/69d35u/seldon_core_v144_released_with_kubernetes/,[deleted],1493965953,[deleted],0,1
198,2017-5-5,2017,5,5,15,69d3pj,Can I skip most of ML and just focus on Neural Networks?,https://www.reddit.com/r/MachineLearning/comments/69d3pj/can_i_skip_most_of_ml_and_just_focus_on_neural/,[deleted],1493966209,[removed],0,1
199,2017-5-5,2017,5,5,15,69d4he,[P] Seldon Core v1.4.4 released with Kubernetes Deployments and Cloud SQL support,https://www.reddit.com/r/MachineLearning/comments/69d4he/p_seldon_core_v144_released_with_kubernetes/,ahousley,1493966571,,0,1
200,2017-5-5,2017,5,5,17,69dfr3,Grad school (Masters) for ML - yay or nay ?,https://www.reddit.com/r/MachineLearning/comments/69dfr3/grad_school_masters_for_ml_yay_or_nay/,marcus21throw,1493972267,[removed],0,1
201,2017-5-5,2017,5,5,17,69dge8,[R] Does Computational Complexity Restrict Artificial Intelligence (AI) and Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/69dge8/r_does_computational_complexity_restrict/,downtownslim,1493972617,,16,28
202,2017-5-5,2017,5,5,17,69djf4,[R] Unbiased Look at Dataset Bias,https://www.reddit.com/r/MachineLearning/comments/69djf4/r_unbiased_look_at_dataset_bias/,tryndisskilled,1493974262,,4,8
203,2017-5-5,2017,5,5,18,69dkip,Weaving Human-Computer Interaction Into the Fabric of Robotics,https://www.reddit.com/r/MachineLearning/comments/69dkip/weaving_humancomputer_interaction_into_the_fabric/,teamrework,1493974823,,0,1
204,2017-5-5,2017,5,5,18,69dlye,my thoughts about internet trends in last 3 months,https://www.reddit.com/r/MachineLearning/comments/69dlye/my_thoughts_about_internet_trends_in_last_3_months/,mutiev,1493975502,,0,1
205,2017-5-5,2017,5,5,18,69dphe,Simulate streaming financial data,https://www.reddit.com/r/MachineLearning/comments/69dphe/simulate_streaming_financial_data/,[deleted],1493977244,[removed],0,1
206,2017-5-5,2017,5,5,19,69dtcy,"R is 4th most popular ML language after Python, C/C++, Java",https://www.reddit.com/r/MachineLearning/comments/69dtcy/r_is_4th_most_popular_ml_language_after_python_cc/,MatosKap,1493979126,,0,1
207,2017-5-5,2017,5,5,19,69dwew,Help needed for learning,https://www.reddit.com/r/MachineLearning/comments/69dwew/help_needed_for_learning/,Alexgil45,1493980521,[removed],0,1
208,2017-5-5,2017,5,5,19,69dxc4,Do startups based on AI and ML create their own algorithms or use existing?,https://www.reddit.com/r/MachineLearning/comments/69dxc4/do_startups_based_on_ai_and_ml_create_their_own/,rjk10892,1493980982,[removed],0,1
209,2017-5-5,2017,5,5,20,69e24r,Plants and equipment used in highway construction,https://www.reddit.com/r/MachineLearning/comments/69e24r/plants_and_equipment_used_in_highway_construction/,infrabazaar,1493983131,,0,1
210,2017-5-5,2017,5,5,20,69e4zd,Automatic High Quality Big Row Ham Sausage Fish Meat Slicing Chopping Ma...,https://www.reddit.com/r/MachineLearning/comments/69e4zd/automatic_high_quality_big_row_ham_sausage_fish/,Elaine2008,1493984259,,0,1
211,2017-5-6,2017,5,6,0,69f73y,[P] Source code available for Deformable ConvNets from MSRA,https://www.reddit.com/r/MachineLearning/comments/69f73y/p_source_code_available_for_deformable_convnets/,flyforlight,1493996517,,7,48
212,2017-5-6,2017,5,6,0,69fe4f,Advise on how to prep for research,https://www.reddit.com/r/MachineLearning/comments/69fe4f/advise_on_how_to_prep_for_research/,krishamehta,1493998437,[removed],0,1
213,2017-5-6,2017,5,6,0,69feme,Artificial Intelligence Knowledge Management Solution by 3di,https://www.reddit.com/r/MachineLearning/comments/69feme/artificial_intelligence_knowledge_management/,agata_mos,1493998569,,0,1
214,2017-5-6,2017,5,6,1,69flfd,Dynamics of Neural Networks,https://www.reddit.com/r/MachineLearning/comments/69flfd/dynamics_of_neural_networks/,rajarsheem,1494000417,,0,1
215,2017-5-6,2017,5,6,1,69frn0,[R] Temporal Tessellation: A Unified Approach for Video Analysis (New Act. Recog. Results + Greatest Hits!),https://www.reddit.com/r/MachineLearning/comments/69frn0/r_temporal_tessellation_a_unified_approach_for/,lioru,1494002121,,0,47
216,2017-5-6,2017,5,6,1,69fw6c,Any .net LSTM/GRU library?,https://www.reddit.com/r/MachineLearning/comments/69fw6c/any_net_lstmgru_library/,piastrina,1494003394,[removed],0,1
217,2017-5-6,2017,5,6,3,69gd5z,"[R] Is it a ghost? Nah, it's just a recommender system that uses AI, ML and data science",https://www.reddit.com/r/MachineLearning/comments/69gd5z/r_is_it_a_ghost_nah_its_just_a_recommender_system/,snatchkite,1494007994,,3,0
218,2017-5-6,2017,5,6,4,69gwd8,Advanced Machine Learning with Basic Excel,https://www.reddit.com/r/MachineLearning/comments/69gwd8/advanced_machine_learning_with_basic_excel/,pmz,1494013723,,0,1
219,2017-5-6,2017,5,6,4,69gx4u,[D] Video classification on a CPU,https://www.reddit.com/r/MachineLearning/comments/69gx4u/d_video_classification_on_a_cpu/,Faizann24,1494013953,"Hi, 

what is the best way to classify videos on a CPU. I want to include the temporal features as well, so I cannot just use CNNs with 2D images.

My RAM is 8gb and with i7 processor.",4,0
220,2017-5-6,2017,5,6,4,69gxqs,How is Tensor Decomposition (Factorization) related to Topological Data Analysis?,https://www.reddit.com/r/MachineLearning/comments/69gxqs/how_is_tensor_decomposition_factorization_related/,datavis,1494014131,[removed],0,1
221,2017-5-6,2017,5,6,5,69hawj,[1705.01450] [R] Gabor Convolutional Networks,https://www.reddit.com/r/MachineLearning/comments/69hawj/170501450_r_gabor_convolutional_networks/,darkconfidantislife,1494017866,,13,13
222,2017-5-6,2017,5,6,6,69he57,Desktop gaming PC for deep learning,https://www.reddit.com/r/MachineLearning/comments/69he57/desktop_gaming_pc_for_deep_learning/,Srowshan,1494018817,[removed],0,1
223,2017-5-6,2017,5,6,6,69hgow,CLI to help track work in machine learning projects,https://www.reddit.com/r/MachineLearning/comments/69hgow/cli_to_help_track_work_in_machine_learning/,[deleted],1494019624,[deleted],0,1
224,2017-5-6,2017,5,6,7,69hqns,[P] Tracking and reproducibility in data projects (CLI tool),https://www.reddit.com/r/MachineLearning/comments/69hqns/p_tracking_and_reproducibility_in_data_projects/,datmo_io,1494022673,,2,2
225,2017-5-6,2017,5,6,7,69hrk0,[P] Shazam: Moving GPUs to Google Cloud,https://www.reddit.com/r/MachineLearning/comments/69hrk0/p_shazam_moving_gpus_to_google_cloud/,fhoffa,1494022944,,11,119
226,2017-5-6,2017,5,6,9,69ij66,PVC Gloves Production Line,https://www.reddit.com/r/MachineLearning/comments/69ij66/pvc_gloves_production_line/,gloveequipment,1494032295,[removed],0,1
227,2017-5-6,2017,5,6,10,69im4h,Latex Gloves Production Line,https://www.reddit.com/r/MachineLearning/comments/69im4h/latex_gloves_production_line/,gloveequipment,1494033329,[removed],0,1
228,2017-5-6,2017,5,6,10,69iqfv,Nitrile Gloves Production Line,https://www.reddit.com/r/MachineLearning/comments/69iqfv/nitrile_gloves_production_line/,gloveequipment,1494034931,[removed],0,1
229,2017-5-6,2017,5,6,12,69j4dz,"Can CUDA, Tensorflow address SLI GPU? = Double Memory?",https://www.reddit.com/r/MachineLearning/comments/69j4dz/can_cuda_tensorflow_address_sli_gpu_double_memory/,supermanava,1494040365,[removed],0,1
230,2017-5-6,2017,5,6,12,69j75v,What are some good resources for doing image queries that return a lot of classified images? (X post from /r/askcomputerscience,https://www.reddit.com/r/MachineLearning/comments/69j75v/what_are_some_good_resources_for_doing_image/,[deleted],1494041447,[removed],0,1
231,2017-5-6,2017,5,6,12,69j8pw,[P] is there any good free resources that allows you to search images by generic tags that returns large amounts of images associated with the query tags?,https://www.reddit.com/r/MachineLearning/comments/69j8pw/p_is_there_any_good_free_resources_that_allows/,redditpirateroberts,1494042112,"Are there any good apis or other free resources that allow me to search generic tags like ""car"" or ""highway"" and return a lot of images with said objects in them. I was planning to use google image search but it limits the number one of things shown to you for a given query, and for good machine learning we need a lot of training data. 


This is a common kind of task in machine learning and computer vision so I'm hoping some good open source data exists! ",9,2
232,2017-5-6,2017,5,6,13,69jeju,The AI revolution is making game characters move more realistically,https://www.reddit.com/r/MachineLearning/comments/69jeju/the_ai_revolution_is_making_game_characters_move/,MisterNine42,1494044577,,0,1
233,2017-5-6,2017,5,6,14,69jl5a,How to determine the dimension of the embedding space?,https://www.reddit.com/r/MachineLearning/comments/69jl5a/how_to_determine_the_dimension_of_the_embedding/,aragakiyuigaki,1494047610,[removed],0,1
234,2017-5-6,2017,5,6,14,69jmno,Face2Face: Real-time Face Capture and Reenactment of RGB Videos,https://www.reddit.com/r/MachineLearning/comments/69jmno/face2face_realtime_face_capture_and_reenactment/,v32uv1u2,1494048313,[removed],0,1
235,2017-5-6,2017,5,6,16,69jxtt,Will random cropping results in class unbalance?,https://www.reddit.com/r/MachineLearning/comments/69jxtt/will_random_cropping_results_in_class_unbalance/,Huluwahh,1494054005,[removed],0,1
236,2017-5-6,2017,5,6,16,69k115,Automatic Hamburger Buddget Pie Patty Burger Molding Making Machine,https://www.reddit.com/r/MachineLearning/comments/69k115/automatic_hamburger_buddget_pie_patty_burger/,Elaine2008,1494055715,,0,1
237,2017-5-6,2017,5,6,20,69kouu,Trading Using Machine Learning In Python,https://www.reddit.com/r/MachineLearning/comments/69kouu/trading_using_machine_learning_in_python/,NitinThapar,1494069371,,0,1
238,2017-5-6,2017,5,6,22,69lben,[D] Plain english programming language,https://www.reddit.com/r/MachineLearning/comments/69lben/d_plain_english_programming_language/,d-burner,1494079146,"Hello, I once saw a github project that had in it's dataset a simple programming language that looked like plain english. I'm now desperately trying to find that project (searched my whole history), but I cant find it anymore.
I know that the github project had something to do with NLP, but I'm not sure what framework (keras, tensorflow, or pytorch).

So does anyone know something about a simplistic programming language that looks like plain english?",12,0
239,2017-5-6,2017,5,6,23,69le9c,what is the state of the art technique in text classification?,https://www.reddit.com/r/MachineLearning/comments/69le9c/what_is_the_state_of_the_art_technique_in_text/,cbj1123,1494080163,[removed],0,1
240,2017-5-6,2017,5,6,23,69lhpu,interiordesigningtrends.com/5-basic-features-of-a-compact-excavator/,https://www.reddit.com/r/MachineLearning/comments/69lhpu/interiordesigningtrendscom5basicfeaturesofacompact/,paulrussell,1494081394,,0,1
241,2017-5-7,2017,5,7,0,69lmgd,Is there any way today to train on unlabeled images and then generate new photorealistic images from that set?,https://www.reddit.com/r/MachineLearning/comments/69lmgd/is_there_any_way_today_to_train_on_unlabeled/,mrconter1,1494083005,[removed],0,1
242,2017-5-7,2017,5,7,0,69lou1,Demistify data science - Launching our first data science training batch,https://www.reddit.com/r/MachineLearning/comments/69lou1/demistify_data_science_launching_our_first_data/,DeepLearningTrack,1494083789,,0,1
243,2017-5-7,2017,5,7,2,69mf5z,[1705.01088] Visual Attribute Transfer through Deep Image Analogy,https://www.reddit.com/r/MachineLearning/comments/69mf5z/170501088_visual_attribute_transfer_through_deep/,gcusso,1494092076,,0,1
244,2017-5-7,2017,5,7,4,69n74f,[P] Hyperparameter search benchmark?,https://www.reddit.com/r/MachineLearning/comments/69n74f/p_hyperparameter_search_benchmark/,0xfd,1494100713,"I wonder if there is some popular benchmark for hyperparameter search algorithms? I would appreciate any pointers. 

I am imagining a website where people can post their algorithms (much like OpenAI gym) on a public leaderboard. In particular, as a graduate student, i am wondering how good/bad ""grad student descent"" is. I think this can promote the spread of some generic hyperparameter search implementations. When reading papers, i feel mildly annoyed by claims/suggestions to the effect of ""we didn't do *much* hyperparameter tuning and thus we *might* do much better than the number we showed."" ",23,47
245,2017-5-7,2017,5,7,5,69naf2,Knowledge / Skills required to work on the ML research teams at Facebook or Google?,https://www.reddit.com/r/MachineLearning/comments/69naf2/knowledge_skills_required_to_work_on_the_ml/,[deleted],1494101771,[removed],0,1
246,2017-5-7,2017,5,7,5,69nh45,Watch .Canelo .vs .Chavez .Live .Streaming .Free!,https://www.reddit.com/r/MachineLearning/comments/69nh45/watch_canelo_vs_chavez_live_streaming_free/,[deleted],1494104025,[removed],0,1
247,2017-5-7,2017,5,7,6,69ning,psychoanalysis of AI,https://www.reddit.com/r/MachineLearning/comments/69ning/psychoanalysis_of_ai/,kocosman,1494104505,"Hi all, I'm seeing mostly technical approaches, i want to create a critical discussion here. The main idea is, since the training data is created by humans, can our cognitive biases become a part of the system. For me the main issue is how we approach ML. The tech we are used to is deterministik, so its objective, unbiased, and most of the time right. But ML and AI is stocastic. But we are willing to deploy without much questoining. The tools and methods that we have for debugging, diagnosis and calibration are not working for ML and AI. This was the main questions i had before starting this research. I exhibited it last october. Let me know what you think. You can read my full text here: https://medium.com/@9abcca7da209/d844212cc42f And the analysis of the rorschach expert is here: https://medium.com/@9abcca7da209/aeba8193c52f",0,0
248,2017-5-7,2017,5,7,6,69nqdb,Anyone know what kind of hardware setup they used for the DeepMind A3C paper?,https://www.reddit.com/r/MachineLearning/comments/69nqdb/anyone_know_what_kind_of_hardware_setup_they_used/,[deleted],1494107025,[removed],0,1
249,2017-5-7,2017,5,7,12,69pf5f,I want to start researching in some fields,https://www.reddit.com/r/MachineLearning/comments/69pf5f/i_want_to_start_researching_in_some_fields/,alcoholicfox,1494129592,[removed],0,1
250,2017-5-7,2017,5,7,13,69pg3a,CNN techniques for stereo matching?,https://www.reddit.com/r/MachineLearning/comments/69pg3a/cnn_techniques_for_stereo_matching/,[deleted],1494129938,[removed],0,1
251,2017-5-7,2017,5,7,13,69pmqn,UK - Masters in Machine Learning at either Imperial College or UCL,https://www.reddit.com/r/MachineLearning/comments/69pmqn/uk_masters_in_machine_learning_at_either_imperial/,ViralRiver,1494132793,[removed],0,1
252,2017-5-7,2017,5,7,14,69ptb2,"[D] Elad: Deep learning's impact on image processing, mathematics and humanity",https://www.reddit.com/r/MachineLearning/comments/69ptb2/d_elad_deep_learnings_impact_on_image_processing/,loopyfloop,1494135985,,15,61
253,2017-5-7,2017,5,7,15,69pzdg,[D] Oxford deep nlp 2017 solutions,https://www.reddit.com/r/MachineLearning/comments/69pzdg/d_oxford_deep_nlp_2017_solutions/,nil_magnum,1494139037,"My solutions here: https://github.com/mleue/oxford-deep-nlp-2017-solutions

I've recently been going through the lectures of oxford's 2017 deep nlp course (https://github.com/oxford-cs-deepnlp-2017). The course was well presented and I've really deepened my understanding of modern NLP methods.

Naturally I am going through the practicals as well. I've linked to the repo with my current progress but I feel a bit stuck atm.

The main task revolves around a multi-class classification of ~2k transcripts of TED talks. However, the dataset is heavily skewed with one class covering ~50% and some classes only around 3-5% of the data.

Practical 2 wants you to try a basic averaging over word-vectors approach and then pumping that through a single-hidden-layer NN. I've been trying to tweak a lot with preprocessing and tokenization but I can't come beyond ~66% accuracy on the test set.

In Practical 3 you are then supposed to try the same task with a RNN approach. I thought this might get better but I am basically stuck at around the same test set accuracy of ~66%.

Maybe not much more is possible, especially given the fact that there is very little data for some of the classes. Basically I am wondering if anyone else has gone through the course (or even attended the real deal at oxford) so we can get a discussion going.

Thanks in advance! //Michael",6,64
254,2017-5-7,2017,5,7,17,69qa8i,[Github] Winner Solution of Kaggle Data Science Bowl 2017,https://www.reddit.com/r/MachineLearning/comments/69qa8i/github_winner_solution_of_kaggle_data_science/,[deleted],1494145349,[deleted],0,1
255,2017-5-7,2017,5,7,17,69qbiu,[P] Winner Solution of Kaggel Data Science Bowl 2017,https://www.reddit.com/r/MachineLearning/comments/69qbiu/p_winner_solution_of_kaggel_data_science_bowl_2017/,[deleted],1494146084,[deleted],0,1
256,2017-5-7,2017,5,7,18,69qgcl,Would implementing the model for application be meaningful?,https://www.reddit.com/r/MachineLearning/comments/69qgcl/would_implementing_the_model_for_application_be/,[deleted],1494148782,[removed],0,1
257,2017-5-7,2017,5,7,18,69qgu9,Anyone know how to design website with machine Learning or Artificial Intelligence ?,https://www.reddit.com/r/MachineLearning/comments/69qgu9/anyone_know_how_to_design_website_with_machine/,neelneelpurk,1494149099,[removed],0,1
258,2017-5-7,2017,5,7,19,69qpc1,Publishing date of Sutton &amp; Barto's Introduction to reinforcement learning 2nd edition,https://www.reddit.com/r/MachineLearning/comments/69qpc1/publishing_date_of_sutton_bartos_introduction_to/,Jaksen93,1494153899,[removed],0,1
259,2017-5-7,2017,5,7,19,69qqn3,[D] University of Edinburgh VS KU Leuven: Master in Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/69qqn3/d_university_of_edinburgh_vs_ku_leuven_master_in/,ctrlaltv,1494154647,[removed],3,0
260,2017-5-7,2017,5,7,22,69ra0x,How to calculate nats per dimension?,https://www.reddit.com/r/MachineLearning/comments/69ra0x/how_to_calculate_nats_per_dimension/,[deleted],1494163477,[removed],0,1
261,2017-5-7,2017,5,7,22,69ra4c,[D] How to calculate nats per dimension?,https://www.reddit.com/r/MachineLearning/comments/69ra4c/d_how_to_calculate_nats_per_dimension/,[deleted],1494163516,[deleted],1,1
262,2017-5-7,2017,5,7,22,69rb4t,[D] How to calculate Negative log-likelihood in nats/dimension?,https://www.reddit.com/r/MachineLearning/comments/69rb4t/d_how_to_calculate_negative_loglikelihood_in/,[deleted],1494163940,[deleted],0,1
263,2017-5-7,2017,5,7,23,69ri5j,[D] How to calculate Negative log-likelihood in nats/dimension?,https://www.reddit.com/r/MachineLearning/comments/69ri5j/d_how_to_calculate_negative_loglikelihood_in/,[deleted],1494167059,[deleted],1,0
264,2017-5-7,2017,5,7,23,69rl16,Deep Learning: Language identification using Keras &amp; TensorFlow,https://www.reddit.com/r/MachineLearning/comments/69rl16/deep_learning_language_identification_using_keras/,lukasz_km,1494168047,,0,1
265,2017-5-8,2017,5,8,0,69rqza,[R] What is the current state of the art architectures for RNNs?,https://www.reddit.com/r/MachineLearning/comments/69rqza/r_what_is_the_current_state_of_the_art/,[deleted],1494169962,[deleted],14,16
266,2017-5-8,2017,5,8,0,69rrsa,[D] Study group: a month later!,https://www.reddit.com/r/MachineLearning/comments/69rrsa/d_study_group_a_month_later/,Kiuhnm,1494170225,"A month ago, I created a [study group](https://www.reddit.com/r/MachineLearning/comments/63d8p2/d_study_group_on_piazza/) about Advanced Machine Learning.

For now there are only two classes:

1. [Optimization (code: ku701)](http://piazza.com/kiuhnms_university/spring2017/ku701)
2. [Deep RL (code: ku702)](https://www.piazza.com/kiuhnms_university/spring2017/ku702).

I can't really say how everyone's doing since I suspect I and maybe a couple of others are the only ones left.

This shouldn't keep you from joining since I'm still very active and motivated.

## Optimization

I started with Convex Optimization since the theory is well developed and gives very strong foundations for dealing with more advanced topics such as Hessian Free Methods in nonconvex optimization.

The [main course](http://www.stat.cmu.edu/~ryantibs/convexopt/) is too hasty so I decided to complement it with Boyd's courses and book. In particular:

1. [CVX101](https://lagunita.stanford.edu/courses/Engineering/CVX101/Winter2014/info)
2. [Book](http://stanford.edu/~boyd/cvxbook/)
3. [EE364B](https://see.stanford.edu/Course/EE364B)

Basically, **main course = CVX101/Book + EE364B**, but the RHS is much more in depth.

CVX101 follows the book very closely, whereas EE364B is more advanced and builds on CVX101. The book doesn't cover the topics taught in EE364B, but Boyd wrote some additional notes for the course.

Right now I'm doing (some of) the exercises from chapter 8 (Unconstrained Minimization) so I've almost completed the CVX101 course and the book, and I'm about to start EE364B.

There are no deadlines whatsoever. I usually post about my progress and then create a poll just to have an idea of how everyone's doing. Feel free to ask questions and start discussions about anything related to Optimization, but I won't be able to help if it's not something I've already studied, of course.

I intend to stick around even after I've completed the courses.

## Deep Reinforcement Learning

In this class we're going through:

1. Sutton&amp;Barto's [book](http://incompleteideas.net/sutton/book/bookdraft2016sep.pdf) (2nd edition),
2. the [lectures](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html) by Silver and
3. the recent Berkeley Deep RL [course](http://rll.berkeley.edu/deeprlcourse/).

For now I've focused mainly on Optimization so I've only read the first 4 chapters of Sutton&amp;Barto's book. Since I didn't feel any pressure from the other members of the class, I took my time.",9,41
267,2017-5-8,2017,5,8,0,69rv70,[D] Modern ways to handle missing data in a Deep model,https://www.reddit.com/r/MachineLearning/comments/69rv70/d_modern_ways_to_handle_missing_data_in_a_deep/,kaitzu,1494171317,"Are there any novel approaches for training a deep model with missing features?  

What would you think about selective dropout or DropConnect for the missing features during training? Another idea I was considering is to use a denoising autoencoder with loss function that does not take into account the missing features. That is to (additionally) corrupt the available features during training in order to minimise the reconstruction error of these specifically.

Concretely I have about 50K labelled and 100K unlabelled samples with about 150 continuous features. Of these, about 10-50% of the features per sample are randomly missing. ",10,13
268,2017-5-8,2017,5,8,0,69rzva,Understanding the paper -- I am new to GRU-based attention models and was wondering how I can go about learning the background material required to consume this paper. Please let me know any suggestions.,https://www.reddit.com/r/MachineLearning/comments/69rzva/understanding_the_paper_i_am_new_to_grubased/,224_throw,1494172781,,0,1
269,2017-5-8,2017,5,8,1,69s7bv,Does Tensorflow simply graphs?,https://www.reddit.com/r/MachineLearning/comments/69s7bv/does_tensorflow_simply_graphs/,warmsnail,1494175051,"Does Tensorflow analyze the computational graph and simplify any subset of the operations, since the definition of the computational graph is separate from its execution?

My intuition is that the answer is yes, but I'm stumped by the existence of the [tf.nn.sigmoid_cross_entropy_with_logits](https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits) and the similar softmax function.
If I had defined the equivalent cross entropy function on the output of a sigmoid/softmax function, could Tensorflow simplify it in the way presented on the link above? If not, why not?

Also, doesn't the above method violate some of the software engineering principles of separating functionality into separate methods?
Perhaps more generally, is there any sort of good explanation of various computational graph optimizations that Tensorflow does?

I haven't been really able to find any satisfying explanation on Google.
Thanks! ",9,2
270,2017-5-8,2017,5,8,1,69sbnp,"[P] Variational Coin Toss: VI applied to a simple ""unfair coin"" problem",https://www.reddit.com/r/MachineLearning/comments/69sbnp/p_variational_coin_toss_vi_applied_to_a_simple/,bjornsing,1494176386,,15,93
271,2017-5-8,2017,5,8,3,69srg9,[P] Load Word Embeddings 10-20x Faster,https://www.reddit.com/r/MachineLearning/comments/69srg9/p_load_word_embeddings_1020x_faster/,spenny_the_dollar,1494180881,,8,13
272,2017-5-8,2017,5,8,3,69syya,JSbin for fiddling with movie lens dataset with lodash.,https://www.reddit.com/r/MachineLearning/comments/69syya/jsbin_for_fiddling_with_movie_lens_dataset_with/,VojvodaDjujic,1494182909,,0,1
273,2017-5-8,2017,5,8,5,69teiz,[D] Machine Learning - WAYR (What Are You Reading) - Week 25,https://www.reddit.com/r/MachineLearning/comments/69teiz/d_machine_learning_wayr_what_are_you_reading_week/,ML_WAYR_bot,1494187204,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|
|----|-----|-----|
|[Week 1](https://www.reddit.com/r/MachineLearning/comments/4qyjiq/machine_learning_wayr_what_are_you_reading_week_1/)|[Week 11](https://www.reddit.com/r/MachineLearning/comments/57xw56/discussion_machine_learning_wayr_what_are_you/)|[Week 21](https://www.reddit.com/r/MachineLearning/comments/60ildf/d_machine_learning_wayr_what_are_you_reading_week/)|
|[Week 2](https://www.reddit.com/r/MachineLearning/comments/4s2xqm/machine_learning_wayr_what_are_you_reading_week_2/)|[Week 12](https://www.reddit.com/r/MachineLearning/comments/5acb1t/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 22](https://www.reddit.com/r/MachineLearning/comments/64jwde/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 3](https://www.reddit.com/r/MachineLearning/comments/4t7mqm/machine_learning_wayr_what_are_you_reading_week_3/)|[Week 13](https://www.reddit.com/r/MachineLearning/comments/5cwfb6/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 23](https://www.reddit.com/r/MachineLearning/comments/674331/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 4](https://www.reddit.com/r/MachineLearning/comments/4ub2kw/machine_learning_wayr_what_are_you_reading_week_4/)|[Week 14](https://www.reddit.com/r/MachineLearning/comments/5fc5mh/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 24](https://www.reddit.com/r/MachineLearning/comments/68hhhb/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 5](https://www.reddit.com/r/MachineLearning/comments/4xomf7/machine_learning_wayr_what_are_you_reading_week_5/)|[Week 15](https://www.reddit.com/r/MachineLearning/comments/5hy4ur/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 6](https://www.reddit.com/r/MachineLearning/comments/4zcyvk/machine_learning_wayr_what_are_you_reading_week_6/)|[Week 16](https://www.reddit.com/r/MachineLearning/comments/5kd6vd/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 7](https://www.reddit.com/r/MachineLearning/comments/52t6mo/machine_learning_wayr_what_are_you_reading_week_7/)|[Week 17](https://www.reddit.com/r/MachineLearning/comments/5ob7dx/discussion_machine_learning_wayr_what_are_you/)||
|[Week 8](https://www.reddit.com/r/MachineLearning/comments/53heol/machine_learning_wayr_what_are_you_reading_week_8/)|[Week 18](https://www.reddit.com/r/MachineLearning/comments/5r14yd/discussion_machine_learning_wayr_what_are_you/)||
|[Week 9](https://www.reddit.com/r/MachineLearning/comments/54kvsu/machine_learning_wayr_what_are_you_reading_week_9/)|[Week 19](https://www.reddit.com/r/MachineLearning/comments/5tt9cz/discussion_machine_learning_wayr_what_are_you/)||
|[Week 10](https://www.reddit.com/r/MachineLearning/comments/56s2oa/discussion_machine_learning_wayr_what_are_you/)|[Week 20](https://www.reddit.com/r/MachineLearning/comments/5wh2wb/d_machine_learning_wayr_what_are_you_reading_week/)||

Most upvoted papers two weeks ago:

/u/whenmaster: https://arxiv.org/abs/1701.07875v2

/u/nicrob355982: https://arxiv.org/abs/1507.04808

Besides that, there are no rules, have fun.

Hey, seems there was a little hiccup where last week's WAYR post wasn't stickied, so I'm going to change the bot to post every other week.",16,54
274,2017-5-8,2017,5,8,5,69tnu6,[D] A variant on k-hearest neighbors classifier where k on a per-prediction basis to maximize predictive accuracy - looking for feedback,https://www.reddit.com/r/MachineLearning/comments/69tnu6/d_a_variant_on_khearest_neighbors_classifier/,[deleted],1494189882,[removed],0,1
275,2017-5-8,2017,5,8,5,69to09,[D] A variant on k-nearest neighbors classifier where k on a per-prediction basis to maximize predictive accuracy - looking for feedback,https://www.reddit.com/r/MachineLearning/comments/69to09/d_a_variant_on_knearest_neighbors_classifier/,[deleted],1494189931,[removed],0,1
276,2017-5-8,2017,5,8,5,69to5h,[D] A variant on k-nearest neighbors classifier where k varies on a per-prediction basis to maximize predictive accuracy - looking for feedback,https://www.reddit.com/r/MachineLearning/comments/69to5h/d_a_variant_on_knearest_neighbors_classifier/,sanity,1494189973,[removed],0,1
277,2017-5-8,2017,5,8,6,69tval,"high cardinality categorical variable encoding - Y-aware ""impact encoding"". ""Leaking"" data from the future?",https://www.reddit.com/r/MachineLearning/comments/69tval/high_cardinality_categorical_variable_encoding/,[deleted],1494192066,[removed],0,1
278,2017-5-8,2017,5,8,6,69txzx,"[D] high cardinality categorical variable encoding - Y-aware ""impact encoding"". ""Leaking"" data from the future?",https://www.reddit.com/r/MachineLearning/comments/69txzx/d_high_cardinality_categorical_variable_encoding/,akcom,1494192856,"Hi all,

An interesting question came up at work, and I'd like to get input from the experts here.  We are dealing with a very common issue: modeling high cardinality categorical variables.  My go to solution would be either one hot encoding with a penalized model, or feature hashing.  My colleague suggested ""impact encoding"" which is a method I am not familiar with (references below).  Essentially the idea is this: for a categorical variable with k levels, instead of using k-1 dummy variables, you use one variable and for each observation, set the variable equal to the prevalence of your outcome for that level in the training set.

This seems like cheating to me, in that we are ""looking into the future"" by using our outcome in the modeling step.  Is anyone else familiar with this method?  Does this seem credible?


1.  [arXiv - vtreat: a data.frame Processor for Predictive Modeling](https://arxiv.org/abs/1611.09477)
2.  [Blog post - Impact modeling trick (by vtreat author)](http://www.win-vector.com/blog/2012/07/modeling-trick-impact-coding-of-categorical-variables-with-many-levels/)",5,5
279,2017-5-8,2017,5,8,7,69ucql,"Did Trump Tweet It?  Powered by machine learning, the world's first archive of who wrote every @realDonaldTrump and @POTUS tweet.",https://www.reddit.com/r/MachineLearning/comments/69ucql/did_trump_tweet_it_powered_by_machine_learning/,didtrumptweetit,1494197419,,0,1
280,2017-5-8,2017,5,8,11,69vjz1,"I have built a timeline to show the developments of GAN, hope it helps!",https://www.reddit.com/r/MachineLearning/comments/69vjz1/i_have_built_a_timeline_to_show_the_developments/,zombder,1494211976,,0,1
281,2017-5-8,2017,5,8,15,69wezm,[HELP] Starting from scratch !?,https://www.reddit.com/r/MachineLearning/comments/69wezm/help_starting_from_scratch/,imtr8r,1494224480,[removed],0,1
282,2017-5-8,2017,5,8,17,69wvc8,Visual Localization &amp; Mapping for Autonomous Driving,https://www.reddit.com/r/MachineLearning/comments/69wvc8/visual_localization_mapping_for_autonomous_driving/,reworksophie,1494232336,,0,1
283,2017-5-8,2017,5,8,17,69wvzo,Top 5 Key Areas: Deep Learning in Retail &amp; Advertising,https://www.reddit.com/r/MachineLearning/comments/69wvzo/top_5_key_areas_deep_learning_in_retail/,reworksophie,1494232649,,0,1
284,2017-5-8,2017,5,8,17,69ww45,Tensorflow on Heroku. Good idea?,https://www.reddit.com/r/MachineLearning/comments/69ww45/tensorflow_on_heroku_good_idea/,slinto,1494232721,,0,1
285,2017-5-8,2017,5,8,17,69ww9v,Agile Deep Learning For Modern Software Development (Interview with ML lead at Spotify),https://www.reddit.com/r/MachineLearning/comments/69ww9v/agile_deep_learning_for_modern_software/,reworksophie,1494232788,,0,1
286,2017-5-8,2017,5,8,17,69wwiu,Self-Driving Cars: the Tech &amp; the Roadblocks,https://www.reddit.com/r/MachineLearning/comments/69wwiu/selfdriving_cars_the_tech_the_roadblocks/,reworksophie,1494232921,,0,1
287,2017-5-8,2017,5,8,17,69wx3b,"[P]pytorch-playground: Base pretrained model and datasets in pytorch (MNIST, SVHN, CIFAR10, CIFAR100, STL10, AlexNet, VGG16, VGG19, ResNet, Inception, SqueezeNet)",https://www.reddit.com/r/MachineLearning/comments/69wx3b/ppytorchplayground_base_pretrained_model_and/,aaronxic,1494233208,,7,42
288,2017-5-8,2017,5,8,17,69wx79,Environmental Test Chambers Market 2012- 2022,https://www.reddit.com/r/MachineLearning/comments/69wx79/environmental_test_chambers_market_2012_2022/,ezio136,1494233263,,0,1
289,2017-5-8,2017,5,8,18,69x602,"[D] Physiognomys New Clothes - An article on fairness, bias and machine learning.",https://www.reddit.com/r/MachineLearning/comments/69x602/d_physiognomys_new_clothes_an_article_on_fairness/,stephen370,1494237463,,34,49
290,2017-5-8,2017,5,8,19,69x8hh,How to Learn from Little Data,https://www.reddit.com/r/MachineLearning/comments/69x8hh/how_to_learn_from_little_data/,boltrain,1494238527,,0,1
291,2017-5-8,2017,5,8,20,69xitd,[D] The End of Human Doctors  Radiology Escape Velocity,https://www.reddit.com/r/MachineLearning/comments/69xitd/d_the_end_of_human_doctors_radiology_escape/,drlukeor,1494243100,,13,13
292,2017-5-8,2017,5,8,22,69y2g6,[R] CNNs and Hierarchical Tensor Decompositions - High-level summaries of a series of works,https://www.reddit.com/r/MachineLearning/comments/69y2g6/r_cnns_and_hierarchical_tensor_decompositions/,XalosXandrez,1494250014,,0,14
293,2017-5-8,2017,5,8,22,69y4pf,6 MIPI CSI-2 Cameras support for NVIDIA Jetson TX1/TX2,https://www.reddit.com/r/MachineLearning/comments/69y4pf/6_mipi_csi2_cameras_support_for_nvidia_jetson/,econsystems,1494250709,,0,1
294,2017-5-8,2017,5,8,22,69y7pu,Transfer Learning for Flight Delay Prediction via Variational Autoencoders,https://www.reddit.com/r/MachineLearning/comments/69y7pu/transfer_learning_for_flight_delay_prediction_via/,cavaunpeu,1494251658,,0,1
295,2017-5-8,2017,5,8,23,69yif8,Play music with a variational autoencoder,https://www.reddit.com/r/MachineLearning/comments/69yif8/play_music_with_a_variational_autoencoder/,mobeetsforyou,1494254751,,0,1
296,2017-5-9,2017,5,9,0,69yn1z,[N] Uber hires Racquel Urtasun,https://www.reddit.com/r/MachineLearning/comments/69yn1z/n_uber_hires_racquel_urtasun/,cbfinn,1494256004,,33,13
297,2017-5-9,2017,5,9,0,69yxao,[N] Introducing NVIDIA Metropolis,https://www.reddit.com/r/MachineLearning/comments/69yxao/n_introducing_nvidia_metropolis/,senorstallone,1494258677,,12,7
298,2017-5-9,2017,5,9,1,69z0uu,[R] Sharing deep generative representation for perceived image reconstruction from human brain activity,https://www.reddit.com/r/MachineLearning/comments/69z0uu/r_sharing_deep_generative_representation_for/,hooba_stank_,1494259603,,2,3
299,2017-5-9,2017,5,9,1,69z365,"AI learns to generate Mozart, Beethoven, Ragtime piano music",https://www.reddit.com/r/MachineLearning/comments/69z365/ai_learns_to_generate_mozart_beethoven_ragtime/,[deleted],1494260202,[removed],0,1
300,2017-5-9,2017,5,9,1,69z5q9,"[P] AI learns to generate Mozart, Beethoven, Ragtime piano music",https://www.reddit.com/r/MachineLearning/comments/69z5q9/p_ai_learns_to_generate_mozart_beethoven_ragtime/,happyhammy,1494260885,,19,39
301,2017-5-9,2017,5,9,2,69zm72,Applying Microsoft Cognitive Emotion Recognition ML API's to Videos,https://www.reddit.com/r/MachineLearning/comments/69zm72/applying_microsoft_cognitive_emotion_recognition/,ammararaja,1494265103,,1,1
302,2017-5-9,2017,5,9,2,69zqqk,Starting a company. Looking for advice.,https://www.reddit.com/r/MachineLearning/comments/69zqqk/starting_a_company_looking_for_advice/,NottaGoon,1494266281,[removed],0,1
303,2017-5-9,2017,5,9,3,6a028m,[P] Self-driving AI in GTA V - Just using a ConvNet with decent results update,https://www.reddit.com/r/MachineLearning/comments/6a028m/p_selfdriving_ai_in_gta_v_just_using_a_convnet/,sentdex,1494269240,"I've been working on a tutorial series for creating [self-driving cars in Grand Theft Auto 5](https://pythonprogramming.net/game-frames-open-cv-python-plays-gta-v/) for a bit now. 

The most recent creation is the result of day or so worth of collecting training data, and about 4 days of actual training of the model. 

It's currently a 30-layer convolutional neural network, it works purely on a frame-by-frame basis with no preprocessing other than an image resize and grayscale. It makes actions based on the current frame's pixel data, with no memory of what it's been doing. I plan to eventually incorporate some form of memory with something like recurrent layers, but...baby steps at a time!

Right now, the stream is just a stream of the latest model, it's not training itself any further, but I do plan to eventually implement self-training into the model, I just wanted to get the stream to run 24/7 first. 

I am streaming the bot 24/7 on Twitch: **[Python Plays GTA V](https://www.twitch.tv/sentdex)**

Here's a video covering the latest model: [self-driving AI update #15](https://www.youtube.com/watch?v=edWI4ZnWUGg&amp;list=PLQVvvaa0QuDeETZEOy4VdocT7TOjfSA8a&amp;index=15)

If you want to learn about how it's made: **[Self Driving Cars in GTA with Python and TensorFlow tutorial series](https://pythonprogramming.net/game-frames-open-cv-python-plays-gta-v/)**

If you want to just see the base source code: check it out on **[github](https://github.com/sentdex/pygta5/)**

Unfortunately, right now, the stream is kind of touch and go. My internet is failing me on the upload, and the GPU running the game, stream, and neural network is frequently maxed out. I will try to improve it in time, but still somewhat amusing to watch regardless. ",63,308
304,2017-5-9,2017,5,9,3,6a03ox,"[D] Deep, Deep Trouble Deep Learnings Impact on Image Processing, Mathematics, and Humanity by Michael Elad",https://www.reddit.com/r/MachineLearning/comments/6a03ox/d_deep_deep_trouble_deep_learnings_impact_on/,CyberByte,1494269617,,3,0
305,2017-5-9,2017,5,9,4,6a05lm,Calling a basic LSTM cell within a custom Tensorflow cell,https://www.reddit.com/r/MachineLearning/comments/6a05lm/calling_a_basic_lstm_cell_within_a_custom/,FamousMortimer,1494270120,[removed],0,1
306,2017-5-9,2017,5,9,4,6a092u,[D] Seq2Seq VAE is worse than vanilla AE for text reconstruction?,https://www.reddit.com/r/MachineLearning/comments/6a092u/d_seq2seq_vae_is_worse_than_vanilla_ae_for_text/,Pieranha,1494271022,"I'm training a Seq2Seq autoencoder on text reconstruction for short texts of length 5-30 tokens. Interestingly, I find that my VAE is doing much worse as measured by the Softmax reconstruction loss than a vanilla AE. This is strange as I hear that the VAE should generally be better than AE for most choices.

The architecture is rather simple in that it has a 256 embedding layer, 1024 LSTM encoding layer, 128 latent dim (Dense layer) and 1024 LSTM decoding layer. The model is trained using Adam with default hyperparameters. I have plenty of data (500k+) so that should not be an issue.

The performance is much worse for the VAE with it learning for around 20 epochs before stalling at around a Softmax reconstruction loss of 3.8 on the validation set, whereas the vanilla AE converges after 100+ epochs to a loss of about 0.25. Also, the reconstructed text quality is much better.

I have the following questions that I would love if someone could comment on!

1. Do I need to increase the latent dimensions to make up for the regularizing effect of the KL divergence term and the sampling?
2. What is a reasonable loss multiplier for the KL divergence term? So far I've just used 1.
3. I expect that a VAE takes longer to train than a AE. Is that also what you find?
4. Do you generally experience that a vanilla AE can outperform a VAE? ",14,8
307,2017-5-9,2017,5,9,6,6a0x2e,ahmedbesbes.com,https://www.reddit.com/r/MachineLearning/comments/6a0x2e/ahmedbesbescom/,ahmedbesbes,1494277265,,0,1
308,2017-5-9,2017,5,9,6,6a0xiv,Sentiment analysis on Twitter using word2vec and keras,https://www.reddit.com/r/MachineLearning/comments/6a0xiv/sentiment_analysis_on_twitter_using_word2vec_and/,ahmedbesbes,1494277389,,0,1
309,2017-5-9,2017,5,9,6,6a0xxn,How to mine newsfeed data and extract interactive insights in Python,https://www.reddit.com/r/MachineLearning/comments/6a0xxn/how_to_mine_newsfeed_data_and_extract_interactive/,ahmedbesbes,1494277495,,0,1
310,2017-5-9,2017,5,9,6,6a0y44,How to score 0.8134 in Titanic Kaggle Challenge,https://www.reddit.com/r/MachineLearning/comments/6a0y44/how_to_score_08134_in_titanic_kaggle_challenge/,ahmedbesbes,1494277544,,0,1
311,2017-5-9,2017,5,9,6,6a17vg,t-sne gives crappy results with word2vec vectors,https://www.reddit.com/r/MachineLearning/comments/6a17vg/tsne_gives_crappy_results_with_word2vec_vectors/,SuperCComplex,1494280268,[removed],0,1
312,2017-5-9,2017,5,9,7,6a1cv9,True or false machine learning questions,https://www.reddit.com/r/MachineLearning/comments/6a1cv9/true_or_false_machine_learning_questions/,EmptyVector,1494281655,[removed],0,1
313,2017-5-9,2017,5,9,7,6a1j87,A few questions,https://www.reddit.com/r/MachineLearning/comments/6a1j87/a_few_questions/,PhasSec,1494283516,[removed],0,1
314,2017-5-9,2017,5,9,9,6a1z8y,"Build Time Series ARIMA Model in R, Excel and Tableau. [Git and Tableau links included].",https://www.reddit.com/r/MachineLearning/comments/6a1z8y/build_time_series_arima_model_in_r_excel_and/,kyanyoga,1494288452,,0,1
315,2017-5-9,2017,5,9,9,6a213w,Newer types of neural networks,https://www.reddit.com/r/MachineLearning/comments/6a213w/newer_types_of_neural_networks/,deepNeural,1494288984,,0,1
316,2017-5-9,2017,5,9,9,6a21hc,[1705.02394] Learning Representations of Emotional Speech with Deep Convolutional Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/6a21hc/170502394_learning_representations_of_emotional/,[deleted],1494289096,[deleted],0,1
317,2017-5-9,2017,5,9,10,6a2azz,Data Quality should be a primary feature that you deliver in your project. Not an After Thought.,https://www.reddit.com/r/MachineLearning/comments/6a2azz/data_quality_should_be_a_primary_feature_that_you/,kyanyoga,1494292082,,0,1
318,2017-5-9,2017,5,9,10,6a2goy,[1705.02894] Geometric GAN &lt;-- converges to Nash equilibrium,https://www.reddit.com/r/MachineLearning/comments/6a2goy/170502894_geometric_gan_converges_to_nash/,[deleted],1494293879,[deleted],0,1
319,2017-5-9,2017,5,9,10,6a2gun,[R] [1705.02894] Geometric GAN &lt;-- converges to Nash equilibrium,https://www.reddit.com/r/MachineLearning/comments/6a2gun/r_170502894_geometric_gan_converges_to_nash/,evc123,1494293932,,11,30
320,2017-5-9,2017,5,9,11,6a2tvj,[P] Bayesian RNN Implementation Question/Review,https://www.reddit.com/r/MachineLearning/comments/6a2tvj/p_bayesian_rnn_implementation_questionreview/,MarkusDeNeutoy,1494298113,"I thought the posterior sharpening method in the Bayesian RNN paper was particularly cool, so I had a crack at implementing it [here](https://github.com/DeNeutoy/bayesian-rnn).
It kind of works, and I think i've done the posterior sharpening part correctly, but I think my MOG prior for the phi KL term in the paper is [wrong somehow](https://github.com/DeNeutoy/bayesian-rnn/blob/master/bayesian_rnn.py#L142) and I can't quite figure it out. Using a single sample in the way that the authors suggest doesn't seem to be working (or possibly/probably I have done it incorrectly). I used a univariate gaussian prior for phi instead and it gets to around 120ish test perplexity. The other difference from the original is i'm using a single layer LSTM to speed things up. 

The posterior sharpening method seems very powerful - whilst I was implementing this, I was thinking if there was a way to parameterise the posterior distribution on theta (q(theta | phi, x, y)) using a linear combination of the gradient with respect to some *negative* evidence and the phi parameters, in order to not require using the labels, which would allow this to be used on validation data as well. Thoughts/comments appreciated. ",3,9
321,2017-5-9,2017,5,9,12,6a2x92,[P] Need help calculating loss for A3C policy network,https://www.reddit.com/r/MachineLearning/comments/6a2x92/p_need_help_calculating_loss_for_a3c_policy/,normally_i_lurk,1494299267,"Hello,

I'm currently in the process of implementing A3C, but I'm facing a somewhat tricky problem: All of the implementations I'm using for reference have a policy network with output size N (a value for each action), and the argmax of this output corresponds to the index of the action to take in a given state. Of the examples I've seen, the agent either takes one action (button press) per frame or some specific combination of buttons constituting a single action. I want the latter, but herein lies the problem: the example I've seen which uses multiple buttons per frame simply precomputes all possible button combinations and uses the index of the policy network to point to that specific combination. This is okay in small scenarios, but if I wanted to make use of, say, N=20 buttons, that's 2^20 combinations of button presses, or 1,048,576 different actions to choose from, which is absurd. I don't think the network could properly learn the best action for each state in that case.

My ideal solution is to have an output of size N=20, and the actual action is determined by some threshold on the output values (e.g. thresh=0.5, output=[0.1, 0.2, 0.5, 0.6] ==&gt; action=[False, False, True, True]).  However, I don't know how to compute the loss function for this. The targets for the policy network come from the advantages, which are still size 1 since the value network only returns a single value for each state, and the reward is always a single number. So how can I associate 1-dimensional rewards with N-dimensional outputs? Should I just make the reward repeat N times, or is there a better way? Better as in, should I change the network architecture somehow?

Apologies if this is a simple question; this is my first DNN implementation and I couldn't find anything via Google.",2,1
322,2017-5-9,2017,5,9,12,6a31bo,Linear Algebra for Beginners,https://www.reddit.com/r/MachineLearning/comments/6a31bo/linear_algebra_for_beginners/,rickmister24,1494300680,,0,1
323,2017-5-9,2017,5,9,12,6a34p8,Discrete Mathematics for Beginners,https://www.reddit.com/r/MachineLearning/comments/6a34p8/discrete_mathematics_for_beginners/,rickmister24,1494301918,,0,1
324,2017-5-9,2017,5,9,12,6a3560,"[N] Reproducibility in ML Workshop, ICML'17",https://www.reddit.com/r/MachineLearning/comments/6a3560/n_reproducibility_in_ml_workshop_icml17/,alexmlamb,1494302095,,0,27
325,2017-5-9,2017,5,9,13,6a3a6i,How to Build a Diagnostic System for Psychiatric Disorders?,https://www.reddit.com/r/MachineLearning/comments/6a3a6i/how_to_build_a_diagnostic_system_for_psychiatric/,TheoryEternity,1494303981,[removed],0,1
326,2017-5-9,2017,5,9,13,6a3baf,Predicting Next Character using RNN,https://www.reddit.com/r/MachineLearning/comments/6a3baf/predicting_next_character_using_rnn/,yashkatariya,1494304407,,0,1
327,2017-5-9,2017,5,9,14,6a3kbd,[R] [1705.02394] Learning Representations of Emotional Speech with Deep Convolutional Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/6a3kbd/r_170502394_learning_representations_of_emotional/,sergeyfukov,1494308091,,0,4
328,2017-5-9,2017,5,9,15,6a3s7n,[R] Accessible Format for Birds+Captions Dataset,https://www.reddit.com/r/MachineLearning/comments/6a3s7n/r_accessible_format_for_birdscaptions_dataset/,alexmlamb,1494311635,"Hello, 

Does anyone know of an accessible format for the Birds+Captions dataset?  

https://arxiv.org/pdf/1612.03242v1.pdf

I found data here, but it's in a kind of awkward .t7 format, with a non-parallel format between images and captions: 

https://github.com/reedscot/cvpr2016

I would be most interested in a fuel format, but anything that just has images in a normal image format would be nice.  

Best, 

Alex.  ",2,3
329,2017-5-9,2017,5,9,16,6a3wha,Chapter progression for Machine Learning: A Probabilistic Perspective,https://www.reddit.com/r/MachineLearning/comments/6a3wha/chapter_progression_for_machine_learning_a/,makerdota2greatagain,1494313687,[removed],0,1
330,2017-5-9,2017,5,9,16,6a3xav,Question regarding the Machine Learning algorithms being used in Google Assistant.,https://www.reddit.com/r/MachineLearning/comments/6a3xav/question_regarding_the_machine_learning/,piykat,1494314078,[removed],0,1
331,2017-5-9,2017,5,9,16,6a3ywi,[D] Why have chatbots recently become so hot?,https://www.reddit.com/r/MachineLearning/comments/6a3ywi/d_why_have_chatbots_recently_become_so_hot/,hobblyknobs,1494314866,"Is it just because people have started spending a majority of their time on chat applications?

It doesn't seem to be related to advances in AI in any way.. The most useful bots (eg Hipmunk, digg) I've tried seem to be largely rule based and work only for very specific kinds of questions.

Am I off? Anyone aware of a useful chatbot out there that actually uses NLP which could blow my mind?",29,33
332,2017-5-9,2017,5,9,17,6a44aj,Machine Learning Will Help Improve Google Maps Services,https://www.reddit.com/r/MachineLearning/comments/6a44aj/machine_learning_will_help_improve_google_maps/,digitalmarketingrobi,1494317561,,0,1
333,2017-5-9,2017,5,9,17,6a44on,[1705.02999] Real-Time User-Guided Image Colorization with Learned Deep Priors,https://www.reddit.com/r/MachineLearning/comments/6a44on/170502999_realtime_userguided_image_colorization/,Valiox,1494317751,,5,20
334,2017-5-9,2017,5,9,17,6a49c3,[N] N2D2 - Open source European platform for Neural Networks,https://www.reddit.com/r/MachineLearning/comments/6a49c3/n_n2d2_open_source_european_platform_for_neural/,EyedMoon,1494320234,,4,6
335,2017-5-9,2017,5,9,18,6a4bgv,[P] pdpipe - Easy pipelines for pandas DataFrames.,https://www.reddit.com/r/MachineLearning/comments/6a4bgv/p_pdpipe_easy_pipelines_for_pandas_dataframes/,shaypal5,1494321283,,1,31
336,2017-5-9,2017,5,9,18,6a4ce1,Let's settle this.... WHAT IS THE BEST COLOUR AND WHY?,https://www.reddit.com/r/MachineLearning/comments/6a4ce1/lets_settle_this_what_is_the_best_colour_and_why/,SugarDatesUk,1494321770,[removed],0,1
337,2017-5-9,2017,5,9,18,6a4cyn,Fact Based Human Resources at ABN AMRO Bank,https://www.reddit.com/r/MachineLearning/comments/6a4cyn/fact_based_human_resources_at_abn_amro_bank/,czuriaga,1494322094,,0,1
338,2017-5-9,2017,5,9,18,6a4fwl,"TensorFlow, Encog vs New machine learning algorythm",https://www.reddit.com/r/MachineLearning/comments/6a4fwl/tensorflow_encog_vs_new_machine_learning_algorythm/,leonsalayog,1494323474,[removed],0,1
339,2017-5-9,2017,5,9,20,6a4qrt,Supervised and Unsupervised Text Classification technology,https://www.reddit.com/r/MachineLearning/comments/6a4qrt/supervised_and_unsupervised_text_classification/,parth10,1494328397,,0,1
340,2017-5-9,2017,5,9,20,6a4rpm,How To Create A Neural Network in JavaScript - Scrimba screencast,https://www.reddit.com/r/MachineLearning/comments/6a4rpm/how_to_create_a_neural_network_in_javascript/,mrborgen86,1494328772,,0,1
341,2017-5-9,2017,5,9,20,6a4tdj,Where to look for Machine Learning Internships?,https://www.reddit.com/r/MachineLearning/comments/6a4tdj/where_to_look_for_machine_learning_internships/,nivm321,1494329428,[removed],0,1
342,2017-5-9,2017,5,9,21,6a58a5,[P] Evolutionary Algorithms: Introduction,https://www.reddit.com/r/MachineLearning/comments/6a58a5/p_evolutionary_algorithms_introduction/,shahinrostami,1494334765,,12,114
343,2017-5-9,2017,5,9,23,6a5oo8,[R] Videos of the 1st NIPS Workshop on Neural Abstract Machines &amp; Program Induction online,https://www.reddit.com/r/MachineLearning/comments/6a5oo8/r_videos_of_the_1st_nips_workshop_on_neural/,_rockt,1494339609,,0,25
344,2017-5-9,2017,5,9,23,6a5qgr,machine learning or AI,https://www.reddit.com/r/MachineLearning/comments/6a5qgr/machine_learning_or_ai/,apaar123,1494340118,[removed],0,1
345,2017-5-10,2017,5,10,0,6a62zj,"We have indexed over 27M research papers and 12M associated social interactions (posts, comments, etc.), used some ML and built a browser extension to help students &amp; academics research faster.",https://www.reddit.com/r/MachineLearning/comments/6a62zj/we_have_indexed_over_27m_research_papers_and_12m/,rabbit140,1494343501,[removed],0,1
346,2017-5-10,2017,5,10,0,6a69zq,Linguistics Breakthrough Heralds Machine Translation for Thousands of Rare Languages,https://www.reddit.com/r/MachineLearning/comments/6a69zq/linguistics_breakthrough_heralds_machine/,[deleted],1494345393,[deleted],0,1
347,2017-5-10,2017,5,10,1,6a6eky,Liquid filling machines in turkey,https://www.reddit.com/r/MachineLearning/comments/6a6eky/liquid_filling_machines_in_turkey/,sividolummakinasi,1494346543,,0,1
348,2017-5-10,2017,5,10,1,6a6ibm,[R] A novel approach to neural machine translation,https://www.reddit.com/r/MachineLearning/comments/6a6ibm/r_a_novel_approach_to_neural_machine_translation/,alxndrkalinin,1494347477,,20,50
349,2017-5-10,2017,5,10,1,6a6lqy,"[P] Fellowship for real-time machine learning in Berkeley, CA",https://www.reddit.com/r/MachineLearning/comments/6a6lqy/p_fellowship_for_realtime_machine_learning_in/,findx2,1494348332,"If you're interested in real-time machine learning control of real-world energy systems, there's a one-year fellowship being offered at Lawrence Berkeley National Lab (LBNL).  The fellowship is part of a fully-funded entrepreneurship program at LBNL, and has access to resources both at LBNL and the Univ. of California, Berkeley.  The technology being developed is similar to [this short video](https://www.youtube.com/watch?v=qQG7ocnE3EA), but we're targeting more general energy-related applications beyond just near-chaotic engine combustion.  Btw, since ""real-time"" can be a little vague, response times needed by some systems are on the order of 5-100 microseconds, so expect more low-level coding than Python.  More details (including application information) are [available here](http://www.cyclotronroad.org/applied-research-fellows).",5,20
350,2017-5-10,2017,5,10,2,6a6qxr,"[R] ""CaloGAN: Simulating 3D High Energy Particle Showers in Multi-Layer Electromagnetic Calorimeters with Generative Adversarial Networks"", Paganini et al 2017",https://www.reddit.com/r/MachineLearning/comments/6a6qxr/r_calogan_simulating_3d_high_energy_particle/,gwern,1494349621,,10,9
351,2017-5-10,2017,5,10,2,6a6z54,Gelato Convolutional MNIST,https://www.reddit.com/r/MachineLearning/comments/6a6z54/gelato_convolutional_mnist/,bobchennan,1494351654,,0,1
352,2017-5-10,2017,5,10,2,6a732r,Facebook AI Research Sequence-to-Sequence Toolkit: High-performance pretrained NMT models available,https://www.reddit.com/r/MachineLearning/comments/6a732r/facebook_ai_research_sequencetosequence_toolkit/,AlexCoventry,1494352644,,0,1
353,2017-5-10,2017,5,10,2,6a73ht,Tutorial using a NARX to forecast time series data,https://www.reddit.com/r/MachineLearning/comments/6a73ht/tutorial_using_a_narx_to_forecast_time_series_data/,svpadd2,1494352760,,0,1
354,2017-5-10,2017,5,10,3,6a7euf,[D] Atrous Convolution vs Strided Convolution vs Pooling,https://www.reddit.com/r/MachineLearning/comments/6a7euf/d_atrous_convolution_vs_strided_convolution_vs/,guyfrom7up,1494355617,"Whats peoples opinion on how these techniques?  I've barely seen much talk on Atrous Convolution (I believe it's also called dilated convolution), but it seems like an interesting technique to have a larger receptive field without increasing number of parameters.  But, unlike Strided convolution and pooling, the feature map stays the same size as the input.  What are peoples experiences/opinions?",33,18
355,2017-5-10,2017,5,10,6,6a8bqk,BatchNorm is used everywhere. What is the difference between BatchNorm and Adaptive BatchNorm (AdaBN)?,https://www.reddit.com/r/MachineLearning/comments/6a8bqk/batchnorm_is_used_everywhere_what_is_the/,DavieTheAl,1494364395,,0,1
356,2017-5-10,2017,5,10,6,6a8c3f,TF Implementation of Fast-Rcnn. Why can't I get the same result ?,https://www.reddit.com/r/MachineLearning/comments/6a8c3f/tf_implementation_of_fastrcnn_why_cant_i_get_the/,[deleted],1494364493,[removed],0,1
357,2017-5-10,2017,5,10,6,6a8khj,Alternative Data and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6a8khj/alternative_data_and_machine_learning/,gregory_k,1494366773,,0,1
358,2017-5-10,2017,5,10,7,6a8tks,[D] Towards Anything2Vec,https://www.reddit.com/r/MachineLearning/comments/6a8tks/d_towards_anything2vec/,theciank,1494369126,,4,13
359,2017-5-10,2017,5,10,7,6a8y69,Comparing dense compute platforms for AI,https://www.reddit.com/r/MachineLearning/comments/6a8y69/comparing_dense_compute_platforms_for_ai/,jessiclr,1494370500,,0,1
360,2017-5-10,2017,5,10,8,6a90ty,[R] Dilated Residual Networks,https://www.reddit.com/r/MachineLearning/comments/6a90ty/r_dilated_residual_networks/,xternalz,1494371233,,3,16
361,2017-5-10,2017,5,10,8,6a92ls,Unsupervised Machine Learning Explained with GIFs,https://www.reddit.com/r/MachineLearning/comments/6a92ls/unsupervised_machine_learning_explained_with_gifs/,[deleted],1494371779,[deleted],0,1
362,2017-5-10,2017,5,10,8,6a94oi,[P] Unsupervised Machine Learning Explained with GIFs,https://www.reddit.com/r/MachineLearning/comments/6a94oi/p_unsupervised_machine_learning_explained_with/,dashee87,1494372406,,6,44
363,2017-5-10,2017,5,10,8,6a95j1,Market analyst Palihapitiya: IBM's Watson is a joke,https://www.reddit.com/r/MachineLearning/comments/6a95j1/market_analyst_palihapitiya_ibms_watson_is_a_joke/,[deleted],1494372646,[deleted],0,1
364,2017-5-10,2017,5,10,8,6a95xz,[D] Market analyst Palihapitiya: IBM's Watson is a joke,https://www.reddit.com/r/MachineLearning/comments/6a95xz/d_market_analyst_palihapitiya_ibms_watson_is_a/,rumblestiltsken,1494372778,,31,12
365,2017-5-10,2017,5,10,8,6a97pt,[N] New massive medical image dataset coming from Stanford (info via GTC17),https://www.reddit.com/r/MachineLearning/comments/6a97pt/n_new_massive_medical_image_dataset_coming_from/,drlukeor,1494373329,,38,480
366,2017-5-10,2017,5,10,8,6a9aqe,easily retrieve/load datasets for data science,https://www.reddit.com/r/MachineLearning/comments/6a9aqe/easily_retrieveload_datasets_for_data_science/,mynameisvinn,1494374316,,0,1
367,2017-5-10,2017,5,10,11,6aa3y3,What do you guys think of Sentdex's machine learning videos with python?,https://www.reddit.com/r/MachineLearning/comments/6aa3y3/what_do_you_guys_think_of_sentdexs_machine/,parswimcube,1494383518,[removed],0,1
368,2017-5-10,2017,5,10,11,6aa6f4,Questions about Variational auto-encoders cost term,https://www.reddit.com/r/MachineLearning/comments/6aa6f4/questions_about_variational_autoencoders_cost_term/,zalperst,1494384342,[removed],0,1
369,2017-5-10,2017,5,10,12,6aaa0e,Titanic Solution using Speedml. 70% fewer lines of code. From low 80% to top 20% on leaderboard.,https://www.reddit.com/r/MachineLearning/comments/6aaa0e/titanic_solution_using_speedml_70_fewer_lines_of/,manavsehgal,1494385531,,0,1
370,2017-5-10,2017,5,10,13,6aap0q,How does a Generator (GAN) create samples similar to the data space from a vector of random numbers?,https://www.reddit.com/r/MachineLearning/comments/6aap0q/how_does_a_generator_gan_create_samples_similar/,raltk,1494391013,[removed],0,1
371,2017-5-10,2017,5,10,15,6ab55r,"Mayflay Manual Sand Blasting Machine,Manual Sandblasting, Manual Sand Bl...",https://www.reddit.com/r/MachineLearning/comments/6ab55r/mayflay_manual_sand_blasting_machinemanual/,limingzhu,1494397970,,0,1
372,2017-5-10,2017,5,10,15,6ab5cg,(UK) Durham Police AI to help with custody decisions,https://www.reddit.com/r/MachineLearning/comments/6ab5cg/uk_durham_police_ai_to_help_with_custody_decisions/,elgraf,1494398050,,0,1
373,2017-5-10,2017,5,10,16,6abczi,Minimal PyTorch Implementation of CycleGAN and SGAN,https://www.reddit.com/r/MachineLearning/comments/6abczi/minimal_pytorch_implementation_of_cyclegan_and/,[deleted],1494401674,[deleted],0,1
374,2017-5-10,2017,5,10,16,6abd57,Cluster validation in unsupervised learning using R,https://www.reddit.com/r/MachineLearning/comments/6abd57/cluster_validation_in_unsupervised_learning_using/,kkulma,1494401739,,0,1
375,2017-5-10,2017,5,10,17,6abht3,What's Next For Virtual Assistants &amp; Deep Learning?,https://www.reddit.com/r/MachineLearning/comments/6abht3/whats_next_for_virtual_assistants_deep_learning/,reworksophie,1494404155,,0,1
376,2017-5-10,2017,5,10,18,6abu9s,Context-aware text generation : Hierarchical RNN vs. Memory network,https://www.reddit.com/r/MachineLearning/comments/6abu9s/contextaware_text_generation_hierarchical_rnn_vs/,gmkim90,1494410385,[removed],0,1
377,2017-5-10,2017,5,10,20,6ac2dm,"[N] Nvidia aims to train 100,000 developers in deep learning, AI technologies",https://www.reddit.com/r/MachineLearning/comments/6ac2dm/n_nvidia_aims_to_train_100000_developers_in_deep/,massiveattack778,1494414040,,2,1
378,2017-5-10,2017,5,10,20,6ac31h,"Proper use of BatchNorm in Keras, as opposed to Tensorflow",https://www.reddit.com/r/MachineLearning/comments/6ac31h/proper_use_of_batchnorm_in_keras_as_opposed_to/,DavieTheAl,1494414303,,0,1
379,2017-5-10,2017,5,10,20,6ac3r3,[D] Why does AlphaGo use an input feature plane that is only zeros?,https://www.reddit.com/r/MachineLearning/comments/6ac3r3/d_why_does_alphago_use_an_input_feature_plane/,sickasthma,1494414612,"I think I understand the other feature planes

http://imgur.com/a/PbvMg

but I don't see that a zeros-only plane has any effect. Why would they include this in their AI?",13,5
380,2017-5-10,2017,5,10,22,6acv4n,Does anybody recommend a machine configuration for deep learning?,https://www.reddit.com/r/MachineLearning/comments/6acv4n/does_anybody_recommend_a_machine_configuration/,fly200,1494424147,[removed],0,1
381,2017-5-10,2017,5,10,22,6acwd7,Minimal PyTorch Implementation of CycleGAN and SGAN,https://www.reddit.com/r/MachineLearning/comments/6acwd7/minimal_pytorch_implementation_of_cyclegan_and/,[deleted],1494424510,[deleted],0,1
382,2017-5-10,2017,5,10,22,6acwpc,[P] Minimal PyTorch implementation of CycleGAN and SGAN,https://www.reddit.com/r/MachineLearning/comments/6acwpc/p_minimal_pytorch_implementation_of_cyclegan_and/,[deleted],1494424625,[deleted],0,1
383,2017-5-10,2017,5,10,23,6acyv3,[R] [1705.03387] Generative Adversarial Trainer: Defense to Adversarial Perturbations with GAN,https://www.reddit.com/r/MachineLearning/comments/6acyv3/r_170503387_generative_adversarial_trainer/,downtownslim,1494425203,,6,7
384,2017-5-10,2017,5,10,23,6ad3gd,Top 15 Python Libraries for Data Science in 2017,https://www.reddit.com/r/MachineLearning/comments/6ad3gd/top_15_python_libraries_for_data_science_in_2017/,[deleted],1494426481,[deleted],0,1
385,2017-5-10,2017,5,10,23,6ad6f7,Writing a sentiment analysys in my home country,https://www.reddit.com/r/MachineLearning/comments/6ad6f7/writing_a_sentiment_analysys_in_my_home_country/,SpreadThatShit,1494427312,[removed],0,1
386,2017-5-11,2017,5,11,0,6adc2u,Future of Machine Learning in Finance,https://www.reddit.com/r/MachineLearning/comments/6adc2u/future_of_machine_learning_in_finance/,nitinkarma,1494428810,,0,1
387,2017-5-11,2017,5,11,0,6adex5,Recommendations on Supervised Signal Classification,https://www.reddit.com/r/MachineLearning/comments/6adex5/recommendations_on_supervised_signal/,p01ym47h,1494429548,[removed],0,1
388,2017-5-11,2017,5,11,0,6adgnm,Neural Networks Face Unexpected Problems in Analyzing Financial Data,https://www.reddit.com/r/MachineLearning/comments/6adgnm/neural_networks_face_unexpected_problems_in/,[deleted],1494430013,[deleted],0,1
389,2017-5-11,2017,5,11,0,6adha2,L2 Heatmap regression.,https://www.reddit.com/r/MachineLearning/comments/6adha2/l2_heatmap_regression/,[deleted],1494430180,[removed],0,1
390,2017-5-11,2017,5,11,0,6admkr,"Simple Questions Thread May 10, 2017",https://www.reddit.com/r/MachineLearning/comments/6admkr/simple_questions_thread_may_10_2017/,AutoModerator,1494431558,[removed],0,1
391,2017-5-11,2017,5,11,0,6adno7,Machine Learning using Instagram Images,https://www.reddit.com/r/MachineLearning/comments/6adno7/machine_learning_using_instagram_images/,khijazi,1494431844,,1,1
392,2017-5-11,2017,5,11,0,6ado09,[P] A Comprehensive Tutorial for Image Transforms in Pytorch,https://www.reddit.com/r/MachineLearning/comments/6ado09/p_a_comprehensive_tutorial_for_image_transforms/,megaman01232,1494431931,"I put together an in-depth tutorial to explain Transforms (Data Augmentation), the Dataset class, and the DataLoader class in Pytorch. I also show a ton of use cases for different transforms applied on Grayscale and Color images, along with Segmentation datasets where the same transform should be applied to both the input and target images.

I show how to do Affine transforms (rotation, translation, shear, zoom), some awesome Image-based transforms (saturation, brightness, contrast, gamma, grayscale). These transforms can be applied with pre-determined settings or randomly sampled from a range of values. I also show some cool utility transforms like type casting, converting to tensors, and going from CHW to HWC. 

Hopefully, this will close the gap between available data augmentation functions in tensorflow and those in pytorch.

In another tutorial soon, I will go in-depth on Datasets and DataLoaders, including how to make a Dataset for loading images from a CSV file which many Kagglers commonly ask for.

The tutorial requires the [torchsample package](https://github.com/ncullen93/torchsample) where all these custom transforms exist. Hopefully some of them will be included in the official pytorch package.

Here is a link the [Jupyer Notebook Tutorial](https://github.com/ncullen93/torchsample/blob/master/examples/Transforms%20with%20Pytorch%20and%20Torchsample.ipynb)

I think you'll find that understanding and making custom transforms will be quite easy after going through this tutorial :)",5,32
393,2017-5-11,2017,5,11,1,6adtzr,[P] Generating Hackernews Titles using Recurrent Neural Networks,https://www.reddit.com/r/MachineLearning/comments/6adtzr/p_generating_hackernews_titles_using_recurrent/,PiMaker101,1494433471,,0,2
394,2017-5-11,2017,5,11,1,6advzm,"Artificial Intelligence Body Gesture Detection in ""Nobody"" Wonder Girl.",https://www.reddit.com/r/MachineLearning/comments/6advzm/artificial_intelligence_body_gesture_detection_in/,scidem,1494434003,,0,1
395,2017-5-11,2017,5,11,2,6ae3z0,[N] Inside Volta: The Worlds Most Advanced Data Center GPU,https://www.reddit.com/r/MachineLearning/comments/6ae3z0/n_inside_volta_the_worlds_most_advanced_data/,SlowInFastOut,1494436050,,38,58
396,2017-5-11,2017,5,11,2,6aebk2,[P] Kullback-Leibler Divergence Explained,https://www.reddit.com/r/MachineLearning/comments/6aebk2/p_kullbackleibler_divergence_explained/,pmigdal,1494437986,,15,219
397,2017-5-11,2017,5,11,2,6aefns,[P] Region of interest pooling in TensorFlow  an example,https://www.reddit.com/r/MachineLearning/comments/6aefns/p_region_of_interest_pooling_in_tensorflow_an/,pmigdal,1494439068,,1,22
398,2017-5-11,2017,5,11,3,6aejxt,Darviz - A Deep Learning IDE from IBM,https://www.reddit.com/r/MachineLearning/comments/6aejxt/darviz_a_deep_learning_ide_from_ibm/,alekhka,1494440153,,0,1
399,2017-5-11,2017,5,11,3,6aeoa6,Automatically turn on/off Amazon GPU instances?,https://www.reddit.com/r/MachineLearning/comments/6aeoa6/automatically_turn_onoff_amazon_gpu_instances/,taewoo,1494441294,[removed],0,1
400,2017-5-11,2017,5,11,3,6aeoqg,[P] A List of Medical Datasets for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6aeoqg/p_a_list_of_medical_datasets_for_machine_learning/,pmigdal,1494441413,,8,84
401,2017-5-11,2017,5,11,3,6aerqm,Data Science + Journalism Workshop @ KDD 2017,https://www.reddit.com/r/MachineLearning/comments/6aerqm/data_science_journalism_workshop_kdd_2017/,ciolaamotore,1494442207,,0,1
402,2017-5-11,2017,5,11,4,6af251,"[N] Advances in Data Science, 2017 conference organized by Neil Lawrence in Manchester, UK on May 15",https://www.reddit.com/r/MachineLearning/comments/6af251/n_advances_in_data_science_2017_conference/,insider_7,1494444939,"Web:
http://www.ds-advances.org/

Programme:
http://www.ds-advances.org/program

Speakers including:

Overcoming Catastrophic Forgetting in Neural Nets Raia Hadsell, DeepMind

Automating Machine Learning Zoubin Ghahramani, University of Cambridge and Uber AI

Enabling open science and data science via software: scikit-learn Gal Varoquaux, INRIA (Sklearn dev)

Automatic Generation of Tile Maps Graham McNeill, Oxford Internet Institute, University of Oxford
",0,7
403,2017-5-11,2017,5,11,5,6af8kd,NVIDIA Volta GV100 GPU Unveiled,https://www.reddit.com/r/MachineLearning/comments/6af8kd/nvidia_volta_gv100_gpu_unveiled/,Phnyx,1494446624,,0,1
404,2017-5-11,2017,5,11,5,6afdk6,[N] Ubisoft's Star Trek Bridge Crew will be the first major game to use speech recognition and NLP in gameplay,https://www.reddit.com/r/MachineLearning/comments/6afdk6/n_ubisofts_star_trek_bridge_crew_will_be_the/,[deleted],1494447938,[deleted],0,1
405,2017-5-11,2017,5,11,5,6afifr,Differentiable Neural Computer (LIVE),https://www.reddit.com/r/MachineLearning/comments/6afifr/differentiable_neural_computer_live/,funmaster11,1494449215,,0,1
406,2017-5-11,2017,5,11,5,6afjlv,Caffe2 adds 16 bit floating point training support on the NVIDIA Volta platform,https://www.reddit.com/r/MachineLearning/comments/6afjlv/caffe2_adds_16_bit_floating_point_training/,turbocpp,1494449513,,0,1
407,2017-5-11,2017,5,11,6,6afq26,How does one get accepted into Google Brain Residency Program?,https://www.reddit.com/r/MachineLearning/comments/6afq26/how_does_one_get_accepted_into_google_brain/,[deleted],1494451259,[removed],0,1
408,2017-5-11,2017,5,11,6,6afs64,[D] Usable video superresolution projects?,https://www.reddit.com/r/MachineLearning/comments/6afs64/d_usable_video_superresolution_projects/,atomicthumbs,1494451832,"Is there any machine learning project that accomplishes video superresolution and has released usable code?  

I've got a very noisy black-and-white video I'd like to either upscale or denoise (would decide based on results), and I'm wondering if open-source ML solutions exist (with neural networks or otherwise) and would work better than traditional SR techniques. It's difficult to research these, since most of the results on Gitxiv and so on (understandably) focus on single-image neural SR.",3,2
409,2017-5-11,2017,5,11,6,6afsf3,Just got accepted into Udacity AI nanodegree. Is it worth the money?,https://www.reddit.com/r/MachineLearning/comments/6afsf3/just_got_accepted_into_udacity_ai_nanodegree_is/,hraun,1494451888,[removed],0,1
410,2017-5-11,2017,5,11,6,6afswm,[D] Is deep learning a crowded field yet?,https://www.reddit.com/r/MachineLearning/comments/6afswm/d_is_deep_learning_a_crowded_field_yet/,rantana,1494452039,"Honest opinion from people working in machine learning. Is deep learning a crowded field yet? Or is there still room to expand?

",11,0
411,2017-5-11,2017,5,11,6,6afxqo,Is there any ML algorithm focused on small amount of data?,https://www.reddit.com/r/MachineLearning/comments/6afxqo/is_there_any_ml_algorithm_focused_on_small_amount/,kddevelop,1494453399,[removed],2,1
412,2017-5-11,2017,5,11,7,6afzcn,[R] Selected Machine Learning Posters from GTC,https://www.reddit.com/r/MachineLearning/comments/6afzcn/r_selected_machine_learning_posters_from_gtc/,TheTwigMaster,1494453847,,4,29
413,2017-5-11,2017,5,11,7,6ag3nd,[D] GTC 2017 keynote &lt;-- starts at 2:40,https://www.reddit.com/r/MachineLearning/comments/6ag3nd/d_gtc_2017_keynote_starts_at_240/,evc123,1494455116,,0,4
414,2017-5-11,2017,5,11,8,6agck2,Question: machine learning tools for detecting image anomalies,https://www.reddit.com/r/MachineLearning/comments/6agck2/question_machine_learning_tools_for_detecting/,fgheorghe,1494457864,[removed],0,1
415,2017-5-11,2017,5,11,8,6agjj0,[D] Top 15 Python Libraries for Data Science in 2017,https://www.reddit.com/r/MachineLearning/comments/6agjj0/d_top_15_python_libraries_for_data_science_in_2017/,[deleted],1494460055,[deleted],0,1
416,2017-5-11,2017,5,11,9,6agpo6,[D] Would love some project suggestions and industry advice-- undergraduate student,https://www.reddit.com/r/MachineLearning/comments/6agpo6/d_would_love_some_project_suggestions_and/,atm_vestibule,1494461973,"Hey, 

I'm a third-year Electrical and Computer Engineering student and I'll likely be looking for full-time jobs in the Fall. Sticking with a B.S. for now but may come back down the line for an advanced degree.

I've generally worked on software or IoT in terms of industry experience (will be returning to Facebook for another internship this summer doing software/production eng. work, some analytics). 

Anyway, I've been doing a fair amount of machine learning lately and am getting pretty passionate about it. I've taken some classes, I'm leading a team on a video recognition project (CNN, LSTMs to classify short videos) and I've done some Kaggle competitions. 

Anyway, I have this summer to keep learning about data science and might take on a side project, as well as ask about side projects at work. 

What kind of things would be good to work on to build knowledge for interviews and a portfolio? Looking to apply to the Google Brain residency for example. 

Also, it seems tech companies are creating opportunities to join ML teams internally, such as FB, so would it make sense to stay in a software job and try to transition internally if I find myself getting more excited about it? 

tl;dr have three months, what should I learn (I've read Introduction to Statistical Learning by James, Witten, ...), what projects would be interesting, what companies or opportunities do you know of? 

Thanks! 

edit: added textbook name",5,3
417,2017-5-11,2017,5,11,9,6agr9b,How do I use a retrained tensorflow model via the terminal?,https://www.reddit.com/r/MachineLearning/comments/6agr9b/how_do_i_use_a_retrained_tensorflow_model_via_the/,idodankspatialalgos,1494462453,[removed],0,1
418,2017-5-11,2017,5,11,9,6agu0z,[P] How do I use a retrained tensorflow model via the terminal?,https://www.reddit.com/r/MachineLearning/comments/6agu0z/p_how_do_i_use_a_retrained_tensorflow_model_via/,idodankspatialalgos,1494463308,[removed],1,0
419,2017-5-11,2017,5,11,10,6ah18p,[R] [1705.03562] Deep Episodic Value Iteration for Model-based Meta-Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/6ah18p/r_170503562_deep_episodic_value_iteration_for/,zergylord,1494465585,,5,5
420,2017-5-11,2017,5,11,12,6ahl6h,1st IJCAI Workshop on Artificial Intelligence (Machine Learning) in Affective Computing,https://www.reddit.com/r/MachineLearning/comments/6ahl6h/1st_ijcai_workshop_on_artificial_intelligence/,hlyates,1494471885,[removed],0,1
421,2017-5-11,2017,5,11,12,6ahn8d,"Call for Papers: 1st IJCAI Workshop on AI (Machine Learning) in Affective Computing due May 27, 2017",https://www.reddit.com/r/MachineLearning/comments/6ahn8d/call_for_papers_1st_ijcai_workshop_on_ai_machine/,hlyates,1494472576,[removed],0,1
422,2017-5-11,2017,5,11,14,6ai46z,[D] RL Exploration Policies?,https://www.reddit.com/r/MachineLearning/comments/6ai46z/d_rl_exploration_policies/,normally_i_lurk,1494479142,"Hello,

In terms of exploration policies for RL, I only know of a few; the biggest one is epsilon greedy, and I recently learned about entropy-based loss functions as an alternative. Are there any other methods out there for this kind of thing?

Also, in a recent project I was experimenting with outputting probabilities of taking multiple binary actions (as opposed to outputting straight T/F for each action) in each state. The idea is that until the ""true"" probabilities converged, the randomness would lead to new states. Additionally, the probabilities would only converge if that particular action actually mattered; if a specific action mattered in the future, eventually it would propagate back and lead to convergence, otherwise it simply wouldn't converge on T/F.  Is this idea sound? Has anything similar been done before?",1,4
423,2017-5-11,2017,5,11,14,6ai839,Multi class classification with growing number of classes,https://www.reddit.com/r/MachineLearning/comments/6ai839/multi_class_classification_with_growing_number_of/,[deleted],1494480779,[removed],0,1
424,2017-5-11,2017,5,11,14,6aia6a,Predicting Emotion Based on Speech,https://www.reddit.com/r/MachineLearning/comments/6aia6a/predicting_emotion_based_on_speech/,fuck_manu,1494481602,[removed],0,1
425,2017-5-11,2017,5,11,15,6aie93,[D] Multi-class classification with growing number of classes - question,https://www.reddit.com/r/MachineLearning/comments/6aie93/d_multiclass_classification_with_growing_number/,Markus_lei22,1494483390,"Hey,
I have a multi-class classification problem where the algorithm should detect (and later on classify) new classes.

An example for such a task could be classifying if an image shows a dog or a cat. Furthermore, the model should be able to recognize that a goose doesn't fit into one of these two categories, thus create a new class.

[edit:] The specific task is to predict categories of articles

**Specific Questions:**

* How can the model detect new classes?
    - Some unsupervised clustering algorithm
    - When all classes are predicted by a value beyond a certain threshold?

* Is there a (proven) model, which can handle a growing number of classes to classify - without expensive retraining of all the other classes?
    - one vs all?
    - one-class?
    - something completely different?

I greatly appreciate every form of help and experiences you had with such a problem. Thank you in advance.

Here are two links where similar questions were asked, but (at least for me) not fully answered.

[Stackexchange](https://stats.stackexchange.com/questions/244073/streaming-multi-class-classification-with-growing-number-of-classes)

[Stackoverflow](http://stackoverflow.com/questions/34204700/multiclass-classification-growing-number-of-classes)
",7,15
426,2017-5-11,2017,5,11,16,6aiklh,Any working examples of using Google's new seq2seq code for other datasets?,https://www.reddit.com/r/MachineLearning/comments/6aiklh/any_working_examples_of_using_googles_new_seq2seq/,adammathias,1494486213,[removed],0,1
427,2017-5-11,2017,5,11,16,6ailoh,[R] Understanding deep learning requires re-thinking generalization,https://www.reddit.com/r/MachineLearning/comments/6ailoh/r_understanding_deep_learning_requires_rethinking/,Delthc,1494486718,,19,82
428,2017-5-11,2017,5,11,16,6ailud,[R][1705.03633] Inferring and Executing Programs for Visual Reasoning,https://www.reddit.com/r/MachineLearning/comments/6ailud/r170503633_inferring_and_executing_programs_for/,undefdev,1494486801,,5,40
429,2017-5-11,2017,5,11,17,6aivum,Question about STDP learning rule,https://www.reddit.com/r/MachineLearning/comments/6aivum/question_about_stdp_learning_rule/,Laurence-Lin,1494491829,[removed],0,1
430,2017-5-11,2017,5,11,17,6aixrq,Help in choosing and installing an external GPU to do deep learning with tensorlfow on a MBP?,https://www.reddit.com/r/MachineLearning/comments/6aixrq/help_in_choosing_and_installing_an_external_gpu/,pifof_the_third,1494492790,[removed],0,1
431,2017-5-11,2017,5,11,19,6aj61b,Help in juxtaposing Image Captioning Researches,https://www.reddit.com/r/MachineLearning/comments/6aj61b/help_in_juxtaposing_image_captioning_researches/,saxenauts,1494496842,[removed],0,1
432,2017-5-11,2017,5,11,19,6aj6f2,[D] Why is temporal difference only ever introduced in the context of reinforcement learning?,https://www.reddit.com/r/MachineLearning/comments/6aj6f2/d_why_is_temporal_difference_only_ever_introduced/,BigBlindBais,1494497020,"I have recently read an old document by R. Sutton, ""Learning to Predict by the Methods of Temporal Differences"" dated 1988.  Sutton claims that while temporal difference (TD) itself had been previously used, such uses were of an empirical nature, and that his article represents the first fundamentally theoretical analysis of TD performance, convergence and optimality properties.

In the article, Sutton argues that many prediction problems are of a sequential nature, listing examples like weather prediction, stock market prediction, and game-play evaluation.  In each of these settings, a temporal sequence of observations `[; (x_1, x_2, \ldots) ;]` are made before the outcome `[; y ;]` is observed at a later time.  The standard supervised learning (SL) approach for solving this type of problem would train a model by comparing (i.e. computing an error based on the difference between) the model's prediction at a certain time `[; f(x_t) ;]` and the outcome `[; y ;]` once it is revealed.  On the other hand, TD is introduced as an alternative strategy by which models are trained by comparing temporally adjacent predictions `[; f(x_t) ;]` and `[; f(x_{t+1}) ;]`.

While reading, I was really surprised by one particular aspect:  This article does not touch or even mention the topic of reinforcement learning (RL).  Rather, TD is discussed exclusively as a learning strategy to solve such type of dynamic/sequential (SL) prediction problems.  This represents IMHO a bit contrast wrt how TD is discussed in modern literature (including ML courses, tutorials and books).

This *shouldn't* have been a surprise:  I already knew about TD and, even in the context of RL, TD is only bothered with the problem of value prediction, and never with the control problem itself, and the TD learning procedure in RL is pretty much the same as the one discussed by Sutton.  And yet it was a surprise to me sheerly because of how strongly TD is associated with RL.  For example, I have *never* seen TD discussed in the SL section of a course, which I now think should definitely be the case.  I understand that the sequential nature of many RL problems are the perfect playing ground for TD, but this does not mean that there aren't fine domains in non-control/decision settings.

I'm trying to make a sense of how widespread this misconception is, and whether it was purely my own blind spot or not.  I've talked about this with a couple of post-docs in my group, both of whom work in RL:  One was not surprised to hear about TD purely in the context of SL, while the other one was a bit.

So how surprised are you about hearing of TD being a useful technique in its own rights outside of RL?
Poll:  http://www.strawpoll.me/12941077",13,9
433,2017-5-11,2017,5,11,19,6aj6mo,GPU Tech Conference: Best Demos by Nvidia CEO Jen-Hsun Huang,https://www.reddit.com/r/MachineLearning/comments/6aj6mo/gpu_tech_conference_best_demos_by_nvidia_ceo/,tiagomoraismorgado88,1494497122,,0,1
434,2017-5-11,2017,5,11,20,6ajjyv,Why do we need to many types of neural networks?,https://www.reddit.com/r/MachineLearning/comments/6ajjyv/why_do_we_need_to_many_types_of_neural_networks/,[deleted],1494502771,[deleted],0,1
435,2017-5-11,2017,5,11,22,6ak2o3,[R] Network dissection: quantifying interpretability,https://www.reddit.com/r/MachineLearning/comments/6ak2o3/r_network_dissection_quantifying_interpretability/,drlukeor,1494508980,,0,10
436,2017-5-11,2017,5,11,22,6ak5gy,AI Learns to Synthesize Pictures of Animals | Two Minute Papers,https://www.reddit.com/r/MachineLearning/comments/6ak5gy/ai_learns_to_synthesize_pictures_of_animals_two/,zorfbee,1494509835,,0,1
437,2017-5-11,2017,5,11,22,6ak5jp,Video: Why artificial intelligence will be humankind's final invention,https://www.reddit.com/r/MachineLearning/comments/6ak5jp/video_why_artificial_intelligence_will_be/,[deleted],1494509860,[deleted],0,1
438,2017-5-11,2017,5,11,23,6akc3k,[R] Exemplar-CNNs: an Information Maximization Derivation.,https://www.reddit.com/r/MachineLearning/comments/6akc3k/r_exemplarcnns_an_information_maximization/,fhuszar,1494511705,,3,15
439,2017-5-12,2017,5,12,0,6akod9,PyTorch Implementation of CycleGAN and SGAN for Domain Transfer,https://www.reddit.com/r/MachineLearning/comments/6akod9/pytorch_implementation_of_cyclegan_and_sgan_for/,[deleted],1494515098,[deleted],0,1
440,2017-5-12,2017,5,12,0,6akolp,[P] PyTorch Implementation of CycleGAN and SGAN for Domain Transfer,https://www.reddit.com/r/MachineLearning/comments/6akolp/p_pytorch_implementation_of_cyclegan_and_sgan_for/,yunjey,1494515146,,0,21
441,2017-5-12,2017,5,12,0,6akp66,"Noob question: What's the difference between machine learning, statistical learning and data mining?",https://www.reddit.com/r/MachineLearning/comments/6akp66/noob_question_whats_the_difference_between/,lordylordylordy,1494515295,[removed],0,1
442,2017-5-12,2017,5,12,0,6akrt3,"[P] Source code available for ""Deep Feature Flow for Video Recognition"" from MSRA",https://www.reddit.com/r/MachineLearning/comments/6akrt3/p_source_code_available_for_deep_feature_flow_for/,flyforlight,1494516024,,7,90
443,2017-5-12,2017,5,12,0,6aks0i,"[P] Source code available for ""Fully Convolutional Instance-aware Semantic Segmentation"" from MSRA",https://www.reddit.com/r/MachineLearning/comments/6aks0i/p_source_code_available_for_fully_convolutional/,flyforlight,1494516072,,3,73
444,2017-5-12,2017,5,12,0,6aks6j,One Tesla P100 vs Four GTX 1080 which one better for images ML ??,https://www.reddit.com/r/MachineLearning/comments/6aks6j/one_tesla_p100_vs_four_gtx_1080_which_one_better/,cherryMxMech,1494516122,[removed],0,1
445,2017-5-12,2017,5,12,1,6al1z5,Microsoft Windows Story Remix uses machine learning to make your videos look awesome,https://www.reddit.com/r/MachineLearning/comments/6al1z5/microsoft_windows_story_remix_uses_machine/,SeungJeon,1494518662,,0,1
446,2017-5-12,2017,5,12,1,6al559,"Maybe useful slides for an overview of Deep Learning techniques (Neural networks, CNNs, RNNs, and toolboxes)",https://www.reddit.com/r/MachineLearning/comments/6al559/maybe_useful_slides_for_an_overview_of_deep/,[deleted],1494519457,[deleted],0,1
447,2017-5-12,2017,5,12,1,6al8uy,Googles New AI Tool Turns Your Selfies Into Emojis,https://www.reddit.com/r/MachineLearning/comments/6al8uy/googles_new_ai_tool_turns_your_selfies_into_emojis/,cyprianfrancis,1494520392,,0,1
448,2017-5-12,2017,5,12,2,6allts,"I'm alright in stats, but I want to become fluent in it.",https://www.reddit.com/r/MachineLearning/comments/6allts/im_alright_in_stats_but_i_want_to_become_fluent/,[deleted],1494523669,[removed],0,1
449,2017-5-12,2017,5,12,2,6alo6q,[N] Neural Network-Generated Illustrations in Allo,https://www.reddit.com/r/MachineLearning/comments/6alo6q/n_neural_networkgenerated_illustrations_in_allo/,pmigdal,1494524252,,1,10
450,2017-5-12,2017,5,12,3,6am0wp,RobotBach: Composing music with LSTMs,https://www.reddit.com/r/MachineLearning/comments/6am0wp/robotbach_composing_music_with_lstms/,LolopoPro,1494527488,[removed],0,1
451,2017-5-12,2017,5,12,3,6am404,NVIDIA Launches GPU Cloud Platform to Simplify AI Development,https://www.reddit.com/r/MachineLearning/comments/6am404/nvidia_launches_gpu_cloud_platform_to_simplify_ai/,jlkinsel,1494528275,,0,1
452,2017-5-12,2017,5,12,4,6am7jh,[P] A Deep Reinforced Model for Abstractive Summarization,https://www.reddit.com/r/MachineLearning/comments/6am7jh/p_a_deep_reinforced_model_for_abstractive/,Flipper3,1494529210,,2,56
453,2017-5-12,2017,5,12,4,6am7w1,"[R] ""Sukiyaki in French style: A novel system for transformation of dietary patterns"", Kazama et al 2017",https://www.reddit.com/r/MachineLearning/comments/6am7w1/r_sukiyaki_in_french_style_a_novel_system_for/,gwern,1494529290,,1,9
454,2017-5-12,2017,5,12,4,6ami00,"[D]Machine Learning School Project, ideas needed!",https://www.reddit.com/r/MachineLearning/comments/6ami00/dmachine_learning_school_project_ideas_needed/,Raphen,1494531920,"(I didn't know where to tag the post in, so I tagged it under discussion)

Hello /r/MachineLearning,

At my school, every student has to do a project of their choice as a part of finishing school. Me and my project-partner have decided to do something with Machine Learning, but we are both not experienced with the subject. We both have a little bit of experience with Python but that's it. We have to put in a minimum amount of 80 hours into the project (including documentation). We are looking to have a project that would be easy enough to get into from a beginner level, but hard enough to actually reach those 80 hours (or more).
At first, we wanted to remake MarI/O (https://youtu.be/qv6UVOQ0F44), but we figured it would be too hard to accomplish without spending too much time on it.

Do you have any ideas what kind of program we could make?

Thanks in Advance!",3,0
455,2017-5-12,2017,5,12,5,6amqb2,What are good techniques to debug seq2seq LSTM time series models in TensorFlow?,https://www.reddit.com/r/MachineLearning/comments/6amqb2/what_are_good_techniques_to_debug_seq2seq_lstm/,m_alzantot,1494534084,[removed],0,1
456,2017-5-12,2017,5,12,5,6amqfb,Question: Mini-Batch SGD for Captioning with Multiple Explanations,https://www.reddit.com/r/MachineLearning/comments/6amqfb/question_minibatch_sgd_for_captioning_with/,sbarratt,1494534122,[removed],0,1
457,2017-5-12,2017,5,12,5,6amvfq,[D] GANs from extracted features,https://www.reddit.com/r/MachineLearning/comments/6amvfq/d_gans_from_extracted_features/,Staturecrane,1494535506,"Does anyone know of successfully training GANs on images' extracted features, like from a pretrained VGG, instead of their actual pixel data? It's been used for autoencoders, reconstruction, super-resolution and so forth. Extending that to GANs seems like an obvious choice, but perhaps not? Is there any reason the math wouldn't work for perceptual features instead of pixel data?",3,5
458,2017-5-12,2017,5,12,6,6an2lf,Getting into RL,https://www.reddit.com/r/MachineLearning/comments/6an2lf/getting_into_rl/,zfm2,1494537453,[removed],0,1
459,2017-5-12,2017,5,12,6,6an5sq,Streets' cracks images dataset,https://www.reddit.com/r/MachineLearning/comments/6an5sq/streets_cracks_images_dataset/,EscVM,1494538355,[removed],0,1
460,2017-5-12,2017,5,12,7,6ane0g,"""Hard Mixtures of Experts for Large Scale Weakly Supervised Vision"", Gross et al 2017",https://www.reddit.com/r/MachineLearning/comments/6ane0g/hard_mixtures_of_experts_for_large_scale_weakly/,gwern,1494540701,,1,1
461,2017-5-12,2017,5,12,7,6anki8,[Discussion] What do you all think of companies that specialize in preparing training data?,https://www.reddit.com/r/MachineLearning/comments/6anki8/discussion_what_do_you_all_think_of_companies/,cityred,1494542658,"I'm following the progress of companies such as Crowdflower, Samasource, and Mighty AI. My understanding is that they generally use people who aren't data scientists to clean/prepare data, which is then sold to clients. 



Data scientists I know have said that they'd be skeptical of the quality of data trained/cleaned/prepared by people who are not data scientists. 


I understand that, but I also figure that if funds are investing in these companies, there must be processes in place to maintain data integrity. 

Any thoughts?
",20,12
462,2017-5-12,2017,5,12,8,6anu7y,[D] Did I get too far ahead of myself?,https://www.reddit.com/r/MachineLearning/comments/6anu7y/d_did_i_get_too_far_ahead_of_myself/,Wocto,1494545735,"For the past 1.5 years I've been interning as an undergrad research engineer on ML, and I am getting results, and some of it is going to be published. From this perspective, it looks like I am doing quite ok, but in reality I have no idea what I am doing, and the paper(s) that I'll be publishing won't even be close to the quality of the papers that I'm reading. My understanding of ML algorithms is at a black box level, but I have a decent understanding of what approach I should take for a problem, and domain knowledge in the field that I'm applying ML to. However, my math understanding is terrible, and I can't even count to potato. I ignore the math problems and move on to problems that I am able to solve, but this severely limits my usefulness and I'm unable to reproduce most of the new research papers.

I came from a biology background, but I've been programming and reading up about comp sci topics ever since I was a kid. Never good at math, and that's the reason why I wasn't eligible for a math/compsci major, and had to self-study my way into this field. 

At this point I am uncertain whether I am just overwhelmed by this new field, and that I should just continue applying ML and hopefully learn and understand it this way, or that I will eventually hit a wall and get stuck as a half-assed biologist and half-assed computer scientist. Instead of continuing with getting practical experience, I could take a few steps back and formally enroll for math/comp sci courses for a couple of years and take the usual safe route. In the long term, I would like to end up a tech company as a research engineer, but I feel like if I don't get a degree in math/comp sci, I will never be confident in my math skills and have a hard time getting past technical interviews.

Thanks for taking the time to read this. What do you guys think?

edit: thanks for all the great answers!",64,100
463,2017-5-12,2017,5,12,10,6ao9kp,Is all of Regression problem has linear-shaped loss function?,https://www.reddit.com/r/MachineLearning/comments/6ao9kp/is_all_of_regression_problem_has_linearshaped/,soo9297,1494550807,[removed],0,1
464,2017-5-12,2017,5,12,12,6aozxt,Using Deep Learning at Scale in Twitters Timelines,https://www.reddit.com/r/MachineLearning/comments/6aozxt/using_deep_learning_at_scale_in_twitters_timelines/,urish,1494559928,,0,1
465,2017-5-12,2017,5,12,14,6apfh9,Predicting the next number in a sequence of 1s and 0s,https://www.reddit.com/r/MachineLearning/comments/6apfh9/predicting_the_next_number_in_a_sequence_of_1s/,mvalen,1494566128,[removed],0,1
466,2017-5-12,2017,5,12,15,6apsib,Convolutional Sequence to Sequence Learning,https://www.reddit.com/r/MachineLearning/comments/6apsib/convolutional_sequence_to_sequence_learning/,kazi_shezan,1494572189,,0,1
467,2017-5-12,2017,5,12,17,6aq0qk,[R] Learning to act by predicting the future (Using supervised learning instead of reinforcement learning),https://www.reddit.com/r/MachineLearning/comments/6aq0qk/r_learning_to_act_by_predicting_the_future_using/,Delthc,1494576360,,11,32
468,2017-5-12,2017,5,12,17,6aq6g7,Using spacy with the JVM.,https://www.reddit.com/r/MachineLearning/comments/6aq6g7/using_spacy_with_the_jvm/,[deleted],1494579469,[removed],0,1
469,2017-5-12,2017,5,12,18,6aqdd8,"[P] Explaining How a Deep Neural Network Trained with End-to-End Learning Steers a Car (Unity, Tensorflow)",https://www.reddit.com/r/MachineLearning/comments/6aqdd8/p_explaining_how_a_deep_neural_network_trained/,leonardoaraujosantos,1494582925,"Hi, while trying to get our heads around Deep learning me and my colleagues implemented a few demos using NVIDIA End-to-End Driverless car papers.

Basically we implemented on tensorflow and Unity an environment to train how to steer a car, and also the last paper on visualizing it's activation maps:

https://www.youtube.com/watch?v=PT8oToyV85w

https://www.youtube.com/watch?v=QJqdbJh9GoM

Python Notebook and project:
https://github.com/leonardoaraujosantos/DLMatFramework/blob/master/virtual/tensorDriver/notebooks/Show_Driving_Activation.ipynb
https://github.com/leonardoaraujosantos/DLMatFramework/tree/master/virtual/tensorDriver",22,140
470,2017-5-12,2017,5,12,19,6aqii6,"DEVOXX London,UK '17 - DeepLearning on IoT Sensor data on ApacheSpark",https://www.reddit.com/r/MachineLearning/comments/6aqii6/devoxx_londonuk_17_deeplearning_on_iot_sensor/,tiagomoraismorgado88,1494585299,,0,1
471,2017-5-12,2017,5,12,20,6aqnut,"FMA dataset: 100k songs, 1TB, 343 days of audio for music genre recognition and more",https://www.reddit.com/r/MachineLearning/comments/6aqnut/fma_dataset_100k_songs_1tb_343_days_of_audio_for/,m_deff,1494587642,,0,1
472,2017-5-12,2017,5,12,20,6aqoa0,"Slides for an introduction to deep learning (Neural networks, CNNs, RNNs, and toolboxes)",https://www.reddit.com/r/MachineLearning/comments/6aqoa0/slides_for_an_introduction_to_deep_learning/,yannael,1494587828,,0,1
473,2017-5-12,2017,5,12,20,6aqpd0,Need some advice on Udemy courses,https://www.reddit.com/r/MachineLearning/comments/6aqpd0/need_some_advice_on_udemy_courses/,plsms,1494588270,[removed],0,1
474,2017-5-12,2017,5,12,20,6aqq9p,Predict a time series with periodic patterns and detect anomalies,https://www.reddit.com/r/MachineLearning/comments/6aqq9p/predict_a_time_series_with_periodic_patterns_and/,niujin,1494588660,[removed],0,1
475,2017-5-12,2017,5,12,20,6aqu0e,[P] Smith Waterman Distance for feature extraction in NLP,https://www.reddit.com/r/MachineLearning/comments/6aqu0e/p_smith_waterman_distance_for_feature_extraction/,CL4DSOFT,1494590029,,0,15
476,2017-5-12,2017,5,12,21,6aqzk3,Some Lesser-Known Deep Learning Libraries,https://www.reddit.com/r/MachineLearning/comments/6aqzk3/some_lesserknown_deep_learning_libraries/,socialmindai,1494592128,,0,1
477,2017-5-12,2017,5,12,22,6arg96,[D] Applications of complex numbers in ML,https://www.reddit.com/r/MachineLearning/comments/6arg96/d_applications_of_complex_numbers_in_ml/,xristaforante,1494597506,"In the EURNN paper, the authors (IIRC) note that the use of complex numbers is unusual in ML. Their experiments and the previous work that they build on seem to suggest that the complex domain is very valuable, although I don't know how much this aspect contributes to their overall results. Are there any recent explorations into the use of complex numbers in deep learning?",12,16
478,2017-5-12,2017,5,12,23,6arjxe,Is there anyone here who works at Element AI?,https://www.reddit.com/r/MachineLearning/comments/6arjxe/is_there_anyone_here_who_works_at_element_ai/,[deleted],1494598502,[removed],0,1
479,2017-5-12,2017,5,12,23,6arq7w,[P] CNNs &amp; Dealing with Overfitting,https://www.reddit.com/r/MachineLearning/comments/6arq7w/p_cnns_dealing_with_overfitting/,[deleted],1494600331,[deleted],0,1
480,2017-5-12,2017,5,12,23,6arsod,[P] Steps to Reduce Overfitting (+ more on CNNs),https://www.reddit.com/r/MachineLearning/comments/6arsod/p_steps_to_reduce_overfitting_more_on_cnns/,rruizen,1494601022,,1,0
481,2017-5-13,2017,5,13,0,6arult,"This is a collection of notes I've written on writing, testing, and debugging computation graphs while learning Theano.",https://www.reddit.com/r/MachineLearning/comments/6arult/this_is_a_collection_of_notes_ive_written_on/,senarvi,1494601537,,0,1
482,2017-5-13,2017,5,13,0,6arvow,"Hi r/machinelearning , Can someone explain what's going on with the initialization in this paper: https://arxiv.org/pdf/1511.07122.pdf",https://www.reddit.com/r/MachineLearning/comments/6arvow/hi_rmachinelearning_can_someone_explain_whats/,shriphani,1494601826,[removed],0,1
483,2017-5-13,2017,5,13,0,6as0ab,Weight clamping as implicit network architecture definition,https://www.reddit.com/r/MachineLearning/comments/6as0ab/weight_clamping_as_implicit_network_architecture/,warmsnail,1494603118,"Hey,

I've been wondering some things about various neural network architectures and I have a question.

**TLDR;**

Can all neural network architectures (recurrent, convolutional, GAN etc.) be described simply as a computational graph with fully connected layers where a subset of the trainable weights are clamped together (ie. they must have the same value)? Is there something missing in this description?

**Not TLDR;**

Lots of different deep learning papers go on to great lengths to describe some sort of new neural network architecture and at a first glance, the differences can seem really huge. Some of the architectures seem to be only applicable to some domains and inherently, different than others.
But I've learned some new things and it got me wondering.

I've learned that a convolutional layer in a neural network is pretty much the same thing as a fully connected one, except some of the weights are zero and the other ones are set to have the same value (in a specified way) so that the end results semantically describes a ""filter"" moving around the picture and capturing the dot product similarity.

The recurrent neural network can be also thought of a huge fully connected layer over all time steps, except that all the weights that correspond to different time steps are equal. Those weights are just the usual vanilla RNN/LSTM cell.

The automatic differentiation just normally computes all the gradients and applies the gradient update rule for a certain weight to *all* the weights that are supposed to share the same value.
This then represents a form of regularization; bias that helps train the network for a specified task (RNN: sequences, CNN: images).

GAN could also be described in a similar way, where weights are updated just for a subset of the network (although that seems to be generally known for GANs).

So to state my question again, is any part of what I've said wrong? I'm asking because I've never seen such a description of a neural network (computational graph, regularization in the form of weight clamping) and I'm wondering are there any resources that shed more light on it? 
Is there something here that I'm missing?

Thank you!

**EDIT**: I posted a clarification and expansion of ideas in one of the comments here.

",16,3
484,2017-5-13,2017,5,13,0,6as5hv,Artificial Intelligence Big Bang! NVIDIA's GPU Conference 2017 Highlights in 12 min,https://www.reddit.com/r/MachineLearning/comments/6as5hv/artificial_intelligence_big_bang_nvidias_gpu/,scidem,1494604581,,0,1
485,2017-5-13,2017,5,13,1,6ascs8,Machine Learning libraries with lesser code verbosity?,https://www.reddit.com/r/MachineLearning/comments/6ascs8/machine_learning_libraries_with_lesser_code/,pybokeh,1494606570,[removed],0,1
486,2017-5-13,2017,5,13,1,6asdin,[R] Inferring and Executing Programs for Visual Reasoning (implementation),https://www.reddit.com/r/MachineLearning/comments/6asdin/r_inferring_and_executing_programs_for_visual/,brannondorsey,1494606762,,0,28
487,2017-5-13,2017,5,13,1,6ashn8,Has anyone done any research work on the implications of adversarial examples and numerical approximations?,https://www.reddit.com/r/MachineLearning/comments/6ashn8/has_anyone_done_any_research_work_on_the/,[deleted],1494607919,[removed],0,1
488,2017-5-13,2017,5,13,1,6ashtb,[D] Any research work done on implications of adversarial examples to numerical approximations?,https://www.reddit.com/r/MachineLearning/comments/6ashtb/d_any_research_work_done_on_implications_of/,[deleted],1494607961,[deleted],1,0
489,2017-5-13,2017,5,13,2,6aslr9,"Based on your personal work/research experience, what's the 5-10 year future of ML? Will it really become commonplace at every company for nearly every process, or will it remain a niche (but effective) methodology?",https://www.reddit.com/r/MachineLearning/comments/6aslr9/based_on_your_personal_workresearch_experience/,talyen42,1494609014,[removed],0,1
490,2017-5-13,2017,5,13,3,6at5oa,Challenges in machine learning for Trust,https://www.reddit.com/r/MachineLearning/comments/6at5oa/challenges_in_machine_learning_for_trust/,chiragmahapatra,1494614416,,0,1
491,2017-5-13,2017,5,13,4,6atcuk,[D] A potential Solution to Varying Length Softmax,https://www.reddit.com/r/MachineLearning/comments/6atcuk/d_a_potential_solution_to_varying_length_softmax/,CaHoop,1494616435,"tl:dr Some back-of-the-envelope ideas about a dynamically scaled softmax.


Has there been any work into creating a length-scaled softmax? I couldn't find any with a quick google.

Here is a good motivating (and quite contrived) example:

Suppose you have a seq2seq model which uses an attention mechanism for the decoder. The mechanism looks at the previous states of the decoder (similar to [1]), and computes a weight for each previous hidden states. Let's say the attention module produces values between [-1, 1] representing the importance of that hidden state to the current one.

This attention mechanism is then used on a varying length of weights: Early on in the decoding step, the sequence of previous hidden states is quite small, whereas the later steps will have significantly longer sequences of weights.


Typically these weights are then softmaxed to produce the final weights used to form the attention vector.
An important thing to note here is that *attention mechanisms are typically meant to pick out only a few parts of a sequence*. We hope for trained models to produce attention coefficients where many values are close to 0, and only a few values which are not close to zero.


Now lets consider this mechanism when it only has three previous hidden states. The trained model has learned to single out only the hidden states that pertain to the current hidden state.

For example, the unnormalized weights could be:

[-1, 1, -1].

Here the attention mechanism is ""telling"" us that only the second value is worth considering. The softmaxed version of these becomes:

[0.107, 0.787, 0.107]

Not bad, but we would still get some noise from the first and last hidden state. multiplying the unnormalized weights by a constant could help. If we multiply the unnormalized weights by 2 for example we get:

[0.018, 0.965, 0.018]

Which is much closer to our desired values.


Now lets consider a point when the decoder has already produced 200 hidden states. At this point, the decoder identifies ten values in the sequence that pertain to the 201st hidden state, so the attention weights before softmax are:

[-1, -1, -1, .... 1, -1, ...1, -1.... ]

with 10 1s and 190 -1s. Ideally we would like the softmax of the 1s to be close to 1/10, and the -1s close to 0. In fact, the softmaxed value for the 1s is 0.0280, where the -1s are 0.0038. In this case, the -1 values occupy 72% of the mass of the weights!

If we used the previous constant of 2, the 1s then become 0.074 and the -1s become 0.001. The mass of the -1s is 25%, which is a lot of noise to add to the attention vector.

The problem with using a larger constant, say 3 or 4, is that although this might solve the longer case, it makes the short sequence case very volatile, with values slightly larger than zero being much larger after softmax than values just below zero.  


If we take the case of an attention module for a sequence of length l, for which we expect m values in the sequence to be high (close to 1) and (l-m) values in the sequence to be low (close to -1), we can compute a constant k which aims to scale the unnormalized weights. We need to add another term, epsilon, which represents the mass that exists outside the high values after softmax.

[Here is the maths](http://i.imgur.com/juzgNIM.jpg) for those interested. the final value is:
```
k = 0.5 ln(
        (1-epsilon)(l-m)/
        epsilon*m
    )
```


There are several issues to be discussed with this:

* What is the value of m? Could this just be a function of the length (e.g. m = sqrt(l)).

* Does this contrived example bear any resemblance to real attention models?

* How much could this improve performance? Due to the logarithmic scaling of k wrt. length, it might turn out that using a trained constant for scaling might work just as well. In fact, some papers use a trained constant to scale the softmax of weights.




references:
* [1] [A Deep Reinforced Model for Abstractive Summarization](https://arxiv.org/pdf/1705.04304.pdf)
",10,18
492,2017-5-13,2017,5,13,4,6atimb,Adaptive learning and item response theory,https://www.reddit.com/r/MachineLearning/comments/6atimb/adaptive_learning_and_item_response_theory/,poilpy,1494618058,[removed],0,1
493,2017-5-13,2017,5,13,4,6atj1o,[Dictionary learning/PCA] What is the benefit of promoting sparsity in the coefficient matrix?,https://www.reddit.com/r/MachineLearning/comments/6atj1o/dictionary_learningpca_what_is_the_benefit_of/,cpsii13,1494618193,[removed],0,1
494,2017-5-13,2017,5,13,5,6att3w,Good algorithm/framework to use for this task?,https://www.reddit.com/r/MachineLearning/comments/6att3w/good_algorithmframework_to_use_for_this_task/,[deleted],1494621083,[removed],0,1
495,2017-5-13,2017,5,13,5,6atx1o,Cool ML ideas for Beer Reviews dataset,https://www.reddit.com/r/MachineLearning/comments/6atx1o/cool_ml_ideas_for_beer_reviews_dataset/,LinearModel,1494622206,[removed],0,1
496,2017-5-13,2017,5,13,6,6au9id,"Halla is a app that uses advanced machine learning to match user's to the perfect food. Download the app at, please feel free to provide any feedback here https://itunes.apple.com/us/app/halla-find-food-with-friends/id1154304380?mt=8",https://www.reddit.com/r/MachineLearning/comments/6au9id/halla_is_a_app_that_uses_advanced_machine/,HallaFood,1494625963,,0,1
497,2017-5-13,2017,5,13,7,6aubkq,[N] Pathology finder challenge,https://www.reddit.com/r/MachineLearning/comments/6aubkq/n_pathology_finder_challenge/,bfelbo,1494626609,"There's a new competition about detection of dental pathologies in x-rays. Support the doctors by finding these pathologies such as periodontitis, granulomas, cysts and tumors to win $4000!

https://www.topcoder.com/challenge-details/30057606/?type=develop&amp;noncache=true",1,7
498,2017-5-13,2017,5,13,7,6aud6m,Strange but recurring learning curves,https://www.reddit.com/r/MachineLearning/comments/6aud6m/strange_but_recurring_learning_curves/,SuperFX,1494627091,[removed],0,1
499,2017-5-13,2017,5,13,8,6auw2q,"[P] Andreessen Horowitz' new ""AI Playbook""",https://www.reddit.com/r/MachineLearning/comments/6auw2q/p_andreessen_horowitz_new_ai_playbook/,sup6978,1494633332,,4,158
500,2017-5-13,2017,5,13,10,6avd12,Adding entities to dataset,https://www.reddit.com/r/MachineLearning/comments/6avd12/adding_entities_to_dataset/,bipedaljellyfish,1494639500,[removed],0,1
501,2017-5-13,2017,5,13,13,6avym5,[D] TensorFlow client for Kotlin released with kotlin-native 0.2,https://www.reddit.com/r/MachineLearning/comments/6avym5/d_tensorflow_client_for_kotlin_released_with/,[deleted],1494648076,[deleted],0,1
502,2017-5-13,2017,5,13,13,6aw4ea,"[D] Disregarding time complexity, would OnevAll or AllvAll ensemble classifiers be the best to use if no single algorithm is doing well?",https://www.reddit.com/r/MachineLearning/comments/6aw4ea/d_disregarding_time_complexity_would_onevall_or/,mofoss,1494650585,"I have data given to me and am told to learn a classifier. Tried Random Forest since it does the job, but in this case I was hitting ~85% accuracy. SVM did poor with a RBF kernel. 

In these cases, disregarding time complexity, is All v All, or One v All the best route to go? I have a hard time believing single classifiers can do better than one averaged over multiple classifiers.",7,2
503,2017-5-13,2017,5,13,14,6aw6z5,[D] Does Bash (or Linux Distros) on Windows mean that we can use Deep Learning libraries without hassle on Windows?,https://www.reddit.com/r/MachineLearning/comments/6aw6z5/d_does_bash_or_linux_distros_on_windows_mean_that/,nonap_,1494651773,,11,4
504,2017-5-13,2017,5,13,14,6aw8ik,"[D] Reddit, do you use autoencoders in practice?",https://www.reddit.com/r/MachineLearning/comments/6aw8ik/d_reddit_do_you_use_autoencoders_in_practice/,Reiinakano,1494652452,"If you do, what is a common use case for them? 

Are they generally helpful as a more  ""advanced"" form of dimensionality reduction before applying more traditional ML methods?

The Keras blog states they are rarely used in practice. Why so? Seems like it could be a natural next step in feature reduction if something like PCA proves insufficient. ",30,28
505,2017-5-13,2017,5,13,15,6awg2g,[D] ICML Decisions Discussion Mega Thread,https://www.reddit.com/r/MachineLearning/comments/6awg2g/d_icml_decisions_discussion_mega_thread/,nonap_,1494656215,,36,6
506,2017-5-13,2017,5,13,15,6awhwh,ICML result,https://www.reddit.com/r/MachineLearning/comments/6awhwh/icml_result/,dodonote,1494657209,[removed],1,1
507,2017-5-13,2017,5,13,16,6awmy1,Do orthogonally initialized weights have to be orthogonal across both dimensions?,https://www.reddit.com/r/MachineLearning/comments/6awmy1/do_orthogonally_initialized_weights_have_to_be/,mscheifer,1494659980,[removed],0,1
508,2017-5-13,2017,5,13,16,6awnua,[Question] [Caffe] Proper data layer for image to image?,https://www.reddit.com/r/MachineLearning/comments/6awnua/question_caffe_proper_data_layer_for_image_to/,[deleted],1494660494,[removed],0,1
509,2017-5-13,2017,5,13,16,6awp4w,"[Question, Caffe] Proper data layer for image to image?",https://www.reddit.com/r/MachineLearning/comments/6awp4w/question_caffe_proper_data_layer_for_image_to/,[deleted],1494661236,[removed],0,1
510,2017-5-13,2017,5,13,17,6awthe,Distance learning master programs in Europe?,https://www.reddit.com/r/MachineLearning/comments/6awthe/distance_learning_master_programs_in_europe/,STNP,1494663869,[removed],0,1
511,2017-5-13,2017,5,13,18,6awxif,[D] Automated Machine Learning @ Airbnb,https://www.reddit.com/r/MachineLearning/comments/6awxif/d_automated_machine_learning_airbnb/,KnightAdz,1494666216,,6,40
512,2017-5-13,2017,5,13,18,6awyed,[P] A multi-agent system based on human communication,https://www.reddit.com/r/MachineLearning/comments/6awyed/p_a_multiagent_system_based_on_human_communication/,inboble,1494666764,,0,6
513,2017-5-13,2017,5,13,18,6awzcn,[R] Anyone else attending the International Joint Conference on Neural Networks (IJCNN 2017)?,https://www.reddit.com/r/MachineLearning/comments/6awzcn/r_anyone_else_attending_the_international_joint/,murakamifanboy,1494667342,,5,13
514,2017-5-13,2017,5,13,22,6axsub,[D] Does anyone else not really do any of their own projects?,https://www.reddit.com/r/MachineLearning/comments/6axsub/d_does_anyone_else_not_really_do_any_of_their_own/,rfukui,1494681844,"I'm doing a PhD in ML, I love it and I love my research but as my research is theoretical, I feel like I'm just doing applied math. 

I've done the odd solo project, and dipped into the odd Kaggle competition but I never really feel super excited about applying anything or building something new, and as soon as I finished them I forgot all about them. I just love the inner workings behind what's happening. 

I really want to start a practical project that I'm excited about, but I'm not sure where I'd start. Is it just a lack of inspiration? A lack of first-hand experience in creating something practical and new?

Sorry for rambling, just wondering if there are others who feel the same. ",116,112
515,2017-5-13,2017,5,13,23,6ay2ac,[D] /r/MachineLearning should do an unconference,https://www.reddit.com/r/MachineLearning/comments/6ay2ac/d_rmachinelearning_should_do_an_unconference/,rantana,1494685318,"Reject, Accept or In Submission? Why not post your paper here?

This field is moving too fast to wait 6 months to see the great research that's happening (and that's assuming the review process isn't noisy). 

/r/MachineLearning has already been an unofficial mini-conference for the papers submitted here. I find the best discussion happens when the authors show up to answer questions and address comments. It seems like this is happening mostly by coincidence. Someone will post a paper they like and the authors will happen to notice and engage in the discussion.

It stands to reason that if this happens so often by chance, there's enough critical mass of users here to create something more official. Let's get authors posting their work and discussing it on /r/MachineLearning, sort of like a virtual poster session.",18,173
516,2017-5-14,2017,5,14,1,6aynxr,I want to start Machine Learning and I have a fairly good hold on regular coding.,https://www.reddit.com/r/MachineLearning/comments/6aynxr/i_want_to_start_machine_learning_and_i_have_a/,Rafan2106,1494692438,[removed],0,1
517,2017-5-14,2017,5,14,1,6aypfo,Don't know where to start with ML,https://www.reddit.com/r/MachineLearning/comments/6aypfo/dont_know_where_to_start_with_ml/,[deleted],1494692915,[removed],0,1
518,2017-5-14,2017,5,14,1,6aysrp,Need Help with Designing a Neural Net Algorithm or/and Architecture,https://www.reddit.com/r/MachineLearning/comments/6aysrp/need_help_with_designing_a_neural_net_algorithm/,[deleted],1494693964,[removed],0,1
519,2017-5-14,2017,5,14,4,6azplj,ML Prompt: A ML program that takes a wikipedia article about a native tribe as input and returns a Disney movie script as output,https://www.reddit.com/r/MachineLearning/comments/6azplj/ml_prompt_a_ml_program_that_takes_a_wikipedia/,[deleted],1494704203,[removed],0,1
520,2017-5-14,2017,5,14,4,6azrma,[D] ML Prompt: An algorithm that takes a wikipedia article about a native people as input and returns a Disney movie script as output,https://www.reddit.com/r/MachineLearning/comments/6azrma/d_ml_prompt_an_algorithm_that_takes_a_wikipedia/,[deleted],1494704833,[removed],1,0
521,2017-5-14,2017,5,14,5,6azu6t,[N] MuJoCo Student licence is now Free!,https://www.reddit.com/r/MachineLearning/comments/6azu6t/n_mujoco_student_licence_is_now_free/,internet_ham,1494705638,,49,28
522,2017-5-14,2017,5,14,5,6azyjy,Best way to Learn Machining?,https://www.reddit.com/r/MachineLearning/comments/6azyjy/best_way_to_learn_machining/,KeenTD,1494707006,[removed],0,1
523,2017-5-14,2017,5,14,9,6b126w,[N] Facebook releases code for its fast ConvNet machine translation model,https://www.reddit.com/r/MachineLearning/comments/6b126w/n_facebook_releases_code_for_its_fast_convnet/,MasterEpictetus,1494720226,,5,183
524,2017-5-14,2017,5,14,11,6b1l89,What feature can I use to classify object in an image patch?,https://www.reddit.com/r/MachineLearning/comments/6b1l89/what_feature_can_i_use_to_classify_object_in_an/,RavlaAlvar,1494727409,[removed],0,1
525,2017-5-14,2017,5,14,11,6b1qv1,[D] numpy.einsum on GPU?,https://www.reddit.com/r/MachineLearning/comments/6b1qv1/d_numpyeinsum_on_gpu/,kh40tika,1494729636,"I often find certain linear operations being very difficult to be factored down into `matmul`, or the batched version. Often ends up doing sequential loops on CPU, or some ugly reshapes that eats up GPU memory. In general, I think the best solution is to make a kernel generator. Take the sum expression, and optionally some constraints as input, generate specialized kernel code. The generator should try to optimize both execution speed and memory consumption.

This is a *very nontrivial* task. Is there any existing library implementation does it or something similar? Or at least, related research papers?",13,8
526,2017-5-14,2017,5,14,15,6b2ma4,Machine learning documentation created and edited by the Stack Overflow community,https://www.reddit.com/r/MachineLearning/comments/6b2ma4/machine_learning_documentation_created_and_edited/,[deleted],1494743908,[deleted],0,1
527,2017-5-14,2017,5,14,19,6b38b9,Nonlinear Dynamic Boltzmann Machines for Time-Series Prediction (online energy-efficient for edge devices),https://www.reddit.com/r/MachineLearning/comments/6b38b9/nonlinear_dynamic_boltzmann_machines_for/,BoltzmannGuy,1494757009,[removed],0,1
528,2017-5-14,2017,5,14,21,6b3lfp,[D]Have you ever felt tired when running after deep learning wave?,https://www.reddit.com/r/MachineLearning/comments/6b3lfp/dhave_you_ever_felt_tired_when_running_after_deep/,huyhcmut,1494763899,[removed],1,0
529,2017-5-14,2017,5,14,21,6b3qik,dewarping and stitching 360 photos,https://www.reddit.com/r/MachineLearning/comments/6b3qik/dewarping_and_stitching_360_photos/,mynameisvinn,1494766249,,0,1
530,2017-5-14,2017,5,14,22,6b3vxn,Citation impact applied to contents of religious literatures,https://www.reddit.com/r/MachineLearning/comments/6b3vxn/citation_impact_applied_to_contents_of_religious/,[deleted],1494768519,[removed],0,1
531,2017-5-14,2017,5,14,22,6b3y3i,Citation impact applied to religious literatures,https://www.reddit.com/r/MachineLearning/comments/6b3y3i/citation_impact_applied_to_religious_literatures/,[deleted],1494769387,[removed],0,1
532,2017-5-14,2017,5,14,23,6b42xt,[D] Citation impact for contents of religious literatures,https://www.reddit.com/r/MachineLearning/comments/6b42xt/d_citation_impact_for_contents_of_religious/,tomekanco,1494771227,"(rewritten)

A friend asked me a question: 
The book has some many stories, which are the most relevant?

This made me wonder if this question has been approached with data-driven methods.

For scientific papers, there are citation impacts. 
There is a source, and the number of references to it. 

Could a simular method be used to create a heatmap for the contents of religious books?

***

There is a central node, and secondary nodes. 
These are related to the central node if there is a citation.
If so we have an edge.

In the case of academic papers, this is a straightforward problem.

The central node is static. 
Secondary sources are well defined.
Citations (references) are supposed to be explicit &amp; formalized. 
So edges are known and determining them requires no additional calculation.

Religious books are different.

For one they often exist in multiple versions, the source is actually a set of nodes.
Historically, this problem has been partially handled by using canons (numerical indexes), which could also help here.
There are slight variations in the indexes, but mappings could be created with limited effort.
The central node could be a union of indexed versions.

It would be impractical to sort trough all secondary sources.

A rough method could be to look at a large set of pages, and scan each one for an element from a group of keywords,
plus an index format. Then check if there is a significant substring match in the page and the related element in central node.
If so there is an edge.

Additional impact analysis could be performed by comparing the results from different choises of keywords, or more broadly speaking:
categorising the references: sect, language, year, etc...

***

Do you know about existing research in this direction, if so, could you give me a pointer?
(such as [Sefaria] (http://www.sefaria.org/explore/Genesis))

Does the approach described above seem sensible?

Any suggestions which math to use in order to perform the text matching part efficiently?






",4,4
533,2017-5-14,2017,5,14,23,6b43qy,"Nvidia CEO: Software is eating the world, but AI is going to eat software",https://www.reddit.com/r/MachineLearning/comments/6b43qy/nvidia_ceo_software_is_eating_the_world_but_ai_is/,[deleted],1494771516,[deleted],0,1
534,2017-5-14,2017,5,14,23,6b45gh,"Nvidia CEO: Software is eating the world, but AI is going to eat software",https://www.reddit.com/r/MachineLearning/comments/6b45gh/nvidia_ceo_software_is_eating_the_world_but_ai_is/,didi778,1494772139,,0,2
535,2017-5-15,2017,5,15,1,6b4ogz,De-Embedding as output in Keras?,https://www.reddit.com/r/MachineLearning/comments/6b4ogz/deembedding_as_output_in_keras/,butWhoWasBee,1494778441,[removed],0,1
536,2017-5-15,2017,5,15,2,6b54ny,LambdaML - Generic MLE-based ML library,https://www.reddit.com/r/MachineLearning/comments/6b54ny/lambdaml_generic_mlebased_ml_library/,true_ham_sandwich,1494783481,[removed],0,1
537,2017-5-15,2017,5,15,3,6b5c3n,A self-driving neural network does some invasive maneuvers.,https://www.reddit.com/r/MachineLearning/comments/6b5c3n/a_selfdriving_neural_network_does_some_invasive/,kingburrito666,1494785737,,0,1
538,2017-5-15,2017,5,15,4,6b5lm7,Anybody accepted as a finalist for Nat Friedman's AI Grant?,https://www.reddit.com/r/MachineLearning/comments/6b5lm7/anybody_accepted_as_a_finalist_for_nat_friedmans/,minflynn,1494788537,[removed],0,1
539,2017-5-15,2017,5,15,4,6b5mf3,Blogs explaining ML/AI research?,https://www.reddit.com/r/MachineLearning/comments/6b5mf3/blogs_explaining_mlai_research/,Gear5th,1494788779,[removed],0,1
540,2017-5-15,2017,5,15,5,6b64u4,[D] Nvidia K80 training time performance,https://www.reddit.com/r/MachineLearning/comments/6b64u4/d_nvidia_k80_training_time_performance/,Cock-tail,1494794411,"Has anybody used this GPU instance?

How long does it take to train a model on ImageNet or MSCOCO using this GPU? What batch sizes do you typically use?

I need to evaluate my funds and time.

Thank you.",4,6
541,2017-5-15,2017,5,15,5,6b65uz,"Having fun with machine learning, Node and Cloud 66",https://www.reddit.com/r/MachineLearning/comments/6b65uz/having_fun_with_machine_learning_node_and_cloud_66/,pmz,1494794745,,0,1
542,2017-5-15,2017,5,15,7,6b6p2t,[R] Quantum Entanglement in Neural Network States (PDF),https://www.reddit.com/r/MachineLearning/comments/6b6p2t/r_quantum_entanglement_in_neural_network_states/,[deleted],1494801042,[deleted],12,81
543,2017-5-15,2017,5,15,8,6b73et,Images of varied sizes as input (Keras),https://www.reddit.com/r/MachineLearning/comments/6b73et/images_of_varied_sizes_as_input_keras/,[deleted],1494805927,[removed],0,1
544,2017-5-15,2017,5,15,9,6b7cxd,Best recruiter for machine learning / AI?,https://www.reddit.com/r/MachineLearning/comments/6b7cxd/best_recruiter_for_machine_learning_ai/,djc1000,1494809257,[removed],0,1
545,2017-5-15,2017,5,15,12,6b7z91,Image Dataset!,https://www.reddit.com/r/MachineLearning/comments/6b7z91/image_dataset/,EscVM,1494817269,[removed],0,1
546,2017-5-15,2017,5,15,12,6b82m6,"Marc Andreessen: ""Software is eating the world."" Nvidia CEO: ""AI is going to eat software.""",https://www.reddit.com/r/MachineLearning/comments/6b82m6/marc_andreessen_software_is_eating_the_world/,webneek,1494818503,,0,1
547,2017-5-15,2017,5,15,14,6b8it1,"Use Deep Learning, Machine Learning to Diagnose Injury - Healthcare",https://www.reddit.com/r/MachineLearning/comments/6b8it1/use_deep_learning_machine_learning_to_diagnose/,[deleted],1494825155,[deleted],0,1
548,2017-5-15,2017,5,15,14,6b8oc5,Neural network gets only 50% good prediction on test data,https://www.reddit.com/r/MachineLearning/comments/6b8oc5/neural_network_gets_only_50_good_prediction_on/,cretu97,1494827652,[removed],1,1
549,2017-5-15,2017,5,15,15,6b8sy4,What open source DL/ML project needs contributors?,https://www.reddit.com/r/MachineLearning/comments/6b8sy4/what_open_source_dlml_project_needs_contributors/,[deleted],1494829715,[removed],0,1
550,2017-5-15,2017,5,15,16,6b92d4,Robust Face Detection that detects in profile faces too.,https://www.reddit.com/r/MachineLearning/comments/6b92d4/robust_face_detection_that_detects_in_profile/,[deleted],1494834276,[removed],0,1
551,2017-5-15,2017,5,15,16,6b92fm,mInference demo: ImageNet convnets inside a Web browser (WebAssembly/Asm.js/PNaCl),https://www.reddit.com/r/MachineLearning/comments/6b92fm/minference_demo_imagenet_convnets_inside_a_web/,[deleted],1494834324,[deleted],0,1
552,2017-5-15,2017,5,15,18,6b9fm3,What open source DL/ML project needs contributors?,https://www.reddit.com/r/MachineLearning/comments/6b9fm3/what_open_source_dlml_project_needs_contributors/,bhaangh,1494841315,"I am free during the summer and am looking do some meaningful open source contribution. 

Do you have anything in mind you would like to see implemented or is there any project which needs contributors?",35,37
553,2017-5-15,2017,5,15,18,6b9g03,What is recommended way to deal with compound nouns in word embeddings and topic modeling?,https://www.reddit.com/r/MachineLearning/comments/6b9g03/what_is_recommended_way_to_deal_with_compound/,[deleted],1494841530,[removed],0,1
554,2017-5-15,2017,5,15,18,6b9hkf,What is the recommended way to deal with compound nouns in word embeddings and topic modeling?,https://www.reddit.com/r/MachineLearning/comments/6b9hkf/what_is_the_recommended_way_to_deal_with_compound/,NLPGuy,1494842316,[removed],0,1
555,2017-5-15,2017,5,15,19,6b9jrr,MachineLabs - Run your Machine Learning cod ein the browser,https://www.reddit.com/r/MachineLearning/comments/6b9jrr/machinelabs_run_your_machine_learning_cod_ein_the/,[deleted],1494843379,[deleted],0,1
556,2017-5-15,2017,5,15,19,6b9lbv,MachineLabs - Run your Machine Learning code in the browser,https://www.reddit.com/r/MachineLearning/comments/6b9lbv/machinelabs_run_your_machine_learning_code_in_the/,PascalPrecht,1494844143,,0,1
557,2017-5-15,2017,5,15,19,6b9orw,Answers Portals - Machine Learning Assignment Help,https://www.reddit.com/r/MachineLearning/comments/6b9orw/answers_portals_machine_learning_assignment_help/,Answersportals,1494845809,[removed],0,1
558,2017-5-15,2017,5,15,20,6b9qy1,Salesforce created an algorithm that automatically summarizes text using machine learning,https://www.reddit.com/r/MachineLearning/comments/6b9qy1/salesforce_created_an_algorithm_that/,sharaisley,1494846767,,0,1
559,2017-5-15,2017,5,15,21,6ba23c,[R] You said that? Synthesizing videos of talking faces from audio,https://www.reddit.com/r/MachineLearning/comments/6ba23c/r_you_said_that_synthesizing_videos_of_talking/,amirjamaludin,1494850995,,15,54
560,2017-5-15,2017,5,15,21,6ba3af,mInference demo: ImageNet convnets inside a Web browser (WebAssembly/Asm.js/PNaCl),https://www.reddit.com/r/MachineLearning/comments/6ba3af/minference_demo_imagenet_convnets_inside_a_web/,[deleted],1494851452,[deleted],0,1
561,2017-5-15,2017,5,15,21,6ba3b4,[D] Contrasting approaches of recall/precision trade off in SVM classification,https://www.reddit.com/r/MachineLearning/comments/6ba3b4/d_contrasting_approaches_of_recallprecision_trade/,Zman420,1494851459,"Hi all.

As you know, the usual approach is to separate the data into train/validation/test sets (e.g 50,25,25%), or, how I prefer to do it, a training set of 75% and the testing set of 25%, and do 10 fold cross-validation within the training set to estimate optimal parameters, before training on the full training set and testing against the [blind] test set.

You can then vary the threshold of the SVM output to create a different recall/precision (or sensitivity/specificity, if you prefer) trade off, for example when generating receiver operating characteristic plots.  You can do this directly with the raw svm decimal outputs, or with the probability trick (e.g '-b 1' flag in LibSVM) to map the outputs from to a 'probability' from 0 to 1.

However, I find with this approach that a 'probability' threshold from the model of say 0.25 actually gives a higher actual precision on my test data...of say 0.3.

The other approach is of course to just use the probability directly...so with a probability threshold of 0.25, I would expect the minimum precision on real life data to be 0.25.

I am inclined to believe scenario 1 more - because it's derived from an actual 'bind' test set.  If you were to use scenario 2 for your real world data (just taking straight probabilities from your model), then you've essentially not 'tested' your model at all...you've simply trained on a large training set with some cross validation, and using those overfitted/underfitted values directly.

Thoughts?


Tl;dr:How can we believe any SVM probability outputs from a model when those probabilities are derived solely from the training data - so may be subject to bias from overfitting? Wouldn't you need a separate test set to derive probabilities?",2,1
562,2017-5-15,2017,5,15,21,6ba4ex,"Is a contender to neural networks likely to emerge for audio, image, video, translation?",https://www.reddit.com/r/MachineLearning/comments/6ba4ex/is_a_contender_to_neural_networks_likely_to/,_bakauguu,1494851864,[removed],0,1
563,2017-5-15,2017,5,15,22,6ba9qh,How to train linear regression model effectively in RapidMiner?,https://www.reddit.com/r/MachineLearning/comments/6ba9qh/how_to_train_linear_regression_model_effectively/,rexlow0823,1494853626,,0,1
564,2017-5-15,2017,5,15,22,6bagnx,[D] Machine Learning and security applications,https://www.reddit.com/r/MachineLearning/comments/6bagnx/d_machine_learning_and_security_applications/,tryndisskilled,1494855904,"Do you know of any ML algorithm applied to a security problem in the real world? Such as authentication with digit/face recognition for instance.

Can we expect a ML algorithm to perform exceptionally well and satisfy the very harsh error rates needed in security applications? For example under 1/10000 or false acceptance &amp; 1/1000 of false rejection for a digital authentication algorithm? I'm guessing these kind of problems would be related to One-Shot Learning a lot since we usually would not have a lot of information about the user.",14,10
565,2017-5-15,2017,5,15,22,6bahiw,Detecting Adversarial Samples Using Density Ratio Estimates,https://www.reddit.com/r/MachineLearning/comments/6bahiw/detecting_adversarial_samples_using_density_ratio/,lvdp00,1494856194,,0,1
566,2017-5-15,2017,5,15,23,6balii,Google event for Machine Learning and AI startups in NYC,https://www.reddit.com/r/MachineLearning/comments/6balii/google_event_for_machine_learning_and_ai_startups/,milvalchal,1494857413,,0,1
567,2017-5-15,2017,5,15,23,6bau6k,Looking for pre-trained CNN sound-classifier,https://www.reddit.com/r/MachineLearning/comments/6bau6k/looking_for_pretrained_cnn_soundclassifier/,lookDroerImOnReddit,1494859953,[removed],0,1
568,2017-5-16,2017,5,16,1,6bbadh,How to write a program to locate an orange in the image?,https://www.reddit.com/r/MachineLearning/comments/6bbadh/how_to_write_a_program_to_locate_an_orange_in_the/,rousse101,1494864506,[removed],0,1
569,2017-5-16,2017,5,16,1,6bbam1,HD Larry Bird,https://www.reddit.com/r/MachineLearning/comments/6bbam1/hd_larry_bird/,Stone_d_,1494864580,[removed],0,1
570,2017-5-16,2017,5,16,2,6bbz4k,MachineLabs  Run Machine Learning Code in the Browser,https://www.reddit.com/r/MachineLearning/comments/6bbz4k/machinelabs_run_machine_learning_code_in_the/,cburgdorf,1494871092,,0,1
571,2017-5-16,2017,5,16,3,6bc535,Learning Machine Learning: Too Early?,https://www.reddit.com/r/MachineLearning/comments/6bc535/learning_machine_learning_too_early/,[deleted],1494872709,[removed],0,1
572,2017-5-16,2017,5,16,3,6bc8b0,[R] A Generative Model of People in Clothing,https://www.reddit.com/r/MachineLearning/comments/6bc8b0/r_a_generative_model_of_people_in_clothing/,[deleted],1494873573,[deleted],0,1
573,2017-5-16,2017,5,16,3,6bc8ul,[R] Curiosity-driven Exploration by Self-supervised Prediction,https://www.reddit.com/r/MachineLearning/comments/6bc8ul/r_curiositydriven_exploration_by_selfsupervised/,wordbag,1494873729,,19,73
574,2017-5-16,2017,5,16,3,6bcb5p,"[R] ""Imagination improves Multimodal Translation"", Elliott &amp; Kadar 2017",https://www.reddit.com/r/MachineLearning/comments/6bcb5p/r_imagination_improves_multimodal_translation/,gwern,1494874343,,0,6
575,2017-5-16,2017,5,16,4,6bciam,Blog post on Posterior Sampling for Reinforcement Learning.,https://www.reddit.com/r/MachineLearning/comments/6bciam/blog_post_on_posterior_sampling_for_reinforcement/,sudeepraja,1494876283,,0,1
576,2017-5-16,2017,5,16,4,6bcjfm,Performing Hyperparameter Optimization with Amazon Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6bcjfm/performing_hyperparameter_optimization_with/,alexcmu,1494876605,,7,27
577,2017-5-16,2017,5,16,5,6bd362,[D] How much detail should be left to appendices?,https://www.reddit.com/r/MachineLearning/comments/6bd362/d_how_much_detail_should_be_left_to_appendices/,zergylord,1494881962,"With the NIPS deadline fast approaching, the 8 page limit is becoming more and more daunting. I'm trying to motivate and introduce two variants of a new algorithm, and then show the results of two experiments -- something has to give. What is the general consensus on how much you can push into an appendix without making the paper itself hopelessly vague? For example, is leaving algorithm blocks to an appendix frowned upon? Is it better gloss over algorithm details, experiment details, or details of prior work you're building on?",2,1
578,2017-5-16,2017,5,16,6,6bd8yg,[D] Anuj Gupta | Building Continuous Learning Systems,https://www.reddit.com/r/MachineLearning/comments/6bd8yg/d_anuj_gupta_building_continuous_learning_systems/,_alphamaximus_,1494883525,,1,9
579,2017-5-16,2017,5,16,7,6bdmgr,Anybody prove what GANs are convergent yet?,https://www.reddit.com/r/MachineLearning/comments/6bdmgr/anybody_prove_what_gans_are_convergent_yet/,mr_throwaway_1234,1494887496,[removed],0,1
580,2017-5-16,2017,5,16,8,6bdycg,What ML blogs do you read except reddit?,https://www.reddit.com/r/MachineLearning/comments/6bdycg/what_ml_blogs_do_you_read_except_reddit/,dmpetrov,1494891345,[removed],0,1
581,2017-5-16,2017,5,16,9,6be4f9,"[R][1704.00109] Snapshot Ensembles: Train 1, get M for free",https://www.reddit.com/r/MachineLearning/comments/6be4f9/r170400109_snapshot_ensembles_train_1_get_m_for/,downtownslim,1494893245,,30,55
582,2017-5-16,2017,5,16,9,6be9s0,[P] Roboschool,https://www.reddit.com/r/MachineLearning/comments/6be9s0/p_roboschool/,wei_jok,1494894956,,6,69
583,2017-5-16,2017,5,16,10,6begna,bo dng iu ha,https://www.reddit.com/r/MachineLearning/comments/6begna/bo_dng_iu_ha/,lynhan2911,1494897254,,0,1
584,2017-5-16,2017,5,16,12,6bf58k,What is the difference between YOLO and YOLO9000?,https://www.reddit.com/r/MachineLearning/comments/6bf58k/what_is_the_difference_between_yolo_and_yolo9000/,missionary0,1494905629,[removed],0,1
585,2017-5-16,2017,5,16,13,6bffkb,SEO guided by neural network?,https://www.reddit.com/r/MachineLearning/comments/6bffkb/seo_guided_by_neural_network/,commander-worf,1494909551,[removed],0,1
586,2017-5-16,2017,5,16,15,6bfydi,[D] Contrastive loss with Siamese LSTM's gradient underflow,https://www.reddit.com/r/MachineLearning/comments/6bfydi/d_contrastive_loss_with_siamese_lstms_gradient/,FutureIsMine,1494917873,"I've been recently experimenting with contrastive loss as a loss function for using an LSTM as an encoder for paragraphs. My approach is to have an LSTM with 2 layers be the encoder, which is used on both bodies of text. I then use Cosine similarity as my distance function. While experimenting with using both MSE and Constrastive loss, I've found that MSE seems to have a bigger gradient, or at least thats what tensorboard will show me, which means that my models tend to learn faster and produce better results than using Constrastive loss. This is something I've found surprising, and Im looking to ask the community to see who's had similar or differing experiences. Im certainly interested in how [Neculoiu, Et all](http://anthology.aclweb.org/W16-1617) achieved their state of the art results, I suspect it could be the problem they tackle, as they've got to work with very short job titles whilst an entire article has many paragraphs. ",3,3
587,2017-5-16,2017,5,16,16,6bfz58,best way to ensemble two sets of GMMs?,https://www.reddit.com/r/MachineLearning/comments/6bfz58/best_way_to_ensemble_two_sets_of_gmms/,[deleted],1494918228,[removed],0,1
588,2017-5-16,2017,5,16,16,6bfzeh,[R] correct way to integrate multiple GMMs for classification?,https://www.reddit.com/r/MachineLearning/comments/6bfzeh/r_correct_way_to_integrate_multiple_gmms_for/,anonDogeLover,1494918343,"Without going into the details of why exactly I must do this, I have four GMMs (two sets for two classes), and I need to integrate their predictions. Two of them are trained on two classes from dataset A, and the other two on dataset B. To be clear, the datasets (A and B) are different, but the class labels are the same (let's say ""cat"" and ""dog"" images for simplicity). You could think of dataset A and B as just being two sets of dog and cat images, for which I learn GM densities.

Using just the first two for example, the models (in scikit-learn) can return either probability or LL of a new test point. I can then compare these values for the two cat and dog densities and choose the larger of the two to classify. I can do this with the second set of GMMs too.

What I want to do is sort of integrate the two sets of models. One way I assume this can be done is to simply average the ultimate categorical predictions they make, but I'd like to do this a bit less hacky. It's not clear to me that one of these is the regularizing ""prior"" in respect to the other, since both may be of comparable confidence.

Does anyone know how I can think about this more formally? Should I multiply the two LLs for the single new test datapoint? Multiply the probabilities instead? It also seems like finding some sort of optimal weighting of the two would be in order.

Edit: Thanks everyone for the advice!! :-)",11,9
589,2017-5-16,2017,5,16,16,6bfzuy,Speedml is a Python package to speed start machine learning projects.,https://www.reddit.com/r/MachineLearning/comments/6bfzuy/speedml_is_a_python_package_to_speed_start/,manavsehgal,1494918536,,0,1
590,2017-5-16,2017,5,16,16,6bg5lz,[D] Alexnet hyper parameters in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/6bg5lz/d_alexnet_hyper_parameters_in_tensorflow/,mkreddy48,1494921408,"Has anyone trained Alexnet in TensorFlow from scratch ? I need the set of hyper parameters (initial_leraning_rate, learning_rate_decay, optimizer,weight decay etc.) that resulted in the reported accuracies (top-1--&gt; 57%,top-5--&gt; 80%). I have tried initial_learning_rate=0.01, learning_rate_decay=0.926 step down every 2 epochs, optimizer=momentum, weight decay=1e-4. This model gave top-1 accuracy ~ 50%,top-5 accuracy ~ 70%. I am trying to train the network given in TF-slim (https://github.com/tensorflow/models/blob/master/slim/nets/alexnet.py). Any help would be appreciated.",3,2
591,2017-5-16,2017,5,16,20,6bgutg,Picasso: A free open-source visualizer for CNNs [P],https://www.reddit.com/r/MachineLearning/comments/6bgutg/picasso_a_free_opensource_visualizer_for_cnns_p/,pointmetotheinternet,1494933715,,2,164
592,2017-5-16,2017,5,16,20,6bgv61,Machine Learning Intelligence For Micro-Moment Shopping,https://www.reddit.com/r/MachineLearning/comments/6bgv61/machine_learning_intelligence_for_micromoment/,teamrework,1494933852,,0,1
593,2017-5-16,2017,5,16,21,6bh9du,[D] A bunch of cheap old PC's at my thrift store. Is there a way to rig these up in a way that do really fast NN training via parallel computing over a couple PCs?,https://www.reddit.com/r/MachineLearning/comments/6bh9du/d_a_bunch_of_cheap_old_pcs_at_my_thrift_store_is/,PervertWhenCorrected,1494938962,,10,0
594,2017-5-16,2017,5,16,22,6bhcle,Mkr Autonics,https://www.reddit.com/r/MachineLearning/comments/6bhcle/mkr_autonics/,automationmkr,1494940010,,1,1
595,2017-5-16,2017,5,16,22,6bhd51,KDD 2017 review discussion thread,https://www.reddit.com/r/MachineLearning/comments/6bhd51/kdd_2017_review_discussion_thread/,lvdp00,1494940166,[removed],0,1
596,2017-5-16,2017,5,16,22,6bhdp3,[N] IBM Watson helps Korean aircraft mechanics,https://www.reddit.com/r/MachineLearning/comments/6bhdp3/n_ibm_watson_helps_korean_aircraft_mechanics/,algaewolf,1494940352,,0,0
597,2017-5-16,2017,5,16,22,6bhi83,Comparing binary files?,https://www.reddit.com/r/MachineLearning/comments/6bhi83/comparing_binary_files/,Duende3,1494941850,[removed],0,1
598,2017-5-16,2017,5,16,22,6bhjy6,"[D] Does anyone here work at Element AI? If so, what are your experiences? How does it look research-wise?",https://www.reddit.com/r/MachineLearning/comments/6bhjy6/d_does_anyone_here_work_at_element_ai_if_so_what/,roamer_and_lurker,1494942406,"I've read glaring reviews at glassdoor.com and I am wondering whether anyone here has a first-hand experience with Element AI
I'd love to know more about this company. ",5,10
599,2017-5-16,2017,5,16,23,6bhxnt,[D] How to know if an idea has been developed before?,https://www.reddit.com/r/MachineLearning/comments/6bhxnt/d_how_to_know_if_an_idea_has_been_developed_before/,aboelashba7_GHOST,1494946450,I am new to the field of machine learning and i have been thinking about developing some new ideas in relation to optimizing linear regressions and maximizing training set generalization errors. Is there a way to search the current literature to find out if ideas were already done instead of finding out 3 months later when I am about to publish?,9,16
600,2017-5-17,2017,5,17,0,6bi2cu,Best way to find subgroups (clustering if applicable) using user provided interest tags?,https://www.reddit.com/r/MachineLearning/comments/6bi2cu/best_way_to_find_subgroups_clustering_if/,random65431,1494947722,[removed],0,1
601,2017-5-17,2017,5,17,0,6bi4yf,"The Machine Learning Canvas plays a crucial role in the solution design process. Its a remarkably simple technique for clearly defining the objectives, scope and outcomes of a project.",https://www.reddit.com/r/MachineLearning/comments/6bi4yf/the_machine_learning_canvas_plays_a_crucial_role/,meganameliasmith,1494948452,,0,1
602,2017-5-17,2017,5,17,0,6bi6np,[D] G-learning: Taming the noise in reinforcement learning via soft updates,https://www.reddit.com/r/MachineLearning/comments/6bi6np/d_glearning_taming_the_noise_in_reinforcement/,jaromiru,1494948913,"I'll refer to this paper:

**Taming the noise in reinforcement learning via soft updates**

Roy Fox, Ari Pakman, Naftali Tishby, 2015

https://arxiv.org/abs/1512.08562
_____
Hi, it seems this *G-learning* received a little attention. I wonder, why it hasn't been explored more, e.g. in DQN domain? It seems it could alleviate the Q learning from it's maximization bias, comparably to double Q-learning. 

The major idea seems to be, that the update rule for G function (analogy of Q function):

    G(s, a) -&gt; r + gamma * mellowmax( G(s_, *) )
where 

    mellowmax( x ) = 1/beta * log( sum_i [ e^(beta*x_i) ]
and s_ is the next state after selecting action a

(i borrowed mellowmax definition from https://arxiv.org/abs/1612.05628)

The policy is defined as 

    pi_g(s) = softmax( G(s) )

compare to *Q-learning* where

    Q(s, a) -&gt; r + gamma * max Q(s_, *)

and it's policy

    pi_q(s) ~ deterministically select action argmax_a( Q(s, *) )

(I simplified prior policy rho mentioned in the paper into an uniform policy)",5,7
603,2017-5-17,2017,5,17,0,6bibob,Exponential Memory in the Feynman Machine,https://www.reddit.com/r/MachineLearning/comments/6bibob/exponential_memory_in_the_feynman_machine/,[deleted],1494950275,[deleted],0,1
604,2017-5-17,2017,5,17,1,6bicfo,[D] Keras vs PyTorch,https://www.reddit.com/r/MachineLearning/comments/6bicfo/d_keras_vs_pytorch/,andyandy16,1494950486,"Just wondering what people's thoughts are on PyTorch vs Keras? E.g.

1. Do you use one or the other completely, or do you both dependent on task?
2. Is PyTorch much more tricky than Keras (e.g. could you code faster in Keras than in PyTorch)?
3. What about in the longer term? Is one better for a wider range of activities (e.g. mobile, robotics, more complicated networks,...)?

Thanks!",29,47
605,2017-5-17,2017,5,17,1,6bifm0,[D] Imbalanced Datasets,https://www.reddit.com/r/MachineLearning/comments/6bifm0/d_imbalanced_datasets/,gregory_k,1494951326,,5,8
606,2017-5-17,2017,5,17,1,6bioke,[R] Robots that Learn (OpenAI),https://www.reddit.com/r/MachineLearning/comments/6bioke/r_robots_that_learn_openai/,Teleavenger,1494953709,,29,66
607,2017-5-17,2017,5,17,2,6bj19w,[R] Exponential Memory in the Feynman Machine,https://www.reddit.com/r/MachineLearning/comments/6bj19w/r_exponential_memory_in_the_feynman_machine/,fergbyrne,1494956919,,3,2
608,2017-5-17,2017,5,17,3,6bjaj4,A Reddit Dataset for Understanding Online Discussions By Google,https://www.reddit.com/r/MachineLearning/comments/6bjaj4/a_reddit_dataset_for_understanding_online/,blacklightpy,1494959354,,0,1
609,2017-5-17,2017,5,17,3,6bjdyf,Using Machine Learning to change the way we wear clothes,https://www.reddit.com/r/MachineLearning/comments/6bjdyf/using_machine_learning_to_change_the_way_we_wear/,weseklund,1494960272,,0,1
610,2017-5-17,2017,5,17,4,6bjjtf,Tensorflow iPython Notebook Tutorials,https://www.reddit.com/r/MachineLearning/comments/6bjjtf/tensorflow_ipython_notebook_tutorials/,adeshpande3,1494961870,[removed],0,1
611,2017-5-17,2017,5,17,4,6bjlji,Too late to jump into ML?,https://www.reddit.com/r/MachineLearning/comments/6bjlji/too_late_to_jump_into_ml/,Daneye77,1494962313,[removed],0,1
612,2017-5-17,2017,5,17,4,6bjm5w,Visual Domain Adaptation Challenge 2017,https://www.reddit.com/r/MachineLearning/comments/6bjm5w/visual_domain_adaptation_challenge_2017/,nkaushik1,1494962492,,0,1
613,2017-5-17,2017,5,17,6,6bkgfo,[P] Basic introduction to machine learning and the use of gradient descent.,https://www.reddit.com/r/MachineLearning/comments/6bkgfo/p_basic_introduction_to_machine_learning_and_the/,Xochipilli,1494970871,,6,18
614,2017-5-17,2017,5,17,6,6bkj8b,[D] What is the best approach to apply machine learning to classify whether you will like X based on previous X likes/dislikes from a small sample set?,https://www.reddit.com/r/MachineLearning/comments/6bkj8b/d_what_is_the_best_approach_to_apply_machine/,mr-jaime,1494971657,[removed],4,1
615,2017-5-17,2017,5,17,7,6bkmok,[N] Matt from Numenta will be on AMA.,https://www.reddit.com/r/MachineLearning/comments/6bkmok/n_matt_from_numenta_will_be_on_ama/,nocortex,1494972673,,3,9
616,2017-5-17,2017,5,17,7,6bknbn,[1511.07289] Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs) (2016),https://www.reddit.com/r/MachineLearning/comments/6bknbn/151107289_fast_and_accurate_deep_network_learning/,[deleted],1494972870,[deleted],0,1
617,2017-5-17,2017,5,17,7,6bkngh,[R] [1511.07289] Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs) (2016),https://www.reddit.com/r/MachineLearning/comments/6bkngh/r_151107289_fast_and_accurate_deep_network/,[deleted],1494972912,[deleted],0,0
618,2017-5-17,2017,5,17,7,6bknhd,Suggestions for research in the field of Sports Engineering,https://www.reddit.com/r/MachineLearning/comments/6bknhd/suggestions_for_research_in_the_field_of_sports/,bill_hatkins,1494972921,[removed],0,1
619,2017-5-17,2017,5,17,7,6bknkd,AMD Vega for ML,https://www.reddit.com/r/MachineLearning/comments/6bknkd/amd_vega_for_ml/,[deleted],1494972945,[deleted],1,1
620,2017-5-17,2017,5,17,7,6bkot6,[D] AMD Vega for ML,https://www.reddit.com/r/MachineLearning/comments/6bkot6/d_amd_vega_for_ml/,siblbombs,1494973315,"AMD just announced they will be shipping their new Vega gpu in late June, it should be interesting to get some competition in the hardware space. 

[FP 16/32 Tflops](https://i.imgur.com/kVW2tgo.png)

[Deepbench comparison](http://i.imgur.com/G68sd0Y.jpg)",19,21
621,2017-5-17,2017,5,17,7,6bkqhc,Local Methods in High Dimension Question,https://www.reddit.com/r/MachineLearning/comments/6bkqhc/local_methods_in_high_dimension_question/,CircuitBeast,1494973802,[removed],0,1
622,2017-5-17,2017,5,17,7,6bkw0c,[D] org.ideal.theory.wwidew.net,https://www.reddit.com/r/MachineLearning/comments/6bkw0c/d_orgidealtheorywwidewnet/,jlind0,1494975477,,32,1
623,2017-5-17,2017,5,17,9,6bla0q,Extracting prediction-level predictor relative importance,https://www.reddit.com/r/MachineLearning/comments/6bla0q/extracting_predictionlevel_predictor_relative/,AxelUrbiz,1494979810,[removed],0,1
624,2017-5-17,2017,5,17,9,6blab3,[1705.05665] Learning Image Relations with Contrast Association Networks,https://www.reddit.com/r/MachineLearning/comments/6blab3/170505665_learning_image_relations_with_contrast/,[deleted],1494979888,[deleted],0,1
625,2017-5-17,2017,5,17,10,6blr0s,VC view of the ML/AI landscape w/ 113 startups to watch in the Enterprise space,https://www.reddit.com/r/MachineLearning/comments/6blr0s/vc_view_of_the_mlai_landscape_w_113_startups_to/,edworldreddit,1494985205,,0,1
626,2017-5-17,2017,5,17,11,6blvgk,[P] Conversation Models in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/6blvgk/p_conversation_models_in_tensorflow/,oopsleon,1494986623,,8,91
627,2017-5-17,2017,5,17,13,6bmlyt,xkcd: Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6bmlyt/xkcd_machine_learning/,-rico,1494995972,,0,3
628,2017-5-17,2017,5,17,13,6bmmfl,[D] Upcoming ML/DL events in Toronto,https://www.reddit.com/r/MachineLearning/comments/6bmmfl/d_upcoming_mldl_events_in_toronto/,[deleted],1494996167,[removed],0,0
629,2017-5-17,2017,5,17,14,6bmqc1,XKCD: Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6bmqc1/xkcd_machine_learning/,Eurchus,1494997745,,0,1
630,2017-5-17,2017,5,17,14,6bmt70,[D] Questions on Elements of Statistical Learning,https://www.reddit.com/r/MachineLearning/comments/6bmt70/d_questions_on_elements_of_statistical_learning/,CircuitBeast,1494998947,"I came across a post (link below) with a guide to learning this awesome stuff. I bought elements of statistical learning, but I am having trouble with some technical terms/concepts in chapter 2. Can someone please elaborate.
 1) The idea of input space. Is this just mean the possible x that the learner see? 
 2) Importance of the curse of dimensionality
 3) Meaning of local constant fits in infinitesimally small neighborhoods not being a constraint. What defines a small and large neighborhood? pg33

https://www.reddit.com/r/MachineLearning/comments/5z8110/d_a_super_harsh_guide_to_machine_learning/",15,5
631,2017-5-17,2017,5,17,15,6bn2x0,test,https://www.reddit.com/r/MachineLearning/comments/6bn2x0/test/,[deleted],1495003228,[removed],0,1
632,2017-5-17,2017,5,17,15,6bn363,To download data set for machine learning approach,https://www.reddit.com/r/MachineLearning/comments/6bn363/to_download_data_set_for_machine_learning_approach/,Shobana_M,1495003349,[removed],0,1
633,2017-5-17,2017,5,17,15,6bn48z,GAN for text,https://www.reddit.com/r/MachineLearning/comments/6bn48z/gan_for_text/,Lieblich,1495003887,[removed],0,1
634,2017-5-17,2017,5,17,17,6bndhg,Keras Implementation of Character-Based Named Entity Recognition Model,https://www.reddit.com/r/MachineLearning/comments/6bndhg/keras_implementation_of_characterbased_named/,nlnlnl86,1495008477,,0,1
635,2017-5-17,2017,5,17,17,6bnfrk,Where to start for doing object detection?,https://www.reddit.com/r/MachineLearning/comments/6bnfrk/where_to_start_for_doing_object_detection/,reggie_chan,1495009667,[removed],0,1
636,2017-5-17,2017,5,17,17,6bngt5,Pair/Triplet mining for Siamese/Triplet networks,https://www.reddit.com/r/MachineLearning/comments/6bngt5/pairtriplet_mining_for_siamesetriplet_networks/,spidey-fan,1495010221,"Let us consider MNIST, which has 60000 samples belonging to 10 classes.
If I want to train a siamese or a triplet network on these images to learn a embedding, I need to pick pairs or triplets. The total number of possible pairs/triplets is HUGE.
How does one prepare batches of pairs/triplets in such cases? For proper datasets, how to ensure that proper samples are being sent to the network?",6,5
637,2017-5-17,2017,5,17,17,6bnhoo,Deep Learning Basics: The Score Function &amp; Cross Entropy,https://www.reddit.com/r/MachineLearning/comments/6bnhoo/deep_learning_basics_the_score_function_cross/,propete,1495010676,,0,1
638,2017-5-17,2017,5,17,17,6bnis0,[D] Literature CNN classification + conditional probability,https://www.reddit.com/r/MachineLearning/comments/6bnis0/d_literature_cnn_classification_conditional/,DLeater,1495011243,"Hey,

I am looking for some literature to integrate conditional probability during the training of a CNN on a classification task.

I have a training dataset composed of image + label + probability of each class in the image to appear. The later probability is given as an additional input and is expected to improve the prediction by providing relevant information.

My first try was to use this conditional probability *p* in a post-processing step, meaning that given the class predicted by the network, it is compared to *p* to assert the label is effectively possible. 
This solution improves on the network only solution, however I think there should be a way to integrate *p* during the training, it's the reason why I hope someone has an article/idea following this idea.

Thanks !",6,1
639,2017-5-17,2017,5,17,18,6bnke9,Imarticus Live Webinar on Text Analytics,https://www.reddit.com/r/MachineLearning/comments/6bnke9/imarticus_live_webinar_on_text_analytics/,Imarticuslearning,1495012045,,0,1
640,2017-5-17,2017,5,17,18,6bnmte,[D] Best frameworks for C++ implementations?,https://www.reddit.com/r/MachineLearning/comments/6bnmte/d_best_frameworks_for_c_implementations/,tryndisskilled,1495013234,"I'm looking to implement some ML algorithms (mainly DNNs) under C++ files so I can build them and run them on different targets to do inference.

I was able to do this (to some extent) with the TensorFlow repo and its C++ ""documentation"", but I wondered what you chose to use if you got to implement something too.",15,5
641,2017-5-17,2017,5,17,18,6bnnf6,Evolution Strategies vs Bayesian Optimisation. What's the difference?,https://www.reddit.com/r/MachineLearning/comments/6bnnf6/evolution_strategies_vs_bayesian_optimisation/,[deleted],1495013533,[removed],0,1
642,2017-5-17,2017,5,17,19,6bnqsb,Women in Tech: Interview With DeepMind's Silvia Chiappa,https://www.reddit.com/r/MachineLearning/comments/6bnqsb/women_in_tech_interview_with_deepminds_silvia/,reworksophie,1495015228,,0,1
643,2017-5-17,2017,5,17,19,6bnsk7,Here's a Machine Learning example using the Mini SP-500 Futures,https://www.reddit.com/r/MachineLearning/comments/6bnsk7/heres_a_machine_learning_example_using_the_mini/,NitinThapar,1495016015,,0,1
644,2017-5-17,2017,5,17,20,6bnytq,Machine Learning - XKCD,https://www.reddit.com/r/MachineLearning/comments/6bnytq/machine_learning_xkcd/,[deleted],1495018879,[deleted],0,1
645,2017-5-17,2017,5,17,20,6bo4lg,How to start mini-project: classifying news articles,https://www.reddit.com/r/MachineLearning/comments/6bo4lg/how_to_start_miniproject_classifying_news_articles/,[deleted],1495021198,[removed],0,1
646,2017-5-17,2017,5,17,20,6bo4ll,[D] The End of Human Doctors  Understanding Regulation,https://www.reddit.com/r/MachineLearning/comments/6bo4ll/d_the_end_of_human_doctors_understanding/,drlukeor,1495021200,,6,22
647,2017-5-17,2017,5,17,20,6bo7gx,Local Minima and Neurons Permutations in Shallow MLP,https://www.reddit.com/r/MachineLearning/comments/6bo7gx/local_minima_and_neurons_permutations_in_shallow/,NicolaBernini,1495022288,[removed],0,1
648,2017-5-17,2017,5,17,21,6bodk5,[1705.05665] Learning Image Relations with Contrast Association Networks,https://www.reddit.com/r/MachineLearning/comments/6bodk5/170505665_learning_image_relations_with_contrast/,yaolubrain,1495024309,,0,1
649,2017-5-17,2017,5,17,22,6bol2r,"Deep Learning/Machine Learning Technical Interest Group (TIG) is now online: Applying new analytics, neural networks, computational approaches using structured and unstructured data, and also training neural networks with supervised and unsupervised algorithms.",https://www.reddit.com/r/MachineLearning/comments/6bol2r/deep_learningmachine_learning_technical_interest/,bogdanez,1495026677,,0,1
650,2017-5-17,2017,5,17,22,6boswp,[N] Radeon Vega Frontier Edition,https://www.reddit.com/r/MachineLearning/comments/6boswp/n_radeon_vega_frontier_edition/,RadeonVegaFrontier,1495029023,"Hi r/MachineLearning,

This is the AMD Radeon team here to say hi to the ML community. We have recently launched our Radeon Vega Frontier Edition graphics card, designed for deep learning and advanced visualization.

We would like to invite you to an AMA this Thursday at 2PM PST on r/AMD with AMDs Raja Koduri to discuss what the Radeon Vega Frontier Edition means for the future of scientists, data analysts and professionals.

http://pro.radeon.com/en-us/vega-frontier-edition/

Hope to see you there!
",21,96
651,2017-5-17,2017,5,17,23,6bow2k,How do you explain Machine Learning to non Computer Science people?,https://www.reddit.com/r/MachineLearning/comments/6bow2k/how_do_you_explain_machine_learning_to_non/,fluffyzilly,1495029918,[removed],0,1
652,2017-5-17,2017,5,17,23,6bp3mc,[R][1705.05502] The power of deeper networks for expressing natural functions,https://www.reddit.com/r/MachineLearning/comments/6bp3mc/r170505502_the_power_of_deeper_networks_for/,Mandrathax,1495032014,,4,29
653,2017-5-18,2017,5,18,0,6bpaoj,"[R] Slides up for Workshop on AI and Neuroscience [DeepMind, Gatsby, RIKEN, UCL, etc]",https://www.reddit.com/r/MachineLearning/comments/6bpaoj/r_slides_up_for_workshop_on_ai_and_neuroscience/,feedthecreed,1495033902,,0,16
654,2017-5-18,2017,5,18,0,6bpk1e,"Simple Questions Thread May 17, 2017",https://www.reddit.com/r/MachineLearning/comments/6bpk1e/simple_questions_thread_may_17_2017/,AutoModerator,1495036353,[removed],0,1
655,2017-5-18,2017,5,18,2,6bq5r9,Drones with clear APIs (to use with OpenCV),https://www.reddit.com/r/MachineLearning/comments/6bq5r9/drones_with_clear_apis_to_use_with_opencv/,ThisIs_BEARTERRITORY,1495041983,[removed],0,1
656,2017-5-18,2017,5,18,2,6bq96e,Can't make sense of following lines from a deep learning for food recognition paper,https://www.reddit.com/r/MachineLearning/comments/6bq96e/cant_make_sense_of_following_lines_from_a_deep/,newyorkfuckingcity,1495042857,[removed],0,1
657,2017-5-18,2017,5,18,2,6bqauq,TensorFlow Research Cloud,https://www.reddit.com/r/MachineLearning/comments/6bqauq/tensorflow_research_cloud/,[deleted],1495043275,[deleted],0,1
658,2017-5-18,2017,5,18,2,6bqc30,[N] Google Offers Cloud-Based TPU Service for Training and Deploying Deep Learning Models,https://www.reddit.com/r/MachineLearning/comments/6bqc30/n_google_offers_cloudbased_tpu_service_for/,beamsearch,1495043587,,52,301
659,2017-5-18,2017,5,18,2,6bqcoc,"Google.ai, the new umbrella for all AI/ML efforts from Google",https://www.reddit.com/r/MachineLearning/comments/6bqcoc/googleai_the_new_umbrella_for_all_aiml_efforts/,luiscosio,1495043753,,0,1
660,2017-5-18,2017,5,18,3,6bqeye,TensorFlow Research Cloud,https://www.reddit.com/r/MachineLearning/comments/6bqeye/tensorflow_research_cloud/,gdahl,1495044354,,0,1
661,2017-5-18,2017,5,18,3,6bqfta,"[R] ""Real-Time Adaptive Image Compression"", Rippel &amp; Bourdev 2017",https://www.reddit.com/r/MachineLearning/comments/6bqfta/r_realtime_adaptive_image_compression_rippel/,gwern,1495044575,,22,16
662,2017-5-18,2017,5,18,3,6bqjtp,First In-Depth Look at Google's Just-Announced Second-Generation TPU,https://www.reddit.com/r/MachineLearning/comments/6bqjtp/first_indepth_look_at_googles_justannounced/,[deleted],1495045588,[deleted],0,1
663,2017-5-18,2017,5,18,3,6bqmgm,Summaries for many recent DL papers,https://www.reddit.com/r/MachineLearning/comments/6bqmgm/summaries_for_many_recent_dl_papers/,Bardelaz,1495046254,,0,1
664,2017-5-18,2017,5,18,3,6bqov5,[N] Using Machine Learning to Explore Neural Network Architecture,https://www.reddit.com/r/MachineLearning/comments/6bqov5/n_using_machine_learning_to_explore_neural/,_bakauguu,1495046865,,25,44
665,2017-5-18,2017,5,18,3,6bqp5z,"[N] ""WebVision Challenge: Visual Learning and Understanding With Web Data"", Li et al 2017 (2.4m images; semi-supervised followup to ImageNet)",https://www.reddit.com/r/MachineLearning/comments/6bqp5z/n_webvision_challenge_visual_learning_and/,gwern,1495046944,,1,7
666,2017-5-18,2017,5,18,4,6bqt81,"Google CEO at I/O: ""we're moving from a mobile first world to an AI first world""",https://www.reddit.com/r/MachineLearning/comments/6bqt81/google_ceo_at_io_were_moving_from_a_mobile_first/,[deleted],1495047920,[removed],0,1
667,2017-5-18,2017,5,18,4,6bqzc7,Wavenet sound help?,https://www.reddit.com/r/MachineLearning/comments/6bqzc7/wavenet_sound_help/,[deleted],1495049462,[removed],0,1
668,2017-5-18,2017,5,18,6,6brtyv,[R] Using machine learning to create new melodies (blog post),https://www.reddit.com/r/MachineLearning/comments/6brtyv/r_using_machine_learning_to_create_new_melodies/,brannondorsey,1495057436,,8,14
669,2017-5-18,2017,5,18,6,6bru4n,[D] Tune into our livestream of the AI Venture Capital in SD event on Thursday (5/18) at 6:30pm PST here: https://youtu.be/J-4b5ZGUQu4.,https://www.reddit.com/r/MachineLearning/comments/6bru4n/d_tune_into_our_livestream_of_the_ai_venture/,[deleted],1495057476,[deleted],1,1
670,2017-5-18,2017,5,18,7,6bs0pw,[D] Shouldn't the V100 GPU be faster?,https://www.reddit.com/r/MachineLearning/comments/6bs0pw/d_shouldnt_the_v100_gpu_be_faster/,SBodenstein,1495059222,"NVIDIA has given some benchmarks comparing the V100 with the P100 (""2.5x Faster Training of CNNs"" and ""3x Faster Training of LSTM RNNs"", https://developer.nvidia.com/cudnn). Yet the caption tells us that they used FP16 on the V100 and FP32 on the P100 (why would they do that?). But we know the P100 has 21TFLOPs FP16, and 11TFLOPs FP32 (http://www.nvidia.com/object/tesla-p100.html), so presumably it would be 2x faster also using FP16. Thus the V100 would be less than a factor 2x faster than the P100. 

But the V100 has 120TFLOPs tensor cores. Are they that irrelevant for real network training that they cannot even help give a 2x speedup over the P100? Or am I missing something?",4,5
671,2017-5-18,2017,5,18,7,6bs1ve,pre trained model for faster RCNN,https://www.reddit.com/r/MachineLearning/comments/6bs1ve/pre_trained_model_for_faster_rcnn/,forthoseaboutcaca,1495059541,[removed],0,1
672,2017-5-18,2017,5,18,9,6bst63,"[D] The Machine Learning Society (www.MLSociety.com) is live streaming an event on Th @ 6:30p (PST) about Venture Capital for AI in San Diego, if anyone's interested: https://youtu.be/J-4b5ZGUQu4",https://www.reddit.com/r/MachineLearning/comments/6bst63/d_the_machine_learning_society_wwwmlsocietycom_is/,[deleted],1495067518,[deleted],0,1
673,2017-5-18,2017,5,18,9,6bswj5,"[D] The Machine Learning Society (www.MLSociety.com) is live streaming an event on Th @ 6:30p (PST) about Venture Capital for AI in San Diego, if anyone's interested: https://youtu.be/J-4b5ZGUQu4",https://www.reddit.com/r/MachineLearning/comments/6bswj5/d_the_machine_learning_society_wwwmlsocietycom_is/,JustOneMoreStat,1495068562,[removed],0,1
674,2017-5-18,2017,5,18,13,6bu0bu,"[R] Learning to represent tasks for few-shot learning (Communication, Part 1) | ARAYA",https://www.reddit.com/r/MachineLearning/comments/6bu0bu/r_learning_to_represent_tasks_for_fewshot/,NichG,1495081689,,2,33
675,2017-5-18,2017,5,18,15,6buf64,PyOpenCL vs C OpenCL,https://www.reddit.com/r/MachineLearning/comments/6buf64/pyopencl_vs_c_opencl/,AlienScience,1495087824,[removed],0,1
676,2017-5-18,2017,5,18,18,6bv11m,How do I stay updated and in the loop of new machine learning advances?,https://www.reddit.com/r/MachineLearning/comments/6bv11m/how_do_i_stay_updated_and_in_the_loop_of_new/,illiterate_gorillas,1495098246,[removed],0,1
677,2017-5-18,2017,5,18,19,6bv9i0,[D] UK ranking for machine learning?,https://www.reddit.com/r/MachineLearning/comments/6bv9i0/d_uk_ranking_for_machine_learning/,phd3938,1495102183,[removed],3,0
678,2017-5-18,2017,5,18,20,6bvgu0,Doc2Vec - 'Inference stage' question,https://www.reddit.com/r/MachineLearning/comments/6bvgu0/doc2vec_inference_stage_question/,apple-sauce,1495105393,[removed],0,1
679,2017-5-18,2017,5,18,21,6bvuvu,[R] Efficient Parallel Methods for Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/6bvuvu/r_efficient_parallel_methods_for_deep/,alfredvc,1495110573,,11,56
680,2017-5-18,2017,5,18,21,6bvynp,Clustering sub datasets in a dataset based on patterns/similarities,https://www.reddit.com/r/MachineLearning/comments/6bvynp/clustering_sub_datasets_in_a_dataset_based_on/,ramakrishna578,1495111789,[removed],0,1
681,2017-5-18,2017,5,18,22,6bw7ti,"Minimizing the Negative Log-Likelihood, in English",https://www.reddit.com/r/MachineLearning/comments/6bw7ti/minimizing_the_negative_loglikelihood_in_english/,cavaunpeu,1495114553,,0,2
682,2017-5-18,2017,5,18,23,6bwdai,Machine Learning Guide Podcast,https://www.reddit.com/r/MachineLearning/comments/6bwdai/machine_learning_guide_podcast/,[deleted],1495116174,[deleted],0,1
683,2017-5-18,2017,5,18,23,6bwesi,Multi-Layer Neural Network in Swift,https://www.reddit.com/r/MachineLearning/comments/6bwesi/multilayer_neural_network_in_swift/,[deleted],1495116557,[deleted],0,1
684,2017-5-18,2017,5,18,23,6bwj86,[WEBINAR] Introduction to Machine Learning for Quantitative Finance,https://www.reddit.com/r/MachineLearning/comments/6bwj86/webinar_introduction_to_machine_learning_for/,nitinkarma,1495117818,,0,1
685,2017-5-18,2017,5,18,23,6bwjdl,[P] Multi-Layer Neural Network in Swift,https://www.reddit.com/r/MachineLearning/comments/6bwjdl/p_multilayer_neural_network_in_swift/,pltlg,1495117857,,0,0
686,2017-5-18,2017,5,18,23,6bwliu,Machine Learning and Social Media,https://www.reddit.com/r/MachineLearning/comments/6bwliu/machine_learning_and_social_media/,salestechio,1495118471,,0,1
687,2017-5-18,2017,5,18,23,6bwnm2,How is tensorflow's Back propagation implemented ? (Memory problems),https://www.reddit.com/r/MachineLearning/comments/6bwnm2/how_is_tensorflows_back_propagation_implemented/,[deleted],1495119043,[removed],0,1
688,2017-5-19,2017,5,19,0,6bx0kb,"""Democratize Artificial Intelligence(AI)"" Google CEO Sundar Pichai at Google I/O",https://www.reddit.com/r/MachineLearning/comments/6bx0kb/democratize_artificial_intelligenceai_google_ceo/,scidem,1495122394,,0,1
689,2017-5-19,2017,5,19,1,6bxfrq,Machine Learning Foundation Course. Very Helpful.,https://www.reddit.com/r/MachineLearning/comments/6bxfrq/machine_learning_foundation_course_very_helpful/,tomald_drumpf,1495126227,,0,1
690,2017-5-19,2017,5,19,2,6bxj4h,DNN can overfit a small dataset or not?,https://www.reddit.com/r/MachineLearning/comments/6bxj4h/dnn_can_overfit_a_small_dataset_or_not/,zTWang,1495127076,[removed],0,1
691,2017-5-19,2017,5,19,2,6bxjoi,[D] Interested in using Wavenet,https://www.reddit.com/r/MachineLearning/comments/6bxjoi/d_interested_in_using_wavenet/,[deleted],1495127215,[deleted],0,1
692,2017-5-19,2017,5,19,2,6bxmqi,LSTM Neural Network used for Audio Synthesis (Music),https://www.reddit.com/r/MachineLearning/comments/6bxmqi/lstm_neural_network_used_for_audio_synthesis_music/,samparkewolfe,1495127979,[removed],0,1
693,2017-5-19,2017,5,19,2,6bxt80,[D] Using Wavenet,https://www.reddit.com/r/MachineLearning/comments/6bxt80/d_using_wavenet/,SnazzyMax,1495129642,"Hi!

So I'm an absolute novice when it comes to machine learning, but I find it absolutely fascinating and I feel it would be of great use for my art.

I'm currently working on a project that explores synaesthesia and neural networks: looking at relationships between organic and synthetic sound and how visual cues affect the perception of them.

I'd love to use some sort of machine learning to process my field recordings in order to create 'synthetic' versions of these organic sounds - however I'm finding it exceedingly difficult to understand how I would go about doing this: my knowledge in coding is extremely limited. I tried looking into Wavenet but I was in way over my head...

Does anyone have any tips? Other places I could ask? People I could contact? Any information on the subject would be greatly appreciated.

Thanks in advance!",8,1
694,2017-5-19,2017,5,19,3,6bxx7a,[D] Classification with Missing Features Published Benchmarks (MNIST/SVHN preferred),https://www.reddit.com/r/MachineLearning/comments/6bxx7a/d_classification_with_missing_features_published/,alexmlamb,1495130583,"One can imagine a task where you take a dataset like MNIST, and at test time, you randomly remove N% of the pixels (or otherwise remove some subset) and still are tasked with doing classification.  

This seems like a reasonably rigorous task, and I'm curious if there are any published baseline numbers on it?  

Would be greatly appreciated for NIPS rush :p :p",2,6
695,2017-5-19,2017,5,19,5,6bywfp,Machine Learning in High-Frequency Trading by Gaurav Chakravorty.,https://www.reddit.com/r/MachineLearning/comments/6bywfp/machine_learning_in_highfrequency_trading_by/,Targaryen1947,1495139365,,0,1
696,2017-5-19,2017,5,19,9,6c0cc4,"[P] Google releases dataset of 50M vector drawings, open sources Sketch-RNN implementation.",https://www.reddit.com/r/MachineLearning/comments/6c0cc4/p_google_releases_dataset_of_50m_vector_drawings/,hardmaru,1495154145,,30,523
697,2017-5-19,2017,5,19,10,6c0qnb,Paint Colors Invented by Neural Network,https://www.reddit.com/r/MachineLearning/comments/6c0qnb/paint_colors_invented_by_neural_network/,RevMen,1495158719,,0,1
698,2017-5-19,2017,5,19,13,6c1ey5,[D] Recommending books based on natural language search queries,https://www.reddit.com/r/MachineLearning/comments/6c1ey5/d_recommending_books_based_on_natural_language/,[deleted],1495166930,[deleted],2,5
699,2017-5-19,2017,5,19,13,6c1frr,"[D] Upcoming Machine Learning Events in Toronto, Canada",https://www.reddit.com/r/MachineLearning/comments/6c1frr/d_upcoming_machine_learning_events_in_toronto/,UofTNeuralNet,1495167230,[removed],0,1
700,2017-5-19,2017,5,19,15,6c1w4p,How to actually find a machine learning mentor?,https://www.reddit.com/r/MachineLearning/comments/6c1w4p/how_to_actually_find_a_machine_learning_mentor/,clanleader,1495174007,[removed],0,1
701,2017-5-19,2017,5,19,16,6c261a,Would Generative Adversarial Networks works on traditional SVM classification with low dimensional hand-craft feature?,https://www.reddit.com/r/MachineLearning/comments/6c261a/would_generative_adversarial_networks_works_on/,RavlaAlvar,1495178608,[removed],0,1
702,2017-5-19,2017,5,19,16,6c28j8,Is it possible to use machine learning for generating CSS styles?,https://www.reddit.com/r/MachineLearning/comments/6c28j8/is_it_possible_to_use_machine_learning_for/,Ali-Zuhair,1495179771,[removed],0,1
703,2017-5-19,2017,5,19,17,6c2b2i,Tensorflow NaN loss value,https://www.reddit.com/r/MachineLearning/comments/6c2b2i/tensorflow_nan_loss_value/,future_duded,1495181023,[removed],0,1
704,2017-5-19,2017,5,19,17,6c2dz4,what is tensors rank?,https://www.reddit.com/r/MachineLearning/comments/6c2dz4/what_is_tensors_rank/,John_Smith111,1495182535,[removed],1,1
705,2017-5-19,2017,5,19,17,6c2fkz,[P] Energy use prediction and appliance labels with LSTM,https://www.reddit.com/r/MachineLearning/comments/6c2fkz/p_energy_use_prediction_and_appliance_labels_with/,whatnick,1495183389,I am toying with LSTM's to label my mix of appliances from energy monitoring data series. If anyone would like to play with my live data or suggest easy labelling solutions / appliance signature databases here is my notebook so far https://github.com/whatnick/TS_EnergyMonitor/blob/master/LSTM%2BEnergy%2BSeries.ipynb,2,12
706,2017-5-19,2017,5,19,17,6c2fm4,"A new platform for unifying the chatbot research and development, ParlAI",https://www.reddit.com/r/MachineLearning/comments/6c2fm4/a_new_platform_for_unifying_the_chatbot_research/,vladosaurus,1495183406,[removed],0,1
707,2017-5-19,2017,5,19,19,6c2ptc,Why is the KNN implementation in sklearn slower when I use a smaller float?,https://www.reddit.com/r/MachineLearning/comments/6c2ptc/why_is_the_knn_implementation_in_sklearn_slower/,satorulogic,1495188328,,0,1
708,2017-5-19,2017,5,19,19,6c2vld,Digital Ventures Company,https://www.reddit.com/r/MachineLearning/comments/6c2vld/digital_ventures_company/,oaashish,1495190792,,0,1
709,2017-5-19,2017,5,19,20,6c2xvh,Question during autonomous robot training,https://www.reddit.com/r/MachineLearning/comments/6c2xvh/question_during_autonomous_robot_training/,Laurence-Lin,1495191756,[removed],0,1
710,2017-5-19,2017,5,19,20,6c319c,A Quick Guide to Identify Twitterbots Using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6c319c/a_quick_guide_to_identify_twitterbots_using/,parth10,1495193124,,0,1
711,2017-5-19,2017,5,19,21,6c3b14,How A Data Scientist Can Improve His Productivity By Pipelines,https://www.reddit.com/r/MachineLearning/comments/6c3b14/how_a_data_scientist_can_improve_his_productivity/,[deleted],1495196771,[deleted],0,1
712,2017-5-19,2017,5,19,22,6c3p32,What are some great Machine Learning PDFs?,https://www.reddit.com/r/MachineLearning/comments/6c3p32/what_are_some_great_machine_learning_pdfs/,[deleted],1495201309,[removed],0,1
713,2017-5-19,2017,5,19,22,6c3qp3,Stuck on Basic Backpropagation Problem for Neural Network,https://www.reddit.com/r/MachineLearning/comments/6c3qp3/stuck_on_basic_backpropagation_problem_for_neural/,Eriod,1495201801,[removed],0,1
714,2017-5-19,2017,5,19,22,6c3ry7,Looking for first step recommendations for ML in Finance.,https://www.reddit.com/r/MachineLearning/comments/6c3ry7/looking_for_first_step_recommendations_for_ml_in/,somethingconcon,1495202186,[removed],0,1
715,2017-5-19,2017,5,19,22,6c3sbl,Not Everything Needs to be Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6c3sbl/not_everything_needs_to_be_machine_learning/,curie_User,1495202297,[removed],0,1
716,2017-5-19,2017,5,19,23,6c3vd2,Stephen Hawking: Self-Evolving Artificial Intelligence(AI) Has a Free Will and End Humanity,https://www.reddit.com/r/MachineLearning/comments/6c3vd2/stephen_hawking_selfevolving_artificial/,scidem,1495203149,,0,1
717,2017-5-19,2017,5,19,23,6c3vwi,"Authoring an introductory resource for newbies in the AI field and need help with a poll. The prompt is to finish this sentence, ""Artificial Intelligence is..."" - Will release PDF here when finished. [x-post from r/artificial]",https://www.reddit.com/r/MachineLearning/comments/6c3vwi/authoring_an_introductory_resource_for_newbies_in/,[deleted],1495203279,[deleted],0,1
718,2017-5-19,2017,5,19,23,6c42s0,MKR AUTOMATION,https://www.reddit.com/r/MachineLearning/comments/6c42s0/mkr_automation/,automationmkr,1495205162,,3,1
719,2017-5-19,2017,5,19,23,6c43js,Google publishes quickdraw training data they collected,https://www.reddit.com/r/MachineLearning/comments/6c43js/google_publishes_quickdraw_training_data_they/,yogthos,1495205370,,0,1
720,2017-5-20,2017,5,20,0,6c4ca1,Advanced watercolor conversion,https://www.reddit.com/r/MachineLearning/comments/6c4ca1/advanced_watercolor_conversion/,seominlee,1495207748,[removed],0,1
721,2017-5-20,2017,5,20,0,6c4g5k,Make your own music with WaveNets,https://www.reddit.com/r/MachineLearning/comments/6c4g5k/make_your_own_music_with_wavenets/,JesseEngel,1495208777,,11,163
722,2017-5-20,2017,5,20,3,6c5kma,Review of RWA model (in Japanese),https://www.reddit.com/r/MachineLearning/comments/6c5kma/review_of_rwa_model_in_japanese/,[deleted],1495219358,[deleted],0,1
723,2017-5-20,2017,5,20,4,6c5q5h,[D] Review of RWA model (in Japanese),https://www.reddit.com/r/MachineLearning/comments/6c5q5h/d_review_of_rwa_model_in_japanese/,[deleted],1495220878,[deleted],0,1
724,2017-5-20,2017,5,20,4,6c5q8y,[Discussion] Review of RWA model (in Japanese),https://www.reddit.com/r/MachineLearning/comments/6c5q8y/discussion_review_of_rwa_model_in_japanese/,jostmey,1495220905,,7,0
725,2017-5-20,2017,5,20,5,6c62d2,[D] Thus ends the coffee and hope-fueled frenzy leading up to the NIPS deadline. How's everyone doing?,https://www.reddit.com/r/MachineLearning/comments/6c62d2/d_thus_ends_the_coffee_and_hopefueled_frenzy/,ajmooch,1495224160,"I'm too exhausted to go out for drinks, so I just want to hang out on the internet, post [ML memes](https://i.imgflip.com/1pd3tt.jpg), and talk shop. 

How was your run up to the deadline? 

Is anyone else working on HyperNetworks? (drop me a line if you are and want to discuss 'em). 

How many total submissions do you reckon there'll be? I started my submission file yesterday and was already numbered in the 1500s, so I'd guess there's over 3000 by now.

",40,47
726,2017-5-20,2017,5,20,5,6c690s,[R][1705.05994] Learning a Hierarchical Latent-Variable Model of Voxelized 3D Shapes,https://www.reddit.com/r/MachineLearning/comments/6c690s/r170505994_learning_a_hierarchical_latentvariable/,lorenmontez,1495226061,,1,14
727,2017-5-20,2017,5,20,7,6c6rlr,Interesting knowledge graph papers?,https://www.reddit.com/r/MachineLearning/comments/6c6rlr/interesting_knowledge_graph_papers/,spurious_recollectio,1495231560,[removed],0,1
728,2017-5-20,2017,5,20,7,6c6tiz,Open source tools for visualizing what ConvNets learn?,https://www.reddit.com/r/MachineLearning/comments/6c6tiz/open_source_tools_for_visualizing_what_convnets/,andyandy16,1495232143,[removed],0,1
729,2017-5-20,2017,5,20,7,6c6w6i,How AI Startups Must Compete with Google: Reply to Fei-Fei Li,https://www.reddit.com/r/MachineLearning/comments/6c6w6i/how_ai_startups_must_compete_with_google_reply_to/,mostafabenh,1495232980,,0,1
730,2017-5-20,2017,5,20,7,6c6zr1,Do you know of any water availability related dataset ?,https://www.reddit.com/r/MachineLearning/comments/6c6zr1/do_you_know_of_any_water_availability_related/,mayankj08,1495234130,[removed],0,1
731,2017-5-20,2017,5,20,9,6c7gts,How did everyone's NIPS submission go? Anything exciting to report or just tired?,https://www.reddit.com/r/MachineLearning/comments/6c7gts/how_did_everyones_nips_submission_go_anything/,sergeyfukov,1495239820,[removed],0,1
732,2017-5-20,2017,5,20,9,6c7m4d,What is the difference between Google cloud vision api vs mobile vision api?,https://www.reddit.com/r/MachineLearning/comments/6c7m4d/what_is_the_difference_between_google_cloud/,aprl_la,1495241707,[removed],0,1
733,2017-5-20,2017,5,20,12,6c8cwz,Creating a neural network from scratch in Python,https://www.reddit.com/r/MachineLearning/comments/6c8cwz/creating_a_neural_network_from_scratch_in_python/,roman882,1495251696,[removed],0,1
734,2017-5-20,2017,5,20,13,6c8m2f,Future of Machine Learning in Finance,https://www.reddit.com/r/MachineLearning/comments/6c8m2f/future_of_machine_learning_in_finance/,nitinkarma,1495255493,,0,1
735,2017-5-20,2017,5,20,17,6c9dma,Googles New AI Is Better at Creating AI Than the Companys Engineers,https://www.reddit.com/r/MachineLearning/comments/6c9dma/googles_new_ai_is_better_at_creating_ai_than_the/,ProgrammingGodJordan,1495269339,,0,1
736,2017-5-20,2017,5,20,19,6c9py3,any semantic image segmentation solution on mobile device?,https://www.reddit.com/r/MachineLearning/comments/6c9py3/any_semantic_image_segmentation_solution_on/,noguxun,1495276452,[removed],0,1
737,2017-5-20,2017,5,20,22,6caa3l,[D] Generating vectors for bands using word2vec,https://www.reddit.com/r/MachineLearning/comments/6caa3l/d_generating_vectors_for_bands_using_word2vec/,0pet,1495286022,"I have a dataset which has 300,000 users' play history i.e band &amp; number of plays. I was thinking of using Skip gram for learning the vectors. The train output for each band would be (number of plays of the band)/(total number of plays of the user). 

Is this a good way to generate vectors? Will I be facing issues?

Also which library should I use? Gensim requires that I have sentences but clearly, I'm not using sentences, also ""context window"" doesn't make sense in my project.

Should I train using keras and then load the weights to gensim to process them? Or is there a way to do this in gensim itself. I have tried and searched but nothing came up. 

Can I use my MacBook Air for training? Would it take too long on my machine to train?",22,15
738,2017-5-20,2017,5,20,22,6caaqt,[P] Watch an AI teach itself to drive in 'GTA V' on Twitch,https://www.reddit.com/r/MachineLearning/comments/6caaqt/p_watch_an_ai_teach_itself_to_drive_in_gta_v_on/,lopespm,1495286280,,0,9
739,2017-5-20,2017,5,20,22,6cafj3,[R] Curiosity-driven Exploration by Self-supervised Prediction,https://www.reddit.com/r/MachineLearning/comments/6cafj3/r_curiositydriven_exploration_by_selfsupervised/,[deleted],1495288114,[deleted],0,1
740,2017-5-20,2017,5,20,22,6cafkz,Memory Network for Mario,https://www.reddit.com/r/MachineLearning/comments/6cafkz/memory_network_for_mario/,ad48hp,1495288136,[removed],0,1
741,2017-5-21,2017,5,21,0,6casj5,The Hardware of Deep Learning,https://www.reddit.com/r/MachineLearning/comments/6casj5/the_hardware_of_deep_learning/,arshakn,1495292676,,0,1
742,2017-5-21,2017,5,21,0,6casnl,Self-Supervised Video Anomaly Detection,https://www.reddit.com/r/MachineLearning/comments/6casnl/selfsupervised_video_anomaly_detection/,arshakn,1495292722,,0,2
743,2017-5-21,2017,5,21,0,6cb0wi,Looking for a paper that used markov random fields /w CNNs to exploit correlation in output variables to improve segmentation.,https://www.reddit.com/r/MachineLearning/comments/6cb0wi/looking_for_a_paper_that_used_markov_random/,[deleted],1495295338,[removed],0,1
744,2017-5-21,2017,5,21,0,6cb1gr,[R] [1705.01166] Rational ignorance: simpler models learn more from finite data,https://www.reddit.com/r/MachineLearning/comments/6cb1gr/r_170501166_rational_ignorance_simpler_models/,fixpoint,1495295504,,16,58
745,2017-5-21,2017,5,21,1,6cb5sj,[P] Real-time face detection and emotion/gender classification with keras CNN and openCV.,https://www.reddit.com/r/MachineLearning/comments/6cb5sj/p_realtime_face_detection_and_emotiongender/,[deleted],1495296846,[deleted],0,1
746,2017-5-21,2017,5,21,1,6cb99w,Real-time face detection and emotion/gender classification using keras CNN and openCV.,https://www.reddit.com/r/MachineLearning/comments/6cb99w/realtime_face_detection_and_emotiongender/,[deleted],1495297918,[deleted],0,2
747,2017-5-21,2017,5,21,1,6cbb9m,[P] Real-time face detection and emotion/gender classification using a keras CNN and openCV.,https://www.reddit.com/r/MachineLearning/comments/6cbb9m/p_realtime_face_detection_and_emotiongender/,[deleted],1495298566,[deleted],0,1
748,2017-5-21,2017,5,21,2,6cbi05,[P] Real-time face detection and emotion/gender classification with a keras CNN model and openCV.,https://www.reddit.com/r/MachineLearning/comments/6cbi05/p_realtime_face_detection_and_emotiongender/,oarriaga,1495300686,,31,159
749,2017-5-21,2017,5,21,2,6cbmfg,[P] Paraphrase Identification In Tensorflow (documented/tested/good for beginners),https://www.reddit.com/r/MachineLearning/comments/6cbmfg/p_paraphrase_identification_in_tensorflow/,nfliu,1495302039,,0,39
750,2017-5-21,2017,5,21,4,6ccayi,How to reuse Keras Neural Network using Docker,https://www.reddit.com/r/MachineLearning/comments/6ccayi/how_to_reuse_keras_neural_network_using_docker/,jskalc,1495309362,,0,1
751,2017-5-21,2017,5,21,5,6ccmvj,[D] Is there a canonical way to structure Tensorflow research projects?,https://www.reddit.com/r/MachineLearning/comments/6ccmvj/d_is_there_a_canonical_way_to_structure/,nharada,1495313121,Preferably one that Google employees use internally? There are a whole bunch of tools in contrib that all seem to mostly solve the same problem (or at least the same 90% of problems). ,13,39
752,2017-5-21,2017,5,21,6,6ccpmi,New paint colors invented by neural network,https://www.reddit.com/r/MachineLearning/comments/6ccpmi/new_paint_colors_invented_by_neural_network/,slavakurilyak,1495314026,,1,1
753,2017-5-21,2017,5,21,6,6cd0cc,[P] Predicting the Projected Score of a Cricket match at any point using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6cd0cc/p_predicting_the_projected_score_of_a_cricket/,Faizann24,1495317548,,0,13
754,2017-5-21,2017,5,21,7,6cd140,[D] Attacking Machine Learning with Adversarial Examples,https://www.reddit.com/r/MachineLearning/comments/6cd140/d_attacking_machine_learning_with_adversarial/,_alphamaximus_,1495317789,,3,24
755,2017-5-21,2017,5,21,8,6cdkzk,A Marketplace for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6cdkzk/a_marketplace_for_machine_learning/,[deleted],1495324539,[deleted],0,1
756,2017-5-21,2017,5,21,9,6cdocx,A Marketplace for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6cdocx/a_marketplace_for_machine_learning/,[deleted],1495325692,[removed],0,1
757,2017-5-21,2017,5,21,9,6cdrfy,How to combine unsupervised and supervised techniques for text classification?,https://www.reddit.com/r/MachineLearning/comments/6cdrfy/how_to_combine_unsupervised_and_supervised/,chisras,1495326776,[removed],0,1
758,2017-5-21,2017,5,21,16,6cfg1j,Did you ever try a convolution neural network without pooling or size reduction? How did it perform?,https://www.reddit.com/r/MachineLearning/comments/6cfg1j/did_you_ever_try_a_convolution_neural_network/,falmasri,1495353289,[removed],0,1
759,2017-5-21,2017,5,21,17,6cfh5v,"Join The Los Angeles Machine Learning for .NET Meetup (Los Angeles, CA)",https://www.reddit.com/r/MachineLearning/comments/6cfh5v/join_the_los_angeles_machine_learning_for_net/,sumoboy1231,1495353955,,1,1
760,2017-5-21,2017,5,21,17,6cfjfd,tensorflow 1.1 RNN seq2seq API tutorials,https://www.reddit.com/r/MachineLearning/comments/6cfjfd/tensorflow_11_rnn_seq2seq_api_tutorials/,mrbeatronic,1495355309,[removed],0,1
761,2017-5-21,2017,5,21,19,6cfxg0,Understanding and Implementing CycleGAN in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/6cfxg0/understanding_and_implementing_cyclegan_in/,[deleted],1495363438,[deleted],0,1
762,2017-5-21,2017,5,21,20,6cg5q1,"[D] How to calculate / estimate word level perplexity of a character-level model, given character-level perplexity and a corpus?",https://www.reddit.com/r/MachineLearning/comments/6cg5q1/d_how_to_calculate_estimate_word_level_perplexity/,bubaonaruba,1495367713,,5,8
763,2017-5-21,2017,5,21,23,6cgrd3,2k budget Learning Rig suggestions,https://www.reddit.com/r/MachineLearning/comments/6cgrd3/2k_budget_learning_rig_suggestions/,extra074,1495376510,[removed],1,1
764,2017-5-21,2017,5,21,23,6cgtuf,How is machine learning applied in different areas?,https://www.reddit.com/r/MachineLearning/comments/6cgtuf/how_is_machine_learning_applied_in_different_areas/,krinart,1495377394,[removed],0,1
765,2017-5-21,2017,5,21,23,6cgud6,[P]Attention-based Extraction of Structured Information from Street View Imagery (open-source impl),https://www.reddit.com/r/MachineLearning/comments/6cgud6/pattentionbased_extraction_of_structured/,hooba_stank_,1495377577,,1,35
766,2017-5-22,2017,5,22,0,6ch3qt,[P] A tutorial on implementing CycleGAN in tensorflow,https://www.reddit.com/r/MachineLearning/comments/6ch3qt/p_a_tutorial_on_implementing_cyclegan_in/,architrathore,1495380597,,14,164
767,2017-5-22,2017,5,22,0,6ch5jy,Data prepping and data type consistency question,https://www.reddit.com/r/MachineLearning/comments/6ch5jy/data_prepping_and_data_type_consistency_question/,ihatov,1495381116,[removed],0,1
768,2017-5-22,2017,5,22,1,6chc08,Help needed --&gt;TensorFlow: Using my own data,https://www.reddit.com/r/MachineLearning/comments/6chc08/help_needed_tensorflow_using_my_own_data/,ko260,1495383066,[removed],0,1
769,2017-5-22,2017,5,22,1,6chhnr,"Is this theorem ""wrong""?",https://www.reddit.com/r/MachineLearning/comments/6chhnr/is_this_theorem_wrong/,[deleted],1495384814,[deleted],0,1
770,2017-5-22,2017,5,22,1,6chkfo,"Is this theorem ""wrong""?",https://www.reddit.com/r/MachineLearning/comments/6chkfo/is_this_theorem_wrong/,[deleted],1495385640,[deleted],0,1
771,2017-5-22,2017,5,22,2,6chmym,"Is this theorem ""wrong""?",https://www.reddit.com/r/MachineLearning/comments/6chmym/is_this_theorem_wrong/,[deleted],1495386419,[deleted],0,1
772,2017-5-22,2017,5,22,2,6chrk2,"Is this theorem ""wrong""?",https://www.reddit.com/r/MachineLearning/comments/6chrk2/is_this_theorem_wrong/,EconEuler,1495387775,,1,1
773,2017-5-22,2017,5,22,2,6chx1b,3 or more features in KNN,https://www.reddit.com/r/MachineLearning/comments/6chx1b/3_or_more_features_in_knn/,Bishonen_88,1495389424,[removed],0,1
774,2017-5-22,2017,5,22,3,6chxte,"[R] ""DeepXplore: Automated Whitebox Testing of Deep Learning Systems"", Pei et al 2017",https://www.reddit.com/r/MachineLearning/comments/6chxte/r_deepxplore_automated_whitebox_testing_of_deep/,gwern,1495389641,,0,18
775,2017-5-22,2017,5,22,4,6cifv5,Setting up for deep learning with a GPU,https://www.reddit.com/r/MachineLearning/comments/6cifv5/setting_up_for_deep_learning_with_a_gpu/,melonmeli23,1495394835,[removed],0,1
776,2017-5-22,2017,5,22,5,6city3,Back propagation rookie problems,https://www.reddit.com/r/MachineLearning/comments/6city3/back_propagation_rookie_problems/,julianxxxx,1495399001,[removed],0,1
777,2017-5-22,2017,5,22,5,6cixw9,[R] Share your NIPS 2017 paper,https://www.reddit.com/r/MachineLearning/comments/6cixw9/r_share_your_nips_2017_paper/,insider_7,1495400180,"If you have submitted a paper to NIPS 2017 and you plan to share it on Arxiv, or if it's already on it, share with us, to know what is the trend now in the submissions. Have we moved now from ""deep learning""?
",59,16
778,2017-5-22,2017,5,22,6,6cj4rj,What do you set your net's output vector to train for during DQN reinforcement learning when you don't know expected value of actions you haven't taken?,https://www.reddit.com/r/MachineLearning/comments/6cj4rj/what_do_you_set_your_nets_output_vector_to_train/,sharp7,1495402254,[removed],0,1
779,2017-5-22,2017,5,22,7,6cji6d,Flying objet over the roof of the front house,https://www.reddit.com/r/MachineLearning/comments/6cji6d/flying_objet_over_the_roof_of_the_front_house/,antoniotraveler2017,1495406443,[removed],0,1
780,2017-5-22,2017,5,22,8,6cjn23,Multivariate Linear Regression Graphing?,https://www.reddit.com/r/MachineLearning/comments/6cjn23/multivariate_linear_regression_graphing/,denotatedanonuser,1495408042,[removed],0,1
781,2017-5-22,2017,5,22,10,6ck81n,[R] Building effective deep neural network architectures one feature at a time,https://www.reddit.com/r/MachineLearning/comments/6ck81n/r_building_effective_deep_neural_network/,xternalz,1495415171,,0,26
782,2017-5-22,2017,5,22,11,6ckjy4,[D] The Extraordinary Link Between Deep Neural Networks and the Nature of the Universe,https://www.reddit.com/r/MachineLearning/comments/6ckjy4/d_the_extraordinary_link_between_deep_neural/,edmfanyo,1495419347,,10,0
783,2017-5-22,2017,5,22,12,6ckzhm,We are creating a predictive model for our class! Please take our short survey about your life.,https://www.reddit.com/r/MachineLearning/comments/6ckzhm/we_are_creating_a_predictive_model_for_our_class/,HeelBruise,1495425081,[removed],0,1
784,2017-5-22,2017,5,22,14,6cle5q,"[R] Recurrent Additive Networks - no recurrent non-linear computations, much simpler but still competitive with LSTM/GRU",https://www.reddit.com/r/MachineLearning/comments/6cle5q/r_recurrent_additive_networks_no_recurrent/,downtownslim,1495430973,,16,68
785,2017-5-22,2017,5,22,15,6clio9,[D] Convolutional Methods for Text,https://www.reddit.com/r/MachineLearning/comments/6clio9/d_convolutional_methods_for_text/,TalkingJellyFish,1495432970,,9,61
786,2017-5-22,2017,5,22,15,6clo33,[D]Two implementations of A3C,https://www.reddit.com/r/MachineLearning/comments/6clo33/dtwo_implementations_of_a3c/,darkzero_reddit,1495435389,"So far I have seen two kinds of implementaions of A3C:

The first one is that every thread owns a local network and accumulate their gradients respectively, then they sync their networks to and from a global network from time to time. This is identical to the paper's design;

The second one is that there is only a global network to which every thread has access. Every thread puts their experiences into a buffer and the global network is trained upon the buffer is full, then buffer is cleared for new experiences.

I wonder if the second one would be problematic, because in implementation it is by far more simple than the first one.

Thank you! ",4,9
787,2017-5-22,2017,5,22,16,6clt82,[D] Looking for pretrained fairseq translation models,https://www.reddit.com/r/MachineLearning/comments/6clt82/d_looking_for_pretrained_fairseq_translation/,Delthc,1495437802,"Hello, as the title suggests I am looking for pretrained fairseq translation models beyond the 3 that are officially offered.

I could not find any on google, and I really hope someone here has already trained one of them and can either share the model or tell me how long it took to train them and what corpora you suggest for good translation performance.

Last but not least, do you know any reason why facebook only released 3 of them? 

Regards",1,4
788,2017-5-22,2017,5,22,17,6cly3j,Let us have a look at powder mixer blender for mixing color pigment powder,https://www.reddit.com/r/MachineLearning/comments/6cly3j/let_us_have_a_look_at_powder_mixer_blender_for/,JCT_Janice,1495440259,,0,1
789,2017-5-22,2017,5,22,18,6cm712,Armchairs Sales Market Report 2017,https://www.reddit.com/r/MachineLearning/comments/6cm712/armchairs_sales_market_report_2017/,Reportsandmarkets,1495444706,,0,1
790,2017-5-22,2017,5,22,18,6cm8pl,Deep learning for best fitting shapes,https://www.reddit.com/r/MachineLearning/comments/6cm8pl/deep_learning_for_best_fitting_shapes/,arijitiit,1495445515,[removed],0,1
791,2017-5-22,2017,5,22,18,6cmb6b,"First speakers announced for REWORK Deep Learning Summit in Canada include Yoshua Bengio, Yann LeCun, Geoff Hinton, Aaron Courville, Roland Memisevic",https://www.reddit.com/r/MachineLearning/comments/6cmb6b/first_speakers_announced_for_rework_deep_learning/,reworksophie,1495446688,,0,1
792,2017-5-22,2017,5,22,20,6cmkig,Global Auto Labeler (Print &amp; Apply System) Sales Market Report Forecast 2017-2021,https://www.reddit.com/r/MachineLearning/comments/6cmkig/global_auto_labeler_print_apply_system_sales/,Reportsandmarkets,1495450953,,0,1
793,2017-5-22,2017,5,22,20,6cmm23,[R] A Survey of Neuromorphic Computing and Neural Networks in Hardware,https://www.reddit.com/r/MachineLearning/comments/6cmm23/r_a_survey_of_neuromorphic_computing_and_neural/,villasv,1495451578,,10,2
794,2017-5-22,2017,5,22,20,6cmse8,"Join Deep Learning leaders in Boston, May 25-26  KDnuggets Offer",https://www.reddit.com/r/MachineLearning/comments/6cmse8/join_deep_learning_leaders_in_boston_may_2526/,reworksophie,1495454128,,0,1
795,2017-5-22,2017,5,22,21,6cmua4,Faster machine learning is coming to the Linux kernel - Heterogenous memory management for CPU/GPU,https://www.reddit.com/r/MachineLearning/comments/6cmua4/faster_machine_learning_is_coming_to_the_linux/,Barbas,1495454859,,0,1
796,2017-5-22,2017,5,22,21,6cn076,Practical Machine Learning With Python - Part 1,https://www.reddit.com/r/MachineLearning/comments/6cn076/practical_machine_learning_with_python_part_1/,savan77,1495457000,,0,1
797,2017-5-22,2017,5,22,23,6cnpt6,A neural net-based image classifier helps man sort two tons of LEGO bricks,https://www.reddit.com/r/MachineLearning/comments/6cnpt6/a_neural_netbased_image_classifier_helps_man_sort/,BridgeofBirds,1495464890,,0,1
798,2017-5-22,2017,5,22,23,6cnqeq,"[D] Anyone selling ISL,ESL, or Deep Learning textbooks?",https://www.reddit.com/r/MachineLearning/comments/6cnqeq/d_anyone_selling_islesl_or_deep_learning_textbooks/,Octopuscabbage,1495465055,[removed],2,0
799,2017-5-23,2017,5,23,0,6cnviy,Deep Learning Summer school-Bilbao,https://www.reddit.com/r/MachineLearning/comments/6cnviy/deep_learning_summer_schoolbilbao/,hull11,1495466399,[removed],0,1
800,2017-5-23,2017,5,23,1,6co6fs,"Mad About The Way You Write. Its Me, Your AI Friend.",https://www.reddit.com/r/MachineLearning/comments/6co6fs/mad_about_the_way_you_write_its_me_your_ai_friend/,[deleted],1495469402,[deleted],0,1
801,2017-5-23,2017,5,23,1,6codqu,GPU-accelerated Keras w. Theano or Tensorflow on Windows 10 native [UPDATED TO Keras2.0.4 + Theano0.9 + Tensorflow 1.1.0 + VS2015 + CUDA8.0.61 + cuDNN5.1],https://www.reddit.com/r/MachineLearning/comments/6codqu/gpuaccelerated_keras_w_theano_or_tensorflow_on/,[deleted],1495471327,[removed],0,1
802,2017-5-23,2017,5,23,1,6cofgx,[P] Enhance: Word Embedding in Golang: Calculate the cosine similarity between words.,https://www.reddit.com/r/MachineLearning/comments/6cofgx/p_enhance_word_embedding_in_golang_calculate_the/,[deleted],1495471763,[deleted],2,1
803,2017-5-23,2017,5,23,2,6cojgi,[P] Mushroom recognition by photo  iOS App,https://www.reddit.com/r/MachineLearning/comments/6cojgi/p_mushroom_recognition_by_photo_ios_app/,vernik911,1495472778,,23,15
804,2017-5-23,2017,5,23,2,6colms,Neat - Management of population,https://www.reddit.com/r/MachineLearning/comments/6colms/neat_management_of_population/,BitPhinix,1495473329,[removed],0,1
805,2017-5-23,2017,5,23,2,6con7c,[D] Under The Hood Of Google's TPU2 Machine Learning Clusters,https://www.reddit.com/r/MachineLearning/comments/6con7c/d_under_the_hood_of_googles_tpu2_machine_learning/,cryptoz,1495473744,,7,93
806,2017-5-23,2017,5,23,2,6cou6p,Google Lens Is Now Beyond Your Thought And Intelligence,https://www.reddit.com/r/MachineLearning/comments/6cou6p/google_lens_is_now_beyond_your_thought_and/,newarktechs,1495475554,[removed],0,1
807,2017-5-23,2017,5,23,3,6coyi2,Tensor Processing Units (TPU) are used to power up machine learning in Google Lens. How it works,https://www.reddit.com/r/MachineLearning/comments/6coyi2/tensor_processing_units_tpu_are_used_to_power_up/,newarktechs,1495476676,,0,1
808,2017-5-23,2017,5,23,3,6coyvv,[D]What tool/algorithm should i use for detection of texts in an image? (preferably from openCV) [x-post: r/computervision],https://www.reddit.com/r/MachineLearning/comments/6coyvv/dwhat_toolalgorithm_should_i_use_for_detection_of/,z546,1495476766,"Hello
I need to correctly identify texts in an image, for example in a photograph of a street with a street sign, i would have to detect the text on the street sign. I am planning to correctly box the text in and image and then use a classifier to correctly classify it. What algorithm may i use to correctly identify and retrieve the text from an image?",4,2
809,2017-5-23,2017,5,23,3,6coz2g,Is it possible to have a extremely low l2-loss while having accuracy at chance level?,https://www.reddit.com/r/MachineLearning/comments/6coz2g/is_it_possible_to_have_a_extremely_low_l2loss/,real_pinocchio,1495476824,,0,1
810,2017-5-23,2017,5,23,5,6cpugq,Machine Learning in Agriculture,https://www.reddit.com/r/MachineLearning/comments/6cpugq/machine_learning_in_agriculture/,BradJ,1495484960,[removed],0,1
811,2017-5-23,2017,5,23,5,6cpv4b,[N] Wolfram Data Repository new landing page with categorized datasets from agriculture to transportation,https://www.reddit.com/r/MachineLearning/comments/6cpv4b/n_wolfram_data_repository_new_landing_page_with/,sutronice,1495485126,,1,57
812,2017-5-23,2017,5,23,6,6cqcda,[D] Neural nets that refuse to converge,https://www.reddit.com/r/MachineLearning/comments/6cqcda/d_neural_nets_that_refuse_to_converge/,eraaaaaeee,1495489771,"I've used neural nets for several projects, some of which have succeeded and some of which have failed. Almost always, I am forced to write off the failed projects as ""too hard of a problem for today's neural nets to learn"" after spending weeks checking that gradient norms and layer activations stay at reasonable levels, parameters move a reasonable amount, loss functions decay near-monotonically, and network structure/training algorithm is up to date (ReLU/PReLU, ADAM, batch/layer normalization).

Since researchers tend to publish only after they get good results, I know there's some bias towards believing neural nets work more easily than they really do, but I'm curious as to whether other researchers (especially well established ones, e.g. those at DeepMind, OpenAI, and other high-output labs) have these same experiences where they sink weeks into debugging their net without ever conclusively finding what the problem was.

I would also be interested in hearing any techniques beyond those mentioned above for dealing with this problem. I've recently discovered how much more convenient it is to debug networks with TensorBoard, but I feel like there's more I could be plotting than just parameters, gradients, and activations.",30,6
813,2017-5-23,2017,5,23,6,6cqdhg,Unsupervised Coin Sorting with Arduino LED Lighting Augmentation,https://www.reddit.com/r/MachineLearning/comments/6cqdhg/unsupervised_coin_sorting_with_arduino_led/,PaulKrush,1495490091,,1,1
814,2017-5-23,2017,5,23,7,6cqlr3,KB+M Control Classification,https://www.reddit.com/r/MachineLearning/comments/6cqlr3/kbm_control_classification/,[deleted],1495492420,[removed],0,1
815,2017-5-23,2017,5,23,7,6cqpju,PyTorch ACER implementation used for Malmo Challenge,https://www.reddit.com/r/MachineLearning/comments/6cqpju/pytorch_acer_implementation_used_for_malmo/,[deleted],1495493513,[deleted],0,1
816,2017-5-23,2017,5,23,8,6cr1su,Machine Learning Techniques for Predictive Maintenance,https://www.reddit.com/r/MachineLearning/comments/6cr1su/machine_learning_techniques_for_predictive/,srinath_perera,1495497131,,0,1
817,2017-5-23,2017,5,23,9,6crf58,[P]How to Better Classify Coachella With Machine Learning (Part 1),https://www.reddit.com/r/MachineLearning/comments/6crf58/phow_to_better_classify_coachella_with_machine/,tenqyu,1495501188,,0,0
818,2017-5-23,2017,5,23,10,6crlqe,ML problem where one instance has several correct labels: some help?,https://www.reddit.com/r/MachineLearning/comments/6crlqe/ml_problem_where_one_instance_has_several_correct/,[deleted],1495503193,[removed],0,1
819,2017-5-23,2017,5,23,10,6crlv9,[P] Enhance: Word Embedding in Golang: Calculate the cosine similarity between words.,https://www.reddit.com/r/MachineLearning/comments/6crlv9/p_enhance_word_embedding_in_golang_calculate_the/,aqny,1495503237,,1,0
820,2017-5-23,2017,5,23,10,6crm64,[R] On the Effects of Batch and Weight Normalization in Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/6crm64/r_on_the_effects_of_batch_and_weight/,rui_,1495503331,,1,12
821,2017-5-23,2017,5,23,10,6cro6h,[R] Deep Image Analogy (code and demo are released),https://www.reddit.com/r/MachineLearning/comments/6cro6h/r_deep_image_analogy_code_and_demo_are_released/,e_walker,1495503955,,8,62
822,2017-5-23,2017,5,23,11,6crsl8,[D] What's the most black box or magical thing you've learned?,https://www.reddit.com/r/MachineLearning/comments/6crsl8/d_whats_the_most_black_box_or_magical_thing_youve/,LearnDataSci,1495505344,"Can you remember a time when you first saw an algorithm, application, or anything else when learning machine learning and were like ""How the hell does it do that..."" or just had your mind blown?
",36,20
823,2017-5-23,2017,5,23,11,6crvyz,"The Future of Go Summit, Match One: Ke Jie &amp;amp; AlphaGo",https://www.reddit.com/r/MachineLearning/comments/6crvyz/the_future_of_go_summit_match_one_ke_jie_amp/,chogall,1495506455,,0,1
824,2017-5-23,2017,5,23,12,6cs23j,Deep Mind's Alpha Go vs Ke Jie game one,https://www.reddit.com/r/MachineLearning/comments/6cs23j/deep_minds_alpha_go_vs_ke_jie_game_one/,supersammy00,1495508462,,0,1
825,2017-5-23,2017,5,23,12,6cs4bs,[P] GPU-accelerated Keras w. Theano or Tensorflow on Windows 10 native [UPDATED TO Keras2.0.4 + Theano0.9 + Tensorflow 1.1.0 + VS2015 + CUDA8.0.61 + cuDNN5.1],https://www.reddit.com/r/MachineLearning/comments/6cs4bs/p_gpuaccelerated_keras_w_theano_or_tensorflow_on/,tezcaML,1495509213,"If, and only if, you **MUST** run Windows 10 and still want decent performance running Keras with either Theano or Tensorflow as a backend, the following guide may help. It describes GPU acceleration on Windows 10 **in native mode** -- no VMs, no Docker:

[https://github.com/philferriere/dlwin](https://github.com/philferriere/dlwin)

[Alexander Pacha](https://github.com/apacha) made a major contribution to this tutorial by adding support for Tensorflow on Windows 10 and tested it on the following hardware:

* Custom PC, 16GB RAM [Intel i7 4771 @ 3.5 GHz (1 processor, 4 cores total, 8 logical processors)]
* NVIDIA GeForce GTX 1080 Ti, 11GB RAM [Driver version: 382.05 / Win 10 x64]

The following tools/libraries are now used:

* Visual Studio 2015 Community Edition Update 3 w. Windows Kit 10.0.10240.0 [Used for its C/C++ compiler (not its IDE) and SDK]
* CUDA 8.0.61 (64-bit) [Used for its GPU math libraries, card driver, and CUDA compiler]
* MinGW-w64 (5.4.0) [Used for its Unix-like compiler and build tools (g++/gcc, make...) for Windows]
* Anaconda (64-bit) w. Python 2.7 (Anaconda2-4.2.0) [no Tensorflow support] or Python 3.5 (Anaconda3-4.2.0) [for Tensorflow support] [A Python distro that gives us NumPy, SciPy, and other scientific libraries]
* Theano 0.9 [Used to evaluate mathematical expressions on multi-dimensional arrays]
* Tensorflow 1.1.0 [Used to evaluate mathematical expressions on multi-dimensional arrays and serves as an alternate backend to Theano]
* Keras 2.0.4 [Used for deep learning on top of Theano]
* OpenBLAS 0.2.19 (Optional) [Used for its CPU-optimized implementation of many linear algebra operations]
* cuDNN v5.1 (August 10, 2016) for CUDA 8.0 (Recommended) [Used to run vastly faster convolution neural networks]

Hope this helps!",13,20
826,2017-5-23,2017,5,23,12,6cs7us,Question about an RBF and LIF sampler,https://www.reddit.com/r/MachineLearning/comments/6cs7us/question_about_an_rbf_and_lif_sampler/,Laurence-Lin,1495510410,[removed],0,1
827,2017-5-23,2017,5,23,13,6csd2m,[P] AIXIJS: JavaScript library for running General RL agents in the browser.,https://www.reddit.com/r/MachineLearning/comments/6csd2m/p_aixijs_javascript_library_for_running_general/,wei_jok,1495512165,,0,7
828,2017-5-23,2017,5,23,14,6csp81,[P] Introducing Seldon Deploy,https://www.reddit.com/r/MachineLearning/comments/6csp81/p_introducing_seldon_deploy/,ahousley,1495516759,,0,1
829,2017-5-23,2017,5,23,14,6cssnb,[D] Is there any good step by step guides that explain how to train and deploy a image classification model on Google's Cloud ML Engine?,https://www.reddit.com/r/MachineLearning/comments/6cssnb/d_is_there_any_good_step_by_step_guides_that/,redditpirateroberts,1495518217,"SO far I have found the following two guides on how to do this:

https://cloud.google.com/blog/big-data/2016/12/how-to-classify-images-with-tensorflow-using-google-cloud-machine-learning-and-cloud-dataflow

https://codelabs.developers.google.com/codelabs/cloud-ml-engine-image-classification/index.html?index=..%2F..%2Findex#0

But when I follow these neither of them work and I run into problems. Is there any more complete, step by step guide on how to do this?",0,1
830,2017-5-23,2017,5,23,15,6ct26r,What characteristics does industrial dough mixer machine for sale have?,https://www.reddit.com/r/MachineLearning/comments/6ct26r/what_characteristics_does_industrial_dough_mixer/,mixmachinery,1495522401,,0,1
831,2017-5-23,2017,5,23,15,6ct2sl,"""#AlphaGo wins game 1! Ke Jie fought bravely and some wonderful moves were played."" - Demis Hassabis",https://www.reddit.com/r/MachineLearning/comments/6ct2sl/alphago_wins_game_1_ke_jie_fought_bravely_and/,[deleted],1495522680,[deleted],0,1
832,2017-5-23,2017,5,23,16,6ct31x,"[N] ""#AlphaGo wins game 1! Ke Jie fought bravely and some wonderful moves were played."" - Demis Hassabis",https://www.reddit.com/r/MachineLearning/comments/6ct31x/n_alphago_wins_game_1_ke_jie_fought_bravely_and/,Eurchus,1495522809,,96,361
833,2017-5-23,2017,5,23,16,6ct4rc,How to Prevent an AI Apocalypse,https://www.reddit.com/r/MachineLearning/comments/6ct4rc/how_to_prevent_an_ai_apocalypse/,funmaster11,1495523553,,0,1
834,2017-5-23,2017,5,23,16,6ct6cd,XGBoost GPU precompiled for Win 64?,https://www.reddit.com/r/MachineLearning/comments/6ct6cd/xgboost_gpu_precompiled_for_win_64/,[deleted],1495524276,[removed],0,1
835,2017-5-23,2017,5,23,17,6ctatl,[P] A PyTorch ACER implementation used for the Microsoft Malmo Challenge,https://www.reddit.com/r/MachineLearning/comments/6ctatl/p_a_pytorch_acer_implementation_used_for_the/,pawni,1495526419,,0,11
836,2017-5-23,2017,5,23,17,6ctdmz,Automatic Bottle Washer Filler Capper Line,https://www.reddit.com/r/MachineLearning/comments/6ctdmz/automatic_bottle_washer_filler_capper_line/,neostarpack,1495527826,,0,1
837,2017-5-23,2017,5,23,18,6ctiak,[R] Beyond Quantization. Modeling Continuous Densities with Deep Kernel Mixture Networks.,https://www.reddit.com/r/MachineLearning/comments/6ctiak/r_beyond_quantization_modeling_continuous/,LucaAmbrogioni,1495530150,,11,14
838,2017-5-23,2017,5,23,18,6ctl1x,European metadata augmentation companies,https://www.reddit.com/r/MachineLearning/comments/6ctl1x/european_metadata_augmentation_companies/,SummitSnowStorm,1495531418,[removed],0,1
839,2017-5-23,2017,5,23,18,6ctmk2,Frequentist regret bounds for Bayesian-inspired exploration in Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/6ctmk2/frequentist_regret_bounds_for_bayesianinspired/,Bayes-Ian,1495532122,,0,1
840,2017-5-23,2017,5,23,20,6cty38,Human Pose Detection - Mining Body Language from Videos (using OpenPose),https://www.reddit.com/r/MachineLearning/comments/6cty38/human_pose_detection_mining_body_language_from/,samim23,1495537328,,1,1
841,2017-5-23,2017,5,23,21,6cu9sh,Applying deep learning to real-world problems: 3 lessons from our work at Merantix,https://www.reddit.com/r/MachineLearning/comments/6cu9sh/applying_deep_learning_to_realworld_problems_3/,[deleted],1495541772,[deleted],0,1
842,2017-5-23,2017,5,23,21,6cublk,Applying deep learning to real-world problems: 3 lessons from our work at Merantix,https://www.reddit.com/r/MachineLearning/comments/6cublk/applying_deep_learning_to_realworld_problems_3/,[deleted],1495542380,[deleted],0,1
843,2017-5-23,2017,5,23,21,6cudf5,[R] Applying deep learning to real-world problems: 3 lessons from our work at Merantix,https://www.reddit.com/r/MachineLearning/comments/6cudf5/r_applying_deep_learning_to_realworld_problems_3/,rrothe,1495542992,,4,20
844,2017-5-23,2017,5,23,21,6cuf63,[R] [1705.07860] On-the-fly Operation Batching in Dynamic Computation Graphs &lt;-- no more manual batching,https://www.reddit.com/r/MachineLearning/comments/6cuf63/r_170507860_onthefly_operation_batching_in/,evc123,1495543557,,6,14
845,2017-5-23,2017,5,23,23,6cuuzx,Mathematical intuition behind AdaMax,https://www.reddit.com/r/MachineLearning/comments/6cuuzx/mathematical_intuition_behind_adamax/,Eternahl,1495548414,[removed],0,1
846,2017-5-23,2017,5,23,23,6cv2qv,"[P] Xcessiv is a tool to help you create the biggest, craziest, and most excessive (heh) stacked ensembles you can think of.",https://www.reddit.com/r/MachineLearning/comments/6cv2qv/p_xcessiv_is_a_tool_to_help_you_create_the/,[deleted],1495550614,[deleted],1,1
847,2017-5-23,2017,5,23,23,6cv3bt,[R] Reducing Reparameterization Gradient Variance (blog post + paper + code),https://www.reddit.com/r/MachineLearning/comments/6cv3bt/r_reducing_reparameterization_gradient_variance/,acmueller,1495550767,,0,16
848,2017-5-24,2017,5,24,0,6cv780,"[P] Xcessiv is a tool to help you create the biggest, craziest, and most excessive (heh) stacked ensembles you can think of.",https://www.reddit.com/r/MachineLearning/comments/6cv780/p_xcessiv_is_a_tool_to_help_you_create_the/,[deleted],1495551817,[deleted],3,56
849,2017-5-24,2017,5,24,1,6cvoiu,18 online resources to learn deep learning,https://www.reddit.com/r/MachineLearning/comments/6cvoiu/18_online_resources_to_learn_deep_learning/,smartsg,1495556310,,0,1
850,2017-5-24,2017,5,24,1,6cvpc1,[R] [1705.07832] Concrete Dropout &lt;-- learnable dropout probabilities!!,https://www.reddit.com/r/MachineLearning/comments/6cvpc1/r_170507832_concrete_dropout_learnable_dropout/,evc123,1495556519,,6,13
851,2017-5-24,2017,5,24,1,6cvs3d,"[P] Thinking of building Affordable GPU hosting designed for Machine Learning, was wondering if there is interest.",https://www.reddit.com/r/MachineLearning/comments/6cvs3d/p_thinking_of_building_affordable_gpu_hosting/,ownthisfield,1495557211,"Having been victim of expensive gpu hosting on aws and google cloud. I have discovered a selection of hardware and software optmisations that can cut costs dramatically and charge a fraction of the their cost with the same releative performance. So i was wondering if anyone was interested in such a service. 

Price measure: a AWS p2.xlarge costs $0.9/hr which is only 1 gpu. 
For $0.9/hr my specs can provide up to 4 gpus with even better performance than the p2.xlarge. 


I've made a web page which briefly outlines the project at: www.epochs.ml


And a sign up form, to apply for early access: https://epochs.paperform.co/",29,20
852,2017-5-24,2017,5,24,1,6cvwcg,Has anyone seen applications of Tensorflow in remote sensing/satellite data?,https://www.reddit.com/r/MachineLearning/comments/6cvwcg/has_anyone_seen_applications_of_tensorflow_in/,magkum123,1495558290,[removed],0,1
853,2017-5-24,2017,5,24,2,6cw17z,The High-Dimensional Geometry of Binary Neural Networks,https://www.reddit.com/r/MachineLearning/comments/6cw17z/the_highdimensional_geometry_of_binary_neural/,[deleted],1495559514,[deleted],0,1
854,2017-5-24,2017,5,24,2,6cw3nr,The High-Dimensional Geometry of Binary Neural Networks,https://www.reddit.com/r/MachineLearning/comments/6cw3nr/the_highdimensional_geometry_of_binary_neural/,[deleted],1495560134,[deleted],0,1
855,2017-5-24,2017,5,24,2,6cw4va,"[D] March Machine Learning Mania, 5th Place Winners Interview: David Scott",https://www.reddit.com/r/MachineLearning/comments/6cw4va/d_march_machine_learning_mania_5th_place_winners/,_alphamaximus_,1495560450,,0,1
856,2017-5-24,2017,5,24,2,6cw62v,[R] The High-Dimensional Geometry of Binary Neural Networks,https://www.reddit.com/r/MachineLearning/comments/6cw62v/r_the_highdimensional_geometry_of_binary_neural/,alex_ml,1495560749,,12,26
857,2017-5-24,2017,5,24,2,6cw7g8,[D] Upcoming University of Toronto Fields Institute for Research in Mathematical Sciences - Machine Learning Advances and Applications Seminar,https://www.reddit.com/r/MachineLearning/comments/6cw7g8/d_upcoming_university_of_toronto_fields_institute/,UofTNeuralNet,1495561095,,0,5
858,2017-5-24,2017,5,24,2,6cwbkr,How does a machine learning system store its learned memory ?,https://www.reddit.com/r/MachineLearning/comments/6cwbkr/how_does_a_machine_learning_system_store_its/,urbanhood,1495562157,[removed],0,1
859,2017-5-24,2017,5,24,4,6cwv45,[D] What new AR filters can be built using Pose Detection?,https://www.reddit.com/r/MachineLearning/comments/6cwv45/d_what_new_ar_filters_can_be_built_using_pose/,singham,1495567143,http://prostheticknowledge.tumblr.com/post/160992911996/human-pose-detection-mining-body-language-from,2,1
860,2017-5-24,2017,5,24,4,6cwva4,VAE with a VampPrior,https://www.reddit.com/r/MachineLearning/comments/6cwva4/vae_with_a_vampprior/,goblin_got_game,1495567179,,0,1
861,2017-5-24,2017,5,24,4,6cww91,[R] Accelerated Hierarchical Density Clustering,https://www.reddit.com/r/MachineLearning/comments/6cww91/r_accelerated_hierarchical_density_clustering/,lmcinnes,1495567447,,2,3
862,2017-5-24,2017,5,24,4,6cwycv,"[R] ""Backprop without Learning Rates Through Coin Betting"", Orabona &amp; Tommasi 2017",https://www.reddit.com/r/MachineLearning/comments/6cwycv/r_backprop_without_learning_rates_through_coin/,gwern,1495567996,,22,48
863,2017-5-24,2017,5,24,5,6cx64l,[P] Word2vec for computer-assisted creation of rhyming definitions &amp; Book of Genesis with words starting with 'a',https://www.reddit.com/r/MachineLearning/comments/6cx64l/p_word2vec_for_computerassisted_creation_of/,gwern,1495569970,,3,19
864,2017-5-24,2017,5,24,5,6cx7bj,Machine learning implementation video,https://www.reddit.com/r/MachineLearning/comments/6cx7bj/machine_learning_implementation_video/,sagivmal,1495570270,[removed],0,1
865,2017-5-24,2017,5,24,5,6cxe8j,[Research] Tool Construction in an Articulated Limb Controlled by Evolved Neural Circuits,https://www.reddit.com/r/MachineLearning/comments/6cxe8j/research_tool_construction_in_an_articulated_limb/,ActiveInference,1495572077,,2,0
866,2017-5-24,2017,5,24,6,6cxo8w,[P] Skater is a new Python library for model agnostic interpretation,https://www.reddit.com/r/MachineLearning/comments/6cxo8w/p_skater_is_a_new_python_library_for_model/,DataScienceInc,1495574708,,2,18
867,2017-5-24,2017,5,24,7,6cxz09,Best file format for deep learning when dealing with textbooks?,https://www.reddit.com/r/MachineLearning/comments/6cxz09/best_file_format_for_deep_learning_when_dealing/,Baconator4815162342,1495577679,[removed],0,1
868,2017-5-24,2017,5,24,8,6cy9zx,[D] Scientific Method-based Generative Models?,https://www.reddit.com/r/MachineLearning/comments/6cy9zx/d_scientific_methodbased_generative_models/,normally_i_lurk,1495580847,"Are there any DNN architectures out there based on the Scientific Method? That is to say, the model would continuously develop and test hypotheses regarding how information is abstracted in a given environment.",6,6
869,2017-5-24,2017,5,24,8,6cyhto,"In the future, any app built without machine learning technology will be considered a ""dumb application.""",https://www.reddit.com/r/MachineLearning/comments/6cyhto/in_the_future_any_app_built_without_machine/,[deleted],1495583227,[removed],0,1
870,2017-5-24,2017,5,24,9,6cyo9x,[R] Ternary Neural Networks with Fine-Grained Quantization,https://www.reddit.com/r/MachineLearning/comments/6cyo9x/r_ternary_neural_networks_with_finegrained/,dharma-1,1495585211,,0,0
871,2017-5-24,2017,5,24,9,6cypv8,Is it possible to use google voice recognition for offline commands?,https://www.reddit.com/r/MachineLearning/comments/6cypv8/is_it_possible_to_use_google_voice_recognition/,Kousket,1495585673,[removed],0,1
872,2017-5-24,2017,5,24,9,6cyqld,Created an IndieGogo for a MOOC - Neural networks for hackers,https://www.reddit.com/r/MachineLearning/comments/6cyqld/created_an_indiegogo_for_a_mooc_neural_networks/,happinesssIs,1495585883,,0,1
873,2017-5-24,2017,5,24,10,6cz0mu,Explaining How End-to-End Deep Learning Steers a Self-Driving Car,https://www.reddit.com/r/MachineLearning/comments/6cz0mu/explaining_how_endtoend_deep_learning_steers_a/,harrism,1495589009,,0,1
874,2017-5-24,2017,5,24,10,6cz4k4,YouTube channel stealing machine learning videos,https://www.reddit.com/r/MachineLearning/comments/6cz4k4/youtube_channel_stealing_machine_learning_videos/,ch3njus,1495590207,[removed],0,1
875,2017-5-24,2017,5,24,11,6cza0z,Autonomous F16 now flies better than human pilot!,https://www.reddit.com/r/MachineLearning/comments/6cza0z/autonomous_f16_now_flies_better_than_human_pilot/,multiscaleistheworld,1495591887,,0,1
876,2017-5-24,2017,5,24,11,6czdyp,"""Parallel Stochastic Gradient Descent with Sound Combiners"", Maleki et al 2017",https://www.reddit.com/r/MachineLearning/comments/6czdyp/parallel_stochastic_gradient_descent_with_sound/,gwern,1495593114,,1,1
877,2017-5-24,2017,5,24,11,6czery,[D] Why methods like DCGAN and WGAN just generate simple faces&amp;scenes?,https://www.reddit.com/r/MachineLearning/comments/6czery/d_why_methods_like_dcgan_and_wgan_just_generate/,gaosq0604,1495593381,"I wanna know about the difference about faces and the whole human body with its background. Is it just hardware source problem? 
Also I think natural interaction between human and background is worth researching like adding another discriminator to judge the interaction.
I'm now searching research topic now and do you think this one is worth doing(whole human body, then with background interaction)?",6,1
878,2017-5-24,2017,5,24,11,6czg85,Is it impossible to increase the resolution of cGAN input/output?,https://www.reddit.com/r/MachineLearning/comments/6czg85/is_it_impossible_to_increase_the_resolution_of/,[deleted],1495593848,[removed],0,1
879,2017-5-24,2017,5,24,12,6czlty,[D] Upsampling vs. weighting: what's the best way to handle unbalanced training sets?,https://www.reddit.com/r/MachineLearning/comments/6czlty/d_upsampling_vs_weighting_whats_the_best_way_to/,changoplatanero,1495595708,I'm making a language model and I have some text from one domain that I care a lot about and much more text from a general domain that I care less about. To give more weight to the in-domain data I can either sample it more frequently when creating mini-batches or I can increase it's weight when computing the loss. Is there any reason to prefer one approach over the other?,16,9
880,2017-5-24,2017,5,24,12,6cznfc,[D] Is it possible to increase the input/output resolution of cGANs (or generative image deepnets in general)?,https://www.reddit.com/r/MachineLearning/comments/6cznfc/d_is_it_possible_to_increase_the_inputoutput/,pkuznets,1495596249,"I want to apply algos like pix2pix and cycleGAN to high resolution photographs, but the github implementations seem to be limited to 256x256 input/output. I've heard that convolutions can be applied to arbitrarily large images, but I'm not sure how to do that in practice. Any advice/resources on doing this or attempts/successes at tackling this exact sort of problem?",9,11
881,2017-5-24,2017,5,24,13,6czyg2,A simulation of the Multi-Armed Bandit problem,https://www.reddit.com/r/MachineLearning/comments/6czyg2/a_simulation_of_the_multiarmed_bandit_problem/,puzzler10,1495600224,,0,1
882,2017-5-24,2017,5,24,15,6d0c81,Machine Learning Weekly News Mailing List,https://www.reddit.com/r/MachineLearning/comments/6d0c81/machine_learning_weekly_news_mailing_list/,anoushkavaswani,1495605871,,0,1
883,2017-5-24,2017,5,24,16,6d0p7h,[R] The Marginal Value of Adaptive Gradient Methods in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6d0p7h/r_the_marginal_value_of_adaptive_gradient_methods/,x2342,1495611692,,15,33
884,2017-5-24,2017,5,24,17,6d0xx0,Machine learning with OBD2 data?,https://www.reddit.com/r/MachineLearning/comments/6d0xx0/machine_learning_with_obd2_data/,EpiphanyMania1312,1495615999,[removed],0,1
885,2017-5-24,2017,5,24,18,6d11or,[P] DEvol: Automated deep neural network design with genetic programming,https://www.reddit.com/r/MachineLearning/comments/6d11or/p_devol_automated_deep_neural_network_design_with/,tim_anglade,1495617779,,34,134
886,2017-5-24,2017,5,24,19,6d183m,Fully convolutional network as classification,https://www.reddit.com/r/MachineLearning/comments/6d183m/fully_convolutional_network_as_classification/,[deleted],1495620702,[removed],0,1
887,2017-5-24,2017,5,24,19,6d19xm,[D] Classification task with fully convolutional networks,https://www.reddit.com/r/MachineLearning/comments/6d19xm/d_classification_task_with_fully_convolutional/,marcjschmidt,1495621489,"I wonder, if anyone of you knows a paper that describes an architecture that uses a fully convolutional network (only conv layer, no dense layer) for pure classification tasks (is object x in picture, no segmentation) without the need for training data where every pixel is labeled? (like in segmentation tasks, you need special training data where each pixel is labeled). I'm working currently on a type of net that achieves that, but I don't want to make unnecessary work if this already exists. All networks I can find are segmentation networks, which you can of course use to do classification, but you need always pixel-wise labeled training data, which are very expensive to get.",1,1
888,2017-5-24,2017,5,24,19,6d1che,[R] Anatomically Constrained Neural Networks (ACNN): Application to Cardiac Image Enhancement and Segmentation,https://www.reddit.com/r/MachineLearning/comments/6d1che/r_anatomically_constrained_neural_networks_acnn/,senorstallone,1495622614,,0,2
889,2017-5-24,2017,5,24,19,6d1ec2,"The Bleeding Edge of Medical AI Research (part 1), an in depth review of the Google paper on diabetic retinopathy",https://www.reddit.com/r/MachineLearning/comments/6d1ec2/the_bleeding_edge_of_medical_ai_research_part_1/,[deleted],1495623401,[deleted],1,1
890,2017-5-24,2017,5,24,20,6d1gl5,"[D] The Bleeding Edge of Medical AI Research (Part 1), an in-depth review of the Google paper on retinopathy",https://www.reddit.com/r/MachineLearning/comments/6d1gl5/d_the_bleeding_edge_of_medical_ai_research_part_1/,drlukeor,1495624291,,15,23
891,2017-5-24,2017,5,24,20,6d1jpb,[D] How to handle multiple data sources with varying availability?,https://www.reddit.com/r/MachineLearning/comments/6d1jpb/d_how_to_handle_multiple_data_sources_with/,Geilminister,1495625498,"**Problem description**:
I have two data sources: A, B that comes in pairs, e.g. (a1, b1) that I use to predict Y. However B is sometimes missing e.g. (a2, _). (A is always available) I would like to setup a neural network to be able to take an input pair (a, b) and an A input alone (a, _). 

**Question**: What is the best way to set this up? 

___
The things I have thought of so far

* The naive approach would be to just pass a mask of zeros in b's place?
* Two encoders, One decoder: Have two different encoders encode to the same latent space, and one decoder.

*I am interested in this problem in the general case, but for reference A is an image, and B is flow information. Y is dense segmentation*",4,3
892,2017-5-24,2017,5,24,20,6d1kpl,Faster-RCNN vs Yolo for Faces/License Plates detection,https://www.reddit.com/r/MachineLearning/comments/6d1kpl/fasterrcnn_vs_yolo_for_faceslicense_plates/,[deleted],1495625889,[removed],0,1
893,2017-5-24,2017,5,24,20,6d1o1k,"Deep learning for natural language processing, Part 1",https://www.reddit.com/r/MachineLearning/comments/6d1o1k/deep_learning_for_natural_language_processing/,IdaBzo,1495627134,,0,1
894,2017-5-24,2017,5,24,21,6d1q4t,A Gentle Introduction to Gradient Descent for Programmers,https://www.reddit.com/r/MachineLearning/comments/6d1q4t/a_gentle_introduction_to_gradient_descent_for/,AlanZucconi,1495627886,,0,1
895,2017-5-24,2017,5,24,21,6d1sau,Shot blasting procedure,https://www.reddit.com/r/MachineLearning/comments/6d1sau/shot_blasting_procedure/,surfaceinnov,1495628646,,0,1
896,2017-5-24,2017,5,24,21,6d1sed,[PROJECT] Music generated by my RNN using gregorian chant (dataset link in first message),https://www.reddit.com/r/MachineLearning/comments/6d1sed/project_music_generated_by_my_rnn_using_gregorian/,electricjimi,1495628674,,6,8
897,2017-5-24,2017,5,24,21,6d1ukz,Shot blasting procedure,https://www.reddit.com/r/MachineLearning/comments/6d1ukz/shot_blasting_procedure/,surfaceinnov,1495629427,[removed],0,1
898,2017-5-24,2017,5,24,21,6d1xwx,"[D] Dilemma between graduation topics: ""variational inference on audio data"" or ""semantic segmentation on image data""",https://www.reddit.com/r/MachineLearning/comments/6d1xwx/d_dilemma_between_graduation_topics_variational/,RobRomijnders,1495630563,"I got two options to write my graduation thesis. 
At my university, graduation spans a 9 month period working full time on an assigned research question. That's a huge time investment, so I want to make a wise choice. 

  * Option 1: 

    * __Focus__ on variational inference and message passing. Data = audio. 
    * __Cornerstone paper__ [on predictive coding](https://coxlab.github.io/prednet/)
    * [website of professor and lab](https://biaslab.github.io/)
    * My __colleagues__ would be people working a lot with gaussian processes, no particular deep learning experience
    * __Technology stack:__ The lab works mostly in Julia. No signs of GPU's or distributed hardware.

  * Option 2:

    * __Focus__ on Adversarial training and semantic segmentation. Data = images from self-driving car
    * __Cornerstone paper__ [Semantic Segmentation using Adversarial Networks](https://arxiv.org/abs/1611.08408) 
    * [website of professor and lab](http://www.gijsdubbelman.com/)
    * My __colleagues__ would be two PhD's working a lot on (semantic) segmentation. They have a ResNet implemented that I can use. (both code and as trained model)
    * __Technology stack:__ The lab works mostly with Tensorflow/Caffe. Two desktops with Tesla K80 installed. (that's how they train the ResNet)


I've been doubting for weeks on this decision. I need to announce my choice in ten days. What would you advise me?

Thanks in advance for your comments!",10,2
899,2017-5-24,2017,5,24,22,6d23o8,Mini CNC Build,https://www.reddit.com/r/MachineLearning/comments/6d23o8/mini_cnc_build/,_SpeedyStriker_,1495632286,[removed],0,1
900,2017-5-24,2017,5,24,23,6d2gz9,"[R] [1705.08168] Look, Listen and Learn",https://www.reddit.com/r/MachineLearning/comments/6d2gz9/r_170508168_look_listen_and_learn/,downtownslim,1495636127,,0,3
901,2017-5-25,2017,5,25,0,6d2tam,Why is it useful to sample probability distributions models?,https://www.reddit.com/r/MachineLearning/comments/6d2tam/why_is_it_useful_to_sample_probability/,real_pinocchio,1495639437,,0,1
902,2017-5-25,2017,5,25,0,6d2wl9,What is the fastest (fps) object detection algorithm for a cpu-only machine,https://www.reddit.com/r/MachineLearning/comments/6d2wl9/what_is_the_fastest_fps_object_detection/,hannibaldon,1495640283,[removed],0,1
903,2017-5-25,2017,5,25,0,6d2zco,[R] ICML 2017 Accepted Papers,https://www.reddit.com/r/MachineLearning/comments/6d2zco/r_icml_2017_accepted_papers/,iidealized,1495640982,,19,44
904,2017-5-25,2017,5,25,0,6d30rc,"Simple Questions Thread May 24, 2017",https://www.reddit.com/r/MachineLearning/comments/6d30rc/simple_questions_thread_may_24_2017/,AutoModerator,1495641337,[removed],0,1
905,2017-5-25,2017,5,25,1,6d34ot,[P] OpenAI Baselines: DQN,https://www.reddit.com/r/MachineLearning/comments/6d34ot/p_openai_baselines_dqn/,madebyollin,1495642353,,8,154
906,2017-5-25,2017,5,25,1,6d38ke,"[R] Learning to communicate to learn (Communication, Part 2)",https://www.reddit.com/r/MachineLearning/comments/6d38ke/r_learning_to_communicate_to_learn_communication/,NichG,1495643336,,0,10
907,2017-5-25,2017,5,25,1,6d3ekf,[R] Automatic Handgun Detection Alarm in Videos Using Deep Learning,https://www.reddit.com/r/MachineLearning/comments/6d3ekf/r_automatic_handgun_detection_alarm_in_videos/,luiscosio,1495644865,,0,1
908,2017-5-25,2017,5,25,2,6d3i6c,[D] - Measuring orthogonality of descent directions to adapt learning rate?,https://www.reddit.com/r/MachineLearning/comments/6d3i6c/d_measuring_orthogonality_of_descent_directions/,abello966,1495645773,"Hello everyone

I'm doing a non-linear optimization course this semester and one of the results I was presented with was that in gradient descent when you define the step/learning rate via optimization (i.e the learning rate minimizes the function in the direction of descent), you always get descent directions that are ortoghonal with relation to the one before. 

I was wondering if someone tried measuring the orthogonality of descent directions during a ML algorithm. Could this give some information useful for adjusting the learning rate (i.e when the internal product is positive you can increase, when negative you can decrease)? Or are the functions too complex and bad-behaved to do this? A quick search in google and arxiv didnt bring up any answers",7,3
909,2017-5-25,2017,5,25,2,6d3knk,AMD's game plan to become a machine learning giant,https://www.reddit.com/r/MachineLearning/comments/6d3knk/amds_game_plan_to_become_a_machine_learning_giant/,[deleted],1495646401,[deleted],0,1
910,2017-5-25,2017,5,25,3,6d3xty,[D] AMD's game plan to become a machine learning giant,https://www.reddit.com/r/MachineLearning/comments/6d3xty/d_amds_game_plan_to_become_a_machine_learning/,keptavista,1495649757,,6,5
911,2017-5-25,2017,5,25,3,6d43tj,PyTorch Implementation of the Variational Autoencoder.,https://www.reddit.com/r/MachineLearning/comments/6d43tj/pytorch_implementation_of_the_variational/,ethanluoyc,1495651302,,0,1
912,2017-5-25,2017,5,25,3,6d44i7,[D] How to use Gumbel-Softmax for Policy Gradient methods?,https://www.reddit.com/r/MachineLearning/comments/6d44i7/d_how_to_use_gumbelsoftmax_for_policy_gradient/,godofprobability,1495651488,"I understand that [Gumbel-Softmax](https://arxiv.org/abs/1611.01144) create a differentiable proxy for samples from categorical distributions, hence can be used in variational inference methods where expectation is over categorical distribution. But I am failing to grasp its importance for policy gradient methods. Specifically, in policy gradient methods you have:
$$\delta_w E_{p(z, \theta)}[f(z)\delta_{\theta} log(p(z: \theta))]$$

In general, in policy gradient methods, we have f(z) as a reward function which is **non-differentiable** (in my case). My question is how can I improve policy gradient based network using Gumbel-Softmax?",4,1
913,2017-5-25,2017,5,25,3,6d45ev,"[Research] Looking for some finished ""sorting"" projects to learn about",https://www.reddit.com/r/MachineLearning/comments/6d45ev/research_looking_for_some_finished_sorting/,monkeymonkey35,1495651726,"Not a programmer, but looking to learn about interesting projects similar to the [Lego Sorter](https://jacquesmattheij.com/sorting-two-metric-tons-of-lego) and the [Mushroom recognition app](https://www.reddit.com/r/MachineLearning/comments/6cojgi/p_mushroom_recognition_by_photo_ios_app/)",5,1
914,2017-5-25,2017,5,25,4,6d4c2c,Why softmax and ReLU?,https://www.reddit.com/r/MachineLearning/comments/6d4c2c/why_softmax_and_relu/,riel234,1495653443,[removed],0,1
915,2017-5-25,2017,5,25,4,6d4gl2,"[R] ""Sluice networks: Learning what to share between loosely related tasks"", Ruder et al 2017",https://www.reddit.com/r/MachineLearning/comments/6d4gl2/r_sluice_networks_learning_what_to_share_between/,gwern,1495654629,,0,14
916,2017-5-25,2017,5,25,5,6d4u54,Are there computer viruses based on machine learning?,https://www.reddit.com/r/MachineLearning/comments/6d4u54/are_there_computer_viruses_based_on_machine/,pepitolander,1495658151,[removed],0,1
917,2017-5-25,2017,5,25,5,6d4xbm,[R] Neural Networks for Hackers - The Course I Wish I'd Had,https://www.reddit.com/r/MachineLearning/comments/6d4xbm/r_neural_networks_for_hackers_the_course_i_wish/,SpeakMouthWords,1495658957,,0,0
918,2017-5-25,2017,5,25,6,6d56qc,iPlexus Launched at BioIT 2017 leverages AI &amp; Machine Learning to cut drug development time and cost,https://www.reddit.com/r/MachineLearning/comments/6d56qc/iplexus_launched_at_bioit_2017_leverages_ai/,cbil360,1495661409,,0,1
919,2017-5-25,2017,5,25,6,6d5aus,Layering two machine learning algorithms?,https://www.reddit.com/r/MachineLearning/comments/6d5aus/layering_two_machine_learning_algorithms/,Deepadarshan,1495662520,[removed],0,1
920,2017-5-25,2017,5,25,7,6d5djy,"[D] Deep Learning Is Not Good Enough, We Need Bayesian Deep Learning for Safe AI",https://www.reddit.com/r/MachineLearning/comments/6d5djy/d_deep_learning_is_not_good_enough_we_need/,_alphamaximus_,1495663241,,27,51
921,2017-5-25,2017,5,25,7,6d5emx,Suitable algorithms for different types of data-set,https://www.reddit.com/r/MachineLearning/comments/6d5emx/suitable_algorithms_for_different_types_of_dataset/,katilililumplet,1495663541,[removed],0,1
922,2017-5-25,2017,5,25,7,6d5i7b,[D] xcessiv/README.md at master  reiinakano/xcessiv,https://www.reddit.com/r/MachineLearning/comments/6d5i7b/d_xcessivreadmemd_at_master_reiinakanoxcessiv/,_alphamaximus_,1495664534,,0,1
923,2017-5-25,2017,5,25,7,6d5mj7,Want to try out deep learning without running any code? Darknet now has a Twitter API!,https://www.reddit.com/r/MachineLearning/comments/6d5mj7/want_to_try_out_deep_learning_without_running_any/,[deleted],1495665742,[deleted],0,1
924,2017-5-25,2017,5,25,7,6d5pdc,"[P] Darknet now has a Twitter API! Play with state-of-the-art models, no coding or GPUs needed",https://www.reddit.com/r/MachineLearning/comments/6d5pdc/p_darknet_now_has_a_twitter_api_play_with/,pjreddie,1495666565,,3,70
925,2017-5-25,2017,5,25,9,6d64vv,[Project] first attempt at object detection,https://www.reddit.com/r/MachineLearning/comments/6d64vv/project_first_attempt_at_object_detection/,skymagic,1495671174,,0,1
926,2017-5-25,2017,5,25,9,6d68wr,"interested in bleeding edge machine learning applications, seefood founder Jian Yang interview on bloomberg tech (xpost from r/videos)",https://www.reddit.com/r/MachineLearning/comments/6d68wr/interested_in_bleeding_edge_machine_learning/,philosochu,1495672347,,0,1
927,2017-5-25,2017,5,25,9,6d6caq,[D] Human benchmark datasets,https://www.reddit.com/r/MachineLearning/comments/6d6caq/d_human_benchmark_datasets/,anonDogeLover,1495673408,Can anyone think of a problem that humans currently solve better than machines that is well exemplified by a particular behavioral dataset? I'm making a list. All ideas welcome,4,9
928,2017-5-25,2017,5,25,10,6d6f8h,"[R] Train longer, generalize better: closing the generalization gap in large batch training of neural networks",https://www.reddit.com/r/MachineLearning/comments/6d6f8h/r_train_longer_generalize_better_closing_the/,xternalz,1495674322,,12,47
929,2017-5-25,2017,5,25,10,6d6jrp,Building up a portfolio - Advice,https://www.reddit.com/r/MachineLearning/comments/6d6jrp/building_up_a_portfolio_advice/,boltzman_machine,1495675801,[removed],0,2
930,2017-5-25,2017,5,25,10,6d6kpm,[R] Causal Effect Inference with Deep Latent-Variable Models,https://www.reddit.com/r/MachineLearning/comments/6d6kpm/r_causal_effect_inference_with_deep/,urish,1495676087,,6,13
931,2017-5-25,2017,5,25,11,6d6z6z,Is there a public slack channel for ML questions/collaboration?,https://www.reddit.com/r/MachineLearning/comments/6d6z6z/is_there_a_public_slack_channel_for_ml/,[deleted],1495680836,[removed],0,1
932,2017-5-25,2017,5,25,12,6d77hq,Radial basis function with sensor values as input,https://www.reddit.com/r/MachineLearning/comments/6d77hq/radial_basis_function_with_sensor_values_as_input/,Laurence-Lin,1495683727,[removed],0,1
933,2017-5-25,2017,5,25,13,6d7grf,Dataset for unsupervised learning: Public Companies + Elements &amp; Minerals,https://www.reddit.com/r/MachineLearning/comments/6d7grf/dataset_for_unsupervised_learning_public/,[deleted],1495687051,[deleted],0,1
934,2017-5-25,2017,5,25,14,6d7lie,[D] How A Data Scientist Can Improve His Productivity By Pipelines,https://www.reddit.com/r/MachineLearning/comments/6d7lie/d_how_a_data_scientist_can_improve_his/,thumbsdrivesmecrazy,1495688860,,0,2
935,2017-5-25,2017,5,25,14,6d7nb1,[D] Machine Learning - WAYR (What Are You Reading) - Week 26,https://www.reddit.com/r/MachineLearning/comments/6d7nb1/d_machine_learning_wayr_what_are_you_reading_week/,ML_WAYR_bot,1495689557,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|
|----|-----|-----|
|[Week 1](https://www.reddit.com/r/MachineLearning/comments/4qyjiq/machine_learning_wayr_what_are_you_reading_week_1/)|[Week 11](https://www.reddit.com/r/MachineLearning/comments/57xw56/discussion_machine_learning_wayr_what_are_you/)|[Week 21](https://www.reddit.com/r/MachineLearning/comments/60ildf/d_machine_learning_wayr_what_are_you_reading_week/)|
|[Week 2](https://www.reddit.com/r/MachineLearning/comments/4s2xqm/machine_learning_wayr_what_are_you_reading_week_2/)|[Week 12](https://www.reddit.com/r/MachineLearning/comments/5acb1t/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 22](https://www.reddit.com/r/MachineLearning/comments/64jwde/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 3](https://www.reddit.com/r/MachineLearning/comments/4t7mqm/machine_learning_wayr_what_are_you_reading_week_3/)|[Week 13](https://www.reddit.com/r/MachineLearning/comments/5cwfb6/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 23](https://www.reddit.com/r/MachineLearning/comments/674331/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 4](https://www.reddit.com/r/MachineLearning/comments/4ub2kw/machine_learning_wayr_what_are_you_reading_week_4/)|[Week 14](https://www.reddit.com/r/MachineLearning/comments/5fc5mh/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 24](https://www.reddit.com/r/MachineLearning/comments/68hhhb/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 5](https://www.reddit.com/r/MachineLearning/comments/4xomf7/machine_learning_wayr_what_are_you_reading_week_5/)|[Week 15](https://www.reddit.com/r/MachineLearning/comments/5hy4ur/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 25](https://www.reddit.com/r/MachineLearning/comments/69teiz/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 6](https://www.reddit.com/r/MachineLearning/comments/4zcyvk/machine_learning_wayr_what_are_you_reading_week_6/)|[Week 16](https://www.reddit.com/r/MachineLearning/comments/5kd6vd/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 7](https://www.reddit.com/r/MachineLearning/comments/52t6mo/machine_learning_wayr_what_are_you_reading_week_7/)|[Week 17](https://www.reddit.com/r/MachineLearning/comments/5ob7dx/discussion_machine_learning_wayr_what_are_you/)||
|[Week 8](https://www.reddit.com/r/MachineLearning/comments/53heol/machine_learning_wayr_what_are_you_reading_week_8/)|[Week 18](https://www.reddit.com/r/MachineLearning/comments/5r14yd/discussion_machine_learning_wayr_what_are_you/)||
|[Week 9](https://www.reddit.com/r/MachineLearning/comments/54kvsu/machine_learning_wayr_what_are_you_reading_week_9/)|[Week 19](https://www.reddit.com/r/MachineLearning/comments/5tt9cz/discussion_machine_learning_wayr_what_are_you/)||
|[Week 10](https://www.reddit.com/r/MachineLearning/comments/56s2oa/discussion_machine_learning_wayr_what_are_you/)|[Week 20](https://www.reddit.com/r/MachineLearning/comments/5wh2wb/d_machine_learning_wayr_what_are_you_reading_week/)||

Most upvoted papers two weeks ago:

/u/ccmlacc: [A Unifying Review of Linear Gaussian Models](https://www.cs.nyu.edu/~roweis/papers/NC110201.pdf)

/u/madapeti: [Geometric deep learning: going beyond Euclidean data](https://arxiv.org/pdf/1611.08097.pdf)

/u/dark_entropy: [Deep Reinforcement Learning with a Natural Language Action Space](https://arxiv.org/pdf/1511.04636.pdf)

Besides that, there are no rules, have fun.",18,45
936,2017-5-25,2017,5,25,14,6d7snh,[1705.08690] Continual Learning with Deep Generative Replay,https://www.reddit.com/r/MachineLearning/comments/6d7snh/170508690_continual_learning_with_deep_generative/,[deleted],1495691778,[deleted],0,8
937,2017-5-25,2017,5,25,15,6d7u4v,[R] Nonlinear Information Bottleneck,https://www.reddit.com/r/MachineLearning/comments/6d7u4v/r_nonlinear_information_bottleneck/,rilut,1495692381,,0,4
938,2017-5-25,2017,5,25,15,6d7vef,4 GPU PC for Kaggle competition,https://www.reddit.com/r/MachineLearning/comments/6d7vef/4_gpu_pc_for_kaggle_competition/,wschong,1495692941,[removed],0,1
939,2017-5-25,2017,5,25,15,6d80es,[R][1705.08690] Continual Learning with Deep Generative Replay,https://www.reddit.com/r/MachineLearning/comments/6d80es/r170508690_continual_learning_with_deep/,shn010203,1495695166,,8,48
940,2017-5-25,2017,5,25,16,6d83hn,[D] links to NIPS 2017 papers,https://www.reddit.com/r/MachineLearning/comments/6d83hn/d_links_to_nips_2017_papers/,evc123,1495696535,,5,2
941,2017-5-25,2017,5,25,16,6d87z0,One-shot imitation learning and verification,https://www.reddit.com/r/MachineLearning/comments/6d87z0/oneshot_imitation_learning_and_verification/,yoav_hollander,1495698739,,0,1
942,2017-5-25,2017,5,25,16,6d88f6,Semi-supervised learning in python using pomegranate [x-post r/python],https://www.reddit.com/r/MachineLearning/comments/6d88f6/semisupervised_learning_in_python_using/,[deleted],1495698962,[deleted],0,1
943,2017-5-25,2017,5,25,17,6d89sa,[R] Fast-Slow Recurrent Neural Networks - SOTA in PTB and enwik8,https://www.reddit.com/r/MachineLearning/comments/6d89sa/r_fastslow_recurrent_neural_networks_sota_in_ptb/,asierm,1495699632,,8,16
944,2017-5-25,2017,5,25,17,6d8dpe,[P] Generate font combinations with deep learning,https://www.reddit.com/r/MachineLearning/comments/6d8dpe/p_generate_font_combinations_with_deep_learning/,pmigdal,1495701594,,13,37
945,2017-5-25,2017,5,25,18,6d8gsq,"A Free Session on ""Introduction to Machine Learning for Quantitative Finance"" by CTO of Quantiacs",https://www.reddit.com/r/MachineLearning/comments/6d8gsq/a_free_session_on_introduction_to_machine/,kaushikqi,1495703141,,0,1
946,2017-5-25,2017,5,25,18,6d8jdb,multiple postdoctoral positions,https://www.reddit.com/r/MachineLearning/comments/6d8jdb/multiple_postdoctoral_positions/,jeffreysbowers,1495704322,[removed],0,1
947,2017-5-25,2017,5,25,19,6d8ppi,Historic UK weather data (x-post from /r/weather),https://www.reddit.com/r/MachineLearning/comments/6d8ppi/historic_uk_weather_data_xpost_from_rweather/,ComaBoyRunning,1495707229,[removed],0,1
948,2017-5-25,2017,5,25,19,6d8v5g,[P] Need suggestions on which optimizers to use for our self-driving car DeepLearning Model.,https://www.reddit.com/r/MachineLearning/comments/6d8v5g/p_need_suggestions_on_which_optimizers_to_use_for/,leeebron,1495709573,"Hi, our team is building a DeepLearning model for a self-driving car

We are currently using basic Adam optimizer, but the training time increases dramatically after third epoch.

We were not able to go beyond 4th epoch due to continual increase of training time.

Our Model uses Keras 2.0. TF backends.
Has about 1.4million parameters. 
layers consist of
 - batch norm
 - 2dConv
 - max pooling
Our training data is around 30gb. 
Training takes about an hour per epoch ( up to third epoch) on Nvidia Tesla K80.
The model contains both classification and regression, concatenated at the end.

Would appreciate any direction or suggestions on which optimizers to use, in order to stop training time to reach infinite.

I think the problem lies within the Keras adam optimizer.",2,0
949,2017-5-25,2017,5,25,20,6d94ok,Huge list of arXiv papers from May 23-25,https://www.reddit.com/r/MachineLearning/comments/6d94ok/huge_list_of_arxiv_papers_from_may_2325/,[deleted],1495713259,[removed],0,1
950,2017-5-25,2017,5,25,20,6d94yd,[R] List of arXiv papers published on May 23-25,https://www.reddit.com/r/MachineLearning/comments/6d94yd/r_list_of_arxiv_papers_published_on_may_2325/,[deleted],1495713364,[deleted],0,2
951,2017-5-25,2017,5,25,21,6d9ccc,Bachelor Thesis in 24 days,https://www.reddit.com/r/MachineLearning/comments/6d9ccc/bachelor_thesis_in_24_days/,MartinMeincke,1495715949,[removed],0,1
952,2017-5-25,2017,5,25,22,6d9ohj,[D] The Long History and Bright Future of Artificial Intelligence in Medicine,https://www.reddit.com/r/MachineLearning/comments/6d9ohj/d_the_long_history_and_bright_future_of/,[deleted],1495719676,[deleted],0,0
953,2017-5-25,2017,5,25,22,6d9r62,[R]DeepMasterPrint: Generating Fingerprints for Presentation Attacks,https://www.reddit.com/r/MachineLearning/comments/6d9r62/rdeepmasterprint_generating_fingerprints_for/,jivatman,1495720509,,0,3
954,2017-5-25,2017,5,25,23,6d9tmp,[D] Everything that works works because it's Bayesian: An overview of new work on generalization in deep nets,https://www.reddit.com/r/MachineLearning/comments/6d9tmp/d_everything_that_works_works_because_its/,fhuszar,1495721235,,68,396
955,2017-5-25,2017,5,25,23,6d9z83,Google's AlphaGo clinches series win over Chinese Go master,https://www.reddit.com/r/MachineLearning/comments/6d9z83/googles_alphago_clinches_series_win_over_chinese/,chrico031,1495722797,,0,1
956,2017-5-25,2017,5,25,23,6da15z,Regression with sparse categorical data in two dimensions,https://www.reddit.com/r/MachineLearning/comments/6da15z/regression_with_sparse_categorical_data_in_two/,niujin,1495723331,[removed],0,1
957,2017-5-25,2017,5,25,23,6da4lw,Automated ML Company DataRobot just acquired Nutonian,https://www.reddit.com/r/MachineLearning/comments/6da4lw/automated_ml_company_datarobot_just_acquired/,dolphinrapeawareness,1495724247,,0,1
958,2017-5-26,2017,5,26,0,6da7pu,[1705.07215] How to Train Your DRAGAN: Training Generative Adversarial Networks with no mode collapse,https://www.reddit.com/r/MachineLearning/comments/6da7pu/170507215_how_to_train_your_dragan_training/,TheOverGrad,1495725077,,1,2
959,2017-5-26,2017,5,26,0,6da9sf,Unsupervised learning applied to the problem of double exponential hypothesis growth,https://www.reddit.com/r/MachineLearning/comments/6da9sf/unsupervised_learning_applied_to_the_problem_of/,jtsymonds,1495725624,,0,1
960,2017-5-26,2017,5,26,0,6dabl7,"The most global developer survey, providing the dev community with knowledge, insights and fun",https://www.reddit.com/r/MachineLearning/comments/6dabl7/the_most_global_developer_survey_providing_the/,Nonstopcoin,1495726100,,0,1
961,2017-5-26,2017,5,26,0,6dafec,(help) Want to use machine-learning + computer vision techniques to program autonomous vehicle in a driving sim game. How to get started?,https://www.reddit.com/r/MachineLearning/comments/6dafec/help_want_to_use_machinelearning_computer_vision/,LesPaulMane,1495727062,[removed],0,1
962,2017-5-26,2017,5,26,0,6dag7x,Benchmark comparison of boosted trees libraries XGBoost and LightGBM,https://www.reddit.com/r/MachineLearning/comments/6dag7x/benchmark_comparison_of_boosted_trees_libraries/,hoaphumanoid,1495727265,,0,1
963,2017-5-26,2017,5,26,1,6damv7,[R] Fast way to find argmax of a radial basis function? (optimization problem).,https://www.reddit.com/r/MachineLearning/comments/6damv7/r_fast_way_to_find_argmax_of_a_radial_basis/,ptitz,1495728980,"I'm working on a continuous state and action Q-learning algorithm, using radial basis nets to store the value function. It works OK, but I'm not completely happy with the way I'm doing the argmax to get the action. Basically I have a radial basis function and I have to find maximum. The function looks like [this](http://i.imgur.com/Kzi9g2F.jpg) more or less.

Things I've tried so far:

PSO optimization. Works ok, but too slow.    
Golden section search. Not that fast either, and prone to stuck in local maximum.    
Polynomial curve fitting. Basically fit a poly curve and then find the max root value. It's analytical, so it works pretty fast, but for low number of poly coefficients it's not very accurate, and for high number you get overfitting problems like you can see on the graph.

The function itself looks pretty simple as you can see. So what else can I try?",6,6
964,2017-5-26,2017,5,26,1,6dao02,[P] Semi-supervised learning in python using pomegranate,https://www.reddit.com/r/MachineLearning/comments/6dao02/p_semisupervised_learning_in_python_using/,ants_rock,1495729264,,0,2
965,2017-5-26,2017,5,26,1,6daqz6,Multiclass classification without supervised learning ?,https://www.reddit.com/r/MachineLearning/comments/6daqz6/multiclass_classification_without_supervised/,bsandyy,1495729964,[removed],1,1
966,2017-5-26,2017,5,26,1,6datha,Need an advice on what path to take,https://www.reddit.com/r/MachineLearning/comments/6datha/need_an_advice_on_what_path_to_take/,valentyn_vasylenko,1495730604,[removed],0,1
967,2017-5-26,2017,5,26,1,6datpq,Transfer Learning,https://www.reddit.com/r/MachineLearning/comments/6datpq/transfer_learning/,yashkatariya,1495730671,,0,1
968,2017-5-26,2017,5,26,1,6davhe,"AMA about Wikipedia and ethical, transparent AI (June 1st at 21:00 UTC/14:00 PST in /r/iAMA)",https://www.reddit.com/r/MachineLearning/comments/6davhe/ama_about_wikipedia_and_ethical_transparent_ai/,flusterer,1495731133,,0,1
969,2017-5-26,2017,5,26,2,6dayt6,COMPUTE LIBRARY FOR DEEP NEURAL NETWORKS (CLDNN),https://www.reddit.com/r/MachineLearning/comments/6dayt6/compute_library_for_deep_neural_networks_cldnn/,[deleted],1495731987,[deleted],0,1
970,2017-5-26,2017,5,26,2,6daz41,[P] COMPUTE LIBRARY FOR DEEP NEURAL NETWORKS (CLDNN),https://www.reddit.com/r/MachineLearning/comments/6daz41/p_compute_library_for_deep_neural_networks_cldnn/,hooba_stank_,1495732061,,1,0
971,2017-5-26,2017,5,26,2,6db3wv,Predictable predictions can be leveraged infinitely,https://www.reddit.com/r/MachineLearning/comments/6db3wv/predictable_predictions_can_be_leveraged/,[deleted],1495733305,[deleted],0,1
972,2017-5-26,2017,5,26,2,6db7n0,From source to target and back: symmetric bi-directional adaptive GAN,https://www.reddit.com/r/MachineLearning/comments/6db7n0/from_source_to_target_and_back_symmetric/,[deleted],1495734239,[deleted],0,1
973,2017-5-26,2017,5,26,2,6dbb4u,[D] Dumb Noob Question,https://www.reddit.com/r/MachineLearning/comments/6dbb4u/d_dumb_noob_question/,fried_ass,1495735157,"So I am a noob, sorry in advance.

Why implement machine learning?

It seems like many small projects that I have seen can be easily hard coded rather than implementing ML code.

For example: A banana farmer creates a machine that can learn to knock out bad banana's from his sorting machine.  The bananas move through a conveyor belt and the ML device learns to detect defects and knock out the bad bananas.  

Why not just hard code this?  ",11,0
974,2017-5-26,2017,5,26,3,6dbdx0,[P] Predictable predictions can be leveraged infinitely,https://www.reddit.com/r/MachineLearning/comments/6dbdx0/p_predictable_predictions_can_be_leveraged/,n_jai,1495735846,,0,3
975,2017-5-26,2017,5,26,4,6dbwnf,[D] What is exactly a Bayesian guy in machine learning?,https://www.reddit.com/r/MachineLearning/comments/6dbwnf/d_what_is_exactly_a_bayesian_guy_in_machine/,fonfonx,1495740727,I read lot of stuff about the Bayesian community (e.g. http://www.inference.vc/everything-that-works-works-because-its-bayesian-2/) but I don't really understand what exactly characterizes a Bayesian guy? What kind of machine learning model does he use? What characterizes Bayesian machine learning?,20,37
976,2017-5-26,2017,5,26,5,6dc31z,[R] Deep Voice 2: Multi-Speaker Neural Text-to-Speech,https://www.reddit.com/r/MachineLearning/comments/6dc31z/r_deep_voice_2_multispeaker_neural_texttospeech/,madebyollin,1495742494,,8,46
977,2017-5-26,2017,5,26,5,6dc66j,[R] [1705.08395] Continual Learning in Generative Adversarial Nets,https://www.reddit.com/r/MachineLearning/comments/6dc66j/r_170508395_continual_learning_in_generative/,l3v3l_up,1495743300,,5,10
978,2017-5-26,2017,5,26,5,6dc7tg,Need help learning about RNNs (and LSTM especially),https://www.reddit.com/r/MachineLearning/comments/6dc7tg/need_help_learning_about_rnns_and_lstm_especially/,garytho,1495743720,[removed],0,1
979,2017-5-26,2017,5,26,5,6dc8ba,From source to target and back: symmetric bi-directional adaptive GAN,https://www.reddit.com/r/MachineLearning/comments/6dc8ba/from_source_to_target_and_back_symmetric/,engharat,1495743860,,0,3
980,2017-5-26,2017,5,26,7,6dcut0,About to pull the trigger on Machine Learning Build.,https://www.reddit.com/r/MachineLearning/comments/6dcut0/about_to_pull_the_trigger_on_machine_learning/,jhatput,1495750055,[removed],0,1
981,2017-5-26,2017,5,26,8,6ddbeq,[D] Is it a good idea to put 8 Titan Xp into a server for deep/machine learning applications?,https://www.reddit.com/r/MachineLearning/comments/6ddbeq/d_is_it_a_good_idea_to_put_8_titan_xp_into_a/,yield22,1495754947,"Titan Xp is much cheaper than Tesla P100 or V100. And it offers comparable single precision computation. So it is tempting to put 8 Titan Xp instead of 8 Tesla P100 into a single server (e.g. supermicro server). But if this is a good idea? If so, why do people even bother to buy Tesla P100? Is it more reliable, run longer before broken?

BTW, it is aimed for research, not production.",14,7
982,2017-5-26,2017,5,26,10,6ddt9p,A workaround for non-determinism in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/6ddt9p/a_workaround_for_nondeterminism_in_tensorflow/,[deleted],1495760669,[deleted],0,1
983,2017-5-26,2017,5,26,10,6ddwcu,"[R] ""Unbiasing Truncated Backpropagation Through Time"", Tallec &amp; Ollivier 2017",https://www.reddit.com/r/MachineLearning/comments/6ddwcu/r_unbiasing_truncated_backpropagation_through/,gwern,1495761656,,5,27
984,2017-5-26,2017,5,26,11,6deaf4,Can anyone link me to best/most comprehensive/up-to-date resource on googles page rank algorithm?,https://www.reddit.com/r/MachineLearning/comments/6deaf4/can_anyone_link_me_to_bestmost/,findandwrite,1495766459,"I'm trying to create a visual representation of the relationship between search terms and google results.
I understand that the page rank algorithm has gone through many iterations over the years and some things that greatly impacted page rank in the past no longer have an effect.
I was hoping someone who was more abreast of the current situation could point me to the most update resource covering the current state of googles page rank algo.
thanks!",0,2
985,2017-5-26,2017,5,26,11,6debqv,Hanger type shot blasting machine,https://www.reddit.com/r/MachineLearning/comments/6debqv/hanger_type_shot_blasting_machine/,Shot-blasting,1495766929,,1,1
986,2017-5-26,2017,5,26,11,6decqs,Principal component Analysis,https://www.reddit.com/r/MachineLearning/comments/6decqs/principal_component_analysis/,mikeyt21,1495767265,,0,1
987,2017-5-26,2017,5,26,12,6denef,[R] [1705.08991] Approximation and Convergence Properties of Generative Adversarial Learning,https://www.reddit.com/r/MachineLearning/comments/6denef/r_170508991_approximation_and_convergence/,ShuangLiu,1495771146,,0,6
988,2017-5-26,2017,5,26,14,6df17l,Submodularity and Deep Neural networks,https://www.reddit.com/r/MachineLearning/comments/6df17l/submodularity_and_deep_neural_networks/,KrisSingh,1495776370,[removed],0,1
989,2017-5-26,2017,5,26,14,6df198,How did you first break into Machine Learning/Data Science?,https://www.reddit.com/r/MachineLearning/comments/6df198/how_did_you_first_break_into_machine_learningdata/,[deleted],1495776384,[removed],0,1
990,2017-5-26,2017,5,26,14,6df1tm,[D] How did you first break into Machine Learning/Data Science?,https://www.reddit.com/r/MachineLearning/comments/6df1tm/d_how_did_you_first_break_into_machine/,datavinci,1495776612,"What I mean to say is this:-

1. What kind of side projects you did?

2. Any Internships or other kind of opportunities,etc. ?

3. Any postgraduate qualifications like masters that helped?


All I want to know in short is that what helped landing your first **job** or  **internship** and how difficult was it?

Note:- Crossposted from datascience subreddit,FYI",53,44
991,2017-5-26,2017,5,26,15,6df9oj,[R] A workaround for non-determinism in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/6df9oj/r_a_workaround_for_nondeterminism_in_tensorflow/,carmichael561,1495779934,,4,12
992,2017-5-26,2017,5,26,15,6df9rt,"[R] NIPS 2016: A survey of tutorials, papers, and workshops",https://www.reddit.com/r/MachineLearning/comments/6df9rt/r_nips_2016_a_survey_of_tutorials_papers_and/,carmichael561,1495779979,,0,31
993,2017-5-26,2017,5,26,15,6dfbjz,Googles AlphaGo Continues Dominance With Second Win in China,https://www.reddit.com/r/MachineLearning/comments/6dfbjz/googles_alphago_continues_dominance_with_second/,pedromnasc,1495780790,,0,1
994,2017-5-26,2017,5,26,16,6dfjpr,Hanger type Shot blasting machine From China,https://www.reddit.com/r/MachineLearning/comments/6dfjpr/hanger_type_shot_blasting_machine_from_china/,Shot-blasting,1495784554,,1,1
995,2017-5-26,2017,5,26,16,6dfkl5,Machine Learning Blogs: Please suggest more blogs that can be followed. Cheers!,https://www.reddit.com/r/MachineLearning/comments/6dfkl5/machine_learning_blogs_please_suggest_more_blogs/,[deleted],1495784974,[deleted],0,1
996,2017-5-26,2017,5,26,18,6dftv8,"Interested in ML, need help with College Major",https://www.reddit.com/r/MachineLearning/comments/6dftv8/interested_in_ml_need_help_with_college_major/,[deleted],1495789611,[removed],0,1
997,2017-5-26,2017,5,26,18,6dfx5b,Which approach to use when inputs that are in a tri dimensional array?,https://www.reddit.com/r/MachineLearning/comments/6dfx5b/which_approach_to_use_when_inputs_that_are_in_a/,raffbr2,1495791112,[removed],0,1
998,2017-5-26,2017,5,26,19,6dg8ed,[R] Example-Based Synthesis of Stylized Facial Animations,https://www.reddit.com/r/MachineLearning/comments/6dg8ed/r_examplebased_synthesis_of_stylized_facial/,jezeq,1495796143,,29,547
999,2017-5-26,2017,5,26,19,6dg8l3,"Truck Mounted Forklift Industry, 2016 Market Research Report",https://www.reddit.com/r/MachineLearning/comments/6dg8l3/truck_mounted_forklift_industry_2016_market/,Reportsandmarkets,1495796236,,0,1
1000,2017-5-26,2017,5,26,20,6dg9dh,xkcd: Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6dg9dh/xkcd_machine_learning/,ergzay,1495796540,,1,2
1001,2017-5-26,2017,5,26,20,6dgb36,"Bulk Cargo Semi-Trailer Industry, 2016 Market Research Report",https://www.reddit.com/r/MachineLearning/comments/6dgb36/bulk_cargo_semitrailer_industry_2016_market/,Reportsandmarkets,1495797231,,0,1
1002,2017-5-26,2017,5,26,20,6dgflv,Helical Insight BI - Community Edition is now on GitHub,https://www.reddit.com/r/MachineLearning/comments/6dgflv/helical_insight_bi_community_edition_is_now_on/,abhi_kush,1495799060,[removed],0,1
1003,2017-5-26,2017,5,26,21,6dgq2v,AI Landscape after Build 2017,https://www.reddit.com/r/MachineLearning/comments/6dgq2v/ai_landscape_after_build_2017/,ivanfarkas,1495802803,,1,1
1004,2017-5-26,2017,5,26,22,6dh141,Classification with scikit-learn,https://www.reddit.com/r/MachineLearning/comments/6dh141/classification_with_scikitlearn/,ataspinar,1495806264,,0,1
1005,2017-5-26,2017,5,26,23,6dh4yw,[D] How do we assess quality of Generated Network Samples ?,https://www.reddit.com/r/MachineLearning/comments/6dh4yw/d_how_do_we_assess_quality_of_generated_network/,Lladz,1495807438,"I've been reading a couple of GAN papers and it seems like the gold standard for assessing the realism of an image is still having a human in the loop.

As far as i can tell some of the other more popular approaches are FCN scene segmentation comparisons.

Is anybody aware of any research in new approaches for measuring image realism? 

",6,4
1006,2017-5-26,2017,5,26,23,6dh5q8,Building a Linux machine for machine learning; Which CPU and GPU to buy?,https://www.reddit.com/r/MachineLearning/comments/6dh5q8/building_a_linux_machine_for_machine_learning/,entirix,1495807655,[removed],0,1
1007,2017-5-26,2017,5,26,23,6dh6qz,What are some potential solutions to the social problems that might arise when AI becomes good enough?,https://www.reddit.com/r/MachineLearning/comments/6dh6qz/what_are_some_potential_solutions_to_the_social/,savovs,1495807953,[removed],0,1
1008,2017-5-26,2017,5,26,23,6dh98z,[D] Anyone using of NVIDIA DIGITS for training deep learning models?,https://www.reddit.com/r/MachineLearning/comments/6dh98z/d_anyone_using_of_nvidia_digits_for_training_deep/,andyandy16,1495808632,"https://github.com/NVIDIA/DIGITS and https://developer.nvidia.com/digits

- How does it compare to other systems/frameworks (including code based frameworks like Keras)?
- Can you perform tasks like fine-tuning a pre-trained model?
- Does it scale to big datasets/models?

Thanks",11,4
1009,2017-5-27,2017,5,27,1,6di1qz,Free Webinar -- Intro to Machine Learning in Python for Quantitative Finance,https://www.reddit.com/r/MachineLearning/comments/6di1qz/free_webinar_intro_to_machine_learning_in_python/,bestquant,1495816562,,0,1
1010,2017-5-27,2017,5,27,1,6di56j,[D] Does anyone know where to find the corresponding actions for Atari Gym environments?,https://www.reddit.com/r/MachineLearning/comments/6di56j/d_does_anyone_know_where_to_find_the/,cryptobionic,1495817506,"I'm working on a project where I need the actual actions taken (e.g. 3 = left) for different environments. I've tried just sampling the space and rendering the environment which works okay, but can get confusing as many actions look the same, for example in MsPacman-v0 there are multiple actions which go left. I haven't found anything in the documentation or in other projects, does someone know where this information can be found? Thanks!",2,5
1011,2017-5-27,2017,5,27,2,6diblr,"Buying a new laptop, MacBook ok? or MacBook pro?",https://www.reddit.com/r/MachineLearning/comments/6diblr/buying_a_new_laptop_macbook_ok_or_macbook_pro/,faust111,1495819150,[removed],0,1
1012,2017-5-27,2017,5,27,3,6dimbw,Rule of thumb for time to run topic modeling algos like LDA?,https://www.reddit.com/r/MachineLearning/comments/6dimbw/rule_of_thumb_for_time_to_run_topic_modeling/,findandwrite,1495821918,"I have about 50-100k documents I want to produce topic models for.

How long should I budget for this?

I'll likely be using Gensim/python.

Then depending on cost/time trade offs, attempt to employ their distributed computing architecture across some number of ec2 instances.  


I'd like to start getting ball park ideas for what kind of time figures I should expect, and what it would cost to run the documents on a LARGE cluster of ec2 nodes. ",2,2
1013,2017-5-27,2017,5,27,3,6diwuc,How AI and Machine Learning is Improving the Summer Traveling Experience,https://www.reddit.com/r/MachineLearning/comments/6diwuc/how_ai_and_machine_learning_is_improving_the/,kyle4beantown,1495824765,,0,1
1014,2017-5-27,2017,5,27,4,6diztg,"""Doubly Stochastic Variational Inference for Deep Gaussian Processes"", Salimbeni &amp; Deisenroth 2017",https://www.reddit.com/r/MachineLearning/comments/6diztg/doubly_stochastic_variational_inference_for_deep/,gwern,1495825602,,0,1
1015,2017-5-27,2017,5,27,5,6djnay,[N] Apple Is Working on a Dedicated Chip to Power AI on Devices,https://www.reddit.com/r/MachineLearning/comments/6djnay/n_apple_is_working_on_a_dedicated_chip_to_power/,cryptoz,1495832381,,14,33
1016,2017-5-27,2017,5,27,6,6djnpp,How to find events before they happen?,https://www.reddit.com/r/MachineLearning/comments/6djnpp/how_to_find_events_before_they_happen/,[deleted],1495832492,[removed],0,1
1017,2017-5-27,2017,5,27,6,6djygs,Some questions about batch normalization in CNN,https://www.reddit.com/r/MachineLearning/comments/6djygs/some_questions_about_batch_normalization_in_cnn/,[deleted],1495835691,[removed],0,1
1018,2017-5-27,2017,5,27,7,6dk0f8,[R] Some questions about batch normalization in CNN,https://www.reddit.com/r/MachineLearning/comments/6dk0f8/r_some_questions_about_batch_normalization_in_cnn/,[deleted],1495836300,[deleted],2,0
1019,2017-5-27,2017,5,27,7,6dk4ie,Can machine learning and AI help Facebook better moderate troubling content?,https://www.reddit.com/r/MachineLearning/comments/6dk4ie/can_machine_learning_and_ai_help_facebook_better/,Aware360,1495837566,,0,1
1020,2017-5-27,2017,5,27,10,6dkx9m,Adjust learning rate in CNN,https://www.reddit.com/r/MachineLearning/comments/6dkx9m/adjust_learning_rate_in_cnn/,K_Augus,1495847206,[removed],0,1
1021,2017-5-27,2017,5,27,10,6dl5x5,Has anyone attempted guitar effect style matching? Like the Prisma of guitar sounds?,https://www.reddit.com/r/MachineLearning/comments/6dl5x5/has_anyone_attempted_guitar_effect_style_matching/,tim_schaaf,1495850231,[removed],0,1
1022,2017-5-27,2017,5,27,12,6dlhz0,Which Activation Function Should I Use?,https://www.reddit.com/r/MachineLearning/comments/6dlhz0/which_activation_function_should_i_use/,funmaster11,1495854668,,0,1
1023,2017-5-27,2017,5,27,13,6dlpyu,"""Our measurements are showing up to 70x higher performance for training and up to 85x higher performance for inference on Intel Xeon Phi""",https://www.reddit.com/r/MachineLearning/comments/6dlpyu/our_measurements_are_showing_up_to_70x_higher/,[deleted],1495857900,[deleted],0,1
1024,2017-5-27,2017,5,27,13,6dlq31,"[N] ""Our measurements are showing up to 70x higher performance for training and up to 85x higher performance for inference on Intel Xeon Phi""",https://www.reddit.com/r/MachineLearning/comments/6dlq31/n_our_measurements_are_showing_up_to_70x_higher/,downtownslim,1495857942,,37,32
1025,2017-5-27,2017,5,27,15,6dma3f,Binary cross entropy or categorical cross entropy for 2 class problem,https://www.reddit.com/r/MachineLearning/comments/6dma3f/binary_cross_entropy_or_categorical_cross_entropy/,lvbu,1495866678,[removed],0,1
1026,2017-5-27,2017,5,27,17,6dmmly,[N] AlphaGo's Next Move | DeepMind,https://www.reddit.com/r/MachineLearning/comments/6dmmly/n_alphagos_next_move_deepmind/,Spotlight0xff,1495873370,,9,130
1027,2017-5-27,2017,5,27,18,6dmtwo,Implementing skip connections with TF-slim,https://www.reddit.com/r/MachineLearning/comments/6dmtwo/implementing_skip_connections_with_tfslim/,future_duded,1495877383,[removed],0,1
1028,2017-5-27,2017,5,27,19,6dmzdy,[D] On using Huber loss in (Deep) Q-learning,https://www.reddit.com/r/MachineLearning/comments/6dmzdy/d_on_using_huber_loss_in_deep_qlearning/,jaromiru,1495880304,"**Edit: Based on the discussion, Huber loss with appropriate delta is correct to use. The article and discussion holds true for pseudo-huber loss though.**

I argue that using Huber loss in Q-learning is fundamentally incorrect. I present my arguments on my blog here:
https://jaromiru.com/2017/05/27/on-using-huber-loss-in-deep-q-learning/

I summarize the posed questions here:

* Does this problem really matter? 
* Does it manifest in the Atari domain? 
* Has it been discussed previously?
- What are the real advantages to using Huber loss?
- Is there any research comparing different cost functions in (deep) Q-learning?

I welcome any constructive discussion below.",7,10
1029,2017-5-27,2017,5,27,20,6dn6xz,Difficulty in training a discriminator (GAN),https://www.reddit.com/r/MachineLearning/comments/6dn6xz/difficulty_in_training_a_discriminator_gan/,checkeredHambagu,1495884124,[removed],1,1
1030,2017-5-27,2017,5,27,21,6dngtb,[D] Tensorflow) Why variables are not assigned after restoration?,https://www.reddit.com/r/MachineLearning/comments/6dngtb/d_tensorflow_why_variables_are_not_assigned_after/,Mark-Lee,1495888458,[removed],14,6
1031,2017-5-27,2017,5,27,21,6dnhp1,[D] Best approach for using multiple time-series to predict a single time-series,https://www.reddit.com/r/MachineLearning/comments/6dnhp1/d_best_approach_for_using_multiple_timeseries_to/,EnemyBagJones,1495888845,"I've found a number of tutorials working with ML to attempt prediction of a time series, but practically all of the ones I've found take in a single series and try to predict it. 

I'm looking for an approach that will allow me to effectively have a primary signal I want to predict (e.g. price of commodity or a stock) and then allow me to experiment with adding in other secondary 'helper' time-series signals that could help with the prediction of that primary signal, e.g. daily temperature, futures values, previous day high/low, or even something as goofy as '# of positive tweets' and so on.

Is an LSTM RNN the 'state of the art', or should I be looking at something else?
",6,5
1032,2017-5-27,2017,5,27,22,6dnnh7,I want to take a job in Google Deepmind,https://www.reddit.com/r/MachineLearning/comments/6dnnh7/i_want_to_take_a_job_in_google_deepmind/,complectere,1495891219,[removed],0,1
1033,2017-5-27,2017,5,27,22,6dnr1p,"[P] Common Representation Learning using Deep CorrNet - reconstruction of multi-view data (text, images, audio, etc).",https://www.reddit.com/r/MachineLearning/comments/6dnr1p/p_common_representation_learning_using_deep/,bhatt_gaurav,1495892559,,15,16
1034,2017-5-28,2017,5,28,0,6do648,[D] (ACM 2012) When do you think computers will crack Go?,https://www.reddit.com/r/MachineLearning/comments/6do648/d_acm_2012_when_do_you_think_computers_will_crack/,Cock-tail,1495897794,,35,42
1035,2017-5-28,2017,5,28,2,6dp15s,An AI invented a bunch of new paint colors that are hilariously wrong,https://www.reddit.com/r/MachineLearning/comments/6dp15s/an_ai_invented_a_bunch_of_new_paint_colors_that/,georgeo,1495907790,,0,1
1036,2017-5-28,2017,5,28,4,6dpir5,"[R] HIM Special Program ""Applied Computational Algebraic Topology"" (see #3,4 for most relevant content)",https://www.reddit.com/r/MachineLearning/comments/6dpir5/r_him_special_program_applied_computational/,[deleted],1495913329,[deleted],0,1
1037,2017-5-28,2017,5,28,5,6dpt7r,"[R] Using Empirical Bayes to approximate posteriors for large ""black box"" estimators",https://www.reddit.com/r/MachineLearning/comments/6dpt7r/r_using_empirical_bayes_to_approximate_posteriors/,carmichael561,1495916722,,0,7
1038,2017-5-28,2017,5,28,5,6dptav,[R] The reusable holdout: Preserving validity in adaptive data analysis,https://www.reddit.com/r/MachineLearning/comments/6dptav/r_the_reusable_holdout_preserving_validity_in/,carmichael561,1495916747,,9,28
1039,2017-5-28,2017,5,28,6,6dpztb,"[D] cs231n lecture from Stanford, comparing between TensorFlow  and PyTorch ",https://www.reddit.com/r/MachineLearning/comments/6dpztb/d_cs231n_lecture_from_stanford_comparing_between/,evc123,1495918836,,78,231
1040,2017-5-28,2017,5,28,8,6dqmrm,Prediction intervals for LSTM time series model,https://www.reddit.com/r/MachineLearning/comments/6dqmrm/prediction_intervals_for_lstm_time_series_model/,lbcommer,1495926554,[removed],0,1
1041,2017-5-28,2017,5,28,8,6dqrmf,What recommender model should I use?,https://www.reddit.com/r/MachineLearning/comments/6dqrmf/what_recommender_model_should_i_use/,[deleted],1495928279,[removed],0,1
1042,2017-5-28,2017,5,28,8,6dqtfj,What recommender system should I use?,https://www.reddit.com/r/MachineLearning/comments/6dqtfj/what_recommender_system_should_i_use/,[deleted],1495928916,[removed],0,1
1043,2017-5-28,2017,5,28,14,6ds4sk,How Data Science apply to Robotics?,https://www.reddit.com/r/MachineLearning/comments/6ds4sk/how_data_science_apply_to_robotics/,ammararaja,1495947619,,1,1
1044,2017-5-28,2017,5,28,17,6dsr5t,Bracci per escavatori,https://www.reddit.com/r/MachineLearning/comments/6dsr5t/bracci_per_escavatori/,AgnolinoTango,1495959210,,0,1
1045,2017-5-28,2017,5,28,17,6dst29,Bras pour pelle hydraulique,https://www.reddit.com/r/MachineLearning/comments/6dst29/bras_pour_pelle_hydraulique/,AgnolinoTango,1495960325,,0,1
1046,2017-5-28,2017,5,28,17,6dsv3r,"Calculate a normalized ""data complexity""",https://www.reddit.com/r/MachineLearning/comments/6dsv3r/calculate_a_normalized_data_complexity/,pvkooten,1495961576,[removed],0,1
1047,2017-5-28,2017,5,28,19,6dt51z,[D] Why use cosine similarity for content-based addressing?,https://www.reddit.com/r/MachineLearning/comments/6dt51z/d_why_use_cosine_similarity_for_contentbased/,nasimrahaman,1495967154,"As it turns out, [Neural Turing Machines](https://arxiv.org/abs/1410.5401) and [Differentiable Neural Computers](https://www.nature.com/articles/nature20101.epdf?author_access_token=ImTXBI8aWbYxYQ51Plys8NRgN0jAjWel9jnR3ZoTv0MggmpDmwljGswxVdeocYSurJ3hxupzWuRNeGvvXnoO8o4jTJcnAyhGuZzXJ1GEaD-Z7E6X_a9R-xqJ9TfJWBqz) both use cosine similarity for content based addressing. However, the cosine similarity does not respond to the vector magnitudes, as in:

    cos_similarity([1, 0], [1, 0]) = cos_similarity([1, 0], [0.0001, 0])

Given that the query key is generated by the controller (see e.g. equation 5 of the NTM paper linked above), I could imagine the gradients running wild for small key vectors*. What I'm unsure about is whether this is necessary / intended behaviour^+ especially given that we're ignoring ""what the controller is trying to say"" with the query key magnitude? 

One could perhaps (?) trivially modify the cosine similarity by multiplying an additional factor like:

    cos_similarity(u, v) * minimum(mag(u)/mag(v), mag(v)/mag(u))

which btw reminds of the coefficient in a simple linear regression model - just symmetricised.

^* we could clamp, but that's still besides the point, imho. 

^+ the insensitivity to magnitude is arguably useful in NLP applications where we're interested in (say) *relative* frequencies, etc. ",12,18
1048,2017-5-28,2017,5,28,20,6dtccs,[P] PyTorch Tutorial Updated (14 examples + TensorBoard),https://www.reddit.com/r/MachineLearning/comments/6dtccs/p_pytorch_tutorial_updated_14_examples_tensorboard/,yunjey,1495971125,,12,209
1049,2017-5-28,2017,5,28,22,6dtpve,dataanalysisclassroom  making data analysis easy,https://www.reddit.com/r/MachineLearning/comments/6dtpve/dataanalysisclassroom_making_data_analysis_easy/,[deleted],1495977162,[deleted],0,1
1050,2017-5-28,2017,5,28,23,6dtxnh,What is the best GPU I can buy for around $1000?,https://www.reddit.com/r/MachineLearning/comments/6dtxnh/what_is_the_best_gpu_i_can_buy_for_around_1000/,raffbr2,1495980215,[removed],0,1
1051,2017-5-29,2017,5,29,0,6duewt,"What is that mean?, so we can not see the result tomorrow either accept or reject?",https://www.reddit.com/r/MachineLearning/comments/6duewt/what_is_that_mean_so_we_can_not_see_the_result/,[deleted],1495986134,[deleted],0,1
1052,2017-5-29,2017,5,29,0,6duf5q,Show ML: A simple text punctuator with a practical application.,https://www.reddit.com/r/MachineLearning/comments/6duf5q/show_ml_a_simple_text_punctuator_with_a_practical/,vackosar,1495986210,,0,1
1053,2017-5-29,2017,5,29,0,6dugv6,It seems we can not see the ICCV results tomorrow. Only reviews will be visible.,https://www.reddit.com/r/MachineLearning/comments/6dugv6/it_seems_we_can_not_see_the_iccv_results_tomorrow/,[deleted],1495986737,[deleted],0,1
1054,2017-5-29,2017,5,29,1,6durel,Unsupervised Machine Learning for Fun &amp; Profit with Basket Clusters,https://www.reddit.com/r/MachineLearning/comments/6durel/unsupervised_machine_learning_for_fun_profit_with/,[deleted],1495990018,[deleted],0,1
1055,2017-5-29,2017,5,29,1,6dusxr,[R] Unsupervised Machine Learning for Fun &amp; Profit with Basket Clusters,https://www.reddit.com/r/MachineLearning/comments/6dusxr/r_unsupervised_machine_learning_for_fun_profit/,liconvalleysi,1495990503,,5,6
1056,2017-5-29,2017,5,29,2,6duxal,The History and Future of Artificial Intelligence (A.I.),https://www.reddit.com/r/MachineLearning/comments/6duxal/the_history_and_future_of_artificial_intelligence/,scidem,1495991798,,0,1
1057,2017-5-29,2017,5,29,3,6dvgql,"[P] Minimizing the Negative Log-Likelihood, in English",https://www.reddit.com/r/MachineLearning/comments/6dvgql/p_minimizing_the_negative_loglikelihood_in_english/,pmigdal,1495997712,,1,16
1058,2017-5-29,2017,5,29,4,6dvkkx,GTX 1060 vs GTX 1070 for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6dvkkx/gtx_1060_vs_gtx_1070_for_machine_learning/,[deleted],1495998854,[removed],0,1
1059,2017-5-29,2017,5,29,4,6dvpio,Hidden Technical Debt of Machine Learning - Play Now Pay Later,https://www.reddit.com/r/MachineLearning/comments/6dvpio/hidden_technical_debt_of_machine_learning_play/,codefying,1496000408,,0,1
1060,2017-5-29,2017,5,29,4,6dvqk1,[D] GTX 1060 vs GTX 1070 for Machine Learning Workstation,https://www.reddit.com/r/MachineLearning/comments/6dvqk1/d_gtx_1060_vs_gtx_1070_for_machine_learning/,lolcatbot010101,1496000730,[removed],6,2
1061,2017-5-29,2017,5,29,5,6dvtb2,[D] Machine Learning - WAYR (What Are You Reading) - Week 26,https://www.reddit.com/r/MachineLearning/comments/6dvtb2/d_machine_learning_wayr_what_are_you_reading_week/,[deleted],1496001604,[deleted],1,10
1062,2017-5-29,2017,5,29,5,6dvxax,What machine learning method can I use to find a set of points in an image?,https://www.reddit.com/r/MachineLearning/comments/6dvxax/what_machine_learning_method_can_i_use_to_find_a/,eriknyu,1496002821,[removed],0,1
1063,2017-5-29,2017,5,29,7,6dwi50,"OpenAIs new approach for one-shot imitation learning, a peek into the future of AI",https://www.reddit.com/r/MachineLearning/comments/6dwi50/openais_new_approach_for_oneshot_imitation/,jtmoustache,1496009360,,0,1
1064,2017-5-29,2017,5,29,8,6dwt00,[D] Interpreting #AlphaGo,https://www.reddit.com/r/MachineLearning/comments/6dwt00/d_interpreting_alphago/,yield22,1496013026,"DeepMind AlphaGo (Master version) has beaten top Go players in the past few months, clearly it is the #1 player on the earth. But how good can we interpret its moves? Or can we summarize its knowledge in similar ways that human players developed the theory for Go?

It is also mysterious to me how exactly AlphaGo dose ""planning"". Its core, i.e. MCTS + Action/Value Networks, seems memory-less, while ""planing"" and ""strategy"" require a sequence of consistent executions. How does it achieve this? Or it suggests Go game can be solved without long-term planning?",24,2
1065,2017-5-29,2017,5,29,8,6dwusy,[D] Hybrid Generative-Discriminative Deep Models,https://www.reddit.com/r/MachineLearning/comments/6dwusy/d_hybrid_generativediscriminative_deep_models/,bjornsing,1496013660,,8,21
1066,2017-5-29,2017,5,29,10,6dxe2l,[D] Modern Machine Learning Algorithms: Strengths and Weaknesses,https://www.reddit.com/r/MachineLearning/comments/6dxe2l/d_modern_machine_learning_algorithms_strengths/,_alphamaximus_,1496020510,,0,19
1067,2017-5-29,2017,5,29,11,6dxljh,"[P] Keeping track of hundreds of models and hyperparameters can get insane pretty quickly, so I built a notebook-like tool for quick, scalable, and parallelized hyperparameter tuning and stacked ensembling",https://www.reddit.com/r/MachineLearning/comments/6dxljh/p_keeping_track_of_hundreds_of_models_and/,Reiinakano,1496023261,,14,202
1068,2017-5-29,2017,5,29,11,6dxp0b,Multimodal Machine Learning: A Survey and Taxonomy,https://www.reddit.com/r/MachineLearning/comments/6dxp0b/multimodal_machine_learning_a_survey_and_taxonomy/,chahuja,1496024524,,0,1
1069,2017-5-29,2017,5,29,12,6dxzt5,Fourier Machine,https://www.reddit.com/r/MachineLearning/comments/6dxzt5/fourier_machine/,[deleted],1496028609,[deleted],0,1
1070,2017-5-29,2017,5,29,15,6dynqw,[D] How to Solve the New $1 Million Kaggle Problem - Home Value Estimates,https://www.reddit.com/r/MachineLearning/comments/6dynqw/d_how_to_solve_the_new_1_million_kaggle_problem/,_alphamaximus_,1496038327,,2,0
1071,2017-5-29,2017,5,29,15,6dyp9o,My friend and I have some experiences with NLP and deep learning respectively. We are looking for side project ideas applying machine learning to any real world problem. What would you want us to work on?,https://www.reddit.com/r/MachineLearning/comments/6dyp9o/my_friend_and_i_have_some_experiences_with_nlp/,baobaodumpling,1496039006,[removed],0,1
1072,2017-5-29,2017,5,29,16,6dyuy6,shallow updates for deep reinforcement learning,https://www.reddit.com/r/MachineLearning/comments/6dyuy6/shallow_updates_for_deep_reinforcement_learning/,touring_stuff,1496041632,[removed],0,1
1073,2017-5-29,2017,5,29,16,6dyxib,"The $1700 great DL Box: Assembly, setup and benchmarks",https://www.reddit.com/r/MachineLearning/comments/6dyxib/the_1700_great_dl_box_assembly_setup_and/,[deleted],1496042794,[deleted],0,1
1074,2017-5-29,2017,5,29,16,6dyxqa,"[P] Great DL box for $1700: Assembly, setup and benchmarks",https://www.reddit.com/r/MachineLearning/comments/6dyxqa/p_great_dl_box_for_1700_assembly_setup_and/,slavivanov,1496042912,,8,13
1075,2017-5-29,2017,5,29,18,6dz9ba,'A white mask worked better': why algorithms are not colour blind,https://www.reddit.com/r/MachineLearning/comments/6dz9ba/a_white_mask_worked_better_why_algorithms_are_not/,budgie,1496048801,,0,1
1076,2017-5-29,2017,5,29,18,6dzcya,Kaggle Ensembling Guide,https://www.reddit.com/r/MachineLearning/comments/6dzcya/kaggle_ensembling_guide/,frankster,1496050616,,0,1
1077,2017-5-29,2017,5,29,19,6dzkpa,[P] Unblackboxing the deep neural network black box - a free webinar (May 30th),https://www.reddit.com/r/MachineLearning/comments/6dzkpa/p_unblackboxing_the_deep_neural_network_black_box/,pmigdal,1496054271,,4,4
1078,2017-5-29,2017,5,29,20,6dzrwe,[D] Introduction to Bayesian ML,https://www.reddit.com/r/MachineLearning/comments/6dzrwe/d_introduction_to_bayesian_ml/,Kiuhnm,1496057555,,15,202
1079,2017-5-29,2017,5,29,20,6dztmd,Motor Lubrication And Its Benefits,https://www.reddit.com/r/MachineLearning/comments/6dztmd/motor_lubrication_and_its_benefits/,jackerfrinandis,1496058347,,0,1
1080,2017-5-29,2017,5,29,22,6e0b87,"How to see the algorithm your machine learning model has applied to predictions? [Sciki-Learn, LinearRegression]",https://www.reddit.com/r/MachineLearning/comments/6e0b87/how_to_see_the_algorithm_your_machine_learning/,the1ine,1496065034,[removed],0,1
1081,2017-5-29,2017,5,29,23,6e0ezy,What Is Machine Learning All About And What Are The Various Machine Learning Algorithms - A Complete Guide,https://www.reddit.com/r/MachineLearning/comments/6e0ezy/what_is_machine_learning_all_about_and_what_are/,pooja_edureka,1496066401,,0,1
1082,2017-5-29,2017,5,29,23,6e0ifn,Neural Message Passing on PyTorch,https://www.reddit.com/r/MachineLearning/comments/6e0ifn/neural_message_passing_on_pytorch/,[deleted],1496067561,[deleted],0,1
1083,2017-5-29,2017,5,29,23,6e0keg,Neural Message Passing on PyTorch,https://www.reddit.com/r/MachineLearning/comments/6e0keg/neural_message_passing_on_pytorch/,[deleted],1496068246,[removed],0,1
1084,2017-5-29,2017,5,29,23,6e0oz8,[P] Neural Message Passing on PyTorch,https://www.reddit.com/r/MachineLearning/comments/6e0oz8/p_neural_message_passing_on_pytorch/,AnjanDutta,1496069772,,1,26
1085,2017-5-30,2017,5,30,0,6e0usm,When to use pre-trained CNNs?,https://www.reddit.com/r/MachineLearning/comments/6e0usm/when_to_use_pretrained_cnns/,AlCapown3d,1496071525,[removed],0,1
1086,2017-5-30,2017,5,30,0,6e0yd6,[D] Introduction To Probabilistic Modeling and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/6e0yd6/d_introduction_to_probabilistic_modeling_and/,_alphamaximus_,1496072595,,0,1
1087,2017-5-30,2017,5,30,1,6e1cx0,[D] Circular 1-Dimensional Convolutions,https://www.reddit.com/r/MachineLearning/comments/6e1cx0/d_circular_1dimensional_convolutions/,Delthc,1496076603,"Hello,

Imagine a 1-dimensional tensor T that is n elements long, and where the spatial information of the components matter (so, T[0] and T[1] are near each other in the 'real world', and this information should be preserved).

So naturally I would like to use a 1D-ConvNet to process the dataset, however T[0] and T[n-1] are not further away from each other as T[0] and T[1] is..
That means, the Tensor is a representation of sensors that are arranged in a circle, if that makes any sense.

Ideally I would like to use Keras, and as far as I know there is no ""circular convolutions"" available. So, how would you guys tackle it?

My naive approach would be to append the first X elements to the end of the tensor, and the last X elements to the beginning of the tensor, where X is the kernel_size of the first layer.
Any comments on that?

Thanks in advance!",14,2
1088,2017-5-30,2017,5,30,2,6e1gb9,Acceleration: 16 hour days,https://www.reddit.com/r/MachineLearning/comments/6e1gb9/acceleration_16_hour_days/,MusicIsLife1995,1496077540,[removed],0,1
1089,2017-5-30,2017,5,30,2,6e1njx,Inexplicable spikes and drops in SVM performance,https://www.reddit.com/r/MachineLearning/comments/6e1njx/inexplicable_spikes_and_drops_in_svm_performance/,[deleted],1496079522,[removed],0,1
1090,2017-5-30,2017,5,30,2,6e1ppe,[D] Inexplicable spikes and drops in SVM performance,https://www.reddit.com/r/MachineLearning/comments/6e1ppe/d_inexplicable_spikes_and_drops_in_svm_performance/,[deleted],1496080127,[deleted],1,4
1091,2017-5-30,2017,5,30,2,6e1qpv,Transfer Learning across PyTorch's model zoo,https://www.reddit.com/r/MachineLearning/comments/6e1qpv/transfer_learning_across_pytorchs_model_zoo/,dafcok,1496080416,,0,1
1092,2017-5-30,2017,5,30,3,6e1vmc,A collection of 15+ tutorials and projects for Udacity's deep learning program,https://www.reddit.com/r/MachineLearning/comments/6e1vmc/a_collection_of_15_tutorials_and_projects_for/,Noctambulist,1496081783,,0,1
1093,2017-5-30,2017,5,30,3,6e1yt1,[R] Stabilizing Training of Generative Adversarial Networks through Regularization,https://www.reddit.com/r/MachineLearning/comments/6e1yt1/r_stabilizing_training_of_generative_adversarial/,_jamorton,1496082670,,5,16
1094,2017-5-30,2017,5,30,4,6e2eos,How to out it all together ?,https://www.reddit.com/r/MachineLearning/comments/6e2eos/how_to_out_it_all_together/,MartyDeParty,1496087048,[removed],0,1
1095,2017-5-30,2017,5,30,5,6e2ih2,Can you help me retrain inception for multi-labelling?,https://www.reddit.com/r/MachineLearning/comments/6e2ih2/can_you_help_me_retrain_inception_for/,lagagne72,1496088116,[removed],0,1
1096,2017-5-30,2017,5,30,5,6e2ntb,I need a dataset of pictures of meals with the amount of calories of each meal.,https://www.reddit.com/r/MachineLearning/comments/6e2ntb/i_need_a_dataset_of_pictures_of_meals_with_the/,ronsap123,1496089672,[removed],0,1
1097,2017-5-30,2017,5,30,5,6e2q0i,[P] Understanding Tensorflow using Go,https://www.reddit.com/r/MachineLearning/comments/6e2q0i/p_understanding_tensorflow_using_go/,pgaleone,1496090285,,0,4
1098,2017-5-30,2017,5,30,5,6e2rrt,[D] Increasing GPU Memory for Convolutions By Placing Forward Activations in CPU Memory -- Via tf.scan(),https://www.reddit.com/r/MachineLearning/comments/6e2rrt/d_increasing_gpu_memory_for_convolutions_by/,nickshahml,1496090773,"Hey Guys,

For RNN's, tensorflow introduced *tf.nn.dynamic_rnn* which basically allows you to use the swap_memory feature. In the forward pass, all the tensors are moved from GPU memory and placed in CPU memory. Upon calculating the backward pass, these tensors are retrieved. Overall, this allows you to train much larger RNN's for *many* more timesteps. 

I was thinking about this more, and was wondering if this same approach could be applied to convolutions. Lets consider ResNet-101. During the forward pass, you could store each of the 100 forward tensors in cpu memory and then recall them in the backward pass. 

As far as I'm aware, this could be done using tf.scan or at least with one of the [higher order functions](https://www.tensorflow.org/versions/r0.11/api_docs/python/functional_ops/higher_order_operators). You would be sure to set swap_memory=True.

Maybe I'm missing something but I feel that this could significantly increase the available memory for training convolutional networks at very minimal speed cost. I can't be the first one to think of this, meaning that there must be something I'm missing.",6,5
1099,2017-5-30,2017,5,30,7,6e3dp1,[D] PC build for ML,https://www.reddit.com/r/MachineLearning/comments/6e3dp1/d_pc_build_for_ml/,OfficialBananas,1496097232,"I'm kind of like a beginner to ML and DL and I want a pc for ML/DL/AI research. I probably wouldn't be doing too much training on this pc when I'm first getting started. This is my first time taking a shot at PC building and was wondering if you guys have any advice.

[PCPartPicker part list](https://ca.pcpartpicker.com/list/mcLkKZ) / [Price breakdown by merchant](https://ca.pcpartpicker.com/list/mcLkKZ/by_merchant/)

Type|Item|Price
:----|:----|:----
**CPU** | [AMD - Ryzen 7 1700 3.0GHz 8-Core Processor](https://ca.pcpartpicker.com/product/3kPzK8/amd-ryzen-7-1700-30ghz-8-core-processor-yd1700bbaebox) | $407.98 @ DirectCanada 
**CPU Cooler** | [Corsair - H60 54.0 CFM Liquid CPU Cooler](https://ca.pcpartpicker.com/product/Vwdqqs/corsair-cpu-cooler-h60cw9060007ww) | $79.99 @ Newegg Canada 
**Motherboard** | [MSI - B350M GAMING PRO Micro ATX AM4 Motherboard](https://ca.pcpartpicker.com/product/TsfmP6/msi-b350m-gaming-pro-micro-atx-am4-motherboard-b350m-gaming-pro) | $107.99 @ Amazon Canada 
**Memory** | [Corsair - Vengeance LPX 16GB (2 x 8GB) DDR4-3000 Memory](https://ca.pcpartpicker.com/product/MYH48d/corsair-memory-cmk16gx4m2b3000c15) | $164.99 @ Amazon Canada 
**Storage** | [Samsung - 850 EVO-Series 250GB 2.5"" Solid State Drive](https://ca.pcpartpicker.com/product/3kL7YJ/samsung-internal-hard-drive-mz75e250bam) | $129.99 @ Memory Express 
**Video Card** | [EVGA - GeForce GTX 1080 8GB Superclocked Gaming ACX 3.0 Video Card](https://ca.pcpartpicker.com/product/63yxFT/evga-video-card-08gp46183) | $724.99 @ Newegg Canada 
**Case** | [Corsair - 200R ATX Mid Tower Case](https://ca.pcpartpicker.com/product/cTQypg/corsair-case-200r) | $74.50 @ Vuugo 
**Power Supply** | [EVGA - SuperNOVA NEX 650W 80+ Gold Certified Fully-Modular ATX Power Supply](https://ca.pcpartpicker.com/product/g63RsY/evga-power-supply-120g10650xr) | $104.99 @ Newegg Canada 
**Sound Card** | [Asus - Xonar DGX 24-bit 96 KHz Sound Card](https://ca.pcpartpicker.com/product/zRckcf/asus-sound-card-xonardgx) | $44.75 @ Vuugo 
**Wireless Network Adapter** | [TP-Link - TL-WDN4800 PCI-Express x1 802.11a/b/g/n Wi-Fi Adapter](https://ca.pcpartpicker.com/product/G4H323/tp-link-wireless-network-card-tlwdn4800) | $48.98 @ DirectCanada 
 | *Prices include shipping, taxes, rebates, and discounts* |
 | **Total** | **$1889.15**
 | Generated by [PCPartPicker](http://pcpartpicker.com) 2017-05-29 18:30 EDT-0400 |

Edit: After reading the comments, I have changed my pc build according to what you guys had suggested:
[PCPartPicker part list](https://ca.pcpartpicker.com/list/Y9gtYr) / [Price breakdown by merchant](https://ca.pcpartpicker.com/list/Y9gtYr/by_merchant/)

[PCPartPicker part list](https://ca.pcpartpicker.com/list/r8cHtJ) / [Price breakdown by merchant](https://ca.pcpartpicker.com/list/r8cHtJ/by_merchant/)

Type|Item|Price
:----|:----|:----
**CPU** | [AMD - Ryzen 5 1600 3.2GHz 6-Core Processor](https://ca.pcpartpicker.com/product/mV98TW/amd-ryzen-5-1600-32ghz-6-core-processor-yd1600bbaebox) | $280.25 @ shopRBC 
**Motherboard** | [MSI - X370 SLI PLUS ATX AM4 Motherboard](https://ca.pcpartpicker.com/product/vwvZxr/msi-x370-sli-plus-atx-am4-motherboard-x370-sli-plus) | $187.98 @ DirectCanada 
**Memory** | [Corsair - Vengeance LPX 16GB (2 x 8GB) DDR4-2133 Memory](https://ca.pcpartpicker.com/product/PL2rxr/corsair-memory-cmk16gx4m2a2133c13) | $159.98 @ DirectCanada 
**Storage** | [Samsung - 850 EVO-Series 250GB 2.5"" Solid State Drive](https://ca.pcpartpicker.com/product/3kL7YJ/samsung-internal-hard-drive-mz75e250bam) | $129.98 @ DirectCanada 
**Storage** | [Western Digital - Caviar Blue 1TB 3.5"" 7200RPM Internal Hard Drive](https://ca.pcpartpicker.com/product/MwW9TW/western-digital-internal-hard-drive-wd10ezex) | $64.50 @ Vuugo 
**Video Card** | [EVGA - GeForce GTX 1080 Ti 11GB Founder Edition Video Card](https://ca.pcpartpicker.com/product/tgyxFT/evga-geforce-gtx-1080-ti-11gb-founder-edition-video-card-11g-p4-6390-kr) | $979.98 @ DirectCanada 
**Case** | [NZXT - S340 (Black/Red) ATX Mid Tower Case](https://ca.pcpartpicker.com/product/tD38TW/nzxt-case-cas340wbr1) | $94.50 @ Vuugo 
**Power Supply** | [EVGA - SuperNOVA G2 750W 80+ Gold Certified Fully-Modular ATX Power Supply](https://ca.pcpartpicker.com/product/MfJwrH/evga-power-supply-220g20750xr) | $148.00 @ shopRBC 
 | *Prices include shipping, taxes, rebates, and discounts* |
 | **Total** | **$2045.17**
 | Generated by [PCPartPicker](http://pcpartpicker.com) 2017-05-31 16:17 EDT-0400 |",32,9
1100,2017-5-30,2017,5,30,8,6e3qpa,Feasibility Question Neural Network for Chess Move Ordering,https://www.reddit.com/r/MachineLearning/comments/6e3qpa/feasibility_question_neural_network_for_chess/,mentallyabsnet,1496101362,[removed],0,1
1101,2017-5-30,2017,5,30,9,6e436x,getting into neural networks?,https://www.reddit.com/r/MachineLearning/comments/6e436x/getting_into_neural_networks/,IncrementTimesTwo,1496105290,[removed],0,1
1102,2017-5-30,2017,5,30,12,6e4s9w,[D] [1705.09558] Bayesian GAN,https://www.reddit.com/r/MachineLearning/comments/6e4s9w/d_170509558_bayesian_gan/,_alphamaximus_,1496113599,,11,42
1103,2017-5-30,2017,5,30,12,6e4wxs,% of how much a data point belongs to each class? (Multi-class or Multi-label Classification?),https://www.reddit.com/r/MachineLearning/comments/6e4wxs/of_how_much_a_data_point_belongs_to_each_class/,vibhash_chandra,1496115215,[removed],0,1
1104,2017-5-30,2017,5,30,12,6e50qj,Good Tutorial / Exercise on Tensor Math using Tensorflow APIs?,https://www.reddit.com/r/MachineLearning/comments/6e50qj/good_tutorial_exercise_on_tensor_math_using/,melvinma,1496116628,[removed],0,1
1105,2017-5-30,2017,5,30,13,6e55dv,[D] Is there a better way to visualize tensorflow models?,https://www.reddit.com/r/MachineLearning/comments/6e55dv/d_is_there_a_better_way_to_visualize_tensorflow/,architrathore,1496118295,"I found this [figure](https://3.bp.blogspot.com/-8Lsg0rnxl7k/WRtttN18MKI/AAAAAAAAB0o/KpHbFnYBmTYQ3dBjVLimPUkKphU_qLBfgCLcB/s1600/image2.png) in google's [blog](https://research.googleblog.com/2017/05/using-machine-learning-to-explore.html) on learning to explore network architectures and was wondering if there is any way to generate such network images from tensorflow. I know of tensorboard, but I want aesthetics that match this figure. I found [this](http://ethereon.github.io/netscope) but it presently supports Caffe only.
Asked this earlier on r/learnmachinelearning but did not find any answers.",15,11
1106,2017-5-30,2017,5,30,14,6e5js5,[P] A TensorFlow Implementation of Bytenet,https://www.reddit.com/r/MachineLearning/comments/6e5js5/p_a_tensorflow_implementation_of_bytenet/,longinglove,1496123983,,5,29
1107,2017-5-30,2017,5,30,15,6e5ogq,Essential Cheat Sheets for Machine Learning and Deep Learning Engineers,https://www.reddit.com/r/MachineLearning/comments/6e5ogq/essential_cheat_sheets_for_machine_learning_and/,kailashahirwar12,1496126041,,0,1
1108,2017-5-30,2017,5,30,16,6e5s0j,[R] Lifelong Generative Modeling,https://www.reddit.com/r/MachineLearning/comments/6e5s0j/r_lifelong_generative_modeling/,bge0,1496127649,,0,15
1109,2017-5-30,2017,5,30,16,6e5yu7,Cool Machine Learning Examples in Real Life,https://www.reddit.com/r/MachineLearning/comments/6e5yu7/cool_machine_learning_examples_in_real_life/,itenterprise09,1496130848,[removed],0,1
1110,2017-5-30,2017,5,30,18,6e67x6,Predicting the observations in a partially observable Markov decision process with a recurrent neural network,https://www.reddit.com/r/MachineLearning/comments/6e67x6/predicting_the_observations_in_a_partially/,wehnsdaefflae,1496135258,[removed],0,1
1111,2017-5-30,2017,5,30,18,6e69wp,Sentiment model (for Spanish natural language),https://www.reddit.com/r/MachineLearning/comments/6e69wp/sentiment_model_for_spanish_natural_language/,Zeta36,1496136208,[removed],0,1
1112,2017-5-30,2017,5,30,19,6e6lz5,ICCV results are out.,https://www.reddit.com/r/MachineLearning/comments/6e6lz5/iccv_results_are_out/,seleucia,1496141611,,1,1
1113,2017-5-30,2017,5,30,19,6e6mhl,[D] PC Build for ML &amp; VR,https://www.reddit.com/r/MachineLearning/comments/6e6mhl/d_pc_build_for_ml_vr/,[deleted],1496141839,[deleted],0,0
1114,2017-5-30,2017,5,30,19,6e6mlf,"[D] Is VGG common in newer research, or is ResNet the new standard for pretrained networks?",https://www.reddit.com/r/MachineLearning/comments/6e6mlf/d_is_vgg_common_in_newer_research_or_is_resnet/,Cock-tail,1496141885,"I've looked at some benchmarks, and it seems like Resnet-50 is both faster and more accurate than both VGGs.
Is there any reason to use VGG, other than the simple architecture?",20,15
1115,2017-5-30,2017,5,30,21,6e6x8c,[P] pyGPGO: Another Python package for Bayesian Optimization,https://www.reddit.com/r/MachineLearning/comments/6e6x8c/p_pygpgo_another_python_package_for_bayesian/,jimenezluna,1496145832,,19,17
1116,2017-5-30,2017,5,30,21,6e6x8w,"How to infer ""groupings"" of data points separated alone one dimension?",https://www.reddit.com/r/MachineLearning/comments/6e6x8w/how_to_infer_groupings_of_data_points_separated/,Zeekawla99ii,1496145837,[removed],0,1
1117,2017-5-30,2017,5,30,22,6e7bk6,[P] Open curated list of Machine Learning Surveys,https://www.reddit.com/r/MachineLearning/comments/6e7bk6/p_open_curated_list_of_machine_learning_surveys/,nianhao,1496150686,,0,33
1118,2017-5-30,2017,5,30,23,6e7qa2,How Machine Learning Facilitates Fraud Detection?,https://www.reddit.com/r/MachineLearning/comments/6e7qa2/how_machine_learning_facilitates_fraud_detection/,hardikmakadia,1496155174,,0,1
1119,2017-5-31,2017,5,31,0,6e83og,I wrote this blog about sentiment analysis. Do you know of other better ways to improve this model?,https://www.reddit.com/r/MachineLearning/comments/6e83og/i_wrote_this_blog_about_sentiment_analysis_do_you/,jennifercqcq,1496158837,,0,1
1120,2017-5-31,2017,5,31,0,6e84ks,"This is interesting. How do you say ""deep learning""? Apprendimento profondo, tiefes lernen, pembelajaran dalam...",https://www.reddit.com/r/MachineLearning/comments/6e84ks/this_is_interesting_how_do_you_say_deep_learning/,reworksophie,1496159080,,0,1
1121,2017-5-31,2017,5,31,0,6e84q5,Meet The World's Leading AI Pioneers in The 'Silicon Valley of Deep Learning',https://www.reddit.com/r/MachineLearning/comments/6e84q5/meet_the_worlds_leading_ai_pioneers_in_the/,reworksophie,1496159126,,0,1
1122,2017-5-31,2017,5,31,0,6e84te,Pretrained models for nlp,https://www.reddit.com/r/MachineLearning/comments/6e84te/pretrained_models_for_nlp/,cece95x,1496159147,[removed],0,1
1123,2017-5-31,2017,5,31,0,6e85sb,BOSTON DEEP LEARNING SUMMIT - DAY 1 HIGHLIGHTS,https://www.reddit.com/r/MachineLearning/comments/6e85sb/boston_deep_learning_summit_day_1_highlights/,reworksophie,1496159400,,0,1
1124,2017-5-31,2017,5,31,1,6e88eo,"Graphons and ""Inferencing""",https://www.reddit.com/r/MachineLearning/comments/6e88eo/graphons_and_inferencing/,dendisuhubdy,1496160089,,0,1
1125,2017-5-31,2017,5,31,2,6e8ngl,Good list of courses to learn machine learning,https://www.reddit.com/r/MachineLearning/comments/6e8ngl/good_list_of_courses_to_learn_machine_learning/,[deleted],1496163995,[deleted],0,1
1126,2017-5-31,2017,5,31,2,6e8vmj,Compelling AI case study in HBR,https://www.reddit.com/r/MachineLearning/comments/6e8vmj/compelling_ai_case_study_in_hbr/,Ricmerrifield,1496166012,,0,1
1127,2017-5-31,2017,5,31,3,6e9271,dSprites - a simple dataset to check the disentanglement properties of unsupervised models.,https://www.reddit.com/r/MachineLearning/comments/6e9271/dsprites_a_simple_dataset_to_check_the/,[deleted],1496167648,[deleted],0,2
1128,2017-5-31,2017,5,31,3,6e94ko,How Googles Music-Making AI Learns From Human Minds At Festivals,https://www.reddit.com/r/MachineLearning/comments/6e94ko/how_googles_musicmaking_ai_learns_from_human/,[deleted],1496168270,[deleted],0,1
1129,2017-5-31,2017,5,31,3,6e97gm,[D] A Tour of PyTorch Internals (Part I),https://www.reddit.com/r/MachineLearning/comments/6e97gm/d_a_tour_of_pytorch_internals_part_i/,evc123,1496169014,,1,66
1130,2017-5-31,2017,5,31,3,6e97jg,[P] Sortable and searchable compilation of solutions to past Kaggle competitions,https://www.reddit.com/r/MachineLearning/comments/6e97jg/p_sortable_and_searchable_compilation_of/,pmigdal,1496169033,,2,79
1131,2017-5-31,2017,5,31,3,6e99gc,Data Scientists - The Secret Sauce of Profitable Food Companies?,https://www.reddit.com/r/MachineLearning/comments/6e99gc/data_scientists_the_secret_sauce_of_profitable/,deepnify,1496169528,,0,1
1132,2017-5-31,2017,5,31,3,6e9acq,Can somebody tell me how many layers does it have? which one count as a layer and which one not?,https://www.reddit.com/r/MachineLearning/comments/6e9acq/can_somebody_tell_me_how_many_layers_does_it_have/,muneeb2405,1496169755,[removed],0,1
1133,2017-5-31,2017,5,31,3,6e9ay0,Using RGB-D data with keras,https://www.reddit.com/r/MachineLearning/comments/6e9ay0/using_rgbd_data_with_keras/,Cheses100,1496169911,[removed],0,1
1134,2017-5-31,2017,5,31,4,6e9fuq,[P] Having some fun with conditional VAEs,https://www.reddit.com/r/MachineLearning/comments/6e9fuq/p_having_some_fun_with_conditional_vaes/,rui_,1496171176,,0,4
1135,2017-5-31,2017,5,31,4,6e9ife,(Project) Application for writing College papers,https://www.reddit.com/r/MachineLearning/comments/6e9ife/project_application_for_writing_college_papers/,Iph0n3junki,1496171837,[removed],0,1
1136,2017-5-31,2017,5,31,4,6e9obs,What is the relation of the negative sampling (NS) objective function to the original objective function in word2vec?,https://www.reddit.com/r/MachineLearning/comments/6e9obs/what_is_the_relation_of_the_negative_sampling_ns/,real_pinocchio,1496173390,,0,1
1137,2017-5-31,2017,5,31,5,6e9tbi,What use cases would require a deep learning model actively get trained on growing datasets?,https://www.reddit.com/r/MachineLearning/comments/6e9tbi/what_use_cases_would_require_a_deep_learning/,baobaodumpling,1496174669,[removed],0,1
1138,2017-5-31,2017,5,31,5,6ea01y,[P] dSprites - a simple dataset to check the disentanglement properties of unsupervised models,https://www.reddit.com/r/MachineLearning/comments/6ea01y/p_dsprites_a_simple_dataset_to_check_the/,azhag,1496176421,,1,6
1139,2017-5-31,2017,5,31,6,6ea8fg,"[R] ""Kronecker Recurrent Units"", Jose et al 2017",https://www.reddit.com/r/MachineLearning/comments/6ea8fg/r_kronecker_recurrent_units_jose_et_al_2017/,gwern,1496178634,,25,39
1140,2017-5-31,2017,5,31,6,6eabmt,Everything you need to know about machine learning,https://www.reddit.com/r/MachineLearning/comments/6eabmt/everything_you_need_to_know_about_machine_learning/,pmz,1496179490,,0,1
1141,2017-5-31,2017,5,31,7,6eaqon,[D] Good books/lectures on tensor decomposition?,https://www.reddit.com/r/MachineLearning/comments/6eaqon/d_good_bookslectures_on_tensor_decomposition/,oqowa,1496183542,"Hey guys, I'm complete newbie in all this stuff. I'm trying to read and learn. And I really struggle with tensor decomposition methods. Can anyone recommend me any material/book/monograph for reading? Especially I would like to see the examples of using the methods. Because it's really hard for me to visualize in my brain all the stuff that I'm reading.",4,1
1142,2017-5-31,2017,5,31,7,6easvm,what is impose coordinate frame ?,https://www.reddit.com/r/MachineLearning/comments/6easvm/what_is_impose_coordinate_frame/,John_Smith111,1496184133,[removed],3,1
1143,2017-5-31,2017,5,31,8,6eb1ky,Multiple optima in cross validated elastic net regression?,https://www.reddit.com/r/MachineLearning/comments/6eb1ky/multiple_optima_in_cross_validated_elastic_net/,UmamiSalami,1496186618,[removed],0,1
1144,2017-5-31,2017,5,31,8,6eb7qc,Theory Question,https://www.reddit.com/r/MachineLearning/comments/6eb7qc/theory_question/,available-_-username,1496188410,[removed],0,1
1145,2017-5-31,2017,5,31,9,6ebayt,Is there a difference between autoencoders and encoder-decoder in deep learning?,https://www.reddit.com/r/MachineLearning/comments/6ebayt/is_there_a_difference_between_autoencoders_and/,moh3th1,1496189384,[removed],0,1
1146,2017-5-31,2017,5,31,10,6ebw3z,Medical Image Analysis with Deep Learning,https://www.reddit.com/r/MachineLearning/comments/6ebw3z/medical_image_analysis_with_deep_learning/,[deleted],1496195732,[deleted],0,1
1147,2017-5-31,2017,5,31,11,6ec4kl,3 different ways for doing backprop in an MLP using TensorFlow (high-level optimizer to low level linalg),https://www.reddit.com/r/MachineLearning/comments/6ec4kl/3_different_ways_for_doing_backprop_in_an_mlp/,[deleted],1496198385,[deleted],0,1
1148,2017-5-31,2017,5,31,11,6ec769,What's going on at OpenAI?,https://www.reddit.com/r/MachineLearning/comments/6ec769/whats_going_on_at_openai/,[deleted],1496199224,[removed],0,1
1149,2017-5-31,2017,5,31,12,6ec8q6,"Backprop in TensorFlow coded up in 3 different ways, high and low-level MLPs",https://www.reddit.com/r/MachineLearning/comments/6ec8q6/backprop_in_tensorflow_coded_up_in_3_different/,[deleted],1496199720,[deleted],0,1
1150,2017-5-31,2017,5,31,12,6ecfa2,[D] Art datasets?,https://www.reddit.com/r/MachineLearning/comments/6ecfa2/d_art_datasets/,beef__,1496201900,"The title is pretty self explanatory - are there any datasets of artwork out there? I've been looking around but can't seem to find anything really... Even if it's just like, totally unlabeled data of artwork (just the images), that'd be cool - literally anything would help.

I've been looking around to see if any art galleries have digital archives that could be used as a dataset, but can't seem to find any readily available ones... 

There are so many cool ML projects that I'd love to do with generative art i just really need data :(",15,9
1151,2017-5-31,2017,5,31,12,6echff,"Reviewers of ML subreddit, what's your mindset as you review a paper ?",https://www.reddit.com/r/MachineLearning/comments/6echff/reviewers_of_ml_subreddit_whats_your_mindset_as/,[deleted],1496202646,[removed],0,1
1152,2017-5-31,2017,5,31,14,6ed159,The Cramer Distance as a Solution to Biased Wasserstein Gradients,https://www.reddit.com/r/MachineLearning/comments/6ed159/the_cramer_distance_as_a_solution_to_biased/,juxtaposicion,1496210020,,0,2
1153,2017-5-31,2017,5,31,15,6ed5pv,[D] On the influence of Zero-Inputs in Neural Networks,https://www.reddit.com/r/MachineLearning/comments/6ed5pv/d_on_the_influence_of_zeroinputs_in_neural/,Delthc,1496211818,"Hello,

I am currently dealing with a toy reinforcement learning enviroment, where the agent has proximity sensors as inputs, a bit like the Water World ( http://cs.stanford.edu/people/karpathy/reinforcejs/waterworld.html )

However, the enviroment is a lot more complex, so it will have dozends of these sensors, which means a lot of inputs where most of them will be zero at any given point in time.

So my first question is:
Is it true that, without a bias in the layer, a neuron that has zero activation has no influence on the next layer and/or the whole network, as its forward passed signal is always zero.

My naive guess is that it has no direct influence (but basically acts as some kind of dropout) but the network can still learn to make sense of it IF the absence of a sensor input is some kind of usefull information.


My second question is:
Am I right with the assumption that I should not use any kind of BatchNormalisation in the first layer because then it could change zero-inputs to non-zero inputs, which would suddenly ""flood"" the network with signals even tough the corresponding sensor says ""nothing there""

My third question is:
Am I right with the assumption that I might be better off not using dropout - at least not in the first layer, but perhaps also not in other layers - because the sparse input is some kind of dropout in itself?

Thanks in advance!",6,7
1154,2017-5-31,2017,5,31,15,6ed9g5,Mayflay Hot sale Shot blasting machine,https://www.reddit.com/r/MachineLearning/comments/6ed9g5/mayflay_hot_sale_shot_blasting_machine/,Shot-blasting,1496213384,,1,1
1155,2017-5-31,2017,5,31,16,6ede0s,Best book/resource for beginners to learn TF Learn,https://www.reddit.com/r/MachineLearning/comments/6ede0s/best_bookresource_for_beginners_to_learn_tf_learn/,JitHu1306,1496215319,[removed],0,1
1156,2017-5-31,2017,5,31,16,6ede5o,Collection of Books and Articles in Machine Learning and Computer Vision,https://www.reddit.com/r/MachineLearning/comments/6ede5o/collection_of_books_and_articles_in_machine/,zhaokai,1496215366,,0,1
1157,2017-5-31,2017,5,31,16,6edh2v,"What is the ""state of the science"" within ""OCR"" meets NLP ML?",https://www.reddit.com/r/MachineLearning/comments/6edh2v/what_is_the_state_of_the_science_within_ocr_meets/,[deleted],1496216698,[removed],0,1
1158,2017-5-31,2017,5,31,16,6edi8w,[R]Anyone Fancy Doing a Ph.D. in Deep Learning Intrusion Detection for IoT Networks in the UK?,https://www.reddit.com/r/MachineLearning/comments/6edi8w/ranyone_fancy_doing_a_phd_in_deep_learning/,Alex0789,1496217227,Have a look at http://www.xavierbellekens.com/PhDApplication,22,18
1159,2017-5-31,2017,5,31,17,6edjyk,[D] Royal Holloway - Msc by research,https://www.reddit.com/r/MachineLearning/comments/6edjyk/d_royal_holloway_msc_by_research/,Param-eter,1496217956,"Has anyone done an Msc by research? This one at Royal Holloway looks decent and it seems like it's more like a mini PHD than a traditional taught masters but I can't feed any information on how good these types of programs are.

Any thoughts would be helpful.

http://www.cs.rhul.ac.uk/Studying/pg/ml.html
",4,7
1160,2017-5-31,2017,5,31,17,6edku6,[D] Inverted Dropout: How does it really work?,https://www.reddit.com/r/MachineLearning/comments/6edku6/d_inverted_dropout_how_does_it_really_work/,xternalz,1496218338,"It has replaced the conventional dropout method of scaling the activations during testing, but there isn't any paper that talks about it in depth.",6,25
1161,2017-5-31,2017,5,31,18,6edyhy,How to do hyper parameter tuning using sklearn quickly,https://www.reddit.com/r/MachineLearning/comments/6edyhy/how_to_do_hyper_parameter_tuning_using_sklearn/,Abhi001vj,1496224629,[removed],0,1
1162,2017-5-31,2017,5,31,20,6eee4z,Non- numeric data interpretation for machine learning.,https://www.reddit.com/r/MachineLearning/comments/6eee4z/non_numeric_data_interpretation_for_machine/,mendax007,1496230889,[removed],0,1
1163,2017-5-31,2017,5,31,21,6eeq1v,Deep Complex Networks,https://www.reddit.com/r/MachineLearning/comments/6eeq1v/deep_complex_networks/,[deleted],1496234862,[deleted],0,1
1164,2017-5-31,2017,5,31,21,6eeq7g,[R] Deep Complex Networks,https://www.reddit.com/r/MachineLearning/comments/6eeq7g/r_deep_complex_networks/,[deleted],1496234911,[deleted],0,1
1165,2017-5-31,2017,5,31,21,6eeqfb,[R] Deep Complex Networks,https://www.reddit.com/r/MachineLearning/comments/6eeqfb/r_deep_complex_networks/,popcorncolonel,1496234985,,11,24
1166,2017-5-31,2017,5,31,21,6eer9v,Pi zero phone project bot,https://www.reddit.com/r/MachineLearning/comments/6eer9v/pi_zero_phone_project_bot/,BridgeOfAlter,1496235249,[removed],0,1
1167,2017-5-31,2017,5,31,22,6eesom,Getting started with ML books,https://www.reddit.com/r/MachineLearning/comments/6eesom/getting_started_with_ml_books/,ComaBoyRunning,1496235695,[removed],0,1
1168,2017-5-31,2017,5,31,22,6eewla,An Overview of Multi-Task Learning for Deep Learning,https://www.reddit.com/r/MachineLearning/comments/6eewla/an_overview_of_multitask_learning_for_deep/,[deleted],1496236847,[deleted],0,1
1169,2017-5-31,2017,5,31,22,6eey4y,Google Machine Learning Attribution Tool for Online Market,https://www.reddit.com/r/MachineLearning/comments/6eey4y/google_machine_learning_attribution_tool_for/,K2Bsolutions,1496237319,,0,1
1170,2017-5-31,2017,5,31,22,6ef17n,[D] An Overview of Multi-Task Learning for Deep Learning,https://www.reddit.com/r/MachineLearning/comments/6ef17n/d_an_overview_of_multitask_learning_for_deep/,i-heart-turtles,1496238273,,4,41
1171,2017-5-31,2017,5,31,22,6ef24k,Question about Random Forest performance on my data,https://www.reddit.com/r/MachineLearning/comments/6ef24k/question_about_random_forest_performance_on_my/,[deleted],1496238528,[removed],0,1
1172,2017-5-31,2017,5,31,22,6ef3pj,"[R] Emergent Language in a Multi-Modal, Multi-Step Referential Game",https://www.reddit.com/r/MachineLearning/comments/6ef3pj/r_emergent_language_in_a_multimodal_multistep/,anantzoid,1496238977,,0,2
1173,2017-5-31,2017,5,31,22,6ef47i,"Twitter Sentiment Analysis using python, xgboost and word2vec",https://www.reddit.com/r/MachineLearning/comments/6ef47i/twitter_sentiment_analysis_using_python_xgboost/,[deleted],1496239115,[deleted],0,1
1174,2017-5-31,2017,5,31,23,6ef9rs,Machine Learning on Stampede2 Supercomputer Bolsters Brain Research,https://www.reddit.com/r/MachineLearning/comments/6ef9rs/machine_learning_on_stampede2_supercomputer/,KeponeFactory,1496240601,,0,1
1175,2017-5-31,2017,5,31,23,6efg8z,Deep Learning for Semantic Segmentation of Aerial Imagery,https://www.reddit.com/r/MachineLearning/comments/6efg8z/deep_learning_for_semantic_segmentation_of_aerial/,aerialml,1496242342,,0,2
