,sbr,sbr_id,date,year,month,hour,day,id,domain,title,full_link,author,created,selftext,num_comments,score,over_18,thumbnail,media_provider,media_thumbnail,media_title,media_description,media_url
0,MachineLearning,t5_2r3gv,2016-12-1,2016,12,1,10,5ftjdi,self.MachineLearning,[D] Does 'linear separability' matter for regression?,https://www.reddit.com/r/MachineLearning/comments/5ftjdi/d_does_linear_separability_matter_for_regression/,virivim,1480554103,[removed],1,3,False,default,,,,,
1,MachineLearning,t5_2r3gv,2016-12-1,2016,12,1,13,5fumxe,bloomberg.com,[N] Why Comma.ai Is Giving Away Self-Driving Car Technology,https://www.reddit.com/r/MachineLearning/comments/5fumxe/n_why_commaai_is_giving_away_selfdriving_car/,evc123,1480566938,,0,1,False,default,,,,,
2,MachineLearning,t5_2r3gv,2016-12-1,2016,12,1,13,5fup17,self.MachineLearning,[D] Is it possible to train a 'nouns' only word2vec style model ?,https://www.reddit.com/r/MachineLearning/comments/5fup17/d_is_it_possible_to_train_a_nouns_only_word2vec/,curryage,1480567712,"I would like to train a model to predict 'word2vec' representations for a given image. The input image contains a single object. Currently, the model uses Glove/word2vec as output. Currently, the nearest neighbors for a predicted word2vec could be 'any' part of the speech. Instead, is it possible to train a customized model which captures word2vec style relationships but is confined to nouns ? That way, the word2vec dictionary (and predictions) can be confined to object names (and their synonyms or closely related concepts). One possibility is to use WordNet, but confined to only the noun senses. Any suggestions/ideas ?

",9,4,False,self,,,,,
3,MachineLearning,t5_2r3gv,2016-12-1,2016,12,1,14,5fur2d,youtube.com,Plastic Recycling Machine,https://www.reddit.com/r/MachineLearning/comments/5fur2d/plastic_recycling_machine/,Regulusmachinery,1480568490,,1,1,False,default,,,,,
4,MachineLearning,t5_2r3gv,2016-12-1,2016,12,1,14,5fuw8q,github.com,[P] openpilot - An open source driving agent,https://www.reddit.com/r/MachineLearning/comments/5fuw8q/p_openpilot_an_open_source_driving_agent/,luiscosio,1480570376,,15,44,False,http://b.thumbs.redditmedia.com/BDej5-ATYbtXU93xVDeCaZqBkWO21VcwMClHqhPD2sM.jpg,,,,,
5,MachineLearning,t5_2r3gv,2016-12-1,2016,12,1,14,5fux6s,self.MachineLearning,What does bAbI stand for?,https://www.reddit.com/r/MachineLearning/comments/5fux6s/what_does_babi_stand_for/,63coldnoodle,1480570744,[removed],1,1,False,default,,,,,
6,MachineLearning,t5_2r3gv,2016-12-1,2016,12,1,15,5fv6vp,arxiv.org,[R] Google Research's COCO detection winning solution,https://www.reddit.com/r/MachineLearning/comments/5fv6vp/r_google_researchs_coco_detection_winning_solution/,zhongwenxu,1480574829,,3,63,False,default,,,,,
7,MachineLearning,t5_2r3gv,2016-12-1,2016,12,1,17,5fvjzp,self.MachineLearning,[D] Will a PhD help me as a startup founder in ML?,https://www.reddit.com/r/MachineLearning/comments/5fvjzp/d_will_a_phd_help_me_as_a_startup_founder_in_ml/,[deleted],1480581399,[removed],1,1,False,default,,,,,
8,MachineLearning,t5_2r3gv,2016-12-1,2016,12,1,18,5fvo9o,youtube.com,The one of blazes of resins paddle mixers for sale,https://www.reddit.com/r/MachineLearning/comments/5fvo9o/the_one_of_blazes_of_resins_paddle_mixers_for_sale/,mixmachinery,1480583767,,1,1,False,default,,,,,
9,MachineLearning,t5_2r3gv,2016-12-1,2016,12,1,19,5fvt2o,arxiv.org,[R] [1611.04231] Identity Matters in Deep Learning,https://www.reddit.com/r/MachineLearning/comments/5fvt2o/r_161104231_identity_matters_in_deep_learning/,TheFlyingDrildo,1480586429,,7,38,False,default,,,,,
10,MachineLearning,t5_2r3gv,2016-12-1,2016,12,1,19,5fvw1v,wired.co.uk,Europe is leading the way in AI and machine learning (and even Silicon Valley wants in,https://www.reddit.com/r/MachineLearning/comments/5fvw1v/europe_is_leading_the_way_in_ai_and_machine/,[deleted],1480587895,[deleted],0,1,False,default,,,,,
11,MachineLearning,t5_2r3gv,2016-12-1,2016,12,1,19,5fvw3t,wired.co.uk,Europe is leading the way in AI and machine learning (and even Silicon Valley wants in),https://www.reddit.com/r/MachineLearning/comments/5fvw3t/europe_is_leading_the_way_in_ai_and_machine/,johnmountain,1480587923,,0,1,False,default,,,,,
12,MachineLearning,t5_2r3gv,2016-12-1,2016,12,1,22,5fwnxm,i.redd.it,Visualizing neural network learning with Tensorflow Playground,https://www.reddit.com/r/MachineLearning/comments/5fwnxm/visualizing_neural_network_learning_with/,FearlessAnt,1480600523,,1,1,False,default,,,,,
13,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,0,5fx5o6,arxiv.org,[1611.09957] t-Exponential Triplet Embedding,https://www.reddit.com/r/MachineLearning/comments/5fx5o6/161109957_texponential_triplet_embedding/,Bardelaz,1480606332,,0,1,False,default,,,,,
14,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,0,5fx5pa,self.MachineLearning,NVIDIA Jetson TX1 as RPI alternative for Neural Networks in the wild?,https://www.reddit.com/r/MachineLearning/comments/5fx5pa/nvidia_jetson_tx1_as_rpi_alternative_for_neural/,Neural_Nigel,1480606339,[removed],0,1,False,default,,,,,
15,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,0,5fx9zv,arxiv.org,[R][1611.08669] Visual Dialog,https://www.reddit.com/r/MachineLearning/comments/5fx9zv/r161108669_visual_dialog/,[deleted],1480607598,[deleted],0,1,False,default,,,,,
16,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,0,5fxa8m,arxiv.org,[R][1611.08669] Visual Dialog,https://www.reddit.com/r/MachineLearning/comments/5fxa8m/r161108669_visual_dialog/,abhshkdz,1480607670,,1,28,False,default,,,,,
17,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,3,5fy1wi,self.MachineLearning,What's state of the art in keyword mining?,https://www.reddit.com/r/MachineLearning/comments/5fy1wi/whats_state_of_the_art_in_keyword_mining/,coffeecoffeecoffeee,1480615376,[removed],0,1,False,default,,,,,
18,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,3,5fy5x9,self.MachineLearning,Some questions about Conv3D (3D convolution),https://www.reddit.com/r/MachineLearning/comments/5fy5x9/some_questions_about_conv3d_3d_convolution/,Coderx7,1480616449,[removed],1,1,False,default,,,,,
19,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,3,5fy5yc,140.221.6.23,On Automatic Differentiation,https://www.reddit.com/r/MachineLearning/comments/5fy5yc/on_automatic_differentiation/,[deleted],1480616458,[deleted],0,1,False,default,,,,,
20,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,3,5fy68o,140.221.6.23,[R] On Automatic Differentiation (1988),https://www.reddit.com/r/MachineLearning/comments/5fy68o/r_on_automatic_differentiation_1988/,rd11235,1480616531,,5,8,False,default,,,,,
21,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,3,5fy6gr,math.uni-bielefeld.de,Who Invented the Reverse Mode of Differentiation?,https://www.reddit.com/r/MachineLearning/comments/5fy6gr/who_invented_the_reverse_mode_of_differentiation/,[deleted],1480616592,[deleted],0,1,False,default,,,,,
22,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,3,5fy6lo,math.uni-bielefeld.de,[R] Who Invented the Reverse Mode of Differentiation?,https://www.reddit.com/r/MachineLearning/comments/5fy6lo/r_who_invented_the_reverse_mode_of_differentiation/,rd11235,1480616623,,9,22,False,default,,,,,
23,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,3,5fy80x,evolvingai.org,[R] Plug &amp;amp; Play Generative Networks: Conditional Iterative Generation of Images in Latent Space,https://www.reddit.com/r/MachineLearning/comments/5fy80x/r_plug_amp_play_generative_networks_conditional/,[deleted],1480617004,[deleted],0,1,False,default,,,,,
24,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,3,5fy8xg,evolvingai.org,[R] Plug &amp; Play Generative Networks,https://www.reddit.com/r/MachineLearning/comments/5fy8xg/r_plug_play_generative_networks/,downtownslim,1480617232,,16,49,False,http://b.thumbs.redditmedia.com/t3m_as0t6lUQtar4Xr4RTKBnrysYEYQ6IaTvQxEac9Q.jpg,,,,,
25,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,3,5fyeh3,self.MachineLearning,"[D] Aside from in CNN's, what is the evidence that NN's learn increasingly abstract representations of their inputs?",https://www.reddit.com/r/MachineLearning/comments/5fyeh3/d_aside_from_in_cnns_what_is_the_evidence_that/,fuckinghelldad,1480618780,[removed],1,1,False,default,,,,,
26,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,4,5fyrqp,self.MachineLearning,[D]How would I ideally structure training data to train a CNN to output bounding box coordinates?,https://www.reddit.com/r/MachineLearning/comments/5fyrqp/dhow_would_i_ideally_structure_training_data_to/,gregkop,1480622382,[removed],2,2,False,default,,,,,
27,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,5,5fz02i,blog.cylance.com,"""There is no such thing as 100 percent security. There is always some way in. But now, as artificial intelligence and machine learning have improved, you can prevent the hackers of today and tomorrow, because hackers use the same techniques.""",https://www.reddit.com/r/MachineLearning/comments/5fz02i/there_is_no_such_thing_as_100_percent_security/,Fiddle_sticks8,1480624725,,0,1,False,default,,,,,
28,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,5,5fz18z,self.MachineLearning,[D] RL theorem proofer,https://www.reddit.com/r/MachineLearning/comments/5fz18z/d_rl_theorem_proofer/,[deleted],1480625072,How feasible is it to build a Deep Q learner that churns out new math proofs with a secondary reinforcer being verification from an actual theorem proofer. Ideally in the long run this will proof anything mathematical. ,14,10,False,self,,,,,
29,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,7,5fzhh9,code.facebook.com,"""Artificial intelligence, revealed"" - Blog post and 6 videos by Yann LeCun and Joaquin Quionero Candela",https://www.reddit.com/r/MachineLearning/comments/5fzhh9/artificial_intelligence_revealed_blog_post_and_6/,[deleted],1480629660,[deleted],0,1,False,default,,,,,
30,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,7,5fzizz,code.facebook.com,"[R] ""Artificial intelligence, revealed"" - Blog post and 6 videos by Yann LeCun and Joaquin Quionero Candela",https://www.reddit.com/r/MachineLearning/comments/5fzizz/r_artificial_intelligence_revealed_blog_post_and/,jakn,1480630056,,0,68,False,http://a.thumbs.redditmedia.com/UiQS1IrKZc9iMnNvqNQefnvFWBsQaJhfuHHXvVVM-H0.jpg,,,,,
31,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,7,5fzjcx,news.developer.nvidia.com,Artificial Intelligence Generates and Sung Christmas Song From Holiday Image,https://www.reddit.com/r/MachineLearning/comments/5fzjcx/artificial_intelligence_generates_and_sung/,bnemire,1480630161,,0,1,False,default,,,,,
32,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,7,5fzo22,spectrum.ieee.org,Deep Learning Startup Maluuba's AI Wants to Talk to You,https://www.reddit.com/r/MachineLearning/comments/5fzo22/deep_learning_startup_maluubas_ai_wants_to_talk/,[deleted],1480631513,[deleted],0,1,False,default,,,,,
33,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,8,5fzy85,engineering.siftscience.com,"ML Experiments at Sift Science, Part 1: Minimizing Bias",https://www.reddit.com/r/MachineLearning/comments/5fzy85/ml_experiments_at_sift_science_part_1_minimizing/,atpaino,1480634513,,0,1,False,default,,,,,
34,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,9,5g06xn,self.MachineLearning,[D] Will a PhD help me as a startup founder in ML?,https://www.reddit.com/r/MachineLearning/comments/5g06xn/d_will_a_phd_help_me_as_a_startup_founder_in_ml/,[deleted],1480639028,[removed],0,1,False,default,,,,,
35,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,10,5g0dqj,self.MachineLearning,[D] Will a PhD help me as a startup founder in ML?,https://www.reddit.com/r/MachineLearning/comments/5g0dqj/d_will_a_phd_help_me_as_a_startup_founder_in_ml/,Indy20161,1480641098,[removed],1,1,False,default,,,,,
36,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,10,5g0khj,github.com,"Guide: How to Set Up Spark with Jupyter painlessly on AWS EC2 clusters, with S3 I/O",https://www.reddit.com/r/MachineLearning/comments/5g0khj/guide_how_to_set_up_spark_with_jupyter_painlessly/,datasciencelover,1480643321,,0,1,False,default,,,,,
37,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,11,5g0rsp,kdnuggets.com,Machine Learning vs Statistics,https://www.reddit.com/r/MachineLearning/comments/5g0rsp/machine_learning_vs_statistics/,kumeralex,1480645776,,0,1,False,default,,,,,
38,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,13,5g1gmr,durantco.com,Durant Tool Company for Machine Manufacturer and Distributor,https://www.reddit.com/r/MachineLearning/comments/5g1gmr/durant_tool_company_for_machine_manufacturer_and/,durantco,1480654508,,0,1,False,default,,,,,
39,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,14,5g1nd2,self.MachineLearning,Cracking mobile device (iOS / Android) pin codes,https://www.reddit.com/r/MachineLearning/comments/5g1nd2/cracking_mobile_device_ios_android_pin_codes/,[deleted],1480657131,[removed],0,1,False,default,,,,,
40,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,14,5g1osn,self.MachineLearning,[Project] Cracking mobile device (iOS / Android) pin codes,https://www.reddit.com/r/MachineLearning/comments/5g1osn/project_cracking_mobile_device_ios_android_pin/,kentsommer,1480657736,"https://www.youtube.com/watch?v=bBQtMo-zpqg

This is a proof of concept demo I built showing the potential for cracking mobile device pin codes / inferring touch locations via a compromised website that logs gyroscope and accelerometer data streams.

Basic logic flow is:

1) Independent (no dependencies and fits W3C specification so it is supported in every mobile browser) JS script logs both accelerometer and gyroscope sensor streams on a compromised website to a Mongo database.

2) Matlab pulls in sensor streams from Mongo and processes them before passing the processed sequences to a trained artificial neural network.

The network was trained on a sample of 1514 manually collected key presses. The artificial neural network is extremely simple, consisting of one hidden layer with 1000 nodes. Training was done using gradient descent with a learning rate of 0.01. The network is trained using cross entropy loss to output class (0-9) probabilities  for each key press. This setup assumes the ability to distinguish taps. 

All questions are welcome :)

Source code is available upon request (PM or email)",5,51,False,self,,,,,
41,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,16,5g20dg,arxiv.org,[R] Playing Doom with SLAM-Augmented Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/5g20dg/r_playing_doom_with_slamaugmented_deep/,Eruditass,1480663028,,6,32,False,default,,,,,
42,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,16,5g21pm,arxiv.org,[R] High-Resolution Image Inpainting using Multi-Scale Neural Patch Synthesis,https://www.reddit.com/r/MachineLearning/comments/5g21pm/r_highresolution_image_inpainting_using/,leehomyc,1480663694,,1,20,False,default,,,,,
43,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,17,5g26eo,arxiv.org,[R] [1611.01186] Demystifying ResNet,https://www.reddit.com/r/MachineLearning/comments/5g26eo/r_161101186_demystifying_resnet/,TheFlyingDrildo,1480666112,,5,40,False,default,,,,,
44,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,18,5g2gyc,medium.com,Intelligence in Mobile Applications.,https://www.reddit.com/r/MachineLearning/comments/5g2gyc/intelligence_in_mobile_applications/,[deleted],1480671998,[deleted],0,1,False,default,,,,,
45,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,19,5g2odr,ams.org,Finding Holes in the Data,https://www.reddit.com/r/MachineLearning/comments/5g2odr/finding_holes_in_the_data/,[deleted],1480675960,[deleted],0,1,False,default,,,,,
46,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,19,5g2oja,ams.org,Finding Holes in the Data [R],https://www.reddit.com/r/MachineLearning/comments/5g2oja/finding_holes_in_the_data_r/,cavedave,1480676033,,4,27,False,http://b.thumbs.redditmedia.com/H0pfDucWrVQOe8VOM9ry-ymPtJhMj4OOwcvRWzbzQnY.jpg,,,,,
47,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,20,5g2vpb,self.MachineLearning,Idea: Machine Learning for Podcast Translation,https://www.reddit.com/r/MachineLearning/comments/5g2vpb/idea_machine_learning_for_podcast_translation/,march-ai,1480679698,[removed],0,1,False,default,,,,,
48,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,21,5g33g1,sciencedirect.com,[R] Playing real-time strategy games by imitating human players' micromanagement skills based on spatial analysis - data from Starcraft,https://www.reddit.com/r/MachineLearning/comments/5g33g1/r_playing_realtime_strategy_games_by_imitating/,sybilckw,1480683208,,9,82,False,http://b.thumbs.redditmedia.com/xrJnasx-_fke7JFYnaOuW9WxEzldqlbM-rWYkp-6Jts.jpg,,,,,
49,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,23,5g3htn,self.MachineLearning,Need a huge amount of training data for my specific web application. Any help would be much appreciated!,https://www.reddit.com/r/MachineLearning/comments/5g3htn/need_a_huge_amount_of_training_data_for_my/,raziwaqar,1480688633,[removed],0,1,False,default,,,,,
50,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,23,5g3jp1,github.com,[P] [C++] simple_cnn: Simple convolutional neural network library,https://www.reddit.com/r/MachineLearning/comments/5g3jp1/p_c_simple_cnn_simple_convolutional_neural/,goldenrifle,1480689294,,9,33,False,http://a.thumbs.redditmedia.com/h-Pb2AW1UNQQdtKOZdpgr7ZMYiMJjX1dwMmzPnWi1L8.jpg,,,,,
51,MachineLearning,t5_2r3gv,2016-12-2,2016,12,2,23,5g3mra,dzone.com,Dive Deep Into Deep Learning - DZone Big Data,https://www.reddit.com/r/MachineLearning/comments/5g3mra/dive_deep_into_deep_learning_dzone_big_data/,Sibanjan,1480690319,,0,1,False,default,,,,,
52,MachineLearning,t5_2r3gv,2016-12-3,2016,12,3,0,5g3pmv,spectrum.ieee.org,[N] Deep Learning Startup Maluuba's AI Wants to Talk to You,https://www.reddit.com/r/MachineLearning/comments/5g3pmv/n_deep_learning_startup_maluubas_ai_wants_to_talk/,deepthrawa,1480691249,,0,2,False,default,,,,,
53,MachineLearning,t5_2r3gv,2016-12-3,2016,12,3,1,5g449v,self.MachineLearning,May I have some suggestions on hardware?,https://www.reddit.com/r/MachineLearning/comments/5g449v/may_i_have_some_suggestions_on_hardware/,allProfessionalNStuf,1480695702,[removed],0,1,False,default,,,,,
54,MachineLearning,t5_2r3gv,2016-12-3,2016,12,3,1,5g44pr,self.MachineLearning,[D] Any services being used for tagging test image and video data?,https://www.reddit.com/r/MachineLearning/comments/5g44pr/d_any_services_being_used_for_tagging_test_image/,CodeInTheCity,1480695826,[removed],0,2,False,default,,,,,
55,MachineLearning,t5_2r3gv,2016-12-3,2016,12,3,1,5g44ys,self.MachineLearning,I want to get a single sentence from multiple sentences.,https://www.reddit.com/r/MachineLearning/comments/5g44ys/i_want_to_get_a_single_sentence_from_multiple/,[deleted],1480695897,[removed],0,1,False,default,,,,,
56,MachineLearning,t5_2r3gv,2016-12-3,2016,12,3,1,5g4b89,users.cecs.anu.edu.au,NIPS 2016 Exhibition of Rejected Papers,https://www.reddit.com/r/MachineLearning/comments/5g4b89/nips_2016_exhibition_of_rejected_papers/,zdk,1480697718,,0,1,False,default,,,,,
57,MachineLearning,t5_2r3gv,2016-12-3,2016,12,3,2,5g4c6i,medium.com,MACHINE LEARNING: How Black is This Black Box,https://www.reddit.com/r/MachineLearning/comments/5g4c6i/machine_learning_how_black_is_this_black_box/,excipi,1480698011,,0,1,False,default,,,,,
58,MachineLearning,t5_2r3gv,2016-12-3,2016,12,3,5,5g5hcn,medium.com,[R] You Only Look Twice - Multi-Scale Object Detection in Satellite Imagery,https://www.reddit.com/r/MachineLearning/comments/5g5hcn/r_you_only_look_twice_multiscale_object_detection/,highlife159,1480709743,,9,78,False,http://a.thumbs.redditmedia.com/UDvnuzHZgJN54WB_h5MfkcfIn2Bqgs7_2xok6Gy04b8.jpg,,,,,
59,MachineLearning,t5_2r3gv,2016-12-3,2016,12,3,6,5g5qpu,arxiv.org,[R] Fast face-swap with Nicolas Cage using Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/5g5qpu/r_fast_faceswap_with_nicolas_cage_using/,PM_ME_UR_PM_ME_ACC,1480712465,,7,92,False,default,,,,,
60,MachineLearning,t5_2r3gv,2016-12-3,2016,12,3,7,5g6cp1,self.MachineLearning,[D] What is in your opinion the best book to use as a Machine Learning reference.,https://www.reddit.com/r/MachineLearning/comments/5g6cp1/d_what_is_in_your_opinion_the_best_book_to_use_as/,leonoel,1480719099,[removed],0,2,False,default,,,,,
61,MachineLearning,t5_2r3gv,2016-12-3,2016,12,3,9,5g6tl0,self.MachineLearning,Difference between Markov Assumption and Causal Markov Condition in the context of Bayesian Networks?,https://www.reddit.com/r/MachineLearning/comments/5g6tl0/difference_between_markov_assumption_and_causal/,frnkcn,1480724604,[removed],0,1,False,default,,,,,
62,MachineLearning,t5_2r3gv,2016-12-3,2016,12,3,9,5g6zpu,youtu.be,Make an Amazing Tensorflow Chatbot Easily,https://www.reddit.com/r/MachineLearning/comments/5g6zpu/make_an_amazing_tensorflow_chatbot_easily/,llSourcell,1480726726,,0,1,False,default,,,,,
63,MachineLearning,t5_2r3gv,2016-12-3,2016,12,3,11,5g7aal,github.com,[P]Finding Lane Lines on the Road,https://www.reddit.com/r/MachineLearning/comments/5g7aal/pfinding_lane_lines_on_the_road/,upulbandara,1480730596,,4,7,False,http://b.thumbs.redditmedia.com/3ELm7t1bHJCfTP8Q-Xl2iWv01N6tVLsgkvqbgMsvj2M.jpg,,,,,
64,MachineLearning,t5_2r3gv,2016-12-3,2016,12,3,12,5g7oaj,blog.kaggle.com,Kaggle Announces Code Competitions,https://www.reddit.com/r/MachineLearning/comments/5g7oaj/kaggle_announces_code_competitions/,benhamner,1480736159,,0,1,False,default,,,,,
65,MachineLearning,t5_2r3gv,2016-12-3,2016,12,3,14,5g87db,arxiv.org,[1611.02167] Designing Neural Network Architectures using Reinforcement Learning &lt;-- uses 10 gpus instead of 800,https://www.reddit.com/r/MachineLearning/comments/5g87db/161102167_designing_neural_network_architectures/,[deleted],1480744474,[deleted],0,1,False,default,,,,,
66,MachineLearning,t5_2r3gv,2016-12-3,2016,12,3,14,5g87k8,arxiv.org,"[R] [1611.02167] ""Designing Neural Network Architectures using Reinforcement Learning"" &lt;-- uses 10 gpus instead of 800",https://www.reddit.com/r/MachineLearning/comments/5g87k8/r_161102167_designing_neural_network/,evc123,1480744575,,17,77,False,default,,,,,
67,MachineLearning,t5_2r3gv,2016-12-3,2016,12,3,15,5g8erc,mectechnology.co.in,Bandsaw Machine manufacturer in india,https://www.reddit.com/r/MachineLearning/comments/5g8erc/bandsaw_machine_manufacturer_in_india/,mectechnology,1480748135,,0,1,False,default,,,,,
68,MachineLearning,t5_2r3gv,2016-12-3,2016,12,3,16,5g8j80,self.MachineLearning,[D] Idea to generalize a network for a specific task,https://www.reddit.com/r/MachineLearning/comments/5g8j80/d_idea_to_generalize_a_network_for_a_specific_task/,PianoMastR64,1480750494,"Layman here, but tell me what you think. Take many seperate neural networks and train them all to master the same specific task. Then take another neural network and train it on the neural data (every neuron and their connections and weights) of every one of those networks for the purpose of finding all the common structures. Once that network is trained, run it in reverse and output neural data to get a network that represents a generalized version of all the others. Then analyze that network to see what seems to be necessary to do that particular task.

I'm operating under the assumption that each individual network, even when trained on the same data, is very different from the others on the surface, yet similar in many ways that are hard to see.",4,7,False,self,,,,,
69,MachineLearning,t5_2r3gv,2016-12-3,2016,12,3,16,5g8knm,self.MachineLearning,[D]Will Deepmind Labyrinth be released near NIPS ?,https://www.reddit.com/r/MachineLearning/comments/5g8knm/dwill_deepmind_labyrinth_be_released_near_nips/,xingdongrobotics,1480751316,[removed],0,7,False,default,,,,,
70,MachineLearning,t5_2r3gv,2016-12-3,2016,12,3,17,5g8mub,self.MachineLearning,[D] Benchmarks of the TF seq2seq example code?,https://www.reddit.com/r/MachineLearning/comments/5g8mub/d_benchmarks_of_the_tf_seq2seq_example_code/,MetricSpade007,1480752572,Do people have benchmarks of the error rate in training and development over a few day when running the TF seq2seq example code (as is)?,4,4,False,self,,,,,
71,MachineLearning,t5_2r3gv,2016-12-3,2016,12,3,21,5g9bge,self.MachineLearning,"Luka chatbot vs Google chatbot from paper ""A neural conversation model""",https://www.reddit.com/r/MachineLearning/comments/5g9bge/luka_chatbot_vs_google_chatbot_from_paper_a/,mihaitensor,1480767467,[removed],0,1,False,default,,,,,
72,MachineLearning,t5_2r3gv,2016-12-3,2016,12,3,21,5g9btp,i.redd.it,Browser ML algorithms,https://www.reddit.com/r/MachineLearning/comments/5g9btp/browser_ml_algorithms/,[deleted],1480767688,[deleted],1,1,False,default,,,,,
73,MachineLearning,t5_2r3gv,2016-12-3,2016,12,3,21,5g9fvg,webandroid.org,Web Android - Browser ML tools,https://www.reddit.com/r/MachineLearning/comments/5g9fvg/web_android_browser_ml_tools/,[deleted],1480769838,[deleted],1,1,False,default,,,,,
74,MachineLearning,t5_2r3gv,2016-12-3,2016,12,3,22,5g9mj3,webandroid.org,[P]Web Android - Browser ML tools.,https://www.reddit.com/r/MachineLearning/comments/5g9mj3/pweb_android_browser_ml_tools/,maka89,1480772947,,3,2,False,default,,,,,
75,MachineLearning,t5_2r3gv,2016-12-3,2016,12,3,23,5g9qg8,self.MachineLearning,[D] Tasks unsolvable by machine learning.,https://www.reddit.com/r/MachineLearning/comments/5g9qg8/d_tasks_unsolvable_by_machine_learning/,SS_NN,1480774669,"Hey everyone,

I have a question. Are there relatively simple tasks which cannot be done by conventional neural networks? I mean some kind of conscious problems (which can be done by human, but not solvable by machine learning).

For example, text-based question answering, when the text doesn't directly contain an answer. Like this:  
- *Input*: grass is green.  
- *Input*: grass is plant.  
- *Input*: what is grass color?  
- *Output*: green.  
Of course, the neural network is previously trained to understand and distinguish colors. But the word ""grass"" is mentioned for the first time.

Sorry, if I made a dumb example, but maybe you could explain how it can be done?  
What simple tasks unsolvable by machine learning can you come up with?",40,2,False,self,,,,,
76,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,0,5g9whm,github.com,Beginner's Tutorials for Deep Learning in CV,https://www.reddit.com/r/MachineLearning/comments/5g9whm/beginners_tutorials_for_deep_learning_in_cv/,samchoi7,1480777277,,0,1,False,default,,,,,
77,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,0,5ga26q,medium.com,On the Wrong Side of Algorithms  Part 1,https://www.reddit.com/r/MachineLearning/comments/5ga26q/on_the_wrong_side_of_algorithms_part_1/,eternaldatalearner,1480779461,,0,1,False,default,,,,,
78,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,1,5ga7xt,medium.com,Intelligence in Mobile Applications.,https://www.reddit.com/r/MachineLearning/comments/5ga7xt/intelligence_in_mobile_applications/,sadmansamee,1480781546,,0,1,False,default,,,,,
79,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,2,5gagg3,self.MachineLearning,[discussion] Automatically discard bad photos?,https://www.reddit.com/r/MachineLearning/comments/5gagg3/discussion_automatically_discard_bad_photos/,youngChange,1480784501,[removed],6,1,False,default,,,,,
80,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,4,5gba6t,medium.com,[P] Trade signals on basket of stocks with LSTM,https://www.reddit.com/r/MachineLearning/comments/5gba6t/p_trade_signals_on_basket_of_stocks_with_lstm/,TalkingJellyFish,1480793882,,7,14,False,http://b.thumbs.redditmedia.com/iL8ICDYa_LyINtmDkUg9AHaauwL1lnnmuZKDazSnjZc.jpg,,,,,
81,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,5,5gbf6t,youtube.com,What CNNs look at when they look at nudity NYC ML Meetup [video],https://www.reddit.com/r/MachineLearning/comments/5gbf6t/what_cnns_look_at_when_they_look_at_nudity_nyc_ml/,xamdam,1480795482,,0,1,False,default,,,,,
82,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,5,5gbmju,self.MachineLearning,You can now download the first 12 chapters of Andrew Ng's Machine Learning Yearning book draft.,https://www.reddit.com/r/MachineLearning/comments/5gbmju/you_can_now_download_the_first_12_chapters_of/,[deleted],1480797901,[removed],0,1,False,default,,,,,
83,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,5,5gbn0r,gallery.mailchimp.com,"Andrew Ng's new book's draft ""Machine Learning Yearning""",https://www.reddit.com/r/MachineLearning/comments/5gbn0r/andrew_ngs_new_books_draft_machine_learning/,[deleted],1480798047,[deleted],0,1,False,default,,,,,
84,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,5,5gbnwl,self.MachineLearning,[N] Machine Learning Yearning book draft is out,https://www.reddit.com/r/MachineLearning/comments/5gbnwl/n_machine_learning_yearning_book_draft_is_out/,perceptron01,1480798332,"http://www.mlyearning.org/

I just received this:

""""""

Dear Friends, 

You can now download the first 12 chapters of the Machine Learning Yearning book draft. These chapters discuss how good machine learning strategy will help you, and give new guidelines for setting up your datasets and evaluation metric in the deep learning era. 

You can download the text here (5.3MB): [REMOVED]*

Thank you for your patience. I ended up making many revisions before feeling this was ready to send to you. Additional chapters will be coming in the next week.

I would love to hear from you. To ask questions, discuss the content, or give feedback, please post on Reddit at:
http://www.reddit.com/r/mlyearning

You can also tweet at me at https://twitter.com/AndrewYNg . I hope this book will help you build highly effective AI and machine learning systems. 

Andrew

""""""

 \* I removed the download link just in case he'd prefer people subscribe on the website to receive the download link.",24,116,False,self,,,,,
85,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,5,5gboi9,self.MachineLearning,[D] You can now download the first 12 chapters of the Machine Learning Yearning book draft by Andrew Ng.,https://www.reddit.com/r/MachineLearning/comments/5gboi9/d_you_can_now_download_the_first_12_chapters_of/,[deleted],1480798517,[deleted],0,1,False,default,,,,,
86,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,6,5gbpi1,self.MachineLearning,Are there any universally recognized certifications?,https://www.reddit.com/r/MachineLearning/comments/5gbpi1/are_there_any_universally_recognized/,[deleted],1480798853,[removed],0,1,False,default,,,,,
87,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,6,5gbqvz,self.MachineLearning,half precision performance Tesla P100,https://www.reddit.com/r/MachineLearning/comments/5gbqvz/half_precision_performance_tesla_p100/,hma02,1480799297,[removed],0,1,False,default,,,,,
88,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,6,5gbt35,youtube.com,[Machine Learning] Naive Bayes Classifier (1/2) - Bayes Theorem,https://www.reddit.com/r/MachineLearning/comments/5gbt35/machine_learning_naive_bayes_classifier_12_bayes/,minsuk_heo,1480800021,,0,1,False,default,,,,,
89,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,7,5gc1co,github.com,TorchCraft: a Library for Machine Learning Research on StarCraft: BroodWar,https://www.reddit.com/r/MachineLearning/comments/5gc1co/torchcraft_a_library_for_machine_learning/,arbitrary_gravitas,1480802696,,0,1,False,default,,,,,
90,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,7,5gc93t,github.com,[P] Reinforcement Learning basic reference implementation in JavaScript.,https://www.reddit.com/r/MachineLearning/comments/5gc93t/p_reinforcement_learning_basic_reference/,illegibleKey46,1480805299,,10,6,False,http://b.thumbs.redditmedia.com/RnfgzjdcMfEVkqNZyhDi-ie-v9Lg6no-QnfPWEMr9xU.jpg,,,,,
91,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,11,5gd7b7,youtube.com,[Machine Learning] Naive Bayes Classifier (2/2) - Python implementation,https://www.reddit.com/r/MachineLearning/comments/5gd7b7/machine_learning_naive_bayes_classifier_22_python/,minsuk_heo,1480817592,,0,1,False,default,,,,,
92,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,12,5gdje1,lukeoakdenrayner.wordpress.com,[D] Will standardised reporting in radiology hurt the development of medical AI systems?,https://www.reddit.com/r/MachineLearning/comments/5gdje1/d_will_standardised_reporting_in_radiology_hurt/,drlukeor,1480822355,,19,30,False,http://b.thumbs.redditmedia.com/lZl0CsS0UvHdwvIbs0ykawBxUU9Yb7wPrdRsRzz74yY.jpg,,,,,
93,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,12,5gdlns,arxiv.org,[R] Texture Enhancement via High-Resolution Style Transfer,https://www.reddit.com/r/MachineLearning/comments/5gdlns/r_texture_enhancement_via_highresolution_style/,madebyollin,1480823301,,3,11,False,default,,,,,
94,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,13,5gds4n,self.MachineLearning,Question about the feasibility of ML for an articulated robot?,https://www.reddit.com/r/MachineLearning/comments/5gds4n/question_about_the_feasibility_of_ml_for_an/,irascible,1480826001,[removed],2,1,False,default,,,,,
95,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,13,5gdtxo,github.com,[P] Seq2Seq translation with attention in Torch,https://www.reddit.com/r/MachineLearning/comments/5gdtxo/p_seq2seq_translation_with_attention_in_torch/,[deleted],1480826763,[deleted],0,1,False,default,,,,,
96,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,14,5gdwjc,adityathebe.com,NeuroEvolution : Flappy Bird | Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5gdwjc/neuroevolution_flappy_bird_machine_learning/,[deleted],1480827919,[deleted],0,1,False,default,,,,,
97,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,14,5ge3c3,github.com,Implementation of Using Fast Weights to Attend to the Recent Past [1610.06258],https://www.reddit.com/r/MachineLearning/comments/5ge3c3/implementation_of_using_fast_weights_to_attend_to/,[deleted],1480830911,[deleted],0,1,False,default,,,,,
98,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,15,5ge4x4,self.MachineLearning,Implementation of [1610.06258] Using Fast Weights to Attend to the Recent Past,https://www.reddit.com/r/MachineLearning/comments/5ge4x4/implementation_of_161006258_using_fast_weights_to/,[deleted],1480831620,[removed],0,1,False,default,,,,,
99,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,15,5ge6c8,self.MachineLearning,[P] Implementation of [1610.06258] Using Fast Weights to Attend to the Recent Past,https://www.reddit.com/r/MachineLearning/comments/5ge6c8/p_implementation_of_161006258_using_fast_weights/,[deleted],1480832303,[deleted],0,1,False,default,,,,,
100,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,15,5ge7n7,github.com,[P] Implementation of [1610.06258] Using Fast Weights to Attend to the Recent Past,https://www.reddit.com/r/MachineLearning/comments/5ge7n7/p_implementation_of_161006258_using_fast_weights/,gokumd,1480832932,,6,29,False,http://b.thumbs.redditmedia.com/KDR84bZS1eCWnu8jahbSrTrnX0Uw_lgQcBcduuR1Mzw.jpg,,,,,
101,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,17,5gei1z,github.com,Torch implementation of [1409.0473] Neural Machine Translation by Jointly Learning to Align and Translate,https://www.reddit.com/r/MachineLearning/comments/5gei1z/torch_implementation_of_14090473_neural_machine/,[deleted],1480838598,[deleted],0,1,False,default,,,,,
102,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,17,5gekcq,github.com,[P] Torch implementation of [1409.0473] Neural Machine Translation by Jointly Learning to Align and Translate,https://www.reddit.com/r/MachineLearning/comments/5gekcq/p_torch_implementation_of_14090473_neural_machine/,iamspro,1480840000,,1,32,False,http://b.thumbs.redditmedia.com/X3burR1R9En6_0P95wCEXLj4uNIF7rwu3srsklYUU1I.jpg,,,,,
103,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,17,5gem6o,ostagram.ru,"[D] Ostagram is a Russian website utilizing a convolutional neural network to copy the style and texture of a picture, to remake another one. Inputs are created by users and the results are often fascinating - I think this site deserves more attention.",https://www.reddit.com/r/MachineLearning/comments/5gem6o/d_ostagram_is_a_russian_website_utilizing_a/,KatamoriHUN,1480841147,,0,2,False,default,,,,,
104,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,18,5gensq,self.MachineLearning,questions regarding scikit-learn library for python,https://www.reddit.com/r/MachineLearning/comments/5gensq/questions_regarding_scikitlearn_library_for_python/,foo121,1480842180,[removed],0,1,False,default,,,,,
105,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,22,5gfisn,breloff.com,Learning without Backpropagation: zero-derivative activations,https://www.reddit.com/r/MachineLearning/comments/5gfisn/learning_without_backpropagation_zeroderivative/,Hshskwkk2,1480859964,,0,1,False,default,,,,,
106,MachineLearning,t5_2r3gv,2016-12-4,2016,12,4,23,5gfl3e,creativeai.net,MusicNet : Large new annotated (classical) music dataset for AI,https://www.reddit.com/r/MachineLearning/comments/5gfl3e/musicnet_large_new_annotated_classical_music/,xristos_forokolomvos,1480860927,,0,1,False,default,,,,,
107,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,0,5gfw2p,self.MachineLearning,So I trained a network to visualize images from nothing,https://www.reddit.com/r/MachineLearning/comments/5gfw2p/so_i_trained_a_network_to_visualize_images_from/,AwastYee,1480865348,[removed],0,1,False,default,,,,,
108,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,1,5gg3p0,github.com,Collection of papers (and their summaries) in Machine Learning and Data Mining,https://www.reddit.com/r/MachineLearning/comments/5gg3p0/collection_of_papers_and_their_summaries_in/,shagunsodhani,1480868078,,1,1,False,default,,,,,
109,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,1,5gg5bs,self.MachineLearning,Estimate most important dimensions in each cluster after performing k-means,https://www.reddit.com/r/MachineLearning/comments/5gg5bs/estimate_most_important_dimensions_in_each/,nko83,1480868624,[removed],0,1,False,default,,,,,
110,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,2,5gglci,research.jukedeck.com,"Audio synthesis at Jukedeck - ""...the first time a computer has written and produced a complete song, from start to finish, using purely machine learning-driven techniques. All we specified in advance was the genre and duration  everything else was generated completely by AI.""",https://www.reddit.com/r/MachineLearning/comments/5gglci/audio_synthesis_at_jukedeck_the_first_time_a/,whatllmyusernamebe,1480873699,,1,1,False,default,,,,,
111,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,4,5gh6qi,self.MachineLearning,How can i start learning machine learning and artificial intelligence. I want learning by doing. Not boring algebra lessons. I'm currently studying engineering and i have a good mathematical and coding background.,https://www.reddit.com/r/MachineLearning/comments/5gh6qi/how_can_i_start_learning_machine_learning_and/,zrock562,1480880072,[removed],0,1,False,default,,,,,
112,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,4,5gh993,miguelgfierro.com,How to Develop a Data Science Project using the Lean Startup Method,https://www.reddit.com/r/MachineLearning/comments/5gh993/how_to_develop_a_data_science_project_using_the/,hoaphumanoid,1480880806,,0,1,False,default,,,,,
113,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,6,5ghw8m,mostafa-samir.github.io,Machine Learning Theory - Part 3: Regularization and the Bias-variance Trade-off,https://www.reddit.com/r/MachineLearning/comments/5ghw8m/machine_learning_theory_part_3_regularization_and/,[deleted],1480887636,[deleted],0,1,False,default,,,,,
114,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,6,5ghwq6,mostafa-samir.github.io,[P] Machine Learning Theory - Part 3: Regularization and the Bias-variance Trade-off,https://www.reddit.com/r/MachineLearning/comments/5ghwq6/p_machine_learning_theory_part_3_regularization/,mostafa-samir,1480887802,,2,85,False,http://a.thumbs.redditmedia.com/7Hi_j6fXoAHZTwes68p_RUl-6jX0Q5kv08VFAAE2020.jpg,,,,,
115,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,7,5gi1kn,self.MachineLearning,How easy are CLUTO and WEKA to use for amateurs to MLE?,https://www.reddit.com/r/MachineLearning/comments/5gi1kn/how_easy_are_cluto_and_weka_to_use_for_amateurs/,ShadowCorn96,1480889218,[removed],0,1,False,default,,,,,
116,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,9,5giy1h,self.MachineLearning,Will NIPS 2016 have any sort of life stream or real-time update feed?,https://www.reddit.com/r/MachineLearning/comments/5giy1h/will_nips_2016_have_any_sort_of_life_stream_or/,adeshpande3,1480899530,[removed],0,1,False,default,,,,,
117,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,12,5gjnac,arxiv.org,[1612.00796] Overcoming catastrophic forgetting in neural networks [Deepmind],https://www.reddit.com/r/MachineLearning/comments/5gjnac/161200796_overcoming_catastrophic_forgetting_in/,RushAndAPush,1480908225,,18,25,False,default,,,,,
118,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,13,5gjud1,medium.com,Learn about Mechanical Turk &amp; Machine Learning!,https://www.reddit.com/r/MachineLearning/comments/5gjud1/learn_about_mechanical_turk_machine_learning/,johndavid5,1480910754,,0,1,False,default,,,,,
119,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,13,5gjw8s,github.com,[P] Prediction Template Learning,https://www.reddit.com/r/MachineLearning/comments/5gjw8s/p_prediction_template_learning/,[deleted],1480911441,[deleted],8,3,False,default,,,,,
120,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,13,5gjy21,papers.ai,Papers.ai: Discuss and share notes on NIPS 2016 proceedings.,https://www.reddit.com/r/MachineLearning/comments/5gjy21/papersai_discuss_and_share_notes_on_nips_2016/,[deleted],1480912101,[deleted],0,1,False,default,,,,,
121,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,13,5gjyu2,papers.ai,[P] Papers.ai: Discuss and share notes on NIPS 2016 proceedings,https://www.reddit.com/r/MachineLearning/comments/5gjyu2/p_papersai_discuss_and_share_notes_on_nips_2016/,hiteck,1480912418,,1,27,False,http://a.thumbs.redditmedia.com/EthhvpUuq8QZDpwCbxqPOY5PkIIvEmRoR-dsOfkJA04.jpg,,,,,
122,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,14,5gkb6r,i.redd.it,Very useful time series machine learning/data mining tool,https://www.reddit.com/r/MachineLearning/comments/5gkb6r/very_useful_time_series_machine_learningdata/,eamonnkeogh,1480917272,,1,1,False,default,,,,,
123,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,15,5gkhr6,waterjettingsystems.wordpress.com,Widespread use of Water Jetting Solutions,https://www.reddit.com/r/MachineLearning/comments/5gkhr6/widespread_use_of_water_jetting_solutions/,terra-tuae,1480920070,,0,1,False,default,,,,,
124,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,15,5gkisp,openai.com,[R]OpenAI Universe,https://www.reddit.com/r/MachineLearning/comments/5gkisp/ropenai_universe/,gambs,1480920550,,58,361,False,http://b.thumbs.redditmedia.com/TQuFsg23i2NdQhX8qMF7jC6fHwfJ4pm8p72l6h-xMTs.jpg,,,,,
125,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,16,5gkqpk,youtube.com,How to Make an Amazing Video Game Bot Easily,https://www.reddit.com/r/MachineLearning/comments/5gkqpk/how_to_make_an_amazing_video_game_bot_easily/,llSourcell,1480924299,,0,1,False,default,,,,,
126,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,17,5gkuqy,github.com,"TheanoLM 1.0 supports word lattice decoding, noise-contrastive estimation, and BlackOut",https://www.reddit.com/r/MachineLearning/comments/5gkuqy/theanolm_10_supports_word_lattice_decoding/,senarvi,1480926310,,1,1,False,default,,,,,
127,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,18,5gkzzx,deepmind.com,[N] Open-sourcing DeepMind Lab | DeepMind,https://www.reddit.com/r/MachineLearning/comments/5gkzzx/n_opensourcing_deepmind_lab_deepmind/,evc123,1480929159,,18,91,False,http://b.thumbs.redditmedia.com/o3FXwtAXxGc_rvw0EEtcyy59U0aw-tIpQx9YmFLPpYg.jpg,,,,,
128,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,19,5gl70p,self.MachineLearning,[D] How hard would it be to automatically generate code from ML papers?,https://www.reddit.com/r/MachineLearning/comments/5gl70p/d_how_hard_would_it_be_to_automatically_generate/,visarga,1480932853,"Say, we choose a framework, and then attempt to generate code in that framework that implements a paper, based off the PDF file. 

The algorithm should be able to figure out the architecture, loss function, data flow, and replicate the experiments in the paper. It's something nobody's tried so far, at least from my knowledge, but how hard would it be?

If this worked, it would open up the way to automatically generate many papers and try them out in parallel, perhaps applying RL to guide the search process.

Even a partial implementation would accelerate testing of research ideas.",16,1,False,self,,,,,
129,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,19,5gl9or,self.MachineLearning,Learning theoretical physics to extend my machine learning knowledge?,https://www.reddit.com/r/MachineLearning/comments/5gl9or/learning_theoretical_physics_to_extend_my_machine/,Hamchuntan,1480934252,[removed],0,1,False,default,,,,,
130,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,20,5glcsc,self.MachineLearning,Is there a place to discuss machine learning papers in depth?,https://www.reddit.com/r/MachineLearning/comments/5glcsc/is_there_a_place_to_discuss_machine_learning/,mind_juice,1480935836,[removed],0,1,False,default,,,,,
131,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,20,5glfy4,goarya.com,Algorithms Hire Better Than Humans,https://www.reddit.com/r/MachineLearning/comments/5glfy4/algorithms_hire_better_than_humans/,ranjanme,1480937383,,0,1,False,default,,,,,
132,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,22,5gm0ko,wired.com,[N] Uber aquihired Geometric Intelligence !?!?,https://www.reddit.com/r/MachineLearning/comments/5gm0ko/n_uber_aquihired_geometric_intelligence/,evc123,1480946305,,10,13,False,http://a.thumbs.redditmedia.com/g-B5m_zIvHCQTTfrCn4R3hPBOIxHhr6HRcTkgGMpyq8.jpg,,,,,
133,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,23,5gm649,mshen.me,What I learned from Standford ML (Andrew Ng) class (part 1 of 2),https://www.reddit.com/r/MachineLearning/comments/5gm649/what_i_learned_from_standford_ml_andrew_ng_class/,marshalization,1480948195,,0,1,False,default,,,,,
134,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,23,5gm9ow,self.MachineLearning,"NIPS 2016, drama at Ian Goodfellow's talk: I'm out of the loop",https://www.reddit.com/r/MachineLearning/comments/5gm9ow/nips_2016_drama_at_ian_goodfellows_talk_im_out_of/,Jollyhrothgar,1480949413,[removed],0,1,False,default,,,,,
135,MachineLearning,t5_2r3gv,2016-12-5,2016,12,5,23,5gm9s3,self.MachineLearning,Good resources for a (kinda) beginner?,https://www.reddit.com/r/MachineLearning/comments/5gm9s3/good_resources_for_a_kinda_beginner/,PineappleMechanic,1480949442,[removed],0,1,False,default,,,,,
136,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,0,5gmjni,youtu.be,"Open AI, ""Cruisin"" flash game playthrough",https://www.reddit.com/r/MachineLearning/comments/5gmjni/open_ai_cruisin_flash_game_playthrough/,andrew-lucker,1480952526,,0,1,False,default,,,,,
137,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,0,5gmkcr,notebooks.azure.com,Azure Jupyter Notebooks,https://www.reddit.com/r/MachineLearning/comments/5gmkcr/azure_jupyter_notebooks/,iamkeyur,1480952744,,0,1,False,default,,,,,
138,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,0,5gmkir,overcomingbias.com,This AI Boom Will Also Bust,https://www.reddit.com/r/MachineLearning/comments/5gmkir/this_ai_boom_will_also_bust/,iamkeyur,1480952800,,0,1,False,default,,,,,
139,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,1,5gmqpq,engadget.com,Amazon Go,https://www.reddit.com/r/MachineLearning/comments/5gmqpq/amazon_go/,[deleted],1480954644,[deleted],0,1,False,default,,,,,
140,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,1,5gmqzt,youtube.com,"Cyber Minute ""Machine Learning"". Put company data to work for your organization.",https://www.reddit.com/r/MachineLearning/comments/5gmqzt/cyber_minute_machine_learning_put_company_data_to/,shanemcgrawspm,1480954735,,0,1,False,default,,,,,
141,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,1,5gmvml,flyelephant.net,Data Science Tools Survey 2016,https://www.reddit.com/r/MachineLearning/comments/5gmvml/data_science_tools_survey_2016/,flyelephant,1480956066,,0,1,False,default,,,,,
142,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,2,5gn1mm,self.MachineLearning,Vectors,https://www.reddit.com/r/MachineLearning/comments/5gn1mm/vectors/,raslnkeeee,1480957751,[removed],0,1,False,default,,,,,
143,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,2,5gn56k,arxiv.org,[R] [1612.00147] Combining Deep Reinforcement Learning and Safety Based Control for Autonomous Driving,https://www.reddit.com/r/MachineLearning/comments/5gn56k/r_161200147_combining_deep_reinforcement_learning/,sybilckw,1480958727,,3,8,False,default,,,,,
144,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,2,5gn9t8,amazon.com,Amazon Go,https://www.reddit.com/r/MachineLearning/comments/5gn9t8/amazon_go/,[deleted],1480959951,[deleted],0,1,False,default,,,,,
145,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,2,5gn9y5,amazon.com,[N] Amazon Go,https://www.reddit.com/r/MachineLearning/comments/5gn9y5/n_amazon_go/,[deleted],1480959982,[deleted],0,5,False,default,,,,,
146,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,3,5gnddj,self.MachineLearning,List of things Schmidhuber said at NIPS2016,https://www.reddit.com/r/MachineLearning/comments/5gnddj/list_of_things_schmidhuber_said_at_nips2016/,Schmihoobered,1480960903,[removed],0,1,False,default,,,,,
147,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,3,5gnh9m,self.MachineLearning,Amazon Go - Just Walk Out Technology,https://www.reddit.com/r/MachineLearning/comments/5gnh9m/amazon_go_just_walk_out_technology/,[deleted],1480961959,[removed],0,1,False,default,,,,,
148,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,4,5gnqru,self.MachineLearning,"Has anyone used neural networks for SLAM - input to the network: current frame, output: position/orientation + points in a point cloud?",https://www.reddit.com/r/MachineLearning/comments/5gnqru/has_anyone_used_neural_networks_for_slam_input_to/,chris2point0,1480964578,[removed],0,1,False,default,,,,,
149,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,4,5gns0u,self.MachineLearning,Why cant we make language translation algorithms work better?,https://www.reddit.com/r/MachineLearning/comments/5gns0u/why_cant_we_make_language_translation_algorithms/,anivader1789,1480964903,[removed],0,1,False,default,,,,,
150,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,5,5go4ao,self.MachineLearning,Difference between word-embeddings and frequency counts as features.,https://www.reddit.com/r/MachineLearning/comments/5go4ao/difference_between_wordembeddings_and_frequency/,[deleted],1480968189,[removed],0,1,False,default,,,,,
151,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,5,5go4sa,twitter.com,[N] What's happening at NIPS 2016? (Jurgen Schmidhuber),https://www.reddit.com/r/MachineLearning/comments/5go4sa/n_whats_happening_at_nips_2016_jurgen_schmidhuber/,gokstudio,1480968317,,53,69,False,http://b.thumbs.redditmedia.com/iZpQHQqm_VZ7Lro400zjKYyf63yDchTHM6b61dmt87M.jpg,,,,,
152,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,5,5gobdo,self.MachineLearning,[D] Estimating aggregate data from individual predictions,https://www.reddit.com/r/MachineLearning/comments/5gobdo/d_estimating_aggregate_data_from_individual/,[deleted],1480970102,[deleted],8,1,False,default,,,,,
153,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,6,5goilv,youtube.com,Video Tutorial: Import a Keras Neural Net Model into Deeplearning4j,https://www.reddit.com/r/MachineLearning/comments/5goilv/video_tutorial_import_a_keras_neural_net_model/,vonnik,1480972070,,0,1,False,default,,,,,
154,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,6,5gomyt,self.MachineLearning,[D] Need some help in building a product that you may find useful,https://www.reddit.com/r/MachineLearning/comments/5gomyt/d_need_some_help_in_building_a_product_that_you/,S1r1usBl4ck,1480973292,"I am trying to build a tool that makes it easy to run your heavy workloads on the cloud. I would like to chat with some of you who may be using (or planning to use) computers on the cloud for running your tools or for training.

This is a personal pet project so I will not be able to offer anything ATM. However, when I release the product, I will gladly give you some compute credit for your help.",5,2,False,self,,,,,
155,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,6,5goopd,self.MachineLearning,does kaggle test data usually have the same distribution as the training data?,https://www.reddit.com/r/MachineLearning/comments/5goopd/does_kaggle_test_data_usually_have_the_same/,[deleted],1480973769,[removed],0,1,False,default,,,,,
156,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,6,5goosa,self.MachineLearning,Is machine learning overhyped? Is the bubble about the burst?,https://www.reddit.com/r/MachineLearning/comments/5goosa/is_machine_learning_overhyped_is_the_bubble_about/,[deleted],1480973790,[removed],0,1,False,default,,,,,
157,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,6,5goqhg,arxiv.org,"""'Influence Sketching': Finding Influential Samples In Large-Scale Regressions"", Wojnowicz et al 2016",https://www.reddit.com/r/MachineLearning/comments/5goqhg/influence_sketching_finding_influential_samples/,gwern,1480974258,,1,1,False,default,,,,,
158,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,7,5gp05q,self.MachineLearning,[D] Need some help in embedding temporal point process.,https://www.reddit.com/r/MachineLearning/comments/5gp05q/d_need_some_help_in_embedding_temporal_point/,breadFTD,1480976942,[removed],0,0,False,default,,,,,
159,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,8,5gp78w,openreview.net,(R) SampleRNN: An Unconditional End-to-End Neural Audio Generation Model,https://www.reddit.com/r/MachineLearning/comments/5gp78w/r_samplernn_an_unconditional_endtoend_neural/,dharma-1,1480978995,,15,29,False,default,,,,,
160,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,9,5gpo5t,self.MachineLearning,[D] Rot180 in CNNs (for beginners),https://www.reddit.com/r/MachineLearning/comments/5gpo5t/d_rot180_in_cnns_for_beginners/,Kiuhnm,1480984096,"# Why

I saw some complicated answers to the following question:

&gt; Why do I need to rotate the filter in the backprop for CNNs?

I'd like to show where the ""rotation"" comes from in a more intuitive way.

# How to ""rotate"" the filter

First of all, note that ""rotating"" a filter by 180 degrees is equivalent to reversing the order of its elements when in vectorized form:

     filter   rotated filter
    
      1234        gfed
      5678        cba9
      9abc        8765
      defg        4321
      
    123456789abcdefg --&gt; gfedcba987654321

# Gradient in MLPs
    
Let's start with normal MLPs (i.e. fully-connected nets).

If

    O = X W           (X = input; O = output; W = weights)

then

    __       __    
    \/_X L = \/_O L  W^T         (L = loss)

# Gradient in CNNs
    
Now let's consider a simple example where the rows of X are vectorized 3x3 images and W represents a convolution with a 2x2 filter.

Let's focus on a single image/row of X:

    image      filter
   
     123        ab       st
     456 (conv) cd    =  uv
     789                 
  
It's easy to see that in matrix form we have

        X          W                   O
   
    123456789   a 0 0 0     1a+2b+4c+5d  2a+3b+5c+6d ...
    2nd image   b a 0 0  =  conv. of second image
    3rd image   0 b 0 0     conv. of third image
    etc...      c 0 a 0     etc...
                d c b a
                0 d 0 b
                0 0 c 0
                0 0 d c
                0 0 0 d
    
For the gradient we need to transpose W:

    __
    \/_O L           W^T
       
     1234      a b 0 c d 0 0 0 0     1a 1b+2a 2b 1c+3a 1d+2c+3b+4a ...
     ....      0 a b 0 c d 0 0 0  =  .......
     ....      0 0 0 a b 0 c d 0     .......
    etc...     0 0 0 0 a b 0 c d     etc...
      
Do you see how the elements of the original filter (abcd) appear in reverse order (dcba)? It turns out that multiplying by W^T is equivalent to performing a convolution with the filter in reverse order (if seen as a vector) or rotated by 180 degrees (if seen like an ""image""):

     d   c
     b  1a  2       = 1a
        3   4       
                    
         d   c       
        1b  2a      = 1b+2a
        3   4
            
             d   c
        1   2b   a  = 2b
        3   4
            
            
     d  1c  2       = 1c+3a
     b  3a  4       
                    
                    
        1d  2c      = 1d+2c+3b+4a
        3b  4a
        
    And so on...
    
I hope this helps!",9,16,False,self,,,,,
161,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,9,5gpqbc,medium.com,Deep Learning Cheat Sheet,https://www.reddit.com/r/MachineLearning/comments/5gpqbc/deep_learning_cheat_sheet/,[deleted],1480984749,[deleted],0,1,False,default,,,,,
162,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,11,5gq78u,github.com,"[Project] Convert Sino-Korean words in Hangul to Chinese characters, using convolutional neural networks",https://www.reddit.com/r/MachineLearning/comments/5gq78u/project_convert_sinokorean_words_in_hangul_to/,longinglove,1480990232,,2,23,False,http://b.thumbs.redditmedia.com/ts981DlRYYRwmTt2F9p8StzGZm1psXN1d1JT_XoLzmE.jpg,,,,,
163,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,11,5gq7fp,dineshrai.herokuapp.com,Lessons in Deep Learning,https://www.reddit.com/r/MachineLearning/comments/5gq7fp/lessons_in_deep_learning/,[deleted],1480990294,[deleted],0,1,False,default,,,,,
164,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,11,5gq91v,self.MachineLearning,How much maths is required to conducts a research project in ML?,https://www.reddit.com/r/MachineLearning/comments/5gq91v/how_much_maths_is_required_to_conducts_a_research/,Buttezvant,1480990838,[removed],0,1,False,default,,,,,
165,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,11,5gqfis,self.MachineLearning,[D] IAN (Neural Photo Editing) vs iGAN. Which one is better?,https://www.reddit.com/r/MachineLearning/comments/5gqfis/d_ian_neural_photo_editing_vs_igan_which_one_is/,leehomyc,1480992943,[removed],0,1,False,default,,,,,
166,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,12,5gqgas,techiemd.com,[Project] Lessons in Deep Learning,https://www.reddit.com/r/MachineLearning/comments/5gqgas/project_lessons_in_deep_learning/,techiemd1,1480993210,,0,1,False,default,,,,,
167,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,12,5gqndj,self.MachineLearning,Is machine learning overhyped? Is the bubble about the burst?,https://www.reddit.com/r/MachineLearning/comments/5gqndj/is_machine_learning_overhyped_is_the_bubble_about/,[deleted],1480995603,[removed],0,1,False,default,,,,,
168,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,12,5gqoyy,youtube.com,My ch nhm thng 6 tc 2 trc i Loan gi r,https://www.reddit.com/r/MachineLearning/comments/5gqoyy/my_ch_nhm_thng_6_tc_2_trc_i_loan_gi_r/,tovan668888,1480996153,,0,1,False,default,,,,,
169,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,12,5gqq9f,self.MachineLearning,"I want to perform 'sliding window' recognition on a very long sequence using tensorflow &amp; RNN, is that possible?",https://www.reddit.com/r/MachineLearning/comments/5gqq9f/i_want_to_perform_sliding_window_recognition_on_a/,metorm,1480996591,[removed],1,1,False,default,,,,,
170,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,15,5grfv8,self.MachineLearning,What are your thoughts on the inner workings of Amazon's new Go store?,https://www.reddit.com/r/MachineLearning/comments/5grfv8/what_are_your_thoughts_on_the_inner_workings_of/,[deleted],1481006492,[removed],0,1,False,default,,,,,
171,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,17,5grrlv,youtube.com,The chemical platform of mixers and agitators,https://www.reddit.com/r/MachineLearning/comments/5grrlv/the_chemical_platform_of_mixers_and_agitators/,mixmachinery,1481012333,,1,1,False,default,,,,,
172,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,17,5grrva,youtube.com,What do you think about this?,https://www.reddit.com/r/MachineLearning/comments/5grrva/what_do_you_think_about_this/,[deleted],1481012467,[deleted],0,1,False,default,,,,,
173,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,17,5grt3m,github.com,"Keras implementation of SIGIR'15 paper titled - "" ""Learning to Rank Short Text Pairs with Convolutional Deep Neural Networks"".",https://www.reddit.com/r/MachineLearning/comments/5grt3m/keras_implementation_of_sigir15_paper_titled/,shash273,1481013147,,0,1,False,default,,,,,
174,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,17,5gru9d,youtube.com,The one of mixing blaze of rubber extruder mixer in JCT Machinery,https://www.reddit.com/r/MachineLearning/comments/5gru9d/the_one_of_mixing_blaze_of_rubber_extruder_mixer/,mixmachinery,1481013802,,1,1,False,default,,,,,
175,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,17,5gruem,self.MachineLearning,[D] Are there any more important paper on transfer learning after https://arxiv.org/abs/1411.1792 ?,https://www.reddit.com/r/MachineLearning/comments/5gruem/d_are_there_any_more_important_paper_on_transfer/,muktabh,1481013882,[removed],4,10,False,default,,,,,
176,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,18,5grwbz,mixmachinery.com,Who is the rubber chemical mix tanks?,https://www.reddit.com/r/MachineLearning/comments/5grwbz/who_is_the_rubber_chemical_mix_tanks/,mixmachinery,1481014923,,1,1,False,default,,,,,
177,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,18,5gs2nq,github.com,[R] Bayesian Optimization for Probabilistic Programs,https://www.reddit.com/r/MachineLearning/comments/5gs2nq/r_bayesian_optimization_for_probabilistic_programs/,prior_posterior,1481018366,,1,42,False,http://b.thumbs.redditmedia.com/E04LxaUnqKDrkFWjyzt80N6UeaVwRwdVboMjn22aYvc.jpg,,,,,
178,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,19,5gs3i6,youtu.be,Introducing Amazon Go and the worlds most advanced shopping technology,https://www.reddit.com/r/MachineLearning/comments/5gs3i6/introducing_amazon_go_and_the_worlds_most/,[deleted],1481018787,[deleted],0,1,False,default,,,,,
179,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,21,5gsney,self.MachineLearning,[R]-&gt;[C] Going from python to C,https://www.reddit.com/r/MachineLearning/comments/5gsney/rc_going_from_python_to_c/,muffa,1481028488,[removed],6,2,False,default,,,,,
180,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,21,5gsnk8,self.MachineLearning,[D] Any work on 3D dilated convolution?,https://www.reddit.com/r/MachineLearning/comments/5gsnk8/d_any_work_on_3d_dilated_convolution/,hapliniste,1481028546,[removed],2,6,False,default,,,,,
181,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,21,5gso7z,medium.com,Deep Learning Cheat Sheet,https://www.reddit.com/r/MachineLearning/comments/5gso7z/deep_learning_cheat_sheet/,[deleted],1481028810,[deleted],0,1,False,default,,,,,
182,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,21,5gsoa8,self.MachineLearning,C# Encog Recurrent NN example?,https://www.reddit.com/r/MachineLearning/comments/5gsoa8/c_encog_recurrent_nn_example/,Dark_Messiah,1481028838,[removed],0,1,False,default,,,,,
183,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,22,5gsrff,youtu.be,[N] Introducing Amazon Go and the worlds most advanced shopping technology,https://www.reddit.com/r/MachineLearning/comments/5gsrff/n_introducing_amazon_go_and_the_worlds_most/,hooba_stank_,1481029982,,6,3,False,default,,,,,
184,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,23,5gt0wm,github.com,[P] Fast and efficient LayerNorm GPU kernel for TensorFlow,https://www.reddit.com/r/MachineLearning/comments/5gt0wm/p_fast_and_efficient_layernorm_gpu_kernel_for/,Cmyc,1481033440,,8,27,False,http://b.thumbs.redditmedia.com/kI9WYACKzgkLwaiIJvd87-n7DU-BkMGi2cTXsCvQEmQ.jpg,,,,,
185,MachineLearning,t5_2r3gv,2016-12-6,2016,12,6,23,5gt4yf,research.googleblog.com,Deep Learning for Detection of Diabetic Eye Disease,https://www.reddit.com/r/MachineLearning/comments/5gt4yf/deep_learning_for_detection_of_diabetic_eye/,3eyedravens,1481034799,,1,1,False,default,,,,,
186,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,0,5gtafn,medium.com,Hillary emails: not just useful for winning elections... but also for building virtual assistants,https://www.reddit.com/r/MachineLearning/comments/5gtafn/hillary_emails_not_just_useful_for_winning/,[deleted],1481036596,[deleted],0,1,False,default,,,,,
187,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,0,5gtfv8,ai-first.world,What machines have learned to do by 2017,https://www.reddit.com/r/MachineLearning/comments/5gtfv8/what_machines_have_learned_to_do_by_2017/,ekozelkova,1481038203,,0,1,False,default,,,,,
188,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,1,5gtm74,self.MachineLearning,Practical data science: Building Minimum Viable Models,https://www.reddit.com/r/MachineLearning/comments/5gtm74/practical_data_science_building_minimum_viable/,ErnestoMislej,1481040060,[removed],0,1,False,default,,,,,
189,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,1,5gtoix,i.redd.it,"[P] Hillary emails: not just useful for winning elections, but also for building personal assistants",https://www.reddit.com/r/MachineLearning/comments/5gtoix/p_hillary_emails_not_just_useful_for_winning/,[deleted],1481040702,[deleted],0,1,False,default,,,,,
190,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,1,5gtqaz,icons8.com,What Google AI Cant Say About Your Doodles?,https://www.reddit.com/r/MachineLearning/comments/5gtqaz/what_google_ai_cant_say_about_your_doodles/,OddsUXs,1481041179,,0,2,False,default,,,,,
191,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,1,5gtqyh,medium.com,"[P] Hillary emails: not just useful for winning elections, but also building personal assistants",https://www.reddit.com/r/MachineLearning/comments/5gtqyh/p_hillary_emails_not_just_useful_for_winning/,savvopoulos,1481041349,,1,2,False,default,,,,,
192,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,1,5gtt8f,talend.com,Machine Learning 101 - An Intro to Decision Trees,https://www.reddit.com/r/MachineLearning/comments/5gtt8f/machine_learning_101_an_intro_to_decision_trees/,[deleted],1481041952,[deleted],0,1,False,default,,,,,
193,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,2,5guaqm,self.MachineLearning,[D] Meta: Can someone connect me with the owner @mxlearn account on twitter?,https://www.reddit.com/r/MachineLearning/comments/5guaqm/d_meta_can_someone_connect_me_with_the_owner/,olaf_nij,1481046806,[removed],1,1,False,default,,,,,
194,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,2,5guar1,github.com,ResNet training code for Caffe framework,https://www.reddit.com/r/MachineLearning/comments/5guar1/resnet_training_code_for_caffe_framework/,[deleted],1481046809,[deleted],1,1,False,default,,,,,
195,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,3,5guini,erogol.com,[R]Selfai: A Method for Undestanding Beauty in Selfies,https://www.reddit.com/r/MachineLearning/comments/5guini/rselfai_a_method_for_undestanding_beauty_in/,[deleted],1481048979,[deleted],0,1,False,default,,,,,
196,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,3,5guj8x,blog.insightdatascience.com,NIPS 2016  Day 1 Highlights,https://www.reddit.com/r/MachineLearning/comments/5guj8x/nips_2016_day_1_highlights/,jakek123,1481049131,,0,1,False,default,,,,,
197,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,3,5gujge,erogol.com,Selfai: A Method for Understanding Beauty in Selfies,https://www.reddit.com/r/MachineLearning/comments/5gujge/selfai_a_method_for_understanding_beauty_in/,[deleted],1481049197,[deleted],0,1,False,default,,,,,
198,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,3,5gujiz,erogol.com,[R] Selfai: A Method for Understanding Beauty in Selfies,https://www.reddit.com/r/MachineLearning/comments/5gujiz/r_selfai_a_method_for_understanding_beauty_in/,erogol,1481049216,,0,6,False,http://b.thumbs.redditmedia.com/1N7flO71aHHxC3sqOJRrlFiWX9LQ0NDJut3E3nhUYik.jpg,,,,,
199,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,3,5guk4y,github.com,[P] ResNet training code for Caffe framework,https://www.reddit.com/r/MachineLearning/comments/5guk4y/p_resnet_training_code_for_caffe_framework/,MarcelSimon,1481049381,,0,1,False,http://b.thumbs.redditmedia.com/knRT_OLqM6N5tnXacY-BTRZk-bz3jMdumHQ_OzBP5GQ.jpg,,,,,
200,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,3,5gulip,dzone.com,Anomaly Detection Using H2O Deep Learning - DZone Big Data,https://www.reddit.com/r/MachineLearning/comments/5gulip/anomaly_detection_using_h2o_deep_learning_dzone/,Sibanjan,1481049773,,0,1,False,default,,,,,
201,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,3,5gulw0,tryolabs.com,The major advancements in Deep Learning in 2016,https://www.reddit.com/r/MachineLearning/comments/5gulw0/the_major_advancements_in_deep_learning_in_2016/,[deleted],1481049869,[deleted],0,1,False,default,,,,,
202,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,3,5gumzs,tryolabs.com,[D] The major advancements in Deep Learning in 2016,https://www.reddit.com/r/MachineLearning/comments/5gumzs/d_the_major_advancements_in_deep_learning_in_2016/,[deleted],1481050175,[deleted],0,0,False,default,,,,,
203,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,3,5gup5q,self.MachineLearning,Import Data using NLTK for machine learning,https://www.reddit.com/r/MachineLearning/comments/5gup5q/import_data_using_nltk_for_machine_learning/,bob122222,1481050779,[removed],0,1,False,default,,,,,
204,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,4,5gut6n,learnopencv.com,Histogram of Oriented Gradients explained,https://www.reddit.com/r/MachineLearning/comments/5gut6n/histogram_of_oriented_gradients_explained/,spmallick,1481051863,,0,1,False,default,,,,,
205,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,4,5gutxy,self.MachineLearning,[D] The most relevant advancements in Deep Learning in 2016?,https://www.reddit.com/r/MachineLearning/comments/5gutxy/d_the_most_relevant_advancements_in_deep_learning/,thesameoldstories,1481052077,"[This post](https://tryolabs.com/blog/2016/12/06/major-advancements-deep-learning-2016/) states that the most relevant advancements in DL in 2016 are in the field of Unsupervised Learning (mostly because of GANs) and in NLP (JMT, DCN and GNMT). 

As there are certainly other great advancements, such as [WaveNet](https://deepmind.com/blog/wavenet-generative-model-raw-audio/) or Image Segmentation ([Inception-v4](https://arxiv.org/abs/1602.07261v2)), I wanted to know your thoughts on which are the most relevant advancements in terms of impact in the short term. 

Looking forward to discuss. ",20,49,False,self,,,,,
206,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,4,5guvl3,bloomberg.com,[N] Apple to Start Publishing AI Research,https://www.reddit.com/r/MachineLearning/comments/5guvl3/n_apple_to_start_publishing_ai_research/,nested_dreams,1481052523,,39,292,False,http://b.thumbs.redditmedia.com/MpKbthibEC02Pb2o4VagPacM_CsCemRBXfP7QLgn-xw.jpg,,,,,
207,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,5,5gv9g5,arnabgho.github.io,Message Passing Multi-Agent Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/5gv9g5/message_passing_multiagent_generative_adversarial/,arnabgho,1481056294,,0,1,False,default,,,,,
208,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,5,5gvfqa,hackernoon.com,Deep Learning Cheat Sheet,https://www.reddit.com/r/MachineLearning/comments/5gvfqa/deep_learning_cheat_sheet/,[deleted],1481057984,[deleted],0,1,False,default,,,,,
209,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,6,5gvkw7,distill.pub,[R] Four Experiments in Handwriting with a Neural Network,https://www.reddit.com/r/MachineLearning/comments/5gvkw7/r_four_experiments_in_handwriting_with_a_neural/,clbam8,1481059344,,4,41,False,http://b.thumbs.redditmedia.com/UpU9Xjv-iLbgx9Qn38bIie26A-TQKioHNQqFxYH5q7c.jpg,,,,,
210,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,7,5gvtfl,backchannel.com,"No, You Can't Use Machine Learning to ""Predict"" Criminals",https://www.reddit.com/r/MachineLearning/comments/5gvtfl/no_you_cant_use_machine_learning_to_predict/,mirandaBC,1481061674,,0,1,False,default,,,,,
211,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,9,5gwp3i,news.mit.edu,MIT neural network learns to speak using images,https://www.reddit.com/r/MachineLearning/comments/5gwp3i/mit_neural_network_learns_to_speak_using_images/,[deleted],1481070921,[deleted],0,1,False,default,,,,,
212,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,9,5gwr4j,news.mit.edu,[N] MIT neural network learns to speak using images,https://www.reddit.com/r/MachineLearning/comments/5gwr4j/n_mit_neural_network_learns_to_speak_using_images/,skoocda,1481071544,,6,9,False,http://b.thumbs.redditmedia.com/ToqsDm0WNfB18akZV-ErPH0DJJey8SHAtQYt6mE06qg.jpg,,,,,
213,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,15,5gyc9w,self.MachineLearning,What is wrong with my convolved images?,https://www.reddit.com/r/MachineLearning/comments/5gyc9w/what_is_wrong_with_my_convolved_images/,mrTang5544,1481091008,[removed],0,1,False,default,,,,,
214,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,15,5gyhgh,drive.google.com,[R][Slides]Yann LeCun's Posner Lecture at the NIPS,https://www.reddit.com/r/MachineLearning/comments/5gyhgh/rslidesyann_lecuns_posner_lecture_at_the_nips/,downtownslim,1481093285,,22,34,False,http://b.thumbs.redditmedia.com/TlTlPBe9xf24kxncMx4z9DBRauU7pXeVdpLRaXvYprE.jpg,,,,,
215,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,16,5gyl3z,self.MachineLearning,Flour Mill operation and maintenance,https://www.reddit.com/r/MachineLearning/comments/5gyl3z/flour_mill_operation_and_maintenance/,flourmillplant,1481094936,[removed],1,1,False,default,,,,,
216,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,16,5gyoos,self.MachineLearning,Can someone explain how the following will be multiplied?,https://www.reddit.com/r/MachineLearning/comments/5gyoos/can_someone_explain_how_the_following_will_be/,oneirlgg26,1481096668,[removed],0,1,False,default,,,,,
217,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,17,5gywgl,nytimes.com,Uber Bets on Artificial Intelligence With Acquisition and New Lab,https://www.reddit.com/r/MachineLearning/comments/5gywgl/uber_bets_on_artificial_intelligence_with/,fully_connected,1481100834,,0,1,False,default,,,,,
218,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,18,5gyyce,arxiv.org,[R] [1612.01340] We used Neural Networks to Detect Clickbaits: You won't believe what happened Next!,https://www.reddit.com/r/MachineLearning/comments/5gyyce/r_161201340_we_used_neural_networks_to_detect/,sybilckw,1481101871,,16,62,False,default,,,,,
219,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,18,5gyzqj,self.MachineLearning,[D] How do you keep track of your experiments?,https://www.reddit.com/r/MachineLearning/comments/5gyzqj/d_how_do_you_keep_track_of_your_experiments/,alantrrs,1481102629,I remember when I was doing research I had to write my own custom scripts that I manually ran after every git commit. I'm now working on an open source tool to automate this process and I'm wondering what workflow do other people use?,29,35,False,self,,,,,
220,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,20,5gzbv4,self.MachineLearning,The Art of Structuring Alerts: The Pain of False Positives,https://www.reddit.com/r/MachineLearning/comments/5gzbv4/the_art_of_structuring_alerts_the_pain_of_false/,Everything_Cyber,1481108822,[removed],0,1,False,default,,,,,
221,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,21,5gziay,cs.columbia.edu,[R] Slides for NIPS 2016 Tutorial on 'Variational Inference: Foundations and Modern Methods',https://www.reddit.com/r/MachineLearning/comments/5gziay/r_slides_for_nips_2016_tutorial_on_variational/,clbam8,1481112063,,6,74,False,default,,,,,
222,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,21,5gzolb,backchannel.com,"Alexa, Tell Me Where Youre Going Next",https://www.reddit.com/r/MachineLearning/comments/5gzolb/alexa_tell_me_where_youre_going_next/,deepaurorasky,1481114781,,0,1,False,default,,,,,
223,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,22,5gzz7f,arxiv.org,[R] [1612.01887] Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning,https://www.reddit.com/r/MachineLearning/comments/5gzz7f/r_161201887_knowing_when_to_look_adaptive/,evc123,1481118769,,2,6,False,default,,,,,
224,MachineLearning,t5_2r3gv,2016-12-7,2016,12,7,23,5h019b,self.MachineLearning,Is machine learning overhyped? Is the bubble about the burst?,https://www.reddit.com/r/MachineLearning/comments/5h019b/is_machine_learning_overhyped_is_the_bubble_about/,[deleted],1481119463,[removed],0,1,False,default,,,,,
225,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,0,5h0bxs,facebook.com,Marc Raibert from Boston Dynamics Demonstrating the Spot Mini Robot at NIPS,https://www.reddit.com/r/MachineLearning/comments/5h0bxs/marc_raibert_from_boston_dynamics_demonstrating/,SuprinsignlyHuman,1481122976,,0,1,False,default,,,,,
226,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,0,5h0dn0,research.googleblog.com,"""[P]"" Open sourcing the Embedding Projector: a tool for visualizing high dimensional data",https://www.reddit.com/r/MachineLearning/comments/5h0dn0/p_open_sourcing_the_embedding_projector_a_tool/,singularvalue,1481123460,,5,70,False,http://b.thumbs.redditmedia.com/xYfo8wNYQkyz-IOr2W5JrpHHdvSwPKKcuW7uJ4Eo7Mg.jpg,,,,,
227,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,0,5h0jgg,redd.it,"[cross-post] IamA Data Science Professor at the University of Michigan, lets discuss ethics surrounding privacy, data sharing and algorithmic decision-making. AMA!  /r/IAmA",https://www.reddit.com/r/MachineLearning/comments/5h0jgg/crosspost_iama_data_science_professor_at_the/,dataethics,1481125159,,0,1,False,default,,,,,
228,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,0,5h0mbh,self.MachineLearning,"Simple Questions Thread December 07, 2016",https://www.reddit.com/r/MachineLearning/comments/5h0mbh/simple_questions_thread_december_07_2016/,AutoModerator,1481125949,[removed],0,1,False,default,,,,,
229,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,1,5h0xe6,blog.insightdatascience.com,NIPS Day 2 Highlights with Reinforcement Learning Platforms,https://www.reddit.com/r/MachineLearning/comments/5h0xe6/nips_day_2_highlights_with_reinforcement_learning/,mwakanosya,1481128997,,0,1,False,default,,,,,
230,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,1,5h0z3k,hackernoon.com,Deep Learning Cheat Sheet,https://www.reddit.com/r/MachineLearning/comments/5h0z3k/deep_learning_cheat_sheet/,reddit0r1234,1481129474,,0,1,False,default,,,,,
231,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,2,5h119m,github.com,"[P] DeepMind Tensorflow implementation of ""Learning to learn by gradient descent by gradient descent""",https://www.reddit.com/r/MachineLearning/comments/5h119m/p_deepmind_tensorflow_implementation_of_learning/,DX89B,1481130066,,22,207,False,http://a.thumbs.redditmedia.com/l7h9kR0KUTBmP8QbyRNvzRbDfjEX18-6zUj5JS2Swv8.jpg,,,,,
232,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,2,5h1b3e,self.MachineLearning,"'A Deep Hierarchical Approach to Lifelong Learning in Minecraft' (AAAI-17), Tessler et al 2016",https://www.reddit.com/r/MachineLearning/comments/5h1b3e/a_deep_hierarchical_approach_to_lifelong_learning/,chentessler,1481132895,[removed],0,1,False,default,,,,,
233,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,3,5h1jxb,engineering.skymind.io,Why Aeron Matters for Deep Learning: Interview With Adam Gibson,https://www.reddit.com/r/MachineLearning/comments/5h1jxb/why_aeron_matters_for_deep_learning_interview/,vonnik,1481135226,,0,3,False,default,,,,,
234,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,3,5h1os5,self.MachineLearning,"Future of ""biologically-plausible"" research",https://www.reddit.com/r/MachineLearning/comments/5h1os5/future_of_biologicallyplausible_research/,[deleted],1481136555,[removed],0,1,False,default,,,,,
235,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,4,5h1ra9,self.MachineLearning,Looking for a data set of classified postie negative social media posts to train a classifier,https://www.reddit.com/r/MachineLearning/comments/5h1ra9/looking_for_a_data_set_of_classified_postie/,yanks09champs,1481137235,[removed],0,1,False,default,,,,,
236,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,4,5h1s32,self.MachineLearning,"[D] Future of ""biologically-plausible"" research?",https://www.reddit.com/r/MachineLearning/comments/5h1s32/d_future_of_biologicallyplausible_research/,harmonium1,1481137435,"The machine learning community in general is usually skeptical of techniques that are justified by vague references to ""biological plausibility"" rather than being empirically or theoretically justified.
However, there have been some pretty interesting techniques over the past few years that have their origins in neuroscience research, and the cross-pollination between deep learning and biology is likely to continue.
What are some techniques or models from neuroscience that you expect to pop up in machine learning research in the next few years?",10,20,False,self,,,,,
237,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,4,5h20fa,self.MachineLearning,Having trouble accessing Karpathy's computer vision/deep learning course. Anyone have a site-rip of his notes?,https://www.reddit.com/r/MachineLearning/comments/5h20fa/having_trouble_accessing_karpathys_computer/,[deleted],1481139682,[removed],0,1,False,default,,,,,
238,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,5,5h284n,github.com,"[P] Implementation of PFasterXML - SOTA for extreme, large scale, multi-label learning",https://www.reddit.com/r/MachineLearning/comments/5h284n/p_implementation_of_pfasterxml_sota_for_extreme/,Refefer,1481141766,,2,7,False,http://b.thumbs.redditmedia.com/kLcCe89p59zien2AyRgOcXC-DHdZ76DtCO_8_VskQMk.jpg,,,,,
239,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,5,5h29sf,youtube.com,Synthesize a photorealistic texture map of a complete 3D face model given a partial 2D view of a person - Facial Texture Inference Using Deep Neural Networks (ArXiv 2016) [1:42],https://www.reddit.com/r/MachineLearning/comments/5h29sf/synthesize_a_photorealistic_texture_map_of_a/,bboyjkang,1481142215,,0,1,False,default,,,,,
240,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,5,5h2ao5,self.MachineLearning,We should do a recap of the major contributions to Reinforcement Learning in 2016?,https://www.reddit.com/r/MachineLearning/comments/5h2ao5/we_should_do_a_recap_of_the_major_contributions/,sudeepraja,1481142464,[removed],0,1,False,default,,,,,
241,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,5,5h2dik,self.MachineLearning,[D] What deep learning papers should I implement to learn?,https://www.reddit.com/r/MachineLearning/comments/5h2dik/d_what_deep_learning_papers_should_i_implement_to/,derEitel,1481143212,"Andrew Ng has often stated that the best approach (that he has seen) to mastering DL is to start reading papers and then to implement them.

But the question remains where to start.

Now my goal is to curate a list of papers and their difficulty to implement them so that anyone can have a roadmap of papers to learn deep learning.

If you want to help, please rank the papers you think are worth implementing in the following categories: 
[Beginner] 
[Intermediate] 
[Advanced] 
[Pro]",19,76,False,self,,,,,
242,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,6,5h2l09,self.MachineLearning,[D] CNN object recognition: grayscale vs RGB,https://www.reddit.com/r/MachineLearning/comments/5h2l09/d_cnn_object_recognition_grayscale_vs_rgb/,mcwillie,1481145217,"This is a question / discussion seed (since definitive web jury is still out).

When training a CNN for object recognition, how does the image color change the CNN's accuracy?
I would assume that color plays a role in recognizing color-specific objects (oranges are usually not blue), but doesn't help much in telling a car and a bus apart. Somebody, however, pointed out that in grayscale some detail is lost e.g. edge information to an extent. Is there any proof of this?
Removing color processing would also potentially speed things up and any drawbacks could be supplemented with more training data.
I'd really love to hear any thoughts on this.",6,5,False,self,,,,,
243,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,6,5h2nmb,youtube.com,How to Make a Tensorflow Neural Network (LIVE),https://www.reddit.com/r/MachineLearning/comments/5h2nmb/how_to_make_a_tensorflow_neural_network_live/,llSourcell,1481145936,,0,1,False,default,,,,,
244,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,8,5h384k,self.MachineLearning,Machine learning on a laptop; does GPU matter?,https://www.reddit.com/r/MachineLearning/comments/5h384k/machine_learning_on_a_laptop_does_gpu_matter/,[deleted],1481151668,[removed],0,1,False,default,,,,,
245,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,8,5h3fl3,self.MachineLearning,Generative sequential models,https://www.reddit.com/r/MachineLearning/comments/5h3fl3/generative_sequential_models/,[deleted],1481153852,[removed],0,1,False,default,,,,,
246,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,8,5h3fqn,self.MachineLearning,[D] Generative sequential models using RNNs,https://www.reddit.com/r/MachineLearning/comments/5h3fqn/d_generative_sequential_models_using_rnns/,bronzestick,1481153905,"Is there any paper or resource that lays down the theory behind deep generative sequential models using RNNs? I am trying to understand what kind of models RNNs can represent and the theory behind it.
As far as I can see, there are a couple of papers that briefly lay down the theory (the handwriting generation paper by Graves 2013 and Variational RNN paper by Chung 2015). I am curious to know if there is any paper that goes into more detail.",7,13,False,self,,,,,
247,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,8,5h3hva,engadget.com,Facebook patent hints at an automated solution for fake news,https://www.reddit.com/r/MachineLearning/comments/5h3hva/facebook_patent_hints_at_an_automated_solution/,josourcing,1481154539,,1,1,False,default,,,,,
248,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,9,5h3vmq,self.MachineLearning,What is a word embedding neural network classifier that a beginner can create in about an hour?,https://www.reddit.com/r/MachineLearning/comments/5h3vmq/what_is_a_word_embedding_neural_network/,FuzziCat,1481158718,[removed],0,1,False,default,,,,,
249,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,10,5h444j,self.MachineLearning,Data Set for Music Genre Classification of Audio Signals Using Naive Bayes/ML,https://www.reddit.com/r/MachineLearning/comments/5h444j/data_set_for_music_genre_classification_of_audio/,sinuspane,1481161483,[removed],0,1,False,default,,,,,
250,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,10,5h44rm,general-ai-challenge.org,General AI Challenge,https://www.reddit.com/r/MachineLearning/comments/5h44rm/general_ai_challenge/,titusnicolae,1481161688,,0,1,False,default,,,,,
251,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,10,5h454i,self.MachineLearning,Neural Network is always giving same output. Please help!,https://www.reddit.com/r/MachineLearning/comments/5h454i/neural_network_is_always_giving_same_output/,[deleted],1481161808,[removed],0,1,False,default,,,,,
252,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,12,5h4ml4,self.MachineLearning,[Question] Question Answering Sytems,https://www.reddit.com/r/MachineLearning/comments/5h4ml4/question_question_answering_sytems/,__bee,1481167480,[removed],0,1,False,default,,,,,
253,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,13,5h4ue9,tryolabs.com,Major advancements in Deep Learning in 2016,https://www.reddit.com/r/MachineLearning/comments/5h4ue9/major_advancements_in_deep_learning_in_2016/,iamkeyur,1481170171,,0,1,False,default,,,,,
254,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,13,5h50w3,self.MachineLearning,First machine learning textbook to read for hopeful future phd student?,https://www.reddit.com/r/MachineLearning/comments/5h50w3/first_machine_learning_textbook_to_read_for/,newl_survivor,1481172552,[removed],0,1,False,default,,,,,
255,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,14,5h5boc,medium.com,Machine Learning Top 10 For The Past Month,https://www.reddit.com/r/MachineLearning/comments/5h5boc/machine_learning_top_10_for_the_past_month/,[deleted],1481176757,[deleted],0,1,False,default,,,,,
256,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,15,5h5ga6,youtube.com,2 6m Plywood Production Line-veneer peeling lathe of Paraguay,https://www.reddit.com/r/MachineLearning/comments/5h5ga6/2_6m_plywood_production_lineveneer_peeling_lathe/,woodworking-machine,1481178627,,0,1,False,default,,,,,
257,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,17,5h5uui,mixmachinery.com,Where can we find the suitable double paddle mixer manufacturers,https://www.reddit.com/r/MachineLearning/comments/5h5uui/where_can_we_find_the_suitable_double_paddle/,mixmachinery,1481185522,,1,1,False,default,,,,,
258,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,18,5h620k,self.MachineLearning,"[P] Newbie in Machine Learning, need a strategy",https://www.reddit.com/r/MachineLearning/comments/5h620k/p_newbie_in_machine_learning_need_a_strategy/,vadim878,1481189466,"Hi Reddit, 

I am new to machine learning. However, I've some experience with python.

My question would be kind of ""what should I do"", sorry for that.

Basically, I have a project, and I want to use machine learning (AI) there.

I can represent the idea like this (here is a picture https://i.stack.imgur.com/hobmZ.png):

The first blue box (Design) has up to 15 parameters which can be changed, and each parameter has up to 100 possible solutions (test cases), in total more than billion possible states for the design.

A second box Machine Learning (ML), algorithm proposes a parameter set for the design box, a checker (green box) checks if it meets the specifications.

Long story short, I am looking for the solution which helps select a proper parameters set from 10e12 possibilities... And in the end, it would learn from it, means for the next generations the selection process should take less time.  

Questions:

What do you recommend to understand/read/watch before to proceed to the problem?
What would you do if you have the same task as I? Which Libraries (Tensorflow,  scikit, etc.) would you use? (your strategy)

I am inspired by the FlappyLearning project, it's based on Neuroevolution ([Demo](http://xviniette.github.io/FlappyLearning/))  


Feedback, ideas, tips, hints are welcome!


",5,1,False,self,,,,,
259,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,19,5h6abf,self.MachineLearning,[R] Blurry pictures of NIPS posters,https://www.reddit.com/r/MachineLearning/comments/5h6abf/r_blurry_pictures_of_nips_posters/,thvasilo,1481193885,"Hello all, 

I'm currently attending NIPS and have been taking some pictures of posters I found interesting (and the heads in front of them...). I thought some people might be interested in taking a look so I uploaded some to this album:

http://imgur.com/a/F5Ekz

Feel free to add your own pictures in the comments and I'll try to update / extend this album. 

I also tweet about the conference at [@thvasilo](https://www.twitter.com/thvasilo)",15,19,False,self,,,,,
260,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,19,5h6aio,arxiv.org,PVANet: Lightweight Deep Neural Networks for Real-time Object Detection (NIPS 2106 EMDNN workshop),https://www.reddit.com/r/MachineLearning/comments/5h6aio/pvanet_lightweight_deep_neural_networks_for/,[deleted],1481193994,[deleted],1,1,False,default,,,,,
261,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,19,5h6bwm,arxiv.org,[R] PVANet: Lightweight Deep Neural Networks for Real-time Object Detection (NIPS2016 EMDNN workshop),https://www.reddit.com/r/MachineLearning/comments/5h6bwm/r_pvanet_lightweight_deep_neural_networks_for/,goodcarrot,1481194713,,2,21,False,default,,,,,
262,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,20,5h6h6g,colearn.xyz,[CoLearn] Find people to learn ML and AI with you,https://www.reddit.com/r/MachineLearning/comments/5h6h6g/colearn_find_people_to_learn_ml_and_ai_with_you/,colearn,1481197259,,0,1,False,default,,,,,
263,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,20,5h6jf4,self.MachineLearning,Training data for object localization problem,https://www.reddit.com/r/MachineLearning/comments/5h6jf4/training_data_for_object_localization_problem/,vivgandhi,1481198378,[removed],0,1,False,default,,,,,
264,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,21,5h6mtf,bayesianbiologist.com,Generative Adversarial Networks are the hotness at NIPS 2016,https://www.reddit.com/r/MachineLearning/comments/5h6mtf/generative_adversarial_networks_are_the_hotness/,likelihoodtprior,1481199916,,1,1,False,default,,,,,
265,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,21,5h6qst,self.MachineLearning,Am I stupid or is vector embedding starting of from shit premises already? Is online learning ever a thing?,https://www.reddit.com/r/MachineLearning/comments/5h6qst/am_i_stupid_or_is_vector_embedding_starting_of/,[deleted],1481201653,[removed],0,1,False,default,,,,,
266,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,22,5h6t9t,self.MachineLearning,[P] Text Classification - Many (~600) classes,https://www.reddit.com/r/MachineLearning/comments/5h6t9t/p_text_classification_many_600_classes/,eupatt,1481202610,"Hi. I am currently doing a text classification project, but i dont have much experience at this kind of problem, so I am mainly looking for guidance, advices and a couple specific doubts.
My approach so far has been:

* bag of words for count/frequency
* formated words (removed a few special language characters, all lower, ...)
* engineered few features (last/first word to appear/...)
* xgb classifier

Some of my specific doubts:

* How many examples per class should I have for an okay accuracy? (was hoping 80% or higher)

* Is there an ideal (or more suitable) approach for this problem? (different ML methods, etc..)

texts are about 1 page long. any advice or reference is very welcome, ty!",11,7,False,self,,,,,
267,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,22,5h6y5q,self.MachineLearning,[D] Am I stupid or is vector embedding starting of from shit premises already? Is online learning ever a thing? If not why not?,https://www.reddit.com/r/MachineLearning/comments/5h6y5q/d_am_i_stupid_or_is_vector_embedding_starting_of/,princeidiot,1481204376,"I'm just starting to learn NLP (electrical engineer by training, i come from this via control/search/classification) and I must be misunderstanding things. Do all current methods always start by building an index in a dictionary, then do embedding etc on top of that?

I ask because that seems utterly stupid to me if you want to ever have online learning(though maybe I'm too influenced form the reinforcement learning I'm used to).

Whenever there is a new word, you potentially have to retrain your whole model right? Because either you are using something like inverted frequency (which means you have to recompute the freq and then retrain) or you just add the new word with a new index...which wasn't included in the training, so you'll have to redo that?

I've heard something of character based RNN-LSTM encoders that do the vector projection based on the input data...but I haven't found any papers based on this. It seems like a good tradeoff, having a fixed size input large enough to catch 99.9% of words, add a beginning_of_word,end_of_word and after_word token and then let the network learn representations that get fed into the higher layers.

But I'm surely misunderstanding something?(I genuinely mean that. Whenever I am this confused I've usually missed at least one big point)
",9,2,False,self,,,,,
268,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,22,5h6yvl,people.idsia.ch,[D] Recurrent Neural Networks and Other Machines that Learn Algorithms,https://www.reddit.com/r/MachineLearning/comments/5h6yvl/d_recurrent_neural_networks_and_other_machines/,evc123,1481204629,,15,72,False,http://b.thumbs.redditmedia.com/u8U0LYMAQeqVmaXkviIBXxKn5C4Ao8SNRjHQDpMvF4M.jpg,,,,,
269,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,23,5h71s3,github.com,"[D] DenseNets look very promising on ImageNet, but no one published any results. Why is that?",https://www.reddit.com/r/MachineLearning/comments/5h71s3/d_densenets_look_very_promising_on_imagenet_but/,[deleted],1481205663,,21,21,False,http://b.thumbs.redditmedia.com/ObJrceRL_v9pFHzW81Xvn5sk_qkhtGi9AEqkEJC18NA.jpg,,,,,
270,MachineLearning,t5_2r3gv,2016-12-8,2016,12,8,23,5h7byj,self.MachineLearning,[D] Interfacing Tensorflow with Java/Scala,https://www.reddit.com/r/MachineLearning/comments/5h7byj/d_interfacing_tensorflow_with_javascala/,michal_sustr,1481209093,"Hi, I'm looking for advice. I am about to join diploma thesis done by my friend. He creates an AI bot to play StarCraft1 via BWAPI in Java.

We want to use specifically SC1, because it is much simpler than SC2 (which is not released yet anyway). SC1 allows much higher FPS with graphics-off playing (manageable more than 1000FPS, crucial for RL).

His work is about learning to play from gameplays using MDPs, and I'd like to join his project by supplying a smaller part done by deep RL, which could be plugged in later via clever dependency injection :)

Since he is using Java it creates a constraint in my choice of programming languages. Most interesting ML libraries are written in Python, specifically Tensorflow, and I am worried about throughput of the system, if we try to interface SC1 &lt;-&gt; C++ BWAPI &lt;-&gt; Java (my friend) &lt;-&gt; Python (scientific code, RL implementation) &lt;-&gt; C++ (tensorflow implementation) :-)

Since there is going to be a fair amount of engineering, I want to use languages I feel comfortable with - {Java, Scala, Python}. I'm not so good in {C, C++, Lua}. Since he is doing main work in Java and I don't know Lua/Torch, TorchStarcraft is out of question (and probably it's slower than Java &lt;-&gt; C++).

Do you have some advice about what constraints I should relax, or some other idea I could do in this situation? ",5,3,False,self,,,,,
271,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,0,5h7kux,recode.net,In five years machine learning will be part of every doctors job,https://www.reddit.com/r/MachineLearning/comments/5h7kux/in_five_years_machine_learning_will_be_part_of/,jonfla,1481211772,,0,1,False,default,,,,,
272,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,0,5h7m1u,self.MachineLearning,Manufacturing and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5h7m1u/manufacturing_and_machine_learning/,grantthegreat,1481212129,[removed],0,1,False,default,,,,,
273,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,0,5h7n91,surpriselib.com,"[P] Surprise, a simple recommender system library for Python",https://www.reddit.com/r/MachineLearning/comments/5h7n91/p_surprise_a_simple_recommender_system_library/,Niourf,1481212494,,9,18,False,default,,,,,
274,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,1,5h7pxh,pocketcluster.wordpress.com,"BigData &amp; ML Library and Framework Weekly Roundup  Dec. 8, 2016",https://www.reddit.com/r/MachineLearning/comments/5h7pxh/bigdata_ml_library_and_framework_weekly_roundup/,stkim1,1481213241,,0,1,False,default,,,,,
275,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,2,5h81e5,bonaccorso.eu,Neural artistic style transfer experiments with Keras,https://www.reddit.com/r/MachineLearning/comments/5h81e5/neural_artistic_style_transfer_experiments_with/,giuseppe_bonaccorso,1481216519,,0,1,False,default,,,,,
276,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,2,5h857z,github.com,Interactive Spatial Transformer Network Layer Demo with Lasagne in a Jupyter notebook!,https://www.reddit.com/r/MachineLearning/comments/5h857z/interactive_spatial_transformer_network_layer/,ieee8023,1481217544,,0,1,False,default,,,,,
277,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,2,5h860z,arxiv.org,"[R] Spatially Adaptive Computation Time for Residual Networks ""correlate surprisingly well with human eye fixation positions""",https://www.reddit.com/r/MachineLearning/comments/5h860z/r_spatially_adaptive_computation_time_for/,downtownslim,1481217750,,8,30,False,default,,,,,
278,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,4,5h8x6h,self.MachineLearning,[Question] Question Answering Sytems,https://www.reddit.com/r/MachineLearning/comments/5h8x6h/question_question_answering_sytems/,[deleted],1481225168,[removed],0,1,False,default,,,,,
279,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,4,5h904j,github.com,[P] DeepMind Lab now released on Github!,https://www.reddit.com/r/MachineLearning/comments/5h904j/p_deepmind_lab_now_released_on_github/,BafflesSean,1481225985,,8,198,False,http://b.thumbs.redditmedia.com/lOpgme-XgE_vIWLzbbg-3LD0rYxXIr048ixv-PipXeo.jpg,,,,,
280,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,5,5h9bdl,dtic.upf.edu,[P] A Singing Synthesizer Based on PixelCNN,https://www.reddit.com/r/MachineLearning/comments/5h9bdl/p_a_singing_synthesizer_based_on_pixelcnn/,disentangle,1481229023,,9,28,False,http://b.thumbs.redditmedia.com/roKMCKt33Tsde8GUdsHAy0vwgyMaH1gSHEYc9H2LX7k.jpg,,,,,
281,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,5,5h9cl0,cnn.com,testing,https://www.reddit.com/r/MachineLearning/comments/5h9cl0/testing/,[deleted],1481229338,[deleted],0,1,False,default,,,,,
282,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,6,5h9six,technologyreview.com,"AI winter isnt coming, says Baidus Andrew Ng",https://www.reddit.com/r/MachineLearning/comments/5h9six/ai_winter_isnt_coming_says_baidus_andrew_ng/,dendisuhubdy,1481233764,,0,1,False,default,,,,,
283,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,7,5ha08v,arxiv.org,"[R] Uncertainty Estimation using Deep Ensembles ""an alternative to Bayesian neural networks""",https://www.reddit.com/r/MachineLearning/comments/5ha08v/r_uncertainty_estimation_using_deep_ensembles_an/,[deleted],1481235968,[deleted],0,1,False,default,,,,,
284,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,7,5ha18g,arxiv.org,"[R] Uncertainty Estimation using Deep Ensembles, ""an alternative to Bayesian""",https://www.reddit.com/r/MachineLearning/comments/5ha18g/r_uncertainty_estimation_using_deep_ensembles_an/,downtownslim,1481236261,,3,14,False,default,,,,,
285,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,7,5ha3ci,meetup.com,[N] Discussion of InfoGAN in Boston Thursday Dec 15 7 p.m.,https://www.reddit.com/r/MachineLearning/comments/5ha3ci/n_discussion_of_infogan_in_boston_thursday_dec_15/,AlexCoventry,1481236896,,0,1,False,default,,,,,
286,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,8,5haf0h,github.com,"[P] [C++] Canalysis - a machine learning, crime analysis framework.",https://www.reddit.com/r/MachineLearning/comments/5haf0h/p_c_canalysis_a_machine_learning_crime_analysis/,[deleted],1481240394,[deleted],0,0,False,default,,,,,
287,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,9,5ham8b,github.com,Implement Aggregated Residual Transformations for Deep Neural Networks (ResNeXt) in MXNet,https://www.reddit.com/r/MachineLearning/comments/5ham8b/implement_aggregated_residual_transformations_for/,[deleted],1481242667,[deleted],0,1,False,default,,,,,
288,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,9,5haml9,github.com,[P] Implementation of Aggregated Residual Transformations for Deep Neural Networks (ResNeXt) in MXNet,https://www.reddit.com/r/MachineLearning/comments/5haml9/p_implementation_of_aggregated_residual/,phunter_lau,1481242781,,3,10,False,http://b.thumbs.redditmedia.com/C2P46VMi3JS2mQiCMrjCJWCx6_3tCGTD07p3HXPQjtY.jpg,,,,,
289,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,9,5hanfp,self.MachineLearning,[D] Model complexity - is there a way (or heuristic) to calculate it?,https://www.reddit.com/r/MachineLearning/comments/5hanfp/d_model_complexity_is_there_a_way_or_heuristic_to/,Icko_,1481243048,"The more data we have the more complicated model we'll be able to build without overfitting. With constant amount of data, there should exist an optimal level of model complexity. By complexity I mean some function of number of parameters, regularization applied, and architecture (idk if architecture is the right word). So a regression over 1000 features is more complicated model than a regression over 100, and *probably* is more complicated than a MLP with (10, 5, 5) layer sizes. 

Is there any work done on this? More specifically, I was thinking that it should be possible to somehow use information theory to quantify the amount of information contained in a specific neural network architecture. ",8,12,False,self,,,,,
290,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,9,5harqg,nervanasys.com,[P] End-to-end speech recognition - Deep Speech 2 implementation with Nervana neon,https://www.reddit.com/r/MachineLearning/comments/5harqg/p_endtoend_speech_recognition_deep_speech_2/,jennifermyers,1481244452,,1,19,False,http://b.thumbs.redditmedia.com/5k9-NqZDXnICa-jWC7thKbwwO3W4T-rhJS77HrY3aFU.jpg,,,,,
291,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,10,5hawjn,youtube.com,1 4 Automatic Knife Grinding Machine,https://www.reddit.com/r/MachineLearning/comments/5hawjn/1_4_automatic_knife_grinding_machine/,woodworking-machine,1481246074,,0,1,False,default,,,,,
292,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,13,5hbrni,self.MachineLearning,Skipping frequentist/classical statistics while self-studying ML?,https://www.reddit.com/r/MachineLearning/comments/5hbrni/skipping_frequentistclassical_statistics_while/,super_brain,1481256991,[removed],0,1,False,default,,,,,
293,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,14,5hc42t,self.MachineLearning,Problem with machine,https://www.reddit.com/r/MachineLearning/comments/5hc42t/problem_with_machine/,vladimladi,1481261810,[removed],0,1,False,default,,,,,
294,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,15,5hceic,spectrum.ieee.org,Deep Learning Reinvents the Hearing Aid,https://www.reddit.com/r/MachineLearning/comments/5hceic/deep_learning_reinvents_the_hearing_aid/,momentumkid,1481266449,,0,1,False,default,,,,,
295,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,16,5hcld3,muoro.io,Top Algorithms for Data Scientist,https://www.reddit.com/r/MachineLearning/comments/5hcld3/top_algorithms_for_data_scientist/,Yovyom,1481269755,,0,1,False,default,,,,,
296,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,17,5hcony,self.MachineLearning,Q deep learning not working,https://www.reddit.com/r/MachineLearning/comments/5hcony/q_deep_learning_not_working/,Dark_Messiah,1481271438,[removed],0,1,False,default,,,,,
297,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,18,5hcvec,self.MachineLearning,[D] Music Classification using RNN?,https://www.reddit.com/r/MachineLearning/comments/5hcvec/d_music_classification_using_rnn/,AntixK,1481275221,"I am a newbie to ML. I have this pet project of classifying music data. I prepared the data myself from my music collection. I have 3 classes. Basically, all the music is sampled at 44100Hz and split into wav files, each 5 seconds long. For training I have 500 such wav files, for testing I have 200 wav files. I have created a csv file composed of the audio data and the label. (to import easily across various platforms)
I am planning to use LTSM-RNN for learning to classify the data. I am facing the following problems -
1) The data is too huge and it takes forever to import in tensorflow. Have I prepared the data in a good way? Is there a better way? Kindly educate me. 

2) How do I go about implementing this in Tensorflow of TFLearn? How do I set the parameters for LTSM? 

3) Should I preprocess the audio? like taking the STFT? or just learn with the raw data?
Thank you",10,7,False,self,,,,,
298,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,19,5hd1vf,self.MachineLearning,Is there new information about topic X or are people still just copy pasting?,https://www.reddit.com/r/MachineLearning/comments/5hd1vf/is_there_new_information_about_topic_x_or_are/,Romek_Buch,1481278681,[removed],0,1,False,default,,,,,
299,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,20,5hd74e,self.MachineLearning,Question Answering Systems,https://www.reddit.com/r/MachineLearning/comments/5hd74e/question_answering_systems/,__bee,1481281469,[removed],0,1,False,default,,,,,
300,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,20,5hd819,github.com,Word Embedding based on Autoencoder implementation in tensorflow.,https://www.reddit.com/r/MachineLearning/comments/5hd819/word_embedding_based_on_autoencoder/,shash273,1481281911,,0,1,False,default,,,,,
301,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,20,5hdcw6,bonaccorso.eu,BBC News classification algorithm comparison,https://www.reddit.com/r/MachineLearning/comments/5hdcw6/bbc_news_classification_algorithm_comparison/,giuseppe_bonaccorso,1481284372,,0,1,False,default,,,,,
302,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,21,5hdk9n,phys.csail.mit.edu,Intuitive Physics workshop at NIPS,https://www.reddit.com/r/MachineLearning/comments/5hdk9n/intuitive_physics_workshop_at_nips/,[deleted],1481287712,[deleted],0,1,False,default,,,,,
303,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,21,5hdkyo,phys.csail.mit.edu,[D] Intuitive Physics Workshop at NIPS 2016,https://www.reddit.com/r/MachineLearning/comments/5hdkyo/d_intuitive_physics_workshop_at_nips_2016/,evc123,1481287997,,5,20,False,http://b.thumbs.redditmedia.com/UFQ8teMG4YnMyiSb0UcyV-tw-eBGl8zO3oJSZuRatTQ.jpg,,,,,
304,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,22,5hdofr,paper.dropbox.com,"[D] NIPS 2016 Symposium on People and machines: Public views on machine learning, and what this means for machine learning researchers. (Notes and panel discussion)",https://www.reddit.com/r/MachineLearning/comments/5hdofr/d_nips_2016_symposium_on_people_and_machines/,gcr,1481289295,,0,4,False,default,,,,,
305,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,23,5he046,humanizing.tech,Biologic Intelligence is NOT Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/5he046/biologic_intelligence_is_not_artificial/,seanmeverett,1481293484,,0,1,False,default,,,,,
306,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,23,5he11u,ruslangermanov.com,Some Interesting Articles on Machine Learning.,https://www.reddit.com/r/MachineLearning/comments/5he11u/some_interesting_articles_on_machine_learning/,[deleted],1481293836,[deleted],0,1,False,default,,,,,
307,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,23,5he3zs,self.MachineLearning,Question about Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5he3zs/question_about_machine_learning/,[deleted],1481294856,[removed],0,1,False,default,,,,,
308,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,23,5he63i,blog.insightdatascience.com,"NIPS 2016  Day 3 Highlights: Robots, Autonomous Vehicles, and more!",https://www.reddit.com/r/MachineLearning/comments/5he63i/nips_2016_day_3_highlights_robots_autonomous/,mwakanosya,1481295521,,0,1,False,default,,,,,
309,MachineLearning,t5_2r3gv,2016-12-9,2016,12,9,23,5he67i,arxiv.org,[R] [1301.2820] Clustering Learning for Robotic Vision. Trains really fast.,https://www.reddit.com/r/MachineLearning/comments/5he67i/r_13012820_clustering_learning_for_robotic_vision/,muktabh,1481295559,,6,7,False,default,,,,,
310,MachineLearning,t5_2r3gv,2016-12-10,2016,12,10,0,5heb2s,imgur.com,Why wont WEKA read in this as a CSV file,https://www.reddit.com/r/MachineLearning/comments/5heb2s/why_wont_weka_read_in_this_as_a_csv_file/,barryq93,1481297022,,0,1,False,default,,,,,
311,MachineLearning,t5_2r3gv,2016-12-10,2016,12,10,0,5heeh7,technologyreview.com,[N] Andrew Ng: AI Winter Isnt Coming,https://www.reddit.com/r/MachineLearning/comments/5heeh7/n_andrew_ng_ai_winter_isnt_coming/,downtownslim,1481298047,,183,231,False,http://b.thumbs.redditmedia.com/m7XJyusnX04zXzjlFFgOw6_PaMEX_DYAcmC1cq-pgmw.jpg,,,,,
312,MachineLearning,t5_2r3gv,2016-12-10,2016,12,10,1,5hemh7,github.com,"Starter from ""How to Train a GAN?"" at NIPS2016",https://www.reddit.com/r/MachineLearning/comments/5hemh7/starter_from_how_to_train_a_gan_at_nips2016/,shagunsodhani,1481300340,,0,2,False,default,,,,,
313,MachineLearning,t5_2r3gv,2016-12-10,2016,12,10,1,5heps2,self.MachineLearning,Replace image mean by batch normalization layer,https://www.reddit.com/r/MachineLearning/comments/5heps2/replace_image_mean_by_batch_normalization_layer/,[deleted],1481301259,[removed],0,1,False,default,,,,,
314,MachineLearning,t5_2r3gv,2016-12-10,2016,12,10,1,5hesvm,self.MachineLearning,[D] InfoGAN vs VAE-GAN,https://www.reddit.com/r/MachineLearning/comments/5hesvm/d_infogan_vs_vaegan/,AI_entrepreneur,1481302135,"In terms of performance what is the difference between an InfoGAN with a particular latent structure vs a VAE-GAN with the same latent structure? Presumably the InfoGAN can guarantee that all latent variables will be used while VAE-GAN cannot, but is there anything else?",2,9,False,self,,,,,
315,MachineLearning,t5_2r3gv,2016-12-10,2016,12,10,2,5hey8o,self.MachineLearning,How to validate if you have implemented Backpropagation correctly?,https://www.reddit.com/r/MachineLearning/comments/5hey8o/how_to_validate_if_you_have_implemented/,[deleted],1481303610,[removed],0,1,False,default,,,,,
316,MachineLearning,t5_2r3gv,2016-12-10,2016,12,10,2,5hf1tr,self.MachineLearning,ML related podcasts,https://www.reddit.com/r/MachineLearning/comments/5hf1tr/ml_related_podcasts/,btlk48,1481304599,[removed],0,1,False,default,,,,,
317,MachineLearning,t5_2r3gv,2016-12-10,2016,12,10,2,5hf3ku,blog.sigopt.com,[N] SigOpt for ML: Using Bayesian Optimization for Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/5hf3ku/n_sigopt_for_ml_using_bayesian_optimization_for/,beeftug,1481305071,,0,1,False,default,,,,,
318,MachineLearning,t5_2r3gv,2016-12-10,2016,12,10,3,5hfcg3,self.MachineLearning,[D] Replace image mean by batch normalization layer,https://www.reddit.com/r/MachineLearning/comments/5hfcg3/d_replace_image_mean_by_batch_normalization_layer/,MarcelSimon,1481307545,"Is there a specific reason why in all current CNN models, the image mean is still computed manually? Batch normalization on the input image data can be used instead. I experimented a bit and obtained pretty good results [1].

Advantages:

- Automatic calculation of image mean

- During fine-tuning the mean is updated according to the new dataset

- Image mean subtraction is a special case of batch normalization

What do you think? I would be happy to get any thoughts on this topic!

References

[1] arxiv.org/abs/1612.01452
",7,6,False,self,,,,,
319,MachineLearning,t5_2r3gv,2016-12-10,2016,12,10,3,5hfghc,invrea.com,"Invrea Blog: Data, Models, and AI",https://www.reddit.com/r/MachineLearning/comments/5hfghc/invrea_blog_data_models_and_ai/,yura_invrea,1481308691,,0,1,False,default,,,,,
320,MachineLearning,t5_2r3gv,2016-12-10,2016,12,10,4,5hfmh9,gab41.lab41.org,Make a Deep Learning Dataset in 24 hours.,https://www.reddit.com/r/MachineLearning/comments/5hfmh9/make_a_deep_learning_dataset_in_24_hours/,datasutra,1481310351,,0,1,False,default,,,,,
321,MachineLearning,t5_2r3gv,2016-12-10,2016,12,10,5,5hg4fc,cdn.rawgit.com,Implemented Reinforced (backpropagated) Pong Game today,https://www.reddit.com/r/MachineLearning/comments/5hg4fc/implemented_reinforced_backpropagated_pong_game/,[deleted],1481315507,[deleted],0,1,False,default,,,,,
322,MachineLearning,t5_2r3gv,2016-12-10,2016,12,10,5,5hg7m5,elitedatascience.com,Keras Tutorial: The Ultimate Beginner's Guide to Deep Learning in Python,https://www.reddit.com/r/MachineLearning/comments/5hg7m5/keras_tutorial_the_ultimate_beginners_guide_to/,[deleted],1481316465,[deleted],0,1,False,default,,,,,
323,MachineLearning,t5_2r3gv,2016-12-10,2016,12,10,5,5hg9p1,elitedatascience.com,[P] Keras Tutorial: The Ultimate Beginner's Guide to Deep Learning in Python,https://www.reddit.com/r/MachineLearning/comments/5hg9p1/p_keras_tutorial_the_ultimate_beginners_guide_to/,[deleted],1481317090,[deleted],3,1,False,default,,,,,
324,MachineLearning,t5_2r3gv,2016-12-10,2016,12,10,6,5hgekk,self.MachineLearning,[D] Looking for advice on a binary classification project,https://www.reddit.com/r/MachineLearning/comments/5hgekk/d_looking_for_advice_on_a_binary_classification/,dbbn,1481318526,"I would love some advice on recommended techniques, NN architectures, etc for the problem described below.

Background:  My cat is a jerk and loves to bring live mice, birds, etc into my house.  She enters via a [fancy cat door](https://www.amazon.com/Cat-Mate-Elite-Microchip-Control/dp/B009GODTTK) that has a locking mechanism and a switch that detects when she pushes on it.  She pushes on the flap, the controller runs a motor to disengage the lock, she can now enter.  When she's through, the motor runs again to re-engage the lock.  My thought is that I can interpose a computer with camera (Raspberry Pi 3, probably) between the push sensor and the onboard electronics.  The computer takes a picture when she pushes on the door, and decides whether or not to pass this ""request"" on to the door controller.  It will deny requests in which the photo reveals a contraband item in kitty's mouth.

I've played with ML a few times over the years and have a fairly good big-picture understanding, but I lack experience in choosing the right technique / designing an architecture for a given problem domain.  Here are the constraints as I see them:

1. Similarity:  On the plus side, due to the way photos are triggered, all of my photos will be of the same cat (hopefully!), in roughly the same pose, orientation, frame location, etc.  My gut feeling is that ""overfitting"" to these parameters is a good thing in my application, not a bad thing.
1. Limited training set:  This is the big issue, as I see it.  I wouldn't be going down this road if the problem didn't occur ""often"", but it will still take me quite a while to capture even 10's of ""bad kitty"" photos.  1000's are out of the question.  ""good kitty"" (no contraband) photos can be accumulated at a rate of several per day.  I could attempt to augment my set with generic ""cat with mouse in mouth"" photos, but wouldn't this destroy the advantages of #1?
1. Lighting: This system needs to operate in a wide variety of lighting conditions, including night-time where the cat will be lit by IR led's (I'll use an IR-capable camera).  I'm be interested in expert opinions on what type of image pre-processing I should use on my images to mitigate this issue.
1. Latency / compute power: I need to make a decision in less than one second (hopefully less than half?).  This, combined with the lack of GPU acceleration and relatively low CPU performance on the RPI, will presumably affect the network design and choice of software tools.  (On the flip side, training can be done elsewhere on a GPU-equipped computer).
1. False positives: I'd like the system to err on the side of letting the cat in.  In other words, I only want to deny requests if I have high confidence there's contraband.

I'm currently playing around with Tensorflow/Keras (which seems to be supported on the RPI) but I'm not wedded to that choice (or to NN-based techniques).  Any advice will be greatly appreciated!",11,10,False,self,,,,,
325,MachineLearning,t5_2r3gv,2016-12-10,2016,12,10,7,5hgud1,bayesianbiologist.com,Visualizing Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/5hgud1/visualizing_generative_adversarial_networks/,likelihoodtprior,1481323285,,0,1,False,default,,,,,
326,MachineLearning,t5_2r3gv,2016-12-10,2016,12,10,9,5hhhsr,self.MachineLearning,[R] Should multiple ideas be published in a single paper?,https://www.reddit.com/r/MachineLearning/comments/5hhhsr/r_should_multiple_ideas_be_published_in_a_single/,[deleted],1481331143,"Let's say you have two ideas that each improve ImageNet results by 1%, and when you combine them, you get 1.5% improvement.

Should you stuff all 3 results in one angry paper? (Which may be size-limited, and therefore problematic)

Should you try to publish 3 different papers? What do you think is the best practice?
",9,7,False,self,,,,,
327,MachineLearning,t5_2r3gv,2016-12-10,2016,12,10,11,5hhv95,youtube.com,How to Make a Simple Tensorflow Speech Recognizer,https://www.reddit.com/r/MachineLearning/comments/5hhv95/how_to_make_a_simple_tensorflow_speech_recognizer/,llSourcell,1481336199,,0,1,False,default,,,,,
328,MachineLearning,t5_2r3gv,2016-12-10,2016,12,10,11,5hhxb0,arxiv.org,[R] [1603.07954] Improving Information Extraction by Acquiring External Evidence with Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/5hhxb0/r_160307954_improving_information_extraction_by/,CultOfLamb,1481336986,,1,13,False,default,,,,,
329,MachineLearning,t5_2r3gv,2016-12-10,2016,12,10,14,5hikrg,self.MachineLearning,"[Discussion] Reddit ""machine learning"" is really ""deep leaning"", how to encourage diversity?",https://www.reddit.com/r/MachineLearning/comments/5hikrg/discussion_reddit_machine_learning_is_really_deep/,[deleted],1481346517,[deleted],10,0,False,default,,,,,
330,MachineLearning,t5_2r3gv,2016-12-10,2016,12,10,14,5hiq87,self.MachineLearning,[D] Unsupervised Option Discovery,https://www.reddit.com/r/MachineLearning/comments/5hiq87/d_unsupervised_option_discovery/,kjw0612,1481348939,"I heard this term Unsupervised Option Discovery at NIPS and tried to look it up, but haven't succeeded. Does anyone have some reference?",2,8,False,self,,,,,
331,MachineLearning,t5_2r3gv,2016-12-10,2016,12,10,15,5hivrg,youtube.com,How does the chemical fluid mixers mix,https://www.reddit.com/r/MachineLearning/comments/5hivrg/how_does_the_chemical_fluid_mixers_mix/,mixmachinery,1481351479,,1,1,False,default,,,,,
332,MachineLearning,t5_2r3gv,2016-12-10,2016,12,10,17,5hj6j0,metamind.io,Multiple Different Natural Language Processing Tasks in a Single Deep Model,https://www.reddit.com/r/MachineLearning/comments/5hj6j0/multiple_different_natural_language_processing/,deepaurorasky,1481357230,,0,1,False,default,,,,,
333,MachineLearning,t5_2r3gv,2016-12-10,2016,12,10,17,5hj82c,github.com,Test Open AI universe in 3 commands,https://www.reddit.com/r/MachineLearning/comments/5hj82c/test_open_ai_universe_in_3_commands/,[deleted],1481358137,[deleted],0,1,False,default,,,,,
334,MachineLearning,t5_2r3gv,2016-12-10,2016,12,10,18,5hjfso,self.MachineLearning,Deep Q Network for Uncontrolled Environment,https://www.reddit.com/r/MachineLearning/comments/5hjfso/deep_q_network_for_uncontrolled_environment/,naimelhajj,1481362855,[removed],0,1,False,default,,,,,
335,MachineLearning,t5_2r3gv,2016-12-10,2016,12,10,22,5hk6kf,github.com,[Project] Numpy Exercises,https://www.reddit.com/r/MachineLearning/comments/5hk6kf/project_numpy_exercises/,longinglove,1481377612,,7,195,False,http://b.thumbs.redditmedia.com/gVPaUi0QrNbtAYRmQwkLtvqLtOV4f-snL-Rrhb_WA4k.jpg,,,,,
336,MachineLearning,t5_2r3gv,2016-12-11,2016,12,11,1,5hkwjp,self.MachineLearning,[Advice]: Machine/Deep learning doesn't seem exciting anymore... or just burning out of grad school?,https://www.reddit.com/r/MachineLearning/comments/5hkwjp/advice_machinedeep_learning_doesnt_seem_exciting/,burningphd,1481387548,[removed],0,1,False,default,,,,,
337,MachineLearning,t5_2r3gv,2016-12-11,2016,12,11,1,5hkyuo,lauragelston.ghost.io,Building a ChatBot with tensorflow,https://www.reddit.com/r/MachineLearning/comments/5hkyuo/building_a_chatbot_with_tensorflow/,Geir568,1481388325,,0,1,False,default,,,,,
338,MachineLearning,t5_2r3gv,2016-12-11,2016,12,11,4,5hltrt,breloff.com,"Learning without Backpropagation: Intuition and Ideas (Part 1), Part 2 link in comment",https://www.reddit.com/r/MachineLearning/comments/5hltrt/learning_without_backpropagation_intuition_and/,muktabh,1481398197,,1,1,False,default,,,,,
339,MachineLearning,t5_2r3gv,2016-12-11,2016,12,11,4,5hluhk,youtube.com,Most Amazing Modern Machinery in The World | Amazing Construction Machin...,https://www.reddit.com/r/MachineLearning/comments/5hluhk/most_amazing_modern_machinery_in_the_world/,Kahloonjutt,1481398425,,0,1,False,default,,,,,
340,MachineLearning,t5_2r3gv,2016-12-11,2016,12,11,4,5hlwkr,self.MachineLearning,What If I Overfit?,https://www.reddit.com/r/MachineLearning/comments/5hlwkr/what_if_i_overfit/,stacky777,1481399122,[removed],0,1,False,default,,,,,
341,MachineLearning,t5_2r3gv,2016-12-11,2016,12,11,6,5hmdty,self.MachineLearning,[Discussion] RocketAI,https://www.reddit.com/r/MachineLearning/comments/5hmdty/discussion_rocketai/,kevinzakka,1481404622,"Reading some extremely excited tweets about RocketAI but no one's elaborating. Could anyone that attended NIPS fill us in?

Edit: If it's a prank i'm gonna look really stupid lol",19,29,False,self,,,,,
342,MachineLearning,t5_2r3gv,2016-12-11,2016,12,11,9,5hngbs,self.MachineLearning,types of employers/jobs in machine learning - doing good?,https://www.reddit.com/r/MachineLearning/comments/5hngbs/types_of_employersjobs_in_machine_learning_doing/,machinelean,1481417540,[removed],0,1,False,default,,,,,
343,MachineLearning,t5_2r3gv,2016-12-11,2016,12,11,10,5hnq25,arxiv.org,[R] (CAD)RL: Real Single-Image Flight without a Single Real Image,https://www.reddit.com/r/MachineLearning/comments/5hnq25/r_cadrl_real_singleimage_flight_without_a_single/,madebyollin,1481421193,,7,10,False,default,,,,,
344,MachineLearning,t5_2r3gv,2016-12-11,2016,12,11,12,5ho3wy,shrikar.com,Self Driving Car : Lane detection in a video stream using OpenCV,https://www.reddit.com/r/MachineLearning/comments/5ho3wy/self_driving_car_lane_detection_in_a_video_stream/,canhelp,1481426553,,0,1,False,default,,,,,
345,MachineLearning,t5_2r3gv,2016-12-11,2016,12,11,15,5hotyc,self.MachineLearning,simple keras LSTM,https://www.reddit.com/r/MachineLearning/comments/5hotyc/simple_keras_lstm/,maximus12793,1481437701,[removed],0,1,False,default,,,,,
346,MachineLearning,t5_2r3gv,2016-12-11,2016,12,11,15,5how8p,self.MachineLearning,[D] We need a theano visualization tool similar to tensorboard.,https://www.reddit.com/r/MachineLearning/comments/5how8p/d_we_need_a_theano_visualization_tool_similar_to/,procarastinizer,1481438837,"We need something like this for theano.  https://www.tensorflow.org/versions/r0.12/how_tos/graph_viz/index.html
All we have is theano function visualization through pydot print and d3viz.
",8,8,False,self,,,,,
347,MachineLearning,t5_2r3gv,2016-12-11,2016,12,11,20,5hpmga,i.imgur.com,What is this type of GAN called? What is it used for? I saw it at NIPS but can't find it.,https://www.reddit.com/r/MachineLearning/comments/5hpmga/what_is_this_type_of_gan_called_what_is_it_used/,[deleted],1481454228,[deleted],0,1,False,default,,,,,
348,MachineLearning,t5_2r3gv,2016-12-11,2016,12,11,20,5hpo4c,i.imgur.com,[D] What is this type of GAN called? What is it used for? I saw it at NIPS but can't find it.,https://www.reddit.com/r/MachineLearning/comments/5hpo4c/d_what_is_this_type_of_gan_called_what_is_it_used/,[deleted],1481455207,[deleted],6,4,False,default,,,,,
349,MachineLearning,t5_2r3gv,2016-12-11,2016,12,11,21,5hps9m,iro.umontreal.ca,[R] [NIPS 2016] Yoshua Bengio: Towards biologically plausible deep learning,https://www.reddit.com/r/MachineLearning/comments/5hps9m/r_nips_2016_yoshua_bengio_towards_biologically/,downtownslim,1481457727,,41,84,False,default,,,,,
350,MachineLearning,t5_2r3gv,2016-12-11,2016,12,11,22,5hq5vx,self.MachineLearning,Are there any datasets on Cross-Lingual Lexical Substitution?,https://www.reddit.com/r/MachineLearning/comments/5hq5vx/are_there_any_datasets_on_crosslingual_lexical/,DemiourgosD,1481464776,[removed],0,1,False,default,,,,,
351,MachineLearning,t5_2r3gv,2016-12-11,2016,12,11,23,5hqaxw,self.MachineLearning,"[Project]A content-based recommendation system for recommending subreddits, written in Python. We would like some feedback.",https://www.reddit.com/r/MachineLearning/comments/5hqaxw/projecta_contentbased_recommendation_system_for/,BigDataAAU,1481466837,"Hello /r/MachineLearning

We are a group of six Computer Scientist students from Aalborg University in Denmark, and we are currently working on a Machine Intelligence project, where we try to give content-based recommendations based on the descriptions for each subreddit. This form of recommendations is generally used to webshops to recommend products to users, based on previous purchases.

In order to validate our recommendation technique, we have created a Chrome browser extension. The extensions recommends other subreddits when used while browsing a subreddit. An example of this extension in use can be seen [here](http://imgur.com/t7PD21C).

We would like you to install the extension, visit a few of your favorite subreddits, and give us feedback on the recommendation you will be given. The feedback does not change the recommendations, but will be used for our report.

It is also possible to give us feedback here on reddit, or through our e-mail address: d506e16@cs.aau.dk.

The Chrome extension can be downloaded [here](https://chrome.google.com/webstore/detail/subreddit-recommendations/nnfoccgmkafhnfobffnogiledendibbl), and the source code can be found on GitHub [here](https://github.com/Joklost/subreddit-recommendations).

The source code for the recommendation engine can also be found on GitHub [here](https://github.com/Joklost/contentpy).",19,43,False,self,,,,,
352,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,1,5hquh1,self.MachineLearning,[D] Serving deep learning predictions on a website,https://www.reddit.com/r/MachineLearning/comments/5hquh1/d_serving_deep_learning_predictions_on_a_website/,Pieranha,1481473946,"Suppose I have a deep CNN or LSTM model and I want to build a website that serves users a prediction from this model based on their input. Each user only submits one input at a time and there may be thousands of users at a time.

I'd like to find the most cost-efficient way of doing this while keeping the time from submission of input to serving of prediction within 5 seconds. The model will be provided in Keras/Tensorflow form. I have the following questions related to this that I hope someone can provide me with some input on:

1. What frameworks would you recommend for serving these predictions?
2. Would you use GPU's or CPU's?
3. How many hours would you roughly estimate it would take a single skilled developer to build the link between website and model?

If anyone has any case studies on doing this using any framework/backend I'd love to see them. Thanks!

---------------------------

Edit:
Thanks for the many replies! Answering some follow-up questions here so the information is easily available.

**4. Do you need authentication, or pricing per call?** No need for authentication or pricing per call. The service would be for free. Some simple techniques to blocking someone navely spamming the service might be useful though.

**5. How reliable is the rate of requests, highly ""bursty"" or steady through the day?** It would sadly be highly bursty.

**6. What's your price range for running this?** I do not know that yet, but I'm currently exploring how expensive this is and what price range would be feasible.
",23,10,False,self,,,,,
353,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,2,5hr0gu,youtube.com,Hayao Miyazaki's thoughts on an artificial intelligence,https://www.reddit.com/r/MachineLearning/comments/5hr0gu/hayao_miyazakis_thoughts_on_an_artificial/,johnmountain,1481475844,,0,1,False,default,,,,,
354,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,2,5hr6ty,self.MachineLearning,Unversity ML versus Real World,https://www.reddit.com/r/MachineLearning/comments/5hr6ty/unversity_ml_versus_real_world/,SANDER22,1481477731,[removed],0,1,False,default,,,,,
355,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,2,5hr70g,self.MachineLearning,What's the current state-of-the-art in genetic programming?,https://www.reddit.com/r/MachineLearning/comments/5hr70g/whats_the_current_stateoftheart_in_genetic/,sanity,1481477792,[removed],0,1,False,default,,,,,
356,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,3,5hrnwv,wsiukweb.kinja.com,Make Your Work Effortless By Modern Deburring Machines,https://www.reddit.com/r/MachineLearning/comments/5hrnwv/make_your_work_effortless_by_modern_deburring/,wsiukweb,1481482702,,0,1,False,default,,,,,
357,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,5,5hs99m,whattobrew.com,[Project] Using Tensorflow Projector to visualize beer styles and additions - try it out!,https://www.reddit.com/r/MachineLearning/comments/5hs99m/project_using_tensorflow_projector_to_visualize/,sparge,1481488901,,3,2,False,http://b.thumbs.redditmedia.com/dKKDvwHZj6fNx1JbcH3vQ-Rt-9JDIjyxC60bhpDnVSw.jpg,,,,,
358,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,7,5hssvf,self.MachineLearning,"Classifying images, my success today",https://www.reddit.com/r/MachineLearning/comments/5hssvf/classifying_images_my_success_today/,Simusid,1481494700,[removed],0,1,False,default,,,,,
359,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,8,5ht9ex,self.MachineLearning,[Project] VAE model for single person facial expression + unseen face reconstructions,https://www.reddit.com/r/MachineLearning/comments/5ht9ex/project_vae_model_for_single_person_facial/,int8blog,1481499920,"Hi there, 

To familiarize with VAE I worked on a hobby project - described in a title - with details available here: 

http://int8.io/variational-autoencoder-in-tensorflow/

I hope you find it interesting or anyhow useful

[edit] typo",15,35,False,self,,,,,
360,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,9,5htd70,youtube.com,Really Quick Questions with a Google Deep Learning Researcher,https://www.reddit.com/r/MachineLearning/comments/5htd70/really_quick_questions_with_a_google_deep/,llSourcell,1481501172,,0,0,False,default,,,,,
361,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,9,5htgzb,cs.ucr.edu,An amazing new time series machine learning tool,https://www.reddit.com/r/MachineLearning/comments/5htgzb/an_amazing_new_time_series_machine_learning_tool/,eamonnkeogh,1481502317,,1,1,False,default,,,,,
362,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,9,5htla3,self.MachineLearning,Does NIPS have video recordings of the keynote/tutorials?,https://www.reddit.com/r/MachineLearning/comments/5htla3/does_nips_have_video_recordings_of_the/,Neutran,1481503772,[removed],0,1,False,default,,,,,
363,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,10,5htwea,fertilizer-machine.com,Reliable Rotary Drum Fertilizer Drying Machine Manufacturer,https://www.reddit.com/r/MachineLearning/comments/5htwea/reliable_rotary_drum_fertilizer_drying_machine/,Anne0712,1481507481,,1,1,False,default,,,,,
364,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,11,5hu4vm,self.MachineLearning,[D] Anyone else out there also applying to graduate school for Machine Learning right now?,https://www.reddit.com/r/MachineLearning/comments/5hu4vm/d_anyone_else_out_there_also_applying_to_graduate/,yoyosarian,1481510407,Im applying to Ph.D programs in machine learning and still frantically getting my applications together. I was just wondering if there are people in similar situations on this reddit. (Sorry that this is a sciencey post).,48,62,False,self,,,,,
365,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,15,5hv242,self.MachineLearning,What is the relationship between the bias node in a perceptron and the threshold of the activation function?,https://www.reddit.com/r/MachineLearning/comments/5hv242/what_is_the_relationship_between_the_bias_node_in/,skipper_sans,1481522755,[removed],0,1,False,default,,,,,
366,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,15,5hv6tv,github.com,[P] Try OpenAI Universe in 3 commands,https://www.reddit.com/r/MachineLearning/comments/5hv6tv/p_try_openai_universe_in_3_commands/,alantrrs,1481524800,,3,0,False,http://b.thumbs.redditmedia.com/cDLZz84fG6zuHquZuZE1kBUpAjXqc9d_OG137ZKGlCA.jpg,,,,,
367,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,16,5hvbln,youtu.be,"Rotary Sieve Machine Supplier, Rotary Screening Machine, Fertilizer Screener",https://www.reddit.com/r/MachineLearning/comments/5hvbln/rotary_sieve_machine_supplier_rotary_screening/,frady2015,1481526989,,1,1,False,default,,,,,
368,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,16,5hveem,github.com,[P] An Implementation of 'Texture Synthesis Using Convolutional Neural Networks' with Kylberg Texture Dataset,https://www.reddit.com/r/MachineLearning/comments/5hveem/p_an_implementation_of_texture_synthesis_using/,longinglove,1481528343,,0,6,False,http://b.thumbs.redditmedia.com/xui8Kn5IBjy_0GFC-tSd_z0uyXyQQ3S2ObsFwClefwI.jpg,,,,,
369,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,18,5hvoc9,self.MachineLearning,[Discussion] Are newer high-end gaming laptops now valid machine learning training rigs?,https://www.reddit.com/r/MachineLearning/comments/5hvoc9/discussion_are_newer_highend_gaming_laptops_now/,cjmcmurtrie,1481533496,"Until now I've favoured using a Titan X tower for training models, but one of the newer gaming laptops has caught my eye. Some of these machines have a Pascal GTX1070 8G GPU in a 2.2kg machine, with up to 512G SSD and 32G ram. The 1070 card is apparently capable of heavy lifting without overheating issues (e.g. VR games).

Anyone have experience with a GTX1070 laptop? I really like the idea of being able to hit 'train' without going to my office workstation (and a firewall currently prevents me from SSHing in).
",19,0,False,self,,,,,
370,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,19,5hvzg7,youtube.com,"Double shaft mixer, professional dry powder production machine",https://www.reddit.com/r/MachineLearning/comments/5hvzg7/double_shaft_mixer_professional_dry_powder/,mixmachinery,1481539349,,1,1,False,default,,,,,
371,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,20,5hw2ab,i.redd.it,Playing Atari SpaceInvaders with Asynchronous one-step Q-Learning (implementation + explanation).,https://www.reddit.com/r/MachineLearning/comments/5hw2ab/playing_atari_spaceinvaders_with_asynchronous/,[deleted],1481540845,[deleted],0,1,False,default,,,,,
372,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,20,5hw3s4,github.com,Playing Atari SpaceInvaders with Asynchronous one-step Q-Learning (implementation + explanation).,https://www.reddit.com/r/MachineLearning/comments/5hw3s4/playing_atari_spaceinvaders_with_asynchronous/,[deleted],1481541594,[deleted],0,1,False,default,,,,,
373,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,20,5hw6jx,dbobrenko.github.io,Playing Atari SpaceInvaders with Asynchronous one-step Q-Learning (implementation + explanation).,https://www.reddit.com/r/MachineLearning/comments/5hw6jx/playing_atari_spaceinvaders_with_asynchronous/,[deleted],1481542990,[deleted],0,1,False,default,,,,,
374,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,21,5hw9wz,self.MachineLearning,NIPS videos?,https://www.reddit.com/r/MachineLearning/comments/5hw9wz/nips_videos/,circuithunter,1481544586,[removed],0,1,False,default,,,,,
375,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,21,5hwda6,i.redd.it,Playing Atari SpaceInvaders with Asynchronous one-step Q-Learning (implementation + explanation).,https://www.reddit.com/r/MachineLearning/comments/5hwda6/playing_atari_spaceinvaders_with_asynchronous/,[deleted],1481546099,[deleted],0,1,False,default,,,,,
376,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,21,5hwfbm,dbobrenko.github.io,Playing Atari SpaceInvaders with DeepMind's Asynchronous one-step Q-Learning,https://www.reddit.com/r/MachineLearning/comments/5hwfbm/playing_atari_spaceinvaders_with_deepminds/,[deleted],1481546968,[deleted],0,1,False,default,,,,,
377,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,22,5hwpf4,mshen.me,What I learned from Coursera ML class (part 2 of 2),https://www.reddit.com/r/MachineLearning/comments/5hwpf4/what_i_learned_from_coursera_ml_class_part_2_of_2/,marshalization,1481550886,,0,1,False,default,,,,,
378,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,23,5hwqeb,self.MachineLearning,[Project] All Code Implementations for NIPS 2016 papers,https://www.reddit.com/r/MachineLearning/comments/5hwqeb/project_all_code_implementations_for_nips_2016/,peterkuharvarduk,1481551245,"I want to compile a comprehensive list of all the available code repos for the NIPS 2016's top papers. Please add to the list!

1. Using Fast Weights to Attend to the Recent Past (https://arxiv.org/abs/1610.06258)
&gt;&gt;**Repo**: https://github.com/ajarai/fast-weights

2. Learning to learn by gradient descent by gradient descent (https://arxiv.org/abs/1606.04474)
&gt;&gt;**Repo**: https://github.com/deepmind/learning-to-learn

3. R-FCN: Object Detection via Region-based Fully Convolutional Networks (https://arxiv.org/abs/1605.06409)
&gt;&gt;**Repo**: https://github.com/Orpine/py-R-FCN

4. Fast and Provably Good Seedings for k-Means (https://las.inf.ethz.ch/files/bachem16fast.pdf).
&gt;&gt;**Repo**: https://github.com/obachem/kmc2

5. How to Train a GAN
&gt;&gt;**Repo**: https://github.com/soumith/ganhacks

6. Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences (https://arxiv.org/abs/1610.09513)
&gt;&gt;**Repo**: https://github.com/dannyneil/public_plstm

7. Generative Adversarial Imitation Learning (https://arxiv.org/abs/1606.03476)
&gt;&gt;**Repo**: https://github.com/openai/imitation

8. Adversarial Multiclass Classification: A Risk Minimization Perspective (https://www.cs.uic.edu/~rfathony/pdf/fathony2016adversarial.pdf)
&gt;&gt;**Repo**: https://github.com/rizalzaf/adversarial-multiclass

9. Unsupervised Learning for Physical Interaction through Video Prediction (https://arxiv.org/abs/1605.07157)
&gt;&gt;**Repo**: https://github.com/tensorflow/models/tree/master/video_prediction

10. Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks (https://arxiv.org/abs/1602.07868)
&gt;&gt;**Repo**: https://github.com/openai/weightnorm

11. Full-Capacity Unitary Recurrent Neural Networks (https://arxiv.org/abs/1611.00035)
&gt;&gt;**Repo**: Code: https://github.com/stwisdom/urnn

12. Sequential Neural Models with Stochastic Layers (https://arxiv.org/pdf/1605.07571.pdf)
&gt;&gt;**Repo**: https://github.com/marcofraccaro/srnn

13. Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering (https://arxiv.org/abs/1606.09375)
&gt;&gt;**Repo**: https://github.com/mdeff/cnn_graph

14. Interpretable Distribution Features with Maximum Testing Power (https://papers.nips.cc/paper/6148-interpretable-distribution-features-with-maximum-testing-power.pdf)
&gt;&gt;**Repo**: https://github.com/wittawatj/interpretable-test/

15. Composing graphical models with neural networks for structured representations and fast inference (https://arxiv.org/abs/1603.06277)
&gt;&gt;**Repo**: https://github.com/mattjj/svae

16. Supervised Learning with Tensor Networks (https://arxiv.org/abs/1605.05775)
&gt;&gt;**Repo**: https://github.com/emstoudenmire/TNML

17. Fast -free Inference of Simulation Models with Bayesian Conditional Density Estimation: (https://arxiv.org/abs/1605.06376)
&gt;&gt;**Repo**: https://github.com/gpapamak/epsilon_free_inference

18. Bayesian Optimization for Probabilistic Programs (http://www.robots.ox.ac.uk/~twgr/assets/pdf/rainforth2016BOPP.pdf)
&gt;&gt;**Repo**: https://github.com/probprog/bopp

19. PVANet: Lightweight Deep Neural Networks for Real-time Object Detection (https://arxiv.org/abs/1611.08588)
&gt;&gt;**Repo**: https://github.com/sanghoon/pva-faster-rcnn

20. Data Programming: Creating Large Training Sets Quickly (https://arxiv.org/abs/1605.07723)
&gt;&gt;**Repo**: snorkel.stanford.edu

21. Convolutional Neural Fabrics for Architecture Learning (https://arxiv.org/pdf/1606.02492.pdf)
&gt;&gt;**Repo**: https://github.com/shreyassaxena/convolutional-neural-fabrics",51,112,False,self,,,,,
379,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,23,5hwqj8,self.MachineLearning,Are there any good papers/methods related to Q-function learning with validation?,https://www.reddit.com/r/MachineLearning/comments/5hwqj8/are_there_any_good_papersmethods_related_to/,ptitz,1481551299,[removed],0,1,False,default,,,,,
380,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,23,5hwqmi,anandtech.com,"AMD - Radeon Instinct: GPUs for Deep Learning, Coming In 2017",https://www.reddit.com/r/MachineLearning/comments/5hwqmi/amd_radeon_instinct_gpus_for_deep_learning_coming/,rndnum123,1481551339,,0,1,False,default,,,,,
381,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,23,5hwsd8,videocardz.com,AMD announces their first deep learning hardware INSTINCT MI25,https://www.reddit.com/r/MachineLearning/comments/5hwsd8/amd_announces_their_first_deep_learning_hardware/,[deleted],1481551936,[deleted],0,1,False,default,,,,,
382,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,23,5hwsrc,hbr.org,How to make your company machine-learning ready,https://www.reddit.com/r/MachineLearning/comments/5hwsrc/how_to_make_your_company_machinelearning_ready/,jonfla,1481552078,,0,1,False,default,,,,,
383,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,23,5hwu2d,videocardz.com,[N] AMD announces their first deep learning hardware,https://www.reddit.com/r/MachineLearning/comments/5hwu2d/n_amd_announces_their_first_deep_learning_hardware/,L0SG,1481552535,,54,190,False,http://a.thumbs.redditmedia.com/l3KnGVbtl6Vf1qHCbDaPxWpB-S3flRbdMbRw71M-Gp0.jpg,,,,,
384,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,23,5hwul1,github.com,Code for Plug and Play Generative Networks released!,https://www.reddit.com/r/MachineLearning/comments/5hwul1/code_for_plug_and_play_generative_networks/,hungry_for_knowledge,1481552710,,0,1,False,default,,,,,
385,MachineLearning,t5_2r3gv,2016-12-12,2016,12,12,23,5hwzod,self.MachineLearning,[D] Where can I get proprietary data?,https://www.reddit.com/r/MachineLearning/comments/5hwzod/d_where_can_i_get_proprietary_data/,[deleted],1481554477,[removed],1,0,False,default,,,,,
386,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,0,5hx1aq,github.com,[P] XGBoost now with GPU support. 7-9x speedup.,https://www.reddit.com/r/MachineLearning/comments/5hx1aq/p_xgboost_now_with_gpu_support_79x_speedup/,CultOfLamb,1481554995,,13,80,False,http://b.thumbs.redditmedia.com/spwXM0Hc_mKqRMcwZ6z957pqIIV_S-4kFI4o2iwMtcA.jpg,,,,,
387,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,0,5hx9pi,benfrederickson.com,[P] Faster Implicit Matrix Factorization,https://www.reddit.com/r/MachineLearning/comments/5hx9pi/p_faster_implicit_matrix_factorization/,benfred,1481557588,,3,20,False,default,,,,,
388,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,0,5hxa1y,bloomberg.com,[N] Microsoft's New AI Fund Invests in Bengio's Element AI,https://www.reddit.com/r/MachineLearning/comments/5hxa1y/n_microsofts_new_ai_fund_invests_in_bengios/,nested_dreams,1481557695,,1,27,False,http://b.thumbs.redditmedia.com/66L79qOcttU3QpfyFfzst_ugrlhszxry5Xg8lvhP8TM.jpg,,,,,
389,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,1,5hxctk,wired.com,"Numerai Used 7,500 Faceless Coders Paid in Bitcoin to Build Its Hedge Fund's Brain",https://www.reddit.com/r/MachineLearning/comments/5hxctk/numerai_used_7500_faceless_coders_paid_in_bitcoin/,[deleted],1481558521,[deleted],0,1,False,default,,,,,
390,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,1,5hxd3c,self.MachineLearning,[D] Is it worth it to join the NVIDIA GPU Educators Program?,https://www.reddit.com/r/MachineLearning/comments/5hxd3c/d_is_it_worth_it_to_join_the_nvidia_gpu_educators/,[deleted],1481558590,[deleted],0,9,False,default,,,,,
391,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,1,5hxfka,blog.kovalevskyi.com,"Own ChatBot, based on recurrent neural network. for 6$/6 hours and ~100 lines of code.",https://www.reddit.com/r/MachineLearning/comments/5hxfka/own_chatbot_based_on_recurrent_neural_network_for/,[deleted],1481559290,[deleted],0,1,False,default,,,,,
392,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,1,5hxj2i,chuyentivi.com,Washing machines cause electrical leakage and how to fix it,https://www.reddit.com/r/MachineLearning/comments/5hxj2i/washing_machines_cause_electrical_leakage_and_how/,Tanmkt,1481560285,,0,1,False,default,,,,,
393,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,2,5hxtjs,self.MachineLearning,Can someone help me understand what this txt has to do with a Markov chain?,https://www.reddit.com/r/MachineLearning/comments/5hxtjs/can_someone_help_me_understand_what_this_txt_has/,[deleted],1481563167,[removed],0,1,False,default,,,,,
394,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,3,5hy4ur,self.MachineLearning,[D] Machine Learning - WAYR (What Are You Reading) - Week 15,https://www.reddit.com/r/MachineLearning/comments/5hy4ur/d_machine_learning_wayr_what_are_you_reading_week/,Mandrathax,1481566255,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

|Previous weeks|
|--------------|
|[Week 1](https://www.reddit.com/r/MachineLearning/comments/4qyjiq/machine_learning_wayr_what_are_you_reading_week_1/)|
|[Week 2](https://www.reddit.com/r/MachineLearning/comments/4s2xqm/machine_learning_wayr_what_are_you_reading_week_2/)|
|[Week 3](https://www.reddit.com/r/MachineLearning/comments/4t7mqm/machine_learning_wayr_what_are_you_reading_week_3/)|
|[Week 4](https://www.reddit.com/r/MachineLearning/comments/4ub2kw/machine_learning_wayr_what_are_you_reading_week_4/)|
|[Week 5](https://www.reddit.com/r/MachineLearning/comments/4xomf7/machine_learning_wayr_what_are_you_reading_week_5/)|
|[Week 6](https://www.reddit.com/r/MachineLearning/comments/4zcyvk/machine_learning_wayr_what_are_you_reading_week_6/)|
|[Week 7](https://www.reddit.com/r/MachineLearning/comments/52t6mo/machine_learning_wayr_what_are_you_reading_week_7/)|
|[Week 8](https://www.reddit.com/r/MachineLearning/comments/53heol/machine_learning_wayr_what_are_you_reading_week_8/)|
|[Week 9](https://www.reddit.com/r/MachineLearning/comments/54kvsu/machine_learning_wayr_what_are_you_reading_week_9/)|
|[Week 10](https://www.reddit.com/r/MachineLearning/comments/56s2oa/discussion_machine_learning_wayr_what_are_you/)|
|[Week 11](https://www.reddit.com/r/MachineLearning/comments/57xw56/discussion_machine_learning_wayr_what_are_you/)|
|[Week 12](https://www.reddit.com/r/MachineLearning/comments/5acb1t/d_machine_learning_wayr_what_are_you_reading_week/)|
|[Week 13](https://www.reddit.com/r/MachineLearning/comments/5cwfb6/d_machine_learning_wayr_what_are_you_reading_week/)|
|[Week 14](https://www.reddit.com/r/MachineLearning/comments/5fc5mh/d_machine_learning_wayr_what_are_you_reading_week/)|

Most upvoted papers last week :

[Professor Forcing: A New Algorithm for Training Recurrent Networks](https://arxiv.org/abs/1610.09038)

[Data-Efficient Reinforcement Learning in Continuous-State POMDPs](https://arxiv.org/abs/1602.02523v1)

[Understanding Line Plots Using Bayesian Network](http://ieeexplore.ieee.org/document/7490102/) (Paywall)


Besides that, there are no rules, have fun.
",7,34,False,self,,,,,
395,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,3,5hy7pu,self.MachineLearning,Can GAN used to generate semantically similar 3D objects?,https://www.reddit.com/r/MachineLearning/comments/5hy7pu/can_gan_used_to_generate_semantically_similar_3d/,yobichi,1481566971,[removed],0,1,False,default,,,,,
396,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,3,5hyat9,self.MachineLearning,[P] Playing Atari SpaceInvaders with DeepMind's Asynchronous one-step Q-Learning (implementation + explanation),https://www.reddit.com/r/MachineLearning/comments/5hyat9/p_playing_atari_spaceinvaders_with_deepminds/,qr0sity,1481567757,"Explanation: https://dbobrenko.github.io/2016/11/03/async-deeprl.html

Code: https://github.com/dbobrenko/async-deeprl",1,26,False,self,,,,,
397,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,3,5hyen8,reddit.com,CNN correctly detected 95% of diabetic retinopathy cases - leads in public dataset classification results  /r/computervision,https://www.reddit.com/r/MachineLearning/comments/5hyen8/cnn_correctly_detected_95_of_diabetic_retinopathy/,CyndaquilTurd,1481568757,,0,1,False,default,,,,,
398,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,4,5hyq2x,self.MachineLearning,Classifying digits vs. non-digits,https://www.reddit.com/r/MachineLearning/comments/5hyq2x/classifying_digits_vs_nondigits/,deepconvnet,1481571757,[removed],0,1,False,default,,,,,
399,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,4,5hyt60,blog.insightdatascience.com,"NIPS 2016  Final Highlights Days 46: Likelihood-free inference, Dessert analogies, and much more.",https://www.reddit.com/r/MachineLearning/comments/5hyt60/nips_2016_final_highlights_days_46_likelihoodfree/,mwakanosya,1481572572,,0,1,False,default,,,,,
400,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,5,5hywjr,cdn.rawgit.com,[Project] Simple-to-study Reinforcement Pong Demo,https://www.reddit.com/r/MachineLearning/comments/5hywjr/project_simpletostudy_reinforcement_pong_demo/,[deleted],1481573480,[deleted],2,3,False,default,,,,,
401,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,5,5hywlc,self.MachineLearning,[D] What areas are currently under hyped for machine learning solutions?,https://www.reddit.com/r/MachineLearning/comments/5hywlc/d_what_areas_are_currently_under_hyped_for/,RefurbishedMac,1481573493,,13,10,False,self,,,,,
402,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,5,5hyxwa,twitter.com,"Andrew Ng recently tweeted, ""AI knowledge sharing from US-&gt;China is much faster than China-&gt;US, not because of secrecy but just because of language fluency."" What are some good new developments in the Chinese-language literature which aren't well known among those who are illiterate in Chinese?",https://www.reddit.com/r/MachineLearning/comments/5hyxwa/andrew_ng_recently_tweeted_ai_knowledge_sharing/,AlexCoventry,1481573842,,0,1,False,default,,,,,
403,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,5,5hyyal,motherboard.vice.com,AI Replacing Human Writers -- Are We Really This Far?,https://www.reddit.com/r/MachineLearning/comments/5hyyal/ai_replacing_human_writers_are_we_really_this_far/,EsTonInaToR,1481573943,,0,1,False,default,,,,,
404,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,6,5hzkeh,self.MachineLearning,General purpose binary image representations,https://www.reddit.com/r/MachineLearning/comments/5hzkeh/general_purpose_binary_image_representations/,anonDogeLover,1481579925,[removed],1,1,False,default,,,,,
405,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,7,5hzul4,beamandrew.github.io,"NIPS 2016 summary, wrap up, and links to slides",https://www.reddit.com/r/MachineLearning/comments/5hzul4/nips_2016_summary_wrap_up_and_links_to_slides/,[deleted],1481582830,[deleted],0,1,False,default,,,,,
406,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,7,5hzvfi,beamandrew.github.io,"[D] NIPS 2016 summary, wrap up, and links to slides",https://www.reddit.com/r/MachineLearning/comments/5hzvfi/d_nips_2016_summary_wrap_up_and_links_to_slides/,beamsearch,1481583088,,6,70,False,http://b.thumbs.redditmedia.com/K_9DOW3d0SanE5x1X2LOrHUwmQfwXKwcYi1hgULn-UM.jpg,,,,,
407,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,8,5i05fd,self.MachineLearning,[D] How would I train a CNN to select a filter based on features?,https://www.reddit.com/r/MachineLearning/comments/5i05fd/d_how_would_i_train_a_cnn_to_select_a_filter/,Blammar,1481586117,"The function I am trying to emulate works like the following pseudo code. The input is an image, and the output is also an image of the same size.

    1. Use a CNN of say 128 x 9 x 9 x 3 and a tanh as a nonlinear feature detector, first step.

    2. Use a full 128 x 128 NN and a max over the 128 outputs to choose an integer in the 0-127 range. Note this integer is WHICH output is the max, not the actual max value of the outputs!

    3. Use that integer to choose one of 128 9x9 (different) convolutions to apply to the input image at that pixel to generate the output image.

I do have desired output images, and it's sufficient to use say the euclidean distance norm to determine loss.

What I don't see is how to do back propagation (or any similar method) to figure out the coefficients of operations 1, 2, and 3. I can see how to do 1 and 2, or 3, separately, but not how to update their coefficients jointly.

Is there something obvious I am missing here? Or am I stuck with doing a genetic algorithm instead?

    ",1,1,False,self,,,,,
408,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,9,5i0e4r,ctss.net.au,commercial vacuum cleaners Adelaide,https://www.reddit.com/r/MachineLearning/comments/5i0e4r/commercial_vacuum_cleaners_adelaide/,CleaningTSS,1481588769,,0,1,False,default,,,,,
409,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,9,5i0k9g,sites.google.com,[P] Learning to Coach Football,https://www.reddit.com/r/MachineLearning/comments/5i0k9g/p_learning_to_coach_football/,[deleted],1481590678,[deleted],1,14,False,default,,,,,
410,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,10,5i0ljj,self.MachineLearning,Looking for resources to learn linear algebra while using Python. Any suggestions?,https://www.reddit.com/r/MachineLearning/comments/5i0ljj/looking_for_resources_to_learn_linear_algebra/,bbennett36,1481591116,[removed],0,1,False,default,,,,,
411,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,10,5i0ne0,youtube.com,The Mind Machines - Artificial Intelligence Documentary from 1978,https://www.reddit.com/r/MachineLearning/comments/5i0ne0/the_mind_machines_artificial_intelligence/,alphydan,1481591791,,0,1,False,default,,,,,
412,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,11,5i0wmv,i.reddituploads.com,Medical Imaging ML Roadmap,https://www.reddit.com/r/MachineLearning/comments/5i0wmv/medical_imaging_ml_roadmap/,manicRug,1481594788,,0,1,False,default,,,,,
413,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,13,5i1kf1,self.MachineLearning,How to increase PixelCNN testing speed?,https://www.reddit.com/r/MachineLearning/comments/5i1kf1/how_to_increase_pixelcnn_testing_speed/,[deleted],1481603060,[removed],0,1,False,default,,,,,
414,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,14,5i1u1n,self.MachineLearning,How to start contributing to tensorflow ?,https://www.reddit.com/r/MachineLearning/comments/5i1u1n/how_to_start_contributing_to_tensorflow/,robot_t0,1481606608,[removed],0,1,False,default,,,,,
415,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,15,5i20mf,news.ycombinator.com,[D] Ask HN: Where is AI/ML actually adding value at your company?,https://www.reddit.com/r/MachineLearning/comments/5i20mf/d_ask_hn_where_is_aiml_actually_adding_value_at/,anantzoid,1481609145,,0,1,False,default,,,,,
416,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,15,5i23wt,arxiv.org,[R] StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/5i23wt/r_stackgan_text_to_photorealistic_image_synthesis/,madebyollin,1481610614,,59,185,False,default,,,,,
417,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,16,5i2d3w,mixmachinery.com,What is the common problems towards the powder plow mixer?,https://www.reddit.com/r/MachineLearning/comments/5i2d3w/what_is_the_common_problems_towards_the_powder/,mixmachinery,1481614935,,1,1,False,default,,,,,
418,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,16,5i2e4r,udemycouponcodes.com,Machine Learning A-Z: Hands-On Python &amp; R In Data Science,https://www.reddit.com/r/MachineLearning/comments/5i2e4r/machine_learning_az_handson_python_r_in_data/,jessicaleiva609,1481615435,,0,1,False,default,,,,,
419,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,18,5i2q6k,cadem.com,"Chips, and heat removal in CNC machining",https://www.reddit.com/r/MachineLearning/comments/5i2q6k/chips_and_heat_removal_in_cnc_machining/,CademSoftware,1481621598,,1,1,False,default,,,,,
420,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,18,5i2r57,youtube.com,[N] Facial analisys with CNTK + kinect v2,https://www.reddit.com/r/MachineLearning/comments/5i2r57/n_facial_analisys_with_cntk_kinect_v2/,pmfcdb,1481622133,,1,1,False,http://b.thumbs.redditmedia.com/Hy0QtvH1fPYvaFWA8U-W1JEVI-c_Y9t84LPGg-ztW6Q.jpg,,,,,
421,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,19,5i2uiw,self.MachineLearning,Classification problem - shifted distribution in training vs test set,https://www.reddit.com/r/MachineLearning/comments/5i2uiw/classification_problem_shifted_distribution_in/,[deleted],1481623861,[removed],0,1,False,default,,,,,
422,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,19,5i2vqw,self.MachineLearning,[Research] Classification problem: Class-conditional Training data distribution and test data distribution is different.,https://www.reddit.com/r/MachineLearning/comments/5i2vqw/research_classification_problem_classconditional/,enken90,1481624485,"So I'm working on a classification problem where the goal is to identify the birth place (encoded as class labels) of a species of fish by using geochemical data sampled from their scales. The training data consists of scales sampled from juvenile fish and the test data consists of scales sampled from the same species a year or so later. Not sure if this is relevant in this case, but I'm using an ensemble of 5 models (Random Forest, KNN, Naive Bayes, SVM (radial basis), LDA) to solve this problem. I have tried many other models but this ensemble seems to work best, both CV wise and test error wise. 

The problem is that this particular species of fish migrates from fresh water lakes to the ocean during this period, and by looking at labeled instances of training and test data, it is clear that this migration changes the geochemical composition of the scales in a major way. This in turn means that the conditional class distribution of the training and test data is often very different, which in the worst case renders my model useless. I read around on the internet and found surprisingly little established research on this phenomenon. There is some research on a simpler problem where the data distribution is different (P(X_after) not equal to P(X_before)) but class conditional distribution is the same for the training and test data, i.e  P(Y=k|X_after) = P(Y=k|X_before), but that doesn't help me since the shift happens for the class conditional distribution. 

I have come up with some ""solutions"" to the problem, none that I particularly like:

* Remove the variables that are causing the shift. This is out of the question because most variables do shift a little bit, and the ones that changes the most happen to be (unfortunately) some of the most significant predictors of class in the training data. 

* Create an online learning algorithm by sampling data continuously during the lifetime of the fish, so that the training data does not get ""outdated"". This is also out of the question due to limited resources (out of my hands, already talked to the project supervisor about this)

* Reconstruct the training data distribution from the test data by regression (trainable by labelled instances of training and test data). I have had some success with this using naive linear regression (test error goes up from 100% to 50% worst case), but the training set in this case is small and I don't expect this approach to generalize well. The 50% test error is still obviously unacceptable. 

I have been stuck on this problem now for quite a while and I have no idea if a good solution is even within the realm of possibility. Has anyone encountered and solved a similar problem? Any advice is appreciated. 

**TL;DR**: I have a classification problem where the class-conditional distribution changes over time, making the classification models almost useless when evaluated on test data. Is there a path to a solution for this problem?",7,2,False,self,,,,,
423,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,19,5i2zxd,forbes.com,Big Data In Healthcare: Paris Hospitals Predict Admission Rates Using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5i2zxd/big_data_in_healthcare_paris_hospitals_predict/,dannyeuu,1481626723,,0,1,False,default,,,,,
424,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,20,5i31jl,pgaleone.eu,[P] Convolutional Autoencoders in Tensorflow,https://www.reddit.com/r/MachineLearning/comments/5i31jl/p_convolutional_autoencoders_in_tensorflow/,pgaleone,1481627532,,19,22,False,http://b.thumbs.redditmedia.com/fnDZcTwqk9IFNReQCP-ow0RvxdIDiUD9-vKOGhfogmo.jpg,,,,,
425,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,22,5i3fyt,arxiv.org,[Research] Prediction in Business Processes using LSTM Neural Networks,https://www.reddit.com/r/MachineLearning/comments/5i3fyt/research_prediction_in_business_processes_using/,TaXxER,1481634007,,6,10,False,default,,,,,
426,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,22,5i3kff,self.MachineLearning,Only one bias per feature map in CNNs?,https://www.reddit.com/r/MachineLearning/comments/5i3kff/only_one_bias_per_feature_map_in_cnns/,nate1421m,1481635659,[removed],0,1,False,default,,,,,
427,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,22,5i3npu,self.MachineLearning,Only one bias per feature map in CNNs?,https://www.reddit.com/r/MachineLearning/comments/5i3npu/only_one_bias_per_feature_map_in_cnns/,[deleted],1481636909,[removed],0,1,False,default,,,,,
428,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,23,5i3qwz,arxiv.org,[1612.02879] Learning representations through stochastic gradient descent in cross-validation error by R. Sutton &amp; V. Veeriah - Alternative to backprop,https://www.reddit.com/r/MachineLearning/comments/5i3qwz/161202879_learning_representations_through/,[deleted],1481638044,[deleted],0,1,False,default,,,,,
429,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,23,5i3rbt,arxiv.org,[1612.02879] Learning representations through stochastic gradient descent in cross-validation error by R. Sutton &amp; V. Veeriah - Alternative to backprop,https://www.reddit.com/r/MachineLearning/comments/5i3rbt/161202879_learning_representations_through/,Thomjazz,1481638178,,0,1,False,default,,,,,
430,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,23,5i3slf,self.MachineLearning,NIPS 2016 Overviews,https://www.reddit.com/r/MachineLearning/comments/5i3slf/nips_2016_overviews/,[deleted],1481638622,[removed],0,1,False,default,,,,,
431,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,23,5i3v0k,self.MachineLearning,[R] NIPS 2016 Overviews,https://www.reddit.com/r/MachineLearning/comments/5i3v0k/r_nips_2016_overviews/,barmaley_exe,1481639460,[removed],12,94,False,default,,,,,
432,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,23,5i3vu4,self.MachineLearning,[P] Trying to setup up CNN on Sentence data for live training and eval,https://www.reddit.com/r/MachineLearning/comments/5i3vu4/p_trying_to_setup_up_cnn_on_sentence_data_for/,talaqen,1481639752,"I'd like to setup a server endpoint/port that I can pass 30-50 sentences to.  If the sentences are scored, they are added to the training set and the model adjusts.  If the sentences are not, they are score against the existing model.  Incremental CNN with a web accessible endpoint.  

I've looked at CNN at http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/

Any other resources/tutorials you can recommend?  Anyone willing to help me cludge together some code?",0,0,False,self,,,,,
433,MachineLearning,t5_2r3gv,2016-12-13,2016,12,13,23,5i3z7o,github.com,Machine Learning based Facebook Messenger game bot,https://www.reddit.com/r/MachineLearning/comments/5i3z7o/machine_learning_based_facebook_messenger_game_bot/,kendrick__,1481640885,,0,2,False,default,,,,,
434,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,0,5i40fy,keithselover.wordpress.com,Using Scikit Learn Algos on Global Stock Index Data,https://www.reddit.com/r/MachineLearning/comments/5i40fy/using_scikit_learn_algos_on_global_stock_index/,[deleted],1481641294,[deleted],0,1,False,default,,,,,
435,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,1,5i4fj0,self.MachineLearning,"Follow us on Twitter, @slashML",https://www.reddit.com/r/MachineLearning/comments/5i4fj0/follow_us_on_twitter_slashml/,[deleted],1481645706,[deleted],0,1,False,default,,,,,
436,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,1,5i4fj6,self.MachineLearning,[D] DQN preprocessing of sequences?,https://www.reddit.com/r/MachineLearning/comments/5i4fj6/d_dqn_preprocessing_of_sequences/,LucidElectron,1481645707,"Hello! I am currently reading about DQN from the Deepmind paper, but I do not understand how they are preprocessing their sequences. This is the paper I'm reading: https://storage.googleapis.com/deepmind-data/assets/papers/DeepMindNature14236Paper.pdf

At the start of ""Methods"" they explain their preprocessing step aimed at reducing the input dimensionality. They take the maximum pixel values over two frames, extract the luminance and rescale the frame to 84x84. This is done for the m most recent frames, and they state that this is the function called phi. Nothing strange here. 

They also explain that since it is impossible to fully understand the current situation from the current screen, they use a sequence of actions and observations as input to the algorithm. But since these sequences has arbitrary length, it is difficult to use them as inputs to a neural network. They therefore use a fixed length representation of the sequences produced by the function phi. I'm assuming that they input a sequence into phi, and get a fixed length representation of that sequence. 

Now to my question: in the methods section they explain that phi preprocesses a *frame*, not a *sequence*. How can phi work on sequences, which are not the same as frames? The sequences are a combination of many frames and actions, which they somehow feed into phi to get a fixed length representation. How is this actually done in practice?

Everything else about DQN makes sense to me, and I can't find anything explaining this question on Google. I would be very glad for any help or pointers in the right direction! ",3,1,False,self,,,,,
437,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,1,5i4g7f,self.MachineLearning,Only one bias per feature map in CNNs?,https://www.reddit.com/r/MachineLearning/comments/5i4g7f/only_one_bias_per_feature_map_in_cnns/,twrayy,1481645900,[removed],0,1,False,default,,,,,
438,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,1,5i4i2h,twitter.com,"/r/MachineLearning now on Twitter, @slashML",https://www.reddit.com/r/MachineLearning/comments/5i4i2h/rmachinelearning_now_on_twitter_slashml/,olaf_nij,1481646426,,0,2,False,default,,,,,
439,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,1,5i4jd0,twitter.com,[D] /r/MachineLearning now on Twitter (@slashML),https://www.reddit.com/r/MachineLearning/comments/5i4jd0/d_rmachinelearning_now_on_twitter_slashml/,olaf_nij,1481646794,,4,34,False,http://b.thumbs.redditmedia.com/gUdws8eg--MGSg25EfretaMwkifYyFKrPnlnTAkpZTc.jpg,,,,,
440,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,1,5i4lct,keithselover.wordpress.com,Using Scikit Learn Algos on Global Stock Index Data,https://www.reddit.com/r/MachineLearning/comments/5i4lct/using_scikit_learn_algos_on_global_stock_index/,[deleted],1481647358,[deleted],0,1,False,default,,,,,
441,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,1,5i4nj9,keithselover.wordpress.com,Using Scikit Learn Algos on Global Stock Index Data,https://www.reddit.com/r/MachineLearning/comments/5i4nj9/using_scikit_learn_algos_on_global_stock_index/,[deleted],1481647974,[deleted],0,1,False,default,,,,,
442,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,2,5i50th,self.MachineLearning,Understanding LSTM in Keras,https://www.reddit.com/r/MachineLearning/comments/5i50th/understanding_lstm_in_keras/,Tsadkiel,1481651756,[removed],0,1,False,default,,,,,
443,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,5,5i64l4,filez.in,Download python machine learning ebook pdf pdf,https://www.reddit.com/r/MachineLearning/comments/5i64l4/download_python_machine_learning_ebook_pdf_pdf/,rudrodipto,1481662508,,0,1,False,default,,,,,
444,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,6,5i672k,willwolf.io,Generating World Flags with Sparse Auto-Encoders,https://www.reddit.com/r/MachineLearning/comments/5i672k/generating_world_flags_with_sparse_autoencoders/,cavaunpeu,1481663189,,0,1,False,default,,,,,
445,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,6,5i67q3,richard-alan-herbert.com,[D] A Thought Experiment on the Future of Text Generation,https://www.reddit.com/r/MachineLearning/comments/5i67q3/d_a_thought_experiment_on_the_future_of_text/,Staturecrane,1481663352,,15,47,False,http://b.thumbs.redditmedia.com/10MgCoDOBMpbA53LevH5cIikyW0sNmvert5t-wb-Zig.jpg,,,,,
446,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,6,5i6a3v,github.com,Tensorflow implementation of Glove,https://www.reddit.com/r/MachineLearning/comments/5i6a3v/tensorflow_implementation_of_glove/,shash273,1481664003,,0,1,False,default,,,,,
447,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,6,5i6dwo,self.MachineLearning,Industry research groups/labs?,https://www.reddit.com/r/MachineLearning/comments/5i6dwo/industry_research_groupslabs/,[deleted],1481665055,[removed],0,1,False,default,,,,,
448,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,6,5i6hny,arstechnica.co.uk,[N] AMDs Zen CPU is now called Ryzen; uses neural net in scheduler,https://www.reddit.com/r/MachineLearning/comments/5i6hny/n_amds_zen_cpu_is_now_called_ryzen_uses_neural/,omniron,1481666112,,4,7,False,default,,,,,
449,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,7,5i6tza,arxiv.org,[R] [1612.03770] Neurogenesis Deep Learning,https://www.reddit.com/r/MachineLearning/comments/5i6tza/r_161203770_neurogenesis_deep_learning/,jimfleming,1481669580,,8,25,False,default,,,,,
450,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,8,5i6vwu,youtube.com,Intro to Autoencoders (livestream),https://www.reddit.com/r/MachineLearning/comments/5i6vwu/intro_to_autoencoders_livestream/,vanboxel,1481670139,,0,1,False,default,,,,,
451,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,8,5i6xo0,self.MachineLearning,Best/most interesting videos at NIPS?,https://www.reddit.com/r/MachineLearning/comments/5i6xo0/bestmost_interesting_videos_at_nips/,spurious_recollectio,1481670653,[removed],0,1,False,default,,,,,
452,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,10,5i7r51,self.MachineLearning,"Collaborative filtering with factorization machine (steffen rendle), how does it work?",https://www.reddit.com/r/MachineLearning/comments/5i7r51/collaborative_filtering_with_factorization/,flittiflanke,1481679882,[removed],0,1,False,default,,,,,
453,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,10,5i7s96,arxiv.org,TF.Learn: TensorFlow's High-level Module for Distributed Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5i7s96/tflearn_tensorflows_highlevel_module_for/,[deleted],1481680251,[deleted],0,1,False,default,,,,,
454,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,11,5i7vlo,self.MachineLearning,My Article on Stacking (i.e. Meta Ensembling),https://www.reddit.com/r/MachineLearning/comments/5i7vlo/my_article_on_stacking_ie_meta_ensembling/,Neb519,1481681338,[removed],0,2,False,default,,,,,
455,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,11,5i7zix,arxiv.org,[P] TF.Learn: TensorFlow's High-level Module for Distributed Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5i7zix/p_tflearn_tensorflows_highlevel_module_for/,[deleted],1481682597,[deleted],0,0,False,default,,,,,
456,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,12,5i8dow,youtu.be,Why hydraulic compost windrow turner?,https://www.reddit.com/r/MachineLearning/comments/5i8dow/why_hydraulic_compost_windrow_turner/,frady2015,1481687230,,1,1,False,default,,,,,
457,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,13,5i8g1o,self.MachineLearning,[D] Is Homomorphic encryption for ML practical?,https://www.reddit.com/r/MachineLearning/comments/5i8g1o/d_is_homomorphic_encryption_for_ml_practical/,[deleted],1481688060,[deleted],10,5,False,default,,,,,
458,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,13,5i8hee,self.MachineLearning,"Background in engineering, best online resources/course(s) to learn machine learning?",https://www.reddit.com/r/MachineLearning/comments/5i8hee/background_in_engineering_best_online/,satchelf,1481688504,[removed],0,1,False,default,,,,,
459,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,13,5i8hhw,baohanhdienmay.vn,u nhc im ca dng my git Toshiba - 0439.111.000,https://www.reddit.com/r/MachineLearning/comments/5i8hhw/u_nhc_im_ca_dng_my_git_toshiba_0439111000/,Toan_Hg,1481688537,,0,1,False,default,,,,,
460,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,13,5i8jp6,maidentales.com,Machine Learning meets Astrophysics,https://www.reddit.com/r/MachineLearning/comments/5i8jp6/machine_learning_meets_astrophysics/,aakashsing,1481689334,,0,1,False,default,,,,,
461,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,13,5i8nhk,github.com,"Quickly view satellite imagery, hyperspectral imagery, and machine learning image outputs directly in your iTerm2 terminal.",https://www.reddit.com/r/MachineLearning/comments/5i8nhk/quickly_view_satellite_imagery_hyperspectral/,daleroberts0,1481690669,,0,1,False,default,,,,,
462,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,14,5i8rhi,reverieinc.com,Inside the Mechanics of Machine Learning: Word Vectors (Part I),https://www.reddit.com/r/MachineLearning/comments/5i8rhi/inside_the_mechanics_of_machine_learning_word/,RadzM,1481692150,,0,1,False,default,,,,,
463,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,15,5i940e,self.MachineLearning,[D] How does Batch Normalization not completely prevent the network from being able to train at all?,https://www.reddit.com/r/MachineLearning/comments/5i940e/d_how_does_batch_normalization_not_completely/,MildlyCriticalRole,1481697225,"First, I do understand that BN *does* work; I just don't understand how arbitrarily changing the distribution of every mini-batch doesn't throw everything completely out of whack.

For example, let's say you were (for some reason) training a network to match a number to a letter grade.

Your first training batch is (A, 90), (B, 80), (C, 70)
You normalize it and the B data point becomes (B, 0) - ignoring the constant factor since that's basically just another linear layer.

Your second training batch is (D, 60), (D, 60), (D, 60)
Now you have 3 data points that say (D, 0) - but your network just spent time learning that 0 meant B.

How does this sort of transformation not break down training in its entirety?

Even though you definitely normalized your features before-hand, aren't mini-batches going to end up having significantly differing means and variances that end up throwing everything off? (x^i, 0.1) in one batch might mean something completely different than (x^i, 0.1) in another.

What's my fundamental misunderstanding here? Apologies if this is a simple question; I haven't been able to find any answer to this on the web, since I'm assuming it's more of my failure to understand statistics than ML specifically.",36,40,False,self,,,,,
464,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,15,5i97dz,self.MachineLearning,[D] Advice on Training Highway RNN (RHN),https://www.reddit.com/r/MachineLearning/comments/5i97dz/d_advice_on_training_highway_rnn_rhn/,throwaway775849,1481698727,"Seeking advice on training difficulties for an autoencoder

I'm using RHN cells for an encoder, but the resulting encodings after training are all too similar (~5 decimal places of similarity).
For example:  
     
     encoding 1 -&gt; [0.000123456, -0.0000456, ...]   
     encoding 2 -&gt; [0.000124191, -0.0000391, ...] 

Too similar - **the decoder is invariant to the small changes and produces the same result for every input** (However the result has perfect syntax!). So I investigated and added noise across the encodings in different ranges. Feeding Encoding * RandomNoise(-1000, 1000) to the decoder successfully made new output, whereas smaller ranges such as (-1, 1) did not.

My first instinct - some initialization is in the wrong spectrum of decimal precision (ex. truncated_normal_initializer(1e-4) should really be 1e-1, or something like that). I fixed one or two initializations, and cranked the learning rate up to 1.0. 

Success! My encodings are primed to live in a better range now. I haven't verified that the encodings maintain their integrity after training though.

Why does this problem exist both before and after training? 

* During training, why is the magnitude of the weight updates so small to the encoder parameters, and should I be looking to increase it? 

* Are there good rules of thumb for scaling initialization parameters? 


I don't feel satisfied with my current solution and I'd be happy to provide more info on the initializations used if that will help.

How would you fine folks approach this?",4,3,False,self,,,,,
465,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,16,5i97rj,dzone.com,Data Science Start-Ups in Focus: BigML,https://www.reddit.com/r/MachineLearning/comments/5i97rj/data_science_startups_in_focus_bigml/,Sibanjan,1481698900,,0,1,False,default,,,,,
466,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,16,5i9eld,dmitryulyanov.github.io,Neural texture synthesis and style transfer for audio,https://www.reddit.com/r/MachineLearning/comments/5i9eld/neural_texture_synthesis_and_style_transfer_for/,[deleted],1481702280,[deleted],0,1,False,default,,,,,
467,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,17,5i9i33,self.MachineLearning,[D] Is there a differentiable activation function that simulates an argmax to return discrete outputs?,https://www.reddit.com/r/MachineLearning/comments/5i9i33/d_is_there_a_differentiable_activation_function/,cjmcmurtrie,1481704002,"I was wondering if anyone has thought about this. What I'm looking for is essentially an activation function that will return discrete outputs (like a one-hot code), and that is differentiable during backpropagation.

I have messed around blindly with nn.ArgMax in dpnn, but learning is unstable and generally unsuccessful (though not completely absent) for a moderate dataset. I find learning to be heavily biased to the 2-3 most common categories in the distribution. Some more research led me to the Gumbel-Softmax, which I'm playing with now, so far without much success:

https://arxiv.org/pdf/1611.01144v1.pdf

Any takers?",15,7,False,self,,,,,
468,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,17,5i9jf9,arxiv.org,[R] Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer,https://www.reddit.com/r/MachineLearning/comments/5i9jf9/r_paying_more_attention_to_attention_improving/,xternalz,1481704755,,7,11,False,default,,,,,
469,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,18,5i9mib,dmitryulyanov.github.io,[P] Neural texture synthesis and style transfer for audio,https://www.reddit.com/r/MachineLearning/comments/5i9mib/p_neural_texture_synthesis_and_style_transfer_for/,dmitry_ulyanov,1481706384,,13,56,False,http://b.thumbs.redditmedia.com/1YAhTmB04oHps48ZvWVF_KQEkBLDIzRWdZkIwlxGmFI.jpg,,,,,
470,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,18,5i9n4h,self.MachineLearning,Managed Machine Learning Prediction Server,https://www.reddit.com/r/MachineLearning/comments/5i9n4h/managed_machine_learning_prediction_server/,mitbal,1481706684,[removed],0,1,False,default,,,,,
471,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,18,5i9rwy,tecmint.com,Deal: Get Machine Learning and Artificial Intelligence Course (91% Off),https://www.reddit.com/r/MachineLearning/comments/5i9rwy/deal_get_machine_learning_and_artificial/,ravisaive,1481709147,,0,1,False,default,,,,,
472,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,19,5i9wgv,en.wikipedia.org,"skills that appear effortless to be difficult to reverse-engineer, but skills that require effort may not necessarily be difficult to engineer at all.",https://www.reddit.com/r/MachineLearning/comments/5i9wgv/skills_that_appear_effortless_to_be_difficult_to/,sarker306,1481711434,,0,1,False,default,,,,,
473,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,21,5iabbl,self.MachineLearning,Want a happier on-call team? Apply Machine Learning to your alerts system!,https://www.reddit.com/r/MachineLearning/comments/5iabbl/want_a_happier_oncall_team_apply_machine_learning/,Everything_Cyber,1481718606,[removed],0,1,False,default,,,,,
474,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,23,5iapuv,blog.hackerearth.com,Learn &amp; build predictive models using Bagging and Random Forest algorithm from scratch. [x-post r/hackerearth],https://www.reddit.com/r/MachineLearning/comments/5iapuv/learn_build_predictive_models_using_bagging_and/,NarendhiranS,1481724189,,0,1,False,default,,,,,
475,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,23,5ias0w,i.redd.it,[D] Is deep learning progress principled / comprehensible?,https://www.reddit.com/r/MachineLearning/comments/5ias0w/d_is_deep_learning_progress_principled/,[deleted],1481724929,[deleted],0,1,False,default,,,,,
476,MachineLearning,t5_2r3gv,2016-12-14,2016,12,14,23,5iatrr,dublin.zhaw.ch,[D] Is deep learning progress principled / comprehensible?,https://www.reddit.com/r/MachineLearning/comments/5iatrr/d_is_deep_learning_progress_principled/,ThiloSt,1481725531,,0,3,False,http://b.thumbs.redditmedia.com/hM06lzJX6yhCBYQwATP4mfpnt2O_j3k_S3v7xKHGwQg.jpg,,,,,
477,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,0,5ib12o,self.MachineLearning,Minibatch SGD gradient computation- average or sum,https://www.reddit.com/r/MachineLearning/comments/5ib12o/minibatch_sgd_gradient_computation_average_or_sum/,roger_genbot,1481727905,[removed],0,1,False,default,,,,,
478,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,0,5ib4jf,inference.vc,"[Discussion] Summary of NIPS 2016 Adversarial Training Workshop: More Theory, Exciting Progress",https://www.reddit.com/r/MachineLearning/comments/5ib4jf/discussion_summary_of_nips_2016_adversarial/,fhuszar,1481728967,,8,22,False,http://b.thumbs.redditmedia.com/PRbaF4VWjnKDosGWgrKAAN9HpwUoAb4GmGJj2_YOzuw.jpg,,,,,
479,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,0,5ib6n0,github.com,NIPS 2016 slides and videos,https://www.reddit.com/r/MachineLearning/comments/5ib6n0/nips_2016_slides_and_videos/,[deleted],1481729586,[deleted],0,1,False,default,,,,,
480,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,0,5ib8ro,github.com,[P] NIPS 2016 slides and videos,https://www.reddit.com/r/MachineLearning/comments/5ib8ro/p_nips_2016_slides_and_videos/,hindupuravinash,1481730200,,1,27,False,http://b.thumbs.redditmedia.com/ptazb1dIUiKsarXo5jpyP6Ej7t7yz7UQaM6BMu75MSo.jpg,,,,,
481,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,0,5ibaky,self.MachineLearning,"Simple Questions Thread December 14, 2016",https://www.reddit.com/r/MachineLearning/comments/5ibaky/simple_questions_thread_december_14_2016/,AutoModerator,1481730754,[removed],0,1,False,default,,,,,
482,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,0,5ibbyq,self.MachineLearning,[NIPS 2016]Has anyone dabbled with the WebNav code?,https://www.reddit.com/r/MachineLearning/comments/5ibbyq/nips_2016has_anyone_dabbled_with_the_webnav_code/,spoiltForChoice,1481731173,[removed],0,1,False,default,,,,,
483,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,1,5ibcdy,self.MachineLearning,Has anyone read Neural Networks and Fuzzy Systems: A Dynamical Systems Approach to Machine Intelligence/Book?,https://www.reddit.com/r/MachineLearning/comments/5ibcdy/has_anyone_read_neural_networks_and_fuzzy_systems/,bagelorder,1481731286,[removed],0,1,False,default,,,,,
484,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,1,5ibjav,twitter.com,"[N] Jrgen Schmidhuber: There was no real progress towards AI at this year's #nips2016 (yes, that includes work from my lab)...",https://www.reddit.com/r/MachineLearning/comments/5ibjav/n_jrgen_schmidhuber_there_was_no_real_progress/,WhoCanVeirfy,1481733245,,7,1,False,default,,,,,
485,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,1,5ibni2,self.MachineLearning,Looking for resources for applying neural networks to more structured data.,https://www.reddit.com/r/MachineLearning/comments/5ibni2/looking_for_resources_for_applying_neural/,spotta,1481734395,[removed],0,1,False,default,,,,,
486,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,2,5ibqqk,arxiv.org,[R] Understanding How Image Quality Affects Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/5ibqqk/r_understanding_how_image_quality_affects_deep/,rndnum123,1481735282,,19,18,False,default,,,,,
487,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,2,5ibzzq,self.MachineLearning,[D] Building a Baseline approach for closed-domain Question Answering,https://www.reddit.com/r/MachineLearning/comments/5ibzzq/d_building_a_baseline_approach_for_closeddomain/,jayjaymz,1481737783,"Hello,
I'm trying to design a baseline approach for closed domain answering. Assuming there is either 

A. a question - answer pair database, or

B. a question - document containing answer + answer database.

I've looked around the literature and found many discussions, especially for open-domain question answering. I haven't been able to start building though.

Where does one start with designing &amp; building such a system. Are there basic tried methods? How far can such a system go without using ""deep learning""?

Any links, tutorials, papers or advice is welcome, thank you for your time!",1,7,False,self,,,,,
488,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,3,5ic92l,making.duolingo.com,"Duolingo's ""half-life regression"" method for modeling human memory",https://www.reddit.com/r/MachineLearning/comments/5ic92l/duolingos_halflife_regression_method_for_modeling/,tatou27,1481740214,,0,2,False,default,,,,,
489,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,3,5icbpj,making.duolingo.com,"[D] Duolingo's ""half-life regression"" method for modeling human memory",https://www.reddit.com/r/MachineLearning/comments/5icbpj/d_duolingos_halflife_regression_method_for/,tatou27,1481740938,,25,289,False,http://b.thumbs.redditmedia.com/zomzmqQZ5pEWV-Au7dLOF8IPB-mIiTdwSXsy_dmetME.jpg,,,,,
490,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,4,5icrrv,youtube.com,How to Make a Path Planning Algorithm Easily (Live Stream),https://www.reddit.com/r/MachineLearning/comments/5icrrv/how_to_make_a_path_planning_algorithm_easily_live/,llSourcell,1481745376,,0,1,False,default,,,,,
491,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,5,5icw3o,github.com,Snape: A Package for Generating 'Realistic' Synthetic ML Datasets,https://www.reddit.com/r/MachineLearning/comments/5icw3o/snape_a_package_for_generating_realistic/,justmike77,1481746554,,3,5,False,default,,,,,
492,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,5,5icx8r,self.MachineLearning,Training with imperfect training data,https://www.reddit.com/r/MachineLearning/comments/5icx8r/training_with_imperfect_training_data/,WorkoutWinner,1481746884,[removed],0,1,False,default,,,,,
493,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,6,5idges,koaning.io,Neural Autoencoders as a User Interface,https://www.reddit.com/r/MachineLearning/comments/5idges/neural_autoencoders_as_a_user_interface/,cantdutchthis,1481752235,,0,1,False,default,,,,,
494,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,8,5ie4gu,self.MachineLearning,Any resources to get into learning neural networks / computer vision?,https://www.reddit.com/r/MachineLearning/comments/5ie4gu/any_resources_to_get_into_learning_neural/,[deleted],1481759249,[removed],0,1,False,default,,,,,
495,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,8,5ie4nf,nytimes.com,NYTimes Magazine Feature on Google Brain,https://www.reddit.com/r/MachineLearning/comments/5ie4nf/nytimes_magazine_feature_on_google_brain/,jamesvoltage,1481759307,,0,3,False,default,,,,,
496,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,10,5ieiq7,self.MachineLearning,[Discussion] Cold-emailing ML researchers with potential findings regarding their work - how should I approach this as a complete outsider?,https://www.reddit.com/r/MachineLearning/comments/5ieiq7/discussion_coldemailing_ml_researchers_with/,xristaforante,1481763799,"Hello,

I suspect that I have demonstrated something that would be of interest to the authors of a paper I've been studying, so I would like to offer my insight to them. There's always a catch, and that is that I have no affiliation with ML at present and have no reputation of substance in academia for that matter. I'm only an undergrad. I'm wary of being overlooked on account of this, and maybe rightfully so, but my math seems to be experimentally-solid. My only option really is to cold-email them. How can I approach this effectively and catch their interest?",17,8,False,self,,,,,
497,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,10,5iescg,arxiv.org,[R] Wider or Deeper: Revisiting the ResNet Model for Visual Recognition,https://www.reddit.com/r/MachineLearning/comments/5iescg/r_wider_or_deeper_revisiting_the_resnet_model_for/,xternalz,1481767015,,5,23,False,default,,,,,
498,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,11,5ievyu,youtu.be,Neural network styled We Are Number One!,https://www.reddit.com/r/MachineLearning/comments/5ievyu/neural_network_styled_we_are_number_one/,widdakay,1481768230,,0,1,False,default,,,,,
499,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,11,5iez3u,arxiv.org,[1612.04530] Permutation-equivariant neural networks applied to dynamics prediction,https://www.reddit.com/r/MachineLearning/comments/5iez3u/161204530_permutationequivariant_neural_networks/,[deleted],1481769301,[deleted],0,1,False,default,,,,,
500,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,12,5if40d,smartsheet.io,[P] Implementation of Linear Regression for the Lay Man - Smartsheet,https://www.reddit.com/r/MachineLearning/comments/5if40d/p_implementation_of_linear_regression_for_the_lay/,The18thWarrior,1481770950,,0,0,False,default,,,,,
501,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,13,5ife6t,nytimes.com,The Great A.I. Awakening - New York Times,https://www.reddit.com/r/MachineLearning/comments/5ife6t/the_great_ai_awakening_new_york_times/,[deleted],1481774539,[deleted],0,1,False,default,,,,,
502,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,13,5ifil1,self.MachineLearning,How does optimizing for multiple loss functions work?,https://www.reddit.com/r/MachineLearning/comments/5ifil1/how_does_optimizing_for_multiple_loss_functions/,gidime,1481776224,[removed],0,1,False,default,,,,,
503,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,13,5ifm4s,arxiv.org,[R] [1612.04530] Permutation-equivariant neural networks applied to dynamics prediction,https://www.reddit.com/r/MachineLearning/comments/5ifm4s/r_161204530_permutationequivariant_neural/,NichG,1481777627,,2,11,False,default,,,,,
504,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,15,5ig47y,self.MachineLearning,NLP positive data augmentation,https://www.reddit.com/r/MachineLearning/comments/5ig47y/nlp_positive_data_augmentation/,FutureIsMine,1481784752,[removed],0,1,False,default,,,,,
505,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,16,5ig6i3,ncbi.nlm.nih.gov,[R] Toward an Integration of Deep Learning and Neuroscience,https://www.reddit.com/r/MachineLearning/comments/5ig6i3/r_toward_an_integration_of_deep_learning_and/,downtownslim,1481785705,,29,30,False,default,,,,,
506,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,16,5igcf8,trendintech.com,Can Machine Learning Be Used to Solve Social Problems?,https://www.reddit.com/r/MachineLearning/comments/5igcf8/can_machine_learning_be_used_to_solve_social/,TinTMag,1481788600,,0,1,False,default,,,,,
507,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,17,5igeua,cytora.com,"The internet is a powerful lens for observing the world, and we use machine learning to make sense of it.",https://www.reddit.com/r/MachineLearning/comments/5igeua/the_internet_is_a_powerful_lens_for_observing_the/,Cytora,1481789800,,0,1,False,default,,,,,
508,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,17,5igjei,mljar.com,How we get #6th place on Kaggle with automatic solution,https://www.reddit.com/r/MachineLearning/comments/5igjei/how_we_get_6th_place_on_kaggle_with_automatic/,[deleted],1481792291,[deleted],0,1,False,default,,,,,
509,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,18,5igks5,mljar.com,[P] How we get #6th place on Kaggle with automatic solution,https://www.reddit.com/r/MachineLearning/comments/5igks5/p_how_we_get_6th_place_on_kaggle_with_automatic/,[deleted],1481793003,[deleted],1,0,False,default,,,,,
510,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,18,5igmhl,techcrunch.com,Researchers use machine learning to pull interest signals from readers brain waves,https://www.reddit.com/r/MachineLearning/comments/5igmhl/researchers_use_machine_learning_to_pull_interest/,Johnmack013,1481793878,,0,1,False,default,,,,,
511,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,18,5igp31,talung.gimyong.com,,https://www.reddit.com/r/MachineLearning/comments/5igp31//,casillas17,1481795223,,0,1,False,default,,,,,
512,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,19,5igtjl,self.MachineLearning,Help Needed with Image Processing/recognition!,https://www.reddit.com/r/MachineLearning/comments/5igtjl/help_needed_with_image_processingrecognition/,NotThatLebowski,1481797526,[removed],0,1,False,default,,,,,
513,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,19,5igulc,self.MachineLearning,How do you compress multiple filtered images into one in a convolutional network.,https://www.reddit.com/r/MachineLearning/comments/5igulc/how_do_you_compress_multiple_filtered_images_into/,Camcrazy,1481798092,[removed],0,1,False,default,,,,,
514,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,20,5ih4gd,technologyreview.com,[N] How Long Before AI Systems Are Hacked in Creative New Ways?,https://www.reddit.com/r/MachineLearning/comments/5ih4gd/n_how_long_before_ai_systems_are_hacked_in/,rgermanov,1481802973,,0,1,False,default,,,,,
515,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,22,5iheis,self.MachineLearning,automatic hyperparameter optimization for deep learning,https://www.reddit.com/r/MachineLearning/comments/5iheis/automatic_hyperparameter_optimization_for_deep/,[deleted],1481807159,[removed],0,1,False,default,,,,,
516,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,22,5ihhxq,self.MachineLearning,"""[P]"" automatic hyperparameter optimization for deep learning",https://www.reddit.com/r/MachineLearning/comments/5ihhxq/p_automatic_hyperparameter_optimization_for_deep/,KarenUllrich,1481808451,"Spearmint is a framework for hp optimization that is out there since some time now, however, I have rarely seen it in the deep learning community yet.

This is why I made a [spearmint fork](https://github.com/KarenUllrich/Spearmint-TheanoEdition) that includes

(A) an MNIST example (what else :))

(B) support to run spearmint on multiple GPUs

I hope that makes the entry to use automatic hp optimizers easier. ATM it's only for theano but it is certainly easily extendable. Feel free to contribute and use it!",7,24,False,self,,,,,
517,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,22,5ihjnf,self.MachineLearning,[D] what's the best way to deal with tree as data?,https://www.reddit.com/r/MachineLearning/comments/5ihjnf/d_whats_the_best_way_to_deal_with_tree_as_data/,hapliniste,1481809095,[removed],1,5,False,default,,,,,
518,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,23,5ihpqi,producthunt.com,[News] A Linux desktop in the cloud built for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5ihpqi/news_a_linux_desktop_in_the_cloud_built_for/,gvaldes1,1481811264,,2,7,False,default,,,,,
519,MachineLearning,t5_2r3gv,2016-12-15,2016,12,15,23,5ihsss,self.MachineLearning,Please help find the paper source,https://www.reddit.com/r/MachineLearning/comments/5ihsss/please_help_find_the_paper_source/,Oleicas,1481812282,[removed],0,1,False,default,,,,,
520,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,0,5ii5dh,pocketcluster.wordpress.com,"Machine Learning Library and Model Weekly Roundup  Dec. 15, 2016",https://www.reddit.com/r/MachineLearning/comments/5ii5dh/machine_learning_library_and_model_weekly_roundup/,stkim1,1481816277,,0,1,False,default,,,,,
521,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,1,5iigl2,mljar.com,[N] Predictive API comparison: MLJAR vs Amazon ML vs Google ML vs PredicSis vs BigML,https://www.reddit.com/r/MachineLearning/comments/5iigl2/n_predictive_api_comparison_mljar_vs_amazon_ml_vs/,[deleted],1481819556,[deleted],0,1,False,default,,,,,
522,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,2,5iis1m,github.com,[P] Python library for writing interactive visualizations,https://www.reddit.com/r/MachineLearning/comments/5iis1m/p_python_library_for_writing_interactive/,qacek,1481822707,,7,50,False,http://a.thumbs.redditmedia.com/Uv8NcT55lLN73tloscb3r3ybUBUbs4zM3LqxeeKafd8.jpg,,,,,
523,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,2,5iiypr,venturebeat.com,[N] Big data software company Databricks raises $60 million for Spark etc.,https://www.reddit.com/r/MachineLearning/comments/5iiypr/n_big_data_software_company_databricks_raises_60/,vonnik,1481824638,,0,1,False,default,,,,,
524,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,3,5ij19b,maluuba.com,[R] Decomposing Tasks like Humans: Scaling Reinforcement Learning By Separation of Concerns,https://www.reddit.com/r/MachineLearning/comments/5ij19b/r_decomposing_tasks_like_humans_scaling/,pierrelux,1481825319,,3,24,False,http://b.thumbs.redditmedia.com/NLWSLma1QDZlzjHupA-lnw40Dj7YUJfZFA9ZJclK-Bc.jpg,,,,,
525,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,4,5ije23,github.com,"I just finished writing a book on TensorFlow, and here's the full source code. In the coming weeks, I'll be annotating and explaining each concept. Come follow along!",https://www.reddit.com/r/MachineLearning/comments/5ije23/i_just_finished_writing_a_book_on_tensorflow_and/,[deleted],1481828828,[deleted],0,1,False,default,,,,,
526,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,4,5ijm4o,arxiv.org,"[R] Generative Adversarial Parallelization: GANs are trained simultaneously, exchanging their discriminators",https://www.reddit.com/r/MachineLearning/comments/5ijm4o/r_generative_adversarial_parallelization_gans_are/,downtownslim,1481831065,,8,46,False,default,,,,,
527,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,4,5ijn9j,self.MachineLearning,"WEKA: takes way too much time to run SMOreg on 9,000 data under Experiment. What should I do?",https://www.reddit.com/r/MachineLearning/comments/5ijn9j/weka_takes_way_too_much_time_to_run_smoreg_on/,kleinblue2015,1481831395,[removed],0,1,False,default,,,,,
528,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,4,5ijnnb,github.com,"[P] All code from ""Machine Learning with TensorFlow"" is now available on GitHub",https://www.reddit.com/r/MachineLearning/comments/5ijnnb/p_all_code_from_machine_learning_with_tensorflow/,CarbonFire,1481831505,,6,192,False,http://b.thumbs.redditmedia.com/k5VS4uKaMw0-FzBqlk5yKJcjz_a5RbGGuRvKVJaeJbc.jpg,,,,,
529,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,5,5ijpgx,self.MachineLearning,"Would you help me about the formula deployment of Bayesian GPLVM(Michalis K. Titsias, 2010)",https://www.reddit.com/r/MachineLearning/comments/5ijpgx/would_you_help_me_about_the_formula_deployment_of/,nishinari_ailina,1481832012,[removed],1,1,False,default,,,,,
530,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,5,5ijpwt,github.com,[Project] Implementation of a ConvLSTM cell for TensorFlow,https://www.reddit.com/r/MachineLearning/comments/5ijpwt/project_implementation_of_a_convlstm_cell_for/,carlthome,1481832125,,8,21,False,http://b.thumbs.redditmedia.com/61YFksrlRwiEmTdfLmFLbntCs6SJ_52QKFnSevw_mEo.jpg,,,,,
531,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,6,5ik9rw,reddit.com,We are the authors of Algorithms to Live By: The Computer Science of Human Decisions. Ask Us Anything!,https://www.reddit.com/r/MachineLearning/comments/5ik9rw/we_are_the_authors_of_algorithms_to_live_by_the/,anonDogeLover,1481837745,,0,1,False,default,,,,,
532,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,6,5ikc1o,gab41.lab41.org,[R] Swapout: Learning an Ensemble of Deep Architectures,https://www.reddit.com/r/MachineLearning/comments/5ikc1o/r_swapout_learning_an_ensemble_of_deep/,amplifier_khan,1481838401,,0,1,False,default,,,,,
533,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,7,5ikhzk,arxiv.org,[1612.04357] Stacked Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/5ikhzk/161204357_stacked_generative_adversarial_networks/,rz16,1481840089,,1,1,False,default,,,,,
534,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,7,5ikjei,medium.com,"The full story behind ""AI Start-up"" Rocket AI at NIPS 2016",https://www.reddit.com/r/MachineLearning/comments/5ikjei/the_full_story_behind_ai_startup_rocket_ai_at/,[deleted],1481840501,[deleted],0,1,False,default,,,,,
535,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,7,5iklm0,medium.com,"[N] The full story behind ""AI Start-up"" Rocket AI at NIPS 2016",https://www.reddit.com/r/MachineLearning/comments/5iklm0/n_the_full_story_behind_ai_startup_rocket_ai_at/,tidier,1481841162,,11,29,False,http://a.thumbs.redditmedia.com/A2XXG5YEr1wjDtjduY7A2MScAOWAmW5SPxTqe8-IVV4.jpg,,,,,
536,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,8,5ikuf1,self.MachineLearning,Ladder Network on CIFAR,https://www.reddit.com/r/MachineLearning/comments/5ikuf1/ladder_network_on_cifar/,[deleted],1481843892,[removed],0,1,False,default,,,,,
537,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,10,5ilhd7,self.MachineLearning,[D]Random Forest Based Character Level Language Model,https://www.reddit.com/r/MachineLearning/comments/5ilhd7/drandom_forest_based_character_level_language/,godspeed_china,1481851407,"Inspired by char-rnn, I tried to develop a random forest analogue.  
The method keeps a sliding window (eg. 32 chars) to predict the next character.  
A specially designed Random Forest is used to grow trees directly on the text instead of transforming the text into matrix data form.  
We grow one random forest classifier for each symbol in the character set.  
The take home message is that such model works! We can repeatedly sample characters and obtain a good text, similar to char-rnn. However, this model is much easier to understand: there is no magic at all.  
Some sampled text here (trained on ankylosing spondylitis gene abstracts):  
  
  

 ) were disease and the significantly higher in the patients with AS and the controls from the haplotpes were associated with AS in the Chinese population and and on a the association of and controls (P and 1on unde Allele controls (a t 0.00tion and the polymorphisms and haplotypes and controls in on patients with AS and of the oothl (rt fise and and the results susceptibility to AS in patients with AS and hhe eations and the TNalle of the some and Cet in patients wit AS If a the associatio of the predious and of patients with AS and patients with AS and polymorphisms and Bhe controls (ore 0erolted and markers and the gene for the rs10087, were inalleed in the disease and a segint the presenting the significant differences between and the disease. Rere and the red by the associa of in the controls (ere genotyped for single nucleotide polymorhisms (SNPs) in the study gene haplotype was associaed with AS in the pathogenesis of AS patients andc of the significntly increased in the associa of the pathogenesis of AS. He and cere sere controls (s = 0.00) and rs104o9 the in the patients with AS and was associaed with ankylosing sondylitis (AS). AETHODS: A pothNas were several and rs1ression and controls (f and the associa develop and the sthection fred the Tight in the studies of the results susceptibility to AS in several subinding and the pering featent the controls (f the alleles were analysis of strong and pime in the pathogenesis of AS. The and of the HLA-B27 positive controls (ore and the pNesent significant differences in the controls (an and Seuin markers of the susceptibility to AS in the patients with AS and 1hinese population haplotype analysis in the pathogenesis of AS patiets and 1on and the associatio of in the pathogenesis of AS. the previous was severom and controls (n = 0.01) and controls (aspend disease and 5enterb and the controls and the associaion of the HLA-B27 (ight controls (n and single nucleotid and the associaion between and recent relative and the development of in the controls (s = 0.00s and the polymorphisms gene alleles were associaion with AS susceptibility to AS, and DN2 vS patiets and res healthy contols were analysis of the Ters and the associaion with AS in the Cest rare and the suggest polymorphisms and ef the HLA-B27 positive and the markers (o and controls and reen and 1o and the rene aor associated wit ankylosingspondylitis (AS) and Tean",6,4,False,self,,,,,
538,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,10,5iliuh,arxiv.org,[R] The More You Know: Using Knowledge Graphs for Image Classification,https://www.reddit.com/r/MachineLearning/comments/5iliuh/r_the_more_you_know_using_knowledge_graphs_for/,2deeplearning4me,1481851918,,1,5,False,default,,,,,
539,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,10,5iljph,self.MachineLearning,[D] Character Embedding shape for convolutions,https://www.reddit.com/r/MachineLearning/comments/5iljph/d_character_embedding_shape_for_convolutions/,TheCriticalSkeptic,1481852217,"I want to try a text classifier using character level convolutions. I wasn't sure on the best shape to transform the character embedding into for 2D convolutions. 

If I have batch size b, sequence length l, and embedding size e, then once I get the embedding for each character should I either:

a) Reshape to [b, l, e 1] and use the embedding dimension as a height, or
b) Reshape to [b, l, 1, e] and use the embedding dimension as channels

From some quick reading online it seems like (a) is the way to go but my first assumption would have been (b).",1,2,False,self,,,,,
540,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,10,5ilku9,cleverhans.io,[R] Breaking things is easy - Machine learning security and privacy,https://www.reddit.com/r/MachineLearning/comments/5ilku9/r_breaking_things_is_easy_machine_learning/,clbam8,1481852605,,0,28,False,http://b.thumbs.redditmedia.com/ctXyLnpUqfM1c-XvYa72iIu7HRK_XxtLOYcwiNdrOnY.jpg,,,,,
541,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,11,5ilvqp,i.redd.it,I think I'm ready to take on Watson.,https://www.reddit.com/r/MachineLearning/comments/5ilvqp/i_think_im_ready_to_take_on_watson/,[deleted],1481856408,[deleted],0,1,False,default,,,,,
542,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,13,5im864,self.MachineLearning,[D] Novel pattern recognition architecture worth attempting to publish?,https://www.reddit.com/r/MachineLearning/comments/5im864/d_novel_pattern_recognition_architecture_worth/,sirilovescortana,1481860915,"Hello, 

I'm looking for input on something I've been working on for the last year. I have a simple, novel learning algorithm that trains and achieves &lt;4% error on the MNIST test set, in less than 20 seconds in a single-threaded application on my Macbook Air. I'm a SW engineer working on a patent through my company in my spare time, but what I really want is to go to grad school for ML and/or Neuro. Consequently, I'd like to publish my results to increase my competitiveness for admission to a good program. I understand that the error rate is unremarkable (I can get it up to ~2.5% with more complexity and time), but I'm wondering if the novelty and efficiency of the approach justifies attempting to submit something to a peer-reviewed journal. ",10,6,False,self,,,,,
543,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,13,5imffb,lobal.io,[Project] Browse and share ML results with extensive tags.,https://www.reddit.com/r/MachineLearning/comments/5imffb/project_browse_and_share_ml_results_with/,lobalproject,1481863735,,2,4,False,default,,,,,
544,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,15,5imv7w,cluemachines.com,CNC machine for sale | used CNC machines canada,https://www.reddit.com/r/MachineLearning/comments/5imv7w/cnc_machine_for_sale_used_cnc_machines_canada/,cluemachine1,1481870477,,1,1,False,default,,,,,
545,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,16,5in08i,self.MachineLearning,[D] Survey of Reinforcement Learning Platforms,https://www.reddit.com/r/MachineLearning/comments/5in08i/d_survey_of_reinforcement_learning_platforms/,jalFaizy,1481872872,"I recently did a survey of the popular reinforcement Learning Platforms (https://www.analyticsvidhya.com/blog/2016/12/getting-ready-for-ai-based-gaming-agents-overview-of-open-source-reinforcement-learning-platforms/). Is there any more popular platform I may have missed?

EDIT: Thanks for all the comments. They really helped me to improve the article!",14,7,False,self,,,,,
546,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,17,5in51b,arxiv.org,[R] Stacked Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/5in51b/r_stacked_generative_adversarial_networks/,ycilop272,1481875459,,6,21,False,default,,,,,
547,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,17,5ina6p,github.com,[P] Laia: a Toolkit for Offline Handwriting Recognition,https://www.reddit.com/r/MachineLearning/comments/5ina6p/p_laia_a_toolkit_for_offline_handwriting/,confortablyNaN,1481878210,,0,11,False,http://b.thumbs.redditmedia.com/A3tmpXSSemD6tb8IEnKlTJ00UQplP9XEhRgIwaOZIeg.jpg,,,,,
548,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,18,5inf7f,youtube.com,"Amazing Top 10 most Awesome Heavy Equipment, Big Machine Power Dozer",https://www.reddit.com/r/MachineLearning/comments/5inf7f/amazing_top_10_most_awesome_heavy_equipment_big/,iamsanjaysaini,1481881017,,1,1,False,default,,,,,
549,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,19,5ino2q,medium.com,Machine Learning Security,https://www.reddit.com/r/MachineLearning/comments/5ino2q/machine_learning_security/,mhausenblas,1481885783,,0,1,False,default,,,,,
550,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,20,5inq37,self.MachineLearning,CfP: 18th Int. Conf. on Engineering Applications of Neural Networks,https://www.reddit.com/r/MachineLearning/comments/5inq37/cfp_18th_int_conf_on_engineering_applications_of/,scardax88,1481886798,[removed],0,1,False,default,,,,,
551,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,20,5inq68,youtube.com,Yard Trailer Number ID Detection and recognition,https://www.reddit.com/r/MachineLearning/comments/5inq68/yard_trailer_number_id_detection_and_recognition/,marearts,1481886829,,0,1,False,default,,,,,
552,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,21,5inynl,youtu.be,[P] Automatic Machine Learning tested on Kaggle 'Give me some credit' dataset,https://www.reddit.com/r/MachineLearning/comments/5inynl/p_automatic_machine_learning_tested_on_kaggle/,pplonski,1481890777,,0,3,False,default,,,,,
553,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,22,5io480,self.MachineLearning,http://ioloop.io/blog/hoverpy-ml/,https://www.reddit.com/r/MachineLearning/comments/5io480/httpioloopiobloghoverpyml/,[deleted],1481893201,[removed],0,1,False,default,,,,,
554,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,22,5io5v1,ioloop.io,Speeding up Machine Learning workflow using a high-performance Go proxy.,https://www.reddit.com/r/MachineLearning/comments/5io5v1/speeding_up_machine_learning_workflow_using_a/,cpplinuxdude,1481893820,,0,1,False,default,,,,,
555,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,22,5io8hz,self.MachineLearning,[Discussion] Deep Learning Libraries for Java,https://www.reddit.com/r/MachineLearning/comments/5io8hz/discussion_deep_learning_libraries_for_java/,a933,1481894831,[removed],0,2,False,default,,,,,
556,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,22,5iodgn,twitter.com,"""Ng claims Chinese first did NMT, gets wide audience. Counter-claims with facts get no audience. Most people will believe Ng...whats the fix?""",https://www.reddit.com/r/MachineLearning/comments/5iodgn/ng_claims_chinese_first_did_nmt_gets_wide/,[deleted],1481896709,[deleted],0,1,False,default,,,,,
557,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,23,5iodyw,twitter.com,"[Discussion] ""Ng claims Chinese first did NMT, gets wide audience. Counter-claims with facts get no audience. Most people will believe Ng...whats the fix?""",https://www.reddit.com/r/MachineLearning/comments/5iodyw/discussion_ng_claims_chinese_first_did_nmt_gets/,[deleted],1481896895,[deleted],0,1,False,default,,,,,
558,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,23,5iof4c,twitter.com,"[Discussion] ""Ng claims Chinese first did NMT, gets wide audience. Counter-claims with facts get no audience. Most people will believe Ng...whats the fix?""",https://www.reddit.com/r/MachineLearning/comments/5iof4c/discussion_ng_claims_chinese_first_did_nmt_gets/,metacurse,1481897298,,21,22,False,default,,,,,
559,MachineLearning,t5_2r3gv,2016-12-16,2016,12,16,23,5ioiz1,blog.niland.io,[D] Blogpost : How we keep track of our experiments at niland.io,https://www.reddit.com/r/MachineLearning/comments/5ioiz1/d_blogpost_how_we_keep_track_of_our_experiments/,aloisg,1481898654,,0,11,False,default,,,,,
560,MachineLearning,t5_2r3gv,2016-12-17,2016,12,17,0,5iotu6,self.MachineLearning,ML engineer frustrated with the state of the world and want to change it.,https://www.reddit.com/r/MachineLearning/comments/5iotu6/ml_engineer_frustrated_with_the_state_of_the/,[deleted],1481902265,[removed],0,1,False,default,,,,,
561,MachineLearning,t5_2r3gv,2016-12-17,2016,12,17,1,5ip0nc,nytimes.com,[N] The Great A.I. Awakening,https://www.reddit.com/r/MachineLearning/comments/5ip0nc/n_the_great_ai_awakening/,BlurryZombie,1481904334,,21,26,False,default,,,,,
562,MachineLearning,t5_2r3gv,2016-12-17,2016,12,17,1,5ip4ln,youtube.com,HTM Topology Explained,https://www.reddit.com/r/MachineLearning/comments/5ip4ln/htm_topology_explained/,numenta,1481905505,,0,1,False,default,,,,,
563,MachineLearning,t5_2r3gv,2016-12-17,2016,12,17,1,5ip6rv,self.MachineLearning,"[D] Problem formulation: When should a task be broken down and factored into sub problems, and when should it be learned end to end?",https://www.reddit.com/r/MachineLearning/comments/5ip6rv/d_problem_formulation_when_should_a_task_be/,[deleted],1481906134,[deleted],1,1,False,default,,,,,
564,MachineLearning,t5_2r3gv,2016-12-17,2016,12,17,1,5ipaf5,github.com,[P] TensorFlow Exercises - focusing on the comparison with NumPy.,https://www.reddit.com/r/MachineLearning/comments/5ipaf5/p_tensorflow_exercises_focusing_on_the_comparison/,longinglove,1481907205,,1,31,False,http://b.thumbs.redditmedia.com/ZZFc0o-NrLSA76ebqtCtJUxnl7DySGAoPuz2grdqoFA.jpg,,,,,
565,MachineLearning,t5_2r3gv,2016-12-17,2016,12,17,2,5ipevd,blog.talla.com,[R]Neural Turing Machines: Perils and Promise,https://www.reddit.com/r/MachineLearning/comments/5ipevd/rneural_turing_machines_perils_and_promise/,raithism,1481908540,,5,63,False,http://b.thumbs.redditmedia.com/AFKIDw6jDrp89xGoHg9tYCfK8prHkfMsdryOg4vyblo.jpg,,,,,
566,MachineLearning,t5_2r3gv,2016-12-17,2016,12,17,3,5ipu8e,self.MachineLearning,[P] Open source ML projects,https://www.reddit.com/r/MachineLearning/comments/5ipu8e/p_open_source_ml_projects/,Agent008t,1481912956,"How would one go about finding open-source ML projects to join, that ideally involve large amounts of data, implementations of machine learning techniques instead of just using well-known libraries, and practical applications? Kaggle seems a bit too sandboxed, I would prefer something more ""real-world"".",3,1,False,self,,,,,
567,MachineLearning,t5_2r3gv,2016-12-17,2016,12,17,3,5ipvf5,self.MachineLearning,"Is making a 3D implementation of ""A Neural Algorithm for Artistic Style?"" possible?",https://www.reddit.com/r/MachineLearning/comments/5ipvf5/is_making_a_3d_implementation_of_a_neural/,cpgeier,1481913282,[removed],0,1,False,default,,,,,
568,MachineLearning,t5_2r3gv,2016-12-17,2016,12,17,3,5ipxxc,self.MachineLearning,is it possible to use GANs for synthetic data synthesis?,https://www.reddit.com/r/MachineLearning/comments/5ipxxc/is_it_possible_to_use_gans_for_synthetic_data/,abell25,1481914019,[removed],0,1,False,default,,,,,
569,MachineLearning,t5_2r3gv,2016-12-17,2016,12,17,4,5iq8lx,self.MachineLearning,Struggling with Scikitlearn and Numpy arrays...pleeeease help,https://www.reddit.com/r/MachineLearning/comments/5iq8lx/struggling_with_scikitlearn_and_numpy/,sinuspane,1481917119,[removed],0,1,False,default,,,,,
570,MachineLearning,t5_2r3gv,2016-12-17,2016,12,17,5,5iqifa,yaleentrepreneurship.com,Machine learning to treat depression,https://www.reddit.com/r/MachineLearning/comments/5iqifa/machine_learning_to_treat_depression/,sealturkey,1481920052,,0,2,False,default,,,,,
571,MachineLearning,t5_2r3gv,2016-12-17,2016,12,17,6,5iqt5u,self.MachineLearning,Why are neural networks trained over training 'stacks'?,https://www.reddit.com/r/MachineLearning/comments/5iqt5u/why_are_neural_networks_trained_over_training/,Weriak,1481923317,[removed],0,1,False,default,,,,,
572,MachineLearning,t5_2r3gv,2016-12-17,2016,12,17,6,5iqvr9,i.redd.it,[D] How many layers of network are you on?,https://www.reddit.com/r/MachineLearning/comments/5iqvr9/d_how_many_layers_of_network_are_you_on/,ErrantRailer,1481924122,,2,0,False,default,,,,,
573,MachineLearning,t5_2r3gv,2016-12-17,2016,12,17,6,5iqy33,youtube.com,The Best Way to Prepare a Dataset Easily,https://www.reddit.com/r/MachineLearning/comments/5iqy33/the_best_way_to_prepare_a_dataset_easily/,llSourcell,1481924868,,0,1,False,default,,,,,
574,MachineLearning,t5_2r3gv,2016-12-17,2016,12,17,7,5ir41f,self.MachineLearning,[R] Using Machine Learning for Text Generation,https://www.reddit.com/r/MachineLearning/comments/5ir41f/r_using_machine_learning_for_text_generation/,x-DeiFieD-x,1481926751,"Forgive me, I am new to Machine Learning and new to Reddit (so if this needs to be moved please let me know). I have been reading up on text generation using Machine Learning, mainly Recurrent Neural Networks, however it seems that the current implementations have the algorithm take a large quantity of text (say the works of [William Shakespeare](http://karpathy.github.io/2015/05/21/rnn-effectiveness/#shakespeare), or [political speeches](https://medium.com/@samim/obama-rnn-machine-generated-political-speeches-c8abd18a2ea0#.vp03dzu4d)), and have the algorithm write entirely new passages of speech from what it has learned. My question is rather, could we utilise a Machine Learning algorithm instead by inputting JSON, and have the algorithm output some text/speech? For example:

Input:
{
    ""breed"" : ""German Shepherd"",
    ""name"" : ""Max"",
    ""illness"" : ""Cancer""
}

Output:
""Im sorry to hear that your German Shepherd, Max, has cancer""

The reason for this structure, is say I have some data from a database, I want to generate some output text that makes the returned data readable to the user. While I could hard-code some text generation tool, I thought it would be cool to see if the computer could figure it out for me. Any help would be greatly appreciated.",4,7,False,self,,,,,
575,MachineLearning,t5_2r3gv,2016-12-17,2016,12,17,8,5iree7,self.MachineLearning,NIPS2016 Vague memories of a paper (Search help!),https://www.reddit.com/r/MachineLearning/comments/5iree7/nips2016_vague_memories_of_a_paper_search_help/,justtheprint,1481930120,[removed],0,1,False,default,,,,,
576,MachineLearning,t5_2r3gv,2016-12-17,2016,12,17,8,5irieq,self.MachineLearning,[X-post from Statistics] Forecasting Classifier: Trying To Find Use Cases And Data,https://www.reddit.com/r/MachineLearning/comments/5irieq/xpost_from_statistics_forecasting_classifier/,[deleted],1481931512,[removed],0,1,False,default,,,,,
577,MachineLearning,t5_2r3gv,2016-12-17,2016,12,17,8,5irixt,self.MachineLearning,[D] How do I become better at kaggle competitions?,https://www.reddit.com/r/MachineLearning/comments/5irixt/d_how_do_i_become_better_at_kaggle_competitions/,[deleted],1481931703,[deleted],16,20,False,default,,,,,
578,MachineLearning,t5_2r3gv,2016-12-17,2016,12,17,9,5irpg0,analyticsvidhya.com,Machine Learning with the caret package in r - with a practice problem,https://www.reddit.com/r/MachineLearning/comments/5irpg0/machine_learning_with_the_caret_package_in_r_with/,ruskeeblue,1481933966,,0,1,False,default,,,,,
579,MachineLearning,t5_2r3gv,2016-12-17,2016,12,17,13,5isqx2,self.MachineLearning,[D] What is the state of machine learning research in China?,https://www.reddit.com/r/MachineLearning/comments/5isqx2/d_what_is_the_state_of_machine_learning_research/,Buck-Nasty,1481948599,"I came across [this article](https://www.weforum.org/agenda/2016/11/china-is-now-the-world-leader-in-deep-learning-research-and-the-us-is-worried-about-it?) from the World Economic Forum which states that China surpassed the US in the total number of Deep Learning papers published and cited in 2015. 

The perception I get as an outside observer of the field is that the US is still far ahead. I know Baidu is doing interesting work but other than that I thought the ML community in China was pretty sparse. 

Are the World Economic Forum's statistics misleading in saying that China is now the world's leader in Deep Learning?",4,6,False,self,,,,,
580,MachineLearning,t5_2r3gv,2016-12-17,2016,12,17,15,5it7ga,github.com,caffe implementation for ResNeXt (Aggregated Residual Transformations for Deep Neural Network),https://www.reddit.com/r/MachineLearning/comments/5it7ga/caffe_implementation_for_resnext_aggregated/,[deleted],1481955780,[deleted],0,1,False,default,,,,,
581,MachineLearning,t5_2r3gv,2016-12-17,2016,12,17,15,5it9a6,github.com,[P] caffe implementation for ResNeXt (Aggregated Residual Transformations for Deep Neural Network),https://www.reddit.com/r/MachineLearning/comments/5it9a6/p_caffe_implementation_for_resnext_aggregated/,giorking,1481956664,,3,8,False,http://b.thumbs.redditmedia.com/VphEH1D4FRWADVVIqjuGlWJYWQk_MSVjiLBgbsV19Qc.jpg,,,,,
582,MachineLearning,t5_2r3gv,2016-12-17,2016,12,17,15,5itc0a,self.MachineLearning,State of the Developer Nation survey,https://www.reddit.com/r/MachineLearning/comments/5itc0a/state_of_the_developer_nation_survey/,akoshodi,1481957972,[removed],0,1,False,default,,,,,
583,MachineLearning,t5_2r3gv,2016-12-17,2016,12,17,16,5itcpr,alpha.openai.com,[R] MiniWoB: OpenAI benchmark for reinforcement learning agents who interact with websites,https://www.reddit.com/r/MachineLearning/comments/5itcpr/r_miniwob_openai_benchmark_for_reinforcement/,downtownslim,1481958302,,7,61,False,http://a.thumbs.redditmedia.com/EcYFXXEJTvX-MUYVv2VzIQ9yKbGLZoiWE_3vjwRLRD8.jpg,,,,,
584,MachineLearning,t5_2r3gv,2016-12-17,2016,12,17,17,5itm39,self.MachineLearning,"When training a gender voice classifier, does it worsen your model to have long (15-20 seconds) input data from individual people?",https://www.reddit.com/r/MachineLearning/comments/5itm39/when_training_a_gender_voice_classifier_does_it/,ACTBRUH,1481963521,[removed],0,1,False,default,,,,,
585,MachineLearning,t5_2r3gv,2016-12-18,2016,12,18,1,5ivc1h,youtube.com,other great machine.,https://www.reddit.com/r/MachineLearning/comments/5ivc1h/other_great_machine/,degisikmakineler,1481993742,,1,1,False,default,,,,,
586,MachineLearning,t5_2r3gv,2016-12-18,2016,12,18,2,5ivho9,github.com,[P] Tensorflow implementation of PixelCNN++ [OpenAI],https://www.reddit.com/r/MachineLearning/comments/5ivho9/p_tensorflow_implementation_of_pixelcnn_openai/,downtownslim,1481995546,,17,90,False,http://b.thumbs.redditmedia.com/wUto-T36Yn7PA0Q4aRpaOaZw0FqbvFu8AX2zj5LKYFk.jpg,,,,,
587,MachineLearning,t5_2r3gv,2016-12-18,2016,12,18,2,5ivikv,arxiv.org,[R] FastText.zip: Compressing text classification models,https://www.reddit.com/r/MachineLearning/comments/5ivikv/r_fasttextzip_compressing_text_classification/,rrenaud,1481995863,,2,8,False,default,,,,,
588,MachineLearning,t5_2r3gv,2016-12-18,2016,12,18,4,5iw5bp,self.MachineLearning,Do artificial neural networks necessarily represent inputs as distributed representations? (Answer much appreciated),https://www.reddit.com/r/MachineLearning/comments/5iw5bp/do_artificial_neural_networks_necessarily/,ibrdo,1482003232,[removed],0,1,False,default,,,,,
589,MachineLearning,t5_2r3gv,2016-12-18,2016,12,18,5,5iweur,self.MachineLearning,[D] How to best represent multidimensional features?,https://www.reddit.com/r/MachineLearning/comments/5iweur/d_how_to_best_represent_multidimensional_features/,cinamon_swirl,1482006294,"Hi, first off I'm pretty new to machine learning, so sorry if I shouldn't be posting this kinda question here, but I haven't found any straightforward tutorials or examples on how to represent these kinda features to be used by scikit-learn models :s So any advice you guys could provide would be really appreciated.
 
To be more specific, basically while learning java Ive made a crappy turn based board game (like chess), but where the pieces have health and attack and can move different amounts of squares (kinda like final fantasy but more crappy; if your king/ hero piece dies, you lose) and since finding out more about machine learning Ive been wanting to try to use it for the games AI. 

Ive thought that I could run simulations of the game with random moves and then use board configurations after certain moves as the observations and then whether or not this particular board config was part of a winning game or not as the label. The idea being that once my model is trained, I can use it to determine which move to make based on whether the output board config of tht move is classified as a win or not. 

The bit Im stuck at is how to convert a board configuration to a row for the feature matrix. Like Ive thought I could make each observation have 64 columns (one for each square on the board) and then put what piece is currently occupying that square (Ive read that I need to do one-hot encoding on the piece types be4 I can use them in scikit learn models), but then how would I include how much hp the piece currently has and its color? Like in all the examples Ive seen, the observations were one dimensional like:
 [[female,blue,73] , [male,red,65].... ]
how do I represent smthing like this: [[empty,(king,black,50%hp),empty,(pawn,white,100%hp),empty,empty..] , [empty,...],...]

Ive done a lot of googling, but all Ive discovered is that I really have no idea what Im doing and the more I read the less confident I feel &gt;.&lt; Sorry for the wall of text, but I would really, really appreciate any advice you could give on getting this kinda data into a suitable feature matrix.",6,3,False,self,,,,,
590,MachineLearning,t5_2r3gv,2016-12-18,2016,12,18,6,5iwo51,self.MachineLearning,Trying to simplify an image data set for Deep learning input,https://www.reddit.com/r/MachineLearning/comments/5iwo51/trying_to_simplify_an_image_data_set_for_deep/,xomalg,1482009378,[removed],0,1,False,default,,,,,
591,MachineLearning,t5_2r3gv,2016-12-18,2016,12,18,8,5ixaf5,self.MachineLearning,[D] Hope this becomes a norm for the field,https://www.reddit.com/r/MachineLearning/comments/5ixaf5/d_hope_this_becomes_a_norm_for_the_field/,rantana,1482017028,"Not sure if this is too meta for /r/MachineLearning, but /u/badmephisto (Andrej Karpathy) from OpenAI just posted trained weights for a model at a users request in less than 3 hours:

https://www.reddit.com/r/MachineLearning/comments/5ivho9/p_tensorflow_implementation_of_pixelcnn_openai/dbblpzl/?context=10000

Just wanted to say the amount of openness and collaboration from this community is fantastic.",26,241,False,self,,,,,
592,MachineLearning,t5_2r3gv,2016-12-18,2016,12,18,10,5ixsjx,hypebeast.com,"Wow House Guests With This $30,000 USD Floating Coffee Table",https://www.reddit.com/r/MachineLearning/comments/5ixsjx/wow_house_guests_with_this_30000_usd_floating/,smalltrump,1482023621,,0,1,False,default,,,,,
593,MachineLearning,t5_2r3gv,2016-12-18,2016,12,18,11,5iy6u9,self.MachineLearning,[D] Generating attention matrices from Tensorflow NMT model?,https://www.reddit.com/r/MachineLearning/comments/5iy6u9/d_generating_attention_matrices_from_tensorflow/,MetricSpade007,1482029385,Do people know how to generate the pretty attention matrices that are like figure 3 in the Bahdanau paper (https://arxiv.org/pdf/1409.0473v7.pdf)? I'm wondering more specifically if people know how to tweak the existing example seq2seq code in the TensorFlow tutorials to get these matrices. Thanks!,2,2,False,self,,,,,
594,MachineLearning,t5_2r3gv,2016-12-18,2016,12,18,13,5iyits,warmspringwinds.github.io,[P] Image Segmentation with Tensorflow using CNNs and Conditional Random Fields,https://www.reddit.com/r/MachineLearning/comments/5iyits/p_image_segmentation_with_tensorflow_using_cnns/,warmspringwinds,1482034398,,6,22,False,default,,,,,
595,MachineLearning,t5_2r3gv,2016-12-18,2016,12,18,16,5iz4fi,self.MachineLearning,Difference between a state machine and a Markov chain?,https://www.reddit.com/r/MachineLearning/comments/5iz4fi/difference_between_a_state_machine_and_a_markov/,[deleted],1482044667,[removed],0,1,False,default,,,,,
596,MachineLearning,t5_2r3gv,2016-12-18,2016,12,18,16,5iz4k6,fsecurify.com,Machine Learning and Cyber Security Resources,https://www.reddit.com/r/MachineLearning/comments/5iz4k6/machine_learning_and_cyber_security_resources/,[deleted],1482044733,[deleted],0,1,False,default,,,,,
597,MachineLearning,t5_2r3gv,2016-12-18,2016,12,18,16,5iz4rd,fsecurify.com,All the machine learning and cyber security resources I could find at one place,https://www.reddit.com/r/MachineLearning/comments/5iz4rd/all_the_machine_learning_and_cyber_security/,Faizann24,1482044837,,0,1,False,default,,,,,
598,MachineLearning,t5_2r3gv,2016-12-18,2016,12,18,18,5iziqc,self.MachineLearning,What are currently actively pursued fields of machine learning?,https://www.reddit.com/r/MachineLearning/comments/5iziqc/what_are_currently_actively_pursued_fields_of/,Fisher9001,1482053140,[removed],0,1,False,default,,,,,
599,MachineLearning,t5_2r3gv,2016-12-18,2016,12,18,18,5izkux,github.com,[P] openai-gemm: fp16 speedups over cublas,https://www.reddit.com/r/MachineLearning/comments/5izkux/p_openaigemm_fp16_speedups_over_cublas/,spruceabtuse,1482054566,,18,38,False,http://b.thumbs.redditmedia.com/h6_SKw3tS0hTFv-V5oJXf_GTG8ruqAkjeGUetZkLw-Y.jpg,,,,,
600,MachineLearning,t5_2r3gv,2016-12-18,2016,12,18,21,5j02tn,facebook.com,Bayesian neural nets: The Saga,https://www.reddit.com/r/MachineLearning/comments/5j02tn/bayesian_neural_nets_the_saga/,NicolasGuacamole,1482065603,,0,1,False,default,,,,,
601,MachineLearning,t5_2r3gv,2016-12-18,2016,12,18,22,5j08vt,technobium.com,A glimpse into SyntaxNet - the worlds most accurate parser,https://www.reddit.com/r/MachineLearning/comments/5j08vt/a_glimpse_into_syntaxnet_the_worlds_most_accurate/,technobium,1482068627,,0,1,False,default,,,,,
602,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,0,5j0l9h,self.MachineLearning,[D] Word embeddings table?,https://www.reddit.com/r/MachineLearning/comments/5j0l9h/d_word_embeddings_table/,gabriel1983,1482073888,"Hello,

I have googled and googled for hours with no success so far, so I guess that it is not easily googled.

I am looking for a database table of word embeddings, something like this:

word dimension1 dimension2 dimension3 ... dimension1000.     
tree 1.24 -5 3.2 ... You understand.     
car.     
house.     

Preferably trained with a large amount of varied text.

All I could find was code upon code. I used to code but not anymore, now simply looking at it makes my stomach sick.

I have a great interest in linguistics, though, and I think that these word embeddings have potential to offer nice insights. I want to try and understand what each of these dimensions mean. Size, gender, etc would be some obvious ones, but I'm guessing there might be some more interesting ones.

So, where can I find a good set of embeddings nicely ordered in a table, with all the dimensions?

Thank you!",6,2,False,self,,,,,
603,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,3,5j1f2x,norvig.com,[P] Natural Language Data Corpus: Beautiful Data,https://www.reddit.com/r/MachineLearning/comments/5j1f2x/p_natural_language_data_corpus_beautiful_data/,[deleted],1482084157,[deleted],1,0,False,default,,,,,
604,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,3,5j1iu3,self.MachineLearning,Can you train tensorflow to recognize any kind of object in an image?,https://www.reddit.com/r/MachineLearning/comments/5j1iu3/can_you_train_tensorflow_to_recognize_any_kind_of/,wildanimalperson,1482085352,[removed],0,1,False,default,,,,,
605,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,3,5j1jxs,self.MachineLearning,What is the C matrix in the log-bilinear model?,https://www.reddit.com/r/MachineLearning/comments/5j1jxs/what_is_the_c_matrix_in_the_logbilinear_model/,jay_ik,1482085719,[removed],0,1,False,default,,,,,
606,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,4,5j1qlx,medium.com,[P] Traffic Sign Recognition with TensorFlow,https://www.reddit.com/r/MachineLearning/comments/5j1qlx/p_traffic_sign_recognition_with_tensorflow/,waleedka,1482087857,,6,145,False,http://b.thumbs.redditmedia.com/pqSnlS5wMmrczwavytvjUZRBA55DNwFmUY1PZbCqecc.jpg,,,,,
607,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,4,5j1zzi,self.MachineLearning,[D] Link to paper on using a larger neural net to train a smaller one?,https://www.reddit.com/r/MachineLearning/comments/5j1zzi/d_link_to_paper_on_using_a_larger_neural_net_to/,RegularDisorder,1482090872,"I remember reading a paper a year or two ago on how you could get similar accuracy with a small CNN that is trained on the output of a larger CNN. For example, you train the larger CNN with a label of [0, 1, 0] and it outputs something close, say [0.1, 0.95, 0.05]. That second vector is what you use for training the smaller CNN.

Does anyone have a link to that paper or remember the author/title?",8,6,False,self,,,,,
608,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,6,5j2get,self.MachineLearning,Compare two images to determine if they belong to the same set?,https://www.reddit.com/r/MachineLearning/comments/5j2get/compare_two_images_to_determine_if_they_belong_to/,SeveQStorm,1482096189,[removed],0,1,False,default,,,,,
609,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,6,5j2jnx,youtube.com,Dnyann En Gl Rzgar Trbini,https://www.reddit.com/r/MachineLearning/comments/5j2jnx/dnyann_en_gl_rzgar_trbini/,degisikmakineler,1482097254,,1,1,False,default,,,,,
610,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,6,5j2mec,self.MachineLearning,[D] Is this a good book for beginners?,https://www.reddit.com/r/MachineLearning/comments/5j2mec/d_is_this_a_good_book_for_beginners/,Vikaton,1482098173,"I came across this book when searching from some resources on ML for beginners: http://shop.oreilly.com/product/0636920033400.do

Seems pretty nice, has anyone read it before? I'm trying to grasp the mathematical concepts of some ML algorithms but I have no prior knowledge in linear algebra or calculus, so maybe this is a good option for me.

Thoughts?",3,1,False,self,,,,,
611,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,7,5j2oyd,self.MachineLearning,Prioritising output nodes during training,https://www.reddit.com/r/MachineLearning/comments/5j2oyd/prioritising_output_nodes_during_training/,Ozzah,1482099006,[removed],0,1,False,default,,,,,
612,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,7,5j2pco,youtube.com,Dev Dikim Makinesi,https://www.reddit.com/r/MachineLearning/comments/5j2pco/dev_dikim_makinesi/,degisikmakineler,1482099138,,1,1,False,default,,,,,
613,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,7,5j2ts7,self.MachineLearning,[D] Question/Problem with Large-N Hopfield Network,https://www.reddit.com/r/MachineLearning/comments/5j2ts7/d_questionproblem_with_largen_hopfield_network/,im_mobile,1482100587,"Hi.  My product development task involves a relatively large Hopfield network (N=10000..100000).  Before going big, I built a smaller one (N=512) for testing.  I'm seeing some strange results, and I'm hoping to either (a) hear from someone who has actually coded/used relatively large-N Hopfield networks, or (b) be directed to better literature than I've been able to find thus far.  Thanks in advance for any insights you may have to offer.

For reasons you can guess, I can't really share the code.  However, I don't think the problem is in the implementation.  The salient details:

I'm using Hopfield's original 1982 framework as much as possible.  I'm using 0/1 as node values (instead of the more common -1/1), I'm using one-pass Hebbian weighting, using Hopfield's (2Vi-1) * (2Vj-1) formula (which yields incremental weights of +/-1, just like Vi * Vj does when using +/-1 for node values).  Based on the capacity formula (0.138 * N), my 512-node network should be able to hold ~70 distinct patterns before the error rate becomes noticeable (at 70 patterns, expected error is ~1.84 bits).  For small values of N, my code seems to work just fine.  So far, so good.

Hopfield notes in his paper that ""Memories too close to each other are confused and tend to merge.""  (I can emphatically confirm this.)  He goes on to say that ""[f]or N=100, a pair of random memories should be separated by 50+/-5 Hamming units.""  He doesn't explain how he derived this (or if he did, I missed it), so I've extrapolated linearly - for N=512, separation should be 256+/-26 Hamming units.  This means two things: (1) in a general case, one must somehow ensure that learned values aren't too close to one another, leading to the realization that (2) a Hopfield network is therefore not ideal as a general-purpose pattern storage/recognition filter.  But I digress.

The problem is this: Regardless of the randomness of the learned patterns or the Hamming distances between them, I start to see higher than expected error rates using relatively few learned patterns.  At n=20, the error rate already about 2 bits;  at n=30, it's approaching 5 bits;  at n=40, the error rate is well into the double digits and many spurious attractors/minima turn up (yielding individual errors in the 150-200+ bit range).  While I haven't done any serious testing with it, a cursory test using N=1024 suggests similar results.

I've read that having an odd number of learned patterns increases the probability of spurious attractors/minima, but I'm seeing similar results regardless of whether the input set contains an odd or even number of elements.

Most of the literature I've found that provides concrete examples either uses a trivial size (N=5, N=10) or doesn't venture beyond N=100 and instead uses phrases such as ""...should scale linearly with larger values of N"", suggesting that the authors never really tested larger systems.

My question for anyone with hands-on experience with large-N Hopfield networks is this: Do your results seem to confirm a capacity of ~0.138 * N with an error rate below 0.004?  I've examined my code thoroughly, and I've dumped all the matrices and hand-calculated each step, so it's hard for me to believe that this is an implementation problem - however, given that Hopfield networks have been studied and used for 30+ years, it's even harder for me to believe that I'm seeing emergent behavior that no one else has ever reported publicly.  Do large-N Hopfield networks really behave differently than their smaller cousins?  Or do I have some subtle bug that I need to track down?  At this point, I can't advance toward the N=10k-100k scenario until I know what I'm dealing with...

Thanks for any advice or insight you can offer.
",4,0,False,self,,,,,
614,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,8,5j2zeu,github.com,Computational Healthcare Library : Training an embedding model on 1 million hospitalizations using TensorFlow [Project],https://www.reddit.com/r/MachineLearning/comments/5j2zeu/computational_healthcare_library_training_an/,[deleted],1482102453,[deleted],0,5,False,default,,,,,
615,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,8,5j32x7,self.MachineLearning,[D] Deep Learning Framework Rankings?,https://www.reddit.com/r/MachineLearning/comments/5j32x7/d_deep_learning_framework_rankings/,congerous,1482103580,"Just wonder how valid these rankings are. I find it hard to believe that Torch ranks so low on the list, for example. 

https://twitter.com/fchollet/status/810201293151145984",14,7,False,self,,,,,
616,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,8,5j3525,self.MachineLearning,[D] In a position to provide datasets from a State Medicaid system,https://www.reddit.com/r/MachineLearning/comments/5j3525/d_in_a_position_to_provide_datasets_from_a_state/,ml_throwaway234,1482104307,"So, I believe I can convince the appropriate authorities to release de-identified data from a large US State's Medicaid System. This includes full medical claim data (ICD-9 and ICD-10), Eligibility and Provider data.

Does anyone have any ideas for interesting projects around it? What sort of data are you looking for?",5,12,False,self,,,,,
617,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,10,5j3rbh,github.com,depth estimation in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/5j3rbh/depth_estimation_in_tensorflow/,masazdream,1482112146,,0,1,False,default,,,,,
618,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,11,5j3tmu,youtu.be,Really Quick Questions with an OpenAI Engineer,https://www.reddit.com/r/MachineLearning/comments/5j3tmu/really_quick_questions_with_an_openai_engineer/,llSourcell,1482112969,,0,1,False,default,,,,,
619,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,11,5j3xke,self.MachineLearning,[D] Help me make sure I understand the potential uses of neural networks correctly. Which of those assumptions about possible uses for neural network is wrong?,https://www.reddit.com/r/MachineLearning/comments/5j3xke/d_help_me_make_sure_i_understand_the_potential/,sorryamhigh,1482114391,"Neural networks are used to identify patterns and it's accuracy relies on a large amount of data being fed into it.

Can it make sense of patterns without humans feeding the output to train it? For example, could I show it lots of animal pictures and tell it to group them by anatomic similarities? Or if used in tandem with NLP could a website like reddit feed it all of the users post history so it can detect patterns in their behaviours? Or even detect fake accounts or figure out that a user uses multiple accounts?

Could the same method that was used to teach it to play go teach it to play other games? Maybe by collecting replays from pro gamers and figuring out patterns on 1v1 games? Could the same, with enough data and processing power, be also used on shooters to figure out the best strategy? 

Could it feed into patient data and diagnose diseases based on that knowledge?

I suspect I'm being too wild on my predictions so please explain me why I'm wrong.

Also what other maybe not so widely known uses are there? It's such an interesting subject.",11,3,False,self,,,,,
620,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,11,5j3z2i,datasciencecentral.com,"Great list of resources: data science, visualization, machine learning, big data",https://www.reddit.com/r/MachineLearning/comments/5j3z2i/great_list_of_resources_data_science/,psangrene,1482114921,,0,1,False,default,,,,,
621,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,13,5j4e2m,arxiv.org,"[R] The Mellowmax Operator : ""A New Softmax Operator for Reinforcement Learning""",https://www.reddit.com/r/MachineLearning/comments/5j4e2m/r_the_mellowmax_operator_a_new_softmax_operator/,pierrelux,1482120598,,10,20,False,default,,,,,
622,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,15,5j4xam,dataaspirant.com,Amazon Go : The Just Walk out Technology,https://www.reddit.com/r/MachineLearning/comments/5j4xam/amazon_go_the_just_walk_out_technology/,dataaspirant,1482128549,,0,1,False,default,,,,,
623,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,16,5j528z,self.MachineLearning,getting into ML research,https://www.reddit.com/r/MachineLearning/comments/5j528z/getting_into_ml_research/,dataislyfe,1482130866,[removed],0,1,False,default,,,,,
624,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,16,5j547f,self.MachineLearning,Need guidance on a image recognition/processing project,https://www.reddit.com/r/MachineLearning/comments/5j547f/need_guidance_on_a_image_recognitionprocessing/,NotThatLebowski,1482131771,[removed],0,1,False,default,,,,,
625,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,16,5j55as,arxiv.org,Differentiable Ransac,https://www.reddit.com/r/MachineLearning/comments/5j55as/differentiable_ransac/,muktabh,1482132289,,0,1,False,default,,,,,
626,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,16,5j55wt,arxiv.org,[R] deep homography,https://www.reddit.com/r/MachineLearning/comments/5j55wt/r_deep_homography/,muktabh,1482132587,,3,2,False,default,,,,,
627,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,16,5j57iu,self.MachineLearning,[D] Opinions needed on a image recognition/processing task using Machine Learning!,https://www.reddit.com/r/MachineLearning/comments/5j57iu/d_opinions_needed_on_a_image/,NotThatLebowski,1482133400,"I have hundreds of images of various documents. So, I would like an algo to read those statements on the docs and would like to find specific words for e.g. expiry date, project started etc. 

Is there a way I can do this in Python/R language? Please guide me on how to do this.


I'm newbie to image recognition/processing hence posting it here. Please forgive me if my question sounds naive.



Also, is there a way (algo) whereby I can do image classification? There are images of car, building, indoor, outdoor, documents etc and I would like to classify them accordingly. Can this be done? Please guide on how to do it.


I read somewhere that it can be done with opencv, imutils and ocr but I have no idea how to proceed. I'm also reading Computer Vision with Python by Jan Erik Solem and would appreciate any guidance for the same.


Thanks in advance!",2,2,False,self,,,,,
628,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,16,5j59bj,youtu.be,Using The Biggest Machines In The Biggest Dig In The World [The America's Huge Dig],https://www.reddit.com/r/MachineLearning/comments/5j59bj/using_the_biggest_machines_in_the_biggest_dig_in/,[deleted],1482134315,[deleted],0,1,False,default,,,,,
629,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,17,5j5dik,self.MachineLearning,"[D] What is the simplest, first-attempt dataset for testing reinforcement learning designs?",https://www.reddit.com/r/MachineLearning/comments/5j5dik/d_what_is_the_simplest_firstattempt_dataset_for/,[deleted],1482136544,[deleted],1,1,False,default,,,,,
630,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,18,5j5inl,self.MachineLearning,Which of the following Data Science masters programs should I choose?,https://www.reddit.com/r/MachineLearning/comments/5j5inl/which_of_the_following_data_science_masters/,datavinci,1482139335,[removed],0,1,False,default,,,,,
631,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,18,5j5jdk,github.com,[P] TensorFlow Implementation of PoseNet,https://www.reddit.com/r/MachineLearning/comments/5j5jdk/p_tensorflow_implementation_of_posenet/,kentsommer,1482139704,,0,16,False,http://b.thumbs.redditmedia.com/jCOpqj_ksWdILN9oYyxLzKLV2W0-5KNe8zQ0UyFIDfU.jpg,,,,,
632,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,18,5j5jh0,github.com,[P] Keras Implementation of PoseNet,https://www.reddit.com/r/MachineLearning/comments/5j5jh0/p_keras_implementation_of_posenet/,kentsommer,1482139751,,0,2,False,default,,,,,
633,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,18,5j5ksh,self.MachineLearning,Looking for an image dataset,https://www.reddit.com/r/MachineLearning/comments/5j5ksh/looking_for_an_image_dataset/,jazzsaxmafia,1482140473,[removed],0,1,False,default,,,,,
634,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,19,5j5q9f,arxiv.org,[R] End-to-End Subtitle Detection and Recognition for Videos in East Asian Languages via CNN Ensemble with Near-Human-Level Performance,https://www.reddit.com/r/MachineLearning/comments/5j5q9f/r_endtoend_subtitle_detection_and_recognition_for/,nuberudi,1482143376,,4,28,False,default,,,,,
635,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,19,5j5qa5,issuu.com,Caractersticas tcnicas de la maquinaria hidrulica,https://www.reddit.com/r/MachineLearning/comments/5j5qa5/caractersticas_tcnicas_de_la_maquinaria/,Barriuso,1482143389,,0,1,False,default,,,,,
636,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,20,5j601p,self.MachineLearning,What is the C matrix in the log-bilinear language model?,https://www.reddit.com/r/MachineLearning/comments/5j601p/what_is_the_c_matrix_in_the_logbilinear_language/,jay_ik,1482148373,"I'm trying to understand the log-bilinear neural language model of Minh and Hinton, but I cannot find a good explanation of what the context matrix C is. Take formula (1) in the paper ""A Scalable Hierarchical Distributed Language Model"" from 2008:
r' = \sum_(i=1)^(n-1) C_(i) r_(w_i)
As far as I can understand, the r's are the embedding vectors we want to learn, but what is the C matrix? The paper says ""C(i) is the weight matrix associated with the context position i"", but I don't understand this statement: doesn't the notation indicate that C(i) is a vector? Or is it a matrix, and do we need one separate weight matrix for each context position? (That seems inefficient.) Or is it perhaps a weight matrix representing the words in their context positions rather than their embeddings?
As you can see I am a bit confused. Can someone please explain this in as simple terms as possible?
",3,2,False,self,,,,,
637,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,22,5j6e81,alxd.org,"[P] NeuroOn ""world's first smart sleep mask"" is much better than a coin toss",https://www.reddit.com/r/MachineLearning/comments/5j6e81/p_neuroon_worlds_first_smart_sleep_mask_is_much/,pmigdal,1482154412,,3,0,False,default,,,,,
638,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,22,5j6ej5,uk.businessinsider.com,"[N] Alphabet's DeepMind unit could be expanded to 1,000 people",https://www.reddit.com/r/MachineLearning/comments/5j6ej5/n_alphabets_deepmind_unit_could_be_expanded_to/,[deleted],1482154522,[deleted],0,1,False,default,,,,,
639,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,23,5j6iwo,self.MachineLearning,[D] Chance for Phd in Machine learning(or NLP/Vision) in US,https://www.reddit.com/r/MachineLearning/comments/5j6iwo/d_chance_for_phd_in_machine_learningor_nlpvision/,huyhcmut,1482156206,"I have just looked at the profile of a friend  in my undergraduate class(  graduated for 1 year). He shared his CV and asked me some advices about Phd admission in US. However i do not have any experiences about this. Here are his profile:
+ GPA: 8.5/10. However, he had very bad grade in 3 first semesters because of farmily problem: One Failed course, 3 C graded. He has retook 4 these course with almost perfect grade.
+Two Publication: One at UAI( extended form Under thesis) and one on ICML(in one year  research after under)
+ one third prize in competitive programming prize in ACM regional at 4th year under.
+ 2 application machine learning project on android. (one got medal at small compertition)
+1 semester teaching asistant.
+one internship at an start up company about data science.
Can any one give idea about his profile. Will 4 bad course grade affacted a lot. His  aim is from Top 10-30 ML Phd program US/ or good ML phd program in Canada.",11,1,False,self,,,,,
640,MachineLearning,t5_2r3gv,2016-12-19,2016,12,19,23,5j6p63,arxiv.org,Unsupervised Pixel-Level Domain Adaptation with GANs,https://www.reddit.com/r/MachineLearning/comments/5j6p63/unsupervised_pixellevel_domain_adaptation_with/,[deleted],1482158432,[deleted],0,1,False,default,,,,,
641,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,0,5j6unj,self.MachineLearning,[D] When is it right/wrong to use XGBoost?,https://www.reddit.com/r/MachineLearning/comments/5j6unj/d_when_is_it_rightwrong_to_use_xgboost/,[deleted],1482160262,[deleted],11,5,False,default,,,,,
642,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,0,5j6vsv,andymiller.github.io,[R] Monte Carlo Gradient Estimators and Variational Inference (blog post),https://www.reddit.com/r/MachineLearning/comments/5j6vsv/r_monte_carlo_gradient_estimators_and_variational/,[deleted],1482160632,[deleted],0,1,False,default,,,,,
643,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,0,5j6whn,medium.com,Considering today's electoral college vote: Using a Genetic Algorithm to Draw Electoral Maps,https://www.reddit.com/r/MachineLearning/comments/5j6whn/considering_todays_electoral_college_vote_using_a/,DontVoteForMe,1482160865,,0,1,False,default,,,,,
644,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,0,5j6wkg,andymiller.github.io,[R] Monte Carlo Gradient Estimators and Variational Inference (blog post),https://www.reddit.com/r/MachineLearning/comments/5j6wkg/r_monte_carlo_gradient_estimators_and_variational/,acmueller,1482160890,,1,26,False,http://b.thumbs.redditmedia.com/GTY1urmUp3kA3crAqMCdXycpeVzeLBnLrTKjJjdz_2Q.jpg,,,,,
645,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,0,5j6yb9,self.MachineLearning,Software Engineer vs Data Scientist/Analyst?,https://www.reddit.com/r/MachineLearning/comments/5j6yb9/software_engineer_vs_data_scientistanalyst/,[deleted],1482161448,[removed],0,1,False,default,,,,,
646,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,0,5j703f,self.MachineLearning,What do you use to log development and learning of your ML models?,https://www.reddit.com/r/MachineLearning/comments/5j703f/what_do_you_use_to_log_development_and_learning/,[deleted],1482162012,[removed],0,1,False,default,,,,,
647,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,0,5j70p6,github.com,Memory Augmented Neural Networks (MANN) Repository for D-NTM,https://www.reddit.com/r/MachineLearning/comments/5j70p6/memory_augmented_neural_networks_mann_repository/,albertzeyer,1482162205,,0,1,False,default,,,,,
648,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,0,5j7104,self.MachineLearning,Software writing machine learning-ist?,https://www.reddit.com/r/MachineLearning/comments/5j7104/software_writing_machine_learningist/,rodrigo-silveira,1482162293,[removed],0,1,False,default,,,,,
649,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,1,5j75v2,self.MachineLearning,Machine Learning Without Borders?,https://www.reddit.com/r/MachineLearning/comments/5j75v2/machine_learning_without_borders/,[deleted],1482163738,[removed],0,1,False,default,,,,,
650,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,1,5j764m,arxiv.org,"[R] [1612.00222] Interaction Networks for Learning about Objects, Relations and Physics",https://www.reddit.com/r/MachineLearning/comments/5j764m/r_161200222_interaction_networks_for_learning/,evc123,1482163820,,3,13,False,default,,,,,
651,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,1,5j77w9,self.MachineLearning,[D] Machine Learning Without Borders?,https://www.reddit.com/r/MachineLearning/comments/5j77w9/d_machine_learning_without_borders/,JamminJames921,1482164338,What are your ideas on using ML for developing countries? What current problems can be solved? What are the current challenges for this area and what kind of infrastructure can support this?,17,18,False,self,,,,,
652,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,1,5j78b6,self.MachineLearning,[D] Unsupervised &amp; Weak-Supervised Online Learning &amp; Domain Adaptation,https://www.reddit.com/r/MachineLearning/comments/5j78b6/d_unsupervised_weaksupervised_online_learning/,senorstallone,1482164452,"So, I have a bunch of supervised data but my target images are a bit different and the new samples that I'm receiving are also changing sometimes. Because of that I'm having poor results. So, How can I have a CNN adapt continuously to new data using none or few labels? What is the soa in these topics? ",4,2,False,self,,,,,
653,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,2,5j7jt6,3dgan.csail.mit.edu,[P] Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling,https://www.reddit.com/r/MachineLearning/comments/5j7jt6/p_learning_a_probabilistic_latent_space_of_object/,luiscosio,1482167662,,1,2,False,default,,,,,
654,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,2,5j7m7c,facebook.com,[P] Mark Zuckerberg: Building Jarvis,https://www.reddit.com/r/MachineLearning/comments/5j7m7c/p_mark_zuckerberg_building_jarvis/,jakn,1482168320,,78,206,False,http://b.thumbs.redditmedia.com/XESlIyAGDk2efcxM8aCO4s_DSJHpyC2GBSwJ9DdWEos.jpg,,,,,
655,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,2,5j7pnk,scyfer.nl,Data-Efficient Deep Learning with G-CNNs,https://www.reddit.com/r/MachineLearning/comments/5j7pnk/dataefficient_deep_learning_with_gcnns/,dzyl,1482169315,,0,3,False,default,,,,,
656,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,3,5j80ya,scyfer.nl,[R] Data-Efficient Deep Learning with G-CNNs,https://www.reddit.com/r/MachineLearning/comments/5j80ya/r_dataefficient_deep_learning_with_gcnns/,tscohen,1482172480,,15,26,False,http://b.thumbs.redditmedia.com/UTxgdkXu3qqR1-Tsa4yQ2g-A3PQRYeDW-BksTe-JNrs.jpg,,,,,
657,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,3,5j834y,self.MachineLearning,[D] Learning Lua for ML  Worth it?,https://www.reddit.com/r/MachineLearning/comments/5j834y/d_learning_lua_for_ml_worth_it/,onewugtwowugs,1482173094,"I just saw the announcement of [OpenNMT](http://opennmt.net)  an open source neural machine translation system built with Torch for production usage. While I don't work much with machine translation, it made me wonder what the current status of using Lua in the community is and whether it would be worth spending time learning at least the basics of it. As someone who is mainly using Python and has so far been pretty happy with it, my understanding has been that its use outside of Facebook is quite limited, but perhaps this is changing? What has your experience been?",9,2,False,self,,,,,
658,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,4,5j871z,arxiv.org,[R] Unsupervised Pixel-Level Domain Adaptation with Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/5j871z/r_unsupervised_pixellevel_domain_adaptation_with/,bousmalis,1482174174,,4,14,False,default,,,,,
659,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,6,5j90dx,jalammar.github.io,A Visual and Interactive Guide to the Basics of Neural Networks,https://www.reddit.com/r/MachineLearning/comments/5j90dx/a_visual_and_interactive_guide_to_the_basics_of/,Dogsindahouse1,1482182123,,0,1,False,default,,,,,
660,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,6,5j918j,self.MachineLearning,Generative models trained with large datasets,https://www.reddit.com/r/MachineLearning/comments/5j918j/generative_models_trained_with_large_datasets/,anonDogeLover,1482182355,[removed],0,1,False,default,,,,,
661,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,8,5j9vjf,medium.com,Teaching a Machine to Steer a Car (5 Open Sourced Models!),https://www.reddit.com/r/MachineLearning/comments/5j9vjf/teaching_a_machine_to_steer_a_car_5_open_sourced/,oliverfromudacity,1482191031,,0,1,False,default,,,,,
662,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,8,5j9ykq,opennmt.net,[P] OpenNMT: Open-Source Neural Machine Translation,https://www.reddit.com/r/MachineLearning/comments/5j9ykq/p_opennmt_opensource_neural_machine_translation/,tuan3w,1482191992,,6,32,False,default,,,,,
663,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,9,5ja7nq,medium.com,[R] Yes you should understand backprop,https://www.reddit.com/r/MachineLearning/comments/5ja7nq/r_yes_you_should_understand_backprop/,waleedka,1482194870,,40,239,False,http://b.thumbs.redditmedia.com/Z6pQ1AG2f8TE3DMBH3Ld2jhdhi0rt3z8P9wY7pgf3gc.jpg,,,,,
664,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,9,5ja8qy,self.MachineLearning,Keras/Theano LSTM exact mathematical implementation,https://www.reddit.com/r/MachineLearning/comments/5ja8qy/kerastheano_lstm_exact_mathematical_implementation/,Don_Mahoni,1482195221,[removed],0,1,False,default,,,,,
665,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,10,5jak8c,highpowercleaning.com.au,Melbourne Bond Back Cleaners - 100 Bond Back Guaranteed,https://www.reddit.com/r/MachineLearning/comments/5jak8c/melbourne_bond_back_cleaners_100_bond_back/,TheresaLampgx60,1482199138,,0,1,False,default,,,,,
666,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,11,5jappf,gananath.github.io,[P] DrugAI: Classification of Drug Like molecules using Artificial Neural Network,https://www.reddit.com/r/MachineLearning/comments/5jappf/p_drugai_classification_of_drug_like_molecules/,gananath,1482201011,,2,4,False,http://b.thumbs.redditmedia.com/_UpkRg9bAV1ZVjJNV9QENYjcJ3B1DJjzCrrBoczOE4c.jpg,,,,,
667,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,11,5jau1t,self.MachineLearning,Getting started with ML,https://www.reddit.com/r/MachineLearning/comments/5jau1t/getting_started_with_ml/,yagizt,1482202550,[removed],0,1,False,default,,,,,
668,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,12,5javjo,self.MachineLearning,[D] what are some top machine learning journals for music?,https://www.reddit.com/r/MachineLearning/comments/5javjo/d_what_are_some_top_machine_learning_journals_for/,AntixK,1482203059,I am doing research on applying machine learning for music.  What are some top journals for this area?  ,10,3,False,self,,,,,
669,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,14,5jbfds,self.MachineLearning,[D] What is the current status of mathematical research in machine learning and deep learning?,https://www.reddit.com/r/MachineLearning/comments/5jbfds/d_what_is_the_current_status_of_mathematical/,yadec,1482210236,"There are a few things that I'm aware of but I can't seem to find much. I remember hearing about the paper by Hornik, et al. in 1989 that proved mathematically that neural networks are universal function approximators. I also see 18.657 from MIT OCW, which is a course that tries to present machine learning methods in a mathematically rigorous way.

However, the vast majority of the research I see on this sub as well as places like arXiv present only empirical evidence that shows how a specific kind of model architecture is able to do some task well. For example, a paper on residual networks might say that they perform very well on ImageNet and that this makes sense with some intuitive basis, but as far as I can tell, there are no rigorous mathematical proofs to show why residual networks approximate the ideal function closer than normal convolutional networks, or even just a regular vanilla neural network.

In a field based on calculus (backprop) and linear algebra, one would expect more mathematical rigor. Is this something certain people are working on? Or have I simply been looking in the wrong places?",12,12,False,self,,,,,
670,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,14,5jbkzp,linkedin.com,"8 great applications of ""Machine Learning""",https://www.reddit.com/r/MachineLearning/comments/5jbkzp/8_great_applications_of_machine_learning/,MCAL_Training,1482212401,,0,1,False,default,,,,,
671,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,14,5jbmy0,github.com,[P] I made a tool that renders LaTeX for your Github Readmes. Now you can have pretty equations in addition to your pretty graphs.,https://www.reddit.com/r/MachineLearning/comments/5jbmy0/p_i_made_a_tool_that_renders_latex_for_your/,possiblyquestionable,1482213173,,6,92,False,http://b.thumbs.redditmedia.com/odL6889C99u4hLwl-iOXNm47v6-LPgaakpo91-UL9nY.jpg,,,,,
672,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,14,5jbmyq,arxiv.org,[R] [1612.05695] Quantum reinforcement learning,https://www.reddit.com/r/MachineLearning/comments/5jbmyq/r_161205695_quantum_reinforcement_learning/,lukepaulson,1482213187,,2,6,False,default,,,,,
673,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,15,5jbvjn,self.MachineLearning,Overclocked EVGA FTW/ASUS STRIX GTX 1070 vs Blower-design GTX 1080 (ASUS Turbo) for machine learning or analytics?,https://www.reddit.com/r/MachineLearning/comments/5jbvjn/overclocked_evga_ftwasus_strix_gtx_1070_vs/,shstan,1482216784,[removed],0,1,False,default,,,,,
674,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,17,5jc5xb,self.MachineLearning,[D] How to make RNNs consistent?,https://www.reddit.com/r/MachineLearning/comments/5jc5xb/d_how_to_make_rnns_consistent/,AntixK,1482221740,"I have a LSTM model built in tensorflow. I ran the code on a dataset for classification.

I tried several trials but then the results from each trial were different and not consistent at all. I have attached the results from two such trials - One which performs exceptionally well and the other not so good. In these trials, I haven't changed any code or data whatsoever.

[Loss Function Plot](https://drive.google.com/file/d/0Byqpd-34yYZrZUwzUHY1bVhEeEk/view?usp=sharing)

[Training Accuracy Plot](https://drive.google.com/file/d/0Byqpd-34yYZrQmd4Y2ZDZnhhcms/view?usp=sharing)

How do I resolve this? Is it due to initialisation problems? I am using the standard (easiest) way 

    init = tf.initialize_all_variables()
Or is there an inherent problem with my model? (If yes, I will provide the details of my model, Basically, I simply modified the RNN_MNIST.py example from tensorflow)

Furthermore, why am I getting such sudden jumps in the loss function? I am currently using Adam Optimizer. Sorry if these questions are elementary, this is my first attempt in learning ML.

Thank you",7,3,False,self,,,,,
675,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,19,5jcknn,sscaitournament.com,Student StarCraft AI Tournament is live now,https://www.reddit.com/r/MachineLearning/comments/5jcknn/student_starcraft_ai_tournament_is_live_now/,breakk,1482229375,,0,2,False,default,,,,,
676,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,20,5jcux9,self.MachineLearning,Python/C libraries diagnostic tests for classification/regression model fitting/tests ?,https://www.reddit.com/r/MachineLearning/comments/5jcux9/pythonc_libraries_diagnostic_tests_for/,Hey_Me_Its_U,1482234424,[removed],0,1,False,default,,,,,
677,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,20,5jcvgw,docs.seldon.io,Seldon v1.4 released with gRPC and protocol buffers for faster machine learning APIs,https://www.reddit.com/r/MachineLearning/comments/5jcvgw/seldon_v14_released_with_grpc_and_protocol/,[deleted],1482234697,[deleted],0,1,False,default,,,,,
678,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,21,5jcwrc,docs.seldon.io,[P] Seldon v1.4 uses gRPC with protocol buffers for faster machine learning APIs,https://www.reddit.com/r/MachineLearning/comments/5jcwrc/p_seldon_v14_uses_grpc_with_protocol_buffers_for/,ahousley,1482235341,,0,1,False,default,,,,,
679,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,21,5jd01u,self.MachineLearning,Diagnostic tests while using TensorFlow,https://www.reddit.com/r/MachineLearning/comments/5jd01u/diagnostic_tests_while_using_tensorflow/,Hey_Me_Its_U,1482236757,[removed],0,1,False,default,,,,,
680,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,22,5jd4v3,ghyslain.me,A Junior Data Scientist Bookshelf (including free versions and HN discussions),https://www.reddit.com/r/MachineLearning/comments/5jd4v3/a_junior_data_scientist_bookshelf_including_free/,cocorico,1482238829,,0,1,False,default,,,,,
681,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,22,5jdcje,nytimes.com,Google Translate and the Great AI Awakening,https://www.reddit.com/r/MachineLearning/comments/5jdcje/google_translate_and_the_great_ai_awakening/,jonfla,1482241925,,0,1,False,default,,,,,
682,MachineLearning,t5_2r3gv,2016-12-20,2016,12,20,23,5jdftn,self.MachineLearning,What's more important in machine learning research?Maths or programming?,https://www.reddit.com/r/MachineLearning/comments/5jdftn/whats_more_important_in_machine_learning/,Hamchuntan,1482243120,[removed],0,1,False,default,,,,,
683,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,0,5jdsru,self.MachineLearning,Can a bigger neural network be less predictive than a smaller subset neural network?,https://www.reddit.com/r/MachineLearning/comments/5jdsru/can_a_bigger_neural_network_be_less_predictive/,styagi68,1482247580,[removed],0,1,False,default,,,,,
684,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,0,5jdt49,youtu.be,A Deep Learning book gift for AI enthusiasts/beginners,https://www.reddit.com/r/MachineLearning/comments/5jdt49/a_deep_learning_book_gift_for_ai/,spmallick,1482247698,,2,1,False,default,,,,,
685,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,0,5jdxor,medium.com,[P] The Programmers Guide to Booking a Concert,https://www.reddit.com/r/MachineLearning/comments/5jdxor/p_the_programmers_guide_to_booking_a_concert/,naturalespresso,1482249119,,0,2,False,default,,,,,
686,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,1,5je6vw,amazon.com,[Book] Building Machine Learning Projects with Tensorflow,https://www.reddit.com/r/MachineLearning/comments/5je6vw/book_building_machine_learning_projects_with/,temporal1234,1482251820,,0,1,False,default,,,,,
687,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,1,5je8fi,self.MachineLearning,"AI at our fingertips, the modern esperanto",https://www.reddit.com/r/MachineLearning/comments/5je8fi/ai_at_our_fingertips_the_modern_esperanto/,lsalazarg,1482252254,[removed],0,1,False,default,,,,,
688,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,1,5je9i8,self.MachineLearning,"In your experience, what's a good reinforcement learning library in Python. For example, how's RLLab vs PyBrain?",https://www.reddit.com/r/MachineLearning/comments/5je9i8/in_your_experience_whats_a_good_reinforcement/,skfit,1482252561,[removed],0,1,False,default,,,,,
689,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,3,5jepzd,self.MachineLearning,What are current relations between (algebraic) topology and deep learning?,https://www.reddit.com/r/MachineLearning/comments/5jepzd/what_are_current_relations_between_algebraic/,[deleted],1482257247,[removed],0,1,False,default,,,,,
690,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,4,5jfaox,self.MachineLearning,[D] What are current relations between (algebraic) topology and deep learning?,https://www.reddit.com/r/MachineLearning/comments/5jfaox/d_what_are_current_relations_between_algebraic/,konasj,1482263102,"I am a graduate student in AI with an undergrad in pure math (algebraic topology, abstract algebra, PDEs). Currently I am working a lot on deep learning - especially manifold learning and nonlinear embeddings. Since finding a mapping on a nonlinear sub manifold and the normally unknown network architecture are closely linked I asked myself, if there is a connection between the topological properties of the map/diffeomorphism generated by a DNN and it's capabilities to learn certain things. I found [this](http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/) introduction on colah's blog and I also started to read on the methodology of Gunnar Carlson's topological data analysis. However, colah's blog gives me the idea where the journey could head to and Carlson's way is not really connected to research on DNN (in terms of learning diffeomorphism of your data) - as far as I see it. But I am stuck finding deeper literature on that. Can you give any recommendation for papers or introductory work on this boundary? Everything bringing together the topology of neural networks, group theory and algebraization (e.g. using functors such as chain complexes or homotopy) would really interest me.",33,74,False,self,,,,,
691,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,4,5jfbkc,laurent-dinh.github.io,[R] Variational Auto-Encoders Optimize a Joint,https://www.reddit.com/r/MachineLearning/comments/5jfbkc/r_variational_autoencoders_optimize_a_joint/,prajit,1482263363,,5,10,False,http://b.thumbs.redditmedia.com/7i8TYvw4gxTtUZqWvGHEKNoI5CFnoHcDF3e9cYDSaoM.jpg,,,,,
692,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,6,5jft0f,simplystatistics.org,A non-comprehensive list of awesome things other people did in 2016  Simply Statistics,https://www.reddit.com/r/MachineLearning/comments/5jft0f/a_noncomprehensive_list_of_awesome_things_other/,cavedave,1482268365,,2,13,False,default,,,,,
693,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,6,5jfydj,arxiv.org,[1612.04609] Neural Emoji Recommendation in Dialogue Systems,https://www.reddit.com/r/MachineLearning/comments/5jfydj/161204609_neural_emoji_recommendation_in_dialogue/,Sebastian-JF,1482269886,,4,1,False,default,,,,,
694,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,7,5jg35w,blogs.microsoft.com,Microsoft dataset aims to help researchers create tools to answer questions as well as people,https://www.reddit.com/r/MachineLearning/comments/5jg35w/microsoft_dataset_aims_to_help_researchers_create/,hoaphumanoid,1482271288,,0,1,False,default,,,,,
695,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,7,5jg380,self.MachineLearning,What techniques could help with understanding cost drivers for vehicle repairs?,https://www.reddit.com/r/MachineLearning/comments/5jg380/what_techniques_could_help_with_understanding/,montrex,1482271307,[removed],0,1,False,default,,,,,
696,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,7,5jg57w,course.fast.ai,Deep Learning For Coders18 hours of lessons for free,https://www.reddit.com/r/MachineLearning/comments/5jg57w/deep_learning_for_coders18_hours_of_lessons_for/,[deleted],1482271910,[deleted],0,1,False,default,,,,,
697,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,7,5jg7b8,course.fast.ai,[P] Deep Learning For Coders18 hours of lessons for free,https://www.reddit.com/r/MachineLearning/comments/5jg7b8/p_deep_learning_for_coders18_hours_of_lessons_for/,jeremyhoward,1482272540,,79,346,False,http://a.thumbs.redditmedia.com/U7R0JHbZZQg5VS-zfOQ1PLnhCn_4T2vpVpbxD4bhOl4.jpg,,,,,
698,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,7,5jgc4i,techrepublic.com,The 6 most exciting AI advances of 2016,https://www.reddit.com/r/MachineLearning/comments/5jgc4i/the_6_most_exciting_ai_advances_of_2016/,8000008,1482273960,,0,1,False,default,,,,,
699,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,11,5jheeo,self.MachineLearning,"[R] Overfitting in Neural Nets: Backpropagation, Conjugate Gradient, and Early Stopping, NIPS2000",https://www.reddit.com/r/MachineLearning/comments/5jheeo/r_overfitting_in_neural_nets_backpropagation/,ultrakoge,1482286526,"I've been applying deep neural networks to medical images. One of the main obstacles in this domain is the lack of enough training data which often leads to poor generalization. 

While trying hyper parameter tuning to overcome the overfitting including depth/width of ths network, dropout ratio, weight decay term, etc, I found simple early stopping was quite effective. 

Below is the link to the very interesting paper which explains what happens during the back prop and the role of the early stopping:
https://papers.nips.cc/paper/1895-overfitting-in-neural-nets-backpropagation-conjugate-gradient-and-early-stopping",6,16,False,self,,,,,
700,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,11,5jhehz,github.com,[P] Pre-trained word vectors of 30+ languages,https://www.reddit.com/r/MachineLearning/comments/5jhehz/p_pretrained_word_vectors_of_30_languages/,longinglove,1482286560,,5,27,False,http://b.thumbs.redditmedia.com/XVaaAxFhRz1MJfbrNHV-xaZNrHzcZs-EjHkocT01BBE.jpg,,,,,
701,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,17,5jiu3z,self.MachineLearning,Does SLI-ing two GTX-1080 benifit in DeepLearning?,https://www.reddit.com/r/MachineLearning/comments/5jiu3z/does_sliing_two_gtx1080_benifit_in_deeplearning/,Coderx7,1482308602,[removed],0,1,False,default,,,,,
702,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,18,5jj099,self.MachineLearning,Using feature importance as a tool for Feature Selection,https://www.reddit.com/r/MachineLearning/comments/5jj099/using_feature_importance_as_a_tool_for_feature/,xristos_forokolomvos,1482311795,"Suppose the following scenario:

You have a dataset with labelled data and you train two models on it,   a Random Forest Classifier and a XGBoost Classifier. Then you plot the feature importances calculated by either of the classifiers and you notice some differences. That's kind of expected because these two classifiers are fundamentally different and capture varying non-linearities in the data. 

The question is, what does it tell us about a feature that one classifier cares about it while another ignores it? Has anyone experimented with this type of feature selection? Thoughts / comments?

",8,16,False,self,,,,,
703,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,18,5jj0nb,self.MachineLearning,Is a GTX980 bottlenecked with an Intel G3220 processor in a deep learning usage?,https://www.reddit.com/r/MachineLearning/comments/5jj0nb/is_a_gtx980_bottlenecked_with_an_intel_g3220/,Coderx7,1482312001,[removed],0,1,False,default,,,,,
704,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,18,5jj26g,mixmachinery.com,How can use the chemical paint mixer shaker?,https://www.reddit.com/r/MachineLearning/comments/5jj26g/how_can_use_the_chemical_paint_mixer_shaker/,mixmachinery,1482312812,,1,1,False,default,,,,,
705,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,19,5jjbul,dzone.com,Apache Flink: The Next Gen Big Data Analytics Framework - DZone Big Data,https://www.reddit.com/r/MachineLearning/comments/5jjbul/apache_flink_the_next_gen_big_data_analytics/,Sibanjan,1482317685,,0,1,False,default,,,,,
706,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,20,5jjf8l,aimakes.com,"Online gallery for machine art, now accepting submissions",https://www.reddit.com/r/MachineLearning/comments/5jjf8l/online_gallery_for_machine_art_now_accepting/,thelibar,1482319346,,15,5,False,http://b.thumbs.redditmedia.com/3hZdhIuhZWcHc8Cjw8iPZUrpRkVmkgt--tg_wNjZTRg.jpg,,,,,
707,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,22,5jjya5,self.MachineLearning,Contribute to Machine learning and Datascience research and stand a chance to win prizes,https://www.reddit.com/r/MachineLearning/comments/5jjya5/contribute_to_machine_learning_and_datascience/,akoshodi,1482327696,[removed],0,1,False,default,,,,,
708,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,22,5jjylo,self.MachineLearning,[D] Deep Learning Twitter Loop,https://www.reddit.com/r/MachineLearning/comments/5jjylo/d_deep_learning_twitter_loop/,[deleted],1482327819,[deleted],0,1,False,default,,,,,
709,MachineLearning,t5_2r3gv,2016-12-21,2016,12,21,22,5jjzny,self.MachineLearning,[D] Deep Learning Twitter Loop,https://www.reddit.com/r/MachineLearning/comments/5jjzny/d_deep_learning_twitter_loop/,peterkuharvarduk,1482328223,"If you want to stay in the know on all the up-to-date deep learning news (without absurd retweet overlap), here the people to follow on Twitter based on your needs. I've been part of the community for over two years so I thought I'd share a bit about the ecosystem. (**disclaimer**: Based on my experience and people below wear multiple hats which is what makes them worthy of following. I just wanted some amusing categories).

**Twitter List**: https://twitter.com/DL_ML_Loop/lists/deep-learning-loop/members (You can quickly follow people straight down the list. **Note:** Follow them in addition to subscribing because the lists have been a bit weird lately and not working for some people in the comments below after a while.)

**Paparazi**: 
&gt;&gt; Jack Clark [@jackclarkSF](https://twitter.com/jackclarkSF)

&gt;&gt; Denny Britz [@dennybritz](https://twitter.com/dennybritz)

**Chatty Professors**:
&gt;&gt; Nando De Freitas [@NandoDF](https://twitter.com/NandoDF)

&gt;&gt; Fei-Fei Li [@drfeifei](https://twitter.com/drfeifei)

&gt;&gt; Andrew Moore [@awmcmu](https://twitter.com/awmcmu)

&gt;&gt; Daphne Koller [@DaphneKoller](https://twitter.com/DaphneKoller)

&gt;&gt; Kyunghyun Cho [@kchonyc](https://twitter.com/kchonyc)

&gt;&gt; Suchi Saria [@suchisaria](https://twitter.com/suchisaria)

&gt;&gt; Christopher Manning [@chrmanning](https://twitter.com/chrmanning)

**Captains of Industry**:
&gt;&gt; Hugo Larochelle [@hugo_larochelle](https://twitter.com/following)

&gt;&gt; Russ SalakHutdinov [@rsalakhu](https://twitter.com/rsalakhu)

&gt;&gt; Richard Socher [@RichardSocher](https://twitter.com/RichardSocher)

&gt;&gt; Greg Brockman [@gdb](https://twitter.com/gdb)

&gt;&gt; Demis Hassabis [@demishassabis](https://twitter.com/demishassabis)

&gt;&gt; Andrej Karpathy [@karpathy](https://twitter.com/karpathy)

&gt;&gt; Oriol Vinyals [@OriolVinyalsML](https://twitter.com/OriolVinyalsML)

&gt;&gt; Soumith Chintala [@soumithchintala](https://twitter.com/soumithchintala)

&gt;&gt; Ian Goodfellow [@goodfellow_ian](https://twitter.com/goodfellow_ian)

&gt;&gt; Oriol Vinyals [@OriolVinyalsML](https://twitter.com/oriolvinyalsml)

&gt;&gt; Alec Radford [@AlecRad](https://twitter.com/AlecRad)

&gt;&gt; Adam Coates [@adampaulcoates](https://twitter.com/adampaulcoates)

&gt;&gt; Shakir Mohammed [@shakir_za](https://twitter.com/shakir_za)

**The Cool Kids**: (HIGHLY informative/**entertaining**) 
&gt;&gt; Hardmaru [@hardmaru](https://twitter.com/hardmaru)

&gt;&gt; Francois Chollet [@fchollet](https://twitter.com/fchollet)

&gt;&gt; Smerity [@Smerity](https://twitter.com/Smerity)

&gt;&gt; Miles Brundage [@Miles_Brundage](https://twitter.com/Miles_Brundage)

**Celebrities**:
&gt;&gt; Yann LeCun [@ylecun](https://twitter.com/ylecun)

&gt;&gt; Andrew Ng [@AndrewYNg](https://twitter.com/andrewyng)

&gt;&gt; Elon Musk [@elonmusk](https://twitter.com/elonmusk)

**Justice League**:
&gt;&gt; OpenAI [@OpenAI](https://twitter.com/OpenAI)

&gt;&gt; DeepMind [@DeepMindAI](https://twitter.com/deepmindai)

&gt;&gt; Google Research [@googleresearch](https://twitter.com/googleresearch)

&gt;&gt; Baidu [@BaiduResearch](https://twitter.com/BaiduResearch)


**Hoarders**:
&gt;&gt; Deep Hub [@Deep_Hub](https://twitter.com/Deep_Hub)

&gt;&gt; FastML Extra [@fastml_extra](https://twitter.com/fastml_extra)

&gt;&gt; ML Reddit [@slashml](https://twitter.com/slashML)


**Artists**:
&gt;&gt; Samim [@samim](https://twitter.com/samim)

&gt;&gt; Roelof Pieters [@graphific](https://twitter.com/graphific?lang=en)


**Rebels**:
&gt;&gt; Bored Yann Lecun [@boredyannlecun](https://twitter.com/boredyannlecun)

&gt;&gt; ML_Hipster [@ML_Hipster](https://twitter.com/ml_hipster)


**Game Changers**:
&gt;&gt; Denny Britz [@dennybritz](https://twitter.com/dennybritz)

&gt;&gt; Goku Mohandas [@GokuMohandas](https://twitter.com/GokuMohandas)

&gt;&gt; Jeremy Howard [@jeremyphoward](https://twitter.com/jeremyphoward)

&gt;&gt; Danijar Hafner [@danijarh](https://twitter.com/danijarh)

&gt;&gt; Chris Olah [@ch402](https://twitter.com/ch402)",51,169,False,self,,,,,
710,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,0,5jke29,self.MachineLearning,Suggestions for studying Reinforcement Learning during the winter,https://www.reddit.com/r/MachineLearning/comments/5jke29/suggestions_for_studying_reinforcement_learning/,domarps123,1482333208,[removed],0,1,False,default,,,,,
711,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,0,5jkgwt,self.MachineLearning,"Help me choose a name for a Machine Learning, AI, Deep Learning blog that will help portuguese speakers to learn these techniques",https://www.reddit.com/r/MachineLearning/comments/5jkgwt/help_me_choose_a_name_for_a_machine_learning_ai/,vmesel,1482334100,[removed],0,1,False,default,,,,,
712,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,0,5jki8n,self.MachineLearning,4 Tips for Improving Alert Response Times,https://www.reddit.com/r/MachineLearning/comments/5jki8n/4_tips_for_improving_alert_response_times/,Everything_Cyber,1482334517,[removed],0,1,False,default,,,,,
713,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,0,5jklj9,self.MachineLearning,"Simple Questions Thread December 21, 2016",https://www.reddit.com/r/MachineLearning/comments/5jklj9/simple_questions_thread_december_21_2016/,AutoModerator,1482335552,[removed],0,1,False,default,,,,,
714,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,1,5jksdm,self.MachineLearning,"[D] Training a Convolution Neural Network, what should I try next?",https://www.reddit.com/r/MachineLearning/comments/5jksdm/d_training_a_convolution_neural_network_what/,upulbandara,1482337491,"I trained a CNN with three convolutional (+ max-pooling) layers ( 5x5 filters, depths of layers: 64, 64, 128). After 120 epochs both dev and training accuracies are close to one. But there is a significant gap between these two curves. For details please refer:

https://goo.gl/photos/FfB97zMsqfjay4ux9

What should I try (create a bigger network with more layers, increase the number of layers, create more augmented data and etc.) next in order to increase the accuracy of the CNN?

Thanks,


",11,2,False,self,,,,,
715,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,3,5jlh7n,openai.com,Faulty Reward Functions in the Wild,https://www.reddit.com/r/MachineLearning/comments/5jlh7n/faulty_reward_functions_in_the_wild/,mappingbabel,1482344653,,0,2,False,default,,,,,
716,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,4,5jlvu2,self.MachineLearning,Forcing neural network to more diverse outputs,https://www.reddit.com/r/MachineLearning/comments/5jlvu2/forcing_neural_network_to_more_diverse_outputs/,derk22,1482348836,[removed],0,1,False,default,,,,,
717,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,5,5jm4hk,self.MachineLearning,consultant shop recommendations,https://www.reddit.com/r/MachineLearning/comments/5jm4hk/consultant_shop_recommendations/,segelah,1482351359,[removed],0,1,False,default,,,,,
718,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,5,5jm8bm,youtube.com,How to Make a Tic Tac Toe Neural Network Easily (LIVE),https://www.reddit.com/r/MachineLearning/comments/5jm8bm/how_to_make_a_tic_tac_toe_neural_network_easily/,funtwo2,1482352487,,0,1,False,default,,,,,
719,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,5,5jmbm9,github.com,[P] Prediction Template Learning (Now with graphs),https://www.reddit.com/r/MachineLearning/comments/5jmbm9/p_prediction_template_learning_now_with_graphs/,inboble,1482353448,,0,2,False,http://a.thumbs.redditmedia.com/6bZK4gZlBFoyibeYVcJtCg4k_Ie9X5Lcw8mwhButOg8.jpg,,,,,
720,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,6,5jmg7s,i.redd.it,Introduction to Computational Learning Theory (1994),https://www.reddit.com/r/MachineLearning/comments/5jmg7s/introduction_to_computational_learning_theory_1994/,thecity2,1482354795,,1,1,False,default,,,,,
721,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,6,5jmogx,self.MachineLearning,what is the role of sequence length in RNN,https://www.reddit.com/r/MachineLearning/comments/5jmogx/what_is_the_role_of_sequence_length_in_rnn/,John_Smith111,1482357240,[removed],0,1,False,default,,,,,
722,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,7,5jmutv,self.MachineLearning,[D] attention mechanism in current google neural translation model?,https://www.reddit.com/r/MachineLearning/comments/5jmutv/d_attention_mechanism_in_current_google_neural/,djc1000,1482359141,"I'm confused about the function of attention in the google model, as published in Johnson 2016.

Johnson says the model is like the one introduced in Bahdanau 2015. In Bahdanau, the attention is in a context vector which is fed into the decoder along with the output from the current encoder step. The context vector is the weighted sum of annotation vectors for each step of the input sequence. The weights are calculated through a separate feedforward network that takes as input the current outputs from low-level hidden layers in the recurrences. 

Johnson, though, says that the context vector is formed by passing the output from the lowest level of the decoder rnn through a separate feedforward network. This would imply that the weighted annotations are not being used. That also seems to be what's shown in the diagram, where the output from the attention mechanism is passed directly to each layer of the decoder lstm above the first.

Did Johnson mean to say that the annotation weight vector, rather than the context vector, is formed by passing the output from the lowest decoder lstm through a feed forward network? Am I totally misunderstanding this? ",4,5,False,self,,,,,
723,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,8,5jn3l7,github.com,[R] Seg-Torch: Generic code base for image segmentation by deep learning.,https://www.reddit.com/r/MachineLearning/comments/5jn3l7/r_segtorch_generic_code_base_for_image/,erogol,1482361875,,0,10,False,http://a.thumbs.redditmedia.com/FnbGzQAMqnw6aEIpkvK-Y7Ze2-9d1MctXQYVODMDXt4.jpg,,,,,
724,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,8,5jn5h6,warmspringwinds.github.io,[P] Demystifying Tensorflow's tfrecords,https://www.reddit.com/r/MachineLearning/comments/5jn5h6/p_demystifying_tensorflows_tfrecords/,[deleted],1482362456,[deleted],0,0,False,default,,,,,
725,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,8,5jn9pe,cbinsights.com,AI Deals And Dollars Have Already Reached Record Annual Highs,https://www.reddit.com/r/MachineLearning/comments/5jn9pe/ai_deals_and_dollars_have_already_reached_record/,vonnik,1482363810,,0,1,False,default,,,,,
726,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,10,5jnwxd,fertilizer-machine.com,How to Properly Choose Desirable Organic Fertilizer Equipment,https://www.reddit.com/r/MachineLearning/comments/5jnwxd/how_to_properly_choose_desirable_organic/,Anne0712,1482371567,,1,1,False,default,,,,,
727,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,12,5jobdo,self.MachineLearning,[D]To use or not to use word2vec's while training seq2seq?,https://www.reddit.com/r/MachineLearning/comments/5jobdo/dto_use_or_not_to_use_word2vecs_while_training/,cvikasreddy,1482376704,"I am building a simple seq2seq model in English currently the input is a one hot representation of words.

1.I would like to know if using word2vec improves the performance.

2.The number of words used in my Corpus are very less, so does it make sense to build word2vec on my Corpus or use pre-built word2vecs.

3.If one hot representation is preferred, then which to use char embeddings or word embeddings (remember number of words in my Corpus is limited.).

Thanks.",2,1,False,self,,,,,
728,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,14,5jov5i,github.com,[P] A tool to view machine learning / computer vision image outputs directly in your iTerm2 terminal.,https://www.reddit.com/r/MachineLearning/comments/5jov5i/p_a_tool_to_view_machine_learning_computer_vision/,daleroberts0,1482384277,,6,39,False,http://b.thumbs.redditmedia.com/rjaYGCBO79PEf3iKQk7qgYpzEYtCMv-87LdSl9eh7ZM.jpg,,,,,
729,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,14,5jow1y,self.MachineLearning,Does anybody know about an active discord server dedicated to machine learning? Or any community for that matter.,https://www.reddit.com/r/MachineLearning/comments/5jow1y/does_anybody_know_about_an_active_discord_server/,iansee,1482384618,[removed],0,1,False,default,,,,,
730,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,14,5joy6o,self.MachineLearning,How to learn Advanced ML,https://www.reddit.com/r/MachineLearning/comments/5joy6o/how_to_learn_advanced_ml/,babganoush,1482385444,[removed],0,1,False,default,,,,,
731,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,16,5jp8qb,durantco.com,Combination Of Decoiler Or Flat Stock Straighteners,https://www.reddit.com/r/MachineLearning/comments/5jp8qb/combination_of_decoiler_or_flat_stock/,durantco,1482390061,,0,1,False,default,,,,,
732,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,16,5jpajk,self.MachineLearning,Deepmind Talk Video Links ?,https://www.reddit.com/r/MachineLearning/comments/5jpajk/deepmind_talk_video_links/,DollarAkshay,1482390920,[removed],0,1,False,default,,,,,
733,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,16,5jpb1n,casadei-busellato.com,Order Online CNC routers edgebander,https://www.reddit.com/r/MachineLearning/comments/5jpb1n/order_online_cnc_routers_edgebander/,casadeibusellato,1482391156,,0,1,False,default,,,,,
734,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,16,5jpbn2,github.com,Latex equation image recognition in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/5jpbn2/latex_equation_image_recognition_in_tensorflow/,[deleted],1482391454,[deleted],0,1,False,default,,,,,
735,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,16,5jpd3o,github.com,[P] Latex equation image recognition in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/5jpd3o/p_latex_equation_image_recognition_in_tensorflow/,ShakespearePoop,1482392133,,8,42,False,http://b.thumbs.redditmedia.com/CRbjiG1JZPDCHQLXuLtfagJpHJipLG1a53IydLgVW1M.jpg,,,,,
736,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,17,5jpgqv,arxiv.org,[R] Inference Compilation,https://www.reddit.com/r/MachineLearning/comments/5jpgqv/r_inference_compilation/,downtownslim,1482393963,,1,4,False,default,,,,,
737,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,17,5jpgu6,fertilizer-machines.com,Principles of Fertilizer Application: Balanced Fertilization &amp;amp; Timing,https://www.reddit.com/r/MachineLearning/comments/5jpgu6/principles_of_fertilizer_application_balanced/,frady2015,1482393997,,1,1,False,default,,,,,
738,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,17,5jpiaw,prlz77.github.io,[P] An early overview of ICLR2017,https://www.reddit.com/r/MachineLearning/comments/5jpiaw/p_an_early_overview_of_iclr2017/,prlz77,1482394775,,10,35,False,default,,,,,
739,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,18,5jpmu7,github.com,[P] Artstyle-Transfer with TensorFlow (portation of pretrained DmitryUlyanov/texture_nets model),https://www.reddit.com/r/MachineLearning/comments/5jpmu7/p_artstyletransfer_with_tensorflow_portation_of/,t_gyg,1482397214,,2,8,False,http://b.thumbs.redditmedia.com/aUiECEeQwU_x8obZUy_c6DD2CDf_WbEI5676f9vf5yY.jpg,,,,,
740,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,18,5jpnvz,self.MachineLearning,Looking for recommendations on Prolog Tutorials,https://www.reddit.com/r/MachineLearning/comments/5jpnvz/looking_for_recommendations_on_prolog_tutorials/,[deleted],1482397764,[removed],0,1,False,default,,,,,
741,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,18,5jpqk6,youtube.com,Wow! how amazing does the chemical paste continuous mixing impellers,https://www.reddit.com/r/MachineLearning/comments/5jpqk6/wow_how_amazing_does_the_chemical_paste/,mixmachinery,1482399145,,1,1,False,default,,,,,
742,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,19,5jpuef,durantco.com,Single Loop Controllers &amp; Industrial Process Controls System,https://www.reddit.com/r/MachineLearning/comments/5jpuef/single_loop_controllers_industrial_process/,durantco,1482401138,,0,1,False,default,,,,,
743,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,22,5jqj4o,blog.grakn.ai,Reviewing some of the year's best general ML stories,https://www.reddit.com/r/MachineLearning/comments/5jqj4o/reviewing_some_of_the_years_best_general_ml/,stichbury,1482412864,,0,1,False,default,,,,,
744,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,22,5jqk4d,youtube.com,You can't miss this type of multi functional chemical liquid blending eq...,https://www.reddit.com/r/MachineLearning/comments/5jqk4d/you_cant_miss_this_type_of_multi_functional/,mixmachinery,1482413273,,1,1,False,default,,,,,
745,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,22,5jqm1q,self.MachineLearning,ML conferences in Europe?,https://www.reddit.com/r/MachineLearning/comments/5jqm1q/ml_conferences_in_europe/,trance1st,1482414040,[removed],0,1,False,default,,,,,
746,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,23,5jqxd1,github.com,[P] DeepLab-LargeFOV for Semantic Image Segmentation in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/5jqxd1/p_deeplablargefov_for_semantic_image_segmentation/,_dr_sleep,1482418189,,0,3,False,http://b.thumbs.redditmedia.com/O3L_Op9qkVkt6noMAeQxSA3tfbZcf4FM-3ei9AC1xZE.jpg,,,,,
747,MachineLearning,t5_2r3gv,2016-12-22,2016,12,22,23,5jqyos,self.MachineLearning,[D]Can we compare clustering+classification with attention mechanism ?,https://www.reddit.com/r/MachineLearning/comments/5jqyos/dcan_we_compare_clusteringclassification_with/,erogol,1482418637,"From the initial investigation of attention mechanism (like memory networks) which is lately used for many NLP problems, I had a feeling that if we cluster the data and train a classifier per cluster, we might have something similar in essence. My assumption (not verified empirically) is each cluster might capture group specifier priorities (importance of a word or such) and then related classifier might learn based on this. (Each cluster behaves like a memory). For instance, for text classification, we can compute bag of words, cluster data and learn class labels for each cluster.

Of course this is not an end-to-end learning involving different incremental stages but simpler and more compute friendly.

Hope I could describe what is in my mind well.

How does it sounds? Do you think this is a valid analogy with a simpler idea? If you think, I am particularly wrong, please inform me why?

",0,5,False,self,,,,,
748,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,0,5jr1ns,self.MachineLearning,Implementing pre-trained TensorFlow,https://www.reddit.com/r/MachineLearning/comments/5jr1ns/implementing_pretrained_tensorflow/,hugokhf,1482419612,[removed],0,1,False,default,,,,,
749,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,0,5jr85u,pocketcluster.wordpress.com,"BigData and ML Example and Library Weekly Roundup  Dec. 22, 2016",https://www.reddit.com/r/MachineLearning/comments/5jr85u/bigdata_and_ml_example_and_library_weekly_roundup/,stkim1,1482421667,,0,1,False,default,,,,,
750,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,1,5jraz4,self.MachineLearning,Applications of machine learning,https://www.reddit.com/r/MachineLearning/comments/5jraz4/applications_of_machine_learning/,rkpsnh,1482422573,[removed],0,1,False,default,,,,,
751,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,1,5jrh8u,self.MachineLearning,[D] What are your favorite sequence-modeling / sequence-labeling tasks that require long-term dependencies?,https://www.reddit.com/r/MachineLearning/comments/5jrh8u/d_what_are_your_favorite_sequencemodeling/,rd11235,1482424456,"I'm interested in extending RNN architectures to do a better job at capturing extremely long-term dependencies in sequence-modeling / sequence-labeling tasks.

I have some specific tasks / datasets that are driving this, but to publish in ML conferences, I'd like to use some benchmark datasets that have been worked on extensively by the ML community.

One decent option: Permuted MNIST. Here, to classify correctly, the RNN needs to remember information for 100s of time steps. (But this is fairly toy like.)

Another option that might be decent (not sure yet): IAM Online handwriting recognition.

Some not-so-great options: JSB Chorales (music modeling) and TIMIT (phoneme recognition). I was surprised that these make up 2 out of the 3 datasets in [LSTM: A Search Space Odyssey](https://arxiv.org/abs/1503.04069), as even simple tanh RNNs do well on these tasks.

Anyone have any favorite tasks / datasets that require very long-term dependencies?",2,5,False,self,,,,,
752,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,1,5jril3,hackernoon.com,Deep Learning Cheat Sheet,https://www.reddit.com/r/MachineLearning/comments/5jril3/deep_learning_cheat_sheet/,[deleted],1482424849,[deleted],0,1,False,default,,,,,
753,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,1,5jrl79,twitter.com,[N] Elon Musk on Twitter : Tesla Autopilot vision neural net now working well. Just need to get a lot of road time to validate in a wide range of environments.,https://www.reddit.com/r/MachineLearning/comments/5jrl79/n_elon_musk_on_twitter_tesla_autopilot_vision/,anantzoid,1482425649,,163,300,False,http://a.thumbs.redditmedia.com/YKGbJcsQAxtrtv4W-ZGeQUHd6VxuuLoXSL9aTgJc-c0.jpg,,,,,
754,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,2,5jrrva,self.MachineLearning,[D] Advice on GPU training,https://www.reddit.com/r/MachineLearning/comments/5jrrva/d_advice_on_gpu_training/,c0cky_,1482427625,"What methods do you use to train models? Do you own your a training GPU, do you use EC2 instances?

I feel like it's a big barrier to training a decent model is there's a lot of time training and tweaking.",7,8,False,self,,,,,
755,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,2,5jrsif,techcrunch.com,A stealthy startup called Cerebras raised around $25 million to build deep learning hardware,https://www.reddit.com/r/MachineLearning/comments/5jrsif/a_stealthy_startup_called_cerebras_raised_around/,vonnik,1482427818,,0,1,False,default,,,,,
756,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,2,5jrsy9,hsaghir.github.io,[p] Denoising autoencoders vs. Variational autoencoders - a primer,https://www.reddit.com/r/MachineLearning/comments/5jrsy9/p_denoising_autoencoders_vs_variational/,saghirhr,1482427945,,8,36,False,http://b.thumbs.redditmedia.com/W83N1-VJPphDD2cDVn7Z6Cu3p-uEPSWEKSr_bK2icxQ.jpg,,,,,
757,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,2,5jru1u,medium.com,Principal Component Analysis,https://www.reddit.com/r/MachineLearning/comments/5jru1u/principal_component_analysis/,maheshkkumar,1482428261,,0,1,False,default,,,,,
758,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,2,5jrwm1,ataspinar.com,Perceptron Classification explained with Python code,https://www.reddit.com/r/MachineLearning/comments/5jrwm1/perceptron_classification_explained_with_python/,ataspinar,1482429018,,0,1,False,default,,,,,
759,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,3,5jrz0s,arxiv.org,New dataset for visual reasoning and question answering,https://www.reddit.com/r/MachineLearning/comments/5jrz0s/new_dataset_for_visual_reasoning_and_question/,strojax,1482429714,,0,1,False,default,,,,,
760,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,3,5js5bl,self.MachineLearning,College student looking for a low-budget way to get into ML / Data Science,https://www.reddit.com/r/MachineLearning/comments/5js5bl/college_student_looking_for_a_lowbudget_way_to/,moinnadeem,1482431522,[removed],0,1,False,default,,,,,
761,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,3,5js69t,self.MachineLearning,[D] Is there a difference between science and engineering in deep learning?,https://www.reddit.com/r/MachineLearning/comments/5js69t/d_is_there_a_difference_between_science_and/,rantana,1482431778,"Going through the papers posted to ICLR, it seems like most of the abstracts read like elevator pitches for why I should implement their idea (much like an engineer would pitch to their manager). 

Is it just me or is there less analysis about emergent properties of existing architectures or interesting studies about failure cases this year?

I miss papers like:

""Visualizing and Understanding Convolutional Networks""
https://arxiv.org/abs/1311.2901

""Intriguing properties of neural networks""
https://arxiv.org/abs/1312.6199

There are of course exceptions, but have we hit a wall in the science of deep learning? Or is what I'm defining as engineering (i.e. applications) also science?",5,2,False,self,,,,,
762,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,3,5jsb5k,tech.gilt.com,Gilt  Open Source / Deep Learning at GILT,https://www.reddit.com/r/MachineLearning/comments/5jsb5k/gilt_open_source_deep_learning_at_gilt/,[deleted],1482433166,[deleted],0,1,False,default,,,,,
763,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,4,5jscnl,self.MachineLearning,Good books to start learning AI / machine learning that are written in Python3 ?(version 3.x),https://www.reddit.com/r/MachineLearning/comments/5jscnl/good_books_to_start_learning_ai_machine_learning/,akmarap,1482433557,[removed],0,1,False,default,,,,,
764,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,5,5jt02a,ibm.com,[N] The Most Popular Languages For Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5jt02a/n_the_most_popular_languages_for_machine_learning/,[deleted],1482440275,[deleted],0,0,False,default,,,,,
765,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,5,5jt08x,medium.com,Using graph centrality to find important movie characters,https://www.reddit.com/r/MachineLearning/comments/5jt08x/using_graph_centrality_to_find_important_movie/,BabiCarter,1482440334,,0,1,False,default,,,,,
766,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,6,5jt4rv,github.com,[P] StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/5jt4rv/p_stackgan_text_to_photorealistic_image_synthesis/,han_z,1482441647,,19,61,False,http://b.thumbs.redditmedia.com/RPjnGT8SQ6lUgpstFu_Is-ZIiDAnRK0Y_FuKCww_PDk.jpg,,,,,
767,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,7,5jthh4,conf.startup.ml,Distillation of Deepnets,https://www.reddit.com/r/MachineLearning/comments/5jthh4/distillation_of_deepnets/,arshakn,1482445471,,0,1,False,default,,,,,
768,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,8,5jtu4i,self.MachineLearning,Any projects that can count the value of a stack of poker chips from a video feed?,https://www.reddit.com/r/MachineLearning/comments/5jtu4i/any_projects_that_can_count_the_value_of_a_stack/,This_is_for_real_yes,1482449597,[removed],0,1,False,default,,,,,
769,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,10,5jugp7,github.com,[P] Can Convolutional Neural Networks Crack Sudoku Puzzles?,https://www.reddit.com/r/MachineLearning/comments/5jugp7/p_can_convolutional_neural_networks_crack_sudoku/,longinglove,1482457421,,10,9,False,http://b.thumbs.redditmedia.com/oVtBlXM98fHRl0tuFl_SsJkmaFKhxiMWM0CivMz4xDw.jpg,,,,,
770,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,11,5juq1z,adgefficiency.com,[P] Forecasting UK Imbalance Price using a Multilayer Perceptron Neural Network,https://www.reddit.com/r/MachineLearning/comments/5juq1z/p_forecasting_uk_imbalance_price_using_a/,ADGEfficiency,1482460787,,0,5,False,http://b.thumbs.redditmedia.com/xYcAREUq7b1W2t33ExFlQQmuWC7UQBqFh9mpm1soauI.jpg,,,,,
771,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,13,5jv7xr,self.MachineLearning,How to remove Batch normalization layer for deployment after training a net with BN?,https://www.reddit.com/r/MachineLearning/comments/5jv7xr/how_to_remove_batch_normalization_layer_for/,dongshuhao12,1482467664,[removed],0,1,False,default,,,,,
772,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,14,5jvi7l,self.MachineLearning,How do I get Octave to work on my Mac?,https://www.reddit.com/r/MachineLearning/comments/5jvi7l/how_do_i_get_octave_to_work_on_my_mac/,icevermin,1482471634,[removed],0,1,False,default,,,,,
773,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,15,5jvob0,arxiv.org,[R] Towards Information-Seeking Agents,https://www.reddit.com/r/MachineLearning/comments/5jvob0/r_towards_informationseeking_agents/,downtownslim,1482474244,,6,26,False,default,,,,,
774,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,15,5jvpsf,self.MachineLearning,"""[Discussion]"", ""[D]""Data derived from base data",https://www.reddit.com/r/MachineLearning/comments/5jvpsf/discussion_ddata_derived_from_base_data/,mldatathrowaway,1482474900,"I have a question that maybe someone has some insight into.  Please feel free to chime in if you have any thoughts, I'm always open to listening.

My question pertains to data you can derive from an original data set.  Is it 

A) Necessary

B) Worthwhile/statistically viable

So, for example, if we have a list of price points over time and zip codes for houses:



House| Zip | Price Month 1 | Price Month 2 | Price Month 3 | Price Month 4 | Price Month 5
---|---|----|----|----|----|----
1| 55555| 55k| 56k| 45k| 55k| 50k
2| 55557| 44k| 46k| 47k| 48k| 49k
3| 55555| 68k| 70k| 72k| 74k| 76k

So, if we take the changes in each month and add it to our original data set and retrain, is that worthwhile?  

House| Zip | Price Month 1 | Price Month 2 | Price Month 3 | Price Month 4 | Price Month 5 | Delta 1-2 | Delta 2-3
---|---|----|----|----|----|----|----|-----
1| 55555| 55k| 56k| 45k| 55k| 50k| 1k| -11k|
2| 55557| 44k| 46k| 47k| 48k| 49k| 2k| 1k|
3| 55555| 68k| 70k| 72k| 74k| 76k| 2k| 2k|

And how far can one go if it is?  
Is it of value to include changes in Delta month to month?  What about changes to the changes monthly?  And what about cross linking between rows, where you track the changes in the relative deltas across different datapoints?

So would putting a recursive function that adds derived data be of any use, or better yet does one already exist I can utilize?  I'm looking for anything of note I can research preferably with open papers.
",3,1,False,self,,,,,
775,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,15,5jvs38,cvgl.stanford.edu,Stanford drone dataset,https://www.reddit.com/r/MachineLearning/comments/5jvs38/stanford_drone_dataset/,Horus764698,1482475933,,0,1,False,default,,,,,
776,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,16,5jvwvi,techcrunch.com,We Need To Fully Understand The Brain Before We Can Build A Machine That Replicates It #AaryaTechnovation #AI #MachineLearning,https://www.reddit.com/r/MachineLearning/comments/5jvwvi/we_need_to_fully_understand_the_brain_before_we/,Aaryatech,1482478229,,0,1,False,default,,,,,
777,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,20,5jwo8f,self.MachineLearning,What's important in Graphics Cards for Neural Nets?,https://www.reddit.com/r/MachineLearning/comments/5jwo8f/whats_important_in_graphics_cards_for_neural_nets/,fd1760,1482492596,[removed],0,1,False,default,,,,,
778,MachineLearning,t5_2r3gv,2016-12-23,2016,12,23,21,5jwz0j,tryolabs.com,The major advancements in Deep Learning in 2016 - Tryolabs Blog,https://www.reddit.com/r/MachineLearning/comments/5jwz0j/the_major_advancements_in_deep_learning_in_2016/,matalab,1482497928,,0,1,False,default,,,,,
779,MachineLearning,t5_2r3gv,2016-12-24,2016,12,24,0,5jxjoj,redd.it,The Most Popular Language For Machine Learning Is ...,https://www.reddit.com/r/MachineLearning/comments/5jxjoj/the_most_popular_language_for_machine_learning_is/,jfpuget,1482506151,,0,1,False,default,,,,,
780,MachineLearning,t5_2r3gv,2016-12-24,2016,12,24,0,5jxpin,inference.vc,"[R,D] Deriving the Subpixel CNN Architecture from First Principles - for Superresolution and other Inverse Problems",https://www.reddit.com/r/MachineLearning/comments/5jxpin/rd_deriving_the_subpixel_cnn_architecture_from/,fhuszar,1482508097,,0,1,False,default,,,,,
781,MachineLearning,t5_2r3gv,2016-12-24,2016,12,24,0,5jxqy7,ogma.ai,[Project] Ball Physics Simulation from Pixels using OgmaNeo,https://www.reddit.com/r/MachineLearning/comments/5jxqy7/project_ball_physics_simulation_from_pixels_using/,CireNeikual,1482508563,,9,16,False,http://b.thumbs.redditmedia.com/Yapr-Q-XqBajB-T6l4Ad6wEbexRZgZGO_5nz4oKoL-w.jpg,,,,,
782,MachineLearning,t5_2r3gv,2016-12-24,2016,12,24,3,5jyg0e,medium.com,[D] Deep Learning Race: A Survey of Industry Players Strategies  Intuition Machine,https://www.reddit.com/r/MachineLearning/comments/5jyg0e/d_deep_learning_race_a_survey_of_industry_players/,evc123,1482516304,,11,103,False,http://b.thumbs.redditmedia.com/EDgFBUnPnCIbm7a86a3QKKnMzIOGvBH6W-m5c1QOP5U.jpg,,,,,
783,MachineLearning,t5_2r3gv,2016-12-24,2016,12,24,4,5jyr6z,youtube.com,How To Make UPVC Door Panel - Plastic Door Machinery,https://www.reddit.com/r/MachineLearning/comments/5jyr6z/how_to_make_upvc_door_panel_plastic_door_machinery/,mmlbhabib,1482519782,,1,1,False,default,,,,,
784,MachineLearning,t5_2r3gv,2016-12-24,2016,12,24,4,5jysde,self.MachineLearning,Should I move into Machine Learning for career?,https://www.reddit.com/r/MachineLearning/comments/5jysde/should_i_move_into_machine_learning_for_career/,[deleted],1482520165,[removed],0,1,False,default,,,,,
785,MachineLearning,t5_2r3gv,2016-12-24,2016,12,24,4,5jyw32,ijdykeman.github.io,A visual and Intuitive Explanation of Conditional Variational Autoencoders,https://www.reddit.com/r/MachineLearning/comments/5jyw32/a_visual_and_intuitive_explanation_of_conditional/,[deleted],1482521336,[deleted],0,1,False,default,,,,,
786,MachineLearning,t5_2r3gv,2016-12-24,2016,12,24,4,5jyyco,ijdykeman.github.io,[P] A Visual and Intuitive Explanation of Variational Autoencoders,https://www.reddit.com/r/MachineLearning/comments/5jyyco/p_a_visual_and_intuitive_explanation_of/,ijdykeman,1482522031,,17,88,False,http://b.thumbs.redditmedia.com/2S_kEpRVU1EhEnJy2opRF9-azIG-lsJe53PDZ0eqJOc.jpg,,,,,
787,MachineLearning,t5_2r3gv,2016-12-24,2016,12,24,5,5jz92b,self.MachineLearning,An incredibly useful new tool for Time Series Machine Learning/Data Mining,https://www.reddit.com/r/MachineLearning/comments/5jz92b/an_incredibly_useful_new_tool_for_time_series/,[deleted],1482525475,[removed],0,1,False,default,,,,,
788,MachineLearning,t5_2r3gv,2016-12-24,2016,12,24,5,5jzb0a,self.MachineLearning,[R] An incredibly useful new tool for Time Series Machine Learning/Data Mining,https://www.reddit.com/r/MachineLearning/comments/5jzb0a/r_an_incredibly_useful_new_tool_for_time_series/,dnaoh,1482526120,"Dear Colleagues 

Forgive this intrusion, but I wanted to bring a very useful time series data mining tool to your attention. The UCR Matrix Profile has the potential to revolutionize time series data mining because of its generality, versatility, simplicity and scalability. 

In particular, it has implications for time series motif discovery, time series joins, shapelet discovery (classification), density estimation, semantic segmentation, visualization, clustering etc. 

The advantages of using the Matrix Profile (over hashing, indexing etc.) for most time series data mining tasks include: It is exact, it is simple and parameter-free, it is space efficient, it allows anytime algorithms, it is incrementally maintainable (can handle streams), it can leverage hardware, it has time complexity that is constant in subsequence length (no curse of dimensionality!), it can be constructed in deterministic time/space, it can handle missing data and still return exact results. 

Interested? Please visit http://www.cs.ucr.edu/~eamonn/MatrixProfile.html 

Best wishes, Michael and the Matrix Profile Team",30,46,False,self,,,,,
789,MachineLearning,t5_2r3gv,2016-12-24,2016,12,24,6,5jzhfh,amazon.com,"""Deep Learning"" for just $10,121.00, Merry Christmas!",https://www.reddit.com/r/MachineLearning/comments/5jzhfh/deep_learning_for_just_1012100_merry_christmas/,wongct,1482528304,,0,1,False,default,,,,,
790,MachineLearning,t5_2r3gv,2016-12-24,2016,12,24,9,5k0e3u,ibm.com,The Most Popular Language For Machine Learning Is Python,https://www.reddit.com/r/MachineLearning/comments/5k0e3u/the_most_popular_language_for_machine_learning_is/,speckz,1482539545,,0,1,False,default,,,,,
791,MachineLearning,t5_2r3gv,2016-12-24,2016,12,24,10,5k0r5g,onlinemathtraining.com,The wonderful and terrifying implications of computers that can learn.,https://www.reddit.com/r/MachineLearning/comments/5k0r5g/the_wonderful_and_terrifying_implications_of/,rickmister24,1482544637,,0,1,False,default,,,,,
792,MachineLearning,t5_2r3gv,2016-12-24,2016,12,24,11,5k0u4d,youtu.be,Visualize a Dataset using T-SNE,https://www.reddit.com/r/MachineLearning/comments/5k0u4d/visualize_a_dataset_using_tsne/,llSourcell,1482545819,,0,2,False,default,,,,,
793,MachineLearning,t5_2r3gv,2016-12-24,2016,12,24,12,5k11c2,thehypertext.com,Novel Camera by Ross Goodwin - a camera which prints out image descriptions instead of images.,https://www.reddit.com/r/MachineLearning/comments/5k11c2/novel_camera_by_ross_goodwin_a_camera_which/,hockiklocki,1482548811,,0,1,False,default,,,,,
794,MachineLearning,t5_2r3gv,2016-12-24,2016,12,24,13,5k1czm,dataaspirant.com,"Knn Classifier, Introduction to K-Nearest Neighbor Algorithm",https://www.reddit.com/r/MachineLearning/comments/5k1czm/knn_classifier_introduction_to_knearest_neighbor/,dataaspirant,1482553703,,0,1,False,default,,,,,
795,MachineLearning,t5_2r3gv,2016-12-24,2016,12,24,17,5k276c,self.MachineLearning,[D] Which IDEs / editors / tools do you use?,https://www.reddit.com/r/MachineLearning/comments/5k276c/d_which_ides_editors_tools_do_you_use/,jacobgil,1482568580,"There are so many different machine learning frameworks in different languages, it seems difficult for me to have a good setup that works with everything.

I'm often finding myself using ""printf debugging"" instead of setting up a graphical debugger, and using grep to search a code base. I'm wondering if there is something more productive.

For example for debugging C++ and Python frameworks like Caffe or Tensorflow, do you use gdb? do you use a frontend that is more graphic?

Please share the setup you use.",37,5,False,self,,,,,
796,MachineLearning,t5_2r3gv,2016-12-24,2016,12,24,20,5k2pkl,sg.news.yahoo.com,9 applications that will greatly benefit from machine learning in 2017,https://www.reddit.com/r/MachineLearning/comments/5k2pkl/9_applications_that_will_greatly_benefit_from/,CentricAE,1482579831,,0,1,False,default,,,,,
797,MachineLearning,t5_2r3gv,2016-12-24,2016,12,24,22,5k2z7l,bafflednerd.com,A good list of ML courses available online,https://www.reddit.com/r/MachineLearning/comments/5k2z7l/a_good_list_of_ml_courses_available_online/,[deleted],1482585088,[deleted],0,1,False,default,,,,,
798,MachineLearning,t5_2r3gv,2016-12-24,2016,12,24,22,5k31xt,self.MachineLearning,"Interesting Data Store, Question about its Utility for ML",https://www.reddit.com/r/MachineLearning/comments/5k31xt/interesting_data_store_question_about_its_utility/,GraphicH,1482586518,[removed],0,1,False,default,,,,,
799,MachineLearning,t5_2r3gv,2016-12-24,2016,12,24,22,5k32dl,github.com,[P] A framework to build object detectors easily in Python,https://www.reddit.com/r/MachineLearning/comments/5k32dl/p_a_framework_to_build_object_detectors_easily_in/,nekrasov777,1482586734,,4,15,False,http://a.thumbs.redditmedia.com/tbIoNuhupeSUilH55hUzIdPPXE5-uj94v18xKUt50K0.jpg,,,,,
800,MachineLearning,t5_2r3gv,2016-12-24,2016,12,24,23,5k355f,github.com,[P] Neural Painter: Paint artistic patterns using random neural network,https://www.reddit.com/r/MachineLearning/comments/5k355f/p_neural_painter_paint_artistic_patterns_using/,zxytim,1482588087,,16,84,False,http://b.thumbs.redditmedia.com/_O5vzkv9jnoC8cjKPPjBL0_cbOuIxeuoO_ANb3RtzNc.jpg,,,,,
801,MachineLearning,t5_2r3gv,2016-12-25,2016,12,25,2,5k4149,self.MachineLearning,Short-ish Deep Learning Tutorial? [Please read comments],https://www.reddit.com/r/MachineLearning/comments/5k4149/shortish_deep_learning_tutorial_please_read/,YourWelcomeOrMine,1482600425,[removed],0,1,False,default,,,,,
802,MachineLearning,t5_2r3gv,2016-12-25,2016,12,25,3,5k48kb,self.MachineLearning,Deep learning (neural nets) on smaller data sets,https://www.reddit.com/r/MachineLearning/comments/5k48kb/deep_learning_neural_nets_on_smaller_data_sets/,Smallpaul,1482602982,[removed],0,1,False,default,,,,,
803,MachineLearning,t5_2r3gv,2016-12-25,2016,12,25,3,5k4g74,self.MachineLearning,NN recognizing MNIST digits but not mine. Help please,https://www.reddit.com/r/MachineLearning/comments/5k4g74/nn_recognizing_mnist_digits_but_not_mine_help/,Weriak,1482605597,[removed],0,1,False,default,,,,,
804,MachineLearning,t5_2r3gv,2016-12-25,2016,12,25,11,5k6cay,self.MachineLearning,[P] Latent Dirichlet Allocation on UFO data,https://www.reddit.com/r/MachineLearning/comments/5k6cay/p_latent_dirichlet_allocation_on_ufo_data/,wolfy44,1482631838,"I recently spent some time getting down into the nuts and bolts of LDA for topic models. I ended up letting it loose on this ridiculous UFO data set. 

Check out the results and the details here:
https://medium.com/@samsachedina/effective-data-science-latent-dirichlet-allocation-a109742f7d1c

Any comments or suggestions are highly appreciated!
",15,48,False,self,,,,,
805,MachineLearning,t5_2r3gv,2016-12-25,2016,12,25,11,5k6f2z,self.MachineLearning,[D] Networks trained on 32x32 resized ilsvrc12 dataset,https://www.reddit.com/r/MachineLearning/comments/5k6f2z/d_networks_trained_on_32x32_resized_ilsvrc12/,anonDogeLover,1482633090,Are there any (pretrained) cifar-sized (32x32) networks trained on imagenet that anyone knows of? ,0,4,False,self,,,,,
806,MachineLearning,t5_2r3gv,2016-12-25,2016,12,25,11,5k6g43,github.com,tensorflow-qnd: Quick and Distributed TensorFlow command framework to experiment with models on multiple computers,https://www.reddit.com/r/MachineLearning/comments/5k6g43/tensorflowqnd_quick_and_distributed_tensorflow/,[deleted],1482633561,[deleted],0,1,False,default,,,,,
807,MachineLearning,t5_2r3gv,2016-12-25,2016,12,25,12,5k6k1r,github.com,[P] tensorflow-qnd: Quick and Distributed TensorFlow command framework to experiment with models on multiple computers,https://www.reddit.com/r/MachineLearning/comments/5k6k1r/p_tensorflowqnd_quick_and_distributed_tensorflow/,raviqqe,1482635381,,1,16,False,http://a.thumbs.redditmedia.com/w4VNAaTD88om6zGrJ0NWUBdGFnNAFf7Nze8g1sBFzP4.jpg,,,,,
808,MachineLearning,t5_2r3gv,2016-12-25,2016,12,25,12,5k6lrs,self.MachineLearning,Is there a state of the art MNist model that's simpler than LeNet?,https://www.reddit.com/r/MachineLearning/comments/5k6lrs/is_there_a_state_of_the_art_mnist_model_thats/,cinjon,1482636165,[removed],0,1,False,default,,,,,
809,MachineLearning,t5_2r3gv,2016-12-25,2016,12,25,20,5k82a4,adityathebe.com,NeuroEvolution : Flappy Bird | Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5k82a4/neuroevolution_flappy_bird_machine_learning/,setopati,1482666376,,0,1,False,default,,,,,
810,MachineLearning,t5_2r3gv,2016-12-25,2016,12,25,23,5k8ffj,self.MachineLearning,How do Factorization Machines predict click through rate?,https://www.reddit.com/r/MachineLearning/comments/5k8ffj/how_do_factorization_machines_predict_click/,alcaidhuang,1482674521,[removed],0,1,False,default,,,,,
811,MachineLearning,t5_2r3gv,2016-12-25,2016,12,25,23,5k8fp0,itunes.apple.com,"Artificial Intelligence, Snowloop Search Engine for your Camera Roll Photos",https://www.reddit.com/r/MachineLearning/comments/5k8fp0/artificial_intelligence_snowloop_search_engine/,thisismohit,1482674656,,0,1,False,default,,,,,
812,MachineLearning,t5_2r3gv,2016-12-25,2016,12,25,23,5k8h07,self.MachineLearning,[P] Insights into variational autoencoders for unsupervised clustering,https://www.reddit.com/r/MachineLearning/comments/5k8h07/p_insights_into_variational_autoencoders_for/,rui_,1482675339,"I recently came across this paper (https://arxiv.org/abs/1611.02648) and decided to do some additional experiments to shed more light on the use of VAE for clustering.

The code for my experiment can be found here: https://github.com/RuiShu/vae-clustering
And the accompanying blog post is available at: http://ruishu.io/2016/12/25/gmvae

I hope someone out there will find this project helpful :P Comments/suggestions are also much appreciated!",6,65,False,self,,,,,
813,MachineLearning,t5_2r3gv,2016-12-25,2016,12,25,23,5k8k73,atarigrandchallenge.com,Collecting dataset of humans playing Atari 2600 for Reinforcement Learning research,https://www.reddit.com/r/MachineLearning/comments/5k8k73/collecting_dataset_of_humans_playing_atari_2600/,y0b1byte,1482676866,,0,3,False,default,,,,,
814,MachineLearning,t5_2r3gv,2016-12-26,2016,12,26,2,5k98xi,self.MachineLearning,[D] Dimensionality of random vector for EBGANs,https://www.reddit.com/r/MachineLearning/comments/5k98xi/d_dimensionality_of_random_vector_for_ebgans/,debau,1482687727,"https://arxiv.org/pdf/1609.03126v3.pdf

A vector z is sampled which is fed into a generator G that tries to fool a discriminator D into believing G(z) is an actual data sample.

For the MNIST dataset, the data distribution will be highly multi-modal (probably 10 modes for each number). Any mapping from a single dimensional z taken from N(0,1) will not be able to cover much of such a highly multi-modal data distribution. Then if the dimensionality of z is too big, training the generator becomes impossible becomes we need to sample so many different z's to cover most of the input space.

Picking the right dimensionality of z seems to be quite important.

Am I too stupid and overread it in the paper or does the paper not discuss this at all? Does anyone know if there's a good heuristic for picking the dimensionality of z?",3,5,False,self,,,,,
815,MachineLearning,t5_2r3gv,2016-12-26,2016,12,26,3,5k9elo,self.MachineLearning,[D] - Are there any studies about mixing Deep Learning and normal feature learning?,https://www.reddit.com/r/MachineLearning/comments/5k9elo/d_are_there_any_studies_about_mixing_deep/,abello966,1482689891,"I wanted to know how this may affect both classifying performance and time performance. In a case of limited processing resources for example, can we use it to reduce the convnet complexity whilst maintaining overall performance?

Also I was tempted to name it ""parametric and nonparametric learning"" but I thought it wouldn't be accurate, would it? Is the way I named it a good one or is there a better way?

This winning Kaggle team used it on classifying plankton and it worked pretty well:
http://benanne.github.io/2015/03/17/plankton.html

Papers welcome :)",11,18,False,self,,,,,
816,MachineLearning,t5_2r3gv,2016-12-26,2016,12,26,6,5ka8v6,matheusgadelha.github.io,[R] 3D Shape Induction from 2D Views of Multiple Objects,https://www.reddit.com/r/MachineLearning/comments/5ka8v6/r_3d_shape_induction_from_2d_views_of_multiple/,mgadelha,1482701367,,9,17,False,default,,,,,
817,MachineLearning,t5_2r3gv,2016-12-26,2016,12,26,7,5kahbv,smithsonianmag.com,"Researchers use machine learning to ""translate"" the language of fruit bat vocalizations",https://www.reddit.com/r/MachineLearning/comments/5kahbv/researchers_use_machine_learning_to_translate_the/,pappypapaya,1482704670,,1,1,False,default,,,,,
818,MachineLearning,t5_2r3gv,2016-12-26,2016,12,26,10,5kbagl,self.MachineLearning,When should we stop training GAN? How to apply early stopping?,https://www.reddit.com/r/MachineLearning/comments/5kbagl/when_should_we_stop_training_gan_how_to_apply/,gmkim90,1482715980,[removed],0,1,False,default,,,,,
819,MachineLearning,t5_2r3gv,2016-12-26,2016,12,26,10,5kbboo,self.MachineLearning,What are some techniques for using ML to improve classical models when minimal training data is available?,https://www.reddit.com/r/MachineLearning/comments/5kbboo/what_are_some_techniques_for_using_ml_to_improve/,[deleted],1482716466,[removed],0,1,False,default,,,,,
820,MachineLearning,t5_2r3gv,2016-12-26,2016,12,26,12,5kbrdj,arxiv.org,An official Apple Inc. research paper - Learning from Simulated and Unsupervised Images through Adversarial Training,https://www.reddit.com/r/MachineLearning/comments/5kbrdj/an_official_apple_inc_research_paper_learning/,youcancallmejoey,1482722822,,0,1,False,default,,,,,
821,MachineLearning,t5_2r3gv,2016-12-26,2016,12,26,12,5kbsjb,arxiv.org,"[R] [1612.08083] ""Language Modeling with Gated Convolutional Networks"" &lt;- sota single gpu performance",https://www.reddit.com/r/MachineLearning/comments/5kbsjb/r_161208083_language_modeling_with_gated/,evc123,1482723314,,25,46,False,default,,,,,
822,MachineLearning,t5_2r3gv,2016-12-26,2016,12,26,13,5kbyg1,arxiv.org,[R] Apple's FIRST paper: Learning from Simulated and Unsupervised Images through Adversarial Training,https://www.reddit.com/r/MachineLearning/comments/5kbyg1/r_apples_first_paper_learning_from_simulated_and/,downtownslim,1482725742,,32,209,False,default,,,,,
823,MachineLearning,t5_2r3gv,2016-12-26,2016,12,26,14,5kcco8,self.MachineLearning,[D] KL Divergence,https://www.reddit.com/r/MachineLearning/comments/5kcco8/d_kl_divergence/,wolfy44,1482731816,"I wrote a short piece, partly to remind myself, partly as an introduction to KL divergence for bayesian models. Thought it would add value here in case anyone is working on similar tracks

https://medium.com/@samsachedina/demystified-kullback-leibler-divergence-3971f956ef34

Feedback is always appreciated. Thanks for reading!",13,7,False,self,,,,,
824,MachineLearning,t5_2r3gv,2016-12-26,2016,12,26,16,5kco88,medium.com,A simple Machine Learning project to perform static-gesture recognition using sklearn,https://www.reddit.com/r/MachineLearning/comments/5kco88/a_simple_machine_learning_project_to_perform/,[deleted],1482737154,[deleted],0,1,False,default,,,,,
825,MachineLearning,t5_2r3gv,2016-12-26,2016,12,26,16,5kcpqt,self.MachineLearning,"[P] A simple, beginner-level machine learning project to perform static-gesture recognition using sklearn",https://www.reddit.com/r/MachineLearning/comments/5kcpqt/p_a_simple_beginnerlevel_machine_learning_project/,theonlybox,1482737974,"I recently wrote a blog post explaining an ML project that I completed as part of a course I took up in college. Sharing it here hoping that people who are new to machine learning and looking for simple-enough projects will find it interesting and useful. 

Link to the blog post: http://www.ssreehari.com/Sign-language-and-static-gesture-recgnition/ 

Link to the code on github: https://github.com/mon95/Sign-Language-and-Static-gesture-recognition-using-sklearn

Comments/suggestions for any future posts are much appreciated!
(edit: changed the blog link to point to my recently set up blog)",2,17,False,self,,,,,
826,MachineLearning,t5_2r3gv,2016-12-26,2016,12,26,17,5kcwan,muratbuffalo.blogspot.rs,Learning Machine Learning: A beginner's journey,https://www.reddit.com/r/MachineLearning/comments/5kcwan/learning_machine_learning_a_beginners_journey/,-elektro-pionir-,1482741770,,0,1,False,default,,,,,
827,MachineLearning,t5_2r3gv,2016-12-26,2016,12,26,19,5kd6vd,self.MachineLearning,[D] Machine Learning - WAYR (What Are You Reading) - Week 16,https://www.reddit.com/r/MachineLearning/comments/5kd6vd/d_machine_learning_wayr_what_are_you_reading_week/,Mandrathax,1482748090,"This is a place to share machine learning research papers, journals, and articles that you're reading this week.
If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.  

|Previous weeks|
|--------------|
|[Week 1](https://www.reddit.com/r/MachineLearning/comments/4qyjiq/machine_learning_wayr_what_are_you_reading_week_1/)|  
|[Week 2](https://www.reddit.com/r/MachineLearning/comments/4s2xqm/machine_learning_wayr_what_are_you_reading_week_2/)|  
|[Week 3](https://www.reddit.com/r/MachineLearning/comments/4t7mqm/machine_learning_wayr_what_are_you_reading_week_3/)|  
|[Week 4](https://www.reddit.com/r/MachineLearning/comments/4ub2kw/machine_learning_wayr_what_are_you_reading_week_4/)| 
|[Week 5](https://www.reddit.com/r/MachineLearning/comments/4xomf7/machine_learning_wayr_what_are_you_reading_week_5/)| 
|[Week 6](https://www.reddit.com/r/MachineLearning/comments/4zcyvk/machine_learning_wayr_what_are_you_reading_week_6/)|
|[Week 7](https://www.reddit.com/r/MachineLearning/comments/52t6mo/machine_learning_wayr_what_are_you_reading_week_7/)|
|[Week 8](https://www.reddit.com/r/MachineLearning/comments/53heol/machine_learning_wayr_what_are_you_reading_week_8/)|
|[Week 9](https://www.reddit.com/r/MachineLearning/comments/54kvsu/machine_learning_wayr_what_are_you_reading_week_9/)|
|[Week 10](https://www.reddit.com/r/MachineLearning/comments/56s2oa/discussion_machine_learning_wayr_what_are_you/)|
|[Week 11](https://www.reddit.com/r/MachineLearning/comments/57xw56/discussion_machine_learning_wayr_what_are_you/)|
|[Week 12](https://www.reddit.com/r/MachineLearning/comments/5acb1t/d_machine_learning_wayr_what_are_you_reading_week/)|
|[Week 13](https://www.reddit.com/r/MachineLearning/comments/5cwfb6/d_machine_learning_wayr_what_are_you_reading_week/)|
|[Week 14](https://www.reddit.com/r/MachineLearning/comments/5fc5mh/d_machine_learning_wayr_what_are_you_reading_week/)|
|[Week 15](https://www.reddit.com/r/MachineLearning/comments/5hy4ur/d_machine_learning_wayr_what_are_you_reading_week/)|

Most upvoted papers last week : 

[Learning to learn by gradient descent by gradient descent](https://arxiv.org/abs/1606.04474)

[Natural Language Understanding with Distributed Representation](https://github.com/nyu-dl/NLP_DL_Lecture_Note)

[Geometric deep learning: going beyond Euclidean data](https://arxiv.org/abs/1611.08097)

Besides that, there are no rules, have fun and Merry Christmas to everyone!",5,22,False,self,,,,,
828,MachineLearning,t5_2r3gv,2016-12-26,2016,12,26,20,5kddh8,self.MachineLearning,[P] Python logger that syncs logs to cloud and sends messenger notifications,https://www.reddit.com/r/MachineLearning/comments/5kddh8/p_python_logger_that_syncs_logs_to_cloud_and/,navoshta,1482751973,"I use a remote machine for long-running tasks, so I felt need for a lightweight Python logger that would save my console logs to a local file. It would also be handy to access those logs on the go (say, from my phone) and be notified when another task is finished. So I quickly built [a simple logger](http://navoshta.com/cloud-log/) that syncs logs to a **Dropbox** folder and notifies you in a **Telegram** chat  and it works with `pyplot` plots too!

Thought it could be useful for some folks here: https://github.com/navoshta/cloudlog",5,23,False,self,,,,,
829,MachineLearning,t5_2r3gv,2016-12-26,2016,12,26,21,5kdgru,self.MachineLearning,"[D] What are some current problems in ML which are ""interestingly intractable""?",https://www.reddit.com/r/MachineLearning/comments/5kdgru/d_what_are_some_current_problems_in_ml_which_are/,epicwisdom,1482753947,"Where ""interestingly intractable"" means:

- There exists a large, high quality, publicly available dataset against which performance can be reliably measured. (Labeled, if the problem is supervised) Therefore, **the problem is narrowly well-defined, and lack of progress is not just due to lack of data.** So ""AGI"" and ""unsupervised learning"" are not valid.

- The problem is significant in and of itself, or in other words, **it is not a ""toy problem.""** For example, playing Go, as opposed to playing Atari games.

- Either there has been a lack of significant progress, or despite progress, we are still far from attaining the goal (by our own best estimates). So, much like computer Go before AlphaGo proved itself, **it is currently believed that the problem will not be solved in the next 1-3 years.**

And imaginary bonus points if:

- It's impossible, or at least extremely costly/risky/difficult, to accomplish with humans or traditional, non-ML algorithms.

- It's been an area of active research for longer than a decade.

Publications are generally looking at incremental improvements on ""toy"" datasets, so I've found it hard to discern any meaningful larger-scale trends on the ""Next Big Problem[s]"" in ML.

Inspired by [What can we *not* do with ML these days?](https://www.reddit.com/r/MachineLearning/comments/48remo/)",61,21,False,self,,,,,
830,MachineLearning,t5_2r3gv,2016-12-26,2016,12,26,23,5kdyln,yaroslavvb.com,Where can I get or how can I build a complete notMNIST dataset? This one only has from A to J: http://yaroslavvb.blogspot.com.co/2011/09/notmnist-dataset.html,https://www.reddit.com/r/MachineLearning/comments/5kdyln/where_can_i_get_or_how_can_i_build_a_complete/,Evilpipe,1482762850,,1,1,False,default,,,,,
831,MachineLearning,t5_2r3gv,2016-12-27,2016,12,27,0,5ke2bm,lunduniversity.lu.se,WATCH: New method detects more breast cancer in screening | Lund University,https://www.reddit.com/r/MachineLearning/comments/5ke2bm/watch_new_method_detects_more_breast_cancer_in/,smorrel1,1482764557,,0,1,False,default,,,,,
832,MachineLearning,t5_2r3gv,2016-12-27,2016,12,27,1,5keirx,self.MachineLearning,Labs working on Machine Learning and Health Care,https://www.reddit.com/r/MachineLearning/comments/5keirx/labs_working_on_machine_learning_and_health_care/,Root5566,1482770949,[removed],0,1,False,default,,,,,
833,MachineLearning,t5_2r3gv,2016-12-27,2016,12,27,3,5kf20t,learnopencv.com,Minified OpenCV Haar and LBP Cascades,https://www.reddit.com/r/MachineLearning/comments/5kf20t/minified_opencv_haar_and_lbp_cascades/,spmallick,1482777455,,0,1,False,default,,,,,
834,MachineLearning,t5_2r3gv,2016-12-27,2016,12,27,3,5kf4hs,self.MachineLearning,train algorithm to extract party names from an agreement text file,https://www.reddit.com/r/MachineLearning/comments/5kf4hs/train_algorithm_to_extract_party_names_from_an/,carldgosselin,1482778310,[removed],0,1,False,default,,,,,
835,MachineLearning,t5_2r3gv,2016-12-27,2016,12,27,4,5kfcnn,queirozf.com,Installing CUDA TK 8 and Tensorflow on a Clean Ubuntu 16.04 Install,https://www.reddit.com/r/MachineLearning/comments/5kfcnn/installing_cuda_tk_8_and_tensorflow_on_a_clean/,orange_robot338,1482781066,,0,1,False,default,,,,,
836,MachineLearning,t5_2r3gv,2016-12-27,2016,12,27,6,5kfs23,papers.ai,[R] Understanding deep learning requires rethinking generalization,https://www.reddit.com/r/MachineLearning/comments/5kfs23/r_understanding_deep_learning_requires_rethinking/,hiteck,1482786319,,8,113,False,http://b.thumbs.redditmedia.com/piGk-Xx8ysrZmlm4Fm_Tum9VNY2N2JN4K3OSBxkzsAo.jpg,,,,,
837,MachineLearning,t5_2r3gv,2016-12-27,2016,12,27,6,5kfsd3,self.MachineLearning,Can someone help me understand how feature mapping is working in this example from ANdew NG's course?,https://www.reddit.com/r/MachineLearning/comments/5kfsd3/can_someone_help_me_understand_how_feature/,[deleted],1482786434,[removed],0,1,False,default,,,,,
838,MachineLearning,t5_2r3gv,2016-12-27,2016,12,27,8,5kgczl,jakob-aungiers.com,LSTM Neural Network for Time Series Prediction,https://www.reddit.com/r/MachineLearning/comments/5kgczl/lstm_neural_network_for_time_series_prediction/,Dogsindahouse1,1482793725,,0,1,False,default,,,,,
839,MachineLearning,t5_2r3gv,2016-12-27,2016,12,27,8,5kgd1h,forbes.com,McKinsey's 2016 Analytics Study Defines The Future Of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5kgd1h/mckinseys_2016_analytics_study_defines_the_future/,cavedave,1482793747,,3,11,False,http://a.thumbs.redditmedia.com/-h1IBahOd39VUY-sa6dLtRR53bGhM1kaNL1TiVZq-l8.jpg,,,,,
840,MachineLearning,t5_2r3gv,2016-12-27,2016,12,27,9,5kguce,self.MachineLearning,Multiple gtx 1070 vs single titan x for deep learning,https://www.reddit.com/r/MachineLearning/comments/5kguce/multiple_gtx_1070_vs_single_titan_x_for_deep/,harvey_slash,1482799958,[removed],0,1,False,default,,,,,
841,MachineLearning,t5_2r3gv,2016-12-27,2016,12,27,10,5kh1fo,github.com,[P] TensorFlow implementation of Value Iteration Networks (winner of Best Paper Award at NIPS 2016),https://www.reddit.com/r/MachineLearning/comments/5kh1fo/p_tensorflow_implementation_of_value_iteration/,abhishkk65,1482802566,,0,58,False,http://a.thumbs.redditmedia.com/Ze_Ft5Lkw6ugsnaHR2qjL67TzVJX-408Gqu3Ja4xZ80.jpg,,,,,
842,MachineLearning,t5_2r3gv,2016-12-27,2016,12,27,12,5khnug,self.MachineLearning,[R] A cross-benchmark comparison of 87 learning to rank algorithms,https://www.reddit.com/r/MachineLearning/comments/5khnug/r_a_crossbenchmark_comparison_of_87_learning_to/,TaXxER,1482810832,"In this paper we compare 87 machine learning algorithms on the task of ranking. A frequent application domain of ranking with machine learning is web search and/or information retrieval where a collection of candidate documents is ranked based on a user query. This paper just won the award for best paper of the year 2015 that appeared in the Elsevier journal Information Processing &amp; Management. 

Link to article:
http://wwwhome.cs.utwente.nl/~hiemstra/papers/ipm2015.pdf",0,10,False,self,,,,,
843,MachineLearning,t5_2r3gv,2016-12-27,2016,12,27,13,5khvbn,deeplearningathome.com,Simplest AutoEncoder in Tensorflow.,https://www.reddit.com/r/MachineLearning/comments/5khvbn/simplest_autoencoder_in_tensorflow/,gizcard,1482813720,,0,1,False,default,,,,,
844,MachineLearning,t5_2r3gv,2016-12-27,2016,12,27,14,5ki3l1,hn.premii.com,Symbolic Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5ki3l1/symbolic_machine_learning/,[deleted],1482816970,[deleted],0,1,False,default,,,,,
845,MachineLearning,t5_2r3gv,2016-12-27,2016,12,27,14,5ki3sl,languagengine.co,[R] Symbolic Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5ki3sl/r_symbolic_machine_learning/,[deleted],1482817044,[deleted],1,1,False,default,,,,,
846,MachineLearning,t5_2r3gv,2016-12-27,2016,12,27,16,5kiirf,self.MachineLearning,Minimum IOU required for bounding box regression to work well ?,https://www.reddit.com/r/MachineLearning/comments/5kiirf/minimum_iou_required_for_bounding_box_regression/,I_am_a_robot_,1482823416,[removed],0,1,False,default,,,,,
847,MachineLearning,t5_2r3gv,2016-12-27,2016,12,27,18,5kiwas,mixmachinery.com,Useful tips for powder blender volume calculation,https://www.reddit.com/r/MachineLearning/comments/5kiwas/useful_tips_for_powder_blender_volume_calculation/,mixmachinery,1482830411,,1,1,False,default,,,,,
848,MachineLearning,t5_2r3gv,2016-12-27,2016,12,27,19,5kj566,self.MachineLearning,[D] How to train generative adversarial networks,https://www.reddit.com/r/MachineLearning/comments/5kj566/d_how_to_train_generative_adversarial_networks/,rumblestiltsken,1482835048,"We have had a few posts here before, and the [notes of the talk at NIPS](https://github.com/soumith/ganhacks) are useful, and there are some other great ""how to"" [resources](https://github.com/shekkizh/neuralnetworks.thought-experiments/blob/master/Generative%20Models/GAN/Readme.md). There is also the [Torch blogpost on the topic](http://torch.ch/blog/2015/11/13/gan.html).

I have generated images that look good. I have toyed with tons of GAN variants.

But I still feel like I have no idea how to train a GAN in any sort of rigorous manner. To me it seems like the most important factor in generating visually understandable images is some strange and exploratory architecture balancing act, which appears completely arbitrary. I train one GAN to equilibrium and end up with trash images, but change a tiny thing in the architecture and reach a very similar equilibrium (ie the G and D training curves look the same) but have nice images.

This suggests to me that what we are actually doing is (over)fitting models based on human visual interpretation, not model metrics. This is very ""human in the loop"" and not theoretically satisfying. And more frustratingly, it is not discussed even in the few articles and blogposts on GAN hacks and methods. I wasn't at NIPS so I don't know if the workshop covered more than the git.

Mode collapse and ""stability"" don't seem to explain my experiences. It kind of feels more like model hacking. I know my colleagues feel similar frustrations, like we are all just randomly wandering around image space until we stumble upon a training method that lands us close to the image manifold and then it magically starts working. 

I really want to be told I am just missing something that should be obvious. 

So, is there any rigorous way to train a GAN? Where I can look at my curves and my gradients and my activations and just *know* I will end up with quality images? 

",14,70,False,self,,,,,
849,MachineLearning,t5_2r3gv,2016-12-27,2016,12,27,19,5kj6g5,mmbusinessblog.wordpress.com,How Do Combines Harvest Corn?,https://www.reddit.com/r/MachineLearning/comments/5kj6g5/how_do_combines_harvest_corn/,BaganMart,1482835707,,0,1,False,default,,,,,
850,MachineLearning,t5_2r3gv,2016-12-27,2016,12,27,22,5kjrad,arxiv.org,[R] [1612.07771] Highway and Residual Networks learn Unrolled Iterative Estimation,https://www.reddit.com/r/MachineLearning/comments/5kjrad/r_161207771_highway_and_residual_networks_learn/,SuperFX,1482845891,,11,15,False,default,,,,,
851,MachineLearning,t5_2r3gv,2016-12-27,2016,12,27,22,5kjsch,arxiv.org,[R] [1611.05104] A Way out of the Odyssey: Analyzing and Combining Recent Insights for LSTMs,https://www.reddit.com/r/MachineLearning/comments/5kjsch/r_161105104_a_way_out_of_the_odyssey_analyzing/,SuperFX,1482846388,,2,5,False,default,,,,,
852,MachineLearning,t5_2r3gv,2016-12-28,2016,12,28,1,5kkejc,arxiv.org,LightRNN: Memory and Computation-Efficient Recurrent Neural Networks,https://www.reddit.com/r/MachineLearning/comments/5kkejc/lightrnn_memory_and_computationefficient/,YohOkuno,1482854700,,0,1,False,default,,,,,
853,MachineLearning,t5_2r3gv,2016-12-28,2016,12,28,1,5kkfml,homestars.com,Public Plumbing HomeStars,https://www.reddit.com/r/MachineLearning/comments/5kkfml/public_plumbing_homestars/,JaneDavisonjo3,1482855052,,0,1,False,default,,,,,
854,MachineLearning,t5_2r3gv,2016-12-28,2016,12,28,1,5kkgts,self.MachineLearning,"[D] Academics, what do you use for ML? MATLAB/Python or something else?",https://www.reddit.com/r/MachineLearning/comments/5kkgts/d_academics_what_do_you_use_for_ml_matlabpython/,buy_some_wow,1482855438,"What language would you recommend for a student who's about to start his/her research in ML(and hoping to stay in research)?

I'm aware of [these type of questions](https://www.quora.com/What-are-the-comparative-pros-and-cons-of-using-Python-MATLAB-Octave-and-R-for-data-analysis-and-machine-learning) but I would like to see this community's views on this regard.

*Mods:* I hope the data points in this thread's comments would give some idea about the tools that academia is using, which I think would be beneficial for someone that's getting in to research. Apologies in advance if you think this post lacks technicality. Please remove if you think so.

Edit: I wanted to ask this on this thread after seeing [this](https://www.reddit.com/r/MachineLearning/comments/5jzb0a/r_an_incredibly_useful_new_tool_for_time_series/dbld71s/)

Edit2: Thanks for the replies. It would also be beneficial if you mention what is your research work on.",23,4,False,self,,,,,
855,MachineLearning,t5_2r3gv,2016-12-28,2016,12,28,1,5kki7r,cs.mcgill.ca,[P] FastText for Windows,https://www.reddit.com/r/MachineLearning/comments/5kki7r/p_fasttext_for_windows/,xiamx,1482855879,,0,1,False,default,,,,,
856,MachineLearning,t5_2r3gv,2016-12-28,2016,12,28,1,5kkl6z,yerevann.com,A Guide to Deep Learning by YerevaNN,https://www.reddit.com/r/MachineLearning/comments/5kkl6z/a_guide_to_deep_learning_by_yerevann/,[deleted],1482856829,[deleted],0,1,False,default,,,,,
857,MachineLearning,t5_2r3gv,2016-12-28,2016,12,28,2,5kkx6n,self.MachineLearning,How could I bind IT Security and Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/5kkx6n/how_could_i_bind_it_security_and_machine_learning/,ShinDragon44,1482860413,[removed],0,1,False,default,,,,,
858,MachineLearning,t5_2r3gv,2016-12-28,2016,12,28,5,5kltmt,tensorflow.org,XLA: The TensorFlow compiler framework document release,https://www.reddit.com/r/MachineLearning/comments/5kltmt/xla_the_tensorflow_compiler_framework_document/,olBaa,1482869821,,0,1,False,default,,,,,
859,MachineLearning,t5_2r3gv,2016-12-28,2016,12,28,5,5klv6i,self.MachineLearning,Genetic Algorithm substitute in case of dependent values?,https://www.reddit.com/r/MachineLearning/comments/5klv6i/genetic_algorithm_substitute_in_case_of_dependent/,shakedzy,1482870282,[removed],0,1,False,default,,,,,
860,MachineLearning,t5_2r3gv,2016-12-28,2016,12,28,5,5klxil,self.MachineLearning,Follow AI on Snapchat (daily funny/interesting/inspiring submissions),https://www.reddit.com/r/MachineLearning/comments/5klxil/follow_ai_on_snapchat_daily/,[deleted],1482870969,[removed],0,1,False,default,,,,,
861,MachineLearning,t5_2r3gv,2016-12-28,2016,12,28,5,5klywi,self.MachineLearning,[D] Which aspects of probability and linear algebra are most important to know for a machine learning class?,https://www.reddit.com/r/MachineLearning/comments/5klywi/d_which_aspects_of_probability_and_linear_algebra/,kekemac,1482871363,"I'm taking an introductory machine learning class next semester, and it will be pretty mathy, with probability and linear algebra as prerequisites. I've taken both, but years ago, and need to brush up, but wanted to focus on the right things.

What aspects of probability and linear algebra are most used in an introductory machine learning class? I can assume the content is like [Ng's CS229](http://cs229.stanford.edu/schedule.html), like most general machine learning classes.",12,34,False,self,,,,,
862,MachineLearning,t5_2r3gv,2016-12-28,2016,12,28,5,5klzm0,self.MachineLearning,Follow AI on Snapchat (daily funny/interesting/inspiring submissions),https://www.reddit.com/r/MachineLearning/comments/5klzm0/follow_ai_on_snapchat_daily/,[deleted],1482871579,[removed],0,1,False,default,,,,,
863,MachineLearning,t5_2r3gv,2016-12-28,2016,12,28,5,5km1nx,self.MachineLearning,[N] Follow AI on Snapchat (daily funny/interesting/inspiring submissions),https://www.reddit.com/r/MachineLearning/comments/5km1nx/n_follow_ai_on_snapchat_daily/,[deleted],1482872179,[deleted],0,1,False,default,,,,,
864,MachineLearning,t5_2r3gv,2016-12-28,2016,12,28,6,5km6md,yerevann.com,[P] A detailed guide to deep learning,https://www.reddit.com/r/MachineLearning/comments/5km6md/p_a_detailed_guide_to_deep_learning/,HrantKhachatrian,1482873660,,12,248,False,default,,,,,
865,MachineLearning,t5_2r3gv,2016-12-28,2016,12,28,9,5kn5ku,self.MachineLearning,[D] Using Machine learning to detect fraudulent emails,https://www.reddit.com/r/MachineLearning/comments/5kn5ku/d_using_machine_learning_to_detect_fraudulent/,OptimizeBST,1482884802,"Hello reddit!

With a group of university students we have decided to do a little science project on fraudulent email detection. We have managed to have a bank to sponsor our work and provide two datasets of email metadata.

The company told us that they have identified two signs of fraudulent behavior: 

1. A group of people regularly emailing with carbon copies suddenly reduced to two people emailing each other, then resuming emailing with everyone in copies (fraud being hidden from managers).
2. Emailing an email domain that doesn't belong to the company (info leak).

For now, we are looking into ways to grasp the problem, we have considered:

1. Building graphs of relationships, trying to find a link between one person's centrality in the graph and its probability of frauding (distribution model).
2. Designing a clusterization algorithm on the graphs.

We are new with machine learning and since we have a very long time for this project, we'd like to lay a solid groundwork in the first part of our report. We are starting to run out of idea, what do you think would be other interesting work we could do with the data we have? What would be your next steps?

Thank you for your help.",3,3,False,self,,,,,
866,MachineLearning,t5_2r3gv,2016-12-28,2016,12,28,10,5knl8l,github.com,[P] Build a Traffic Sign Recognition Classifier using CNN,https://www.reddit.com/r/MachineLearning/comments/5knl8l/p_build_a_traffic_sign_recognition_classifier/,upulbandara,1482890105,,1,5,False,http://b.thumbs.redditmedia.com/HmaqqOUpGxpDknB8k8yCHZ-pfYUdmkdqBWvehYQGq-Y.jpg,,,,,
867,MachineLearning,t5_2r3gv,2016-12-28,2016,12,28,10,5knlk4,self.MachineLearning,[D] How to best format data across multiple tables,https://www.reddit.com/r/MachineLearning/comments/5knlk4/d_how_to_best_format_data_across_multiple_tables/,mlnew,1482890228,"Still new to machine learning and exploring different concepts, I seem to have gotten the hand of dealing with fairly basic problems but now want to try dealing with more comprehensive data. I'm looking at data which is formatted in a SQL DB where there are multiple tables with rows referencing each other and some tables having multiple rows referencing one row in another. 

What would be the best approach in formatting this kind of data? ",5,3,False,self,,,,,
868,MachineLearning,t5_2r3gv,2016-12-28,2016,12,28,11,5knnjs,self.MachineLearning,[D] Are people here satisfied with how Kaggle is run? Do you think there should be another company in the same space?,https://www.reddit.com/r/MachineLearning/comments/5knnjs/d_are_people_here_satisfied_with_how_kaggle_is/,[deleted],1482890911,[deleted],0,1,False,default,,,,,
869,MachineLearning,t5_2r3gv,2016-12-28,2016,12,28,15,5koqee,self.MachineLearning,[P]Is it possible that using mean/var of validation minibatch data for BN at validation phase?,https://www.reddit.com/r/MachineLearning/comments/5koqee/pis_it_possible_that_using_meanvar_of_validation/,[deleted],1482905239,[deleted],0,1,False,default,,,,,
870,MachineLearning,t5_2r3gv,2016-12-28,2016,12,28,15,5kos4y,self.MachineLearning,[D]Is it okay that using mean/variance of validation minibatch data for BN at validation phase?,https://www.reddit.com/r/MachineLearning/comments/5kos4y/dis_it_okay_that_using_meanvariance_of_validation/,kainsi,1482905966,"I'm training my classification model that has Batch Normalization layer.  At training phase, mean/var of training data is used to accelarate training. But at validation phase, it seems that a lot of models use whole training data's mean/var to validate their model as validation takes only 1 data sample. But, If my model acheives higher performance by using mean/var of minibatch validation data sample(not takes 1 validation sample, but minibatch sample that contains 32 samples), is it valid performance? (I heard that is cheating, but could not find the reason of it.)
If performance of my model is critically lower when it use mean/var of whole-training data than minibatch validation data, what are the possible reasons?",2,3,False,self,,,,,
871,MachineLearning,t5_2r3gv,2016-12-28,2016,12,28,16,5koy7p,self.MachineLearning,Is there a schedule for NMT rollouts for language pairs on Google Translate?,https://www.reddit.com/r/MachineLearning/comments/5koy7p/is_there_a_schedule_for_nmt_rollouts_for_language/,[deleted],1482908622,[removed],0,1,False,default,,,,,
872,MachineLearning,t5_2r3gv,2016-12-28,2016,12,28,16,5koz7j,technobium.com,Find words similarity using Deeplearning4j word2vec,https://www.reddit.com/r/MachineLearning/comments/5koz7j/find_words_similarity_using_deeplearning4j/,technobium,1482909033,,0,1,False,default,,,,,
873,MachineLearning,t5_2r3gv,2016-12-28,2016,12,28,16,5kp1g8,self.MachineLearning,newbie help needed - posted question on tensorflow https://www.reddit.com/r/tensorflow/comments/5kijxq,https://www.reddit.com/r/MachineLearning/comments/5kp1g8/newbie_help_needed_posted_question_on_tensorflow/,HibernationUnLtd,1482910072,[removed],0,1,False,default,,,,,
874,MachineLearning,t5_2r3gv,2016-12-28,2016,12,28,17,5kp60t,youtube.com, Automatic piston filling capping labeling Machine line ,https://www.reddit.com/r/MachineLearning/comments/5kp60t/_automatic_piston_filling_capping_labeling/,neostarpack,1482912332,,0,1,False,default,,,,,
875,MachineLearning,t5_2r3gv,2016-12-28,2016,12,28,20,5kpq2i,github.com,[p] Implementing mnist with High Performance Extreme Learning machine,https://www.reddit.com/r/MachineLearning/comments/5kpq2i/p_implementing_mnist_with_high_performance/,lashuel,1482922986,,13,0,False,http://b.thumbs.redditmedia.com/9E_75Qm2mdD1Or60IdZP4lSOKc-KuQ10HyyV-brIa2c.jpg,,,,,
876,MachineLearning,t5_2r3gv,2016-12-28,2016,12,28,20,5kprt0,lukeoakdenrayner.wordpress.com,"[D] A ""three phases"" framework for medical AI research",https://www.reddit.com/r/MachineLearning/comments/5kprt0/d_a_three_phases_framework_for_medical_ai_research/,drlukeor,1482923884,,6,11,False,http://b.thumbs.redditmedia.com/nwsoeOpfJcTcs7e1GvrE-x5dzSKay0I11GI1Uv9KSQM.jpg,,,,,
877,MachineLearning,t5_2r3gv,2016-12-28,2016,12,28,22,5kq57v,self.MachineLearning,[D] Master program in Artificial Intelligence or Computer Science,https://www.reddit.com/r/MachineLearning/comments/5kq57v/d_master_program_in_artificial_intelligence_or/,sikief,1482930403,"I'm currently studying applied Computer Science(BSc) with applications in computational neuroscience. I will finish my BSc in the next year, so I'm looking for a master program.
I'm very interested in ml and i would like to study and work in a field related to it.
I've found the artifical intelligence master program of the university of Amsterdam and I wondered if I should study something specialized to ml/ai or if it is better to continue a more general study in computer science.
So what do you think about this?",33,18,False,self,,,,,
878,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,0,5kqv4j,self.MachineLearning,"Simple Questions Thread December 28, 2016",https://www.reddit.com/r/MachineLearning/comments/5kqv4j/simple_questions_thread_december_28_2016/,AutoModerator,1482940351,[removed],0,1,False,default,,,,,
879,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,0,5kqvnq,media.giphy.com,This is me learning about neural networks,https://www.reddit.com/r/MachineLearning/comments/5kqvnq/this_is_me_learning_about_neural_networks/,lems2,1482940525,,0,1,False,default,,,,,
880,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,1,5kqygf,self.MachineLearning,"[D] Saliency and ""Maximal"" Images in Convolutional Neural Networks.",https://www.reddit.com/r/MachineLearning/comments/5kqygf/d_saliency_and_maximal_images_in_convolutional/,aiapplicant,1482941394,"In the literature for deep conv neural nets, I see a lot of people talk about ""saliency"" where they take a black box and convolve it along the image, and generate an image based on the max output value (from what I understand of their writings). Then I also sometimes see ""feature maps"" at each hidden layer where they generate the max output image that layer reacts to. How are these implemented, and is there a tensorflow implementation on hand?",8,11,False,self,,,,,
881,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,1,5kr31v,arxiv.org,[R] YOLO 9000,https://www.reddit.com/r/MachineLearning/comments/5kr31v/r_yolo_9000/,darkconfidantislife,1482942860,,31,60,False,default,,,,,
882,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,2,5kr9kw,pansop.com,Awesome Python ML Projects.,https://www.reddit.com/r/MachineLearning/comments/5kr9kw/awesome_python_ml_projects/,Pragyaditya1994,1482944828,,0,1,False,default,,,,,
883,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,2,5kr9wy,self.MachineLearning,"[D] ResNet vs. Highway Networks, when to use which?",https://www.reddit.com/r/MachineLearning/comments/5kr9wy/d_resnet_vs_highway_networks_when_to_use_which/,carlthome,1482944931,For what data and problems is it better to use highway networks instead of a non-trainable skip connection like those used by ResNet architectures?,5,5,False,self,,,,,
884,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,2,5krdy2,github.com,Implementing MaxMin Convolution Neural Networks- Better Accuracy Than Normal CNN,https://www.reddit.com/r/MachineLearning/comments/5krdy2/implementing_maxmin_convolution_neural_networks/,[deleted],1482946169,[deleted],1,1,False,default,,,,,
885,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,2,5kridl,karandesai-96.github.io,A modified Convolution Neural Network Architecture for better accuracy.,https://www.reddit.com/r/MachineLearning/comments/5kridl/a_modified_convolution_neural_network/,[deleted],1482947461,[deleted],0,1,False,default,,,,,
886,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,3,5krvbb,arxiv.org,[R] Deep Probabilistic Modeling of Natural Images using a Pyramid Decomposition,https://www.reddit.com/r/MachineLearning/comments/5krvbb/r_deep_probabilistic_modeling_of_natural_images/,goodside,1482951207,,12,21,False,default,,,,,
887,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,4,5ks62v,self.MachineLearning,"[D] ELI5, XGBoost?",https://www.reddit.com/r/MachineLearning/comments/5ks62v/d_eli5_xgboost/,[deleted],1482954369,[deleted],3,4,False,default,,,,,
888,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,5,5ks8vd,youtube.com,How to Make an Asteroids Game Bot (LIVE),https://www.reddit.com/r/MachineLearning/comments/5ks8vd/how_to_make_an_asteroids_game_bot_live/,llSourcell,1482955208,,0,1,False,default,,,,,
889,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,5,5ksdcn,arxiv.org,[R] Generative Models and Model Criticism via Optimized Maximum Mean Discrepancy,https://www.reddit.com/r/MachineLearning/comments/5ksdcn/r_generative_models_and_model_criticism_via/,adagrad,1482956490,,1,8,False,default,,,,,
890,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,5,5kshrf,ml.berkeley.edu,"[P] Machine Learning at Berkeley's Introductory ML Tutorial Series: Perceptrons, Logistic Regression, SVMs",https://www.reddit.com/r/MachineLearning/comments/5kshrf/p_machine_learning_at_berkeleys_introductory_ml/,mlberkeley,1482957811,,4,221,False,http://b.thumbs.redditmedia.com/2ECxRYUOkc0UVmMslFUYZkl35l8QhMaM2SCmKBADjAQ.jpg,,,,,
891,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,8,5ktcq7,tutorials.technology,Intro tutorial about linear regression with python,https://www.reddit.com/r/MachineLearning/comments/5ktcq7/intro_tutorial_about_linear_regression_with_python/,llazzaror,1482967151,,0,1,False,default,,,,,
892,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,10,5ktwbl,i.redd.it,[R] Made a visualization of a linear NN,https://www.reddit.com/r/MachineLearning/comments/5ktwbl/r_made_a_visualization_of_a_linear_nn/,blazarious,1482973548,,3,9,False,http://b.thumbs.redditmedia.com/rbm8Furwh7pMMElN2BxPsYHNQfgHoolQQC3GNJ4CAuk.jpg,,,,,
893,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,10,5ku5qj,github.com,[P] beauty.torch: Understanding facial beauty with deep learning.,https://www.reddit.com/r/MachineLearning/comments/5ku5qj/p_beautytorch_understanding_facial_beauty_with/,erogol,1482976579,,5,8,False,http://a.thumbs.redditmedia.com/QER_f7kbb5GfpXrXsPeNIZdTFx9GNymyHBVl0w7_pe0.jpg,,,,,
894,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,14,5kv2b7,self.MachineLearning,Thoughts on function prediction between two datasets.,https://www.reddit.com/r/MachineLearning/comments/5kv2b7/thoughts_on_function_prediction_between_two/,officialkwade,1482988296,[removed],0,1,False,default,,,,,
895,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,14,5kv768,self.MachineLearning,GTX 1080 or Titan X Pascal?,https://www.reddit.com/r/MachineLearning/comments/5kv768/gtx_1080_or_titan_x_pascal/,nhrahi_iut,1482990190,[removed],0,1,False,default,,,,,
896,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,15,5kvdci,self.MachineLearning,[D] Two dataset prediction,https://www.reddit.com/r/MachineLearning/comments/5kvdci/d_two_dataset_prediction/,officialkwade,1482992679,"I have two time series data sets, where set A undergoes some unknown function and becomes set B. 
my goals are two-fold:
1. I would like to predict some sort of function the two sets are undergoing. 
2. A high-fidelity way to predict set B from set A input. (maybe vice versa!?)

I would really appreciate any thoughts on the best way to go about this. I've attempted a couple approaches, but admittedly I'm still learning. Regression and RNN are what I've been hacking away at, and what reading has lead me too, but I think some advice will go a long way at saving me time and effort. I originally thought of useing half of the sets as test to arrive at the function, and I've been working with tensorflow too if that helps at all. 
Thanks in advance!

More Details:
This is a eeg dataset recorded from the hippocampus. Essentially, Set A is the firing patterns of neurons that send signals to Set B, which is more neuron firing in another portion of the hippocampus upstream from set A. The correspondence is staggered, so A fires, then B does something, etc, or at least that what it seem's like.
I want to see if an algorithm can predict the activity (set B) in the more upstream region based on its input (Set A). Set B, In my eyes, is really more of a training set, because for the final test it won't be needed, but I hope this helps. ",5,5,False,self,,,,,
897,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,16,5kvnd6,youtube.com,The video for showing the operation of being used horizontal ribbon mixers,https://www.reddit.com/r/MachineLearning/comments/5kvnd6/the_video_for_showing_the_operation_of_being_used/,mixmachinery,1482997093,,1,1,False,default,,,,,
898,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,17,5kvu4l,blog.hackerearth.com,Exclusive SQL Tutorial on Data Analysis in R (From Scratch),https://www.reddit.com/r/MachineLearning/comments/5kvu4l/exclusive_sql_tutorial_on_data_analysis_in_r_from/,NarendhiranS,1483000625,,0,1,False,default,,,,,
899,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,18,5kw0vc,self.MachineLearning,Create emotion recognition and run it on a server,https://www.reddit.com/r/MachineLearning/comments/5kw0vc/create_emotion_recognition_and_run_it_on_a_server/,gabegabe6,1483004220,[removed],0,1,False,default,,,,,
900,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,19,5kw65d,github.com,YOLOv1 and YOLOv2 on Tensorflow (with training supported for YOLOv1 and graph freezing for porting to C/C++),https://www.reddit.com/r/MachineLearning/comments/5kw65d/yolov1_and_yolov2_on_tensorflow_with_training/,thtrieu,1483006933,,0,1,False,default,,,,,
901,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,19,5kwa5z,self.MachineLearning,Incorporating Features based on Target in Training Set,https://www.reddit.com/r/MachineLearning/comments/5kwa5z/incorporating_features_based_on_target_in/,babuunn,1483009110,[removed],0,1,False,default,,,,,
902,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,21,5kwhn0,neptune.deepsense.io,Neptune - a platform for tracking machine learning experiments,https://www.reddit.com/r/MachineLearning/comments/5kwhn0/neptune_a_platform_for_tracking_machine_learning/,[deleted],1483012950,[deleted],0,1,False,default,,,,,
903,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,21,5kwhqw,neptune.deepsense.io,[P] Neptune - a platform for tracking machine learning experiments,https://www.reddit.com/r/MachineLearning/comments/5kwhqw/p_neptune_a_platform_for_tracking_machine/,pmigdal,1483013000,,18,26,False,default,,,,,
904,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,21,5kwj3g,mljar.com,[P] Analysis of 'Give me some credit' dataset from Kaggle,https://www.reddit.com/r/MachineLearning/comments/5kwj3g/p_analysis_of_give_me_some_credit_dataset_from/,[deleted],1483013634,[deleted],0,1,False,default,,,,,
905,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,22,5kwupd,dexur.com,Understanding &amp; Predicting Length of Stay (LOS) using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5kwupd/understanding_predicting_length_of_stay_los_using/,[deleted],1483018950,[deleted],0,1,False,default,,,,,
906,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,22,5kww3z,dexur.com,Understanding &amp; Predicting Length of Stay (LOS) using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5kww3z/understanding_predicting_length_of_stay_los_using/,YasukoHolmen,1483019576,,0,1,False,default,,,,,
907,MachineLearning,t5_2r3gv,2016-12-29,2016,12,29,23,5kwylg,self.MachineLearning,[D] Why ELM is so hated here ?,https://www.reddit.com/r/MachineLearning/comments/5kwylg/d_why_elm_is_so_hated_here/,mustafaihssan,1483020532,"I've seen that most threads about ELM in heavily down-voted, and the community here is very vocal about it's hatred toward it.",9,3,False,self,,,,,
908,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,0,5kx8uw,self.MachineLearning,[P] Analysis of 'Give me some credit' dataset from kaggle,https://www.reddit.com/r/MachineLearning/comments/5kx8uw/p_analysis_of_give_me_some_credit_dataset_from/,pplonski,1483024308,"I run analysis on dataset 'Give me some credit' from Kaggle. For analysis I used MLJAR for model training and hyperparameters tuning. The obtained predictions (in automatic way) got a 6th place on kaggle leaderbord (post-competition submission). The results are summarized in my [article](https://mljar.com/blog/machine-learning-wars/) - I also compared MLJAR results with Amazon ML, Google ML, PredicSis and BigML.",1,6,False,self,,,,,
909,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,0,5kxfkb,self.MachineLearning,[D] r/MachineLearning's 2016 Best Paper Award!,https://www.reddit.com/r/MachineLearning/comments/5kxfkb/d_rmachinelearnings_2016_best_paper_award/,Mandrathax,1483026508,"***EDIT : I will be announcing the results on monday 1/9***

***EDIT 2 : maybe 1/10 then because of travel issues irl, sorry about that***

---

Hi guys!

Welcome to /r/MachineLearning's 2016 Best Paper Award!

The idea is to have a community-wide vote for the best papers of this year.

I hope you find this to be a good idea, mods please tell me if this breaks any rules/if you had something like this in store.

---

## How does it work?

**Nominate** by commenting on the dedicatd top level comments. Please provide a (paywall free) link. Feel free to justify your choice. Also if you're one of the author, be courteous and indicate it.

**Vote** by upvoting the nominees.

The **results** will be announced **by the end of next week** (6-7th of Jan.). Depending on the participation/interest I might change it.

It's that simple!

There are some simple rules to make sure everything runs smoothly, you can find them below, please read them before commenting.

---

## Categories

- [Best Paper of the year](https://www.reddit.com/r/MachineLearning/comments/5kxfkb/d_rmachinelearnings_2016_best_paper_award/dbrapti/)

&gt; No rules! Any research paper you feel had the greatest impact/had top writing, any criterion is good.

- [Best student paper](https://www.reddit.com/r/MachineLearning/comments/5kxfkb/d_rmachinelearnings_2016_best_paper_award/dbraqkv/)

&gt; Papers from a student, grad/undergrad/highschool, everyone who doesn't have a phd and goes to school. The student must be first author of course. Provide evidence if possible.

- [Best paper name](https://www.reddit.com/r/MachineLearning/comments/5kxfkb/d_rmachinelearnings_2016_best_paper_award/dbrar08/)

&gt; Try to beat [this](http://www.oneweirdkerneltrick.com/spectral.pdf)

- [Best paper from academia](https://www.reddit.com/r/MachineLearning/comments/5kxfkb/d_rmachinelearnings_2016_best_paper_award/dbraroz/)

&gt; Papers where the first author is from a university / a state research organization (eg INRIA in France). 

- [Best paper from the industry](https://www.reddit.com/r/MachineLearning/comments/5kxfkb/d_rmachinelearnings_2016_best_paper_award/dbrasnz/)

&gt; Great paper from a multi-billion tech company (or more generally a research lab sponsored by privat funds, eg. openai)

- [Best rejected paper](https://www.reddit.com/r/MachineLearning/comments/5kxfkb/d_rmachinelearnings_2016_best_paper_award/dbrat9t/)

&gt; A chance of redemption for good papers that didn't make it trough peer review. Please provide evidence that the paper was rejected if possible.

- [Best unpublished preprint](https://www.reddit.com/r/MachineLearning/comments/5kxfkb/d_rmachinelearnings_2016_best_paper_award/dbratyb/)

&gt; A category for those yet to be published (e.g. papers from the end of the year). This may or may not be redundant with the rejected paper category, we'll see.

- [Best theoretical paper](https://www.reddit.com/r/MachineLearning/comments/5kxfkb/d_rmachinelearnings_2016_best_paper_award/dbrauan/)

&gt; Keep the math coming

- [Best non Deep Learning paper](https://www.reddit.com/r/MachineLearning/comments/5kxfkb/d_rmachinelearnings_2016_best_paper_award/dbraumv/)

&gt; Because gaussian processes, random forests and kernel methods deserve a chance amid the DL hype train

---

## Rules

1. Only one nomination by comment. You can nominate multiple papers in different comments/categories.
2. Nominations should include a **link to the paper**. In case of an arxiv link, please link to the arxiv page and not the pdf directly. Please do not link paywalled articles.
3. Only **research paper** are to be nominated. This means no book, no memo or no tutorial/blog post for instance. This could be adressed in a separate award or category if there is enough demand.
4. For the sake of clarity, there are some rules on commenting :
 - ***Do NOT comment on the main thread***. For discussion, use the [*discussion* thread](https://www.reddit.com/r/MachineLearning/comments/5kxfkb/d_rmachinelearnings_2016_best_paper_award/dbrap6u/)
 - ***Please ONLY comment the other threads with nominations***. You can discuss individual nominations in child comments. However 1rst level comments on each thread should be nominations only.
5. Respect reddit and this sub's rules.

I am not a mod so I have no way of enforcing these rules, please follow them to keep the thread clear. Of course, suggestions are welcome [here](https://www.reddit.com/r/MachineLearning/comments/5kxfkb/d_rmachinelearnings_2016_best_paper_award/dbrap6u/).

---

That's it, have fun!",100,232,False,self,,,,,
910,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,1,5kxnwy,analyticbridge.com,12 Statistical and Machine Learning Methods that Every Data Scientist Should Know,https://www.reddit.com/r/MachineLearning/comments/5kxnwy/12_statistical_and_machine_learning_methods_that/,pmz,1483029096,,0,2,False,default,,,,,
911,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,2,5kxy5v,self.MachineLearning,Intel NUC build enough?,https://www.reddit.com/r/MachineLearning/comments/5kxy5v/intel_nuc_build_enough/,throwawayintheville,1483032122,[removed],0,1,False,default,,,,,
912,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,2,5ky1il,self.MachineLearning,What does a typical project directory look like for you?,https://www.reddit.com/r/MachineLearning/comments/5ky1il/what_does_a_typical_project_directory_look_like/,coffeecoffeecoffeee,1483033087,[removed],0,1,False,default,,,,,
913,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,3,5ky7sd,stats.stackexchange.com,[D] What would cause the validation loss in LSTM to alternate between heavily improving and heavily worsening every epoch?,https://www.reddit.com/r/MachineLearning/comments/5ky7sd/d_what_would_cause_the_validation_loss_in_lstm_to/,c0cky_,1483034858,,0,0,False,default,,,,,
914,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,3,5ky9aj,self.MachineLearning,Are ELUs generally the best choice?,https://www.reddit.com/r/MachineLearning/comments/5ky9aj/are_elus_generally_the_best_choice/,chris2point0,1483035290,[removed],0,1,False,default,,,,,
915,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,4,5kykov,self.MachineLearning,"Why does WaveNet need special ""causal"" convolutions?",https://www.reddit.com/r/MachineLearning/comments/5kykov/why_does_wavenet_need_special_causal_convolutions/,[deleted],1483038587,[removed],0,1,False,default,,,,,
916,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,4,5kyru6,self.MachineLearning,"[D] Why does WaveNet need special ""causal"" convolutions?",https://www.reddit.com/r/MachineLearning/comments/5kyru6/d_why_does_wavenet_need_special_causal/,nharada,1483040592,"In the paper the authors state ""For 1-D data such as audio one can more easily implement [causal convolutions] by shifting the output of a normal convolution by a few timesteps""[1]

Why do they even need to do this? My impression was that for 1D signals the convention[2] is to use the right edge of the impulse as the location where the convolution is summed -- unlike in a 2D convolution where the center of the kernel is used. Wouldn't this result in a ""causal"" convolution by default? Is this shifting just to deal with edge effects?

[1] https://arxiv.org/pdf/1609.03499.pdf, section 2.1, paragraph 1

[2] https://docs.scipy.org/doc/numpy/reference/generated/numpy.convolve.html",3,3,False,self,,,,,
917,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,5,5kywrz,self.MachineLearning,[D] Tools to create conceptual diagrams?,https://www.reddit.com/r/MachineLearning/comments/5kywrz/d_tools_to_create_conceptual_diagrams/,robintibor,1483041998,What are good tools to quickly create nice-looking conceptual diagrams for ML papers? With conceptual diagrams I mean figures like this: https://arxiv.org/pdf/1608.06993v3.pdf figure 1 or the network figure here: http://hi.cs.waseda.ac.jp/~iizuka/projects/colorization/en/? What do people use when they want to make them fairly quickly?,7,10,False,self,,,,,
918,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,6,5kz8ns,arxiv.org,[P] StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/5kz8ns/p_stackgan_text_to_photorealistic_image_synthesis/,[deleted],1483045401,[deleted],0,1,False,default,,,,,
919,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,6,5kz8tz,arxiv.org,[R] StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/5kz8tz/r_stackgan_text_to_photorealistic_image_synthesis/,[deleted],1483045446,[deleted],2,0,False,default,,,,,
920,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,6,5kzbz2,self.MachineLearning,What Are Vectors In Deep Learning Exactly &amp; What Math Do I Need To Know To Build NNs? Yes I Googled These Questions. Still In The Dark.,https://www.reddit.com/r/MachineLearning/comments/5kzbz2/what_are_vectors_in_deep_learning_exactly_what/,Motor_City_Cobra,1483046385,[removed],0,1,False,default,,,,,
921,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,8,5kzw4k,spectrum.ieee.org,Faster ML/DL using specialised hardware beyond just GPUs,https://www.reddit.com/r/MachineLearning/comments/5kzw4k/faster_mldl_using_specialised_hardware_beyond/,Phnyx,1483052468,,0,1,False,default,,,,,
922,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,8,5kzxql,deeplearninggallery.com,Deep Learning Gallery - a curated list of awesome deep learning projects. Any feedback?,https://www.reddit.com/r/MachineLearning/comments/5kzxql/deep_learning_gallery_a_curated_list_of_awesome/,alecmgo,1483052949,,0,1,False,default,,,,,
923,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,8,5l00o5,youtu.be,Image Synthesis From Text With Deep Learning | Two Minute Papers,https://www.reddit.com/r/MachineLearning/comments/5l00o5/image_synthesis_from_text_with_deep_learning_two/,[deleted],1483053872,[deleted],0,1,False,default,,,,,
924,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,8,5l00re,youtu.be,[R] Image Synthesis From Text With Deep Learning | Two Minute Papers,https://www.reddit.com/r/MachineLearning/comments/5l00re/r_image_synthesis_from_text_with_deep_learning/,Buck-Nasty,1483053902,,23,176,False,http://b.thumbs.redditmedia.com/Jj3XzZMQb295pYLlea7ZtoWTZy3lmQTMJTGYifNwiBk.jpg,,,,,
925,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,8,5l02to,self.MachineLearning,[D] Decision fusion using multiple classifiers,https://www.reddit.com/r/MachineLearning/comments/5l02to/d_decision_fusion_using_multiple_classifiers/,nightshade_7,1483054547,What are some of the methods used to combine classifiers to get a higher rate of accuracy?,3,3,False,self,,,,,
926,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,10,5l0k6w,arxiv.org,[R] DelugeNets: Deep Networks with Massive and Flexible Cross-layer Information Inflows,https://www.reddit.com/r/MachineLearning/comments/5l0k6w/r_delugenets_deep_networks_with_massive_and/,xternalz,1483060224,,6,12,False,default,,,,,
927,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,10,5l0mfm,arxiv.org,[R] lfda: An R Package for Local Fisher Discriminant Analysis and Visualization,https://www.reddit.com/r/MachineLearning/comments/5l0mfm/r_lfda_an_r_package_for_local_fisher_discriminant/,terrytangyuan,1483060939,,1,5,False,default,,,,,
928,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,10,5l0ml4,self.MachineLearning,[D] Which normalization technique works best for LSTMs?,https://www.reddit.com/r/MachineLearning/comments/5l0ml4/d_which_normalization_technique_works_best_for/,ma2rten,1483060996,"There have been a couple of papers over the past year applying different kinds of normalization to RNN / LSTM networks.

* Layer Norm: https://arxiv.org/abs/1607.06450
* Weight Norm: https://arxiv.org/abs/1602.07868
* Batch Norm: https://arxiv.org/abs/1603.09025

Do you guys have any insight or practical experience which one of these works best?",6,24,False,self,,,,,
929,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,10,5l0muq,arxiv.org,[R] TF.Learn: TensorFlow's High-level Module for Distributed Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5l0muq/r_tflearn_tensorflows_highlevel_module_for/,terrytangyuan,1483061083,,25,11,False,default,,,,,
930,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,11,5l0t28,youtube.com,"Nail making machine factory,thread rolling machine manufacturers from china",https://www.reddit.com/r/MachineLearning/comments/5l0t28/nail_making_machine_factorythread_rolling_machine/,shengxin01,1483063227,,0,1,False,default,,,,,
931,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,11,5l0zpf,self.MachineLearning,Illustrated Neural Network,https://www.reddit.com/r/MachineLearning/comments/5l0zpf/illustrated_neural_network/,digitalOctopus,1483065569,[removed],0,1,False,default,,,,,
932,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,12,5l15yc,youtube.com,Products Catalog -shandong jinlun machinery,https://www.reddit.com/r/MachineLearning/comments/5l15yc/products_catalog_shandong_jinlun_machinery/,woodworking-machine,1483067749,,0,1,False,default,,,,,
933,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,12,5l1bgb,affinelayer.com,[P] Hip-Hop: Generating lyrics with RNNs,https://www.reddit.com/r/MachineLearning/comments/5l1bgb/p_hiphop_generating_lyrics_with_rnns/,Tryneus,1483069735,,6,25,False,default,,,,,
934,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,12,5l1d83,arxiv.org,[R] The Predictron: end-to-end learning and planning,https://www.reddit.com/r/MachineLearning/comments/5l1d83/r_the_predictron_endtoend_learning_and_planning/,NYDreamer,1483070383,,3,25,False,default,,,,,
935,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,13,5l1fcj,self.MachineLearning,[D] Ideas for my fully connected layer in my CNN (Resnet),https://www.reddit.com/r/MachineLearning/comments/5l1fcj/d_ideas_for_my_fully_connected_layer_in_my_cnn/,nimakhin,1483071171,"I am doing a 3D implementation of Resnet in which the input has the size of 64x64x12 (3d Image), after couple of layers I end up with 1024 feature maps, each with the size of 2x2x3 so when I flatten them i will get 12288 nodes, now is the time for the fully connected(FC) layers. In Resnet they use FC-1000 but in my situation i should end with 1 node (either True of False). I would appreciate your ideas about my FC layer, how many layers do i need at the end? what is the best way to reduce 12288 nodes to 1, layer by layer !
if I'm doing it wrong before my FC please help me also",6,2,False,self,,,,,
936,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,14,5l1p5z,self.MachineLearning,[D] Research to look forward to in 2017,https://www.reddit.com/r/MachineLearning/comments/5l1p5z/d_research_to_look_forward_to_in_2017/,tyrael71,1483074883,"- What areas do you think will be explored most in 2017? Are there any low-hanging fruits?

- Which problems are you hoping will be solved in the following year? Should people focus on something in particular?

- What are you focusing on next year?",15,27,False,self,,,,,
937,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,14,5l1pf3,youtube.com,Generating anime voices with RNNs,https://www.reddit.com/r/MachineLearning/comments/5l1pf3/generating_anime_voices_with_rnns/,theemathas,1483074980,,1,1,False,default,,,,,
938,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,14,5l1uuf,youtube.com,SUS-101-MHW (VFFS) Vertical Multiples Dates Packaging Machine,https://www.reddit.com/r/MachineLearning/comments/5l1uuf/sus101mhw_vffs_vertical_multiples_dates_packaging/,Machiningan,1483077091,,0,1,False,default,,,,,
939,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,15,5l1wca,spectrum.ieee.org,Expect Deeper and Cheaper Machine Learning | Supercharged hardware will speed up deep learning in everything from tiny devices to massive data centers.,https://www.reddit.com/r/MachineLearning/comments/5l1wca/expect_deeper_and_cheaper_machine_learning/,NarendhiranS,1483077681,,0,1,False,default,,,,,
940,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,15,5l1zdc,blog.algorithmia.com,"[N] Hey Zuck, we built your office A.I. solution",https://www.reddit.com/r/MachineLearning/comments/5l1zdc/n_hey_zuck_we_built_your_office_ai_solution/,anantzoid,1483078903,,1,0,False,http://a.thumbs.redditmedia.com/E_JoaFDFSrUQoPC3zTfPJhasBdFR1Lv1o2vWhMRGz94.jpg,,,,,
941,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,15,5l22aj,github.com,"Auto-differentiable Conv, BatchNorm, Long Short Term Memory built from scratch on numpy",https://www.reddit.com/r/MachineLearning/comments/5l22aj/autodifferentiable_conv_batchnorm_long_short_term/,[deleted],1483080105,[deleted],0,1,False,default,,,,,
942,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,16,5l28nm,self.MachineLearning,SackGAN for Textsynthese?,https://www.reddit.com/r/MachineLearning/comments/5l28nm/sackgan_for_textsynthese/,[deleted],1483082968,[removed],0,1,False,default,,,,,
943,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,16,5l29vy,self.MachineLearning,[D] StackGAN for Textsynthesis,https://www.reddit.com/r/MachineLearning/comments/5l29vy/d_stackgan_for_textsynthesis/,thepok,1483083572,"Hello, did someone yet applay stacked GANs to the domain of Textsynthesis? I imagine a first or multiple GANs working on a grammar to create higher order Structure, and GANs that Fill this grammers with life. This way, longer logicly correct Texts could be generated?",2,1,False,self,,,,,
944,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,17,5l2e3x,mixmachinery.com,What is the conical mixer design?,https://www.reddit.com/r/MachineLearning/comments/5l2e3x/what_is_the_conical_mixer_design/,mixmachinery,1483085666,,1,1,False,default,,,,,
945,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,18,5l2o7y,self.MachineLearning,"Stupid question: Why do neural networks need thousands of training images to recognize a cat, but a human child can learn what a cat is just by seeing one cat?",https://www.reddit.com/r/MachineLearning/comments/5l2o7y/stupid_question_why_do_neural_networks_need/,Halcyon_Red,1483091001,[removed],0,1,False,default,,,,,
946,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,18,5l2oug,self.MachineLearning,Hobbyist voice recognition and generation,https://www.reddit.com/r/MachineLearning/comments/5l2oug/hobbyist_voice_recognition_and_generation/,OptimalPrimeRib,1483091324,[removed],0,1,False,default,,,,,
947,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,19,5l2uul,github.com,[P]nvidia-multiple-smi All your network's GPUs at a glance,https://www.reddit.com/r/MachineLearning/comments/5l2uul/pnvidiamultiplesmi_all_your_networks_gpus_at_a/,Ouitos,1483094583,,7,18,False,http://b.thumbs.redditmedia.com/oEF4mVIHaOxo3pUSatvnM_VGMcw9ARg_UqIuYqJmjQY.jpg,,,,,
948,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,20,5l32ii,insidebigdata.com,Ushering in a Whole New Cognitive Era with Deep Learning,https://www.reddit.com/r/MachineLearning/comments/5l32ii/ushering_in_a_whole_new_cognitive_era_with_deep/,NehaSahrma001,1483098606,,0,1,False,default,,,,,
949,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,21,5l370v,self.MachineLearning,[D] Is it possible to learn sexy tasks with tree based method?,https://www.reddit.com/r/MachineLearning/comments/5l370v/d_is_it_possible_to_learn_sexy_tasks_with_tree/,godspeed_china,1483100748,"tree dominates in structured data, eg xgboost, while neural network dominates sexy tasks, eg. neural turing machine, GAN. my bias is trees are very elegant (fast, easy tuning, accurate). So can trees be used in sexy tasks? my previous post shows that Random Forest can do char-rnn task well. So can we develop random forest turing machine, adversarial  forest etc?",3,1,False,self,,,,,
950,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,22,5l3cwu,machinelearningblogs.com,How to build a search engine: Part 3,https://www.reddit.com/r/MachineLearning/comments/5l3cwu/how_to_build_a_search_engine_part_3/,vivekkalyanarangan,1483103415,,0,1,False,default,,,,,
951,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,22,5l3f1c,self.MachineLearning,[D] What happened to DropOut?,https://www.reddit.com/r/MachineLearning/comments/5l3f1c/d_what_happened_to_dropout/,svantana,1483104364,"When Hinton plugged DropOut bigtime a few years ago, it seemed like a good solution to the overfitting problem, and like a new standard that everyone would use from then on. Some variants on the theme came about after that. But these days you hardly see it mentioned in any of the papers with impressive results. What happened? These days it seems overfitting is hardly a problem, although nets are huge and often larger than the dataset. Do you think the DropOut patent has something to do with it? Also I guess the VAE is a more elegant solution to the same problem?",35,107,False,self,,,,,
952,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,22,5l3i5n,dzone.com,Data Science Using Oracle Advanced Analytics - DZone Big Data,https://www.reddit.com/r/MachineLearning/comments/5l3i5n/data_science_using_oracle_advanced_analytics/,Sibanjan,1483105751,,0,1,False,default,,,,,
953,MachineLearning,t5_2r3gv,2016-12-30,2016,12,30,22,5l3iyc,mljar.com,[P] MLJAR: Platform for building Machine Learning models,https://www.reddit.com/r/MachineLearning/comments/5l3iyc/p_mljar_platform_for_building_machine_learning/,pplonski,1483106126,,1,1,False,default,,,,,
954,MachineLearning,t5_2r3gv,2016-12-31,2016,12,31,0,5l40x9,self.MachineLearning,AI and machine learning,https://www.reddit.com/r/MachineLearning/comments/5l40x9/ai_and_machine_learning/,theguy2108,1483112622,[removed],0,1,False,default,,,,,
955,MachineLearning,t5_2r3gv,2016-12-31,2016,12,31,0,5l42ma,arxiv.org,[R] EnhanceNet: Single Image Super-Resolution through Automated Texture Synthesis,https://www.reddit.com/r/MachineLearning/comments/5l42ma/r_enhancenet_single_image_superresolution_through/,carbonat38,1483113169,,8,16,False,default,,,,,
956,MachineLearning,t5_2r3gv,2016-12-31,2016,12,31,2,5l4gfl,self.MachineLearning,[D] How to use world model to help train a controller using RNN ?,https://www.reddit.com/r/MachineLearning/comments/5l4gfl/d_how_to_use_world_model_to_help_train_a/,COGITO_7,1483117413,"Last year Jurgen Schmidhuber release a technical report on a new way to perform unsupervised learning :
 https://arxiv.org/abs/1511.09249

In the paper, i don't really understand how to use data predication from the world model ""M"" to help train the controller ""C"" which use reinforcement learning.

How to use M as an state for C ? (all details in the section 5)",0,5,False,self,,,,,
957,MachineLearning,t5_2r3gv,2016-12-31,2016,12,31,2,5l4mc8,openreview.net,[R] Deep Learning with Dynamic Computation Graphs (Google Brain),https://www.reddit.com/r/MachineLearning/comments/5l4mc8/r_deep_learning_with_dynamic_computation_graphs/,SuperFX,1483119158,,16,17,False,default,,,,,
958,MachineLearning,t5_2r3gv,2016-12-31,2016,12,31,3,5l529y,arxiv.org,[R] Operational calculus on programming spaces and generalized tensor networks,https://www.reddit.com/r/MachineLearning/comments/5l529y/r_operational_calculus_on_programming_spaces_and/,abstractcontrol,1483123785,,9,29,False,default,,,,,
959,MachineLearning,t5_2r3gv,2016-12-31,2016,12,31,5,5l5kcd,adversarial.ai,AI's Role in Our Urban Future: Response to Pentagon Video,https://www.reddit.com/r/MachineLearning/comments/5l5kcd/ais_role_in_our_urban_future_response_to_pentagon/,arshakn,1483129169,,0,1,False,default,,,,,
960,MachineLearning,t5_2r3gv,2016-12-31,2016,12,31,7,5l6d2s,github.com,AI Guild: A podcast akin to grabbing coffee with Creative AI researchers,https://www.reddit.com/r/MachineLearning/comments/5l6d2s/ai_guild_a_podcast_akin_to_grabbing_coffee_with/,chadwittman,1483138161,,1,1,False,default,,,,,
961,MachineLearning,t5_2r3gv,2016-12-31,2016,12,31,8,5l6o48,openreview.net,Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer,https://www.reddit.com/r/MachineLearning/comments/5l6o48/outrageously_large_neural_networks_the/,[deleted],1483141828,[deleted],0,1,False,default,,,,,
962,MachineLearning,t5_2r3gv,2016-12-31,2016,12,31,8,5l6o9u,openreview.net,[R] Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer,https://www.reddit.com/r/MachineLearning/comments/5l6o9u/r_outrageously_large_neural_networks_the/,ma2rten,1483141887,,17,40,False,default,,,,,
963,MachineLearning,t5_2r3gv,2016-12-31,2016,12,31,13,5l7t9j,self.MachineLearning,Neural Networks newbie,https://www.reddit.com/r/MachineLearning/comments/5l7t9j/neural_networks_newbie/,Miseryy,1483156865,[removed],0,1,False,default,,,,,
964,MachineLearning,t5_2r3gv,2016-12-31,2016,12,31,14,5l87d6,github.com,A non overwhelming list of machine learning resources for beginners,https://www.reddit.com/r/MachineLearning/comments/5l87d6/a_non_overwhelming_list_of_machine_learning/,kendrick__,1483162474,,0,2,False,default,,,,,
965,MachineLearning,t5_2r3gv,2016-12-31,2016,12,31,14,5l87g9,ieeexplore.ieee.org,[R] A Scalable Algorithm for Simulating the Structural Plasticity of the Brain,https://www.reddit.com/r/MachineLearning/comments/5l87g9/r_a_scalable_algorithm_for_simulating_the/,KennySmash,1483162509,,4,30,False,default,,,,,
966,MachineLearning,t5_2r3gv,2016-12-31,2016,12,31,14,5l87r9,self.MachineLearning,explaining Bayesian networks reasoning/outcome via deep learning,https://www.reddit.com/r/MachineLearning/comments/5l87r9/explaining_bayesian_networks_reasoningoutcome_via/,koormoosh,1483162649,[removed],0,1,False,default,,,,,
967,MachineLearning,t5_2r3gv,2016-12-31,2016,12,31,16,5l8kz3,self.MachineLearning,How much calculus for machine learning?,https://www.reddit.com/r/MachineLearning/comments/5l8kz3/how_much_calculus_for_machine_learning/,abefromdublin,1483168422,[removed],0,1,False,default,,,,,
968,MachineLearning,t5_2r3gv,2016-12-31,2016,12,31,19,5l97h9,self.MachineLearning,[D] SOM - Color Mapping,https://www.reddit.com/r/MachineLearning/comments/5l97h9/d_som_color_mapping/,WuhuSpringfield,1483181602,"Hello guys,    
I am fairly new into the whole 'Machine Learning' and 'Self Organzing Map' thematic and ready to dig into it. I just have a basic question to see if I do have the right understanding.    

We are talking about [this particular website](http://jjguy.com/som/) (Subtitle *""Hello, world"" of SOMs""*, Subsubtitle *""Colors""*). You can see two pictures - the first one with randomly colored points and a second one where color levels are clustered together.    

**My understanding / hypothesis** so far is, that ....     
The first picture (random colors) can be presented in a three-dimensional world by projecting the different colors (RGB) onto an xyz-axis-system and inserting the individual points in these three dimensions. A SOM will now try to straighten these disperse data points. The result is a plane within the three dimensional RGB world.    
     

Can you confirm my hypothesis?    
(Disclaimer: I am not a native English speaker. If some words sounds wrong, please correct me)",6,3,False,self,,,,,
969,MachineLearning,t5_2r3gv,2016-12-31,2016,12,31,21,5l9h7e,self.MachineLearning,[D] The current state of virtual assistants and they immediate future.,https://www.reddit.com/r/MachineLearning/comments/5l9h7e/d_the_current_state_of_virtual_assistants_and/,I-Want-An-AI-Wife,1483187505,"Hi, I've always been into AI and Future technology and even slightly believe in the singularity. I think the best thing that will happen for the average person in the next 10 years due to AI will be the arrival of personal digital Assistants. Much like Siri or Cortana but with more advanced AI functions build in. The ability to learn their ""clients?"" preferences and adapt to better suit their needs. I know we are a long way off from being able to have a program that can make new command libraries without manually going in and creating them yourself but I don't see why we can't have some sort of chat bot integrated with Cortana and a program similar to how Google decides what ads you see. This program would essentially talk to you as you play a game or look at memes and while you are doing that it could browse for example, reddit. I think the easiest would be to start it in TIL and it begins to read out TIL posts to you. You then say your thoughts on the post and according to what you say it would modify what posts it reads to you next. After a bit you would only be read things that interest you. It could be integrated to read comments on things you find very interesting or ones that have a large amount of karma. It could also be programmed to preform fact checks on what you request and summerizing articles that the post is sent to. Obviously the options are endless when this kind of program is made but i imagine at some point in the future the program would begin adding comments of its own to conversations with you. It could also then browse images and videos and even music and help give you new content. It would be like having a friend who's life was dedicated to making yours better. Think Samantha from Her. How far are we from having a program like this that could go onto a modern gaming computer? How for are we from a program like this that could go on a modern gaming computer without having to be connected to massive database network in order to function? What is the closest thing to this I could get to begin playing with?
I am also preparing to go back to school and I think I want to go into AI. I do some programming and I'm good at math but I don't want to sit Infront of a bunch of code all day for the next 10-15 years. Is there anything in the AI field that is more related to working on the personality and personalization of AI as opposed to the image and voice recognition software that's all over YouTuber? What kind of program would I want to enter to start working on AI? Am I looking at a 3 year program, or a masters? Should I just join a general CS?
Cheers",2,0,False,self,,,,,
970,MachineLearning,t5_2r3gv,2016-12-31,2016,12,31,22,5l9l1n,lukeoakdenrayner.wordpress.com,Predicting Medical AI in 2017,https://www.reddit.com/r/MachineLearning/comments/5l9l1n/predicting_medical_ai_in_2017/,[deleted],1483189603,[deleted],0,1,False,default,,,,,
971,MachineLearning,t5_2r3gv,2016-12-31,2016,12,31,22,5l9n3s,lukeoakdenrayner.wordpress.com,[D] Predicting Medical AI in 2017,https://www.reddit.com/r/MachineLearning/comments/5l9n3s/d_predicting_medical_ai_in_2017/,drlukeor,1483190655,,29,69,False,http://a.thumbs.redditmedia.com/NkuBKuXqMDt7qSgRKEqkrKwXT-GqrZEuVjBlKo4bcR0.jpg,,,,,
972,MachineLearning,t5_2r3gv,2016-12-31,2016,12,31,23,5l9uic,github.com,[P] DeepLab-ResNet for Semantic Image Segmentation in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/5l9uic/p_deeplabresnet_for_semantic_image_segmentation/,_dr_sleep,1483194340,,0,40,False,http://b.thumbs.redditmedia.com/uYTOcgjNpKyDm4DgrjD96YqlnKE-GCaiqgOgze_AWvY.jpg,,,,,
