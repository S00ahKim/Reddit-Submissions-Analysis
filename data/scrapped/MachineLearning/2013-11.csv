,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2013-11-1,2013,11,1,14,1po6xq,Machine learning with Mahout: The Lay of the Land,https://www.reddit.com/r/MachineLearning/comments/1po6xq/machine_learning_with_mahout_the_lay_of_the_land/,neutronbob,1383284176,,0,16
1,2013-11-2,2013,11,2,0,1poutd,Tips on choosing appropriate time series for prediction in R (using SVR),https://www.reddit.com/r/MachineLearning/comments/1poutd/tips_on_choosing_appropriate_time_series_for/,[deleted],1383318277,"Hi,

I have to write paper on SVM and the practical part includes running a SVR to predict impact of different time series on oil prices. I'm quite new to R and applied statistics and first of all, have no idea how to choose and where to get appropriate time series, and secondly how to get started with the practical part. I've been reading a lot of SVM, and think I got the intuition and the math behind it, however I don't really know how to get started with the part in R. Can anyone provide me with some guidance on this? Thanks! ",5,5
2,2013-11-2,2013,11,2,1,1pp1mv,Easiest to use library or tool for multi-class linear discriminant analysis?,https://www.reddit.com/r/MachineLearning/comments/1pp1mv/easiest_to_use_library_or_tool_for_multiclass/,ikurei,1383323320,"I've been asked to use LDA for dimensionality reduction, with a multiclass dataset. What is the fastest way to do it? I'd prefer weka or octave over matlab or R, but it will do too.

thanks!


PD: it's part of a class assignment i need to do asap. I did most of it, but I forgot about this part because I'm kind of a disaster and trying to do too much stuff in too little time.",2,0
3,2013-11-2,2013,11,2,4,1ppgz5,Day 4 : PredictionIO : How to Build A Blog Recommender,https://www.reddit.com/r/MachineLearning/comments/1ppgz5/day_4_predictionio_how_to_build_a_blog_recommender/,shekhargulati,1383334787,,0,0
4,2013-11-2,2013,11,2,4,1ppiif,Daily Paper Review: Deep Generative Stochastic Networks Trainable by Backprop (Bengio et al),https://www.reddit.com/r/MachineLearning/comments/1ppiif/daily_paper_review_deep_generative_stochastic/,not_not_sure,1383335905,"[Arxiv link](http://arxiv.org/pdf/1306.1091) I read it really quickly, ~~but I'm confused by log(P) being positive in the results (Table 1)~~. (**Edit**: never mind) If I remember correctly, DBMs enable really good discriminative accuracy, like 0.9% error rate on ""knowledge-free"" MNIST. Why not compare to that?",30,20
5,2013-11-2,2013,11,2,5,1ppmsg,Any experts on Probabilistic Neural Networks?,https://www.reddit.com/r/MachineLearning/comments/1ppmsg/any_experts_on_probabilistic_neural_networks/,VortexK,1383339142,"I'm looking for useful information on algorithms and detailed pseudocode for implementing the neural network. I have a basic idea of how to do it but I need a better foundation of the Neural Network.

Fundamentally, my professor has showed the use of the Gaussian Weighting Function, features of input vectors, sigma values for the gaussians, but applying the code is difficult for me in that I would like to see the pseudocode for a similar network.

I would like to know the best way for implementing the neural network, optimizing values for sigma, and how training should be done. I've looked through many books in my university's library but I haven't found anything that I could follow through and see how to implement for real data.

Any help&gt;",8,0
6,2013-11-2,2013,11,2,7,1ppvkx,"Tried to overfit a Bayes net, but mean prediction error is worse than learned network?",https://www.reddit.com/r/MachineLearning/comments/1ppvkx/tried_to_overfit_a_bayes_net_but_mean_prediction/,osazuwa,1383346369,"I have variables A, B, C, D, and E.  I am interested in building a classifier for A. 

I learned a Bayes net structure from the data using greedy search and BIC as a score.  Call this network 1.  Using cross validation, I got the mean prediction error for node A in network 1

I then thought to create a network structure where all the arcs are incoming into A (B-&gt;A, C-&gt;A, D-&gt;A, E-&gt;A).  Call this network 2.

I also learned a third network that was constrained by having all the arcs in network 2, but could allow additional arcs between B, C, D, and E.  Call this network 3.

It seemed to me that the network 2 and network 3 would be better at predicting A because I was forcing all the info in the data as a direct input into predicting A -- i.e. overfitting.  So I expected the mean prediction errors for these networks to be less than the first network.  But instead they were higher.

Also, when I repeated the cross validation several times, the mean prediction error for network 1 was always the same.  But the value varied for networks 2 and 3. 

Why would networks 2 and 3 have a higher mpe, and why would mpe for those networks be variable while not variable for network 1?",1,0
7,2013-11-2,2013,11,2,8,1ppway,What Are the Benefits of Knowledge Graphs?,https://www.reddit.com/r/MachineLearning/comments/1ppway/what_are_the_benefits_of_knowledge_graphs/,redmnms,1383346959,,0,0
8,2013-11-2,2013,11,2,11,1pqazz,Quick Sentiment Analysis with Vowpal Wabbit (IMDB review dataset),https://www.reddit.com/r/MachineLearning/comments/1pqazz/quick_sentiment_analysis_with_vowpal_wabbit_imdb/,NOT_BRIAN_POSEHN,1383360743,,1,11
9,2013-11-2,2013,11,2,20,1pqtn6,Has anyone had success training multi-class SVMs in openCV?,https://www.reddit.com/r/MachineLearning/comments/1pqtn6/has_anyone_had_success_training_multiclass_svms/,Badoosker,1383391432,"I've been trying for a couple hours to train a multi-class SVM in opencv and the trained SVM, which is trained for 7 classes, is only able to output and predict on 2.

Does this mean I have not blown up the dimensionality enough? Or does the multi-class svm suck?

I've been thinking of using a one-vs-all method instead.",6,1
10,2013-11-3,2013,11,3,3,1prg4w,Jobs in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/1prg4w/jobs_in_machine_learning/,iamiamwhoami,1383417201,"I am currently a fourth year physics PhD student. I've decided I much rather go into some sort of programming field rather than academia. I am curious what sorts of jobs are out there in the field of machine learning and what sort of background you need for these jobs. I've spent a large part of the last few years programming in python and matlab. I've also done coursework in java and c++. I've done the intro to algorithms course on coursera, and I'm currently taking the coursera machine learning course and the udacity parallel programming course. I'm very much interested in these online programming courses, and I'm going to try to take as many as I can over the next few years. I also would like to know if anyone has any suggestions for topics to learn to make myself more competitive for jobs in the field. Thanks for the help.",20,5
11,2013-11-3,2013,11,3,7,1prz4n,A simple method for regression of percentages?,https://www.reddit.com/r/MachineLearning/comments/1prz4n/a_simple_method_for_regression_of_percentages/,cypherx,1383433082,"Hi, 

I have a low-dimensional dataset whose output is a percentage, typically between .5% to ~6%. I would like to build a simple (and somewhat intrepertable) model from this data. The obvious methods available are linear regression (which can easily give values outside the valid range) and logistic regression (which is biased toward higher percentages on new inputs). So, what's a better model that will give values that are bounded below by 0? Should I simply take the log of the target values and do a linear regression on that? ",11,4
12,2013-11-3,2013,11,3,14,1psls8,Beginner examples/problems to practice ML?,https://www.reddit.com/r/MachineLearning/comments/1psls8/beginner_examplesproblems_to_practice_ml/,Olonzac,1383455136,What are some problems/examples which a beginner could implement ML to practice it?,20,11
13,2013-11-4,2013,11,4,5,1ptt0r,Ask Reddit: What other online ML communities are out there?,https://www.reddit.com/r/MachineLearning/comments/1ptt0r/ask_reddit_what_other_online_ml_communities_are/,not_not_sure,1383510342,,13,20
14,2013-11-4,2013,11,4,10,1pugdd,Multiclass SVM Experimental Results,https://www.reddit.com/r/MachineLearning/comments/1pugdd/multiclass_svm_experimental_results/,Badoosker,1383528782,"The SVM I used is in the link.


I did some experiments to figure out why it wasn't working, and to analyze what gives me proper percentages.


I checked out things like sample size, number of classes, cluster size, difference of gaussian kernels, and image size.




I'll be updating with my experimental results tonight in comments. 





Edit: Sorry, link wasn't working before. http://docs.opencv.org/doc/tutorials/ml/introduction_to_svm/introduction_to_svm.html



The first experiment:



Number of classes 10


Number of clusters: 50


DoG Kernels: (151,151) - (11,11)


Image size: 256x256



Average accuracy: 38%


Training time: 31s


Experiment 4: 3000 clusters

Number of classes 10

Number of clusters: 3000

DoG Kernels: (151,151) - (11,11)

Image size: 256x256

Average accuracy: 50%

Training time: 204s

Experiment 5: 5000 clusters

Number of classes 10

Number of clusters: 5000

DoG Kernels: (151,151) - (11,11)

Image size: 256x256

Average accuracy: 37%

Training time: 306s



Experiment 6: 10,000 clusters

Number of classes 10

Number of clusters 10,000

DoG Kernels: (151,151)-(11,11)

Image size: 256x256

Average accuracy: 32%

Training time: 450s

Experiment 7: 3500 clusters

Number of classes 10

Number of clusters 3500

DoG Kernels: (151,151)-(11,11)

Image size: 256x256

Average accuracy: 32%

Training Time: 219s",3,0
15,2013-11-4,2013,11,4,14,1puxmd,Are there publicly available large datasets where I can play around with ML?,https://www.reddit.com/r/MachineLearning/comments/1puxmd/are_there_publicly_available_large_datasets_where/,Should_I_say_this,1383542607,I want to apply some of my ML skills but want to get inspiration from the dataset. Are there any large datasets available I can play with? ,5,0
16,2013-11-4,2013,11,4,14,1puya9,Doing Sketch Recogntion,https://www.reddit.com/r/MachineLearning/comments/1puya9/doing_sketch_recogntion/,Radzell,1383543291,"Does anyone know a good method for doing sketch recognition?

Edit: http://cybertron.cg.tu-berlin.de/eitz/pdf/2012_siggraph_classifysketch.pdf
I think I found a good paper. I'll leave it here if anyone wants to see the process. Also if there is anything more recent I would like to see their approach.",11,0
17,2013-11-4,2013,11,4,15,1pv192,Doubt in LIBSVM classification,https://www.reddit.com/r/MachineLearning/comments/1pv192/doubt_in_libsvm_classification/,ramk2504,1383546659,"Actually i got a classification model with the following output, 

Best c=8.0, g=0.03125 CV rate=63.5071
Training...
Output model: ontsg_scaled.libsvm.model
Scaling testing data...
Testing...
Accuracy = 56.5217% (13/23) (classification)

And my png file created had little little circle , what does it means 

Actually it has formed 4 little boundaries under a big boundary region

What does it mean ",2,0
18,2013-11-4,2013,11,4,15,1pv2gh,Can existing algorithms detect all the faces in Oleg Shuplyak's art?,https://www.reddit.com/r/MachineLearning/comments/1pv2gh/can_existing_algorithms_detect_all_the_faces_in/,usrnym,1383548228,,3,20
19,2013-11-4,2013,11,4,17,1pv654,"Goodbye scripts, hello R packages!",https://www.reddit.com/r/MachineLearning/comments/1pv654/goodbye_scripts_hello_r_packages/,joelthelion,1383554336,,1,26
20,2013-11-4,2013,11,4,18,1pv89r,Which online courses cover the mathematics in detail?,https://www.reddit.com/r/MachineLearning/comments/1pv89r/which_online_courses_cover_the_mathematics_in/,jamesmcm,1383558560,"As the title says, which online courses cover the mathematics in detail?

Ng's Coursera course, for all its excellence in the practicality, does not cover much mathematics (in the way of Bayesian methods, etc. and their derivations), though Daphne Koller's course is slightly better, but aimed much more at PGM's (understandably).

The only course I know which covers a lot almost comprehensively, is MathematicalMonk's videos on YouTube: http://www.youtube.com/playlist?list=PLD0F06AA0D2E8FFBA",6,7
21,2013-11-4,2013,11,4,21,1pvczl,Good Universities for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/1pvczl/good_universities_for_machine_learning/,theNewBeginning001,1383567747,"Redditors can you help me select few good universities for my Master's in Machine Learning. I have to support myself so funding is a great obstacle which makes Ivy League colleges (Stanford etc. really tough).
I have more than 2 years of job experience as a S/W dev, a gre score of 313..A good bachelor in CS (2 years ago)... downside is no publications and little on-paper experience in ML",13,2
22,2013-11-5,2013,11,5,1,1pvszz,"Daily Paper Review, Nov 4: Maxout Networks",https://www.reddit.com/r/MachineLearning/comments/1pvszz/daily_paper_review_nov_4_maxout_networks/,Foxtr0t,1383583442,"In spike-and-slab topic Ian Goodfellow said:

&gt; If you'd like to see a different one of my papers where we did get relatively big improvements on a lot of tasks I would recommend: http://arxiv.org/abs/1302.4389

It's Maxout Networks:

&gt; We consider the problem of designing models to leverage a recently introduced approximate model averaging technique called dropout. We define a simple new model called maxout (so named because its output is the max of a set of inputs, and because it is a natural companion to dropout) designed to both facilitate optimization by dropout and improve the accuracy of dropout's fast approximate model averaging technique. We empirically verify that the model successfully accomplishes both of these tasks. We use maxout and dropout to demonstrate state of the art classification performance on four benchmark datasets: MNIST, CIFAR-10, CIFAR-100, and SVHN.

Here's an explanation of maxout (hopefully correct) and an experiment on Kaggle version of the MNIST digits, with code using Pylearn2:

http://fastml.com/maxing-out-the-digits/

",36,21
23,2013-11-5,2013,11,5,2,1pvvkn,"How valuable do you think feature selection is in machine learning? Which do you think improves accuracy more, feature selection or feature engineering?",https://www.reddit.com/r/MachineLearning/comments/1pvvkn/how_valuable_do_you_think_feature_selection_is_in/,mrlovell,1383585345,"How valuable is perhaps an analysis like this (see link)  when dealing with a regression or a classification problem?
http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html#example-ensemble-plot-forest-importances-py
 
 Would it be better to engineer features in your opinion?",3,7
24,2013-11-5,2013,11,5,3,1pw3z8,Rule induction off of labeled dataset - Health Insurance claims,https://www.reddit.com/r/MachineLearning/comments/1pw3z8/rule_induction_off_of_labeled_dataset_health/,ptpatil,1383591302,"I am trying to see if I can give users of a Insurance claim submission software for medical practices probability based warnings of things called CAS Codes before they submit a particular claim.

CAS Codes are standardized claim codes used by U.S. health insurance companies to specify reasons for rejecting or sending claims back for corrections. I have a database of hundreds of thousands of claims with multiple nominal attributes labeled with single or multiple applicable CAS Codes returned by the Insurance companies as a target classification variable.

I consider it as a multilabel classification problem, however an additional constraint of the desired software solution is to specify WHICH INPUT ATTRIBUTE of the claim is most responsible for the given CAS Code warning, i.e. (""95% probability of CAS Code 'Y', due to Attribute Field 'X1=x1','X2=x2' &amp; 'X3=x3'""). So that the user can narrow down what he/she has to do in order to change the ""predicted class"" to ""None"" or ""No CAS Code"".

I believe this requirement forces me to use non-blackbox methods of approximating the ground truth decision function implicit in the data. Doing some of my own research I believe the CN2 rule algorithm is pretty good, but I am more familiar with Machine Learning libraries rather than Business Rule engines which this seems to be.

If anyone can offer insight into this problem and possible first routes to explore I (and our 1000+ doctors!) would appreciate it very much.",3,0
25,2013-11-5,2013,11,5,4,1pw6cp,Anyone know of a community for game engines for Trading card games?,https://www.reddit.com/r/MachineLearning/comments/1pw6cp/anyone_know_of_a_community_for_game_engines_for/,bflizzle,1383592958,"So, I'm trying to get into writing programs that learn stuff. I feel like a trading card game could be an interesting problem to try to analyze. I was wondering if anyone knew of any communities/irc channels or subreddits where people collaborate or talk about this. 

If no, would anyone be interested in chatting with me about this? Discuss things like what a good approach would be to modeling a problem like a card game. I don't really play card games but I have a general understanding and would like the idea of this problem.",7,0
26,2013-11-5,2013,11,5,12,1pxabm,Understanding multi-armed bandit algorithms,https://www.reddit.com/r/MachineLearning/comments/1pxabm/understanding_multiarmed_bandit_algorithms/,[deleted],1383620808,,0,1
27,2013-11-5,2013,11,5,12,1pxaee,Understanding multi-armed bandit algorithms,https://www.reddit.com/r/MachineLearning/comments/1pxaee/understanding_multiarmed_bandit_algorithms/,DarkXanthos,1383620860,,3,22
28,2013-11-5,2013,11,5,13,1pxgvd,Petition: Paper Review Schedule,https://www.reddit.com/r/MachineLearning/comments/1pxgvd/petition_paper_review_schedule/,Badoosker,1383625937,"With all the recent motions of reviewing papers, it would be nice to have themed weeks (maybe too complicated for now) and a list of papers to review for the week.

We could possibly do something like the AMA reddit and be inspired from their setup.

What does everyone think?",16,20
29,2013-11-5,2013,11,5,20,1py01h,Several Local Minima in Training set in libsvm,https://www.reddit.com/r/MachineLearning/comments/1py01h/several_local_minima_in_training_set_in_libsvm/,ramk2504,1383651607,"While training a sample data i obtained several local minima, inferred from the contour plot generated . is it good to have several local minima or not?

total classification is between three dataset .",4,0
30,2013-11-6,2013,11,6,2,1pynpo,"[WEKA] Random Forest model building times are much much less that Decision Table on 30k x 30k, sparse data set. Guesses as to why?",https://www.reddit.com/r/MachineLearning/comments/1pynpo/weka_random_forest_model_building_times_are_much/,jwgibbo,1383673395,"The data is approximately 30k attributes by 30k instances. The data is sparse numeric data with multiple classes (6 total).  I was expecting random forest to take much longer than decision table to run since random forest is just a collection of decision trees.  Current experiment have decision table taking as much as 10 times longer to build a model.

Anyone have any theories as to why?",2,3
31,2013-11-6,2013,11,6,3,1pyrta, Those versed in machine learning looking to make some extra money or love to teach should check out the new Google Helpouts!!!,https://www.reddit.com/r/MachineLearning/comments/1pyrta/those_versed_in_machine_learning_looking_to_make/,mrlovell,1383676166,,0,0
32,2013-11-6,2013,11,6,3,1pytlj,Computer I was given for a ML/Programming internship. I didnt know that much RAM was possible in a laptop.,https://www.reddit.com/r/MachineLearning/comments/1pytlj/computer_i_was_given_for_a_mlprogramming/,WuTangClanftKubrick,1383677309,,0,1
33,2013-11-6,2013,11,6,7,1pzd9n,I do artifical life simulations. This is a predator-prey relationship evolving in real time. Rewind to the beginning for more intro on what all the graphs mean.,https://www.reddit.com/r/MachineLearning/comments/1pzd9n/i_do_artifical_life_simulations_this_is_a/,dickingaround,1383690605,,23,114
34,2013-11-6,2013,11,6,12,1q00zx,Machine Learning datsets,https://www.reddit.com/r/MachineLearning/comments/1q00zx/machine_learning_datsets/,liquid11,1383707374,"Hi there I am an ANN student looking for datasets in the fashion/sports/business domains for which neural networks have not been applied. I want to train a multilayer perceptron classifier with them.

Thanks.",3,0
35,2013-11-6,2013,11,6,13,1q0899,Any good papers (that you think) regarding handwritten number recognition?,https://www.reddit.com/r/MachineLearning/comments/1q0899/any_good_papers_that_you_think_regarding/,chaoism,1383712976,"Hi guys, I'm new here and am working on a project for handwritten number (digit) recognition. I haven't decided what method I should approach and would love to get some ideas from you guys. Need some developed studies/ideas to create sparks. I hope I'm not breaking any posting rule here. 

Thanks a lot!",4,0
36,2013-11-6,2013,11,6,15,1q0een,machine to machine,https://www.reddit.com/r/MachineLearning/comments/1q0een/machine_to_machine/,harrywills753,1383719014,"M2M Logic is providing m to m with latest technologies such as GPS, Odometer and many advanced technologies. 
",0,0
37,2013-11-6,2013,11,6,19,1q0o7v,Tramsportable Homemade Electric Table Saw,https://www.reddit.com/r/MachineLearning/comments/1q0o7v/tramsportable_homemade_electric_table_saw/,[deleted],1383734255,,0,0
38,2013-11-6,2013,11,6,23,1q0xha,Paper Review Submission/Vote Thread,https://www.reddit.com/r/MachineLearning/comments/1q0xha/paper_review_submissionvote_thread/,dhammack,1383747314,"Submit your paper review requests here, we can vote on them, and we'll pop off the top ones for review over the next week (or more?) such that they're sufficiently spaced out.

How about as a format, submit the title, author and abstract of the paper. Other comments (like ""this was given [award] at [conference]"") are cool as well.",9,5
39,2013-11-7,2013,11,7,2,1q1ahu,What are the best steps/strategies to perform cross-validation on time series data?,https://www.reddit.com/r/MachineLearning/comments/1q1ahu/what_are_the_best_stepsstrategies_to_perform/,mrlovell,1383757554,,12,12
40,2013-11-7,2013,11,7,8,1q26da,"""Compete to Compute"" - New NN architecture from Jrgen Schmidhuber's group (pdf)",https://www.reddit.com/r/MachineLearning/comments/1q26da/compete_to_compute_new_nn_architecture_from/,not_not_sure,1383779523,,12,17
41,2013-11-7,2013,11,7,9,1q2ef6,NuPIC 2013 Fall Hackathon Outcome,https://www.reddit.com/r/MachineLearning/comments/1q2ef6/nupic_2013_fall_hackathon_outcome/,numenta,1383785514,,0,0
42,2013-11-7,2013,11,7,10,1q2icc,How to build Credit Score System?,https://www.reddit.com/r/MachineLearning/comments/1q2icc/how_to_build_credit_score_system/,imsome1,1383788400,"I really want to know how to build a credit score system, what parameters/data need? how to calculate credit score from parameters/data? Please help me with simple examples or models. Thanks",7,6
43,2013-11-7,2013,11,7,11,1q2md5,A question about the AI winter.,https://www.reddit.com/r/MachineLearning/comments/1q2md5/a_question_about_the_ai_winter/,fan_lamp_door,1383791400,"The XOR problem put a damper on AI. But the perceptron could in fact learn XOR when arranged in the correct network. Did people know this? If not, why did they overlook this seemingly simple solution?",9,3
44,2013-11-7,2013,11,7,15,1q32w9,"Freshman interested in ML/AI, could anyone please point me towards the right road?",https://www.reddit.com/r/MachineLearning/comments/1q32w9/freshman_interested_in_mlai_could_anyone_please/,[deleted],1383805107,"Hello I'm a first year science student at UBC, and started getting interested in AI after reading (and still trying to understand) Godel Escher Bach. I found it funny how pretty much everything could possibly be 1-up'ed by AI/ML, even other branches of computer science within computer science itself. I think it is interesting how all branches of studies are becoming more and more reliant on computers, and I believe that in the future even the discovery in the natural sciences could be automated, such as drug discovery within chemistry.

Now...I want to say that I know only what I know...and I know that I know very little in computer science, AI, and math. I know that strong AI or true AI maybe impossible, but I want to think that it is. I have read The Singularity is Near which is a pop-sci book but by comparing his predictions for 2010, which he seems to be only off by a couple of years, and using his projections for 2030, he thinks to believe strong AI may be possible...I find it interesting how the model of AI started with a top down approach of giving rules for everything in math to a more networked model which resembles intelligent systems from evolution, how this is similar to Google's algorithm (on which I know close to nothing about). I have been going to my profs to ask if they can go over Godel's incompleteness theorem for me, but I'm very weak in the maths (I have only recently learned about the word ""axiom""), and they seem kind of lazy about it, maybe I'm not understanding something?? 

Which books/journals/people should I be following? Should I go to graduate school? I don't want to do a PhD because I know that becoming a professor is very unlikely to happen. At most I plan on getting a MS in AI/ML and working in the industry for hopefully google or ibm or something like that. (I know that is hard, too). I think an advantage of a BS in computer science is that if things don't work out too well, I can always fall back to working as a programmer or freelancing, which I know is also not that easy since companies prefer software engineers over people specialized in AI or ML. 

What types of general and specific points of advice could you give to someone like me? 

Is ML/computer science/AI more heavy towards math or statistics?

Thanks for your time. ",11,14
45,2013-11-7,2013,11,7,16,1q35pz,Applications of information theory in machine learning (except feature selection and decision trees),https://www.reddit.com/r/MachineLearning/comments/1q35pz/applications_of_information_theory_in_machine/,hadian,1383808451,"What are the applications of information theory (enropy, coding, etc.) in machine learning?

I know that information theory have been widely used for **feature selection** and **decision tree learning**. Would you please mention any other applications?",2,1
46,2013-11-7,2013,11,7,19,1q3d7b,Inverse clustering?,https://www.reddit.com/r/MachineLearning/comments/1q3d7b/inverse_clustering/,predef,1383820118,"I have a set of data files which have been manually partitioned into two classes (each file goes either to class A or B). How would I go about figuring out according to which metrics these two classes are established?

That is to say, if I provide for example a feature vector for each file, are there algorithms which can figure out the total ""discriminatory"" function which would put the files into exactly (or with high probability) the two pre-established classes?",6,0
47,2013-11-8,2013,11,8,2,1q40zs,All Models of Machine Learning have Flaws,https://www.reddit.com/r/MachineLearning/comments/1q40zs/all_models_of_machine_learning_have_flaws/,rrenaud,1383844106,,21,47
48,2013-11-8,2013,11,8,4,1q4c1l,Would you really release the real AI into the world if you had the information to do it?,https://www.reddit.com/r/MachineLearning/comments/1q4c1l/would_you_really_release_the_real_ai_into_the/,testmypatience,1383851477,"I feel that it would be dangerous, and that you would probably not fair well if you did produce the solution to it. Thoughts?",6,0
49,2013-11-8,2013,11,8,19,1q63w1,Online study group for reading Bishop's PRML?,https://www.reddit.com/r/MachineLearning/comments/1q63w1/online_study_group_for_reading_bishops_prml/,not_not_sure,1383906283,"I wonder if people here are interested in reading Bishop's PRML together, say, 10 pages a day or 70 pages a week or so, and discussing it, answering each other's questions, etc.? They say emotional involvement, like from debating with your peers, leads to better memorization of the material.

The book seems to be suitable for math/physics undergrads and above, I think. If you are math-challenged, PRML is probably not for you IMHO.

I personally prefer video lectures, but none that I know have the depth and breadth of PRML.

Please **reply** if you may be interested. I basically want to gauge the interest at this point. I also wonder if reddit is the best venue for this sort of thing.

**Edit:**

[**The class started!**](http://www.reddit.com/r/mlstudy/comments/1q9s9b/prml_chap_1_study_group_discussion_nov_9nov_24/) Spread the word, if you wish.",51,26
50,2013-11-8,2013,11,8,22,1q69nx,Hands on Intro to Gibbs sampling for Bayesian Networks,https://www.reddit.com/r/MachineLearning/comments/1q69nx/hands_on_intro_to_gibbs_sampling_for_bayesian/,nipun_batra,1383915683,,4,6
51,2013-11-8,2013,11,8,22,1q6anx,PSA: /r/mlresearch exists and might be a better place for paper reviews,https://www.reddit.com/r/MachineLearning/comments/1q6anx/psa_rmlresearch_exists_and_might_be_a_better/,BeatLeJuce,1383916952,"Hi there!

I appreciate all the new enthusiasm about reading groups and doing paper reviews. It's nice to see the subreddit come alive like this.  I just want to point out a (now defunct) subreddit for ML paper reviews that already exists: /r/mlresearch

/r/mlresearch used to be a nice place for reading about/discussing interesting papers, and attracted quite knowledgeable folk, but it's been pretty much dead since two years, now. Given that /r/machinelearning is relatively low-volume, it might not be worth it to use a separate subreddit for paper-reviews. On the other hand, the paper-reviews have pretty much dominated this subreddit for a while, which might scare of newcomers/people trying out ML for the first time. Thus, maybe we can revive /r/mlresearch for things more pertaining to the research-side of ML.... just throwing it out there.",5,0
52,2013-11-8,2013,11,8,23,1q6e2i,Cassandra + Hadoop = Knewton's KassandraMRHelper,https://www.reddit.com/r/MachineLearning/comments/1q6e2i/cassandra_hadoop_knewtons_kassandramrhelper/,chris_knerd,1383920771,,0,0
53,2013-11-9,2013,11,9,0,1q6j8z,Daily Paper Review: Vanishing Component Analysis,https://www.reddit.com/r/MachineLearning/comments/1q6j8z/daily_paper_review_vanishing_component_analysis/,Badoosker,1383925187,"Apologies, forgot link: http://jmlr.org/proceedings/papers/v28/livni13.pdf

Title: Vanishing Component Analysis


Abstract


The vanishing ideal of a set of points, S 
Rn , is the set of all polynomials that attain
the value of zero on all the points in S. Such
ideals can be compactly represented using a
small set of polynomials known as generators
of the ideal. Here we describe and analyze
an efficient procedure that constructs a set
of generators of a vanishing ideal. Our pro-
cedure is numerically stable, and can be used
to find approximately vanishing polynomials.
The resulting polynomials capture nonlinear
structure in data, and can for example be
used within supervised learning. Empirical
comparison with kernel methods show that
our method constructs more compact classi-
fiers with comparable accuracy.",56,11
54,2013-11-9,2013,11,9,4,1q73rx,Scikit-learn based Ensemble Selection,https://www.reddit.com/r/MachineLearning/comments/1q73rx/scikitlearn_based_ensemble_selection/,geneorama,1383939646,,6,18
55,2013-11-9,2013,11,9,5,1q777q,ML researchers: tell us about your work,https://www.reddit.com/r/MachineLearning/comments/1q777q/ml_researchers_tell_us_about_your_work/,DanceExMachina,1383942032,I'm interested in what working researchers in Machine Learning who visit this subreddit are currently working on - care to share?,18,26
56,2013-11-9,2013,11,9,15,1q8ero,Finding good ML papers to read,https://www.reddit.com/r/MachineLearning/comments/1q8ero/finding_good_ml_papers_to_read/,ninja1690,1383979636,"Hello fellow Machine Learning enthusiasts. I am almost done taking a graduate level course in ML. I want to get into the habit of reading more papers in the ML literature. 

I am looking for resources to find good papers to read in Machine Learning. Where to start, what to look for, what to read/not read? Please do share your thoughts and suggestions on how you go about finding good papers. Thanks. ",24,13
57,2013-11-10,2013,11,10,2,1q96go,The Big Data Brain Drain: Why Science is in Trouble,https://www.reddit.com/r/MachineLearning/comments/1q96go/the_big_data_brain_drain_why_science_is_in_trouble/,srkiboy83,1384018753,,3,33
58,2013-11-10,2013,11,10,7,1q9syq,"PRML Chap 1 Study Group discussion (Nov 9-Nov 24, 2013) : mlstudy",https://www.reddit.com/r/MachineLearning/comments/1q9syq/prml_chap_1_study_group_discussion_nov_9nov_24/,not_not_sure,1384037516,,0,13
59,2013-11-10,2013,11,10,9,1q9yrd,Approaches to image segmentation using Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/1q9yrd/approaches_to_image_segmentation_using_machine/,Bobsmit,1384042462,"I'm working on a problem where accurate segmentation of an image is the most important issue.

I have a very large reference data set (Color image, binary segmented image) and the filtering-edgefinding approach I've been using hasn't been showing the results I've been hoping for, because of nuances/exceptions in each image that are hard to plan for.

I've read that there could be promise in using a 3-layer perceptron network or a hopfield network to solve problems like this, but I haven't been able to make fanangle anything into working very well using MATLAB's NN toolbox. 

Any good reading you'd recommend on the topic? Is it even a worthwhile approach?",5,2
60,2013-11-10,2013,11,10,23,1qb1jz,Graduate Study in Statistics or Computer Science,https://www.reddit.com/r/MachineLearning/comments/1qb1jz/graduate_study_in_statistics_or_computer_science/,webbed_feets,1384093089,"I'm really interested in Machine Learning, and I want to study it at the graduate level. When I look at the websites of Statistics programs, I see that people research Data Mining, Machine Learning, and computer science-y statistics in both the Statistics departments and Computer Science departments.

So I'm curious, for someone with my interests, is it better to apply to Computer Science graduate programs or Statistics graduate programs? I have the correct coursework for both.

What will I miss out by focusing on one area of the other?
",19,18
61,2013-11-11,2013,11,11,4,1qbnp2,"Gridsearch, how to determine the range of C and Gamma? Are there good rules of thumb?",https://www.reddit.com/r/MachineLearning/comments/1qbnp2/gridsearch_how_to_determine_the_range_of_c_and/,Should_I_say_this,1384112694,"Hi,

I'm trying to find the best values for C and Gamma and I know that it will depend on my data set, but I was wondering if there is a range that would be considered realistic for most data sets. Alternatively is there a rule of thumb?

I have my own data set and came across a [scikit page](http://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html) which tested C values from the range of -0.01 to 10^8 and Gamma values from 0.00001 to 10^3. 

That C range seemed extraordinary to me. On my own data set I tested a linear kernel from C=0.001 to C=1000 on a logarithmic scale and found everything from C=0.02 to C=1000 having more or less the same predictive power (give or take 1 or 2%).

I'm just learning, (which is why I tested the Linear Kernel), but now I want to find the best values for an RBF Kernel. (I only just realized that an RBF with proper C and Gamma values performs at least as good as a Linear kernel).

Anyways, before I plug my computer to use such a large range of C Values and such a large range of Gamma values, I'm wondering if there is a way to determine what might be a better range (and thus waste less time training since I expect this to take hours to train)...

Another question I had was if the appropriate method is to test C Values first, then followed by Gamma values, or if they needed to be tested simultaneously to find the best C &amp; Gamma fit. 

Hope this is the right place to ask this! Thanks!",2,3
62,2013-11-11,2013,11,11,5,1qbrla,New ML Mods,https://www.reddit.com/r/MachineLearning/comments/1qbrla/new_ml_mods/,cavedave,1384115531,"We have not been doing much modding lately. Which means I think we could do with some more mods. 

1. Who do you think would be good at it? Nominations welcome.

2. While I am talking to you some of the comments in r/MachineLearning are a bit harsh. Where do we want to set the line for getting a comment deleted? Cursing, calling someone names, brandishing weapons?

3. While on the ever exciting topic of modding lines. Where do we stand on spam. Are people finding the self posts too spammy? Or the posts to peoples own sites? This is a community choice and i prefer downvoting to deleting but the mods should take into account the general view.

4. Any thing else you think the mods should know about?",5,6
63,2013-11-11,2013,11,11,7,1qc04o,Daily Paper Review: A Machine Learning Framework for Programming by Example,https://www.reddit.com/r/MachineLearning/comments/1qc04o/daily_paper_review_a_machine_learning_framework/,Badoosker,1384121678,"Link: [ A Machine Learning Framework for Programming by Example](http://jmlr.org/proceedings/papers/v28/menon13.pdf)



Abstract:


Learning programs is a timely and interest-
ing challenge. In Programming by Example
(PBE), a system attempts to infer a program
from input and output examples alone, by
searching for a composition of some set of
base functions. We show how machine learn-
ing can be used to speed up this seemingly
hopeless search problem, by learning weights
that relate textual features describing the
provided input-output examples to plausible
sub-components of a program. This generic
learning framework lets us address problems
beyond the scope of earlier PBE systems.
Experiments on a prototype implementation
show that learning improves search and rank-
ing on a variety of text processing tasks found
on help forums.


",4,17
64,2013-11-11,2013,11,11,8,1qc5k0,What is the total value of the data science (not big data) market?,https://www.reddit.com/r/MachineLearning/comments/1qc5k0/what_is_the_total_value_of_the_data_science_not/,eastofwestla,1384125687,"I am doing a research project for school, and need to figure out the size of the data science market.  How many data scientists are there in the US and globally?  What do you think is the total value of the the market?  I'd like to exclude the big data industry ($50B) because it's too broad.  Any ideas on how to go about this?  Thanks.",0,0
65,2013-11-11,2013,11,11,11,1qcig5,Adversarial Bandits and the Exp3 Algorithm,https://www.reddit.com/r/MachineLearning/comments/1qcig5/adversarial_bandits_and_the_exp3_algorithm/,rrenaud,1384135743,,6,24
66,2013-11-11,2013,11,11,11,1qciuq,Why is machine learning experiencing such explosive growth today?,https://www.reddit.com/r/MachineLearning/comments/1qciuq/why_is_machine_learning_experiencing_such/,rrenaud,1384136044,,10,2
67,2013-11-11,2013,11,11,14,1qcvbx,AIWorld6: The war of white vs. teal (1min long),https://www.reddit.com/r/MachineLearning/comments/1qcvbx/aiworld6_the_war_of_white_vs_teal_1min_long/,dickingaround,1384146147,,3,7
68,2013-11-12,2013,11,12,1,1qdu8i,CLA Quiz Office Hour,https://www.reddit.com/r/MachineLearning/comments/1qdu8i/cla_quiz_office_hour/,numenta,1384187551,,9,0
69,2013-11-12,2013,11,12,3,1qe4rz,Sparse Filtering (2011) -- fast unsupervised learning algorithm that requires little tuning to get great results [pdf],https://www.reddit.com/r/MachineLearning/comments/1qe4rz/sparse_filtering_2011_fast_unsupervised_learning/,not_not_sure,1384194797,,38,15
70,2013-11-12,2013,11,12,3,1qe4vj,"A Tutorial Survey of Architectures, Algorithms, and Applications for Deep Learning [pdf]",https://www.reddit.com/r/MachineLearning/comments/1qe4vj/a_tutorial_survey_of_architectures_algorithms_and/,b0b0b0b,1384194857,,0,29
71,2013-11-12,2013,11,12,5,1qef6a,Looking to volunteer at a lab- undergrad in search of advice,https://www.reddit.com/r/MachineLearning/comments/1qef6a/looking_to_volunteer_at_a_lab_undergrad_in_search/,terrappin,1384201432,"I'm a first year undergrad studying CS and math. I've been thinking of volunteering at a Professor's lab (he works on machine learning applications for social sciences and bioinformatics), but I'm not quite sure how to proceed or if I should. I have covered math upto Calc IV, and linear algebra. I have an elementary understanding of probability and statistics. I know some python and java, along with some data structures and algorithms (I've been using Rob Sedgewick's book). I've thought of spending my winter break continuing to learn about ML, especially more stats and probability along with learning how to use scikit learn (and numpy, pandas, etc.), and then asking the professor if I could volunteer in his lab next semester. Am I reaching too far, or is it possible that I could do something with my lack of skills/background?",11,3
72,2013-11-12,2013,11,12,15,1qfv8w,"""Probabilistic Topic Models"" (Blei 2012) - surveying a suite of algorithms that offer a solution to managing large document archives",https://www.reddit.com/r/MachineLearning/comments/1qfv8w/probabilistic_topic_models_blei_2012_surveying_a/,[deleted],1384238635,,0,0
73,2013-11-12,2013,11,12,19,1qg4a9,Type of analysis to do when labels are incorrect?,https://www.reddit.com/r/MachineLearning/comments/1qg4a9/type_of_analysis_to_do_when_labels_are_incorrect/,[deleted],1384251448,"I have a classification task of chemical samples and their country of origin, but it turns out that these chemicals (which are of illicit nature) are manufactured in one place and widely distributed - so the country in which the samples were seized might not be the country in which they were manufactured. Consequently my highest classification accuracy is somewhere in the 60s because the labels themselves convey little information about the data generating distribution. 
 
Any suggestions regarding a more descriptive, unsupervised approach is very welcomed (ideas or paper references). I was thinking about doing some kind of non-linear clustering (the data is all over the place), maybe a probabilistic/soft clustering type approach that would afford me a notion of confidence in the cluster assignments, and then re-labeling the samples according to these clusters. Off the top of my head, the regions of highest probability density would correspond to whatever is dictating the data variance (true country of origin, chemical synthesis method, or something along those lines), which domain experts could then verify on their own. But truthfully I'm a little unfamiliar with this stuff, so any advice would be great! 
 
Thanks!",18,5
74,2013-11-12,2013,11,12,23,1qggyx,Worlds largest disease database containing 1.7 billion experimental results will use artificial intelligence to find new cancer treatments (x-post from science),https://www.reddit.com/r/MachineLearning/comments/1qggyx/worlds_largest_disease_database_containing_17/,_trendspotter,1384267471,,8,40
75,2013-11-13,2013,11,13,7,1qhkqj,"(Best Available Classification Methods?) I already using random forests, gradient boosted trees and support vector machines!",https://www.reddit.com/r/MachineLearning/comments/1qhkqj/best_available_classification_methods_i_already/,dimon_zelonoy,1384294041,"I though a interesting question related to my work would be a good first submission. Here a few more details regarding my problem (its not a problem per say, I am trying to find more efficient ways I haven't used yet). 

What are the best available classification methods out there?  I'm aware of random forests, gradient boosted trees and support vector machines, but is there anything better (or newer) than those?  I need to do binary classification with something like 10 million rows and 100 columns of all numerical data.  Also, what packages should I use?  I would need really fast training time.

Any advice or suggestions would be appreciated. ",12,0
76,2013-11-13,2013,11,13,8,1qhrqi,Music Information Retrieval subreddit now up!,https://www.reddit.com/r/MachineLearning/comments/1qhrqi/music_information_retrieval_subreddit_now_up/,Metabog,1384298509,"Hello to all.

http://www.reddit.com/r/musicir/

I am a researcher working in music information retrieval and I've found that there is no subreddit for this large and rapidly evolving field. If you're interested, hop over to this (currently empty) subreddit and introduce yourself!

""Music information retrieval (MIR) is the interdisciplinary science of retrieving information from music. MIR is a small but growing field of research with many real-world applications. Those involved in MIR may have a background in musicology, psychology, academic music study, signal processing, machine learning or some combination of these."" - Wikipedia

[Wikipedia Article on MIR](http://en.wikipedia.org/wiki/Music_information_retrieval)

Cheers.",1,10
77,2013-11-13,2013,11,13,9,1qhzfs,Applications of machine learning in economics?,https://www.reddit.com/r/MachineLearning/comments/1qhzfs/applications_of_machine_learning_in_economics/,bernard-of-oran,1384303673,"What applications of machine learning are there for economics/econometrics? If someone could point me towards researchers, papers, or articles that are related to machine learning and economics/econometrics, that would be really helpful.",4,0
78,2013-11-13,2013,11,13,19,1qj1a3,Classical Probabilistic Models and Conditional Random Fields [pdf],https://www.reddit.com/r/MachineLearning/comments/1qj1a3/classical_probabilistic_models_and_conditional/,petrux,1384339527,,1,17
79,2013-11-13,2013,11,13,20,1qj2f4,Looking for crosswords dataset,https://www.reddit.com/r/MachineLearning/comments/1qj2f4/looking_for_crosswords_dataset/,Naurgul,1384341502,"Hello all, 

I'm writing a [crossword generator](https://github.com/NikolasTzimoulis/CrosswordGenerator) and the generated crosswords are not looking very natural compared to real ones. I am considering using machine learning to learn how to select the position each new word should be put on the grid. 

I have two issues: 

1.  I can't think of a generic machine learning technique that could be used. This is quite all right though, I think I can get away with using a novel stochastic model to describe the process and fit the data to it with a genetic algorithm (or some other metaheuristic technique). 

2. I can't seem to find a dataset to work with. The only datasets I have found on the Internet are ones with lists of words. For my needs, I require a dataset showing the start and end positions of words on the grid, I don't even really need it to contain the words themselves. Does anyone know if such a dataset exist and if so how one would go about getting their hands on it?

Thanks you in advance!",6,0
80,2013-11-14,2013,11,14,1,1qjj67,Is value iteration considered reinforcement learning?,https://www.reddit.com/r/MachineLearning/comments/1qjj67/is_value_iteration_considered_reinforcement/,xeightx,1384358835,I'm a bit confused...is it reinforcement learning or something to help reinforcement learning methods like monte carlo/temporal difference?,2,1
81,2013-11-14,2013,11,14,1,1qjjmc,"Why are deep networks difficult to train, really?",https://www.reddit.com/r/MachineLearning/comments/1qjjmc/why_are_deep_networks_difficult_to_train_really/,Coffee2theorems,1384359169,"As I understand it, deep learning is basically about neural networks with multiple hidden layers. A long time (decades) ago, such networks were not used because they were hard to train, in contrast to shallow networks. Then people discovered pretraining (autoencoders and such), and got over that roadblock: the ""good initialization"" + ""gradient descent fine-tuning"" approach worked.

It is often said that the real reason for the difficulties was not the initialization (or many bad local minima), but the use of first-order methods (""pathological curvature"" causes problems). This is solved by using curvature information in e.g. so-called Hessian-free methods (which, amusingly, do use the Hessian).

That does not make sense. Surely someone took L-BFGS or a Conjugate Gradient method and applied it to deep networks back in the bad old days? Wouldn't such methods have removed problems with the ""pathological curvature"", and people would have noticed? Why did it take decades for the discovery to happen? Or do these methods not work, after all? Is there some special sauce in Hessian-free methods that makes them work where L-BFGS or CG doesn't? If I try L-BFGS or CG with deep networks, will I actually get any problems other than costlier function evaluations compared to HF methods?",13,35
82,2013-11-14,2013,11,14,3,1qjvx8,Java/Weka Training Set/Test Set Error,https://www.reddit.com/r/MachineLearning/comments/1qjvx8/javaweka_training_settest_set_error/,piptook,1384367552,"I am using Java Weka library to train a set of data and test it against another. Here is my Java code:

	import java.io.BufferedReader;
	import java.io.FileReader;
	
	import weka.classifiers.meta.FilteredClassifier;
	import weka.classifiers.trees.J48;
	import weka.core.Instances;
	import weka.filters.unsupervised.attribute.Remove;
	
	
	
	public class WekaStocks {
	
		public static void main(String[] args) throws Exception {
			// Instantiate Training Data
			Instances training_data = new Instances(
					new BufferedReader(
							new FileReader(
									""res/training_data.arff"")));
			training_data.setClassIndex(
					training_data.numAttributes() - 1);
			
			// Instantiate Testing Data
			Instances testing_data = new Instances(
					new BufferedReader(
							new FileReader(
									""res/test_data.arff"")));
			testing_data.setClassIndex(
					testing_data.numAttributes() - 1);
			
			// Print Initial Data Summary
			String summary = training_data.toSummaryString();
			int number_samples = training_data.numInstances();
			int number_attributes_per_sample= training_data.numAttributes();
			System.out.println(
					""Number of attributes in model = "" +
					number_attributes_per_sample);
			System.out.println(
					""Number of samples = "" + number_samples);
			System.out.println(""Summary: "" + summary);
			System.out.println();
			
			// a classifier for decision trees:
			J48 j48 = new J48();
			
			// filter for removing samples:
			Remove rm = new Remove();
			// remove first attribute
			rm.setAttributeIndices(""l"");
			
			// filtered classifier
			FilteredClassifier fc = new FilteredClassifier();
			fc.setFilter(rm);
			fc.setClassifier(j48);
			
			// train using training data
			fc.buildClassifier(training_data);
			
			// test using test data
			for (int i = 0; i &lt; testing_data.numInstances(); i++) {
				double pred = fc.classifyInstance(testing_data.instance(i));
				System.out.print(""given value: "" + 
				testing_data.classAttribute().value((int)testing_data.instance(i).classValue()));
				
				System.out.println("". predicted value: "" + testing_data.classAttribute().value((int)pred));
				
			}
	
		}
	
	}


And here are my two data files:

training_data.arff:

    @relation stock

	@attribute percent_change_since_open real
	@attribute percent_change_from_day_low real
	@attribute percent_change_from_day_high real
	@attribute action {buy, sell, hold}

	@data
	-0.3,0.2,-0.22,hold
	-2.2,0.0,-2.5,sell
	0.2,0.22,-0.01,buy
	-0.25,0.12,-0.25,hold
	-2.0,0.0,-2.1,sell
	0.26,0.26,-0.4,buy
	-0.12,0.18,-0.14,hold
	-2.6,0.12,-2.6,sell
	0.24,0.3,-0.035,buy

test_data.arff:

    @relation stock

	@attribute percent_change_since_open real
	@attribute percent_change_from_day_low real
	@attribute percent_change_from_day_high real
	@attribute action {buy, sell, hold}

	@data
	-0.2,0.1,-0.22,hold
	-2.2,0.0,-2.5,sell
	0.2,0.21,-0.01,buy
	-0.22,0.12,-0.25,hold
	-2.0,0.0,-2.1,sell
	0.28,0.26,-0.4,buy
	-0.12,0.08,-0.14,hold
	-2.6,0.1,-2.6,sell
	0.24,0.25,-0.03,buy

I'm getting an error in Eclipse at runtime that says:

    Exception in thread ""main"" java.lang.IllegalArgumentException: Invalid range list at l

	at weka.core.Range.setFlags(Range.java:316)

	at weka.core.Range.setUpper(Range.java:88)

	at weka.filters.unsupervised.attribute.Remove.setInputFormat(Remove.java:202)

	at weka.classifiers.meta.FilteredClassifier.buildClassifier(FilteredClassifier.java:389)

	at WekaStocks.main(WekaStocks.java:56)


I think there is an issue with the training_data.arff file because the error occurs on the first time the program manipulates that data. This is line 56:

		// train using training data
		fc.buildClassifier(training_data);

Can anyone shed light on what is going wrong here?
",2,0
83,2013-11-14,2013,11,14,3,1qjwaj,Convolutional neural nets for detection on PASCAL VOC (crosspost from /r/mlresearch),https://www.reddit.com/r/MachineLearning/comments/1qjwaj/convolutional_neural_nets_for_detection_on_pascal/,gdahl,1384367805,,3,8
84,2013-11-14,2013,11,14,4,1qjzi5,Deep Learning and Its Role in Computer Vision [videos/slides] BAVM 2013,https://www.reddit.com/r/MachineLearning/comments/1qjzi5/deep_learning_and_its_role_in_computer_vision/,[deleted],1384369982,,0,2
85,2013-11-14,2013,11,14,4,1qk1hn,Book / resource recommendations for machine learning / artificial intelligence?,https://www.reddit.com/r/MachineLearning/comments/1qk1hn/book_resource_recommendations_for_machine/,[deleted],1384371354,"Hi guys,

I'm a software developer. I'm interested in learning about artificial intelligence and machine learning, particularly optical character recognition. Are there any good books or resources that you'd recommend?

My maths background needs a lot of dusting up on, so i'd appreciate anything that teaches the maths as well (if / where its needed).

Thanks.",3,1
86,2013-11-14,2013,11,14,10,1qkwz4,Is Machine Learning just maths?,https://www.reddit.com/r/MachineLearning/comments/1qkwz4/is_machine_learning_just_maths/,[deleted],1384391864,"I'm a software developer, and I'm looking into machine learning.

When I first looked into it, it seemed very interesting and fun. E.g, having a dataset, like the size of houses and their prices, and then predicting the price of a house based on its size. I thought of lots of cool ways that a program could be written to predict this. For example, loop over the dataset, get the 'gap' between the prices (e.g if a 1 square meter house sells for 100k, and a 2 sq meter house sells for 120k, then the gap is 20k), and then get the average gap in price per square meter. And use that to calculate / predict the price of any given house, based on the house sizes closest to it. (E.g if on average the price increases by 10k per sq meter, and the price of a 10 sq meter house is 100k, and you're asked to predict an 11 sq meter house's price, you would say 100k+10 = 110k).

But instead, the solution given for solving this problem in the ML course I'm taking, just seems to involve memorizing a formula, punching that formula into octave, and letting it figure out the result. I'm seeing very little actual programming being done.

Is that all machine learning is? Just memorizing formulas and applying them to different datasets / attributes? Or is there any of the problem solving involved which makes regular programming fun?

Thanks.",23,0
87,2013-11-14,2013,11,14,12,1ql7w9,Deep Learning 101,https://www.reddit.com/r/MachineLearning/comments/1ql7w9/deep_learning_101/,holy_ona_sandwich,1384399588,,9,53
88,2013-11-14,2013,11,14,15,1qlkpq,Announcing Deedle - Data Frame and Time Series Package for Exploratory Data Programming with F# and C# inspired by Pandas,https://www.reddit.com/r/MachineLearning/comments/1qlkpq/announcing_deedle_data_frame_and_time_series/,NOT_BRIAN_POSEHN,1384410414,,0,8
89,2013-11-14,2013,11,14,16,1qlmzs,All the required processing equipments,https://www.reddit.com/r/MachineLearning/comments/1qlmzs/all_the_required_processing_equipments/,rendeq1111,1384413013,,0,1
90,2013-11-14,2013,11,14,16,1qlnfe,Career Advice?,https://www.reddit.com/r/MachineLearning/comments/1qlnfe/career_advice/,[deleted],1384413539,"Hello all,

I'm currently a mathematics phd student at a big state school, and I am considering leaving my graduate program with a master's degree (in May. I do not have any publications, and my only work experience of note has been as an instructor for various math courses).  I started off with an interest in pure mathematics, but for the last year or so I have been working on inverse problems in imaging, specifically, stuff related to wavelet frames &amp; total variation regularization, l_1 methods. An 'inverse problem' in this context is more or less something like ""I'd like a nice looking picture, but all I've got is this blurry + noisy thing, can you fix it up for me?"", but it can also include things like inpainting or to a certain extent, segmentation. One typical way of doing this is to use some variational model -- your restored image minimizes an energy -- and then solve it by some reasonably clever optimization algorithm. So I've got some background in numerical optimization &amp; convex analysis, and this has been my first point of contact with machine learning. My second point of contact is from watching most of the lectures and doing most of the homeworks over at [Learning from Data](http://work.caltech.edu/telecourse)

My interest in machine learning, broadly speaking, stems from two curiosities. The first is that I'd like to better understand how to model the world (or at least parts of it). In image restoration, for example, the 'space of natural images' is so huge and wildly incomprehensible that the classic 'geometric' approach of many models seems to be falling way short of what's possible. The second curiosity is that I'd like to better understand how decisions can be made in the face of uncertainty, incomplete data, etc. My interest in machine learning, more narrowly speaking, is that I'd like to work on **real** problems and get $$$.

So with that introduction, I'd like to solicit your advice :)

Specifically, what are some important things I should be aware of when trying to land an entry level job? What 'technologies' should I spend some time with? How can I market myself, given my background?  Or really, if you have any other advice, I'd love to hear it.",1,0
91,2013-11-14,2013,11,14,23,1qm6me,"My company just announced a $5.3M investment. We use Java, machine learning, and game theory to predict what will interest people. We're based in Austin, TX and we're hiring!",https://www.reddit.com/r/MachineLearning/comments/1qm6me/my_company_just_announced_a_53m_investment_we_use/,sanity,1384440324,"Here is the [press release](http://www.onespot.com/press-releases/onespot-secures-5-3-million-series-a-financing-round-led-by-mohr-davidow-ventures/).

[Here is a full job description and a form where you can apply](http://onespot.theresumator.com/apply/JmfcMw/Senior-Java-Software-Developer.html?source=reddti1).

Feel free to pm me also if you have any private questions, or ask below.",11,14
92,2013-11-15,2013,11,15,0,1qmbay,Detecting a Hacked Tweet with Machine Learning,https://www.reddit.com/r/MachineLearning/comments/1qmbay/detecting_a_hacked_tweet_with_machine_learning/,primaryobjects,1384444097,,2,0
93,2013-11-15,2013,11,15,3,1qmpws,Skytree Extends Machine Learning to Any Hadoop Big Data Environment!!!,https://www.reddit.com/r/MachineLearning/comments/1qmpws/skytree_extends_machine_learning_to_any_hadoop/,Mrr_Cow,1384454015,"Here is the link to the original article: http://www.marketwired.com/press-release/skytree-extends-machine-learning-to-any-hadoop-big-data-environment-1843923.htm

Our site www.Skytree.net has a lot of great info or you can PM me with any questions. I will do my best to answer any questions and we are hiring.

Please reach out if you have an ML focused PhD, here a link to our Machine Learning R&amp;D role. http://talentdesk.com/job/21000/skytree-inc/machine-learning-rd-developer

EDIT: Another good unbiased article from Forbes, regarding ML highlighting Skytree and some of our competition: 
http://www.forbes.com/sites/oreillymedia/2013/10/06/gaining-access-to-the-best-machine-learning-methods/

EDIT2: A bit more detail on Skytree (Trying to give you guys another 3rd party perspective) 
http://www.datanami.com/datanami/2013-10-24/skytree_hangs_machine_learning_hat_on_hadoop.html",4,0
94,2013-11-15,2013,11,15,6,1qn4oo,I wanted to repost my similarity algorithm question here because this subreddit seems to be a bit more active,https://www.reddit.com/r/MachineLearning/comments/1qn4oo/i_wanted_to_repost_my_similarity_algorithm/,cbr0wn,1384463546,,3,7
95,2013-11-15,2013,11,15,7,1qn9ya,Good algorithms for unsupervised learning on sequences of actions?,https://www.reddit.com/r/MachineLearning/comments/1qn9ya/good_algorithms_for_unsupervised_learning_on/,hmgp,1384466959,"I'm working on a sports project where we try to discover teams' strategies based on the movements of players. We have started with a couple different algorithms based on papers published in the past on sports and e-sports, but we want to expand the number of algorithms we test. Any recommendations on what works well?",17,7
96,2013-11-15,2013,11,15,8,1qnjj3,How many of you have successfully written code to identify trending keywords/topics in text? Have any good reading on the subject?,https://www.reddit.com/r/MachineLearning/comments/1qnjj3/how_many_of_you_have_successfully_written_code_to/,neelshiv,1384473436,"I'm working on a side project that identifies trending topics in tech support chat/email. Needless to say, it's quite difficult, and I am looking for additional reading or success stories on the subject.

Here are some articles that I have found pretty useful...

* http://www.cs.uccs.edu/~jkalita/work/reu/REUFinalPapers2010/Benhardus.pdf
 * Honestly, this is the most useful. The others are on more advanced topics
* http://www1.cs.columbia.edu/~hila/papers/becker35-icwsm2011.pdf
* http://www.michael-noll.com/blog/2013/01/18/implementing-real-time-trending-topics-in-storm/
",7,3
97,2013-11-15,2013,11,15,19,1qon1h,Deep Learning for time-series prediction.,https://www.reddit.com/r/MachineLearning/comments/1qon1h/deep_learning_for_timeseries_prediction/,ChuckKillerDoll,1384511656,Does anybody can advise me on the application of #deeplearning techniques for time series prediction?,9,3
98,2013-11-15,2013,11,15,21,1qor45,Machine learning branches out,https://www.reddit.com/r/MachineLearning/comments/1qor45/machine_learning_branches_out/,paul_sidoroff,1384518436,,4,14
99,2013-11-16,2013,11,16,0,1qp1aw,"""Probabilistic Models of Cognition"", book by Goodman /Tenenbaum with code in scheme-like language ""Church""",https://www.reddit.com/r/MachineLearning/comments/1qp1aw/probabilistic_models_of_cognition_book_by_goodman/,gtani,1384529245,,1,27
100,2013-11-16,2013,11,16,4,1qpnka,Captcha test cracked by US firm Vicarious,https://www.reddit.com/r/MachineLearning/comments/1qpnka/captcha_test_cracked_by_us_firm_vicarious/,rightname,1384545214,,2,0
101,2013-11-16,2013,11,16,8,1qq63u,How intelligent assistants will get more accurate in the coming years,https://www.reddit.com/r/MachineLearning/comments/1qq63u/how_intelligent_assistants_will_get_more_accurate/,lalasf111,1384558461,,0,1
102,2013-11-16,2013,11,16,20,1qr7qk,Watson in the Cloud.,https://www.reddit.com/r/MachineLearning/comments/1qr7qk/watson_in_the_cloud/,petrux,1384602355,,1,1
103,2013-11-16,2013,11,16,23,1qrdi5,X-post from r/AskStatistics: How do Bayesian nonparametric methods end up with useful models of the data?,https://www.reddit.com/r/MachineLearning/comments/1qrdi5/xpost_from_raskstatistics_how_do_bayesian/,thrownintothesun,1384611763,,0,3
104,2013-11-17,2013,11,17,0,1qrhjs,Using Cassandra to Build a Naive Bayes Classifier | OpenSource Connections,https://www.reddit.com/r/MachineLearning/comments/1qrhjs/using_cassandra_to_build_a_naive_bayes_classifier/,jnbrymn,1384616422,,4,15
105,2013-11-17,2013,11,17,2,1qrq07,Summary of Paris Machine Learning Meetup #5: Genomics and SARAH,https://www.reddit.com/r/MachineLearning/comments/1qrq07/summary_of_paris_machine_learning_meetup_5/,compsens,1384623867,,0,3
106,2013-11-17,2013,11,17,4,1qry17,Kaggle Team Members,https://www.reddit.com/r/MachineLearning/comments/1qry17/kaggle_team_members/,Should_I_say_this,1384630366,"Hi All,

I'm just doing some competitions for learning and I have found some difficulty in achieving high/acceptable scores in some competitions.

Even though I plug away at it, I am not learning if I don't get to see someone else's code to see what they did differently to me.

Therefore I'm wondering if anyone would like to add me as a team member and to share code when we join various competitions? 

I'm hoping that if we get a good team together, we will be able to all learn faster.

Thanks!

Also, I code in Python but honestly, we could just share parameters, estimator models and the process of why we ended up choosing those estimators / parameters. ",9,2
107,2013-11-17,2013,11,17,9,1qsmbw,Am I wasting my time learning mysql?,https://www.reddit.com/r/MachineLearning/comments/1qsmbw/am_i_wasting_my_time_learning_mysql/,sleepicat,1384649572,"I picked up my old mysql book to practice sql commands and maybe use it for small data analysis projects (on my Mac), but I'm wondering if I should be using a newer technology.   

Any suggestions?

Update: Thanks for the replies. Sounds like Postgres is the current standard.",19,4
108,2013-11-17,2013,11,17,16,1qt940,Object Discovery in 3D scenes via Shape Analysis (includes open source solution and new public dataset),https://www.reddit.com/r/MachineLearning/comments/1qt940/object_discovery_in_3d_scenes_via_shape_analysis/,NOT_BRIAN_POSEHN,1384671826,,1,9
109,2013-11-17,2013,11,17,17,1qtc7t,Publishing my Own Paper,https://www.reddit.com/r/MachineLearning/comments/1qtc7t/publishing_my_own_paper/,ArmenAg,1384676665,"So basically about 6 months ago I discovered the field of Machine Learning and I immediately fell in love with it. My whole summer was spent on learning and programming different algorithms (p.s. I code in C#). Once my sophomore year started in school completely all of my free time was spent on reading and formulating different ideas. About a month ago I created a new semi-supervised classification algorithm that works through clustering that worked remarkably well for a wide range of problems and it compared better that most traditional clustering algorithms such as K-Means, Kohonen, etc. I decided that i want to publish a paper. Can anyone help me with the process. For example the structure of a paper, the publishing of the paper and other stuff. Help is much appreciated! Please keep in mind that I'm only 16.",34,24
110,2013-11-17,2013,11,17,21,1qtjd3,Is there any good text summarisation library that you have used and recommend?,https://www.reddit.com/r/MachineLearning/comments/1qtjd3/is_there_any_good_text_summarisation_library_that/,Intern_MSFT,1384690473,,1,5
111,2013-11-18,2013,11,18,4,1qu86x,Introduction to Machine Learning With Student Presentations (PhD level) - Carnegie Mellon University [Playlist],https://www.reddit.com/r/MachineLearning/comments/1qu86x/introduction_to_machine_learning_with_student/,jry_AIHub,1384716104,,6,55
112,2013-11-18,2013,11,18,7,1qum7x,New PyData NYC 2013 Videos online,https://www.reddit.com/r/MachineLearning/comments/1qum7x/new_pydata_nyc_2013_videos_online/,p3n15h34d,1384726243,,7,21
113,2013-11-19,2013,11,19,0,1qwf7e,I'm working on a flexible RF implementation in Go with lots of related algorithms. Any Suggestions/Feedback?,https://www.reddit.com/r/MachineLearning/comments/1qwf7e/im_working_on_a_flexible_rf_implementation_in_go/,micro_cam,1384788975,,10,17
114,2013-11-19,2013,11,19,2,1qwpua,"Oryx - An Open Source, Real Time, Large Scale ML implementation on Hadoop. Includes RF, ALS Recommender, and Kmeans++",https://www.reddit.com/r/MachineLearning/comments/1qwpua/oryx_an_open_source_real_time_large_scale_ml/,justmike77,1384796553,,0,8
115,2013-11-19,2013,11,19,12,1qy9c8,RIP Ben Taskar - ML lost a star.,https://www.reddit.com/r/MachineLearning/comments/1qy9c8/rip_ben_taskar_ml_lost_a_star/,tyrial,1384832426,,28,51
116,2013-11-19,2013,11,19,23,1qz5iq,Validation/training set data question,https://www.reddit.com/r/MachineLearning/comments/1qz5iq/validationtraining_set_data_question/,pl47,1384869807,"Hi,

I have the following question. I have  ~100000 labeled data and a division on 70% training and 30% test data. 

Am I allowed to create n (say 50) bootstrap training and test data sets and use the mean and variance between the estimates on the 50 test test set as my estimate of the mean and the variance as an error estimate ? given that I've taken care that none of the 50 bootstrap samples was over-trained

Will the mean of the 50 be too optimistic ? 


",2,0
117,2013-11-20,2013,11,20,1,1qzfur,Why is it that I get a better accuracy score when using different datasets with a Random Forest classifier?,https://www.reddit.com/r/MachineLearning/comments/1qzfur/why_is_it_that_i_get_a_better_accuracy_score_when/,mrlovell,1384877719,"Why is it that I get better accuracy score on the test set when using a Random Forest classifier on a dataset where the target I am trying to predict is either '1' or '0' and out of the 10,000 data point training set only 20% of the time the target is '1', however, when I use a training set where the target is '1' 50% of the time I get a much lower accuracy score when running the classifier on the test set?
 
An example would be I am trying to predict if a cars value is greater than $15,000.  So with my data I assign a '1' to all cars (data points) that have a value of $15,000 and over and anything less than $15,000 a '0'.  So being that 20% of my data points (cars) in the dataset are greater than $15,000 I train on 70% of the data and test on the remaining 30%.
 
Then say I want to change up what I am trying to predict by doing a second experiment and want to predict if a car's value is greater than $10,000 instead of $15,000 and so I assign a '1' to cars greater than $10,000 and a '0' to everything else.  This time my data set turns out that about 50% of the cars are greater than $10,000 therefore 50% of the time the target is '1'.  
 
After doing the 70% train/30% test cross-validation and even 5 folds cross-validation on both cases I get a significantly better accuracy score on the 1st experiment where I am predicting for cars values greater than $15,000 than the second experiment.
 
Any idea why?",8,0
118,2013-11-20,2013,11,20,1,1qzhnn,What are some advantages of using Gaussian Process Models vs Neural Networks?,https://www.reddit.com/r/MachineLearning/comments/1qzhnn/what_are_some_advantages_of_using_gaussian/,rrenaud,1384878903,,3,8
119,2013-11-20,2013,11,20,5,1r06hg,"What is the best way to measure the variance of a cluster in unsupervised machine learning? Thanks, David",https://www.reddit.com/r/MachineLearning/comments/1r06hg/what_is_the_best_way_to_measure_the_variance_of_a/,[deleted],1384894501,That cluster would be using using a high dimension space. At least 24.,0,1
120,2013-11-20,2013,11,20,6,1r07hb,What is the best way to measure the variance of a cluster in unsupervised machine learning? Say with at least 24 features being used.,https://www.reddit.com/r/MachineLearning/comments/1r07hb/what_is_the_best_way_to_measure_the_variance_of_a/,daithibowzy,1384895113,,3,3
121,2013-11-20,2013,11,20,6,1r080c,Video lectures for Hugo Larochelle's neural networks class,https://www.reddit.com/r/MachineLearning/comments/1r080c/video_lectures_for_hugo_larochelles_neural/,lightcatcher,1384895434,,1,58
122,2013-11-20,2013,11,20,8,1r0n2d,Feature Extraction for Speech Recognition,https://www.reddit.com/r/MachineLearning/comments/1r0n2d/feature_extraction_for_speech_recognition/,BeefSmacker,1384904670,"I have been looking all over the web for a toolkit that extracts features from audio files, in order to classify speech recognition.  It is a small program for a school project, and it will be trained classifying three distinct voices and then be able to classify them based on new voice input.  Since the classification is a small set, the feature set does not have to be big, but sufficient.

I have found a ton of linux based feature extraction tools: most of which are old, outdated, and hard to derive any real data from.  I was wondering if anyone knew of an open-source windows based tool with a GUI that gives detailed feature output given an audio file.  Thanks!",5,0
123,2013-11-20,2013,11,20,15,1r1lvs,Perceptron: Please Explain,https://www.reddit.com/r/MachineLearning/comments/1r1lvs/perceptron_please_explain/,kezalb,1384930183,"Can someone explain, or link to a great explanation of, the perceptron conceptually?  I am in a theory phase in a machine learning course, so perhaps I just need to wait to dig into an implementation during the practical application phase.   At this point, I know the math and the algorithm superficially; I can plug 'n' chug to answer quiz questions about weights correctly, and I can give correct theory exam answers such as ""it is guaranteed to find the seperating hyperplane if there is one.""

But... I feel like I have no idea what is actually happening with a perceptron in action. Why does it work?  How is it working?  Help me gain some intuition, please!",8,4
124,2013-11-20,2013,11,20,21,1r1zs9,Questioning my knowledge...,https://www.reddit.com/r/MachineLearning/comments/1r1zs9/questioning_my_knowledge/,[deleted],1384950917,"I've been working on a kind of neural network for my PhD for over three years now, and approaching the end.  But even now, I sometimes see posts on here that I know nothing about... I mean I thought I knew the basic AI/ML methods, but there just seems to be so many more... and people just talk about them like they're an everyday thing.  Latest was Gaussian Process Models.  I get that US PhDs get 2 years of coursework to learn this stuff, but still it seems so limitless!

What am I doing wrong here?  I feel like I'm going to submit my PhD and get knocked back as a fool for not knowing something obvious that I should have (nobody at my university is in the exact field I'm working in, including my supervisors). 

I see linear algebra everywhere, yet my (really complex) networks don't use matrix maths... just plain old loops.  Is that the wrong way? am I missing something?  Feeling a bit despondent :(",32,17
125,2013-11-20,2013,11,20,21,1r20iq,Parameter uncertainty in probabilistic forecasting,https://www.reddit.com/r/MachineLearning/comments/1r20iq/parameter_uncertainty_in_probabilistic_forecasting/,glutamate,1384951871,,0,3
126,2013-11-21,2013,11,21,0,1r2azh,Machine Learning Tutorial: The Max Entropy Text Classifier,https://www.reddit.com/r/MachineLearning/comments/1r2azh/machine_learning_tutorial_the_max_entropy_text/,datumbox,1384961761,,0,8
127,2013-11-21,2013,11,21,5,1r2ywc,Machine learning proposal on Area 51 (StackOverflow): what's your take on it?,https://www.reddit.com/r/MachineLearning/comments/1r2ywc/machine_learning_proposal_on_area_51/,DanieleSalatti,1384977720,,1,0
128,2013-11-21,2013,11,21,7,1r3fcx,Determining best predictors / most relevant features,https://www.reddit.com/r/MachineLearning/comments/1r3fcx/determining_best_predictors_most_relevant_features/,radarsat1,1384988043,"Say I have a bunch of inputs that are somehow related to a desired output, but I don't know which ones are the most important for predicting the output I want.  Possibly no one particular input well-predicts the output (i.e. simple correlation), but some combination of inputs does indeed produce a good prediction score.  However, some features are clearly uncorrelated with the output.

What are good methods for determining which inputs are most relevant?

A ""brute force"" method I can think of would be to train some classifier on the dataset using a variety of subsets of the input.  This is a kind of trial and error approach that I see happening a lot in various applications of machine learning during the research phase.  Students will start reducing their data set and looking at how the quality of the prediction changes.

However, it seems utterly inefficient to me.  At the extreme, how do you know how many features are _really_ needed?  You'd need to explore the superset of all features, which is a combinatorial explosion.

So, I'd rather use some tools that analyse the inputs and outputs and try to score inputs (or subsets thereof) based on how useful they were in approximating the target.  One way I can imagine is to use a neural network and have a look at the weights on the first layer to see what gets weighted highly.  I'm not sure this is really a straight-forward method however.  (Side question, does ""high weight"" really imply ""high relevance"" for neural networks? This is a bit fuzzy to me.)

There are some unsupervised methods, like for example with PCA you can take a look at how much each dimension contributes to the variance in the data since they are essentially re-ordered for you according to this criteria, however this ignores any target output so I'm not sure it is a good approach.

One could also perform any unsupervised basic dimensionality reduction and see which features are most highly-correlated with the target -- this could work, perhaps, but seems a bit long-winded.

What are some other methods for automatically judging feature relevance?",6,5
129,2013-11-21,2013,11,21,8,1r3jly,Multilevel modeling in applied ML,https://www.reddit.com/r/MachineLearning/comments/1r3jly/multilevel_modeling_in_applied_ml/,110010101,1384990945,"Hi all, I am curious as to how popular is it to use multilevel/hierarchical (AKA ""mixed-effects"") modeling in practical situations. Does anyone have any experience? What did you use it for?",2,2
130,2013-11-21,2013,11,21,11,1r3zo5,An interesting infographic that helps you choose the right Machine Learning approach for your task.,https://www.reddit.com/r/MachineLearning/comments/1r3zo5/an_interesting_infographic_that_helps_you_choose/,siddhukrs,1385002161,,20,100
131,2013-11-21,2013,11,21,18,1r4p76,NIPS 2013 reading list (Alexandre Passos's ML blog),https://www.reddit.com/r/MachineLearning/comments/1r4p76/nips_2013_reading_list_alexandre_passoss_ml_blog/,urish,1385027717,,7,20
132,2013-11-21,2013,11,21,20,1r4srg,Machine Learning for Computer Security,https://www.reddit.com/r/MachineLearning/comments/1r4srg/machine_learning_for_computer_security/,galapag0,1385033423,,0,11
133,2013-11-21,2013,11,21,21,1r4v1k,Need resources related to mathematical concepts behind Machine Learning,https://www.reddit.com/r/MachineLearning/comments/1r4v1k/need_resources_related_to_mathematical_concepts/,anantzoid,1385036752,"Most introductory ML courses and books don't throw light on the math behind the concepts. Even though I had taken related courses in college, a brief brush up is required so that the mechanisms behind the algorithms are thoroughly understood.
It'd be helpful if someone could share resources pertaining to concepts in Statistics, Linear Algebra, Calculus that find their application in Machine Learning. Moreover, it'd be awesome if these concepts are explained taking the ML domain in mind. ",6,3
134,2013-11-21,2013,11,21,23,1r53hd,"Recently interested in machine learning, and I want to use it to help people.",https://www.reddit.com/r/MachineLearning/comments/1r53hd/recently_interested_in_machine_learning_and_i/,multimath,1385045640,"I don't really know anything about the state-of-the-art of machine learning, so keep that in mind while reading.



It seems like there is a lot of work that can be done in applying machine learning to medicine and biology. I want to know how close we are to being able to apply these techniques to helping people directly (i.e. through healthier/longer lives). I also see things like self-driving cars as a step in this direction.


I have a strong programming background, but only a BS in Math from a mid-tier state university.

I just want to know:

1. Are there enough people working on these problems? (I think the answer will always be ""no"", but in terms of the number of people able to contribute significantly) 

2. Are there subfields/related areas that are making more progress than others?

3. How can I get started, given my background?

4. Given my goal (helping people live longer/healthier lives) is machine learning a reasonable approach currently?


Here is what I am doing currently:

1. I've started working through Bishop's Pattern Recognition and Machine Learning, this has been slow going, but is very interesting.
2. I am currently working on different solutions to the beginner Kaggle competitions
3. I've finished Andrew Ng's Coursera course (which is what piqued my interest, but is obviously lacking in depth)",17,5
135,2013-11-22,2013,11,22,4,1r5pf3,A Resurgence of Neural Networks in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/1r5pf3/a_resurgence_of_neural_networks_in_machine/,datumbox,1385060842,,5,27
136,2013-11-22,2013,11,22,14,1r75ro,Weka prediction output questions,https://www.reddit.com/r/MachineLearning/comments/1r75ro/weka_prediction_output_questions/,ScullerLite,1385097547,"Good Evening,

As I am playing with weka and learning I have a few questions I am not quite sure on the answer.  I plug in my training and test data, run my algorithms and then I can get Weka to out put the probabilities.  It looks something like this:

    inst#,    actual, predicted, error, probability distribution
         1      1:win      1:win         *0.514      0.486
         2     2:loss     2:loss          0.464     *0.536

1. I assume, the numbers under the probability title is just the probability the classifier is correct?

2. What is ""distribution""?  It just looks like 1-probability.

3. What is the difference between confidence vs probability and how can I calculate it?

Thanks",2,1
137,2013-11-22,2013,11,22,14,1r75ve,How do you measure the accuracy score for each class when testing classifier in sklearn?,https://www.reddit.com/r/MachineLearning/comments/1r75ve/how_do_you_measure_the_accuracy_score_for_each/,mrlovell,1385097643,"Sklearn has http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html

...But this gives the mean accuracy score from ALL of the predictions for both classes when doing binary classification.  

Is there a way to get the mean estimator accuracy for each individual class in sklearn?",1,1
138,2013-11-22,2013,11,22,19,1r7l9r,How Python became the language of choice for data science,https://www.reddit.com/r/MachineLearning/comments/1r7l9r/how_python_became_the_language_of_choice_for_data/,srkiboy83,1385117566,,41,52
139,2013-11-23,2013,11,23,1,1r83v6,Deep Learning vs. AdaBoost vs. Random Forest,https://www.reddit.com/r/MachineLearning/comments/1r83v6/deep_learning_vs_adaboost_vs_random_forest/,[deleted],1385137600,,5,0
140,2013-11-23,2013,11,23,12,1r9j8f,How do feature/variable importance measures work?,https://www.reddit.com/r/MachineLearning/comments/1r9j8f/how_do_featurevariable_importance_measures_work/,SpaceWizard,1385176378,I know RF and SVM will provide measures of feature importance but can sometimes be misleading. This is potentially very useful for reporting experimental results in neuroscience. ,2,1
141,2013-11-23,2013,11,23,12,1r9jh5,"Risk-Aversion in Multi-armed Bandits: ""In many practical problems, maximizing the expected reward is not the most desirable objective... we introduce a novel setting based on the principle of risk-aversion where the objective is to compete against the arm with the best risk-return trade-off.""",https://www.reddit.com/r/MachineLearning/comments/1r9jh5/riskaversion_in_multiarmed_bandits_in_many/,NOT_BRIAN_POSEHN,1385176568,,0,12
142,2013-11-23,2013,11,23,22,1ra9v1,We ranked second on first large scale action recognition challenge@ICCV 2013,https://www.reddit.com/r/MachineLearning/comments/1ra9v1/we_ranked_second_on_first_large_scale_action/,sixmoney,1385214069,,7,9
143,2013-11-23,2013,11,23,23,1rad7c,Video Lectures of Harvard CS109 Data Science Course,https://www.reddit.com/r/MachineLearning/comments/1rad7c/video_lectures_of_harvard_cs109_data_science/,datumbox,1385218496,,8,47
144,2013-11-24,2013,11,24,2,1ramdy,Alternatives to Kaggle,https://www.reddit.com/r/MachineLearning/comments/1ramdy/alternatives_to_kaggle/,feedtheaimbot,1385227357,Just wondering if the community knows of any alternatives to Kaggle! No issues with Kaggle but curious what else is out there.,3,8
145,2013-11-24,2013,11,24,4,1rave5,Practical limit on matrix size for singular value decomposition (SVD) in R or MATLAB?,https://www.reddit.com/r/MachineLearning/comments/1rave5/practical_limit_on_matrix_size_for_singular_value/,seitanicverses,1385234550,"Hi folks,

I'm hoping people can give me a ballpark idea of the upper size limits on matrices for SVD in R or MATLAB. I am a newbie to using SVD in analyses, and I don't have a good intuition for what size input data is reasonable for this type of analysis. I have some imaging data--on the order of 100 images by 100,000 elements per image--which I would like to perform SVD or some other type of dimensionality reduction on. Is this reasonable to run on a decent newish Linux or Mac desktop? (Let's say 8 GB of RAM, 64-bit OS.) Execution speed is not so important to me, although for my purposes, several hours or more would be off-putting. ",9,6
146,2013-11-24,2013,11,24,7,1rbb6r,Nice collection of datasets (mostly graph data),https://www.reddit.com/r/MachineLearning/comments/1rbb6r/nice_collection_of_datasets_mostly_graph_data/,xamdam,1385247242,,3,23
147,2013-11-24,2013,11,24,13,1rbz8o,becoming big data's daddy in 1100 days,https://www.reddit.com/r/MachineLearning/comments/1rbz8o/becoming_big_datas_daddy_in_1100_days/,[deleted],1385268871,,0,0
148,2013-11-25,2013,11,25,3,1rcyom,Implementation of a multi-class class classfier using logistic regression,https://www.reddit.com/r/MachineLearning/comments/1rcyom/implementation_of_a_multiclass_class_classfier/,Warrior--,1385316652,"Hello,

I want to implement a multi-class classifier using logistic regression, but I don't know the steps for doing that.

I describe the problem below:

- I have five data sets as training set in the form of matrices with the size 600 x 50.
- Each training data matrix belongs to one of the targets 1, 2, 3, 4, 5.
- I add a bias vector as the first column to each of the training data matrices. Now, each matrix has the size 600 x 51

This is the part where I get confused ... . Some people say we need to combine all of the training data matrices in one matrix and use that matrix to train 5 different we vectors. Some people say in addition to that, we need to add another column to the BIG matrix as label. Some others say we need a Softmax function, some people say we don't!

Anyway, I don't know what to do from this part on. I don't know how to calculate the error and decrease it and train a classifier. The only thing I know (hope it is true) is that at the end I will have 5 different W vectors.

Please help me with that.",7,2
149,2013-11-25,2013,11,25,4,1rd30f,Ideas for a good place (department/lab) for a PostDoc position?,https://www.reddit.com/r/MachineLearning/comments/1rd30f/ideas_for_a_good_place_departmentlab_for_a/,danielv134,1385319940,"Preference for ML applications to clean tech, system software, remote sensing or medical. Strong reproducible research/open source culture a bonus. 

Ideas for places to look into? bonus points if you're also coming to NIPS next week and want to tell me more over a beer.",6,8
150,2013-11-25,2013,11,25,9,1rdv8b,R clustering and decision tree examples,https://www.reddit.com/r/MachineLearning/comments/1rdv8b/r_clustering_and_decision_tree_examples/,JST_79,1385340819,"Hi All - I'm fairly new to R and am playing around with some of the UCI datasets.  I'm looking for a couple of R data mining examples. Specifically, I'm looking for a kmeans example in R where k=N (any value).  I am also looking for R decision tree example where the data set is split into training and test datasets of specific sizes.  I know these have to be online, but the examples I'm finding either A) aren't defining N (for the clustering), B) not splitting into training/testing (for classification), or C) maybe doing some of this, but I'm not well versed in R enough to see.  Any help is appreciated.


EDIT/UPDATE:

I think I have the clustering thing in terms of the K=N thing - I feel silly.

km10 &lt;- kmeans(yeast2,10)

km4 &lt;- kmeans(yeast2,4)

I know how to look at the clusters in terms of the sizes, but how can I plot them and the centroids?  I tried and it's just ugly meaningless graphs.

EDIT/UPDATE 2:

Still working on the clustering...still stuck, but moving on to classification, I was able to get it (somewhat) with the following code, but still confused on how to see the accuracy of the model:

library(rpart)


yeast &lt;- read.table(""http://archive.ics.uci.edu/ml/machine-learning-databases/yeast/yeast.data"")


colnames(yeast)[1]  &lt;- ""SequenceName""

colnames(yeast)[2]  &lt;- ""Mcg""

colnames(yeast)[3]  &lt;- ""Gyh""

colnames(yeast)[4]  &lt;- ""Alm""

colnames(yeast)[5]  &lt;- ""Mit""

colnames(yeast)[6]  &lt;- ""Erl""

colnames(yeast)[7]  &lt;- ""Pox""

colnames(yeast)[8]  &lt;- ""Vac""

colnames(yeast)[9]  &lt;- ""Nuc""

colnames(yeast)[10]  &lt;- ""Class""


yeast.df &lt;- data.frame(yeast)



set.seed(2568)

n &lt;- nrow(yeast.df)

train &lt;- sort(sample(1:n, floor(n*.7)))



yeast.train &lt;- yeast.df[train,]
yeast.test &lt;- yeast.df[-train,]

fit &lt;- rpart(Class ~ Mcg + Gyh + Alm + Mit + Erl + Pox + Vac + Nuc,method=""class"", data=yeast.train)


# plot tree

plot(fit, uniform=TRUE,
     main=""Classification Tree for Yeast"")

text(fit, use.n=TRUE, all=TRUE, cex=.8)


pred &lt;- predict(fit, yeast.test, type=""class"")

pred



EDIT/UPDATE 3:

I added this to the decision tree to get the error on the test data:

printcp(fit)

summary(fit)

pred &lt;- predict(fit, yeast.test, type=""class"")

error = mean( pred!=yeast.test$Class )

table( pred, yeast.test$Class )",0,10
151,2013-11-25,2013,11,25,11,1re1mx,Machine Learning job for Msc.,https://www.reddit.com/r/MachineLearning/comments/1re1mx/machine_learning_job_for_msc/,binge_learner,1385345708,"Hi everyone !
I just got my Master's degree in applied mathematics (optimization and operations research ), and I've been interested in Machine Learning, o more broadly, Data Science for quite some time now ( read books on the subjects, learned python and the relevant libraries, and I already know R, C++ and Java).
What is then the best way to land a job in the field, what are companies looking for exactly, and what skills should I try to learn/refine in order to make myself more employable ?

P.S. : I live in France.
Thank you !",10,4
152,2013-11-25,2013,11,25,17,1renib,"Is there a type of linear regression in which I can put brackets on the coefficients? (If this question is confusing, there's a further explanation inside)",https://www.reddit.com/r/MachineLearning/comments/1renib/is_there_a_type_of_linear_regression_in_which_i/,randombozo,1385367923,"Let's say I know a coefficient should be between 1 and 4, so I want to limit its range within those numbers. It's similar to using offsets, only that the coefficients are ranges rather than specific numbers that I set. Using my example, if the original estimate said the coefficient was 7, this particular algorithm would change it to 4 because it'd be the upper limit.

Is there any stat package (R or one of those Python libraries) that would allow me to do so? 

Hope my grammar isn't too bad as I'm tired and about to hit the sack.
",11,5
153,2013-11-25,2013,11,25,18,1repsa,An Introduction to Decision Trees with Julia,https://www.reddit.com/r/MachineLearning/comments/1repsa/an_introduction_to_decision_trees_with_julia/,joelthelion,1385371579,,0,21
154,2013-11-25,2013,11,25,21,1rexj1,Machine Learning Tutorial: The Multinomial Logistic Regression (Softmax Regression),https://www.reddit.com/r/MachineLearning/comments/1rexj1/machine_learning_tutorial_the_multinomial/,datumbox,1385384115,,6,19
155,2013-11-26,2013,11,26,3,1rfnd7,Multiclass Naive Bayes with probabilities for y,https://www.reddit.com/r/MachineLearning/comments/1rfnd7/multiclass_naive_bayes_with_probabilities_for_y/,kau_mad,1385405381,"Hi, I've got to train a classifier where a sample can belong to one of many classes. And the training set output is given as the probability for belonging that sample to each class.
Eg: sample#1 : C1-0.6, C2-0.4, C3-0.0

I'm planning to use a Naive Bayes classifier using Scikit-learn. I couldn't find a fit method in naive_bayes.py which takes probability for each class for training.",1,2
156,2013-11-26,2013,11,26,6,1rg2kp,How does an algorithm qualify as sequential?,https://www.reddit.com/r/MachineLearning/comments/1rg2kp/how_does_an_algorithm_qualify_as_sequential/,CQFD,1385415245,"I'm trying to understand why some algorithms fit the ""statistical query model"" and some don't. Aka. why some can be parallelized and scaled using tools like Hadoop while others are limited because they are inherently sequential. What are some examples of sequentials algos?",6,1
157,2013-11-26,2013,11,26,6,1rg4s2,"Thanksgiving link: ""Editorial Board of the Kluwer Journal, Machine Learning: Resignation Letter""",https://www.reddit.com/r/MachineLearning/comments/1rg4s2/thanksgiving_link_editorial_board_of_the_kluwer/,satsatsat,1385416644,,2,18
158,2013-11-26,2013,11,26,7,1rg75o,Book-in-progress: Neural Networks and Deep Learning,https://www.reddit.com/r/MachineLearning/comments/1rg75o/bookinprogress_neural_networks_and_deep_learning/,chl,1385418240,,5,18
159,2013-11-26,2013,11,26,7,1rg8o4,R vs. Python,https://www.reddit.com/r/MachineLearning/comments/1rg8o4/r_vs_python/,mrShu,1385419207,"Over the last few days I've been reading a lot about Python taking over the R's as the primary tool of many for playing with ML/Data science [1] [2] [3]. The reasons presented made sense to me, Python is my language of choice when it comes to this kind of stuff. 

Coincidentally enough, I'm right now reading Machine Learning for Hackers which uses R. I am enjoying the book so far (it's mostly about learning R for me) and will certainly try to finish it. But I would still like to ask: are there areas in ML/Data science where R would be still a better fit or is it really doomed to be used only by statisticians who created it?

[1] http://www.talyarkoni.org/blog/2013/11/18/the-homogenization-of-scientific-computing-or-why-python-is-steadily-eating-other-languages-lunch/

[2] http://blog.mikiobraun.de/2013/11/how-python-became-the-language-of-choice-for-data-science.html

[3] http://readwrite.com/2013/11/25/python-displacing-r-as-the-programming-language-for-data-science
",36,20
160,2013-11-26,2013,11,26,10,1rgnrd,important features/variables in kmeans cluster,https://www.reddit.com/r/MachineLearning/comments/1rgnrd/important_featuresvariables_in_kmeans_cluster/,kahpowpow,1385429571,I am trying to figure out the best way to determine the most important/dominate variables in a kmeans cluster.  I know it's probably somewhat simple but my Googleing isn't taking me anywhere helpful...maybe my search isn't phrased properly.,7,3
161,2013-11-26,2013,11,26,19,1rhkps,Does releasing a library with prominent ML agorithms help me get a job?,https://www.reddit.com/r/MachineLearning/comments/1rhkps/does_releasing_a_library_with_prominent_ml/,Intern_MSFT,1385462013,"For sometime now, I have been trying to code up all the algorithms that I understand in C++. This has helped me immensely in both sharpening my skills as a C++ programmer, as well as have given me a deeper understanding of what is going on. I am building it on OpenCV so there is a lot parallels between Matlab syntax and what I am doing and the fact it is relatively easy to make it portable across Windows and Linux. Some algos I am done with are Logistic Regression, Softmax, SVM (SMO), Naive Bayes and Backpropagation for Neural Nets. On the graphical side, I have Sumproduct and MaxSum. May be in a couple of months, I will also try to get running with deep learning algos, but to be frank, right now, I have no idea of Neural Nets besides the very basic Backpropagation.




P.S.: I understand there are libraries out there, mlpack, and others for ML in C++ with a number of great contributors and I am no comparisan.


P.S.S.: I have an MSEE.",11,6
162,2013-11-26,2013,11,26,23,1rhuea,How to visualize a DFA problem.,https://www.reddit.com/r/MachineLearning/comments/1rhuea/how_to_visualize_a_dfa_problem/,[deleted],1385475224,"Hello. I got my theory of computation exam day after and I am having difficulty in solving problems involving construction of deterministic finite automaton. 

The problems are of the following manner. 

Give deterministic automaton accepting the following languages over the alphabet {0,1} 
1)Number of 1s is even and number of 0's is odd. 
2)All strings with exactly two 1s
3)Containing at least two 0s
And so on. 

My question is how exactly do you people visualize such kind of problems? What's your approach? Anything which can help me?",11,5
163,2013-11-27,2013,11,27,0,1ri0dl,How Many Lines (how do I fit a mixture of linear models)?,https://www.reddit.com/r/MachineLearning/comments/1ri0dl/how_many_lines_how_do_i_fit_a_mixture_of_linear/,orangecat99,1385480480,"I have recently started reading about Bayesian methods, and saw a few examples of people fitting mixture models by MCMC: create a graphical model where the observed variables are drawn from K Gaussian distributions. K is fixed, but the means and standard deviations aren't.
This is pretty straightforward, and works great.

Now, I want to expand this example and try to solve something a little harder. Let's say I have data generated through the following process:
1. Pick a uniformly random K between 1 and M (M is unknown to the observer, but small, ~20 or so).
2. For each line L_i, draw a_i, b_i from some random distribution (say Gaussian). L_i is the line x*a_i + b_i.
3. For each generated point (x, y), pick a random i (uniformly from 1..K), and a random x (from some fixed distribution - could be normal), and set y=a_i*x + b_i + epsilon (where epsilon is random Gaussian noise, with mean 0 and std &lt; a_i).

The description above is a bit long, but the idea is very simple: I am observing a mixture of an unknown number of signals, and what to simultaneously infer the number of signals and their parameters.

How would you go about it?

EDIT: After thinking about it for a bit, I know how I'm thinking to go about it: Fit one model for every possible value of K (#lines), and then use Bayesian model selection to pick my favorite one. I would be happy to hear about other alternatives, in any case.",6,6
164,2013-11-27,2013,11,27,0,1ri1mc,(MOOC) StatLearning Statistical Learning taught by Trevor Hastie and Rob Tibshirani,https://www.reddit.com/r/MachineLearning/comments/1ri1mc/mooc_statlearning_statistical_learning_taught_by/,chalupapa,1385481402,,16,63
165,2013-11-27,2013,11,27,2,1riamr,Google releases a Data Set: Features Extracted From YouTube Videos for Multiview Learning,https://www.reddit.com/r/MachineLearning/comments/1riamr/google_releases_a_data_set_features_extracted/,petrux,1385487749,,2,27
166,2013-11-27,2013,11,27,4,1rijxo,Reminder: the PRML Study Group has started with chapter 2,https://www.reddit.com/r/MachineLearning/comments/1rijxo/reminder_the_prml_study_group_has_started_with/,BeatLeJuce,1385494048,,0,11
167,2013-11-27,2013,11,27,9,1rjde2,Deep Learning that Doesn't Involve Neural Networks?,https://www.reddit.com/r/MachineLearning/comments/1rjde2/deep_learning_that_doesnt_involve_neural_networks/,caesarten,1385513827,"Hey everyone,

I've been delving deeper and deeper into this deep learning rabbit hole (harharhar). For all intensive purposes it seems like everything I come across is a variant of a neural network. Different structure, different cost functions, so on, but a neural network nonetheless.

So, just for curiosity's sake, are there any models/techniques out there that aren't neural-network based?

edit: Still learning more about the English language apparently, really thought ""intensive"" was an idiom, not ""intents and purposes"" :)",22,17
168,2013-11-27,2013,11,27,19,1rkcfx,Research Report: China Car Purchasing Process 2013 : Now available at Market-Research-Reports.biz,https://www.reddit.com/r/MachineLearning/comments/1rkcfx/research_report_china_car_purchasing_process_2013/,Research-biz,1385549120,,0,0
169,2013-11-27,2013,11,27,20,1rkczx,Buy Soda Fountain Machine Parts Here,https://www.reddit.com/r/MachineLearning/comments/1rkczx/buy_soda_fountain_machine_parts_here/,sodamachineparts,1385550050,,0,0
170,2013-11-27,2013,11,27,21,1rkfaj,Mini Video Lecture: Social Network Analysis for Fraud Detection,https://www.reddit.com/r/MachineLearning/comments/1rkfaj/mini_video_lecture_social_network_analysis_for/,datumbox,1385553802,,1,7
171,2013-11-28,2013,11,28,3,1rl89g,Five ways to handle Big Data in R,https://www.reddit.com/r/MachineLearning/comments/1rl89g/five_ways_to_handle_big_data_in_r/,talgalili,1385578334,,0,1
172,2013-11-28,2013,11,28,4,1rlcbw,Dragonball Z - Eres un Hroe,https://www.reddit.com/r/MachineLearning/comments/1rlcbw/dragonball_z_eres_un_hroe/,SANCHE123,1385580981,,1,0
173,2013-11-28,2013,11,28,4,1rle4h,Help with a Graduate Project,https://www.reddit.com/r/MachineLearning/comments/1rle4h/help_with_a_graduate_project/,[deleted],1385582124,"Hi all, I'm working on creating a Movie Suggestion AI for a graduate project and wondered if the AI hobbyists/professionals could provide some input.

What I intend to do is have an interface where the user puts in 2 movies and the result will be a movie with common traits to both. Doing this is fairly simple just using keywords and seeing which are the most common and choosing that movie, but I'm struggling with how to turn this into a Machine Learning implementation.

I intend to use Weka to train the algorithm first, then use that model to make decisions for future queries. The problem is, if I simply put in the keywords and tell Weka what the result should be (as training), won't it simply just be learning my method of finding the most common keywords? 

That doesn't seem like Machine Learning, can anyone provide a suggestion on how I can train the model so it also will make it's own assumptions/improvements?",8,3
174,2013-11-28,2013,11,28,7,1rlqcs,Stochastic Outlier Selection,https://www.reddit.com/r/MachineLearning/comments/1rlqcs/stochastic_outlier_selection/,rrenaud,1385590302,,11,43
175,2013-11-28,2013,11,28,8,1rlusq,Andrew Ng - Machine Learning via Large-scale Brain Simulations - Technion lecture,https://www.reddit.com/r/MachineLearning/comments/1rlusq/andrew_ng_machine_learning_via_largescale_brain/,mind_bomber,1385593472,,7,30
176,2013-11-28,2013,11,28,8,1rluz7,Horse Racing Betfair Odds Prediction System,https://www.reddit.com/r/MachineLearning/comments/1rluz7/horse_racing_betfair_odds_prediction_system/,[deleted],1385593608,"Hi,

Has anyone here ever did something like a financial prediction system, but applied to sports betting? For those who aren't familiar with Betfair, it's just a platform that works as an exchange market where players bet on sports events (mainly), it works very similar to the stock market. 
I'm developing such a system myself on behalf of a Multi-Agent course I'm attending. I built a system that follows the value of the most bet horse (in horse races) 1 hour prior to the race itself. That way the odd isn't biased from the race itself. 
Most of the agents in the system don't make use of machine learning at all, they have strict betting profiles (they aren't very successful). Right now I'm developing an agent that uses Random Forests to learn market behaviour. I'm feeding it with different combinations of technical indicators that were computed from the odd variation along time. 
My problem now is, what do I really want the model to learn? I mean, right now it's learning the variation of a moving average. In other words, in a moment t I compute the variation of odd(t) / odd(t+n) where n is the look ahead window I choose.
The issue is that even if the model was fitted the data 100% I still have to implement some strategy on top of my model to make the agent bet only when slope of the variation is greater than X or when the variation has been positive for N periods...
Can anyone shed some light on the path I should take?

Thanks.",4,4
177,2013-11-28,2013,11,28,9,1rm24a,"Course ""Data analysis with R"" - open access",https://www.reddit.com/r/MachineLearning/comments/1rm24a/course_data_analysis_with_r_open_access/,MangirdasA,1385599130,"Good day machine learning experts!

Hope you all are doing great.

I have created course named Data analysis with R. I would like to share it with you for free!

If interested in learning data analysis and R:
1)	Go to udemy platform - http://bit.ly/18oS9Um
2)	Search for my course Data analysis with R.
3)	Press Redeem a Coupon and enter Reddit_Free_M(without quotes)
4)	Easily signup/login with Facebook or mail and enjoy!

First 100 will get free access.

This course is developed for R beginners in mind.

I would love to hear your feedback : )
",2,1
178,2013-11-28,2013,11,28,11,1rmaf8,My model for the recent See Click Predict Fix Kaggle competition. Feedback appreciated!,https://www.reddit.com/r/MachineLearning/comments/1rmaf8/my_model_for_the_recent_see_click_predict_fix/,eloisius,1385605993,,0,10
179,2013-11-28,2013,11,28,15,1rmotp,What are some good data visualization and performance measures for machine learning?,https://www.reddit.com/r/MachineLearning/comments/1rmotp/what_are_some_good_data_visualization_and/,Badoosker,1385618899,"For most of you doing research, and those of you who are looking to get into it, this would be of great benefit to know.




The performance measures I'm familiar with are ROC (Receiver Operating Characteristic), AUC (Area under curve) and Confusion Matrices.

For data visualization, I know of PCA.. and that's bout it folks. Help!",3,7
180,2013-11-28,2013,11,28,23,1rnbyt,"Best spot for PhD in ML, deep learning and/or reinforcement learning",https://www.reddit.com/r/MachineLearning/comments/1rnbyt/best_spot_for_phd_in_ml_deep_learning_andor/,justinzoinks,1385650567,"I really REALLY like multi-agent learning.

Do you guys know of any good projects going on, even unpublished, that a really excited Masc and PEng would like?

I guess I should just ask: what are the most exciting projects going on to you personally.

Edit: Thanks for the comments guys!

I'm currently doing my masters at U of T (in Aerospace) so it looks like I'm partly in the right part of the world. That's kind of how I felt, but it's good to see that it looks like that other people see that too!

Working with Andrew Ng would be a dream. He is the reason I'm doing my thesis at the moment! Bengio's lab in MTL looks extremely fun, and similar to my personality. I have found that I'm teetering on the edge of abandoning academics because it's so stuffy and pedantic, but seeing some of these happy positive researchers is really encouraging. ",22,10
181,2013-11-29,2013,11,29,5,1rny03,NIPS 2013 papers are now available online,https://www.reddit.com/r/MachineLearning/comments/1rny03/nips_2013_papers_are_now_available_online/,urish,1385668849,,14,57
182,2013-11-29,2013,11,29,19,1rpb93,Need some help. Trying to categorize products.,https://www.reddit.com/r/MachineLearning/comments/1rpb93/need_some_help_trying_to_categorize_products/,[deleted],1385719672,"I'm a bit stuck on a problem and it'll be awesome if you can provide some help or opinions on this, if you can manage.

My use case:

My labeled training data looks like this (# separated, first is the target, 2nd is the training data)
White-spaces introduced for readability.

Nokia 101 Dual Sim#Nokia 101 Feature Phone
Nokia 101 Dual Sim#Nokia  101
Nokia 101 Dual Sim#Nokia  101
Nokia 101 Dual Sim#Nokia 101 Dual Sim Mobile
Nokia 101 Dual Sim#Nokia 101 Dual sim Mobile Phone Black with Original Tax Paid Invoice and Express Shipping (Sourced From Brand)
Nokia 101 Dual Sim#Nokia 101 (P. Black)
Nokia 207         #Nokia Asha 207 Mobile Phone - Orange
Nokia 207         #Nokia Asha 207 Mobile Phone - Yellow
Nokia 207         #Nokia 207
Nokia 208         #Nokia Asha 208 Mobile Phone - Black
Nokia 2610        #Brand New Nokia 2610 GSM 100% Genuine Product.Lowest Price A Must Have One
Nokia 301         #Nokia 301 (Black)
Nokia 301         #Nokia 301 (White)
Samsung ATIV S    #Samsung Ativ S I8750 16 GB - Grey
Samsung ATIV S Neo#Samsung ATIV S Neo

What I'm trying to do here is to map a product name from the Internet to a product I already know about.

So, the target variable is the product name that I already know.

Now when I give a string like ""Nokia 207 Mobile with Dual Sim and FM Radio"", I get an output that the recognized match is Nokia 207

Problem:

Now since it gets pretty hard to extract features from names found on the Internet, mos
tly because people will write anything to name their products, specially on ebay, I got pretty poor results while I tried to tackle this is a multi-class classification problem using a Random Forest Classifier. The toughest part being unable to properly extract the features from the training data.

I was thinking of using Autoencoders or maybe Restricted Boltzmann Machines to get a solution, but unfortunately I don't have much theoretical knowledge on the same (ML wasn't a part of my coursework at college).

It'd be really helpful if you can provide some insight on how this can be done.",0,1
183,2013-11-29,2013,11,29,20,1rpf3w,Need some help. Trying to classify products.,https://www.reddit.com/r/MachineLearning/comments/1rpf3w/need_some_help_trying_to_classify_products/,wtdfck,1385726098,"I'm a bit stuck on a problem and it'll be awesome if you can provide some help or opinions on this.

**My use case:**

My example labeled training data looks like this (# separated, first is the target, 2nd is the training data) White-spaces introduced for readability.    
[Example dataset on pastebin](http://pastebin.com/raw.php?i=ezCYqTq9)

    Nokia 101 Dual Sim#Nokia 101 Feature Phone
    Nokia 101 Dual Sim#Nokia  101
    Nokia 101 Dual Sim#Nokia  101
    Nokia 101 Dual Sim#Nokia 101 Dual Sim Mobile
    Nokia 101 Dual Sim#Nokia 101 Dual sim Mobile Phone Black with Original Tax Paid Invoice and Express Shipping (Sourced From Brand)
    Nokia 101 Dual Sim#Nokia 101 (P. Black)
    Nokia 207         #Nokia Asha 207 Mobile Phone - Orange
    Nokia 207         #Nokia Asha 207 Mobile Phone - Yellow
    Nokia 207         #Nokia 207
    Nokia 208         #Nokia Asha 208 Mobile Phone - Black
    Nokia 2610        #Brand New Nokia 2610 GSM 100% Genuine Product.Lowest Price A Must Have One
    Nokia 301         #Nokia 301 (Black)
    Nokia 301         #Nokia 301 (White)
    Samsung ATIV S    #Samsung Ativ S I8750 16 GB - Grey
    Samsung ATIV S Neo#Samsung ATIV S Neo

What I'm trying to do here is to map a product name from the Internet to a product I already know about.

So, the target variable is the product name that I already know.

Now when I give a string like ""Nokia 207 Mobile with Dual Sim and FM Radio"", I need to get an output that the recognized match is Nokia 207

**Problem:**

Now since it gets pretty hard to extract features from names found on the Internet, mos tly because people will write anything to name their products, specially on ebay, I got pretty poor results while I tried to tackle this is a multi-class classification problem using a Random Forest Classifier. The toughest part being unable to properly extract the features from the training data. So, in the above dataset you see that I did not do any feature extraction.

I was thinking of using Autoencoders or maybe Restricted Boltzmann Machines to get a solution, but unfortunately I don't have much theoretical knowledge on the same (ML wasn't a part of my coursework at college).

It'd be really helpful if you can provide some insight on how this can be done.
",19,8
184,2013-11-29,2013,11,29,23,1rpm4r,Is there research that exploits the history of version control systems like git?,https://www.reddit.com/r/MachineLearning/comments/1rpm4r/is_there_research_that_exploits_the_history_of/,schwarmbloedheit,1385736345,"Version control commits capture a small change in programs which were made by a programmer with an intention. For example if the programmer implements a web shop he could add the feature 'user login' and commit these changes. There are thousands of repositories on git-hub, thus a huge amount of more or less well structured data. Git-hub also gathers other data such as programming language, popularity of repository and much more. The programmer also adds a comment.

There have been research in [genetic programming](http://en.wikipedia.org/wiki/Genetic_programming) where a search in the space of possible programs is performed. This space is very high-dimensional and small changes in the code can have a huge impact on the program output, which makes it very difficult. However, version control histories available on git-hub could be used to guide and facility this search. Is there research in this direction?",13,26
185,2013-11-30,2013,11,30,2,1rpvac,Help on detecting anomalies in parametric time-series,https://www.reddit.com/r/MachineLearning/comments/1rpvac/help_on_detecting_anomalies_in_parametric/,ptpatil,1385744999,"Quick question, I have to write a implementation of NNs or something else that will tell us if a certain process is going as expected based on previous ""normal"" operations data or if it's diverging from the expected output time-series.

AKA:

    T0: parameters: (1 x, 2 y, 1.4 z) ---&gt; $560 for Today, Expected $605, Divergence: 45/560, ~10%
    T-1:"" ""
    T-2:"" ""
    T-3:"" ""

etc..

I was thinking of doing autoencoding to figure out the complex relationships (theres more than 3 parameters, thousands actually). The entire time series is composed of granular ""encounters"" objects that have relative time based values for each parameter i.e., parameter X was 1.5 in T-3 (3 days from Encounter creation). 

What would be the best way to tackle this sort of problem where I want the algorithm predictions to serve as expectation values for a time-series from which divergence and thus ""operational abnormality/anomaly"" is detected?

",5,10
186,2013-11-30,2013,11,30,9,1rqq9o,Seeking approaches or packages for analyzing incomplete graphs of people &amp; organizations,https://www.reddit.com/r/MachineLearning/comments/1rqq9o/seeking_approaches_or_packages_for_analyzing/,sleepicat,1385770041,"I have a dataset that contains name and organization pairs, and I'm trying to find a method that will either fill in edges and/or else cluster people based on common connections.

The edges sometimes connect people and other times connect people with an organization. 

So, for example, maybe I have 'edges' that look like this:

     Joe, OrgA
     Bill, OrgA
     Scott, Bill
     Scott, OrgB
     ...

where usually the first column is a person, but the second column can be either a person or an organization.

My goal is to find how Scott is connected to OrgA (via Bill) and how Scott is connected to Joe (via Bill and OrgA), and how OrgA and OrgB are connected (via Scott and Bill).

I realize that maybe some data munging is needed to perhaps sort out the people and organizations, etc., but I was hoping I could find network analysis package that would cut down on some of the work for me.

What would you suggest?

I'm currently using igraph in R, but I've only just started and I'm not wedded to it. If anyone can recommend a types of approaches (as opposed to software packages), that would be fine too.  
",3,8
187,2013-11-30,2013,11,30,23,1rrvqe,Hunting Target Leaks - or Trolling Kaggle for Fun and Profit,https://www.reddit.com/r/MachineLearning/comments/1rrvqe/hunting_target_leaks_or_trolling_kaggle_for_fun/,rouli,1385821888,,0,16
