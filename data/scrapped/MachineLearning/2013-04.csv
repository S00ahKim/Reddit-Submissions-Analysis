,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2013-4-1,2013,4,1,17,1beum3,Updating R (on Windows) through a menu-bar: installr 0.9 released on CRAN,https://www.reddit.com/r/MachineLearning/comments/1beum3/updating_r_on_windows_through_a_menubar_installr/,talgalili,1364806540,,0,1
1,2013-4-1,2013,4,1,21,1bf2hu,Find a separating hyperplane with this one weird kernel trick,https://www.reddit.com/r/MachineLearning/comments/1bf2hu/find_a_separating_hyperplane_with_this_one_weird/,[deleted],1364819859,,1,0
2,2013-4-1,2013,4,1,23,1bfa6g,Dimensionality reduction for sparse binary data - an overview of methods,https://www.reddit.com/r/MachineLearning/comments/1bfa6g/dimensionality_reduction_for_sparse_binary_data/,Foxtr0t,1364827384,,0,1
3,2013-4-2,2013,4,2,17,1bi6tx,"crusher plant for quartz crushing, quartz stone crushing machine",https://www.reddit.com/r/MachineLearning/comments/1bi6tx/crusher_plant_for_quartz_crushing_quartz_stone/,conecrusherforsale,1364892243,,0,0
4,2013-4-3,2013,4,3,2,1biyvs,pyfeast - a feature selection tool for python,https://www.reddit.com/r/MachineLearning/comments/1biyvs/pyfeast_a_feature_selection_tool_for_python/,mutantturkey,1364923312,,0,16
5,2013-4-3,2013,4,3,3,1bj5jd,Simple bayesian classifying question I'm stuck on (part b!),https://www.reddit.com/r/MachineLearning/comments/1bj5jd/simple_bayesian_classifying_question_im_stuck_on/,EphemeralPower,1364928037,"Hi, guys. I have fortunately found a subreddit that might be able to answer a simple question that has been racking my mind for a while. (I also have an upcoming exam in a month and really want to get &gt;80% on it!) 


EDIT: link didn't work, here it is http://imgur.com/hIR6wcA


For part a) of this question I got 

P(poisonous|X) ~= 0.72 and P(!poisonous|X) ~= 0.28

Where X is the independent variables of the plant (the toughness/colour etc etc)..

So we would classify plant 8 as poisonous. However, for part b) I don't know how to approach it. I know what to expect (the introduction of the prior knowledge about the chance of the plant being poisonous in the given terrain will mean that our MAP hypothesis will change - meaning it is now less likely to be a poisonous plant) but I don't know how to go about 'showing' this. I mean I guess it's a combination of bayes formula and marginalisation? I just don't know where to start! 

Thanks again!",0,1
6,2013-4-3,2013,4,3,3,1bj6op,[Question] Can you recommend an ML project that could utilize the GPU ?,https://www.reddit.com/r/MachineLearning/comments/1bj6op/question_can_you_recommend_an_ml_project_that/,oneAngrySonOfaBitch,1364928882,"Hey guys, as part of my final project for a GPU programming course i need to implement a project that uses GPU parallelism solve a problem. I was thinking of learning some ML by implementing a (simple) algorithm in a parallel manner and was wondering if you guys had any ideas.

It would have to be something that would benefit from several (independent) threads running on the data. ",27,10
7,2013-4-3,2013,4,3,4,1bj9z6,Can somebody help me with neural networks ?,https://www.reddit.com/r/MachineLearning/comments/1bj9z6/can_somebody_help_me_with_neural_networks/,[deleted],1364931227,"Hello all, 

I am a physics major coding a very very simple neural network for a CS module. The goal is to train it for character recognition using a backpropagation algorithm. 

I have something that works not too bad, and I understand the basic idea behind the algorithm, but I am really lost on the theory. 

Here is an example of something I don't understand : the choice of the activation function. It has to be non-linear or else the network would not be interesting and just reduce to a one-layer network. But the most commonly used function is the sigmoid or something similar, that becomes constant (0 or 1) if the input is outside of a certain interval. If the input is out of this interval, the derivative is zero and since the updating of weights is proportional to the derivative, nothing happens, the network is paralysed. So for training we want to stay in the zone where the sigmoid is not constant, that is to say, where it's almost linear. Isn't that a contradiction ?

None of my teachers know anything about the subject, including the one who offered kids to work on that. He thought it was cool but he is not a specialist. I've browsed through books, but they spend 3 pages max on this kind of network and the only advice they seem to give is ""Tweak parameters at random until it works. Enjoy your black box"". Or they go very fast in mathematics theory or algorithms I can not follow. 

Can somebody help me ?",0,2
8,2013-4-3,2013,4,3,9,1bjz2j,Advice on ML given SQL data?,https://www.reddit.com/r/MachineLearning/comments/1bjz2j/advice_on_ml_given_sql_data/,binarysolo,1364949457,"Background: Math-y with R/MATLAB experience; some work using Python/SQLAlchemy/Rails/d3 but I'm really an analyst, notsomuch a developer or DB guy (but always learning!).  Looking at a DB that's &lt;10GB, so not doing Hadoop/Hive-level stuff yet.

Haven't really tried my hand at the two together... typically I receive exports in csv files that I then play around with in R, but I think the better practice is mining the data directly without exporting, so I wanted to check what good practices/libraries people would recommend.

Would love to hear any advice or just points toward the right direction.

PS -- Bonus q, and a bit more ambitious -- would love to hear advice on dashboarding (whether it's d3-based, opensourced, or a freemium/enterprise solution) for such an SQL database as well.  This is for a personal project so I'm preferring to bootstrap with time/labor. :)

Edit 4/3/13: Thanks guys for advice; you're all awesome!",6,3
9,2013-4-3,2013,4,3,10,1bk186,Infinity of words,https://www.reddit.com/r/MachineLearning/comments/1bk186/infinity_of_words/,[deleted],1364951109,,0,1
10,2013-4-3,2013,4,3,10,1bk4so,Just a friendly PSA about using WEKA to edit ARFF files,https://www.reddit.com/r/MachineLearning/comments/1bk4so/just_a_friendly_psa_about_using_weka_to_edit_arff/,jwgibbo,1364953771,"I had a simple problem to solve: rearrange the order of columns in my arff files.  Despite being simple, I wasted one too many hours struggling to find a way to use WEKA to edit my arff files.  The built in arff viewer and experimenter failed to successfully save any changes made to the them.  I was about the give up and just code up my own script to do the job, but, luckily, I found that the filters in the explorer has a rearrange filter that can successfully alter and save the arff file.

It's in:

filters -&gt; unsupervised -&gt; attribute -&gt; reorder",4,3
11,2013-4-3,2013,4,3,14,1bkjb3,Predictive Analytics Healthcare Vendors?,https://www.reddit.com/r/MachineLearning/comments/1bkjb3/predictive_analytics_healthcare_vendors/,[deleted],1364965537,"Anyone know any good PA vendors with solid models in the healthcare space, specifically around readmission risk stratification?

I'm working on a project and could use some help.

TIA",11,5
12,2013-4-3,2013,4,3,22,1bl4bv,"R 3.0.0 is released! (whats new, and how to upgrade)",https://www.reddit.com/r/MachineLearning/comments/1bl4bv/r_300_is_released_whats_new_and_how_to_upgrade/,talgalili,1364996783,,0,1
13,2013-4-4,2013,4,4,1,1bliau,Nonparametric Regression on the results of a Linear Regression,https://www.reddit.com/r/MachineLearning/comments/1bliau/nonparametric_regression_on_the_results_of_a/,Nonparametrictrouble,1365007944,"So I was recently talking to this guy who told me that he regressed some price data on some independent variables before taking those predictions and regressing the price data onto the predictions of the linear regression with a nonparametric method.

I was wondering under what circumstances it would be a good idea to do something like that?

Edit: A little clearer

Matrix of independent variables: X

Vector of dependent variable values: Y

**LinearRegression.fit(X,Y)**

**NewPrediction = LinearRegression.predict(X)**

**Nonparametricmethod.fit(NewPrediction,Y)**

",9,2
14,2013-4-4,2013,4,4,16,1bndah,Abusing hash kernels for wildly unprincipled machine learning,https://www.reddit.com/r/MachineLearning/comments/1bndah/abusing_hash_kernels_for_wildly_unprincipled/,zlorg,1365061795,,8,16
15,2013-4-4,2013,4,4,23,1bnt2u,Find a separating hyperplane with this One Weird Trick...,https://www.reddit.com/r/MachineLearning/comments/1bnt2u/find_a_separating_hyperplane_with_this_one_weird/,mutantturkey,1365084662,,21,112
16,2013-4-5,2013,4,5,1,1bo55p,"Typical report from a ""Data Scientist""",https://www.reddit.com/r/MachineLearning/comments/1bo55p/typical_report_from_a_data_scientist/,fortyninerbruin,1365094313,"My experience in industry tells me that the range of what a Data Scientist could mean is anything from pie charts all the way up to Hadoop and using some pretty serious CS stuff. 

Is there a sample online somewhere of what a typical report from a ""Data Scientist"" looks like? I see everything talked about very generally and abstractly, but never anything concrete. ",0,0
17,2013-4-5,2013,4,5,1,1bo56o,Dimensionality reduction for sparse binary data - an overview,https://www.reddit.com/r/MachineLearning/comments/1bo56o/dimensionality_reduction_for_sparse_binary_data/,Foxtr0t,1365094334,,0,1
18,2013-4-5,2013,4,5,11,1bpheb,"I have a cluster all to me, what must I experiment it with?",https://www.reddit.com/r/MachineLearning/comments/1bpheb/i_have_a_cluster_all_to_me_what_must_i_experiment/,waheedmurad,1365128967,"Okay, the professor who used to research with the cluster left the university some months back. The lab was closed since then. I asked the head of department, and he said okay the lab is yours. What should I try? Graphlab or Map Reduce? Latest research trends, anything?",8,0
19,2013-4-5,2013,4,5,15,1bpv34,Multitudes of effect/no-effect multifactor determinations on the cheap provided that samples can be scored on the fly,https://www.reddit.com/r/MachineLearning/comments/1bpv34/multitudes_of_effectnoeffect_multifactor/,kburjorj,1365141905,,3,7
20,2013-4-5,2013,4,5,16,1bpyqn,"A Spectral Approach to Ghost Detection: "". In this paper we survey our groundbreaking research on in this direction, with algorithms inspired on ghosts, astral projections and aliens, among others. We hope to convince researchers of the value of not letting research be constrained by reality.""",https://www.reddit.com/r/MachineLearning/comments/1bpyqn/a_spectral_approach_to_ghost_detection_in_this/,[deleted],1365147141,,8,6
21,2013-4-6,2013,4,6,21,1bsl88,How to use a t-test to compare a binary classification to pure random data?,https://www.reddit.com/r/MachineLearning/comments/1bsl88/how_to_use_a_ttest_to_compare_a_binary/,DarkSareon,1365253196,"So I am new to this and I am not quite sure how to do this.  I could be over thinking it.

I have a binary classification where all the data is labelled as Win or Lose.  THere is an equal amount of both.  I am using libSVM on weka with 10-fold cross validation and I am getting results of around 55%.  Since that is just slightly higher than a coin flip I want to ensure that it is actually 55% and not just luck of the data so I need to conduct a t-test I believe.

But what I am conducting a t-test against?  The success of each of the folds and what?  Just 50%s?  

Or is there another way to approach this problem that I am overthinking?

**edit Update**

Can I just use the student's t-test with one vector of the results of each of the ten folds compared to a vector of all 0.5 and see if that results in a p &lt; 0.05?",12,7
22,2013-4-7,2013,4,7,7,1btio7,"Learning a high-frequency, irregular objective function",https://www.reddit.com/r/MachineLearning/comments/1btio7/learning_a_highfrequency_irregular_objective/,adamcrume,1365286878,"I have an objective function f(x) that looks like (x%m_1)/m_1 for one range, then (x%m_2)/m_2 for another range, etc. for several ranges, with x ranging from 0 to 1 billion, and the m's are roughly a thousand.  The ranges are not regularly spaced, I don't know where they are, I don't know what the m's are, and the total number of oscillations will be roughly a million.  How can I learn f(x) (given noisy data)?

For extra credit:  I actually don't have the values for f(x).  I'm trying to learn g(x_1, x_2), where g(x_1, x_2) = h(f(x_1), f(x_2)) for some function h.  How do I learn g, or h and f?",14,5
23,2013-4-7,2013,4,7,7,1btja6,21st Century Problems: Multi-Armed Bandits,https://www.reddit.com/r/MachineLearning/comments/1btja6/21st_century_problems_multiarmed_bandits/,HootBack,1365287416,,3,26
24,2013-4-7,2013,4,7,8,1bto9p,Getting started in Machine Learning from square one: please tell me if I'm wasting my time...,https://www.reddit.com/r/MachineLearning/comments/1bto9p/getting_started_in_machine_learning_from_square/,VCavallo,1365292002,"Hi

I know next to nothing about Machine Learning, have a beginner-level (and growing) understanding of a variety of programming languages (mostly Ruby) and the highest level of math I've taken is Calculus I. No formal statistics. I read lesswrong.com and attempt to grok rationality and Bayes (no promises). 

From searching around ""noob"" threads on /r/MachineLearning I came across the O'Reilly [Natural Language Processing with Python](http://nltk.org/book/) book and was considering starting there. 

The reason I am posting this here: As I said, I have no formal statistics training/education and the highest math I've completed is Calculus I. Math and statistics are intriguing to me but I haven't had time to pursue further. Is it not worth getting into Machine Learning with the level of math education I currently have? I am not opposed to learning more (I'd like to), but if that's a necessity from day one or shortly thereafter I might be better off waiting and pursuing this again in the future. 

My interest is hobby-level at the moment, possibly developing into web-app applications down the line and of course with the ultimate goal of helping to save the planet and/or take over the world eventually.

Your advice appreciated! Be as honest as you want - you won't be crushing my dreams or anything. As I said: hobby-level interest at the moment.

Thanks!

EDIT: thanks thanks everyone so far! ",22,14
25,2013-4-7,2013,4,7,18,1bug8x,jaw crusher for rock crushing,https://www.reddit.com/r/MachineLearning/comments/1bug8x/jaw_crusher_for_rock_crushing/,conecrusherforsale,1365326514,,2,0
26,2013-4-7,2013,4,7,22,1bummf,Brew: a Forth laboratory for artificially evolving programs fit for a purpose,https://www.reddit.com/r/MachineLearning/comments/1bummf/brew_a_forth_laboratory_for_artificially_evolving/,pointfree,1365340044,,0,11
27,2013-4-7,2013,4,7,22,1buol9,Datasets for using ML algorithms,https://www.reddit.com/r/MachineLearning/comments/1buol9/datasets_for_using_ml_algorithms/,Maedhros,1365343056,"Hi,

I've worked through much of the machine learning course that is on Coursera from Andrew Ng. What I would like is the opportunity to play around with some of these algorithms in practice, for example, support vector machines, clustering, neural networks. 

I am quite experienced in R and have experience working mainly with regressions and time series forecasting, so I shouldn't have much problem figuring out the mechanics of doing it, I just need the datasets. Can anyone guide me to some useful datasets online that would be interesting for these types of algorithms? Thanks.",15,16
28,2013-4-8,2013,4,8,2,1bv0zc,Implicit Concurrency in Genetic Algorithms,https://www.reddit.com/r/MachineLearning/comments/1bv0zc/implicit_concurrency_in_genetic_algorithms/,[deleted],1365355871,,0,1
29,2013-4-8,2013,4,8,15,1bwi8r,Predictive Analytics: A Force Multiplier for Big Data,https://www.reddit.com/r/MachineLearning/comments/1bwi8r/predictive_analytics_a_force_multiplier_for_big/,hkotadia1,1365401013,,0,1
30,2013-4-9,2013,4,9,1,1bxdz8,Has anyone used NumaScale? What are your opinions and experiences?,https://www.reddit.com/r/MachineLearning/comments/1bxdz8/has_anyone_used_numascale_what_are_your_opinions/,solen-skiner,1365440294,,1,3
31,2013-4-9,2013,4,9,12,1byrts,"What do people think about Jeff Hawkins' Cortical Learning Algorithm? Seems like it should be the ""holy grail"", what are it's flaws?",https://www.reddit.com/r/MachineLearning/comments/1byrts/what_do_people_think_about_jeff_hawkins_cortical/,sanity,1365476662,,29,17
32,2013-4-9,2013,4,9,13,1byy0f,Multiple Kernel Learning issue,https://www.reddit.com/r/MachineLearning/comments/1byy0f/multiple_kernel_learning_issue/,DKBOS,1365481756,Suppose I have a set of normalised Kernels that line on the unit semi definite cone. While combining these kernels in a MKL algorithm how should I set the constraints on the optimization problem so that the resultant kernel \sum_{i}^{N} \theta_{i} K_{i} also lie on the unit semi definite cone ?,2,1
33,2013-4-9,2013,4,9,13,1byzvt,Using PCA to produce a black and white (grayscale) photo,https://www.reddit.com/r/MachineLearning/comments/1byzvt/using_pca_to_produce_a_black_and_white_grayscale/,VodkaRocks4Breakfast,1365483502,"I was messing around with some image processing and tried out a fun (albeit trivial) use for PCA. For a given image, I took each pixel's RGB value as a 3 dimensional vector. Then projected each pixel onto the first PC and normalized for the appropriate value. 

The results are here:
http://imgur.com/a/a4kwY

I know this isn't anything crazy, I just thought it was kind of a fun use of a data processing algorithm. Also, if you think about it more deeply, this method of creating a black and white photo could possible preserve more of the original qualities of the color version than just taking the average of the color pixels. 

EDIT:

As requested, here is the image projected into HSV space. Looks like solarize filter.

http://i.imgur.com/d7J2Bjj.jpg",8,12
34,2013-4-9,2013,4,9,15,1bz4c2,Upright Vacuum Cleaner,https://www.reddit.com/r/MachineLearning/comments/1bz4c2/upright_vacuum_cleaner/,webtwitter,1365488615,,0,1
35,2013-4-9,2013,4,9,18,1bzawc,A really gentle introduction to Hidden Markov Models.,https://www.reddit.com/r/MachineLearning/comments/1bzawc/a_really_gentle_introduction_to_hidden_markov/,thinksthoughts,1365499835,,3,71
36,2013-4-9,2013,4,9,22,1bzjpo,Not sure if ML is applicable to my problem.,https://www.reddit.com/r/MachineLearning/comments/1bzjpo/not_sure_if_ml_is_applicable_to_my_problem/,[deleted],1365513440,"I don't know much about machine learning, but currently have a project that might benefit from it. Unfortunately, as I don't know much about ML I don't know if this is true, nor where to start!

I have a large number of value vs time graphs (charts?). From these graphs I wish to group those that are similar. My no-machine learning approach was going to be having a load of measures about the graphs (eg how long it takes to fall to 50% of the maximum value, if it does), and manually define some groups based on these values.

Could machine learning help here? If so, which algorithms might I want to look at ?

Many thanks!",1,0
37,2013-4-10,2013,4,10,1,1bzv7e,Instructions for Installing &amp; Using R on Amazon EC2,https://www.reddit.com/r/MachineLearning/comments/1bzv7e/instructions_for_installing_using_r_on_amazon_ec2/,talgalili,1365523599,,0,1
38,2013-4-10,2013,4,10,4,1c0dh8,"On concepts, invariant memories, and machine learning",https://www.reddit.com/r/MachineLearning/comments/1c0dh8/on_concepts_invariant_memories_and_machine/,toisanji,1365536600,,0,2
39,2013-4-10,2013,4,10,7,1c0q8h,"The secret is that ""big data"" means different things depending on whether you are on the engineering or business side of the problem.",https://www.reddit.com/r/MachineLearning/comments/1c0q8h/the_secret_is_that_big_data_means_different/,mediawoman,1365545275,,0,20
40,2013-4-10,2013,4,10,11,1c195q,Credit Risk Model Help /*Xpost r/statistics*/,https://www.reddit.com/r/MachineLearning/comments/1c195q/credit_risk_model_help_xpost_rstatistics/,daidoji70,1365559365,"Hello.  Making a Probability to Default model for the first time and we need to make a transactional based, real time model for various business reasons.  Having never done this before and having long assumed this was the realm of acturial science, never thought about applying ML to the issue.  

Do you know any free resources regarding such arts from the ML perspective?  Do you know any non-free resources?  How would you construct such a model in a perfect world?  How would you construct a model in the real world?

Any perspective or help on where to start here would help me out immensely.  Thanks r/MachineLearning in advance.  Keep up the interesting posts!",1,0
41,2013-4-10,2013,4,10,11,1c19j4,Learning to play Super Mario [x-post from /r/compsci],https://www.reddit.com/r/MachineLearning/comments/1c19j4/learning_to_play_super_mario_xpost_from_rcompsci/,blfang,1365559660,,6,41
42,2013-4-11,2013,4,11,0,1c2du4,Research on plastic/mutable neural networks,https://www.reddit.com/r/MachineLearning/comments/1c2du4/research_on_plasticmutable_neural_networks/,[deleted],1365606148,"Does anyone know of any good sources on plastic neural networks? i.e. neural networks where you add/remove inputs, outputs and/or any nodes in between. 
",6,6
43,2013-4-11,2013,4,11,3,1c2wi0,Trying to implement LSA in matlab. How can I build my incidence matrix faster?,https://www.reddit.com/r/MachineLearning/comments/1c2wi0/trying_to_implement_lsa_in_matlab_how_can_i_build/,mayonaise55,1365619891,"I'm attempting to utilize latent semantic analysis (LSA) to develop a semantic space in order to use a SVM to classify text based on semantic relatedness. I've attempted to use a few open source versions of LSA and have been met with just failure after failure.

So now, I'm trying to develop my own function which produces an incidence matrix in matlab, so that I can then use singular value decomposition. For the life of me I cannot figure out an efficient method to do this in matlab. 

Basically my program is searching a cell array for terms that have already been encountered in documents to find their index in the matrix. If they are not found, they are added to the index and the matrix. However, searching for the terms in the cell array and finding their indices is taking forever. I'm using:

wherestring = strcmp(A{1}{j},term);
i = find(wherestring, 1,'first');

to search for the string (word) in A{1}{j} in the term cell array.

Is there a faster way to do this? All I can think is to implement some data structure to make searching more efficient (binary search tree or hash table), but this doesn't seem to be easily implemented in matlab. Sigh.",6,1
44,2013-4-11,2013,4,11,5,1c32xi,Credit Card Fraud Detection,https://www.reddit.com/r/MachineLearning/comments/1c32xi/credit_card_fraud_detection/,kafka399,1365624368,,0,0
45,2013-4-11,2013,4,11,10,1c3rf8,"What's a typical, or your, ML hourly contracting rate in the Bay Area (experienced practitioner)",https://www.reddit.com/r/MachineLearning/comments/1c3rf8/whats_a_typical_or_your_ml_hourly_contracting/,dethpicable,1365642267,,25,20
46,2013-4-11,2013,4,11,10,1c3u0d,Need help identifying this ensemble post processing technique,https://www.reddit.com/r/MachineLearning/comments/1c3u0d/need_help_identifying_this_ensemble_post/,metaobject,1365644267,"Hello all,  suppose we have ensemble output that consists of N members.  Each member is real valued (single floating point number). In addition, assume we have ""truth"" values that specify what the ""Correct"" value is that the ensemble output is trying to predict.  The ensemble and truth values are generated every T hours, and we have several months of data available.  
We want to quantify how we'll each member performs by comparing it to the truth value.  In addition, we like to know if certain members are biased on a consistent basis.
I'm looking for information on a technique that takes ensemble members and performs linear regression on the values in order to quantify how these members do over time.  In addition, is it possible to determine whether certain members are off by a certain amount and apply weights to them to adjust their output?
The idea is to train the algorithm on a historical data set, then use it to predict actual values in real time.
What is this approach called that employs regression to generate/update the member weights?  If anyone has any info on this I'd be very grateful.  Or, if anyone knows which keywords i could use to dig deeper, that would be great.  Everything I've found so far are PDFs of research papers that say they're using a technique like I've described, but give no details.  Perhaps it's trivial and I'm thinking too hard about this, but I can't find anything that describes how to perform these kinds of calculations.  Thanks!",5,5
47,2013-4-11,2013,4,11,12,1c40lc,Two ways of finding k in k-means,https://www.reddit.com/r/MachineLearning/comments/1c40lc/two_ways_of_finding_k_in_kmeans/,rrenaud,1365649348,,7,37
48,2013-4-11,2013,4,11,23,1c4w02,"Beginner here, where to start on document classification?",https://www.reddit.com/r/MachineLearning/comments/1c4w02/beginner_here_where_to_start_on_document/,crazy_raisin,1365690017,"Problem: Assume I have a 100 TB worth of web pages. How do I go about classifying them?

* With little background in machine learning, what books/tutorials should I read to be able to accomplish this?

* After I'm done with reading, are there any libraries out there that should help me with such endeavor?",8,14
49,2013-4-12,2013,4,12,3,1c5ejg,"I thought it would be cool to model reddit's comment scoring as a multi-armed bandit problem, suggestions?",https://www.reddit.com/r/MachineLearning/comments/1c5ejg/i_thought_it_would_be_cool_to_model_reddits/,[deleted],1365704162,,3,20
50,2013-4-12,2013,4,12,3,1c5f18,AskML: Pointers towards using appropriate NLP techniques in a ML problem,https://www.reddit.com/r/MachineLearning/comments/1c5f18/askml_pointers_towards_using_appropriate_nlp/,rightname,1365704511,"I want to use Natural Language Processing techniques in a Machine Learning problem. 

 The problem is to find how many upvotes a new comment in a website like reddit/Hacker News might get. Especially on the posts submitted in r/new. Other than the comment itself, I am also provided with meta-information about the user's comment karma, posts karma, her usual activity hours and how long she has been registered. 

My background is in Operations research, I have taken classes specializing in Statistics, Machine Learning,  Optimization Theory.  But I have no idea about text processing. I want to know where to start. And what would be appropriate techniques to quantify the usefulness of a comment. As much as I would like to learn NLP in depth, possible quick fixes will be really appreciated.  ",6,2
51,2013-4-12,2013,4,12,4,1c5kdl,Are there non-PhD jobs in Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/1c5kdl/are_there_nonphd_jobs_in_machine_learning/,natehotchkiss,1365708280,"I've been on the job search for a little while now. I know that I would like to something that would give me a chance to practice and learn more about machine learning. I'm struggling to find a job or internship that is not at the PhD level. So my question is, do they exist? Even if it was mostly grunt work, but you could sit in on a few meetings with the real clever people. Thanks!",29,13
52,2013-4-12,2013,4,12,12,1c6oc4,A Practical Intro to Data Science,https://www.reddit.com/r/MachineLearning/comments/1c6oc4/a_practical_intro_to_data_science/,zipfian,1365738294,,7,40
53,2013-4-12,2013,4,12,21,1c79i4,job market looks good...nytimes talks about the rising field of data science,https://www.reddit.com/r/MachineLearning/comments/1c79i4/job_market_looks_goodnytimes_talks_about_the/,drbabinski,1365769020,,8,20
54,2013-4-13,2013,4,13,6,1c8c4u,Using UMLS as a dictionary for Mahout vectorizer?,https://www.reddit.com/r/MachineLearning/comments/1c8c4u/using_umls_as_a_dictionary_for_mahout_vectorizer/,ptpatil,1365800606,"I am working on a project to apply machine learning to recommend disease diagnoses codes and relevant treatments to a doctor by training on a data set of hundreds of thousands of doctor's progress notes in XML.

I am interested in using Mahout for this and to convert the part structured, part free text data in each progress note to a large vector for word presence and presence count.

However, as this is a limited problem domain concerning medical text I want to use the Unified Medical Language System developed by the National Library of Medicine instead of the english dictionary used by default in Mahout to create codified/tokenized representations of the input text. 

Has anyone done this? If not the UMLS specifically, maybe an alternate dictionary for Mahout?

Any help is much appreciated, thanks in advance!

-PT",6,5
55,2013-4-13,2013,4,13,8,1c8mx8,Three new machine learning competitions for ICML 2013,https://www.reddit.com/r/MachineLearning/comments/1c8mx8/three_new_machine_learning_competitions_for_icml/,willis77,1365809607,"The tasks are interesting. I promise!

[The black box challenge](http://www.kaggle.com/c/challenges-in-representation-learning-the-black-box-learning-challenge)

[Multi-modal Learning](https://www.kaggle.com/c/challenges-in-representation-learning-multi-modal-learning)

[Learning facial expressions](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge)",20,29
56,2013-4-13,2013,4,13,10,1c8v8f,AskML: function/library/software that auto-fills missing values in a csv,https://www.reddit.com/r/MachineLearning/comments/1c8v8f/askml_functionlibrarysoftware_that_autofills/,binarysolo,1365817407,"Edit: forgot to mention: auto-fill missing values in incomplete data *for classicifaction/clustering type problems*

I don't really encounter this problem in my ML work, but I'm noticing this in Kaggle problems -- basically getting incomplete datasets that need to be sanitized or filled appropriately.

I wrote a few scripts (Python, R) to deal with the basic probs and it occurred to me that this might be useful to others.  Wanted to make sure this wasn't done and I'm reinventing the wheel.

Current simple use case: MLFill(""incomplete_file.csv"") -&gt; ensembles using RandomForestClassifier, goes through csv starting from the most-filled columns and working outwards -&gt; returns ""filled_file.csv"".

Obviously this has huge garbage in, garbage out potential, but I figured if extended further it could be interesting -- push it as a simple web service, or maybe show confidence levels of prediction.  Iono, someone else on Github can figure it out.

Besides, as a half-assed developer I can finally contribute something that's actually more up my alley.  It's either this or doing some Kaggle contests I guess. :)",7,1
57,2013-4-14,2013,4,14,7,1calf3,Where can I learn machine learning?,https://www.reddit.com/r/MachineLearning/comments/1calf3/where_can_i_learn_machine_learning/,Javi_in_1080p,1365893024,,19,9
58,2013-4-14,2013,4,14,16,1cbesu,Using PyMC to implement MCMC analysis for astrophysics research,https://www.reddit.com/r/MachineLearning/comments/1cbesu/using_pymc_to_implement_mcmc_analysis_for/,[deleted],1365925649,.,0,2
59,2013-4-15,2013,4,15,2,1cc07z,What is the state of the art in unsupervised image clustering?,https://www.reddit.com/r/MachineLearning/comments/1cc07z/what_is_the_state_of_the_art_in_unsupervised/,kurtgodelisdead,1365959502,"Is it worth building a business model around it, or it is still in heavy research mode?",16,15
60,2013-4-15,2013,4,15,17,1cdnao,"I see there are lots of great word-prediction software for mobile phone (like Swiftkey for Android, ...). I wonder if there is any for desktop environment?",https://www.reddit.com/r/MachineLearning/comments/1cdnao/i_see_there_are_lots_of_great_wordprediction/,knmaster,1366013724,,3,10
61,2013-4-16,2013,4,16,0,1ce7k5,Looking for info about machine learning for sound synthesis,https://www.reddit.com/r/MachineLearning/comments/1ce7k5/looking_for_info_about_machine_learning_for_sound/,justonium,1366040786,"Can anyone find any information about using machine learning algorithms to learn to predict the next sample in a sound file from the previous samples, and using the trained model to generate novel sound? In particular, I would like to hear audio files associated with any projects out there. I made a synthesizer that works this way, and the only sound I have ever heard produced like this are my own. I am sure there are others out there, but google has failed me.",8,16
62,2013-4-16,2013,4,16,6,1cf1kz,Speech Recognition Time-Frequency Feature Selection,https://www.reddit.com/r/MachineLearning/comments/1cf1kz/speech_recognition_timefrequency_feature_selection/,SpaceWizard,1366062755,"Speech Recognition can categorize spoken words well, but what features of the time frequency characteristics of speech are most useful in making discrimination between words/speech sounds on average? Are there any papers out there that show what effective speech systems are 'attending to' in the signal? I'd really like to see a 2d (imagesc style) plot where the x-axis is word onset to 1 second or so, and the y-axis is frequency, and colors in the plot are feature importance. Perhaps this exact plot doesn't exist or isn't practical because features are happening at very different times, but it's usually helpful to give a concrete example of what I'm looking for. I'd like to learn why this isn't practical if so as well. ",4,2
63,2013-4-16,2013,4,16,20,1cgdjo,2D visual pattern generation algorithm,https://www.reddit.com/r/MachineLearning/comments/1cgdjo/2d_visual_pattern_generation_algorithm/,[deleted],1366110395,"The algorithm I am interested in: takes a set of 2D black-and-white patterns and generates similar, but not exactly same patterns.

I was googling for this kind of algorithm for some time but can't quite find it. Thought you guys would know of it, or would know if maybe it does not even exist.",0,2
64,2013-4-17,2013,4,17,0,1cgsa5,XPLR UmbReddit : Explore subreddits graph [X-post /r/dataisbeautiful],https://www.reddit.com/r/MachineLearning/comments/1cgsa5/xplr_umbreddit_explore_subreddits_graph_xpost/,peeloo,1366126679,,2,2
65,2013-4-17,2013,4,17,1,1cgyjy,[META] Competitor in GE Quest claims Kaggle wrongdoing and reveals privately sent CEO (Anthony Goldbloom) response,https://www.reddit.com/r/MachineLearning/comments/1cgyjy/meta_competitor_in_ge_quest_claims_kaggle/,[deleted],1366131347,,0,1
66,2013-4-17,2013,4,17,3,1ch6zf,What's the canonical way to go about binarizing a set of input data for use in a neural network?,https://www.reddit.com/r/MachineLearning/comments/1ch6zf/whats_the_canonical_way_to_go_about_binarizing_a/,blindConjecture,1366137586,"For example, say I have a length n vector of continuous variables, where each variable falls within the range [0,1]. Now suppose that I want to convert such an input vector into a vector of 1's and 0's that I can feed into a neural network. What is the best way to go about doing this? Should I simply convert each of the n components into binary, and then concatenate them?",17,1
67,2013-4-17,2013,4,17,8,1chufj,Dataset containing meme name | top text | bottom text,https://www.reddit.com/r/MachineLearning/comments/1chufj/dataset_containing_meme_name_top_text_bottom_text/,taekwonbro,1366154655,,11,19
68,2013-4-17,2013,4,17,17,1citqh,Chinese Machine | Close to the Interesting Machine Parts and Machine Design,https://www.reddit.com/r/MachineLearning/comments/1citqh/chinese_machine_close_to_the_interesting_machine/,gaotaiwei,1366188948,,1,0
69,2013-4-17,2013,4,17,22,1cj4ov,TIL there's a probabilistic programming language called Church. Anyone here using it?,https://www.reddit.com/r/MachineLearning/comments/1cj4ov/til_theres_a_probabilistic_programming_language/,lenwood,1366205948,,16,30
70,2013-4-17,2013,4,17,23,1cj7jo,A Few Questions on GLMNET (x-post from /r/statistics),https://www.reddit.com/r/MachineLearning/comments/1cj7jo/a_few_questions_on_glmnet_xpost_from_rstatistics/,econometrician,1366208653,,0,0
71,2013-4-18,2013,4,18,0,1cjaa7,"Help, desperately trying to understand EM algorithm",https://www.reddit.com/r/MachineLearning/comments/1cjaa7/help_desperately_trying_to_understand_em_algorithm/,[deleted],1366210969,"Got an exam soon, and I can't make any sense of the EM algorithm. Anyone here understand it?",0,1
72,2013-4-18,2013,4,18,5,1ck2eu,Pulitzer prize given as a result of lengthy data-mining analysis on speeding police officers,https://www.reddit.com/r/MachineLearning/comments/1ck2eu/pulitzer_prize_given_as_a_result_of_lengthy/,bwana_singsong,1366230757,,1,13
73,2013-4-18,2013,4,18,8,1cki96,DAE think Denis Koller's Prob Graph Model class (coursera) tries to be straddle being intuitive and formal but somehow manages to be neither well and so does nothing well?,https://www.reddit.com/r/MachineLearning/comments/1cki96/dae_think_denis_kollers_prob_graph_model_class/,[deleted],1366241977,"Just started the online course but I'm not sure I'm going to continue it.  I don't like her teaching style.

I can't put my finger on it.  The examples aren't worked out much and their explanations seem to rely on a lot of intuition.  There's definitions but they are never applied, except in the most hand wavy of ways, to the examples.  I feel like I'm being asked to put together a puzzle with randomly selected pieces dumped onto the floor.  I'm not sure I wouldn't be better off just using a book.

Maybe this is just a start-up issue (the class just started its second week) and as stuff sinks in I won't feel this way.",10,7
74,2013-4-18,2013,4,18,12,1cl2k2,The 2013 KDD Cup: Author-Paper Identification in the Microsoft Academic Search Dataset,https://www.reddit.com/r/MachineLearning/comments/1cl2k2/the_2013_kdd_cup_authorpaper_identification_in/,willis77,1366257478,,2,18
75,2013-4-18,2013,4,18,22,1clpq8,A short introduction to Gradient Boosting Machine in Python,https://www.reddit.com/r/MachineLearning/comments/1clpq8/a_short_introduction_to_gradient_boosting_machine/,hltt,1366290122,,0,1
76,2013-4-19,2013,4,19,1,1cm2cd,How long is the average dissertation?,https://www.reddit.com/r/MachineLearning/comments/1cm2cd/how_long_is_the_average_dissertation/,talgalili,1366301292,,0,1
77,2013-4-19,2013,4,19,5,1cmnqg,"""""Principal Component Analysis"" is a dimensionally invalid method.""",https://www.reddit.com/r/MachineLearning/comments/1cmnqg/principal_component_analysis_is_a_dimensionally/,[deleted],1366316567,,0,2
78,2013-4-19,2013,4,19,8,1cn29p,"Fast, Accurate Detection of 100,000 Object Classes on a Single Machine",https://www.reddit.com/r/MachineLearning/comments/1cn29p/fast_accurate_detection_of_100000_object_classes/,marshallp,1366326361,,4,34
79,2013-4-19,2013,4,19,9,1cn6sd,ML/DM/DS for non-CS PhDs,https://www.reddit.com/r/MachineLearning/comments/1cn6sd/mldmds_for_noncs_phds/,bwgroff,1366329766,"Hey all,

I'm finishing a PhD in pure math soon and machine learning and data science (whatever that means today) is the direction that I'm really interested in taking my career. The issue is that I'm really worried that my pure math background is not a perfect fit and employers are going to prefer a CS degree. 

I know a fair amount of programming, mostly in Python (using IPython, NumPy, SciPy, pandas). As an example. I spent some time figuring out [exactly how Ayasdi Iris works](http://bwgroff.wordpress.com/2013/04/13/the-reeb-graph-and-topological-data-analysis/) and writing my own less colorful version. I'm also spending a lot of time (whatever is left over from working on my thesis anyway) learning statistics and ML techniques. 

So what's the market for someone with an almost-fit like me? What about specifically in the DC area (no wiggle room on this one - fiance has a job there)? I know things are tight with the slow recovery of the economy so I'd really like to know what I'm up against.

Thanks!",6,6
80,2013-4-19,2013,4,19,9,1cn831,How do you compare related but different text corpora?,https://www.reddit.com/r/MachineLearning/comments/1cn831/how_do_you_compare_related_but_different_text/,satsatsat,1366330717,"What are some methods to compare related but different text corpora:
eg. 1. Product reviews of say 5 different models/versions of the same product (possibly by the same manufacturer). 
2. Product reviews of the same product, but by say 5 different age-groups.
I've used 5 related-but-different corpora in each case, but pairwise comparisons are fine too. 

Examples of what I meant by compare:
* find n-grams that tend to be used more in 1 group over the other
* find n-grams that seem to be used with the same frequency across groups

A pairwise comparison would compare, say Group 1 vs Group 2 (and ignore Groups 3 thru 5)",4,0
81,2013-4-19,2013,4,19,15,1cnysg,A New Way to Visualize Decision Trees,https://www.reddit.com/r/MachineLearning/comments/1cnysg/a_new_way_to_visualize_decision_trees/,ciskothekid,1366353212,,5,59
82,2013-4-20,2013,4,20,4,1coxzl,"Course materials for ""Data and Computing Fundamentals (using R)""",https://www.reddit.com/r/MachineLearning/comments/1coxzl/course_materials_for_data_and_computing/,talgalili,1366398642,,0,2
83,2013-4-21,2013,4,21,5,1crei7,Help needed with Bayesian Spectral Analysis,https://www.reddit.com/r/MachineLearning/comments/1crei7/help_needed_with_bayesian_spectral_analysis/,BayesianSpoon,1366490407,"I have recently discovered Larry Bretthorst's article on  [Bayesian Spectral Analysis](http://bayes.wustl.edu/glb/excerpts.pdf) and I'm trying it out. I'm struggling with making the method able for use to detect multiple harmonic signals though. Can anyone point me somewhere I would be able to get some example code for BSA or be able to help me? Much appreciated.

More detail: I'm particularly struggling with harmonic signals that have close frequencies. As input I have two signals with very little noise that are far apart (w1 and w2 frequencies). The output I get suggests it is just as likley that there are two very close frequencies near w1 or two very close frequencies near w2 respectively as it is that there is a frequency at w1 and w2.

Edit: Here is my [output](http://i.imgur.com/vHwrVU8h.png) which suggests two very close frequencies at either 0.2 and 0.8 hertz/sample is more likely than two signals at 0.2 and 0.8 hertz/sample respectively. [Here](http://i.imgur.com/qbN3Hajh.png) is a closeup of 0.2 hertz/sample. It would seem that the probability of two signals on top of one another at 0.2 hertz per sample is low but then the probability shoots up around that area. Very strange and likely not correct. I would expect [this](http://i.imgur.com/a4iQxlw.jpg) output, but with a function that decreases the probability by 0.5 on the diagonal and gradually less as one moves away from the diagonal.",5,18
84,2013-4-21,2013,4,21,22,1csr75,Open source library to perform texture classification with multifractal dimensions,https://www.reddit.com/r/MachineLearning/comments/1csr75/open_source_library_to_perform_texture/,galapag0,1366551304,,0,5
85,2013-4-22,2013,4,22,2,1ct3r8,Read dreams with support vector machines,https://www.reddit.com/r/MachineLearning/comments/1ct3r8/read_dreams_with_support_vector_machines/,the_mind_is_a_sponge,1366564878,,2,23
86,2013-4-23,2013,4,23,2,1cvgqj,Machine Learning Susses Out Social-Network Fraud,https://www.reddit.com/r/MachineLearning/comments/1cvgqj/machine_learning_susses_out_socialnetwork_fraud/,ciskothekid,1366650905,,1,1
87,2013-4-23,2013,4,23,2,1cvizd,Machine Learning Phd/Postdoc/Job message boards,https://www.reddit.com/r/MachineLearning/comments/1cvizd/machine_learning_phdpostdocjob_message_boards/,directionMapping,1366652567,"I recently discovered the Imageworld mailing list http://lists.diku.dk/pipermail/imageworld/
which looks great for finding phd/postdoc/job positions in computer vision. I was wondering if anyone knew of other mailing lists like this, possibly for other machine learning areas or a more general one for machine learning.
",4,3
88,2013-4-23,2013,4,23,8,1cwdp8,Andrew Ng's Coursera machine learning course starts today!,https://www.reddit.com/r/MachineLearning/comments/1cwdp8/andrew_ngs_coursera_machine_learning_course/,dhammack,1366674481,,0,2
89,2013-4-23,2013,4,23,10,1cwla8,Really excited to share this - Using Neural Networks and 'luck' to predict who will win in the NHL,https://www.reddit.com/r/MachineLearning/comments/1cwla8/really_excited_to_share_this_using_neural/,DarkSareon,1366680172,,50,38
90,2013-4-23,2013,4,23,14,1cx2l8,Anyone else doing Andrew Ng's Coursera course on machine learning?,https://www.reddit.com/r/MachineLearning/comments/1cx2l8/anyone_else_doing_andrew_ngs_coursera_course_on/,K_Interesante,1366694060,"The class started today. You can sign up [here](https://www.coursera.org/course/ml) (it is free). /r/mlclass has been a sort of subreddit/study group for it in the past, it seems, and I assume it could fill that purpose again this time around. Anyway, I signed up for it and I'm pretty stoked for it. :D",34,64
91,2013-4-23,2013,4,23,20,1cxhkv,"McNemar's test - Wikipedia, the free encyclopedia",https://www.reddit.com/r/MachineLearning/comments/1cxhkv/mcnemars_test_wikipedia_the_free_encyclopedia/,flamingsushi,1366717775,,0,0
92,2013-4-23,2013,4,23,21,1cxkp9,Join The Foundation for Open Access Statistics!,https://www.reddit.com/r/MachineLearning/comments/1cxkp9/join_the_foundation_for_open_access_statistics/,talgalili,1366721667,,0,3
93,2013-4-23,2013,4,23,23,1cxqsq,Benchmarking RL Agents,https://www.reddit.com/r/MachineLearning/comments/1cxqsq/benchmarking_rl_agents/,SevrenBG,1366727547,"Hey reddit, 

I am currently learning about reinforcement learning agents and Python.  I am at the point where I would like to explore benchmarking between various agents on a set of problems(mostly pertaining to mountain car, pole balancing and mazes) is there a package that lets me do this easily? 

I have heard of PyBrain and MMLF as well as RLGlue but digging around is confusing me quite a bit. 

What I have so far is: some agents coded in python(Numpy) not using any Machine learning libraries. I have created some quick tests to run the agents on with XOR tasks 

but now I want to be able to ""plugin"" my agents with some other tasks, such as the above. I assume I will need a bridge or an interface but the trick is how I can connect the task coded using the pyBrain library to my agent. I think RL Glue is supposed to take care of this but the documentation is scarce on using PyBrain tasks with it.

Any ideas or suggests for some other packages? They must be compatible with Python.

Thanks",1,2
94,2013-4-25,2013,4,25,2,1d0t2d,Restricted Boltzmann Machines vs Denoising Autoencoders for Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/1d0t2d/restricted_boltzmann_machines_vs_denoising/,rudyl313,1366824936,"It's my understanding that the Renaissance of Deep Neural Networks is fueled by initializing the weights (as apposed to setting them randomly) through unsupervised pretraining. The most popular technique appears to be greedily stacking Restricted Boltzmann Machines, but I noticed that Andrew Ng has a lot of research involving stacking Denoising Autoencoders instead.

So, I'm wondering: is one technique more powerful than the other? Are there pros and cons for choosing RBMs over Denoising Autoencoders, and vice versa?",0,2
95,2013-4-25,2013,4,25,7,1d1h64,Click on a few dots and this program will guess your age!,https://www.reddit.com/r/MachineLearning/comments/1d1h64/click_on_a_few_dots_and_this_program_will_guess/,[deleted],1366841907,Pretty close for me,0,1
96,2013-4-25,2013,4,25,21,1d2tyg,Anyone here actually use SAS Enterprise Miner?,https://www.reddit.com/r/MachineLearning/comments/1d2tyg/anyone_here_actually_use_sas_enterprise_miner/,Ju11ian,1366892779,"This company I'm doing ML type work for dropped an ungodly amount of money on seat licenses for SAS Enterprise Miner.  

Like many of you, I tend to code up solutions.  This however, looks point and click, but is complicated enough that I'd need to spend some serious time learning how to use it.

For those of you who have already tried it, is it worth the investment time in terms of learning it?  Or, as I suspect, does the point and click nature of it oversimplify?   ",0,2
97,2013-4-26,2013,4,26,2,1d3dai,Classier Chains for Multi-label Classication - A nice multi-label classification -&gt; binary classification reduction,https://www.reddit.com/r/MachineLearning/comments/1d3dai/classier_chains_for_multilabel_classication_a/,rrenaud,1366909386,,2,20
98,2013-4-26,2013,4,26,2,1d3hox,Help needed with RNN for music composition,https://www.reddit.com/r/MachineLearning/comments/1d3hox/help_needed_with_rnn_for_music_composition/,Tiomaidh,1366912583,"I'm trying to create a music composer using an LSTM RNN, much like [Doug Eck has](http://www.idsia.ch/~juergen/blues/index.html) but for more melodically-complex music (18th century Scottish dance tunes).

The corpus spans 34 notes, so I've written a library that parses the input files into vectors of length 34. The network I'm using has 34 input nodes and 34 output nodes--each one corresponds to a note, with 1 meaning the note is played and 0 meaning it's not. This is what Eck did.

For the actual training, I'm using PyBrain. My code is below. The problem is that the network gets stuck on a certain note (22), and after a few (&lt;5) steps will only predict that. I think that this is because I'm not training it with explicit time information--it has no real concept of what's come before (which defeats the point of having the memory provided by LSTM). But I've done a lot of searching about how to get around this, and so far am stumped. I thought about introducing new nodes to represent the time variable explicitly, but that sounded like a really bad idea since the network wouldn't know the difference between those and the note nodes.

I feel like I went through this really quickly--please let me know if you have any questions or want more information. Thanks!

    #!/usr/bin/python
    from pybrain.datasets import SequentialDataSet
    from pybrain.supervised.trainers import BackpropTrainer
    from pybrain.tools.shortcuts import buildNetwork
    from pybrain.structure import SigmoidLayer
    from pybrain.structure.modules.lstm import LSTMLayer
    
    import glob
    
    INPUTS = 34
    HIDDEN = 25
    OUTPUTS = 34
    
    network = buildNetwork(INPUTS, HIDDEN, OUTPUTS, hiddenclass=LSTMLayer, outclass=SigmoidLayer, recurrent=True)
    ds = SequentialDataSet(INPUTS, OUTPUTS)
    
    def to_bitmask(i): x = [0.0] * INPUTS; x[i] = 1.0; return tuple(x)
    
    files = glob.glob('l16_1d/*.csv')
    tunes = []
    for filename in files: #tune
    	with open(filename) as f:
    		notes = map(int, map(str.strip, f.readlines()))[::2]
    		bitmasks = map(to_bitmask, notes)
    		tunes.append(bitmasks)
    
    for tune in tunes:
    	for (inp, target) in zip(tune, tune[1:]):
    		ds.newSequence()
    		ds.appendLinked(inp, target)
    
    network.randomize()
    
    trainer = BackpropTrainer(network, ds, learningrate=.05, momentum=.99)
    import time
    print ""training...""
    try:
      for i in range(200):
        print ""%d\t%f""%(i, trainer.train())
    except KeyboardInterrupt:
    	pass
    
    import pickle
    with open('network3.pickled', 'w') as f:
    	pickle.dump(network, f)
",0,2
99,2013-4-26,2013,4,26,4,1d3n2i,Non-technical(ish) machine learning books,https://www.reddit.com/r/MachineLearning/comments/1d3n2i/nontechnicalish_machine_learning_books/,the_mind_is_a_sponge,1366916486,"Today I was talking with a neuroscientist and she explained that she would like some reference that explains what she might be able to do with machine learning. All the books I have read have been highly technical so I couldn't recommend any. Does anyone know of such books, articles, or other references? It's ok if the reference has technical parts, but she is looking for a ref which would also have high level explanations of the different types of machine learning tasks.

Thanks!",6,7
100,2013-4-26,2013,4,26,8,1d49vq,[Followup] Using PCA to produce,https://www.reddit.com/r/MachineLearning/comments/1d49vq/followup_using_pca_to_produce/,[deleted],1366933245,"I saw [VodkaRocks4Breakfast's post a few weeks ago,](http://www.reddit.com/r/MachineLearning/comments/1byzvt/using_pca_to_produce_a_black_and_white_grayscale/) and I remembered it today when I needed to grayscale some images. I made a simple matlab function to do this, so I thought I would make it available for anyone else who might be interested:

    function imGray = rgb2grayPCA(imRGB)
    % Use Principal Components Analysis to convert an RGB image to grayscale
    	
    	% Reshape RGB image to column vectors of each color
    	[y x z] = size(imRGB);
    	imRGB = reshape(imRGB, [ x*y z ]);
    	
    	% Get PC's of image
    	imRGB = double(imRGB);
        [PC V] = eig(cov(imRGB));
        [~, iV] = sort(diag(V),1,'descend');
        PC = PC(:,iV);
    	
    	% Use PC's to create grayscale image
    	imGray = imRGB*PC;
    	imGray = imGray(:,1);
    	
    	% Convert grayscale image to 8-bit integer
    	imGray = imGray - min(imGray);
    	imGray = imGray / max(imGray) * 255;
    	imGray = uint8(imGray);
    	
    	% Reshape grayscale image to dimensions of original RGB image
    	imGray = reshape(imGray, [ y x ]);
    	
    end",0,1
101,2013-4-26,2013,4,26,8,1d4an2,[Followup] Using PCA to produce a black and white (grayscale) photo,https://www.reddit.com/r/MachineLearning/comments/1d4an2/followup_using_pca_to_produce_a_black_and_white/,amemut,1366933852,"I saw [VodkaRocks4Breakfast's post a few weeks ago,](http://www.reddit.com/r/MachineLearning/comments/1byzvt/using_pca_to_produce_a_black_and_white_grayscale/) and I remembered it today when I needed to grayscale some images. I made a simple matlab function to do this, so I thought I would make it available for anyone else who might be interested:

    function imGray = rgb2grayPCA(imRGB)
    % Use Principal Components Analysis to convert an RGB image to grayscale
    	
    	% Reshape RGB image to column vectors of each color
    	[y x z] = size(imRGB);
    	imRGB = reshape(imRGB, [ x*y z ]);
    	
    	% Get PC's of image
    	imRGB = double(imRGB);
        [PC V] = eig(cov(imRGB));
        [~, iV] = sort(diag(V),1,'descend');
        PC = PC(:,iV);
    	
    	% Use PC's to create grayscale image
    	imGray = imRGB*PC;
    	imGray = imGray(:,1);
    	
    	% Convert grayscale image to 8-bit integer
    	imGray = imGray - min(imGray);
    	imGray = imGray / max(imGray) * 255;
    	imGray = uint8(imGray);
    	
    	% Reshape grayscale image to dimensions of original RGB image
    	imGray = reshape(imGray, [ y x ]);
    	
    end",2,5
102,2013-4-26,2013,4,26,8,1d4ap3,Machine Learning and Link Spam: My Brush With Insanity,https://www.reddit.com/r/MachineLearning/comments/1d4ap3/machine_learning_and_link_spam_my_brush_with/,[deleted],1366933891,,0,1
103,2013-4-26,2013,4,26,12,1d4qmi,Question for those familiar with Simon Funk's incremental SVD method...,https://www.reddit.com/r/MachineLearning/comments/1d4qmi/question_for_those_familiar_with_simon_funks/,YaoPau,1366946470,"I'm trying to implement this for a ratings dataset that's similar to Netflix, and I've gotten it to ""work"", in that the training error is driven toward 0 after each iteration / more features are added.

My question is, how do I determine how well this will predict a test dataset (of users with a handful of ratings that weren't used for training)?  Funk glosses over that part and it's really confusing me.

My thought process: you start with the following matrices:

* (1) User Feature Matrix (Users x Num_Features)

* (2) Movies Feature Matrix (Movies x Num_Features)

* (3) Ratings Matrix (Movies x Users)

And so the only way to update the first two matrices is by updating them iteration by iteration in the algorithm.  I don't think you can train those matrices, AND THEN introduce a completely new user afterwards and estimate what his feature matrix looks like.

What I've tried now is removing 20% of the ratings from the Rating Matrix, moving them into a Test Matrix, and filling in all the empty cells in both with 0's (which are ignored in the cost function).  It's not working.  
",4,9
104,2013-4-26,2013,4,26,14,1d4zsu,Reddit! Spare some clicks? Gathering manual Twitter sentiment classifications. Feedback appreciated.,https://www.reddit.com/r/MachineLearning/comments/1d4zsu/reddit_spare_some_clicks_gathering_manual_twitter/,[deleted],1366955704,,0,1
105,2013-4-26,2013,4,26,23,1d5k99,Thesis Machine Learning,https://www.reddit.com/r/MachineLearning/comments/1d5k99/thesis_machine_learning/,[deleted],1366985613,"I have to choose my thesis for my masters degree in ""Civil Engineering: Computer Science"".

I'm interested in having a thesis on the Machine Learning subject.

Maybe Reddit can help me with a suggestion for a specific topic?",4,0
106,2013-4-27,2013,4,27,1,1d5ukv,Don't forget that UW's Introduction to Data Science (Coursera) starts 5/1. An excellent concurrent complement to Andrew Ng's ML class.,https://www.reddit.com/r/MachineLearning/comments/1d5ukv/dont_forget_that_uws_introduction_to_data_science/,edomo,1366993987,,12,38
107,2013-4-27,2013,4,27,4,1d68qa,Trying to solve the extra-credit for the coursera machine learning course wk1/2.. cannot get J(theta) to converge,https://www.reddit.com/r/MachineLearning/comments/1d68qa/trying_to_solve_the_extracredit_for_the_coursera/,eof,1367004835,"code is here:  https://pastee.org/u878p

(full code is here)

https://github.com/gdoteof/machine_learning_week1


J(Theta) is oscillating between ~0 and 6.2e6



The way they have you do the homework you can verify that other parts of it work fine and everything builds on the piece from before.  So I am pretty sure the error must be in the pastie i linked above.. but I have checked and double and triple (etc) checked that I am doing the algorithm right.. and it seems like I am but obviously something is wrong.

Normally I turn to IRC for support but this seems a bit too nichey and I am not able to get help in there.. thanks",5,2
108,2013-4-27,2013,4,27,6,1d6inu,"Is supervised classification a ""solved"" problem?",https://www.reddit.com/r/MachineLearning/comments/1d6inu/is_supervised_classification_a_solved_problem/,Jeremymia,1367012689,"Assume we have infinite training data, where each feature has unknown correlations with other features. Have we already perfectly solved the problem of assigning class based on this data?

For example, is an SVM using the kernel trick for feature selection going to create the optimal answer based on the data?",11,7
109,2013-4-27,2013,4,27,21,1d7oko,How serious is Andrew Ng's Coursera course?,https://www.reddit.com/r/MachineLearning/comments/1d7oko/how_serious_is_andrew_ngs_coursera_course/,shogun333,1367066448,,27,26
110,2013-4-28,2013,4,28,3,1d87be,Yann LeCun on Deep Learning and Graphical Models,https://www.reddit.com/r/MachineLearning/comments/1d87be/yann_lecun_on_deep_learning_and_graphical_models/,rrenaud,1367087299,,0,20
111,2013-4-28,2013,4,28,3,1d899i,"Google have this week been granted a very broad patent on using Machine Learning on phones. I have an app that does exactly this, published before they filed their application. What do?",https://www.reddit.com/r/MachineLearning/comments/1d899i/google_have_this_week_been_granted_a_very_broad/,ohell,1367089102,"[My app uses machine learning to predict people you are likely to call](https://play.google.com/store/apps/details?id=in.lipik.ai_dial), as a way of enhancing the phone dialer.

[Google's shiny new patent](http://www.google.com/patents/US8429103) gives them the exclusive right to use machine learning on phones (claim 1). Amongst other things, they claim it can be used to predict people you are likely to call (claim 9).

I know about not being evil etc, but this is such a broad patent - and not really novel. I am struggling to understand how a non-evil researcher/engineer would have written the application (I never considered my app to contain anything patentable) - they have essentially claimed rights to the use of machine learning services on phones. So, nobody can make an adaptive app for and phone platform, if Google objects!

I know about the rational for defensive patenting, but still, they have claimed an invention where none exists (they do not have any demonstrated products using this yet - and even if they did, it would not really be invention), and they have subjected all AI implementers to seek their consent before developing!

I am not in America, but my app is on app store. I am wondering what would be the best course of action to take? Ideally, I'd like to show my app as very obvious prior art, and get them to donate the patent to EFF or something.

**Edit**: [I am not that concerned about getting sued, etc. More astonished at the breadth of this patent](/r/MachineLearning/comments/1d899i/google_have_this_week_been_granted_a_very_broad/c9nxvmr).",46,119
112,2013-4-28,2013,4,28,4,1d8b90,"What are your thoughts on ""Deep Learning""?",https://www.reddit.com/r/MachineLearning/comments/1d8b90/what_are_your_thoughts_on_deep_learning/,inspired2apathy,1367090869,"I've read a bit about deep learning, and it seems quite compelling.  Basically, we finally figured out how to train the kinds of feedback networks everyone was excited about in the 70s.  And surprise, they're awesome.  What are your thoughts?
* Great for feature extraction/dimensionality reduction?
* Great for supervised learning?
* Great for unsupervised learning?
* Interesting, but too finicky to rely on?
* Effective, but difficult to intuit/trust so unsuitable for business applications?

I've felt all these things at various times about neural networks.  They're neat, and when they work it's impressive, but I've had trouble in the past with them being extremely finicky about learning rates/configuration, and they seem potentially difficult to debug and I could have trouble trusting them when reliability really mattered.",18,18
113,2013-4-28,2013,4,28,10,1d8yiq,What are your opinions on regression by classification?,https://www.reddit.com/r/MachineLearning/comments/1d8yiq/what_are_your_opinions_on_regression_by/,rwdalpe,1367112708,"When attempting to learn and predict a numerical value, what are your opinions on regression by classification--where you train a set of binary classifiers to identify if a sample has a price above a certain threshold. For example, predicting an auction sale price and having a classifier for samples with a price above $5, $10, etc, and then using the results of those classifiers to select a most likely range for a sample.",0,2
114,2013-4-29,2013,4,29,6,1dan0n,Help! Extra credit for my ML class is to determine who this man is.,https://www.reddit.com/r/MachineLearning/comments/1dan0n/help_extra_credit_for_my_ml_class_is_to_determine/,Melo_,1367185351,,5,0
115,2013-4-29,2013,4,29,7,1dashi,Machine Learning Counterexamples,https://www.reddit.com/r/MachineLearning/comments/1dashi/machine_learning_counterexamples/,HootBack,1367189894,,8,27
116,2013-4-29,2013,4,29,15,1dbnrb,Need advice: Very small sample,https://www.reddit.com/r/MachineLearning/comments/1dbnrb/need_advice_very_small_sample/,m1sta,1367216678,"I'm looking for advice. I'm trying to predict the question mark using the following tiny data set.
 
    Tag1 Tag2 Tag3 Tag4	Score
    1	 0    0	   0	2000
    1	 0    0	   1	2400
    0	 1    0	   0	3000
    0	 1    0	   1	3600
    0	 0    1	   0	4000
    0    0    1    1    ?
 
I'm expecting the answer to be 4800. I'm very new to this space. I've tried a quick linear regression algorithm but the results aren't great. I've tried a simple neural network but I appreciate that I don't have enough samples to allow this approach to work. 
 
I feel like my options now are to either find another approach or invest the time in understanding how to apply one of the two approaches that I have tried so properly. Any advice at all would be appreciated.",12,13
117,2013-4-29,2013,4,29,22,1dc5bb,Our tiny startup just won back the title of worlds most accurate noun-sense disambiguator!,https://www.reddit.com/r/MachineLearning/comments/1dc5bb/our_tiny_startup_just_won_back_the_title_of/,tal-rotbart,1367243517,,0,3
118,2013-4-30,2013,4,30,1,1dcegi,Maxent for feature induction?,https://www.reddit.com/r/MachineLearning/comments/1dcegi/maxent_for_feature_induction/,wildething,1367251401,"Problem: classifying reddit posts by subreddit based on the text in the post title. I have ~3000 labeled posts taken from /r/all over the last two weeks (about 1/3 of them are from r/funny).

This is my first text classification project ever (I am a whippersnapper). That said:

I've tried NLTK's Naive Bayes classifier with lots of different feature configs, never got better than 50% accuracy. Just for fun I tried NTLK's Maxent classifier and now I'm getting about 52%.

I've tried to read about Maxent (Jurafsky&amp;Martin, Manning&amp;Schutze, etc.) but I still just don't really get how Maxent works (but I have by no means given up).

Mostly, my question is: I've head Maxent does something called feature induction? What is feature induction, how does it work, and how would I make NLTK's Maxent do it?

(Also, do I have enough data yet?)


Edit: more details:

* I'm only classifying between /r/funny and /r/AdviceAnimals because those are by far the biggest ""bins"" (just trying to keep it simple)
* I'm using the top 20 most frequent words from each subreddit as features (e.g. if the post contains the word ""funny"" then features[""contains 'funny'""] = 1)
* My test data is 20% of total, training is 80%",0,2
119,2013-4-30,2013,4,30,4,1dcw4k,Alternatives to Bag of Words representation for text documents?,https://www.reddit.com/r/MachineLearning/comments/1dcw4k/alternatives_to_bag_of_words_representation_for/,dhammack,1367264353,"I've seen in literature and practice that most machine learning systems in the text domain use Bag-of-Words representation of data. Is this really the best option? 

I really think we can come up with something better, BOW is extremely naive and throws away a ton of useful information.",13,19
120,2013-4-30,2013,4,30,21,1deofm,Numenta will open source their core algorithms,https://www.reddit.com/r/MachineLearning/comments/1deofm/numenta_will_open_source_their_core_algorithms/,numenta,1367326507,,33,74
