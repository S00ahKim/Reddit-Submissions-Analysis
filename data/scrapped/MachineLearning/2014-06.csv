,sbr,sbr_id,date,year,month,hour,day,id,domain,title,full_link,author,created,selftext,num_comments,score,over_18,thumbnail,media_provider,media_thumbnail,media_title,media_description,media_url
0,MachineLearning,t5_2r3gv,2014-6-2,2014,6,2,11,272tpr,fastml.com,FastML TL;DR for Yann Lecun's AMA,https://www.reddit.com/r/MachineLearning/comments/272tpr/fastml_tldr_for_yann_lecuns_ama/,xamdam,1401675874,,5,31,False,default,,,,,
1,MachineLearning,t5_2r3gv,2014-6-2,2014,6,2,16,273e6i,machineryequipment123.blogspot.com,The Working Principle Of Road Grader - Machinery &amp; Equipment Part Online,https://www.reddit.com/r/MachineLearning/comments/273e6i/the_working_principle_of_road_grader_machinery/,jessicperson,1401692727,,0,1,False,default,,,,,
2,MachineLearning,t5_2r3gv,2014-6-2,2014,6,2,21,273t9d,self.MachineLearning,Must-reads in ML literature,https://www.reddit.com/r/MachineLearning/comments/273t9d/mustreads_in_ml_literature/,InfinityCoffee,1401711685,"There are a wealth of online and offline resources on machine learning. What works do you think every student of machine learning should acquaint himself with? 

I think Bishop's **Pattern Recognition and Machine Learning** is an amazing introductory textbook which definitely warrants a place on a list of must-reads, and I also think that Hastie and Tibshiranis **Elements of Statistical Learning** deserves a spot. But I am fairly new to the field, so I am keen to hear what you think.
Influential articles are welcome too. ",13,23,False,self,,,,,
3,MachineLearning,t5_2r3gv,2014-6-3,2014,6,3,0,2747tp,self.MachineLearning,Are there any good books or resources on EEG pattern recognition?,https://www.reddit.com/r/MachineLearning/comments/2747tp/are_there_any_good_books_or_resources_on_eeg/,mrboombastic123,1401722450,,3,6,False,self,,,,,
4,MachineLearning,t5_2r3gv,2014-6-3,2014,6,3,1,274cdr,self.MachineLearning,Anyone aware of a GPU boosted regression tree implementation. Seems a logical and an easy enough thing to do,https://www.reddit.com/r/MachineLearning/comments/274cdr/anyone_aware_of_a_gpu_boosted_regression_tree/,dethpicable,1401725212,"They train pretty fast to begin with and, for training, at each new tree node a portion of the observation matrix is evaluated 1 feature at a time.  Unlike bagging, the trees can't be trained in parallel, but  I would think because a merit function is evaluated 1 feature at a time (i.e. looping through each feature), each feature (i.e. column of the current node's observation matrixe) could be sent to a different GPU and return the position and merit of its best dividing point.  Then a simple max on the merit values returned across all the GPUs/features ( vector 1 element per feature as returned by a GPU) does the trick.  As I recall, all other operations are insignificant from a computational expense point of view.

I would think this would result in a nearly linear speed increase maxing out at the number of GPU cores or features, which ever is less.  I would think, the GPU code would be trivial (e.g. sort a feature vector and eval a merit function on that.)  This small routine could be buried in any standard implementation (i.e. it's just a small part of the tree, the rest of the tree code not to mention all the boosting would be generic/nonGPU as desired)

...and yet I can't seem to find a cuda version.  Am I missing something.
",7,2,False,self,,,,,
5,MachineLearning,t5_2r3gv,2014-6-3,2014,6,3,1,274eir,engineering.richrelevance.com,Bandit Algorithms for Recommendation Systems,https://www.reddit.com/r/MachineLearning/comments/274eir/bandit_algorithms_for_recommendation_systems/,sergeyfeldman,1401726457,,4,30,False,http://a.thumbs.redditmedia.com/H0sqwd0nlGZ5JNRf.jpg,,,,,
6,MachineLearning,t5_2r3gv,2014-6-3,2014,6,3,1,274fnl,self.MachineLearning,ML Perspectives: Engineering vs Statistics? Choosing Masters program,https://www.reddit.com/r/MachineLearning/comments/274fnl/ml_perspectives_engineering_vs_statistics/,tensorstrength,1401727142,"Hi everyone, I was wondering what way Electrical Engineers approach ML vs. how Statisticians do. I know that conventionally ML is under computer science, but I am trying to choose between EE and Stats as I am interested in the overlapping areas of the fields. How do the two areas differ in how they use ML?



",8,1,False,self,,,,,
7,MachineLearning,t5_2r3gv,2014-6-3,2014,6,3,2,274ns8,medium.com,Sway Trained Sinus Activated Neural Networks - Monte Carlo Exploration of Optimization Volumes,https://www.reddit.com/r/MachineLearning/comments/274ns8/sway_trained_sinus_activated_neural_networks/,[deleted],1401731962,,21,0,False,http://a.thumbs.redditmedia.com/378iGQVSGOr-MAM0.jpg,,,,,
8,MachineLearning,t5_2r3gv,2014-6-3,2014,6,3,9,275qaj,self.MachineLearning,Good approach for Job Titles Clustering?,https://www.reddit.com/r/MachineLearning/comments/275qaj/good_approach_for_job_titles_clustering/,manueslapera,1401754592,"On my job i have a dateset of more than 10K job titles. I would like to cluster them into a smaller dataset. 

I have tried the approaches for clustering available in [OpenRefine](https://github.com/OpenRefine/OpenRefine/wiki/Clustering-In-Depth), as well as a modifed clustering using Jaccard's similarity.

I managed to cluster the titles into a smaller dataset, however, I was wondering if any fellow wants to recommend me a better approach.",2,0,False,self,,,,,
9,MachineLearning,t5_2r3gv,2014-6-3,2014,6,3,11,2762ji,self.MachineLearning,Clustering algorithm for gps data,https://www.reddit.com/r/MachineLearning/comments/2762ji/clustering_algorithm_for_gps_data/,randmars,1401762688,"I have a data set consisting of gps coordinates for points over a particular city (let's take San Francisco for example). I want to cluster the coordinates into groups such as in the image:
http://imgur.com/iizKtLr

Should I use k-means or DBSCAN or some other clustering algorithm? Should I find the clusters first and then find the border points to draw the boundaries?",5,3,False,self,,,,,
10,MachineLearning,t5_2r3gv,2014-6-3,2014,6,3,13,276dg4,self.MachineLearning,"SVM predicts single value, trained on real data. Trying to predict using simulated data.",https://www.reddit.com/r/MachineLearning/comments/276dg4/svm_predicts_single_value_trained_on_real_data/,work_phriendly,1401770528,"Hey All, I've trained a svm model using the e1071 svm() function in R. 

When testing using my test set, I get fairly good results in my eyes. It doesn't have to be perfect and the average error is around 1.2 units. For these purposes, this is more than acceptable. 

My problem is I'm trying to use this model to predict new Values, however every time I run it I only get one value in return. 6.77523. 

This is beyond frustrating. I'll be upfront and admit that I'm sorta poking around in the dark here. As in I have little formal training in this, I have a strong Math background but not much statistics. 

I'm thinking it's very possible that my simulated data is not being constructed properly. That perhaps some values in my simulated are not actually simulating the real world, and thus not giving accurate values. But What I can't understand is why am I getting this single value? It would be one thing if I was just getting unrealistic values, but my simulated data has variation, I've randomly generated everything I felt fits a firm distribution and use averages (that are usually multiplied against a randomly generated value). It's getting late local time so I can't post any data I'm using at the moment but I'm stumped. 

Is it possible that one feature is exerting a disproportional influence and this is what is flattening out my predictions?

It would be one thing if this was predicting a growing line, as the values grow over time, but this is simply predicting 6.77523 for every entry and I don't know where to begin. ",8,0,False,self,,,,,
11,MachineLearning,t5_2r3gv,2014-6-3,2014,6,3,17,276r3o,eric-kim.net,Detailed explanation of the kernel trick,https://www.reddit.com/r/MachineLearning/comments/276r3o/detailed_explanation_of_the_kernel_trick/,larsga,1401785230,,6,81,False,http://b.thumbs.redditmedia.com/iYcKSwNnQzD2ZbwO.jpg,,,,,
12,MachineLearning,t5_2r3gv,2014-6-3,2014,6,3,18,276s1k,ainow.weebly.com,AI Now,https://www.reddit.com/r/MachineLearning/comments/276s1k/ai_now/,AINowProject,1401786541,,6,0,False,default,,,,,
13,MachineLearning,t5_2r3gv,2014-6-3,2014,6,3,21,2773av,gigaom.com,Skymind - an open source deep learning startup.,https://www.reddit.com/r/MachineLearning/comments/2773av/skymind_an_open_source_deep_learning_startup/,alexgmcm,1401799280,,16,3,False,http://a.thumbs.redditmedia.com/CvMgneESoUFEhDDl.jpg,,,,,
14,MachineLearning,t5_2r3gv,2014-6-3,2014,6,3,22,2775tx,used-presses.net,Used 1992 Heidelberg SORSZ machine for Sale - Heidelberg Printing Equipment,https://www.reddit.com/r/MachineLearning/comments/2775tx/used_1992_heidelberg_sorsz_machine_for_sale/,Equipment111,1401801341,,0,1,False,default,,,,,
15,MachineLearning,t5_2r3gv,2014-6-3,2014,6,3,22,2778vy,self.MachineLearning,How does GPS-Segment Matching like Strava Work?,https://www.reddit.com/r/MachineLearning/comments/2778vy/how_does_gpssegment_matching_like_strava_work/,aidan_morgan,1401803479,"I'm not a cyclist, but some colleagues of mine showed me Strava today. 

Basically they upload data from their GPS device from their ride in the morning and Strava manages to match the GPS data to known ""segments"" in their database.

These segments all have amusing names and with their GPS data some interesting Gamification occurs; who has the fastest time for that segment for the day etc.

I was wondering if anybody knew any algorithms or approaches that can be used to perform this sort of comparison. From Strava's engineering blog they have a _lot_ of data available to them, so whatever algorithm they are using must be pretty fast. They also mention that some segments are manually created, but some are extracted from the raw GPS data.

Thanks!",2,2,False,self,,,,,
16,MachineLearning,t5_2r3gv,2014-6-4,2014,6,4,3,277y1h,self.MachineLearning,Is combining features deemed 'important' by different learning methods logical?,https://www.reddit.com/r/MachineLearning/comments/277y1h/is_combining_features_deemed_important_by/,mtnchkn,1401818772,"I apologize for the post's title, but hope to explain with an example. 

I have a simple binary classification problem involving hundreds/thousands of features to predict cancer. Given the field, a panel of features to predict cancer is preferred as this is considered more robust across the population, and moving forward, the panel will get smaller as classifiers are qualified in larger studies. Point being, the object is a small but not overly small panel of features (&lt;20 or so).

Using different supervised learning approaches (SVM, random forest, neural network, etc.) combined with sequential feature selection (minimizing mis-classification error with forward feature addition to models), I can create classifiers using a subset (panel) of features. The models won't always find the same features, though there will be overlap. 

In this example, does it make any sense to use all of the features selected by all the classifiers to move forward? OR is the only rational choice to chose one panel of features and their classifier and move forward to qualify in a larger population?

Please ask any questions for clarification or let me know if you think finding a consensus panel by machine learning is idiotic.

Thanks",4,5,False,self,,,,,
17,MachineLearning,t5_2r3gv,2014-6-4,2014,6,4,4,2787db,cryptex-cs.blogspot.de,Formalizing machine learning task by example,https://www.reddit.com/r/MachineLearning/comments/2787db/formalizing_machine_learning_task_by_example/,gfoxvh,1401824115,,0,2,False,default,,,,,
18,MachineLearning,t5_2r3gv,2014-6-4,2014,6,4,6,278j04,levyomer.files.wordpress.com,Dependency-Based Word Embeddings,https://www.reddit.com/r/MachineLearning/comments/278j04/dependencybased_word_embeddings/,galapag0,1401830651,,1,1,False,default,,,,,
19,MachineLearning,t5_2r3gv,2014-6-4,2014,6,4,15,279uok,machineryequipment123.blogspot.com,Bulldozer  A Versatile Construction Equipment - Machinery &amp; Equipment Part Online,https://www.reddit.com/r/MachineLearning/comments/279uok/bulldozer_a_versatile_construction_equipment/,jessicperson,1401864760,,0,1,False,default,,,,,
20,MachineLearning,t5_2r3gv,2014-6-4,2014,6,4,18,27a2ov,self.MachineLearning,Linear SVM,https://www.reddit.com/r/MachineLearning/comments/27a2ov/linear_svm/,nischalhp,1401875094,"Hello Guys,

My friend is facing issues trying to run Linear SVM for a large training data on his laptop. 
He wants to distribute it to multiple machines now and he is  trying to figure out which is the best way to do it.

Any clarifications regarding this will be very useful.

Thanks in advance.
",8,6,False,self,,,,,
21,MachineLearning,t5_2r3gv,2014-6-4,2014,6,4,19,27a5cm,used-presses.net,1972 Heidelberg SORKZ machine for Sale,https://www.reddit.com/r/MachineLearning/comments/27a5cm/1972_heidelberg_sorkz_machine_for_sale/,Equipment111,1401878644,,1,1,False,default,,,,,
22,MachineLearning,t5_2r3gv,2014-6-4,2014,6,4,20,27a6ov,self.MachineLearning,Are there any open source implementations of COTS HPC?,https://www.reddit.com/r/MachineLearning/comments/27a6ov/are_there_any_open_source_implementations_of_cots/,PhrackSipsin,1401880306,"I was reading [Deep learning with COTS HPC systems
](http://stanford.edu/~acoates/papers/CoatesHuvalWangWuNgCatanzaro_icml2013.pdf) and the results seem pretty impressive. I have access to similar hardware that is used in the paper and wondered if this was something that had been implemented or would be implementable on either of the popular frameworks for such things, Torch or Theano? Or have these ideas been readily adopted by most of the frameworks.",4,1,False,self,,,,,
23,MachineLearning,t5_2r3gv,2014-6-4,2014,6,4,23,27akom,waterstechnology.com,Machine learning and big data to replace high frequency trading,https://www.reddit.com/r/MachineLearning/comments/27akom/machine_learning_and_big_data_to_replace_high/,[deleted],1401892256,,3,0,False,default,,,,,
24,MachineLearning,t5_2r3gv,2014-6-5,2014,6,5,0,27arl0,techtalks.tv,Barnes-Hut-SNE by Laurens van der Maaten,https://www.reddit.com/r/MachineLearning/comments/27arl0/barneshutsne_by_laurens_van_der_maaten/,turnersr,1401896649,,0,11,False,default,,,,,
25,MachineLearning,t5_2r3gv,2014-6-5,2014,6,5,0,27arpt,github.com,"Tapkee, ""A flexible and efficient ++ template library for dimension reduction""",https://www.reddit.com/r/MachineLearning/comments/27arpt/tapkee_a_flexible_and_efficient__template/,turnersr,1401896734,,0,19,False,http://f.thumbs.redditmedia.com/r_Fgj-N0MLBdzh-M.jpg,,,,,
26,MachineLearning,t5_2r3gv,2014-6-5,2014,6,5,5,27bmcp,yhathq.com,Sciencebox: easy to deploy scientific computing server,https://www.reddit.com/r/MachineLearning/comments/27bmcp/sciencebox_easy_to_deploy_scientific_computing/,agconway,1401914201,,0,1,False,http://a.thumbs.redditmedia.com/ozkFneLQe6meJu96.jpg,,,,,
27,MachineLearning,t5_2r3gv,2014-6-5,2014,6,5,8,27c67j,self.MachineLearning,Having trouble parallelizing recurrent long short-short term memory neural network,https://www.reddit.com/r/MachineLearning/comments/27c67j/having_trouble_parallelizing_recurrent_long/,purpleladydragons,1401926177,"Typo in the title: long short-term memory*

So I recently learned to represent my network as a matrix in order to speed it up, presumably because as a matrix operation it can benefit from parallelization. With a RNN though, I feel like you need to iterate over the columns of the matrix since they're dependent on the previous ones because of recurrent connections. Additionally, I am using LSTM cells whose final activation is dependent upon the activations of their gates. I feel like I've already lost a lot of speed up because of this. Can any recommend how to best implement this type of network?",6,3,False,self,,,,,
28,MachineLearning,t5_2r3gv,2014-6-5,2014,6,5,17,27d7lx,issuu.com,ISSUU - Wheeled Excavator by Machines4u,https://www.reddit.com/r/MachineLearning/comments/27d7lx/issuu_wheeled_excavator_by_machines4u/,jessicperson,1401955249,,0,1,False,default,,,,,
29,MachineLearning,t5_2r3gv,2014-6-5,2014,6,5,17,27d9lh,self.MachineLearning,Introduction to recurrent neural networks?,https://www.reddit.com/r/MachineLearning/comments/27d9lh/introduction_to_recurrent_neural_networks/,makakimekaki,1401957973,"I have two questions please:

1- What are the applications of recurrent neural networks?

2- Can you recommend some good resources/papers that introduce recurrent neural networks?",5,21,False,self,,,,,
30,MachineLearning,t5_2r3gv,2014-6-5,2014,6,5,20,27di0x,machineryequipment123.blogspot.com,Caterpillar or Komatsu Graders - Machinery &amp; Equipment Part Online,https://www.reddit.com/r/MachineLearning/comments/27di0x/caterpillar_or_komatsu_graders_machinery/,jessicperson,1401968624,,0,1,False,default,,,,,
31,MachineLearning,t5_2r3gv,2014-6-5,2014,6,5,20,27di6l,blog.bigml.com,BigML Clusters in Action!,https://www.reddit.com/r/MachineLearning/comments/27di6l/bigml_clusters_in_action/,czuriaga,1401968805,,0,1,False,default,,,,,
32,MachineLearning,t5_2r3gv,2014-6-5,2014,6,5,21,27dla9,onlinemachinery.tumblr.com,Powerscreen Crushing &amp; Screening for sale - International Powerscreen,https://www.reddit.com/r/MachineLearning/comments/27dla9/powerscreen_crushing_screening_for_sale/,jessicperson,1401971836,,0,1,False,default,,,,,
33,MachineLearning,t5_2r3gv,2014-6-6,2014,6,6,1,27e47x,self.MachineLearning,Interesting/spectacular ML-related GIFs,https://www.reddit.com/r/MachineLearning/comments/27e47x/interestingspectacular_mlrelated_gifs/,bochker,1401984705,"Let's share spectacular visualizations of some ML algorithms (like kNN, clustering, etc.)",3,0,False,self,,,,,
34,MachineLearning,t5_2r3gv,2014-6-6,2014,6,6,2,27ebcg,self.MachineLearning,Bizarre auditory RBM Results using Pylearn2,https://www.reddit.com/r/MachineLearning/comments/27ebcg/bizarre_auditory_rbm_results_using_pylearn2/,nivrams_brain,1401988853,"Dear /r/MachineLearning

I was hoping you guys could help me interpret some strange results I'm getting.

I am using Pylearn2 to do the training and my model is based off the [dbm demo](https://github.com/lisa-lab/pylearn2/tree/master/pylearn2/scripts/tutorials/dbm_demo) they have.

I use [spectrograms of raw auditory signals](http://i.imgur.com/TFkSXxb.png).  20 pixels (100 mS) along the horizontal axis and 44 pixels along the vertical axis (frequency)

I do a couple preprocessing steps, zero mean, remove zero column, and ZCA to make [my data](http://i.imgur.com/yMbS9aO.png) behave a bit nicer.

Then train my RBM using a mixture of contrastive divergence and sparsity.  Once the training is complete I get receptive fields that look like [this](http://i.imgur.com/zbxCuDX.png).

Looking at the structure of the training data, these receptive fields don't make much sense.  I was hoping some of you machine learning masters might be able to tell me what I'm doing wrong.

Thanks,

~Nivram's Brain",2,10,False,self,,,,,
35,MachineLearning,t5_2r3gv,2014-6-6,2014,6,6,4,27en5o,self.MachineLearning,What do you do when your biggest source of error is the people hired to evaluate your classifier?,https://www.reddit.com/r/MachineLearning/comments/27en5o/what_do_you_do_when_your_biggest_source_of_error/,iwantedthisusername,1401995644,"Hey all. I'm currently working on a ML project that involves record linkage optimized by ML. When I first started the project, I knew I would need a way to rapidly evaluate the accuracy of the classifier. I knew I would need a labeled data set, but unfortunately this data set did not exist yet. 

I'm not afraid of getting dirty with the data, so I dug in, and eventually found a way to consistently find the correct answer. Unfortunately, labeling this data takes quite a bit of time, since it involves a level of manual record linkage. Hence, I was only able to do a small set on my own. I trained on this data, and found it to generalize fairly well, so a plan was set in place to get a set of outsourced interns to do this labeling task so I could improve performance and generalization.

Unfortunately, I found early on, no one else had the accuracy or efficiency to do this task well. Even when the task was simplified to simply evaluating the accuracy of the output of the classifier, they struggle. They consistently can not see the patterns in the data and mark correct things as incorrect. When I go through their work, and make corrections, they agree that my corrections are accurate, however, they have never improved on the tasks provided to them. 

This is stressing me the hell out. They are the biggest source of error in my project, but I have no other resources to hire someone better. What can I do? The classifier is doing a hell of a job based on my evaluations, but I simply do not have the time to take a sample each time and evaluate it myself. I can't run the optimization system until I have at least a modestly sized set of data with the correct answers. But the team hired to evaluate has a 10% error rate

Have any of you dealt with this issue before? What do I do?",7,7,False,self,,,,,
36,MachineLearning,t5_2r3gv,2014-6-6,2014,6,6,6,27f0y0,self.MachineLearning,Deep learning without contrastive divergence,https://www.reddit.com/r/MachineLearning/comments/27f0y0/deep_learning_without_contrastive_divergence/,entron,1402003518,"Can somebody recommend me some recent deep learning papers without using contrastive divergence learning rule? 

If I understand correctly the essence of deep learning is the unsupervised pre-training of multi-layer network, and it should not be restricted to using only contrastive divergence learning rules. However, I haven't found any deep learning papers without contrastive divergence. I am new in this field.",5,3,False,self,,,,,
37,MachineLearning,t5_2r3gv,2014-6-6,2014,6,6,6,27f35a,engineering.richrelevance.com,Online Recommendations with Thompson Sampling,https://www.reddit.com/r/MachineLearning/comments/27f35a/online_recommendations_with_thompson_sampling/,sergeyfeldman,1402004830,,1,11,False,http://a.thumbs.redditmedia.com/H0sqwd0nlGZ5JNRf.jpg,,,,,
38,MachineLearning,t5_2r3gv,2014-6-6,2014,6,6,8,27fdgf,self.MachineLearning,"I want to get into Machine Learning, I am coming from very little knowledge and need help with choosing a major/unit selection. Any help would be greatly appreciated.",https://www.reddit.com/r/MachineLearning/comments/27fdgf/i_want_to_get_into_machine_learning_i_am_coming/,randinte,1402011363,"Okay so, as of next year I am transfering to a double degree(currently in IT), Bachelor of Mathematics &amp; Bachelor of Information Technology (Computer Science Major, but in reality, it primarily programming). 

Course Structure here

https://www.student.qut.edu.au/studying/courses/course?courseCode=SE30&amp;courseID=26896

Now, I recently and over the next few months I'll be playing catchup with mathematics as my math background is weaker than I would like ( I am coming from a Security / Pentesting Background), However I need to make a major selection now to tell my course coordinator for the transfer to happen.

I will be taking some ai/machine learning units as electives.

Should I take the Statistical Science Major?

Any other input would be amazing, as I am extremely noob when it comes to ML and mathematics in general. I know I have a bunch of hard work, hell I have to catchup on highschool math let alone the rest of it, but I have always been a pretty good self study.

",3,0,False,self,,,,,
39,MachineLearning,t5_2r3gv,2014-6-6,2014,6,6,10,27flyw,self.MachineLearning,A Simple Idea (cross-post from /r/artificial),https://www.reddit.com/r/MachineLearning/comments/27flyw/a_simple_idea_crosspost_from_rartificial/,CireNeikual,1402017316,"Hello,

I am a hobby AI researcher (so feel free to question the validity of all this), and I am designing a system which can adapt to be any type of neural network. It's a blank slate, the dynamics of the system are all encoded into genes (as the weights of a standard feedforward neural network, which updates some memory variables as well as the neuron output). It is then evolved to produce the most reward-seeking network. I plan to start on simple tests such as XOR, pole balancing, and mountain car.

The standard feed-foward neural networks are universal function approximators, so theoretically they can produce any neural network within the limitations of the data the neural networks operate on (their memory variables, their allowed connectivity).

Right now I have planned to evolve the synaptic update, the activation function (it might end up being spiking, it might not), the connector (decides when neurons to connect/disconnect), an input encoder (takes a single float as input and feeds it to the net) and a decoder (reverse of encoder).

Has anybody ever thought of this before? Surely someone has, but I can't find anything on the web.
Just wanted to share this. If someone makes something out of this, at least I feel like I contributed somehow. I will let you all know how it goes. Also, ideas on how to improve the system are welcome.

EDIT: It seems that many people confuse this approach with something like [NEAT](http://www.cs.ucf.edu/~kstanley/neat.html)

However, instead of deciding the weights of the neural network, the evolutionary algorithm instead decides what the rules for updating/maintaining the network are. Also, this would not be a feedforward neural network necessarily, it could end up being one, but it can really represent any topology of some sort of nodes that might be evolved to work like neural networks (it may not actually use logic as we understand neural networks using today, since the purpose is to evolve that).",11,1,False,self,,,,,
40,MachineLearning,t5_2r3gv,2014-6-6,2014,6,6,14,27g6bk,self.MachineLearning,Stanford's Unsupervised Feature Learning &amp; Deep Learning Tutorial,https://www.reddit.com/r/MachineLearning/comments/27g6bk/stanfords_unsupervised_feature_learning_deep/,[deleted],1402033392,"Here's my implementation of Stanford's UFLDL Tutorial in Python. 

The code includes complete and fully functional implementation of sparse auto encoder, softmax regression, stacked auto encoder and convolutional neural networks. It also includes code for classifying MNIST digits and STL-10 images.

The code is reasonably easy to understand and has comments wherever it makes sense. Please feel free to get in touch with questions or feedback.",0,1,False,default,,,,,
41,MachineLearning,t5_2r3gv,2014-6-6,2014,6,6,15,27g7tm,self.MachineLearning,Stanford's Unsupervised Feature Learning &amp; Deep Learning Tutorial,https://www.reddit.com/r/MachineLearning/comments/27g7tm/stanfords_unsupervised_feature_learning_deep/,[deleted],1402034817,"Here's my implementation of Stanford's UFLDL Tutorial in Python:
[UFLDL Tutorial Code](https://github.com/jatinshah/ufldl_tutorial)

The code includes complete and fully functional implementation of sparse auto encoder, softmax regression, stacked auto encoder and convolutional neural networks. It also includes code for classifying MNIST digits and STL-10 images.

The code is reasonably easy to understand and has comments wherever it makes sense. Please feel free to get in touch with questions or feedback.",5,32,False,self,,,,,
42,MachineLearning,t5_2r3gv,2014-6-6,2014,6,6,22,27gudj,blog.yhathq.com,Sparse random projections and SVM using Python,https://www.reddit.com/r/MachineLearning/comments/27gudj/sparse_random_projections_and_svm_using_python/,hernamesbarbara,1402061322,,0,7,False,http://a.thumbs.redditmedia.com/ozkFneLQe6meJu96.jpg,,,,,
43,MachineLearning,t5_2r3gv,2014-6-6,2014,6,6,23,27gzof,hakkalabs.co,Digging into the Dirichlet Distribution,https://www.reddit.com/r/MachineLearning/comments/27gzof/digging_into_the_dirichlet_distribution/,BKDev,1402065075,,1,28,False,http://a.thumbs.redditmedia.com/CEL96-dEBO_DDv0h.jpg,,,,,
44,MachineLearning,t5_2r3gv,2014-6-7,2014,6,7,6,27i6wg,self.MachineLearning,New user looking for help with SharpNeat,https://www.reddit.com/r/MachineLearning/comments/27i6wg/new_user_looking_for_help_with_sharpneat/,ai_noob,1402091666,"Has anyone here worked with SharpNeat before?  I wrote up a quick experiment and I have it running but I do not see where or how to train the genomes (?, I get caught on terminology as well).  From what I can tell it just goes through the process of adding nodes and weights to the genomes.  The fitness never really improves.  I have some experience using Encog for training ANN's where you create your dataset and feed it into the trainer.  I don't see where the process of training the actual ANN's is in SharpNeat.

Can someone tell me where that is or what its called?  Or am I just fundamentally missing how NEAT works?  In my code I implemented IPhenomeEvaluator&lt;IBlackBox&gt; and INeatExperiment to get the code running.",0,1,False,self,,,,,
45,MachineLearning,t5_2r3gv,2014-6-7,2014,6,7,10,27ipa2,self.MachineLearning,Hierarchical clustring given distance matrix,https://www.reddit.com/r/MachineLearning/comments/27ipa2/hierarchical_clustring_given_distance_matrix/,vmirjalily,1402105423,"I have computed the distance matrix for 256 objects, and I want to cluster these objects accordingly. The distance matrix is basically the edit-distance between each pair of objects (strings).

However, R hclust gives me an error? Any idea how to solve this?

http://stackoverflow.com/questions/24092839/r-hclust-clustering-given-a-distance-matrix-256x256",1,5,False,self,,,,,
46,MachineLearning,t5_2r3gv,2014-6-7,2014,6,7,12,27iyjm,self.MachineLearning,A good reference for boosted decision trees?,https://www.reddit.com/r/MachineLearning/comments/27iyjm/a_good_reference_for_boosted_decision_trees/,Flaw_in_the_system,1402113444,"I want to be able to use boosted decision trees for an analysis that I am doing, and I am wondering what people around here would reccommend as a good source to dive in with.",8,14,False,self,,,,,
47,MachineLearning,t5_2r3gv,2014-6-8,2014,6,8,15,27lrxo,self.MachineLearning,Bayesian optimization with gaussian processes,https://www.reddit.com/r/MachineLearning/comments/27lrxo/bayesian_optimization_with_gaussian_processes/,A_Schwarzenschnitzel,1402210655,"I put together a python module to perform [global optimization with gaussian processes](https://github.com/fmfn/Bayesian-Optimization-with-Gaussian-Processes)

My motivation was finding good sets of parameters when doing cross validation in a efficient manner, and this seems to work quite well. I included in the repository some visualization and a simple test case with the iris data set.

So far it supports the squared exponential and ARD Matern kernels, and probability of improvement, expected improvement and upper confidence bound acquisition functions. But the user is free to use custom ones as well.

I would greatly appreciate comments, corrections and suggestions, since, after all, this is an ongoing project that I would like to improve upon.

ps: A blog post discussing some of the theory behind it as well as performing more realistic experiments should follow up shortly.

cheers,",29,21,False,self,,,,,
48,MachineLearning,t5_2r3gv,2014-6-8,2014,6,8,16,27ls6g,distillationcolumns.wordpress.com,Distillation Columns,https://www.reddit.com/r/MachineLearning/comments/27ls6g/distillation_columns/,maletacdcom,1402210970,,0,1,False,default,,,,,
49,MachineLearning,t5_2r3gv,2014-6-9,2014,6,9,0,27mf01,self.MachineLearning,Advice on a problem I want to solve to get started in ML,https://www.reddit.com/r/MachineLearning/comments/27mf01/advice_on_a_problem_i_want_to_solve_to_get/,af280,1402240798,"I'm trying to learn machine learning on my own and though of a summer project that is intersting to me.  I've done a bit of reading on the subject but I'm sure there are plenty of things I'm missing.  Is this a reasonable problem to try out or way too hard?  Is there another approtch that I should be taking?

Here's the problem I want to solve:  You are given an article (or website) that also contains images.  Many of the images are junk i.e. advertisments.  Return a single image from the page that is most relevant to the article. 

My first though are to:

1. read the article and generate a list of words used and their frequency (removing common words, the, a, an ... )
2. Using the `n` most common words, get 50 or so images using this keyword from an image search. 
3.  Use bag of words model for the images. 
4. compare the images from the article to the model in #3. 

How to implement 3,4 are where it gets a but fuzzy for me but that's why I'm doing this. ",7,2,False,self,,,,,
50,MachineLearning,t5_2r3gv,2014-6-9,2014,6,9,0,27mgxr,self.MachineLearning,Estimating bias-variance trade-off in practice.,https://www.reddit.com/r/MachineLearning/comments/27mgxr/estimating_biasvariance_tradeoff_in_practice/,[deleted],1402242339,"In practice, when you are given just the data set and you are free to apply a model of your choice, how do you go about choosing your possible hypothesis set and approximate the hypothesis for say a certain subset of the data points by comparing the bias-variance or the expected out of sample error ? Obviously we don't know what the target function is and the bias depends on the target function. So, how do we compare to get the optimal trade-off ?",3,7,False,default,,,,,
51,MachineLearning,t5_2r3gv,2014-6-9,2014,6,9,6,27n9h4,self.MachineLearning,Two class classification or one class classification for selecting sports articles from dataset ?,https://www.reddit.com/r/MachineLearning/comments/27n9h4/two_class_classification_or_one_class/,muktabh,1402262707,"Is the problem of classifying a document as sports-related / non-sports better handled when solved as a one class classifier problem ?

I have worked on a similar problem earlier using Naive-Bayes classifier where  was trying to use two-class classifier, and since the negative class could not be sampled well, I had to train with an unreasonably high number of negative samples and scale down classifier output for this bias, and still the accuracy was at best 75%.

I have a similar problem at hand again, and I can choose between one/two class classifier for it (When I did it last time few years back, I did not have idea about one-class classification).

There are two constraints that I have to address :

1. The classifier needs to have high precision, a low recall is OK for initial performance . However both mistakes of wrongly classified negative samples as positive (error in precision) and missed out positive class documents (error in recall) will have to be relearnt via feedback.
2. The documents classified wrongly will be given back as feedback .

I am tempted to try out a one-class classifiers, but want to check whether commonly used implementations like one class SVM can somehow be fed back the errors ? This would be really well handled in a MaxEnt/NaiveBayes method, but then I will have to use the bias again, that is putting in too many negative class documents to train, which I dont want to do. ",6,1,False,self,,,,,
52,MachineLearning,t5_2r3gv,2014-6-9,2014,6,9,7,27ncj7,self.MachineLearning,Why can you solve LASSO with gradient descent if LASSO is not differentiable,https://www.reddit.com/r/MachineLearning/comments/27ncj7/why_can_you_solve_lasso_with_gradient_descent_if/,mLquestion,1402264855,"We know that LASSO is 


   min ||Ax - b||_2^2 + lambda||beta||_1

where
    
   the L1 regularization is not differentiable due to the absolute operator


so I am really confused to how we use gradient descent to solve LASSO

Thanks

",5,19,False,self,,,,,
53,MachineLearning,t5_2r3gv,2014-6-9,2014,6,9,15,27ofp7,techtalkshub.com,Hadoop - Just the Basics for Big Data Rookies - full talk,https://www.reddit.com/r/MachineLearning/comments/27ofp7/hadoop_just_the_basics_for_big_data_rookies_full/,Feribg,1402295526,,0,3,False,http://b.thumbs.redditmedia.com/pgbhM6J2F0LQ9Tf5.jpg,,,,,
54,MachineLearning,t5_2r3gv,2014-6-9,2014,6,9,16,27oi8l,self.MachineLearning,Fun prediction task - suggestions please!,https://www.reddit.com/r/MachineLearning/comments/27oi8l/fun_prediction_task_suggestions_please/,pmrr,1402298349,"For fun at work we're having a sweepstake predicting scores of all world cup football matches. Any method is fair game, so I'm wondering what ML techniques I can use.

TRAINING

I've gathered historic data in the following format for every match:

    TeamA GoalsA - TeamB GoalsB

And ranking data from the same period:

    Team RankNum RankPoints

Meaning for every game I have the following data:

    TeamA GoalsA RankNumA RankPointsA - TeamB GoalsB RankNumB RankPointsB

There are 64 games per world cup, so I very little historic data, especially considering teams will compete in a small percentage of those games.

PREDICTION

For the sweepstake I need to guess the score, so I need goals for team A and goals for team B.

    TeamA RankNumA RankPointsA TeamB RankNumB RankPointsB =&gt; GoalsA GoalsB

I have in mind an ANN or similar, but I'm concerned on training set size. Any suggestions?",4,4,False,self,,,,,
55,MachineLearning,t5_2r3gv,2014-6-9,2014,6,9,23,27p3aj,self.MachineLearning,Machine Learning Study Group - Thread # 1 (Update),https://www.reddit.com/r/MachineLearning/comments/27p3aj/machine_learning_study_group_thread_1_update/,rovingr,1402322438,"As an update to the last thread, I'll be posting study group content both to a reddit thread and to a blog I've started. This seems easier to manage than a mailing list, and this way, people can discuss the article in the comments, pass on the link to other individuals who might be interested, etc. I'm thinking I'll keep this going for 8 to 12 weeks and then possibly move on to another non-Machine Learning (but data science related) subject area. As always, suggestions and comments are welcome, though, nothing is set in stone!

Also, our Kaggle team is going well. I don't believe there is a team size limit for the Bike Sharing Demand competition, and our intent is just to get some practice and share ideas, so any newcomers are still welcome! Message me if you'd like to join.

Here's the link: http://datasciencetalk.blogspot.com .

Link to the last thread: http://www.reddit.com/r/MachineLearning/comments/26x06e/machine_learning_study_group_thread_1/

",3,10,False,self,,,,,
56,MachineLearning,t5_2r3gv,2014-6-10,2014,6,10,0,27p9a9,self.MachineLearning,"Desk Reference: Bishop, Hastie, Murphy or Duda?",https://www.reddit.com/r/MachineLearning/comments/27p9a9/desk_reference_bishop_hastie_murphy_or_duda/,mtnchkn,1402326573,"I sometimes need a good resource to share with colleagues or students to give them a basic background about machine learning approaches being used for analysis. The Hastie book has an online pdf which is great, but of the four listed (below), which would you recommend, or which do you think are more essential, as a desk reference. To be more specific, the goal would be to provide a basic understanding of the concepts behind different machine learning approaches, as well as the caveats and advantages of different approaches. I work in academia with biologist and statisticians, so there are a varying backgrounds.

Bishop - 
Pattern Recognition and Machine Learning (Information Science and Statistics)

[Barber - Bayesian Reasoning and Machine Learning](http://web4.cs.ucl.ac.uk/staff/D.Barber/pmwiki/pmwiki.php?n=Brml.HomePage)

[Boyd - Convex Optimization](http://www.stanford.edu/~boyd/cvxbook/)

Duda - Pattern Classification

[Hastie - The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition](http://statweb.stanford.edu/~tibs/ElemStatLearn/)

Murphy - Machine Learning: A Probabilistic Perspective






**EDIT: Included commenter's additions, and links for those available online**",7,4,False,self,,,,,
57,MachineLearning,t5_2r3gv,2014-6-10,2014,6,10,0,27paaq,pyimagesearch.com,Trends in machine learning...and why I'm sick of the deep learning hype.,https://www.reddit.com/r/MachineLearning/comments/27paaq/trends_in_machine_learningand_why_im_sick_of_the/,zionsrogue,1402327239,,75,86,False,http://a.thumbs.redditmedia.com/ebvp8qgyU-J11KDJ.jpg,,,,,
58,MachineLearning,t5_2r3gv,2014-6-10,2014,6,10,1,27pfh0,self.MachineLearning,Reg choosing the right course work,https://www.reddit.com/r/MachineLearning/comments/27pfh0/reg_choosing_the_right_course_work/,rajsekar37,1402330357,"Hi,

I want to be a data analyst and planning for an advanced degree. I have the following queries regarding Big data /data science/analytics. 

1.  As analytics is a applied knowledge,  How can I get the same applied knowledge of data scientist after doing an MS-Computer Science degree  (ML/NLP/data mining specialization)?  I want to work on interpretation of variety of data with multi-disciplinary approach(campaign analysis /Political analysis ). Which area that I need to focus apart from CS curriculm or does CS curriculum itself fulfills that ? I am not sure of job perspective and growth(scope and wideness of jobs) after doing specilized MS-data analytics/Business analytics .So , I choose MS-CS than MS-business/data analytics because of wide range of opportunities for MS-CS in general. 

2.   Does what they achieve from specialized MS-Business analytics/data analtyics degree ,Can be achieved from MS-CS (data mining/NLP/machine learning ) curriculum ?How does course content and job responsibilities varies for either of the degrees ? 

3.   How is proliferation of data science techniques in Government policy making/humanities domain  . How much is the demand for data Science professionals in these fields ? and  Does a MS-CS(Data mining/Machine learning/NLP) get a job/work  as analyst in humanities fields such as Sociology /Political Science / Public policy or any other quantitative roles provided he has the domain knowledge apart from technical ones? 

4.  Does the job opportunities in Big data and allied fields is exaggerated ? Is it worth doing ?

 
Note: 
MS analytics/Business analytics - like the one offered in http://analytics.ncsu.edu/?page_id=1799 or http://msbapm.business.uconn.edu/academics/curriculum/



Thanks for taking time.

Kind Regards,",3,3,False,self,,,,,
59,MachineLearning,t5_2r3gv,2014-6-10,2014,6,10,2,27pmxn,self.MachineLearning,"Markov chains, Gaussian processes, regressors and Bayesian filters",https://www.reddit.com/r/MachineLearning/comments/27pmxn/markov_chains_gaussian_processes_regressors_and/,Arnoke,1402334753,"Hi all,

I'm a bit confused here. I have used Kalman filters and Particle filters before to filter noisy observations. The state transition model in such Bayesian filters represent P(state[t] | state[t-1]) and is therefore a prediction model.

Now I was thinking that, instead of using a simple random walk or constant velocity model as a prediction model, maybe I could gather some statistics based on my training data that shows which transitions are the most likely to occur. This actually corresponds to a Markov Chain model.

Then I came across some papers that describe how to use Gaussian processes for prediction, and now I'm kinda lost.

What is the difference between predicting a variable using a Markov Chain, and predicting it using a Gaussian process? Is one of them clearly better or more advanced than the other? And what about using simple regression techniques (e.g. linear regression) to obtain a prediction?

",9,9,False,self,,,,,
60,MachineLearning,t5_2r3gv,2014-6-10,2014,6,10,12,27rauq,self.MachineLearning,Career transition into Data Science,https://www.reddit.com/r/MachineLearning/comments/27rauq/career_transition_into_data_science/,pchun008,1402371657,,4,0,False,default,,,,,
61,MachineLearning,t5_2r3gv,2014-6-10,2014,6,10,15,27rmbh,datascience.stackexchange.com,Data Science Stack Exchange is in public beta from today.,https://www.reddit.com/r/MachineLearning/comments/27rmbh/data_science_stack_exchange_is_in_public_beta/,tomaskazemekas,1402381341,,2,66,False,http://a.thumbs.redditmedia.com/_cQxjPmZwKhwY9nR.jpg,,,,,
62,MachineLearning,t5_2r3gv,2014-6-10,2014,6,10,15,27rnb8,techtalks.tv,deep-learning-for-nlp-without-magic-part-1,https://www.reddit.com/r/MachineLearning/comments/27rnb8/deeplearningfornlpwithoutmagicpart1/,grad_ml,1402382392,,5,0,False,default,,,,,
63,MachineLearning,t5_2r3gv,2014-6-10,2014,6,10,16,27rpct,machineryequipment123.blogspot.com,How to Operate a Mini Excavator - Machinery &amp; Equipment Part Online,https://www.reddit.com/r/MachineLearning/comments/27rpct/how_to_operate_a_mini_excavator_machinery/,jessicperson,1402384593,,0,1,False,default,,,,,
64,MachineLearning,t5_2r3gv,2014-6-10,2014,6,10,17,27rttq,self.MachineLearning,Reg choosing the right course,https://www.reddit.com/r/MachineLearning/comments/27rttq/reg_choosing_the_right_course/,rajsekar37,1402390595,,0,0,False,default,,,,,
65,MachineLearning,t5_2r3gv,2014-6-10,2014,6,10,21,27s5xd,pyimagesearch.com,Get Off the Deep Learning Bandwagon and get some Perspective,https://www.reddit.com/r/MachineLearning/comments/27s5xd/get_off_the_deep_learning_bandwagon_and_get_some/,vikkamath,1402404792,,1,1,False,default,,,,,
66,MachineLearning,t5_2r3gv,2014-6-11,2014,6,11,1,27ss2j,igi.tugraz.at,Liquid State Machines - Wolfgang Maass [x-post from /r/chaoskampf],https://www.reddit.com/r/MachineLearning/comments/27ss2j/liquid_state_machines_wolfgang_maass_xpost_from/,Chaoskampf_,1402419305,,1,18,False,default,,,,,
67,MachineLearning,t5_2r3gv,2014-6-11,2014,6,11,9,27u59k,self.MachineLearning,FAQ and measures of impact crusher in Africa,https://www.reddit.com/r/MachineLearning/comments/27u59k/faq_and_measures_of_impact_crusher_in_africa/,[deleted],1402448042,,2,0,False,default,,,,,
68,MachineLearning,t5_2r3gv,2014-6-11,2014,6,11,15,27uupj,self.MachineLearning,Question About Recurrent Neural Network Training Procedure,https://www.reddit.com/r/MachineLearning/comments/27uupj/question_about_recurrent_neural_network_training/,alexmlamb,1402467306,"Hello, 

I am experimenting with recurrent neural networks for time-series prediction, and in the simplest case, having each time-step in the recurrent neural network predict x[t + 1] using x[t] as the only input feature.  

In the part of the time series used for validation/testing, the values for x[t] are not known so the RNN's prediction from the previous time step is used (or samples from the conditional distribution if the network is modeling p(x[t] | x[1:t-1])).  

In the training window, however, I have a choice between using the value for x[t] predicted at the last time step in the network and using the known value for x[t].  One option would be to always use the known value of x[t] in the training window.  Another option (which Alex Graves uses in his paper on wind power forecasting) is to segment the part of the time-series available for training and use the observed values of x[t] for the first part and use the network's predicted value of x[t] for the second part.  

I suspect that the first approach might make it harder for the network to learn long-range dependencies because it's never forced to make long-range predictions during training.  However, I'm curious if there's any more formal/theoretical analysis related to this problem.  ",2,7,False,self,,,,,
69,MachineLearning,t5_2r3gv,2014-6-11,2014,6,11,18,27v5ao,self.MachineLearning,Possible Problems of Hydraulic cone crusher,https://www.reddit.com/r/MachineLearning/comments/27v5ao/possible_problems_of_hydraulic_cone_crusher/,greatwallmill,1402480349,,0,1,False,default,,,,,
70,MachineLearning,t5_2r3gv,2014-6-11,2014,6,11,19,27v5mc,miecoindia.in,"Mieco Pumps and Generators Pvt.Ltd Bangalore | Pumping is Our Bussiness, Experience is Our Asset..",https://www.reddit.com/r/MachineLearning/comments/27v5mc/mieco_pumps_and_generators_pvtltd_bangalore/,indiamieco,1402480836,,1,0,False,default,,,,,
71,MachineLearning,t5_2r3gv,2014-6-11,2014,6,11,20,27vas8,self.MachineLearning,Learning Theano/Torch7,https://www.reddit.com/r/MachineLearning/comments/27vas8/learning_theanotorch7/,binge_learner,1402486943,"Hi guys,

Do you guys have any resources on learning Theano to a point where I can actually code stuff from research papers ( most tutorials I found were either too basic, or not that clear ) ?

And what is the difference between Theano and Torch7 ? What do you guys recommend ?",10,11,False,self,,,,,
72,MachineLearning,t5_2r3gv,2014-6-11,2014,6,11,20,27vbfn,self.MachineLearning,Where I find open problems to solve about Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/27vbfn/where_i_find_open_problems_to_solve_about_machine/,Ewybe,1402487657,"I just want know if you can give me where i can find open problems about Machine Learning or Computer Science.
I mean something like this.
https://www.kaggle.com/competitions


",5,3,False,self,,,,,
73,MachineLearning,t5_2r3gv,2014-6-11,2014,6,11,22,27vgx4,github.com,Tiny Bayesian A/B testing library,https://www.reddit.com/r/MachineLearning/comments/27vgx4/tiny_bayesian_ab_testing_library/,hidden-markov,1402492695,,0,23,False,http://b.thumbs.redditmedia.com/2s71qpjppUI6MRTE.jpg,,,,,
74,MachineLearning,t5_2r3gv,2014-6-12,2014,6,12,3,27wc0t,self.MachineLearning,Any tips for multi-class classification where one of the classes sits in the middle of the others in PC space?,https://www.reddit.com/r/MachineLearning/comments/27wc0t/any_tips_for_multiclass_classification_where_one/,NotAHomeworkQuestion,1402512179,"So I've got 5 classes, and 4 of them separate well in pretty tight clusters when you PCA plot the samples (only 2 dimensions are significant). However, the 5th sits in the middle of all of them and is quite a bit more spread out, basically spanning the space in the middle of the other 4 clusters with a small amount of overlap with each. When I do my classification (using the original features) using random forests I'm usually calling the samples in this 5th class as one of the other classes. Does anyone have any tips as to how to increase performance?",5,3,False,self,,,,,
75,MachineLearning,t5_2r3gv,2014-6-12,2014,6,12,4,27whld,self.MachineLearning,Any info on Machine Learning Summer School at Carnegie Mellon?,https://www.reddit.com/r/MachineLearning/comments/27whld/any_info_on_machine_learning_summer_school_at/,Knux-,1402515418,"Does anyone have any info on [this summer school program at Carnegi Mellon](http://www.mlss2014.com/)? It seems very interesting, but the information on their website is a bit sparse.

I'm a math undergrad student who is barely (and independently, since there is nothing at my university) getting into machine learning and I would like to go to a program such as this one if it is worthwhile. What do you all think? Have any of you ever participated in such a program?  ",6,3,False,self,,,,,
76,MachineLearning,t5_2r3gv,2014-6-12,2014,6,12,5,27wn27,self.MachineLearning,"Meta-Learning Algorithm ""HyperNet"" produces first results!",https://www.reddit.com/r/MachineLearning/comments/27wn27/metalearning_algorithm_hypernet_produces_first/,CireNeikual,1402518629,"Hello!

I posted a few days ago about the idea of using evolutionary algorithms to train the dynamics of some generic network of nodes (this included activation function, synaptic update, connection establisher/remover, and an encoder/decoder). This original post is available [here](http://www.reddit.com/r/artificial/comments/27fg2v/a_simple_idea_artificial_intelligence/). There was a lot of skepticism but also encouragement, thank you for both!

I have brought my meta-learning algorithm into a working state. It is still far from done, but its first results show that it is possible to make this concept work. I call it ""HyperNet"", since it is essentially optimizing only hyperparameters (functions, in this case).

The first experiment I ran it on was XOR. It first kept on getting stuck in a local minimum where it would just output the same value for every input, but after some bug fixes and tweaks I got it out of there. I just now (5 minutes before writing this) got it to ascend into the next local minimum, where all but one of the outputs are correct. This was after only 100 generations, and it was still steadily improving before I stopped it (it was taking quite a while ;) ). I will dedicate more time to the evolution of proper learning rules after submitting this post.

I just had to post about this, it's so exciting!

I will upload the code when it is ready (when it is less buggy).",9,0,False,self,,,,,
77,MachineLearning,t5_2r3gv,2014-6-12,2014,6,12,5,27wn7s,self.MachineLearning,Stanford's UFLDL Tutorial with Octave,https://www.reddit.com/r/MachineLearning/comments/27wn7s/stanfords_ufldl_tutorial_with_octave/,JimTheSavage,1402518720,"I was just wondering if anybody has done the UFLDL Tutorial with Octave instead of Matlab. If so, are there Matlab specific functions in the starter code that would necessitate a rewrite?",2,6,False,self,,,,,
78,MachineLearning,t5_2r3gv,2014-6-12,2014,6,12,17,27y6a6,machineryequipment123.blogspot.com,Types of Sand Bagging Machines - Machinery &amp; Equipment Part Online,https://www.reddit.com/r/MachineLearning/comments/27y6a6/types_of_sand_bagging_machines_machinery/,jessicperson,1402560127,,0,1,False,default,,,,,
79,MachineLearning,t5_2r3gv,2014-6-12,2014,6,12,19,27yd9d,self.MachineLearning,"Anyone reading ""Real World Machine Learning"" through the MEAP?",https://www.reddit.com/r/MachineLearning/comments/27yd9d/anyone_reading_real_world_machine_learning/,srkiboy83,1402569600,They've released the first 4 chapters. Any thoughts?,2,4,False,self,,,,,
80,MachineLearning,t5_2r3gv,2014-6-12,2014,6,12,21,27yi27,synapse.org,Three new DREAM challenges starting,https://www.reddit.com/r/MachineLearning/comments/27yi27/three_new_dream_challenges_starting/,[deleted],1402574891,,0,10,False,default,,,,,
81,MachineLearning,t5_2r3gv,2014-6-13,2014,6,13,1,27z5xt,engineering.richrelevance.com,Personalization with Contextual Bandits,https://www.reddit.com/r/MachineLearning/comments/27z5xt/personalization_with_contextual_bandits/,sergeyfeldman,1402591527,,0,19,False,http://a.thumbs.redditmedia.com/H0sqwd0nlGZ5JNRf.jpg,,,,,
82,MachineLearning,t5_2r3gv,2014-6-13,2014,6,13,6,2800fv,self.MachineLearning,Suggestions for applying machine learning to 3D data?,https://www.reddit.com/r/MachineLearning/comments/2800fv/suggestions_for_applying_machine_learning_to_3d/,PhysicsNovice,1402609707,"Im rather new to machine learning. I'm applying neural networks to a problem only because thats the tool I have. I am open to other machine learning approaches. 

I have 3D positions of atoms and Im looking at what happens when a few are changed. Thus far my approach is going to be to grid out the 3D space Im interested in and assign a vector to each grid cell that counts the number of each type of atom in that cell then I will construct my input vector using these cell vectors and an additional three-vector that consists of the 3D coordinates for the center of each cell. At the end of this input vector will be another small vector that represents the changes I made and the target vector will be a simple number that represents the measured consequence of that change.

This is mostly off the top of my head with little experience in machine learning. If some of you have suggestions or know of a different method I should be looking at please let me know. ",2,0,False,self,,,,,
83,MachineLearning,t5_2r3gv,2014-6-13,2014,6,13,8,280ak0,blogs.scientificamerican.com,"World Cup Prediction Mathematics Explained | Observations, Scientific American Blog Network",https://www.reddit.com/r/MachineLearning/comments/280ak0/world_cup_prediction_mathematics_explained/,[deleted],1402616152,,0,1,False,default,,,,,
84,MachineLearning,t5_2r3gv,2014-6-13,2014,6,13,16,281b2i,self.MachineLearning,Which is the best machine learning and data analysis tool for processing petabytes of data in terms of speed and power?,https://www.reddit.com/r/MachineLearning/comments/281b2i/which_is_the_best_machine_learning_and_data/,[deleted],1402645904,"Considering all available options like
RapidMiner
R
Python 
MATLAB
Orange
Weka
etc.

Please give a detailed analysis on why the specific tool would be the best one to process this huge data. 

Also it is important to have good Machine Learning algorithm implementation libraries along with it since that is the purpose of it.",3,0,False,default,,,,,
85,MachineLearning,t5_2r3gv,2014-6-13,2014,6,13,18,281e8g,machines4u.altervista.org,Hydraulic Excavators Vs. Wheeled Loaders,https://www.reddit.com/r/MachineLearning/comments/281e8g/hydraulic_excavators_vs_wheeled_loaders/,jessicperson,1402650327,,0,1,False,default,,,,,
86,MachineLearning,t5_2r3gv,2014-6-13,2014,6,13,23,282057,bugra.github.io,"Numerical Differentiation, Convolution and Curve Fitting via MCMC",https://www.reddit.com/r/MachineLearning/comments/282057/numerical_differentiation_convolution_and_curve/,bugra,1402671444,,0,17,False,default,,,,,
87,MachineLearning,t5_2r3gv,2014-6-14,2014,6,14,8,283e2x,additiveanalytics.com,MIT and Harvard Researchers Develop Groundbreaking New Algorithm to Automatically Classify Lymphoma,https://www.reddit.com/r/MachineLearning/comments/283e2x/mit_and_harvard_researchers_develop/,graysquirrel20,1402702942,,0,1,False,http://a.thumbs.redditmedia.com/6uVsi1jm0W0iySEV.jpg,,,,,
88,MachineLearning,t5_2r3gv,2014-6-15,2014,6,15,0,284vgy,visualstudiomagazine.com,Deep Neural Networks: A Getting Started Tutorial -- Visual Studio Magazine,https://www.reddit.com/r/MachineLearning/comments/284vgy/deep_neural_networks_a_getting_started_tutorial/,mttd,1402759136,,10,22,False,http://b.thumbs.redditmedia.com/wrjFlzOjjjqkrcdO.jpg,,,,,
89,MachineLearning,t5_2r3gv,2014-6-16,2014,6,16,5,28827z,imgur.com,Dude... do you even Bayes?,https://www.reddit.com/r/MachineLearning/comments/28827z/dude_do_you_even_bayes/,piskvorky,1402862692,,5,0,False,default,,,,,
90,MachineLearning,t5_2r3gv,2014-6-16,2014,6,16,10,288rsm,self.MachineLearning,A few questions about getting started...,https://www.reddit.com/r/MachineLearning/comments/288rsm/a_few_questions_about_getting_started/,[deleted],1402881319,,4,1,False,default,,,,,
91,MachineLearning,t5_2r3gv,2014-6-16,2014,6,16,16,289i9g,self.MachineLearning,Question on putting all things together.,https://www.reddit.com/r/MachineLearning/comments/289i9g/question_on_putting_all_things_together/,dandruffhead,1402903689,"I am pretty new with ML, but I have done few small projects on ML using scikit-learn, opencv, etc. I've done online classes like Andrew Ng's ML as well. I can say I am quite familiar with how things work or the processes in general.

But I still do not understand how to put things together especially on the deployment of ML. Currently, let's say I'm doing a predictive engine or some sort, after done with training the samples, now I have the model of the prediction and I can start pumping in new sample to test.

In real project, how do people actually persist the information of the model after it is done with training? I've done googling, some suggest to use pickle (im using python btw). What are some other methods to actually store the information without the need to run the training sets again. This is the thing I am really confused. Most of examples only show a simple script that run training set and then run the prediction.

Thanks!",5,10,False,self,,,,,
92,MachineLearning,t5_2r3gv,2014-6-16,2014,6,16,17,289m1v,machineryequipment123.blogspot.com,Mining Trends: Caterpillar Hybridizes the Excavator - Machinery &amp; Equipment Part Online,https://www.reddit.com/r/MachineLearning/comments/289m1v/mining_trends_caterpillar_hybridizes_the/,jessicperson,1402908788,,0,1,False,default,,,,,
93,MachineLearning,t5_2r3gv,2014-6-16,2014,6,16,19,289qvt,issuu.com,ISSUU - Long Reach Excavator by Machines4u,https://www.reddit.com/r/MachineLearning/comments/289qvt/issuu_long_reach_excavator_by_machines4u/,jessicperson,1402915273,,0,1,False,default,,,,,
94,MachineLearning,t5_2r3gv,2014-6-16,2014,6,16,20,289s6w,nuit-blanche.blogspot.fr,"Tonight: Europe Wide Machine Learning Meetup and Paris Machine Learning #12: Season 1 Finale, Andrew Ng and More...",https://www.reddit.com/r/MachineLearning/comments/289s6w/tonight_europe_wide_machine_learning_meetup_and/,compsens,1402916861,,2,14,False,http://a.thumbs.redditmedia.com/UXZG6Y-XUtU5071p.jpg,,,,,
95,MachineLearning,t5_2r3gv,2014-6-17,2014,6,17,2,28al0p,cacm.acm.org,Judge Weighs In on Chatbots Turing Test Performance,https://www.reddit.com/r/MachineLearning/comments/28al0p/judge_weighs_in_on_chatbots_turing_test/,ACMlarry,1402938845,,4,1,False,http://a.thumbs.redditmedia.com/DNJfsvaL20-udU_F.jpg,,,,,
96,MachineLearning,t5_2r3gv,2014-6-17,2014,6,17,4,28b0e4,skizzlesec.com,"Security, Sentiment Analysis, and Machine Learning",https://www.reddit.com/r/MachineLearning/comments/28b0e4/security_sentiment_analysis_and_machine_learning/,MaxRogers5,1402947755,,0,2,False,http://b.thumbs.redditmedia.com/p9EZ3x6rWwnxGDg1.jpg,,,,,
97,MachineLearning,t5_2r3gv,2014-6-17,2014,6,17,5,28b3ni,azure.microsoft.com,Microsoft Announces Azure Machine-Learning-as-a-Service,https://www.reddit.com/r/MachineLearning/comments/28b3ni/microsoft_announces_azure/,InfiniteState,1402949664,,25,54,False,http://b.thumbs.redditmedia.com/faDo3-D50bCi4W9q.jpg,,,,,
98,MachineLearning,t5_2r3gv,2014-6-17,2014,6,17,8,28bp5i,streamhacker.com,Deep Search,https://www.reddit.com/r/MachineLearning/comments/28bp5i/deep_search/,japerk,1402962987,,6,0,False,http://a.thumbs.redditmedia.com/gTgS-n_Tf4eJhoSt.jpg,,,,,
99,MachineLearning,t5_2r3gv,2014-6-17,2014,6,17,15,28clf4,code.google.com,VisualRBM - An interactive tool for training RBMs and AutoEncoders on the GPU,https://www.reddit.com/r/MachineLearning/comments/28clf4/visualrbm_an_interactive_tool_for_training_rbms/,pospeselr,1402986918,,11,15,False,default,,,,,
100,MachineLearning,t5_2r3gv,2014-6-17,2014,6,17,19,28cwh4,dataconomy.com,Microsoft's Azure ML- What to Expect,https://www.reddit.com/r/MachineLearning/comments/28cwh4/microsofts_azure_ml_what_to_expect/,[deleted],1403000485,,0,0,False,default,,,,,
101,MachineLearning,t5_2r3gv,2014-6-18,2014,6,18,0,28dfy8,self.MachineLearning,"What do people think of the book ""Predicting Structured Data"" by the MIT press?",https://www.reddit.com/r/MachineLearning/comments/28dfy8/what_do_people_think_of_the_book_predicting/,[deleted],1403017397,"I work as data scientist with a start-up company, I have a linear algebra/measure theory heavy math background (I did some graduate level course work in those subjects while doing my bachelor's degree).  I've spent a decent amount of time studying Neural Networks when I got this job (I also do a lot of non-ML algorithmic work for the company) but I've realized that the best results in the field I'm working in use techniques like Hidden Markov Support Vector Machines.

I've been using ""Predicting Structured Data"" to get a better handle on the mathematics of using Kernel methods mixed with Probabilistic Graphical Models. I've found it does a great job of covering the material, but it doesn't have much in the way of exercises - I'm just left trying to prove propositions on my own, etc.

Is there a better or more popular book that covers this material?

Link: http://mitpress.mit.edu/books/predicting-structured-data
",5,30,False,self,,,,,
102,MachineLearning,t5_2r3gv,2014-6-18,2014,6,18,0,28djlm,hakkalabs.co,Practical Deep Learning Lecture: Machine Perception and Its Applications (Deeplearning4j),https://www.reddit.com/r/MachineLearning/comments/28djlm/practical_deep_learning_lecture_machine/,BKDev,1403019602,,0,0,False,default,,,,,
103,MachineLearning,t5_2r3gv,2014-6-18,2014,6,18,2,28dxt3,self.MachineLearning,Any tips for my dataset?,https://www.reddit.com/r/MachineLearning/comments/28dxt3/any_tips_for_my_dataset/,Rbender5,1403027595,"Im working on a medical dataset with a great deal of randomness. What Im trying to do is to identify a smaller subset of highly probable classifications for automatic diagnoses, hence the need for high precision. In my use case, its fine for the majority of the dataset to be a dont know and require a physician to manually review the case.

I suspect that only a few of my features are highly relevant, so my first approach has been with random forests to identify which those are. However, my first few attempts have been largely unsuccessful, Im guessing because of the high degree of randomness. The best result Ive gotten is about 55% accuracy on my test set. I tried restricting my test set to those that had a probability of 60% or greater, and achieved ~63%.

What Im wondering is, how should I tweak my approach to this problem? Is the bulk of the highly random data in the training set causing problems? Should I be using some sort of abstaining classifier instead? Any general tips or guidance would be much appreciated.",5,2,False,self,,,,,
104,MachineLearning,t5_2r3gv,2014-6-18,2014,6,18,8,28ewko,self.MachineLearning,What's a good data set to practice using an echo state network on?,https://www.reddit.com/r/MachineLearning/comments/28ewko/whats_a_good_data_set_to_practice_using_an_echo/,[deleted],1403047705,I'm writing an ESN from scratch and looking for a good data set to practice on. Anyone have any suggestions?,3,2,False,default,,,,,
105,MachineLearning,t5_2r3gv,2014-6-18,2014,6,18,21,28gc8b,d277f6d674b2cfd0d2436b2145030d5d731cac78.googledrive.com,Machine Learning for Clinical Data Analysis and Healthcare [NIPS 2013],https://www.reddit.com/r/MachineLearning/comments/28gc8b/machine_learning_for_clinical_data_analysis_and/,EastCoastLA,1403093471,,2,18,False,http://a.thumbs.redditmedia.com/Nruzpy8BiJ4MMGQT.jpg,,,,,
106,MachineLearning,t5_2r3gv,2014-6-18,2014,6,18,23,28go2e,self.MachineLearning,Downsides to Extreme Learning Machines?,https://www.reddit.com/r/MachineLearning/comments/28go2e/downsides_to_extreme_learning_machines/,pwoolf,1403102328,"I just came across [Extreme Learning Machines (ELM)](http://www.ntu.edu.sg/home/egbhuang/), and they seem to have some nice properties.  Essentially they are a neural network with a single layer of many hidden nodes.  However, the weights connecting the inputs to the hidden nodes are assigned randomly and never updated.  The weights between the hidden nodes and the outputs are learned in a single step. 

From my read, the method is not new.  [There is another post](http://www.reddit.com/r/Physics/comments/z09ag/physicists_you_win_the_state_of_the_art_in/) that claims it is similar to Random Matrices of Eugene Wigner in the 1940s, or gaussian processes from the 90s or Random Kitchen Sinks.

I started playing with [a python implementation of ELM](https://github.com/dclambert/Python-ELM), and it is crazy fast and works quite well.  Seems not to overfit on cross validation, and is pretty insensitive to the number of hidden nodes beyond a certain point.  Works on simple linear relationships, and more complex nonlinear ones quite well.  Handles noise well.  Also it is just so darn simple.   

So what is the catch?  Are these widely used?  If not, why?  ",19,11,False,self,,,,,
107,MachineLearning,t5_2r3gv,2014-6-19,2014,6,19,2,28h82r,self.MachineLearning,What kind of criteria to optimize when building a tree for Boosting algorithms?,https://www.reddit.com/r/MachineLearning/comments/28h82r/what_kind_of_criteria_to_optimize_when_building_a/,zl1zl,1403114099,"For example, For AdaBoost, at each iteration, we need to select the weak classifier that gives the smallest weighted error rate. If we want to build tree with depth larger than 1, it is desired to train the tree node by node greedily . What kind of criteria should we use to find the best split for the nodes? Select the split that gives the smallest weighted error or other rules like gini value?

Thanks a lot!",3,2,False,self,,,,,
108,MachineLearning,t5_2r3gv,2014-6-19,2014,6,19,3,28h9ju,self.MachineLearning,How can I apply machine learning to computer vision,https://www.reddit.com/r/MachineLearning/comments/28h9ju/how_can_i_apply_machine_learning_to_computer/,fight_off_thy_demons,1403114942,,2,1,False,default,,,,,
109,MachineLearning,t5_2r3gv,2014-6-19,2014,6,19,4,28hfhg,self.MachineLearning,"Want to do PhD in ML, should I be contacting profs directly?",https://www.reddit.com/r/MachineLearning/comments/28hfhg/want_to_do_phd_in_ml_should_i_be_contacting_profs/,[deleted],1403118138,,1,3,False,default,,,,,
110,MachineLearning,t5_2r3gv,2014-6-19,2014,6,19,4,28hjzd,self.MachineLearning,Does PageRank have a different name?,https://www.reddit.com/r/MachineLearning/comments/28hjzd/does_pagerank_have_a_different_name/,whatswithpagerank,1403120690,PageRank is a pretty intuitive concept when you analyze influences in directed graphs. I find it hard to believe that it hadn't been invented before Google. Does anyone know of earlier papers that introduce the idea? Does it have a different name?,8,12,False,self,,,,,
111,MachineLearning,t5_2r3gv,2014-6-19,2014,6,19,4,28hlal,self.MachineLearning,Machine Learning Study Group -- Thread # 2,https://www.reddit.com/r/MachineLearning/comments/28hlal/machine_learning_study_group_thread_2/,rovingr,1403121407,"This week's post is up on http://datasciencetalk.blogspot.com . We'll be focusing on Principal Component Analysis. 

Now that everyone has had a chance to read last week's article (Domingo's 'A Few Useful things to Know About Machine Learning', feel free to discuss it either in this thread, or in the blog's comments. 

Additionally, our Kaggle team is going well, though we are not taking additional team members at this time, since we have 6 team members right now. 


Links to past threads:
http://www.reddit.com/r/MachineLearning/comments/27p3aj/machine_learning_study_group_thread_1_update/
http://www.reddit.com/r/MachineLearning/comments/26x06e/machine_learning_study_group_thread_1/",10,9,False,self,,,,,
112,MachineLearning,t5_2r3gv,2014-6-19,2014,6,19,8,28i4n6,github.com,[HELP] Gas consumption outliers detection - Neural network project. Bad results,https://www.reddit.com/r/MachineLearning/comments/28i4n6/help_gas_consumption_outliers_detection_neural/,marcodena,1403132860,,3,1,False,http://a.thumbs.redditmedia.com/jONJje3Xd_kovgah.jpg,,,,,
113,MachineLearning,t5_2r3gv,2014-6-19,2014,6,19,9,28idnv,self.MachineLearning,"DropConnect Neural Networks, a final project.",https://www.reddit.com/r/MachineLearning/comments/28idnv/dropconnect_neural_networks_a_final_project/,[deleted],1403138812,"For the final project of our neural nets class a friend and I investigated DropConnect networks, regularization, and model averaging. Check out our [write-up](http://www.cs.hmc.edu/~jderose/html/main.html). We drew heavily from [DeepLearningToolBox](https://github.com/rasmusbergpalm/DeepLearnToolbox) but thought our extension was worth [sharing](https://github.com/billderose/DropConnect).",6,12,False,self,,,,,
114,MachineLearning,t5_2r3gv,2014-6-19,2014,6,19,12,28iszf,self.MachineLearning,Collecting training / testing information for on-line handwritten math classifier,https://www.reddit.com/r/MachineLearning/comments/28iszf/collecting_training_testing_information_for/,themoosemind,1403149348,"Hello,

I am currently writing my bachelors thesis about the recognition of handwritten mathematical symbols.
The aim is to provide a solid theoretical and base for a master thesis about recognition of complete mathematical formulas.
The practical part includes the website http://write-math.com which already classifies symbols.

Here is the reason why I write this post: I need more data. Different people write in a different way. To find meaningful results, I need a lot of data from different people.

Except for Email and password (which is stored individually salted and hashed) everything is shared:

* Code: https://github.com/MartinThoma/write-math
   - Of Classifiers: https://github.com/MartinThoma/write-math/tree/master/website/classifiers
* Data: https://github.com/MartinThoma/write-math/tree/master/database
* Scientific progress / results: https://github.com/MartinThoma/write-math/tree/master/bsthesis

Everything I make is under a MIT license.

So please: Could you register and train at http://write-math.com so that I get labeled training / testing information?

Best regards,
Martin",2,2,False,self,,,,,
115,MachineLearning,t5_2r3gv,2014-6-19,2014,6,19,15,28j5o1,jmlr.org,Structured Generative Models of Natural Source Code,https://www.reddit.com/r/MachineLearning/comments/28j5o1/structured_generative_models_of_natural_source/,galapag0,1403160240,,2,6,False,default,,,,,
116,MachineLearning,t5_2r3gv,2014-6-19,2014,6,19,16,28j9f9,machineryequipment123.blogspot.com,Benefits of Ball Mills - Machinery &amp; Equipment Part Online,https://www.reddit.com/r/MachineLearning/comments/28j9f9/benefits_of_ball_mills_machinery_equipment_part/,jessicperson,1403164544,,0,1,False,default,,,,,
117,MachineLearning,t5_2r3gv,2014-6-19,2014,6,19,19,28jhms,self.MachineLearning,Multiresponse regression with some eigenvector constraints,https://www.reddit.com/r/MachineLearning/comments/28jhms/multiresponse_regression_with_some_eigenvector/,bathingrickmoranis,1403174364,"Hey I'm dealing with a regression problem where I have a response matrix Y, data matrix X and some parameter matrix B. Let's say that their sizes are  (N,m), (N,p) and (p,m) respectively. 

To give you some insight then Y are actually histogram observations (approximations of a distribution) which I'm trying to predict hence there is a normalization constraints. I also want to use a linear model and find optimal B with respect to some loss e.g. the Frobenius norm. 

The constraints are the ones that I'm puzzled by and don't have an exact idea on how to deal with. They can be formulated in such a way that:

X*B*1 = 1 i.e. unitary vector (1) is an eigenvector of the matrix (X*B) with an eigenvalue 1. 

Is there another way to formulate these constraints? Can you use SVD to solve such an optimization problem? 

If you could at least point me in the right direction, cause I'm not exactly sure what to put in the search bars, then that would be awesome :)


edit 1 : Another way to formulate the constraint: (X*B - Y)*1 = 0

Edit 2: sorry it's not called unitary, it's just a vector with all entries as 1s.",0,1,False,self,,,,,
118,MachineLearning,t5_2r3gv,2014-6-20,2014,6,20,0,28k1mr,datascience.stackexchange.com,Data Science Stack Exchange,https://www.reddit.com/r/MachineLearning/comments/28k1mr/data_science_stack_exchange/,madisonmay,1403190730,,3,15,False,http://a.thumbs.redditmedia.com/_cQxjPmZwKhwY9nR.jpg,,,,,
119,MachineLearning,t5_2r3gv,2014-6-20,2014,6,20,1,28k93y,self.MachineLearning,ANCEM: An Artificial Neural Network for the Characterization of Emotion within Music,https://www.reddit.com/r/MachineLearning/comments/28k93y/ancem_an_artificial_neural_network_for_the/,raahilsha,1403195149,"I have started a project called ANCEM, which seeks to classify music
according to the multi-dimensional theory of emotion (activation &amp;
pleasantness).

As I am using a neural network, I need to provide ANCEM with large
amounts of training data so that it can be used in practice. Thus, I am
asking for assistance in creating training data in a very particular
format. If you would like to help, or are even just interested in the
project, please visit [this
website](http://www.pyronebula.com/ancem.html) and submit a few music
samples for the network to train on.

An example of a sample is [this
track](https://app.box.com/s/8rf8san7j0j1nscwnds3), which would
represent relaxation, or emotion #13 according to the table on the site.

Ultimately, I plan to create an app that can be used on a mobile device
that will look at all the music in your library and sort it by emotion.
The app will then allow you to play music based on how you are feeling
at that moment.

Thanks for reading. I hope you can help make this project a reality.",22,22,False,self,,,,,
120,MachineLearning,t5_2r3gv,2014-6-20,2014,6,20,3,28kjw7,jakevdp.github.io,Practical introduction to MCMC Bayesian inference using three Python alternatives.,https://www.reddit.com/r/MachineLearning/comments/28kjw7/practical_introduction_to_mcmc_bayesian_inference/,qkdhfjdjdhd,1403201125,,0,27,False,default,,,,,
121,MachineLearning,t5_2r3gv,2014-6-20,2014,6,20,4,28ku5z,kdnuggets.com,Does Deep Learning Have Deep Flaws? (x-post from /r/agi),https://www.reddit.com/r/MachineLearning/comments/28ku5z/does_deep_learning_have_deep_flaws_xpost_from_ragi/,nickb,1403206701,,0,0,False,http://a.thumbs.redditmedia.com/kidA63EzWCTXkCy6.jpg,,,,,
122,MachineLearning,t5_2r3gv,2014-6-20,2014,6,20,5,28kx1l,self.MachineLearning,A beginners doubt about gradient and Gradient Descent,https://www.reddit.com/r/MachineLearning/comments/28kx1l/a_beginners_doubt_about_gradient_and_gradient/,ericking640,1403208360,"Sorry for a newbie question. I haven't quite understood the correct meaning of what it means to take the partial derivative of a cost function with respect to the parameters of the model, say theta. Suppose these parameters include 2 arrays of dimensions axb and cxd.

When we do stochastic gradient descent, then what will be the partial derivative of J wrt theta (let's call it x)? Mathematically this is a symbolic expression. So when I program SGD, what should be the term x.

What happens if J is a scalar, and what happens if J is a matrix? If in any case it is a matrix, what will be its dimensions?

Thanks in advance!
Hope I can clarify this issue soon",4,0,False,self,,,,,
123,MachineLearning,t5_2r3gv,2014-6-20,2014,6,20,8,28lhgm,self.MachineLearning,Association Rule Mining to find unbeatable strategy in a Tic Tac Toe game,https://www.reddit.com/r/MachineLearning/comments/28lhgm/association_rule_mining_to_find_unbeatable/,gfoxvh,1403220790,"Hey guys! Thought of sharing with you :)
I have used association rule mining to extract game positions that ensure a win for X. The move I was interested was the 4th one. And I have got pretty interesting results on that.

http://cryptex-cs.blogspot.de/2014/06/association-rule-mining-tic-tac-toe.html
",4,7,False,self,,,,,
124,MachineLearning,t5_2r3gv,2014-6-20,2014,6,20,23,28n742,sulcus.berkeley.edu,The Neurobiological Infrastructure of Natural Computing: Intentionality [x-post from /r/chaoskampf],https://www.reddit.com/r/MachineLearning/comments/28n742/the_neurobiological_infrastructure_of_natural/,Chaoskampf_,1403275287,,0,5,False,default,,,,,
125,MachineLearning,t5_2r3gv,2014-6-21,2014,6,21,7,28ohy7,self.MachineLearning,Continuous state POMDP,https://www.reddit.com/r/MachineLearning/comments/28ohy7/continuous_state_pomdp/,mo_rar,1403304343,"Has anyone used the MCVI simulator provided by NUS for solving continuous state POMDPs, I am running into some problems, would be grateful if someone here may be able to help",1,3,False,self,,,,,
126,MachineLearning,t5_2r3gv,2014-6-21,2014,6,21,10,28owkn,jvns.ca,Kaggle competitions won't teach you machine learning,https://www.reddit.com/r/MachineLearning/comments/28owkn/kaggle_competitions_wont_teach_you_machine/,bork,1403315393,,18,31,False,default,,,,,
127,MachineLearning,t5_2r3gv,2014-6-21,2014,6,21,14,28pb33,pythonformachinelearning.wordpress.com,Python for Machine Learning | Learning through Experience,https://www.reddit.com/r/MachineLearning/comments/28pb33/python_for_machine_learning_learning_through/,RedItJot,1403327757,,0,0,False,http://a.thumbs.redditmedia.com/gUvv-eb-E87Zz3xb.jpg,,,,,
128,MachineLearning,t5_2r3gv,2014-6-21,2014,6,21,23,28q116,cs.berkeley.edu,AI on the Web,https://www.reddit.com/r/MachineLearning/comments/28q116/ai_on_the_web/,[deleted],1403360683,,0,1,False,default,,,,,
129,MachineLearning,t5_2r3gv,2014-6-21,2014,6,21,23,28q1d7,self.MachineLearning,How to bring divergence into GMM clustering?,https://www.reddit.com/r/MachineLearning/comments/28q1d7/how_to_bring_divergence_into_gmm_clustering/,hadian,1403360984,"I am working on a (modified) version of Gaussian mixture model for clustering. Unfortunately, The naive EM method converges to a solution in which two or more mean points (cluster centers) are exactly equal. I have tested several initialization methods (e.g. random means, results from another algorithm, and even the true -oracle- mean points), but it still converges to such local optimum.

Is there any mathematical technique that can prevent convergence into duplicated clusters and considers a penalty for duplicate mean points? (i.e. something similar to regularization term, maybe)",0,1,False,self,,,,,
130,MachineLearning,t5_2r3gv,2014-6-21,2014,6,21,23,28q2rf,erogol.com,"Our ECCV2014 work ""ConceptMap: Mining noisy web data for concept learning""",https://www.reddit.com/r/MachineLearning/comments/28q2rf/our_eccv2014_work_conceptmap_mining_noisy_web/,erogol,1403362115,,0,1,False,http://b.thumbs.redditmedia.com/wp1IcTUTr-tj-B6m.jpg,,,,,
131,MachineLearning,t5_2r3gv,2014-6-22,2014,6,22,3,28qkh0,cs.berkeley.edu,Wealth of machine learning and artificial intelligence material by Russell (University of California) &amp; Norvig (Google),https://www.reddit.com/r/MachineLearning/comments/28qkh0/wealth_of_machine_learning_and_artificial/,hoteit,1403375381,,4,47,False,default,,,,,
132,MachineLearning,t5_2r3gv,2014-6-22,2014,6,22,7,28r60o,self.MachineLearning,"What's a Comprehensive, Intuitive Machine Learning Resource?",https://www.reddit.com/r/MachineLearning/comments/28r60o/whats_a_comprehensive_intuitive_machine_learning/,throwmeaway39q234r,1403391148,"I want to apply the approaches I learn to Natural Language Processing (NLP). (I've already read Jurfsky and Martin's introductory NLP text.)

I don't mind at all if the material is challenging or full of mathematics, but I want to come away with an *intuition* for the techniques I learn. Along those lines, I'd like a good collection of exercises to cut my teeth on.",7,3,False,self,,,,,
133,MachineLearning,t5_2r3gv,2014-6-22,2014,6,22,16,28s3in,self.MachineLearning,What is required to work as an entry level data scientist/engineer?,https://www.reddit.com/r/MachineLearning/comments/28s3in/what_is_required_to_work_as_an_entry_level_data/,[deleted],1403421593,"I'll be graduating with a degree in CS in a year from a relatively unknown school, after dropping out of a top university for personal reasons (my math background is okay, except no calculus).

I recently finished the coursera course without difficulty, and I just got the [MLPP](http://www.amazon.com/Machine-Learning-Probabilistic-Perspective-Computation/dp/0262018020/) book. I lack the mathematical maturity to be able to get through it in a reasonable amount of time. Even after figuring out the math, it's unclear how I'd apply the math to data.

What level of technical knowledge is required for an entry-level machine learning job? And how can I proceed? (Is a master's necessary?)

To clarify, I'm mostly curious about the level of math required, I'm aware that there are business, software engineering, and dealing with data I/O involved. ",2,0,False,default,,,,,
134,MachineLearning,t5_2r3gv,2014-6-23,2014,6,23,2,28t1e8,self.MachineLearning,Google flu tricked: Any academic research about this topic?,https://www.reddit.com/r/MachineLearning/comments/28t1e8/google_flu_tricked_any_academic_research_about/,piscoster,1403459461,"Hello guys,

several articles came out about a short wile ago:

http://time.com/23782/google-flu-trends-big-data-problems/

http://www.businessweek.com/articles/2014-04-17/the-flu-tricked-google-dot-can-wikipedia-do-better

http://www.nature.com/news/when-google-got-flu-wrong-1.12413

As we can see from this example, google flu tends and also a lot of other models tend to have the problem of losing their accuracy over time, the model tends to fit to good to the underlying data(curve-fitting). Is there any scientific research done in this field how to prevent this phenomenon? 

Would appreciate papers/keywords!",15,8,False,self,,,,,
135,MachineLearning,t5_2r3gv,2014-6-23,2014,6,23,5,28tgvq,self.MachineLearning,Bagging vs Cross-Validation,https://www.reddit.com/r/MachineLearning/comments/28tgvq/bagging_vs_crossvalidation/,neeratyoy,1403470165,"How is Bagging (Bootstrap Aggregation) different from Cross Validation ?
In both we take samples from the training the data without replacement, train the classifier on it, then test for the out-of-bag error in case of Bagging, and the validation error in case of CV.
What essentially separates them in use and also in principle ?  ",9,8,False,self,,,,,
136,MachineLearning,t5_2r3gv,2014-6-23,2014,6,23,6,28tjh5,self.MachineLearning,Stupid question about NN weight update equations,https://www.reddit.com/r/MachineLearning/comments/28tjh5/stupid_question_about_nn_weight_update_equations/,purpleladydragons,1403472031,"I'm working with long short term memory cells which require that not every node in a layer connects to every node in another, I.e there are many 0-weight connections. The typical weight update equation looks like alpha * error(j) * output(i) where i connects to j. If I'm doing this for a whole layer with matrices I can't easily specify to skip the 0-weight connections without losing a lot of speed. How can I use matrix ops without changing the 0-weight connections? I was thinking to multiply the update equation by the current weight but I don't know if that would negatively affect the overall accuracy.",2,2,False,self,,,,,
137,MachineLearning,t5_2r3gv,2014-6-23,2014,6,23,13,28uha5,deeplearning.net,Deep Learning Tutorials,https://www.reddit.com/r/MachineLearning/comments/28uha5/deep_learning_tutorials/,hoteit,1403497502,,0,2,False,default,,,,,
138,MachineLearning,t5_2r3gv,2014-6-23,2014,6,23,14,28uksg,self.MachineLearning,Interesting Optimization Problem Related to Information Gain,https://www.reddit.com/r/MachineLearning/comments/28uksg/interesting_optimization_problem_related_to/,[deleted],1403500479,"I've been thinking of the problem of how to supply information to a neural network. Given that I have a defined amount of information (e.g x + y + z + a = 100), how can I maximize the volume of the neural net. In a simple case, this optimization problem can be formed as:

(x^1) x (y^2) x (z^3) x  (a^4) where x+y+z+a=100.

The trick is, it's not to put them all evenly, or even put them so that the weight sights toward the a^4. It's been bothering me for about a week now, and I don't know any methods that solve this kind of optimization.

Here's a start to see why:

(25^1) x (25^2) x (25^3) x (25^4) = 9.53x10^13, which is essentially 25^10. So we take 1 from the (25^4) and distribute to each and make it (28^3) x (24^7).. which if you break it down is just a simplification of (24^1) x (24^2) x (28^3) x (24^4) = (24^7) x (28^3)

and that makes (28^3) x (24^7) &gt; 25^10

This problem may have many local maxima and many local minima, could I get some insight on this?

Thanks!",3,2,False,default,,,,,
139,MachineLearning,t5_2r3gv,2014-6-23,2014,6,23,16,28us1y,machineryequipment123.blogspot.com,How Is Technology Helping The Mining Companies - Machinery &amp; Equipment Part Online,https://www.reddit.com/r/MachineLearning/comments/28us1y/how_is_technology_helping_the_mining_companies/,jessicperson,1403507463,,0,1,False,default,,,,,
140,MachineLearning,t5_2r3gv,2014-6-23,2014,6,23,17,28uwzb,blog.datumbox.com,The Dirichlet Process Mixture Model and the Gibbs Sampler,https://www.reddit.com/r/MachineLearning/comments/28uwzb/the_dirichlet_process_mixture_model_and_the_gibbs/,datumbox,1403513466,,0,16,False,http://a.thumbs.redditmedia.com/jJenlnQnxyN1nGYz.jpg,,,,,
141,MachineLearning,t5_2r3gv,2014-6-23,2014,6,23,17,28uxe6,scribd.com,Mobile Crushers,https://www.reddit.com/r/MachineLearning/comments/28uxe6/mobile_crushers/,jessicperson,1403513976,,0,1,False,default,,,,,
142,MachineLearning,t5_2r3gv,2014-6-24,2014,6,24,0,28voe1,hakkalabs.co,Square's Machine Learning Infrastructure and Applications,https://www.reddit.com/r/MachineLearning/comments/28voe1/squares_machine_learning_infrastructure_and/,BKDev,1403538044,,3,24,False,default,,,,,
143,MachineLearning,t5_2r3gv,2014-6-24,2014,6,24,2,28w25f,self.MachineLearning,"Do you happen to know of a free dataset with handwritten English block capitals? If not, could you contribute to mine?",https://www.reddit.com/r/MachineLearning/comments/28w25f/do_you_happen_to_know_of_a_free_dataset_with/,popoffka,1403545863,"I'm currently working on a little OCR-related project, and I was quite surprised to find that there don't seem to be any free sets of scanned images of handwritten letters. Am I missing something?

I've already started gathering my own data set. Would some of you care to contribute, pretty please?
I need something like [this](https://i.imgur.com/XeGxmCF.jpg): scan at 300 DPI, try to make each letter at least 100 px high and place them 50 px apart (this corresponds to about 2 cm and 1 cm on paper). You don't have to write each letters six times: 2-3 are already greatly appreciated, but even one of each will be OK.
If I manage to collect a good enough data set, I will make it public and free for anyone to use.

Thanks a lot!",4,7,False,self,,,,,
144,MachineLearning,t5_2r3gv,2014-6-24,2014,6,24,11,28xg8k,self.MachineLearning,[Question] AdaBoost as service?,https://www.reddit.com/r/MachineLearning/comments/28xg8k/question_adaboost_as_service/,throwaway_sss,1403575544,"Hi,
 I have a moderate dataset I'd like to run AdaBoost over (~1M points, 140 features each).

It is taking a really long time on my machine.

Is there a paid service where I can upload my data and let them run AdaBoost over it? I am fine paying a reasonable fee. I was hoping by using a big cluster of machines, they'd be able to run it way faster than I can. Thanks in advance.

",5,2,False,self,,,,,
145,MachineLearning,t5_2r3gv,2014-6-24,2014,6,24,16,28y4j4,issuu.com,ISSUU - Cone Crusher by Machines4u,https://www.reddit.com/r/MachineLearning/comments/28y4j4/issuu_cone_crusher_by_machines4u/,jessicperson,1403594826,,0,1,False,default,,,,,
146,MachineLearning,t5_2r3gv,2014-6-24,2014,6,24,18,28y98z,blog.applysci.com,Context sensitive robot understands casual language,https://www.reddit.com/r/MachineLearning/comments/28y98z/context_sensitive_robot_understands_casual/,ApplySci,1403600632,,0,0,False,http://a.thumbs.redditmedia.com/I7YlOhK2-VV_2QLp.jpg,,,,,
147,MachineLearning,t5_2r3gv,2014-6-24,2014,6,24,18,28y9qc,self.MachineLearning,Why use sparse overcomplete autoencoders vs. non-over complete normal ones?,https://www.reddit.com/r/MachineLearning/comments/28y9qc/why_use_sparse_overcomplete_autoencoders_vs/,[deleted],1403601247,"[This page](http://torch.cogbits.com/doc/tutorials_unsupervised/) recommends the use of sparsified overcomplete autoencoders (i.e. the learned representation has a higher dimensionality than the input, but many of the values are zeros). 

What is the advantage of this over a normal autoencoder?",3,6,False,default,,,,,
148,MachineLearning,t5_2r3gv,2014-6-24,2014,6,24,21,28yj5s,self.MachineLearning,Deep Learning Applications aside from Vision/Speech/NLP,https://www.reddit.com/r/MachineLearning/comments/28yj5s/deep_learning_applications_aside_from/,binge_learner,1403611832,"Hi guys,

Deep Learning has numerous applications in Computer Vision, Speech Recognition and NLP. Bu I was wondering if anyone cared applying these techniques to other fields ? And do you guys have any resources ( articles, ...) about the subject ?

Thank you !",14,16,False,self,,,,,
149,MachineLearning,t5_2r3gv,2014-6-25,2014,6,25,0,28yyhr,self.MachineLearning,Replication of machine learning experiment,https://www.reddit.com/r/MachineLearning/comments/28yyhr/replication_of_machine_learning_experiment/,piscoster,1403622714,"Hello guys,

one big problem in science and machine learning seems to be the replication of experiments in machine learning. For example to analyse the recent google flu data problem:

http://www.sciencemag.org/content/343/6176/1203.full#xref-ref-13-1

Is there any scientific research done in this field how to actually replicate data science experiments in a meaningful way?

Would appreciate papers/keywords!",3,3,False,self,,,,,
150,MachineLearning,t5_2r3gv,2014-6-25,2014,6,25,2,28zbdo,reference.wolfram.com,Wolfram Language new 'Classify' Machine Learning method,https://www.reddit.com/r/MachineLearning/comments/28zbdo/wolfram_language_new_classify_machine_learning/,louisdorard,1403630282,,2,3,False,http://a.thumbs.redditmedia.com/09syhqJXqHjz0z8l.jpg,,,,,
151,MachineLearning,t5_2r3gv,2014-6-25,2014,6,25,5,28zx25,self.MachineLearning,How much math do you need to understand machine learning algorithms?,https://www.reddit.com/r/MachineLearning/comments/28zx25/how_much_math_do_you_need_to_understand_machine/,zapdos,1403642007,"How much math do you need to understand common ML algorithms? Not just being able to apply the algorithms...but being able to fully explain why and how they work. And which specific topics?


My background is computer science so I'm only used to dealing with the discrete and am feeling rusty when encountering stuff like gradients and partial derivatives. I thought I'd just make a list of stuff to review and get it over at once.",24,25,False,self,,,,,
152,MachineLearning,t5_2r3gv,2014-6-25,2014,6,25,5,28zzje,self.MachineLearning,Boundary detection across a spatial point process by a continuous variable,https://www.reddit.com/r/MachineLearning/comments/28zzje/boundary_detection_across_a_spatial_point_process/,windpipe123,1403643380,"Hello all - I'm new to machine learning although I have lots of experience doing prediction with OLS and Logistic regression (ie. cross-validaiton, out-of-sample prediction etc.) as well a bit of clustering (k-means mostly)

Ideally I'm looking for some advice on methods (maybe even an R package) on detecting boundaries across a spatial point process using a continuous outcome.  The data is correlated in space but very noisy.  There are 2 ways I'd like to ask the question - the second likely more difficult than the first.

1. Imagine I had the income of every household (and the xy coordinates of their house) in a city and wanted to cluster these events without an a priori notion of how many clusters exist.  Again the data are noisy.  What algorithms should I look at? Are any specifically well-suited to spatial data?

2. Imagine I took this same data where each house knew which street it was closest too.  I would like to ask which streets exhibit the greatest statistically significant income differences on either side.  What algorithms might be useful for this approach.  I realize such a hypothesis test is likely not the best way to approach this problem but it seems intuitive enough for a lay person.

Thanks for the advice.

",1,0,False,self,,,,,
153,MachineLearning,t5_2r3gv,2014-6-25,2014,6,25,13,29125o,dataorigami.net,Data Origami Screencasts - level up your data skills,https://www.reddit.com/r/MachineLearning/comments/29125o/data_origami_screencasts_level_up_your_data_skills/,[deleted],1403668938,,0,0,False,default,,,,,
154,MachineLearning,t5_2r3gv,2014-6-25,2014,6,25,18,291lp8,self.MachineLearning,Deeplearning.net code - how to actually get predictions from ANN?,https://www.reddit.com/r/MachineLearning/comments/291lp8/deeplearningnet_code_how_to_actually_get/,[deleted],1403688122,"I'm currently using the SdA code, and it seems to train okay, but how do I actually get the predictions for test data?

This seems like a really stupid question, but it's not so simple with the Theano code.",5,0,False,default,,,,,
155,MachineLearning,t5_2r3gv,2014-6-25,2014,6,25,19,291omv,self.MachineLearning,Tutorials on Sentiment Analysis?,https://www.reddit.com/r/MachineLearning/comments/291omv/tutorials_on_sentiment_analysis/,Chobeat,1403691777,"Greetings,

i'm taking my first steps in the world of real machine learning and i need to work on a problem of sentiment analysis. My teacher told me to look for stuff on the subject in the literature, mainly to understand how to do sentiment analysis on Twitter. 

I would love to receive suggestions on papers and tutorials useful to this objective both generic or specific to Twitter.",10,8,False,self,,,,,
156,MachineLearning,t5_2r3gv,2014-6-25,2014,6,25,21,291v3i,insightdataengineering.com,Insight Data Engineering Fellows Program applications open for September 2014,https://www.reddit.com/r/MachineLearning/comments/291v3i/insight_data_engineering_fellows_program/,jakek123,1403698804,,2,1,False,default,,,,,
157,MachineLearning,t5_2r3gv,2014-6-25,2014,6,25,23,2926t8,cs.utexas.edu,Inferring Unseen Views of People,https://www.reddit.com/r/MachineLearning/comments/2926t8/inferring_unseen_views_of_people/,galapag0,1403707483,,0,2,False,default,,,,,
158,MachineLearning,t5_2r3gv,2014-6-26,2014,6,26,1,292f6p,shakthydoss.com,"What is the difference between Artificial Intelligence, machine learning, statistics, and data mining :",https://www.reddit.com/r/MachineLearning/comments/292f6p/what_is_the_difference_between_artificial/,shakthydoss,1403712442,,8,42,False,http://a.thumbs.redditmedia.com/DcPLNcEJqliulYmH.jpg,,,,,
159,MachineLearning,t5_2r3gv,2014-6-26,2014,6,26,2,292p5a,dataconomy.com,Understanding Big Data: Machine Learning,https://www.reddit.com/r/MachineLearning/comments/292p5a/understanding_big_data_machine_learning/,eileenamholmes,1403717923,,0,0,False,default,,,,,
160,MachineLearning,t5_2r3gv,2014-6-26,2014,6,26,3,292spn,javaworld.com,What's machine learning? It depends on who you ask.,https://www.reddit.com/r/MachineLearning/comments/292spn/whats_machine_learning_it_depends_on_who_you_ask/,confused_n_lovinit,1403719862,,0,0,False,default,,,,,
161,MachineLearning,t5_2r3gv,2014-6-26,2014,6,26,5,2938a3,self.MachineLearning,Machine Learning for Time Series (Power Consumption Data),https://www.reddit.com/r/MachineLearning/comments/2938a3/machine_learning_for_time_series_power/,binge_learner,1403728256,"Hi guys,

I am working on a problem where I am trying to predict Time Series data, using historical observations and another Time Series dataset ( predicting power consumption using historical data and weather data ).
And I was wondering if some of you can point me towards relevant work in the field.

Thanks a lot guys ! ",12,9,False,self,,,,,
162,MachineLearning,t5_2r3gv,2014-6-26,2014,6,26,6,293dps,lucy24.bitbucket.org,Andrew Ng about Deep Learning at Paris ML Meetup,https://www.reddit.com/r/MachineLearning/comments/293dps/andrew_ng_about_deep_learning_at_paris_ml_meetup/,amyrit,1403731254,,1,11,False,default,,,,,
163,MachineLearning,t5_2r3gv,2014-6-26,2014,6,26,8,293rg4,dataorigami.net,Sorting Colors using PCA [Screencast],https://www.reddit.com/r/MachineLearning/comments/293rg4/sorting_colors_using_pca_screencast/,HootBack,1403739512,,4,16,False,http://a.thumbs.redditmedia.com/6m2H86-Iy2fCLtpN.jpg,,,,,
164,MachineLearning,t5_2r3gv,2014-6-26,2014,6,26,15,294oxx,self.MachineLearning,Best metric for clustering evaluation on BIG-DATA?,https://www.reddit.com/r/MachineLearning/comments/294oxx/best_metric_for_clustering_evaluation_on_bigdata/,hadian,1403763961,"I have made a new algorithm that is specifically crafted for clustering very large datasets. In order to document it as a research paper, I have to choose one or two internal (no-label) cluster evaluation measures to evaluate my algorithm. Which algorithm do you think is generally the best choice for big datasets? And why???

Note that my method evaluates non-spherical clusters (similar to gaussian-mixture clustering). So spherical evaluation measures such as sum of squared error (SSE) are not a good choice.",0,1,False,self,,,,,
165,MachineLearning,t5_2r3gv,2014-6-26,2014,6,26,18,294yz7,self.MachineLearning,Will Kmeans++'s initialization improve the convergence of Gaussian Mixture Model?,https://www.reddit.com/r/MachineLearning/comments/294yz7/will_kmeanss_initialization_improve_the/,[deleted],1403776225,"Dear ML,

I'm pretty new to clustering algorithms. My question is if I initialize mean vector of each Gaussian pdf in GMM following the Kmeans++ method, would there be any advantage and why? Is there any work about this because quickly googling gave me nothing.

Thank you in advance.",8,7,False,self,,,,,
166,MachineLearning,t5_2r3gv,2014-6-26,2014,6,26,21,2958ya,sebastianraschka.com,Entry point: Data - Using Python's sci-packages to prepare data for Machine Learning tasks and other data analyses,https://www.reddit.com/r/MachineLearning/comments/2958ya/entry_point_data_using_pythons_scipackages_to/,rasbt,1403787085,,4,23,False,http://b.thumbs.redditmedia.com/hdfWlMykzDieLSYs.jpg,,,,,
167,MachineLearning,t5_2r3gv,2014-6-27,2014,6,27,3,2967qh,self.MachineLearning,"Machine Learning Study Group: Week 3: Breiman's ""Statistical Modeling: The Two Cultures""",https://www.reddit.com/r/MachineLearning/comments/2967qh/machine_learning_study_group_week_3_breimans/,rovingr,1403808523,"This week's blog post is up -- check out http://datasciencetalk.blogspot.com . This week's article is Breiman's 'Statistical Modeling: The Two Cultures' -- feel free to discuss the article either in this thread or in the blog's comments, as well as last week's post on Principal Component Analysis.

Links to past threads:
http://www.reddit.com/r/MachineLearning/comments/28hlal/machine_learning_study_group_thread_2/
http://www.reddit.com/r/MachineLearning/comments/27p3aj/machine_learning_study_group_thread_1_update/ http://www.reddit.com/r/MachineLearning/comments/26x06e/machine_learning_study_group_thread_1/",3,19,False,self,,,,,
168,MachineLearning,t5_2r3gv,2014-6-27,2014,6,27,5,296hip,self.MachineLearning,Are there any good sources for chat log datasets?,https://www.reddit.com/r/MachineLearning/comments/296hip/are_there_any_good_sources_for_chat_log_datasets/,geareddev,1403813715,Are there any good data sets out there for online chat logs between two strangers?  I'm working on a chat bot and I'd like to train it against natural chat logs.   Time stamped conversations would be a plus.  My initial goal is to build a system that finds patterns in how people introduce themselves to strangers online.  ,2,2,False,self,,,,,
169,MachineLearning,t5_2r3gv,2014-6-27,2014,6,27,5,296le0,cerebralmastication.com,Principal Component Analysis vs. Ordinary Least Squares: a visual explanation.,https://www.reddit.com/r/MachineLearning/comments/296le0/principal_component_analysis_vs_ordinary_least/,qkdhfjdjdhd,1403815856,,3,17,False,http://b.thumbs.redditmedia.com/tyYK6teUM_FH0cUw.jpg,,,,,
170,MachineLearning,t5_2r3gv,2014-6-27,2014,6,27,6,296p3e,self.MachineLearning,Problem sets for Yann LeCun's Spring class on DL?,https://www.reddit.com/r/MachineLearning/comments/296p3e/problem_sets_for_yann_lecuns_spring_class_on_dl/,throwaway,1403817993,"I'd like to work through Yann LeCun's [Spring class on Deep Learning](http://cilvr.cs.nyu.edu/doku.php?id=deeplearning:slides:start).  The website has no information about the problem sets, and very little about the labs for the class.  Are they available anywhere?

Other suggestions for DL tutorials based around Torch are welcome.  I've already gone through the official Torch7 tutorial, but it's a bit fast, in terms of introducing the concepts.  If I don't find any, I'm thinking of translating the deeplearning.net tutorial to Torch.",2,3,False,self,,,,,
171,MachineLearning,t5_2r3gv,2014-6-27,2014,6,27,14,297vss,probmods.org,Probabilistic Models of Cognition (by Goodman &amp; Tenenbaum).,https://www.reddit.com/r/MachineLearning/comments/297vss/probabilistic_models_of_cognition_by_goodman/,qkdhfjdjdhd,1403846583,,4,9,False,default,,,,,
172,MachineLearning,t5_2r3gv,2014-6-27,2014,6,27,15,297zxe,gorge.net.au,What Do Mobile Crushers Do - What Do,https://www.reddit.com/r/MachineLearning/comments/297zxe/what_do_mobile_crushers_do_what_do/,jessicperson,1403850607,,0,1,False,default,,,,,
173,MachineLearning,t5_2r3gv,2014-6-27,2014,6,27,17,2986yk,self.MachineLearning,ELI5 why projecting input onto random matrices ends up identifying the signal?,https://www.reddit.com/r/MachineLearning/comments/2986yk/eli5_why_projecting_input_onto_random_matrices/,AmusementPork,1403858587,"I see random matrices popping up everywhere these days (Compressed Sensing, Extreme Learning Machines, reservoir computing, random projections, etc.) but I still don't fundamentally understand how they work. Why does this phenomenon not just randomly corrupt your input and that's it?",8,9,False,self,,,,,
174,MachineLearning,t5_2r3gv,2014-6-27,2014,6,27,18,2989w4,self.MachineLearning,Anomaly detection in machine learning,https://www.reddit.com/r/MachineLearning/comments/2989w4/anomaly_detection_in_machine_learning/,piscoster,1403862288,"Hello guys,

I am extremely interested in anomaly/fraud detection in machine learning. I have read some scientific papers about this topic and personally think that this topic is quite satured by scientific research. Besides that I would like to contribute to this field in my free time and I am looking for research questions.

Therefore, my question is:

Which questions are still open in anomaly/fraud detection? What are interesting subfield in anomaly/fraud detection?

I really would appreciate your hints about papers/research articles? 

Best regards!",5,10,False,self,,,,,
175,MachineLearning,t5_2r3gv,2014-6-27,2014,6,27,23,298prr,hakkalabs.co,Machine Learning Tutorial: Distributed Gradient Boosting (GBM),https://www.reddit.com/r/MachineLearning/comments/298prr/machine_learning_tutorial_distributed_gradient/,BKDev,1403878425,,0,10,False,http://a.thumbs.redditmedia.com/cgQvOtRnvRyeD7Xj.jpg,,,,,
176,MachineLearning,t5_2r3gv,2014-6-28,2014,6,28,2,299a5z,self.MachineLearning,[REQUEST] Fuzzy logic(?) pattern matching + n-gram forecast tool to assist building algorithm?,https://www.reddit.com/r/MachineLearning/comments/299a5z/request_fuzzy_logic_pattern_matching_ngram/,[deleted],1403891198,"Please excuse my newbieness...  Let me know if there is a better subreddit for this request.

Example of a pattern record with total length as integer or string (one or the other is fine):

Pattern (string): 1211

Total length (integer): 9

Total length (string): 000000000

Example of time series data as a string using n-grams to forecast next element:

(string): 121121121212111

Goal:

I'm trying to find a tool that would help me produce an algorithm (EDIT: or I could integrate with my data sources for real-time analysis) that would perform approximate matching of the string patterns based on their total length and after a match is found use the time series data to forecast the end of the current/start of the next pattern. 

Something that could tell me ""using this fuzzy logic algo with the current pattern against the data with a pattern/length tolerance of n then forecasting the next time series element we are able to determine a reasonable approximation of the end/start of the next pattern"".

I read else where someone using Matlab simulation and R, but details are not available.  I'm willing to investigate any potential tool, but free is best.  ;-)

Any help is appreciated.  Thanks!",0,0,False,default,,,,,
177,MachineLearning,t5_2r3gv,2014-6-28,2014,6,28,3,299g2l,self.MachineLearning,Machine learning with evolving set of features ?,https://www.reddit.com/r/MachineLearning/comments/299g2l/machine_learning_with_evolving_set_of_features/,dexter89_kp,1403894790,"Hi all,

I was recently wondering about how machine learning systems are developed in real world, especially when there could be new data streams and new features in the future.

Imagine, there is a customer marketing model, which uses data from 20 separate sources and integrates them together and learns a classifier/predictor. Now six months down the line, there is a possibility of adding another set of features which were previously not explored in the model. 

How does the integration take place ? In a batch setting, is the model recreated from scratch, assuming missing values for data not available ? or is there a way to update the model without rerunning the entire system ? ",3,4,False,self,,,,,
178,MachineLearning,t5_2r3gv,2014-6-28,2014,6,28,3,299gbk,sciencemag.org,New clustering algorithm in Science,https://www.reddit.com/r/MachineLearning/comments/299gbk/new_clustering_algorithm_in_science/,SuperFX,1403894932,,25,26,False,default,,,,,
179,MachineLearning,t5_2r3gv,2014-6-28,2014,6,28,4,299jbj,youtube.com,Google I/O 2014 - Biologically inspired models of intelligence,https://www.reddit.com/r/MachineLearning/comments/299jbj/google_io_2014_biologically_inspired_models_of/,pedro_123,1403896806,,14,9,False,http://a.thumbs.redditmedia.com/JZ_Szwb6qrBRgYzX.jpg,,,,,
180,MachineLearning,t5_2r3gv,2014-6-29,2014,6,29,2,29byic,self.MachineLearning,What are some recent advancements in the anomaly detection space?,https://www.reddit.com/r/MachineLearning/comments/29byic/what_are_some_recent_advancements_in_the_anomaly/,[deleted],1403975451,"Looking for algorithms which have been examined within the last few years and look promising. All I really need are some names, but if you have links to papers examining them that would be much appreciated as well.",0,1,False,default,,,,,
181,MachineLearning,t5_2r3gv,2014-6-29,2014,6,29,3,29c45u,self.MachineLearning,"Pyramid ConvNet, greedy supervised pre-training, 97.3% on labeled faces dataset?",https://www.reddit.com/r/MachineLearning/comments/29c45u/pyramid_convnet_greedy_supervised_pretraining_973/,meandtree,1403979658,"I came across a paper which proposes a pretty interesting method of training ConvNets I haven't really seen before: http://arxiv.org/pdf/1403.2802v1.pdf

This seems like the supervised version of the greedy layerwise pre-training people used to do. I'm kind of surprised such a simple strategy works. It doesn't even seem like there's any fine tuning is done.

Has anyone looked into this Pyramid CNN architecture? It seems way more computationally efficient to train than regular ConvNets.",5,3,False,self,,,,,
182,MachineLearning,t5_2r3gv,2014-6-29,2014,6,29,6,29cje0,nuit-blanche.blogspot.fr,"Saturday Morning Videos: Data Science and Massive Data Analysis, ESIEE Paris",https://www.reddit.com/r/MachineLearning/comments/29cje0/saturday_morning_videos_data_science_and_massive/,compsens,1403990770,,0,4,False,http://a.thumbs.redditmedia.com/UXZG6Y-XUtU5071p.jpg,,,,,
183,MachineLearning,t5_2r3gv,2014-6-29,2014,6,29,6,29ck3l,self.MachineLearning,Python Recommendation Frameworks,https://www.reddit.com/r/MachineLearning/comments/29ck3l/python_recommendation_frameworks/,[deleted],1403991294,"For fun I'm developing a Python application that recommends Soundcloud users with other users who have similiar taste in followers and liked tracks. This is something that I can create on my own but I eventually want it to match users with specific songs too. I don't know much about algorithms or machine learning so I was hoping that I could just implement an already existing Python framework. Based on the task I've described does anyone here have a recommendation of a framework I should look into? Thanks, Blzn.",0,0,False,default,,,,,
184,MachineLearning,t5_2r3gv,2014-6-29,2014,6,29,6,29clbi,bugra.github.io,Law of Large Numbers and Central Limit Theorem,https://www.reddit.com/r/MachineLearning/comments/29clbi/law_of_large_numbers_and_central_limit_theorem/,bugra,1403992189,,2,4,False,default,,,,,
185,MachineLearning,t5_2r3gv,2014-6-29,2014,6,29,8,29ctf7,self.MachineLearning,How to initialize rectifier linear units (ReLU) network,https://www.reddit.com/r/MachineLearning/comments/29ctf7/how_to_initialize_rectifier_linear_units_relu/,rishok,1403998360,"when using the Relu activation function, what is the right way to initialize the weights and the bias of one network",4,6,False,self,,,,,
186,MachineLearning,t5_2r3gv,2014-6-29,2014,6,29,13,29ddxt,self.MachineLearning,Clustering Question: Formatting and Visualizing Data,https://www.reddit.com/r/MachineLearning/comments/29ddxt/clustering_question_formatting_and_visualizing/,equalx,1404015747,"If there's a better place to post something like this, please let me know.

I have a data set of high-dimensional categorical variables.  It's for a card game where winning requires strategy, and instead of a strict ordering, there's a sort of ""rock paper scissors"" tactic for winning.  Hands are semi-random, there's both strategic and preferential card selection going on.  I want to cluster to find different types of hands (bear with me on that, I know it sounds a little silly).

I'm trying to figure out how to represent the data - My current idea is a vector of 52 0s and 1s, where 1s represent cards in your hand?  If I run that through something like k-means, how can I display the clusters I come up with?

The biggest issues I've been having are because my data is huge (millions of rows, but I can sample) and I don't know how to represent it visually with such high dimensionality.  If I'm able to visualize correctly, I expect to see some cards in several clusters.

I'm working with this in R, if it matters or if there's a good package to help.  Also, if anything I posted was unclear, please ask.  Thanks!",3,9,False,self,,,,,
187,MachineLearning,t5_2r3gv,2014-6-29,2014,6,29,18,29dse6,self.MachineLearning,Rules of thumb for input size in Deep Neural Network,https://www.reddit.com/r/MachineLearning/comments/29dse6/rules_of_thumb_for_input_size_in_deep_neural/,biboufr,1404034014,"I was wondering if there is any rules of thumb for the input size of a Deep Neural Network in a regression case with time series data? 

I mean, should the number of features be equal to a certain multiple of the number of examples used in input ? (when I an choosing the window size aka the number of features in input)
Cheers !",4,0,False,self,,,,,
188,MachineLearning,t5_2r3gv,2014-6-29,2014,6,29,19,29du5r,youtube.com,Has the McGurk Effect been studied under speech-recognition/computer-vision?,https://www.reddit.com/r/MachineLearning/comments/29du5r/has_the_mcgurk_effect_been_studied_under/,yudlejoza,1404036977,,8,15,False,http://b.thumbs.redditmedia.com/7xhTITLz5XJH70pK.jpg,,,,,
189,MachineLearning,t5_2r3gv,2014-6-29,2014,6,29,22,29e41u,self.MachineLearning,Learn from current categories in bank statement for future data?,https://www.reddit.com/r/MachineLearning/comments/29e41u/learn_from_current_categories_in_bank_statement/,funny_games,1404050264,,2,0,False,default,,,,,
190,MachineLearning,t5_2r3gv,2014-6-30,2014,6,30,8,29ffo7,lesswrong.com,The Weighted Majority Algorithm.,https://www.reddit.com/r/MachineLearning/comments/29ffo7/the_weighted_majority_algorithm/,qkdhfjdjdhd,1404083926,,12,10,False,default,,,,,
191,MachineLearning,t5_2r3gv,2014-6-30,2014,6,30,13,29g4t7,fastml.com,Extreme Learning Machines and optimizing hyperparams with hyperopt.,https://www.reddit.com/r/MachineLearning/comments/29g4t7/extreme_learning_machines_and_optimizing/,qkdhfjdjdhd,1404102773,,0,15,False,http://a.thumbs.redditmedia.com/VagemTPAVPCOG7ox.jpg,,,,,
192,MachineLearning,t5_2r3gv,2014-6-30,2014,6,30,17,29ghav,self.MachineLearning,What's the best place to look for Swype datasets?,https://www.reddit.com/r/MachineLearning/comments/29ghav/whats_the_best_place_to_look_for_swype_datasets/,[deleted],1404115230,,3,0,False,default,,,,,
193,MachineLearning,t5_2r3gv,2014-6-30,2014,6,30,18,29gms5,blog.datumbox.com,Clustering documents and gaussian data with Dirichlet Process Mixture Models,https://www.reddit.com/r/MachineLearning/comments/29gms5/clustering_documents_and_gaussian_data_with/,datumbox,1404122356,,0,6,False,http://a.thumbs.redditmedia.com/jJenlnQnxyN1nGYz.jpg,,,,,
