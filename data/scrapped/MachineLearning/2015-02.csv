,sbr,sbr_id,date,year,month,hour,day,id,domain,title,full_link,author,created,selftext,num_comments,score,over_18,thumbnail,media_provider,media_thumbnail,media_title,media_description,media_url
0,MachineLearning,t5_2r3gv,2015-2-1,2015,2,1,13,2udj95,reddit.com,AI-themed Art  /r/artificial,https://www.reddit.com/r/MachineLearning/comments/2udj95/aithemed_art_rartificial/,chras,1422763426,,1,0,False,default,,,,,
1,MachineLearning,t5_2r3gv,2015-2-1,2015,2,1,17,2ue665,self.MachineLearning,can someone share Papers or reading material or online lectures(link) about data stream mining?,https://www.reddit.com/r/MachineLearning/comments/2ue665/can_someone_share_papers_or_reading_material_or/,tushar1408,1422781014,,2,3,False,self,,,,,
2,MachineLearning,t5_2r3gv,2015-2-1,2015,2,1,20,2ueesd,journals.aps.org,High-Reproducibility and High-Accuracy Method for Automated Topic Classification,https://www.reddit.com/r/MachineLearning/comments/2ueesd/highreproducibility_and_highaccuracy_method_for/,alexeyr,1422790913,,10,38,False,http://b.thumbs.redditmedia.com/Qt98gPG3q3TG2qgpX8fqxG7UC-PRJIYW60yiIfVAgvs.jpg,,,,,
3,MachineLearning,t5_2r3gv,2015-2-1,2015,2,1,21,2ueiw6,nuit-blanche.blogspot.com,The Hardest Challenges We Should be Unwilling to Postpone in Machine Learning and Data Science,https://www.reddit.com/r/MachineLearning/comments/2ueiw6/the_hardest_challenges_we_should_be_unwilling_to/,compsens,1422795055,,0,3,False,http://b.thumbs.redditmedia.com/l3dukoFzN6JLhFh-fbdOK1BJe7A7o7BqHsonNjTIKRo.jpg,,,,,
4,MachineLearning,t5_2r3gv,2015-2-2,2015,2,2,1,2uf1ss,self.MachineLearning,"How do unsupervised neural networks work, compared to other simpler unsupervised learning techniques?",https://www.reddit.com/r/MachineLearning/comments/2uf1ss/how_do_unsupervised_neural_networks_work_compared/,you_piece_of_shit__,1422808206,"I tend to think of unsupervised learning as factor analysis - most approaches can be interpreted as factor analysis with different constraints on the factors - and I'm wondering if neural nets are always like that or if there's something more going on. What are the aspects that distinguish it most from classical factor analysis? Is it the stacking of multiple layers? Maybe the fancy algorithmic regularization they do, like dropout? Other stuff? 

I guess the key question is the following: are the advances of deep learning basically stacking multiple alternating layers of factor analysis and sigmoidal nonlinearity, plus using algorithmic, cross-validation-like regularization techniques?

Example link: [Introduction to RBMs](http://blog.echen.me/2011/07/18/introduction-to-restricted-boltzmann-machines/)

My paraphrase: RBMs are basically doing factor analysis on high-dimensional binary feature data. (But why does it have to be binary? Other factor analysis methods work equally well for continuous regression, mixed categorical/numerical data, censored data, you name it. Does it have something to do with the desire to cascade layers?)

And are there different approaches to unsupervised neural nets that are just not factor analysis at all?
",11,1,False,self,,,,,
5,MachineLearning,t5_2r3gv,2015-2-2,2015,2,2,4,2uflth,computerworld.com,"Test shows big data text analysis inconsistent, inaccurate",https://www.reddit.com/r/MachineLearning/comments/2uflth/test_shows_big_data_text_analysis_inconsistent/,[deleted],1422818088,,2,0,False,default,,,,,
6,MachineLearning,t5_2r3gv,2015-2-2,2015,2,2,4,2ufoxj,self.MachineLearning,How can I encode continuous input from sensors to a neural network to produce discrete output?,https://www.reddit.com/r/MachineLearning/comments/2ufoxj/how_can_i_encode_continuous_input_from_sensors_to/,sanity,1422819554,"I'm interested in using a neural network to take continuous input from sensors (actually accelerometers attached to someone's hands), and produce english text (ie. what they're typing).

I guess it's a little like speech recognition, which also takes a continuous input and produces a discrete output.

I'd appreciate any pointers that might assist with this translation from continuous input to a discrete output.",5,0,False,self,,,,,
7,MachineLearning,t5_2r3gv,2015-2-2,2015,2,2,5,2ufrvt,self.MachineLearning,ELI5 what's a RBF kernel and how does it work?,https://www.reddit.com/r/MachineLearning/comments/2ufrvt/eli5_whats_a_rbf_kernel_and_how_does_it_work/,Offender_Ralphist,1422820986,"Hey everyone. I'm starting to learn machine learning and I'm having some conceptual issues at learning what an RBF kernel. Would anyone be able to give me an intuitive explanation and what these kernels are since I'm also beginning to learn linear algebra? Thanks!

EDIT: I would also love to have an intuitive explanation of the Gamma parameter for SVM's. What are they exactly and how they affect the results? I'm classifying a Parkinson's Disease dataset that consists of voice features(23 attributes) and changing the gamma value to 1 immediately increases my accuracy by 7%. Why does that happen?",12,7,False,self,,,,,
8,MachineLearning,t5_2r3gv,2015-2-2,2015,2,2,7,2ugbno,self,Learning to estimate phase for a family of functions,https://www.reddit.com/r/MachineLearning/comments/2ugbno/learning_to_estimate_phase_for_a_family_of/,justtheprint,1422830391,,2,1,False,default,,,,,
9,MachineLearning,t5_2r3gv,2015-2-2,2015,2,2,9,2uglzd,austinrochford.com,Prior Distributions for Bayesian Regression Using PyMC,https://www.reddit.com/r/MachineLearning/comments/2uglzd/prior_distributions_for_bayesian_regression_using/,rasbt,1422836173,,7,31,False,http://a.thumbs.redditmedia.com/LhtiJLyzRbL9etGFc58Bpm_ZyAudYG8AINsh5xafaI4.jpg,,,,,
10,MachineLearning,t5_2r3gv,2015-2-2,2015,2,2,11,2uh1tc,self.MachineLearning,My ML class was supposed to cover unsupervised learning today...,https://www.reddit.com/r/MachineLearning/comments/2uh1tc/my_ml_class_was_supposed_to_cover_unsupervised/,[deleted],1422845160,...and the professor didn't show up.  Is this a common joke in ML classes?,1,0,False,default,,,,,
11,MachineLearning,t5_2r3gv,2015-2-2,2015,2,2,13,2uhhbh,self.MachineLearning,"Difference between Binomial, Multinomial and Bernoulli Naive Bayes Classifiers?",https://www.reddit.com/r/MachineLearning/comments/2uhhbh/difference_between_binomial_multinomial_and/,mcdonalds_king,1422853102,"Hello r/MachineLearning,
I'm learning Naive bayes and I've come across this [site](http://blog.datumbox.com/machine-learning-tutorial-the-naive-bayes-text-classifier/) where it talks about different kinds of naive bayes algorithms used for different purposes(spam filtering, sentiment analysis). I've googled about these types but don't understand exactly how the three algorithms  are different from each other. Anyone please explain me if possible with an example. Thank you.",10,1,False,self,,,,,
12,MachineLearning,t5_2r3gv,2015-2-3,2015,2,3,3,2ujhb5,kaggle.com,Kaggle | March Machine Learning Mania 2015,https://www.reddit.com/r/MachineLearning/comments/2ujhb5/kaggle_march_machine_learning_mania_2015/,clbam8,1422901346,,0,2,False,http://b.thumbs.redditmedia.com/Nzf68AfLc2l5-zuuuVTkoiyFiZxlu9eskv0j-t_JK0c.jpg,,,,,
13,MachineLearning,t5_2r3gv,2015-2-3,2015,2,3,3,2ujiwm,self.MachineLearning,March Machine Learning Mania 2015,https://www.reddit.com/r/MachineLearning/comments/2ujiwm/march_machine_learning_mania_2015/,willis77,1422902020,"Kaggle &amp; HP are hosting our second annual NCAA March Mania prediction competition. All methods, flavors, credos, and styles of prediction are legal, guessing included. Here's how it works:

* You're given team-level data going back three decades, and are welcome to use whatever data you want
* We have a historical ""warm up"" stage so you can get used to the data format and have some motivation to work on the problem before March
* On Selection Sunday (when teams are announced), we wipe the leaderboard and collect 2015 predictions
* Entries are judged on the log loss of predicted probabilities for every possible matchup in the tournament.
* We update scores as the games unfold

Have fun!

https://www.kaggle.com/c/march-machine-learning-mania-2015",2,1,False,self,,,,,
14,MachineLearning,t5_2r3gv,2015-2-3,2015,2,3,3,2ujkvu,toptal.com,Music Recognition: The Shazam Algorithm,https://www.reddit.com/r/MachineLearning/comments/2ujkvu/music_recognition_the_shazam_algorithm/,clbam8,1422902865,,7,110,False,http://b.thumbs.redditmedia.com/QU2eQsP1-H_qQaTyXP4zHhyDWQAOx5KPAcUXsn5Swzo.jpg,,,,,
15,MachineLearning,t5_2r3gv,2015-2-3,2015,2,3,4,2ujsl3,vertica.com,HP Vertica Distributed R,https://www.reddit.com/r/MachineLearning/comments/2ujsl3/hp_vertica_distributed_r/,Thalassoma,1422906173,,0,3,False,http://b.thumbs.redditmedia.com/KpyVPIDJQBycdWwQWKJYsTxLr64JKmYg-T47vIIeAro.jpg,,,,,
16,MachineLearning,t5_2r3gv,2015-2-3,2015,2,3,6,2uk5jg,aioptify.com,Using Advanced Machine Learning Algorithms to Buy/Serve B2C and B2B Display Ads at Very Large Scale,https://www.reddit.com/r/MachineLearning/comments/2uk5jg/using_advanced_machine_learning_algorithms_to/,kjahan,1422911747,,2,0,False,default,,,,,
17,MachineLearning,t5_2r3gv,2015-2-3,2015,2,3,7,2ukc3b,self.MachineLearning,Beginners question - How much time do I need to learn Machine Learning,https://www.reddit.com/r/MachineLearning/comments/2ukc3b/beginners_question_how_much_time_do_i_need_to/,jedruch,1422914540,,28,0,False,default,,,,,
18,MachineLearning,t5_2r3gv,2015-2-3,2015,2,3,9,2ukt81,metacademy.org,Metacademy - your package manager for knowledge(amazing resource for learning ML),https://www.reddit.com/r/MachineLearning/comments/2ukt81/metacademy_your_package_manager_for/,raymestalez,1422922239,,1,12,False,http://b.thumbs.redditmedia.com/rKMi9PnLYzBrNtfjiWU_LYIAbVqLopsZkIbY3aD--ls.jpg,,,,,
19,MachineLearning,t5_2r3gv,2015-2-3,2015,2,3,9,2ukyp7,self.MachineLearning,"Implementing linear regression in python, had a question",https://www.reddit.com/r/MachineLearning/comments/2ukyp7/implementing_linear_regression_in_python_had_a/,[deleted],1422924783,"I am lookign at this post: http://stackoverflow.com/questions/17784587/gradient-descent-using-python-and-numpy

It seems to work for small number of input variables. However, if I try it with 1000 or so input variables, so that X = [ [1, 0], [1, 1] ... [1,1000] ] I get large amounts of overflow because it looks like         hypothesis = np.dot(x, theta) causes the hypothesis to just explode.

What am I doing wrong?

I tried going on my own code but I get similar errors.",3,1,False,default,,,,,
20,MachineLearning,t5_2r3gv,2015-2-3,2015,2,3,11,2ulaph,arxiv.org,[paper] Scaling Recurrent Neural Network Language Models,https://www.reddit.com/r/MachineLearning/comments/2ulaph/paper_scaling_recurrent_neural_network_language/,jesuslop,1422930499,,0,10,False,default,,,,,
21,MachineLearning,t5_2r3gv,2015-2-3,2015,2,3,12,2ulj26,medium.com,Google Brains Co-Inventor Tells Why Hes Building Chinese Neural Networks,https://www.reddit.com/r/MachineLearning/comments/2ulj26/google_brains_coinventor_tells_why_hes_building/,georgeo,1422934634,,7,14,False,http://b.thumbs.redditmedia.com/CHafWdJ5lOsfV5iMlPuk6w_Ea-x8QFLe0NU0AuC8lco.jpg,,,,,
22,MachineLearning,t5_2r3gv,2015-2-3,2015,2,3,13,2ulr1z,thoughtly.co,Prototype ML/NLP Code Tutorial Series Lesson 1: Working with Text,https://www.reddit.com/r/MachineLearning/comments/2ulr1z/prototype_mlnlp_code_tutorial_series_lesson_1/,[deleted],1422938863,,0,4,False,default,,,,,
23,MachineLearning,t5_2r3gv,2015-2-3,2015,2,3,14,2ulxy6,ganeshiyer.net,Can computers imagine?,https://www.reddit.com/r/MachineLearning/comments/2ulxy6/can_computers_imagine/,lastlegion,1422943046,,1,0,False,http://b.thumbs.redditmedia.com/6E0YXUncXhFZE-HgC8IH7COjePvS20nr4P30WrcpyiU.jpg,,,,,
24,MachineLearning,t5_2r3gv,2015-2-3,2015,2,3,15,2ulzo9,thoughtly.co,Prototype ML/NLP Code Tutorial Series Lesson 1: Working With Text,https://www.reddit.com/r/MachineLearning/comments/2ulzo9/prototype_mlnlp_code_tutorial_series_lesson_1/,[deleted],1422944177,,0,2,False,default,,,,,
25,MachineLearning,t5_2r3gv,2015-2-3,2015,2,3,20,2umm75,self.MachineLearning,Feedback on my intro to machine learning presentation?,https://www.reddit.com/r/MachineLearning/comments/2umm75/feedback_on_my_intro_to_machine_learning/,Prooffread3r,1422964277,"Hello, I've just finished making a slideshow and suite of IPython notebooks designed to introduce some grad students to machine learning, and I was wondering if anyone might have any feedback, see any errors, etc.

http://github.com/Prooffreader/intro_machine_learning/",7,8,False,self,,,,,
26,MachineLearning,t5_2r3gv,2015-2-4,2015,2,4,2,2unnew,thoughtly.co,Prototype ML/NLP Code Tutorial Series Lesson 1: Working With Text,https://www.reddit.com/r/MachineLearning/comments/2unnew/prototype_mlnlp_code_tutorial_series_lesson_1/,mercurialkitten,1422985262,,3,33,False,http://a.thumbs.redditmedia.com/XHqnQP9ClRThEB54sDy38vORYhQ7Rob8Yc0ViLSixc8.jpg,,,,,
27,MachineLearning,t5_2r3gv,2015-2-4,2015,2,4,3,2unvt8,blog.monkeylearn.com,Sentiment analysis with machine learning and web scraped data,https://www.reddit.com/r/MachineLearning/comments/2unvt8/sentiment_analysis_with_machine_learning_and_web/,wildcodegowrong,1422988947,,0,0,False,default,,,,,
28,MachineLearning,t5_2r3gv,2015-2-4,2015,2,4,5,2uo8fp,randalolson.com,Here's Waldo: Computing the optimal search strategy for finding Waldo,https://www.reddit.com/r/MachineLearning/comments/2uo8fp/heres_waldo_computing_the_optimal_search_strategy/,[deleted],1422994380,,2,2,False,default,,,,,
29,MachineLearning,t5_2r3gv,2015-2-4,2015,2,4,6,2uogqt,self.MachineLearning,What is coadaptation in the context of neural network?,https://www.reddit.com/r/MachineLearning/comments/2uogqt/what_is_coadaptation_in_the_context_of_neural/,MAS313,1422997946,What is coadaptation in the context of neural network? And Why is it undesirable? ,7,1,False,self,,,,,
30,MachineLearning,t5_2r3gv,2015-2-4,2015,2,4,6,2uoi7q,self.MachineLearning,Identifying a small group in a big data set?,https://www.reddit.com/r/MachineLearning/comments/2uoi7q/identifying_a_small_group_in_a_big_data_set/,[deleted],1422998567,"Hello,

I am having a lot of trouble figuring out how to approach the following problem.  Any advice or pointers would be really helpful!

I have about 20k data entries, each entry containing about 19 variables and an output variable (Say, True/False).

I want to create an algorithm to try to predict which cases tend to be True.  The issue is, only about 1% of the training dataset values are true, and each individual variable has some predictive power, but not a ton.

If it matters, it is preferable to have high sensitivity, and lower specificity can be tolerated.

I am a bit stumped about how to approach this problem.  I have run through a basic decision tree and a random forest in R, but I am not getting any useful output.  Since the decision is binary, I figured there may be a better way of approaching this problem.

Again, any advice is greatly appreciated!
",8,1,False,default,,,,,
31,MachineLearning,t5_2r3gv,2015-2-4,2015,2,4,17,2uql96,self.MachineLearning,Ideas for bachelor degree level computer science project on machine learning,https://www.reddit.com/r/MachineLearning/comments/2uql96/ideas_for_bachelor_degree_level_computer_science/,yolandasquatpump,1423039798,,11,11,False,default,,,,,
32,MachineLearning,t5_2r3gv,2015-2-4,2015,2,4,17,2uqle6,self.MachineLearning,Machine Learning as AI? (Examples similar to DeepMind's Atari work),https://www.reddit.com/r/MachineLearning/comments/2uqle6/machine_learning_as_ai_examples_similar_to/,alexgmcm,1423039931,,17,1,False,default,,,,,
33,MachineLearning,t5_2r3gv,2015-2-4,2015,2,4,19,2uqsr7,self.MachineLearning,What is the best way to preform sentiment analysis on data that has both qualitative and quantitative variables?,https://www.reddit.com/r/MachineLearning/comments/2uqsr7/what_is_the_best_way_to_preform_sentiment/,DomMk,1423047487,"example:

A questionnaire asks you to rate your mood from 1 to 10  (1 being happy and 10 being sad).

Then also asks you to write 5 words about your day. It could be a sentence, or just a string of nonsensical words.

How would you best analyze that type of data? Is sentiment analysis even necessary?",1,0,False,self,,,,,
34,MachineLearning,t5_2r3gv,2015-2-4,2015,2,4,22,2ur2pd,self.MachineLearning,some material on stream mining pls.,https://www.reddit.com/r/MachineLearning/comments/2ur2pd/some_material_on_stream_mining_pls/,tushar1408,1423056312,,0,0,False,self,,,,,
35,MachineLearning,t5_2r3gv,2015-2-4,2015,2,4,23,2ur5w4,self.MachineLearning,"[Question] When making a decision tree, how do you choose the best decision for each split point?",https://www.reddit.com/r/MachineLearning/comments/2ur5w4/question_when_making_a_decision_tree_how_do_you/,LMR_adrian,1423058589,"**I've been researching decision trees over the last couple days - and there is certainly a lot of information available, but the one detail I can't seem to find a lot of information on is how we decide upon the decisions to make at each split? (I'm sure the information is out there in full, I'm just not googling the right combinations to find it!)**

**For example**: I have three red ball and three blue balls at a decision point - the obvious decision to make here would be ""is the ball red?"" or ""is the ball blue"", either will divide the set perfectly into classes.

**However**: Let's say I have 100 balls with a bunch of vector components (where [34, 10, 2, 45] could be a ball's representation), the decision isn't so obvious: ""vector component 2 is greater than 42.0"" or ""components 1 and 3 added together total more than 6"".

*I realize the problem changes depending on the data, but I think there must be some underlying idea or pattern to use to get at least started? Can anyone help shed some light? I would really appreciate it!*",12,1,False,self,,,,,
36,MachineLearning,t5_2r3gv,2015-2-4,2015,2,4,23,2ur76s,self.MachineLearning,Mining Massive Datasets Question on SVD,https://www.reddit.com/r/MachineLearning/comments/2ur76s/mining_massive_datasets_question_on_svd/,Graaaaarrr,1423059401,"I've been looking through the course found [here](https://www.coursera.org/course/mmds) and am slightly confused in the Week 4 Lecture ""Finding the Latent Factors"".

The course goes in-depth into SVD but then says it can't be used as the matrix is not fully filled etc. So, it says to solve this problem the following optimisation problem must be solved [see here](http://i.imgur.com/sfmhzkO.png).

Now, what I don't understand is, if SVD isn't being done then where do the Matrices P and Q come from? We have the original matrix, call it M, but without doing SVD we don't have P or Q, thus we don't have any factors, thus how are we meant to do the optimisation problem?

I am clearly missing something that is quite obvious. Furthermore, if I only do the optimisation for the values I have, then what would the blanks be filled in with (I know what you're going to say, it's the estimated values) but I don't understand how. Because, how does the formula know to fill in a matrix value if a value never existed there in the first place?

I'm just a bit confused, any help would be super!",4,1,False,self,,,,,
37,MachineLearning,t5_2r3gv,2015-2-5,2015,2,5,0,2urio1,self.MachineLearning,Which are the world's top master programs for beginning a career in AI/Deep Learning (preferably private) research? - Please consider my situation described below,https://www.reddit.com/r/MachineLearning/comments/2urio1/which_are_the_worlds_top_master_programs_for/,eteimoso,1423065494,,20,0,False,default,,,,,
38,MachineLearning,t5_2r3gv,2015-2-5,2015,2,5,2,2urs13,self.MachineLearning,Ranking a document collection - What algorithm?,https://www.reddit.com/r/MachineLearning/comments/2urs13/ranking_a_document_collection_what_algorithm/,[deleted],1423069800,,5,0,False,default,,,,,
39,MachineLearning,t5_2r3gv,2015-2-5,2015,2,5,2,2urujb,aka.ms,"Free O'Reilly Report on ""Data Science in the Cloud""",https://www.reddit.com/r/MachineLearning/comments/2urujb/free_oreilly_report_on_data_science_in_the_cloud/,MLBlogTeam,1423070875,,0,1,False,http://b.thumbs.redditmedia.com/ftHpWQAnv3s0dZOYmKtT5se6GYnxC1PtnSwz-u2EnQg.jpg,,,,,
40,MachineLearning,t5_2r3gv,2015-2-5,2015,2,5,4,2usb8d,rednuht.org,HTML5 Genetic Algorithm Biped Walkers,https://www.reddit.com/r/MachineLearning/comments/2usb8d/html5_genetic_algorithm_biped_walkers/,rhiever,1423078501,,18,53,False,default,,,,,
41,MachineLearning,t5_2r3gv,2015-2-5,2015,2,5,4,2usbuo,self.MachineLearning,Best GA Book?,https://www.reddit.com/r/MachineLearning/comments/2usbuo/best_ga_book/,[deleted],1423078769,What's the best GA book for someone with a technical background but only introductory Machine Learning knowledge?,1,0,False,self,,,,,
42,MachineLearning,t5_2r3gv,2015-2-5,2015,2,5,6,2usv4o,self.MachineLearning,Help with analyzing multiple sequences of data for overall outcome prediction,https://www.reddit.com/r/MachineLearning/comments/2usv4o/help_with_analyzing_multiple_sequences_of_data/,petrichor1234,1423087113,"Hi, I am not sure how to analyze some data I have obtained. I think it might be a time series or regression problem, but not sure how to proceed. It also seems sort of similar to gene sequence problems.

I have 10 continuous variables, which in unison each give a sequence of 100 values (real numbers within a typical range). I also have some categorical variables that describe the setup. At the end of the sequences, there is a single outcome for the whole set, which is a single real number. I have about 20,000 sets (10 sequences of 100 + categorical variables + overall outcome).

Any suggestions on how I would do the following:

1) Predict the overall outcome, based on the 10 sequences and categorical variables. Would this be some sort of regression? Most importantly, what kinds of features do I extract from the 10 sequences for use in a regression model?

2) How do I include the categorical values describing the setup of each set, as well as the 10 numerical sequences?

3) Determine how much of the sequences do I need to see, before I can reliably predict the overall outcome? For example, ""after seeing the first 20% of the sequences, I can predict the outcome"". This would enable early response.

4) How do I determine what is the ""signature"" of sequences that result in high or low overall outcome? For example, high values in the first 10% of variable 1 combined with low values in last 10% of variable 2 results in very high outcome. This ties into my question about what features to extract from the 10 sequences.

Thanks very much for any suggestions on how to tackle this! I'm new to machine learning and appreciate the help!",3,0,False,self,,,,,
43,MachineLearning,t5_2r3gv,2015-2-5,2015,2,5,7,2usy83,medium.com,"The Story of Google's ""Brain""",https://www.reddit.com/r/MachineLearning/comments/2usy83/the_story_of_googles_brain/,Quantizedz,1423088472,,0,2,False,default,,,,,
44,MachineLearning,t5_2r3gv,2015-2-5,2015,2,5,7,2ut0j6,self.MachineLearning,The coming age of superhuman visual comprehension: Brief article about AI,https://www.reddit.com/r/MachineLearning/comments/2ut0j6/the_coming_age_of_superhuman_visual_comprehension/,apmTech,1423089497,,0,0,False,default,,,,,
45,MachineLearning,t5_2r3gv,2015-2-5,2015,2,5,8,2ut4sd,self.MachineLearning,Best way to quickly get a handle on big data?,https://www.reddit.com/r/MachineLearning/comments/2ut4sd/best_way_to_quickly_get_a_handle_on_big_data/,ohanlom4,1423091485,,2,1,False,default,,,,,
46,MachineLearning,t5_2r3gv,2015-2-5,2015,2,5,8,2ut51w,self.MachineLearning,Blocks vs Pylearn2 vs Groundhog for RNN,https://www.reddit.com/r/MachineLearning/comments/2ut51w/blocks_vs_pylearn2_vs_groundhog_for_rnn/,nharada,1423091610,"Does anyone have strong opinions or experience working with any of these frameworks for RNNs? I'd like to apply RNNs to my research (time series ECG), but I was looking for something higher level than pure Theano. Right now I'm leaning towards blocks: it seems to offer more flexibility than GroundHog and more support for RNN than PyLearn2. This could be an incorrect assumption though.

Has anyone here worked with or tried all three of these? All three are from LISA lab:

* https://github.com/lisa-groundhog/GroundHog
* https://github.com/bartvm/blocks
* https://github.com/lisa-lab/pylearn2",2,6,False,self,,,,,
47,MachineLearning,t5_2r3gv,2015-2-5,2015,2,5,9,2utdo1,backblaze.com,[x-post /r/sysadmin] Backblaze releases hard drive reliability dataset,https://www.reddit.com/r/MachineLearning/comments/2utdo1/xpost_rsysadmin_backblaze_releases_hard_drive/,zmjjmz,1423095820,,1,1,False,http://b.thumbs.redditmedia.com/80RxyBN8ti5ojs7M2RszL1lx-8fEYLCB7GXWhUmXMvc.jpg,,,,,
48,MachineLearning,t5_2r3gv,2015-2-5,2015,2,5,14,2uuc3e,self.MachineLearning,Looking for a corpus of contracts and other legal documents,https://www.reddit.com/r/MachineLearning/comments/2uuc3e/looking_for_a_corpus_of_contracts_and_other_legal/,DanRubins,1423113560,"Anyone have ideas of where I could source a corpus of contracts? I know the SEC has EDGAR, but those are very corporate-specific and US Federal contracts are available through FPDS. However, I'm looking for something that is a bit broader, and especially covers consumer and small business contracts.",1,3,False,self,,,,,
49,MachineLearning,t5_2r3gv,2015-2-5,2015,2,5,14,2uudo6,self.MachineLearning,Non-Iterative path finding,https://www.reddit.com/r/MachineLearning/comments/2uudo6/noniterative_path_finding/,faust_1706,1423114522,"I am wondering if there is a way to generate the shortest path from point a to b while avoiding obstacles without using going node by node. 

If one doesn't exist, what would happen in terms of autonomous navigation if it did?
",5,0,False,self,,,,,
50,MachineLearning,t5_2r3gv,2015-2-5,2015,2,5,15,2uugl3,github.com,A Neural Turing Machine implementation using Torch,https://www.reddit.com/r/MachineLearning/comments/2uugl3/a_neural_turing_machine_implementation_using_torch/,algebroic,1423116436,,30,54,False,http://a.thumbs.redditmedia.com/c7ZRGfTYVnvaZbvcbs24h3tUMjWdLxZlii2jL_DZ3F4.jpg,,,,,
51,MachineLearning,t5_2r3gv,2015-2-5,2015,2,5,18,2uuumm,self.MachineLearning,Which of the two MOOCs will be a better option? Illinois DM Specialization or Stanford's Massive Data Mining?,https://www.reddit.com/r/MachineLearning/comments/2uuumm/which_of_the_two_moocs_will_be_a_better_option/,gardinal,1423128318,"I want to make sure by the end of the course I would have enough artifacts to apply for intern positions in Data Science. I am currently in the r&amp;d department of a company for 6 months and my work is going to involve ml and stats. Right now brushing on stats using Duda Hart.

Option one : University of Illinois Data Mining Specialization.
https://www.coursera.org/specialization/datamining/20/faqs

Option two : Mining Massive Datasets by Stanford.
https://www.coursera.org/course/mmds

I have 6 months, and along with the current internship's experience and one of the above courses I want to be able to apply to data positions as an intern in companies in the states.

Getting good practical artifacts is one thing which would help.
What else could I do in this period of 6 months to make my CV strong enough for companies abroad?
Please help.

I am not willing to pay a total of 300$ unless the difference in the courses is really really worth it.",2,3,False,self,,,,,
52,MachineLearning,t5_2r3gv,2015-2-5,2015,2,5,22,2uvaoa,self.MachineLearning,Is there a way to modify words like 'rainy' back to 'rain' or 'faster' to 'fast'? NLTK stemmers are unable to do this.,https://www.reddit.com/r/MachineLearning/comments/2uvaoa/is_there_a_way_to_modify_words_like_rainy_back_to/,YesIAmTheMorpheus,1423143218,,1,0,False,default,,,,,
53,MachineLearning,t5_2r3gv,2015-2-6,2015,2,6,0,2uvksz,self.MachineLearning,Beginner question: how do I make a decision tree into a propensity score?,https://www.reddit.com/r/MachineLearning/comments/2uvksz/beginner_question_how_do_i_make_a_decision_tree/,[deleted],1423149221,,0,0,False,default,,,,,
54,MachineLearning,t5_2r3gv,2015-2-6,2015,2,6,0,2uvmi3,radar.oreilly.com,Network structure and dynamics in online social systems,https://www.reddit.com/r/MachineLearning/comments/2uvmi3/network_structure_and_dynamics_in_online_social/,gradientflow,1423150095,,0,6,False,http://b.thumbs.redditmedia.com/JikmiMOkEfOdIPCj3j5IO0OcNh2sAQXsm3XiOCJMzng.jpg,,,,,
55,MachineLearning,t5_2r3gv,2015-2-6,2015,2,6,3,2uwaef,self.MachineLearning,"Question about SVM solver algorithms, in matlab specifically",https://www.reddit.com/r/MachineLearning/comments/2uwaef/question_about_svm_solver_algorithms_in_matlab/,KevinG81,1423161309,"Hey Everyone.  So, this is my first foray into SVM and I've been studying Learning With Kernels while trying to implement SVM on some of my own data.   I have some questions about some of the Matlab functions used to fit the models and was hoping someone could provide some insight. 

I'm using fitcsvm for a two-class problem.  I'm using a polynomial kernel, am trying to optimize the parameters for BoxConstraint and KernelScale simultaneously, and am evaluating the generalizability of the model using leave one out cross validation.  (Note: in reality this is a biological problem and I want to see how well the firing rates of ensembles of neurons differentiate certain behavioral states, so my terminology might seem off as some of it reflects more so the question and perhaps less so the standard nomenclature used in the machine learning world).  

The default solver for matlab's fitcsvm() is SMO.  This seems to work fine, but there's also the option of using the L1Qp solver, which uses a quadratic programming algorithm to implement L1 soft-margin minimization.  When I use L1Qp with parallel enabled this uses about 12 of my cores (I'm using a 32 core machine) and takes about twice as long as the SMO algorithm; this is less than desirable because my optimization already takes a few hours with SMO.  Furthermore the minimum found with L1Qp isn't necessarily better than what's found with SMO, but I haven't been able to rigorously test this.  

So, my question is: what are the benefits of using L1Qp? 

A second question is: what is matlab doing to the Kernel via the KernelScale argument pair? In the documentation it says it divides the kernel by the kernel scale elementwise and then applies the 'appropriate kernel norm'.  It's this last part that I'm a little confused by -- are they normalizing each column/row vector to unit length?  fitcsvm doesn't return the kernel so I can't actually look at this myself.  

edit: Thanks everyone!",8,1,False,self,,,,,
56,MachineLearning,t5_2r3gv,2015-2-6,2015,2,6,3,2uwcuo,aka.ms,Learn how to publish your R code as a web service - all in a few clicks,https://www.reddit.com/r/MachineLearning/comments/2uwcuo/learn_how_to_publish_your_r_code_as_a_web_service/,MLBlogTeam,1423162439,,0,1,False,default,,,,,
57,MachineLearning,t5_2r3gv,2015-2-6,2015,2,6,7,2ux7fm,wiki.polyfra.me,WikiGalaxy: Explore Wikipedia in 3D,https://www.reddit.com/r/MachineLearning/comments/2ux7fm/wikigalaxy_explore_wikipedia_in_3d/,alexcasalboni,1423176657,,3,10,False,default,,,,,
58,MachineLearning,t5_2r3gv,2015-2-6,2015,2,6,7,2ux7mo,lxmls.it.pt,The 5th Lisbon Machine Learning School,https://www.reddit.com/r/MachineLearning/comments/2ux7mo/the_5th_lisbon_machine_learning_school/,matiskay,1423176751,,0,4,False,default,,,,,
59,MachineLearning,t5_2r3gv,2015-2-6,2015,2,6,8,2ux9ms,self.MachineLearning,[Question] Where is the DataScience WOW value in Google self-driving car,https://www.reddit.com/r/MachineLearning/comments/2ux9ms/question_where_is_the_datascience_wow_value_in/,def_Questions,1423177737,"I am sure that I can find brilliant answers here. 

I am wondering, if we could program obstacle avoiding algorithms for rc car, path finding, and we have a huge database of street information (Google street view, Google map, Google places , .. ), a mashup of all these solutions would give us Google self-driving car. 

Where is the data science wow factor in self driving car, I ve seen some papers trying to build so-called Google self drive car ( but the only difference was the dB) and the scale of the project. 


Can anyone highlight things I am missing in building such solution ? ",4,0,False,self,,,,,
60,MachineLearning,t5_2r3gv,2015-2-6,2015,2,6,8,2uxcdf,theparisreview.org,"""Turning novels plots into data points"" -- mentions a Vonnegut writing quote I hadn't heard before -- ""if you feel threatened by a machine, theres probably something suspect about your humanism. """,https://www.reddit.com/r/MachineLearning/comments/2uxcdf/turning_novels_plots_into_data_points_mentions_a/,[deleted],1423179059,,0,1,False,default,,,,,
61,MachineLearning,t5_2r3gv,2015-2-6,2015,2,6,9,2uxm6j,nautil.us,The Man Who Tried to Redeem the World with Logic,https://www.reddit.com/r/MachineLearning/comments/2uxm6j/the_man_who_tried_to_redeem_the_world_with_logic/,galapag0,1423183917,,13,65,False,http://b.thumbs.redditmedia.com/woQPibsUEu42gcSIXmlVx9DbRnWnlWOtOoTVmAQH1hM.jpg,,,,,
62,MachineLearning,t5_2r3gv,2015-2-6,2015,2,6,10,2uxq8f,datasciencecentral.com,"64 new external resources and articles about machine learning, data science - February 5",https://www.reddit.com/r/MachineLearning/comments/2uxq8f/64_new_external_resources_and_articles_about/,urinec,1423185963,,0,0,False,http://b.thumbs.redditmedia.com/MEQ88oaM1gpg6qtf0f2JUAnPjLIdlm0DrrYX6NN_m7s.jpg,,,,,
63,MachineLearning,t5_2r3gv,2015-2-6,2015,2,6,10,2uxr0g,self.MachineLearning,Is it possible to model the demand for parking space based upon parking ticket data?,https://www.reddit.com/r/MachineLearning/comments/2uxr0g/is_it_possible_to_model_the_demand_for_parking/,andrewfok007,1423186382,"As title, currently i have the times and counts for cars parked every minutes for the past few years. However this doesnt tell me if there is an actual demand for parking space. E.g. there could be no cars parked at a certain time because the car park might be full or there actually no demand. 
Is there a way to build a statistical model for the demand ? Would hidden markov be appropriate for this? 

Sorry if this is a basic question, my understand of ml theories is still very basic and happy if anyone can point in the right direction.",13,4,False,self,,,,,
64,MachineLearning,t5_2r3gv,2015-2-6,2015,2,6,15,2uylvg,ausloadshifting.blog.com,Forklift Training,https://www.reddit.com/r/MachineLearning/comments/2uylvg/forklift_training/,aus_andr,1423203940,,0,0,False,default,,,,,
65,MachineLearning,t5_2r3gv,2015-2-6,2015,2,6,15,2uyn9a,machine-training.blogspot.com.au,Machine Training,https://www.reddit.com/r/MachineLearning/comments/2uyn9a/machine_training/,aus_andr,1423205007,,0,0,False,default,,,,,
66,MachineLearning,t5_2r3gv,2015-2-6,2015,2,6,15,2uynqa,self.MachineLearning,Please explain support vector *regression* like i'm five.,https://www.reddit.com/r/MachineLearning/comments/2uynqa/please_explain_support_vector_regression_like_im/,joe056,1423205397,"Inspired by the epic top comment in [this thread](http://www.reddit.com/r/MachineLearning/comments/15zrpp/please_explain_support_vector_machines_svm_like_i).  Any chance anyone can explain Support Vector Regression in a non-technical fashion?  

I've been playing around with the implementations in R and Scikit-Learn at my job, and have gotten some interesting results.  I'd like to share the technique with others, but don't understand how the SVR works, really.

",9,15,False,self,,,,,
67,MachineLearning,t5_2r3gv,2015-2-6,2015,2,6,16,2uypx9,ausloadshifting.tumblr.com,Penrith Forklift Training,https://www.reddit.com/r/MachineLearning/comments/2uypx9/penrith_forklift_training/,aus_andr,1423207203,,0,0,False,default,,,,,
68,MachineLearning,t5_2r3gv,2015-2-6,2015,2,6,16,2uyrwq,ausload.wordpress.com,Truck licence,https://www.reddit.com/r/MachineLearning/comments/2uyrwq/truck_licence/,aus_andr,1423208998,,0,0,False,default,,,,,
69,MachineLearning,t5_2r3gv,2015-2-6,2015,2,6,17,2uysuq,ausload.weebly.com,Machine Training,https://www.reddit.com/r/MachineLearning/comments/2uysuq/machine_training/,aus_andr,1423209868,,0,1,False,default,,,,,
70,MachineLearning,t5_2r3gv,2015-2-6,2015,2,6,21,2uz9jg,self.MachineLearning,Combining two similar data sets,https://www.reddit.com/r/MachineLearning/comments/2uz9jg/combining_two_similar_data_sets/,soulslicer0,1423226507,"I am not very familiar with too much statistics or mathematics.

I would like to know, assuming I have two sensors, or maybe N sensors giving me two similar data sets. (Say position) What would be the mathematical way to correlate the datasets and improve the accuracy of it?

I am familiar with the least square solution but that's about it. Thing is, one sensors is better than the other. How shall I approach this?",2,1,False,self,,,,,
71,MachineLearning,t5_2r3gv,2015-2-6,2015,2,6,22,2uzb7r,self.MachineLearning,"RE.WORK Deep Learning Summit coming to Boston and London this year, videos soon available from San Francisco edition (featured Andrew Ng, Greg Corrado, Clarifai etc)",https://www.reddit.com/r/MachineLearning/comments/2uzb7r/rework_deep_learning_summit_coming_to_boston_and/,reworksophie,1423227948,"Just wanted to share with you all that the Deep Learning Summit is also coming up in Boston this May, and London this September. Check out all of our events here if you're interested: http://www.re-work.co/events
We're still looking for speakers, exhibitors, press etc - email hello@re-work.co for more information!
If you're interested in attending now's a good time to sign up as Super Early Bird passes are still available. We also have special discount tickets for Startups, Students and Academics.
Hope to see you there!
P.S. We should have some videos online soon from San Francisco, I'll share with you when we do!",7,5,False,self,,,,,
72,MachineLearning,t5_2r3gv,2015-2-6,2015,2,6,22,2uzd5x,self.MachineLearning,"RE.WORK Deep Learning Summit coming to Boston and London this year, videos soon available from San Francisco edition (featured Andrew Ng, Greg Corrado, Clarifai etc)",https://www.reddit.com/r/MachineLearning/comments/2uzd5x/rework_deep_learning_summit_coming_to_boston_and/,reworksophie,1423229521,,0,1,False,default,,,,,
73,MachineLearning,t5_2r3gv,2015-2-7,2015,2,7,0,2uznyb,self.MachineLearning,How to not waste-time/procrastinate while ml scripts are running?,https://www.reddit.com/r/MachineLearning/comments/2uznyb/how_to_not_wastetimeprocrastinate_while_ml/,polytop3,1423235930,"Hi All,

One of my biggest productivity saps is the time it takes ml scripts to run. Even for small data sets, sometimes scripts can take a few mins to run. In those few minutes I tend to browse the internet / watch youtube videos, and end up wasting 2x-5x more time than the script took to run.

Also, I program best when I can get into a state of flow: code / get immediate feedback; and scripts taking more than a minute disrupt this flow (as I will go do other things).

I was wondering what others in the community do while waiting for scripts to finish? What is your best way to remain productive? What I find works best for me is taking a walk and pondering the ml problem while the script is running (but more often than not, I browse the internet, sapping productivity).",31,28,False,self,,,,,
74,MachineLearning,t5_2r3gv,2015-2-7,2015,2,7,1,2uzwxu,self.MachineLearning,Can someone explain segmentation using HMMs?,https://www.reddit.com/r/MachineLearning/comments/2uzwxu/can_someone_explain_segmentation_using_hmms/,madhorse-overtime,1423240350,"I'm having trouble understanding how HMMs are used to segment for example speech audio or images. Assume I kinda know the definition of an HMM, but not that well. Here are my questions (although they may demonstrate my ignorance, sorry about that. I just want to put my confusion into words):

1. How do you train the HMM for segmentation purposes? What training data is needed?
2. Is topology important? What are some methods to determine how many hidden states (or whatever) to arrange in my model?
3. How do I actually segment my input data stream with my HMM?

A walkthrough of the processing pipeline would be great, too.",1,2,False,self,,,,,
75,MachineLearning,t5_2r3gv,2015-2-7,2015,2,7,2,2v03ni,arxiv.org,"LeCun: ""Text Understanding from Scratch""",https://www.reddit.com/r/MachineLearning/comments/2v03ni/lecun_text_understanding_from_scratch/,improbabble,1423243489,,58,94,False,default,,,,,
76,MachineLearning,t5_2r3gv,2015-2-7,2015,2,7,3,2v0flc,self.MachineLearning,Question about text classification algorithm,https://www.reddit.com/r/MachineLearning/comments/2v0flc/question_about_text_classification_algorithm/,learningmachines,1423249061,"I am trying to start building an algorithm for classifying texts. There will be multiple labels. From what I understand if one text can be assigned only one label, it's multiclass, and multi-label otherwise. I am wondering if multiclass is easier and faster to build, and if I can change it to multi-label later on. 
I just want to start building something to test if what I am doing makes sense at all, and works. Thanks a lot. ",1,0,False,self,,,,,
77,MachineLearning,t5_2r3gv,2015-2-7,2015,2,7,15,2v2ice,self.MachineLearning,What do you do at work?,https://www.reddit.com/r/MachineLearning/comments/2v2ice/what_do_you_do_at_work/,watersign,1423289477,I mean obviously..you're probably a data scientist or data analyst who uses machine learning..but what types of problems or tasks are you using ML on? ,44,17,False,self,,,,,
78,MachineLearning,t5_2r3gv,2015-2-7,2015,2,7,17,2v2rlf,thenewstack.io,How Facebook's Open AI Research Uses GPU Neural Networks,https://www.reddit.com/r/MachineLearning/comments/2v2rlf/how_facebooks_open_ai_research_uses_gpu_neural/,mttd,1423298047,,0,0,False,http://a.thumbs.redditmedia.com/hoFrNXa2grO-PHtwBncbLvlCoc9SsaJylclumWCIpV8.jpg,,,,,
79,MachineLearning,t5_2r3gv,2015-2-7,2015,2,7,21,2v34ca,self.MachineLearning,How can I use machine learning for this simple task?,https://www.reddit.com/r/MachineLearning/comments/2v34ca/how_can_i_use_machine_learning_for_this_simple/,dsocma,1423313144,"Lets say I take 10 nutritional supplments per day (numbered 1-10, each in 4 different doses (No dose, small dose, regular dose, high dose).  And each day I take each each dose by rolling a 4 sided die, so the dose each day is random.

Then I write a short list of words as a summary along with of how I felt for that day ""focused(3), tired(5), anxious(0), calm(3), ect. ect.""

For example if we were talking about ""focused"", you want to find (1. the contribution of each supplment 1-10 to ""focus"" at each dose and (2. what supplements antagonize each other when combined, vs which ones synergize when combined. and finally (3. you want to find the best possible combination of supplments to acheive focus.

What technique would be best, or what would you use?  Also, the most important thing is that you get high accuracy with the smallest number of samples.",14,3,False,self,,,,,
80,MachineLearning,t5_2r3gv,2015-2-8,2015,2,8,0,2v3gaz,self.MachineLearning,Training a neural net; an intuition for weight variation,https://www.reddit.com/r/MachineLearning/comments/2v3gaz/training_a_neural_net_an_intuition_for_weight/,osazuwa,1423322545,"I am working with some feedforward neural network models.  Repeatedly training a network (using backprobagation) on the same data, I get a different set of weights.  The loss function output (MSE) and predictive performance of each network are very similar.  The different models clearly represent different but comparably performant local minima.  

Yet, I am struck how local minima with similar performance and loss can have such dramatically different weights.  My intuition tells me this phenomenon would increase with the size (# nodes/weights) of the model.  Can anyone help me expand on this?  Under what circumstances would the weight fit to an edge in a network have more or less variability between local minima?",9,3,False,self,,,,,
81,MachineLearning,t5_2r3gv,2015-2-8,2015,2,8,2,2v3w99,self.MachineLearning,How to find computer vision / image processing PhD topic ideas?,https://www.reddit.com/r/MachineLearning/comments/2v3w99/how_to_find_computer_vision_image_processing_phd/,sutr90,1423331315,"I have MSc. in computer science with major focus on computer vision and image processing. In my Master Thesis I did some work with Deep Nets and images. Now I have started in PhD program. So far I had some TA stuff, but not much research going on. Lately I have realized I have no idea what should I research to earn my PhD. There come you in the equation. Can you please advise me where can I find some ideas what to do? Or even better do you have some idea what should I research.

Can you suggest something?",18,0,False,self,,,,,
82,MachineLearning,t5_2r3gv,2015-2-8,2015,2,8,3,2v3yiq,cs.stanford.edu,Andrej Karpathy's slides on Generating Image Description using Deep Learning,https://www.reddit.com/r/MachineLearning/comments/2v3yiq/andrej_karpathys_slides_on_generating_image/,imanishshah,1423332453,,2,26,False,default,,,,,
83,MachineLearning,t5_2r3gv,2015-2-8,2015,2,8,5,2v4crg,self.MachineLearning,Need help finding a talk: The Unreasonable Effectiveness of Deep Learning by Yann LeCun,https://www.reddit.com/r/MachineLearning/comments/2v4crg/need_help_finding_a_talk_the_unreasonable/,strayadvice,1423339412,"I was watching this talk by Yann LeCun from late last year: http://www.clsp.jhu.edu/seminars/1503/

He stops before speaking about Unsupervised Learning. I was wondering if there's a version of this talk where he even discusses Unsupervised Learning.",2,10,False,self,,,,,
84,MachineLearning,t5_2r3gv,2015-2-8,2015,2,8,6,2v4jb3,self.MachineLearning,When (?) will there be specialized neural nets easily available for insertion in code?,https://www.reddit.com/r/MachineLearning/comments/2v4jb3/when_will_there_be_specialized_neural_nets_easily/,asdfjakarta,1423342876,"Just making up a silly example at first:


camera feed in a mall -&gt; neural net for estimating gender and age of each customer -&gt; database/""regular"" programming


Where the neural net in question is trained and tweaked by a provider of neural nets for different tasks, and devs that need such functionality just buys/gets it.


Do anyone else see this happening in the future?",3,0,False,self,,,,,
85,MachineLearning,t5_2r3gv,2015-2-8,2015,2,8,6,2v4jrm,arxiv.org,Explaining and Harnessing Adversarial Examples,https://www.reddit.com/r/MachineLearning/comments/2v4jrm/explaining_and_harnessing_adversarial_examples/,[deleted],1423343121,,1,0,False,default,,,,,
86,MachineLearning,t5_2r3gv,2015-2-8,2015,2,8,8,2v52l0,self.MachineLearning,What do you use to create graphics for neural-nets related papers/presentations?,https://www.reddit.com/r/MachineLearning/comments/2v52l0/what_do_you_use_to_create_graphics_for_neuralnets/,shonaland,1423352886,"As the title says. 

Also, are there tools that let you add interactive elements? If you've seen the talk [""Media for Thinking the Unthinkable""](http://vimeo.com/67076984), I'm referring to the sort of interactive elements he discusses.

I'm just looking to get a feel for what the community uses for presentations and papers.",2,0,False,self,,,,,
87,MachineLearning,t5_2r3gv,2015-2-8,2015,2,8,9,2v571m,arxiv.org,[Discuss] A New Framework to Probe and Learn Neural Networks,https://www.reddit.com/r/MachineLearning/comments/2v571m/discuss_a_new_framework_to_probe_and_learn_neural/,rantana,1423355331,,4,10,False,default,,,,,
88,MachineLearning,t5_2r3gv,2015-2-8,2015,2,8,11,2v5k2m,self.MachineLearning,"Are there any cool ""learning"" programs that I could download and run on my computer just to watch develop?",https://www.reddit.com/r/MachineLearning/comments/2v5k2m/are_there_any_cool_learning_programs_that_i_could/,bioemerl,1423362652,"Self explanatory, I really love the concept.  Also would be amazing if it's an open source project.",4,12,False,self,,,,,
89,MachineLearning,t5_2r3gv,2015-2-8,2015,2,8,14,2v60xt,self.MachineLearning,Sparse matrices and encoding categorical variables.,https://www.reddit.com/r/MachineLearning/comments/2v60xt/sparse_matrices_and_encoding_categorical_variables/,[deleted],1423372955,"I think I'm finally understanding the point of this but would just like someone to confirm if I'm on the right track..

I have a matrix full of continuous data that I want to add some categorical variables to and run through an SVM.

Let's say Variable A has 3 levels.. so to encode this, I could just create a vector of n=3 (1,0,0),(0,1,0),(0,0,1). 

Now if I have another variable B with the same number of levels, I can't just create another vector, because it would be in the same vector space as variable A, right? The SVM would see that and say 'hey, these two guys are vectors in the same dimension so they might be related in some way'..

So this is why we create a sparse matrix..? A single matrix represents the entire set of categorical variables, while keeping them in separate dimensions?

Assuming this is true (and if it's not, I guess ignore these questions..)

1 = given a sparse matrix mxn, columns n would represent the indivual variables, and m the levels of those variables?

2 = if the factor variables have different levels, do we just extend the mxn matrix so that m = the largest amount of levels in all factors, and any factors that don't have those levels are just get set to 0 for those rows/levels.

Am I getting close here?",7,0,False,default,,,,,
90,MachineLearning,t5_2r3gv,2015-2-8,2015,2,8,20,2v6p83,self.MachineLearning,Recommended server hosters for GPU clusters?,https://www.reddit.com/r/MachineLearning/comments/2v6p83/recommended_server_hosters_for_gpu_clusters/,gogglygogol,1423396624,"Hi, 

I was wondering what kind of server hosters people here use for building GPU clusters.  Or is building your own still the way to go for now?

Thanks!",3,5,False,self,,,,,
91,MachineLearning,t5_2r3gv,2015-2-8,2015,2,8,22,2v6vsg,self.MachineLearning,"If you could only use one programming language to do your job, what would it be and why?",https://www.reddit.com/r/MachineLearning/comments/2v6vsg/if_you_could_only_use_one_programming_language_to/,LMR_adrian,1423403395,"**I get asked this question a surprising amount - almost as though the new community is looking for the ""magic"" language that does all things perfectly right out of the gate.  Now although there is no one perfect language, there are a lot of awesome ones that can get pretty much any job done.**

So /r/machinelearning if you had to be restricted to one programming language to do your job what would it be and why?

*(my answer is in the comments)*",51,24,False,self,,,,,
92,MachineLearning,t5_2r3gv,2015-2-8,2015,2,8,23,2v6wuu,nuit-blanche.blogspot.com,Subspace Clustering: Of Fluid Autoencoders and Data Tsunamis,https://www.reddit.com/r/MachineLearning/comments/2v6wuu/subspace_clustering_of_fluid_autoencoders_and/,compsens,1423404284,,0,1,False,http://b.thumbs.redditmedia.com/PAfSIgPz0v325jEbe5zKvGEB92b1PwcCb9UcklBudqo.jpg,,,,,
93,MachineLearning,t5_2r3gv,2015-2-8,2015,2,8,23,2v6ywl,self.MachineLearning,ImageNet convnets are NOT so easily fooled :),https://www.reddit.com/r/MachineLearning/comments/2v6ywl/imagenet_convnets_are_not_so_easily_fooled/,[deleted],1423405878,"http://i.imgur.com/pgxj3Pk.jpg

&lt;--- check the difference. But more importantly, while modified images fool all three ImageNet convnets (Berkeley CaffeNet 2012, Oxford CNN-S 2013, Oxford VeryDeep-19 2014), modifying image to fool one was not enough to change opinion about image of the other two convnets. And modifying modified image again, so it would fool two out of three convnets was still not enough to persuade third one to misclassify image.  

* I used the very first three images I could find that were correctly classified by all three networks(daisy, jay, agaric). 

* Second step I generated adversarial image that was classified as ostrich by Oxford VeryDeep-19. VeryDeep-19 was chosen as most advanced/newest net.

* Check if classification of the other two nets have changed. No, in all three cases the other two nets were correctly classifying images as being daisy, jay and agaric.

* Create adversarial image of adversarial one generated on previous step but now using Oxford CNN-S 2013(second most advanced net), again adjusting image so CNN would classify it as being ostrich.

* Check if classification of the last nets have changed. No, in all three cases CaffeNet was still able to correctly classify images as being daisy, jay and agaric.
 
* Create adversarial image of adversarial one generated on previous step but now using CaffeNet, again so it would see ostrich in it. And this is the pictures that you see in the right column.

This is first 3 random images I tried. The demo is slow plus CAPTCHA protected. And sometimes convnets were not able to agree among themselves about image, nvm misclassification error rate for top1 result.

Possible explanation, original work (""intriguing properties"") was done on much simpler dataset(CIFAR), but large convnets on ImageNet were forced to come up with more feature that distinguish between 1000 classes. And being big they probably come up with different features. At least it looks like being the case for ostrich classifier. Would be nice to check more nets that trained on even more than 1k classes, lets say 10k. Each net might be even more resilient to examples that persuade other nets. Interesting fact that in two cases out of three final image was not classified as being ostrich by VeryDeep-19, that classification was broken on the last step and VeryDeep-19 classified two images nether as an ostrich nor as correct class. 
 
Link to the demo: http://deeplearning.twbbs.org/

EDIT: changed hosting to imgur",4,3,False,default,,,,,
94,MachineLearning,t5_2r3gv,2015-2-9,2015,2,9,1,2v796w,self.MachineLearning,Looking for a reference Prism implementation.,https://www.reddit.com/r/MachineLearning/comments/2v796w/looking_for_a_reference_prism_implementation/,Fireblend,1423412577,"Hello!

I'm currently interested in implementing a Random Prism algorithm for an existing ML framework. I've read the papers where both the Random Prism and the base Prism algorithms are described:

 - Prism - http://sci2s.ugr.es/keel/pdf/algorithm/articulo/1987-Cendrowska-IJMMS.pdf
 - Random Prism - http://eprints.bournemouth.ac.uk/20513/3/submittedManuscript.pdf

Where they're both defined in general terms, however I was hoping to find an example implementation somewhere I could use as a reference while making my own. Does anyone here know of one I could use?

Thanks in advance.",2,5,False,self,,,,,
95,MachineLearning,t5_2r3gv,2015-2-9,2015,2,9,3,2v7n77,xcorr.net,Machine learning in online dating,https://www.reddit.com/r/MachineLearning/comments/2v7n77/machine_learning_in_online_dating/,arodesc,1423419882,,7,26,False,http://b.thumbs.redditmedia.com/m_dS8LkuMHXFeCmm_lhTaDRvpcN0g8PsIWFBziCsSbQ.jpg,,,,,
96,MachineLearning,t5_2r3gv,2015-2-9,2015,2,9,7,2v8gh0,nbviewer.ipython.org,Tips and Tricks for Encoding Categorical Features in Classification Tasks (IPython nb),https://www.reddit.com/r/MachineLearning/comments/2v8gh0/tips_and_tricks_for_encoding_categorical_features/,rasbt,1423433982,,4,15,False,default,,,,,
97,MachineLearning,t5_2r3gv,2015-2-9,2015,2,9,7,2v8jwd,self.MachineLearning,MS (Statistics) or Master's in CS or nil?,https://www.reddit.com/r/MachineLearning/comments/2v8jwd/ms_statistics_or_masters_in_cs_or_nil/,drkenta,1423435688,"Hey guys,
&amp;nbsp;

I'm at a fork in the road and I need your help in deciding between two degrees.
&amp;nbsp;

Background:
&gt;I have an unrelated science bachelors and have been working in this unrelated field since graduation (2010).

&gt;Fortunately, I have a very supportive partner so I need only work part-time and the rest of my spare time I can spend studying (until I can get off the ground).

&amp;nbsp;
~~--------------------------------------------------------------~~
&amp;nbsp;

I have a strong interest in AI and have some minor background in casual programming since I was young. 

I've decided on a career change at this point in my life and want to be involved in AI/ML. 

To further myself I have already completed multivariable calculus and linear algebra courses online (MIT OCW), and have just begun a whole load of MOOCs in Probability/stats, Compsci, AI, etc - So far I am finding them fun and challenging.

On top of self-study/projects, I want to complete an official university degree, mostly for employability reasons, but also to advance into research if I choose to do so in the future.
&amp;nbsp;

~~--------------------------------------------------------------~~
&amp;nbsp;

After extensive research and looking at all possible options I have come down to two options (given my location, flexibility, etc). 
&amp;nbsp;

1. 2 year Master of Science in Mathematics/Statistics with a 1 semester research component
2. 2 year Master of Computer Science also with a 1 semester research component
3. Self-study only
&amp;nbsp;

Unfortunately, in my country, there aren't many AI/ML specific degrees and none that are accessible to me.
&amp;nbsp;

~~--------------------------------------------------------------~~
&amp;nbsp;

After searching in this subreddit, I've gotten the feeling that a Statistics degree would be much more useful than a CS degree in the ML field. I just wanted to confirm this suspicion through this thread.
&amp;nbsp;

If you guys can give me any other advice, it'd be very welcome and appreciated.
&amp;nbsp;

Thanks.
&amp;nbsp;

edit: formatting",20,0,False,self,,,,,
98,MachineLearning,t5_2r3gv,2015-2-9,2015,2,9,12,2v9hae,self.MachineLearning,"What do you do, and how did you get there?",https://www.reddit.com/r/MachineLearning/comments/2v9hae/what_do_you_do_and_how_did_you_get_there/,[deleted],1423452945,"Been wondering about skill levels of people on this sub, and how people get into machine learning and what it takes to get a machine learning job, or what it takes to get into a machine learning school. ",3,2,False,default,,,,,
99,MachineLearning,t5_2r3gv,2015-2-9,2015,2,9,13,2v9ofm,nikhilbuduma.com,Genetics as a Social Network - A Data Scientist's Perspective,https://www.reddit.com/r/MachineLearning/comments/2v9ofm/genetics_as_a_social_network_a_data_scientists/,gwulfs,1423456989,,3,3,False,http://b.thumbs.redditmedia.com/zB4kV9V1Baefg5vOaMh_ARYG1qR4S6MsptXHYzlL1Fc.jpg,,,,,
100,MachineLearning,t5_2r3gv,2015-2-9,2015,2,9,14,2v9rjj,engineeringblog.yelp.com,Yelp Dataset Challenge is Doubling Up,https://www.reddit.com/r/MachineLearning/comments/2v9rjj/yelp_dataset_challenge_is_doubling_up/,soupsranjan,1423458823,,0,17,False,http://b.thumbs.redditmedia.com/Jc3ScWGCJb_6W4_WmxSO-eN_dwFAtKdxW6JyYQumxbg.jpg,,,,,
101,MachineLearning,t5_2r3gv,2015-2-9,2015,2,9,17,2va5p7,self.MachineLearning,Hinton and Learning Rates in Deep Networks,https://www.reddit.com/r/MachineLearning/comments/2va5p7/hinton_and_learning_rates_in_deep_networks/,mfagerlund,1423469371,"I'm considering how to scale learning rate with regards to batches and the number of training sets.

My reading of Hinton suggests that learning should be scaled by number of items in the total trainingset, which seems odd to me. At least to do it in a linear fashion.

What Hinton suggests is that we divide learning rate with number of batches **and** by the number of items in the batch. This number always comes out the same, no matter what size the batches are?

Hinton (in A Practical Guide to Training
Restricted Boltzmann Machines https://www.google.se/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;ved=0CCcQFjAA&amp;url=https%3A%2F%2Fwww.cs.toronto.edu%2F~hinton%2Fabsps%2FguideTR.pdf&amp;ei=lGXYVN-KDMTcatTtgagJ&amp;usg=AFQjCNEgnNMhuCJpMLeg16W18j3_YLicDA) writes:

&gt;To avoid having to change the learning rate when the size of a mini-batch is changed, it is helpful
to divide the total gradient computed on a mini-batch by the size of the mini-batch, 

he then writes

&gt; so when talking
about learning rates we will assume that they multiply the average, per-case gradient computed on
a mini-batch, not the total gradient for the mini-batch.

Please correct me if I'm wrong, but using the average per-case gradient is the same as dividing the learning rate with the number of items in the batch (except in the case of the very last batch that might be slower because there weren't cases enough to fill it).

So:

    ActualLearningRate=SpecifiedLearningRate/(NumberOfBatches * BatchSize)
    NumberOfBatches=TotalTrainingItems/BatchSize

which gives us

    ActualLearningRate=SpecifiedLearningRate/((TotalTrainingItems/BatchSize) *  BatchSize)
    ActualLearningRate=SpecifiedLearningRate/TotalTrainingItems

I realize that more data means that we can trust each datum less, but it is inversely linear?

Any thoughts

cheers,
m

",3,3,False,self,,,,,
102,MachineLearning,t5_2r3gv,2015-2-9,2015,2,9,17,2va6mc,self.MachineLearning,Tuition Compensation for Data Science Positions? (x-post from /r/DataScience),https://www.reddit.com/r/MachineLearning/comments/2va6mc/tuition_compensation_for_data_science_positions/,[deleted],1423470302,"Hello all!

Currently, I am an ECE Master's student in the US, with a thesis emphasis in ML and Stats, and I am hoping to get into the ML/data science world upon graduation. However, it seems like it can be super helpful to have a ML/Stats PhD in this career track. Does anyone have experience with being offered (or explicitly not being offered) tuition compensation for advanced degree programs as an industry data scientist? All of the companies that I have been in contact with over the years for more ""engineer-y"" internships have offered tuition reimbursement programs for their full-time engineers. It seems to me like it is very much an industry standard to offer some sort of this type of program. I am wondering if it is even somewhat the same in the data science field.

So does anyone have any experience with getting/not getting education benefits as a ML Researcher/Data Scientist? If it is not, would anyone here recommend spending the extra 4-5 years getting a ML/data science-related PhD before entering the workforce? It seems like deferring actual work experience this much longer could not help, but I'm not sure, given that the career track might end early in this field for non-PhD's.",0,0,False,default,,,,,
103,MachineLearning,t5_2r3gv,2015-2-9,2015,2,9,17,2va6nv,self.MachineLearning,role of hypothetical statements in sentiment analysis,https://www.reddit.com/r/MachineLearning/comments/2va6nv/role_of_hypothetical_statements_in_sentiment/,new2machinelearning,1423470345,"Hi folks .. i am trying to use a hybrid model of semantic orientation (of various features in the document) and SVM. After sampling the SO output i noticed that hypothetical statements , for instance 

""if , like last year, the prices of wheat do rise..."" 

are confusing the algo (which considers the verb ""rise"" with the key phrase ""wheat"" and assigns the statement a positive SO) Does it make sense to just get rid of such statements ? for a start i am trying to get rid of sentences that contain "" if "" but then again i might be losing out on valid hypothesis ..any pointers will be greatly appreciated.

i tried googling for help but turned up with junk.

Regards,
vikram",0,1,False,self,,,,,
104,MachineLearning,t5_2r3gv,2015-2-9,2015,2,9,21,2vak7v,google.co.in,Understanding Big Data: John Doe Meets Big Numbers,https://www.reddit.com/r/MachineLearning/comments/2vak7v/understanding_big_data_john_doe_meets_big_numbers/,[deleted],1423484047,,0,0,False,default,,,,,
105,MachineLearning,t5_2r3gv,2015-2-9,2015,2,9,22,2varxx,self.MachineLearning,Just started the Andrew Ng course on Coursera,https://www.reddit.com/r/MachineLearning/comments/2varxx/just_started_the_andrew_ng_course_on_coursera/,rhianos,1423490071,"And as it turns out, the course is very interesting and enjoyable!",0,0,False,self,,,,,
106,MachineLearning,t5_2r3gv,2015-2-9,2015,2,9,23,2vat7p,self.MachineLearning,Any good project ideas related to applications of ML to biology?,https://www.reddit.com/r/MachineLearning/comments/2vat7p/any_good_project_ideas_related_to_applications_of/,YesIAmTheMorpheus,1423490919,With data available hopefully. We want to work on soemthing for our course project on Computational systems biology.,4,4,False,self,,,,,
107,MachineLearning,t5_2r3gv,2015-2-9,2015,2,9,23,2vawhv,self.MachineLearning,Algorithm to recover the original word from an abbreviation?,https://www.reddit.com/r/MachineLearning/comments/2vawhv/algorithm_to_recover_the_original_word_from_an/,awesterdam,1423492930,"I am in need of an algorithm for the task of reversing the process of abbreviation.

For example,

* Input: Apl Jce
* Output: Apple Juice

or

* Input: Tlt Rll
* Output: Toilet Rolls

The range of possible output is well-defined, and known. However, I do not know what the form of input is.

Before I get down and dirty and start writing my own algorithm, I just want to know if anyone knows of any algorithms/libraries for this task? Research papers would be great too.",3,0,False,self,,,,,
108,MachineLearning,t5_2r3gv,2015-2-10,2015,2,10,0,2vaytg,self.MachineLearning,Pattern Discovery in Elastic Search?,https://www.reddit.com/r/MachineLearning/comments/2vaytg/pattern_discovery_in_elastic_search/,bernardosgr,1423494249,"Hi guys, pretty straightforward question:

Does anyone know of a tool/suite/project fo conducting automatic pattern discovery on elasticsearch stored data? I'm looking for something that can do this and possibly enhance analysis with interactive user feedback.",6,8,False,self,,,,,
109,MachineLearning,t5_2r3gv,2015-2-10,2015,2,10,1,2vb7ot,self.MachineLearning,ML challenges with autonomous vehicles,https://www.reddit.com/r/MachineLearning/comments/2vb7ot/ml_challenges_with_autonomous_vehicles/,[deleted],1423498684,"My knowledge of autonomous vehicles comes entirely from Professor Thrun's AI class, so I'm curious about the challenges with dealing with incomplete data due to inclement weather. My understanding is that these cars rely on Lidar which is not as reliable during heavy precipitation.

What kind of research has there been on working with incomplete/missing/error-prone sensor data? ",0,0,False,default,,,,,
110,MachineLearning,t5_2r3gv,2015-2-10,2015,2,10,1,2vb9bb,arxiv-web3.library.cornell.edu,Surpassing Human-Level Performance on ImageNet Classification,https://www.reddit.com/r/MachineLearning/comments/2vb9bb/surpassing_humanlevel_performance_on_imagenet/,downtownslim,1423499475,,24,54,False,default,,,,,
111,MachineLearning,t5_2r3gv,2015-2-10,2015,2,10,2,2vbgeq,fastml.com,FastML: Torch vs Theano,https://www.reddit.com/r/MachineLearning/comments/2vbgeq/fastml_torch_vs_theano/,[deleted],1423502777,,10,7,False,default,,,,,
112,MachineLearning,t5_2r3gv,2015-2-10,2015,2,10,3,2vbol5,self.MachineLearning,Calculus of variations for machine learning?,https://www.reddit.com/r/MachineLearning/comments/2vbol5/calculus_of_variations_for_machine_learning/,RaulPL,1423506538,"Hi, I'm looking for an introductory text to calculus of variations with machine learning applications, does anyone know a good resource (tutorial/paper/webpage) of where to start with? Thanks.",3,1,False,self,,,,,
113,MachineLearning,t5_2r3gv,2015-2-10,2015,2,10,5,2vc1h9,self.MachineLearning,Neural Network input question.,https://www.reddit.com/r/MachineLearning/comments/2vc1h9/neural_network_input_question/,PhysicsNovice,1423512222,I have several objects with unknown properties. For each input I want to specify which object is being used to create that input. I have 20 objects. How should I specify them in the input vector? i.e. 1-20 integers or binary like 0 1 1 or 1 0 0 ect.,6,0,False,self,,,,,
114,MachineLearning,t5_2r3gv,2015-2-10,2015,2,10,6,2vca9z,self.MachineLearning,Model selection and training/validation/test sets vs cross-validation.,https://www.reddit.com/r/MachineLearning/comments/2vca9z/model_selection_and_trainingvalidationtest_sets/,mx12,1423515987,"I recently watched Andrew Ng's lecture on Coursera on model selection. In his lecture he suggested that using a training/validation/test was better than just using cross-validation to determine which model to use. I can definitely see how using CV can lead to an overly optimistic error estimation. I was wondering if in practice the two are combined.

For instance, why not perform k-fold cross-validation on the training/validation set. Then once the model is selected, use the test set to estimate the final error. This also leads to the possibility of instead repeating the entire training/validation/test process multiple times. My only concern with using the training/validation/set once, is that there is a chance the samples chosen are bad. Therefore running it multiple times, a better estimate of the error can be found. This does mean that the model selected is different every time.

Thanks!",6,0,False,self,,,,,
115,MachineLearning,t5_2r3gv,2015-2-10,2015,2,10,7,2vcmk6,self.MachineLearning,Looking for a special NN for prediction,https://www.reddit.com/r/MachineLearning/comments/2vcmk6/looking_for_a_special_nn_for_prediction/,[deleted],1423521235," Well, i run and jump on my skate board and cost. I am look for the distance 
costed. 
 I run one meter and jump onto the board and cost three meters. 
 I run two meters and jump onto the board and and cost seven meters. 
 I run three meters and jump onto the board and and cost 12 meters. 

 I train the NN with this data. Is there a NN that can predict outside
the given training range, that i will cost. For example: 

 If I run 5 meters and jump onto the skate board. Is there a NN that will give me 
a close answer, on the distance i will cost? 

Much appreciate any help, 

k_ ",2,0,False,default,,,,,
116,MachineLearning,t5_2r3gv,2015-2-10,2015,2,10,8,2vcvtw,self.MachineLearning,Comparing multiple SVMs for multi-class prediction,https://www.reddit.com/r/MachineLearning/comments/2vcvtw/comparing_multiple_svms_for_multiclass_prediction/,KevinG81,1423525440,"Hey everyone.  I have  question regarding comparing different SVM models for the purpose of multi-class prediction.  I understand that approaches to this kind of problem are generally to use multiple one-vs-all or one-vs-one models, then to compare the scores between the set of models and pick the one with the highest score. 

My question is whether this assumes that identical model parameters are selected for each, e.g., the same polynomial kernel order is chosen, that the kernel scale is the same, and so on.  For example, if you had four one-vs all models, and one was fit using a 4th order polynomial kernel, and the rest 1st order, is it a fair comparison to compare the SVM scores between these models.  ",2,1,False,self,,,,,
117,MachineLearning,t5_2r3gv,2015-2-10,2015,2,10,9,2vd2hh,fsharpshow.com,A Machine Learning Journey in F# with Richard Minerich on The F# Show podcast,https://www.reddit.com/r/MachineLearning/comments/2vd2hh/a_machine_learning_journey_in_f_with_richard/,CatReallyRock,1423528638,,1,4,False,http://a.thumbs.redditmedia.com/BkPFdokaOISiHLPyI_BJAhm30ya8m2mTqo5o50orEX4.jpg,,,,,
118,MachineLearning,t5_2r3gv,2015-2-10,2015,2,10,13,2vducn,self.MachineLearning,"Definitions of ""Parametric"" vs. ""Non-parametric"" in ML and statistics - Let's get it straight",https://www.reddit.com/r/MachineLearning/comments/2vducn/definitions_of_parametric_vs_nonparametric_in_ml/,rasbt,1423542785,"Hi all, 

I just had this discussion with a colleague today -- I didn't agree with him that perceptrons are non-parametric.

However, saying that perceptrons are non-parametric just didn't sound right to me. After submitting some search terms to Google Scholar, I saw that those terms are being used interchangeably in literature. 
Please let's discuss and clarify!

Based on my understanding now, statisticians use the term parametric in context of making assumptions about the distribution the samples have been drawn from. In contrast to ML where we use it to distinguish between the relation of training samples and assumptions.

Some examples:

I think ""naive Bayes"" classifiers are obviously parametric! E.g., in the Gaussian case have the mean and SD. Being a generative model, I think there is no argument about that from both sides. In terms of ""statistics,"" this would be parametric. And furthermore, this also doesn't have anything to do with our training samples.

Another easy one: k-nearest neighbor classifiers. Here, we don't make any assumptions about the distribution, however, being a lazy learner, our parameters do depend on the training data. Same for SVM.

But what about perceptrons now? Using the ML definition, I would say it is parametric, however, in terms of ""statistics,"" we don't model the joint probabilities here... 

I am looking forward to hear your opinion on this ""issue.""",11,5,False,self,,,,,
119,MachineLearning,t5_2r3gv,2015-2-10,2015,2,10,13,2vdv5j,self.MachineLearning,noob trying to use word2vec,https://www.reddit.com/r/MachineLearning/comments/2vdv5j/noob_trying_to_use_word2vec/,programmingselenium,1423543221,I want to programmatically make a game that prompts you with four words and asks you to choose the one that doesn't fit. My understanding is word2vec is pretty much the ideal way to get the data to do this programmatically. Is there an easier way to do this than having to deal with the entire pretrained word2vec model? I don't even know how to make ./distance GoogleNews-vectors-negative300.bin work on my terminal,3,0,False,self,,,,,
120,MachineLearning,t5_2r3gv,2015-2-10,2015,2,10,14,2ve1uc,arxiv.org,Stochastic rounding in training neural networks using integer math,https://www.reddit.com/r/MachineLearning/comments/2ve1uc/stochastic_rounding_in_training_neural_networks/,pseudopotential,1423547057,,7,5,False,default,,,,,
121,MachineLearning,t5_2r3gv,2015-2-10,2015,2,10,14,2ve22k,pythonhosted.org,Python package for the Particle Swarm Optimization Algorithm (PSO),https://www.reddit.com/r/MachineLearning/comments/2ve22k/python_package_for_the_particle_swarm/,[deleted],1423547203,,9,3,False,default,,,,,
122,MachineLearning,t5_2r3gv,2015-2-10,2015,2,10,15,2ve5uh,self.MachineLearning,"Is machine learning simply inputting objets and inputting an arbitrary reaction, then inputting objects and asking for an appropriate reaction based on previously inputted reactions?",https://www.reddit.com/r/MachineLearning/comments/2ve5uh/is_machine_learning_simply_inputting_objets_and/,[deleted],1423549750,,1,1,False,default,,,,,
123,MachineLearning,t5_2r3gv,2015-2-10,2015,2,10,19,2vem85,self.MachineLearning,Any package for Mixture Density RNN?,https://www.reddit.com/r/MachineLearning/comments/2vem85/any_package_for_mixture_density_rnn/,disentangle,1423564684,"Is there any package/library that implements Mixture Density Networks, or very specifically bidirectional long short-term memory recurrent neural nets with gaussian mixture density output layer?",5,2,False,self,,,,,
124,MachineLearning,t5_2r3gv,2015-2-10,2015,2,10,20,2vepji,crockpotveggies.com,Automating Tinder with Eigenfaces,https://www.reddit.com/r/MachineLearning/comments/2vepji/automating_tinder_with_eigenfaces/,galapag0,1423568010,,43,213,False,http://a.thumbs.redditmedia.com/-iSa8aFug_loQla3o1rvQ1a-podOvpmf_dKQDDZtqV8.jpg,,,,,
125,MachineLearning,t5_2r3gv,2015-2-10,2015,2,10,22,2vexub,hypothes.is,Someone is using hypothes.is to add useful comments on papers?,https://www.reddit.com/r/MachineLearning/comments/2vexub/someone_is_using_hypothesis_to_add_useful/,galapag0,1423574986,,0,1,False,http://a.thumbs.redditmedia.com/L2Ruw1ltB6FE4Wdxhintq1_qL9mrpmUvN6Dgu2FQIr4.jpg,,,,,
126,MachineLearning,t5_2r3gv,2015-2-11,2015,2,11,1,2vfguu,arxiv.org,Gated Feedback Recurrent Networks outperform LSTMs,https://www.reddit.com/r/MachineLearning/comments/2vfguu/gated_feedback_recurrent_networks_outperform_lstms/,[deleted],1423585523,,6,1,False,default,,,,,
127,MachineLearning,t5_2r3gv,2015-2-11,2015,2,11,2,2vfqkl,aka.ms,Short video clip shows how easy it is to get your IoT solution up &amp; running in the cloud,https://www.reddit.com/r/MachineLearning/comments/2vfqkl/short_video_clip_shows_how_easy_it_is_to_get_your/,MLBlogTeam,1423589906,,0,0,False,http://b.thumbs.redditmedia.com/ftHpWQAnv3s0dZOYmKtT5se6GYnxC1PtnSwz-u2EnQg.jpg,,,,,
128,MachineLearning,t5_2r3gv,2015-2-11,2015,2,11,3,2vfui6,analyticsvidhya.com,Learning path for Weka - GUI based machine learning,https://www.reddit.com/r/MachineLearning/comments/2vfui6/learning_path_for_weka_gui_based_machine_learning/,kunalj101,1423591608,,0,0,False,http://b.thumbs.redditmedia.com/gqaTdk7-nEEgB6rjUC5Vnh_KG_5ULiBgu5dvwaEXj4M.jpg,,,,,
129,MachineLearning,t5_2r3gv,2015-2-11,2015,2,11,4,2vg32d,self.MachineLearning,"Any awesome idea that you have in mind to see come true that uses Speech Processing and/or Machine Learning, NLP and AI",https://www.reddit.com/r/MachineLearning/comments/2vg32d/any_awesome_idea_that_you_have_in_mind_to_see/,tejdeepg,1423595381,Looking for an awesome idea to implement over the next year that uses the above domains. Should be new and innovative. Not worried about the complexity for now.,2,0,False,self,,,,,
130,MachineLearning,t5_2r3gv,2015-2-11,2015,2,11,4,2vg8rr,self.MachineLearning,Strategies for generating categorical variable transformations,https://www.reddit.com/r/MachineLearning/comments/2vg8rr/strategies_for_generating_categorical_variable/,Zelazny7,1423598168,"I am curious what career data scientists do to generate novel features of categorical data? All sorts of methods exist for transforming continuous data, but in my experience as a predictive modeler of credit and fraud risk, many of the features take on a small number of discrete values (both nominal and ordinal).

Apart from binarizing the levels of these variables, what other strategies are used to good effect?

Currently, I am creating new features by using randomForest and pulling in entire trees into other learning algorithms such as GBM or LASSO. Any other suggestions?",0,0,False,self,,,,,
131,MachineLearning,t5_2r3gv,2015-2-11,2015,2,11,5,2vgfz2,self.MachineLearning,Evaluating importance of a node in a neural network,https://www.reddit.com/r/MachineLearning/comments/2vgfz2/evaluating_importance_of_a_node_in_a_neural/,osazuwa,1423601195,"I am interested in conducting inference on the weights estimated in a neural network model with multiple hidden node layers.  Assume all the features are on the same scale, measured in the same units.  In regression, the explanatory contribution of a feature with response the response is given by the magnitude (and standard error) of the coefficient.  In a neural network, is there a similar way of discerning a hidden node's effect on the response, or other downstream nodes between itself and the response?",4,0,False,self,,,,,
132,MachineLearning,t5_2r3gv,2015-2-11,2015,2,11,6,2vghup,numenta.org,HTM.java Receives Benchmark Harness,https://www.reddit.com/r/MachineLearning/comments/2vghup/htmjava_receives_benchmark_harness/,numenta,1423602007,,5,0,False,http://b.thumbs.redditmedia.com/z7mVZA1ucx8qGhtyuCsGjfNIf5xFaLwH6i_tn8c43ZM.jpg,,,,,
133,MachineLearning,t5_2r3gv,2015-2-11,2015,2,11,6,2vglrz,stuartreid.co.za,10 Misconceptions about Neural Networks,https://www.reddit.com/r/MachineLearning/comments/2vglrz/10_misconceptions_about_neural_networks/,[deleted],1423603658,,14,1,False,default,,,,,
134,MachineLearning,t5_2r3gv,2015-2-11,2015,2,11,7,2vgs3g,self.MachineLearning,Best lang/environment to take advantage of parallel computing with an AMD GPU.,https://www.reddit.com/r/MachineLearning/comments/2vgs3g/best_langenvironment_to_take_advantage_of/,______POTATOES______,1423606327,"I'd like to start using GPU computing for my machine learning projects. I 
have a fairly modern AMD GPU with 1028 cores, and was but I noticed Theano appears to only support NVIDEA GPU  at the moment? Similarly, even poor MATLAB (my version anyway) doesn't support AMD GPU's. There is pyopencl but Theano seems to have a lot of symbolic manipulation features and other things, that I'd like to take advantage of those features if i can.

Is there an environment using AMD GPU's that is comparable to if using NVIDEA cards? I'm not restricting any recommend libraries/tools to python, but any of the other ""big data languages"" like Scala/R/Julia ideally. I would like to stay away from MATLAB and C.

Thanks.


",11,3,False,self,,,,,
135,MachineLearning,t5_2r3gv,2015-2-11,2015,2,11,8,2vh02y,self.MachineLearning,Looking for a challenging and interesting problem to solve? Jobr needs a rockstar data scientist to lead our team!,https://www.reddit.com/r/MachineLearning/comments/2vh02y/looking_for_a_challenging_and_interesting_problem/,JonathanPaulJobr,1423609932,"San Francisco, CA

Jobr (www.jobrapp.com) is seeking a talented and versatile data scientist to analyze and help optimize the algorithms used for job recommendations that drive hundreds of thousands of job applications per month. As part of our Science &amp; Algorithms team, you will have a direct and high impact on how product decisions related to recommendations are made.

Responsibilities

Proactively perform data exploration on user behavior to discover opportunities for improving our recommendation algorithms. Present your research and insights to all levels of the company, clearly and concisely
Create visualizations to make data easily accessible to the algorithm product team
Partner closely with our CTO to analyze algorithm experiments. Develop deep analyses and use your product sense to interpret the results and help drive key product decisions

The technical experience that will help you succeed (not a rigid litmus test):

5+ years relevant experience with a proven track record of leveraging analytics to drive significant business impact
Strong SQL skills
Experience with recommendation systems and machine learning
Programming experience with a scripting / backend language such as Python, Perl, Ruby, C, Java and Golang
Strong data visualizations skills to convey information and results clearly
MS/BS degree in Statistics, Mathematics, Operations Research, CS, Econometrics or related field
Proficiency with a statistical analysis tool such as R or SAS
Statistical knowledge and intuition - ideally utilized in A/B testing
Deep product sense
Self-starter
Exceptional interpersonal and communication skills
Impactful presentation skills in front of a large and diverse audience
A fan of Jobr is a strong plus

A few more things to know:

We expect a lot. Our culture is unique and we live by our values
We are a tight and driven team with big goals, so we seek individuals who are truly passionate about their work

Contact jp@jobrapp.com if you're interested.",2,0,False,self,,,,,
136,MachineLearning,t5_2r3gv,2015-2-11,2015,2,11,8,2vh3jp,self.MachineLearning,[Help] Does anybody know where I can download weka besides sourceforge?,https://www.reddit.com/r/MachineLearning/comments/2vh3jp/help_does_anybody_know_where_i_can_download_weka/,[deleted],1423611539,"I need weka (for os x) to complete some homework assignments but it looks like the sourceforge website that hosts the files is currently inoperable. does anybody know any mirrors where it's hosted or something?

thank you",2,0,False,default,,,,,
137,MachineLearning,t5_2r3gv,2015-2-11,2015,2,11,8,2vh62z,self.MachineLearning,Gesture recognition using accelerometer and gyroscope data,https://www.reddit.com/r/MachineLearning/comments/2vh62z/gesture_recognition_using_accelerometer_and/,[deleted],1423612718,"I'm trying to build a classifier that will be able to detect when a user performs a certain gesture by using data from a wrist-worn accelerometer+gyroscope.  I am looking at a sliding window of the last second of data and using the mean and standard deviation of both acceleration and angular velocity in x, y, and z axes as the features (so 12 total).

Right now I collect calibration data by getting the user to perform the action 5 times and then calculating the mean and standard deviation of each of the 12 features for those measurements. 

For testing, every time I get a new reading from the sensor I compute the 12 features for the last second of data and compare that with the calibration numbers.  I started out by calculating the ((current reading - calibration average)/calibration stdev)^2 for each feature and if the average for all features was below a threshold that I set empirically I classified it as the gesture I was looking for.  I've found that this can perform well if calibrated well but differences in how consistently the calibration actions are performed cause the calibration stdevs to change which requires the classification threshold to need to change too.  

I started looking into Naive Bayes classifiers because I realized that that was pretty close to what I was doing.  I replaced the calculation above with calculating the probability density for each feature and then summing their logs to get most of the posterior numerator.  What I don't have is the probability that this gesture is occurring or the posterior numerators of any other gestures to compare this to.  If I just compare the sum of the logs of the probability densities to an empirical threshold it works pretty similar to what I was getting before. 

I guess what I'm trying to figure out is how to get a Naive Bayes classifier (or similar) to classify if one action is happening or not, instead of choosing the best fit between multiple classes.  I could try to provide data for other actions that would be negative results but I'm not sure how I would go about doing this since I need to differentiate the desired action from any random motion.

I'm new to machine learning so any suggestions on how to get my classifier more consistent, any other classifiers I should try, or ideas on how I could improve my overall process would be greatly appreciated!",1,1,False,default,,,,,
138,MachineLearning,t5_2r3gv,2015-2-11,2015,2,11,10,2vhj3f,arxiv.org,"""on a straight path from initialization to solution, ... NNs never encounter any significant obstacles"" (ICLR 2015 paper)",https://www.reddit.com/r/MachineLearning/comments/2vhj3f/on_a_straight_path_from_initialization_to/,[deleted],1423618891,,13,21,False,default,,,,,
139,MachineLearning,t5_2r3gv,2015-2-11,2015,2,11,13,2vi1un,github.com,Torch7 Workshop by FB's Soumith Chintala @ Next.ML,https://www.reddit.com/r/MachineLearning/comments/2vi1un/torch7_workshop_by_fbs_soumith_chintala_nextml/,gwulfs,1423628038,,0,7,False,http://b.thumbs.redditmedia.com/bh7_uxaHxe2b2nRClgi1AYvVSfq7vMlcmlS8hzCBqNg.jpg,,,,,
140,MachineLearning,t5_2r3gv,2015-2-11,2015,2,11,16,2vii0o,yanirseroussi.com,Learning to rank for personalised search (Kaggle competition summary),https://www.reddit.com/r/MachineLearning/comments/2vii0o/learning_to_rank_for_personalised_search_kaggle/,yanirse,1423638022,,0,11,False,http://b.thumbs.redditmedia.com/dMqpceFBQaWGT111UPJ0iyP9DmAs5nWNc-eSw0SuShU.jpg,,,,,
141,MachineLearning,t5_2r3gv,2015-2-11,2015,2,11,16,2vilud,self.MachineLearning,Question: What are some good techniques/tests to tell if one time series is affected by the other ?,https://www.reddit.com/r/MachineLearning/comments/2vilud/question_what_are_some_good_techniquestests_to/,klug3,1423641139,"Say, If I wanted to verify if the NYSE movements have a significant effect on the Frankfurt/London exchanges or vice versa. ",7,6,False,self,,,,,
142,MachineLearning,t5_2r3gv,2015-2-11,2015,2,11,18,2visgg,memkite.com,Deep Learning for Speech Recognition,https://www.reddit.com/r/MachineLearning/comments/2visgg/deep_learning_for_speech_recognition/,atveit,1423647810,,0,0,False,http://b.thumbs.redditmedia.com/YJiLRsmLfh5Hr7HRYeU1sV7gFJAELNmBs_dRssUmoXw.jpg,,,,,
143,MachineLearning,t5_2r3gv,2015-2-11,2015,2,11,20,2vj0na,rstudio-pubs-static.s3.amazonaws.com,CUDA is not meant for training random forests,https://www.reddit.com/r/MachineLearning/comments/2vj0na/cuda_is_not_meant_for_training_random_forests/,galapag0,1423655897,,4,1,False,default,,,,,
144,MachineLearning,t5_2r3gv,2015-2-11,2015,2,11,21,2vj3vp,self.MachineLearning,I've asked a couple of questions on Quora recently and would love to hear r/machinelearning's take on them..?,https://www.reddit.com/r/MachineLearning/comments/2vj3vp/ive_asked_a_couple_of_questions_on_quora_recently/,peeaypeeay,1423658579,"Hi, these are the two questions I asked, I'm interested to hear responses to either or both :) 

 What are the three top algorithms that every data scientist should have in their toolbox?

 Regarding machine learning, unless I'm using some relatively simple algorithm like logistic regression or decision trees, how can I know which variables are important in my model?

Thank-you! 


",9,4,False,self,,,,,
145,MachineLearning,t5_2r3gv,2015-2-11,2015,2,11,22,2vj914,info.mariner-usa.com,I just wrote a white paper on Azure ML. Check it out and tell me what you think!,https://www.reddit.com/r/MachineLearning/comments/2vj914/i_just_wrote_a_white_paper_on_azure_ml_check_it/,[deleted],1423662361,,1,0,False,default,,,,,
146,MachineLearning,t5_2r3gv,2015-2-11,2015,2,11,22,2vj9pv,grip.qa,Training an AI team member using machine learning,https://www.reddit.com/r/MachineLearning/comments/2vj9pv/training_an_ai_team_member_using_machine_learning/,k-mile,1423662799,,1,0,False,http://b.thumbs.redditmedia.com/2h3nDA5Nnmpdh4w03fgxnuL-whz0lXWtKmHYQrHT3EY.jpg,,,,,
147,MachineLearning,t5_2r3gv,2015-2-11,2015,2,11,23,2vjdcw,arxiv.org,"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention",https://www.reddit.com/r/MachineLearning/comments/2vjdcw/show_attend_and_tell_neural_image_caption/,clbam8,1423664864,,7,14,False,default,,,,,
148,MachineLearning,t5_2r3gv,2015-2-12,2015,2,12,0,2vjhur,self.MachineLearning,Can anyone help me in installing The TARSQI Toolkit or suggest me a temporal detection toolkit?,https://www.reddit.com/r/MachineLearning/comments/2vjhur/can_anyone_help_me_in_installing_the_tarsqi/,harshil93,1423667391,,0,0,False,self,,,,,
149,MachineLearning,t5_2r3gv,2015-2-12,2015,2,12,0,2vjm4s,kdnuggets.com,10 things statistics taught us about big data analysis (or machine learning),https://www.reddit.com/r/MachineLearning/comments/2vjm4s/10_things_statistics_taught_us_about_big_data/,Quantizedz,1423669568,,28,81,False,http://b.thumbs.redditmedia.com/zvFe6zTtIMywZ6yPjz7uAWe0AUd44iFuzCMUKF_XMjo.jpg,,,,,
150,MachineLearning,t5_2r3gv,2015-2-12,2015,2,12,0,2vjn3x,anthonygarvan.github.io,Interactive Visualization of 20k Word2Vec Vectors,https://www.reddit.com/r/MachineLearning/comments/2vjn3x/interactive_visualization_of_20k_word2vec_vectors/,botman55,1423670060,,6,14,False,http://b.thumbs.redditmedia.com/XZ5TzZATTpjRoyYrn-PIMM_OxHFwrWiivB1atgjCdDw.jpg,,,,,
151,MachineLearning,t5_2r3gv,2015-2-12,2015,2,12,1,2vjsyr,arxiv.org,Gated Feedback Recurrent Neural Networks,https://www.reddit.com/r/MachineLearning/comments/2vjsyr/gated_feedback_recurrent_neural_networks/,mega,1423672789,,9,5,False,default,,,,,
152,MachineLearning,t5_2r3gv,2015-2-12,2015,2,12,1,2vjt91,self.MachineLearning,Resource for crowdsourced algorithm development?,https://www.reddit.com/r/MachineLearning/comments/2vjt91/resource_for_crowdsourced_algorithm_development/,indydiddle,1423672919,"First off, this is NOT me trying to get people to do my homework. This is to supplement work that I'm doing at my current job, and just a general question. So I'm slowly building up my ML skill-set, but I am running into a problem that I need solved before I feel I can ""catch up"". I've been looking around for a resource like I describe in the title--a place where people come with specific ML or general algorithm development questions, and the community can respond with suggestions and co-develop the algorithm with the user who posted the question. 

TL;DR I have a 2D clustering problem, and I have loads of training data. 1: does anyone want to take a look? 2: does anyone know of a community to which I can bring this problem?",5,0,False,self,,,,,
153,MachineLearning,t5_2r3gv,2015-2-12,2015,2,12,2,2vjxn2,aka.ms,"Gigaom Research hosts a free webinar + panel discussion tomorrow on ""ML for Business Users &amp; Enterprise Developers""",https://www.reddit.com/r/MachineLearning/comments/2vjxn2/gigaom_research_hosts_a_free_webinar_panel/,MLBlogTeam,1423674955,,0,1,False,http://b.thumbs.redditmedia.com/ftHpWQAnv3s0dZOYmKtT5se6GYnxC1PtnSwz-u2EnQg.jpg,,,,,
154,MachineLearning,t5_2r3gv,2015-2-12,2015,2,12,2,2vjyxp,self.MachineLearning,I'm providing a free data visualization service,https://www.reddit.com/r/MachineLearning/comments/2vjyxp/im_providing_a_free_data_visualization_service/,GalaxyTurf,1423675541,"This is for most D3 visualizations you see here: 

https://github.com/mbostock/d3/wiki/Gallery

PM me if you want.",4,0,False,self,,,,,
155,MachineLearning,t5_2r3gv,2015-2-12,2015,2,12,3,2vk7cy,self.MachineLearning,Latent Dirichlet Allocation vs. TF-IDF for Indexing,https://www.reddit.com/r/MachineLearning/comments/2vk7cy/latent_dirichlet_allocation_vs_tfidf_for_indexing/,Archawn,1423679244,"Yesterday, I tried to briefly describe the idea of (topic modeling via) Latent Dirichlet Allocation to a software engineer who was interviewing me for an unrelated internship position doing coding work.  He asked me to explain topic models, which I mention on my resume.  He had a general understanding of machine learning but told me that he hadn't ever witnessed the Bayesian side of things.

My explanation was rather poor, and it was hard for me to explain both LDA and Bayesian modeling / modeling with PGMs in such a short amount of time.  To most people without a technical background, they're satisfied if I say that LDA yields list of salient groups of related words over a collection, with documents represented as a mixture of these groups.

The interviewer, however, familiar with simpler indexing schemes, asked me genuinely what the difference is between LDA and tf/idf indexing, for example.  The best I could come up with is that 

After this experience, I realize that although I understand certain machine learning algorithms on a technical level, I need to work on my intuitive understanding of what they accomplish.

Looking back at the original LDA paper, the only explanation is the following:

&gt; While the tf-idf reduction has some appealing featuresnotably in its basic identification of sets of words that are discriminative for documents in the collectionthe approach also provides a relatively small amount of reduction in description length and reveals little in the way of inter- or intradocument statistical structure.

Reddit, how would you answer this question?  Can you provide any insight in to the quote above?  What limitations does TF-IDF have that LDA improves upon?

TL;DR if an interviewer asked you what the difference between LDA and indexing by tf/idf or something similar, how would you respond?",2,0,False,self,,,,,
156,MachineLearning,t5_2r3gv,2015-2-12,2015,2,12,4,2vkfpo,self.MachineLearning,Questions about RMSprop,https://www.reddit.com/r/MachineLearning/comments/2vkfpo/questions_about_rmsprop/,[deleted],1423682993,"There is no paper describing RMSprop, only lecture notes, that are a bit ambiguous. I'm hoping to clarify a couple of things:

* When keeping track of the exponential average of the gradient square, is there a single average used for all components, or one average square partial derivatives for each dimension? (I think I've seen both interpretations, but what's the ""official"" RMSprop?)

* How is the learning rate adjusted? Rprop does something like ""divide by 2, if the sign of the derivative changes, multiply by 1.2, if it doesn't"", but I don't this this would work in a stochastic setting.",0,1,False,default,,,,,
157,MachineLearning,t5_2r3gv,2015-2-12,2015,2,12,4,2vkfs2,self.MachineLearning,Questions about RMSprop,https://www.reddit.com/r/MachineLearning/comments/2vkfs2/questions_about_rmsprop/,[deleted],1423683019,"There is no paper describing RMSprop, only lecture notes, that are a bit ambiguous. I'm hoping to clarify a couple of things:

* When keeping track of the exponential average of the gradient square, is there a single average used for all components, or one average square partial derivative per dimension? (I think I've seen both interpretations, but what's the ""official"" RMSprop?)

* How is the learning rate adjusted? Rprop does something like ""divide by 2, if the sign of the derivative changes, multiply by 1.2, if it doesn't"", but I don't this this would work in a stochastic setting.",8,5,False,self,,,,,
158,MachineLearning,t5_2r3gv,2015-2-12,2015,2,12,5,2vkq85,predictiveanalyticsworld.com,Automated algorithm selection is set to transform Data Science,https://www.reddit.com/r/MachineLearning/comments/2vkq85/automated_algorithm_selection_is_set_to_transform/,[deleted],1423687607,,0,0,False,default,,,,,
159,MachineLearning,t5_2r3gv,2015-2-12,2015,2,12,5,2vkq9a,next.ml,Machine Learning Conference (Free for Students),https://www.reddit.com/r/MachineLearning/comments/2vkq9a/machine_learning_conference_free_for_students/,gwulfs,1423687620,,1,7,False,default,,,,,
160,MachineLearning,t5_2r3gv,2015-2-12,2015,2,12,8,2vl8hp,self.MachineLearning,A question about Maxout: who gets the error,https://www.reddit.com/r/MachineLearning/comments/2vl8hp/a_question_about_maxout_who_gets_the_error/,mfagerlund,1423695727,"I just implemented Maxout and on re-reading the paper, I get the feeling that I over engineered this thing. It was the hardest activation to implement thus far; I've built it so that only the winner takes an error hit (the node with the highest activation*weight) and all other nodes (who didn't get the max) don't get pushed around.

The other option is to spread the error around somehow. When adding activations together, this makes sense. But with Maxout, it doesn't make as much sense?

So, which one's the correct one, and if I'm doing it wrong, what's my way called ;)",17,3,False,self,,,,,
161,MachineLearning,t5_2r3gv,2015-2-12,2015,2,12,10,2vlp6l,slideshare.net,Intro to Supervised Machine Learning (presentation slides),https://www.reddit.com/r/MachineLearning/comments/2vlp6l/intro_to_supervised_machine_learning_presentation/,[deleted],1423704071,,0,1,False,default,,,,,
162,MachineLearning,t5_2r3gv,2015-2-12,2015,2,12,11,2vlux8,arxiv.org,Surpassing Human-Level Performance on ImageNet Classification,https://www.reddit.com/r/MachineLearning/comments/2vlux8/surpassing_humanlevel_performance_on_imagenet/,Devilsbabe,1423706918,,2,0,False,default,,,,,
163,MachineLearning,t5_2r3gv,2015-2-12,2015,2,12,11,2vlzws,self.MachineLearning,[META] Could we get autoremoval of duplicate articles?,https://www.reddit.com/r/MachineLearning/comments/2vlzws/meta_could_we_get_autoremoval_of_duplicate/,[deleted],1423709551,"Not sure if there is a mod bot in use in this sub, or how this could be implemented but it seems like every time there's an interesting article on arXiv it gets posted here several times, a day or two apart. 

This is annoying and also fragments the already minimal discussion.

In my dream world, ""data science"" blogspam domains would get autobanned as well, but just restricting URLs from being posted multiple times within a week or so would be nice.",1,3,False,default,,,,,
164,MachineLearning,t5_2r3gv,2015-2-12,2015,2,12,13,2vm7oa,slideshare.net,The big picture of Machine Learning and classification in 50 slides,https://www.reddit.com/r/MachineLearning/comments/2vm7oa/the_big_picture_of_machine_learning_and/,[deleted],1423713609,,0,1,False,default,,,,,
165,MachineLearning,t5_2r3gv,2015-2-12,2015,2,12,13,2vmd0f,databoys.github.io,A very gentle tutorial on a very basic neural network in python.,https://www.reddit.com/r/MachineLearning/comments/2vmd0f/a_very_gentle_tutorial_on_a_very_basic_neural/,yourbuddyflo,1423716580,,9,68,False,http://b.thumbs.redditmedia.com/yeypdo1qMucAypOLst4lnFXqqwOXw33wPdsewfiOD7Q.jpg,,,,,
166,MachineLearning,t5_2r3gv,2015-2-12,2015,2,12,14,2vmh8o,arxiv.org,"Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9% top-5 validation error (and 4.8% test error), exceeding the accuracy of human raters.",https://www.reddit.com/r/MachineLearning/comments/2vmh8o/using_an_ensemble_of_batchnormalized_networks_we/,biomimic,1423719140,,30,54,False,default,,,,,
167,MachineLearning,t5_2r3gv,2015-2-12,2015,2,12,16,2vmrcg,innsbigdata.wordpress.com,50 Years of Deep Learning and Beyond: an Interview with Jrgen Schmidhuber,https://www.reddit.com/r/MachineLearning/comments/2vmrcg/50_years_of_deep_learning_and_beyond_an_interview/,iori42,1423726470,,0,7,False,http://b.thumbs.redditmedia.com/PWbJf-e-mYlKhO92SDug0xeObkStGExihFfmDCvnhSE.jpg,,,,,
168,MachineLearning,t5_2r3gv,2015-2-12,2015,2,12,20,2vn4fu,nuit-blanche.blogspot.com,"Slides Paris Machine Learning #6 Season 2: Vowpal Wabbit, a Survey on RL and Deep RL, Inmoov, libFM and more (Video in English only for John Langford's presentation, otherwise in French)",https://www.reddit.com/r/MachineLearning/comments/2vn4fu/slides_paris_machine_learning_6_season_2_vowpal/,compsens,1423739439,,0,0,False,http://b.thumbs.redditmedia.com/CcjQJfVkk-Q-tCXSXXUWoFJI8grMdlKLZAoKjnyQYCA.jpg,,,,,
169,MachineLearning,t5_2r3gv,2015-2-13,2015,2,13,1,2vnwvs,thetalkingmachines.com,Talking Machines Ep 4 - Topic modeling using LDA,https://www.reddit.com/r/MachineLearning/comments/2vnwvs/talking_machines_ep_4_topic_modeling_using_lda/,vkhuc,1423758329,,6,35,False,http://b.thumbs.redditmedia.com/Bf48OF_9xBhrpE_TAleNaUaYage-tdtm5eViIjbDI4Q.jpg,,,,,
170,MachineLearning,t5_2r3gv,2015-2-13,2015,2,13,2,2vo2d8,analyticsbot.ml,Classifying the MNIST hand-written digit with Pybrain - Deep Learning Architecture. Get started with Pybrain,https://www.reddit.com/r/MachineLearning/comments/2vo2d8/classifying_the_mnist_handwritten_digit_with/,YahooGuys,1423760846,,0,1,False,http://b.thumbs.redditmedia.com/M7U5ZR7wJ1Lv5pvRvzsIItx-rLRJPD1NPHyJf9tOyes.jpg,,,,,
171,MachineLearning,t5_2r3gv,2015-2-13,2015,2,13,3,2voc54,aka.ms,A step-by-step guide to building web services with R and Azure Machine Learning,https://www.reddit.com/r/MachineLearning/comments/2voc54/a_stepbystep_guide_to_building_web_services_with/,MLBlogTeam,1423765391,,0,1,False,default,,,,,
172,MachineLearning,t5_2r3gv,2015-2-13,2015,2,13,3,2voca8,setosa.io,Principal Component Analysis explained visually,https://www.reddit.com/r/MachineLearning/comments/2voca8/principal_component_analysis_explained_visually/,clockworkmischief,1423765452,,21,68,False,default,,,,,
173,MachineLearning,t5_2r3gv,2015-2-13,2015,2,13,4,2volzd,uzmanlarmakine.com,"Uzmanlar Makine - Makine imalat diyarbakr, konkasr imalat",https://www.reddit.com/r/MachineLearning/comments/2volzd/uzmanlar_makine_makine_imalat_diyarbakr_konkasr/,isyankar458,1423770049,,0,1,False,default,,,,,
174,MachineLearning,t5_2r3gv,2015-2-13,2015,2,13,5,2vopjb,self.MachineLearning,How can I understand why a particular (ML) decision was made? (evidence counterfactuals),https://www.reddit.com/r/MachineLearning/comments/2vopjb/how_can_i_understand_why_a_particular_ml_decision/,vicflair,1423772080,"In this [keynote talk](https://www.youtube.com/watch?v=l7XPN0XUCkw) at the 2014 Hadoop + Strata conference, Foster Provost says:

&gt; With the increasing use of predictive models based on massive fine-grained data, it is becoming increasingly difficult to understand *why particular decisions were made*.

Can anyone explain approaches to do this, i.e. understand what causes a particular data point to be classified the way it is? For random forests? In general?

He talks about ""evidence counterfactuals"" in an example about Facebook, where they remove certain features (or data) to see what the effect was. It seems like this is somewhat related to the idea of [lift](http://en.wikipedia.org/wiki/Lift_%28data_mining%29), [partial dependence plots](http://math.furman.edu/~dcs/courses/math47/R/library/randomForest/html/partialPlot.html), and feature importance.
",1,0,False,self,,,,,
175,MachineLearning,t5_2r3gv,2015-2-13,2015,2,13,5,2vorez,radar.oreilly.com,"Forecasting events, from disease outbreaks to sales to cancer research",https://www.reddit.com/r/MachineLearning/comments/2vorez/forecasting_events_from_disease_outbreaks_to/,gradientflow,1423772932,,0,2,False,http://b.thumbs.redditmedia.com/JikmiMOkEfOdIPCj3j5IO0OcNh2sAQXsm3XiOCJMzng.jpg,,,,,
176,MachineLearning,t5_2r3gv,2015-2-13,2015,2,13,6,2vowoz,genopharmix.com,Data Science and Fifty Shades of Grey - A Text Summarization Algorithm at Play,https://www.reddit.com/r/MachineLearning/comments/2vowoz/data_science_and_fifty_shades_of_grey_a_text/,[deleted],1423775199,,10,0,False,default,,,,,
177,MachineLearning,t5_2r3gv,2015-2-13,2015,2,13,8,2vpdv9,techcrunch.com,YC-Backed SigOpt Helps Customers Optimize Everything From Online Ads To Shaving Cream,https://www.reddit.com/r/MachineLearning/comments/2vpdv9/ycbacked_sigopt_helps_customers_optimize/,Zephyr314,1423782890,,9,1,False,http://b.thumbs.redditmedia.com/ZXag_gSX-gNDQRld0UgXFrofrqiaaWYiRSRpPCis8PQ.jpg,,,,,
178,MachineLearning,t5_2r3gv,2015-2-13,2015,2,13,10,2vpwvo,tech.opentable.com,Valentines Day diners are getting more demanding,https://www.reddit.com/r/MachineLearning/comments/2vpwvo/valentines_day_diners_are_getting_more_demanding/,datamusing,1423792334,,0,0,False,default,,,,,
179,MachineLearning,t5_2r3gv,2015-2-13,2015,2,13,16,2vqwdd,arxiv.org,Random Walks on Context Spaces: Towards an Explanation of the Mysteries of Semantic Word Embeddings,https://www.reddit.com/r/MachineLearning/comments/2vqwdd/random_walks_on_context_spaces_towards_an/,onewugtwowugs,1423813897,,0,12,False,default,,,,,
180,MachineLearning,t5_2r3gv,2015-2-14,2015,2,14,0,2vru1l,queue.acm.org,Online Algorithms in High-frequency Trading,https://www.reddit.com/r/MachineLearning/comments/2vru1l/online_algorithms_in_highfrequency_trading/,alexcasalboni,1423841594,,2,51,False,http://a.thumbs.redditmedia.com/NqROt2hDt3jYINsLXM2rSkOJhs6JaiRjBD7WNbeuTW0.jpg,,,,,
181,MachineLearning,t5_2r3gv,2015-2-14,2015,2,14,2,2vsba7,arxiv.org,Over-Sampling in a Deep Neural Network,https://www.reddit.com/r/MachineLearning/comments/2vsba7/oversampling_in_a_deep_neural_network/,noideaman,1423849624,,1,6,False,default,,,,,
182,MachineLearning,t5_2r3gv,2015-2-14,2015,2,14,2,2vsc2x,self.MachineLearning,Does anyone get flack from people in other departments or areas of specialization?,https://www.reddit.com/r/MachineLearning/comments/2vsc2x/does_anyone_get_flack_from_people_in_other/,andrewff,1423849986,"I've been taking a biostats course this semester and thus far I've heard several rude or ignorant comments about machine learning people from both the instructor of the course and the head of the department.

Has anyone had similar experiences with other departments? How do you respond/react to these things?",23,3,False,self,,,,,
183,MachineLearning,t5_2r3gv,2015-2-14,2015,2,14,3,2vsk6r,self.MachineLearning,Online Projects in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/2vsk6r/online_projects_in_machine_learning/,heisenbug007,1423853803,,1,0,False,default,,,,,
184,MachineLearning,t5_2r3gv,2015-2-14,2015,2,14,4,2vsrd6,github.com,I'm training an ANN to classify small from big tits. Yup.,https://www.reddit.com/r/MachineLearning/comments/2vsrd6/im_training_an_ann_to_classify_small_from_big/,[deleted],1423857246,,18,0,False,default,,,,,
185,MachineLearning,t5_2r3gv,2015-2-14,2015,2,14,4,2vsrn1,self.MachineLearning,Class help:,https://www.reddit.com/r/MachineLearning/comments/2vsrn1/class_help/,bigdickmassinf,1423857369,,0,0,False,default,,,,,
186,MachineLearning,t5_2r3gv,2015-2-14,2015,2,14,8,2vtjwf,thoughtly.co,Prototype ML/NLP Code Tutorial Series Lesson 2: Probability,https://www.reddit.com/r/MachineLearning/comments/2vtjwf/prototype_mlnlp_code_tutorial_series_lesson_2/,mercurialkitten,1423870776,,1,11,False,http://b.thumbs.redditmedia.com/VGvGhvuBlt-Tk2yvGjjDuCvuEVp2QalmNZLuvlgOVoI.jpg,,,,,
187,MachineLearning,t5_2r3gv,2015-2-14,2015,2,14,15,2vun1w,self.MachineLearning,I just have to ask. How do people get any kind of machine learning done in Java?,https://www.reddit.com/r/MachineLearning/comments/2vun1w/i_just_have_to_ask_how_do_people_get_any_kind_of/,beaverteeth92,1423894424,"I implemented association rule mining in Java about two weeks ago and it was not a fun experience.  I mean things like absurd amounts of nested generics and spending 80% of my time converting types and data structures back and forth and messing with generics.  It felt like I was drowning without vectorization, list comprehensions, operator overloading, and most of the functional stuff Python supports.

I keep seeing people mention Java on here, and most MapReduce stuff runs on the JVM (although I have no MapReduce experience).  How do you guys deal with data-related stuff in Java, and how do you go about making your life easier when using it?",34,21,False,self,,,,,
188,MachineLearning,t5_2r3gv,2015-2-14,2015,2,14,23,2vvg9b,self.MachineLearning,Russian script training set?,https://www.reddit.com/r/MachineLearning/comments/2vvg9b/russian_script_training_set/,merkinj,1423923560,"My in-laws have a family history that was handwritten by an ancestor. I thought I would play around with trying to digitize it, but need a training set of Russian script characters. Can anybody point me to a good resource?",4,0,False,self,,,,,
189,MachineLearning,t5_2r3gv,2015-2-15,2015,2,15,2,2vw0gv,self.MachineLearning,Extract sentence containing a particular word from millions of paragraphs,https://www.reddit.com/r/MachineLearning/comments/2vw0gv/extract_sentence_containing_a_particular_word/,[deleted],1423935458,"I'm making an app for examinations like SAT, GRE where students need to improve their vocabulary. Students want to know how a particular word is implemented in a sentence. What I'm doing is that I am crawling _a lot_ of newspaper articles and extracting the sentence what contains GRE/SAT word.

Here is what I've done and what I want to do/improve and I need your help on that.

What I've done to collect data:
Python Scrapy to extract data from newspaper websites.

Improvements:
1. I'm finding it hard to scrape only a particular day's articles. If you guys want to scrape only a particular day's articles from top newspapers of the world, then how would you do it ?
2. Currently I've crawled millions of articles and stored in MongoDB. It is taking a lot of time to extract sentences from these articles. Anyway I can improve the performance.
3. I'm currently using MongoDB to store the articles. Is it OK? What is more scalable ?

What I'm doing to extract sentences:
Here is the rough code that I've written to extract sentences using Python NLTK library - http://pastebin.com/x9qRKv2R 

This code is wrong since it is not looking at the root word. I used PorterStemmer but it returns wrong stem word for many words. Is there any better way to do that?",7,3,False,default,,,,,
190,MachineLearning,t5_2r3gv,2015-2-15,2015,2,15,4,2vwffi,self.MachineLearning,Question: doesn't exponential learning rate decay contradict Robbins &amp; Monro?,https://www.reddit.com/r/MachineLearning/comments/2vwffi/question_doesnt_exponential_learning_rate_decay/,[deleted],1423943053,"Some people advocate and use exponential learning rate decay in training, but doesn't this contradict the Robbins and Monro conditions? (Eq. 27 in the ""SGD paper"": Robbins and Monro, A Stochastic Approximation Method, 1951) What's the motivation for using exponential decay?",0,3,False,self,,,,,
191,MachineLearning,t5_2r3gv,2015-2-15,2015,2,15,5,2vwijn,self.MachineLearning,Juergen Schmidhuber will be doing an AMA in /r/MachineLearning on March 4 10AM EST,https://www.reddit.com/r/MachineLearning/comments/2vwijn/juergen_schmidhuber_will_be_doing_an_ama_in/,olaf_nij,1423944665,"I'm happy to announce Director of the Swiss AI Lab IDSIA/Professor of Artificial Intelligence at the University of Lugano Juergen Schmidhuber will be visiting /r/MachineLearning on March 4 10AM EST for an AMA.

As usual, a thread will be created before the official AMA time for those who won't be able to attend.

Special thanks to Sohrob Kazerounian and Rupesh Srivastava for help organizing.",10,107,False,self,,,,,
192,MachineLearning,t5_2r3gv,2015-2-15,2015,2,15,5,2vwkye,andyljones.tumblr.com,An explanation of Xavier initialization for neural networks,https://www.reddit.com/r/MachineLearning/comments/2vwkye/an_explanation_of_xavier_initialization_for/,bluecoffee,1423945920,,16,8,False,http://b.thumbs.redditmedia.com/sGFevTdH-cqwIPu3brviaUKCJ9GnVjadbi-2CEgMY4Y.jpg,,,,,
193,MachineLearning,t5_2r3gv,2015-2-15,2015,2,15,19,2vyn8g,tjo-en.hatenablog.com,What kind of decision boundaries does Deep Learning (Deep Belief Net) draw? Practice with R and {h2o} package,https://www.reddit.com/r/MachineLearning/comments/2vyn8g/what_kind_of_decision_boundaries_does_deep/,TJO_datasci,1423997191,,0,1,False,http://b.thumbs.redditmedia.com/iU2RQWstI-vZF6vPeGsbqVoJkx8e0zaPVTzwzwkgk3E.jpg,,,,,
194,MachineLearning,t5_2r3gv,2015-2-15,2015,2,15,19,2vyn8x,technologyreview.com,http://www.technologyreview.com/view/535176/human-face-recognition-found-in-neural-network-based-on-monkey-brains/,https://www.reddit.com/r/MachineLearning/comments/2vyn8x/httpwwwtechnologyreviewcomview535176humanfacerecog/,[deleted],1423997206,,0,1,False,default,,,,,
195,MachineLearning,t5_2r3gv,2015-2-15,2015,2,15,19,2vyn9m,technologyreview.com,"Neural network mimics functions of parts of monkey brain concerning facial recognition, exhibits similar quirks",https://www.reddit.com/r/MachineLearning/comments/2vyn9m/neural_network_mimics_functions_of_parts_of/,cybrbeast,1423997231,,0,5,False,http://b.thumbs.redditmedia.com/EZGzcGiezcORIe-QASCBP_FjKwT_4dULgtRoPHlYG6M.jpg,,,,,
196,MachineLearning,t5_2r3gv,2015-2-15,2015,2,15,19,2vynmn,self.MachineLearning,How do I implement a Bayesian network?,https://www.reddit.com/r/MachineLearning/comments/2vynmn/how_do_i_implement_a_bayesian_network/,bluedunnock,1423997695,"I have taken the PGM course of Kohler and read Kevin murphy's introduction to BN. Now I kind of understand, If i can come up with a structure and also If i have data to compute the CPDs I am good to go. I want to implement a simple BN, what are libraries, software that support defining factor graphs, BN structure and allow probabilistic queries?",13,11,False,self,,,,,
197,MachineLearning,t5_2r3gv,2015-2-15,2015,2,15,23,2vyybs,self.MachineLearning,[RL] What is the difference between Sarsa and Q-learning and which one is the best to use?,https://www.reddit.com/r/MachineLearning/comments/2vyybs/rl_what_is_the_difference_between_sarsa_and/,[deleted],1424008958,,5,12,False,default,,,,,
198,MachineLearning,t5_2r3gv,2015-2-15,2015,2,15,23,2vz13s,self.MachineLearning,Help on sentence classification,https://www.reddit.com/r/MachineLearning/comments/2vz13s/help_on_sentence_classification/,ChiefChinawhite,1424011166,"Dear Reddit,

I need to classify large amounts of sentences in two categories (in somewhat real time). I have never done any NLP before. Things went pretty well in the beginning but now I'm stuck. I found the Word2Vec algorithm to convert words into fixed length feature vectors. From there, there seem to be multiple ways to handle variable length data.

1. Histogram / Bag of words / Averaging feature vectors: I don't think this will work, since the order of words is very important.
2. Combining all word vectors in a sentence feature vector. (And classify that vector). Problem: I could not find an algorithm to that.
3. Recursive neural networks. This would be nice, because it is possible to use the 'syntax tree' of a sentence, which removes something the network should learn. Problem: I don't know how to train them. (Minibatch)SGD seems to be the right (or at least a working) algorithm here, but I don't know how to express the cost/loss function for such a network.
4.  Recurrent neural networks, feeding the word vectors over time. Same problem: I don't know how to train them.
5. Convolutional neural networks??...

I'm stuck here. My knowledge is limited, and I need to choose one of these.
Could someone tell which method is the easiest/gives the best results or some pointers on the problems I'm having?
I'll be happy with any kind of information.

// Another problem I have is that Word2Vec is sometimes unable to find correlations on large amounts of data. Could this have to to with learning rate / vector size? Also, I need to deliver next friday... :(",10,1,False,self,,,,,
199,MachineLearning,t5_2r3gv,2015-2-16,2015,2,16,6,2w06z7,arxiv.org,Probabilistic Line Searches for Stochastic Optimization (SGD that adjusts its learning rate using Bayesian Optimization),https://www.reddit.com/r/MachineLearning/comments/2w06z7/probabilistic_line_searches_for_stochastic/,[deleted],1424034013,,6,17,False,default,,,,,
200,MachineLearning,t5_2r3gv,2015-2-16,2015,2,16,7,2w0lly,genopharmix.com,Text &amp; Literature Summarizer for Mobile Research - GS1 GenoPharmix Tuatara Machine Learning Algorithm (/r/programming),https://www.reddit.com/r/MachineLearning/comments/2w0lly/text_literature_summarizer_for_mobile_research/,[deleted],1424041187,,0,1,False,default,,,,,
201,MachineLearning,t5_2r3gv,2015-2-16,2015,2,16,8,2w0ndm,self.MachineLearning,STEM project,https://www.reddit.com/r/MachineLearning/comments/2w0ndm/stem_project/,n-d-j,1424042080,"Hey guys,

I'm doing a STEM project at my HS (I'm in 9th grade) and I am developing a semi-autonomous word censor-er for use when explicit words need to be censored from continuous speech. How would I go about segmenting the words in the speech? (I already have the algorithm itself-which is an SVM-finished.)
EDIT: Why the downvotes?",10,0,False,self,,,,,
202,MachineLearning,t5_2r3gv,2015-2-16,2015,2,16,8,2w0nl1,genopharmix.com,Text &amp; Literature Summarizer for Mobile Research - GS1 GenoPharmix Tuatara Machine Learning Algorithm (/r/android),https://www.reddit.com/r/MachineLearning/comments/2w0nl1/text_literature_summarizer_for_mobile_research/,bboyjkang,1424042189,,2,2,False,default,,,,,
203,MachineLearning,t5_2r3gv,2015-2-16,2015,2,16,8,2w0odl,self.MachineLearning,How to start learning natural language processing,https://www.reddit.com/r/MachineLearning/comments/2w0odl/how_to_start_learning_natural_language_processing/,just_learning_,1424042585,"First off, I'm new to Reddit so I don't know if this is the right place to post questions like this (sorry if it isn't).

I am looking into diving into natural language processing. Are there some recommended steps to follow to build up a strong foundation in the subject so I can evetually start applying it and understand technical papers (e.g. specific books or online lecture series to watch)? Additionally, what math areas/classes should I brush up on (any recommended resources here also)?

About me: I'm an undergrad with a strong math and software background.",22,47,False,self,,,,,
204,MachineLearning,t5_2r3gv,2015-2-16,2015,2,16,10,2w12kn,self.MachineLearning,[Question] What do you do when filters aren't learning?,https://www.reddit.com/r/MachineLearning/comments/2w12kn/question_what_do_you_do_when_filters_arent/,flangles,1424050125,"I'm trying to train a CNN for image classification, and I've noticed that the upper level filters don't seem to be learning - after many epochs they still are nearly identical to their random initialization. 

This seems like a problem, although the network overall seems to be training ok (steadily decreasing validation loss). 

Is there a rule of thumb for what to do in this situation?",4,1,False,self,,,,,
205,MachineLearning,t5_2r3gv,2015-2-16,2015,2,16,11,2w197d,self.MachineLearning,Is there any research on how well hyperparameters scale with data?,https://www.reddit.com/r/MachineLearning/comments/2w197d/is_there_any_research_on_how_well_hyperparameters/,polytop3,1424053899,"Sometimes I tune hyperparameters on small data sets (for the sake of time), and then check the top k hyperparamter settings on larger data sets to determine which are the ""best"" hyperparamters.

I was wondering if there was any research (or rules of thumb), on how well hyperparamters scale with data for various learning algorithms (Random Forest, Neural Nets, SVMs, etc)

Thanks in advance!",8,6,False,self,,,,,
206,MachineLearning,t5_2r3gv,2015-2-16,2015,2,16,13,2w1npt,self.MachineLearning,How can we compare two probabilistic models(markov networks) such that its inference probability(or some confidence metric) depends on amount of training data ?,https://www.reddit.com/r/MachineLearning/comments/2w1npt/how_can_we_compare_two_probabilistic_modelsmarkov/,MLGUY7,1424062350,I have a task of comparing two CRF models where each node and edge probability is associated with reliability depending on amount of data it is trained .How can I have a confidence metric for prediction model which depends on amount of training data for each model ?,1,3,False,self,,,,,
207,MachineLearning,t5_2r3gv,2015-2-16,2015,2,16,18,2w29de,machinelearningsalon.org,The Machine Learning Salon,https://www.reddit.com/r/MachineLearning/comments/2w29de/the_machine_learning_salon/,compsens,1424079472,,0,11,False,default,,,,,
208,MachineLearning,t5_2r3gv,2015-2-16,2015,2,16,18,2w2aal,nuit-blanche.blogspot.com,A small list of highly technical reference pages.,https://www.reddit.com/r/MachineLearning/comments/2w2aal/a_small_list_of_highly_technical_reference_pages/,compsens,1424080403,,1,11,False,http://b.thumbs.redditmedia.com/Uz9e1Zb3oAly9VKE_CdWcCIh1Bw3B1upqx-iiX3UWBE.jpg,,,,,
209,MachineLearning,t5_2r3gv,2015-2-17,2015,2,17,3,2w3j6r,blog.bigml.com,Google Cloud + BigML = Easier Machine Learning!,https://www.reddit.com/r/MachineLearning/comments/2w3j6r/google_cloud_bigml_easier_machine_learning/,czuriaga,1424109837,,0,0,False,http://b.thumbs.redditmedia.com/MJM4IjtLMWFwgBiAs8S23pg71O4n0ei1lUu1yeVh4TI.jpg,,,,,
210,MachineLearning,t5_2r3gv,2015-2-17,2015,2,17,3,2w3l1x,aka.ms,Short tutorial on building Neural Nets using the Net# language,https://www.reddit.com/r/MachineLearning/comments/2w3l1x/short_tutorial_on_building_neural_nets_using_the/,MLBlogTeam,1424110662,,0,1,False,http://b.thumbs.redditmedia.com/ftHpWQAnv3s0dZOYmKtT5se6GYnxC1PtnSwz-u2EnQg.jpg,,,,,
211,MachineLearning,t5_2r3gv,2015-2-17,2015,2,17,3,2w3l23,self.MachineLearning,So I built this website and I think I need to implement machine learning...,https://www.reddit.com/r/MachineLearning/comments/2w3l23/so_i_built_this_website_and_i_think_i_need_to/,OptimisticOnanist,1424110663,"I built www.whatwouldbeysay.com (this is the proof-of-concept, the next one will have a bunch of people such as Gandhi, Confucius, and Shakespeare). 

It currently works with a simple keywords list that are associated with categories of problems--girlfriend is in the romance category, fight is in the conflict category etc. Then it chooses the quote with the most similar category tags as the problem. It works alright overall, but not nearly as well as I desire.

 So how can I make this site better? I've read around and feel that Natural Language Processing could make my interpretation much more sophisticated than just ""does the sentence have this word, does it have this one, etc."" I also feel that maybe some kind of machine learning where a user gives feedback to the returned quote could help, but I really have no clue how it would. **This website is interesting territory because it's supposed to return quotes that aren't just relevant, but provide good advice/guiding/perspective for the searched problem.**

I'm a novice programmer, but I'm very dedicated to this project as I believe it can really help people. How would you go about implementing more sophisticated algorithms? And how exactly would they work? Thanks for reading all this--hopefully someone will be able to shed some light on this issue.",20,1,False,self,,,,,
212,MachineLearning,t5_2r3gv,2015-2-17,2015,2,17,5,2w41lp,meetup.com,Come learn about AI in the health space this Thursday at IDEO (Pier 28) at 7pm,https://www.reddit.com/r/MachineLearning/comments/2w41lp/come_learn_about_ai_in_the_health_space_this/,sfai,1424118092,,2,0,False,http://b.thumbs.redditmedia.com/Bf4rkVWtNPD_rZAHEPpkdrTAZ5rVTgEdZR9XEdwlVEU.jpg,,,,,
213,MachineLearning,t5_2r3gv,2015-2-17,2015,2,17,6,2w46uc,blogs.technet.com,Net#: Introducing Microsoft's Neural Nets Library,https://www.reddit.com/r/MachineLearning/comments/2w46uc/net_introducing_microsofts_neural_nets_library/,SuperFX,1424120407,,12,39,False,http://b.thumbs.redditmedia.com/ftHpWQAnv3s0dZOYmKtT5se6GYnxC1PtnSwz-u2EnQg.jpg,,,,,
214,MachineLearning,t5_2r3gv,2015-2-17,2015,2,17,8,2w4nyy,self.MachineLearning,Applied Machine Learning - Reporting results in a publication,https://www.reddit.com/r/MachineLearning/comments/2w4nyy/applied_machine_learning_reporting_results_in_a/,Clampurloiner,1424128016,"Hi, I have a question about how to report ML results in a publication in an engineering style discipline. 

Let's say I am using a SVM model to classify data into several categories. I have several features which, intuitively, would be good predictors, but add no accuracy to the final model. How can I write that into a publication? That is, how can I justify saying ""Out of features X, Y, and Z, only X and Y offer predictive value"", but in a statistically literate fashion?

Is it enough to report the accuracy of the model on a validation set? 
Thanks!",2,2,False,self,,,,,
215,MachineLearning,t5_2r3gv,2015-2-17,2015,2,17,8,2w4p81,forbes.com,How Does NASA Use Machine Learning? - Forbes,https://www.reddit.com/r/MachineLearning/comments/2w4p81/how_does_nasa_use_machine_learning_forbes/,vikashkodati,1424128571,,1,2,False,http://b.thumbs.redditmedia.com/15Q7gl7S6PlmpxWUw3X5l1lEJmvwjZnQR-_j4wNg4pQ.jpg,,,,,
216,MachineLearning,t5_2r3gv,2015-2-17,2015,2,17,9,2w4x1h,technologyreview.com,The Face Detection Algorithm Set To Revolutionise Image Search | MIT Technology Review,https://www.reddit.com/r/MachineLearning/comments/2w4x1h/the_face_detection_algorithm_set_to_revolutionise/,vikashkodati,1424132226,,4,3,False,http://b.thumbs.redditmedia.com/BqTfp2LlUr0DkB5rapX4sNnMlNDFVj0g8kTuxxOFAEg.jpg,,,,,
217,MachineLearning,t5_2r3gv,2015-2-17,2015,2,17,10,2w566z,genopharmix.com,World's first context-controllable text summarizer,https://www.reddit.com/r/MachineLearning/comments/2w566z/worlds_first_contextcontrollable_text_summarizer/,[deleted],1424136726,,0,0,False,default,,,,,
218,MachineLearning,t5_2r3gv,2015-2-17,2015,2,17,11,2w5cjq,arxiv.org,Random Walks... (training 1000-layer networks),https://www.reddit.com/r/MachineLearning/comments/2w5cjq/random_walks_training_1000layer_networks/,[deleted],1424139849,,15,10,False,default,,,,,
219,MachineLearning,t5_2r3gv,2015-2-17,2015,2,17,17,2w6bfl,self.MachineLearning,Ask ML: has anyone tried to reproduce ADASECANT?,https://www.reddit.com/r/MachineLearning/comments/2w6bfl/ask_ml_has_anyone_tried_to_reproduce_adasecant/,[deleted],1424161818,"For those who missed the earlier discussion, [ADASECANT](http://arxiv.org/abs/1412.7419) is an adaptive stochastic gradient method, *largely* free of hyperparameters. It appears to beat RMSprop and other methods by a **factor of 30+** on a 16-layer network (Figure 1b), which I find impressive.

However, my implementation of it ~~diverges~~ *converges very slowly* even on the simplest of problems: minimizing `f(x) = x^2` with or without added noise. 

I implemented the pseudocode as I understood it, except I added the `epsilon` as per the author's suggestion, and I also added a warm-up period for sanity, so the first 10 steps are plain SGD.

~~The algorithm diverges within 100 steps.~~ Has anyone else tried this? Am I misunderstanding something?

    #include &lt;iostream&gt;
    #include &lt;cmath&gt;
    #include &lt;cstdlib&gt;
    
    int warm_up = 10;
    double eps = 1e-8;
    double tau_init = 2.2;
    double sq(double x) { return x*x; }
    void aver(double&amp; a, double x, double tau) { a = a * (1 - 1/tau) + x / tau; }
    
    double gradient(double x) { return 2*x /* + double(std::rand()) / RAND_MAX - 0.5 */ ; }
    
    void adasecant(double x, int t_max)
    {
        double gamma_numer = 0, gamma_denom = 0, g_aver = 0, g_sq_aver = 0, g_prev = 0, tau = tau_init, 
               alpha_aver = 0, alpha_sq_aver = 0, alpha_delta_aver = 0, delta_sq_aver = 0, delta_aver = 0, delta = 0;
    
        for(int t = 0; t &lt; t_max; ++t) {
            double g = gradient(x);

            double gamma = 0;
            if(t &gt;= warm_up)
                gamma = gamma_numer / (gamma_denom + eps);
            double g_wave = (g + gamma * g_aver) / (1 + gamma);
            double alpha = g - g_prev;
    
            if(sq(g - g_aver) &gt; 4 * (g_sq_aver - sq(g_aver)) ||
               sq(alpha - alpha_aver) &gt; 4 * (alpha_sq_aver - sq(alpha_aver)))
            {
                tau = tau_init;
            }
    
            aver(g_aver, g, tau);
            aver(gamma_numer, (g - g_prev) * (g - g_aver), tau);
            aver(gamma_denom, (g - g_aver) * (g_prev - g_aver), tau);
            aver(g_sq_aver, sq(g), tau);
            aver(alpha_aver, alpha, tau);
            aver(alpha_sq_aver, sq(alpha), tau);
            aver(alpha_delta_aver, alpha * delta, tau);
            aver(delta_sq_aver, sq(delta), tau);
            aver(delta_aver, delta, tau);
    
            double eta = 1e-3; // for warm-up
            if(t &gt;= warm_up)
                eta = std::sqrt(delta_sq_aver / (alpha_sq_aver + eps)) - alpha_delta_aver / (alpha_sq_aver + eps);
    
            tau = (1 - sq(delta_aver) / (delta_sq_aver + eps)) * tau + 1;
    
            delta = -eta * g_wave;
    
            x += delta;
    
            g_prev = g;

            std::cout &lt;&lt; t &lt;&lt; ' ' &lt;&lt; tau &lt;&lt; ' ' &lt;&lt; gamma &lt;&lt; ' ' &lt;&lt; eta &lt;&lt; ' ' &lt;&lt; x &lt;&lt; '\n';
        }
    }
    
    int main() { adasecant(10, 10000); }

**Edit 1:** Changed the sign of `delta` (now different from the paper). The original had

    delta = eta * g_wave;
    x -= delta;

This seems to have stopped the divergence. Now, after about 6000 steps, `|x|` reaches 1e-6. (SGD would do **much better**, as long as the learning rate is between 0.01 and 0.99) With the noise on, |x| asymptotes at 0.026. This is definitely an improvement, but is this now implemented as intended?

**Edit 2:** The order in which the averages are calculated is probably important, unless `tau` is quite big, but we know it's not always big, because it's meant to be reset to `2.2` sometimes (why not `2`?). However, this order is not specified.

**Edit 3:** `epsilon = 1e-5` improves things, but it's starting to look like a hyperparameter",19,19,False,self,,,,,
220,MachineLearning,t5_2r3gv,2015-2-17,2015,2,17,18,2w6exm,self.MachineLearning,Sentence Labelling in Torch7,https://www.reddit.com/r/MachineLearning/comments/2w6exm/sentence_labelling_in_torch7/,DX89B,1424165190,"Hi everyone,
I'm implementing a neural network to do some task for an NLP pipeline (NER, POS tagging, Chunking), Starting from the work of Collobert and Weston i was able to replicate part of their system and even improve it to some extend but i'm struggling in one part the sentence level log likelihood  using the viterbi algorithm (for now i'm working with word level log likelihood). I don't understand how to implement it in torch7, have you some suggestion on how to implement it or some code of similar algorithm implemented on top of the neural network?

Thanks you.",5,2,False,self,,,,,
221,MachineLearning,t5_2r3gv,2015-2-17,2015,2,17,21,2w6op1,bbabenko.tumblr.com,Nice summary of deep learning,https://www.reddit.com/r/MachineLearning/comments/2w6op1/nice_summary_of_deep_learning/,spidey-fan,1424174803,,0,2,False,default,,,,,
222,MachineLearning,t5_2r3gv,2015-2-17,2015,2,17,21,2w6s1e,techeffigytutorials.blogspot.com,The Genetic Algorithm - Explained,https://www.reddit.com/r/MachineLearning/comments/2w6s1e/the_genetic_algorithm_explained/,Tech-Effigy,1424177744,,21,69,False,http://b.thumbs.redditmedia.com/s1Semkm-cA6oqioHfwhvfgS3aCWq5_EscPLykk4wu-U.jpg,,,,,
223,MachineLearning,t5_2r3gv,2015-2-17,2015,2,17,22,2w6t8u,tylervigen.com,[spurious correlations] How to Lie With Statistics,https://www.reddit.com/r/MachineLearning/comments/2w6t8u/spurious_correlations_how_to_lie_with_statistics/,[deleted],1424178658,,0,0,False,default,,,,,
224,MachineLearning,t5_2r3gv,2015-2-17,2015,2,17,23,2w6xqs,blog.aureusanalytics.com,Build Predictive Modelling to get big results from Big Data,https://www.reddit.com/r/MachineLearning/comments/2w6xqs/build_predictive_modelling_to_get_big_results/,[deleted],1424181808,,0,1,False,default,,,,,
225,MachineLearning,t5_2r3gv,2015-2-17,2015,2,17,23,2w6ys4,google.co.in,Build Predictive Modelling to get big results from Big Data,https://www.reddit.com/r/MachineLearning/comments/2w6ys4/build_predictive_modelling_to_get_big_results/,[deleted],1424182450,,0,0,False,default,,,,,
226,MachineLearning,t5_2r3gv,2015-2-17,2015,2,17,23,2w6zms,self.MachineLearning,Some basic questions on Cross-validation (in neural networks),https://www.reddit.com/r/MachineLearning/comments/2w6zms/some_basic_questions_on_crossvalidation_in_neural/,Emmanuel_Cant,1424183005,"1) Typically, is the gradient descent's learning rate simply fixed at a low enough number that the cost function reduces steadily, or is it necessary to learn an optimal value using cross-validation ? 

2) Similarly, when training a neural network, the initial weights have to be initialized as U(-r,r). Is the parameter 'r', i.e the variance of the uniform distribution simply picked (like [here](http://deeplearning.net/tutorial/mlp.html) ), or do you have to do cross-validation for that too ? 

More generally, how do you decide when a parameter can simply be picked to be some number, and when it should be gotten from Cross-validation  ? (within a restricted range, based on the application)

3) If I am training a three-layer network (say, Autoencoder), can I also make the number of hidden nodes a parameter to be cross-validated ? 

4) Finally, suppose, I am cross-validating on learning rate and #hidden-nodes, is it necessary to use a grid-search, or can I search over values for each separately since they dont seem very closely tied intuitively.

Thanks for the answers. Sorry if the questions are a bit basic.

Edit - Thanks for the answers ! They were pretty helpful !
",8,2,False,self,,,,,
227,MachineLearning,t5_2r3gv,2015-2-17,2015,2,17,23,2w72go,kdnuggets.com,"Data Mining finds JASBUG, a Critical Security Vulnerability",https://www.reddit.com/r/MachineLearning/comments/2w72go/data_mining_finds_jasbug_a_critical_security/,kdnuggets,1424184572,,0,3,False,http://b.thumbs.redditmedia.com/mxFfYKxwyUpKtb2dgNerQfdwrUX6JmQjMVs188jTPvc.jpg,,,,,
228,MachineLearning,t5_2r3gv,2015-2-18,2015,2,18,0,2w78kn,arxiv.org,Unsupervised Learning of Video Representations using LSTMs,https://www.reddit.com/r/MachineLearning/comments/2w78kn/unsupervised_learning_of_video_representations/,clbam8,1424187734,,2,17,False,default,,,,,
229,MachineLearning,t5_2r3gv,2015-2-18,2015,2,18,1,2w7bmx,github.com,FunkyYak: autodiff raw numpy+Python code,https://www.reddit.com/r/MachineLearning/comments/2w7bmx/funkyyak_autodiff_raw_numpypython_code/,rantana,1424189248,,6,4,False,http://b.thumbs.redditmedia.com/B3YziAxspPOCJzkagpbh23mLE6FZgKjGsVEcw9csh9c.jpg,,,,,
230,MachineLearning,t5_2r3gv,2015-2-18,2015,2,18,2,2w7itz,arxiv.org,Towards Building Deep Networks with Bayesian Factor Graphs,https://www.reddit.com/r/MachineLearning/comments/2w7itz/towards_building_deep_networks_with_bayesian/,clbam8,1424192455,,0,5,False,default,,,,,
231,MachineLearning,t5_2r3gv,2015-2-18,2015,2,18,2,2w7n8e,jotflow.com,Working with UCI's ML Datasets (Pure Python),https://www.reddit.com/r/MachineLearning/comments/2w7n8e/working_with_ucis_ml_datasets_pure_python/,rogerkingpin,1424194315,,2,0,False,http://b.thumbs.redditmedia.com/jsnjoPPdwQx7H6si_L7SnYTDyJW8D7Fwv7jjqaf1rwo.jpg,,,,,
232,MachineLearning,t5_2r3gv,2015-2-18,2015,2,18,2,2w7qe9,aka.ms,"Scale your machine learning to TB of data with Dracula, aka ""Learning with Counts""",https://www.reddit.com/r/MachineLearning/comments/2w7qe9/scale_your_machine_learning_to_tb_of_data_with/,MLBlogTeam,1424195688,,0,1,False,default,,,,,
233,MachineLearning,t5_2r3gv,2015-2-18,2015,2,18,5,2w8eau,andyljones.tumblr.com,Why word2vec works,https://www.reddit.com/r/MachineLearning/comments/2w8eau/why_word2vec_works/,bluecoffee,1424205979,,3,16,False,http://b.thumbs.redditmedia.com/sGFevTdH-cqwIPu3brviaUKCJ9GnVjadbi-2CEgMY4Y.jpg,,,,,
234,MachineLearning,t5_2r3gv,2015-2-18,2015,2,18,7,2w8sih,self.MachineLearning,Back-propagation output layer error confusion -- wondering if anyone can clear up this quick question?,https://www.reddit.com/r/MachineLearning/comments/2w8sih/backpropagation_output_layer_error_confusion/,zZJollyGreenZz,1424212148,"Looking at the back-propagation documentation on the UFLDL web page,
http://ufldl.stanford.edu/wiki/index.php/Backpropagation_Algorithm

Step 1 is to perform the feed forward passes.
Step 2 is setting the errors for the output nodes.

The equation listed for Step 2 shows to compute the (yi-ai)*f'(zi)

Step 2 makes sense to me, but other documentation I have read seems to only use (yi-ai) for the output layer errors.

Does anyone know why the ""f'(zi)"" term is dropped?

Specifically, in Andrew Ng's coursera class notes for Lecture 9, the term looks to be dropped.  See slide 7 from this PDF
http://dirlt.com/images/ml-class-nn-learning.pdf",2,0,False,self,,,,,
235,MachineLearning,t5_2r3gv,2015-2-18,2015,2,18,8,2w90dk,arxiv-web3.library.cornell.edu,"""DRAW: A Recurrent Neural Network For Image Generation"" from DeepMind",https://www.reddit.com/r/MachineLearning/comments/2w90dk/draw_a_recurrent_neural_network_for_image/,vkhuc,1424215757,,17,20,False,default,,,,,
236,MachineLearning,t5_2r3gv,2015-2-18,2015,2,18,8,2w9183,youtube.com,Introduction to Deep Learning with Python,https://www.reddit.com/r/MachineLearning/comments/2w9183/introduction_to_deep_learning_with_python/,madisonmay,1424216135,,2,74,False,http://b.thumbs.redditmedia.com/bfm_1ltiSZNiDaQWKszAXHjVQoKV0aPeCWOvvE8fcps.jpg,,,,,
237,MachineLearning,t5_2r3gv,2015-2-18,2015,2,18,20,2waugw,self.MachineLearning,1 smartphone = 1 neuron,https://www.reddit.com/r/MachineLearning/comments/2waugw/1_smartphone_1_neuron/,gabriel1983,1424257314,"Do you know of any distributed neural network apps implementing a neuron on each smartphone, and connecting them over the Internet?

If no, what do you think about the idea?

If you like it, how can we make this happen?",13,0,False,self,,,,,
238,MachineLearning,t5_2r3gv,2015-2-18,2015,2,18,20,2wax2i,technologyreview.com,The Face Detection Algorithm Set to Revolutionize Image Search,https://www.reddit.com/r/MachineLearning/comments/2wax2i/the_face_detection_algorithm_set_to_revolutionize/,cavedave,1424259745,,1,1,False,http://b.thumbs.redditmedia.com/BqTfp2LlUr0DkB5rapX4sNnMlNDFVj0g8kTuxxOFAEg.jpg,,,,,
239,MachineLearning,t5_2r3gv,2015-2-18,2015,2,18,23,2wb8y0,self.MachineLearning,How to calculate Kullback-Leibner divergence when both distribution P and Q contain zero-probable elements?,https://www.reddit.com/r/MachineLearning/comments/2wb8y0/how_to_calculate_kullbackleibner_divergence_when/,wodenokoto,1424268816,"So I'm trying to calculate the Kullback-Leibner divergence between two texts, p and q with probability distributions P and Q. I have calculated a probability distribution of each character in each text.

p='abcdefghijklmw'
q='abcdefghijklmz'

However, p contains the letter 'w' which is not in use in q. Meanwhile q contains the letter 'z' which is not in use in p. So for p, I have set the relative frequency of P('z')=0 and Q('w')=0.

Now, when I calculate KL(P||Q) = P* log(P/Q) I end up dividing by zero. I can't find anywhere in the literature that deals with this. Measures has been made to ensure that KL works when P contains zero probabilities. I have tested this with Python's scipy.stats.entropy function, but it fails.

I find it weird that P is expected to contain zero probabilities, but not Q.",6,2,False,self,,,,,
240,MachineLearning,t5_2r3gv,2015-2-18,2015,2,18,23,2wb9ro,youtube.com,Text Analysis using Recurrent Neural Networks,https://www.reddit.com/r/MachineLearning/comments/2wb9ro/text_analysis_using_recurrent_neural_networks/,iori42,1424269288,,3,17,False,http://b.thumbs.redditmedia.com/HoqtdlJ7AcL3QkzV1HUARWNut3kdHqwrKjtaJz8jtvU.jpg,,,,,
241,MachineLearning,t5_2r3gv,2015-2-19,2015,2,19,1,2wbma9,markallenthornton.com,What interests Reddit? A network analysis of 84M comments by 200K users,https://www.reddit.com/r/MachineLearning/comments/2wbma9/what_interests_reddit_a_network_analysis_of_84m/,alexcasalboni,1424275784,,8,103,False,http://a.thumbs.redditmedia.com/yA-7YVH56ewYizpcjrQhFKP8ApGk_0Hiub00rKRoXi8.jpg,,,,,
242,MachineLearning,t5_2r3gv,2015-2-19,2015,2,19,1,2wbnd8,blog.adammenges.com,Sentiment Analysis Over My Personal Email Corpus,https://www.reddit.com/r/MachineLearning/comments/2wbnd8/sentiment_analysis_over_my_personal_email_corpus/,therealadammenges,1424276309,,4,3,False,default,,,,,
243,MachineLearning,t5_2r3gv,2015-2-19,2015,2,19,1,2wboqq,aka.ms,"We announced the general availability of Azure ML at Strata+Hadoop World this morning. New features: Python support, Net#, ""Big Learning"" with counts, community-based sharing on ML experiments and more",https://www.reddit.com/r/MachineLearning/comments/2wboqq/we_announced_the_general_availability_of_azure_ml/,[deleted],1424276938,,0,1,False,default,,,,,
244,MachineLearning,t5_2r3gv,2015-2-19,2015,2,19,1,2wbp09,aka.ms,"We announced the general availability of Azure ML at Strata+Hadoop World this morning. New features: Python support, Net#, ""Big Learning"" with counts, community-based sharing of ML experiments and more",https://www.reddit.com/r/MachineLearning/comments/2wbp09/we_announced_the_general_availability_of_azure_ml/,MLBlogTeam,1424277051,,0,2,False,http://b.thumbs.redditmedia.com/ftHpWQAnv3s0dZOYmKtT5se6GYnxC1PtnSwz-u2EnQg.jpg,,,,,
245,MachineLearning,t5_2r3gv,2015-2-19,2015,2,19,2,2wbvjh,blog.bigml.com,Filling the Blanks in Your Google Sheets with Machine Learning,https://www.reddit.com/r/MachineLearning/comments/2wbvjh/filling_the_blanks_in_your_google_sheets_with/,czuriaga,1424279958,,0,0,False,http://b.thumbs.redditmedia.com/l5UUIKxNFhgyTnbUCeODOBh24FCgTCwJkzrsiCXdNhM.jpg,,,,,
246,MachineLearning,t5_2r3gv,2015-2-19,2015,2,19,3,2wc48i,self.MachineLearning,[Question] What does joint sample state x1 from the multivariate distribution p(x) mean?,https://www.reddit.com/r/MachineLearning/comments/2wc48i/question_what_does_joint_sample_state_x1_from_the/,bluedunnock,1424283776,"I am studying sampling techniques used in graphical models from the book ""Bayesian Reasoning and Machine Learning"" by David Barber.( In the section 27.3 Gibbs sampling, I could not understand the following text

Assume we have a joint sample state x1 from the multivariate distribution p(x). 

If the variables are discrete is it correct to consider x1 as a single entry in the joint probability distribution table? Or What does joint sample state mean in case if all the attributes are continuous?

",2,0,False,self,,,,,
247,MachineLearning,t5_2r3gv,2015-2-19,2015,2,19,3,2wc8q0,self.MachineLearning,Machine Learning Applied to Multiple Choice Questions,https://www.reddit.com/r/MachineLearning/comments/2wc8q0/machine_learning_applied_to_multiple_choice/,Kendama_Llama,1424285785,I am currently taking an online physics course and was wondering how well a machine learning algorithm would do in guessing the correct answer to multiple choice questions. There definitely seem to be trends in the answers that are correct (longer answers and median values seem to have a higher likelihood of being correct). For someone new to programming how easy would it be to implement something like this? I could imagine having something setup where I feed the algorithm past questions and correct answers and then feed it questions for which I do not know the answer and see what it comes up with. What do you think? How could I do something like this? Thanks!,2,0,False,self,,,,,
248,MachineLearning,t5_2r3gv,2015-2-19,2015,2,19,4,2wca01,cs.toronto.edu,"Intro to Neural Networks, taught by creator of Metacademy",https://www.reddit.com/r/MachineLearning/comments/2wca01/intro_to_neural_networks_taught_by_creator_of/,gwulfs,1424286318,,1,2,False,default,,,,,
249,MachineLearning,t5_2r3gv,2015-2-19,2015,2,19,6,2wcrwh,github.com,Dato Open Sources Core of GraphLab ML Library,https://www.reddit.com/r/MachineLearning/comments/2wcrwh/dato_open_sources_core_of_graphlab_ml_library/,carvedata,1424293941,,3,6,False,http://a.thumbs.redditmedia.com/vy80ZkJtp0OkBrm-zLv1yV_ek1M-hlE5gKi_cXxxtA0.jpg,,,,,
250,MachineLearning,t5_2r3gv,2015-2-19,2015,2,19,6,2wcsn3,defenseone.com,"Mathematically speaking, a robot uprising may be inevitable.",https://www.reddit.com/r/MachineLearning/comments/2wcsn3/mathematically_speaking_a_robot_uprising_may_be/,karlid,1424294267,,2,0,False,http://b.thumbs.redditmedia.com/aKpe9PXyFuJ90FuGMCxB_WhlN9cgURosUt4Mtd9mXgg.jpg,,,,,
251,MachineLearning,t5_2r3gv,2015-2-19,2015,2,19,6,2wcwem,devblogs.nvidia.com,John Canny on BIDMach Machine Learning: One GPU faster than 100s of Spark / Graphlab cluster nodes,https://www.reddit.com/r/MachineLearning/comments/2wcwem/john_canny_on_bidmach_machine_learning_one_gpu/,harrism,1424295885,,0,4,False,http://a.thumbs.redditmedia.com/0PImn2oUXV0XENvqKjPHB6ONNw1LJhncT5YkSYLoiW8.jpg,,,,,
252,MachineLearning,t5_2r3gv,2015-2-19,2015,2,19,7,2wd5zm,spectrum.ieee.org,Facebook AI Director Yann LeCun on His Quest to Unleash Deep Learning and Make Machines Smarter,https://www.reddit.com/r/MachineLearning/comments/2wd5zm/facebook_ai_director_yann_lecun_on_his_quest_to/,clbam8,1424300051,,3,10,False,default,,,,,
253,MachineLearning,t5_2r3gv,2015-2-19,2015,2,19,10,2wdnky,self.MachineLearning,Designing a machine learning tutorial (x-post DataScience),https://www.reddit.com/r/MachineLearning/comments/2wdnky/designing_a_machine_learning_tutorial_xpost/,mizay7,1424308361,"I am a grad student in a non-cs field but I do have a solid grounding in econometrics, operations research, and statistical coding (mostly in STATA and R, but some Python as well).


I am designing a tutorial (one-on-one course with a researcher) to gain a better understanding of machine learning techniques which i can then try to apply to my dissertation topic.


A portion of my dissertation will be focused on mining community generated data (likely twitter) to try and recreate behavioral indicators compiled by traditional survey based tools. For example: Does the rate at which some subset of people tweet about going to the gym match the data on exercise levels that we gather about that subset in a representative sample survey?


I am not trying tailor this tutorial specifically to the dissertation but rather to ensure that I have a solid grounding in core methods which i can then explore more deeply when working with my dissertation data.


I see trees/random forests, nearest neighbor, neural networks, and naive bayes as staples. What would be your suggestions of core methods to learn?",1,0,False,self,,,,,
254,MachineLearning,t5_2r3gv,2015-2-19,2015,2,19,13,2wead2,slideshare.net,An Introduction to Supervised Machine Learning and Pattern Classification: The Big Picture (Slides),https://www.reddit.com/r/MachineLearning/comments/2wead2/an_introduction_to_supervised_machine_learning/,[deleted],1424320110,,0,1,False,default,,,,,
255,MachineLearning,t5_2r3gv,2015-2-19,2015,2,19,13,2weal7,slideshare.net,An Introduction to Supervised Machine Learning and Pattern Classification (slides),https://www.reddit.com/r/MachineLearning/comments/2weal7/an_introduction_to_supervised_machine_learning/,[deleted],1424320248,,0,1,False,default,,,,,
256,MachineLearning,t5_2r3gv,2015-2-19,2015,2,19,14,2weihq,forklifttraining.blog.com,Penrith Forklift Training,https://www.reddit.com/r/MachineLearning/comments/2weihq/penrith_forklift_training/,aus_andr,1424325017,,0,1,False,default,,,,,
257,MachineLearning,t5_2r3gv,2015-2-19,2015,2,19,15,2weka3,learnmachinetraining.blogspot.com.au,Machine Tarining,https://www.reddit.com/r/MachineLearning/comments/2weka3/machine_tarining/,aus_andr,1424326189,,0,1,False,default,,,,,
258,MachineLearning,t5_2r3gv,2015-2-19,2015,2,19,15,2welld,shakthydoss.com,ROC-Receiver Operating Characteristic for selecting best classification model,https://www.reddit.com/r/MachineLearning/comments/2welld/rocreceiver_operating_characteristic_for/,shakthydoss,1424327112,,0,0,False,http://b.thumbs.redditmedia.com/UNRuA6YZrZNRL5TGL_Jn2w-QZA7qChw9dsxQ8n76xjg.jpg,,,,,
259,MachineLearning,t5_2r3gv,2015-2-19,2015,2,19,15,2wenkh,heisenberg.ziraffe.in,Heisenberg 0.5 - An AI powered engine to evaluate your startup idea.,https://www.reddit.com/r/MachineLearning/comments/2wenkh/heisenberg_05_an_ai_powered_engine_to_evaluate/,[deleted],1424328561,,20,7,False,default,,,,,
260,MachineLearning,t5_2r3gv,2015-2-19,2015,2,19,17,2wetxj,arxiv.org,Learning Stochastic Recurrent Networks (ICLR 2015),https://www.reddit.com/r/MachineLearning/comments/2wetxj/learning_stochastic_recurrent_networks_iclr_2015/,[deleted],1424333987,,15,16,False,default,,,,,
261,MachineLearning,t5_2r3gv,2015-2-19,2015,2,19,18,2wexxj,self.MachineLearning,Categorizing text based off 1 or 2 samples,https://www.reddit.com/r/MachineLearning/comments/2wexxj/categorizing_text_based_off_1_or_2_samples/,[deleted],1424338191,"What is a good algorithm for multi-class classification of high-dimensional data like text using only a very few training dataset?

Most algorithms assume training is done on hundreds or thousands of training samples. But I'm under the strict constraint of 1 or 2 samples to train a classifier. What do you recommend?",3,0,False,default,,,,,
262,MachineLearning,t5_2r3gv,2015-2-19,2015,2,19,19,2wf1m7,moodpatrol.com,Sentiment Analysis wants to make its debut in consumer mobile apps,https://www.reddit.com/r/MachineLearning/comments/2wf1m7/sentiment_analysis_wants_to_make_its_debut_in/,carlos_argueta,1424341847,,13,0,False,http://b.thumbs.redditmedia.com/XK6rEQLSO2nZWLu2aBih2reR40gTKeRWgriQJZboKcw.jpg,,,,,
263,MachineLearning,t5_2r3gv,2015-2-19,2015,2,19,23,2wfiei,sci2s.ugr.es,"#ThrowbackThursday: 1961, First use of naive Bayes for text classification. On freaking punch cards!",https://www.reddit.com/r/MachineLearning/comments/2wfiei/throwbackthursday_1961_first_use_of_naive_bayes/,botman55,1424355517,,0,1,False,default,,,,,
264,MachineLearning,t5_2r3gv,2015-2-20,2015,2,20,2,2wg664,fastcompany.com,"""How To Save A Hacked Power Grid? Machine Learning""",https://www.reddit.com/r/MachineLearning/comments/2wg664/how_to_save_a_hacked_power_grid_machine_learning/,reworksophie,1424367014,,0,0,False,http://b.thumbs.redditmedia.com/DdZpFP8BVhLta0SjQdEMnw0kM6FhA8dhrnxsZTjmE2I.jpg,,,,,
265,MachineLearning,t5_2r3gv,2015-2-20,2015,2,20,3,2wgawc,self.MachineLearning,"What are some ML techniques that are being applied to data from sensor networks, IoT?",https://www.reddit.com/r/MachineLearning/comments/2wgawc/what_are_some_ml_techniques_that_are_being/,pippo9,1424369065,,2,1,False,self,,,,,
266,MachineLearning,t5_2r3gv,2015-2-20,2015,2,20,3,2wgcz3,self.MachineLearning,"As interest was previously expressed for the Boston edition of the RE.WORK Deep Learning Summit, some info for you all:",https://www.reddit.com/r/MachineLearning/comments/2wgcz3/as_interest_was_previously_expressed_for_the/,reworksophie,1424369971,"The Super Early Bird tickets will end tomorrow! These tickets save you $670 off the Standard ticket price. If you are a student or startup, there are discounted tickets available for you also, see all prices on the event page under 'Registration'. Hope to see some of you there! Go the event page here: http://www.re-work.co/events/deep-learning-boston-2015",0,0,False,self,,,,,
267,MachineLearning,t5_2r3gv,2015-2-20,2015,2,20,4,2wgojo,youtube.com,Automated Image Captioning - Andrej Karpathy,https://www.reddit.com/r/MachineLearning/comments/2wgojo/automated_image_captioning_andrej_karpathy/,gwulfs,1424374895,,4,35,False,http://b.thumbs.redditmedia.com/bSYUUcdgq57aYVLu0PgmQvHvRuGPxda1D-_S6svmzPI.jpg,,,,,
268,MachineLearning,t5_2r3gv,2015-2-20,2015,2,20,10,2why6i,youtu.be,Andy Kitchen - ML and AI Meetup (Melbourne) Video,https://www.reddit.com/r/MachineLearning/comments/2why6i/andy_kitchen_ml_and_ai_meetup_melbourne_video/,sordina,1424395570,,0,0,False,http://b.thumbs.redditmedia.com/AntmA68_YkESj6Uh5LWDIK_kg7Bi9DcReGNvku_-uMo.jpg,,,,,
269,MachineLearning,t5_2r3gv,2015-2-20,2015,2,20,11,2wi93h,self.MachineLearning,AskML: Where do you discuss new arXiv papers?,https://www.reddit.com/r/MachineLearning/comments/2wi93h/askml_where_do_you_discuss_new_arxiv_papers/,bkkb,1424401110,"I've seen some very interesting arXiv papers lately, particularly papers in Artificial Intelligence (cs.AI), Computation and Language (cs.CL), and Machine Learning (stat.ML).  Where does discussion normally take place about these papers? ",7,7,False,self,,,,,
270,MachineLearning,t5_2r3gv,2015-2-20,2015,2,20,12,2wiazu,datasciencecentral.com,Do all credit card accounts eventually die from fraud?,https://www.reddit.com/r/MachineLearning/comments/2wiazu/do_all_credit_card_accounts_eventually_die_from/,urinec,1424402026,,1,0,False,http://a.thumbs.redditmedia.com/okoO9wQtEZifXLkDQap9KZOOTl9sU-0IdG6BQL70gz0.jpg,,,,,
271,MachineLearning,t5_2r3gv,2015-2-20,2015,2,20,12,2wieol,irjejune.wordpress.com,Navigating the Machine Learning job market,https://www.reddit.com/r/MachineLearning/comments/2wieol/navigating_the_machine_learning_job_market/,wonkypedia,1424404013,,18,16,False,http://b.thumbs.redditmedia.com/6E0YXUncXhFZE-HgC8IH7COjePvS20nr4P30WrcpyiU.jpg,,,,,
272,MachineLearning,t5_2r3gv,2015-2-20,2015,2,20,19,2wj96c,blogs.nvidia.com,Using Deep Learning for Toxicology Prediction,https://www.reddit.com/r/MachineLearning/comments/2wj96c/using_deep_learning_for_toxicology_prediction/,CaseOfTuesday,1424427202,,0,4,False,http://b.thumbs.redditmedia.com/NS68n8eFTg3cF9LTF-Rf9MGSCfMANYDxuU74SnE2uyI.jpg,,,,,
273,MachineLearning,t5_2r3gv,2015-2-20,2015,2,20,19,2wj9tb,demo.soulhackerslabs.com,"Beyond polarity: a multi-emotions, bi-lingual sentiment analysis demo",https://www.reddit.com/r/MachineLearning/comments/2wj9tb/beyond_polarity_a_multiemotions_bilingual/,carlos_argueta,1424427869,,2,0,False,default,,,,,
274,MachineLearning,t5_2r3gv,2015-2-20,2015,2,20,20,2wjdlw,self.MachineLearning,What would be your approach to a large scale machine learning problem with the single laptop? [See Details],https://www.reddit.com/r/MachineLearning/comments/2wjdlw/what_would_be_your_approach_to_a_large_scale/,erogol,1424431598,"This was simply a interview question that I faced. The setting is following. We have billions of rows (instances) and thousands of columns (features). There are N number of classes which is smaller than both the columns number and the row number. You have a simple up to date laptop with reasonable rig.  In such a setting what would be you approach and workflow to the final deployment model?

I don't share my approach initially so to not cause any bias and I want to see  and discuss what other people think and what the alternative approaches are. At the end, I 'll share my humble solution too.",0,1,False,default,,,,,
275,MachineLearning,t5_2r3gv,2015-2-20,2015,2,20,20,2wjdog,self.MachineLearning,Dependency graphy for the chapters of Machine Learning by Kevin Murphy,https://www.reddit.com/r/MachineLearning/comments/2wjdog/dependency_graphy_for_the_chapters_of_machine/,oaaaa,1424431656,"This is a comprehensive book. 

I want to understand a later chapter, but I do not have the time to read the whole book yet. 

Assuming I want to understand a later chapter like chapter 20, what chapters do I need to read before it, obviously without reading all previous 19?",2,2,False,self,,,,,
276,MachineLearning,t5_2r3gv,2015-2-20,2015,2,20,20,2wjfbb,arxiv.org,Scalable Bayesian Optimization Using Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/2wjfbb/scalable_bayesian_optimization_using_deep_neural/,alecradford,1424433338,,19,36,False,default,,,,,
277,MachineLearning,t5_2r3gv,2015-2-20,2015,2,20,22,2wjmxa,self.MachineLearning,news summary using semantic orientation,https://www.reddit.com/r/MachineLearning/comments/2wjmxa/news_summary_using_semantic_orientation/,new2machinelearning,1424439268,"hey folks! i have been looking for sources on news summarization but keep running into garbage (sorry if its a little strong) via google. So i tried out the following

- collected a bunch of articles

- used a lexicon (which i have built over time) of positive and negative words

- used this along with POS tagging to figure out the semantic orientation of every sentence

- use the sentence with the strongest SO in the article as the article summary 

...what i have read so far tells me of a lot of complicated stuff in generating a human readable summary, but dont you folks think humans are smart enough to figure out the gist of the article using one sentence ? why not give them the strongest there is ? isn't this similar (a little?) to what google does if i ask ""how does h1n1 spread"" ? please let me know if you have come across some out of the box papers on doing the same or even your thoughts .. if you are in my city (bangalore) you ll be treated to free beer as well :)",7,1,False,self,,,,,
278,MachineLearning,t5_2r3gv,2015-2-20,2015,2,20,23,2wju04,blog.thehumangeo.com,(Machine) Learning About Love: Who will Leave The Bachelor next?,https://www.reddit.com/r/MachineLearning/comments/2wju04/machine_learning_about_love_who_will_leave_the/,WStHappenings,1424443516,,0,4,False,http://b.thumbs.redditmedia.com/0AS-K4IyH5sLMYr2jNFN3nMrg87wQgpoTHRsNndOx6E.jpg,,,,,
279,MachineLearning,t5_2r3gv,2015-2-21,2015,2,21,0,2wk0ob,jotflow.com,Gaussian Naive Bayes,https://www.reddit.com/r/MachineLearning/comments/2wk0ob/gaussian_naive_bayes/,rogerkingpin,1424446952,,0,1,False,default,,,,,
280,MachineLearning,t5_2r3gv,2015-2-21,2015,2,21,0,2wk2q9,self.MachineLearning,What is the minimum data required for deep learning?,https://www.reddit.com/r/MachineLearning/comments/2wk2q9/what_is_the_minimum_data_required_for_deep/,geekybarnstar,1424447966,"I have been hearing a lot about deep learning and I work in neural networks. I would just like to test it on the side for fun. But is it only useful for really large datasets that the likes of Microsoft have access to? What about a dataset that has 100, 000 events of a climate event where we are interested in predicting into the future using  data from the past. If not deep learning, what other kinds of techniques have become popular in recent years. Would love some ideas.",9,1,False,self,,,,,
281,MachineLearning,t5_2r3gv,2015-2-21,2015,2,21,1,2wk30k,github.com,"CN24: complete semantic segmentation framework using fully convolutional networks, supports OpenCL, MKL, AMCL...",https://www.reddit.com/r/MachineLearning/comments/2wk30k/cn24_complete_semantic_segmentation_framework/,clrokr,1424448088,,0,5,False,http://b.thumbs.redditmedia.com/powgQq15J96BJ0_vlJTYrwK_9OLrYkqVu7KYRCf6LnQ.jpg,,,,,
282,MachineLearning,t5_2r3gv,2015-2-21,2015,2,21,1,2wk3bb,thoughtly.co,Prototype ML/NLP Code Tutorial Series Lesson 3: Bayes Theorem,https://www.reddit.com/r/MachineLearning/comments/2wk3bb/prototype_mlnlp_code_tutorial_series_lesson_3/,clbam8,1424448222,,0,17,False,http://a.thumbs.redditmedia.com/UIYIfW8-Xvfs47500-G8d4BuKATrGZqmpe1cLB3Ig-8.jpg,,,,,
283,MachineLearning,t5_2r3gv,2015-2-21,2015,2,21,1,2wk8yi,self.MachineLearning,[Discuss] The elephant in the room of machine learning research,https://www.reddit.com/r/MachineLearning/comments/2wk8yi/discuss_the_elephant_in_the_room_of_machine/,rantana,1424450796,"I thought I would use the momentum of my [previous post](http://www.reddit.com/r/MachineLearning/comments/2wjfbb/scalable_bayesian_optimization_using_deep_neural/corfd7z) (quoted below) to create a discussion. /r/MachineLearning has a good mix of researchers and practitioners, so  this might be a good place to try and resolve this issue. 

&gt; I like these hyperparameter optimization papers mainly because it exposes something endemic to machine learning research. The obsession with what I call the 'marginally state-of-the-art'. It's become particularly bad with deep learning because of all the hyperparameters available to tune.

&gt; As a practitioner, this is extremely frustrating. Papers pushing complicated augmentations to standard methods keep using the word 'outperform' for results that OBVIOUSLY lie within the variance caused by the hyperparameters. This is both dishonest and a disservice to the larger machine learning community. And it's getting worse if you look at the neural network papers submitted to NIPS, ICML, ICLR. If you look at the reviews of ICLR, at best this issue is being completely ignored and at worst this sort of misleading progress is encouraged.

&gt; Do no misunderstand what I say, I believe classification performance and other measures are extremely important, but not when the increase is so marginal. Researchers should be simplifying their methods and getting competitive performance. This is where real progress happens.

Since so many researchers are guilty of it (take a look at most of the papers posted here in the past few weeks), I wanted to hear their side of the argument.",86,164,False,self,,,,,
284,MachineLearning,t5_2r3gv,2015-2-21,2015,2,21,2,2wkh42,techblog.netflix.com,The Netflix Tech Blog: RAD - Outlier Detection on Big Data,https://www.reddit.com/r/MachineLearning/comments/2wkh42/the_netflix_tech_blog_rad_outlier_detection_on/,xamdam,1424454508,,0,15,False,default,,,,,
285,MachineLearning,t5_2r3gv,2015-2-21,2015,2,21,3,2wkp5r,self.MachineLearning,Machine Learning Software Design,https://www.reddit.com/r/MachineLearning/comments/2wkp5r/machine_learning_software_design/,thingamarobert,1424458087,"Are there any useful guides or papers outlining best practices while implementing machine learning workflows? To be more clear, I put together some machine learning models I had implemented in the past into a nice little library where I can specify model and optimization parameters in configuration files, carry out grid search, re-train best models, etc. The models have identical class structure with similar interfaces with other modules of the library for optimization, parameter saving, etc. Often I find that there are several design choices I'm having to make as I progress, and I don't realize the problems with some of these until it's a bit too late to revert back and try something different. Could someone recommend any reading material that will give me a heads-up on various design considerations and best practices?

tl,dr: I want to implement my own little scikit-learn. Are there any useful guides with the help of which I can avoid common pitfalls of designing such a library?

Thanks!",3,3,False,self,,,,,
286,MachineLearning,t5_2r3gv,2015-2-21,2015,2,21,4,2wksbo,blog.yhathq.com,What is Linear Regression? A Qualitative Exploration,https://www.reddit.com/r/MachineLearning/comments/2wksbo/what_is_linear_regression_a_qualitative/,theglamp,1424459519,,0,0,False,default,,,,,
287,MachineLearning,t5_2r3gv,2015-2-21,2015,2,21,5,2wl0j6,arxiv.org,SelfieBoost: A Boosting Algorithm for Deep Learning,https://www.reddit.com/r/MachineLearning/comments/2wl0j6/selfieboost_a_boosting_algorithm_for_deep_learning/,[deleted],1424463512,,0,1,False,default,,,,,
288,MachineLearning,t5_2r3gv,2015-2-21,2015,2,21,6,2wlaot,arxiv.org,The Ladder: A Reliable Leaderboard for Machine Learning Competitions,https://www.reddit.com/r/MachineLearning/comments/2wlaot/the_ladder_a_reliable_leaderboard_for_machine/,urish,1424468457,,0,12,False,default,,,,,
289,MachineLearning,t5_2r3gv,2015-2-21,2015,2,21,11,2wm8j1,self.MachineLearning,Predicting Arrival/Departure of butterflies,https://www.reddit.com/r/MachineLearning/comments/2wm8j1/predicting_arrivaldeparture_of_butterflies/,[deleted],1424486071,"I don't have a solid background in statistics, I am double checking with you on a phenomena I am trying to study. 

we are doing a study on some very rare spices of flowers. We are putting them in different places in our farming area. We are trying to predict the time when  Butterflies are coming and when they are leaving. Butterflies are coming in specific time, they are feeding from these flowers, when butterflies come to place **x** in our farming area, they are looking for flower **Y** some of the flowers are already occupied, and some times, the whole flowers are all occupied, so they leave or go to other places looking for another flower in another place.  We collected a dataset of  Arrival/Departure of butterflies in the farming area. we want to analyze the dataset to be able to predict their next move. we have different locations (10-20 places).  


**Dataset:** 

- Arrival time

- Departure time 

- isThere noise: time when there is a noise,  usually butterflies don't come when they hear noise.

**Question:** 

We are trying to choose which model works best here. 

Some points to double check with you. SHould we divide our dataset to different cells, and analyze every location separately. 

If no, Some cells are spatially near to each others. Should we consider that. Again, which model should we use to predict if the Butterflies are coming and when they are leaving X (location based on our grid-division). we are looking for a good approach to build a predictive model to arrival-departure, and whether they would find flower x in place y occupied or no 


**Note:** For those who are wondering why we do that, it's very tedious problem to manage the presence of humans in farming areas. We don't wanna scare butterflies, it's more rewarding for us to have them come to feed from flowers (there is a deep discussion here), so we need to manage the time we should be there. 

Last thing, we are not researchers, we practionars who want to use data/tech to manage their farming industry.  I know that this is funny for some of you to see someone using ML to take care of his flowers, but this is so damn cool",1,5,False,default,,,,,
290,MachineLearning,t5_2r3gv,2015-2-21,2015,2,21,13,2wmhxu,self.MachineLearning,Pair natives to teach each other their language. Use produced data to train speech recognition algos?,https://www.reddit.com/r/MachineLearning/comments/2wmhxu/pair_natives_to_teach_each_other_their_language/,rodolfoocampo,1424491802,"I though of an app that would pair people from different parts of the world to teach each other their language, guided by prompts. If you are teaching the other one English, the app tells you to read some text in your language and then check if the listener understood what you just said with a multiple choice question, among other activities to guide mutual teaching. That way we would have many hours of data relating spoken-written words. Could that data be helpful (and sellable) to researchers, speech recognition companies?",0,1,False,self,,,,,
291,MachineLearning,t5_2r3gv,2015-2-21,2015,2,21,13,2wmkt3,learningwithdata.wordpress.com,Introduction to Bayes Theorem with Python,https://www.reddit.com/r/MachineLearning/comments/2wmkt3/introduction_to_bayes_theorem_with_python/,syrios12,1424493604,,0,3,False,http://b.thumbs.redditmedia.com/6E0YXUncXhFZE-HgC8IH7COjePvS20nr4P30WrcpyiU.jpg,,,,,
292,MachineLearning,t5_2r3gv,2015-2-21,2015,2,21,14,2wmqmb,arxiv.org,RMSProp and equilibrated adaptive learning rates for non-convex optimization,https://www.reddit.com/r/MachineLearning/comments/2wmqmb/rmsprop_and_equilibrated_adaptive_learning_rates/,mlalma,1424497491,,5,4,False,default,,,,,
293,MachineLearning,t5_2r3gv,2015-2-21,2015,2,21,15,2wmsik,class.coursera.org,Coursera Free course on Linear Algebra. Coding The Matrix: Linear Algebra Through Computer Science Applications by Philip Klein,https://www.reddit.com/r/MachineLearning/comments/2wmsik/coursera_free_course_on_linear_algebra_coding_the/,sybarite29,1424498799,,12,97,False,http://b.thumbs.redditmedia.com/k5y5hjIT7tTvN2sW1gQZp16iR8cThRBhRO2ObbZRj2o.jpg,,,,,
294,MachineLearning,t5_2r3gv,2015-2-21,2015,2,21,22,2wnkft,deeplearning4j.org,"Deeplearning4j - Open-source, distributed deep learning for the JVM",https://www.reddit.com/r/MachineLearning/comments/2wnkft/deeplearning4j_opensource_distributed_deep/,petrux,1424525990,,10,0,False,default,,,,,
295,MachineLearning,t5_2r3gv,2015-2-21,2015,2,21,23,2wno4j,self.MachineLearning,I have a vague idea for a literature review...,https://www.reddit.com/r/MachineLearning/comments/2wno4j/i_have_a_vague_idea_for_a_literature_review/,gumbel_distro,1424528803,"Hi, 

I'd like to write a literature review about my research area ( (dynamic) discrete choice models (DDCM) in econometrics) and I'm also quite interested in machine learning (both econometrics and machine learning have a lot in common actually). I was thinking about using machine learning methods to analyze journal articles about DDCM; maybe try to classify articles for example, analyze correlations between worlds (for example, cor(""DDCM"", ""structural"") etc. I'm not quite sure about the possibilities that are out there and would be grateful if you could point me to some articles that do such analyzes that I could take inspiration from and cite. Thanks!",2,0,False,self,,,,,
296,MachineLearning,t5_2r3gv,2015-2-21,2015,2,21,23,2wnoqc,twitter.com,@word2vec,https://www.reddit.com/r/MachineLearning/comments/2wnoqc/word2vec/,galapag0,1424529251,,2,0,False,default,,,,,
297,MachineLearning,t5_2r3gv,2015-2-22,2015,2,22,0,2wntuw,genopharmix.com,Word2Vec used to summarize content at medium.com,https://www.reddit.com/r/MachineLearning/comments/2wntuw/word2vec_used_to_summarize_content_at_mediumcom/,biomimic,1424532662,,1,0,False,http://b.thumbs.redditmedia.com/Ma5eYLGVWTRoOfQ1qrvUI92FjxzjAveJsRcIrknufZs.jpg,,,,,
298,MachineLearning,t5_2r3gv,2015-2-22,2015,2,22,2,2wo4wc,self.MachineLearning,Best way to choose which category a word fits in based on correlations to words already assigned to those categories?,https://www.reddit.com/r/MachineLearning/comments/2wo4wc/best_way_to_choose_which_category_a_word_fits_in/,Unum_Lupus,1424538962,"I don't have very much experience with natural language processing but I have an application that I think it would work very nicely for. I was hoping someone would be able to point me in the right direction as far as selecting the most suitable method.

Here is the problem I would like to solve. My town has a garbage collection program where everyone is required to sort their trash into one of four categories: organics, recyclable, garbage, and hazardous.  I would like to create a program that, given a word, will tell you which category of garbage it goes into.

I have some small lists (~30 items for each category) that give an idea of what items go in each category. Off the top of my head I was thinking that one possible solution would be to make a word2vec model, calculate the similarities between the example items and the input word, and then select the category that contains the best similarity. Is this solution reasonable or are there better options?",0,1,False,self,,,,,
299,MachineLearning,t5_2r3gv,2015-2-22,2015,2,22,4,2womn3,flosshub.org,Predicting the Severity of a Reported Bug (2010),https://www.reddit.com/r/MachineLearning/comments/2womn3/predicting_the_severity_of_a_reported_bug_2010/,galapag0,1424547682,,0,1,False,default,,,,,
300,MachineLearning,t5_2r3gv,2015-2-22,2015,2,22,6,2wp1lc,jotflow.com,Nearest Sphere Classification (New Algorithm),https://www.reddit.com/r/MachineLearning/comments/2wp1lc/nearest_sphere_classification_new_algorithm/,rogerkingpin,1424554620,,0,1,False,default,,,,,
301,MachineLearning,t5_2r3gv,2015-2-23,2015,2,23,3,2ws2sr,arxiv.org,Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks,https://www.reddit.com/r/MachineLearning/comments/2ws2sr/towards_aicomplete_question_answering_a_set_of/,SuperFX,1424628710,,7,25,False,default,,,,,
302,MachineLearning,t5_2r3gv,2015-2-23,2015,2,23,3,2ws3d4,gradientflow.com,Summary of Hardcore Data Science: 2015 California,https://www.reddit.com/r/MachineLearning/comments/2ws3d4/summary_of_hardcore_data_science_2015_california/,gradientflow,1424628970,,0,0,False,http://b.thumbs.redditmedia.com/6E0YXUncXhFZE-HgC8IH7COjePvS20nr4P30WrcpyiU.jpg,,,,,
303,MachineLearning,t5_2r3gv,2015-2-23,2015,2,23,5,2wsh7q,cireneikual.wordpress.com,My Attempt at Outperforming Deepmind's Atari Results - UPDATE 12,https://www.reddit.com/r/MachineLearning/comments/2wsh7q/my_attempt_at_outperforming_deepminds_atari/,CireNeikual,1424635466,,8,26,False,http://b.thumbs.redditmedia.com/KeEnwLefvnrH3FiPOhm68EFvNHzEa7ut4CG3XO4EZYM.jpg,,,,,
304,MachineLearning,t5_2r3gv,2015-2-23,2015,2,23,5,2wsior,self.MachineLearning,Splitting binary classification into smaller susbsets,https://www.reddit.com/r/MachineLearning/comments/2wsior/splitting_binary_classification_into_smaller/,apSTRK,1424636138,"If you are tying to classify animals and humans. Is it possible to approach this problem by classifying different kinds of animals (birds, fish, reptiles, mammals, ...) or even smaller subsets (dogs, cats, whales, lions, ...) Then when you try to classify a new data set, anything that did not fall into one of those classes can be considered a human.

If this is possible, are there any benefits into breaking a binary class problem into several classes (or perhaps labels)? ",8,0,False,self,,,,,
305,MachineLearning,t5_2r3gv,2015-2-23,2015,2,23,6,2wssr9,arxiv.org,Bengio et al: Towards Biologically Plausible Deep Learning,https://www.reddit.com/r/MachineLearning/comments/2wssr9/bengio_et_al_towards_biologically_plausible_deep/,downtownslim,1424640787,,9,41,False,default,,,,,
306,MachineLearning,t5_2r3gv,2015-2-23,2015,2,23,14,2wualo,google-opensource.blogspot.sg,Google open sources a MapReduce framework for C/C++,https://www.reddit.com/r/MachineLearning/comments/2wualo/google_open_sources_a_mapreduce_framework_for_cc/,chubbymaggie,1424668001,,20,73,False,http://a.thumbs.redditmedia.com/U1VbsBUKWtgTfh6gYGbfyRr2oa4c4oRy0p7u7n3NTy4.jpg,,,,,
307,MachineLearning,t5_2r3gv,2015-2-23,2015,2,23,15,2wuhkl,chronicle.com,The Believers: long profile of Hinton and history of neural nets in Chronicle of Higher Ed,https://www.reddit.com/r/MachineLearning/comments/2wuhkl/the_believers_long_profile_of_hinton_and_history/,normee,1424672315,,0,6,False,http://a.thumbs.redditmedia.com/XZvAP1L9AKML2jLp1cGgA_9GMbZ598tLg9qBS3_lZo8.jpg,,,,,
308,MachineLearning,t5_2r3gv,2015-2-23,2015,2,23,19,2wuwv3,sdtimes.com,Microsoft releases Azure Machine Learning,https://www.reddit.com/r/MachineLearning/comments/2wuwv3/microsoft_releases_azure_machine_learning/,bobbyjerdon,1424686021,,0,4,False,http://b.thumbs.redditmedia.com/QF3abJ63BI6QwN2xWShRDq9JfDfDnHQ7zmFhwvzP02w.jpg,,,,,
309,MachineLearning,t5_2r3gv,2015-2-23,2015,2,23,22,2wvb28,self.MachineLearning,Good MOOCS on Cost minization mathematics/matlab code?,https://www.reddit.com/r/MachineLearning/comments/2wvb28/good_moocs_on_cost_minization_mathematicsmatlab/,soulslicer0,1424698834,"Lagrange Multiplier, adding weights to your data, SVD, Energy functions, etc. etc.

AND with code examples on how to use the optimisation toolbox on MATLAB possibly.",0,0,False,self,,,,,
310,MachineLearning,t5_2r3gv,2015-2-24,2015,2,24,2,2ww285,arxiv.org,[1502.02506] Predicting Alzheimer's disease: a neuroimaging study with 3D convolutional neural networks,https://www.reddit.com/r/MachineLearning/comments/2ww285/150202506_predicting_alzheimers_disease_a/,mttd,1424713251,,0,2,False,default,,,,,
311,MachineLearning,t5_2r3gv,2015-2-24,2015,2,24,3,2ww5cg,youtu.be,Lively debate at a recent AI meetup worth checking out.,https://www.reddit.com/r/MachineLearning/comments/2ww5cg/lively_debate_at_a_recent_ai_meetup_worth/,sfai,1424714689,,4,1,False,http://b.thumbs.redditmedia.com/rav96HBIbxQmI4Mys9CAy38l-peHfRPnir44XbKd_vU.jpg,,,,,
312,MachineLearning,t5_2r3gv,2015-2-24,2015,2,24,3,2ww6fe,arxiv.org,ICLR2015: Learning Longer Memory in RNNs (without LSTM),https://www.reddit.com/r/MachineLearning/comments/2ww6fe/iclr2015_learning_longer_memory_in_rnns_without/,[deleted],1424715168,,8,25,False,default,,,,,
313,MachineLearning,t5_2r3gv,2015-2-24,2015,2,24,4,2wweor,youtube.com,"Now online: videos from RE.WORK Deep Learning Summit, San Francisco 2015",https://www.reddit.com/r/MachineLearning/comments/2wweor/now_online_videos_from_rework_deep_learning/,reworksophie,1424718769,,1,31,False,http://b.thumbs.redditmedia.com/ZCF7XSU4bxMOrGpQu-YDaAN98f7xdwWqor2c5qQJ9Lg.jpg,,,,,
314,MachineLearning,t5_2r3gv,2015-2-24,2015,2,24,4,2wwfkb,self.MachineLearning,Machine Learning masters programs still open,https://www.reddit.com/r/MachineLearning/comments/2wwfkb/machine_learning_masters_programs_still_open/,glass_bottles,1424719137,"Hi everyone, 
I recently decided to bite the bullet and apply for a masters program in machine learning or data science this year, but I realize that a majority of programs are already past their deadlines.  

I found a few stats programs still accepting applications, but I was wondering if you guys could bring up good programs that you'd recommend I look into.

",10,0,False,self,,,,,
315,MachineLearning,t5_2r3gv,2015-2-24,2015,2,24,6,2wwxwr,webserv.jcu.edu,Emergent Behavior Simulation tool for beginners (Let's see who can build the best model!),https://www.reddit.com/r/MachineLearning/comments/2wwxwr/emergent_behavior_simulation_tool_for_beginners/,[deleted],1424726937,,2,0,False,default,,,,,
316,MachineLearning,t5_2r3gv,2015-2-24,2015,2,24,6,2wx0z0,self.MachineLearning,Variable sized output of NN,https://www.reddit.com/r/MachineLearning/comments/2wx0z0/variable_sized_output_of_nn/,jrkirby,1424728254,"Are there any examples of neural networks which don't have a constant sized output vector? The only way I can think of to do this would be to use an RNN, but I'm not sure if that's the only option. Can anybody describe any techniques that involve a fairly large, but variable sized output of a neural network? Any papers I can read?

I'm just looking for general direction and prior art at the moment.",16,0,False,self,,,,,
317,MachineLearning,t5_2r3gv,2015-2-24,2015,2,24,8,2wxc4t,github.com,reinforce - simple reinforcement learning in Python,https://www.reddit.com/r/MachineLearning/comments/2wxc4t/reinforce_simple_reinforcement_learning_in_python/,epsteinN,1424733172,,5,4,False,http://b.thumbs.redditmedia.com/7SC5lv3-9bai7RGslTfbNv-ITYSkBAIvjS6GZD9wUsE.jpg,,,,,
318,MachineLearning,t5_2r3gv,2015-2-24,2015,2,24,8,2wxeoe,self.MachineLearning,A few reasons why Machine Learning applied to content summarization is important,https://www.reddit.com/r/MachineLearning/comments/2wxeoe/a_few_reasons_why_machine_learning_applied_to/,[deleted],1424734338,"1. Summarization is key when it comes to the initial stages of sentiment analysis.

2. Summarization is integral to the mobile experience today as content needs to be boiled down to its more important points for anyone interested in saving time and that's everyone, when it comes to content consumption.

3. Yahoo bought a few lines of summarization code in the form of Summly for $30 million in cash before the company had any notable traction. See: http://allthingsd.com/20130325/yahoo-paid-30-million-in-cash-for-18-months-of-young-summly-entrepreneurs-time/

4. Google bought Wavii for north of $30 million, another summarization system. See: http://techcrunch.com/2013/04/23/google-buys-wavii-for-north-of-30-million/ 

5. Companies are beginning to see content summarization as the new consumer gateway to all sorts of other content.

",0,0,False,default,,,,,
319,MachineLearning,t5_2r3gv,2015-2-24,2015,2,24,8,2wxfar,self.MachineLearning,Building a Recommendation Engine,https://www.reddit.com/r/MachineLearning/comments/2wxfar/building_a_recommendation_engine/,[deleted],1424734614,"Hey everyone,
I'm working to build a website that will offer users custom recommendations for products (kinda like pandora or amazon) for a specific market. This would be a bit more complex than usual as it would allow users to elect to fill out a number of other fields for feedback and data. 

I've seen online lots of stuff about building one's own recommendation engine, but it's definitely beyond me. 

Was wondering if anyone knew how long a project like this would take, what it might cost, and how I could find someone to do this.

Thanks so much!",1,0,False,default,,,,,
320,MachineLearning,t5_2r3gv,2015-2-24,2015,2,24,9,2wxj3o,self.MachineLearning,How important is Math in Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/2wxj3o/how_important_is_math_in_machine_learning/,BPellegrino,1424736408,"So every machine learning class / resource I have seen seems to have very complex derivatives, many higher level stats references, etc., much different than all of the CS courses I have taken online or more than any course I took in my CS degree at university

so my question is, how important is Math in working on machine learning? Would it be more important to focus on calculus/stats or to focus on becoming a better programmer/algorithms?",19,1,False,self,,,,,
321,MachineLearning,t5_2r3gv,2015-2-24,2015,2,24,9,2wxj4n,blog.bigml.com,PAPIs 2015  Call for Proposals Begins!,https://www.reddit.com/r/MachineLearning/comments/2wxj4n/papis_2015_call_for_proposals_begins/,czuriaga,1424736423,,0,1,False,default,,,,,
322,MachineLearning,t5_2r3gv,2015-2-24,2015,2,24,14,2wyllq,analyticsvidhya.com,Best article of 2014 on Online Machine Learning.,https://www.reddit.com/r/MachineLearning/comments/2wyllq/best_article_of_2014_on_online_machine_learning/,ken_analyst,1424756340,,0,0,False,http://b.thumbs.redditmedia.com/o5OTOfY48Vj0CKiq2p0JGFVNhTZaiY5SqwzP7nM0uwc.jpg,,,,,
323,MachineLearning,t5_2r3gv,2015-2-24,2015,2,24,16,2wywzx,arxiv.org,Translating Videos to Natural Language Using Deep Recurrent Neural Networks,https://www.reddit.com/r/MachineLearning/comments/2wywzx/translating_videos_to_natural_language_using_deep/,alexjc,1424764628,,2,14,False,default,,,,,
324,MachineLearning,t5_2r3gv,2015-2-24,2015,2,24,18,2wz4ae,timdettmers.wordpress.com,Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning,https://www.reddit.com/r/MachineLearning/comments/2wz4ae/which_gpus_to_get_for_deep_learning_my_experience/,iori42,1424771578,,34,77,False,http://b.thumbs.redditmedia.com/rF5vorzyzMDwRHdZLqi8KTYiyiQ2adbaf3TugeUxb0E.jpg,,,,,
325,MachineLearning,t5_2r3gv,2015-2-24,2015,2,24,19,2wz5c1,cityam.com,Machine learning: Microsoft creates platform for analysing data in the cloud,https://www.reddit.com/r/MachineLearning/comments/2wz5c1/machine_learning_microsoft_creates_platform_for/,ZaneSpritzer,1424772636,,1,0,False,http://b.thumbs.redditmedia.com/f0N531I46sRP2Y7nIVdJOTcGnIbgF80VEL4xczx7xVo.jpg,,,,,
326,MachineLearning,t5_2r3gv,2015-2-24,2015,2,24,19,2wz6ze,self.MachineLearning,"[Question] What is the architecture (development Stack) that you have adopted for data analysis solutions, after validating your ML model",https://www.reddit.com/r/MachineLearning/comments/2wz6ze/question_what_is_the_architecture_development/,SomeoneisWondering,1424774238,"We are developing a solution using machine learning, we could build our first machine learning model, we used R/scikit to build this model (we got good accuracy). However, we want to scale our solution and build a web/mobile application. We are discussing the backend choice, and technologies that we should use. 

I am sure that there are many experts who are frequenting this sub, would you please share with you us your story. What are the backend-technologies that you have adopted after building ML model. ",6,5,False,self,,,,,
327,MachineLearning,t5_2r3gv,2015-2-24,2015,2,24,20,2wzbyl,self.MachineLearning,[Question] How to calculate the gradient of a neural network with respect to the input?,https://www.reddit.com/r/MachineLearning/comments/2wzbyl/question_how_to_calculate_the_gradient_of_a/,RossoFiorentino,1424778999,"In particular i am looking to calculate the derivative of a particular output neuron with respect to a particular input neuron. 

Kind Regards",3,0,False,self,,,,,
328,MachineLearning,t5_2r3gv,2015-2-24,2015,2,24,22,2wzkaq,youtube.com,USE CASE: Medical Study Data in DSX,https://www.reddit.com/r/MachineLearning/comments/2wzkaq/use_case_medical_study_data_in_dsx/,[deleted],1424785241,,0,1,False,default,,,,,
329,MachineLearning,t5_2r3gv,2015-2-25,2015,2,25,2,2x08gp,blog.sigopt.com,Tuning machine learning models via hyperparameter optimization,https://www.reddit.com/r/MachineLearning/comments/2x08gp/tuning_machine_learning_models_via_hyperparameter/,Zephyr314,1424797439,,17,5,False,http://b.thumbs.redditmedia.com/sGFevTdH-cqwIPu3brviaUKCJ9GnVjadbi-2CEgMY4Y.jpg,,,,,
330,MachineLearning,t5_2r3gv,2015-2-25,2015,2,25,2,2x0bq8,self.MachineLearning,Some questions regarding Batch Normalization,https://www.reddit.com/r/MachineLearning/comments/2x0bq8/some_questions_regarding_batch_normalization/,Refefer,1424798877,"For those of you who have kept up with the latest and greatest research, a couple of questions with the Batch Normalization paper listed [here](http://arxiv.org/pdf/1502.03167v2.pdf):

1. For the fully connected case, where is the normalization process done?  The paper infers it's at the 'layer inputs', which I've interpretted as before the linear transform, but later states in the convolutional case that it's done in between the linear and non linear transforms.  Similarly, ZCA whitening is done as a preprocessing step, lending weight to the 'layer inputs' idea.

2. Is the m/(m-1) really needed in this case?  Given a large enough batch size, does it actually have a sizable impact?

3. Anyone have a sense of what they're using for the numerical constant?  I'm dumping in 1e-6 since I took that as avoiding the divide by zero problem.

4. For convolutional filters, I can't tell whether they're batch normalizing all the channels together once, independent of number of output channels, or if they're normalizing once per filter.

Empirically, adding batch normalization prior to the linear transformations have yielded better results than sandwiched between the linear and nonlinear transforms, but both have peformed worse and trained slower than without it.  Hopefully I'm simply misinterpretting something in the paper :)

EDIT: Thanks for the feedback!",3,7,False,self,,,,,
331,MachineLearning,t5_2r3gv,2015-2-25,2015,2,25,3,2x0mua,blog.bigml.com,Divining the K in K-means Clustering,https://www.reddit.com/r/MachineLearning/comments/2x0mua/divining_the_k_in_kmeans_clustering/,czuriaga,1424803712,,0,1,False,default,,,,,
332,MachineLearning,t5_2r3gv,2015-2-25,2015,2,25,5,2x13rj,codingrefs.com,Data Mining and Machine Learning Digest: FEB 2015 #2,https://www.reddit.com/r/MachineLearning/comments/2x13rj/data_mining_and_machine_learning_digest_feb_2015_2/,plywoods,1424810984,,0,4,False,http://a.thumbs.redditmedia.com/Rq4YHWNXPi1dmVlk0lZyJoWjJcL3j_l0XJX5zcJqlA4.jpg,,,,,
333,MachineLearning,t5_2r3gv,2015-2-25,2015,2,25,6,2x16p9,blog.twitter.com,Understanding users through Twitter data and machine learning,https://www.reddit.com/r/MachineLearning/comments/2x16p9/understanding_users_through_twitter_data_and/,tryolabs,1424812218,,0,7,False,http://b.thumbs.redditmedia.com/oNehjPXD11QRRfwtqZYfxN_RnL7_BI5Q6rv-FxoUdWc.jpg,,,,,
334,MachineLearning,t5_2r3gv,2015-2-25,2015,2,25,6,2x1b6e,devblogs.nvidia.com,Hands-On GPU-Accelerated Machine Learning Training at GTC 2015,https://www.reddit.com/r/MachineLearning/comments/2x1b6e/handson_gpuaccelerated_machine_learning_training/,harrism,1424814072,,2,23,False,http://b.thumbs.redditmedia.com/b3-_Msnj2tYFNljlUuU-q3ouQcgRcVOX572IcC2OZgw.jpg,,,,,
335,MachineLearning,t5_2r3gv,2015-2-25,2015,2,25,7,2x1ma0,ayasdi.com,GPGU vs. CPU for Artificial and Machine Intelligence Tasks,https://www.reddit.com/r/MachineLearning/comments/2x1ma0/gpgu_vs_cpu_for_artificial_and_machine/,Ayasdi,1424818443,,0,0,False,http://a.thumbs.redditmedia.com/rHpiDUIiX1K47ONu_zY7a9PvTRRqYsSAofePb0wXu98.jpg,,,,,
336,MachineLearning,t5_2r3gv,2015-2-25,2015,2,25,10,2x23vi,self.MachineLearning,Failing at training a simple NN... what am I doing wrong?,https://www.reddit.com/r/MachineLearning/comments/2x23vi/failing_at_training_a_simple_nn_what_am_i_doing/,[deleted],1424826324,"I'm a total n00b, going through Mitchell's ML book, and I have hit a roadblock on a simple task. Instead of repeating everything, here's a SE question I posted: http://cs.stackexchange.com/questions/39788/trying-to-implement-a-simple-neural-network-without-success

Some help please? I'm stumped. :-(",6,1,False,default,,,,,
337,MachineLearning,t5_2r3gv,2015-2-25,2015,2,25,17,2x3epl,tjo-en.hatenablog.com,Deep Learning with {h2o} on MNIST dataset (and Kaggle competition),https://www.reddit.com/r/MachineLearning/comments/2x3epl/deep_learning_with_h2o_on_mnist_dataset_and/,TJO_datasci,1424854028,,0,1,False,default,,,,,
338,MachineLearning,t5_2r3gv,2015-2-25,2015,2,25,17,2x3fgi,self.MachineLearning,Any one know any good survey papers on image classification ?,https://www.reddit.com/r/MachineLearning/comments/2x3fgi/any_one_know_any_good_survey_papers_on_image/,[deleted],1424854780,"I've been reading up on deep neural networks/neural networks for a week and I'm getting the impression that this is the state of the art algorithm in the field of image classification. 

I remember reading up on a whole variety of ML algorithms which gave equally good results as neural networks in the MNIST dataset. I wonder what happened to them and if they've been improved upon in recent times.

Are there any good survey papers out there giving a good comparison/pros &amp; cons of each approach on a standard dataset ? 

Maybe in IEEE Xplore ? 

Thanks guys. 

P:S I don't have access to any journals or a library, hence hoping someone here can help me out",4,1,False,default,,,,,
339,MachineLearning,t5_2r3gv,2015-2-25,2015,2,25,18,2x3gm1,arxiv.org,ICLR2015: Memory Networks (Facebook AI Research),https://www.reddit.com/r/MachineLearning/comments/2x3gm1/iclr2015_memory_networks_facebook_ai_research/,[deleted],1424855891,,2,23,False,default,,,,,
340,MachineLearning,t5_2r3gv,2015-2-25,2015,2,25,18,2x3i55,self.MachineLearning,[Discuss] most useful heuristics related to stochastic optimization,https://www.reddit.com/r/MachineLearning/comments/2x3i55/discuss_most_useful_heuristics_related_to/,[deleted],1424857363,"What are the most useful heuristics related to stochastic optimization in ML (not just SGD, but also other SO algorithms) ?

I'll post some of my favorites (FTR, I didn't invent them) in the comments. Discuss them, or share your own.",0,2,False,default,,,,,
341,MachineLearning,t5_2r3gv,2015-2-25,2015,2,25,19,2x3ksr,self.MachineLearning,basic question about machine learning and probabilistic framework?,https://www.reddit.com/r/MachineLearning/comments/2x3ksr/basic_question_about_machine_learning_and/,MAS313,1424859886,"Why do we assume that the pair (X,Y) where X and Y are features and labels respectively are random variables governed by a probability distribution? Why does this assumption make sense? What if the underling source is deterministic?",9,1,False,self,,,,,
342,MachineLearning,t5_2r3gv,2015-2-25,2015,2,25,20,2x3px2,siliconangle.com,Microsoft brings Machine Learning in the cloud,https://www.reddit.com/r/MachineLearning/comments/2x3px2/microsoft_brings_machine_learning_in_the_cloud/,jamaalmerlo,1424864707,,0,0,False,http://a.thumbs.redditmedia.com/6SRe3kYyEDiOgtq7gUjd15scLujaMh0sD9UvGTxWvc0.jpg,,,,,
343,MachineLearning,t5_2r3gv,2015-2-25,2015,2,25,21,2x3rqw,qlearning.4ck5.com,Q-Learning demo,https://www.reddit.com/r/MachineLearning/comments/2x3rqw/qlearning_demo/,galapag0,1424866277,,0,0,False,default,,,,,
344,MachineLearning,t5_2r3gv,2015-2-25,2015,2,25,22,2x3zly,self.MachineLearning,[Question] Which metric to trust ?,https://www.reddit.com/r/MachineLearning/comments/2x3zly/question_which_metric_to_trust/,SomeoneisWondering,1424872117,"Self-learner here, learning how to make predictive model of a specific problem, I am using ensemble learning algorithms (CART, Random Forest), in my example I got a good value of accuracy 0.81, but very high error  Mean squared error (0.37). Should I say that my predictive model is good in this case, how can I comment on my model in this case. 

**Note** I am using Scikit, to get the score I use .accuracy()/.score() functions.  ",6,0,False,self,,,,,
345,MachineLearning,t5_2r3gv,2015-2-25,2015,2,25,23,2x42am,self.MachineLearning,Job Title disambiguation?,https://www.reddit.com/r/MachineLearning/comments/2x42am/job_title_disambiguation/,manueslapera,1424873702,"Hey guys, im working on a project and hope that someone here can help out.

I work on an H R Startup and one of the things i focus is increasing data quality.

I'm trying to add some sanity to the Job titles in our system. (More than 60% of the titles only appear once).

I was wondering, does anybody know of any way of clustering the titles to reduce the sparsity of the dataset?

Right now i'm using Open Refine, but I was looking for a set of text clustering tools that worked either with Python or R.

Thanks!",9,0,False,self,,,,,
346,MachineLearning,t5_2r3gv,2015-2-26,2015,2,26,0,2x4dsw,self.MachineLearning,"Suggest a speaker or apply for a press pass for the Deep Learning Summit in Boston and London! ALL are welcome to submit: students, academics, startups, established companies, freelance, bloggers etc",https://www.reddit.com/r/MachineLearning/comments/2x4dsw/suggest_a_speaker_or_apply_for_a_press_pass_for/,reworksophie,1424879676,"After the great feedback for the Deep Learning Summit in San Francisco, we'll be holding editions in Boston and London this year, as well as returning to San Francisco next year.

We'd love to hear your suggestions for speakers, whether it be yourself, someone you know, or an expert you follow the work of. Please feel free to make suggestions in the comments or use our dedicated form. 
Find the Suggest a Speaker form [here](http://teamrework.wufoo.com/forms/suggest-a-speaker)

Find the Press Pass Request form [here](http://teamrework.wufoo.com/forms/mxzkss509u4v5w/)

See the event pages here:
[Deep Learning Summit Boston](http://www.re-work.co/events/deep-learning-boston-2015) - 26-27 May 2015
[Deep Learning Summit London](http://www.re-work.co/events/deep-learning-london-2015) - 24-25 September 2015
[Deep Learning Summit San Francisco](http://www.re-work.co/events/deep-learning-sanfran-2016) - 28-29 January 2016

Hope to hear from some of you soon!",0,3,False,self,,,,,
347,MachineLearning,t5_2r3gv,2015-2-26,2015,2,26,1,2x4fez,nathanepstein.github.io,Implementing Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/2x4fez/implementing_reinforcement_learning/,epsteinN,1424880447,,1,8,False,default,,,,,
348,MachineLearning,t5_2r3gv,2015-2-26,2015,2,26,1,2x4iqn,self.MachineLearning,How necessary is an advanced degree to getting a job in the ML/AI field?,https://www.reddit.com/r/MachineLearning/comments/2x4iqn/how_necessary_is_an_advanced_degree_to_getting_a/,questions_ML,1424881950,"I am currently a junior in college and I am trying to decide what I want to do with my life post graduation next year. Machine Learning and AI have been at the top of my interests for some time now, and I would love to one day work in the field. Most jobs I see say they either require or strongly prefer either a masters degree of a PhD. In your opinion how necessary  is some kind of advanced degree to work in the field? Is it possible to supplement one with a lot of self teaching and some personal projects? 

Sorry if this is the wrong place to ask this, you guys just seem like the best people to answer.",31,18,False,self,,,,,
349,MachineLearning,t5_2r3gv,2015-2-26,2015,2,26,1,2x4jcl,self.MachineLearning,Help a newbie? Train simple neural network on image.,https://www.reddit.com/r/MachineLearning/comments/2x4jcl/help_a_newbie_train_simple_neural_network_on_image/,Katastic_Voyage,1424882210,"Please forgive me if I'm in the wrong area.

I want to use a neural network with an image as a source to predict a different image. I'm not trying to do image recognition (""Is this a bird?""). I just want ""given [X] images, get [Y] images output. Train on [Z] visually similar images to [Y].""

What programs, techniques, or topics, would you recommend to look into? I've seen convolution neural networks but they're pretty complex for a new guy, and I think they're making an assumption ""far away coordinates do not impact the image cell"" that does not apply to me.

I've seen some programs, but they all seem dauntingly complex.

Thank you.",1,1,False,self,,,,,
350,MachineLearning,t5_2r3gv,2015-2-26,2015,2,26,2,2x4s00,self.MachineLearning,Need help with fuzzy toolbox in matlab for machine learning,https://www.reddit.com/r/MachineLearning/comments/2x4s00/need_help_with_fuzzy_toolbox_in_matlab_for/,mascot6699,1424885968,"Hello
I am working of MATLAB's fuzzy tool and I do not understand how to determine rules for a particular model. In the example given(the tipping problem) the rules were already determined whereas in our case we are using the PIma Indians Diabetes dataset (archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes).
So the questions I have is
1) Is this dataset suitable for fuzzy classification?
2) how do I convert data to fuzzy value? 
I tried two ways one by making clusters in weka and another using binning in weka
3) how to generate rules ?
maybe by check all sets of rules for support and confidence above a certain threshold or any other way?
http://www.scirp.org/journal/PaperDownload.aspx?paperID=29500
in short how have the people in above journal performed their 4.7. Fuzzy Inference System (FIS) model ?
Thanks",2,0,False,self,,,,,
351,MachineLearning,t5_2r3gv,2015-2-26,2015,2,26,3,2x4yy1,nature.com,Google DeepMind Nature Paper: Human-level control through deep reinforcement learning,https://www.reddit.com/r/MachineLearning/comments/2x4yy1/google_deepmind_nature_paper_humanlevel_control/,egrefen,1424888949,,65,80,False,default,,,,,
352,MachineLearning,t5_2r3gv,2015-2-26,2015,2,26,3,2x51rs,stablemarkets.wordpress.com,Network Analysis - Visualizing Bike Trips in Boston,https://www.reddit.com/r/MachineLearning/comments/2x51rs/network_analysis_visualizing_bike_trips_in_boston/,stablemarkets,1424890133,,0,0,False,http://a.thumbs.redditmedia.com/yKiuYWY4DWgzx-qaN90SBj5E24WkYC4Vmmo70-dG408.jpg,,,,,
353,MachineLearning,t5_2r3gv,2015-2-26,2015,2,26,6,2x5n5v,devblogs.nvidia.com,Baidu blogs about Deep Speech: Accurate Speech Recognition with GPU-Accelerated Deep Learning,https://www.reddit.com/r/MachineLearning/comments/2x5n5v/baidu_blogs_about_deep_speech_accurate_speech/,harrism,1424899224,,0,5,False,http://b.thumbs.redditmedia.com/Y-Bsy8xNaNAGI8DT87KK3CIPe-WvrtYgx9LsziQRyEc.jpg,,,,,
354,MachineLearning,t5_2r3gv,2015-2-26,2015,2,26,7,2x5zj8,self.MachineLearning,I've just read Grammar as a Foreign Language Vinyals et al. and isn't this a possible solution for training deep nets on small data?,https://www.reddit.com/r/MachineLearning/comments/2x5zj8/ive_just_read_grammar_as_a_foreign_language/,SnowLong,1424904447,"What guys did, the parsing datasets are too small for RNNs to outperform traditional ML. Around ~90k sentences total. So they took publicly available parser from 2006, F1 score 90.4, grabbed 7 million unlabeled sentences and parsed them using it. Then they trained LSTM model first on 7M examples and finetuned model on original 90k examples. LSTM ensemble got F1 score of 91.6.

They haven't manage to outperform SOTA, current one is 92.4 from 2010. 

But think what will happens if they would label another 7M sentences, now using much improved parser they've got, and then train&amp;finetune new LSTM model? Will F1 score go up? Most likely yes. Rinse, repeat.

I understand this is time/computationally consuming procedure, but if it would work, it would work for speech, vision, other NLP tasks like machine translation. Anywhere where there are plenty of unlabeled data but shortage of high quality labeled one.

Am I onto something? Or this is not worth checking?

*PS. Technically I hold MSc in applied math, but had nothing to do with academia since graduation, since a long time ago. Reading DL papers for fun, ya know?*",8,1,False,self,,,,,
355,MachineLearning,t5_2r3gv,2015-2-26,2015,2,26,8,2x691m,self.MachineLearning,how difficult would it be to build a math tutor ai that is useful (ie not useless simplistic),https://www.reddit.com/r/MachineLearning/comments/2x691m/how_difficult_would_it_be_to_build_a_math_tutor/,velveteenrabbis,1424908761,,3,0,False,default,,,,,
356,MachineLearning,t5_2r3gv,2015-2-26,2015,2,26,9,2x6arj,youtube.com,Deepmind office interview,https://www.reddit.com/r/MachineLearning/comments/2x6arj/deepmind_office_interview/,evc123,1424909503,,0,8,False,http://b.thumbs.redditmedia.com/euoQlZuGpwkzjOBc9Wc5K8fStURGLLl1n0vHp7FIWWY.jpg,,,,,
357,MachineLearning,t5_2r3gv,2015-2-26,2015,2,26,10,2x6kdf,newsoffice.mit.edu,Better machine learning,https://www.reddit.com/r/MachineLearning/comments/2x6kdf/better_machine_learning/,[deleted],1424914050,,0,0,False,default,,,,,
358,MachineLearning,t5_2r3gv,2015-2-26,2015,2,26,10,2x6lwc,self.MachineLearning,Rollio Hiring: Lead Machine Learning/ NLP Engineer,https://www.reddit.com/r/MachineLearning/comments/2x6lwc/rollio_hiring_lead_machine_learning_nlp_engineer/,Jas1292,1424914786,,0,0,False,default,,,,,
359,MachineLearning,t5_2r3gv,2015-2-26,2015,2,26,11,2x6r2s,machineslikeus.com,Machines master classic video games without being told the rules,https://www.reddit.com/r/MachineLearning/comments/2x6r2s/machines_master_classic_video_games_without_being/,MachinesLikeUs,1424917417,,0,1,False,default,,,,,
360,MachineLearning,t5_2r3gv,2015-2-26,2015,2,26,13,2x76i5,self.MachineLearning,"(ML Beginner) - I want to implement an algorithm from a research paper, but not sure how to tackle it...",https://www.reddit.com/r/MachineLearning/comments/2x76i5/ml_beginner_i_want_to_implement_an_algorithm_from/,kuhcd,1424925294,"Hi All,

I'm very much a beginner when it comes to Machine Learning topics  and don't have a formal background in either Computer Science or Math (self taught web developer). I've been studying this research paper for a few weeks now as it is relevant to a project I want to tackle: ""How to Improve Your Google Ranking: Myths and Reality""  (Download Link: https://mega.co.nz/#!Rw0xyTLJ!OzLA6YjHsL0_1L8gwmNPw745Sbb6rVnwynqw_RUg9ds)

Note: I'm not concerned with the quality of their findings or with discussing the topic of SEO here

In the paper, they describe an algorithm they use to fairly accurate reproduce Google rankings for random keywords. The approach they used was to scrape the top 100 results for a set of random keywords, grab about 17 ""known"" ranking factors (such as Page Rank, keyword in URL, domain age, etc), then use that data along with a **pairwise linear programming ranking model** and a **recursive partitioning ranking algorithm** to then predict which of those 100 results are in the top 10. This is all trained against the actual Google rankings.

Now, I understand conceptually what is happening, such as pairwise ranking and recursive partitioning, but what I can't figure out (and this could just be my incredibly naive understanding of research papers) is how to actually reproduce this algorithm with my own code. Is all the information I need to reproduce this algorithm even contained within this paper and I just can't put it all together? Or is this more of an overview of what the researchers did and the algorithm is actually secret?

And in the latter case, is it possible/normal for someone to reach out to the researchers and ask them for more details of their implementation? Or is that a no-no?

Sorry for what is probably a very simple question, but I've reached a dead end and figured you guys might be able to help. Thanks in advance.",8,1,False,self,,,,,
361,MachineLearning,t5_2r3gv,2015-2-26,2015,2,26,16,2x7nbo,self.MachineLearning,Advice for getting into ML from a humanities PhD,https://www.reddit.com/r/MachineLearning/comments/2x7nbo/advice_for_getting_into_ml_from_a_humanities_phd/,bunchabinchois,1424936058,"I'm mid-way through a humanities (music theory) PhD and I definitely want out of humanities academia. My pipe dream job would be doing ML for a place like Spotify/Echo Nest doing things like [this](http://benanne.github.io/2014/08/05/spotify-cnns.html), or [this](http://www.nyu.edu/projects/farbood/publications.html), but I doubt anyone would hire me for anything interesting with a humanities degree.

My current math background: calculus+ODEs, one of those awkward ""introduction to analysis"" courses that's proof-based but not at the level of baby Rudin, probability (from Ross's book), linear algebra (also proof-based but not very rigorous).

I've been teaching myself CS over the past year or so. After working my way through the textbooks and assignments for the undergrad core courses (algorithms/data structures/intro to systems),  I'm currently hopping departments to audit some CS classes while putting the majority of my dissertation work to the side in the hopes of being able to do something both ML and music related once I get my skills up. Last semester, I audited computer vision and AI. I'm auditing information retrieval and a data science course this semester.

My current goal is to master a textbook like PRML or MLAPP and then work on a big project that I can grow a dissertation from. This would let me please my department while also advancing my ML skills. Unfortunately, I'm in the ""danger zone"" on that infamous Venn diagram: domain expertise and hacking skills, but no statistical intuition.

What's the best place for me to go from here?  I have no mentorship whatsoever from my department, but a very strong desire to learn.",15,8,False,self,,,,,
362,MachineLearning,t5_2r3gv,2015-2-26,2015,2,26,18,2x7v8s,insidebigdata.com,Dato Updates Machine Learning Platform,https://www.reddit.com/r/MachineLearning/comments/2x7v8s/dato_updates_machine_learning_platform/,vernonamailla,1424943457,,0,2,False,http://a.thumbs.redditmedia.com/KH8Xn6NstU8T2ghhelLD2YTLyyHVX7DGJcDP5mEcuF4.jpg,,,,,
363,MachineLearning,t5_2r3gv,2015-2-26,2015,2,26,19,2x7wuf,bloomberg.com,Google Invents an AI System That Plays Video Games on Its Own,https://www.reddit.com/r/MachineLearning/comments/2x7wuf/google_invents_an_ai_system_that_plays_video/,[deleted],1424944963,,0,0,False,default,,,,,
364,MachineLearning,t5_2r3gv,2015-2-26,2015,2,26,20,2x83pp,googleresearch.blogspot.ru,From Pixels to Actions: Human-level control through Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/2x83pp/from_pixels_to_actions_humanlevel_control_through/,alexeyr,1424951780,,0,0,False,http://b.thumbs.redditmedia.com/qbo7n5EDp541SUEkpNcmzo6cU3hkW8pwblnFzC_Vt-E.jpg,,,,,
365,MachineLearning,t5_2r3gv,2015-2-26,2015,2,26,22,2x8ab2,self.MachineLearning,Importance sampling and impossible to sample distribution,https://www.reddit.com/r/MachineLearning/comments/2x8ab2/importance_sampling_and_impossible_to_sample/,PsychedelicStore,1424957014,"Hi all,

I've problem understanding the case of ""distribution from which is impossible to sample from"". Textbooks refer to this but they not explain why or make an example of such distributions.  Can someone come up with an example of distribution for which we can't sample from with standard methods (maybe it's the case of using the inverse cdf sampling for distributions for which the cdf cannot be computed)? I understood that in this case, other techniques can be used, such as importance sampling. This requires, however, to be able to evaluate this distribution that cannot be sampled (to computed the weights). But if we know its expression, why we can't sample from it? Thank you!",11,8,False,self,,,,,
366,MachineLearning,t5_2r3gv,2015-2-26,2015,2,26,23,2x8ee8,sites.google.com,Code for Human-Level Control through Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/2x8ee8/code_for_humanlevel_control_through_deep/,siddharth950,1424959719,,3,7,False,default,,,,,
367,MachineLearning,t5_2r3gv,2015-2-27,2015,2,27,0,2x8lqn,people.idsia.ch,Juergen Schmidhuber: DeepMind's Nature Paper and Earlier Related Work,https://www.reddit.com/r/MachineLearning/comments/2x8lqn/juergen_schmidhuber_deepminds_nature_paper_and/,spdiner,1424963848,,20,33,False,http://a.thumbs.redditmedia.com/H6v-7ydjk69-q9eqYlgoo-XNhQKCWTA4eBZ93yK5Kt8.jpg,,,,,
368,MachineLearning,t5_2r3gv,2015-2-27,2015,2,27,0,2x8o77,radar.oreilly.com,"David Blei on Topic Models (past, present, future)",https://www.reddit.com/r/MachineLearning/comments/2x8o77/david_blei_on_topic_models_past_present_future/,gradientflow,1424965093,,1,9,False,http://b.thumbs.redditmedia.com/JikmiMOkEfOdIPCj3j5IO0OcNh2sAQXsm3XiOCJMzng.jpg,,,,,
369,MachineLearning,t5_2r3gv,2015-2-27,2015,2,27,1,2x8xzs,thetalkingmachines.com,"Geoffrey Hinton, Yann LeCun and Yoshua Bengio Talk the History of Deep Nets",https://www.reddit.com/r/MachineLearning/comments/2x8xzs/geoffrey_hinton_yann_lecun_and_yoshua_bengio_talk/,awiltschko,1424969691,,7,55,False,http://b.thumbs.redditmedia.com/Bf48OF_9xBhrpE_TAleNaUaYage-tdtm5eViIjbDI4Q.jpg,,,,,
370,MachineLearning,t5_2r3gv,2015-2-27,2015,2,27,2,2x8z48,medium.com,"""Machine learning is not, by default, fair or just in any meaningful way""",https://www.reddit.com/r/MachineLearning/comments/2x8z48/machine_learning_is_not_by_default_fair_or_just/,urish,1424970171,,4,3,False,http://b.thumbs.redditmedia.com/fYWr_l0n-AIHV1ezD7EJo39L-VgAO7m5LjjlsiPDhhk.jpg,,,,,
371,MachineLearning,t5_2r3gv,2015-2-27,2015,2,27,2,2x8zoc,mln.io,Periodic Table of Machine Learning Libraries,https://www.reddit.com/r/MachineLearning/comments/2x8zoc/periodic_table_of_machine_learning_libraries/,iori42,1424970414,,1,10,False,default,,,,,
372,MachineLearning,t5_2r3gv,2015-2-27,2015,2,27,3,2x9ant,self.MachineLearning,How long can u think about math ? What to do to extend this period?,https://www.reddit.com/r/MachineLearning/comments/2x9ant/how_long_can_u_think_about_math_what_to_do_to/,[deleted],1424975062,After 2 hrs of mathematical brainstorming I get a headache. The session is rewarding but I want to extend it. The thing is that I get a headache and taking 15 mins break doesn't seem to help. I'm sure you guys experience a similar problem. How long can u go think about math and what do u do to refresh in general or get rid of the headache? ,1,0,False,default,,,,,
373,MachineLearning,t5_2r3gv,2015-2-27,2015,2,27,4,2x9gbw,static.googleusercontent.com,Machine Learning: The High-Interest Credit Card of Technical Debt [PDF],https://www.reddit.com/r/MachineLearning/comments/2x9gbw/machine_learning_the_highinterest_credit_card_of/,alexeyr,1424977510,,0,7,False,default,,,,,
374,MachineLearning,t5_2r3gv,2015-2-27,2015,2,27,8,2xadgp,pages.cs.wisc.edu,Machine Teaching: An Inverse Problem to Machine Learning and an Approach Toward Optimal Education [pdf],https://www.reddit.com/r/MachineLearning/comments/2xadgp/machine_teaching_an_inverse_problem_to_machine/,RockDiesel,1424991918,,7,14,False,default,,,,,
375,MachineLearning,t5_2r3gv,2015-2-27,2015,2,27,8,2xagx4,self.MachineLearning,When cross-validation goes wrong: model inspection in scikit-learn,https://www.reddit.com/r/MachineLearning/comments/2xagx4/when_crossvalidation_goes_wrong_model_inspection/,elanmart,1424993566,"Hello Guys,

I need some help with a certain ML problem. I'll try to be quick:

My task was to classify offers from an online trading website into 10 categories. About 90% of training data had label 0 (offer does not violate website's terms). I was training my model for Balanced Accuracy metric.

Each example had a few dense features (when the offer was added etc.) and text features: description + attributes. 1 million training examples, 1kk testing.

I was working with **scikit-learn**.

**--------**

I used cross-validation (really safe one: 5-fold, training on 65% of the training set). The results were great: balanced Accuracy of about ~70% on the validation set. My model was predicting label 0 in something around ~85% of validation examples.

And then I used the model on the test data: it predicted label 0 for 98% of examples and scored 30% on the hidden test-set. 

I then used a Naive Bayes classifier -- it achieved validation accuracy of around 60% and again predicted the label 0 in almost right amount. Then I used in on the testing data and... it predicted label 0 in 30% of the test examples, which is clearly a nonsense. I didn't check the model on the test set, because I was leaving the country and the competition deadline passed in the meantime. 

Lastly I used Vowpal Wabbit - it did as poorly as sklearn.

**--------**

So here's my actual question:

How does one approach a situation in which something goes as bad as in the case above? There is no reason to think that test and training sets had different label distributions. Also, as far as I can tell, words (from the top 3000 bag) occurred with the same frequencies in both sets.

Is there any way in which I can check why my models behave in such a weird way? Is there anything I can do to discover if I have a bug in the code, or the test and training sets are truly different? And can I discover in what way they differ to train my model appropriately? Or I should simply abandon cross-validation and validate my models directly on the test set (which fails if I'm allowed to do, say, 1 submission per day and there are 62 hours left ;) ). 

**--------**

Thanks in advance for any help!!!",4,2,False,self,,,,,
376,MachineLearning,t5_2r3gv,2015-2-27,2015,2,27,8,2xaj1z,self.MachineLearning,Finding the next most informative feature,https://www.reddit.com/r/MachineLearning/comments/2xaj1z/finding_the_next_most_informative_feature/,in_the_fresh,1424994567,"Let X = {x_1 ... x_N} be a set of points in R_m. For each x_i, some subset of the possible features {f_1 ... f_m} is observed and the rest are unobserved/latent.


One can achieve very good discriminative accuracy during cross-validation by merely imputing the unobserved features or, for categorical features, adding a new category corresponding to ""missing"" or ""unobserved."" 

Given a datapoint x_i, how might one go about determining what the next best feature would be to 'unveil' in order to boost your prediction confidence?

Thanks!",0,2,False,self,,,,,
377,MachineLearning,t5_2r3gv,2015-2-27,2015,2,27,10,2xaxkk,self.MachineLearning,"Ask ML: After ATARI, what ""dataset"" do you think is the next frontier for Reinforcement Learning / AI?",https://www.reddit.com/r/MachineLearning/comments/2xaxkk/ask_ml_after_atari_what_dataset_do_you_think_is/,[deleted],1425001475,"**Edit** Maybe a few upvotes wouldn't hurt, if people want to have an active discussion (I earn no karma here, as it's a self-post :-)",24,42,False,self,,,,,
378,MachineLearning,t5_2r3gv,2015-2-27,2015,2,27,11,2xb0be,blog.dato.com,Deep Learning made Doubly Easy with GraphLab Create,https://www.reddit.com/r/MachineLearning/comments/2xb0be/deep_learning_made_doubly_easy_with_graphlab/,rainydata,1425002834,,0,7,False,http://b.thumbs.redditmedia.com/iJdytOP14eFRvlo61VN9il-6xoOvLmrGGGLx1iisBuo.jpg,,,,,
379,MachineLearning,t5_2r3gv,2015-2-27,2015,2,27,12,2xba2o,self.MachineLearning,Hyperthetical Question,https://www.reddit.com/r/MachineLearning/comments/2xba2o/hyperthetical_question/,[deleted],1425007673,"What would you do as datascientist if you found undisputed data-sets from large-scale crowd-data input that supported the presence of serious life-quality-reducing medical conditions were clustered into hotspots around certain dirty industry that would be vital to the economy? If you had a view that all the dirty industries were purposefully placed in one area and government was aware of the direct link and placed a hospital as the solution, but did not inform the population because they are the workforce for these essential economic interests?

In a moral or ethical question, would you attempt to raise awareness of the risks so people could make informed decisions on their health? Or would you accept the necessary evil for the greater good and not rock the boat in-case you are seen as a risk to government interests and invite a risk to yourself?

These are the sorts of questions that I expect many datascientist have asked themselves in a 'what if' scenario? Is there an official rule you have about health-ethics and finding things you'd wish not had landed in your awareness? Any similar case studies out there?

Professor Nutt, the UK's chief drug scientist/advisor at the time crossed a similar line when he was quoted to say ""horse riding is more dangerous than ecstacy"" - which triggered several news headlines. The results of the science and being open about it was enough to see him sacked because it conflicted with political policy regarding drug law.

Any material you are aware of that talks about matters of the thin line new data can cross into causing political considerations?",0,0,False,default,,,,,
380,MachineLearning,t5_2r3gv,2015-2-27,2015,2,27,13,2xbhxs,tjo-en.hatenablog.com,"In Japan ""Data Scientist"" has gone and ""Artificial Intelligence"" is explosively rising",https://www.reddit.com/r/MachineLearning/comments/2xbhxs/in_japan_data_scientist_has_gone_and_artificial/,TJO_datasci,1425011750,,0,0,False,http://a.thumbs.redditmedia.com/uzYRcD8Dl_wmza10ALWNWIk9vo_4RiO23ajfpnqNSL4.jpg,,,,,
381,MachineLearning,t5_2r3gv,2015-2-27,2015,2,27,20,2xce7d,self.MachineLearning,Anyone here working on wing/aerofoil optimization?,https://www.reddit.com/r/MachineLearning/comments/2xce7d/anyone_here_working_on_wingaerofoil_optimization/,LMR_adrian,1425038277,"Hey /r/MachineLearning - is anyone here working on wing-aerofoil optimizations for work or in their spare time?

I'm trying to get a pipeline up and running for doing genetic trials and was wondering if anyone had recommendations of techniques or available code?

Thanks!",3,4,False,self,,,,,
382,MachineLearning,t5_2r3gv,2015-2-27,2015,2,27,21,2xcfgd,self.MachineLearning,Question about data mining for speech recognition,https://www.reddit.com/r/MachineLearning/comments/2xcfgd/question_about_data_mining_for_speech_recognition/,urosstegic,1425039391,"I'm not sure if this is the right subreddit, but i've tried asking on /r/MLQuestions and since there are 326 readers in total it was destined to fail.

Anyway, i would like to attack already solved machine learning problem: speech recognition, but for some foreign language. Does anyone have an idea where to gather labeled data or maybe raw data and what would be the best approach to label them?

Little background: i'm CS student from Serbia and i would like to create cool things like Google Now, Amazon Echo etc. for Serbian market or even for personal use. I completed Coursera course on machine learning and read a lot of papers, so basically i'm still beginner and i thought that a solved problem would be a great intro to ml world and speech recognition for my language could also be of practical use.

I don't want do look naive, i know that in order to build such devices i need experience, time and dedicated team, but for starters i'd like to build simple speech recognition system for myself that could run on my local PC and execute simple commands such as alarm creation and weather status.

Complete product like Amazon Echo that features speech synthesis, compilation of search reports, NLP and other stuff would be a distant goal that i'll probably never reach, but still that's the dirrection this project is headed.

tl;dr; What are the best/common strategies in collecting raw/labeled data for speech recognition systems in any language and in case of raw data, any best practise in labeling them?",9,5,False,self,,,,,
383,MachineLearning,t5_2r3gv,2015-2-27,2015,2,27,21,2xchng,self.MachineLearning,Having trouble getting Theano to work on my work station (Windows server 2008 + Tesla k20c GPU) Can anyone please help me out ?,https://www.reddit.com/r/MachineLearning/comments/2xchng/having_trouble_getting_theano_to_work_on_my_work/,[deleted],1425041359,"I'm trying to install Theano in my Windows Server 2008 OS(64-bit) and I'm following the tutorial given in

http://deeplearning.net/software/theano/install_windows.html#install-windows

I followed the ""Winpython"" approach and

have reached this step

http://deeplearning.net/software/theano/install_windows.html#configuring-theano

As Instructed I executed the command

python setup.py develop

The tutorial said ""this step will add the Theano directory to you PYTHON_PATH environment variable""

However after executing the code when I try to import theano, it shows that the module cannot be found.

If I directly copy the theano directory into the site-package folder of my winpython directory , I get a lot of jumbled messages and errors (over 100 lines) In my ipython console.

Please tell me what I am doing wrong.

Is there a better tutorial that I can follow ?

EDIT : extremely sorry if this the inappropriate place to ask this. please point me to the appropriate forum in that case",8,0,False,default,,,,,
384,MachineLearning,t5_2r3gv,2015-2-27,2015,2,27,23,2xcosu,self.MachineLearning,How to deal with known symmetries in the input of an ANN?,https://www.reddit.com/r/MachineLearning/comments/2xcosu/how_to_deal_with_known_symmetries_in_the_input_of/,NasenSpray,1425046304,"**Preface:**  
I have no background in ML. My experience is based mainly on a course assignment where we should create an AI that plays Nine Men's Morris and related research.

**Main:**  
I've created an ANN that's able to play Nine Men's Morris. It's a simple feedforward network with two hidden layers, it defeats me and other minmax AIs almost every time, and even manages to not suck that much against
a perfect player. It was trained with TD() through self-play and games against a perfect player (~10^7 games in total). It's input consists of the raw board encoding and some high-level features like ""the opponent is able to close a mill"" and ""we have only 3 men left"". It's output is the predicted value of the state from the point of view of the player to move, i.e., move selection is done by showing it every possible after-state and selecting the one that's best for us.

**The problem:**  
There are up to 16 symmetric boards (rotated, mirrored etc.) that - for the outcome of the game - are exactly the same. I tried to deal with that by randomly applying one of the symmetries on each board before training and hoped that the NN figures it out on it's own. But still, there are many situations where it selects vastly different moves depending on which particular variant is presented.

So... do you know a better way to solve this problem?",14,2,False,self,,,,,
385,MachineLearning,t5_2r3gv,2015-2-28,2015,2,28,0,2xcyrl,self.MachineLearning,"I am Jrgen Schmidhuber, AMA!",https://www.reddit.com/r/MachineLearning/comments/2xcyrl/i_am_jrgen_schmidhuber_ama/,JuergenSchmidhuber,1425051617,"Hello */r/machinelearning*,

I am Jrgen Schmidhuber (pronounce: You_again Shmidhoobuh) and I will be here to answer your questions on 4th March 2015, 10 AM EST. You can post questions in this thread in the meantime. Below you can find a short introduction about me from my website (you can read more about my labs work at [people.idsia.ch/~juergen/](http://people.idsia.ch/~juergen/)).

**Edits since 9th March: Still working on the long tail of more recent questions hidden further down in this thread ...**

**Edit of 6th March: I'll keep answering questions today and in the next few days - please bear with my sluggish responses.**

**Edit of 5th March 4pm (= 10pm Swiss time): Enough for today - I'll be back tomorrow.**

**Edit of 5th March 4am: Thank you for great questions - I am online again, to answer more of them!**


*Since age 15 or so, Jrgen Schmidhuber's main scientific ambition has been to build an optimal scientist through self-improving Artificial Intelligence (AI), then retire. He has pioneered self-improving general problem solvers since 1987, and Deep Learning Neural Networks (NNs) since 1991. The recurrent NNs (RNNs) developed by his research groups at the Swiss AI Lab IDSIA (USI &amp; SUPSI) &amp; TU Munich were the first RNNs to win official international contests. They recently helped to improve connected handwriting recognition, speech recognition, machine translation,  optical character recognition, image caption generation, and are now in use at Google, Microsoft, IBM, Baidu, and many other companies. IDSIA's Deep Learners were also the first to win object detection and image segmentation contests, and achieved the world's first superhuman visual classification results, winning nine international competitions in machine learning &amp; pattern recognition (more than any other team).  They also were the first to learn control policies directly from high-dimensional sensory input using reinforcement learning. His research group also established the field of mathematically rigorous universal AI and optimal universal problem solvers. His formal theory of creativity &amp; curiosity &amp; fun explains art, science, music, and humor. He also generalized algorithmic information theory and the many-worlds theory of physics, and introduced the concept of Low-Complexity Art, the information age's extreme form of minimal art. Since 2009 he has been member of the European Academy of Sciences and Arts. He has published 333 peer-reviewed papers, earned seven best paper/best video awards, and is recipient of the 2013 Helmholtz Award of the International Neural Networks Society.* 

",354,241,False,self,,,,,
386,MachineLearning,t5_2r3gv,2015-2-28,2015,2,28,1,2xd5gs,self.MachineLearning,Implementation of Hinton's Deep Autoencoder (Science2006) using Pylearn2,https://www.reddit.com/r/MachineLearning/comments/2xd5gs/implementation_of_hintons_deep_autoencoder/,ernsthowe,1425054830,"I want to implement a deep autoencoder, which is proposed in Hinton's Science2006 paper, for the image reconstruction. 
I have built a 784-500-250-64-250-500-784 stacked autoencoder in Pylearn2. I know how to train the part of the encoder (784-500-250-64), and I also know the weights of the decoder should be equal to the transpose of the encoder weight matrix. My first question is how to transfer this weight?
Another question is how to finetuning the whole network after pre-training? 
Anyone who did this can give me some help or some code examples to show how to do it? Many thanks!",4,0,False,self,,,,,
387,MachineLearning,t5_2r3gv,2015-2-28,2015,2,28,1,2xd7cy,self.MachineLearning,"Does DeepMind use neural net chips, or digitally simulate a neural net, or work some other way?",https://www.reddit.com/r/MachineLearning/comments/2xd7cy/does_deepmind_use_neural_net_chips_or_digitally/,jollybumpkin,1425055691,Some other way? Maybe a vast tangle of if-then-else statements it develops by trial and error... Or maybe developing algorithms by survival of the fittest... I'm not an expert by any means. Just curious.,11,0,False,self,,,,,
388,MachineLearning,t5_2r3gv,2015-2-28,2015,2,28,3,2xdod3,self.MachineLearning,Getting an RNN/LSTM to overfit?,https://www.reddit.com/r/MachineLearning/comments/2xdod3/getting_an_rnnlstm_to_overfit/,spurious_recollectio,1425062999,I've implemented both a standard RNN and LSTM and have checked via finite difference that backprop works both over timeseries and minibatches so I think my code should be more or less sane.  I started generating some synthetic (large) datasets (not unlike Alex Graves wikipedia set) to play with but after maxing out at ~60% accuracy I decided to go back and try something simpler to make _sure_ I'm doing everything correctly.  So I want to find a dataset small enough that I can easily over-fit it.  I'm doing sequence-to-sequence style stuff so my idea is to generate some random phrases and then train the network on strings of length 30-100 one character at a time.  The input will be one ascii character and the output should eb the next character (again much like Alex Graves setup).  My question is how large should I make a network to ensure that it can overfit (or that I would then know its doing something wrong if its not overfitting)?  Also if anyone has other suggestions for simple things to try I would appreciate it.,17,6,False,self,,,,,
389,MachineLearning,t5_2r3gv,2015-2-28,2015,2,28,4,2xdu40,thoughtly.co,Prototype ML/NLP Code Tutorial Series Lesson 4: Naive Bayes Classifier,https://www.reddit.com/r/MachineLearning/comments/2xdu40/prototype_mlnlp_code_tutorial_series_lesson_4/,mercurialkitten,1425065567,,0,5,False,default,,,,,
390,MachineLearning,t5_2r3gv,2015-2-28,2015,2,28,4,2xduly,store-rite.com,Pallet Flow Racking,https://www.reddit.com/r/MachineLearning/comments/2xduly/pallet_flow_racking/,similura1,1425065807,,0,1,False,default,,,,,
391,MachineLearning,t5_2r3gv,2015-2-28,2015,2,28,5,2xe5r0,self.MachineLearning,Have any of you had any experience of Hypercube by Bearingpoint?,https://www.reddit.com/r/MachineLearning/comments/2xe5r0/have_any_of_you_had_any_experience_of_hypercube/,[deleted],1425070782,"As the title says, the company I work for may be meeting the marketing guys and I wanted to see if there were any opinions.

The marketing blurb is here
http://www.bearingpoint.com/en-other/7633-5295/

Lots of articles promoting it but it seems Bearingpoint may be playing some slightly games

http://www.contrepoints.org/2013/03/01/116647-comment-les-entreprises-tentent-enjoliver-wikipedia-lexemple-bearingpoint

Google translate may help here
",0,0,False,default,,,,,
392,MachineLearning,t5_2r3gv,2015-2-28,2015,2,28,7,2xekjw,self.MachineLearning,Best way to use the GPU in a linux VM (Windows host)?,https://www.reddit.com/r/MachineLearning/comments/2xekjw/best_way_to_use_the_gpu_in_a_linux_vm_windows_host/,FiReaNG3L,1425077554,"I'm trying to figure out the best way (or any way really) to use a GPU in a linux virtual machine under a Windows host. Virtual box doesn't support passthrought, rCUDA is linux-linux only, etc...

The only way I can think of is dual boot, but that is not really a good option for me for various reasons.

Anything else is available?",7,2,False,self,,,,,
393,MachineLearning,t5_2r3gv,2015-2-28,2015,2,28,15,2xfwvi,self.MachineLearning,What is a good flexible way of playing with reinforcement learning in Python?,https://www.reddit.com/r/MachineLearning/comments/2xfwvi/what_is_a_good_flexible_way_of_playing_with/,[deleted],1425106440,"So, I've heard about Theano - but only from people using them for stuff like ImageNet - supervised learning. (That being said, I have no idea how Theano works or what it is - I am guessing it's some cool library for matrices and GPUs?).

I want to play around with reinforcement learning - which means getting flexibility in the architecture of the neural network and ability to customize learning algorithm.

What would be a good bunch of packages to use for this sort of thing? I don't want to recode a lot of things, but want the ability to. For example, if I want a specific configuration of a deep FFNN with backprop, that is something I think could be available to do in a couple of lines in relevant ML packages.

You get the point: Want to play with interesting new architectures and learning algorithms while having the ability to swiftly throw down a conventional architecture if I want. What is a good library setup? I am guessing a lot of people will recommend Theano, but what else might I need/use/want?

---

My experience with neural networks so far has been purely independent. I just coded inefficient networks using numpy arrays myself because I thought it would be a good way to learn (I never bothered making a convnet though). Now, I am ready to stop labouring and make good use of other people's work for efficiency.",3,5,False,default,,,,,
394,MachineLearning,t5_2r3gv,2015-2-28,2015,2,28,19,2xg819,mineralmetals.eleecit.com,"Mineral Metals Products, Mineral Metals Online Products, Mineral Metals Online Store, Mineral Metals Online Shop, Mineral Metals Products List, Mineral Metals Products World Wide, Global, International, Sites, Website, Eleecit",https://www.reddit.com/r/MachineLearning/comments/2xg819/mineral_metals_products_mineral_metals_online/,eleecit,1425118011,,0,1,False,default,,,,,
395,MachineLearning,t5_2r3gv,2015-2-28,2015,2,28,19,2xg8a3,blog.shriphani.com,Dimension Analysis: A Recap,https://www.reddit.com/r/MachineLearning/comments/2xg8a3/dimension_analysis_a_recap/,shriphani,1425118319,,0,17,False,http://b.thumbs.redditmedia.com/LkxZiokxJ0P6iB5CBtHF2hbfxS2vwOP2x5Jbb34xJ1M.jpg,,,,,
396,MachineLearning,t5_2r3gv,2015-2-28,2015,2,28,19,2xga9e,warwick.ac.uk,Index-learning -- a novel form of NN for UL on high-entropy data (pdf),https://www.reddit.com/r/MachineLearning/comments/2xga9e/indexlearning_a_novel_form_of_nn_for_ul_on/,[deleted],1425120644,,6,13,False,default,,,,,
