,sbr,sbr_id,date,year,month,hour,day,id,domain,title,full_link,author,created,selftext,num_comments,score,over_18,thumbnail,media_provider,media_thumbnail,media_title,media_description,media_url
0,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,9,9kbkxv,durantco.com,Durant Ambassador Series Counters and Totalizer with 3 Years Full Warranty,https://www.reddit.com/r/MachineLearning/comments/9kbkxv/durant_ambassador_series_counters_and_totalizer/,durantco,1538353937,,0,1,False,default,,,,,
1,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,10,9kbzkb,arxiv.org,[R] Large Scale GAN Training for High Fidelity Natural Image Synthesis (Google Brain),https://www.reddit.com/r/MachineLearning/comments/9kbzkb/r_large_scale_gan_training_for_high_fidelity/,milaworld,1538357161,,7,1,False,default,,,,,
2,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,11,9kcih3,self.MachineLearning,Issue with Spark Data Processing,https://www.reddit.com/r/MachineLearning/comments/9kcih3/issue_with_spark_data_processing/,PotentialFlow12,1538361348,[removed],0,1,False,self,,,,,
3,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,13,9kderh,openreview.net,[R] Instance-aware Image-to-Image Translation,https://www.reddit.com/r/MachineLearning/comments/9kderh/r_instanceaware_imagetoimage_translation/,randomstring1234,1538369573,,0,1,False,default,,,,,
4,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,14,9kdh3s,self.MachineLearning,Complete newbie: How do I train/predict Up/Downs?,https://www.reddit.com/r/MachineLearning/comments/9kdh3s/complete_newbie_how_do_i_trainpredict_updowns/,completetotalidiot,1538370213,[removed],0,1,False,self,,,,,
5,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,14,9kdr3n,medium.com,[N} Introducing best-in-class image annotation tools for computer vision applications,https://www.reddit.com/r/MachineLearning/comments/9kdr3n/n_introducing_bestinclass_image_annotation_tools/,labelbox,1538373104,,0,1,False,https://b.thumbs.redditmedia.com/_eWrqeXbvrlUZmHNH_8ynQogHUnsWGwoz1X7Dg3uijI.jpg,,,,,
6,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,15,9kdtcy,medium.com,[N] Introducing best-in-class image annotation tools for computer vision applications,https://www.reddit.com/r/MachineLearning/comments/9kdtcy/n_introducing_bestinclass_image_annotation_tools/,labelbox,1538373782,,0,1,False,default,,,,,
7,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,15,9kdzf5,self.MachineLearning,Colaboratory now offering TPUs?,https://www.reddit.com/r/MachineLearning/comments/9kdzf5/colaboratory_now_offering_tpus/,PaulConyngham,1538375660,[removed],0,1,False,https://b.thumbs.redditmedia.com/43iHu9o_1Ks_E_QiSXD86jIKJCyVWuUBGOKEQ89s6DI.jpg,,,,,
8,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,15,9ke102,self.MachineLearning,[D] What is the SOTA in Inverse Reinforcement Learning?,https://www.reddit.com/r/MachineLearning/comments/9ke102/d_what_is_the_sota_in_inverse_reinforcement/,banksyb00mb00m,1538376155,,2,1,False,self,,,,,
9,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,16,9ke81w,arxiv.org,[R] Flex-Convolution (Deep Learning Beyond Grid-Worlds) [Fast and scalable point cloud classification],https://www.reddit.com/r/MachineLearning/comments/9ke81w/r_flexconvolution_deep_learning_beyond_gridworlds/,wassname,1538378384,,2,1,False,default,,,,,
10,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,16,9ke94c,self.MachineLearning,What are some good alternatives to /r/MachineLearning?,https://www.reddit.com/r/MachineLearning/comments/9ke94c/what_are_some_good_alternatives_to/,upulbandara,1538378750,[removed],0,1,False,self,,,,,
11,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,16,9kec8o,arxiv.org,[R] My DeepMind internship project: Large-Scale GANs (BigGAN),https://www.reddit.com/r/MachineLearning/comments/9kec8o/r_my_deepmind_internship_project_largescale_gans/,ajmooch,1538379806,,60,1,False,default,,,,,
12,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,16,9keeh2,self.MachineLearning,Tips for training second stage classifier for detection model,https://www.reddit.com/r/MachineLearning/comments/9keeh2/tips_for_training_second_stage_classifier_for/,mywa11,1538380616,[removed],0,1,False,self,,,,,
13,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,17,9kegld,self.MachineLearning,[Discussion] Variational Autoencoder (VAE) VS Data Augmentation,https://www.reddit.com/r/MachineLearning/comments/9kegld/discussion_variational_autoencoder_vae_vs_data/,smallestpanhandle97,1538381362,"A section about ANNs in a book I am reading spoke of Data Augmentation as a form of regularisation. For example, passing some training data  (such as images) through some function that changes the data very slightly (such as mirroring an image) in order to allow better model generalisation.

 I have also watched a video recently on VAEs that described them almost as if the model is ""learning in its dreams"" (training on variants of data it has seen before, like a fuzzy dream).  My question is based on how these two things are different.

Is a VAE a form of Data Augmentation? Are they different due to the fact that a VAE produces, effectively, new training data based on previous material and Data Augmentation just changes existing data very slightly, as opposed to creating new data? ",1,1,False,self,,,,,
14,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,17,9kenqf,hanxiao.github.io,[P] Fashion-MNIST: Year In Review,https://www.reddit.com/r/MachineLearning/comments/9kenqf/p_fashionmnist_year_in_review/,h_xiao,1538383901,,0,1,False,default,,,,,
15,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,19,9kf4je,arxiv.org,[1809.10678] Introducing Noise in Decentralized Training of Neural Networks,https://www.reddit.com/r/MachineLearning/comments/9kf4je/180910678_introducing_noise_in_decentralized/,ihaphleas,1538389300,,0,1,False,default,,,,,
16,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,19,9kf4md,self.MachineLearning,What is the state of the art in video captioning?,https://www.reddit.com/r/MachineLearning/comments/9kf4md/what_is_the_state_of_the_art_in_video_captioning/,IntelligentSignature,1538389328,,0,1,False,self,,,,,
17,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,19,9kf5jk,medium.com,Machine learning models monitoring architectures  Part 1: ETL,https://www.reddit.com/r/MachineLearning/comments/9kf5jk/machine_learning_models_monitoring_architectures/,PycT,1538389622,,0,1,False,https://b.thumbs.redditmedia.com/5fnIn1TJS2kUXh_a_f__QdfajyPJfCr-BCQbrZoaAxs.jpg,,,,,
18,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,19,9kf6v1,self.MachineLearning,[D] What is the SOTA for video captioning?,https://www.reddit.com/r/MachineLearning/comments/9kf6v1/d_what_is_the_sota_for_video_captioning/,IntelligentSignature,1538390046,Is there something better than Watch Listen and Describe [https://arxiv.org/abs/1804.05448](https://arxiv.org/abs/1804.05448) ,6,1,False,self,,,,,
19,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,19,9kf8q3,arxiv.org,[1809.11086] Learning Recurrent Binary/Ternary Weights,https://www.reddit.com/r/MachineLearning/comments/9kf8q3/180911086_learning_recurrent_binaryternary_weights/,ihaphleas,1538390601,,0,1,False,default,,,,,
20,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,19,9kf9wv,github.com,PyCM 1.2 : Multi-class confusion matrix library in Python,https://www.reddit.com/r/MachineLearning/comments/9kf9wv/pycm_12_multiclass_confusion_matrix_library_in/,sepandhaghighi,1538390970,,0,1,False,https://b.thumbs.redditmedia.com/3xaUyzl_TlQJ7cGBCJsfK_NHpRaPnxWLBcpe7SxkHDI.jpg,,,,,
21,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,20,9kff31,self.askscience,AskScience AMA Series: We're team Vectorspace AI and here to talk about datasets based on human language and how they can contribute to scientific discovery. Ask us anything!,https://www.reddit.com/r/MachineLearning/comments/9kff31/askscience_ama_series_were_team_vectorspace_ai/,pannous,1538392483,,0,1,False,default,,,,,
22,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,20,9kff77,self.MachineLearning,[R] An Introduction to Probabilistic Programming,https://www.reddit.com/r/MachineLearning/comments/9kff77/r_an_introduction_to_probabilistic_programming/,iahtfu,1538392521,"200 page book on probabilistic programming, from [Anglican](https://probprog.github.io/anglican/index.html) devs

link: [https://arxiv.org/abs/1809.10756](https://arxiv.org/abs/1809.10756)",1,1,False,self,,,,,
23,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,20,9kfmo3,reddit.com,[AI] Brief Explain &amp; Impotance About Artificial Intelligence | /r/artificial !  r/artificial,https://www.reddit.com/r/MachineLearning/comments/9kfmo3/ai_brief_explain_impotance_about_artificial/,vepambattuchandu111,1538394583,,0,1,False,default,,,,,
24,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,21,9kfuam,i.redd.it,supervised machine learning from A to Z Details,https://www.reddit.com/r/MachineLearning/comments/9kfuam/supervised_machine_learning_from_a_to_z_details/,onclick360,1538396519,,1,1,False,https://b.thumbs.redditmedia.com/TDOoevcWdT3iEmo_q1JFAhcDnh9QHKMHc5D8ODToabY.jpg,,,,,
25,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,21,9kg0lo,arxiv.org,An Introduction to Probabilistic Programming,https://www.reddit.com/r/MachineLearning/comments/9kg0lo/an_introduction_to_probabilistic_programming/,j_orshman,1538398099,,8,1,False,default,,,,,
26,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,21,9kg0lq,self.MachineLearning,AI Weekly October 1st 2018,https://www.reddit.com/r/MachineLearning/comments/9kg0lq/ai_weekly_october_1st_2018/,TomekB,1538398099,[removed],0,1,False,self,,,,,
27,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,21,9kg0rp,thelowdownblog.com,What Algorithms Know About You Based On Your Grocery Cart,https://www.reddit.com/r/MachineLearning/comments/9kg0rp/what_algorithms_know_about_you_based_on_your/,jonfla,1538398136,,0,1,False,https://a.thumbs.redditmedia.com/lQufdOT-tfhkaCXcpHLJrQ455m9Xzj15JFukX_KNJR8.jpg,,,,,
28,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,22,9kgcy8,medium.com,[N] M12-backed TwentyBN raises $10 million to build digital companions that can see and understand,https://www.reddit.com/r/MachineLearning/comments/9kgcy8/n_m12backed_twentybn_raises_10_million_to_build/,nahuak,1538400830,,0,1,False,default,,,,,
29,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,23,9kgtt3,ambcrypto.com,Lition applies Blockchain technology and AI to accelerate the green energy revolution,https://www.reddit.com/r/MachineLearning/comments/9kgtt3/lition_applies_blockchain_technology_and_ai_to/,Lition_io,1538404313,,0,1,False,default,,,,,
30,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,23,9kgvs3,self.MachineLearning,[Discussion] Rules about using external data in research,https://www.reddit.com/r/MachineLearning/comments/9kgvs3/discussion_rules_about_using_external_data_in/,newpro_git,1538404715,"Hey everyone.
I just started in this field and confused by this question often when reading papers. It seems that some papers do this, but others are not. To make the question clear: for a given dataset that is published for research, If we can use external data for pre-train + additional technique to be better than SOTA, is it counts as research contribution? 

To break the question into details for further elaboration:
* Q1: I believe the research all agree that using ImageNet or COCO for pre-train then apply on other datasets are acceptable. But is it acceptable to use datasets other than those for pre-train? If not acceptable (i am not sure), what is the difference?
* Q2: for some datasets or competitions, e.g., [Inclusive Images challenge] (https://www.kaggle.com/c/inclusive-images-challenge/) , the rule specifically forbidden using external data. The propose of those challenges are to specifically test model ability to adapt to unknown cases and avoid overfitting (I think). However, if a published dataset does not specifically forbidden (external data). Is it ok to use them for pre-train or process before apply model to targeted dataset?
* Q3: If it is ok to use external data, and with additional techniques proposed in our paper to break a SOTA record on a dataset, can the additional techniques count as research contributions? Also is it count as good contributions (e.g., contributions in conferences like CVPR)?

Thanks in advance!",4,1,False,self,,,,,
31,MachineLearning,t5_2r3gv,2018-10-1,2018,10,1,23,9kgxrp,self.MachineLearning,Object Detection With RCNN,https://www.reddit.com/r/MachineLearning/comments/9kgxrp/object_detection_with_rcnn/,ElegantFeeling,1538405094,[removed],0,1,False,self,,,,,
32,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,0,9kh2ys,self.MachineLearning,[P] Generating Words from Embeddings,https://www.reddit.com/r/MachineLearning/comments/9kh2ys/p_generating_words_from_embeddings/,MindSustenance,1538406115,"I've been working on a project recently which involves generating new and original words from word vectors. I used a simple decoder RNN model to generate the words character by character. You can find the details in my blog post:

https://rajatvd.github.io/Generating-Words-From-Embeddings/

The code for the project is on my github here:

https://github.com/rajatvd/WordGenerator

I used pytorch along with a bunch of neat packages like [sacred](https://github.com/IDSIA/sacred) and [visdom](https://github.com/facebookresearch/visdom) for this project, and wrote up some helper packages myself as well. 

I've also added a set of pretrained weights so you guys can go ahead and directly sample words. Just follow the instructions in the repo to first get the GloVe word vectors, then go ahead and sample your own words. Do share if you encounter some really cool looking words!

",8,1,False,self,,,,,
33,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,0,9kh39k,self.MachineLearning,[D] How do you get your paper reviewed?,https://www.reddit.com/r/MachineLearning/comments/9kh39k/d_how_do_you_get_your_paper_reviewed/,ArtificialAffect,1538406171,"If you write a new paper on a task, how do you get people to review it and publish it?

I am almost done writing a paper for a conference, but that conference doesn't have any review period. It just says that it wants a  'camera ready' paper by this date. I worked on this project alone so who am I supposed to get to review my paper and make sure it is clear and understandable?",9,1,False,self,,,,,
34,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,0,9kh3kr,self.MachineLearning,[R] Entropic Optimal Transport and the Sinkhorn Iterations,https://www.reddit.com/r/MachineLearning/comments/9kh3kr/r_entropic_optimal_transport_and_the_sinkhorn/,LucaAmbrogioni,1538406229,"Hi guys! This is the third post of [our series](https://www.mindcodec.com/an-intuitive-guide-to-optimal-transport-for-machine-learning/) about optimal transport for machine learning. In [this new post](https://www.mindcodec.com/an-intuitive-guide-to-optimal-transport-part-iii-entropic-regularization-and-sinkhorn-divergences/) I explained an algorithm that is becoming very important in machine learning research: The Sinkhorn iterations. The post contains an intuitive explanation of the concept of entropic regularization for optimal transport problems and a derivation of the Sinkhorn iterations for solving the regularized problems. At the end of the post I also included a simple Python implementation of the iterations. Enjoy!

&amp;#x200B;

[An Intuitive Guide to Optimal Transport, Part III: Entropic Regularization and the Sinkhorn Iterations](https://www.mindcodec.com/an-intuitive-guide-to-optimal-transport-part-iii-entropic-regularization-and-sinkhorn-divergences/)

&amp;#x200B;

Next week I will cover some practical applications of the Sinkh9orn iterations and explain how to combine them with deep learning.",3,1,False,self,,,,,
35,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,0,9khdvp,openreview.net,Someone is posting fake positive comments on their ICLR submission,https://www.reddit.com/r/MachineLearning/comments/9khdvp/someone_is_posting_fake_positive_comments_on/,schrodingershit,1538408164,,82,1,False,default,,,,,
36,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,1,9khwfo,blog.janestreet.com,How to shuffle a big dataset (with proof and pictures),https://www.reddit.com/r/MachineLearning/comments/9khwfo/how_to_shuffle_a_big_dataset_with_proof_and/,leftic,1538411643,,0,1,False,default,,,,,
37,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,1,9ki3lb,self.MachineLearning,AI + Blockchain?,https://www.reddit.com/r/MachineLearning/comments/9ki3lb/ai_blockchain/,ZiQiLN,1538412974,[removed],0,1,False,self,,,,,
38,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,2,9ki50g,youtu.be,"New video on Proximal Policy Optimization, the Deep RL algorithm behind OpenAI Five!",https://www.reddit.com/r/MachineLearning/comments/9ki50g/new_video_on_proximal_policy_optimization_the/,tr1pzz,1538413244,,0,1,False,https://a.thumbs.redditmedia.com/CsYwdv-dyJZzAosIRdzfm7svvnBsNX0_YaqLAHa9_H8.jpg,,,,,
39,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,2,9kidwt,facebook.com,"First PyTorch Developer Conference, October 2 at 9:25 am PT.",https://www.reddit.com/r/MachineLearning/comments/9kidwt/first_pytorch_developer_conference_october_2_at/,ndha1995,1538414818,,0,1,False,default,,,,,
40,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,2,9kinef,blog.janestreet.com,[R] How to shuffle a big dataset (with proof and pictures),https://www.reddit.com/r/MachineLearning/comments/9kinef/r_how_to_shuffle_a_big_dataset_with_proof_and/,leftic,1538416560,,0,1,False,default,,,,,
41,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,3,9kiqxj,canvasdrawer.autodeskresearch.com,[R] Unsupervised stroke-based drawing agents! + scaling to 512x512 sketches.,https://www.reddit.com/r/MachineLearning/comments/9kiqxj/r_unsupervised_strokebased_drawing_agents_scaling/,kvfrans,1538417216,,1,1,False,default,,,,,
42,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,3,9kirts,self.MachineLearning,[R] Unsupervised stroke-based drawing agents! + scaling to 512x512 sketches.,https://www.reddit.com/r/MachineLearning/comments/9kirts/r_unsupervised_strokebased_drawing_agents_scaling/,kvfrans,1538417382,"This was my project over summer @ Autodesk research! Happy to answer any questions.

We spent a considerable effort on building a nice blog post with interactive demos + animated examples: http://canvasdrawer.autodeskresearch.com

Arxiv paper for technical details: https://arxiv.org/abs/1809.08340",7,1,False,self,,,,,
43,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,3,9kisz6,self.MachineLearning,[D] Question about comparing accepted but unpublished papers on ICLR reviews,https://www.reddit.com/r/MachineLearning/comments/9kisz6/d_question_about_comparing_accepted_but/,schrodingershit,1538417594,"Hi,
I was reading comments on this [ICLR Submission!](https://openreview.net/forum?id=HyG1_j0cYQ&amp;noteId=B1lSK22yqX&amp;noteId=S1luH11e5X) where someone has compared the results with NIPS 2018 papers. I know NIPS results are out but these papers are not published yet officially and are only available at ARXIV, is it a fair comparison?",6,1,False,self,,,,,
44,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,3,9kitfd,old.reddit.com,[P] Under the hood of my large scale neuroevolution simulator,https://www.reddit.com/r/MachineLearning/comments/9kitfd/p_under_the_hood_of_my_large_scale_neuroevolution/,FredrikNoren,1538417672,,1,1,False,default,,,,,
45,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,3,9kiz9y,openreview.net,[R] Machine Translation With Weakly Paired Bilingual Documents,https://www.reddit.com/r/MachineLearning/comments/9kiz9y/r_machine_translation_with_weakly_paired/,abhishek0318,1538418747,,1,1,False,default,,,,,
46,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,3,9kj06v,intelauthentic.com,Predicting Hospital Readmission Rates for Diabetic Patients - A Deep Learning Approach,https://www.reddit.com/r/MachineLearning/comments/9kj06v/predicting_hospital_readmission_rates_for/,data_science_manager,1538418898,,0,1,False,default,,,,,
47,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,4,9kjfy1,self.MachineLearning,[P] How to Use an LSTM for Timeseries and the Cold-start Problem,https://www.reddit.com/r/MachineLearning/comments/9kjfy1/p_how_to_use_an_lstm_for_timeseries_and_the/,dat-um,1538421815,"We've put together a tutorial showing how to work with LSTMs in Keras to address situations where only a small amount of data is available:

http://drivendata.co/blog/benchmark-cold-start-lstm-deep-learning/",1,1,False,self,,,,,
48,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,4,9kjl9k,self.MachineLearning,[D] I'm learning machine learning and I was curious. Can I use an AMD GPU for tensor flow gpu?,https://www.reddit.com/r/MachineLearning/comments/9kjl9k/d_im_learning_machine_learning_and_i_was_curious/,EnginesNIdiots,1538422768,,5,1,False,self,,,,,
49,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,5,9kjwqp,self.MachineLearning,[P] Can Reinforcement Learning Learn a World State?,https://www.reddit.com/r/MachineLearning/comments/9kjwqp/p_can_reinforcement_learning_learn_a_world_state/,throwaway775849,1538424911,"I boiled a complicated problem down to a toy example (I will code it up too), but need help describing or framing the problem first. I'm using RL since there are non-differentiable actions taken. It could be considered a classification problem (0 to 20).

    # (x,y) input, output pairs to learn 
    data = [(0, 7), (1, 8), (2, 9)]

    m = [8, 19, 5]

    def read(i): return m[i]

    def write(i,j):
        m[i] = j

    actions = [read, write]
    
    def reward(i, y): return m[i] == y

The goal at the end of training is that m = [7,8,9] (not necessarily in that order though). The probability of doing a 'write' action would have also reached zero. 

Each training step, you would predict action(s), 0 or 1, until 0 is predicted, at which time, compare m[i] to the true target for a binary reward. Specifically, you'd predict (0 and i) or (1, i,  and j). For clarity, ""m"" does not reset to some initial state, and is persistent across episodes. 

The world state is (x,m) and only x is observable. The agent is learning to find the state of the world 'm', where it will only have to make observations (read) and get reward. Since 'm' is not observable, this is like a random search for m. 

Where have I gone wrong with the description? 
",0,1,False,self,,,,,
50,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,5,9kk1t2,self.MachineLearning,Can GANs generate better text than char-rnn?,https://www.reddit.com/r/MachineLearning/comments/9kk1t2/can_gans_generate_better_text_than_charrnn/,tunestar2018,1538425860,[removed],0,1,False,self,,,,,
51,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,5,9kk33i,self.MachineLearning,Beginner Coder: HELP! (R and Deducer),https://www.reddit.com/r/MachineLearning/comments/9kk33i/beginner_coder_help_r_and_deducer/,-champagne-socialist,1538426095,[removed],0,1,False,self,,,,,
52,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,5,9kk7ni,arxiv.org,[R] Are adversarial examples inevitable?,https://www.reddit.com/r/MachineLearning/comments/9kk7ni/r_are_adversarial_examples_inevitable/,Seerdecker,1538426969,,11,1,False,default,,,,,
53,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,5,9kk91j,self.MachineLearning,[R] How to shuffle a big dataset,https://www.reddit.com/r/MachineLearning/comments/9kk91j/r_how_to_shuffle_a_big_dataset/,NegativeVariance,1538427242,"Here is a
[post](http://blog.janestreet.com/how-to-shuffle-a-big-dataset?utm_source=share)
about how to shuffle large datasets (where ""large"" means much larger than
fits in RAM).  I wrote it because this seems like a problem other ML
people must run into, yet when I search for how other people deal with
it, I generally find approaches that are either impractical (e.g., just do
some naive thing, but on an SSD) or don't sufficiently resemble a
random permutation (e.g., tensorflow's `dataset.shuffle` is
very good for some purposes, but for large datasets that are not
already well-mixed, it's inadequate).",20,1,False,self,,,,,
54,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,6,9kkdz1,self.MachineLearning,What kind of hardware do I need for machine learning?,https://www.reddit.com/r/MachineLearning/comments/9kkdz1/what_kind_of_hardware_do_i_need_for_machine/,mattbros,1538428169,Will any laptop do? Do I have to have a gpu? Im particularly interested in running the code from this (GitHub repository)[https://github.com/xunhuang1995/AdaIN-style]. So it looks like Id need to run Torch. What kind of hardware would I need? ,0,1,False,self,,,,,
55,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,6,9kkjpq,self.MachineLearning,What kind of hardware do I need for machine learning?,https://www.reddit.com/r/MachineLearning/comments/9kkjpq/what_kind_of_hardware_do_i_need_for_machine/,mattbros,1538429274,[removed],0,1,False,self,,,,,
56,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,6,9kkk41,self.MachineLearning,[D] Neuroevolution with Keras,https://www.reddit.com/r/MachineLearning/comments/9kkk41/d_neuroevolution_with_keras/,leekocytes,1538429346,"Has anyone seen Neuroevolution methodologies implemented with Keras? I would be interested to understand potentially taking a Neuroevolution based approach to network topologies while using Keras for the model forward and backward prop. 

Relatively new to Neuroevolution so perhaps there is a reason why this would not make sense. I realize you would still be tying yourself to differentiable models with back-prop which eliminates one of the strengths of Neuroevolution.

Would still be interesting to select and evolve network topologies in this way.",3,1,False,self,,,,,
57,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,6,9kklkp,endorsed.club,[D] Some of the best ML accounts to follow on Twitter. What are some other accounts that are good to follow?,https://www.reddit.com/r/MachineLearning/comments/9kklkp/d_some_of_the_best_ml_accounts_to_follow_on/,jacobgc75,1538429636,,0,1,False,https://b.thumbs.redditmedia.com/TVjm74wGz4rSj7UpYatBhi_5MulJn9_cqMc3w8k4PdU.jpg,,,,,
58,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,6,9kkoyb,self.MachineLearning,[D] Some of the best ML accounts to follow on Twitter. What are some other accounts that are good to follow?,https://www.reddit.com/r/MachineLearning/comments/9kkoyb/d_some_of_the_best_ml_accounts_to_follow_on/,jacobgc75,1538430299,"1. @ylecun

2. @rsalakhu

3. @karpathy

4. @hugo\_larochelle

5. @goodfellow\_ian

6. @drfeifei

7. @soumithchintala

8. @nandodf

9. @jeffdean

10. @fchollet

&amp;#x200B;

View full list: [https://www.endorsed.club/?t=0&amp;q=ml](https://www.endorsed.club/?t=0&amp;q=ml)",16,1,False,self,,,,,
59,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,7,9kl0su,self.MachineLearning,What would be the best approach to design a new deep learning framework?,https://www.reddit.com/r/MachineLearning/comments/9kl0su/what_would_be_the_best_approach_to_design_a_new/,MaherDL,1538432678,[removed],0,1,False,self,,,,,
60,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,8,9klkrl,self.MachineLearning,Resources for Dynamic bayesian networks,https://www.reddit.com/r/MachineLearning/comments/9klkrl/resources_for_dynamic_bayesian_networks/,adi1709,1538436986,[removed],0,1,False,self,,,,,
61,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,10,9km7rb,arxiv.org,[R] Predicting the Generalization Gap in Deep Networks with Margin Distributions,https://www.reddit.com/r/MachineLearning/comments/9km7rb/r_predicting_the_generalization_gap_in_deep/,downtownslim,1538442046,,0,1,False,default,,,,,
62,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,10,9kma8r,self.MachineLearning,ML PhD with Masters in Optimization,https://www.reddit.com/r/MachineLearning/comments/9kma8r/ml_phd_with_masters_in_optimization/,DarioCruiser,1538442594,[removed],0,1,False,self,,,,,
63,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,10,9kmgdy,self.MachineLearning,[D] Inductive biases for neural language models,https://www.reddit.com/r/MachineLearning/comments/9kmgdy/d_inductive_biases_for_neural_language_models/,anonDogeLover,1538443961,"What language-specific or -relevant inductive biases (architectural) exist for neural language models, especially RNNs / LSTMs?",2,1,False,self,,,,,
64,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,11,9kmqb2,self.MachineLearning,[D] Advice for career transition: How are applied lab experiences viewed?,https://www.reddit.com/r/MachineLearning/comments/9kmqb2/d_advice_for_career_transition_how_are_applied/,underwhere,1538446188,"I've tried to search past posts, but couldn't find anything on this topic.

&amp;#x200B;

My goal is to make the transition from a MS Statistics + BS Computer Science background to a ML research/programmer role in the industry. Would you say modelling experience (mix of ML and Statistics) in a science lab (like neuroimaging) will help with my career goals?

&amp;#x200B;

Previously, I spent a few years doing software engineering, but my resume is littered with ML projects. However I'm only getting interest from Data Science/Engineering roles. Any other advice would be greatly appreciated!",4,1,False,self,,,,,
65,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,11,9kmw42,self.MachineLearning,Do the new Nvidia GPUs have a substantial improvement in training time over 1080/1080ti? [Discussion],https://www.reddit.com/r/MachineLearning/comments/9kmw42/do_the_new_nvidia_gpus_have_a_substantial/,Moondra2017,1538447509,"I'm looking into buying some graphics cards for deep learning and looking into either two 1080s (so I can run two NNs at the same time) or one 1080ti, OR not sure if I should splurge extra money and buy either 2080/2080 Ti.  
I read that the newer graphics cards have tech built especially for deep learning, but not sure if the substantial price increase is worth it.   


If there is around %40-%50 increase in training improvement over 1080/1080ti I may have to reconsider. 

&amp;#x200B;

I'm currently browsing prices and doing research, but if there is great tech coming next year I can wait a bit and just buy a 1070/1080 for small projects. ",34,1,False,self,,,,,
66,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,11,9kn1f3,self.MachineLearning,Is there such a network that can output probability distributions if you have an incomplete sample?,https://www.reddit.com/r/MachineLearning/comments/9kn1f3/is_there_such_a_network_that_can_output/,1vs,1538448689,"E.g. Let's say you have 10,000 samples of 6-dimensional vectors. (E.g. Sex, height, weight, race, risk of heart disease, age of death.) You train a neural network on this.

Then, given an incomplete sample (e.g. only 4 dimensions, such as a persons, sex, height, weight, and race), the network outputs a probability distribution representing the risk of heart disease, and one representing the age of death.

If you knew different knowledge (e.g. only the persons sex) then the network would output a probability distribution for each of the remaining statistics.

I feel that this would only be useful for data with many dimensions (otherwise this is just an easy-peasy data processing problem.) Anybody have any advice here?",0,1,False,self,,,,,
67,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,12,9kn596,self.MachineLearning,Wave pattern question,https://www.reddit.com/r/MachineLearning/comments/9kn596/wave_pattern_question/,thlinks,1538449607,[removed],0,1,False,self,,,,,
68,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,12,9knfdm,self.MachineLearning,Where can machine learning be applied in software testing?,https://www.reddit.com/r/MachineLearning/comments/9knfdm/where_can_machine_learning_be_applied_in_software/,netstole,1538452140,[removed],0,1,False,self,,,,,
69,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,13,9knk8l,arxiv.org,[R] Modelling joint distribution (with high degree polynomial) of neighboring values in time series to predict probability distribution of the next value based on a few previous,https://www.reddit.com/r/MachineLearning/comments/9knk8l/r_modelling_joint_distribution_with_high_degree/,jarekduda,1538453385,,6,1,False,default,,,,,
70,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,13,9knlt2,self.MachineLearning,Model Joint Probability of N Words Appearing Together in a Sentence,https://www.reddit.com/r/MachineLearning/comments/9knlt2/model_joint_probability_of_n_words_appearing/,YuansongFeng,1538453791,[removed],0,1,False,self,,,,,
71,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,13,9knpbh,self.MachineLearning,Can we use an ascending precision for training performance improvement?,https://www.reddit.com/r/MachineLearning/comments/9knpbh/can_we_use_an_ascending_precision_for_training/,Baelfire_Nightshade,1538454792,[removed],0,1,False,self,,,,,
72,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,13,9knpr7,self.MachineLearning,[Discussion] Joint Probability of N Words Appearing Together in a Sentence,https://www.reddit.com/r/MachineLearning/comments/9knpr7/discussion_joint_probability_of_n_words_appearing/,YuansongFeng,1538454902,"Assume that we have a large corpus of texts to train with. Given N words as input, I want to model the joint probability p(x\_1, x\_2, ..., x\_N) of these words appearing together in a sentence. More specifically, the N words are not required to be ordered or contiguous, and words other than given words can appear in the sentence. There is no restriction on the number of times each of N words can appear in the sentence. I did some research and below are some possible directions.

1. Popular RNN models like LSTM offer conditional probability p(x\_t | x\_{t-1}, ..., x\_0), which may shed light on the joint probability I am modeling. However, RNN models take sequential inputs and require the N given words to be ordered. Also, if I am to use RNN models, I need to use Markov chain rule to calculate the joint probability, the N words would need to be continuous, and no words other than given words would be allowed.
2. Topic models like LSA(Latent Semantic Analysis) or LDA(Latent Dirichlet Allocation) may help me find topics from corpus, and model joint probability based on topics that each of N words belong to. Words from same topic are assigned higher joint probability. These models require me to manually set the number of topics. As I am not really familiar with these models, I am not sure how good they will perform.
3. A neural network alternative to LDA is a Restricted Boltzmann Machine, where topics are learnt as hidden neurons. The input to this RBM would be a vector the size of my whole dictionary. Each entry is either 1(present), 0(not present), or -1(dont know). During training the probability p(h|v\_{train}) is learnt, where h is my learnt topics and v are training data. At test time, the test input v\_{test} will have all N given words value equal to 1, while all other words equal to -1. In this way we can learn the probability p(v\_{test}|h).

I feel like this is a really fundamental problem in language modeling, but have not yet been able to find recent research on this. Could anyone please give any pointers on this problem? Does any of the above proposed solutions look feasible? Any help is appreciated!",10,1,False,self,,,,,
73,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,15,9koguv,self.MachineLearning,21 Curated Blogs About Deep Learning and Data Science,https://www.reddit.com/r/MachineLearning/comments/9koguv/21_curated_blogs_about_deep_learning_and_data/,andrea_manero,1538463489,r/https://www.datasciencecentral.com/profiles/blogs/21-curated-blogs-about-deep-learning-and-data-science,0,1,False,self,,,,,
74,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,16,9koiol,self.MachineLearning,Building your first Machine Learning model on iPhone,https://www.reddit.com/r/MachineLearning/comments/9koiol/building_your_first_machine_learning_model_on/,andrea_manero,1538464088,[removed],0,1,False,self,,,,,
75,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,16,9komgr,self.MachineLearning,[D] Papers accepted in NIPS workshops are not being added to any proceedings.,https://www.reddit.com/r/MachineLearning/comments/9komgr/d_papers_accepted_in_nips_workshops_are_not_being/,Hardik_Meisheri,1538465396,"Papers accepted in NIPS workshops are not being added to any proceedings. Even though they are little or incremental research, I wonder why people would submit there and not on arxiv.",25,1,False,self,,,,,
76,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,16,9koo3k,self.MachineLearning,Should I cite a paper which doesn't have any citation and haven't been published anywhere?,https://www.reddit.com/r/MachineLearning/comments/9koo3k/should_i_cite_a_paper_which_doesnt_have_any/,moewiewp,1538465984,"I recently writing a paper and while searching for literature from the internet, I stumble upon a paper which is not cited or published anywhere but reported a quite impressive performance. Should I cite that paper for comparision? I feel a little bit shady since I'm working on image denoising and a paper with that high performance is very likely be cited. ",0,1,False,self,,,,,
77,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,17,9korcu,self.MachineLearning,Remote work in ML,https://www.reddit.com/r/MachineLearning/comments/9korcu/remote_work_in_ml/,utkarshshukla2912,1538467266,[removed],0,1,False,self,,,,,
78,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,17,9kovtj,youtube.com,Rookie here: I'm doing a project where the direction of a two wheeler should be detected from camera mounted on it.,https://www.reddit.com/r/MachineLearning/comments/9kovtj/rookie_here_im_doing_a_project_where_the/,datavoyager92,1538468941,,1,1,False,https://b.thumbs.redditmedia.com/ErqLsGc0MFLfmf4EORRrGQYna2V57982A2Jp7zwi3tE.jpg,,,,,
79,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,17,9kow1m,self.MachineLearning,Structure of a multilayered LSTM neural network?,https://www.reddit.com/r/MachineLearning/comments/9kow1m/structure_of_a_multilayered_lstm_neural_network/,lyhendp,1538469024,[removed],0,1,False,self,,,,,
80,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,17,9kowxr,self.MachineLearning,Structure of a multilayered LSTM neural network?,https://www.reddit.com/r/MachineLearning/comments/9kowxr/structure_of_a_multilayered_lstm_neural_network/,lyhendo,1538469343,[removed],0,1,False,self,,,,,
81,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,17,9kox6q,self.MachineLearning,Structure of a multilayered LSTM neural network?,https://www.reddit.com/r/MachineLearning/comments/9kox6q/structure_of_a_multilayered_lstm_neural_network/,togani,1538469431,[removed],0,1,False,self,,,,,
82,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,17,9koylu,self.MachineLearning,Processing data with different number of features,https://www.reddit.com/r/MachineLearning/comments/9koylu/processing_data_with_different_number_of_features/,plusgarbage,1538469954,"hi to all, 

I have the following problem:

I have a series of data (they are temporal sequences) with features calculated on them.

The features are the derivative and other things like that.

The problem I have encountered is that since my time series have different lengths, the length of the features I'm going to calculate is variable. I can have a series of features of a timeline equal to 100 and another equal to 60. I would use a classifier (like SVM or something) to classify these data, but how should I do to obtain features with a fixed size to give to the classifier?

thank you very much",0,1,False,self,,,,,
83,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,17,9kp056,self.datascience,"[P] We're building a data versioning tool, feedback wanted!",https://www.reddit.com/r/MachineLearning/comments/9kp056/p_were_building_a_data_versioning_tool_feedback/,m88m,1538470541,,0,1,False,default,,,,,
84,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,18,9kp1hl,self.MachineLearning,"[N] PyTorch 1.0rc1 is out: torch.jit, C++ API, c10d distributed",https://www.reddit.com/r/MachineLearning/comments/9kp1hl/n_pytorch_10rc1_is_out_torchjit_c_api_c10d/,metaAI,1538471050,"[PyTorch 1.0rc1](https://github.com/pytorch/pytorch/releases) is released now ! By the way, it might also be interesting to follow up [PyTorch DeveloperConference](https://pytorch.fbreg.com/) in 02 OCT. ",51,1,False,self,,,,,
85,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,18,9kp1p8,self.MachineLearning,[Discussion] Should I cite a paper which doesn't have any citation and haven't been published anywhere?,https://www.reddit.com/r/MachineLearning/comments/9kp1p8/discussion_should_i_cite_a_paper_which_doesnt/,moewiewp,1538471126,"I recently writing a paper and while searching for literature from the internet, I stumble upon a paper which is not cited or published anywhere but reported a quite impressive performance. Should I cite that paper for comparision? I feel a little bit shady since I'm working on image restoration and a paper with that high performance is very likely be cited.",10,1,False,self,,,,,
86,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,18,9kp2a1,self.MachineLearning,Training Deep Learning Models specifically for the Web / for the Browser with Tensorflow.js,https://www.reddit.com/r/MachineLearning/comments/9kp2a1/training_deep_learning_models_specifically_for/,justadudewhohacks,1538471325,[removed],0,1,False,self,,,,,
87,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,18,9kp4ae,self.MachineLearning,[D] Training Deep Learning Models specifically for the Web / for the Browser with Tensorflow.js,https://www.reddit.com/r/MachineLearning/comments/9kp4ae/d_training_deep_learning_models_specifically_for/,justadudewhohacks,1538472003,"Hello Machine Learners,

I have recently fiddled around with training deep learning models with tensorflow.js in the browser, specifically to make them web friendly (tiny model sizes + fast inference times) and it turns out you can actually train pretty decent models, some of them even running in almost realtime on mobile devices.

So far I have trained face detectors, 68 point face landmark detectors, and a pascal voc object detection of different network complexities, but still want to experiment more with training different object detection and image classification models.

I know some people are still sceptical about in-browser machine learning, but I would be interested, if anyone else has tried something similar and if anyone has had success with training models for the browser.

Furthermore, I wrote up an article with 18 best practices for training web / tensorflow.js models in (or atleast for) the browser, which worked for me quite well: https://itnext.io/18-tips-for-training-your-own-tensorflow-js-models-in-the-browser-3e40141c9091

Would love to hear, if anyone could share their experiences here as well, since the topic of in-browser machine learning seems to be still very fresh and resources about that topic are pretty rare.",5,1,False,self,,,,,
88,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,18,9kp5mi,youtu.be,"[P] New video on the nuts and bolts of Proximal Policy Optimization, the Deep RL algorithm behind OpenAI Five!",https://www.reddit.com/r/MachineLearning/comments/9kp5mi/p_new_video_on_the_nuts_and_bolts_of_proximal/,tr1pzz,1538472478,,0,1,False,https://a.thumbs.redditmedia.com/CsYwdv-dyJZzAosIRdzfm7svvnBsNX0_YaqLAHa9_H8.jpg,,,,,
89,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,18,9kpaq2,self.MachineLearning,[D] What is the difference b/w an Indicator vector and a One-hot vector?,https://www.reddit.com/r/MachineLearning/comments/9kpaq2/d_what_is_the_difference_bw_an_indicator_vector/,the_supreme_smirk,1538474240,"Indicator vector - https://en.wikipedia.org/wiki/Indicator_vector
One hot vector - https://en.wikipedia.org/wiki/One-hot

I am asking this in context to the 2015 paper on abstractive summarisation by FAIR titled ""A Neural Attention Model for Abstractive Sentence Summarization"" (arXiv:1509.00685v2)",6,1,False,self,,,,,
90,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,19,9kpbk6,medium.com,Why Can a Machine Beat Mario but not Pokemon?,https://www.reddit.com/r/MachineLearning/comments/9kpbk6/why_can_a_machine_beat_mario_but_not_pokemon/,atomlib_com,1538474512,,0,1,False,https://b.thumbs.redditmedia.com/suRezTyvvX5sUUfZ33RXhtc-vX60pkxBzpZg5FH4Llg.jpg,,,,,
91,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,20,9kpn3x,self.MachineLearning,[D] Open Domain Question-Answering models for set queries,https://www.reddit.com/r/MachineLearning/comments/9kpn3x/d_open_domain_questionanswering_models_for_set/,blahm432,1538478227,"Are there any well-known open domain QA models that are trained to return multiple candidate answers for a given query? For example, for the query ""famous scientists that played a music instrument"" (not necessarily this complex), it should return multiple candidates (in this case, scientists) with their respective scores. ",1,1,False,self,,,,,
92,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,21,9kq73t,blog.milton.ai,Top 10 Machine Learning Accounts to Follow On Twitter,https://www.reddit.com/r/MachineLearning/comments/9kq73t/top_10_machine_learning_accounts_to_follow_on/,theNonlinearity,1538483621,,0,1,False,default,,,,,
93,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,21,9kq76s,twitter.com,Microsoft Tay-like AI version of Donald Trump,https://www.reddit.com/r/MachineLearning/comments/9kq76s/microsoft_taylike_ai_version_of_donald_trump/,JohannesT,1538483642,,0,1,False,default,,,,,
94,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,21,9kq8pv,activewizards.com,Comparison of the Most Useful Text Processing APIs,https://www.reddit.com/r/MachineLearning/comments/9kq8pv/comparison_of_the_most_useful_text_processing_apis/,viktoriia_shulga,1538484002,,0,1,False,default,,,,,
95,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,21,9kq9ob,blog.milton.ai,[D] Top 10 Accounts to Follow on Twitter,https://www.reddit.com/r/MachineLearning/comments/9kq9ob/d_top_10_accounts_to_follow_on_twitter/,theNonlinearity,1538484228,,0,1,False,https://b.thumbs.redditmedia.com/YyUf93a7AkdJDEo6VbY_J0yAkpuXRmW2Qv-gaG8UDIE.jpg,,,,,
96,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,21,9kqden,self.MachineLearning,"[N] Mujoco 2.0: muscle modelling, soft bodies, skinned meshes, faster simulation up to 40%.",https://www.reddit.com/r/MachineLearning/comments/9kqden/n_mujoco_20_muscle_modelling_soft_bodies_skinned/,metaAI,1538485121,[https://www.roboti.us/index.html#mujoco200](https://www.roboti.us/index.html#mujoco200),0,1,False,self,,,,,
97,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,22,9kql35,gmarti.gitlab.io,[D] Hierarchical Risk Parity for Asset Allocation - Implementation &amp; Experiments (Part I),https://www.reddit.com/r/MachineLearning/comments/9kql35/d_hierarchical_risk_parity_for_asset_allocation/,gau_mar,1538486772,,0,1,False,default,,,,,
98,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,22,9kqmyh,self.MachineLearning,Do convolutional layers in segmentation networks have a regularising effect?,https://www.reddit.com/r/MachineLearning/comments/9kqmyh/do_convolutional_layers_in_segmentation_networks/,limarg,1538487163,[removed],0,1,False,self,,,,,
99,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,22,9kqpmp,self.MachineLearning,[P] Using ML to digitally emulate commercial vacuum tube amplifiers and transistor-based distortion circuits for guitars,https://www.reddit.com/r/MachineLearning/comments/9kqpmp/p_using_ml_to_digitally_emulate_commercial_vacuum/,KjellJagland,1538487754,"I'm still pretty new to ML in general so forgive my ignorance. I'm interested in real-time audio signal processing using ANNs, in particular to digitally emulate commercial hardware, such as vacuum tube amplifiers and transistor-based distortion circuits for guitars (ignoring the power amp, speaker and microphone parts of the full signal chain). This is going to be an open source project, by the way.

Here's an overview of the general approach:

1. Record several clean electric guitar or bass signals, covering a wide range of possible signal workloads the emulation should be able to deal with (chords, palm muting, connected notes, disconnected notes, scratching, pinch harmonics)
2. Feed the clean signals into the device you wish to emulate and record its output using one particular set of gain, equalizer and tone shaping settings
3. Use a subset of these pairs of (clean input, distorted output) to train an ANN on a GPU
4. Evaluate the quality of the ANN using the unused signal pairs, using a metric such as root mean square error between the actual output from the circuit and the predicted output from the ANN
5. Use the ANN as a plugin (VST) for a digital audio workstation (DAW) to be able to play a guitar or a bass in real-time using a digital model of the emulated piece of hardware

I've been particularly inspired by the following papers:

* [https://arxiv.org/ftp/arxiv/papers/1804/1804.07145.pdf](https://arxiv.org/ftp/arxiv/papers/1804/1804.07145.pdf)
* [https://www.mitpressjournals.org/doi/pdf/10.1162/comj.2009.33.2.85](https://www.mitpressjournals.org/doi/pdf/10.1162/comj.2009.33.2.85)

Here are my questions:

1. Am I correct in assuming that RNNs (rather than fastfoward neural networks) are the way to go for modelling complex non-linear circuits, due to the time-variant behaviour introduced by capacitors charging and discharging, which might affect the output signal for up to 20-50 ms even without any reverb or echo effects in the signal chain?
2. Several sources I came across were pushing LSTM cells as the way to go for DSP purposes. I came across some approaches that involved spectrography in combination with CNNs for audio classification but that's a different beast. What other types of RNN cells available in TensorFlow might I want to check out? Perhaps some of them actually perform better than LSTM cells. Here's an overview: [https://www.tensorflow.org/api\_docs/python/tf/contrib/rnn](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn)
3.  Am I correct in assuming that I would likely want to run TensorFlow in CPU mode when performing the real-time simulation? It's hardly worth launching GPU kernels to execute the ANN, right? The overhead might be as great as several milliseconds for a host to device transfer, a kernel launch and a device to host transfer to push the data to the buffer of the audio device using the VST infrastructure. The latency introduced would likely ruin real-time capabilities when jamming or previewing a track. You could still use the GPU for rendering an entire song, though, I suppose.
4. What kind of approach would you recommend for supporting features such as variable gain control and different equalizer settings? For one, these could be additional inputs for the ANN, of course. I first considered an approach in which the training data would be generated for different gain settings, ranging from minimum (typically 1) to maximum (typically 10). Adding additional dimensions might be challenging. Fully training the ANN with all possible combinations might already require 10000 combinations of gain, bass, mid and treble settings being recorded, which, of course, is rather unrealistic. A more simple approach would involve keeping the other parameters constant and just generating, say, 40 samples that fully explore each potentiometer for one particular ""neutral"" position of the others. It might be possible to separate the tone layer, which tends to behave in a more linear way, from the more complex signal processing operations of the gain layer, though.

Thanks!",11,1,False,self,,,,,
100,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,23,9kr2df,robots.ox.ac.uk,[D] Seeing Voices and Hearing Faces (Blog Post),https://www.reddit.com/r/MachineLearning/comments/9kr2df/d_seeing_voices_and_hearing_faces_blog_post/,hyenal,1538490366,,0,1,False,default,,,,,
101,MachineLearning,t5_2r3gv,2018-10-2,2018,10,2,23,9kr5tf,youtube.com,"A short demo video of my data-crowdsourcing platform, Metro",https://www.reddit.com/r/MachineLearning/comments/9kr5tf/a_short_demo_video_of_my_datacrowdsourcing/,CarefulOnGambon,1538491047,,1,1,False,https://a.thumbs.redditmedia.com/N4GF4HwZwMbFJ_6DfW4T_D-msGpV6jYS-17b_lzNEz4.jpg,,,,,
102,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,0,9krt5t,self.MachineLearning,Project: Generative Model for text: An overview of recent advancements,https://www.reddit.com/r/MachineLearning/comments/9krt5t/project_generative_model_for_text_an_overview_of/,kuanchen,1538495559,"I had been interested in the generative model for text generation since I saw this [reddit discussion](https://www.reddit.com/r/MachineLearning/comments/40ldq6/generative_adversarial_networks_for_text/) two years ago answered by Dr. Goodfellow. At that time (2016), there were very few works in this field. In 2017, there was also a [discussion](https://www.reddit.com/r/MachineLearning/comments/68lyuu/d_gans_for_text_generation_progress_in_the_last/) about it. Since one of my research is related to this field and there is few source to discuss this topic, I would like to share my collection of work and wrap them in an article to summarize the recent development (from 2016 to now) .   


[https://www.kuanchchen.com/post/nlp\_generative\_model/](https://www.kuanchchen.com/post/nlp_generative_model/)  


Hope you enjoy, any feedback or suggestion are welcome :)  
",0,1,False,self,,,,,
103,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,1,9krwfv,self.MachineLearning,[P] Generative Model for text: An overview of recent advancements,https://www.reddit.com/r/MachineLearning/comments/9krwfv/p_generative_model_for_text_an_overview_of_recent/,kuanchen,1538496185,"I had been interested in the generative model for text generation since I saw this Reddit [discussion](https://www.reddit.com/r/MachineLearning/comments/40ldq6/generative_adversarial_networks_for_text/) two years ago answered by Dr. Goodfellow. At that time (2016), there were very few works in this field. In 2017, there was also a [discussion](https://www.reddit.com/r/MachineLearning/comments/68lyuu/d_gans_for_text_generation_progress_in_the_last/) about it. Since one of my research is related to this field and there are few sources to discuss this topic, I would like to share my collection of works and wrap them in an article to summarize the recent development (from 2016 to now) of this topic. Hope you enjoy!   


[https://www.kuanchchen.com/post/nlp\_generative\_model/](https://www.kuanchchen.com/post/nlp_generative_model/)  


Any feedback or suggestion are welcome :)",7,1,False,self,,,,,
104,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,1,9krwhx,openreview.net,[R] Rethinking the Value of Network Pruning,https://www.reddit.com/r/MachineLearning/comments/9krwhx/r_rethinking_the_value_of_network_pruning/,downtownslim,1538496195,,10,1,False,https://a.thumbs.redditmedia.com/O5xSqPxXQan0eq4XIj_39G9lsyFLtyg3D_81hYNOIr4.jpg,,,,,
105,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,1,9kryoj,self.MachineLearning,Can I run custom-trained TF Mask RCNN models on the Jetson TX2 / TensorRT ?,https://www.reddit.com/r/MachineLearning/comments/9kryoj/can_i_run_customtrained_tf_mask_rcnn_models_on/,rgb_input,1538496587,[removed],0,1,False,self,,,,,
106,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,1,9ks1kq,colab.research.google.com,[D] ICLR 2019 analysis by Harvard NLP,https://www.reddit.com/r/MachineLearning/comments/9ks1kq/d_iclr_2019_analysis_by_harvard_nlp/,sksq9,1538497133,,0,1,False,https://b.thumbs.redditmedia.com/M5QUr5L8doQM_eXAIIaxPjjHd-WmlbBJLU3zSVnyO2M.jpg,,,,,
107,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,2,9ksmzb,gereshes.com,An Introduction to Gradient Descent,https://www.reddit.com/r/MachineLearning/comments/9ksmzb/an_introduction_to_gradient_descent/,Gereshes,1538501062,,0,1,False,default,,,,,
108,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,2,9ksnah,code.fb.com,Facebook accelerates AI development with new partners and production capabilities for PyTorch 1.0,https://www.reddit.com/r/MachineLearning/comments/9ksnah/facebook_accelerates_ai_development_with_new/,balazshoranyi,1538501118,,0,1,False,default,,,,,
109,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,2,9kssod,i.redd.it,Rise of the Machines,https://www.reddit.com/r/MachineLearning/comments/9kssod/rise_of_the_machines/,thepseudeone,1538502101,,0,1,False,https://a.thumbs.redditmedia.com/xttNqQTDqNn3T8LMTtG2s5U77aKPOHZjAj-rwloiYX0.jpg,,,,,
110,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,2,9ksxmb,self.MachineLearning,[D] which is better for pre-learning : q- value or policy gradient ??,https://www.reddit.com/r/MachineLearning/comments/9ksxmb/d_which_is_better_for_prelearning_q_value_or/,temptempyahoo,1538502998,"I can train a large network for an agent in my mdp world. I hope to use the ""lower levels"" as a pre-trained features for other problems where I have less data.

Dos this make sense ?

If so - should I train the first large network as a value network or a policy network ?
",6,1,False,self,,,,,
111,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,3,9kt281,self.MachineLearning,Classification and Mapping,https://www.reddit.com/r/MachineLearning/comments/9kt281/classification_and_mapping/,aunitpls,1538503848,"I want to be able to detect a defect on the surface and keep track what part of the surface that image was from. Is there a way to do this with ML. At the end, I want to have a map with defect locations. ",0,1,False,self,,,,,
112,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,3,9kt3ox,medium.com,BigGAN: A New State of the Art in Image Synthesis,https://www.reddit.com/r/MachineLearning/comments/9kt3ox/biggan_a_new_state_of_the_art_in_image_synthesis/,trcytony,1538504113,,0,1,False,https://a.thumbs.redditmedia.com/ivcc0zBMiTJtBuMC_eLe-y-TvFyHO1Z1GtkGBctSV78.jpg,,,,,
113,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,3,9kte26,blog.shahinrostami.com,Machine Learning with Kaggle Kernels - Part 1,https://www.reddit.com/r/MachineLearning/comments/9kte26/machine_learning_with_kaggle_kernels_part_1/,shahinrostami,1538505996,,0,1,False,default,,,,,
114,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,3,9kteuv,blog.shahinrostami.com,Machine Learning with Kaggle Kernels - Part 1,https://www.reddit.com/r/MachineLearning/comments/9kteuv/machine_learning_with_kaggle_kernels_part_1/,shahinrostami,1538506150,,1,1,False,https://b.thumbs.redditmedia.com/mfohFHqOFNF2r1lK6kXpcpCqSt6DVOTqxCBUgX0-LbM.jpg,,,,,
115,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,4,9ktjw5,self.MachineLearning,[P] Food recognition model for class project on machine learning?,https://www.reddit.com/r/MachineLearning/comments/9ktjw5/p_food_recognition_model_for_class_project_on/,badboyyy112,1538507085,"So I'm taking an ML class and my prof said she wants to see novel project ideas. I know food recognition is not too novel but it doesn't seem like a done and dusted problem yet. (AFAIK..)

Do you guys think it is doable? Any other ideas/suggestions for good projects for ML class ( as in idk a lot of deep learning stuff)

Thanks!",6,1,False,self,,,,,
116,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,4,9ktu97,self.MachineLearning,[D] An Introduction to Gradient Descent,https://www.reddit.com/r/MachineLearning/comments/9ktu97/d_an_introduction_to_gradient_descent/,Gereshes,1538508983,"Hey,

&amp;#x200B;

I've been writing a series on numerical methods and the latest post, [An Introduction to Gradient Descent](https://gereshes.com/2018/10/01/an-introduction-to-gradient-descent/), has been getting a lot of comments from people in intro machine learning classes about how it's helping clear up some confusion they had with gradient descent.

&amp;#x200B;

Hopefully it's also useful here!",7,1,False,self,,,,,
117,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,5,9ku9i6,self.MachineLearning,"[D] If I want to train Torch-RNN on a set of images, could I use base64 encoding/decoding?",https://www.reddit.com/r/MachineLearning/comments/9ku9i6/d_if_i_want_to_train_torchrnn_on_a_set_of_images/,JesseOS,1538511834,Would this work? I honestly know nothing about base64.,9,1,False,self,,,,,
118,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,5,9kujen,self.MachineLearning,GPU vs CPU on batch size of 1?,https://www.reddit.com/r/MachineLearning/comments/9kujen/gpu_vs_cpu_on_batch_size_of_1/,trubo793,1538513713,"Does anyone know which is superior? My naive implementation makes a CPU version (pytorch) vastly outperform the GPU version.


In case anyone is wondering, you can't have batches when input is of unique variable length (that is, you can't even find inputs that have the same length and batch them together, even if that was a good idea - bias) and when you introduce routing (decisions on which layers to kill for a specific input) the disparity only increases, by a lot.",0,1,False,self,,,,,
119,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,6,9kulir,stackoverflow.com,RandomForestClassifier .fit fails with Memory Error on ec2 but runs without error locally,https://www.reddit.com/r/MachineLearning/comments/9kulir/randomforestclassifier_fit_fails_with_memory/,ankit481,1538514104,,1,1,False,https://b.thumbs.redditmedia.com/iyke0KM1eHtHsU1EDTbXBmgPxGkCsIz8JHaBfgzwebc.jpg,,,,,
120,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,6,9kumhv,self.MachineLearning,"Is there any open source implementation of the paper - ""FACE AGING WITH CONDITIONAL GENERATIVE ADVERSARIAL NETWORKS"" https://arxiv.org/pdf/1702.01983.pdf ?",https://www.reddit.com/r/MachineLearning/comments/9kumhv/is_there_any_open_source_implementation_of_the/,kailashahirwar12,1538514282,[removed],0,1,False,self,,,,,
121,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,6,9kutgy,blog.shahinrostami.com,[P] Machine Learning with Kaggle Kernels - Part 1,https://www.reddit.com/r/MachineLearning/comments/9kutgy/p_machine_learning_with_kaggle_kernels_part_1/,shahinrostami,1538515587,,1,1,False,https://b.thumbs.redditmedia.com/mfohFHqOFNF2r1lK6kXpcpCqSt6DVOTqxCBUgX0-LbM.jpg,,,,,
122,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,6,9kuvbx,self.MachineLearning,[P] Machine Learning with Kaggle Kernels - Part 1,https://www.reddit.com/r/MachineLearning/comments/9kuvbx/p_machine_learning_with_kaggle_kernels_part_1/,shahinrostami,1538515956,"https://blog.shahinrostami.com/2018/10/machine-learning-with-kaggle-kernels-part-1/

Hope this is interesting for you, maybe the easy level of difficulty is unsuitable for this sub-reddit. My desire when writing this was to create a gentle introduction to all the tools covered, mostly by using the most straightforward code for whatever I was trying to achieve. This is the first part of a four part series, and what follows will be an experimental design, an implementation, and discussion of the results.

Corrections are welcome... if I receive any I will add credits in the article.",3,1,False,self,,,,,
123,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,6,9kuyhk,self.MachineLearning,Custom Activation Function,https://www.reddit.com/r/MachineLearning/comments/9kuyhk/custom_activation_function/,Aesix,1538516585,[removed],0,1,False,self,,,,,
124,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,6,9kv1re,github.com,"Supersymmetric Artificial Neural Network (""Thought Curvature"")",https://www.reddit.com/r/MachineLearning/comments/9kv1re/supersymmetric_artificial_neural_network_thought/,ProgrammingGodJordan,1538517231,,0,1,False,default,,,,,
125,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,7,9kvdlt,self.MachineLearning,"What feedback clients usually give in data science projects, e.g., in classification/prediction models, and what is the parameter?",https://www.reddit.com/r/MachineLearning/comments/9kvdlt/what_feedback_clients_usually_give_in_data/,labelmine,1538519694,[removed],0,1,False,self,,,,,
126,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,7,9kvex9,github.com,Geometric computer vision library for PyTorch,https://www.reddit.com/r/MachineLearning/comments/9kvex9/geometric_computer_vision_library_for_pytorch/,shagunsodhani,1538519979,,0,1,False,default,,,,,
127,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,7,9kvgy1,self.MachineLearning,[D] Michael Bronstein (and probably others) posting repeatedly on OpenReview and telling people to cite his unreviewed papers,https://www.reddit.com/r/MachineLearning/comments/9kvgy1/d_michael_bronstein_and_probably_others_posting/,mrshitwheel,1538520405,"I work on graphs and attention and while looking through the openreview I noticed that Michael Bronstein had posted on at least four papers, telling authors that they needed to cite his works, including a paper of his which was posted on arXiv in June and is not in any conference. Based on the style it looks like a NIPS submission, which would mean it's a NIPS reject!

These are the papers I found (there are probably more) where he came in and told the authors they needed to cite his ""important baselines:""
https://openreview.net/forum?id=HJePRoAct7
https://openreview.net/forum?id=HylsgnCcFQ
https://openreview.net/forum?id=H1ewdiR5tQ
https://openreview.net/forum?id=H1g0Z3A9Fm

Of all the works he requested people cite, only TWO were not from him or authors in his group!

This seems very unprofessional and against the spirit of the community, especially since his comments can influence reviewers and make them force the authors to cite his unreviewed (and completely uncited except for a self-citation!) papers. Do we think this kind of ""schmidhubering"" is acceptable? If it's not, what should be done about it?",43,1,False,self,,,,,
128,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,7,9kvgz1,self.MachineLearning,[N] Introducing PyTorch across Google Cloud,https://www.reddit.com/r/MachineLearning/comments/9kvgz1/n_introducing_pytorch_across_google_cloud/,hardmaru,1538520411,"Google Cloud announce support for PyTorch 1.0 on:

- Deep Learning VM Images

- Kubeflow

- TensorBoard integration

- PyTorch on Cloud TPUs

Source: https://cloud.google.com/blog/products/ai-machine-learning/introducing-pytorch-across-google-cloud",6,1,False,self,,,,,
129,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,8,9kvljx,self.MachineLearning,[R] Differences between different types of Active Learning?,https://www.reddit.com/r/MachineLearning/comments/9kvljx/r_differences_between_different_types_of_active/,MrLeylo,1538521386,"Hello /r/MachineLearning,

First of all, I don't know if that post should be here or in /r/MLQuestions, so if I am not posting on the most appropiate subreddit I apologize for it and ask you to tell me it so the next time I can do it better.

Now, I am currently working on something related to Active Learning in a Meta-Learning setting (*learning to select the best samples to learn*). Summarizing the problem, it consists in learning to pick samples from a set of unlabelled instances for further labelling and supervised learning (but only with those few picked ones). We could see Active Learning as an specific type of Budgeted Learning problems, where the labels have some cost and we have to label just the most informative ones.

As far as I know, we can classify Active Learning into *Static* (where the system selects the samples to label from a pool of unlabelled instances at once, for further labelling of the whole subset) or *Sequential* (where we label some picked samples before picking the rest). Furthermore, in the case of *Sequential Active Learning* we have a specific setting which is *Stream-based*, which has the scenario of samples arriving sequentially, so once a sample arrives the system decides to label it or not, and trains the model before more samples arrive. Else, we have a *Sequential Pool Based Active Learning* problem, where the setting is again having a pool of instances and unlike in*Static Active Learning* we pick the samples and label them sequentially.

And here come my doubts. I am a little bit confused about the *Sequential Active Learning* problems. 

My first doubt is, does *Sequential Active Learning*  necessarily train the model at each picking and labelling of samples? That is, imagine that one by one you pick the samples and label them. For each sample you have into account the labels of the previous samples, but you don't update the model. Is it *Sequential Active Learning*, since you don't pick the samples all at once before labelling, or is it *Static Active Learning* since you don't train the model until the end of the episode?

My second doubt is about the classification of the *Sequential Active Learning* approaches. I know they can split between *Single-Instance* or *Batch* mode. I understand that Single-Instance is one by one, but I don't know clearly if Batch mode is just picking samples by batches for labelling them iteratively until the system picks all the samples it needs for the episode. If that's so, I find it kind of strange since batches should be really small because normally the amount of samples the problem requires is also pretty small. Moreover, if you look at [Ravi and Larochelle's paper on Active Learning](https://openreview.net/pdf?id=r1PsGFJPz) they seem to face a different problem, since they have a given support (or training, in the other nomenclature) set and they have to select a batch to add to it.

As I said, I find pretty strange what I understand for it, and that's why I'm asking for help. In fact, I find it a very interesting problem but all details should be tied.

Thank you in advanced.",4,1,False,self,,,,,
130,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,8,9kvspp,self.MachineLearning,What papers/articles/guides are a must read if I want to learn how to implement a neural network with distribuited training?,https://www.reddit.com/r/MachineLearning/comments/9kvspp/what_papersarticlesguides_are_a_must_read_if_i/,itcouldbemuchworse,1538522895,[removed],0,1,False,self,,,,,
131,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,9,9kw8gc,blog.christianperone.com,[P] PyTorch 1.0 tracing JIT and LibTorch C++ API to integrate PyTorch into NodeJS,https://www.reddit.com/r/MachineLearning/comments/9kw8gc/p_pytorch_10_tracing_jit_and_libtorch_c_api_to/,perone,1538526322,,0,1,False,default,,,,,
132,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,9,9kwdhj,forums.xilinx.com,AMD and Xilinx announce AI inference world record,https://www.reddit.com/r/MachineLearning/comments/9kwdhj/amd_and_xilinx_announce_ai_inference_world_record/,invest2018,1538527464,,1,1,False,https://b.thumbs.redditmedia.com/o9DBl2_J1teiva6rhdahbXM83xLywBggbQAD4ISu9iQ.jpg,,,,,
133,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,10,9kwvat,self.MachineLearning,[GITHUB] Lightning speed web scraper for Shutterstock and GettyImages,https://www.reddit.com/r/MachineLearning/comments/9kwvat/github_lightning_speed_web_scraper_for/,affinitive2,1538531500,[removed],1,1,False,self,,,,,
134,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,12,9kxkvh,self.MachineLearning,[D] Use Gradient-Based Methods to Approximate Genetic Algorithms to Learn Weights in Deep NN,https://www.reddit.com/r/MachineLearning/comments/9kxkvh/d_use_gradientbased_methods_to_approximate/,throwaway775849,1538537301,"A few papers in the past year or so used Evolutionary Strategies and Genetic Algorithms to learn weights for deep nets. One key benefit being their scalability. Most people don't have access to 800 CPU's though.


Is there generally a rate limiting step across most genetic algorithms? If so, could you approximate it? 
",15,1,False,self,,,,,
135,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,12,9kxs8f,self.MachineLearning,Looking for an autoencoder with skip connections sample network for Pytorch,https://www.reddit.com/r/MachineLearning/comments/9kxs8f/looking_for_an_autoencoder_with_skip_connections/,soulslicer0,1538539148,[removed],0,1,False,self,,,,,
136,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,13,9kxsjo,self.MachineLearning,[D] Looking for a simple Pytorch example of an Autoencoder with Skip Connections,https://www.reddit.com/r/MachineLearning/comments/9kxsjo/d_looking_for_a_simple_pytorch_example_of_an/,soulslicer0,1538539225,"I've been trying to transition from Caffe to Pytorch, and I have been struggling to find a simple Autoencoder with Skip connections example I can look at in Pytorch. Is anyone able to direct me to such a thing so that I may implement it for my own code",3,1,False,self,,,,,
137,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,13,9ky1l4,self.MachineLearning,Interpreting Neural Networks for Classification,https://www.reddit.com/r/MachineLearning/comments/9ky1l4/interpreting_neural_networks_for_classification/,bluesky314,1538541542,[removed],0,1,False,self,,,,,
138,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,13,9ky1v1,self.MachineLearning,Any examples where i can input image in CNN and output image.,https://www.reddit.com/r/MachineLearning/comments/9ky1v1/any_examples_where_i_can_input_image_in_cnn_and/,dvijayd,1538541614,[removed],0,1,False,self,,,,,
139,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,14,9kyfoy,self.MachineLearning,Newbie,https://www.reddit.com/r/MachineLearning/comments/9kyfoy/newbie/,Lel2357,1538545452,[removed],0,1,False,self,,,,,
140,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,15,9kyp4k,self.MachineLearning,Keras Dnn binary classification problem,https://www.reddit.com/r/MachineLearning/comments/9kyp4k/keras_dnn_binary_classification_problem/,BoldriniCoder,1538548238,[removed],0,1,False,self,,,,,
141,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,15,9kys38,self.MachineLearning,"[R] Frameworks mentioned @ICLR 2018-2019: {TensorFlow 228-&gt;266}, {Keras: 42-&gt;56}, {Pytorch 87-&gt;252}",https://www.reddit.com/r/MachineLearning/comments/9kys38/r_frameworks_mentioned_iclr_20182019_tensorflow/,Temporary_Goup,1538549169,"Looks like Pytorch made some big adoption gains @ICLR2019 this year.

Sources:

http://search.iclr2018.smerity.com/search/?query=tensorflow
http://search.iclr2019.smerity.com/search/?query=tensorflow
http://search.iclr2018.smerity.com/search/?query=keras
http://search.iclr2019.smerity.com/search/?query=keras
http://search.iclr2018.smerity.com/search/?query=pytorch
http://search.iclr2019.smerity.com/search/?query=pytorch",68,1,False,self,,,,,
142,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,15,9kys9a,self.MachineLearning,Signal Processing or Machine Learning good field to study,https://www.reddit.com/r/MachineLearning/comments/9kys9a/signal_processing_or_machine_learning_good_field/,Shagggggeeee,1538549219,"s too many people doing AI

Would signal processing be a better career path.

I actually love mathematics and both seem really good paths to take.

AI and ML seem to have cooler applications, but way too many ppl trying to get in the field

Signal Processing is enriching too (mathematically). It's interesting to research but I don't like there's much envelope to push as AI, plus the applications don't sound as cool tbh",0,1,False,self,,,,,
143,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,16,9kyx89,rubikscode.net,Introduction to Restricted Boltzmann Machines,https://www.reddit.com/r/MachineLearning/comments/9kyx89/introduction_to_restricted_boltzmann_machines/,RubiksCodeNMZ,1538550728,,0,1,False,default,,,,,
144,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,16,9kz1x6,self.MachineLearning,About Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9kz1x6/about_machine_learning/,NearLearnguru,1538552226,[removed],0,1,False,self,,,,,
145,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,16,9kz4qd,self.MachineLearning,Lyrebird AI,https://www.reddit.com/r/MachineLearning/comments/9kz4qd/lyrebird_ai/,n1ksp,1538553177,[removed],0,1,False,self,,,,,
146,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,17,9kz8j1,self.MachineLearning,All GANs dynamic search,https://www.reddit.com/r/MachineLearning/comments/9kz8j1/all_gans_dynamic_search/,hollobit,1538554489,"I have updated ""All About the GANs"" list.  

&amp;#x200B;

Here was added to the arXiv papers that were registered until September and the GANs related papers published by ECCV 2018 and MICCAI 2018.

&amp;#x200B;

There are 1631 articles in this list. There are about 257 medical / bio related GANs papers.

&amp;#x200B;

I also add to dynamic search functionality. Now, anyone can find GANs articles more easily.

&amp;#x200B;

I would like to help those who want to research or develop based on the GANs model. If you have any further suggestions or comments please let me know.

&amp;#x200B;

[https://github.com/hollobit/All-About-the-GAN/](https://github.com/hollobit/All-About-the-GAN/)

[https://hollobit.github.io/All-About-the-GAN/](https://hollobit.github.io/All-About-the-GAN/)

[https://hollobit.github.io/All-About-the-GAN/search.html](https://hollobit.github.io/All-About-the-GAN/search.html)

&amp;#x200B;",0,1,False,self,,,,,
147,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,18,9kzqct,pdfs.semanticscholar.org,papers needed to detect suspicious behaviour,https://www.reddit.com/r/MachineLearning/comments/9kzqct/papers_needed_to_detect_suspicious_behaviour/,umanaga9,1538560469,,0,1,False,default,,,,,
148,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,18,9kzr8o,self.MachineLearning,[D] Making an unofficial place to publish replication studies,https://www.reddit.com/r/MachineLearning/comments/9kzr8o/d_making_an_unofficial_place_to_publish/,Phylliida,1538560770,"Replicating someone elses work is a vital part of science, and seems to be neglected in the Machine Learning domain because it is so much work and hard to publish.

This is a problem. Id propose that we create a place where we can submit detailed reproduction studies, with:

1. Details about what didnt work
2. Open source code that is relatively easy to install and use
3. Measurements on publically available datasets when the original data is not publically available
4. Detailed description of hyperparamaters 
5. Non-trivial implementation details not mentioned in the work

Where of course it is perfectly valid for the author(s) of the original paper to be the ones that submit this, but anyone else can as well.

Does this exist? If not, is this a good idea? What do you all think? What are other ways we can solve this lack of replication studies? 

",37,1,False,self,,,,,
149,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,19,9l018k,kaggle.com,Using Linear Regression to understand a Footballer's Value,https://www.reddit.com/r/MachineLearning/comments/9l018k/using_linear_regression_to_understand_a/,maurya96,1538563737,,0,1,False,default,,,,,
150,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,19,9l02dv,marketersmedia.com,Aloha Technology Helps Global Companies Race to the Top With Artificial Intelligence and Machine Learning  MarketersMEDIA ,https://www.reddit.com/r/MachineLearning/comments/9l02dv/aloha_technology_helps_global_companies_race_to/,kiranhoku,1538564062,,0,1,False,default,,,,,
151,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,19,9l039v,palin.co.in,Machine Learning K-Nearest Neighbors (KNN) Algorithm: Palin Analytics,https://www.reddit.com/r/MachineLearning/comments/9l039v/machine_learning_knearest_neighbors_knn_algorithm/,PalinTechnologies,1538564294,,0,1,False,default,,,,,
152,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,20,9l07kk,self.MachineLearning,"I'm an oncology resident with ML knowledge, and I'm looking for people or projects to join to work on medical applicabilities",https://www.reddit.com/r/MachineLearning/comments/9l07kk/im_an_oncology_resident_with_ml_knowledge_and_im/,FrenchDizzie,1538565409,[removed],0,1,False,self,,,,,
153,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,20,9l07u2,palin.co.in,Difference Between Population And Sampling With Example,https://www.reddit.com/r/MachineLearning/comments/9l07u2/difference_between_population_and_sampling_with/,PalinTechnologies,1538565474,,0,1,False,default,,,,,
154,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,21,9l0r6b,self.MachineLearning,h2o on kaggle,https://www.reddit.com/r/MachineLearning/comments/9l0r6b/h2o_on_kaggle/,HellSingYang,1538570174,[removed],0,1,False,self,,,,,
155,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,21,9l0t6r,reddit.com,GANsResearch: To have discussions on the progress and advancements in gans.  r/GANsResearch,https://www.reddit.com/r/MachineLearning/comments/9l0t6r/gansresearch_to_have_discussions_on_the_progress/,kailashahirwar12,1538570626,,0,1,False,https://b.thumbs.redditmedia.com/LWH4hghCeSEDMsOyLAQtmbIvnQ8gVBTPUaKi_6JHYgw.jpg,,,,,
156,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,21,9l0v8r,self.MachineLearning,Predictive Analysis project for a class : any suggestions what to work on?,https://www.reddit.com/r/MachineLearning/comments/9l0v8r/predictive_analysis_project_for_a_class_any/,Yeamf93,1538571100,[removed],0,1,False,self,,,,,
157,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,21,9l0vwm,self.MachineLearning,[R] TDLS: Prediction of Cardiac Arrest from Physiological Signals in the Pediatric ICU,https://www.reddit.com/r/MachineLearning/comments/9l0vwm/r_tdls_prediction_of_cardiac_arrest_from/,tdls_to,1538571246,"In this paper the authors use LSTMs to use different vital signals to predict the onset of cardiac arrest and then an ensemble method to combine all the predictors. They get more than 80% predictability (F1 score)

Paper review (by the author): [https://youtu.be/QcHoHljBxsk](https://youtu.be/QcHoHljBxsk)

ref: [https://static1.squarespace.com/static/59d5ac1780bd5ef9c396eda6/t/5b73738d88251beb6017ede8/1534343143656/Tonekaboni\_S](https://static1.squarespace.com/static/59d5ac1780bd5ef9c396eda6/t/5b73738d88251beb6017ede8/1534343143656/Tonekaboni_S)

&amp;#x200B;

abstract: Cardiac arrest is a rare but devastating event in critically ill children associated with death, disability and significant healthcare costs. When a cardiac arrest occurs, the limited interventions available to save patient lives are associated with poor patient outcomes. The most effective way of improving patient outcomes and decreasing the associated healthcare costs would be to prevent cardiac arrest from occurring. This observation highlights the importance of prediction models that consistently identify high risk individuals and assist health care providers in providing targeted care to the right patient at the right time. In this paper, we took advantage of the power of convolutional neural networks (CNN) to extract information from high resolution temporal data, and combine this with a recurrent network (LSTM) to model time dependencies that exist in these temporal signals. We trained this CNN+LSTM model on high-frequency physiological measurements that are recorded in the ICU to facilitate early detection of a potential cardiac arrest at the level of the individual patient. Our model results in an F1 value of .61 to .83 across six different physiological signals, the most predictive single signal being the heart rate. To address the issue of instances of missing data in the recorded physiological signals, we have also implemented an ensemble model that combines predictors for the signals that were collected for a given patient. The ensemble achieves .83 average F1 score on a held-out test set, on par with the best performing signal, even in the absence of a number of signals. The results of our model are clinically relevant. We intend to explore implementation of this model at the point of care as a means of providing precise, personalized, predictive care to an at-risk cohort of patients.",4,1,False,self,,,,,
158,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,22,9l0yzd,self.MachineLearning,DDD : The Databases for Drug Discovery,https://www.reddit.com/r/MachineLearning/comments/9l0yzd/ddd_the_databases_for_drug_discovery/,ljhyun33,1538571914,[removed],0,1,False,self,,,,,
159,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,22,9l1btx,github.com,[P] Markov.js - A simple library to generate text in the browser using Markov chains,https://www.reddit.com/r/MachineLearning/comments/9l1btx/p_markovjs_a_simple_library_to_generate_text_in/,Paletton,1538574611,,0,1,False,default,,,,,
160,MachineLearning,t5_2r3gv,2018-10-3,2018,10,3,23,9l1hio,self.MachineLearning,"TIL about FindResearch.org - collection of research papers with corresponding code and dataset links, verfied by authors",https://www.reddit.com/r/MachineLearning/comments/9l1hio/til_about_findresearchorg_collection_of_research/,olBaa,1538575739,[removed],0,1,False,self,,,,,
161,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,0,9l1zcr,twimlai.com,"[N] If you're interested in the new Fastai v1 Deep Learning Framework, check out this interview with fast.ai founder Jeremy Howard from the This Week in ML &amp; AI Podcast. Sam and Jeremy explore why the update is important and whats changed, how it was developed, the future of the course &amp; more.",https://www.reddit.com/r/MachineLearning/comments/9l1zcr/n_if_youre_interested_in_the_new_fastai_v1_deep/,Fatman_Johnson,1538579171,,0,1,False,https://a.thumbs.redditmedia.com/OPdTPpceXRi_UJIJ2mInPWp913nLylqc0UwhYSKeXN0.jpg,,,,,
162,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,0,9l20ot,self.MachineLearning,Categorical and continuous dataset for outlier detection,https://www.reddit.com/r/MachineLearning/comments/9l20ot/categorical_and_continuous_dataset_for_outlier/,abhishexreddit,1538579421,[removed],0,1,False,self,,,,,
163,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,0,9l2115,self.MachineLearning,"[D] OpennMT, Fairseq or your implementation? , which one you use for prototyping Seq2Seq models",https://www.reddit.com/r/MachineLearning/comments/9l2115/d_opennmt_fairseq_or_your_implementation_which/,pigdogsheep,1538579493,"Several Seq2Seq libraries has been around for a while such as [OpenNMT](https://github.com/OpenNMT/OpenNMT-py), [Fairseq](https://github.com/pytorch/fairseq/) their contain many models ranging from vanilla Seq2Seq, Copy actions, CNN encoders, Self Attention etc. yet still many researchers rely on their own [implementation](https://github.com/eladhoffer/seq2seq.pytorch) 

What is the pros/cons or each If you are  starting a new project (including potentially adapting one of the model's architecture).   


  
",6,1,False,self,,,,,
164,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,0,9l24jw,self.MachineLearning,Has anyone made a business out of publicly available data?,https://www.reddit.com/r/MachineLearning/comments/9l24jw/has_anyone_made_a_business_out_of_publicly/,nikogamulin,1538580178,[removed],0,1,False,self,,,,,
165,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,0,9l29fz,self.MachineLearning,External memory architectures applied to RL?,https://www.reddit.com/r/MachineLearning/comments/9l29fz/external_memory_architectures_applied_to_rl/,fosa2,1538581059,"""Learning to Remember, Forget and Ignore using Attention Control in Memory""  [https://arxiv.org/abs/1809.11087](https://arxiv.org/abs/1809.11087)

This is so cool. Has anyone come across a paper or thought much about combining RL with external memory?",0,1,False,self,,,,,
166,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,0,9l2f1o,self.MachineLearning,PyTorch Geometry: a geometric computer vision library for PyTorch.,https://www.reddit.com/r/MachineLearning/comments/9l2f1o/pytorch_geometry_a_geometric_computer_vision/,edgarriba,1538582115,[removed],0,1,False,https://b.thumbs.redditmedia.com/TgWIZKisGVHMIPCHKvxomn1xmZc6rfqrwT2-R5wjcEY.jpg,,,,,
167,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,0,9l2f81,self.MachineLearning,"Simple Questions Thread October 03, 2018",https://www.reddit.com/r/MachineLearning/comments/9l2f81/simple_questions_thread_october_03_2018/,AutoModerator,1538582145,[removed],0,1,False,self,,,,,
168,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,1,9l2j6k,self.MachineLearning,What is the simplest way to avoid notebooks and collaborate on a machine learning project?,https://www.reddit.com/r/MachineLearning/comments/9l2j6k/what_is_the_simplest_way_to_avoid_notebooks_and/,cocorico,1538582850,"Hi all,

My colleague and I are trying to refactor out the massive single jupyter notebook we have so that we can enable better collaboration.

The notebook contains all classical steps: data pre-processing, creation of training/testing, features extraction (can get quite complex and interdependent), model training, testing and analyses.

We are a small team of 2, so I would like to avoid getting into Luigi, Airflow or any other full blown frameworks as much as possible.

Thanks",0,1,False,self,,,,,
169,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,1,9l2lzl,self.MachineLearning,Query about a Project,https://www.reddit.com/r/MachineLearning/comments/9l2lzl/query_about_a_project/,igniterook,1538583339,"First of all lemme introduce myself:- I am a college student and i want to make a project. After searching around the internet for ideas, I decided upon on the following:- Start off with creating a CNN to train a bot to play Tic tac toe and move forward and hopefully use another better model to make a better A.I.

&amp;#x200B;

Also, I want to write a paper on it. 

&amp;#x200B;

My queries :-

1. How do you guys go about learning CNN from scratch? Also what all steps do you take while making a project?

2.  How do i write a paper on it (for college)?

&amp;#x200B;

Im still adjusting to reddit so if you guys dont like me posting , kindly guide me... :D

Cheers

&amp;#x200B;",0,1,False,self,,,,,
170,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,1,9l2npy,self.MachineLearning,Several softmax probabilities to perform a final classification,https://www.reddit.com/r/MachineLearning/comments/9l2npy/several_softmax_probabilities_to_perform_a_final/,SancheZZF,1538583675,[removed],0,1,False,self,,,,,
171,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,1,9l2vuf,self.MachineLearning,[P] Serverless model in AWS,https://www.reddit.com/r/MachineLearning/comments/9l2vuf/p_serverless_model_in_aws/,ritchie46,1538585159,"At work I had to deploy serverless model in AWS and thought let's share what I've learned. I describe how to setup a serverless architecture with Lambda, SQS and Elastic Container Service. The stacks are deployed with the serverless (TM) Framework.

[https://www.ritchievink.com/blog/2018/09/16/deploy-any-machine-learning-model-serverless-in-aws/](https://www.ritchievink.com/blog/2018/09/16/deploy-any-machine-learning-model-serverless-in-aws/)

&amp;#x200B;",17,1,False,self,,,,,
172,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,1,9l2xhh,self.MachineLearning,What do I need to buy other than 1080 ti to run small/medium experiments?,https://www.reddit.com/r/MachineLearning/comments/9l2xhh/what_do_i_need_to_buy_other_than_1080_ti_to_run/,nishimiyaa,1538585483,[removed],0,1,False,self,,,,,
173,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,2,9l3e2j,self.MachineLearning,"DataViZ, Data Science and Machine Learning White Papers - Part 4",https://www.reddit.com/r/MachineLearning/comments/9l3e2j/dataviz_data_science_and_machine_learning_white/,andrea_manero,1538588376,r/http://www.datasciencecentral.com/profiles/blogs/dataviz-data-science-and-machine-learning-white-papers-part-4,0,1,False,self,,,,,
174,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,2,9l3k26,gpytorch.ai,[R] GPytorch: Scalable Gaussian Processes in Pytorch with strong GPU acceleration,https://www.reddit.com/r/MachineLearning/comments/9l3k26/r_gpytorch_scalable_gaussian_processes_in_pytorch/,programmerChilli,1538589417,,1,1,False,default,,,,,
175,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,3,9l3lqg,marktechpost.com,Forecast and Market Estimates: Machine Learning 2018,https://www.reddit.com/r/MachineLearning/comments/9l3lqg/forecast_and_market_estimates_machine_learning/,asifrazzaq1988,1538589710,,0,1,False,default,,,,,
176,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,3,9l3owh,self.MachineLearning,Textbook for applying deep learning to computer vision?,https://www.reddit.com/r/MachineLearning/comments/9l3owh/textbook_for_applying_deep_learning_to_computer/,MachineInTheStone,1538590277,I am currently reading deep learning by bengio and a textbook for classical computer vision. I would like a third textbook that combines both fields. Preferably the bulk of the text should focus on applying deep learning to comp vision and not on defining the two things.,0,1,False,self,,,,,
177,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,3,9l3t0o,arxiv.org,[R] Set Transformer,https://www.reddit.com/r/MachineLearning/comments/9l3t0o/r_set_transformer/,akosiorek,1538590922,,3,1,False,default,,,,,
178,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,4,9l49ma,sites.google.com,NIPS 2018 Workshop on Causal Learning,https://www.reddit.com/r/MachineLearning/comments/9l49ma/nips_2018_workshop_on_causal_learning/,adammathias,1538593681,,0,1,False,default,,,,,
179,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,4,9l4c6u,youtu.be,New rain machine,https://www.reddit.com/r/MachineLearning/comments/9l4c6u/new_rain_machine/,usman11211,1538594121,,0,1,False,default,,,,,
180,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,4,9l4g9b,self.MachineLearning,how to predict textual entailment using SVM?,https://www.reddit.com/r/MachineLearning/comments/9l4g9b/how_to_predict_textual_entailment_using_svm/,anis016,1538594847,[removed],0,1,False,self,,,,,
181,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,4,9l4poz,self.MachineLearning,[D] Side-by-side Keras and PyTorch code (transfer learning on Alien vs. Predator dataset),https://www.reddit.com/r/MachineLearning/comments/9l4poz/d_sidebyside_keras_and_pytorch_code_transfer/,pmigdal,1538596507,"Blog post: \[[Keras vs. PyTorch: Alien vs. Predator recognition with transfer learning](https://deepsense.ai/keras-vs-pytorch-avp-transfer-learning/)\]([https://deepsense.ai/keras-vs-pytorch-avp-transfer-learning/](https://deepsense.ai/keras-vs-pytorch-avp-transfer-learning/)) by Patryk Miziua, Rafa Jakubanis and me

In the last blog post I discussed main differences between Keras and PyTorch philosophies and abstractions (post: \[[Keras or PyTorch as your first deep learning framework](https://deepsense.ai/keras-or-pytorch/)\]([https://deepsense.ai/keras-or-pytorch/](https://deepsense.ai/keras-or-pytorch/)) and \[discussion thread on Reddit\]()[https://www.reddit.com/r/MachineLearning/comments/8uhqol/d\_keras\_vs\_pytorch\_in\_depth\_comparison\_of/](https://www.reddit.com/r/MachineLearning/comments/8uhqol/d_keras_vs_pytorch_in_depth_comparison_of/)).

Here we want to show it in examples, with snippets of code side-by-side. Transfer learning for image classification (here: with ResNet-50) is a practical problem showing many differences.  No more cats and dogs - we use an extraterrestrial dataset! :)

* Interactive kernels: [https://www.kaggle.com/pmigdal/alien-vs-predator-images/kernels](https://www.kaggle.com/pmigdal/alien-vs-predator-images/kernels)
* Code: [https://github.com/deepsense-ai/Keras-PyTorch-AvP-transfer-learning](https://github.com/deepsense-ai/Keras-PyTorch-AvP-transfer-learning)

Here we have an advanced community. So my main questions are:

* which things, in Keras or PyTorch, did you find most confusing (or enlightening)?
* when it comes to providing examples, what does work the best for you: GitHub repo, Kaggle kernels, just code in a blog post, sth different?",7,1,False,self,,,,,
182,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,5,9l4y74,self.MachineLearning,Quarterly forecast,https://www.reddit.com/r/MachineLearning/comments/9l4y74/quarterly_forecast/,throwaway_6545,1538598005,[removed],0,1,False,self,,,,,
183,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,5,9l51ho,venturebeat.com,"[N] Fast.ai launches fastai v1, a deep learning library for PyTorch",https://www.reddit.com/r/MachineLearning/comments/9l51ho/n_fastai_launches_fastai_v1_a_deep_learning/,gtechmisc,1538598624,,0,1,False,default,,,,,
184,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,5,9l57h7,self.MachineLearning,Deep Neuroevolution: Genetic Algorithms are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/9l57h7/deep_neuroevolution_genetic_algorithms_are_a/,anerd2390,1538599730,[removed],0,1,False,self,,,,,
185,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,5,9l58gf,self.MachineLearning,[D] Are there any universities doing research in the financial field using ML and DL?,https://www.reddit.com/r/MachineLearning/comments/9l58gf/d_are_there_any_universities_doing_research_in/,Jdope1,1538599929,"I'm mainly talking about financial trading among other aspects of the field, would be interested to hear about any other applications too!",8,1,False,self,,,,,
186,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,6,9l5c4z,zdnet.com,Cloudera and Hortonworks Announce Merger,https://www.reddit.com/r/MachineLearning/comments/9l5c4z/cloudera_and_hortonworks_announce_merger/,PineappleOnPizzaSin,1538600634,,0,1,False,default,,,,,
187,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,6,9l5fbz,zdnet.com,[N] Cloudera &amp; Hortonworks announce merger,https://www.reddit.com/r/MachineLearning/comments/9l5fbz/n_cloudera_hortonworks_announce_merger/,PineappleOnPizzaSin,1538601239,,0,1,False,https://b.thumbs.redditmedia.com/KC3hRN4TjcaR3_SmMc6qp8RDTVsIE62uI8C-JLsknGM.jpg,,,,,
188,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,6,9l5gzh,self.MachineLearning,Is filter actually trained in a CNN??,https://www.reddit.com/r/MachineLearning/comments/9l5gzh/is_filter_actually_trained_in_a_cnn/,logan2503,1538601550,[removed],1,1,False,self,,,,,
189,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,6,9l5k16,blackswans.io,Lessons Learnt by Facebook Data Scientist Brandon Rohrer,https://www.reddit.com/r/MachineLearning/comments/9l5k16/lessons_learnt_by_facebook_data_scientist_brandon/,jdyr1729,1538602143,,0,1,False,default,,,,,
190,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,6,9l5sac,medium.com,Informedness and Markedness as unbiased alternatives to Recall and Precision,https://www.reddit.com/r/MachineLearning/comments/9l5sac/informedness_and_markedness_as_unbiased/,rvprasad,1538603763,,0,1,False,https://b.thumbs.redditmedia.com/DscKHCqWpC3q77E7dpLHbTPsAYUrrhzZXNk70JR2vyk.jpg,,,,,
191,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,7,9l5tif,self.MachineLearning,"[Discussion] Is there a released implementation for ILP, from the paper ""Learning explanatory rules from noisy data""?",https://www.reddit.com/r/MachineLearning/comments/9l5tif/discussion_is_there_a_released_implementation_for/,_SunBrah_,1538604016,"Here's the paper in question, for anyone who has not seen it: https://arxiv.org/pdf/1711.04574.pdf 

I have found it quite interesting, and recently referenced in the [Neural Logic Machines](https://openreview.net/pdf?id=B1xY-hRctX) submission to ICLR 2019. I'd be really interested in trying to reproduce some results, but from what I can find there hasn't been any code released for it.. unless I'm missing it somewhere? ",0,1,False,self,,,,,
192,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,7,9l5wxg,tvm.ai,[P] Automatic Kernel Optimization for Deep Learning on All Hardware Platforms,https://www.reddit.com/r/MachineLearning/comments/9l5wxg/p_automatic_kernel_optimization_for_deep_learning/,ZihengJiang,1538604704,,0,1,False,default,,,,,
193,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,7,9l5y8t,github.com,Evolutionary Optimization toolbox,https://www.reddit.com/r/MachineLearning/comments/9l5y8t/evolutionary_optimization_toolbox/,AcceptableArmy,1538604967,,0,1,False,default,,,,,
194,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,7,9l63yt,self.MachineLearning,[D] a list ranking universities and labs by ML publications?,https://www.reddit.com/r/MachineLearning/comments/9l63yt/d_a_list_ranking_universities_and_labs_by_ml/,betram23,1538606139,"It seems useful to have one site, is there something like this? Do you think its worth doing? (I think it can be really useful for people like myself who are choosing where to apply for grad school) ",8,1,False,self,,,,,
195,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,8,9l6d3o,self.MachineLearning,Semantic Role Labeling for German data,https://www.reddit.com/r/MachineLearning/comments/9l6d3o/semantic_role_labeling_for_german_data/,BLPML,1538608063,[removed],0,1,False,self,,,,,
196,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,9,9l6uye,self.MachineLearning,"[D] Applications Of Reading Detection Algorithms (Hidden Markov Models, Anomoly Detection Algorithms)",https://www.reddit.com/r/MachineLearning/comments/9l6uye/d_applications_of_reading_detection_algorithms/,eng_steve,1538611887,"Hey all,

I'm not sure if this fits the sub or not but I'd like to request some papers or anecdotes re: the application of algorithms which are able to track a reader's progression through a block of text.

I'm a grad student, and I'm currently producing a paper describing the detection of the line which a reader is currently focused on using HMMs given (often noisy) eye gaze data. Future work will involve what I plan to be the implementation of an anomoly detection algorithm (if anyone has any other suggestions feel free to  discuss!) to distinguish between reading and not reading, to cue the reading algorithm to kick in during normal web browsing when necessary. 

This is work that I'm doing during my graduate studies - of it were up to me I'd be looking at more general applications. I'm having trouble imagining a demand in industry for software which a) detects when you're reading and b) tracks your progress on a line-by-line basis. There are plenty of applications for point-of-focus algorithms that take messy eye gaze data and determine where the user was actually interested in, but reading algorithms seem a bit too niche. I'm wondering what this subreddit thinks of this specific application and where it might be useful in industry/academia. Thank you!",4,1,False,self,,,,,
197,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,9,9l6wdx,self.MachineLearning,hierarchical softmax in keras/tensorflow?,https://www.reddit.com/r/MachineLearning/comments/9l6wdx/hierarchical_softmax_in_kerastensorflow/,melonochelo,1538612186,[removed],0,1,False,self,,,,,
198,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,9,9l733h,openreview.net,[R] Learning To Simulate,https://www.reddit.com/r/MachineLearning/comments/9l733h/r_learning_to_simulate/,StrawberryNumberNine,1538613687,,0,1,False,default,,,,,
199,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,9,9l75tv,80000hours.org,Dr Paul Christiano on how OpenAI is developing real solutions to the 'AI alignment problem' - and his vision of how humanity will progressively hand over decision-making to AI systems,https://www.reddit.com/r/MachineLearning/comments/9l75tv/dr_paul_christiano_on_how_openai_is_developing/,robwiblin,1538614299,,0,1,False,https://b.thumbs.redditmedia.com/tW4gjN4G6KtwABZUD_hwaxZ2urK3P-bJtyv0b7yN_Hk.jpg,,,,,
200,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,10,9l7bfn,self.MachineLearning,Why does machine learning papers have such terrible math?,https://www.reddit.com/r/MachineLearning/comments/9l7bfn/why_does_machine_learning_papers_have_such/,RandomProjections,1538615518,"I am a beginning graduate student in CS and I am transferring from my field of complexity theory to machine learning. One thing I cannot help but notice is that machine learning papers that are published in NIPS and elsewhere have terrible math.

Right now I am reading a popular paper called [Generative Adversarial Nets](https://arxiv.org/pdf/1406.2661.pdf), and I am hit with walls of unclear math.

* The paper begins with defining a generator distribution p\_g over data x, but what set is x contained in? What dimension  is x? What does the distribution p\_g look like? If it is unknown, then say so.
* Then it says, we define a prior on ""input noise variables p\_z(z)"". So is z the variable or p\_z(z)? When is the distribution written as a function of z here, but not for p\_g?
* Then, authors define a mapping to ""data space"" G(z;\\theta\_g), where G is claimed to be differentiable (but no proof, we just accept), and \\theta\_g is a parameter (in what set, space?)
* Is G and D functions? If so, what are domains and range of such functions?

When I got to the proof of proposition 1, I burst out in laughter, because this proof would fail any 1st year undergraduate math students at my university. (How was this paper written by 8 people)?

* First, what does it mean for G to be fixed? Fixed with what?
* The proof attempts to define a mapping y \\to alog(y) + blog(1-y). First of all, writing 1D constants as a pair (a,b) in 2D Euclidean space is just bizarre. The fact that R\^2 is subtracting a set {0, 0} instead of the set containing the pair {(0,0)} is wrong. The map should be written with \\to (as with ANY math textbook), instead of an arrow, so it is also notationally incorrect. Finally, Supp(p\_data) and Supp(p\_g) is never defined anywhere. 

I seriously could not continue anymore with this field. My advisor warned me something about the field lacking in rigor and I did not believe him, but now I do. Does anyone else feel the same way?",0,1,False,self,,,,,
201,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,10,9l7dha,youtube.com,YouTube,https://www.reddit.com/r/MachineLearning/comments/9l7dha/youtube/,SageAldermanpu2,1538615988,,0,1,False,default,,,,,
202,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,10,9l7e77,self.MachineLearning,Why do machine learning papers have such terrible math (or is it just me)?,https://www.reddit.com/r/MachineLearning/comments/9l7e77/why_do_machine_learning_papers_have_such_terrible/,RandomProjections,1538616161,[removed],0,1,False,self,,,,,
203,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,10,9l7fn0,80000hours.org,[R] Dr Paul Christiano on how OpenAI is developing real solutions to the 'AI alignment problem' - and his vision of how humanity will progressively hand over decision-making to AI systems,https://www.reddit.com/r/MachineLearning/comments/9l7fn0/r_dr_paul_christiano_on_how_openai_is_developing/,robwiblin,1538616492,,0,1,False,https://b.thumbs.redditmedia.com/tW4gjN4G6KtwABZUD_hwaxZ2urK3P-bJtyv0b7yN_Hk.jpg,,,,,
204,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,10,9l7j46,self.MachineLearning,[D] Why do machine learning papers have such terrible math (or is it just me)?,https://www.reddit.com/r/MachineLearning/comments/9l7j46/d_why_do_machine_learning_papers_have_such/,RandomProjections,1538617280,"I am a beginning graduate student in CS and I am transferring from my field of complexity theory to machine learning.

One thing I cannot help but notice (after starting out a month ago) is that machine learning papers that are published in NIPS and elsewhere have absolutely terrible, downright atrocious, indecipherable math.

**Right now I am reading a ""popular paper"" called** [**Generative Adversarial Nets**](https://arxiv.org/pdf/1406.2661.pdf)**, and I am hit with walls of unclear math.**

* The paper begins with defining a generator distribution p\_g over data x, but what set is x contained in? What dimension is x? What does the distribution p\_g look like? If it is unknown, then say so.
* Then it says, ""we define a prior on input noise variables p\_z(z)"". So is z the variable or p\_z(z)? When is the distribution written as a function of z here, but not for p\_g?
* Then, authors define a mapping to ""data space"" G(z;\\theta\_g), where G is claimed to be differentiable (a very strong claim, yet no proof, we just need to accept it), and \\theta\_g is a parameter (in what set, space?)
* Are G and D functions? If so, what are domains and range of such functions? These are *basic details* from high school algebra around the world.

**When I got to the proof of proposition 1, I burst out in laughter!!!!!** This proof would fail any 1st year undergraduate math students at my university. (How was this paper written by 8 people, statisticians no less)?

* First, what does it mean for G to be fixed? Fixed with what?
* The proof attempts to define a mapping, y \\to alog(y) + blog(1-y). First of all, writing 1D constants, a, b, as a pair (a,b) in R2 is simply bizarre. The fact that R\^2 is subtracting a set {0, 0} instead of the set containing the pair {(0,0)} is wrong from the perspective of set theory.
* The map should be written with $\\mapsto$ instead of $\\to$ (just look at ANY math textbook, [or even Wikipedia](https://en.wikipedia.org/wiki/Function_(mathematics)#Arrow_notation)) so it is also notationally incorrect.
* Finally, Supp(p\_data) and Supp(p\_g) are never defined anywhere.
* The proof seems to be using a simple 1D differentiation argument. Say so at the beginning. And please do not differentiable over the closed sets \[0,1\]. The derivatives are not well defined at the boundary (you know?).

I seriously could not continue anymore with this paper. My advisor warned me something about the field lacking in rigor and I did not believe him, but now I do. Does anyone else feel the same way?",173,1,False,self,,,,,
205,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,10,9l7lpw,self.MachineLearning,Wanting to learn,https://www.reddit.com/r/MachineLearning/comments/9l7lpw/wanting_to_learn/,nickypie7,1538617858,"Hey y'all. I'm curious where I can learn more about machine learning algorithms, theory, and applications. What are some good places to learn? (Preferably for free).",0,1,False,self,,,,,
206,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,10,9l7miq,self.MachineLearning,SIX Flags Stock Price Prediction,https://www.reddit.com/r/MachineLearning/comments/9l7miq/six_flags_stock_price_prediction/,uniAdapter,1538618032,[removed],1,1,False,self,,,,,
207,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,11,9l7u0q,self.MachineLearning,[D] Object localization (not detection) in images - papers,https://www.reddit.com/r/MachineLearning/comments/9l7u0q/d_object_localization_not_detection_in_images/,ketsok,1538619673,"I'm looking for papers dealing with object localization in images.
I distinguish object localization from object detection.
Object detection task is about predicting bounding boxes (x, y, width, height) whereas object localization task is about pointing an object, i.e. predicting its x, y coordinates.
I know I can take solutions that predict bounding boxes and discard width and height.
However, I'm looking for papers that solve object localization task.
When I use phrase ""object localization"" in google/google scholar, I'm getting only papers dealing with object detection.
Are you aware of any papers dealing with object localization?",10,1,False,self,,,,,
208,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,12,9l8cni,self.MachineLearning,Anyone has a list of overlapping/soft clustering ?,https://www.reddit.com/r/MachineLearning/comments/9l8cni/anyone_has_a_list_of_overlappingsoft_clustering/,nff21,1538624037,[removed],0,1,False,self,,,,,
209,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,12,9l8eq3,tvm.ai,[P] Automatic Kernel Optimization for Deep Learning on All Hardware Platforms,https://www.reddit.com/r/MachineLearning/comments/9l8eq3/p_automatic_kernel_optimization_for_deep_learning/,crowwork,1538624545,,0,1,False,https://b.thumbs.redditmedia.com/ZKAxhY0-P0hyvRHd268VL8Ba0cT5oObZjqKYGKqB6eg.jpg,,,,,
210,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,12,9l8i0s,self.MachineLearning,Tips on getting into a good PhD program for ML/DS?,https://www.reddit.com/r/MachineLearning/comments/9l8i0s/tips_on_getting_into_a_good_phd_program_for_mlds/,friedcomputerz208,1538625360,[removed],0,1,False,self,,,,,
211,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,13,9l8rk7,arxiv.org,[R] Taming VAEs,https://www.reddit.com/r/MachineLearning/comments/9l8rk7/r_taming_vaes/,baylearn,1538627825,,1,1,False,default,,,,,
212,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,13,9l8t10,github.com,"[P] Awesome Human Pose Estimation : A collection of resources on 2D and 3D pose estimation, 3D shape generation, Person image generation and a lot more.",https://www.reddit.com/r/MachineLearning/comments/9l8t10/p_awesome_human_pose_estimation_a_collection_of/,cbsudux,1538628200,,0,1,False,default,,,,,
213,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,14,9l90dl,self.MachineLearning,k-Nearest Neighbor,https://www.reddit.com/r/MachineLearning/comments/9l90dl/knearest_neighbor/,luchins,1538630196,"Hi  I was reading here about  K-nearest neighbor  and I have a  question

The k-Nearest Neighbor (kNN) does not create a model, instead  itcreatespredictions from closedata on-demand when a prediction is  required. A similarity measure (such as Euclidean distance) is used to  locate close data in order to make predictions.

&amp;#x200B;

Can  I ask you  which is the difference  between  ''create  predictions  from close  data on-demand  when  a  prediction is required''?  Where  is  the difference  with a  regression  model?  Can't  KNN  be used  instead of  regression?

&amp;#x200B;

Also in this code:

[https://image.ibb.co/i8pw9K/Aimmagine.png](https://image.ibb.co/i8pw9K/Aimmagine.png)

&amp;#x200B;

what is  that  ''K=3''  ? 

also  what does  this  command stand  for:

&amp;#x200B;

''mse &lt;-  mean((longley employed - prediction) \^2)''

&amp;#x200B;

What  is mse?  

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;",0,1,False,self,,,,,
214,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,15,9l9agh,blog.flowandform.agency,Machine Learning social platform for model sharing,https://www.reddit.com/r/MachineLearning/comments/9l9agh/machine_learning_social_platform_for_model_sharing/,astraldemon,1538633038,,0,1,False,default,,,,,
215,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,15,9l9gc5,self.MachineLearning,How can i train a classifier with 50 images ( above 40% acuracy expected ),https://www.reddit.com/r/MachineLearning/comments/9l9gc5/how_can_i_train_a_classifier_with_50_images_above/,peterpanvn,1538634784,[removed],0,1,False,self,,,,,
216,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,16,9l9np9,medium.com,Parallel Processing of Machine Learning Algorithms using Docker and Kubernetes,https://www.reddit.com/r/MachineLearning/comments/9l9np9/parallel_processing_of_machine_learning/,vpmr201,1538637094,,0,1,False,default,,,,,
217,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,16,9l9pg5,self.MachineLearning,Copula Variational Bayes (CVB) inference and the next generation of neural networks?,https://www.reddit.com/r/MachineLearning/comments/9l9pg5/copula_variational_bayes_cvb_inference_and_the/,viettran86,1538637674,[removed],0,1,False,self,,,,,
218,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,16,9l9r8l,self.MachineLearning,[Q] OHEM for Faster RCNN,https://www.reddit.com/r/MachineLearning/comments/9l9r8l/q_ohem_for_faster_rcnn/,gabegabe2,1538638254,[removed],0,1,False,self,,,,,
219,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,16,9l9rgq,arjoonn.com,Machine Reading Comprehension Datasets/Challenges list,https://www.reddit.com/r/MachineLearning/comments/9l9rgq/machine_reading_comprehension_datasetschallenges/,arjoonn,1538638330,,0,1,False,default,,,,,
220,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,16,9l9vrr,self.MachineLearning,Difference between VAEs and GANs ?,https://www.reddit.com/r/MachineLearning/comments/9l9vrr/difference_between_vaes_and_gans/,prabhat7298,1538639815,[removed],0,1,False,self,,,,,
221,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,16,9l9vur,colaninfotech.com,Business Entrepreneurs Choose Machine Learning for DigitalMarketing. Do you know why?,https://www.reddit.com/r/MachineLearning/comments/9l9vur/business_entrepreneurs_choose_machine_learning/,Colaninfotechpvtltd,1538639844,,0,1,False,default,,,,,
222,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,17,9la34h,medium.freecodecamp.org,"Every single Machine Learning course on the internet, ranked by the reviews",https://www.reddit.com/r/MachineLearning/comments/9la34h/every_single_machine_learning_course_on_the/,ITlovers,1538642351,,0,1,False,default,,,,,
223,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,18,9lagfw,hub.packtpub.com,Best Machine Learning Datasets for beginners | Packt Hub,https://www.reddit.com/r/MachineLearning/comments/9lagfw/best_machine_learning_datasets_for_beginners/,sugandhaLa,1538646748,,0,1,False,default,,,,,
224,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,19,9lajj5,self.MachineLearning,China Artificial Intelligence Plans To Be a World Leader in 2025,https://www.reddit.com/r/MachineLearning/comments/9lajj5/china_artificial_intelligence_plans_to_be_a_world/,mavicare,1538647724,"China Artificial intelligence (AI) is now an important part of Beijing's ""Made in China 2025"" project. China wants to become a world leader in this field by 2030 and now has an advantage in terms of academic documents, patents, and international and cross-border AI financing.

In 2017, China released its [""Next Generation Artificial Intelligence Development Plan""](http://techywebspace.club/china-artificial-intelligence/)
, which plans to become the world's leading artificial intelligence company, with a national AI sector of nearly $ 150 billion. The first step in this plan is to catch up with the US on AI technology and applications by 2020.

China Artificial Intelligence will now dominate funding. Last year, 48% of the total equity financing of American start-ups came from China, compared with 38% of the United States and 13% of the rest of the world. This is a significant leap from the 11.3% of global financing in China in 2016.

Article Source [techy webspace](http://techywebspace.club/china-artificial-intelligence/)",0,1,False,self,,,,,
225,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,19,9lajo4,self.MachineLearning,Hierarchical Seq2seq (chatbot),https://www.reddit.com/r/MachineLearning/comments/9lajo4/hierarchical_seq2seq_chatbot/,Darshut,1538647764,[removed],0,1,False,self,,,,,
226,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,19,9lalvv,self.MachineLearning,[D] Hierarchical Seq2Seq (eventually with attention),https://www.reddit.com/r/MachineLearning/comments/9lalvv/d_hierarchical_seq2seq_eventually_with_attention/,Darshut,1538648400,"Hey all,

So well I created a chatbot with an encoder-decoder + attention mechanism. It works well but I want to add a little bit more intelligence since at the moment the bot's answer only depends on the last user's message :)  

I'd like to make my bot consider the general context of the conversation i.e. all the previous messages of the conversation and that's where I'm struggling with the hierarchical structure. 
I don't know exactly how to handle the context, I tried to concat a doc2vec representation of the latter with the last user's message word2vec representation but the model is far worst now...  

I really like what has been done in [this paper](https://www.cs.cmu.edu/~hovy/papers/16HLT-hierarchical-attention-networks.pdf) and I would like to adapt it to a seq2seq model knowing that the main difference is that I perform several attention steps when generating the answer.  

Any idea, example or useful paper would be greatly appreciated ! Thanks :)",6,1,False,self,,,,,
227,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,20,9lawa6,self.MachineLearning,Do you believe in the future of AI?,https://www.reddit.com/r/MachineLearning/comments/9lawa6/do_you_believe_in_the_future_of_ai/,Intellexer,1538651280,[removed],0,1,False,self,,,,,
228,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,20,9laxuf,self.MachineLearning,How can I use machine learning to create acapellas of a song?,https://www.reddit.com/r/MachineLearning/comments/9laxuf/how_can_i_use_machine_learning_to_create/,drakeandjoshua,1538651713,[removed],0,1,False,self,,,,,
229,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,20,9layto,self.MachineLearning,assigning topics to a text in R,https://www.reddit.com/r/MachineLearning/comments/9layto/assigning_topics_to_a_text_in_r/,o10o62330,1538651968,[removed],0,1,False,self,,,,,
230,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,21,9lba0p,arxiv.org,"[1810.00393] Deep, Skinny Neural Networks are not Universal Approximators",https://www.reddit.com/r/MachineLearning/comments/9lba0p/181000393_deep_skinny_neural_networks_are_not/,ihaphleas,1538654762,,59,1,False,default,,,,,
231,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,21,9lbd3j,self.MachineLearning,Delmer - Manufacturers for Animal Comfort Machine,https://www.reddit.com/r/MachineLearning/comments/9lbd3j/delmer_manufacturers_for_animal_comfort_machine/,chrisclinton12,1538655486,[removed],0,1,False,self,,,,,
232,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,21,9lbed3,self.MachineLearning,[D] Training a neural network to mimic another?,https://www.reddit.com/r/MachineLearning/comments/9lbed3/d_training_a_neural_network_to_mimic_another/,machinesa,1538655792,"I have been trying to find papers or code where we train a new neural network to learn to behave exactly like a pre-trained net. Do you know of any such cases? 

I want recommendations for the kind of loss functions to use, pitfalls and so on.

We can have infinite data in this case so it should be possible but I am having trouble getting a new net to mimic a generative neural network that I have trained from the GAN algorithm. I use the MSE loss with thousands of epochs but it doesn't learn.",23,1,False,self,,,,,
233,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,21,9lbki9,insights.dice.com,[N] A.I. May Have Met Its Ethical Match in California Senate Bill 1001,https://www.reddit.com/r/MachineLearning/comments/9lbki9/n_ai_may_have_met_its_ethical_match_in_california/,BrooklynShatterDome,1538657201,,0,1,False,default,,,,,
234,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,21,9lbmn2,self.MachineLearning,"[P] Experiment on open sharing, discovering and collaborating with models",https://www.reddit.com/r/MachineLearning/comments/9lbmn2/p_experiment_on_open_sharing_discovering_and/,f3nnix,1538657684,"Experiment still needs a ton of work for all the ideas to fit in one place but we felt like it is never too early for some feedback.  


Idea is to have place where we can discover, share and develop models together and faster. Apart from discovery one feature we focus on is to add an UI to each model repository where we can request datasets or model training that would produce model version after approved by owner, this has potential to enable better open source collaboration.  


There are few other tools that do the same or similar but we would like to test a different approach.  
Any feedback on the idea would be great.  


Blog post:  
[https://blog.flowandform.agency/bonumic-bringing-machine-learning-to-the-people-b9e958e1eb70](https://blog.flowandform.agency/bonumic-bringing-machine-learning-to-the-people-b9e958e1eb70)  


Prelaunch site:  
r/https://bonumic.com  


Cheers ",0,1,False,self,,,,,
235,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,22,9lc1eo,self.MachineLearning,Models like VGG-Face ?,https://www.reddit.com/r/MachineLearning/comments/9lc1eo/models_like_vggface/,ankur248,1538660836,[removed],0,1,False,self,,,,,
236,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,22,9lc36l,self.MachineLearning,[P] Evolutionary Optimization Toolbox,https://www.reddit.com/r/MachineLearning/comments/9lc36l/p_evolutionary_optimization_toolbox/,AcceptableArmy,1538661208,[removed],0,1,False,self,,,,,
237,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,22,9lc4tk,self.MachineLearning,[R] Datasets for mind reading,https://www.reddit.com/r/MachineLearning/comments/9lc4tk/r_datasets_for_mind_reading/,kseeliger,1538661553,"We have written a brief overview of data sets openly available for playing around with machine learning-driven visual perception reconstruction ideas ('mind reading' like in [this video](https://www.youtube.com/watch?v=pFnBipjQUbE)). 

[Datasets for mind reading](https://mindcodec.com/datasets-for-mind-reading-visual-reconstruction/)

We have decided to write this overview up as a short guide-like manuscript with more details and information for getting started  so if you find this blog post useful please check it again in a few weeks, we will link it there. ",31,1,False,self,,,,,
238,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,23,9lc6t6,arxiv.org,[1810.00303] Newton-MR: Newton&amp;#x27;s Method Without Smoothness or Convexity,https://www.reddit.com/r/MachineLearning/comments/9lc6t6/181000303_newtonmr_newtonx27s_method_without/,ihaphleas,1538661952,,0,1,False,default,,,,,
239,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,23,9lcdwc,arxiv.org,[1810.00208] To compress or not to compress: Understanding the Interactions between Adversarial Attacks and Neural Network Compression,https://www.reddit.com/r/MachineLearning/comments/9lcdwc/181000208_to_compress_or_not_to_compress/,ihaphleas,1538663338,,1,1,False,default,,,,,
240,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,23,9lceer,self.MachineLearning,Machine learning techniques used in edge detection,https://www.reddit.com/r/MachineLearning/comments/9lceer/machine_learning_techniques_used_in_edge_detection/,AbodeCo,1538663436,[removed],0,1,False,self,,,,,
241,MachineLearning,t5_2r3gv,2018-10-4,2018,10,4,23,9lcm7x,self.MachineLearning,How to randomly pick cluster centers,https://www.reddit.com/r/MachineLearning/comments/9lcm7x/how_to_randomly_pick_cluster_centers/,DuckDuckFooGoo,1538664972,[removed],0,1,False,self,,,,,
242,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,0,9lcrcg,self.MachineLearning,[D] Reachability Analysis : panacea of DNN safety concerns?,https://www.reddit.com/r/MachineLearning/comments/9lcrcg/d_reachability_analysis_panacea_of_dnn_safety/,Hizachi,1538665941,"[Reachability Analysis of Deep Neural Networks with Provable Guarantees] (https://arxiv.org/abs/1805.02242) (long version of a paper accepted to IJCAI 2018) announces better performance than virtually all other tools (Reluplex, Sherlock, MIP, etc). Not only that, their performance does not depend on the size of the network which apparently allows them to scale very well to large networks (more layers, more nodes). 

Could this be the answer ? Any thoughts ?",5,1,False,self,,,,,
243,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,0,9lcwre,self.MachineLearning,[P] Deduplicating files in Public Git Archive,https://www.reddit.com/r/MachineLearning/comments/9lcwre/p_deduplicating_files_in_public_git_archive/,keramitas,1538666985,"Hey all ! 

Here is a link to the blog post I wrote on the main focus of my intership at source{d}:  [https://blog.sourced.tech/post/deduplicating\_pga\_with\_apollo/](https://blog.sourced.tech/post/deduplicating_pga_with_apollo/)

It mostly describes the process I went through in order to deduplicate large amounts of source code from Public Git Archive, using semantical and syntactical features - and then the results. Hope you have a nice read, if you got any questions go ahead and I'll do my best to answer :)",0,1,False,self,,,,,
244,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,1,9ldeyz,self.MachineLearning,[D] Reinforcement Learning in Non Stationary Environments,https://www.reddit.com/r/MachineLearning/comments/9ldeyz/d_reinforcement_learning_in_non_stationary/,abhishek0318,1538670289,Has there been any research on reinforcement learning in non stationary environments for the general case? I could only find papers where they assumed that the environment can be modeled as multiple MDPs [\[1\]](https://papers.nips.cc/paper/1665-an-environment-model-for-nonstationary-reinforcement-learning.pdf%20http://inf.ufrgs.br/~bsilva/nonstationary_icml2006.pdf%20http://www-poleia.lip6.fr/~hadouxe/files/LMCE14.pdf) [\[2\]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.5.6184&amp;rep=rep1&amp;type=pdf) [\[3\]](http://inf.ufrgs.br/~bsilva/nonstationary_icml2006.pdf) [\[4\]](http://www-poleia.lip6.fr/~hadouxe/files/LMCE14.pdf) [\[5\]](https://arxiv.org/pdf/1609.06757.pdf). Any papers for the general case?,6,1,False,self,,,,,
245,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,1,9ldmax,blog.pocketcluster.io,"[N] Weekly Machine Learning Opensource Roundup  Oct. 4, 2018",https://www.reddit.com/r/MachineLearning/comments/9ldmax/n_weekly_machine_learning_opensource_roundup_oct/,stkim1,1538671644,,0,1,False,default,,,,,
246,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,2,9ldr8u,self.MachineLearning,[D] Are there any large publicly available datasets of chat rooms?,https://www.reddit.com/r/MachineLearning/comments/9ldr8u/d_are_there_any_large_publicly_available_datasets/,blake8086,1538672570,"I'm looking for chats where there were many participants and ideally, millions of messages.",13,1,False,self,,,,,
247,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,2,9ldsf7,self.MachineLearning,Is it possible to teach a neural network to solve IQ tests?,https://www.reddit.com/r/MachineLearning/comments/9ldsf7/is_it_possible_to_teach_a_neural_network_to_solve/,scriptkiddie42,1538672783,[removed],0,1,False,self,,,,,
248,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,2,9ldsl7,youtube.com,[P] Using machine learning to make dogs talk (and other effects). Built using Keras / Tensorflow / iOS,https://www.reddit.com/r/MachineLearning/comments/9ldsl7/p_using_machine_learning_to_make_dogs_talk_and/,hwoolery,1538672812,,0,1,False,https://b.thumbs.redditmedia.com/wCZWYnUsLSzZ8kh7MVQ6aFYmEQWjwRbfFngD0xB_Axw.jpg,,,,,
249,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,2,9ldyra,self.MachineLearning,[D] Is it possible to teach a neural network to solve cognitive IQ tests?,https://www.reddit.com/r/MachineLearning/comments/9ldyra/d_is_it_possible_to_teach_a_neural_network_to/,scriptkiddie42,1538673942,"While watching a Sam Harris TEDx talk about the apocalyptic nature of AI he said that ""As long as we continue to build *systems of atoms* that display increasingly intelligent behaviour we will create **general intelligence**."" 

So I wondered, with today's ML technology, would it be possible to give a neural network a bunch of IQ(general intelligence) tests and teach it to solve them at a level higher than that of an average human, or is it just impossible? ",11,1,False,self,,,,,
250,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,3,9leb68,youtu.be,Artificial Intelligence - Singularity - Social Media,https://www.reddit.com/r/MachineLearning/comments/9leb68/artificial_intelligence_singularity_social_media/,themodernape368,1538676293,,1,1,False,https://b.thumbs.redditmedia.com/yPaWTVAjW1tRUx46NVKyMhVTxu6ZaPVdmEaaAOWUA8E.jpg,,,,,
251,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,3,9lenbd,self.MachineLearning,[D] What makes a paper a good candidate for a reproducibility report?,https://www.reddit.com/r/MachineLearning/comments/9lenbd/d_what_makes_a_paper_a_good_candidate_for_a/,elephantFarmz,1538678547,"I'm a final-year undergraduate student, and my deep learning class is encouraged to participate in the 2019 ICLR \[Reproducibility Challenge\]([https://github.com/reproducibility-challenge](https://github.com/reproducibility-challenge)), I think that participating in this challenge sounds far more interesting than the other options that we have for our final project. 

&amp;#x200B;

However while looking over the candidate papers on OpenReview the past few days, I am somewhat lost in trying to identify papers than lend themselves well to this challenge for me. Speaking with some of my classmates, it seems like there are many others in this boat as well. I'm sure this isn't the reality, but it feels like many papers either fall in the ""completely unreasonable to even try and re-implement"" realm due to resource constraints, private code dependencies, etc. Other papers look trivially reproducible in a weekend of work, which doesn't make for a great final project, and my guess is it wouldn't be particularly useful to the community. 

&amp;#x200B;

So I was wondering if anyone had

\- papers they would like to see reproduced

\- or just general advice on selecting a paper for the reproducibility report.

&amp;#x200B;",6,1,False,self,,,,,
252,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,3,9leoep,nature.com,[R] Quantum Artificial Life in an IBM Quantum Computer,https://www.reddit.com/r/MachineLearning/comments/9leoep/r_quantum_artificial_life_in_an_ibm_quantum/,ActiveInference,1538678750,,0,1,False,default,,,,,
253,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,4,9leyhr,self.MachineLearning,"[D] Is the programming for ML itself that hard, or is the research and study portion doing most of the legwork?",https://www.reddit.com/r/MachineLearning/comments/9leyhr/d_is_the_programming_for_ml_itself_that_hard_or/,Checkai,1538680631,"I'm a casual coder and I've checked out a few of the papers' source for [Two Minute Papers](https://www.youtube.com/channel/UCbfYPyITQ-7l4upoX8nvctg), and there's like a thousand lines of code at most, but *tons* of input data.

Given how fast the field seems to be moving, is that because there's so much fertile ground, combined with a relatively easy and simple programming hurdle, or is it moreso that there's just a ton of researchers approaching it right now?

Here's an example for the amazing SuperResolution project https://github.com/fperazzi/proSR featured in [this video](https://www.youtube.com/watch?v=HvH0b9K_Iro) for example. 

Now don't get me wrong, I could not write something like this myself, but it seems like it's fairly straightforward, but I'm 100% ignorant of the challenges they face, so that's why I'm asking the question. 

Thanks for taking the time to help me better understand!",11,1,False,self,,,,,
254,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,4,9lf323,self.MachineLearning,I build a simple app that allows you to turn your trained model into a REST endpoint for everyone to use.,https://www.reddit.com/r/MachineLearning/comments/9lf323/i_build_a_simple_app_that_allows_you_to_turn_your/,tsuberim,1538681468,[removed],0,1,False,self,,,,,
255,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,5,9lfcmw,self.MachineLearning,[R] [questionnaire] Age estimation from audio,https://www.reddit.com/r/MachineLearning/comments/9lfcmw/r_questionnaire_age_estimation_from_audio/,Goron97,1538683275,"Dear fellow scholars, 

&amp;#x200B;

we are working on a method that automatically estimates an age of a speaker from audio, i.e. without seeing the speaker. We did not find any study presenting how accurate people are in their estimates. So, we would like to know a human baseline. If you have 5 minutes of your time, please kindly fill in the following simple form: 

&amp;#x200B;

[http://bit.ly/age-estimation](https://bit.ly/age-estimation)

&amp;#x200B;

There are 20 short recordings you can play freely, then guess how old the speaker is. The questionnaire is anonymous, but you can leave your email if you are interested in early results of the study. We will also appreciate if you distribute our survey to your friends. 

&amp;#x200B;

Thank you very much for your help. ",0,1,False,self,,,,,
256,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,5,9lfj5d,goo.gl,[R] [questionnaire] Age detection from audio,https://www.reddit.com/r/MachineLearning/comments/9lfj5d/r_questionnaire_age_detection_from_audio/,Goron97,1538684498,,1,1,False,default,,,,,
257,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,5,9lfmaj,deepideas.net,Building a Content-Based Search Engine: Signature Quadratic Form Distance,https://www.reddit.com/r/MachineLearning/comments/9lfmaj/building_a_contentbased_search_engine_signature/,deepideas,1538685114,,0,1,False,https://a.thumbs.redditmedia.com/17ckDh4Zdt5kUr8bvio7cWhgeRr90Y2toBj7YjN73X0.jpg,,,,,
258,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,5,9lfs0p,dl.acm.org,Joint Discrete and Continuous Emotion Prediction Using Ensemble and End-to-End Approaches,https://www.reddit.com/r/MachineLearning/comments/9lfs0p/joint_discrete_and_continuous_emotion_prediction/,ebadawy,1538686193,,0,1,False,default,,,,,
259,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,5,9lfuuq,self.MachineLearning,Identify data points from t-SNE plot?,https://www.reddit.com/r/MachineLearning/comments/9lfuuq/identify_data_points_from_tsne_plot/,cwcreddit,1538686754,"Is it possible to run t-SNE on a large data set, then figure out which data points I start with are in which cluster? How would I implement something like that?",0,1,False,self,,,,,
260,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,6,9lfvg4,self.MachineLearning,Multi-task Learning architectures code snippets,https://www.reddit.com/r/MachineLearning/comments/9lfvg4/multitask_learning_architectures_code_snippets/,edunuke,1538686868,[removed],0,1,False,self,,,,,
261,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,7,9lgfa3,self.MachineLearning,"Amazon - Seeking Applied, Data and Research Scientists",https://www.reddit.com/r/MachineLearning/comments/9lgfa3/amazon_seeking_applied_data_and_research/,Colin_Amazonian,1538690792,[removed],0,1,False,self,,,,,
262,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,7,9lgtzt,zdnet.com,"Neuton: A new, disruptive neural network framework for AI applications | ZDNet",https://www.reddit.com/r/MachineLearning/comments/9lgtzt/neuton_a_new_disruptive_neural_network_framework/,avturchin,1538693859,,0,1,False,https://b.thumbs.redditmedia.com/jP6X2VconfKkreDMfXIl8Cup7Q_rUBxXzr2IENOaeXw.jpg,,,,,
263,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,8,9lgymt,i.redd.it,Boo!,https://www.reddit.com/r/MachineLearning/comments/9lgymt/boo/,temptempyahoo,1538694834,,0,1,False,https://a.thumbs.redditmedia.com/96So6ijACR4uLskwGyRUJjNBHg8cE1As_c-AIp_gnF0.jpg,,,,,
264,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,8,9lh0hm,hypertrack.com,Deriving data insights from on-demand delivery using activity data,https://www.reddit.com/r/MachineLearning/comments/9lh0hm/deriving_data_insights_from_ondemand_delivery/,sasaram,1538695248,,0,1,False,https://b.thumbs.redditmedia.com/xy2PipWScqcp0V2tVl9pd3WJZp0yw9aYzr0LGV-zEPA.jpg,,,,,
265,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,8,9lh468,pcc.cs.byu.edu,Holodeck - a High Fidelity Simulator for Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/9lh468/holodeck_a_high_fidelity_simulator_for/,joshgreaves,1538696064,,21,1,False,default,,,,,
266,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,8,9lh5cb,self.MachineLearning,Training on multiple datasets and losses,https://www.reddit.com/r/MachineLearning/comments/9lh5cb/training_on_multiple_datasets_and_losses/,divyanshpal91,1538696319,[removed],0,1,False,self,,,,,
267,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,9,9lhdvw,openreview.net,[R] Neural Rendering Model: Joint Generation and Prediction for Semi-Supervised Learning,https://www.reddit.com/r/MachineLearning/comments/9lhdvw/r_neural_rendering_model_joint_generation_and/,_SunBrah_,1538698248,,2,1,False,default,,,,,
268,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,9,9lhele,self.MachineLearning,"[D] Is this possible in Pytorch or Tensorflow? Only loading and training a fraction of the weights from a model ? This is for instances where not all weights are trained in each batch, like word2vec. The purpose of this is to create much bigger models within memory limits.",https://www.reddit.com/r/MachineLearning/comments/9lhele/d_is_this_possible_in_pytorch_or_tensorflow_only/,Research2Vec,1538698375,"I am trying to train weights for items using a word2vec algorithm. I have millions of items, so with embedding sizes of 3 figures, I have hundreds of millions or even billions of weights to train. 

This causes my GPU to crash due to lack of memory. 

The thing is, with word2vec algorithms, each training iteration only needs the embeddings of the labels, the embeddings of the batch, and the embeddings for the negative samples (for negative sampling). So just a few hundred or few thousand embeddings, out of the millions. 

This would require **much** less memory. 

I am wondering if it's possible to do something like this in Tensorflow or Pytorch. I realize this will be much slower, but I rather train slowly then to significantly reduce my embedding sizes. ",14,1,False,self,,,,,
269,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,10,9lhrhq,self.MachineLearning,Created a Book Recommender System using RBMs. Need inputs to make it more robust and build an app out of it!,https://www.reddit.com/r/MachineLearning/comments/9lhrhq/created_a_book_recommender_system_using_rbms_need/,adityashrm21,1538701303,[removed],0,1,False,self,,,,,
270,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,10,9li1q2,self.MachineLearning,Free Deep Learning Book (MIT Press),https://www.reddit.com/r/MachineLearning/comments/9li1q2/free_deep_learning_book_mit_press/,andrea_manero,1538703678,[removed],0,1,False,self,,,,,
271,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,11,9liaq1,getrevue.co,Awesome Computer Science - #9,https://www.reddit.com/r/MachineLearning/comments/9liaq1/awesome_computer_science_9/,Enterprisesoft,1538705768,,0,1,False,https://b.thumbs.redditmedia.com/m9tTNDjuKptYXJ2Y8RwEpnxlC4g46s_QFJ0Z0mvFpZY.jpg,,,,,
272,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,12,9liujh,self.MachineLearning,is there an open source NLP algorithm for reading financial statements?,https://www.reddit.com/r/MachineLearning/comments/9liujh/is_there_an_open_source_nlp_algorithm_for_reading/,akorrafan,1538710651,"Hi, everyone. This problem is having a bunch of investment portfolio statements, and trying to have an ML tool read them to extract relationships about who owns what portfolio, and identify what funds or assets are invested in each of those portfolios. 

Not sure if something open source (preferably python) is already out there, or, if not, where to start. Thanks!",0,1,False,self,,,,,
273,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,12,9liw9b,self.MachineLearning,[D] Cheaper to buy a Deep Learning rig or rent it out on Amazon?,https://www.reddit.com/r/MachineLearning/comments/9liw9b/d_cheaper_to_buy_a_deep_learning_rig_or_rent_it/,cbsudux,1538711083,,14,1,False,self,,,,,
274,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,12,9liy2p,self.MachineLearning,Formula for Hypothesis space in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9liy2p/formula_for_hypothesis_space_in_machine_learning/,kiramonchan,1538711572,[removed],0,1,False,self,,,,,
275,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,13,9lj5dn,datasciencecentral.com,Machine Learning for Lotteries,https://www.reddit.com/r/MachineLearning/comments/9lj5dn/machine_learning_for_lotteries/,hiren_p,1538713449,,0,1,False,default,,,,,
276,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,13,9ljcr1,blog.yellowant.com,Can Machines Learn To Understand Our Dreams?,https://www.reddit.com/r/MachineLearning/comments/9ljcr1/can_machines_learn_to_understand_our_dreams/,JayaYellowAnt,1538715445,,0,1,False,default,,,,,
277,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,14,9ljee2,pugetsystems.com,"NVIDIA RTX 2080 Ti vs 2080 vs 1080 Ti vs Titan V, TensorFlow Performance with CUDA 10.0",https://www.reddit.com/r/MachineLearning/comments/9ljee2/nvidia_rtx_2080_ti_vs_2080_vs_1080_ti_vs_titan_v/,Marha01,1538715889,,0,1,False,default,,,,,
278,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,14,9ljgso,self.MachineLearning,Help needed :Transfer learning on Models trained on Face Datasets,https://www.reddit.com/r/MachineLearning/comments/9ljgso/help_needed_transfer_learning_on_models_trained/,ankur248,1538716541,"I know about VGG-Face , but are there other models like this ? ",0,1,False,self,,,,,
279,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,14,9ljjo1,self.MachineLearning,Few things about Machine learning,https://www.reddit.com/r/MachineLearning/comments/9ljjo1/few_things_about_machine_learning/,NearLearnguru,1538717404,[removed],0,1,False,self,,,,,
280,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,14,9ljlai,self.MachineLearning,Observing Mode collapse on a synthetic dataset when training WGAN with Gradient Penalty.,https://www.reddit.com/r/MachineLearning/comments/9ljlai/observing_mode_collapse_on_a_synthetic_dataset/,YBuzzinGA,1538717903,[removed],0,1,False,self,,,,,
281,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,14,9ljnm3,self.MachineLearning,[R] Observing Mode collapse on a synthetic dataset when training WGAN with Gradient Penalty.,https://www.reddit.com/r/MachineLearning/comments/9ljnm3/r_observing_mode_collapse_on_a_synthetic_dataset/,YBuzzinGA,1538718611,"Hello, I am working on getting up to speed on training the wonderful GAN models. For this purpose I was trying to re-create the synthetic scenario of learning a data distribution supported on a 1-D manifold in R2 and learning a generative model for it using WGAN with gradient penalty method. This case is similar to the problem discussed in the original WGAN paper's example-1 (https://arxiv.org/pdf/1701.07875.pdf) with the difference that the data distribution on the y-axis in my setup is a 1D Mixture of Gaussians (as opposed to the Uniform distribution used in the paper's example). I observe that using the WGAN_GP method, the generator rather quickly learns to map the standard normal latent variables to the 1-D distribution that is supported by my data. But I observe a mode collapse on the 1-D manifold, that is, the generator always learns to generate samples from one strong gaussian mode ( from among 3 gaussian modes ( with means=[0, 4.5, 8.2] and variances=[0.05, 0.5, 0.25] in my example dataset) present in my data distribution).

Please find the snapshots of the samples generated during the training in this link : https://drive.google.com/drive/folders/1IlP8_9zGiVolwQNktRzlMXarMCfJAi9D?usp=sharing In the plots, the samples in blue color are generated from my true data distribution, the green ones are the latent variable samples from a 0-mean Gaussian distribution. The red samples are the ones generated by the generator function trained using the WGAN with Gradient Penalty method (https://arxiv.org/pdf/1704.00028.pdf).

I have read in multiple places (including the original papers) that the WGAN procedure typically avoids the mode collapse problem due to the critic fuction providing useful gradients to train the generator in almost the entire space supported by P_data and P_model. So I am wondering what might be causing the mode collapse that I am observing in this setup. Can someone please tell me if they too observed such phenomenon or if it is expected to happen in this specific case ( I tried to reason but could not find why that might be the case) or if I need to train it for more number of iterations to start seeing samples from other modes in my example.

Any comments, suggestions are welcome!

Thanks in advance!",13,1,False,self,,,,,
282,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,14,9ljp40,self.MachineLearning,Is the Interactive Activation and Competition Model still used?,https://www.reddit.com/r/MachineLearning/comments/9ljp40/is_the_interactive_activation_and_competition/,redmage123,1538719050,[removed],0,1,False,self,,,,,
283,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,14,9ljp7h,byteacademy.co,a great beginner's guide to Binomial Logistic Regression,https://www.reddit.com/r/MachineLearning/comments/9ljp7h/a_great_beginners_guide_to_binomial_logistic/,saloni_ba,1538719086,,0,1,False,default,,,,,
284,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,15,9lk0ug,self.MachineLearning,Has anyone applied reinforcement learning outside robotics/game/simulation environment?,https://www.reddit.com/r/MachineLearning/comments/9lk0ug/has_anyone_applied_reinforcement_learning_outside/,nikogamulin,1538722737,[removed],0,1,False,self,,,,,
285,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,16,9lk524,self.MachineLearning,Need some help with my data mining assignment,https://www.reddit.com/r/MachineLearning/comments/9lk524/need_some_help_with_my_data_mining_assignment/,Rando8128,1538724046,[removed],0,1,False,self,,,,,
286,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,17,9lkfc0,/r/MachineLearning/comments/9lkfc0/artificial_intelligence_developer_interviewed_by/,Artificial Intelligence Developer Interviewed by Deadpool,https://www.reddit.com/r/MachineLearning/comments/9lkfc0/artificial_intelligence_developer_interviewed_by/,aiprobably,1538727678,,0,1,False,https://b.thumbs.redditmedia.com/TFiAN23WI_VDg-mDu66tsoU3B-LsWbDk8NpeCdkP7OY.jpg,,,,,
287,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,18,9lkqhk,self.MachineLearning,Reviews for datarobot?,https://www.reddit.com/r/MachineLearning/comments/9lkqhk/reviews_for_datarobot/,Poepholuk,1538731414,I'm interested to get opinions on how datarobot works and if it is useful. I hear their accuracy metrics can be a bit smoke and mirrors.,0,1,False,self,,,,,
288,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,18,9lkquh,self.MachineLearning,[D] When is greedy the best exploration choice for contextual bandits?,https://www.reddit.com/r/MachineLearning/comments/9lkquh/d_when_is_greedy_the_best_exploration_choice_for/,temporary_idiot_420,1538731527,"Hi all,

this might be some very specific questions about contextual bandits and the exploration/exploitation tradeoff. I'm sorry, if I'm just throwing in something, but maybe someone can help me with the following:

There are a bunch of rather new papers  


[Mostly Exploration-Free Algorithms for Contextual Bandits](https://arxiv.org/pdf/1704.09011.pdf)  


[Smoothed Analysis of the Greedy Algorithm for the Linear Contextual Bandit Problem](https://arxiv.org/pdf/1801.03423.pdf)  


[A Contextual Bandit Bake-off](https://arxiv.org/pdf/1802.04064.pdf)  


[The Externalities of Exploration and How Data Diversity Helps Exploitation](https://arxiv.org/pdf/1806.00543.pdf)

which indicate that sometimes, when the contexts are diverse enough, we don't need to perform explicit exploration and can just pick our choices greedily.

Did I understand correctly, that the proofs just hold for linear models?

Is this basically about the smallest eigenvalue of the data's covariance matrix fulfilling a certain criterion?

I have a dataset and apply different regression models and it seems like greedy outperforms all explorations methods I tested. It would be good, if I could support this observation with something formal instead of just something empirical. How can I approach this?

Do you guys have any experience in this topic?

Your help is appreciated.",8,1,False,self,,,,,
289,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,18,9lkrky,selfgrowth.com,The Rise of AI &amp; Machine Learning in the Transportation &amp; Logistics Industry,https://www.reddit.com/r/MachineLearning/comments/9lkrky/the_rise_of_ai_machine_learning_in_the/,kiranaloha,1538731764,,0,1,False,default,,,,,
290,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,19,9lky6p,arxiv.org,[1810.02054] Gradient Descent Provably Optimizes Over-parameterized Neural Networks,https://www.reddit.com/r/MachineLearning/comments/9lky6p/181002054_gradient_descent_provably_optimizes/,ihaphleas,1538733874,,64,1,False,default,,,,,
291,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,19,9lkyf8,arxiv.org,[1810.02328] A Practical Approach to Sizing Neural Networks,https://www.reddit.com/r/MachineLearning/comments/9lkyf8/181002328_a_practical_approach_to_sizing_neural/,ihaphleas,1538733948,,3,1,False,default,,,,,
292,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,20,9llcm1,self.MachineLearning,"[P] Awesome Human Pose Estimation : A collection of resources on 2D and 3D Pose estimation, 3D shape generation, Person Image generation and a lot more.",https://www.reddit.com/r/MachineLearning/comments/9llcm1/p_awesome_human_pose_estimation_a_collection_of/,cbsudux,1538738039,[removed],0,1,False,self,,,,,
293,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,21,9llq2c,self.MachineLearning,[D] I have completed the book 'Machine Learning with R' and was wondering what to do next and how to steer in right direction.,https://www.reddit.com/r/MachineLearning/comments/9llq2c/d_i_have_completed_the_book_machine_learning_with/,RGODRGOD,1538741583,I am learning R in my free time in college though I don't need as per the branch i am in but I am actively doing it and want to take it to the expert level.,13,1,False,self,,,,,
294,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,21,9llrs8,self.MachineLearning,The Future of AI,https://www.reddit.com/r/MachineLearning/comments/9llrs8/the_future_of_ai/,The_Syndicate_VC,1538742002,[removed],0,1,False,self,,,,,
295,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,21,9llw9m,self.MachineLearning,[D] What is ICLR 2019's Rebuttal and Decisions Dates?,https://www.reddit.com/r/MachineLearning/comments/9llw9m/d_what_is_iclr_2019s_rebuttal_and_decisions_dates/,Shani_Gamrian,1538743067,Could not find it on their website.,0,1,False,self,,,,,
296,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,21,9llzss,self.MachineLearning,Show reddit: we launched an unlimited data cleaning service,https://www.reddit.com/r/MachineLearning/comments/9llzss/show_reddit_we_launched_an_unlimited_data/,Coup1,1538743886,[removed],0,1,False,self,,,,,
297,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,22,9lm7kj,medium.com,Baffled by Covariance and Correlation??? Get the Math and the Application in Analytics for both the terms,https://www.reddit.com/r/MachineLearning/comments/9lm7kj/baffled_by_covariance_and_correlation_get_the/,SrishtiSaha,1538745556,,0,1,False,default,,,,,
298,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,22,9lmawn,self.MachineLearning,Books for hyper-parameter optimization.,https://www.reddit.com/r/MachineLearning/comments/9lmawn/books_for_hyperparameter_optimization/,keyurparalkar,1538746299,[removed],0,1,False,self,,,,,
299,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,22,9lmb2v,self.MachineLearning,[R] Now you can tailor a deep net to your data,https://www.reddit.com/r/MachineLearning/comments/9lmb2v/r_now_you_can_tailor_a_deep_net_to_your_data/,sgi_love,1538746337,"https://arxiv.org/abs/1810.02328

The times of guessing and checking the size of a deep neural network are over!",7,1,False,self,,,,,
300,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,22,9lmcx0,self.MachineLearning,Any bad papers on scene reconstruction?,https://www.reddit.com/r/MachineLearning/comments/9lmcx0/any_bad_papers_on_scene_reconstruction/,uakbar,1538746742,[removed],0,1,False,self,,,,,
301,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,23,9lmlxu,zeolearn.com,How will AI and Machine Learning revolutionize e-learning?,https://www.reddit.com/r/MachineLearning/comments/9lmlxu/how_will_ai_and_machine_learning_revolutionize/,Zeolearn,1538748619,,0,1,False,default,,,,,
302,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,23,9lmqsd,techrepublic.com,How to become a machine learning engineer: A cheat sheet,https://www.reddit.com/r/MachineLearning/comments/9lmqsd/how_to_become_a_machine_learning_engineer_a_cheat/,PavanBelagatti,1538749617,,0,1,False,https://b.thumbs.redditmedia.com/E_TBubmVOXNSDxf8rJXFZ3OMlZ41mYy5q5PX1OybSmQ.jpg,,,,,
303,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,23,9lmufc,self.MachineLearning,"Has any work looked into training neural networks to provide inputs for other ML algorithms? (Random forest, SVM, etc)",https://www.reddit.com/r/MachineLearning/comments/9lmufc/has_any_work_looked_into_training_neural_networks/,kds_medphys,1538750346,[removed],0,1,False,self,,,,,
304,MachineLearning,t5_2r3gv,2018-10-5,2018,10,5,23,9lmv0u,blog.milton.ai,Helpful Pytorch Questions and Answers from StackOverflow,https://www.reddit.com/r/MachineLearning/comments/9lmv0u/helpful_pytorch_questions_and_answers_from/,theNonlinearity,1538750457,,0,1,False,default,,,,,
305,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,0,9ln0xy,blog.milton.ai,[D] Helpful PyTorch Questions and Answers from StackOverflow,https://www.reddit.com/r/MachineLearning/comments/9ln0xy/d_helpful_pytorch_questions_and_answers_from/,theNonlinearity,1538751656,,0,1,False,https://b.thumbs.redditmedia.com/vsy0vAFYHVebxqXjKLiragIaXVYKjYQKUtTkWlNdNbg.jpg,,,,,
306,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,0,9ln4gv,dotnetlovers.com,Simple Linear Regression and Multiple Linear Regression explanation and prediction,https://www.reddit.com/r/MachineLearning/comments/9ln4gv/simple_linear_regression_and_multiple_linear/,coolnikhilj22,1538752317,,0,1,False,default,,,,,
307,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,0,9ln5ar,som.yale.edu,Who is attending this event?,https://www.reddit.com/r/MachineLearning/comments/9ln5ar/who_is_attending_this_event/,Yale_machine_learnin,1538752473,,2,1,False,https://b.thumbs.redditmedia.com/IiHNsE4OThWs_KzB3elc6jlsrgpiREbhcIKMKzasraM.jpg,,,,,
308,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,0,9lnb36,self.MachineLearning,How to begin with Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/9lnb36/how_to_begin_with_reinforcement_learning/,martingirish,1538753581,[removed],0,1,False,self,,,,,
309,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,0,9lni89,blog.aylien.com,A Review of the Neural History of Natural Language Processing,https://www.reddit.com/r/MachineLearning/comments/9lni89/a_review_of_the_neural_history_of_natural/,parsabg,1538754957,,0,1,False,default,,,,,
310,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,0,9lnja3,self.MachineLearning,[D] Does anybody know when the camera-ready NIPS paper will be out?,https://www.reddit.com/r/MachineLearning/comments/9lnja3/d_does_anybody_know_when_the_cameraready_nips/,schrodingershit,1538755163,,5,1,False,self,,,,,
311,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,1,9lnjy0,pynative.com,"Complete Guide to Generate Random data in Python ""[Research]""",https://www.reddit.com/r/MachineLearning/comments/9lnjy0/complete_guide_to_generate_random_data_in_python/,rahuldev29,1538755284,,1,1,False,default,,,,,
312,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,1,9lnm0w,self.MachineLearning,Help and some clarification needed,https://www.reddit.com/r/MachineLearning/comments/9lnm0w/help_and_some_clarification_needed/,sairaamv92,1538755642,[removed],0,1,False,self,,,,,
313,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,1,9lnnqq,self.MachineLearning,Cool app for exploring concepts in machine learning.,https://www.reddit.com/r/MachineLearning/comments/9lnnqq/cool_app_for_exploring_concepts_in_machine/,cybernetic80,1538755957,[removed],0,1,False,https://b.thumbs.redditmedia.com/bB1Pda0WxA06E4uaYVyd8vfpAXceVqANQKTodUu9yWs.jpg,,,,,
314,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,1,9lnrx9,self.MachineLearning,[Research] Help relating to a theorem in machine learning,https://www.reddit.com/r/MachineLearning/comments/9lnrx9/research_help_relating_to_a_theorem_in_machine/,sairaamv92,1538756738,"This is related to a theorem that I have proved and its relation (or not) to an existing result.

Essentially, I have shown that PAC-learning is undecidable in the Turing sense. The arxiv link to the paper is [https://arxiv.org/abs/1808.06324](https://arxiv.org/abs/1808.06324)

I am told that this is provable as a corollary of existing results. I was hinted that the fundamental theorem of statistical machine learning that relates the VC dimension and PAC-learning could be used to prove the undecidability of PAC-learning. An arxiv link to a set of notes for this is  [https://arxiv.org/abs/1507.05307](https://arxiv.org/abs/1507.05307)

I am confused, however. I understand that that the above theorem stipulates a condition for the learnability of functions and does not comment about the Turing-decidability of the same.

Can someone help me, please?

&amp;#x200B;",4,1,False,self,,,,,
315,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,1,9lns9s,self.MachineLearning,Future of Digital Marketing  Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9lns9s/future_of_digital_marketing_machine_learning/,peteriuvara,1538756798,[removed],0,1,False,self,,,,,
316,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,1,9lntwy,self.MachineLearning,Creating Partially Connected NNs with specified connections using Tensorflow (or something else)?,https://www.reddit.com/r/MachineLearning/comments/9lntwy/creating_partially_connected_nns_with_specified/,pinard9,1538757090,"Hi!

&amp;#x200B;

I'd like to implement a partially connected neural network with  \~3-4 hidden layers (a sparse deep neural network?) where I can specify which node connects to which node from the previous/next layer. So I want the architecture to be

highly specified/customized from the get go and I want the neural network to optimize the weights of the specified connections, while keeping everything else 0 during the forward pass and the backprogopagation (connection does not exist). I am a complete beginner in neural networks. I have been recently working with tensorflow &amp; tensorflow-keras to construct fully connected deep networks. Is there anything in tensorflow that I should look into that might allow me to do this? I think I should be able to specify the computational graph such that only certain connections exist but I really have no idea yet where to start from to do this...

&amp;#x200B;

While doing some online research, I came across papers/posts on network pruning, but it doesn't seem really relevant to me. I don't want to go back and prune my network to make it less over-parameterized or eliminate insignificant connections. I want the connections to be specified and the network to be relatively sparse from the initialization and stay that way during the backprogopagation.

&amp;#x200B;

Thank!",0,1,False,self,,,,,
317,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,1,9lny5o,self.MachineLearning,[D] What happens when you pit an XGBoost model against a scorecard?,https://www.reddit.com/r/MachineLearning/comments/9lny5o/d_what_happens_when_you_pit_an_xgboost_model/,makennabreit,1538757877,"Anyone have any thoughts on when it's best to use se ML v. Scorecards?

This blog compares predicted probabilities vs. observed proportions at the feature/predictor level. The example finds that  the XGBoost model is consistently under-estimating good credit risk across all bins of this predictor while the risk Scorecard demonstrates less discrepancy between the estimated and observed outcome.

[https://community.fico.com/s/blog-post/a5Q80000000DsL6EAK](https://community.fico.com/s/blog-post/a5Q80000000DsL6EAK)

&amp;#x200B;",3,1,False,self,,,,,
318,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,1,9lnzur,self.MachineLearning,Tyring to pick courses to get a strong grasp on machine learning,https://www.reddit.com/r/MachineLearning/comments/9lnzur/tyring_to_pick_courses_to_get_a_strong_grasp_on/,MachineInTheStone,1538758182,[removed],0,1,False,self,,,,,
319,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,1,9lo0he,arxiv.org,Deep Neural Network Structures Solving Variational Inequalities,https://www.reddit.com/r/MachineLearning/comments/9lo0he/deep_neural_network_structures_solving/,netw0rkf10w,1538758293,,5,1,False,default,,,,,
320,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,2,9lo5ov,self.MachineLearning,Is process optimization/scheduling a good application for ML?,https://www.reddit.com/r/MachineLearning/comments/9lo5ov/is_process_optimizationscheduling_a_good/,AnodeAnonymous,1538759270,[removed],0,1,False,self,,,,,
321,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,3,9lor4d,youtu.be,Computerphile --&gt; AGI safety using logical induction,https://www.reddit.com/r/MachineLearning/comments/9lor4d/computerphile_agi_safety_using_logical_induction/,turtle_13,1538763185,,0,1,False,https://a.thumbs.redditmedia.com/RylRPHwkSOLGdUpLJocfKk-X6TZhKNKGNZ8lfrGkb70.jpg,,,,,
322,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,5,9lpu9d,github.com,Hyperparameter Optimization for Keras Models,https://www.reddit.com/r/MachineLearning/comments/9lpu9d/hyperparameter_optimization_for_keras_models/,mikkokotila,1538770797,,0,1,False,default,,,,,
323,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,6,9lqoqw,self.MachineLearning,Did anyone hear back from Google AI residency (healthcare) 2019?,https://www.reddit.com/r/MachineLearning/comments/9lqoqw/did_anyone_hear_back_from_google_ai_residency/,bliss_of_solitude,1538776528,[removed],0,1,False,self,,,,,
324,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,7,9lqqx7,self.MachineLearning,How Machine Learning is Revolutionizing Digital Enterprises,https://www.reddit.com/r/MachineLearning/comments/9lqqx7/how_machine_learning_is_revolutionizing_digital/,andrea_manero,1538776930,[removed],0,1,False,self,,,,,
325,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,7,9lqy3b,self.MachineLearning,Did anyone hear back from Google AI residency (healthcare) 2019?,https://www.reddit.com/r/MachineLearning/comments/9lqy3b/did_anyone_hear_back_from_google_ai_residency/,bliss_of_solitude,1538778379,[removed],1,1,False,self,,,,,
326,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,7,9lqykz,self.MachineLearning,[D] Text segmentation techniques?,https://www.reddit.com/r/MachineLearning/comments/9lqykz/d_text_segmentation_techniques/,plucesiar,1538778475,"I have a massive dump of raw text files that seem to have been manually copied from various pdfs, meaning that it includes a lot of extraneous text, like page numbers, etc.  Problem is that these are different pdfs, so theres no simply defined pattern consistent across documents for a regex pattern to clean.  Is there some gold standard text segmentation technique to tackle this problem?",9,1,False,self,,,,,
327,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,8,9lrl1u,self.MachineLearning,Clear guides on how to apply KNN or K-means on a high definition image for object detection?,https://www.reddit.com/r/MachineLearning/comments/9lrl1u/clear_guides_on_how_to_apply_knn_or_kmeans_on_a/,Jddocs12,1538783776,[removed],0,1,False,self,,,,,
328,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,9,9lry54,self.MachineLearning,Reasons to use c/c++ over python for machine learning?,https://www.reddit.com/r/MachineLearning/comments/9lry54/reasons_to_use_cc_over_python_for_machine_learning/,MachineInTheStone,1538787016,[removed],0,1,False,self,,,,,
329,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,11,9lsk3r,arxiv.org,Extracting pixel-level masks of extreme weather patterns using variants of Tiramisu and DeepLabv3+ neural networks,https://www.reddit.com/r/MachineLearning/comments/9lsk3r/extracting_pixellevel_masks_of_extreme_weather/,Dennyglee,1538792829,,5,1,False,default,,,,,
330,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,11,9lsnva,self.MachineLearning,My TED talk on Artificial Intelligence addressing the Terminator fears.,https://www.reddit.com/r/MachineLearning/comments/9lsnva/my_ted_talk_on_artificial_intelligence_addressing/,Sushrit_Lawliet,1538793863,[removed],0,1,False,self,,,,,
331,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,11,9lsqfx,self.MachineLearning,can someone solve this simple linear regression test?,https://www.reddit.com/r/MachineLearning/comments/9lsqfx/can_someone_solve_this_simple_linear_regression/,umbrelamafia,1538794581,[removed],0,1,False,self,,,,,
332,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,12,9lssjs,analyticsvidhya.com,Best Machine Learning github repositories with code!,https://www.reddit.com/r/MachineLearning/comments/9lssjs/best_machine_learning_github_repositories_with/,jayjay59,1538795173,,0,1,False,default,,,,,
333,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,13,9lt5rx,self.MachineLearning,Desktop Build,https://www.reddit.com/r/MachineLearning/comments/9lt5rx/desktop_build/,WranglerOverload,1538799002,[removed],0,1,False,self,,,,,
334,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,14,9ltm9y,arxiv.org,[1810.01993] Exascale Deep Learning for Climate Analytics: Tensorflow on 27360 Volta GPUs,https://www.reddit.com/r/MachineLearning/comments/9ltm9y/181001993_exascale_deep_learning_for_climate/,phobrain,1538803989,,0,1,False,default,,,,,
335,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,14,9ltml3,self.MachineLearning,"how to synthesize data for faster-rcnn for logo images, give i have just the logo images",https://www.reddit.com/r/MachineLearning/comments/9ltml3/how_to_synthesize_data_for_fasterrcnn_for_logo/,mumbaimaari,1538804082,[removed],0,1,False,self,,,,,
336,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,14,9ltq0w,self.MachineLearning,Grouping images approach for recently recovered files,https://www.reddit.com/r/MachineLearning/comments/9ltq0w/grouping_images_approach_for_recently_recovered/,maye-scs,1538805216,[removed],0,1,False,self,,,,,
337,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,14,9ltqt1,imarticus.org,The Origins and History of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9ltqt1/the_origins_and_history_of_machine_learning/,imarticus_nirmal,1538805465,,0,1,False,default,,,,,
338,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,15,9ltx5r,self.MachineLearning,What to expect for data and applied Scientist interview at Microsoft Bing ads?,https://www.reddit.com/r/MachineLearning/comments/9ltx5r/what_to_expect_for_data_and_applied_scientist/,mrcet007,1538807603,[removed],0,1,False,self,,,,,
339,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,15,9lty5b,imarticus.org,15 Questions to Ask at Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9lty5b/15_questions_to_ask_at_machine_learning/,imarticus_nirmal,1538807967,,0,1,False,default,,,,,
340,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,15,9ltzsu,imarticus.org,5 Simple But Important Things to Remember About Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9ltzsu/5_simple_but_important_things_to_remember_about/,imarticus_nirmal,1538808567,,0,1,False,default,,,,,
341,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,15,9lu1hs,imarticus.org,10 Common Myths About Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9lu1hs/10_common_myths_about_machine_learning/,imarticus_nirmal,1538809165,,0,1,False,default,,,,,
342,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,16,9lu3iy,imarticus.org,7 Preparations You Should Make Before Using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9lu3iy/7_preparations_you_should_make_before_using/,imarticus_nirmal,1538809836,,0,1,False,default,,,,,
343,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,16,9lu55u,imarticus.org,7 Preparations You Should Make Before Using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9lu55u/7_preparations_you_should_make_before_using/,imarticus_nirmal,1538810450,,0,1,False,default,,,,,
344,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,16,9lu61v,mamathaindustries.blogspot.com,Precision machined components manufacturers in India,https://www.reddit.com/r/MachineLearning/comments/9lu61v/precision_machined_components_manufacturers_in/,mamathaindustries,1538810760,,0,1,False,https://a.thumbs.redditmedia.com/YBst2ZyFdsy2AEockmSAK94FTnJlcO813c9fbzUzOf4.jpg,,,,,
345,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,16,9lu6q3,self.MachineLearning,How to fetch text from pdf to further proceed with question answer based model from the same document?,https://www.reddit.com/r/MachineLearning/comments/9lu6q3/how_to_fetch_text_from_pdf_to_further_proceed/,arijitonline8,1538811001,[removed],0,1,False,self,,,,,
346,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,16,9lu73w,imarticus.org,7 Lessons That Will Teach You All You Need To Know About Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9lu73w/7_lessons_that_will_teach_you_all_you_need_to/,imarticus_nirmal,1538811155,,0,1,False,default,,,,,
347,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,16,9lu8e0,self.MachineLearning,"please refer me any study material for beginners regarding support vector regression, decision tree regression, random forest regression",https://www.reddit.com/r/MachineLearning/comments/9lu8e0/please_refer_me_any_study_material_for_beginners/,yashoo1,1538811629,,0,1,False,self,,,,,
348,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,16,9luavz,imarticus.org,7 Lessons That Will Teach You All You Need To Know About Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9luavz/7_lessons_that_will_teach_you_all_you_need_to/,imarticus_nirmal,1538812628,,0,1,False,default,,,,,
349,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,17,9luk16,blockdelta.io,"Why AI, Robotics and Blockchain are a SMART combination.",https://www.reddit.com/r/MachineLearning/comments/9luk16/why_ai_robotics_and_blockchain_are_a_smart/,BlockDelta,1538816176,,0,1,False,https://a.thumbs.redditmedia.com/QqXPwQMUamPo3pTy4bHETv2EstS4pP5TsU6m44v_-T0.jpg,,,,,
350,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,17,9lukf0,imarticus.org,10 Easy Yet Effective Rules of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9lukf0/10_easy_yet_effective_rules_of_machine_learning/,imarticus_nirmal,1538816323,,0,1,False,default,,,,,
351,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,18,9luky2,self.MachineLearning,"As a machine learner, what is your biggest pain point while training data?",https://www.reddit.com/r/MachineLearning/comments/9luky2/as_a_machine_learner_what_is_your_biggest_pain/,vedai,1538816503,[removed],0,1,False,self,,,,,
352,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,18,9lulug,self.MachineLearning,Awesome Computer Science - #11,https://www.reddit.com/r/MachineLearning/comments/9lulug/awesome_computer_science_11/,reddit-machinelearn,1538816843,"Each month, this newsletter showcases the latest computer science projects in the world. Main topics: robotics &amp; machine learning. [https://www.getrevue.co/profile/jexia/issues/awesome-computer-science-11-127317](https://www.getrevue.co/profile/jexia/issues/awesome-computer-science-11-127317)",0,1,False,self,,,,,
353,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,19,9lv1s9,self.MachineLearning,"Any current resource that synthesizes different sentences or phrases into one while maintaining meaning? For example, three different definitions are combined into one.",https://www.reddit.com/r/MachineLearning/comments/9lv1s9/any_current_resource_that_synthesizes_different/,lnhvtepn,1538822785,Something to similar to [Quillbot](https://quillbot.com/) but synthesizing multiple phrases or sentences.,0,1,False,self,,,,,
354,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,20,9lvdod,medium.com,Inspiring article about Women in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9lvdod/inspiring_article_about_women_in_machine_learning/,XiarongCui,1538826862,,0,1,False,default,,,,,
355,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,21,9lvlfc,self.ArtificialInteligence,"AI to build prototypes in the future, and how to earn from it",https://www.reddit.com/r/MachineLearning/comments/9lvlfc/ai_to_build_prototypes_in_the_future_and_how_to/,Ferrari_VIP,1538829148,,0,1,False,default,,,,,
356,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,21,9lvq2s,self.MachineLearning,Amazon SageMaker Demo,https://www.reddit.com/r/MachineLearning/comments/9lvq2s/amazon_sagemaker_demo/,AndroiderApp,1538830424,[removed],0,1,False,https://b.thumbs.redditmedia.com/nDA3izGl4sOpR0LFkIir1_egjAwkOn9kvXpyj5qMEVs.jpg,,,,,
357,MachineLearning,t5_2r3gv,2018-10-6,2018,10,6,22,9lw39z,self.MachineLearning,[D] Advice for a master's degree in Statistics in Europe,https://www.reddit.com/r/MachineLearning/comments/9lw39z/d_advice_for_a_masters_degree_in_statistics_in/,rods2292,1538833964,"I'm an actuary who is interested in machine learning and its application in insurance. Currently I'm willing to study a master's degree in Statistics to further my skills in this field and make me more competitible in the job market. Although I like to be an actuary, I know it's a narrow field since it's only related to insurance and I'd like to have more opportunities in the financial/banking sector.

I was thinking about a master's in Statistics and I'd like some recommendations of good programs in Europe. I found a lot of programs to be too theorical and, given my actuarial science background, I'd rather prefer something more applied. Does anyone know good programs in this sense? ",30,1,False,self,,,,,
358,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,1,9lx54f,self.MachineLearning,[R] Is there room for someone doing an industrial Engineering MSc to do research in ML?,https://www.reddit.com/r/MachineLearning/comments/9lx54f/r_is_there_room_for_someone_doing_an_industrial/,Yeamf93,1538842554,"I have a BSc in Applied Math, and am currently doing my Master's in Industrial &amp; Systems Eng. It's a research Master's and very project oriented. (Currently doing three projects for my 4 classes! All prediction heavy, using Regression models and ML ) 

I'm really interested in Machine Learning. I'm familiar with Neural Networks (and other MetaH algs), I'm familiar with Python (like intermediate levels) and I have almost finished the Data Science track on datacamp. It was very boring and dry, though! 

I don't know how to do research as a grad student in the industrial engineering department (we share a lot of faculty members with the MBA/Management side, and Electronics Engineering department). I don't have an advisor yet, which is why I'm asking this here. I also want to read up on a few papers, so I have something to say when I do talk to potential advisors. ",6,1,False,self,,,,,
359,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,1,9lxcsu,microsoft.com,The India Microsoft AI Challenge 2018,https://www.reddit.com/r/MachineLearning/comments/9lxcsu/the_india_microsoft_ai_challenge_2018/,rajarsheem,1538844192,,0,1,False,default,,,,,
360,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,2,9lxo72,blockdelta.io,When Robots Kill...!,https://www.reddit.com/r/MachineLearning/comments/9lxo72/when_robots_kill/,BlockDelta,1538846528,,0,1,False,https://b.thumbs.redditmedia.com/Kh7FK2SbOcQQ0zKQyua_ugMT1jgyf-E7dQJtcDMA6yg.jpg,,,,,
361,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,3,9lyet4,self.MachineLearning,[P] Progressive InfoGAN - code and paper,https://www.reddit.com/r/MachineLearning/comments/9lyet4/p_progressive_infogan_code_and_paper/,jonasz_pamula,1538851643,"Hi all,

I while back I shared a post about a project I've done, which combines the progressive training and InfoGAN techniques. Now that the code (along with a paper describing the experiment in detail) is on github, I thought I'd share it with you: [https://github.com/jonasz/progressive\_infogan/](https://github.com/jonasz/progressive_infogan/)  
Enjoy, and please reach out if you have questions / suggestions :)  
Cheers,  
Jonasz",7,1,False,self,,,,,
362,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,4,9lyk9i,youtube.com,Get free GPU for training with Google Colab - Detailed Tutorial,https://www.reddit.com/r/MachineLearning/comments/9lyk9i/get_free_gpu_for_training_with_google_colab/,Additional_Proof,1538852696,,1,1,False,default,,,,,
363,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,5,9lz5vs,self.MachineLearning,Story of AI,https://www.reddit.com/r/MachineLearning/comments/9lz5vs/story_of_ai/,reachingshar1,1538857090,"Hi everyone. I am part of a small AI research group based out of Bangalore, India. We collaborated to write, how the idea of AI came about. Here is the second article of the series.

[https://medium.com/rla-academy/dartmouth-workshop-the-birthplace-of-ai-34c533afe992](https://medium.com/rla-academy/dartmouth-workshop-the-birthplace-of-ai-34c533afe992)

I recommend that you skim through the first article... [https://medium.com/rla-academy/story-of-ai-the-prologue-87f28b466e17](https://medium.com/rla-academy/story-of-ai-the-prologue-87f28b466e17) , if you haven't yet.

&amp;#x200B;

Feedback in all shapes and sizes are welcome. Thanks :)

Motivation : I think, many people who are working in this field don't realise the work that went into creating AI (at least, what people perceive as AI).

&amp;#x200B;",0,1,False,self,,,,,
364,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,5,9lz924,self.MachineLearning,Difference in these two papers,https://www.reddit.com/r/MachineLearning/comments/9lz924/difference_in_these_two_papers/,drive29,1538857736,[removed],0,1,False,self,,,,,
365,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,5,9lzabc,self.MachineLearning,"[P] ""Mathematics for Machine Learning"": drafts for all chapters now available",https://www.reddit.com/r/MachineLearning/comments/9lzabc/p_mathematics_for_machine_learning_drafts_for_all/,seann999,1538857999,"[Site](https://mml-book.github.io/)

[Discussion from 4 months ago](https://www.reddit.com/r/MachineLearning/comments/8kifb0/n_mathematics_for_machine_learning/)

Since the beginning of the year, new chapters became available one by one, and it seems like all draft chapters have become available since a few weeks ago. Personally, as a ""math deficient"" person, I've been using this as a resource to prepare myself (yet again) for another attempt at Bishop's PRML.",55,1,False,self,,,,,
366,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,6,9lzum5,self.MachineLearning,Using machine learning to create r/Showerthoughts.,https://www.reddit.com/r/MachineLearning/comments/9lzum5/using_machine_learning_to_create_rshowerthoughts/,Romek_Buch,1538862231,[removed],0,1,False,self,,,,,
367,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,6,9lzyhq,self.MachineLearning,Machine Learning using NN on the Wrong track,https://www.reddit.com/r/MachineLearning/comments/9lzyhq/machine_learning_using_nn_on_the_wrong_track/,dbaechtel2,1538863064,[removed],2,1,False,self,,,,,
368,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,7,9m0bml,steemit.com,Simple Introduction to Computer Vision in Under 1 Hour(Tensorflow + Keras),https://www.reddit.com/r/MachineLearning/comments/9m0bml/simple_introduction_to_computer_vision_in_under_1/,hisairnessag3,1538865963,,0,1,False,default,,,,,
369,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,7,9m0eeg,self.MachineLearning,RNN vs Dense questions,https://www.reddit.com/r/MachineLearning/comments/9m0eeg/rnn_vs_dense_questions/,maxisawesome538,1538866630,[removed],0,1,False,self,,,,,
370,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,8,9m0jvn,self.MachineLearning,Real time technical discussions on ML and related?,https://www.reddit.com/r/MachineLearning/comments/9m0jvn/real_time_technical_discussions_on_ml_and_related/,nobodywillobserve,1538867909,[removed],0,1,False,self,,,,,
371,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,10,9m1inf,kaggle.com,Using Neural Network To Get Feature Importance With Super High Precision,https://www.reddit.com/r/MachineLearning/comments/9m1inf/using_neural_network_to_get_feature_importance/,microic,1538876627,,0,1,False,default,,,,,
372,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,13,9m2j8u,self.MachineLearning,Need help with my grad. school project on Fake News detection,https://www.reddit.com/r/MachineLearning/comments/9m2j8u/need_help_with_my_grad_school_project_on_fake/,fakenewssurvey2018,1538886618,"Hi Reddit,  
We are working on a project to gather information about public impressions of ""fake news"". This is part of my graduate school project where we plan to use data science for fake news detection. It would help a lot if everyone can take this 5 minute survey before Monday night. Thanks in advance!  
[https://goo.gl/forms/EHtFZ6PJrcJ7ORnN2](https://goo.gl/forms/EHtFZ6PJrcJ7ORnN2)

We are also still evaluating various text classification and other algorithms for the project. Your suggestions will help us a lot. So far we have shortlisted Naive Bayes and Fine Tune (which uses generative pre-training).",1,1,False,self,,,,,
373,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,15,9m31h7,self.MachineLearning,Machine learning to predict failures,https://www.reddit.com/r/MachineLearning/comments/9m31h7/machine_learning_to_predict_failures/,Successful_Bridge,1538892548,[removed],0,1,False,self,,,,,
374,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,15,9m33rg,self.MachineLearning,"LSTM model using Keras, two layers, each layer with different size, make sense?",https://www.reddit.com/r/MachineLearning/comments/9m33rg/lstm_model_using_keras_two_layers_each_layer_with/,albert1905,1538893324,[removed],0,1,False,self,,,,,
375,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,16,9m3h5m,goo.gl,[R] [questionnaire] Age detection from audio,https://www.reddit.com/r/MachineLearning/comments/9m3h5m/r_questionnaire_age_detection_from_audio/,Goron97,1538898429,,1,1,False,default,,,,,
376,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,17,9m3kir,self.MachineLearning,Can anyone give me a rundown of the various paradigms of ML?,https://www.reddit.com/r/MachineLearning/comments/9m3kir/can_anyone_give_me_a_rundown_of_the_various/,colebasaurus,1538899783,[removed],0,1,False,self,,,,,
377,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,18,9m3sjo,self.MachineLearning,Help with dataset consisting of daily stock returns,https://www.reddit.com/r/MachineLearning/comments/9m3sjo/help_with_dataset_consisting_of_daily_stock/,nadalska,1538903218,[removed],0,1,False,self,,,,,
378,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,18,9m3t29,self.MachineLearning,Dogs vs. Cats: Image Classification with Deep Learning using TensorFlow in Python,https://www.reddit.com/r/MachineLearning/comments/9m3t29/dogs_vs_cats_image_classification_with_deep/,andrea_manero,1538903425,[removed],0,1,False,self,,,,,
379,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,18,9m3vsh,self.MachineLearning,Is there a premade app to cluster 1000s of images?,https://www.reddit.com/r/MachineLearning/comments/9m3vsh/is_there_a_premade_app_to_cluster_1000s_of_images/,TangibleDifference,1538904621,[removed],0,1,False,self,,,,,
380,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,18,9m3x8v,github.com,[P] Facial Landmarks of Several Datasets,https://www.reddit.com/r/MachineLearning/comments/9m3x8v/p_facial_landmarks_of_several_datasets/,LynnHoHZL,1538905237,,1,1,False,default,,,,,
381,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,20,9m4aqb,self.MachineLearning,Math or cs major,https://www.reddit.com/r/MachineLearning/comments/9m4aqb/math_or_cs_major/,widowmainftw,1538910557,[removed],0,1,False,self,,,,,
382,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,20,9m4c3j,self.MachineLearning,Multiple Model on multiple machine,https://www.reddit.com/r/MachineLearning/comments/9m4c3j/multiple_model_on_multiple_machine/,pcidev,1538911056,[removed],0,1,False,self,,,,,
383,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,21,9m4n5x,self.MachineLearning,"Managing a Spotify library, Golang face recognition, Mafia &amp; more",https://www.reddit.com/r/MachineLearning/comments/9m4n5x/managing_a_spotify_library_golang_face/,programming-innovate,1538914929,"Managing a Spotify library, Golang face recognition, Mafia &amp; more - https://ift.tt/2y8xpAo, recommended on October 7, 2018 at 12:57PM
   
   
",0,1,False,self,,,,,
384,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,21,9m4p99,pugetsystems.com,Multi-GPU NVIDIA 2080Ti usage crippled due to overheating caused by side fans,https://www.reddit.com/r/MachineLearning/comments/9m4p99/multigpu_nvidia_2080ti_usage_crippled_due_to/,FrimannKjerulf,1538915579,,1,1,False,https://b.thumbs.redditmedia.com/0ZU3puNCf9Lg4XgsWshrBFlUEIfjUpK8f6GYRSSiB6Y.jpg,,,,,
385,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,22,9m4zf0,timesnownews.com,Microsoft's machine learning framework goes open source How much this means to the ML community? How is it different from existing libraries like Apache spark MLlib or Scikit Learn?,https://www.reddit.com/r/MachineLearning/comments/9m4zf0/microsofts_machine_learning_framework_goes_open/,avikd,1538918425,,0,1,False,default,,,,,
386,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,22,9m50i1,youtu.be,"""Self-supervised learning: could machines learn like humans?"" By Yann LeCun @ EPFL",https://www.reddit.com/r/MachineLearning/comments/9m50i1/selfsupervised_learning_could_machines_learn_like/,Eternahl,1538918723,,0,1,False,https://b.thumbs.redditmedia.com/YGYQ49jcohbLEz7qr6gVF6oLiCnGyDXhdPs5I318z_g.jpg,,,,,
387,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,22,9m51pw,self.MachineLearning,Microsoft's machine learning framework goes open source,https://www.reddit.com/r/MachineLearning/comments/9m51pw/microsofts_machine_learning_framework_goes_open/,avikd,1538919038,[removed],0,1,False,self,,,,,
388,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,23,9m5cg9,youtu.be,"[D] ""Self-supervised learning: could machines learn like humans?"" By Yann LeCun @ EPFL",https://www.reddit.com/r/MachineLearning/comments/9m5cg9/d_selfsupervised_learning_could_machines_learn/,Eternahl,1538921823,,0,1,False,https://b.thumbs.redditmedia.com/YGYQ49jcohbLEz7qr6gVF6oLiCnGyDXhdPs5I318z_g.jpg,,,,,
389,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,23,9m5d9d,self.MachineLearning,Thoughts of Lattice sensAI Stack for embedded solution?,https://www.reddit.com/r/MachineLearning/comments/9m5d9d/thoughts_of_lattice_sensai_stack_for_embedded/,Delengowski,1538922038,[removed],0,1,False,self,,,,,
390,MachineLearning,t5_2r3gv,2018-10-7,2018,10,7,23,9m5dnm,self.MachineLearning,[D] Where can I find older Satellite images for a change detection project?,https://www.reddit.com/r/MachineLearning/comments/9m5dnm/d_where_can_i_find_older_satellite_images_for_a/,cbsudux,1538922139,,10,1,False,self,,,,,
391,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,0,9m5sf7,self.MachineLearning,Need help with my grad. school project on Fake News detection,https://www.reddit.com/r/MachineLearning/comments/9m5sf7/need_help_with_my_grad_school_project_on_fake/,U2Fan,1538925474,[removed],0,1,False,self,,,,,
392,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,0,9m61yw,self.MachineLearning,[Peoject] looking for a project idea,https://www.reddit.com/r/MachineLearning/comments/9m61yw/peoject_looking_for_a_project_idea/,Mj_12_,1538927510,"hi guys ,
I really need your help , I am currently searching for a project idea but I am still new to machine learning and AI in general .
I have a basic understanding of deep learning and computer vision and built some simple projects and now I am looking for a real life projects ideas .
Any help is appreciated and please don't suggest the standards ones .
",0,1,False,self,,,,,
393,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,1,9m6ag7,self.MachineLearning,[D] How was backpropagation done to change the resulting image in Style Transfer using VGGnet by Gatys et.al,https://www.reddit.com/r/MachineLearning/comments/9m6ag7/d_how_was_backpropagation_done_to_change_the/,CSGOvelocity,1538929204," 

Original Paper link - [https://www.cv-foundation.org/openaccess/content\_cvpr\_2016/papers/Gatys\_Image\_Style\_Transfer\_CVPR\_2016\_paper.pdf](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf)

In  this paper I completely understand how content loss and style loss is  defined for the content image, style image and the noise (resulting  image) we are giving as input to the network.

Q1  : To calculate the gram matrix, is the image passed through the whole  network or just the layer for which the gram matrix needs to be  calculated.

Q2 : How is the style and content loss for various layers combined ?

Q3 : How is backpropagation done on the image and the network ?

By  question 3 what I mean to say is how does the backpropagation reach the  noise ( resulting image ) since we are backpropagating through the network and not the image, so how does the image get affected by it.",8,1,False,self,,,,,
394,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,1,9m6ayp,self.MachineLearning,Fraud Autoencoder in Keras weird metrics,https://www.reddit.com/r/MachineLearning/comments/9m6ayp/fraud_autoencoder_in_keras_weird_metrics/,mortenhaga,1538929308,[removed],0,1,False,self,,,,,
395,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,1,9m6fsb,self.MachineLearning,Best major for a career in ml,https://www.reddit.com/r/MachineLearning/comments/9m6fsb/best_major_for_a_career_in_ml/,widowmainftw,1538930269,[removed],0,1,False,self,,,,,
396,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,3,9m7d6j,self.MachineLearning,What's your advice to an engineer that manages Applied ML Researchers,https://www.reddit.com/r/MachineLearning/comments/9m7d6j/whats_your_advice_to_an_engineer_that_manages/,Xorify,1538936714,[removed],0,1,False,self,,,,,
397,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,5,9m8ayi,self.MachineLearning,[D] How could ML aid the implementation of environmental programs?,https://www.reddit.com/r/MachineLearning/comments/9m8ayi/d_how_could_ml_aid_the_implementation_of/,Trump_Hunter,1538943074,"Hi all,

I'm looking for examples/prospects of machine learning being used to aid environmental program implementation. Does anyone have any?",28,1,False,self,,,,,
398,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,5,9m8en7,self.MachineLearning,How do I get involved after starting my degree in ML(MS)?,https://www.reddit.com/r/MachineLearning/comments/9m8en7/how_do_i_get_involved_after_starting_my_degree_in/,sleepingtalent901,1538943812,"Okay so I started my degree at Georgia Tech in ML. I also will be taking a few courses in AI, but mostly ML.

&amp;#x200B;

I see most internships for ML are PhD only. 

That is issue #1 for me

Issue # 2, ML isnt as easy as the average web developer, to get internships in ML do they usually expect lots of projects to be done? Is ML really worth they pay out (and I dont just mean salary, but job opportunities, stability, interest of work.

&amp;#x200B;

So far I like what Im learning, I just dont know if Ill even have a chance to use it because of how hard set the requirements seem to be online for ML jobs and even internships ",0,1,False,self,,,,,
399,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,5,9m8kwy,self.MachineLearning,[P] Using AI without coding at autodeeplearning.com,https://www.reddit.com/r/MachineLearning/comments/9m8kwy/p_using_ai_without_coding_at_autodeeplearningcom/,ADL-AI,1538945091,"Hello All,

[autodeeplearning.com](https://autodeeplearning.com/) is an online platform to apply AI to your data without using any software or hardware. Our automated AI system provides you an optimised model for your data. It is designed to be used for a beginner in AI to an expert.

If you find it interesting, please go ahead and sign up to hear from us at launch of the product and also avail discounts.

We would love to hear what you think about it. You can either comment here or write to us at contact@autodeeplearning.com.",3,1,False,self,,,,,
400,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,6,9m8z0j,munchron.com,Munchron - Web-Based Disease &amp; Illness Scanner,https://www.reddit.com/r/MachineLearning/comments/9m8z0j/munchron_webbased_disease_illness_scanner/,munchron,1538948143,,0,1,False,default,,,,,
401,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,7,9m9a2z,tanmoyray.com,"Scopes of Big Data Analytics, Machine Learning and AI in the Renewable Energy Sector",https://www.reddit.com/r/MachineLearning/comments/9m9a2z/scopes_of_big_data_analytics_machine_learning_and/,tanmoyray01,1538950551,,0,1,False,https://b.thumbs.redditmedia.com/VRFj4xWfgXAALTQaBwAs7ET3G5FgnuY6_XmJircr3Aw.jpg,,,,,
402,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,7,9m9kvh,self.MachineLearning,Do you think Deep Learning can give use truly intelligent system?,https://www.reddit.com/r/MachineLearning/comments/9m9kvh/do_you_think_deep_learning_can_give_use_truly/,ifcarscouldspeak,1538953043,"We had this discussion at Bell Labs recently, and I found it fascinating.
To clarify- Do you think Deep Learning techniques can lead us to Human level intelligence? Or do you think we will need a different paradigm to get there?",0,1,False,self,,,,,
403,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,8,9m9q70,self.MachineLearning,"[D] Choosing datatype for vector embedding integers, int64 vs int32 vs int16. Basically embedding size vs range of possible values for each number in the embedding. Anyone have any experience or have done studies on this?",https://www.reddit.com/r/MachineLearning/comments/9m9q70/d_choosing_datatype_for_vector_embedding_integers/,Research2Vec,1538954265,"I noticed that in Tensorflow's official word2vec example, they use int32 as the datatypes for the numbers in the vectors, so each number can have a value ranging from -2,147,483,648 to 2,147,483,648. 

I am working with a large number of items to training embeddings on (millions), and looking to reduce memory in every place I can. 

One way I can do this is to pick a different datatype for the embedding numbers, int16 or int8. This would reduce the range of values for each number, but would increase the embedding size I can use and/or the number of items I can embed. 

I know of studies that look at reduced states for the embedding values while increasing the embedding size, which reduce the overall memory while maintaining or even improving performance; here's a study on Quantized word vectors

https://github.com/agnusmaximus/Word2Bits

I'm not looking to go that experimental, I'm just trying to look for what's SOA/common practice. I'm trying googling, but I can't seem to form the right query for this topic. ",17,1,False,self,,,,,
404,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,9,9maemn,explainxkcd.com,[D] 2054: Data Pipeline - explain xkcd,https://www.reddit.com/r/MachineLearning/comments/9maemn/d_2054_data_pipeline_explain_xkcd/,_quanttrader_,1538960246,,0,1,False,default,,,,,
405,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,10,9magpu,medium.com,[N] AI Diary (#2)  PyTorch Developer Conference 2018 Edition,https://www.reddit.com/r/MachineLearning/comments/9magpu/n_ai_diary_2_pytorch_developer_conference_2018/,omarsar,1538960771,,0,1,False,https://b.thumbs.redditmedia.com/8m6HoN8GThm8x7oqsxfDcz7YK29f4ve-6-g9cPybMdI.jpg,,,,,
406,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,11,9mb4xs,self.MachineLearning,Do you think there's a need for an ML package manager?,https://www.reddit.com/r/MachineLearning/comments/9mb4xs/do_you_think_theres_a_need_for_an_ml_package/,tsuberim,1538966691,[removed],0,1,False,self,,,,,
407,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,11,9mb57g,self.MachineLearning,Mouth movement and text,https://www.reddit.com/r/MachineLearning/comments/9mb57g/mouth_movement_and_text/,Moonkeycap198,1538966760,[removed],0,1,False,self,,,,,
408,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,11,9mb8fs,self.MachineLearning,Thoughts on Karl Friston's Active Inference.,https://www.reddit.com/r/MachineLearning/comments/9mb8fs/thoughts_on_karl_fristons_active_inference/,sreejithb,1538967562,[removed],0,1,False,self,,,,,
409,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,13,9mbo2g,self.MachineLearning,[D] What's your advice to an engineer that manages ML Researcher?,https://www.reddit.com/r/MachineLearning/comments/9mbo2g/d_whats_your_advice_to_an_engineer_that_manages/,Xorify,1538971650," I'm a software engineer that recently been asked to lead a mixed team of SW engineers and Applied ML Researchers. I don't have experience whatsoever in ML, so I wonder what would be a good approach to help my team members to shine and deliver, prevent them from going into pitfalls and empower their work effectively?",144,1,False,self,,,,,
410,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,13,9mbt07,i.redd.it,machine_learning=guess the right answer after the correct answer has been repeatedly told. Not even cheating.,https://www.reddit.com/r/MachineLearning/comments/9mbt07/machine_learningguess_the_right_answer_after_the/,chaisme,1538973006,,0,1,False,default,,,,,
411,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,13,9mbump,self.MachineLearning,[P] My first ML home project: an algorithm to predict (Australian) football matches,https://www.reddit.com/r/MachineLearning/comments/9mbump/p_my_first_ml_home_project_an_algorithm_to/,AFL_gains,1538973429,"Hello!
I have a weekend hobby of learning how to do machine learning, and recently (A few months ago actually) I completed my first ML project: predicting Australian Rules football matches. I trained / tested the model on 2003-2016 data and used 2017 as a hold-out. This year, I was able to live test the algorithm on the last 5 matches and it did quite well!! I wrote a little blog about my method and what features I used [here](https://www.aflgains.com/2018/07/11/machine-learning-in-afl/#creating-a-machine-learning-model-to-predict-afl-matches). Since this was my first real ML project that I did outside of work, I would love to hear some feedback - what could I improve or change? Thanks so much guys!",9,1,False,self,,,,,
412,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,14,9mc1uf,machinelearningplus.com,Top 10 Lemmatization Approaches with Examples in Python,https://www.reddit.com/r/MachineLearning/comments/9mc1uf/top_10_lemmatization_approaches_with_examples_in/,selva86,1538975427,,0,1,False,default,,,,,
413,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,14,9mc2ia,self.MachineLearning,"I am working on implementation of Bangla Handwriting Recognition From Scratch, but my predication result is wrong. Need help",https://www.reddit.com/r/MachineLearning/comments/9mc2ia/i_am_working_on_implementation_of_bangla/,Masum9876,1538975615,[removed],0,1,False,self,,,,,
414,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,15,9mcg6e,openreview.net,[R] Zero-training Sentence Embedding via Orthogonal Basis,https://www.reddit.com/r/MachineLearning/comments/9mcg6e/r_zerotraining_sentence_embedding_via_orthogonal/,serveboy,1538979664,,4,1,False,default,,,,,
415,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,15,9mciei,self.MachineLearning,[D] Thoughts on Karl Friston's Active Inference.,https://www.reddit.com/r/MachineLearning/comments/9mciei/d_thoughts_on_karl_fristons_active_inference/,sreejithb,1538980333,"Hi everyone,

&amp;#x200B;

I read many of Friston's paper on Active Inference like ""Reinforcement Learning or Active Inference?""(at PLOSOne), ""Active Inference and Learning"" (at  Neuroscience and Biobehavioral Reviews) and many more.

&amp;#x200B;

But I can't help feel that a lot of claims he has made is a bit of a stretch. For instance, in one of his presentations on Youtube (watch?v=Y1egnoCWgUg&amp;t=555s), he uses an example of own to motivate Active Inference and compare it to RL. However, it feels like he is just pointing out the difference between an MDP and POMDP? Also, the fact that there is no reward parameter and you need to ""hack"" the prior to get the desired behavior is also  troubling (look at the example in the PLOSOne paper mentioned above).

&amp;#x200B;

I thought I will ask your opinion on his approach and the grand claims he makes that Active Inference is the way the human brain works.  This is my first post. Go easy on me if I completely missed the point about Active Inference.",14,1,False,self,,,,,
416,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,15,9mckyp,self.MachineLearning,The Top 5 Machine Learning Libraries in Python,https://www.reddit.com/r/MachineLearning/comments/9mckyp/the_top_5_machine_learning_libraries_in_python/,Isobellz,1538981165,[removed],0,1,False,https://b.thumbs.redditmedia.com/Ti3Cc4M10WlzilQ8qEKVCyK6cyXOi4cRXqhb5AqAm5w.jpg,,,,,
417,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,17,9mczrt,self.MachineLearning,Doing Independent research in AI and Computer Vision?,https://www.reddit.com/r/MachineLearning/comments/9mczrt/doing_independent_research_in_ai_and_computer/,abhijeetpanda12,1538986062,"I am a masters student interested in researching some of the areas that I am passionate about. I needed some help in how can I get started with writing research papers, submitting them to the conferences. I don't want to go for a Ph.D. but I would like to do some of my independent research.",0,1,False,self,,,,,
418,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,17,9md464,palin.co.in,Basic Fundamentals of Statistics for Data Science - Palin Analytics,https://www.reddit.com/r/MachineLearning/comments/9md464/basic_fundamentals_of_statistics_for_data_science/,PalinTechnologies,1538987671,,0,1,False,default,,,,,
419,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,17,9md4br,sloboda-studio.com,Python Tools for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9md4br/python_tools_for_machine_learning/,birchyio,1538987726,,0,1,False,default,,,,,
420,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,18,9md9h0,self.MachineLearning,"  ,    .",https://www.reddit.com/r/MachineLearning/comments/9md9h0/______/,serl256,1538989517,[removed],0,1,False,self,,,,,
421,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,18,9mdb60,self.MachineLearning,Appropriate Test Time Measure for Beta Reparameterization,https://www.reddit.com/r/MachineLearning/comments/9mdb60/appropriate_test_time_measure_for_beta/,bge0,1538990076,[removed],0,1,False,self,,,,,
422,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,19,9mdrs2,self.MachineLearning,     .,https://www.reddit.com/r/MachineLearning/comments/9mdrs2/____/,WilliamW1979,1538995297,     .  --- .18s.w,0,1,False,self,,,,,
423,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,19,9mds2e,self.MachineLearning,    .,https://www.reddit.com/r/MachineLearning/comments/9mds2e/____/,elcolo-02,1538995383,    .  --- .18s.w,0,1,False,self,,,,,
424,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,19,9mdu22,self.MachineLearning,"What kind of Markov model do I use for estimating marketing channel attribution if I do not have data for one channel? The goal is purchasing a product and the data is aggregated Facebook data. I am missing several channels for this. Is purchasing a product an ""absorbing"" state?",https://www.reddit.com/r/MachineLearning/comments/9mdu22/what_kind_of_markov_model_do_i_use_for_estimating/,sparrow999,1538996029,[removed],0,1,False,self,,,,,
425,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,20,9mdw74,self.MachineLearning,BEST OF ECCV2018 and BEST OF MICCAI2018 in the same online magazine!,https://www.reddit.com/r/MachineLearning/comments/9mdw74/best_of_eccv2018_and_best_of_miccai2018_in_the/,Gletta,1538996638,[removed],0,1,False,https://b.thumbs.redditmedia.com/hpgZ8tUU_bgr4as0uXqCY13OCftFyXdnPxnANXnnLUk.jpg,,,,,
426,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,20,9me4on,blogs.msdn.microsoft.com,[R]Developing AI which will respond to multi language answer as like human,https://www.reddit.com/r/MachineLearning/comments/9me4on/rdeveloping_ai_which_will_respond_to_multi/,kiranaloha,1538999057,,0,1,False,default,,,,,
427,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,21,9mehhj,self.MachineLearning,How do you find and delete duplicates images within your dataset ?,https://www.reddit.com/r/MachineLearning/comments/9mehhj/how_do_you_find_and_delete_duplicates_images/,FrenchDizzie,1539002369,[removed],0,1,False,self,,,,,
428,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,21,9mem79,self.MachineLearning,Image ( TIFF ) to text conversion,https://www.reddit.com/r/MachineLearning/comments/9mem79/image_tiff_to_text_conversion/,shubhra2018,1539003479," 

Could you please let me know which is the best \*\*python library to convert a TIFF image to text conversion\*\*. I need to extract some text ( which could be any portion of paragraph ) from the image and completely convert the extracted image into the text format.

I am aware of Tesseract but I am looking for some other library other than Tesseract.

I am new to Machine learning.",0,1,False,self,,,,,
429,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,22,9mesaf,self.MachineLearning,10 Must Know Algorithms to learn the Basics of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9mesaf/10_must_know_algorithms_to_learn_the_basics_of/,randylaosat,1539004794,[removed],0,1,False,self,,,,,
430,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,22,9mey59,self.MachineLearning,[Discussion] Is training similar models for different contexts viable?,https://www.reddit.com/r/MachineLearning/comments/9mey59/discussion_is_training_similar_models_for/,josequadrado,1539006133,"Currently working on a project/product in the object detection domain.
Inference should be done in a resource constrained device which steered us naturally to the SSD Mobilenet side of the field which is a trade-off in terms of accuracy and generalization capacity.

My game plan is this: In case of a new context, create a new dataset from in-context frame annotated by a more capable model (e.g FasterRCCN-NAS) and use it to bring a base model up to par for this specific context.

Is this viable, or even worth doing? Or should I aim to produce a general model by gradually putting more context-diverse frames into a large dataset and retrain the model?

Thanks in advance for anyone kind enough to enlighten me!",3,1,False,self,,,,,
431,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,23,9mf7gh,self.MachineLearning,What are examples of machine learning in a trading manager.mq4 EA?,https://www.reddit.com/r/MachineLearning/comments/9mf7gh/what_are_examples_of_machine_learning_in_a/,michaellobry,1539008051,"As a beginner in ML (data, preparation, training, model, evaluation) and data mining, I'd like to hear some examples from the pro's with ML in a trade manager.mq4 expert advisor with:

&amp;#x200B;

Assume the trade manager contains:

\- 100s of indi's, oscillators, bands, volume based

\- rules 

\- filters (alphas)

&amp;#x200B;

What are some examples with ML?",0,1,False,self,,,,,
432,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,23,9mfbsg,self.MachineLearning,Deep Contextualized Word Representations With ELMo from AI2,https://www.reddit.com/r/MachineLearning/comments/9mfbsg/deep_contextualized_word_representations_with/,ElegantFeeling,1539008917,[removed],0,1,False,self,,,,,
433,MachineLearning,t5_2r3gv,2018-10-8,2018,10,8,23,9mfkuh,youtube.com,Elon Musk and Alex Jones discuss the future of artificial intelligence. (satire),https://www.reddit.com/r/MachineLearning/comments/9mfkuh/elon_musk_and_alex_jones_discuss_the_future_of/,Shamien,1539010733,,0,1,False,https://b.thumbs.redditmedia.com/Uk_1xG9rLCj_dIl535KfdqyWVI0baSXxrg-pVAemA9g.jpg,,,,,
434,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,0,9mfmqs,self.MachineLearning,"The good, the bad and the ugly of machine translation for customer service",https://www.reddit.com/r/MachineLearning/comments/9mfmqs/the_good_the_bad_and_the_ugly_of_machine/,JoaoVasques,1539011099,[removed],0,1,False,self,,,,,
435,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,0,9mfnnh,self.MachineLearning,[R] Survey regarding companies and AI,https://www.reddit.com/r/MachineLearning/comments/9mfnnh/r_survey_regarding_companies_and_ai/,LuigiHarrisMario,1539011274,"Hello r/MachineLearning!

&amp;#x200B;

We decided to research companies and AI for our school research project, we would like to have people from r/MachineLearning to fill in our survey so we can get an idea how people think!

All information needed is in the survey. Survey is filled in anonymously.  


[Survey Link](https://goo.gl/forms/k16TVhwx1RrvjBIA3)

&amp;#x200B;

Thanks for helping us !

*Approved by moderators*",4,1,False,self,,,,,
436,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,0,9mfszv,self.MachineLearning,Help with identifying main object on the image,https://www.reddit.com/r/MachineLearning/comments/9mfszv/help_with_identifying_main_object_on_the_image/,gevorgter,1539012278,[removed],0,1,False,self,,,,,
437,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,0,9mfu70,microsoft.com,"Cutting edge genetic engineering technique CRISPR, which is used to ""cut and paste"" genes with surgical precision, meets ML",https://www.reddit.com/r/MachineLearning/comments/9mfu70/cutting_edge_genetic_engineering_technique_crispr/,dillibazarsadak1,1539012492,,0,1,False,default,,,,,
438,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,0,9mfwnn,self.MachineLearning,"[D] Do any machine learning techniques work with zero examples? Like, it improves itself over time by abstract rationalizing from a few hard coded principles about a universe?",https://www.reddit.com/r/MachineLearning/comments/9mfwnn/d_do_any_machine_learning_techniques_work_with/,wakka54,1539012952,,18,1,False,self,,,,,
439,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,0,9mg06q,microsoft.com,"[Research] Cutting edge genetic engineering technique CRISPR, which is used to ""cut and paste"" genes with surgical precision, meets ML",https://www.reddit.com/r/MachineLearning/comments/9mg06q/research_cutting_edge_genetic_engineering/,dillibazarsadak1,1539013620,,0,1,False,default,,,,,
440,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,0,9mg2e9,onclick360.com,What is reinforcement learning?,https://www.reddit.com/r/MachineLearning/comments/9mg2e9/what_is_reinforcement_learning/,onclick360,1539014046,,0,1,False,default,,,,,
441,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,0,9mg36k,github.com,"Tutorial: Pandas scale up with numba, scale out with dask",https://www.reddit.com/r/MachineLearning/comments/9mg36k/tutorial_pandas_scale_up_with_numba_scale_out/,raghothams,1539014187,,0,1,False,https://b.thumbs.redditmedia.com/GOuu2hGDcPeprfaYmfFJrvSIas26KxHeo5o0CEiyHww.jpg,,,,,
442,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,1,9mg8gy,self.MachineLearning,How can to build a FAQ with ml / dl,https://www.reddit.com/r/MachineLearning/comments/9mg8gy/how_can_to_build_a_faq_with_ml_dl/,mahi2311,1539015112,[removed],0,1,False,self,,,,,
443,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,1,9mgg8o,sotabot.com,Bot for Slack that sends state-of-the-art papers from arXiv.org,https://www.reddit.com/r/MachineLearning/comments/9mgg8o/bot_for_slack_that_sends_stateoftheart_papers/,anton_kar,1539016485,,1,1,False,default,,,,,
444,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,3,9mhb18,self.MachineLearning,Is intelligence the same as consciousness and if not is the fear that ai will the take over the world not justified.,https://www.reddit.com/r/MachineLearning/comments/9mhb18/is_intelligence_the_same_as_consciousness_and_if/,Kenyancuntissweet,1539021978,[removed],1,1,False,self,,,,,
445,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,3,9mhexe,datasciencecentral.com,From Machine Learning to Machine Unlearning,https://www.reddit.com/r/MachineLearning/comments/9mhexe/from_machine_learning_to_machine_unlearning/,jonfla,1539022679,,0,1,False,default,,,,,
446,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,3,9mhn6x,self.MachineLearning,Online study group for reading PRML by Christopher bishop ?,https://www.reddit.com/r/MachineLearning/comments/9mhn6x/online_study_group_for_reading_prml_by/,mad_boy_819,1539024170,[removed],0,1,False,self,,,,,
447,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,3,9mhs58,self.MachineLearning,[D] The Glossary of Machine Learning Terms,https://www.reddit.com/r/MachineLearning/comments/9mhs58/d_the_glossary_of_machine_learning_terms/,semanti_ca,1539025099,"Hi!

We have created a [glossary of machine learning terms](https://semanti.ca/blog/?glossary-of-machine-learning-terms). Does it look complete?

Could we tell that if you have all entries of this glossary in your head you can consider yourself an expert in practical machine learning?

What would you add to this glossary?

Thanks!",15,1,False,self,,,,,
448,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,4,9mhvz4,self.MachineLearning,Deep Learning for Natural Language Processing: Tutorials with Jupyter Notebooks,https://www.reddit.com/r/MachineLearning/comments/9mhvz4/deep_learning_for_natural_language_processing/,andrea_manero,1539025796,[removed],0,1,False,self,,,,,
449,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,4,9mi2ki,self.MachineLearning,"[P] An implementation of ""100 layers tiramisu"" - A FC DenseNet in TensorFlow.",https://www.reddit.com/r/MachineLearning/comments/9mi2ki/p_an_implementation_of_100_layers_tiramisu_a_fc/,breaking_ciphers,1539027044,"Hello r/MachineLearning,

I implemented the [100 layer tiramisu](https://arxiv.org/abs/1611.09326) in TensorFlow, I would like ideally like some feedback to verify if the implementation is correct, because the Tiramisu is difficult to optimize on PASCAL VOC. A lot of people have been saying that it doesn't work too well for their datasets, but the paper shows SOTA results on CamVid. Why could this be, do you guys have insights into this?",1,1,False,self,,,,,
450,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,5,9mipdc,self.MachineLearning,[D] Is there any adversarial defense method that has successfully beaten or is robust to Carlini Wagner attacks ?,https://www.reddit.com/r/MachineLearning/comments/9mipdc/d_is_there_any_adversarial_defense_method_that/,iamlordkurdleak,1539031772,"Link to the paper describing the attack - https://arxiv.org/pdf/1608.04644.pdf

As per my search, no paper has shown even slight robustness to C&amp;W attacks. Though some methods claimed to have, they were refuted by Carlini in subsequent papers( for eg - https://nicholas.carlini.com/papers/2017_threebreaks.pdf ).",30,1,False,self,,,,,
451,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,5,9miqpq,self.MachineLearning,Adapting the U-net architecture for non-square images and training and test images of different sizes,https://www.reddit.com/r/MachineLearning/comments/9miqpq/adapting_the_unet_architecture_for_nonsquare/,nakumgaurav,1539032058,[removed],0,1,False,self,,,,,
452,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,6,9mit6u,self.MachineLearning,What would the best resources or forums be for beginners to ask questions?,https://www.reddit.com/r/MachineLearning/comments/9mit6u/what_would_the_best_resources_or_forums_be_for/,Laughingllama42,1539032540,[removed],0,1,False,self,,,,,
453,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,6,9mixgc,self.MachineLearning,Please help me improve my college with AI!,https://www.reddit.com/r/MachineLearning/comments/9mixgc/please_help_me_improve_my_college_with_ai/,snowmanonfire99,1539033367,I am a student at Penn State and I'm participating in a challenge that tasks students to improve the college through Artificial Intelligence. We could do anything from optimizing operations to improving students experience. My team is unsure with what we want to do. Do you guys have any ideas that could have a huge impact on my campus? No idea is too big! Let's make a difference!!!,0,1,False,self,,,,,
454,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,6,9mj0gb,arxiv.org,[R] Generative Ensembles for Robust Anomaly Detection,https://www.reddit.com/r/MachineLearning/comments/9mj0gb/r_generative_ensembles_for_robust_anomaly/,kmkolasinski,1539033971,,3,1,False,default,,,,,
455,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,7,9mjmb8,self.MachineLearning,[Research] Generative Neural Machine Translation,https://www.reddit.com/r/MachineLearning/comments/9mjmb8/research_generative_neural_machine_translation/,milaworld,1539038357,"

This blog post and paper looks at using shared representations and semi-supervised learning to improve language models:

Blog: https://davidbarber.github.io/blog/2018/09/12/Generative-Neural-Machine-Translation/

NIPS2018 Paper: https://arxiv.org/abs/1806.05138
",4,1,False,self,,,,,
456,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,7,9mjmoe,github.com,How do you use neural networks to beat the market! Check out this highly extensible project GitHub.,https://www.reddit.com/r/MachineLearning/comments/9mjmoe/how_do_you_use_neural_networks_to_beat_the_market/,vivekpa,1539038432,,0,1,False,default,,,,,
457,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,7,9mjofs,self.MachineLearning,Artini: A photo editor with beautiful AI features,https://www.reddit.com/r/MachineLearning/comments/9mjofs/artini_a_photo_editor_with_beautiful_ai_features/,zduhaci,1539038800,[removed],0,1,False,self,,,,,
458,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,8,9mjxe0,phoronix.com,"NVIDIA GeForce RTX 2080 Ti To GTX 980 Ti TensorFlow Benchmarks With ResNet-50, AlexNet, GoogLeNet, Inception, VGG-16 Review",https://www.reddit.com/r/MachineLearning/comments/9mjxe0/nvidia_geforce_rtx_2080_ti_to_gtx_980_ti/,SlowInFastOut,1539040735,,0,1,False,default,,,,,
459,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,8,9mjxyp,self.MachineLearning,[D] Free GPU compute time in exchange for feedback,https://www.reddit.com/r/MachineLearning/comments/9mjxyp/d_free_gpu_compute_time_in_exchange_for_feedback/,ronnieboy333,1539040856,"Hi Reddit! I wanted to see if anyone in this sub is interested in some free compute time in exchange for feedback. I am toying with the idea of doing a peer to peer marketplace for GPUs. Where you can rent a persons Machine Learning rig for a small fee. Probably a lot cheaper than some of the established cloud providers. I went ahead and built several rigs out of spare parts and need some real world usage to prove out the concept. I was hoping there are some projects out there that might need some processing power and all you need to do is let me know if the rig is sufficient for your needs. 

&amp;#x200B;

**Basic Specs:**  
Ubuntu 18.04  
Intel Celeron Dual Core  
8GB RAM  
250 GB SSD  
NVIDIA 1080ti 

If you are interested in participating fill out the participation form below.  I am running a few cycles throughout the next few weeks of projects and want as much input as possible. 

&amp;#x200B;

**Participation Form:**  
[https://goo.gl/forms/KlpIPgonAadhbqCi1](https://goo.gl/forms/KlpIPgonAadhbqCi1)

&amp;#x200B;",38,1,False,self,,,,,
460,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,8,9mk4ba,self.MachineLearning,"Train CNN to classify image as (face/age combo or NOT face), opinion on best approach?",https://www.reddit.com/r/MachineLearning/comments/9mk4ba/train_cnn_to_classify_image_as_faceage_combo_or/,Dark_Messiah,1539042300,[removed],0,1,False,self,,,,,
461,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,8,9mk4lq,i.redd.it,Mathpix Snipping Tool: AI that turns an image of an equation into LaTeX instantly. mathpix.com,https://www.reddit.com/r/MachineLearning/comments/9mk4lq/mathpix_snipping_tool_ai_that_turns_an_image_of/,kaitlinmcunningham,1539042372,,0,1,False,default,,,,,
462,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,8,9mk7t0,self.MachineLearning,Can anyone list what exactly this PyTorch 1.0 enables that previous versions didn't?,https://www.reddit.com/r/MachineLearning/comments/9mk7t0/can_anyone_list_what_exactly_this_pytorch_10/,engine_town_rattler,1539043110,"Same question about FastAI 1.0.  

I've read a few articles about the recent updates of each but they are pretty hand wavy.",0,1,False,self,,,,,
463,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,9,9mkmp3,self.MachineLearning,[Question] What's the best way to evolve a new neural net from previous ones when back prop isn't an option?,https://www.reddit.com/r/MachineLearning/comments/9mkmp3/question_whats_the_best_way_to_evolve_a_new/,Biotot,1539046503,[removed],0,1,False,self,,,,,
464,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,10,9ml3gy,self.MachineLearning,[D] What are your thoughts on Neuromorphic Computing?,https://www.reddit.com/r/MachineLearning/comments/9ml3gy/d_what_are_your_thoughts_on_neuromorphic_computing/,ShittingTits,1539050264,Great idea? Promising future? Too specialized? Unrealistic? Not useful? Why? Why not?,16,1,False,self,,,,,
465,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,11,9ml9m3,self.MLQuestions,Advice for Satellite Image Classification with Keras in R,https://www.reddit.com/r/MachineLearning/comments/9ml9m3/advice_for_satellite_image_classification_with/,thiswillsuffice,1539051655,,0,1,False,default,,,,,
466,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,11,9mlfn8,self.MachineLearning,AAAI 2019 rebuttal,https://www.reddit.com/r/MachineLearning/comments/9mlfn8/aaai_2019_rebuttal/,jamesben6688,1539053075,[removed],0,1,False,self,,,,,
467,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,12,9mlotm,self.MachineLearning,Effects of image preprocessing on inference/training time,https://www.reddit.com/r/MachineLearning/comments/9mlotm/effects_of_image_preprocessing_on/,Bdamkin54,1539055265,[removed],0,1,False,self,,,,,
468,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,13,9mm3y7,blog.engati.com,Most e-commerce businesses face a massive challenge of increased churn rate. How does a chatbot stop this unnerving gush? Find out,https://www.reddit.com/r/MachineLearning/comments/9mm3y7/most_ecommerce_businesses_face_a_massive/,getengati,1539059128,,0,1,False,default,,,,,
469,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,13,9mm6ew,arxiv.org,[R] Deep Graph Infomax,https://www.reddit.com/r/MachineLearning/comments/9mm6ew/r_deep_graph_infomax/,Cock-tail,1539059826,,0,1,False,default,,,,,
470,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,14,9mml9e,self.MachineLearning,[D] Using MachineLearning as an adopting assistive-speech program,https://www.reddit.com/r/MachineLearning/comments/9mml9e/d_using_machinelearning_as_an_adopting/,jonumand,1539064164,"Hi, 

I have Cerebral Palsy and have an idea for a project, but I dont know how to code ML. If this would be possible, Id be in on learning to code ML.

Using the camera of a device and Machine Learning/Neural Networks/AI to make communicationprograms adapt to the user insttead of the user adapting to the computer. 

I use Danish Sign Language (ASL with ) to communicate with my family, which s super fast. When Im at school, I commumicate via a Surface Pro 4 with Rolltalk Designer with a qwerty layout. If I could use my hand to communicate with, itd be so much easier - and faster. 

This could be scaled up to include other systems of communicating - like AAC.

Is this possible with the current ML tech?",3,1,False,self,,,,,
471,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,16,9mn5a1,self.MachineLearning,Rate/Critique my Machine Learning resume! Please and thank you.,https://www.reddit.com/r/MachineLearning/comments/9mn5a1/ratecritique_my_machine_learning_resume_please/,Silver5005,1539070446,[removed],1,1,False,self,,,,,
472,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,16,9mn6sc,arxiv.org,[R] Understanding Recurrent Neural Architectures by Analyzing and Synthesizing Long Distance Dependencies in Benchmark Sequential Datasets,https://www.reddit.com/r/MachineLearning/comments/9mn6sc/r_understanding_recurrent_neural_architectures_by/,HigherTopoi,1539070985,,2,1,False,default,,,,,
473,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,16,9mn96i,self.MachineLearning,Using ECC RAM with NON-ECC GPU,https://www.reddit.com/r/MachineLearning/comments/9mn96i/using_ecc_ram_with_nonecc_gpu/,StevenVandenBroucke,1539071847,[removed],0,1,False,self,,,,,
474,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,17,9mnb81,self.MachineLearning,[D] Non-ECC RAM vs ECC RAM when using Non-ECC GPU,https://www.reddit.com/r/MachineLearning/comments/9mnb81/d_nonecc_ram_vs_ecc_ram_when_using_nonecc_gpu/,StevenVandenBroucke,1539072595,"Dear all,

I'm ready to purchase a desktop device for machine learning research at my university.The GPU units we use for ML (personal devices) is often are 1080 and 1080TI which have non-ecc memory.

&amp;#x200B;

My question is:Is it still useful  buying ECC RAM (on motherboard/ not gpu) rather then just buying cheaper non-ecc ram?I've read some discussions where people use gradient clipping and checkpointing to lessen the need of using ECC ram. But if you're not using a GPU with ECC ram from the start, is it even worth it buying one?

&amp;#x200B;

Thank you for your responses!",6,1,False,self,,,,,
475,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,17,9mnh18,self.MachineLearning,[R] CINIC-10 Is Not ImageNet or CIFAR-10,https://www.reddit.com/r/MachineLearning/comments/9mnh18/r_cinic10_is_not_imagenet_or_cifar10/,learning-luke,1539074736,"We compiled a new benchmarking image dataset called CINIC-10

It is designed as a drop-in replacement for CIFAR-10 since it has the same classes. It is a more challenging dataset, yet it has more samples per class. It was compiled by taking CIFAR-10 and augmenting it with 210,000 images listed on the ImageNet database (downsampled to 32x32 pixels).

[Darlow L.N., Crowley E.J., Antoniou A., and A.J. Storkey (2018) CINIC-10 is not ImageNet or CIFAR-10. Report EDI-INF-ANC-1802 (arXiv:1810.03505).](https://arxiv.org/abs/1810.03505)

Github: [https://github.com/BayesWatch/cinic-10](https://github.com/BayesWatch/cinic-10)

Download link: [https://datashare.is.ed.ac.uk/handle/10283/3192]",13,1,False,self,,,,,
476,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,18,9mnmhh,self.MachineLearning,Can anyone suggest some College project?,https://www.reddit.com/r/MachineLearning/comments/9mnmhh/can_anyone_suggest_some_college_project/,anashabb,1539076617,[removed],0,1,False,self,,,,,
477,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,18,9mnn1n,youtu.be,GOTO 2018  Deep Learning in Medicine  Allen Day,https://www.reddit.com/r/MachineLearning/comments/9mnn1n/goto_2018_deep_learning_in_medicine_allen_day/,rick-rebel,1539076816,,0,1,False,default,,,,,
478,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,18,9mnq7w,twitter.com,Human Learning,https://www.reddit.com/r/MachineLearning/comments/9mnq7w/human_learning/,luibelgo,1539077880,,0,1,False,default,,,,,
479,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,18,9mnstb,blog.engati.com,"Banks grow when their customers grow, and chatbots ensure the sustainability of this growth by providing fast &amp; efficient customer support. Get your free trial &amp; explore the plan that best suits your banking needs!",https://www.reddit.com/r/MachineLearning/comments/9mnstb/banks_grow_when_their_customers_grow_and_chatbots/,getengati,1539078695,,0,1,False,default,,,,,
480,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,19,9mnwue,reddit.com,Need suggestions on project,https://www.reddit.com/r/MachineLearning/comments/9mnwue/need_suggestions_on_project/,anashabb,1539079973,,0,1,False,default,,,,,
481,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,19,9mnyav,arxiv.org,[R] Exascale Deep Learning for Climate Analytics,https://www.reddit.com/r/MachineLearning/comments/9mnyav/r_exascale_deep_learning_for_climate_analytics/,baylearn,1539080430,,3,1,False,default,,,,,
482,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,19,9mo0g8,towardsdatascience.com,An in-depth knowledge of Naive Bayes with some interesting examples and its code in scratch.,https://www.reddit.com/r/MachineLearning/comments/9mo0g8/an_indepth_knowledge_of_naive_bayes_with_some/,gauravc2796,1539081123,,0,1,False,default,,,,,
483,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,21,9moilm,arxiv.org,[R] Deep Convolutional Gaussian Processes,https://www.reddit.com/r/MachineLearning/comments/9moilm/r_deep_convolutional_gaussian_processes/,slash-dot,1539086415,,8,1,False,default,,,,,
484,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,21,9moljc,self.MachineLearning,[P] A CNN-based Vocoder,https://www.reddit.com/r/MachineLearning/comments/9moljc/p_a_cnnbased_vocoder/,tuan3w,1539087123,"Recently, I was interested in [m-cnn](https://arxiv.org/abs/1808.06719) model. The authors demonstrate that even a simple upsampling network is enough to create a vocoder. I did some experiments and get some good results. There are a lot of rooms to improve

the quality of vocoder. So I would love to share this problem to everyone who are interest.

Link to project: [https://github.com/tuan3w/cnn\_vocoder](https://github.com/tuan3w/cnn_vocoder)

Audio samples: [https://soundcloud.com/nguyen-duc-tuan-80422561/sets/cnn-vocoder-samples](https://soundcloud.com/nguyen-duc-tuan-80422561/sets/cnn-vocoder-samples)

&amp;#x200B;",15,1,False,self,,,,,
485,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,21,9mornm,self.MachineLearning,Books to Start With,https://www.reddit.com/r/MachineLearning/comments/9mornm/books_to_start_with/,tjspitfire,1539088616,[removed],0,1,False,self,,,,,
486,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,21,9moula,oodlestechnologies.com,Ethically Stepping Into The Future With AI,https://www.reddit.com/r/MachineLearning/comments/9moula/ethically_stepping_into_the_future_with_ai/,vidushivij,1539089324,,0,1,False,https://b.thumbs.redditmedia.com/vG1fCnDQjjBxVdFc0JHHJlmhK0FoRwZtjCHX9pbexbY.jpg,,,,,
487,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,22,9moyc8,oodlestechnologies.com,Big Data Application Development Services,https://www.reddit.com/r/MachineLearning/comments/9moyc8/big_data_application_development_services/,vidushivij,1539090197,,0,1,False,default,,,,,
488,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,22,9moyzk,self.MachineLearning,[D] What happened to Spatial Transformers?,https://www.reddit.com/r/MachineLearning/comments/9moyzk/d_what_happened_to_spatial_transformers/,iliauk,1539090344,"It looks like [they](https://arxiv.org/abs/1506.02025) introduced some really useful (and simple) functionality a couple of years ago to make CNNs invariant to various geometric operations (compared to the small localised invariance that max-pooling provides)

However nowadays we see papers like [""A Rotation and a Translation Suffice: Fooling CNNs with Simple Transformations""](https://arxiv.org/abs/1712.02779), which show a simple (linear) attack of translation (10% of pixels max e.g 3px for CIFAR10) and rotation (30 degrees max) reduces accuracy of traditional models like ResNet-50 from 93% to 3% on CIFAR10 and 76% to 31% on ImageNet.

[Spherical CNNs](https://arxiv.org/pdf/1801.10130.pdf) introduced a new mechanism entirely to deal with non-linear distortions caused by a projection from sphere-surface to plane.

However in both of these cases it seems that a spatial-transformer should have provided some resistance since Table 1 in the paper shows that it does seem to help with RTS (rotation, translation, scale) and P (projective distortion).

And finally Capsule Networks went another way entirely ",10,1,False,self,,,,,
489,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,22,9mpbfs,dluo.me,How I Transitioned from Physics Academia to the ML Industry,https://www.reddit.com/r/MachineLearning/comments/9mpbfs/how_i_transitioned_from_physics_academia_to_the/,datasciencelover,1539093090,,0,1,False,https://b.thumbs.redditmedia.com/-PvO-6ppxxdB-Glni4WxClAA9Wem7mTGJ9J31ewNdxA.jpg,,,,,
490,MachineLearning,t5_2r3gv,2018-10-9,2018,10,9,23,9mprtw,self.MachineLearning,Ideas,https://www.reddit.com/r/MachineLearning/comments/9mprtw/ideas/,ato1996,1539096448,[removed],0,1,False,self,,,,,
491,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,0,9mq3sc,en.wikipedia.org,Plato's Theory of Forms sounds a lot like Principal Component Analysis and Eigenfaces,https://www.reddit.com/r/MachineLearning/comments/9mq3sc/platos_theory_of_forms_sounds_a_lot_like/,wakka54,1539098772,,0,1,False,default,,,,,
492,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,0,9mq542,self.MachineLearning,Riemannian MDM Classifier for passive BCI,https://www.reddit.com/r/MachineLearning/comments/9mq542/riemannian_mdm_classifier_for_passive_bci/,RickJLM,1539099010,[removed],0,1,False,self,,,,,
493,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,0,9mq6h7,self.MachineLearning,AMA with Vladimir [Kaggle Grand Master],https://www.reddit.com/r/MachineLearning/comments/9mq6h7/ama_with_vladimir_kaggle_grand_master/,Relaxation_Time,1539099266,"Dear Reddit.

Myself just came into the Data Science world around 1 year ago. I've learned a lot with the help of [Kaggle](http://kaggle/)and [ODS.ai](http://ods.ai/) (Open Data Science) -- the biggest Data Science community.

When I just joined the ODS, there were already some STARS. Well, they were STARS in my eyes at that time. What I mean is that there were some guys who would easily crack Kaggle (and other) challenges. They were really good.

Some of you may have heard of [Vladimir Iglovikov](https://www.kaggle.com/iglovikov/). He is one of these stars. Vladimir got his Ph.D. in Theoretical Condensed Matter Physics at UC Davis in 2015. After graduation, he moved to the Silicon Valley and accepted a position as a Data Scientist in a company in Sunnyvale named Bidgely, where he developed Energy Disaggregation algorithms that were a combination of the signal processing and machine learning techniques. After this, he moved to San Francisco to work in TrueAccord where he was mainly focussed working on building recommender systems. Finally, after a set of top finishes in a different Computer Vision challenges, he was finally confident that he eventually moved to Lyft, where he is working right now applying Deep Learning techniques to the computer vision problems at the Lyft's Level5 Engineering centre that is focussed on the development of the self-driving cars.

* 3rd place: [Kaggle: Dstl Satellite Imagery Feature Detection](https://www.kaggle.com/c/dstl-satellite-imagery-feature-detection)
* 2nd place: Safe passage: Detecting and classifying vehicles in aerial imagery:
* 7th place: [Kaggle: Planet: Understanding the Amazon from Space](https://www.kaggle.com/c/planet-understanding-the-amazon-from-space)
* 1st place: MICCAI 2017: Gastrointestinal Image ANAlysis (GIANA)
* 1st place: MICCAI 2017: Robotic Instrument Segmentation
* 1st place: [Kaggle: Carvana Image Masking Challenge](https://www.kaggle.com/c/carvana-image-masking-challenge)
* 9th place: [Kaggle: IEEE's Signal Processing Society - Camera Model Identification](https://www.kaggle.com/c/sp-society-camera-model-identification)
* 2nd place: CVPR 2018 Deepglobe. Road Extraction.
* 2nd place: CVPR 2018 Deepglobe. Building Detection.
* 3rd place: CVPR 2018 Deepglobe. Land Cover Classification.

With the time I realized that Vladimir is just a normal person, very bright and hardworking, but he is just one of us. That's why ODS.ai organizes AMA (ask me anything) with Vladimir, as a part of the ""demystifying top Kaggler"" campaign. Our point is that all he had achieved could be achieved by you. You can ask him any questions about anything and upvote the ones you liked a lot. We will collect the best questions from various platforms (Kaggle, Reddit and ODS.ai) and then we will release AMA as an interview on a medium.

Peace and stay tuned. Vad",0,1,False,self,,,,,
494,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,0,9mq985,self.MachineLearning,A Guide to Using AI/ML in Highly Regulated Industries,https://www.reddit.com/r/MachineLearning/comments/9mq985/a_guide_to_using_aiml_in_highly_regulated/,jtsymonds,1539099797,[removed],1,1,False,self,,,,,
495,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,0,9mqa0e,self.IAmA,"I am Kate Saenko, Artificial Intelligence researcher and professor at Boston University Department of Computer Science. Ask me anything!",https://www.reddit.com/r/MachineLearning/comments/9mqa0e/i_am_kate_saenko_artificial_intelligence/,mgluck_23,1539099946,,0,1,False,default,,,,,
496,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,1,9mqo6f,self.MachineLearning,Text intent generation and request handling.,https://www.reddit.com/r/MachineLearning/comments/9mqo6f/text_intent_generation_and_request_handling/,Kadersk,1539102601,[removed],0,1,False,self,,,,,
497,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,1,9mqs3k,self.MachineLearning,[R] Image Inpainting: Humans vs. AI,https://www.reddit.com/r/MachineLearning/comments/9mqs3k/r_image_inpainting_humans_vs_ai/,merofeev,1539103357,"&amp;#x200B;

*Processing img 4t46jda6u6r11...*

During the past two years several novel image inpainting (completion) methods based on deep learning were proposed.

Our team was impressed by the results reported in these papers. So we decided to find out: are modern neural image inpainting methods good enough to compete with human artists. 

&amp;#x200B;

We performed subjective comparison of 6 neural methods vs. 3 conventional methods vs. results of 3 human-artists. 

The results of this study are available online at TowardsDataScience: [https://towardsdatascience.com/image-inpainting-humans-vs-ai-48fc4bca7ecc](https://towardsdatascience.com/image-inpainting-humans-vs-ai-48fc4bca7ecc)",7,1,False,self,,,,,
498,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,1,9mqxa8,i.redd.it,"First ever ML lab ,and program is not working.help me",https://www.reddit.com/r/MachineLearning/comments/9mqxa8/first_ever_ml_lab_and_program_is_not_workinghelp/,Inglorius_bastard,1539104352,,0,1,False,https://b.thumbs.redditmedia.com/XrLWzdB1Mr5b6JmxejZVFeJuGSDAL5UV6A8Y8HX983I.jpg,,,,,
499,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,2,9mr20l,self.MachineLearning,Locating and matching spatial data points and polylines accurately and automatically.,https://www.reddit.com/r/MachineLearning/comments/9mr20l/locating_and_matching_spatial_data_points_and/,vijaybendigeri,1539105211,[removed],0,1,False,self,,,,,
500,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,2,9mr2g8,youtu.be,Artificial intelligence genetic algorithm evolution,https://www.reddit.com/r/MachineLearning/comments/9mr2g8/artificial_intelligence_genetic_algorithm/,DevTechRetopall,1539105294,,1,1,False,https://b.thumbs.redditmedia.com/EgnTi8FKs635UzIcKNz_CVcR9mfXweKIYPRrCSRsxwI.jpg,,,,,
501,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,2,9mr3e2,self.MachineLearning,"[P] Vel, PyTorch implementations of reinforcement learning algorithms",https://www.reddit.com/r/MachineLearning/comments/9mr3e2/p_vel_pytorch_implementations_of_reinforcement/,djrx,1539105469,"Hi Reddit!

I've wanted to share with you my experience with developing implementations to most popular reinforcement learning algorithms in PyTorch. Feel free to use the code in your projects.


Blog link: https://blog.millionintegrals.com/vel-pytorch-meets-baselines/
Github repo: https://github.com/MillionIntegrals/vel

",7,1,False,self,,,,,
502,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,2,9mr5ig,self.MachineLearning,AMA with Vladimir [Kaggle Grand Master],https://www.reddit.com/r/MachineLearning/comments/9mr5ig/ama_with_vladimir_kaggle_grand_master/,Relaxation_Time,1539105888,[removed],1,1,False,self,,,,,
503,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,2,9mr7md,modeldepot.io,[P] Try Open Source Pretrained ML Models in Seconds,https://www.reddit.com/r/MachineLearning/comments/9mr7md/p_try_open_source_pretrained_ml_models_in_seconds/,es6masterrace,1539106299,,0,1,False,default,,,,,
504,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,2,9mrc32,self.MachineLearning,Student Contest: Announcing the Public Health Data Challenge,https://www.reddit.com/r/MachineLearning/comments/9mrc32/student_contest_announcing_the_public_health_data/,ThisisStatisticsASA,1539107124,[removed],0,1,False,self,,,,,
505,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,2,9mrd69,self.MachineLearning,Machine Learning approach to Develope skill taxonmy,https://www.reddit.com/r/MachineLearning/comments/9mrd69/machine_learning_approach_to_develope_skill/,abbasi081,1539107335,[removed],0,1,False,self,,,,,
506,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,2,9mreca,self.MachineLearning,[D] AMA with Vladimir  Kaggle Grand Master,https://www.reddit.com/r/MachineLearning/comments/9mreca/d_ama_with_vladimir_kaggle_grand_master/,Relaxation_Time,1539107579,"Dear Reddit.

Myself just came into the Data Science world around 1 year ago. I've learned a lot with the help of [Kaggle](http://kaggle/)and [ODS.ai](http://ods.ai/) (Open Data Science) -- the biggest Data Science community.

When I just joined the ODS, there were already some STARS. Well, they were STARS in my eyes at that time. What I mean is that there were some guys who would easily crack Kaggle (and other) challenges. They were really good.

Some of you may have heard of [Vladimir Iglovikov](https://www.kaggle.com/iglovikov/). He is one of these stars. Vladimir got his Ph.D. in Theoretical Condensed Matter Physics at UC Davis in 2015. After graduation, he moved to the Silicon Valley and accepted a position as a Data Scientist in a company in Sunnyvale named Bidgely, where he developed Energy Disaggregation algorithms that were a combination of the signal processing and machine learning techniques. After this, he moved to San Francisco to work in TrueAccord where he was mainly focussed working on building recommender systems. Finally, after a set of top finishes in a different Computer Vision challenges, he was finally confident that he eventually moved to Lyft, where he is working right now applying Deep Learning techniques to the computer vision problems at the Lyft's Level5 Engineering centre that is focussed on the development of the self-driving cars.

* 3rd place: [Kaggle: Dstl Satellite Imagery Feature Detection](https://www.kaggle.com/c/dstl-satellite-imagery-feature-detection)
* 2nd place: Safe passage: Detecting and classifying vehicles in aerial imagery:
* 7th place: [Kaggle: Planet: Understanding the Amazon from Space](https://www.kaggle.com/c/planet-understanding-the-amazon-from-space)
* 1st place: MICCAI 2017: Gastrointestinal Image ANAlysis (GIANA)
* 1st place: MICCAI 2017: Robotic Instrument Segmentation
* 1st place: [Kaggle: Carvana Image Masking Challenge](https://www.kaggle.com/c/carvana-image-masking-challenge)
* 9th place: [Kaggle: IEEE's Signal Processing Society - Camera Model Identification](https://www.kaggle.com/c/sp-society-camera-model-identification)
* 2nd place: CVPR 2018 Deepglobe. Road Extraction.
* 2nd place: CVPR 2018 Deepglobe. Building Detection.
* 3rd place: CVPR 2018 Deepglobe. Land Cover Classification.

With the time I realized that Vladimir is just a normal person, very bright and hardworking, but he is just one of us. That's why ODS.ai organizes AMA (ask me anything) with Vladimir, as a part of the ""demystifying top Kaggler"" campaign. Our point is that all he had achieved could be achieved by you. You can ask him any questions about anything and upvote the ones you liked a lot. We will collect the best questions from various platforms (Kaggle, Reddit and ODS.ai) and then we will release AMA as an interview on a medium.

Peace and stay tuned. Vad",51,1,False,self,,,,,
507,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,3,9mrjsf,self.MachineLearning,[D] How do machine learning engineers use C++?,https://www.reddit.com/r/MachineLearning/comments/9mrjsf/d_how_do_machine_learning_engineers_use_c/,Sherbhy,1539108613,"I've heard a lot about C++ being used for ML algorithms to make fast af models. Yousician for example uses this. 
How does C++ fall inside the pipeline? Do they make the entire model on C++? And if so is there any beginner project I could implement to get some sort of understanding on this.",15,1,False,self,,,,,
508,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,3,9mrk2c,medium.com,[N] Berkeley Targets Dexterous Manipulation Using Deep RL,https://www.reddit.com/r/MachineLearning/comments/9mrk2c/n_berkeley_targets_dexterous_manipulation_using/,gwen0927,1539108668,,0,1,False,default,,,,,
509,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,3,9mroqn,self.MachineLearning,Reading strategy for the following books?,https://www.reddit.com/r/MachineLearning/comments/9mroqn/reading_strategy_for_the_following_books/,zindarod,1539109575,"I am trying to read the following list of books on statistical learning. I have a BSCS and about 4 yrs of experience working in image processing and parallel programming. I wont be an expert in the field by any means, however:

* I dont want to be a script kiddie, using tools and algorithms without understanding the hows and whys.
* I want to be able read and digest the latest research in statistical learning, specially w.r.t computer vision.

**Books to read:**

* An Introduction to Statistical Learning with Applications in R by Robert Tibshirani et al.
* The Elements of Statistical Learning by Robert Tibshirani et al.
* Understanding Machine Learning: From Theory to Algorithms by Shai Shalev-Shwartz et al.
* Pattern Recognition and Machine Learning by Christopher M. Bishop
* Information Theory, Inference, and Learning Algorithms by David J.C. MacKay
* Deep Learning by Ian Goodfellow et al.
* Convex Optimization by Stephen Boyd et al.
* Computer Vision by Richard Szeliski

**Prerequisites I have studied in preparation:**

* Matrix Algebra by James E. Gentle
* [Statistical and Mathematical Methods course by Carlos Fernandez-Granda](https://cims.nyu.edu/~cfgranda/pages/DSGA1002_fall15/index.html)

I am looking for a reading strategy and reading order in ascending level of difficulty. Id specially appreciate input from users whove read the majority of the books.",0,1,False,self,,,,,
510,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,3,9mrwnk,self.MachineLearning,RL vs Planning (policy learning?),https://www.reddit.com/r/MachineLearning/comments/9mrwnk/rl_vs_planning_policy_learning/,wavelander,1539111124,"While designing a model, I've been coming up against this question a lot and there isn't really a way to proceed if I avoid this question.

&amp;#x200B;

What is the difference between RL and planning? Googling has only made me more confused.

Consider the example:

If you have a sequence which can be generated using a Finite State Machine (FSM), is learning to produce a sequence (which can be represented using the FSM) RL? Or is it planning? 

Is it RL when the FSM is not known, but the agent has to learn the FSM from supervision using sequences? Or is it planning? 

Is planning the same as the agent learning a policy ? 

The agent needs to look at sample sequences and learn to produce them given a starting state. ",0,1,False,self,,,,,
511,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,3,9mryw4,slovenec.org,How artificial intelligence can defeat capitalism,https://www.reddit.com/r/MachineLearning/comments/9mryw4/how_artificial_intelligence_can_defeat_capitalism/,naDlani,1539111549,,0,1,False,default,,,,,
512,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,4,9ms2jq,self.MachineLearning,PLEASE HELP! Looking to utilize adversarial images to defend my privacy,https://www.reddit.com/r/MachineLearning/comments/9ms2jq/please_help_looking_to_utilize_adversarial_images/,jppope,1539112245,[removed],0,1,False,self,,,,,
513,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,4,9msgew,youtu.be,Artificial intelligence machine learning the future evolution Neural Network,https://www.reddit.com/r/MachineLearning/comments/9msgew/artificial_intelligence_machine_learning_the/,DevTechRetopall,1539114946,,0,1,False,https://b.thumbs.redditmedia.com/sIsqKkUbEH_QN_t6dpA8ZnHAGzPo9-PRLFkfe1H58ww.jpg,,,,,
514,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,5,9mspoh,self.MachineLearning,Which are the best countries in the European Union for starting a career in the ML field?,https://www.reddit.com/r/MachineLearning/comments/9mspoh/which_are_the_best_countries_in_the_european/,6_akaka,1539116707,[removed],0,1,False,self,,,,,
515,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,6,9mt2y6,self.MachineLearning,Rent my GPU Workstation - Requirements,https://www.reddit.com/r/MachineLearning/comments/9mt2y6/rent_my_gpu_workstation_requirements/,John_Vinci,1539119244,[removed],0,1,False,self,,,,,
516,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,6,9mteea,self.MachineLearning,[Research] BAIR - Reinforcement Learning of Physical Skills from Videos,https://www.reddit.com/r/MachineLearning/comments/9mteea/research_bair_reinforcement_learning_of_physical/,ceceshao1,1539121559,"BAIR (UC Berkeley) team did some very cool work around deep pose estimation using computer vision and reinforcement learning models trained on video clip data.

IMHO the most interesting part of their work was the simulated characters' ability to generalize to different + irregular environments

Their full blog post is here: [https://bair.berkeley.edu/blog/2018/10/09/sfv/](https://bair.berkeley.edu/blog/2018/10/09/sfv/) and you can find their paper here: [https://xbpeng.github.io/projects/SFV/2018\_TOG\_SFV.pdf](https://xbpeng.github.io/projects/SFV/2018_TOG_SFV.pdf)

*Processing gif cb7h8bc4c8r11...*",4,1,False,https://b.thumbs.redditmedia.com/Avs4RrOGRa4Fdyn5tFkuPIOvFy0fAm7DKkCkgeCPLho.jpg,,,,,
517,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,8,9mu32u,self.MachineLearning,[P] An implementation of Confusion Entropy(CEN)/Modified Confusion Entropy(MCEN),https://www.reddit.com/r/MachineLearning/comments/9mu32u/p_an_implementation_of_confusion/,sepandhaghighi,1539126616,"Github Repo : [https://github.com/sepandhaghighi/pycm](https://github.com/sepandhaghighi/pycm)

&amp;#x200B;

Papers : 

1-  Wei, J.-M., Yuan, X.-Y., Hu, Q.-H., Wang, S.-Q.: A novel measure for evaluating classifiers. Expert Systems with Applications, Vol 37, 37993809 (2010). 

2-  Delgado R., Nez-Gonzlez J.D. (2019) Enhancing Confusion Entropy as Measure for Evaluating Classifiers. In: Graa M. et al. (eds) International Joint Conference SOCO18-CISIS18-ICEUTE18. SOCO18-CISIS18-ICEUTE18 2018. Advances in Intelligent Systems and Computing, vol 771. Springer, Cham ",1,1,False,self,,,,,
518,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,8,9mufjf,self.MachineLearning,AAAI Author Feedback: What happened to work life balance,https://www.reddit.com/r/MachineLearning/comments/9mufjf/aaai_author_feedback_what_happened_to_work_life/,adiM,1539129334,[removed],0,1,False,self,,,,,
519,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,9,9muu2g,self.MachineLearning,Image classification as Unsupervised machine learning task,https://www.reddit.com/r/MachineLearning/comments/9muu2g/image_classification_as_unsupervised_machine/,amansinha_,1539132567,[removed],0,1,False,self,,,,,
520,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,13,9mwcrn,uxdesign.cc,A peoples Bill of Rights for personalization,https://www.reddit.com/r/MachineLearning/comments/9mwcrn/a_peoples_bill_of_rights_for_personalization/,r4dius,1539145574,,0,1,False,default,,,,,
521,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,14,9mwmcf,self.MachineLearning,[D] What are your favorite Tensorflow/Pytorch secret menu items?,https://www.reddit.com/r/MachineLearning/comments/9mwmcf/d_what_are_your_favorite_tensorflowpytorch_secret/,BatmantoshReturns,1539148235,"For Tensorflow when you use `tf.nn.sampled_softmax_loss` it uses `log_uniform_candidate_sampler` by default to pick your negative samples, which uses log-uniform (Zipfian) base distribution, so you shouldn't use it unless your classes are ordered in descending order. If your classes are not in descending  order a better item to order is the `uniform_candidate_sampler`. 

But I like to order the `learned_unigram_candidate_sampler` . 

&gt; The base distribution for this operation is constructed on the fly
&gt;   during training.  It is a unigram distribution over the target
&gt;   classes seen so far during training.  Every integer in `[0, range_max)`
&gt;   begins with a weight of 1, and is incremented by 1 each time it is
&gt;   seen as a target class.  The base distribution is not saved to checkpoints,
&gt;   so it is reset when the model is reloaded.

Delicious! ",24,1,False,self,,,,,
522,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,14,9mwrd1,engati.com,"1 of the major reasons why people prefer hashtag#online shopping over store shopping is that they hashtag#hate waiting in long queues.Then why keep your customers waiting over hashtag#banking hashtag#support calls? Introducing hashtag#Engati, which helps you build your own",https://www.reddit.com/r/MachineLearning/comments/9mwrd1/1_of_the_major_reasons_why_people_prefer/,getengati,1539149720,,0,1,False,default,,,,,
523,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,15,9mwyay,self.MachineLearning,Implementing a deep learning application for recognition of product appearance: any suggestions for suitable algorithms and open source implementations?,https://www.reddit.com/r/MachineLearning/comments/9mwyay/implementing_a_deep_learning_application_for/,zenggyu,1539151888,[removed],0,1,False,self,,,,,
524,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,15,9mx0f3,self.MachineLearning,What to do if you find the proof of a top conference paper is wrong?,https://www.reddit.com/r/MachineLearning/comments/9mx0f3/what_to_do_if_you_find_the_proof_of_a_top/,Kristery,1539152546,[removed],0,1,False,self,,,,,
525,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,15,9mx2pm,self.MachineLearning,[Discussion] Implementing a deep learning application for recognition of product appearance: any suggestions for suitable algorithms and open source implementations?,https://www.reddit.com/r/MachineLearning/comments/9mx2pm/discussion_implementing_a_deep_learning/,zenggyu,1539153278,"Some background:

&amp;#x200B;

I am going to participate in an project which intends to develop a system for discovering potential dress infringement (similarity of visual appearance of a product, e.g., knife). 

Given a collection of images of registered products to train the model, the model should be able to tell whether the appearance of a new product (which is not in the training set) is (almost) the same as any registered products; or more preferably, the model can use a metric to indicate the similarity between the new product and each registered product, and then return the ranks.

&amp;#x200B;

My questions are:

&amp;#x200B;

1. Is this a task that is similar to face recognition? If so, can face recognition algorithms be adapted accomplish this task?

2. Are there any paper that introduce related algorithms?

3. Are there any Github repos that provide open source implementations of related applications?

&amp;#x200B;

Thanks in advance for any comments!",5,1,False,self,,,,,
526,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,16,9mx9p4,self.MachineLearning,[D]facial recognition training with less data,https://www.reddit.com/r/MachineLearning/comments/9mx9p4/dfacial_recognition_training_with_less_data/,Sarthaks21,1539155486,"I'm planning to make a facial recognition model but the amount of data I have is not much. For each person, I have at most 2-5 images. 
What type of NN would be suitable for training this model?
Any other suggestions or appropriate links are also welcome. ",11,1,False,self,,,,,
527,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,16,9mxa9w,self.MachineLearning,[D] Machine learning latest trends,https://www.reddit.com/r/MachineLearning/comments/9mxa9w/d_machine_learning_latest_trends/,FitRemove,1539155660,"I have here jotted down a list of trends that, I feel, will shape ML in 2019 and beyond. Thoughts?

&amp;#x200B;

teks.co.in/site/blog/machine-learning-in-2019-tracing-the-artificial-intelligence-growth-path/",11,1,False,self,,,,,
528,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,16,9mxd9z,self.MachineLearning,[R] Reinforcement Learning for Improving Agent Design,https://www.reddit.com/r/MachineLearning/comments/9mxd9z/r_reinforcement_learning_for_improving_agent/,milaworld,1539156667,"From the abstract: *we explore the possibility of learning a version of the agent's design that is better suited for its task, jointly with the policy. We propose a minor alteration to the OpenAI Gym framework, where we parameterize parts of an environment, and allow an agent to jointly learn to modify these environment parameters along with its policy.*

https://designrl.github.io

https://arxiv.org/abs/1810.03779
",0,1,False,self,,,,,
529,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,16,9mxdfr,forbes.com,How Machine Learning Helps This Russian Steel Giant Prevent Energy Fraud And Stay Number One In Profitability,https://www.reddit.com/r/MachineLearning/comments/9mxdfr/how_machine_learning_helps_this_russian_steel/,asifrazzaq1988,1539156722,,0,1,False,default,,,,,
530,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,16,9mxe3b,self.MachineLearning,Research group formation.,https://www.reddit.com/r/MachineLearning/comments/9mxe3b/research_group_formation/,ClassicPattern,1539156959,[removed],0,1,False,self,,,,,
531,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,17,9mxqis,self.MachineLearning,Machine learning training image resizing,https://www.reddit.com/r/MachineLearning/comments/9mxqis/machine_learning_training_image_resizing/,devansdev,1539161317,[removed],0,1,False,self,,,,,
532,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,18,9mxu1b,digit.fyi,Mental Health Foundation Scotland Urges Caution Over Use of Technology in Treatment,https://www.reddit.com/r/MachineLearning/comments/9mxu1b/mental_health_foundation_scotland_urges_caution/,WhoopDeFreakinDo,1539162556,,0,1,False,default,,,,,
533,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,18,9mxwfj,gautier.marti.ai,[R] network-based portfolio optimization: a new approach?,https://www.reddit.com/r/MachineLearning/comments/9mxwfj/r_networkbased_portfolio_optimization_a_new/,gau_mar,1539163279,,0,1,False,default,,,,,
534,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,19,9my3ni,youtube.com,Is Web Scraping Legal?,https://www.reddit.com/r/MachineLearning/comments/9my3ni/is_web_scraping_legal/,hiren_p,1539165666,,0,1,False,https://b.thumbs.redditmedia.com/WDe10iT-1u6SglxFGOkmZgHd7wv_tvAX99mSb3bQtII.jpg,,,,,
535,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,19,9mydue,medium.com,Advantages Of Machine Learning In Network Management,https://www.reddit.com/r/MachineLearning/comments/9mydue/advantages_of_machine_learning_in_network/,fullstackanalytics1,1539168727,,0,1,False,default,,,,,
536,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,20,9myh17,arxiv.org,[1810.03798] The Outer Product Structure of Neural Network Derivatives,https://www.reddit.com/r/MachineLearning/comments/9myh17/181003798_the_outer_product_structure_of_neural/,ihaphleas,1539169655,,14,1,False,default,,,,,
537,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,20,9mykuz,arxiv.org,[1810.03943] ns3-gym: Extending OpenAI Gym for Networking Research,https://www.reddit.com/r/MachineLearning/comments/9mykuz/181003943_ns3gym_extending_openai_gym_for/,ihaphleas,1539170696,,0,1,False,default,,,,,
538,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,20,9mymnp,thetechnologyheadlines.com,Google to launch StreetLearn dataset to teach machine learning models to navigate cities,https://www.reddit.com/r/MachineLearning/comments/9mymnp/google_to_launch_streetlearn_dataset_to_teach/,vish_007,1539171182,,0,1,False,https://a.thumbs.redditmedia.com/iq5FrHSe_kDYrB5hwKHnpX6bWEXYc0L03QtoENQz4j8.jpg,,,,,
539,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,20,9mynlo,arxiv.org,[1810.02443] FashionNet: Personalized Outfit Recommendation with Deep Neural Network,https://www.reddit.com/r/MachineLearning/comments/9mynlo/181002443_fashionnet_personalized_outfit/,ihaphleas,1539171415,,1,1,False,default,,,,,
540,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,20,9myppo,youtube.com,Can We Stop Artificial Intelligence from Harming Us? (Asimov's laws) - AI Insight episode 1,https://www.reddit.com/r/MachineLearning/comments/9myppo/can_we_stop_artificial_intelligence_from_harming/,Cogno-Res,1539171951,,0,1,False,default,,,,,
541,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,22,9mz9qa,clusterr.io,What features need to be added for this model to make money on BTC predictions.,https://www.reddit.com/r/MachineLearning/comments/9mz9qa/what_features_need_to_be_added_for_this_model_to/,simple_m3,1539176667,,1,1,False,default,,,,,
542,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,22,9mza0g,self.MachineLearning,[D] Designing a recursive/fractal alphabet + implications for artificial intelligence &amp; philosophy of mind/language(?),https://www.reddit.com/r/MachineLearning/comments/9mza0g/d_designing_a_recursivefractal_alphabet/,academc,1539176728,"Hey r/MachineLearningI'm a literature professor who conducts research in global literature and the digital humanities, and I'm currently working on a project involving the alphabet, typography, and computation. In particular, I've spent the last few months working to design and program a recursive alphabet that I believe has important implications for AI and philosophy of mind/language. I could use your help in assessing the philosophical and theoretical implications of what I'm designing and possibly discuss where to take its development from here. If you find this promising, I could especially use technical help to formally implement it and explore its possibilities.


First, please find attached a rather basic but workable illustration of what I plan to implement more robustly in code ([Proof of Concept model](https://i.imgur.com/k5UW1Kc.jpg)). I know it might not seem like much at first glance and I of course welcome critique, but I hope you'll entertain a few thoughts I have about what I believe are its vast implications for computer vision, philosophy of mind/language, and the algorithmic implementation of artificial intelligence. Though I'm not a specialist in these fields, I am here as a literary scholar to offer what I can to help solve interesting + important problems, and I believe the solution to AI cognition might unexpectedly require ""literary"" forms of thinking/reading (though ""literal"" would be more accurate here). Relatedly, please bear in mind that the use of the Latin alphabet here is merely for ease of modeling; the real interest will entail swapping in other alphabetical sets, such as a programming language with self-replicating capabilities.


The recursive alphabet's most distinctive feature is the visual capability of each of its letters to display as either (1) themselves, as per normal, and (2) as recursive and atomically structured [homoglyphs](https://en.wikipedia.org/wiki/Homoglyph) of themselves composed of every letter of the alphabet. For example, the ""single"" ""A"" below can at once be represented as a normal A and also as constituted by the entire alphabet at the same time (among which exists another A):

       A
      BCD
     E   F 
    GH   IJ
    KLMNOPQR
    ST    UV   
    WX    YZ

This model should make intuitive sense to us because it stands to reason that even in everyday contexts, the letter ""A"" presupposes the entire alphabet regardless of the absence of all other letters (one could even argue that the phrase ""the letter A"" is a tautology 10x over). Thus, what is represented by ""A"" holds for B and C, etc. as well as for each of the A-Z letter-atoms that constitute the larger A. And from there, for each of the micro-letters and macro-letters up and down the scale. 


Thus, a second majorly distinctive feature of this recursive alphabet is that each letter is in fact recursively homoglyphic vertically (i.e., each letter ""looks"" like itself at higher and lower scales of observations) as well recursively isomorphic horizontally (i.e. the entire alphabet embedded in one letter is identical in both ordinance and substance to the same entire alphabet embedded in a different letter on the same scalar plane). Basically what we get is an alphabetical structure that is at once consistent, complete, and endlessly self-referential that has a lot of stability because each of the alphabet's characters both constitute and are constituted by all alphabetical characters.

---

I have much more to say about the alphabet's formal implementation, including how we can visualize it using an interface that allows for recursive zoom in and out of the various scales of alphabet, with attention paid to optimizing draw distance at the limits of human perception and pixel display technologies. But the more important application, as mentioned, is not just to visually represent the recursive structure of the English/Latin alphabet but to conceive of novel programming applications. These may possibly proceed in the form of self-replicating Quines, which print out strings of code that are copies (simulacra) of the program's original source code. Having spent a lot of time thinking about and modeling this recursive alphabet, it seems clear to me that if properly developed, a recursive Unicode alphabet could very well be the missing link to true artificial general intelligence, and from there, everything else. 


While I haven't been able to implement this myself due to the limits of my technical expertise, I submit for your consideration the possibility that forms of literary thinking might in fact be essential for conceptualizing how we will build true AGI. As understood via literary theory (re: structuralism, deconstruction, etc.), one could say our human ability to read (and therefore have intelligence) is founded on being able to relate everything to everything in terms of metaphor. The words you're reading right now, for instance, are just metaphors for things that they aren't (e.g. the word ""tree"" =/= actual tree). And these ""words"" are literally made of letters that are themselves metaphors for more fundamental ""letters"", which include, for example, subatomic particles like Higgs bosons or Ideal Letterforms, etc. (e.g. a is not a, it's just particles in the shape of a; also, a is not True A because this &gt;a is not that &gt;a). However, now that we've modeled a recursive alphabet, we have a means by which we can show the interchangeability of meanings between and among any letter or set of letters. Thus we might be able to teach computers to achieve the same nuance of reading.


Consider the following three letters: , , and A. By scrutinizing them, you will discover the letters are very slightly different because they're not English but rather Unicode. Indeed, they are not even of the same local alphabet; the first is Greek, the second is Cyrillic, and the third is Latin. Like the recursive As of my alphabet, these characters are also homoglyphs of each other and are sometimes used in [IDN homograph attacks](https://en.wikipedia.org/wiki/IDN_homograph_attack). However, an important difference is that the , , and A homoglyphs are only hard to detect for humans. For computers, they're as easy to delineate between as we humans are able to delineate between the micro-As and macro-As of my recursive alphabet model.


What is happening is that there are perceptual scales in which humans cannot tell any difference between two given letter-defined objects, while our Unicode-OCD computers have trouble seeing/distinguishing anything except via hardcoded boolean logic (though deep learning can train them to just ""go with it""). Hence the need for my recursive alphabet. In order for us to help AI develop and match human-level adaptive reading skills, I'd argue that it will require a well-implemented recursive Unicode alphabet. AI development up until now has been built on alphabet/Unicode standards that have hyper-rigid or else impossibly ambiguous definitions for what ""A"" means. However, the utility of my recursive alphabet applied to Unicode is that it would allow our Alphabet AI to understand that every ""A"" is in fact made up of the entire cast of other Unicode characters. This more sophisticated understanding of the recursive morphology of the alphabet will give A.I. the ability to observe letters at a much greater range of scales and interrelatedness, allowing them not just to ""identify"" glyphs in parallel isolation but indeed to read letters and their interrelation (and literal intertwinement) with other letters. And from there, words, actions, practices, humans, etc. 


Thus, I am rather confident the first true AGI will become so by becoming fluent in reading Unicode as a recursive alphabet. As you might imagine, I have much, much more to say about this, but I've already gone on too long. If you have a free moment to respond with any thoughts or suggestions for next steps, I would very much appreciate it.",35,1,False,self,,,,,
543,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,22,9mzam2,self.MachineLearning,Deep learning with differential Gaussian process flows,https://www.reddit.com/r/MachineLearning/comments/9mzam2/deep_learning_with_differential_gaussian_process/,alemaari1,1539176860,"Abstract: We propose a novel deep learning paradigm of differential flows that learn a stochastic differential equation transformations of inputs prior to a standard classification or regression function. The key property of differential Gaussian processes is the warping of inputs through infinitely deep, but infinitesimal, differential fields, that generalise discrete layers into a dynamical system. We demonstrate state-of-the-art results that exceed the performance of deep Gaussian processes and neural networks.

&amp;#x200B;

arxiv : [https://arxiv.org/pdf/1810.04066.pdf](https://arxiv.org/pdf/1810.04066.pdf)",0,1,False,self,,,,,
544,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,22,9mzk0o,reuters.com,Amazon scraps secret AI recruiting tool that showed bias against women,https://www.reddit.com/r/MachineLearning/comments/9mzk0o/amazon_scraps_secret_ai_recruiting_tool_that/,BroPowers,1539178863,,0,1,False,https://b.thumbs.redditmedia.com/b-7ODDlvqAmdOjI_sA22ZGK1qjY4IvGF2NOX316uk8g.jpg,,,,,
545,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,23,9mzpzx,self.MachineLearning,Comparison of the reinforcement learning algorithms,https://www.reddit.com/r/MachineLearning/comments/9mzpzx/comparison_of_the_reinforcement_learning/,melihnur,1539180093,[removed],0,1,False,self,,,,,
546,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,23,9mzwpq,medium.com,[D] Live Demo Recording of a Touchless Sensing Control System,https://www.reddit.com/r/MachineLearning/comments/9mzwpq/d_live_demo_recording_of_a_touchless_sensing/,nahuak,1539181438,,0,1,False,https://b.thumbs.redditmedia.com/DMdIe2wPhnZNeDet7lSaMvM1KnUtbYqyMNMw-tTUG9o.jpg,,,,,
547,MachineLearning,t5_2r3gv,2018-10-10,2018,10,10,23,9mzysr,self.MachineLearning,"Resources I used to learn Deep Learning (ML&amp;CV, math, compsci and others)",https://www.reddit.com/r/MachineLearning/comments/9mzysr/resources_i_used_to_learn_deep_learning_mlcv_math/,junweima,1539181858,"if you like it, clap for me on medium: [https://medium.com//best-resources-for-deep-learning-9d78a](https://medium.com/@junweima2/best-resources-for-deep-learning-9d78ac7338c8)  
star my github: [https://github.com/junweima/Deep-Learning-Resources](https://github.com/junweima/Deep-Learning-Resources)and visit my website: [https://junweima.github.io/online-coures-books/](https://junweima.github.io/online-coures-books/)

  
Thanks,

Jeremy",0,1,False,self,,,,,
548,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,0,9n0ogo,self.MachineLearning,"Simple Questions Thread October 10, 2018",https://www.reddit.com/r/MachineLearning/comments/9n0ogo/simple_questions_thread_october_10_2018/,AutoModerator,1539186763,[removed],0,1,False,self,,,,,
549,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,1,9n0xia,self.MachineLearning,[D] CS 598 Statistical Reinforcement Learning (F18),https://www.reddit.com/r/MachineLearning/comments/9n0xia/d_cs_598_statistical_reinforcement_learning_f18/,tigerneil,1539188455,"Theoretical view on Reinforcement Learning

[http://nanjiang.cs.illinois.edu/cs598/](http://nanjiang.cs.illinois.edu/cs598/) ",24,1,False,self,,,,,
550,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,1,9n12j7,self.MachineLearning,A neural network algorithm that seeks 'clarification' on the fly,https://www.reddit.com/r/MachineLearning/comments/9n12j7/a_neural_network_algorithm_that_seeks/,shifty-1,1539189405,"My goal is to develop an algorithm that achieves the following:

* Step 1) For each observation entered into the algorithm there is a limited number of **initial** input nodes (perhaps 5 or so). These would be 'initialising questions'.
* Step 2) Based on the data or responses entered into these initial input nodes the model computes the probability that the observation fits into one of several pre-specified output categories, and presents the top 5 possibilities along with the probabilities that the observation belongs to that class.
* Step 3) If the difference in probabilities between the top two most probable classes is &gt; a pre-determined threshold value (eg 0.6), this is fed back into the algorithm.
* Step 4) The algorithm should then identify which **additional** 1 or 2 input nodes (from a very large pool) would best help to better discern the most likely outcome class. It then requests this data from the user. I'll term these 'clarification questions'.
* Step 5) The user enters the responses to these 'clarification questions' and the data is combined with that from the 'initialising questions' and Steps 2 - 4 are repeated. This cycle continues until the difference in probabilities of outputs is &gt; the threshold value.

I guess that there would need to be an initial model trained on pre-existing data (using the large pool of data fields) to simulate this process, but ideally with each continued observation (or more probably in batches), the model would improve not only the accuracy of its predicted probabilities but also the **additional** input nodes (or 'clarification questions' it selects to request from the user at each round (thereby reducing the number of rounds over time and improving the model's efficiency).

Anyone have any thoughts on this?  Or perhaps may be aware of something similar that has been done? I haven't found anything yet... Maybe I'm going the wrong way about solving my problem and going down the route of a pre-coded classification algorithm is more suited than a neural network? I'd welcome any thoughts or pointers before I delve deeper.

&amp;#x200B;

Thanks.",0,1,False,self,,,,,
551,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,1,9n17wj,reuters.com,[bias in ML] Amazon scraps secret AI recruiting tool that showed bias against women,https://www.reddit.com/r/MachineLearning/comments/9n17wj/bias_in_ml_amazon_scraps_secret_ai_recruiting/,onasafari,1539190400,,0,1,False,https://b.thumbs.redditmedia.com/b-7ODDlvqAmdOjI_sA22ZGK1qjY4IvGF2NOX316uk8g.jpg,,,,,
552,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,2,9n1amm,self.MachineLearning,Why does NTM rotate the previous attention for memory addressing?,https://www.reddit.com/r/MachineLearning/comments/9n1amm/why_does_ntm_rotate_the_previous_attention_for/,throwaway775849,1539190907,[removed],0,1,False,self,,,,,
553,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,2,9n1fbl,self.MachineLearning,Perceptron with three input,https://www.reddit.com/r/MachineLearning/comments/9n1fbl/perceptron_with_three_input/,macob12432,1539191735,[removed],0,1,False,self,,,,,
554,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,2,9n1h9c,self.MachineLearning,Building a Deep Learning Model for Process Optimisation,https://www.reddit.com/r/MachineLearning/comments/9n1h9c/building_a_deep_learning_model_for_process/,andrea_manero,1539192084,[removed],0,1,False,self,,,,,
555,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,2,9n1rss,self.learnmachinelearning,[P] Save and Restore Models with TensorFlow - Hands on Tutorial,https://www.reddit.com/r/MachineLearning/comments/9n1rss/p_save_and_restore_models_with_tensorflow_hands/,amival,1539193950,,0,1,False,default,,,,,
556,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,2,9n1s67,ai.google,[R] Ask the Right Questions: Active Question Reformulation with Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/9n1s67/r_ask_the_right_questions_active_question/,P4TR10T_TR41T0R,1539194017,,0,1,False,default,,,,,
557,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,3,9n24lq,self.MachineLearning,Atari games: MDP or POMDP,https://www.reddit.com/r/MachineLearning/comments/9n24lq/atari_games_mdp_or_pomdp/,AppelsinJuice32,1539196290,"Trying to get a clear understanding between the difference between MDPs and POMDPs but i see some conflicting information. 

In this paper \[1\], at the text for figure 1 they state that the Atari pong is a POMDP because a single frame/observation does not tell us about the direction and velocity of the ball. Stacking the last few frames like in the DQN paper does provide this information - **does that imply that in the DQN paper they change it from POMDP to MDP?**

I would guess so, but in David Silver RL lecture \[2\] slide 23,  he states that its an MDP if the agent directly observe the *environment state.* I.e. Obs = agent state = environment state. But, he also state in the same lecture that the environment state is everything that goes on inside the emulator - which we do not get to see by stacking frames.

&amp;#x200B;

I hope my confusion is clear and that someone can clarify. 

&amp;#x200B;

1, [https://arxiv.org/pdf/1507.06527.pdf](https://arxiv.org/pdf/1507.06527.pdf)

2, [http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching\_files/intro\_RL.pdf](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/intro_RL.pdf)",0,1,False,self,,,,,
558,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,3,9n27od,blog.floydhub.com,English to French translator from scratch with deep learning,https://www.reddit.com/r/MachineLearning/comments/9n27od/english_to_french_translator_from_scratch_with/,narenst,1539196869,,0,1,False,default,,,,,
559,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,3,9n2avu,self.MachineLearning,An Attention Model for Group-Level Emotion Recognition,https://www.reddit.com/r/MachineLearning/comments/9n2avu/an_attention_model_for_grouplevel_emotion/,dakshit97,1539197452,"Check it out! New work on emotion recognition:

Code: r/https://github.com/vlgiitr/Group-Level-Emotion-Recognition

Paper: r/https://dl.acm.org/citation.cfm?doid=3242969.3264985",0,1,False,self,,,,,
560,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,4,9n2gyq,self.MachineLearning,"[D] What is the job interview process for ""Software Engineering"" positions at OpenAI?",https://www.reddit.com/r/MachineLearning/comments/9n2gyq/d_what_is_the_job_interview_process_for_software/,silverblader_,1539198565,"Hi, I have seen previous discussion threads related to interview process at OpenAI for Machine learning research and engineering position. 

I wanted to, specifically know about the interview process for more traditional software engineering roles at OpenAI. It'd be great people can share their own experiences. Thanks. ",27,1,False,self,,,,,
561,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,4,9n2n2d,self.MachineLearning,Building my own Machine-Learning Computer,https://www.reddit.com/r/MachineLearning/comments/9n2n2d/building_my_own_machinelearning_computer/,PeddyCS,1539199683,"Hey guys,

&amp;#x200B;

I just finished Highschool and I will start my CS course next week. I am planning to build my own computer for about 1000 Euros (about 1115 Dollar) which should be able to do some minor machine learning stuff. I know that there are many companies which rent the hardware for a small price. Nevertheless, I would like to have my own computer for some little projects.   
Unfortunately I'm a newbie in machine learning and just started learning Python on my own. But I'm pretty sure that I will get more involved in AI/ML and would like to have the right computer for that.  


I already found this guide ([https://www.oreilly.com/learning/build-a-super-fast-deep-learning-machine-for-under-1000](https://www.oreilly.com/learning/build-a-super-fast-deep-learning-machine-for-under-1000)) and would like to know if you would change something/everything. The post is from February last year.

Since products in the guide are mostly shipped within America I searched for the same products in Germany. Here is the list:

GPU: [https://www.idealo.de/preisvergleich/OffersOfProduct/5135309\_-geforce-gtx-1060-6gt-oc-v1-6144mb-gddr5-msi.html](https://www.idealo.de/preisvergleich/OffersOfProduct/5135309_-geforce-gtx-1060-6gt-oc-v1-6144mb-gddr5-msi.html)  
Mainboard: [https://www.amazon.de/B150I-Pro-Gaming-Mainboard-Mini-ITX-Speicher/dp/B01AWC3FVQ](https://www.amazon.de/B150I-Pro-Gaming-Mainboard-Mini-ITX-Speicher/dp/B01AWC3FVQ)

Case: [https://www.alternate.de/html/product/1153349?gclid=Cj0KCQjwxvbdBRC0ARIsAKmec9au8NJ\_cgCM9P4EbKkMOaL8viiZenceWSLbKdYyTphASeItDSWm4bEaAjNxEALw\_wcB](https://www.alternate.de/html/product/1153349?gclid=Cj0KCQjwxvbdBRC0ARIsAKmec9au8NJ_cgCM9P4EbKkMOaL8viiZenceWSLbKdYyTphASeItDSWm4bEaAjNxEALw_wcB)

RAM: [https://www.alternate.de/html/product/1353796?gclid=Cj0KCQjwxvbdBRC0ARIsAKmec9amCLIwvRULwAncatrwWxbaXZaApWDj1rHbehNDY6JdE1Xz8s6FPPgaAqnKEALw\_wcB](https://www.alternate.de/html/product/1353796?gclid=Cj0KCQjwxvbdBRC0ARIsAKmec9amCLIwvRULwAncatrwWxbaXZaApWDj1rHbehNDY6JdE1Xz8s6FPPgaAqnKEALw_wcB)

CPU: [https://www.amazon.de/Intel-i5-6600-Prozessor-SmartCache-Silber-silver/dp/B010T6D39O/ref=sr\_1\_1?ie=UTF8&amp;qid=1539197520&amp;sr=8-1&amp;keywords=Intel+Core+i5-6600](https://www.amazon.de/Intel-i5-6600-Prozessor-SmartCache-Silber-silver/dp/B010T6D39O/ref=sr_1_1?ie=UTF8&amp;qid=1539197520&amp;sr=8-1&amp;keywords=Intel+Core+i5-6600)

SSD: [https://www.amazon.de/Samsung-MZ-75E250B-EU-interne-schwarz/dp/B00P736UEU](https://www.amazon.de/Samsung-MZ-75E250B-EU-interne-schwarz/dp/B00P736UEU)

Cooler: [https://www.amazon.de/Cooler-Master-CPU-K%C3%BChler-Heatpipes-RR-212E-16PK-R1/dp/B0068OI7T8](https://www.amazon.de/Cooler-Master-CPU-K%C3%BChler-Heatpipes-RR-212E-16PK-R1/dp/B0068OI7T8)

Power Supply: [https://www.amazon.de/Cooler-Master-Netzteil-Semi-Modular-RS650-AMAAB1-EU/dp/B00FNCIGE2](https://www.amazon.de/Cooler-Master-Netzteil-Semi-Modular-RS650-AMAAB1-EU/dp/B00FNCIGE2)

&amp;#x200B;

I'm thankful for every helpful comment. 

&amp;#x200B;

Peddy

&amp;#x200B;

P.S: Sorry for my english \^\^",0,1,False,self,,,,,
562,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,4,9n2n4j,self.MachineLearning,Is there a list of progressive neural networks?,https://www.reddit.com/r/MachineLearning/comments/9n2n4j/is_there_a_list_of_progressive_neural_networks/,coshjollins,1539199694,"I feel like there should already be a timeline of breakthroughs in neural network design somewhere like github or wikipedia. I've seen lists of different neural network typologies, but nothing that shows a timeline or, or in depth explanations of the algorithms, or benchmarks. If it doesn't exist, someone should definitely make one, as it would be a great help in figuring out where the current bar is set for the different areas of in machine learning.",0,1,False,self,,,,,
563,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,4,9n2qdd,medium.com,[N] Huawei Leaps into AI; Announces Powerful Chips and ML Framework,https://www.reddit.com/r/MachineLearning/comments/9n2qdd/n_huawei_leaps_into_ai_announces_powerful_chips/,gwen0927,1539200278,,0,1,False,https://b.thumbs.redditmedia.com/IkEHP9iwEwps1KOlbudgd73Y7ZVeM8iiQ8Pxp_t9Egc.jpg,,,,,
564,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,4,9n2vw9,self.MachineLearning,Reading strategy for the following books?,https://www.reddit.com/r/MachineLearning/comments/9n2vw9/reading_strategy_for_the_following_books/,zindarod,1539201295,[removed],0,1,False,self,,,,,
565,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,7,9n4187,self.MachineLearning,"Study Group for Goodfellow's Book ""Deep Learning""",https://www.reddit.com/r/MachineLearning/comments/9n4187/study_group_for_goodfellows_book_deep_learning/,kal138,1539209129,[removed],0,1,False,self,,,,,
566,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,7,9n4d0t,blogs.msdn.microsoft.com,[N] Using .NET Hardware Intrinsics API to accelerate machine learning scenarios,https://www.reddit.com/r/MachineLearning/comments/9n4d0t/n_using_net_hardware_intrinsics_api_to_accelerate/,darkjeepers,1539211627,,0,1,False,https://b.thumbs.redditmedia.com/I7projRdcEKpWzDoFlZLTWm02D9yYsc2pF-v4dbSKfs.jpg,,,,,
567,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,8,9n4oma,self.MachineLearning,Does the neural network work the same way neurons in our body work?,https://www.reddit.com/r/MachineLearning/comments/9n4oma/does_the_neural_network_work_the_same_way_neurons/,chanyeolxx,1539214157,[removed],0,1,False,self,,,,,
568,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,8,9n4rcl,self.MachineLearning,"Is there a research field of ""human-assisted reasoning""?",https://www.reddit.com/r/MachineLearning/comments/9n4rcl/is_there_a_research_field_of_humanassisted/,rumborak,1539214780,"So, I know there's a good amount of research happening in automated reasoning, where algorithms discover both the constituent facts and their relationships automatically, but because of World Knowledge, or rather the lack thereof, these ontologies are usually very confined, as part of experts systems.

My question is, has there been any research into facilitating a type of ""Wikipedia of reasoning""? That is, users both provide both facts and their relationships, and the underlying automated system would occasionally say ""actually, this contradicts existing reason XYZ"" when entering new relationships.",0,1,False,self,,,,,
569,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,8,9n4wh6,self.MachineLearning,Can someone help me out with this?,https://www.reddit.com/r/MachineLearning/comments/9n4wh6/can_someone_help_me_out_with_this/,mbk0073,1539215961,[removed],0,1,False,self,,,,,
570,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,9,9n4x2s,self.MachineLearning,"[Q] I have done almost 5 ML courses from lynda, packethub, udemy etc. but still dont understand most of the content here!",https://www.reddit.com/r/MachineLearning/comments/9n4x2s/q_i_have_done_almost_5_ml_courses_from_lynda/,0xb800,1539216093,I am usually good at learning stuff but this ML elopes me.  Am I doing something wrong? Should I take different courses ? Should I focus on theory first. Or math. I am totally confused. ,0,1,False,self,,,,,
571,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,12,9n69ek,self.MachineLearning,Choosing the right hardware for ML/DL applications,https://www.reddit.com/r/MachineLearning/comments/9n69ek/choosing_the_right_hardware_for_mldl_applications/,Nubby109,1539227241,[removed],0,1,False,self,,,,,
572,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,12,9n69nd,analyticsinsight.net,Machine Learning Will Convert Your Unstructured Data into Structured Data for Usable Sources of Insight | Analytics Insight,https://www.reddit.com/r/MachineLearning/comments/9n69nd/machine_learning_will_convert_your_unstructured/,analyticsinsight,1539227293,,0,1,False,default,,,,,
573,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,12,9n6kl5,self.MachineLearning,SVM: How to find support vectors?,https://www.reddit.com/r/MachineLearning/comments/9n6kl5/svm_how_to_find_support_vectors/,kiramonchan,1539230006,[removed],0,1,False,self,,,,,
574,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,13,9n6ygp,designrl.github.io,Reinforcement Learning for Improving Agent Design [Google Brain],https://www.reddit.com/r/MachineLearning/comments/9n6ygp/reinforcement_learning_for_improving_agent_design/,serveboy,1539233738,,0,1,False,https://b.thumbs.redditmedia.com/UCF-KDVIwlxFRxV2Zqd2J5akovtAl3MshBe1b8lEaAI.jpg,,,,,
575,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,14,9n738t,self.MachineLearning,Best of Linux Academy,https://www.reddit.com/r/MachineLearning/comments/9n738t/best_of_linux_academy/,MavSidharth,1539235093,[removed],0,1,False,self,,,,,
576,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,15,9n7c6q,arxiv.org,[R] Doubly Reparameterized Gradient Estimators for Monte Carlo Objectives,https://www.reddit.com/r/MachineLearning/comments/9n7c6q/r_doubly_reparameterized_gradient_estimators_for/,hardmaru,1539237722,,1,1,False,default,,,,,
577,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,15,9n7hkw,self.MachineLearning,How to find probabilities of a single tagged entity in the implemented NER,https://www.reddit.com/r/MachineLearning/comments/9n7hkw/how_to_find_probabilities_of_a_single_tagged/,Farhanajz,1539239404,[removed],0,1,False,self,,,,,
578,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,15,9n7kec,self.MachineLearning,[D] What projects can I do with time log data?,https://www.reddit.com/r/MachineLearning/comments/9n7kec/d_what_projects_can_i_do_with_time_log_data/,FlyingQuokka,1539240309,"I've been time logging (recording every single thing I do every day) for about 5 months now, and I want to do something interesting with this data. Any ideas?",16,1,False,self,,,,,
579,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,16,9n7pw2,theverge.com,[N] Apple bought a machine learning green screen startup to focus on AR. This acquisition may boost the iPhones AR features for Memoji or FaceTime or as a part of its plans for an AR headset.,https://www.reddit.com/r/MachineLearning/comments/9n7pw2/n_apple_bought_a_machine_learning_green_screen/,geekgranny,1539242039,,0,1,False,https://b.thumbs.redditmedia.com/uGglJIgzXLsV3KzxGGUBphWS4kd2ft2Z0QSkEFUkBAY.jpg,,,,,
580,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,16,9n7qaj,towardsdatascience.com,All about Logistic regression in one article,https://www.reddit.com/r/MachineLearning/comments/9n7qaj/all_about_logistic_regression_in_one_article/,gauravc2796,1539242167,,0,1,False,https://b.thumbs.redditmedia.com/HyrHc0jc3WkSuYMjTrdtIzEbuK_Qyi_2HV8HEsYjivQ.jpg,,,,,
581,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,16,9n7vq6,macbookphonenumber.com,Dial:-1-888-678-5401 Mac Mini Customer Support Phone Number For Repair &amp; Fix Technical issue,https://www.reddit.com/r/MachineLearning/comments/9n7vq6/dial18886785401_mac_mini_customer_support_phone/,macservicenumber,1539243983,,0,1,False,default,,,,,
582,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,18,9n88kg,github.com,Tinder for your data samples - A PyTorch library for dropping samples from datasets dynamically,https://www.reddit.com/r/MachineLearning/comments/9n88kg/tinder_for_your_data_samples_a_pytorch_library/,UpsetArticle,1539248513,,0,1,False,default,,,,,
583,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,18,9n8faz,self.MachineLearning,Deep Learning course by Great Learning in association with IIT-B faculties.,https://www.reddit.com/r/MachineLearning/comments/9n8faz/deep_learning_course_by_great_learning_in/,akshad_GL,1539250518,[removed],0,1,False,self,,,,,
584,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,18,9n8h4a,corporatetraininganalytics.blogspot.com,Machine Learning Applications: The Dawn of Machine Learning in the Enterprise,https://www.reddit.com/r/MachineLearning/comments/9n8h4a/machine_learning_applications_the_dawn_of_machine/,corporateanalytics,1539251059,,0,1,False,default,,,,,
585,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,18,9n8hlv,self.MachineLearning,What research topics can utilize Machine Learning from a business/managerial perspective?,https://www.reddit.com/r/MachineLearning/comments/9n8hlv/what_research_topics_can_utilize_machine_learning/,clutchking_asiimov,1539251215,[removed],0,1,False,self,,,,,
586,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,18,9n8i5p,self.MachineLearning,Beta demo: TensorflowJS GUI to visualise and train DL models,https://www.reddit.com/r/MachineLearning/comments/9n8i5p/beta_demo_tensorflowjs_gui_to_visualise_and_train/,0mbre,1539251392,[removed],0,1,False,self,,,,,
587,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,18,9n8jl6,self.MachineLearning,[D] What research topics can I work on which use machine learning from a managerial/business perspective?,https://www.reddit.com/r/MachineLearning/comments/9n8jl6/d_what_research_topics_can_i_work_on_which_use/,clutchking_asiimov,1539251846,"Currently a junior year business student with Finance as my specialization. I need to submit a research paper by the end of my senior year according to the undergraduate course outline. I have been planning to use Machine Learning for my research and to find its applicability and utility from a business/managerial perspective. Here are some of the topics I have thought for now:

1. Sentiment analysis to determine consumer behavior and analyze customer trends

2. Determining the best learning method to detect frauds in commercial transactions

3. Forecasting stock market movements using neural networks/genetic algorithms

4. Image recognition to catch faulty products on production line belts.

Do pardon me if the topics I thought of dont sound as catchy as they should since I am not so well versed in making my topics appear more ML oriented. Would love to get more research topic recommendations, or advice about my planned research topics in general.",10,1,False,self,,,,,
588,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,19,9n8k2f,self.MachineLearning,[P] Beta demo: TensorflowJS GUI to visualise and train DL models,https://www.reddit.com/r/MachineLearning/comments/9n8k2f/p_beta_demo_tensorflowjs_gui_to_visualise_and/,0mbre,1539252002,"Hi guys,

Over the past few months I've been working on a tool to build, visualise  and train deep neural net models in the browser.

The tool is in early stages so before spending too much time on this, getting some initial impressions from the people in this community would be tremendously helpful.

The tools is currently here ( this link is temporary):

[http://ai-fiddle-alpha.s3-website.eu-west-3.amazonaws.com/#/dataset](http://ai-fiddle-alpha.s3-website.eu-west-3.amazonaws.com/#/dataset)

I've made a video intro to give an overview:

[https://youtu.be/9NcBqjAMNjQ](https://youtu.be/9NcBqjAMNjQ)

Also I've created a repo to track issues:

[https://github.com/m4nuC/aifiddle/issues](https://github.com/m4nuC/aifiddle/issues)

\- Could you see yourself using this tool ? If so in which context ?

\- Can you think of any features you'd like to see added?

&amp;#x200B;

Thanks a ton,

Emmanuel",53,1,False,self,,,,,
589,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,19,9n8shi,self.MachineLearning,Learning/predicting labels from transaction data,https://www.reddit.com/r/MachineLearning/comments/9n8shi/learningpredicting_labels_from_transaction_data/,woolybulli,1539254322,[removed],0,1,False,self,,,,,
590,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,19,9n8uje,arxiv.org,[R] Sinkhorn AutoEncoders,https://www.reddit.com/r/MachineLearning/comments/9n8uje/r_sinkhorn_autoencoders/,baylearn,1539254903,,4,1,False,default,,,,,
591,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,20,9n90e0,self.MachineLearning,Project Ideas in Multi-Agent Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/9n90e0/project_ideas_in_multiagent_reinforcement_learning/,ynliPbqM,1539256432,"Does anyone have any interesting ideas worth exploring in MARL - possibly in relation to game theory? I started my masters recently and my prof (who does game theory, auctioning, ....) wants me to start looking into MARL. So far I've been looking at coordination in collaborative MARL and some recent papers there. For example, Learning to Communicate with Deep Multi-Agent Reinforcement Learning ([https://arxiv.org/abs/1605.06676](https://arxiv.org/abs/1605.06676)) and Counterfactual multi-agent policy gradients ([https://arxiv.org/pdf/1705.08926.pdf](https://arxiv.org/pdf/1705.08926.pdf)).

&amp;#x200B;

I was wondering what are some reasonable ideas worth exploring in this field that I can hopefully build on.",0,1,False,self,,,,,
592,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,20,9n96y1,self.MachineLearning,Online Learning,https://www.reddit.com/r/MachineLearning/comments/9n96y1/online_learning/,__olamilekan__,1539258019,[removed],0,1,False,self,,,,,
593,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,22,9n9wtl,reddit.com,X-Post: Setting up a machine learning GPU cluster machine at university,https://www.reddit.com/r/MachineLearning/comments/9n9wtl/xpost_setting_up_a_machine_learning_gpu_cluster/,s_m_w,1539264080,,0,1,False,default,,,,,
594,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,22,9n9x2j,self.MachineLearning,IRIS Flower Classification using Logistic Regression Classifier: An end- 2-end Data Science Recipe for Beginners,https://www.reddit.com/r/MachineLearning/comments/9n9x2j/iris_flower_classification_using_logistic/,setscholars,1539264139,[removed],0,1,False,self,,,,,
595,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,23,9naa1h,blog.pocketcluster.io,"[N] Weekly Machine Learning Opensource Roundup  Oct. 11, 2018",https://www.reddit.com/r/MachineLearning/comments/9naa1h/n_weekly_machine_learning_opensource_roundup_oct/,stkim1,1539266897,,0,1,False,default,,,,,
596,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,23,9naa6u,i.redd.it,"[:,None]*X /////Can somebody tell what the dimension of this array would be?",https://www.reddit.com/r/MachineLearning/comments/9naa6u/nonex_can_somebody_tell_what_the_dimension_of/,shreykhetrapal,1539266923,,0,1,False,https://b.thumbs.redditmedia.com/hRDrWe2Ssxif8A6nRxrshRj0CWJwwlsOQqtdzWcRThA.jpg,,,,,
597,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,23,9naiwy,self.MachineLearning,What happened to Facebook's TensorComprehensions?,https://www.reddit.com/r/MachineLearning/comments/9naiwy/what_happened_to_facebooks_tensorcomprehensions/,gr_eabe,1539268669,[removed],0,1,False,self,,,,,
598,MachineLearning,t5_2r3gv,2018-10-11,2018,10,11,23,9nakxb,cloud.google.com,How RealtimeCRM built a business card reader using machine learning,https://www.reddit.com/r/MachineLearning/comments/9nakxb/how_realtimecrm_built_a_business_card_reader/,Mattrt123,1539269065,,0,1,False,default,,,,,
599,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,0,9nasmc,cloud.google.com,[N] How RealtimeCRM built a business card reader using machine learning,https://www.reddit.com/r/MachineLearning/comments/9nasmc/n_how_realtimecrm_built_a_business_card_reader/,Mattrt123,1539270564,,0,1,False,https://b.thumbs.redditmedia.com/kKo3YFbhhgPGxKw7zMtuH1-fATDmMdPVsmg3is-pSHo.jpg,,,,,
600,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,0,9naxtf,self.MachineLearning,Pre-requisites for machine learning - from a software developer,https://www.reddit.com/r/MachineLearning/comments/9naxtf/prerequisites_for_machine_learning_from_a/,Conura,1539271575,[removed],0,1,False,self,,,,,
601,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,0,9nay9b,self.MachineLearning,"[P] OpenAI GLOW tensorflow re-implementation: code, notebooks, slides: CelebA 64x64 on single GPU",https://www.reddit.com/r/MachineLearning/comments/9nay9b/p_openai_glow_tensorflow_reimplementation_code/,kmkolasinski,1539271665,"Hi, I made a simple re-implementation of the OpenAI GLOW model, which resulted in quite simple, modular and keras-like high level library (see README). I was able to train a decent model up to 64x64 resolution on single GPU within few hours with model having more than 10M parameters. I also made some experiments with prior temperature control, having some interesting results not discussed in the paper (see slides.pdf).

Link to the project: [https://github.com/kmkolasinski/deep-learning-notes/tree/master/seminars/2018-10-Normalizing-Flows-NICE-RealNVP-GLOW](https://github.com/kmkolasinski/deep-learning-notes/tree/master/seminars/2018-10-Normalizing-Flows-NICE-RealNVP-GLOW)

Models can be trained with notebooks. You just need to download CelebA dataset and convert it to tfrecords as described in the readme. 

Finally, of course all kudos to OpenAI for sharing the code! otherwise I wouldn't have time to implement everything from scratch. 

Here are some samples, which were generated by the model trained with [Celeba48x48\_22steps](https://github.com/kmkolasinski/deep-learning-notes/blob/master/seminars/2018-10-Normalizing-Flows-NICE-RealNVP-GLOW/notebooks/Celeba48x48_22steps.ipynb) 

*Processing img b56u0pzvqkr11...*",12,1,False,self,,,,,
602,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,0,9nb2z3,self.MachineLearning,Deep Learning for Advanced Additive Manufacturing,https://www.reddit.com/r/MachineLearning/comments/9nb2z3/deep_learning_for_advanced_additive_manufacturing/,amyne02,1539272560,[removed],0,1,False,self,,,,,
603,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,0,9nb7ke,self.MachineLearning,[D] Training GANs on a one 3D sample dataset,https://www.reddit.com/r/MachineLearning/comments/9nb7ke/d_training_gans_on_a_one_3d_sample_dataset/,nottakumasato,1539273470,"Apart from using data augmentation methods (like rotating), is there any way to increase the datasize of a one 3D sample? For a project I am doing, I only have one large cube of values to make the GAN learn and replicate the cube with similar distributions.",7,1,False,self,,,,,
604,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,1,9nba6l,youtube.com,Neural Network Artificial Intelligence - 2018 2D Designer,https://www.reddit.com/r/MachineLearning/comments/9nba6l/neural_network_artificial_intelligence_2018_2d/,DevTechRetopall,1539273952,,1,1,False,https://b.thumbs.redditmedia.com/mZDOqHKrJZOynLrRPxFiEjULe_3DNXTrUrIRUN9Q5Fo.jpg,,,,,
605,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,2,9nbqx2,self.MachineLearning,OpenAI scholar Application open.,https://www.reddit.com/r/MachineLearning/comments/9nbqx2/openai_scholar_application_open/,rosh_ray,1539277216,Check out @gdbs Tweet: https://twitter.com/gdb/status/1050424629058105344?s=09,0,1,False,self,,,,,
606,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,2,9nbt5s,picovoice.ai,Voice control engine running fully in the browser using WebAssembly,https://www.reddit.com/r/MachineLearning/comments/9nbt5s/voice_control_engine_running_fully_in_the_browser/,alikenar,1539277622,,0,1,False,default,,,,,
607,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,2,9nc6xm,self.MachineLearning,"To preserve order invariance, can you shuffle instead of sum?",https://www.reddit.com/r/MachineLearning/comments/9nc6xm/to_preserve_order_invariance_can_you_shuffle/,throwaway775849,1539280203,[removed],0,1,False,self,,,,,
608,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,4,9nd0qu,self.MachineLearning,[D] How are state bodies using ML to improve their operations?,https://www.reddit.com/r/MachineLearning/comments/9nd0qu/d_how_are_state_bodies_using_ml_to_improve_their/,Trump_Hunter,1539285737,"For example, using ML to improve permitting process (building), prioritising food safety inspections, etc.",2,1,False,self,,,,,
609,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,4,9nd6wt,self.MachineLearning,Confused by DCGAN Architecture,https://www.reddit.com/r/MachineLearning/comments/9nd6wt/confused_by_dcgan_architecture/,StackBPoppin,1539286899,"I successfully implemented a GAN which learned to generate photos from a batch of images which were 200x113 pixels in size.

I'm now attempting to achieve the same with a DCGAN, this time the images have been cropped to 200x112 and I'm only working with greyscale values. 

My architecture is roughly:

For the generator: A dense layer of (14 \* 25 \* 512) -&gt; Reshaped to \[-1, 14, 25, 512\] -&gt; conv2d\_transpose(filters=256) -&gt; conv2d\_transpose(filters=128) -&gt; conv2\_transpose(filters=1)

For the discriminator: conv2d(filters=64) -&gt; conv2d(filters=128) -&gt; conv2d(filters=256) -&gt; flatten -&gt; Dense layer (512) -&gt; Dense layer(1)

For each convolution/transposed convolution I use a stride of 2 and a kernel size of 2. This way the dimensions repeatedly double from the original 14x25 to the image size of 112x200.

I've tried different activation functions (ReLU, Leaky ReLU, sigmoid, tanh) but I keep getting one of two results: the discriminator score plummets and the generator output doesn't change, or the generator keeps outputting a blank image with a single dark column at the right of the image.

I've been reading conflicting information on which activation functions to use, which layers, what the kernel and stride should be. I've tried all sorts without any results.

Which layers and activation functions would you recommend for generating greyscale images with a resolution of 200 (width) and 112 (height)?

&amp;#x200B;",0,1,False,self,,,,,
610,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,4,9ndapm,self.MachineLearning,Classification algorithm to predict next purchase?,https://www.reddit.com/r/MachineLearning/comments/9ndapm/classification_algorithm_to_predict_next_purchase/,nishgaddam,1539287604,[removed],0,1,False,self,,,,,
611,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,5,9ndfsw,self.MachineLearning,[R] Variational Sequential Labelers for Semi-Supervised Learning,https://www.reddit.com/r/MachineLearning/comments/9ndfsw/r_variational_sequential_labelers_for/,rokrokss,1539288551,[removed],0,1,False,self,,,,,
612,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,5,9ndjdm,ttic.uchicago.edu,Variational Sequential Labelers for Semi-Supervised Learning,https://www.reddit.com/r/MachineLearning/comments/9ndjdm/variational_sequential_labelers_for/,rokrokss,1539289201,,0,1,False,default,,,,,
613,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,5,9ndmka,ttic.uchicago.edu,[R] Variational Sequential Labelers for Semi-Supervised Learning,https://www.reddit.com/r/MachineLearning/comments/9ndmka/r_variational_sequential_labelers_for/,rokrokss,1539289808,,1,1,False,default,,,,,
614,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,5,9ndo1k,lambdalabs.com,2080 Ti TensorFlow GPU benchmarks comparing 2080 Ti vs V100 vs 1080 Ti vs Titan V,https://www.reddit.com/r/MachineLearning/comments/9ndo1k/2080_ti_tensorflow_gpu_benchmarks_comparing_2080/,sabalaba,1539290075,,1,1,False,default,,,,,
615,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,5,9ndrsw,self.MachineLearning,Elements of Statistical Learning or Andrew Ng's Course First?,https://www.reddit.com/r/MachineLearning/comments/9ndrsw/elements_of_statistical_learning_or_andrew_ngs/,themooseexperience,1539290797,"So I'm an undergraduate student looking to get into ML. I'm sure this has been asked before, but I've read the Super Harsh Guide to Getting a Career in ML, and I'm wondering if there really is an order in which I should real ESL and take the Coursera course. I'm much more of a visual learner, so I feel that the online course would be most helpful off the bat, but if there's information in it I won't understand without reading ESL, I'd feel I wasted my money.

Does anyone have any tips on if I should definitely read ESL before taking the Coursera course, or if order isn't really that important. I have taken Linear Algebra, some basic stats, and 2 courses on ML in my undergraduate studies (one very introductory, one I'm currently taken now going into more complex linear algebra topics - least squares, ridge regression, getting into svm's soon, etc). ",0,1,False,self,,,,,
616,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,6,9ndxgx,self.MachineLearning,"M4 Forecasting Competition Conference, December, NYC",https://www.reddit.com/r/MachineLearning/comments/9ndxgx/m4_forecasting_competition_conference_december_nyc/,slaweks,1539291883,[removed],0,1,False,self,,,,,
617,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,6,9ne27k,self.MachineLearning,Supervised learning methods for match detection,https://www.reddit.com/r/MachineLearning/comments/9ne27k/supervised_learning_methods_for_match_detection/,etmhpe,1539292776,"I am trying to do some research into supervised match detection.  What I mean by this is that positive examples would be  two entities that ""match"" in some sense and negative examples would be two entities that don't ""match"".  A concrete example would be predicting friends in a social network - positive examples would be two users who are friends and negative examples would be two users who are not friends.  The input features could be based on the two users individually or they could be based on what the two users have in common.   So at prediction time you can predict whether two users are likely to be friends.  I am trying to do some research on this and perhaps find a survey of methods.  Or better yet does this type of problem have an actual name that is used in research?",0,1,False,self,,,,,
618,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,6,9nec99,lambdalabs.com,"2080 Ti: The Killer GPU for TensorFlow vs. 2080, 1080 Ti, Titan V, V100.",https://www.reddit.com/r/MachineLearning/comments/9nec99/2080_ti_the_killer_gpu_for_tensorflow_vs_2080/,mippie_moe,1539294834,,0,1,False,https://b.thumbs.redditmedia.com/FF2brnCckSBqJ0bDf7D4p4mYZ-BJaYk4-bRcth2PUFE.jpg,,,,,
619,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,6,9nedr5,self.MachineLearning,1x Titan V or 2x 2080Ti?,https://www.reddit.com/r/MachineLearning/comments/9nedr5/1x_titan_v_or_2x_2080ti/,gonzales82,1539295154,[removed],0,1,False,self,,,,,
620,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,8,9nf0v4,self.datascience,"Dataset available of 3,019 Billboard music chart entries with lyrics for 2,840 of them",https://www.reddit.com/r/MachineLearning/comments/9nf0v4/dataset_available_of_3019_billboard_music_chart/,today_is_tuesday,1539300004,,0,1,False,https://b.thumbs.redditmedia.com/JVF1WdxVQomU4Fx23_smsrisjl_KQdJSns5Xv6rLMpE.jpg,,,,,
621,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,8,9nf8u8,self.MachineLearning,[P] PyTorch version of NEAT (UberAI Lab),https://www.reddit.com/r/MachineLearning/comments/9nf8u8/p_pytorch_version_of_neat_uberai_lab/,wei_jok,1539301775,"Link to GitHub repo: https://github.com/uber-research/PyTorch-NEAT/

## Background
NEAT (NeuroEvolution of Augmenting Topologies) is a popular neuroevolution algorithm, one of the few such algorithms that evolves the architectures of its networks in addition to the weights. For more information, see this research paper: http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf.

HyperNEAT is an extension to NEAT that indirectly encodes the weights of the network (called the substrate) with a separate network (called a CPPN, for compositional pattern-producing network). For more information on HyperNEAT, see this website: http://eplex.cs.ucf.edu/hyperNEATpage/.

Adaptive HyperNEAT is an extension to HyperNEAT which indirectly encodes both the initial weights and an update rule for the weights such that some learning can occur during a network's ""lifetime."" For more information, see this research paper: http://eplex.cs.ucf.edu/papers/risi_sab10.pdf.

## About
PyTorch NEAT builds upon [NEAT-Python](https://github.com/CodeReclaimers/neat-python) by providing some functions which can turn a NEAT-Python genome into either a recurrent PyTorch network or a PyTorch CPPN for use in HyperNEAT or Adaptive HyperNEAT.
We also provide some environments in which to test NEAT and Adaptive HyperNEAT, and a more involved example using the CPPN infrastructure with Adaptive HyperNEAT on a T-maze.",11,1,False,self,,,,,
622,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,9,9nfhyy,self.MachineLearning,Has anyone worked with Natural Language Understanding,https://www.reddit.com/r/MachineLearning/comments/9nfhyy/has_anyone_worked_with_natural_language/,nargund_07,1539303744,"Hello Guys, 
Can you guys help me out with where to start with Natural Language Understanding.
I have completed my machine learning MOOC and have done basic projects and a beginner at  deep learning so I need help! 

Thank You

PS : my first language is not English please forgive for my mistakes",0,1,False,self,,,,,
623,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,9,9nfleg,self.MachineLearning,[D] Help me getting started with Natural Language Understanding,https://www.reddit.com/r/MachineLearning/comments/9nfleg/d_help_me_getting_started_with_natural_language/,nargund_07,1539304508,"Hello Guys

I am beginner in deep learning and I wanted to explore this domain of Natural Language Understanding can you guys please help me in where to get started with 

Thank You

PS : my first language is not English so please forgive me for my bad language",7,1,False,self,,,,,
624,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,9,9nfltt,arxiv.org,Patient2Vec: A Personalized Interpretable Deep Representation of the Longitudinal Electronic Health Record,https://www.reddit.com/r/MachineLearning/comments/9nfltt/patient2vec_a_personalized_interpretable_deep/,kk7nc,1539304602,,19,1,False,default,,,,,
625,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,9,9nfq9a,self.MachineLearning,"[N] M4 Forecasting Competition Conference, December, NYC",https://www.reddit.com/r/MachineLearning/comments/9nfq9a/n_m4_forecasting_competition_conference_december/,slaweks,1539305610,"Hi,
Latest edition of prof. Makridakis time series forecasting competitions (https://en.wikipedia.org/wiki/Makridakis_Competitions) ended a few months ago. 
The data set was rather large: 100K of series.
If you are interested in time series forecasting, using standard or ML methods, including NNs, consider attending a two day M4 Conference (http://www.mcompetitions.unic.ac.cy/) in NYC on 10-11 December 2018. 
The speakers will include Nassim Taleb, Spyros Makridakis, Scott Armstrong, and yours truly :-)

Slawek",2,1,False,self,,,,,
626,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,9,9nfqxz,arxiv.org,[R] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,https://www.reddit.com/r/MachineLearning/comments/9nfqxz/r_bert_pretraining_of_deep_bidirectional/,ofirpress,1539305778,,82,1,False,default,,,,,
627,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,9,9nfqzs,arxiv.org,[R] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,https://www.reddit.com/r/MachineLearning/comments/9nfqzs/r_bert_pretraining_of_deep_bidirectional/,HigherTopoi,1539305790,,0,1,False,default,,,,,
628,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,10,9ng65y,self.MachineLearning,Best sentiment analyzer for reddit data,https://www.reddit.com/r/MachineLearning/comments/9ng65y/best_sentiment_analyzer_for_reddit_data/,karunanayak,1539309205,[removed],0,1,False,self,,,,,
629,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,11,9ngcaj,self.MachineLearning,SAGAN code available,https://www.reddit.com/r/MachineLearning/comments/9ngcaj/sagan_code_available/,Overload175,1539310646,[removed],0,1,False,self,,,,,
630,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,11,9ngfg5,self.MachineLearning,[P] Best sentiment analyzer for Reddit data?,https://www.reddit.com/r/MachineLearning/comments/9ngfg5/p_best_sentiment_analyzer_for_reddit_data/,karunanayak,1539311401," Hello, I am working on a project where I want to find the sentiment of reddit comments. I found TextBlob and NLTK's vader sentiment analyzer mentioned somewhere. Which one is better?

Is there anything else which works better than these two above?",1,1,False,self,,,,,
631,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,11,9nghh1,self.MachineLearning,[D] Graphical Form Filler,https://www.reddit.com/r/MachineLearning/comments/9nghh1/d_graphical_form_filler/,criticalcontext,1539311889,"I'm a machine learning researcher professionally, and I'd like to start a project to create a form filler. Specifically, a form filler that can overcome adversarial attempts by web designers to fight form fillers. To do so, I'd like to handle the entire process by RPA (robotic process automation). The software robot sees the webpage graphically, and places the information in the proper locations via the mouse and keyboard.

First things first, I want to ask the community, what is the closest reference to this line of work? Links are appreciated. I can think of a few, one that compiles android apps from pictures, and one dataset of android apps, but I'd like this for the web preferably. 

Second, I'd like to ask, short of just doing google searches for ""button"" ""text box"" ""calendar"" etc. Are there any datasets to train a one shot classifier to detect UI elements? If not I'd need to write a scrapper to scour the web for images of web pages segmented with buttons I suppose... 

Thanks for your help.",6,1,False,self,,,,,
632,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,11,9nglc0,self.MachineLearning,[D] My cognitive model for model free RL agents,https://www.reddit.com/r/MachineLearning/comments/9nglc0/d_my_cognitive_model_for_model_free_rl_agents/,slayemin,1539312831,"I've been trying to come up with a working model for how biological intelligence works and using that to develop my own AI model. I've been working on this off and on for months, inspired by reinforcement learning. Here's what I've got:  


**PropertySet:**

	The mind does not use or work with objects, but with the set of properties for those objects. It's critical to make this distinction for the sake of pattern matching.

	

**Memory:**

	Memory is transient, stateful information which is used to choose a most optimal behavior. All memory comes with expiration times. When an expiration time is up, the memory is lost and forgotten. The importance of a memory determines how long it persists in memory, and its importance is driven by relevance to internal motivations and number of recalls. The constant trimming of memory state is what prevents cognitive overload in the mind.

	

**Sensory Input:**

	Sensory input is how an agent gets stateful information about the environment around itself. Sensory input information is fed directly into transient memory. There is no filter applied at the sensory input level. Sensor inputs get fed sets of properties created by external objects in the surrounding environment.

	

**Behavior:**

	Behavior is a type of response or interaction an agent can have with itself or the external world around it. Behavior choice is the only tangible evidence we have of an agents internal intelligence, so choosing the correct and wrong behaviors will determine whether the agent passes an intelligence test.

	

**Motivator:**

	Every character has internal needs it is trying to satisfy through the use of behaviors. Motivators are what drive behavior choice in the agents given environmental context. Motivators are defined by a name, a normalized value, and a set of behaviors which have been discovered to change the motivation value one way or another.

	

**Reward:**

	Reward (emergent) is the summed result of all motivations when a behavior effect has been applied to an object. The amount of reward gained is exponentially proportionate to the motivation satisfaction, using an F(X,W) = W(10X\^3); equation, where X is normalized and represents motivational need, and W represents a weight. If you are manually assigning reward values to actions or properties, you're doing it wrong.

	

**Knowledge:**

	Knowledge is a collection of abstract ideas and concepts which are used to identify relationships and associations between things. The abstractions can be applied towards related objects to make predictive outcomes, even though there is no prior history of experience. Knowledge is stored as a combination of property sets, behaviors, motivators, and reward experiences. Knowledge is transferable between agents.

	

	***Knowledge reflection:*** This is an internal process where we look at our collection of assembled knowledge sets and try to infer generalizations, remove redundancies, streamline connections, and make a better organized sense of things. In humans, this crystalization phase typically happens during sleep or through intentional reflection.

	

**Mind:**

	The mind is the central repository for storing memory, knowledge, motivators, and behavior sets, and chooses behaviors based on these four areas of cognition. This is also where it does behavior planning/prediction via a dynamically generated behavior graph, with each node weighted by anticipated reward value evaluated through knowledge.

	  
\-------  
My goal is to build a model free artificial intelligence which learns through trial and error, creates abstractions, applies those abstractions to related objects which drive behavior choice. I don't want to write any finite state machine code, so I've been trying to come up with a generalized intelligence model which can be applied to a variety of character types with a variety of motivators which drive behavior choice. Am I missing anything here? Did I get anything wrong?  


I've got a rough working model in code and am ironing out wrinkles before I start scaling this to lots of objects and dozens of agents.

&amp;#x200B;",5,1,False,self,,,,,
633,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,12,9ngqo0,twitter.com,[P] Magic cards through multiple language iterations of Google Translate,https://www.reddit.com/r/MachineLearning/comments/9ngqo0/p_magic_cards_through_multiple_language/,julian88888888,1539314094,,0,1,False,default,,,,,
634,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,12,9ngwfo,arxiv.org,"[R] ""In a blow to Bayesians everywhere, we find that for CNNs fully Bayesian predictions deviate from, and can dramatically underperform, SGD-trained networks.""",https://www.reddit.com/r/MachineLearning/comments/9ngwfo/r_in_a_blow_to_bayesians_everywhere_we_find_that/,downtownslim,1539315560,,24,1,False,default,,,,,
635,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,13,9nha78,tutorials.technology,GTX2080 Ti TensorFlow GPU benchmarks: The best GPU of 2018?,https://www.reddit.com/r/MachineLearning/comments/9nha78/gtx2080_ti_tensorflow_gpu_benchmarks_the_best_gpu/,pepito_pistola,1539319091,,0,1,False,https://b.thumbs.redditmedia.com/pJ_FbJH9yZXGypo34uc3y6BHbmJCvovvi8lAoAY6BFw.jpg,,,,,
636,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,13,9nhdat,167.114.87.240,88Tangkas | Daftar 88tangkas terpercaya 2018 di Indonesia - Clickbet88,https://www.reddit.com/r/MachineLearning/comments/9nhdat/88tangkas_daftar_88tangkas_terpercaya_2018_di/,abiegarandsoh,1539319964,,0,1,False,default,,,,,
637,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,14,9nhfuv,self.MachineLearning,Lockheed Martin partners with new Australian Institute of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9nhfuv/lockheed_martin_partners_with_new_australian/,TheLeadSA,1539320690,[removed],0,1,False,self,,,,,
638,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,14,9nhjua,twitter.com,Why does Yoshua Bengio think that Boltzmann Machines are promising?,https://www.reddit.com/r/MachineLearning/comments/9nhjua/why_does_yoshua_bengio_think_that_boltzmann/,evc123,1539321875,,0,1,False,default,,,,,
639,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,14,9nhk1f,twitter.com,[D] Why does Yoshua Bengio think that Boltzmann Machines are promising?,https://www.reddit.com/r/MachineLearning/comments/9nhk1f/d_why_does_yoshua_bengio_think_that_boltzmann/,evc123,1539321939,,4,1,False,https://b.thumbs.redditmedia.com/CRAZbOjF8VcdsOe9ZX_wIBnGpcBMKnM8zidc4Hmf19Q.jpg,,,,,
640,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,14,9nhqhy,self.MachineLearning,Summarization models: smmry.com,https://www.reddit.com/r/MachineLearning/comments/9nhqhy/summarization_models_smmrycom/,_spicyramen,1539323942,[removed],0,1,False,self,,,,,
641,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,15,9nhsb1,self.MachineLearning,[R] Recycle-GAN: Unsupervised Video Retargeting,https://www.reddit.com/r/MachineLearning/comments/9nhsb1/r_recyclegan_unsupervised_video_retargeting/,chisai_mikan,1539324492,"*We introduce a data-driven approach for unsupervised video retargeting that translates content from one domain to another while preserving the style native to a domain, i.e., if contents of John Oliver's speech were to be transferred to Stephen Colbert, then the generated content/speech should be in Stephen Colbert's style. Our approach combines both spatial and temporal information along with adversarial losses for content translation and style preservation. In this work, we first study the advantages of using spatiotemporal constraints over spatial constraints for effective retargeting. We then demonstrate the proposed approach for the problems where information in both space and time matters such as face-to-face translation, flower-to-flower, wind and cloud synthesis, sunrise and sunset.*

http://www.cs.cmu.edu/~aayushb/Recycle-GAN/",2,1,False,self,,,,,
642,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,15,9nhw2t,self.MachineLearning,[D] t-sne for insight into neural networks,https://www.reddit.com/r/MachineLearning/comments/9nhw2t/d_tsne_for_insight_into_neural_networks/,Fronkan,1539325663,"Hello I am a M.Sc student in ML and AI and I'm trying to get some insight into my DNN. I have seen some articles on using t-sne for vizualizeing the fully connected layers of a CNN.

What do you think of the approach for a DNN trained on structured (tabular) data? Any practical tips on how to apply it? Alternatively would you recommend some other method to vizualize and understand the internals of a DNN?",9,1,False,self,,,,,
643,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,15,9nhwsb,theaispace.com,Trending and Featured Artificial Intelligence (AI) News,https://www.reddit.com/r/MachineLearning/comments/9nhwsb/trending_and_featured_artificial_intelligence_ai/,theaispace,1539325900,,0,1,False,default,,,,,
644,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,15,9nhxw2,self.MachineLearning,Python GUI that classifies URLs using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9nhxw2/python_gui_that_classifies_urls_using_machine/,Red_Toucan,1539326237,"Hey guys, is it possible to develop a Python GUI that categorizes a URL as malicious or benign based on a Machine Learning classification algorithm?

Thanks.",0,1,False,self,,,,,
645,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,16,9ni94q,self.MachineLearning,Face recognition for theme parks,https://www.reddit.com/r/MachineLearning/comments/9ni94q/face_recognition_for_theme_parks/,shubhamkackar,1539329842,[removed],0,1,False,self,,,,,
646,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,17,9nidzp,self.MachineLearning,How can I learn Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/9nidzp/how_can_i_learn_machine_learning/,anik_saxena,1539331537,[removed],0,1,False,self,,,,,
647,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,17,9nilig,self.MachineLearning,Looking for Healthcare datasets with relevant articles,https://www.reddit.com/r/MachineLearning/comments/9nilig/looking_for_healthcare_datasets_with_relevant/,bibocas,1539334191,[removed],0,1,False,self,,,,,
648,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,17,9nin0f,sql-datatools.com,Artificial intelligence with SQL Server,https://www.reddit.com/r/MachineLearning/comments/9nin0f/artificial_intelligence_with_sql_server/,sql-datatools,1539334764,,0,1,False,https://a.thumbs.redditmedia.com/xTz1jKJkey7PMC8mdWShL_Irj37IIOJgU5EDD1IrBE0.jpg,,,,,
649,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,18,9niwkb,github.com,[R] Google-AI has just open-sourced a bunch of repos with nice codes/experiments,https://www.reddit.com/r/MachineLearning/comments/9niwkb/r_googleai_has_just_opensourced_a_bunch_of_repos/,Thomjazz,1539337967,,0,1,False,default,,,,,
650,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,19,9nj1ux,blog.alookanalytics.com,"Highlights from IEEE International Conference on Image Processing 2018 - Fire detection, better segmentation of Urban Areas using deep learning, and more.",https://www.reddit.com/r/MachineLearning/comments/9nj1ux/highlights_from_ieee_international_conference_on/,gutenmorgenmitnutell,1539339551,,0,1,False,default,,,,,
651,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,19,9nj7uq,self.MachineLearning,[R] Google-AI has just open-sourced a repos with nice codes/experiments on several research projects,https://www.reddit.com/r/MachineLearning/comments/9nj7uq/r_googleai_has_just_opensourced_a_repos_with_nice/,Thomjazz,1539341354,[removed],0,1,False,self,,,,,
652,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,20,9njc4f,self.MachineLearning,[D] Package for multi-GPU training in PyTorch?,https://www.reddit.com/r/MachineLearning/comments/9njc4f/d_package_for_multigpu_training_in_pytorch/,cbsudux,1539342520,,7,1,False,self,,,,,
653,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,20,9njeyp,self.MachineLearning,Python GUI with Machine Learning that classifies URLs,https://www.reddit.com/r/MachineLearning/comments/9njeyp/python_gui_with_machine_learning_that_classifies/,Red_Toucan,1539343301,[removed],0,1,False,self,,,,,
654,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,21,9njofq,sinxloud.com,5 Best (and Free!!) Machine Learning Courses and Tutorials.,https://www.reddit.com/r/MachineLearning/comments/9njofq/5_best_and_free_machine_learning_courses_and/,skj8,1539345877,,0,1,False,default,,,,,
655,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,21,9njtv8,self.MachineLearning,"Transfer learning tutorial, with sample Python code",https://www.reddit.com/r/MachineLearning/comments/9njtv8/transfer_learning_tutorial_with_sample_python_code/,will_nowak,1539347197,"I wrote a tutorial on transfer learning in Keras, with working code. I couldn't find anything else like this on the web so hopefully it can help others get started with this really useful neural network training hack.

[https://medium.com/@williampnowak/how-to-train-your-model-dramatically-faster-9ad063f0f718](https://medium.com/@williampnowak/how-to-train-your-model-dramatically-faster-9ad063f0f718)",0,1,False,self,,,,,
656,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,21,9njx3z,activewizards.com,Comparison of the Top Cloud APIs for Computer Vision,https://www.reddit.com/r/MachineLearning/comments/9njx3z/comparison_of_the_top_cloud_apis_for_computer/,viktoriia_shulga,1539348005,,0,1,False,default,,,,,
657,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,21,9njyfp,self.MachineLearning,Geometric Deep Learning Journal Club,https://www.reddit.com/r/MachineLearning/comments/9njyfp/geometric_deep_learning_journal_club/,Gumeo,1539348328,[removed],0,1,False,self,,,,,
658,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,22,9nkh2x,self.MachineLearning,[News],https://www.reddit.com/r/MachineLearning/comments/9nkh2x/news/,alejandralopzs,1539352512,USC's Information Sciences Institute  chooses Univa to manage growing infrastructure and accelerate Machine Learning Research. [http://www.univa.com/about/news/press\_2018/10092018.php](http://www.univa.com/about/news/press_2018/10092018.php) ,2,1,False,self,,,,,
659,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,23,9nkrzh,medium.com,Experimenting with a crazy way to train Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/9nkrzh/experimenting_with_a_crazy_way_to_train_deep/,sibyjackgrove,1539354846,,1,1,False,default,,,,,
660,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,23,9nkuts,medium.com,Experimenting with a crazy new way to train Deep Neural Networks (Part II),https://www.reddit.com/r/MachineLearning/comments/9nkuts/experimenting_with_a_crazy_new_way_to_train_deep/,sibyjackgrove,1539355451,,0,1,False,https://a.thumbs.redditmedia.com/7bBXQJv8ctIFoHmR11f9NQlBMd_V-j55_GGF0VPdCG8.jpg,,,,,
661,MachineLearning,t5_2r3gv,2018-10-12,2018,10,12,23,9nkwb7,self.MachineLearning,[R] TDLS: Bayesian Deep Learning on a Quantum Computer,https://www.reddit.com/r/MachineLearning/comments/9nkwb7/r_tdls_bayesian_deep_learning_on_a_quantum/,tdls_to,1539355723,"In this paper the authors try to extend the Deep Bayesian Networks to quantum computing architectures and speak about advantages and challenges of this approach.

Paper discussion (by the author): [https://youtu.be/bx5gJwD29p8](https://youtu.be/bx5gJwD29p8)

Paper Ref:  [https://arxiv.org/abs/1806.11463](https://arxiv.org/abs/1806.11463)",5,1,False,self,,,,,
662,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,0,9nl4mx,self.MachineLearning,Convert image to text in-place,https://www.reddit.com/r/MachineLearning/comments/9nl4mx/convert_image_to_text_inplace/,slugsnot,1539357371,[removed],0,1,False,self,,,,,
663,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,0,9nli00,self.datascience,How do you store data long term on the cloud and run data science workflows also on the cloud?,https://www.reddit.com/r/MachineLearning/comments/9nli00/how_do_you_store_data_long_term_on_the_cloud_and/,curadosoprano,1539359994,,0,1,False,default,,,,,
664,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,1,9nlnek,self.MachineLearning,[P] Andrew Ngs Coursera ML course done entirely in Python,https://www.reddit.com/r/MachineLearning/comments/9nlnek/p_andrew_ngs_coursera_ml_course_done_entirely_in/,rsdsdsr,1539361028,"**tl;dr Andrew Ngs Coursera ML course can be done in Python, you dont have to be a Python expert to do it, but you do need a good mathematical foundation, it will be very time consuming, and you wont get a certificate.**

I recently finished Andrew Ngs ML course on Coursera, but rather than using the recommended Matlab/Octave, I did it entirely in Python. You can view the Jupyter notebooks of my work here: https://github.com/seddonr/Ng_ML

Im by no means the first person to do this, but I thought Id post this as encouragement to others who are considering taking the course who, like me, arent interested in learning Matlab/Octave and are wondering about the plusses and minuses of doing it in Python.

Doing the course in Python was quite time consuming as it meant I had to build everything from scratch, whereas if youre doing the course in Matlab/Octave youre provided with a lot of pre-written code. On the other hand it was a great learning experience and I learnt a huge amount of Python that I otherwise wouldnt have.

You dont have to be a Python expert to do this - before doing this course my Python experience was limited to Automate the Boring Stuff with Python and a couple of very brief tutorials on the basics of NumPy and Matplotlib. You do, however, need to have a good mathematical grounding to be able follow the lectures - theres a lot of matrix algebra and differential calculus.

The other issue is that since the course is designed for Matlab/Octave, work done in Python cant be submitted, so you cant have your homeworks graded or get the certificate. This wasnt something that mattered to me, but if it matters to you then maybe Matlab/Octave is the better choice.

Overall I found the course really interesting and enjoyable and I feel like it provided very good coverage of a wide range of ML topics. Andrew Ng presents things very clearly with a pleasant demeanour and his lessons were very easy to follow. Best of luck to anyone who decides to attempt the course in Python, I hope this post proves encouraging!",37,1,False,self,,,,,
665,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,1,9nltlu,self.MachineLearning,[D] What is the most informative and helpful NN diagram you have ever seen?,https://www.reddit.com/r/MachineLearning/comments/9nltlu/d_what_is_the_most_informative_and_helpful_nn/,Periaps,1539362249,"I am looking for figures that allow the reader to grasp the architecture of the whole network without having to carefully read the entire relevant paragraph/paper. A good step in the right direction is [Neural Network Zoo - Asimov Institute](http://www.asimovinstitute.org/neural-network-zoo/) for its uniformity and aesthetics. However, this style of illustration still involves a jumble of connections and individual perceptrons, which is impossible to draw for larger networks.",5,1,False,self,,,,,
666,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,1,9nlz6y,self.MachineLearning,Intriguing Properties of Neural Networks,https://www.reddit.com/r/MachineLearning/comments/9nlz6y/intriguing_properties_of_neural_networks/,bluesky314,1539363321,[removed],0,1,False,self,,,,,
667,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,2,9nm1vp,self.MachineLearning,How do you store data long term on the cloud and run data science workflows also on the cloud?,https://www.reddit.com/r/MachineLearning/comments/9nm1vp/how_do_you_store_data_long_term_on_the_cloud_and/,curadosoprano,1539363827,"I am looking for the most economical option for storing my data (1tb) in an easily accessible cloud storage (like Google Drive/G Suite) that is long term and mountable on my desktop, but then also have the ability to access those data, for example while running a Google cloud instance. I then want to be able to write outputs back to the drive. I never want my data to be local. According to Google, their Drive and Cloud Computing do not interact. Am I thinking about this the right way? Any advice would help.",0,1,False,self,,,,,
668,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,2,9nmc6o,self.MachineLearning,[R] Evolutionary algorithms with and without adaptive mutation in AI based cryptography,https://www.reddit.com/r/MachineLearning/comments/9nmc6o/r_evolutionary_algorithms_with_and_without/,tyburam,1539365769,"**Abstract**

The key role of cryptography is to make cipher so hard to reproduce without knowing all the details that no one besides the recipient could decipher the message. Those algorithms which are used nowadays gets its security mostly from highly reliable algorithms and/or complicated cryptographic keys. Unfortunately, those human-made methods arent invulnerable so sooner or later they compromise. So, it could be really useful to make a cipher which could change. But currently only neural networks are capable of thing known as transfer learning. In this article similar method was proposed in order to make it possible to re-learn already established evolutionary algorithm to do new, similar task.

&amp;#x200B;

Paper: [https://www.itm-conferences.org/articles/itmconf/abs/2018/06/itmconf\_cst2018\_00008/itmconf\_cst2018\_00008.html](https://www.itm-conferences.org/articles/itmconf/abs/2018/06/itmconf_cst2018_00008/itmconf_cst2018_00008.html)

Citation download: [https://www.itm-conferences.org/component/makeref/?task=show&amp;type=html&amp;doi=10.1051/itmconf/20182100008](https://www.itm-conferences.org/component/makeref/?task=show&amp;type=html&amp;doi=10.1051/itmconf/20182100008)",3,1,False,self,,,,,
669,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,3,9nmydb,self.MachineLearning,AWS Credit,https://www.reddit.com/r/MachineLearning/comments/9nmydb/aws_credit/,ramML,1539370093,[removed],0,1,False,self,,,,,
670,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,3,9nn14k,medium.com,Machine Learning: Sentiment analysis of movie reviews using LogisticRegression - A focus on analysing IMDb movie reviews data and try to predict whether the review is positive or negative.,https://www.reddit.com/r/MachineLearning/comments/9nn14k/machine_learning_sentiment_analysis_of_movie/,Fewthp,1539370623,,0,1,False,default,,,,,
671,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,4,9nner0,self.MachineLearning,[N] Join mlcourse.ai - open and free Machine Learning course,https://www.reddit.com/r/MachineLearning/comments/9nner0/n_join_mlcourseai_open_and_free_machine_learning/,festline,1539373279,"&amp;#x200B;

&amp;#x200B;

https://i.redd.it/3txungy25tr11.jpg

This is your chance to join (and compete with) other 5k students studying Machine Learning.  Visit [mlcourse.ai](https://mlcourse.ai), deadline for the first assignment is **October 14**, 20:59 CET. Video lectures on [this](https://www.youtube.com/watch?v=QKTuw4PNOsU&amp;list=PLVlY_7IJCMJeRfZ68eVfEcu-UcN9BbwiX) YouTube playlist will help you. Now more details.

&amp;#x200B;

**What?**

[mlcourse.ai](https://mlcourse.ai/) is an open and free ML course led by OpenDataScience, or [ods.ai](https://ods.ai/), a big (&gt;19k members) community known firstly for its top Kagglers. The course is 10-week long and has lots of practice including assignments (each week), Kaggle Inclass competitions, individual projects, and tutorials. However, focus is made on a perfect balance between theory and practice, so [prerequisites](https://mlcourse.ai/prerequisites) include both basic math concepts and Python skills.

This is actually a MOOC, \~4k guys already passed it in Russian, now is the second time the course launches in English, already &gt;5k participants.

&amp;#x200B;

**What's so special about the course?**

* There will be an interactive [student rating](https://drive.google.com/open?id=19AGEhUQUol6_kNLKSzBsjcGUU3qWy3BNUg8x8IFkO3Q) making it fun to participate and motivating to endure till the end. Yes, this thing really motivates you, lots of participants confirmed that
* It's not for total beginners, the pace is pretty intensive, check out [prerequisites](https://mlcourse.ai/prerequisites)
* The course is supported by a big and alive community, you''ll find authors of articles/assignments/competitions right in the same Slack channel. We chat informally, with jokes and gags
* If you finish the course, you'll master most essential skills required for a Junior Data Scientist
* The course is free after all

All main material is already there in a form of Medium articles, Kaggle Kernels, and Jupyter notebooks, [https://mlcourse.ai/resources](https://mlcourse.ai/resources)

&amp;#x200B;

**Lectures**

Visit [this](https://www.youtube.com/watch?v=QKTuw4PNOsU&amp;list=PLVlY_7IJCMJeRfZ68eVfEcu-UcN9BbwiX) YouTube playlist, lectures are recorded in process, new ones will be uploaded on Fridays/weekends. Though English is not perfect, still you'll see that complicated concepts are expressed in a very intuitive and comprehensible, even for those with no background in math. Just check it out! Start with an introductory [video](https://www.youtube.com/watch?v=QKTuw4PNOsU&amp;list=PLVlY_7IJCMJeRfZ68eVfEcu-UcN9BbwiX&amp;index=1).

&amp;#x200B;

**Articles**

We consider this to be the main content. You'll go from exploratory data analysis with Pandas all the way through logistic regression and Random Forests to gradient boosting, which is an engine under the hood of many real-world systems applying Machine Learning (ex. search and recommender systems).

Jupyter notebooks for all 10 topics are found on [mlcourse.ai](https://mlcourse.ai), main page. The same is also kept in a form of [Kaggle Kernels](https://www.kaggle.com/kashnitsky/mlcourse/kernels) (editable and interactive) in [this](https://www.kaggle.com/kashnitsky/mlcourse) Kaggle Dataset. Or Medium articles (a [""publication""](https://medium.com/open-machine-learning-course)), if you prefer that. Finally, if you are used to work with git &amp; GitHub, go directly to the [course repo](https://github.com/Yorko/mlcourse.ai).

&amp;#x200B;

**Assignments**

Assignments cover each topic, from Pandas till gradient boosting. Are announced in the **#mlcourse\_ai** channel in [ODS Slack team](https://opendatascience.slack.com/). Also, links to fresh assignments are provided in the Readme file of the [course repository](https://github.com/Yorko/mlcourse.ai). Deadlines are typically on Sundays, 20:59 CET. Apart from that, you can practice with demo assignments. See tab [assignments](https://mlcourse.ai/assignments) on the main site.

&amp;#x200B;

**Competitions**

We like Kaggle, it can be a very cool activity, especially for beginners who only start gaining practical experience in ML. We propose two Kaggle Inclass competitions during the course. In some assignments your task will be to beat baselines in these competitions, many guys called these the best ML exercises they've already seen.

Both competitions are not for ""stacking xgboosts"" but require you to come up with nice features (feature engineering is arguably the most interesting part of a Data Scientist's work) and apply (most probably) simple linear models.

In the 1st [competition](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2) youll be solving the task of user identification tracking his/her sequence of visited websites. In the second [competition](https://www.kaggle.com/c/how-good-is-your-medium-article/) you are challenged to predict popularity (number of claps) of an article on Medium.

&amp;#x200B;

**Individual projects**

Your own project for the whole run of the course. Clear instructions, peer review in the end. Arguably, it's the best experience that you can get during the course. For those who don't have nice data to work on, we propose a project with clear instructions in a form of Jupyter notebooks. More info to appear [here](https://mlcourse.ai/roadmap).

&amp;#x200B;

**How to join**

Fill in the [form](https://docs.google.com/forms/d/1_pDNuVHwBxV5wuOcdaXoxBZneyAQcqfOl4V2qkqKbNQ/edit), it's also mentioned on the main page [mlcourse.ai](https://mlcourse.ai). Yo'll get an invitation to OpenDataScience Slack team. You're encouraged to watch the [introductory video](https://www.youtube.com/watch?v=QKTuw4PNOsU&amp;index=1&amp;list=PLVlY_7IJCMJeRfZ68eVfEcu-UcN9BbwiX), it's not that long but will answer most of your questions.

Once again, you can still join the course, deadline for A1 is October 14. Even if you miss it, you still have much more activities to catch up, get credits and finish in a top-100 list. Even if you don't manage o win, you'll get very cool and valuable experience.

Good luck! And ask here your questions.

&amp;#x200B;",11,1,False,https://a.thumbs.redditmedia.com/2uJf0OTAiT8otec82rp3ra5tEN523_BinB1FZI9D0D4.jpg,,,,,
672,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,5,9nntdo,blog.milton.ai,Data Science for Groundhog Day: Avoid Time Loops With Cross-Validation,https://www.reddit.com/r/MachineLearning/comments/9nntdo/data_science_for_groundhog_day_avoid_time_loops/,deliberateinvestor,1539376253,,0,1,False,default,,,,,
673,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,5,9nnxk2,self.MachineLearning,[D] MSc Data Science/AI in Australia,https://www.reddit.com/r/MachineLearning/comments/9nnxk2/d_msc_data_scienceai_in_australia/,___smurf,1539377105,"I am looking for a good program in Data Science in Australia. What are the best universities that has solid programs in ML. How is the level compared to European universities (Edinburgh, Amsterdam, UCL, .. etc) or Canadian universities (UofT, Waterloo,..) ",5,1,False,self,,,,,
674,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,6,9no6my,self.MachineLearning,How can I find Data set for Person Pose recognition?,https://www.reddit.com/r/MachineLearning/comments/9no6my/how_can_i_find_data_set_for_person_pose/,moizkhalid,1539378809,"How can I find Data set for Person Pose recognition and some recommended research papers.

Thank you",0,1,False,self,,,,,
675,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,6,9no9ns,self.MachineLearning,Any advice on how to draw 3D decision boundary hyperplane for Logistic Regression?,https://www.reddit.com/r/MachineLearning/comments/9no9ns/any_advice_on_how_to_draw_3d_decision_boundary/,PhD_BME_job,1539379372,Title says it all basically. I have a 3D scatter plot in Python that Id like to add a hyperplane to show how well Im fitting the data. ,0,1,False,self,,,,,
676,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,6,9nogh5,self.MachineLearning,"[D] AutoML and Google AutoML, and any better naming to avoid confusion?",https://www.reddit.com/r/MachineLearning/comments/9nogh5/d_automl_and_google_automl_and_any_better_naming/,machinenotlearning,1539380658,"When I search AutoML before, it usually means ""automated machine learning"" (ref [wiki](https://en.wikipedia.org/wiki/Automated_machine_learning)), but now days it almost certainly pointed to Google AutoML, which is invented by Quoc Le according to [this](https://aifrontiers.com/2018/08/08/an-unassuming-genius-the-man-behind-google-brains-automl/),  and sometimes it is also called [Cloud ML](https://cloud.google.com/automl/), but actually the same thing.  This is really confusing when you search AutoML,  as you cannot just review the abstract and see which one the article is really about, you have to click and checkout the whole article.  If there are articles mentioned both (like [this one](https://www.forbes.com/sites/janakirammsv/2018/04/15/why-automl-is-set-to-become-the-future-of-artificial-intelligence/)),  you are completely clueless before you finish reading the whole article.  

&amp;#x200B;

I know naming is hard. But would it be possible for the industry to come up with more distinguishable names and terms?  Maybe someone is smarter to propose new names here, :-). ",23,1,False,self,,,,,
677,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,7,9nolfa,self.MachineLearning,10th graders can learn RL in Python,https://www.reddit.com/r/MachineLearning/comments/9nolfa/10th_graders_can_learn_rl_in_python/,michael_jvon,1539381659,[removed],0,1,False,self,,,,,
678,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,7,9nomv1,self.MachineLearning,[D] AAAI rebuttal discussion,https://www.reddit.com/r/MachineLearning/comments/9nomv1/d_aaai_rebuttal_discussion/,schrodingershit,1539381948,I hope the reviews are not as bad as the NIPS reviews this time.,92,1,False,self,,,,,
679,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,7,9nor13,self.MachineLearning,Two Minute Papers &gt;&gt; Sex,https://www.reddit.com/r/MachineLearning/comments/9nor13/two_minute_papers_sex/,Colorless_Idea,1539382856,[removed],0,1,False,self,,,,,
680,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,7,9notb8,self.MachineLearning,Irregular Time Series Classification Help,https://www.reddit.com/r/MachineLearning/comments/9notb8/irregular_time_series_classification_help/,browric2,1539383352,[removed],0,1,False,self,,,,,
681,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,7,9noxzb,self.MachineLearning,What's a good laptop for deep learning?,https://www.reddit.com/r/MachineLearning/comments/9noxzb/whats_a_good_laptop_for_deep_learning/,dokabo,1539384433,[removed],0,1,False,self,,,,,
682,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,8,9npe8h,medium.com,[D] Multi-GPU Framework Comparisons,https://www.reddit.com/r/MachineLearning/comments/9npe8h/d_multigpu_framework_comparisons/,cv_ml,1539388214,,0,1,False,default,,,,,
683,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,12,9nqobs,self.MachineLearning,Both Octave and Python courses well worth the effort.,https://www.reddit.com/r/MachineLearning/comments/9nqobs/both_octave_and_python_courses_well_worth_the/,dandick,1539400399,[removed],0,1,False,self,,,,,
684,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,12,9nqre9,twit.tv,"This Week in Enterprise Tech (#TWiET) - Google's privacy Controls, Facebook Vid Devices, and AI for all Organizations",https://www.reddit.com/r/MachineLearning/comments/9nqre9/this_week_in_enterprise_tech_twiet_googles/,LouMM,1539401259,,0,1,False,default,,,,,
685,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,12,9nqtk5,self.MachineLearning,Any paper on NLP (text summarization etc) using GANs?,https://www.reddit.com/r/MachineLearning/comments/9nqtk5/any_paper_on_nlp_text_summarization_etc_using_gans/,lcukerd,1539401880,[removed],0,1,False,self,,,,,
686,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,13,9nr3ov,self.MachineLearning,Trouble with tensor flow Bin classification,https://www.reddit.com/r/MachineLearning/comments/9nr3ov/trouble_with_tensor_flow_bin_classification/,gireeshwaran,1539404861,[removed],0,1,False,spoiler,,,,,
687,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,13,9nr9ef,singularityweblog.com,Roman Yampolskiy on Artificial Intelligence Safety and Security,https://www.reddit.com/r/MachineLearning/comments/9nr9ef/roman_yampolskiy_on_artificial_intelligence/,StockCampaign,1539406604,,0,1,False,default,,,,,
688,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,14,9nrbb2,singularityweblog.com,[R] Roman Yampolskiy on Artificial Intelligence Safety and Security,https://www.reddit.com/r/MachineLearning/comments/9nrbb2/r_roman_yampolskiy_on_artificial_intelligence/,StockCampaign,1539407206,,0,1,False,default,,,,,
689,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,14,9nrkhj,self.MachineLearning,Can I become a machine learning engineer,https://www.reddit.com/r/MachineLearning/comments/9nrkhj/can_i_become_a_machine_learning_engineer/,gamedev90,1539410082,[removed],0,1,False,self,,,,,
690,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,15,9nrouu,arxiv.org,[R] [1810.04996] A Simple Way to Deal with Cherry-picking,https://www.reddit.com/r/MachineLearning/comments/9nrouu/r_181004996_a_simple_way_to_deal_with/,guicho271828,1539411540,,9,1,False,default,,,,,
691,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,16,9ns0zf,twitter.com,[D] Oxford appears to have ripped off fast.ai,https://www.reddit.com/r/MachineLearning/comments/9ns0zf/d_oxford_appears_to_have_ripped_off_fastai/,therealkenkaniff,1539415685,,0,1,False,default,,,,,
692,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,16,9ns2qz,self.MachineLearning,[N] Oxford appears to have ripped off fast.ai,https://www.reddit.com/r/MachineLearning/comments/9ns2qz/n_oxford_appears_to_have_ripped_off_fastai/,therealkenkaniff,1539416287,"Oxford has announced a [course](https://www.oxfordfoundry.ox.ac.uk/events/2018-10-20-hands-introduction-deep-learning-8-week-course) titled ""Hands-on introduction to deep learning"", and it appears to have almost the exact same content as fast.ai's [Deep Learning for Coders course](http://course.fast.ai/).

https://twitter.com/jeremyphoward/status/1050983049230340096",12,1,False,self,,,,,
693,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,17,9ns85i,self.MachineLearning,[D] Is it worth it to invest in a (slightly) better processor (i7-7700 vs i7-8700) for DL,https://www.reddit.com/r/MachineLearning/comments/9ns85i/d_is_it_worth_it_to_invest_in_a_slightly_better/,matisek1233,1539418305,"Hi, I have a difficult choice to make. I'd like build a DL/ML PC and wondering if slightly better procesor (for slightly higher price :D) will make any impact on DL performance (and user experience), as most of computation will run on GPU (in my case its GTX1070ti).",13,1,False,self,,,,,
694,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,17,9nsbna,self.MachineLearning,[D] Am I the only one stumbled at the recent book Mathematics for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9nsbna/d_am_i_the_only_one_stumbled_at_the_recent_book/,solomonxie,1539419682,"[MML Github](https://mml-book.github.io/)

Im a beginner to Machine learning and looking for a book to start. (Currently got undergrads level knowledge of Linear algebra, calculus and statistics &amp; probability)

The book Mathematics for Machine Learning seems a vibe recently, so I decide to read through it as building up a good foundation for further study.
So excited that it claims to be for the beginner and only requires high school level knowledge. 

But when I got to chapter 2 Linear algebra, it stroke me immediately: large amount of symbols without any explanation, which makes me spent quite a bit to search each symbol. But symbol isnt  the only problem, I found it way too difficult for me to understand ALL sections.

Got frustrated whole day, dont know if I should stick with it or find myself a simpler book to read.

Anyone care to share your opinions?",89,1,False,self,,,,,
695,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,18,9nsh2a,self.MachineLearning,[D]What Linux distro do you use for ML?,https://www.reddit.com/r/MachineLearning/comments/9nsh2a/dwhat_linux_distro_do_you_use_for_ml/,l0gicbomb,1539421817,And how do they make a difference to the ML pipeline...,32,1,False,self,,,,,
696,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,18,9nshd3,self.MachineLearning,Log-Uniform Samples in Random Search,https://www.reddit.com/r/MachineLearning/comments/9nshd3/loguniform_samples_in_random_search/,NexYY,1539421938,[removed],0,1,False,self,,,,,
697,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,18,9nsj8f,youtube.com,Neural Network Editor - Machine Learning - Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/9nsj8f/neural_network_editor_machine_learning_artificial/,DevTechRetopall,1539422698,,0,1,False,default,,,,,
698,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,19,9nstny,self.MachineLearning,Anyone else feeling a little bit emotional?,https://www.reddit.com/r/MachineLearning/comments/9nstny/anyone_else_feeling_a_little_bit_emotional/,IamNobody01000001,1539426707,[removed],0,1,False,self,,,,,
699,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,20,9nt5bj,youtube.com,Avant-Garfield - Creating New Comics With Neural Networks,https://www.reddit.com/r/MachineLearning/comments/9nt5bj/avantgarfield_creating_new_comics_with_neural/,HumblePlayer1,1539430802,,0,1,False,default,,,,,
700,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,22,9ntsdo,youtube.com,What is machine learning (ML) &amp; how it works? Is ML over rated? Difference between Artificial intelligence and Machine Learning!,https://www.reddit.com/r/MachineLearning/comments/9ntsdo/what_is_machine_learning_ml_how_it_works_is_ml/,iamparameswaran,1539437699,,1,1,False,default,,,,,
701,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,23,9nty2d,medium.com,[P] DeNAs PSGAN Dresses Anime Characters at 1024x1024 Pixels,https://www.reddit.com/r/MachineLearning/comments/9nty2d/p_denas_psgan_dresses_anime_characters_at/,gwen0927,1539439202,,0,1,False,https://b.thumbs.redditmedia.com/netD6kNBdGKQgPEkoRS-ykx9dXHHnWY2H6pdg-rJShc.jpg,,,,,
702,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,23,9ntyk1,medium.com,[P] DeNAs PSGAN Dresses Anime Characters at 1024x1024 Pixels,https://www.reddit.com/r/MachineLearning/comments/9ntyk1/p_denas_psgan_dresses_anime_characters_at/,gwen0927,1539439319,,0,1,False,https://b.thumbs.redditmedia.com/netD6kNBdGKQgPEkoRS-ykx9dXHHnWY2H6pdg-rJShc.jpg,,,,,
703,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,23,9ntyne,medium.com,DeNAs PSGAN Dresses Anime Characters at 1024x1024 Pixels,https://www.reddit.com/r/MachineLearning/comments/9ntyne/denas_psgan_dresses_anime_characters_at_1024x1024/,gwen0927,1539439343,,0,1,False,https://b.thumbs.redditmedia.com/netD6kNBdGKQgPEkoRS-ykx9dXHHnWY2H6pdg-rJShc.jpg,,,,,
704,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,23,9nu7nd,self.MachineLearning,Math Major slowly learning Machine Learning. What is the degree of math needed exactly?,https://www.reddit.com/r/MachineLearning/comments/9nu7nd/math_major_slowly_learning_machine_learning_what/,powerforward1,1539441560,[removed],0,1,False,self,,,,,
705,MachineLearning,t5_2r3gv,2018-10-13,2018,10,13,23,9nu9hs,self.MachineLearning,"[D] Grad students of /r/ml, whats your topic? Why is it interesting / good to work on?",https://www.reddit.com/r/MachineLearning/comments/9nu9hs/d_grad_students_of_rml_whats_your_topic_why_is_it/,NicolasGuacamole,1539441998,"Just interested to know the kinds of things people pursuing PhDs in ML are working on, would be great to hear from people about what their research directions are and what they like about them.",148,1,False,self,,,,,
706,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,0,9nufmg,self.MachineLearning,Gradient Descent,https://www.reddit.com/r/MachineLearning/comments/9nufmg/gradient_descent/,lifeinsrndpt,1539443406,[removed],0,1,False,self,,,,,
707,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,2,9nvclr,self.MachineLearning,[D] Need help in answering questions from reviewer,https://www.reddit.com/r/MachineLearning/comments/9nvclr/d_need_help_in_answering_questions_from_reviewer/,schrodingershit,1539450519,"Hi,

I hope everyone who submitted in AAAI had good reviews unlike me. I have sent a Multi-Agent RL paper and the reviewer has asked me this question 
&gt; Did you use any statistical test to analyze the significance of the difference between the performance of different models? I believe it will strengthen the evaluation to include some statistical analysis.

What type of statistical analysis are they talking about? Any help will be great appreciated. 
",22,1,False,self,,,,,
708,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,2,9nvqp5,self.MachineLearning,[D] Fake news,https://www.reddit.com/r/MachineLearning/comments/9nvqp5/d_fake_news/,nutellaNstrawberries,1539453510,How would you go about determining if news is fake / not fully true?,16,1,False,self,,,,,
709,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,3,9nvxcz,self.MachineLearning,Lyrebird.ai API is released. Anyone know what model/training goes on under the hood?,https://www.reddit.com/r/MachineLearning/comments/9nvxcz/lyrebirdai_api_is_released_anyone_know_what/,tzoom,1539454780,[removed],0,1,False,self,,,,,
710,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,4,9nwaju,self.MachineLearning,15 Deep Learning Libraries,https://www.reddit.com/r/MachineLearning/comments/9nwaju/15_deep_learning_libraries/,andrea_manero,1539457295,r/http://www.datasciencecentral.com/profiles/blogs/here-are-15-libraries-in-various-languages-to-help-implement-your,0,1,False,self,,,,,
711,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,6,9nxia1,self.MachineLearning,[D] Recursive Softmax for Attention by Elimination,https://www.reddit.com/r/MachineLearning/comments/9nxia1/d_recursive_softmax_for_attention_by_elimination/,throwaway775849,1539466748,"Had an idea for an attention mechanism. 

Attention mechanisms assume you can learn a specific element to attend to over a sequence. What about problems when it's more practical to easily eliminate one element recursively, until one remains? 

For example, with 10 elements: 

*t=0, get attention scores via softmax over all elements, use them to weight the input, zero out the argmax element 
*t=1, your input would be 10 elements; one element now a zero vector. The function that produces the attention weights should have an easier time eliminating one element than at t=0, because the size of the set is (effectively) reduced. 

Is this a realistic idea or is there a better way to accomplish it?",5,1,False,self,,,,,
712,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,9,9nyo6j,self.MachineLearning,So I think we need to agree on a joke,https://www.reddit.com/r/MachineLearning/comments/9nyo6j/so_i_think_we_need_to_agree_on_a_joke/,IamNobody01000001,1539476637,[removed],0,1,False,self,,,,,
713,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,9,9nyu9q,mbmlbook.com,[R] Model-Based Machine Learning Book,https://www.reddit.com/r/MachineLearning/comments/9nyu9q/r_modelbased_machine_learning_book/,P4TR10T_TR41T0R,1539478253,,0,1,False,default,,,,,
714,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,10,9nz3q2,self.MachineLearning,[D] Looking for a generator of trivially simple synthetic image data?,https://www.reddit.com/r/MachineLearning/comments/9nz3q2/d_looking_for_a_generator_of_trivially_simple/,hongloumeng,1539480730,"I want to generate synthetic images with trivially simple shapes and patterns and use it to evaluate some of the ML models I'm working with.  Ideally it would be in Python and generate large datasets that can be handled easily with torch vision.  Does anyone know of a good solution?

I found \[ShapeWorld\]([https://github.com/AlexKuhnle/ShapeWorld](https://github.com/AlexKuhnle/ShapeWorld)), and it seems very close to what I want, particularly the stochastic generation of components of the image (shape, position, rotation, color, etc).  But it is buggy :(

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;",5,1,False,self,,,,,
715,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,10,9nz61j,self.MachineLearning,Question on Feature selection,https://www.reddit.com/r/MachineLearning/comments/9nz61j/question_on_feature_selection/,drakesword514,1539481387,"If i have 2 features, one of which is binary (feature1), and the other is some integer value(feature2),
If i am to train a regressor on this to predict some value,
How does having the feature as
Theta0 + theta1 x (feature1==true) + theta2 x feature2

Versus

Theta0 + theta1 x (feature2 if feature1 == true else 0) + theta2 x (feature2 if feature1 == false else 0)


Differ?
As in what is different and which of them is better? ",0,1,False,self,,,,,
716,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,11,9nzbib,self.MachineLearning,Management Zone Delineation,https://www.reddit.com/r/MachineLearning/comments/9nzbib/management_zone_delineation/,subredditnvn,1539482843,[removed],0,1,False,self,,,,,
717,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,13,9o05r0,mbmlbook.com,[P] Model-Based Machine Learning (Early Access),https://www.reddit.com/r/MachineLearning/comments/9o05r0/p_modelbased_machine_learning_early_access/,tensorflower,1539491421,,0,1,False,default,,,,,
718,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,13,9o06e9,self.MachineLearning,[P] Model-Based Machine Learning (Early Access),https://www.reddit.com/r/MachineLearning/comments/9o06e9/p_modelbased_machine_learning_early_access/,tensorflower,1539491608,"http://mbmlbook.com/toc.html

By Christopher Bishop of PRML fame, deals with elementary Bayesian inference applied to real world problems. ",14,1,False,self,,,,,
719,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,13,9o07zk,nature.com,"Machine learning techniques developed, which could catch 2-7 times as many environmental infractions at public facilities than traditional approaches.",https://www.reddit.com/r/MachineLearning/comments/9o07zk/machine_learning_techniques_developed_which_could/,Science_Podcast,1539492101,,1,1,False,default,,,,,
720,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,14,9o0dic,donttrack.us,A nice animation : Don't Track Us!,https://www.reddit.com/r/MachineLearning/comments/9o0dic/a_nice_animation_dont_track_us/,Ringo-luke,1539493866,,0,1,False,https://b.thumbs.redditmedia.com/tdj1V7zwk7COTtUBvXgmGHuFG8phTw9OogWUXWt9K7g.jpg,,,,,
721,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,15,9o0pag,self.MachineLearning,[D]Dartmouth Workshop: The Birthplace Of AI,https://www.reddit.com/r/MachineLearning/comments/9o0pag/ddartmouth_workshop_the_birthplace_of_ai/,bonagging,1539497991,"Ever wondered how AI got its name? Want to know the ""Story of AI""? 

Sunscribe to us as we potray the historic events of AI in an unique way! Read this article to know more...

[https://medium.com/rla-academy/dartmouth-workshop-the-birthplace-of-ai-34c533afe992](https://medium.com/rla-academy/dartmouth-workshop-the-birthplace-of-ai-34c533afe992)

And do let us know what you think.

Good day!

&amp;#x200B;",2,1,False,self,,,,,
722,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,15,9o0qd5,self.MachineLearning,[D] Where do you guys look for part time remote AI work?,https://www.reddit.com/r/MachineLearning/comments/9o0qd5/d_where_do_you_guys_look_for_part_time_remote_ai/,ken_signzen,1539498391,"I am hoping to post one. Where do you post for free ones? Message I am to post is listed below:

Hello! Are you interested in remote part time AI Engineer work? Its mainly about vision, and you will have full autonomy in translating the business and functional requirements into awesome technical solutions. And also handle deployment of cutting-edge computer vision and machine learning algorithms in production.

If you are comfortable with Python, Linux, GIT, CV toolkits and has depth and breadth in modern computer vision and machine learning methods. Check us out, and we would love to hear from you. Here is the link for the application form: https://bit.ly/2IYjWj6 Cheers!",0,1,False,self,,,,,
723,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,16,9o0ymt,self.MachineLearning,Evolution algorithm,https://www.reddit.com/r/MachineLearning/comments/9o0ymt/evolution_algorithm/,errminator,1539501514,[removed],0,1,False,self,,,,,
724,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,16,9o0zcn,self.MachineLearning,Empowerment driven Exploration,https://www.reddit.com/r/MachineLearning/comments/9o0zcn/empowerment_driven_exploration/,Teenvan1995,1539501777,"For the past year I have been dabbling with the idea of using empowerment as an intrinsic reward. I know that it is nothing new but I wanted to have a system which was very easy and intuitive to implement, similar to what was achieved by Curiosity driven Exploration using Self Supervised Learning.

[https://navneet-nmk.github.io/2018-08-26-empowerment/](https://navneet-nmk.github.io/2018-08-26-empowerment/)

I believe with better computational resources, I have a chance of having a system which could go toe to toe with the SOTA on Montezuma's revenge.

Thanks !",0,1,False,self,,,,,
725,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,16,9o10uj,self.MachineLearning,[D] Why does Attention in NMT use Softmax instead of Sigmoid?,https://www.reddit.com/r/MachineLearning/comments/9o10uj/d_why_does_attention_in_nmt_use_softmax_instead/,throwaway775849,1539502363,Isn't it a strong inductive bias that we want a distribution peaked on a single element? Wouldn't the ability to have a bimodal with sigmoid / ReLU be more flexible?,45,1,False,self,,,,,
726,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,16,9o112q,self.MachineLearning,"If a keras network takes a grayscale image as input and ouputs an image of same size, with all pixels being either 0 or 1, what loss function and accuracy metric should I use",https://www.reddit.com/r/MachineLearning/comments/9o112q/if_a_keras_network_takes_a_grayscale_image_as/,kingslayyer,1539502459,[removed],0,1,False,self,,,,,
727,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,17,9o1bwk,amitray.com,Artificial Intelligence for Balance Control &amp; Fall Detection of Elderly People,https://www.reddit.com/r/MachineLearning/comments/9o1bwk/artificial_intelligence_for_balance_control_fall/,sanandasen,1539506598,,0,1,False,default,,,,,
728,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,17,9o1dv5,self.MachineLearning,[D]What programming language do you use for ML?,https://www.reddit.com/r/MachineLearning/comments/9o1dv5/dwhat_programming_language_do_you_use_for_ml/,Oghma92,1539507390,"Every project, library that I know or that are linked in this subreddit are written in python. What programming language do you use? Only Python? Im not a big fan of python",47,1,False,self,,,,,
729,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,18,9o1exy,self.MachineLearning,Anyone from India going to MLSS Africa?,https://www.reddit.com/r/MachineLearning/comments/9o1exy/anyone_from_india_going_to_mlss_africa/,yashiiit,1539507815,[removed],1,1,False,self,,,,,
730,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,18,9o1gpv,self.MachineLearning,How do I start learning machine learning through YouTube,https://www.reddit.com/r/MachineLearning/comments/9o1gpv/how_do_i_start_learning_machine_learning_through/,Dreamzzzzzzzzzzz,1539508532,[removed],0,1,False,self,,,,,
731,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,18,9o1gq4,self.MachineLearning,"Can pose estimation use for person recognition? [""project""]",https://www.reddit.com/r/MachineLearning/comments/9o1gq4/can_pose_estimation_use_for_person_recognition/,moizkhalid,1539508534,,0,1,False,self,,,,,
732,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,19,9o1oim,self.MachineLearning,[D] Why doesn't CMT allow MathJax or at least Markdown for reviews and rebuttals?,https://www.reddit.com/r/MachineLearning/comments/9o1oim/d_why_doesnt_cmt_allow_mathjax_or_at_least/,SolitaryPenman,1539511601,"I am writing the rebuttal for my AAAI paper and it irks me that I cannot use math or even simple formatting such as bold, code, quote, etc. Shouldn't a website that hosts research papers at least allow math and markdown for authors and reviewers? ",5,1,False,self,,,,,
733,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,20,9o1zwo,i.redd.it,"[:,None] ----- I'm new to ML using python. I've already implemented this in MATLAB. Can somebody explain the highlighted syntax?",https://www.reddit.com/r/MachineLearning/comments/9o1zwo/none_im_new_to_ml_using_python_ive_already/,shreykhetrapal,1539515888,,0,1,False,https://b.thumbs.redditmedia.com/1KmvOWI3CewvW5sycs0MsU6K7DzOG3_B5LzN5jhdYRA.jpg,,,,,
734,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,23,9o2yud,self.MachineLearning,How to create a dummy from an integer variable in R?,https://www.reddit.com/r/MachineLearning/comments/9o2yud/how_to_create_a_dummy_from_an_integer_variable_in/,milanm23,1539526120,[removed],0,1,False,self,,,,,
735,MachineLearning,t5_2r3gv,2018-10-14,2018,10,14,23,9o30zx,python36.com,How to install Tensorflow GPU with CUDA 10.0 for python on Ubuntu,https://www.reddit.com/r/MachineLearning/comments/9o30zx/how_to_install_tensorflow_gpu_with_cuda_100_for/,Aryal007,1539526653,,0,1,False,default,,,,,
736,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,1,9o3xfk,self.MachineLearning,[D] Can I use CNN (Style transfer) to create handwriting generation.,https://www.reddit.com/r/MachineLearning/comments/9o3xfk/d_can_i_use_cnn_style_transfer_to_create/,jhondipto,1539533668,Suppose i have two image. One is the image that i need to convert. And on another image i have the sample handwriting style. Now i can convert my first image handwriting that will looks like the second image. ,28,1,False,self,,,,,
737,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,1,9o4bci,self.MachineLearning,Need HELP getting started with an automated image captioning system and then search images based on that caption.,https://www.reddit.com/r/MachineLearning/comments/9o4bci/need_help_getting_started_with_an_automated_image/,peeyalk,1539536348,[removed],0,1,False,self,,,,,
738,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,2,9o4e9m,self.MachineLearning,[D] MLSS2018 Shakir Mohamed lectures with slides.,https://www.reddit.com/r/MachineLearning/comments/9o4e9m/d_mlss2018_shakir_mohamed_lectures_with_slides/,tigerneil,1539536899,[removed],0,1,False,self,,,,,
739,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,3,9o4wzp,self.MachineLearning,[D] Upgrading 7 Year Old PC Build to Deep Learning Machine,https://www.reddit.com/r/MachineLearning/comments/9o4wzp/d_upgrading_7_year_old_pc_build_to_deep_learning/,GnarKnees,1539540660,[removed],0,1,False,self,,,,,
740,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,3,9o5483,self.MachineLearning,Machine learning - best way to learn,https://www.reddit.com/r/MachineLearning/comments/9o5483/machine_learning_best_way_to_learn/,Aaraeus,1539542124,[removed],0,1,False,self,,,,,
741,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,4,9o5n9c,github.com,[P] Opensourcing code for aggression detection in Facebook comments (shared task held at COLING 2018),https://www.reddit.com/r/MachineLearning/comments/9o5n9c/p_opensourcing_code_for_aggression_detection_in/,bay_der,1539545923,,0,1,False,default,,,,,
742,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,4,9o5r47,self.MachineLearning,Audiobook follower which follows/prints the text being read?,https://www.reddit.com/r/MachineLearning/comments/9o5r47/audiobook_follower_which_followsprints_the_text/,IHateProtoss,1539546726,[removed],0,1,False,self,,,,,
743,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,5,9o5y5s,biorxiv.org,A Framework for Intelligence and Cortical Function Based on Grid Cells in the Neocortex,https://www.reddit.com/r/MachineLearning/comments/9o5y5s/a_framework_for_intelligence_and_cortical/,slacka123,1539548117,,0,1,False,default,,,,,
744,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,5,9o61iu,biorxiv.org,[R] A Framework for Intelligence and Cortical Function Based on Grid Cells in the Neocortex,https://www.reddit.com/r/MachineLearning/comments/9o61iu/r_a_framework_for_intelligence_and_cortical/,slacka123,1539548798,,0,1,False,default,,,,,
745,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,5,9o62lc,self.MachineLearning,CART: Training set &amp; Test set vs. Training set &amp; Validation set &amp; Test set (help),https://www.reddit.com/r/MachineLearning/comments/9o62lc/cart_training_set_test_set_vs_training_set/,milanm23,1539549015,"Hi there  


I have 2 data sets containing each 100k observations (in one of these the depended variable is a binary response and in the other a continuous). I have to build up 2 trees: A classification and a regression tree for each set. Since I have to prune this tree afterwards I have following questions:

&amp;#x200B;

\- To get the alpha I want to do a cross-validation with 10 ""bins"" (subsets). Should I rater split my data set into 10 folders or split the whole set in a (let's say) 80% training and 20% test set? 

\- Can someone explain me when to use just a training and test set and when to go with three sets (a training set, validation set and a test set)?  What is the main difference between the validation and test set?  


  ",0,1,False,self,,,,,
746,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,5,9o64zc,nytimes.com,Jeff Hawkins Is Finally Ready to Explain His Brain Research,https://www.reddit.com/r/MachineLearning/comments/9o64zc/jeff_hawkins_is_finally_ready_to_explain_his/,Atupis,1539549484,,0,1,False,default,,,,,
747,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,6,9o6g6t,self.MachineLearning,knowledge graph embedding model accuracy not coming up for Neural Association model,https://www.reddit.com/r/MachineLearning/comments/9o6g6t/knowledge_graph_embedding_model_accuracy_not/,rajat_patel,1539551732,[removed],0,1,False,self,,,,,
748,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,6,9o6hx0,self.MachineLearning,Generating images with a NN: am I unprepared?,https://www.reddit.com/r/MachineLearning/comments/9o6hx0/generating_images_with_a_nn_am_i_unprepared/,ralucavinti,1539552098,[removed],0,1,False,self,,,,,
749,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,6,9o6jxa,self.MachineLearning,Help getting started,https://www.reddit.com/r/MachineLearning/comments/9o6jxa/help_getting_started/,leadfoot19,1539552516,[removed],0,1,False,self,,,,,
750,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,6,9o6kre,self.MachineLearning,[D] Chinese Language Machine Learning Discussion Forum,https://www.reddit.com/r/MachineLearning/comments/9o6kre/d_chinese_language_machine_learning_discussion/,alexmlamb,1539552685,"Does anyone know of a forum / site in the Chinese language () for discussing machine learning (papers, topics, etc)?  ",7,1,False,self,,,,,
751,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,7,9o6yqi,self.MachineLearning,Which class to take: Mathematical Statistics or Statistical Learning?,https://www.reddit.com/r/MachineLearning/comments/9o6yqi/which_class_to_take_mathematical_statistics_or/,crypto_ha,1539555681,[removed],0,1,False,self,,,,,
752,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,7,9o71m5,self.MachineLearning,[D] Mathematical Statistics vs. Statistical Learning?,https://www.reddit.com/r/MachineLearning/comments/9o71m5/d_mathematical_statistics_vs_statistical_learning/,crypto_ha,1539556309,"I have to prioritize CS classes, so next (last) semester I will have to decide between taking Mathematical Statistics (proof-based) and Statistical Learning (stat learning theory + exercises on R) from the Statistics department. I want to do Machine Learning in grad school. Which of these 2 classes should I prioritize over the other?",21,1,False,self,,,,,
753,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,7,9o72jz,medium.com,Reinforcement Learning for Home Robotics pt. 1  Coinmonks  Medium,https://www.reddit.com/r/MachineLearning/comments/9o72jz/reinforcement_learning_for_home_robotics_pt_1/,coinmonks,1539556509,,0,1,False,default,,,,,
754,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,8,9o7dih,self.MachineLearning,[D] Question about Variational Lossy Autoencoder paper,https://www.reddit.com/r/MachineLearning/comments/9o7dih/d_question_about_variational_lossy_autoencoder/,knowedgelimited,1539558982,"In the paper 
   Chen, Kingma et al. Variational Lossy Encoder
it discusses about the possibility of VAE ignoring the latent code.

On p.4 it says this: 

&gt;   ""one common way to encourage putting information into the code is to use a factorized decoder p(x|z) = \prod_i p(x_i|z)""

where ""putting information into the code"" meaning into the latent, z.

[screenshot](https://imgur.com/a/J79sEPR)

My question: can anyone explain this:  Why does using a factorized decoder encourage the latent to be used?

In their notation, I believe x_i are individual dimensions of the output, such as individual pixels of an image.

",6,1,False,self,,,,,
755,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,11,9o8ux0,self.MachineLearning,Finding minimum number of features that distinguishes all samples,https://www.reddit.com/r/MachineLearning/comments/9o8ux0/finding_minimum_number_of_features_that/,Sanisco,1539571593,[removed],0,1,False,self,,,,,
756,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,11,9o8vnm,self.MachineLearning,Do You Ever Buy Buy Datasets? If So How/Where?,https://www.reddit.com/r/MachineLearning/comments/9o8vnm/do_you_ever_buy_buy_datasets_if_so_howwhere/,Clarkeyyyy,1539571729,"I'm familiar with Kaggle, Google Data Search, Data is Plural, and a few other sites to find free datasets which have worked great. I'm just really curious if you or anyone you have worked with has paid or sold datasets for data science or machine learning purposes.
",0,1,False,self,,,,,
757,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,12,9o905w,towardsdatascience.com,Tensorflow GPU installation made easy. Cuda and cuDnn are a part of conda installation now.,https://www.reddit.com/r/MachineLearning/comments/9o905w/tensorflow_gpu_installation_made_easy_cuda_and/,harveenchadha,1539572820,,0,1,False,https://b.thumbs.redditmedia.com/bM5-Z99RXIBhrqLslcGLGK0u0MCoZhv0JQjiXox6GwQ.jpg,,,,,
758,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,12,9o987a,github.com,Predicting category of purchase using knn.,https://www.reddit.com/r/MachineLearning/comments/9o987a/predicting_category_of_purchase_using_knn/,atum47,1539574790,,0,1,False,https://a.thumbs.redditmedia.com/er0I_6rnJxrM1uvga68RSF2MO91eVXfG5VObjzuq7I0.jpg,,,,,
759,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,12,9o9a8j,self.MachineLearning,Paper on NLP that takes an interesting/unique approach?,https://www.reddit.com/r/MachineLearning/comments/9o9a8j/paper_on_nlp_that_takes_an_interestingunique/,lcukerd,1539575303,,0,1,False,self,,,,,
760,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,13,9o9dec,self.MachineLearning,"[Project] PyTorch Implementation of Show, Attend, and Tell",https://www.reddit.com/r/MachineLearning/comments/9o9dec/project_pytorch_implementation_of_show_attend_and/,tangbinh,1539576104,"I've been implementing some of the earlier approaches to image captioning, include the famous paper [Show, Attend, and Tell](https://arxiv.org/abs/1502.03044). Notable features include beam search based on [fairseq](https://github.com/pytorch/fairseq) and faster training with easy extension to multi-GPU training. Feel free to use the code if you like. Here's a link to the GitHub repository https://github.com/tangbinh/image-captioning.",1,1,False,self,,,,,
761,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,13,9o9gpx,self.MachineLearning,"[D] I have a about a thousand text samples roughly a paragraph in length that can be divided into categories and follow a general format, I want to generate new examples like these from unstructured source material that the samples I have are derived from. Can I do this?",https://www.reddit.com/r/MachineLearning/comments/9o9gpx/d_i_have_a_about_a_thousand_text_samples_roughly/,Morninglow,1539576935,"The samples would correspond to condensed versions of concepts/events from the source material which would be books. They all follow the format of an observer encountering the concept/event after it has happened or as it is happening and the observer's reaction to it of which there are only a few possible choices. 

&amp;#x200B;

I know I do not have enough examples to recreate the distribution directly but I do have the source material that represents the entire distribution of possible samples albiet in unstructured long form and containing large amounts of unnecessary information instead of condensed excerpts. 

&amp;#x200B;

There is also the potential for free human labeling of a large number of generated samples as good or bad if that makes a difference. ",1,1,False,self,,,,,
762,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,13,9o9qnk,self.LanguageTechnology,My knowledge graph embedding model accuracy not coming up for Neural Association model,https://www.reddit.com/r/MachineLearning/comments/9o9qnk/my_knowledge_graph_embedding_model_accuracy_not/,rajat_patel,1539579580,,0,1,False,default,,,,,
763,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,14,9o9v6b,self.MachineLearning,[D] Jeff Hawkins Is Finally Ready to Explain His Brain Research,https://www.reddit.com/r/MachineLearning/comments/9o9v6b/d_jeff_hawkins_is_finally_ready_to_explain_his/,milaworld,1539580809,"Do any of you follow Numenta's work? There's an article today discussing about their (lack of) collaboration with the rest of the scientific research community:

*Inside Numenta, Mr. Hawkins sits in a small office. Five other neuroscientists, mostly self-taught, work in a single room outside his door.

Mr. Hawkins said a moment of clarity came about two and a half years ago, while he was sitting in his office, staring at a coffee cup.

He touched the cup and dragged his finger across the rim. Then he leapt to his feet and ran through the door.

He ran headlong into his wife, who had stopped by for lunch, and stumbled toward his closest collaborator, Subutai Ahmad, the vice president of research. The cortex knows the location of everything, Mr. Hawkins said. Mr. Ahmad had no idea what he was talking about.

As Mr. Hawkins looked at that cup, he decided that cortical columns did not just capture sensations. They captured the location of those sensations. They captured the world in three dimensions rather than two. Everything was seen in relation to what was around it.

If cortical columns handle sight and touch in this way, Mr. Hawkins thought, they handle hearing, language and even math in similar ways. Hes been working on proving that ever since.

When the brain builds a model of the world, everything has a location relative to everything else, Mr. Hawkins said. That is how it understands everything.

The source of tension between Mr. Hawkins and other brain and A.I. researchers is not that they necessarily think he is wrong. Its that they simply dont know because what he has been trying to do has been so different. And so wildly ambitious.

For the science to advance, what Mr. Hawkins has been working on cant stay in a silo. His ideas could benefit from extensive experimentation with other neuroscientists, said Nelson Spruston, a senior director at the Janelia Research Campus, a research lab in Virginia that focuses on neuroscience. A continuous cycle of testing and revising biologically inspired models of neural computation is the key to developing insightful theories of the brain, he said.

Translation: Mr. Hawkins will have to open his work to rigorous scrutiny and find a way to interact with researchers who most likely have never looked at the brain the way he does.*

https://www.nytimes.com/2018/10/14/technology/jeff-hawkins-brain-research.html
",120,1,False,self,,,,,
764,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,14,9o9w0b,github.com,Progressive GANs implementation using PyTorch.,https://www.reddit.com/r/MachineLearning/comments/9o9w0b/progressive_gans_implementation_using_pytorch/,Karthik9999,1539581062,,0,1,False,default,,,,,
765,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,15,9oa7mh,arxiv.org,[R] Variational Bayesian Monte Carlo,https://www.reddit.com/r/MachineLearning/comments/9oa7mh/r_variational_bayesian_monte_carlo/,hardmaru,1539584492,,1,1,False,default,,,,,
766,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,15,9oaa1s,arxiv.org,[R] Q-map: a Convolutional Approach for Goal-Oriented Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/9oaa1s/r_qmap_a_convolutional_approach_for_goaloriented/,baylearn,1539585288,,0,1,False,default,,,,,
767,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,15,9oaad0,self.MachineLearning,[D] Expected behavior of loss values for a WGAN-GP?,https://www.reddit.com/r/MachineLearning/comments/9oaad0/d_expected_behavior_of_loss_values_for_a_wgangp/,Atom_101,1539585397,"I have been trying to train a WGAN-GP on a custom dataset, to no avail. The discriminator loss after 50-60 iterations stabilizes to around -17 to -25 and stays in this range. I know this sort of GAN takes a lot of time to train but my model has learnt nothing significant even after about 25 epochs. Is this normal behaviour?

I'm asking this because, I had read a post that had described the expectef loss behaviour of WGAN with weight clipping(the discriminator loss is supposed to quickly reach a high negative value and then fall slowly and stabilize to a low negative value). When I train the same model with weight clipping instead of GP, I do get this behaviour(but it still doesn't learn anything after 25 epochs).

So, should I give the same model a few more epochs to train, or do I need change something? Is this even possible to tell from the information that I have?",2,1,False,self,,,,,
768,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,15,9oacim,self.MachineLearning,Are MOOC's worth anything?,https://www.reddit.com/r/MachineLearning/comments/9oacim/are_moocs_worth_anything/,ItsHampster,1539586095,[removed],0,1,False,self,,,,,
769,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,18,9ob7wv,self.MachineLearning,Does 3d facial alignment and reconstruction help improve the accuracy of face recognition?,https://www.reddit.com/r/MachineLearning/comments/9ob7wv/does_3d_facial_alignment_and_reconstruction_help/,lmwang4321,1539596568,[removed],0,1,False,self,,,,,
770,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,18,9ob9va,self.MachineLearning,"Learn about the most effective machine learning techniques, and gain practice implementing them and getting them to work for yourself.",https://www.reddit.com/r/MachineLearning/comments/9ob9va/learn_about_the_most_effective_machine_learning/,davidreed7021,1539597167,[removed],0,1,False,self,,,,,
771,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,18,9obb5n,self.MachineLearning,[Project] Can a pretrained LSTM Recurrent network be used as an encoder in a seq2seq model.,https://www.reddit.com/r/MachineLearning/comments/9obb5n/project_can_a_pretrained_lstm_recurrent_network/,CSGOvelocity,1539597587,"I am making a project that is a ""fill in the blanks"" model. Basically, you provide it a fill in the blanks problem and it solve it.

So far I think a seq2seq model should be able to achieve this using attention.

So can a pretrained LSTM model be attached to the seq2seq model as the encoder and fine tuned using data?

Also, I would greatly appreciate some critique on my approach and if it is correct to solve the ""Fill in the blanks"" model.",10,1,False,self,,,,,
772,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,19,9obd5a,self.MachineLearning,"Learn about the most effective machine learning techniques, and gain practice implementing them and getting them to work for yourself.",https://www.reddit.com/r/MachineLearning/comments/9obd5a/learn_about_the_most_effective_machine_learning/,davidreed7021,1539598153,[removed],0,1,False,self,,,,,
773,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,19,9oblhd,plus.google.com,"Learn about the most effective machine learning techniques, and gain practice implementing them and getting them to work for yourself.",https://www.reddit.com/r/MachineLearning/comments/9oblhd/learn_about_the_most_effective_machine_learning/,davidreed7021,1539600609,,0,1,False,default,,,,,
774,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,19,9obm13,i.redd.it,Easy to understand PyTorch implementation of the paper Progressive Growing Of GANS with decent generated samples-https://github.com/nvnbny/progressive_growing_of_gans,https://www.reddit.com/r/MachineLearning/comments/9obm13/easy_to_understand_pytorch_implementation_of_the/,nvnbny,1539600747,,1,1,False,https://a.thumbs.redditmedia.com/y5oKUm_mqxsKf8_vaXdo3Kjxl1nuujkP8mOvq08a2U4.jpg,,,,,
775,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,20,9obp5b,self.MachineLearning,Jointly training a deep convolutional network that feeds to a recurrent architecture,https://www.reddit.com/r/MachineLearning/comments/9obp5b/jointly_training_a_deep_convolutional_network/,Mondestrasz,1539601635,[removed],0,1,False,self,,,,,
776,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,20,9oc10h,i.redd.it,[P] Easy to understand PyTorch implementation of the paper Progressive Growing Of GANS with decent generated samples - https://github.com/nvnbny/progressive_growing_of_gans,https://www.reddit.com/r/MachineLearning/comments/9oc10h/p_easy_to_understand_pytorch_implementation_of/,nvnbny,1539604777,,1,1,False,default,,,,,
777,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,21,9oc1tm,agilityexchange.com,Governance of ML Models is becoming increasingly important for the organisations today. A good food for thought.,https://www.reddit.com/r/MachineLearning/comments/9oc1tm/governance_of_ml_models_is_becoming_increasingly/,shailendramalik,1539604971,,0,1,False,https://b.thumbs.redditmedia.com/ZJ1DSNKZEQ0OSnJE_m9oFSTjWQZmGV53kblxfyMx7TE.jpg,,,,,
778,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,21,9oc47f,self.MachineLearning,Ranking features in tabular data using deep learning,https://www.reddit.com/r/MachineLearning/comments/9oc47f/ranking_features_in_tabular_data_using_deep/,somnet,1539605544,[removed],0,1,False,self,,,,,
779,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,21,9oc4er,/r/MachineLearning/comments/9oc4er/microsoft_ai_great_job_by_anil_kumble/,Microsoft AI :) Great job by Anil Kumble ... :) #machinelearning hashtag#artificialintelligence,https://www.reddit.com/r/MachineLearning/comments/9oc4er/microsoft_ai_great_job_by_anil_kumble/,myinnos,1539605595,,0,1,False,https://b.thumbs.redditmedia.com/4a6TtC7v3lYQYcaLw1epKGlNYogOFvx7_ZZtIVFEuSc.jpg,,,,,
780,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,21,9oc6d9,medium.com,Why everybody is switching to the Blockchain Technology ?,https://www.reddit.com/r/MachineLearning/comments/9oc6d9/why_everybody_is_switching_to_the_blockchain/,zerohalo,1539606076,,2,1,False,https://b.thumbs.redditmedia.com/ERjFOqoMwea92f4kcrl84bFucgILttPej5ym44_BRwk.jpg,,,,,
781,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,21,9ocd29,self.MachineLearning,"Why is ""neural style transfer"" faster on Prisma app compared to deeplearning.ai CNN assignment on Jupyter notebook?",https://www.reddit.com/r/MachineLearning/comments/9ocd29/why_is_neural_style_transfer_faster_on_prisma_app/,F1lover143,1539607674,[removed],0,1,False,self,,,,,
782,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,22,9ocii4,github.com,GitHub -List-of-Machine-Learning-And-Statistics-Repositories: Useful list of Machine Learning And Statistics Repositories,https://www.reddit.com/r/MachineLearning/comments/9ocii4/github/,myinnos,1539608901,,0,1,False,https://b.thumbs.redditmedia.com/ajcrwAgb7x55G9pLjE3b7-WEuC7Cmnl925r1-mCA6EU.jpg,,,,,
783,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,22,9ocovx,self.MachineLearning,[D] Understanding Neural Attention,https://www.reddit.com/r/MachineLearning/comments/9ocovx/d_understanding_neural_attention/,cryptopaws,1539610262,"I've been training a lot of encoder-decoder architectures with attention, There are a lot of types of attentions and this (article)\[[https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html)\] here makes a good attempt at summing them all up. Although i understand how it works, and having seen a lot of alignment maps and visual attention maps on images, I can't seem to wrap my head around why it works? Can someone explain this to me ?",16,1,False,self,,,,,
784,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,22,9ocqgg,self.MachineLearning,[D] What is the benefit of discriminator with lipschitz constant less than 1 in GAN?,https://www.reddit.com/r/MachineLearning/comments/9ocqgg/d_what_is_the_benefit_of_discriminator_with/,the-fire-fist,1539610601,"The purpose of spectral normalization is to make lipschitz constant less than 1. 

&amp;#x200B;

According to WGAN, the reason why this lipschitz constant constraint is necessary is that the discriminator should have lipschitz constant less than 1 for the approximation of wasserstein distance which is intractable function.

&amp;#x200B;

However, spectral normalization is not using wasserstein distance.

&amp;#x200B;

Anybody knows what the benefit of discriminator with lipschitz constant less than 1 is in case of NOT using wasserstein distance?",5,1,False,self,,,,,
785,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,23,9oczh8,self.MachineLearning,Is Anyone here worked on Action recognition in video?,https://www.reddit.com/r/MachineLearning/comments/9oczh8/is_anyone_here_worked_on_action_recognition_in/,elonmuskX,1539612498,[removed],0,1,False,self,,,,,
786,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,23,9od3dy,self.MachineLearning,Fast Object Detection with Fast R-CNN,https://www.reddit.com/r/MachineLearning/comments/9od3dy/fast_object_detection_with_fast_rcnn/,ElegantFeeling,1539613278,[removed],0,1,False,self,,,,,
787,MachineLearning,t5_2r3gv,2018-10-15,2018,10,15,23,9odedz,self.MachineLearning,RL: Actor-Critic vs Model-based,https://www.reddit.com/r/MachineLearning/comments/9odedz/rl_actorcritic_vs_modelbased/,lepton99,1539615427,[removed],0,1,False,self,,,,,
788,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,0,9odgs6,self.MachineLearning,Create machine learning models without coding,https://www.reddit.com/r/MachineLearning/comments/9odgs6/create_machine_learning_models_without_coding/,SarvasvKulpati,1539615870,[removed],0,1,False,self,,,,,
789,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,0,9odkez,self.MachineLearning,Self-driving on reinforcement-learning optimises to minimum reward,https://www.reddit.com/r/MachineLearning/comments/9odkez/selfdriving_on_reinforcementlearning_optimises_to/,BadFeelz,1539616560,[removed],0,1,False,self,,,,,
790,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,0,9odtr0,self.MachineLearning,Need help on uploading images on google cloud platform or google colaboratory,https://www.reddit.com/r/MachineLearning/comments/9odtr0/need_help_on_uploading_images_on_google_cloud/,wellbehavedguy,1539618314,[removed],0,1,False,self,,,,,
791,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,2,9oenxz,youtube.com,Dileep George (Numenta/Vicarious) on the BrainInspired podcast,https://www.reddit.com/r/MachineLearning/comments/9oenxz/dileep_george_numentavicarious_on_the/,corticonaut,1539623779,,0,1,False,default,,,,,
792,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,2,9oevwp,self.MachineLearning,[Discussion] Jointly training a deep convolutional network that feeds to a recurrent one,https://www.reddit.com/r/MachineLearning/comments/9oevwp/discussion_jointly_training_a_deep_convolutional/,Mondestrasz,1539625159,"So I've seen something along those lines happen in a lot of works. In my case it has to do with video datasets but maybe there are other cases as well. In the past, when I was training a recurrent network I noticed some particularities, specifically regarding backprop through time. So what I had to do at the time using PyTorch was retain the computational graph up until the end of a certain clip size and then release it:

&amp;#x200B;

if idx == (clip.size()\[0\]-1):

loss.backward()

else:

loss.backward(retain\_graph=True)

&amp;#x200B;

So now I want to feed a deep representation from VGG to the LSTM and I want to train the two simultaneously. I expect that retaining the graph will be a huge load for memory. What is the best way to jointly train the two? ",3,1,False,self,,,,,
793,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,3,9of3b7,youtu.be,"Road scene segmentation in 4K with Unet in keras, how do i improve these results",https://www.reddit.com/r/MachineLearning/comments/9of3b7/road_scene_segmentation_in_4k_with_unet_in_keras/,sriharihumbarwadi,1539626484,,0,1,False,https://a.thumbs.redditmedia.com/O6ewUu9Wz8OOkWV_YRs-AouCQbq81SgLAVe6QYibu88.jpg,,,,,
794,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,3,9ofbuw,medium.com,Ray  A cluster computing ML framework for emerging applications,https://www.reddit.com/r/MachineLearning/comments/9ofbuw/ray_a_cluster_computing_ml_framework_for_emerging/,coinmonks,1539628013,,0,1,False,https://b.thumbs.redditmedia.com/Umx6XxOFE4O_nCjraIi91f1lhpEfiZKEPFPRfMLxAMU.jpg,,,,,
795,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,3,9ofcvw,nytimes.com,"M.I.T. Plans College for Artificial Intelligence, Backed by $1B",https://www.reddit.com/r/MachineLearning/comments/9ofcvw/mit_plans_college_for_artificial_intelligence/,j_orshman,1539628199,,0,1,False,default,,,,,
796,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,3,9ofd7x,self.MachineLearning,[D] Machine Learning on Time Series Data?,https://www.reddit.com/r/MachineLearning/comments/9ofd7x/d_machine_learning_on_time_series_data/,Fender6969,1539628261,"I am going to be working with building models with time series data, which is something that I have not done in the past. Is there a different approach to the building models with time series data? Anything that I should be doing differently? Things to avoid etc? Apologies if this is a dumb question, I am new to this. ",104,1,False,self,,,,,
797,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,3,9ofi6r,self.MachineLearning,Is there any open access database for speech recognition? something like TI46 or TIDIGITS?,https://www.reddit.com/r/MachineLearning/comments/9ofi6r/is_there_any_open_access_database_for_speech/,xy26,1539629182,"I need at least two words, each repeated 25+ times by 15+ different individuals. ",0,1,False,self,,,,,
798,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,3,9ofj5o,self.MachineLearning,How can I classify these aerial images?,https://www.reddit.com/r/MachineLearning/comments/9ofj5o/how_can_i_classify_these_aerial_images/,thiswillsuffice,1539629347,[removed],0,1,False,self,,,,,
799,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,3,9ofku3,self.MachineLearning,GAN Best Practices,https://www.reddit.com/r/MachineLearning/comments/9ofku3/gan_best_practices/,kylepob,1539629640,[removed],0,1,False,self,,,,,
800,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,3,9oflr8,self.MachineLearning,Connection with Social Sciences?,https://www.reddit.com/r/MachineLearning/comments/9oflr8/connection_with_social_sciences/,mopamop,1539629808,Is machine learning connected with knowledge from the social sciences or is it mainly just coding?,0,1,False,self,,,,,
801,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,4,9ofy23,self.MachineLearning,"Vectorization, cost function, gradient descent",https://www.reddit.com/r/MachineLearning/comments/9ofy23/vectorization_cost_function_gradient_descent/,Tshadowburn,1539631941,"  

Hi, guys, this is quit the beginner question, but I just started to learn machine learning and I find it difficult to understand the vectorized implementation to optimize machine learning algorithms, I get that it involve to use matrix calculus instead of loops to speed up the code, but I can seem to grasp the way of thinking in order to do it, Ill be very thankful if someone manage to explain me how to implement the cost and the gradient descent of a linear regression ( univariate), So I can get the intuition of vectorization .

Thank you .",0,1,False,self,,,,,
802,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,4,9ofydj,google.co.uk,Tesla deploys massive new Autopilot neural net in v9,https://www.reddit.com/r/MachineLearning/comments/9ofydj/tesla_deploys_massive_new_autopilot_neural_net_in/,TetsVR,1539632001,,0,1,False,default,,,,,
803,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,4,9og1lo,self.MachineLearning,Publicly available datasets for forecasting demand for pharmaceutical drugs.,https://www.reddit.com/r/MachineLearning/comments/9og1lo/publicly_available_datasets_for_forecasting/,avatar_aangkora,1539632582,[removed],0,1,False,self,,,,,
804,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,4,9og48l,wacoin.io,WABI a very cutting edge crypto with AI Supply chain and Internet of things all rolled into one. Massive Upside avail on Binance,https://www.reddit.com/r/MachineLearning/comments/9og48l/wabi_a_very_cutting_edge_crypto_with_ai_supply/,yogibearnxs,1539633048,,1,1,False,default,,,,,
805,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,5,9oghy3,self.MachineLearning,[D] Automation of training,https://www.reddit.com/r/MachineLearning/comments/9oghy3/d_automation_of_training/,ylankgz,1539635441,"I have to retrain model on a monthly updating dataset and update the whole infrastructure to use the new model. Typically, we are doing the same process constantly, which is obviously can be automated. I would like to know if anyone using CI/CD tools and devops in their ai applications. 
I was considering to build a sort of cli tool where one can trigger the process of training and then updating with just one command, when you update the dataset.",7,1,False,self,,,,,
806,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,6,9ogtkg,eventbrite.com,[N] MLconf - The Machine Learning Conference - 11/14 in San Francisco - 35% discount link,https://www.reddit.com/r/MachineLearning/comments/9ogtkg/n_mlconf_the_machine_learning_conference_1114_in/,shonburton,1539637501,,0,1,False,default,,,,,
807,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,6,9ogtlw,self.MachineLearning,[D] Correct way to formalize this (probabilistic) model?,https://www.reddit.com/r/MachineLearning/comments/9ogtlw/d_correct_way_to_formalize_this_probabilistic/,DesignerTaro,1539637509,"Bit of background: I'm an engineer and have had some basic stats training years ago. I work with some basic DL in my day to day (mostly helping out the infra side). I'm comfortably reading code and following along with high level stats but have run out of things to Google for my question. Onward to the actual question:

Let's say I want to predict or somehow describe the true ""rate"" for a particular user. I have a lot of users and a lot of features about the user. Some users have attempted to flip a coin once, some 50 times, some 150 times, etc. I want to build a model that uses the data about their flips as well as the exogenous regressors to predict the true rate (or better yet return the RV for their particular Bernoulli) of each user. I've read a few things on Hierarchical Partial Pooling (I was able to *mostly* follow along [here](http://mc-stan.org/rstanarm/articles/pooling.html)). 

This method seems very nice as it explicitly handles the problem of certain users having more or less data. For users with more data, we are confident their empirical rate is their true rate. For users with no data, the prior has more of a say. At the same time the global distribution of users has some shared understanding.

What I couldn't really find, however, is how I would go ahead and add other features to a model like this (user's age, gender, post count, articles read, etc).

I'd appreciate any help on how to correctly phrase or build a model like this. Python/tensorflow would be great just because that's what I'm used to but I won't turn down any help in R or other languages that are popular in this domain. Thanks!",5,1,False,self,,,,,
808,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,6,9ogwzt,self.MachineLearning,I have a bunch of local DMV reviews (open text) exported to excel. I need to find the common themes among them. Can someone with machine learning experience help?,https://www.reddit.com/r/MachineLearning/comments/9ogwzt/i_have_a_bunch_of_local_dmv_reviews_open_text/,UpgradeNotSure,1539638105,[removed],0,1,False,self,,,,,
809,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,6,9oh65j,self.MachineLearning,[D] Over 200 Machine Learning &amp; AI presentations with slides from MLconf,https://www.reddit.com/r/MachineLearning/comments/9oh65j/d_over_200_machine_learning_ai_presentations_with/,shonburton,1539639804,"We're about to finish our 6th year at MLconf! We have compiled over 200 videos from ML/AI presentations from all of our past conferences here:  


[https://www.youtube.com/channel/UCjeM1xxYb\_37bZfyparLS3Q](https://www.youtube.com/channel/UCjeM1xxYb_37bZfyparLS3Q)  


Our next event is in San Francisco on November 14th. Use discount code ""SlashML"" for a 35% discount  


What topics would you most like to see covered by MLconf next year?",5,1,False,self,,,,,
810,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,6,9oh817,agilityexchange.com,"The breakdown of the latest AI study ""Elephant in the Room"" A drill down into the reasons, why a recently published study in AI Elephant in the Room creating so much interest and noise",https://www.reddit.com/r/MachineLearning/comments/9oh817/the_breakdown_of_the_latest_ai_study_elephant_in/,shailendramalik,1539640163,,0,1,False,default,,,,,
811,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,6,9ohaqk,self.MachineLearning,Looking for a demo of online learning that Ive seen in the past,https://www.reddit.com/r/MachineLearning/comments/9ohaqk/looking_for_a_demo_of_online_learning_that_ive/,omniron,1539640704,"the demo had clustered images of vehicles, and you would label the vehicles as facing either to the left or right, and once you labeled the image, the cluster would readjust in real time based on your label.

The you could keep refining the clusters and it would become more accurate

Anyone know what Im talking about?",0,1,False,self,,,,,
812,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,7,9ohgq7,self.MachineLearning,[D] try to find a demo of semi-supervised learning Ive seen in the past,https://www.reddit.com/r/MachineLearning/comments/9ohgq7/d_try_to_find_a_demo_of_semisupervised_learning/,omniron,1539641790,"the demo had clustered images of vehicles, and you would label the vehicles as facing either to the left or right, and once you labeled the image, the cluster would readjust in real time based on your label.

The you could keep refining the clusters and it would become more accurate

Anyone know what Im talking about?",2,1,False,self,,,,,
813,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,7,9ohied,self.MachineLearning,What are some of the biggest limitations of CycleGAN today?,https://www.reddit.com/r/MachineLearning/comments/9ohied/what_are_some_of_the_biggest_limitations_of/,mrconter1,1539642115,,0,1,False,self,,,,,
814,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,9,9oifh0,self.MachineLearning,An ML Framework,https://www.reddit.com/r/MachineLearning/comments/9oifh0/an_ml_framework/,andrea_manero,1539648920,r/https://www.datasciencecentral.com/profiles/blogs/an-ml-framework,0,1,False,self,,,,,
815,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,10,9oivh5,teslamotorsclub.com,[D] A high level description of Tesla's model for autonomous driving,https://www.reddit.com/r/MachineLearning/comments/9oivh5/d_a_high_level_description_of_teslas_model_for/,Zinan,1539652366,,0,1,False,https://b.thumbs.redditmedia.com/vD81yu-XYUUMdUJ2yxyK7Z1UNzZJpxkybDbV456k94g.jpg,,,,,
816,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,10,9oizvd,self.MachineLearning,[Project] Result visualization tool,https://www.reddit.com/r/MachineLearning/comments/9oizvd/project_result_visualization_tool/,ellie6939,1539653323,"Is there a result visualization tool that I can use for different use cases -&gt; image understanding, NLP or recommendation?",1,1,False,self,,,,,
817,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,12,9ojudn,self.MachineLearning,[P] Question: Text - Category matching on 9.6M of medical records training data,https://www.reddit.com/r/MachineLearning/comments/9ojudn/p_question_text_category_matching_on_96m_of/,kvha,1539660100,"Hey guys, 

**The Why:** Most people are not healthcare expert, when you're sick, the last thing you want to do is to spend hours of researching to see what kind of doctor is the most appropriate for you

**End goal:** ML model to recommend the appropriate doctor/specialist depend on the patient symptom (Ex: ""I have acne"" -&gt; Dermatologist)

**Data description**: 9.6M claim level records with procedure description, physician name, physician specialty (primary care, cardiologist, etc) 

**The problem I am trying to solve:** procedure description is already matched with the specialty (Ex: Internal medicine has 3000 procedures), I need to build a ML model that not only understand but can also expand the definition of procedure to also include layman language synonyms. 

&amp;#x200B;

I am thinking of using Tensorflow, but I wonder if this would be an appropriate platform for this project, and if so any of you have an idea of how I should proceed?",11,1,False,self,,,,,
818,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,12,9ojz2t,technologyreview.com,Here it is... MIT has just announced a $1 billion plan to create a new college for AI,https://www.reddit.com/r/MachineLearning/comments/9ojz2t/here_it_is_mit_has_just_announced_a_1_billion/,Promontory_Tech,1539661226,,0,1,False,default,,,,,
819,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,14,9okjym,self.MachineLearning,I am in need of a teammate for a Kaggle Competition,https://www.reddit.com/r/MachineLearning/comments/9okjym/i_am_in_need_of_a_teammate_for_a_kaggle/,mikeynoonja,1539666513,[removed],0,1,False,self,,,,,
820,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,14,9oknk1,self.MachineLearning,[P] I am in need of a teammate for a Kaggle Competition,https://www.reddit.com/r/MachineLearning/comments/9oknk1/p_i_am_in_need_of_a_teammate_for_a_kaggle/,mikeynoonja,1539667550,"Hello everyone, I am just trying to find a teammate for a Kaggle Competition that I would like to try out. I have some understanding in the process of making a model, if anyone is interested send me a DM.

The competition is: [https://www.kaggle.com/c/human-protein-atlas-image-classification/team](https://www.kaggle.com/c/human-protein-atlas-image-classification/team)",4,1,False,self,,,,,
821,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,14,9oktrv,self.MachineLearning,[D] Googles CEO Says Tests of Censored Chinese Search Engine Turned Out Great,https://www.reddit.com/r/MachineLearning/comments/9oktrv/d_googles_ceo_says_tests_of_censored_chinese/,wei_jok,1539669329,"An article on [Wired](https://www.wired.com/story/wired-25-sundar-pichai-china-censored-search-engine/) about Google's reentry into the Chinese market, and also reasons for backing out from military projects. Not directly related to ML, but I felt there are some interesting quotes about their views on AI (where they have written a set of principles) and self-regulation:

*While onstage at the event, Pichai did not back away from Googles controversial decision to build a censored search engine in China. In fact, he doubled down on the search engine, codenamed Project Dragonfly, saying the potential to expose the world to more information is guiding Googles push into China.*

...

*Nonetheless, Pichai said employee feedback wasnt the main reason for backing away from Maven or JEDI.*

*Throughout Google's history, we've given our employees a lot of voice and say, said Pichai. But we don't we don't run the company by holding referendums. It's an important input. We take it seriously. On the issue of Maven, however, it's more also the debate within the AI Community around how you perceive our work in this area, Pichai explained.*

*Besides, Googles work with the military is far from over. Pichai said theyre going to continue to work on a set of projects in cyber-security, transportation, logistics, and areas where Google is uniquely qualified. The only area where Google has is being more deliberate is the way AI gets used with autonomous weaponry.*

**Pichai compared it to advances in biology. When you're so early with a powerful technology, he said, sometimes you have to self-regulate.**



https://www.wired.com/story/wired-25-sundar-pichai-china-censored-search-engine/
",137,1,False,self,,,,,
822,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,14,9okudz,self.MachineLearning,Projects ideas supervised machine learning,https://www.reddit.com/r/MachineLearning/comments/9okudz/projects_ideas_supervised_machine_learning/,avatar_aangkora,1539669513,[removed],0,1,False,self,,,,,
823,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,15,9okvom,self.MachineLearning,Face recognition application using a deep learning model (Python and Keras),https://www.reddit.com/r/MachineLearning/comments/9okvom/face_recognition_application_using_a_deep/,sumantrajoshi,1539669875,[removed],0,1,False,self,,,,,
824,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,15,9ol1fb,self.MachineLearning,[R] Piano Genie: An Intelligent Musical Interface,https://www.reddit.com/r/MachineLearning/comments/9ol1fb/r_piano_genie_an_intelligent_musical_interface/,inarrears,1539671551,"Recent project from Google Brain / DeepMind:

blog post: https://magenta.tensorflow.org/pianogenie

arxiv paper: https://arxiv.org/abs/1810.05246

youtube demonstration video: https://youtu.be/YRb0XAnUpIk

*Piano Genie is in some ways reminiscent of video games such as [Rock Band](https://en.wikipedia.org/wiki/Rock_Band_(video_game)) and [Guitar Hero](https://en.wikipedia.org/wiki/Guitar_Hero) that are accessible to novice musicians, with the crucial difference that users can freely improvise on Piano Genie rather than re-enacting songs from a fixed repertoire. You can try it out yourself via our [interactive web demo](https://tensorflow.github.io/magenta-demos/piano-genie/)!*

I tried their demo on Chrome in desktop mode: https://tensorflow.github.io/magenta-demos/piano-genie/

",38,1,False,self,,,,,
825,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,15,9ol1wv,self.MachineLearning,what is weakly supervised learning with convolution neural network?,https://www.reddit.com/r/MachineLearning/comments/9ol1wv/what_is_weakly_supervised_learning_with/,Midhilesh29,1539671682,[removed],0,1,False,self,,,,,
826,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,15,9ol3c5,self.MachineLearning,Blockchain workshop mumbai,https://www.reddit.com/r/MachineLearning/comments/9ol3c5/blockchain_workshop_mumbai/,NearLearnguru,1539672103," [\#ai](https://plus.google.com/u/0/s/%23ai/posts) [\#blockchain](https://plus.google.com/u/0/s/%23blockchain/posts) [\#machinelearning](https://plus.google.com/u/0/s/%23machinelearning/posts) [\#training](https://plus.google.com/u/0/s/%23training/posts) [\#artificialintelligence](https://plus.google.com/u/0/s/%23artificialintelligence/posts) [\#python](https://plus.google.com/u/0/s/%23python/posts) [\#mi](https://plus.google.com/u/0/s/%23mi/posts) [\#classroomtraining](https://plus.google.com/u/0/s/%23classroomtraining/posts) [\#ais](https://plus.google.com/u/0/s/%23ais/posts)  
[https://nearlearn.com/in/blockchain-workshop-mumbai](https://nearlearn.com/in/blockchain-workshop-mumbai) ",0,1,False,self,,,,,
827,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,16,9olctp,self.learnmachinelearning,[Discussion] How do you manage your research projects?,https://www.reddit.com/r/MachineLearning/comments/9olctp/discussion_how_do_you_manage_your_research/,onkelFungus,1539674930,,0,1,False,default,,,,,
828,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,17,9olkhy,arxiv.org,[R] Towards Understanding Linear Word Analogies,https://www.reddit.com/r/MachineLearning/comments/9olkhy/r_towards_understanding_linear_word_analogies/,serveboy,1539677348,,1,1,False,default,,,,,
829,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,17,9ollze,self.MachineLearning,Aternatives to FBProphet for timeseries forecasting,https://www.reddit.com/r/MachineLearning/comments/9ollze/aternatives_to_fbprophet_for_timeseries/,einenchat,1539677824,[removed],0,1,False,self,,,,,
830,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,17,9olo5l,self.MachineLearning,"[D] Training Neural Nets on Larger Batches: Practical Tips for 1-GPU, Multi-GPU &amp; Distributed setups",https://www.reddit.com/r/MachineLearning/comments/9olo5l/d_training_neural_nets_on_larger_batches/,Thomjazz,1539678519,"With the current trend toward bigger models (like OpenAI's GPT or BERT in NLP), it is often difficult to fit more than a handful of samples/GPU.

But stochastic gradient descent algorithms often require more than few samples/batch to get decent results.

I've gathered in a post practical tools and tips I've been using to train such large model with reasonable batch sizes (from simple tricks like gradient accumulation to efficient multi-GPU code &amp; distributed setups):

[https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255](https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255)

I would be happy to hear your thoughts and whether you know and use other technics.",12,1,False,self,,,,,
831,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,17,9olqto,hackernoon.com,How Cortex brings AI on the Blockchain  Hacker Noon,https://www.reddit.com/r/MachineLearning/comments/9olqto/how_cortex_brings_ai_on_the_blockchain_hacker_noon/,srumble11,1539679381,,0,1,False,https://a.thumbs.redditmedia.com/KTUhxBZoNntUE2l9ldJkibjUvdY2VarsT8naFGXMcp4.jpg,,,,,
832,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,18,9oluun,medium.com,Medical Imaging Analysis using PyTorch,https://www.reddit.com/r/MachineLearning/comments/9oluun/medical_imaging_analysis_using_pytorch/,omarsar,1539680636,,0,1,False,default,,,,,
833,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,18,9olxmp,self.MachineLearning,Image Recognition AI Survey Questions,https://www.reddit.com/r/MachineLearning/comments/9olxmp/image_recognition_ai_survey_questions/,LivyMcKaine,1539681476,[removed],0,1,False,self,,,,,
834,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,18,9om1j9,self.AskProgramming,"How to compare GLM, Random Forest and Nerual Network prediction on the same data set?",https://www.reddit.com/r/MachineLearning/comments/9om1j9/how_to_compare_glm_random_forest_and_nerual/,devdibyo,1539682640,,0,1,False,https://b.thumbs.redditmedia.com/F6sx3CE4MShHP2db45xj3GY_VBdElFy4RzYL_QrXHPY.jpg,,,,,
835,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,19,9om84e,self.MachineLearning,[D] Time based sequence prediction / sequence classification,https://www.reddit.com/r/MachineLearning/comments/9om84e/d_time_based_sequence_prediction_sequence/,harry_0_0_7,1539684533,"I am new to sequence prediction/classification.. 


Its possible to do ""Time series"" and ""sequence classification"" separately but how to combine both.?

Like predicting next event with its time",8,1,False,self,,,,,
836,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,19,9omhyx,self.MachineLearning,Text to Video Generation,https://www.reddit.com/r/MachineLearning/comments/9omhyx/text_to_video_generation/,Tusharminj,1539687209,"I'm working on generating videos from captions(text). I want to know if there are any datasets (WITH CAPTIONS) for this project. If there are no captions, are they being generated? How are they being generated. Please help. 

&amp;#x200B;",0,1,False,self,,,,,
837,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,19,9omio0,smarten.com,What is the Chi Square Test of Association and How Can it be Used for Analysis?,https://www.reddit.com/r/MachineLearning/comments/9omio0/what_is_the_chi_square_test_of_association_and/,ElegantMicroWebIndia,1539687408,,0,1,False,default,,,,,
838,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,20,9omns7,self.MachineLearning,"[R] What are your thoughts on ""Focusing Neuron"" paper",https://www.reddit.com/r/MachineLearning/comments/9omns7/r_what_are_your_thoughts_on_focusing_neuron_paper/,fbtek,1539688683,"Hi,

I believe that our new paper titled ""[An Adaptive Locally Connected Neuron Model: Focusing Neuron](https://arxiv.org/abs/1809.09533)"" would be an interesting read for anyone who is working on artificial neural network architectures, partially connected networks, visual attention, network pruning/growing, and differentiable neuroplasticity. I would be very happy to read your comments as this could be the first opportunity hear any technical feedback. Thanks.

BTEK

&amp;#x200B;

[https://www.researchgate.net/publication/327882222\_An\_Adaptive\_Locally\_Connected\_Neuron\_Model\_Focusing\_Neuron](https://www.researchgate.net/publication/327882222_An_Adaptive_Locally_Connected_Neuron_Model_Focusing_Neuron)

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;",4,1,False,self,,,,,
839,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,20,9omo9p,self.MachineLearning,Early stopping - Why not always?,https://www.reddit.com/r/MachineLearning/comments/9omo9p/early_stopping_why_not_always/,baahalex,1539688801,[removed],0,1,False,self,,,,,
840,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,20,9omr67,self.MachineLearning,[Discussion] Early Stopping - Why not always?,https://www.reddit.com/r/MachineLearning/comments/9omr67/discussion_early_stopping_why_not_always/,baahalex,1539689532,"I was thinking recently that from all the deep-learning articles and papers I've read, early stopping gets mentioned quite rarely. Why is that?

Unless I'm missing something, I believe early-stopping should be the default behavior most of the times.  Even if you want to compare models, you don't necessarily need to train them for the same amount of epochs in order to make them comparable. Sometimes you can have a winning model after only a few epochs. Why waste time with a predefined n\_epochs value?

Am I missing any downsides to always using early stopping? I can't think of any and I've been wondering for a while.",22,1,False,self,,,,,
841,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,20,9omtgf,self.tensorflow,Where can I find learning resources just for understanding Tensorflow?,https://www.reddit.com/r/MachineLearning/comments/9omtgf/where_can_i_find_learning_resources_just_for/,sedgecrooked,1539690105,,0,1,False,default,,,,,
842,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,20,9omucq,smarten.com,What is the Decision Tree Analysis and How Does it Help a Business to Analyze Data?,https://www.reddit.com/r/MachineLearning/comments/9omucq/what_is_the_decision_tree_analysis_and_how_does/,ElegantMicroWebIndia,1539690330,,0,1,False,default,,,,,
843,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,21,9omyli,arxiv.org,Person-Job Fit: Adapting the Right Talent for the Right Job with Joint Representation Learning,https://www.reddit.com/r/MachineLearning/comments/9omyli/personjob_fit_adapting_the_right_talent_for_the/,moombai,1539691337,,0,1,False,default,,,,,
844,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,21,9on19m,arxiv.org,[R] Person-Job Fit: Adapting the Right Talent for the Right Job with Joint Representation Learning,https://www.reddit.com/r/MachineLearning/comments/9on19m/r_personjob_fit_adapting_the_right_talent_for_the/,moombai,1539691936,,2,1,False,default,,,,,
845,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,21,9on1vs,self.MachineLearning,[D] Seq2Seq learning when the typical length of the input and output sequences differ a lot,https://www.reddit.com/r/MachineLearning/comments/9on1vs/d_seq2seq_learning_when_the_typical_length_of_the/,mln000b,1539692075,"I am facing a seq2seq problem where the input sequence has a mean length of 6k items while the output sequence has a mean length of 7 items.

&amp;#x200B;

I have tried typical seq2seq models like ""LSTM with attention"" and ""convolutional seq2seq"" models (Thanks to [github.com/pytorch/fairseq](https://github.com/pytorch/fairseq)), but they don't really work for my dataset.

&amp;#x200B;

What do you think I have to do? Can you suggest some research papers where people solve similar problems?",11,1,False,self,,,,,
846,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,21,9on3lc,smarten.com,What is Outlier Analysis and How Can It Improve Analysis?,https://www.reddit.com/r/MachineLearning/comments/9on3lc/what_is_outlier_analysis_and_how_can_it_improve/,ElegantMicroWebIndia,1539692483,,0,1,False,default,,,,,
847,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,21,9on5u3,self.MachineLearning,Very basic ML doubt.,https://www.reddit.com/r/MachineLearning/comments/9on5u3/very_basic_ml_doubt/,gireeshwaran,1539693009,[removed],0,1,False,self,,,,,
848,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,21,9on9ns,self.MachineLearning,[D] Evolution Strategies on Jump and Run,https://www.reddit.com/r/MachineLearning/comments/9on9ns/d_evolution_strategies_on_jump_and_run/,CrazyKing11,1539693866,"Hello guys i am trying to use the Evolution Strategies described by OpenAi [here](https://blog.openai.com/evolution-strategies/) to ""solve"" a Jump and Run.

The problem i am having is, that if i only use the x position of my character as my fitness, then almost all of my population die at the same position and the progress stops.

Does anyone have an idea how to solve this issues in these game types?",6,1,False,self,,,,,
849,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,21,9onc9s,self.MachineLearning,"[P] 73% Faster, 60% less RAM Sparse Pairwise Euclidean/L2 Distances",https://www.reddit.com/r/MachineLearning/comments/9onc9s/p_73_faster_60_less_ram_sparse_pairwise/,danielhanchen,1539694441,"Just wanted to report that HyperLearn's ongoing development is great!

I just updated it today, and wanted to report that HyperLearn's L2 pairwise distances on itself dist(X, X) is now 29% faster on Dense Matrices, and 73% faster on Sparse Matrices!!! \[n = 10,000 | p = 1,000\] when compared to Sklearn's Pairwise Distances and Euclidean Distance modules. 60% less Memory usage is seen.

Also, I tested on \[n = 20,000 | p = 1,000\]. Sadly, Sklearn got a Memory Error, whilst HyperLearn still succeeded!

[https://github.com/danielhanchen/hyperlearn](https://github.com/danielhanchen/hyperlearn)

|n\_jobs|HyperLearn Sparse|HyperLearn Dense|Sklearn Sparse|Sklearn Dense|
|:-|:-|:-|:-|:-|
|1|19.9 s|1.49 s|43.2 s|2.08 s|
|\-1|11.5 s|1.57 s|\---|5.8 s|

I'll wrap it up into modules, but I am planning to rewrite TSNE most likely next, as it uses Nearest Neighbors on itself (dist(X,X))

Maybe you missed it, but NNMF (Non negative Matrix Factorisation) is also approx 50% faster in HyperLearn! Code also pushed. Note I'll make them into modules later.

Likewise, if anyone wants to contrib, email me @ [danielhanchen@gmail.com](mailto:danielhanchen@gmail.com) or message me!",49,1,False,self,,,,,
850,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,22,9onegg,smarten.com,What is SVM Classification Analysis and How Can It Benefit Business Analytics?,https://www.reddit.com/r/MachineLearning/comments/9onegg/what_is_svm_classification_analysis_and_how_can/,ElegantMicroWebIndia,1539694902,,0,1,False,default,,,,,
851,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,22,9onjsv,self.MachineLearning,Creating a simulation with real world sensor data,https://www.reddit.com/r/MachineLearning/comments/9onjsv/creating_a_simulation_with_real_world_sensor_data/,H3t0N,1539696009,"Heay com,

&amp;#x200B;

i was thinking about somehint. I will join an electric/driverless racingcar team at my university. 

The car has a ton of sensors and they are always recording while driving. 

&amp;#x200B;

Is it possible to make a good car behavior simulation with these datas? 

&amp;#x200B;

I think this should be possible. What do you guys think? ",0,1,False,self,,,,,
852,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,22,9onmfv,smarten.com,What is Hierarchical Clustering and How Can an Organization Use it to Analyze Data?,https://www.reddit.com/r/MachineLearning/comments/9onmfv/what_is_hierarchical_clustering_and_how_can_an/,ElegantMicroWebIndia,1539696558,,0,1,False,default,,,,,
853,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,22,9onng6,medium.com,Importance of feedback in ML models and in real life,https://www.reddit.com/r/MachineLearning/comments/9onng6/importance_of_feedback_in_ml_models_and_in_real/,charan_1996,1539696767,,0,1,False,https://b.thumbs.redditmedia.com/FEQZ6tOkZonyTSRMvJ991cxv-EMYcxGnNIgKoSgEaNs.jpg,,,,,
854,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,22,9onrbq,self.MachineLearning,[Discussion] Predict the previous word in a sequence,https://www.reddit.com/r/MachineLearning/comments/9onrbq/discussion_predict_the_previous_word_in_a_sequence/,CSGOvelocity,1539697577,"All NLP models I have seen so far predict the next word that comes in a sequence.

Is there a model or a way to predict the word that comes before or in the middle of the sequence ?  
Please take into consideration the fact that if we are trying to predict something in the middle then the whole sentence comes into the picture not just the words that come before the ""BLANK"".

Eg. Bruno is a \_\_\_\_ dog

Bruno is a good dog.

\_\_\_\_ is a fruit.

Apple is a fruit.  
",13,1,False,self,,,,,
855,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,22,9ont7g,blog.sicara.com,[D] The Best of AI: New Articles Published This Month (September 2018),https://www.reddit.com/r/MachineLearning/comments/9ont7g/d_the_best_of_ai_new_articles_published_this/,dan_ringwald,1539697960,,0,1,False,https://a.thumbs.redditmedia.com/lmh8p493gIicSvKeGepNIP5EjoCyumP8l3NWFz-ujm4.jpg,,,,,
856,MachineLearning,t5_2r3gv,2018-10-16,2018,10,16,23,9oo3br,towardsdatascience.com,Machine Learning Trends from World Summit AI Amsterdam,https://www.reddit.com/r/MachineLearning/comments/9oo3br/machine_learning_trends_from_world_summit_ai/,MLpractitioner,1539699941,,0,1,False,default,,,,,
857,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,0,9oofzv,towardsdatascience.com,[P] Article: Curiosity-Driven Learning made easy Part I [Deep Reinforcement Learning course],https://www.reddit.com/r/MachineLearning/comments/9oofzv/p_article_curiositydriven_learning_made_easy_part/,cranthir_,1539702299,,0,1,False,default,,,,,
858,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,0,9oom5q,i.redd.it,"Books for Machine Learning, Deep Learning and AI",https://www.reddit.com/r/MachineLearning/comments/9oom5q/books_for_machine_learning_deep_learning_and_ai/,Eng28,1539703415,,0,1,False,https://b.thumbs.redditmedia.com/6Deq3C6RisWoZ_OEwl9PVjgRFa6rzBmhfa0z9eWSTtA.jpg,,,,,
859,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,0,9ooswj,self.MachineLearning,[P] Article: Curiosity-Driven Learning made easy Part I [Deep Reinforcement Learning course],https://www.reddit.com/r/MachineLearning/comments/9ooswj/p_article_curiositydriven_learning_made_easy_part/,cranthir_,1539704627,"Hey there!

I published the 7th article of the Deep Reinforcement Learning series, about the most promising innovation in Deep Reinforcement Learning : Curiosity Driven Learning.

THE ARTICLE: [https://towardsdatascience.com/curiosity-driven-learning-made-easy-part-i-d3e5a2263359](https://towardsdatascience.com/curiosity-driven-learning-made-easy-part-i-d3e5a2263359)

For those who don't know what is Curiosity Driven Learning, the idea is to build a reward function that is generated by the agent itself .

It means that the agent **will be a self-learner since he will be the student but also the feedback master.** That's just awesome.

Let me say what you think!

&amp;#x200B;

&amp;#x200B;",4,1,False,self,,,,,
860,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,0,9oowjm,ieeexplore.ieee.org,HDLTex: Hierarchical Deep Learning for Text Classification,https://www.reddit.com/r/MachineLearning/comments/9oowjm/hdltex_hierarchical_deep_learning_for_text/,kk7nc,1539705270,,0,1,False,default,,,,,
861,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,0,9oowt9,dl.acm.org,RMDL: Random Multimodel Deep Learning for Classification,https://www.reddit.com/r/MachineLearning/comments/9oowt9/rmdl_random_multimodel_deep_learning_for/,kk7nc,1539705321,,0,1,False,default,,,,,
862,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,1,9opezi,medium.com,[N] Best NLP Model Ever? Google BERT Sets New Standards in 11 Language Tasks,https://www.reddit.com/r/MachineLearning/comments/9opezi/n_best_nlp_model_ever_google_bert_sets_new/,gwen0927,1539708512,,0,1,False,https://b.thumbs.redditmedia.com/9eRXCyTbdEiEerzh3PJF9f5J5RhwGFQs9bshOHqMnsY.jpg,,,,,
863,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,2,9opkub,self.MachineLearning,[D] High-dimensional classification of isotropic Gaussian categories,https://www.reddit.com/r/MachineLearning/comments/9opkub/d_highdimensional_classification_of_isotropic/,anonDogeLover,1539709550,"I'm trying to figure out if data from two isotropic Gaussian toy classes are harder or easier to classify in higher dimensions. If the inter-class-center distance is held constant, does the likelihood ratio of the two classes change? I'm assuming we don't care too much about overfitting (since we can take many samples from the categories to train with) or computation time to compute means in higher d.",4,1,False,self,,,,,
864,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,2,9opl19,youtube.com,"""Can you estimate the computational complexity?"" [CVPR'18], have we come to a point where authors cannot/ have not prepared an answer to important questions?",https://www.reddit.com/r/MachineLearning/comments/9opl19/can_you_estimate_the_computational_complexity/,EveryDay-NormalGuy,1539709586,,0,1,False,https://b.thumbs.redditmedia.com/c2C3KafIQPelHvOZBfKTPFQdeQvjUqclGDiuM54_EQM.jpg,,,,,
865,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,2,9opmgr,self.MachineLearning,Cindicator Hybrid AI Prediction Intelligence for financial markets.,https://www.reddit.com/r/MachineLearning/comments/9opmgr/cindicator_hybrid_ai_prediction_intelligence_for/,yogibearnxs,1539709834,"[https://cindicator.com/ecosystem](https://cindicator.com/ecosystem)

&amp;#x200B;",0,1,False,self,,,,,
866,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,2,9opnke,determined.ai,Warm Starting for Efficient Deep Learning Resource Utilization,https://www.reddit.com/r/MachineLearning/comments/9opnke/warm_starting_for_efficient_deep_learning/,yoavz,1539710034,,0,1,False,default,,,,,
867,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,2,9opt39,self.MachineLearning,[D] Seq-to-set-of-seqs?,https://www.reddit.com/r/MachineLearning/comments/9opt39/d_seqtosetofseqs/,AnvaMiba,1539711016,"Let the input be a sequence and the output an unordered set of sequences.

During training, one could force a canonical order between the output sequences, reducing the task to seq-to-seq, but this seems to be over-constrained, since the model would be forced to learn the arbitrary ordering criterion in addition to the information that is relevant to the task.

Any idea of how to solve this? Is there any prior work?",8,1,False,self,,,,,
868,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,2,9opvh1,self.MachineLearning,Can anyone explain Dropout in a RNN?,https://www.reddit.com/r/MachineLearning/comments/9opvh1/can_anyone_explain_dropout_in_a_rnn/,ImaginaryAnon,1539711439,[removed],0,1,False,self,,,,,
869,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,2,9opw4p,openreview.net,[R] Just the error of fitting to a random convolutional network is a reward signal that can solve Montezuma's Revenge,https://www.reddit.com/r/MachineLearning/comments/9opw4p/r_just_the_error_of_fitting_to_a_random/,downtownslim,1539711554,,33,1,False,default,,,,,
870,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,2,9opych,self.MachineLearning,[D] Pachyderm is hiring an ML Evangelist and I thought some of you might be interested,https://www.reddit.com/r/MachineLearning/comments/9opych/d_pachyderm_is_hiring_an_ml_evangelist_and_i/,coolhand1,1539711955,"Hi folks, 

I'm a fellow /r/machinelearning community member and my company ([Pachyderm](http://www.pachyderm.io/)) is looking to hire a Machine Learning Evangelist to role to create original content focused around ML and go around presenting their work at different conferences. If anyone is interested in applying for the role, please feel free to PM me. 

More details about that role can be found here: https://gist.github.com/Nick-Harvey/41920227252f55c95910579c8386c702",0,1,False,self,,,,,
871,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,2,9oq1qw,self.MachineLearning,What are the challenges in using OCR for reading unevenly spaced characters?,https://www.reddit.com/r/MachineLearning/comments/9oq1qw/what_are_the_challenges_in_using_ocr_for_reading/,spectrumology,1539712562,[removed],0,1,False,self,,,,,
872,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,2,9oq2kn,self.MachineLearning,"Machine Learning Algorithms to Segment Keywords, Predict Performance, and Generate Automated Insights",https://www.reddit.com/r/MachineLearning/comments/9oq2kn/machine_learning_algorithms_to_segment_keywords/,LityxIQ,1539712712,[removed],0,1,False,self,,,,,
873,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,3,9oq649,self.MachineLearning,Understanding Machine Learning: How machines learn?,https://www.reddit.com/r/MachineLearning/comments/9oq649/understanding_machine_learning_how_machines_learn/,andrea_manero,1539713326,r/http://www.datasciencecentral.com/profiles/blogs/understanding-machine-learning-1-how-machines-learn,0,1,False,self,,,,,
874,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,3,9oq6i8,self.MachineLearning,[D] Resources on Marketing / Real Time Bidding,https://www.reddit.com/r/MachineLearning/comments/9oq6i8/d_resources_on_marketing_real_time_bidding/,xristos_forokolomvos,1539713402,"Hi reddit,  


I know this is a very Deep Learning / research focused community but I'd like to ask a small favour from my ML bros and sisters. I'm looking for directions with regards to ML applied in marketing. Are there any cornerstone papers (or even keywords) that you could share so I can make my quest for knowledge more efficient? What are some basics around advertising, personalisation and real-time ad bidding?",0,1,False,self,,,,,
875,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,3,9oq9hq,self.MachineLearning,Top 9 Machine Learning Applications in Real World,https://www.reddit.com/r/MachineLearning/comments/9oq9hq/top_9_machine_learning_applications_in_real_world/,andrea_manero,1539713933,[removed],0,1,False,self,,,,,
876,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,3,9oqkv1,youtube.com,[AIEditor Project] Neural Network Editor - Machine Learning - Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/9oqkv1/aieditor_project_neural_network_editor_machine/,DevTechRetopall,1539715927,,1,1,False,https://b.thumbs.redditmedia.com/Uf2XKQ0ZLA4SjFCJTZxCQFH7F3SpX4g6sxajFlk8jTQ.jpg,,,,,
877,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,4,9oqvlr,self.MachineLearning,What's the point of blind peer review when we're allowed to post our paper on Arxiv?,https://www.reddit.com/r/MachineLearning/comments/9oqvlr/whats_the_point_of_blind_peer_review_when_were/,AmazingWolverine3,1539717821,[removed],0,1,False,self,,,,,
878,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,5,9or7sb,i.redd.it,They are learning.,https://www.reddit.com/r/MachineLearning/comments/9or7sb/they_are_learning/,Virial23,1539720097,,0,1,False,https://b.thumbs.redditmedia.com/2-uCm8mYo3IrGqOG6SVwa4bSPYHBqGhfelXF8hxHEak.jpg,,,,,
879,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,5,9orgbu,self.MachineLearning,"[D] Deeplearning Workstation Options for Keras on Windows 10, in September 2018",https://www.reddit.com/r/MachineLearning/comments/9orgbu/d_deeplearning_workstation_options_for_keras_on/,AccurateFrosting,1539721650,"Hi all,

I combed through several posts on here regarding the topic of workstations for ML, from native Windows 10 to Linux subsystem setups and dual-booting with Ubuntu. 

I have a fairly powerful Windows gaming PC (GTX 1080ti and 8700), and would like to make use of my GPU for machine learning with Keras, as opposed to paying for cloud GPUs. According to Francois Chollet's book, as well as some posts on here dated from around the time of his book's publication (\~10 months ago), it seems like the most commonly suggested route would be to install some sort of Ubuntu partition and dual boot with Windows 10. 

As I am a little leery about complications that might result from this process (having to re-install Windows, restore from backup, etc.), I was wondering if, in the recent months, GPU-powered machine learning, specifically with Keras, has become a tenable option.

I'm using an RNN so I think GPU support would be preferable, even though I don't necessarily have a ton of data - about \~10-20mb of a .txt file.

Sorry if this question's answer is overly obvious. I'm a relative newcomer to this field. Any help or guidance would be much appreciated.",15,1,False,self,,,,,
880,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,6,9orvoy,self.MachineLearning,[P] TensorFlow Semantic Segmentation DataLoader.,https://www.reddit.com/r/MachineLearning/comments/9orvoy/p_tensorflow_semantic_segmentation_dataloader/,breaking_ciphers,1539724524,"I made a data loader based on the [tf.data](https://tf.data) API which works for semantic segmentation problems. Is also able to do random augmentations (brightness, contrast, saturation, random\_crop, flips).

You can find it \[here\]([https://github.com/HasnainRaz/Tensorflow-input-pipeline](https://github.com/HasnainRaz/Tensorflow-input-pipeline))

If you have any suggestions to improve the functionality or add more features, would love any feedback!",4,1,False,self,,,,,
881,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,7,9oshfc,manikvarma.org,[R] Machine Learning on 2KB of RAM,https://www.reddit.com/r/MachineLearning/comments/9oshfc/r_machine_learning_on_2kb_of_ram/,hrogo,1539728807,,0,1,False,default,,,,,
882,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,7,9osmde,arxiv.org,[1709.08267] HDLTex: Hierarchical Deep Learning for Text Classification,https://www.reddit.com/r/MachineLearning/comments/9osmde/170908267_hdltex_hierarchical_deep_learning_for/,kk7nc,1539729810,,0,1,False,default,,,,,
883,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,9,9otiig,self.MachineLearning,Is there something in Machine Learning like sampling theorem in DSP,https://www.reddit.com/r/MachineLearning/comments/9otiig/is_there_something_in_machine_learning_like/,limTeTE,1539736657,[removed],0,1,False,self,,,,,
884,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,10,9otoyy,self.MachineLearning,"[P] I trained a Variational Autoencoder on a bunch of images of myself to generate a cool profile pic. However, rather than taking a bunch of selfies, I 3D scanned myself and used renders instead",https://www.reddit.com/r/MachineLearning/comments/9otoyy/p_i_trained_a_variational_autoencoder_on_a_bunch/,Deinos_Mousike,1539738029,"Twitter thread with NN output here: https://twitter.com/_not_Ian_/status/1052352168819343360

So, I wanted to run images of my head through one of the VAEs I've been working on to generate weird images of myself, but as we all know, you usually need a lot of images to train, and I didn't want to lose a friend by asking them to take a bunch of images for me.

SOOOOO, what I did instead was:

1. 3D scanned my head. I got a friend to take a short video of me, and I ran it through photogrammetry software to create a 3D scan. Thankfully, we're still friends.

2. Cleaned up and imported said 3D scan into Blender. Now I can render as many images as I want.

3. Used a python script from another *sort-of-similar project* (more on this below) to automatically randomize N number of frames, so they all have various lighting, camera position, etc. Hopefully this gives the NN enough to work with to generate an interesting set of images.

NOW I have all the images I need, so I rendered 1,000+ images overnight, and have been training a neural network on it over the past ~24 hours.

Some things I'm looking at doing to improve results: Since I'm using a U-net based VAE with multiple latent spaces, currently some latent spaces are huge, thus needing huge L1 reg values. So, something might be wrong there - I'm going to experiment with smaller/bigger L1 reg values. **I'd appreciate any feedback on this part specifically**. Also, of course, rending more images with more varying parameters. 

-------

*As for the sort of similar project*: I wanted to train an image segmentation model on a chess board, but I didn't want to take thousands of photos of chess boards, label them all, etc. 

So instead, I imported a free chess set model from the internet into Blender and wrote a python script to randomize positions on the board, rotation, lighting, camera position, etc. Now I can render as many images as I want, all with various board states.

As this point I've only generated the input images, not the image masks. I haven't gotten around to actually doing it yet, but I thought of a solution to generate the corresponding masks:

Lets say you wanted to detect the 6 types of pieces (plus the background): pawn, rook, knight, queen, king, bishop. For every randomized chess board frame you generated, you'd want to render *an additional 7* frames of the board in the exact same position. 

For the first additional frame, you'd ""turn off"" (make black) everything instead of, say, the pawns' texture, which you would make all-white. For the next frame, you'd ""turn off"" the pawns' texture, and ""turn on"" another classes' texture. You could do something similar for every other class you'd want to detect: making everything in the image black instead of the current class which you would make all-white. Finally make everything black and the ""background"" white.

This way you'd have X number of output channels (one channel for each class) for a corresponding input image, thus being able to train the image segmentation model to detect each class.

------

Anyways, I hope this was of interest or taught someone something. I think once you consider what you can do in 3D software like Blender, it really opens up a lot of possibilities. 

Also, if this sort of thing was interesting to you, I post updates to other projects of mine on twitter: https://twitter.com/_not_Ian_
",8,1,False,self,,,,,
885,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,10,9otsra,self.MachineLearning,[D] Can humans estimate monocular depth - Depth with one eye closed,https://www.reddit.com/r/MachineLearning/comments/9otsra/d_can_humans_estimate_monocular_depth_depth_with/,WillingCucumber,1539738852,"Hi all,

On covering one of my eye, I am still able to get the depth of the objects.

I have heard that human vision works under the principle of Stereo Vision i.e parallax between two eyes.

Is it that for most of the objects surrounding me, my brain has learnt an estimate of the depth ?

Or are there any other clues or motion of a single eye which enables us to estimate the depth ?

&amp;#x200B;

Thanks !!",5,1,False,self,,,,,
886,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,11,9ouonw,self.MachineLearning,[D] Looking for literature on advanced ideas in NLP/NLU,https://www.reddit.com/r/MachineLearning/comments/9ouonw/d_looking_for_literature_on_advanced_ideas_in/,skevthedev,1539744740,"I am a graduate student studying deep learning and computer vision. I will start my research next year and I have always assumed I would pick a sub-field in computer vision, but recently in the United States the baseball playoffs started and one of the marketing campaigns is for google assistant, which got me thinking about NLP. I have never really been interested in NLP and have maybe used Siri once on my iPhone, but the commercials that google kept exposing me to got me thinking, and I started asking Siri some more thought provoking questions, like ""Who is/was the most superstitious Baseball Player?"", and ""Who is the most misunderstood athlete?"". Obviously the answers were lack luster, but I am very intrigued why that is... Although they are subjective questions with no absolute, correct answer, I think a decent answer could be achieved, like a list of some very superstitious players and why they are considered superstitious.

&amp;#x200B;

At first, I thought the missing key is mainly data. There is probably no data set that maps baseball players to there superstitious tendencies, and the only way to really get this information would be to comb over thousands and thousands of hours of game color commentary, player interviews, and any other media that might lend itself to being superstitious (a nearly impossible task). This automatically made me question, can we teach an algorithm what superstitious behavior even is? 

&amp;#x200B;

These questions have me very interested and I want to pursue them. Who is doing research in this type of field? How far have they come? Are these types of problems that we think we can be reasonably solved or make some progress in the near future, or are we simply missing too many pieces to the puzzle, right now? 

&amp;#x200B;

Thanks!",18,1,False,self,,,,,
887,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,13,9ov6pk,self.MachineLearning,[P] Article: Gensim Tutorial for NLP [New],https://www.reddit.com/r/MachineLearning/comments/9ov6pk/p_article_gensim_tutorial_for_nlp_new/,selva86,1539748913,"Hello guys, 

For a fantastic NLP package it is, Gensim is not receiving the attention it deserves. May be the native tutorials aren't as easy to grasp compared to other NLP packages. So I wrote a [gensim tutorial for beginners](https://www.machinelearningplus.com/nlp/gensim-tutorial/) who haven't been introduced. 

Thanks",7,1,False,self,,,,,
888,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,13,9ov89u,self.MachineLearning,The problem about image synthesis,https://www.reddit.com/r/MachineLearning/comments/9ov89u/the_problem_about_image_synthesis/,yetianyi,1539749264,[removed],0,1,False,self,,,,,
889,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,15,9ovymf,medium.com,Web application for creating labeled data sets,https://www.reddit.com/r/MachineLearning/comments/9ovymf/web_application_for_creating_labeled_data_sets/,premrajnarkhede,1539756110,,0,1,False,https://a.thumbs.redditmedia.com/9RvhyCtuFtACtx3nv5v8yM6DYPZI8SS7gPIQn9SWfL8.jpg,,,,,
890,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,15,9ow9ec,self.MachineLearning,best multiclass classification technique (small data set),https://www.reddit.com/r/MachineLearning/comments/9ow9ec/best_multiclass_classification_technique_small/,t_rex66,1539759187,[removed],0,1,False,self,,,,,
891,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,16,9owc65,self.MachineLearning,A discussion about doing computer vision in big companies,https://www.reddit.com/r/MachineLearning/comments/9owc65/a_discussion_about_doing_computer_vision_in_big/,VectorChange,1539759962,[removed],0,1,False,self,,,,,
892,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,16,9oweq1,self.MachineLearning,Was reading through Principal Components Analysis. In it they tell all the principal components are othogonal to each other. How do you visualize it?,https://www.reddit.com/r/MachineLearning/comments/9oweq1/was_reading_through_principal_components_analysis/,mr_meeesix,1539760711,[removed],0,1,False,self,,,,,
893,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,16,9owhiu,self.MachineLearning,Val_loss of cnn model keras not decreasing.,https://www.reddit.com/r/MachineLearning/comments/9owhiu/val_loss_of_cnn_model_keras_not_decreasing/,edidamanish,1539761553,"I have a vgg inspired model which is giving me an accuracy of 85%. But during my epochs, my train_loss approaches 0 but the validation loss starts increasing after a while and gives me a fluctuating validation accuracy. Is there something which I should check in my model?
",0,1,False,self,,,,,
894,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,16,9owhk4,self.MachineLearning,[D] Was reading through Principal Component Analysis. How are all the principal components orthogonal to each other?,https://www.reddit.com/r/MachineLearning/comments/9owhk4/d_was_reading_through_principal_component/,mr_meeesix,1539761567,"Principal components denote the highest direction of variance, when taking the top 3 you can visualize them in 3D space. But more than 3 how will they still be orthogonal, can someone detail me on this.",5,1,False,self,,,,,
895,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,17,9owxfu,self.MachineLearning,[HELP] Best multiclass slassification technique (small dataset),https://www.reddit.com/r/MachineLearning/comments/9owxfu/help_best_multiclass_slassification_technique/,t_rex66,1539766745,[removed],0,1,False,self,,,,,
896,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,18,9ox0bn,blog.jetbrains.com,Datalore 1.0 - Intelligent Web Application for Data Analysis,https://www.reddit.com/r/MachineLearning/comments/9ox0bn/datalore_10_intelligent_web_application_for_data/,zozozzzoya,1539767611,,0,1,False,default,,,,,
897,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,18,9ox0ps,rubikscode.net,Implementing Restricted Boltzmann Machine with .NET Core,https://www.reddit.com/r/MachineLearning/comments/9ox0ps/implementing_restricted_boltzmann_machine_with/,RubiksCodeNMZ,1539767739,,0,1,False,https://a.thumbs.redditmedia.com/z3LnLB_yI1E4Qd_2GXlwtrIyvAI1DrADxhW9LUy71q0.jpg,,,,,
898,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,18,9ox26g,self.MachineLearning,[R] Pruning neural networks: is it time to nip it in the bud?,https://www.reddit.com/r/MachineLearning/comments/9ox26g/r_pruning_neural_networks_is_it_time_to_nip_it_in/,learning-luke,1539768208,[removed],0,1,False,self,,,,,
899,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,19,9oxa78,alibabacloud.com,Investing in AI the Smart Way  Lessons from 7 Tech Giants,https://www.reddit.com/r/MachineLearning/comments/9oxa78/investing_in_ai_the_smart_way_lessons_from_7_tech/,Jen_Cl,1539770699,,0,1,False,default,,,,,
900,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,19,9oxc0s,self.MachineLearning,How are open source medical imaging datasets for ML/DL development created?,https://www.reddit.com/r/MachineLearning/comments/9oxc0s/how_are_open_source_medical_imaging_datasets_for/,mangostickyriced,1539771221,"I am interest in knowing how these big open source imaging datasets are initially created? 

I understand usually it is compiled existing retrospective data, which is then labelled. But how do you source the images in the first place? How do you then facilitate the labelling process? 

What are the information governance issues and how are they overcome?",0,1,False,self,,,,,
901,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,19,9oxe53,smarten.com,What is Karl Pearson Correlation Analysis and How Can it be Used for Enterprise Analysis Needs?,https://www.reddit.com/r/MachineLearning/comments/9oxe53/what_is_karl_pearson_correlation_analysis_and_how/,ElegantMicroWebIndia,1539771836,,0,1,False,default,,,,,
902,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,20,9oxoaw,self.MachineLearning,[R] Subword Semantic Hashing for Intent Classification on Small Datasets,https://www.reddit.com/r/MachineLearning/comments/9oxoaw/r_subword_semantic_hashing_for_intent/,jupyterAI,1539774730,[removed],0,1,False,self,,,,,
903,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,20,9oxpa9,self.MachineLearning,Survey for a ML Project,https://www.reddit.com/r/MachineLearning/comments/9oxpa9/survey_for_a_ml_project/,Dev_Ahmed_Radwan,1539774962,[removed],0,1,False,self,,,,,
904,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,20,9oxrsn,kedjja.com,How to start creating an AI based chatbot to automate your customer support- Artificial Intelligence Solutions,https://www.reddit.com/r/MachineLearning/comments/9oxrsn/how_to_start_creating_an_ai_based_chatbot_to/,Kedjja,1539775610,,0,1,False,https://b.thumbs.redditmedia.com/9Ngrnwk7izfxOyimqluH0sxZh8kJ83CpedzValw56FY.jpg,,,,,
905,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,20,9oxunl,arxiv.org,[R] Optimizing Agent Behavior over Long Time Scales by Transporting Value,https://www.reddit.com/r/MachineLearning/comments/9oxunl/r_optimizing_agent_behavior_over_long_time_scales/,Kaixhin,1539776315,,4,1,False,default,,,,,
906,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,20,9oxxed,self.MachineLearning,Turn any phone into an AI car assistant,https://www.reddit.com/r/MachineLearning/comments/9oxxed/turn_any_phone_into_an_ai_car_assistant/,neoxitys,1539776986,"Hi everybody,

I'm currently working on a new project which aims to make driving stress-free, safe and cheaper ([https://ai-passenger.com/](http://ai-passenger.com/)). In my opinion everyone should get the advantages of smart driving assistants but right now only people with fancy and expensive cars can. Therefore, I thought about giving everybody access to this technology by building a smartphone application everybody can use.

Looking for some feedback (good or bad). Feel free to check out the website link.",0,1,False,self,,,,,
907,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,20,9oxz8c,planystech.com,Get some ideas on skip hull inspection,https://www.reddit.com/r/MachineLearning/comments/9oxz8c/get_some_ideas_on_skip_hull_inspection/,vincent897,1539777438,,0,1,False,default,,,,,
908,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,20,9oxzk9,smarten.com,What is ARIMAX Forecasting and How is it Used for Enterprise Analysis?,https://www.reddit.com/r/MachineLearning/comments/9oxzk9/what_is_arimax_forecasting_and_how_is_it_used_for/,ElegantMicroWebIndia,1539777518,,0,1,False,default,,,,,
909,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,21,9oy537,smarten.com,What is Simple Linear Regression and How Can an Enterprise Use this Technique to Analyze Data?,https://www.reddit.com/r/MachineLearning/comments/9oy537/what_is_simple_linear_regression_and_how_can_an/,ElegantMicroWebIndia,1539778790,,0,1,False,default,,,,,
910,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,21,9oy72j,self.MachineLearning,Advice on Deep Reinforcment Learning for Klondike,https://www.reddit.com/r/MachineLearning/comments/9oy72j/advice_on_deep_reinforcment_learning_for_klondike/,olafgarten,1539779242,[removed],0,1,False,self,,,,,
911,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,21,9oy7re,self.MachineLearning,[D] Architectures for image generation,https://www.reddit.com/r/MachineLearning/comments/9oy7re/d_architectures_for_image_generation/,Bestbellydancer,1539779410,"Hi, I was wondering what architectures are out there that produce images similar to the input data set. Lets suppose I was trying to predict what a 'cool' car looks like, my data set would include images of cars that I believe to be 'cool' and the network would output new cars with features from the ones from the inputs, with the hope being that these cars are also 'cool'.

I have come across Deep Convolutional Generative Averserial Networks (DCGANs) but I was wondering if there are any other architectures out there that are good for this.

Thanks for your help.",8,1,False,self,,,,,
912,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,21,9oybsc,self.MachineLearning,Summer School 2019,https://www.reddit.com/r/MachineLearning/comments/9oybsc/summer_school_2019/,CrostaBot,1539780340,[removed],0,1,False,self,,,,,
913,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,21,9oycga,self.MachineLearning,"Report: Why are 50,000 Seats in IT Vacant",https://www.reddit.com/r/MachineLearning/comments/9oycga/report_why_are_50000_seats_in_it_vacant/,akshad_GL,1539780480,[removed],0,1,False,self,,,,,
914,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,21,9oychr,self.MachineLearning,"Best universities for Data Science, Machine Learning and Deep Learning",https://www.reddit.com/r/MachineLearning/comments/9oychr/best_universities_for_data_science_machine/,mohit__,1539780490,[removed],0,1,False,self,,,,,
915,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,21,9oycjq,self.MachineLearning,Benchmark for Deeplearning models,https://www.reddit.com/r/MachineLearning/comments/9oycjq/benchmark_for_deeplearning_models/,aksel_id234,1539780500,[removed],0,1,False,self,,,,,
916,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,21,9oyfpb,smarten.com,What is the Paired Sample T Test and How is it Beneficial to Business Analysis?,https://www.reddit.com/r/MachineLearning/comments/9oyfpb/what_is_the_paired_sample_t_test_and_how_is_it/,ElegantMicroWebIndia,1539781179,,0,1,False,default,,,,,
917,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,22,9oym47,smarten.com,What is Binary Logistic Regression Classification and How is it Used in Analysis?,https://www.reddit.com/r/MachineLearning/comments/9oym47/what_is_binary_logistic_regression_classification/,ElegantMicroWebIndia,1539782520,,0,1,False,default,,,,,
918,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,22,9oysfa,smarten.com,What is Spearman's Rank Correlation and How is it Useful for Business Analysis?,https://www.reddit.com/r/MachineLearning/comments/9oysfa/what_is_spearmans_rank_correlation_and_how_is_it/,ElegantMicroWebIndia,1539783883,,0,1,False,default,,,,,
919,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,22,9oyta5,self.MachineLearning,state-of-the-art for Natural Language Generation?,https://www.reddit.com/r/MachineLearning/comments/9oyta5/stateoftheart_for_natural_language_generation/,giobin,1539784066,I'm working on a neural net that reads a wikipedia biography and generate a couple of sentence in English describing the input data. Is there a paper pointing out the state-of-the-art for this task? Have you any suggestion with whom I might compare my work with?,0,1,False,self,,,,,
920,MachineLearning,t5_2r3gv,2018-10-17,2018,10,17,23,9oz001,self.MachineLearning,Terminator uses machine learning,https://www.reddit.com/r/MachineLearning/comments/9oz001/terminator_uses_machine_learning/,m3diam1k3,1539785460,[removed],0,1,False,self,,,,,
921,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,0,9ozgrf,self.MachineLearning,"About the Titan V - I know there are benchmarks, but I wanted to ask you experts...",https://www.reddit.com/r/MachineLearning/comments/9ozgrf/about_the_titan_v_i_know_there_are_benchmarks_but/,engine_town_rattler,1539788833,"How does it compare to a 1080ti?  

Do you have to use Tensorflow and/or do special things to the model to utilize the Titan V's full potential?",0,1,False,self,,,,,
922,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,0,9ozkk5,medium.com,Train your own ML model using Scikit and use in iOS app with CoreML (and probably with Augmented Reality),https://www.reddit.com/r/MachineLearning/comments/9ozkk5/train_your_own_ml_model_using_scikit_and_use_in/,Happycodeine,1539789528,,0,1,False,default,,,,,
923,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,0,9oznd0,techcrunch.com,Memory raises $5M to bring AI to time tracking,https://www.reddit.com/r/MachineLearning/comments/9oznd0/memory_raises_5m_to_bring_ai_to_time_tracking/,AndetteM,1539790048,,0,1,False,https://b.thumbs.redditmedia.com/XXdobWM_ZlKq7jMdtY7Q8dgemZYsX4lCiNyh67Y9ZBo.jpg,,,,,
924,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,0,9ozpfd,self.MachineLearning,"About the Titan V - I know there are benchmarks, but I wanted to ask you experts...",https://www.reddit.com/r/MachineLearning/comments/9ozpfd/about_the_titan_v_i_know_there_are_benchmarks_but/,Shekeller,1539790449,"Now that it's been out for a while,

How does it compare to a 1080ti?

Do you have to use Tensorflow and/or do special things to the model to utilize the Titan V's full potential?

The Titan V costs more than 4x the money for a 1080ti. Do you get 4x the performance on your training?
",0,1,False,self,,,,,
925,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,0,9oztb5,dimensionless.in,Spam Detection with Natural Language Processing (NLP) - Part 1,https://www.reddit.com/r/MachineLearning/comments/9oztb5/spam_detection_with_natural_language_processing/,divya2018,1539791179,,0,1,False,default,,,,,
926,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,0,9ozven,self.MachineLearning,"Simple Questions Thread October 17, 2018",https://www.reddit.com/r/MachineLearning/comments/9ozven/simple_questions_thread_october_17_2018/,AutoModerator,1539791566,"Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!

Thread will stay alive until next one so keep posting after the date in the title.

Thanks to everyone for answering questions in the previous thread!
",0,1,False,self,,,,,
927,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,1,9p0bnx,self.MachineLearning,[N] DeepMind open-sources TRFL: a library of reinforcement learning building blocks,https://www.reddit.com/r/MachineLearning/comments/9p0bnx/n_deepmind_opensources_trfl_a_library_of/,gohu_cd,1539794530,"Blog post: [https://deepmind.com/blog/trfl/](https://deepmind.com/blog/trfl/)  


Github link: [https://github.com/deepmind/trfl](https://github.com/deepmind/trfl)  


Good to see some open-source efforts from DeepMind, although a bit late. ",5,1,False,self,,,,,
928,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,1,9p0cg3,self.MachineLearning,[P] I have a dataset of over 7m pictures that's been manually labeled as nude/suggestive/non-nude over 10 years (X-Post r/computevision),https://www.reddit.com/r/MachineLearning/comments/9p0cg3/p_i_have_a_dataset_of_over_7m_pictures_thats_been/,AllergicToDinosaurs,1539794669,"(I posted [this just now](https://www.reddit.com/r/computervision/comments/9ozydg/i_have_a_dataset_of_over_7m_pictures_thats_been/) in /r/computervision as well, hope cross-posting is not frowned upon, didn't see it in the rules, sorry otherwise!)

*I haven't done a CV task before where the available dataset have been this big, or of this exceptional quality.* 

Every image of this dataset of **seven million+ user-uploaded pictures** have been painstakingly **labeled manually** by our ""community support"" team over the last 10 years, plus the addition of volunteers from the social networks where the pictures where uploaded (ten or so people has historically been required to have chosen the same label for a picture before the label was assigned).

The dataset is near perfection, with extremely few mislabeled images (except for human bias, though would have to be collectively biased since multiple people needs to miss-classify).

This dataset has six labels:

* pictures of **animate** objects that morally and legally we can't show to users that are &lt;**18** years old,
* pictures of **animate** objects that morally and legally we can't show to users that are &lt;**16** years old,
* pictures of **animate** objects that morally and legally we can't show to users that are &lt;**12** years old,
* pictures of **INANIMATE** objects (toys, cars, whatever) that morally and legally we can't show to users that are &lt;**18** years old,
* pictures of **INANIMATE** objects (toys, cars, whatever) that morally and legally we can't show to users that are &lt;**16** years old,
* pictures of **INANIMATE** objects (toys, cars, whatever) that morally and legally we can't show to users that are &lt;**12** years old.

*(****animate*** *means dick pics and titties more or less,* ***inanimate*** *is non-human, e.g. dildos and forests; genitals and pr0n is labeled 18+, any nipple showing or more sexual than that is labeled 16+ if not enough to earns the 18+ stamp, anything else is just labeled 12+ since we don't allow users below this age to use our services.)*

The task at hand is to automatically label pictures that we legally can't show to users that are &lt;16 years old. The laws basically boils down to this (which the manual labeling has followed):

***""if a nipple and/or anything more sexual can be seen in a picture, the user needs to be at least 16 years old to see it.""***

My initial idea is to use a pre-trained VGG19 or ResNet50 model, lock a number of first layers and do transfer learning on whatever number of later layers show promise, and if the results are bad, experiment with a combination of AWS Rekognition and a custom solution.

**Any thoughts, tips, guidelines? Appreciate any feedback!**

&amp;#x200B;

***NB****: CV is not my main focus at work (though I've studied and played around with it quite a lot); I'm usually involved in time-series and NLP, and I have a much stronger comp-sci background than stats, but focusing on bridging that gap the last few years.*",104,1,False,self,,,,,
929,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,2,9p0lq2,self.MachineLearning,Is there a single book that covers maths required for ML?,https://www.reddit.com/r/MachineLearning/comments/9p0lq2/is_there_a_single_book_that_covers_maths_required/,nashenas786,1539796377,,0,1,False,self,,,,,
930,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,2,9p0lu3,kaggle.com,Is this Connect-4 Data set enough to teach a neural network to beat me at the game?,https://www.reddit.com/r/MachineLearning/comments/9p0lu3/is_this_connect4_data_set_enough_to_teach_a/,Silver5005,1539796399,,1,1,False,default,,,,,
931,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,2,9p0ntx,self.MachineLearning,[P] GANs trained on Indian (Bollywood) Celebs Dataset,https://www.reddit.com/r/MachineLearning/comments/9p0ntx/p_gans_trained_on_indian_bollywood_celebs_dataset/,akanimax,1539796766,[removed],0,1,False,self,,,,,
932,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,3,9p15mb,self.MachineLearning,Never Fail Twice,https://www.reddit.com/r/MachineLearning/comments/9p15mb/never_fail_twice/,AleksandrTavgen,1539800041,"Hi, this is applying machine learning in creating automated monitoring system which is working in production and outperforms a lot of commercial solutions. Approaches, architecture, issues etc.

&amp;#x200B;

[https://medium.com/@ATavgen/never-fail-twice-608147cb49b](https://medium.com/@ATavgen/never-fail-twice-608147cb49b)",0,1,False,self,,,,,
933,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,3,9p173r,self.MachineLearning,RTX 2070 or GTX 1080 for DL and ML?,https://www.reddit.com/r/MachineLearning/comments/9p173r/rtx_2070_or_gtx_1080_for_dl_and_ml/,Phoen1xSoul,1539800318,[removed],0,1,False,self,,,,,
934,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,3,9p19o3,timdettmers.com,TPUs vs GPUs for Transformers (BERT)  Tim Dettmers,https://www.reddit.com/r/MachineLearning/comments/9p19o3/tpus_vs_gpus_for_transformers_bert_tim_dettmers/,phobrain,1539800802,,1,1,False,default,,,,,
935,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,3,9p1bm2,self.MachineLearning,[P] GANs trained on Indian (Bollywood) Celebs Dataset,https://www.reddit.com/r/MachineLearning/comments/9p1bm2/p_gans_trained_on_indian_bollywood_celebs_dataset/,akanimax,1539801181,[removed],0,1,False,self,,,,,
936,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,4,9p1ltx,self.MachineLearning,Survey for factors affecting footfall in a college fest,https://www.reddit.com/r/MachineLearning/comments/9p1ltx/survey_for_factors_affecting_footfall_in_a/,rwarlock,1539803141,[removed],0,1,False,self,,,,,
937,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,4,9p20x3,self.MachineLearning,"If I decide to do a PhD in Applied Mathematics, can I do research in Deep Learning, or would I have to get my graduate degree in Computer Science?",https://www.reddit.com/r/MachineLearning/comments/9p20x3/if_i_decide_to_do_a_phd_in_applied_mathematics/,SciFi_Fish,1539806058,[removed],0,1,False,self,,,,,
938,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,4,9p228o,self.MachineLearning,NLP unbalanced class issue,https://www.reddit.com/r/MachineLearning/comments/9p228o/nlp_unbalanced_class_issue/,gireeshwaran,1539806300,"Hey guys. I am solving 2 class NLP problem.  classes are quite  unbalanced. 0 = 80%, 1 = 20%. 

Process pipeline 
Cleaning of my text -&gt; stemming -&gt; tokenization. 

After using svm / and random forest class
All my test data is getting predicted as lablel 0 .
Leading to high accuracy of 80% but bad precision 0/0. 

How do I fix this ?  

Do I take less sample of label 0 . 
Or there is some better method I should be doing for NLP problems. 

Thanks in advance. ",0,1,False,self,,,,,
939,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,5,9p2gag,self.MachineLearning,[D] Machine learning jobs about causal inference?,https://www.reddit.com/r/MachineLearning/comments/9p2gag/d_machine_learning_jobs_about_causal_inference/,Causality_Guy,1539809001,"Hi fellows,

I am a senior year Ph.D. student in US (CS program ranking around 50 only) working on inferring causal effects and relationships with machine learning. I only have several papers in 2nd-tier conferences like SDM, CIKM and IJCAI. I wonder if it is possible to get an internship about causal inference from companies/research labs. I am also heading to CIKM'18 next week, hope can meet some of you there.

If you are interested in my background, please pm me.",24,1,False,self,,,,,
940,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,6,9p2qb0,self.MachineLearning,Can anyone explain to me why KL collapse happens?,https://www.reddit.com/r/MachineLearning/comments/9p2qb0/can_anyone_explain_to_me_why_kl_collapse_happens/,randomchickibum,1539810917,[removed],0,1,False,self,,,,,
941,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,6,9p2v0x,self.MachineLearning,Can someone explain to me why KL collapse happens in VAE?,https://www.reddit.com/r/MachineLearning/comments/9p2v0x/can_someone_explain_to_me_why_kl_collapse_happens/,randomchickibum,1539811851,[removed],0,1,False,self,,,,,
942,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,7,9p3f3z,arxiv.org,"[R] Trellis Networks for Sequence Modeling. New SOTA for PTB, WikiText-103, Permuted MNIST, etc.",https://www.reddit.com/r/MachineLearning/comments/9p3f3z/r_trellis_networks_for_sequence_modeling_new_sota/,baylearn,1539815995,,5,1,False,default,,,,,
943,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,7,9p3j5y,self.MachineLearning,[D] Should We Be Worried About Artificial Intelligence?,https://www.reddit.com/r/MachineLearning/comments/9p3j5y/d_should_we_be_worried_about_artificial/,BumbleZeed,1539816866,"[https://rzim.org/ask-away-broadcasts/should-we-be-worried-about-artificial-intelligence/](https://rzim.org/ask-away-broadcasts/should-we-be-worried-about-artificial-intelligence/)

&amp;#x200B;",2,1,False,self,,,,,
944,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,7,9p3jdz,self.MachineLearning,"[R] TDLS: StackGAN++, Realistic Image Synthesis with Stacked Generative Adversarial Networks",https://www.reddit.com/r/MachineLearning/comments/9p3jdz/r_tdls_stackgan_realistic_image_synthesis_with/,tdls_to,1539816911,"In this paper the authors propose 2 new multi-stage architectures for generating high resolution images and obtain very impressive results

paper review: [https://youtu.be/PXWIaLE7\_NU](https://youtu.be/PXWIaLE7_NU)

paper ref: [https://arxiv.org/abs/1710.10916](https://www.youtube.com/redirect?redir_token=jTPZxTkaBbYdjGMkghL3I_D1MAV8MTUzOTkwMzI4NEAxNTM5ODE2ODg0&amp;q=https%3A%2F%2Farxiv.org%2Fabs%2F1710.10916&amp;event=video_description&amp;v=PXWIaLE7_NU)",6,1,False,self,,,,,
945,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,8,9p3v9v,self.MachineLearning,[D] Ideas for my master thesis,https://www.reddit.com/r/MachineLearning/comments/9p3v9v/d_ideas_for_my_master_thesis/,FelipwMarcelino,1539819480,"Hello guys, next month I will begin my masters. During two years I have to write my thesis and make five class's. About my thesis I really like focus in META-LEARNING , but I am lack of ideias what I can explore in that subfield. Someone have suggestions or ideas I can explore, or maybe some good articles to read? I really appreciate if someone can help me.

Thanks ",2,1,False,self,,,,,
946,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,9,9p4fs8,self.MachineLearning,Best reinforcement learning GitHub repo for fast training,https://www.reddit.com/r/MachineLearning/comments/9p4fs8/best_reinforcement_learning_github_repo_for_fast/,ai_is_matrix_mult,1539824069,[removed],0,1,False,self,,,,,
947,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,10,9p4mz2,self.MachineLearning,Best Model Type to Explore for Active Feedback and Adjustment?,https://www.reddit.com/r/MachineLearning/comments/9p4mz2/best_model_type_to_explore_for_active_feedback/,DataRulesEverything,1539825671,[removed],0,1,False,self,,,,,
948,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,10,9p4uwv,engineering.eckovation.com,"I have tried covering all the elements of Decision Tree in this, can you please review and give your comment.",https://www.reddit.com/r/MachineLearning/comments/9p4uwv/i_have_tried_covering_all_the_elements_of/,aaobihar,1539827468,,0,1,False,default,,,,,
949,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,11,9p5877,self.MachineLearning,Autism: Using Data Science to fix Holes in the System,https://www.reddit.com/r/MachineLearning/comments/9p5877/autism_using_data_science_to_fix_holes_in_the/,pavanmirla,1539830581,[removed],0,1,False,self,,,,,
950,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,12,9p5gwh,self.MachineLearning,What to do if your team member spends a lot of working time on Kaggle?,https://www.reddit.com/r/MachineLearning/comments/9p5gwh/what_to_do_if_your_team_member_spends_a_lot_of/,t0mthakat,1539832658,"I am a member in a Data Science(DS) team. We are paid to do company DS project. But some of my team members spend A LOT OF their working time on Kaggle competitions. I agree that personal education is good, but spend 6/8 hours working time, 5 days/week, for personal work is unacceptable. So they cannot focus on the team project. In every communication or teamwork, they just turn the blind eyes to the problem that they can do something to improve it. They play it safe so they have more time on Kaggle. It turns out that our DS outcome was just underperformance. What should I do get them to pay more focus on work? Otherwise, our team will be dismissed soon.",0,1,False,self,,,,,
951,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,12,9p5khv,self.MachineLearning,[D] AI is not really a threat to mankind,https://www.reddit.com/r/MachineLearning/comments/9p5khv/d_ai_is_not_really_a_threat_to_mankind/,adolfchurchill1945,1539833534,"Here are some of the arguments I can think of, please let me know if you can find some more or think any of these are fallacies. 

1. Desire for survival is crucial, its very unlikely AI will have desires. 

2. The idea that something more intelligent than humans will be hostile to humans comes from a very human perspective, not a rational perspective. 

3. AI will be developed in very specific and secure environments, the idea of the dangerous mad scientist is very unlikely and deeply rooted into modern paranoid culture 

4. AI will be very smart and even more controllable, the idea that intelligence cant be controlled is a hoax 

5. Good and bad, justice, fairness and suffering are animal ideas, machines wont interfere intrinsically with them.  

&amp;#x200B;",5,1,False,self,,,,,
952,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,12,9p5mr5,self.MachineLearning,How to validate a neural network learning to play deterministic games with self play,https://www.reddit.com/r/MachineLearning/comments/9p5mr5/how_to_validate_a_neural_network_learning_to_play/,ngroover504,1539834091,[removed],0,1,False,self,,,,,
953,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,13,9p5ytb,self.MachineLearning,is Super Harsh Guide to Machine Learning post a satire?,https://www.reddit.com/r/MachineLearning/comments/9p5ytb/is_super_harsh_guide_to_machine_learning_post_a/,ml_kid,1539836973,[removed],0,1,False,self,,,,,
954,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,15,9p6izj,self.MachineLearning,Machine Learning Training Institute in Delhi,https://www.reddit.com/r/MachineLearning/comments/9p6izj/machine_learning_training_institute_in_delhi/,smadrid056,1539842428,[removed],0,1,False,self,,,,,
955,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,15,9p6mbv,madridsoftwaretrainings.com,Machine Learning Training Institute in Delhi,https://www.reddit.com/r/MachineLearning/comments/9p6mbv/machine_learning_training_institute_in_delhi/,smadrid056,1539843377,,0,1,False,default,,,,,
956,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,16,9p7075,self.MachineLearning,Why Conditional GAN only input real label in the discriminator?,https://www.reddit.com/r/MachineLearning/comments/9p7075/why_conditional_gan_only_input_real_label_in_the/,Brave_Establishment,1539847337,[removed],0,1,False,self,,,,,
957,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,17,9p7c41,youtube.com,Technological Revolution,https://www.reddit.com/r/MachineLearning/comments/9p7c41/technological_revolution/,baDoxx,1539851091,,0,1,False,default,,,,,
958,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,17,9p7e6m,self.MachineLearning,Emotional dataset for NLP,https://www.reddit.com/r/MachineLearning/comments/9p7e6m/emotional_dataset_for_nlp/,acobobby,1539851772,[removed],0,1,False,self,,,,,
959,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,17,9p7gqc,towardsdatascience.com,[P] My main take home messages from World Summit AI,https://www.reddit.com/r/MachineLearning/comments/9p7gqc/p_my_main_take_home_messages_from_world_summit_ai/,MLpractitioner,1539852569,,0,1,False,default,,,,,
960,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,17,9p7gwk,self.MachineLearning,how to share weights and features between 2 network which is trying to find the similarity between 2 images,https://www.reddit.com/r/MachineLearning/comments/9p7gwk/how_to_share_weights_and_features_between_2/,cervantes-loves-ai,1539852626,[removed],0,1,False,self,,,,,
961,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,18,9p7jke,self.MachineLearning,Gradient Ascent Algorithm Pseudocode,https://www.reddit.com/r/MachineLearning/comments/9p7jke/gradient_ascent_algorithm_pseudocode/,WillyGnome,1539853439,[removed],0,1,False,self,,,,,
962,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,18,9p7kkt,github.com,Real-Time 3D Dense Face Reconstruction,https://www.reddit.com/r/MachineLearning/comments/9p7kkt/realtime_3d_dense_face_reconstruction/,cleardusk,1539853743,,0,1,False,default,,,,,
963,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,18,9p7ltm,self.MachineLearning,Do RL Models benefit from having differentiable components?,https://www.reddit.com/r/MachineLearning/comments/9p7ltm/do_rl_models_benefit_from_having_differentiable/,throwaway775849,1539854120,[removed],0,1,False,self,,,,,
964,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,19,9p8241,self.MachineLearning,The case for open source classifiers in AI algorithms | Opensource.com,https://www.reddit.com/r/MachineLearning/comments/9p8241/the_case_for_open_source_classifiers_in_ai/,kimberlad,1539858918,[removed],0,1,False,self,,,,,
965,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,19,9p85w3,self.MachineLearning,Large Scale Distributed Machine Learning (Deep Learning) Systems,https://www.reddit.com/r/MachineLearning/comments/9p85w3/large_scale_distributed_machine_learning_deep/,arunkumar_bvr,1539859991,[removed],2,1,False,self,,,,,
966,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,20,9p88s7,medium.com,Train your own ML model using Scikit and use in iOS app with CoreML (and probably with Augmented Reality),https://www.reddit.com/r/MachineLearning/comments/9p88s7/train_your_own_ml_model_using_scikit_and_use_in/,Fewthp,1539860772,,0,1,False,default,,,,,
967,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,20,9p8b4r,self.MachineLearning,Artificial Intelligence with Python through Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/9p8b4r/artificial_intelligence_with_python_through_deep/,arunkumar_bvr,1539861355,[removed],3,1,False,self,,,,,
968,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,20,9p8dng,smarten.com,What Are Simple Random Sampling and Stratified Random Sampling Analytical Techniques?,https://www.reddit.com/r/MachineLearning/comments/9p8dng/what_are_simple_random_sampling_and_stratified/,ElegantMicroWebIndia,1539862008,,0,1,False,default,,,,,
969,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,20,9p8fej,self.MachineLearning,Robotics with Python through Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/9p8fej/robotics_with_python_through_deep_reinforcement/,arunkumar_bvr,1539862475,Can anybody list out the popular/great projects and research papers for Robotics with Python through Deep Reinforcement Learning?,2,1,False,self,,,,,
970,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,20,9p8ikr,self.MachineLearning,Computational Advertising with Recommender Systems for Targeting and Ranking Ads through Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9p8ikr/computational_advertising_with_recommender/,arunkumar_bvr,1539863304,[removed],1,1,False,self,,,,,
971,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,20,9p8jdq,smarten.com,What is the Independent Samples T Test Method of Analysis and How Can it Benefit an Organization?,https://www.reddit.com/r/MachineLearning/comments/9p8jdq/what_is_the_independent_samples_t_test_method_of/,ElegantMicroWebIndia,1539863505,,0,1,False,default,,,,,
972,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,21,9p8o4a,medium.com,[R] Deep Learning Based Emotion Recognition with PyTorch and TensorFlow,https://www.reddit.com/r/MachineLearning/comments/9p8o4a/r_deep_learning_based_emotion_recognition_with/,omarsar,1539864592,,0,1,False,https://b.thumbs.redditmedia.com/jPQzfC_sTxcJSONmgT1IEK2Lzwxz-_XDw97I8WS7DSI.jpg,,,,,
973,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,21,9p8o4g,i.imgur.com,Brace yourselves for the reviews,https://www.reddit.com/r/MachineLearning/comments/9p8o4g/brace_yourselves_for_the_reviews/,Kay_Dhi,1539864593,,0,1,False,default,,,,,
974,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,21,9p8p82,smarten.com,What is Multiple Linear Regression and How Can it be Helpful for Business Analysis?,https://www.reddit.com/r/MachineLearning/comments/9p8p82/what_is_multiple_linear_regression_and_how_can_it/,ElegantMicroWebIndia,1539864837,,0,1,False,default,,,,,
975,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,21,9p8qq4,i.redd.it,Bracing myself for the reviews,https://www.reddit.com/r/MachineLearning/comments/9p8qq4/bracing_myself_for_the_reviews/,Kay_Dhi,1539865196,,0,1,False,default,,,,,
976,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,21,9p8rw0,self.MachineLearning,How can the on-policy Monte Carlo control method be designed that does not use the unrealistic assumption of exploring starts,https://www.reddit.com/r/MachineLearning/comments/9p8rw0/how_can_the_onpolicy_monte_carlo_control_method/,huayangshiboqi,1539865493,[removed],0,1,False,https://b.thumbs.redditmedia.com/K7EeqHsXcuMX2atALzljLlHJHbLI0LCD2kIqPG6BNpk.jpg,,,,,
977,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,21,9p8shw,github.com,[P] Yolo-v3 implementation with tensorflow-eager-execution.,https://www.reddit.com/r/MachineLearning/comments/9p8shw/p_yolov3_implementation_with/,penny4860,1539865637,,0,1,False,default,,,,,
978,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,21,9p8tpm,smarten.com,What is KNN Classification and How Can This Analysis Help an Enterprise?,https://www.reddit.com/r/MachineLearning/comments/9p8tpm/what_is_knn_classification_and_how_can_this/,ElegantMicroWebIndia,1539865914,,0,1,False,default,,,,,
979,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,21,9p8tqp,blog.dataversioncontrol.com,[N] ML best practices in PyTorch Dev Conf 2018,https://www.reddit.com/r/MachineLearning/comments/9p8tqp/n_ml_best_practices_in_pytorch_dev_conf_2018/,AnYvia,1539865920,,0,1,False,default,,,,,
980,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,21,9p8x3n,medium.com,Manage ML Deployments Like A Boss,https://www.reddit.com/r/MachineLearning/comments/9p8x3n/manage_ml_deployments_like_a_boss/,ahousley,1539866693,,0,1,False,default,,,,,
981,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,21,9p8y9n,smarten.com,What is Frequent Pattern Mining (Association) and How Does it Support Business Analysis?,https://www.reddit.com/r/MachineLearning/comments/9p8y9n/what_is_frequent_pattern_mining_association_and/,ElegantMicroWebIndia,1539866946,,0,1,False,default,,,,,
982,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,21,9p8zr8,self.MachineLearning,Natural Language Processing with Deep Learning,https://www.reddit.com/r/MachineLearning/comments/9p8zr8/natural_language_processing_with_deep_learning/,arunkumar_bvr,1539867275,Can anybody list out the popular/great projects and research papers for Natural Language Processing with Deep Learning?,1,1,False,self,,,,,
983,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,21,9p9110,blog.pocketcluster.io,"[N] Weekly Machine Learning Opensource Roundup  Oct. 18, 2018",https://www.reddit.com/r/MachineLearning/comments/9p9110/n_weekly_machine_learning_opensource_roundup_oct/,stkim1,1539867564,,0,1,False,default,,,,,
984,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,22,9p935a,smarten.com,What is Nave Bayes Classification and How is it Used for Enterprise Analysis?,https://www.reddit.com/r/MachineLearning/comments/9p935a/what_is_nave_bayes_classification_and_how_is_it/,ElegantMicroWebIndia,1539867989,,0,1,False,default,,,,,
985,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,22,9p9ccz,self.MachineLearning,[D] ML is losing some of its luster for me. How do you like your ML career?,https://www.reddit.com/r/MachineLearning/comments/9p9ccz/d_ml_is_losing_some_of_its_luster_for_me_how_do/,mltoss,1539869890,"Soliciting thoughts on ML careers (in industry or academia), especially in light of machine learning and deep learning hype.

&amp;#x200B;

I work as an applied research engineer at a large non-tech company. Over the last few years ML has lost some of its luster in my mind - the hype around deep learning and ML has added a lot of noise into the system, and for someone who cares about doing good science that's been hard for me. 

&amp;#x200B;

I feel like the effort I put into rigorous and reasoned application of ML is wasted and makes me less competitive - management wants the ""deep learning"" solution and they are satisfied by someone reading a blog post, throwing half-baked training data and Keras model.fit() at the problem and calling it solved. I'm not sure I can do ML in an environment like that, and it's difficult to push back against the seductive hype of ""cheap and easy"" deep learning (ironically a simple random forest would be much easier and often quite effective, but that isn't sexy. I've seen pressure to use neural networks even when something else makes much more sense to use). I love ML and like seeing others learn and be excited about it, but the low barrier to entry makes it easy for people to sell bad modeling to those who don't know any better.

&amp;#x200B;

How are you all enjoying your ML career? I'm considering moving away from ML and going back into software engineering, but maybe I just need to switch companies. Perhaps I'm just a curmudgeon or an idealist. Does anyone else have similar thoughts?

&amp;#x200B;

(Background: I have a masters in CS with a focus on machine learning. Since graduating a few years ago I've been working in an applied research role doing a 50/50 mix of software engineering and machine learning. I'm not particularly exceptional, but my company doesn't have a deep bench in AI/ML so I've become recognized as a subject-matter expert and could make a career out of researching and applying ML here.)",133,1,False,self,,,,,
986,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,22,9p9e1q,dragan.rocks,Adopt a Neanderthal function as your own pet! Support my Clojure work on Patreon.,https://www.reddit.com/r/MachineLearning/comments/9p9e1q/adopt_a_neanderthal_function_as_your_own_pet/,oVerde,1539870237,,0,1,False,https://b.thumbs.redditmedia.com/TfBjhOInDUltz_9_9LbCYc2bLuUWMSyJig_IWu33OoM.jpg,,,,,
987,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,23,9p9rwq,github.com,GitHub - BarnesLab/Patient2Vec: Patient2Vec: A Personalized Interpretable Deep Representation of the Longitudinal Electronic Health Record,https://www.reddit.com/r/MachineLearning/comments/9p9rwq/github_barneslabpatient2vec_patient2vec_a/,kk7nc,1539872981,,0,1,False,default,,,,,
988,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,23,9p9tq7,self.MachineLearning,Computer Vision with Deep Learning,https://www.reddit.com/r/MachineLearning/comments/9p9tq7/computer_vision_with_deep_learning/,arunkumar_bvr,1539873318,[removed],1,1,False,self,,,,,
989,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,23,9p9xh4,self.MachineLearning,[D] LSTM for sequence of images,https://www.reddit.com/r/MachineLearning/comments/9p9xh4/d_lstm_for_sequence_of_images/,timo4ever,1539874049,"I've seen research going on for using LSTM to encode sequence of images (in a video, for purposes like classification, etc). I wonder, for LSTM in general, is there a limit on how long each example should be? I have a dataset where each data point consists of 3 images (each 1-2 seconds apart) and was trying to see if LSTM can be used to encode them.",6,1,False,self,,,,,
990,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,23,9p9xig,self.MachineLearning,Is it important to use part-of-speech tagging in NLP and topic modeling?,https://www.reddit.com/r/MachineLearning/comments/9p9xig/is_it_important_to_use_partofspeech_tagging_in/,ahahaa,1539874055,[removed],0,1,False,self,,,,,
991,MachineLearning,t5_2r3gv,2018-10-18,2018,10,18,23,9p9zlk,self.MachineLearning,Computer Vision with Python through Deep Learning,https://www.reddit.com/r/MachineLearning/comments/9p9zlk/computer_vision_with_python_through_deep_learning/,arunkumar_bvr,1539874470,Can anybody list out the popular/great projects and research papers for Computer Vision with Python through Deep Learning?,1,1,False,self,,,,,
992,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,0,9pa22o,self.MachineLearning,[D] Any suggestion for multiple input images with pre-trained models in CNN?,https://www.reddit.com/r/MachineLearning/comments/9pa22o/d_any_suggestion_for_multiple_input_images_with/,ployandppp,1539874938,"I am trying to make an custom image classifier by using two or more images as an input images. As I try to search some of documents and ref, it can do by training a whole new model. But how about using pre-trained model for the best weight and better performance? How the layer sequence should be in this case?",18,1,False,self,,,,,
993,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,0,9pa8rv,self.MachineLearning,Error on training own convolutional neural network using tensorflow,https://www.reddit.com/r/MachineLearning/comments/9pa8rv/error_on_training_own_convolutional_neural/,Gameatro,1539876181,"I am trying to train some image dataset on tensorflow, but I am getting error resource allocation exceeds 10% memory. I have 8gb ram, so dont get why is memory a issue. I tried reducing batch size but no effect. The dataset is train fine using the darknet. so why is it giving error in my cnn? can somebody pls guide me. I am new to deep learning and don't know many of the complex stuff. so pls understand it.",0,1,False,self,,,,,
994,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,0,9pakao,self.MachineLearning,is Super Harsh Guide to Machine Learning post a satire?,https://www.reddit.com/r/MachineLearning/comments/9pakao/is_super_harsh_guide_to_machine_learning_post_a/,ml_kid,1539878368,"I found this post https://np.reddit.com/r/MachineLearning/comments/5z8110/d_a_super_harsh_guide_to_machine_learning/ from /r/LearnMachineLearning 's wiki where they mentioned this post as a guide. And i was following exactly that. However, some of the comments sound sarcastic and indicate the post is satire. is it so? 

as a noob in this field, I cannot figure out what is satire and what is not. thank you",0,1,False,self,,,,,
995,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,1,9pakjo,math.ias.edu,"IAS Special Year on Optimisation, Statistics and Theoretical Machine Learning",https://www.reddit.com/r/MachineLearning/comments/9pakjo/ias_special_year_on_optimisation_statistics_and/,DragonGod2718,1539878414,,4,1,False,default,,,,,
996,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,2,9pb4vc,self.MachineLearning,Generating Sequential Data,https://www.reddit.com/r/MachineLearning/comments/9pb4vc/generating_sequential_data/,worldhellow,1539882175,[removed],0,1,False,self,,,,,
997,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,2,9pbd2u,self.MachineLearning,[D] How to identify confidently the source of the empirical gains while designing new models?,https://www.reddit.com/r/MachineLearning/comments/9pbd2u/d_how_to_identify_confidently_the_source_of_the/,pigdogsheep,1539883653,"While designing new models  I usually fail to identify confidently the source of the empirical gains, is it something related to the model architecture or because of a better selection of the hyper-parameter tuning. This is a common problem in the literature as mentioned in \[[1](https://arxiv.org/pdf/1807.03341.pdf)\]

Are there less expensive techniques that one should follow to do a ""fair"" comparison between two models, rather than the obvious one of trying grid search over hyper param of the two models and picking the one with the best performance.

&amp;#x200B;

  


&amp;#x200B;",2,1,False,self,,,,,
998,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,2,9pbf14,self.MachineLearning,DeepMind is releasing their graph NN library,https://www.reddit.com/r/MachineLearning/comments/9pbf14/deepmind_is_releasing_their_graph_nn_library/,olBaa,1539884024,"Github: https://github.com/deepmind/graph_nets
Hope it will be updated with more architectures, as right now it's pretty minimal",0,1,False,self,,,,,
999,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,2,9pbf4p,self.MachineLearning,[R] DeepMind is releasing their graph NN library,https://www.reddit.com/r/MachineLearning/comments/9pbf4p/r_deepmind_is_releasing_their_graph_nn_library/,olBaa,1539884046,"Github: https://github.com/deepmind/graph_nets Hope it will be updated with more architectures, as right now it's pretty minimal",9,1,False,self,,,,,
1000,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,2,9pbj24,self.MachineLearning,[P] modAL: A modular active learning framework for Python,https://www.reddit.com/r/MachineLearning/comments/9pbj24/p_modal_a_modular_active_learning_framework_for/,cosmic-cortex,1539884789,"Hi there!

I am happy to share [modAL](https://github.com/modAL-python/modAL) with you, which is an active learning framework for Python, developed by me. Active learning is a branch of semi-supervised learning, allowing to increase performance of your machine learning algorithm by intelligently querying you to label the most informative instances. modAL is built on top of scikit-learn, but Keras models are also supported. Check out the [official website](https://modAL-python.github.io/) for tutorials and documentation!

Contributions and feedback are much appreciated!",15,1,False,self,,,,,
1001,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,2,9pbmy0,self.MachineLearning,[N] CFP: AAAI Workshop on Reinforcement Learning in Games,https://www.reddit.com/r/MachineLearning/comments/9pbmy0/n_cfp_aaai_workshop_on_reinforcement_learning_in/,sharky6000,1539885533,"Date: January 27th or 28th, 2019  
Location: Honolulu, Hawaii  
Submission deadline: November 5th, 2018  
Web site: [http://aaai-rlg.mlanctot.info/](http://aaai-rlg.mlanctot.info/)  
 

**Description**  
 

Games provide an abstract and formal model of environments in which  multiple agents interact: each player has a well-defined goal and rules  to describe the effects of interactions among the players. The first  achievements in playing these games at super-human level were attained  with methods that relied on and exploited domain expertise that was  designed manually (e.g. chess, checkers). In recent years, we have seen  examples of general approaches that learn to play these games via  self-play reinforcement learning (RL), as first demonstrated in  Backgammon. While progress has been impressive, we believe we have just  scratched the surface of what is capable, and much work remains to be  done in order to truly understand the algorithms and learning processes  within these environments.  
 

The main objective of the workshop is to bring researchers together to  discuss ideas, preliminary results, and ongoing research in the field of  reinforcement in games.   
 

We invite participants to submit papers, based on but not limited to, the following topics: 

* RL in one-shot games
* RL in turn-based and Markov games
* RL in partially-observable games
* RL in continuous games
* RL in cooperative games
* Deep RL in games
* Combining search and RL in games
* Inverse RL in games
* Foundations, theory, and game-theoretic algorithms for RL
* Opponent / teammate modeling
* Ad-hoc teamwork
* Analyses of learning dynamics in games
* Evolutionary methods for RL in games
* RL in games without the rules  
 

**Structure and Submission Instructions**  


RLG is a 1 full-day workshop. It will start a 60 minute mini-tutorial  covering a brief tour of the history and basics of RL in games, 2-3  invited talks by prominent contributors to the field, paper  presentations, a poster session, and will close with a discussion panel.  
 

Papers must be between 4-8 pages in the AAAI submission format, with the  eighth page containing only references. Papers will be submitted  electronically using Easychair. Accepted papers will not be archival,  and we explicitly allow papers that are concurrently submitted to,  currently under review at, or recently accepted in other conferences /  venues.  
 

Easychair link: [https://easychair.org/conferences/?conf=aaai19rlg](https://easychair.org/conferences/?conf=aaai19rlg)  
 

**Programme Committee**  
 

* David Balduzzi
* Yngvi Bjornnsson
* Michael Bowling
* Noam Brown
* Michael Buro
* Jakob Foerster
* Matthieu Geist
* Johannes Heinrich
* Thomas Hubert
* Emilie Kaufmann
* Ed Lockhart
* Viliam Lisy
* Michael Littman
* Matej Moravcik
* Martin Mueller
* Alex Peysakhovich
* Olivier Pietquin
* Bilal Piot
* Tom Schaul
* Bruno Scherrer
* Gerald Tesauro
* Julian Togelius
* Karl Tuyls
* Vinicius Zambaldi  
 

**Organizers**  
 

Marc Lanctot (DeepMind)  
Julien Perolat (DeepMind)  
Martin Schmid (DeepMind)",0,1,False,self,,,,,
1002,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,3,9pbnwz,arxiv.org,[1810.07382] Analysis of Railway Accidents&amp;#x27; Narratives Using Deep Learning,https://www.reddit.com/r/MachineLearning/comments/9pbnwz/181007382_analysis_of_railway_accidentsx27/,kk7nc,1539885712,,0,1,False,default,,,,,
1003,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,3,9pbqbz,self.MachineLearning,VFI5 Algorithm Implementation,https://www.reddit.com/r/MachineLearning/comments/9pbqbz/vfi5_algorithm_implementation/,bibocas,1539886163,"Hello!!

I'm currently reading ""Learning differential diagnosis of erythemato-squamous diseases using voting feature intervals"" by H. Altay Guvenir et al. and I'm wondering if anyone has ever implemented the VFI5 algorithm. I'm having some difficulties understanding their explanation.

&amp;#x200B;

Thank you",0,1,False,self,,,,,
1004,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,3,9pbwgn,self.MachineLearning,AI fellow programs,https://www.reddit.com/r/MachineLearning/comments/9pbwgn/ai_fellow_programs/,Reqiiblaze,1539887366,[removed],0,1,False,self,,,,,
1005,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,4,9pcapl,self.MachineLearning,[D] What critical ML skills should a ML Product Manager have?,https://www.reddit.com/r/MachineLearning/comments/9pcapl/d_what_critical_ml_skills_should_a_ml_product/,akfs,1539889999,"The age-old question on if a product manager should be technical or not. When it comes to ML, what key concepts should a PM understand if partnering with an engineer to build a consumer facing app that is powered by ML?",6,1,False,self,,,,,
1006,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,4,9pcexz,self.MachineLearning,Any code out there on automatic generation of table of contents/large document structure?,https://www.reddit.com/r/MachineLearning/comments/9pcexz/any_code_out_there_on_automatic_generation_of/,outofusernams,1539890793,"Newbie here, so standard apologies apply...

I'm interested in techniques for automating the generation of a table of contents/hierarchical structure of large documents  - in particular, those that are already very structured (a classic example would be a legal contract with headings, sub-headings etc., the kind that would be generated by Microsoft Word if the document were manually formatted to include an outline and headings).

I could find only two relatively recent papers on the subject (&lt;a href=""http://www.itiis.org/digital-library/manuscript/file/1614/TIIS+Vol+11,+No+2-23.pdf""&gt;one&lt;/a&gt; and &lt;a href=""https://arxiv.org/pdf/1709.00770.pdf""&gt;two&lt;/a&gt;) but no implementing code. 

Is there anything like that out there or am I barking up the wrong tree?",0,1,False,self,,,,,
1007,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,4,9pcmya,self.MachineLearning,e-readers for online papers?,https://www.reddit.com/r/MachineLearning/comments/9pcmya/ereaders_for_online_papers/,wasprobot,1539892367,"I find myself reading research papers online a lot these days. this might be very basic for some of you, but I need to figure this out. Anyone accomplished the following on a tablet/e-reader like device?

1) Navigate to online resources (e.e.g, arxiv) and load pdfs to read?
2) Highlight/bookmark pdfs for future reference (possibly add notes?)
3) Store &amp; organize pdfs on device for future use?

Any help will be greatly appreciated. I am tired of reading on my glaring laptop screen and/or printing and wasting paper.",0,1,False,self,,,,,
1008,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,5,9pcrov,self.MachineLearning,[D] Representative Intelligence,https://www.reddit.com/r/MachineLearning/comments/9pcrov/d_representative_intelligence/,James_Representi,1539893276,"While reading Ludwig Wittgenstein's Tractatus Logico-Philosophicus, first published in English in 1922, I got the idea that machine intelligence could be created by representation. After all, W said that we picture facts to ourselves and a picture is a model of reality. This is representation. In a picture the elements of the picture are the representatives of objects. So if in thinking we use representatives of objects, perhaps a representative of intelligence would be viewed as intelligence by us.

All very philosophical, I know, but I believe this thinking leads to a different method of making software I can talk to, one that doesn't require scripting a response for anything I might say, or mapping a brain's nodes with mathematics and paying for a lot of compute time to train the system. :)

I've created representation of intelligence, and it's available [here](http://representi.com). I'd like to discuss. I'd particularly like to hear how it can be improved.",8,1,False,self,,,,,
1009,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,5,9pd69v,self.MachineLearning,Where can one find a business partner that is technical hands-on with ML/Neural Networks?,https://www.reddit.com/r/MachineLearning/comments/9pd69v/where_can_one_find_a_business_partner_that_is/,nicklesprout,1539896070,,0,1,False,self,,,,,
1010,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,6,9pd9zs,self.MachineLearning,[Discussion] Best multiclass slassification technique (small dataset),https://www.reddit.com/r/MachineLearning/comments/9pd9zs/discussion_best_multiclass_slassification/,t_rex66,1539896782,"I have a project of identification of hand sketched circuit components.

5 classes in total and all will have a small number of training examples.Which technique should be used for the best accuracy possible.

PS: I have to code it in Matlab so keeping that in mind.",0,1,False,self,,,,,
1011,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,7,9pdteu,self.MachineLearning,[Research] What is a nice progression of papers to go from basics of Variational Inference (especially VAEs) to cutting edge research in the area?,https://www.reddit.com/r/MachineLearning/comments/9pdteu/research_what_is_a_nice_progression_of_papers_to/,UltaBeedi,1539900697,"Ideally something like:

* High level concept
* Math
* Applications
* Issues with VI/VAEs
* Sophisticated that address important issues
* Emerging directions and research frontiers",16,1,False,self,,,,,
1012,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,7,9pe3oc,self.MachineLearning,[N] ARTificial : where art meets AI - call for contributions/sponsors,https://www.reddit.com/r/MachineLearning/comments/9pe3oc/n_artificial_where_art_meets_ai_call_for/,artificialmtl,1539902820,"Hello everyone :)

We are a team of non-professional artists who is working on an art exhibit called ARTificial, here in Montreal QC on December 6-7 2018.

We would like to make public the call for contributions that can be found at [artificialmtl.github.io](https://artificialmtl.github.io), our website.

Let us know if you have any questions regarding this project, either on this thread or by email ([artificialmtl@gmail.com](mailto:artificialmtl@gmail.com) ) /DM.

Thank you and hope to see you there !

\-ARTificial MTL

&amp;#x200B;",4,1,False,self,,,,,
1013,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,7,9pe49a,self.MachineLearning,CNN Tensorflow same code different results coursera jupyter notebook/laptop,https://www.reddit.com/r/MachineLearning/comments/9pe49a/cnn_tensorflow_same_code_different_results/,overbit123,1539902945,"I started learning ML and playing around with tensorflow in my spare time and am struggling to determine the cause of an inconsistency I found.  When I run the CNN from the hand gesture classification in the online coursera jupyter notebook, the results are way different then when I run it from my personal laptop (mac pro python script).  All seeds and random initializes are set and are all the same.  Everything is identical until conv2d is first called and then the results are way different, and the accuracy drops by about 20% and trains way slower on my laptop.  

&amp;#x200B;

Would any redditors know why this happens?  I am disappointed I will not be able to train simple CNNs from my machine.",0,1,False,self,,,,,
1014,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,8,9pe8vx,kottongrammer.com,Kotton Grammer Chicago,https://www.reddit.com/r/MachineLearning/comments/9pe8vx/kotton_grammer_chicago/,BiancaDickenb00,1539903907,,0,1,False,default,,,,,
1015,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,8,9peb4g,self.MachineLearning,Created an awesome repo of graph representation learning papers,https://www.reddit.com/r/MachineLearning/comments/9peb4g/created_an_awesome_repo_of_graph_representation/,spuriousregression,1539904394,[removed],0,1,False,https://b.thumbs.redditmedia.com/WsFZoovZioRIx0Y0U7w2ESgQf6vr5KIG7s8J097ARIg.jpg,,,,,
1016,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,8,9pen59,self.MachineLearning,[D] Do you often find striking differences between open source implementations of papers? How do you decide which one to go with?,https://www.reddit.com/r/MachineLearning/comments/9pen59/d_do_you_often_find_striking_differences_between/,Valiox,1539907067,"For example I can find dozen of Wavenet implementations. Assuming I'm not restricting myself to a given framework, how would I go about determining which one is the most faithful to the original paper or the one that generally yields the best performance?",3,1,False,self,,,,,
1017,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,9,9peuvs,self.MachineLearning,Our new ML model beats LSTM,https://www.reddit.com/r/MachineLearning/comments/9peuvs/our_new_ml_model_beats_lstm/,ryoppippi,1539908819,"We developed new ML model inspired by quantum physics, and we started a company.

The training time is x4K faster than LSTM, and the accuracy is the same or higher.

In this demo, our model is running on AWS t2.micro, so it's low power and without GPU.

APIs, libraries are available soon.

Here is our page(sorry there is only Japanese versions rn) [qcore.co.jp](https://qcore.co.jp)

&amp;#x200B;

![video](33teiwy2d1t11 ""Speech detection using our model"")",0,1,False,self,,,,,
1018,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,9,9pevko,self.MachineLearning,ODSC Pass,https://www.reddit.com/r/MachineLearning/comments/9pevko/odsc_pass/,Mohamed_AlMakki,1539908969,[removed],0,1,False,self,,,,,
1019,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,9,9peybn,self.MachineLearning,ODSC Ticket,https://www.reddit.com/r/MachineLearning/comments/9peybn/odsc_ticket/,Mohamed_AlMakki,1539909634,[removed],0,1,False,self,,,,,
1020,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,10,9pfgdw,self.MachineLearning,Tensorpad  1080ti cloud GPU for 0.49$ per hour,https://www.reddit.com/r/MachineLearning/comments/9pfgdw/tensorpad_1080ti_cloud_gpu_for_049_per_hour/,whitezl0,1539913940,[removed],0,1,False,self,,,,,
1021,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,11,9pfu4y,self.MachineLearning,[D] Have anyone tried any of the stuff in tensorflow contrib ? What has your experience been with them?,https://www.reddit.com/r/MachineLearning/comments/9pfu4y/d_have_anyone_tried_any_of_the_stuff_in/,BatmantoshReturns,1539917210,"I am particular interested in 

https://www.tensorflow.org/api_docs/python/tf/contrib/opt/ShampooOptimizer

From the makers of adagrad optimizer, it's supposed to be much better than adagrad. ",9,1,False,self,,,,,
1022,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,11,9pfujw,self.MachineLearning,[D] First steps with brand new data source?,https://www.reddit.com/r/MachineLearning/comments/9pfujw/d_first_steps_with_brand_new_data_source/,zildjiandrummer1,1539917302,"Let's say you just got a dump of a brand new data source that you're tangentially familiar with (you're aware of the type of data but have never worked with it directly). Your goal is to classify this data into N classes using a CNN within a normal time constraint. There's a *real* data set that has X samples, and a very accurately *simulated* data set that has 2X samples. The simulated set covers a wide variety of cases, as does the real set.

Question: Do you start with the very clean and well-constrained simulated set of experiments, go straight to the real data and see what's even possible, or do a hybrid approach right out of the gate?

^^I'm ^^leaving ^^this ^^question ^^extremely ^^broad ^^on ^^purpose",5,1,False,self,,,,,
1023,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,12,9pfxuv,self.MachineLearning,How's researches on Memory Networks going?,https://www.reddit.com/r/MachineLearning/comments/9pfxuv/hows_researches_on_memory_networks_going/,rabbitxuqh,1539918116,[removed],0,1,False,self,,,,,
1024,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,12,9pfz6b,self.MachineLearning,Trouble Loading Images with Keras' ImageDataGenerator(),https://www.reddit.com/r/MachineLearning/comments/9pfz6b/trouble_loading_images_with_keras/,Silver5005,1539918443,[removed],0,1,False,self,,,,,
1025,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,12,9pg75a,self.MachineLearning,Question about dlib and facial landmarking,https://www.reddit.com/r/MachineLearning/comments/9pg75a/question_about_dlib_and_facial_landmarking/,marictdude,1539920349,[removed],0,1,False,self,,,,,
1026,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,13,9pgfxf,github.com,Find this git repo about BERT-pytorch,https://www.reddit.com/r/MachineLearning/comments/9pgfxf/find_this_git_repo_about_bertpytorch/,KorChris,1539922512,,0,1,False,default,,,,,
1027,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,13,9pgirc,self.MachineLearning,[D] why do you add noise when modeling images as continuous data?,https://www.reddit.com/r/MachineLearning/comments/9pgirc/d_why_do_you_add_noise_when_modeling_images_as/,elder_price666,1539923232,"I've been looking through a few repos that model images as continuous data, and most of them

add uniform noise U\[0, 1/256\] before feeding it to a Gaussian likelihood.

Why is this necessary? Why not just model the image data as continuous?

&amp;#x200B;",10,1,False,self,,,,,
1028,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,13,9pgj6l,readyforai.com,The secret of the Chinese team winning the Microsoft COCO Challenge,https://www.reddit.com/r/MachineLearning/comments/9pgj6l/the_secret_of_the_chinese_team_winning_the/,seeryang,1539923339,,0,1,False,https://b.thumbs.redditmedia.com/AyZI8A9Y71xsRpwbBRUgvRY7ZDfXK94_A7cFftYCt-I.jpg,,,,,
1029,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,13,9pgo0v,arxiv.org,[R] LeukoNet: DCT-based CNN architecture for the classification of normal versus Leukemic blasts in B-ALL Cancer,https://www.reddit.com/r/MachineLearning/comments/9pgo0v/r_leukonet_dctbased_cnn_architecture_for_the/,pulkitkumar95,1539924654,,1,1,False,default,,,,,
1030,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,14,9pgq36,analyticsinsight.net,Leveraging Machine Learning Strategies for Hedge Fund Gains | Analytics Insight,https://www.reddit.com/r/MachineLearning/comments/9pgq36/leveraging_machine_learning_strategies_for_hedge/,analyticsinsight,1539925246,,0,1,False,default,,,,,
1031,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,14,9pgryr,github.com,Found the BERT paper implementation pytorch in github,https://www.reddit.com/r/MachineLearning/comments/9pgryr/found_the_bert_paper_implementation_pytorch_in/,KorChris,1539925732,,0,1,False,default,,,,,
1032,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,14,9pgufv,self.MachineLearning,[D] Pytorch Implementation of BERT:Bidirectional Encoder Representations from Transformers,https://www.reddit.com/r/MachineLearning/comments/9pgufv/d_pytorch_implementation_of_bertbidirectional/,codertimo,1539926416,[https://github.com/codertimo/BERT-pytorch](https://github.com/codertimo/BERT-pytorch),0,1,False,self,,,,,
1033,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,14,9pgwwj,xdeal.ml,I found a site that uses Machine Learning to find the best deals from multiple sites,https://www.reddit.com/r/MachineLearning/comments/9pgwwj/i_found_a_site_that_uses_machine_learning_to_find/,indianbois,1539927109,,0,1,False,https://a.thumbs.redditmedia.com/ISCKThEyXTcCEdu4xaLpjjKjlAiwKMn6cEozUwR7zu0.jpg,,,,,
1034,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,14,9ph0lh,self.MachineLearning,"Intuition for the V matrix in the attention block in ""attention is all you need""",https://www.reddit.com/r/MachineLearning/comments/9ph0lh/intuition_for_the_v_matrix_in_the_attention_block/,albert1905,1539928210,[removed],0,1,False,self,,,,,
1035,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,15,9ph64h,koriavinash1.github.io,Unconstrained-Optimization,https://www.reddit.com/r/MachineLearning/comments/9ph64h/unconstrainedoptimization/,koriavinash1,1539929855,,0,1,False,default,,,,,
1036,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,15,9phbew,self.MachineLearning,[D] Why the sponsors of IJCAI are all Chinese companies,https://www.reddit.com/r/MachineLearning/comments/9phbew/d_why_the_sponsors_of_ijcai_are_all_chinese/,Kristery,1539931449,I just saw the website of IJCAI 2019 ([https://ijcai19.org/](https://ijcai19.org/)) and all the sponsors are from China. I mean why there is no company from other countries? The case of AAAI is similar though but not that crazy.,12,1,False,self,,,,,
1037,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,16,9phjik,self.deeplearning,Computational Advertising with Recommender Systems for Targeting and Ranking Ads through Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9phjik/computational_advertising_with_recommender/,arunkumar_bvr,1539933867,,1,1,False,https://b.thumbs.redditmedia.com/0JsdeF_O_Ur4ArvzrMjuepBzr0ErhmClCI2UBMiZ14g.jpg,,,,,
1038,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,16,9phldj,self.deeplearning,Computer Vision with Python through Deep Learning,https://www.reddit.com/r/MachineLearning/comments/9phldj/computer_vision_with_python_through_deep_learning/,arunkumar_bvr,1539934473,,3,1,False,https://b.thumbs.redditmedia.com/gQHojHd7UUynaXcRAs1ujdBNmMv1tx94C4eDm_3V_oM.jpg,,,,,
1039,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,16,9phpbg,self.MachineLearning,"R&amp;D work (Research and Development) on Artificial Intelligence, Machine Learning, and Deep Learning [Discussion] [D] [News] [N] [Research] [R] [Project] [P]",https://www.reddit.com/r/MachineLearning/comments/9phpbg/rd_work_research_and_development_on_artificial/,arunkumar_bvr,1539935596,"u/arunkumar_bvr

https://www.reddit.com/u/arunkumar_bvr?utm_source=reddit-android",3,1,False,self,,,,,
1040,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,17,9phr7d,ndres.me,[D] My approach to solving (almost) any machine learning problem,https://www.reddit.com/r/MachineLearning/comments/9phr7d/d_my_approach_to_solving_almost_any_machine/,Paletton,1539936162,,0,1,False,default,,,,,
1041,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,17,9phuuj,self.MachineLearning,3 easy things that are hard for both humans and machine learning (AI),https://www.reddit.com/r/MachineLearning/comments/9phuuj/3_easy_things_that_are_hard_for_both_humans_and/,techczech,1539937344,[removed],0,1,False,self,,,,,
1042,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,17,9pi00v,self.MachineLearning,Artificial Intelligence with Python through Deep Reinforcement Learning and Other Novel Learning Algorithms,https://www.reddit.com/r/MachineLearning/comments/9pi00v/artificial_intelligence_with_python_through_deep/,arunkumar_bvr,1539938967,[removed],2,1,False,self,,,,,
1043,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,17,9pi0tm,self.MachineLearning,[P] Step by Step Jupyter Notebook to learn basics of ML,https://www.reddit.com/r/MachineLearning/comments/9pi0tm/p_step_by_step_jupyter_notebook_to_learn_basics/,jaleyhd,1539939229,[removed],0,1,False,self,,,,,
1044,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,17,9pi1x2,self.MachineLearning,How do you introduce a simple Keras use case into an organization with no previous Machine Learning experience?,https://www.reddit.com/r/MachineLearning/comments/9pi1x2/how_do_you_introduce_a_simple_keras_use_case_into/,Facts_About_Cats,1539939568,[removed],0,1,False,self,,,,,
1045,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,18,9piali,medium.com,[P] Evolving agents to solve XOR in Pixling World,https://www.reddit.com/r/MachineLearning/comments/9piali/p_evolving_agents_to_solve_xor_in_pixling_world/,FredrikNoren,1539942161,,0,1,False,default,,,,,
1046,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,18,9pic9s,self.MachineLearning,[D] My approach to solving (almost) any machine learning problem,https://www.reddit.com/r/MachineLearning/comments/9pic9s/d_my_approach_to_solving_almost_any_machine/,Paletton,1539942656,"As I've been a freelance machine learning engineer for almost two years now, I thought I'd share a few tips on how to get started on a machine learning problem. So I made a blog post:

[My approach to solving (almost) any machine learning problem](https://ndres.me/post/approach-solve-any-machine-learning/)

&amp;#x200B;

I know that this approach won't work for 100% of the projects. Also, a ML problem is never ""solved"", a solution can always be improved. But I hope this blog post can help people. Let me know what you think !

&amp;#x200B;

&amp;#x200B;",24,1,False,self,,,,,
1047,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,19,9pigny,self.MachineLearning,[D] 3 easy things that are hard for both humans and machine learning (AI),https://www.reddit.com/r/MachineLearning/comments/9pigny/d_3_easy_things_that_are_hard_for_both_humans_and/,techczech,1539943909,"The point of [this post](http://metaphorhacker.net/2018/10/3-easy-things-that-are-hard-for-both-humans-and-ai/) is that while ML is great at dealing with high dimensionality, there are a class of problems that are algorithmically very simple but due to the high dimensionality of the inputs to the base algorithm, current solutions are not as useful (ML or not) as one would expect in real life.

[The post](http://metaphorhacker.net/2018/10/3-easy-things-that-are-hard-for-both-humans-and-ai/) tries to describe in some detail how humans go about  resolving these problems.

The 3 examples are:

1. Dealing with time zones

2. Scheduling meetings

3. Merging and deduping lists

The argument is not that ML cannot help at all, it certainly can, but that it cannot be used to solve the whole process or even enough of its parts to eliminate human intervention altogether. That would require something closer to general AI than anyone is getting to now.

I definitely would like to see some counterexamples and welcome any and all criticisms.",19,1,False,self,,,,,
1048,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,19,9pioqp,towardsdatascience.com,[D] CatBoost overview: Mastering The New Generation of Gradient Boosting,https://www.reddit.com/r/MachineLearning/comments/9pioqp/d_catboost_overview_mastering_the_new_generation/,s0ulmate,1539946194,,0,1,False,https://b.thumbs.redditmedia.com/CYNQr7G6VJtGDq9gjg1AwWfqDvcvKCOKtiv36fONMtI.jpg,,,,,
1049,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,21,9pjh0e,self.MachineLearning,[D]: Pretrained Models that can be used with TF Eager,https://www.reddit.com/r/MachineLearning/comments/9pjh0e/d_pretrained_models_that_can_be_used_with_tf_eager/,gokstudio,1539953134,"Since Google is going to go all in with eager execution starting from TF 2.0, I was curious if there are any repositories (official or otherwise) that can be used in eager execution mode in TF.

&amp;#x200B;

PS

 I know of the existence of \`tfhub\` but according to their repository, they don't support eager execution currently.

Thanks!",8,1,False,self,,,,,
1050,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,22,9pjrfz,youtu.be,Youtube spotted this cover photo for my new video ...and he made an AMAZiNG mistake ,https://www.reddit.com/r/MachineLearning/comments/9pjrfz/youtube_spotted_this_cover_photo_for_my_new_video/,flowish8,1539955355,,0,1,False,https://b.thumbs.redditmedia.com/eAFEUjBVWqiRb8Ssn9HrMsY0iqBQoaflAq89cNQwaGs.jpg,,,,,
1051,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,22,9pjurd,self.MachineLearning,Best Python/Jupyter/PyCharm experience + report generation with Pandoc filters,https://www.reddit.com/r/MachineLearning/comments/9pjurd/best_pythonjupyterpycharm_experience_report/,kiwi0fruit,1539956044,[removed],0,1,False,self,,,,,
1052,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,22,9pk1k2,self.MachineLearning,DataCamp is hiring course instructors,https://www.reddit.com/r/MachineLearning/comments/9pk1k2/datacamp_is_hiring_course_instructors/,emm-kay,1539957396,[removed],0,1,False,self,,,,,
1053,MachineLearning,t5_2r3gv,2018-10-19,2018,10,19,23,9pkcf8,arxiv.org,[R] Private Machine Learning in TensorFlow Using Secure Computation,https://www.reddit.com/r/MachineLearning/comments/9pkcf8/r_private_machine_learning_in_tensorflow_using/,jvmancuso,1539959451,,12,1,False,default,,,,,
1054,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,0,9pkrm8,arxiv.org,[R] Interesting application: DeepLens - Shallow Depth Of Field From A Single Image,https://www.reddit.com/r/MachineLearning/comments/9pkrm8/r_interesting_application_deeplens_shallow_depth/,zhamisen,1539962246,,5,1,False,default,,,,,
1055,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,0,9pkt7w,self.MachineLearning,"[P] Productionizing a machine learning model with an API, and iOS and Watch applications",https://www.reddit.com/r/MachineLearning/comments/9pkt7w/p_productionizing_a_machine_learning_model_with/,Laboratory_one,1539962536,"I had a Tensorflow model which I was ready to move to the next stage of production but had difficulties with some of the standard tools. CoreML and Serving didnt seem to work for my use-case. I believe theyd work if I had structured model inference with the TF graph rather than procedurally. 

To bridge this experience gap, I wrapped up inference in a Python REST API so that I could expose it to the open internet. My exploration can be read here:

https://www.reddit.com/r/reactnative/comments/9pkpdz/productionizing_a_machine_learning_model_with_an/

How would you put a trained ML model into production? Any recommended learning resource?",3,1,False,self,,,,,
1056,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,0,9pkvun,reddit.com,[D] Best Python/Jupyter/PyCharm experience + report generation with Pandoc filters  r/datascience,https://www.reddit.com/r/MachineLearning/comments/9pkvun/d_best_pythonjupyterpycharm_experience_report/,kiwi0fruit,1539963016,,0,1,False,https://b.thumbs.redditmedia.com/60mtOk5iKajDp-vkO8vwO4FCSdkg7nH7RdDBH3knjzc.jpg,,,,,
1057,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,0,9pkxge,self.MachineLearning,Anyone know a good resource for the Perceptron algorithm that will walkthrough what is happening each step?,https://www.reddit.com/r/MachineLearning/comments/9pkxge/anyone_know_a_good_resource_for_the_perceptron/,ghettoyouthsrock,1539963314,[removed],0,1,False,self,,,,,
1058,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,0,9pkzf6,self.MachineLearning,New ML model that beats LSTM.,https://www.reddit.com/r/MachineLearning/comments/9pkzf6/new_ml_model_that_beats_lstm/,ryoppippi,1539963676,"We developed new ML model inspired by quantum physics, and we started a company.

On our model, the training time become x4K faster than LSTM, and the accuracy is the same or higher.

This demo is doing speaker recognition. In this demo, our model is running on AWS t2.micro, so it's low power and without GPU.

APIs, libraries are available soon(Follow our Github [github.com/qcore-info](https://github.com/qcore-info)).

Here is our page(sorry there is only Japanese versions rn) [qcore.co.jp](https://qcore.co.jp)

&amp;#x200B;

![video](yvzgximmw5t11 ""Speaker recognition"")",0,1,False,self,,,,,
1059,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,0,9pl23d,self.MachineLearning,Steps to creating specialised generative art AI? [P},https://www.reddit.com/r/MachineLearning/comments/9pl23d/steps_to_creating_specialised_generative_art_ai_p/,facadepapergirl,1539964165,[removed],0,1,False,self,,,,,
1060,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,1,9pldn2,stats.stackexchange.com,Why is accuracy not the best measure for assessing classification models?,https://www.reddit.com/r/MachineLearning/comments/9pldn2/why_is_accuracy_not_the_best_measure_for/,Comprehend13,1539966219,,1,1,False,default,,,,,
1061,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,1,9plfo1,self.MachineLearning,"How to apply NN to financial time series (not prediction, more game theory)",https://www.reddit.com/r/MachineLearning/comments/9plfo1/how_to_apply_nn_to_financial_time_series_not/,Yogi_DMT,1539966582,"I know this is a question that must be asked every other day but i see that a lot of ML and financial time series seems to apply to predicting the price at X units of time in the future. My question is a little bit different... i'm not trying to predict a future price, i just want to use a NN purely as a game theory of buys and sells. Ie. i want to input a recent history of trade data (ie. 24hr) and i want the output to be a buy, sell, or nothing, not a prediction of what the price will be.

Conceptually i know what i'd like to do (find a NN that would do the above, use that NN to out an action (in inaction) for every slice of data for an entire time series, and then make adjustments based on the resulting profit value.

Any ideas where i could start?",0,1,False,self,,,,,
1062,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,1,9plohm,self.MachineLearning,"Ideas and Information about Artificial Intelligence, Machine Learning, &amp; Deep Learning, and areas akin to AI https://linkedin.com/in/arunkumarramanan u/arunkumar_bvr https://www.reddit.com/u/arunkumar_bvr?utm_source=reddit-android",https://www.reddit.com/r/MachineLearning/comments/9plohm/ideas_and_information_about_artificial/,arunkumar_bvr,1539968146,[removed],0,1,False,self,,,,,
1063,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,1,9plopp,youtu.be,This scientist used machine learning to design a vaccine for HIV. It is one of the 5-6 vaccines to ever make it to human efficacy trials.,https://www.reddit.com/r/MachineLearning/comments/9plopp/this_scientist_used_machine_learning_to_design_a/,philomax,1539968183,,0,1,False,default,,,,,
1064,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,2,9plra5,self.MachineLearning,"I'm new to this field, but very interested in it. I have a thought. Tear it to pieces, and help me learn :)",https://www.reddit.com/r/MachineLearning/comments/9plra5/im_new_to_this_field_but_very_interested_in_it_i/,DrFranklbob,1539968650,[removed],0,1,False,self,,,,,
1065,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,2,9plswa,self.MachineLearning,"Ideas and Information as Suggestion and Recommendation about Artificial Intelligence, Machine Learning, and Deep Learning, and Other Novel Learning Algorithms or Areas related to AI",https://www.reddit.com/r/MachineLearning/comments/9plswa/ideas_and_information_as_suggestion_and/,arunkumar_bvr,1539968941,"Kindly please ping me here on LinkedIn with any ideas/information as Suggestion and Recommendation for my subreddit posts that are related to Artificial Intelligence, Machine Learning, &amp; Deep Learning, and Other Novel Learning Algorithms or areas akin to AI

u/arunkumar_bvr

https://www.reddit.com/u/arunkumar_bvr?utm_source=reddit-android

https://linkedin.com/in/arunkumarramanan

[R] [P] [D]",2,1,False,self,,,,,
1066,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,3,9pmc0g,self.MachineLearning,[D] Neural Network predicts only one class and all output layer activation for testing becomes 0.999~,https://www.reddit.com/r/MachineLearning/comments/9pmc0g/d_neural_network_predicts_only_one_class_and_all/,sarmientoj24,1539972411,"I am currently working on creating a Neural Network in Python and I have been stuck to this problem.

\-  I have balanced my data by upsampling now so data balancing shouldn't be a problem. 

\- For my labels, there are 8 classes and 354 features. I used one-hot vector per sample to transform class/label 4 into 

\[0, 0, 0, 1, 0, 0, 0, 0\]

\- using sigmoid for 2 hidden layers and output, tried using softmax on output layer but has the same problem

&amp;#x200B;

Problem:

\- output layer activation/output for validation becomes something like this \[0.99999997,  0.99999997,  0.99999997,  0.99999997, 0.99999997,  0.99999997,  0.99999997,  0.99999997\]

\- predicts only 1 class for everything (for this latest run, predicts 2)

\- accuracy does not change (because of the thing above)

\- error is fluctuating 

Epoch: 119 Error: \[255.99999638\]

Epoch: 120 Error: \[143.99999741\]

Epoch: 121 Error: \[63.99999831\]

Epoch: 122 Error: \[3.99999957\]

Epoch: 123 Error: \[3.99999955\]

Epoch: 124 Error: \[35.99999874\]

Epoch: 125 Error: \[255.9999965\]

&amp;#x200B;

Code for train()

`def train(self, test_set, test_labels, validation_set, validation_label):`  
`total_error = numpy.zeros((max_epoch, 1))`  


   `size_of_traning_set = len(test_set)`  
`len_test_set_col = len(test_set[0])`  
`len_test_label_col = len(test_labels[0])`  


   `for count in range(0, max_epoch):`  
`random_permutations = numpy.random.permutation(size_of_traning_set)`  
`for count_2 in range(0, size_of_traning_set):`  
`random_index = random_permutations[count_2]`  


`# input vector`  
`x_in = numpy.reshape(test_set[random_index], (len_test_set_col, 1))`  
`# label/output vector`  
`d_out = numpy.reshape(test_labels[random_index], (len_test_label_col, 1))`  
`# forward propagation`  


`# 1st hidden layer`  
`v_hidden_layer_1 = numpy.add(numpy.dot(self.layer_one_weights, x_in), self.layer_one_bias)`  
`y_hidden_layer_1 = compute_activation(v_hidden_layer_1)`  


`# 2nd hidden layer`  
`v_hidden_layer_2 = numpy.add(numpy.dot(self.layer_two_weights, y_hidden_layer_1), self.layer_two_bias)`  
`y_hidden_layer_2 = compute_activation(v_hidden_layer_2)`  


`v_output_layer = numpy.add(numpy.dot(self.output_layer_weights, y_hidden_layer_2), self.output_layer_bias)`  
`final_output = compute_activation(v_output_layer)`  
`error_vector = d_out - final_output`  


`# compute gradient in output layer`  
`delta_output_x = numpy.multiply(error_vector, final_output)`  
`one_minus_out = 1 - final_output`  
`delta_output = numpy.multiply(delta_output_x, one_minus_out)`  


`# compute gradient in hidden layer 2`  
`one_minus_y_h2 = 1 - y_hidden_layer_2`  
`output_layer_weights_trans = numpy.transpose(self.output_layer_weights)`  
`deriv_hidden_layer_2_x = numpy.multiply(y_hidden_layer_2, one_minus_y_h2)`  
`deriv_out_layer = numpy.dot(output_layer_weights_trans, delta_output)`  
`delta_hidden_layer_2 = numpy.multiply(deriv_hidden_layer_2_x, deriv_out_layer)`  


`# compute gradient in hidden layer 1`  
`one_minus_y_h1 = 1 - y_hidden_layer_1`  
`hidden_layer_2_weights_trans = numpy.transpose(self.layer_two_weights)`  
`deriv_hidden_layer_1_x = numpy.multiply(y_hidden_layer_1, one_minus_y_h1)`  
`deriv_layer_2 = numpy.dot(hidden_layer_2_weights_trans, delta_hidden_layer_2)`  
`delta_hidden_layer_1 = numpy.multiply(deriv_hidden_layer_1_x, deriv_layer_2)`  


`# update weights and biases of output layer`  
`self.output_layer_weights = self.output_layer_weights + \`  
`numpy.multiply(self.learning_rate, numpy.dot(delta_output,`  
`numpy.reshape(y_hidden_layer_2, (1, self.number_of_layer_2))))`  
`self.output_layer_bias = self.output_layer_bias + numpy.multiply(self.learning_rate, delta_output)`  


`# update weights and biases of hidden layer 2`  
`self.layer_two_weights = self.layer_two_weights + \`  
`numpy.multiply(self.learning_rate, numpy.dot(delta_hidden_layer_2,`  
`numpy.reshape(y_hidden_layer_1, (1, self.number_of_layer_1))))`  
`self.layer_two_bias = self.layer_two_bias + numpy.multiply(self.learning_rate, delta_hidden_layer_2)`  


`# update weights and biases of hidden layer 1`  
`self.layer_one_weights = self.layer_one_weights + \`  
`numpy.multiply(self.learning_rate, numpy.dot(delta_hidden_layer_1,`  
`numpy.reshape(x_in, (1, self.number_of_inputs))))`  
`self.layer_one_bias = self.layer_one_bias + numpy.multiply(self.learning_rate, delta_hidden_layer_1)`  


`err_sum = numpy.multiply(error_vector, error_vector)`  
`err_sum = numpy.divide(err_sum, 2)`  
`total_error[count] = total_error[count] + numpy.sum(err_sum)`  


`print('Epoch: {} Error: {}'.format(count, total_error[count]))`  


`if count % 100 == 0 and count != 0:`

`self.validate(validation_set, validation_label)`

&amp;#x200B;

I'm actually trying to mimic this behavior:

&amp;#x200B;

https://i.redd.it/a6ms8e82n6t11.png

Any insights?

&amp;#x200B;",1,1,False,https://b.thumbs.redditmedia.com/W2NxRLsOwVQjDCgsZvonqDpAtZeGT4amF0LkkF7lRtQ.jpg,,,,,
1067,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,3,9pmn1c,self.MachineLearning,Computational neuroscience and machine learning,https://www.reddit.com/r/MachineLearning/comments/9pmn1c/computational_neuroscience_and_machine_learning/,deathofamorty,1539974396,[removed],0,1,False,self,,,,,
1068,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,3,9pmoca,self.MachineLearning,[D] How powerful is unsupervised clustering? Is it capable of deep understanding like supervised NNs?,https://www.reddit.com/r/MachineLearning/comments/9pmoca/d_how_powerful_is_unsupervised_clustering_is_it/,lefty_cz,1539974639,"Example: supervised learning is able to generate classical music seemingly from given artist. Supervised deep neural networks are capable of learning deep meaning in the data and utilizing it. 

Is unsupervised learning capable of similar level of understanding and perhaps cluster music into groups written by similar authors without providing the author as label?  

The unsupervised clustering techniques I am aware of are only able to cluster music based on some obvious 'shallow' features like note pitch range or track length. It seems that proper embedding (learned through auto-encoder for example) could be able to improve the classification strength, but still nowhere close supervised learning performance.

What is your opinion on unsupervised learning strength? Or how would you solve the music clustering task?

&amp;#x200B;

&amp;#x200B;",13,1,False,self,,,,,
1069,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,3,9pmqya,self.MachineLearning,[D] Computational Neuroscience and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9pmqya/d_computational_neuroscience_and_machine_learning/,deathofamorty,1539975107,"Are there any computational neuroscientists here?

What do you use machine learning for?

Do you ever submit papers to machine learning journals?

What has your career path been and what is your area of research?

I am finishing my CS undergrad, and I want to do a phd relating to biologically plausible machine learning algorithms. Computational Neuroscience looks like the right direction, but I don't really know the layout of the field. I ultimately want to be applying neuroscience to machine learning, and I am a bit concerned a CompNeuro phd would push me into research for clinical applications or pure neuroscience research without the CS/ML component that I really enjoy.",27,1,False,self,,,,,
1070,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,4,9pmvx9,self.learnmachinelearning,Learn Machine Learning step by step for FREE. BEST RESOURCE,https://www.reddit.com/r/MachineLearning/comments/9pmvx9/learn_machine_learning_step_by_step_for_free_best/,iamarmaan,1539975978,,0,1,False,default,,,,,
1071,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,4,9pn23x,self.MachineLearning,Meetup: Artificial Intelligence in Brain Imaging,https://www.reddit.com/r/MachineLearning/comments/9pn23x/meetup_artificial_intelligence_in_brain_imaging/,FullOfGraceJones,1539977101,"Date: Oct. 25

Time: 6:00pm EST - 7:45pm EST

Place: Qplum, 185 Hudson St #1620, Jersey City, NJ 07311

Speaker: Russell Hanson is currently Chief Scientific Officer of Endjinn a Consensys Spoke company. Previously he was a professor of Genetics and Genomic Sciences at the Mount Sinai School of Medicine and also serves as the CSO of Brain Backups. Brain Backups develops technologies in imaging and artificial intelligence to analyze the brain at unprecedented scales and resolution. Previously he held positions at Harvard, MIT, the Danish Technical University, and Reed College. In his spare time he likes motorcycling and paragliding.

Description: Without AI, human pathologists could take lifetimes to systematically label and annotate all of the neuroanatomical features of the brain. With it, we are making quick work of laying bare the intimate secrets of the complex human brain. This, in turn, is accelerating the creation of new products, services, and businesses for health, wellness, and anti-aging. More details [here](https://www.meetup.com/Data-Science-Fintech-JC-NY/events/255393303/). 

*Processing img 3nun33s117t11...*",0,1,False,self,,,,,
1072,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,4,9pn250,self.MachineLearning,Last Elective Choice,https://www.reddit.com/r/MachineLearning/comments/9pn250/last_elective_choice/,QuietLie,1539977107,[removed],0,1,False,self,,,,,
1073,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,4,9pn80d,self.MachineLearning,What method would you use for creating a basket of goods to predict a future raw material index for pricing?,https://www.reddit.com/r/MachineLearning/comments/9pn80d/what_method_would_you_use_for_creating_a_basket/,Vaslo,1539978191,[removed],0,1,False,self,,,,,
1074,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,5,9pnduo,self.MachineLearning,What to do when some values are missing in sequential data for training?,https://www.reddit.com/r/MachineLearning/comments/9pnduo/what_to_do_when_some_values_are_missing_in/,torlakx,1539979279,[removed],0,1,False,self,,,,,
1075,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,5,9pnl33,self.MachineLearning,Product-ising Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9pnl33/productising_machine_learning/,BackgroundChemist,1539980613,"I know this sub is mostly research, but has any one experience of selling products with machine learning at their heart ? 

 There's some range of options between 'integrate our product into your environment'  and the equivalent of shrink-wrapped software.  The integration option implies the sale has a longer term 'getting to know you' process but its slower and more bespoke.  

 But in either case, how do you handle training/re-training for a given customer's environment ?

Otherwise I'm thinking of putting the product inside a cloud and providing it as a black-box service, but that doesn't work always for some customers, large volumes of data, or short latency tasks.  This avoids some concerns about protecting my IP and supporting somebody else's on-premises installation.

All comments and experience you can share would be appreciated.  

&amp;#x200B;",0,1,False,self,,,,,
1076,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,5,9pnr35,self.MachineLearning,AI Scholars Programs,https://www.reddit.com/r/MachineLearning/comments/9pnr35/ai_scholars_programs/,Reqiiblaze,1539981723,"Can you list all the AI, ML and DL fellow programs for international students (preferably for Undergraduate students)
",0,1,False,self,,,,,
1077,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,5,9pntro,self.MachineLearning,47 New External Data Science / Machine Learning Resources and Articles,https://www.reddit.com/r/MachineLearning/comments/9pntro/47_new_external_data_science_machine_learning/,andrea_manero,1539982213,r/http://www.datasciencecentral.com/profiles/blogs/47-new-external-data-sclience-machine-learning-resources-and-arti,0,1,False,self,,,,,
1078,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,6,9pnxyu,self.MachineLearning,Why Cognitive Systems should combine Machine Learning with Semantic Technologies,https://www.reddit.com/r/MachineLearning/comments/9pnxyu/why_cognitive_systems_should_combine_machine/,andrea_manero,1539983000,[removed],0,1,False,self,,,,,
1079,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,8,9ppa46,self.MachineLearning,[D] Freezing weights in tensorflow to achieve particular output,https://www.reddit.com/r/MachineLearning/comments/9ppa46/d_freezing_weights_in_tensorflow_to_achieve/,captaincyypher,1539992876,"Is there a way in tensorflow to achieve a fixed output for a particular input? Let's say f(1) = 0. 

I still want to train the neural network with data and optimize the weights, however, with the restriction to get some fixed outputs at some points.

&amp;#x200B;",8,1,False,self,,,,,
1080,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,8,9ppbpj,self.MachineLearning,Machine Learning on Images,https://www.reddit.com/r/MachineLearning/comments/9ppbpj/machine_learning_on_images/,BitKrow13,1539993236,[removed],0,1,False,self,,,,,
1081,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,10,9ppx16,self.MachineLearning,Announcing a 128-dataset archive of time series datasets,https://www.reddit.com/r/MachineLearning/comments/9ppx16/announcing_a_128dataset_archive_of_time_series/,eamonnkeogh,1539998155,"Dear Friends.

We are delighted to announce a new, one hundred twenty-eight dataset archive of time series datasets [a].

The archive contains many interesting datasets, including a gesture dataset featuring the same two actors, but recorded 16 years apart! (we are nothing if not patient!).

The datasets are mostly designed for testing classification and clustering algorithms, but we are sure that the creative community will find other uses for it.

The archive is accompanied by a paper. Beyond explaining this resource, this paper offers pragmatic advice to anyone who may wish to evaluate a new algorithm on the archive. In addition, the paper makes a novel and actionable claim: of the hundreds of papers that show an improvement over the standard baseline (1-Nearest Neighbor classification), a large fraction may be misattributing the reasons for their improvement). 

The archive is current in Beta. We welcome feedback. 

Best wishes

The UCR Team

[a] https://www.cs.ucr.edu/~eamonn/time_series_data_2018/    
",0,1,False,self,,,,,
1082,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,10,9ppybj,self.MachineLearning,What's the best activation function for neural network machine learning?,https://www.reddit.com/r/MachineLearning/comments/9ppybj/whats_the_best_activation_function_for_neural/,Polybagel,1539998463,[removed],0,1,False,self,,,,,
1083,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,10,9pq12q,nerdynaut.com,Naiad  Timely Dataflow Model,https://www.reddit.com/r/MachineLearning/comments/9pq12q/naiad_timely_dataflow_model/,dcshehan,1539999138,,0,1,False,default,,,,,
1084,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,10,9pq44p,self.MachineLearning,Please help me in finding a good project,https://www.reddit.com/r/MachineLearning/comments/9pq44p/please_help_me_in_finding_a_good_project/,YoYoVaTsA,1539999877,[removed],0,1,False,self,,,,,
1085,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,10,9pq4kk,self.MachineLearning,how to change this model output from float to string ?,https://www.reddit.com/r/MachineLearning/comments/9pq4kk/how_to_change_this_model_output_from_float_to/,asda43asdf23423,1539999985,[removed],0,1,False,self,,,,,
1086,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,10,9pq5yf,youtube.com,Support Vector Machines - THE MATH YOU SHOULD KNOW,https://www.reddit.com/r/MachineLearning/comments/9pq5yf/support_vector_machines_the_math_you_should_know/,ajhalthor,1540000339,,0,1,False,default,,,,,
1087,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,11,9pq9fe,self.MachineLearning,[P] Wug Test (predict plural forms of fake English nouns),https://www.reddit.com/r/MachineLearning/comments/9pq9fe/p_wug_test_predict_plural_forms_of_fake_english/,damnedharvey,1540001178,"[github.com/damtharvey/wug-test/](https://github.com/damtharvey/wug-test/)

I'm a noob and this is my first GitHub project, so I'd appreciate any feedback. I'm a squishy humanities major, so I just learned Python about a year ago. I couldn't find a [Wug Test](https://en.wikipedia.org/wiki/Jean_Berko_Gleason#Children.27s_learning_of_English_morphology.E2.80.8D.E2.80.94.E2.80.8Cthe_Wug_Test) given to machines, so I decided to do it as my first project. It's probably really dumb compared to stuff you usually see here, but maybe someone will find the arpabet2ipa module useful.",14,1,False,self,,,,,
1088,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,11,9pqf5d,self.MachineLearning,"a lying down hourglass symbol, what is it?",https://www.reddit.com/r/MachineLearning/comments/9pqf5d/a_lying_down_hourglass_symbol_what_is_it/,DeepWeaver,1540002594,[removed],1,1,False,self,,,,,
1089,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,12,9pqneb,self.MachineLearning,How do I not get lost in learning resources...,https://www.reddit.com/r/MachineLearning/comments/9pqneb/how_do_i_not_get_lost_in_learning_resources/,dondraper36,1540004690,[removed],0,1,False,self,,,,,
1090,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,12,9pqwl1,christies.com,Christie's auctions its first AI-generated portrait,https://www.reddit.com/r/MachineLearning/comments/9pqwl1/christies_auctions_its_first_aigenerated_portrait/,robot_most_human,1540007134,,0,1,False,https://b.thumbs.redditmedia.com/pl-rSHmDFYR6tiHfRjj48O5_LAzYssVcXbEUf5QUY4U.jpg,,,,,
1091,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,15,9prro4,self.MachineLearning,[D] What are some tips for someone who is visiting a top conference for the first time?,https://www.reddit.com/r/MachineLearning/comments/9prro4/d_what_are_some_tips_for_someone_who_is_visiting/,Conference_Visitor,1540015972,I am an undergraduate student doing some NLP research. I will be attending EMNLP 2018 as my first conference. What are some things that I should keep in mind so that I can maximise the benefit of attending the conference?,18,1,False,self,,,,,
1092,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,15,9prtnp,self.MachineLearning,Hi please help me!!,https://www.reddit.com/r/MachineLearning/comments/9prtnp/hi_please_help_me/,nathaliacecca266,1540016586,[removed],0,1,False,self,,,,,
1093,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,15,9prwcg,self.MachineLearning,"When you sell your trained model to a company, what do you actually do ?",https://www.reddit.com/r/MachineLearning/comments/9prwcg/when_you_sell_your_trained_model_to_a_company/,RaccoonTeachesYou,1540017414,[removed],0,1,False,self,,,,,
1094,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,16,9ps6ks,youtube.com,Backprop and compute graph tutorial,https://www.reddit.com/r/MachineLearning/comments/9ps6ks/backprop_and_compute_graph_tutorial/,avilay,1540020626,,1,1,False,default,,,,,
1095,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,16,9ps6t5,self.MachineLearning,Where can I find code for winning/top models on kaggle?,https://www.reddit.com/r/MachineLearning/comments/9ps6t5/where_can_i_find_code_for_winningtop_models_on/,BombBurper,1540020705,[removed],0,1,False,self,,,,,
1096,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,16,9ps8wp,self.MachineLearning,Backprop and compute graph tutorial,https://www.reddit.com/r/MachineLearning/comments/9ps8wp/backprop_and_compute_graph_tutorial/,avilay,1540021385,[removed],0,1,False,self,,,,,
1097,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,17,9psec0,medium.com,GANs beyond generation: 7 alternative use cases,https://www.reddit.com/r/MachineLearning/comments/9psec0/gans_beyond_generation_7_alternative_use_cases/,rachnogstyle,1540023187,,0,1,False,default,,,,,
1098,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,17,9psm8l,self.MachineLearning,What's your setup for doing ML research using cloud servers?,https://www.reddit.com/r/MachineLearning/comments/9psm8l/whats_your_setup_for_doing_ml_research_using/,bluecoffee,1540025851,[removed],0,1,False,self,,,,,
1099,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,19,9pt63k,self.MachineLearning,Should I learn statics at first?,https://www.reddit.com/r/MachineLearning/comments/9pt63k/should_i_learn_statics_at_first/,Alkemist11111,1540032349,[removed],0,1,False,self,,,,,
1100,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,22,9pu1av,self.MachineLearning,[D] Over-reliance on a single feature.,https://www.reddit.com/r/MachineLearning/comments/9pu1av/d_overreliance_on_a_single_feature/,mac_cumhaill,1540041240,"I have a supervised ML problem, a dataset which contains 24 features (1600\~ observations).

I've trained a Linear SVC model on the data and have reasonable accuracy, about 13%\~ above majority class baseline.

**However** if I remove 23 of the 24 features, I get about 1% less accuracy, i've looked at the feature weights and essentially all of the power is coming from a single feature. 

&amp;#x200B;

In terms of building a model that can generalise to future unknown datapoints, I know just having one feature in the model isn't acceptable. (This is an academic publication btw). 

&amp;#x200B;

My current ideas are to deliberately reduce the weight of that feature using some form of regularizer. 

&amp;#x200B;

Has anyone alternative suggestions?  ",21,1,False,self,,,,,
1101,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,22,9pu57v,i.redd.it,Data Scientists now earn more than CAs ?,https://www.reddit.com/r/MachineLearning/comments/9pu57v/data_scientists_now_earn_more_than_cas/,myinnos,1540042195,,0,1,False,https://b.thumbs.redditmedia.com/8AA7OL8Qllx-6SLq18ZS7S7J27KQqTFBc8l-zFPkGqo.jpg,,,,,
1102,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,23,9pugo6,self.MachineLearning,Application of Machine learning in Travel,https://www.reddit.com/r/MachineLearning/comments/9pugo6/application_of_machine_learning_in_travel/,ankitm1,1540044858,[removed],0,1,False,self,,,,,
1103,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,23,9pujx9,self.MachineLearning,A telegram group for resources for ML/DL,https://www.reddit.com/r/MachineLearning/comments/9pujx9/a_telegram_group_for_resources_for_mldl/,ank_itsharma,1540045664,[removed],1,1,False,self,,,,,
1104,MachineLearning,t5_2r3gv,2018-10-20,2018,10,20,23,9puki3,self.MachineLearning,[P] Application of Machine learning in Travel,https://www.reddit.com/r/MachineLearning/comments/9puki3/p_application_of_machine_learning_in_travel/,ankitm1,1540045798,[removed],0,1,False,self,,,,,
1105,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,0,9puunh,sinxloud.com,"If you want to learn R for Data Science, take a few of these classes",https://www.reddit.com/r/MachineLearning/comments/9puunh/if_you_want_to_learn_r_for_data_science_take_a/,skj8,1540048054,,0,1,False,https://a.thumbs.redditmedia.com/s9T6wdXq5KCxj93zBmi4S0uKmvzS9s2TaKTpLtBt4K0.jpg,,,,,
1106,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,0,9puxym,self.MachineLearning,An Anime recommendation model!!!!!!,https://www.reddit.com/r/MachineLearning/comments/9puxym/an_anime_recommendation_model/,dhanushyp,1540048790,"So I was hanging out with my friends and it came to my notice that the concept of recommending someone an anime to watch based on their previous interests or what they like is kinda hard.

People have a broad spectrum of what they feel or like about something

So what there could be a model that could fetch data from the anime and the user to apply deep learning and ML to get the output

&amp;#x200B;

The problem I'm facing is related to the raw data organizing part

How do you compare or what logic do you use to connect One anime or Book or anything To what someone would like watching?

&amp;#x200B;",0,1,False,self,,,,,
1107,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,0,9pv0ff,self.MachineLearning,[P]: Backprop and compute graph tutorial,https://www.reddit.com/r/MachineLearning/comments/9pv0ff/p_backprop_and_compute_graph_tutorial/,avilay,1540049326,"We take things like compute graphs and backprop for granted when using auto-differentiators like Pytorch's autograd. For the more curious amongst us, I created this tutorial to understand the underpinnings of these very fundamental concepts in ML. I hope you enjoy learning from it as much as I enjoyed making it :-)

[https://www.youtube.com/playlist?list=PLWv7dKcFUITuTPs-PYrRWYRzFrIxsR4ru](https://www.youtube.com/playlist?list=PLWv7dKcFUITuTPs-PYrRWYRzFrIxsR4ru)",2,1,False,self,,,,,
1108,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,0,9pv1h3,i.redd.it,Bounding boxes in YOLO Model,https://www.reddit.com/r/MachineLearning/comments/9pv1h3/bounding_boxes_in_yolo_model/,CSGOvelocity,1540049534,,0,1,False,default,,,,,
1109,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,0,9pv1pz,i.redd.it,[D] Bounding boxes in YOLO Model,https://www.reddit.com/r/MachineLearning/comments/9pv1pz/d_bounding_boxes_in_yolo_model/,CSGOvelocity,1540049593,,0,1,False,default,,,,,
1110,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,0,9pv1yx,self.MachineLearning,[D] Bounding Boxes in yolo model,https://www.reddit.com/r/MachineLearning/comments/9pv1yx/d_bounding_boxes_in_yolo_model/,CSGOvelocity,1540049650," 

The YOLO model splits the image into smaller boxes and each box is responsible for predicting 5 bounding boxes.

My question is are the bounding boxes predefined with respect to the dimensions of the smaller boxes in the grid ?

Like  for example if the smaller grid cell is located at say 50x50 (the  center of it) then the bounding boxes should be at (50+5)x(50+5) or  something like that

If not then how do the bounding boxes come to be ?

Also, does the model divide the initial image into a grid of smaller boxes ?

Paper - [https://arxiv.org/pdf/1506.02640.pdf](https://arxiv.org/pdf/1506.02640.pdf)

![img](3nu980xr0dt11)",5,1,False,self,,,,,
1111,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,0,9pv61q,paperswithcode.com,ML research papers with code implementation,https://www.reddit.com/r/MachineLearning/comments/9pv61q/ml_research_papers_with_code_implementation/,dronecub,1540050558,,0,1,False,default,,,,,
1112,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,1,9pvawc,washingtonpost.com,"Please no politics - this is a question about the underlying algorithm cited in the article (created by the author, who compared it to Georgia's ""Exact Match"" law). Anyone want to share experience with probabilistic name matching approaches?",https://www.reddit.com/r/MachineLearning/comments/9pvawc/please_no_politics_this_is_a_question_about_the/,androbot,1540051567,,1,1,False,default,,,,,
1113,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,1,9pvc6g,self.MachineLearning,Question about necessities for feature layers,https://www.reddit.com/r/MachineLearning/comments/9pvc6g/question_about_necessities_for_feature_layers/,Poo-et,1540051819,[removed],0,1,False,self,,,,,
1114,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,1,9pvm9c,self.MachineLearning,AdamW vs Adam,https://www.reddit.com/r/MachineLearning/comments/9pvm9c/adamw_vs_adam/,Botekin,1540053921,[removed],0,1,False,self,,,,,
1115,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,2,9pvuwg,blog.google,Google - A new course to teach people about fairness in machine learning,https://www.reddit.com/r/MachineLearning/comments/9pvuwg/google_a_new_course_to_teach_people_about/,ramblinscarecrow,1540055695,,0,1,False,https://b.thumbs.redditmedia.com/tXvS-MWH2V6jOhTRXelec_VdLgJ8EC0w7S_VMhGsSks.jpg,,,,,
1116,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,2,9pvyug,self.MachineLearning,[R] Run OpenAI Retro online,https://www.reddit.com/r/MachineLearning/comments/9pvyug/r_run_openai_retro_online/,CrazyKing11,1540056522,"Hey i am using OpenAI to train some games, now i am asking if there is a possibility to let ir train online.

I found [spell.run](https://spell.run), but i couldnt get it to work cause it needs the roms. Is it possible to do it with spell? or is there something else out there that i can use? (if possible for free)",1,1,False,self,,,,,
1117,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,2,9pvyyp,self.blockchain_and_ai,Blockchain and AI - Possible Synergy?,https://www.reddit.com/r/MachineLearning/comments/9pvyyp/blockchain_and_ai_possible_synergy/,lepton99,1540056543,,0,1,False,https://b.thumbs.redditmedia.com/3yvWgpXPEo9q45hGDXGy2oBc_Fdz9ngFGRpbbBNFF0w.jpg,,,,,
1118,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,3,9pwj1d,self.MachineLearning,NOOB: a question about features,https://www.reddit.com/r/MachineLearning/comments/9pwj1d/noob_a_question_about_features/,AlanRoofies,1540060395,[removed],0,1,False,self,,,,,
1119,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,3,9pwkwp,self.MachineLearning,can Neural networks be trained to break Symmetric encryption with enough data?,https://www.reddit.com/r/MachineLearning/comments/9pwkwp/can_neural_networks_be_trained_to_break_symmetric/,logan2503,1540060730,"is it possible for Neural Networks to deencrypt a folder with 500 images if i use some images ""enrypted and its orignal"" to train NN?? ",0,1,False,self,,,,,
1120,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,3,9pwpjf,self.MachineLearning,Beginner`s Question: Where to place Deep Learning?,https://www.reddit.com/r/MachineLearning/comments/9pwpjf/beginners_question_where_to_place_deep_learning/,andrelandgraf,1540061638,[removed],0,1,False,self,,,,,
1121,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,3,9pwqxh,self.MachineLearning,"Caesar Robot Platform for Research and Education: Human Arm Size, Vision Sensors, Super Programmable: $5K",https://www.reddit.com/r/MachineLearning/comments/9pwqxh/caesar_robot_platform_for_research_and_education/,EmpiricalAutomation,1540061917,[removed],0,1,False,self,,,,,
1122,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,4,9pwvdv,self.MachineLearning,[D] How can I use edge-type embeddings to better predict edges between nodes?,https://www.reddit.com/r/MachineLearning/comments/9pwvdv/d_how_can_i_use_edgetype_embeddings_to_better/,hates_pockets,1540062771,"First off, sorry if this is not the right place/way to post one of these. This is my first time writing on reddit.

I'm working on a research project which, as a side-effect, is producing edge-type embeddings as well as node embeddings for heterogeneous graphs.

At the moment, I'm evaluating it in a similar way to [this paper](http://snap.stanford.edu/decagon/), by concatenating the nodes and training a logistic regression classifier for each edge type, but besides it's problems of not working well for less common edge types, I feel like I'm missing out on the information embedded on the edge-types.

(I also asked on quora, but due to me not having an IQ of over 255, it didn't attract any attention)",7,1,False,self,,,,,
1123,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,4,9pwwe5,self.MachineLearning,Extending DTW 1-NN Classification to On-line Scenario,https://www.reddit.com/r/MachineLearning/comments/9pwwe5/extending_dtw_1nn_classification_to_online/,pig_newton1,1540062975,[removed],0,1,False,self,,,,,
1124,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,4,9px83r,self.MachineLearning,[D] Anomaly detection and causal analysis (?),https://www.reddit.com/r/MachineLearning/comments/9px83r/d_anomaly_detection_and_causal_analysis/,IborkedyourGPU,1540065372,"I want to create an anomaly detection model for a multivariate time series **x**(t), and that's the easy part (there are literally thousands of models to choose from). The hard part is that, once I catch an anomaly, I'd like to be able to find out which component(s) of **x**(t) contributed the most to the anomaly. I have some ground truth on which to train the model (i.e., multivariate time series where I introduced a disturbance on one or more components of **x**(t) at some time t). However, the model should be unsupervised, because the data I will be getting in the future aren't labeled: I will receive some ""normal behavior"" data to train my model, and then the model will have to be able to detect deviation from normal behavior on future data, **as well as** identify the components related to the anomaly.

All the models I tried up to now do a great job of detecting the anomalies, but an incredibly lousy job of detecting the cause(s) of the anomalies. Basically, they don't understand which component was perturbed: they attribute the cause of the disturbance either to the wrong components, or to a very wide subset of components, including the right ones. 

I'm starting to suspect the problem is ill-posed, i.e., it's actually **impossible** to learn which component is perturbed, if I train my model only on unperturbed data. Am I right? Pointers to relevant literature, anyone? I could find heaps of stuff on anomaly detection for multivariate time series, but literally zero papers on attributing the cause of the anomaly to one or more components of the time series vector.",13,1,False,self,,,,,
1125,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,6,9py0og,self.MachineLearning,I need some help about rankboost,https://www.reddit.com/r/MachineLearning/comments/9py0og/i_need_some_help_about_rankboost/,nader002,1540071307,"Good morning everyone 

i have a small request  i m trying to find a practical exemple about the rankboost algorithm  i looked all over the internet

but i didnt find what i m looking for i found about the adaranking and other types , which lead me to ask for your help 

i m hoping that the community can give me anything about this algorithm thankyou &lt;3",0,1,False,self,,,,,
1126,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,6,9py4l6,self.MachineLearning,Trade-off between taking courses and working on personal projects or kaggle challenges,https://www.reddit.com/r/MachineLearning/comments/9py4l6/tradeoff_between_taking_courses_and_working_on/,imscaredofpuppies,1540072166,"I always want to learn new stuff and deepen my knowledge in Machine Learning (for example: take the Stanford Computer Vision course, read ESL, learn more about Reinforcement Learning, etc.). I also want to work on kaggle challenges and personal projects. The thing is, I find it really hard to allocate time for both tasks, and I feel like when I'm trying to do both, I don't really achieve anything in any.

Do you guys also run into this issue? How do you handle it?",0,1,False,self,,,,,
1127,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,7,9pycoo,github.com,[P] Chaos Games Driven by Popular ML Datasets,https://www.reddit.com/r/MachineLearning/comments/9pycoo/p_chaos_games_driven_by_popular_ml_datasets/,underPanther,1540073952,,0,1,False,default,,,,,
1128,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,8,9pyx0e,self.MachineLearning,Good mobo for 12+ card rig?,https://www.reddit.com/r/MachineLearning/comments/9pyx0e/good_mobo_for_12_card_rig/,oDaftDank,1540078513,[removed],0,1,False,self,,,,,
1129,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,8,9pz00c,self.MachineLearning,[P] Good mobo for 12+ card rig?,https://www.reddit.com/r/MachineLearning/comments/9pz00c/p_good_mobo_for_12_card_rig/,oDaftDank,1540079214,"Hey everyone, I am trying to put together possibly a 12 card 1070ti rig and also possibly another 1080ti rig. I have all the components except for a proper motherboard. I'm looking for a motherboard that will support 128gb or more of RAM and enough PCI-e slots for 12 cards. I was originally looking at using an Intel Xeon E5-2650 v4 processor. Any suggestions would be much appreciated :) ",11,1,False,self,,,,,
1130,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,10,9pzjbb,self.MachineLearning,Best approach to handle multi-class text classification on imbalanced data?,https://www.reddit.com/r/MachineLearning/comments/9pzjbb/best_approach_to_handle_multiclass_text/,hemangb,1540083979,[removed],0,1,False,self,,,,,
1131,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,11,9pzwmr,self.MachineLearning,Finding Relationship Between Questionnare's Item,https://www.reddit.com/r/MachineLearning/comments/9pzwmr/finding_relationship_between_questionnares_item/,imperativa,1540087421,"Let's say i work in an organization that do hundreds of surveys each year. The problem is, each survey is created in such way that most of them does not have proper info about what other survey do so sometimes questions asked repeteadly in more than one survey (although sometimes the same textual question asked with different concept&amp;definition and possible answers).

What kind of ML (NLP) technique(s) can i use here?
",0,1,False,self,,,,,
1132,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,11,9q03q8,self.MachineLearning,[D] Finding Relationship Between Questionnare's Item,https://www.reddit.com/r/MachineLearning/comments/9q03q8/d_finding_relationship_between_questionnares_item/,imperativa,1540089178,"Let's say i work in an organization that do hundreds of surveys each year. The problem is, each survey is created in such way that most of them does not have proper info about what other survey do so sometimes questions asked repeteadly in more than one survey (although sometimes the same textual question asked with different concept&amp;definition and possible answers).

What kind of ML (NLP) technique(s) can i use here?
",2,1,False,self,,,,,
1133,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,12,9q0cgy,github.com,Using k-means to cluster images,https://www.reddit.com/r/MachineLearning/comments/9q0cgy/using_kmeans_to_cluster_images/,atum47,1540091404,,0,1,False,default,,,,,
1134,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,12,9q0kbx,self.MachineLearning,Looking for a cofounder!,https://www.reddit.com/r/MachineLearning/comments/9q0kbx/looking_for_a_cofounder/,AlphaDraconion,1540093420,"I know this is not the right place to find the cofounder for start ups! But any ways I am here looking for a cofounder partner who is good in ML and A.I development! 

If yes drop a comment or DM me!",0,1,False,self,,,,,
1135,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,13,9q0rz8,blog.google,[P] Google - A new course to teach people about fairness in machine learning,https://www.reddit.com/r/MachineLearning/comments/9q0rz8/p_google_a_new_course_to_teach_people_about/,ramblinscarecrow,1540095465,,0,1,False,https://b.thumbs.redditmedia.com/tXvS-MWH2V6jOhTRXelec_VdLgJ8EC0w7S_VMhGsSks.jpg,,,,,
1136,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,13,9q10bq,self.MachineLearning,Making a neural network (hypernetwork) with 33 million + outputs?,https://www.reddit.com/r/MachineLearning/comments/9q10bq/making_a_neural_network_hypernetwork_with_33/,botperson,1540097869,[removed],0,1,False,self,,,,,
1137,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,14,9q11pz,self.MachineLearning,[D] Beginner question: how do I measure the accuracy for sequence prediction?,https://www.reddit.com/r/MachineLearning/comments/9q11pz/d_beginner_question_how_do_i_measure_the_accuracy/,rampant_juju,1540098277,"I have a dataset of sequences of different lengths (think sentences of words). I have a trained model (Variable-Length Markov Chain) which can predict the next item given some starting prefix. E.g. given ""The boy ran in the \_\_\_"", it can predict ""park"".

&amp;#x200B;

I want to measure the prediction accuracy of my model. One way I thought of doing so was by taking all the sentences in my train/CV/test set, and cutting off the last word in the sentence, and then comparing against what is predicted, to get the train/CV/test accuracy. So I would take the prefix ""The man pulled out a \_\_\_\_"", knowing the next word is ""gun"", and compare it to the model's answer. Since there are a lot of words possible, Top-K accuracy might be a better measure than Top-1 accuracy.

&amp;#x200B;

What is the standard way of measuring accuracy?",5,1,False,self,,,,,
1138,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,15,9q1kb2,self.MachineLearning,[P] Chaos Games with ML Data Sets,https://www.reddit.com/r/MachineLearning/comments/9q1kb2/p_chaos_games_with_ml_data_sets/,underPanther,1540104436,"There are a few studies of people who use [chaos games (Wikipedia link)](https://en.m.wikipedia.org/wiki/Chaos_game) to visualise correlations in DNA sequences. 

I think the resulting patterns should be invariant under translations to the input data. This is similar to the behaviour of convolutional neural networks, so motivates an attempt to visualise standard ML image datasets in a similar way. So I did, and put [results in a GitHub repo](https://github.com/atiyo/dataset_chaos).

Not entirely sure of the practical uses of this kind of transformation yet, but I thought I would put it out there.

",2,1,False,self,,,,,
1139,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,15,9q1kfo,self.MachineLearning,MV-Tractus: A simple and fast tool to extract motion vectors from H264 encoded video streams.,https://www.reddit.com/r/MachineLearning/comments/9q1kfo/mvtractus_a_simple_and_fast_tool_to_extract/,jishnup,1540104478,[removed],0,1,False,self,,,,,
1140,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,16,9q1q08,youtube.com,Machine Learning tutorial series in Hindi,https://www.reddit.com/r/MachineLearning/comments/9q1q08/machine_learning_tutorial_series_in_hindi/,sambhal,1540106544,,0,1,False,default,,,,,
1141,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,17,9q1zs3,self.MachineLearning,Plyplot not Working,https://www.reddit.com/r/MachineLearning/comments/9q1zs3/plyplot_not_working/,HummelsM,1540110314,[removed],0,1,False,self,,,,,
1142,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,18,9q28z8,sumo.ly,Learn Machine Learning On Coursera with Andrew Ng - Free Access Until 31 Oct,https://www.reddit.com/r/MachineLearning/comments/9q28z8/learn_machine_learning_on_coursera_with_andrew_ng/,frenchdic,1540113816,,0,1,False,default,,,,,
1143,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,18,9q2at7,medium.com,Learn Machine Learning with Andrew Ng - Free Access Until 31 Oct,https://www.reddit.com/r/MachineLearning/comments/9q2at7/learn_machine_learning_with_andrew_ng_free_access/,frenchdic,1540114497,,0,1,False,default,,,,,
1144,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,18,9q2bev,self.MachineLearning,[P] A small tool to orchestrate ML experiments: skeletor,https://www.reddit.com/r/MachineLearning/comments/9q2bev/p_a_small_tool_to_orchestrate_ml_experiments/,noahgolm,1540114736,"I recently made a lightweight tool called [skeletor](https://github.com/noahgolmant/skeletor) that aims to make it easier to orchestrate ML experiments. It emphasizes reproducibility, easy logging / post-experiment analysis, as well as easy parallelization to test out various hyperparameter configurations with a grid search. This makes it pretty easy to prototype things like new model architectures or optimization algorithms.

&amp;#x200B;

All of the experiment logging is done through a nice tool called [track](https://github.com/richardliaw/track) which lets you programmatically access experiment results through a simple interface with pandas DataFrames. Parallelizing experiments is done with [ray](https://github.com/ray-project/ray), so you just have to specify a config file that provides the possible values for each of the command-line arguments. To be honest, this module basically just implements two functions and some training boilerplate (i.e. track and ray take care of 99% of the work), but it's made my life a bit easier when I'm trying out new ideas.

&amp;#x200B;

Let me know what you think! I would appreciate any feedback on possible improvements or glaring issues.

[https://github.com/noahgolmant/skeletor](https://github.com/noahgolmant/skeletor)

&amp;#x200B;

&amp;#x200B;",17,1,False,self,,,,,
1145,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,18,9q2bpu,self.MachineLearning,[D]Saliency maps for arbitrary subset of nodes (not just class label or entire filter),https://www.reddit.com/r/MachineLearning/comments/9q2bpu/dsaliency_maps_for_arbitrary_subset_of_nodes_not/,Reformations,1540114846,"I'd like to expand the notion of saliency maps so that they can be generated by a subset of nodes that are not necessarily in the output layer or even in the same filter or layer.

Here's some more details
https://raghakot.github.io/keras-vis/visualizations/saliency/.

It seems to be able to work in 2 modes:  

One mode is passing the dense layer parameter and then filter_indices (terrible name?) as the class node/label.

The other is passing it a conv layer then filter_indices is the position of the filter you wish to visualize in the conv layer.  

I'd like to know if a 3rd (more general) option is available so that any arbitrary subset of nodes (possibly spanning multiple layers/filters) could be used as parameters into a saliency visualization over an input image.  

A naive approach would be to create k maps (one for each of the k nodes in the subset) and then do some union operation.  

A more elegant approach would be to do the backprop calculation once, but with respect to a subset of nodes.  

Does the math/code for this exist?  Things get a bit weird when the subset of nodes spans multiple layers.",0,1,False,self,,,,,
1146,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,19,9q2ko6,self.MachineLearning,I've made a script for retrieving and processing results from a sacred MongoDB database,https://www.reddit.com/r/MachineLearning/comments/9q2ko6/ive_made_a_script_for_retrieving_and_processing/,poppear,1540118125,"In the last couple of days I was trying sacred ([https://github.com/IDSIA/sacred](https://github.com/IDSIA/sacred)) and it is awesome but as far as I know it seems that there is no a script in the internet for pulling the results from a sacred mongodb database, grouping them by the same parameters and computing some basic statistics (min, max, mean + CI, etc..) so I wrote it!

&amp;#x200B;

[https://github.com/galatolofederico/sacred-retrieve](https://github.com/galatolofederico/sacred-retrieve)

&amp;#x200B;

Maybe it turn out to be useful to some other sacred users here",0,1,False,self,,,,,
1147,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,21,9q34o3,insidebigdata.com,How does AI training work?,https://www.reddit.com/r/MachineLearning/comments/9q34o3/how_does_ai_training_work/,reimmoriks,1540124807,,0,1,False,https://b.thumbs.redditmedia.com/WXRfR2Zqc3D0SRuhDdjVTBa5h98dZlhIJgoBRfGj9qI.jpg,,,,,
1148,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,21,9q3568,youtube.com,Google Colaboratory Notebook Tutorial with GPU (Very Easy),https://www.reddit.com/r/MachineLearning/comments/9q3568/google_colaboratory_notebook_tutorial_with_gpu/,tim_macgyver,1540124963,,0,1,False,https://b.thumbs.redditmedia.com/doKs9fHGL4Vf5HgVBcZyBOV9JRfa0ax7REXhPtRyixs.jpg,,,,,
1149,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,21,9q35sf,self.Avengerblockchain,"Biggest airdrop is live , want to receive 0.35 ETH ? Join us now !",https://www.reddit.com/r/MachineLearning/comments/9q35sf/biggest_airdrop_is_live_want_to_receive_035_eth/,harjitbaj,1540125153,,0,1,False,https://b.thumbs.redditmedia.com/eAP5lHF3QZiH-IOuI-pEXeS9QS2LgazL-pnjto_QuaI.jpg,,,,,
1150,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,21,9q39kq,i.redd.it,Unable to train and predict right classification using Dynamic time warping,https://www.reddit.com/r/MachineLearning/comments/9q39kq/unable_to_train_and_predict_right_classification/,Math_Enthusiast48,1540126302,,0,1,False,https://b.thumbs.redditmedia.com/8P8VQOLdiGXvLcg4VC7b6D6XYhQwU7kHvtLLbpcsXpw.jpg,,,,,
1151,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,22,9q3dm3,self.MachineLearning,Making a neural network (hypernetwork) with 33 million + outputs?,https://www.reddit.com/r/MachineLearning/comments/9q3dm3/making_a_neural_network_hypernetwork_with_33/,botperson,1540127396,[removed],0,1,False,self,,,,,
1152,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,22,9q3g66,self.MachineLearning,Making a neural network with 30 million+ outputs?,https://www.reddit.com/r/MachineLearning/comments/9q3g66/making_a_neural_network_with_30_million_outputs/,botperson,1540128027,[removed],0,1,False,self,,,,,
1153,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,22,9q3kjz,bhutanio.com,Learn Computer Vision using OpenCV with Python,https://www.reddit.com/r/MachineLearning/comments/9q3kjz/learn_computer_vision_using_opencv_with_python/,sonamdargay,1540129174,,0,1,False,default,,,,,
1154,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,22,9q3mmq,self.MachineLearning,Starting my studies on CNN,https://www.reddit.com/r/MachineLearning/comments/9q3mmq/starting_my_studies_on_cnn/,Leli94,1540129706,[removed],0,1,False,self,,,,,
1155,MachineLearning,t5_2r3gv,2018-10-21,2018,10,21,23,9q4183,self.MachineLearning,Looking for team/collaborators,https://www.reddit.com/r/MachineLearning/comments/9q4183/looking_for_teamcollaborators/,HummelsM,1540133166,[removed],0,1,False,self,,,,,
1156,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,0,9q462f,self.MachineLearning,Handwriting generation,https://www.reddit.com/r/MachineLearning/comments/9q462f/handwriting_generation/,thedrowsywinger,1540134204,[removed],0,1,False,self,,,,,
1157,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,0,9q47qa,self.MachineLearning,Master AI and Neural Networks,https://www.reddit.com/r/MachineLearning/comments/9q47qa/master_ai_and_neural_networks/,Sarthaks21,1540134563,[removed],0,1,False,self,,,,,
1158,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,1,9q520d,self.MachineLearning,[D] Which filter or approach can manipulate Handwriting structure?,https://www.reddit.com/r/MachineLearning/comments/9q520d/d_which_filter_or_approach_can_manipulate/,jhondipto,1540140777,"So i'm trying to understand handwriting generators. What filters (or anything really) exactly manipulate the structure of a handwriting. I've tried putting a normal written text as the content image and handwritten text as the style image and implemented them in several style transfer models, but all of them have one thing in common, they keep the structure/edges unchanged and change the rest , and if doesn't change the edge it doesn't really change to the handwriting i want. So how exactly should i be approaching this problem here? thanks",3,1,False,self,,,,,
1159,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,3,9q5t92,self.MachineLearning,"[R] Recent ""Rethinking the Value of Network Pruning"" contradicts Deep Compression work",https://www.reddit.com/r/MachineLearning/comments/9q5t92/r_recent_rethinking_the_value_of_network_pruning/,rantana,1540146264,"Quote from the article:
&gt;The contradiction between our results and
those reported in the literature might be explained by less carefully chosen hyper-parameters, data
augmentation schemes and unfair computation budget for evaluating this baseline approach.

""Rethinking the Value of Network Pruning""

 * Paper: https://arxiv.org/abs/1810.05270
 * Source Code: https://github.com/Eric-mingjie/rethinking-network-pruning

This paper seems to contradict all the network pruning papers of recent times including Song Han's 2015 paper https://arxiv.org/abs/1510.00149 (which has over 1200 citations). This is very surprising and will likely change the workflow of the models we train and deploy in industry. ",21,1,False,self,,,,,
1160,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,3,9q5u9q,self.MachineLearning,What should I expect in a technical interview from a large AI startup?,https://www.reddit.com/r/MachineLearning/comments/9q5u9q/what_should_i_expect_in_a_technical_interview/,Ctrl_Alt_Del3te,1540146477,"I'm used to completing data structure questions in coding challenges and over the phone from like the standard big companies, but i doubt a large AI startup is going to ask me to perform DFS on a graph. I'm thinking maybe more like explaining core ML topics like backpropogation, SVMs etc. Would I be right in thinking this, or would they ask me something else?",0,1,False,self,,,,,
1161,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,3,9q5vkk,self.MachineLearning,I am trying to build an experimentation platform for my models. Any idea how to go about it?,https://www.reddit.com/r/MachineLearning/comments/9q5vkk/i_am_trying_to_build_an_experimentation_platform/,afrodata,1540146738,[removed],0,1,False,self,,,,,
1162,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,3,9q5wb6,self.MachineLearning,[R] Keras tensorflow,https://www.reddit.com/r/MachineLearning/comments/9q5wb6/r_keras_tensorflow/,i-stat,1540146882,"Hi. I am trying to access the out put of an intermediate layer in a Keras model running under R.

I can obtain the output of layer 1 for example by: &lt; layer\_output &lt;- get\_layer(mymodel, index=1)$output/&gt;

The problem I'm left with is that layer\_output is a tensorflow tensor;

&lt; class(layer\_output)/&gt;

\[1\] ""tensorflow.tensor""    ""tensorflow.python.framework.ops.Tensor""     

\[3\] ""tensorflow.python.framework.ops.\_TensorLike"" ""python.builtin.object""

&amp;#x200B;

I want to convert layer\_output to an R array, but I can't seem to find a way to do this. Any help appreciated.

&amp;#x200B;",4,1,False,self,,,,,
1163,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,3,9q60uu,self.MachineLearning,Is there a simple way to prove the convergence of the perception.,https://www.reddit.com/r/MachineLearning/comments/9q60uu/is_there_a_simple_way_to_prove_the_convergence_of/,moar55,1540147809,I have watched/read proof of convergence of the perceptron and I always get lost midway. Can any one refer me to a source that has a simple mathematical proof for it.,0,1,False,self,,,,,
1164,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,4,9q64cr,self.MachineLearning,{D}Transformer with OOV?,https://www.reddit.com/r/MachineLearning/comments/9q64cr/dtransformer_with_oov/,aimoralist,1540148497,[removed],0,1,False,self,,,,,
1165,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,4,9q667i,self.MachineLearning,[R] Reinforcement learning with A* and a deep heuristic,https://www.reddit.com/r/MachineLearning/comments/9q667i/r_reinforcement_learning_with_a_and_a_deep/,skariel,1540148869,"Results are ready but I couldn't wait till the paper is (a couple of weeks away). So here's the link to the  code for reproduction, together with a short introduction and slides from the my GTC talk:

[https://github.com/imagry/aleph\_star](https://github.com/imagry/aleph_star)

feedback is welcome of course :)

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;",7,1,False,self,,,,,
1166,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,4,9q68h1,self.MachineLearning,"[D]Transformer, Is there any way to get souce position?",https://www.reddit.com/r/MachineLearning/comments/9q68h1/dtransformer_is_there_any_way_to_get_souce/,aimoralist,1540149300,"Is there any way to get source position of result words?  
",1,1,False,self,,,,,
1167,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,4,9q6d8r,self.MachineLearning,[D] What's the best performing approach to localise/regress points in an image?,https://www.reddit.com/r/MachineLearning/comments/9q6d8r/d_whats_the_best_performing_approach_to/,cbsudux,1540150237,,7,1,False,self,,,,,
1168,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,4,9q6huq,self.MachineLearning,Stock analyst on Python and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9q6huq/stock_analyst_on_python_and_machine_learning/,canonier,1540151134,[removed],0,1,False,self,,,,,
1169,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,6,9q7ag4,github.com,"[P] Reproducing and extending the results of paper ""Concrete Dropout"" [1705.07832] in Pytorch",https://www.reddit.com/r/MachineLearning/comments/9q7ag4/p_reproducing_and_extending_the_results_of_paper/,alfo5123,1540156818,,0,1,False,default,,,,,
1170,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,6,9q7b38,github.com,"[P] Reproducing and extending the results of paper ""Concrete Dropout"" [1705.07832] in Pytorch",https://www.reddit.com/r/MachineLearning/comments/9q7b38/p_reproducing_and_extending_the_results_of_paper/,alfo5123,1540156955,,0,1,False,https://b.thumbs.redditmedia.com/SwZvl2i3eVtGXAT5ukQ1qUANOBK0xjjEYULy7VZQABY.jpg,,,,,
1171,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,6,9q7eao,self.MachineLearning,How do you go about implementing a paper?,https://www.reddit.com/r/MachineLearning/comments/9q7eao/how_do_you_go_about_implementing_a_paper/,juice-lover,1540157625,[removed],0,1,False,self,,,,,
1172,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,6,9q7fc1,self.MachineLearning,Finding a similarity measure between two audio signals,https://www.reddit.com/r/MachineLearning/comments/9q7fc1/finding_a_similarity_measure_between_two_audio/,AnasAlmasri,1540157843,"I have been trying to make a program that compares two audio signals and gives a percentage of how similar they are. 

I tried extracting MFCC features and using DTW to compare them. However, that gave unreasonable results. Turns out DTW is mostly used to find the best match from a dataset by finding the shortest distance. I want to find how similar the recordings are without having to rely on a dataset.

Any thoughts?",0,1,False,self,,,,,
1173,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,7,9q7obu,munchron.com,ML Health Scanner for Skin problems,https://www.reddit.com/r/MachineLearning/comments/9q7obu/ml_health_scanner_for_skin_problems/,comtech,1540159796,,0,1,False,default,,,,,
1174,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,7,9q7oor,self.MachineLearning,[D] Are there any public models trained against google street view to associate a image of buildings to a location?,https://www.reddit.com/r/MachineLearning/comments/9q7oor/d_are_there_any_public_models_trained_against/,Loggerny,1540159884,"ie. Feed an image of a building/skyline, and get back possible address.",4,1,False,self,,,,,
1175,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,7,9q7sz8,self.MachineLearning,How to approach a semi-supervised sequence to sequence problem?,https://www.reddit.com/r/MachineLearning/comments/9q7sz8/how_to_approach_a_semisupervised_sequence_to/,fogbugz,1540160825,[removed],0,1,False,self,,,,,
1176,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,8,9q84o5,self.MachineLearning,montezuma's revenge,https://www.reddit.com/r/MachineLearning/comments/9q84o5/montezumas_revenge/,Schoolunch,1540163435,"I've been working on montezuma's revenge for the past few weeks and wanted to share some ideas, and get some feedback in how these techniques might be implemented.

&amp;#x200B;

Firstly, Montezuma's Revenge could potentially be reduced to a maze based algorithm, where each room is a maze/graph and the game as a whole is treated as a collection of nodes, with each node being a graph.  If we could make this mapping, an algorithm like [https://cs.stackexchange.com/questions/29312/minimum-distance-between-start-and-end-by-going-through-must-visit-points-in-a-m/29339#29339](https://cs.stackexchange.com/questions/29312/minimum-distance-between-start-and-end-by-going-through-must-visit-points-in-a-m/29339#29339) could be used to find the optimal path.  This feels similar to [https://arxiv.org/pdf/1803.10122.pdf](https://arxiv.org/pdf/1803.10122.pdf), which uses world models, except instead of trying to understand the full map, you're trying to create an internal representation of this graph based on exploring the game.

&amp;#x200B;

So maybe the algorithm would be mapping the existing state to a minimal graph, and then solving the minimal representation.  I think world models is an extremely powerful technique, and I'm curious how this could generally apply to this problem where instead of hallucinating a representation of a single state, you're building a minimal representation of the existing world using some form of inverse graphics.  I think a Differentiable Neural Computer might be able to do this, since it was able to learn the family tree graphs and things like this [https://deepmind.com/blog/differentiable-neural-computers/](https://deepmind.com/blog/differentiable-neural-computers/) .

&amp;#x200B;

What are your thoughts, do you think it would be possible to learn a minimum viable internal representation of the world map in the game?",2,1,False,self,,,,,
1177,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,8,9q86p7,self.MachineLearning,Prediction of failure of electronic equipment,https://www.reddit.com/r/MachineLearning/comments/9q86p7/prediction_of_failure_of_electronic_equipment/,evertonalex,1540163900,[removed],0,1,False,self,,,,,
1178,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,8,9q878f,self.MachineLearning,"Some Deep Learning with Python, TensorFlow and Keras",https://www.reddit.com/r/MachineLearning/comments/9q878f/some_deep_learning_with_python_tensorflow_and/,andrea_manero,1540164006,[removed],0,1,False,self,,,,,
1179,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,8,9q8a9w,self.MachineLearning,Deep Learning Epic Fail  Right Answer - Wrong Reason,https://www.reddit.com/r/MachineLearning/comments/9q8a9w/deep_learning_epic_fail_right_answer_wrong_reason/,andrea_manero,1540164622,r/http://www.datasciencecentral.com/profiles/blogs/deep-learning-epic-fail-right-answer-wrong-reason,0,1,False,self,,,,,
1180,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,11,9q9hm5,kaggle.com,How do I use the .ann files from Brat as inputs to a sequence learning algorithm?,https://www.reddit.com/r/MachineLearning/comments/9q9hm5/how_do_i_use_the_ann_files_from_brat_as_inputs_to/,Dawny33,1540174686,,0,1,False,default,,,,,
1181,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,11,9q9o5i,youtube.com,[D] MIT AGI: Deep Learning (Yoshua Bengio),https://www.reddit.com/r/MachineLearning/comments/9q9o5i/d_mit_agi_deep_learning_yoshua_bengio/,AFewSentientNeurons,1540176207,,0,1,False,default,,,,,
1182,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,13,9qa80r,self.MachineLearning,[D] Statistical connection data for biological neurons,https://www.reddit.com/r/MachineLearning/comments/9qa80r/d_statistical_connection_data_for_biological/,MemeBox,1540180884,"I just had a thought. Perhaps transplanting the connectivity of biological neurons into the initialisation of an artificial neural net would improve learning.

I was wondering where I could find data on the kinds of neuron found in each part of the brain together with the kinds of connectivity properties for each type. So I can try and fudge some of those structural properties into the initialisation stage of a deep or recurrent neural network.",4,1,False,self,,,,,
1183,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,13,9qab1j,fixitright.co,Refrigerator and Washing Machine Repair Service,https://www.reddit.com/r/MachineLearning/comments/9qab1j/refrigerator_and_washing_machine_repair_service/,tomriddletom3,1540181558,,0,1,False,https://a.thumbs.redditmedia.com/Q8RdKn5jtcIQmqeBMAoVFKObFIsSTlK0XE0UeHvmp28.jpg,,,,,
1184,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,13,9qaj5r,self.MachineLearning,[D] What is the best neural network structure to approximate functions?,https://www.reddit.com/r/MachineLearning/comments/9qaj5r/d_what_is_the_best_neural_network_structure_to/,captaincyypher,1540183547,"I have heard that both feed-forward networks as well as recurrent neural networks are universal function approximators, i.e., they can approximate any function arbitrarily close with increasing hidden layers and hidden units.

&amp;#x200B;

* Is there a difference between smooth and non-smooth functions?
* What is better, a few hidden layers with many hidden units per layer or deep learning, i.e., many hidden layers?
* Has anyone tried to use LSTM networks to do this kind of stuff?",4,1,False,self,,,,,
1185,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,13,9qak6q,github.com,[Python] Recent- Patient2Vec: A Personalized Interpretable Deep Representation of the Longitudinal Electronic Health Record,https://www.reddit.com/r/MachineLearning/comments/9qak6q/python_recent_patient2vec_a_personalized/,kk7nc,1540183815,,0,1,False,default,,,,,
1186,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,13,9qakv7,github.com,[R] Patient2Vec: A Personalized Interpretable Deep Representation of the Longitudinal Electronic Health Record,https://www.reddit.com/r/MachineLearning/comments/9qakv7/r_patient2vec_a_personalized_interpretable_deep/,kk7nc,1540183997,,0,1,False,https://b.thumbs.redditmedia.com/lLiW0jNrDoN8-EbM99WkCVpQMaYxzhSpiRY9aZcoP5Q.jpg,,,,,
1187,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,14,9qamze,github.com,[P] K-means,https://www.reddit.com/r/MachineLearning/comments/9qamze/p_kmeans/,atum47,1540184553,,1,1,False,https://a.thumbs.redditmedia.com/WSfiSQnZkZVblKOzJi6OtuMHc_vntsX1haQAHz8SeZ8.jpg,,,,,
1188,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,14,9qaz19,self.MachineLearning,What do tools like Algorithmia and FastScore do that running a model on GCP or AWS can't accomplish?,https://www.reddit.com/r/MachineLearning/comments/9qaz19/what_do_tools_like_algorithmia_and_fastscore_do/,AlexSnakeKing,1540187820,[removed],0,1,False,self,,,,,
1189,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,15,9qb7r2,thetechnologyheadlines.com,"AirAsia partners Google Cloud to integrate AI, Machine Learning into its business",https://www.reddit.com/r/MachineLearning/comments/9qb7r2/airasia_partners_google_cloud_to_integrate_ai/,ttheadlines,1540190229,,0,1,False,https://b.thumbs.redditmedia.com/ewCVGkQECb02La2LHdl89gDNwl7vnewAa0-KRnbyccE.jpg,,,,,
1190,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,15,9qb9yv,self.MachineLearning,Can AI kill PHP?,https://www.reddit.com/r/MachineLearning/comments/9qb9yv/can_ai_kill_php/,rusty_on_rampage,1540190855,[removed],0,1,False,self,,,,,
1191,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,16,9qbjgy,self.MachineLearning,"A full explanation of logistic regression, mathematical background, classification, likelihood methods and Newton Raphson method",https://www.reddit.com/r/MachineLearning/comments/9qbjgy/a_full_explanation_of_logistic_regression/,coolnikhilj22,1540193489,[removed],0,1,False,self,,,,,
1192,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,16,9qbkr1,self.artificial,Resources to stay updated on artificial intelligence,https://www.reddit.com/r/MachineLearning/comments/9qbkr1/resources_to_stay_updated_on_artificial/,reimmoriks,1540193876,,0,1,False,https://b.thumbs.redditmedia.com/7rW041K-XfWBI2iwcWR2xOYenYUpXoSMZ4E77QuCT5M.jpg,,,,,
1193,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,17,9qbuvi,link.medium.com,Intuition behind logistic regression : Nueral Network building block,https://www.reddit.com/r/MachineLearning/comments/9qbuvi/intuition_behind_logistic_regression_nueral/,ruchit007,1540197014,,0,1,False,default,,,,,
1194,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,17,9qbw14,self.MachineLearning,[R] Discriminator Rejection Sampling,https://www.reddit.com/r/MachineLearning/comments/9qbw14/r_discriminator_rejection_sampling/,donatas_repecka,1540197369,"[https://arxiv.org/abs/1810.06758](https://arxiv.org/abs/1810.06758)

&amp;#x200B;",1,1,False,self,,,,,
1195,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,17,9qby1b,self.MachineLearning,"If CNN replaces fully connected layer with logistic regression, can i pull out the feature properly in convolutional layer?",https://www.reddit.com/r/MachineLearning/comments/9qby1b/if_cnn_replaces_fully_connected_layer_with/,taehyuk,1540198000,[removed],0,1,False,self,,,,,
1196,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,18,9qc3bg,self.MachineLearning,[R] On the Margin Theory of Feedforward Neural Networks,https://www.reddit.com/r/MachineLearning/comments/9qc3bg/r_on_the_margin_theory_of_feedforward_neural/,gohu_cd,1540199633,"""We establish: 1) for multi-layer feedforward relu networks, the global minimizer of a weakly-regularized cross-entropy loss has the maximum normalized margin among all networks, 2) as a result, increasing the over-parametrization improves the normalized margin and generalization error bounds for two-layer networks.""  


Margin theory results for multi-layer FF neural nets. A hint towards why over-parametrization is better.   


I'm interested to see the feedback on this paper.  


[https://arxiv.org/abs/1810.05369](https://arxiv.org/abs/1810.05369)",7,1,False,self,,,,,
1197,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,18,9qcaiy,self.MachineLearning,1-Nearest Neighbour,https://www.reddit.com/r/MachineLearning/comments/9qcaiy/1nearest_neighbour/,Mistoffelees7,1540201720,[removed],0,1,False,self,,,,,
1198,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,19,9qcdhd,self.MachineLearning,[D] Need an idea of testing Anticipatory Learning Classifier using interval predicates,https://www.reddit.com/r/MachineLearning/comments/9qcdhd/d_need_an_idea_of_testing_anticipatory_learning/,khozzy,1540202529,"Hi, I'm working on a modification of ALCS (*Anticipatory Learning Classifier System*) capable of handling real-valued input data.

&amp;#x200B;

The big picture of the algorithm is to create ""*rules*"" in form of *condition-action-effect* triples capturing knowledge of the environment.

An example of such a rule might be for controlling traffic lights:

&gt;**Condition**: light: green, number\_of\_cars\_passing: huge  
&gt;  
&gt;**Action**: stop traffic  
&gt;  
&gt;**Effect**: light: red, number\_of\_cars\_passing: low

The ACS environment is most commonly evaluated in typical RL environments like a maze (multistep - predicting consequences of taken action) or multiplexer (singlestep - dealing with epistasis and heterogeneity across features).

&amp;#x200B;

My changes will treat perceived environment attributes as floating numbers and turn them into intervals.

So the analogous example might look like (numbers are made up): 

&gt;**Condition**: color\_val: (200, 200&gt;, number\_of\_cars\_passing: (50, 84&gt;  
&gt;  
&gt;**Action**: stop traffic  
&gt;  
&gt;**Effect**: color\_val: (150, 1500&gt;, number\_of\_cars\_passing: (0, 0&gt;

&amp;#x200B;

Do you know any testing environment with characteristics that would be beneficial for such potentials, ie. predict a change of numeric variable after executing the certain action? For XCSR Most up to date environment is a checkboard problem, but it's not enough for the real-valued ACS to shine.",0,1,False,self,,,,,
1199,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,19,9qcei9,dexlabanalytics.com,LinkedIn Suggests How to Find Machine Learning Experts across Diverse Career Pathways,https://www.reddit.com/r/MachineLearning/comments/9qcei9/linkedin_suggests_how_to_find_machine_learning/,dexlabanalytics,1540202799,,0,1,False,default,,,,,
1200,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,19,9qcenr,self.MachineLearning,[P] Take derivatives of a neural network,https://www.reddit.com/r/MachineLearning/comments/9qcenr/p_take_derivatives_of_a_neural_network/,moewiewp,1540202839,"I'm building a network based on SURE (Stein's unbiased risk estimate) and I'm struggling to calculate the derivative of the network as part of the loss function. For example, let's say we have a pre-trained model N and an input image x so how to calculate N(x) for the loss function ? I'm trying with tf and keras backend tutorials but still haven't figure out how :(",1,1,False,self,,,,,
1201,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,19,9qck22,self.MachineLearning,[D] Can you recommend international funding sources/calls?,https://www.reddit.com/r/MachineLearning/comments/9qck22/d_can_you_recommend_international_funding/,fbtek,1540204265,"Hi,

Can you recommend international  -(not specific to US citizens, universities)-

sources to apply for research grants **in the field of machine learning**? 

The funding I am looking for is to cover research costs and include PHD or PostDoc grants.

Have you applied and received grant from such organizations? 

Thanks.

&amp;#x200B;

&amp;#x200B;",0,1,False,self,,,,,
1202,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,19,9qclos,self.MachineLearning,[D] What type of documentation do you use ? (python),https://www.reddit.com/r/MachineLearning/comments/9qclos/d_what_type_of_documentation_do_you_use_python/,amitxy,1540204694,"I noticed that a lot of people use numpydoc for their projects, but I don't like it because it's works sluggish on pycharm and I'm really used to document in reStructuredText. 

    numpydoc example:
    
def func(x,y):
        """"""
        Parameters
        ----------
        x : type
            Description of parameter `x`.
        y
            Description of parameter `y` (with type not specified)
        
        Returns
        -------
        x + y
        """"""
        return x + y
    
    reStructuredText example:
    
    def func(x,y):
        """"""
        :param x: Description of parameter `x`.
        :param type x: type
    
        :param y: Description of parameter `y`
    
        :return: x + y
        """"""
        return x + y


  


&amp;#x200B;",21,1,False,self,,,,,
1203,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,19,9qcmlu,medium.com,"[R] Sotawhat, Dynamic Meta-Embeddings, Journal, Fairness in ML Course, GraphNets, NLP Overview Paper, Medical Torch,",https://www.reddit.com/r/MachineLearning/comments/9qcmlu/r_sotawhat_dynamic_metaembeddings_journal/,omarsar,1540204941,,0,1,False,default,,,,,
1204,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,19,9qcnok,self.MachineLearning,Penalize distance in CartPole openAI-Gym,https://www.reddit.com/r/MachineLearning/comments/9qcnok/penalize_distance_in_cartpole_openaigym/,MrSh4nnon,1540205230,[removed],0,1,False,self,,,,,
1205,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,20,9qcs5m,self.MachineLearning,[Discussion]Home made Alpha Zero,https://www.reddit.com/r/MachineLearning/comments/9qcs5m/discussionhome_made_alpha_zero/,daredevildas,1540206350,Is there any tutorial out there that shows how to train my own version of the chess playing alpha zero (which would ofcourse be far weaker because I would not have access to the computing resources DeepMind does)?,21,1,False,self,,,,,
1206,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,20,9qcuxu,self.MachineLearning,Getting into machine learning,https://www.reddit.com/r/MachineLearning/comments/9qcuxu/getting_into_machine_learning/,wilhouse,1540207031,[removed],0,1,False,self,,,,,
1207,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,20,9qcxqn,self.MachineLearning,Concise Cheat Sheets for Machine Learning with Python (and Maths),https://www.reddit.com/r/MachineLearning/comments/9qcxqn/concise_cheat_sheets_for_machine_learning_with/,skj8,1540207735,"Machine learning is difficult for beginners. As well as libraries for Machine Learning in python are difficult to understand.Over the past few weeks, I have been collecting Machine Learning cheat sheets from different sources and would like to share them.

# 1. [Scikit-Learn Cheat Sheet: Python Machine Learning](https://sinxloud.com/machine-learning-cheat-sheets-python-math-statistics/#1-scikit-learn-cheat-sheet-python-machine-learning)

# 2. [Python Cheat Sheet for Scikit-learn](https://sinxloud.com/machine-learning-cheat-sheets-python-math-statistics/#2-python-cheat-sheet-for-scikit-learn)

# 3. [Keras Cheat Sheet:Neural Networks in Python](https://sinxloud.com/machine-learning-cheat-sheets-python-math-statistics/#3-keras-cheat-sheet-neural-networks-in-python)

# 4. [Python SciPy Cheat Sheet](https://sinxloud.com/machine-learning-cheat-sheets-python-math-statistics/#4-python-scipy-cheat-sheet)

# 5. [Theano Cheat Sheet](https://sinxloud.com/machine-learning-cheat-sheets-python-math-statistics/#5-theano-cheat-sheet)

Also, if you have any Cheat Sheets on TensorFlow in a PDF Version, please add the source information in the comments below.

# Cheers !!!

# ",0,1,False,self,,,,,
1208,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,21,9qd6ki,self.MachineLearning,Generative Adversarial Networks Miniseries [FREE TUTORIALS &amp; REFERENCES],https://www.reddit.com/r/MachineLearning/comments/9qd6ki/generative_adversarial_networks_miniseries_free/,iamarmaan,1540209822,[removed],0,1,False,self,,,,,
1209,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,21,9qd6uf,self.MachineLearning,"[D] Please help us founding a new machine learning channel for humans, ##machinelearning-general on Freenode IRC",https://www.reddit.com/r/MachineLearning/comments/9qd6uf/d_please_help_us_founding_a_new_machine_learning/,randombetty,1540209888,"As some of you may remember, the guy who is the admin of most of the machine learning channels on FreeNode is prone to unpredictable outburst of anger, which some of you have noticed in this thread about a year ago: https://www.reddit.com/r/MachineLearning/comments/6w1qtn/d_announcing_machinelearning_chat_on_freenode_irc/

We are veterans of these channels and want to try to improve things by founding a new channel: ##machinelearning-general .

We would like to welcome everybody to join!

We try to have a wider view on general machine learning topics, ranging from philosophical questions, to oldschool statistics, to modern deep learning architectures, the latest arxiv papers, or any kind of related programming question--all under one hood.  But most of all we try to be friendly human beings.

If you want to take a peek the easiest to do so is via webchat: https://webchat.freenode.net/?channels=##machinelearning-general (You will automatically be assigned a Guest&lt;number&gt; username unless you register with a nick)

If you want to become a regular user you should use a real IRC client: irccloud is currently the most convenient client (it remembers messages of the time you were offline) and also without cost for the basic version:

https://www.irccloud.com/

Thanks!!
",20,1,False,self,,,,,
1210,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,21,9qd963,multisoftvirtualacademy.com,Expedite Your Career Growth Through Machine Learning Online Courses,https://www.reddit.com/r/MachineLearning/comments/9qd963/expedite_your_career_growth_through_machine/,multisoftmva0,1540210410,,0,1,False,default,,,,,
1211,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,21,9qdaxg,self.MachineLearning,Collaborative filtering - fundamental assumption,https://www.reddit.com/r/MachineLearning/comments/9qdaxg/collaborative_filtering_fundamental_assumption/,grupiotr,1540210810,[removed],0,1,False,self,,,,,
1212,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,21,9qdeuf,self.MachineLearning,Concise Cheat Sheets for Machine Learning with Python (and Maths),https://www.reddit.com/r/MachineLearning/comments/9qdeuf/concise_cheat_sheets_for_machine_learning_with/,skj8,1540211711,[removed],0,1,False,self,,,,,
1213,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,21,9qdhik,self.MachineLearning,"Compared to ""natural"" language, retail data can be a better test bed for evaluating topic models",https://www.reddit.com/r/MachineLearning/comments/9qdhik/compared_to_natural_language_retail_data_can_be_a/,adamnhornsby,1540212329,[removed],0,1,False,self,,,,,
1214,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,21,9qdidm,self.MachineLearning,Machine Learning Cheat Sheets,https://www.reddit.com/r/MachineLearning/comments/9qdidm/machine_learning_cheat_sheets/,skj8,1540212512,[removed],0,1,False,self,,,,,
1215,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,22,9qdxdk,self.MachineLearning,"[R] Compared to ""natural"" language, retail data is often a better test bed for evaluating NLP algorithms",https://www.reddit.com/r/MachineLearning/comments/9qdxdk/r_compared_to_natural_language_retail_data_is/,adamnhornsby,1540215760," [https://arxiv.org/abs/1810.08577](https://arxiv.org/abs/1810.08577)

&amp;#x200B;

Code and data are due to be released ASAP",4,1,False,self,,,,,
1216,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,23,9qeh5d,github.com,"[P] Reproducing and extending the results of paper ""Concrete Dropout"" [1705.07832] in Pytorch",https://www.reddit.com/r/MachineLearning/comments/9qeh5d/p_reproducing_and_extending_the_results_of_paper/,alfo5123,1540219594,,0,1,False,default,,,,,
1217,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,23,9qehty,medium.com,[N] Peer Review: CVPR Paper Controversy,https://www.reddit.com/r/MachineLearning/comments/9qehty/n_peer_review_cvpr_paper_controversy/,gwen0927,1540219714,,0,1,False,default,,,,,
1218,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,23,9qeiu3,self.MachineLearning,[P] An overview of current state in OCR,https://www.reddit.com/r/MachineLearning/comments/9qeiu3/p_an_overview_of_current_state_in_ocr/,shgidigo,1540219905,[removed],0,1,False,self,,,,,
1219,MachineLearning,t5_2r3gv,2018-10-22,2018,10,22,23,9qejm3,self.MachineLearning,Possible to get NIPS registration if no conference paper?,https://www.reddit.com/r/MachineLearning/comments/9qejm3/possible_to_get_nips_registration_if_no/,AndroAsc,1540220057,[removed],0,1,False,self,,,,,
1220,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,0,9qelt2,self.MachineLearning,Will I get a job after completing some online courses due to high demand for ML engineers or I still need Masters?,https://www.reddit.com/r/MachineLearning/comments/9qelt2/will_i_get_a_job_after_completing_some_online/,erjcan,1540220472,[removed],0,1,False,self,,,,,
1221,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,0,9qepg4,arxiv.org,[R] Pruning neural networks: is it time to nip it in the bud?,https://www.reddit.com/r/MachineLearning/comments/9qepg4/r_pruning_neural_networks_is_it_time_to_nip_it_in/,downtownslim,1540221121,,3,1,False,default,,,,,
1222,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,0,9qepwi,self.MachineLearning,"[R] An Introduction to Causal Inference with Gaussian Processes, Part I",https://www.reddit.com/r/MachineLearning/comments/9qepwi/r_an_introduction_to_causal_inference_with/,kseeliger,1540221205,"This is a new blog post about our method for causal inference with Gaussian process regression (GP CaKe). We think the explanation is intuitive :)

[An Introduction to Causal Inference with Gaussian Processes, Part I](https://mindcodec.com/an-introduction-to-causal-inference-with-gaussian-processes-part-i/)",26,1,False,self,,,,,
1223,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,0,9qf1zy,arxiv.org,Dynamic Automatic Differentiation of mixed mode GPU Broadcast Kernels,https://www.reddit.com/r/MachineLearning/comments/9qf1zy/dynamic_automatic_differentiation_of_mixed_mode/,Bdamkin54,1540223415,,0,1,False,default,,,,,
1224,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,0,9qf4pm,self.MachineLearning,Getting joint co-ordinates from datasets,https://www.reddit.com/r/MachineLearning/comments/9qf4pm/getting_joint_coordinates_from_datasets/,ursulazsenya,1540223904,[removed],0,1,False,self,,,,,
1225,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,1,9qf8og,reddit.com,When Agile Meets Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9qf8og/when_agile_meets_machine_learning/,SolidVegetable,1540224571,,0,1,False,default,,,,,
1226,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,2,9qfy05,self.MachineLearning,[R] First-Class Automatic Differentiation in Swift: A Manifesto,https://www.reddit.com/r/MachineLearning/comments/9qfy05/r_firstclass_automatic_differentiation_in_swift_a/,tensorflower,1540229010,"https://gist.github.com/rxwei/30ba75ce092ab3b0dce4bde1fc2c9f1d

Interesting writeup on first-class support of AD in Swift. ",0,1,False,self,,,,,
1227,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,2,9qg0fc,self.MachineLearning,"[D] Looking for data sources for McKinsey's ""Use Cases of Machine Learning in Business""",https://www.reddit.com/r/MachineLearning/comments/9qg0fc/d_looking_for_data_sources_for_mckinseys_use/,Jacobinite,1540229429,"https://www.mckinsey.com/~/media/mckinsey/featured%20insights/artificial%20intelligence/notes%20from%20the%20ai%20frontier%20applications%20and%20value%20of%20deep%20learning/mgi_notes-from-ai-frontier_discussion-paper.ashx

I'm wondering if you guys are aware of sources for some of the use cases they describe here. Maybe it's all internal data, or they're just using this report for marketing purposes, but I figured I would ask here if you guys were aware of any.

Thanks!",1,1,False,self,,,,,
1228,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,2,9qg96r,self.MachineLearning,[P] Worfor - curated list of jobs and internships in AI Industry,https://www.reddit.com/r/MachineLearning/comments/9qg96r/p_worfor_curated_list_of_jobs_and_internships_in/,alexwawl,1540230999,"Hello, I'm maker of [https://worfor.com](https://worfor.com). I have started Worfor as the place where you can find jobs or internships as Data Scientist, Machine Learning Engineer, Analyst, etc. But then I decide to make it more than just a job board. 

&amp;#x200B;

I want to make a place where you can easily find and apply to any jobs which fit for you. A company will propose salary and benefits based on your profile and earlier offers which made by other companies.

By filling personal profile you can get personalized job recommendations/notifications, weekly newsletters, avoid sending CV and Resume to each open positions and much more features in future.

&amp;#x200B;

**I want to ask you a few questions:**

1) What I should add/change to make Worfor better?

2) Do you know companies which have Juniors positions or internships? We want to collect all of these opportunities and share them with students or somebody who just start their career path.",11,1,False,self,,,,,
1229,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,2,9qg9nw,self.MachineLearning,[D]Stock analyst on Python and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9qg9nw/dstock_analyst_on_python_and_machine_learning/,canonier,1540231088,"Hi.

I'm starter in Machine Learning, but I have idea, that I want to try to realize. I red many articles about python ML modules and data modules so pandas, scikit-learn, numpy, tensorflow but I didn't understand, how I can realize my idea and I don't know if it possible.

So, my idea:

I want to do stock analyst for features stock exchange, which will predict me what is next bar - green or red? (It means price will increase or decrease)

How I see that It has to work:

Income data is stock quotes, its will look like below, for example:

|datatime|I1|I2|I3|I4|open|min|max|close|bar|
|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|
|.....|.....|.....|.....|.....|.....|.....|.....|.....|.....|
|2018-10-22 12:00|xxx|xxx|xxx|xxx|xxx|xxx|xxx|xxx|green|
|2018-10-22 12:00|xxx|xxx|xxx|xxx|xxx|xxx|xxx|xxx|red|
|2018-10-22 13:00|xxx|xxx|xxx|xxx|xxx|xxx|xxx|xxx|green|
|2018-10-22 14:00|?|?|?|?|?|?|?|?|?|

where

I1 - I4 - stock indicators

bar = close-open If bar &lt; 0: red else:green

open, close, min and max are prices (open price, close....)

xxx - real values of stock exchange

Admit, this quotes is from several month

Its need to set in the system, that:

1. This is TimeSeries and in any column next value depends on previous one.
2. We will assume that open, close, max and min depends on I1, I2, I3, I4

Our problem is predict next row (mainly open and close and bar as a consequence)

How to solve this problem? Which modules I need to use?

Please describe how this can be realize?

Thank you",1,1,False,self,,,,,
1230,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,3,9qgadz,self.MachineLearning,Questions about application,https://www.reddit.com/r/MachineLearning/comments/9qgadz/questions_about_application/,TemporaryUser10,1540231216,[removed],0,1,False,self,,,,,
1231,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,3,9qgaev,self.MachineLearning,[D] CI/CD for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9qgaev/d_cicd_for_machine_learning/,ps_dillon,1540231222,"I've seen a few posts about CI/CD best practices for ML pipelines. Curious what best practices people are seeing emerge. Is anyone using a Jenkins/Travis/etc for their ML work? 

&amp;#x200B;

I collected my own thoughts on how these newer pipelines differ from i.e. web app pipelines. Would love any feedback!

[https://blog.paperspace.com/ci-cd-for-machine-learning-ai/](https://blog.paperspace.com/ci-cd-for-machine-learning-ai/)",3,1,False,self,,,,,
1232,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,3,9qgn6m,self.MachineLearning,Is ML/Computer Vision research slowing?,https://www.reddit.com/r/MachineLearning/comments/9qgn6m/is_mlcomputer_vision_research_slowing/,timmytimmyturner12,1540233493,"Seems like we haven't had a record-breaking Res-Net/DenseNet in a few cycles, and new approaches like Capsule-Nets have proven to be quite a dud. Is it just me or was the last round of ICLR/NIPS submissions quite underwhelming?",0,1,False,self,,,,,
1233,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,3,9qgoqb,self.MachineLearning,Gumbel Softmax vs Simple Softmax,https://www.reddit.com/r/MachineLearning/comments/9qgoqb/gumbel_softmax_vs_simple_softmax/,amahmood1,1540233775,[removed],0,1,False,self,,,,,
1234,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,3,9qgtse,self.MachineLearning,OCR for Medieval writing,https://www.reddit.com/r/MachineLearning/comments/9qgtse/ocr_for_medieval_writing/,mimYounes,1540234680,[removed],0,1,False,self,,,,,
1235,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,4,9qh7md,github.com,My First ML Project - GAN that Learns to Generate Pencil Sketches,https://www.reddit.com/r/MachineLearning/comments/9qh7md/my_first_ml_project_gan_that_learns_to_generate/,santoso-sheep,1540237055,,0,1,False,default,,,,,
1236,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,5,9qhoc9,self.MachineLearning,[D] How many research projects at once during a PhD?,https://www.reddit.com/r/MachineLearning/comments/9qhoc9/d_how_many_research_projects_at_once_during_a_phd/,rtk25,1540240189,"Hey everyone,

I was wondering what your thoughts are on how many research projects can be reasonably pursued simultaneously during a full-time PhD or equivalent. Obviously this differs under individual circumstances, so it would be interesting to hear those as well :)

In my case, I've recently started a PhD Data Science program. I have a topic ""close to heart"" which I would really like to make serious progress with. There is a large engineering element to it, so even just a POC will demand a lot of work- maybe a few months of full-time work. However, my advisor would like me to primarily pursue a largely unrelated topic and has suggested a 2/3 day division between the two, respectively (2 days for first subject, 3 for second). Currently, in both I would be mainly on my own. I'm a little worried that such a split would diffuse my efforts and that both projects may wallow for lack of critical mass.

&amp;#x200B;

Would be happy to hear your 0.02$!",12,1,False,self,,,,,
1237,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,5,9qhsmv,self.MachineLearning,[D] Organizing papers and annotations.,https://www.reddit.com/r/MachineLearning/comments/9qhsmv/d_organizing_papers_and_annotations/,asdfajsdkfj,1540240952,"Apologies if this has been discussed before. Wanted to quickly survey readers here on how they go about annotating research papers and organizing them when reading through.

I'm trying to decide whether something like Evernote is a decent approach or if there is some secret/not well known online solution for this that's especially optimized for research papers. ",6,1,False,self,,,,,
1238,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,5,9qhumx,github.com,GAN Learns to Pencil Sketch,https://www.reddit.com/r/MachineLearning/comments/9qhumx/gan_learns_to_pencil_sketch/,santoso-sheep,1540241304,,0,1,False,https://a.thumbs.redditmedia.com/99D5gULX0gqRo-lWalkga-54E4deZw78vSI391vIFh8.jpg,,,,,
1239,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,6,9qi14h,self.MachineLearning,In the data cleaning process how do you identify the dependent variables and how to know what kind of operations to perform on them?,https://www.reddit.com/r/MachineLearning/comments/9qi14h/in_the_data_cleaning_process_how_do_you_identify/,realprime,1540242476,[removed],0,1,False,self,,,,,
1240,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,6,9qi50k,docs.google.com,Can you guys please fill put my survey about Artificial Intelligence!,https://www.reddit.com/r/MachineLearning/comments/9qi50k/can_you_guys_please_fill_put_my_survey_about/,jenish-2147,1540243193,,0,1,False,default,,,,,
1241,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,6,9qifea,self.MachineLearning,Batch Normalization Quirks in RL in PyTorch,https://www.reddit.com/r/MachineLearning/comments/9qifea/batch_normalization_quirks_in_rl_in_pytorch/,penguinshin,1540245137,[removed],0,1,False,self,,,,,
1242,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,6,9qigt7,youtu.be,[P] A Horrifying Trip into the Uncanny Valley with GANs,https://www.reddit.com/r/MachineLearning/comments/9qigt7/p_a_horrifying_trip_into_the_uncanny_valley_with/,coolstuffthatiscool,1540245410,,1,1,False,default,,,,,
1243,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,8,9qjetj,self.MachineLearning,[D] Has anyone successfully implemented float16 embedding for word2vec ? So far training has been extremely slow for me for some reason.,https://www.reddit.com/r/MachineLearning/comments/9qjetj/d_has_anyone_successfully_implemented_float16/,BatmantoshReturns,1540252017,"Theoretically it should be faster with float16, but it turns out to be slower, in some cases much slower. 

If anyone is interested, here's the code I used

https://drive.google.com/file/d/1bnlSfezPqtwapvURRTAqGR4mkcCl9QZl/view

I opened the issue on the official Tensorflow github

https://github.com/tensorflow/tensorflow/issues/23086

I really hope to be able to implement float16, because that would lead to recommendation systems that can take in many more items, 8 or 9 figures of items. ",4,1,False,self,,,,,
1244,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,8,9qjf6x,arxiv.org,[R] Supervising strong learners by amplifying weak experts (OpenAI),https://www.reddit.com/r/MachineLearning/comments/9qjf6x/r_supervising_strong_learners_by_amplifying_weak/,milaworld,1540252100,,3,1,False,default,,,,,
1245,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,10,9qkbi5,self.MachineLearning,[P] Trying to implement Triplet Loss and not getting good results as I expected,https://www.reddit.com/r/MachineLearning/comments/9qkbi5/p_trying_to_implement_triplet_loss_and_not/,Ajju19,1540258833,I'm working on Triplet loss for standford cars dataset. I've tried using Triplet loss provided by https://github.com/adambielski/siamese-triplet and I've used the same strategy used in this code to get my triplets for both offline and online mining . The number of correct predictions I get using Triplet loss are less than 10% (both online and offline). I also tried the same dataset using  cross-entropy loss and ended up with better results  like 70% correct predictions. I'm curious to understand why is this happening and if there are better ways to mine for triplets. I've used Resnet-18 for both triplet loss and cross entropy loss.,13,1,False,self,,,,,
1246,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,11,9qkmqq,i.redd.it,Unsupervised Machine learning,https://www.reddit.com/r/MachineLearning/comments/9qkmqq/unsupervised_machine_learning/,onclick360,1540261251,,1,1,False,default,,,,,
1247,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,11,9qkp2i,self.MachineLearning,Is there a book or resource about machine learning that teaches different algorithms with step by step calculations for simple examples? Like how a mathematics or physics book would.,https://www.reddit.com/r/MachineLearning/comments/9qkp2i/is_there_a_book_or_resource_about_machine/,ihollaback,1540261783,,0,1,False,self,,,,,
1248,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,11,9qku70,self.MachineLearning,AI Safety and Security Discord,https://www.reddit.com/r/MachineLearning/comments/9qku70/ai_safety_and_security_discord/,starstorm312,1540262914,[removed],0,1,False,self,,,,,
1249,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,11,9qkvxm,self.MachineLearning,[Discussion]Is there a book or resource about machine learning that teaches different algorithms with step by step calculations for simple examples? Like how a mathematics or physics book would.,https://www.reddit.com/r/MachineLearning/comments/9qkvxm/discussionis_there_a_book_or_resource_about/,ihollaback,1540263311,,0,1,False,self,,,,,
1250,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,12,9ql11l,self.MachineLearning,[D] Is there a book or resource about machine learning that teaches different algorithms with step by step calculations for simple examples? Like how a mathematics or physics book would.,https://www.reddit.com/r/MachineLearning/comments/9ql11l/d_is_there_a_book_or_resource_about_machine/,ihollaback,1540264463,"Many books have equations or sample code, but few run through classification steps with an example that does all of the math by hand.",75,1,False,self,,,,,
1251,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,12,9ql8k4,self.MachineLearning,Advice on handwritten text recognition?,https://www.reddit.com/r/MachineLearning/comments/9ql8k4/advice_on_handwritten_text_recognition/,veilerdude,1540266170,[removed],0,1,False,self,,,,,
1252,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,12,9qlcki,stats.stackexchange.com,Yolo v3 loss function? [D],https://www.reddit.com/r/MachineLearning/comments/9qlcki/yolo_v3_loss_function_d/,themathstudent,1540267131,,0,1,False,default,,,,,
1253,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,13,9qleie,self.MachineLearning,Chatbot,https://www.reddit.com/r/MachineLearning/comments/9qleie/chatbot/,xXPrateekXx,1540267581,[removed],0,1,False,self,,,,,
1254,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,15,9qm8a8,self.MachineLearning,"How would an ML classifier assign a datapoint to the class that represents ""None of the Above""",https://www.reddit.com/r/MachineLearning/comments/9qm8a8/how_would_an_ml_classifier_assign_a_datapoint_to/,mayurjay,1540275260,[removed],0,1,False,self,,,,,
1255,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,15,9qmdwd,self.MachineLearning,[D] How to properly cite google earth images in a research paper?,https://www.reddit.com/r/MachineLearning/comments/9qmdwd/d_how_to_properly_cite_google_earth_images_in_a/,cbsudux,1540276854,"According to [https://www.google.com/permissions/geoguidelines/attr-guide/](https://www.google.com/permissions/geoguidelines/attr-guide/), I need to mention Map data 2018 Google"" as an image caption. 

&amp;#x200B;

What do I put in the references section?",0,1,False,self,,,,,
1256,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,16,9qmjjw,readyforai.com,Introduction of computer vision machine learning development,https://www.reddit.com/r/MachineLearning/comments/9qmjjw/introduction_of_computer_vision_machine_learning/,seeryang,1540278503,,0,1,False,default,,,,,
1257,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,16,9qmjl6,self.MachineLearning,Credit card transactions related datasets for graph visualization.,https://www.reddit.com/r/MachineLearning/comments/9qmjl6/credit_card_transactions_related_datasets_for/,JJbiki,1540278513,[removed],0,1,False,self,,,,,
1258,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,16,9qmjqi,self.MachineLearning,What are you working on TODAY?,https://www.reddit.com/r/MachineLearning/comments/9qmjqi/what_are_you_working_on_today/,Fito33Pete,1540278557,[removed],0,1,False,self,,,,,
1259,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,16,9qmknz,self.MachineLearning,Unsupervised pattern recognition/detection,https://www.reddit.com/r/MachineLearning/comments/9qmknz/unsupervised_pattern_recognitiondetection/,Sirhc78870,1540278814,[removed],0,1,False,self,,,,,
1260,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,16,9qmkx7,self.MachineLearning,[D] What is an extended abstract?,https://www.reddit.com/r/MachineLearning/comments/9qmkx7/d_what_is_an_extended_abstract/,cbsudux,1540278884,A few workshops in NIPS ask for a 2-4 page extended abstract. ,0,1,False,self,,,,,
1261,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,16,9qmmmh,dexlabanalytics.com,"How Machine Learning is Driving Out DDoS, The Latest Hazard in Cyber Security",https://www.reddit.com/r/MachineLearning/comments/9qmmmh/how_machine_learning_is_driving_out_ddos_the/,dexlabanalytics,1540279370,,0,1,False,default,,,,,
1262,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,16,9qmrk1,arxiv.org,[R] Synscapes: A Photorealistic Synthetic Dataset for Street Scene Parsing,https://www.reddit.com/r/MachineLearning/comments/9qmrk1/r_synscapes_a_photorealistic_synthetic_dataset/,jonun,1540280916,,0,1,False,default,,,,,
1263,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,16,9qmtdp,github.com,"Implementation of NIPS 2017 paper ""Pose Guided Person Image Generation"" in PyTorch. https://arxiv.org/abs/1705.09368",https://www.reddit.com/r/MachineLearning/comments/9qmtdp/implementation_of_nips_2017_paper_pose_guided/,iamharsshit,1540281507,,0,1,False,default,,,,,
1264,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,17,9qn32l,self.MachineLearning,identifying patterns in text data,https://www.reddit.com/r/MachineLearning/comments/9qn32l/identifying_patterns_in_text_data/,hasagi69,1540284567,[removed],0,1,False,self,,,,,
1265,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,18,9qn61s,youtube.com,What Is Machine Learning And How Does It Work? - Learn in just 10 Mins,https://www.reddit.com/r/MachineLearning/comments/9qn61s/what_is_machine_learning_and_how_does_it_work/,pooja307,1540285480,,0,1,False,default,,,,,
1266,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,18,9qn8ck,self.MachineLearning,Deploy Python Sci-kit model in Spring Boot,https://www.reddit.com/r/MachineLearning/comments/9qn8ck/deploy_python_scikit_model_in_spring_boot/,naveenmvv,1540286155,"&amp;#x200B;

I have a sci-kit MLP model to be deployed. Can i deploy it in Spring Boot. Is there any lib that can read model and predict in java.

i deployed using Flask, is there a way to port to java.",0,1,False,self,,,,,
1267,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,18,9qnaxv,self.MachineLearning,Is there a way to synthesise features in Keras?,https://www.reddit.com/r/MachineLearning/comments/9qnaxv/is_there_a_way_to_synthesise_features_in_keras/,Zman420,1540286927,"In some libraries, like VowpalWabbit, you can use a command (e.g --cubic) to do some cross-feature multiplication to create far more features.

Is there something similar in Keras? I've got about 5000 features per instance at the moment, so doing the cross-multiplication to create more features into a csv ahead of time is not practical ahead of time because of the vast disc usage.",0,1,False,self,,,,,
1268,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,18,9qneck,self.MachineLearning,[D] Latest digital transformation trends,https://www.reddit.com/r/MachineLearning/comments/9qneck/d_latest_digital_transformation_trends/,FitRemove,1540287929,"For machine learning to become more accurate and usable, I feel that data processing capabilities have to increase significantly. I have here created a list of the biggest digital transformations to look forward to next year. Thoughts?

&amp;#x200B;

teks.co.in/site/blog/top-12-trends-in-digital-transformation-to-watch-out-for-in-2019/",0,1,False,self,,,,,
1269,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,18,9qneji,self.MachineLearning,How to build a CNN which classifies bald people and people with hair?,https://www.reddit.com/r/MachineLearning/comments/9qneji/how_to_build_a_cnn_which_classifies_bald_people/,lakshaydulani,1540287990,"I have gone through a lot of online resources on the topic of CNN and I can say that I have a good understanding of how things work in a CNN.

But having gone through simple tutorial CNNs which have using their own layers, I still dont how to get started with building one for a new classification from the scratch.

What will be the filters? Whether convolution will have activation ReLU or something else?

How many images of bald and hairy men should I arrange?

Please advise me as in how should I proceed? I dont have a GPU based machine.

 ",0,1,False,self,,,,,
1270,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,18,9qngax,self.MachineLearning,[D] Is there a way to synthesise features in Keras?,https://www.reddit.com/r/MachineLearning/comments/9qngax/d_is_there_a_way_to_synthesise_features_in_keras/,Zman420,1540288498,"In some libraries, like VowpalWabbit, you can use a command (e.g --cubic) to do some cross-feature multiplication to create far more features.

Is there something similar in Keras? I've got about 5000 features per instance at the moment, so doing the cross-multiplication to create more features into a csv ahead of time is not practical because of the vast disc usage.
",0,1,False,self,,,,,
1271,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,18,9qngfi,self.MachineLearning,Deploy Python Sci-kit model in Spring Boot,https://www.reddit.com/r/MachineLearning/comments/9qngfi/deploy_python_scikit_model_in_spring_boot/,naveenmvv,1540288531," I have a sci-kit MLP model to be deployed. Can i deploy it in Spring Boot. Is there any lib that can read model and predict in java.

i deployed using Flask, is there a way to port to java.",0,1,False,self,,,,,
1272,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,19,9qnlow,self.MachineLearning,Real world example with Spark,https://www.reddit.com/r/MachineLearning/comments/9qnlow/real_world_example_with_spark/,angelovdaa,1540289922,[removed],0,1,False,self,,,,,
1273,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,19,9qno6b,self.MachineLearning,Remote Jupyter notebook Issue,https://www.reddit.com/r/MachineLearning/comments/9qno6b/remote_jupyter_notebook_issue/,stunods57,1540290587,[removed],0,1,False,self,,,,,
1274,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,20,9qo1o2,self.MachineLearning,[D] Is AMD's RYZEN CPUs good choice for machine learning study/projects,https://www.reddit.com/r/MachineLearning/comments/9qo1o2/d_is_amds_ryzen_cpus_good_choice_for_machine/,JeffreyChl,1540294020,"Okay I'm new to this forum and I mostly see academic discussions on this forum so I guess newb questions might not be so popular here but I thought it was better than asking on Quora. 

&amp;#x200B;

Cut to the chase, is it good idea to use AMD's RYZEN 2700x or 2600x for machine learning/projects?

Does it have any possible/reported issue with machine learning library/platforms in use compared to (standard) Intel CPUs? 

Also, is 2700x/2600x which is fairly high-end an overkill for machine learning and data analysis? (They are considered great choices for gaming but that's not my interest.)

&amp;#x200B;

&amp;#x200B;

To add more details and story to my question: I'm fairly new to machine learning and studying it from very basic - Andrew Ng's Coursera lectures and CS231n course by Stanford Univ. Later on, I'm planning to implement my knowledge on real world problems like Kaggle tournaments or other various applications ranging from image analysis to NLP to quantitative investment models. 

My current system is a bit outdated and less powerful i3-6100 / 16gb ram / enough ssd space and the system lags from time to time when I open up too many Stackoverflow tabs with Pycharm running. So I was looking for an upgrade.

One day a friend of mine who's fairly good at machine learning and definitely on higher level than me advised me to get a good set of PC with decent CPU and GPU if I want to get serious with machine learning. However since my budget is limited, I don't wanna spend too much on CPU unit to save some money to buy GPU and other stuffs. 

Benchmarks on many hardware forums suggest that Intel's CPU is no better than AMD's when it comes to price-value ratio but I heard many software are optimized for Intel CPUs and even more, AMD CPUs can sometime get quirky and unstable. (This might just be an urban myth since I'm not so knowledgeable with hardware-level optimizations.) 

&amp;#x200B;

What do you guys think? Anyone using AMD CPUs and having some trouble? 

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;",32,1,False,self,,,,,
1275,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,20,9qo1ud,siemplify.co,What Machine Learning Means for Security Operations,https://www.reddit.com/r/MachineLearning/comments/9qo1ud/what_machine_learning_means_for_security/,siemplifyco,1540294060,,0,1,False,default,,,,,
1276,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,20,9qo58z,self.MachineLearning,"[P] Regression implemented four different ways (MLE, OLS, GD, MCMC)",https://www.reddit.com/r/MachineLearning/comments/9qo58z/p_regression_implemented_four_different_ways_mle/,Xochipilli,1540294890,"[https://peterroelants.github.io/posts/linear-regression-four-ways/](https://peterroelants.github.io/posts/linear-regression-four-ways/)

Blogpost I just published that explores the foundation of linear regression and implements four different methods of training a regression model on toy data: 

1. Maximum likelihood estimation (MLE)
2. Ordinary least squares (OLS)
3. Gradient descent
4. Markov chain monte carlo (MCMC)",23,1,False,self,,,,,
1277,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,20,9qo5an,liip.ch,A-Z Tutorial: From MNIST dataset to real-time iPhone recognition app with CoreML.,https://www.reddit.com/r/MachineLearning/comments/9qo5an/az_tutorial_from_mnist_dataset_to_realtime_iphone/,plotti,1540294903,,0,1,False,default,,,,,
1278,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,20,9qo7np,self.MachineLearning,Neuro-Evolution with Dinosaurs,https://www.reddit.com/r/MachineLearning/comments/9qo7np/neuroevolution_with_dinosaurs/,Max_Lell,1540295500,"Hey folks,

You ever had the urge of creating your own Dino-population like they do in Jurassic park? Well here you go :D

I just recently published my attempt of a Deep Reinforcement Neuro-Evolution Algorithm, which is able to learn and play the Chrome-Browser Dino Game to a level, which is not-human-achievable. 

You might say: Well you can solve this game, by simply writing a suitable IF-ELSE-command, but ... well I wanted to learn this and required a simple game to do so. I wrote the algorithm and the game from scratch.

Anyway: Please feel free to check it out: [https://medium.com/@maximilian.lell/neuro-evolution-with-dinosaurs-1cfce5eadbd8](https://medium.com/@maximilian.lell/neuro-evolution-with-dinosaurs-1cfce5eadbd8) 

The source code is also available: [https://github.com/MaxLell/Chrome\_Dino\_AI](https://github.com/MaxLell/Chrome_Dino_AI)

Looking forward to critique. Any suggestions?

Greetings ;)

&amp;#x200B;",0,1,False,self,,,,,
1279,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,20,9qo8g2,apsense.com,What is the scope of Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/9qo8g2/what_is_the_scope_of_machine_learning/,smadrid056,1540295709,,0,1,False,default,,,,,
1280,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,21,9qopio,self.MachineLearning,Question about NIPS registration,https://www.reddit.com/r/MachineLearning/comments/9qopio/question_about_nips_registration/,sidsig,1540299457,[removed],0,1,False,self,,,,,
1281,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,22,9qov53,self.MachineLearning,Data Science Webinar: Recommender Systems - From Simple to Complex - November 15,https://www.reddit.com/r/MachineLearning/comments/9qov53/data_science_webinar_recommender_systems_from/,supercake53,1540300597,"Recommender Systems are a collection of algorithms that can be used to personalize content and offers for customers. Often considered one of the most successful and widespread application of machine learning technologies in business, they have been employed by major companies like Netflix, Amazon or Google to create new revenue streams and provide tailored experiences. Fortunately, their benefits are not limited to major tech companies with deep pockets. With a minimal technical background, almost anyone can implement a simple recommender system.

The objective of this webinar, hosted by Bigstep's Data Scientist, Andras Palfi, is to demystify the algorithms and methods used by recommender systems and provide a few practical use cases. No previous technical background is necessary, but familiarity with high-school level programming and mathematics will be helpful.

For more details, you can check out [this article](https://bigstep.com/blog/data-science-webinar-recommender-systems-from-simple-to-complex), for fast registering, see [here](https://zoom.us/webinar/register/5115397636034/WN_-Ch4K0gLTYeTEv5l2L8Ojw).",0,1,False,self,,,,,
1282,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,22,9qp13w,nymag.com,The Secretive Business of Facial-Recognition Software in Retail Stores,https://www.reddit.com/r/MachineLearning/comments/9qp13w/the_secretive_business_of_facialrecognition/,j_orshman,1540301820,,0,1,False,default,,,,,
1283,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,23,9qp8wi,self.MachineLearning,Transformers: Attention is All You Need,https://www.reddit.com/r/MachineLearning/comments/9qp8wi/transformers_attention_is_all_you_need/,ElegantFeeling,1540303329,[removed],0,1,False,self,,,,,
1284,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,23,9qpo8d,self.MachineLearning,Uses Machine Learning to Determine age based on facial characteristics,https://www.reddit.com/r/MachineLearning/comments/9qpo8d/uses_machine_learning_to_determine_age_based_on/,LasekApps,1540306215,"[Machine Learning Age Predictor](https://itunes.apple.com/ca/app/whats-my-age-how-old-am-i/id1437333124)

&amp;#x200B;

Let me know the age you get :) If there are any improvements I can make also let me know. ",0,1,False,self,,,,,
1285,MachineLearning,t5_2r3gv,2018-10-23,2018,10,23,23,9qprdz,youtube.com,"[R] GANs, challenges and research topics, by Tatjana Chavdarova (EPFL)",https://www.reddit.com/r/MachineLearning/comments/9qprdz/r_gans_challenges_and_research_topics_by_tatjana/,narsilouu,1540306791,,0,1,False,https://b.thumbs.redditmedia.com/Hf48OvZJOgAqDk-TPl5a7FmHROaWzuN-dHyTzd1E2bs.jpg,,,,,
1286,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,0,9qprie,self.MachineLearning,[D] I'm going to be starting a new job as a researcher in the new year. What do you wish you knew before getting started? And how can I best prepare?,https://www.reddit.com/r/MachineLearning/comments/9qprie/d_im_going_to_be_starting_a_new_job_as_a/,WestShare,1540306812,"I'm going to be starting a new job in research in a few months -- most of my work so far has been on the engineering side of projects. The enviorment is going to be fairly academic, I'll be placed on existing projects but also have the opportunity to do independent work. My workload right now is fairly light and I have a considerable amount of free time to prepare. I really want to make the most of this experience - how should I best prepare? Especially for working on independent research projects. ",10,1,False,self,,,,,
1287,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,0,9qpvkd,self.MachineLearning,"[R] Talk on GANs, its challenges and research topics by Tatjana Chavdarova (EPFL) at ParisGAN meetup",https://www.reddit.com/r/MachineLearning/comments/9qpvkd/r_talk_on_gans_its_challenges_and_research_topics/,narsilouu,1540307519,"Talk [https://www.youtube.com/watch?v=m9USSDtUy40](https://www.youtube.com/watch?v=m9USSDtUy40)

The topic start by explaining what is a GAN before adressing more complex subjects, like mode collapse, evaluation metric (IS, FID) and various extensions of GANs.

If you are living in Paris you can attend the next meetup: [https://www.meetup.com/fr-FR/Paris-GANs-co/](https://www.meetup.com/fr-FR/Paris-GANs-co/)",0,1,False,self,,,,,
1288,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,0,9qpxpt,youtube.com,How Does Artificial Intelligence React to Conflicting Orders? - AI Insig...,https://www.reddit.com/r/MachineLearning/comments/9qpxpt/how_does_artificial_intelligence_react_to/,Cogno-Res,1540307896,,0,1,False,default,,,,,
1289,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,0,9qpy37,self.MachineLearning,[P] Nonlinear regression with NNs and knn,https://www.reddit.com/r/MachineLearning/comments/9qpy37/p_nonlinear_regression_with_nns_and_knn/,maka89,1540307972,"Training NNs for regression of highly nonlinear functions with low dimensional input can often be slow and frustrating task. Classify CIFAR-10 images? No problem.  Regression on y=sin(2\*pi\*30\*x) ? Not so easy, even with lots of data.

&amp;#x200B;

Kernel methods work well, but also has its issues (Limited size of dataset, there is one characteristic lengthscale for every input parameter, this lengthscale is also fixed over the entire range).

&amp;#x200B;

This project I work on coming up with NN architectures for doing simple nonlinear regression / spatial interpolation. Main trick is that I input kNN datapoints in the training set into the neural network in addition to regular input.

&amp;#x200B;

[https://github.com/maka89/ccnet](https://github.com/maka89/ccnet)",10,1,False,self,,,,,
1290,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,0,9qq1jb,self.MachineLearning,[P] Safe Reinforcement Learning with Model Uncertainty Estimates,https://www.reddit.com/r/MachineLearning/comments/9qq1jb/p_safe_reinforcement_learning_with_model/,Blutjens,1540308584,"Many current autonomous systems are being designed with a strong reliance on black box predictions from deep neural networks (DNNs). However, DNNs tend to be overconfident in predictions on unseen data and can give unpredictable results for far-from-distribution test data. The importance of predictions that are robust to this distributional shift is evident for safety-critical applications, such as collision avoidance around pedestrians. Measures of model uncertainty can be used to identify unseen data, but the state-of-the-art extraction methods such as Bayesian neural networks are mostly intractable to compute. This paper uses MC-Dropout and Bootstrapping to give computationally tractable and parallelizable uncertainty estimates. The methods are embedded in a Safe Reinforcement Learning framework to form uncertainty-aware navigation around pedestrians. The result is a collision avoidance policy that knows what it does not know and cautiously avoids pedestrians that exhibit unseen behavior. The policy is demonstrated in simulation to be more robust to novel observations and take safer actions than an uncertainty-unaware baseline.",0,1,False,self,,,,,
1291,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,0,9qq57i,arxiv.org,[R] Safe Reinforcement Learning with Model Uncertainty Estimates,https://www.reddit.com/r/MachineLearning/comments/9qq57i/r_safe_reinforcement_learning_with_model/,Blutjens,1540309229,,2,1,False,default,,,,,
1292,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,1,9qqgdz,news.ucsb.edu,UC Santa Barbara will collaborate on a Department of Energy research center adapting machine learning for use in scientific research,https://www.reddit.com/r/MachineLearning/comments/9qqgdz/uc_santa_barbara_will_collaborate_on_a_department/,Chipdoc,1540311182,,2,1,False,default,,,,,
1293,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,1,9qqhkq,medium.com,[N] Baidu Announces Breakthrough in Simultaneous Translation,https://www.reddit.com/r/MachineLearning/comments/9qqhkq/n_baidu_announces_breakthrough_in_simultaneous/,gwen0927,1540311387,,0,1,False,https://b.thumbs.redditmedia.com/2cvmqCBjkHGCrxebxTRoZxU4PIYg08MAMzVahml8-4Y.jpg,,,,,
1294,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,2,9qreli,self.MachineLearning,How to apply capsule nets to your own dataset?,https://www.reddit.com/r/MachineLearning/comments/9qreli/how_to_apply_capsule_nets_to_your_own_dataset/,Raman070,1540317284,I am trying to apply capsule networks to my own dataset. Can anyone provide me any resource which addresses this problem?,0,1,False,self,,,,,
1295,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,2,9qrfod,self.MachineLearning,machine learning reusable component,https://www.reddit.com/r/MachineLearning/comments/9qrfod/machine_learning_reusable_component/,i3ahad,1540317484,[removed],0,1,False,self,,,,,
1296,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,3,9qrk4z,self.MachineLearning,Vectorized K-Means Algorithm?,https://www.reddit.com/r/MachineLearning/comments/9qrk4z/vectorized_kmeans_algorithm/,reygoch,1540318282,[removed],0,1,False,self,,,,,
1297,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,3,9qrpo2,blog.rogerluo.me,Implement Your Own Automatic Differentiation with Julia in ONE day,https://www.reddit.com/r/MachineLearning/comments/9qrpo2/implement_your_own_automatic_differentiation_with/,Bdamkin54,1540319302,,0,1,False,default,,,,,
1298,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,3,9qrqy5,github.com,PySyft - a PyTorch module for Encrypted Deep Learning,https://www.reddit.com/r/MachineLearning/comments/9qrqy5/pysyft_a_pytorch_module_for_encrypted_deep/,iamtrask,1540319542,,0,1,False,default,,,,,
1299,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,3,9qrxo4,self.MachineLearning,[D] Is there any progress on one-step installation of Neural Style Transfer networks for 'regular' Windows end-users ?,https://www.reddit.com/r/MachineLearning/comments/9qrxo4/d_is_there_any_progress_on_onestep_installation/,ad48hp,1540320842,"Having no prior knowledge of neither Lua or Python, i have found installing nearly every single deep-learning oriented Github repository exceptionally hard, spending days trying to figure out how to install each of the prerequirements, having several errors while installing them, as most of the work done by researchers focus on the Unix systems. The same can be said about super-resolution and SLAM algorithms. While there are plenty of videos showcasing experimental progress, it's hard to find a binary of even 6 years outdated techniques. Something that is marketed as being easy-to-setup like Deepfakes, still took me about 2 days to prepare (after installing CUDA &amp; cuDNN seperately). I have found out that out of entire, large libraries (CUDA having 1,6GB and cuDNN another 176MB), only about hundreth is needed for the actual piece of software to run.

I have found an implentation in Java that is still inside an enormous repository containing various diverse examples, and i would be mad to experience it again after downloading all of it.

The only rep. that i had success running so far was the [*Deep Image Analogy*](https://www.reddit.com/r/MachineLearning/comments/6cro6h/r_deep_image_analogy_code_and_demo_are_released/) which still lacked some dll libraries i had to take out of the cuDNN install afterwards.",5,1,False,self,,,,,
1300,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,4,9qs580,youtube.com,T3 Neural Nets,https://www.reddit.com/r/MachineLearning/comments/9qs580/t3_neural_nets/,soulslicer0,1540322233,,0,1,False,default,,,,,
1301,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,4,9qs7ee,self.MachineLearning,[P] Training the YOLO model to recognize person of significance.,https://www.reddit.com/r/MachineLearning/comments/9qs7ee/p_training_the_yolo_model_to_recognize_person_of/,CSGOvelocity,1540322630,"I am planning to train the YOLO model on a custom dataset of images of 13 people of significance.

What I want to know is:

1. How many images it might need per person ? Currently, I think it needs about 400-450 per person seeing the PASCAL VOC dataset.
2. Can some images be redundant or does every image need to be unique in some way ?
3. Should I do some partial labelling of faces as in label only the top half / bottom half of the face in some images ? 
4. Should I keep drawings of that person in the dataset ?

I already know how to label and format the labelling for images using the BBox Label tool.",4,1,False,self,,,,,
1302,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,4,9qsd5d,self.MachineLearning,Using machine learning for ranking news in a feed,https://www.reddit.com/r/MachineLearning/comments/9qsd5d/using_machine_learning_for_ranking_news_in_a_feed/,youni0,1540323678,[removed],0,1,False,self,,,,,
1303,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,4,9qsdah,self.MachineLearning,"Progress Bar - A short film co-written by RivetAI, and artificial intelligence program.",https://www.reddit.com/r/MachineLearning/comments/9qsdah/progress_bar_a_short_film_cowritten_by_rivetai/,PLATINUMPETEDOG,1540323709,"&lt;iframe src=""\\\[https://player.vimeo.com/video/296346787?byline=0&amp;portrait=0\\\](https://player.vimeo.com/video/296346787?byline=0&amp;portrait=0)"" width=""640"" height=""360"" frameborder=""0"" webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;    


&lt;p&gt;&lt;a href=""\\\[https://vimeo.com/296346787\\\](https://vimeo.com/296346787)""&gt;Progress Bar&lt;/a&gt; from &lt;a href=""\\\[https://vimeo.com/petermccoubrey\\\](https://vimeo.com/petermccoubrey)""&gt;Peter McCoubrey&lt;/a&gt; on &lt;a href=""\\\[https://vimeo.com\\\](https://vimeo.com)""&gt;Vimeo&lt;/a&gt;.&lt;/p&gt;    


&lt;p&gt;In a near future, a woman navigates a virtual customer service call via her own avatar and digital assistant. &lt;br /&gt;    


&lt;br /&gt;    


This film was written and directed by a human, however, LEXI\&amp;#039;s dialogue was generated by RivetAI, an artificial intelligence program.&lt;br /&gt;

&lt;br /&gt;    


From the producers of 2016\&amp;#039;s \&amp;quot;A.I. scripted\&amp;quot; viral sensation, SUNSPRING:  [https://youtu.be/LY7x2Ihqjmc](https://youtu.be/LY7x2Ihqjmc)&lt;br /&gt;

&lt;br /&gt;    


PROGRESS BAR is an experiment that attempts to harness the inherent absurdity of dialogue generated by A.I. (as seen in SUNSPRING) by placing it within the confines of a more traditional (human-written) narrative film structure. &lt;br /&gt;

&lt;br /&gt;    


Starring Jennifer Kim (Search Party, Mozart in the Jungle) Lucy Walters (Get Shorty, Power) and Kevin Breznahan (The Deuce, Billions)&lt;br /&gt;

&lt;br /&gt;    


[www.rivetai.com](https://www.rivetai.com)&lt;br /&gt;

[www.endcue.com](https://www.endcue.com)&lt;br /&gt;

&lt;br /&gt;    


Written \&amp;amp; Directed by Peter McCoubrey&lt;br /&gt;

LEXI dialogue generated by RivetAI&lt;br /&gt;

Director of Photography Luke McCoubrey&lt;br /&gt;

Produced by Andrew Kortschak, Walter Kortschak, Debajyoti Ray&lt;br /&gt;

Co-Producer Sadaf Amouzegar&lt;br /&gt;

Produced by Emily Wiedemann, Chazz Carfora, Jennifer Sharpe&lt;br /&gt;

Composer Ron Patane&lt;br /&gt;

Production Designer Marta Castaing&lt;br /&gt;

Wardrobe Jackie McCoubrey&lt;br /&gt;

Production Company Greencard Pictures / End Cue&lt;br /&gt;

&lt;br /&gt;    


&lt;br /&gt;    


RAE - Jennifer Kim&lt;br /&gt;

LEXI - Lucy Walters&lt;br /&gt;

REP/AVATAR - Kevin Breznahan&lt;/p&gt;",0,1,False,self,,,,,
1304,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,4,9qseh0,self.MachineLearning,Effective Time Series Forecasting Methods When dealing with low data?,https://www.reddit.com/r/MachineLearning/comments/9qseh0/effective_time_series_forecasting_methods_when/,SpartanElite123,1540323934,[removed],0,1,False,self,,,,,
1305,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,4,9qsfjg,self.MachineLearning,Face recognition,https://www.reddit.com/r/MachineLearning/comments/9qsfjg/face_recognition/,roseqqq,1540324135,[removed],0,1,False,self,,,,,
1306,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,4,9qshxk,self.MachineLearning,Machine Learning from a business perspective (i.e. - applications),https://www.reddit.com/r/MachineLearning/comments/9qshxk/machine_learning_from_a_business_perspective_ie/,granite603,1540324599,[removed],0,1,False,self,,,,,
1307,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,5,9qsk2d,self.datascience,Doing an interview with Ian Goodfellow. What questions should I ask?,https://www.reddit.com/r/MachineLearning/comments/9qsk2d/doing_an_interview_with_ian_goodfellow_what/,jdyr1729,1540324969,,0,1,False,default,,,,,
1308,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,5,9qskx1,intelauthentic.com,Extreme Gradient Boosting to Lift Click Through Rates by 15%,https://www.reddit.com/r/MachineLearning/comments/9qskx1/extreme_gradient_boosting_to_lift_click_through/,data_science_manager,1540325121,,0,1,False,https://a.thumbs.redditmedia.com/n4mCaZMAamBZDS0SlO9sbWsmvES2iKVH76SPDft6DN4.jpg,,,,,
1309,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,5,9qsmtc,self.MachineLearning,[D] Get started,https://www.reddit.com/r/MachineLearning/comments/9qsmtc/d_get_started/,KJ-16,1540325451,"Hi, I am an research assistant at the engineering department of my university, with a strong focus on factory planning, production management and quality management.

Reading different use cases of ML and its benefits, I would like to start with my own projects (unfortunately my collegues stick to known principles and methods), but I do not really know how begin. 

Main problem is the huge amount of software, books and papers about ML and the feeling of uncertainty without starting point.

Therefore I would like to know:

What book should I start with?
- The Elements of Statistical Learning (Hastie et al)
- Pattern Recognition and Machine Learning (Bishop)
- others?

Which Software should I use (Windows)
- TensorFlow
- Anaconda with SciKit Learn
- RapidMiner
- others?

Aims : Image recognition/classification and output prediction based on given inputs with artificial neural networks.

I hope you can give me some information on how to start, recommandations about must-reads and common mistakes of beginners!",7,1,False,self,,,,,
1310,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,5,9qsnki,self.datascience,Doing an interview with Ian Goodfellow. What questions should I ask?,https://www.reddit.com/r/MachineLearning/comments/9qsnki/doing_an_interview_with_ian_goodfellow_what/,jdyr1729,1540325588,,0,1,False,default,,,,,
1311,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,5,9qsp50,medium.com,[N] GluonCV 0.3 offers some of the best open-sourced and reproducible pretrained models in computer vision,https://www.reddit.com/r/MachineLearning/comments/9qsp50/n_gluoncv_03_offers_some_of_the_best_opensourced/,hetong_007,1540325884,,0,1,False,https://b.thumbs.redditmedia.com/cmDg9SR-1Y-9mS_fy_4wIgUs9I-bFs5J70z3bEpxZGU.jpg,,,,,
1312,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,5,9qszs7,self.MachineLearning,Evaluating GANs,https://www.reddit.com/r/MachineLearning/comments/9qszs7/evaluating_gans/,apinkcat12,1540327838,"It seems like papers mostly report one number per model for inception or fid score. Given how unstable training is, do they search through the network state after each epoch and report the best one? Is there a standarized methodology for reporting performance?",0,1,False,self,,,,,
1313,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,5,9qt23q,self.MachineLearning,[D] Having trouble coming up with an appropriate job title.,https://www.reddit.com/r/MachineLearning/comments/9qt23q/d_having_trouble_coming_up_with_an_appropriate/,stillconfuseddddd,1540328287,"I am a software developer with 2 years experience in the US with a BS in CS. Since my company is small, we all wear many hats, but I mainly develop plugins for B2B desktop applications and may be dealing with plugins for related web apps in the future. Our company would like to add some ML into our mix.

Since I had taken an undergrad AI course, I was the most familiar with the topic, and to gain more familiarity I took a grad-level Machine Learning course, which focused on the theoretical foundations of popular models. Now my boss would like for me to basically be a one-man ML department (with possible interns in the future): coming up with ideas of where to use ML, gathering the required data, selecting implementing and training the models, and then integrating that with our existing tools. I don't expect much research/theoretical stuff, more application of existing techniques to our particular historical data and domain.

Basically, I'm having trouble coming up with a job title that's relevant, but doesn't imply that I'm more educated or experienced than I really am. I may get a masters' someday, but it would be years out. Machine Learning Engineer job listings seem to skew very heavily towards masters and PhDs, or at least people with a ton of experience. Machine Learning Developer seems like it might be a bit better, but I'm not sure. Data Scientist seems to include much more of a statistics background, and a different focus.

Basically, we want an official title for me for client/marketing/business reasons, and I don't want to mislead people. What is appropriate?",23,1,False,self,,,,,
1314,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,6,9qt3er,self.MachineLearning,I'm a late comer to the Machine Learning world - what can I do now to help steer my career into the realm of ML and AI?,https://www.reddit.com/r/MachineLearning/comments/9qt3er/im_a_late_comer_to_the_machine_learning_world/,FullYorker,1540328527,[removed],0,1,False,self,,,,,
1315,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,6,9qte08,self.MachineLearning,The Future of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9qte08/the_future_of_machine_learning/,VirgaAurea,1540330511,Eventually we will have a granular feedback loop of computer optimization to optimize learning and development eedback loops... Inception?,0,1,False,self,,,,,
1316,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,7,9qtzck,self.MachineLearning,[N] NIPS keeps it name unchanged,https://www.reddit.com/r/MachineLearning/comments/9qtzck/n_nips_keeps_it_name_unchanged/,baylearn,1540334692,"from https://nips.cc/Conferences/2018/Press

**NIPS Foundation Board Concludes Name Change Deliberations**

*Conference name will not change; continued focus on diversity and inclusivity initiatives*

Montreal, October 22 2018 -- The Board of Trustees of the Neural Information Processing Systems Foundation has decided not to change the name of their main conference. The Board has been engaged in ongoing discussions concerning the name of the Neural Information Processing Systems, or NIPS, conference. The current acronym, NIPS, has undesired connotations. The Name-of-NIPS Action Team was formed, in order to better understand the prevailing attitudes about the name. The team conducted polls of the NIPS community requesting submissions of alternative names, rating the existing and alternative names, and soliciting additional comments. The polling conducted by the the Team did not yield a clear consensus, and no significantly better alternative name emerged.

Aware of the need for a more substantive approach to diversity and inclusivity that the call for a name change points to, this year NIPS has increased its focus on diversity and inclusivity initiatives. The NIPS code of conduct was implemented, two Inclusion and Diversity chairs were appointed to the organizing committee and, having resolved a longstanding liability issue, the NIPS Foundation is introducing childcare support for NIPS 2018 Conference in Montreal. In addition, NIPS has welcomed the formation of several co-located workshops focused on diversity in the field. Longstanding supporters of the co-located Women In Machine Learning workshop (WiML) NIPS is extending support to additional groups, including Black in AI (BAI), Queer in AI@NIPS, Latinx in AI (LXAI), and Jews in ML (JIML).

Dr. Terrence Sejnowski, president of the NIPS Foundation, says that even though the data on the name change from the survey did not point to one concerted opinion from the NIPS community, focusing on substantive changes will ensure that the NIPS conference is representative of those in its community. As the NIPS conference continues to grow and evolve, it is important that everyone in our community feels that NIPS is a welcoming and open place to exchange ideas. Im encouraged by the meaningful changes weve made to the conference, and more changes will be made based on further feedback.

*About The Conference On Neural Information Processing Systems (NIPS)*

Over the past 32 years, the Neural Information Processing Systems (NIPS) conference has been held at various locations around the world.The conference is organized by the NIPS Foundation, a non-profit corporation whose purpose is to foster insights into solving difficult problems by bringing together researchers from biological, psychological, technological, mathematical, and theoretical areas of science and engineering.

In addition to the NIPS Conference, the NIPS Foundation manages a continuing series of professional meetings including the International Conference on Machine Learning (ICML) and the International Conference on Learning Representations (ICLR).",218,1,False,self,,,,,
1317,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,8,9qufoz,bairblog.github.io,Drilling Down on Depth Sensing and Deep Learning,https://www.reddit.com/r/MachineLearning/comments/9qufoz/drilling_down_on_depth_sensing_and_deep_learning/,DanielSeita,1540338050,,0,1,False,default,,,,,
1318,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,15,9qx5qv,self.MachineLearning,Good multimodal datasets?,https://www.reddit.com/r/MachineLearning/comments/9qx5qv/good_multimodal_datasets/,neanderthal_math,1540361313,[removed],0,1,False,self,,,,,
1319,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,15,9qx6a8,self.MachineLearning,Trying to find the Duke Outage dataset (1994-2002),https://www.reddit.com/r/MachineLearning/comments/9qx6a8/trying_to_find_the_duke_outage_dataset_19942002/,daffodils123,1540361468,[removed],0,1,False,self,,,,,
1320,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,15,9qx6tp,self.MachineLearning,Scalable and accurate(trying to) deep learning with hospital records plus eletronic health records,https://www.reddit.com/r/MachineLearning/comments/9qx6tp/scalable_and_accuratetrying_to_deep_learning_with/,ageuzatus,1540361622,"In order to provide useful and effective information for physicians, nurse and ICU team, I'm working on a predictive modelling with eletronic health records (EHR) and patient records from the ERP hospital system. I'm using Python ecosystem in order to accomplish this. 

I thought would be beneficial to the community this approache to share and learn on this field.

Hope hear from you folks",0,1,False,self,,,,,
1321,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,15,9qx9ub,self.MachineLearning,[D] NIPS name change decision,https://www.reddit.com/r/MachineLearning/comments/9qx9ub/d_nips_name_change_decision/,therealkenkaniff,1540362550,"[https://nips.cc/public/NameChange](https://nips.cc/public/NameChange)

&amp;#x200B;

I seriously don't mean to offend anyone, but if you are able to have a sense of humour about it, this whole situation is kinda funny I recognise all the negative consequences of such a name, (alienating people from the field and such) but c'mon.

&amp;#x200B;

What does r/MachineLearning think? Should they change the name?",0,1,False,self,,,,,
1322,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,15,9qx9w7,self.MachineLearning,AI Residency,https://www.reddit.com/r/MachineLearning/comments/9qx9w7/ai_residency/,idkname999,1540362560,[removed],0,1,False,self,,,,,
1323,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,15,9qxaf8,self.MachineLearning,[D] Trying to find the Duke outage dataset (1994-2002),https://www.reddit.com/r/MachineLearning/comments/9qxaf8/d_trying_to_find_the_duke_outage_dataset_19942002/,daffodils123,1540362730,"I was trying to find the Duke outage dataset(database for power failure logs that occurred in USA between 1994 and 2002) used in journal papers given below among others.

i)Power distribution outage cause identification with imbalanced data using artificial immune recognition system (AIRS) algorithm- L.Xu, MY Chow

ii)Power Distribution Fault Cause Identification With Imbalanced Data Using the Data Mining-Based Fuzzy Classification -Algorithm- same authors as above

Can anyone point me to a link where i can find the above database? I tried but was unsuccessful. Thanks in advance.

&amp;#x200B;",1,1,False,self,,,,,
1324,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,15,9qxdk5,labex.io,LabEx: Online PRO Machine Learning Tutorials Based On Notebook,https://www.reddit.com/r/MachineLearning/comments/9qxdk5/labex_online_pro_machine_learning_tutorials_based/,brycehu24,1540363717,,0,1,False,default,,,,,
1325,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,16,9qxglc,self.MachineLearning,[R] Dense neural networks as sparse graphs and the lightning initialization,https://www.reddit.com/r/MachineLearning/comments/9qxglc/r_dense_neural_networks_as_sparse_graphs_and_the/,pircherth,1540364675,"Dense neural networks can be interpreted as sparse graphs. The lightning initialization, which tries to improve the flow of information in the network, is based on this consideration.

[https://arxiv.org/abs/1809.08836](https://arxiv.org/abs/1809.08836)",0,1,False,self,,,,,
1326,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,16,9qxit2,youtube.com,"Gereon Frahling, Linguee (DeepL) - NOAH16 London",https://www.reddit.com/r/MachineLearning/comments/9qxit2/gereon_frahling_linguee_deepl_noah16_london/,adammathias,1540365336,,0,1,False,https://a.thumbs.redditmedia.com/H6G2vCa-Zx4wynN6Qg1vzQMqfbB6UcxcZ3hVkR9e9X0.jpg,,,,,
1327,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,16,9qxj3k,i.redd.it,You know when youve hired an expert!,https://www.reddit.com/r/MachineLearning/comments/9qxj3k/you_know_when_youve_hired_an_expert/,sk2977,1540365425,,0,1,False,https://a.thumbs.redditmedia.com/8Ev_eitSmdD7hoDqhyc9YuAke5_JJCnQOrHms8-a_38.jpg,,,,,
1328,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,16,9qxph2,self.MachineLearning,[D] Applying for Grad school...don't have any Deep Learning experience and I feel so far behind,https://www.reddit.com/r/MachineLearning/comments/9qxph2/d_applying_for_grad_schooldont_have_any_deep/,rampant_juju,1540367475,"70% of posts on this subject seem to be about Deep Learning, and 20% about how to get into Deep Learning. Is this representative of how all research is nowadays? Is Deep Learning a necessary skill to break into ML, even for a Masters?",0,1,False,self,,,,,
1329,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,16,9qxqlh,self.MachineLearning,What are some interesting German universities (berlin) that offer (in English) Machine Learning Masters?,https://www.reddit.com/r/MachineLearning/comments/9qxqlh/what_are_some_interesting_german_universities/,emanAboelatta,1540367872,[removed],0,1,False,self,,,,,
1330,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,17,9qxrs1,witgie.com,Introduction to Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9qxrs1/introduction_to_machine_learning/,chandan641989,1540369687,,0,1,False,default,,,,,
1331,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,18,9qy0fp,agileinfoways.com,Introducing Machine Learning to Business,https://www.reddit.com/r/MachineLearning/comments/9qy0fp/introducing_machine_learning_to_business/,haniskaroy,1540372544,,0,1,False,default,,,,,
1332,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,18,9qy663,self.MachineLearning,"Is there some implementation for this paper ""On the Automatic Generation of Medical Imaging Reports""",https://www.reddit.com/r/MachineLearning/comments/9qy663/is_there_some_implementation_for_this_paper_on/,datawool,1540374331,[removed],0,1,False,self,,,,,
1333,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,19,9qyeky,self.MachineLearning,Micro ATX Build Advice?,https://www.reddit.com/r/MachineLearning/comments/9qyeky/micro_atx_build_advice/,PetWolves,1540376820,"Hey guys I made a thing but I'm not sure if it will work. Any advice would be well received thank you for checking it out.

https://pcpartpicker.com/user/sedaji/saved/#view=bJZq4D

My reasonings:

Ryzen 2700 because I heard a lot of cores is good for ML/DL. Also a lot less wattage so less heat than a 2700x

1080ti - Lots of cuda cores and at $670 it's way cheaper than the 2080ti at $1200

MSI B450M Titatanium - It's the one PCPartpicker recommended, and I think it will work with the ryzen 2700

Corsair dominator 32GB - I heard I need a lot of RAM for this stuff. It is ddr4-3000 though, will that be a problem with the motherboard rated at DDR4 3466?

Samsung 970 evo - I heard NVME is fast and 1 TB is a lot of space

Corsair 860W PSU - I went with platinum because it's the highest tier. 860W to be safe and in case I add another graphics card one day.

Corsair 240 air case - I made this whole build around this case. I love the look of it in spite of the flimsy plastic side panels. 

My main concern as a beginner is: Will these components work with each other? Will they fit inside the case? Should I buy some fans too or will the fans on the Graphics Card be enough?

Thanks for reading. 
",0,1,False,self,,,,,
1334,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,19,9qyj2p,self.MachineLearning,Deep Learning Demystified,https://www.reddit.com/r/MachineLearning/comments/9qyj2p/deep_learning_demystified/,andrea_manero,1540378062,[removed],0,1,False,self,,,,,
1335,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,19,9qyk6j,self.MachineLearning,[D] Do you people read multiple text books on machine learning or are you satisfied with reading a single book?,https://www.reddit.com/r/MachineLearning/comments/9qyk6j/d_do_you_people_read_multiple_text_books_on/,mr_meeesix,1540378386,,10,1,False,self,,,,,
1336,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,19,9qyl6g,self.MachineLearning,Ranking Popular Deep Learning Libraries for Data Science,https://www.reddit.com/r/MachineLearning/comments/9qyl6g/ranking_popular_deep_learning_libraries_for_data/,andrea_manero,1540378667,[removed],0,1,False,self,,,,,
1337,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,20,9qyv5b,self.MachineLearning,I don't believe in test sets,https://www.reddit.com/r/MachineLearning/comments/9qyv5b/i_dont_believe_in_test_sets/,Pafnouti,1540381307,[removed],0,1,False,self,,,,,
1338,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,20,9qyvxw,self.MachineLearning,Introduction to Azure Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9qyvxw/introduction_to_azure_machine_learning/,gaurav-kaila,1540381505,[removed],0,1,False,self,,,,,
1339,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,20,9qyxso,self.MachineLearning,[Discussion] I don't believe in test sets,https://www.reddit.com/r/MachineLearning/comments/9qyxso/discussion_i_dont_believe_in_test_sets/,Pafnouti,1540381976,"Do you believe in test sets?

Tests sets work when you don't make decisions on which model to select based on it, but how often does this happen, except for competitions when a new test set is created and kept hidden ?

Most papers publish on standard datasets, such as PTB, Wikitext, MNIST, CIFAR, ImageNet, etc., and although they usually have standards train, dev and test splits, they've been used so much that I can't believe that there is no bias to publishing the models that do well on both dev and test, which defeats the point of having these separate.

And it's not only an academics issue, in any company, if you create a new model, with hyperparameters that ace the dev set, but is bad on the test set (that would be reused many times because even the GAFAM probably can't afford creating a new test set for each tentative release), good luck trying to put it in production.

What are the thoughts of the community on this?",59,1,False,self,,,,,
1340,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,22,9qzg5d,palin.co.in,"Data Science with Python Courses, training, certification online Gurgaon, Delhi",https://www.reddit.com/r/MachineLearning/comments/9qzg5d/data_science_with_python_courses_training/,PalinTechnologies,1540386171,,0,1,False,default,,,,,
1341,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,22,9qzgmb,self.MachineLearning,[D] graphic showing what companies are hiring famous ML researchers?,https://www.reddit.com/r/MachineLearning/comments/9qzgmb/d_graphic_showing_what_companies_are_hiring/,muddlebrain,1540386282,"About 1.5 years ago someone had made a graphic showing IIRC a list of famous ML researchers and what companies they had joined. I think I saw it on a linkedin feed, but cannot find it now.

&amp;#x200B;

Does anyone remember this and have a pointer to the figure?",15,1,False,self,,,,,
1342,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,22,9qzkdg,edyoda.com,Introduction to Machine Learning for complete beginners without any background in Machine Learning. Folks having a background in machine learning can ignore this.,https://www.reddit.com/r/MachineLearning/comments/9qzkdg/introduction_to_machine_learning_for_complete/,iamarmaan,1540387049,,1,1,False,default,,,,,
1343,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,22,9qzpc2,self.MachineLearning,HMM Datasets [P],https://www.reddit.com/r/MachineLearning/comments/9qzpc2/hmm_datasets_p/,errminator,1540388059,"Hi I've been working arning about HMMs and associated algorithms and I'd like to test out my implementation of them and ideally get a nice result that I could type up into a blog post.

I'm not looking for a super challenging problem to tackle but rather just a dataset that I could work with and an idea of how HMMs could be used on it. Any suggestions?

I'm open to all possibilities but anything related to genetics would be of parti ular interest.

Thank you everyone :) ",0,1,False,self,,,,,
1344,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,22,9qzr1u,self.MachineLearning,[P] NLP Overview: An integrated platform to learn about modern NLP techniques,https://www.reddit.com/r/MachineLearning/comments/9qzr1u/p_nlp_overview_an_integrated_platform_to_learn/,omarsar,1540388421,[removed],0,1,False,self,,,,,
1345,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,22,9qzvta,medium.com,NLP Overview: Open-Source Book for Deep Learning Based NLP,https://www.reddit.com/r/MachineLearning/comments/9qzvta/nlp_overview_opensource_book_for_deep_learning/,omarsar,1540389363,,0,1,False,default,,,,,
1346,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,23,9qzx0h,self.MachineLearning,[D] Introduction to Azure Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9qzx0h/d_introduction_to_azure_machine_learning/,gaurav-kaila,1540389613,"Hey!

I recently published an article on how to get started with Azure Machine Learning service that was launched in September.

[https://medium.com/ey-ireland/introduction-to-azure-machine-learning-service-87135cfbf78b](https://medium.com/ey-ireland/introduction-to-azure-machine-learning-service-87135cfbf78b)

The article goes through a step-by-step method for setting up Azure ML service including an example of training and deploying a simple sklearn-regression model. Associated python code is also provided with a link to the github repo.

Hope you guys enjoy the article and would love to get your feedback.

Thanks!",3,1,False,self,,,,,
1347,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,23,9r02a3,github.com,[N] Microsoft Releases the Cognitive Services on Apache Spark,https://www.reddit.com/r/MachineLearning/comments/9r02a3/n_microsoft_releases_the_cognitive_services_on/,mhamilton723,1540390626,,0,1,False,default,,,,,
1348,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,23,9r04fj,medium.com,Experimenting with a crazy way to train Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/9r04fj/experimenting_with_a_crazy_way_to_train_deep/,sibyjackgrove,1540391048,,1,1,False,default,,,,,
1349,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,23,9r0cpn,self.MachineLearning,Reproducing Results of Previous Papers For Benchmarking New Results,https://www.reddit.com/r/MachineLearning/comments/9r0cpn/reproducing_results_of_previous_papers_for/,AlanMLuu,1540392620,"Let's say that I want to write and publish a paper coming up with a new machine learning approach for some particular task, and I want to benchmark it against previous approaches. Now, for the experiments section, this requires me to run the previous approaches on some test data so that I can presumably show that my new approach is better. 

Here's the question: When I reproduce someone else's approach, should I try to use their same exact code from the Github and modify it as minimally as I can to run the experiments, or can I implement it myself keeping all the design decisions faithful to the original codebase?

Perhaps the answer to this question is obvious to someone who works in the field, but I'm sort of an outsider who doesn't know the customs and norms of the field.",0,1,False,self,,,,,
1350,MachineLearning,t5_2r3gv,2018-10-24,2018,10,24,23,9r0f92,self.MachineLearning,[R] CVPR Paper Controversy; ML Community Reviews Peer Review,https://www.reddit.com/r/MachineLearning/comments/9r0f92/r_cvpr_paper_controversy_ml_community_reviews/,downtownslim,1540393115,"&gt; a series of unsettling incidents and heated discussions on social media have now put the peer review process itself under scrutiny.

Article: https://medium.com/syncedreview/cvpr-paper-controversy-ml-community-reviews-peer-review-79bf49eb0547",32,1,False,self,,,,,
1351,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,0,9r0lre,self.MachineLearning,[P] - Reinforcement learning Game AI for multiple Atari games. Student needs advice,https://www.reddit.com/r/MachineLearning/comments/9r0lre/p_reinforcement_learning_game_ai_for_multiple/,FeederMario,1540394587,"Hi guys,

&amp;#x200B;

I am a student and I am working on Game AI which will play multiple Atari 2600 games using sensory input. I'm trying to recreate what google DeepMind has done on 2013: [https://deepmind.com/research/publications/playing-atari-deep-reinforcement-learning/](https://deepmind.com/research/publications/playing-atari-deep-reinforcement-learning/) . I am new to the Machine learning and I just wanted your help understanding how feasible is it to complete in a couple of months as a student. Couple of questions:

1. How long should the training take for 1 game(e.g. Pong/Breakout) and is it possible to do on a laptop or do I need a sophisticated machine?
2. How feasible is it to implement in 2-3 months working for about 4hrs on the project everyday assuming I have average Tensorflow, Python knowledge and have not worked on a similar project before
3. I am planning to use OpenAI Gym as an environment, is there something else I should have a look at?
4. To understand real time sensory input, I will be combining multiple frames and feed it to convolutional neural network. Is there any other way? Will it work?
5. Any good way to solve Credit Assignment Problem(Difficult to understand which exact actions lead to reward as reward is given much later after the moves(e.g. Breakout - important move is when paddle is positioned correctly but reward only given when ball flies for multiple frames and hits blocks))
6. How good is DeepMind's new TRFL library? Can I get much use of it in this project(I will be using Q-learning)? [https://deepmind.com/blog/trfl/](https://deepmind.com/blog/trfl/) [https://github.com/deepmind/trfl](https://github.com/deepmind/trfl)

&amp;#x200B;

Any other tips on how should I go about this project?

&amp;#x200B;

Thank you guys very much! Looking forward to your answers.",9,1,False,self,,,,,
1352,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,0,9r0vip,self.MachineLearning,"Simple Questions Thread October 24, 2018",https://www.reddit.com/r/MachineLearning/comments/9r0vip/simple_questions_thread_october_24_2018/,AutoModerator,1540396366,"Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!

Thread will stay alive until next one so keep posting after the date in the title.

Thanks to everyone for answering questions in the previous thread!
",0,1,False,self,,,,,
1353,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,0,9r0vxe,self.MachineLearning,[P] Project Idea for defect detection in a product - need your thoughts on my thoughts,https://www.reddit.com/r/MachineLearning/comments/9r0vxe/p_project_idea_for_defect_detection_in_a_product/,Davoc8,1540396447,"The goal of the project is a raspberri pi that can detect certain defects in a product that is moving past the Raspberri Pi. If a defect is detected, a signal is sent to a PLC.
I want to get to the point where the Pi sends a signal whenever a defective product is detected.
Following are my somehow unordered thoughts as I never did something like this before.


**Task 1:**

Take a picture whenever a product passes a certain lightbarrier -&gt; this image will then be evaluated. If a product is detected, check if the product is ""good"" or has a defective.
For this I have to first train a model that detects a product in an image. I'd use a trigger signal to take a picture whenever a product passes some sensor. Images will always be from the same angle and camera position.
Once I have enough images that contain a product, I'd take some pictures from the same angle and position, just without any product.
With this set of images I'd train a model which should then be able to say whether an image contains a prodcut or not.
Pictures should be taken with a webcam connected to the Raspberry Pi and be sent to my computer through WiFi.
Training the model would then happen on my computer.


**Task 2:**

 If a product is detected, check for abnormalities compared to a ""good"" product.
For this I am somewhat uncertain. Should I do this similar to task 1, but just manually take pictures of defective products? Or is it possible to detect defects, just based on the image data from good products?

There is one minor detail that should be considered: I know very little about computer vision and just started studying Data Science as a second Masters Degree.
I know a little Python and can work to wrap my head around new technologies.

What are your thoughts on this project? Is this in general a doable approach? What am I missing? Do you need more background information?
I want to get this up and running as fast as possible, so I'm thinking about just buying a Raspberry Pi and downloading Tensorflow on my computer . From there I'd go through some TensorFlow tutorials and then start working on Task 1.

So what do you think? What things are important? What should I work on first?
",4,1,False,self,,,,,
1354,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,1,9r11zr,heartbeat.fritz.ai,Choose the Right On-Device Text Recognition (OCR) SDK on Android Using DeltaML,https://www.reddit.com/r/MachineLearning/comments/9r11zr/choose_the_right_ondevice_text_recognition_ocr/,zsajjad,1540397539,,0,1,False,https://b.thumbs.redditmedia.com/jK_636dB7f1go4n0gRLlThXWBpmdAA0yVkiwJ2yhXlA.jpg,,,,,
1355,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,1,9r17y9,self.MachineLearning,Pretty naive question,https://www.reddit.com/r/MachineLearning/comments/9r17y9/pretty_naive_question/,steven_4,1540398635,What negative connotations does the name of NIPS have?,0,1,False,self,,,,,
1356,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,1,9r1bqa,self.MachineLearning,PyTorch CycleGAN summer2winter Google Cloud,https://www.reddit.com/r/MachineLearning/comments/9r1bqa/pytorch_cyclegan_summer2winter_google_cloud/,westminsterrealm,1540399327,[removed],0,1,False,self,,,,,
1357,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,1,9r1cau,self.MachineLearning,Cointelegraph: Financial Giant SBI Group to Develop Wallet Following New Partnership.,https://www.reddit.com/r/MachineLearning/comments/9r1cau/cointelegraph_financial_giant_sbi_group_to/,mej2030,1540399433,[removed],0,1,False,self,,,,,
1358,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,1,9r1g5d,explained.ai,[D] Beware Default Random Forest Importances,https://www.reddit.com/r/MachineLearning/comments/9r1g5d/d_beware_default_random_forest_importances/,_quanttrader_,1540400140,,0,1,False,default,,,,,
1359,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,1,9r1gip,self.MachineLearning,Question from a newbie to Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9r1gip/question_from_a_newbie_to_machine_learning/,The_Aoki_Taki,1540400209,[removed],0,1,False,self,,,,,
1360,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,1,9r1h21,self.MachineLearning,[D] Recommender systems state-of-the-art resources,https://www.reddit.com/r/MachineLearning/comments/9r1h21/d_recommender_systems_stateoftheart_resources/,SirFitzherbert,1540400316,"Looking to read up on the latest developments in the area of recommender systems - state-of-the-art ML models, best practices, obstacles, etc.. Any pointers to literature (books, academic articles), blogs, website or other resources are highly appreciated. Thanks!",19,1,False,self,,,,,
1361,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,2,9r1olt,self.MachineLearning,Machine Learning Cheat Sheets (Python and Maths),https://www.reddit.com/r/MachineLearning/comments/9r1olt/machine_learning_cheat_sheets_python_and_maths/,skj8,1540401628,[removed],0,1,False,self,,,,,
1362,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,2,9r1xfh,self.MachineLearning,Skafos - ML Deployment &amp; Automation - Need help - Step-by-Step Tutorial: Churn Modeling,https://www.reddit.com/r/MachineLearning/comments/9r1xfh/skafos_ml_deployment_automation_need_help/,heybluez,1540403243,[removed],0,1,False,self,,,,,
1363,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,2,9r21as,self.MachineLearning,Remote Consulting Machine Learning Project $75-$150/hr,https://www.reddit.com/r/MachineLearning/comments/9r21as/remote_consulting_machine_learning_project_75150hr/,JyoC,1540403953,"Experfy is a Harvard-Incubated Consulting marketplace for projects in ML/deep learning/analytics. Here is the link to the project -https://www.experfy.com/projects/category
If this is of interest please create and submit a profile on Experfy.com, once approved you can bid on any of the projects - https://www.experfy.com/accounts/signup/expert",0,1,False,self,,,,,
1364,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,3,9r22f5,nldalmia.org,Big Data with SAS | Post Graduate Certification | NL Dalmia,https://www.reddit.com/r/MachineLearning/comments/9r22f5/big_data_with_sas_post_graduate_certification_nl/,dipika20,1540404142,,0,1,False,default,,,,,
1365,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,3,9r22fz,datahacker.rs,Implementing a fast logistic regression with python code.,https://www.reddit.com/r/MachineLearning/comments/9r22fz/implementing_a_fast_logistic_regression_with/,sk2977,1540404146,,0,1,False,default,,,,,
1366,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,3,9r253t,youtu.be,Artificial Intelligence - Singularity - Social Media,https://www.reddit.com/r/MachineLearning/comments/9r253t/artificial_intelligence_singularity_social_media/,themodernape368,1540404610,,0,1,False,https://b.thumbs.redditmedia.com/yPaWTVAjW1tRUx46NVKyMhVTxu6ZaPVdmEaaAOWUA8E.jpg,,,,,
1367,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,3,9r26ru,medium.com,Tencent AI Lab Open-Sources 8M Word Chinese NLP Vector Dataset,https://www.reddit.com/r/MachineLearning/comments/9r26ru/tencent_ai_lab_opensources_8m_word_chinese_nlp/,Yuqing7,1540404927,,0,1,False,https://b.thumbs.redditmedia.com/NBV3rziXUcOGHPhq2O9kOGcqQjAi5rx8VP1eKAzA5Iw.jpg,,,,,
1368,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,3,9r2aet,self.MachineLearning,When to use unsupervised machine learning &amp; reinforcement learning?,https://www.reddit.com/r/MachineLearning/comments/9r2aet/when_to_use_unsupervised_machine_learning/,WhichNumber,1540405604,"Hey guys, 

&amp;#x200B;

I have a presentation to do on the above question on when to use these things, I have been browsing and learning about both but cannot find when it is best to use this style of learning without just giving an example of when a business is using it. Anyone able to help?",0,1,False,self,,,,,
1369,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,3,9r2ccu,self.MachineLearning,[D] Help finding a paper on designing fully connected networks?,https://www.reddit.com/r/MachineLearning/comments/9r2ccu/d_help_finding_a_paper_on_designing_fully/,R4_Unit,1540405956,"I've spent a few hours trying to find a paper from the past couple of years.  Basically the theme of it was, ""we've done tons of fantastic stuff recently designing network architectures, lets see how well we can use these tricks to design fully connected networks!""  It was a practical/experimental paper, not theoretical.  Does anyone know what I could be thinking of?

Also, feel free to point me to another subreddit if you think it is a better match.",9,1,False,self,,,,,
1370,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,4,9r2reh,github.com,Machine learning research papers,https://www.reddit.com/r/MachineLearning/comments/9r2reh/machine_learning_research_papers/,donutloop,1540408787,,0,1,False,https://b.thumbs.redditmedia.com/BdsTW2a98MDTqcKMRqLG0ZfQuP0_28cKz7fl3MUPjls.jpg,,,,,
1371,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,4,9r2tey,self.MachineLearning,[P] A good site to find and promote jobs in AI/ML and Big Data: ai-jobs.net,https://www.reddit.com/r/MachineLearning/comments/9r2tey/p_a_good_site_to_find_and_promote_jobs_in_aiml/,ai_jobs,1540409147,"The site originally started as 2 regional job sites in Switzerland and the UK this year and now got merged into [ai-jobs.net](https://ai-jobs.net) to cover the global potential of the rising demand in AI/ML and Big Data professionals.

&amp;#x200B;

The focus lies on a simple (mobile-friendly) site with no fluff and simple but effective job ads, an easy (paid) submission process and a simple job alert feature. The search allows for filtering by region so job seekers can add some regional flavor to the result list. Hope you enjoy it - happy hiring!

&amp;#x200B;

Suggestions, thoughts and feedback welcome!",6,1,False,self,,,,,
1372,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,4,9r2v59,i.redd.it,[P] Error estimates for image classification,https://www.reddit.com/r/MachineLearning/comments/9r2v59/p_error_estimates_for_image_classification/,maka89,1540409470,,1,1,False,https://a.thumbs.redditmedia.com/jBfIBlB_29tB4Ab9Xn4WJS0710hj6b7gz1Mgd1ZEdw8.jpg,,,,,
1373,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,4,9r2y0j,i.redd.it,[P] Error estimates in image classification,https://www.reddit.com/r/MachineLearning/comments/9r2y0j/p_error_estimates_in_image_classification/,maka89,1540409974,,0,1,False,https://b.thumbs.redditmedia.com/N74-Zit_GXj0Vo8q94VJg1uYn8JhnXFnNKuNTGpaXnA.jpg,,,,,
1374,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,4,9r301l,self.MachineLearning,[P] Error estimates for image classification,https://www.reddit.com/r/MachineLearning/comments/9r301l/p_error_estimates_for_image_classification/,maka89,1540410328,"I tried my [nonlinear regression model using neural networks and k-nearest neighbours](https://github.com/maka89/ccnet) on the triplet loss embeddings of MNIST. The estimated errors of the model were highly predictive of wether the model misclassified the test samples.

&amp;#x200B;

The figure below shows this by ploting the cumulative accuracy of the test set sorted by the predicted error.

By discarding the \~500 samples that has the highest predictive error we get the error to drop from 0.8% to below  0.1%.

&amp;#x200B;

https://i.redd.it/s5fhwv1js6u11.png",3,1,False,https://b.thumbs.redditmedia.com/oZk13_i_B3qKQnFfM82DoZXD4yXgWEVpAHdju1HCQuM.jpg,,,,,
1375,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,5,9r3aii,forbes.com,Delivering Application Security At The Speed Of Technology With Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9r3aii/delivering_application_security_at_the_speed_of/,tonys3kur3,1540412246,,0,1,False,https://b.thumbs.redditmedia.com/-DbJ1pXOQMDK5t2Z7F8jNK_O-OyzBL7d1i7MXEqaZXo.jpg,,,,,
1376,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,5,9r3d68,self.MachineLearning,Looking for material on deep learning and machine learning,https://www.reddit.com/r/MachineLearning/comments/9r3d68/looking_for_material_on_deep_learning_and_machine/,silaner,1540412729,[removed],0,1,False,self,,,,,
1377,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,5,9r3e30,self.MachineLearning,Lex Fridman on Joe Rogan Experience,https://www.reddit.com/r/MachineLearning/comments/9r3e30/lex_fridman_on_joe_rogan_experience/,slap_n_tickler,1540412892,[removed],0,1,False,self,,,,,
1378,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,6,9r3tkq,self.MachineLearning,[R] MaskRCNN-Benchmark: Faster R-CNN and Mask R-CNN in PyTorch 1.0,https://www.reddit.com/r/MachineLearning/comments/9r3tkq/r_maskrcnnbenchmark_faster_rcnn_and_mask_rcnn_in/,ndha1995,1540415875,"This project aims at providing the necessary building blocks for easily creating detection and segmentation models using PyTorch 1.0.

***Highlights:***

* **PyTorch 1.0:** RPN, Faster R-CNN and Mask R-CNN implementations that matches or exceeds Detectron accuracies
* **Very fast**: up to **2x** faster than [Detectron](https://github.com/facebookresearch/Detectron) and **30%** faster than [mmdetection](https://github.com/open-mmlab/mmdetection) during training. See [MODEL\_ZOO.md](https://github.com/facebookresearch/maskrcnn-benchmark/blob/master/MODEL_ZOO.md) for more details.
* **Memory efficient:** uses roughly 500MB less GPU memory than mmdetection during training
* **Multi-GPU training and inference**
* **Batched inference:** can perform inference using multiple images per batch per GPU
* **CPU support for inference:** runs on CPU in inference time. See [webcam demo](https://github.com/facebookresearch/maskrcnn-benchmark/blob/master/demo) for an example
* Provides pre-trained models for almost all reference Mask R-CNN and Faster R-CNN configurations with 1x schedule.

[https://github.com/facebookresearch/maskrcnn-benchmark](https://github.com/facebookresearch/maskrcnn-benchmark)",6,1,False,self,,,,,
1379,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,6,9r3uwz,self.MachineLearning,[P] LDA calculate variational parameters in log scale,https://www.reddit.com/r/MachineLearning/comments/9r3uwz/p_lda_calculate_variational_parameters_in_log/,cuenta4384,1540416133,"Hi, 

I am trying to implement LDA with variational EM as in the original paper by Blei. I got stuck in a point that my algorithm does not converge, so I take a look at the original implementation of Blei \[1\]. He treats the calculations of the variational parameters in the E step in a log scale. However, in the original implementation he does not mention anything about that (see figure 6 \[2\]). Why would I treat this calculation in a log scale?

&amp;#x200B;

\[1\] [https://github.com/blei-lab/lda-c/blob/master/lda-inference.c#L52-L73](https://github.com/blei-lab/lda-c/blob/master/lda-inference.c#L52-L73)

\[2\] [http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf](http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf)",2,1,False,self,,,,,
1380,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,6,9r3z8z,self.MachineLearning,Programming Languages widely used in Data Science and Machine Learning ?,https://www.reddit.com/r/MachineLearning/comments/9r3z8z/programming_languages_widely_used_in_data_science/,andrea_manero,1540416949,[removed],0,1,False,self,,,,,
1381,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,6,9r44wm,self.MachineLearning,First project for a beginner learning about data science and machine learning at college,https://www.reddit.com/r/MachineLearning/comments/9r44wm/first_project_for_a_beginner_learning_about_data/,JianYangMarsh,1540418047,[removed],0,1,False,self,,,,,
1382,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,7,9r46zy,self.MachineLearning,Improving CNN Accuracy,https://www.reddit.com/r/MachineLearning/comments/9r46zy/improving_cnn_accuracy/,mfrohman,1540418456,[removed],0,1,False,self,,,,,
1383,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,7,9r4c0m,self.MachineLearning,Do this paper's suggestions for maml are novel ?,https://www.reddit.com/r/MachineLearning/comments/9r4c0m/do_this_papers_suggestions_for_maml_are_novel/,Periplokos,1540419447,[removed],0,1,False,self,,,,,
1384,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,7,9r4kox,self.MachineLearning,Machine Learning and CyberSecurity,https://www.reddit.com/r/MachineLearning/comments/9r4kox/machine_learning_and_cybersecurity/,Caerbanoob,1540421228,[removed],0,1,False,self,,,,,
1385,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,8,9r54ay,self.MachineLearning,Higher Resolution SSD Network,https://www.reddit.com/r/MachineLearning/comments/9r54ay/higher_resolution_ssd_network/,asicman78,1540425432,Super Noob Questions: How do I go about training SSD with a larger resolution than the standard 300x300 and 512x512? I am looking for something closer to 720p,0,1,False,self,,,,,
1386,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,9,9r5cqi,i.redd.it,#NIPS2018,https://www.reddit.com/r/MachineLearning/comments/9r5cqi/nips2018/,nips_2018,1540427306,,0,1,False,default,,,,,
1387,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,9,9r5gls,self.MachineLearning,Which one deserves the SSD ... ML or Gaming ?,https://www.reddit.com/r/MachineLearning/comments/9r5gls/which_one_deserves_the_ssd_ml_or_gaming/,thetimeisnow2017,1540428173,[removed],0,1,False,self,,,,,
1388,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,11,9r63p0,self.MachineLearning,"[D] #ProtestNIPS hashtag started on Twitter, Change.org petition started.",https://www.reddit.com/r/MachineLearning/comments/9r63p0/d_protestnips_hashtag_started_on_twitter/,kirasolo,1540433263,"With the recent news that NIPS will not be changing its name, some ML researchers on Twitter have [started a Change.org petition to #ProtestNIPS](https://www.change.org/p/members-of-nips-board-protestnips-nips-acronym-encourages-sexism-and-is-a-slur-change-the-name?recruiter=552354677&amp;utm_source=share_petition&amp;utm_medium=twitter&amp;utm_campaign=share_petition), and are voicing their concerns:

* [@AnimaAnandkumar: #ProtestNIPS I am starting this new hashtag. Please retweet if you are in support of @NipsConference changing its name. Looking for ideas on how to wear protest on our sleeves/carry signs throughout the conference. Ideas? We can't let the board get away with this shoddy treatment](https://twitter.com/AnimaAnandkumar/status/1055262867501412352)
* [@AnimaAnandkumar: Unfortunately none of the terrible incidents at previous @NipsConference was enough to change its name. @elonmusk talked about nips and tits on stage and it is business as usual. #women are second class citizens in #MachineLearning](https://twitter.com/AnimaAnandkumar/status/1055262867501412352)
* [@AnimaAnandkumar: Members of NIPS board: #ProtestNIPS: NIPS acronym encourages sexism and is a slur. Change the name - Sign the Petition! https://chn.ge/2Ra0Ysv  via @Change](https://twitter.com/AnimaAnandkumar/status/1055276676232278018)
*[@daniela_witten: I am so disappointed in @NipsConference for missing the opportunity to join the 21st century and change the name of this conference. But maybe the worst part is that their purported justification is based on a shoddy analysis of their survey results. 1/n](https://twitter.com/daniela_witten/status/1054800509364621312)
* [@negar_rz Considering the majority vote when the minorities are mainly affected doesn't sound right to me! @NipsConference](https://twitter.com/negar_rz/status/1054915008931467264)
* [@WillOremus: A plurality of women thought a leading AI conference called NIPS should change its name. But most men wanted to keep it, and there were way more men than women... so the name stays.](https://twitter.com/WillOremus/status/1055255396263321600)
* [@theoriginalbrk: Extremely disappointed by the @NipsConference decision on a potential name change. Thoughtful women and allies in #MachineLearning dared to speak up, and their request was not honored. In an age of #MeToo , it is unacceptable to think that ""hiring a diversity chair"" is enough. 1/](https://twitter.com/theoriginalbrk/status/1054761280790257664)
* [@besanushi: It never occurred to me but this is the result if you search for nips. Similar results appear on Twitter too. We need to accept that this is bizarre! Also, I really don't understand what is wrong with changing the name. How does it objectively hurt the community?](https://twitter.com/besanushi/status/1055264093764894720)

While the story is still developing, it is important to share and discuss this topic, and to consider the petition seriously, in good faith. More than a few researchers [have voice concerns about the civility of this subreddit before](https://www.reddit.com/r/MachineLearning/comments/98hxuq/d_meta_the_toxicity_of_this_sub_discussed_by_ml/), so please remember that your words matter and affect people here and elsewhere in the community.",35,1,False,self,,,,,
1389,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,11,9r6anh,self.MachineLearning,[D] Learn Machine Learning as a newbie. Where to start?,https://www.reddit.com/r/MachineLearning/comments/9r6anh/d_learn_machine_learning_as_a_newbie_where_to/,The_Aoki_Taki,1540434827,"Hi! I'm a 1st year undergraduate. I want to learn machine learning, because nowadays machine learning is one of the trending topics, it is currently the state-of-the-art solution for a wide range of problems aaand I love robotics. I have a dream to create a robot which use ML for its processes. I did a small research to get an idea about how can I start learning machine learning and to get a idea to start a ML based project.

I came to know about Coursera's Machine learning course, googles crash course, Kaggles data sets, Tensorflow ,Compromise and BrainJS. I practiced both Tensorflow and BrainJS and I found that using BrainJS is easier than using Tensorflow. I followed Google Crash Course some far, so now I have a small idea about Regression, Classification, Clustering, Neural Networks and so on and nowadays I do some experiments using BrainJS.

In order to be a successful machine learning practitioner, what kind of things I need to do? Is there any wrong with my current path to ML? My ultimate goal is to develop a ML based project. So are there any beginner friendly projects/ideas which Machine Learning newbie can be able to do as her/his first projects? Any opinions/ suggestions? Thanks :D",4,1,False,self,,,,,
1390,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,12,9r6o01,self.MachineLearning,[D] [Serious] Are my opinions and beliefs flawed?,https://www.reddit.com/r/MachineLearning/comments/9r6o01/d_serious_are_my_opinions_and_beliefs_flawed/,aConfusedNeuron,1540437959,"So as many of you have heard NIPS decided to keep its name. I answered the survey in favor of keeping the name. But, it seems many of the people I look up to in the field and work with are outraged by this lack of change based on workplace conversations and twitter. I felt socially pressured today to feign outrage rather than admit I would rather keep the name at the risk of being labelled sexist or someone who is trying to marginalize women. It feels crazy to me since I'm behaving as if I am in this controversial minority, but the survey results appear to be fairly even.

I would rather not bring political discussion to a sub that already lacks high quality content, but this whole situation has me perplexed so I was hoping that someone could give me a perspective I am not understanding to explain this whole thing.

In case anyone thinks this, I am genuinely not trolling. I am usually on the right side of social justice so it feels concerning to me that for once I am not. Please be kind in the comments. The other thread on the announcement didn't appear to go so well.

Disclaimer: I am male. I consider myself a liberal and a feminist and support women's rights for equality.",132,1,False,self,,,,,
1391,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,12,9r6p2u,self.MachineLearning,Question about image segmentation,https://www.reddit.com/r/MachineLearning/comments/9r6p2u/question_about_image_segmentation/,nathanaherne,1540438211,[removed],0,1,False,self,,,,,
1392,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,13,9r76xz,self.MachineLearning,[D] Which loss function is best fit for learning a exponential distribution?,https://www.reddit.com/r/MachineLearning/comments/9r76xz/d_which_loss_function_is_best_fit_for_learning_a/,moewiewp,1540442741,"Lets say, if I want my network to learn an output draw from an exponential-kind distribution (in my case generalized pareto distribution), what is the best loss function to use? I've tried MSE but it tends to output gaussian distribution. I also have no luck with logarithmic MSE, logcost or l1 loss.

What kind of loss function should I try now?",0,1,False,self,,,,,
1393,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,13,9r79hd,self.MachineLearning,[R] How to train your MAML,https://www.reddit.com/r/MachineLearning/comments/9r79hd/r_how_to_train_your_maml/,AntreasAntoniou,1540443419,"Dear Reddit ML community,

I just wanted to share some of my latest work in meta-learning. I was mainly trying to build something on top of the very well known Model Agnostic Meta Learning framework, and found it very unstable and hard to work with. So, I decided to fix the problems so I could then use it to achieve my original goal. This is what this work is about. Techniques that reduce chances of gradient degradation induced instability, in addition to techniques that can automatically learn most of the hyperparameters whilst substantially improving generalization performance by learning things step by step (pun intended). Here is the paper and code for it:

Paper: https://arxiv.org/abs/1810.09502 

Code: https://github.com/AntreasAntoniou/HowToTrainYourMAMLPytorch",15,1,False,self,,,,,
1394,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,13,9r79mr,self.MachineLearning,[D] What kind of loss function is best fit to learn exponential distribution?,https://www.reddit.com/r/MachineLearning/comments/9r79mr/d_what_kind_of_loss_function_is_best_fit_to_learn/,moewiewp,1540443460,"Lets say, if I want my network to learn an output draw from an exponential-kind distribution (in my case generalized pareto distribution), what is the best loss function to use? I've tried MSE but it tends to output gaussian distribution. I also have no luck with logarithmic MSE, logcost or l1 loss.

What kind of loss function should I try now?",5,1,False,self,,,,,
1395,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,14,9r7f9d,self.MachineLearning,How would you will prepare for the Google AI Residency Program.,https://www.reddit.com/r/MachineLearning/comments/9r7f9d/how_would_you_will_prepare_for_the_google_ai/,abhi3301,1540445095,"Google AI residency program 2019 applications has started I have submitted my application. I was wondering what are the points on which they accept, i mean what type of candidates typically they accept. I read in some blogs they accept only from top tier institutes mostly Phd's, having a bachelors degree I am curious what is my chance of being accepted.

Thanks in advance for any kind of help",0,1,False,self,,,,,
1396,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,14,9r7joz,analyticsinsight.net,Quantum Machine Learning: A Smart Convergence of Two Disruptive Technologies | Analytics Insight,https://www.reddit.com/r/MachineLearning/comments/9r7joz/quantum_machine_learning_a_smart_convergence_of/,analyticsinsight,1540446424,,0,1,False,default,,,,,
1397,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,15,9r7qkz,dexlabanalytics.com,How Google Is Fighting Floods in India with AI,https://www.reddit.com/r/MachineLearning/comments/9r7qkz/how_google_is_fighting_floods_in_india_with_ai/,dexlabanalytics,1540448429,,0,1,False,default,,,,,
1398,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,15,9r7y9f,self.MachineLearning,Machine learning in finance,https://www.reddit.com/r/MachineLearning/comments/9r7y9f/machine_learning_in_finance/,kremaytuz,1540450768,[removed],0,1,False,self,,,,,
1399,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,16,9r81dd,self.MachineLearning,Is there any method to deal with errors in supervised learning? (error analysis),https://www.reddit.com/r/MachineLearning/comments/9r81dd/is_there_any_method_to_deal_with_errors_in/,LiXiaoB,1540451725,[removed],0,1,False,self,,,,,
1400,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,16,9r824a,davidsbatista.net,Comparison of ROC-Curves and Precision-Recall-Curves on imbalanced data,https://www.reddit.com/r/MachineLearning/comments/9r824a/comparison_of_roccurves_and_precisionrecallcurves/,fulltime_philosopher,1540451943,,0,1,False,default,,,,,
1401,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,17,9r89z3,self.MachineLearning,Machine Learning based Intrusion Detection System,https://www.reddit.com/r/MachineLearning/comments/9r89z3/machine_learning_based_intrusion_detection_system/,synops09,1540454457,[removed],0,1,False,self,,,,,
1402,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,17,9r8a0x,medium.com,Typescript + Machine Learning + simplicity = Kalimdor.js,https://www.reddit.com/r/MachineLearning/comments/9r8a0x/typescript_machine_learning_simplicity_kalimdorjs/,Fewthp,1540454476,,0,1,False,default,,,,,
1403,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,17,9r8c8w,mobile.twitter.com,Change NIPS name petition.,https://www.reddit.com/r/MachineLearning/comments/9r8c8w/change_nips_name_petition/,lesharcerer,1540455243,,0,1,False,default,,,,,
1404,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,17,9r8cns,self.MachineLearning,Trying to understand Multi-head Attention,https://www.reddit.com/r/MachineLearning/comments/9r8cns/trying_to_understand_multihead_attention/,ReasonablyBadass,1540455385,[removed],0,1,False,self,,,,,
1405,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,17,9r8j6y,self.MachineLearning,[Q] Data scientist CV: how it should look like?,https://www.reddit.com/r/MachineLearning/comments/9r8j6y/q_data_scientist_cv_how_it_should_look_like/,meechosch,1540457656,[removed],0,1,False,self,,,,,
1406,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,18,9r8m5c,self.MachineLearning,Need help creating a web-app that trains a model on uploaded data,https://www.reddit.com/r/MachineLearning/comments/9r8m5c/need_help_creating_a_webapp_that_trains_a_model/,CoolUser69,1540458620,[removed],0,1,False,self,,,,,
1407,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,18,9r8p7t,self.MachineLearning,Getting started with Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9r8p7t/getting_started_with_machine_learning/,CarbonNanoTubes007,1540459656,[removed],0,1,False,self,,,,,
1408,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,18,9r8ush,self.MachineLearning,[D]Why several groups like facebook don't use tensorflow directly and develop their own platform?,https://www.reddit.com/r/MachineLearning/comments/9r8ush/dwhy_several_groups_like_facebook_dont_use/,MinHoon,1540461398,"First, I am first to reddit and my english is not so good. Please tell me if my post is not proper!

Maybe it's a silly question, but I can't come up with clear answer by myself.

I am not saying tensorflow is the best. I mean that almost platform is open-source anyway, so I think it's better to develop one very nice platform cooperating with each others than to develop each groups' own platform.

Hope someone can give clear idea about this question!

Thank you!",19,1,False,self,,,,,
1409,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,19,9r8w85,twitter.com,"Anima Anandkumar on Twitter: ""A woman told me that a gun toting bro physically threatened her on @mxlearn over @NipsConference name change ...""",https://www.reddit.com/r/MachineLearning/comments/9r8w85/anima_anandkumar_on_twitter_a_woman_told_me_that/,metacurse,1540461771,,0,1,False,default,,,,,
1410,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,19,9r8wly,twitter.com,"[D] Anima Anandkumar on Twitter: ""A woman told me that a gun toting bro physically threatened her on @mxlearn over @NipsConference name change. ...""",https://www.reddit.com/r/MachineLearning/comments/9r8wly/d_anima_anandkumar_on_twitter_a_woman_told_me/,metacurse,1540461870,,0,1,False,https://b.thumbs.redditmedia.com/tFkcbIfmZt0wysZX7E6muNMrJamuHDul9UWoLa6tcqg.jpg,,,,,
1411,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,19,9r930c,stude.co,[P] Developing a Machine Learning Application on iOS. Free Resource for Neural Network Building,https://www.reddit.com/r/MachineLearning/comments/9r930c/p_developing_a_machine_learning_application_on/,EmiTzx,1540463731,,0,1,False,default,,,,,
1412,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,20,9r9gd9,self.MachineLearning,AIs Ethical Dilemma  An Unexpectedly Urgent Problem,https://www.reddit.com/r/MachineLearning/comments/9r9gd9/ais_ethical_dilemma_an_unexpectedly_urgent_problem/,andrea_manero,1540467293,[removed],0,1,False,self,,,,,
1413,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,20,9r9j8f,indiumsoftware.com,5 Challenges in AI and Deep Learning,https://www.reddit.com/r/MachineLearning/comments/9r9j8f/5_challenges_in_ai_and_deep_learning/,indiumsoftware18,1540468013,,0,1,False,default,,,,,
1414,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,20,9r9lje,bizsignitythings.tumblr.com,How Machine Learning Resources are becoming the Future of Marketing.,https://www.reddit.com/r/MachineLearning/comments/9r9lje/how_machine_learning_resources_are_becoming_the/,biz_signity,1540468578,,0,1,False,default,,,,,
1415,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,20,9r9m6u,self.MachineLearning,[Discussion] Transfer learning and GANs,https://www.reddit.com/r/MachineLearning/comments/9r9m6u/discussion_transfer_learning_and_gans/,teclics,1540468747,"Given an image classification task with alot (1000000+) of unlabelled images and only a few labelled examples (10000), would it be possible to apply a transfer learning approach combined with a GAN?

Typically, GANs are considered to be unstable to train. Using a pretrained network (as a discriminator) such as the inception nets by Google would be troublesome because it would instantly detect an image to be fake, right? This would make it even more difficult te train?

Had any work been done in this area of research?

",7,1,False,self,,,,,
1416,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,21,9r9nxa,self.MachineLearning,Mode Normalization for Keras,https://www.reddit.com/r/MachineLearning/comments/9r9nxa/mode_normalization_for_keras/,philipperemy,1540469119,[removed],0,1,False,self,,,,,
1417,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,21,9ra1mx,blog.pocketcluster.io,"[N] Weekly Machine Learning Opensource Roundup  Oct. 25, 2018",https://www.reddit.com/r/MachineLearning/comments/9ra1mx/n_weekly_machine_learning_opensource_roundup_oct/,stkim1,1540472241,,0,1,False,default,,,,,
1418,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,22,9racim,self.MachineLearning,"[D] Nature: ""First analysis of pre-registered studies shows sharp rise in null findings""",https://www.reddit.com/r/MachineLearning/comments/9racim/d_nature_first_analysis_of_preregistered_studies/,brainggear,1540474466,"Drawing from this study:

[https://www.nature.com/articles/d41586-018-07118-1](https://www.nature.com/articles/d41586-018-07118-1)

It would be nice to have a conference/journal of such pre-registered experiments in ML.

Basically you submit the paper with theory only and design of experiments, it gets peer reviewed (reviewers suggest tweaks to experiment design) and accepted, and only then you do the experiments. The paper gets accepted regardless of the experimental results.",30,1,False,self,,,,,
1419,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,22,9raf4w,self.MachineLearning,[D] How do you explain complex models to non-technical people?,https://www.reddit.com/r/MachineLearning/comments/9raf4w/d_how_do_you_explain_complex_models_to/,FriendlyCartoonist,1540475044,Any advice or tips?,11,1,False,self,,,,,
1420,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,23,9ral2k,arxiv.org,[1810.10032] Some negative results for Neural Networks,https://www.reddit.com/r/MachineLearning/comments/9ral2k/181010032_some_negative_results_for_neural/,ihaphleas,1540476221,,8,1,False,default,,,,,
1421,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,23,9raoz5,self.MachineLearning,Dedicated machine,https://www.reddit.com/r/MachineLearning/comments/9raoz5/dedicated_machine/,dudetreftgsg,1540476972,[removed],0,1,False,self,,,,,
1422,MachineLearning,t5_2r3gv,2018-10-25,2018,10,25,23,9razl5,medium.com,[N] Can a Canadian AI Startup Challenge Google in AutoML?,https://www.reddit.com/r/MachineLearning/comments/9razl5/n_can_a_canadian_ai_startup_challenge_google_in/,gwen0927,1540479035,,0,1,False,https://a.thumbs.redditmedia.com/P7bpryMBSSGkXUKknLaAJsW9H3Jq68XGiKP8fBhBUZ0.jpg,,,,,
1423,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,0,9rb4ge,self.MachineLearning,"[Question]Example 7.1 in Learning from Data, Abu-mostafa",https://www.reddit.com/r/MachineLearning/comments/9rb4ge/questionexample_71_in_learning_from_data/,BoemelBoi,1540479982,[removed],0,1,False,self,,,,,
1424,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,0,9rb5rm,self.MachineLearning,Machine Learning and Deep Learning with fast.ai,https://www.reddit.com/r/MachineLearning/comments/9rb5rm/machine_learning_and_deep_learning_with_fastai/,harrshjain,1540480219,[removed],0,1,False,self,,,,,
1425,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,0,9rbcxd,self.MachineLearning,Learning rate,https://www.reddit.com/r/MachineLearning/comments/9rbcxd/learning_rate/,lijunyi95,1540481594,[removed],0,1,False,self,,,,,
1426,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,0,9rbiub,self.MachineLearning,[P] 50%+ Faster Machine Learning - Modern Big Data Algorithms (HyperLearn),https://www.reddit.com/r/MachineLearning/comments/9rbiub/p_50_faster_machine_learning_modern_big_data/,danielhanchen,1540482723,"As we enter the first quarter of the 21st century, datasets are getting larger and wider. 

Running primitive and slow algorithms will cause headaches, productivity and economic losses. By optimising algorithms used in stock market predictions, climate change modelling, artificial intelligence and cancer research, the world can benefit dramatically from faster and more accurate numerical methods.  

Modern Big Data Algorithms is a comprehensive collection of Faster Machine Learning techniques. Many algorithms are implemented in Python 3.6 at [**github.com/danielhanchen/hyperlearn**](http://github.com/danielhanchen/hyperlearn).  

I'm currently writing this, and will showcase my findings late November! HyperLearn already has staggering results, where Linear Regression runs in approx 50% of the time than Sklearn, Non-Negative Matrix Factorization is now parallelized with 50% speed improvement. 

&amp;#x200B;

A sneak peak: :) Hope you like it!

[Chapter on SVD](https://i.redd.it/yrqvn610scu11.png)

&amp;#x200B;

[Chapter on PCA](https://i.redd.it/3dpn88ffscu11.png)

[Chapter on PCA \(2\)](https://i.redd.it/325fg9r4scu11.png)",33,1,False,self,,,,,
1427,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,1,9rbmnc,self.MachineLearning,"Wait, the NVLink doesn't fully combine two 2080Tis?",https://www.reddit.com/r/MachineLearning/comments/9rbmnc/wait_the_nvlink_doesnt_fully_combine_two_2080tis/,engine_town_rattler,1540483436,"Can we talk hardware? Very few in r/Hardware discuss workstations for training models. Where do you read about hardware for data science needs?  

I thought the NVLink would combine any two Nvidia Turing GPUs effectively into one giant GPU.  
Would you buy a 2080 Ti for a home desktop workstation? How much would a second improve?  
Would you buy something else if you had a few thousand to spend on RAM and some new GPUs?  
Are you waiting for another company to top Nvidia in GPU hardware?

What, other than a DGX-2 is going to fit a model larger than 16gbs?",0,1,False,self,,,,,
1428,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,1,9rbn3r,self.MachineLearning,"How do you decide when to use median, mean or fit a model to impute missing values?",https://www.reddit.com/r/MachineLearning/comments/9rbn3r/how_do_you_decide_when_to_use_median_mean_or_fit/,Drakkenstein,1540483519,[removed],0,1,False,self,,,,,
1429,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,1,9rboky,medium.com,[Research]Experimenting with a crazy new way to train Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/9rboky/researchexperimenting_with_a_crazy_new_way_to/,sibyjackgrove,1540483796,,0,1,False,https://b.thumbs.redditmedia.com/WY-ldK5wwEI85379N1-U5mTOwObP83kp8Z1W6eBwxzA.jpg,,,,,
1430,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,1,9rbw0t,medium.com,[Research] Experimenting with a crazy new way to train Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/9rbw0t/research_experimenting_with_a_crazy_new_way_to/,sibyjackgrove,1540485151,,0,1,False,https://b.thumbs.redditmedia.com/WY-ldK5wwEI85379N1-U5mTOwObP83kp8Z1W6eBwxzA.jpg,,,,,
1431,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,1,9rbwx5,self.MachineLearning,Are there any deep learning techniques for picking out a specific mark or piece of text from a whole document?,https://www.reddit.com/r/MachineLearning/comments/9rbwx5/are_there_any_deep_learning_techniques_for/,GenTiradentes,1540485326,[removed],0,1,False,self,,,,,
1432,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,1,9rbx19,self.MachineLearning,I am trying to make an Image classifier using CNN which classifes image into 5 categories. But it is giving only one category for all images,https://www.reddit.com/r/MachineLearning/comments/9rbx19/i_am_trying_to_make_an_image_classifier_using_cnn/,skbhagat40,1540485350," 

I am using convolutional neural network to classify the image into five different categories. In the final output layer(a Dense Layer) i am using 'softmax' as the activation function. While compiling the model i am using *loss = 'categorical\_crossentropy'* and *optimizer = 'adam'*, *metrices = 'accuracy'*. But it is giving only one category for all images. Output is like \[0,1,0,0,0\] (as i am classifying into five categories). Everytime i retrain the model only the class changes but it gives same result for all images. 

Please help. Thanks!!",0,1,False,self,,,,,
1433,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,1,9rbyae,self.MachineLearning,Input layer of a convolutional neural network to recognize MNIST digits,https://www.reddit.com/r/MachineLearning/comments/9rbyae/input_layer_of_a_convolutional_neural_network_to/,edwinwongy,1540485585,"From my understanding for neural network the input layer has 784 neurons, each representing 1 pixel of the MNIST greyscale image.

What are the values for the input neurons. Is it (0,255) or scaled to (0,1)? Does a neuron have to represent a value between 0-1 or can it be any number?",0,1,False,self,,,,,
1434,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,2,9rc6er,self.MachineLearning,Free resources for building and deploying a web app,https://www.reddit.com/r/MachineLearning/comments/9rc6er/free_resources_for_building_and_deploying_a_web/,avatar_aangkora,1540487076,[removed],0,1,False,self,,,,,
1435,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,2,9rcbkr,medium.com,"""[Research]"" Experimenting with a crazy new way to train Deep Neural Networks (Part II)",https://www.reddit.com/r/MachineLearning/comments/9rcbkr/research_experimenting_with_a_crazy_new_way_to/,sibyjackgrove,1540488043,,0,1,False,default,,,,,
1436,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,2,9rchj6,self.MachineLearning,What's the minimum accuracy needed for paper publication?,https://www.reddit.com/r/MachineLearning/comments/9rchj6/whats_the_minimum_accuracy_needed_for_paper/,emissary_of_death,1540489153,"I wanted to know if I will be able to publish paper if I choose a topic that will give me low accuracy. For example, there is a kaggle competition going on for Pneumonia Detection, where top score is around 26% percentage. So I was wondering how much the accuracy will be a factor publishing a paper. ",0,1,False,self,,,,,
1437,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,2,9rcicw,i.redd.it,Someone able to get me a pic of this with labeled parts?,https://www.reddit.com/r/MachineLearning/comments/9rcicw/someone_able_to_get_me_a_pic_of_this_with_labeled/,UgaBugaRiver,1540489298,,0,1,False,default,,,,,
1438,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,2,9rcjhd,blog.insightdatascience.com,Generating custom photo-realistic faces using AI,https://www.reddit.com/r/MachineLearning/comments/9rcjhd/generating_custom_photorealistic_faces_using_ai/,e_ameisen,1540489519,,0,1,False,default,,,,,
1439,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,3,9rcx9q,self.MachineLearning,[D] Are there any deep learning techniques for picking out a specific mark or piece of text from a whole document?,https://www.reddit.com/r/MachineLearning/comments/9rcx9q/d_are_there_any_deep_learning_techniques_for/,GenTiradentes,1540492102,"I'm working on a problem right now that involves classifying scanned documents based on a stamp. The stamp is typically placed twice on the cover of each document, on the left and right sides. It can vary some in size, shape, rotation, vertical placement, and surroundings. The stamp is a number, typically about eight digits. The goal is to extract the text of the stamp.

&amp;#x200B;

My first experiment involved training a CNN to simply classify a document as having a stamp or not, which had some limited success, but of course, won't work to retrieve the text of the stamp.

&amp;#x200B;

I've been experimenting with training a model to generate bounding boxes around stamps using YOLO, and that's worked pretty well. However the bounding boxes don't always capture the whole stamp, so I'm having to enlarge the box before cropping, and I still have to properly orient the cropped image, and extract the text.

&amp;#x200B;

I'm aware that the purpose of CNNs are to classify and extract features from an input. Are there any papers or references that solve a problem similar to mine using deep learning? I would think that with the right data and model, It's possible I wouldn't need to train a separate model to generate a bounding box around the regions of interest.",7,1,False,self,,,,,
1440,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,3,9rd5v2,self.MachineLearning,To what extent is the following statement true: If you recognise a pattern (for example in a video) then you can change it?,https://www.reddit.com/r/MachineLearning/comments/9rd5v2/to_what_extent_is_the_following_statement_true_if/,fakebreathingpattern,1540493731,[removed],0,1,False,self,,,,,
1441,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,3,9rd60j,i.redd.it,Network choice help,https://www.reddit.com/r/MachineLearning/comments/9rd60j/network_choice_help/,ATastyPeanut,1540493763,,1,1,False,https://a.thumbs.redditmedia.com/pdmUJ65W2SPoAIiY-amOemPJhXrVhUEcA_WWvtt1iy0.jpg,,,,,
1442,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,4,9rdcvf,bbc.com,"Portrait by AI program sells for $432,000",https://www.reddit.com/r/MachineLearning/comments/9rdcvf/portrait_by_ai_program_sells_for_432000/,prashp,1540495063,,1,1,False,default,,,,,
1443,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,4,9rdcz2,self.MachineLearning,"[D] Research Engineers in the sub, what do you do?",https://www.reddit.com/r/MachineLearning/comments/9rdcz2/d_research_engineers_in_the_sub_what_do_you_do/,PM_ME_YOUR_CONTRACTS,1540495085,"What do Research Engineers actually do?  


Is it building research infrastructure? Implementing model architectures for your fellow Research Scientists? Do you feel as if there is a class divide between RE/RS?  If you working on a project that has publishable results, are you credited in the paper?  


Anyone at Facebook, Amazon, Google/DeepMind, OpenAI care to elaborate?",16,1,False,self,,,,,
1444,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,5,9re3ji,self.MachineLearning,[P] Dehazing GAN,https://www.reddit.com/r/MachineLearning/comments/9re3ji/p_dehazing_gan/,thatbrguy_,1540500106,"Hello, I have been working on creating a modified conditional GAN that can de-haze images. It has the following features:

* The 56-Layer Tiramisu as the generator.
* A patch-wise discriminator.
* A weighted loss function involving three components, namely:
   * GAN loss component. (pix2pix)
   * Perceptual loss component. (aka VGG loss component)
   * L1 loss component.

The model was coded using TensorFlow, and is available on GitHub: [https://github.com/thatbrguy/Dehaze-GAN](https://github.com/thatbrguy/Dehaze-GAN)

The paper for this project is available on Arxiv: [http://arxiv.org/abs/1810.09479](http://arxiv.org/abs/1810.09479)

A small demo on YouTube: [https://www.youtube.com/watch?v=ioSL6ese46A](https://www.youtube.com/watch?v=ioSL6ese46A)

I do realize that a hybrid version of a pix2pix GAN is not very novel, however it was a fulfilling experience to draft my first paper as an undergrad. I would appreciate any feedback or criticism with respect to the code or the paper!",4,1,False,self,,,,,
1445,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,6,9regng,rise.cs.berkeley.edu,Modin: Accelerate Your Pandas Workflows by Changing One Line of Code,https://www.reddit.com/r/MachineLearning/comments/9regng/modin_accelerate_your_pandas_workflows_by/,adits31,1540502568,,13,1,False,default,,,,,
1446,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,6,9rehf8,self.space,Calculate area from Google Earth images.,https://www.reddit.com/r/MachineLearning/comments/9rehf8/calculate_area_from_google_earth_images/,hoho_india,1540502716,,0,1,False,default,,,,,
1447,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,6,9remno,self.MachineLearning,TF Eager Performance Hits,https://www.reddit.com/r/MachineLearning/comments/9remno/tf_eager_performance_hits/,gokstudio,1540503696,"I've recently transitioned to TF Eager and with all the niceness, TF might have a chance against PyTorch. But I see that there are significant performance hits. For example, for training simple CNNs, I see a GPU utilization drop from 90% to 10%. Eventough I use \`with tf.device(""GPU:0"")\` everywhere I can. Am I doing something wrong or is Eager just that terribly slow?

&amp;#x200B;

Have others faced similar experiences with TF Eager?",0,1,False,self,,,,,
1448,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,6,9res1a,twitter.com,"The GAN portrait Christie's just auctioned off for almost $500,000 appears to be stolen",https://www.reddit.com/r/MachineLearning/comments/9res1a/the_gan_portrait_christies_just_auctioned_off_for/,professorGAN,1540504755,,0,1,False,default,,,,,
1449,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,7,9rf32t,self.MachineLearning,Something wrong in xgboost,https://www.reddit.com/r/MachineLearning/comments/9rf32t/something_wrong_in_xgboost/,Anonymous_Guru,1540506999,I trained a dataset using xgboostregressor and both on my training and validation set got a loss( Mae) of 0.0002 while on the test set got a loss of 0.47 that's a huge difference .... Can anyone explain what kind of error I might be doing here.,0,1,False,self,,,,,
1450,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,7,9rf57n,self.MachineLearning,multi head attention,https://www.reddit.com/r/MachineLearning/comments/9rf57n/multi_head_attention/,deluded_soul,1540507450,[removed],0,1,False,self,,,,,
1451,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,8,9rfje6,self.MachineLearning,[R] TDLS - Classic: Neural Machine Translation by Jointly Learning to Align and Translate,https://www.reddit.com/r/MachineLearning/comments/9rfje6/r_tdls_classic_neural_machine_translation_by/,tdls_to,1540510529,"we recently went through one of the original attention papers where the authors go beyond the encoder-decoder architecture and use a soft search to find parts of the sequence that are important in the certain task. they try their proposal on machine translation. 

review: [https://youtu.be/wyQBfi6uOHk](https://youtu.be/wyQBfi6uOHk)

paper: [https://arxiv.org/abs/1409.0473](https://www.youtube.com/redirect?q=https%3A%2F%2Farxiv.org%2Fabs%2F1409.0473&amp;redir_token=GFYznV2efRakmYtGtnexsQvW4oF8MTU0MDU5NjU3N0AxNTQwNTEwMTc3&amp;v=wyQBfi6uOHk&amp;event=video_description)",1,1,False,self,,,,,
1452,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,8,9rfjtc,fatiherikli.github.io,Emojis as a language,https://www.reddit.com/r/MachineLearning/comments/9rfjtc/emojis_as_a_language/,fthrkl,1540510626,,0,1,False,default,,,,,
1453,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,9,9rg0bp,self.MachineLearning,Human-Computer Question Answering Competition (Dec. 15),https://www.reddit.com/r/MachineLearning/comments/9rg0bp/humancomputer_question_answering_competition_dec/,ezubaric,1540514483,[removed],0,1,False,self,,,,,
1454,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,10,9rg8qz,self.MachineLearning,Emotion recognition via with MXNet Gluon with slides and code - x-post r/mxnet,https://www.reddit.com/r/MachineLearning/comments/9rg8qz/emotion_recognition_via_with_mxnet_gluon_with/,sinafz,1540516395,[removed],0,1,False,self,,,,,
1455,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,10,9rgblc,self.MachineLearning,Emotion recognition via with MXNet Gluon with slides and code - x-post r/mxnet,https://www.reddit.com/r/MachineLearning/comments/9rgblc/emotion_recognition_via_with_mxnet_gluon_with/,sinafz,1540517069,[removed],0,1,False,self,,,,,
1456,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,10,9rgbv3,self.MachineLearning,[D] Recommendations for logging images,https://www.reddit.com/r/MachineLearning/comments/9rgbv3/d_recommendations_for_logging_images/,cbHXBY1D,1540517132,I have a small low powered device (Raspberry Pi level device) with a camera attached where I'm performing image recognition on individual frames. Does anyone have recommendations for a logging system to use in production? I don't need to log every frame but I'd theoretically like to log frames that are interesting. I'm writing this in a Python script but would be OK with a C++ logger which I can wrap into a Python SDK.,0,1,False,self,,,,,
1457,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,10,9rgc38,github.com,[P] SketchGAN - A DCGAN that learns to pencil sketch,https://www.reddit.com/r/MachineLearning/comments/9rgc38/p_sketchgan_a_dcgan_that_learns_to_pencil_sketch/,santoso-sheep,1540517187,,0,1,False,default,,,,,
1458,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,10,9rgdiy,self.MachineLearning,GAN and CGAN,https://www.reddit.com/r/MachineLearning/comments/9rgdiy/gan_and_cgan/,Sammiendichu,1540517509,[removed],0,1,True,nsfw,,,,,
1459,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,11,9rgxso,self.MachineLearning,[Discussion] Is it possible to use English ASR systems to improve other non-English ASR systems?,https://www.reddit.com/r/MachineLearning/comments/9rgxso/discussion_is_it_possible_to_use_english_asr/,iamatyro,1540522108,"I apologize in advance if it is a Noob question.

Let's say I have a dataset for French ASR dataset. Can we try using English ASR models to improve it. Sort of like Transfer Learning for Object Detection in Computer Vision.  
Is there any resources i could refer to?

I am currently going through this paper. [using English ASR for German ASR](https://arxiv.org/abs/1706.00290) ",2,1,False,self,,,,,
1460,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,12,9rh5aw,self.MachineLearning,Punctuate a Blob of Text,https://www.reddit.com/r/MachineLearning/comments/9rh5aw/punctuate_a_blob_of_text/,tataiermail,1540523897,[removed],0,1,False,self,,,,,
1461,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,13,9rhjjf,self.MachineLearning,tensorflow inference gives only one detection,https://www.reddit.com/r/MachineLearning/comments/9rhjjf/tensorflow_inference_gives_only_one_detection/,jostiniane,1540527478,[removed],0,1,False,self,,,,,
1462,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,13,9rhr79,self.MachineLearning,Problem with MLP producing same outputs? possibly due to bias term?,https://www.reddit.com/r/MachineLearning/comments/9rhr79/problem_with_mlp_producing_same_outputs_possibly/,qudcjf7928,1540529562,[removed],0,1,False,self,,,,,
1463,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,16,9rij8h,self.MachineLearning,Sequence models other than DL,https://www.reddit.com/r/MachineLearning/comments/9rij8h/sequence_models_other_than_dl/,harry_0_0_7,1540537866,[removed],0,1,False,self,,,,,
1464,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,16,9rik9w,self.MachineLearning,[D] On the confusing metrics of AP and mAP for instance segmentation,https://www.reddit.com/r/MachineLearning/comments/9rik9w/d_on_the_confusing_metrics_of_ap_and_map_for/,bantou_41,1540538190,"When I searched for the details of AP and mAP for datasets like PASCAL, COCO, and CityScapes, usually some vague answer comes up and doesn't really explain them all that well. So I went to read the hundreds of lines of evaluation source code for both CityScapes and COCO and summarized it into this [blog post](https://medium.com/@yanfengliux/the-confusing-metrics-of-ap-and-map-for-object-detection-3113ba0386ef). I hope it helps! ",3,1,False,self,,,,,
1465,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,16,9rir8c,self.MachineLearning,Companies that implement ML to solve Electrical Engineering problems?,https://www.reddit.com/r/MachineLearning/comments/9rir8c/companies_that_implement_ml_to_solve_electrical/,dolladollabilly,1540540468,[removed],0,1,False,self,,,,,
1466,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,17,9riwr2,self.MachineLearning,[D] !DL Sequence models,https://www.reddit.com/r/MachineLearning/comments/9riwr2/d_dl_sequence_models/,harry_0_0_7,1540542405,[removed],0,1,False,self,,,,,
1467,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,17,9riyn1,self.MachineLearning,Running Code summary,https://www.reddit.com/r/MachineLearning/comments/9riyn1/running_code_summary/,sinashish,1540543066,I wonder if NLP can be applied to reducing the length and complexities of code by summarizing it and still preserve the understanding so that the code runs without any errors? ,0,1,False,self,,,,,
1468,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,17,9rj0uc,building.lang.ai,[R] Is my algorithm good enough? - Developing an evaluation framework for our unsupervised AI system,https://www.reddit.com/r/MachineLearning/comments/9rj0uc/r_is_my_algorithm_good_enough_developing_an/,fjaguero,1540543846,,0,1,False,default,,,,,
1469,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,18,9rj61x,self.MachineLearning,Please Explain Feature Engineering,https://www.reddit.com/r/MachineLearning/comments/9rj61x/please_explain_feature_engineering/,Vinceeeent,1540545476,"Can anyone please explain feature engineering? All I know is that feature engineering just combines the features to create a better feature.

&amp;#x200B;

And after doing feature engineering, should I divide my data into: test, train and validation dataset?",0,1,False,self,,,,,
1470,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,18,9rj6nj,self.MachineLearning,Deciphering the Neural Language Model,https://www.reddit.com/r/MachineLearning/comments/9rj6nj/deciphering_the_neural_language_model/,andrea_manero,1540545677,r/http://www.datasciencecentral.com/profiles/blogs/deciphering-the-neural-language-model,0,1,False,self,,,,,
1471,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,18,9rjal1,i.redd.it,"Yann LeCun probably used a GAN to make this presentation [RI Seminar, 2016]",https://www.reddit.com/r/MachineLearning/comments/9rjal1/yann_lecun_probably_used_a_gan_to_make_this/,EveryDay-NormalGuy,1540546919,,0,1,False,https://b.thumbs.redditmedia.com/sX3k1weUKyV-db5jZsCXm5O5AAb2xPW9NlmeSFMCLRw.jpg,,,,,
1472,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,19,9rje6x,self.MachineLearning,[D] : Data-driven narratives for reproducible data-science and research.,https://www.reddit.com/r/MachineLearning/comments/9rje6x/d_datadriven_narratives_for_reproducible/,giulioungaretti,1540548052,"We released our beta version and python client   Check it out here: [www.amie.ai](https://www.amie.ai) !

&amp;#x200B;

We'd be really curious to hear what this sub feels about such an app! ",0,1,False,self,,,,,
1473,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,19,9rjlm4,self.MachineLearning,[D] Does meta-learning like MAML and Reptile applied on regular-sized datasets makes models converge faster?,https://www.reddit.com/r/MachineLearning/comments/9rjlm4/d_does_metalearning_like_maml_and_reptile_applied/,radenML,1540550249,"Meta learning papers usually use Omniglot and mini Imagenet.  


What if I train full MNIST and full CIFAR-10 with MAML and Reptile. Will the models converge faster?",0,1,False,self,,,,,
1474,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,19,9rjm90,medium.com,10 Selection Python Machine Learning Library,https://www.reddit.com/r/MachineLearning/comments/9rjm90/10_selection_python_machine_learning_library/,rg33gj,1540550455,,0,1,False,default,,,,,
1475,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,20,9rjri4,self.MachineLearning,[D] EMOTIONAL INTELLIGENCE,https://www.reddit.com/r/MachineLearning/comments/9rjri4/d_emotional_intelligence/,rmohammadhasnain,1540551979,"Hi guys

We are a small group learning and applying ai to wide variety of areas including BI, image processing, NLP and a lot more places

Recently we got interest into emotional intelligence and wanted to get a snapshot of the current state.

Key addresses, research papers, journals text everything is welcome that you would think is the best in the field.",4,1,False,self,,,,,
1476,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,20,9rjujt,thetechnologyheadlines.com,Google's Machine Learning Framework Comes To Nature's Rescue,https://www.reddit.com/r/MachineLearning/comments/9rjujt/googles_machine_learning_framework_comes_to/,NEWS-TTH,1540552834,,0,1,False,https://b.thumbs.redditmedia.com/y5oVu4lWsVXxhTzQV9zK_Et0UwnwiK3xfzCHAAw6AiI.jpg,,,,,
1477,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,20,9rjvac,self.MachineLearning,What method/approach to use to analysing Taxi Location data?,https://www.reddit.com/r/MachineLearning/comments/9rjvac/what_methodapproach_to_use_to_analysing_taxi/,Imakesensealot,1540553043,[removed],0,1,False,self,,,,,
1478,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,20,9rjyxi,digitalindiapreview.com,Smart Glasses-Ar Glasses Looks Like Regular Glasses,https://www.reddit.com/r/MachineLearning/comments/9rjyxi/smart_glassesar_glasses_looks_like_regular_glasses/,Deepak6954,1540554063,,1,1,False,https://b.thumbs.redditmedia.com/XQGK27tS72u1VqtlLIxs73asAoS6fcvl7dslT2jSpww.jpg,,,,,
1479,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,21,9rk56c,self.scrapinghub,scraping SEC 10-k 10-q files,https://www.reddit.com/r/MachineLearning/comments/9rk56c/scraping_sec_10k_10q_files/,jcoder42,1540555647,,0,1,False,default,,,,,
1480,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,21,9rk8hx,thedigitalenterprise.tumblr.com,Top Business Benefits of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9rk8hx/top_business_benefits_of_machine_learning/,thedigitalenterprise,1540556507,,0,1,False,default,,,,,
1481,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,21,9rk8yg,biorxiv.org,[R] A Framework for Intelligence and Cortical Function Based on Grid Cells in the Neocortex,https://www.reddit.com/r/MachineLearning/comments/9rk8yg/r_a_framework_for_intelligence_and_cortical/,doctorjuice,1540556620,,1,1,False,default,,,,,
1482,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,21,9rkalg,medium.com,Deep Learning approaches to understand Human Reasoning - How to Integrate Reasoning into CNNs and Knowledge Graphs.,https://www.reddit.com/r/MachineLearning/comments/9rkalg/deep_learning_approaches_to_understand_human/,iamarmaan,1540557030,,0,1,False,default,,,,,
1483,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,22,9rkl16,self.MachineLearning,[D] What happened to posting papers?,https://www.reddit.com/r/MachineLearning/comments/9rkl16/d_what_happened_to_posting_papers/,Valiox,1540559420,I come to this sub mainly to learn about recent papers on fancy stuff. Why does it look like all of this has disappeared recently?,41,1,False,self,,,,,
1484,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,22,9rknn1,link.medium.com,Latest research around Adam optimizer,https://www.reddit.com/r/MachineLearning/comments/9rknn1/latest_research_around_adam_optimizer/,bushaev,1540559981,,1,1,False,default,,,,,
1485,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,22,9rkq1q,arxiv.org,Reversible Recurrent Neural Networks [NIPS],https://www.reddit.com/r/MachineLearning/comments/9rkq1q/reversible_recurrent_neural_networks_nips/,sidsig,1540560521,,0,1,False,default,,,,,
1486,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,22,9rkq8w,arxiv.org,[1810.10999] Reversible Recurrent Neural Networks,https://www.reddit.com/r/MachineLearning/comments/9rkq8w/181010999_reversible_recurrent_neural_networks/,sidsig,1540560565,,19,1,False,default,,,,,
1487,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,22,9rkrk0,medium.com,Variational Auto Encoders for Letter Encoding,https://www.reddit.com/r/MachineLearning/comments/9rkrk0/variational_auto_encoders_for_letter_encoding/,brnko,1540560843,,0,1,False,default,,,,,
1488,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,22,9rkslg,arxiv.org,[R] Training behavior of deep neural network in frequency domain,https://www.reddit.com/r/MachineLearning/comments/9rkslg/r_training_behavior_of_deep_neural_network_in/,Deep_Fried_Learning,1540561078,,4,1,False,default,,,,,
1489,MachineLearning,t5_2r3gv,2018-10-26,2018,10,26,23,9rl6em,blog.mgechev.com,Playing Mortal Kombat with TensorFlow.js - Transfer learning and data augmentation,https://www.reddit.com/r/MachineLearning/comments/9rl6em/playing_mortal_kombat_with_tensorflowjs_transfer/,kunalag129,1540563876,,0,1,False,https://b.thumbs.redditmedia.com/fr7eZ8JeQdJJy-S9KRhKVNW3iS5yuVf6QgbleF2dpoI.jpg,,,,,
1490,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,0,9rlxeh,i.redd.it,[P] Tensorflow implementation of Discriminator Rejection Sampling,https://www.reddit.com/r/MachineLearning/comments/9rlxeh/p_tensorflow_implementation_of_discriminator/,_sshin_,1540569134,,1,1,False,https://b.thumbs.redditmedia.com/ylKrAKfqZb9jmNojGWD3lUDKiuJRogwUVM9VB5ye_rE.jpg,,,,,
1491,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,1,9rm4lo,dimensionless.in,How to be an Artificial Intelligence (AI) Expert?,https://www.reddit.com/r/MachineLearning/comments/9rm4lo/how_to_be_an_artificial_intelligence_ai_expert/,divya2018,1540570471,,0,1,False,default,,,,,
1492,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,1,9rm6qk,self.MachineLearning,Is the multinomial sampling function in TF and PyTorch essentially the same as Fitness Proportional (Roulette Wheel) Selection?,https://www.reddit.com/r/MachineLearning/comments/9rm6qk/is_the_multinomial_sampling_function_in_tf_and/,UncleOxidant,1540570879,[removed],0,1,False,self,,,,,
1493,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,1,9rmdo8,self.MachineLearning,What is a widely needed tutorial?,https://www.reddit.com/r/MachineLearning/comments/9rmdo8/what_is_a_widely_needed_tutorial/,Abstractoid,1540572196,"I want to start a blog, and want to post about topics that some people feel need clarification.  I'm perfectly fine taking the time to learn any topic, especially complex ones, in depth - that's the whole point of this. Does anyone have suggestions for what you want to see?",0,1,False,self,,,,,
1494,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,2,9rmm8f,self.MachineLearning,[D] NIPS Funding is at risk. One sponsor is pulling out for not changing the NIPS name.,https://www.reddit.com/r/MachineLearning/comments/9rmm8f/d_nips_funding_is_at_risk_one_sponsor_is_pulling/,SuccessfulBasket,1540573748,"Given the conferences disdain for the concerns of female scientists, Ill be recommending that my team pull its funding support for the conference

The guys living in their Moms basements playing Fortnight &amp; publishing derivative GAN papers - who like the name - can fund it 


https://twitter.com/mattocko/status/1055415314253459456


Note: Please remember we get a lot of heat for not being civil in the discussion. Please follow the sub-rules.",5,1,False,self,,,,,
1495,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,2,9rmox9,github.com,[P] DeepCreamPy - Decensoring H*ntai with CNN (formly named DeepMindBreak),https://www.reddit.com/r/MachineLearning/comments/9rmox9/p_deepcreampy_decensoring_hntai_with_cnn_formly/,re_anon,1540574244,,1,1,False,default,,,,,
1496,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,2,9rmrrw,self.MachineLearning,[D] Is the multinomial sampling function in TF and PyTorch essentially the same as Fitness Proportional (Roulette Wheel) Selection?,https://www.reddit.com/r/MachineLearning/comments/9rmrrw/d_is_the_multinomial_sampling_function_in_tf_and/,UncleOxidant,1540574788," 

## 



In Genetic algorithms Fitness Proportional Selection (often called Roulette wheel selection) is often used to select genomes to move to the next generation. I'm looking at some PyTorch code for a meta-learning algorithm that's making a selection based on the softmax of the outputs of an LSTM like so:

`logits, hidden = self.forward(inputs,hidden`

`probs = F.softmax(logits)`

`action = probs.multinomial(num_samples=1).data`

Some action is being taken based on the probabilities in probs (in this case an RNN cell is being constructed and an activation function is being selected). In the debugger if I run that multinomial over and over I find I can get different results, but the results are proportional to the probabilities - so there's some randomness here, but in general it's more likely to pick the index from probs that has the highest value. Seems a lot like a Roulette wheel selection: [https://en.wikipedia.org/wiki/Fitness\_proportionate\_selection](https://en.wikipedia.org/wiki/Fitness_proportionate_selection) is that a good analogy for what multinomial is doing here?",1,1,False,self,,,,,
1497,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,3,9rn3d3,edyoda.com,Step By Step Guide to learning Machine Learning,https://www.reddit.com/r/MachineLearning/comments/9rn3d3/step_by_step_guide_to_learning_machine_learning/,iamarmaan,1540576966,,0,1,False,default,,,,,
1498,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,3,9rn98p,self.MachineLearning,What am I doing wrong here with TensorFlow? I did a very simple test.,https://www.reddit.com/r/MachineLearning/comments/9rn98p/what_am_i_doing_wrong_here_with_tensorflow_i_did/,imbaisgood,1540578114,[removed],0,1,False,self,,,,,
1499,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,3,9rnits,self.MachineLearning,Help,https://www.reddit.com/r/MachineLearning/comments/9rnits/help/,venx623,1540580001,[removed],0,1,False,self,,,,,
1500,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,3,9rnjzk,frontiersin.org,"someone posted, WHAT HAPPENED WITH RESEARCHES HERE, well -&gt; Enjoy",https://www.reddit.com/r/MachineLearning/comments/9rnjzk/someone_posted_what_happened_with_researches_here/,SGlob,1540580233,,1,1,False,default,,,,,
1501,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,4,9rnmff,arxiv.org,[1810.10098] Deblending galaxy superpositions with branched generative adversarial networks,https://www.reddit.com/r/MachineLearning/comments/9rnmff/181010098_deblending_galaxy_superpositions_with/,davidmreiman,1540580690,,5,1,False,default,,,,,
1502,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,5,9roih6,self.MachineLearning,How to start in ML?,https://www.reddit.com/r/MachineLearning/comments/9roih6/how_to_start_in_ml/,MeEu1,1540587099,[removed],0,1,False,self,,,,,
1503,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,6,9rolma,arxiv.org,[R] pair2vec: Compositional Word-Pair Embeddings for Cross-Sentence Inference,https://www.reddit.com/r/MachineLearning/comments/9rolma/r_pair2vec_compositional_wordpair_embeddings_for/,ofirpress,1540587734,,1,1,False,default,,,,,
1504,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,6,9roqgc,arxiv.org,[R] Analyzing Inverse Problems with Invertible Neural Networks,https://www.reddit.com/r/MachineLearning/comments/9roqgc/r_analyzing_inverse_problems_with_invertible/,olaf_nij,1540588716,,0,1,False,default,,,,,
1505,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,6,9rox8h,self.MachineLearning,[D] An Introduction to Convergence &amp; Error,https://www.reddit.com/r/MachineLearning/comments/9rox8h/d_an_introduction_to_convergence_error/,Gereshes,1540590142,"Hey,

&amp;#x200B;

I wrote up blog posts [about convergence](https://gereshes.com/2018/10/15/an-introduction-to-convergence/) through the lens on iterative methods and how [error](https://gereshes.com/2018/10/08/an-introduction-to-error/) drives numerical methods forward. My last post on gradient descent was well received here, so I figured I would share these as well.

&amp;#x200B;

I hope you enjoy!",0,1,False,self,,,,,
1506,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,6,9rozio,medium.com,DeepMind Paper Challenges Generative Models Judgement,https://www.reddit.com/r/MachineLearning/comments/9rozio/deepmind_paper_challenges_generative_models/,Yuqing7,1540590625,,0,1,False,default,,,,,
1507,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,7,9rp5vd,github.com,GitHub - deeppomf/DeepCreamPy: Decensoring Hentai with Deep Learning Convolutional Neural Networks. Release.,https://www.reddit.com/r/MachineLearning/comments/9rp5vd/github_deeppomfdeepcreampy_decensoring_hentai/,MuzzleO,1540591953,,0,1,False,https://b.thumbs.redditmedia.com/eONh7ufThjImsmX9ly7fTBYvuf-218QK7jr9YAX1IMI.jpg,,,,,
1508,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,7,9rpcat,self.MachineLearning,[D] Variational Autoencoders,https://www.reddit.com/r/MachineLearning/comments/9rpcat/d_variational_autoencoders/,Natsu6767,1540593362,"Recently I read the paper: *Auto-Encoding Variational Bayes**.  Kingma, D. P. &amp; Welling, M. (2013)* , which introduces variational autoencoders a type of generative model which finds application from generating faces to even music!

I wrote a blog post on understanding variational autoencoders: [https://mohitjain.me/2018/10/26/variational-autoencoder/](https://mohitjain.me/2018/10/26/variational-autoencoder/)  to give some insights on how it works and also the mathematical derivations involved (to properly understand VAE, I believe that understanding the mathematics behind it is very crucial). Would love to get any feedback on it.

One shortcoming of VAEs I found is that you can't tell what feature each latent dimension controls. There has been research done on this problem and Beta-VAEs seem to address this problem. Although, I can't seem to understand how just weighing the latent-loss by Beta (&gt;1) can disentangle the latent encodings.

One more thing, instead of using the ""reparametrization trick"" used in the paper to handle the sampling operation, can't we use reinforcement learning methods instead? (I don't have much knowledge on reinforcement learning,  so, maybe my point is completely absurd.)

Also, comparing with GANs, is there any way to tell which will perform ""better"" in certain tasks right from the beginning? For example, tasks which VAEs handle really well but GANs don't. Or can both models perform the same tasks approximately equally well (in this case I think using VAEs is the best due to stability in training problems with GANs)",14,1,False,self,,,,,
1509,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,8,9rpnom,self.MachineLearning,HELP: Testing significance of features in a Boosted tree model,https://www.reddit.com/r/MachineLearning/comments/9rpnom/help_testing_significance_of_features_in_a/,labmeme,1540595945,[removed],0,1,False,self,,,,,
1510,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,8,9rpwl8,arxiv.org,[R] Statistical mechanics of low-rank tensor decomposition,https://www.reddit.com/r/MachineLearning/comments/9rpwl8/r_statistical_mechanics_of_lowrank_tensor/,RSchaeffer,1540598113,,0,1,False,default,,,,,
1511,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,9,9rq0hm,self.MachineLearning,[D] [Serious] Social pressure for #ProtestNIPS is ridiculous where you can give only one answer-- Yes.,https://www.reddit.com/r/MachineLearning/comments/9rq0hm/d_serious_social_pressure_for_protestnips_is/,CorrectRent,1540599055,"*If you are a prominent researcher and you are silent or say no for NIPS name change, these people will label you sexist. *

I know Mark Riedl. I saw this on his Twitter today


&gt; Dear @NipsConference sponsors: do you endorse the message that NIPS is sending to women scientists by not changing its name? If not, please consider pulling your support.

@facebook @IBMResearch @Microsoft @amazon  @NvidiaAI @intel @uber @DeepMindAI @apple @Twitter @netflix


https://twitter.com/mark_riedl/status/1055859349153665025

They are forcing all companies to agree with them. It is basically their way or no way over a  pun.  I do not have a lot of voice in this field. I am a new researcher in this field with a couple of papers in ML. I hope a prominent and powerful voice in ML stands up and talk about this without a fear of repercussions. 

",38,1,False,self,,,,,
1512,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,9,9rq99n,self.MachineLearning,"Has anyone been able to reproduce the results of ""Language Modeling with Gated Convolutional Networks"" ?",https://www.reddit.com/r/MachineLearning/comments/9rq99n/has_anyone_been_able_to_reproduce_the_results_of/,Nimitz14,1540601274,There are some implementations on github but none seem to have bothered to try to recreate the performance. Paper [here](https://arxiv.org/pdf/1612.08083.pdf).,0,1,False,self,,,,,
1513,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,10,9rqca8,github.com,[P] SketchGAN - DCGAN learns to sketch,https://www.reddit.com/r/MachineLearning/comments/9rqca8/p_sketchgan_dcgan_learns_to_sketch/,santoso-sheep,1540602050,,0,1,False,default,,,,,
1514,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,11,9rr317,self.MachineLearning,[P] Looking for some feedback on a small side project: Classifying NBA action with 3D CNN,https://www.reddit.com/r/MachineLearning/comments/9rr317/p_looking_for_some_feedback_on_a_small_side/,nsstring96,1540609102,"
Source and examples [on Github](https://github.com/neeilan/DeepPlayByPlay)

I'd love to get some ideas on how to utilize the high quality training data I have collected without ending up with a massive model that is too slow to train or simply doesn't fit in GPU memory. For example, the 3D ConvNet model in the repo has about ~20 million parameters, but it's input is a massively downsampled, 90 frame, 240 x 320, single channel version of an originally 1080p clip. I feel that the model's accuracy can be improved significantly if the input video didn't have to be so low quality (often bad enough that a human may not do better than 74% with 4 classes).

When compared to popular classification datasets like UCF, classifying plays within the same game proved tricky because the information distinguishing one type of play from another is contained in less than 0.5% of the values in the input tensor - are there any architectures that give great compute 'bang for buck' when it comes to video classification of this nature?

I also tried a simple LSTM across frames (did not perform as well) and 3-channel (color) version of this model, which was quite slow to train. Is video classification always computationally intensive?

Thanks!",12,1,False,self,,,,,
1515,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,12,9rr4zy,self.MachineLearning,What are the best hackathon in machine learning and deep learning for beginners?,https://www.reddit.com/r/MachineLearning/comments/9rr4zy/what_are_the_best_hackathon_in_machine_learning/,Midhilesh29,1540609642,[removed],0,1,False,self,,,,,
1516,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,13,9rrp1m,self.MachineLearning,[D] Evolving designs to understand Human Reasoning,https://www.reddit.com/r/MachineLearning/comments/9rrp1m/d_evolving_designs_to_understand_human_reasoning/,jaleyhd,1540615522,"Understanding ***Human reasoning*** has been a focal point of a lot of AI research in the past decade.  The article is an extremely *well researched attempt* to bring out the journey. 

Do share the list of research papers (in the comment section), which give you a deeper insight into Human Reasoning.  

&amp;#x200B;

**Blog Link :** [https://towardsdatascience.com/deep-learning-approaches-to-understand-human-reasoning-46f1805d454d](https://towardsdatascience.com/deep-learning-approaches-to-understand-human-reasoning-46f1805d454d)

&amp;#x200B;

*PS: Show your support to* ***independent*** ***well researched publications*** *by giving claps .* ",1,1,False,self,,,,,
1517,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,15,9rs4zl,reddit.com,[N] 20 top lawyers were beaten by legal AI,https://www.reddit.com/r/MachineLearning/comments/9rs4zl/n_20_top_lawyers_were_beaten_by_legal_ai/,kunalag129,1540620594,,0,1,False,default,,,,,
1518,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,18,9rt2od,self.MachineLearning,"PC configuration for machine learning. Thoughts, views, help?",https://www.reddit.com/r/MachineLearning/comments/9rt2od/pc_configuration_for_machine_learning_thoughts/,aichemzee,1540633045,[removed],0,1,False,self,,,,,
1519,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,18,9rt2yn,arxiv.org,[R] On the Spectral Bias of Neural Networks,https://www.reddit.com/r/MachineLearning/comments/9rt2yn/r_on_the_spectral_bias_of_neural_networks/,kekkmachine,1540633145,,13,1,False,default,,,,,
1520,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,19,9rt90u,self.MachineLearning,Implements of cs229(Machine Learning course taught by Andrew Ng) in python.,https://www.reddit.com/r/MachineLearning/comments/9rt90u/implements_of_cs229machine_learning_course_taught/,Sierkinhane,1540635361,[removed],0,1,False,https://b.thumbs.redditmedia.com/oOfDBkBIs_D-0keDHUSVR1tvE4hq3dWA0_D2_LKvqBQ.jpg,,,,,
1521,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,19,9rtc7q,self.MachineLearning,[D] What developments do you expect to see in machine learning in the upcoming 5 years?,https://www.reddit.com/r/MachineLearning/comments/9rtc7q/d_what_developments_do_you_expect_to_see_in/,mrconter1,1540636569,I expect to see a easier access to massively parallelized hardware for training and inference. What do you think?,176,1,False,self,,,,,
1522,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,20,9rtj83,self.MachineLearning,[AAAI-19] Student Abstracts discussion,https://www.reddit.com/r/MachineLearning/comments/9rtj83/aaai19_student_abstracts_discussion/,zvnanon1337,1540639167,[removed],0,1,False,self,,,,,
1523,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,20,9rtkya,self.MachineLearning,AAAI'19 Student Abstracts discussion,https://www.reddit.com/r/MachineLearning/comments/9rtkya/aaai19_student_abstracts_discussion/,zvnanon1337,1540639767,[removed],0,1,False,self,,,,,
1524,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,20,9rtn3v,self.MachineLearning,[D] AAAI'19 Student Abstracts discussion,https://www.reddit.com/r/MachineLearning/comments/9rtn3v/d_aaai19_student_abstracts_discussion/,zvnanon1337,1540640470,"Has anyone received notification for their [Student Abstracts](https://aaai.org/Conferences/AAAI-19/aaai19studentcall/) track submission for AAAI'19?

Also, what is the acceptance rate like in recent years?",2,1,False,self,,,,,
1525,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,21,9rtzob,self.MachineLearning,Telecom: Enterprise Messaging is the New Black,https://www.reddit.com/r/MachineLearning/comments/9rtzob/telecom_enterprise_messaging_is_the_new_black/,andrea_manero,1540644431,[removed],0,1,False,self,,,,,
1526,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,22,9ru4h6,arxiv.org,[R] One-Shot High-Fidelity Imitation (DM),https://www.reddit.com/r/MachineLearning/comments/9ru4h6/r_oneshot_highfidelity_imitation_dm/,yazriel0,1540645767,,1,1,False,default,,,,,
1527,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,22,9ru7ih,self.MachineLearning,Want to teach machine learning for free,https://www.reddit.com/r/MachineLearning/comments/9ru7ih/want_to_teach_machine_learning_for_free/,sahilbanno,1540646580,"Hello everyone i am looking for students who are interested to learn  machine and deep learning.

I can teach you machine learning for free.

Requirements: some basic understanding of python language and a computer

We will build some awesome projects.
We will communicate with each other via skype id (amazing python)

If you appreciate my efforts and love my teachings then you can pay me but its not mandatory.

The session will be one on one.


Thank you
",0,1,False,self,,,,,
1528,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,22,9ru8ir,self.MachineLearning,E-commerce Search Engine,https://www.reddit.com/r/MachineLearning/comments/9ru8ir/ecommerce_search_engine/,artificial_intel423,1540646848,[removed],0,1,False,self,,,,,
1529,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,22,9ruaq0,self.MachineLearning,[D] The abysmal state of non-stochastic optimization in TF (and elsewhere?),https://www.reddit.com/r/MachineLearning/comments/9ruaq0/d_the_abysmal_state_of_nonstochastic_optimization/,svantana,1540647427,"I find that most (all?) optimizers in autodiff libraries are designed with sgd in mind. When doing deterministic optimization, even with a simple scalar cost(x) = k*x^2, most (all?) optimizers in TF require tuning of hyperparams dependent on k to avoid superslow convergence, diverge, or getting stuck. Even the ""quasi-newton-inspired"" ones (AdaGrad, AdaDelta, etc). TF-probability has a BFGS optimizer, which is great, but is a no-go for the 1000's of dimensions I'm working with.

Do you guys have any tips on 3rd party implementations, or if any other ML lib is more suited for tasks like this? For reference, I'm doing auto-encoding by optimizing a feature+reconstruction cost function on one data point at a time. I'm currrently considering writing my own optimizer with a combination of momentum, per-dim-quasi-newton, and some form of trust region.",17,1,False,self,,,,,
1530,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,22,9rubsq,self.MachineLearning,Max Utility Optimization,https://www.reddit.com/r/MachineLearning/comments/9rubsq/max_utility_optimization/,Domm311,1540647715,[removed],0,1,False,self,,,,,
1531,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,22,9ruc1d,self.MachineLearning,"""Autoblow A.I."" The male masturbation device",https://www.reddit.com/r/MachineLearning/comments/9ruc1d/autoblow_ai_the_male_masturbation_device/,trenuss,1540647774,[removed],0,1,False,self,,,,,
1532,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,22,9rud4g,self.MachineLearning,[D] Where do you get data to train your models?,https://www.reddit.com/r/MachineLearning/comments/9rud4g/d_where_do_you_get_data_to_train_your_models/,nutellaNstrawberries,1540648046,"Assuming the data is not easily accessible, how would you go about collecting?",13,1,False,self,,,,,
1533,MachineLearning,t5_2r3gv,2018-10-27,2018,10,27,23,9ruqko,self.MachineLearning,Recent Advances in Object Detection in the Age of Deep Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/9ruqko/recent_advances_in_object_detection_in_the_age_of/,gnavihs,1540651321,[removed],0,1,False,self,,,,,
1534,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,0,9ruym6,github.com,"[P] Code for Sequential Attend, Infer, Repeat: Generative Modelling of Moving Objects",https://www.reddit.com/r/MachineLearning/comments/9ruym6/p_code_for_sequential_attend_infer_repeat/,akosiorek,1540653093,,0,1,False,default,,,,,
1535,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,0,9ruz0y,self.MachineLearning,What do you use to train your data when working on small learning projects?,https://www.reddit.com/r/MachineLearning/comments/9ruz0y/what_do_you_use_to_train_your_data_when_working/,ahadcove,1540653192,[removed],0,1,False,self,,,,,
1536,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,0,9rv3n7,self.MachineLearning,"[Research] GANs for predictive models, e.g. future scene/frame prediction in videos?",https://www.reddit.com/r/MachineLearning/comments/9rv3n7/research_gans_for_predictive_models_eg_future/,daniel451,1540654208,"Original post: [https://www.reddit.com/r/deeplearning/comments/9rv0eq/gans\_for\_future\_sceneframe\_prediction/](https://www.reddit.com/r/deeplearning/comments/9rv0eq/gans_for_future_sceneframe_prediction/)

As stated there, I am looking for papers, blog posts or implementations about predictive tasks solved with GANs, especially future scene/frame prediction.

I have started with *Deep multi-scale video prediction beyond mean square error* by Mathieu, Couprie &amp; LeCun (paper: [https://arxiv.org/abs/1511.05440](https://arxiv.org/abs/1511.05440); implementation: [https://github.com/dyelax/Adversarial\_Video\_Generation](https://github.com/dyelax/Adversarial_Video_Generation)).

Any suggestions for additional literature?",4,1,False,self,,,,,
1537,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,0,9rv4au,medium.com,How to Beat the 85% Failure Rate in Production ML,https://www.reddit.com/r/MachineLearning/comments/9rv4au/how_to_beat_the_85_failure_rate_in_production_ml/,whiteoakwonder,1540654340,,0,1,False,default,,,,,
1538,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,1,9rvcbw,self.MachineLearning,[R] Deep Learning Approaches to understand Human Reasoning,https://www.reddit.com/r/MachineLearning/comments/9rvcbw/r_deep_learning_approaches_to_understand_human/,jaleyhd,1540656064," Understanding Human reasoning has been a focal point of a lot of AI research in the past decade. The article is an *extremely well researched* attempt to bring out the journey. 

[https://towardsdatascience.com/deep-learning-approaches-to-understand-human-reasoning-46f1805d454d](https://towardsdatascience.com/deep-learning-approaches-to-understand-human-reasoning-46f1805d454d)

&amp;#x200B;

&amp;#x200B;",11,1,False,self,,,,,
1539,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,1,9rve79,self.MachineLearning,Questions about PPO algorithm,https://www.reddit.com/r/MachineLearning/comments/9rve79/questions_about_ppo_algorithm/,Pawnbrake,1540656438,[removed],0,1,False,self,,,,,
1540,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,1,9rvefh,self.MachineLearning,[D] Questions about PPO algorithm,https://www.reddit.com/r/MachineLearning/comments/9rvefh/d_questions_about_ppo_algorithm/,Pawnbrake,1540656489,"I'm a bit confused about the math behind [PPO](https://arxiv.org/pdf/1707.06347.pdf) and I was hoping to get some questions answered.  Sorry if some of these questions are trivial.

&amp;#x200B;

So I have an actor and a critic.  This paper seems to be only interested in improving the loss function for the actor.

1. **What is the function that I am trying to minimize using gradient descent?**  My understanding is that it's -L^(CLIP) (equation (7), page 3).
2. **When does the policy get updated?**  My best guess from reading is that we collect experiences from a number of rollouts until we have a number of experiences.  The stability allows us to batch the experience into minibatches and train for multiple epochs which isn't available with other policy gradient methods.
   1. So, for the sake of example, collect 1024 experiences (each experience consisting of state, action, advantage) and then learn based off randomly generated minibatches of size 64.  Do this for 10 epochs.  Good example?  Then, the policy before learning becomes the new `policy_old`.  We discard these experiences - don't keep them in an experience replay - and start generating new experiences with new rollouts.
3. **What is pi\_theta(a\_t | s\_t)?**  I assume that it's the vector that is returned when you feed a state into a policy.  I assume that the entries in this vector are in the range \[0, 1\] and that `sum(vector_of_policies) == 1`.
4. **What does the E\_t function mean?**  In the paper it says that it's ""...the empirical average over a finite batch of samples, in an algorithm that alternates between sampling and optimization. "" but this doesn't quite make sense to me.  Let's say that my policy generates vectors of length 5, does it average over those 5 values (after dividing by the old policy vector, multiplying by advantage, and clipping)?  Or does it instead mean that (with minibatch size 64 for example, causing the input to be a 64x5 dimension matrix) we average over the minibatch, such that the dimensions of the matrix get changed from 64x5 to 5?  Or something else?
5. **Why do all of the implementations of this algorithm I see have e****^(r(t)****)?**  In equation (7) I don't see where a natural exponent would enter the equation.  However, I see natural exponents [here](https://github.com/reinforcement-learning-kr/pg_travel/blob/f9280bb3d5922f5d2678db2d75b8b05633da8871/unity/agent/ppo.py#L34), [here](https://github.com/uidilr/ppo_tf/blob/222f3c53a7d486e04827cadfe860dfe9fdd898db/ppo.py#L49), and [here](https://github.com/ikostrikov/pytorch-a2c-ppo-acktr/blob/2edf667a2e2bb2fcfe8f102b0a58576a69dad4e5/algo/ppo.py#L61) for example.  After looking at these I think I understand that they're taking the natural logarithm and then the natural exponent, but this doesn't make sense to me because this seems redundant and computationally slow.

&amp;#x200B;

&amp;#x200B;",12,1,False,self,,,,,
1541,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,1,9rvf2w,youtube.com,Dynamic Programming in Reinforcement Learning (RL in a nutshell),https://www.reddit.com/r/MachineLearning/comments/9rvf2w/dynamic_programming_in_reinforcement_learning_rl/,vector_machines,1540656639,,0,1,False,https://b.thumbs.redditmedia.com/T1_UizBCX7xjIML-cmr1_2yiJeebKrZdoZ9OE1Vf9Vg.jpg,,,,,
1542,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,1,9rvl87,medium.com,[R] Recurrent Binary Embedding for GPU-Enabled Exhaustive Retrieval from Billion-Scale Semantic Vectors,https://www.reddit.com/r/MachineLearning/comments/9rvl87/r_recurrent_binary_embedding_for_gpuenabled/,gwen0927,1540657959,,0,1,False,default,,,,,
1543,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,2,9rvxj6,self.MachineLearning,[D] Best book/course to get started with PyTorch?,https://www.reddit.com/r/MachineLearning/comments/9rvxj6/d_best_bookcourse_to_get_started_with_pytorch/,raymestalez,1540660468,"I'm relatively new to ML, it would be nice to have a simple straightforward introduction to PyTorch. Can you recommend me something good and reasonably easy to get started with?",7,1,False,self,,,,,
1544,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,2,9rw5v4,self.MachineLearning,comparing a classifier against a random predictor,https://www.reddit.com/r/MachineLearning/comments/9rw5v4/comparing_a_classifier_against_a_random_predictor/,alexwasnotfree,1540662109,"I'm reading a paper and got stuck in this part that compares a classifier against a random predictor

&amp;#x200B;

&gt;McNemars c2 test was performed to compare each of the classifiers against random predictors. The random predictors were developed by training each of the classification algorithms with a randomly permuted training set to disrupt the relationships between the class labels and input features. Furthermore, a paired t-test was performed to compare AUC and F1 scores of the RUSRF predictor against the other 4 predictors, while McNemars c2 test was used to compare the sensitivity and specificity.  

&amp;#x200B;

I don't exactly understand how a random permuted training set would dissolve the relationship between classes and input features and what exactly is the goal of this.",0,1,False,self,,,,,
1545,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,3,9rwieu,self.MachineLearning,Accelerate your IT career with CompTIA Network+ Training,https://www.reddit.com/r/MachineLearning/comments/9rwieu/accelerate_your_it_career_with_comptia_network/,internetdigitalentre,1540664758,[removed],0,1,False,https://a.thumbs.redditmedia.com/5WubNVejeygKGK3OmQATnoEfDpSIcDqwAOyZPFio5y4.jpg,,,,,
1546,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,4,9rx1o6,medium.com,"[P] I wrote a tutorial on Reinforcement Learning in for games in Unity, illustrated on Flappy Bird",https://www.reddit.com/r/MachineLearning/comments/9rx1o6/p_i_wrote_a_tutorial_on_reinforcement_learning_in/,AdamStreck,1540668845,,0,1,False,default,,,,,
1547,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,4,9rx5c8,youtu.be,"The Neural Engine on iPhone XS is not 7x faster, but its still a damn BEAST",https://www.reddit.com/r/MachineLearning/comments/9rx5c8/the_neural_engine_on_iphone_xs_is_not_7x_faster/,OrgaHenry,1540669657,,0,1,False,https://b.thumbs.redditmedia.com/VUfEzEm95gQU2pj_ttLHJyselE9nDMX9ivRk3iSby-c.jpg,,,,,
1548,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,5,9rx908,self.MachineLearning,How do CNNs classify different types into the same class?,https://www.reddit.com/r/MachineLearning/comments/9rx908/how_do_cnns_classify_different_types_into_the/,kkota,1540670454,[removed],0,1,False,self,,,,,
1549,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,5,9rxd1m,aclweb.org,EMNLP 2018 paper FewRel: A Large-Scale Supervised Few-Shot Relation Classification Dataset with State-of-the-Art Evaluation,https://www.reddit.com/r/MachineLearning/comments/9rxd1m/emnlp_2018_paper_fewrel_a_largescale_supervised/,ProKil_Chu,1540671332,,1,1,False,default,,,,,
1550,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,5,9rxlnc,conal.net,[R] The Simple Essence of Automatic Differentiation,https://www.reddit.com/r/MachineLearning/comments/9rxlnc/r_the_simple_essence_of_automatic_differentiation/,breandan,1540673245,,0,1,False,default,,,,,
1551,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,6,9rxuzy,deeplearningio.com,Google Colab Free GPU Tutorial | Deep Learning IO,https://www.reddit.com/r/MachineLearning/comments/9rxuzy/google_colab_free_gpu_tutorial_deep_learning_io/,mrcgllr,1540675291,,0,1,False,default,,,,,
1552,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,6,9ry01h,self.MachineLearning,Can a CNN find features with large dynamic range?,https://www.reddit.com/r/MachineLearning/comments/9ry01h/can_a_cnn_find_features_with_large_dynamic_range/,QuirksNquarkS,1540676447,"Hi there,

I have a problem which I'm considering applying a CNN to a problem where I need to identify features in an image which will generally have a brightness of 10\^-5 relative to the average pixel brightness. I know that DL usually works best on numbers of order 1, so I was wondering if anyone had any references or suggestions.

Thanks!",0,1,False,self,,,,,
1553,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,9,9rzdvq,self.MachineLearning,"[D] For window-based word embedding models (Word2vec, Glove, etc), is there any studies on the relationship between window size (number of words to Consider left/right of a center word) and the number of words to sample from that window? I know something like this must exist, but just can't find it.",https://www.reddit.com/r/MachineLearning/comments/9rzdvq/d_for_windowbased_word_embedding_models_word2vec/,BatmantoshReturns,1540688301,"There's an easy misconception that all the words within the window size hyperparameter are sampled. For example, for word2vec Cbow, for the following sentence

'The dish ran away with the spoon to jump over the moon'

Say that the center word is 'spoon' and there's a window size of 4 on each side, so the words within the window size is 'ran', 'away', 'with', 'the', 'to', 'jump', 'over', 'the' (ignoring filtering out most common words such as 'the' and 'to'). So the label would be the embedding corresponding to 'spoon'. 

However, the input does't necessarily have to be the average of all 8 embeddings corresponding to all the words within the window. We can randomly sample 1 to 8 words from those 8 words. So if we pick 4 words to sample, it could be the average of 'ran', 'with', 'jump', 'to'. On the next epoch it could be another 4 random words from that window. 

**So the window size and number of words per center word are two completely different hyper parameters**. This distinction becomes very important when applying these algorithms to recommendation systems, since the equivalent parameter of the 'window size' can vary within the dataset itself, and have a range from the minimum sampling rate to 200 (in my minor experience). 

Does anyone know of any studies looking at these hyper parameters individually. I have a feeling there must be something done already, but I can't seem to form the right query phrase to find it. ",8,1,False,self,,,,,
1554,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,10,9rzefv,self.MachineLearning,"PDF parsers to extract headers, body of text",https://www.reddit.com/r/MachineLearning/comments/9rzefv/pdf_parsers_to_extract_headers_body_of_text/,SuperCComplex,1540688437,[removed],0,1,False,self,,,,,
1555,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,10,9rzg62,self.MachineLearning,"Has anyone received a comment on OpenReview with the title ""relevant reference""?",https://www.reddit.com/r/MachineLearning/comments/9rzg62/has_anyone_received_a_comment_on_openreview_with/,Richard_wth,1540688860,"I submitted a paper to OpenReview recently and received a comment today stating:

Hi, just wanted to point out a very relevant paper --
(paper link)
I guess it deserves to be mentioned in your paper. 

I read the linked paper and tbh do not agree with the ""very relevant"" part. However, then I found this comment suspicious because:
1. The comment is only shown to the reviewers and authors, and not publicly available;
2. It appeared during the period when the reviewers should post their comments.
3. I happened to check the recent activity and found other authors replied to such comment saying they would add that paper.

I wonder if this is an improper way to promote someone's work or it's just me being too sensitive. ",0,1,False,self,,,,,
1556,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,10,9rzh5i,self.MachineLearning,Tensorflow downloading problems.,https://www.reddit.com/r/MachineLearning/comments/9rzh5i/tensorflow_downloading_problems/,Zman98789,1540689118,"Hello, I have VS Code on my PC and I use it to program in python (I love useing it) but I am not able to use Tensorflow with VS Code because I have python 3.7 installed on it I want to downgrade python to 3.6 so I can download Tensorflow if anyone knows how I can do this please help.

&amp;#x200B;

PS: If you know how to enable AMD cards to work with Tensorflow that would help immensely to.",0,1,False,self,,,,,
1557,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,11,9rzzj2,self.MachineLearning,How to wire up bi-directional LSTMs?,https://www.reddit.com/r/MachineLearning/comments/9rzzj2/how_to_wire_up_bidirectional_lstms/,cristodaro,1540693984,[removed],0,1,False,https://b.thumbs.redditmedia.com/XoCIAVaUhxK9ntEQuz0ovFybK18gKRLBomoOvtoaoWI.jpg,,,,,
1558,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,11,9s010a,youtube.com,[P] Just released my latest video on Dynamic Programming in RL. Check it out!,https://www.reddit.com/r/MachineLearning/comments/9s010a/p_just_released_my_latest_video_on_dynamic/,vector_machines,1540694371,,0,1,False,https://b.thumbs.redditmedia.com/T1_UizBCX7xjIML-cmr1_2yiJeebKrZdoZ9OE1Vf9Vg.jpg,,,,,
1559,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,12,9s05fr,self.MachineLearning,Interpreting ARIMA model,https://www.reddit.com/r/MachineLearning/comments/9s05fr/interpreting_arima_model/,sarasotadude,1540695631,"Hey guys,

&amp;#x200B;

I'm getting started in timeseries and I'm having a hard time finding resources that explain how to interpret a non zero significant intercept term of an ARIMA model.  How is this term supposed to be interpreted?

&amp;#x200B;

I greatly appreciate all responses!  Thanks for the help!",0,1,False,self,,,,,
1560,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,12,9s0ao1,self.MachineLearning,Free servers with 1080Ti for deep learning,https://www.reddit.com/r/MachineLearning/comments/9s0ao1/free_servers_with_1080ti_for_deep_learning/,whitezl0,1540697076,[removed],0,1,False,self,,,,,
1561,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,13,9s0jwg,self.MachineLearning,When he tells me....,https://www.reddit.com/r/MachineLearning/comments/9s0jwg/when_he_tells_me/,Einstein321,1540699744,[removed],0,1,False,self,,,,,
1562,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,13,9s0pgc,self.MachineLearning,"[D] Has anyone received a comment on OpenReview with the title ""relevant reference""?",https://www.reddit.com/r/MachineLearning/comments/9s0pgc/d_has_anyone_received_a_comment_on_openreview/,Richard_wth,1540701415,"I submitted a paper to OpenReview recently and received a comment today stating:

    Hi, just wanted to point out a very relevant paper --
    (paper link)
    I guess it deserves to be mentioned in your paper. 

I read the linked paper and tbh do not agree with the ""very relevant"" part. However, then I found this comment suspicious because:
1. The comment is only shown to the reviewers and authors, and not publicly available;
2. It appeared during the period when the reviewers should post their comments.
3. I happened to check the recent activity and found several other authors replied to such comment saying they would cite that paper.

I wonder if this is an improper way to promote someone's work or it's just me being too sensitive. ",8,1,False,self,,,,,
1563,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,14,9s1135,self.MachineLearning,[D] Where do you get data to train your models? Follow up,https://www.reddit.com/r/MachineLearning/comments/9s1135/d_where_do_you_get_data_to_train_your_models/,nutellaNstrawberries,1540705346,"There were a lot  good answers to my initial question on where people find data here: [https://www.reddit.com/r/MachineLearning/comments/9rud4g/d\_where\_do\_you\_get\_data\_to\_train\_your\_models/](https://www.reddit.com/r/MachineLearning/comments/9rud4g/d_where_do_you_get_data_to_train_your_models/)

&amp;#x200B;

My follow up question is what happens when the data you are looking for is not available? Do you hire a mechanical turk? Do you scrape? Other way? Or do you call it a day?",5,1,False,self,,,,,
1564,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,14,9s12pz,self.MachineLearning,Your thoughts on https://www.appliedaicourse.com/,https://www.reddit.com/r/MachineLearning/comments/9s12pz/your_thoughts_on_httpswwwappliedaicoursecom/,KarthikMgk,1540705954,[removed],0,1,False,self,,,,,
1565,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,15,9s1av3,self.MachineLearning,Ideas For ML Hackathon,https://www.reddit.com/r/MachineLearning/comments/9s1av3/ideas_for_ml_hackathon/,UpcominTerminator,1540708963,What are some good ideas related to computer vision and machine learning? It is a 24hr hackathon.,0,1,False,self,,,,,
1566,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,19,9s24lg,self.MachineLearning,Gaussian process regression,https://www.reddit.com/r/MachineLearning/comments/9s24lg/gaussian_process_regression/,luchins,1540720949,[removed],0,1,False,self,,,,,
1567,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,20,9s2epd,self.MachineLearning,Learn all Machine Learning Algorithm,https://www.reddit.com/r/MachineLearning/comments/9s2epd/learn_all_machine_learning_algorithm/,adarsh_adg,1540724806,[removed],0,1,False,self,,,,,
1568,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,20,9s2hmk,self.MachineLearning,Early Time Series Classification,https://www.reddit.com/r/MachineLearning/comments/9s2hmk/early_time_series_classification/,MK0390,1540725913,[removed],0,1,False,self,,,,,
1569,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,20,9s2kem,self.MachineLearning,When Not to Use Deep Learning,https://www.reddit.com/r/MachineLearning/comments/9s2kem/when_not_to_use_deep_learning/,andrea_manero,1540726991,[removed],0,1,False,self,,,,,
1570,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,22,9s39pq,vox.com,IBM is creating perfume using artificial intelligence,https://www.reddit.com/r/MachineLearning/comments/9s39pq/ibm_is_creating_perfume_using_artificial/,impulsecorp,1540734641,,0,1,False,https://b.thumbs.redditmedia.com/C4spnhdekn--z3jOqIn1PNGnXAFk9KeHsms37IEBK1I.jpg,,,,,
1571,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,22,9s3bqk,self.MachineLearning,Simulation Environment for Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/9s3bqk/simulation_environment_for_deep_reinforcement/,spacevstab,1540735136,[removed],0,1,False,self,,,,,
1572,MachineLearning,t5_2r3gv,2018-10-28,2018,10,28,23,9s3jr1,self.MachineLearning,What Approach can one take to creating new images from a batch of selected images?,https://www.reddit.com/r/MachineLearning/comments/9s3jr1/what_approach_can_one_take_to_creating_new_images/,pmkiller,1540737059,"Hello,

&amp;#x200B;

For one of my courses at master degree we were allowed to implement any project we want. Being a fan of AI-generated images I wanted to create something similar to: [https://logojoy.com/](https://logojoy.com/) 

&amp;#x200B;

Currently I am testing a Variational Auto Encoder on CIFAR10, but even when the algorithm manages to recreate something similar to the training set ( from random means ), I still have no idea how I could make a batch of selected images, pass it to the Autoencoder and recreate variations of the selected images ( combinations of the more specifically ).

&amp;#x200B;

What are some approaches or what would be your approach ?",0,1,False,self,,,,,
1573,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,0,9s3r3k,edyoda.com,Coding Game of Thrones in 9 lines [Markov Decision Process],https://www.reddit.com/r/MachineLearning/comments/9s3r3k/coding_game_of_thrones_in_9_lines_markov_decision/,iamarmaan,1540738844,,0,1,False,default,,,,,
1574,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,0,9s3tqu,self.MachineLearning,ClassificaIO,https://www.reddit.com/r/MachineLearning/comments/9s3tqu/classificaio/,roushang,1540739421,"Just released the final version of ClassificaIO on GitHub and PyPi. ClassificaIO is an open-source graphical user interface, written in python, for machine learning classification for the scikit-learning python library. Hope you like it.

GitHub code:[https://github.com/gmiaslab/ClassificaIO](https://github.com/gmiaslab/ClassificaIO)

PyPi:[https://pypi.org/project/ClassificaIO/](https://pypi.org/project/ClassificaIO/)

&amp;#x200B;

Also wrote a user manual that can be found here:[https://github.com/gmiaslab/manuals/blob/master/ClassificaIO/ClassificaIO\_UserManual.pdf](https://github.com/gmiaslab/manuals/blob/master/ClassificaIO/ClassificaIO_UserManual.pdf)

Supplementary data files are here:[https://github.com/gmiaslab/manuals/tree/master/ClassificaIO/Supplementary%20Files](https://github.com/gmiaslab/manuals/tree/master/ClassificaIO/Supplementary%20Files)

&amp;#x200B;

&amp;#x200B;

![img](buh80h0jyxu11 ""ClassificaIOs main window as it will appear on your screen"")

![img](p3swoh0jyxu11 ""Illustrative examples using the Iris dataset: (a) Use My Own Training Data window with uploaded training and testing data files, selected logistic regression classifier, populated classifier parameters, and output classification results, (b) Already Trained My Model window with uploaded logistic regression ClassificaIO trained model and testing data file, and output result."")",0,1,False,self,,,,,
1575,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,0,9s4142,self.MachineLearning,"[D] Did anyone actually find out where exactly did Andrew Ng say that ""Enough Papers, Lets Build AI Now!"" sort of opinions in any keynote speech?",https://www.reddit.com/r/MachineLearning/comments/9s4142/d_did_anyone_actually_find_out_where_exactly_did/,Thanatine,1540741037,"I hope this thing is considered relevant in this subreddit.

&amp;#x200B;

Recently, I need to write something more discussion than technique details about AI and I saw [THIS](https://medium.com/syncedreview/andrew-ng-says-enough-papers-lets-build-ai-now-6b52d24bcd58) during my survey.

Then I found the [keynote speech](https://www.youtube.com/watch?v=JsGPh-HOqjY) which the medium post references, but it seems that the quote never appears in the speech.

I knew that Andrew keeps saying that ""AI is the new electricity"" as a metaphor how AI might bring revolution to current industries like electricity did in hundred years ago, and I also knew that Andrew is devoted to this process.

But the quote means totally something else and I could find its origin.

I hope someone here might help me verify the post's quote. Thanks!",26,1,False,self,,,,,
1576,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,0,9s448w,self.MachineLearning,"""Learning Physics with Deep Neural Networks""",https://www.reddit.com/r/MachineLearning/comments/9s448w/learning_physics_with_deep_neural_networks/,Yu_Xuelin,1540741681,"Hi all, the Simons Foundation uploaded a recording of their Foundation Series Lecture ""Learning Physics with Deep Neural Networks,"" that was given October 17, 2018, by Dr. Stphane Mallat (cole Normale Suprieure de Paris) . 

[https://www.simonsfoundation.org/event/learning-physics-with-deep-neural-networks/?fbclid=IwAR0VZYdEygOsMW0bcFNhNuxPSgnILSPYE-PbcD1ooGish0rYSjaMSg6wvYg](https://www.simonsfoundation.org/event/learning-physics-with-deep-neural-networks/?fbclid=IwAR0VZYdEygOsMW0bcFNhNuxPSgnILSPYE-PbcD1ooGish0rYSjaMSg6wvYg)

&amp;#x200B;

Very interesting. Application of deep convolutional networks with wavelets in the setting of physics problems. Application to problems in density functional theory (DFT) is at around 45min; deep CNNs with wavelets seems to be comparable to DFT (in some sense) with relatively little data.

&amp;#x200B;

Related work: [https://arxiv.org/pdf/1601.04920.pdf](https://arxiv.org/pdf/1601.04920.pdf)",0,1,False,self,,,,,
1577,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,1,9s4avz,github.com,"""[P]"" BERT-keras: bert in keras with open ai's pretrained transformer model as initialization",https://www.reddit.com/r/MachineLearning/comments/9s4avz/p_bertkeras_bert_in_keras_with_open_ais/,Separius12,1540743066,,0,1,False,default,,,,,
1578,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,1,9s4cyw,github.com,"[P] Tensorflow Implementation of ""Attention-Based Bi-LSTM for Relation Classification"" (ACL paper)",https://www.reddit.com/r/MachineLearning/comments/9s4cyw/p_tensorflow_implementation_of_attentionbased/,roomylee,1540743492,,0,1,False,default,,,,,
1579,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,1,9s4f50,github.com,[Project] BERT-keras: BERT in keras with OpenAI's pretrained transformer network for weight initialization,https://www.reddit.com/r/MachineLearning/comments/9s4f50/project_bertkeras_bert_in_keras_with_openais/,Separius12,1540743926,,0,1,False,default,,,,,
1580,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,1,9s4kz7,github.com,[P] BERT-keras: BERT in keras with OpenAI's pretrained transformer network for weight initialization,https://www.reddit.com/r/MachineLearning/comments/9s4kz7/p_bertkeras_bert_in_keras_with_openais_pretrained/,Separius12,1540745128,,0,1,False,https://b.thumbs.redditmedia.com/iNCT2KD609Td2iuXQ13nsJJQ0-yVIY3_ojd1LIK1KTA.jpg,,,,,
1581,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,2,9s4yti,medium.com,[P] AI TicTacToe based on random Forest and Decision Tree. Do you know any JS ML libraries?,https://www.reddit.com/r/MachineLearning/comments/9s4yti/p_ai_tictactoe_based_on_random_forest_and/,GiacomoFava,1540747891,,0,1,False,https://b.thumbs.redditmedia.com/YO_w1xsyFmCGGlYbZrXxmB25_Rp0HoX5OoxSMkWSqEI.jpg,,,,,
1582,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,2,9s52w2,self.MachineLearning,"ML, AI bootcamps or 1y long Masters in China?",https://www.reddit.com/r/MachineLearning/comments/9s52w2/ml_ai_bootcamps_or_1y_long_masters_in_china/,erjcan,1540748714,[removed],0,1,False,self,,,,,
1583,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,2,9s54nl,self.MachineLearning,[D] Is UCB with an negative uncertainty weight still legitimate?,https://www.reddit.com/r/MachineLearning/comments/9s54nl/d_is_ucb_with_an_negative_uncertainty_weight/,temporary_idiot_420,1540749095,"Hi guys,  


in reinforcement learning one can use UCB (upper confidence bound) to introduce explorative action choices as opposed to exploitative (greedy) choices.  


An action would be chosen like this: a' = argmax\_a(Q(s, a) + alpha \* U(s, a))  


where a' is the chosen action, s is the state, a is an action, Q(s, a) is the action-value function, alpha is an parameter and U(s, a) is the uncertainty value.  


Usually, for alpha &gt; 0 you would call this ""optimism in the face of uncertainty"" because an action with worse estimated value might be chosen, because there is a lot of uncertainty and the action might turn out to be better than the greedy choice.  


What about alpha &lt; 0 ? I was not able to find anything about that in literature. Would you call this ""pessimism in the face of uncertainty"" ? Does this still count as UCB?  


Sorry for the sloppy notation and hopefully I'm not missing something obvious. Your help is much appreciated!",14,1,False,self,,,,,
1584,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,2,9s5523,self.MachineLearning,[D] Alternatives to AUC/PR-curve when model is trained on log-loss but labels themselves (as well as predictions) are probabilities rather than binary classes?,https://www.reddit.com/r/MachineLearning/comments/9s5523/d_alternatives_to_aucprcurve_when_model_is/,kebabmybob,1540749184,"It makes sense for me to train using log-loss/cross-entropy as my loss function but I could not find much information in the literature on good eval functions or metrics to interpret the overfitting here. 

I can use cross-entropy for both eval and loss but I am having a hard time really interpreting it.",9,1,False,self,,,,,
1585,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,3,9s5nqb,colab.research.google.com,Privacy-preserving AI 101,https://www.reddit.com/r/MachineLearning/comments/9s5nqb/privacypreserving_ai_101/,Acuratio,1540752926,,1,1,False,default,,,,,
1586,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,3,9s5omc,deepideas.net,Building a Content-Based Search Engine: Efficient Query Processing,https://www.reddit.com/r/MachineLearning/comments/9s5omc/building_a_contentbased_search_engine_efficient/,deepideas,1540753104,,0,1,False,https://b.thumbs.redditmedia.com/rzobj65b6fwxlQAe42DbEoVp_VFESELPvCHpdrYgKZU.jpg,,,,,
1587,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,4,9s5z0x,self.MachineLearning,Chroma Subsampling,https://www.reddit.com/r/MachineLearning/comments/9s5z0x/chroma_subsampling/,CaveDoctor,1540755167,"I'm new to machine learning but I have a fascination with it.  
I wonder if there is a way to reconstruct information lost in chroma subsampling, using methods that fall into one of two categories, Super Resolution or Machine Learning.  
My goal with this idea is not to recreate what was lost, as that would be impossible, but to improve the quality of video shot on cameras that only capture material at the resolution of 1080p.  
Is this concept viable?",0,1,False,self,,,,,
1588,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,5,9s6nfh,arxiv.org,[R] Mean Field Residual Networks: On the Edge of Chaos,https://www.reddit.com/r/MachineLearning/comments/9s6nfh/r_mean_field_residual_networks_on_the_edge_of/,jinpanZe,1540760072,,0,1,False,default,,,,,
1589,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,5,9s6oq0,self.MachineLearning,Are approximation techniques like negative subsampling still used to train word vectors?,https://www.reddit.com/r/MachineLearning/comments/9s6oq0/are_approximation_techniques_like_negative/,etmhpe,1540760351,[removed],0,1,False,self,,,,,
1590,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,6,9s6rqp,self.MachineLearning,[D] Best YouTube playlist for Statistics?,https://www.reddit.com/r/MachineLearning/comments/9s6rqp/d_best_youtube_playlist_for_statistics/,AKoreanEngima,1540760954,"Hey guys, I'm trying to refresh my statistics knowledge and looking for a good youtube playlist with statistics. Anybody got recommendations?",5,1,False,self,,,,,
1591,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,6,9s72ur,self.MachineLearning,[D] Restricted (use of) data how does it restrict the use of the model?,https://www.reddit.com/r/MachineLearning/comments/9s72ur/d_restricted_use_of_data_how_does_it_restrict_the/,da_g_prof,1540763215,"Suppose that a dataset (images and ground truth) is limited to non commercial use but free academic use. 

Case 1. However, a company used them to train a model and is reselling the model?
They are not reselling the data, just the model. Are they violating the terms?

Case 2. Now suppose that a university academic lab is using the same data to train a model, but they license the model to a company for commercial use. Do they (the university) violate the terms?

What are your thoughts?
",15,1,False,self,,,,,
1592,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,8,9s843u,self.MachineLearning,Is Jenks algorithm a Machine Learning algorithm?,https://www.reddit.com/r/MachineLearning/comments/9s843u/is_jenks_algorithm_a_machine_learning_algorithm/,amahmood1,1540771138,Can we call Jenks algorithm a Machine Learning algorithm ?,0,1,False,self,,,,,
1593,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,10,9s8tgs,self.MachineLearning,Kernels on polynomials/featurizing polynomials?,https://www.reddit.com/r/MachineLearning/comments/9s8tgs/kernels_on_polynomialsfeaturizing_polynomials/,bckmpa,1540776769,[removed],0,1,False,self,,,,,
1594,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,10,9s8xs3,self.MachineLearning,Chat bot backend,https://www.reddit.com/r/MachineLearning/comments/9s8xs3/chat_bot_backend/,Zman98789,1540777749,i want to create a chat bot but i want it to be able to learn while talking to someone (you would not have to make a new session to make the A.I. learn) are their any back ends for that in python?,0,1,False,self,,,,,
1595,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,11,9s9dj0,self.MachineLearning,"Is it worth reading books like Bishop, Kevin Murphy, Koller &amp; Friedman for a new PhD student in Machine learning",https://www.reddit.com/r/MachineLearning/comments/9s9dj0/is_it_worth_reading_books_like_bishop_kevin/,hmi2015,1540781491,[removed],0,1,False,self,,,,,
1596,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,11,9s9el5,self.MachineLearning,[D] Machine Learning - WAYR (What Are You Reading) - Week 51,https://www.reddit.com/r/MachineLearning/comments/9s9el5/d_machine_learning_wayr_what_are_you_reading_week/,ML_WAYR_bot,1540781746,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|31-40|41-50|
|----|-----|-----|-----|-----|
|[Week 1](https://www.reddit.com/4qyjiq)|[Week 11](https://www.reddit.com/57xw56)|[Week 21](https://www.reddit.com/60ildf)|[Week 31](https://www.reddit.com/6s0k1u)|[Week 41](https://www.reddit.com/7tn2ax)|||
|[Week 2](https://www.reddit.com/4s2xqm)|[Week 12](https://www.reddit.com/5acb1t)|[Week 22](https://www.reddit.com/64jwde)|[Week 32](https://www.reddit.com/72ab5y)|[Week 42](https://www.reddit.com/7wvjfk)||
|[Week 3](https://www.reddit.com/4t7mqm)|[Week 13](https://www.reddit.com/5cwfb6)|[Week 23](https://www.reddit.com/674331)|[Week 33](https://www.reddit.com/75405d)|[Week 43](https://www.reddit.com/807ex4)||
|[Week 4](https://www.reddit.com/4ub2kw)|[Week 14](https://www.reddit.com/5fc5mh)|[Week 24](https://www.reddit.com/68hhhb)|[Week 34](https://www.reddit.com/782js9)|[Week 44](https://reddit.com/8aluhs)||
|[Week 5](https://www.reddit.com/4xomf7)|[Week 15](https://www.reddit.com/5hy4ur)|[Week 25](https://www.reddit.com/69teiz)|[Week 35](https://www.reddit.com/7b0av0)|[Week 45](https://reddit.com/8tnnez)||
|[Week 6](https://www.reddit.com/4zcyvk)|[Week 16](https://www.reddit.com/5kd6vd)|[Week 26](https://www.reddit.com/6d7nb1)|[Week 36](https://www.reddit.com/7e3fx6)|[Week 46](https://reddit.com/8x48oj)||
|[Week 7](https://www.reddit.com/52t6mo)|[Week 17](https://www.reddit.com/5ob7dx)|[Week 27](https://www.reddit.com/6gngwc)|[Week 37](https://www.reddit.com/7hcc2c)|[Week 47](https://reddit.com/910jmh)||
|[Week 8](https://www.reddit.com/53heol)|[Week 18](https://www.reddit.com/5r14yd)|[Week 28](https://www.reddit.com/6jgdva)|[Week 38](https://www.reddit.com/7kgcqr)|[Week 48](https://reddit.com/94up0g)||
|[Week 9](https://www.reddit.com/54kvsu)|[Week 19](https://www.reddit.com/5tt9cz)|[Week 29](https://www.reddit.com/6m9l1v)|[Week 39](https://www.reddit.com/7nayri)|[Week 49](https://reddit.com/98n2rt)||
|[Week 10](https://www.reddit.com/56s2oa)|[Week 20](https://www.reddit.com/5wh2wb)|[Week 30](https://www.reddit.com/6p3ha7)|[Week 40](https://www.reddit.com/7qel9p)|[Week 50](https://reddit.com/9cf158)||

Most upvoted papers two weeks ago:

/u/Gimagon: [A Unifying Review of Linear Gaussian Models](http://mlg.eng.cam.ac.uk/zoubin/papers/lds.pdf)

/u/ndha1995: [Deep Neuroevolution: Genetic Algorithms Are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning](https://arxiv.org/abs/1712.06567)

/u/kaushal28: https://mpatacchiola.github.io/blog/2017/01/15/dissecting-reinforcement-learning-2.html

Besides that, there are no rules, have fun.",51,1,False,self,,,,,
1597,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,12,9s9r1t,stats.stackexchange.com,Is it true that normalizing the output of a ReLu feedforward Neural Network that it's Radamacher Complexity becomes a constant?,https://www.reddit.com/r/MachineLearning/comments/9s9r1t/is_it_true_that_normalizing_the_output_of_a_relu/,real_pinocchio,1540784715,,0,1,False,https://b.thumbs.redditmedia.com/u-SEj4BdPt33XpBWtrqXwltqvbCXxl-145xBFCwMIpc.jpg,,,,,
1598,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,13,9sa0uk,self.MachineLearning,[D] Accounting for Randomness in NN optimization and Determining Significance (in comparison to other reported results) for Public Test Set Evaluation,https://www.reddit.com/r/MachineLearning/comments/9sa0uk/d_accounting_for_randomness_in_nn_optimization/,newperson77777777,1540787235,"Hi, I was wondering if an appropriate way to account for randomness in NN optimization is to evaluate the network with several random seeds (like 10) on a public test set and then produce the average and confidence intervals based on the results.

&amp;#x200B;

Also, I'm having a hard time trying to figure out how to determine if my model's test set results are statistically significant in comparison to other reported results. How would you do this? Especially if the reported results are based on a single random seed or the maximum over several random seeds (or even the average over a certain number of random seeds, though I've never seen this done before).",8,1,False,self,,,,,
1599,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,13,9sa40k,self.MachineLearning,Dynamic Programming in RL simplified,https://www.reddit.com/r/MachineLearning/comments/9sa40k/dynamic_programming_in_rl_simplified/,vector_machines,1540788083,[https://youtu.be/fAGgZrGZRsc](https://youtu.be/fAGgZrGZRsc) ,0,1,False,self,,,,,
1600,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,13,9sa5wl,self.MachineLearning,Please help me on trigger/wake word detection problem.,https://www.reddit.com/r/MachineLearning/comments/9sa5wl/please_help_me_on_triggerwake_word_detection/,Mohansrk123,1540788642,[removed],0,1,False,self,,,,,
1601,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,14,9sag40,self.MachineLearning,Machine Learning is the New Literacy For Business Enterprises and Leadership,https://www.reddit.com/r/MachineLearning/comments/9sag40/machine_learning_is_the_new_literacy_for_business/,judemohanty,1540791614,[removed],0,1,False,self,,,,,
1602,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,14,9sagv7,self.MachineLearning,Artificial Intelligence is a solution without a problem.,https://www.reddit.com/r/MachineLearning/comments/9sagv7/artificial_intelligence_is_a_solution_without_a/,VerbotenPublish,1540791858,[removed],0,1,False,self,,,,,
1603,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,14,9saiu3,newscenter.lbl.gov,Machine Learning to Help Optimize Traffic and Reduce Pollution,https://www.reddit.com/r/MachineLearning/comments/9saiu3/machine_learning_to_help_optimize_traffic_and/,KiranKiller,1540792474,,0,1,False,https://b.thumbs.redditmedia.com/luGsNTYm2Mx1-Tv_9Vc14ST9wRdTnXoZ1Z48oGTdM6k.jpg,,,,,
1604,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,15,9saljb,reddit.com,The trending hot topics in artificial intelligence | AI research topics and Solutions,https://www.reddit.com/r/MachineLearning/comments/9saljb/the_trending_hot_topics_in_artificial/,Kedjja,1540793332,,0,1,False,default,,,,,
1605,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,15,9saniq,self.MachineLearning,[D] Artificial Intelligence is a solution without a problem.,https://www.reddit.com/r/MachineLearning/comments/9saniq/d_artificial_intelligence_is_a_solution_without_a/,VerbotenPublish,1540793960," *A fantasy of automatic production in a world where only automatic manufacturing is possible.*  Perpetual motion machines aren't real.

When businesses and computer scientists talk about AI they are really talking about a machine that produceswithout the cost.

&gt;The first law of thermodynamics, also known as Law of Conservation of **Energy**, states that **energy can neither be created nor destroyed**; **energy can** only be transferred or changed from one form to another.

Perpetual  motion violates this law. Production must be paid for. The results must  have a value greater than the cost while still reconciling the energy  involved in all the moving parts to be profitable. Capitalist production  doesnt violate this principle because capitalizing on capacity and  opportunity is the transfer from one form to another more useful.

It  must be creatively repeated to overcome the law of diminishing returns.  Its a process where energy is applied intelligently such that the  consequences form a potentiality for other valuable consequences not  accessible before the capitalization. Its easy to imagine a machine  doing this; like its easy to imagine a million monkeys at a million  type writers, but in reality it doesnt work.

Only  life can produce intelligently, and rarely at that. Restrained by, if  nothing else, food energy and biological considerations such as  environmental challenge and competition. We are machines and our  production is good when balanced and self defeating when not. It  requires unique experiences; not just facts and memory replications. Not  just time; but the patina of its passage.

Give  a person all the facts of a situation and theyll never produce  anything of value compared to the product of those who have actually  lived and experienced those facts. Data alone cannot separate the wheat  from the chaff. There are copies of us, twins, and we watch them become  entirely different people. Different interests and different outcomes  and it only diverges further over time. This is the inner production  that is life itself.

***Dont be so quick to open Pandoras box.***

Life  is the closest thing to a perpetual motion machine there is. Elevate  the biological potential and forget about all these silly experts  trying to seduce you into investing in something that isnt possible.  Perpetual motion doesnt exist; Automatic Production is a form of  perpetual motion. AI is a form of Automatic Production. Therefore, it  doesnt exist.

Why  is AI really Automatic Production? The answer is in the nature of  intelligence and its desirable ability to improve profitable returns.  For example a writer is a producer only when theyve written something  of greater value than the cost of writing it. A good writer lives and  experiences the extraordinary and captures that in a book.

There  is a cost to living and experiencing; and its only productive if the  result is worth while. We dont always get what we want. Thats the risk  and with itthe possible reward. No guarantees even for the previously  successful. The mighty fall all the time. There is no best formula for  success.

There  is no policy that ensures profit. Sometimes the greatest achievements  have been accidents or out right mistakesor motivated by lies or  misunderstandings. The best things that will come out of chasing AI is  faster computers and better video games. But at what cost? Could we not  have had better machines without wasting billions of dollars on  bullshit?

As  it is the prior investment in AI has ballooned so high that its almost  inconceivable that well dig out from the hole. An AI acting all  artificial and intelligent will have a further run-time cost as  everything does. Its processes will consume opportunity if nothing  else. Even a computer on a solar panel consumes opportunity. Making  something of greater value than the opportunity cost is the problem that  biology is solving very well if slowly.

***The basic idea that makes AI valuable in any form, the necessary ingredient that matters is***

Can  the program do, without any of the biological costs like growing up,  taking time to experience and gain wisdom, what a real producer can do  naturally? No. Duplication of past work to extract production value is  what manufacturing is all about. Its the mechanics. Energy in motion.  It doesnt create the value.

Manufacturing  isnt the transfer from one form to another more valuable form. It  isnt the conversion of a good idea into a working solution, but rather  the process of collecting the return on the original idea produced. Its  something less; and AI is something less than I.

If  any machine could write a book worth reading, a song worth hearing, a  product worth sellingthen it would kill all life on earth and beyond.  Just like infinite free energy, or immortality, or my personal favourite  an excise tax set at 100%.

Just  like every other kind of perpetual motion machine. It would break the  game, the entire universe in fact. Like the infinite lives cheat in  Super Contra we soon lose interest in playing. The moment one such  machine comes into existence it would inevitably consume the entirety of  reality by producing too much in a way that interferes with the  production of others. Everything, including itself, would ultimately  choke and die. Like cancer it would grow without purpose until there is  nowhere else to go.

Life  is restrained by food energy and timemortality; thus driven to produce  rational solutions to real problems like survival and reproduction. All  around us every day are genuine producers making dreams into reality.  But they cant do this beyond the ecosystem that accepts it. Gluttony is  no better than starvation. Production is a partnership between the  objective and the subjective that solves a problem. To a computer  program all problems are artificial. No skin in the gameno skin at all.

The  best well ever do is Automatic Manufacturing so get used to it and  invest accordingly. Celebrate input costs in time and material; costs  your competitors will also have to endure. Buy a factory. Give your  machine a purpose and let it fulfill that without going beyond so it  doesnt rob future value we cant make use of yet. It copies the design  and builds, prints, compiles, and processes.

**BUT IT DOES NOT PRODUCE.**

It  does not invent; createor reason. Thought is production based on a  million and one different factors including the benefits of limits and  purpose. Billions of years of universal evolution and far from  automatic. By definition original and the difference between sane and  insane is the value of our thoughts in there potential to lead us  through a productive life.

AI  is like a writer producing the great American novel after reading the  encyclopedia. A long time ago I read a great quote in a Superman comic  that sums it up well I think.

&gt;Some  people look at the ingredients on a bubble gum wrapper and they see the  ingredients on a bubble gum wrapper; while others see the secrets of  the Universe.LexLuthor

What do you think AI would learn from that pack of gum? At bestit figures out how to make more gum.",12,1,False,self,,,,,
1606,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,15,9saqms,self.MachineLearning,[P] BERT-keras: BERT in keras with OpenAI's pretrained transformer network for weight initialization,https://www.reddit.com/r/MachineLearning/comments/9saqms/p_bertkeras_bert_in_keras_with_openais_pretrained/,Separius12,1540794979,[https://github.com/Separius/BERT-keras](https://github.com/Separius/BERT-keras),0,1,False,self,,,,,
1607,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,15,9sauh2,self.MachineLearning,"[Discussion] Not able to reproduce the results reported in the paper which won the ""Best Paper Award in Cognitive Robotics"" at ICRA'18",https://www.reddit.com/r/MachineLearning/comments/9sauh2/discussion_not_able_to_reproduce_the_results/,1234pk9,1540796258,"The paper titled as ""**Social Attention: Modeling Attention in Human Crowds**"" \[[https://arxiv.org/abs/1710.04689](https://arxiv.org/abs/1710.04689)\] is not reproducible even with the codes written by the authors. Link to code: [https://github.com/vvanirudh/srnn-pytorch](https://github.com/vvanirudh/srnn-pytorch)

&amp;#x200B;

A bug was reported when the paper was under submission I guess. [https://github.com/vvanirudh/srnn-pytorch/issues/2](https://github.com/vvanirudh/srnn-pytorch/issues/2)

The author fixed the code and closed the issue. That makes the results even more worse. But still the results are not reproducible. There have been numerous complains regarding this paper which I have listed below.  But this paper has won the ""Best Paper Award in Cognitive Robotics"". Really? 

&amp;#x200B;

1. [https://github.com/vvanirudh/srnn-pytorch/issues/4](https://github.com/vvanirudh/srnn-pytorch/issues/4)
2. [https://github.com/vvanirudh/srnn-pytorch/issues/8](https://github.com/vvanirudh/srnn-pytorch/issues/8)
3. [https://github.com/vvanirudh/social-lstm-tf/issues/26](https://github.com/vvanirudh/social-lstm-tf/issues/26)

&amp;#x200B;

Should not this paper be retracted?

&amp;#x200B;

&amp;#x200B;",25,1,False,self,,,,,
1608,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,18,9sbhf4,self.MachineLearning,[D] Legal action against this subreddit (and de-anonymizing people opposed to name change),https://www.reddit.com/r/MachineLearning/comments/9sbhf4/d_legal_action_against_this_subreddit_and/,sorry_babby,1540804355,"r/https://twitter.com/AnimaAnandkumar/status/1056674982955122689

&amp;#x200B;

\&gt; @mxlearn You cannot let cowards hide their identity and bully and threaten women. The same happened with #pittsburghshootings Online hatred was allowed to thrive. You need to pull down garbage collecting in [http://dlvr.it/QpQ5dy](http://dlvr.it/QpQ5dy) [http://dlvr.it/QpdzXh](http://dlvr.it/QpdzXh) or my lawyers will do it

&amp;#x200B;

Those shortened links (may be tracked) link to the discussions on this Reddit about the name change. Some of my comments here were reposted on Twitter and construed as ""anonymous coward"" and ""attacking/threatening women"". Those opposed to a name change (including members of the NIPS board) are equated with sexists and shooting spree killers. In such a climate it is impossible to safely give your opinion under your real name, let alone make a clear-headed decision.

&amp;#x200B;

Remember that posting here, even anonymously, can lead to social, financial, and now legal nightmares. Beware the thought police and stay safe.",5,1,False,self,,,,,
1609,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,18,9sbk2t,medium.com,"[N] NLP-Overview, Facebooks XNLI, ShaRC, AutoAugment, pair2vec, Iterated Amplification,",https://www.reddit.com/r/MachineLearning/comments/9sbk2t/n_nlpoverview_facebooks_xnli_sharc_autoaugment/,omarsar,1540805254,,0,1,False,default,,,,,
1610,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,18,9sbm5o,self.MachineLearning,[D] How do I get KFAC to work with plastic RNNs?,https://www.reddit.com/r/MachineLearning/comments/9sbm5o/d_how_do_i_get_kfac_to_work_with_plastic_rnns/,abstractcontrol,1540805890,"[KFAC](https://arxiv.org/abs/1503.05671) works great for me in RL and in supervised learning with both feedforward and recurrent nets. On the RL game I am testing it on in fact it works so great that I would not dare try doing it without a higher order optimizer. For that reason if I had drop one of the plastic RNNs and KFAC I'd drop the plastic RNNs, but I'd prefer to use both.

That having said, it just works so poorly when it comes to optimizing the plastic RNN on the Binary Pattern test and essentially has none of the invariance to parameterization one would expect from a NG method.

I've managed to figure out a few things about the [plastic RNNs](https://arxiv.org/abs/1804.02464) during my playtime with them. The paper makes a big deal about the plasticity coefficients `alpha`, but even without them on the Binary Pattern it turns out if you let the recurrent connections be plastic and repeatedly feed it the same input plus add it to the output it gets over 99% without training (and any parameters.) This is actually significantly better than one would get by training the net - in fact random initializations tend to make things a lot worse.

I am guessing that this auto-associative memory effect would also work for the Image Recontruction task and possibly the Omniglot. I thought I'd just mention it somewhere since I am not in the business of writing papers and this might be a novel discovery about Hebbian learning. At least it certainly was not obvious to me that repeatedly feeding the same input to the recurrent plastic RNN would lead to it trying to reconstruct the inputs without any special effort - I'd have guessed that the network would be needed to be trained for that first.

Now that is all fine and good, but for a realistic use of plastic RNNs one would want modulation of both the weight updates and the plasticity coefficients. When I left the first as a hyperparameter and I tried optimizing just the later I've found that SGD pretty much crushed KFAC at what turned out to be learning the identity.

When it comes to optimizing only the weight update coefficients using a variant of the Oja's rule the picture is more mixed though still quite bad. Here is how the weight update looks like in Spiral code:

    inm theta = (to float 0.0001) * theta
    H + theta * input * out - abs theta * out * out * H

To prevent an instant blowup, I had to multiply `theta` by a small constant such as 0.0001 otherwise the gradients flowing into it would blow up the network. With this multiplier SGD does not budge from its initial value, and to make KFAC do anything I've had to hike the learning rate to extreme values and mess with the learning rates for the covariance matrices.

A second order method would make this unecessary. In fact, my brilliant plan was to use the semi-second order KFAC to stabilize the plastic RNNs and use it for RL tasks, but as they are right now the plastic RNNs are barely usable and would just be a liability. I was fooled by their great performance on associative memory tasks; SGD is not at all capable of optimizing them.

With the prelude out of the way here are the questions.

* Why does KFAC not work with plastic RNNs?
* Is KFAC not supposed to be model agnostic?
* Is there a way of making it work with plastic RNNs? There are some optimization schemes similar to KFAC like the [Zap](https://arxiv.org/abs/1707.03770) algorithm, but I have no reason to try that one. I could also try centering the gradients and the inputs, but those are just random things that I have no reason to expect would make things work.
* Though unlikely, maybe the square error is making things worse and I should replace it with a probabilistic interpretation of squared error (with multiple classifiers). What sort of cost function would be appropriate for that? I've tried the sigmoid cross entropy, but that did not make any difference.
* Are there any alternative to KFAC I could try? [KFGN](https://arxiv.org/abs/1706.03662) comes to mind, but I would not know how to adapt that for plastic RNNs. [CurveBall](https://arxiv.org/abs/1805.08095) would be another option though that one does not do as well in general compared to block diagonal approximations and would require me to add higher order differentiation to the library I am using. KFAC is great in that it only requires me to understand how to keep track and invert covariance matrices which is a much smaller implementation effort.",2,1,False,self,,,,,
1611,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,19,9sbtun,self.MachineLearning,Machine Learning: The New Language of Leadership,https://www.reddit.com/r/MachineLearning/comments/9sbtun/machine_learning_the_new_language_of_leadership/,jm851100,1540808249,"In the hype of new technology artificial intelligence (AI) It is easy to get caught up, as the promise of this technology relatively credited with saving everything from our health to our work life and even our planet. In different ways, we are still a long way off from achieving these promises.

A more profound and perhaps even more impact immediate of AI can be found within the enterprise, via the application of machine learning and aggregation of big data. Machine learning is a subset of the broader AI field which is the area of AI most likely to provide direct and tangible benefits to an organization for the foreseeable future.

Most important that executives today can articulate the high-level benefits of AI and machine learning, as they are becoming key components of business strategies and service offerings. The most important question is that -Is it will prove to have the greatest impact on business and leadership success. Is whether we understand the deeper promise and limitations of AI in a particular field. 

For years, weve taught up-and-coming leaders that programming is the new literacy., We are rapidly moving beyond the time where simple functional programming is sufficient to enable the next generation of business capabilities. The machine learning is our new literacy that will define and shape businesses and industries at large, perhaps in even more profound ways than the internet did.

&amp;#x200B;

[Picture Courtesy-Scrabbl](https://i.redd.it/3ey498deo3v11.jpg)

**Few Business Benefits of Machine Learning**

**Customer Lifetime Value Prediction**

The major challenges faced by the marketers today is Customer lifetime value prediction and customer segmentation are some of. Many companies have access to huge amount of data, which can be effectively used to derive meaningful business insights. Data mining and Machine Learning can help businesses predict customer behaviours, purchasing patterns, and help in sending best possible offers to individual customers, based on their browsing and purchase histories.

**Predictive Maintenance**

Manufacturing firms regularly follow corrective and preventive maintenance practices, which are often inefficient and expensive. However, with the advent of Machine Learning, companies in this sector can make use of ML to discover meaningful insights and patterns hidden in their factory data. This is termed as predictive maintenance and it helps in reducing the risks associated with unexpected failures and eliminates unnecessary expenses. Its architecture can be built using historical data, workflow visualization tool, flexible analysis environment, and the feedback loop.

**Eliminates Manual Data Entry**

One of the biggest problems faced by the businesses today is duplicate and inaccurate data that are some of Predictive modeling algorithms and ML can significantly avoid any errors caused by manual data entry. So, machine Learning programs make these processes better by using the discovered data. Hence, the employees can utilize the same time for carrying out tasks that add value to the business.

**Detecting Spam**

ML in detecting spam has been in use for quite some time. Email service providers made use of pre-existing or rule-based techniques to filter out spam. Hence, the spam filters are now creating new rules by using neural networks detect spam and phishing messages.

**Product Recommendations**

Unsupervised learning helps in developing product-based recommendation systems. Some of the E-commerce websites today are making use of machine learning for making product recommendations. Here, the ML algorithms use customer's purchase history and match it with the large product inventory to identify hidden group and patterns similar products together. So, these products are then suggested to customers, thereby motivating product purchase.

**Financial Analysis**

Using large volumes of accurate and quantitative historical data, ML can now be used in financial analysis. It is already being used in finance for portfolio management, algorithmic trading, fraud detection and loan underwriting. Therefore, future applications of ML in finance will include Chatbots and other conversational interfaces for security, customer service, and sentiment analysis.",0,1,False,self,,,,,
1612,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,19,9sbxid,self.sql-datatools,Azure Data Studio Tool in SQL Server 2019,https://www.reddit.com/r/MachineLearning/comments/9sbxid/azure_data_studio_tool_in_sql_server_2019/,sql-datatools,1540809363,,0,1,False,default,,,,,
1613,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,20,9sc6pz,self.MachineLearning,What method/approach to use to analysing Taxi Location data?,https://www.reddit.com/r/MachineLearning/comments/9sc6pz/what_methodapproach_to_use_to_analysing_taxi/,Imakesensealot,1540811972,[removed],0,1,False,self,,,,,
1614,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,20,9scd1m,self.MachineLearning,[D] SVD just as good as word2vec. Where to find the former?,https://www.reddit.com/r/MachineLearning/comments/9scd1m/d_svd_just_as_good_as_word2vec_where_to_find_the/,anonDogeLover,1540813744,"Levy et al. (2015) showed that LSA/SVD was just as good as word2vec/GloVe given the right hyperparameters. 

Does anyone know where to find pretrained LSA embeddings? 

It's been around so long, it should be a standard baseline, but I can't find embeddings anywhere.",4,1,False,self,,,,,
1615,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,20,9scf5r,celadon.ae,Mobile trends to look for in 2019,https://www.reddit.com/r/MachineLearning/comments/9scf5r/mobile_trends_to_look_for_in_2019/,Apprehensive_Intern,1540814282,,0,1,False,https://b.thumbs.redditmedia.com/vq_dy6CCUCftuJgRr720hH0P5LvdmBqhi39ZpnH8h1U.jpg,,,,,
1616,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,21,9scjnl,youtube.com,JSGuru Talk IT - Why Your Business Needs a Progressive Web App,https://www.reddit.com/r/MachineLearning/comments/9scjnl/jsguru_talk_it_why_your_business_needs_a/,Sine_Nomine_djm,1540815377,,0,1,False,https://b.thumbs.redditmedia.com/kD80SE39nkmJYgEH3_st_VFIpipSNqubT3mThaNu4NE.jpg,,,,,
1617,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,21,9scnjh,self.MachineLearning,[R] An Imagenet-like dataset of reddit selfposts : classify text into over 1000 curated subreddits,https://www.reddit.com/r/MachineLearning/comments/9scnjh/r_an_imagenetlike_dataset_of_reddit_selfposts/,mike_sj,1540816329,"\[This post is to announce a new dataset for text classification\]([https://www.evolution.ai/blog/page/5/an-imagenet-like-text-classification-task-based-on-reddit-posts/](https://www.evolution.ai/blog/page/5/an-imagenet-like-text-classification-task-based-on-reddit-posts/)) - many classes, many example per class. The goal is to classify self-posts into a curated set of subreddits, carefully selected to reduce overlap. Enjoy!

&amp;#x200B;

\[Kaggle link\]([https://www.kaggle.com/mswarbrickjones/reddit-selfposts/home](https://www.kaggle.com/mswarbrickjones/reddit-selfposts/home))

&amp;#x200B;

\[Link to a pretty rough draft of a paper\]([https://www.evolution.ai/blog\_figures/reddit\_dataset/rspct\_preprint\_v3.pdf](https://www.evolution.ai/blog_figures/reddit_dataset/rspct_preprint_v3.pdf)) I'm planning to submit about this.",0,1,False,self,,,,,
1618,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,21,9scpfl,allclearweather.com,"[P] Update on using photos of the sky for weather forecasting data: 50 tagged photos collected (need 5,000? for training dataset), recent work to increase the tagging accuracy, and a new website for the project. Thanks for your feedback so far!",https://www.reddit.com/r/MachineLearning/comments/9scpfl/p_update_on_using_photos_of_the_sky_for_weather/,cryptoz,1540816767,,0,1,False,default,,,,,
1619,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,21,9scqvq,blog.qure.ai,[P] Challenges of Development &amp; Validation of Deep Learning for Radiology,https://www.reddit.com/r/MachineLearning/comments/9scqvq/p_challenges_of_development_validation_of_deep/,saucysassy,1540817114,,0,1,False,https://b.thumbs.redditmedia.com/A7BgUyCbIU5eilgT4dTJxpHeJoHYsaonRNmTRC1Nhoo.jpg,,,,,
1620,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,21,9scrox,arxiv.org,Recent Advances in Object Detection in the Age of Deep Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/9scrox/recent_advances_in_object_detection_in_the_age_of/,gnavihs,1540817305,,1,1,False,default,,,,,
1621,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,21,9scsjn,self.MachineLearning,What are the various problems that need prediction?,https://www.reddit.com/r/MachineLearning/comments/9scsjn/what_are_the_various_problems_that_need_prediction/,cloudrobo,1540817513,[removed],0,1,False,self,,,,,
1622,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,22,9scwk4,self.MachineLearning,New to Machine learning,https://www.reddit.com/r/MachineLearning/comments/9scwk4/new_to_machine_learning/,vrp2004,1540818383,I want to know basic about machine learning. And can anyone give me example of applications with machine learning,0,1,False,self,,,,,
1623,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,22,9scxf7,blog.qure.ai,[P] Challenges of Development &amp; Validation of Deep Learning for Radiology,https://www.reddit.com/r/MachineLearning/comments/9scxf7/p_challenges_of_development_validation_of_deep/,black_7_white,1540818561,,0,1,False,https://b.thumbs.redditmedia.com/A7BgUyCbIU5eilgT4dTJxpHeJoHYsaonRNmTRC1Nhoo.jpg,,,,,
1624,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,22,9sd48t,arxiv.org,[D] Recent Advances in Object Detection in the Age of Deep Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/9sd48t/d_recent_advances_in_object_detection_in_the_age/,gnavihs,1540819978,,1,1,False,default,,,,,
1625,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,22,9sd95v,arxiv.org,[R] Recent Advances in Object Detection in the Age of Deep Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/9sd95v/r_recent_advances_in_object_detection_in_the_age/,gnavihs,1540821068,,5,1,False,default,,,,,
1626,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,23,9sdchq,medium.com,"[N] Machine Learning Generated Artwork Auctions Off for $ 432,500",https://www.reddit.com/r/MachineLearning/comments/9sdchq/n_machine_learning_generated_artwork_auctions_off/,leonkohler,1540821752,,0,1,False,default,,,,,
1627,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,23,9sdgvp,self.MachineLearning,"[N] Machine Learning Generated Artwork Auctions Off for $ 432,500",https://www.reddit.com/r/MachineLearning/comments/9sdgvp/n_machine_learning_generated_artwork_auctions_off/,leonkohler,1540822632,"I have always thought the public's opinion of ML is on the opposite spectrum of creativity. 

Genuinely surprised to see such [overwhelming reception](https://medium.com/datadriveninvestor/machine-learning-generated-artwork-auctions-off-for-432-500-c377be74146f) for a ML generated painting.

Can ML really have a place in creative arts or is this just a ""in the moment"" hype?",15,1,False,self,,,,,
1628,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,23,9sdmjq,theregister.co.uk,[N] Top AI conference NIPS won't change its name amid growing protest over 'bad taste' acronym,https://www.reddit.com/r/MachineLearning/comments/9sdmjq/n_top_ai_conference_nips_wont_change_its_name/,kirasolo,1540823759,,0,1,False,https://a.thumbs.redditmedia.com/pfxvzetIL9q4t9GIJtqJNOGEArWwLhLO3_SHMqf0TR0.jpg,,,,,
1629,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,23,9sdmni,self.MachineLearning,Made-up Halloween-themed paper title thread,https://www.reddit.com/r/MachineLearning/comments/9sdmni/madeup_halloweenthemed_paper_title_thread/,chris2point0,1540823777,[removed],0,1,False,self,,,,,
1630,MachineLearning,t5_2r3gv,2018-10-29,2018,10,29,23,9sdqx9,youtu.be,[P] Dynamic Programming in RL simplified,https://www.reddit.com/r/MachineLearning/comments/9sdqx9/p_dynamic_programming_in_rl_simplified/,vector_machines,1540824637,,0,1,False,https://a.thumbs.redditmedia.com/76FB3saaOfD5upN6bwr4QwLmGRdk9AonQBZmc79M890.jpg,,,,,
1631,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,0,9sdvus,self.MachineLearning,Where can i take the first steps at ML ?,https://www.reddit.com/r/MachineLearning/comments/9sdvus/where_can_i_take_the_first_steps_at_ml/,botclimber,1540825579,[removed],0,1,False,self,,,,,
1632,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,0,9se023,self.MachineLearning,What is your reaction to your idea not working?,https://www.reddit.com/r/MachineLearning/comments/9se023/what_is_your_reaction_to_your_idea_not_working/,T_hank,1540826400,[removed],0,1,False,self,,,,,
1633,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,0,9se73r,crate.io,"Machine Learning and CrateDB, Part One",https://www.reddit.com/r/MachineLearning/comments/9se73r/machine_learning_and_cratedb_part_one/,nslater,1540827770,,0,1,False,default,,,,,
1634,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,0,9se7lc,self.MachineLearning,[P] An Imagenet-like dataset of reddit selfposts : classify text into over 1000 curated subreddits,https://www.reddit.com/r/MachineLearning/comments/9se7lc/p_an_imagenetlike_dataset_of_reddit_selfposts/,mike_sj,1540827868,"[This is an announcement of a new dataset for text classification.](https://www.kaggle.com/mswarbrickjones/reddit-selfposts/home) The goal is to classify reddit self-posts into a curated set of subreddits, selected to reduce overlap --- many classes, many examples per class.

[See a writeup here.](https://www.evolution.ai/blog/page/5/an-imagenet-like-text-classification-task-based-on-reddit-posts/). 

[Link to a pretty rough draft of a paper.](https://www.evolution.ai/blog_figures/reddit_dataset/rspct_preprint_v3.pdf)
",0,1,False,self,,,,,
1635,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,0,9sebqu,self.MachineLearning,[R] Challenges of Development &amp; Validation of Deep Learning for Radiology,https://www.reddit.com/r/MachineLearning/comments/9sebqu/r_challenges_of_development_validation_of_deep/,saucysassy,1540828646,"There has been a slew of research for applying deep learning in radiology. Here's a blog post which details the challenges of applying DL to radiology:
http://blog.qure.ai/notes/deep-learning-radiology-challenges

The described challenges are fairly general and should be applicable to any research involving AI and radiology images.",2,1,False,self,,,,,
1636,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,1,9sefue,self.MachineLearning,Awesome Unsupervised Machine Translation talk by Guillaume Lample (FAIR),https://www.reddit.com/r/MachineLearning/comments/9sefue/awesome_unsupervised_machine_translation_talk_by/,narsilouu,1540829378,"[https://youtu.be/yRlINjCQnc8](https://youtu.be/yRlINjCQnc8)

The outline of the talk is how to translate between two languages without having \*any\* rosetta stone (sentences that say the same thing in two different languages).

It uses embedding alignment and then specific language domain transformations.",0,1,False,self,,,,,
1637,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,1,9sehvz,self.MachineLearning,Implementing sigmf activation function,https://www.reddit.com/r/MachineLearning/comments/9sehvz/implementing_sigmf_activation_function/,Nicholas_Snakeeyes,1540829758,"Is there any step function to it? As in if &gt; .5, 1, else 0?",0,1,False,self,,,,,
1638,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,1,9semgy,self.MachineLearning,[R] Awesome talk on Unsupervise Machine Translation by Guillaume Lample (FAIR),https://www.reddit.com/r/MachineLearning/comments/9semgy/r_awesome_talk_on_unsupervise_machine_translation/,narsilouu,1540830601,"[https://youtu.be/yRlINjCQnc8](https://youtu.be/yRlINjCQnc8)

The outline of the talk is how to translate between two languages without having \*any\* rosetta stone (sentences that say the same thing in two different languages), so basically without any prior alignment.

It uses embedding alignment and then specific language domain transformations.",2,1,False,self,,,,,
1639,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,1,9ses7v,arxiv.org,[R] Evading classifiers in discrete domains with provable optimality guarantees,https://www.reddit.com/r/MachineLearning/comments/9ses7v/r_evading_classifiers_in_discrete_domains_with/,hidden-markov,1540831539,,0,1,False,default,,,,,
1640,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,2,9seygu,self.MachineLearning,How many times a year is Andrew Ng's ML course on coursera offered ?,https://www.reddit.com/r/MachineLearning/comments/9seygu/how_many_times_a_year_is_andrew_ngs_ml_course_on/,MightyParserer,1540832583,"Also, is it self paced?",4,1,False,self,,,,,
1641,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,2,9sez6o,arxiv.org,[R] Uncovering divergent linguistic information in word embeddings with lessons for intrinsic and extrinsic evaluation,https://www.reddit.com/r/MachineLearning/comments/9sez6o/r_uncovering_divergent_linguistic_information_in/,serveboy,1540832710,,1,1,False,default,,,,,
1642,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,2,9sezcg,self.MachineLearning,Facing a problem with text classification,https://www.reddit.com/r/MachineLearning/comments/9sezcg/facing_a_problem_with_text_classification/,Rishit1501,1540832738,"Hi, I am trying to obtain concept words of each document with LDA and LSA ( I want to obtain concept words (not keywords) of individual documents and cluster them based on those obtained concept words. I tried it with LSA and LDA  using gensim and sklearn both ) but I am getting mixed words and not document wise. How do I do that. 

&amp;#x200B;

Thanks in advance.",0,1,False,self,,,,,
1643,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,2,9sf509,self.MachineLearning,NIPS 2018 is it worth it ?,https://www.reddit.com/r/MachineLearning/comments/9sf509/nips_2018_is_it_worth_it/,JohnnyDeepLearner,1540833771,"Hi EveryOne,

&amp;#x200B;

Just wanted to ask i am an entrepreneur interested in ML and Deep Learning. I am planning to attend NIPS 2018 but i come from far (France). I am asking myself today is it worth to travel for such conference ? Am i going to get some value ? 

Thanks to all for your kind replies.",0,1,False,self,,,,,
1644,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,2,9sfbyb,self.MachineLearning,"[P] Type of model to be used for a ""fill in the blanks"" model.",https://www.reddit.com/r/MachineLearning/comments/9sfbyb/p_type_of_model_to_be_used_for_a_fill_in_the/,CSGOvelocity,1540834910,"I am trying to make a project on a ""fill in the blanks model""

I am stuck on what kind of model can be used if the blank lies in the middle of a sentence. (eg- Apple \_\_\_\_ a fruit, so the answer will be Apple IS a fruit)

Classic LSTM models cannot be used as they will only take the part before the blank.

Same goes for seq2seq networks and frankly I have no idea as to what kind of model can take both into account the part after and before the blank simultaneously and give an answer to the blank.

Please suggest types of models and/or some research work that I can look into. Thanks.",10,1,False,self,,,,,
1645,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,2,9sffw3,self.MachineLearning,Proven use cases of DL for NLP tasks (ex. speech recognition and machine translation),https://www.reddit.com/r/MachineLearning/comments/9sffw3/proven_use_cases_of_dl_for_nlp_tasks_ex_speech/,amarofades,1540835561,[removed],0,1,False,self,,,,,
1646,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,3,9sfozf,github.com,PyTorch code release: Two classic deep reinforcement-learning models for teaching agents to communicate to play collaborative games,https://www.reddit.com/r/MachineLearning/comments/9sfozf/pytorch_code_release_two_classic_deep/,helicalpen,1540837034,,0,1,False,https://b.thumbs.redditmedia.com/IKwRPaPMmcZ7uK8A_JciV7zuNSCZH_IM5NBtg9F8EVI.jpg,,,,,
1647,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,3,9sfryb,self.MachineLearning,A note on why gradient descent is even needed in the first place,https://www.reddit.com/r/MachineLearning/comments/9sfryb/a_note_on_why_gradient_descent_is_even_needed_in/,DBCerigo,1540837507,[removed],0,1,False,self,,,,,
1648,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,3,9sft28,github.com,Learning to communicate in PyTorch,https://www.reddit.com/r/MachineLearning/comments/9sft28/learning_to_communicate_in_pytorch/,helicalpen,1540837715,,0,1,False,https://b.thumbs.redditmedia.com/IKwRPaPMmcZ7uK8A_JciV7zuNSCZH_IM5NBtg9F8EVI.jpg,,,,,
1649,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,3,9sftla,github.com,[P] Learning to Communicate in PyTorch,https://www.reddit.com/r/MachineLearning/comments/9sftla/p_learning_to_communicate_in_pytorch/,helicalpen,1540837816,,0,1,False,default,,,,,
1650,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,3,9sfudk,self.MachineLearning,[D] How do you focus on the Lifecycle of a Data Model?,https://www.reddit.com/r/MachineLearning/comments/9sfudk/d_how_do_you_focus_on_the_lifecycle_of_a_data/,LityxIQ,1540837955,"Modeling is a powerful way to predict behaviors and business outcomes. But, to maintain relevant and accurate models, they must be regularly monitored and adjusted to address changes that occur as part of the natural model evolution.

Managing the lifecycle of a model requires many factors that need to be considered to maintain its quality. The cost of storage, understanding the models approach, the documentation of metadata, monitoring the evolution of the model, validating and meeting the standards of the model compliance framework are all essential. [Click here to read more of the article.](https://lityx.com/why-model-lifecycle-management-is-essential-for-data-quality/)

&amp;#x200B;

We are curious how others focus on the Lifecycle of a Data model...?",0,1,False,self,,,,,
1651,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,3,9sfv8x,self.MachineLearning,[D] A note on why gradient descent is even needed in the first place,https://www.reddit.com/r/MachineLearning/comments/9sfv8x/d_a_note_on_why_gradient_descent_is_even_needed/,DBCerigo,1540838116,"I recently gave a talk (called Deep Learning Without The Hype), and in that talk I showed a classic slide (inserted below) from the classic Stanfords Andrew Ngs MOOC Machine Learning course \[1\]. After the talk I was approached by some of the students and they had  a number of interrelated questions raised specifically by this slide, and at the time I dont believe I gave (or even had) a completely satisfactory answer to them.

So since then I formulated a (hopefully) more satisfactory answer to it. And it surprisingly showed a few fundamental holes in my understanding (even though I'm a successful enough practitioner of using this stuff in industry settings). This is anything new - it's a hopefully much more thorough revision of some basic stuff. I thought to share in the hope it's interesting to take this step back and really aim for full clarity, and to maybe receive any further insights from people.

So here goes the revised questions and answers.

**Q:** Do you actually have that surface? If so why not just take the minimum of it?  
**Q:** Do you really have all the gradients? If not then how do you do gradient descent? And if so, why not also just pick one where the gradient is zero?

**One-liner Answer:** Its due to computational limitations we hit with large models that we use gradient descent and nothing to do with it being a special learning algorithmjust repeatedly choosing random sets of parameters and keeping the best performing one would work if we had a powerful enough machine+enough time.

**Abridged Answer:**You mathematically and theoretically have the entire Cost surfaceits functional form is fully specified (thats what your model and cost function are), all you have to do is put actual values in for your model parameters and compute it. And you mathematically and theoretically have the entire vector field of gradients for that surfacei.e. you have all the gradients. But ***in reality*** you only have what you are able to ***compute with your limited resources and time***. The aim of the game is to find a set of parameters that make for a low error, and theres no rules on how you do that. But trying to do a grid search (which is akin to plotting/computing the loss surface) in a 1million+ dimension parameter space is going to be a slow progress (think taking years even on current state of the art computers). It is precisely a computation limitation problem that gradient descent overcomes, not a mathematical one. In reality it might be better to think of it as a search algorithm rather than an optimisation algorithm, i.e. it efficiently searches about in parameter space for areas of low(er) loss.A nice way to think about the extent of the computational efficiency/gains that gradient descent gives you over say a grid search over the model parameters is to think about the dimension of the space each traverses. If your model has a million paramters then a volume in that space is a million dimensional volume and we know that volumes grow like *V=l*\^*D*thats going to be painfully big. But gradient descent only traverses a line through parameter space (by following gradients), and lines are only 1*D*. Hopefully thats persuasive to you.

**Ulta-Extended And Complete With Coded Examples Answer:**

See this [notebook](https://github.com/DBCerigo/talks-presentations/blob/master/deep_learning_without_hype/On%20Why%20Gradient%20Descent%20Is%20Needed%20-%20Without%20The%20Hype.ipynb)

&amp;#x200B;

![img](lly1p40z36v11)

\[1\] [https://www.coursera.org/learn/machine-learning](https://www.coursera.org/learn/machine-learning)

Link to post on Medium [https://medium.com/@DBCerigo/on-why-gradient-descent-is-even-needed-25160197a635](https://medium.com/@DBCerigo/on-why-gradient-descent-is-even-needed-25160197a635)",125,1,False,self,,,,,
1652,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,4,9sgdnq,self.MachineLearning,Question on 'Curse of Dimensionality' and 'No Free Lunch' theorem -- fast.ai ML course,https://www.reddit.com/r/MachineLearning/comments/9sgdnq/question_on_curse_of_dimensionality_and_no_free/,chilukrn,1540841447,[removed],0,1,False,self,,,,,
1653,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,4,9sgeqm,self.MachineLearning,(New machine learning learner) How to understand the f(xi) has a likelihood?,https://www.reddit.com/r/MachineLearning/comments/9sgeqm/new_machine_learning_learner_how_to_understand/,xihajun,1540841636,"If we have input output pairs, we could estimate the function f

but what does p(y\_i|f,x\_i) mean?

why the mapping has a probability?

Also, in this case, parameter is the f or something else?

Sorry for my English :(

&amp;#x200B;",0,1,False,self,,,,,
1654,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,4,9sgijh,self.MachineLearning,A Gentle Introduction to Automatic Speech Recognition (1950s  1980s),https://www.reddit.com/r/MachineLearning/comments/9sgijh/a_gentle_introduction_to_automatic_speech/,troltilla,1540842308,[removed],0,1,False,self,,,,,
1655,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,4,9sgmxd,self.MachineLearning,Rising Artificial Intelligence in the Legal Profession - Research Help!,https://www.reddit.com/r/MachineLearning/comments/9sgmxd/rising_artificial_intelligence_in_the_legal/,nullislandlawyers,1540843085,[removed],0,1,False,self,,,,,
1656,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,5,9sgto4,self.MachineLearning,[P] Learning to Communicate in PyTorch,https://www.reddit.com/r/MachineLearning/comments/9sgto4/p_learning_to_communicate_in_pytorch/,helicalpen,1540844274,"Github repo: https://github.com/minqi/learning-to-communicate-pytorch

I recently implemented the RIAL and DIAL models from one of the first papers on learning communication protocols in a multi-agent reinforcement-learning setting. Specifically, these models learn discrete communication protocols, though DIAL can also be used to learn continuous messages. You can read the original paper here: https://arxiv.org/abs/1605.06676

In a nutshell, these models build off of a recurrent DQN architecture to learn actions to take and messages to send for collaborative multiplayer games that require communication among agents to successfully earn high rewards. RIAL learns a factorized policy across actions and discrete messages, while DIAL backpropagates errors directly through a noisy communication channel to learn continuous message vectors that become discretized (binarized) during test time. The latter approach is shown to learn more quickly and achieve better test-time performance.",0,1,False,self,,,,,
1657,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,5,9sh26b,youtube.com,"For anyone looking to get into machine learning, I would advise that you don't learn the behemoth libraries like Tensorflow or Theano, but instead learn how to use a high-level API like Keras. Here's a quick video to explain what it is. Hope I was helpful!",https://www.reddit.com/r/MachineLearning/comments/9sh26b/for_anyone_looking_to_get_into_machine_learning_i/,antaloaalonso,1540845796,,0,1,False,https://b.thumbs.redditmedia.com/VeOOWnBsA49wJCtCan9jcEGRYYS_UxVWwAmiJ07YSPM.jpg,,,,,
1658,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,5,9sh3pk,self.MachineLearning,Lightweight Probabilistic Deep Networks: Dirichlet Output Layer,https://www.reddit.com/r/MachineLearning/comments/9sh3pk/lightweight_probabilistic_deep_networks_dirichlet/,nicolasj92,1540846092,[removed],0,1,False,self,,,,,
1659,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,7,9shtxf,self.MachineLearning,"[N] Google starts AI For Social Good Program, $25M in funding available",https://www.reddit.com/r/MachineLearning/comments/9shtxf/n_google_starts_ai_for_social_good_program_25m_in/,FirstTimeResearcher,1540851085,"$25M in Funding available to organizations around the world to submit their ideas for how they could use AI to help address societal challenges.

https://ai.google/social-good",9,1,False,self,,,,,
1660,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,7,9shtyb,self.MachineLearning,Unintentional bias in Google Translate,https://www.reddit.com/r/MachineLearning/comments/9shtyb/unintentional_bias_in_google_translate/,Terpomo11,1540851089,[removed],0,1,False,self,,,,,
1661,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,7,9si5vp,self.MachineLearning,[D] What is your reaction to your idea not working?,https://www.reddit.com/r/MachineLearning/comments/9si5vp/d_what_is_your_reaction_to_your_idea_not_working/,T_hank,1540853468,"I easily become deflated when my hunches fail to yield rewards. I was wondering how long others wrestle with an idea before calling quits? And what does your implementation pipleline look like in general?

Lets try with a hypothetical problem: say for example you felt regularizer R would improve a learning system. Would you : A. spend time coming up with experiments to test out if your assumption would be right, that is would you first try and figure out whether the current system is not doing what R can add to it, maybe (hypothetically again) by checking the say distribution of some parameter, and check that with an experiment.

B. Would you prefer to implement R into the system to see directly if it improves the system?
In case your hunch doesn't work out, do you try to get closer to understanding what was wrong in your assumption?

I'd like to keep this question open -ended, and would love to hear any bits of wisdom you learnt on the job, or your experience with some specific problem, or maybe something you feel people do wrong.",21,1,False,self,,,,,
1662,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,8,9sic57,self.MachineLearning,Training data format for anomaly detection,https://www.reddit.com/r/MachineLearning/comments/9sic57/training_data_format_for_anomaly_detection/,blahsphemer_,1540854722,[removed],0,1,False,self,,,,,
1663,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,8,9sim5v,self.MachineLearning,[D] Post all your non-technical ML related discussion to this new sub: r/MachineLearningLounge,https://www.reddit.com/r/MachineLearning/comments/9sim5v/d_post_all_your_nontechnical_ml_related/,oldforstocks,1540856753,"I am posting after I spoke to mods and received the permission from them. This sub (r/MachineLearning) gets so much heat from Twitter ML researchers. When they point out something bad about this sub, they usually pick a non-technical post and show comments in it. In order to bring this sub back to its glory, I decided to create a new sub for ML related non-technical discussion. I kept the rules to minimal in that sub so that people can express the opinion freely.

https://www.reddit.com/r/MachineLearningLounge/


Here is an example to differentiate between r/MachineLearningLounge and r/MachineLearning

You went and came back from a conference. You wrote a nice report about things that you learned. Post that in r/MachineLearning. You had a bad experience from a researcher at that conference. Post that in r/MachineLearningLounge. This subtle difference would help this sub and the new sub a lot. ML community provides more drama than expected (esp. Twitter) 

",7,1,False,self,,,,,
1664,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,8,9sinly,self.MachineLearning,Text classification questions,https://www.reddit.com/r/MachineLearning/comments/9sinly/text_classification_questions/,johne898,1540857064,[removed],1,1,False,self,,,,,
1665,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,9,9sizer,self.MachineLearning,Tensorflow (or otherbackends) chatbot?!,https://www.reddit.com/r/MachineLearning/comments/9sizer/tensorflow_or_otherbackends_chatbot/,Zman98789,1540859512,"I want to create a chat bot but i want it to gradually learn so the user will type to the bot then the bot will try and respond after the user decides that the bot did a good job or bad job the bot will train off of that and try talking to the user again.

dose anyone know any resources for this because i am dumbfounded right now on what to do

&amp;#x200B;",0,1,False,self,,,,,
1666,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,10,9sjnd9,arxiv.org,[R] The Singular Values of Convolutional Layers,https://www.reddit.com/r/MachineLearning/comments/9sjnd9/r_the_singular_values_of_convolutional_layers/,downtownslim,1540864685,,2,1,False,default,,,,,
1667,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,11,9sjoz7,self.MachineLearning,[P] Playing Mortal Kombat with TensorFlow.js,https://www.reddit.com/r/MachineLearning/comments/9sjoz7/p_playing_mortal_kombat_with_tensorflowjs/,hardmaru,1540865021,"From the [article](https://blog.mgechev.com/2018/10/20/transfer-learning-tensorflow-js-data-augmentation-mobile-net/):

*In this blog post, Ill share my experience of building a posture classification algorithm using TensorFlow.js and MobileNet. In the process, well look at the following topics:*

- *Collecting training data for image classification*

- *Performing data augmentation using [imgaug](https://github.com/aleju/imgaug)*

- *Transfer learning with MobileNet*

- *Binary classification and n-ary classification*

- *Training an image classification TensorFlow.js model in Node.js and using it in the browser*

- *Few words on using action classification with LSTM*

*For this article, well relax the problem to posture detection based on a single frame, in contrast to recognizing an action from a sequence of frames. Well develop a supervised deep learning model, which based on an image from the users laptop camera, indicates if on this image the user is punching, kicking, or not doing the first two.
By the end of the article, wed be able to build a model for playing [MK.js](https://github.com/mgechev/mk.js)* (Web version of Mortal Kombat).

https://blog.mgechev.com/2018/10/20/transfer-learning-tensorflow-js-data-augmentation-mobile-net/",4,1,False,self,,,,,
1668,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,11,9sjt5j,arxiv.org,On the Equivalence of Convolutional and Hadamard Networks using DFT,https://www.reddit.com/r/MachineLearning/comments/9sjt5j/on_the_equivalence_of_convolutional_and_hadamard/,almaya,1540865944,,2,1,False,default,,,,,
1669,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,12,9skbnb,link.medium.com,"I Built a $2M Gameboy Supercomputer, for AI",https://www.reddit.com/r/MachineLearning/comments/9skbnb/i_built_a_2m_gameboy_supercomputer_for_ai/,kmrocki,1540870159,,0,1,False,default,,,,,
1670,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,13,9skoq7,openpr.com,"Machine Learning Accelerator for Healthcare Market: Google, IBM, Microsoft Power the AI",https://www.reddit.com/r/MachineLearning/comments/9skoq7/machine_learning_accelerator_for_healthcare/,reportconsultant10,1540873424,,0,1,False,default,,,,,
1671,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,13,9skr8v,latestindustrynews.com,"Global Debt Management Solutions Market: Organic and Inorganic Strategies Applied By Major Vendors (Financial Sciences Corp., Fair Isaac Corporation, Capita PLC)",https://www.reddit.com/r/MachineLearning/comments/9skr8v/global_debt_management_solutions_market_organic/,reportconsultant10,1540874094,,0,1,False,default,,,,,
1672,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,13,9sku09,openpr.com,"Global Enterprise Mobility Management Solution Market: Frequent Use of Mobile Devices is the Key Driver With Key Players (Microsoft, IBM, Vmware)",https://www.reddit.com/r/MachineLearning/comments/9sku09/global_enterprise_mobility_management_solution/,reportconsultant10,1540874819,,0,1,False,default,,,,,
1673,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,13,9skugx,self.MachineLearning,OCR word classification or character recognition,https://www.reddit.com/r/MachineLearning/comments/9skugx/ocr_word_classification_or_character_recognition/,jetjodh,1540874943,[removed],0,1,False,self,,,,,
1674,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,13,9skwfg,thebusinessinvestor.com,"Managed Equipment Services Market: Siemens Healthcare GmbH, GE Healthcare Concentrate on Patient Care",https://www.reddit.com/r/MachineLearning/comments/9skwfg/managed_equipment_services_market_siemens/,reportconsultant10,1540875505,,0,1,False,default,,,,,
1675,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,14,9sl55s,analyticmarket.com,"Americas, APAC, and EMEA Are The Leading Regions of Global Help Desk Outsourcing Market With Major Vendors HP Enterprise Services, IBM, Qcom Outsourcing, CSC, HCL Technologies, and Wipro",https://www.reddit.com/r/MachineLearning/comments/9sl55s/americas_apac_and_emea_are_the_leading_regions_of/,reportconsultant10,1540878085,,0,1,False,default,,,,,
1676,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,14,9sl6d3,self.MachineLearning,Progress in Unsupervised Image-to-Image Translation?,https://www.reddit.com/r/MachineLearning/comments/9sl6d3/progress_in_unsupervised_imagetoimage_translation/,deep-yearning,1540878454,[removed],0,1,False,self,,,,,
1677,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,15,9slamp,github.com,[P] Fast eigendecomposition of the Hessian for any PyTorch model using subsampled power iteration,https://www.reddit.com/r/MachineLearning/comments/9slamp/p_fast_eigendecomposition_of_the_hessian_for_any/,noahgolm,1540879824,,0,1,False,default,,,,,
1678,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,15,9sldg8,self.MachineLearning,[P] Efficient eigendecomposition of the Hessian for any PyTorch model,https://www.reddit.com/r/MachineLearning/comments/9sldg8/p_efficient_eigendecomposition_of_the_hessian_for/,noahgolm,1540880738,"[https://github.com/noahgolmant/pytorch-hessian-eigenthings](https://github.com/noahgolmant/pytorch-hessian-eigenthings)

Lately, I've been playing with some second-order analysis, so I wanted to make a faster tool to analyze the spectrum of the Hessian of the loss for arbitrary PyTorch models. Most of the tools to do this are really slow or only work on small models. This calculates the spectrum by performing power iteration with deflation on a mini-batch estimate of the Hessian-vector product. The cost is linear in the number of parameters, and you can play with the mini-batch size and power iteration precision for more accurate estimates. It's pretty fast since you can do it all on the GPU. For example, it only takes a few minutes to compute the top 20-30 eigenvalues/eigenvectors on a single device for ResNet18. 

&amp;#x200B;",19,1,False,self,,,,,
1679,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,16,9slple,self.MachineLearning,[P] BERT-keras: BERT in keras with OpenAI's pertained transformer network for weight initialization,https://www.reddit.com/r/MachineLearning/comments/9slple/p_bertkeras_bert_in_keras_with_openais_pertained/,Separius12,1540884743,"Here's my full implementation of BERT in keras with both fine tuning and pre training code, because the pertained weights are not out yet, I used OpenAI's transformer pertained model for initialization: https://github.com/Separius/BERT-keras",8,1,False,self,,,,,
1680,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,16,9sls0d,self.MachineLearning,Japanese computer-vision related company,https://www.reddit.com/r/MachineLearning/comments/9sls0d/japanese_computervision_related_company/,jane199209,1540885625,[removed],0,1,False,self,,,,,
1681,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,18,9sm9my,self.MachineLearning,Importing keras load_model,https://www.reddit.com/r/MachineLearning/comments/9sm9my/importing_keras_load_model/,R00T-,1540891746,[removed],0,1,False,self,,,,,
1682,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,18,9sm9qh,self.MachineLearning,[D] Features of AI-as-a-Service,https://www.reddit.com/r/MachineLearning/comments/9sm9qh/d_features_of_aiasaservice/,FitRemove,1540891771,"I have here jotted down some interesting facts about AI-as-a-service and the roles of machine learning. Do you agree with my study?

&amp;#x200B;

teks.co.in/site/blog/ai-as-a-service-all-that-you-need-to-know/",1,1,False,self,,,,,
1683,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,18,9smcfj,self.MachineLearning,[N] QNNPACK: Open source library for running PyTorch models on mobile devices,https://www.reddit.com/r/MachineLearning/comments/9smcfj/n_qnnpack_open_source_library_for_running_pytorch/,tehnokv,1540892583,"""We are open-sourcing QNNPACK to provide comprehensive support for quantized inference as part of the PyTorch 1.0 platform.""

* https://code.fb.com/ml-applications/qnnpack/
* https://github.com/pytorch/QNNPACK",4,1,False,self,,,,,
1684,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,20,9smv0s,arxiv.org,[R] [1810.09038] Depth with Nonlinearity Creates No Bad Local Minima in ResNets,https://www.reddit.com/r/MachineLearning/comments/9smv0s/r_181009038_depth_with_nonlinearity_creates_no/,TwoUpper,1540897990,,12,1,False,default,,,,,
1685,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,20,9smv78,self.MachineLearning,Best youtube playlist or papers for learning OpenCv?,https://www.reddit.com/r/MachineLearning/comments/9smv78/best_youtube_playlist_or_papers_for_learning/,ashishsaini,1540898037,,0,1,False,self,,,,,
1686,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,20,9smwvx,self.MachineLearning,[P] Github-course in deep learning for natural language processing,https://www.reddit.com/r/MachineLearning/comments/9smwvx/p_githubcourse_in_deep_learning_for_natural/,justheuristic,1540898499,"[https://github.com/yandexdataschool/nlp\_course](https://github.com/yandexdataschool/nlp_course)

A github-based course covering a range of topics from embeddings to sequence-to-sequence learning with attention.

Each week contains video lectures in english &amp; russian, assignments in jupyter (colab-friendly) and tons of links.

The course is in sync with on-campus course taught at YSDA, currently at \~60%.

Contributions are always welcome!",15,1,False,self,,,,,
1687,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,20,9smz1s,self.MachineLearning,What is Machine Learning and Why is it Important?,https://www.reddit.com/r/MachineLearning/comments/9smz1s/what_is_machine_learning_and_why_is_it_important/,MarkWilston,1540899069,[removed],0,1,False,self,,,,,
1688,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,20,9sn3k9,self.MachineLearning,[Project] Knowledge Graph Convolutional Networks: Machine Learning over Reasoned Knowledge,https://www.reddit.com/r/MachineLearning/comments/9sn3k9/project_knowledge_graph_convolutional_networks/,jmsfltchr,1540900206,"I'm starting a project aiming to combine graph convolutional networks with a knowledge graph (including an automated reasoner). My implementation is underway, but I'd like to see what people think of the concept and what they'd like to be able to do with it.

I've put together a blog post to give an overview of the vision: [Knowledge Graph Convolutional Networks](https://blog.grakn.ai/knowledge-graph-convolutional-networks-machine-learning-over-reasoned-knowledge-9eb5ce5e0f68)

I intend to write a follow-up with the technical approach, and publish the code open-source when it's ready :)",0,1,False,self,,,,,
1689,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,21,9sn6vp,self.MachineLearning,[P] Knowledge Graph Convolutional Networks: Machine Learning over Reasoned Knowledge,https://www.reddit.com/r/MachineLearning/comments/9sn6vp/p_knowledge_graph_convolutional_networks_machine/,jmsfltchr,1540901035,"I'm starting a project aiming to combine graph convolutional networks with a knowledge graph (including an automated reasoner). My implementation is underway, but I'd like to see what people think of the concept and what they'd like to be able to do with it.

I've put together a blog post to give an overview of the vision: [Knowledge Graph Convolutional Networks](https://blog.grakn.ai/knowledge-graph-convolutional-networks-machine-learning-over-reasoned-knowledge-9eb5ce5e0f68)

I intend to write a follow-up with the technical approach, and publish the code open-source when it's ready :)",3,1,False,self,,,,,
1690,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,21,9snhfx,self.MachineLearning,[P] Heatmaps for visualising spatio-temporal regions of 3D CNNs.,https://www.reddit.com/r/MachineLearning/comments/9snhfx/p_heatmaps_for_visualising_spatiotemporal_regions/,Alex_Stergiou,1540903344,"Despite the fact that there is a great amount of works and research that are done for visualising what is learned by convolution kernels in different parts of the network, in image-based tasks, little effort has been made towards the better interpretability of video/3D models. Thus, the main focus of this repo was to convert the popular CAM approach to also include time as an additional dimension.  What I find most interesting about using a heatmap visualisation for clips, is the fact that the network not only focuses at specific regions in the frames but also at (what they are found to be) ""informative"" parts of the video.

&amp;#x200B;

Github repo: [https://github.com/alexandrosstergiou/Keras-3DCNN-Heatmap](https://github.com/alexandrosstergiou/Keras-3DCNN-Heatmap)

&amp;#x200B;

(Although the code is for Keras, there will be PyTorch and TF versions respectively in the future)

&amp;#x200B;

Feedback is much appreciated!

&amp;#x200B;",0,1,False,self,,,,,
1691,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,21,9snhjt,yourtechstory.com,Google to reward $25 million to the winners of AI impact challenge 2019.,https://www.reddit.com/r/MachineLearning/comments/9snhjt/google_to_reward_25_million_to_the_winners_of_ai/,yourtechstory,1540903365,,0,1,False,default,,,,,
1692,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,21,9snhkr,self.MachineLearning,"Can I get torch to run with more than 1 CPU core from the command line when using ""th""?",https://www.reddit.com/r/MachineLearning/comments/9snhkr/can_i_get_torch_to_run_with_more_than_1_cpu_core/,swiftrob,1540903369,[removed],0,1,False,self,,,,,
1693,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,22,9so2jq,self.MachineLearning,"[D] I'm offended by weapons, could COLT changes its name too?",https://www.reddit.com/r/MachineLearning/comments/9so2jq/d_im_offended_by_weapons_could_colt_changes_its/,Caerbanoob,1540907470,Title,0,1,False,self,,,,,
1694,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,23,9so6jg,self.MachineLearning,Machine Learning Algorithm for Beginners,https://www.reddit.com/r/MachineLearning/comments/9so6jg/machine_learning_algorithm_for_beginners/,adarsh_adg,1540908270,[removed],0,1,False,self,,,,,
1695,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,23,9so8h3,self.MachineLearning,Do you use a different framework between development and production of deep learning models? Why or why not?,https://www.reddit.com/r/MachineLearning/comments/9so8h3/do_you_use_a_different_framework_between/,Valiox,1540908670,[removed],0,1,False,self,,,,,
1696,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,23,9so8na,self.MachineLearning,Rising Artificial Intelligence use in the Legal Profession - Research Help!,https://www.reddit.com/r/MachineLearning/comments/9so8na/rising_artificial_intelligence_use_in_the_legal/,nullislandlawyers,1540908709," 

Hi there, we are a group of post graduate researchers at the Royal College of Art.

Our research topic considers the role in which Artificial Intelligence is affecting the Legal profession.  
Some of our speculative research questions are as followed:

* *With the use of the Internet and technological proficiency growing exponentially, the platform for Cybercrime increases also. How do we presently define Cybercrime and where do we see its direction heading in the future? With increasing calls for a neutral net, how should we regulate these offences while maintaining a free and open internet?*
* *New original forms of crime are being facilitated by the Internet; recent cases of SWATTING and DDoS attacks have showcased this. Is the current legal system able to adapt and enforce accurate justice against these new crimes, or should an alternative judiciary be considered?*
* *Can you envision a future where an AI system has entirely automated the Legal Profession? Can a machine learning program take on the roll of the Judge, Jury and Executioner ? What happens to the idea of empathy and compassion in this future?*
* *It is often claimed that our Judiciary doesnt reflect the diverse society in which it serves. Is there a potential growing disparity between the way in which communication and information is shared over the Internet and the typical demographic which sentences it? Is internet culture completely/accurately understood at the highest level?*

If anybody, can offer an insight into any of the above questions, we would greatly appreciate this!

We would also be super stoked to have a conversation with somebody with a background in this world too/

B, D &amp; K",0,1,False,self,,,,,
1697,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,23,9sob5h,self.MachineLearning,[R] Multi-Agent Common Knowledge Reinforcement Learning https://arxiv.org/pdf/1810.11702.pdf,https://www.reddit.com/r/MachineLearning/comments/9sob5h/r_multiagent_common_knowledge_reinforcement/,tigerneil,1540909214,[removed],0,1,False,self,,,,,
1698,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,23,9sodou,github.com,"[P] Pytorch reproducibility of ""Concrete Dropout"" [1705.07832] paper experiments.",https://www.reddit.com/r/MachineLearning/comments/9sodou/p_pytorch_reproducibility_of_concrete_dropout/,alfo5123,1540909634,,0,1,False,default,,,,,
1699,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,23,9sof7e,self.MachineLearning,[R] Model-Based Active Exploration,https://www.reddit.com/r/MachineLearning/comments/9sof7e/r_modelbased_active_exploration/,alekhka,1540909882,"A cool paper from NNaisense (Schmidhuber's startup) which claims orders of magnitude improvement in efficiency over the state of the art, albeit only in simple toy environments:

https://arxiv.org/abs/1810.12162",2,1,False,self,,,,,
1700,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,23,9sogug,medium.freecodecamp.org,How to rock your next time series forecasting project,https://www.reddit.com/r/MachineLearning/comments/9sogug/how_to_rock_your_next_time_series_forecasting/,kernelmode,1540910136,,0,1,False,https://b.thumbs.redditmedia.com/AZv7MQrlQZsklc-1OLaD0Ukt0gT90pMoy7iCbiKty4I.jpg,,,,,
1701,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,23,9son6e,self.MachineLearning,"[D] Chat bots represent the next evolution in natural language processing, and they provide a cheap and effective way to answer simple questions and provide a 24/7 access point between businesses and customers.",https://www.reddit.com/r/MachineLearning/comments/9son6e/d_chat_bots_represent_the_next_evolution_in/,Md_Khaledur_Rahman,1540911216,"An Introduction to Natural Language Processing

Source- [https://medium.com/datadriveninvestor/an-introduction-to-natural-language-processing-c7d66be89df6](https://medium.com/datadriveninvestor/an-introduction-to-natural-language-processing-c7d66be89df6)

&amp;#x200B;

**NATURAL LANGUAGE PROCESSING** is pretty much exactly what it sounds like. Its an umbrella term thats used to refer to the ability of machines to process and understand language as its written or spoken by human beings. While it would be nice to think that our languages make logical sense and follow basic rules of grammar and punctuation, we all know thats not always the case. We use slang, proper nouns, abbreviations and acronyms, and not everyone can string a sentence together like Stephen King or J. K. Rowling.

Thats where natural language processing comes in. Loosely speaking, its a form of artificial intelligence thats all about trying to analyze and understand either written or spoken language and the context that its being used in. A basic example of natural language processing in action is the predictive text that we see when we use our smartphones. As we type our messages, the phones operating system uses AI and natural language processing to try to guess at what we might be typing and which words might come next.

Natural language processing isnt perfect, as youll have seen if youve ever used a tool like Google Translate, but it is pretty powerful and getting better all of the time. It can even be combined with machine learning to create a system that can not only understand whats being said but which will also continue to improve the more its used. A great example here is Google Assistant, which gets better at understanding and responding to the commands of individual users. This can come in useful if you have an accent or a speech impediment, and its all made possible by a combination of natural language processing and machine learning.",0,1,False,self,,,,,
1702,MachineLearning,t5_2r3gv,2018-10-30,2018,10,30,23,9sonte,self.MachineLearning,How do I model this?,https://www.reddit.com/r/MachineLearning/comments/9sonte/how_do_i_model_this/,blahblahquesera,1540911319,[removed],0,1,False,self,,,,,
1703,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,0,9soua1,self.MachineLearning,"[R] Test post, don't upvote",https://www.reddit.com/r/MachineLearning/comments/9soua1/r_test_post_dont_upvote/,MTGTraner,1540912392,,0,1,False,self,,,,,
1704,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,0,9sowyt,self.MachineLearning,Making AI Agent Outside Controlled Environment,https://www.reddit.com/r/MachineLearning/comments/9sowyt/making_ai_agent_outside_controlled_environment/,rpdtrsh,1540912873,[removed],0,1,False,self,,,,,
1705,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,0,9sp2jv,self.MachineLearning,only 4 invites left join before I get banned from every subreddit :DDDDDDD,https://www.reddit.com/r/MachineLearning/comments/9sp2jv/only_4_invites_left_join_before_i_get_banned_from/,Cosmosity777,1540913847,"Initiative Q is an attempt by ex-PayPal guys to create a new payment system instead of credit cards that were designed in the 1950s. The system uses its own currency, the Q, and to get people to start using the system once it's ready they are allocating Qs for free to people that sign up now (the amount drops as more people join - so better to join early). Signing up is free and they only ask for your name and an email address. There's nothing to lose but if this payment system becomes a world leading payment method your Qs can be worth a lot. If you missed getting bitcoin seven years ago, you wouldn't want to miss this.

&amp;#x200B;

Here is my invite link: [https://initiativeq.com/invite/SGnMCBH2X](https://initiativeq.com/invite/SGnMCBH2X)

&amp;#x200B;

 This link will stop working once Im out of invites. Let me know after you registered, because I need to verify you on my end.",0,1,False,self,,,,,
1706,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,0,9sp5pt,self.MachineLearning,[N] Microsoft AI For Good. 1) AI for Humanitarian Action 2) AI for Accessibility 3) AI for Earth,https://www.reddit.com/r/MachineLearning/comments/9sp5pt/n_microsoft_ai_for_good_1_ai_for_humanitarian/,FirstTimeResearcher,1540914460,"AI for Good
Providing technology, resource, and expertise to empower those working to solve humanitarian issues and create a more sustainable and accessible world.

Apply Here: https://www.microsoft.com/en-us/ai/ai-for-good
",1,1,False,self,,,,,
1707,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,1,9spei3,self.MachineLearning,[D] Progress in Unpaired Image-to-Image Translation?,https://www.reddit.com/r/MachineLearning/comments/9spei3/d_progress_in_unpaired_imagetoimage_translation/,deep-yearning,1540916101,"I'm starting a new project in unpaired image-to-image translation and am wondering if there has been significant progress made in this area since last year's CycleGAN? I've been searching for newer, more impressive methods but haven't found anything newer than CycleGANs (that isn't incremental). I'm aware of some newer work by nVidia in paired image translation (pix2pix, vid2vid, etc) and 'multimodal' image translation.

&amp;#x200B;

Also, I'm trying to understand the architecture of CycleGANs a bit better - is there a tutorial out there for this? Thanks!",12,1,False,self,,,,,
1708,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,1,9speu6,self.MachineLearning,Idea About New Type of Neural Nets,https://www.reddit.com/r/MachineLearning/comments/9speu6/idea_about_new_type_of_neural_nets/,MemoriesThatUCall,1540916155,[removed],0,1,False,self,,,,,
1709,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,1,9sph54,saberatalukder.com,"Article Describing Neuroengineering, A Little ML at the End",https://www.reddit.com/r/MachineLearning/comments/9sph54/article_describing_neuroengineering_a_little_ml/,ScienTecht,1540916582,,0,1,False,https://b.thumbs.redditmedia.com/Ub30f0IKGjokBBv3ECJ5kL8upRsOTiQI8LWH3FHPDoM.jpg,,,,,
1710,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,1,9spi3b,self.MachineLearning,[D] Idea About New Type of Neural Nets,https://www.reddit.com/r/MachineLearning/comments/9spi3b/d_idea_about_new_type_of_neural_nets/,MemoriesThatUCall,1540916763," 

I am just a layman and do not have much knowledge of neural nets, but I do have a basic grasp of the fundamentals.

From what I understand, there are multiple layers, and between each layer are nodes that connect each other with a number between 1 and 0. After learning from the inputs and outputs, the neural net weighs these 1 and 0s with a weighting, and over time, the network learns the optimal weighting between the different layers and nodes.

What if instead of just a number on a 1 dimensional spectrum, you have a 2D or even 3D connection? Where you can basically a bunch of different numbers each representing a dimension and weight on that connection? That way, instead of having 1 layer only talking with 1 other layer, you can branch out and interact with multiple layers at the same time, each with a different weight? You can also have a more granular and detailed breakdown of the weighting as you are measuring data in multiple dimensions? It seems like it would perform a lot more powerfully and get better results.

Does this exists in the world of neural nets? I am sorry if its unclear, and I can elaborate more if it doesnt make sense.",10,1,False,self,,,,,
1711,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,1,9splr9,arxiv.org,"[R] ""CurriculumNet: Weakly Supervised Learning from Large-Scale Web Images"", Guo et al 2018 {Malong} [WebVision]",https://www.reddit.com/r/MachineLearning/comments/9splr9/r_curriculumnet_weakly_supervised_learning_from/,gwern,1540917434,,0,1,False,default,,,,,
1712,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,2,9spt7d,twitter.com,"Well structured and perfectly paced course with experienced and engaging instructors, covering modeling in both Python and R. But the intuition part can be improved.Especially SVM and CNN modules went over my head and similar problem was faced by other students as well.",https://www.reddit.com/r/MachineLearning/comments/9spt7d/well_structured_and_perfectly_paced_course_with/,usualyprogramming,1540918821,,0,1,False,default,,,,,
1713,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,2,9spw5g,self.MachineLearning,[P] Google AI open-sources a TensorFlow framework for fast and flexible AutoML with learning guarantees,https://www.reddit.com/r/MachineLearning/comments/9spw5g/p_google_ai_opensources_a_tensorflow_framework/,cweill,1540919327,"Today, were announcing our open source TensorFlow framework for AutoML! 

**Google AI Blog**: [https://ai.googleblog.com/2018/10/introducing-adanet-fast-and-flexible.html](https://ai.googleblog.com/2018/10/introducing-adanet-fast-and-flexible.html).

**GitHub**: [https://github.com/tensorflow/adanet](https://github.com/tensorflow/adanet)

**Tutorials**: [https://github.com/tensorflow/adanet/tree/master/adanet/examples/tutorials](https://github.com/tensorflow/adanet/tree/master/adanet/examples/tutorials)

This project is based on the AdaNet algorithm from [Cortes et al., 2017](https://arxiv.org/abs/1607.01097), for learning the structure of a neural network as an ensemble of subnetworks. 

We created this framework to automatically change the TensorFlow graph as it learns from the performance of neural networks with different architectures and hyperparameters on large-scale datasets. Since this is a unique functionality that is packaged nicely as an Estimator, we wanted to share it with the ML community.

AdaNet provides the following features:

* An Estimator API for easily training, evaluating, and serving AdaNet models.
* Learns to ensemble user-defined subnetworks in TensorFlow.
* An interface for searching over subnetwork architectures and parameters *in a single train() call*.
* Distributed training on CPU and GPU (were working on TPU support).
* First-class TensorBoard integration.
* An objective that offers theoretical learning guarantees.

A few of the project and original paper **authors are here today** to reply to questions/comments.",33,1,False,self,,,,,
1714,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,2,9sq1nx,self.MachineLearning,"[D] Compilation/Labeling of Machine Learning Datasets, the ones that require significant Manual work.",https://www.reddit.com/r/MachineLearning/comments/9sq1nx/d_compilationlabeling_of_machine_learning/,AyansinhaJU,1540920343,"So I suppose there are Datasets which are more difficult to label (than say labeling dog/cat breeds or object classes), and someone has to manually label them for Models to successfully learn something from them (Masks for Cars, let's say). So which are the specific problems/applications which require more of this type of data and how/by whom are they done mostly at present? Pointers would be helpful. ",2,1,False,self,,,,,
1715,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,2,9sq7ko,self.MachineLearning,[R] Improving Tomographic Reconstruction from Limited Data Using Mixed-Scale Dense Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/9sq7ko/r_improving_tomographic_reconstruction_from/,757cbdb0b61385577130,1540921428,"Title: Improving Tomographic Reconstruction from Limited Data Using Mixed-Scale Dense Convolutional Neural Networks  


Journal: J. Imaging 2018, 4(11), 128  


DOI: 10.3390/jimaging4110128  


Journal link: [https://www.mdpi.com/2313-433X/4/11/128](https://www.mdpi.com/2313-433X/4/11/128)  


HTML Full-Text: [https://www.mdpi.com/2313-433X/4/11/128/htm](https://www.mdpi.com/2313-433X/4/11/128/htm)  


PDF Full-Text: [https://www.mdpi.com/2313-433X/4/11/128/pdf](https://www.mdpi.com/2313-433X/4/11/128/pdf)  


Abstract:  


In many applications of tomography, the acquired data are limited in one or more ways due to unavoidable experimental constraints. In such cases, popular direct reconstruction algorithms tend to produce inaccurate images, and more accurate iterative algorithms often have prohibitively high computational costs. Using machine learning to improve the image quality of direct algorithms is a recently proposed alternative, for which promising results have been shown. However, previous attempts have focused on using encoderdecoder networks, which have several disadvantages when applied to large tomographic images, preventing wide application in practice. Here, we propose the use of the Mixed-Scale Dense convolutional neural network architecture, which was specifically designed to avoid these disadvantages, to improve tomographic reconstruction from limited data. Results are shown for various types of data limitations and object types, for both simulated data and large-scale real-world experimental data. The results are compared with popular tomographic reconstruction algorithms and machine learning algorithms, showing that Mixed-Scale Dense networks are able to significantly improve reconstruction quality even with severely limited data, and produce more accurate results than existing algorithms.",0,1,False,self,,,,,
1716,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,2,9sqcqs,self.MachineLearning,[D] How do I get an Arxiv referral?,https://www.reddit.com/r/MachineLearning/comments/9sqcqs/d_how_do_i_get_an_arxiv_referral/,rampant_juju,1540922352,"I recently presented at a Machine Learning/Big Data conference, and want to list the paper on my resume. The conference proceedings will take a few months to come out. I don't have anybody in my network who can refer me for the Arxiv ""Machine Learning"" tag. What do?",11,1,False,self,,,,,
1717,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,3,9sqetj,self.MachineLearning,Cant we train one deep learning system to use other deep learning systems.,https://www.reddit.com/r/MachineLearning/comments/9sqetj/cant_we_train_one_deep_learning_system_to_use/,asdfghqw8,1540922635,[removed],0,1,False,self,,,,,
1718,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,3,9sqg4n,github.com,[P] A 1 Year Machine Learning Journey,https://www.reddit.com/r/MachineLearning/comments/9sqg4n/p_a_1_year_machine_learning_journey/,andri27-ts,1540922868,,0,1,False,default,,,,,
1719,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,3,9sqm6h,self.MachineLearning,[D] Proven use cases of Deep Learning for NLP tasks (excl. speech recognition and machine translation),https://www.reddit.com/r/MachineLearning/comments/9sqm6h/d_proven_use_cases_of_deep_learning_for_nlp_tasks/,amarofades,1540923961,"DL has made breakthrough in tasks such as object classification and detection, and the technology has been applied to real-world use cases such as facial ID, security surveillance, photo apps, etc.

I wonder, besides speech recognition and machine translation, what are the other proven use cases in NLP that utilize DL? By proven, I mean that DL has been shown to improve the task performance significantly in both research and real-world applications. Text-to-speech, summarization, or something else?",11,1,False,self,,,,,
1720,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,4,9sr81b,realworldnlpbook.com,Improving a Sentiment Analyzer using ELMo  Word Embeddings on Steroids,https://www.reddit.com/r/MachineLearning/comments/9sr81b/improving_a_sentiment_analyzer_using_elmo_word/,mhagiwara,1540928001,,0,1,False,https://b.thumbs.redditmedia.com/x92AB8QJ7dV7g6lvfcwF2tsyRY0mH728qQ9RV2ccuqc.jpg,,,,,
1721,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,4,9srg0b,self.MachineLearning,"I've been thinking of an idea related to learning representation and I'd appreciate some input, because I wasn't able to find any literature that's close to what I have in mind",https://www.reddit.com/r/MachineLearning/comments/9srg0b/ive_been_thinking_of_an_idea_related_to_learning/,settinghead,1540929436,[removed],0,1,False,self,,,,,
1722,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,5,9srlzj,self.MachineLearning,MACKRL: Multi-Agent Common Knowledge Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/9srlzj/mackrl_multiagent_common_knowledge_reinforcement/,casdewitt,1540930502,[removed],0,1,False,self,,,,,
1723,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,5,9srpbf,self.MachineLearning,"[P] Training a Bidirectional LSTM model for a ""fill in the blanks"" problem.",https://www.reddit.com/r/MachineLearning/comments/9srpbf/p_training_a_bidirectional_lstm_model_for_a_fill/,CSGOvelocity,1540931110,"I am making a project where in I train a Bi-LSTM to predict a blank that is in a sentence.

So for when the blank is somewhere in the middle (NOT in the end OR beginning), I have decided to use Bi-LSTM as it will be able to take the whole sentence and not just the part before/after the blank.

My question is how do I train it?

Do I train it on a text corpus and teach it to predict the next word ? 

Or do I prepare the dataset and teach it to predict a blank which I will encode as a token. As in have sentence and target pairs for example:  


Alfred is a \_\_\_\_ dog -&gt; good

Apple is a \_\_\_\_\_ fruit -&gt; red

etc.

Also, in case of the latter how do I feed in the whole encoded sentence and ""tell"" the network to predict the encoded blank as it will be a ""n-&gt;1"" prediction (feeding in n words and predicting 1) ?

Please ask for any further clarification that is required.",10,1,False,self,,,,,
1724,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,5,9srzr9,self.MachineLearning,[R] Ordered Neurons: Integrating Tree Structures into Recurrent Neural Networks,https://www.reddit.com/r/MachineLearning/comments/9srzr9/r_ordered_neurons_integrating_tree_structures/,visarga,1540933028,"Interesting use of cumsum with softmax to create hierarchical gating inside LSTMs, improving long-term dependency.

https://arxiv.org/abs/1810.09536",0,1,False,self,,,,,
1725,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,5,9ss08o,self.MachineLearning,'categorical_crossentropy' does nothing but 'sparse_categorical_crossentropy' yields very good results,https://www.reddit.com/r/MachineLearning/comments/9ss08o/categorical_crossentropy_does_nothing_but_sparse/,trispi,1540933123,[removed],0,1,False,self,,,,,
1726,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,7,9ssrnw,self.MachineLearning,Concise Cheat Sheets of Machine Learning with Python (and Maths),https://www.reddit.com/r/MachineLearning/comments/9ssrnw/concise_cheat_sheets_of_machine_learning_with/,skj8,1540938311,[removed],0,1,False,self,,,,,
1727,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,7,9sszrb,arxiv.org,"tempoGAN: A Temporally Coherent, Volumetric GAN for Super-resolution Fluid Flow",https://www.reddit.com/r/MachineLearning/comments/9sszrb/tempogan_a_temporally_coherent_volumetric_gan_for/,PresentCompanyExcl,1540939936,,0,1,False,default,,,,,
1728,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,8,9st9q5,self.MachineLearning,What type of model to use to predict retirement based on my past spending?,https://www.reddit.com/r/MachineLearning/comments/9st9q5/what_type_of_model_to_use_to_predict_retirement/,5Doum,1540941873,[removed],0,1,False,self,,,,,
1729,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,8,9stfgq,self.MachineLearning,"What are the practical differences between 1080ti, 2080ti, and the Titan V for machine learning?",https://www.reddit.com/r/MachineLearning/comments/9stfgq/what_are_the_practical_differences_between_1080ti/,smashMaster3000,1540943028,"Hi, I have a budget of approximately $3k and I was wondering what combination of graphics cards would be most optimal for training large models. ",0,1,False,self,,,,,
1730,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,8,9stgf5,self.MachineLearning,Project PAI  Personal Artificial Intelligence on the Blockchain,https://www.reddit.com/r/MachineLearning/comments/9stgf5/project_pai__personal_artificial_intelligence_on/,kevcasper,1540943213,"""California-based ObEN came to the Bradfield Centre this week, brandishing its innovative avatar  PAI  and looking to invest up to $1million in pilot projects applying personalized AI technology in digital healthcare innovations.

PAI  Personalised Artificial Intelligence  is unique in that it is based on a decentralized AI platform for intelligent 3D avatars, and is authenticated and secured on the blockchain, so your data is safe. The PAI avatar is an app which runs on your smartphone. Its use of KYC (Know Your Customer) blockchain technology provides the security consumers require when engaging with the avatar. You can shop on PAI, organize meetings, send messages, and it can speak different languages.""

They were just featured in the Cambridge Independent. I think they're super under the radar. They seem to already have a wallet out for you to eventually buy and sell AI data for your virtual avatar. Check out the details here: [https://projectpai.com/](https://projectpai.com/)

They seem to be backed by huge companies too like Tencent and Vive HTC. I'm gonna check out their event at UCLA tomorrow. Anyone else in the LA area checking this out? It's free.

[https://www.eventbrite.com/e/personal-artificial-intelligence-on-the-blockchain-hosted-by-ucla-oben-tickets-50983753780](https://www.eventbrite.com/e/personal-artificial-intelligence-on-the-blockchain-hosted-by-ucla-oben-tickets-50983753780)

Project PAI Telegram:  
[https://t.me/projectpai](https://t.me/projectpai)",0,1,False,self,,,,,
1731,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,8,9stifq,self.MachineLearning,Transitioning from a Computational Neuroscience PhD to Machine Learning Research. What math and skills?,https://www.reddit.com/r/MachineLearning/comments/9stifq/transitioning_from_a_computational_neuroscience/,Stereoisomer,1540943606,[removed],0,1,False,self,,,,,
1732,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,9,9stt2f,github.com,How to Grow Neat Software Architecture out of Jupyter Notebooks,https://www.reddit.com/r/MachineLearning/comments/9stt2f/how_to_grow_neat_software_architecture_out_of/,GChe,1540945749,,0,1,False,default,,,,,
1733,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,9,9sttj3,self.MachineLearning,Train a supermario with Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/9sttj3/train_a_supermario_with_deep_reinforcement/,wonseokjung,1540945841,[removed],0,1,False,self,,,,,
1734,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,9,9stvto,i.redd.it,Percia Judicial - PENHORA de Faturamento III,https://www.reddit.com/r/MachineLearning/comments/9stvto/percia_judicial_penhora_de_faturamento_iii/,JamurGerloff,1540946319,,0,1,False,https://a.thumbs.redditmedia.com/cIUjOhiCk8QMb768_45SN4i0Js8k1Sp-jeLyWR7Vmg8.jpg,,,,,
1735,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,10,9su20i,github.com,supermario,https://www.reddit.com/r/MachineLearning/comments/9su20i/supermario/,wonseokjung,1540947647,,0,1,False,default,,,,,
1736,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,10,9su24l,self.MachineLearning,[D] Bayesian Global Optimization - Using Optimal Learning to Tune Machine Learning Models,https://www.reddit.com/r/MachineLearning/comments/9su24l/d_bayesian_global_optimization_using_optimal/,shonburton,1540947671,"One of MLconf's most popular recent talks is from Scott Clark on Bayesian Global Optimization - Using Optimal Learning to Tune Machine Learning Models. Watch the full presentation here:  


[https://www.youtube.com/watch?v=J6UcAdH54RE](https://www.youtube.com/watch?v=J6UcAdH54RE)

  
Our next event is on November 14th in SF. We will upload the talks to our YouTube Channel. If you'd like to join us in person redditors can get a 35% discount using code ""SlashML"" here:   


[https://www.eventbrite.com/e/mlconf-sf-2018-tickets-45989163827](https://www.eventbrite.com/e/mlconf-sf-2018-tickets-45989163827)

&amp;#x200B;

&amp;#x200B;

&amp;#x200B;",1,1,False,self,,,,,
1737,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,10,9su3qb,self.MachineLearning,How Much Memory Should DQN Use?,https://www.reddit.com/r/MachineLearning/comments/9su3qb/how_much_memory_should_dqn_use/,ElJefesDisciple,1540947994,"I'm curious about how much GPU memory DQN should be using? It's just the two networks' parameters in the memory right? 

&amp;#x200B;

I'm using a 3 hidden layer MLP network with 100 neurons in each layer and it is using nearly 12 GB of GPU memory. This seems extremely high for how many parameters are in my network(\~3\*100\*100 + 300 each being a 32 bit = 4 byte float is about 120000 bytes for each network an order of magnitude lower.) I tried with smaller network sizes (single layer) and it doesn't seem to decrease significantly. I'm not using images either so that can't be it.

&amp;#x200B;

Are there other good open source DQN implementations that use less memory that I could try? I'd prefer not to use Open AI Baselines since those are poorly maintained.",0,1,False,self,,,,,
1738,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,10,9su4x9,self.MachineLearning,Training a Supermario through Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/9su4x9/training_a_supermario_through_deep_reinforcement/,wonseokjung,1540948244,[removed],0,1,False,self,,,,,
1739,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,10,9subbj,i.redd.it,Percia Judicial - PENHORA de Faturamento III,https://www.reddit.com/r/MachineLearning/comments/9subbj/percia_judicial_penhora_de_faturamento_iii/,JamurGerloff,1540949581,,0,1,False,https://a.thumbs.redditmedia.com/cIUjOhiCk8QMb768_45SN4i0Js8k1Sp-jeLyWR7Vmg8.jpg,,,,,
1740,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,10,9sufso,arxiv.org,[R] Insect cyborgs: Biological feature generators improve machine learning accuracy on limited data,https://www.reddit.com/r/MachineLearning/comments/9sufso/r_insect_cyborgs_biological_feature_generators/,PresentCompanyExcl,1540950525,,4,1,False,default,,,,,
1741,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,10,9suimj,arxiv.org,"[R] tempoGAN: A Temporally Coherent, Volumetric GAN for Super-resolution Fluid Flow",https://www.reddit.com/r/MachineLearning/comments/9suimj/r_tempogan_a_temporally_coherent_volumetric_gan/,PresentCompanyExcl,1540951124,,1,1,False,default,,,,,
1742,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,11,9suk70,self.MachineLearning,[D] I've been thinking of an idea related to learning representation and I'd appreciate some input,https://www.reddit.com/r/MachineLearning/comments/9suk70/d_ive_been_thinking_of_an_idea_related_to/,settinghead,1540951453,[removed],0,1,False,self,,,,,
1743,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,11,9suy91,youtube.com,[P] MLSS 2018 Madrid Videos,https://www.reddit.com/r/MachineLearning/comments/9suy91/p_mlss_2018_madrid_videos/,satsatsat,1540954573,,0,1,False,default,,,,,
1744,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,12,9suzwm,i.redd.it,Top 10 anime betrayals,https://www.reddit.com/r/MachineLearning/comments/9suzwm/top_10_anime_betrayals/,hennypennypoopoo,1540954937,,1,1,False,https://a.thumbs.redditmedia.com/pjqhvxnRuRrQ8KQvP7SCphg-pu5ZmzidTGtD5cZBGO8.jpg,,,,,
1745,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,12,9sv4vx,self.MachineLearning,[R] Generating Memoji from Photos...,https://www.reddit.com/r/MachineLearning/comments/9sv4vx/r_generating_memoji_from_photos/,patniemeyer,1540956087,"I recently did some very basic experiments in which I used VGG Face to compare real world photos with Apple Memoji characters and tried to have it guide the creation of new ones.  I've written it up here:

[https://patniemeyer.github.io/2018/10/29/generating-memoji-from-photos.html](https://patniemeyer.github.io/2018/10/29/generating-memoji-from-photos.html)

I'd be interested in any feedback and ideas on how I could improve the results.  In particular I had a lot of trouble with skin tone and hair color.  Hair color worked pretty well for basic light and dark hair but completely failed to match brightly colored hair in the way that I expected.

Thanks!

&amp;#x200B;",11,1,False,self,,,,,
1746,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,12,9svaio,self.MachineLearning,Time Series Analysis using LSTM,https://www.reddit.com/r/MachineLearning/comments/9svaio/time_series_analysis_using_lstm/,Abhishekmamidi,1540957458,[removed],0,1,False,self,,,,,
1747,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,13,9svilg,self.MachineLearning,Free big data event at Stanford,https://www.reddit.com/r/MachineLearning/comments/9svilg/free_big_data_event_at_stanford/,Jessica-100,1540959441,[removed],0,1,False,self,,,,,
1748,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,14,9svs62,self.MachineLearning,[D] How do you measure performance for word prediction tasks?,https://www.reddit.com/r/MachineLearning/comments/9svs62/d_how_do_you_measure_performance_for_word/,rampant_juju,1540962047,"Say I have to predict the next word in a sentence, given the initial few words. 

Suppose the prefix is ""I went to _____"". This prefix is common enough that it might appear 10 times in the training data with a few different variations:

Sentence | Count 
--- | ---
I went to **college** | 5
I went to **California** | 3
I went to **London** | 2

In such a case, suppose my model predicts ""college"" as the right answer. It would still get only a 50% score if I used accuracy as a metric. How do I solve this?",14,1,False,self,,,,,
1749,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,14,9svxi0,self.MachineLearning,Do you think there is a market for pretrained machine learning models?,https://www.reddit.com/r/MachineLearning/comments/9svxi0/do_you_think_there_is_a_market_for_pretrained/,orgesleka,1540963572,[removed],0,1,False,self,,,,,
1750,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,15,9sw4c2,self.MachineLearning,Industry_4.0 #AI Services From MANNYA!,https://www.reddit.com/r/MachineLearning/comments/9sw4c2/industry_40_ai_services_from_mannya/,MannyaTS,1540965658,[removed],0,1,False,self,,,,,
1751,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,15,9sw5xq,self.MachineLearning,Sight Machines Enterprise Manufacturing Analytic to Improve Production - Highest Demand.,https://www.reddit.com/r/MachineLearning/comments/9sw5xq/sight_machines_enterprise_manufacturing_analytic/,JackWallner2,1540966143,[removed],0,1,False,self,,,,,
1752,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,15,9sw62k,self.MachineLearning,Is anyone aware of specialized multi-label classification architectures/networks for COCO?,https://www.reddit.com/r/MachineLearning/comments/9sw62k/is_anyone_aware_of_specialized_multilabel/,magkum123,1540966188,"Or any suggestions? (other than Object Detectors, or ResNets with Multilabel losses). My goal is to classify all the classes present in the COCO dataset with hopefully a high mAP. ",0,1,False,self,,,,,
1753,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,15,9sw6yv,self.MachineLearning,[D] How good are InfoGAN and VAE for continuous latent variables with unbalanced database? (more details and specific DB are in the post),https://www.reddit.com/r/MachineLearning/comments/9sw6yv/d_how_good_are_infogan_and_vae_for_continuous/,kiwi0fruit,1540966457,"Assuming we have a psychological survey database that contains continuous and non-linear dependencies. But people with different personality traits are imbalanced in the database: some kind of people almost never consider taking a survey and some other kinds like to take the survey.

And there is an external tool that is a rough approximation that can classify survey entities into discrete classes (but in reality there is no discrete classes!). And some classes have ten times more samples than other. And... I guess this can help to balance the DB somehow.

Are InfoGAN or VAE capable of learning balanced latent variable space as if the original database was balanced (or close to this)? Do you have any advice on approach how to balance?
",3,1,False,self,,,,,
1754,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,15,9swc6f,alibabacloud.com,Using Machine Learning for Automatic Label Classification,https://www.reddit.com/r/MachineLearning/comments/9swc6f/using_machine_learning_for_automatic_label/,Jen_Cl,1540968151,,0,1,False,https://a.thumbs.redditmedia.com/GWxpvHFgNGxr6QriM8-5PJyKmaqHOV9ikIJ9JGXrIw0.jpg,,,,,
1755,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,16,9swgyp,self.MachineLearning,Training logistic regression with only labeled 1 data.,https://www.reddit.com/r/MachineLearning/comments/9swgyp/training_logistic_regression_with_only_labeled_1/,taehyuk,1540969741,[removed],0,1,False,self,,,,,
1756,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,16,9swp11,self.MachineLearning,Any programs that can upscale video using AI?,https://www.reddit.com/r/MachineLearning/comments/9swp11/any_programs_that_can_upscale_video_using_ai/,HiFi2WiFi,1540972431,[removed],0,1,False,self,,,,,
1757,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,16,9swpdj,github.com,PyTorch to Keras deep neural network model converter,https://www.reddit.com/r/MachineLearning/comments/9swpdj/pytorch_to_keras_deep_neural_network_model/,nerox8664,1540972545,,0,1,False,default,,,,,
1758,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,17,9swynk,self.MachineLearning,Find multiple intents from a text,https://www.reddit.com/r/MachineLearning/comments/9swynk/find_multiple_intents_from_a_text/,achyuta786,1540975812,[removed],0,1,False,self,,,,,
1759,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,17,9swzsm,venturebeat.com,Google launches AdaNet for combining algorithms with AutoML,https://www.reddit.com/r/MachineLearning/comments/9swzsm/google_launches_adanet_for_combining_algorithms/,rsossl,1540976202,,0,1,False,https://b.thumbs.redditmedia.com/L-5jNBMoGxgBxVzunWA_a1S4CxqGEnFmjLY4YR-EeMg.jpg,,,,,
1760,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,17,9swzyc,youtube.com,"There is a YouTube Live Session on ""Data Science Interview Questions"" by Richard Kershner, live today at 8:00 PM IST/ 7:30 AM PST. Be sure to attend and get your queries answered.",https://www.reddit.com/r/MachineLearning/comments/9swzyc/there_is_a_youtube_live_session_on_data_science/,pooja307,1540976264,,0,1,False,default,,,,,
1761,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,18,9sx0d5,self.MachineLearning,[P] BERT-Pytorch: The First Implementation of Google's BERT Model and Training Process,https://www.reddit.com/r/MachineLearning/comments/9sx0d5/p_bertpytorch_the_first_implementation_of_googles/,codertimo,1540976418,"Google AI's BERT paper shows the amazing result on various NLP task (new 17 NLP tasks SOTA), including outperform the human F1 score on SQuAD v1.1 QA task. This paper proved that Transformer(self-attention) based encoder can be powerfully used as alternative of previous language model with proper language model training method. And more importantly, they showed us that this pre-trained language model can be transfer into any NLP task without making task specific model architecture.

This amazing result would be record in NLP history, and I expect many further papers about BERT will be published very soon. This is the implementation of BERT. Code is very simple and easy to understand fastly. Some of these codes are based on The Annotated Transformer

&amp;#x200B;

BERT-pytorch Github Link : [https://github.com/codertimo/BERT-pytorch](https://github.com/codertimo/BERT-pytorch)

Paper Link : [https://arxiv.org/abs/1810.04805](https://arxiv.org/abs/1810.04805)

BERT Authors Reddit Post : [https://www.reddit.com/r/MachineLearning/comments/9nfqxz/r\_bert\_pretraining\_of\_deep\_bidirectional/](https://www.reddit.com/r/MachineLearning/comments/9nfqxz/r_bert_pretraining_of_deep_bidirectional/)",11,1,False,self,,,,,
1762,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,18,9sx6dh,github.com,Hyperparameter Optimization for Keras Models,https://www.reddit.com/r/MachineLearning/comments/9sx6dh/hyperparameter_optimization_for_keras_models/,mikkokotila,1540978397,,0,1,False,https://b.thumbs.redditmedia.com/cTlBzimBjiZTv9mB2ItEIIJb8AtS0a5F_2Y0rHJ_5yQ.jpg,,,,,
1763,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,18,9sx83o,self.MachineLearning,Need help with Sentiment analysis on Amazon Reviews,https://www.reddit.com/r/MachineLearning/comments/9sx83o/need_help_with_sentiment_analysis_on_amazon/,the_rek,1540978984,[removed],0,1,False,self,,,,,
1764,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,19,9sxcay,devblogs.nvidia.com,[P] Deep Learning for Classifying Hotel Aesthetics Photos,https://www.reddit.com/r/MachineLearning/comments/9sxcay/p_deep_learning_for_classifying_hotel_aesthetics/,datitran,1540980336,,1,1,False,default,,,,,
1765,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,19,9sxfa1,arxiv.org,[R] Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/9sxfa1/r_gatherexcite_exploiting_feature_context_in/,xternalz,1540981182,,1,1,False,default,,,,,
1766,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,19,9sxfbp,self.MachineLearning,[Research] MACKRL: Multi-Agent Common Knowledge Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/9sxfbp/research_mackrl_multiagent_common_knowledge/,casdewitt,1540981196,[removed],0,1,False,self,,,,,
1767,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,19,9sxkd5,self.MachineLearning,[R] MACKRL: Multi-Agent Common Knowledge Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/9sxkd5/r_mackrl_multiagent_common_knowledge/,casdewitt,1540982671,[removed],0,1,False,self,,,,,
1768,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,19,9sxklp,self.MachineLearning,"Best Vastu Consultant | Best Vastushastra Consultant in Thane, Mumbai, India.",https://www.reddit.com/r/MachineLearning/comments/9sxklp/best_vastu_consultant_best_vastushastra/,vasturaviraj123,1540982739,[removed],0,1,False,self,,,,,
1769,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,20,9sxu1b,mattermore.io,"Helping AI / data scientist gurus around the world discover work opportunities to reverse climate change. Please, give feedback about my new passion project and sign up :)",https://www.reddit.com/r/MachineLearning/comments/9sxu1b/helping_ai_data_scientist_gurus_around_the_world/,mattermorehq,1540985308,,0,1,False,default,,,,,
1770,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,20,9sxyk8,dx.plos.org,[Paper] Statistical and Machine Learning forecasting methods: Concerns and ways forward,https://www.reddit.com/r/MachineLearning/comments/9sxyk8/paper_statistical_and_machine_learning/,theainerd,1540986510,,0,1,False,default,,,,,
1771,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,21,9sy7g1,self.MachineLearning,[D]I work under a famous researcher in a big company. He is my manager. He is trash talking about other employees work under him with me and yesterday he threw a shade at me in a group meeting,https://www.reddit.com/r/MachineLearning/comments/9sy7g1/di_work_under_a_famous_researcher_in_a_big/,MoreTrainer,1540988551,"I do not know whether I should post it here or in r/cscareerquestions. I feel like here we have matured Redditors as opposed to other subs. I am an AI scientist. Did my Ph.D. and joined a new job.  My manager is smart and intelligent. He is a prominent researcher in NLP. The problem is he trash talks about employees work under him with me. I find it very uneasy.  Yesterday, he threw me under the bus at the meeting. I wanted to work with him because of his reputation. Now I am second guessing.

Do you guys ever give up working with big researchers because of his/her lack of work ethics? ",108,1,False,self,,,,,
1772,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,21,9sycuc,self.MachineLearning,SOS!! PDF needed!,https://www.reddit.com/r/MachineLearning/comments/9sycuc/sos_pdf_needed/,MarielouFimo,1540989760,[removed],0,1,False,self,,,,,
1773,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,22,9symfk,self.MachineLearning,[D] Reverse-engineering a massive neural network,https://www.reddit.com/r/MachineLearning/comments/9symfk/d_reverseengineering_a_massive_neural_network/,born_in_cyberspace,1540991779," I'm trying to reverse-engineer a huge neural network. The problem is, it's essentially a blackbox. The creator has left no documentation, and the code is obfuscated to hell.    

Some facts that I've managed to learn about the network:

* it's a recurrent neural network
* it's huge: about 10\^11 neurons and about 10\^14 weights
* it takes 8K Ultra HD video (60 fps) as the input, and generates text as the output (100 bytes per second on average)
* it can do some image recognition and natural language processing, among other things

I have the following experimental setup:

* the network is functioning about 16 hours per day
* I can give it specific inputs and observe the outputs
* I can record the inputs and outputs (already collected several years of it)

Assuming that we have Google-scale computational resources, is it theoretically possible to successfully reverse-engineer the network? (meaning, we can create network that will produce similar outputs giving the same inputs) .

How many years of the input/output records do we need to do it?",180,1,False,self,,,,,
1774,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,23,9sz1zl,edyoda.com,FREE comprehensive course to learn - Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/9sz1zl/free_comprehensive_course_to_learn_deep/,iamarmaan,1540994902,,0,1,False,default,,,,,
1775,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,23,9sz27m,self.MachineLearning,How would I convert a CSV into a machine learneable format?,https://www.reddit.com/r/MachineLearning/comments/9sz27m/how_would_i_convert_a_csv_into_a_machine/,EzCZ-75,1540994949,[removed],0,1,False,self,,,,,
1776,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,23,9sz7cr,self.MachineLearning,[D] Continual learning on large images,https://www.reddit.com/r/MachineLearning/comments/9sz7cr/d_continual_learning_on_large_images/,numpee,1540995895,"So I've read a couple papers on the topic of continual learning (most notably [EWC](https://arxiv.org/abs/1612.00796), and [GEM](https://arxiv.org/abs/1706.08840)), but it seems that most papers only deal with small image datasets, such as MNIST variants, or in the case of GEM, incremental CIFAR100. I'm curious if anybody has tried something like EWC or GEM on larger image datasets, and if so, if the methods can achieve similar results on larger images. 

&amp;#x200B;",1,1,False,self,,,,,
1777,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,23,9sz91y,medium.com,[P] I used GAN to generate new Pokmon,https://www.reddit.com/r/MachineLearning/comments/9sz91y/p_i_used_gan_to_generate_new_pokmon/,laser_velociraptor,1540996214,,0,1,False,default,,,,,
1778,MachineLearning,t5_2r3gv,2018-10-31,2018,10,31,23,9szi88,self.MachineLearning,EPQ on Job Security with Machine Learning.,https://www.reddit.com/r/MachineLearning/comments/9szi88/epq_on_job_security_with_machine_learning/,chris_harris_15,1540997899,[removed],0,1,False,self,,,,,
