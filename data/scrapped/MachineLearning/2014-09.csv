,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2014-9-1,2014,9,1,15,2f5d8v,"Sales Organization has Sales data from 2012-Present, which data should I use?",https://www.reddit.com/r/MachineLearning/comments/2f5d8v/sales_organization_has_sales_data_from/,[deleted],1409552722,"I am using the SQL Server Data Mining Add-In (for Excel 2013) to forecast sales volume for the month.


Note(s):

1.) The company growth rate is extremely high, around 30% year-over-year.
2.) There is a large sales data set that shows sales by day, categorized by three seperate Regions spanning 2012-Present.

Question:
1.) If the growth rate is so high, should I only use more recent data?
2.) Should I do seperate forecasts for each of the three Regions and then total for the total forecast?
3.) Any other tips?
",4,0
1,2014-9-1,2014,9,1,15,2f5ew9,Simple Guide to Buying a Motor Grader - SimpleGuideTo,https://www.reddit.com/r/MachineLearning/comments/2f5ew9/simple_guide_to_buying_a_motor_grader/,jessicperson,1409554300,,0,1
2,2014-9-1,2014,9,1,19,2f5s06,Neural Network Illustrated  Step by Step,https://www.reddit.com/r/MachineLearning/comments/2f5s06/neural_network_illustrated_step_by_step/,[deleted],1409568659,,15,50
3,2014-9-1,2014,9,1,21,2f5y3c,A simple implementation of the ID3 algorithm.,https://www.reddit.com/r/MachineLearning/comments/2f5y3c/a_simple_implementation_of_the_id3_algorithm/,copybin,1409574921,,0,0
4,2014-9-2,2014,9,2,0,2f6brs,What are some high quality production ready deep learning libraries?,https://www.reddit.com/r/MachineLearning/comments/2f6brs/what_are_some_high_quality_production_ready_deep/,m3wm3wm3wm,1409585745,"Which deep learning libraries/frameworks do you use in production? Apart from a high quality implementation, I'm looking for those which come with state of the art algorithms.",8,1
5,2014-9-2,2014,9,2,0,2f6dns,Understanding Statlog german credit data (numeric) version,https://www.reddit.com/r/MachineLearning/comments/2f6dns/understanding_statlog_german_credit_data_numeric/,omnipresent101,1409587054,"I'm trying to use the stat log credit card data  set found here: https://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)

I would like to use the numeric version -  https://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)  but can't find any explanation on it. 

 - What do the numbers represent. There is no mapping of numbers to any information. 
 - Why are there extra attributes and what do they represent? (original data has 21 attributes whereas numeric has 25)

Am I missing something here? It seems without the attribute information, the data sett can't be used...

",1,0
6,2014-9-2,2014,9,2,1,2f6evf,Help: how do I get into a solid ML PhD program?,https://www.reddit.com/r/MachineLearning/comments/2f6evf/help_how_do_i_get_into_a_solid_ml_phd_program/,tyatyatya,1409587862,"I want to get into a solid ML PhD program (solid == having some recognition in the field). I think I probably don't have what it takes at the moment to achieve that, so I'm willing to devote some time to improve (I have savings for up to a couple years of self-study). BTW my interests skew more towards applications like computer vision, medical/geophysics imaging etc. (as oposed to pure stats/ML research), but i want to approach those problems from a ML perspective (a'la ""Computer Vision"" by Prince). 

I have a Bsc+Msc in CS from a technical university in Poland (it's one of the best in the country, sadly doesn't really have major cred outside). I am familiar with the ML field - my Msc thesis was in AI and ML, and I've worked for 2 years in a startup where I implemented ML-based products. I am aware that my knowledge of ML is mostly limited to that of a practitioner's and I most likely lack in some of the fundamentals required to do math-heavy research.

This brings me to my question - which subject to self-study and at what depth? I'm inclined to just go through everything obviously relevant (calculus, linear algebra, probability, statistics, machine learning) at a fairly deep level, working through ""harder"" textbooks (I'm currently plowing through Spivak's Calculus) and gaining solid mathematical foundations. However, I'm wondering if that's the smartest course of action - i.e. if this will even be enough to get me into a solid program - or, alternatively, if I could get in without going through some of the material (or by studying from less in-depth textbooks for now) and fill in the gaps by taking courses during first years of study. In other words - I don't really know how high the bar is set.",23,22
7,2014-9-2,2014,9,2,3,2f6pl3,Can both ReLUs and softmax be used? (nolearn python module seems to do it),https://www.reddit.com/r/MachineLearning/comments/2f6pl3/can_both_relus_and_softmax_be_used_nolearn_python/,Poydflink,1409595102,"Hello, I was trying some neural networks implementations and I found this one https://pythonhosted.org/nolearn/dbn.html intriguing. It seems that you can both use ReLUs and another activation function (such as softmax, linear or sigmoid) to train a neural network. Are those things different or is there an error in this implementation?",7,0
8,2014-9-2,2014,9,2,15,2f8jff,Using neural networks for nearest neighbor?,https://www.reddit.com/r/MachineLearning/comments/2f8jff/using_neural_networks_for_nearest_neighbor/,matlab484,1409638132,"I have seen neural networks used all the time for classification, but is there any tutorials/uses of neural networks on finding the nearest neighbor? Say for example, you are building a car finder which takes an input of a car image and tries to find a similar car in a list of images saved. Is this possible with neural networks?",14,4
9,2014-9-2,2014,9,2,17,2f8r67,Videos of ICML 2014 talks,https://www.reddit.com/r/MachineLearning/comments/2f8r67/videos_of_icml_2014_talks/,urish,1409646398,,15,54
10,2014-9-2,2014,9,2,19,2f8wqu,Machine Learning: Easy How-to Guides,https://www.reddit.com/r/MachineLearning/comments/2f8wqu/machine_learning_easy_howto_guides/,jm_ml,1409652966,,2,0
11,2014-9-2,2014,9,2,21,2f92xj,How Mimicking Brain Function is Revolutionising NLP,https://www.reddit.com/r/MachineLearning/comments/2f92xj/how_mimicking_brain_function_is_revolutionising/,[deleted],1409659371,,0,1
12,2014-9-2,2014,9,2,21,2f936c,How Mimicking Brain Function is Revolutionising NLP,https://www.reddit.com/r/MachineLearning/comments/2f936c/how_mimicking_brain_function_is_revolutionising/,jreacher,1409659602,,3,0
13,2014-9-2,2014,9,2,23,2f9ehu,How GPUs enable researchers to simulate the brains of bees,https://www.reddit.com/r/MachineLearning/comments/2f9ehu/how_gpus_enable_researchers_to_simulate_the/,DeathHamster1,1409667960,,0,11
14,2014-9-3,2014,9,3,4,2fa94s,Extracting opinion phrases from user reviews,https://www.reddit.com/r/MachineLearning/comments/2fa94s/extracting_opinion_phrases_from_user_reviews/,tarabos,1409684942,,0,0
15,2014-9-3,2014,9,3,6,2faqnf,Regression with inequalities?,https://www.reddit.com/r/MachineLearning/comments/2faqnf/regression_with_inequalities/,cypherx,1409694310,"I have a problem where I'd like to perform L1-penalized regression and a portion of my labels are lower bounds. 

So, I'd like to solve for `w` which minimizes ||w||_1 subject to w^T * x_i = y_i for i in 1 .. m and w^T * x_j &lt;= y_j for j in m+1 .. n. 

Is there a name for this kind of estimation problem? ""Constrained Lasso""? 

Are there any packages which perform the optimization on medium-sized data sets (~100k rows with ~500 features)? I've tried using generic convex optimization frameworks (cvx for Matlab and cvxopt for Python) but found them unworkably slow. 
",12,1
16,2014-9-3,2014,9,3,8,2faz9v,Prior for Bayesian analysis,https://www.reddit.com/r/MachineLearning/comments/2faz9v/prior_for_bayesian_analysis/,gadjo95,1409699135,"I am doing some Bayesian Analysis and a lot of time I'm stumbling upon the choice of prior. After a lot of reading and some experience, I get a feeling of how to choose a good prior for a specific problem. My problem is that I'll prefer a more 'scientific approach' when I choose it. 
From a lot of book I read, I always end up seeing this: ""Each of these steps should seem reasonable; however, the details (such as the 2 distributions and their degrees of freedom) are not particularly intuitive and must be derived using probability calculations that are beyond the scope of this book.""

So now my question is, what ressources (books, papers, even videos) are good explaining the underlying principle of choosing prior/distribution.",8,6
17,2014-9-3,2014,9,3,10,2fbd5r,My attempt as sarcasm detection,https://www.reddit.com/r/MachineLearning/comments/2fbd5r/my_attempt_as_sarcasm_detection/,MathieuCliche,1409707461,,47,65
18,2014-9-3,2014,9,3,13,2fbv9y,How to get out of a ML project rut?,https://www.reddit.com/r/MachineLearning/comments/2fbv9y/how_to_get_out_of_a_ml_project_rut/,CSGradStudent,1409719325,With all the research that goes on and all the cool ideas out there does anyone else feel overwhelmed when trying to work on their own projects? lately its been putting me into a rut and curious how some of you get out of it when you run into a rut in your work.,3,1
19,2014-9-3,2014,9,3,13,2fbw7i,Kernel Methods Match Deep Neural Networks On TIMIT,https://www.reddit.com/r/MachineLearning/comments/2fbw7i/kernel_methods_match_deep_neural_networks_on_timit/,exellentpossum,1409720041,,16,14
20,2014-9-3,2014,9,3,15,2fc4m4,Time series analysis?,https://www.reddit.com/r/MachineLearning/comments/2fc4m4/time_series_analysis/,invaluable,1409727387,"In a few weeks I will start a project at work where I have to do time series analysis. The customer will inject changes in their process, and it is going to be my work to detect this change, and be able to predict future change in output from changes in input. The lag in output may be anything from a few days up to several weeks.

Now, I have done a lot of machine learning, and numerical/scientific computing, but never any time series analysis.

Does anyone have any ideas for where I should start reading up on the subject? Maybe you know of any good papers or books where things like this are covered?",5,8
21,2014-9-4,2014,9,4,0,2fd25p,Facial detection methods/libraries,https://www.reddit.com/r/MachineLearning/comments/2fd25p/facial_detection_methodslibraries/,CreativePunch,1409757278,"Hi all,

I was wondering: what are some of the most widely used and best methods for performing facial detection? And are there any libraries available, preferably for python?

To clarify: I am talking about detecting if one or more faces are present in a picture and if so, where? (X,Y coordinates). I don't require it to be capable of recignizing the face, merely detecting where it's located on the image.

Thanks!",13,8
22,2014-9-4,2014,9,4,1,2fd7pq,Struggling with SVMs and having a hard time figuring out what I'm wrong about.,https://www.reddit.com/r/MachineLearning/comments/2fd7pq/struggling_with_svms_and_having_a_hard_time/,juckele,1409760360,"EDIT: I posted this on stack exchange and learned the answer. LIBSVM doesn't perform the optimization I mention of representing a linear SVM as a single vector. LIBLINEAR does. I should be using LIBLINEAR instead of LIBSVM if I want to use a linear kernel. http://stats.stackexchange.com/questions/114204/linear-svm-prediction-time-is-scaling-in-an-unexpected-manner-based-on-training



I've been playing with SVMs for the past week or so and I'm pretty vexed at this point so I'm hoping someone will have some insight into what I've overlooked. I'm using LIBSVM to do some training as it was recommended by Andrew Ng and is used under the hood in SciKit Learn. LIBSVM is doing something different than what I expect though:

My beliefs are as follows:  
\-LIBSVM when set to use a linear kernel is a reasonable implementation of a linear SVM  
\-A linear SVM model should just be a hyper plane and a margin.  
\-A n-1 dimensional hyper-plane can be represented by a single n dimensional vector and constant.  
\-A prediction performed against a single hyper-plane should be constant with respect to the number of training examples used to train the model.  
\-Linear kernel SVMs are roughly equivalent to logistic regression.  

My understanding is challenged though. LIBSVM models trained with a linear kernel show different prediction times depending on how the model was trained. When I look in the model file, there are many vectors in the file instead of a single one.

Can anyone illuminate what I am missing?",8,3
23,2014-9-4,2014,9,4,3,2fdp2q,Absolute fastest Bayesian Network library for extremely large networks,https://www.reddit.com/r/MachineLearning/comments/2fdp2q/absolute_fastest_bayesian_network_library_for/,jbiz1,1409769874,What Bayesian net library is best suited for quickly updating nodes and connections within very large networks?,1,0
24,2014-9-4,2014,9,4,4,2fdth1,Neural Networks and Deep Learning.,https://www.reddit.com/r/MachineLearning/comments/2fdth1/neural_networks_and_deep_learning/,qkdhfjdjdhd,1409772240,,2,1
25,2014-9-4,2014,9,4,5,2fe04o,Making a Bayesian Model to Infer Uber Rider Destinations,https://www.reddit.com/r/MachineLearning/comments/2fe04o/making_a_bayesian_model_to_infer_uber_rider/,carmichael561,1409775738,,8,26
26,2014-9-4,2014,9,4,13,2ffbxq,Framework to build a niche dictionary for text mining,https://www.reddit.com/r/MachineLearning/comments/2ffbxq/framework_to_build_a_niche_dictionary_for_text/,kunalj101,1409803987,,0,0
27,2014-9-4,2014,9,4,13,2ffejw,Why don't researchers use the kernel method in neural networks?,https://www.reddit.com/r/MachineLearning/comments/2ffejw/why_dont_researchers_use_the_kernel_method_in/,in_the_fresh,1409805981,"it seems like using kernel logistic regression units in a neural network would offer some advantages, despite being more computationally intensive to train. Is this something that researchers have tried and concluded it wasn't worth it? This is something that I have never encountered and am curious about... though maye be because i'm not well-read enough (yet!) ;) thanks!",18,6
28,2014-9-4,2014,9,4,17,2ffsyu,Why invent Maxout units? Wouldn't it be more efficient to...,https://www.reddit.com/r/MachineLearning/comments/2ffsyu/why_invent_maxout_units_wouldnt_it_be_more/,[deleted],1409820302,"Why invent Maxout units? Wouldn't it be more efficient to use mini neural nets with ReLU instead? Those mini nets would be able to approximate much wider range of activation functions than maxout units...

I mean if we got deep fully connected NN with 5 hidden layers and 2000 units in each layer, the network would have at least 16 million parameters. If we replace each unit with mini net that contain 3 hidden layers each consisting of 3 units we would add 24 parameters per unit (3+9+9+3), so total number of parameters additionally added to original 16+ million net would be 240,000.  

Wouldn't such net be more powerful while barely adding computational time and training time(increase in number of parameters is relatively small)? ",9,2
29,2014-9-4,2014,9,4,19,2ffx8h,"Science, Models and Machine Learning: introduction to feature extraction and cross-validation with applications to environmentalism.",https://www.reddit.com/r/MachineLearning/comments/2ffx8h/science_models_and_machine_learning_introduction/,DevFRus,1409825377,,0,1
30,2014-9-4,2014,9,4,19,2ffxmx,Ecml 2014 Papers,https://www.reddit.com/r/MachineLearning/comments/2ffxmx/ecml_2014_papers/,walrusesarecool,1409825821,,6,2
31,2014-9-4,2014,9,4,20,2fg0va,What I learned from competing against a ConvNet on ImageNet,https://www.reddit.com/r/MachineLearning/comments/2fg0va/what_i_learned_from_competing_against_a_convnet/,benanne,1409829391,,9,70
32,2014-9-4,2014,9,4,23,2fgdbl,Simple explanation of Regression concepts,https://www.reddit.com/r/MachineLearning/comments/2fgdbl/simple_explanation_of_regression_concepts/,akc_c,1409839348,,0,0
33,2014-9-4,2014,9,4,23,2fggmy,K-Means,https://www.reddit.com/r/MachineLearning/comments/2fggmy/kmeans/,liranreg,1409841390,"Hello all,
I'm new to this all field of machine learning, and i'm facing some problems that i though maybe you can shed some light on them due to your expertise, and i would really appreciate any help you can provide!


So basically, i have a lot of ""profiles"" (profile is a combination of internal attributes of my users), and each profiles got a ranked list of 10 items.
what i would like to achieve, is to divide the profiles into clusters, so in the end of the procedure each clusters will contain a group of profiles with similar lists.

for example,
if i have the following profile's lists:
A, B, C, D
B, A, C, D
A, F, G, E
A, F, G, K

then for k=2 clusters, the first two would form a cluster, and the last two would form a cluster.



here is my current idea. it is mostly based on my crazy mind, so i hope that i'm not making fun of myself :)

first, i created a distance function. its input is two ranked lists, and the output is a score ""how differ these lists are"", so the more they differ, the higher their distance is.
i still don't exactly know how to implement this function, but my current idea is to count how many items in A are not in B + how many items in B are not in A (this method doesn't take the position(rank) of each item in the list, so i'll have to figure it out.. maybe only consider ""not in"" when the index is at least 3 positions away..) - if you have a better idea i would love to hear

then, i created a ""lists average"" function that given a set of lists, calculates the ""center"" of those lists. kind of ""average"" list out of the list of lists.
i was thinking about calculating the average rank of each item, and then sort all items by their average rank, and declare the first 10 items as the result


now, after i created those two methods, i want to execute K-Means algorithm, with my distance function as the.. correct: my distance function
and the center of each cluster will get calculated from my ""lists average"" function.

so now with each iteration, i'll run over all my profiles, and assign each profile to the most similar cluster (shortest distance, using my distance function with input of the current profile's list and current cluster's center), and then recalculate the cluster's center using the ""lists average"" function.


i would really appreciate your feedback on all this, and also would love to hear how you would have attack such problem.
now, regarding my problems:
1. is there a way to insert my own custom function to calculate the cluster's center in the common libraries like Mahout?
2. in your experience, does K-Means is a good match for cases where i'll want to run over a few billions of profiles (lets say 5 billion), and assign them to about 100,000 clusters (K= 100,000) ? i would really appreciate if you share similar results from similar case studies you encountered
3. is there a way to take advantage of previous executions of the algorithm, and now given X profiles, include them in the clustering without the need to run over all the profiles again? (i understand that if i'll set the previous centers it would save a lot of iterations of the algorithm, but if there is a way or maybe another algorithm to also pass the iteration over the old profiles it would be great)


thank you so much again,
Liran",1,0
34,2014-9-5,2014,9,5,0,2fgl9r,"Dimensionality Reduction Techniques such as PCA, are considered Machine Learning or Statistics?",https://www.reddit.com/r/MachineLearning/comments/2fgl9r/dimensionality_reduction_techniques_such_as_pca/,doublebyte1,1409844004,,12,1
35,2014-9-5,2014,9,5,1,2fgrvc,Predicting the tips in the NewY ork City taxis,https://www.reddit.com/r/MachineLearning/comments/2fgrvc/predicting_the_tips_in_the_newy_ork_city_taxis/,[deleted],1409847738,,0,1
36,2014-9-5,2014,9,5,1,2fgt26,Predicting the tips in the New York City taxis,https://www.reddit.com/r/MachineLearning/comments/2fgt26/predicting_the_tips_in_the_new_york_city_taxis/,josemazo_reddit,1409848370,,2,1
37,2014-9-5,2014,9,5,3,2fh7bb,Resources for learning about deep neural networks?,https://www.reddit.com/r/MachineLearning/comments/2fh7bb/resources_for_learning_about_deep_neural_networks/,sebzim4500,1409855909,"I've just finished reading everything that is currently available on http://neuralnetworksanddeeplearning.com/. Unfortunately, Michael Nielson has not yet written anything on deep neural network specifically. What are some good learning resources that would serve as a continuation to 'neural networks and deep learning' (as it currently stands)?",2,3
38,2014-9-5,2014,9,5,5,2fhizh,ML approach for clustering of text data,https://www.reddit.com/r/MachineLearning/comments/2fhizh/ml_approach_for_clustering_of_text_data/,hm80,1409861835,"I am new to ML and this is my first post so I hope that this one is a good one :) . Here is what my problem is: 
 I need to cluster different descriptions of parts from catalog data from different vendors. I am trying to come up with algorithm that can detect clusters of similar descriptions. 

This is a sample dataset for one part number A100: [""COCPIT VOICE RECORDER"", ""RECORDER"", ""VOICE RECORDER"",""BELT"", ""REGULARTOR BELT"", ""OXIGEN REGULATOR"", ""BULB"", ""OXIGEN REG""]

From this dataset I need to discover clusters and associate them together?

Result will be : Cluster 1: [""COCPIT VOICE RECORDER"", ""RECORDER"", ""VOICE RECORDER""], Cluster 2 : [""BELT""], Cluster 3: [""OXIGEN REG"", ""OXIGEN REGULATOR""], Cluster 4: [""BULB""]

I never had experience with this but my basic research on ML shows that first thing you need to do is to extract features from data so I tried. 

My approach was to compare each and every one of these parts with each other using similarity function (i.e. edit_distance or Levenstain distance) . 

Then I was thinking to choose an algorithm for clustering? 

Any ideas if this feature selection is good? Any other idea about feature extraction or an approach to this problem?

Thanks !
",1,0
39,2014-9-5,2014,9,5,6,2fhri6,Machine Learning Gone Wrong: Why you should think about cost benefit on your prediction outcomes.,https://www.reddit.com/r/MachineLearning/comments/2fhri6/machine_learning_gone_wrong_why_you_should_think/,maxToTheJ,1409866407,,1,0
40,2014-9-5,2014,9,5,6,2fhry3,The science of crawl part 1: deduplication of web content,https://www.reddit.com/r/MachineLearning/comments/2fhry3/the_science_of_crawl_part_1_deduplication_of_web/,jisaacso,1409866657,,0,1
41,2014-9-5,2014,9,5,6,2fhtak,The Data Science Skills Network,https://www.reddit.com/r/MachineLearning/comments/2fhtak/the_data_science_skills_network/,bueller_off,1409867403,,0,0
42,2014-9-5,2014,9,5,8,2fi0i8,Machine Learning and DIY Recommendation Engines for Mom and Pop Ecommerce Shops,https://www.reddit.com/r/MachineLearning/comments/2fi0i8/machine_learning_and_diy_recommendation_engines/,LillianPierson,1409871701,,0,1
43,2014-9-5,2014,9,5,8,2fi18j,Morse Learning Machine challenge,https://www.reddit.com/r/MachineLearning/comments/2fi18j/morse_learning_machine_challenge/,ag1le,1409872121,"My **Morse Learning Machine Challenge** was approved by Kaggle last night.  [For details click here](http://ag1le.blogspot.com/2014/09/morse-learning-machine-challenge.html)

The goal of this competition is to build a machine that learns how to decode audio files containing Morse code. I hope to attract people  who are interested in solving new, difficult challenges using their predictive data modeling, computer science and machine learning expertise.

During the competition, the participants build a learning system capable of decoding Morse code. To that end, they get development data consisting of 200 .WAV audio files containing short sequences of randomized Morse code. The data labels are provided for a training set so the participants can self-evaluate their systems. To evaluate their progress and compare themselves with others, they can submit their prediction results on-line to get immediate feedback. A real-time Kaggle leaderboard shows participants their current standing based on their validation set predictions.

I have also provided  sample Python Morse decoder  to make it easier to get started. While this software is purely experimental version it has some features of the FLDIGI Morse decoder  but implemented using Python instead of C++.

Please help me to spread this message to attract participants for the Morse Learning Machine challenge!

The link to the challenge is [here!](https://inclass.kaggle.com/c/morse-challenge)

73 
Mauri AG1LE",13,7
44,2014-9-5,2014,9,5,8,2fi2y5,How to make spam poetry?,https://www.reddit.com/r/MachineLearning/comments/2fi2y5/how_to_make_spam_poetry/,kleer001,1409873168,"*tl;dr How do I word-salad?*

**edit:** answer : https://en.wikipedia.org/wiki/Markov_chain

**edit2:** example for fun!: http://projects.haykranen.nl/markov/demo/

Sorry for the super specific question. I do love the general topics and explanations that are usually posted here. And I'm sure the answer is straightforward enough, I just can't remember the terms. 

So, I guess my real question boils down to... What are the techniques used by spam bots to salad together bits of blogs and web text into something that appears lanuageish. It seems to me that it's not entirely random copy-paste, but there's some sort of ordering based on quintessential English language structuring. 

OR, what techniques would **you** use to slam together, say, Mary Shelly's Frankenstein and Lewis Carol's Alice in Wonderland?

Have you heard of anyone building a web based toy to do this? ",6,1
45,2014-9-5,2014,9,5,11,2fihra,1 to 2 Semester long project ideas in Machine Learning.,https://www.reddit.com/r/MachineLearning/comments/2fihra/1_to_2_semester_long_project_ideas_in_machine/,[deleted],1409882523,"The only experience that I've had in ML so far is taking Professor Andrew Ng's [course](https://www.coursera.org/course/ml) on Machine Learning on Coursera. Considering that are there any projects which I can do in approximately 1.5 semester's worth of time? I'm ready to spend some time in learning the concepts required but do you guys think this is something feasible or even the idea itself is outrageous?

I saw a similar question posted 2 years ago [here](http://www.reddit.com/r/MachineLearning/comments/okm5c/can_anyone_suggest_a_semester_project_related_to/) and seems they were suggesting projects on Kaggle. One more thing is that the problem itself should not be too trivial because I've to present it as a part of my final year b.tech. course. 

I really liked this one : https://www.kaggle.com/c/cifar-10 
Do you guys think this is something that can be done with my experience in ~1.5 semester's worth of time? 

PS : On a tangential note, will I be able to submit my results to Kaggle when the competition is not active? ",0,0
46,2014-9-5,2014,9,5,11,2filcy,Updating GMM with time ?,https://www.reddit.com/r/MachineLearning/comments/2filcy/updating_gmm_with_time/,[deleted],1409884849,"Suppose I have a set of N points at time t. I perform GMM (Gaussian Mixture Model) on it to get my initial result.

This is sort of like a heat map in gaming trying to keep track of a users probable location.

Now, I update the model at every new time step t+m, where m= 1,2,...
If I do not receive any new points, I want to gaussians to get smaller indicating a decrease in accuracy. With every new point, the model updates to reflect the new probable location.

I hope this made some sense. I am working on a very vague idea right now, would really appreciate some pointers on how to proceed with this.

EDIT : With further thought, I realized that I am looking for a weighted GMM technique. Each point has a weight associated with it which either decays/grows at every time step. I would still appreciate help on implementing this.",1,0
47,2014-9-5,2014,9,5,18,2fjbb3,Baidu says its massive deep-learning system is nearly complete,https://www.reddit.com/r/MachineLearning/comments/2fjbb3/baidu_says_its_massive_deeplearning_system_is/,mrprint,1409908175,,5,25
48,2014-9-5,2014,9,5,22,2fjq1i,Gaussian mixture models with weighted samples.,https://www.reddit.com/r/MachineLearning/comments/2fjq1i/gaussian_mixture_models_with_weighted_samples/,subszero,1409923157,"The images are not completely accurate of the gaussian curves, but I hope my question comes across clearly.

Standard Gaussian mixture modelling works along these lines. The blue points are the samples, all of the same weight.

[Standard GMM](http://i.imgur.com/cZy2JPl)

I am looking for a way to implement GMM/EM similar to the image below

[Modified GMM](http://i.imgur.com/EtAoxMX)

Here, each point has a weight associated with it as well.


I would be happy to use any existing library to do this. In case I need to modify EM algorithm to work with this case, I would appreciate some help.

",6,3
49,2014-9-5,2014,9,5,23,2fjxqv,Running isomap on audio?,https://www.reddit.com/r/MachineLearning/comments/2fjxqv/running_isomap_on_audio/,ninjeezy,1409928342,"I want to run isomap on a wav file, but the required input is a set of distances...how to you go from one to the other?",1,0
50,2014-9-6,2014,9,6,0,2fk0gx,Deep Learning for Education,https://www.reddit.com/r/MachineLearning/comments/2fk0gx/deep_learning_for_education/,atveit,1409929983,,0,0
51,2014-9-6,2014,9,6,1,2fka5t,Building a deep understanding of images (GoogLeNet ImageNet challenge description),https://www.reddit.com/r/MachineLearning/comments/2fka5t/building_a_deep_understanding_of_images_googlenet/,doomie,1409935707,,6,57
52,2014-9-6,2014,9,6,2,2fkbe9,Neural Networks and Deep Learning  the free online textbook,https://www.reddit.com/r/MachineLearning/comments/2fkbe9/neural_networks_and_deep_learning_the_free_online/,dmos62,1409936415,,7,32
53,2014-9-6,2014,9,6,4,2fksfm,Lasso regression with stochastic gradient descent?,https://www.reddit.com/r/MachineLearning/comments/2fksfm/lasso_regression_with_stochastic_gradient_descent/,cypherx,1409945988,"I'm reading Leon [Large-Scale Machine Learning with Stochastic Gradient Descent](http://leon.bottou.org/papers/bottou-2010) and I'm curious about the weight update equations he presents for L1-penalized regression. 

Bottou splits the weight vector into two positive components (u and v) and then updates each with:

    u[i] = max(0, u[i] - rate * (lambda - (y - dot(w,x)) * x[i])))
    v[i] = max(0, v[i] - rate * (lambda + (y - dot(w,x)) * x[i])))

where w is reconstructed as u - v. 

Any idea how/where Bottou derived these updates and does anyone have a proof handy that this actually achieves the optimum solution for the Lasso objective?",2,2
54,2014-9-6,2014,9,6,6,2fl5rm,Should the average prediction bucketed by a particular attribute be close to the average actual for that attribute?,https://www.reddit.com/r/MachineLearning/comments/2fl5rm/should_the_average_prediction_bucketed_by_a/,sanity,1409953764,"Imagine I'm predicting the probability that someone will buy a widget, based on some data about them.

I have a lot of training data of buy/no-buy decisions, and I know the age, gender, and eye color of each person - these are the input attributes to my predictive model.

Picking an attribute, say eye color, would I expect that the average of the buy probability predictions for people with blue eyes should be the same or close to the overall rate at which blue eye'd people buy the widgets?",7,0
55,2014-9-6,2014,9,6,9,2flkhr,What are some linearly inseparable classification data sets?,https://www.reddit.com/r/MachineLearning/comments/2flkhr/what_are_some_linearly_inseparable_classification/,gavinmh,1409963226,Are there any publicly available data sets (other than Iris and MNIST) that have linearly inseparable classes? I am looking for data sets that would be suitable for demonstrating multi-layer perceptrons.,4,1
56,2014-9-6,2014,9,6,9,2flkys,"As someone interested in getting into machine learning, what's the coolest thing you can show me that's been done with it?",https://www.reddit.com/r/MachineLearning/comments/2flkys/as_someone_interested_in_getting_into_machine/,[deleted],1409963563,What's the most fascinating machine learning thing you've seen? I'm interested!,19,14
57,2014-9-6,2014,9,6,21,2fmtti,Zoubin Ghahramani is taking our jerbs,https://www.reddit.com/r/MachineLearning/comments/2fmtti/zoubin_ghahramani_is_taking_our_jerbs/,AmusementPork,1410007562,,9,24
58,2014-9-6,2014,9,6,22,2fmxjg,Advice to someone who is starting his MS in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/2fmxjg/advice_to_someone_who_is_starting_his_ms_in/,newMachinist,1410011165,"Hey guyz,
I begin my MS in machine learning course from Monday. Care to share any tips that would help me maximize my studies and understanding? Also are there any courses that I must/should take as electives other than the compulsory ones?
And the last Is there anything that I can start doing from today which would help me get internships? (Where should I look and what should I do)?

My college in a foreign country so I could use as much as help that I get 
",12,1
59,2014-9-7,2014,9,7,4,2fnsvv,Guess Who Rated This Movie: Identifying Users Through Subspace Clustering,https://www.reddit.com/r/MachineLearning/comments/2fnsvv/guess_who_rated_this_movie_identifying_users/,hrb1979,1410032772,,0,1
60,2014-9-7,2014,9,7,6,2fo35z,Learning from Data Textbook Online,https://www.reddit.com/r/MachineLearning/comments/2fo35z/learning_from_data_textbook_online/,ml_textbook_guy,1410039493,"Hi guys,

I'm wondering if any of you have a link to a copy of the Learning From Data Textbook online by Abu Mostafa. I've purchased the book, but I would really like an electronic copy of it. Any links to a torrent or something else?

Thanks for all your help!",0,0
61,2014-9-7,2014,9,7,7,2foaad,Trouble Understanding Recurrent Neural Network Architecture Motivation,https://www.reddit.com/r/MachineLearning/comments/2foaad/trouble_understanding_recurrent_neural_network/,alexmlamb,1410044334,"I've seen a number of variations on the Long Short Term Memory architecture and I'm having a hard time understanding the motivation behind the exact architecture.  For simplicity, I'll focus on the specification given by Alex Graves.  Notably the definition given in Ilya Sutskever's doctoral thesis is quite different.  

http://arxiv.org/abs/1308.0850
http://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf

1.  Why do the connections between the memory and the gates (the peephole connections) need to use a diagonal weight matrix? Why can't the opening/closing of a gate depend on the values of all of the memory cells?  

2.  Why does the gate that writes values into the memory block need to be the product of a logistic gate and a tanh gate?  Why not a relu gate and a tanh gate, or a relu, tanh, and logistic gate?  ",2,24
62,2014-9-7,2014,9,7,18,2fpi7m,Rotation invariant OCR,https://www.reddit.com/r/MachineLearning/comments/2fpi7m/rotation_invariant_ocr/,[deleted],1410083066,"Does anyone know whether machine learning techniques such as ANNs or SVMs can be used to recognise letters regardless of their rotation (and also be tolerant towards slight changes in scale)? For instance, if I were to train an SVM on the letters ""A"" and ""X"" rotated at varying degrees, would it be able to accurately tell them apart? Or am I better off using something else like HAAR? Thanks!",14,3
63,2014-9-8,2014,9,8,0,2fq1z0,Timeseries Classification: KNN &amp; DTW,https://www.reddit.com/r/MachineLearning/comments/2fq1z0/timeseries_classification_knn_dtw/,Derpscientist,1410103488,,2,13
64,2014-9-8,2014,9,8,0,2fq51x,A visual proof that neural nets can approximate any continuous function,https://www.reddit.com/r/MachineLearning/comments/2fq51x/a_visual_proof_that_neural_nets_can_approximate/,carmichael561,1410105561,,14,21
65,2014-9-8,2014,9,8,5,2fqtt9,Would you hire an actuary for a data science position?,https://www.reddit.com/r/MachineLearning/comments/2fqtt9/would_you_hire_an_actuary_for_a_data_science/,actuarially_sound,1410120678,"I studied Statistics and Computer Science as an undergrad. Afterwards I went and got a job doing programming for 3 years before going and starting grad school for software engineering.

After one semester, I decided that software engineering grad school wasn't for me (though I did well in class and I got 2 B's in the classes that I took.) and I've decided to become an actuary instead. I'll be sitting the Probability exam this November before applying to a few companies and my goal is to work towards Associateship over the next 2 years (basically the time that I planned on spending in grad school).

I know that there are actuarial roles that focus on predictive modeling and data mining and using a lot of the tools that you hear about with data science positions.

If I ever decided to switch into more of a data science role would Actuarial credentials be a plus, minus or neutral? Would you rather hire some guy with a PhD in Quantum-Astro Physics? I'm just curious.",1,0
66,2014-9-8,2014,9,8,6,2fr1gb,A comprehensive literature review of the most significant research papers on opinion spam detection until now,https://www.reddit.com/r/MachineLearning/comments/2fr1gb/a_comprehensive_literature_review_of_the_most/,tarabos,1410125055,,0,3
67,2014-9-8,2014,9,8,7,2fr8x1,"QUOTE:""Want to train your own neural machine translation model on your favourite pair of languages? You can do it right away"", using state of art deep learning based model.",https://www.reddit.com/r/MachineLearning/comments/2fr8x1/quotewant_to_train_your_own_neural_machine/,test3545,1410129660,,1,2
68,2014-9-8,2014,9,8,8,2frcgf,cuDNN: GPU-Accelerated Deep Neural Network Library from NVIDIA,https://www.reddit.com/r/MachineLearning/comments/2frcgf/cudnn_gpuaccelerated_deep_neural_network_library/,harrism,1410131989,,25,130
69,2014-9-8,2014,9,8,17,2fshij,Is it possible to use machine learning to make a program that can program?,https://www.reddit.com/r/MachineLearning/comments/2fshij/is_it_possible_to_use_machine_learning_to_make_a/,TechnoSingularity,1410163457,"So I've had this idea for a long time now and this year started at university in computer science. Now as the title states I was wondering if it is possible to use machine learning to make a program that can make programs?

You might be wondering why would someone want to do this, well the idea is perhaps if you could somehow be able to give it some direction of what you want it to make, say you could direct it to make AI. Which having a computer do the job it might be able to code faster than a human although probably not as intelligently though. See with machine learning doing it perhaps it would seem to have some 'intelligence' instead of just piecing together random pieces of code till it makes something.

I've looked into genetic programming but the one problem I've discovered is the fact you need to have a fitness function which comes across to me as a sort of answer to the question. So basically you need to know the 'answer' before it can make anything. With AGI or AI I don't see how you would know what the answer would be.

I was also wondering about the cuDNN and it's suitability to this idea as I just recently got a GTX 770 4GB model which would hopefully be perfect for using with it. Or the other idea was a Python machine learning setup as I actually just learnt Python (well Python 3.x) so it is fresh in my mind. Also hoping there would be an easy to setup version for testing at first as if it requires too much cs knowledge and mathematics knowledge I will be stumped.

Any replies will be greatly appreciated.

Thanks.",17,3
70,2014-9-8,2014,9,8,19,2fsq8o,Build a Spam Filter with R using a SVM,https://www.reddit.com/r/MachineLearning/comments/2fsq8o/build_a_spam_filter_with_r_using_a_svm/,julhillebrand,1410173976,,0,3
71,2014-9-8,2014,9,8,23,2ft5ef,NN to separate out parts of whole by just studying the parts?,https://www.reddit.com/r/MachineLearning/comments/2ft5ef/nn_to_separate_out_parts_of_whole_by_just/,my_face_is_up_here,1410186245,"That title is pretty vague, but I think it's the general case of what I'm trying to do.

My specific case music/audio. I have a training set of audio signals of individual piano notes (let's assume all within the same octave). I want to train a neural network to classify the audio signal into one of 12 classes (corresponding to the 12 semitones in the octave). The output specification would be a one-hot encoding, so it would have 12 dimensions, but the output layer would *not* have a softmax activation (because of my test case described below).

If I train the network using audio signals of single, individual notes, would it be able to separate out the notes of a chord played at test time? For example, assuming the network does a great job at determining the note being played when a single note is presented (i.e. great training performance), if the network was presented with an audio signal of a chord (F, A, and C, for example), would it be able to output a 1 for the F tone, the A tone, and the C tone?

I realize that all of this could be accomplished by playing around with the audio signal in frequency domain, but I was just curious if a neural network was able to do something like this. The human brain can clearly learn like this (if I showed you many pictures of Ferraris, you'd be able to pick one out of a parking lot).",3,2
72,2014-9-9,2014,9,9,0,2ftcfa,Using evolutionary computation to explain network growth,https://www.reddit.com/r/MachineLearning/comments/2ftcfa/using_evolutionary_computation_to_explain_network/,2Q14,1410190467,,1,9
73,2014-9-9,2014,9,9,1,2ftgkc,Determining the optimal weight assignments when given the previous period's error,https://www.reddit.com/r/MachineLearning/comments/2ftgkc/determining_the_optimal_weight_assignments_when/,[deleted],1410192792,"Perhaps optimal is too strong a word, but I'd like to write a function with the following signature:

    def findWeights(prev_pd_errors, curr_weights, learning_rate)
    
where the weights for a set of learners are determined in accordance with their respective errors from the previous period. This should step the current weights in the direction of the new weights by a meta parameter learning_rate. 

I have what I think is correct, which I've pieced together from a few different sources, but there's two things I'm concerned with: 

 - the meta parameter doesn't seem to change anything when adjusted

 - there's probably a better way to do it, since as I said, this is just pieced together by me

Here's some pseudocode of what I've come up with:

    def findWeights(errors, curr_weights, learning_rate):
      dev = stddev(errors)
      optimal = exp( -errors / dev )
      changes = (optimal - curr_weights) * learning_rate
      return (curr_weights + changes) / sum(curr_weights + changes)

I'm thinking the meta parameter doesn't work because I normalize the weights to sum to 1, which in turn negates adding the multiple changes. Am I on the right track here? Any suggestions?",0,1
74,2014-9-9,2014,9,9,1,2ftgky,Personas Machine-Learning App Lets People Follow Different Sides Of Your Twitter Identity,https://www.reddit.com/r/MachineLearning/comments/2ftgky/personas_machinelearning_app_lets_people_follow/,SoggyBusquets,1410192804,,4,7
75,2014-9-9,2014,9,9,5,2fuapb,"Machine Learning, Data Science, Artificial Intelligence",https://www.reddit.com/r/MachineLearning/comments/2fuapb/machine_learning_data_science_artificial/,sanketshah04,1410208656,,0,1
76,2014-9-9,2014,9,9,7,2fun92,MSCOCO - a new image recognition and segmentation dataset,https://www.reddit.com/r/MachineLearning/comments/2fun92/mscoco_a_new_image_recognition_and_segmentation/,rantana,1410215493,,0,11
77,2014-9-9,2014,9,9,8,2futfe,Why AI Is Simple &amp; Biological Neural Networks Are Not,https://www.reddit.com/r/MachineLearning/comments/2futfe/why_ai_is_simple_biological_neural_networks_are/,jostmey,1410219056,,23,0
78,2014-9-9,2014,9,9,10,2fv6cs,Would anyone be interested in starting an ML reading group?,https://www.reddit.com/r/MachineLearning/comments/2fv6cs/would_anyone_be_interested_in_starting_an_ml/,m_ke,1410226405,We could pick a paper or two to discuss each week.,67,74
79,2014-9-9,2014,9,9,14,2fvrdo,"Efficient Online Bootstrapping for Large Scale Learning - John Langford, et al",https://www.reddit.com/r/MachineLearning/comments/2fvrdo/efficient_online_bootstrapping_for_large_scale/,rrenaud,1410240273,,1,3
80,2014-9-9,2014,9,9,15,2fvvdr,Coursera Machine Learning on 22nd September,https://www.reddit.com/r/MachineLearning/comments/2fvvdr/coursera_machine_learning_on_22nd_september/,capecamorin,1410243876,"Is there anyone taking the course?
 We can form a study group as well. We can discuss, share and study together. And also anyone who is already into ML and want to get into it can also join - it's all about learning! :)",6,0
81,2014-9-9,2014,9,9,16,2fw01v,Recover Canonical-View Faces in the Wild with Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/2fw01v/recover_canonicalview_faces_in_the_wild_with_deep/,CreativePunch,1410248467,,0,4
82,2014-9-9,2014,9,9,19,2fw8fw,"The Future of Machine Learning, According to Clouderas Sean Owen",https://www.reddit.com/r/MachineLearning/comments/2fw8fw/the_future_of_machine_learning_according_to/,huitseeker,1410258158,,0,0
83,2014-9-9,2014,9,9,22,2fwlmn,Is there anyone using ART (Adaptive resonance theory)?,https://www.reddit.com/r/MachineLearning/comments/2fwlmn/is_there_anyone_using_art_adaptive_resonance/,guscl,1410269600,"Hi everyone, I'm starting a research here where I would like to work with incremental learning. I found the ART models, they have the ability to keep learning patterns. http://en.wikipedia.org/wiki/Adaptive_resonance_theory

I had a hard time finding recent works with this models... Does anyone use them? Or know why they are not being used? 
Keep in mind that I'm still a noob in ML, so this question may be stupid... Thank you, =].

",4,4
84,2014-9-9,2014,9,9,22,2fwm5k,Help with Neural Network,https://www.reddit.com/r/MachineLearning/comments/2fwm5k/help_with_neural_network/,xDouble,1410269934,"Hey guys, I am a beginner with Machine Learning and Neural Networks and I really need some help with a Xor Network that i made.
Well, I tried to make it vectorized, but I'm not sure if it's correct, sometimes the network converge, some times not, this is normal?
Can you please look the code and tell me what you think?

Here is the link for my Github : https://github.com/jpvmm/ANN_Octave/blob/master/xorBIAS.m

Thank You.

Ps: I made it in Octave.",3,0
85,2014-9-9,2014,9,9,23,2fwpc1,What is the best number of clusters in when using K-Means?,https://www.reddit.com/r/MachineLearning/comments/2fwpc1/what_is_the_best_number_of_clusters_in_when_using/,TwistedHardware,1410272035,,7,0
86,2014-9-9,2014,9,9,23,2fwt7c,Philadelphia 76ers looking to hire analytics/technology staff,https://www.reddit.com/r/MachineLearning/comments/2fwt7c/philadelphia_76ers_looking_to_hire/,seventysixers,1410274324,"The Philadelphia 76ers are looking to add talented new developers, software engineers, statistical analysts, and data scientists to the team. Basketball analysts will work as a part of the front office and collaborate extensively with the entire basketball operations department including President and GM Sam Hinkie. Experience in basketball is not required; analytical talent and learning easily is. The Sixers are looking for both permanent employees and interns. Most basketball analysts will work in our basketball operations office in Philadelphia but other arrangements may be possible.


If you're passionate about basketball and have technical skills that you think could help an NBA team, **[please see the official posting and apply here](http://nbateamjobs.teamworkonline.com/teamwork/jobs/jobskey.cfm?s=76ers#71706)**.


If you have questions, you can reach us at bballopsjobs@sixers.com.


Thanks,

76ers Basketball Operations",2,6
87,2014-9-10,2014,9,10,1,2fx5au,Introductory book for the mathematically mature?,https://www.reddit.com/r/MachineLearning/comments/2fx5au/introductory_book_for_the_mathematically_mature/,letoseldon,1410281022,I have a BS in Applied Math and most of the ML Intro books I've looked at were pretty light on theory (they throw out a few equations without deriving them and then show how to implement the algorithm in R) - what's a good theory-heavy book for someone with no previous background in ML?,12,5
88,2014-9-10,2014,9,10,1,2fx5x5,CaltechX 'Learning from Data' course begins September 25th,https://www.reddit.com/r/MachineLearning/comments/2fx5x5/caltechx_learning_from_data_course_begins/,rz2000,1410281355,"This is an introductory course to machine learning with pretty rigorous mathematics. The professor, Yasser Abu-Mostafa, is really engaging, and in the past he actively participated in the forums.

The course was previously offered directly from a CalTech website, and then as a course on Coursera. The quizzes were in the form of multiple choice questions, rather than being interactive or open-ended, but you could use whatever language or tool you wanted to help you get your answers.

I am curious to see how it will be done on the EdX platform. The earlier lectures and instruction itself were at the level of EdX classes (and the forums were better\*), but the multiple choice quizzes were less involved than typical exercises and assignments you find in EdX classes.

https://www.edx.org/course/caltechx/caltechx-cs1156x-learning-data-2516

\* I don't why so many of the student moderators have an us vs them attitude on EdX. The same problem seems nonexistent on Coursera.",7,8
89,2014-9-10,2014,9,10,3,2fxi6v,AMA: Michael I Jordan,https://www.reddit.com/r/MachineLearning/comments/2fxi6v/ama_michael_i_jordan/,michaelijordan,1410287955,"Michael I. Jordan is the Pehong Chen Distinguished Professor in the Department of Electrical Engineering and Computer Science and the Department of Statistics at the University of California, Berkeley. He received his Masters in Mathematics from Arizona State University, and earned his PhD in Cognitive Science in 1985 from the University of California, San Diego. He was a professor at MIT from 1988 to 1998. His research interests bridge the computational, statistical, cognitive and biological sciences, and have focused in recent years on Bayesian nonparametric analysis, probabilistic graphical models, spectral methods, kernel machines and applications to problems in distributed computing systems, natural language processing, signal processing and statistical genetics. Prof. Jordan is a member of the National Academy of Sciences, a member of the National Academy of Engineering and a member of the American Academy of Arts and Sciences. He is a Fellow of the American Association for the Advancement of Science. He has been named a Neyman Lecturer and a Medallion Lecturer by the Institute of Mathematical Statistics. He received the David E. Rumelhart Prize in 2015 and the ACM/AAAI Allen Newell Award in 2009. He is a Fellow of the AAAI, ACM, ASA, CSS, IEEE, IMS, ISBA and SIAM. ",109,264
90,2014-9-10,2014,9,10,4,2fxp3n,Predicting what user reviews are about with LDA and gensim  source code on GitHub,https://www.reddit.com/r/MachineLearning/comments/2fxp3n/predicting_what_user_reviews_are_about_with_lda/,tarabos,1410291577,,0,2
91,2014-9-10,2014,9,10,6,2fy4t2,My Brainteaser: Predicting the Output of a Boolean Black Box using Dependence as a Prior Assumption,https://www.reddit.com/r/MachineLearning/comments/2fy4t2/my_brainteaser_predicting_the_output_of_a_boolean/,[deleted],1410299880,,0,1
92,2014-9-10,2014,9,10,7,2fy9i2,My Brainteaser: Predicting the Output of a Boolean Black Box using Dependence as a Prior Assumption,https://www.reddit.com/r/MachineLearning/comments/2fy9i2/my_brainteaser_predicting_the_output_of_a_boolean/,[deleted],1410302558,,0,1
93,2014-9-10,2014,9,10,7,2fy9xo,ReLU activation function and gradient vanishing problem ?,https://www.reddit.com/r/MachineLearning/comments/2fy9xo/relu_activation_function_and_gradient_vanishing/,rishok,1410302792,Why doesn't the ReLU activation function face gradient vanishing problem as with sigmoid and tanh function,5,3
94,2014-9-10,2014,9,10,7,2fyamt,My Brainteaser: Dependence as a Prior Assumption,https://www.reddit.com/r/MachineLearning/comments/2fyamt/my_brainteaser_dependence_as_a_prior_assumption/,jostmey,1410303173,,0,1
95,2014-9-10,2014,9,10,8,2fyewm,How important is going to a good college if I want to go into ML?,https://www.reddit.com/r/MachineLearning/comments/2fyewm/how_important_is_going_to_a_good_college_if_i/,[deleted],1410305590,"I'm a freshman in high school, and I want to do something with machine learning when I grow up, like work at a tech company like Google or IBM. How important is going to a good college? I don't do super well in school, I'm not super good at keeping track of papers and due dates- so I probably won't end up going to a super great college. What kind of college should I shoot for?",5,0
96,2014-9-10,2014,9,10,11,2fyuu0,"I ran out of patience waiting for the Test Error ""hockey stick"", to indicate overfitting, shortly after the train Misclassification rate hit 0",https://www.reddit.com/r/MachineLearning/comments/2fyuu0/i_ran_out_of_patience_waiting_for_the_test_error/,crossentropy,1410315028,,15,1
97,2014-9-10,2014,9,10,14,2fzcmy,Neural nets are ~ universal function approximators ~,https://www.reddit.com/r/MachineLearning/comments/2fzcmy/neural_nets_are_universal_function_approximators/,clurdron,1410327586,"I see this fact mentioned a lot of threads on r/MachineLearning. I want to point out that this isn't such a unique property for families of functions to have. Weierstrass proved that polynomials can uniformly approximate any continuous function defined on a closed interval in the 1800s. We had the conceptual technology (e.g. least squares) to fit polynomials in the 1800s, too. There are a lot of similar theorems for othogonal functions on L2 spaces, wavelets, Fourier series, etc. A mixture of normals can approximate any density. These theorems are everywhere. The fixation on the theorem for neural networks is kind of odd. I can only attribute it to the dramatic name. ",11,16
98,2014-9-10,2014,9,10,21,2g00s6,Morse Learning Machine Challenge is ARRL headline news today!,https://www.reddit.com/r/MachineLearning/comments/2g00s6/morse_learning_machine_challenge_is_arrl_headline/,ag1le,1410352750,"
http://www.arrl.org/news/morse-learning-machine-challenge-catching-on-with-hams",0,0
99,2014-9-10,2014,9,10,21,2g026c,Clustering tools in languages that are faster than Python?,https://www.reddit.com/r/MachineLearning/comments/2g026c/clustering_tools_in_languages_that_are_faster/,SufferSome,1410353958,"I'm interested in doing clustering of timeseries data. The data is genome-wide timeseries expression data, so ~30,000 genes/samples (50+ timepoints each). The methods that I've found to work for this on a smaller scale (when I've looked at subsets of genes) rely on generating a similarity matrix (30,000x30,000), which is too large to keep in memory.

The only way I see of getting around this is by calculating the similarity measures each time they're required, and caching results as I go to speed things up a bit (but how well this works depends on the algorithm implementation).

This is very slow, though, and its useful for me to be able to run the analysis repeatedly, so I think I'm at a limit of how much I can do within Python (I'm using scikit-learn and pandas at the moment). Does anybody have any experience with tools that implement clustering algorithms in faster languages? The specific algorithm that I've found useful for my problem is affinity propagation, but I'm willing to look at other things.


Edit: I'd just like to thank everybody again for their input, this has been really stimulating for me, not just in thinking about this particular problem but thinking about all of the tools I use.",13,8
100,2014-9-10,2014,9,10,23,2g0ahd,"How Twitter Handles Your Data - Interview with Jake Mannix, Machine Learning Engineer at Twitter",https://www.reddit.com/r/MachineLearning/comments/2g0ahd/how_twitter_handles_your_data_interview_with_jake/,jreacher,1410359473,,0,23
101,2014-9-11,2014,9,11,2,2g0rz8,A neural network that can answer paragraph-length questions,https://www.reddit.com/r/MachineLearning/comments/2g0rz8/a_neural_network_that_can_answer_paragraphlength/,larsga,1410369149,,4,92
102,2014-9-11,2014,9,11,8,2g1uql,[comments welcome] Detecting anomalies with Neural newtorks,https://www.reddit.com/r/MachineLearning/comments/2g1uql/comments_welcome_detecting_anomalies_with_neural/,[deleted],1410390118,,0,1
103,2014-9-11,2014,9,11,8,2g1y31,[comments are welcome] Detecting anomalies with Neural Networks,https://www.reddit.com/r/MachineLearning/comments/2g1y31/comments_are_welcome_detecting_anomalies_with/,marcodena,1410392073,,7,8
104,2014-9-11,2014,9,11,10,2g27fo,Hill Climbing Algorithm &amp; Artificial Intelligence - Computerphile - YouTube,https://www.reddit.com/r/MachineLearning/comments/2g27fo/hill_climbing_algorithm_artificial_intelligence/,VivaLaPandaReddit,1410397620,,0,4
105,2014-9-11,2014,9,11,13,2g2qlq,"QUOTE: Our results further confirm the ""deep learning hypothesis"": a big deep neural network can solve pretty much any problem, provided it has a very big high quality labelled training set.",https://www.reddit.com/r/MachineLearning/comments/2g2qlq/quote_our_results_further_confirm_the_deep/,test3545,1410410027,,36,28
106,2014-9-11,2014,9,11,19,2g3c89,lagerbladmachine,https://www.reddit.com/r/MachineLearning/comments/2g3c89/lagerbladmachine/,Elin777,1410432022,,0,1
107,2014-9-11,2014,9,11,22,2g3m46,kind-of french supreme court wish to regulate predictive algorithms (french only),https://www.reddit.com/r/MachineLearning/comments/2g3m46/kindof_french_supreme_court_wish_to_regulate/,[deleted],1410440824,,0,0
108,2014-9-11,2014,9,11,22,2g3nyv,Math skills required for getting into Machine Learning.,https://www.reddit.com/r/MachineLearning/comments/2g3nyv/math_skills_required_for_getting_into_machine/,capecamorin,1410442185,"I don't have a good math background. And as per my knowledge, Algebra, Probability and Statistics are highly involved in ML and Data science. 
Where should I start to obtain math skills needed for ML/Data science?
Suggestions for good books will be more helpful. ",21,5
109,2014-9-11,2014,9,11,22,2g3o66,"NVIDIA's cuDNN ConvNet library, now with Torch7 bindings",https://www.reddit.com/r/MachineLearning/comments/2g3o66/nvidias_cudnn_convnet_library_now_with_torch7/,vkhuc,1410442334,,7,21
110,2014-9-11,2014,9,11,23,2g3sso,Similarity Is Subjective,https://www.reddit.com/r/MachineLearning/comments/2g3sso/similarity_is_subjective/,haifengl,1410445290,,1,0
111,2014-9-12,2014,9,12,2,2g4ci6,Kdd14 Retro: Google Knowledge Vault And Topic Modeling,https://www.reddit.com/r/MachineLearning/comments/2g4ci6/kdd14_retro_google_knowledge_vault_and_topic/,jisaacso,1410456337,,0,1
112,2014-9-12,2014,9,12,3,2g4jnx,What would you do in preprocessing?,https://www.reddit.com/r/MachineLearning/comments/2g4jnx/what_would_you_do_in_preprocessing/,TwistedHardware,1410460057,"I have a Youtube series about machine learning. I have finished 4 tutorials about:
- Setup your environment
- Introduction to ML/Classification
- Regression
- Clustering

The next one is about ""Preprocessing"". What would you suggest I include in this tutorial?",14,0
113,2014-9-12,2014,9,12,3,2g4kpc,PP plot vs QQ plot,https://www.reddit.com/r/MachineLearning/comments/2g4kpc/pp_plot_vs_qq_plot/,akc_c,1410460582,,0,2
114,2014-9-12,2014,9,12,4,2g4o50,Real-time time-series classification,https://www.reddit.com/r/MachineLearning/comments/2g4o50/realtime_timeseries_classification/,stupider_than_you,1410462347,"I am working on an algorithm that predicts, in real-time, the class label (or if none apply) of incoming discrete time-series data. At each discrete step in time the length of the input increases, due to the new observation, and I want to predict the membership (if any) of the entire sequence. I have been focused on statistical graphical models (conditional random fields, hidden Markov models, Bayes nets) since they are designed for sequential data. Additionally, these methods can provide a level of confidence in the estimate.

Are there any other algorithms that can handle this type of problem? Would kernel methods work if I design an appropriate kernel? Can spectral clustering be applied somehow?

Any suggestions of other algorithms I should research would be appreciated.",16,9
115,2014-9-12,2014,9,12,4,2g4t7p,cuDNN - Nvidia support for deep networks on gpu's,https://www.reddit.com/r/MachineLearning/comments/2g4t7p/cudnn_nvidia_support_for_deep_networks_on_gpus/,[deleted],1410464948,,0,1
116,2014-9-12,2014,9,12,6,2g55cj,Universities With Respected Programs in Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/2g55cj/universities_with_respected_programs_in_machine/,voodoochile78,1410471323,"Hi all,

I'm looking for a career change (currently an Electrical Engineer with an academic background in EE and applied mathematics) and would like to focus on Machine Learning.   I'd like some help identifying a short list of schools in the US and Canada whose ML programs are highly respected in the private sector. I have just a small list of schools in mind, and am turning to the collective wisdom of Reddit to cast my net a little wider. 

Thanks!",10,0
117,2014-9-12,2014,9,12,7,2g59c9,Elements of Statistical Learning: Reading Group,https://www.reddit.com/r/MachineLearning/comments/2g59c9/elements_of_statistical_learning_reading_group/,Divided_Pi,1410473560,"Hey Everyone! 

So lately there has been discussions about reading groups for papers and what not. I don't feel I have a deep enough fundamental understanding to fully participate in those reading groups. I personally would also like to go through the Elements with other people since I'm not entirely confident in my own abilities and I hear Elements is a great starting point. 

So far I have two other people on reddit, /u/CreativePunch and /u/rianahmamy, and one friend in real life who have expressed interest in a reading group on this. 

My general idea for the reading group would be structured similar to class in my mind. Perhaps assign a chapter to read every week[negotiable depending on chapter length &amp; difficulty]. Then have some subset of example problems to work through on your own and each week we would get together on perhaps a google hang out or similar free meeting website and discuss/compare answers. 

I've never attempted this before but I'm thinking might as well give it a shot. If we get low number probably up 10 people or so, we can probably keep it one group. Much more than that it would probably be one group with more flexible attendance or perhaps separate smaller groups. 


I feel like I'm rambling a bit, but TL;DR is if you're interested let me know! Hopefully we can start in the next week or two and work through the text in the coming months. 

EDIT:
Post Time zone too! 

EDIT 2: Wow! A lot more interest than I was expecting! I know that many of you have posted time zones here, I'm going to send out a survey to everyone to get a rough idea for everyone's availability. Since we seem to be at least in the 30+ range of participants I'm wondering what the next move is in terms of organization. Should we move to our own subreddit? Either to a defunct  one or create our own, or perhaps google groups? 

Either way, I'm heading into work soon so I won't be able to do too much in the next 8-9 hour range. I'll PM everyone some details or post them here in the next day or two so watch your inboxes!



EDITTTTTTTTT:



Wow, so this thing continues to grow, and frankly has been a little bit overwhelming but very exciting too. So following the advice of some other redditors and figuring that we might as well start getting the ball rolling I created.... (cue drumroll, dim lights)...... /r/eosl !!!!! (yayyyyy)

But really right now it is very rough because I just woke up and created it. But it exists. So everyone should subscribe there and we'll start making moves. I'll do my best to try and get the subreddit up and running smoother this weekend but I have a lot of family time slotted for this weekend so I may not get a chance to update it until sunday evening est. In the mean time for those of you who have not yet started reading, I'll post the link to the book and perhaps this week will be Preface/Intro/Chapter 1 general discussion. 


We'll read chapter 1 this week but mainly focus moving forward. Maybe, we can also discuss this in r/eosl since that is a thing now. 

Either way, really crazy to see this much support!",123,30
118,2014-9-12,2014,9,12,12,2g61mw,Dealing with unequal data set?,https://www.reddit.com/r/MachineLearning/comments/2g61mw/dealing_with_unequal_data_set/,watersign,1410491324,"I have a list of 40K or so people, about 33K of them are not using said company product and the rest are. I've been using a variety of CART/CHAID trees to model this data and am taking a sample of the group who are not using it to make it equal with those who are. I am using SPSS and have been getting good results (70%+ accuracy)  however I am not positive that this data is being utilised properly. I am partitioning it 60/40 and using cross-validating 60/20/20 and the results are similar, if not identical. What am I doing wrong? Am I doing anything right? 

",2,0
119,2014-9-12,2014,9,12,20,2g6wgr,Highly Recommended Books for Machine Learning Researchers,https://www.reddit.com/r/MachineLearning/comments/2g6wgr/highly_recommended_books_for_machine_learning/,nzhiltsov,1410520480,,5,75
120,2014-9-12,2014,9,12,22,2g74au,Anybody know of any Neural Network/Deep Learning researchers in Buenos Aires or any ther city in Argentina?,https://www.reddit.com/r/MachineLearning/comments/2g74au/anybody_know_of_any_neural_networkdeep_learning/,BeijingChina,1410527316,"Hi,
An irregular post. I shall be visiting Argentina for a short while next month. I wanted to know if there are any Neural Network/Deep Learning Researchers/Labs there that I might request a meeting with? I don't know much about the research going on in the country.",8,3
121,2014-9-13,2014,9,13,1,2g7ogg,Data Partitioning: How To Repair Explanation,https://www.reddit.com/r/MachineLearning/comments/2g7ogg/data_partitioning_how_to_repair_explanation/,quantumprogress,1410539687,,0,0
122,2014-9-13,2014,9,13,3,2g7z4h,The Automatic Statistician,https://www.reddit.com/r/MachineLearning/comments/2g7z4h/the_automatic_statistician/,[deleted],1410545554,,1,0
123,2014-9-13,2014,9,13,3,2g81ci,"I am planning to create an Analytics platform for a Retail store for my academic coursework. I am unable to locate a good dataset. Does anyone know of such a dataset. Datasets from Amazon, Walmart, Costco and the like",https://www.reddit.com/r/MachineLearning/comments/2g81ci/i_am_planning_to_create_an_analytics_platform_for/,dipakdayanand,1410546782,,6,1
124,2014-9-13,2014,9,13,5,2g8b8k,Spectral clustering with multiple features?,https://www.reddit.com/r/MachineLearning/comments/2g8b8k/spectral_clustering_with_multiple_features/,[deleted],1410552283,"Hi guys! So here's the question... as far as I know, spectral clustering is convenient when one has an affinity matrix aka pairwise similarities, but what if there are multiple features? Let's say that one's only constrain is that one has to apply spectral clustering and nothing else :) 
Combining features maybe (but in what way)? What would you guys do?",3,1
125,2014-9-13,2014,9,13,5,2g8fkp,Word2Vec as Implicit Matrix Factorization,https://www.reddit.com/r/MachineLearning/comments/2g8fkp/word2vec_as_implicit_matrix_factorization/,goblin_got_game,1410554701,,0,17
126,2014-9-13,2014,9,13,10,2g93w0,XOR Decision Boundaries,https://www.reddit.com/r/MachineLearning/comments/2g93w0/xor_decision_boundaries/,maybemax,1410570168,"Decision boundaries on XOR-like data as created by different ML algorithms:

[http://imgur.com/a/oDwFr](http://imgur.com/a/oDwFr)

[code](http://pastebin.com/7HFWrbTg)

Does anyone know why nnet fails so often? Often it only gets about 75% right no matter what parameters I try (# of iterations, convergence limits,...). Shouldn't 3 neurons be enough?
",9,7
127,2014-9-13,2014,9,13,15,2g9qio,"Interested in Data Science. Check this out 25 free online #MOOC courses on Data Science from #coursera , #udacity, #edx",https://www.reddit.com/r/MachineLearning/comments/2g9qio/interested_in_data_science_check_this_out_25_free/,Brads9736,1410588723,,0,1
128,2014-9-13,2014,9,13,16,2g9vq7,Why is the partition function for RBMs hard to calculate?,https://www.reddit.com/r/MachineLearning/comments/2g9vq7/why_is_the_partition_function_for_rbms_hard_to/,deep_learner,1410594660,"I have seen proofs that have gone over my head. So, without appealing to esoteric mathematics, is there any analysis that I could do to prove to myself that it is indeed hard? Maybe not prove beyond a doubt, but see that it would be ""reasonbly hard"". ",16,7
129,2014-9-14,2014,9,14,1,2gaos3,Similarity Measure between Gaussian Mixture Models.,https://www.reddit.com/r/MachineLearning/comments/2gaos3/similarity_measure_between_gaussian_mixture_models/,subszero,1410624740,"Given 2 GMM's with different number of components ( say 8 and 12), I am looking for a similarity/overlap measure between them. Is there some established technique for this ?


I found out about KL divergence and the bhattacharya coefficient, but am not sure on using them with GMM's. I would prefer a technique which has some publicly available implementation to test on my dataset.",9,5
130,2014-9-14,2014,9,14,7,2gbqm6,Dealing with multiple predictor variables,https://www.reddit.com/r/MachineLearning/comments/2gbqm6/dealing_with_multiple_predictor_variables/,kirtyv,1410648984,"**Problem** 

Building a model which can predict the cost of a house depending on factors like cost of the house in the previous year, number of bedrooms, number of bathrooms, lot square area, total area, the year in which it was built etc.

Dataset - All these features for about 3000 values in the training set, 3000 in the validation set

**My idea**

Use a multiple regression model after normalizing each variable.

1.  Do a bi-variate analysis in order to find out the relationship between the present house cost and each of the variables
2.  Measure Pearson correlations of all the predictor values with the current house price (dependent value)
3. Measure inter-correlations of all predictor variables and find their significance (2-tailed test) and take out the most significant features

Here are my questions with respect to this - 

* How many top features should I select from this? 
* Statisticians say that the model should be as simple and interpretable as possible. However, if I should use combination of features (for example - the product of number of bedrooms and bathrooms), how do I go about selecting them?
* Can the model be improved by better training ( using gradient descent) than by feature selection? What is the trade-off?
* Finally, can decision trees be used as an alternative? If so, what are their merits/demerits?

Please give me some ideas regarding this, and also any possible sources for getting to know more about the practical implications of designing a data model.

Any help is much appreciated, thanks! :)",3,3
131,2014-9-14,2014,9,14,10,2gc2wp,Interactive visualization of growing Data Science / Big Data profiles on Twitter,https://www.reddit.com/r/MachineLearning/comments/2gc2wp/interactive_visualization_of_growing_data_science/,vincentg64,1410657751,,2,0
132,2014-9-14,2014,9,14,13,2gch8d,[Reading Group] Survey and Introductory Discussion,https://www.reddit.com/r/MachineLearning/comments/2gch8d/reading_group_survey_and_introductory_discussion/,m_ke,1410668812,"Judging by the responses in the previous thread it looks like we might have enough interested people to get this going. Before we get started I'd like to get a better idea of what everyone is interested in and where everyone is in terms of experience, [so I made a quick survey that I'd like to have everyone fill out.](https://docs.google.com/forms/d/1LvVN56YdY235-m21IF2Zrt9aAwFRE8QKPeKZuwoQCPI/viewform)



Here's my proposal for how things should work:

* Single topic per month.

* One required paper per week, along with optional supplementary material such as related papers, online articles and textbook chapters. (A thread for weekly discussion would go up every Tuesday)

* We would have a monthly topic proposal thread where anyone could pitch a syllabus for the following month.

* A poll would go up about a week before the end of the month to decide which syllabus we follow next.

* The poster(s) of the winning syllabus then has the option to moderate the discussion throughout the month. This includes electing weekly discussion leaders (3-4 people), who have to give a brief summary of the paper and pose questions for the rest of the group.


Would everyone be okay with that?",15,13
133,2014-9-14,2014,9,14,19,2gcyhb,Must have books for data scientists (or aspiring ones),https://www.reddit.com/r/MachineLearning/comments/2gcyhb/must_have_books_for_data_scientists_or_aspiring/,kunalj101,1410690308,,2,0
134,2014-9-14,2014,9,14,19,2gczst,A Unifying View of Deep Networks and Hierarchical Temporal Memory,https://www.reddit.com/r/MachineLearning/comments/2gczst/a_unifying_view_of_deep_networks_and_hierarchical/,fergbyrne,1410692117,,22,0
135,2014-9-14,2014,9,14,22,2gd7ki,Machine learning cheat sheet in pdf by soulmachine,https://www.reddit.com/r/MachineLearning/comments/2gd7ki/machine_learning_cheat_sheet_in_pdf_by_soulmachine/,kkeu,1410700887,,13,83
136,2014-9-15,2014,9,15,6,2gefiv,[ASK] mobile phone usage dataset. What to do?,https://www.reddit.com/r/MachineLearning/comments/2gefiv/ask_mobile_phone_usage_dataset_what_to_do/,marcodena,1410729432,,4,1
137,2014-9-15,2014,9,15,8,2get84,Pure Python Benchmark Code for Criteo Display Ad Challenge on Kaggle,https://www.reddit.com/r/MachineLearning/comments/2get84/pure_python_benchmark_code_for_criteo_display_ad/,vodkagoodmeatrotten,1410738184,,4,7
138,2014-9-15,2014,9,15,9,2gezkj,Practical help with WEKA based ML model,https://www.reddit.com/r/MachineLearning/comments/2gezkj/practical_help_with_weka_based_ml_model/,caedin8,1410742301,,4,1
139,2014-9-15,2014,9,15,18,2gg133,Learning python for machine learning,https://www.reddit.com/r/MachineLearning/comments/2gg133/learning_python_for_machine_learning/,PsychedelicStore,1410772988,"Hi to all, I know how to program in various languages such as java, c++, matlab, and I want to learn python, basically for data science and machine learning purposes. I was wondering which are the best resources (books, tutorial) to learn python quickly, with this scope in mind, that is, for machine learning. I'm not interested in learning all the language features, but only those that are needed. I'd like to use scikit-learn which seems the state of the art library for python. Thanks in adavance.",22,30
140,2014-9-15,2014,9,15,20,2gg813,Heidelberg SM52-4P-L | Used Heidelberg Presses | Second Hand Printing Press,https://www.reddit.com/r/MachineLearning/comments/2gg813/heidelberg_sm524pl_used_heidelberg_presses_second/,Equipment111,1410780436,,0,1
141,2014-9-16,2014,9,16,2,2gh51o,Can R square value of regression model be exactly zero or one in real life scenarios?,https://www.reddit.com/r/MachineLearning/comments/2gh51o/can_r_square_value_of_regression_model_be_exactly/,akc_c,1410801594,If yes then what are the examples you have seen? If no then why not?,5,0
142,2014-9-16,2014,9,16,6,2ghwxw,"This machine is making its own games based on a priori training data, encyclopedic datasets and what it learns on the Internet.",https://www.reddit.com/r/MachineLearning/comments/2ghwxw/this_machine_is_making_its_own_games_based_on_a/,biomimic,1410815850,,0,0
143,2014-9-16,2014,9,16,6,2gi1i2,Need advice on learning AI/Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/2gi1i2/need_advice_on_learning_aimachine_learning/,[deleted],1410818217,"For some background information, i'm planning to enter my school's science fair with something pertaining to artificial intelligence, machine learning, or neural networks.
Right now I don't know where to start, for instance what courses/books to start with, how far in knowledge do I need in math/linear algebra, or if this sort of project is even feasible to with my time or knowledge?
Any suggestions?  
EDIT: Really? Down voting my question without at least some constructive criticism?",2,0
144,2014-9-16,2014,9,16,8,2gia1b,Kernel tricks and nonlinear dimensionality reduction via RBF kernel PCA,https://www.reddit.com/r/MachineLearning/comments/2gia1b/kernel_tricks_and_nonlinear_dimensionality/,rasbt,1410823185,,3,27
145,2014-9-16,2014,9,16,11,2gispm,FX,https://www.reddit.com/r/MachineLearning/comments/2gispm/fx/,qz6siktc,1410834164,,0,1
146,2014-9-16,2014,9,16,12,2giz30,I am writing a simple algorithm to find if a given name is Male/Female. I want a dataset representative of the American population to test the algorithm against.,https://www.reddit.com/r/MachineLearning/comments/2giz30/i_am_writing_a_simple_algorithm_to_find_if_a/,dipakdayanand,1410838099,,13,1
147,2014-9-16,2014,9,16,21,2gk0di,Higgs Boson Machine Learning Challenge won with a bag of 70 neural networks,https://www.reddit.com/r/MachineLearning/comments/2gk0di/higgs_boson_machine_learning_challenge_won_with_a/,benanne,1410872350,,31,66
148,2014-9-16,2014,9,16,22,2gk4xl,"Something About Cats, Dogs, Machine and Deep Learning",https://www.reddit.com/r/MachineLearning/comments/2gk4xl/something_about_cats_dogs_machine_and_deep/,[deleted],1410875381,,0,1
149,2014-9-16,2014,9,16,23,2gk6lm,Is this a good time?  how an experimental app can tell when youre busy,https://www.reddit.com/r/MachineLearning/comments/2gk6lm/is_this_a_good_time_how_an_experimental_app_can/,[deleted],1410876468,,1,0
150,2014-9-16,2014,9,16,23,2gk72r,"Learning the ""average"" of a face.",https://www.reddit.com/r/MachineLearning/comments/2gk72r/learning_the_average_of_a_face/,[deleted],1410876763,"Hi all,

Question:

I am doing some research on learning the ""average"" representation of a person's face from various facial images from the subjects.

I am thinking of maybe doing it like this:

1) Get an arbitrary small number of the most clean frontal-face images of the person as targets (Y).

2) Train several images of the person to several of the targets. This means I would have an iteration where image X1 would train to Y1, but in the next epoch X1 would train to Y2 as output, I am hoping this will result in the generation of an average from the images in the Y-set.

One thing I am stuck on though is how could I define a training routine that takes into account that X1 should not only be as close as it can be to Y1, but also to Y2, Y3, ... at the same time in a more effective manner than just doing permuations of all the available images in the X/Y set?

I am using deep learning for these experiments.

Is this possible, have there been any papers on this?",0,1
151,2014-9-16,2014,9,16,23,2gk8co,10 Machine Learning Experts You Need to Know,https://www.reddit.com/r/MachineLearning/comments/2gk8co/10_machine_learning_experts_you_need_to_know/,bigdatamaven,1410877593,,16,0
152,2014-9-16,2014,9,16,23,2gk9mf,Get started with Machine Learning using these Online Courses,https://www.reddit.com/r/MachineLearning/comments/2gk9mf/get_started_with_machine_learning_using_these/,[deleted],1410878333,"With Andrew Ng's Machine Learning Course (from Standford) starting [yet another session](https://www.coursera.org/course/ml) next week, this is the perfect time to up your knowledge of Machine Learning.  
This list covers both introductory and advanced courses as well as some on Neural Networks.  
  
Here is the link - http://www.mysliderule.com/blog/machine-learning-online-courses/",0,0
153,2014-9-17,2014,9,17,3,2gkwa6,I'm looking for a relatively simple and large dataset for classification,https://www.reddit.com/r/MachineLearning/comments/2gkwa6/im_looking_for_a_relatively_simple_and_large/,juckele,1410890400,"Hey everyone,

I'm looking for something a bit like the Iris flower data set (relatively few numerical measurements, ideally 3--5), but with a much higher row count (100K min, preferably 1 million). Does anyone know of any data sets like this? Maybe some height, weight, and body fat data sets?",9,3
154,2014-9-17,2014,9,17,4,2gl54w,Modelling the dynamics of many independent time series?,https://www.reddit.com/r/MachineLearning/comments/2gl54w/modelling_the_dynamics_of_many_independent_time/,ohell,1410894897,"Hello,
I am looking at an unusual problem for a client: There are ~20 CO sensors in the factory, each one generates a number every 15 minutes.   
Each sensor puts out a time series with 96 steps every day. I need to come up with a generative model for these (for automatic anomaly detection). Each sensor is identical, so generative process for the data can be assumed to be the same.

As a first pass, I averaged out each component of the series, to come up with a mean time series. Autocorrelation over the elements of this mean series shows clear first order dynamics, and an ARMA model fits quite well.

However, I am worried that this is the best way to model this kind of data, since each sensor is deployed in its own environment and the standard deviation of each component of the mean series is significant. So, a model trained on the mean might miss outlier events in individual series.

I wonder if there is any guidance on how to approach this kind of problem?  
Thanks for any pointers!",0,1
155,2014-9-17,2014,9,17,4,2gl621,"Something About Cats, Dogs, Machine and Deep Learning",https://www.reddit.com/r/MachineLearning/comments/2gl621/something_about_cats_dogs_machine_and_deep/,little__big,1410895399,,0,13
156,2014-9-17,2014,9,17,5,2glfj5,Top Cities and Other Demographics for Data Scientists,https://www.reddit.com/r/MachineLearning/comments/2glfj5/top_cities_and_other_demographics_for_data/,urinec,1410900299,,1,2
157,2014-9-17,2014,9,17,13,2gmodv,Artificial Intelligence Is Doomed if We Don't Control Our Data,https://www.reddit.com/r/MachineLearning/comments/2gmodv/artificial_intelligence_is_doomed_if_we_dont/,biomimic,1410926519,,2,0
158,2014-9-17,2014,9,17,13,2gmse3,Best companies to apply for machine learning internships?,https://www.reddit.com/r/MachineLearning/comments/2gmse3/best_companies_to_apply_for_machine_learning/,matlab484,1410929317,"Does anyone have any recommendations on where/how to apply to them? Im a junior in computer science and I'd love to apply to any company doing cool stuff in ml, but I really don't know where to start in terms of a list of companies. ",15,10
159,2014-9-17,2014,9,17,16,2gn3qh,Vector Space API v0.1 based on in silico Cognitive Biomimicry,https://www.reddit.com/r/MachineLearning/comments/2gn3qh/vector_space_api_v01_based_on_in_silico_cognitive/,biomimic,1410939758,,0,2
160,2014-9-17,2014,9,17,20,2gneof,"Deep learning - The ""Average"" Facial Representation",https://www.reddit.com/r/MachineLearning/comments/2gneof/deep_learning_the_average_facial_representation/,TheAlienDude,1410952281,"Hi all,

Question:
I am doing some research on learning the ""average"" representation of a person's face from various facial images from the subjects.

I am thinking of maybe doing it like this:

1) Get an arbitrary small number (like 5) of the most clean frontal-face images of the person as targets (*Y*). Remaining images go in the *X* set.

2) Permute *X* and *Y* so that for each target of the subject in the set *Y* will be used as target for each entry in *X*. So if *X* has 20 images for *subject1* and *Y* has 5 images of *subject1* this means that the final training set would have 100 entries, 5 for each entry in *X*, for each subject.

3) Use a deep network in order to learn a facial representation for each subject that approximates all the targets for that subject with the least error. Thus acquiring (hopefully) an ""average"" of each of the subject's images in *Y*. (with optionally some extra constraints such as penalizing asymmetry

Now I do realize this is probably not very optimal, especially when it comes to approximating the average representation using 5 different targets for each entry in *X*, and using MSE will probably not do very well in this case.

So my question is: Has there been any research on this? Is there a better error measure, or method I could use?

**Note:** I am not looking to do sample reduction either. The targets *Y* will have the same resolution as inputs *X*",4,2
161,2014-9-17,2014,9,17,22,2gnodg,Dirichlet Process Mixtures and label switching,https://www.reddit.com/r/MachineLearning/comments/2gnodg/dirichlet_process_mixtures_and_label_switching/,superbobry,1410960260,"I'm reading a paper by Kurihara et al. [""Collapsed Variational Dirichlet Process Mixture Models""](http://people.ee.duke.edu/~lcarin/IJCAI07-449.pdf), 2007. The paper compares different representation of the DP prior and VB inference for these approaches. One of the flaws of the truncated stick-breaking representation in the VB setting is that it's **not** invariant to label switching, i.e. randomly permuting the labels changes the probability of the data.

In section ""Optimal Cluster Label Reordering"" the authors suggest a way to overcome this. Here's a quote:

&gt; The optimal relabelling of the clusters is given by the one that orders the cluster sizes in decreasing order.


I have a problem understanding two things about the proposed method:

1. How the relabelling procedure should be incorporated into the VB algorithm.
2. Why relabelling doesn't break anything.

",6,2
162,2014-9-17,2014,9,17,23,2gnt4r,Picking step size for gradient descent,https://www.reddit.com/r/MachineLearning/comments/2gnt4r/picking_step_size_for_gradient_descent/,AlexandreZani,1410963361,"I'm writing a least-squares linear regression program. (as a learning exercise) It mostly works, but I can't figure out how to select the initial step size when doing the gradient descent. What are good techniques for that?",7,5
163,2014-9-18,2014,9,18,3,2goizd,Microsoft Machine Learning Hackathon 2014 - Report,https://www.reddit.com/r/MachineLearning/comments/2goizd/microsoft_machine_learning_hackathon_2014_report/,vkhuc,1410977143,,2,9
164,2014-9-18,2014,9,18,3,2goj6n,WalnutiQ: Biologically inspired machine learning in Java,https://www.reddit.com/r/MachineLearning/comments/2goj6n/walnutiq_biologically_inspired_machine_learning/,quinnliu1,1410977263,,2,7
165,2014-9-18,2014,9,18,4,2gopfa,"Visualizing (Gradient) Optimization Techniques (Annealing, Stochastic Gradient Descent, Momentum, Nesterov, AdaGrad, AdaDelta).",https://www.reddit.com/r/MachineLearning/comments/2gopfa/visualizing_gradient_optimization_techniques/,robertsdionne,1410980530,,18,11
166,2014-9-18,2014,9,18,5,2gp385,GoogLeNet slides from ECCV 2014 workshop,https://www.reddit.com/r/MachineLearning/comments/2gp385/googlenet_slides_from_eccv_2014_workshop/,osdf,1410987553,,21,36
167,2014-9-18,2014,9,18,9,2gpozy,GoogleLeNet paper: Going Deeper with Convolutions,https://www.reddit.com/r/MachineLearning/comments/2gpozy/googlelenet_paper_going_deeper_with_convolutions/,doomie,1410999592,,0,2
168,2014-9-18,2014,9,18,15,2gql5f,Are projects such as Azure ML going to make data science less lucrative?,https://www.reddit.com/r/MachineLearning/comments/2gql5f/are_projects_such_as_azure_ml_going_to_make_data/,nrmlform,1411020048," I don't have a lot of background in machine learning so I can't properly gauge how much Azure ML lowers barriers to entry and similar projects may further lower barriers to entry in the future, so I don't have much more to elaborate past the title. ",1,0
169,2014-9-18,2014,9,18,21,2gr9jx,DeepLearning.University  An Annotated Deep Learning Bibliography,https://www.reddit.com/r/MachineLearning/comments/2gr9jx/deeplearninguniversity_an_annotated_deep_learning/,atveit,1411044975,,5,13
170,2014-9-18,2014,9,18,22,2grf3r,Using data science to build better products,https://www.reddit.com/r/MachineLearning/comments/2grf3r/using_data_science_to_build_better_products/,hernamesbarbara,1411048600,,0,5
171,2014-9-18,2014,9,18,22,2grf74,"Computer, Let Me Know What's Interesting About This Article",https://www.reddit.com/r/MachineLearning/comments/2grf74/computer_let_me_know_whats_interesting_about_this/,wheeler1432,1411048671,,1,0
172,2014-9-18,2014,9,18,23,2grkxj,Estimating linear functions using SGD and a square loss function,https://www.reddit.com/r/MachineLearning/comments/2grkxj/estimating_linear_functions_using_sgd_and_a/,AlexandreZani,1411052057,"I have a true underlying model of ax+by+some error=z a,b,x,y,z are real numbers. (x and y are constrained to be between 0 and 1000)
My data set is a set of ([x,y], z). x an y are my features, z is my label.
My data is randomly distributed.

Now I want to estimate a and b.
So I start with a random a and b and do SGD. My error is the average of the squares of the error.

The algorithm looks like this:

* randomly pick a or b.
* randomly choose to increment or decrement by step size
* calculate new error
* if new error &gt; old error, undo
* otherwise, new error = old error
* do it again

So, if I calculate the error over the whole dataset, no problem. But if I try to compute the error over a subset of the data set, it doesnt work and here is why: as x and y grow, so does the error since the error is:

((a-a')x + (b-b')y)^2

And so if on iteration 1 I calculate errors over a subset with small xs and ys and in iteration 2 the xs and yx in the subset I pick are big, the error of the second iteration will be higher regardless of whether I stepped in the right direction or not.

So how do I solve this? Is square the wrong loss function? Wont this problem come up with any loss function? Should I pick a single subset of the dataset to calc error on instead of picking a new one each time? Isnt there a risk of bias? Any other comments?

(forgive typos, 1 arm out of order makes typing hard)",14,0
173,2014-9-19,2014,9,19,1,2gry5e,Andrew Ng (Stanford University) on Deep Learning,https://www.reddit.com/r/MachineLearning/comments/2gry5e/andrew_ng_stanford_university_on_deep_learning/,[deleted],1411059185,,14,78
174,2014-9-19,2014,9,19,2,2gs12z,Weka vs scikit-learn/NLTK?,https://www.reddit.com/r/MachineLearning/comments/2gs12z/weka_vs_scikitlearnnltk/,computer_scientist1,1411060717,"Im in the process of selecting a tool for natural language processing/machine learning/sentiment analisys task in spanish. By the way , could anybody help me to convince to my thesis advisor why scikit learn is better than Weka. I need some factual data, features on why scikits better option than weka, i argued that productivity is a nice feature of scikit-learn but my advisor didnt like the argument.

Thanks",5,3
175,2014-9-19,2014,9,19,2,2gs2km,A Novel Semi-Supervised Algorithm for Rare Prescription Side Effect Discovery,https://www.reddit.com/r/MachineLearning/comments/2gs2km/a_novel_semisupervised_algorithm_for_rare/,incredulitor,1411061502,,0,1
176,2014-9-19,2014,9,19,4,2gsdab,1 Determining Parameter Ranges for Scikit-learn's GridSearchCV,https://www.reddit.com/r/MachineLearning/comments/2gsdab/1_determining_parameter_ranges_for_scikitlearns/,Stareons,1411067120,"I asked this yesterday in /r/learnpython but with no responses so I am trying again here.

I am playing with Scikit-learn for the first time.  I have a little bit of machine learning experience but am in no way an expert.  One of the interesting tools I see is GridSearchCV so I don't have to manually try different combinations and permutations of parameters.

So following [this](http://scikit-learn.org/stable/auto_examples/grid_search_digits.html#example-grid-search-digits-py) as a tutorial and guide I can see how to implement the function.  What I am curious is how do you know within what ranges do you try values for the different parameters.

For example if I am trying to train C in my SVM we can look at the [SVC documents](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)

But all it says is:

&gt; C : float, optional (default=1.0)
 
&gt; Penalty parameter C of the error term.

So I have no idea if I should be trying positive numbers, negative numbers, in [0.0, 1.0], if I should be trying 0.1, 0.01, 0.001, etc or if I should be going larger in trying 9, 99, 999, 9999.

Obviously I could enter in all those different numbers in the parmeter value of GridSearchCV (but there are literally infinite) so I am wondering if there is a more intuitive way to find the realistic ranges of values to try for different parameters?  ",2,1
177,2014-9-19,2014,9,19,5,2gspo2,"Machine Learning Project: Email app that can classify and ""summarize"" emails",https://www.reddit.com/r/MachineLearning/comments/2gspo2/machine_learning_project_email_app_that_can/,pchun008,1411073537,"Hi r/machinelearning community, 

I'm excited to see if there are any able machine learners looking into using their special set of skills to help get a new email app off the ground. The general idea is that I'm creating an email app that can categorize emails and extract key information from emails. At this point of the product, we need more added input from machine learners to test the feasibility of the app. We want to create a robust and powerful machine learning email app.  

How you can help:

1. Add to the conversation- how we can classify emails and how machine learning can specifically help with extracting key information from emails.

2. If you know of any tools, programming, or articles that can help us understand the machine learning on a conceptual level.

3. Aid in planning and obtaining a realistic training set 

Most if not all of the project is currently in the planning phase so you will have the ability to be really creative with your solution. 

Here's the link to the specific task: www.bit.ly/1BN6bJA

Thanks everyone, hope to collaborate with you guys soon.

",1,0
178,2014-9-19,2014,9,19,9,2gtezt,Proof that weight sharing + downsampling = mathematical convolution,https://www.reddit.com/r/MachineLearning/comments/2gtezt/proof_that_weight_sharing_downsampling/,wandarksend,1411088004,"Hello!

I have been independently studying CNNs and have been a little frustrated because I am trying to implement my own CNN and a lot of literature is a bit vague on the details of their architecture. This required me to go back to the source and read some of LeCun's papers from 1989 and 1990.

When he presents his Net-5 he describes the idea of weight sharing and downsampling. However, not until a later paper in 1990 does he describe it again and then says that it is equivalent to a convolution with a small kernel. The paper states this with no justification.

Maybe this is obvious for some people, but I know very little about mathematical convolutions, and do not understand the intuition behind them. Thus I don't understand the relationship between them and weight sharing + downsampling.

Can anyone help explain these concepts to me? Or point me to literature that does make this connection?

Thanks so much!",3,2
179,2014-9-19,2014,9,19,19,2gukuz,Machine learning Tools vs theory,https://www.reddit.com/r/MachineLearning/comments/2gukuz/machine_learning_tools_vs_theory/,nischalhp,1411122051,"Hello,

I am starting to find machine learning interesting but the discussions I have had with some people always leaves me with a question. All these guys know how to use tools but they dont really understand what happens behind the scenes. 

Isnt it important to understand why something in machine learning works and what are the difference before using the tools that give outputs based on stackoverflow discussions?

Or the only way to understand machine learning is to use tools and learn progressively? 

I would love to know what you guys think, I will be working on project soon which might involve machine learning and I dont want to take it up without understand what machine learning involves.

",4,3
180,2014-9-19,2014,9,19,23,2gv4ua,"Where to start with data analytics/mining? (x-posted to r/MachineLearning, r/LearnProgramming, and r/Statistics)",https://www.reddit.com/r/MachineLearning/comments/2gv4ua/where_to_start_with_data_analyticsmining_xposted/,lolajoan,1411137896,"Let me preface by saying that I'm a librarian with some basic web and database skills - not a real programmer. I'm a quick study though, but I don't always know where to begin or how deep I'm going to have to go with a project.

What we have: Our library transactions (check-outs, renewals, as well as research questions and also the book catalog and customer database) are tracked in a MySQL database (via a library-specific product). We have some functions on our website that use PHP to pull stuff from the database, and I'm reasonably competent at manipulating that. We also use Crystal Reports to do some basic stats and reporting.

What I want to do: customer profiling, discovery of trends, and other basic data analytics and data mining. 

""Big data"" is of course the buzzword going around, but from my reading it seems clear that what we really need is just basic analytics. I've tried doing some research to find a product or service or platform that could be useful. I dont have much of a budget, though if I prove that I can get some useful stuff going then I might get some budget  next year.

So what Im looking for here is advice about which product or service (if any) I should be looking into. Any advice is appreciated!!

The options Im looking at:

* http://ubiq.co/ - surprisingly cheap web based reporting for MySQL
* http://infinidb.co/ - would use the open source version, but might have to learn Hadoop? Also might be too big data for my needs
* https://spark.apache.org  supposed to be an easier alternative to Hadoop (Im 90% sure our server runs on Apache  not sure if thats relevant)
* http://www.cloudera.com/ - seems like a bigger deal than I need at this time
* Learn to use http://en.wikipedia.org/wiki/Apache_Hive on top of Hadoop
* Just get way better at Crystal Reports
* Just use PowerPivot in Excel (after taking a course in it because I suck at basic pivot tables)
*  http://watsonanalytics.com/ - sounds like it might be exactly my speed  any experience with it?

**TLDR**  Idiot noob wants data analytics on MySQL. What do? Halp.",10,0
181,2014-9-20,2014,9,20,0,2gva78,Reactive LDA Library (x-post /r/scala),https://www.reddit.com/r/MachineLearning/comments/2gva78/reactive_lda_library_xpost_rscala/,[deleted],1411141089,,0,9
182,2014-9-20,2014,9,20,1,2gvgk3,Numenta: Increasing Research Transparency,https://www.reddit.com/r/MachineLearning/comments/2gvgk3/numenta_increasing_research_transparency/,numenta,1411144560,,5,3
183,2014-9-20,2014,9,20,3,2gvr6e,Surprising results in scikit learn's DecisionTreeClassifier,https://www.reddit.com/r/MachineLearning/comments/2gvr6e/surprising_results_in_scikit_learns/,merchinebelearned,1411150277,"I'm using scikit learn and tried out the decision tree classifier: http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html


Based on the default settings listed, I would expect the classifier to always predict with 100% accuracy on the data set it was trained on unless the data set has two data points with the exact same features, but with different labels. I don't think my dataset has a lot of these, but I could be wrong. Am I misunderstanding the classifier somehow, or should my assumption be correct?


Thanks!",9,3
184,2014-9-20,2014,9,20,5,2gw6ip,"Paris Machine Learning Meetup #1, Season 2: A New Beginning (Snips, Nomo, Clustaar and more) - Slides in English, Video in French -",https://www.reddit.com/r/MachineLearning/comments/2gw6ip/paris_machine_learning_meetup_1_season_2_a_new/,compsens,1411158906,,0,1
185,2014-9-20,2014,9,20,10,2gwxk4,Political Ideology Detection Using Recursive Neural Networks,https://www.reddit.com/r/MachineLearning/comments/2gwxk4/political_ideology_detection_using_recursive/,captcompile,1411176201,,0,27
186,2014-9-20,2014,9,20,15,2gxitm,"Sci kit and Building ML Systems with Python, unexpected results",https://www.reddit.com/r/MachineLearning/comments/2gxitm/sci_kit_and_building_ml_systems_with_python/,[deleted],1411193074,"Hi,


I'm working through `Building ML Systems with Python`. It uses the Isis set. There is this code:

    plength = features[:, 2]
    # use numpy operations to get setosa features
    is_setosa = (labels == 'setosa')
    # This is the important step:
    max_setosa =plength[is_setosa].max()
    min_non_setosa = plength[~is_setosa].min()
    print('Maximum of setosa: {0}.'.format(max_setosa))  
    print('Minimum of others: {0}.'.format(min_non_setosa))

The book says it should print 1.9 and 3.0, but having pasted it straight from the book, I get 1.4 and 1.3. 


Any idea what it could be? I paste the code from the book!",0,0
187,2014-9-20,2014,9,20,15,2gxjge,PAPER CUP FORMING MACHINE |PAPER CUP PRODUCTION LINE | E-Dynamic,https://www.reddit.com/r/MachineLearning/comments/2gxjge/paper_cup_forming_machine_paper_cup_production/,dongli201203,1411193660,,0,0
188,2014-9-21,2014,9,21,3,2gyu9m,An algorithm for trending topics,https://www.reddit.com/r/MachineLearning/comments/2gyu9m/an_algorithm_for_trending_topics/,[deleted],1411236100,,0,5
189,2014-9-21,2014,9,21,4,2gyzw6,"Saturday Morning Videos: Random Functions for Dependence and Component Analysis, Randomized Nonlinear Component Analysis and the Automatic Statistician",https://www.reddit.com/r/MachineLearning/comments/2gyzw6/saturday_morning_videos_random_functions_for/,compsens,1411239656,,0,10
190,2014-9-21,2014,9,21,5,2gzb3t,Machine learning internship in Europe?,https://www.reddit.com/r/MachineLearning/comments/2gzb3t/machine_learning_internship_in_europe/,perceptronico,1411246681,"A few days ago, u/matlab484 posted a question about a ML internship inside the US, and now I'm kindly asking you all basically the same thing, but this time for the European Union. It would be great if anyone could recommend a few companies (startups, big firms, it doesn't matter). I'm not asking much, I know it probably can't be a full blown ML internship (as in fitting models and doing analysis from scratch from day 1), but at least with some data munging/mining going on :)",3,0
191,2014-9-21,2014,9,21,6,2gzgbz,Bachelors Thesis in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/2gzgbz/bachelors_thesis_in_machine_learning/,eptheta,1411249930,"I'm an ML fan. Unfortunately, when I tell people I know ML, I basically mean:  
1) I've done a Coursera course and an ML course at uni  
2) I've done a project or two on classification/clustering  
3) I've read one paper on SVM optimizations(and that was really hard to do) and glanced at the abstracts of hundreds.  
&amp;nbsp;

In other words, I'm great at applying the things I learn about ML from the internet, but when I open up last year's NIPS or ICMLC proceedings, I don't understand much.   
I now have the daunting task of finding a professor willing to host me for 6 months for my Bachelor thesis.  
Who in their right mind would want to host someone who just knows the basic math behind some ML algorithms that he picked up from Coursera?  
&amp;nbsp;

----------------------------------------------------------------------  
My point is, I'm not sure how to approach the process of searching for a professor, because my interest in and understanding of ML isn't evolved enough to look at the publications of a professor, and say ""Hey, this guy's interests match up perfectly with mine! This might work!""  


I've been told to spam mails to everyone in an ML research group, mention something about one of their papers, and ask nicely to be part of the family. But  
A) There is no chance I'd be able to do justice to claiming I *read* their papers, so short of listing out my skills, and experience with ML, I can't think of anything else I can do.  
B) Sending mails to everyone like that is just plain insulting  

&amp;nbsp;

So my questions are:  
1) As a professor, what are you looking for in a student who is REALLY REALLY interested in doing a Bachelor thesis under you/with your ML research group?  
2) As an undergraduate student who's at my level of ML exposure, what should I be doing right now (other than reading a textbook on ML, I'm trying to do that anyway) with the motive of securing a Bachelor Thesis?  
3) How do I find these elusive, magical professors who are willing to take me in?  

&amp;nbsp;

PS: My university professors won't help me at all.",5,9
192,2014-9-21,2014,9,21,7,2gzm6a,"Work after Undergrad, or go for Masters?",https://www.reddit.com/r/MachineLearning/comments/2gzm6a/work_after_undergrad_or_go_for_masters/,caedin8,1411253853,"Hi all, 

I assume this subreddit is populated by many masters and phd students in ML. I am a senior computer science major, and i've been working as an undergraduate researcher for a year using ML. My question for you is, why did you choose to pursue a Masters or PhD in ML?

My dream job involves doing something with ML, or working on difficult computational problems. The last thing I want to do is be a generic application developer for a big company. But unfortunately that is the only job I've been able to find.

I am faced with the following decision, accept a job as a software consultant making 70k salary and hope that I can eventually move to a more interesting job after a few years experience, or I can apply for masters/phd programs in ML and then look for work again when I finish. I would really love to work for Amazon or Facebook or another big company that does a lot of ML work. Would it be easier to get there with a Masters or with 2-3 years experience doing software consulting?

I am sure some of you have been in my situation before, what did you do? Are you happy with your choices?

Thanks",11,6
193,2014-9-21,2014,9,21,8,2gzn9y,[Fresh off ArXiv] Deeply-Supervised Nets (claim to be new state-of-the-art for CV),https://www.reddit.com/r/MachineLearning/comments/2gzn9y/fresh_off_arxiv_deeplysupervised_nets_claim_to_be/,[deleted],1411254620,,1,1
194,2014-9-21,2014,9,21,9,2gzucs,"Top 2,500 Data Science, Big Data and Analytics Websites",https://www.reddit.com/r/MachineLearning/comments/2gzucs/top_2500_data_science_big_data_and_analytics/,urinec,1411259691,,0,12
195,2014-9-21,2014,9,21,14,2h0hoj,Python implementation of Neural Tensor Network,https://www.reddit.com/r/MachineLearning/comments/2h0hoj/python_implementation_of_neural_tensor_network/,[deleted],1411277697,,17,45
196,2014-9-21,2014,9,21,14,2h0ioe,Vibration control for wire bunching machines,https://www.reddit.com/r/MachineLearning/comments/2h0ioe/vibration_control_for_wire_bunching_machines/,Dynemech,1411278643,,1,1
197,2014-9-21,2014,9,21,15,2h0lh5,Any interesting machine learning project ideas?,https://www.reddit.com/r/MachineLearning/comments/2h0lh5/any_interesting_machine_learning_project_ideas/,UannaFF,1411281492,"Hi guys, i was wondering if any of you have some interesting ideas for a project using machine learning. Any idea is accepted, i am just brain storming to see what can i accomplish in three months of artificial intelligence class.",6,8
198,2014-9-21,2014,9,21,16,2h0nun,Anti Vibration Mounts for Wire Bunching Machinery,https://www.reddit.com/r/MachineLearning/comments/2h0nun/anti_vibration_mounts_for_wire_bunching_machinery/,Dynemech,1411284125,,1,1
199,2014-9-21,2014,9,21,19,2h0vuc,Help me make this cocktail party algorithm code from coursera's Machine Learning lecture work.,https://www.reddit.com/r/MachineLearning/comments/2h0vuc/help_me_make_this_cocktail_party_algorithm_code/,[deleted],1411294239,"using this sound file: http://www.ism.ac.jp/~shiro/research/sounds/RSM/X_rsm2.wav

I'm trying to recreate Andrew Ng's Machine Learning presentation(https://class.coursera.org/ml-005/lecture) from coursera in matlab

What I do is to read a .wav file (16khz, 7 sec, 2 channels)

    [x,xfs] = wavread('track.wav')
Now I transpose x

    x = x'
Now I proceed to use x on the cocktail party algorithm

    [W,s,v] = svd((repmat(sum(x.*x,1),size(x,1),1).*x)*x')
MATLAB returns:

    W =

       -0.9233   -0.3841
       -0.3841    0.9233


    s =

      265.4832         0
             0   13.0768


    v =

       -0.9233   -0.3841
       -0.3841    0.9233
Where is the separated audio?

",5,0
200,2014-9-21,2014,9,21,20,2h0yj6,Introduction to Random forest  Simplified,https://www.reddit.com/r/MachineLearning/comments/2h0yj6/introduction_to_random_forest_simplified/,kunalj101,1411297578,,0,0
201,2014-9-22,2014,9,22,9,2h2x3e,Script to download CS109 Data Science lecture videos,https://www.reddit.com/r/MachineLearning/comments/2h2x3e/script_to_download_cs109_data_science_lecture/,Chrispy645,1411345245,"Just thought I'd post my repo here for those that are interested in downloading the actual lecture videos for Harvard's CS109 Data Science course. Those videos are found [here](http://cm.dce.harvard.edu/2014/01/14328/publicationListing.shtml) but there's no download link. I'm also paranoid the page may disappear in the future or something, I don't know.

Here's the repo:

https://github.com/chrispy645/cs109-dl-videos

Hope this helps.",1,28
202,2014-9-22,2014,9,22,18,2h42ic,RiVal - an open source toolkit for recommender system evaluation.,https://www.reddit.com/r/MachineLearning/comments/2h42ic/rival_an_open_source_toolkit_for_recommender/,recsys,1411378545,,2,13
203,2014-9-22,2014,9,22,20,2h49jc,ROMs for DeepMind Atari paper?,https://www.reddit.com/r/MachineLearning/comments/2h49jc/roms_for_deepmind_atari_paper/,[deleted],1411386163,"Hi,

Does anyone know where to find the ROMs for the DeepMind paper on the Arcade Learning Environment?

I'm particularly interested in pong.bin - but I can't find it anywhere so far.

",5,2
204,2014-9-22,2014,9,22,22,2h4jzx,What is the state of the art on estimating online purchase intention?,https://www.reddit.com/r/MachineLearning/comments/2h4jzx/what_is_the_state_of_the_art_on_estimating_online/,[deleted],1411394186,"I'm interested in getting a real-time estimate of the probability that a visitor at an online shop will actually purchase a product.

I assume that something can be done by analyzing mouse movements, keyboard input and visited pages.

A Google search showed some studies but no references to something that can be programmed or automated.",0,1
205,2014-9-23,2014,9,23,1,2h4x4k,Getting Started with Deep Learning and Python,https://www.reddit.com/r/MachineLearning/comments/2h4x4k/getting_started_with_deep_learning_and_python/,zionsrogue,1411401734,,0,6
206,2014-9-23,2014,9,23,1,2h4yem,"How to use R, H2O, and Domino for a Kaggle competition",https://www.reddit.com/r/MachineLearning/comments/2h4yem/how_to_use_r_h2o_and_domino_for_a_kaggle/,DominoDataLab,1411402432,,3,37
207,2014-9-23,2014,9,23,1,2h52g4,ML/Regression based numerical function approximation for lowering (substantial) CPU overhead,https://www.reddit.com/r/MachineLearning/comments/2h52g4/mlregression_based_numerical_function/,AffineParameter,1411404529,"I am looking into utilizing a ML regression technique to approximate a very computationally expensive, but known, function for purposes of improving processing rates (is this common?). 

This function maps a 40 dimensional (floating-point) parameter space to a scalar (also floating-point). The forty dimensions can be reduced (using symmetry and other conserved quantities) to roughly 21 parameters (some of which are periodic), and the internal correlations are known very well and are non-linear.

Over the course of the last few months, we (with the help of a nice global compute network) have spent nearly 350 CPU-years to evaluate this function on the order of 2.2 billion times. Which gives us an average run time of just over 5 seconds per evaluation.

In the coming years, we will need to scale up that 2.2 billion number by orders of magnitude, and I don't believe our compute network will scale at that rate, so we need to come up with a solution. 

My idea was to use the 2.2 billion samples we already have to train some ML regression technique to approximate this function under the Universal approximation theorem. Evaluating the NN should take orders of magnitude less time per sample than a 5 second function, and information lost due to the approximation should be recoverable using a separate technique I recently developed (unique to this problem domain).

Initially, I applied my own implementation of a kNN regression technique which got modest results and definitely showed that there was something to be gained, but the approximation was too rough for ""prime time"" ... so I need to step it up. I am leaning toward using a SGD Regressor but I don't have a handy C++ implementation in the package I am currently using. (Suggestions welcome)

So, any suggestions for where to start? Or more importantly, avenues to avoid? I am probably more interested in a discussion regarding ML-based performance optimizations as I am familiar with some ML techniques but am certainly not a dedicated Data Scientist. 

(Thanks in advance for your time and patience.)",13,6
208,2014-9-23,2014,9,23,12,2h71gs,Coursera's Machine Learning course starts again today!,https://www.reddit.com/r/MachineLearning/comments/2h71gs/courseras_machine_learning_course_starts_again/,sj90,1411442967,,21,72
209,2014-9-23,2014,9,23,16,2h7jcb,Why Machine Translation Falls Short on Quality - Other,https://www.reddit.com/r/MachineLearning/comments/2h7jcb/why_machine_translation_falls_short_on_quality/,tridindia05,1411456612,,0,1
210,2014-9-23,2014,9,23,21,2h832e,Introduction to the inner workings of support vector machines,https://www.reddit.com/r/MachineLearning/comments/2h832e/introduction_to_the_inner_workings_of_support/,copybin,1411476643,,2,0
211,2014-9-23,2014,9,23,23,2h8abk,Is there a word for using something like an autoencoder but to learn the optimal projection of one distribution onto another?,https://www.reddit.com/r/MachineLearning/comments/2h8abk/is_there_a_word_for_using_something_like_an/,alexgmcm,1411481621,"So basically it'd be like an autoencoder but the desired output is not the input, but rather another distribution of the input data.

So for problems of non-stationary data sources where the distributions may change between applications we try to map the new data onto the old data so that the old classifier should still work fairly well without needing to retrain the entire model.

Basically adding a layer to the network for new data that maps it as close as possible to the old data that was used to train the remainder of the network, so we only have to train one layer, rather than retrain the whole model when we get new data.

Does this even make sense?",8,2
212,2014-9-23,2014,9,23,23,2h8eia,[ArXiv] Deeply-Supervised Nets (claim to be new SOTA in CV),https://www.reddit.com/r/MachineLearning/comments/2h8eia/arxiv_deeplysupervised_nets_claim_to_be_new_sota/,dhammack,1411484029,,4,4
213,2014-9-24,2014,9,24,0,2h8h68,Multicore LDA in Python: from over-night to over-lunch,https://www.reddit.com/r/MachineLearning/comments/2h8h68/multicore_lda_in_python_from_overnight_to/,piskvorky,1411485524,,3,19
214,2014-9-24,2014,9,24,1,2h8rrk,Mutlilayer perceptrons with only 1 hidden layer?,https://www.reddit.com/r/MachineLearning/comments/2h8rrk/mutlilayer_perceptrons_with_only_1_hidden_layer/,AshHershaft,1411491261,Are multiplayer perceptrons with a single hidden layer used in industry anywhere today?,11,1
215,2014-9-24,2014,9,24,3,2h94uj,Implementing Machine Learning Algorithms,https://www.reddit.com/r/MachineLearning/comments/2h94uj/implementing_machine_learning_algorithms/,binge_learner,1411498069,"Hi everyone,

Most of the resources on Machine Learning, either teach you the theoretical side of it, or how to use existing libraries.
Are there resources on how to actually implement Machine Learning algorithms, with example pseudo-code or code in Java/C/Python or whatever ? Something that can help people get enough practice to actually be able to go from reading a Machine Learning paper to implementing its content ?

Thank you.",11,26
216,2014-9-24,2014,9,24,4,2h97ah,ML Work w/ Masters plus experience?,https://www.reddit.com/r/MachineLearning/comments/2h97ah/ml_work_w_masters_plus_experience/,[deleted],1411499307,"Yeah, I know, yet another post about this subject. I'll try to add my own spin to it.

I have a Masters in CS, with my thesis involving recurrent neural networks applied to a scientific domain (purposefully being vague). I also have a few years experience as a Data Scientist at an e-commerce startup (smaller company was willing to hire me without a PhD, etc).

Can my experience get my foot in the door at other places looking for Data Scientists/ML Engineers? I don't mind not being considered for ML algorithm research position. I just want a more application position, where I can solve data problems. It's very discouraging when just about all job listings mention that PhDs are strongly preferred.

I do not have any current plans/wants to go back for a PhD.",0,1
217,2014-9-24,2014,9,24,5,2h9j6r,Choosing a Recommender Model,https://www.reddit.com/r/MachineLearning/comments/2h9j6r/choosing_a_recommender_model/,pacmanisfun,1411505495,,0,1
218,2014-9-24,2014,9,24,8,2h9xyf,[Discussion]Finding correlations on a complex datasets with WEKA,https://www.reddit.com/r/MachineLearning/comments/2h9xyf/discussionfinding_correlations_on_a_complex/,programmingnoobie,1411513463,"I had been learning machine learn since last week so I am quite fairly new to the data mining/machine learning field. I downloaded WEKA yesterday and gone through two classes of WekaMOOC but still couldn't learn what I want.

Here is the thing. I have a dataset that contains lots of variables like temperature, waterflow, voltage and such.

The problem here is that the waterflow level decreased over time, everytime it dropped to 1.0 litre/minute, the machine stops. My job here is to find correlations on a complex datasets and find variables that is link to the waterflow level. I know a bit of R Studio but will be glad if anyone can tell me how to do it on WEKA.

This is just some random practice my professor gave me because I told him I want to learn more about machine learning. I hope you people can bring me insights of machine learning. Please enlighten me!",5,0
219,2014-9-24,2014,9,24,13,2hastf,Markov Chain of St James Bible + CS book [X-post from r/webdev],https://www.reddit.com/r/MachineLearning/comments/2hastf/markov_chain_of_st_james_bible_cs_book_xpost_from/,iheartennui,1411531932,,6,70
220,2014-9-24,2014,9,24,13,2hasx2,problems with SVM's over 4 classes,https://www.reddit.com/r/MachineLearning/comments/2hasx2/problems_with_svms_over_4_classes/,StevenTucker,1411532000,"I have a data set with 6 classes. Any subset of 4 classes can be predicted with SVM's, and any pairwise comparison of classes is easily resolved. Yet when I try to use SVM's to discern between 5+ classes, the accuracy goes over the falls. Is this a common SVM problem?",3,1
221,2014-9-24,2014,9,24,13,2haulb,Software recommendation for 1 v 1 round robin,https://www.reddit.com/r/MachineLearning/comments/2haulb/software_recommendation_for_1_v_1_round_robin/,DanSavagesTeet,1411533162,I am trying to do 1 vs 1 round robin multiclass classification - but using different parameters (and selected attributes) for each pairwise classifier. What is some good software to do this en mass?,0,1
222,2014-9-24,2014,9,24,16,2hb7v6,Convolutional Neural network query and advise.,https://www.reddit.com/r/MachineLearning/comments/2hb7v6/convolutional_neural_network_query_and_advise/,automater,1411544878,"Firstly forgive me if my terminology is not correct as this is a field for which I am certainly no expert but basically taken a dive. Thus expect some oddities below if you have a reasonable level of expertise. Information below is fairly sparse but some of you may still have thoughts that might point me in the right direction.

I have been working on a fruit picking project.  One of the challenges to this project has been developing an imaging system that can determine what is fruit and what is not fruit. At a glance it seems fairly easy. I really only need to identify one thing- being weather a pixel in an image is fruit and do this for all pixels in an image. Fruit does seem obvious by colour on the tree. However after working for some time on the problem I still have not achieved a reliability level that is in my mind high enough. It is important to keep in mind a *very* high reliability level is required for commercial feasibility. It is close but not quiet there yet and thus I am hoping for some advise from people who might be interested.

So far it seems Identifying fruit is fairly challenging in the sense that:

1. Real world imaging can be noisy.  White balance is not always consistent. Camera dynamic range is limited and over exposure(heavily effects colour of the region) and sun flairs  are common. Lighting is not controlled so strong shadows are evident.

2. Fruit is regularly obstructed by leaves. It has little shape and little structure. Camera resolution is not high enough to detect the very subtle texture on the fruit that would make it easier to identify. That said I can readily identify what is fruit from the image myself so there should be enough data in the image.

3. I can see that if I change an image to black and white then even for myself it is not obvious which parts are fruit are which parts are leaves. Yes unobstructed fruit is obvious but much that has partial leaf cover is not obvious and easily mistaken. Thus colour is certainly important but has limited dependability.

4. The system must run in real time(preferably 50ms or less per frame) and its done on a per pixel basis.


Currently I am using a self developed hardware accelerated convolutional neural network. Thanks to some prior experience in hardware acceleration it runs fairly fast and thanks to the repetitive structure of convolution neural networks it is repeated very efficiently across an entire image.

I have methods for training it in mini batches via back propagation with momentum, rprop and rmsprop as per obvious literature suggestions. So far I have not implemented dropout(had it in early version but got lost in some optimisations). Activation functions include sigmoids, tanh and RELU units.  Typical structures I try are 5 to 8 layers deep. Map sample size is 5x5 as I cant see much point making it larger due to the lack of structure in fruit obstructed by leaves(wrong maybe- to small?). With some variability I am now trying 90+ maps per layer as lower counts seemed to get to a certain level of reliability but still mis detect some leaves as fruit(for example) in cases where I would expect it to do better. Thus currently I have 10 to 30million connections and about 200k of unique weights used to determine if a pixel is fruit or not(if my serviette calculation is not wrong). To be this seems significant, as if it should be enough, specifically given the lack of structure but perhaps I am wrong?

Something I notice is that error levels during training initially drop very fast. I guess its probably locking onto colour and simple gradients but then the error rate starts to fall very slowly. Slowly in terms of days training for small gains.  So far I dont seem to be over learning but still stuck with under learning.  Training wise I am using a radeon R9 280 and its all running 32bit floats which should give an indication of processing power being used.

One query I have is with regards to what you train too. Literature suggest train to non linear portions of the activation function. How about RELU? For 0 do you train to 0 ,or some variable above or below. For the low side so far I suspect slightly above 0 is best to reduce units from dropping out due to never being activated.  What about secondary non linearities in the target. Do you train such to an exact target value or to a value that is above or below the given target(so far I am trying both) for example in the non linear case if target is 1, and output is 1.5 and then I dont feeback an error as that to me is good, its above the target.I would however feedback that error if it were below 1.  A similar thing is done for the off case? Thoughts?

Otherwise I have also started to look into odd areas that might help like considering other options other than simply adding inputs before the activation function.  One that appeals to me from work in another field is something like a numerical or of inputs. Instead of for example Sig(A1+A2) you have Sig(A1+A2-A1*A2,..gets more complicated for more inputs..).  It is interesting to me because at different magnitudes its acts differently(ie much less than 1 it is more like just A1+A2 for example and near 1 it acts more like an or, above 1 more like xor). I suspect that the xor nature when inputs get large might be useful for forcing input maps to be more unique and more orthogonal(ie force faster convergence on something that might resemble an auto encoder) but am still working on the maths.  Has there been any significant academic investigation into such concepts that anyone can point out?

For me the obvious area would be do you think the structure is appropriate?  Otherwise any thoughts are welcome. Perhaps I am just not training long enough? Thoughts?",8,5
223,2014-9-24,2014,9,24,18,2hbefk,learning curve for Neural network / Machine learning,https://www.reddit.com/r/MachineLearning/comments/2hbefk/learning_curve_for_neural_network_machine_learning/,rishok,1411552349,"I understand the idea of learning curve and how to solve problems based on its information.

https://www.youtube.com/watch?v=g4XluwGYPaA

QUESTION:
If we take the MNIST task with 60k training set + 10k test set. 

I will vary my training set to evaluate, but how big should my test set to be for this. E.g.. if I only use 2000k training set should my test set can still be 10k?",4,2
224,2014-9-24,2014,9,24,20,2hbj5m,Most popular Deep Learning Papers in the (2014) Bibliography,https://www.reddit.com/r/MachineLearning/comments/2hbj5m/most_popular_deep_learning_papers_in_the_2014/,atveit,1411557418,,0,14
225,2014-9-24,2014,9,24,21,2hbot0,[Learning]: Additional learning resources on machine learning,https://www.reddit.com/r/MachineLearning/comments/2hbot0/learning_additional_learning_resources_on_machine/,archerimagine,1411562181,"Hi All,

I have read through the wiki of [MachineLearning](http://www.reddit.com/r/MachineLearning/wiki/index) and it list great resources, I was just trying to collate any other learning resources which are valuable but not mentioned in the wiki. Kindly post your resources.

Here is a sample which I found useful in addition to the wiki.

1. [What's the easiest way to learn machine learning?](http://www.quora.com/Whats-the-easiest-way-to-learn-machine-learning) ",1,3
226,2014-9-25,2014,9,25,1,2hcd8i,cross entropy for Relu and unbounded data ?,https://www.reddit.com/r/MachineLearning/comments/2hcd8i/cross_entropy_for_relu_and_unbounded_data/,rishok,1411576621,"Hi 
Is it smart to use the cross entropy loss function when the activation function used is Relu and is unbounded?

The input is the MNIST data, so binary

It is for an auto-encoder

side note (the reason for my question):

I made two different auto-encoder networks. One with maxout units (with the shared weights) and another with maxout units (where the weights are not shared, like LWTA).

My problem is that my cost value (""mean squared error"") is not close to zero when the data size is small (eg. Training set of 2 sapmles).

In order to optimize my network, I tried to make a learning curve (which is why I need the cost value of a small training set) and came across the problem.

I have tried linear, sigmoid and softplus for the output layer... and still get a big value and don't know why

I use the L-BFGS (matlab's minfunc) for optimization, and it picks the learning rate",10,4
227,2014-9-25,2014,9,25,4,2hczpx,PCA reduction,https://www.reddit.com/r/MachineLearning/comments/2hczpx/pca_reduction/,no_porner,1411588117,How to perform PCA reduction of images in matlab?,0,0
228,2014-9-25,2014,9,25,6,2hd9i4,decision tree based classifiers,https://www.reddit.com/r/MachineLearning/comments/2hd9i4/decision_tree_based_classifiers/,mchine,1411593063,"In decision tree based classifiers (decision tree, random forest, GBT, etc...), the scaling of features is irrelevant since a split point is chosen based on how many points are above/below the split point. So, for example, in a text classification task, the results should be the same for tf (term frequency) features as tf-idf (term frequency - inverse document frequency) features. Is this correct?",3,2
229,2014-9-25,2014,9,25,6,2hdc59,My Attempt at Outperforming Deepmind's Atari Results,https://www.reddit.com/r/MachineLearning/comments/2hdc59/my_attempt_at_outperforming_deepminds_atari/,CireNeikual,1411594466,"Hello!

I am a reinforcement learning hobbyist, and I made myself a challenge: To outperform DeepMind's reinforcement learning agent in the Arcade Learning Environment!

I will be posting updates here as I go!

The codebase I am using (currently separate from the ALE for easier experimentation) is available here: [https://github.com/222464/AILib](https://github.com/222464/AILib)

It contains a large number of agents, the one I am currently working on is called HTMRL (hierarchical temporal memory reinforcement learning).

_What do I do differently?_

First off, I do not have a fixed time window of previous inputs to ""solve"" the hidden state problem. Rather, I am using HTM (hierarchical temporal memory) to form a context for the input automatically, as well as compress the input down to a manageable number of features.

From there, I use a simple feed-forward neural network(s) to be the actor/critic (I have two versions, one with an actor for continuous actions, not necessary for the ALE). These take the output of the last HTM region as input.

The critic-only version (discrete action) updates using standard Q learning updates plus eligibility traces.

The actor-critic version maintains a Q function in the critic and uses a form of policy gradient to optimize the actor on the Q values.

Right now I am working on getting it to function flawlessly on the pole balancing task before scaling up to the ALE.

Here is an image of HTMRL performing pole balancing. The top right shows the highest-level HTM region.

[http://i1218.photobucket.com/albums/dd401/222464/HTMRLPoleBalancing.png~original](http://i1218.photobucket.com/albums/dd401/222464/HTMRLPoleBalancing.png~original)

More coming soon!",9,48
230,2014-9-25,2014,9,25,13,2heisq,One line code of Independent Component Analysis in Matlab/Octave problem.,https://www.reddit.com/r/MachineLearning/comments/2heisq/one_line_code_of_independent_component_analysis/,Lelouch_Yagami,1411620675,"I have been trying to recreate the ICA algorithm Andrew Ng showed  at https://class.coursera.org/ml-005/lecture/4. He mentioned that using only one line of code in Matlab/Octave, it should work. I'm really fascinated by this. However I'm having problems making it work properly.


Using this sound file:  http://www.ism.ac.jp/~shiro/research/sounds/RSM/X_rsm2.wav. 

What I do first is to read a .wav file (16khz, 7 sec, 2 channels)

    [x,xfs] = wavread('track.wav')
    x =
    0.0183    0.0599
    0.0839    0.0833
    0.1250    0.1096
    0.2048    0.1173
    0.2299    0.0631
    0.1151    0.0299
    0.0583    0.0359
    0.0688    0.0631
    0.1052    0.0935 //110000 samples in 2 channels
Now to my understanding, I need to transpose x to make the data 'horizontal'.

    x = x'

Next I proceed to use the code of ICA. 

    [W,s,v] = svd((repmat(sum(x.*x,1),size(x,1),1).*x)*x')
MATLAB returns:

    W =

       -0.9233   -0.3841
       -0.3841    0.9233


    s =

      265.4832         0
             0   13.0768


    v =

       -0.9233   -0.3841
       -0.3841    0.9233
When I multiply the sound matrix to it's transposed matrix, it will only return a size of 2 x 2. I do not have the separated sound sources here. Most likely, I do not have a proper x for this algo.

EDIT: Apparently, I think I was already getting the right output of the code. W is suppose to be only the 'unmixing matrix'. I have no idea how to use this to get the 2 separated sound.
",8,0
231,2014-9-25,2014,9,25,17,2hexz5,"Training cost value big for a small training size (eg. Training set of 2 sapmles), why?",https://www.reddit.com/r/MachineLearning/comments/2hexz5/training_cost_value_big_for_a_small_training_size/,[deleted],1411635210,"Hi

I made two different auto-encoder networks. One with maxout units (with the shared weights) and another maxout units (where the weights are not shared, like LWTA).

My problem is that my cost value (""mean squared error"") is not close to zero when the data size is small (eg. Training set of 2 sapmles).

In order to optimize my network, I tried to make a learning curve (which is why I need the cost value of a small training set) and came across the problem.

I have tried linear, sigmoid and softplus for the output layer... and still get a big value and don't know why

Side note:
I use the L-BFGS (matlab's minfunc) for optimization, and it picks the learning rate",0,0
232,2014-9-25,2014,9,25,18,2heysk,Top Advantages Of Forklift Attachments,https://www.reddit.com/r/MachineLearning/comments/2heysk/top_advantages_of_forklift_attachments/,AlexBanner,1411636166,,0,1
233,2014-9-26,2014,9,26,2,2hg4d7,A Tutorial on Support Vector Machines for Pattern Recognition (PDF),https://www.reddit.com/r/MachineLearning/comments/2hg4d7/a_tutorial_on_support_vector_machines_for_pattern/,rasbt,1411666022,,4,8
234,2014-9-26,2014,9,26,3,2hg9ns,The next Turing Test? Handwriting.,https://www.reddit.com/r/MachineLearning/comments/2hg9ns/the_next_turing_test_handwriting/,cavedave,1411668748,,14,0
235,2014-9-26,2014,9,26,4,2hghmp,Dropout causing big training cost error for small training size?,https://www.reddit.com/r/MachineLearning/comments/2hghmp/dropout_causing_big_training_cost_error_for_small/,rishok,1411672873,"Hi all

I was wondering if Dropout can cause big training cost error rather then a cost error close to zero, when the training size is small like 2 sample (used for learning curve)",3,2
236,2014-9-26,2014,9,26,4,2hgk37,How to Engineer Features and get good at it,https://www.reddit.com/r/MachineLearning/comments/2hgk37/how_to_engineer_features_and_get_good_at_it/,jasonb,1411674149,,6,23
237,2014-9-26,2014,9,26,5,2hgos7,Online Learning and Sub-Linear Debugging - Machine Learning,https://www.reddit.com/r/MachineLearning/comments/2hgos7/online_learning_and_sublinear_debugging_machine/,mttd,1411676613,,0,6
238,2014-9-26,2014,9,26,7,2hgzi4,Weka java API: Attribute Selection and Cross Validation,https://www.reddit.com/r/MachineLearning/comments/2hgzi4/weka_java_api_attribute_selection_and_cross/,__null__,1411682485,"Is there a way to perform Attribute selection(feature selection) regardless of method only for the training set before passing data for Cross Validation using the Weka API?

I currently think that the only possible way to perform this using the Weka API is through AttributeSelectedClassifier. However I am not yet sure whether this method performs attribute selection first in the whole dataset (without taking into account the cross-validation folds) and then classification, thus possibly introducing bias into the cross validation evaluation result.

Any Ideas?",1,0
239,2014-9-26,2014,9,26,9,2hhesz,Procedural locomotion using linear regression,https://www.reddit.com/r/MachineLearning/comments/2hhesz/procedural_locomotion_using_linear_regression/,hhm,1411691629,,0,4
240,2014-9-26,2014,9,26,11,2hhrxg,Comprehensive collection of literature about Support Vector Machines (SVMs),https://www.reddit.com/r/MachineLearning/comments/2hhrxg/comprehensive_collection_of_literature_about/,rasbt,1411699890,,0,2
241,2014-9-26,2014,9,26,14,2hi65a,Fundamental Nature of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/2hi65a/fundamental_nature_of_machine_learning/,tquarton,1411710443,"Though I am highly interested in Machine Learning, I am very hesitant to make the dive and jump into it. Having begun being trained as a physicist and currently a PhD student in synthetic and systems biology, I am very drawn to natural systems and the underlying universal truths contained within them. Every time I begin to skim the surface of ML, I quickly get lost in between ""the amazing new algorithm X"" and ""the statistically relevant approximation method Y"" being applied to ""extremely specific problem Z"". 

Can an experienced person in this field try to appeal to my theoretical physicist instincts and explain how ML is important and relevant on a universally fundamental scale? I think I have a project which could benefit from a ML treatment, but I'd really like to shake this naive feeling that I'm wading in a sea of overly-specific algorithm optimization races. I know a good start would be to realize that most ML is based purely on statistics, the field whose application with the right minds birthed statistical mechanics, thermodynamics and quantum mechanics all of which I feel are universally fundamental.

Anyone else feel like this? I would love review articles or any references to help persuade me. Thanks so much.",30,19
242,2014-9-26,2014,9,26,19,2him0m,"LinkedIn open sources its ML library, ml-ease",https://www.reddit.com/r/MachineLearning/comments/2him0m/linkedin_open_sources_its_ml_library_mlease/,[deleted],1411727801,,9,52
243,2014-9-26,2014,9,26,20,2hiqpa,BigML Late Summer Release: Anomaly Detection and More!,https://www.reddit.com/r/MachineLearning/comments/2hiqpa/bigml_late_summer_release_anomaly_detection_and/,osroca,1411732591,,0,0
244,2014-9-26,2014,9,26,21,2hitjq,IPython notebook of Machines and Intelligence lab class by Neil Lawrence,https://www.reddit.com/r/MachineLearning/comments/2hitjq/ipython_notebook_of_machines_and_intelligence_lab/,[deleted],1411734991,,0,19
245,2014-9-27,2014,9,27,0,2hj73x,Interesting YouTube Channels?,https://www.reddit.com/r/MachineLearning/comments/2hj73x/interesting_youtube_channels/,chocobanh,1411743903,"On YouTube, Sixty Symbols was engaging enough to make me curious about physics and learn physics on my own.  Computerphile isn't as engaging for me, even though I love Computer Science.  

I've found neural network stuff, and have even programmed a few AI simulations on my own.  But, Sixty Symbols and Minute Physics and all cover such a breadth of topics that if I get interested enough, I can dive deeper.  I haven't found any such channels for Computer Science and the like, really.  So I need... a gateway drug for AI and Machine Learning, got any suggestions?",1,9
246,2014-9-27,2014,9,27,0,2hj95w,"For deeplearning and AI, R or Python?",https://www.reddit.com/r/MachineLearning/comments/2hj95w/for_deeplearning_and_ai_r_or_python/,capecamorin,1411745066,"R vs Python is everywhere but however at some point one has to choose one. 
 &gt; **R** has much to do with Statistical computing and data analytics. 
 &gt; It has been used for a long time in scientific/mathematical computing.
 &gt; Has much support and packages for ML/Data science.

 &gt; **Python**  seems versatile being a general purpose language.
 &gt; It seems to be catching up and gaining much attention for doing data science only in recent years.

In Layman terms,which one to choose for what? What could be the career path after choosing it?",6,0
247,2014-9-27,2014,9,27,2,2hjm90,Artificial General Intelligence that plays Atari video games: How did DeepMind do it?,https://www.reddit.com/r/MachineLearning/comments/2hjm90/artificial_general_intelligence_that_plays_atari/,sinhue,1411752248,,16,17
248,2014-9-27,2014,9,27,2,2hjmxa,List of Top Machine Learning experts you should be following on Twitter,https://www.reddit.com/r/MachineLearning/comments/2hjmxa/list_of_top_machine_learning_experts_you_should/,sanket04,1411752648,,0,0
249,2014-9-27,2014,9,27,4,2hk13q,L2 Regularization for multi-task deep neural network learning,https://www.reddit.com/r/MachineLearning/comments/2hk13q/l2_regularization_for_multitask_deep_neural/,speechMachine,1411760692,"I am trying to train a deep neural network, the hidden layers of which are shared between multiple tasks.  My networks are pre-trained with RBM generative pre-training with data from all the tasks.

Though I do get reasonable error rates on my validation set, I see that my model overfits quickly on all the tasks. The overfitting behaviour is consistent amongst all of the tasks. 

I tried a blanket L2 regularization for the soft-max layer only for all the tasks. Now my validation errors behave differently for each task. Though they do not necessarily overfit, on one task the classification performance is relatively bad. Is there any literature that talks about L2 regularization for multi-task learning with neural networks?",1,5
250,2014-9-27,2014,9,27,5,2hk6i9,"Great list of resources: data science, visualization, machine learning, big data",https://www.reddit.com/r/MachineLearning/comments/2hk6i9/great_list_of_resources_data_science/,vincentg64,1411763781,,2,13
251,2014-9-27,2014,9,27,6,2hk96m,My Attempt at Outperforming Deepmind's Atari Results - UPDATE 1,https://www.reddit.com/r/MachineLearning/comments/2hk96m/my_attempt_at_outperforming_deepminds_atari/,CireNeikual,1411765329,"Hello again!

Time for an update!

The first thing I did after my original post was try to optimize HTMRL in order to get more gradient descent updates for the actor/critic portion. I started by experimenting with various numbers of HTM layers and sizes such that the last layer (the input to the actor/critic) was of an appropriate size that was small enough to run fast and large enough to convey enough information.

Secondly, I stopped using vanilla stochastic gradient descent for the actor/critic and started using RMSProp, just like in the original DeepMind paper. It was a simple change but quickly gave me better performance.

Thirdly, I started experimenting with ways to convert the binary information outputted by the last HTM region for the actor/critic into a floating-point representation that preserves information but does not hurt generalization at the same time. Originally I did a straight up binary to floating point value conversion, but this makes similar HTM configurations result in vastly different outputs, which greatly hurts generalization. So, instead I then opted for the lossy but generalizing approach: to sum the inputs and divide by the maximum count. This doesn't take all the positional information of the input into account, but with a small enough condensing radius it can provide a decent compression/loss tradeoff.

Fourth, I played with some advantage learning replacements for standard Q learning. Advantage learning functions better then standard Q learning in continuous environments, since it amplifies the differences in state-action value between the successive timesteps more. This makes it less susceptible to errors in the function approximation as well as noise.

Finally, I received help from the SFML community in making the code work on more platforms. They even added CMake support for me! Many thanks!

That's it for this update, time to get back to coding!",1,30
252,2014-9-27,2014,9,27,6,2hkemn,What Python skills do I need to become a data scientist?,https://www.reddit.com/r/MachineLearning/comments/2hkemn/what_python_skills_do_i_need_to_become_a_data/,duncansdonuts,1411768564,"Currently, I'm taking a python class just to get the basics down, but would like to know anything python-specific that I should be focusing on afterwards. I'm very proficient at SAS and SQL, but python is my missing factor in order to get these jobs. So what kinds of python syntax and programming should I be gearing towards my next step?",4,0
253,2014-9-27,2014,9,27,9,2hksdq,What is the field of machine learning studying specifically prediction/data correlation?,https://www.reddit.com/r/MachineLearning/comments/2hksdq/what_is_the_field_of_machine_learning_studying/,SrPeixinho,1411777528,"Suppose I have 2 datasets and I want to know if there is any correlation between them. For example, a set of pictures and a boolean `containsCat`. I want a system that, given a few samples, finds a generalization. Simple as that.

I know this is an artificial intelligence problem, but the field is so huge I'm not sure what are the right keywords to look at it. I know neural networks are a tool, but it is just one tool. If I google for it I will probably be missing a lot.

So what exactly is the name of that problem, and what is a good starting point for learning the state of art takes on it? What are the relevant keywords?",8,0
254,2014-9-27,2014,9,27,11,2hl0dw,Journal Club/Subreddit,https://www.reddit.com/r/MachineLearning/comments/2hl0dw/journal_clubsubreddit/,captcompile,1411783477,"Hi everyone. I just thought I'd make a post because I was curious about what happened to the last post about starting a journal club/subreddit. I remember someone made a form to gauge interest. After filling out the form, I noticed that there was some interest in starting something.

Anyone gots any updates? I'm pretty keen for this.",15,6
255,2014-9-27,2014,9,27,11,2hl2oh,Idea to improve neural networks,https://www.reddit.com/r/MachineLearning/comments/2hl2oh/idea_to_improve_neural_networks/,RoshawnTerrell,1411785203,"Neural networks are a way of programming, or better, a way of computation that greatly resembles the way your brain works.

Its a relatively new method of programming that has shown to be very useful. I honestly think that neural networks could be the future of all, if not most computation.

Right now, neural networks are used only for things such as image recognition, mapping patterns. Overall used in a way that require you only to train the network, because apparently that is the only way to use them. This statement as you may have realized, foreshadows the main point/idea i am trying to get across.

You can read the rest here: http://ideastwctw.blogspot.com/2014/09/idea-to-improve-neural-networks.html",6,0
256,2014-9-27,2014,9,27,23,2hmaqn,How to mine pictures of someone chronologically?,https://www.reddit.com/r/MachineLearning/comments/2hmaqn/how_to_mine_pictures_of_someone_chronologically/,sloby,1411829920,"Hi fellow redditors!

I want to collect pictures of a certain publicly known person and arrange them chronologically. The goal is to do analysis of him about the aging we see.

How can I create a mining/scraping algorithm in python (or any other language) that reliably scraps pictures of a person online and attaches a date of that picture **reliably**?",1,1
257,2014-9-28,2014,9,28,0,2hmbon,'Show off' with data!,https://www.reddit.com/r/MachineLearning/comments/2hmbon/show_off_with_data/,sloby,1411830590,"Hi there!

I am recently reading and learning a lot about data sciences and machine learning. I am currently working as a contractor with a middle sized firm that is trading pesticides, plant protection materials and various agricultural related stuff and also packaging. 

I'm currently working as a software developer but I want to show them what data science or machine learning can do to the firm. I asked the CEO previously that I'm into this and if the company might need some kind of insight based on this but he was not interested. 

I honestly think that it's due to the fact that I was not able to sell the whole concept to him. I figured maybe it would be best to do it on my own and show him a few graphs or predictions that I could extract from the data I have.

The company is using a custom ERP software that I have full access to. It contains the usual stuff for billing, product list, inventory, customer data, shipping data, etc.

I know it's best if one starts these kind of tasks with a clear goal rather than ""start digging and see what you can find"" approach but it is what it is now..

Besides customer clustering and sales prediction what do you think should I look into?",6,0
258,2014-9-28,2014,9,28,3,2hmu94,I have a rich log of daily activity. Is there any way artificial intelligence can help me finding what triggers my migraines?,https://www.reddit.com/r/MachineLearning/comments/2hmu94/i_have_a_rich_log_of_daily_activity_is_there_any/,SrPeixinho,1411842755,"I've been logging my daily activity for some time now. I have a huge dataset, including:

- Very detailed log of food intake (including timestamps and milligram-precise nutritional information).
- Activity (calories spend, coming from an ""life-hack"" app that tracks my location using GPS).
- Location x Time (same app).
- Sleep/Wakeup time, including waking up mid night (I log it using another app).
- From those I can also infer time working, watching TV, etc.
- Water intake (just weight/day, from measuring a bottle once per day).
- Body weight (measured daily).
- Migraine episodes (start time, duration).
- Blood pressure, blood sugar and body temperature, measured 4 times a day.
- Mood, also 4 times a day.
- Bathroom usage.
- Additional activities such as sex, sports, gaming are logged too.

For anyone wondering, I'm doing this mostly for practicing programming and learning. It's being a cool project, but I wonder if I can somehow find correlations between that data. For example, I'd love to know if an specific food is somehow linked to the migraine episodes. I'd also love to know random trivia such as ""if you eat at morning you are much more likely to have good mood at afternoon"", or ""eating X grams of sugar at once always makes you want to nap"".

Is there any way artificial intelligence can help me on that? 

Edit: just editing here to say I've read all answers and am thankful for you all! I have exactly the info I asked for and much more, thanks. This is a long term project as I'm really busy with other things (opencl/gpu stuff) - the reason I posted now is so that I could have time to plan, buy some books, etc. Since you guys asked, I'll be posting the database and results when I start working with it. Thank you very much!",44,49
259,2014-9-28,2014,9,28,6,2hndlw,Research internships in ML for a Master's student?,https://www.reddit.com/r/MachineLearning/comments/2hndlw/research_internships_in_ml_for_a_masters_student/,zmjjmz,1411855054,"Hey /r/MachineLearning. I'm a (newly minted) Masters student in ML&amp;CV, and I'm looking to do a research internship in the field (preferably corporate research). 

So does anyone know of some good research programs / departments to apply to that take MS students for internships? A lot of the places I've looked at look for PhD only, and I'm just not at that level yet.",1,6
260,2014-9-28,2014,9,28,15,2hoica,efficient method for making a binary classifier multiclass?,https://www.reddit.com/r/MachineLearning/comments/2hoica/efficient_method_for_making_a_binary_classifier/,dogshark77,1411886982,"I am attempting to use binary SVM classification on a 10 class set. It is important to do this as 1 vs 1 binary, because each pair of classes is best separated by a particuluar subset of attributes (as determined with SVM weights). However, training the 45 classifiers this would require would be very time consuming. Does anyone have any experience or advice?",3,1
261,2014-9-28,2014,9,28,22,2hp0fe,Reading list on Bayesian methods,https://www.reddit.com/r/MachineLearning/comments/2hp0fe/reading_list_on_bayesian_methods/,xamdam,1411909612,,1,38
262,2014-9-29,2014,9,29,2,2hpngv,"Apart from the very top, what universities in US offer a great program for MS specializing in Machine learning?",https://www.reddit.com/r/MachineLearning/comments/2hpngv/apart_from_the_very_top_what_universities_in_us/,[deleted],1411925979,"Hi /r/MachineLearning,

I am applying for Masters in Machine learning this year. My profile can't take me to the top 5-6 universities (CMU, Stanford, UCB, UWashington, UT Austin). What are my next options for good Masters program in Machine learning in the USA?

I am looking for universities with enough relevant courses and faculty working in the field of Machine learning. Please suggest good ones.

Thanks in advance! ",11,0
263,2014-9-29,2014,9,29,6,2hqda8,My Attempt at Outperforming Deepmind's Atari Results - UPDATE 2,https://www.reddit.com/r/MachineLearning/comments/2hqda8/my_attempt_at_outperforming_deepminds_atari/,CireNeikual,1411941028,"Hello again!

I am now (almost) satisfied with the performance of the system on pole balancing. The main issue I am having right now is with the function approximators for the actor/critic. They are slow and lack enough precision. Fortunately though, the switch to advantage(lambda) learning helped remedy the inaccuracy in the function approximation to some extent. I need massive Tau values to get decent performance, so increasing the accuracy of the function approximators is a top priority.

Aside from that, I worked on the generalization capabilities of the function approximators. I added regularization and early stopping. I also started using a combination of epsilon-greedy and softmax action selection.

I also experimented with using separate function approximators for each action (for the discrete action version). The intuition behind this is that this will reduce error interference and make it easier to learn the larger differences in outputs that result from advantage learning.

I added plotting capabilities using [sfml-plot](https://github.com/bechu/sfml-plot), allowing me to better observe what effects my changes have.

Here is an image of the pole balancing experiment with plotting: [http://i1218.photobucket.com/albums/dd401/222464/polebalancingimage.png](http://i1218.photobucket.com/albums/dd401/222464/polebalancingimage.png)

Until next time!",4,37
264,2014-9-29,2014,9,29,7,2hqiex,[Journal Club] Organisatorial stuff &amp; poll for first paper,https://www.reddit.com/r/MachineLearning/comments/2hqiex/journal_club_organisatorial_stuff_poll_for_first/,BeatLeJuce,1411944265,"Hi there!

Sorry this took so long to set up. I'm currently kind of swamped at work, so I don't have much time to devote to organizing this as I'd like to.

Please post your suggestions for the first paper we are going to read/discuss in this thread, and use your up- and downvotes to vote for/against papers you're interested in.

**Dates**


The paper that has the most votes by Friday 2014-10-03, 20:00 CEST will be the one we're going to discuss. I'd say we give everyone a week to read it, thus the first discussion thread will go up Friday, 2014-10-10. 

The next voting thread will go up on 2014-10-03 as well. I don't know yet how we're going to handle papers that have come in 2nd place in a voting. Maybe they should get a bonus in the next round of voting. I'm open for suggestions!

**Topics**


I know some people like the idea of doing topics, but I feel like no consensus was reached in the last thread we had about it. How about we just ""wing it"" for the time being? If people want to do more papers of the same topic, please feel free to vote such papers to the front.

Also, to keep confusion to a minimum, please keep this thread for paper-voting only. Please open a new thread to suggest improvements to the process. This is kind of rushed (sorry!), but people are eager to get started, so I didn't want to wait any longer.

",12,14
265,2014-9-29,2014,9,29,14,2hrke9,19yr old CS student's take on data science,https://www.reddit.com/r/MachineLearning/comments/2hrke9/19yr_old_cs_students_take_on_data_science/,gwulfs,1411969218,,3,0
266,2014-9-29,2014,9,29,19,2hrytn,Conv Nets Questions,https://www.reddit.com/r/MachineLearning/comments/2hrytn/conv_nets_questions/,fhadley,1411985548,"Finally doing CV like the cool kids. Two questions:

1) If I train on a GPU, can I deploy in a cpu only environment?
2) If, over a given feature space, I have ~1 missing feature, can I treat this vector as a ""specified"" dropout unit? It's not the same feature all the time obviously.",3,1
267,2014-9-29,2014,9,29,20,2hs4ii,Hacker's guide to Neural Networks (cross post from /r/datascientists),https://www.reddit.com/r/MachineLearning/comments/2hs4ii/hackers_guide_to_neural_networks_cross_post_from/,kunalj101,1411991952,,12,98
268,2014-9-29,2014,9,29,23,2hsgoa,PAPIs.io 2014 Call for Proposals  Predictive APIs and Apps,https://www.reddit.com/r/MachineLearning/comments/2hsgoa/papisio_2014_call_for_proposals_predictive_apis/,louisdorard,1412000763,,0,0
269,2014-9-30,2014,9,30,0,2hspd9,"Wolfe: expressive, extensible and efficient ML (in Scala)",https://www.reddit.com/r/MachineLearning/comments/2hspd9/wolfe_expressive_extensible_and_efficient_ml_in/,petrux,1412006117,,0,10
270,2014-9-30,2014,9,30,1,2hsqmn,Who Owns the Future: Getting paid for our data,https://www.reddit.com/r/MachineLearning/comments/2hsqmn/who_owns_the_future_getting_paid_for_our_data/,gwulfs,1412006853,,0,1
271,2014-9-30,2014,9,30,2,2hsx1v,Seeking ML researchers for tomorrow's /r/compsci questions thread,https://www.reddit.com/r/MachineLearning/comments/2hsx1v/seeking_ml_researchers_for_tomorrows_rcompsci/,cypherx,1412010442,,0,2
272,2014-9-30,2014,9,30,3,2ht4xj,Just a gentle reminder Coursera Mining Massive Datasets has started. Happy Learning.,https://www.reddit.com/r/MachineLearning/comments/2ht4xj/just_a_gentle_reminder_coursera_mining_massive/,[deleted],1412014378,,3,30
273,2014-9-30,2014,9,30,4,2htc9d,Elements of machine learning - free book,https://www.reddit.com/r/MachineLearning/comments/2htc9d/elements_of_machine_learning_free_book/,vincentg64,1412018187,,1,0
274,2014-9-30,2014,9,30,5,2hto0o,Former IBM Watson exec: Cognitive is biggest disruption in computing since Internet,https://www.reddit.com/r/MachineLearning/comments/2hto0o/former_ibm_watson_exec_cognitive_is_biggest/,mtl1015,1412024020,,2,0
275,2014-9-30,2014,9,30,7,2htwv6,Using Machine Learning and NodeJS to detect the gender of Instagram Users,https://www.reddit.com/r/MachineLearning/comments/2htwv6/using_machine_learning_and_nodejs_to_detect_the/,cavedave,1412028521,,2,6
276,2014-9-30,2014,9,30,7,2htxx0,Syncing Weekly Updates with PubChem,https://www.reddit.com/r/MachineLearning/comments/2htxx0/syncing_weekly_updates_with_pubchem/,[deleted],1412029063,,1,2
277,2014-9-30,2014,9,30,12,2hutye,"hey guys, what would you do with The New Yorker corpus?",https://www.reddit.com/r/MachineLearning/comments/2hutye/hey_guys_what_would_you_do_with_the_new_yorker/,charliehack,1412047334,"Intuitively, it seems like it would be an interesting object of study from an NLP perspective, because there's so much Culture encoded in it.

It exists somewhere on Cond Nast's servers in messy OCR'd text; judging by some searches on archives.newyorker.com and playing with the chrome console, it's structured something like 

    'issue1':{
        'page1':'electronics. We began to build vac- uum-tube circuits that did all sorts of things. "" As an undergraduate, Minsky had begun to imagine building an elec- tronic machine that could learn. He had become fascinated', 
        'page2': ...
    } 

so there aren't clear delineations between articles off the bat.

The best I've got so far (thanks /u/agconway for the ideation!) is use NER to extract place names, and plot on a heatmap over time by mention frequency. Then one could (somewhat playfully) address the question-- is The New Yorker really as NY-biased as it's reputed to be?

Also cool would be ""zooming in"" and heatmapping mentions of *neighborhoods* in cities over time, ""hipmapping"" if you will ;)

Could also compare stuff like word usages against the Wikipedia corpus...

LDA topics vs. the Wikipedia corpus....

thoughts, anyone?",4,13
278,2014-9-30,2014,9,30,12,2huw4j,Can you help me design an algo for 3-player Goofspiel? (x-post /r/algorithms),https://www.reddit.com/r/MachineLearning/comments/2huw4j/can_you_help_me_design_an_algo_for_3player/,[deleted],1412048667,.,0,2
279,2014-9-30,2014,9,30,12,2hux8j,What has neuroscience done for machine intelligence?,https://www.reddit.com/r/MachineLearning/comments/2hux8j/what_has_neuroscience_done_for_machine/,DevFRus,1412049356,,16,21
280,2014-9-30,2014,9,30,13,2hv027,"""Rise of the Machines"" by Larry Wasserman [PDF]",https://www.reddit.com/r/MachineLearning/comments/2hv027/rise_of_the_machines_by_larry_wasserman_pdf/,carmichael561,1412051180,,2,14
281,2014-9-30,2014,9,30,15,2hvavn,Jakarta Indonesia Continues to attract Equipment Manufacturers to set up Local Production,https://www.reddit.com/r/MachineLearning/comments/2hvavn/jakarta_indonesia_continues_to_attract_equipment/,chunheiyee,1412060333,,1,0
282,2014-9-30,2014,9,30,18,2hvjkq,Coursera: Linear and Integer Programming starts in a week,https://www.reddit.com/r/MachineLearning/comments/2hvjkq/coursera_linear_and_integer_programming_starts_in/,maybemax,1412070336,,1,6
