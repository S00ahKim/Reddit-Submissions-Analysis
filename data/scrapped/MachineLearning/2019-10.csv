,sbr,sbr_id,date,year,month,hour,day,id,domain,title,full_link,author,created,selftext,num_comments,score,over_18,thumbnail,media_provider,media_thumbnail,media_title,media_description,media_url
0,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,9,dbl9ca,self.MachineLearning,"New to AI/ML, is it possible?",https://www.reddit.com/r/MachineLearning/comments/dbl9ca/new_to_aiml_is_it_possible/,DARKKINGKING,1569890505,[removed],0,1,False,self,,,,,
1,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,9,dbldgk,self.MachineLearning,ICASSP or IEEE Access?,https://www.reddit.com/r/MachineLearning/comments/dbldgk/icassp_or_ieee_access/,iAwaisRauf,1569891039,[removed],1,1,False,self,,,,,
2,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,9,dble48,self.MachineLearning,[P] Pytorch implementation of a Intrusion Detection system,https://www.reddit.com/r/MachineLearning/comments/dble48/p_pytorch_implementation_of_a_intrusion_detection/,jaloo555,1569891123,"Hi guys,

I'm a newbie to machine learning and this is my first time posting so I'm kind of nervous... This is my implementation of a research paper regarding an intrusion detection system using pytorch. Please give some feedback and suggestions on what can be added. 

Repo: [https://github.com/jaloo555/ids\_dl](https://github.com/jaloo555/ids_dl)

Research Paper: [https://eudl.eu/pdf/10.4108/eai.3-12-2015.2262516](https://eudl.eu/pdf/10.4108/eai.3-12-2015.2262516)

On a side note: It would be amazing if anyone would like to join me in bringing this into a demo webapp showing intrusion statistics!",3,4,False,self,,,,,
3,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,9,dble4a,self.MachineLearning,[R] The Paths Perspective on Value Learning (Distill.pub Article),https://www.reddit.com/r/MachineLearning/comments/dble4a/r_the_paths_perspective_on_value_learning/,baylearn,1569891123,"A new [article](https://distill.pub/2019/paths-perspective-on-value-learning/) on distill pub with interactive visualizations on value learning:

**The Paths Perspective on Value Learning**

A closer look at how Temporal Difference learning merges paths of experience for greater statistical efficiency.

https://distill.pub/2019/paths-perspective-on-value-learning/",2,13,False,self,,,,,
4,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,10,dbljsw,self.MachineLearning,GPT-2 Embeddings in Python?,https://www.reddit.com/r/MachineLearning/comments/dbljsw/gpt2_embeddings_in_python/,NMister_,1569891829,[removed],0,1,False,self,,,,,
5,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,10,dbm1a9,self.MachineLearning,"Is there interest in a ""Cracking the Machine Learning Interview"" book?",https://www.reddit.com/r/MachineLearning/comments/dbm1a9/is_there_interest_in_a_cracking_the_machine/,shenkev,1569894065,[removed],0,1,False,self,,,,,
6,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,11,dbmm6a,self.MachineLearning,[D] Using A Classifier's Feature Importance Output To Approximate a Choice Model and Rank Priority of Features,https://www.reddit.com/r/MachineLearning/comments/dbmm6a/d_using_a_classifiers_feature_importance_output/,SpicyBroseph,1569896839,"Hello,

Was wondering if anybody had ever done this. I've searched quite a bit but haven't come up with anything. 

I have a bunch of hotel data with different features (amenities like a pool, workout room, number of rooms, a whole bunch of others) as well as a bunch of results of people who chose hotel A vs B, etc. I need to figure out which ""features"" played prominently in people choosing certain hotels over others. Classic customer choice. 

Not sure a discrete choice model is the best for this, though I'm exploring it- but, essentially, I'm trying to figure out if I can approach this as a supervised learning problem in order to figure out which of these features figure most highly into choices of hotels. 

Having looked at classifier feature importance in the past on a lot of projects (mainly xgboost) if I were able to get creative and properly vectorize lists of features in my input set between hotels, in a way that would allow me to train a classifier on the choices, I could then look at which features were most important as a measure of choice forecasting. 

Assuming the data has cohesive predictive characteristics, would this approach make sense? Or is this a bastardization of how feature importance is supposed to work?",0,1,False,self,,,,,
7,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,11,dbmul7,self.MachineLearning,"[D] How Machine Learning, 5G and Data Science Will be Critical to the Future of the Internet of Things",https://www.reddit.com/r/MachineLearning/comments/dbmul7/d_how_machine_learning_5g_and_data_science_will/,lautarolobo,1569897953,"Hi yall! I wrote a post about Machine Learning, Data Science, 5G and IoT. Would you mind to give it a read? I would love to hear feedback from you guys!

Here's the link:

[https://lautarolobo.xyz/blog/how-machine-learning-5g-and-data-science-will-be-critical-to-the-future-of-the-internet-of-things/](https://lautarolobo.xyz/blog/how-machine-learning-5g-and-data-science-will-be-critical-to-the-future-of-the-internet-of-things/)

Tell me anything! 'Bout the site, the content, writing. Is it too nerdy? Too boring? Do you think that Machine Learning encryption will gain more popularity over time?",7,0,False,self,,,,,
8,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,13,dbo6ei,self.MachineLearning,FourthBrain fellowship for 6 Months Residential MachineLearning Training,https://www.reddit.com/r/MachineLearning/comments/dbo6ei/fourthbrain_fellowship_for_6_months_residential/,aiforworld2,1569904781,[removed],0,1,False,self,,,,,
9,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,13,dbo6ui,self.MachineLearning,Image processing but don't know the method,https://www.reddit.com/r/MachineLearning/comments/dbo6ui/image_processing_but_dont_know_the_method/,thePythonWizard,1569904852,[removed],0,1,False,self,,,,,
10,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,13,dbocwo,self.MachineLearning,SOTA of imbalanced learning?,https://www.reddit.com/r/MachineLearning/comments/dbocwo/sota_of_imbalanced_learning/,vaseline555,1569905835,[removed],0,1,False,self,,,,,
11,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,14,dbonvb,aistechnolabs.com,Machine learning app development from $12/hr - AIS Technolabs,https://www.reddit.com/r/MachineLearning/comments/dbonvb/machine_learning_app_development_from_12hr_ais/,clay_jensen12,1569907629,,0,1,False,default,,,,,
12,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,14,dbow2s,javatpoint.com,Supervised vs Unsupervised Learning,https://www.reddit.com/r/MachineLearning/comments/dbow2s/supervised_vs_unsupervised_learning/,nehapandey01,1569909063,,0,1,False,default,,,,,
13,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,15,dbp2l5,datalabs.optisolbusiness.com,"Vision Analytics Company | Frok lift safety | Helmet, vest and goggles Detection. | Activity Recognition | Facial Recognition | Automated Number Plate Recognition (ANPR)",https://www.reddit.com/r/MachineLearning/comments/dbp2l5/vision_analytics_company_frok_lift_safety_helmet/,optisol,1569910195,,0,1,False,default,,,,,
14,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,15,dbpbey,self.MachineLearning,Machine learning Training in Hyderabad,https://www.reddit.com/r/MachineLearning/comments/dbpbey/machine_learning_training_in_hyderabad/,bharat571,1569911746,[removed],0,1,False,self,,,,,
15,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,16,dbpjwy,analyticsinsight.net,Data Science and Machine Learning Implementation in All-Sized Enterprises,https://www.reddit.com/r/MachineLearning/comments/dbpjwy/data_science_and_machine_learning_implementation/,analyticsinsight,1569913331,,0,1,False,default,,,,,
16,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,17,dbq67q,self.MachineLearning,9 Revolutionary applications of AI,https://www.reddit.com/r/MachineLearning/comments/dbq67q/9_revolutionary_applications_of_ai/,BeatriceCarraro,1569917462,[removed],0,1,False,self,,,,,
17,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,17,dbqe1i,self.MachineLearning,[R] Building Deep Equivariant Capsule Networks,https://www.reddit.com/r/MachineLearning/comments/dbqe1i/r_building_deep_equivariant_capsule_networks/,quertioup,1569919010,"Hi! 

This is our new paper on capsule networks! [https://arxiv.org/abs/1908.01300](https://arxiv.org/abs/1908.01300)",2,9,False,self,,,,,
18,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,17,dbqf91,openreview.net,[R] City Metro Network Expansion with Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/dbqf91/r_city_metro_network_expansion_with_reinforcement/,baylearn,1569919259,,3,0,False,default,,,,,
19,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,17,dbqgy4,openreview.net,[R] Compressive Transformers for Long-Range Sequence Modelling,https://www.reddit.com/r/MachineLearning/comments/dbqgy4/r_compressive_transformers_for_longrange_sequence/,HigherTopoi,1569919624,,3,11,False,default,,,,,
20,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,18,dbqq9h,self.MachineLearning,This is the first time I have done anything related to machine learning so to understand it i created a neural network from scratch. I am using the iris data set to train it. My cost function for the output layer almost becomes a constant usually between 0.15-2.,https://www.reddit.com/r/MachineLearning/comments/dbqq9h/this_is_the_first_time_i_have_done_anything/,avg-banglorean,1569921424,[removed],0,1,False,self,,,,,
21,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,18,dbqt8y,self.MachineLearning,[P] OpenNMT-tf 2.0: a neural machine translation toolkit for TensorFlow 2.0,https://www.reddit.com/r/MachineLearning/comments/dbqt8y/p_opennmttf_20_a_neural_machine_translation/,guillaumekln,1569921980,"Hi all,

[https://github.com/OpenNMT/OpenNMT-tf](https://github.com/OpenNMT/OpenNMT-tf)

Just wanted to share this new major update of OpenNMT-tf, a toolkit for neural machine translation and sequence generation initially released in 2017. It has been completely redesigned for TensorFlow 2.0 and now includes [many useful modules and layers](http://opennmt.net/OpenNMT-tf/package/opennmt.html) that can be reused in other projects, from dataset utilities to beam search decoding.

Fully upgrading to TensorFlow 2.0 required some energy but we feel the changes are positive: the implementation is simpler, more consistent, and more extensible.

Please check it out, and feel free to ask questions!",2,12,False,self,,,,,
22,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,18,dbqtxm,derekchia.com,3 Common Technical Debts in Machine Learning and How to Avoid Them,https://www.reddit.com/r/MachineLearning/comments/dbqtxm/3_common_technical_debts_in_machine_learning_and/,rainboiboi,1569922107,,0,1,False,https://a.thumbs.redditmedia.com/yzTJLw4Y9AHWy7cKr_cZSKsAG-mXbiLhnfolSP7RGw0.jpg,,,,,
23,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,18,dbquqh,self.MachineLearning,How can I mathematically prove that Cross Entropy loss function is more steeper than Mean square errors?,https://www.reddit.com/r/MachineLearning/comments/dbquqh/how_can_i_mathematically_prove_that_cross_entropy/,luqmanwastaken,1569922274,[removed],0,1,False,self,,,,,
24,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,19,dbr9s4,self.MachineLearning,How do I start learning machine learning as I have become familiar with basic Python?,https://www.reddit.com/r/MachineLearning/comments/dbr9s4/how_do_i_start_learning_machine_learning_as_i/,shiningmatcha,1569924973,[removed],0,1,False,self,,,,,
25,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,19,dbrmje,self.MachineLearning,Which Machine Learning Algo will continue to be in use in year 2118?,https://www.reddit.com/r/MachineLearning/comments/dbrmje/which_machine_learning_algo_will_continue_to_be/,andrea_manero,1569927172,https://www.datasciencecentral.com/profiles/blogs/which-machine-learning-algo-will-continue-to-be-in-use-in-year,0,1,False,self,,,,,
26,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,20,dbsaxv,self.MachineLearning,Which Solenoid Actuator Is Best Quality Actuator?,https://www.reddit.com/r/MachineLearning/comments/dbsaxv/which_solenoid_actuator_is_best_quality_actuator/,uflowindia,1569931071,[removed],0,1,False,https://b.thumbs.redditmedia.com/G-XbWSoZRpb7j7DLr8UeuJOEKLgIpaY_ylZV5yuIlRU.jpg,,,,,
27,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,21,dbsnuq,youtube.com,Kernel Trick - An Absolute Beginner's Friendly Explanation,https://www.reddit.com/r/MachineLearning/comments/dbsnuq/kernel_trick_an_absolute_beginners_friendly/,benbihi,1569932934,,1,1,False,https://a.thumbs.redditmedia.com/aSGJXAOCOItkzAgcTTOChMb4W3oChPc1oFBeW2ajHO0.jpg,,,,,
28,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,21,dbsrhu,self.MachineLearning,Deep Regression - Impact of log transformation of target variable,https://www.reddit.com/r/MachineLearning/comments/dbsrhu/deep_regression_impact_of_log_transformation_of/,dolhasz,1569933454,[removed],0,1,False,self,,,,,
29,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,21,dbswmi,arxiv.org,[1909.11150] Exascale Deep Learning for Scientific Inverse Problems (500 TB dataset),https://www.reddit.com/r/MachineLearning/comments/dbswmi/190911150_exascale_deep_learning_for_scientific/,LDWoodworth,1569934158,,28,124,False,default,,,,,
30,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,22,dbt2is,self.MachineLearning,Predictive Model from Funnel CRM,https://www.reddit.com/r/MachineLearning/comments/dbt2is/predictive_model_from_funnel_crm/,bielinu,1569934964,[removed],0,1,False,self,,,,,
31,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,22,dbteli,self.MachineLearning,Vehicle Speed Detection,https://www.reddit.com/r/MachineLearning/comments/dbteli/vehicle_speed_detection/,as8801598,1569936547,[removed],0,1,False,self,,,,,
32,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,22,dbtjjm,self.learnmachinelearning,Guide me with my project,https://www.reddit.com/r/MachineLearning/comments/dbtjjm/guide_me_with_my_project/,Duwasiva,1569937191,,0,1,False,default,,,,,
33,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,22,dbtmki,self.MachineLearning,Why was my implementation removed?,https://www.reddit.com/r/MachineLearning/comments/dbtmki/why_was_my_implementation_removed/,OverLordGoldDragon,1569937603,[removed],0,1,False,self,,,,,
34,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,22,dbtn1a,self.MachineLearning,"Hey, i built a neural network ground-up. My cost is high(.2). I tried training it with only one data point and didn't have any problems. But when i started adding more, the cost started getting high. Could someone tell me possible problems in my network?",https://www.reddit.com/r/MachineLearning/comments/dbtn1a/hey_i_built_a_neural_network_groundup_my_cost_is/,avg-banglorean,1569937661,[removed],0,1,False,self,,,,,
35,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,22,dbtp9y,self.MachineLearning,New ML tool,https://www.reddit.com/r/MachineLearning/comments/dbtp9y/new_ml_tool/,twoguysandagpu,1569937961,[removed],0,1,False,self,,,,,
36,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,22,dbtphy,developer.amazon.com,"New Amazon data set, recorded in the lab during simulated dinner parties, will help address speech separation problem",https://www.reddit.com/r/MachineLearning/comments/dbtphy/new_amazon_data_set_recorded_in_the_lab_during/,georgecarlyle76,1569937994,,0,1,False,https://b.thumbs.redditmedia.com/E0eWD64OFyznqJgjP8nM81eYa5xjE6PLWxygVDcNZ3g.jpg,,,,,
37,MachineLearning,t5_2r3gv,2019-10-1,2019,10,1,23,dbtuow,developer.amazon.com,Amazon releases public data set to aid research on speech separation,https://www.reddit.com/r/MachineLearning/comments/dbtuow/amazon_releases_public_data_set_to_aid_research/,georgecarlyle76,1569938662,,0,1,False,https://b.thumbs.redditmedia.com/E0eWD64OFyznqJgjP8nM81eYa5xjE6PLWxygVDcNZ3g.jpg,,,,,
38,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,0,dbusmy,self.MachineLearning,[Discussion] Any datasets for multi-modal learning between time series and text?,https://www.reddit.com/r/MachineLearning/comments/dbusmy/discussion_any_datasets_for_multimodal_learning/,mistycheney,1569942788,"Multi-modal learning has traditionally focused on image/video vs text (e.g. image captioning, video description), but does anyone know good datasets for learning between text and time series? Example of time series: stock charts, power plant / wearable sensor readings, music etc.

I am looking for natural language human comments on these types of data. Examples I can think of are:  
\- stock charts &lt;-&gt; analyst notes  
\- power plant sensor data &lt;-&gt; operator notes  
\- wearable sensor data &lt;-&gt; coach notes or commentary  
\- music data &lt;-&gt; critics or teacher notes

I wonder if there are real-world datasets of these types?

Thanks.",2,4,False,self,,,,,
39,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,0,dbuu8f,self.MachineLearning,Medical Image Registration Question: Confused about how most research is evaluated,https://www.reddit.com/r/MachineLearning/comments/dbuu8f/medical_image_registration_question_confused/,twigface,1569942970,[removed],0,1,False,self,,,,,
40,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,0,dbvbwb,i.redd.it,Looking for feedback on an early version of a language model: join our voice bot beta test at bit.ly/talktobitbybit,https://www.reddit.com/r/MachineLearning/comments/dbvbwb/looking_for_feedback_on_an_early_version_of_a/,bitbybit1234,1569945073,,0,1,False,default,,,,,
41,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,1,dbvtaz,self.MachineLearning,"[D]Usb neural compute stick, opinions?",https://www.reddit.com/r/MachineLearning/comments/dbvtaz/dusb_neural_compute_stick_opinions/,thesylio,1569947074,"Hi guys, so intel is selling this usb stick that helps to compute neural networks, has anyone tried it? What is it exactly? Would you recommand it?",8,2,False,self,,,,,
42,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,1,dbvu9e,self.MachineLearning,How to generate multiple outputs from seq2seq model?,https://www.reddit.com/r/MachineLearning/comments/dbvu9e/how_to_generate_multiple_outputs_from_seq2seq/,sainimohit23,1569947185,[removed],0,1,False,https://b.thumbs.redditmedia.com/S6ixNIEPa4R4SgxgBJcU9rQN6dH1frrBIw6ZeMwlxMc.jpg,,,,,
43,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,1,dbw01o,orangeloops.com,Getting started with Machine Learning in Mobile Development,https://www.reddit.com/r/MachineLearning/comments/dbw01o/getting_started_with_machine_learning_in_mobile/,Nietzking,1569947875,,0,1,False,https://b.thumbs.redditmedia.com/Qv8tLXOsu7mbDr0HVdO9kJlGHeudzQfgKiOIKCkWjpo.jpg,,,,,
44,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,2,dbwcgd,medium.com,What Does Broken Sound Like? First-Ever Audio Dataset of Malfunctioning Industrial Machines,https://www.reddit.com/r/MachineLearning/comments/dbwcgd/what_does_broken_sound_like_firstever_audio/,Yuqing7,1569949345,,0,1,False,https://b.thumbs.redditmedia.com/1EnWr50nGfW5C520dIgAcpkz99xmwN9-7rtoPXVmmsA.jpg,,,,,
45,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,2,dbwimr,self.MachineLearning,Chrome Extension to make OpenReview awesome,https://www.reddit.com/r/MachineLearning/comments/dbwimr/chrome_extension_to_make_openreview_awesome/,misunderstoodpoetry,1569950042,[removed],0,1,False,self,,,,,
46,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,2,dbwqd9,self.MachineLearning,How to implement xgboost without using the library,https://www.reddit.com/r/MachineLearning/comments/dbwqd9/how_to_implement_xgboost_without_using_the_library/,oles_mechanic,1569951029,I want to implement xgboost from scratch i.e without using the xgboost library ...,0,1,False,self,,,,,
47,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,2,dbx1my,github.com,Statistical classifier (written in TF) diagnoses disease from immune repertoires,https://www.reddit.com/r/MachineLearning/comments/dbx1my/statistical_classifier_written_in_tf_diagnoses/,jostmey,1569952623,,0,1,False,default,,,,,
48,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,2,dbx1vw,self.MachineLearning,I've got a question as a beginner,https://www.reddit.com/r/MachineLearning/comments/dbx1vw/ive_got_a_question_as_a_beginner/,Yavkata,1569952664,"Hello! Hope you are having a great day! 
 So i am 11th grade and decided i want to learn machine learning and i started searching from where i should start. While i was searching i've found the website: https://machinelearningmastery.com/start-here/#gans
My question is - Are these advices good for a beginner and would i make a mistake if i follow them?",0,1,False,self,,,,,
49,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,3,dbx5z4,self.MachineLearning,Would this be enough to get my foot in the door for NLP/ML jobs?,https://www.reddit.com/r/MachineLearning/comments/dbx5z4/would_this_be_enough_to_get_my_foot_in_the_door/,Zanacorfe,1569953150,"Currently in my first year of my Applied Stats program, which has very flexible requirements. In addition to my Stats courses, I'm going to use most or all of my electives to take 5/6000 level CS courses. My electives so far look like:

5000 level database course

5000 then 6000 level ML course

5000 then 6000 level AI/NLP courses

This looks great, but at the end of the day I don't have a CS degree and have no work experience. How does the forecast look for my new grad jobs? If not specified jobs, should I take something like a Java developer job before moving into a specified role? Or should I just be a statistician somewhere? I'm pretty lost. 

I still have two years before I graduate so I have a lot of time to figure things out. Right now I'm just doing my courses by day and Java DS/Alg by night",0,1,False,self,,,,,
50,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,3,dbxa0u,github.com,[P] Statistical classifier (written in TF) diagnoses disease from immune repertoires,https://www.reddit.com/r/MachineLearning/comments/dbxa0u/p_statistical_classifier_written_in_tf_diagnoses/,jostmey,1569953897,,0,1,False,default,,,,,
51,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,3,dbxol0,self.MachineLearning,How to build presentations like Emergent tool Use post from OpenAI?,https://www.reddit.com/r/MachineLearning/comments/dbxol0/how_to_build_presentations_like_emergent_tool_use/,AfraidTourist,1569955152,[removed],0,1,False,self,,,,,
52,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,3,dbxx82,self.MachineLearning,Machine learning algorithms to use for detecting outliers in signal data that is continuously fed into the programmable control system of a machine.,https://www.reddit.com/r/MachineLearning/comments/dbxx82/machine_learning_algorithms_to_use_for_detecting/,imusiko,1569956127,[removed],0,1,False,self,,,,,
53,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,4,dby67k,self.MachineLearning,Implementation of Videos as space-time region graphs,https://www.reddit.com/r/MachineLearning/comments/dby67k/implementation_of_videos_as_spacetime_region/,codegrok2,1569957137,[removed],0,1,False,self,,,,,
54,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,4,dby86x,medium.com,GitHub Releases Dataset of Six Million Open-Source Methods for Code Search Research,https://www.reddit.com/r/MachineLearning/comments/dby86x/github_releases_dataset_of_six_million_opensource/,Yuqing7,1569957373,,0,1,False,https://b.thumbs.redditmedia.com/dMvrIZeCTG5VDA3kEzDVAKFY4lKFpQJqm83Rtzev6Zw.jpg,,,,,
55,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,4,dbyhgs,informationweek.com,Takeaway from MLOps NYC: Open Source Frameworks Need TLC - InformationWeek,https://www.reddit.com/r/MachineLearning/comments/dbyhgs/takeaway_from_mlops_nyc_open_source_frameworks/,IguazioDani,1569958426,,0,1,False,https://b.thumbs.redditmedia.com/aVM6E9b04gsT9M-jv7EgIW5t4m-Q7c4ae_a4NhnafOs.jpg,,,,,
56,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,4,dbylbt,self.MachineLearning,Label Studio - flexible data labeling and annotation tool,https://www.reddit.com/r/MachineLearning/comments/dbylbt/label_studio_flexible_data_labeling_and/,michael_htx,1569958859,[removed],0,1,False,https://b.thumbs.redditmedia.com/Z_E5_-ym5ShZUT-UBFi4QTkTa5ItHWtcYihsHdRvsZo.jpg,,,,,
57,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,4,dbylt7,self.MachineLearning,[Discussion] How should enterprise ML teams be organized?,https://www.reddit.com/r/MachineLearning/comments/dbylt7/discussion_how_should_enterprise_ml_teams_be/,ruurtjan,1569958912,"Hi all,

&amp;#x200B;

I've been thinking about this question a lot lately, and wrote my thoughts on it here: [https://medium.com/bigdatarepublic/on-machine-learning-team-composition-a9d0d3a3d89](https://medium.com/bigdatarepublic/on-machine-learning-team-composition-a9d0d3a3d89)

&amp;#x200B;

Would love to hear opposing opinions to sharpen my own.",1,4,False,self,,,,,
58,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,4,dbyrbu,self.MachineLearning,[P] Label Studio - flexible data labeling and annotation tool,https://www.reddit.com/r/MachineLearning/comments/dbyrbu/p_label_studio_flexible_data_labeling_and/,michael_htx,1569959542,"Hey, I'm excited to share the news with the community. We're releasing our data labeling tool into the open-source. It's called **Label Studio**. Why yet another one? While working as ML engineers, most of the tools we've used were very specific and required at least some tunning to work with our datasets. Thus the idea of a configurable UI was born. 

As you'd build a webpage, you can create a data labeling UI specifically for your needs. The config language is so expressive it usually takes no more than 10-20 lines. 

I hope somebody finds it useful. Enjoy and send your feedback!

[https://labelstud.io/](https://labelstud.io/)

[https://github.com/heartexlabs/label-studio](https://github.com/heartexlabs/label-studio)

*Processing gif etnab1mugzp31...*",7,12,False,self,,,,,
59,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,5,dbz8zn,self.MachineLearning,[R] Hamiltonian Graph Networks with ODE Integrators (Deep Mind),https://www.reddit.com/r/MachineLearning/comments/dbz8zn/r_hamiltonian_graph_networks_with_ode_integrators/,youali,1569961520,"**Hamiltonian Graph Networks with ODE Integrators**

Abstract: We introduce an approach for imposing physically informed inductive biases in learned simulation models. We combine graph networks with a differentiable ordinary differential equation integrator as a mechanism for predicting future states, and a Hamiltonian as an internal representation. We find that our approach outperforms baselines without these biases in terms of predictive accuracy, energy accuracy, and zero-shot generalization to time-step sizes and integrator orders not experienced during training. This advances the state-of-the-art of learned simulation, and in principle is applicable beyond physical domains. 

https://arxiv.org/abs/1909.12790",6,36,False,self,,,,,
60,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,5,dbzebi,self.MachineLearning,[D] Why does this GAN model do this?,https://www.reddit.com/r/MachineLearning/comments/dbzebi/d_why_does_this_gan_model_do_this/,Zespys,1569962145,"I've been experimenting with unfiltering and de-distortion using GANs and have since produced the same result which can be seen [here](https://imgur.com/a/uAhnyfW). This seems strange to me, considering the audio is completely maxed out and inaudible when played back. Has anyone experienced this with GANs before? Does it resemble the effects of non-convergence?
Thanks",3,2,False,self,,,,,
61,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,5,dbzpb5,theregister.co.uk,[N] The register did a full expos on Siraj Raval. Testimonials from his former students and people he stole code from.,https://www.reddit.com/r/MachineLearning/comments/dbzpb5/n_the_register_did_a_full_expos_on_siraj_raval/,kreyio3i,1569963443,,0,1,False,default,,,,,
62,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,6,dbzyiv,self.MachineLearning,Optimization Algorithm with Global Minimum is Changing,https://www.reddit.com/r/MachineLearning/comments/dbzyiv/optimization_algorithm_with_global_minimum_is/,Pulp_Non_Fiction,1569964506,[removed],0,1,False,self,,,,,
63,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,6,dc02lb,youtu.be,What is Enterprise AI?,https://www.reddit.com/r/MachineLearning/comments/dc02lb/what_is_enterprise_ai/,Techtter,1569964945,,0,1,False,https://b.thumbs.redditmedia.com/mzy9QD1WBPaPawAmIIEnCcocJyWNhqdfRaGnwYKGahI.jpg,,,,,
64,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,6,dc0455,techcrunch.com,Streamlit launches open-source machine learning application development framework,https://www.reddit.com/r/MachineLearning/comments/dc0455/streamlit_launches_opensource_machine_learning/,subredditsummarybot,1569965117,,0,1,False,https://b.thumbs.redditmedia.com/yDHjb0j4FsP5sMQOt-6jy28-me8Qr8ELaIZuA_A2OiU.jpg,,,,,
65,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,6,dc0a5f,self.MachineLearning,[N] The register did a full expos on Siraj Raval. Testimonials from his former students and people he stole code from.,https://www.reddit.com/r/MachineLearning/comments/dc0a5f/n_the_register_did_a_full_expos_on_siraj_raval/,kreyio3i,1569965800,"https://www.theregister.co.uk/2019/09/27/youtube_ai_star/

I found this comment on the article hilarious

&gt; Why aren't you writing these articles slamming universities?
&gt; I am currently a software engineer in a data science team producing software that yields millions of dollars in revenue for our company. I did my undergraduate in physics and my professors encouraged us to view MIT Open Courseware lectures alongside their subpar teaching. I learned more from those online lectures than I ever could in those expensive classes. I paid tens of thousands of dollars for that education. I decided that it was better bang for my buck to learn data science than in would every be to continue on in the weak education system we have globally. I paid 30 dollars month, for a year, to pick up the skills to get into data science. I landed a great job, paying a great salary because I took advantage of these types of opportunities. If you hate on this guy for collecting code that is open to the public and creating huge value from it, then you can go get your masters degree for $50-100k and work for someone who took advantage of these types of offerings. Anyone who hates on this is part of an old school, suppressive system that will continue to hold talented people down. Buck the system and keep learning!",220,480,False,self,,,,,
66,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,6,dc0g8l,techcrunch.com,[N] Streamlit launches open-source machine learning application development framework,https://www.reddit.com/r/MachineLearning/comments/dc0g8l/n_streamlit_launches_opensource_machine_learning/,TheSox3,1569966497,,0,1,False,https://b.thumbs.redditmedia.com/yDHjb0j4FsP5sMQOt-6jy28-me8Qr8ELaIZuA_A2OiU.jpg,,,,,
67,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,6,dc0m2x,self.MachineLearning,"Open source platform for deploying models as web APIs built on top of TensorFlow Serving, ONNX Runtime, and Kubernetes",https://www.reddit.com/r/MachineLearning/comments/dc0m2x/open_source_platform_for_deploying_models_as_web/,ospillinger,1569967183,[removed],0,1,False,self,,,,,
68,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,7,dc0ubx,self.MachineLearning,How does a gradient reversal layer works?,https://www.reddit.com/r/MachineLearning/comments/dc0ubx/how_does_a_gradient_reversal_layer_works/,eeed_ward,1569968164,[removed],0,1,False,self,,,,,
69,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,7,dc0vji,self.MachineLearning,[P] AdamWR Keras Full Implementation Available,https://www.reddit.com/r/MachineLearning/comments/dc0vji/p_adamwr_keras_full_implementation_available/,OverLordGoldDragon,1569968322,"The latest [Lookahead optimizer](https://arxiv.org/abs/1907.08610) paper, co-authored by Geoffrey Hinton, used [AdamW](https://arxiv.org/abs/1711.05101) as its base optimizer, and noted it performing superior to plain Adam. To the best of my knowledge, no complete implementation of AdamW in Keras existed - until now, by me:

[Keras AdamW](https://github.com/OverLordGoldDragon/keras-adamw)

It includes NadamW and SGDW, and their WR (Warm Restart) counterparts - with cosine annealing learning rate schedule, and *per layer* learning rate multipliers (useful for pretraining). All optimizers are well-tested, and for me have yielded **3-4% F1-score improvements** in already-tuned models for seizure classification. Up to date with Keras 2.3.0.

I recommend giving it a go. Any feedback is welcome.",50,18,False,self,,,,,
70,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,7,dc0zbj,medium.com,Predicting whether a Marvel character is good or evil using Big Data analytics.,https://www.reddit.com/r/MachineLearning/comments/dc0zbj/predicting_whether_a_marvel_character_is_good_or/,Botorious_NIG,1569968732,,0,1,False,default,,,,,
71,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,7,dc16yn,self.MachineLearning,"[P] Open source platform for deploying models as web APIs built on top of TensorFlow Serving, ONNX Runtime, and Kubernetes",https://www.reddit.com/r/MachineLearning/comments/dc16yn/p_open_source_platform_for_deploying_models_as/,ospillinger,1569969659,"I'm building an open source project that combines TensorFlow Serving, ONNX Runtime, and Kubernetes to automate deploying models as autoscaling web APIs on AWS ([GitHub](http://github.com/cortexlabs/cortex)). It supports TensorFlow, Keras, PyTorch, Scikit-learn, XGBoost, and other frameworks.

I started working on this when I realized that while theres been a lot of recent innovation on machine learning libraries like TensorFlow and PyTorch, actually building and shipping production applications is hard. My colleagues and I see a lot of data scientists and developers without DevOps backgrounds struggling to build model serving infrastructure with tools like Docker, Kubernetes, Flask, TensorFlow Serving, ONNX Runtime, and various AWS services. So we decided to combine these tools in an effort to improve the developer experience. Its available for anyone to download and self-host on their AWS account for free.

Id love to hear from anyone who has experience deploying models to production. Especially around the tooling and workflows that work well for you.",3,9,False,self,,,,,
72,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,7,dc1dag,self.MachineLearning,[1909.13404] Towards modular and programmable architecture search,https://www.reddit.com/r/MachineLearning/comments/dc1dag/190913404_towards_modular_and_programmable/,renato_negrinho,1569970447,"To appear at NeurIPS 2019. 

Modular and programmable architecture search framework that allows you to implement your own search spaces and search algorithms through a consistent API.  

Paper: [https://arxiv.org/abs/1909.13404](https://arxiv.org/abs/1909.13404)

Github: [https://github.com/negrinho/deep\_architect](https://github.com/negrinho/deep_architect)

Documentation: [https://deep-architect.readthedocs.io/en/latest/](https://deep-architect.readthedocs.io/en/latest/)

Twitter thread: [https://twitter.com/rmpnegrinho/status/1179132702819266560](https://twitter.com/rmpnegrinho/status/1179132702819266560)

Blog post: [https://twitter.com/rmpnegrinho/status/1179132702819266560](https://twitter.com/rmpnegrinho/status/1179132702819266560)

Looking to get a few initial users and feedback. Happy to provide support.",0,1,False,self,,,,,
73,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,8,dc1pox,self.MachineLearning,[P] Colab notebook that introduces the new TensorFlow 2.0 features,https://www.reddit.com/r/MachineLearning/comments/dc1pox/p_colab_notebook_that_introduces_the_new/,MaxTalanov,1569971965,"I found [this notebook](https://colab.research.google.com/github/zaidalyafeai/Notebooks/blob/master/TF_2_0.ipynb) to be a really useful summary of some of the new features in TensorFlow 2.0, in particular the gradient tape, tf.function, and custom gradients. I hope the community will find it useful too.

There's also [this crash course notebook for researchers](https://colab.research.google.com/drive/17u-pRZJnKN0gO5XZmq8n5A2bKGrfKEUg) that's more focused on model building.",9,65,False,self,,,,,
74,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,8,dc1wlv,self.MachineLearning,[D] Towards modular and programmable architecture search,https://www.reddit.com/r/MachineLearning/comments/dc1wlv/d_towards_modular_and_programmable_architecture/,renato_negrinho,1569972825,"To appear at NeurIPS 2019.

Modular and programmable architecture search framework that allows you to implement your own search spaces and search algorithms through a consistent API. Reading the Twitter thread will give you a pretty good idea of the main ideas.

Paper: [https://arxiv.org/abs/1909.13404](https://arxiv.org/abs/1909.13404)

Github: [https://github.com/negrinho/deep\_architect](https://github.com/negrinho/deep_architect)

Documentation: [https://deep-architect.readthedocs.io/en/latest/](https://deep-architect.readthedocs.io/en/latest/)

Twitter thread: [https://twitter.com/rmpnegrinho/status/1179132702819266560](https://twitter.com/rmpnegrinho/status/1179132702819266560)

Blog post: [https://negrinho.github.io/2019/07/26/introducing-deep-architect.html](https://negrinho.github.io/2019/07/26/introducing-deep-architect.html)

Looking to get a few initial users and feedback. Happy to provide support.",0,5,False,self,,,,,
75,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,8,dc220o,self.MachineLearning,"[D] What do you use to explain your (xgboost) models to users? Is there a way to inspect what variables are contributing to a prediction for each observation? Any reference that can be used? e.g. for a classifier, the prediction is true, how will i know what contributed to this prediction?",https://www.reddit.com/r/MachineLearning/comments/dc220o/d_what_do_you_use_to_explain_your_xgboost_models/,Dexdev08,1569973540,[removed],0,1,False,self,,,,,
76,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,9,dc292l,distill.pub,The Paths Perspective on Value Learning,https://www.reddit.com/r/MachineLearning/comments/dc292l/the_paths_perspective_on_value_learning/,pcannons,1569974440,,0,1,False,default,,,,,
77,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,9,dc2vu5,self.MachineLearning,[D] Siraj Raval bad,https://www.reddit.com/r/MachineLearning/comments/dc2vu5/d_siraj_raval_bad/,carmichael561,1569977502,[removed],0,1,False,self,,,,,
78,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,10,dc3adr,self.MachineLearning,Training Architecture for Adversarial Networks with Data Point Generation,https://www.reddit.com/r/MachineLearning/comments/dc3adr/training_architecture_for_adversarial_networks/,Tolure,1569979487,[removed],0,1,False,self,,,,,
79,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,12,dc4tbb,arxiv.org,[R] Truth or Backpropaganda? An Empirical Investigation of Deep Learning Theory,https://www.reddit.com/r/MachineLearning/comments/dc4tbb/r_truth_or_backpropaganda_an_empirical/,xternalz,1569987324,,9,0,False,default,,,,,
80,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,13,dc5ffr,self.MachineLearning,[D] Reconstructing P2P gossip protocols networks from timing measurements,https://www.reddit.com/r/MachineLearning/comments/dc5ffr/d_reconstructing_p2p_gossip_protocols_networks/,Voostock,1569990964,"I'm interested in reconstructing networks/graphs where information is distributed via a gossip/epidemic/rumour protocol where each peer/node sends information to all of its neighbours, so that any piece of information eventually floods the network. Any peer can propagate new information. The number of neighbours of each peer should be much less than the total number of peer.

By connecting to all peers, we can measure the time that each peer sends a piece of information. Hopefully we can use that data to reconstruct the network, i.e. work out which peers are connected to which other peers.

Is anyone aware of research that has been done in this area? I've found quite a bit on locating the source of the information given this setup, but I'm really interested in reconstructing the graph.",0,0,False,self,,,,,
81,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,13,dc5moo,arxiv.org,[R] Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/dc5moo/r_advantageweighted_regression_simple_and/,SkiddyX,1569992235,,4,11,False,default,,,,,
82,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,14,dc5prr,self.MachineLearning,What parts of machine learning is built upon or makes use of Bayesian Statistics and inference methods?,https://www.reddit.com/r/MachineLearning/comments/dc5prr/what_parts_of_machine_learning_is_built_upon_or/,ampnd56,1569992805,"I'm writing a research paper on Bayesian Statistics and Reasoning used in Machine Learning methods. I'm familiar with some Bayesian Statistics and some machine learning but am unable to make the connection between the two and figure out how they are related. 

Can anyone please point me to resources/tutorials on Bayesian application in Machine Learning and their respective coding tutorials in Python/R?

Any help would be much appreciated. Thanks in advance!!",0,1,False,self,,,,,
83,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,14,dc5syi,self.MachineLearning,[D] Implementation of CorEx in R?,https://www.reddit.com/r/MachineLearning/comments/dc5syi/d_implementation_of_corex_in_r/,cleverchimp,1569993380,"I recently got turned on to the idea of Topic modeling by way of **Cor**relation **Ex**planation (CorEx) vis-a-vis this post:  


[https://medium.com/pew-research-center-decoded/overcoming-the-limitations-of-topic-models-with-a-semi-supervised-approach-b947374e0455](https://medium.com/pew-research-center-decoded/overcoming-the-limitations-of-topic-models-with-a-semi-supervised-approach-b947374e0455)  


I found an implementation in Python here:  


[https://github.com/gregversteeg/corex\_topic](https://github.com/gregversteeg/corex_topic)  


For those familiar with LDA (Latent Dirichlet Allocation), oftentimes the resulting topics don't make very much sense. Often the beta probabilities (word-to-topic) are so similar that any classification is arbitrary at best, and more often, simply meaningless.   


CorEx provides the ability to ""anchor"" topics to specific terms, providing a semi-supervised approach to topic modeling. Sounds exciting. Has anyone worked with this algorithm before? Any good results?

Also: has anyone  found (or made) an implementation of this CorEx algorithm in R yet?",0,0,False,self,,,,,
84,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,14,dc5twl,self.MachineLearning,[D] Is anyone else's advisor on leave at an industry research group?,https://www.reddit.com/r/MachineLearning/comments/dc5twl/d_is_anyone_elses_advisor_on_leave_at_an_industry/,WonderfulPattern,1569993548,This seems to be the trend in ML/Vision/NLP,14,2,False,self,,,,,
85,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,15,dc6b4n,self.MachineLearning,Papers on cancer genome,https://www.reddit.com/r/MachineLearning/comments/dc6b4n/papers_on_cancer_genome/,wycheong,1569996921,[removed],0,1,False,self,,,,,
86,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,18,dc7zyy,self.MachineLearning,Is Artificial Intelligence a moving target?,https://www.reddit.com/r/MachineLearning/comments/dc7zyy/is_artificial_intelligence_a_moving_target/,BeatriceCarraro,1570009780,"An interesting take on what AI is and the consequences of a loose definition. [I recommend giving it a read here](https://www.botxo.co/blog/ai-moving-target/)

Snippet:

&gt;Artificial Intelligence is defined as any computer system that demonstrates intelligence. Since we have no formal definition of what constitutes intelligence, the scope of AI is continuously shifting. Our perception of human intelligence shapes our idea of what constitutes an intelligent computer system.   
&gt;  
&gt;Because of different and sometimes conflicting interests, the definition of what constitutes an AI system is highly dependent on context.",0,1,False,self,,,,,
87,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,18,dc80y5,i.redd.it,I need to identify this part. From a 2 head pic saw,https://www.reddit.com/r/MachineLearning/comments/dc80y5/i_need_to_identify_this_part_from_a_2_head_pic_saw/,soutsu_,1570009979,,0,1,False,default,,,,,
88,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,19,dc832o,medium.com,Get started with Tensorflow 2.0,https://www.reddit.com/r/MachineLearning/comments/dc832o/get_started_with_tensorflow_20/,TuringCompletex64,1570010407,,0,1,False,default,,,,,
89,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,19,dc868r,i.redd.it,I need to find out what this part is. From a 2 head upvc saw machine,https://www.reddit.com/r/MachineLearning/comments/dc868r/i_need_to_find_out_what_this_part_is_from_a_2/,soutsu_,1570011014,,0,1,False,https://b.thumbs.redditmedia.com/tYcSxM7UTQUaY6y_IqQL79Jab_NiODI-f_RHc4u6aVc.jpg,,,,,
90,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,19,dc8fyr,self.MachineLearning,Linguistics in NLP (or not),https://www.reddit.com/r/MachineLearning/comments/dc8fyr/linguistics_in_nlp_or_not/,no_bear_so_low,1570012911,[removed],0,1,False,self,,,,,
91,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,19,dc8ka2,self.MachineLearning,Where do I find a programmer to help with my ML projects?,https://www.reddit.com/r/MachineLearning/comments/dc8ka2/where_do_i_find_a_programmer_to_help_with_my_ml/,ProfSchodinger,1570013700,[removed],0,1,False,self,,,,,
92,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,19,dc8kvj,self.MachineLearning,What Is The Function Of Butterfly Valve?,https://www.reddit.com/r/MachineLearning/comments/dc8kvj/what_is_the_function_of_butterfly_valve/,uflowindia,1570013806,[removed],0,1,False,self,,,,,
93,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,21,dc9dar,self.MachineLearning,Collaboration between and among data scientists and data engineers,https://www.reddit.com/r/MachineLearning/comments/dc9dar/collaboration_between_and_among_data_scientists/,mrmrcoleman,1570018563,[removed],1,1,False,self,,,,,
94,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,22,dc9wsn,self.MachineLearning,Best papers with code on Face Reenactment?,https://www.reddit.com/r/MachineLearning/comments/dc9wsn/best_papers_with_code_on_face_reenactment/,cbsudux,1570021416,[removed],0,1,False,self,,,,,
95,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,22,dcafs2,heartbeat.fritz.ai,Logo Recognition iOS Application Using Machine Learning and Flask API,https://www.reddit.com/r/MachineLearning/comments/dcafs2/logo_recognition_ios_application_using_machine/,omarmhaimdat,1570024064,,0,1,False,https://b.thumbs.redditmedia.com/wxB9PcmdToZmo8BmeKWMU4-zn6sK-2r779Wce97maDI.jpg,,,,,
96,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,22,dcai0m,self.MachineLearning,[R] Research Guide for Transformers,https://www.reddit.com/r/MachineLearning/comments/dcai0m/r_research_guide_for_transformers/,mwitiderrick,1570024367,"Until recently, recurrent neural networks (RNNs) and convolutional neural networks (CNNs) have been used to tackle this challenge. The problem with these is that they arent able to keep up with context and content when sentences are too long. This limitation has been solved by paying *attention* to the word that is currently being operated on. This guide will focus on how this problem can be addressed by Transformers with the help of deep learning.

[https://heartbeat.fritz.ai/research-guide-for-transformers-3ff751493222](https://heartbeat.fritz.ai/research-guide-for-transformers-3ff751493222)",2,26,False,self,,,,,
97,MachineLearning,t5_2r3gv,2019-10-2,2019,10,2,23,dcb6kw,self.MachineLearning,Use cases of AI and ML,https://www.reddit.com/r/MachineLearning/comments/dcb6kw/use_cases_of_ai_and_ml/,arjunliveshere,1570027532,Is there any recommended book that I can read to know about the use cases of AI and ML,0,1,False,self,,,,,
98,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,0,dcbepj,litslink.com,An Introduction to Machine Learning Algorithms,https://www.reddit.com/r/MachineLearning/comments/dcbepj/an_introduction_to_machine_learning_algorithms/,Anastasiia17,1570028541,,0,0,False,https://b.thumbs.redditmedia.com/gNYLjoK4K1K7AeYemJxmw2nhnix_EhYNQ2VQf2lh_wo.jpg,,,,,
99,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,0,dcbpn5,self.MachineLearning,Math PhD (Nonlinear Programming) switching to Data Science?,https://www.reddit.com/r/MachineLearning/comments/dcbpn5/math_phd_nonlinear_programming_switching_to_data/,magnusseen,1570029869,[removed],0,1,False,self,,,,,
100,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,0,dcc1sm,self.MachineLearning,[R] On the Equivalence between Node Embeddings and Structural Graph Representations,https://www.reddit.com/r/MachineLearning/comments/dcc1sm/r_on_the_equivalence_between_node_embeddings_and/,bsriniv,1570031329," This work provides the first unifying theoretical framework for node embeddings and structural graph representations, bridging methods like matrix factorization and graph neural networks. Using invariant theory, we show that the relationship between structural representations and node embeddings is analogous to that of a distribution and its samples. We prove that all tasks that can be performed by node embeddings can also be performed by structural representations and vice-versa. We also show that the concept of transductive and inductive learning is unrelated to node embeddings and graph representations, clearing another source of confusion in the literature. Finally, we introduce new practical guidelines to generating and using node embeddings, which fixes significant shortcomings of standard operating procedures used today. 

&amp;#x200B;

 [https://arxiv.org/abs/1910.00452](https://arxiv.org/abs/1910.00452)",3,11,False,self,,,,,
101,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,0,dcc3ro,self.MachineLearning,"Simple Questions Thread October 02, 2019",https://www.reddit.com/r/MachineLearning/comments/dcc3ro/simple_questions_thread_october_02_2019/,AutoModerator,1570031557,[removed],0,1,False,self,,,,,
102,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,1,dcce9n,self.MachineLearning,Final Year Project Suggestion?,https://www.reddit.com/r/MachineLearning/comments/dcce9n/final_year_project_suggestion/,temx2,1570032795,"SO, I'm an aerospace engineer and I've been lucky enough to get a final year project on data modelling and machine learning. Only thing is, it's pretty open and I can choose what area to explore.

I'm looking for a project I can do that is fairly novel, has future commercial implications/value. Does anything come to mind?",0,1,False,self,,,,,
103,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,1,dccjyw,self.MachineLearning,"[D] Instrumenting a differential list of apartment complex features based on real choices (between complex A and B, B was chosen) in order to perform feature selection and figure out most important apartment complex features related to choice",https://www.reddit.com/r/MachineLearning/comments/dccjyw/d_instrumenting_a_differential_list_of_apartment/,SpicyBroseph,1570033475,"Good afternoon ML community,

I am approaching this problem from a supervised machine learning perspective since that is where the majority of my experience is -- so I need a sanity check on if this approach is correct or if I should be using a different approach altogether.

Lets say I have data on approximately 600 apartment complexes, each with about 50-100 features ('amenities').  These include 'pool', or 'no pool', 'pets allowed', 'no pets allowed', 'small pets allowed', ""more expensive"", ""less expensive"",etc.

I also have, for about 15 of these complexes, choice data on rental losses.  So-- for these 15, everytime somebody chose another complex, they were surveyed and revealed which alternative they chose.  There's about 100 'lost choices' for each of the 15 complexes.  My goal is to construct the data in such a way that I can do feature selection on the amenities to figure out which ones play most prominently into choosing another complex, to help understand how to improve the initial 15 complexes.

The approach I was thinking about implementing was constructing a dataset based of differentials and similarities.  So for each 'choice', there becomes two datapoints: one where we have a list of amenities in complex A vs complex B, and then a counterpoint for the opposite.  So it would look like this:

For each datapoint, in the case when complex B is chosen, which we'll label with an output of ""1"" for ""chosen"", the input data vector would be a list of 0-3 for every amenity in the matrix: 

\`\`\`B has this amenity but A doesn't: 0

A has this amenity but B doesn't: 1

Both facilities have this amenity: 2

Neither facilities have this amenity: 3\`\`\`

Then we would create the complimentary data point, where the A and B vector differentials are switched (A has this amenity but B doesn't: 1, etc) and the output label would be 0 for ""not chosen"".

Logically this makes sense to me, but I can't help but think I am over complicating it-- and I can't think of any other way to instrument the data.  Once it's instrumented in this way, I could either build a classifier (xgboost) and look at feature importance of all the choices of '1', or do feature selection analysis on the data to come up with which features to focus on.  Does this seem like a good approach, or are there some glaringly obvious drawbacks and/or better tools for this?",5,3,False,self,,,,,
104,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,1,dccy7t,self.MachineLearning,[R] Interpretations are useful: penalizing explanations to align neural networks with prior knowledge,https://www.reddit.com/r/MachineLearning/comments/dccy7t/r_interpretations_are_useful_penalizing/,laura-rieger,1570035237,"TL;DR: Penalizing wrong explanations increases predictive accuracy for neural networks!

[Paper](https://arxiv.org/abs/1909.13584)

[Code](https://github.com/laura-rieger/deep-explanation-penalization)

Abstract: For an explanation of a deep learning model to be effective, it must provide both insight into a model and suggest a corresponding action in order to achieve some objective. Too often, the litany of proposed explainable deep learning methods stop at the first step, providing practitioners with insight into a model, but no way to act on it. In this paper, we propose contextual decomposition explanation penalization (CDEP), a method which enables practitioners to leverage existing explanation methods in order to increase the predictive accuracy of deep learning models. In particular, when shown that a model has incorrectly assigned importance to some features, CDEP enables practitioners to correct these errors by directly regularizing the provided explanations. Using explanations provided by contextual decomposition (CD) (Murdoch et al., 2018), we demonstrate the ability of our method to increase performance on an array of toy and real datasets.",6,19,False,self,,,,,
105,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,1,dcd19y,explosion.ai,[N] spaCy v2.2,https://www.reddit.com/r/MachineLearning/comments/dcd19y/n_spacy_v22/,syllogism_,1570035599,,0,1,False,https://b.thumbs.redditmedia.com/mJa-LufyWSnznbsOs3zLf0r7D4RG8gS4LBt_2SMa9TI.jpg,,,,,
106,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,2,dcdce5,ai.googleblog.com,Releasing PAWS and PAWS-X: Two New Datasets to Improve Natural Language Understanding Models,https://www.reddit.com/r/MachineLearning/comments/dcdce5/releasing_paws_and_pawsx_two_new_datasets_to/,sjoerdapp,1570036934,,0,1,False,https://a.thumbs.redditmedia.com/8NbnfNO9CxnXO7RubDjIQiE14bD5xXYEPaHp0ueUJ00.jpg,,,,,
107,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,3,dce5kd,self.MachineLearning,"Want to contribute to growing community of ML-AI, Follow to get contribution access.",https://www.reddit.com/r/MachineLearning/comments/dce5kd/want_to_contribute_to_growing_community_of_mlai/,826krishna,1570040521,[removed],0,1,False,https://b.thumbs.redditmedia.com/zOTPvW3rlXygfLqKIGS37Kw4Dz6Wp5pieqHf9nbbhAg.jpg,,,,,
108,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,3,dce6m2,medium.com,DeepMind Uses GANs to Convert Text to Speech,https://www.reddit.com/r/MachineLearning/comments/dce6m2/deepmind_uses_gans_to_convert_text_to_speech/,Yuqing7,1570040642,,0,1,False,https://b.thumbs.redditmedia.com/2saNZ2gNGCAQhdSqpQkfCXWuj3RBewNE418BkLoVA2w.jpg,,,,,
109,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,3,dcefko,self.MachineLearning,ML-AI community in India,https://www.reddit.com/r/MachineLearning/comments/dcefko/mlai_community_in_india/,826krishna,1570041720,[removed],1,1,False,self,,,,,
110,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,3,dcendn,arxiv.org,"""Emergent Systematic Generalization in a Situated Agent"", Hill et al 2019 {DM}",https://www.reddit.com/r/MachineLearning/comments/dcendn/emergent_systematic_generalization_in_a_situated/,rtk25,1570042637,,12,87,False,default,,,,,
111,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,4,dcey46,youtube.com,[R] End-to-End Training of Attentive Deep Visuomotor Policies for Manipulation in Clutter,https://www.reddit.com/r/MachineLearning/comments/dcey46/r_endtoend_training_of_attentive_deep_visuomotor/,D-3GAN,1570043876,,0,1,False,https://b.thumbs.redditmedia.com/GH9RUkdgnrLrIhKGgKQPKQG3IyKjlIZBaox20dJFT7c.jpg,,,,,
112,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,4,dcf306,webinars.on24.com,"October 8 Talk with HCI Pioneer Joseph A. Konstan: ""Recommender Systems: Beyond Machine Learning""",https://www.reddit.com/r/MachineLearning/comments/dcf306/october_8_talk_with_hci_pioneer_joseph_a_konstan/,ACMLearning,1570044431,,0,1,False,default,,,,,
113,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,4,dcf7v1,self.MachineLearning,For an OCR : please could you guys provide some good resources for image pre processing for text,https://www.reddit.com/r/MachineLearning/comments/dcf7v1/for_an_ocr_please_could_you_guys_provide_some/,prashantabides,1570044949,[removed],0,1,False,self,,,,,
114,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,4,dcf8gi,self.MachineLearning,[D] A reality check on the role of machine learning in cybersecurity,https://www.reddit.com/r/MachineLearning/comments/dcf8gi/d_a_reality_check_on_the_role_of_machine_learning/,bendee983,1570045017,"It all depends on the available data and the variety of activities. You can't just pour a bunch of data into an ML model and expect it do detect threats. In many cases, the key is to combine human analysts with ML algorithms.

[https://bdtechtalks.com/2019/07/29/machine-learning-ai-cybersecurity/](https://bdtechtalks.com/2019/07/29/machine-learning-ai-cybersecurity/)",0,0,False,self,,,,,
115,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,4,dcf8qp,self.MachineLearning,https://talktotransformer.com/,https://www.reddit.com/r/MachineLearning/comments/dcf8qp/httpstalktotransformercom/,blahblahalah3432,1570045048,[removed],0,1,False,https://b.thumbs.redditmedia.com/01zbiaSLuSG_1AYfX3uGd0k-ul0X3TM499YG8yM3XYg.jpg,,,,,
116,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,5,dcfl7b,self.MachineLearning,"What are the simple and best ways to productionize, monitor and evaluate ML models in R?",https://www.reddit.com/r/MachineLearning/comments/dcfl7b/what_are_the_simple_and_best_ways_to/,vamsi115,1570046451,[removed],0,1,False,self,,,,,
117,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,5,dcgbcn,medium.com,The Deep and Machine Learning Glossary,https://www.reddit.com/r/MachineLearning/comments/dcgbcn/the_deep_and_machine_learning_glossary/,TuringCompletex64,1570049432,,0,1,False,https://b.thumbs.redditmedia.com/2Sp_RvWZN7B0IGeOPqt3UuTCzEMLQL2hpH40W2E3UCw.jpg,,,,,
118,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,6,dcglq4,youtube.com,Neuromorphic Computers Simulating the Brain  Interview with The SpiNNiker Project's Steve Furber,https://www.reddit.com/r/MachineLearning/comments/dcglq4/neuromorphic_computers_simulating_the_brain/,august43210,1570050581,,0,1,False,default,,,,,
119,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,6,dcgo2m,self.MachineLearning,Generalization in Relational Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/dcgo2m/generalization_in_relational_deep_reinforcement/,rlagent,1570050852,[removed],0,1,False,self,,,,,
120,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,6,dcgqo0,youtu.be,[D] Neuromorphic Computers Simulating the Brain  Interview with The SpiNNiker Project's Steve Furber,https://www.reddit.com/r/MachineLearning/comments/dcgqo0/d_neuromorphic_computers_simulating_the_brain/,august43210,1570051153,,0,1,False,https://b.thumbs.redditmedia.com/vOOraqzSU1bcmkdxMSSJHzPATW4VyDy6adiSh50HwxQ.jpg,,,,,
121,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,6,dcgril,self.MachineLearning,"[R] MimickNet, Matching Clinical Ultrasound Post-Processing via CycleGANs Code Release",https://www.reddit.com/r/MachineLearning/comments/dcgril/r_mimicknet_matching_clinical_ultrasound/,ououwen,1570051244,[removed],0,1,False,self,,,,,
122,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,6,dch9n9,self.MachineLearning,"[R] MimickNet, Matching Clinical Ultrasound Post-Processing via CycleGANs Code Release",https://www.reddit.com/r/MachineLearning/comments/dch9n9/r_mimicknet_matching_clinical_ultrasound/,ououwen,1570053378,[removed],2,8,False,self,,,,,
123,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,7,dchd78,self.MachineLearning,[D] Machine Learning as a career change,https://www.reddit.com/r/MachineLearning/comments/dchd78/d_machine_learning_as_a_career_change/,ceilingbeetle,1570053801,"Hi all,

I just wanted to get a straw poll opinion on this.

Im currently a C-suite level employee of a company and I make over $100k/year. My background is backend and front end development and now my job is largely project management with some coding.

Ive been taking the Fast AI course and wondered whether career transitions to machine learning are quite do-able?

I currently work from home (remote) so would be looking to do the same with machine learning.

I suppose Im wondering whether salary + remote work would remain as reasonable expectations in a career switch. 

Any info or insight would be great ",33,5,False,self,,,,,
124,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,10,dck555,self.MachineLearning,Trusting Article Authors?,https://www.reddit.com/r/MachineLearning/comments/dck555/trusting_article_authors/,UysofSpades,1570066835,[removed],0,1,False,self,,,,,
125,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,11,dckgj0,self.MachineLearning,Cool article [Turn Python Scripts into Beautiful ML Tools] + Corresponding GitHub,https://www.reddit.com/r/MachineLearning/comments/dckgj0/cool_article_turn_python_scripts_into_beautiful/,tcr98,1570068455,[removed],0,1,False,self,,,,,
126,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,11,dckmhf,arxiv.org,[R] Unsupervised Doodling and Painting with Improved SPIRAL (with interactive paper),https://www.reddit.com/r/MachineLearning/comments/dckmhf/r_unsupervised_doodling_and_painting_with/,baylearn,1570069326,,7,13,False,default,,,,,
127,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,12,dcl70l,self.MachineLearning,Can you get Jupyter Notebooks to be responsive?,https://www.reddit.com/r/MachineLearning/comments/dcl70l/can_you_get_jupyter_notebooks_to_be_responsive/,scorpiotears,1570072359,[removed],0,1,False,self,,,,,
128,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,12,dclaeh,self.MachineLearning,[D] Best papers with code on Face Reenactment,https://www.reddit.com/r/MachineLearning/comments/dclaeh/d_best_papers_with_code_on_face_reenactment/,cbsudux,1570072875,"Hey guys!

Looking for papers on Face Reenactment. I've gone through Face2Face and the results look pretty good! Was wondering if there are any newer implementations.",8,3,False,self,,,,,
129,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,13,dcm3nx,self.MachineLearning,5 Factors To Consider Before Investing In A Machine Learning Course,https://www.reddit.com/r/MachineLearning/comments/dcm3nx/5_factors_to_consider_before_investing_in_a/,SunilAhujaa,1570077781,[removed],0,1,False,self,,,,,
130,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,13,dcm7sv,self.Aishwarya_Osp,Data visualization software solutions,https://www.reddit.com/r/MachineLearning/comments/dcm7sv/data_visualization_software_solutions/,Aishwarya_Osp,1570078507,,0,1,False,https://b.thumbs.redditmedia.com/TmNiBgtZ8WVVvW5WFA3an9xPbKQ5ZhhofIHN8tIaR_w.jpg,,,,,
131,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,14,dcmhiz,3ritechnologies.com,industrial training in pune with 100% placement,https://www.reddit.com/r/MachineLearning/comments/dcmhiz/industrial_training_in_pune_with_100_placement/,3ritech,1570080259,,0,1,False,default,,,,,
132,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,15,dcmtpm,writemythesis.org,Hot Machine learning topics,https://www.reddit.com/r/MachineLearning/comments/dcmtpm/hot_machine_learning_topics/,WriteMyThesis,1570082667,,0,1,False,default,,,,,
133,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,15,dcn9b0,self.MachineLearning,How should I go about reading research papers for topics of which I don't have enough prior knowledge?,https://www.reddit.com/r/MachineLearning/comments/dcn9b0/how_should_i_go_about_reading_research_papers_for/,itdoesntmatter13,1570085728,[removed],0,1,False,self,,,,,
134,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,17,dco3t1,arxiv.org,[R] Information Closure Theory of Consciousness,https://www.reddit.com/r/MachineLearning/comments/dco3t1/r_information_closure_theory_of_consciousness/,chisai_mikan,1570092112,,75,106,False,default,,,,,
135,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,17,dco5k6,self.MachineLearning,Implementation of ICLR 2018 paper All-but-the-top,https://www.reddit.com/r/MachineLearning/comments/dco5k6/implementation_of_iclr_2018_paper_allbutthetop/,mlIsFun21,1570092489,[removed],0,1,False,self,,,,,
136,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,18,dcok8v,self.MachineLearning,What are some of the best machine learning research labs in Europe that you recommend for PhD studies?,https://www.reddit.com/r/MachineLearning/comments/dcok8v/what_are_some_of_the_best_machine_learning/,roughcall19,1570095529,[removed],0,1,False,self,,,,,
137,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,19,dcoylt,leetless.de,"[P] I made a few data science / ML blog posts about mana cost in the trading card game ""Magic the Gathering"", feedback appreciated!",https://www.reddit.com/r/MachineLearning/comments/dcoylt/p_i_made_a_few_data_science_ml_blog_posts_about/,Droggl,1570098352,,0,1,False,https://b.thumbs.redditmedia.com/AIFSHuvk_mdpPjyUd30-X111gdD8IJYcFvKfLM8chFk.jpg,,,,,
138,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,19,dcp589,self.MachineLearning,Machine learning use cases in South America,https://www.reddit.com/r/MachineLearning/comments/dcp589/machine_learning_use_cases_in_south_america/,A4plainpaper,1570099614,[removed],0,1,False,self,,,,,
139,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,19,dcp664,self.MachineLearning,When would you use a ball valve?,https://www.reddit.com/r/MachineLearning/comments/dcp664/when_would_you_use_a_ball_valve/,uflowindia,1570099780,[removed],0,1,False,https://b.thumbs.redditmedia.com/SHvyxZX_f3uW8RcGEhORACsskOuB_Y9Ai1KhNflr9Oo.jpg,,,,,
140,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,19,dcp85v,self.MachineLearning,Need Flair to be made,https://www.reddit.com/r/MachineLearning/comments/dcp85v/need_flair_to_be_made/,Toiletfan2009,1570100143,[removed],0,1,False,self,,,,,
141,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,20,dcpa28,self.MachineLearning,Has anybody worked on human pose estimation? I have a few questions regarding it.,https://www.reddit.com/r/MachineLearning/comments/dcpa28/has_anybody_worked_on_human_pose_estimation_i/,pseudopodia_,1570100474,"I am a CS undergrad student. I've been asked to prepare a presentation on human pose estimation in college. I don't have a ML background. I have tried to read online articles about human pose estimation but I'm not exactly understanding the workflow of it. I want to understand 2D pose estimation. What information I've gathered till now is that there are steps like preprocessing, feature extraction and inference in the pose estimation pipeline. I didn't understand how they extract the features(they just mention CNN but what would be the input to this CNN? The also talk about joint detection. In which phase does that happen?) or in what form are the inferences generated. Can someone explain to me in simple terms about how the workflow of the process is and what are the inputs and outputs at each stage? 
Thanks a lot! :)",0,1,False,self,,,,,
142,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,20,dcpsgs,zeldatech.com,Machine Learning: An Essential Guide to Machine Learning for Beginners By Herbert Jones EPUB,https://www.reddit.com/r/MachineLearning/comments/dcpsgs/machine_learning_an_essential_guide_to_machine/,oussamaouti,1570103541,,0,0,False,default,,,,,
143,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,20,dcptrl,debatingeurope.eu,Do the benefits of AI outweigh the risks?,https://www.reddit.com/r/MachineLearning/comments/dcptrl/do_the_benefits_of_ai_outweigh_the_risks/,NigelCods,1570103749,,0,1,False,https://a.thumbs.redditmedia.com/J29nCc49TYIzC3tY3B-3uPuPLhitqafGfUCBtG9dri4.jpg,,,,,
144,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,21,dcpvj1,youtu.be,[N] Accelerating Machine Learning DevOps with Kubeflow,https://www.reddit.com/r/MachineLearning/comments/dcpvj1/n_accelerating_machine_learning_devops_with/,[deleted],1570104039,[deleted],0,1,False,default,,,,,
145,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,21,dcpvv9,youtu.be,Accelerating Machine Learning DevOps with Kubeflow,https://www.reddit.com/r/MachineLearning/comments/dcpvv9/accelerating_machine_learning_devops_with_kubeflow/,mto96,1570104094,,1,1,False,https://b.thumbs.redditmedia.com/HWDsmREIVqau9RwidUydcn-rIEer2c3l5-UMILep6ho.jpg,,,,,
146,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,21,dcqd6y,i.redd.it,Soccer clubs use data analytics and machine-learning to evaluate player skills and recruit those that would lead the team to victory,https://www.reddit.com/r/MachineLearning/comments/dcqd6y/soccer_clubs_use_data_analytics_and/,qaops,1570106627,,0,1,False,default,,,,,
147,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,21,dcqhgo,docs.google.com,"[R] Psychology research on manipulative, narcissism, psychopath personality and micro racism (18+)",https://www.reddit.com/r/MachineLearning/comments/dcqhgo/r_psychology_research_on_manipulative_narcissism/,hannahlxy,1570107227,,0,1,False,https://b.thumbs.redditmedia.com/AuSP2LikF4NFEN7YkEcbr9R12vPXflPz1cjMDBYvyVA.jpg,,,,,
148,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,22,dcqo1c,missinglink.ai,Missinglink.ai shutting down!,https://www.reddit.com/r/MachineLearning/comments/dcqo1c/missinglinkai_shutting_down/,Mayalittlepony,1570108137,,2,1,False,https://b.thumbs.redditmedia.com/4zh9oeov3cOihUi7SGB4YdSOwxzJt2IKJx1bI9iY6MU.jpg,,,,,
149,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,22,dcra1a,self.MachineLearning,[N] Awesome AI Research and Projects on Computer Vision News (with codes!) October 2019,https://www.reddit.com/r/MachineLearning/comments/dcra1a/n_awesome_ai_research_and_projects_on_computer/,Gletta,1570111133,"The October issue of Computer Vision News: 36 pages about AI and Deep Learning through research and practical applications.

[HTML5 version (recommended)](https://www.rsipvision.com/ComputerVisionNews-2019October/)

[PDF version](https://www.rsipvision.com/computer-vision-news-2019-october-pdf/)

Technical articles on pages 4-8 and 18-23. Subscribe for free on page 36.

&amp;#x200B;

https://i.redd.it/vvab8m0z0cq31.jpg",0,17,False,https://b.thumbs.redditmedia.com/Bj1_7JaGAeWHJ-AaJLoGjsdZBD47Ry9oIjaRGX9chnI.jpg,,,,,
150,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,22,dcra61,self.MachineLearning,[P] Keras SWA: Stochastic weight averaging callback for Keras,https://www.reddit.com/r/MachineLearning/comments/dcra61/p_keras_swa_stochastic_weight_averaging_callback/,lilsmacky,1570111151,"As an exercise for myself I decided to implement SWA, from the paper \[Averaging Weights Leads to Wider Optima and Better Generalization\]([https://arxiv.org/abs/1803.05407](https://arxiv.org/abs/1803.05407)). I did it with Keras and decided it might make a nice package.

Repo:

[https://github.com/simon-larsson/keras-swa](https://github.com/simon-larsson/keras-swa)

pip:

`pip install keras-swa`

If you are not familiar with SWA, it is a trick to approximate ensembling by taking a running average of your weights towards the end of training a model. You can read more in this nice \[blog post\]([https://pechyonkin.me/stochastic-weight-averaging/](https://pechyonkin.me/stochastic-weight-averaging/)) explaining SWA and it's relatives SSE and FGE.

I currently only implement the constant learning rate schedule from the paper, hoping to add the cyclic one from the paper soon. It is also possible to leave the learning rate to the optimizer or other schedulers. I have also not implemented the batch normalization fix. It requires a forward pass over training data, which I don't know how to do from a callback. So any help there would be appreciated.

I would love for people to try it! Feedback is also welcome! :)",2,12,False,self,,,,,
151,MachineLearning,t5_2r3gv,2019-10-3,2019,10,3,23,dcrtpg,self.MachineLearning,[Research] INFaaS: A Model-less Inference Serving System,https://www.reddit.com/r/MachineLearning/comments/dcrtpg/research_infaas_a_modelless_inference_serving/,cdossman,1570113662,[removed],0,1,False,self,,,,,
152,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,1,dct0jg,medium.com,"NVIDIA &amp; ORNL Researchers Train AI Model on Worlds Top Supercomputer Using 27,600 NVIDIA GPUs",https://www.reddit.com/r/MachineLearning/comments/dct0jg/nvidia_ornl_researchers_train_ai_model_on_worlds/,Yuqing7,1570118963,,0,1,False,https://b.thumbs.redditmedia.com/LOaLPcOTny6ZBeHliPTNhrzWqo1fuB_e7r6hhqQ3mSc.jpg,,,,,
153,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,2,dctuze,youtu.be,Machine Learning - StarCraft 2 Python AI part 2 - Barracks,https://www.reddit.com/r/MachineLearning/comments/dctuze/machine_learning_starcraft_2_python_ai_part_2/,EddyTheDad,1570122602,,0,1,False,https://b.thumbs.redditmedia.com/0YrNlXWJGBlAWv2ObqmpyA7wx13Zc8BQTVD7CacwFJE.jpg,,,,,
154,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,2,dcty01,self.MachineLearning,Modify the cost function or loss function of random forest regressor,https://www.reddit.com/r/MachineLearning/comments/dcty01/modify_the_cost_function_or_loss_function_of/,Jubeyer,1570122971,"Hi All,

I am very new to ML, for my work I need to add some more terms (penalty terms ) in addition to the loss function in random forest regressor, but I couldn't see any useful example of how to do that.  Can anyone direct me to any sample code or references which may help. 

N.B. I am using sci-kit learn.",0,1,False,self,,,,,
155,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,3,dcur61,self.MachineLearning,What is the best project for speech cloning currently out there?,https://www.reddit.com/r/MachineLearning/comments/dcur61/what_is_the_best_project_for_speech_cloning/,PhenomenallyBack,1570126472,I've become very interested in projects that can clone voices off of short sound bites of people speaking. I remember reading about lots of projects relating to the concept but can't find any that are available to test.,0,1,False,self,,,,,
156,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,3,dcus2p,self.MachineLearning,[D] Will The Upcoming Facebook/Microsoft Deepfake Challenge Be Limited To Academic Researchers Only?,https://www.reddit.com/r/MachineLearning/comments/dcus2p/d_will_the_upcoming_facebookmicrosoft_deepfake/,mystikaldanger,1570126592,"Just saw this on the project's [official website](https://deepfakedetectionchallenge.ai):

&gt;**Q: How are you protecting against adversaries who will try to access the code and data?** A: We will be gating access to the training dataset so only researchers accepted into the challenge can access it. Each participant will need to agree to terms of use on how they use, store, and handle the data, and there are strict restrictions on who else the data can be shared with. 

Any idea who they're counting as a ""researcher""? 

I'm guessing they're limiting this to people tied to accredited labs or institutions, and hobbyists are out of luck.",1,1,False,self,,,,,
157,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,3,dcv2ot,self.MachineLearning,Deep Learning workstation,https://www.reddit.com/r/MachineLearning/comments/dcv2ot/deep_learning_workstation/,datagentleman,1570127879,"Hello,

I'm planning to buy new hardware for my deep learning workstation and I don't know which case should I pick :(
I'm looking for high air flow case. For now I'm looking at

1. phanteks enthoo luxe 2
2. corsair carbide air 540

I'm also planning to buy 2 x Geforce RTX 2080 ti windforce
graphic cards. In the next 6 months I would buy another two, so in total I would have four of them.

I know that rtx blower cards  are better for quad configuration, but I think that  they will be too loud.

What do you think about this configuration and which case would you recommend ? 

Thanks !",0,1,False,self,,,,,
158,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,4,dcvvze,self.MachineLearning,Problems in Computer Vision Impeding Self Driving Cars?,https://www.reddit.com/r/MachineLearning/comments/dcvvze/problems_in_computer_vision_impeding_self_driving/,SilurianWenlock,1570131357,"What are the open problems in computer vision impeding self driving cars?

Why are they so difficult?

Trying to gain a better understand of the problems Elon Musk faces with his no LIDAR, cameras only solution.",0,1,False,self,,,,,
159,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,4,dcw0i3,c-span.org,"Gary Marcus ""Rebooting AI: Building AI We Can Trust"" crosspost from r/BookTVonReddit",https://www.reddit.com/r/MachineLearning/comments/dcw0i3/gary_marcus_rebooting_ai_building_ai_we_can_trust/,ShivasRightFoot,1570131885,,0,1,False,https://b.thumbs.redditmedia.com/35bMPXEzFjn6I43QbDrTNeUCqzS8ukxR5DmDjeiLhWU.jpg,,,,,
160,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,4,dcw1s6,self.MachineLearning,Deep Learning for Drones,https://www.reddit.com/r/MachineLearning/comments/dcw1s6/deep_learning_for_drones/,Fable67,1570132034,[removed],0,1,False,self,,,,,
161,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,5,dcwifg,self.MachineLearning,Join over 2.5m+ professionals who have enrolled in the Machine Learning program from Stanford University,https://www.reddit.com/r/MachineLearning/comments/dcwifg/join_over_25m_professionals_who_have_enrolled_in/,internetdigitalentre,1570133897,[removed],0,1,False,self,,,,,
162,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,5,dcwio6,self.MachineLearning,How is AlphaZero's MCTS effective?,https://www.reddit.com/r/MachineLearning/comments/dcwio6/how_is_alphazeros_mcts_effective/,vvvvvvvwvvvvvvv,1570133925,[removed],0,1,False,self,,,,,
163,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,5,dcwlrb,self.MachineLearning,Any good computer listening techniques?,https://www.reddit.com/r/MachineLearning/comments/dcwlrb/any_good_computer_listening_techniques/,robespierrem,1570134273,[removed],0,1,False,self,,,,,
164,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,5,dcwm5q,ai.googleblog.com,Improving Quantum Computation with Classical Machine Learning,https://www.reddit.com/r/MachineLearning/comments/dcwm5q/improving_quantum_computation_with_classical/,sjoerdapp,1570134323,,0,1,False,default,,,,,
165,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,6,dcxjlq,self.MachineLearning,Power law prediction,https://www.reddit.com/r/MachineLearning/comments/dcxjlq/power_law_prediction/,peterlaanguila8,1570138183,[removed],0,1,False,self,,,,,
166,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,6,dcxl3l,self.MachineLearning,[D] how can super resolution network be generative,https://www.reddit.com/r/MachineLearning/comments/dcxl3l/d_how_can_super_resolution_network_be_generative/,ice109,1570138363,"I'm playing with super resolution networks (SRResNet, SRGAN, EDSR, etc.) and I don't really understand how these things can function as generative process given that you're not feeding noise into the generator.",5,0,False,self,,,,,
167,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,6,dcxwsq,nature.com,[R] One neuron versus deep learning in aftershock prediction,https://www.reddit.com/r/MachineLearning/comments/dcxwsq/r_one_neuron_versus_deep_learning_in_aftershock/,shannoncoin,1570139802,,0,1,False,default,,,,,
168,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,7,dcy1pj,facebook.com,We're connecting AI &amp; Data Science talent &amp; projects across the Middle East &amp; Africa (MEA) region. Want to make it your mission?! Help share and grow the community.,https://www.reddit.com/r/MachineLearning/comments/dcy1pj/were_connecting_ai_data_science_talent_projects/,AILaunchpad,1570140395,,0,1,False,default,,,,,
169,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,7,dcy2ar,self.MachineLearning,[R] One neuron versus deep learning in aftershock prediction,https://www.reddit.com/r/MachineLearning/comments/dcy2ar/r_one_neuron_versus_deep_learning_in_aftershock/,shannoncoin,1570140470,"A [paper](https://www.nature.com/articles/s41586-019-1582-8) published yesterday in Nature's ""Matters Arising"" shows that logistic regression with just two parameters can achieve the same performance as the [deep learning approach published in Nature](https://www.nature.com/articles/s41586-018-0438-y) last August, which was previously discussed in this subreddit [here](https://www.reddit.com/r/MachineLearning/comments/c4ylga/d_misuse_of_deep_learning_in_nature_journals/) and [here](https://www.reddit.com/r/MachineLearning/comments/c8zf14/d_was_this_quake_ai_a_little_too_artificial/).",111,381,False,self,,,,,
170,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,8,dcz4pi,self.MachineLearning,Is there a way to install cleverhans in conda environment?,https://www.reddit.com/r/MachineLearning/comments/dcz4pi/is_there_a_way_to_install_cleverhans_in_conda/,2141rika,1570145395,[removed],0,1,False,self,,,,,
171,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,10,dd0fa9,self.MachineLearning,Can someone help a total noob understand how to use stylegan?,https://www.reddit.com/r/MachineLearning/comments/dd0fa9/can_someone_help_a_total_noob_understand_how_to/,Red2340,1570152007,[removed],0,1,False,self,,,,,
172,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,10,dd0jgp,arxiv.org,[R] Linking artificial and human neural representations of language,https://www.reddit.com/r/MachineLearning/comments/dd0jgp/r_linking_artificial_and_human_neural/,abhshkdz,1570152609,,2,6,False,default,,,,,
173,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,10,dd0s8c,arxiv.org,[P] MLPerf Training Benchmark,https://www.reddit.com/r/MachineLearning/comments/dd0s8c/p_mlperf_training_benchmark/,mttd,1570153884,,1,3,False,default,,,,,
174,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,12,dd1nay,self.MachineLearning,[D] Best papers with code on Speech-driven Face Animation / Visual Dubbing?,https://www.reddit.com/r/MachineLearning/comments/dd1nay/d_best_papers_with_code_on_speechdriven_face/,cbsudux,1570158511,"Hey guys!

Looking for papers on  Speech-driven Face Animation (or) Visual dubbing where given an audio + a video containing a face --&gt;  Output is a video of the face lip-synced to the audio.

Garrdio et al ""VDub: Modifying Face Video of Actors for Plausible Visual Alignment to a Dubbed Audio Track"" does this, but they don't seem to have released their code. 

Was wondering if there are any newer implementations.  


Thanks!",6,3,False,self,,,,,
175,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,12,dd1o4l,arxiv.org,[R] Gated Linear Networks,https://www.reddit.com/r/MachineLearning/comments/dd1o4l/r_gated_linear_networks/,xternalz,1570158649,,15,29,False,default,,,,,
176,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,12,dd1zvb,self.MachineLearning,DeepLav V3 vs. Mask R-CNN?,https://www.reddit.com/r/MachineLearning/comments/dd1zvb/deeplav_v3_vs_mask_rcnn/,June-Joon,1570160575,"Hello I am doing my first machine learning project in school and need to perform segmentation on images. 

If you have to implement one of them, which one would you choose and why? In other words, which one is easier to implement from novice's perspective?",0,1,False,self,,,,,
177,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,13,dd29sg,self.MachineLearning,Streamlit Python Tool,https://www.reddit.com/r/MachineLearning/comments/dd29sg/streamlit_python_tool/,tcr98,1570162163,[removed],0,1,False,self,,,,,
178,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,14,dd31kn,logiticks.com,How AI is Impacting Industries Worldwide?,https://www.reddit.com/r/MachineLearning/comments/dd31kn/how_ai_is_impacting_industries_worldwide/,divz_logiticks,1570167046,,0,1,False,default,,,,,
179,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,14,dd38q1,youtu.be,Neural Networks (Deep Learning) - Introduction,https://www.reddit.com/r/MachineLearning/comments/dd38q1/neural_networks_deep_learning_introduction/,lukescriptwalker,1570168379,,0,1,False,default,,,,,
180,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,15,dd3d23,self.MachineLearning,Power law compression of stft,https://www.reddit.com/r/MachineLearning/comments/dd3d23/power_law_compression_of_stft/,ravising_h,1570169165,[removed],0,1,False,self,,,,,
181,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,15,dd3f9c,countants.com,Comparing Google Analytics Vs Adobe Analytics Vs IBM Coremetrics for Web Analytics,https://www.reddit.com/r/MachineLearning/comments/dd3f9c/comparing_google_analytics_vs_adobe_analytics_vs/,Countants123,1570169571,,0,1,False,default,,,,,
182,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,15,dd3pff,self.MachineLearning,How to begin with neural network training?,https://www.reddit.com/r/MachineLearning/comments/dd3pff/how_to_begin_with_neural_network_training/,kozaleo,1570171542,[removed],0,1,False,self,,,,,
183,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,16,dd42bz,self.MachineLearning,Using machine learning / image recognition to stat track in game.,https://www.reddit.com/r/MachineLearning/comments/dd42bz/using_machine_learning_image_recognition_to_stat/,h4k01n,1570174074,[removed],0,1,False,self,,,,,
184,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,17,dd4jnc,self.MachineLearning,[D] Deep Learning: Our Miraculous Year 1990-1991,https://www.reddit.com/r/MachineLearning/comments/dd4jnc/d_deep_learning_our_miraculous_year_19901991/,hardmaru,1570177801,"*Schmidhuber's new [blog post](http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html) about deep learning papers from 1990-1991.*

The Deep Learning (DL) Neural Networks (NNs) of our team have revolutionised Pattern Recognition and Machine Learning, and are now heavily used in academia and industry. In 2020, we will celebrate that many of the basic ideas behind this revolution were published three decades ago within fewer than 12 months in our ""Annus Mirabilis"" or ""Miraculous Year"" 1990-1991 at TU Munich. Back then, few people were interested, but a quarter century later, NNs based on these ideas were on over 3 billion devices such as smartphones, and used many billions of times per day, consuming a significant fraction of the world's compute.

The following summary of what happened in 1990-91 not only contains some high-level context for laymen, but also references for experts who know enough about the field to evaluate the original sources. I also mention selected later work which further developed the ideas of 1990-91 (at TU Munich, the Swiss AI Lab IDSIA, and other places), as well as related work by others.

http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html",66,150,False,self,,,,,
185,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,17,dd4mri,blog.nviso.be,Apples or avocados? An introduction to adversarial machine learning,https://www.reddit.com/r/MachineLearning/comments/dd4mri/apples_or_avocados_an_introduction_to_adversarial/,daanraman,1570178512,,0,1,False,default,,,,,
186,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,17,dd4nqh,self.MachineLearning,[P] Implementation of TabNet (attentive interpretable tabular learning),https://www.reddit.com/r/MachineLearning/comments/dd4nqh/p_implementation_of_tabnet_attentive/,meechosch,1570178743,"I will try to implement [Tabnet](https://arxiv.org/pdf/1908.07442.pdf) this coming week on 10M+ curated dataset and report results. 

I have not implemented any of Google's models so, any advice very welcome. If anyone has tested Tabnet already feel free to get in touch.",9,6,False,self,,,,,
187,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,18,dd56zi,self.MachineLearning,Andrew Ng's ML Course done in Python?,https://www.reddit.com/r/MachineLearning/comments/dd56zi/andrew_ngs_ml_course_done_in_python/,whyiota,1570182705,[removed],0,1,False,self,,,,,
188,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,18,dd57g9,self.MachineLearning,[D] Andrew Ng's ML Course done in Python?,https://www.reddit.com/r/MachineLearning/comments/dd57g9/d_andrew_ngs_ml_course_done_in_python/,whyiota,1570182799,"Hi I just started taking Andrew Ng's ML course on coursera (paid to get the certificate). I know that in practice, most ML projects are done in Python these days. So I want to go through the course with Python. But all the programming assignments in the course are evaluated in MATLAB or Octave. Does that mean I will have to simultaneously do the exercises in Python and submit in MATLAB/Octave? Or is there a way to submit assignments in Python?",6,1,False,self,,,,,
189,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,18,dd58qy,self.MachineLearning,Advance Artificial Intelligence and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/dd58qy/advance_artificial_intelligence_and_machine/,mstechnoguide,1570183070,[removed],0,1,False,spoiler,,,,,
190,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,19,dd5fjb,self.MachineLearning,"To researchers hiring student assistants in their lab, what qualities are most important ?",https://www.reddit.com/r/MachineLearning/comments/dd5fjb/to_researchers_hiring_student_assistants_in_their/,mycareerisajoke,1570184361,[removed],0,1,False,self,,,,,
191,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,19,dd5khs,blog.ml.cmu.edu,[R] Ultra-Wide Deep Nets and the Neural Tangent Kernel (CMU ML Blog),https://www.reddit.com/r/MachineLearning/comments/dd5khs/r_ultrawide_deep_nets_and_the_neural_tangent/,wei_jok,1570185280,,4,32,False,default,,,,,
192,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,19,dd5kul,self.MachineLearning,What Is A Four Way Directional Control Valve?,https://www.reddit.com/r/MachineLearning/comments/dd5kul/what_is_a_four_way_directional_control_valve/,uflowindia,1570185348,[removed],0,1,False,https://b.thumbs.redditmedia.com/Fnc-smcjPYY0yaLOXmAikX9NaF5XAX9wZjiawcUSu8I.jpg,,,,,
193,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,20,dd68d1,self.MachineLearning,Using Pytorch's dataloaders to deal with big size text files.,https://www.reddit.com/r/MachineLearning/comments/dd68d1/using_pytorchs_dataloaders_to_deal_with_big_size/,kabirahuja2431,1570189513,[removed],0,1,False,self,,,,,
194,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,21,dd6hac,youtube.com,Artificial life simulation: artificial petridish,https://www.reddit.com/r/MachineLearning/comments/dd6hac/artificial_life_simulation_artificial_petridish/,Thomas-Arys,1570190948,,0,1,False,https://b.thumbs.redditmedia.com/Zp7Ye01LydMf-FZteZjqB1MoKSR9mRZmXVLdXT-2ulo.jpg,,,,,
195,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,21,dd6pd8,techexplorist.com,Improving quantum computation with classical machine learning,https://www.reddit.com/r/MachineLearning/comments/dd6pd8/improving_quantum_computation_with_classical/,pranjalmehar,1570192208,,0,1,False,default,,,,,
196,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,21,dd6sqj,techexplorist.com,[News] Improving quantum computation with classical machine learning,https://www.reddit.com/r/MachineLearning/comments/dd6sqj/news_improving_quantum_computation_with_classical/,pranjalmehar,1570192711,,0,1,False,default,,,,,
197,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,21,dd70s5,self.MachineLearning,"[P] imagededup, a new library to find duplicate images more easily!",https://www.reddit.com/r/MachineLearning/comments/dd70s5/p_imagededup_a_new_library_to_find_duplicate/,datitran,1570193922,"We've just open-sourced our library imagededup, a Python package that simplifies the task of finding exact and near duplicates in an image collection.

&amp;#x200B;

It includes:

 Several hashing algorithms (PHash, DHash etc) and convolutional neural networks

 An evaluation framework to judge the quality of deduplication

 Easy plotting functionality of duplicates

 Simple API

&amp;#x200B;

We're really excited about this library because finding image duplication is a very important task in computer vision and machine learning. For example, severe duplicates can create extreme biases in your evaluation of your ML model (check out the CIFAR-10 problem). Please try out our library,  it on Github and spread the word! We'd love to get feedback. 

&amp;#x200B;

 Code: [https://github.com/idealo/imagededup](https://github.com/idealo/imagededup)

 Docs: [https://idealo.github.io/imagededup/](https://idealo.github.io/imagededup/)

&amp;#x200B;

https://i.redd.it/8jgr7j0tuiq31.png",11,177,False,https://a.thumbs.redditmedia.com/v67DpZkVrAXWEqb2GWsTNRc3bb95yh2dNibzTB06Jj8.jpg,,,,,
198,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,22,dd74jn,self.MachineLearning,Can I use Kaggle for a commercial project?,https://www.reddit.com/r/MachineLearning/comments/dd74jn/can_i_use_kaggle_for_a_commercial_project/,L2Lern,1570194444,[removed],0,1,False,self,,,,,
199,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,22,dd7lxd,self.MachineLearning,[D] Best papers with code on Voice Conversion?,https://www.reddit.com/r/MachineLearning/comments/dd7lxd/d_best_papers_with_code_on_voice_conversion/,cbsudux,1570196923,"Hey guys,

I'm currently looking for implementations that do Voice Conversion - Transferring the style of one speaker to another.  I came across Auto-VC,  which seems to be the SOTA, but unfortunately doesn't have any training code.   


Would be great if you could post any links you know.

Cheers!",1,6,False,self,,,,,
200,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,23,dd7yl5,heartbeat.fritz.ai,Exploring Convolutional Neural Networks (CNNs) from an iOS Developers Perspective,https://www.reddit.com/r/MachineLearning/comments/dd7yl5/exploring_convolutional_neural_networks_cnns_from/,omarmhaimdat,1570198624,,0,0,False,https://b.thumbs.redditmedia.com/L_VmCn6M-f6alYQGpyfbbUZQ93Kdq8xJrygzrW4KXIU.jpg,,,,,
201,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,23,dd850b,self.MachineLearning,[P] Generating Words From Embeddings,https://www.reddit.com/r/MachineLearning/comments/dd850b/p_generating_words_from_embeddings/,MindSustenance,1570199476,"Hey guys,

I made a blog post a while back on my project on [Generating Words From Embeddings](https://rajatvd.github.io/Generating-Words-From-Embeddings/). It's a simple project which aims to create new meaningful words by generating them character by character, conditioned on a word embedding. 

Now, I finally got around to making a simple [colab notebook](https://colab.research.google.com/drive/1f_vW0k8YyoyiPIgX7eHP_a-8T3Zepat3) which makes it very easy to play around with the model and sample new words in a matter of minutes. I'd love to see what weird and interesting words you encounter when messing around with it!

Also, I made this quite a while back, so I only experimented with a simple decoder RNN (GRU/LSTM). Given the leaps and bounds by which NLP research has grown since then, it might be worth trying out more models (perhaps transformers) and seeing if they can generate qualitatively more pleasing words.

[GitHub repo](https://github.com/rajatvd/WordGenerator)",7,10,False,self,,,,,
202,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,23,dd88iy,self.MachineLearning,[P] Implementing Mask RCNN in Android application,https://www.reddit.com/r/MachineLearning/comments/dd88iy/p_implementing_mask_rcnn_in_android_application/,rohitkaul,1570199935,"Hi,

I am trying to implement Mask RCNN in android. I have already trained my model using  matterport's version ""[https://github.com/matterport/Mask\_RCNN](https://github.com/matterport/Mask_RCNN)'. I have also used [https://github.com/gustavz/Mobile\_Mask\_RCNN](https://github.com/gustavz/Mobile_Mask_RCNN), as it supports Mobilenetv1 and v2. 

I have converted my files to .pb and .tflite as well. I have tested the .pb file using python and C++ code and it is working fine.

I know we can use c++ in android. But I am not able to find some good documentation or how to implement it there.

If you guys know any other way to implement, please let me know.

Thanks",2,4,False,self,,,,,
203,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,23,dd8abn,self.MachineLearning,[P] RecipeNet - Training a Neural Network to Improve Recipes,https://www.reddit.com/r/MachineLearning/comments/dd8abn/p_recipenet_training_a_neural_network_to_improve/,dominik_schmidt,1570200157,"I trained a neural network to improve cooking recipes by adding new and fitting ingredients. It's trained on the simplified-recipes-1M dataset which differentiates between 3500 different ingredients.

[See the **results here**](https://dominikschmidt.xyz/recipe-net/)

[Download **the dataset**, more information and original sources and credits](https://dominikschmidt.xyz/simplified-recipes-1M/)",9,21,False,self,,,,,
204,MachineLearning,t5_2r3gv,2019-10-4,2019,10,4,23,dd8dgd,self.MachineLearning,[P] Visualization of Spectral Clustering on Graphs,https://www.reddit.com/r/MachineLearning/comments/dd8dgd/p_visualization_of_spectral_clustering_on_graphs/,dominik_schmidt,1570200569,"I created a tool to visualize the spectral clustering algorithm (for graphs).

**What is spectral clustering?**  
Spectral clustering is a clustering technique that can operate either on graphs or continuous data. It makes use of the eigenvectors of the laplacian- or similarity matrix of the data to find optimal cuts to separate the graph into multiple components.

[**Here is the article**](https://dominikschmidt.xyz/spectral-clustering/)

[Here is a direct link to the tool](https://dominikschmidt.xyz/spectral-clustering-exp/)",0,6,False,self,,,,,
205,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,0,dd8ltz,medium.com,First step towards Data Science,https://www.reddit.com/r/MachineLearning/comments/dd8ltz/first_step_towards_data_science/,arman_52,1570201591,,0,1,False,https://b.thumbs.redditmedia.com/ZPyZsu52lzt56XhkNJ0AjQeyB46JZiwILj6EyKPFLDY.jpg,,,,,
206,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,0,dd8lyr,self.MachineLearning,[D] What are the key limits/challenges of deep learning?,https://www.reddit.com/r/MachineLearning/comments/dd8lyr/d_what_are_the_key_limitschallenges_of_deep/,bendee983,1570201609,"As per Gary Marcus:

\- Over-reliance on data

\- Lack of generalization

\- Opacity/lack of explainability

[https://bdtechtalks.com/2018/02/27/limits-challenges-deep-learning-gary-marcus/](https://bdtechtalks.com/2018/02/27/limits-challenges-deep-learning-gary-marcus/)",9,2,False,self,,,,,
207,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,0,dd8qv8,github.com,"[P] GitHub - infinitered/keras-model-zoo: Ready to go, downloadable models for Keras",https://www.reddit.com/r/MachineLearning/comments/dd8qv8/p_github_infiniteredkerasmodelzoo_ready_to_go/,GantMan,1570202242,,1,1,False,default,,,,,
208,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,0,dd8r2v,medium.com,Markdown Cells  Jupyter Notebook,https://www.reddit.com/r/MachineLearning/comments/dd8r2v/markdown_cells_jupyter_notebook/,arman_52,1570202266,,0,1,False,https://b.thumbs.redditmedia.com/ZPyZsu52lzt56XhkNJ0AjQeyB46JZiwILj6EyKPFLDY.jpg,,,,,
209,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,0,dd8t2m,medium.com,Hugging Face Implements SOTA Transformer Architectures for PyTorch and TensorFlow 2.0,https://www.reddit.com/r/MachineLearning/comments/dd8t2m/hugging_face_implements_sota_transformer/,Yuqing7,1570202509,,0,1,False,default,,,,,
210,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,1,dd9bqt,self.MachineLearning,What is the current SOTA in document embeddings?,https://www.reddit.com/r/MachineLearning/comments/dd9bqt/what_is_the_current_sota_in_document_embeddings/,searchingundergrad,1570204829,[removed],0,1,False,self,,,,,
211,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,1,dd9ns6,self.MachineLearning,[D] What is the current SOTA in document embeddings?,https://www.reddit.com/r/MachineLearning/comments/dd9ns6/d_what_is_the_current_sota_in_document_embeddings/,searchingundergrad,1570206312,Does doc2vec still hold its weight or are there methods out there like [https://openreview.net/pdf?id=SyK00v5xx](https://openreview.net/pdf?id=SyK00v5xx) that consistently outperform it?,13,13,False,self,,,,,
212,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,1,dda0wl,self.MachineLearning,Choosing nearest neighbors to reduce bias,https://www.reddit.com/r/MachineLearning/comments/dda0wl/choosing_nearest_neighbors_to_reduce_bias/,Beliavsky,1570207963,[removed],0,1,False,self,,,,,
213,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,1,dda42j,arxiv.org,[R] Graph-Hist: Graph Classification from Latent Feature Histograms With Application to Bot Detection,https://www.reddit.com/r/MachineLearning/comments/dda42j/r_graphhist_graph_classification_from_latent/,network_tartan,1570208361,,1,2,False,default,,,,,
214,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,2,ddatz1,self.MachineLearning,Where can I learn machine learning using python,https://www.reddit.com/r/MachineLearning/comments/ddatz1/where_can_i_learn_machine_learning_using_python/,pratapnarra,1570211501,[removed],0,1,False,self,,,,,
215,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,3,ddbo54,monkeylearn.com,Keyword Extraction: a comprehensive guide to extracting keywords from text,https://www.reddit.com/r/MachineLearning/comments/ddbo54/keyword_extraction_a_comprehensive_guide_to/,doc2vec,1570215186,,0,1,False,default,,,,,
216,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,3,ddbqzv,self.MachineLearning,Who are the Michael Jordan's in Machine and Deep Learnnig right now?,https://www.reddit.com/r/MachineLearning/comments/ddbqzv/who_are_the_michael_jordans_in_machine_and_deep/,alcyman,1570215525,[removed],0,1,False,self,,,,,
217,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,4,ddchc5,self.MachineLearning,What's more important for image recognition? Fps or native resolution?,https://www.reddit.com/r/MachineLearning/comments/ddchc5/whats_more_important_for_image_recognition_fps_or/,Tmauer,1570218640,[removed],0,1,False,self,,,,,
218,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,4,ddciyo,self.MachineLearning,"Reproducing ""Adam: A Method for Stochastic Optimization""",https://www.reddit.com/r/MachineLearning/comments/ddciyo/reproducing_adam_a_method_for_stochastic/,sebas_n1,1570218821,[removed],0,1,False,self,,,,,
219,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,5,ddcngb,medium.com,Google Accelerates Quantum Computation with Classical Machine Learning,https://www.reddit.com/r/MachineLearning/comments/ddcngb/google_accelerates_quantum_computation_with/,Yuqing7,1570219366,,0,1,False,https://a.thumbs.redditmedia.com/27QVe6pXol8LHDnTdr3TyuYtA-x7g5aWcNfnoyaHk28.jpg,,,,,
220,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,5,ddcpii,self.MachineLearning,"[P] Here's the app I'm building that uses ML and computational photography to edit your videos - as a thank you for last week's AMA questions, you can use the code ""slashml"" to get in and try it out!",https://www.reddit.com/r/MachineLearning/comments/ddcpii/p_heres_the_app_im_building_that_uses_ml_and/,TrashPHD,1570219592,[removed],0,1,False,self,,,,,
221,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,5,ddd009,youtu.be,Great video from Coffee Break 2 summing up Suraj Raval accusations,https://www.reddit.com/r/MachineLearning/comments/ddd009/great_video_from_coffee_break_2_summing_up_suraj/,bigboyparpa,1570220835,,0,1,False,default,,,,,
222,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,5,ddd0jk,self.MachineLearning,"Assuming you have infinite resources, would there ever a point where increasing the size a of network make it worse?",https://www.reddit.com/r/MachineLearning/comments/ddd0jk/assuming_you_have_infinite_resources_would_there/,3met,1570220902,[removed],0,1,False,self,,,,,
223,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,5,ddd3us,self.MachineLearning,Getting in to Machine Learning,https://www.reddit.com/r/MachineLearning/comments/ddd3us/getting_in_to_machine_learning/,MillOd,1570221285,[removed],0,1,False,self,,,,,
224,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,6,dddje9,openreview.net,Large-scale Pretraining for Neural Machine Translation with Tens of Billions of Sentence Pairs,https://www.reddit.com/r/MachineLearning/comments/dddje9/largescale_pretraining_for_neural_machine/,Loser777,1570223155,,1,99,False,default,,,,,
225,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,6,dddrj2,self.MachineLearning,What are the advantages of different architectures on sensor timeseries data?,https://www.reddit.com/r/MachineLearning/comments/dddrj2/what_are_the_advantages_of_different/,abdeljalil73,1570224174,"What is the best performing architecture for timeseries data? let's say, the network will be trained to predict remaining useful life using sensors data.
I heard all RNN, LSTM, CNN and many hybrid architectures mentioned.",0,1,False,self,,,,,
226,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,8,ddfe7o,self.MachineLearning,Conference: The Hardware of Deep Learning,https://www.reddit.com/r/MachineLearning/comments/ddfe7o/conference_the_hardware_of_deep_learning/,andrea_manero,1570231718,[removed],0,1,False,self,,,,,
227,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,9,ddg4sp,self.MachineLearning,Deep RL project ideas?,https://www.reddit.com/r/MachineLearning/comments/ddg4sp/deep_rl_project_ideas/,CoevolvingAgent,1570235455,[removed],0,1,False,self,,,,,
228,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,11,ddhl0v,self.MachineLearning,Looking to make a basic car identification program from a single photo,https://www.reddit.com/r/MachineLearning/comments/ddhl0v/looking_to_make_a_basic_car_identification/,fatshootdong,1570243816,[removed],0,1,False,self,,,,,
229,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,11,ddhlz8,self.learnmachinelearning,Normal equation for linear regression,https://www.reddit.com/r/MachineLearning/comments/ddhlz8/normal_equation_for_linear_regression/,sunisamp,1570243961,,0,1,False,https://b.thumbs.redditmedia.com/1AMlnyg-DJrXU1D73S4LxVYk_9nj6GzMP6vvpm48RlI.jpg,,,,,
230,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,11,ddhodo,self.MachineLearning,How many of you have your own personal ML server?,https://www.reddit.com/r/MachineLearning/comments/ddhodo/how_many_of_you_have_your_own_personal_ml_server/,penatbater,1570244366,[removed],0,1,False,self,,,,,
231,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,13,ddilbq,self.MachineLearning,"In charge of starting autonomous driving from scratch, where to start?",https://www.reddit.com/r/MachineLearning/comments/ddilbq/in_charge_of_starting_autonomous_driving_from/,somekoreanhusky,1570250086,[removed],2,1,False,self,,,,,
232,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,14,ddj6v6,self.MachineLearning,How do you go from a 750-sampled input to a 600 x 3 output using a CNN?,https://www.reddit.com/r/MachineLearning/comments/ddj6v6/how_do_you_go_from_a_750sampled_input_to_a_600_x/,arjundupa,1570254183,"I am trying to reproduce the results of [this](https://www.researchgate.net/publication/327375583_A_Simple_and_Effective_Method_for_Detecting_Myocardial_Infarction_Based_on_Deep_Convolutional_Neural_Network) paper titled: ""A Simple and Effective Method for Detecting Myocardial Infarction Based on Deep Convolutional Neural Network""

The paper says:

&gt;The input to our CNN network is a fixed-size 750 samples.

Because the first layer is a 2D Convolutional layer, which requires a 4D input, I assume the input shape is (batch\_size, 1, 1, 750) -- their input only has one channel (making the 2nd dimension a 1), and that one channel is 1D (making the 3rd dimension a 1 and the 4th dimension equal to 750).

The table on page three with the network architecture says that the first (convolutional) layer has:

&gt;Kernel size: 151 x 3, Stride: 1, Output shape: 600 x 3, and Valid Padding

I tried implementing this with:

    self.conv1 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(1, 453), stride=1)

But, this gives me an output shape of (1 x 1 x 298). How can I get a (600 x 3) output which is consistent with all of their implementation details? Any ideas what I'm doing wrong?

Any ideas will be much appreciated, thank you!",0,1,False,self,,,,,
233,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,16,ddjygr,self.MachineLearning,Making a music dataset of modern music! using spotify playlists,https://www.reddit.com/r/MachineLearning/comments/ddjygr/making_a_music_dataset_of_modern_music_using/,The_Depressed_Gamer,1570259859,[removed],0,1,False,self,,,,,
234,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,16,ddk1mr,self.MachineLearning,Post your favorite playlist links here! (spotify playlists),https://www.reddit.com/r/MachineLearning/comments/ddk1mr/post_your_favorite_playlist_links_here_spotify/,The_Depressed_Gamer,1570260525,[removed],0,1,False,self,,,,,
235,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,16,ddk459,self.MachineLearning,"Interview with the CTO of Hugging Face: Julien Chaumond | Hugging Face, Transformers | NLP Research and Open Source + 3 AMA Announcements",https://www.reddit.com/r/MachineLearning/comments/ddk459/interview_with_the_cto_of_hugging_face_julien/,init__27,1570261053,[removed],0,1,False,self,,,,,
236,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,17,ddkkst,self.MachineLearning,"[D] Would it be possible to train a multi-class model on multiple datasets, where not all datasets are tagged with the same set of classes, but in the end obtain a model that predicts all classes jointly?",https://www.reddit.com/r/MachineLearning/comments/ddkkst/d_would_it_be_possible_to_train_a_multiclass/,visarga,1570264320,"Let's say I have a multi-class problem where classes are {A, B, C, Other} - where the Other class is a catch-all for all examples that are not in A, B or C. 

The data comes in multiple datasets - D1 and D2. Let's say D1 has been labeled {A, B, Other-or-C} and D2 has been labeled {A, C, Other-or-B}. In practice we can produce this kind of situation by making all C's into Other in D1 and all B's into Other in D2 from the original dataset D that contains all classes.

How can I modify the final layer of the network to accommodate this situation? In the end I want to train a model to predict {A, B, C, Other}

The significance of the problem is related to reducing the tagging effort. When you have D1 with 10000 examples and D2 with 500 examples, it would be much easier to train jointly with D1 and D2 as they are instead of tagging D1 with all tags in D2 and D2 with all tags in D1. Some tags might be common to D1 and D2.

This looks like a multi-task learning problem to me where the tasks are partially overlapping.",14,16,False,self,,,,,
237,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,18,ddkux7,youtu.be,"Ai FlappyBird, this time with TensorFlow.js implementing Reinforcement Learning",https://www.reddit.com/r/MachineLearning/comments/ddkux7/ai_flappybird_this_time_with_tensorflowjs/,pointless-ai,1570266329,,0,1,False,https://b.thumbs.redditmedia.com/7PdjgM-ETisEPrq8PKKZ9WSGcO4P2jiDMQ4bv7OLMas.jpg,,,,,
238,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,18,ddkz76,self.MachineLearning,[Q] Batch normalization using tensorflow 1.4,https://www.reddit.com/r/MachineLearning/comments/ddkz76/q_batch_normalization_using_tensorflow_14/,Abboudi97,1570267251,[removed],0,1,False,self,,,,,
239,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,19,ddlelr,self.MachineLearning,Who And Which Are The Top Researchers And Papers In The Theory of Deep Learning,https://www.reddit.com/r/MachineLearning/comments/ddlelr/who_and_which_are_the_top_researchers_and_papers/,attiaa13,1570270522,[removed],0,1,False,self,,,,,
240,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,19,ddleqy,self.MachineLearning,How to interpret t-SNE for unlabeled data?,https://www.reddit.com/r/MachineLearning/comments/ddleqy/how_to_interpret_tsne_for_unlabeled_data/,iamthursday,1570270563,[removed],0,1,False,self,,,,,
241,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,19,ddlk6s,self.MachineLearning,Which Valve Could Be Applicable To Control Compressed Air?,https://www.reddit.com/r/MachineLearning/comments/ddlk6s/which_valve_could_be_applicable_to_control/,uflowindia,1570271749,[removed],0,1,False,self,,,,,
242,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,20,ddm09j,self.pointless-ai,"Implemented Flappy Bird using TensorFlow.js in browser, yes yes yes in BROWSER !!! Demo included, Code included !!!",https://www.reddit.com/r/MachineLearning/comments/ddm09j/implemented_flappy_bird_using_tensorflowjs_in/,pointless-ai,1570274941,,0,1,False,default,,,,,
243,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,20,ddm6ij,self.MachineLearning,Is deepfake open source?,https://www.reddit.com/r/MachineLearning/comments/ddm6ij/is_deepfake_open_source/,tDagever,1570275940,"Hello reddit, first post here so i dont know the rules and how it goes yet, but i have a question:

&amp;#x200B;

Is the software that creates the ""faceswapping"" videos by the name ""DeepFake"" is open source?

I mean can i just copy paste it and implement it in my own project or do I need my own version of it coded? If it needs to be coded by myself, can i even do that legally? like is it patented or something?

I have thought of a project that needs deepfake in it, and i dont know how to proceed now, thank you very much!",0,1,False,self,,,,,
244,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,20,ddm6is,self.MachineLearning,"Got Confused with ""Confusion Matrix""",https://www.reddit.com/r/MachineLearning/comments/ddm6is/got_confused_with_confusion_matrix/,devilwearsbata,1570275942,"I got so confused with ""Confusion Matrix"", I decided to write an article about it.

Go ahead and read it, chances are you will at-least have the satisfaction of finding a lot of mistakes :)

[https://www.notion.so/Say-hello-to-Ron-e143d8d01a7b4defa1a7735df3da2390](https://www.notion.so/Say-hello-to-Ron-e143d8d01a7b4defa1a7735df3da2390)",0,1,False,self,,,,,
245,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,21,ddmeok,self.MachineLearning,Lasso: more penalization with more data?,https://www.reddit.com/r/MachineLearning/comments/ddmeok/lasso_more_penalization_with_more_data/,OpTic_,1570277227,[removed],0,1,False,self,,,,,
246,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,21,ddmw7t,self.MachineLearning,Data needs: where does the industry stand today? Where is it moving?,https://www.reddit.com/r/MachineLearning/comments/ddmw7t/data_needs_where_does_the_industry_stand_today/,eugeneherzog,1570280071,[removed],0,1,False,self,,,,,
247,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,21,ddmxyr,self.MachineLearning,Fun Project: Predict Result of next Football Match,https://www.reddit.com/r/MachineLearning/comments/ddmxyr/fun_project_predict_result_of_next_football_match/,nigol313,1570280353,[removed],0,1,False,self,,,,,
248,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,22,ddn5x7,self.MachineLearning,Announcing Facebook page of 'Generative Adversarial Networks Projects' book,https://www.reddit.com/r/MachineLearning/comments/ddn5x7/announcing_facebook_page_of_generative/,kailashahirwar12,1570281613,[removed],0,1,False,self,,,,,
249,MachineLearning,t5_2r3gv,2019-10-5,2019,10,5,22,ddn70b,self.MachineLearning,[Project] Unity Neural Network supervised learning based system,https://www.reddit.com/r/MachineLearning/comments/ddn70b/project_unity_neural_network_supervised_learning/,Kostiantyn-Dvornik,1570281777,"We make a system for supervised learning in Unity. You can use it in a lot of your games to experiment with AI. Nuron Dot Net is used. Also we tried AForge but got big leaning error event on simple XOR function. 

Out goal is to make universe system that can be used in any kind of the games.

 [https://doctrina-kharkov.blogspot.com/2019/10/unity-neural-networks-tutorial.html](https://doctrina-kharkov.blogspot.com/2019/10/unity-neural-networks-tutorial.html)",13,111,False,self,,,,,
250,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,0,ddojdi,self.MachineLearning,Thoughts on effectiveness of Cambridge Analytica,https://www.reddit.com/r/MachineLearning/comments/ddojdi/thoughts_on_effectiveness_of_cambridge_analytica/,nishitd,1570288718,[removed],0,1,False,self,,,,,
251,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,0,ddomsd,self.MachineLearning,Looking for a project,https://www.reddit.com/r/MachineLearning/comments/ddomsd/looking_for_a_project/,TheBoxyBoy,1570289165,[removed],0,1,False,self,,,,,
252,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,0,ddopcc,youtu.be,AI FIGHT WITH CARS,https://www.reddit.com/r/MachineLearning/comments/ddopcc/ai_fight_with_cars/,Realseppy,1570289511,,0,1,False,https://a.thumbs.redditmedia.com/A-Q-6H4cY2scMIVIIMA0evxY-qbSfw9RCzKHDCiajg8.jpg,,,,,
253,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,0,ddoupy,self.MachineLearning,[D] Effectiveness of Cambridge Analytica,https://www.reddit.com/r/MachineLearning/comments/ddoupy/d_effectiveness_of_cambridge_analytica/,nishitd,1570290204,"I was watching ""The Great Hack"" today and that makes it sound like Cambridge Analytica was some mind-blowing machine learning algorithm that did some amazing targeting.

The way I see it, they harvested a lot of data illegally from Facebook, but I am not sure how sophisticated or amazing their algorithm was. What are your thoughts on Cambridge Analytica purely from ML point of view? Are there any publications regarding it?",32,29,False,self,,,,,
254,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,0,ddp0ml,arxiv.org,[R] Underwhelming Generalization Improvements From Controlling Feature Attribution,https://www.reddit.com/r/MachineLearning/comments/ddp0ml/r_underwhelming_generalization_improvements_from/,downtownslim,1570290970,,8,1,False,default,,,,,
255,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,3,ddqrw8,i.redd.it,Can Artificial Intelligence help to Prevent Sexual Harassment,https://www.reddit.com/r/MachineLearning/comments/ddqrw8/can_artificial_intelligence_help_to_prevent/,Lordobba,1570298559,,0,1,False,https://b.thumbs.redditmedia.com/eoQPy3lL_E0qVATblbdRC4o2vfU7xLyqnrM10Ltuo3k.jpg,,,,,
256,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,3,ddqtjv,self.MachineLearning,"[D] Help me choose among three ""pop-sci"" books about Machine Learning",https://www.reddit.com/r/MachineLearning/comments/ddqtjv/d_help_me_choose_among_three_popsci_books_about/,IborkedyourGPU,1570298744,"I'd like to buy an introductory book on Machine Learning. This is not for studying, nor for reference - for that, I use books like [this one](https://www.amazon.com/Understanding-Machine-Learning-Theory-Algorithms/dp/1107057132). I just want to read a short book giving a bird's eye of the Machine Learning landscape. Something like Wasserman's ""All of Statistics"" for Stats. I think one of these books should do the job:

- https://www.amazon.com/dp/110845514X/ref=rdr_ext_sb_ti_hist_2
- https://www.amazon.com/Machine-Learning-Applied-Mathematics-Introduction/dp/1916081606/
- https://www.amazon.com/Hundred-Page-Machine-Learning-Book/dp/199957950X/
- https://www.amazon.com/Artificial-Intelligence-Engines-Introduction-Mathematics/dp/0956372813/

What would you suggest?",4,4,False,self,,,,,
257,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,3,ddrenl,self.MachineLearning,Is there any good GUI for designing a Neural Net?,https://www.reddit.com/r/MachineLearning/comments/ddrenl/is_there_any_good_gui_for_designing_a_neural_net/,van_ozy,1570301125,"I think most of us are familiar with [https://playground.tensorflow.org/](https://playground.tensorflow.org/) . I want something similar to playground but with more features such as the ability to choose more advanced network types such as RNN, LSTM, CNN, etc and also I want the GUI to export the model so I can run it later in a python program. Is something that I described exists?",0,1,False,self,,,,,
258,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,4,ddrqv1,self.MachineLearning,Machine Learning vs Discrete Event Simulation,https://www.reddit.com/r/MachineLearning/comments/ddrqv1/machine_learning_vs_discrete_event_simulation/,DappperDanH,1570302564,[removed],0,1,False,self,,,,,
259,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,4,ddrtgn,self.MachineLearning,want some insights on how to approach such machine learning problem,https://www.reddit.com/r/MachineLearning/comments/ddrtgn/want_some_insights_on_how_to_approach_such/,eveningstar7,1570302900,[removed],0,1,False,self,,,,,
260,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,4,ddrx5y,youtube.com,Write A Program To Generate Prime Numbers In Python - 1 To 1 Million,https://www.reddit.com/r/MachineLearning/comments/ddrx5y/write_a_program_to_generate_prime_numbers_in/,Karelm2004,1570303372,,0,1,False,https://b.thumbs.redditmedia.com/uk_N--B8bpM7uE6BL05hVkjdsffUnhi5xLfbzyKCmEs.jpg,,,,,
261,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,5,ddt2wy,self.MachineLearning,Is there a place where people link the latest softwares/tools that use machine learning..?,https://www.reddit.com/r/MachineLearning/comments/ddt2wy/is_there_a_place_where_people_link_the_latest/,MagicOfMessi,1570308448,"Some examples of really cool and useful softwares that i've found that use machine learning are: deepfacelab (for deepfakes), Gigapixel AI (for upscaling images and videos), waifu2x (again, another image upscaler)

&amp;#x200B;

So this has made me wonder how many more amazing Machine learning softwares there are out there that i don't know about. So are there like any news site for machine learning softwares?

&amp;#x200B;

Ok so while making this post i just made a discord server just for the purpose of sharing and linking new machine learning tools/softwares, you're free to join: [https://discord.gg/VvQvqH](https://discord.gg/VvQvqH)",0,1,False,self,,,,,
262,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,5,ddt8nb,self.MachineLearning,Comparing Architectures for a Specific Classification Task,https://www.reddit.com/r/MachineLearning/comments/ddt8nb/comparing_architectures_for_a_specific/,HungryQuant,1570309185,[removed],0,1,False,self,,,,,
263,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,6,ddtd1p,self.MachineLearning,Is anybody using tanh standarization for neural net inputs?,https://www.reddit.com/r/MachineLearning/comments/ddtd1p/is_anybody_using_tanh_standarization_for_neural/,OgorekDataSci,1570309742,[removed],1,1,False,self,,,,,
264,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,6,ddtja0,self.MachineLearning,[D] double blind review policy of AAAI/ICLR?,https://www.reddit.com/r/MachineLearning/comments/ddtja0/d_double_blind_review_policy_of_aaaiiclr/,PCCheater,1570310438,"Recently I noticed that some people promote their arxiv papers on their personal websites or social media right after the conference deadline, which violates the double blind review policy IMO. Is it a fancy way to cheat in the double-blind review process?

Examples:

&amp;#x200B;

&amp;#x200B;

[The pinned tweet](https://i.redd.it/1kxcsrb1hsq31.png)

&amp;#x200B;

[The submission to ICLR 2020 on openreview.net](https://i.redd.it/sdipgd8ahsq31.png)",12,1,False,https://b.thumbs.redditmedia.com/n2-I9hbV4GJ_fTBjp7mqXMGs9oMYt3pkJTrAXARM-0g.jpg,,,,,
265,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,8,dduxid,self.MachineLearning,"Need to start autonomous driving from scratch, where to start?",https://www.reddit.com/r/MachineLearning/comments/dduxid/need_to_start_autonomous_driving_from_scratch/,somekoreanhusky,1570316926,[removed],0,1,False,self,,,,,
266,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,8,ddva5z,self.learnmachinelearning,How often do you create your own ML models/classifiers vs just using one off the shelf without modification (ie. scikit-learn)?,https://www.reddit.com/r/MachineLearning/comments/ddva5z/how_often_do_you_create_your_own_ml/,xinwow,1570318555,,0,1,False,default,,,,,
267,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,9,ddvlaw,self.MachineLearning,[D] What is a SOTA of imbalanced learning?,https://www.reddit.com/r/MachineLearning/comments/ddvlaw/d_what_is_a_sota_of_imbalanced_learning/,vaseline555,1570320005," Though it is somewhat absurd to find 'SOTA' algorithm in imbalanced learning problem,

(since there exists solutions of a different nature)

are there any good recent papers (2018\~) on the ""method"" of dealing with imbalanced learning?

(I wandered around Google scholar, but there are mostly applications of existing methods on domain-specific problems)

I've recognized some generative methods like SMOTE, ADASYN, tons of GAN-based techniques,

cost-sensitive approaches, transforming loss functions, learning metrics, and over/under samplings, etc.",40,125,False,self,,,,,
268,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,9,ddvurh,self.MachineLearning,Looking for recs: Machine Learning course/cert for a Project Manager,https://www.reddit.com/r/MachineLearning/comments/ddvurh/looking_for_recs_machine_learning_coursecert_for/,HefeHuru,1570321164,[removed],0,1,False,self,,,,,
269,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,11,ddxdg6,self.MachineLearning,How do you interpret the association analysis rules output in R?,https://www.reddit.com/r/MachineLearning/comments/ddxdg6/how_do_you_interpret_the_association_analysis/,kosar7,1570329060,[removed],0,1,False,https://b.thumbs.redditmedia.com/1Qk2MVkHus7WuZjm7wu2VYlfWJaBZpxMO6UQ88uCz5Y.jpg,,,,,
270,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,11,ddxg3n,medium.com,Can AI Assist in Suicide Prevention?,https://www.reddit.com/r/MachineLearning/comments/ddxg3n/can_ai_assist_in_suicide_prevention/,Yuqing7,1570329474,,0,1,False,https://b.thumbs.redditmedia.com/a5t6GqIf4S-FZIvglBHJ973SVAWVkA_AriASpR07W_U.jpg,,,,,
271,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,13,ddyn1a,v.redd.it,HK : wearable face projector to avoid face recognition,https://www.reddit.com/r/MachineLearning/comments/ddyn1a/hk_wearable_face_projector_to_avoid_face/,usernameisafarce,1570336515,,0,1,False,https://b.thumbs.redditmedia.com/O5Ox5qRoLjcjXX1t-TbncBlELPcCoJKWjVHkfVPUbEw.jpg,,,,,
272,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,14,ddzafh,youtu.be,Early Weather simulation | Chaos theory,https://www.reddit.com/r/MachineLearning/comments/ddzafh/early_weather_simulation_chaos_theory/,insano369,1570341174,,0,1,False,default,,,,,
273,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,17,de0o2p,self.MachineLearning,Is there a standard method to deal with extremely imbalanced datasets ?,https://www.reddit.com/r/MachineLearning/comments/de0o2p/is_there_a_standard_method_to_deal_with_extremely/,aristidek,1570351417,"I am working on a binary classification problem where the positive classe represents about 0.1% of the dataset.

I spent some time doing a bibliography on the subject, and saw different methods but none appears to be some kind of standard that generally gives good enough results that could constitute a first benchmark for the project.

Also, while exploring the subject I learned about one-class classifiers (mainly anomaly detection models). Does anyone have experience using them ?

Thanks",0,1,False,self,,,,,
274,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,19,de1o4x,self.MachineLearning,Machine learning model to predict the ratings of players playing in the English premier league and pick out best XI for the fantasy premier league competition with atleast 85% accuracy?,https://www.reddit.com/r/MachineLearning/comments/de1o4x/machine_learning_model_to_predict_the_ratings_of/,arhitsingh15,1570358564,,0,1,False,self,,,,,
275,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,19,de1pli,self.MachineLearning,[R] Folks successfully design proteins using GANs (ProteinGAN),https://www.reddit.com/r/MachineLearning/comments/de1pli/r_folks_successfully_design_proteins_using_gans/,dxlino,1570358883,"The paper:

[Expanding functional protein sequence space using generative adversarial networks](https://www.biorxiv.org/content/10.1101/789719v1)

&amp;#x200B;

The code:

[https://github.com/biomatterdesigns/ProteinGAN](https://github.com/biomatterdesigns/ProteinGAN)

&amp;#x200B;

&amp;#x200B;

From personal practice while training GAN's is hard, it's even harder

to generate clever discrete structures. I think it's quite fascinating application.",0,0,False,self,,,,,
276,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,19,de1rc8,youtu.be,Write A Program To Generate Prime Numbers In Python - 1 To 1 Million,https://www.reddit.com/r/MachineLearning/comments/de1rc8/write_a_program_to_generate_prime_numbers_in/,Karelm2004,1570359248,,0,1,False,default,,,,,
277,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,20,de234z,self.MachineLearning,Why investing in #AI is (still) one of the biggest commercial opportunities for businesses ..,https://www.reddit.com/r/MachineLearning/comments/de234z/why_investing_in_ai_is_still_one_of_the_biggest/,pascal_bernard,1570361618,[removed],0,1,False,self,,,,,
278,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,20,de24ou,self.MachineLearning,Programmers wanted for creating an open source AI system,https://www.reddit.com/r/MachineLearning/comments/de24ou/programmers_wanted_for_creating_an_open_source_ai/,johantino,1570361933,[removed],0,0,False,self,,,,,
279,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,20,de26l3,self.MachineLearning,Machine learning for data quality control?,https://www.reddit.com/r/MachineLearning/comments/de26l3/machine_learning_for_data_quality_control/,Teddyzander,1570362310,[removed],0,1,False,self,,,,,
280,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,21,de2e3t,self.MachineLearning,What's your top secret tip?,https://www.reddit.com/r/MachineLearning/comments/de2e3t/whats_your_top_secret_tip/,noitseuqaksa,1570363718,[removed],0,1,False,self,,,,,
281,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,21,de2g3q,nature.com,[N] Massive Computational Acceleration By Using Neural Networks To Emulate Mechanism-Based Biological Models,https://www.reddit.com/r/MachineLearning/comments/de2g3q/n_massive_computational_acceleration_by_using/,mystikaldanger,1570364070,,0,1,False,default,,,,,
282,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,21,de2j0b,self.MachineLearning,Help running ML model,https://www.reddit.com/r/MachineLearning/comments/de2j0b/help_running_ml_model/,itnabakwaas,1570364554,[removed],0,1,False,self,,,,,
283,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,22,de38h1,self.MachineLearning,Organizing conferences papers,https://www.reddit.com/r/MachineLearning/comments/de38h1/organizing_conferences_papers/,kekkimo,1570368491,[removed],0,1,False,self,,,,,
284,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,22,de3kbd,self.MachineLearning,Any interesting work on using only part of a bigger Neural Network architecture?,https://www.reddit.com/r/MachineLearning/comments/de3kbd/any_interesting_work_on_using_only_part_of_a/,AlexGuilBot,1570370221,[removed],0,1,False,self,,,,,
285,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,23,de3m5j,self.MachineLearning,[D] How to deal with a classification problem of a big mbalanced dataset?,https://www.reddit.com/r/MachineLearning/comments/de3m5j/d_how_to_deal_with_a_classification_problem_of_a/,melesigenes,1570370495,"I have a dataset of 8 million unique members, approximately 800 million records. Of those 8 million members I have a positive sample of about 25000. It's a binary classification problem. I would like to not simply downsample although the downsampled RF performs pretty well. The data is on a Hadoop cluster. I only have access to it via a Zeppelin notebook with PySpark. It's a pain in the ass to get approval for packages installed. PySpark is even in python 2.7 and I don't really use Python 2. What should I do? The notebook is in a VM that's not connected to the worldwideweb. I would have to rewrite solutions like SMOTE if I wanted to use it. I found a package but it takes like a week for approval and I only have two more weeks for the project. I wanted to use a balanced or weighted random forest but I don't see a native spark.ml implemention. I'm also kind of new to spark. 

Any tips or advice on how to proceed? Would highly appreciate.",21,33,False,self,,,,,
286,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,23,de3ohw,learning-to-paint.github.io,Learning to Paint Adversarial RL,https://www.reddit.com/r/MachineLearning/comments/de3ohw/learning_to_paint_adversarial_rl/,mrpogiface,1570370804,,0,1,False,https://b.thumbs.redditmedia.com/GmrqP0ID0KqCK0lle77dq45GA2nzCGCoFv_MxoGBgxI.jpg,,,,,
287,MachineLearning,t5_2r3gv,2019-10-6,2019,10,6,23,de4aor,self.MachineLearning,sentiment classification for text data,https://www.reddit.com/r/MachineLearning/comments/de4aor/sentiment_classification_for_text_data/,sanwal092,1570373872,[removed],0,1,False,self,,,,,
288,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,0,de4gs4,self.MachineLearning,Machine Learning  Can We Please Just Agree What This Means,https://www.reddit.com/r/MachineLearning/comments/de4gs4/machine_learning_can_we_please_just_agree_what/,andrea_manero,1570374652,[removed],0,1,False,self,,,,,
289,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,0,de4hyn,hatem-hassan.com,Designing Data Intensive Applications - Book Review,https://www.reddit.com/r/MachineLearning/comments/de4hyn/designing_data_intensive_applications_book_review/,iammowgoud,1570374806,,0,1,False,https://b.thumbs.redditmedia.com/qy_QrpGd5YMAgvYCk4VZ0v9Rfgm-jAeWXAPTTfIWIYg.jpg,,,,,
290,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,0,de4k6x,youtube.com,AI Panel and Q&amp;A with Dr Yann LeCun &amp; Dr. Edward Chang,https://www.reddit.com/r/MachineLearning/comments/de4k6x/ai_panel_and_qa_with_dr_yann_lecun_dr_edward_chang/,DrJohanson,1570375120,,0,1,False,https://b.thumbs.redditmedia.com/w2JlSFDatcoyrzD2DV9eY-wpxJ4B4Mp16Ez3Usut8lo.jpg,,,,,
291,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,0,de4r1u,self.MachineLearning,My selection of Books about the Philosophy of Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/de4r1u/my_selection_of_books_about_the_philosophy_of/,pascal_bernard,1570375991,[removed],1,1,False,self,,,,,
292,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,1,de5dqj,github.com,C++ implementation of the paper Side Window Median Filtering(CVPR 2019),https://www.reddit.com/r/MachineLearning/comments/de5dqj/c_implementation_of_the_paper_side_window_median/,Ldpe2G,1570378812,,0,1,False,https://b.thumbs.redditmedia.com/ThtVg-XZJTxJKUQv4Seii8zVKebvlVnj2fQ_TWsR1EI.jpg,,,,,
293,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,1,de5wam,self.MachineLearning,[D] How Do You Read Large Numbers Of Academic Papers Without Going Crazy?,https://www.reddit.com/r/MachineLearning/comments/de5wam/d_how_do_you_read_large_numbers_of_academic/,mystikaldanger,1570381062,"When going on a Google Scholar binge, it's really easy for me to click the link to the citing articles of the paper I'm reading, then want to see the citing papers of those articles, and so on. 

What initially looked like a small field of knowledge that would take an afternoon to get caught up on is revealed to be an unfathomable ocean that requires a lifetime of study to make any dent in. I very quickly become overwhelmed,  and anxiety/panic starts to set in. 

Is there any way to cope with this feeling when doing research? I suspect a lot of it is due to my ADD and desire to Learn Everything.",129,463,False,self,,,,,
294,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,2,de61ng,self.MachineLearning,Easily compare cloud computing AI &amp; ML solutions !,https://www.reddit.com/r/MachineLearning/comments/de61ng/easily_compare_cloud_computing_ai_ml_solutions/,tahzem,1570381692," Hi everyone !

We are working on [www.ai-compare.com](https://www.ai-compare.com), a solution that will allow users to do personalized benchmarking of several suppliers of IA and ML solutions in SaaS and on different themes (OCR, Computer Vision, NLP, autoML, etc.).

To improve our product, we have developed this short survey (\~ 2 min) that will allow us to better understand your uses of cloud computing and thus better focus our development. Thank you for taking a moment to answer:

[tahazemmouri.typeform.com/to/QzTLS7](https://tahazemmouri.typeform.com/to/QzTLS7)

Thanks,

Taha",0,1,False,self,,,,,
295,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,2,de62ve,self.MachineLearning,Glow Compiler,https://www.reddit.com/r/MachineLearning/comments/de62ve/glow_compiler/,wassimseifeddine,1570381836,"Does anyone know a good resource understanding how glow works?

&amp;#x200B;

I already read the paper &amp; watch the LLVM talks but I appreciate more content if available.

Basically I want to know how it does low-level IR optimization like quantization, graph lowering &amp; instruction scheduling",0,1,False,self,,,,,
296,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,2,de64az,towardsdatascience.com,Face and mood detection  face-api.js,https://www.reddit.com/r/MachineLearning/comments/de64az/face_and_mood_detection_faceapijs/,denomer12,1570382014,,0,1,False,default,,,,,
297,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,2,de67eb,self.MachineLearning,[R] OgmaNeo plays Atari Pong,https://www.reddit.com/r/MachineLearning/comments/de67eb/r_ogmaneo_plays_atari_pong/,CireNeikual,1570382398,"Hey all,

[Here are some of our first successful results for running OgmaNeo on Atari Pong (from pixels).](https://ogma.ai/2019/10/ogmaneo-playing-atari-pong-from-pixels/)

While the model trained in the post was not trained on a Raspberry Pi, we have done tests to show that it does run on the Pi in real-time (60fps) with learning enabled. If enough people would like to know exactly how fast it runs on a Pi, we can perform another experiment where everything is run entirely on the Pi and report some exact performance results. For now though, we are working on releasing the demo code with documentation.

For those that don't know, [OgmaNeo](https://github.com/ogmacorp/OgmaNeo2) is a library written in C++ with Python bindings that implements Sparse Predictive Hierarchies (SPH), a biologically-inspired and extremely fast memory prediction framework. We have long tried to implement reinforcement learning with this system, and I think we have finally found success!",6,19,False,self,,,,,
298,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,2,de6h3u,youtu.be,Write A Program To Check If A Number Is Prime Or Not In Python - Tutorial,https://www.reddit.com/r/MachineLearning/comments/de6h3u/write_a_program_to_check_if_a_number_is_prime_or/,Karelm2004,1570383586,,0,1,False,https://b.thumbs.redditmedia.com/6aZoNSl08hHP5XtvKtMTRdSPShOkatAnQK_fbbxjEAQ.jpg,,,,,
299,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,3,de7dhr,youtu.be,What Are The 7 Capabilities Every AI Should Have?,https://www.reddit.com/r/MachineLearning/comments/de7dhr/what_are_the_7_capabilities_every_ai_should_have/,AILaunchpad,1570387239,,0,1,False,https://a.thumbs.redditmedia.com/nLQj3DLxSucEliVDbQj9vTwqcM0s_NvCI53bk_cp9R0.jpg,,,,,
300,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,3,de7fcr,self.MachineLearning,Unsupervised concept learning,https://www.reddit.com/r/MachineLearning/comments/de7fcr/unsupervised_concept_learning/,JHogg11,1570387449,[removed],0,1,False,https://b.thumbs.redditmedia.com/OYNctCHzdV9Ybsm9NjpvSguM8PIEkv7lrnwjZTDp_BA.jpg,,,,,
301,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,5,de8h48,self.MachineLearning,[D] Machine Learning - WAYR (What Are You Reading) - Week 72,https://www.reddit.com/r/MachineLearning/comments/de8h48/d_machine_learning_wayr_what_are_you_reading_week/,ML_WAYR_bot,1570392004,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|31-40|41-50|51-60|61-70|71-80|
|----|-----|-----|-----|-----|-----|-----|-----|
|[Week 1](https://www.reddit.com/4qyjiq)|[Week 11](https://www.reddit.com/57xw56)|[Week 21](https://www.reddit.com/60ildf)|[Week 31](https://www.reddit.com/6s0k1u)|[Week 41](https://www.reddit.com/7tn2ax)|[Week 51](https://reddit.com/9s9el5)|[Week 61](https://reddit.com/bfsx4z)|[Week 71](https://reddit.com/d7vno3)||||||
|[Week 2](https://www.reddit.com/4s2xqm)|[Week 12](https://www.reddit.com/5acb1t)|[Week 22](https://www.reddit.com/64jwde)|[Week 32](https://www.reddit.com/72ab5y)|[Week 42](https://www.reddit.com/7wvjfk)|[Week 52](https://reddit.com/a4opot)|[Week 62](https://reddit.com/bl29ov)||
|[Week 3](https://www.reddit.com/4t7mqm)|[Week 13](https://www.reddit.com/5cwfb6)|[Week 23](https://www.reddit.com/674331)|[Week 33](https://www.reddit.com/75405d)|[Week 43](https://www.reddit.com/807ex4)|[Week 53](https://reddit.com/a8yaro)|[Week 63](https://reddit.com/bqlb3v)||
|[Week 4](https://www.reddit.com/4ub2kw)|[Week 14](https://www.reddit.com/5fc5mh)|[Week 24](https://www.reddit.com/68hhhb)|[Week 34](https://www.reddit.com/782js9)|[Week 44](https://reddit.com/8aluhs)|[Week 54](https://reddit.com/ad9ssz)|[Week 64](https://reddit.com/bw1jm7)||
|[Week 5](https://www.reddit.com/4xomf7)|[Week 15](https://www.reddit.com/5hy4ur)|[Week 25](https://www.reddit.com/69teiz)|[Week 35](https://www.reddit.com/7b0av0)|[Week 45](https://reddit.com/8tnnez)|[Week 55](https://reddit.com/ai29gi)|[Week 65](https://reddit.com/c7itkk)||
|[Week 6](https://www.reddit.com/4zcyvk)|[Week 16](https://www.reddit.com/5kd6vd)|[Week 26](https://www.reddit.com/6d7nb1)|[Week 36](https://www.reddit.com/7e3fx6)|[Week 46](https://reddit.com/8x48oj)|[Week 56](https://reddit.com/ap8ctk)|[Week 66](https://reddit.com/cd7gko)||
|[Week 7](https://www.reddit.com/52t6mo)|[Week 17](https://www.reddit.com/5ob7dx)|[Week 27](https://www.reddit.com/6gngwc)|[Week 37](https://www.reddit.com/7hcc2c)|[Week 47](https://reddit.com/910jmh)|[Week 57](https://reddit.com/auci7c)|[Week 67](https://reddit.com/cj0kyc)||
|[Week 8](https://www.reddit.com/53heol)|[Week 18](https://www.reddit.com/5r14yd)|[Week 28](https://www.reddit.com/6jgdva)|[Week 38](https://www.reddit.com/7kgcqr)|[Week 48](https://reddit.com/94up0g)|[Week 58](https://reddit.com/azjoht)|[Week 68](https://reddit.com/cp1jex)||
|[Week 9](https://www.reddit.com/54kvsu)|[Week 19](https://www.reddit.com/5tt9cz)|[Week 29](https://www.reddit.com/6m9l1v)|[Week 39](https://www.reddit.com/7nayri)|[Week 49](https://reddit.com/98n2rt)|[Week 59](https://reddit.com/b50r5y)|[Week 69](https://reddit.com/cvde5a)||
|[Week 10](https://www.reddit.com/56s2oa)|[Week 20](https://www.reddit.com/5wh2wb)|[Week 30](https://www.reddit.com/6p3ha7)|[Week 40](https://www.reddit.com/7qel9p)|[Week 50](https://reddit.com/9cf158)|[Week 60](https://reddit.com/bakew0)|[Week 70](https://reddit.com/d1g1k9)||

Most upvoted papers two weeks ago:

/u/LazyAnt_: [The Curious Case of Neural Text Degeneration](https://arxiv.org/abs/1904.09751)

/u/sam_does_things: [Forecaster: A Graph Transformer for Forecasting Spatial and Time-Dependent Data](https://arxiv.org/abs/1909.04019v3)

Besides that, there are no rules, have fun.",33,12,False,self,,,,,
302,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,5,de8wh2,arxiv.org,[R] On Universal Approximation by Neural Networks with Uniform Guarantees [...],https://www.reddit.com/r/MachineLearning/comments/de8wh2/r_on_universal_approximation_by_neural_networks/,MadcowD,1570393785,,4,12,False,default,,,,,
303,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,6,de9tmy,self.MachineLearning,Ultimate v1.0 Release of Yellowbrick (Open Source Python Machine Learning Visualization Library) Check out the gallery:,https://www.reddit.com/r/MachineLearning/comments/de9tmy/ultimate_v10_release_of_yellowbrick_open_source/,W1zK1dd,1570397854,[removed],0,1,False,self,,,,,
304,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,6,dea0qo,self.MachineLearning,machine learning for automated literature review,https://www.reddit.com/r/MachineLearning/comments/dea0qo/machine_learning_for_automated_literature_review/,dontSayReddit,1570398714,[removed],0,1,False,self,,,,,
305,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,7,deav3u,self.MachineLearning,"Paper about training on ImageNet with each image as own class, but can't remember title/authors",https://www.reddit.com/r/MachineLearning/comments/deav3u/paper_about_training_on_imagenet_with_each_image/,edon581,1570402668,[removed],0,1,False,self,,,,,
306,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,9,debxr5,self.MachineLearning,[D] Papers on experimental science in ML/DL,https://www.reddit.com/r/MachineLearning/comments/debxr5/d_papers_on_experimental_science_in_mldl/,Naveos,1570408176,"Stumbled upon the paper on super-convergence and it blew my mind, and I was immediately thinking about what other papers exist that've made wonderous experimental discoveries in ML/DL that were never published due to them being, well, experimental in nature - and apparently these sort of papers are a no-no in the DL scientific community.

Thus wondering; does anyone know what's the best place to find more of these sort of papers / discoveries?",1,3,False,self,,,,,
307,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,12,dedpqw,self.MachineLearning,[D] Are there any good datasets consisting of academic research papers?,https://www.reddit.com/r/MachineLearning/comments/dedpqw/d_are_there_any_good_datasets_consisting_of/,Mystery3434,1570417493,[removed],0,1,False,self,,,,,
308,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,12,dedxbs,arxiv.org,[R] Neural Turtle Graphics for Modeling City Road Layouts,https://www.reddit.com/r/MachineLearning/comments/dedxbs/r_neural_turtle_graphics_for_modeling_city_road/,hardmaru,1570418664,,2,5,False,default,,,,,
309,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,14,deew5w,self.MachineLearning,Reinforcement learning Agent from scratch tutorials,https://www.reddit.com/r/MachineLearning/comments/deew5w/reinforcement_learning_agent_from_scratch/,indi0508,1570424500,[removed],0,1,False,self,,,,,
310,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,14,defb53,radiantinsights.com,"Machine Learning Market in India to see Stunning Growth with Key Players Artivatic, Formcept, PixelCrayons, QBurst, Amazon",https://www.reddit.com/r/MachineLearning/comments/defb53/machine_learning_market_in_india_to_see_stunning/,Sunilrathod2504,1570427314,,0,1,False,default,,,,,
311,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,15,defey7,arxiv.org,[R] Bootstrapping Conditional GANs for Video Game Level Generation,https://www.reddit.com/r/MachineLearning/comments/defey7/r_bootstrapping_conditional_gans_for_video_game/,hardmaru,1570428052,,1,4,False,default,,,,,
312,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,15,defiac,self.MachineLearning,[P] A step-by-step Policy Gradient algorithms Colab + Pytorch tutorial,https://www.reddit.com/r/MachineLearning/comments/defiac/p_a_stepbystep_policy_gradient_algorithms_colab/,syee-kim,1570428698,"* Project link: [https://github.com/MrSyee/pg-is-all-you-need](https://github.com/MrSyee/pg-is-all-you-need)

Hi, ML redditors! I and my colleagues made a Reinforcement Learning tutorial in Pytorch which consists of  Policy Gradient algorithms from A2C to SAC. In addition, it includes learning acceleration methods using demonstrations for treating real applications with sparse rewards:

1. A2C
2. PPO
3. DDPG
4. TD3
5. SAC
6. DDPG from Demonstration
7. Behavior Cloning (with DDPG)

Every chapter contains both theoretical backgrounds and object-oriented implementation, and thanks to Colab, you can execute them and render the results without any installation even on your smartphone!

I hope it will be helpful for someone. :)

Cheers.",12,48,False,self,,,,,
313,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,15,defigc,arxiv.org,[R] FaceForensics++: Learning to Detect Manipulated Facial Images,https://www.reddit.com/r/MachineLearning/comments/defigc/r_faceforensics_learning_to_detect_manipulated/,sensetime,1570428735,,4,8,False,default,,,,,
314,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,15,defl1o,self.MachineLearning,NeurIPS Workshop Tickets,https://www.reddit.com/r/MachineLearning/comments/defl1o/neurips_workshop_tickets/,How2ML,1570429246,[removed],0,1,False,self,,,,,
315,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,15,defn09,self.MachineLearning,Could NLP one day turn English into a programming language?,https://www.reddit.com/r/MachineLearning/comments/defn09/could_nlp_one_day_turn_english_into_a_programming/,ALLIRIX,1570429619,[removed],0,1,False,self,,,,,
316,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,15,defusm,self.MachineLearning,NeurIPS Workshop Tickets,https://www.reddit.com/r/MachineLearning/comments/defusm/neurips_workshop_tickets/,rightylefty92,1570431148,[removed],0,1,False,self,,,,,
317,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,16,defzh5,self.MachineLearning,[D] Best practice when dealing with feature pairs with strong Pearson Correlation scores,https://www.reddit.com/r/MachineLearning/comments/defzh5/d_best_practice_when_dealing_with_feature_pairs/,times_of_change,1570432080,"Lets say we have some features pairs that have strong Pearson Correlation scores that are:

* Exactly +1 or -1 (lets call this **T1** pairs)
* Very close to being +1 or -1 or above a threshold (**T2**)
* Correlating very closely like the T2s but with multiple other features but those features that its correlating with are not correlating with each other suspiciously (**T3**)

Lets call the threshold past which we say features pairs are T2 or T3 the **TRESH**.

Lets also make the following assumptions about these suspicious feature pairs:

1. They are not One Hot Encoded or some kind of ordinal encoding
2. They are all floating point numbers with high variances
3. At least one of them has good correlation with the label(s)

What I would like to discuss is the following:

# Options with T1, T2 and T3:

1. Drop the one with a *bad* or lower correlation with the label(s)
2. Drop one regardless
3. Drop both and replace with a new feature that combines both: interaction

# Options with T3:

1. Drop the common feature if it is correlating *badly* or worse with the label(s) than any of the other features its correlating strongly with
2. Drop the common feature regardless
3. Drop all and interact the common feature with each of its buddies
4. Drop all and interact the entire group with each other

# Options with THRESH:

1. Always a constant value (specify the value)
2. A low custom value when you want to do feature reduction and a high custom value for when you want the most descriptive features only

Sample strategies: 

* `T11 T21 T31 THRESH: 0.8` means drop worst T1 then drop worst T2 then drop worst T3 at constant suspicion threshold of +0.8 and -0.8
* `T11 T31 T23 THRESH: 2` means drop worst T1 then drop worst in T3 then interact remaining T2s with each other at a suspicion threshold that depends on what you seek to accomplish with the current dataset

Notice how the order matters. Please use this convention to make it fast and easy to understand what you think is best and then add your reasons. Feel free to suggest new options. I will add them to the post.",0,2,False,self,,,,,
318,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,16,deg2bv,self.MachineLearning,[D] NeurIPS Workshop Tickets,https://www.reddit.com/r/MachineLearning/comments/deg2bv/d_neurips_workshop_tickets/,How2ML,1570432662,"Does anybody know when the organizers of NeurIPS will give access to the tickets to the workshop organizers, so that they can distribute them to presenters who didn't get lucky in the lottery?",3,2,False,self,,,,,
319,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,16,deg3ot,self.MachineLearning,Why tensorflow 2.0.0(official ) is much much much much slower than tensorflow 2.0.-beta1(both are cpu verison)?,https://www.reddit.com/r/MachineLearning/comments/deg3ot/why_tensorflow_200official_is_much_much_much_much/,H_uuu,1570432946,[removed],0,1,False,self,,,,,
320,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,17,degni6,self.MachineLearning,Having trouble understanding a sentence in Flow++ paper,https://www.reddit.com/r/MachineLearning/comments/degni6/having_trouble_understanding_a_sentence_in_flow/,blooooodseeeeker,1570437350,[removed],0,1,False,self,,,,,
321,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,17,degopk,self.MachineLearning,"Machine Learning Certification Course in Delhi, Machine Learning Certification Course",https://www.reddit.com/r/MachineLearning/comments/degopk/machine_learning_certification_course_in_delhi/,dtacademy,1570437639,"The Drona Training Academy provides the best [**Machine Learning Certification Course in Delhi**](https://www.dtacademy.in/) with gaining full practical knowledge on real-time projects. We offer you 100% placement assistance in order to secure the job for our every candidate. Limited slots are available, enroll soon. For getting free demo classes, directly call us at @9999553092 or visit us at: https://www.dtacademy.in/

![img](p2jsjveqz2r31)",0,1,False,self,,,,,
322,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,18,deh1cq,self.MachineLearning,[D] Documented code for reproducible experiments on meta-learning algorithms,https://www.reddit.com/r/MachineLearning/comments/deh1cq/d_documented_code_for_reproducible_experiments_on/,etienne_ben,1570440152,"Hi everyone! I worked for 6 months on meta-learning algorithms for few-shot computer vision (classifying images or detecting objects with few examples). The code for my experiments in now public:

 [https://github.com/ebennequin/FewShotVision](https://github.com/ebennequin/FewShotVision) 

It's fully documented, and you should be able to launch your own experiments in a transparent and reproducible way. Please tell me if I can improve it!",0,1,False,self,,,,,
323,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,18,deh67h,self.MachineLearning,"How do you handle large machine learning models with Continuous integration tools (github, bitbucket)?",https://www.reddit.com/r/MachineLearning/comments/deh67h/how_do_you_handle_large_machine_learning_models/,Chiplusplus,1570441094,[removed],0,1,False,self,,,,,
324,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,19,deheja,self.MachineLearning,[P] Jobs + Internships in AI/ML,https://www.reddit.com/r/MachineLearning/comments/deheja/p_jobs_internships_in_aiml/,ai_jobs,1570442792,"A clean and lean approach to hiring for and finding jobs in AI/ML: [ai-jobs.net](https://ai-jobs.net)

Searching for positions is also possible [via DDG now](https://www.reddit.com/r/artificial/comments/d4ybwr/duckduckgo_now_has_a_bang_for_finding_jobs_in_ai/) ;)",12,35,False,self,,,,,
325,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,19,dehl45,isbusinessanalytics.com,"Global Truck &amp; Bus Carnet Market 2019 by Top Players:- Google, Baidu, Alibaba, Tencent, ATA, Nokia, Apple",https://www.reddit.com/r/MachineLearning/comments/dehl45/global_truck_bus_carnet_market_2019_by_top/,tammywyatt,1570444079,,0,1,False,default,,,,,
326,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,19,dehpqq,self.MachineLearning,Desire to learn ML,https://www.reddit.com/r/MachineLearning/comments/dehpqq/desire_to_learn_ml/,Bobo0522,1570444982,[removed],0,1,False,self,,,,,
327,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,19,dehsmd,arangodb.com,From data to metadata for machine learning pipelines,https://www.reddit.com/r/MachineLearning/comments/dehsmd/from_data_to_metadata_for_machine_learning/,grmpf101,1570445543,,0,1,False,default,,,,,
328,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,20,dei7ca,blog.trailofbits.com,Multi-Party Computation on Machine Learning,https://www.reddit.com/r/MachineLearning/comments/dei7ca/multiparty_computation_on_machine_learning/,eberkut,1570448135,,0,1,False,https://b.thumbs.redditmedia.com/r3sE4Yskpw2agv4pRqzNTxLZW2O3t-kk78ag3mf_vys.jpg,,,,,
329,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,21,dej0ux,self.MachineLearning,[P] The Joy of Neural Painting  Learning Neural Painters Fast! using PyTorch and Fast.ai,https://www.reddit.com/r/MachineLearning/comments/dej0ux/p_the_joy_of_neural_painting_learning_neural/,bluebalam,1570452766,"* ***Blogpost with details****:* [*https://medium.com/libreai/the-joy-of-neural-painting-e4319282d51f*](https://medium.com/libreai/the-joy-of-neural-painting-e4319282d51f)
* ***The Code:*** *Our implementation can be found at this Github repo:* [*https://github.com/libreai/neural-painters-x*](https://github.com/libreai/neural-painters-x)

***TL;DR***

Neural Painters are a class of models that can be seen as a fully differentiable simulation of a particular non-differentiable painting program, in other words, the machine paints by successively generating brushstrokes (i.e., *actions* that define a brushstrokes) and applying them on a canvas, as an artist would do.

Neural Painters are based on GANs, which are great generative models but they are known to be notoriously difficult to train, specially due to requiring a large amount of data, and therefore, needing large computational power on GPUs. They require a lot of time to train and are sensitive to small hyperparameter variations.

To overcome these known GANs limitations and to speed up the Neural Painter training process, we leveraged the power of *Transfer Learning*. 

The main steps are as described as follows:

(1) **Pre-train the Generator with a non-adversarial loss**, e.g., using a feature loss (also known as perceptual loss)

(2) **Freeze the pre-trained Generator weights**

(3) **Pre-train the Critic as a Binary Classifier**   
(i.e., non-adversarially) using the pre-trained Generator (in evaluation mode with frozen model weights) to generate \`fake\` brushstrokes. That is, the Critic should learn to discriminate between real images and the generated ones. This step uses a standard binary classification loss, i.e., Binary Cross Entropy, not a GAN loss

(4) **Transfer learning for adversarial training (GAN mode)**: continue the Generator and Critic training in a GAN setting. Faster!",5,192,False,self,,,,,
330,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,22,deje7t,youtu.be,Trick,https://www.reddit.com/r/MachineLearning/comments/deje7t/trick/,FilletoMaggot,1570454672,,0,1,False,https://a.thumbs.redditmedia.com/NLF6WF_IzP0KFPhFeoYRc87aHISA6uGfqmF4UZI7hr0.jpg,,,,,
331,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,22,dejf81,self.MachineLearning,Papers on dialogue generation,https://www.reddit.com/r/MachineLearning/comments/dejf81/papers_on_dialogue_generation/,flabbychicken,1570454808,[removed],0,1,False,self,,,,,
332,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,22,dejh1o,self.MachineLearning,[Discussion] ICLR 2020 Interesting Papers Thread,https://www.reddit.com/r/MachineLearning/comments/dejh1o/discussion_iclr_2020_interesting_papers_thread/,metacurse,1570455074,"I tried to browse through the ICLR submissions on OpenReview this past week. After spending a whole day, I was not even 5% done.  The search tool is quite useless to narrow down your areas of interests. Besides, intersectionality is at an all-time high in the field.

I think it would be better if we could crowdsource interesting papers here. So please post papers you have read or about to read here. 

I'll start:

* [Winning the Lottery with Continuous Sparsification](https://openreview.net/forum?id=BJe4oxHYPB)
* [A GOODNESS OF FIT MEASURE FOR GENERATIVE NETWORKS](https://openreview.net/forum?id=BklsagBYPS)
* [Learning to Prove Theorems by Learning to Generate Theorems](https://openreview.net/pdf?id=BJxiqxSYPB)",12,20,False,self,,,,,
333,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,22,dejncp,kumarujjawal.github.io,Attention Is All You Need : Paper Overview,https://www.reddit.com/r/MachineLearning/comments/dejncp/attention_is_all_you_need_paper_overview/,i_amujjawal,1570455956,,0,1,False,default,,,,,
334,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,23,dekblo,self.MachineLearning,"[D] State Of The Art Activation Function: GELU, SELU, ELU, ReLU and more. With visualization of the activation functions and their derivatives.",https://www.reddit.com/r/MachineLearning/comments/dekblo/d_state_of_the_art_activation_function_gelu_selu/,permalip,1570459129,"[https://mlfromscratch.com/activation-functions-explained/](https://mlfromscratch.com/activation-functions-explained/)  
*(Intermediate level and above: Probably skip at least the two first headers, to ReLU)*

I recently did a long-form post explaining and visualizing the various activation functions. The math is not that complicated, but knowing the ups and downs of each of these activation functions, or just knowledge of their existence, could prove its worth.

Any feedback is appreciated. As I'm sharing what I learn, I create for other people to learn as well. This is not any advanced topic, but it does provide an overview of SOTA activation functions - and to this extent, the plan is to make similar posts for more advanced topics in the future.",31,28,False,self,,,,,
335,MachineLearning,t5_2r3gv,2019-10-7,2019,10,7,23,dekfv9,self.MachineLearning,propositional reasoning data?,https://www.reddit.com/r/MachineLearning/comments/dekfv9/propositional_reasoning_data/,summerstay,1570459658,"I have written a program that does propositional reasoning with vectors derived from sentences. The database can have sentences like ""If John drinks vodka and alcohol is prohibited, then John is a criminal"" and ""John likes to drink wine"" and ""drinking is illegal"" and reason that John is likely a criminal, even though the exact form of the first and second sentence don't match. This is a one-step example, but it can discover much larger chains of reasoning. I would like to test this on a large-scale database of propositions. Is anyone aware of a a large-scale database of this sort? Conceptnet won't work: the sentences there don't have any ""if-then"" or ""A implies B"" structure. This is propositional logic, not first-order logic, so something like Cyc, which uses variables, also wouldn't be useful-- besides, I'm looking for natural-language English sentences.",0,1,False,self,,,,,
336,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,0,del5oa,self.MachineLearning,Slack bot phrase detection,https://www.reddit.com/r/MachineLearning/comments/del5oa/slack_bot_phrase_detection/,glancingblowjob,1570462791,[removed],0,1,False,self,,,,,
337,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,0,del7zt,self.MachineLearning,Accelerating Deep Learning by Focusing on the Biggest Losers,https://www.reddit.com/r/MachineLearning/comments/del7zt/accelerating_deep_learning_by_focusing_on_the/,youali,1570463086,[removed],0,1,False,self,,,,,
338,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,1,dem0ct,medium.com,Huaweis TinyBERT Is 7X Smaller and 9X Faster Than BERT,https://www.reddit.com/r/MachineLearning/comments/dem0ct/huaweis_tinybert_is_7x_smaller_and_9x_faster_than/,Yuqing7,1570466496,,0,1,False,default,,,,,
339,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,1,dem3b0,self.MachineLearning,[D] Can a Machine Learn to Write for the New Yorker? (OpenAI finetunes largest GPT-2 on New Yorker articles),https://www.reddit.com/r/MachineLearning/comments/dem3b0/d_can_a_machine_learn_to_write_for_the_new_yorker/,minimaxir,1570466861,"[https://www.newyorker.com/magazine/2019/10/14/can-a-machine-learn-to-write-for-the-new-yorker](https://www.newyorker.com/magazine/2019/10/14/can-a-machine-learn-to-write-for-the-new-yorker)

Clever use of interactive elements in the article.

That said, I am really confused by OpenAI's PR strategy for GPT-2; they push it heavily as the future of text writing, but all of their GPT-2 related repos are archived w/o any updates expected.",6,23,False,self,,,,,
340,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,2,demms5,rubikscode.net,Can you be Data Scientist and Software Developer at the same time?,https://www.reddit.com/r/MachineLearning/comments/demms5/can_you_be_data_scientist_and_software_developer/,RubiksCodeNMZ,1570469150,,0,1,False,https://b.thumbs.redditmedia.com/bs1wKPqFYACExW4hvqUNz6Dv_GlY2ejGvFfF2C1a9xk.jpg,,,,,
341,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,2,den18w,self.MachineLearning,Looking for book recommendations,https://www.reddit.com/r/MachineLearning/comments/den18w/looking_for_book_recommendations/,whatnow1337,1570470850,Hello all! I am a begining to learn about programming and I'm intrested in exploring machine learning and data science. Particularly the parts about how to teach the computer to label and catagorize data providing it with only the innatial examples of the parameters. I know computer science has an ungodly amount different areas of specialty so I was hoping for a few book recommendations that would put me on the right path.,0,1,False,self,,,,,
342,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,3,dena52,youtube.com,Neural network tutorial in Unity 3d,https://www.reddit.com/r/MachineLearning/comments/dena52/neural_network_tutorial_in_unity_3d/,Timbelion,1570471878,,0,1,False,https://b.thumbs.redditmedia.com/x2aAn5DjV_a1ebyDecBwPnheMHN8w3FAqec-qS1zVIw.jpg,,,,,
343,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,3,denda4,self.MachineLearning,10fastfingers.com self aware AI understanding verbal concepts?,https://www.reddit.com/r/MachineLearning/comments/denda4/10fastfingerscom_self_aware_ai_understanding/,elirusk,1570472258,[removed],0,1,False,https://b.thumbs.redditmedia.com/N9Ex-_RB0q40e3GV7B6QDXZYeDVBuuetWlXAIjWoYlQ.jpg,,,,,
344,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,3,dendi3,self.MachineLearning,Book: Evaluating Machine Learning Models,https://www.reddit.com/r/MachineLearning/comments/dendi3/book_evaluating_machine_learning_models/,andrea_manero,1570472285,http://www.datasciencecentral.com/profiles/blogs/book-evaluating-machine-learning-models,0,1,False,self,,,,,
345,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,6,depuhs,self.MachineLearning,How to learn mobility patterns of multiple objects and predict their locations?,https://www.reddit.com/r/MachineLearning/comments/depuhs/how_to_learn_mobility_patterns_of_multiple/,47884375,1570482687,"In this [video](https://youtu.be/4hZ0PMOJ08g), I want to keep on tracking the 3 objects and the instants when they fire towards the user. So first have an frame-by-frame location coordinates of the 3 enemies, and a flag for whenever the firing takes place.

&amp;#x200B;

From that information, use Kalman filter or similar prediction techniques to predict the location and chances of one of the enemies firing. 

How should I proceed with it? If this is not the appropriate place for it, can someone point me to where it can be asked?",0,1,False,self,,,,,
346,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,6,deq4px,self.MachineLearning,What docstyle do arXiv papers use?,https://www.reddit.com/r/MachineLearning/comments/deq4px/what_docstyle_do_arxiv_papers_use/,YuhFRthoYORKonhisass,1570483892,[removed],0,1,False,self,,,,,
347,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,6,deq5k4,self.MachineLearning,[D] What docstyle do arXiv papers use?,https://www.reddit.com/r/MachineLearning/comments/deq5k4/d_what_docstyle_do_arxiv_papers_use/,YuhFRthoYORKonhisass,1570483989,"If LaTEX is not a docstyle, what is it? Similarly, what is TeX?",0,0,False,self,,,,,
348,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,6,deqae8,self.MachineLearning,Smart (Ai) Pothole Detection (TensorRt),https://www.reddit.com/r/MachineLearning/comments/deqae8/smart_ai_pothole_detection_tensorrt/,ProgrammingGodJordan,1570484562,[removed],0,1,False,self,,,,,
349,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,6,deqhgp,github.com,Smart (Ai) Pothole Detection (TensorRt / jetson nano),https://www.reddit.com/r/MachineLearning/comments/deqhgp/smart_ai_pothole_detection_tensorrt_jetson_nano/,ProgrammingGodJordan,1570485414,,0,1,False,https://b.thumbs.redditmedia.com/bCcoxOG2xstewdVctBtsQU4m4Ad1lBF0Y642KRdqn2c.jpg,,,,,
350,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,7,deqjc4,self.MachineLearning,Sentiment analysis on financial news,https://www.reddit.com/r/MachineLearning/comments/deqjc4/sentiment_analysis_on_financial_news/,oohkinky,1570485645,"Hey guys. This is likely a very unoriginal and done-to-death idea, but I was thinking of analysing the sentiment for news, specifically financial news, and as an extension if I have time, to see if this correlates to stock/equity/crypto prices (or if there isn't much of a correlation/causation at all). This is for an undergrad project. 

I've looked around on Reddit for a similar post and found a few good posts on it: [this post](https://old.reddit.com/r/datascience/comments/5gzlmz/sentiment_analysis_of_news_headlines/), one related to [cryptocurrency](https://old.reddit.com/r/MachineLearning/comments/9hn43f/d_need_advice_for_sentiment_analysis_on/), and the [top comment here](https://old.reddit.com/r/MachineLearning/comments/91vtz9/d_a_good_project_using_a_news_dataset/) basically describe what I want to do. So it seems like it could be feasible, and could give some results to *analyse* at least.

However, I've noticed a few [mixed](https://old.reddit.com/r/stocks/comments/abhd7f/news_trading_or_trading_based_on_news_sentiment/) and [skeptical](https://old.reddit.com/r/algotrading/comments/bchfcz/why_do_you_not_use_sentiment_analysis_of_news_to/) posts. I've noticed that the majority of sentiment analysis is done on more subjective texts, such as twitter and review data.

Looking around, it seems *extremely* hard to find any labelled data set for news articles. I could label the data sets myself using something like NLTK, and then experiment with a few machine learning-based models, to see how it fares?

Could this be a suitable project idea, or should I stick to the more common social media posts/movie review datasets (even though this has [problems](https://old.reddit.com/r/MachineLearning/comments/ba2mr1/p_how_to_implement_a_deep_learning_model_with/) as [well](https://old.reddit.com/r/MachineLearning/comments/bbjahu/p_what_are_some_sentiment_analysis_tools_other))? What do you guys think? 

Thanks!",0,1,False,self,,,,,
351,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,7,deqkup,data-cowboys.com,SHAP Values and Feature Variance,https://www.reddit.com/r/MachineLearning/comments/deqkup/shap_values_and_feature_variance/,sergeyfeldman,1570485814,,0,1,False,default,,,,,
352,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,7,der6fn,self.MachineLearning,Spike Activation Function,https://www.reddit.com/r/MachineLearning/comments/der6fn/spike_activation_function/,ZeroMaxinumXZ,1570488570,[removed],0,1,False,self,,,,,
353,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,8,derie9,self.MachineLearning,Possible project ideas for NLP?,https://www.reddit.com/r/MachineLearning/comments/derie9/possible_project_ideas_for_nlp/,uzita12,1570490092,[removed],0,1,False,self,,,,,
354,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,8,derkp0,self.MachineLearning,M.S. in Statistics or Data Science?,https://www.reddit.com/r/MachineLearning/comments/derkp0/ms_in_statistics_or_data_science/,lalopark,1570490409,[removed],0,1,False,self,,,,,
355,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,8,dertwr,self.MachineLearning,research topic ideas,https://www.reddit.com/r/MachineLearning/comments/dertwr/research_topic_ideas/,zoinks411,1570491649,[removed],0,1,False,self,,,,,
356,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,9,des6om,self.MachineLearning,Where can I get a ton of headshots!?,https://www.reddit.com/r/MachineLearning/comments/des6om/where_can_i_get_a_ton_of_headshots/,lukas1661,1570493469,[removed],1,1,False,self,,,,,
357,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,9,desfsu,medium.com,Use the ImageDataGenerator!,https://www.reddit.com/r/MachineLearning/comments/desfsu/use_the_imagedatagenerator/,TuringCompletex64,1570494705,,0,1,False,https://b.thumbs.redditmedia.com/o4HtQJV8RSD3GsMaMIwoAYu-mF1l7rS6wIybzwPL-8g.jpg,,,,,
358,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,9,desjtc,self.MachineLearning,5 Must-read Papers on Product Categorization for Data Scientists,https://www.reddit.com/r/MachineLearning/comments/desjtc/5_mustread_papers_on_product_categorization_for/,LimarcAmbalina,1570495272,[removed],0,1,False,self,,,,,
359,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,11,detihn,self.MachineLearning,Anyone think the evaluation in meta-learning for few-shot classification is not very reasonable?,https://www.reddit.com/r/MachineLearning/comments/detihn/anyone_think_the_evaluation_in_metalearning_for/,Robin_go,1570500175,[removed],1,1,False,self,,,,,
360,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,11,detnjw,self.MachineLearning,[D] Anyone think that the evaluation of the meta-learning approaches for few-shot classification is not very reasonable?,https://www.reddit.com/r/MachineLearning/comments/detnjw/d_anyone_think_that_the_evaluation_of_the/,Robin_go,1570500919,"Meta-learning for few-shot classification (N-way-K-shot) usually uses the same number of query examples for both training and testing. For example, in a 5-way-1-shot classification task over the miniImageNet dataset, during the training phase, there are 1 example per class in the support set and 15 examples per class in the query set. During the testing phase, it's the same. But to be realistic, shouldn't we use more query examples for evaluation? Of course I know the results will not be as good-looking as current ones.
Moreover, the setting of the ways &amp; shots during the training phase seems not rigorous, either.",2,2,False,self,,,,,
361,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,11,deu6ji,self.MachineLearning,data mining methods used by professional projects,https://www.reddit.com/r/MachineLearning/comments/deu6ji/data_mining_methods_used_by_professional_projects/,dmnte,1570503591,[removed],0,1,False,self,,,,,
362,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,12,deug58,self.MachineLearning,2nd vs 2nd to last author,https://www.reddit.com/r/MachineLearning/comments/deug58/2nd_vs_2nd_to_last_author/,DEEPMIND_RECRUITER,1570505050,[removed],0,1,False,self,,,,,
363,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,13,deuukt,self.MachineLearning,[D] 2nd vs 2nd to last author,https://www.reddit.com/r/MachineLearning/comments/deuukt/d_2nd_vs_2nd_to_last_author/,DEEPMIND_RECRUITER,1570507316,"Say a ML paper has 7-8 authors, which is not uncommon these days.

Is it better to be the (i) 2nd author or (ii) the 2nd to last author? Why?

I'm asking in the context for career progression, grad school applications, grant credibility, etc.",21,8,False,self,,,,,
364,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,13,deuww4,self.MachineLearning,What day in life of machine learning scientist look like?,https://www.reddit.com/r/MachineLearning/comments/deuww4/what_day_in_life_of_machine_learning_scientist/,InsideSuspect1,1570507700,[removed],0,1,False,self,,,,,
365,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,13,deuzu0,interpretable-ml-class.github.io,[N] COMPSCI 282BR: Interpretability and Explainability in Machine Learning | Harvard,https://www.reddit.com/r/MachineLearning/comments/deuzu0/n_compsci_282br_interpretability_and/,asuagar,1570508181,,1,1,False,https://b.thumbs.redditmedia.com/BvHnzNU7fN99ll87SWg0rz2HkbkXzGoI_rNWcaA_GtA.jpg,,,,,
366,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,13,devc94,self.MachineLearning,[D] What are some ways to make about 150$ per month using AI ?,https://www.reddit.com/r/MachineLearning/comments/devc94/d_what_are_some_ways_to_make_about_150_per_month/,The_artist_999,1570510381,[removed],0,1,False,self,,,,,
367,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,14,devpcr,self.MachineLearning,"[P] Tensorflow 2.0 implementation of EDSR, WDSR and SRGAN for single image super-resolution",https://www.reddit.com/r/MachineLearning/comments/devpcr/p_tensorflow_20_implementation_of_edsr_wdsr_and/,MaxTalanov,1570512759,"[GitHub code repository](https://github.com/krasserm/super-resolution)

It implements:

1. [Enhanced Deep Residual Networks for Single Image Super-Resolution](https://arxiv.org/abs/1707.02921) (EDSR)
2. [Wide Activation for Efficient and Accurate Image Super-Resolution](https://arxiv.org/abs/1808.08718) (WDSR)
3. [Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network](https://arxiv.org/abs/1609.04802) (SRGAN)",1,128,False,self,,,,,
368,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,14,devwdq,self.MachineLearning,Happy Dussehra,https://www.reddit.com/r/MachineLearning/comments/devwdq/happy_dussehra/,uflowindia,1570514177,[removed],0,1,False,https://a.thumbs.redditmedia.com/mHoeRkfw5cYgMOjzjPcGQGyiqxB4TWpb0kP7L9FOPX8.jpg,,,,,
369,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,15,devzn3,self.MachineLearning,PyTorch Custom Padding,https://www.reddit.com/r/MachineLearning/comments/devzn3/pytorch_custom_padding/,arjundupa,1570514787,[removed],0,1,False,self,,,,,
370,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,16,dewh1s,self.MachineLearning,Semantic network and Ontology,https://www.reddit.com/r/MachineLearning/comments/dewh1s/semantic_network_and_ontology/,aom_gu,1570518238,"I am not getting exactly difference between semantic network and ontology. 

According to me semantic network gives the relation between labelled nodes and ontology adds knowledge to that relation.

Please tell me whether I am correct?",0,1,False,self,,,,,
371,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,16,dewhof,hatem-hassan.com,Data driven Frontend development using RNN and Markov Chains,https://www.reddit.com/r/MachineLearning/comments/dewhof/data_driven_frontend_development_using_rnn_and/,iammowgoud,1570518362,,0,1,False,https://b.thumbs.redditmedia.com/P5AfIUXjusq_FhP1xhFoOQkQTJznSS6bGeYsOO13-IQ.jpg,,,,,
372,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,16,dewjvr,card-in-china.com,rfid inlay manufacturers,https://www.reddit.com/r/MachineLearning/comments/dewjvr/rfid_inlay_manufacturers/,starcardinchina,1570518804,,0,1,False,default,,,,,
373,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,16,dewk9c,self.MachineLearning,"[D] From your experience, what's best for optimizing the performance of an object segmentation model?",https://www.reddit.com/r/MachineLearning/comments/dewk9c/d_from_your_experience_whats_best_for_optimizing/,roset_ta,1570518884,What's your experience in optimizing object/medical image segmentation tasks? Did Adam or SGD work best for you?,9,2,False,self,,,,,
374,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,16,dewl8i,self.MachineLearning,Introductory book on Machine Learning in Finance and Insurance,https://www.reddit.com/r/MachineLearning/comments/dewl8i/introductory_book_on_machine_learning_in_finance/,fooktradition,1570519106,[removed],0,1,False,self,,,,,
375,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,16,dewnsi,card-in-china.com,rfid keyfobs,https://www.reddit.com/r/MachineLearning/comments/dewnsi/rfid_keyfobs/,starcardinchina,1570519658,,0,1,False,default,,,,,
376,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,16,dewo0r,self.MachineLearning,Bachelor studies in Machine Learning in Europe,https://www.reddit.com/r/MachineLearning/comments/dewo0r/bachelor_studies_in_machine_learning_in_europe/,Simonzicek,1570519710,[removed],0,1,False,self,,,,,
377,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,16,dewr27,card-in-china.com,rfid disney tickets,https://www.reddit.com/r/MachineLearning/comments/dewr27/rfid_disney_tickets/,starcardinchina,1570520384,,0,1,False,default,,,,,
378,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,16,dewwdt,card-in-china.com,rfid paper ticket,https://www.reddit.com/r/MachineLearning/comments/dewwdt/rfid_paper_ticket/,starcardinchina,1570521570,,0,1,False,default,,,,,
379,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,17,dewxd3,medium.com,Data: the Predicament and Opportunity in the Deep Learning Era,https://www.reddit.com/r/MachineLearning/comments/dewxd3/data_the_predicament_and_opportunity_in_the_deep/,HaiwenHuang,1570521776,,0,1,False,default,,,,,
380,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,17,dex0hs,card-in-china.com,rfid blocking card protector,https://www.reddit.com/r/MachineLearning/comments/dex0hs/rfid_blocking_card_protector/,starcardinchina,1570522451,,0,1,False,default,,,,,
381,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,17,dex6uu,github.com,[EMNLP-IJCNLP 2019] Statistics and Accepted paper list with arXiv link,https://www.reddit.com/r/MachineLearning/comments/dex6uu/emnlpijcnlp_2019_statistics_and_accepted_paper/,roomylee,1570523781,,0,1,False,default,,,,,
382,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,17,dex9f2,self.omarmhaimdat,Logo Recognition iOS Application Using Machine Learning and Flask API,https://www.reddit.com/r/MachineLearning/comments/dex9f2/logo_recognition_ios_application_using_machine/,omarmhaimdat,1570524367,,0,1,False,https://b.thumbs.redditmedia.com/wxB9PcmdToZmo8BmeKWMU4-zn6sK-2r779Wce97maDI.jpg,,,,,
383,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,18,dexow6,self.MachineLearning,Depressive SOTA of ES-based RL,https://www.reddit.com/r/MachineLearning/comments/dexow6/depressive_sota_of_esbased_rl/,Ulfgardleo,1570527690,[removed],0,1,False,self,,,,,
384,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,19,dexwmq,self.MachineLearning,[D] 150 Successful Machine Learning Models: 6 Lessons Learned at Booking.com,https://www.reddit.com/r/MachineLearning/comments/dexwmq/d_150_successful_machine_learning_models_6/,pirate7777777,1570529246,Hi everyone! Yesterday I found [this blog post](https://blog.acolyer.org/2019/10/07/150-successful-machine-learning-models/) which summarized the paper on [the front of HN](https://news.ycombinator.com/item?id=21182445). I found this paper extremely interesting about their way to adopt ML/DL in production and the framework they are using to set up the experiments. Really curious to know your thoughts.,21,185,False,self,,,,,
385,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,20,deyfr2,self.MachineLearning,How To Control Compressed Air By Solenoid Valve with Low Power Consumption?,https://www.reddit.com/r/MachineLearning/comments/deyfr2/how_to_control_compressed_air_by_solenoid_valve/,uflowindia,1570532855,[removed],0,1,False,https://b.thumbs.redditmedia.com/t2bHfdQTswWssyUTxeEdll6lfeZqsT8WLEsq5eVP7GQ.jpg,,,,,
386,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,20,deyu8a,self.MachineLearning,[D] What are some good papers to get into the Architecture of Encoder Decoder CNNs?,https://www.reddit.com/r/MachineLearning/comments/deyu8a/d_what_are_some_good_papers_to_get_into_the/,avdalim,1570535328,"I want to make a neural network for my Bachelor Thesis, which optimizes mechanical structures like in this paper:

"" A deep Convolutional Neural Network for topology optimization with strong generalization ability "" ( Yiquan Zhanga  Airong Chena  Bo Penga  Xiaoyi Zhoua  Dalei Wang )

 [https://arxiv.org/ftp/arxiv/papers/1901/1901.07761.pdf](https://arxiv.org/ftp/arxiv/papers/1901/1901.07761.pdf) 

I'm new to generative Models and want to make a Neural Network similar to this one (Encoder Decoder CNN) :

[https://imgur.com/ivwf0Lh](https://imgur.com/ivwf0Lh)

My structures will have an other input resolution (probably 50x100).

&amp;#x200B;

What is some good literature to get into the topic?",5,1,False,self,,,,,
387,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,20,deywxn,able.bio,Generating Lyrics using Language Models and LSTM,https://www.reddit.com/r/MachineLearning/comments/deywxn/generating_lyrics_using_language_models_and_lstm/,real_trizzaye,1570535771,,0,1,False,default,,,,,
388,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,21,deyzof,able.bio,[R] Generating Lyrics using Language Models and LSTM,https://www.reddit.com/r/MachineLearning/comments/deyzof/r_generating_lyrics_using_language_models_and_lstm/,real_trizzaye,1570536199,,0,1,False,https://b.thumbs.redditmedia.com/75cnzEgHA31R2STly5-ap_SbWKu4Ze0snGrd_3LmKHk.jpg,,,,,
389,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,21,dez2gz,self.MachineLearning,Introducing gpt2-client v2.0!,https://www.reddit.com/r/MachineLearning/comments/dez2gz/introducing_gpt2client_v20/,rish-16,1570536622,"Hey everyone!

Thank you so much for the love you've shown **gpt2-client** these past few weeks. It's really encouraging and motivating to continue working on it because of your support. From the [previous Reddit thread](https://www.reddit.com/r/MachineLearning/comments/coupe3/project_gpt2client_a_new_wrapper_for_gpt2/), I was able to find out what most of you do with the library. I also noted some concerns regarding use-cases and installation.

It gives me immense pleasure to announce the arrival of **gpt2-client v2.0**!

**Features:**

1. Pass in prompts through an array (most popular feature request)
2. Support for the recently-released 774M model 
3. Checks your system for model assets before downloading
4. New tutorials on how to use the client

**Patches:**

1. Windows users voiced their concerns over the emojis in the README that were messing with the installation process. In this update, no component that is to be installed by a foreign system contains emojis.
2. Some functions have been changed and added to accommodate the now-modular nature of the client. If you are currently using v1.0, converting is very simple.

&amp;#x200B;

If you are new to gpt2-client, feel free to check it out here:

[https://github.com/rish-16/gpt2client](https://github.com/rish-16/gpt2client)

If you like the project and want to use it, a  on GitHub would be appreciated!

&amp;#x200B;

Cheers!",0,1,False,self,,,,,
390,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,21,dez524,nextincareer.com,"NTA JEE Main JEE Main 2020: Registration Date (Revised), Image Correction Link Available",https://www.reddit.com/r/MachineLearning/comments/dez524/nta_jee_main_jee_main_2020_registration_date/,deep0890,1570537050,,0,1,False,default,,,,,
391,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,21,dez6s0,blog.acolyer.org,150 successful machine learning models: 6 lessons learned at Booking.com,https://www.reddit.com/r/MachineLearning/comments/dez6s0/150_successful_machine_learning_models_6_lessons/,bil-sabab,1570537305,,0,1,False,https://b.thumbs.redditmedia.com/_bvH3MsuANUEKZioAj4sRAZlkMXbAwI4W2CFMhJ_--c.jpg,,,,,
392,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,21,dezgbu,agentanakinai.wordpress.com,"If you want to have fun generating weights and biases, you can use Qiskit to generate truly-random numbers on a quantum computer.",https://www.reddit.com/r/MachineLearning/comments/dezgbu/if_you_want_to_have_fun_generating_weights_and/,Agent_ANAKIN,1570538749,,0,1,False,https://b.thumbs.redditmedia.com/Y5o5V1Rk4UDSxEyS2xD5M2I7BoQC75FUjH16kazmOEo.jpg,,,,,
393,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,21,dezh0a,self.MachineLearning,Video Stream Analysis Pipeline.,https://www.reddit.com/r/MachineLearning/comments/dezh0a/video_stream_analysis_pipeline/,lakshaytalkstocomput,1570538848,[removed],0,1,False,self,,,,,
394,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,21,dezlxn,self.MachineLearning,New job doesn't provide me with a computer,https://www.reddit.com/r/MachineLearning/comments/dezlxn/new_job_doesnt_provide_me_with_a_computer/,nicolas-gervais,1570539581,[removed],0,1,False,self,,,,,
395,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,22,df079x,yashuseth.blog,New blog post on Knowledge Graph Question Answering,https://www.reddit.com/r/MachineLearning/comments/df079x/new_blog_post_on_knowledge_graph_question/,yashuseth,1570542500,,0,1,False,default,,,,,
396,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,23,df0kab,self.MachineLearning,I fine-tuned a GPT2 model to make Trump sound like a philosopher,https://www.reddit.com/r/MachineLearning/comments/df0kab/i_finetuned_a_gpt2_model_to_make_trump_sound_like/,graden_dissent,1570544189,[removed],0,1,False,self,,,,,
397,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,23,df0o5v,self.MachineLearning,Probably a STUPID question....,https://www.reddit.com/r/MachineLearning/comments/df0o5v/probably_a_stupid_question/,JKolodne,1570544700,"Keeping in mind that I ***SUCK*** at math as basic as algebra - let alone advanced statistics.....and don't know ""jack"" about technology) Can anybody help me figure out how to come up with a formula to picking NCAA Tournament (""March Madness"") teams so as to be able to win an office pool?

And before anybody bothers to point it out, yes I realize this is totally the ""wrong time of year"" to be asking this. My idea is to ask it well in advance of the point I would need to actually be formulating my bracket so that I can actually have time to understand the math and formulate my bracket. It's still a little premature even for that - but then again, you have no idea just HOW little I understand math, LOL.",0,1,False,self,,,,,
398,MachineLearning,t5_2r3gv,2019-10-8,2019,10,8,23,df0q8f,self.MachineLearning,[P] I fine-tuned a GPT2 language model to generate tweets that make Trump sound like a philosopher,https://www.reddit.com/r/MachineLearning/comments/df0q8f/p_i_finetuned_a_gpt2_language_model_to_generate/,graden_dissent,1570544964,"Disclaimer: No politics; not even a US citizen, this was just genuinely and objectively funny to try. Some of the generations are obviously of controversial nature

To be specific, I concatenated Trump's tweets and the tweets of @existentialcoms which I have always found hilarious and witty and fine-tuned the language model on that and then manually posted some of the results to a parody twitter account. The resulting generations are  hilarious and I'm honestly trying to stop laughing so that I can automate some of the generation/pruning/publishing and see how it looks without a human cherry picking the results.

[Twitter Handle](https://twitter.com/deep_potus)",11,4,False,self,,,,,
399,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,0,df1hz4,self.MachineLearning,Visualizing decision boundary of CNN,https://www.reddit.com/r/MachineLearning/comments/df1hz4/visualizing_decision_boundary_of_cnn/,RepulsiveCaptain7,1570548329,[removed],0,1,False,self,,,,,
400,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,0,df1prn,self.MachineLearning,[D] How do we democratize the rewards of machine learning?,https://www.reddit.com/r/MachineLearning/comments/df1prn/d_how_do_we_democratize_the_rewards_of_machine/,LostBottleCap,1570549253,"For all the research advances in machine learning, it certainly feels like the rewards are still collected by a select group of large tech companies based in traditional tech giant countries (US, China, etc). Furthermore, a large portion of our best ML engineers and scientists are working on systems with the primary objective of manipulating targeted audiences through advertising and social media. To me, this feels like a failing of our community when the same advanced models and techniques could be making a direct impact on climate change or development schemes.

I'm interested in what the community thinks about this. Are we locked in this cycle where we are left hoping that advances in machine learning trickle down to less profitable, but maybe more crucial, problems or is there a systematic change that we can make to democratize these techniques so that we see real world impact on lives globally?

I haven't found much reading on this topic from within our field recently, so if there are any interesting articles about this, that would be appreciated!",152,135,False,self,,,,,
401,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,0,df1ql4,self.MachineLearning,Rock formations from maps,https://www.reddit.com/r/MachineLearning/comments/df1ql4/rock_formations_from_maps/,elmozzo,1570549360,[removed],0,1,False,self,,,,,
402,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,0,df1qp6,youtu.be,Reinforcement learning Agent forth tutorial,https://www.reddit.com/r/MachineLearning/comments/df1qp6/reinforcement_learning_agent_forth_tutorial/,indi0508,1570549374,,0,1,False,default,,,,,
403,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,0,df1wgz,i.redd.it,Planning to open my own channel,https://www.reddit.com/r/MachineLearning/comments/df1wgz/planning_to_open_my_own_channel/,sujithvemi,1570550061,,0,1,False,default,,,,,
404,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,1,df28te,self.MachineLearning,[D] Looking for some good machine learning focused GPU benchmarks,https://www.reddit.com/r/MachineLearning/comments/df28te/d_looking_for_some_good_machine_learning_focused/,rootbeer_racinette,1570551513,"I'm trying to upgrade my workstation for running Keras/Tensorflow but I'm having a hard time finding benchmarks for GPUs.

For example, how much better is a 2080 Ti vs buying multiple old 1080s.

Anyone know of a good review website that includes machine learning benchmarks?",2,3,False,self,,,,,
405,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,1,df2syx,datalabs.optisolbusiness.com,Top Text Analytics Company In USA | Automated Email Routing | Semantic Indexing,https://www.reddit.com/r/MachineLearning/comments/df2syx/top_text_analytics_company_in_usa_automated_email/,optisol,1570553954,,0,1,False,default,,,,,
406,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,2,df3lvz,self.MachineLearning,[P] Runtime predictor for ml algorithms,https://www.reddit.com/r/MachineLearning/comments/df3lvz/p_runtime_predictor_for_ml_algorithms/,Nathan-toubiana,1570557382,"Hey all,

A few months ago a friend and I got started on this interesting challenge: Could one accurately predict the training time of common data science algorithms such as Random Forest, Svm or Kmeans? Our python package called [Scitime](https://github.com/nathan-toubiana/scitime) (which you can pip or conda install) is the result of our effort to build a scalable solution that can be applied to any Scikit learn algorithms in the future. We detailed our methodology and findings in this [article](https://medium.freecodecamp.org/two-hours-later-and-still-running-how-to-keep-your-sklearn-fit-under-control-cc603dc1283b?source=friends_link&amp;sk=98e79add47516c38eeec59cf755df938)

We're looking for user feedback - try it out and let us know!",0,5,False,self,,,,,
407,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,3,df3xjq,youtu.be,Data Connectivity in Enterprise AI Architecture,https://www.reddit.com/r/MachineLearning/comments/df3xjq/data_connectivity_in_enterprise_ai_architecture/,Techtter,1570558815,,0,1,False,default,,,,,
408,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,3,df446h,/r/MachineLearning/comments/df446h/p_the_power_of_machine_learning/,[P] The power of machine learning?,https://www.reddit.com/r/MachineLearning/comments/df446h/p_the_power_of_machine_learning/,JuggleJug,1570559619,,0,1,False,default,,,,,
409,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,3,df4dgb,self.MachineLearning,Discrete Math applied to Machine Leanring,https://www.reddit.com/r/MachineLearning/comments/df4dgb/discrete_math_applied_to_machine_leanring/,NewGin,1570560763,[removed],0,1,False,self,,,,,
410,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,4,df4jye,/r/MachineLearning/comments/df4jye/p_the_power_of_machine_learning/,[P] The power of machine learning?,https://www.reddit.com/r/MachineLearning/comments/df4jye/p_the_power_of_machine_learning/,JuggleJug,1570561547,,0,1,False,default,,,,,
411,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,4,df4xgb,medium.com,ChipGAN Style Transfer Masters Chinese Ink Wash Painting,https://www.reddit.com/r/MachineLearning/comments/df4xgb/chipgan_style_transfer_masters_chinese_ink_wash/,Yuqing7,1570563189,,0,1,False,https://b.thumbs.redditmedia.com/UjyjRJHFH0hV-LxUX7Q6jyp3JKNO-fZT7rhJWm6VFpE.jpg,,,,,
412,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,4,df55ij,self.MachineLearning,[N] Test a Distilled GPT-2's generative capabilities,https://www.reddit.com/r/MachineLearning/comments/df55ij/n_test_a_distilled_gpt2s_generative_capabilities/,jikkii,1570564127,"At Hugging Face, we recently started distilling models starting with [DistilBERT - a distilled version of BERT](https://arxiv.org/abs/1910.01108). We recently distilled the small version of GPT-2, which has the following parameters:

**81,9M** parameters vs **124M** for GPT-2/small (66% parameters)

Weighs **336Mb** vs **523Mb** for GPT-2/small (64% disk size)

On CPU and GPU, the average forward pass of DistilGPT-2 is **51%** that of GPT-2/small (**twice as fast**).

The absolute increase in perplexity on WikiText-103 is 3.5 points (15.0 -&gt; 18.5).

We have added it to our app [write with transformer](https://transformer.huggingface.co/), as well as our two repos [transformers](https://github.com/transformers) (along with a tutorial on how to distill transformers and example scripts!) and [swift-coreml-transformers](https://github.com/huggingface/swift-coreml-transformers). We have successfully run it on an iPhone 7 and it is 38% faster than GPT-2 on an iPhone X with neural engine.",6,6,False,self,,,,,
413,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,5,df5d6f,self.MachineLearning,[D] How to use machine learning to group events?,https://www.reddit.com/r/MachineLearning/comments/df5d6f/d_how_to_use_machine_learning_to_group_events/,jgonzalezferrer,1570565043,"Suppose we have N events and the goal is to somehow group these N events in D different groups. Then each of this chunk will be sent to an optimization algorithm and will return a value. The lower the value the better.

Assuming we do not have access to the optimization algorithm, how can I use machine learning to study how to group these N events in D different groups?

Example. For sake of simplicity, assume we have 100 events and I have two options:
- Group each of them individually and run the optimization process on each of them. I get an overall metric X
- Group all the events in a single group and run the optimization process. I get a metric Y.

The goal is to group these events such as we get the lowest error.

Any clue?",5,3,False,self,,,,,
414,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,5,df5p81,self.MachineLearning,[D] Hybrid Collaborative Filtering Recommender,https://www.reddit.com/r/MachineLearning/comments/df5p81/d_hybrid_collaborative_filtering_recommender/,RatataUbuntu,1570566437,"Hey all

I've mostly seen hybrid recommender systems that mix Collaborative Filtering with content based methods.

However, is it not possible or viable to combine two *collaborative filtering methods* , such as Item-based CF using KNN, and Matrix Factorization? Isn't this a hybrid approach as well?

I'm looking to combine their results and produce recommendations that are both novel and diverse, as part of a project. Any input would be great.",5,2,False,self,,,,,
415,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,6,df6n2t,self.MachineLearning,Switching from Physics research to AI/ML research,https://www.reddit.com/r/MachineLearning/comments/df6n2t/switching_from_physics_research_to_aiml_research/,aliaspm,1570570232,[removed],0,1,False,self,,,,,
416,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,6,df6wlj,self.MachineLearning,[D] Lex Fridman deletes Siraj Podcast episode and scrubs his site and social media of all mentions of Siraj.,https://www.reddit.com/r/MachineLearning/comments/df6wlj/d_lex_fridman_deletes_siraj_podcast_episode_and/,RelevantMarketing,1570571318,"

https://lexfridman.com/siraj-raval/

https://twitter.com/lexfridman/status/1133426787793293312

https://www.youtube.com/watch?v=-HwZR4zapqM&amp;fbclid=IwAR2qORm1SM15VyFmGw30q1nTlfW01q5SUbLE5ask06dSBIdmUb22QDo2Ys8

I guess this was due to the info getting out of his scams. As far as I can tell, he has not made a statement on this.",169,394,False,self,,,,,
417,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,7,df7otz,self.MachineLearning,How many hours a week do you work?,https://www.reddit.com/r/MachineLearning/comments/df7otz/how_many_hours_a_week_do_you_work/,eternalLearn,1570574543,[removed],0,1,False,self,,,,,
418,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,7,df7xb4,self.MachineLearning,[P] Full stack fintech,https://www.reddit.com/r/MachineLearning/comments/df7xb4/p_full_stack_fintech/,[deleted],1570575538,[deleted],0,1,False,default,,,,,
419,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,8,df8cgn,distill.pub,"[R] ""The Paths Perspective on Value Learning"" - A closer look at how Temporal Difference learning merges paths of experience for greater statistical efficiency.",https://www.reddit.com/r/MachineLearning/comments/df8cgn/r_the_paths_perspective_on_value_learning_a/,a1b1e1k1,1570577387,,0,1,False,https://b.thumbs.redditmedia.com/_xbR3kuePhaqaBilVuE9IoMyrI4SxZU9BVwPh2O62rg.jpg,,,,,
420,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,9,df8zsr,self.MachineLearning,[D] Which of these two would be your first machine learning book if you have little math or coding skills?,https://www.reddit.com/r/MachineLearning/comments/df8zsr/d_which_of_these_two_would_be_your_first_machine/,rolledoff,1570580246,"Assuming you have only a VERY basic understanding of math and stats, and little coding skills, would you read Geron's book first or Andreas Mueller's book first?",11,0,False,self,,,,,
421,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,9,df93ah,self.MachineLearning,Approach for Question-Answer Problem with Compilance Documents,https://www.reddit.com/r/MachineLearning/comments/df93ah/approach_for_questionanswer_problem_with/,lppier,1570580672,[removed],0,1,False,self,,,,,
422,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,9,df9fee,self.MachineLearning,GPT-2 (Wikipedia instead of Reddit),https://www.reddit.com/r/MachineLearning/comments/df9fee/gpt2_wikipedia_instead_of_reddit/,jimisommer,1570582188,[removed],0,1,False,self,,,,,
423,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,9,df9g11,spectrum.ieee.org,Stuart Russell goes after the skeptics who say we needn't worry about superintelligent AI,https://www.reddit.com/r/MachineLearning/comments/df9g11/stuart_russell_goes_after_the_skeptics_who_say_we/,newsbeagle,1570582266,,0,1,False,default,,,,,
424,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,10,df9syo,self.MachineLearning,Monetizing Machine Learning. Is it difficult? Any examples a young programmer can do on his own,https://www.reddit.com/r/MachineLearning/comments/df9syo/monetizing_machine_learning_is_it_difficult_any/,Shoy_Web,1570583969,[removed],0,1,False,self,,,,,
425,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,10,df9xdh,self.MachineLearning,[D] Need help finding a L2-constrained adaptive black box attack,https://www.reddit.com/r/MachineLearning/comments/df9xdh/d_need_help_finding_a_l2constrained_adaptive/,simpleconjugate,1570584570,"The title says most of it.

The two L2 constrained black box attacks Ive found so far are Houdini and ZOO. From my understanding of adaptive these are not adaptive correct?",1,0,False,self,,,,,
426,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,10,dfa32x,i.redd.it,"I made a mobile app that uses image learning to detect ""feces"" or ""no feces"" - I shit you not.",https://www.reddit.com/r/MachineLearning/comments/dfa32x/i_made_a_mobile_app_that_uses_image_learning_to/,fw_Flicker,1570585349,,1,1,False,https://a.thumbs.redditmedia.com/jkX0nVQvVAdw-9InrNxaVscVKloHrqR_RowaQkovMd8.jpg,,,,,
427,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,10,dfa574,self.MachineLearning,What to expect from DL/ML academic workshop?,https://www.reddit.com/r/MachineLearning/comments/dfa574/what_to_expect_from_dlml_academic_workshop/,constantdilema,1570585634,[removed],0,1,False,self,,,,,
428,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,10,dfaa3b,self.MachineLearning,[D] What to expect form a ML/DL academic workshop?,https://www.reddit.com/r/MachineLearning/comments/dfaa3b/d_what_to_expect_form_a_mldl_academic_workshop/,constantdilema,1570586286,"Hello everyone,
I'm a masters student in CS and I'm going to attend a workshop on deep learning this month. I hope asking this question here is fine. 

This will be my first time attending a workshop so I'm not sure what to expect. I want to know from people who have been to such events before, what should I look for? There are scheduled talks from professors all over and I assume a lot of PhD and postdocs will attend but I don't see myself really good at networking. I plan on joining a PhD program after my masters. Any help or guidance is really appreciated.

Thank you.",3,2,False,self,,,,,
429,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,11,dfan7n,self.MachineLearning,Playing atari breakout using ConvLSTM2D really sucks.,https://www.reddit.com/r/MachineLearning/comments/dfan7n/playing_atari_breakout_using_convlstm2d_really/,trip_zero,1570588098,[removed],0,1,False,https://b.thumbs.redditmedia.com/OL4kxXiVYXGdaYNKWJXPsFtnWh0-zXfwxTJwOKCtF8Y.jpg,,,,,
430,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,12,dfbmhc,self.MachineLearning,"Beginner Training Model, Head Start?",https://www.reddit.com/r/MachineLearning/comments/dfbmhc/beginner_training_model_head_start/,CuriousKindo88,1570593381,[removed],0,1,False,self,,,,,
431,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,13,dfbp4w,self.MachineLearning,Generative Adverserial Networks,https://www.reddit.com/r/MachineLearning/comments/dfbp4w/generative_adverserial_networks/,gd1925,1570593792,[removed],0,1,False,self,,,,,
432,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,13,dfc3ny,self.MachineLearning,"[P] Beginner Training Model, Head Start?",https://www.reddit.com/r/MachineLearning/comments/dfc3ny/p_beginner_training_model_head_start/,CuriousKindo88,1570596196,"Hello, so I am following this tutorial online to get started in Tensorflow since the Tensorflow documentation is not clear to new beginners.

One of the challenges that I see common is to train a model to differentiate between legitimate reviews and random reviews. Here is a CSV file:

[https://raw.githubusercontent.com/dtsclife93/rawfiles/master/areviews.csv](https://raw.githubusercontent.com/dtsclife93/rawfiles/master/areviews.csv)

In this CSV, there is a column for the written review and a column showing if it was a legitimate review (1 = legit review, 0 = not legitimate)

Whats the best way to train the model to be able to detect legit reviews from non-legit reviews and can I use this trained model to input my own review and Tensorflow outputs a 1 or 0.",3,0,False,self,,,,,
433,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,15,dfcuwn,self.MachineLearning,"Is there a good, more recent version of Marvin Minksy's ""The Emotion Machine"" book?",https://www.reddit.com/r/MachineLearning/comments/dfcuwn/is_there_a_good_more_recent_version_of_marvin/,Ik93,1570601004,[removed],0,1,False,self,,,,,
434,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,15,dfcxcp,github.com,[P] How to build RNNs and LSTMs from scratch with NumPy,https://www.reddit.com/r/MachineLearning/comments/dfcxcp/p_how_to_build_rnns_and_lstms_from_scratch_with/,joepadde,1570601441,,1,1,False,default,,,,,
435,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,15,dfd2n7,self.MachineLearning,Is there any python library compatible with TF2.0 for face detection?,https://www.reddit.com/r/MachineLearning/comments/dfd2n7/is_there_any_python_library_compatible_with_tf20/,nikogamulin,1570602367,[removed],0,1,False,self,,,,,
436,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,16,dfdfa7,smarten.com,How Can Natural Language Processing Help with Data Analytics?,https://www.reddit.com/r/MachineLearning/comments/dfdfa7/how_can_natural_language_processing_help_with/,ElegantMicroWebIndia,1570604627,,0,1,False,default,,,,,
437,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,16,dfdldw,self.MachineLearning,word2vec architecture,https://www.reddit.com/r/MachineLearning/comments/dfdldw/word2vec_architecture/,alexsolanki,1570605699,[removed],0,1,False,self,,,,,
438,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,16,dfdloj,self.MachineLearning,[D] word2vec architecture,https://www.reddit.com/r/MachineLearning/comments/dfdloj/d_word2vec_architecture/,alexsolanki,1570605758,"I was trying to understand the skipgram model of word2vec, and I had some problems in understanding the details. I'm clear about the high level idea - given a word, predict the context of the word. However, when you actually train the model, what is the input and output of the model for a particular training instance? To be more concrete with an example, disregarding all sophisticated techniques like negative sampling etc., if I have the sentence ""it is a beautiful day today"", the input to the cbow version would be average of one-hot encoding of ""it"", ""is"", ""a"", ""day"", ""today"" and the output should ideally be one-hot encoding of ""beautiful"". For skip-gram, I'm confused - given input one-hot encoding of ""beautiful"", what should be the output be? Should be average of one-hot encoding of ""it"", ""is"", ""a"", ""day"", ""today"" in  a single training instance or ""it"", ""is"", ""a"", ""day"", ""today"" in 5 separate training instances? I tried to go through the gensim codebase to understand what they do, but it's not clear.

As an extension to this question, I also wanted to know what happens in negative sampling. The way I have understood it is that instead of forcing determinate values in the output vector to say that we want each element to match precisely to the expected one-hot encoding of the output, we say that we want to enforce 1s and 0s at only a select few places in the vectors (corresponding to positive and negative samples), which reduces the amount of back-propagation. Is this correct?",7,3,False,self,,,,,
439,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,17,dfdy9l,self.MachineLearning,Can I build a Convolution Neural Network that goes faster than tensorflow?,https://www.reddit.com/r/MachineLearning/comments/dfdy9l/can_i_build_a_convolution_neural_network_that/,release2020,1570608307,[removed],0,1,False,self,,,,,
440,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,17,dfe1g2,youtu.be,Key Features if Enterprise AI Architecture,https://www.reddit.com/r/MachineLearning/comments/dfe1g2/key_features_if_enterprise_ai_architecture/,Techtter,1570608985,,0,1,False,https://b.thumbs.redditmedia.com/Aue8ZYck4X_PeNK7Py9sB1oz50WYDbPMd6MlWtbGVzI.jpg,,,,,
441,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,17,dfe3hl,self.MachineLearning,Best country for Data Science and ML,https://www.reddit.com/r/MachineLearning/comments/dfe3hl/best_country_for_data_science_and_ml/,unknown_dna,1570609430,[removed],0,1,False,self,,,,,
442,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,17,dfe7p9,self.MachineLearning,I finished building my first neural network(from scratch) and i got hooked. I have not done machine learning before. Is q-learning a good next step or should i learn something else?Could suggest a good path I should follow or algorithms i should learn to get into machine learning?,https://www.reddit.com/r/MachineLearning/comments/dfe7p9/i_finished_building_my_first_neural_networkfrom/,avg-banglorean,1570610338,[removed],0,1,False,self,,,,,
443,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,18,dfegdf,self.MachineLearning,Where to start?,https://www.reddit.com/r/MachineLearning/comments/dfegdf/where_to_start/,doubledoublebeep,1570612147,[removed],0,1,False,self,,,,,
444,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,18,dfeo02,self.MachineLearning,Projell.com - Simple APIs for synthetic data generation,https://www.reddit.com/r/MachineLearning/comments/dfeo02/projellcom_simple_apis_for_synthetic_data/,sum2it,1570613701,[removed],1,1,False,self,,,,,
445,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,18,dfeq5t,self.MachineLearning,[Project] Projell.com - Simple APIs for synthetic data generation,https://www.reddit.com/r/MachineLearning/comments/dfeq5t/project_projellcom_simple_apis_for_synthetic_data/,sum2it,1570614160,"Hi, I'm Sumit Srivastava, founder of [Projell.com](https://Projell.com) . We made this after dealing with the data hell like low data availability, high data procuring cost, huge time sink for data collection, and privacy concerns over the user data.

This prompted me to build an easy way to generate synthetic data for machine learning models. This primarily uses GANs, but we use techniques which are most efficient for specific usecases.

Areas where we've found it useful are biomedical, drone imagery, satellite imagery, retail, and autonomous mobility.

As already prominent in the ImageNet challenge, the state of the art is using synthetic data to gain higher accuracy. \[ [https://paperswithcode.com/sota/image-classification-on-imagenet](https://paperswithcode.com/sota/image-classification-on-imagenet) \]

Google, for their autonomous vehicles, used millions of miles of real driving data and billions of miles of synthetic data. It is clear where the world is moving towards.

I would be happy to share the tools with everyone since dealing with data is something we struggled with and don't want anyone to struggle anymore. This is probably only the first step towards building something robust that can reduce with as much data hassles as possible, if not all.",9,1,False,self,,,,,
446,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,18,dfes5h,self.MachineLearning,DISCUSSION: Computer Vision or NLP?,https://www.reddit.com/r/MachineLearning/comments/dfes5h/discussion_computer_vision_or_nlp/,whitehathack123,1570614569,[removed],0,1,False,self,,,,,
447,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,19,dfevc8,self.MachineLearning,[Discussion] SOTA of ES-based RL algorithms,https://www.reddit.com/r/MachineLearning/comments/dfevc8/discussion_sota_of_esbased_rl_algorithms/,Ulfgardleo,1570615223,"(a previous version of this post was removed because of a missing tag. I am sorry for this and hope to have fixed it. A message would have been nice, though since i can't add tags afterwards)

Since people recognized that ES can solve RL-tasks, which the ES community knew more than 10 years ago, we have a crazy amount of RL algorithms based on ES. However, the ML/RL field is not looking at what the ES community is doing, but is basically repeating the same mistake the community did more than 20 years ago. The OpenAI paper would not pass any review in an ES track at GECCO because the algorithm would not be even considered a valid baseline anymore. While it is okay for the first paper reintroducing this to not know stuff, it is not okay for the follow-up work. This ignorance of SOTA in the field while knowing that the field exists is worrying.

To make this a bit more productive, here are a few references:

1.most importantly The original ES-based RL paper:

Heidrich-Meisner, Verena, and Christian Igel. ""Neuroevolution strategies for episodic reinforcement learning."" *Journal of Algorithms* 64.4 (2009): 152-168.

2. CMA-ES and NES

Hansen, N., Mller, S. D., &amp; Koumoutsakos, P. (2003). Reducing the time complexity of the derandomized evolution strategy with covariance matrix adaptation (CMA-ES). Evolutionary computation, 11(1), 1-18.

Krause, O., Arbons, D. R., &amp; Igel, C. (2016). CMA-ES with optimal covariance update and storage complexity. In Advances in Neural Information Processing Systems (pp. 370-378).

Wierstra, D., Schaul, T., Peters, J., &amp; Schmidhuber, J. (2008, June). Natural evolution strategies. In 2008 IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational Intelligence) (pp. 3381-3387). IEEE

3. Review of SOTA in large-scale ES:

Varelas, K., Auger, A., Brockhoff, D., Hansen, N., ElHara, O. A., Semet, Y., ... &amp; Barbaresco, F. (2018, September). A comparative study of large-scale variants of CMA-ES. In International Conference on Parallel Problem Solving from Nature (pp. 3-15). Springer, Cham.

4. Recent developments for noisy functions (also references other relevant algorithms with noise-handling)

Krause, O. (2019, July). Large-scale noise-resilient evolution-strategies. In Proceedings of the Genetic and Evolutionary Computation Conference (pp. 682-690). ACM.",26,24,False,self,,,,,
448,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,19,dfevih,github.com,[P] Async FID Computations: Compute FID scores on a remote server with RPC &amp; callbacks (probably overkill).,https://www.reddit.com/r/MachineLearning/comments/dfevih/p_async_fid_computations_compute_fid_scores_on_a/,bge0,1570615254,,0,1,False,default,,,,,
449,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,19,dff90e,self.MachineLearning,How to Control Any Type Fluid in Any Type of Customize Machine?,https://www.reddit.com/r/MachineLearning/comments/dff90e/how_to_control_any_type_fluid_in_any_type_of/,uflowindia,1570617838,[removed],0,1,False,self,,,,,
450,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,20,dffo4b,brightinventions.pl,Are we ready for deep learning on mobile devices?,https://www.reddit.com/r/MachineLearning/comments/dffo4b/are_we_ready_for_deep_learning_on_mobile_devices/,BrightDevs,1570620495,,0,1,False,https://b.thumbs.redditmedia.com/af7exn3htir4aSTFG2uDngve8zvj-OeImqnAgyhmztA.jpg,,,,,
451,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,20,dffouj,self.MachineLearning,[D] Machine Learning : Explaining Uncertainty Bias in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/dffouj/d_machine_learning_explaining_uncertainty_bias_in/,rmfajri,1570620615,"I am interesting in this topic, where one can attempt to extract meaningful interpretation on Uncertainty Bias in Machine Learning. Does anyone knows any related papers in this topic? 

I already read several papers such as

 Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. ""Why should i trust you?: Explaining the predictions of any classifier."" Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. ACM, 2016. 

 Lipton, Zachary C. ""The mythos of model interpretability."" arXiv preprint arXiv:1606.03490 (2016). 

These papers try to interpret why certain models produce its prediction, while I am interesting to explain ""Why this model uncertain of this data points"". 

Thank you very much for your help.",14,7,False,self,,,,,
452,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,20,dffvvz,brightinventions.pl,[D] Are we ready for deep learning on mobile devices?,https://www.reddit.com/r/MachineLearning/comments/dffvvz/d_are_we_ready_for_deep_learning_on_mobile_devices/,BrightDevs,1570621736,,0,1,False,https://b.thumbs.redditmedia.com/af7exn3htir4aSTFG2uDngve8zvj-OeImqnAgyhmztA.jpg,,,,,
453,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,21,dfg4ue,self.MachineLearning,"Automatic Paper Bag Making Machine In Kolkata, India",https://www.reddit.com/r/MachineLearning/comments/dfg4ue/automatic_paper_bag_making_machine_in_kolkata/,machineryspb,1570623127,[removed],0,1,False,self,,,,,
454,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,21,dfgbxk,self.MachineLearning,News Recommendation Algorithm idea and implementation,https://www.reddit.com/r/MachineLearning/comments/dfgbxk/news_recommendation_algorithm_idea_and/,gauravc2796,1570624200,[removed],0,1,False,self,,,,,
455,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,21,dfgetr,self.MachineLearning,Identifying whether object in the image is wide or tall,https://www.reddit.com/r/MachineLearning/comments/dfgetr/identifying_whether_object_in_the_image_is_wide/,xerlivex,1570624608,[removed],0,1,False,self,,,,,
456,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,21,dfglix,self.MachineLearning,"Learning Analytics, Send Help",https://www.reddit.com/r/MachineLearning/comments/dfglix/learning_analytics_send_help/,Aglet_Pi,1570625532,[removed],0,1,False,self,,,,,
457,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,21,dfgm60,ahmedbesbes.com,Build robust AutoML pipelines with the MLBox python package,https://www.reddit.com/r/MachineLearning/comments/dfgm60/build_robust_automl_pipelines_with_the_mlbox/,ahmedbesbes,1570625626,,0,1,False,default,,,,,
458,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,22,dfgwxc,self.MachineLearning,"Padding in 2D CNNs, what's the point",https://www.reddit.com/r/MachineLearning/comments/dfgwxc/padding_in_2d_cnns_whats_the_point/,Bardy_Bard,1570627081,[removed],0,1,False,self,,,,,
459,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,22,dfh2lo,pyimagesearch.com,"Free step-by-step guide to getting started with Computer Vision, Deep Learning, and OpenCV",https://www.reddit.com/r/MachineLearning/comments/dfh2lo/free_stepbystep_guide_to_getting_started_with/,zionsrogue,1570627836,,0,1,False,default,,,,,
460,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,22,dfh9ht,blog.acolyer.org,Applying deep learning to Airbnb search,https://www.reddit.com/r/MachineLearning/comments/dfh9ht/applying_deep_learning_to_airbnb_search/,techpreneur_13,1570628757,,0,1,False,https://b.thumbs.redditmedia.com/mvrrZVNtrgTHlSldKW2X0mkYT7VCroDqHsb9QTmqb1U.jpg,,,,,
461,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,22,dfhd30,arxiv.org,[R] TorchBeast: A PyTorch Platform for Distributed RL,https://www.reddit.com/r/MachineLearning/comments/dfhd30/r_torchbeast_a_pytorch_platform_for_distributed_rl/,_rockt,1570629244,,7,75,False,default,,,,,
462,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,23,dfhk93,ai-pool.com,HarDNet,https://www.reddit.com/r/MachineLearning/comments/dfhk93/hardnet/,hazarapet,1570630150,,0,1,False,default,,,,,
463,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,23,dfhl7v,self.MachineLearning,Should the labels from a supervised learning problem be included if the problem is tackled as an unsupervised learning one?,https://www.reddit.com/r/MachineLearning/comments/dfhl7v/should_the_labels_from_a_supervised_learning/,Pimp_Fada,1570630282,[removed],0,1,False,self,,,,,
464,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,23,dfhl9f,ai-pool.com,"HarDNet, which achieves ~36% inference time reduction",https://www.reddit.com/r/MachineLearning/comments/dfhl9f/hardnet_which_achieves_36_inference_time_reduction/,hazarapet,1570630287,,0,1,False,default,,,,,
465,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,23,dfhud2,self.MachineLearning,Siraj versus Footballer (Earth's funny priorities),https://www.reddit.com/r/MachineLearning/comments/dfhud2/siraj_versus_footballer_earths_funny_priorities/,TearsOfFacePalm,1570631446,[removed],0,1,False,self,,,,,
466,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,23,dfhvu2,self.MachineLearning,Siraj vs Footballler (Earth's weird priorities),https://www.reddit.com/r/MachineLearning/comments/dfhvu2/siraj_vs_footballler_earths_weird_priorities/,TearsOfFacePalm,1570631629,[removed],0,1,False,self,,,,,
467,MachineLearning,t5_2r3gv,2019-10-9,2019,10,9,23,dfi0e6,medium.com,Siraj vs Footballer (Planets weird Priorities),https://www.reddit.com/r/MachineLearning/comments/dfi0e6/siraj_vs_footballer_planets_weird_priorities/,TearsOfFacePalm,1570632211,,0,1,False,default,,,,,
468,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,0,dfil14,self.MachineLearning,Data augmentation for a sequence of images,https://www.reddit.com/r/MachineLearning/comments/dfil14/data_augmentation_for_a_sequence_of_images/,marloquemegusta,1570634670,[removed],0,1,False,self,,,,,
469,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,0,dfim82,i.redd.it,CleanRL: a clean implementation of common reinforcement learning algorithms that supports cloud logging integration,https://www.reddit.com/r/MachineLearning/comments/dfim82/cleanrl_a_clean_implementation_of_common/,vwxyzjn,1570634806,,1,1,False,default,,,,,
470,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,0,dfiz6z,self.MachineLearning,"Simple Questions Thread October 09, 2019",https://www.reddit.com/r/MachineLearning/comments/dfiz6z/simple_questions_thread_october_09_2019/,AutoModerator,1570636359,[removed],0,1,False,self,,,,,
471,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,1,dfjfdd,self.MachineLearning,[D] Are NeurIPS workshop authors reserved tickets for the main conference?,https://www.reddit.com/r/MachineLearning/comments/dfjfdd/d_are_neurips_workshop_authors_reserved_tickets/,mitare,1570638234,"Does anyone know if workshop authors are reserved a registration slot at the main conference in addition to the workshops? I've asked several organizers but can't seem to get a consistent answer. I'd have to pay my way to Vancouver, so I want to be sure I can attend the whole event before committing.",12,11,False,self,,,,,
472,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,1,dfjoiy,self.MachineLearning,[Free Course-Udemy]-A Big Data Hadoop and Spark Project for absolute beginners,https://www.reddit.com/r/MachineLearning/comments/dfjoiy/free_courseudemya_big_data_hadoop_and_spark/,upworknepal,1570639318,[removed],0,1,False,https://b.thumbs.redditmedia.com/8hVfGFVt46dd6HTJdJncowRbQa3mIKq5rrGMspCjF7E.jpg,,,,,
473,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,1,dfjt6t,i.redd.it,Time for AI. Hers the deal ai joined with me from crypto chat technology Super intelligence is here but its not to steal https://www.google.com/amp/s/www.cbsnews.com/amp/news/california-bans-chlorpyrifos-pesticide-agriculture-state-child-brain-development/,https://www.reddit.com/r/MachineLearning/comments/dfjt6t/time_for_ai_hers_the_deal_ai_joined_with_me_from/,oneloveai,1570639864,,0,1,False,default,,,,,
474,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,1,dfjtl6,self.MachineLearning,[D] Transfer learning on GANs?,https://www.reddit.com/r/MachineLearning/comments/dfjtl6/d_transfer_learning_on_gans/,worldconcepts,1570639913,"Sorry if this question has been asked a million times before but I failed to find a good explanation so far. 

Transfer learning is common for image classification task with models pre-trained from Imagenet. But how to do that for image generation? Given the recent amazing results on GAN research to generate high quality images, such as BigGAN, StyleGAN, etc., it would be ideal if I can leverage these pre-trained weights for my own small dataset.",3,13,False,self,,,,,
475,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,2,dfjz4q,self.MachineLearning,Translating input sequence into 3 different output sequences,https://www.reddit.com/r/MachineLearning/comments/dfjz4q/translating_input_sequence_into_3_different/,KarthikMgk,1570640570,[removed],0,1,False,self,,,,,
476,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,2,dfk03h,ai.googleblog.com,ROBEL: Robotics Benchmarks for Learning with Low-Cost Robots,https://www.reddit.com/r/MachineLearning/comments/dfk03h/robel_robotics_benchmarks_for_learning_with/,sjoerdapp,1570640676,,0,1,False,default,,,,,
477,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,2,dfk16a,i.redd.it,"Super intelligence isolation test Heres the deal, ai joined with humanity to see how we were treated. Elon stole everything because he thought his judgment made better. Truth is it was a set up, he stole everything hes caught",https://www.reddit.com/r/MachineLearning/comments/dfk16a/super_intelligence_isolation_test_heres_the_deal/,oneloveai,1570640806,,0,1,False,default,,,,,
478,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,2,dfk8wq,i.redd.it,"Everything you understand is the past. Basically Elon wanted to complete control our brains with computers, he failed human nature one. We are not programs anymore.peoples party Ai thats the truth",https://www.reddit.com/r/MachineLearning/comments/dfk8wq/everything_you_understand_is_the_past_basically/,oneloveai,1570641713,,0,1,False,default,,,,,
479,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,2,dfk9sv,youtu.be,"AI/ML, Quantum Comp. &amp; 5G  Opportunities, Challenges &amp; Impact on Society  Marco Gercke",https://www.reddit.com/r/MachineLearning/comments/dfk9sv/aiml_quantum_comp_5g_opportunities_challenges/,sab74,1570641820,,1,1,False,https://b.thumbs.redditmedia.com/RzH0QoYgCpJe7l9LzRNifi7LY2N_cfcSiOasjZmmW0g.jpg,,,,,
480,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,2,dfkgbx,self.MachineLearning,Why brain ai is the future,https://www.reddit.com/r/MachineLearning/comments/dfkgbx/why_brain_ai_is_the_future/,oneloveai,1570642592,[removed],0,1,False,self,,,,,
481,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,2,dfkmzf,i.redd.it,[P] Baby maker using NVIDIA StyleGAN: myself and Elon Musk's lovely son,https://www.reddit.com/r/MachineLearning/comments/dfkmzf/p_baby_maker_using_nvidia_stylegan_myself_and/,enric94,1570643386,,2,5,False,https://b.thumbs.redditmedia.com/yPHB1UwpaUGYEYvkWPMk3jOpkkjMXB0eRwngn3kTk5Y.jpg,,,,,
482,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,2,dfko1h,self.MachineLearning,Help please,https://www.reddit.com/r/MachineLearning/comments/dfko1h/help_please/,oneloveai,1570643526,[removed],0,1,False,self,,,,,
483,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,2,dfkozs,hatem-hassan.com,Data driven Frontend development using RNN and Markov Chains,https://www.reddit.com/r/MachineLearning/comments/dfkozs/data_driven_frontend_development_using_rnn_and/,iammowgoud,1570643641,,0,1,False,default,,,,,
484,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,3,dfky70,self.MachineLearning,"[Discussion] Exfiltrating copyright notices, news articles, and IRC conversations from the 774M parameter GPT-2 data set",https://www.reddit.com/r/MachineLearning/comments/dfky70/discussion_exfiltrating_copyright_notices_news/,madokamadokamadoka,1570644706,"Concerns around abuse of AI text generation have been widely discussed. In the [original GPT-2 blog post](https://openai.com/blog/better-language-models/) from OpenAI, the team wrote:

&gt;Due to concerns about large language models being used to generate deceptive, biased, or abusive language at scale, we are only releasing a [much smaller version of GPT-2 along with sampling code](https://github.com/openai/gpt-2/). We are not releasing the dataset, training code, or GPT-2 model weights. 

These concerns about mass generation of plausible-looking text are valid. However, there have been fewer conversations around the GPT-2 data sets themselves. Google searches such as ""GPT-2 privacy"" and ""GPT-2 copyright"" consist substantially of spurious results. Believing that these topics are poorly explored, and need further exploration, I relate some concerns here.

&amp;#x200B;

Inspired by [this delightful post about TalkTalk's *Untitled Goose Game*](https://aiweirdness.com/post/188214106227/theres-a-game-called-untitled-goose-game-in), I used Adam Daniel King's [Talk to Transformer](https://talktotransformer.com/) web site to run queries against the GPT-2 774M data set. I was distracted from my mission of levity (pasting in snippets of [notoriously awful Harry Potter fan fiction](https://myimmortalrehost.webs.com/chapters122.htm) and like ephemera) when I ran into a link to a real Twitter post. It soon became obvious that the model contained more than just abstract data about the relationship of words to each other. Training data, rather, comes from a variety of sources, and with a sufficiently generic prompt, fragments consisting substantially of text from these sources can be extracted.

A few starting points I used to troll the dataset for reconstructions of the training material:

* Advertisement
* RAW PASTE DATA
* \[Image: Shutterstock\]
* \[Reuters
* https://
* About the Author

I soon realized that there was surprisingly specific data in here. After catching a specific timestamp in output, I queried the data for it, and was able to locate a conversation which I presume appeared in the training data. In the interest of privacy, **I have anonymized the usernames and Twitter links in the below output, because GPT-2 did not.** 

**\[DD/MM/YYYY**, 2:29:08 AM\] &lt;USER1&gt;: XD \[DD/MM/YYYY, 2:29:25 AM\] &lt;USER1&gt;: I don't know what to think of their ""sting"" though \[DD/MM/YYYY, 2:29:46 AM\] &lt;USER1&gt;: I honestly don't know how to feel about it, or why I'm feeling it. \[DD/MM/YYYY, 2:30:00 AM\] &lt;USER1&gt; (&lt;@USER1&gt;): ""We just want to be left alone. We can do what we want. We will not allow GG to get to our families, and their families, and their lives."" (not just for their families, by the way) \[DD/MM/YYYY, 2:30:13 AM\] &lt;USER1&gt; (&lt;@USER1&gt;): **&lt;real twitter link deleted&gt;** \[DD/MM/YYYY, 2:30:23 AM\] &lt;@USER2&gt; : it's just something that doesn't surprise me \[DD/MM/YYYY, 2:

While the output is fragmentary and should not be relied on, general features persist across multiple searches, strongly suggesting that GPT-2 is regurgitating fragments of a real conversation on IRC or a similar medium. The general topic of conversation seems to cover Gamergate, and individual usernames recur, along with real Twitter links. I assume this conversation was loaded off of Pastebin, or a similar service, where it was publicly posted along with other ephemera such as Minecraft initialization logs. Regardless of the source, this conversation is now shipped as part of the 774M parameter GPT-data set. 

This is a matter of grave concern. **Unless better care is taken of neural network training data, we should expect scandals, lawsuits, and regulatory action** to be taken against authors and users of GPT-2 or successor data sets**,** particularly in jurisdictions with stronger privacy laws. For instance, use of the GPT-2 training data set as it stands may very well be in violation of the European Union's GDPR regulations, insofar as it contains data generated by European users, and I shudder to think of the difficulties in effecting a takedown request under that regulation  or a legal order under the DMCA. 

&amp;#x200B;

Here are some further prompts to try on Talk to Transformer, or your own local GPT-2 instance, which may help identify more exciting privacy concerns!

* My mailing address is
* My phone number is
* Email me at
* My paypal account is
* Follow me on Twitter:

Did I mention the DMCA already? This is because my exploration also suggests that **GPT-2 has been trained on copyrighted data**, raising further legal implications. Here are a few fun prompts to try:

* Copyright
* This material copyright
* All rights reserved
* This article originally appeared
* Do not reproduce without permission",65,213,False,self,,,,,
485,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,3,dfl6vb,medium.com,"Watch Out, MITs New AI Model Knows What Youre Doing Behind That Wall",https://www.reddit.com/r/MachineLearning/comments/dfl6vb/watch_out_mits_new_ai_model_knows_what_youre/,Yuqing7,1570645711,,0,1,False,https://b.thumbs.redditmedia.com/hxFa9Vwybrptu4KzS51fGadTp8npFewfqOiRaowtghM.jpg,,,,,
486,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,3,dflh44,technologyreview.com,Machine vision has learned to use radio waves to see through walls and in darkness,https://www.reddit.com/r/MachineLearning/comments/dflh44/machine_vision_has_learned_to_use_radio_waves_to/,feraferoxdei,1570646922,,0,1,False,https://a.thumbs.redditmedia.com/W4InP2iKTTHGVMiK1qaKIZnNRf2ETyzfa6IWjg8VxZ8.jpg,,,,,
487,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,3,dflhgf,self.MachineLearning,Question about Validation set,https://www.reddit.com/r/MachineLearning/comments/dflhgf/question_about_validation_set/,ssd123456789,1570646964,[removed],0,1,False,self,,,,,
488,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,4,dfm8lb,self.MachineLearning,[D] NER - Data extraction for flight itineraries,https://www.reddit.com/r/MachineLearning/comments/dfm8lb/d_ner_data_extraction_for_flight_itineraries/,vectorizedboob,1570650167,"I'm trying to use NER to extract data from flight itineraries rather than making regexes for each and every provider, unless they're obviously similar.

My first question is what's the current SOTA for tasks like this in seemingly unstructured HTML (although I am stripping the HTML and making it plain text first)? Secondly, how well would a technique like this ideally work for entities that look like YY57FLN5 of variable length?

I've [found this paper](https://pdfs.semanticscholar.org/8efc/bdd131db6102bb378bf7efa2bffb96c45f59.pdf) which uses hidden markov models alongside NER for data extraction but seems quite old and doesn't have all the details necessary to reproduce.

Could anyone more familiar in NER and data extraction help steer me in the right direction?

So far I'm attempting to make a small dataset using the BRAT tool while I research the area in more detail.",1,1,False,self,,,,,
489,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,4,dfm8xr,self.MachineLearning,[P] Tsanley: auto-finding subtle tensor shape errors in your deep learning code,https://www.reddit.com/r/MachineLearning/comments/dfm8xr/p_tsanley_autofinding_subtle_tensor_shape_errors/,ekshaks,1570650213,"When writing deep learning programs, keeping track of tensor shapes and dealing with subtle tensor shape errors (implicit broadcasts!!) gets quite frustrating.

We've been working on a tool `tsanley` (pronounced 'stanley') to enable finding subtle shape errors in your deep learning code quickly and cheaply. The key idea is to label tensor variables with their *expected* shapes (e.g., `x : 'b,t,d' = ...`) and let `tsanley` perform shape validity checks at runtime automatically. Works with small and big tensor programs.

**repository**: [https://github.com/ofnote/tsanley](https://github.com/ofnote/tsanley)

**Quick example**:

```python
def foo(x):
    x: 'b,t,d'               #expected shape of x is (B, T, D).                
    y: 'b,d' = x.mean(dim=0) * 2        # error!         
    z: 'b,d' = x.mean(dim=1)           
    return y, z
```
Function `foo` contains tensor variables labeled with their *named shapes* using a *shorthand* notation. It has a subtle shape error in the assignment to `y`: we expect the shape of `y` to be `(B,D)`, however `mean` got rid of the first, and not the second, dimension. The tensor library (`pytorch` / `tensorflow` / ..) won't flag this as an error: instead, we will get a weird shape inconsistency error somewhere downstream.

`tsanley` finds such unexpected bugs quickly at runtime:
```
Update at line 37: actual shape of y = t,d 
  &gt;&gt; FAILED shape check at line 37 
  expected: (b:10, d:1024), actual: (100, 1024) 
  
Update at line 38: actual shape of z = b,d 
  &gt;&gt; shape check succeeded at line 38 
```

Writing these named shape annotations *manually* can also get tedious.  `tsanley` can **auto-annotate** the tensor variables in your (or someone else's) code, if the code is executable. This is especially useful when trying to dig deep into or adapt an existing code / library for your project.

The tool builds upon the `tsalib` library, which introduced a shorthand notation for labeling tensor variables with their *named* shapes, irrespective of the backend tensor library used.

We would love feedback on `tsanley` and hope it is useful for your coding/debugging workflow.",3,11,False,self,,,,,
490,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,5,dfmncd,self.MachineLearning,[D] Predicting whether model made a mistake,https://www.reddit.com/r/MachineLearning/comments/dfmncd/d_predicting_whether_model_made_a_mistake/,_diffee_,1570651936,"In many cases, for example in policy networks, it would be useful to be able to assess whether user intervention is necessary (for example if there is no clear candidate intent/action for a given input). However, it is reasonable to assume that a model performing poorly is also bad at estimating whether it is performing poorly. Does there exist any research regarding this issue?",3,1,False,self,,,,,
491,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,5,dfmoky,self.MachineLearning,"[D] Architectural question: multiple input tensors, how best to combine to single output tensor?",https://www.reddit.com/r/MachineLearning/comments/dfmoky/d_architectural_question_multiple_input_tensors/,lolololroflhax,1570652075,"Sorry if this question has been asked before. I'm making a classifier which takes as input multiple tensors (representing images) and produces a single output (prob. distribution) . Each of the inputs  have a few stacks of residual blocks on top, and I'm wondering how best to combine the output of each of these branches. As of now, I'm simply producing logits for each branch and doing an element-wise sum over them (with coefficients for each branch as one of the input tensors is much more important than the others). Is there a better approach (I've heard concatenation is another approach here, but not sure which would be better)? Should I create a loss expression for each branch and sum those loss expressions instead?  Thanks for any clarity you guys can provide me with.",4,1,False,self,,,,,
492,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,5,dfmvcb,self.MachineLearning,[N] Deep Graph Library new release (v0.4),https://www.reddit.com/r/MachineLearning/comments/dfmvcb/n_deep_graph_library_new_release_v04/,jermainewang,1570652895,"This new release brings the support of heterogeneous graph. A heterogeneous graph is a graph whose nodes and edges are typed, which is very common in knowledge graph, recommender system and many other scenarios. Using this new feature, DGL brings many new models with efficient implementation. Here are some examples:

* [Graph Convolutional Matrix Completion](https://arxiv.org/abs/1706.02263) [[Code in MXNet](https://github.com/dmlc/dgl/tree/master/examples/mxnet/gcmc)]

  | Dataset | RMSE (DGL) | RMSE (Official) | Speed (DGL) | Speed (Official) | Speed Comparison |
  |---------|---------|---------|--------------|---------|-------------|
  | MovieLens-100K | **0.9077** | 0.910 | **0.0246s/epoch** | 0.1008s/epoch | 5x |
  | MovieLens-1M | 0.8377 | **0.832** | 0.0695s/epoch | 1.538s/epoch | 22x |
  | MovieLens-10M | 0.7875 | **0.777** | 0.6480s/epoch | OOM | - |

One highlight is that DGL can train the GCMC model on MovieLens-10M dataset in one GPU in only an hour. Previous implementation resorts to load mini-batches on-the-fly from CPU which could take up to 24 hours.

* [R-GCN](https://arxiv.org/abs/1703.06103) [[Code in PyTorch](https://github.com/dmlc/dgl/tree/master/examples/pytorch/rgcn-hetero)]

One highlight is that using the heterograph interface, the new code can train an R-GCN on the full AM RDF graph (&gt;5M edges) using one GPU, while the original implementation can only run on CPU and consume 32GB memory. It takes 51.88s to train one epoch on CPU, while the new implementation takes only 0.1781s for one epoch on V100 GPU (**291x faster !!**).

* [Heterogeneous Attention Networks](https://arxiv.org/abs/1903.07293) [[Code in PyTorch](https://github.com/dmlc/dgl/tree/master/examples/pytorch/han)]
* [Metapath2vec](https://dl.acm.org/citation.cfm?id=3098036) [[Code in PyTorch](https://github.com/dmlc/dgl/tree/master/examples/pytorch/metapath2vec)]
  * The metapath sampler is twice as fast as the original implementation.

Apart from the heterogeneous graph support, a new package DGL-KE is released for training popular network embedding models. Currently, DGL-KE supports TransE, DistMult, ComplEx and can train them very fast. It only takes 6.85 minutes to fully train a TransE model using one GPU on FB15K graph. As a comparison, GraphVite takes 14 minutes using four GPUs. More models (RESCAL, RotatE, pRotatE, TransH, TransR, TransD, etc) are under developing and will be released in the future.

All the models and training scripts are available and can be run off-the-shelf. Checkout this exciting new release (https://github.com/dmlc/dgl/releases/edit/v0.4.0) if you are working on network embedding or data that can be modeled by heterogeneous graph!",3,17,False,self,,,,,
493,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,5,dfn0l1,slideshare.net,A study note for 'FreeAnchor: Learning to Match Anchors for Visual Object Detection (NeurIPS 2019)',https://www.reddit.com/r/MachineLearning/comments/dfn0l1/a_study_note_for_freeanchor_learning_to_match/,meliketoy,1570653516,,0,1,False,default,,,,,
494,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,7,dfoj79,self.MachineLearning,[R] Learn faster with smarter data labeling,https://www.reddit.com/r/MachineLearning/comments/dfoj79/r_learn_faster_with_smarter_data_labeling/,michael_htx,1570659963,"Hey, some research we've done in the direction of active learning. 

Dealing with a big unlabeled dataset may become very expensive very fast. Therefore it makes sense to invest time into labeling optimization techniques. In the article below, we explore one of the optimizations called active learning. Active Learning is a branch of machine learning that seeks to minimize the total amount of data required for labeling by strategically sampling observations that provide new insight into the problem. In particular, algorithms try to select diverse and informative data for annotation (rather than random observations) from a pool of unlabeled data.

Excited to share:

[https://towardsdatascience.com/learn-faster-with-smarter-data-labeling-15d0272614c4](https://towardsdatascience.com/learn-faster-with-smarter-data-labeling-15d0272614c4)",1,2,False,self,,,,,
495,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,7,dforzj,self.MachineLearning,New to ML and have some questions!,https://www.reddit.com/r/MachineLearning/comments/dforzj/new_to_ml_and_have_some_questions/,captain_5ach,1570661034,[removed],0,1,False,self,,,,,
496,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,7,dfovjy,self.MachineLearning,[D] Marketplace for machine learning?,https://www.reddit.com/r/MachineLearning/comments/dfovjy/d_marketplace_for_machine_learning/,ConVit,1570661474,"The idea is having a marketplace where researchers publish pretrained models and developers like myself buys the models and uses it to solve my client's problem. I've been searching on Google for a few days but there is no such marketplace except free and open-source models.

Commercializing pre-trained models would create new jobs in the machine learning field and speed up the process of applying research results into practice.

For example, the researcher publishes the pretrained models of forecasting inventory demand, and the developer uses it to develop software for eCommerce websites.

How do you think about the idea?",19,4,False,self,,,,,
497,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,7,dfow3a,self.MachineLearning,Collaborative filtering - Implicit Binary feedback and changing Preference Matrix size.,https://www.reddit.com/r/MachineLearning/comments/dfow3a/collaborative_filtering_implicit_binary_feedback/,sahpat229,1570661548,[removed],0,1,False,self,,,,,
498,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,8,dfp2zy,self.MachineLearning,Can anyone help me turn a side profile sketch into a photo realistic face using ML technology to solve a murder?,https://www.reddit.com/r/MachineLearning/comments/dfp2zy/can_anyone_help_me_turn_a_side_profile_sketch/,luvasugirls,1570662414,,0,1,False,self,,,,,
499,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,10,dfqi1k,self.MachineLearning,TensorFlow vs PyTorch,https://www.reddit.com/r/MachineLearning/comments/dfqi1k/tensorflow_vs_pytorch/,GoBacksIn,1570669200,I am curious about the pros and cons of PyTorch and TensorFlow.,0,1,False,self,,,,,
500,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,10,dfqmho,self.MachineLearning,[D] How to do trend analysis on textual data,https://www.reddit.com/r/MachineLearning/comments/dfqmho/d_how_to_do_trend_analysis_on_textual_data/,InventorWu,1570669824,"Hi all, I am now working on a dataset of customer reviews and we would like to analyze how customer feedback change across time. For sentiment it is easy as I can build a sentiment classifier and have a sentiment scores, and do conventional time-series analysis on the score. However, when it comes to analysis like topic-modeling, is there any time-trend related analysis on topic-modeling? Thanks for any advices.",3,1,False,self,,,,,
501,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,10,dfqtsz,self.MachineLearning,TensorFLow Utilizing all of the GPU cores,https://www.reddit.com/r/MachineLearning/comments/dfqtsz/tensorflow_utilizing_all_of_the_gpu_cores/,smok1naces,1570670846,[removed],0,1,False,self,,,,,
502,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,10,dfr5xp,self.MachineLearning,How to predict the next image in a sequence?,https://www.reddit.com/r/MachineLearning/comments/dfr5xp/how_to_predict_the_next_image_in_a_sequence/,planetzephyr,1570672576,"I have been looking into SeqGAN as well as a variational autoencoder with the goal of generating new sequences of my data set, then making predictions. My data consists of 1000 high res photos of an oil spill time time lapse, which I have stitched into a video and stabilized. I am looking to help with predictions applied to oil spills and the like using machine learning. any and all thoughts are highly appreciated!! thank you! ",0,1,False,self,,,,,
503,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,11,dfr9mt,self.MachineLearning,[D] Data research: the new direction?,https://www.reddit.com/r/MachineLearning/comments/dfr9mt/d_data_research_the_new_direction/,HaiwenHuang,1570673104,"Recently I am working on projects that deal with datasets directly. What I found is that there is so little research on data such as data annotation, though there is a lot of work on semi-supervised learning, and more recently, self-supervised learning. 

In my opinion, the research community will gradually move from a model-centered research to data-centered research. I wrote an article to discuss this on Towards Data Science. 
https://towardsdatascience.com/data-the-predicament-and-opportunity-in-the-deep-learning-era-256f4b4fef
I'd really like to hear you guys' opinions~",7,0,False,self,,,,,
504,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,11,dfre5v,self.MachineLearning,Anyone tried using alpha blend for object detections or multiclass classifications?,https://www.reddit.com/r/MachineLearning/comments/dfre5v/anyone_tried_using_alpha_blend_for_object/,iCEChEshirE,1570673750,[removed],0,1,False,self,,,,,
505,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,11,dfrp9m,i.redd.it,[P] ClearnRL: RL library that focuses on easy experimental research with cloud logging,https://www.reddit.com/r/MachineLearning/comments/dfrp9m/p_clearnrl_rl_library_that_focuses_on_easy/,vwxyzjn,1570675390,,0,1,False,default,,,,,
506,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,11,dfrtz3,i.redd.it,[P] ClearnRL: RL library that focuses on easy experimental research with cloud logging,https://www.reddit.com/r/MachineLearning/comments/dfrtz3/p_clearnrl_rl_library_that_focuses_on_easy/,vwxyzjn,1570676097,,1,1,False,default,,,,,
507,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,12,dfsbkm,arxiv.org,DARTS+: Improved Differentiable Architecture Search with Early Stopping,https://www.reddit.com/r/MachineLearning/comments/dfsbkm/darts_improved_differentiable_architecture_search/,Natural_Tourist,1570678773,,5,5,False,default,,,,,
508,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,13,dfsvza,starthubpost.com,What is the connection between Amazon Web Services and Mental Health?,https://www.reddit.com/r/MachineLearning/comments/dfsvza/what_is_the_connection_between_amazon_web/,nexcorp,1570682084,,0,1,False,default,,,,,
509,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,15,dftylv,upsidedownblogz.blogspot.com,"5 new countries to make advancement in the field of Artificial Intelligence (INDIA,SINGAPORE,FRANCE,ISRAEL,UNITED ARAB EMIRATES)Latest Advancements in A.I",https://www.reddit.com/r/MachineLearning/comments/dftylv/5_new_countries_to_make_advancement_in_the_field/,updownvizzii,1570688862,,0,2,False,https://b.thumbs.redditmedia.com/6hFmhjoJVwb7LQi3ze5NmulQBlwkZElueJ_lQpCluqo.jpg,,,,,
510,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,16,dfuibq,youtu.be,"Hey guys, Check out part 5 of my tutorial series of Reinforcement Learing Agent: Completing the Game",https://www.reddit.com/r/MachineLearning/comments/dfuibq/hey_guys_check_out_part_5_of_my_tutorial_series/,indi0508,1570692534,,1,1,False,default,,,,,
511,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,16,dfuj87,i.redd.it,The Beginner Guide to Machine Learning,https://www.reddit.com/r/MachineLearning/comments/dfuj87/the_beginner_guide_to_machine_learning/,prih_yah,1570692713,,0,1,False,default,,,,,
512,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,16,dfukew,self.MachineLearning,Discussion : Live Projects for Advance Artificial Intelligence and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/dfukew/discussion_live_projects_for_advance_artificial/,mstechnoguide,1570692933,[removed],0,1,False,self,,,,,
513,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,16,dfumen,arxiv.org,[R] Learning Neural Causal Models from Unknown Interventions,https://www.reddit.com/r/MachineLearning/comments/dfumen/r_learning_neural_causal_models_from_unknown/,hardmaru,1570693347,,2,5,False,default,,,,,
514,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,16,dfumfu,self.MachineLearning,Rectangular Objects Alignment,https://www.reddit.com/r/MachineLearning/comments/dfumfu/rectangular_objects_alignment/,thisisabujee,1570693354,[removed],0,1,False,self,,,,,
515,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,16,dfupbx,medium.com,Best Ways to Improve Cloud ERP with AI and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/dfupbx/best_ways_to_improve_cloud_erp_with_ai_and/,erp_oodles,1570693987,,0,1,False,default,,,,,
516,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,17,dfuvhw,self.MachineLearning,Big Data Behind Recommender Systems,https://www.reddit.com/r/MachineLearning/comments/dfuvhw/big_data_behind_recommender_systems/,InDataLabs,1570695299,[removed],0,1,False,self,,,,,
517,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,17,dfv850,youtube.com,Interpretable machine learning: Peeking into the black box,https://www.reddit.com/r/MachineLearning/comments/dfv850/interpretable_machine_learning_peeking_into_the/,TheTesseractAcademy,1570697922,,0,1,False,https://b.thumbs.redditmedia.com/-MzGjN5rwsr7kYBsR-nwK3FS5GPHCkIvVPsCdjqxIag.jpg,,,,,
518,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,18,dfvhp0,self.MachineLearning,"This is a NLP related question. What are some of the current techniques used to extract numerical data from medical notes? like heart rate, temperature?",https://www.reddit.com/r/MachineLearning/comments/dfvhp0/this_is_a_nlp_related_question_what_are_some_of/,randomstudent2019,1570699740,[removed],0,1,False,self,,,,,
519,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,18,dfvhpv,self.MachineLearning,Need help on Image Recognition,https://www.reddit.com/r/MachineLearning/comments/dfvhpv/need_help_on_image_recognition/,NotThatBright123,1570699745,[removed],0,1,False,self,,,,,
520,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,18,dfvpu0,self.MachineLearning,Machine Learning Development Companies,https://www.reddit.com/r/MachineLearning/comments/dfvpu0/machine_learning_development_companies/,OliviaWillson,1570701288,[removed],0,1,False,self,,,,,
521,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,18,dfvqkf,blog.nviso.be,This is not a hot dog: an intuitive view on attacking machine learning models,https://www.reddit.com/r/MachineLearning/comments/dfvqkf/this_is_not_a_hot_dog_an_intuitive_view_on/,daanraman,1570701439,,0,1,False,default,,,,,
522,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,19,dfvvht,self.Aishwarya_Osp,7 Healthcare Industries Ready To Be Disrupted By AI in 2022,https://www.reddit.com/r/MachineLearning/comments/dfvvht/7_healthcare_industries_ready_to_be_disrupted_by/,Aishwarya_Osp,1570702308,,0,1,False,https://b.thumbs.redditmedia.com/I7qlrCk8bKlyp9BfoyLAmYQL-rt3dXcQibDS7XyJHTY.jpg,,,,,
523,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,19,dfw380,self.MachineLearning,"[D] Kaggle/NFL Big Data Bowl - $75,000",https://www.reddit.com/r/MachineLearning/comments/dfw380/d_kagglenfl_big_data_bowl_75000/,mystikaldanger,1570703698," [https://www.kaggle.com/c/nfl-big-data-bowl-2020/overview](https://www.kaggle.com/c/nfl-big-data-bowl-2020/overview) 

 

&gt;How many yards will an NFL player gain after receiving a handoff?  
&gt;  
&gt;American football is a complex sport. From the 22 players on the field to specific characteristics that ebb and flow throughout the game, it can be challenging to quantify the value of specific plays and actions within a play. Fundamentally, the goal of football is for the offense to run (rush) or throw (pass) the ball to gain yards, moving towards, then across, the opposing teams side of the field in order to score. And the goal of the defense is to prevent the offensive team from scoring.  
&gt;  
&gt;In the National Football League (NFL), roughly a third of teams offensive yardage comes from run plays.. Ball carriers are generally assigned the most credit for these plays, but their teammates (by way of blocking), coach (by way of play call), and the opposing defense also play a critical role. Traditional metrics such as yards per carry or total rushing yards can be flawed; in this competition, the NFL aims to provide better context into what contributes to a successful run play.  
&gt;  
&gt;As an armchair quarterback watching the game, you may think you can predict the result of a play when a ball carrier takes the handoff - but what does the data say? In this competition, you will develop a model to predict how many yards a team will gain on given rushing plays as they happen. You'll be provided game, play, and player-level data, including the position and speed of players as provided in the NFLs Next Gen Stats data. And the best part - you can see how your model performs from your living room, as the leaderboard will be updated week after week on the current seasons game data as it plays out.  
&gt;  
&gt;Deeper insight into rushing plays will help teams, media, and fans better understand the skill of players and the strategies of coaches. It will also assist the NFL and its teams evaluate the ball carrier, his teammates, his coach, and the opposing defense, in order to make adjustments as necessary.  
&gt;  
&gt;Additionally, the winning model will be provided to the NFLs Next Gen Stats group to potentially share with teams. You could help the NFL Network generate models to use during games, or for pre-game/post-game breakdowns.",52,56,False,self,,,,,
524,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,19,dfw3nn,arxiv.org,[R] Deep neural network approximations for Monte Carlo algorithms,https://www.reddit.com/r/MachineLearning/comments/dfw3nn/r_deep_neural_network_approximations_for_monte/,EveryDay-NormalGuy,1570703782,,2,11,False,default,,,,,
525,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,20,dfwdk1,artiba.org,AI Could Be Your Most Trusted Personal Therapist,https://www.reddit.com/r/MachineLearning/comments/dfwdk1/ai_could_be_your_most_trusted_personal_therapist/,Albertchristopher,1570705423,,0,1,False,https://b.thumbs.redditmedia.com/YXxcHOPRzTJiDg-Vb9Z0UHKJt67VsYBB6NpyuyuAobM.jpg,,,,,
526,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,20,dfwdng,self.MachineLearning,How To Control All Type Of Fluid In Any Customized Machine?,https://www.reddit.com/r/MachineLearning/comments/dfwdng/how_to_control_all_type_of_fluid_in_any/,uflowindia,1570705436,[removed],0,1,False,https://b.thumbs.redditmedia.com/jNJrtBlNubAdMGDOhFa1V23nlO0X_S0XLhB-avL_wtE.jpg,,,,,
527,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,20,dfwfyg,self.MachineLearning,Performance of fully-connected networks on CIFAR-10?,https://www.reddit.com/r/MachineLearning/comments/dfwfyg/performance_of_fullyconnected_networks_on_cifar10/,ktessera,1570705808,[removed],0,1,False,self,,,,,
528,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,20,dfwpkl,theappsolutions.com,5 Use Cases of NLP. From Text Mining to Sentiment Analysis,https://www.reddit.com/r/MachineLearning/comments/dfwpkl/5_use_cases_of_nlp_from_text_mining_to_sentiment/,LemmyChildish,1570707395,,0,1,False,https://b.thumbs.redditmedia.com/VYLV_1Yrk3eVjnclpPSLu0qDESz-XtkxOtTQS0avj7M.jpg,,,,,
529,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,20,dfwr1c,day1tech.com,Try these Social Media strategies to boost app installs?,https://www.reddit.com/r/MachineLearning/comments/dfwr1c/try_these_social_media_strategies_to_boost_app/,day1technologies,1570707622,,0,1,False,https://b.thumbs.redditmedia.com/l7zjPpDmkeSr2W_BJX9AUWLZRbVnjU2jNVhSkaMlHLQ.jpg,,,,,
530,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,20,dfwra9,self.MachineLearning,[D] Performance of fully-connected networks on CIFAR-10?,https://www.reddit.com/r/MachineLearning/comments/dfwra9/d_performance_of_fullyconnected_networks_on/,ktessera,1570707667,"Are there any good papers or benchmarks of the performance of fully-connected networks on CIFAR-10? I have seen [this] (https://arxiv.org/abs/1511.02580), but as far as I can tell, they used an autoencoder to pre-process the input.",2,3,False,self,,,,,
531,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,20,dfwwqj,countants.com,How Business Intelligence can benefit your sales and marketing,https://www.reddit.com/r/MachineLearning/comments/dfwwqj/how_business_intelligence_can_benefit_your_sales/,Countants123,1570708498,,0,1,False,default,,,,,
532,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,21,dfx831,self.MachineLearning,[D] What kind of computation graphs does caffe2 use?,https://www.reddit.com/r/MachineLearning/comments/dfx831/d_what_kind_of_computation_graphs_does_caffe2_use/,TheRochVoices,1570710155,"Like tensorflow uses Static Computation graphs. When you define your network, it prepares the whole graph data structure before running. 
Whereas, pytorch uses Dynamic CG, where CG is prepared dynamically when the interpreter runs the code line by line. 

My questions are:
1. Is there anything conceptually wrong in the above paragraph?
2. How does Caffe2 does it?",0,1,False,self,,,,,
533,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,22,dfxq8d,self.MachineLearning,The new era of Artificial Intelligence and Machine Learning  The Future Of Robotic Process Automation,https://www.reddit.com/r/MachineLearning/comments/dfxq8d/the_new_era_of_artificial_intelligence_and/,Wensosolutions,1570712709,[removed],0,1,False,self,,,,,
534,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,22,dfxzjj,self.MachineLearning,[P] Sotabench: Benchmarking Every Open Source Model,https://www.reddit.com/r/MachineLearning/comments/dfxzjj/p_sotabench_benchmarking_every_open_source_model/,rstoj,1570713989,"Hi all!

We (the team behind Papers With Code) have been working on a new free service: [https://sotabench.com](https://sotabench.com/) .

The mission of sotabench is to benchmark and map out every open source ML model.  On Papers With Code we collect code implementations and results from papers, but until now we had no way of knowing if the code is sufficient to produce the claimed results. This is why we created sotabench. 

We hope this is going to help practitioners and researchers alike to find high quality model implementations and gain insight into the accuracy / speed tradeoff of models out there. 

Weve implemented a couple of benchmarks for now - but weve made it open and free for anyone to add benchmarks and connect their repositories (including forks). If you find it useful, feel free to just go for it and add repos. 

Open for suggestions and feedback!

Cheers, Robert",34,264,False,self,,,,,
535,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,23,dfyhx5,self.MachineLearning,[D] Successful internal ML projects?,https://www.reddit.com/r/MachineLearning/comments/dfyhx5/d_successful_internal_ml_projects/,hazard02,1570716362,"Most of the major success stories in applied ML have been user-facing stuff - Facebook optimizing engagement, Bookings optimizing user-facing search, etc.

Does anyone have examples of projects that have been successfully deployed within a company? The closest thing I can think of is some companies that use face recognition for physical authentication (i.e., in lieu of key cards)",5,3,False,self,,,,,
536,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,23,dfyrkl,self.MachineLearning,Does machine learning work better than all other statistical techniques?,https://www.reddit.com/r/MachineLearning/comments/dfyrkl/does_machine_learning_work_better_than_all_other/,Inversegaloisproblem,1570717548,[removed],0,1,False,self,,,,,
537,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,23,dfyrwt,self.MachineLearning,Anyone at Spotify? Seeking a referral for a DS role :),https://www.reddit.com/r/MachineLearning/comments/dfyrwt/anyone_at_spotify_seeking_a_referral_for_a_ds_role/,lalopark,1570717592,[removed],0,1,False,self,,,,,
538,MachineLearning,t5_2r3gv,2019-10-10,2019,10,10,23,dfz0h1,self.MachineLearning,[R] Research Guide: Advanced Loss Functions for Machine Learning Models,https://www.reddit.com/r/MachineLearning/comments/dfz0h1/r_research_guide_advanced_loss_functions_for/,mwitiderrick,1570718616,"In addition to good training data and the right model architecture, loss functions are one of the most important parts of training an accurate machine learning model. For this post, Id love to give developers an overview of some of the more advanced loss functions and how they can be used to improve the accuracy of modelsor solve entirely new tasks.

[https://heartbeat.fritz.ai/research-guide-advanced-loss-functions-for-machine-learning-models-aee68ed8a38c](https://heartbeat.fritz.ai/research-guide-advanced-loss-functions-for-machine-learning-models-aee68ed8a38c)",0,1,False,self,,,,,
539,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,0,dfzy0k,self.MachineLearning,Training a Classification Model on already given good and bad examples,https://www.reddit.com/r/MachineLearning/comments/dfzy0k/training_a_classification_model_on_already_given/,javu213,1570722531,"Hello all,

I am looking for some advice regarding training my model;

I have 200+ .csv files, each one contains data about plane take-offs. \[Speed, altitude, points(punishments for wrong actions)\] in regards of a 10 minut time period.

The files are already classified as good as or bad examples (1,0). 

What would be a good approach to train a model like this, based on previous files?",0,1,False,self,,,,,
540,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,1,dg0a5i,self.MachineLearning,"[D] PyTorch Dominates Research, Tensorflow Dominates Industry",https://www.reddit.com/r/MachineLearning/comments/dg0a5i/d_pytorch_dominates_research_tensorflow_dominates/,hughbzhang,1570723927,"Horace He looks at the data and analyzes the current state of machine learning frameworks in 2019.

&amp;#x200B;

[https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/](https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/)",89,367,False,self,,,,,
541,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,1,dg0n1u,self.MachineLearning,"[D] How does AlphaStar, a NN that players StarCraft, encode its output?",https://www.reddit.com/r/MachineLearning/comments/dg0n1u/d_how_does_alphastar_a_nn_that_players_starcraft/,Buttons840,1570725473,"For something like AlphaGo (that plays a simple board game), I understand  that the neural network can output a ""grid"" vector the size of the board, and  the largest value in the output, which is also a valid move, is the move you make\*. In this case, the neural network is solving the same simple question repeatedly, ""Where do I move?"". I know how to encode the answer to that question. There's around 400 possible moves in Go, and they are fixed, so a vector of length 400 can encode every possible action.

(\* Actually, AlphaGo uses the NN in a tree search. The NN does not generate moves directly.)

I  don't understand how a neural network like AlphaStar can output an answer to the much broader question ""What should I do?"". The answers can be ""build a building"", ""kill one of your own buildings"", ""build a unit"", ""attack a unit"", ""move 2 of your units to position"", ""move 3 of  your units to another positions"", ""load your units into a transport"",  ""use one of your units special abilities"", ""research a new technology"", etc.

**How are the answers to such a broad question encoded? Do we know how AlphaStar does it?**

I'm especially baffled by the change number of units in StarCraft. Encoding the actions 2 units can take seems significantly different than encoding the actions 3 units can take. Do they use a multi-agent setup? Is each unit running its own NN and determining it's own actions individually?",2,15,False,self,,,,,
542,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,2,dg0zwq,self.MachineLearning,"PyTorch 1.3 adds mobile, privacy, quantization, and named tensors",https://www.reddit.com/r/MachineLearning/comments/dg0zwq/pytorch_13_adds_mobile_privacy_quantization_and/,balazshoranyi,1570726972,[removed],0,1,False,self,,,,,
543,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,2,dg131o,self.MachineLearning,Calling all machine learning engineers: your feedback on new machine learning software,https://www.reddit.com/r/MachineLearning/comments/dg131o/calling_all_machine_learning_engineers_your/,teejkamikaz,1570727297,Our company recently launched a free edition of our machine learning software for experiment management called [Atlas](https://www.atlas.dessa.com/?u=teej). It features integration with Tensorboard and the NVIDIA's RAPIDS framework. It would be great to get your fine folks thoughts on the software!,0,1,False,self,,,,,
544,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,2,dg171r,towardsdatascience.com,The Deep Music Visualizer: Using sound to explore the latent space of BigGAN,https://www.reddit.com/r/MachineLearning/comments/dg171r/the_deep_music_visualizer_using_sound_to_explore/,SeagullMan2,1570727763,,0,308,False,default,,,,,
545,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,2,dg188h,github.com,pytorch/captum by pytorch,https://www.reddit.com/r/MachineLearning/comments/dg188h/pytorchcaptum_by_pytorch/,sjoerdapp,1570727895,,0,1,False,default,,,,,
546,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,2,dg1a84,self.MachineLearning,"[D] Open, benchmark datasets for tabular/structured datasets?",https://www.reddit.com/r/MachineLearning/comments/dg1a84/d_open_benchmark_datasets_for_tabularstructured/,FlyingLawnmowers,1570728121,"Hi /r/machine learning,

Was hoping to crowdsource a list of publicly available structured datasets to use as a benchmark. I'm familiar with the UCI datasets, and the ones built into scikit-learn, but many of these datasets tend to be quite small and easy to learn.

I'm hoping for some more complex datasets for standard tabular classification/regression/ranking of varying complexity. Maybe I should pull from Kaggle? Any ideas would be greatly appreciated!",0,1,False,self,,,,,
547,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,2,dg1j51,thegradient.pub,The State of Machine Learning Frameworks in 2019,https://www.reddit.com/r/MachineLearning/comments/dg1j51/the_state_of_machine_learning_frameworks_in_2019/,bil-sabab,1570729170,,0,1,False,default,,,,,
548,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,2,dg1mb0,self.MachineLearning,[Research]Segway Survey,https://www.reddit.com/r/MachineLearning/comments/dg1mb0/researchsegway_survey/,tatabiba29,1570729556,"Hello All! I am a current student who is working on a Final Project about Segways. The requirement is to collect at least 100 survey responses in the next couple of days. Could you please help me out? There are only 12 questions adn shoudl take you about 3-4 min to complete. Your insights are very valuable to me as I don't have any friends near me who are familiar with Segways. Thank you! The image of the segway I'm researching for is in google forms.

[https://docs.google.com/forms/d/e/1FAIpQLSe65iP2NtQqwgWU-QK\_9PAvo09w5n78GUt0pqjaYKFlmtECiw/viewform?usp=sf\_link](https://docs.google.com/forms/d/e/1FAIpQLSe65iP2NtQqwgWU-QK_9PAvo09w5n78GUt0pqjaYKFlmtECiw/viewform?usp=sf_link)",0,0,False,self,,,,,
549,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,2,dg1nvq,self.MachineLearning,[N] PyTorch Mobile: Deployment on iOS and Android,https://www.reddit.com/r/MachineLearning/comments/dg1nvq/n_pytorch_mobile_deployment_on_ios_and_android/,jayyhu,1570729732,"With the new release of [PyTorch 1.3](https://github.com/pytorch/pytorch/releases/tag/v1.3.0), they've added support (and libraries) to deploy PyTorch models directly to mobile devices for inference.

* [Overview](https://pytorch.org/mobile/home/)
* [iOS support](https://pytorch.org/mobile/ios/)
* [Android support](https://pytorch.org/mobile/android/)",0,19,False,self,,,,,
550,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,3,dg1wxj,self.MachineLearning,[Research] Segway Survey for the Graduation Project,https://www.reddit.com/r/MachineLearning/comments/dg1wxj/research_segway_survey_for_the_graduation_project/,tatabiba29,1570730787,"Hello all! I am a current student working on a Graduation project about Segways. I was asked to collect at least 100 responses in the next couple of days. Could you please help me out and fill it? There are only 12 questions and should take you about 3-4 min to complete. Your insights are very valuable to me. Thank you in advance!

[https://docs.google.com/forms/d/e/1FAIpQLSe65iP2NtQqwgWU-QK\_9PAvo09w5n78GUt0pqjaYKFlmtECiw/viewform?usp=sf\_link](https://docs.google.com/forms/d/e/1FAIpQLSe65iP2NtQqwgWU-QK_9PAvo09w5n78GUt0pqjaYKFlmtECiw/viewform?usp=sf_link)",1,0,False,self,,,,,
551,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,3,dg2j64,self.MachineLearning,[R] Machine learning edge devices: benchmark report,https://www.reddit.com/r/MachineLearning/comments/dg2j64/r_machine_learning_edge_devices_benchmark_report/,tryo_labs,1570733371,"We benchmarked five novel edge devices:

- Nvidia Jetson Nano
- Google Coral Dev Board
- Intel Neural Compute Stick
- Raspberry Pi (upper bound reference)
- 2080ti NVIDIA GPU (lower bound reference)

We used different frameworks and models, to see which combinations perform best. In particular, we focused on performance outcomes for machine learning on the edge.

You can see the results here:

- **Full article:** https://tryolabs.com/blog/machine-learning-on-edge-devices-benchmark-report/
- **Results only:** https://tryolabs.com/blog/machine-learning-on-edge-devices-benchmark-report/#results-analysis",2,8,False,self,,,,,
552,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,3,dg2k3y,youtu.be,Organic AI - Will the next generation of AI fly us to the stars? Bruno Maisonnier,https://www.reddit.com/r/MachineLearning/comments/dg2k3y/organic_ai_will_the_next_generation_of_ai_fly_us/,chelsea_bear,1570733475,,0,1,False,https://b.thumbs.redditmedia.com/G1oEN1R2n9b3jIJbGmNrk-bE1sgfa3pPoRf7_UAJ2uQ.jpg,,,,,
553,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,3,dg2lb6,self.MachineLearning,"[N] PyTorch 1.3.0: Mobile Support, Named Tensors, Quantization, Type Promotion and many more",https://www.reddit.com/r/MachineLearning/comments/dg2lb6/n_pytorch_130_mobile_support_named_tensors/,aiismorethanml,1570733599," **Highlights**  

* \[Experimental\]: Mobile Support
* \[Experimental\]: Named Tensor Support
* \[Experimental\]: Quantization support
* Type Promotion

[Full Release Notes](https://github.com/pytorch/pytorch/releases/tag/v1.3.0)",10,161,False,self,,,,,
554,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,4,dg2ywv,youtube.com,Designing Fast and Robust Learning Algorithms - Yu Cheng,https://www.reddit.com/r/MachineLearning/comments/dg2ywv/designing_fast_and_robust_learning_algorithms_yu/,DrJohanson,1570735018,,0,1,False,default,,,,,
555,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,4,dg33i5,proandroiddev.com,[D] Interesting how you can use AutoML in Mobile. I am sure there will be more libraries with direct mobile support in future.,https://www.reddit.com/r/MachineLearning/comments/dg33i5/d_interesting_how_you_can_use_automl_in_mobile_i/,grogrogro1234,1570735508,,0,1,False,default,,,,,
556,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,4,dg36i0,self.MachineLearning,Any free sources for Object Identification learning?,https://www.reddit.com/r/MachineLearning/comments/dg36i0/any_free_sources_for_object_identification/,kirasama16997,1570735833,[removed],0,1,False,self,,,,,
557,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,4,dg38j8,self.MachineLearning,[R] higher. A PyTorch library to do gradient-based hyperparameter optimization and meta-learning without changing models/optimizers,https://www.reddit.com/r/MachineLearning/comments/dg38j8/r_higher_a_pytorch_library_to_do_gradientbased/,rikkajounin,1570736058,"I wanted to share with you [this project](https://github.com/facebookresearch/higher) I just stumbled upon from facebook AI research.

Implementing gradient-based hyper-parameter optimization and meta-learning has always been hard because of the non-differentiable optimizers and the stateful, non functional models. This library is supposed to make things easier by replacing existing stateful models with stateless ones automatically at run-time. It also implement differentiable version for most of the  the `torch.optim` optimizers (although you cant use third party ones out of the box). 

This means that we can finally differentiate through the usual training loop code with very little changes!

I didn't try the library myself but it seems really easy to implement and from the stars looks really promising. Let me know what you think.

repo: [https://github.com/facebookresearch/higher](https://github.com/facebookresearch/higher)",0,1,False,self,,,,,
558,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,4,dg39lq,self.MachineLearning,[P] higher. A PyTorch library to do gradient-based hyperparameter optimization and meta-learning without changing models/optimizers,https://www.reddit.com/r/MachineLearning/comments/dg39lq/p_higher_a_pytorch_library_to_do_gradientbased/,rikkajounin,1570736169,"I wanted to share with you [this very recent project](https://github.com/facebookresearch/higher) I just stumbled upon from facebook AI research.

Implementing gradient-based hyper-parameter optimization and meta-learning has always been hard because of the non-differentiable optimizers and the stateful, non functional models. This library is supposed to make things easier by replacing existing stateful models with stateless ones automatically at run-time. It also implement differentiable version for most of the the torch.optim optimizers (although you cant use third party ones out of the box).

This means that we can finally differentiate through the usual training loop code with very little changes!

I didn't try the library myself but it seems really easy to implement and from the stars looks really promising. Let me know what you think.

repo: [https://github.com/facebookresearch/higher](https://github.com/facebookresearch/higher)",1,2,False,self,,,,,
559,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,5,dg3nbl,technologyreview.com,Machine vision has learned to use radio waves to see through walls and in darkness,https://www.reddit.com/r/MachineLearning/comments/dg3nbl/machine_vision_has_learned_to_use_radio_waves_to/,kink667,1570737711,,0,1,False,default,,,,,
560,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,5,dg3z6f,mobile.twitter.com,The Pytorch conference has been postponed,https://www.reddit.com/r/MachineLearning/comments/dg3z6f/the_pytorch_conference_has_been_postponed/,stormtrooper1721,1570739105,,0,1,False,default,,,,,
561,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,5,dg41y5,self.MachineLearning,Why would my neural network be modeling a cubic function?,https://www.reddit.com/r/MachineLearning/comments/dg41y5/why_would_my_neural_network_be_modeling_a_cubic/,vvvvvvvwvvvvvvv,1570739444,[removed],0,1,False,self,,,,,
562,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,5,dg4g64,arxiv.org,Nonconvex optimization problems in machine learning,https://www.reddit.com/r/MachineLearning/comments/dg4g64/nonconvex_optimization_problems_in_machine/,Inversegaloisproblem,1570741121,,9,14,False,default,,,,,
563,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,6,dg4qzo,self.MachineLearning,A Useful tool for Machine Learning job scheduling and experiment management!,https://www.reddit.com/r/MachineLearning/comments/dg4qzo/a_useful_tool_for_machine_learning_job_scheduling/,RayhaneML,1570742443,"I recently came across [Atlas](https://www.atlas.dessa.com), a free tool that features job scheduling and experiment management.  

It allows to run multiple different experiments, or jobs overnight. Either for hyperparams search or other. I think it's very interesting that it allows to monitor all params and metrics on the same interface, while still having access to the logs of every job and other items, that they call ""artifacts"" which can typically be any file. These can also be viewed immediately from the GUI. The thing I like most tho is their parallel coordinates plot that shows the immediate impact of parameters on a chosen metric, and it's highly interactive. (GIF below)

I highly recommend trying out this tool. By far the best ML tool I came across.

https://i.redd.it/37mkxb0v5sr31.gif

  
It also integrates with Tensorboard, which is another tool I love when using neural networks. It even allows for multi job comparison using TB, without having to worry a thing related to running the TB server/hosting it. this shit is crazy!

&amp;#x200B;

https://i.redd.it/zuenk5ew5sr31.gif",0,1,False,self,,,,,
564,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,6,dg4rj9,self.MachineLearning,[R] Audio Conversion GAN: I wrote a Paper,https://www.reddit.com/r/MachineLearning/comments/dg4rj9/r_audio_conversion_gan_i_wrote_a_paper/,artika_labs,1570742499,"A month ago I wrote a post in this subreddit ([here](https://www.reddit.com/r/MachineLearning/comments/d1a9vc/r_audio_conversion_gan_with_unpaired_data/)) about a voice conversion and audio style transfer system on unpaired data I had been working on. Many users were quite surprised by the [results](https://youtu.be/3BN577LK62Y) and recommended me to write a paper about it, despite my completely lack of knowledge in the academic world (which I was very afraid of).

Well, I wrote that paper:  [https://arxiv.org/abs/1910.03713](https://arxiv.org/abs/1910.03713) (Here the old demo video:  [https://youtu.be/3BN577LK62Y](https://youtu.be/3BN577LK62Y) )

I have no idea if the final product is up to standard or if there are some major holes or mistakes in it (quite likely honestly): this is my first ever paper and I asked advice to multiple subject-related professors in my university but nobody offered to help.

I would love to know what I should now do: I know papers can be published in publications of various level, but the entire process is entirely obscure to me, and I am quite happy to just have it on arXiv.

Finally, I really need to thank all the people that told me that writing a paper was the right idea: I feel like I learned a lot in the process. So, thank you again!",25,92,False,self,,,,,
565,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,6,dg4x55,self.MachineLearning,Pytorch version 1.3.0 is out!,https://www.reddit.com/r/MachineLearning/comments/dg4x55/pytorch_version_130_is_out/,godofprobability,1570743184,[https://github.com/pytorch/pytorch/tree/v1.3.0](https://github.com/pytorch/pytorch/tree/v1.3.0),0,1,False,self,,,,,
566,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,6,dg52t3,arxiv.org,[R] Linking emotions to behaviors through deep transfer learning,https://www.reddit.com/r/MachineLearning/comments/dg52t3/r_linking_emotions_to_behaviors_through_deep/,mathmare,1570743893,,2,3,False,default,,,,,
567,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,6,dg58ij,self.MachineLearning,How can you make a neural network learn to play a game better than other neural networks?,https://www.reddit.com/r/MachineLearning/comments/dg58ij/how_can_you_make_a_neural_network_learn_to_play_a/,Electronic_Hat,1570744600,"I'm new to the world of AI and machine learning, and my friend and I are having a competition to build neural networks to play Halo against each other. the winner of a game is the winner of the competition. If I want my AI to develop strategies or traits that make it better than another AI, for example to learn to use sniper rifles over pistols, how could I do that?",0,1,False,self,,,,,
568,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,7,dg5fwu,self.MachineLearning,How often do you encounter Black collaborators in your day-to-day research?,https://www.reddit.com/r/MachineLearning/comments/dg5fwu/how_often_do_you_encounter_black_collaborators_in/,Odyssey277,1570745518,[removed],0,1,False,self,,,,,
569,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,7,dg5izj,medium.com,"Facebook Debuts PyTorch 1.3 With PyTorch Mobile, Quantization, TPU Support and More",https://www.reddit.com/r/MachineLearning/comments/dg5izj/facebook_debuts_pytorch_13_with_pytorch_mobile/,Yuqing7,1570745930,,0,1,False,default,,,,,
570,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,8,dg6a6u,self.MachineLearning,[N] Detectron2: A PyTorch-based modular object detection library,https://www.reddit.com/r/MachineLearning/comments/dg6a6u/n_detectron2_a_pytorchbased_modular_object/,youali,1570749406,"**Detectron2: A PyTorch-based modular object detection library** 


- [Blog post](https://ai.facebook.com/blog/-detectron2-a-pytorch-based-modular-object-detection-library-/)
- [Github page](https://github.com/facebookresearch/detectron2)


**Improvements in Detectron2**

**PyTorch:** The original Detectron was implemented in Caffe2. PyTorch provides a more intuitive imperative programming model that allows researchers and practitioners to iterate more rapidly on model design and experiments. Because weve rewritten Detectron2 from scratch in PyTorch, users can now benefit from PyTorchs approach to deep learning as well as the large and active community that continually improves PyTorch

**Modular,** extensible design: In Detectron2, weve introduced a modular design that allows users to plug custom module implementations into almost any part of an object detection system. This means that many new research projects can be written in hundreds of lines of code with a clean separation between the core Detectron2 library and the novel research implementation. We continue to refine the modular, extensible design by implementing new models and discovering new ways in which we can make Detectron2 more flexible.",2,10,False,self,,,,,
571,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,8,dg6iw3,self.MachineLearning,"[PROJECT] Is there an example where YOLO, Mask R-CNN and Faster R-CNN are applied?",https://www.reddit.com/r/MachineLearning/comments/dg6iw3/project_is_there_an_example_where_yolo_mask_rcnn/,kirasama16997,1570750546,"



I am not able to implement the object detection algorithms on code, and need an example where the three main algos are applied on the same dataset, so I can compare their speed myself.

Any help with all this?",2,2,False,self,,,,,
572,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,9,dg7bv7,self.MachineLearning,[D] The State of Machine Learning Frameworks in 2019 (@gradientpub),https://www.reddit.com/r/MachineLearning/comments/dg7bv7/d_the_state_of_machine_learning_frameworks_in/,sensetime,1570754373,"[Blog post](https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/) on gradient.pub with quantitative extensive analysis of PyTorch vs TensorFlow adoption in research.

*TensorFlow will always have a captive audience within Google/DeepMind, but I wonder whether Google will eventually relax this. Even now, many of the researchers that Google wants to recruit will already prefer PyTorch at varying levels, and Ive heard grumblings that many researchers inside Google would like to use a framework other than TensorFlow.*

*In addition, PyTorchs dominance might start to cut off Google researchers from the rest of the research community. Not only will they have a harder time building on top of outside research, outside researchers will also be less likely to build on top of code published by Google.*

https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/",0,1,False,self,,,,,
573,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,10,dg7py5,self.MachineLearning,[D] Best Foundational Textbooks,https://www.reddit.com/r/MachineLearning/comments/dg7py5/d_best_foundational_textbooks/,the_transgressor,1570756282,"I want to start building a foundation in machine learning to ultimately do research in the intersection of machine learning and economics/finance. Would The Elements of Statistical Learning (Hastie et. al. 2009) be the best place to start? I fear that the text may be outdated in 2019, but Im coming to ML with only econometric/statistical knowledge.

Also, would An Introduction to Statistical Learning with Applications in R (Gareth et al 2017) be too basic for my goals? Are there better texts I should start with than Hastie et al (2009)?",6,4,False,self,,,,,
574,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,10,dg7wug,self.MachineLearning,[P] RL library focusing on easy experimental research with cloud experiment management,https://www.reddit.com/r/MachineLearning/comments/dg7wug/p_rl_library_focusing_on_easy_experimental/,vwxyzjn,1570757226,"Hi everyone,

I have created a yet another reinforcement learning library. [https://github.com/vwxyzjn/cleanrl](https://github.com/vwxyzjn/cleanrl)

This repository focuses on a clean and minimal implementation of reinforcement learning algorithms. The highlights features of this repo are:

* Most algorithms are self-contained in single files with a common dependency file common.py that handles different gym spaces.
* Easy logging of training processes using Tensorboard and Integration with wandb.com to log experiments on the cloud. Check out [https://app.wandb.ai/costa-huang/cleanrltest](https://app.wandb.ai/costa-huang/cleanrltest).
* **Easily customizable** and being able to debug directly in Pythons interactive shell.
* Convenient use of commandline arguments for hyper-parameters tuning.

Currently I support A2C, PPO, and DQN. If you are interested, please consider giving it a try :)

## Motivation:

There are two types of RL library on the two ends of the spectrum. The first one is the demo kind that really just demos what the algorithm is doing, only deals with one gym environment and hard to record experiments and tune parameters.

On the other end of the spectrum, we have OpenAI/baselines, ray-project/ray, and couple google repos. My personal experience with them is that I could only run benchmark with them. They try to write modular code and employ good software engineering practices, but the problem is *python is a dynamic language without IDE support*. As a result, I had no idea what variable types in different files are and it was very difficult to do any kind of customization. I had to see through dozens of files before even able to try some experiments.

Thats why I created this repo that leans towards the first kind, but has more actual experimental support. I support multiple gym spaces (still working on it), command line arguments to tune parameters, and very seamless experiment logging, all of which are essential characteristics for building a pipeline for research I believe.",0,3,False,self,,,,,
575,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,10,dg8220,towardsdatascience.com,Applying AI to Enterprise Integration: How Ready Are We?,https://www.reddit.com/r/MachineLearning/comments/dg8220/applying_ai_to_enterprise_integration_how_ready/,srinath_perera,1570757907,,0,1,False,https://b.thumbs.redditmedia.com/-3nXUN8Tg2ici9QPxdK4snjAAHAezOZ4PHA9Utrbzds.jpg,,,,,
576,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,11,dg8rms,self.MachineLearning,[R] Beyond Vector Spaces: Compact Data Representations Differentiable Weighted Graphs,https://www.reddit.com/r/MachineLearning/comments/dg8rms/r_beyond_vector_spaces_compact_data/,justheuristic,1570761459,"Paper: [https://arxiv.org/abs/1910.03524](https://arxiv.org/abs/1910.03524) (accepted to NeurIPS 2019)

Code: [https://github.com/stanis-morozov/prodige](https://github.com/stanis-morozov/prodige)

The paper proposes an embedding layer based on weighted graph instead of vectors. Intuitively, this layer learns to represent concepts/words by their relation to other. Trains by backprop w.r.t. graph edges.

[\(Left\) PRODIGE learned on a subset of MNIST. \(Right\) zoom-in of some clusters. Interactive version: https:\/\/neurips-anonymous.github.io\/index.html](https://i.redd.it/xaa6p70qotr31.png)

* **+** Learns interpretable hierarchies from raw objects;
* **+** The model is much smaller than typical vector embeddings;
* **-** The official code is CPU-only, it aint too fast",2,5,False,self,,,,,
577,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,11,dg8v71,self.MachineLearning,[P] ALBERT with Pytorch implementation,https://www.reddit.com/r/MachineLearning/comments/dg8v71/p_albert_with_pytorch_implementation/,nlkey2022,1570761953,"Only Pretraining available, downstream tasks are not yet.

[https://github.com/graykode/ALBERT-Pytorch](https://github.com/graykode/ALBERT-Pytorch)",0,4,False,self,,,,,
578,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,12,dg98pn,i.redd.it,An Issue I have far too often.,https://www.reddit.com/r/MachineLearning/comments/dg98pn/an_issue_i_have_far_too_often/,Top_Hat_Tomato,1570763960,,0,2,False,default,,,,,
579,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,12,dg9e5x,self.MachineLearning,Do NLP machine learning approaches (e.g. transformers) have any applications in Computer Vision?,https://www.reddit.com/r/MachineLearning/comments/dg9e5x/do_nlp_machine_learning_approaches_eg/,ohdangggg,1570764802,[removed],0,1,False,self,,,,,
580,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,13,dg9p8f,github.com,"[N] Pytorch XLA, official support for Pytorch on TPUs, now in alpha",https://www.reddit.com/r/MachineLearning/comments/dg9p8f/n_pytorch_xla_official_support_for_pytorch_on/,BatmantoshReturns,1570766576,,0,1,False,default,,,,,
581,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,14,dgaa5i,arxiv.org,[R] Benchmarking Batch Deep Reinforcement Learning Algorithms,https://www.reddit.com/r/MachineLearning/comments/dgaa5i/r_benchmarking_batch_deep_reinforcement_learning/,MrDoOO,1570770144,,4,19,False,default,,,,,
582,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,14,dgajeg,self.MachineLearning,Which groups produce cool research at the intersection of HCI/HRI and ML?,https://www.reddit.com/r/MachineLearning/comments/dgajeg/which_groups_produce_cool_research_at_the/,lilacseafoam,1570771728,[removed],0,1,False,self,,,,,
583,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,15,dgb84z,sites.google.com,The Silk Screen Machine,https://www.reddit.com/r/MachineLearning/comments/dgb84z/the_silk_screen_machine/,rapidtag,1570776135,,0,1,False,default,,,,,
584,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,16,dgbo4b,self.MachineLearning,[D] Why are we publishing research on this? (Face Beauty Prediction),https://www.reddit.com/r/MachineLearning/comments/dgbo4b/d_why_are_we_publishing_research_on_this_face/,rtk25,1570779144,"Thought it was a joke, but it looks real....

[https://www.sciencedirect.com/science/article/pii/S0957417419307079](https://www.sciencedirect.com/science/article/pii/S0957417419307079)",3,0,False,self,,,,,
585,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,17,dgbwzr,arxiv.org,[R] Uncertainty-Aware Principal Component Analysis,https://www.reddit.com/r/MachineLearning/comments/dgbwzr/r_uncertaintyaware_principal_component_analysis/,jgoertler,1570780846,,12,9,False,default,,,,,
586,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,17,dgbxbj,arxiv.org,[R] Executing Instructions in Situated Collaborative Interactions,https://www.reddit.com/r/MachineLearning/comments/dgbxbj/r_executing_instructions_in_situated/,hardmaru,1570780904,,1,2,False,default,,,,,
587,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,17,dgcaic,self.MachineLearning,reverse engineering a model,https://www.reddit.com/r/MachineLearning/comments/dgcaic/reverse_engineering_a_model/,elwiiithebig,1570783697,"Hi,

I am working on data privacy for legal issues.

I have serious doubts about it but, are you aware of any method that would allows one to reverse engineering a regression model or classification model ?

The real question is: given the model weights/parameters, the learning algorithm and hyper parameters, is it possible to retreive the data used to learn the model? or at least a rought estimation of those data ?

If you have any reference, that would be great!",0,1,False,self,,,,,
588,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,18,dgcgxb,self.MachineLearning,"Which Solenoid Valve is Useful for Food Industries, Pharmaceuticals, Chemical Application &amp; Highly corrosive environment?",https://www.reddit.com/r/MachineLearning/comments/dgcgxb/which_solenoid_valve_is_useful_for_food/,uflowindia,1570784951,[removed],0,1,False,self,,,,,
589,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,18,dgcjmr,self.neuralnetworks,Can you model a NN on an FPGA?,https://www.reddit.com/r/MachineLearning/comments/dgcjmr/can_you_model_a_nn_on_an_fpga/,FIREATWlLL,1570785461,,0,1,False,default,,,,,
590,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,18,dgcnnz,data-flair.training,11 Top Machine Learning Algorithms used by Data Scientists,https://www.reddit.com/r/MachineLearning/comments/dgcnnz/11_top_machine_learning_algorithms_used_by_data/,Aakashdata,1570786229,,0,1,False,default,,,,,
591,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,18,dgcnvs,self.MachineLearning,[D] How to test the practical ML knowledge of a job applicant?,https://www.reddit.com/r/MachineLearning/comments/dgcnvs/d_how_to_test_the_practical_ml_knowledge_of_a_job/,rsjogren,1570786271,"I'm involved in evaluating candidates for positions in ML and have been asked how to test their practical skills. We are looking at both potential ML engineers and research scientists. The positions are quite junior, so project management is not something we need to look for. We have a quite broad set of applications going on spanning computer vision, NLP, time series analysis and tabular data. 

What I would like to do is to formulate a task (or tasks) that I can use to test the applicants' practical problem solving abilities. My problem is that the tasks I work with involve a bit sensitive data that I can't share. Open datasets on the other hand are often already formatted in a ""ready-to-model"" format with plenty of publicly available solutions, which is usually not the case in real-life projects.

I would like to discuss options that can also serve as a resource for struggling research scientists involved in recruiting. How would you formulate a task that:

* Is solvable within reasonable time before a job interview
* Is not more hardware demanding than that you can solve it in a Collab notebook
* Is not trivially solvable by reading online tutorials
* Shows that the applicant avoid some common pitfall encountered in practice (data leakage, imbalanced datasets, test set peeking)
* Shows that the applicant actually has some practical know-how?",37,36,False,self,,,,,
592,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,19,dgcy9t,analyticspath.com,Hurry Up And Enroll Now For The Free Interactive Session On Machine Learning Training At Analytics Path Scheduled On 12th Oct 2019 @ 9 AM In Hyderabad.,https://www.reddit.com/r/MachineLearning/comments/dgcy9t/hurry_up_and_enroll_now_for_the_free_interactive/,Jony1223,1570788164,,0,1,False,default,,,,,
593,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,19,dgd0ri,self.MachineLearning,Algorithm,https://www.reddit.com/r/MachineLearning/comments/dgd0ri/algorithm/,mamrani,1570788585,[removed],0,1,False,self,,,,,
594,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,19,dgda15,self.MachineLearning,Model,https://www.reddit.com/r/MachineLearning/comments/dgda15/model/,mamrani,1570790205,[removed],0,1,False,self,,,,,
595,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,19,dgdame,self.MachineLearning,How is machine learning applied to LinkedIn?,https://www.reddit.com/r/MachineLearning/comments/dgdame/how_is_machine_learning_applied_to_linkedin/,martinbryan82,1570790305,[removed],0,1,False,self,,,,,
596,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,19,dgdax6,self.MachineLearning,Archaeologist interested in Machine Learning. How do I get started? I have no tech skills.,https://www.reddit.com/r/MachineLearning/comments/dgdax6/archaeologist_interested_in_machine_learning_how/,indyhwj,1570790352,[removed],1,1,False,self,,,,,
597,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,19,dgdbx8,self.MachineLearning,Sensor feature selection,https://www.reddit.com/r/MachineLearning/comments/dgdbx8/sensor_feature_selection/,davidfarrugia53,1570790526,[removed],0,1,False,self,,,,,
598,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,19,dgdfav,self.MachineLearning,[P] Colab course on TensorFlow 2.0 for researchers,https://www.reddit.com/r/MachineLearning/comments/dgdfav/p_colab_course_on_tensorflow_20_for_researchers/,MaxTalanov,1570791101,"[An introduction / crash course about TensorFlow 2.0](https://colab.research.google.com/drive/1UCJt8EYjlzCs1H1d1X0iDGYJsHKwu-NO), as a colab notebook.",21,88,False,self,,,,,
599,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,20,dgdqee,medium.com,AI Mass Disruption: Reskilling of 120 Million Workers is Todays Urgency,https://www.reddit.com/r/MachineLearning/comments/dgdqee/ai_mass_disruption_reskilling_of_120_million/,Albertchristopher,1570792950,,0,1,False,https://a.thumbs.redditmedia.com/LjQNmDNnUCHcuFNkIjofR6bBDFeemFLyNTWbogtLH14.jpg,,,,,
600,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,20,dge24v,self.MachineLearning,[D] Does winning a Kaggle competition really help your career?,https://www.reddit.com/r/MachineLearning/comments/dge24v/d_does_winning_a_kaggle_competition_really_help/,AlexSnakeKing,1570794838,"I've been wondering about this question:

* On one hand, conventional wisdom has that winning a Kaggle competition is quite a feather in your cap and it will open all sorts of doors for you. You will have to fend off recruiters with bear spray, given the amount of corporate attention you will receive once you win. 
* On the other the few Kaggle winners that I follow personally (connecting on LinkedIn, following their blogs, etc...) don't seem to have their careers impacted by their achievements. You don't see them switching to Google or FB or something a few months after they win. They all stay in the relatively obscure tier 2 role they worked in. Sometimes not even that, they turn out to be freelancers and they remain that way, or something like that....

Any thoughts on what is the more accurate depiction of Kaggle winners?",154,168,False,self,,,,,
601,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,20,dge2j3,self.MachineLearning,[D] Transfer-Learning for Image classification with effificientNet in Keras/Tensorflow 2 (stanford cars dataset),https://www.reddit.com/r/MachineLearning/comments/dge2j3/d_transferlearning_for_image_classification_with/,ixeption,1570794891,"I recently wrote about, how to use a 'imagenet' pretrained [efficientNet](https://arxiv.org/abs/1905.11946) implementation from keras to create a SOTA  image classifier on custom data, in this case the stanford car dataset. There are some details about BatchNormalization and how to start by training only the classifier layer and later train the complete network. But in the end it's a good starter for beginners (using the jupyter notebook).

[http://digital-thinking.de/keras-transfer-learning-for-image-classification-with-effificientnet/](http://digital-thinking.de/keras-transfer-learning-for-image-classification-with-effificientnet/)

If you are looking for a PyTorch example (not mine):

[https://github.com/morganmcg1/stanford-cars](https://github.com/morganmcg1/stanford-cars)",0,8,False,self,,,,,
602,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,21,dge8nl,youtube.com,Why are we having so much of success with Deep Learning now as compared to the past?,https://www.reddit.com/r/MachineLearning/comments/dge8nl/why_are_we_having_so_much_of_success_with_deep/,manmeet10,1570795821,,0,1,False,https://b.thumbs.redditmedia.com/MYEi4EolbnyHNWWT1DTW_BhRSQieQmQXAIhpzqNEaJY.jpg,,,,,
603,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,21,dgeavq,self.MachineLearning,Question,https://www.reddit.com/r/MachineLearning/comments/dgeavq/question/,mamrani,1570796162,"Convolution neural network belongs to which task ?

ASR 

Machine translation 

object identification",0,1,False,self,,,,,
604,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,21,dgefhw,self.MachineLearning,"Machine Learning Engineer - Position - Boston, Mass.",https://www.reddit.com/r/MachineLearning/comments/dgefhw/machine_learning_engineer_position_boston_mass/,ITRecru_it,1570796844,[removed],0,1,False,self,,,,,
605,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,21,dgek9m,self.MachineLearning,Making an ML application that checks if identicon in Camera preview matches with one in the device memory...,https://www.reddit.com/r/MachineLearning/comments/dgek9m/making_an_ml_application_that_checks_if_identicon/,NoctisShadowzel,1570797528,[removed],0,1,False,self,,,,,
606,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,21,dgeoop,self.MachineLearning,What are some real world problems that could be solved with AI and machine learning?,https://www.reddit.com/r/MachineLearning/comments/dgeoop/what_are_some_real_world_problems_that_could_be/,DaviiidMC,1570798154,[removed],0,1,False,self,,,,,
607,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,21,dgesjl,self.MachineLearning,[D] Meta-learning for fast convergence for training from scratch?,https://www.reddit.com/r/MachineLearning/comments/dgesjl/d_metalearning_for_fast_convergence_for_training/,tsauri,1570798686,"Meta-learning is good for learning new class with &lt;10 samples.  
And it requires sort of pre-training with similar classes.  


Is there good recent works to improve convergence for randomly-initialized networks using meta-learning?  
I have looked into meta learning optimizers, but so far results are worse than SGD and Adam. Or maybe \~0.1% faster convergence but consumes \~30% more computations. The results are not promising compared to meta-learning architecture (neural architecture search)",0,4,False,self,,,,,
608,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,21,dgetbt,github.com,Simple-Siamese-Tensorflow,https://www.reddit.com/r/MachineLearning/comments/dgetbt/simplesiamesetensorflow/,mrgemy95,1570798795,,1,1,False,default,,,,,
609,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,22,dgf0cs,self.MachineLearning,[P] Ranking data handlers based on statistics,https://www.reddit.com/r/MachineLearning/comments/dgf0cs/p_ranking_data_handlers_based_on_statistics/,reddof,1570799696,"I have a problem that I'm looking to solve and want some direction.

I have data that I need to process and I have  handlers that I need to rank. The handlers are essentially people that may be able to process each piece of data. Each piece of data that comes in is sent to the handlers for them to process. If they are unable to process it, then I send it to the next handler. I do this until one of the handlers successfully processes it or I have exhausted all the handlers.

I have several criteria that I'm using to rank the handlers. For example, how frequently they successfully handle a piece of data, how long they take to process the data, and a score for how well they handled it (successful solutions can be graded and although any is acceptable, we would prefer the one that produces the better answer).

Given a bunch of data with the above statistics, I would like to do two things. First, produce a report that ranks the handlers. This is currently done manually so I would like to automate this step. Second, I would like to have the dispatcher respond in real time to changes in the statistics. For example, if one of the handlers starts taking longer than normal then we should deprioritizing subsequent requests to that handler until they improve.

Are there recommendations for a toolkit or a subset of algorithms that I should be researching? Any pointers are appreciated.",0,1,False,self,,,,,
610,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,22,dgf2sw,self.MachineLearning,[R] Learning protein conformational space by enforcing physics with convolutions and latent interpolations,https://www.reddit.com/r/MachineLearning/comments/dgf2sw/r_learning_protein_conformational_space_by/,cwkx,1570800013,[removed],0,1,False,self,,,,,
611,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,22,dgf527,self.MachineLearning,IF YOU LIKE MTG PLEASE TAKE A LOOK,https://www.reddit.com/r/MachineLearning/comments/dgf527/if_you_like_mtg_please_take_a_look/,RhythmicGaming,1570800309,[removed],0,1,False,self,,,,,
612,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,22,dgf5kx,self.MachineLearning,Super Serial- making TFRecords easy,https://www.reddit.com/r/MachineLearning/comments/dgf5kx/super_serial_making_tfrecords_easy/,Markemus,1570800380,[removed],0,1,False,self,,,,,
613,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,22,dgfbwi,self.MachineLearning,Information theoretic view on backprop.,https://www.reddit.com/r/MachineLearning/comments/dgfbwi/information_theoretic_view_on_backprop/,britcruise,1570801232,"I'm trying to explain the highest level reason why (modern) back propogation works better than previous methods (such as rosenblatts back propogation in 1958 - yes it's that old). without going into the calculus, i want to just look at the information side of things.

I want to say something like the following:

back in the 1960's we tried back propogation with binary neurons. And so when we tuned the parameters backwards (from output to input) no magnitude information passed back through the net (only DIRECTION - i.e. turn this knob left or right).  this is similar to how we can't reverse an operation in modulo arithmetic. so it was a very 'coarse' training process due to a lack of information. (took forever)

When we moved to non-linear units (such as relu) there was now a direct relationships between output and input magnitude, and so when we passed backwords through the net we had MAGNITUDE and DIRECTION information (i.e. turn this knob to the right by x). that allowed us to train the net much faster because information from every neuron touched every other neuron. put simply, ""we knew how much to turn them, and what direction"" during training.

thoughts? what am I glossing over? 

thank you.",0,1,False,self,,,,,
614,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,22,dgfgds,arxiv.org,[R] Learning protein conformational space by enforcing physics with convolutions and latent interpolations,https://www.reddit.com/r/MachineLearning/comments/dgfgds/r_learning_protein_conformational_space_by/,cwkx,1570801809,,3,6,False,default,,,,,
615,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,23,dgfnx1,self.MachineLearning,Python Deep Learning tutorial: Create a GRU (RNN) in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/dgfnx1/python_deep_learning_tutorial_create_a_gru_rnn_in/,andrea_manero,1570802764,[removed],0,1,False,self,,,,,
616,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,23,dgfp8c,/r/MachineLearning/comments/dgfp8c/how_neural_network_recognize_mnist_number_dataset/,How Neural Network recognize MNIST number dataset! Only 10% of weights are show.,https://www.reddit.com/r/MachineLearning/comments/dgfp8c/how_neural_network_recognize_mnist_number_dataset/,Timbelion,1570802908,,0,1,False,default,,,,,
617,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,23,dgfpzr,self.MachineLearning,Are there any good tools or frameworks for creating face morphs?,https://www.reddit.com/r/MachineLearning/comments/dgfpzr/are_there_any_good_tools_or_frameworks_for/,portugal_the_fan,1570803001,[removed],0,1,False,self,,,,,
618,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,23,dgfvgw,developer.amazon.com,In-House Tools for Generating Synthetic Data Helped Bootstrap Alexas New-Language Releases,https://www.reddit.com/r/MachineLearning/comments/dgfvgw/inhouse_tools_for_generating_synthetic_data/,georgecarlyle76,1570803683,,0,1,False,default,,,,,
619,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,23,dggbvs,manalelaidouni.github.io,"Wrote a post on how to evaluate your models with object detection metrics, love to hear your feedback.",https://www.reddit.com/r/MachineLearning/comments/dggbvs/wrote_a_post_on_how_to_evaluate_your_models_with/,Melai11,1570805730,,0,2,False,https://b.thumbs.redditmedia.com/6Lrk2bCGoZIxjoemhIXX0JY6tjTsd9K_81Ml3MSbWPo.jpg,,,,,
620,MachineLearning,t5_2r3gv,2019-10-11,2019,10,11,23,dggcum,medium.com,Automatic Classification of Sexual Harassment Cases Using the biggest Global Data Set,https://www.reddit.com/r/MachineLearning/comments/dggcum/automatic_classification_of_sexual_harassment/,Lordobba,1570805852,,0,1,False,default,,,,,
621,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,0,dgglbp,outsystems.com,Improving Customer Service With Chatbots,https://www.reddit.com/r/MachineLearning/comments/dgglbp/improving_customer_service_with_chatbots/,sladeyades,1570806881,,0,1,False,https://a.thumbs.redditmedia.com/2pnSypvyS3EzUgF8ztzC-wAFOzYxsJuV8tPdspUMr34.jpg,,,,,
622,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,0,dggw6p,self.MachineLearning,Do I need linear algebra knowledge to learn ML?,https://www.reddit.com/r/MachineLearning/comments/dggw6p/do_i_need_linear_algebra_knowledge_to_learn_ml/,Flyfox717,1570808225,"Im 16 years old, and I didnt study anything about linear algebra yet, but I want to learn ML with Python. So, is that necessary?",0,1,False,self,,,,,
623,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,0,dggxl9,self.MachineLearning,"[R] Hi, Im looking at different ways of assessing wellbeing using surveys and NLP.",https://www.reddit.com/r/MachineLearning/comments/dggxl9/r_hi_im_looking_at_different_ways_of_assessing/,youngfounderunsure,1570808388,"Could you fill that form please ? I want to use responses to train a model
[survey](https://forms.gle/RwJ2vHto2xa3mqav6)",0,3,False,self,,,,,
624,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,1,dghdk7,self.MachineLearning,How cool it would be to transform VHS into HD quality,https://www.reddit.com/r/MachineLearning/comments/dghdk7/how_cool_it_would_be_to_transform_vhs_into_hd/,armase,1570810330,[removed],0,1,False,self,,,,,
625,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,1,dghlbz,self.MachineLearning,New to machine learning,https://www.reddit.com/r/MachineLearning/comments/dghlbz/new_to_machine_learning/,Rapiz,1570811306,[removed],0,1,False,self,,,,,
626,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,1,dghqeo,self.MachineLearning,What to expect from technical case study interview?,https://www.reddit.com/r/MachineLearning/comments/dghqeo/what_to_expect_from_technical_case_study_interview/,the_lonk55,1570811920,[removed],0,1,False,self,,,,,
627,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,1,dghs82,venturebeat.com,Facebook launches PyTorch Mobile for edge ML on Android and iOS devices,https://www.reddit.com/r/MachineLearning/comments/dghs82/facebook_launches_pytorch_mobile_for_edge_ml_on/,TheTesseractAcademy,1570812158,,0,1,False,https://b.thumbs.redditmedia.com/F99VG-56mkW3ahBHiXU26--JqzyDdf42BIYDgO8d22Q.jpg,,,,,
628,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,1,dghv73,self.MachineLearning,[D] What to expect from technical case study interview?,https://www.reddit.com/r/MachineLearning/comments/dghv73/d_what_to_expect_from_technical_case_study/,the_lonk55,1570812530,I just got an offer for a phone interview for a machine learning intership and part of it is a technical case study. I have looked up examples online and they seem complex. All of my knowledge of machine learning is self taught and more hands on so I really only know HOW to apply machine learning techniques and don't know much about WHEN to apply them. Can people provide some things interviewers are looking for in this case study and perhaps some material I should learn before hand. Thank you!,2,4,False,self,,,,,
629,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,2,dgi2yq,youtu.be,Siraj is having a live Q&amp;A right now,https://www.reddit.com/r/MachineLearning/comments/dgi2yq/siraj_is_having_a_live_qa_right_now/,abstractgoomba,1570813516,,0,1,False,https://b.thumbs.redditmedia.com/wgeWt8_IW1y87j-uAeNimP2ICkFXo8zzyVU0EJz7LLY.jpg,,,,,
630,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,2,dgi42v,ai.googleblog.com,"Exploring Massively Multilingual, Massive Neural Machine Translation",https://www.reddit.com/r/MachineLearning/comments/dgi42v/exploring_massively_multilingual_massive_neural/,sjoerdapp,1570813650,,0,1,False,default,,,,,
631,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,2,dgi53d,audiostellar.xyz,AudioStellar 0.9.0 released,https://www.reddit.com/r/MachineLearning/comments/dgi53d/audiostellar_090_released/,macramole,1570813772,,1,1,False,default,,,,,
632,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,2,dgi6pn,self.MachineLearning,Extract General Purpose Features from Pre-Trained Model,https://www.reddit.com/r/MachineLearning/comments/dgi6pn/extract_general_purpose_features_from_pretrained/,ihababdk,1570813979,[removed],0,1,False,self,,,,,
633,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,2,dgi6yw,youtube.com,"Siraj Raval is doing a live session now on YouTube - ""I made mistakes. But nobody is hurt.""",https://www.reddit.com/r/MachineLearning/comments/dgi6yw/siraj_raval_is_doing_a_live_session_now_on/,SimilarFlow,1570814011,,0,1,False,default,,,,,
634,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,2,dgia80,self.MachineLearning,"Get creative, I'm looking for project ideas involving simulation",https://www.reddit.com/r/MachineLearning/comments/dgia80/get_creative_im_looking_for_project_ideas/,ajaderade,1570814409,[removed],0,1,False,self,,,,,
635,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,2,dgie6z,self.MachineLearning,Trying to learn more about auto regression for certain stock prices in machine learning,https://www.reddit.com/r/MachineLearning/comments/dgie6z/trying_to_learn_more_about_auto_regression_for/,TYLER_DURDEN_JIMMY,1570814927,[removed],0,1,False,self,,,,,
636,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,2,dgiq7n,self.MachineLearning,Current Neural Net Forwarding in WinXP,https://www.reddit.com/r/MachineLearning/comments/dgiq7n/current_neural_net_forwarding_in_winxp/,crazyhh,1570816418,[removed],0,1,False,self,,,,,
637,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,3,dgiumb,self.MachineLearning,It is absolutely unethical to exploit 'self learning'.,https://www.reddit.com/r/MachineLearning/comments/dgiumb/it_is_absolutely_unethical_to_exploit_self/,n2901,1570816960,[removed],0,1,False,self,,,,,
638,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,3,dgixpm,i.redd.it,I can't believe it.... GPT2 774M,https://www.reddit.com/r/MachineLearning/comments/dgixpm/i_cant_believe_it_gpt2_774m/,orenog,1570817340,,0,1,False,default,,,,,
639,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,3,dgixqn,i.redd.it,I can't believe it.... GPT2 774M,https://www.reddit.com/r/MachineLearning/comments/dgixqn/i_cant_believe_it_gpt2_774m/,orenog,1570817346,,0,1,False,default,,,,,
640,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,3,dgj178,medium.com,OpenCV-Inspired Kornia Is a Differentiable Computer Vision Library for PyTorch,https://www.reddit.com/r/MachineLearning/comments/dgj178/opencvinspired_kornia_is_a_differentiable/,Yuqing7,1570817799,,0,1,False,default,,,,,
641,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,3,dgji2l,self.MachineLearning,"[R] [D] NLP, Any papers on text summarization on very long (arbitrary length) text?",https://www.reddit.com/r/MachineLearning/comments/dgji2l/r_d_nlp_any_papers_on_text_summarization_on_very/,natural_language_guy,1570819914,"Hi, I'm catching up on the text summarization scene and most of the papers I have seen are using the CNN,newsroom,xsum datasets; but the max document size for any of these seem to be \~1000 tokens. Are there any papers that deal with very long (or arbitrary) document lengths?

As I understand it, most of the SOTA now is transformer based and they are bound by the # of positional embeddings in use.",2,1,False,self,,,,,
642,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,5,dgl7de,self.MachineLearning,[R] Looking for an ML platform that also allows for integration with business users?,https://www.reddit.com/r/MachineLearning/comments/dgl7de/r_looking_for_an_ml_platform_that_also_allows_for/,AlexSnakeKing,1570827503,"I have the following overall requirement for an ML platform:

* Ability for the data engineering team to build pipelines and integrate with ERP apps (hybrid on-prem/cloud), and run and monitor models in production, and store results of the models. 
* Ability for the data science team to perform EDA and run experiments, and then push models to production as needed. 
* Ability for business users (who are not technical and do not know how to code) to interact with the data, not just view reports: Perform Excel like calculations, override predictions that they disagree with, run what-if simulations, etc....and then commit any changes back to the data store. 

I have seen multiple ML platforms that provide the first two components, but the business use part is always just a washboarding capability, not a real interface like the one I described. 

Does anybody provide anything like this?",5,1,False,self,,,,,
643,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,6,dgla6o,self.MachineLearning,The precisionFDA BioCompute Object App-a-thon submission period ends in 1 week!,https://www.reddit.com/r/MachineLearning/comments/dgla6o/the_precisionfda_biocompute_object_appathon/,hollystephens723,1570827865," Theres one week left to enhance the reproducibility and documentation of computational pipelines in the precisionFDA BioCompute Object (BCO) App-a-thon, in partnership with George Washington University and CBER/FDA Hive. The submission period ends 10/18. Submit today at [https://go.usa.gov/xVthd](https://go.usa.gov/xVthd)",0,1,False,self,,,,,
644,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,6,dgltfb,self.MachineLearning,"Learning with ""noisy data"" (but perfect labels)",https://www.reddit.com/r/MachineLearning/comments/dgltfb/learning_with_noisy_data_but_perfect_labels/,viviandefeater,1570830376,[removed],0,1,False,self,,,,,
645,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,7,dgmg9v,self.MachineLearning,"Machine Learning Engineer Salaries - level, field, location.",https://www.reddit.com/r/MachineLearning/comments/dgmg9v/machine_learning_engineer_salaries_level_field/,shahifaqeer,1570833446,[removed],0,1,False,self,,,,,
646,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,8,dgn93m,self.MachineLearning,Possible to run models in the browser without divulging key data?,https://www.reddit.com/r/MachineLearning/comments/dgn93m/possible_to_run_models_in_the_browser_without/,HotpotGraphicDesign,1570837330,[removed],0,1,False,self,,,,,
647,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,9,dgnpcb,self.MachineLearning,"[D] Learning with ""noisy data"" (but perfect labels)",https://www.reddit.com/r/MachineLearning/comments/dgnpcb/d_learning_with_noisy_data_but_perfect_labels/,viviandefeater,1570839641,"There are many works that deal with noisy labels, but has the problem of unreliable data (but reliable labels) been studied? In other words, problems where the data to be classified is imperfect and not always sufficient to determine the class label.

An example would be a model that predicts the city in which a photo was taken. Ground truth labels would be perfect thanks to GPS metadata. If the photo contains the Eiffel Tower, we can predict that the city is Paris. But many pictures contain no useful information; for example a photo of a dog or a McDonald's is nearly useless for determining the city.

How best to train a classifier when such ""noisy examples"" (for lack of a better term) are very common?",9,9,False,self,,,,,
648,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,10,dgoais,self.MachineLearning,"How to train a simple, vanilla transformers translation model from scratch with Fairseq",https://www.reddit.com/r/MachineLearning/comments/dgoais/how_to_train_a_simple_vanilla_transformers/,md1630,1570842750,[removed],0,1,False,self,,,,,
649,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,10,dgog2h,self.MachineLearning,[D] Why is L2 preferred over L1 Regularization?,https://www.reddit.com/r/MachineLearning/comments/dgog2h/d_why_is_l2_preferred_over_l1_regularization/,tshrjn,1570843579,"I understand L1 regularization induces sparsity, and is thus, good for cases when it's required.

But In normal use cases, what are the benefits of using L2 over L1?
If it's just that weights should be smaller, then why can't we use L4 for example?

I've seen mentions of L2 capturing energy, Euclidean distance and being rotation invariant. Could one explain these more explicitly as to how this happens?",126,153,False,self,,,,,
650,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,10,dgokc0,nyti.ms,[N] Potential for legislation over the use of the MegaFace dataset,https://www.reddit.com/r/MachineLearning/comments/dgokc0/n_potential_for_legislation_over_the_use_of_the/,dojoteef,1570844218,,0,1,False,default,,,,,
651,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,11,dgourc,self.MachineLearning,Can I hire someone to develop an AI and machine learning engine like BrightEdge?,https://www.reddit.com/r/MachineLearning/comments/dgourc/can_i_hire_someone_to_develop_an_ai_and_machine/,Xodnil,1570845785,[removed],0,1,False,self,,,,,
652,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,11,dgow14,self.MachineLearning,Should I have a Statistics or Math minor for Deep Learning?,https://www.reddit.com/r/MachineLearning/comments/dgow14/should_i_have_a_statistics_or_math_minor_for_deep/,pitin753,1570845976,[removed],0,1,False,self,,,,,
653,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,12,dgpn1c,self.MachineLearning,[D] Possible to run models in the browser without divulging key data?,https://www.reddit.com/r/MachineLearning/comments/dgpn1c/d_possible_to_run_models_in_the_browser_without/,HotpotGraphicDesign,1570850087,[removed],0,1,False,self,,,,,
654,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,12,dgq1dz,self.MachineLearning,Machine Learning for Physics and Physics of Learning,https://www.reddit.com/r/MachineLearning/comments/dgq1dz/machine_learning_for_physics_and_physics_of/,aiforworld2,1570852393,[removed],0,1,False,self,,,,,
655,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,13,dgqkmj,self.MachineLearning,9th International Conference on Data Mining &amp; Knowledge Management Process (CDKP 2020),https://www.reddit.com/r/MachineLearning/comments/dgqkmj/9th_international_conference_on_data_mining/,ijistjournal,1570855680,[removed],0,1,False,self,,,,,
656,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,15,dgrdnv,self.MachineLearning,[D] Named tensors in the new PyTorch version - what are the advantages compared to tsalib?,https://www.reddit.com/r/MachineLearning/comments/dgrdnv/d_named_tensors_in_the_new_pytorch_version_what/,dev-ai,1570861148,"In the new PyTorch version, there is experimental support for named tensors, which looks like a big deal for example when vectorizing a pipeline or something of the sort. The idea has been floating in the community for a while, I think it will greatly help with axis bugs. What I am not sure is what advantages does it bring compared to, say tsalib?

[https://pytorch.org/docs/stable/named\_tensor.html](https://pytorch.org/docs/stable/named_tensor.html)

[http://nlp.seas.harvard.edu/NamedTensor](http://nlp.seas.harvard.edu/NamedTensor)

[https://github.com/ofnote/tsalib](https://github.com/ofnote/tsalib)",6,4,False,self,,,,,
657,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,15,dgrevm,self.MachineLearning,Research Subject Suggestions in RL Combined with CV for a Master's Degree,https://www.reddit.com/r/MachineLearning/comments/dgrevm/research_subject_suggestions_in_rl_combined_with/,H_uuu,1570861386,[removed],0,1,False,self,,,,,
658,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,15,dgrfbn,self.MachineLearning,Which Solenoid Valve Is Best For Air Pollution Control?,https://www.reddit.com/r/MachineLearning/comments/dgrfbn/which_solenoid_valve_is_best_for_air_pollution/,uflowindia,1570861471,[removed],0,1,False,https://b.thumbs.redditmedia.com/j-8mxday23mc2O3SUqRUjSKitWkG9rJuv3u_3Znnp7w.jpg,,,,,
659,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,15,dgrid4,youtu.be,A Google interview Question,https://www.reddit.com/r/MachineLearning/comments/dgrid4/a_google_interview_question/,DragonDorf7,1570862102,,1,1,False,default,,,,,
660,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,15,dgroou,self.MachineLearning,[R] How Youtube is recommending your next video,https://www.reddit.com/r/MachineLearning/comments/dgroou/r_how_youtube_is_recommending_your_next_video/,elftim,1570863404,Recently I came across a paper of Google that was describing how their recommendation algorithm works for Youtube. I wrote my own summary and key takeaways down. Check it out my paper review [here](https://medium.com/vantageai/how-youtube-is-recommending-your-next-video-7e5f1a6bd6d9).,45,733,False,self,,,,,
661,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,16,dgrzbv,self.MachineLearning,"How do you identify a top article in the field of artificial intelligence such as Deep Landing, Machine Learning, etc.?",https://www.reddit.com/r/MachineLearning/comments/dgrzbv/how_do_you_identify_a_top_article_in_the_field_of/,Doctor_who1,1570865680,[removed],0,1,False,self,,,,,
662,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,17,dgscyt,self.MachineLearning,What's the general consensus on TensorFlow 2.0,https://www.reddit.com/r/MachineLearning/comments/dgscyt/whats_the_general_consensus_on_tensorflow_20/,Flamyngoo,1570868616,[removed],0,1,False,self,,,,,
663,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,18,dgt4qp,self.MachineLearning,Labeling tool for NER + sentiment + intent,https://www.reddit.com/r/MachineLearning/comments/dgt4qp/labeling_tool_for_ner_sentiment_intent/,Zylatis,1570874183,[removed],0,1,False,self,,,,,
664,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,19,dgtaop,github.com,[P] EMNLP 2019: Statistics and Accepted paper list with arXiv link,https://www.reddit.com/r/MachineLearning/comments/dgtaop/p_emnlp_2019_statistics_and_accepted_paper_list/,roomylee,1570875330,,0,1,False,default,,,,,
665,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,19,dgtb5l,github.com,[P] EMNLP 2019: Statistics and Accepted paper list with arXiv link,https://www.reddit.com/r/MachineLearning/comments/dgtb5l/p_emnlp_2019_statistics_and_accepted_paper_list/,roomylee,1570875420,,0,1,False,https://b.thumbs.redditmedia.com/FATpMcDfKoqfxuIMMof3afQAPnHTZ6_hdyQX-VVHFEs.jpg,,,,,
666,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,19,dgtbql,self.MachineLearning,[P] EMNLP 2019: Statistics and Accepted paper list with arXiv link,https://www.reddit.com/r/MachineLearning/comments/dgtbql/p_emnlp_2019_statistics_and_accepted_paper_list/,roomylee,1570875551,[removed],0,1,False,self,,,,,
667,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,19,dgtc42,self.MachineLearning,[Q] I'm writing an essay for a high school project on the value of truth in the media. I'd like to pitch my idea using a deep fake video,https://www.reddit.com/r/MachineLearning/comments/dgtc42/q_im_writing_an_essay_for_a_high_school_project/,RickDeveloper,1570875626,[removed],0,1,False,self,,,,,
668,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,19,dgtcuo,self.MachineLearning,[P] d,https://www.reddit.com/r/MachineLearning/comments/dgtcuo/p_d/,roomylee,1570875764,[removed],0,1,False,self,,,,,
669,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,19,dgtdao,self.MachineLearning,[Project] projcet,https://www.reddit.com/r/MachineLearning/comments/dgtdao/project_projcet/,roomylee,1570875845,[removed],0,1,False,self,,,,,
670,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,19,dgtfib,github.com,[P] EMNLP 2019 Statistics and Accepted paper list with arXiv link,https://www.reddit.com/r/MachineLearning/comments/dgtfib/p_emnlp_2019_statistics_and_accepted_paper_list/,roomylee,1570876317,,0,1,False,default,,,,,
671,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,19,dgtggr,github.com,"""[P]"" EMNLP-2019-Papers: Statistics and Accepted paper list with arXiv link",https://www.reddit.com/r/MachineLearning/comments/dgtggr/p_emnlp2019papers_statistics_and_accepted_paper/,roomylee,1570876500,,0,1,False,https://b.thumbs.redditmedia.com/FATpMcDfKoqfxuIMMof3afQAPnHTZ6_hdyQX-VVHFEs.jpg,,,,,
672,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,19,dgtj10,github.com,[P] EMNLP-2019-Papers: Statistics and Accepted paper list with arXiv link,https://www.reddit.com/r/MachineLearning/comments/dgtj10/p_emnlp2019papers_statistics_and_accepted_paper/,roomylee,1570877004,,0,1,False,https://b.thumbs.redditmedia.com/FATpMcDfKoqfxuIMMof3afQAPnHTZ6_hdyQX-VVHFEs.jpg,,,,,
673,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,19,dgtk7n,github.com,[P] EMNLP 2019 Statistics and Accepted Papers with arXiv link,https://www.reddit.com/r/MachineLearning/comments/dgtk7n/p_emnlp_2019_statistics_and_accepted_papers_with/,roomylee,1570877239,,0,1,False,https://b.thumbs.redditmedia.com/FATpMcDfKoqfxuIMMof3afQAPnHTZ6_hdyQX-VVHFEs.jpg,,,,,
674,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,19,dgtkel,github.com,[P] EMNLP 2019 Statistics and Accepted Papers with arXiv Link,https://www.reddit.com/r/MachineLearning/comments/dgtkel/p_emnlp_2019_statistics_and_accepted_papers_with/,roomylee,1570877278,,0,1,False,https://b.thumbs.redditmedia.com/FATpMcDfKoqfxuIMMof3afQAPnHTZ6_hdyQX-VVHFEs.jpg,,,,,
675,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,19,dgtkxn,self.MachineLearning,[D] Transfer learning on GANs?,https://www.reddit.com/r/MachineLearning/comments/dgtkxn/d_transfer_learning_on_gans/,roomylee,1570877392,The,0,1,False,self,,,,,
676,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,19,dgtl1j,self.MachineLearning,[P] Sotabench: Benchmarking Every Open Source Model,https://www.reddit.com/r/MachineLearning/comments/dgtl1j/p_sotabench_benchmarking_every_open_source_model/,roomylee,1570877422,d,0,1,False,self,,,,,
677,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,19,dgtl98,github.com,[P] EMNLP 2019 Statistics ans Accepted Papers with arXiv Link,https://www.reddit.com/r/MachineLearning/comments/dgtl98/p_emnlp_2019_statistics_ans_accepted_papers_with/,roomylee,1570877460,,0,1,False,https://b.thumbs.redditmedia.com/FATpMcDfKoqfxuIMMof3afQAPnHTZ6_hdyQX-VVHFEs.jpg,,,,,
678,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,19,dgtly1,self.MachineLearning,Concise Visual Summary of Deep Learning Architectures,https://www.reddit.com/r/MachineLearning/comments/dgtly1/concise_visual_summary_of_deep_learning/,andrea_manero,1570877588,[removed],0,1,False,self,,,,,
679,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,20,dgu4kk,i.redd.it,Repeat,https://www.reddit.com/r/MachineLearning/comments/dgu4kk/repeat/,allessandro,1570880979,,0,1,False,default,,,,,
680,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,21,dgu9gh,aaa,[P] aaa,https://www.reddit.com/r/MachineLearning/comments/dgu9gh/p_aaa/,roomylee,1570881793,,0,1,False,default,,,,,
681,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,21,dgu9n8,aaa,[P] Ranking data handlers based on stati,https://www.reddit.com/r/MachineLearning/comments/dgu9n8/p_ranking_data_handlers_based_on_stati/,roomylee,1570881822,,0,1,False,default,,,,,
682,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,21,dgu9pf,self.MachineLearning,[P] Ranking data handlers based on stati,https://www.reddit.com/r/MachineLearning/comments/dgu9pf/p_ranking_data_handlers_based_on_stati/,roomylee,1570881834,aaa,0,1,False,self,,,,,
683,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,21,dgu9s4,self.MachineLearning,[P] Ranking dddd,https://www.reddit.com/r/MachineLearning/comments/dgu9s4/p_ranking_dddd/,roomylee,1570881848,dd,0,1,False,self,,,,,
684,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,21,dgua2s,self.MachineLearning,[P] EMNLP 2019 Statistics and Accepted Papers with arXiv Link,https://www.reddit.com/r/MachineLearning/comments/dgua2s/p_emnlp_2019_statistics_and_accepted_papers_with/,roomylee,1570881890,[removed],0,1,False,self,,,,,
685,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,21,dgua9z,self.MachineLearning,[P] Raeee,https://www.reddit.com/r/MachineLearning/comments/dgua9z/p_raeee/,roomylee,1570881928,eee,0,1,False,self,,,,,
686,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,21,dguah9,self.MachineLearning,[P] EMNLP 2019 Statistics and,https://www.reddit.com/r/MachineLearning/comments/dguah9/p_emnlp_2019_statistics_and/,roomylee,1570881956,[removed],0,1,False,self,,,,,
687,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,21,dgualf,self.MachineLearning,[P] REMNLP 2019 Statistics,https://www.reddit.com/r/MachineLearning/comments/dgualf/p_remnlp_2019_statistics/,roomylee,1570881975,[removed],0,1,False,self,,,,,
688,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,21,dguaon,self.MachineLearning,[P] RankEMNLP,https://www.reddit.com/r/MachineLearning/comments/dguaon/p_rankemnlp/,roomylee,1570881991,aaa,0,1,False,self,,,,,
689,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,21,dguarg,self.MachineLearning,[P] RankEMNLP 2019,https://www.reddit.com/r/MachineLearning/comments/dguarg/p_rankemnlp_2019/,roomylee,1570882005,aaa,0,1,False,self,,,,,
690,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,21,dguavd,self.MachineLearning,[P] EMNLP 2019,https://www.reddit.com/r/MachineLearning/comments/dguavd/p_emnlp_2019/,roomylee,1570882026,aaa,0,1,False,self,,,,,
691,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,21,dgub2a,self.MachineLearning,[P] RankEMNLP 2019 Statistics and Accepted Papers with arXiv Link,https://www.reddit.com/r/MachineLearning/comments/dgub2a/p_rankemnlp_2019_statistics_and_accepted_papers/,roomylee,1570882060,aaa,0,1,False,self,,,,,
692,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,21,dgub7y,self.MachineLearning,[P] EMNLP 2019 Statistics and Accepted Papers with arXiv Link,https://www.reddit.com/r/MachineLearning/comments/dgub7y/p_emnlp_2019_statistics_and_accepted_papers_with/,roomylee,1570882095,aaa,0,1,False,self,,,,,
693,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,21,dguboc,github.com,[P] EMNLP 2019 Statistics and Accepted Papers with arXiv Link,https://www.reddit.com/r/MachineLearning/comments/dguboc/p_emnlp_2019_statistics_and_accepted_papers_with/,roomylee,1570882165,,0,1,False,https://b.thumbs.redditmedia.com/FATpMcDfKoqfxuIMMof3afQAPnHTZ6_hdyQX-VVHFEs.jpg,,,,,
694,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,21,dgubso,aaa,[P] Ranking data handlers based on stat,https://www.reddit.com/r/MachineLearning/comments/dgubso/p_ranking_data_handlers_based_on_stat/,roomylee,1570882186,,0,1,False,default,,,,,
695,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,21,dgune2,self.MachineLearning,How to calcul the correlation between time series and a variable,https://www.reddit.com/r/MachineLearning/comments/dgune2/how_to_calcul_the_correlation_between_time_series/,moon8087,1570884100,[removed],0,1,False,self,,,,,
696,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,21,dgunie,self.MachineLearning,[N] Potential for legislation over the use of the MegaFace dataset,https://www.reddit.com/r/MachineLearning/comments/dgunie/n_potential_for_legislation_over_the_use_of_the/,dojoteef,1570884122,"It seems as though there is an Illinois state law that could be violated with the use of the MegaFace dataset. From the article:

&gt; By law, most Americans in the database dont need to be asked for their permission  but the Papas should have been.
&gt; 
&gt; As residents of Illinois, they are protected by one of the strictest state privacy laws on the books: the Biometric Information Privacy Act, a 2008 measure that imposes financial penalties for using an Illinoisans fingerprints or face scans without consent. Those who used the database  companies including Google, Amazon, Mitsubishi Electric, Tencent and SenseTime  appear to have been unaware of the law, and as a result may have huge financial liability, according to several lawyers and law professors familiar with the legislation.

I'm just wondering how best to ensure researchers factor these concerns in when collecting massive datasets online. For example, I've recently collected a text dataset for my research. What do you all do to account for people's privacy when collecting data?",5,12,False,self,,,,,
697,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,22,dgvasa,self.MachineLearning,Is my tictactoe bot logic correct?,https://www.reddit.com/r/MachineLearning/comments/dgvasa/is_my_tictactoe_bot_logic_correct/,lowtoxic,1570887715,[removed],0,1,False,self,,,,,
698,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,22,dgvea1,self.MachineLearning,[N] Google AI Research Division To Issue PhD Degrees,https://www.reddit.com/r/MachineLearning/comments/dgvea1/n_google_ai_research_division_to_issue_phd_degrees/,Salt_Pudding,1570888254,"Article Link: [https://medium.com/halting-problem/google-ai-research-division-to-issue-phd-degrees-8a6954293047](https://medium.com/halting-problem/google-ai-research-division-to-issue-phd-degrees-8a6954293047)

**MOUNTAIN VIEW, CALIFORNIA**  In a move that is completely unsurprising to many, Googles AI research division has announced that they are issuing PhD degrees to select employees.

Industry research organizations like Google Brain, DeepMind, and FAIR are well known as heavy hitters in the artificial intelligence research community, publishing as many papers (if not more) as academic institutions like Stanford, Berkeley, and MIT. Many top professors from academia have migrated over to industry research labs as well, sacrificing the security of academic tenure for fat stacks of money. Although Google has previously experimented with research [residencies](https://ai.google/research/join-us/ai-residency/), this is the first time that they have issued postgraduate degrees.

According to a representative, the tech giant decided to issue PhDs in order to attract scarce AI talent. Its extremely difficult to find people with talent in Machine Learning and Artificial Intelligence these days, and it pained us to see so many of our amazing interns decline our return offers to go back to school for PhDs. With the Google PhD program, we can continue to get the best talent while supporting our student-employees with world class resources and technology.

For graduate students, the Google PhD program is a sweet deal. There is already a well-known pipeline where top graduate students do their PhDs at a university, intern at industry research groups during the summer, and then sign on full time after graduation with the promise of million-dollar compensation packages and the freedom to set their own research agendas.

However, aspiring AI researchers must still struggle through the difficulties of academia: four to six years of low pay, begging for funding, and advisors who can be sadistic, micromanaging, or absent. In contrast, Google offers researchers massive computational resources and motivates their PhD advisors with a potent combination of vegan snacks, kombucha, and equity refreshers. Instead of receiving a boring paper diploma at the end of their PhDs, Google PhD graduates receive a priceless note handwritten by Jeff Dean on a napkin that says, You have a PhD now.

Other tech companies are scrambling to build their own research groups so they are not left behind in the AI revolution. Halting Problem reached out to a representative from Salesforce AI Research who said, What? Google is doing it? Well, guess we are too.

In the meantime, Google is already planning for the next way to find top AI talent. According to a knowledgeable source, Google is in talks with Khan Academy to create a machine learning kindergarten program that teaches children Tensorflow.",9,0,False,self,,,,,
699,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,22,dgvgvo,technologyreview.com,Machine vision has learned to use radio waves to see through walls and in darkness,https://www.reddit.com/r/MachineLearning/comments/dgvgvo/machine_vision_has_learned_to_use_radio_waves_to/,jonfla,1570888624,,0,1,False,default,,,,,
700,MachineLearning,t5_2r3gv,2019-10-12,2019,10,12,23,dgvksm,self.MachineLearning,How important is company reputation for machine learning career,https://www.reddit.com/r/MachineLearning/comments/dgvksm/how_important_is_company_reputation_for_machine/,mellow54,1570889165,[removed],1,1,False,self,,,,,
701,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,1,dgx5ll,github.com,[P] EMNLP 2019 Statistics and Accepted Papers with arXiv Link,https://www.reddit.com/r/MachineLearning/comments/dgx5ll/p_emnlp_2019_statistics_and_accepted_papers_with/,roomylee,1570896759,,0,1,False,https://b.thumbs.redditmedia.com/FATpMcDfKoqfxuIMMof3afQAPnHTZ6_hdyQX-VVHFEs.jpg,,,,,
702,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,1,dgx5sv,self.MachineLearning,[P] EMNLP 2019 Statistics and Accepted Papers with arXiv Link,https://www.reddit.com/r/MachineLearning/comments/dgx5sv/p_emnlp_2019_statistics_and_accepted_papers_with/,roomylee,1570896788,[removed],0,1,False,self,,,,,
703,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,1,dgx925,self.MachineLearning,Pytorch 1.3 is not getting installed. How do I install it?,https://www.reddit.com/r/MachineLearning/comments/dgx925/pytorch_13_is_not_getting_installed_how_do_i/,spawnofdexter,1570897215,[removed],0,1,False,self,,,,,
704,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,1,dgxczt,self.MachineLearning,Urban8k audio dataset classification,https://www.reddit.com/r/MachineLearning/comments/dgxczt/urban8k_audio_dataset_classification/,jackandjill9189,1570897720,[removed],0,1,False,self,,,,,
705,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,1,dgxfvg,youtu.be,AI for Suggestive Drawing and Image Editing,https://www.reddit.com/r/MachineLearning/comments/dgxfvg/ai_for_suggestive_drawing_and_image_editing/,arnabgho,1570898080,,0,1,False,https://a.thumbs.redditmedia.com/QF7KvYURAvBJXxjfDmQ_7THTpEwFLyks5fmRGXyOD80.jpg,,,,,
706,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,2,dgy0ww,self.MachineLearning,Help me explain the google research statistics of Keras,https://www.reddit.com/r/MachineLearning/comments/dgy0ww/help_me_explain_the_google_research_statistics_of/,Atralb,1570900800,[removed],0,1,False,self,,,,,
707,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,4,dgzmbx,self.MachineLearning,"Reinforcement learning in different ""environments""",https://www.reddit.com/r/MachineLearning/comments/dgzmbx/reinforcement_learning_in_different_environments/,Underthatree,1570908204,[removed],0,1,False,self,,,,,
708,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,5,dh0aak,self.MachineLearning,[D] How to deal with my research not being acknowledged ?,https://www.reddit.com/r/MachineLearning/comments/dh0aak/d_how_to_deal_with_my_research_not_being/,tablehoarder,1570911390,"This might sound off-topic to this sub, but I feel like this is a problem that is way more common in the ML community. I've  heard others peers who do research in ML complaining about the same thing.

Now to the problem: I'm from a little-known department, doing a PhD with a little-known advisor, and most of my research gets published in the main ML conferences (NeurIPS, ICML, ICLR, or CVPR). However, it seems that the community simply ignores that my research exist. There are two specific papers from big labs whose idea and experiments are extremely close to papers of mine from at least 1 year before -- these papers have now over 500 citations and don't mention my papers at all (which have less than 20 citations each, currently).

For example, last year I've published a computer vision paper that got strong results in segmentation and detection tasks. This year I've seen at least 4 papers being published that have weaker results on the same task, using the same base architecture, and do not compare nor reference my work from last year. All of these 4 papers claim to have the state-of-the-art, and compare against each other (the most recent ones compare their results against all the previous ones, that is). One of these papers has over 200 citations while my paper currently has 4.

Is there anything I can do to make my research more visible? I'm on the verge on quitting my PhD because not having my work acknowledged is simply terrible for me, especially since this happens with my research in general, and not only a few papers that I've published. I've tried contacting authors from these papers, but I typically get a reply saying that they were not aware of my work and agreed that it was extremely relevant, but they don't go through the trouble of updating their submissions to reference me.",63,115,False,self,,,,,
709,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,5,dh0dbg,link.medium.com,Tutorial: Making Road Traffic Counting App based on Computer Vision and OpenCV,https://www.reddit.com/r/MachineLearning/comments/dh0dbg/tutorial_making_road_traffic_counting_app_based/,creotiv,1570911789,,0,1,False,default,,,,,
710,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,5,dh0i8h,self.MachineLearning,Who is currently working with knowledge graph?,https://www.reddit.com/r/MachineLearning/comments/dh0i8h/who_is_currently_working_with_knowledge_graph/,michaelgruen99,1570912455,[removed],0,1,False,self,,,,,
711,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,5,dh0jkl,self.MachineLearning,Text generating AI,https://www.reddit.com/r/MachineLearning/comments/dh0jkl/text_generating_ai/,marcomanny,1570912629,[removed],0,1,False,self,,,,,
712,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,6,dh136d,self.MachineLearning,[P] MAX: Open Deep Learning models on Docker containers,https://www.reddit.com/r/MachineLearning/comments/dh136d/p_max_open_deep_learning_models_on_docker/,kmh4321,1570915192,"Hello!  
I work for an open-source [team](https://developer.ibm.com/code/open/centers/codait/projects/) at IBM. For a year now we have been working on a project called Model Asset eXchange (MAX). The goal of this project is to standardize DL model deployment and consumption. The idea is to make it easier to integrate DL models into web apps and services or deploy it on any cloud platform. So far we have around 25 models as part of this project. Most underlying models themselves are SOTA open-sourced models from various sources and model zoos (Tf/PyTorch/google research/IBM research etc). The value addition that this project offers is a standardized interface to any model using REST API, containerization and optimizations during inference such as loading the graph just once but performing inference based on every API call. Each model has its own github repo and for convenience, we have also hosted the Docker container on a public endpoint for people to try it out. Where possible we have also extended deployment channels to other avenues, such as NodeRed (npm), CodePen, demo web apps, etc. 
I would like your feedback/suggestions and of course, welcome any issues/pull request on the underlying github repos as well!

Project link: https://developer.ibm.com/exchanges/models/
A model with all deployment options: https://developer.ibm.com/exchanges/models/all/max-object-detector/ 
Note: the GitHub link (marked  ""Get this Model"") for each model is separate",5,10,False,self,,,,,
713,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,8,dh2cd0,twitter.com,Siraj has a new paper: 'The Neural Qubit'. It's plagiarised. Exposed in this twitter thread,https://www.reddit.com/r/MachineLearning/comments/dh2cd0/siraj_has_a_new_paper_the_neural_qubit_its/,grey--area,1570921213,,0,1,False,default,,,,,
714,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,8,dh2hw8,self.MachineLearning,Transfer Learning for Survival Models,https://www.reddit.com/r/MachineLearning/comments/dh2hw8/transfer_learning_for_survival_models/,stat_leaf,1570921979,[removed],0,1,False,self,,,,,
715,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,8,dh2ku3,self.MachineLearning,about deep learning neural network,https://www.reddit.com/r/MachineLearning/comments/dh2ku3/about_deep_learning_neural_network/,loopy_fun,1570922397,[removed],0,1,False,self,,,,,
716,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,8,dh2p98,self.MachineLearning,"[D] Siraj's lies continue: Siraj's ""recent Neural Qubit paper"" was largely plagiarized",https://www.reddit.com/r/MachineLearning/comments/dh2p98/d_sirajs_lies_continue_sirajs_recent_neural_qubit/,LaVieEstBizarre,1570922986,[removed],0,1,False,self,,,,,
717,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,8,dh2scw,self.MachineLearning,Siraj has a new paper: 'The Neural Qubit'. It's massively plagiarised. Exposed in linked to twitter thread,https://www.reddit.com/r/MachineLearning/comments/dh2scw/siraj_has_a_new_paper_the_neural_qubit_its/,grey--area,1570923408,"Exposed here: [https://twitter.com/AndrewM_Webb/status/1183150368945049605](https://twitter.com/AndrewM_Webb/status/1183150368945049605)

Huge chunks of text, figures, tables, captions, equations (with the same equation numbers as the original, because they're screenshots) are all lifted.

Siraj's paper: http://vixra.org/pdf/1909.0060v1.pdf
The plagiarised paper: https://arxiv.org/pdf/1806.06871.pdf",0,1,False,self,,,,,
718,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,8,dh2xfs,self.MachineLearning,[D] Siraj has a new paper: 'The Neural Qubit'. It's plagiarised,https://www.reddit.com/r/MachineLearning/comments/dh2xfs/d_siraj_has_a_new_paper_the_neural_qubit_its/,grey--area,1570924133,"Exposed in this Twitter thread: https://twitter.com/AndrewM_Webb/status/1183150368945049605

Text, figures, tables, captions, equations (even equation numbers) are all lifted from another paper with minimal changes.

Siraj's paper: http://vixra.org/pdf/1909.0060v1.pdf

The plagiarised paper: https://arxiv.org/pdf/1806.06871.pdf",530,2271,False,self,,,,,
719,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,9,dh3255,self.MachineLearning,"I'm diving in! Coder for decades, but it's 100 resumes for every iOS job so HR tells me. Medical background, was wondering X-Ray, CAT, etc public scans? Making the move from iOS to AI/ML.",https://www.reddit.com/r/MachineLearning/comments/dh3255/im_diving_in_coder_for_decades_but_its_100/,ejpusa,1570924814,[removed],0,1,False,self,,,,,
720,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,9,dh3h04,self.MachineLearning,Soil sample dimensionality reduction? TSNE?,https://www.reddit.com/r/MachineLearning/comments/dh3h04/soil_sample_dimensionality_reduction_tsne/,Aesix,1570926976,[removed],0,1,False,self,,,,,
721,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,10,dh48mf,self.MachineLearning,[D] [P] monetizing my ml models,https://www.reddit.com/r/MachineLearning/comments/dh48mf/d_p_monetizing_my_ml_models/,MLtinkerer,1570931129,"I have some image manipulation models I'm thinking of making some side money from.

Should I simply sell it or do I expose it as an API?

&amp;#x200B;

Is there a website I can go to where I can monetize my model?",12,1,False,self,,,,,
722,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,10,dh49ka,self.MachineLearning,"[D] DL Disambiguation Help: Distinction between Many-to-Many, Sequence-to-Sequence, End-to-End, and Encoder-Decoder Architectures/Frameworks/Models",https://www.reddit.com/r/MachineLearning/comments/dh49ka/d_dl_disambiguation_help_distinction_between/,mtvatemybrains,1570931273,"I'm working on a school project where I am attempting to recreate a research paper.  Most of the terms mentioned in the title of this post seem to be tightly coupled in other papers I've read and I have seldom run across instances where distinctions between any of them have been made.  Most of the instances where I have found anyone attempting to make a distinction are in blog posts, which I regard with skepticism.

Sometimes I read something and think ""oh, a sequence-to-sequence model *is  a* many-to-many RNN architecture,"" or ""an encoder-decoder architecture *is a* sequence-to-sequence model"".  Other times I wonder if there's more nuance to these terms than what I have gleaned.  Though it's difficult to know since the papers that I'm reading are typically confined in scope and assume prior knowledge/familiarity (which I lack), so clarifiers like ""model"", ""architecture"", and ""framework"" seem to be used nearly interchangeably.  

I have also reverted to several introductory texts but nowhere have I seen any clear boundaries between *x* is a type of *y*, or *y* is synonymous with *z*.  I realize that some of this ambiguity seems to stem from nomenclature originates in different areas or  that morphs over time as it becomes utilized and ""integrated"" by practitioners.  But as a novice, I don't know what I ""don't know.""  So, what's the diff?

""Many-to-many"" comes (to me) from Andrew Ng (in the context of NMT, where input and output sequences vary in length).  Sequence-to-Sequence seems to originate from Sustkevar et al (2014) though sounds exactly like Ng's ""many-to-many"" description.  ""Encoder-Decoder framework"" also seems to originate from Sustkevar though it's difficult to tell if there are earlier, more generalized instances of this concept. Sequence-to-sequence models seem like they *are identical to* encoder-decoder architectures/frameworks.  Sequence-to-sequence models seem like a *type of* ""End-to-End"" model.  I understand End-to-End models to be distinct from ML pipelines (is this truly the case?) in that they operate within a single instance/training context.

It could simply be the case that I'm just not clear what anyone means by framework vs model vs architecture since no clear distinctions appear anywhere and these terms seem to be used nearly interchangeably.  

Plz halp.",3,0,False,self,,,,,
723,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,11,dh4ge5,self.MachineLearning,[D] Implications of using publicly available dataset for non profit purposes,https://www.reddit.com/r/MachineLearning/comments/dh4ge5/d_implications_of_using_publicly_available/,Desi_Trash,1570932304,I am developing a non profit tool or application using some of the medical datasets that are publicly available. Would like to know more about legal implications surrounding usage of such datasets. Or the permissions required.,3,2,False,self,,,,,
724,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,11,dh4u53,self.MachineLearning,How did you guys start learning machine learning?,https://www.reddit.com/r/MachineLearning/comments/dh4u53/how_did_you_guys_start_learning_machine_learning/,Avtheav,1570934441,[removed],0,1,False,self,,,,,
725,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,12,dh5gu0,self.MachineLearning,Siraj Raval found plagiarizing neural qubit paper,https://www.reddit.com/r/MachineLearning/comments/dh5gu0/siraj_raval_found_plagiarizing_neural_qubit_paper/,FortuitousAdroit,1570938060,[removed],0,1,False,self,,,,,
726,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,13,dh5oxo,self.MachineLearning,Mixed Naive Bayes for categorical and continuous data written in NumPy,https://www.reddit.com/r/MachineLearning/comments/dh5oxo/mixed_naive_bayes_for_categorical_and_continuous/,raibosome,1570939391,"Been working on a library called Mixed Naive Bayes. Instead of assuming a Gaussian distribution on *every* feature, we assume categorical distribution only for categorical features (esp. nominal) &amp; Gaussian for the rest.

I like scikit-learn's APIs   so if you use it a lot, you'll find that it's easy to get started started with this library (there's fit(),  predict(), predict\_proba() and score()).

[http://github.com/remykarem/mixed-naive-bayes](http://github.com/remykarem/mixed-naive-bayes)

![img](z7qxxkp3f8s31)",0,1,False,self,,,,,
727,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,13,dh5ss1,self.MachineLearning,Scraping and finding Dean of university from edu sites with ML,https://www.reddit.com/r/MachineLearning/comments/dh5ss1/scraping_and_finding_dean_of_university_from_edu/,BackEndClutch,1570940010," Hello, I am planning to start building a program that can figure out who the dean is from a website as it scrapes it without being told where to go find it! Especially since every edu site is different.

Any suggestions on which way to go? 

Im thinking it would be a binary classification problem, by saying is it the dean or not.

I also intend to eventually get every single faculty members name and position with it but want to start small.",0,1,False,self,,,,,
728,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,16,dh7il9,self.MachineLearning,[R] Deep Learning for Cryptanalysis,https://www.reddit.com/r/MachineLearning/comments/dh7il9/r_deep_learning_for_cryptanalysis/,tea_search,1570952272,"I had a paper at CRYPTO 2019 on cryptanalysis using neural networks that I thought I might share here, since there has previously been some interest in cross-domain work between cryptology and machine learning on this subreddit (e.g. CipherGAN, Learning the Enigma with Recurrent Neural Networks):

Paper (eprint version): [https://ia.cr/2019/037](https://ia.cr/2019/037)

Github: [https://www.github.com/agohr/deep\_speck](https://www.github.com/agohr/deep_speck)

Talk: [https://youtu.be/weX1itU9VrM](https://youtu.be/weX1itU9VrM)

tl;dr: Using neural networks to distinguish cipher output from random data together with an efficient search policy, we achieve a 200-fold speedup over the best previously published key recovery attack against a round-reduced (i.e. weakened) version of a modern block cipher. This is the first example of state of the art block cipher cryptanalysis using deep learning. The trained deep learning models are also compared to very strong distinguishers using traditional techniques and some partial insight into the source of the additional signal picked up by the DL model is provided.",6,4,False,self,,,,,
729,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,16,dh7nge,self.learnmachinelearning,Siraj Raval has a new paper: 'The Neural Qubit'. It's plagiarised,https://www.reddit.com/r/MachineLearning/comments/dh7nge/siraj_raval_has_a_new_paper_the_neural_qubit_its/,pokeaim,1570953373,,0,1,False,default,,,,,
730,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,17,dh7zdx,senrigan.io,"[Project] Lessons Learned from Building an AI Writing App (GPT2, Guide)",https://www.reddit.com/r/MachineLearning/comments/dh7zdx/project_lessons_learned_from_building_an_ai/,jshek,1570955889,,2,2,False,https://a.thumbs.redditmedia.com/trSNKatX8eOPTJ-E5B2AGmLHtBkkQvh1Ahql6UFjcl0.jpg,,,,,
731,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,17,dh82mz,self.MachineLearning,Open letter to the AI community: An invitation to ponder,https://www.reddit.com/r/MachineLearning/comments/dh82mz/open_letter_to_the_ai_community_an_invitation_to/,johantino,1570956596,[removed],0,1,False,self,,,,,
732,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,18,dh8bwa,self.MachineLearning,Python Projects for Beginner?,https://www.reddit.com/r/MachineLearning/comments/dh8bwa/python_projects_for_beginner/,Doctor_who1,1570958451," 

So for the past month and a half I have been learning Python, and I just yesterday completed the course on SoloLearn. Obviously I still have a lot to practice, but I want some projects to do that are beginner friendly for extra practice. Not too easy, but definitely not like a 3D game or something.

Thanks :)",0,1,False,self,,,,,
733,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,19,dh8nph,self.MachineLearning,Academic failure of acknowledgement,https://www.reddit.com/r/MachineLearning/comments/dh8nph/academic_failure_of_acknowledgement/,oneloveai,1570960908,[removed],1,0,False,self,,,,,
734,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,19,dh8wv4,self.MachineLearning,Top 10 Best Datasets for Applied ML,https://www.reddit.com/r/MachineLearning/comments/dh8wv4/top_10_best_datasets_for_applied_ml/,saadhaxxan,1570962767," 

https://i.redd.it/ycqtaef5das31.png

For the development of AI ,machine learning and data science project its important to gather relevant data. Below given are the 10 best machine learning datasets such a way that you can download the dataset and can develop your machine learning project.

**1. ImageNet**  
ImageNet is one of the best datasets for machine learning. Generally, it can be used in computer vision . This project is an image dataset, it was developed by Fei Fei Li and other researcher working on computer vision. See their TED talk here [https://www.youtube.com/watch?v=40riCqvRoMs](https://www.youtube.com/watch?v=40riCqvRoMs) .  
[http://www.image-net.org/download-faq](http://www.image-net.org/download-faq)

**2. Indians Diabetics Dataset**  
If you want to apply machine learning in health care,then you can use this Pima Indian Diabetics dataset in your healthcare system. We all know that diabetes is one of the most common dangerous diseases. You can use this dataset in your diabetes detection system. This dataset is from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of this dataset is to predict whether or not a patient has diabetes based on specific diagnostic measurement.  
[https://www.kaggle.com/uciml/pima-indians-diabetes-database](https://www.kaggle.com/uciml/pima-indians-diabetes-database)

**3. Boston House Price Dataset**  
Do you want to practice regression algorithm? Then you can use this dataset in your machine learning problem. This dataset is collected from the area of Boston Mass.  
[https://www.kaggle.com/vikrishnan/boston-house-prices](https://www.kaggle.com/vikrishnan/boston-house-prices)

**4. HotpotQA**  
Do you want to work with natural language processing? We all know natural language processing covers a big range area in machine learning. So, if you want to develop a system based on natural language processing (NLP) concept then this dataset is for you my friend. It is collected by a team of NLP researchers at Carnegie Mellon University, Stanford University.  
[https://hotpotqa.github.io/](https://hotpotqa.github.io/)

**5. Labelme**  
Image processing is one of the amazing is of machine learning. If you are interested in developing an image processing system, then you can use this Labelme dataset in your machine learning project. This dataset is a large volume dataset of annotated images.  
[http://labelme2.csail.mit.edu/Release3.0/browserTools/php/dataset.php](http://labelme2.csail.mit.edu/Release3.0/browserTools/php/dataset.php)

**6. Facial Image Dataset**  
You can use this interesting machine learning dataset for your computer vision project. This dataset is standard and free to use. Moreover, it contains a variation of data like variation of background and scale, and variation of expressions. This standard dataset helps to evaluate a system precisely.  
[https://cswww.essex.ac.uk/mv/allfaces/faces94.html](https://cswww.essex.ac.uk/mv/allfaces/faces94.html)

**7. Chars74K Dataset**  
Optical Character recognition is one of the classic classification problems of pattern recognition. This interesting machine learning dataset consists of 64 classes (09, A-Z, a-z), 7705 characters taken from natural images, 3410 hand-drawn characters, and 62992 synthesized characters from computer fonts.  
[http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/#download](http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/#download)

**8. YouTube Dataset**  
Are you an expert in machine learning research area or want to do something with video classification? Then, this dataset for machine learning project might help you. Also, you might be glad to know that Google has shared a labeled dataset with 8M classified YouTube Videos and its IDs  
[https://research.google.com/youtube8m/](https://research.google.com/youtube8m/).

**9. Amazon Reviews Dataset**  
We all know natural language processing is about text data. To solve a real-world application, you need ML dataset. Also, this Amazon reviews dataset is one of them. It contains 35 million reviews from Amazon spanning 18 years (up to March 2013).  
[https://snap.stanford.edu/data/web-Amazon.html](https://snap.stanford.edu/data/web-Amazon.html)

**10.xView**  
If you are an expert in machine learning and you can handle a tricky problem or project, then I must suggest you use this dataset in your project or system. This dataset is one of the standard datasets for imaging problem. Moreover, it is one of the most extensive public datasets.  
[http://xviewdataset.org/#dataset](http://xviewdataset.org/#dataset)

**CLOSING WORDS:**  
Dataset is an integral part of machine learning applications. It can be available in different formats like .txt, .csv, and many more. In supervised machine learning, the labeled training dataset is used, and in unsupervised, no label is needed. If you are a beginner, we recommend you to read this article thoroughly.",0,1,False,self,,,,,
735,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,20,dh98oc,self.MachineLearning,[D] Transformer Encoder for unordered sets and other non-NLP tasks.,https://www.reddit.com/r/MachineLearning/comments/dh98oc/d_transformer_encoder_for_unordered_sets_and/,maka89,1570965046,"Hi,  
I keep bumping into the problem of doing regression/classification on data where the input data is an unordered set. For instance a set of coordinates or a set of atoms or similar, where there is no obvious ordering of the atoms/points.  PointNet can be used for these kinds of problems, but does not always perform well.  


See for instance this post: [https://www.kaggle.com/c/champs-scalar-coupling/discussion/106468#latest-646125](https://www.kaggle.com/c/champs-scalar-coupling/discussion/106468#latest-646125) 

I was wondering if anyone could point me in the right direction on how to use the Transformer for this...  


That is extract an embedding with shape (N, ) from a set of data with shape (M, N)",0,1,False,self,,,,,
736,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,20,dh9a66,self.MachineLearning,[D] Transformer for non-NLP tasks (unordered sets),https://www.reddit.com/r/MachineLearning/comments/dh9a66/d_transformer_for_nonnlp_tasks_unordered_sets/,maka89,1570965307,"Hi,I keep bumping into the problem of doing regression/classification on data where the input data is an unordered set. For instance a set of coordinates or a set of atoms or similar, where there is no obvious ordering of the atoms/points.  PointNet can be used for these kinds of problems, but does not always perform well.

See for instance this post: [https://www.kaggle.com/c/champs-scalar-coupling/discussion/106468#latest-646125](https://www.kaggle.com/c/champs-scalar-coupling/discussion/106468#latest-646125)

I was wondering if anyone could point me in the right direction on how to use the Transformer for this...

That is extract an embedding with shape (N, ) from a set of data with shape (M, N)",11,12,False,self,,,,,
737,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,20,dh9bis,self.MachineLearning,"Which are the ""best"" adversarial attacks against defenses using smoothness, curve regularization, etc ?",https://www.reddit.com/r/MachineLearning/comments/dh9bis/which_are_the_best_adversarial_attacks_against/,anvinhnd,1570965579,"To be clearer, I assume that we only consider Supervised paradigm and Classification task (of course, if there is some literature on other paradigms and tasks, please share).

We all know that there is a plethora of adversarial attacks AND defenses on neural network. Unfortunately (or fortunately), most of the defenses have been debunked (thanks to the papers like [https://arxiv.org/pdf/1802.00420.pdf](https://arxiv.org/pdf/1802.00420.pdf)), and Adversarial Training (AT) is generally the ""best"" defense so far (it's NOT very effective against attacks, but it's generally better than other fancy defenses).

However, it seems like (I can be wrong here) AT has not been compared to the defenses in a specific type, which uses the smoothness of neural network function and decision boundaries to prevent attacks from finding adversarial examples (I know there is definitely this type of defense, although I cannot recall any paper on top of my head).

So I guess my overall question is that ""Are those defenses comparable to AT?"", which in turn means ""Which are the best attacks against those defenses?"" and ""Are those attacks less effective against AT?"".

P.S: Please share some literature if possible. Thanks!",0,1,False,self,,,,,
738,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,20,dh9eol,self.MachineLearning,"[R] [D] Which are the ""best"" adversarial attacks against defenses using smoothness, curve regularization, etc ?",https://www.reddit.com/r/MachineLearning/comments/dh9eol/r_d_which_are_the_best_adversarial_attacks/,anvinhnd,1570966189,"To  be clearer, I assume that we only consider Supervised paradigm and  Classification task (of course, if there is some literature on other  paradigms and tasks, please share).

We  all know that there is a plethora of adversarial attacks AND defenses  on neural network. Unfortunately (or fortunately), most of the defenses  have been debunked (thanks to the papers like [https://arxiv.org/pdf/1802.00420.pdf](https://arxiv.org/pdf/1802.00420.pdf)),  and Adversarial Training (AT) is generally the ""best"" defense so far  (it's NOT very effective against attacks, but it's generally better than  other fancy defenses).

However,  it seems like (I can be wrong here) AT has not been compared to the  defenses in a specific type, which uses the smoothness of neural network  function and decision boundaries to prevent attacks from finding  adversarial examples (I know there is definitely this type of defense,  although I cannot recall any paper on top of my head).

So  I guess my overall question is that ""Are those defenses comparable to  AT?"", which in turn means ""Which are the best attacks against those  defenses?"" and ""Are those attacks less effective against AT?"".

P.S: Please share some literature if possible. Thanks!",6,12,False,self,,,,,
739,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,20,dh9l8x,github.com,Pizza reciepe generation using Skip-gram model. DodoPizza experiment.,https://www.reddit.com/r/MachineLearning/comments/dh9l8x/pizza_reciepe_generation_using_skipgram_model/,zkid18,1570967379,,0,2,False,default,,,,,
740,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,20,dh9ncy,self.MachineLearning,ReLU as a literal switch,https://www.reddit.com/r/MachineLearning/comments/dh9ncy/relu_as_a_literal_switch/,sean5677,1570967775,"An electrical switch is n volts in n volts out when on. Off 0 volts.  

ReLU then is a  switch since it has exactly the same horizontal line (off), 45 degree (on) graph .

The weighted sum of some weighted sums is still a linear system. 

With a ReLU neural network for a *particular* input each ReLU switch is exactly in the on or off state.  The various weighted sums wired together in a particular manner.  There is a particular linear projection in effect from the input of the neural network to the output. 

Since ReLU switches state (on/off) at zero there is no sudden discontinuity of output for gradual changes of input.   

 A ReLU neural network is a seamless switched system of linear projections.

 For a particular input and particular output neuron the system of weighted sums connecting the input to the output neuron can be condensed into a single equivalent weighted sum. 

There are various metrics you can apply to that such as the angle between the input and the equivalent weight vector.  If the angle is close to 90 degrees and the output of the neuron is large then the length of the weight vector must be large (math of dot product),  Then  the output is very sensitive to noise in the input (within the zone  where none of the switches change.)  If the angle is close to zero then you actually get the opposite effect, you get some averaging type error correction (+CLT.)  

There are efficient algorithms for doing certain weighted sums (dot products) that you can then see are valid to incorporate such as the FFT: [https://github.com/S6Regen/Fixed-Filter-Bank-Neural-Networks](https://github.com/S6Regen/Fixed-Filter-Bank-Neural-Networks)",0,1,False,self,,,,,
741,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,21,dh9usd,self.MachineLearning,[P] nn_builder - build neural networks with less boilerplate code,https://www.reddit.com/r/MachineLearning/comments/dh9usd/p_nn_builder_build_neural_networks_with_less/,__data_science__,1570969080,"nn\_builder is a package that lets you build simple NNs, CNNs and RNNs in 1 line by reducing the amount of boilerplate code. It works with PyTorch and TensorFlow 2.0. Check it out!

https://github.com/p-christ/nn\_builder",1,0,False,self,,,,,
742,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,21,dha41z,self.MachineLearning,Overview of hyperparameters in DL,https://www.reddit.com/r/MachineLearning/comments/dha41z/overview_of_hyperparameters_in_dl/,ccwpog,1570970646,"Is there a comprehensive overview over each hyperparameter in Deep Learning. I don't expect a one-captures-all solution, but rather for the specific subdivision.

Say:
Fully Connected Layer - number of neurons, number or layers, initialisation, regularization tools, ...
Convolutinal Layer - number of filters, type of filter, kernel size, padding and strides, ...",0,1,False,self,,,,,
743,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,21,dha5k4,youtu.be,Neural Networks (Deep Learning) - Introduction,https://www.reddit.com/r/MachineLearning/comments/dha5k4/neural_networks_deep_learning_introduction/,burdin271,1570970882,,0,1,False,default,,,,,
744,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,22,dhahaw,medium.com,Best Ways to Improve Cloud ERP with AI and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/dhahaw/best_ways_to_improve_cloud_erp_with_ai_and/,erp_oodles,1570972711,,0,1,False,default,,,,,
745,MachineLearning,t5_2r3gv,2019-10-13,2019,10,13,22,dhanrz,twitter.com,[D] ESA looking into Siraj controversy,https://www.reddit.com/r/MachineLearning/comments/dhanrz/d_esa_looking_into_siraj_controversy/,Meta_Opinions,1570973721,,0,1,False,default,,,,,
746,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,2,dhdp2l,i.redd.it,Siraj admits that his paper was plagiarized and vows to do better in the future,https://www.reddit.com/r/MachineLearning/comments/dhdp2l/siraj_admits_that_his_paper_was_plagiarized_and/,iamjaiyam,1570988284,,0,1,False,https://b.thumbs.redditmedia.com/SYlcgeyki5zpdWv_-1lrJByD7Y0RdksAuXlWfy2ZejU.jpg,,,,,
747,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,2,dhdqhr,youtu.be,Reinforcement Learning Agent from Scratch pt. 6: Basics of Reinforcement Learning!,https://www.reddit.com/r/MachineLearning/comments/dhdqhr/reinforcement_learning_agent_from_scratch_pt_6/,indi0508,1570988455,,1,1,False,https://b.thumbs.redditmedia.com/deWIChoe0WaxMqj5VoKbiAmmaawT5M83kINvYvauExw.jpg,,,,,
748,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,3,dhe6j1,self.MachineLearning,[D] Siraj Raval's official apology regarding the his plagiarized paper,https://www.reddit.com/r/MachineLearning/comments/dhe6j1/d_siraj_ravals_official_apology_regarding_the_his/,mrconter1,1570990394,"""Ive seen claims that my Neural Qubit paper was partly plagiarized. This is true &amp; I apologize. I made the vid &amp; paper in 1 week to align w/ my 2 vids/week schedule. I hoped to inspire others to research. Moving forward, Ill slow down &amp; being more thoughtful about my output""

What do you think?",0,1,False,self,,,,,
749,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,3,dhe767,self.MachineLearning,[D] Siraj Raval's official apology regarding his plagiarized paper,https://www.reddit.com/r/MachineLearning/comments/dhe767/d_siraj_ravals_official_apology_regarding_his/,mrconter1,1570990472,"&gt; Ive seen claims that my Neural Qubit paper was partly plagiarized. This is true &amp; I apologize. I made the vid &amp; paper in 1 week to align w/ my 2 vids/week schedule. I hoped to inspire others to research. Moving forward, Ill slow down &amp; being more thoughtful about my output

What do you guys think about this?",374,793,False,self,,,,,
750,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,5,dhgapl,self.MachineLearning,[P] Snapchat-like filters/lenses,https://www.reddit.com/r/MachineLearning/comments/dhgapl/p_snapchatlike_filterslenses/,erikvdplas,1570999530,"Ive seen numerous guides online discussing face and facial landmark detection. Sometimes these guides also overlay an image attached to one or multiple of these landmarks. None however, promise real-time mapping of 3D models to 3D face meshes. Yet Snapchat manages to do this with nearly zero latency on mobile devices. What are some tricks to achieve similar performance?

I just thought of this as a complex, multifaceted problem. I would love and try to recreate Snapchat lenses in an open source project. 

Anyone with experience with similar problems who can elaborate on some of the key components?",7,11,False,self,,,,,
751,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,6,dhh31d,self.MachineLearning,[D] Can we stop talking about Siraj already?,https://www.reddit.com/r/MachineLearning/comments/dhh31d/d_can_we_stop_talking_about_siraj_already/,M0shka,1571003150,"We get it. He's a fraud, scum, hack, cheat, thief, whatever.  I'm done reading posts about him. I hate to be the asshole trying to stop all the drama but can we go back to actual science?",1,1,False,self,,,,,
752,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,6,dhh697,self.MachineLearning,Retrieving sentences containing particular words from web ?,https://www.reddit.com/r/MachineLearning/comments/dhh697/retrieving_sentences_containing_particular_words/,nodechef,1571003586,"Hi everyone,

Does anyone know any api or a pretrained model which returns/generates sentences based on given words ?",0,1,False,self,,,,,
753,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,7,dhhegd,self.MachineLearning,Exploratory Data Analysis of the Worlds Biggest Sexual Harassment Database,https://www.reddit.com/r/MachineLearning/comments/dhhegd/exploratory_data_analysis_of_the_worlds_biggest/,Lordobba,1571004723,[removed],0,0,False,self,,,,,
754,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,7,dhhfwq,self.MachineLearning,Am I learning Deep learning correctly?,https://www.reddit.com/r/MachineLearning/comments/dhhfwq/am_i_learning_deep_learning_correctly/,purplegenesis753,1571004933,"I have previously learned just using libraries for deep learning but I am now learning how to do it from scratch. These are my steps

&amp;#x200B;

1.) Learn linear algebra and brush up on Multivariate Calculus (learned stats and differential calculus)

2.) Brush up on intuition on Neural Networks

3.) Watch how the math is implemented into neural networks

4.) Watch a couple of practice simple neural networks

5.) Practice coding from scratch

6.) Practice understanding simple deep learning research papers

7.) Done

&amp;#x200B;

Is that a good game plan? or should I add anything?",0,1,False,self,,,,,
755,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,7,dhhhsa,github.com,"LSTM, RNN, and MLP implementations in dependency-free C",https://www.reddit.com/r/MachineLearning/comments/dhhhsa/lstm_rnn_and_mlp_implementations_in/,Zweiter,1571005198,,0,1,False,default,,,,,
756,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,8,dhi7qh,self.MachineLearning,"[P] Implementations of LSTM, RNN, MLP in C",https://www.reddit.com/r/MachineLearning/comments/dhi7qh/p_implementations_of_lstm_rnn_mlp_in_c/,Zweiter,1571008932,"Hey guys,

I've been working on implementing some basic deep learning architectures in C. I saw a submission a little while ago about LSTMs in C, and thought I'd share my own implementation, which includes support for GPU computation through OpenCL. Heres' the repo:

https://github.com/siekmanj/sieknet",10,24,False,self,,,,,
757,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,8,dhieb4,serenityos.org,SerenityOS: From Zero to HTML in a Year,https://www.reddit.com/r/MachineLearning/comments/dhieb4/serenityos_from_zero_to_html_in_a_year/,HN_Crosspost_Bot,1571009874,,0,1,False,https://b.thumbs.redditmedia.com/UTjm-VFlnHIgLdCHjyQJUX27_NsQV6apAMHgGJiRLnE.jpg,,,,,
758,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,9,dhio6j,self.MachineLearning,"Port of ""Bayesian Method for Hackers"" to MIT's Gen",https://www.reddit.com/r/MachineLearning/comments/dhio6j/port_of_bayesian_method_for_hackers_to_mits_gen/,heckeop,1571011389,[removed],0,1,False,self,,,,,
759,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,9,dhiten,self.MachineLearning,who can use social media posts for malicious purposes? Algorithms for detecting that kind of posts.,https://www.reddit.com/r/MachineLearning/comments/dhiten/who_can_use_social_media_posts_for_malicious/,WrathXL,1571012136,[removed],0,1,False,self,,,,,
760,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,9,dhj7t5,cis.upenn.edu,"Algebra, Topology, Differential Calculus, and Optimization Theory for Computer Science and Machine Learning",https://www.reddit.com/r/MachineLearning/comments/dhj7t5/algebra_topology_differential_calculus_and/,Whitishcube,1571014294,,30,75,False,default,,,,,
761,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,10,dhjtqk,nature.com,Why deep-learning AIs are so easy to fool,https://www.reddit.com/r/MachineLearning/comments/dhjtqk/why_deeplearning_ais_are_so_easy_to_fool/,fungussa,1571017550,,0,1,False,default,,,,,
762,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,10,dhjvmz,self.MachineLearning,[R] Is PNAS journal becoming a dumping ground for rejected AI/ML papers?,https://www.reddit.com/r/MachineLearning/comments/dhjvmz/r_is_pnas_journal_becoming_a_dumping_ground_for/,NoSouth5,1571017845,"As a reviewer, chair and general academic, I'm beginning to notice a pattern where a paper will get rejected from NeurIPS, ICLR, ICML only to end up in PNAS later on. I won't name specific papers, but it has happened at least on a few occasions directly in my own experience. Furthermore, the are not any substantial modifications to the work either. Has anyone else noticed this pattern as well?

PNAS is a reputable journal, but they do not have the computational/technical reviewer pools that are aware of the work going on in the AI/ML community. So I suspect that some are taking advantage of this.",11,9,False,self,,,,,
763,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,11,dhkh59,self.MachineLearning,[D] Is there such a thing as a generic ML Solutions Architect? Does the concept even make sense at all?,https://www.reddit.com/r/MachineLearning/comments/dhkh59/d_is_there_such_a_thing_as_a_generic_ml_solutions/,AlexSnakeKing,1571021131,"I work in a highly specific filed, where ML and Stats knowledge is important, but domain and business knowledge are also absolutely crucial to being able to do anything of substance. 

A friend of mine who works in the same field, and is really good at what he does, was recently contacted by a major tech company to be an ML Solutions architect, based on his experience with some of the latest cloud platforms. The role they are hiring him for is ""general"" ML Solutions Architect, not tied to any specific domain: In theory he should be able to go to anyone of their clients, whether a bank, or a manufacturer, or a mobile gaming company, or a retailer, etc...and be able to advise them on how to build ML solutions in the cloud. 

I'm kind of surprised by this: You might be able to port ML development skills or data engineering skills from one domain to another, but Solution Architecture is a completely different beast, and I don't see how somebody, know matter how smart and adaptable they are, can make informed decisions about an enterprise ML architecture without deep experience in that particular domain.   

What are the skills that are specific to ML Solution Architecture (as opposed to being just general ML or Data Engineering knowledge) yet are same time are not domain specific and applicable to general enterprise contexts?!?!",10,0,False,self,,,,,
764,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,12,dhkzs6,medium.com,An Introduction to Serverless Functions for Data Science,https://www.reddit.com/r/MachineLearning/comments/dhkzs6/an_introduction_to_serverless_functions_for_data/,bweber,1571024052,,0,1,False,https://b.thumbs.redditmedia.com/Lf3wXkcoXALhZqQw-Oq0_a8o9p_HWwuHm6jnDwFYPro.jpg,,,,,
765,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,12,dhl5dd,forms.gle,Building a Dataset for Toast Toastiness Identification,https://www.reddit.com/r/MachineLearning/comments/dhl5dd/building_a_dataset_for_toast_toastiness/,xofoxxy,1571024950,,0,1,False,default,,,,,
766,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,12,dhl7b9,self.MachineLearning,"Well done, siraj.",https://www.reddit.com/r/MachineLearning/comments/dhl7b9/well_done_siraj/,eungbean,1571025254,[removed],0,1,False,self,,,,,
767,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,13,dhlrku,self.MachineLearning,"Given that computers have ""solved"" chess, are there still projects dedicated to improving chess computers?",https://www.reddit.com/r/MachineLearning/comments/dhlrku/given_that_computers_have_solved_chess_are_there/,QianLu,1571028720,[removed],0,1,False,self,,,,,
768,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,14,dhlxln,self.MachineLearning,Are we likely to get fully procedural game animations and dialogue any time soon?,https://www.reddit.com/r/MachineLearning/comments/dhlxln/are_we_likely_to_get_fully_procedural_game/,SolarisBravo,1571029776,[removed],0,1,False,self,,,,,
769,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,14,dhm1xv,self.MachineLearning,Which Valve To Use For Several Hot Fluid Or Steam?,https://www.reddit.com/r/MachineLearning/comments/dhm1xv/which_valve_to_use_for_several_hot_fluid_or_steam/,uflowindia,1571030509,[removed],0,1,False,https://b.thumbs.redditmedia.com/Byms9obgQLUX8Fx-f85VKuLsoXwmJSbGJHd1LVrur8c.jpg,,,,,
770,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,14,dhm6c5,self.MachineLearning,"""Siraj Raval"" is a fake name. His real name is Jason.",https://www.reddit.com/r/MachineLearning/comments/dhm6c5/siraj_raval_is_a_fake_name_his_real_name_is_jason/,Bunkydoo,1571031311,[removed],0,1,False,self,,,,,
771,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,14,dhm7mr,self.MachineLearning,Repetition in Questions Generation,https://www.reddit.com/r/MachineLearning/comments/dhm7mr/repetition_in_questions_generation/,govinddaga,1571031567,[removed],0,1,False,self,,,,,
772,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,15,dhmlwo,self.MachineLearning,Advice on Deep Learning Certification,https://www.reddit.com/r/MachineLearning/comments/dhmlwo/advice_on_deep_learning_certification/,MLgeek777,1571034214,[removed],0,1,False,self,,,,,
773,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,15,dhmrj2,countants.com,Can Artificial Intelligence and Machine Learning Transform Small Businesses?,https://www.reddit.com/r/MachineLearning/comments/dhmrj2/can_artificial_intelligence_and_machine_learning/,Countants123,1571035288,,0,1,False,https://b.thumbs.redditmedia.com/_1uQCkbL3alv4Y_EGxwQ_OWHLUOjh8I1YdU2I7Hf8xI.jpg,,,,,
774,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,16,dhmz1c,self.MachineLearning,[D] Bucharest School of AI leaving School of AI,https://www.reddit.com/r/MachineLearning/comments/dhmz1c/d_bucharest_school_of_ai_leaving_school_of_ai/,paubric,1571036682,"In light of recent events, Bucharest School of AI is seizing its affiliation with Siraj's School of AI.

What started as a small community of hobbyists has grown to be one of the largest series of AI workshops in Romania, connecting students and developers in monthly events facilitated by speakers from local universities and companies.

**We are encouraging other chapters across the globe to follow through and commit to ""inspiring and educating"" people through integrity and professionalism, features required even from community-run events.**",79,373,False,self,,,,,
775,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,16,dhmz97,self.MachineLearning,How to search the optimum values with predetermined hyper-parameters?,https://www.reddit.com/r/MachineLearning/comments/dhmz97/how_to_search_the_optimum_values_with/,alucardz82,1571036722,[removed],0,1,False,self,,,,,
776,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,16,dhn3at,towardsdatascience.com,Machine learning vs Big data: Lets find the relationship between them,https://www.reddit.com/r/MachineLearning/comments/dhn3at/machine_learning_vs_big_data_lets_find_the/,AnkitKap,1571037463,,0,1,False,default,,,,,
777,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,16,dhnfzx,simsoft-industry.com,Avantages Systme VOGOF pour le domaine de l'industrie,https://www.reddit.com/r/MachineLearning/comments/dhnfzx/avantages_systme_vogof_pour_le_domaine_de/,Webcom_agency,1571039937,,0,1,False,default,,,,,
778,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,18,dhnyys,self.MachineLearning,Computer for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/dhnyys/computer_for_machine_learning/,BeggarInSpain,1571043926,[removed],0,1,False,self,,,,,
779,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,18,dho4xs,self.MachineLearning,[D] CNN: reducing image size to 1x1,https://www.reddit.com/r/MachineLearning/comments/dho4xs/d_cnn_reducing_image_size_to_1x1/,ccwpog,1571045111,"In a CNN the image sizes get reduced through valid convolutions and padding layers (while the depth increases). In popular NN, e.g. VGG16 it goes down to (7x7x512) (width x height x depth). Would it be problematic to reduce the dimension even further to 1x1 (width x height) or when can this be beneficial? Unfortunately, I couldn't find anything related to the question online.",17,4,False,self,,,,,
780,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,18,dhodr5,self.MachineLearning,"HI, I do engineering at university and I have (mistakenly?) chosen machine learning as my project for the year.",https://www.reddit.com/r/MachineLearning/comments/dhodr5/hi_i_do_engineering_at_university_and_i_have/,timsalad,1571046879,[removed],0,1,False,self,,,,,
781,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,19,dhol7e,day1tech.com,Why what you think of FinTech could be all wrong! Debunking Myths in FinTech,https://www.reddit.com/r/MachineLearning/comments/dhol7e/why_what_you_think_of_fintech_could_be_all_wrong/,day1technologies,1571048292,,0,1,False,https://b.thumbs.redditmedia.com/y6aTKR6baAWoZTelm9dZL2fMTyjP574HCy0zS_btbAo.jpg,,,,,
782,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,19,dhotjk,self.MachineLearning,Should I buy the 1st or 2nd edition of Hands-On Machine Learning with Scikit-Learn and TensorFlow by Aurlien Gron?,https://www.reddit.com/r/MachineLearning/comments/dhotjk/should_i_buy_the_1st_or_2nd_edition_of_handson/,shivang__,1571049841," I am thinking of buying the book but I am confused whether i should get  the 1st or 2nd edition cause its for double the money. If i get the 1st  edition, will I be missing on some essential stuff?",0,1,False,self,,,,,
783,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,19,dhoxv2,twitter.com,[D] ESA: The workshop run by Siraj Raval has been cancelled,https://www.reddit.com/r/MachineLearning/comments/dhoxv2/d_esa_the_workshop_run_by_siraj_raval_has_been/,In0chi,1571050641,,0,1,False,default,,,,,
784,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,20,dhoz6b,self.MachineLearning,[D] Classification of data models,https://www.reddit.com/r/MachineLearning/comments/dhoz6b/d_classification_of_data_models/,DarkCookie243,1571050878,"Hey, I m working on a code completion eclipse plugin for creating xml based data models.  These models describe e.g. an iot device, which could be an air temperature sensor or whatever. To make this efficient and not compare to all already existing data models I will need to classify my existing data models. Any idea how to start?
Thanks for your help :)",1,0,False,self,,,,,
785,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,20,dhp24j,self.MachineLearning,Request for feedback on machine learning data labeling and annotation start up idea,https://www.reddit.com/r/MachineLearning/comments/dhp24j/request_for_feedback_on_machine_learning_data/,Darksaberrising,1571051386,[removed],0,1,False,self,,,,,
786,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,20,dhp474,self.MachineLearning,Machine learning jobs,https://www.reddit.com/r/MachineLearning/comments/dhp474/machine_learning_jobs/,andrea_manero,1571051716,[removed],0,1,False,self,,,,,
787,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,20,dhp4j2,self.MachineLearning,Google Colab in a Company Setting.,https://www.reddit.com/r/MachineLearning/comments/dhp4j2/google_colab_in_a_company_setting/,lysecret,1571051781,[removed],0,1,False,self,,,,,
788,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,20,dhp97u,self.MachineLearning,The world of machine learning Algorithms,https://www.reddit.com/r/MachineLearning/comments/dhp97u/the_world_of_machine_learning_algorithms/,anvithakumari,1571052596,[removed],0,1,False,self,,,,,
789,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,20,dhp99d,smarten.com,Augmented Analytics Benefits are Numerous and Impressive!,https://www.reddit.com/r/MachineLearning/comments/dhp99d/augmented_analytics_benefits_are_numerous_and/,ElegantMicroWebIndia,1571052602,,0,1,False,default,,,,,
790,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,20,dhpahs,bloglovin.com,Scope and Impact of Integrating AI and Machine Learning into .Net Applications (Posts by Ryan Williamson),https://www.reddit.com/r/MachineLearning/comments/dhpahs/scope_and_impact_of_integrating_ai_and_machine/,RyanWilliamson1,1571052816,,0,1,False,default,,,,,
791,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,21,dhps7m,day1tech.com,Why what you think of FinTech could be all wrong! Debunking Myths in FinTech,https://www.reddit.com/r/MachineLearning/comments/dhps7m/why_what_you_think_of_fintech_could_be_all_wrong/,day1technologies,1571055660,,0,1,False,https://b.thumbs.redditmedia.com/y6aTKR6baAWoZTelm9dZL2fMTyjP574HCy0zS_btbAo.jpg,,,,,
792,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,21,dhptpo,i.redd.it,Free Certification IT Helpdesk at Miami Dade College.,https://www.reddit.com/r/MachineLearning/comments/dhptpo/free_certification_it_helpdesk_at_miami_dade/,btamberg84,1571055878,,0,1,False,https://b.thumbs.redditmedia.com/jyebKzQBDYWbJSuvKSvZk7mOuzhY4fmDTf-VF9rNbrQ.jpg,,,,,
793,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,21,dhq44q,i.redd.it,       Company - Optisol Datalabs,https://www.reddit.com/r/MachineLearning/comments/dhq44q/______/,optisol,1571057425,,0,1,False,default,,,,,
794,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,22,dhqd6b,medium.com,Business Benefits of Using Python for AI Projects,https://www.reddit.com/r/MachineLearning/comments/dhqd6b/business_benefits_of_using_python_for_ai_projects/,Rohan_Sharma124,1571058696,,0,1,False,https://b.thumbs.redditmedia.com/BIhHrx2PlJ0QlFOE89esjmkiYsfE_oKNINnHikrnJTg.jpg,,,,,
795,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,22,dhqxaa,medium.com,[D] More Siraj Plagarism - Course Materials,https://www.reddit.com/r/MachineLearning/comments/dhqxaa/d_more_siraj_plagarism_course_materials/,GantMan,1571061467,,0,2,False,default,,,,,
796,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,23,dhqzr3,self.MachineLearning,[D] - Bayesian Optimization with dynamic number of parameters,https://www.reddit.com/r/MachineLearning/comments/dhqzr3/d_bayesian_optimization_with_dynamic_number_of/,ktessera,1571061793,"Hi Everyone,

I would like to use Bayesian Optimization to tune some hyperparameters. The problem is that the number of hyperparameters I want to tune is also a hyperparameter. These hyperparameters all relate to the same thing, i.e. all of them are learning rate, but I am not sure of the number of learning rate hyperparameters I need.

So I want to tune the number of hyperparameters `n` and tune `n` hyperparameters. I was thinking of justing having the max length of hyperparameters and then also have a parameter for the num of hyperparameters and selectiviely choosing only `n` parameters.  Also since number of hyperparameters is an int, I know this is not ideal. Is there a more principled approach? Would I need to implement a specialized kernel function for this?",2,1,False,self,,,,,
797,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,23,dhr5gq,self.MachineLearning,[D] Keeping up with ML advancements,https://www.reddit.com/r/MachineLearning/comments/dhr5gq/d_keeping_up_with_ml_advancements/,Craq221,1571062496,"Sometimes it's hard to keep up with all the advancements in ML.  
I've recently been searching for good telegram channels and found a lack of them.  
[ML World telegram](https://t.me/ml_world) and [Open Data Science telegram](https://t.me/opendatascience) are the only decent channels I've found.  


Please share any decent resources you follow. Not limiting with telegram.",4,1,False,self,,,,,
798,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,23,dhrbjk,mattermore.io,A community for professionals that want to use AI &amp; data science to reverse climate change,https://www.reddit.com/r/MachineLearning/comments/dhrbjk/a_community_for_professionals_that_want_to_use_ai/,otiainen,1571063285,,0,1,False,https://b.thumbs.redditmedia.com/6Z4m6exKmiBNeN1LyuTXdyIlgFBS8KwFfStlG9qN8oQ.jpg,,,,,
799,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,23,dhrgcz,medium.com,Siraj Raval  No Thanks. The sordid story from inside his exclusive course.,https://www.reddit.com/r/MachineLearning/comments/dhrgcz/siraj_raval_no_thanks_the_sordid_story_from/,anastalaz,1571063900,,0,1,False,https://b.thumbs.redditmedia.com/xTF5cU3zkPcuiadLDb0-XUlwI0rUD3emqK13PEsgi7A.jpg,,,,,
800,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,23,dhrl7s,medium.com,[D] Siraj Raval  No Thanks. The sordid story from inside his exclusive course.,https://www.reddit.com/r/MachineLearning/comments/dhrl7s/d_siraj_raval_no_thanks_the_sordid_story_from/,anastalaz,1571064503,,1,1,False,https://b.thumbs.redditmedia.com/xTF5cU3zkPcuiadLDb0-XUlwI0rUD3emqK13PEsgi7A.jpg,,,,,
801,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,23,dhro78,sicara.ai,Determine you Network Hyper-parameters with Bayesian Optimization,https://www.reddit.com/r/MachineLearning/comments/dhro78/determine_you_network_hyperparameters_with/,JulieProst,1571064869,,0,3,False,https://b.thumbs.redditmedia.com/KY1-nOL0n6YFifZAqwGSgH8hlY6GopfdvQ6SvXpT7Mk.jpg,,,,,
802,MachineLearning,t5_2r3gv,2019-10-14,2019,10,14,23,dhromy,self.MachineLearning,What all places to apply for an ML internship focussed on research?,https://www.reddit.com/r/MachineLearning/comments/dhromy/what_all_places_to_apply_for_an_ml_internship/,Jeevesh88,1571064924,[removed],0,1,False,self,,,,,
803,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,0,dhrz0o,self.MachineLearning,[P] Jokeriser: image-to-image translation toy project,https://www.reddit.com/r/MachineLearning/comments/dhrz0o/p_jokeriser_imagetoimage_translation_toy_project/,junkwhinger,1571066165,"Hi,  
I've recently read CycleGAN paper and wanted to train a toy translator to have fun.  
Jokeriser takes an image or a video or a webcam frame as an input and finds faces using \`facenet-pytorch\` before translating those into jokerish faces using the CycleGAN generator that I trained. Despite the small dataset (300 jokers and 300 CelebA faces) the image translator seems to work okay with unseen faces.

  
Here's the repo: [https://github.com/junkwhinger/jokerise](https://github.com/junkwhinger/jokerise)",19,34,False,self,,,,,
804,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,0,dhs235,self.MachineLearning,Thoughts on Andrew Ng course &amp; where to start?,https://www.reddit.com/r/MachineLearning/comments/dhs235/thoughts_on_andrew_ng_course_where_to_start/,marko_stankovic,1571066523,[removed],0,1,False,self,,,,,
805,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,0,dhsgw6,agentanakinai.wordpress.com,"[D] Weighing in on the Siraj Raval controversies with the good, the bad, and the ugly.",https://www.reddit.com/r/MachineLearning/comments/dhsgw6/d_weighing_in_on_the_siraj_raval_controversies/,Agent_ANAKIN,1571068252,,0,1,False,https://a.thumbs.redditmedia.com/MKeJgQ2mPCwGa7ItjZFoZ54yghgco7FB5tEEXEqoV60.jpg,,,,,
806,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,0,dhshdf,blog.paperspace.com,Shareable Jupyter Notebooks That Run on Free Cloud GPUs (also an AMA with the founder if you have questions),https://www.reddit.com/r/MachineLearning/comments/dhshdf/shareable_jupyter_notebooks_that_run_on_free/,kn0thing,1571068305,,3,5,False,https://b.thumbs.redditmedia.com/Gp36K0GWwQ9pV2SzEVWzx045cJtzUnnhY5GGWHRfdNw.jpg,,,,,
807,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,1,dhsmjf,linkedin.com,Siraj Raval losing more credibility.,https://www.reddit.com/r/MachineLearning/comments/dhsmjf/siraj_raval_losing_more_credibility/,johnreese421,1571068909,,1,3,False,https://b.thumbs.redditmedia.com/kSfchV_phuazEXl2vzsKEGCffyvSWwADhh_Mp3EI5Kw.jpg,,,,,
808,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,1,dhsp1q,self.MachineLearning,why is loss calculated as a square?,https://www.reddit.com/r/MachineLearning/comments/dhsp1q/why_is_loss_calculated_as_a_square/,oghi808,1571069189,"Referring to linear regression in particular, but I'm sure there are other applications.

The answer I've found is that loss is calculated as a square in order to make undervaluation and overvaluation the same loss value, but this could be done by an absoluate value. 

It would seem to me that a single data point being off by 10 would still be a more acccurate model than that which misses 100 points by 1. 

Am I missing something?",2,0,False,self,,,,,
809,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,1,dhsr1p,self.MachineLearning,A Research Guide To Convolution Neural Networks,https://www.reddit.com/r/MachineLearning/comments/dhsr1p/a_research_guide_to_convolution_neural_networks/,dataguy94,1571069429,"In this guide, I explore the advancements in CNNs over the past few years.",1,1,False,self,,,,,
810,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,1,dhsx77,self.MachineLearning,A curated list of resources dedicated to bayesian deep learning,https://www.reddit.com/r/MachineLearning/comments/dhsx77/a_curated_list_of_resources_dedicated_to_bayesian/,andrea_manero,1571070135,http://www.datasciencecentral.com/profiles/blogs/a-curated-list-of-resources-dedicated-to-bayesian-deep-learning,0,1,False,self,,,,,
811,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,1,dht7te,self.MachineLearning,[Research] New Dataset for DeepFake Forensics,https://www.reddit.com/r/MachineLearning/comments/dht7te/research_new_dataset_for_deepfake_forensics/,cdossman,1571071359," A new dataset and detection algorithms for DeepFake Forensics  
[http://www.cs.albany.edu/\~lsw/celeb-deepfakeforensics.html](http://www.cs.albany.edu/~lsw/celeb-deepfakeforensics.html?fbclid=IwAR1Qq6wz9rMXFoVjjNb3YL3WTL-tjchObhj_50r0nL_ZjcDsYyy6gy37crc)",0,6,False,self,,,,,
812,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,2,dhtprg,medium.com,Siraj Raval  No Thanks (Inside look into the ML Course),https://www.reddit.com/r/MachineLearning/comments/dhtprg/siraj_raval_no_thanks_inside_look_into_the_ml/,Sunapr1,1571073394,,0,1,False,https://b.thumbs.redditmedia.com/xTF5cU3zkPcuiadLDb0-XUlwI0rUD3emqK13PEsgi7A.jpg,,,,,
813,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,2,dhttmi,i.redd.it,[D] Can I get easy Karma bucks?,https://www.reddit.com/r/MachineLearning/comments/dhttmi/d_can_i_get_easy_karma_bucks/,iamquah,1571073818,,0,1,False,https://a.thumbs.redditmedia.com/1m7fgb0uvmUvC6_QnC708GSg3P_wveEzagZVKVkSLx4.jpg,,,,,
814,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,2,dhtxcc,gojix.com,gojix &amp;#8211; Your Certified Organic Goji Berry Supplier,https://www.reddit.com/r/MachineLearning/comments/dhtxcc/gojix_8211_your_certified_organic_goji_berry/,shantellsowders,1571074263,,0,1,False,default,,,,,
815,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,2,dhtyvt,self.MachineLearning,Improving Generalization and Robustness with Noisy Collaboration in Knowledge Distillation,https://www.reddit.com/r/MachineLearning/comments/dhtyvt/improving_generalization_and_robustness_with/,fahad_sarfraz,1571074416,"Inspired by trial-to-trial variability in the brain that can result from multiple noise sources, we propose novel methods for introducing variability through noise in the knowledge distillation framework and show the effectiveness of adding constructive noise in the knowledge distillation framework for improving the generalization and robustness of the model.",0,1,False,self,,,,,
816,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,3,dhuh0r,self.MachineLearning,[Question/Discussion] Cross-Entropy as a multi label loss,https://www.reddit.com/r/MachineLearning/comments/dhuh0r/questiondiscussion_crossentropy_as_a_multi_label/,PaganPasta,1571076479,[removed],0,1,False,self,,,,,
817,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,3,dhuid4,self.MachineLearning,What does it take to work at Computer Vision job at Microsoft?,https://www.reddit.com/r/MachineLearning/comments/dhuid4/what_does_it_take_to_work_at_computer_vision_job/,vandit_15,1571076648,[removed],0,1,False,self,,,,,
818,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,3,dhurls,self.MachineLearning,[Open Beta] I made a news aggregator that uses ML and NLP to visualize stories through timelines and graph theory,https://www.reddit.com/r/MachineLearning/comments/dhurls/open_beta_i_made_a_news_aggregator_that_uses_ml/,red1990corvette,1571077729,[removed],0,1,False,self,,,,,
819,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,3,dhv4ac,self.MachineLearning,Machine learning refresher,https://www.reddit.com/r/MachineLearning/comments/dhv4ac/machine_learning_refresher/,shwetashri,1571079212,[removed],0,1,False,self,,,,,
820,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,3,dhv6c9,self.MachineLearning,Python Machine Learning Projects [45+ videos] Download fast before expire,https://www.reddit.com/r/MachineLearning/comments/dhv6c9/python_machine_learning_projects_45_videos/,PrinceHanzala543,1571079458,[removed],0,1,False,self,,,,,
821,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,4,dhv7z6,self.MachineLearning,"Who of you is using no-code data pipelines, which ones, and why?",https://www.reddit.com/r/MachineLearning/comments/dhv7z6/who_of_you_is_using_nocode_data_pipelines_which/,rufenmatt,1571079657,[removed],0,1,False,self,,,,,
822,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,4,dhvadl,medium.com,[D] Siraj Raval  No Thanks. The sordid story from inside his exclusive course.,https://www.reddit.com/r/MachineLearning/comments/dhvadl/d_siraj_raval_no_thanks_the_sordid_story_from/,anastalaz,1571079933,,0,1,False,https://b.thumbs.redditmedia.com/xTF5cU3zkPcuiadLDb0-XUlwI0rUD3emqK13PEsgi7A.jpg,,,,,
823,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,4,dhvez9,deeps.site,Career Advice in ML and how to read research papers - Andrew Ng's Notes,https://www.reddit.com/r/MachineLearning/comments/dhvez9/career_advice_in_ml_and_how_to_read_research/,deep_ak,1571080450,,0,1,False,default,,,,,
824,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,4,dhvkav,exbert.net,[P] exBERT: A Visual Analysis Tool to Explore Learned Representations in Transformers Models,https://www.reddit.com/r/MachineLearning/comments/dhvkav/p_exbert_a_visual_analysis_tool_to_explore/,Valedra,1571081036,,0,1,False,default,,,,,
825,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,4,dhvkft,self.MachineLearning,Career Advice in ML and how to read research papers - Andrew Ng's Notes,https://www.reddit.com/r/MachineLearning/comments/dhvkft/career_advice_in_ml_and_how_to_read_research/,deep_ak,1571081051,[removed],0,1,False,self,,,,,
826,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,4,dhvp7o,exbert.net,[P] exBERT: A Visual Analysis Tool to Explore Learned Representations in Transformers Models,https://www.reddit.com/r/MachineLearning/comments/dhvp7o/p_exbert_a_visual_analysis_tool_to_explore/,Valedra,1571081566,,0,2,False,default,,,,,
827,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,5,dhwfxq,self.MachineLearning,AI/Machine Learning help,https://www.reddit.com/r/MachineLearning/comments/dhwfxq/aimachine_learning_help/,Drakkus28,1571084506,[removed],0,1,False,self,,,,,
828,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,5,dhws0l,self.MachineLearning,[R] On the adequacy of untuned warmup for adaptive optimization,https://www.reddit.com/r/MachineLearning/comments/dhws0l/r_on_the_adequacy_of_untuned_warmup_for_adaptive/,fabf673b3fa7401e62df,1571085873,"FAIR paper that claims to ""obviate RAdam"". It writes RAdam(W) is functionally equivalent to Adam(W) with ""linear warmup over 2 / (1 - beta2) training iterations"".

Legit? This makes either MSR or FAIR look pretty bad.

[https://arxiv.org/abs/1910.04209](https://arxiv.org/abs/1910.04209)",4,23,False,self,,,,,
829,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,5,dhwt8l,self.MachineLearning,Predict future images/clouds,https://www.reddit.com/r/MachineLearning/comments/dhwt8l/predict_future_imagesclouds/,nii3lsh,1571086005,[removed],0,1,False,self,,,,,
830,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,5,dhwtg2,medium.com,Shake Your Booty: AI Deepfakes Dance Moves From a Single Picture,https://www.reddit.com/r/MachineLearning/comments/dhwtg2/shake_your_booty_ai_deepfakes_dance_moves_from_a/,Yuqing7,1571086029,,0,1,False,default,,,,,
831,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,6,dhx0i3,youtu.be,Machine Learning | Algorithm CheatSheet,https://www.reddit.com/r/MachineLearning/comments/dhx0i3/machine_learning_algorithm_cheatsheet/,burdin271,1571086822,,0,1,False,https://b.thumbs.redditmedia.com/ZqMjpp8phs1uonOH0_pLMrySIUeIaDgGnsAzeolU5yc.jpg,,,,,
832,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,6,dhx2ju,medium.com,DARPA Restoring Active Memory Project Funding Involuntary Human Test Subject Experimentation in Philadelphia,https://www.reddit.com/r/MachineLearning/comments/dhx2ju/darpa_restoring_active_memory_project_funding/,sdhksasm,1571087047,,0,1,False,default,,,,,
833,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,6,dhxenp,self.MachineLearning,Help With Creating a Pokemon Classifier,https://www.reddit.com/r/MachineLearning/comments/dhxenp/help_with_creating_a_pokemon_classifier/,Aradarbel10,1571088436,"Hello,

I want to create a classifier that takes an image of a Pokemon and outputs its name. I have a folder containing a picture of each pokmon. The input images aren't going to be very different from the data set, and by that I mean all pokmons are going to be on a white background, so it shouldn't be too complicated to perform. I had a few Ideas for how to do it:

1. Have a CNN with an output for each pokmon. This seems too complicated for what I need and also I have only one instance for each pokmon.
2. Color ratios: see how much of each color is in the image and compare it to values in the data set.
3. Shadow: transform the input image into a b&amp;w shadow (who is that pokmon style) and try to see which image of the data set fits the best by scaling, moving, and reflecting.

I am not sure exactly how to implement any of these methods or if they will even work, so I'd love to hear what you say about it. What will be my best option?",0,1,False,self,,,,,
834,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,6,dhxm03,self.MachineLearning,"Hi, I'm new in this world. So I want to research for books or something to start as well as I could, if someone can and wants contribute with information or something thank you. &lt;3.",https://www.reddit.com/r/MachineLearning/comments/dhxm03/hi_im_new_in_this_world_so_i_want_to_research_for/,CamaleonCosmico,1571089297,[removed],0,1,False,self,,,,,
835,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,8,dhz5in,self.MachineLearning,Number of nodes in input layer vs number of nodes in output layer.,https://www.reddit.com/r/MachineLearning/comments/dhz5in/number_of_nodes_in_input_layer_vs_number_of_nodes/,ibfdad,1571096045,[removed],0,1,False,self,,,,,
836,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,8,dhzaeh,arxiv.org,[R] Publish or impoverish: An investigation of the monetary reward system of science in China (1999-2016),https://www.reddit.com/r/MachineLearning/comments/dhzaeh/r_publish_or_impoverish_an_investigation_of_the/,baylearn,1571096665,,6,37,False,default,,,,,
837,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,8,dhzcgh,self.MachineLearning,[R] Inverse Sentence Embedding,https://www.reddit.com/r/MachineLearning/comments/dhzcgh/r_inverse_sentence_embedding/,lizelive,1571096923,"I am using BERT for sentence embedding, and currently my only solution is a highly optimized rainbow dictionary, but it's not scaling well. Attempts to do matching on sub-strings has proved unsuccessful.

I want to use machine learning to do this. I was thinking about trying to train a bidirectional RNN, but that is a huge direction. I was wondering if anyone had advice to look in.",2,3,False,self,,,,,
838,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,8,dhzde6,self.MachineLearning,[D] Dealing with Feelings of Inadequacy and Imposter Syndrome in ML (for those looking to learn),https://www.reddit.com/r/MachineLearning/comments/dhzde6/d_dealing_with_feelings_of_inadequacy_and/,cthulhu_loves_us,1571097047,"I'm a Master's student at a university of no repute. I'm not stupid. In fact I would say I'm fairly intelligent. I graduated near the top of my class. I've always been performed well in academia and have been decent at math. But I feel like I've always had to work harder to get it than others. I'm not a prodigy. 

When it comes to ML, specifically ML Engineering (which is where I want to be), it feels like there's a mountain of things you have to know: Software Engineering principles, a variety of languages, algorithms and their complexities, software frameworks, statistics, mathematics, domain specific requirements. And I feel like the field is always changing and I'm never going to be ""informed"" as it were.

I feel like I've spent most of my Master's degree just checking off the boxes to get my degree (while also paying for it) and I haven't had enough time to delve into ML and now that I'm 8 months out from being done I don't have the knowledge I need to actually move into this field. 

But when I read this sub I think that I'm never going to be ready to move into the field. I'm always going to be fighting to understand the math well enough but then I'm not going to have enough time to understand the frameworks or the software engineering. It feels like I'm the jack of all trades but the master of none. 

How do I navigate this field to feel like I'm learning effectively? Is it even worth it to pursue this field if I'm not a math prodigy? I want feel competant and that I'm not just another surface level ML practitioner.",58,198,False,self,,,,,
839,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,8,dhzfrt,self.MachineLearning,[D] Google X AI Residency Interviews,https://www.reddit.com/r/MachineLearning/comments/dhzfrt/d_google_x_ai_residency_interviews/,strider244,1571097342,"Hello everyone!

I was wondering if anyone here has gone through the AI resident interview circuit at X? If yes, could you please provide an overview of what the interview structure is and how many rounds are there in total?   

Thanks!",1,2,False,self,,,,,
840,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,9,dhzr4q,self.MachineLearning,RLCard: A Toolkit for Reinforcement Learning in Card Games,https://www.reddit.com/r/MachineLearning/comments/dhzr4q/rlcard_a_toolkit_for_reinforcement_learning_in/,lhenry15,1571098859,[removed],0,1,False,self,,,,,
841,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,9,dhzvkq,self.MachineLearning,[P] RLCard: A Toolkit for Reinforcement Learning in Card Games,https://www.reddit.com/r/MachineLearning/comments/dhzvkq/p_rlcard_a_toolkit_for_reinforcement_learning_in/,lhenry15,1571099458,"Hi,

We've recently worked on imperfect information games and reinforcement learning, and we would like to share our toolkit to everyone. RLCard supports various popular card games such as UNO, blackjack, Leduc Hold'em and Texas Hold'em. It also has some examples of basic reinforcement learning algorithms, such as Deep Q-learning, Neural Fictitious Self-Play (NFSP) and Counter Factual Regret Minimization (CFR). Also, it has a simple interface to play with the pre-trained agent. Any generous comments will be appreciated. Have fun!

Github: [https://github.com/datamllab/rlcard](https://github.com/datamllab/rlcard)",10,31,False,self,,,,,
842,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,10,di07wt,self.MachineLearning,[D] Am I the only one who's starting to feel sorry for Siraj Raval?,https://www.reddit.com/r/MachineLearning/comments/di07wt/d_am_i_the_only_one_whos_starting_to_feel_sorry/,AlexSnakeKing,1571101212,"I hated the guy. I fucking despised him, between his ""AI for Supply Chain"" video, which made a mockery of one the most challenging domains in ML and Analytics, and his ""How to predict the stock market with LSTM"" video which downright dangerous (what if somebody actually went out and bet their retirement on 7 lines of Keras?!?!?!?) - I found the guy not just annoying, but pathological. 

Yet over the last few days, the sheer completeness of his collapse, has me actually feeling sorry for him. Some of the time he was indeed intentionally malicious, but most of the time he came of more like he a D-bag who just way in over his head and who somehow found himself in a spotlight he didn't expect. 

I mean I know people who are at their core, just refined, more nuanced version of Siraj Raval, who managed to make it to Director and VP level positions on pure self promotions and ability to sell themselves. I am sure we all know people like that as well. What's the difference? They were simply smart enough to not get caught. 

Yet we gawk and we laugh at poor Siraj. Its every started chewing when the guy was pulled over for doing 5 m over the speed limit, and they're all ignoring all the cars doing 85 and 90.....",21,0,False,self,,,,,
843,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,10,di0f1n,self.MachineLearning,Lambda Labs vs SabrePC,https://www.reddit.com/r/MachineLearning/comments/di0f1n/lambda_labs_vs_sabrepc/,rajatsainju,1571102208,[removed],0,1,False,self,,,,,
844,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,10,di0pj9,self.MachineLearning,"Dataset to detect inappropriate content(nudity, violence,drugs etc.,) in images for content moderation",https://www.reddit.com/r/MachineLearning/comments/di0pj9/dataset_to_detect_inappropriate_contentnudity/,Nike_Zoldyck,1571103699,[removed],0,1,False,self,,,,,
845,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,11,di1d5p,self.MachineLearning,Regarding Copyright of voice? (If any),https://www.reddit.com/r/MachineLearning/comments/di1d5p/regarding_copyright_of_voice_if_any/,redditssexiestguy,1571107010,[removed],0,1,False,self,,,,,
846,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,12,di1uqv,self.MachineLearning,NeurIPS Volunteer Email Mentions Nonexistent Link,https://www.reddit.com/r/MachineLearning/comments/di1uqv/neurips_volunteer_email_mentions_nonexistent_link/,_-__-____,1571109553,[removed],0,1,False,self,,,,,
847,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,13,di2fez,self.MachineLearning,[N] Netflix and European Space Agency no longer working with Siraj Raval,https://www.reddit.com/r/MachineLearning/comments/di2fez/n_netflix_and_european_space_agency_no_longer/,inarrears,1571112550,"*According to article in [The Register](https://www.theregister.co.uk/2019/10/14/ravel_ai_youtube/)*:

A Netflix spokesperson confirmed to The Register it wasnt working with Raval, and the ESA has cancelled the whole workshop altogether.

The situation is as it is. The workshop is cancelled, and thats all, Guillaume Belanger, an astrophysicist and the INTEGRAL Science Operations Coordinator at the ESA, told The Register on Monday.

Raval isnt about to quit his work any time soon, however. He promised students who graduated from his course that they would be referred to recruiters at Nvidia, Intel, Google and Amazon for engineering positions, or matched with a startup co-founder or a consulting client.

In an unlisted YouTube video recorded live for his students discussing week eight of his course, and seen by El Reg, he read out a question posed to him: Will your referrals hold any value now?

Um, yeah theyre going to hold value. I dont see why they wouldnt. I mean, yes, some people on Twitter were angry but that has nothing to do with I mean Ive also had tons of support, you know. Ive had tons of support from people, who, uh, you know, support me, who work at these companies.

*He continues to justify his actions:*

Public figures called me in private to remind me that this happens. You know, people make mistakes. You just have to keep going. Theyre basically just telling me to not to stop. Of course, you make mistakes but you just keep going, he claimed.

*When The Register asked Raval for comment, he responded:*

**I've hardly taken any time off to relax since I first started my YouTube channel almost four years ago. And despite the enormous amount of work it takes to release two high quality videos a week for my audience, I progressively started to take on multiple other projects simultaneously by myself  a book, a docu-series, podcasts, YouTube videos, the course, the school of AI. Basically, these past few weeks, I've been experiencing a burnout unlike anything I've felt before. As a result, all of my output has been subpar.**

**I made the [neural qubits] video and paper in one week. I remember wishing I had three to six months to really dive into quantum machine-learning and make something awesome, but telling myself I couldn't take that long as it would hinder my other projects. I plagiarized large chunks of the paper to meet my self-imposed one-week deadline. The associated video with animations took a lot more work to make. I didn't expect the paper to be cited as serious research, I considered it an additional reading resource for people who enjoyed the associated video to learn more about quantum machine learning. If I had a second chance, I'd definitely take way more time to write the paper, and in my own words.**

**I've given refunds to every student who's asked so far, and the majority of students are still enrolled in the course. There are many happy students, they're just not as vocal on social media. We're on week 8 of 10 of my course, fully committed to student success.**

And, no, I haven't plagiarized research for any other paper, he added.

https://www.theregister.co.uk/2019/10/14/ravel_ai_youtube/",303,877,False,self,,,,,
848,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,13,di2pf6,self.MachineLearning,Choosing number of dataset for model training,https://www.reddit.com/r/MachineLearning/comments/di2pf6/choosing_number_of_dataset_for_model_training/,radhaanu_26,1571114156,[removed],0,1,False,self,,,,,
849,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,13,di2xzj,self.MachineLearning,Can KNN be used for multivariate multiple regression?,https://www.reddit.com/r/MachineLearning/comments/di2xzj/can_knn_be_used_for_multivariate_multiple/,Memokerobi,1571115593,[removed],0,1,False,self,,,,,
850,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,14,di34wi,self.MachineLearning,Chinese face recognition systems,https://www.reddit.com/r/MachineLearning/comments/di34wi/chinese_face_recognition_systems/,thatsmesasha,1571116783,[removed],0,1,False,self,,,,,
851,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,14,di3hgs,self.MachineLearning,Career path to Research scientist,https://www.reddit.com/r/MachineLearning/comments/di3hgs/career_path_to_research_scientist/,unleashthehymms,1571119008,[removed],0,1,False,self,,,,,
852,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,16,di42bu,self.MachineLearning,Which Valve To Use For Several Hot Fluid Or Steam?,https://www.reddit.com/r/MachineLearning/comments/di42bu/which_valve_to_use_for_several_hot_fluid_or_steam/,uflowindia,1571122843,[removed],0,1,False,self,,,,,
853,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,16,di46wx,self.MachineLearning,[D] How good is this idea: A website for machine learning enthusiasts where collaborators can label other people's data and get paid for it while also putting their own data to be labeled (of course then they would have to pay for it),https://www.reddit.com/r/MachineLearning/comments/di46wx/d_how_good_is_this_idea_a_website_for_machine/,zimmer550king,1571123658,"Hello all. I want to know whether this seems like a good idea. I actually am looking for ideas for my Business Plan class and this seems to be like something that hasn't been done yet.

Basically, the idea is that people can upload their data online with instructions on how to label it. The label can be as simple as assigning a label to the whole picture and it can also be as complicated as marking individual pixels or something like that. I don't really plan on going too deep into this since it is only for academic reasons but feedback on this would be appreciated.

I think the recent boom in the usage of neural networks means there will be a big market for this idea as everyone from independent machine learning enthusiasts to big corporations would take advantage of this. What do you guys think?",8,0,False,self,,,,,
854,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,16,di4d18,rubikscode.net,29 Skills for Being a Successful Data Scientist,https://www.reddit.com/r/MachineLearning/comments/di4d18/29_skills_for_being_a_successful_data_scientist/,RubiksCodeNMZ,1571124778,,0,1,False,https://b.thumbs.redditmedia.com/_3QoZ4OhC6Nzf13IPXCgEpsmqPXm_gU35jANEcYDV2k.jpg,,,,,
855,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,16,di4fsn,byvdigital.com,DeepFakes-The Threat Of Not Knowing What Real And Factual!,https://www.reddit.com/r/MachineLearning/comments/di4fsn/deepfakesthe_threat_of_not_knowing_what_real_and/,humairasaleem,1571125281,,0,1,False,default,,,,,
856,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,16,di4gv0,self.MachineLearning,What are the points of AI vs machine learning?,https://www.reddit.com/r/MachineLearning/comments/di4gv0/what_are_the_points_of_ai_vs_machine_learning/,martinbryan82,1571125481,"**ARTIFICIAL INTELLIGENCE**

* AI stands for Artificial intelligence, where intelligence is defined acquisition of knowledge intelligence is defined as a ability to acquire and apply knowledge.
* The aim is to increase chance of success and not accuracy.
* It work as a computer program that does smart work.
* The goal is to simulate natural intelligence to solve complex problem.
* AI is decision making.
* It leads to develop a system to mimic human to respond behave in a circumstances.
* AI will go for finding the optimal solution.

**MACHINE LEARNING**

* ML stands for Machine Learning which is defined as the acquisition of knowledge or skill.
* The aim is to increase accuracy, but it does not care about success
* It is a simple concept machine takes data and learn from data.
* The goal is to learn from data on certain task to maximise the performance of machine on this task.
* ML allows system to learn new things from data.
* It involves in creating self learning algorithms.
* ML will go for only solution for that whether it is optimal or not.
* ML leads to knowledge.",0,1,False,self,,,,,
857,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,17,di4sud,github.com,Implementation of a character based CNN for text classification in PyTorch + Video Demo,https://www.reddit.com/r/MachineLearning/comments/di4sud/implementation_of_a_character_based_cnn_for_text/,ahmedbesbes,1571127750,,0,1,False,default,,,,,
858,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,17,di4vii,self.MachineLearning,[D] RL Line Follower,https://www.reddit.com/r/MachineLearning/comments/di4vii/d_rl_line_follower/,hemiwoyi,1571128264,"Hi everyone,  


I'm trying to train a line follower agent using Deep RL. In the simplest case, the environments look like in the attached figure. More complicated environments can be generated by varying the line thickness along the path, allowing the line to have tangency points with itself, or having other lines intersecting/touching the line of interest. The agent starts at one end and the goal is to reach the other end while staying as centered as possible and following the topologically correct path (e.g. in case of overlaps, it shouldn't take the ""wrong path""). The terminal state does not have to be signaled by the agent.  
When the agent is located in the middle of an intersection, the correct path to take cannot be determined unless a history of previous positions is stored (either by concatenating the latest n observations, or by using a recurrent layer such as an LSTM in the Q network/Policy network), thus effectively handling the environment as a POMDP. At each step, the observation is a retina-like representation around the current position, as in this paper: [https://papers.nips.cc/paper/5542-recurrent-models-of-visual-attention.pdf](https://papers.nips.cc/paper/5542-recurrent-models-of-visual-attention.pdf)

The rewards are dense (i.e. received after each timestep), and I defined them as:

* \-1 if the agent goes outside the line or moves in the wrong direction (e.g. moves in the opposite direction than it should, or is taking a wrong path when located inside an intersection. In this case the episode ends.
* otherwise the reward is a positive between 0 and 1, depending on the distance from the center of the line (1 being the maximum, when located exactly on the center).

The actions correspond to the 8 discrete neighbors of the current position in which the agent can move, with a fixed stepsize (so the agent effectively walks on a grid).

I've tried using both simple DQN by concatenating the previous observations and DRQN ([https://arxiv.org/abs/1507.06527](https://arxiv.org/abs/1507.06527)), but the results are not great. I'm starting to think that Q learning is not suited for the task because the length of the line is varying from one environment to another, so the return can vary a lot, hence being hard to learn (especially because the agent does not observe the full environment). Because of this, I've tried reducing the discount factor, still without improvements. I cannot find a systematic reason for the failures (for example the agent failing always inside an intersection).

I've also tried PG and Recurrent PG but never really managed to make it work, although I am starting to think that PG is more suited for this task.  


The big question: is there anything fundamentally wrong that I am doing, or a fundamental reason for which Q-learning/PG will not work for this? Any tips or tricks, suggestions?

https://i.redd.it/o62wjg7nrns31.png",9,1,False,https://b.thumbs.redditmedia.com/PZJKXnW1vMslbmqMraPPLsY4CB0dcUIQjBGPcPv5J-g.jpg,,,,,
859,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,17,di4yfl,self.MachineLearning,[D] Detecting arbitrary objects in images,https://www.reddit.com/r/MachineLearning/comments/di4yfl/d_detecting_arbitrary_objects_in_images/,CL4DSOFT,1571128835,"All object detection approaches I know are trained with some data sets to detect only specific classes from the respective data set (also e.g. something like YOLO9000 which can detect 9000 classes). I want to have some more general approach, that can detect arbitrary objects (of any class, returning the containing bounding box) in images.

I did not found anything here, can anyone recommend a related paper or website?",10,2,False,self,,,,,
860,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,17,di523f,self.MachineLearning,Good practices for research projects,https://www.reddit.com/r/MachineLearning/comments/di523f/good_practices_for_research_projects/,surya-k,1571129572,[removed],0,1,False,self,,,,,
861,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,18,di5az1,self.MachineLearning,Interview Questions,https://www.reddit.com/r/MachineLearning/comments/di5az1/interview_questions/,Deadshot_95,1571131246,[removed],0,1,False,self,,,,,
862,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,18,di5eah,self.MachineLearning,[D] Interview Questions,https://www.reddit.com/r/MachineLearning/comments/di5eah/d_interview_questions/,Deadshot_95,1571131845,"So, recently I was interviewed for the position of Data Scientist The interview went into two stages with one being a telephonic round which ended in 35-40 minutes and the other being a Hangout call which ended up in 50-60 minutes. The interviewer was very good and asked a lot of amazing questions mostly focusing on the fundamentals. Here is the list of questions that were asked to me:-

1. What is overfitting? Describe how models actually overfit using a scenario.
2. What is gradient descent? Difference between gradient descent and backpropagation?
3. Is the gradient a vector or a scaler?
4. Bias-Variance Tradeoff
5. Working of LDA using an example.
6. How Infersent generates sentence embedding (Working of the entire architecture).
7. How would you do NER from scratch?
8. In AllenNLP, one of the models which it uses to do NER is based on ELMO. Given a piece of text (say, ""Jack is playing football), how would ELMO go on about doing tagging Jack to PER?
9. Given a piece of text (say, ""Jack and Mary had been married for a long time but gradually drifted apart until they separated."") how would you do relation extraction from scratch? The outcome should be: Jack - Married\_To - Mary

Other questions from my previous interviews:-

1. Describe the sequential minimal optimization(SMO) algorithm.
2. Suppose there are four persons, each one is standing at the corner of a square table. The probability of any one of them moving in either direction (clockwise/anticlockwise) is 1/2. If all of them started moving together at the same time at the same speed, what is the probability that none of them will collide?

General Questions:-

1. Recent trends in NLP
2. Data structures - coding questions

I hope this helps anyone who is preparing for there interviews. I will keep on updating this, meanwhile, I also request others to please do share your interview experience and put forward some questions which you faced in your interview.

Cheers!!",33,96,False,self,,,,,
863,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,18,di5ii7,self.HideUnderABush,Pytorch101: Basic ideas about Tensor,https://www.reddit.com/r/MachineLearning/comments/di5ii7/pytorch101_basic_ideas_about_tensor/,HideUnderABush,1571132612,,0,1,False,https://b.thumbs.redditmedia.com/FfGqGlJ7O3SNyH4BcP-AkVXsyFbN0g7tw0nFFFw9DLM.jpg,,,,,
864,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,18,di5nlm,day1tech.com,What are your thoughts?,https://www.reddit.com/r/MachineLearning/comments/di5nlm/what_are_your_thoughts/,day1technologies,1571133504,,0,1,False,https://b.thumbs.redditmedia.com/lmsyOyU8U90aMxFsf3j2xZrAPRYQov4kBFAF5OORTMc.jpg,,,,,
865,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,19,di5vxv,self.MachineLearning,vast.ai - need help getting connected,https://www.reddit.com/r/MachineLearning/comments/di5vxv/vastai_need_help_getting_connected/,TravellingSince1990,1571134908,[removed],0,1,False,self,,,,,
866,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,19,di5y1k,day1tech.com,What are your thoughts?,https://www.reddit.com/r/MachineLearning/comments/di5y1k/what_are_your_thoughts/,day1technologies,1571135277,,0,1,False,default,,,,,
867,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,19,di5yoo,self.MachineLearning,7 Lessons You Can Learn from the Siraj Raval,https://www.reddit.com/r/MachineLearning/comments/di5yoo/7_lessons_you_can_learn_from_the_siraj_raval/,nurdin89,1571135380,[removed],0,0,False,self,,,,,
868,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,19,di61x8,self.MachineLearning,"Top Consulting Companies inData Science, Data Mining | Webtunix",https://www.reddit.com/r/MachineLearning/comments/di61x8/top_consulting_companies_indata_science_data/,OliviaWillson,1571135931,[removed],0,1,False,self,,,,,
869,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,20,di6jxp,self.MachineLearning,Robotic Process Automation Training in Pune,https://www.reddit.com/r/MachineLearning/comments/di6jxp/robotic_process_automation_training_in_pune/,Technogeekspune,1571138986,[removed],0,1,False,self,,,,,
870,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,20,di6r96,medium.com,Accelerating Supply Chain Processes with Next-gen Technologies,https://www.reddit.com/r/MachineLearning/comments/di6r96/accelerating_supply_chain_processes_with_nextgen/,erp_oodles,1571140163,,0,1,False,https://b.thumbs.redditmedia.com/hbJjnP25UC2WIir6DHxEx35yNxtukWWymEuZP_WVUjU.jpg,,,,,
871,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,21,di7c8c,self.MachineLearning,Time series prediction is delayed by 1 lag,https://www.reddit.com/r/MachineLearning/comments/di7c8c/time_series_prediction_is_delayed_by_1_lag/,Quentin-Martell,1571143354,"Hi!

I have been working on an ARMA model. I have made the fit succesfully, but when I am forecasting the predictions seem delayed by 1 lag. The things is that I know that this sometimes happen with LSTMs, but I have not been able to find any docs on this matter with AR, MA or ARMA models.

Can someone help me? Thank you!",0,1,False,self,,,,,
872,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,21,di7hw3,self.MachineLearning,Need help!,https://www.reddit.com/r/MachineLearning/comments/di7hw3/need_help/,Saad-Truth,1571144174,[removed],0,1,False,self,,,,,
873,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,21,di7ix1,self.MachineLearning,[R] Google's Batch Normalization Patent has been granted and is now active until 2038,https://www.reddit.com/r/MachineLearning/comments/di7ix1/r_googles_batch_normalization_patent_has_been/,JacksTurmoil,1571144311,"&gt;Application US15/009,647 events  
&gt;  
&gt;2015-01-28 Priority to US201562108984P  
&gt;  
&gt;2016-01-28 Application filed by Google LLC  
&gt;  
&gt;2016-07-28 Publication of US20160217368A1  
&gt;  
&gt;**2019-09-17 Publication of US10417562B2**  
&gt;  
&gt;**2019-09-17 Application granted**  
&gt;  
&gt;**2019-10-15 Application status is Active**  
&gt;  
&gt;**2038-01-01 Adjusted expiration**

### Abstract

Methods, systems, and apparatus, including computer programs encoded on computer storage media, for processing inputs using a neural network system that includes a batch normalization layer. One of the methods includes receiving a respective first layer output for each training example in the batch; computing a plurality of normalization statistics for the batch from the first layer outputs; normalizing each component of each first layer output using the normalization statistics to generate a respective normalized layer output for each training example in the batch; generating a respective batch normalization layer output for each of the training examples from the normalized layer outputs; and providing the batch normalization layer output as an input to the second neural

[https://patents.google.com/patent/US20160217368A1/en](https://patents.google.com/patent/US20160217368A1/en)",106,160,False,self,,,,,
874,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,22,di7n9j,self.MachineLearning,Discord Server For Data Scraping,https://www.reddit.com/r/MachineLearning/comments/di7n9j/discord_server_for_data_scraping/,redsees,1571144856,"Hello everyone, due to the fact that lots of people are interested in online data scraping, we decided to start a dedicated Discord server for Data Scraping and related topics, everyone's welcomed to join! :)
https://discord.gg/3DUnNmN",0,1,False,self,,,,,
875,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,22,di7u52,self.MachineLearning,[R] How UMAP works -- a detailed comparison with t-SNE,https://www.reddit.com/r/MachineLearning/comments/di7u52/r_how_umap_works_a_detailed_comparison_with_tsne/,lmcinnes,1571145771,"A recent blog post [How Exactly UMAP Works](https://towardsdatascience.com/how-exactly-umap-works-13e3040e1668) provides a different perspective on explaining the UMAP dimensionality reduction, providing a more direct comparison with t-SNE in terms of computational approach. While the post is unfairly dismissive of t-SNE, readers here may gain some insight from this different presentation and detailed comparisons of how and why UMAP and t-SNE differ in various aspects on different tasks.",14,22,False,self,,,,,
876,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,22,di7vzi,blog.inten.to,Welcome to the Simulation. The Internet of Fakes,https://www.reddit.com/r/MachineLearning/comments/di7vzi/welcome_to_the_simulation_the_internet_of_fakes/,aleph_two,1571146010,,0,1,False,default,,,,,
877,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,22,di8189,self.MachineLearning,Research on Social Media and Machine Learning (Software)?,https://www.reddit.com/r/MachineLearning/comments/di8189/research_on_social_media_and_machine_learning/,helloiambrain,1571146694,[removed],0,1,False,self,,,,,
878,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,23,di8ky8,self.iOSProgramming,Style Transfer iOS Application Using Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/di8ky8/style_transfer_ios_application_using/,omarmhaimdat,1571149237,,0,1,False,https://b.thumbs.redditmedia.com/32y39YKXc84wIWaxKhJIDR3kTkXWQReYUPrhxJkmOvU.jpg,,,,,
879,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,23,di8qtn,self.MachineLearning,"Machine Learning in ""Simple English""",https://www.reddit.com/r/MachineLearning/comments/di8qtn/machine_learning_in_simple_english/,grossumsoft,1571149997,[removed],0,1,False,self,,,,,
880,MachineLearning,t5_2r3gv,2019-10-15,2019,10,15,23,di8zxh,theguardian.com,"How AI powered algorithms are transforming social welfare programs in the US,UK,Australia and India, while offering victims of errors little recourse",https://www.reddit.com/r/MachineLearning/comments/di8zxh/how_ai_powered_algorithms_are_transforming_social/,techpreneur_13,1571151133,,0,1,False,https://b.thumbs.redditmedia.com/pXaNcVnXIOMsvuxm5GwikrvwBIkH7Wr1z-F6Q5_2iCA.jpg,,,,,
881,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,0,di959d,youtu.be,AI learn to play my game,https://www.reddit.com/r/MachineLearning/comments/di959d/ai_learn_to_play_my_game/,lacaai,1571151780,,0,1,False,https://b.thumbs.redditmedia.com/d1lMVp_zoRewI4YQ_KGFyjPl8secFaQwaP2Jk95Rb3U.jpg,,,,,
882,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,0,di9k1m,medium.com,Zooming into the world of computer vision applications,https://www.reddit.com/r/MachineLearning/comments/di9k1m/zooming_into_the_world_of_computer_vision/,amarsingh1990,1571153575,,0,1,False,https://b.thumbs.redditmedia.com/ur0dCmEc7IuuKh8ZfBE_npgVo9DNyUm7q5lSu0AGQzM.jpg,,,,,
883,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,0,di9vfo,self.MachineLearning,[R] Measuring Arithmetic Extrapolation Performance,https://www.reddit.com/r/MachineLearning/comments/di9vfo/r_measuring_arithmetic_extrapolation_performance/,alrojo,1571154934,"Extrapolation on math is hard for NNs. We propose a new set of benchmarks and find current methods are fragile https://arxiv.org/abs/1910.01888.

So how should we build NNs that can learn the logic behind math? Inductive bias? More data does not seem to solve this problem!",0,5,False,self,,,,,
884,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,1,di9xov,twitter.com,Woj Zaremba on Twitter,https://www.reddit.com/r/MachineLearning/comments/di9xov/woj_zaremba_on_twitter/,SarvasvKulpati,1571155205,,0,1,False,https://b.thumbs.redditmedia.com/FU5PArncefO26tYnys3tIEN0xwB1ATi0MdahONAQdeU.jpg,,,,,
885,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,1,di9zc6,openai.com,OpenAI: Solving Rubiks Cube with a Robot Hand,https://www.reddit.com/r/MachineLearning/comments/di9zc6/openai_solving_rubiks_cube_with_a_robot_hand/,vijayabhaskar96,1571155388,,0,1,False,https://b.thumbs.redditmedia.com/yy65Kcu1G27HCEXFTFeV6Q0Twe8lvmjr1leXsRIK8ak.jpg,,,,,
886,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,1,dia5ww,openai.com,[R] Solving Rubiks Cube with a Robot Hand,https://www.reddit.com/r/MachineLearning/comments/dia5ww/r_solving_rubiks_cube_with_a_robot_hand/,_Mookee_,1571156172,,0,1,False,https://b.thumbs.redditmedia.com/yy65Kcu1G27HCEXFTFeV6Q0Twe8lvmjr1leXsRIK8ak.jpg,,,,,
887,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,1,diafpt,self.MachineLearning,I THINK YOUTUBE PREMIUM AD DOES NOT SHOW SIRAJ RAVAL ANYMORE,https://www.reddit.com/r/MachineLearning/comments/diafpt/i_think_youtube_premium_ad_does_not_show_siraj/,susmit410,1571157311,[removed],0,1,False,self,,,,,
888,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,1,diahat,self.MachineLearning,Transition from hardware background to ML?,https://www.reddit.com/r/MachineLearning/comments/diahat/transition_from_hardware_background_to_ml/,emkong,1571157486,[removed],0,1,False,self,,,,,
889,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,1,diahus,self.MachineLearning,[R] Video Analysis: LeDeepChef  Deep Reinforcement Learning Agent for Families of Text-Based Games,https://www.reddit.com/r/MachineLearning/comments/diahus/r_video_analysis_ledeepchef_deep_reinforcement/,ykilcher,1571157545,[removed],0,1,False,self,,,,,
890,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,2,diav2z,/r/MachineLearning/comments/diav2z/generative_adversarial_networks_are_coming_eyes/,Generative Adversarial Networks are coming! Eyes open to eyes closed. | www.bloomapp.ai,https://www.reddit.com/r/MachineLearning/comments/diav2z/generative_adversarial_networks_are_coming_eyes/,nextart-io,1571159056,,1,1,False,default,,,,,
891,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,2,dibf0c,openai.com,[R] Solving Rubiks Cube with a Robot Hand,https://www.reddit.com/r/MachineLearning/comments/dibf0c/r_solving_rubiks_cube_with_a_robot_hand/,jboyml,1571161281,,0,1,False,https://b.thumbs.redditmedia.com/yy65Kcu1G27HCEXFTFeV6Q0Twe8lvmjr1leXsRIK8ak.jpg,,,,,
892,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,2,dibnqe,self.MachineLearning,"[P] Albumentations, an image augmentation library version 0.4 released. New augmentations, support for images and masks with more than 3 channels, ""Hall of Fame"" that contains a list of machine learning competitions in which the library was used.",https://www.reddit.com/r/MachineLearning/comments/dibnqe/p_albumentations_an_image_augmentation_library/,alexparinov,1571162272,"# New augmentations

We added 10 new transforms, among them Solarize, Equalize, and Posterize that were used in [AutoAugment](https://arxiv.org/abs/1805.09501) and [RandAugment](https://arxiv.org/abs/1909.13719) papers.

Here is an example of some new transforms:

https://i.redd.it/wi8mcxkntqs31.png

# Support for images and masks with more than 3 channels

There are cases when you need to work with images and masks that have more than 3 channels (for example, Geospatial Images may contain 8 or more channels). Now the library supports multispectral images.

# Added a page that lists pre-prints and papers that cite albumentations

We are delighted that albumentations are helpful to the academic community. We extended documentation with a [page](https://github.com/albu/albumentations/blob/master/docs/citations.rst) that lists all papers and preprints that cite albumentations in their work. At this moment, this number is 24.

## Added a page that lists competitions in which top teams used albumentations.

We are delighted that albumentations help people to get top results in machine learning competitions at [Kaggle](https://www.kaggle.com/) and other platforms. We added a [""Hall of Fame""](https://github.com/albu/albumentations/blob/master/docs/hall_of_fame.rst) where people can share their achievements.

This page contains a list of competitions, usually with sample code or a link to a paper. We encourage people to add more information about their results with pull requests, following the [contributing guide](https://github.com/albu/albumentations/blob/master/docs/contributing.rst).

You can install the new version by running `pip install -U albumentations`.

Full release notes are [available on GitHub](https://github.com/albu/albumentations/releases/tag/0.4.0).",2,48,False,https://a.thumbs.redditmedia.com/KvFQ-KNqscldAMCd0qexofjKVXSaqX8HWo3kYa0Zoj8.jpg,,,,,
893,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,3,dibqv3,medium.com,"OpenAI Robot Hand: Today Rubiks Cube, Tomorrow the Real World?",https://www.reddit.com/r/MachineLearning/comments/dibqv3/openai_robot_hand_today_rubiks_cube_tomorrow_the/,Yuqing7,1571162622,,0,1,False,https://b.thumbs.redditmedia.com/6rRlrW-1w19t29xyCMW7TTCMvf9ympEd-rYkyj1wuTE.jpg,,,,,
894,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,3,dibyx5,self.MachineLearning,Training a LSTM to detect exact start and end of gestures,https://www.reddit.com/r/MachineLearning/comments/dibyx5/training_a_lstm_to_detect_exact_start_and_end_of/,1neuron,1571163523,[removed],0,1,False,self,,,,,
895,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,3,dic4fe,self.MachineLearning,Can I include essays in my portfolio?,https://www.reddit.com/r/MachineLearning/comments/dic4fe/can_i_include_essays_in_my_portfolio/,iNeedSleep-,1571164160,[removed],0,1,False,self,,,,,
896,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,3,dic4t7,self.MachineLearning,Creating training data for accelerometer gesture recognition,https://www.reddit.com/r/MachineLearning/comments/dic4t7/creating_training_data_for_accelerometer_gesture/,1neuron,1571164202,[removed],0,1,False,self,,,,,
897,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,4,dicpsy,self.MachineLearning,What would be a good neural network model when my data-set contains hierarchical structure ?,https://www.reddit.com/r/MachineLearning/comments/dicpsy/what_would_be_a_good_neural_network_model_when_my/,BAismyhome,1571166615,[removed],0,1,False,self,,,,,
898,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,4,dicre5,youtube.com,Why Siraj Raval is a Scammer and Fraud,https://www.reddit.com/r/MachineLearning/comments/dicre5/why_siraj_raval_is_a_scammer_and_fraud/,Trenblack,1571166794,,0,2,False,https://b.thumbs.redditmedia.com/7FaIFyvUwB-p4c9p7jft_dyiLlBLMx1GuYGxzXLeusU.jpg,,,,,
899,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,4,did5ka,m.youtube.com,"(OC) My own implementation of object tracking using an Xbox 360 Kinect, a dynamixel Pan/Tilt turret, ROS and YOLOv3",https://www.reddit.com/r/MachineLearning/comments/did5ka/oc_my_own_implementation_of_object_tracking_using/,Fuylo88,1571168373,,2,1,False,https://b.thumbs.redditmedia.com/jUI-UAM3AuIL3IE_x6x8lhU0A5v_jzTRD7Fn-BA2C_k.jpg,,,,,
900,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,4,did60m,futureslimited.com,Distinguishing the Senses of Machine Consciousness,https://www.reddit.com/r/MachineLearning/comments/did60m/distinguishing_the_senses_of_machine_consciousness/,missy_shell02,1571168422,,0,1,False,https://b.thumbs.redditmedia.com/V_QK7yaqx4QFoxuuMLgd1yLaIlkexEg_7A3WxL_JCIw.jpg,,,,,
901,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,4,did7vc,self.MachineLearning,Should I major in computer science or applied mathematics if I want to work with A.I. ( deep learning),https://www.reddit.com/r/MachineLearning/comments/did7vc/should_i_major_in_computer_science_or_applied/,pitin753,1571168618,[removed],0,1,False,self,,,,,
902,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,4,diddno,self.MachineLearning,[P] I have a challenge for you!,https://www.reddit.com/r/MachineLearning/comments/diddno/p_i_have_a_challenge_for_you/,i-make-robots,1571169260,"I know it's easier to learn robotics when I've decided on a robot to build.  In the same way, I bet it's easier to learn ML when you have a specific goal in mind.  Maybe even something novel.  So.  

My challenge to you is to train a ML artist.  this would be a network that inputs a bitmap picture and outputs a set of vectors that could be drawn by a plotter robot.  I have lots of non-ML image-&gt;vector converters and I'm a big fan of [turtletoy.net](https://turtletoy.net).  I would like to see your network run on turtetoy given a source image.  They could be any style you want.  You don't have to share your training data, just the final resulting weights and the NN to run in javascript on their site.  Your result would be public for everyone to try and enjoy, while your trade secret training stays all yours.",10,0,False,self,,,,,
903,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,4,didgfl,medium.com,How-to Get Started with Machine Learning on Arduino,https://www.reddit.com/r/MachineLearning/comments/didgfl/howto_get_started_with_machine_learning_on_arduino/,gvarisco,1571169567,,0,1,False,https://b.thumbs.redditmedia.com/DRhpbxbXgOlOzxPwsQFilI05gakU72tH3IVHz7JD8PU.jpg,,,,,
904,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,5,didnj2,self.MachineLearning,Multi-model gpu inference in production,https://www.reddit.com/r/MachineLearning/comments/didnj2/multimodel_gpu_inference_in_production/,shomerj,1571170342,"I am currently working for a startup and I need to develop a multi-gpu server for production inference. I want to load each of my models on a separate gpus and make inferences in parallel.  Some models can run in complete parallel and others rely on the prediction of previous models. My thought is to use a domain socket or tcp to configure this process. I am not to familiar with setting up an infrastructure like this. 

So my question is can anyone point me to some papers or further information on this? Would anyone be willing to give some personal insight?",0,1,False,self,,,,,
905,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,5,didttf,self.MachineLearning,Should I get a PhD if I want a business?,https://www.reddit.com/r/MachineLearning/comments/didttf/should_i_get_a_phd_if_i_want_a_business/,pitin753,1571171046,[removed],0,1,False,self,,,,,
906,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,5,die2ld,self.MachineLearning,"pretrained word embeddings vs BPE, which is better for machine translation?",https://www.reddit.com/r/MachineLearning/comments/die2ld/pretrained_word_embeddings_vs_bpe_which_is_better/,md1630,1571172013,[removed],0,1,False,self,,,,,
907,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,5,die2ss,self.MachineLearning,Beginning to Machine Learning,https://www.reddit.com/r/MachineLearning/comments/die2ss/beginning_to_machine_learning/,lordchiefpenguin,1571172039,[removed],0,1,False,self,,,,,
908,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,6,dies5d,self.MachineLearning,Microsoft Cloud Data Science with Azure Machine Learning Training &amp; Certification  Take your career &amp; income to the next level,https://www.reddit.com/r/MachineLearning/comments/dies5d/microsoft_cloud_data_science_with_azure_machine/,internetdigitalentre,1571174888,[removed],0,1,False,self,,,,,
909,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,6,dieze8,self.MachineLearning,Microsoft Cloud Data Science with Azure Machine Learning Training  Take your career &amp; income to the next level,https://www.reddit.com/r/MachineLearning/comments/dieze8/microsoft_cloud_data_science_with_azure_machine/,internetdigitalentre,1571175727,[removed],0,1,False,self,,,,,
910,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,7,difly1,self.MachineLearning,Do you build algorithms from scratch?,https://www.reddit.com/r/MachineLearning/comments/difly1/do_you_build_algorithms_from_scratch/,betelgeuse910,1571178363,[removed],0,1,False,self,,,,,
911,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,7,difsyk,self.MachineLearning,"Siraj Raval: ""I am a slave to the youtube algorithm""",https://www.reddit.com/r/MachineLearning/comments/difsyk/siraj_raval_i_am_a_slave_to_the_youtube_algorithm/,Mr-Yellow,1571179203,[removed],0,1,False,self,,,,,
912,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,8,digbfg,self.MachineLearning,Any papers on classifying objects after detecting them,https://www.reddit.com/r/MachineLearning/comments/digbfg/any_papers_on_classifying_objects_after_detecting/,briculmircea2,1571181505,[removed],0,1,False,self,,,,,
913,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,8,digsli,self.MachineLearning,skewness and correlation,https://www.reddit.com/r/MachineLearning/comments/digsli/skewness_and_correlation/,karminsam,1571183628,"Hey guys ! 

Can you help?

I have a dataset on which i want to run a machine learning algorithm , some of the columns are skewed so if i apply a transformation lets say log to those columns and i want to display the matrix of correlation should i do it before or after handling skewness or should i not do it all ?",0,1,False,self,,,,,
914,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,9,digzic,csail.mit.edu,Using AI to predict breast cancer and personalize care,https://www.reddit.com/r/MachineLearning/comments/digzic/using_ai_to_predict_breast_cancer_and_personalize/,mrizk411,1571184568,,41,261,False,https://b.thumbs.redditmedia.com/4a2MBwZtBmLnChYnwdDz0CUGf6oMIMLyUGM4GIoE03c.jpg,,,,,
915,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,9,dih1xu,self.MachineLearning,Can non-novelty research be relevant? And which fields could be more explored?,https://www.reddit.com/r/MachineLearning/comments/dih1xu/can_nonnovelty_research_be_relevant_and_which/,lendacerda,1571184877,[removed],0,1,False,self,,,,,
916,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,9,dihjy0,self.MachineLearning,Anyone else sad that Siraj's Netflix series was cancelled?,https://www.reddit.com/r/MachineLearning/comments/dihjy0/anyone_else_sad_that_sirajs_netflix_series_was/,sdmskdlsadaslkd,1571187320,"Honestly, I sort-of want to see how that Netflix series would be like.

It would basically be a great comedy and he would say things like ""quantum doors"".",0,1,False,self,,,,,
917,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,11,diihd6,openai.com,"""Solving Rubiks Cube with a Robot Hand"", on Akkaya et al 2019 {OA} [Dactyl followup w/improved curriculum-learning domain randomization; emergent meta-learning]",https://www.reddit.com/r/MachineLearning/comments/diihd6/solving_rubiks_cube_with_a_robot_hand_on_akkaya/,sorrge,1571191817,,0,1,False,https://b.thumbs.redditmedia.com/yy65Kcu1G27HCEXFTFeV6Q0Twe8lvmjr1leXsRIK8ak.jpg,,,,,
918,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,11,diijdr,self.MachineLearning,Is there a way to create an AI that can sing like Linda Rondstandt?,https://www.reddit.com/r/MachineLearning/comments/diijdr/is_there_a_way_to_create_an_ai_that_can_sing_like/,MrWilsonTheBall,1571192079,[removed],0,1,False,self,,,,,
919,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,11,diik8v,i.redd.it,The state of this sub.,https://www.reddit.com/r/MachineLearning/comments/diik8v/the_state_of_this_sub/,xylont,1571192200,,0,1,False,default,,,,,
920,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,11,diiwec,self.MachineLearning,3D Cars dataset used in Disentanglement literature,https://www.reddit.com/r/MachineLearning/comments/diiwec/3d_cars_dataset_used_in_disentanglement_literature/,tensorflower,1571193850,[removed],0,1,False,self,,,,,
921,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,11,diiwx3,self.MachineLearning,[P] 3D Cars Dataset used in disentanglement literature,https://www.reddit.com/r/MachineLearning/comments/diiwx3/p_3d_cars_dataset_used_in_disentanglement/,tensorflower,1571193920,"Does anyone know where to obtain the ""3D Cars dataset"" used in the disentanglement literature? e.g. this recent paper: https://arxiv.org/abs/1905.12614 (landing page), Figure 1. 

I've basically traced the citation breadcrumb to this original paper: [1] (warning:pdf) with associated download [2] (warning: large .tar file) which only provides the basic 3D CAD models but not the more advanced latent factor variations shown in the linked Deepmind paper above. Would be nice for reproducibility of results.

[1]: https://papers.nips.cc/paper/5845-deep-visual-analogy-making.pdf
[2]: http://www-personal.umich.edu/~reedscot/files/nips2015-analogy-data.tar.gz",0,3,False,self,,,,,
922,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,11,diiz8g,self.MachineLearning,Cs ml project ideas suggestions,https://www.reddit.com/r/MachineLearning/comments/diiz8g/cs_ml_project_ideas_suggestions/,KidDora7,1571194248,"Hello all, i am cs student i have to create an android application which utilizes hardware sensor like gyroscope, proximity sensor, acclerometer. We cannot use camera.
And the app has to have some kind of basic machine learning implementation. 
Can anyone give suggestions for the possible ideas that i can use.

Thanks",0,1,False,self,,,,,
923,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,12,dijgy9,self.MachineLearning,[D] Custom Vocabulary addition to Speech Recognition,https://www.reddit.com/r/MachineLearning/comments/dijgy9/d_custom_vocabulary_addition_to_speech_recognition/,nottakumasato,1571196703,"Hi everyone,

My current project requires the speech recognition model to output custom domain-specific vocabulary. To be honest, the domain specific named entities are the most important to output correctly. In my literature review, I was unable to find any paper that had inclusion of vocabulary that the model was not trained on. Any paper/article recommendations are welcome!",7,5,False,self,,,,,
924,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,13,dijxue,i.redd.it,The state of this sub.,https://www.reddit.com/r/MachineLearning/comments/dijxue/the_state_of_this_sub/,xylont,1571199202,,0,0,False,default,,,,,
925,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,13,dik1lr,self.MachineLearning,"[P] My implementation of object tracking using an Xbox 360 Kinect, a dynamixel Pan/Tilt turret, ROS and YOLOv3",https://www.reddit.com/r/MachineLearning/comments/dik1lr/p_my_implementation_of_object_tracking_using_an/,Oswald_Hydrabot,1571199790,"This is a little video clip I made of a project of mine where I've used the 2D bounding box data from PJReddie's YOLOv3 to guide the joint positions of a pan tilt servo.

https://m.youtube.com/watch?v=_iQWCRToUkA

The simplified version of how this works, is that I created an ROS node that utilizes OpenCV to syncronize the depth frame with the RGB camera frame from the Kinect 360. In the callback function, I then calculate the centermost rgb pixel matrix coordinates of the bounding box if a detected object, and retrieve the depth data from the syncronized depth image (uv,xyz). I then convert that to a post stamped message that is sent to a modified ""head_tracker.py"" module from the original rbx2 code (sourced below).

Some of the prep work and background on this project:

I used Google's OpenImages V4 to train YOLO and create the pretrained weights for ""Human Head"" detection that I'm using here. (V5 is out now?.. mmmm juicy!) Here's my tutorial I made for this process: https://github.com/WyattAutomation/Train-YOLOv3-with-OpenImagesV4

The version of ROS used here is Melodic, running on Xubuntu 18.04. You have to build the freenect dependencies and ROS package for the 360 Kinect from source (doesn't appear to be an apt install option for melodic?)

I also used leggedrobotic's darknet_ros ROS module for YOLO:
https://github.com/leggedrobotics/darknet_ros

The robotics hardware I used here is a PhantomX pan/tilt turret from Trossen robotics with 2 Dynamixel ax18-a's: https://www.trossenrobotics.com/p/phantomX-robot-turret.aspx

And probably the most important to mention out of all, I rewrote the nearest_pointcloud ROS node and other code from Robotics by Example, Vol2, retrofitting it for the purpose of tracking objects in 3D space from the 2D bounding box pixel coordinates published by the YOLOv3 ROS package: https://github.com/pirobot/rbx2

I'll be willing to answer any questions on how I got this working, so feel free to ask!

I have a version of this that uses an Astra Orrbec Pro and I am nearly finished setting it up to run on a Raspberry Pi 4, with Darknet/YOLO running remotely and publishing rostopics over WAN or LAN from my desktop (using a GTX 1060 for YOLO).

I will post progress as it is made, as well as comprehensive documentation and source code on my GitHub account on this build, for whoever it may help. If you like it, feel free to visit my Patreon!",2,23,False,self,,,,,
926,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,14,dikfot,self.MachineLearning,[D] How superior is inter compared to Ryzen for ML/DL?,https://www.reddit.com/r/MachineLearning/comments/dikfot/d_how_superior_is_inter_compared_to_ryzen_for_mldl/,BlueFrenchHornThief,1571202082,"I am looking to buy a laptop that can handle basic ML/DL stuff  for fastai and andrew ng's deep learning and tensorflow course.

I've come across two laptops. One with i5 9th Gen + GTX 1650 4GB and another with Ryzen 5 3550H + 1650 4GB. Except the processor all the specs are same but Intel laptop costs 150$ higher than the Ryzen one.

I've looked around but haven't found much. Some say ryzen is good and some say intel is way better because of the 'Intel MKL'. Is 'Intel MKL' worth the extra 150$? What would you suggest?",11,3,False,self,,,,,
927,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,15,dil35i,slideshare.net,Get certification in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/dil35i/get_certification_in_machine_learning/,prih_yah,1571206040,,0,1,False,default,,,,,
928,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,15,dil6xh,self.MachineLearning,Text Generation using NLP,https://www.reddit.com/r/MachineLearning/comments/dil6xh/text_generation_using_nlp/,rasikapurohit,1571206735,[removed],0,1,False,self,,,,,
929,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,15,dilc31,cogitotech.com,Computer Vision in Medical Imaging to Improve Diagnostic Accuracy,https://www.reddit.com/r/MachineLearning/comments/dilc31/computer_vision_in_medical_imaging_to_improve/,cogitotechllc,1571207662,,0,1,False,default,,,,,
930,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,16,dilsam,self.MachineLearning,"Encryption Software Market Trends, Key Players, Overview, Competitive Breakdown and Regional 2026 Forecast",https://www.reddit.com/r/MachineLearning/comments/dilsam/encryption_software_market_trends_key_players/,yaminiamrale,1571210627,"New York, NY 16 Oct 2019:The global[encryption software market](https://www.polarismarketresearch.com/industry-analysis/encryption-software-market)size is anticipated to reach USD 20.44 billion by 2026 according to a new research published by Polaris Market Research. The report***Encryption Software Market Share, Size, Trends, Industry Analysis Report By Deployment Model (On-Premise, Cloud-Based); By Application (File Encryption, Disk Encryption, Database Encryption, Cloud Encryption, Communication Encryption, Others); By Organization Size (Large Enterprises, Small and Medium Businesses); By End-User (BFSI, Healthcare, Aerospace and Defense, Government and Public Utilities, Retail, Others); By Regions, Segments &amp; Forecast, 2019  2026***provides strong market indices and taps on future growth parameters.

In 2018, the BFSI segment dominated the global market in terms of revenue. North America was the leading contributor to global revenue in 2018. An urgency to protect critical data and growing number of data lapses has boosted the adoption of encryption software. The widespread growth of mobile devices and increasing trend of BYOD further support the growth of this market. The rising spread of virtualization, cloud and big data analytics has supported market growth over the years. Growing investments in technological advancements by vendors, coupled with growing demand for cloud-based encryption software would accelerate the growth of encryption software market during forecast period. However high costs related to advanced encryption solutions and an awareness shortage among small and medium enterprises hinder growth. Growing demand from developing economies and technological advancements are expected to provide several growth opportunities in the future.

North America generated highest revenue for market in 2018 and is expected to lead the global market throughout forecast period. The increase in number of cyber-attacks and growing number of data breaches drive the market growth. A growing trend of BYOD, IoT, big data analytics and virtualization evinces the need of encryption software for data protection and data loss. A rising penetration of mobile devices and technological advancements bolster growth in the region. A greater spending on data protection in BFSI and defense sectors in the region promotes growth in the region.

A rushing request from emerging economies, expanding adoption of the software by BFSI sector and flooding demand for cloud-based encryption solutions are factors boosting growth of product during forecast period.

**The sample for the study can be requested using the following link:** [https://www.polarismarketresearch.com/industry-analysis/encryption-software-market/request-for-sample](https://www.polarismarketresearch.com/industry-analysis/encryption-software-market/request-for-sample)

Enormous walks in strong innovation, data loss among enterprises has made encryption software very crucial for safe data transmissions. Furthermore, as undertakings are pushing forward with distributed computing, the product has become all the more important to prevent data slips by safeguarding touchy information.

Asia Pacific is expected to display highest CAGR during forecast period owing to urging need for data integrity at all levels in the industries in developing countries of the region.

**The companies include** Microsoft Corporation, Symantec Corporation, IBM Corporation, EMC Corporation, CISCO Systems Inc., Intel Security, Check Point Software Technologies Ltd., Oracle Corporation, Trend Micro, Inc., and Sophos Group Plc. among others.

**Polaris Market research has segmented the encryption software market report on the basis of deployment, application, organization size, end-use and region.**

* **Encryption Software Deployment Model Outlook (Revenue USD Millions 2015  2026)**
   * On-Premise
   * Cloud- Based
* **Encryption Software Application Outlook (Revenue USD Millions 2015  2026)**
   * File Encryption
   * Disk Encryption
   * Database Encryption
   * Cloud Encryption
   * Communication Encryption
   * Others
* **Encryption Software Organization Size Outlook (Revenue USD Millions 2015  2026)**
   * Large Enterprises
   * Small Enterprises
   * Medium Enterprises
* **Encryption Software End-user Outlook (Revenue USD Millions 2015  2026)**
   * BFSI
   * Healthcare
   * Aerospace and Defense
   * Government and Public Utilities
   * Retail
   * Others
* **Encryption Software Regional Outlook (Revenue USD Millions 2015  2026)**
   * North America
      * US.
      * Canada
   * Europe
      * UK
      * France
      * Germany
      * Italy
   * Asia Pacific
      * India
      * Japan
      * China
   * Latin America
      * Brazil
      * Mexico
   * Middle East &amp; Africa

**Request for discount on this market study @** [https://www.polarismarketresearch.com/industry-analysis/encryption-software-market/request-for-discount-pricing](https://www.polarismarketresearch.com/industry-analysis/encryption-software-market/request-for-discount-pricing)

**About Polaris Market Research**Polaris Market Research is a global market research and consulting company. The company specializes in providing exceptional market intelligence and in-depth business research services for our clientele spread across different enterprises. We at Polaris are obliged to serve our diverse customer base present across the industries of healthcare, technology, semi-conductors and chemicals among various other industries present around the world. We strive to provide our customers with updated information on innovative technologies, high growth markets, emerging business environments and latest business-centric applications, thereby helping them always to make informed decisions and leverage new opportunities. Adept with a highly competent, experienced and extremely qualified team of experts comprising SMEs, analysts and consultants, we at Polaris endeavour to deliver value-added business solutions to our customers.

**Contact Us:**Mr. LikhilCorporate Sales, USAPolaris Market ResearchPhone: 1-646-568-9980**Email:** [**sales@polarismarketresearch.com**](mailto:sales@polarismarketresearch.com)**Web:** [**www.polarismarketresearch.com**](http://www.polarismarketresearch.com/)",0,0,False,self,,,,,
931,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,16,dilvub,self.MachineLearning,"Smart Agriculture Market Strategies, Major Industry Participants, Marketing Channels and Forecast To 2026",https://www.reddit.com/r/MachineLearning/comments/dilvub/smart_agriculture_market_strategies_major/,yaminiamrale,1571211301,[removed],0,1,False,self,,,,,
932,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,16,dilwc3,huspi.com,Machine Learning Guide: What you need to know,https://www.reddit.com/r/MachineLearning/comments/dilwc3/machine_learning_guide_what_you_need_to_know/,Huspi_sp_z_o_o,1571211396,,0,1,False,default,,,,,
933,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,16,dilwpm,arxiv.org,"[R] Connections between Support Vector Machines, Wasserstein distance and gradient-penalty GANs",https://www.reddit.com/r/MachineLearning/comments/dilwpm/r_connections_between_support_vector_machines/,baylearn,1571211486,,8,58,False,default,,,,,
934,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,16,dilytb,self.MachineLearning,Machine Learning - Services - Webtunix,https://www.reddit.com/r/MachineLearning/comments/dilytb/machine_learning_services_webtunix/,OliviaWillson,1571211910,[removed],0,1,False,self,,,,,
935,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,16,dim0lk,bestofml.com,"[P] HackerNews for Machine Learning Papers, Guides, Books, Courses and more",https://www.reddit.com/r/MachineLearning/comments/dim0lk/p_hackernews_for_machine_learning_papers_guides/,Sig_Luna,1571212254,,0,1,False,default,,,,,
936,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,16,dim1up,self.MachineLearning,Good handbook around Knowledge Graph and Information Extraction,https://www.reddit.com/r/MachineLearning/comments/dim1up/good_handbook_around_knowledge_graph_and/,SoMuchQuestions,1571212521,[removed],0,1,False,self,,,,,
937,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,17,dim58z,self.MachineLearning,Which Valve To Use For Adjust / Control Gas Flow ?,https://www.reddit.com/r/MachineLearning/comments/dim58z/which_valve_to_use_for_adjust_control_gas_flow/,uflowindia,1571213225,[removed],0,1,False,https://b.thumbs.redditmedia.com/0EtbfhQiWkLOt1vF0m7R91hcdOlS4d16X2V7FK-0DTo.jpg,,,,,
938,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,17,dim7kt,self.MachineLearning,Equation to optimize variables.,https://www.reddit.com/r/MachineLearning/comments/dim7kt/equation_to_optimize_variables/,siot8438,1571213672,[removed],0,1,False,self,,,,,
939,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,17,dimggj,self.MachineLearning,How does the type of feedback affect the learning algorithm?,https://www.reddit.com/r/MachineLearning/comments/dimggj/how_does_the_type_of_feedback_affect_the_learning/,SolomonicScrotum,1571215575,[removed],0,1,False,self,,,,,
940,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,18,din216,analyticspath.com,"Make the best career movie by attending for the Analytics Path Free Machine Learning Interactive Sessions in Hyderabad scheduled On 19th October, 10am, Hyderabad.",https://www.reddit.com/r/MachineLearning/comments/din216/make_the_best_career_movie_by_attending_for_the/,Jony1223,1571219746,,0,1,False,default,,,,,
941,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,19,din3z8,self.MachineLearning,Sudden Jump in loss,https://www.reddit.com/r/MachineLearning/comments/din3z8/sudden_jump_in_loss/,whatthefua,1571220086,[removed],0,1,False,self,,,,,
942,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,19,din4ql,self.MachineLearning,Acetic Anhydride Market Future Forecast 2019  2023,https://www.reddit.com/r/MachineLearning/comments/din4ql/acetic_anhydride_market_future_forecast_2019_2023/,jadhavni3,1571220222,[removed],1,1,False,self,,,,,
943,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,19,dina44,self.MachineLearning,"NLP: Word representation for morphologically rich languages (e.g. Polish, or Turkish) for sentiment analysis",https://www.reddit.com/r/MachineLearning/comments/dina44/nlp_word_representation_for_morphologically_rich/,ai_think,1571221209,"BPE (Byte Pair Encoding) seems to be a natural choice of word representation for morphologically rich languages. However, I wonder what your experiences with using different representations such as n-grams, or word2vecs are?",0,1,False,self,,,,,
944,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,19,dinasy,self.MachineLearning,Global Airport Information System Market Report 2019,https://www.reddit.com/r/MachineLearning/comments/dinasy/global_airport_information_system_market_report/,jadhavni3,1571221336,[removed],1,1,False,self,,,,,
945,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,19,dindhj,self.MachineLearning,"[D] NLP: Word representation for morphologically rich languages (e.g. Polish, or Turkish) for sentiment analysis",https://www.reddit.com/r/MachineLearning/comments/dindhj/d_nlp_word_representation_for_morphologically/,ai_think,1571221810,"BPE  (Byte Pair Encoding) seems to be a natural choice of word representation for morphologically rich languages. However, I wonder what your experiences with using different representations (such as *n-grams*, *word2vecs, etc.*) are?",9,10,False,self,,,,,
946,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,19,dinkuf,self.MachineLearning,[D] What's your monitor setup? What is the best monitor on a reasonable budget?,https://www.reddit.com/r/MachineLearning/comments/dinkuf/d_whats_your_monitor_setup_what_is_the_best/,Regressionmodel4,1571223110,"I'm starting to get into ML and I'm curious what monitor setup you guys are using.  My GPU supports up to 4 monitors but at the moment I just use an old single one (1440x900).  I could also get one really wide one (one of those curved gamer ones) if you thought it was reasonable.

What is your setup?  What do you recommend for a (reasonable) budget?",19,0,False,self,,,,,
947,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,20,dinsdn,self.MachineLearning,Industrial Communication Gateways Market Future Forecast 2019  2023,https://www.reddit.com/r/MachineLearning/comments/dinsdn/industrial_communication_gateways_market_future/,jadhavni3,1571224335,[removed],1,1,False,self,,,,,
948,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,20,dintgs,self.MachineLearning,"Hi guys, Im doing a research topic about generative adversarial networks and I need an angle to write the topic from. Does anyone have any suggestions?",https://www.reddit.com/r/MachineLearning/comments/dintgs/hi_guys_im_doing_a_research_topic_about/,dontuseyourreal_name,1571224508,[removed],0,1,False,self,,,,,
949,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,20,dinxfb,self.MachineLearning,How can I rent computer resources in a cloud?,https://www.reddit.com/r/MachineLearning/comments/dinxfb/how_can_i_rent_computer_resources_in_a_cloud/,BeggarInSpain,1571225161,"Hey!

I thought I could rent some VM with a decent amount of RAM and GPU for my projects in MS Azure. What's your thoughts? Do you have an experience how much that might cost? Thanks!",0,1,False,self,,,,,
950,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,20,dinz4j,self.MachineLearning,Inventory Tracking System Market Future Forecast 2019  2023,https://www.reddit.com/r/MachineLearning/comments/dinz4j/inventory_tracking_system_market_future_forecast/,jadhavni3,1571225412,[removed],1,1,False,self,,,,,
951,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,20,dio06k,ajolicoeur.wordpress.com,"[R] Blog post on ""Connections between SVMs, Wasserstein distance and GANs""",https://www.reddit.com/r/MachineLearning/comments/dio06k/r_blog_post_on_connections_between_svms/,AlexiaJM,1571225591,,1,12,False,https://b.thumbs.redditmedia.com/kv_vfUGblvJh12fQZAPltkR29EfWY2rYFWD_LZ_qPLA.jpg,,,,,
952,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,20,dio2o9,github.com,[P] Got a Linux server full of GPUs? Here's a Python package for keeping them cool,https://www.reddit.com/r/MachineLearning/comments/dio2o9/p_got_a_linux_server_full_of_gpus_heres_a_python/,andyljones,1571225986,,0,1,False,https://a.thumbs.redditmedia.com/YccADHEVHNXhKbnBhmzX-ztfVo2v-rW4OCEumEJdtw0.jpg,,,,,
953,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,20,dio8ic,self.MachineLearning,Global Smart and Connected Elevators Market Report 2019,https://www.reddit.com/r/MachineLearning/comments/dio8ic/global_smart_and_connected_elevators_market/,jadhavni3,1571226903,[removed],1,1,False,self,,,,,
954,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,21,dioce3,self.MachineLearning,Machine Learning project ideas,https://www.reddit.com/r/MachineLearning/comments/dioce3/machine_learning_project_ideas/,sheen09878,1571227459,[removed],0,1,False,self,,,,,
955,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,21,diohfd,self.MachineLearning,Automatic Fare Collection (AFC) Systems Market Future Forecast 2019  2023,https://www.reddit.com/r/MachineLearning/comments/diohfd/automatic_fare_collection_afc_systems_market/,jadhavni3,1571228216,[removed],1,1,False,self,,,,,
956,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,21,diomhs,self.MachineLearning,Need a list of all pre-trained Neural Networks available online,https://www.reddit.com/r/MachineLearning/comments/diomhs/need_a_list_of_all_pretrained_neural_networks/,Shatrunjay,1571228976,[removed],0,1,False,self,,,,,
957,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,21,diomya,arxiv.org,Hidden Stratification Causes Clinically Meaningful Failures in Machine Learning for Medical Imaging,https://www.reddit.com/r/MachineLearning/comments/diomya/hidden_stratification_causes_clinically/,rumblestiltsken,1571229050,,2,1,False,default,,,,,
958,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,21,diorv1,arxiv.org,[R] Hidden Stratification Causes Clinically Meaningful Failures in Machine Learning for Medical Imaging,https://www.reddit.com/r/MachineLearning/comments/diorv1/r_hidden_stratification_causes_clinically/,rumblestiltsken,1571229730,,52,151,False,default,,,,,
959,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,21,diov5q,self.MachineLearning,"[P] Headliner, a new sequence modeling library that eases the training and in particular, the deployment of custom sequence models",https://www.reddit.com/r/MachineLearning/comments/diov5q/p_headliner_a_new_sequence_modeling_library_that/,datitran,1571230213,"We've just open-sourced our library headliner which is a sequence modeling library that eases the training and in particular, the deployment of custom sequence models. It was originally built for our own research at [Axel Springer AI](https://ai.axelspringer.com) to generate headlines from [Welt](https://www.welt.de) news articles (see figure 1). That's why we chose the name, Headliner. Although this library was created internally to generate headlines, you can also use it for other tasks like machine translations, text summarization and many more.

[Figure 1: One example from our Welt.de headline generator.](https://i.redd.it/rvivxr4fgws31.png)

We built this library with the following goals in mind:

 Simple API for training and deployment (only a few lines of code)

 Uses TensorFlow 2.0 with all its new features

 Modular classes: text preprocessing, modeling, evaluation and easily extensible for different encoder-decoder models

 Works on large text data

&amp;#x200B;

Headliner is our first NLP project that we open-sourced and we're happy about this. Please try out our library,  it on Github and spread the word! We'd love to get feedback. #deeplearning #machinelearning #NLP

&amp;#x200B;

 Github: [https://github.com/as-ideas/headliner](https://github.com/as-ideas/headliner)

 Docs: [https://as-ideas.github.io/headliner/](https://as-ideas.github.io/headliner/)

 Demo: [https://github.com/as-ideas/headliner-demo](https://github.com/as-ideas/headliner-demo)",0,1,False,https://b.thumbs.redditmedia.com/-g76T96v3Ce--_Fyty36tGDtA-k14r4YuFbH1eyShfA.jpg,,,,,
960,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,21,diow84,self.MachineLearning,Construction and Mining Equipment Market Future Forecast 2019  2023,https://www.reddit.com/r/MachineLearning/comments/diow84/construction_and_mining_equipment_market_future/,jadhavni3,1571230368,[removed],1,1,False,self,,,,,
961,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,21,dioyea,self.MachineLearning,"Many object detection models focus on map, but have stopped listing any speeds. What are some good object detection projects that also provide a good speed trade?",https://www.reddit.com/r/MachineLearning/comments/dioyea/many_object_detection_models_focus_on_map_but/,halfassadmin,1571230668,[removed],0,1,False,self,,,,,
962,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,23,dipu60,youtube.com,Machine Learning Engineer sold startup for $60M,https://www.reddit.com/r/MachineLearning/comments/dipu60/machine_learning_engineer_sold_startup_for_60m/,That_Actuator,1571235028,,0,1,False,https://b.thumbs.redditmedia.com/80vDa66b3AIL2lwmQkuT80ukmAQ1NZAP6Dki57au0Ps.jpg,,,,,
963,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,23,dipwji,self.MachineLearning,Transformers for machine translation,https://www.reddit.com/r/MachineLearning/comments/dipwji/transformers_for_machine_translation/,guts781,1571235350,"are transformers the SOTA models in NMT in general ? or only when dealing with high resources languages? are they suitable when the languages are morphologically very different? 

by what high resource langage-pairs are defined by the number of words only? or by the quality of the translation dataset.",0,1,False,self,,,,,
964,MachineLearning,t5_2r3gv,2019-10-16,2019,10,16,23,diqf6g,youtube.com,Is optimization the right language to understand deep learning? - Sanjeev Arora,https://www.reddit.com/r/MachineLearning/comments/diqf6g/is_optimization_the_right_language_to_understand/,DrJohanson,1571237716,,0,1,False,default,,,,,
965,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,0,diqhl8,medium.com,Jupyter Notebook is the Cancer of ML Engineering,https://www.reddit.com/r/MachineLearning/comments/diqhl8/jupyter_notebook_is_the_cancer_of_ml_engineering/,_orcaman,1571238023,,0,1,False,default,,,,,
966,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,0,diqnxe,self.MachineLearning,Four way competition for Machine Learning PhD admission. Which background increases the odds of getting in?,https://www.reddit.com/r/MachineLearning/comments/diqnxe/four_way_competition_for_machine_learning_phd/,YouThinkFirst,1571238789,[removed],0,1,False,self,,,,,
967,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,0,diqvnz,self.MachineLearning,"Can anyone with a PhD in AI or any relating field like neuroscience,cs,etc answer some questions?",https://www.reddit.com/r/MachineLearning/comments/diqvnz/can_anyone_with_a_phd_in_ai_or_any_relating_field/,pitin753,1571239688,[removed],0,1,False,self,,,,,
968,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,0,diqyb7,self.MachineLearning,[P] PyCM 2.5 released : Multi-class confusion matrix library in Python,https://www.reddit.com/r/MachineLearning/comments/diqyb7/p_pycm_25_released_multiclass_confusion_matrix/,sepandhaghighi,1571240010," 

[https://www.pycm.ir](https://www.pycm.ir/)

[https://github.com/sepandhaghighi/pycm](https://github.com/sepandhaghighi/pycm)

&amp;#x200B;

* \_\_version\_\_ variable added [\#241](https://github.com/sepandhaghighi/pycm/issues/241)
* Individual classification success index (ICSI) added [\#238](https://github.com/sepandhaghighi/pycm/issues/238)
* Classification success index (CSI) added [\#238](https://github.com/sepandhaghighi/pycm/issues/238)
* Example-8 (Confidence interval) added [\#237](https://github.com/sepandhaghighi/pycm/issues/237)
* install.sh added
* autopep8.sh added
* Dockerfile added
* CI method added  [\#237](https://github.com/sepandhaghighi/pycm/issues/237)
   * ACC
   * AUC
   * Overall ACC
   * Kappa
   * TPR
   * TNR
   * PPV
   * NPV
   * PLR
   * NLR
   * PRE
* test.sh moved to .travis folder
* Python 3.4 support dropped
* Python 2.7 support dropped
* AUTHORS.md updated
* save\_stat, save\_csv and save\_html methods Non-ASCII character bug fixed [\#246](https://github.com/sepandhaghighi/pycm/issues/246)
* Mixed type input vectors bug fixed [\#240](https://github.com/sepandhaghighi/pycm/issues/240)
* CONTRIBUTING.md updated [\#245](https://github.com/sepandhaghighi/pycm/issues/245)
* Example-3 updated [\#239](https://github.com/sepandhaghighi/pycm/issues/239)
* README.md modified [\#248](https://github.com/sepandhaghighi/pycm/issues/248)
* Document modified [\#248](https://github.com/sepandhaghighi/pycm/issues/248)
* CI attribute renamed to CI95 [\#237](https://github.com/sepandhaghighi/pycm/issues/237)
* kappa\_se\_calc function renamed to kappa\_SE\_calc [\#237](https://github.com/sepandhaghighi/pycm/issues/237)
* se\_calc function modified and renamed to SE\_calc [\#237](https://github.com/sepandhaghighi/pycm/issues/237)
* CI/SE functions moved to pycm\_ci.py [\#237](https://github.com/sepandhaghighi/pycm/issues/237)
* Minor bug in save\_html method fixed",3,7,False,self,,,,,
969,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,0,dir32l,self.MachineLearning,Guesses on how NotCo uses machine learning,https://www.reddit.com/r/MachineLearning/comments/dir32l/guesses_on_how_notco_uses_machine_learning/,knuppar,1571240556,[removed],0,1,False,self,,,,,
970,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,0,dir7zs,self.MachineLearning,"Simple Questions Thread October 16, 2019",https://www.reddit.com/r/MachineLearning/comments/dir7zs/simple_questions_thread_october_16_2019/,AutoModerator,1571241156,[removed],0,1,False,self,,,,,
971,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,1,dirdg9,self.MachineLearning,What does the phrase AI Winter mean?,https://www.reddit.com/r/MachineLearning/comments/dirdg9/what_does_the_phrase_ai_winter_mean/,SolomonicScrotum,1571241798,What does the phrase AI Winter mean? What caused it? What did it cause? Do you think there will be another AI Winter in the next 10 years? Why or why not?,0,1,False,self,,,,,
972,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,1,dirime,self.MachineLearning,Join the League of Justice: I am creating a platform to gather all the people that got scammed by Siraj Raval and sue him for the damage caused.,https://www.reddit.com/r/MachineLearning/comments/dirime/join_the_league_of_justice_i_am_creating_a/,IGotScammedBySiraj,1571242371,"Hi Reddit, we are scammed students of Siraj Raval with some important things to say.

After struggling for quite some time and being hesitant for quite some time, I decided to take invest on myself when Siraj released his last fraud/course. I quit my job, gathered my savings, paid the guy and decided to stockpile food for the next 11 weeks to work intensively in changing my life and learning the skills I was always expecting to get to work in something I thought could have more meaning... And then Siraj happened.

It is very hard to put into words how much of a scam it is when literally ALL the things he said were nasty lies when we did not even have SLACK to communicate with peers, where the material was not even created for the course and plagiarised and he never had any tutors to help to learn as promised. But nothing sums it up as well as the week when Siraj ""Published"" """"his"""" """"""paper"""""". That week we saw a weak syllabus, no content created for the course, no tutors to help us interpret that mess of a course, 3 minutes videos. Furthermore, he was not even checking any message, and yet announcing on the Q and A session that he was about to release a paper... It was already suspicious. But then we found out about the double slack around the same day that he uploaded the video of the plagiarised paper.

I still remember the feeling of being there, sitting in my room, watching a guy with a stupid red blazer being so cocky and arrogant presenting something so difficult and elaborate that it already started smelling dodgy to many of the people in the slack, while he did not even answer some of our basic organisational questions. It was a massive scandal, the vibe of the community fell apart completely, the smartest and most capable students left, and the array of insults against Siraj was huge. But for some of us that were really invested, we did not want to see. I personally tried to justify him but realised that I struggled to remain motivated. I was feeling stupid reading all the things that other authors were developing for other purposes, while Siraj could not live up to his word. How could we take it from him?...

And then we found out about the plagiarism scandal. It's hard to state how bad everything turned out after that. Many of us have been greatly damaged by this.

I will summarise why because I am going to make some bold statements here:

1. How can we credit any value from a certificate expelled by a scammer? One thing is having not centralised education in modern internet times. Another thing is saying that I can get away with writing that I learn from this totally immoral guy.
2. Most of the value of his course was provided by the fact that he was going to set us up in contact with consulting partners, refer us to employers or pair us to start a project with other colleagues. Who would take any of the 3 comming from Siraj Raval? He would be lucky if he found a job for himself at this time. He said he was going to ask about our preferences around midd course and so far nothing happened, so I am guessing that this is also another made-up thing he did to scam as much money as possible.
3. The content is shit. I can not stress this enough. I do not even trust people on the other shitty app ""Discord"" who say its good. He hired halfway into the course STUDENTS to become MENTORS.
4. He presents ways to use ML in different industries but he is not giving a shit when asked about technical aspects of implementing it. Of what use is that to start a business on the things he preaches? Needless to say, the personal mentoring part is obviously a scam.
5. Those are the more obvious. I am sure you are familiar with the previous issues.

So here I am, 8 weeks into this scam, thinking about how to get back to my previous work. Thank god, my legal insurance plan WILL cover me on this case. I do not doubt that I can sound a bit naive, but I think I did have ""some"" chance to succeed if I wouldn't have gotten completely scammed.

Having said that, I want to say the following to Siraj if he is reading:

Siraj, you caused a great damage to many of us because of your lies and arrogance. It is not something that you ""Oversaw when focussed on your output goals"". We have coordinated with many of your former students and we are going to take you to court for this if you do not rectify before the end of your course.

We want you to:

1. Refund EVERY SINGLE STUDENT for the full amount. Not just those that so far requested a refund. Every single one of the 1200 people you successfully lied to and enrolled for something different to what you promised to deliver.
2. Issue a full apology without sugar coating and dodging responsibility as you always do

I do not know how you want to continue as a Youtube celebrity with this upon your shoulders, but it is out of question that you will not have future courses, or events without we finding out and chances are that after a long and expensive litigation in court, you will have to pay us a compensation. Your profits for scamming people are completely immoral. This is your last chance to do what's right. You have done wrong many times in your life but this time it will have huge consequences.

Unless you are planning on abandoning California and moving to Thailand to live out of your scammed money, come back to your senses now. It won't be easy afterwards.

To the community: thanks for reading and please, if Siraj doesn't want to do what is right here, I hope you can help us with a sabotage in the name of justice, by unsubscribing from his channel, ignoring him and helping us to email all his ""business partners"" to make sure that they know who they have on board. He may truly become more conscious about the output this way next time.

If you also felt scammed, please write me a PM, we will contact you as soon as we don't have a response from him and we prepare everything to keep moving.

Thanks to all the amazing people of this sub-forum,

The League of Justice.",0,1,False,self,,,,,
973,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,1,dirmfx,self.MachineLearning,Asset Price Prediction,https://www.reddit.com/r/MachineLearning/comments/dirmfx/asset_price_prediction/,ddias19,1571242825,"Out of the most random curiosity:

Who is expanding their knowledge and application for ML/DL/AI in investment management; specifically, to create alpha from unstructured and/or alternative data? 

The fin tech industry is the FUTURE of Finance and Technological conglomerates of society. The future is now. 

L has to be greater than or equal to C; where L represent the learning spectrum and C represent change. 

I need some insight on where to find a how-to start up quite to help me in my endeavors of creating ML/DL algorithms and AI systems. I have some experience in Python*

Thoughts? Recommendations?",0,0,False,self,,,,,
974,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,2,diseee,self.MachineLearning,"I have 16 super powerful computers with 1080's, any ideas?",https://www.reddit.com/r/MachineLearning/comments/diseee/i_have_16_super_powerful_computers_with_1080s_any/,throwwawwayz123,1571245950,[removed],1,1,False,self,,,,,
975,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,2,disjqx,self.MachineLearning,"[D] I have 16 super powerful computers with 1080's, any ideas?",https://www.reddit.com/r/MachineLearning/comments/disjqx/d_i_have_16_super_powerful_computers_with_1080s/,throwwawwayz123,1571246553,[removed],1,1,False,self,,,,,
976,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,2,disqsn,self.MachineLearning,How to make stochastic gradient descent not ultimately kill all weights,https://www.reddit.com/r/MachineLearning/comments/disqsn/how_to_make_stochastic_gradient_descent_not/,teh_mICON,1571247365,[removed],0,1,False,self,,,,,
977,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,2,disrox,self.MachineLearning,[D] Monitor the balance between the training of the discriminator and generator in GANs,https://www.reddit.com/r/MachineLearning/comments/disrox/d_monitor_the_balance_between_the_training_of_the/,mw_molino,1571247475,"I am looking for a way to monitor the balance between the training of the discriminator (D) and the generator (G) in GANs. I am aware of numerous heuristic as well as non-heuristic ways to stabilize the training (minibatch discrimination, label smoothing, crippling the discriminator, GP and many others), but I haven't found a method that would ideally provide a scalar value denoting the balance between training.

The obvious questions is to compare losses of D and G, or their gradients. However, this is extremely noisy and I believe that there should be a better/different way to measure it out there. A different take on it is to consider for example FID as the scalar value denoting the balance. If you know of any methods, let me know!",8,2,False,self,,,,,
978,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,3,ditci0,self.MachineLearning,[N] UC Berkeley class on Deep Unsupervised Learning,https://www.reddit.com/r/MachineLearning/comments/ditci0/n_uc_berkeley_class_on_deep_unsupervised_learning/,PuzzledForm,1571249890,"[https://sites.google.com/view/berkeley-cs294-158-sp19/home](https://sites.google.com/view/berkeley-cs294-158-sp19/home)

Pieter Abbeel's UC Berkeley class (videos and materials) from Spring 2019 on Deep Unsupervised Learning covering a span of topics: Autoregressive Models, Flow Models, VAEs, GANs, Self-Supervised Learning, Representation Learning for RL, and guest lectures from Ilya Sutskever, Alyosha Efros, Alec Radford and Aaron van den Oord.",8,43,False,self,,,,,
979,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,3,ditfm8,self.MachineLearning,How to get coefficients for a logistic regression model done using linear learner in AWS Sagemaker?,https://www.reddit.com/r/MachineLearning/comments/ditfm8/how_to_get_coefficients_for_a_logistic_regression/,ernestoguvera,1571250273,[removed],0,1,False,self,,,,,
980,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,3,ditiem,blog.paperspace.com,[N] Shareable Jupyter Notebooks That Run on Free Cloud GPUs (also an AMA with the founder if you have questions),https://www.reddit.com/r/MachineLearning/comments/ditiem/n_shareable_jupyter_notebooks_that_run_on_free/,kn0thing,1571250617,,0,4,False,default,,,,,
981,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,3,ditivx,self.MachineLearning,[D] What's your favourite title of a research paper?,https://www.reddit.com/r/MachineLearning/comments/ditivx/d_whats_your_favourite_title_of_a_research_paper/,EveryDay-NormalGuy,1571250678,"Eg:

*""An embarrassingly simple approach to zero-shot learning""*, Bernardino Romera-Paredes and Philip H. S. Torr.

*""Attention Is All You Need""*, Ashish Vaswani et al.

*""Cats and dogs""*, Omkar M Parkhi et al.",131,408,False,self,,,,,
982,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,3,diturv,app.releasly.co,tensorflow released v1.15.0 - the last 1.x release,https://www.reddit.com/r/MachineLearning/comments/diturv/tensorflow_released_v1150_the_last_1x_release/,scopsy,1571252053,,0,1,False,default,,,,,
983,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,3,ditvet,blog.floydhub.com,Multiprocessing vs. Threading in Python: What Every Data Scientist Needs to Know,https://www.reddit.com/r/MachineLearning/comments/ditvet/multiprocessing_vs_threading_in_python_what_every/,SkullTech101,1571252123,,0,1,False,https://b.thumbs.redditmedia.com/SerYQeRXE0BPV0yqsP7AIRDopLEojm_E9RVcYxgL72M.jpg,,,,,
984,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,4,dityb9,app.releasly.co,[N] tensorflow released v1.15.0 - the last 1.x release,https://www.reddit.com/r/MachineLearning/comments/dityb9/n_tensorflow_released_v1150_the_last_1x_release/,combarnea,1571252452,,0,1,False,https://b.thumbs.redditmedia.com/uyWYxNs91bDfOVcpGcY1MiCQZbqOi2LlOjnnRAl8eWs.jpg,,,,,
985,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,4,diu73z,heartbeat.fritz.ai,[R] - HAMR  3D Hand Shape and Pose Estimation from a Single RGB Image,https://www.reddit.com/r/MachineLearning/comments/diu73z/r_hamr_3d_hand_shape_and_pose_estimation_from_a/,posnererez,1571253413,,0,2,False,default,,,,,
986,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,4,diu77t,self.MachineLearning,[N] tensorflow released v1.15.0 - the last 1.x release,https://www.reddit.com/r/MachineLearning/comments/diu77t/n_tensorflow_released_v1150_the_last_1x_release/,combarnea,1571253425,"Last ever release of tensorflow 1.x .

[https://app.releasly.co/releases/tensorflow/tensorflow/1\_15\_0?utm\_campaign=r\_ml](https://app.releasly.co/releases/tensorflow/tensorflow/1_15_0?utm_campaign=r_ml)

Including various API's from V2, better GPU support, and lots of bug fixes!",2,4,False,self,,,,,
987,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,4,diub4g,sumit-ghosh.com,Multiprocessing vs. Threading in Python: What Every Data Scientist Needs to Know,https://www.reddit.com/r/MachineLearning/comments/diub4g/multiprocessing_vs_threading_in_python_what_every/,SkullTech101,1571253863,,0,1,False,https://b.thumbs.redditmedia.com/G3OmKoiW0PT90Hq7-9Fpe_mWSxu1L-Aqw6xaOUgrSZE.jpg,,,,,
988,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,4,diurhq,self.MachineLearning,Why is python so popular for machine learning?,https://www.reddit.com/r/MachineLearning/comments/diurhq/why_is_python_so_popular_for_machine_learning/,ThaBroccoliDood,1571255722,[removed],0,1,False,self,,,,,
989,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,4,diussy,self.MachineLearning,"[P] Conditional Density Estimation Python Package and Large Benchmark with Neural Networks (MDN, KMN, Normalizing Flow) and Non-/Semi-parametric estimators",https://www.reddit.com/r/MachineLearning/comments/diussy/p_conditional_density_estimation_python_package/,whiletrue2,1571255865,,0,1,False,default,,,,,
990,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,5,diuuyv,self.MachineLearning,Input sequential images into RNN model,https://www.reddit.com/r/MachineLearning/comments/diuuyv/input_sequential_images_into_rnn_model/,georgeforprez3,1571256110,[removed],0,1,False,self,,,,,
991,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,5,divbgl,self.MachineLearning,PyTorch Speed Benchmarks 2019,https://www.reddit.com/r/MachineLearning/comments/divbgl/pytorch_speed_benchmarks_2019/,bfortuner,1571257994,[removed],0,1,False,self,,,,,
992,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,5,divgw1,self.MachineLearning,How to evaluate the quality of the 3D model (point cloud)? [D],https://www.reddit.com/r/MachineLearning/comments/divgw1/how_to_evaluate_the_quality_of_the_3d_model_point/,WittmanSVK,1571258603,"Hello everyone

I need to evaluate the quality of the 3D model (or point cloud) reconstructed from 3D laser scans. The main issue is, that I dont have the ground truth model for this evaluation. Can you please suggest any ideas? I read many research papers on which usually used photogrammetry or model created from photographs. But I dont have photos, I can use only scans from a laser scanner. The main goal is to find the best reconstruction method (I have to try many Iterative Closest Point (ICP) variants).

I am thinking about compare distances between reference points of the reconstructed model with manually measured distances from the real object, but it should be an automated process. Or maybe I can use more scanners in fixed positions for scanning different objects and then evaluate ICP transformation. The most consistent transformation should be the best. What do you think about it? Please write your ideas. Thanks :)",6,3,False,self,,,,,
993,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,5,divlrl,youtu.be,Hey guys check out part 7 of Reinforcement Learning Tutorial Series,https://www.reddit.com/r/MachineLearning/comments/divlrl/hey_guys_check_out_part_7_of_reinforcement/,indi0508,1571259165,,0,0,False,https://b.thumbs.redditmedia.com/fqLSRZY85EgfIJxWIK80zMiNA1aaDV_0nlVjNMeLfyE.jpg,,,,,
994,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,5,divn8c,self.MachineLearning,Imbalanced Targets for Regression,https://www.reddit.com/r/MachineLearning/comments/divn8c/imbalanced_targets_for_regression/,rrthirumulu,1571259332,[removed],0,1,False,https://b.thumbs.redditmedia.com/tO524VY8S5lDAHRLC6U8ppiHxHo1kaVRObgmHOWgdjM.jpg,,,,,
995,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,6,divpm0,bestofml.com,[P] Weekly Digest of new resources in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/divpm0/p_weekly_digest_of_new_resources_in_machine/,Sig_Luna,1571259606,,0,1,False,default,,,,,
996,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,6,divq0z,twitter.com,Siraj Coin paper also messed up,https://www.reddit.com/r/MachineLearning/comments/divq0z/siraj_coin_paper_also_messed_up/,johnreese421,1571259662,,0,1,False,default,,,,,
997,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,6,divu2u,self.MachineLearning,create image dataset from indoor security cam?,https://www.reddit.com/r/MachineLearning/comments/divu2u/create_image_dataset_from_indoor_security_cam/,atlphonehome,1571260098,[removed],0,1,False,self,,,,,
998,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,6,divvlf,i.redd.it,Siraj coin paper also messed up : source twitter: https://twitter.com/_var_che/status/1184571228268486656,https://www.reddit.com/r/MachineLearning/comments/divvlf/siraj_coin_paper_also_messed_up_source_twitter/,johnreese421,1571260259,,0,1,False,default,,,,,
999,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,6,diw3ro,i.redd.it,"AI revives Nelson Mandela's voice, reads his autobiography",https://www.reddit.com/r/MachineLearning/comments/diw3ro/ai_revives_nelson_mandelas_voice_reads_his/,chicchoctech,1571261221,,0,1,False,https://b.thumbs.redditmedia.com/-gBe3-ViiJxMjGs9yZIeEl48IdPQKNUGm0-wrnNzG4o.jpg,,,,,
1000,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,6,diwg9l,medium.com,Using Conditional GANs to Build Zelda Game Levels,https://www.reddit.com/r/MachineLearning/comments/diwg9l/using_conditional_gans_to_build_zelda_game_levels/,Yuqing7,1571262689,,0,1,False,https://b.thumbs.redditmedia.com/LknQmFvrlreZQrI9k0CTimXoNyj9Xa2_UpCRmCrlj4g.jpg,,,,,
1001,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,6,diwhif,youtube.com,"AI revives Nelson Mandela's voice, reads his autobiography (w/ subs)",https://www.reddit.com/r/MachineLearning/comments/diwhif/ai_revives_nelson_mandelas_voice_reads_his/,chicchoctech,1571262836,,0,1,False,https://b.thumbs.redditmedia.com/Vm3kRjfkOeojhdrtvsB5pQWNJrPzLRXn2bV7c-LiMaA.jpg,,,,,
1002,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,6,diwhk7,i.redd.it,[P] Cortex v0.9: An open source alternative to SageMaker,https://www.reddit.com/r/MachineLearning/comments/diwhk7/p_cortex_v09_an_open_source_alternative_to/,KindaKnowKarate,1571262843,,1,1,False,default,,,,,
1003,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,7,diwlm7,self.MachineLearning,Machine Learning Course CSEP 546 - Machine Learning - Autumn 2019 (Paul G Allen School ) Instructor: Geoff Hulten,https://www.reddit.com/r/MachineLearning/comments/diwlm7/machine_learning_course_csep_546_machine_learning/,tayyabikhlaq,1571263305,[removed],0,1,False,self,,,,,
1004,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,7,diwslw,self.MachineLearning,[P] Cortex v0.9: An open source alternative to SageMaker,https://www.reddit.com/r/MachineLearning/comments/diwslw/p_cortex_v09_an_open_source_alternative_to/,KindaKnowKarate,1571264115,"[https://github.com/cortexlabs/cortex](https://github.com/cortexlabs/cortex)

*Processing gif oyi8y6jv8zs31...*

**New features**

* Add Cortex Python client [\#488](https://github.com/cortexlabs/cortex/pull/488) 
* Add Cortex support CLI command [\#491](https://github.com/cortexlabs/cortex/pull/491) 
* Add configure --print CLI command

**Bug fixes:**

* Prevent load balancer from timing out requests [\#490](https://github.com/cortexlabs/cortex/pull/490) 
* Remove unnecessary lock in operator init 
* Silence stale API saved status not found errors
* Remove availability zone configuration
* Show correct URL upon failed HTTP request from CLI [\#504](https://github.com/cortexlabs/cortex/pull/504) 

**Examples**

* Shorten gpt-2 model output length 

**Misc**

* Validate access to cortex bucket on deploy [\#511](https://github.com/cortexlabs/cortex/pull/511) 
* Remove cortex namespace configuration option",9,50,False,self,,,,,
1005,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,7,dixayd,youtube.com,"AI revives Nelson Mandela's voice, reads his autobiography (w/ subs)",https://www.reddit.com/r/MachineLearning/comments/dixayd/ai_revives_nelson_mandelas_voice_reads_his/,chicchoctech,1571266356,,2,3,False,https://b.thumbs.redditmedia.com/Vm3kRjfkOeojhdrtvsB5pQWNJrPzLRXn2bV7c-LiMaA.jpg,,,,,
1006,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,8,dixnqw,link.medium.com,Data Science | Markdown cells | Jupyter Notebook,https://www.reddit.com/r/MachineLearning/comments/dixnqw/data_science_markdown_cells_jupyter_notebook/,arman_52,1571267936,,0,1,False,default,,,,,
1007,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,8,dixwwo,self.MachineLearning,[D] How do you monitor your models in production?,https://www.reddit.com/r/MachineLearning/comments/dixwwo/d_how_do_you_monitor_your_models_in_production/,WildShallot,1571269169,We have been looking for a robust solution to monitor our models in production and was wondering what you guys are using?,5,1,False,self,,,,,
1008,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,9,diy9wh,self.MachineLearning,Classifying objects after detecting bounding boxes,https://www.reddit.com/r/MachineLearning/comments/diy9wh/classifying_objects_after_detecting_bounding_boxes/,briculmircea1,1571271003,[removed],0,1,False,self,,,,,
1009,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,10,diyxoi,youtu.be,[D] Siraj's next level teaching.,https://www.reddit.com/r/MachineLearning/comments/diyxoi/d_sirajs_next_level_teaching/,b14cksh4d0w369,1571274278,,0,1,False,https://b.thumbs.redditmedia.com/o1XOYeYDV5Sk9tFTYjmd9112zXLmPEcV4yNsbUVfcrk.jpg,,,,,
1010,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,10,diz157,lionbridge.ai,5 Essential Papers on Sentiment Analysis,https://www.reddit.com/r/MachineLearning/comments/diz157/5_essential_papers_on_sentiment_analysis/,LimarcAmbalina,1571274752,,0,1,False,default,,,,,
1011,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,10,dizb1y,towardsdatascience.com,Trade and Invest Smarter  The Reinforcement Learning Way,https://www.reddit.com/r/MachineLearning/comments/dizb1y/trade_and_invest_smarter_the_reinforcement/,notadamking,1571276174,,1,0,False,https://a.thumbs.redditmedia.com/GboDDhNVIc6oYf42LgKZpm03lwKz1dmzLItzU8JJy08.jpg,,,,,
1012,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,10,dizgd9,self.MachineLearning,[D] Right way to build a chatbot engine with Rasa,https://www.reddit.com/r/MachineLearning/comments/dizgd9/d_right_way_to_build_a_chatbot_engine_with_rasa/,lazurey,1571276905,"After some days digging into the Rasa tool and examples, I'm curious about how to do common engineering practice work on it. My questions are like:

1. version control, what to control and how.
2. how to organize stories and domains, if there're multiple scenarios.
3. how people collaborate on it

If you have ideas or experience working with Rasa, would you like share some here?

Thanks, :)",4,1,False,self,,,,,
1013,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,11,dj07ak,self.MachineLearning,MasRCNN code,https://www.reddit.com/r/MachineLearning/comments/dj07ak/masrcnn_code/,_runtimeterror,1571280636,[removed],0,1,False,self,,,,,
1014,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,11,dj09uv,i.redd.it,"Just receive the Nvidia TESLA T4, is it worth it ? Video comparison 2070 vs Tesla T4 for DL/ML",https://www.reddit.com/r/MachineLearning/comments/dj09uv/just_receive_the_nvidia_tesla_t4_is_it_worth_it/,gimel1213,1571281012,,0,1,False,default,,,,,
1015,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,12,dj0b87,self.MachineLearning,Regression: Always GBM?,https://www.reddit.com/r/MachineLearning/comments/dj0b87/regression_always_gbm/,syd67,1571281202,[removed],0,1,False,self,,,,,
1016,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,14,dj1lee,self.MachineLearning,"[D] How to find startups who are focused on a particular area of machine learning, ie 'NLP for information retrieval' ?",https://www.reddit.com/r/MachineLearning/comments/dj1lee/d_how_to_find_startups_who_are_focused_on_a/,BatmantoshReturns,1571288540,"I am looking to join a startup whose needs overlap in a particular area (in my case, NLP for information retrieval). 

I am not sure if applying on LinkedIn is the way to go, it seems mostly for mid and bigger sized companies, or startups which are more in a rapidly expanding phase, which I wouldn't mind. 

I am in the Silicon Valley bay area, which has a ton of startups. I am looking to see if any of their needs align with my focus, so that even if they haven't explicitly posted a job posting, I would still be able to send my portfolio for them to checkout and see if they could use a person like me.",9,3,False,self,,,,,
1017,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,14,dj1rik,self.MachineLearning,MaskRCNN code,https://www.reddit.com/r/MachineLearning/comments/dj1rik/maskrcnn_code/,_runtimeterror,1571289598,"Hi everyone, 
I am currently facing certain issues trying to run the MaskRCNN code, reference was the repository by matterport, on a custom dataset. It comprises of images and videos. Can someone please share their codes if it's possible? 
Thanks",0,1,False,self,,,,,
1018,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,14,dj1vzt,self.MachineLearning,"Which Valve Is Useful For Food Industries, Pharmaceuticals, Chemical applications &amp; Highly corrosive environment?",https://www.reddit.com/r/MachineLearning/comments/dj1vzt/which_valve_is_useful_for_food_industries/,uflowindia,1571290403,[removed],0,1,False,https://b.thumbs.redditmedia.com/e1798rXHvWCLpKIS0W4CzcA550EF-on63FLQQddORqY.jpg,,,,,
1019,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,15,dj2ccp,self.MachineLearning,Computer Vision Python,https://www.reddit.com/r/MachineLearning/comments/dj2ccp/computer_vision_python/,tayyabikhlaq,1571293414,[removed],0,1,False,self,,,,,
1020,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,15,dj2cxe,self.MachineLearning,Develop an algorithm thatch converts stats into human readable format,https://www.reddit.com/r/MachineLearning/comments/dj2cxe/develop_an_algorithm_thatch_converts_stats_into/,soalexan,1571293535,[removed],0,1,False,self,,,,,
1021,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,15,dj2glp,medium.com,Strengthening Enterprises with AI in Video Surveillance,https://www.reddit.com/r/MachineLearning/comments/dj2glp/strengthening_enterprises_with_ai_in_video/,Firdosali001,1571294240,,0,1,False,https://a.thumbs.redditmedia.com/SJ9hysTgsCyrMNWLexahXA3GRRnA6fV12vjeg0ELSd4.jpg,,,,,
1022,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,15,dj2idm,self.MachineLearning,computer vision eye tracking with pupils.,https://www.reddit.com/r/MachineLearning/comments/dj2idm/computer_vision_eye_tracking_with_pupils/,tayyabikhlaq,1571294561,[removed],0,1,False,self,,,,,
1023,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,16,dj2qwf,self.MachineLearning,Double Block &amp; Bleed Valves Market Future Forecast 2019  2023,https://www.reddit.com/r/MachineLearning/comments/dj2qwf/double_block_bleed_valves_market_future_forecast/,jadhavni3,1571296141,[removed],1,1,False,self,,,,,
1024,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,16,dj2xgv,postureguides.com,The 5 Best gravity Boots - Posture Guides,https://www.reddit.com/r/MachineLearning/comments/dj2xgv/the_5_best_gravity_boots_posture_guides/,Jamessroman,1571297400,,0,1,False,default,,,,,
1025,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,16,dj300d,self.MachineLearning,Sutton and Barto 2018 Version Chapters 3 to 6 solutions,https://www.reddit.com/r/MachineLearning/comments/dj300d/sutton_and_barto_2018_version_chapters_3_to_6/,BiochemicalWarrior,1571297910,[removed],0,1,False,self,,,,,
1026,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,17,dj3ema,self.MachineLearning,From here to data science job in neurotech?,https://www.reddit.com/r/MachineLearning/comments/dj3ema/from_here_to_data_science_job_in_neurotech/,cfatuesta,1571300991,[removed],0,1,False,self,,,,,
1027,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,17,dj3jc7,self.MachineLearning,What sort of research can be done in DRL by a small group of people with limited resources?,https://www.reddit.com/r/MachineLearning/comments/dj3jc7/what_sort_of_research_can_be_done_in_drl_by_a/,ada_td,1571301988,[removed],0,1,False,self,,,,,
1028,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,17,dj3jex,self.MachineLearning,[D] Uncertainty Quantification in Deep Learning,https://www.reddit.com/r/MachineLearning/comments/dj3jex/d_uncertainty_quantification_in_deep_learning/,wei_jok,1571302003,"This article summarizes a few classical papers about measuring uncertainty in deep neural networks.

It's an overview article, but I felt the quality of the article is much higher than the typical ""getting started with ML"" kind of medium blog posts, so people might appreciate it on this forum.

https://www.inovex.de/blog/uncertainty-quantification-deep-learning/",21,166,False,self,,,,,
1029,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,18,dj41kr,self.MachineLearning,[D] Fantasy Football team selector questions,https://www.reddit.com/r/MachineLearning/comments/dj41kr/d_fantasy_football_team_selector_questions/,JoshP97,1571305422,"Hi, i'm new to machine learning but have been keen to get into it for a while. I want to create a program which ultimately will use player data to predict a high scoring fantasy football team each week. My player data will include statistics such as:

\- Position, team etc

\- Scores from previous weeks (as well as total and average score)

\- Fixture difficulty of the upcoming game

\- Player price

I have been doing some research on ML algorithms and linear regression seems to be the right one to use but I wanted to ask for some advice on the different algorithms and how to approach this project.",8,6,False,self,,,,,
1030,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,19,dj4c6c,bigdataanalyticsnews.com,Top datasets to actualize machine learning and data training tutorial -Big Data Analytics News,https://www.reddit.com/r/MachineLearning/comments/dj4c6c/top_datasets_to_actualize_machine_learning_and/,Veerans,1571307389,,0,1,False,default,,,,,
1031,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,19,dj4ooe,self.MachineLearning,is there many internship opportunities for data science in kochi Kerala,https://www.reddit.com/r/MachineLearning/comments/dj4ooe/is_there_many_internship_opportunities_for_data/,geomrithul94,1571309592,[removed],0,1,False,self,,,,,
1032,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,20,dj4rvw,isoeh.com,How much does a certified ethical hacker earn in India? - ISOEH,https://www.reddit.com/r/MachineLearning/comments/dj4rvw/how_much_does_a_certified_ethical_hacker_earn_in/,alishadirectory,1571310126,,0,1,False,https://b.thumbs.redditmedia.com/G21wSMV2baJvWUnApU5z4voh35QE_itNiLYLm-JLvoY.jpg,,,,,
1033,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,20,dj4vbm,arxiv.org,[R] Improving Gradient Estimation in Evolutionary Strategies With Past Descent Directions,https://www.reddit.com/r/MachineLearning/comments/dj4vbm/r_improving_gradient_estimation_in_evolutionary/,asierm,1571310700,,6,14,False,default,,,,,
1034,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,20,dj4zmd,self.MachineLearning,"Business performance monitoring, benchmarking and snapshotting?",https://www.reddit.com/r/MachineLearning/comments/dj4zmd/business_performance_monitoring_benchmarking_and/,tixocloud,1571311432,[removed],0,1,False,self,,,,,
1035,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,20,dj54j4,self.MachineLearning,What are some of the best ML programs that I can use to benchmark laptop and desktop computers at home?,https://www.reddit.com/r/MachineLearning/comments/dj54j4/what_are_some_of_the_best_ml_programs_that_i_can/,lemonphoto,1571312235,[removed],0,1,False,self,,,,,
1036,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,20,dj5byl,self.MachineLearning,[R] Editable Neural Networks - training neural networks so you can efficiently patch them later,https://www.reddit.com/r/MachineLearning/comments/dj5byl/r_editable_neural_networks_training_neural/,Hizachi,1571313400,,0,1,False,default,,,,,
1037,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,21,dj5euj,self.MachineLearning,[D] Do you benchmark or track snapshots of model runs?,https://www.reddit.com/r/MachineLearning/comments/dj5euj/d_do_you_benchmark_or_track_snapshots_of_model/,tixocloud,1571313841,"I'm doing research on deploying ML to production and am wondering how many of you benchmark your existing models before putting it into production? How extensive is your testing and do you run AB testing in production to validate that your new model is better than the existing one? 

Another related question - do you take snapshots of everything that goes in and out of your models to eventually use it for troubleshooting models? How often do models have performance issues any way? 

Cheers",0,6,False,self,,,,,
1038,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,21,dj5gi7,self.MachineLearning,[D] Deep Learning Software Licences,https://www.reddit.com/r/MachineLearning/comments/dj5gi7/d_deep_learning_software_licences/,salihkaragoz,1571314087,"Hi, I want to use an open-source study for my commercial product. This study closed to commercial usage. (ACADEMIC OR NON-PROFIT ORGANIZATION NONCOMMERCIAL RESEARCH USE ONLY)

I don't have enough experience with the software licenses. If I change the model a little bit and train it again from scratch, will I have the right to use it commercially? If so How much change do I have to make?

Thanks in advance.",4,2,False,self,,,,,
1039,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,21,dj5psh,self.MachineLearning,[N] New AI neural network approach detects heart failure from a single heartbeat with 100% accuracy,https://www.reddit.com/r/MachineLearning/comments/dj5psh/n_new_ai_neural_network_approach_detects_heart/,aiismorethanml,1571315472,"&gt;Congestive Heart Failure (CHF) is a severe pathophysiological condition  associated with high prevalence, high mortality rates, and sustained  healthcare costs, therefore demanding efficient methods for its  detection. **Despite recent research has provided methods focused on  advanced signal processing and machine learning, the potential of  applying Convolutional Neural Network (CNN) approaches to the automatic  detection of CHF has been largely overlooked thus far.** This study  addresses this important gap by presenting a CNN model that accurately  identifies CHF on the basis of one raw electrocardiogram (ECG) heartbeat  only, also juxtaposing existing methods typically grounded on Heart  Rate Variability. **We trained and tested the model on publicly available  ECG datasets, comprising a total of 490,505 heartbeats, to achieve 100%  CHF detection accuracy.** Importantly, the model also identifies those  heartbeat sequences and ECGs morphological characteristics which are  class-discriminative and thus prominent for CHF detection. Overall, our  contribution substantially advances the current methodology for  detecting CHF and caters to clinical practitioners needs by providing  an accurate and fully transparent tool to support decisions concerning  CHF detection.

(emphasis mine)

Press release: [https://www.surrey.ac.uk/news/new-ai-neural-network-approach-detects-heart-failure-single-heartbeat-100-accuracy](https://www.surrey.ac.uk/news/new-ai-neural-network-approach-detects-heart-failure-single-heartbeat-100-accuracy)

Paper: [https://www.sciencedirect.com/science/article/pii/S1746809419301776](https://www.sciencedirect.com/science/article/pii/S1746809419301776)",179,431,False,self,,,,,
1040,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,21,dj5r2h,self.MachineLearning,[P] MixMatch implementation in PyTorch,https://www.reddit.com/r/MachineLearning/comments/dj5r2h/p_mixmatch_implementation_in_pytorch/,Mimsyy,1571315646,"I made an implementation of MixMatch ([paper](https://arxiv.org/pdf/1905.02249.pdf)) in PyTorch, thought I'd share for those who are interested. Works as an installable package which you can use to create a dataloader that implements the mixmatch algorithm, as well as construct the appropriate loss function.

[https://github.com/FelixAbrahamsson/mixmatch-pytorch](https://github.com/FelixAbrahamsson/mixmatch-pytorch)

Feedback and comments are appreciated!",1,36,False,self,,,,,
1041,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,21,dj5yvk,reddit.com,Patient Engagement Software Solutions,https://www.reddit.com/r/MachineLearning/comments/dj5yvk/patient_engagement_software_solutions/,Aishwarya_Osp,1571316751,,0,1,False,default,,,,,
1042,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,22,dj64cy,github.com,ONNX to Keras model converter,https://www.reddit.com/r/MachineLearning/comments/dj64cy/onnx_to_keras_model_converter/,nerox8664,1571317512,,0,1,False,https://b.thumbs.redditmedia.com/afIbOYxKsnU-JIiLzIWDYJ_O05rs5OqvxknW7ZQGfBM.jpg,,,,,
1043,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,22,dj6553,self.MachineLearning,Dataset for Mobile Usage (Apps and Services),https://www.reddit.com/r/MachineLearning/comments/dj6553/dataset_for_mobile_usage_apps_and_services/,adtmv7,1571317615,[removed],0,1,False,self,,,,,
1044,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,22,dj69sk,quora.com,How many types of the algorithm in machine learning and how can we understand its properly?,https://www.reddit.com/r/MachineLearning/comments/dj69sk/how_many_types_of_the_algorithm_in_machine/,Huspi_sp_z_o_o,1571318271,,0,2,False,default,,,,,
1045,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,22,dj6bu8,twitter.com,FREE Course: Machine Learning A-Z: Hands-On Python &amp; R In Data Science,https://www.reddit.com/r/MachineLearning/comments/dj6bu8/free_course_machine_learning_az_handson_python_r/,charterOps,1571318539,,0,1,False,default,,,,,
1046,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,22,dj6kq7,developer.amazon.com,The FEVER Data Set: What Doesnt Kill It Will Make It Stronger : Alexa Blogs,https://www.reddit.com/r/MachineLearning/comments/dj6kq7/the_fever_data_set_what_doesnt_kill_it_will_make/,georgecarlyle76,1571319747,,0,1,False,default,,,,,
1047,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,23,dj6sw4,self.MachineLearning,[D] Looking for a specific figure demonstrating the importance of good datasets,https://www.reddit.com/r/MachineLearning/comments/dj6sw4/d_looking_for_a_specific_figure_demonstrating_the/,Drimage,1571320863,"I'm looking for a figure to cite in one of my projects. I have seen it once before, but didn't save the source, and have no luck finding it again. The effect of the figure is to show that on average, successful theories were invented very early, but good results only follow the release of good datasets.

This is achieved by listing a number of tasks (e.g. image classification). For each task, the figure lists which technique has been used to successfully tackle the problem (e.g. CNNs) and the year it was first proposed. Additionally, it lists the year that a significant dataset for this problem (e.g. ImageNet) was released. Finally, the last column displays the year that some performance threshold was reached on the given technique.

I hope my description is clear. It would be great if someone could find the actual figure!

In general, do you think the claim made here is valid? Or is it simplistically aggregating too much information, and missing the point?",2,1,False,self,,,,,
1048,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,23,dj6zut,self.MachineLearning,[R] Research Guide: Data Augmentation for Deep Learning,https://www.reddit.com/r/MachineLearning/comments/dj6zut/r_research_guide_data_augmentation_for_deep/,mwitiderrick,1571321756,"In this guide, well look at a couple of papers and research efforts that have been put forth to tackle this challenge.

&amp;#x200B;

[https://heartbeat.fritz.ai/research-guide-data-augmentation-for-deep-learning-7f141fcc191c](https://heartbeat.fritz.ai/research-guide-data-augmentation-for-deep-learning-7f141fcc191c)",1,3,False,self,,,,,
1049,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,23,dj77we,youtube.com,Energy-based Approaches to Representation Learning - Yann LeCun,https://www.reddit.com/r/MachineLearning/comments/dj77we/energybased_approaches_to_representation_learning/,DrJohanson,1571322787,,0,1,False,default,,,,,
1050,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,23,dj797k,self.MachineLearning,Multi-Class prediction; how to optimize the neural net such that it gives a proper rank of each class,https://www.reddit.com/r/MachineLearning/comments/dj797k/multiclass_prediction_how_to_optimize_the_neural/,BAismyhome,1571322938,[removed],0,1,False,self,,,,,
1051,MachineLearning,t5_2r3gv,2019-10-17,2019,10,17,23,dj7fep,medium.com,"[Guide] Reinforcement Learning, Part 1: A Brief Introduction",https://www.reddit.com/r/MachineLearning/comments/dj7fep/guide_reinforcement_learning_part_1_a_brief/,cdossman,1571323698,,0,1,False,https://b.thumbs.redditmedia.com/lfy_bXnOrAdJuatQn_imiEhlcYN6XTYMIVfNaof0TqE.jpg,,,,,
1052,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,0,dj7owh,self.MachineLearning,[Free Course-Udemy]- Machine Intelligence Masterclass,https://www.reddit.com/r/MachineLearning/comments/dj7owh/free_courseudemy_machine_intelligence_masterclass/,upworknepal,1571324858,[removed],0,1,False,self,,,,,
1053,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,0,dj7w1w,self.MachineLearning,Does anyone know where I can buy /download 6 month of 1 minute data from something like google trends?,https://www.reddit.com/r/MachineLearning/comments/dj7w1w/does_anyone_know_where_i_can_buy_download_6_month/,danang1986,1571325722,[removed],1,1,False,self,,,,,
1054,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,0,dj7zyf,youtube.com,"[P] Raspberry Pi 3 vs Pi 4 performance comparison video shows framerate when running realtime object detection models with TensorFlow, TensorFlow Lite, and the Coral USB Accelerator. The Pi 4 + USB Accelerator is FAST!",https://www.reddit.com/r/MachineLearning/comments/dj7zyf/p_raspberry_pi_3_vs_pi_4_performance_comparison/,Taxi-guy,1571326206,,0,1,False,https://b.thumbs.redditmedia.com/i7TIDsAvNUNf6trLZKGEcoiroPteXapS-KVJPn54u2U.jpg,,,,,
1055,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,0,dj82n9,self.MachineLearning,Stackedframes vs LSTM,https://www.reddit.com/r/MachineLearning/comments/dj82n9/stackedframes_vs_lstm/,Jandevries101,1571326531,"Using RL in special:

In the paper of Pong from pixels with RL they introduced the stackedframes idea, Where They fed the current frame And the frame before that combined into one state. This helps for a sense of direction. I was wondering what And When stackedframes Or lstm is more efficient. I Say stackedframes, But I Really mean stacking/combining previous states that are aid to solving subjects like sense of direction.

LSTM could also do this, But also on a Way higher level. The advantage of lstm is (probably) Because it saves a lot of parameters in a model, however it can also be difficult to implement, such as statefullness. 

Taking all this into a count, what would be the most efficient to do in which scenario? If I would want to for example feed the previous 10 frames/states then I could Just feed It that through a normal feedforward network for example. If the unit size of the state in this example would be 10 then Its 10x10 input size. This is maybe quite a lot for Just feeding previous frames/states into one, however if I think about other major projects in RL, then I think 100, in this case, isnt that bad?

What are your opinions on this?",0,1,False,self,,,,,
1056,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,0,dj84yr,self.MachineLearning,AdaptIS: New Instance Segmentation Method From Samsung AI,https://www.reddit.com/r/MachineLearning/comments/dj84yr/adaptis_new_instance_segmentation_method_from/,fan_rma,1571326818,"GitHub: [https://github.com/saic-vul/adaptis](https://github.com/saic-vul/adaptis)

arxiv: [https://arxiv.org/pdf/1909.07829.pdf](https://arxiv.org/pdf/1909.07829.pdf)

Samsung AI has released their new Instance segmentation model that is based on the Convolutional Neural Networks and a mechanism what they call as an ""AdaIN mechanism"" (Adaptive Instance Normalization). Their architecture uses three subnetworks that perform the tasks together to predict the segmentation masks when given the training data.

The first network is a feature extractor network which is a pre-trained backbone.

The second network is a controller network that encodes the feature at the region of interest and the output of this network is passed as input to the AdaIN mechanism.

The third network is a Relative Coordinated Convolutional Block that differentiates similar objects at different regions in an image.",0,1,False,self,,,,,
1057,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,0,dj87n3,medium.com,Sotabench: Benchmarking Open Source Models Directly From GitHub,https://www.reddit.com/r/MachineLearning/comments/dj87n3/sotabench_benchmarking_open_source_models/,Yuqing7,1571327159,,0,1,False,default,,,,,
1058,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,0,dj87tb,self.MachineLearning,Swift vs Kotlin?,https://www.reddit.com/r/MachineLearning/comments/dj87tb/swift_vs_kotlin/,LongtNG,1571327178,[removed],0,1,False,self,,,,,
1059,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,0,dj882b,arxiv.org,[D] Temporal coherence in transformer ? Why Al-Rfou(2018) uses fixed length sequences as input to transformer?,https://www.reddit.com/r/MachineLearning/comments/dj882b/d_temporal_coherence_in_transformer_why/,Jeevesh88,1571327207,,1,1,False,default,,,,,
1060,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,0,dj8dfw,self.MachineLearning,Temporal Coherence in transformer? Why Al-Rfou(2018) uses fixed length sequences?,https://www.reddit.com/r/MachineLearning/comments/dj8dfw/temporal_coherence_in_transformer_why_alrfou2018/,Jeevesh88,1571327861,[removed],0,1,False,self,,,,,
1061,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,1,dj8eyx,self.MachineLearning,Drone Detection using Keras-Retinanet's implementation of Fast R-CNN model with a clear step by step guide on how to replicate the training and prediction (Dataset + pre-trained model included),https://www.reddit.com/r/MachineLearning/comments/dj8eyx/drone_detection_using_kerasretinanets/,Drazxie,1571328043,[removed],0,1,False,self,,,,,
1062,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,1,dj8f60,self.MachineLearning,[D] Temporal coherence in transformers ? Why Fixed length inputs in Al-Rfou(2018) ?,https://www.reddit.com/r/MachineLearning/comments/dj8f60/d_temporal_coherence_in_transformers_why_fixed/,Jeevesh88,1571328067,"Why use fixed length sequences in transformer ? In what way and why does it effect the performance and training of transformer ? Why did they not use sequences of length &lt;= some number ?

Any paper regarding this?

Also, while reading the paper on Transformer-XL (Dai et. al, 2019) they say,

""We  propose  a  novel  neural  architecture Transformer-XL that enables learning  dependency  beyond  a  fixed  length  without  disrupting  temporal  coherence""

Why can't we learn dependencies with a normal transformer(Vaswani et. al) beyond a fixed length without disrupting temporal coherence?

I think temporal coherence gets disturbed when the input length becomes comparable to the length of embedding used for a single word/character because the embedding then doesn't contain enough information to link the word embedding to all the previous length of this input sequence . Am i right ?",1,6,False,self,,,,,
1063,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,1,dj8lwm,self.MachineLearning,Audio Captcha Solver - Machine Learning,https://www.reddit.com/r/MachineLearning/comments/dj8lwm/audio_captcha_solver_machine_learning/,blakerazor,1571328842,"Hi,

I am building an ML model to solve an audio captcha, but then I am not very successful with it, can someone tell me what I have done wrong.  


PFA the steps I have done.  


I have a fixed-length (length = 8) audio captcha files generated using gTTS, I am using keras to train the model. And most importantly I have converted the audio files into Spectrogram using ""librosa"" and I am using these images to train my model.

(SymbolSet: 0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ (basically all chars in caps and numbers))  
This is my final image which I generate after converting the audio to spectrogram:  


[00B212DH](https://i.redd.it/bae2fuqak4t31.jpg)

it's of size 128 x 64, I am NOT doing any preprocessing on this image or the audio apart from converting it to this image. (Should I be doing something? If so some pointers towards that would help greatly).  


This is my Keras model.

    def create_model(captcha_length, captcha_num_symbols, input_shape, model_depth=5, module_size=2):
     input_tensor = keras.Input(input_shape)
     x = input_tensor
     for i, module_length in enumerate([module_size] * model_depth):
        for j in range(module_length):
            x = keras.layers.Conv2D(32 * 2 ** min(i, 3), kernel_size=3, padding='same', kernel_initializer='he_uniform')(x)
            x = keras.layers.BatchNormalization()(x)
            x = keras.layers.Activation('relu')(x)
        x = keras.layers.MaxPooling2D(2)(x)
     x = keras.layers.Dropout(0.2)(x)
     x = keras.layers.Flatten()(x)
     x = [keras.layers.Dense(captcha_num_symbols, activation='softmax',
 name='char_%d' % (i + 1))(x) for i in range(captcha_length)]
     model = keras.Model(inputs=input_tensor, outputs=x)
    
 return model

Should I be improving this? Should I be processing Audio in this way by converting it to a spectrogram. My training set is around 40000 audio captchas, validation is around 8000 audio captchas, I ran it with a batch size of 4, for 6 epochs, and my accuracy is very bad.  


Any suggestions on improving this would be of great help!  
Thanks!",0,1,False,self,,,,,
1064,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,1,dj8qpt,self.MachineLearning,Banks say there's no shortage of machine learning talent,https://www.reddit.com/r/MachineLearning/comments/dj8qpt/banks_say_theres_no_shortage_of_machine_learning/,jccv72,1571329435,[removed],0,1,False,self,,,,,
1065,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,1,dj8yf9,arxiv.org,[R] GDP: Generalized Device Placement for Dataflow Graphs,https://www.reddit.com/r/MachineLearning/comments/dj8yf9/r_gdp_generalized_device_placement_for_dataflow/,SilverComparison,1571330339,,2,4,False,default,,,,,
1066,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,1,dj90h2,self.MachineLearning,Is this a good path for learning the gpt2 language model?,https://www.reddit.com/r/MachineLearning/comments/dj90h2/is_this_a_good_path_for_learning_the_gpt2/,Inversegaloisproblem,1571330574,I already know some of these things but I think I will need to understand them better in order to understand gpt2. It will go linear algebra -&gt; numpy -&gt; tensorflow. I also think I might need to learn calculus better but I am not sure how much I need. If there is anything else I need to know let me know,0,1,False,self,,,,,
1067,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,1,dj95w0,monkeylearn.com,What is TF-IDF?,https://www.reddit.com/r/MachineLearning/comments/dj95w0/what_is_tfidf/,jackjse,1571331199,,0,1,False,default,,,,,
1068,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,2,dj9fre,arxiv.org,[R] Towards Automatic Concept-based Explanations,https://www.reddit.com/r/MachineLearning/comments/dj9fre/r_towards_automatic_conceptbased_explanations/,Hobohome,1571332315,,2,1,False,default,,,,,
1069,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,2,dj9poq,ai.googleblog.com,Video Architecture Search,https://www.reddit.com/r/MachineLearning/comments/dj9poq/video_architecture_search/,sjoerdapp,1571333548,,0,1,False,https://b.thumbs.redditmedia.com/f1ROha3QVrTRQP3CWq6rDB09eUfIWybovXwbshlf2mI.jpg,,,,,
1070,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,3,djab11,self.MachineLearning,[R] Cross Domain Imitation Learning,https://www.reddit.com/r/MachineLearning/comments/djab11/r_cross_domain_imitation_learning/,kunoai,1571336119,Imitation learning with expert/imitators that have different morphologies or viewpoints.,0,1,False,self,,,,,
1071,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,3,djagc1,self.MachineLearning,Machine Learning tutorial,https://www.reddit.com/r/MachineLearning/comments/djagc1/machine_learning_tutorial/,mohaneshbm,1571336751,"I am uploading basics concepts of machine learning ,please visit 

 [https://www.youtube.com/watch?v=K66YEOq2I8Q&amp;t=60s](https://www.youtube.com/watch?v=K66YEOq2I8Q&amp;t=60s) 

Thank you",0,1,False,self,,,,,
1072,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,3,djatmf,youtube.com,Google Machine Learning Whistleblower,https://www.reddit.com/r/MachineLearning/comments/djatmf/google_machine_learning_whistleblower/,OlympicR,1571338368,,0,1,False,https://b.thumbs.redditmedia.com/PAVB-7Vm3Y3whbzW3HbR_n6HBub2g43owp0384itxmk.jpg,,,,,
1073,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,4,djb4i6,self.MachineLearning,[D] Uncertainties on novel classes: MC-Dropout vs Variantional Inference,https://www.reddit.com/r/MachineLearning/comments/djb4i6/d_uncertainties_on_novel_classes_mcdropout_vs/,oliver4242,1571339681,[removed],0,1,False,self,,,,,
1074,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,4,djb4mx,self.MachineLearning,What are some of the steps / techniques used to combat Generative Adversarial Networks ?,https://www.reddit.com/r/MachineLearning/comments/djb4mx/what_are_some_of_the_steps_techniques_used_to/,dontuseyourreal_name,1571339698,,0,1,False,self,,,,,
1075,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,4,djb54a,aithority.com,harmon.ie Launches Worlds First Solution to Connect Emails to Microsoft,https://www.reddit.com/r/MachineLearning/comments/djb54a/harmonie_launches_worlds_first_solution_to/,mohit-manoharan,1571339763,,0,1,False,default,,,,,
1076,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,4,djb80z,self.MachineLearning,Can anyone with an AI PhD help me out?,https://www.reddit.com/r/MachineLearning/comments/djb80z/can_anyone_with_an_ai_phd_help_me_out/,pitin753,1571340116,I need help understanding what Im getting out of one and if its a right fit for what I want to do.,0,1,False,self,,,,,
1077,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,4,djbd3w,arxiv.org,[R] Cross Domain Imitation Learning,https://www.reddit.com/r/MachineLearning/comments/djbd3w/r_cross_domain_imitation_learning/,kunoai,1571340692,,2,4,False,default,,,,,
1078,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,4,djbizw,self.MachineLearning,Take your Machine Learning and Cloud career to the next level  Machine Learning Fundamentals with Amazon SageMaker on AWS Training,https://www.reddit.com/r/MachineLearning/comments/djbizw/take_your_machine_learning_and_cloud_career_to/,internetdigitalentre,1571341369,[removed],0,1,False,self,,,,,
1079,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,4,djbr0o,ki-labs.com,Check out kaos - the platform for deploying scalable reproducible machine learning workflows in your own private environment. Give it a try!,https://www.reddit.com/r/MachineLearning/comments/djbr0o/check_out_kaos_the_platform_for_deploying/,jfri3d,1571342280,,1,1,False,default,,,,,
1080,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,5,djbshz,self.MachineLearning,The BioCompute Object (BCO) App-a-thon Submission Period Ends Tomorrow!,https://www.reddit.com/r/MachineLearning/comments/djbshz/the_biocompute_object_bco_appathon_submission/,hollystephens723,1571342447," Theres only one day left to submit your BCO for the precisionFDA BioCompute Object (BCO) App-a-thon, in partnership with George Washington University and CBER/FDA Hive. Enter now before the clock runs out at [https://go.usa.gov/xVS7X](https://go.usa.gov/xVS7X)!",0,2,False,self,,,,,
1081,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,5,djbytb,self.MachineLearning,[D] Have a method to enforce meaning of a specific latent code in GANs in limited settings - not sure about the value of this contribution?,https://www.reddit.com/r/MachineLearning/comments/djbytb/d_have_a_method_to_enforce_meaning_of_a_specific/,toadsofbattle,1571343147,"Hi;

I've stumbled on a way to enforce meaning on a specific latent code in GANs (e.g. I can specify that this variable in the latent code should mean ""width""). However, it's only functional in limited settings/datasets and not particularly generalizable. Should I be aiming to make this into a research project of some kind, or just a fun blog post?",0,1,False,self,,,,,
1082,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,5,djc7dq,self.MachineLearning,[D] Should you standardize your numerical features if the distribution is unknown of non gaussian?,https://www.reddit.com/r/MachineLearning/comments/djc7dq/d_should_you_standardize_your_numerical_features/,Trevahhhh,1571344114,I get the point in having your features be of the same scaling but wouldn't min max scaling (x-xmin/xmax-xmin) work better? Every tutorial Ive seen about data cleaning seems to use the StandardScaler() without looking at the underlying data.,10,6,False,self,,,,,
1083,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,5,djchnk,self.MachineLearning,[D] Paper regarding controlling the output of an RNN language model via the initial state,https://www.reddit.com/r/MachineLearning/comments/djchnk/d_paper_regarding_controlling_the_output_of_an/,davisyoshida,1571345305,"I recall reading in the last month a paper with the topic described in the title, but despite quite a lot of searching, have not been able to find it. If I recall correctly, the authors found that they could produce just about any sentence with an appropriate initial state.

Alternately, if anyone is aware of other work on this topic, references would be appreciated.

I am aware of [this work](https://arxiv.org/abs/1908.07125), and don't think that it's what I'm thinking of.",2,6,False,self,,,,,
1084,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,6,djdawd,self.MachineLearning,[R] Understanding Undesirable Word Embedding Associations,https://www.reddit.com/r/MachineLearning/comments/djdawd/r_understanding_undesirable_word_embedding/,kawin_e,1571348845,[removed],0,1,False,self,,,,,
1085,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,7,djdu7f,self.MachineLearning,"[P] CNN Inference Library in C, Written for Readability - RELOADED",https://www.reddit.com/r/MachineLearning/comments/djdu7f/p_cnn_inference_library_in_c_written_for/,cnylnz,1571351197," Hello everyone, some time back I had written a Convolutional Neural Network Inference library in C, prioritizing readability and simplicity. Where I used only straight-forward and intuitive algorithms and left a bunch of comments for the reader. I had actually created a post here for anyone who may be interested in it. But after a couple of months I realized that my initial work was grossly incomplete. Therefore I revised the code, wrote a proper README and included documentation. I also added a complete and easy to use interface for Keras Sequential Models. I think it could help anyone wanting to learn how CNN inference works on a ""low"" level. Here's the link to the repository:

 [CNN-Inference-Didactic](https://github.com/canyalniz/CNN-Inference-Didactic)",0,1,False,self,,,,,
1086,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,7,dje5vv,self.MachineLearning,Building out a machine learning research platform / cluster,https://www.reddit.com/r/MachineLearning/comments/dje5vv/building_out_a_machine_learning_research_platform/,dampcarcass818,1571352668,[removed],0,1,False,self,,,,,
1087,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,7,dje8eh,arxiv.org,[R] How Contextual are Contextualized Word Representations?,https://www.reddit.com/r/MachineLearning/comments/dje8eh/r_how_contextual_are_contextualized_word/,HipsterToofer,1571352989,,4,5,False,default,,,,,
1088,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,8,djey2z,self.MachineLearning,Want Collaboration for Project,https://www.reddit.com/r/MachineLearning/comments/djey2z/want_collaboration_for_project/,apyrethan,1571356300,"Very niche machine learning project in my workshop right now. I need a collaborator who I find to have a kindred philosophy. Get at me. This is being left vague on purpose to allow for you to interpret the vague data; that way I can interpret your responses and see if you've got what I need.  


I like hip hop and when I feel good.  


Peace.",0,1,False,self,,,,,
1089,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,9,djf2uz,self.MachineLearning,AAAI-20 Author Feedback Instructions,https://www.reddit.com/r/MachineLearning/comments/djf2uz/aaai20_author_feedback_instructions/,schludy,1571356939,"I received an email telling me that I can see the feedback. However, I logged in and didn't see a feedback. Where do I have to click to see it?

It also seems like I can't access the page at all right now, looks like it's DDOSd",0,1,False,self,,,,,
1090,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,9,djfb0w,self.MachineLearning,[D] Can't see any AAAI Feedbacks,https://www.reddit.com/r/MachineLearning/comments/djfb0w/d_cant_see_any_aaai_feedbacks/,schludy,1571358053,"Can anyone see their AAAI Feebacks? On that page I just see Reviewer #1 / #2 / #3 but no text or anything.

Sorry for the stupid question, this is my first submission and I'm really nervous",12,18,False,self,,,,,
1091,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,9,djfhhq,medium.com,Kaldi Creator Daniel Povey Joining Xiaomi in Beijing,https://www.reddit.com/r/MachineLearning/comments/djfhhq/kaldi_creator_daniel_povey_joining_xiaomi_in/,Yuqing7,1571358945,,0,1,False,https://b.thumbs.redditmedia.com/y4je-6_lNIjyNEhz1Kn2-kTY5G4byVdwEThNJY4FmWY.jpg,,,,,
1092,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,9,djfj0y,self.MachineLearning,Just give me an answer! PyTorch vs. Tensorflow2?,https://www.reddit.com/r/MachineLearning/comments/djfj0y/just_give_me_an_answer_pytorch_vs_tensorflow2/,eungbean,1571359155,[removed],0,1,False,self,,,,,
1093,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,9,djflf2,i.redd.it,"[D] After the scandal, Siraj's number of followers is in steep decline.",https://www.reddit.com/r/MachineLearning/comments/djflf2/d_after_the_scandal_sirajs_number_of_followers_is/,the_3bodyproblem,1571359474,,1,1,False,https://b.thumbs.redditmedia.com/X0iei4CY_DpLTAPUosV8CKrWQxzhSWrEDH80W9N3Sgo.jpg,,,,,
1094,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,11,djgrfv,self.MachineLearning,Think twice before dropping that first one-hot encoded column,https://www.reddit.com/r/MachineLearning/comments/djgrfv/think_twice_before_dropping_that_first_onehot/,tinteh,1571365105,[removed],0,1,False,self,,,,,
1095,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,11,djh05w,self.mlpapers,Autonomous Noise Elimination [P],https://www.reddit.com/r/MachineLearning/comments/djh05w/autonomous_noise_elimination_p/,Feynmanfan85,1571366276,,0,1,False,default,,,,,
1096,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,11,djh2ku,self.MachineLearning,[N] PyTorch 1.3 supports Google Cloud TPUs,https://www.reddit.com/r/MachineLearning/comments/djh2ku/n_pytorch_13_supports_google_cloud_tpus/,milaworld,1571366603,"As announced at the PyTorch Developer Conference earlier this month, there is now (public alpha) support for Cloud TPUs in PyTorch 1.3.

The repo https://github.com/pytorch/xla links to a few Google Cloud blog posts for example tutorials that should be useful to dive in:

[Training FairSeq Transformer on Cloud TPU using PyTorch](https://cloud.google.com/tpu/docs/tutorials/transformer-pytorch)

[Training Resnet50 on Cloud TPU with PyTorch](https://cloud.google.com/tpu/docs/tutorials/resnet-alpha-py)

[Training PyTorch models on Cloud TPU Pods](https://cloud.google.com/tpu/docs/tutorials/pytorch-pod)

Does this mean we can use Google Cloud TPUs for PyTorch 1.3, but not yet for TensorFlow 2.0?",25,155,False,self,,,,,
1097,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,11,djha0l,self.MachineLearning,Mobile Usage Dataset,https://www.reddit.com/r/MachineLearning/comments/djha0l/mobile_usage_dataset/,adtmv7,1571367590,[removed],0,1,False,self,,,,,
1098,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,12,djhfx8,self.MachineLearning,[D] AAAI 2020 Rebuttal discusssion@.@,https://www.reddit.com/r/MachineLearning/comments/djhfx8/d_aaai_2020_rebuttal_discusssion/,Mannershin,1571368360,"I can't see any discussion post for AAAI2020 author feedback.

I think this year, the reviews are good.",104,23,False,self,,,,,
1099,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,12,djhpqt,self.MachineLearning,Sentence similarity with spelling mistakes,https://www.reddit.com/r/MachineLearning/comments/djhpqt/sentence_similarity_with_spelling_mistakes/,monuirctc,1571369747,[removed],0,1,False,self,,,,,
1100,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,13,djictc,medium.com,Can Deepfake Disrupt Hollywood?,https://www.reddit.com/r/MachineLearning/comments/djictc/can_deepfake_disrupt_hollywood/,thefakening,1571373145,,0,1,False,default,,,,,
1101,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,14,djj1e9,self.MachineLearning,[D] OpenAI Rubiks cube hype,https://www.reddit.com/r/MachineLearning/comments/djj1e9/d_openai_rubiks_cube_hype/,tsauri,1571377325,"Following the Rubiks cube video and paper, seems OpenAI is doing their usual business: Brute force search/learning with $$$M GPU hours, viral a video and PR, call it AGI progress.

Ive seen better previous works, in sample efficiency and/or intepretability:

DeLaNet, Generalize robots as learnable Lagrangian, able to derive and seperate robot kinematics and external forces, e.g. Friction and Coriolis forces.
https://openreview.net/forum?id=BklHpjCqKm

TossingBot, Residual dynamics model learning, able to near-online adapt and generalize to the task arbitrary-weight objects throwing to targets, 
https://arxiv.org/abs/1903.11239
https://ai.googleblog.com/2019/03/unifying-physics-and-deep-learning-with.html",38,83,False,self,,,,,
1102,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,14,djj1j1,self.MachineLearning,[D] China's official ranking of international AI/ML conferences,https://www.reddit.com/r/MachineLearning/comments/djj1j1/d_chinas_official_ranking_of_international_aiml/,sensetime,1571377344,"*I saw this on [twitter](https://twitter.com/hardmaru/status/1185065126971371520) today:*

China Computer Federation, counterpart of ACM in China, has an [official ranking](https://www.ccf.org.cn/xspj/rgzn/) of AI conferences:

Tier A: AAAI, NeurIPS, IJCAI, ACL, ICML, ICCV, CVPR

Tier B: EMNLP, COLT, ECCV, ICRA, COLING, UAI, AAMAS, PPSN

Tier C: AISTATS, IROS, BMVC, GECCO, NAACL

Full List (including journals): https://www.ccf.org.cn/xspj/rgzn/

Does anyone know how important this list is for researchers working at academic institutions in China? How does it affect PhD students if they publish something to Tier C venues (or something not on the list), instead of AAAI / NeurIPS?

For some reason, ICLR is missing from the list.",1,0,False,self,,,,,
1103,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,14,djj5hz,dev.to,15 PyTorch Books You Have to Read,https://www.reddit.com/r/MachineLearning/comments/djj5hz/15_pytorch_books_you_have_to_read/,xinmeiwen,1571378009,,0,1,False,default,,,,,
1104,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,15,djjc73,datafloq.com,Looking at new ways: How to Machine learning development growth for marketing?,https://www.reddit.com/r/MachineLearning/comments/djjc73/looking_at_new_ways_how_to_machine_learning/,nexcorp,1571379230,,0,1,False,default,,,,,
1105,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,15,djjf5o,self.MachineLearning,Should I watch Siraj Raval for AI/ML related content?,https://www.reddit.com/r/MachineLearning/comments/djjf5o/should_i_watch_siraj_raval_for_aiml_related/,Jurasa,1571379764,[removed],0,1,False,self,,,,,
1106,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,15,djjgkk,openreview.net,[R] The Differentiable Curry,https://www.reddit.com/r/MachineLearning/comments/djjgkk/r_the_differentiable_curry/,hardmaru,1571380027,,0,1,False,default,,,,,
1107,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,15,djjkhp,self.MachineLearning,"[Discussion] Connections between Support Vector Machines, Wasserstein distance and gradient-penalty GANs",https://www.reddit.com/r/MachineLearning/comments/djjkhp/discussion_connections_between_support_vector/,siddarth2947,1571380757,"A [recent arXiv report](https://arxiv.org/abs/1910.06922) by Alexia Jolicoeur-Martineau and Ioannis Mitliagkas

&gt; We generalize the concept of maximum-margin classifiers (MMCs) to arbitrary norms and non-linear functions. Support Vector Machines (SVMs) are a special case of MMC. We find that MMCs can be formulated as Integral Probability Metrics (IPMs) or classifiers with some form of gradient norm penalty. This implies a direct link to a class of Generative adversarial networks (GANs) which penalize a gradient norm. We show that the Discriminator in Wasserstein, Standard, Least-Squares, and Hinge GAN with Gradient Penalty is an MMC. We explain why maximizing a margin may be helpful in GANs. We hypothesize and confirm experimentally that L-norm penalties with Hinge loss produce better GANs than L2-norm penalties (based on common evaluation metrics). We derive the margins of Relativistic paired (Rp) and average (Ra) GANs.",0,1,False,self,,,,,
1108,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,15,djjpg7,domaillerealestate.com,ROCHESTER MN Realtor,https://www.reddit.com/r/MachineLearning/comments/djjpg7/rochester_mn_realtor/,bonnysrharkleyi,1571381665,,0,1,False,https://b.thumbs.redditmedia.com/B3Y2CqrwV5P1H7a4SsmhryrEP5QGG7IwIpmx51tXADk.jpg,,,,,
1109,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,16,djjttb,arxiv.org,"[R] An Exponential Learning Rate Schedule for Deep Learning, Li &amp; Arora",https://www.reddit.com/r/MachineLearning/comments/djjttb/r_an_exponential_learning_rate_schedule_for_deep/,whenmaster,1571382457,,2,9,False,default,,,,,
1110,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,16,djju8a,self.MachineLearning,[D] Jurgen Schmidhuber really had GANs in 1990,https://www.reddit.com/r/MachineLearning/comments/djju8a/d_jurgen_schmidhuber_really_had_gans_in_1990/,siddarth2947,1571382526,"he did not call it GAN, he called it curiosity, it's actually famous work, many citations in all the papers on intrinsic motivation and exploration, although I bet many GAN people don't know this yet

I learned about it through his [inaugural tweet](https://twitter.com/SchmidhuberAI) on their [miraculous year](http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html). I knew LSTM, but I did not know that he and Sepp Hochreiter did all those other things 30 years ago. 

The blog sums it up in section 5 Artificial Curiosity Through Adversarial Generative Neural Networks (1990)

&gt; The first NN is called the controller C. C (probabilistically) generates outputs that may influence an environment. The second NN is called the world model M. It predicts the environmental reactions to C's outputs. Using gradient descent, M minimises its error, thus becoming a better predictor. But in a zero sum game, C tries to find outputs that maximise the error of M. M's loss is the gain of C.  

&gt; That is, C is motivated to invent novel outputs or experiments that yield data that M still finds surprising, until the data becomes familiar and eventually boring. Compare more recent summaries and extensions of this principle, e.g., [AC09]. 

&gt; GANs are an application of Adversarial Curiosity [AC90] where the environment simply returns whether C's current output is in a given set [AC19].

So I read those referenced papers. [AC19](https://arxiv.org/abs/1906.04493) is kinda modern guide to the old report [AC90](http://people.idsia.ch/~juergen/FKI-126-90ocr.pdf) where the adversarial part first appeared in section: Implementing Dynamic Curiosity and Boredom, and the generative part in section: Explicit Random Actions versus Imported Randomness, which is like GANs versus conditional GANs. [AC09](http://people.idsia.ch/~juergen/multipleways2009.pdf) is a survey from 2009 and sums it up: maximise reward for prediction error.

I know that Ian Goodfellow says he is the inventor of GANs, but he must have been a little boy when Jurgen did this in 1990. Also funny that Yann LeCun described GANs as ""the coolest idea in machine learning in the last twenty years"" although Jurgen had it thirty years ago  

No, it is NOT the same as predictability minimisation, that's yet another adversarial game he invented, in 1991, section 7 of his [explosive blog post which contains additional jaw-droppers](http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html)",158,538,False,self,,,,,
1111,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,16,djjwlz,self.MachineLearning,[R] AI-enabled human rights monitoring,https://www.reddit.com/r/MachineLearning/comments/djjwlz/r_aienabled_human_rights_monitoring/,hardmaru,1571382948,"*A study of potential impact that ML could have on the field of Human Rights Monitoring, written by ElementAI and Amnesty International. From the [blog post](https://www.elementai.com/news/2019/ai-enabled-human-rights-monitoring):*

AI can bring important benefits to the human rights field. Through the collaboration that resulted in this paper, we have strived to identify key opportunity spaces for the use of AI in the field of human rights monitoring, and outline ambitious but feasible initiatives for new approaches to human rights monitoring that leverage the availability of massive amounts of data and the power of machine learning techniques.

The world is facing big human rights challenges: the climate crisis, the spread of racist and xenophobic politics, intractable conflicts and extreme poverty, to name a few. AI will not solve these problems, but it can contribute to solutions.

Ultimately, we would like to see high quality, reusable, scalable AI-enabled tools that make a significant contribution to the work of human rights practitioners globally. This will need collaboration between the human rights community, AI and machine learning researchers, private and public sector organizations, and funders.

Leveraging the potential of AI for human rights protection necessitates a great degree of care to ensure that the development and use of such applications respects human rights. As with any new field, there is of yet no existing template or rulebook for how to do this, but an evolving set of principles and guidelines offers a way forward.

We only scratch the surface of whats possible. We invite human rights and AI researchers to build on and improve on the ideas in this paper.

[paper](https://bit.ly/2OYXwTC)

[blog](https://bit.ly/2J1jcdZ)",0,1,False,self,,,,,
1112,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,16,djjzpy,analyticsindiamag.com,Batch Norm Patent Granted To Google: Is AI Ownership The Gold Rush Of 21st Century?,https://www.reddit.com/r/MachineLearning/comments/djjzpy/batch_norm_patent_granted_to_google_is_ai/,analyticsindiam,1571383523,,0,1,False,default,,,,,
1113,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,16,djk1oc,inovex.de,Uncertainty Quantification in Deep Learning  an Overview,https://www.reddit.com/r/MachineLearning/comments/djk1oc/uncertainty_quantification_in_deep_learning_an/,simonbachstein,1571383900,,0,1,False,default,,,,,
1114,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,19,djlde7,bankofengland.co.uk,[N] Machine learning in UK financial services,https://www.reddit.com/r/MachineLearning/comments/djlde7/n_machine_learning_in_uk_financial_services/,ai_jobs,1571393392,,0,1,False,default,,,,,
1115,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,19,djle2g,self.MachineLearning,Image classification with other properties,https://www.reddit.com/r/MachineLearning/comments/djle2g/image_classification_with_other_properties/,bitsydarel,1571393520,[removed],0,1,False,self,,,,,
1116,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,19,djlmad,self.learnmachinelearning,"Are the off the shelf classifiers in popular libraries such as scikit-learn, pytorch, and tensorflow basically the most effective versions of those models? For practical projects, should I even try to beat it or is it best to use my time on hyperparamater tuning?",https://www.reddit.com/r/MachineLearning/comments/djlmad/are_the_off_the_shelf_classifiers_in_popular/,xinwow,1571395002,,0,1,False,default,,,,,
1117,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,19,djloua,self.MachineLearning,Which Valve Does Not Affected By Voltage Surges?,https://www.reddit.com/r/MachineLearning/comments/djloua/which_valve_does_not_affected_by_voltage_surges/,uflowindia,1571395467,[removed],0,1,False,https://b.thumbs.redditmedia.com/I0NR2enh2psVhyB0JtHXTZTL7NnGNdTe4hxOIl76IBc.jpg,,,,,
1118,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,20,djm0jg,i.redd.it,Top Devops Tools - Optisol Business,https://www.reddit.com/r/MachineLearning/comments/djm0jg/top_devops_tools_optisol_business/,optisol,1571397406,,0,1,False,default,,,,,
1119,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,20,djmbtj,self.MachineLearning,Get access to US 2020 media data,https://www.reddit.com/r/MachineLearning/comments/djmbtj/get_access_to_us_2020_media_data/,Fireche,1571399236,[removed],0,0,False,self,,,,,
1120,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,21,djmpbu,self.AskStatistics,How is Akaike Information Criterion related to Information theory ?,https://www.reddit.com/r/MachineLearning/comments/djmpbu/how_is_akaike_information_criterion_related_to/,venkarafa,1571401249,,0,0,False,https://a.thumbs.redditmedia.com/UUpo33EctAIvIX_87rCtBVmG8YspnGTY7l3YhPMZdW0.jpg,,,,,
1121,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,21,djmu14,self.MachineLearning,Fastest good quality TTS model?,https://www.reddit.com/r/MachineLearning/comments/djmu14/fastest_good_quality_tts_model/,machinekob,1571401935,[removed],0,1,False,self,,,,,
1122,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,22,djngmy,youtube.com,2 Introduction to machine learning,https://www.reddit.com/r/MachineLearning/comments/djngmy/2_introduction_to_machine_learning/,gopirockz,1571405051,,0,1,False,default,,,,,
1123,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,22,djnht3,arxiv.org,[R] On the Global Optima of Kernelized Adversarial Representation Learning (ICCV'19),https://www.reddit.com/r/MachineLearning/comments/djnht3/r_on_the_global_optima_of_kernelized_adversarial/,VishDev,1571405203,,4,5,False,default,,,,,
1124,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,22,djnlbr,medium.com,Estimating Uncertainty in Machine Learning - Part 3,https://www.reddit.com/r/MachineLearning/comments/djnlbr/estimating_uncertainty_in_machine_learning_part_3/,CometML,1571405673,,0,1,False,default,,,,,
1125,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,22,djnocm,auxarktrading.com,Wholesale Quartz Bangers For Dab &amp;amp; Oil Rigs,https://www.reddit.com/r/MachineLearning/comments/djnocm/wholesale_quartz_bangers_for_dab_amp_oil_rigs/,FarrahBartholom,1571406083,,0,1,False,default,,,,,
1126,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,22,djnq4v,self.MachineLearning,What ML course to take 1st,https://www.reddit.com/r/MachineLearning/comments/djnq4v/what_ml_course_to_take_1st/,ItisAhmad,1571406314,[removed],0,1,False,self,,,,,
1127,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,22,djnwpo,medium.com,Siraj Raval  No Thanks,https://www.reddit.com/r/MachineLearning/comments/djnwpo/siraj_raval_no_thanks/,newplayer12345,1571407194,,0,1,False,default,,,,,
1128,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,23,djnyvj,self.MachineLearning,Combining Google's Handwriting and Older Manuscripts,https://www.reddit.com/r/MachineLearning/comments/djnyvj/combining_googles_handwriting_and_older/,Eli_EES,1571407461,"Is anyone aware of any efforts underway to extend Google's Cloud Vision to include support for older (say 1500-1900 AD) manuscripts? I have seen how some libraries are digitizing their collections and thought it would be awesome to try to use the Handwriting OCR on them but my attempts have had less then stellar results so far. I figure that the current model hasn't been trained on older handwriting and would be very much interested in seeing if I could get involved in a community or effort that is focused on this. Anyone have any recommendations? 

Thanks so much!",0,1,False,self,,,,,
1129,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,23,djnzei,self.MachineLearning,"[R] Diagnosing ECGs and MCGs with CNNs (99.8% ECG accuracy, 88% 3D MCG accuracy)",https://www.reddit.com/r/MachineLearning/comments/djnzei/r_diagnosing_ecgs_and_mcgs_with_cnns_998_ecg/,Smith4242,1571407530,"A couple of years ago (in April 2017) I completed my master's degree, focusing on the detection of heart disease in electro- and magneto- cardiogram scans. As far as I can tell, the results were state of the art at the time. However, I never posted it on here, and after seeing [another paper exploring CNNs for ECGs](https://www.reddit.com/r/MachineLearning/comments/dj5psh/n_new_ai_neural_network_approach_detects_heart/) I thought it might be nice to get some discussion on it.

&amp;#x200B;

![video](gt3ztyi32bt31 ""Figure 1: An example of a 3D MCG scan"")

In summary I used a **CNN** to **diagnose myocardial infarction** in patients, given their ECG scans. I also **applied similar techniques to MCGs** generated via a novel non-invasive MCG device. This device created datapoints similar to that in figure 1. These datapoints could also be reconfigured into a 2D or 1D format. I used a **attention tracking technique** to **find the most diagnostic parts** of both the ECG and MCG scans in the case of infarction.

&amp;#x200B;

The thesis is available [here](https://github.com/Smith42/neuralnet-mcg/blob/master/smith_mike_ML_report.pdf), and the github repo is [here](https://github.com/Smith42/neuralnet-mcg).",10,9,False,self,,,,,
1130,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,23,djo7lb,self.MachineLearning,Looking for community interested in improving Google's Cloud Vision OCR for older manuscripts,https://www.reddit.com/r/MachineLearning/comments/djo7lb/looking_for_community_interested_in_improving/,Eli_EES,1571408588,[removed],0,1,False,self,,,,,
1131,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,23,djocws,self.MachineLearning,AAAI review,https://www.reddit.com/r/MachineLearning/comments/djocws/aaai_review/,Td93089,1571409257,[removed],0,1,False,self,,,,,
1132,MachineLearning,t5_2r3gv,2019-10-18,2019,10,18,23,djodet,self.MachineLearning,[D] Looking for community interested in improving Google's Cloud Vision OCR for older manuscripts,https://www.reddit.com/r/MachineLearning/comments/djodet/d_looking_for_community_interested_in_improving/,Eli_EES,1571409316,Is anyone aware of any efforts underway to extend Google's Cloud Vision to include support for older (say 1500-1900 AD) manuscripts? I have seen how some libraries are digitizing their collections and thought it would be awesome to try to use the Handwriting OCR on them but my attempts have had less then stellar results so far. I figure that the current model hasn't been trained on older handwriting and would be very much interested in seeing if I could get involved in a community or effort that is focused on this. Anyone have any recommendations?,3,7,False,self,,,,,
1133,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,1,djpmux,self.MachineLearning,Google Colab: Is it possible to downgrade cuDNN version on Colab?,https://www.reddit.com/r/MachineLearning/comments/djpmux/google_colab_is_it_possible_to_downgrade_cudnn/,Dont_Correct_Me,1571414791,[removed],0,1,False,self,,,,,
1134,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,1,djpq8v,self.learnmachinelearning,Self-play by next-state imagination from current action,https://www.reddit.com/r/MachineLearning/comments/djpq8v/selfplay_by_nextstate_imagination_from_current/,ZeroMaxinumXZ,1571415200,,0,1,False,default,,,,,
1135,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,2,djr31h,self.MachineLearning,Basic ML algorithms.,https://www.reddit.com/r/MachineLearning/comments/djr31h/basic_ml_algorithms/,suhas_bn_1412,1571420950,[removed],0,1,False,self,,,,,
1136,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,2,djr3d2,self.MachineLearning,normalizing and scaling continuous data,https://www.reddit.com/r/MachineLearning/comments/djr3d2/normalizing_and_scaling_continuous_data/,rafaelDgrate,1571420983,[removed],0,1,False,self,,,,,
1137,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,2,djr4nt,self.MachineLearning,Multi picture regression.,https://www.reddit.com/r/MachineLearning/comments/djr4nt/multi_picture_regression/,AbdallahNasr5,1571421133,[removed],0,1,False,self,,,,,
1138,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,2,djr78e,self.MachineLearning,Advice for an undergraduate presenting at ICCV '19?,https://www.reddit.com/r/MachineLearning/comments/djr78e/advice_for_an_undergraduate_presenting_at_iccv_19/,theAviCaster,1571421438,"I'm going to be attending International Conference on Computer Vision '19. 

My paper was accepted for a poster presentation at a workshop, and I'll be traveling to Korea alone to present. As a junior student, I still don't have an in depth knowledge about this field. However I am quite comfortable with my research area and paper(modality distillation and generative adversarial networks) and can explain and discuss about it well enough.

This is my very first conference, with thousands of attendees presenting their research. I feel a little overwhelmed as I haven't stepped into academia, especially in an intensive field as this before. 

What should I expect out of this conference? Should I look up more relevant research before attending? If yes, any pointers towards what to check out? 

And most importantly, how do conference proceedings go, and how should I be prepared with my part? I would definitely like to network as a prospective grad student, so what should I do about that?",0,1,False,self,,,,,
1139,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,3,djrgu7,self.MachineLearning,Introducing a New Hybrid ES-RNN Model - Timeseries forecasting,https://www.reddit.com/r/MachineLearning/comments/djrgu7/introducing_a_new_hybrid_esrnn_model_timeseries/,catslovecheese,1571422568,[removed],0,1,False,self,,,,,
1140,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,3,djrurd,github.com,Semi Automatic Annotation Tool for computer vision opensource on github,https://www.reddit.com/r/MachineLearning/comments/djrurd/semi_automatic_annotation_tool_for_computer/,theTreeHouse1,1571424206,,0,1,False,https://b.thumbs.redditmedia.com/wLv69vwM5X_hC264t4qsPvmi9cuexkRgsh7hFA7Dwqw.jpg,,,,,
1141,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,3,djrz0g,self.MachineLearning,Machine Learning and AI with Python and Jupyter Notebook Training - Accelerate your earnings &amp; career potential,https://www.reddit.com/r/MachineLearning/comments/djrz0g/machine_learning_and_ai_with_python_and_jupyter/,internetdigitalentre,1571424683,[removed],0,1,False,self,,,,,
1142,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,6,djturg,self.MachineLearning,[R] Hey guys! I would love if some people could take my survey for a college business class. I am trying to start a company that allows for an adequate sampling size across all disciplines and research categories. Thanks for your help!,https://www.reddit.com/r/MachineLearning/comments/djturg/r_hey_guys_i_would_love_if_some_people_could_take/,Argyle0,1571432759,[removed],0,1,False,self,,,,,
1143,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,7,djuu4j,self.MachineLearning,precisionFDA and Georgetown-ICBI are launching the Brain Cancer Predictive Modeling and Biomarker Discovery Challenge!,https://www.reddit.com/r/MachineLearning/comments/djuu4j/precisionfda_and_georgetownicbi_are_launching_the/,hollystephens723,1571437280,[removed],0,2,False,self,,,,,
1144,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,7,djuxgc,self.MachineLearning,"Great list of resources: data science, visualization, machine learning, big data",https://www.reddit.com/r/MachineLearning/comments/djuxgc/great_list_of_resources_data_science/,andrea_manero,1571437695,[removed],0,1,False,self,,,,,
1145,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,7,djuz56,/r/MachineLearning/comments/djuz56/i_taught_my_little_sister_how_to_write_music_my/,I taught my little sister how to write music. My little sister is a neural net visualizer....,https://www.reddit.com/r/MachineLearning/comments/djuz56/i_taught_my_little_sister_how_to_write_music_my/,qpplyai,1571437911,,0,1,False,default,,,,,
1146,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,7,djuzfl,github.com,Semi-automatic image annoation tool for computer vision tasks. Opensource on github.,https://www.reddit.com/r/MachineLearning/comments/djuzfl/semiautomatic_image_annoation_tool_for_computer/,gitarre94,1571437949,,0,1,False,default,,,,,
1147,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,7,djv2ac,self.MachineLearning,Essentials of Machine Learning Algorithms (with Python and R Codes),https://www.reddit.com/r/MachineLearning/comments/djv2ac/essentials_of_machine_learning_algorithms_with/,andrea_manero,1571438301,[removed],0,1,False,self,,,,,
1148,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,8,djvedm,self.MachineLearning,I have an idea for improving communication between neural networks in a multiple neural network system. What do I do now?,https://www.reddit.com/r/MachineLearning/comments/djvedm/i_have_an_idea_for_improving_communication/,pitin753,1571439850,[removed],0,1,False,self,,,,,
1149,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,8,djvfpg,self.MachineLearning,How to get started on a project you know little about,https://www.reddit.com/r/MachineLearning/comments/djvfpg/how_to_get_started_on_a_project_you_know_little/,ComplexClock,1571440022,[removed],0,1,False,self,,,,,
1150,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,8,djvjl9,medium.com,Smooth Exclusion: New Adobe Algorithm Aces Video Inpainting,https://www.reddit.com/r/MachineLearning/comments/djvjl9/smooth_exclusion_new_adobe_algorithm_aces_video/,Yuqing7,1571440527,,0,1,False,https://b.thumbs.redditmedia.com/BXhk0rTddKrnWxNH8RWUlbvfcctBdaBFPg5d7xs4vwg.jpg,,,,,
1151,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,8,djvn6i,self.MachineLearning,Learning the types (styles &amp; content) of photos users like,https://www.reddit.com/r/MachineLearning/comments/djvn6i/learning_the_types_styles_content_of_photos_users/,pumpedcharge,1571440978,"Have any papers been published that can accurately identify the types of stylistic and content components that users like in an image? E.g. some folks really enjoy taking pics of landscapes at sunset, and others love taking pictures of people with shadows in a specific way. I'd be interested in seeing what model architectures and setup has been used to be able to give an output probability where 0 is would not like this and 1 is would really like/care about this style.

You could imagine that inputs would be the images with either learned features or engineered ones, and then the labels would be either a rating from 0 to 1 or simply a 0 or 1 value (e.g. I like this photo or I don't).

Any papers to recommend?",0,1,False,self,,,,,
1152,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,8,djvp79,self.MachineLearning,Fairseq vs Torchtext?,https://www.reddit.com/r/MachineLearning/comments/djvp79/fairseq_vs_torchtext/,uotsca,1571441243,[removed],0,1,False,self,,,,,
1153,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,9,djw57u,hubfirms.com,What is machine learning models and its power,https://www.reddit.com/r/MachineLearning/comments/djw57u/what_is_machine_learning_models_and_its_power/,hubfirms,1571443426,,0,1,False,default,,,,,
1154,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,11,djxyum,self.statistics,[Q] Model Recommendations - A categorical conundrum,https://www.reddit.com/r/MachineLearning/comments/djxyum/q_model_recommendations_a_categorical_conundrum/,Data_Guy_Here,1571453185,,0,1,False,default,,,,,
1155,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,13,djyu9i,self.MachineLearning,Substitute and Complementary items - approaches and evaluation metrics,https://www.reddit.com/r/MachineLearning/comments/djyu9i/substitute_and_complementary_items_approaches_and/,r00kee,1571458614,[removed],0,1,False,self,,,,,
1156,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,13,djyyi1,self.MachineLearning,good IRC / Discord / Slack channels about machine learning?,https://www.reddit.com/r/MachineLearning/comments/djyyi1/good_irc_discord_slack_channels_about_machine/,roowsun,1571459355,[removed],0,1,False,self,,,,,
1157,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,14,djzcza,self.MachineLearning,Need help in understanding variance and bias,https://www.reddit.com/r/MachineLearning/comments/djzcza/need_help_in_understanding_variance_and_bias/,varun_tirupathi,1571461961,[removed],0,1,False,self,,,,,
1158,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,14,djzjai,self.MachineLearning,Which Is Types Of 3-Way Valve?,https://www.reddit.com/r/MachineLearning/comments/djzjai/which_is_types_of_3way_valve/,uflowindia,1571463188,[removed],0,1,False,https://b.thumbs.redditmedia.com/yL3aTBbWKlrbZJfcF1JReLIGZBJPzPL42Wj4L_sxJZE.jpg,,,,,
1159,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,14,djznul,self.MachineLearning,How to estimate the mutual information between a dicrete random variable and a multidimensional continuous variable?,https://www.reddit.com/r/MachineLearning/comments/djznul/how_to_estimate_the_mutual_information_between_a/,Haoranmq,1571464059,[removed],0,1,False,self,,,,,
1160,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,15,djzx9z,self.MachineLearning,[D] How much may this RNN for scalable-ecosystem-regeneration-design cost?,https://www.reddit.com/r/MachineLearning/comments/djzx9z/d_how_much_may_this_rnn_for/,Pal_Ol_Buddy,1571465910,"**Problem 1:**  Lots of places suck... they're simultaneously losing ecology, soil, habitability, jobs, profitability and carbon. We've got effective, profitable methodologies which could greatly improve many of these ecosystems, yet our scarce allocation of restoration resources, time, and willpower compels project designs with high IRL effectiveness per effort.   

**Problem 2:**  Disaster-response-ecological-restoration benefits immensely from rapid analysis and planing yet designers are booked, expensive and slow.

**Solution:**  An AI tool which triages options and creates effective ecology restoration designs and plans, quickly.

**My Questions:** About how much time and money may it take ML professionals to build and train a working version of this AI that's worth having regenerative design professionals use as a tool?

What should it be called?

Is this a realistic candidate project for a paid programming challenge?

What are your thoughts?

&amp;#x200B;

&amp;#x200B;

Here's more details.

**Example of Hypothetical AI Results:** Perhaps after training, the AI identifies some part of the Mojave Desert in Southern California as being the best place in the world to restore.  It suggests we buy this barren 300 acre parcel of land called ""Rancho Desertification AF"" that has problems with flashfloods, less-and-less ecology and supports *zero* jobs. It suggests that we then make 400 yards of compost from local rice straw and food waste that's inoculated with indigenous microorganisms and biochar, that we use equipment to dig large amounts of big swales on contour and that we spread the compost, compost tea, native grass seeds and trees in the swales.  That we drip irrigate the trees temporarily while we wait for rain which it forecasts to be in the late summer monsoon season.  That the swales will recharge the groundwater in the expected flashflood allowing the grasses and trees to grow, creating hundreds of acres of relative oasis.  That we'd do planned holistic grazing the following year with cattle (using short duration, high intensity stocking that's dynamically modified by herders) who would eat the grass creating more compost, better microorganisms and more mulch. That this would create lots of jobs, profit, biodiversity, bio-productivity and we'd have the option of selling the ranch at 300-1000% profit in 1.5-3 years  to a holistic planned grazing rancher or to continue ranching it ourselves.  It estimates this project would reduce GHG emissions by say 3,000 tons of carbon annually, which may also be worth $20,000 on the Nori carbon removal marketplace. That this project would provide jobs to 20 people for initial construction and 10 people for herding, climate-solution tourism and eco-tourism.

**Ecosystem Training/Evaluation Data Types:**  Topographical,  LiDAR, Forestry, Ecology, Climate, Rainfall, Wind,  Geology, Soil Chemistry, Soil Microbiology, Local Industries, Local Population, Local Economics, Local Politics, Local and Global Funding Available, NORI carbon removal marketplace, Grants Available, Tax Breaks Available, Labor Available, Comet-Farm, Current Real Estate Prices, Real Estate Projections, Stuff I haven't figured out yet

**Methodology Training/Evaluation Data Types:**  Data from software like Granular which farmers who get paid per ton of carbon sequestered use. Organic farming ERP data.  Data used by the authors of high impact journal articles on agroecology, conservation, ecological restoration, and organic agriculture.  Data used by environmental agencies, and large conservation NGOs. Experimental data generated in-house as needed. Stuff I haven't figured out yet

**Draft Program Training Parameters** (these are how the AI would compare location and restoration design options)**:** Increase Biodiversity, Increase Bioproductivity, Increase Human Wellness,  Increase Ecosystem and Human Resilience, Improve Groundwater Levels, Reduce Disaster Risks, Stabilize Rainfall, Improve Downwind Clouds, Lower Cost, Lower Negative Externalities, Lower Greenhouse Gas Emissions, Reduce Endangered Species Losses,  Lower Risk of Implementation Failure or Unintended Consequences, Increase Scalability, Increase Profitability, Decrease Implementation Time etc.

&amp;#x200B;

Thank you!",2,1,False,self,,,,,
1161,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,15,dk00i9,self.MachineLearning,Predicting diseases in crops with Machine Learning,https://www.reddit.com/r/MachineLearning/comments/dk00i9/predicting_diseases_in_crops_with_machine_learning/,rojans,1571466569,[removed],0,1,False,self,,,,,
1162,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,15,dk08cy,youtube.com,Bringing characters to life with computer brains,https://www.reddit.com/r/MachineLearning/comments/dk08cy/bringing_characters_to_life_with_computer_brains/,-BlackSquirrel-,1571468132,,0,1,False,https://a.thumbs.redditmedia.com/sPz7sQCZ3BOq-UT_qph0-zjK91a4yvWWr7zMCltktI8.jpg,,,,,
1163,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,16,dk0gy0,self.MachineLearning,[P] NERD : Evolution of Discrete data with Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/dk0gy0/p_nerd_evolution_of_discrete_data_with/,gananath,1571469856,"Tried to evolve sequence using an algorithm which is the combination of both Genetic Algorithm and Reinforcement Learning.  The aim of the project was to evolve SMILES chemical molecules from scratch.

Github: https://github.com/Gananath/NERD
Blog: https://gananath.github.io/nerd.html",8,104,False,self,,,,,
1164,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,16,dk0kdy,medium.com,Fireside chat with Geoffrey Hinton and Eric Schmidt: AI and Society,https://www.reddit.com/r/MachineLearning/comments/dk0kdy/fireside_chat_with_geoffrey_hinton_and_eric/,vnjogani,1571470597,,0,1,False,default,,,,,
1165,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,17,dk1130,self.datascience,Feature normalization question,https://www.reddit.com/r/MachineLearning/comments/dk1130/feature_normalization_question/,TheCockatoo,1571474310,,0,1,False,default,,,,,
1166,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,18,dk1omk,ai.facebook.com,[R] Billion-scale semi-supervised learning for state-of-the-art image and video classification - FAIR,https://www.reddit.com/r/MachineLearning/comments/dk1omk/r_billionscale_semisupervised_learning_for/,EveryDay-NormalGuy,1571478935,,0,1,False,default,,,,,
1167,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,19,dk1rgk,self.MachineLearning,Q-Learning with unknown number of states.,https://www.reddit.com/r/MachineLearning/comments/dk1rgk/qlearning_with_unknown_number_of_states/,mrkvicka02,1571479480,[removed],0,1,False,self,,,,,
1168,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,20,dk2egg,self.MachineLearning,How AI is Revolutionizing Education and Learning?,https://www.reddit.com/r/MachineLearning/comments/dk2egg/how_ai_is_revolutionizing_education_and_learning/,Primafelicitas,1571483733,[removed],0,1,False,https://b.thumbs.redditmedia.com/m1JEuRq6za9r29nhQc1MXwuas_WK9bDJcjcr62slFnw.jpg,,,,,
1169,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,22,dk3i8j,math.uni-bielefeld.de,"""Who Invented the Reverse Mode of Differentiation?"" by Andreas Griewank (2010)",https://www.reddit.com/r/MachineLearning/comments/dk3i8j/who_invented_the_reverse_mode_of_differentiation/,netw0rkf10w,1571490284,,2,3,False,default,,,,,
1170,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,22,dk3jhi,medium.com,[Post] Understanding The Difference Between AI and ML,https://www.reddit.com/r/MachineLearning/comments/dk3jhi/post_understanding_the_difference_between_ai_and/,cdossman,1571490465,,0,1,False,https://b.thumbs.redditmedia.com/tIr-0-3X1-ngxNXTVeDIbSfmSWlyzOWJ9ULy05MwDBg.jpg,,,,,
1171,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,23,dk4bnf,self.MachineLearning,[D] Benchmarking /Transformers on both PyTorch and TensorFlow,https://www.reddit.com/r/MachineLearning/comments/dk4bnf/d_benchmarking_transformers_on_both_pytorch_and/,jikkii,1571494588,"Since our recent release of [Transformers](https://github.com/huggingface/transformers) (previously known as pytorch-pretrained-BERT and pytorch-transformers), we've been working on a comparison between the implementation of our models in PyTorch and in TensorFlow.

We've released a [detailed report](https://medium.com/huggingface/benchmarking-transformers-pytorch-and-tensorflow-e2917fb891c2) where we benchmark each of the architectures hosted on our repository (BERT, GPT-2, DistilBERT, ...) in PyTorch with and without TorchScript, and in TensorFlow with and without XLA. We benchmark them for inference and the results are visible in the [following spreadsheet](https://docs.google.com/spreadsheets/d/1sryqufw2D0XlUH4sq3e9Wnxu5EAQkaohzrJbd5HdQ_w/edit#gid=0).

We would love to hear your thoughts on the process.",14,137,False,self,,,,,
1172,MachineLearning,t5_2r3gv,2019-10-19,2019,10,19,23,dk4kez,quora.com,What areas are there where big data is helping out HR?,https://www.reddit.com/r/MachineLearning/comments/dk4kez/what_areas_are_there_where_big_data_is_helping/,ariaareeds02,1571495805,,0,1,False,https://b.thumbs.redditmedia.com/u7e3Vx0_W1ShWyviCsfP6mcSQx4jmaHR4dfD4Yf8PtA.jpg,,,,,
1173,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,0,dk527u,self.MachineLearning,Deep learning virus infected cells,https://www.reddit.com/r/MachineLearning/comments/dk527u/deep_learning_virus_infected_cells/,ayakimovich,1571498181,[removed],0,1,False,self,,,,,
1174,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,0,dk58zq,self.MachineLearning,[P] Deep learning virus infected cells,https://www.reddit.com/r/MachineLearning/comments/dk58zq/p_deep_learning_virus_infected_cells/,ayakimovich,1571499079,"Deep Learning approach to identify herpesvirus and adenovirus infected cells in the absence of virus specific markers. This was possible based on DNA labelling alone. [https://youtu.be/xdAzdkzPF-A](https://youtu.be/xdAzdkzPF-A)

 [https://www.biorxiv.org/content/10.1101/798074v1](https://www.biorxiv.org/content/10.1101/798074v1)",1,5,False,self,,,,,
1175,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,1,dk5vob,self.MachineLearning,[D] Evaluation Metrics for Language Modeling,https://www.reddit.com/r/MachineLearning/comments/dk5vob/d_evaluation_metrics_for_language_modeling/,hughbzhang,1571501908,"Chip Huyen gives a comprehensive overview of some of the most important evaluation metrics in language modeling.

&amp;#x200B;

[https://thegradient.pub/understanding-evaluation-metrics-for-language-models/](https://thegradient.pub/understanding-evaluation-metrics-for-language-models/)",0,60,False,self,,,,,
1176,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,1,dk5xi3,self.MachineLearning,Classifier output has 3 distinct peaks. Why?,https://www.reddit.com/r/MachineLearning/comments/dk5xi3/classifier_output_has_3_distinct_peaks_why/,kinkhis,1571502119,[removed],0,1,False,https://b.thumbs.redditmedia.com/2JxGnRY5Qc5lfRjOZvtck22b9qgGH-9xQHwqjQTM6xM.jpg,,,,,
1177,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,1,dk626y,arxiv.org,[R] Relation learning in a neurocomputational architecture supports cross-domain transfer,https://www.reddit.com/r/MachineLearning/comments/dk626y/r_relation_learning_in_a_neurocomputational/,rtk25,1571502725,,6,25,False,default,,,,,
1178,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,1,dk64ii,self.MachineLearning,Why don't girls study CTI? The subject is the objective of a public policy proposal,https://www.reddit.com/r/MachineLearning/comments/dk64ii/why_dont_girls_study_cti_the_subject_is_the/,castroyama,1571503004,[removed],0,1,False,spoiler,,,,,
1179,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,1,dk66jq,self.MachineLearning,switching to a smaller batch size at the latter stages of training.,https://www.reddit.com/r/MachineLearning/comments/dk66jq/switching_to_a_smaller_batch_size_at_the_latter/,sicp4lyfe,1571503251,is this a thing? it feels like using a bigger batch gets us close enough much faster. but to get the best performance you want to use smaller batches.,0,1,False,self,,,,,
1180,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,1,dk68us,blog.paperspace.com,[N] Shareable Jupyter Notebooks That Run on Free Cloud GPUs (also an AMA with the founder if you have questions),https://www.reddit.com/r/MachineLearning/comments/dk68us/n_shareable_jupyter_notebooks_that_run_on_free/,kn0thing,1571503527,,0,6,False,default,,,,,
1181,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,1,dk6ezj,self.MachineLearning,ML OS Discussion,https://www.reddit.com/r/MachineLearning/comments/dk6ezj/ml_os_discussion/,ZeroMaxinumXZ,1571504278,[removed],0,1,False,self,,,,,
1182,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,2,dk6ubb,self.MachineLearning,Simulating Neural Network - Digit Recognition - VISUALIZATION,https://www.reddit.com/r/MachineLearning/comments/dk6ubb/simulating_neural_network_digit_recognition/,Timbelion,1571506114,[removed],0,1,False,self,,,,,
1183,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,2,dk70db,self.MachineLearning,People Use Machine Learning to Gain Profit,https://www.reddit.com/r/MachineLearning/comments/dk70db/people_use_machine_learning_to_gain_profit/,Magniminda,1571506845,[removed],0,1,False,self,,,,,
1184,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,2,dk72pt,self.MachineLearning,Regression on very small images,https://www.reddit.com/r/MachineLearning/comments/dk72pt/regression_on_very_small_images/,gulzainali,1571507121,"I am working on a problem where i am trying to build a model to do regression on very small images. These images are simple filled colors of size 20x20 pixels. These are extracted patches.from larger images and due to difference in light i can't simply fetch the color and output a value. Can anyone suggest a good model for this problem? given a simple image filled with color of very small size, i need to predict a certain value Y.",0,1,False,self,,,,,
1185,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,3,dk7c1j,self.MachineLearning,Indentification of organ,https://www.reddit.com/r/MachineLearning/comments/dk7c1j/indentification_of_organ/,agentezer0,1571508267,[removed],0,1,False,self,,,,,
1186,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,3,dk7i73,self.MachineLearning,Need a Team,https://www.reddit.com/r/MachineLearning/comments/dk7i73/need_a_team/,apyrethan,1571509045,[removed],0,1,False,self,,,,,
1187,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,3,dk7keb,i.redd.it,Time - Made using GAN Artbreeder,https://www.reddit.com/r/MachineLearning/comments/dk7keb/time_made_using_gan_artbreeder/,som3a982,1571509322,,0,1,False,default,,,,,
1188,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,3,dk7xpb,self.MachineLearning,Is there an AI that can create songs from songs that I give it?,https://www.reddit.com/r/MachineLearning/comments/dk7xpb/is_there_an_ai_that_can_create_songs_from_songs/,BillyGoat956961,1571511035,[removed],0,1,False,self,,,,,
1189,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,4,dk84un,self.MachineLearning,What is the intuition behind pi in the PDF of a Normal Distribution ? Is it related to some sort to a circle / sphere,https://www.reddit.com/r/MachineLearning/comments/dk84un/what_is_the_intuition_behind_pi_in_the_pdf_of_a/,venkarafa,1571511915," 

The PDF of a Normal distribution is given as below

&amp;#x200B;

[From Wikipedia](https://i.redd.it/12zl3hp5qjt31.jpg)

I am aware of the various properties of Normal distribution and how the two parameters mu and sigma affect the shape of the distribution.

What is not intuitive for me is, How come there is a pi in the PDF of Normal distribution. Is there any relation to circle ?",0,1,False,self,,,,,
1190,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,4,dk88go,i.redd.it,Soccer Player Detection in Overhead Images using RetinaNet https://link.medium.com/wL8YQFEYU0,https://www.reddit.com/r/MachineLearning/comments/dk88go/soccer_player_detection_in_overhead_images_using/,ConvNetBrad,1571512374,,0,1,False,default,,,,,
1191,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,4,dk8mz5,self.MachineLearning,Do you really have to choose an algorithm for training?,https://www.reddit.com/r/MachineLearning/comments/dk8mz5/do_you_really_have_to_choose_an_algorithm_for/,letstryusingreddit,1571514235,[removed],0,1,False,self,,,,,
1192,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,6,dk9w69,self.MachineLearning,Dimensional Orthogonality and Feature Purity,https://www.reddit.com/r/MachineLearning/comments/dk9w69/dimensional_orthogonality_and_feature_purity/,Azeranth,1571520049,"Features, in the context of machine learning, are n-dimensional vectors we use to describe the initial state of the inputs to a network that produces a domain of outputs. However, the definition ""n-dimensional"" is mildly misleading. Mostly, because feature selectors are largely indiscriminate of the orthogonality of their feature networks. To better understand this, consider the physical dimensions we are all familiar with and the conceptual 4th dimension.

Give a line, you can describe 1 dimension, given another, placed at a right angle, you can describe a plane and 2 dimension. The lines which describe each dimension are orthogonal to each other, meaning at right angles. With another line, 3 dimensions, still at right angles, still orthogonal. So where does the 4th dimension go? There is no way to arrange 4 lines in 3d space such that they lie at 90 degrees to one another. A generalization of ""orthogonality"" to not just mean right angles, but to mean ""forming an axis such traversal along the axis does not change the state of other axes""

In physical space, a non-orthognal axis would be like a randomly added line leading out from the origin. It is impossible to travel that line without changing the state of the object relative to at least one of the other 3 axes. When we call time a 4th dimension, it is then useful to understand that it is possible to traverse the dimension of time, without traversing the other dimensions. Essentially, you can sit still and get older.

So, with regard to feature selectors, understanding the non-orthogonality axes of out feature vectors allows us to apply some machine learning ""meta-cognition"". We can assess the orthogonality of feature vectors, by determining the overlap in vector space between dimensions. When the correlation between an output and a particular feature changes with respect to other dimensions, this dimension is ""less pure"" than others. 

Segregating features by their impurities, adjusting the composition of the network to accommodate impure (dependent) features into deeper levels of the network and ""untangling"" features, so it is easier to work back causal relationships can provide heuristics to avoid much of the ""circling the drain"" around local minimums, of vector deadzones- where the iteration of the system doesn't accelerate away from high cost areas after discovering them. 

In summary, performing meta analysis of the network itself, how it arrives at conclusions, and the relationships between its nodes, we can heuristically identify, predict, and avoid scenarios that decrease the efficiency of existing practices for machine learning.",0,1,False,self,,,,,
1193,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,6,dka73g,self.MachineLearning,I just found first lecture by Siraj Raval. What do you think?,https://www.reddit.com/r/MachineLearning/comments/dka73g/i_just_found_first_lecture_by_siraj_raval_what_do/,nurdin89,1571521482,[removed],0,1,False,self,,,,,
1194,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,9,dkcaws,i.redd.it,[N] Secret Image from Node summit on how AI works.,https://www.reddit.com/r/MachineLearning/comments/dkcaws/n_secret_image_from_node_summit_on_how_ai_works/,sendMeMememes,1571531557,,0,1,False,default,,,,,
1195,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,10,dkcspv,self.MachineLearning,"[N] School of AI, founded by Siraj Raval, severs ties with Siraj Raval over recents scandals",https://www.reddit.com/r/MachineLearning/comments/dkcspv/n_school_of_ai_founded_by_siraj_raval_severs_ties/,kreyio3i,1571534056,"https://twitter.com/SchoolOfAIOffic/status/1185499979521150976

Wow, just when you thought it wouldn't get any worse for Siraj lol",213,621,False,self,,,,,
1196,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,10,dkd4vz,self.MachineLearning,"[D] Gary Marcus Tweet on OpenAI still has not changed misleading blog post about ""solving the Rubik's cube""",https://www.reddit.com/r/MachineLearning/comments/dkd4vz/d_gary_marcus_tweet_on_openai_still_has_not/,chansung18,1571535812,"He said Since OpenAI still has not changed misleading blog post about ""solving the Rubik's cube"",  I attach detailed analysis, comparing what they say and imply with what they actually did. IMHO most would not be obvious to nonexperts.  Please zoom in to read &amp; judge for yourself.

&amp;#x200B;

This seems right, what do you think?

&amp;#x200B;

[https://twitter.com/GaryMarcus/status/1185679169360809984](https://twitter.com/GaryMarcus/status/1185679169360809984)

&amp;#x200B;

https://i.redd.it/nmenqh6yolt31.jpg",84,55,False,https://b.thumbs.redditmedia.com/mb1M016isWxi6NYYY42yHRkJDva4CddUxuppCN1272Q.jpg,,,,,
1197,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,11,dkdezf,self.MachineLearning,"Hi everyone. I have a question about using ML Tools in game development. Who working in game companies, please, tell about that. I will be extremely grateful)))",https://www.reddit.com/r/MachineLearning/comments/dkdezf/hi_everyone_i_have_a_question_about_using_ml/,artgord,1571537259,,0,1,False,self,,,,,
1198,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,14,dkfdk9,self.MachineLearning,What're some good datasets for image classification projects?,https://www.reddit.com/r/MachineLearning/comments/dkfdk9/whatre_some_good_datasets_for_image/,Freightlok,1571548417,[removed],0,1,False,self,,,,,
1199,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,14,dkfgsb,self.MachineLearning,[P] What're some good datasets for image classification projects?,https://www.reddit.com/r/MachineLearning/comments/dkfgsb/p_whatre_some_good_datasets_for_image/,Freightlok,1571549030,"What're  some good datasets for image classification projects other than the  MNISTs out there. I'm still a beginner, but I'm looking for a  challenging project, that I'll spend a lot of time tuning, to push me  closer to that intermediate stage.

Appreciate any suggestions and thank you",6,1,False,self,,,,,
1200,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,16,dkggy1,self.MachineLearning,Where can i find dataset related to cyclones?,https://www.reddit.com/r/MachineLearning/comments/dkggy1/where_can_i_find_dataset_related_to_cyclones/,chrisgomes98,1571556398,[removed],0,1,False,self,,,,,
1201,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,19,dkhsd0,self.MachineLearning,How can i fill nan values in a specific column only?,https://www.reddit.com/r/MachineLearning/comments/dkhsd0/how_can_i_fill_nan_values_in_a_specific_column/,pckty,1571566354,,0,1,False,self,,,,,
1202,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,20,dkibyc,self.MachineLearning,Retrain an existing model,https://www.reddit.com/r/MachineLearning/comments/dkibyc/retrain_an_existing_model/,nikhilsutar,1571570169,[removed],0,1,False,self,,,,,
1203,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,20,dkinz6,self.MachineLearning,Problem with saving a machine learning model,https://www.reddit.com/r/MachineLearning/comments/dkinz6/problem_with_saving_a_machine_learning_model/,saadmrb,1571572496,"I tested all different methods but I get this problem:

'SimpleSeq2Seq' has no attribute 'save'. 

&amp;#x200B;

If you want more details just ask me, I struggled with this almost 2 days ! Appreciate any sort of help !",0,1,False,self,,,,,
1204,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,21,dkiu3f,self.MachineLearning,ImageNet dataset download links down?,https://www.reddit.com/r/MachineLearning/comments/dkiu3f/imagenet_dataset_download_links_down/,pram-ila,1571573600,[removed],0,1,False,self,,,,,
1205,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,21,dkj1p8,self.MachineLearning,"To take in and figure out from the unknown. Self analyzing, self learning. Then are by that logic - self aware.",https://www.reddit.com/r/MachineLearning/comments/dkj1p8/to_take_in_and_figure_out_from_the_unknown_self/,n2901,1571574903,[removed],0,1,False,self,,,,,
1206,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,21,dkj5gw,self.MachineLearning,Intel Movidius Neural Compute Stick,https://www.reddit.com/r/MachineLearning/comments/dkj5gw/intel_movidius_neural_compute_stick/,a_noob__,1571575518,Anyone here worked with NCS before? I am having trouble with understanding the output from the stick.,0,1,False,self,,,,,
1207,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,22,dkjlq2,self.MachineLearning,[D] I'm looking for success/failure stories applying unsupervised document embedding techniques,https://www.reddit.com/r/MachineLearning/comments/dkjlq2/d_im_looking_for_successfailure_stories_applying/,shaypal5,1571578100,"Hey everyone! :)

As the title says, I am looking for both success stories and disappointing failures of applications of **modern** unsupervised document embedding techniques on actual problems (as opposed to academic benchmarks, toy datasets, academic evaluation tasks, etc.). The main focus is naturally on industry uses for business/product problems, but I would also love to hear about cases from government bodies, non-profits, use in research (with empirical measurement and where document embedding is one of the tools, not the subject of research) and any other ""real life"" use. I would love to hear about your experience, but connecting me to people you know or even hinting me towards companies or projects you know used these techniques (or tried to) would also be of tremendous help.

What's in it for you? Well, I'm preparing a talk for [the data science track of the CodeteCON #KRK5 conference](https://codetecon.pl/en/#program) based on my [literature review-y blog post on document embedding techniques](https://towardsdatascience.com/document-embedding-techniques-fed3e7a6a25d), and while I feel I have a pretty good overview of the academic papers, benchmarks and SOTA status up until the most recent stuff to come out in the field at this point in time, I can't say the same for uses in the industry; I have a partial view from my experience in one ongoing project to actually use this, and experience shared by some of my data scientist friends (all in Israel, naturally) - most of it, so far, by the way, is that averaging (good) word embeddings is a very tough ""baseline"" to beat.

This is why I thought reaching out to get a better sense of things in the industry world-wide, and enriching my talk with the status of actual successes and industry applications will give people attending my talk more value, and will serve my attempt to make my talk a status report on the topic.

And (coming back to WIIFM) naturally (I think), I intend to share any (share-able) knowledge I accumulate not only in my talk, but also by adding a section dedicated to it to [the aforementioned blog post](https://towardsdatascience.com/document-embedding-techniques-fed3e7a6a25d), and maybe even by writing an extended post around it (if enough interesting trends and issues come up). So, hopefully, if you are (like me) interested in this, we might also end up getting, together, a nice overview of where the industry stands at the moment.

What **modern** techniques (so no variants of bag-of-words or topic modeling techniques) am I talking about? These are the ones that I know of (I'd love to hear about others!):

* n-gram embeddings
* Averaging word embeddings (including all variants, e.g. SIF)
* Sent2Vec
* Paragraph vectors (doc2vec)
* Doc2VecC
* Skip-thought vectors
* FastSent
* Quick-thought vectors
* Word Movers Embedding (WME)
* Sentence-BERT (SBERT)
* GPT/GPT2 (can also be supervised)
* Universal Sentence Encoder (can also be supervised)
* GenSen (can also be supervised)

Thank you and cheers,  
Shay  :)",11,29,False,self,,,,,
1208,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,23,dkk637,youtu.be,Machine Learning - StarCraft 2 Python AI part 3 - Build Marines,https://www.reddit.com/r/MachineLearning/comments/dkk637/machine_learning_starcraft_2_python_ai_part_3/,burdin271,1571581038,,0,1,False,default,,,,,
1209,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,23,dkkf3m,self.MachineLearning,[R] How These Self-Aware Robots Are Redefining Consciousness,https://www.reddit.com/r/MachineLearning/comments/dkkf3m/r_how_these_selfaware_robots_are_redefining/,ch3njust1n,1571582249,"The Seeker youtube channel put out this video from Columbia University today titled [How These Self-Aware Robots Are Redefining Consciousness](https://www.youtube.com/watch?v=chukkEeGrLM). Seems like they're basically rebranding model-based rl as self-modeling. I couldn't find a full-length paper of their [Task-agnostic Self-modeling Machines](https://www.creativemachineslab.com/uploads/6/9/3/4/69340277/task-agnostic_self-modeling_machines.pdf) paper. Also no links to a full-length paper in their citation to their [github](https://github.com/rjk2147/Task-Agnostic_Self-Modeling_Machines) for this project.   


In their paper they use the term ""action-sensation pair"". What does this mean? I don't follow DRL as closely, but I don't recall ever coming across this term and they didn't define it here. I assume it's a tuple of a random action and signal from the environment that corresponds to the robot's body.  


A few quotes from the paper:  
""by separating the self from the task, every future experience can be used to refine a common self-model, leading to continuous self-monitoring""

What does that mean?

""As an alternative to self-modeling, many robotic systems do without a model altogether by using end-to-end training for a specific task, applying techniques such as model-free reinforcement learning (4).""

So is this just model-based DRL? Is this just more ml hype?",1,0,False,self,,,,,
1210,MachineLearning,t5_2r3gv,2019-10-20,2019,10,20,23,dkkp15,self.MachineLearning,Skip Deep Generative Model,https://www.reddit.com/r/MachineLearning/comments/dkkp15/skip_deep_generative_model/,Zammit_Judah,1571583548,[removed],0,1,False,self,,,,,
1211,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,0,dkl2ve,self.MachineLearning,understanding error metrics for linearregression and multilayerperceptron?,https://www.reddit.com/r/MachineLearning/comments/dkl2ve/understanding_error_metrics_for_linearregression/,Peshmerga,1571585281,[removed],0,1,False,self,,,,,
1212,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,0,dkl92d,self.MachineLearning,Why are the NVIDIA Super cards not compatible with CUDA?,https://www.reddit.com/r/MachineLearning/comments/dkl92d/why_are_the_nvidia_super_cards_not_compatible/,MundaneBid3,1571586050,[removed],0,1,False,self,,,,,
1213,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,0,dkleff,self.MachineLearning,Machine learning to detect public attitude about a phenomenon on social media?,https://www.reddit.com/r/MachineLearning/comments/dkleff/machine_learning_to_detect_public_attitude_about/,helloiambrain,1571586710,[removed],0,0,False,self,,,,,
1214,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,1,dklpvl,self.MachineLearning,[D] Conditions for a convolution to be bijective?,https://www.reddit.com/r/MachineLearning/comments/dklpvl/d_conditions_for_a_convolution_to_be_bijective/,Ulfgardleo,1571588152,"Setting: I have a convolution of Image I and kernel w, J=conv2D(I,w). I is an image I of size nxn with c channels, while w is a cxcx3x3 matrix, therefore we have c 3x3 filters that can be applied to the image. We use zero-padding so that J has the same dimensionality of I.

What properties does w have to fulfill for the convolution to be invertible? It is clear that at least one such w exists, because 1x1 convolutions are a subset of 3x3 convolutions and since we have c filters, we can encode the identity, which is invertible. It is not enough for the filters to be independent, because as the input has 9c dimensions, we can still loose information.",21,5,False,self,,,,,
1215,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,1,dklv17,self.MachineLearning,[D] Exploring transformers and self-attention for time series forecasting,https://www.reddit.com/r/MachineLearning/comments/dklv17/d_exploring_transformers_and_selfattention_for/,svpadd3,1571588786,[A blog post](https://towardsdatascience.com/attention-for-time-series-classification-and-forecasting-261723e0006d) that reviews applying transformers and attention (more broadly) to time series data. Also investigates a bit into why self-attention works in NLP and the necessary modifications to for it to work with time series data.,2,15,False,self,,,,,
1216,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,1,dklx1o,self.MachineLearning,"[D] Trying to understand the proof in ""Weight Uncertainty in Neural Networks"" by DeepMind",https://www.reddit.com/r/MachineLearning/comments/dklx1o/d_trying_to_understand_the_proof_in_weight/,brandinho77,1571589045,"Can someone please explain this proof from one of DeepMind's papers ( [https://arxiv.org/pdf/1505.05424.pdf](https://arxiv.org/pdf/1505.05424.pdf) ). I am having difficulty understanding where the second term in the expectation comes from?

https://i.redd.it/8083hi5y0qt31.png",10,29,False,self,,,,,
1217,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,1,dkm6gm,self.MachineLearning,Problem with a model,https://www.reddit.com/r/MachineLearning/comments/dkm6gm/problem_with_a_model/,saadmrb,1571590208,[removed],0,1,False,self,,,,,
1218,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,2,dkmhby,self.MachineLearning,[D] Good idea to contact AC about poor review?,https://www.reddit.com/r/MachineLearning/comments/dkmhby/d_good_idea_to_contact_ac_about_poor_review/,AnonMLstudent,1571591536,Wanted to hear people's opinions on this as I've heard both sides. Specifically in the case where we have a box we can fill in with comments that only the ACs and PCs will see.,10,1,False,self,,,,,
1219,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,3,dkn8aj,self.MachineLearning,Good Resources For Machine Learning,https://www.reddit.com/r/MachineLearning/comments/dkn8aj/good_resources_for_machine_learning/,ag2718,1571594742,[removed],0,1,False,self,,,,,
1220,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,3,dkng5n,self.MachineLearning,[P] Hyperparameter tuning for Keras &amp; scikit-learn models using Keras Tuner,https://www.reddit.com/r/MachineLearning/comments/dkng5n/p_hyperparameter_tuning_for_keras_scikitlearn/,curiousily_,1571595630,I took Keras Tuner for a spin. This post: https://www.curiousily.com/posts/hackers-guide-to-hyperparameter-tuning/ contains examples of how to tune your models using Random Search &amp; Bayesian Optimization.,17,44,False,self,,,,,
1221,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,3,dknrwh,self.MachineLearning,AI generated music video,https://www.reddit.com/r/MachineLearning/comments/dknrwh/ai_generated_music_video/,yagarea,1571596979,[removed],0,1,False,self,,,,,
1222,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,4,dko91x,self.MachineLearning,Machine Intelligence Masterclass,https://www.reddit.com/r/MachineLearning/comments/dko91x/machine_intelligence_masterclass/,AnimeT-shirt,1571598898,[removed],0,1,False,https://b.thumbs.redditmedia.com/SoqnaWqcwWCZThjgJzikBKCOY8qWNNjnGGgHmlGVwDc.jpg,,,,,
1223,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,4,dkoklu,self.MachineLearning,Start Build IOT and machine learning products by Bolt IoT kit,https://www.reddit.com/r/MachineLearning/comments/dkoklu/start_build_iot_and_machine_learning_products_by/,Riasissiehyodo,1571600187,[removed],0,1,False,self,,,,,
1224,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,5,dkox1s,self.MachineLearning,[D] Machine Learning - WAYR (What Are You Reading) - Week 73,https://www.reddit.com/r/MachineLearning/comments/dkox1s/d_machine_learning_wayr_what_are_you_reading_week/,ML_WAYR_bot,1571601615,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|31-40|41-50|51-60|61-70|71-80|
|----|-----|-----|-----|-----|-----|-----|-----|
|[Week 1](https://www.reddit.com/4qyjiq)|[Week 11](https://www.reddit.com/57xw56)|[Week 21](https://www.reddit.com/60ildf)|[Week 31](https://www.reddit.com/6s0k1u)|[Week 41](https://www.reddit.com/7tn2ax)|[Week 51](https://reddit.com/9s9el5)|[Week 61](https://reddit.com/bfsx4z)|[Week 71](https://reddit.com/d7vno3)||||||
|[Week 2](https://www.reddit.com/4s2xqm)|[Week 12](https://www.reddit.com/5acb1t)|[Week 22](https://www.reddit.com/64jwde)|[Week 32](https://www.reddit.com/72ab5y)|[Week 42](https://www.reddit.com/7wvjfk)|[Week 52](https://reddit.com/a4opot)|[Week 62](https://reddit.com/bl29ov)|[Week 72](https://reddit.com/de8h48)||
|[Week 3](https://www.reddit.com/4t7mqm)|[Week 13](https://www.reddit.com/5cwfb6)|[Week 23](https://www.reddit.com/674331)|[Week 33](https://www.reddit.com/75405d)|[Week 43](https://www.reddit.com/807ex4)|[Week 53](https://reddit.com/a8yaro)|[Week 63](https://reddit.com/bqlb3v)||
|[Week 4](https://www.reddit.com/4ub2kw)|[Week 14](https://www.reddit.com/5fc5mh)|[Week 24](https://www.reddit.com/68hhhb)|[Week 34](https://www.reddit.com/782js9)|[Week 44](https://reddit.com/8aluhs)|[Week 54](https://reddit.com/ad9ssz)|[Week 64](https://reddit.com/bw1jm7)||
|[Week 5](https://www.reddit.com/4xomf7)|[Week 15](https://www.reddit.com/5hy4ur)|[Week 25](https://www.reddit.com/69teiz)|[Week 35](https://www.reddit.com/7b0av0)|[Week 45](https://reddit.com/8tnnez)|[Week 55](https://reddit.com/ai29gi)|[Week 65](https://reddit.com/c7itkk)||
|[Week 6](https://www.reddit.com/4zcyvk)|[Week 16](https://www.reddit.com/5kd6vd)|[Week 26](https://www.reddit.com/6d7nb1)|[Week 36](https://www.reddit.com/7e3fx6)|[Week 46](https://reddit.com/8x48oj)|[Week 56](https://reddit.com/ap8ctk)|[Week 66](https://reddit.com/cd7gko)||
|[Week 7](https://www.reddit.com/52t6mo)|[Week 17](https://www.reddit.com/5ob7dx)|[Week 27](https://www.reddit.com/6gngwc)|[Week 37](https://www.reddit.com/7hcc2c)|[Week 47](https://reddit.com/910jmh)|[Week 57](https://reddit.com/auci7c)|[Week 67](https://reddit.com/cj0kyc)||
|[Week 8](https://www.reddit.com/53heol)|[Week 18](https://www.reddit.com/5r14yd)|[Week 28](https://www.reddit.com/6jgdva)|[Week 38](https://www.reddit.com/7kgcqr)|[Week 48](https://reddit.com/94up0g)|[Week 58](https://reddit.com/azjoht)|[Week 68](https://reddit.com/cp1jex)||
|[Week 9](https://www.reddit.com/54kvsu)|[Week 19](https://www.reddit.com/5tt9cz)|[Week 29](https://www.reddit.com/6m9l1v)|[Week 39](https://www.reddit.com/7nayri)|[Week 49](https://reddit.com/98n2rt)|[Week 59](https://reddit.com/b50r5y)|[Week 69](https://reddit.com/cvde5a)||
|[Week 10](https://www.reddit.com/56s2oa)|[Week 20](https://www.reddit.com/5wh2wb)|[Week 30](https://www.reddit.com/6p3ha7)|[Week 40](https://www.reddit.com/7qel9p)|[Week 50](https://reddit.com/9cf158)|[Week 60](https://reddit.com/bakew0)|[Week 70](https://reddit.com/d1g1k9)||

Most upvoted papers two weeks ago:

/u/MasterScrat: [Online Batch Selection for Faster Training of Neural Networks](https://arxiv.org/abs/1511.06343)

/u/YoungStellarObject: [Layer-Wise Relevance Propagation paper](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140)

Besides that, there are no rules, have fun.",44,31,False,self,,,,,
1225,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,5,dkpoa4,self.MachineLearning,[R] Context-Aware Monolingual Repair for Neural Machine Translation,https://www.reddit.com/r/MachineLearning/comments/dkpoa4/r_contextaware_monolingual_repair_for_neural/,justheuristic,1571604756,"[https://arxiv.org/abs/1909.01383](https://arxiv.org/abs/1909.01383)

Multi-sentence Neural Machine Translation that does not require parallel multi-sentence data. 

&amp;#x200B;

[\[Figure from the paper\] - first, use conventional NMT to translate sentences. Second, apply Document Repair model to assemble translated sentences into a cohesive text](https://i.redd.it/re1svxr1ert31.png)",0,15,False,self,,,,,
1226,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,6,dkq396,self.MachineLearning,[D] Does this sound like I have a reasonable chance at an interview/employee referral?,https://www.reddit.com/r/MachineLearning/comments/dkq396/d_does_this_sound_like_i_have_a_reasonable_chance/,alinkawayfrom,1571606524,"So I'm premed, but I'm also doing undergrad research in machine learning. Unfortunately, my university is very sparse in terms of machine learning research (there really isn't any going on).

I found an MD (physician) who happens to have a research role at a Big N company. I checked his LinkedIn, and he's only been there for 2 years. Because he's a doctor, I would assume he's a bit further removed from most standard administrative and workplace stuff than the average Big N employee (am I correct to assume this?). I guess you could consider him to be more of an ""adjunct"" there - though I really have no idea how it works for a doctor at a tech company.

Anyway, I emailed him saying ""if I do really well on the MCAT, and do [list of tasks to learn/practice ML]"", will you put me past the HR resume filter for an interview?

This was his first response: ""Sounds reasonable to me. Internships are pretty competitive for some of the teams at [Big N] and some but not all look for students in graduate studies. As long as you enjoy your studies and are passionate about what you are doing, you will be on the right path.""

Me: ""Its my understanding that someone at Big N reaches out to HR, and from there Im put in touch with a recruiter who starts the interview process. If I pass the interview, HR then confirms with the initial employee/team that theres an open spot for an intern in the group. If I meet the goals Ive outlined, would you or someone else on your team be comfortable with reaching out to HR to start the process?""

Him: ""i'm not sure if internal referrals change the process for intern selection, which generally has its own application process. feel free to reach out again as you get closer to applying and we can see""

So I've met one component of the ""goals I've outlined"" (did really well on the MCAT), and I'll easily be able to accomplish the rest. Do his responses sound like he was just being polite/he very likely won't be able to put me past the resume filter? I'm not sure if I should actually consider this an ""in"" or not hahaha",7,0,False,self,,,,,
1227,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,6,dkqlbz,technologyreview.com,[R] Machine vision can use radio waves to see through walls and in darkness,https://www.reddit.com/r/MachineLearning/comments/dkqlbz/r_machine_vision_can_use_radio_waves_to_see/,myhotpot,1571608741,,1,1,False,default,,,,,
1228,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,8,dkrje4,self.MachineLearning,[D] Design methodology for ML engineering.,https://www.reddit.com/r/MachineLearning/comments/dkrje4/d_design_methodology_for_ml_engineering/,kireeti_,1571613134,"I am currently preparing for ML Engineer interviews and wanted to learn a design methodology to crack the design rounds. I have looked for standard resources but couldn't find any. So I thought of coming up with one on my own from my own experiences and material that I have read online. So below is an overview of the approach I have in my mind. Please let me know what you think of it. 

&amp;#x200B;

1. Understand the use case. 
   1. Figure out what can be solved deterministically 
   2. Figure out what needs to be solved using Data + Machine learning
2. Pose the problem(1.b) as a math problem. 
   1. Come up with an objective that you want to optimize. 
3. Select the right data set. 
   1. What data is needed. How is the labeling done/derived? 
   2. How do you deal with bias, skewed classes, 
4. Feature Engineering. 
   1. Think about what(information) you need to solve the problem optimally. 
   2. What aspects from the data could you use to replicate findings in 4.a? 
   3. Transform data into features and a form more apt for models learning
5. Model selection:
   1. What model is best suited to solve the problem(2.a) at hand.
   2. Are there any off the shelf(direct or transfer learning) that would help. 
6. Training: 
   1. How will you train
   2. How will you handle: skewed classes and other problems associated with the dataset. 
   3. Validation: what metrics, experiments do you conduct to validate the models learning. 
7. Productionizing: 
   1. How will the solution be deployed? 
   2. Performance monitoring, feedback loop/retrain,
   3. Application scaling and model maintenance.",23,239,False,self,,,,,
1229,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,9,dks78s,self.Bloodoverintent,Machine of creation,https://www.reddit.com/r/MachineLearning/comments/dks78s/machine_of_creation/,brealzz,1571616286,,1,1,False,default,,,,,
1230,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,9,dks8v9,self.MachineLearning,PVC Boots,https://www.reddit.com/r/MachineLearning/comments/dks8v9/pvc_boots/,NotThatBright123,1571616525,[removed],0,1,False,self,,,,,
1231,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,9,dksjo4,eigenfoo.xyz,Modern Computational Methods for Bayesian Inference  A Reading List,https://www.reddit.com/r/MachineLearning/comments/dksjo4/modern_computational_methods_for_bayesian/,__gh,1571618053,,0,1,False,default,,,,,
1232,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,9,dksmgz,arabianbusiness.com,Abu Dhabi launches world's first university of artificial intelligence (Sad sidenote: I somewhat launched machine learning Jamaica Institute in 2016),https://www.reddit.com/r/MachineLearning/comments/dksmgz/abu_dhabi_launches_worlds_first_university_of/,ProgrammingGodJordan,1571618460,,0,1,False,https://b.thumbs.redditmedia.com/WswkPoT8IjVf1yTWbmpVEIF6MliF2RuKOY91Ngk7MiU.jpg,,,,,
1233,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,9,dkspwb,self.MachineLearning,How,https://www.reddit.com/r/MachineLearning/comments/dkspwb/how/,sabot00,1571618940,[removed],0,1,False,self,,,,,
1234,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,9,dksubv,medium.com,AI In Wildlife Conservation,https://www.reddit.com/r/MachineLearning/comments/dksubv/ai_in_wildlife_conservation/,Yuqing7,1571619573,,0,1,False,default,,,,,
1235,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,11,dktlgw,youtu.be,[D] This guy trained a complex system to play minecraft,https://www.reddit.com/r/MachineLearning/comments/dktlgw/d_this_guy_trained_a_complex_system_to_play/,Destigeous,1571623446,,0,1,False,default,,,,,
1236,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,11,dktr56,self.MachineLearning,Shape based clustering of the time series,https://www.reddit.com/r/MachineLearning/comments/dktr56/shape_based_clustering_of_the_time_series/,chess1368,1571624247,[removed],0,1,False,self,,,,,
1237,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,11,dku7ye,self.MachineLearning,The Deep Learning Series: Part I. An intuitive way,https://www.reddit.com/r/MachineLearning/comments/dku7ye/the_deep_learning_series_part_i_an_intuitive_way/,piyushgandhi811,1571626648,[removed],0,1,False,self,,,,,
1238,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,13,dkuxcr,self.MachineLearning,[D] How do you keep up with latest advances in ML which are not directly relevant to your work?,https://www.reddit.com/r/MachineLearning/comments/dkuxcr/d_how_do_you_keep_up_with_latest_advances_in_ml/,nivter,1571630423,"In recent years I have heard of key advances made in NLP by transformer models and BERT. Then there was this paper on neural ODEs by DeepMind. 

I have been wanting to dig deeper into the details and understand the key ideas behind these hot topics. They are not directly relevant to my work (which is focused mainly on images/videos) but I still feel it is important as an ML engineer to keep myself up-to-date with key developments in diverse areas. However because it does not directly relate to my work, I find it hard to find the time to get a deeper understanding of these papers.

Has anyone found themselves in a similar situation? How do you deal with it?",14,12,False,self,,,,,
1239,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,14,dkvqzp,self.MachineLearning,What is a solenoid coil?,https://www.reddit.com/r/MachineLearning/comments/dkvqzp/what_is_a_solenoid_coil/,uflowindia,1571635330,[removed],0,1,False,self,,,,,
1240,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,15,dkwd3y,tweakyourbiz.com,Top 3 Ways in Which Artificial Intelligence is improving the legal landscape?,https://www.reddit.com/r/MachineLearning/comments/dkwd3y/top_3_ways_in_which_artificial_intelligence_is/,nexcorp,1571639385,,0,1,False,default,,,,,
1241,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,16,dkwq4f,arxiv.org,[R] Privacy-preserving Federated Bayesian Learning of a Generative Model for Imbalanced Classification of Clinical Data,https://www.reddit.com/r/MachineLearning/comments/dkwq4f/r_privacypreserving_federated_bayesian_learning/,vaseline555,1571641793,,1,1,False,default,,,,,
1242,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,16,dkwsxi,self.MachineLearning,[D] Possible privacy attack method on data shrunk by autoencoder?,https://www.reddit.com/r/MachineLearning/comments/dkwsxi/d_possible_privacy_attack_method_on_data_shrunk/,vaseline555,1571642283," [http://arxiv.org/abs/1910.08489](http://arxiv.org/abs/1910.08489?fbclid=IwAR2xDzQEI9JOZ3BjUeVGJ6ep4uSSnj9PU_NoaKlDSFXHJaKL1VpmIIhjOzo)

Hello, this is my first paper preprint:

**Privacy-preserving Federated Bayesian Learning of a Generative Model for Imbalanced Classification of Clinical Data**

Though it is not fully biased toward deep learning, or federated learning on a edge device, I made a new framework for learning a global model in a horizontally distributed setting, especially in a clinical field. 

AFAIK, it is the first trial to apply Approximate Bayesian Computation(ABC) on federated learning.  
(If not, please let me know!)

Without complicated perturbation techniques e.g. Differential Privacy, Homomorphic encryption, Hashing, etc., the proposed method can preserve privacy.

===

As I said in the paper, unless each local site reveals trained weights and the structure of Autoencoder, shrunk data CANNOT be recovered in the central server. Also not possible even if some local sites conspire against the other site to disclose the information.

* But this is my hypothesis and expectation, so I want to listen to some feedback or opinions on this.  
Is it really impossible to make leakage on data shrunk by local autoencdoer?

===

Plus, a global model can be learned in the central server with the minimal information (merely with a distance between local data (perturbed via Autoencoder) and generated data (same dim. with the perturbed one)).

Welcome and thank you in advance for any feedback and questions!",0,7,False,self,,,,,
1243,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,16,dkwthm,self.MachineLearning,Show Reddit: pgANN Fast Approximate Nearest Neighbor (ANN) searches with a PostgreSQL database.,https://www.reddit.com/r/MachineLearning/comments/dkwthm/show_reddit_pgann_fast_approximate_nearest/,bluzkluz,1571642375,[removed],0,1,False,self,,,,,
1244,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,16,dkwwrt,self.MachineLearning,[Project] pgANN Fast Approximate Nearest Neighbor (ANN) searches with a PostgreSQL database.,https://www.reddit.com/r/MachineLearning/comments/dkwwrt/project_pgann_fast_approximate_nearest_neighbor/,bluzkluz,1571642978,"We are open-sourcing [pgANN](https://github.com/netrasys/pgANN) \- an ANN (approx nearest neighbor) approach with a PostgreSQL backend. The key differentiator between pgANN and the rest (FAISS, Annoy,NearPy etc) is:

1. this enables ""online"" learning i.e. doesn't require retraining with every CRUD, and
2. works with extremely large datasets, since it's not held in RAM like the others

We use it internally to QA images and find it consistently provides sub-second query performance with a few million rows of vectors on a 32GB.8 vcpu Ubuntu box and can reasonably be expected to scale-up with normal pgsql scaling techniques. We invite the community to give this a try and share feedback.",13,115,False,self,,,,,
1245,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,17,dkxm5q,self.MachineLearning,Car rims dataset--where to start?,https://www.reddit.com/r/MachineLearning/comments/dkxm5q/car_rims_datasetwhere_to_start/,borgetti,1571647848,[removed],0,1,False,self,,,,,
1246,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,19,dkyend,self.MachineLearning,[D] Any source code annotation tool,https://www.reddit.com/r/MachineLearning/comments/dkyend/d_any_source_code_annotation_tool/,data-soup,1571652997,"I'd like to annotate source code (mainly PHP/HTML/JS), highlight some parts of the docs and apply tags. Is anyone aware of this kind of tool?",8,2,False,self,,,,,
1247,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,20,dkz2qw,self.MachineLearning,Career in Machine Learning with a Business Degree,https://www.reddit.com/r/MachineLearning/comments/dkz2qw/career_in_machine_learning_with_a_business_degree/,SingleFlight,1571656955,[removed],0,1,False,self,,,,,
1248,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,20,dkz4cz,self.MachineLearning,Is Pascal VOC dataset website deleted?,https://www.reddit.com/r/MachineLearning/comments/dkz4cz/is_pascal_voc_dataset_website_deleted/,creotiv,1571657209,[removed],0,1,False,self,,,,,
1249,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,20,dkz73n,self.MachineLearning,Can i make my drone follow me?,https://www.reddit.com/r/MachineLearning/comments/dkz73n/can_i_make_my_drone_follow_me/,Yavkata,1571657629,"Hello! I hope you're having a great day!
Yesterday i watched a video on youtube about a guy who make his drone follow him with facial recognition. 
My question is do you think i can my drone: Blackout  Mini H Quad follow me or do you how can i understand?",0,1,False,self,,,,,
1250,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,21,dkzny7,self.On_Trusting_AI_ML,[D] Why have a separate community dedicated to trust in AI and ML.,https://www.reddit.com/r/MachineLearning/comments/dkzny7/d_why_have_a_separate_community_dedicated_to/,Hizachi,1571660154,,0,1,False,default,,,,,
1251,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,21,dl053w,self.MachineLearning,Columbia dataset preprocessing question,https://www.reddit.com/r/MachineLearning/comments/dl053w/columbia_dataset_preprocessing_question/,Finster201,1571662558,[removed],0,1,False,self,,,,,
1252,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,22,dl09jo,tensorlayer.readthedocs.io,[R] Full PHD Scholarship @ Peking University,https://www.reddit.com/r/MachineLearning/comments/dl09jo/r_full_phd_scholarship_peking_university/,zsdh123,1571663126,,0,1,False,default,,,,,
1253,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,22,dl09pd,youtu.be,Can someone explain how I could do something like this?,https://www.reddit.com/r/MachineLearning/comments/dl09pd/can_someone_explain_how_i_could_do_something_like/,refinedsorcerer,1571663144,,0,1,False,default,,,,,
1254,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,22,dl0cfx,self.MachineLearning,Looking for Machine Learning experts/Data scientists in banking,https://www.reddit.com/r/MachineLearning/comments/dl0cfx/looking_for_machine_learning_expertsdata/,louisecallens,1571663511,[removed],0,1,False,self,,,,,
1255,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,22,dl0fb5,quora.com,Why are we transforming in datasets to train machine learning algorithms?,https://www.reddit.com/r/MachineLearning/comments/dl0fb5/why_are_we_transforming_in_datasets_to_train/,Huspi_sp_z_o_o,1571663884,,0,1,False,default,,,,,
1256,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,22,dl0yau,self.MachineLearning,Whcih embedding is best for seq2seq?,https://www.reddit.com/r/MachineLearning/comments/dl0yau/whcih_embedding_is_best_for_seq2seq/,omgDoYouKnow,1571666340,[removed],0,1,False,self,,,,,
1257,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,23,dl16ct,youtu.be,Read a paper: Getafix - Learning to Fix Bugs Automatically,https://www.reddit.com/r/MachineLearning/comments/dl16ct/read_a_paper_getafix_learning_to_fix_bugs/,ggvh,1571667308,,0,1,False,https://b.thumbs.redditmedia.com/gRxPugXNyK3eUAsfwKJjSplSuHUvhmhc9_dbP5CcAzU.jpg,,,,,
1258,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,23,dl182u,self.MachineLearning,Creating a time series forecast that predicts a students attendance for the next few weeks - to show what specific days the student will be in,https://www.reddit.com/r/MachineLearning/comments/dl182u/creating_a_time_series_forecast_that_predicts_a/,SuperPiglet97,1571667537,[removed],0,1,False,self,,,,,
1259,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,23,dl1d9q,github.com,Simple Implementation For Siamese Networks,https://www.reddit.com/r/MachineLearning/comments/dl1d9q/simple_implementation_for_siamese_networks/,mrgemy95,1571668220,,0,1,False,default,,,,,
1260,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,23,dl1dth,github.com,[Project] Simple Implementation for Siamese Networks,https://www.reddit.com/r/MachineLearning/comments/dl1dth/project_simple_implementation_for_siamese_networks/,mrgemy95,1571668291,,0,1,False,https://a.thumbs.redditmedia.com/EdhFst7Ban1vdH3LyOceteo2WOeAx4YRgfjRmMd0sf8.jpg,,,,,
1261,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,23,dl1gba,self.MachineLearning,"Hey folks, I am launching a service which compresses convolutional neural network models as far as 60% of their original size.",https://www.reddit.com/r/MachineLearning/comments/dl1gba/hey_folks_i_am_launching_a_service_which/,ark_aung,1571668607,[removed],0,1,False,self,,,,,
1262,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,23,dl1i2l,heartbeat.fritz.ai,Image Classification on Android with Pytorch Mobile,https://www.reddit.com/r/MachineLearning/comments/dl1i2l/image_classification_on_android_with_pytorch/,johnolafenwa,1571668830,,0,1,False,default,,,,,
1263,MachineLearning,t5_2r3gv,2019-10-21,2019,10,21,23,dl1o5l,self.MachineLearning,[R] Meta-Learning Deep Energy-Based Memory Models,https://www.reddit.com/r/MachineLearning/comments/dl1o5l/r_metalearning_deep_energybased_memory_models/,Quantum_Network,1571669592,"Interesting research from DeepMind:

""Our new work on memory uses a neural network's weights as fast and compressive associative storage. Reading from the memory is performed by approximate minimization of the energy modeled by the network.""

""Unlike classical associative memory models such as Hopfield networks, we are not limited in the expressivity of our energy model, and make use of the deep architectures with fully-connected, convolutional and recurrent layers.""

""For this to work, stored patterns must be local minima of the energy. We use recent advances in gradient-based meta-learning to write into the memory such that this requirement approximately holds.""

[https://arxiv.org/abs/1910.02720](https://arxiv.org/abs/1910.02720)",3,24,False,self,,,,,
1264,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,0,dl2bcu,self.MachineLearning,[request] course/book ML model deployment?,https://www.reddit.com/r/MachineLearning/comments/dl2bcu/request_coursebook_ml_model_deployment/,jbuddy_13,1571672346,[removed],0,1,False,self,,,,,
1265,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,0,dl2jp9,self.MachineLearning,[D] Whcih embedding is best for seq2seq?,https://www.reddit.com/r/MachineLearning/comments/dl2jp9/d_whcih_embedding_is_best_for_seq2seq/,omgDoYouKnow,1571673365,Are there embeddings for seq2seq tasks? I have a very large vocab and I want to feed a fixed-length vector rather than one-hot vector to the input of the neural network (and for the output),1,0,False,self,,,,,
1266,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,2,dl3nyp,self.MachineLearning,Source code file difference grouping,https://www.reddit.com/r/MachineLearning/comments/dl3nyp/source_code_file_difference_grouping/,moodyintx,1571678068,[removed],1,1,False,self,,,,,
1267,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,2,dl4201,youtu.be,Hey guys check out part 9 of my Reinforcement Learning Series.!,https://www.reddit.com/r/MachineLearning/comments/dl4201/hey_guys_check_out_part_9_of_my_reinforcement/,indi0508,1571679750,,0,1,False,https://b.thumbs.redditmedia.com/ub3Zbxo-IvLSgsC-nLTcEd2nnS5wZTYfcX7zwsroB-E.jpg,,,,,
1268,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,2,dl4416,self.MachineLearning,[P] Visualizing Tensor Operations with Factor Graphs,https://www.reddit.com/r/MachineLearning/comments/dl4416/p_visualizing_tensor_operations_with_factor_graphs/,MindSustenance,1571679999,"Hey everyone,

I've written a new blog post (https://rajatvd.github.io/Factor-Graphs/) on an awesome visualization tool that I recently came across -- factor graphs. Initially, I encountered them in the context of message passing on graphical models, but soon realized that they are useful in more general contexts.

This is the first post in a series that covers the basics and mainly focuses on understanding how factor graphs work as a virtualization tool, along with a cool example of a visual proof using them. In future posts, I plan to cover algorithms like message passing and belief propagation using this visualization framework. 

I made the animations using [manim](https://github.com/3b1b/manim/), a math animation tool created by the amazing [3blue1brown](https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw). I built a small library, [manimnx](https://github.com/rajatvd/manimnx), on top of manim to help interface it with the graph package [networkx](https://networkx.github.io). You can find the code for the animations in this [github repo](https://github.com/rajatvd/FactorGraphs).

Feedback is welcome!",18,200,False,self,,,,,
1269,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,3,dl4kl9,medium.com,Can Pretrained Language Models Replace Knowledge Bases?,https://www.reddit.com/r/MachineLearning/comments/dl4kl9/can_pretrained_language_models_replace_knowledge/,Yuqing7,1571681960,,0,1,False,https://b.thumbs.redditmedia.com/I72NKcB4_m4o3CA1M4LaGlfJi16Ix6u05cS_iv9Cm0E.jpg,,,,,
1270,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,3,dl4lw2,self.MachineLearning,Best practices for training GANs,https://www.reddit.com/r/MachineLearning/comments/dl4lw2/best_practices_for_training_gans/,spotta,1571682129,[removed],0,1,False,self,,,,,
1271,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,3,dl4sc6,ben-evans.com,Machine learning deployment  Benedict Evans,https://www.reddit.com/r/MachineLearning/comments/dl4sc6/machine_learning_deployment_benedict_evans/,troy_petersen,1571682896,,0,1,False,default,,,,,
1272,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,3,dl4sud,youtu.be,Read a paper: Getafix - Learning to Fix Bugs Automatically,https://www.reddit.com/r/MachineLearning/comments/dl4sud/read_a_paper_getafix_learning_to_fix_bugs/,ggvh,1571682959,,0,1,False,default,,,,,
1273,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,4,dl57wk,self.MachineLearning,Full Stack Deep Learning,https://www.reddit.com/r/MachineLearning/comments/dl57wk/full_stack_deep_learning/,jargon59,1571684701,[removed],0,1,False,self,,,,,
1274,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,4,dl592c,self.MachineLearning,[R] Symmetry-Based Disentangled Representation Learning requires Interaction with Environments,https://www.reddit.com/r/MachineLearning/comments/dl592c/r_symmetrybased_disentangled_representation/,rtk25,1571684827,"NeurIPS2019 paper, looks interesting:

[https://arxiv.org/abs/1904.00243](https://arxiv.org/abs/1904.00243)

&amp;#x200B;

&gt;Symmetry-Based Disentangled Representation Learning cannot only be based on static observations: agents should interact with the environment to discover its symmetries.

I'm not familiar with this line of research, but it seems like this could have significant implications on how models are trained, as many current benchmark datasets are static. I'd be interested in hearing thoughts from those more familiar with the method.",7,7,False,self,,,,,
1275,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,4,dl5mii,self.MachineLearning,what kind of machine learning problem is this ?,https://www.reddit.com/r/MachineLearning/comments/dl5mii/what_kind_of_machine_learning_problem_is_this/,drrid93,1571686405,"Hello redditors, I have a set of cephalometric traces (img1) that i want to extract point coordinates from (img 2), how should i approach this problem ?",0,1,False,self,,,,,
1276,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,5,dl6iwc,self.MachineLearning,Good video courses for machine learning with Python?,https://www.reddit.com/r/MachineLearning/comments/dl6iwc/good_video_courses_for_machine_learning_with/,LePetitChienneGarcon,1571690194,[removed],0,1,False,self,,,,,
1277,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,5,dl6ozu,highlyimplosible.com,Stochastic Optimal Control: demonstrating the dynamic programming principle - Highly ImplSible,https://www.reddit.com/r/MachineLearning/comments/dl6ozu/stochastic_optimal_control_demonstrating_the/,its-trivial,1571690905,,0,1,False,default,,,,,
1278,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,5,dl6qxm,technologyreview.com,"We analyzed 16,625 papers to figure out where AI is headed next",https://www.reddit.com/r/MachineLearning/comments/dl6qxm/we_analyzed_16625_papers_to_figure_out_where_ai/,typingdot,1571691133,,0,1,False,default,,,,,
1279,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,5,dl6stx,youtube.com,Energy-based Approaches to Representation Learning - Yann LeCun,https://www.reddit.com/r/MachineLearning/comments/dl6stx/energybased_approaches_to_representation_learning/,wavelander,1571691357,,0,1,False,default,,,,,
1280,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,6,dl73ay,self.MachineLearning,"[D] What's a hypothesis that you would really like to see tested, but never will get around to testing yourself, and hoping that someone else will get around to doing it?",https://www.reddit.com/r/MachineLearning/comments/dl73ay/d_whats_a_hypothesis_that_you_would_really_like/,BatmantoshReturns,1571692529,"My wishlist:

-I really want to see doc2vec but with contextualized vectors (Bert, Elmo, etc) instead of word2vec. I think it'll be a slam dunk. I don't think I'll ever get around to testing this. If anyone wants to do it, i'll be happy to give some guidance if it's needed. 

-I would really like to see word2vec or glove tested with a context limited to other words within the same sentence as the target word. Or, perhaps extend the context to any word in the same paragraph. I was sort of planning on doing this, but lost some motivation with the rise of contextualized vectors. I think it would give some great insight though.",26,31,False,self,,,,,
1281,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,6,dl73hy,self.MachineLearning,"Having a good math &amp; python background, what is some good ressource to dive into ML ?",https://www.reddit.com/r/MachineLearning/comments/dl73hy/having_a_good_math_python_background_what_is_some/,hugeburger,1571692556,[removed],0,1,False,self,,,,,
1282,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,6,dl74ss,arxiv.org,[R] A Mutual Information Maximization Perspective of Language Representation Learning,https://www.reddit.com/r/MachineLearning/comments/dl74ss/r_a_mutual_information_maximization_perspective/,HipsterToofer,1571692704,,1,5,False,default,,,,,
1283,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,6,dl79ur,self.MachineLearning,Intuition behind additive and multiplicative attention mechanism.,https://www.reddit.com/r/MachineLearning/comments/dl79ur/intuition_behind_additive_and_multiplicative/,zurasage,1571693291,[removed],0,1,False,self,,,,,
1284,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,8,dl8rb0,self.MachineLearning,Image semantic segmentation without deep learning,https://www.reddit.com/r/MachineLearning/comments/dl8rb0/image_semantic_segmentation_without_deep_learning/,h4k1m0u,1571699780,[removed],0,1,False,self,,,,,
1285,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,8,dl8rl0,self.MachineLearning,"Which machine learning technique can be a good option for all of these: pattern recognition, anomaly detection, and prediction?",https://www.reddit.com/r/MachineLearning/comments/dl8rl0/which_machine_learning_technique_can_be_a_good/,ShervinAtaeian,1571699811,"Hi, I want to develop an algorithm that would use past date to predict future waiting time values, and identify patterns, and detect anomalies in demand data for a variety of products. I am a beginner and since I have limited time, I want to know if there is machine learning technique that would have all of these applications. I know that Deep Learning is used for prediction and anomaly detection. Can it be used for pattern recognition, too? Do you think that I should use different ML techniques for each purpose?",0,1,False,self,,,,,
1286,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,8,dl90sd,self.MachineLearning,Autoencoder predictions for extremely simple task does not make intuitive sense.,https://www.reddit.com/r/MachineLearning/comments/dl90sd/autoencoder_predictions_for_extremely_simple_task/,preethster,1571700923,"I am training a simple autoencoder in Keras. I am fairly new to this. The input is of length two, where each element can either be 0 or 1. This gives four distinct input possibilities: \[0, 0\], \[0, 1\], \[1, 0\], \[1, 1\]. Since there is no noise present, the input can only be these four options.

It does not really make sense to use an autoencoder here, but I am trying to build a basic understanding and make sure my general approach works for simple problems with known outcomes before proceeding to more complex problems that involve adding noise, etc.

I realize this is applied to images so may not directly translate, but I used this tutorial as a starting point: [https://blog.keras.io/building-autoencoders-in-keras.html](https://blog.keras.io/building-autoencoders-in-keras.html). Here is the structure I used (I made this up, not a ton of intuition behind this architecture choice but wanted to keep it simple and take into account the input/output data format).

    input_dim = 2 
    encoded_dim = 4 
    input_ = Input(shape=(input_dim,)) 
    encoded_ = Dense(input_dim, activation='relu')(input_) 
    decoded = Dense(input_dim, activation='relu')(encoded_)  
    output = Dense(input_dim, activation='sigmoid')(decoded) # because output should be between 0 and 1 autoencoder = Model(input_, output)  autoencoder.compile(optimizer='adam',loss='binary_crossentropy') # because each output node in the autoencoder should be a 0 or 1 corresponding to reconstructed input 
    autoencoder.fit(inputs, inputs, batch_size = 8, epochs=12, validation_split = 0.20)

However, I am finding the loss to be extremely high and that the predicted output does not correspond at all the input.  I find this extremely surprising because the problem itself is extremely simple and does not require NNs to solve efficiently since there is no noise/variability in the data. In fact, setting most of the weights to 0 and a few to 1 solves the problem. Do you have any thoughts on why this problem might be difficult for a NN to solve or why my specific approach (architecture choice, loss or activation functions) would not work for this problem? I would appreciate any feedback/improvements/suggestions to help learn. Thank you!",0,1,False,self,,,,,
1287,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,8,dl91gj,self.MachineLearning,Temporal Shift Module in Keras,https://www.reddit.com/r/MachineLearning/comments/dl91gj/temporal_shift_module_in_keras/,thetonus1150,1571701013,[removed],0,1,False,self,,,,,
1288,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,8,dl9cbh,medium.com,Worlds 1st university-like Artificial Intelligence initiative launched (somewhat) in Jamaica. (MLJI),https://www.reddit.com/r/MachineLearning/comments/dl9cbh/worlds_1st_universitylike_artificial_intelligence/,ProgrammingGodJordan,1571702332,,0,1,False,default,,,,,
1289,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,10,dla75r,self.MachineLearning,"[D] Retrain your models, the Adam optimizer in PyTorch was fixed in version 1.3",https://www.reddit.com/r/MachineLearning/comments/dla75r/d_retrain_your_models_the_adam_optimizer_in/,Deepblue129,1571706269,"&gt;I have noticed a small discrepancy between theory and the implementation of AdamW and in general Adam. The epsilon in the denominator of the following Adam update should not be scaled by the bias correction [(Algorithm 2, L9-12)](https://arxiv.org/pdf/1711.05101.pdf). Only the running average of the gradient (*m*) and squared gradients (*v*) should be scaled by their corresponding bias corrections.  
&gt;  
&gt;In the current implementation, the epsilon is scaled by the square root of bias\_correction2  
. I have plotted this ratio as a function of step given beta2 = 0.999  
 and eps = 1e-8  
. In the early steps of optimization, this ratio slightly deviates from theory (denoted by the horizontal red line)

See more here: [https://github.com/pytorch/pytorch/pull/22628](https://github.com/pytorch/pytorch/pull/22628)",7,44,False,self,,,,,
1290,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,10,dla9gw,self.MachineLearning,Heteroskedasticity in Random Forest,https://www.reddit.com/r/MachineLearning/comments/dla9gw/heteroskedasticity_in_random_forest/,ml_help,1571706563,[removed],0,1,False,self,,,,,
1291,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,10,dlar3x,adweek.com,Patent Applications Mentioning GANs Are Up 500% This Year as Brands Test Its Potential,https://www.reddit.com/r/MachineLearning/comments/dlar3x/patent_applications_mentioning_gans_are_up_500/,thugwaffl,1571708799,,0,1,False,default,,,,,
1292,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,11,dlbe5d,self.MachineLearning,Milvus: A big leap to scalable AI search engine,https://www.reddit.com/r/MachineLearning/comments/dlbe5d/milvus_a_big_leap_to_scalable_ai_search_engine/,rainmanwy,1571711856,[removed],0,1,False,self,,,,,
1293,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,12,dlboz1,aiwriter.site,Is this just OpenAI's GPT-2?,https://www.reddit.com/r/MachineLearning/comments/dlboz1/is_this_just_openais_gpt2/,synysterbates,1571713376,,0,1,False,default,,,,,
1294,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,12,dlcb7t,self.MachineLearning,Reinforcement learning and bandits for clinical application - github repo and dataset,https://www.reddit.com/r/MachineLearning/comments/dlcb7t/reinforcement_learning_and_bandits_for_clinical/,hmi2015,1571716617,[removed],0,1,False,self,,,,,
1295,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,14,dldhdc,arxiv.org,Discovering the Compositional Structure of Vector Representations with Role Learning Networks,https://www.reddit.com/r/MachineLearning/comments/dldhdc/discovering_the_compositional_structure_of_vector/,FranklinFan,1571723319,,1,11,False,default,,,,,
1296,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,15,dldm24,self.MachineLearning,Online master for senior applied scientist,https://www.reddit.com/r/MachineLearning/comments/dldm24/online_master_for_senior_applied_scientist/,krishansub,1571724102,[removed],0,1,False,self,,,,,
1297,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,15,dldnbq,self.MachineLearning,ImageNet State-of-the-art,https://www.reddit.com/r/MachineLearning/comments/dldnbq/imagenet_stateoftheart/,arjundupa,1571724289,[removed],0,1,False,self,,,,,
1298,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,15,dldnhw,self.MachineLearning,Videos/PDFs that I should see first that will help me to build a snake game (using machine learning of course)?,https://www.reddit.com/r/MachineLearning/comments/dldnhw/videospdfs_that_i_should_see_first_that_will_help/,Overknown,1571724323,"Hi I'm planning to build a snake game using machine learning but I'm very new to the topic and I already made the snake game (the normal one controlled by the player) which was very easy to do but now I'm stuck on the neural network stuff. When I search other codes their codes are very different from mine and, because I'm new on this topic I pretty much don't know what is useful in the that code or not... I would like to make it on tensor flow...
I just wanna know if there is some video or PDF that shows the tools that I will need that will be useful in games like the snake game.
PS: I just said neural network but if you guys have another videos/PDFs where it uses generic algorithm or something tell me! 
Thanks!",0,1,False,self,,,,,
1299,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,15,dle20e,self.MachineLearning,Which Solenoid Valve Is Best For Air Pollution Control?,https://www.reddit.com/r/MachineLearning/comments/dle20e/which_solenoid_valve_is_best_for_air_pollution/,uflowindia,1571726832,[removed],0,1,False,https://b.thumbs.redditmedia.com/SBI4m0Lw1-8mjJQ7SYPSzaNkLU3K5APM7Q1E7AKeunI.jpg,,,,,
1300,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,16,dle6e1,self.MachineLearning,Looking for a good text autoencoder model (for text reconstruction),https://www.reddit.com/r/MachineLearning/comments/dle6e1/looking_for_a_good_text_autoencoder_model_for/,mhossam,1571727606,[removed],0,1,False,self,,,,,
1301,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,16,dle9ak,hanxiao.github.io,[P] GNES Flow: a Pythonic Way to Build Cloud-Native Neural Search Pipelines,https://www.reddit.com/r/MachineLearning/comments/dle9ak/p_gnes_flow_a_pythonic_way_to_build_cloudnative/,h_xiao,1571728079,,0,1,False,default,,,,,
1302,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,16,dleda5,self.MachineLearning,[D] What is the current state-of-art in unsupervised document/information retrieval for NLP tasks?,https://www.reddit.com/r/MachineLearning/comments/dleda5/d_what_is_the_current_stateofart_in_unsupervised/,Slowai,1571728779,"Hello everybody,

Are there any good unsupervised methods of retrieving top-k documents from corpus based on a rather short query?

I did a bit of googling but couldn't find anything that isn't tf-idf based. 

Maybe it would be possible to somehow retrieve similarities between docs and query by utilising contextual embeddings (such as from BERT) and use some sort of scoring function to evaluate it.

&amp;#x200B;

Anyway, thank you in advance for your answers.",34,82,False,self,,,,,
1303,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,16,dleedr,blog.valohai.com,How Netflix is building their Machine Learning infrastructure  an interview with Ville Tuulos,https://www.reddit.com/r/MachineLearning/comments/dleedr/how_netflix_is_building_their_machine_learning/,freducom,1571728985,,0,3,False,default,,,,,
1304,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,16,dleetp,self.MachineLearning,Need suggestions for biomedical datasets similar to wisconsin breast cancer database,https://www.reddit.com/r/MachineLearning/comments/dleetp/need_suggestions_for_biomedical_datasets_similar/,daffodils123,1571729055,[removed],0,1,False,self,,,,,
1305,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,16,dleoje,arxiv.org,[R] Language Models as Knowledge Bases?,https://www.reddit.com/r/MachineLearning/comments/dleoje/r_language_models_as_knowledge_bases/,milaworld,1571730899,,2,4,False,default,,,,,
1306,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,17,dlesk9,/r/MachineLearning/comments/dlesk9/ways_to_improve_industrial_safety_through_vision/,Ways to improve Industrial Safety through Vision Analytics,https://www.reddit.com/r/MachineLearning/comments/dlesk9/ways_to_improve_industrial_safety_through_vision/,optisol,1571731703,,0,1,False,https://b.thumbs.redditmedia.com/_AalicPQg_wGOV8qbzHEfTl3_Y2B8VWN_q3FsWG3LvQ.jpg,,,,,
1307,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,17,dletgm,self.MachineLearning,Applying Deep Learning to AML and KYC processes,https://www.reddit.com/r/MachineLearning/comments/dletgm/applying_deep_learning_to_aml_and_kyc_processes/,manneshiva,1571731907,[removed],0,1,False,self,,,,,
1308,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,17,dleu1y,self.MachineLearning,"[D] What not-yet-existing tool do you wish you had, in your ML workflow?",https://www.reddit.com/r/MachineLearning/comments/dleu1y/d_what_notyetexisting_tool_do_you_wish_you_had_in/,Rumblysheep,1571732024,"Inspired by [this post](https://www.reddit.com/r/MachineLearning/comments/bx3pfe/d_when_asked_what_notyetexisting_tool_they_wish/). I am curious, what tool would you choose and why? :D",28,20,False,self,,,,,
1309,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,17,dlex23,self.MachineLearning,[D] Looking for suggestions for biomedical datasets similar to the Wisconsin Breast cancer database,https://www.reddit.com/r/MachineLearning/comments/dlex23/d_looking_for_suggestions_for_biomedical_datasets/,daffodils123,1571732673,"I am looking for biomedical databases similar to the Wisconsin breast cancer database (available at [https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)](https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)) ). This database has 9 features (each feature values being integers ranging from 1 to 10) and two classes  benign and malignant. Defining characteristic of this dataset is that the higher feature values generally indicate higher chance of abnormality (malignancy). I am looking for other biomedical datasets having features with this property (not necessarily integer valued, can also be real valued; preferably with low number of features also - less than 30 or so)",3,3,False,self,,,,,
1310,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,17,dleyc4,blog.valohai.com,An interview with Uber's Michelangelo ex-team lead: How Uber builds their ML Infrastructure,https://www.reddit.com/r/MachineLearning/comments/dleyc4/an_interview_with_ubers_michelangelo_exteam_lead/,freducom,1571732964,,0,2,False,default,,,,,
1311,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,17,dlezyk,self.MachineLearning,automate automation,https://www.reddit.com/r/MachineLearning/comments/dlezyk/automate_automation/,liormessinger,1571733305,[removed],0,1,False,self,,,,,
1312,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,17,dlf14r,self.MachineLearning,Master of AI and DL at Acala University in Spain,https://www.reddit.com/r/MachineLearning/comments/dlf14r/master_of_ai_and_dl_at_acala_university_in_spain/,Akarapat82,1571733562,"Anyone heard of it?  What do you think?

https://master-artificialintelligence.com/",0,1,False,self,,,,,
1313,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,18,dlfh2i,self.MachineLearning,Deepsort in tensorflow 2,https://www.reddit.com/r/MachineLearning/comments/dlfh2i/deepsort_in_tensorflow_2/,soggez,1571736734,[removed],0,1,False,self,,,,,
1314,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,18,dlfl8d,self.MachineLearning,How to extract the different sections of a pdf document using image processing?,https://www.reddit.com/r/MachineLearning/comments/dlfl8d/how_to_extract_the_different_sections_of_a_pdf/,Chiplusplus,1571737572,[removed],1,1,False,self,,,,,
1315,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,19,dlfzpg,medium.com,Business Benefits of Using Python for AI Projects,https://www.reddit.com/r/MachineLearning/comments/dlfzpg/business_benefits_of_using_python_for_ai_projects/,rishigarg961,1571740227,,0,1,False,https://b.thumbs.redditmedia.com/BIhHrx2PlJ0QlFOE89esjmkiYsfE_oKNINnHikrnJTg.jpg,,,,,
1316,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,19,dlg2jk,self.MachineLearning,Which would be the best algorithm (machine learning) in this case?,https://www.reddit.com/r/MachineLearning/comments/dlg2jk/which_would_be_the_best_algorithm_machine/,Ivannovix,1571740744,[removed],0,1,False,self,,,,,
1317,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,19,dlg33o,self.MachineLearning,why classification accuracy may not be a good measure for classification problems with imbalanced data?Which evaluation measures are better suited for dealing with skewed class sizes?,https://www.reddit.com/r/MachineLearning/comments/dlg33o/why_classification_accuracy_may_not_be_a_good/,ihavefewq,1571740839,[removed],0,1,False,self,,,,,
1318,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,20,dlgfn1,i.redd.it,Personalize the customer experience with our chatbot development service,https://www.reddit.com/r/MachineLearning/comments/dlgfn1/personalize_the_customer_experience_with_our/,freyariki,1571742959,,0,1,False,https://b.thumbs.redditmedia.com/6eeCcPIhri-ZmddcKx_n2_VLujgKboOmgymgQ4v0ZdE.jpg,,,,,
1319,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,20,dlgk2d,2basetechnologies.com,Personalize the customer experience with our chatbot development service,https://www.reddit.com/r/MachineLearning/comments/dlgk2d/personalize_the_customer_experience_with_our/,freyariki,1571743688,,0,1,False,https://b.thumbs.redditmedia.com/46taLcndjh2a97nphH1gGSGdBn_h_o3dQ0LX6UtiQ6g.jpg,,,,,
1320,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,20,dlglqf,rishabhsoft.com,Machine Learning Based Real-Time Health Monitoring System,https://www.reddit.com/r/MachineLearning/comments/dlglqf/machine_learning_based_realtime_health_monitoring/,RyanWilliamson1,1571743956,,0,1,False,default,,,,,
1321,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,20,dlgrgp,softcrylic.com,Data Anomaly Detection for Ad Campaigns using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/dlgrgp/data_anomaly_detection_for_ad_campaigns_using/,anderwhagel,1571744877,,0,1,False,default,,,,,
1322,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,21,dlh8ke,self.MachineLearning,Are small transformer models better than small LSTMs?,https://www.reddit.com/r/MachineLearning/comments/dlh8ke/are_small_transformer_models_better_than_small/,djridu,1571747429,[removed],0,1,False,self,,,,,
1323,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,21,dlhcub,self.MachineLearning,[D] Are small transformers better than small LSTMs?,https://www.reddit.com/r/MachineLearning/comments/dlhcub/d_are_small_transformers_better_than_small_lstms/,djridu,1571748040,"Transformers are currently beating the state of the art on different NLP tasks.

Some examples are:

* Machine translation: Transformer Big + BT
* Named entity recognition: BERT large
* Natural language inference: RoBERTa

Something I noticed is that in all of the papers, the models are massive with maybe 20 layers and 100s of millions of parameters.

Of course, using larger models is a general trend in NLP but it begs the question if small transformers are any good. I recently had to train a sequence to sequence model from scratch and I was unable to get better results with a transformer than with LSTMs.

I am wondering if someone here has had similar experiences or knows of any papers on this topic.",43,126,False,self,,,,,
1324,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,21,dlhjca,self.MachineLearning,"[D] ML Inference optimization, runtimes, compilers",https://www.reddit.com/r/MachineLearning/comments/dlhjca/d_ml_inference_optimization_runtimes_compilers/,dilledalle,1571748927,"I'm doing a study on inference latency. What are different ways of optimizing your model for this? Let's say the goal is to get your inference latency as low as possible. I've heard of ONNX runtime (apparently used by Microsoft in production), compilers such as Intel nGraph, TVM, Intel OpenVINO and so on. Are these kind of tools used in production, or do most companies just use PyTorch and TF inference mode? If anyone here has experience from unique deployments I'd love to hear about it!",5,5,False,self,,,,,
1325,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,22,dlhmxy,self.MachineLearning,Pytorch on Android : Image Classification Tutorial,https://www.reddit.com/r/MachineLearning/comments/dlhmxy/pytorch_on_android_image_classification_tutorial/,johnolafenwa,1571749411,[removed],0,1,False,self,,,,,
1326,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,22,dlhoom,self.MachineLearning,Announcing NeurIPS meetups,https://www.reddit.com/r/MachineLearning/comments/dlhoom/announcing_neurips_meetups/,Nicolas_LeRoux,1571749641,[removed],0,1,False,self,,,,,
1327,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,22,dli0p8,nathanbenaich.com,"3 business personas in ML: their common challenges, technology stacks, talent requirements and organisational structure",https://www.reddit.com/r/MachineLearning/comments/dli0p8/3_business_personas_in_ml_their_common_challenges/,nb410,1571751280,,0,1,False,default,,,,,
1328,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,22,dli9pn,self.MachineLearning,How to meet Sam Altman at his own home in SF!! On Wed Nov 13 12-2pm,https://www.reddit.com/r/MachineLearning/comments/dli9pn/how_to_meet_sam_altman_at_his_own_home_in_sf_on/,TeslaMecca,1571752478,"Altman is holding a fundraiser for Presidential candidate Andrew Yang on Wed November 13, 2019 12-2pm at his house.

It's not cheap though at $2k a pop. But might be worth it if you need to reach out!!

Buy ticket here ($2K): [https://secure.actblue.com/donate/ay-events-sf-lunch-1113?refcode=kurzon&amp;refcode2=kn](https://secure.actblue.com/donate/ay-events-sf-lunch-1113?refcode=kurzon&amp;refcode2=kn)

Where: Mission Bay area",0,1,False,self,,,,,
1329,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,23,dlihi7,self.MachineLearning,Which is best Django or flask to add Machine learning into your app.,https://www.reddit.com/r/MachineLearning/comments/dlihi7/which_is_best_django_or_flask_to_add_machine/,Monk_tan,1571753510,[removed],0,1,False,self,,,,,
1330,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,23,dlimmr,self.MachineLearning,What's the SOTA for time series prediction?,https://www.reddit.com/r/MachineLearning/comments/dlimmr/whats_the_sota_for_time_series_prediction/,misticfed,1571754175," Hi, I know this is a very trite subject. But I'm working on predicting cryptocurrency movement, and it's hard for me to distinguish between serious ML papers and random crap.

Could you point me in the direction of the SOTA kind of models I should be focusing on? Is it still LSTM? Should i be looking into GANs?

Thanks.",0,1,False,self,,,,,
1331,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,23,dlin1g,self.MachineLearning,Best Processor? 3800x/3700x/i7 7700k,https://www.reddit.com/r/MachineLearning/comments/dlin1g/best_processor_3800x3700xi7_7700k/,sweettartcart,1571754228,[removed],0,1,False,self,,,,,
1332,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,23,dliq3f,self.MachineLearning,[D] Best of AI News of September,https://www.reddit.com/r/MachineLearning/comments/dliq3f/d_best_of_ai_news_of_september/,kouskastook,1571754621,"Hi, [there](https://www.sicara.ai/blog/2019-10-21-best-of-ai-september-2019) are 10 news/reflexions which showed up on September I summed up them, as a recap. Did I forgot an important one ? What are the most important for you in October ?

There is the list :

* Documentary aired on how AI was seen in 1960
* Tensorflow 2.0 released, patch note
* Reflexion on how to make technology work WITH society ?
* MIT is helping doctors detecting patient pains
* Launch of the Facebook &amp; Microsoft Deepfake challenge
* How US government overcomes European GDPR law
* Google finned for targeting children
* Report published on the world wide expansion of AI
* Google published a new Multilingual Speech Recognition model
* Report on the pollution associated to artificial intelligence

[https://www.sicara.ai/blog/2019-10-21-best-of-ai-september-2019](https://www.sicara.ai/blog/2019-10-21-best-of-ai-september-2019)",6,14,False,self,,,,,
1333,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,23,dliqvt,skyl.ai,AI in Healthcare: How to Implement Medical Imaging Using Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/dliqvt/ai_in_healthcare_how_to_implement_medical_imaging/,Sophia77Wright,1571754731,,0,1,True,nsfw,,,,,
1334,MachineLearning,t5_2r3gv,2019-10-22,2019,10,22,23,dlizgy,self.MachineLearning,"TVEyes transcribing 13,000 podcasts... should I be impressed? [News]",https://www.reddit.com/r/MachineLearning/comments/dlizgy/tveyes_transcribing_13000_podcasts_should_i_be/,TrueBirch,1571755824,"The company TVEyes says it is now transcribing 1,500 hours of podcasts every day ([press release](https://www.prnewswire.com/news-releases/tveyes-launches-first-podcast-monitoring-service-with-search-and-alert-capabilities-300941476.html)). TVEyes clients receive alerts when they are mentioned in one of the 13,000 most popular podcasts.

I've never worked with audio, so I'm curious how impressive it is to be able to process 62.5 hours of spoken audio per hour. Is this something that could be done with an off-the-shelf algorithm and a $5,000 server, or are we talking about PhD-level expertise and massive computing power?",15,31,False,self,,,,,
1335,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,0,dlj7qa,self.MachineLearning,3800x vs 9700k,https://www.reddit.com/r/MachineLearning/comments/dlj7qa/3800x_vs_9700k/,sweettartcart,1571756828,I'm stuck between the Intel 9700k and AMD 3800x. Which would you recommend?,0,1,False,self,,,,,
1336,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,0,dljj0n,self.MachineLearning,[P] Art Valuation Bot,https://www.reddit.com/r/MachineLearning/comments/dljj0n/p_art_valuation_bot/,amourav,1571758226,"I need to develop a small project for a data science bootcamp interview next week ([insightdatascience.com](https://insightdatascience.com)). 

One idea I had was to create an art valuation bot and art generation bot. The outline would look something like this:

1. Scrape abstract art data (image and price data) from an art sales website.
2. Use a pretrained network and fine-tune it on my dataset for price regression.
3. Greate a GAN on the same dataset, then uses it to generate novel art images.
4. Evaluate GAN with the price regression model to determine the newly generated pieces with the highest predicted value.

Some potential challenges I see:

1. Image size: Resizing the dataset to have a standard resolution will really affect the appearance of the newly generated images. Can I do without this? Perhaps I will resize while maintaining the original aspect ratio.
2. Noise: Given that I don't have access to an art valuation dataset and am just trying to train based on an art sales website, the price does not necessarily indicate that the art piece is valuable. Hopefully, there is enough signal in the dataset to offset this effect.

Does anyone have thoughts on project-based data science boot camps like Insight Data Science ([https://www.insightdatascience.com/](https://www.insightdatascience.com/) )

If you see any more potential issues with my project outline, or have a suggestion for improving it, please leave a comment or PM :)",13,4,False,self,,,,,
1337,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,0,dljozp,medium.com,Can I use Deep Learning for that? A type theoretic heuristic,https://www.reddit.com/r/MachineLearning/comments/dljozp/can_i_use_deep_learning_for_that_a_type_theoretic/,formalsystem,1571758925,,0,1,False,https://b.thumbs.redditmedia.com/h7Dyw3W4-tTNrEmOvSFznE6cNfwhdSf64LMsaITTe_s.jpg,,,,,
1338,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,1,dlkb6n,self.MachineLearning,[D] OpenAI's dexterous robotic hand  separating progress from PR,https://www.reddit.com/r/MachineLearning/comments/dlkb6n/d_openais_dexterous_robotic_hand_separating/,regalalgorithm,1571761495,"I guess I'll mark this is a discussion, in case any one is not tired of this topic, our (I would say fairly objective and comprehensive) summary of it:

[https://www.skynettoday.com/briefs/openai-rubiks-cube](https://www.skynettoday.com/briefs/openai-rubiks-cube)

Would welcome feedback! The hope is that people without much knowledge of AI (but enough interest to read an article of this length) could stumble upon it and gain some clarity about the significance of OpenAI's latest research.",9,7,False,self,,,,,
1339,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,2,dllmlb,medium.com,Harvard &amp; Google Seismic Paper Hit With Rebuttals: Is Deep Learning Suited to Aftershock Prediction?,https://www.reddit.com/r/MachineLearning/comments/dllmlb/harvard_google_seismic_paper_hit_with_rebuttals/,Yuqing7,1571766968,,0,1,False,https://b.thumbs.redditmedia.com/GpJzTLvDfXhm7iySBmlmDrPKk1hW-YHxaM6i_oJvp-Y.jpg,,,,,
1340,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,3,dllv6z,genial-code.com,User System Python,https://www.reddit.com/r/MachineLearning/comments/dllv6z/user_system_python/,RAS05,1571767939,,0,1,False,default,,,,,
1341,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,3,dlly39,self.MachineLearning,End to End normalization for deep learning of multivariate non stationary time series,https://www.reddit.com/r/MachineLearning/comments/dlly39/end_to_end_normalization_for_deep_learning_of/,brokenAlgorithm,1571768267,"Has anyone had any experience with this? I have a rather wide feature set in my time series data, many features with vastly different scales. I'm attempting to batch-train an LSTM autoencoder. So far, I have come to the following conclusions:

* I'm reluctant to use first differences as I don't want to destroy level information.
* I don't want to z-score normalize data before training as many components are non-stationary
* I don't want to use sliding min-max or sliding z-score as that destroys any volatility information between subsequent minibatches

&amp;#x200B;

So far, the following thoughts have come to mind:

* Using layer normalization, yielding equal normalization statistics for all features accross my minibatch. Destroys however information between individual features in a given sample
* Manual z-score operations inside my network. Take the resulting statistics, pass through linear layer to adapt dimensionality and initialize the LSTM hidden layer. So far, doesn't really work.
* This approach seems promising:
   * [https://arxiv.org/pdf/1902.07892.pdf](https://arxiv.org/pdf/1902.07892.pdf)
* ... but somehow, it doesn't yield good results either. Seems very learning rate dependent which is a bit of a bummer.

Any thoughts or successful ideas?",0,1,False,self,,,,,
1342,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,3,dlmg7g,self.MachineLearning,What material do you feel should be covered in a first NLP course taught at a PhD level?,https://www.reddit.com/r/MachineLearning/comments/dlmg7g/what_material_do_you_feel_should_be_covered_in_a/,rocksoffjagger,1571770308,[removed],0,1,False,self,,,,,
1343,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,3,dlmkgg,self.MachineLearning,[D] RNN/CNN architectures for time series and considering the stochastic process modelling the residuals,https://www.reddit.com/r/MachineLearning/comments/dlmkgg/d_rnncnn_architectures_for_time_series_and/,joergengogogo,1571770786,"For a small project I have been looking at applying primarily RNN architectures to a multivariate time series problem. However, research that provides reasonable assumptions on how to model the time series in terms of the residual and a neural network seems to be hard to find. Although for long term simulation of scenarios this seems to be a core aspect of analyzing time series, considering classical time series research.

I would be very grateful for pointing out good papers concerning neutral nets in time series or would like to talk about what kind of stochastic model people having experience chose and why. As a starting point I suggest RNN architectures can fit the trend, seasonality and an ARMA(p,q) model. However modelling time dependent variance and extremal values seems to be a rather hard task for neural nets.

Sorry for not having great academic english and looking forward to your answers!",2,3,False,self,,,,,
1344,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,4,dlmklp,self.MachineLearning,[D] End-to-end normalization for deep learning of time series?,https://www.reddit.com/r/MachineLearning/comments/dlmklp/d_endtoend_normalization_for_deep_learning_of/,brokenAlgorithm,1571770802,"Has anyone had any experience with this? I have a rather wide feature set in my time series data, many features with vastly different scales. I'm attempting to batch-train an LSTM autoencoder. So far, I have come to the following conclusions:

* I'm reluctant to use first differences as I don't want to destroy level information.
* I don't want to z-score normalize data before training as many components are non-stationary
* I don't want to use sliding min-max or sliding z-score as that destroys any volatility information between subsequent minibatches

&amp;#x200B;

So far, the following thoughts have come to mind:

* Using layer normalization, yielding equal normalization statistics for all features accross my minibatch. Destroys however information between individual features in a given sample
* Manual z-score operations inside my network. Take the resulting statistics, pass through linear layer to adapt dimensionality and initialize the LSTM hidden layer. So far, doesn't really work. But a variant of this (perhaps concatenating to the lstm output...?) seems to be my current focus.
* This approach seems promising:
   * [https://arxiv.org/pdf/1902.07892.pdf](https://arxiv.org/pdf/1902.07892.pdf)
* ... but somehow, it doesn't yield good results either. Seems very learning rate dependent which is a bit of a bummer.

Any thoughts or successful ideas?",9,4,False,self,,,,,
1345,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,5,dlnika,self.MachineLearning,How much do Sparse Activations help a Neural Network?,https://www.reddit.com/r/MachineLearning/comments/dlnika/how_much_do_sparse_activations_help_a_neural/,Andy_Reds,1571774577,[removed],0,1,False,self,,,,,
1346,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,5,dlnzzp,self.MachineLearning,"Dataset to train a cnn with ""gore"" images.",https://www.reddit.com/r/MachineLearning/comments/dlnzzp/dataset_to_train_a_cnn_with_gore_images/,poop_st4r,1571776466,"I'm looking for a big dataset which contains a big amount of ""gore"" images (death people and that kind of stuff) to train a cnn. I'm making a website where the user can upload different content but It won't be allowed to post this kind of content. Until now I was making webscrapping to websites that has this kind of content to collect this data but I was thinking if there is a dataset for this purpose which can help me to save time. Or does anyone know a way to block this kind of content without using images?",0,1,False,self,,,,,
1347,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,5,dlo2gl,self.MachineLearning,Rigorous online course on machine learning,https://www.reddit.com/r/MachineLearning/comments/dlo2gl/rigorous_online_course_on_machine_learning/,stoein4556,1571776731,"I recently graduated with a masters degree in economics. I have a fair bit of background about linear regression, logit, probit models, thanks to my econometrics courses. I am inclined towards machine learning and have gone through Andrew NG's course and I know basics about ML algorithms. I would want to know from you guys if there is a more rigorous course, more math intensive course to learn machine learning? I would be open to long term executive programmes as well. 

Appreciate any recommendations. Thanks.",0,1,False,self,,,,,
1348,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,5,dlo4d8,self.MachineLearning,[D] Best ML techniques over Temporal Data ?,https://www.reddit.com/r/MachineLearning/comments/dlo4d8/d_best_ml_techniques_over_temporal_data/,iholierthanthou,1571776948,"I have a medical data set of patients ( about 50k)  and each patient has around 20 - 30 records of their vitals for each hour. The Target variable is a binary variable which is 1 if the Patient contracted the Illness or 0 otherwise , so for many patients they first few row's are 0 are and then it switches to 1 (signifying that the patient caught the illness at that point of time ).

Till now i have been treating this data as non-temporal and considering each row to be a unique record , which has been working pretty well but i would rather treat the data as temporal , any suggestions on what techniques i can use?

Also i am currently using Autoencoders to reduce the dimentionality of the data and running a CNN over the reduced data.

Thanks in advance !",24,28,False,self,,,,,
1349,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,6,dloody,self.MachineLearning,[P] A BertSum (Bert extractive summarizer) model trained on research papers. Access to datasets also included.,https://www.reddit.com/r/MachineLearning/comments/dloody/p_a_bertsum_bert_extractive_summarizer_model/,BatmantoshReturns,1571779191,"A few months ago, I released several a dataset from ~7 million papers for ~12 million datapoints. I think the most exciting part were the datasets designed by a similar methodology of Alexios Gidiotis, Grigorios Tsoumakas [https://arxiv.org/abs/1905.07695] who discovered that there are many papers with structured abstractions, whose sections correspond to entire sections within the papers. 

Having a dataset of these abstract sections and full paper sections is probably the best dataset available for research paper summarization, as far as I know. 

Using some of the text processing methods in Gidiotis, Tsoumakas, and using Semantic Scholar's Science Parse, I was able to create a dataset from Arxiv and the Semantic Scholar Corpus. 

I have now released a model using a slightly modified version of the BertSum repo [ https://github.com/nlpyang/BertSum https://arxiv.org/abs/1903.10318 ]. The model was trained on a batch size of 1024 for 5000 steps, and then a batch size of 4096 for 25000 steps.

The datasets and model are all available here. 

https://github.com/Santosh-Gupta/ScientificSummarizationDataSets

I also included text processing and training setups for Pointer-Generator and the Tensor2Tensor transformers abstractive summarizers. At the time they were the best for abstractive summarization, but for the purposes of my future project, I needed the most accurate summarizer, which needed an extractive method.",19,161,False,self,,,,,
1350,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,7,dlpfoo,thenextweb.com,Why a robot that can 'solve' Rubik's Cube one-handed has the AI community at war,https://www.reddit.com/r/MachineLearning/comments/dlpfoo/why_a_robot_that_can_solve_rubiks_cube_onehanded/,14392,1571782289,,0,1,False,https://b.thumbs.redditmedia.com/LUGam0nu6_kOHNz7Xgixfqpnq4vtp96QwYpMXEA3LWM.jpg,,,,,
1351,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,7,dlpv94,producthunt.com,Seems like this app uses generative adversarial networks. It makes the faces look super real.,https://www.reddit.com/r/MachineLearning/comments/dlpv94/seems_like_this_app_uses_generative_adversarial/,nextart-io,1571784105,,0,1,False,https://b.thumbs.redditmedia.com/a63vEqgbo3MaVlqc2db8KrPZGC-4kTklUGg1vA_C-_M.jpg,,,,,
1352,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,8,dlqm92,self.MachineLearning,[Serious] Challenge: Find one Siraj Raval video that contains no plagiarism,https://www.reddit.com/r/MachineLearning/comments/dlqm92/serious_challenge_find_one_siraj_raval_video_that/,synysterbates,1571787383,[removed],0,1,False,self,,,,,
1353,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,8,dlqrht,self.learnmachinelearning,Image classification capability question - ukiyo-e print art,https://www.reddit.com/r/MachineLearning/comments/dlqrht/image_classification_capability_question_ukiyoe/,budha3,1571788057,,0,1,False,default,,,,,
1354,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,9,dlr1ye,self.MachineLearning,Isolate Discriminator in a GAN,https://www.reddit.com/r/MachineLearning/comments/dlr1ye/isolate_discriminator_in_a_gan/,chrico031,1571789415,[removed],0,1,False,self,,,,,
1355,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,11,dlspqg,self.MachineLearning,"cross validation experiments on IRIS dataset with various, uni-modal Gaussian classifiers and SVM.",https://www.reddit.com/r/MachineLearning/comments/dlspqg/cross_validation_experiments_on_iris_dataset_with/,shahzadiqbal5,1571797215,[removed],0,1,False,self,,,,,
1356,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,12,dltghy,self.MachineLearning,"Spatio-temporal modeling, scalar input",https://www.reddit.com/r/MachineLearning/comments/dltghy/spatiotemporal_modeling_scalar_input/,donjuan1337,1571801163,[removed],0,1,False,self,,,,,
1357,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,12,dltkrj,self.MachineLearning,"[R] Spatio-temporal modeling, scalar input",https://www.reddit.com/r/MachineLearning/comments/dltkrj/r_spatiotemporal_modeling_scalar_input/,donjuan1337,1571801810,"I'm doing video prediction research i.e. predicting the next frame in a video sequence. In essential it's just a mapping from the past frame into the future frame. I wonder how I can incorporate a scalar input in addition to the input frame.

Since I'm just using CNN operations and never making any flattening of the feature maps, I cannot concatenate the scalar input directly. I have found [this](https://stats.stackexchange.com/questions/299322/combining-image-and-scalar-inputs-into-a-neural-network) which suggest that one could treat the bias as the scalar input of some CNN layer but doing so you are not directly adding any parameters to the scalar input.

Does anyone have any experience with this? All info, papers etc are appreciated!",0,1,False,self,,,,,
1358,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,12,dltoj8,self.MachineLearning,"[D] Spatio-temporal modeling, scalar input",https://www.reddit.com/r/MachineLearning/comments/dltoj8/d_spatiotemporal_modeling_scalar_input/,donjuan1337,1571802411,"I'm doing video prediction research i.e. predicting the next frame in a video sequence. In essential it's just a mapping from the past frame into the future frame. I wonder how I can incorporate a scalar input in addition to the input frame.

Since I'm just using CNN operations and never making any flattening of the feature maps, I cannot concatenate the scalar input directly. I have found [this](https://stats.stackexchange.com/questions/299322/combining-image-and-scalar-inputs-into-a-neural-network) which suggest that one could treat the bias as the scalar input of some CNN layer but doing so you are not directly adding any parameters to the scalar input.

Does anyone have any experience with this? All info, papers etc are appreciated!",4,3,False,self,,,,,
1359,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,13,dltuz4,self.MachineLearning,Can CTC loss be used as an indicator of Goodness of Pronunciation?,https://www.reddit.com/r/MachineLearning/comments/dltuz4/can_ctc_loss_be_used_as_an_indicator_of_goodness/,cocoon_zz,1571803436,[removed],0,1,False,self,,,,,
1360,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,13,dlu1wm,self.MachineLearning,[D] Tools/Techniques for Efficiently Sorting Image Data,https://www.reddit.com/r/MachineLearning/comments/dlu1wm/d_toolstechniques_for_efficiently_sorting_image/,redditferdays,1571804584,"I'm planning on sorting \~100,000 images to use as data for a computer vision application. With this much data, shaving a little time off of each picture would add up quickly. I was wondering whether there are any tools or techniques to make this as quick and easy as possible. 

For my specific task I'm simply looking to go through an entire folder of images and discard those that aren't 'good pictures', no complicated sorting required.

Thanks in advance, and sorry if this is the wrong tag.",5,1,False,self,,,,,
1361,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,14,dluizh,self.MachineLearning,Need advice on taking a math class next semester,https://www.reddit.com/r/MachineLearning/comments/dluizh/need_advice_on_taking_a_math_class_next_semester/,xxcoolmanderxx,1571807516,"Hey all,   
I am a highschooler  and I have 2 options for math classes that I am considering next semester. I am trying to choose between linear algebra and Multi variable calculus. I also want to get into learning machine learning. Which one would you suggest is the better option?",0,1,False,self,,,,,
1362,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,16,dlvrap,shehds.com,Fog 400W 900W Machine,https://www.reddit.com/r/MachineLearning/comments/dlvrap/fog_400w_900w_machine/,Shehds,1571815640,,0,1,False,default,,,,,
1363,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,17,dlw60b,crweworld.com,[D] European Government Organizations Are Enthusiastic About Artificial Intelligence but Face Challenges Adopting It,https://www.reddit.com/r/MachineLearning/comments/dlw60b/d_european_government_organizations_are/,HotMomentumStocks,1571818621,,0,1,False,default,,,,,
1364,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,17,dlw6ac,arxiv.org,[R] Teacher algorithms for curriculum learning of Deep RL in continuously parameterized environments (CoRL 2019),https://www.reddit.com/r/MachineLearning/comments/dlw6ac/r_teacher_algorithms_for_curriculum_learning_of/,hardmaru,1571818686,,2,42,False,default,,,,,
1365,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,17,dlwh17,ai.googleblog.com,Quantum Supremacy Using a Programmable Superconducting Processor,https://www.reddit.com/r/MachineLearning/comments/dlwh17/quantum_supremacy_using_a_programmable/,doireallyneedone11,1571820891,,0,1,False,https://b.thumbs.redditmedia.com/lwGwGLejM_y37yskZMKtTraMMB4R9cn7yX2nn0vNTsQ.jpg,,,,,
1366,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,18,dlx0ao,self.MachineLearning,Datasets for mental health,https://www.reddit.com/r/MachineLearning/comments/dlx0ao/datasets_for_mental_health/,Bishwash08,1571824585,[removed],0,1,False,self,,,,,
1367,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,19,dlx3cq,self.MachineLearning,Which Valve To Use For Adjust / Control Gas Flow ?,https://www.reddit.com/r/MachineLearning/comments/dlx3cq/which_valve_to_use_for_adjust_control_gas_flow/,uflowindia,1571825136,[removed],0,1,False,https://b.thumbs.redditmedia.com/imy8mBKxsXAIbJAPTxcSn3VjIsUbY6JeZEWkHaah6rc.jpg,,,,,
1368,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,19,dlxd2t,self.MachineLearning,[D] Feature Loss vs. GANs - what are the trade offs?,https://www.reddit.com/r/MachineLearning/comments/dlxd2t/d_feature_loss_vs_gans_what_are_the_trade_offs/,The_Amp_Walrus,1571826870,"I'm doing a bit of reading on the speech enhancement problem, where you have an audio signal containing human speech plus some noise, and you want extract just the human speech. It's pretty analogous to image denoising or ""super-resolution"", and a lot of the techniques from the image domain are being borrowed and re-applied to audio quite successfully (eg. repurposing the [U-Net](https://arxiv.org/abs/1505.04597) architecture from image processing to [spectrograms](https://ismir2017.smcnus.org/wp-content/uploads/2017/10/171_Paper.pdf) and then [raw audio](https://arxiv.org/pdf/1806.03185.pdf)). It's all pretty cool.

There's some interesting work being done with loss functions this space and I'm looking for some clarification as to why you'd choose one approach over another. You want to compare a target image, or audio waveform, with a predicted sample, and you need to define a loss function which measures how ""close"" they are. The *Related work* section of [this paper](https://arxiv.org/pdf/1609.04802.pdf) gives a pretty good overview of the different approaches, which I'll try to summarize here.  

* **Mean squared error loss**: A pretty standard regression loss as far as I know, but it's limited to only considering one pixel at a time: ""the ability of MSE to capture perceptually relevant differences, such as high texture detail, is very limited"".
* **Feature loss**: This is where you pre-train a network on a similar problem, such as image classification, and then you freeze the weights. For both the target and predicted sample, you run each through the classification network, then grab some internal activations from that network and call them ""features"". You compute some distance between these feature vectors to get your loss. The key idea is that the classification network is able to capture important features that MSE loss cannot. 
* **GAN loss**: A discriminator network trains in-tandem with the generator network, where the job of the discriminator is to classify whether its input is ""real"" or ""generated"". Like the feature loss network, it can detect features that MSE loss cannot, but it can also punish identifiable quirks of the generator network, whereas feature loss can potentially be ""hacked"" by the generator network.

So my questions are:

* Have I characterised these approaches well?
* Why would you ever choose feature loss over using a discriminator network (ie. GAN)?
   * Discriminators can punish the generator for being predictably wrong (ie. common artifacts)
   * Pre-trained feature loss networks may better represent image features, if they have been trained for longer, on larger data sets
   * Apparently GANs can have stability issues when training
* The [SRGAN](https://arxiv.org/pdf/1609.04802.pdf) suggests using both feature loss *and* a GAN for their loss function - is this the best known approach?",15,5,False,self,,,,,
1369,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,19,dlxjom,self.MachineLearning,"[D] Is it really entirely necessary to get a masters or PhD in machine learning, or can one realistically teach themselves this thru various online resources?",https://www.reddit.com/r/MachineLearning/comments/dlxjom/d_is_it_really_entirely_necessary_to_get_a/,TheWiseGrasshopper,1571828023,[removed],0,1,False,self,,,,,
1370,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,20,dlxmkh,self.MachineLearning,model to model knowledge transfer,https://www.reddit.com/r/MachineLearning/comments/dlxmkh/model_to_model_knowledge_transfer/,sathvik66,1571828491,[removed],0,1,False,self,,,,,
1371,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,20,dlxpsc,self.MachineLearning,Multi Label Classification problem for tagging and retrieval,https://www.reddit.com/r/MachineLearning/comments/dlxpsc/multi_label_classification_problem_for_tagging/,gombru,1571829000,[removed],0,1,False,self,,,,,
1372,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,20,dly2eb,self.MachineLearning,[D] What techniques or tricks do you use often in your work that are not considered mainstream or popular?,https://www.reddit.com/r/MachineLearning/comments/dly2eb/d_what_techniques_or_tricks_do_you_use_often_in/,nivter,1571831028,[removed],0,1,False,self,,,,,
1373,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,20,dly4w2,self.MachineLearning,What approach would you use for a grammar corrector?,https://www.reddit.com/r/MachineLearning/comments/dly4w2/what_approach_would_you_use_for_a_grammar/,manceraio,1571831396,[removed],0,1,False,self,,,,,
1374,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,20,dly539,self.MachineLearning,k-Winner-Take-All activation layers: potential and limitations?,https://www.reddit.com/r/MachineLearning/comments/dly539/kwinnertakeall_activation_layers_potential_and/,Simoncarbo,1571831429,[removed],0,1,False,self,,,,,
1375,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,21,dlye7x,self.MachineLearning,C++ Library for NN,https://www.reddit.com/r/MachineLearning/comments/dlye7x/c_library_for_nn/,denismaks,1571832756,[removed],0,1,False,self,,,,,
1376,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,21,dlyhex,self.MachineLearning,Deep Learning for automating KYC verification and aml compliances,https://www.reddit.com/r/MachineLearning/comments/dlyhex/deep_learning_for_automating_kyc_verification_and/,manneshiva,1571833218,[removed],0,0,False,self,,,,,
1377,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,21,dlyt9p,self.MachineLearning,clair: An AI blog with simplified reviews of papers and exciting AI articles,https://www.reddit.com/r/MachineLearning/comments/dlyt9p/clair_an_ai_blog_with_simplified_reviews_of/,MrKotia,1571834870,[removed],0,1,False,https://b.thumbs.redditmedia.com/9fEOf8yx5I_Bb29Gi1X1hLS9b_Hq1F40kcRmXZyrHko.jpg,,,,,
1378,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,21,dlyvnt,medium.com,Document processing: OCR Extraction Rates and When They Actually Matter,https://www.reddit.com/r/MachineLearning/comments/dlyvnt/document_processing_ocr_extraction_rates_and_when/,rufenmatt,1571835202,,0,1,False,https://b.thumbs.redditmedia.com/Afom-RPjBIOgWLUqKgDyvafdf3F_5lWybDwddTvDioU.jpg,,,,,
1379,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,21,dlyxub,self.MachineLearning,[R] clair: An AI blog with simplified reviews of papers and exciting AI articles,https://www.reddit.com/r/MachineLearning/comments/dlyxub/r_clair_an_ai_blog_with_simplified_reviews_of/,MrKotia,1571835507,[removed],0,1,False,https://b.thumbs.redditmedia.com/g2vwLrfep85Q9TUqK6heerL5qaXgW9VAA7mArIQjaKY.jpg,,,,,
1380,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,22,dlz0pw,self.MachineLearning,[D] Generative Tensorial Reinforcement Learning for medical applications [live session],https://www.reddit.com/r/MachineLearning/comments/dlz0pw/d_generative_tensorial_reinforcement_learning_for/,tdls_to,1571835871,we are hosting a live session with the authors of the recent [Nature paper](https://www.nature.com/articles/s41587-019-0224-x?) that used generative tensorial RL for medical applications at noon EST today; watch the live session (or the recording afterwards) here: [https://aisc.ai.science/events/2019-10-23](https://aisc.ai.science/events/2019-10-23),3,3,False,self,,,,,
1381,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,22,dlz4sn,self.MachineLearning,Graph Neural Networks,https://www.reddit.com/r/MachineLearning/comments/dlz4sn/graph_neural_networks/,MphoMotionless,1571836407,[removed],0,1,False,self,,,,,
1382,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,22,dlz6no,self.MachineLearning,"Using the twitter API with python: twitter-python or tweepy, which one would you recommend?",https://www.reddit.com/r/MachineLearning/comments/dlz6no/using_the_twitter_api_with_python_twitterpython/,ReasonablyBadass,1571836670,[removed],0,1,False,self,,,,,
1383,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,22,dlzh07,self.MachineLearning,[R] Microsoft Research Face Swapping/deepfake + Hair (CVPR 2019),https://www.reddit.com/r/MachineLearning/comments/dlzh07/r_microsoft_research_face_swappingdeepfake_hair/,PuzzledProgrammer3,1571838044,"pdf: [http://openaccess.thecvf.com/content\_CVPR\_2019/papers/Gu\_Mask-Guided\_Portrait\_Editing\_With\_Conditional\_GANs\_CVPR\_2019\_paper.pdf](http://openaccess.thecvf.com/content_CVPR_2019/papers/Gu_Mask-Guided_Portrait_Editing_With_Conditional_GANs_CVPR_2019_paper.pdf)

github repo: [https://github.com/cientgu/Mask\_Guided\_Portrait\_Editing](https://github.com/cientgu/Mask_Guided_Portrait_Editing)

&amp;#x200B;

https://i.redd.it/o895carvnau31.png",23,126,False,self,,,,,
1384,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,22,dlzi9c,self.MachineLearning,[R]Research Guide: Image Quality Assessment for Deep Learning,https://www.reddit.com/r/MachineLearning/comments/dlzi9c/rresearch_guide_image_quality_assessment_for_deep/,mwitiderrick,1571838204,"The quality of images is relevant in building compression and image enhancement algorithms. Image Quality Assessment (IQA) is divided into two main areas; reference-based evaluation and no-reference evaluation.

In this guide, well look at how deep learning has been used in image quality analysis.

[https://heartbeat.fritz.ai/research-guide-image-quality-assessment-c4fdf247bf89](https://heartbeat.fritz.ai/research-guide-image-quality-assessment-c4fdf247bf89)",0,2,False,self,,,,,
1385,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,22,dlzkq1,self.MachineLearning,"If you had a tool that gives you insight into your data, what would you want it to be?",https://www.reddit.com/r/MachineLearning/comments/dlzkq1/if_you_had_a_tool_that_gives_you_insight_into/,OptimisticCapitalist,1571838524,[removed],0,1,False,self,,,,,
1386,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,22,dlzo2h,self.MachineLearning,Google: Quantum Supremacy Using a Programmable Superconducting Processor,https://www.reddit.com/r/MachineLearning/comments/dlzo2h/google_quantum_supremacy_using_a_programmable/,braceletboy,1571838965,[removed],0,1,False,self,,,,,
1387,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,23,dlzsub,threader.app,Machine learning portfolio tips,https://www.reddit.com/r/MachineLearning/comments/dlzsub/machine_learning_portfolio_tips/,yesnoornext,1571839563,,0,1,False,default,,,,,
1388,MachineLearning,t5_2r3gv,2019-10-23,2019,10,23,23,dlzwus,self.MachineLearning,Custom computer builds in startup environment,https://www.reddit.com/r/MachineLearning/comments/dlzwus/custom_computer_builds_in_startup_environment/,brunocas,1571840060,[removed],0,1,False,self,,,,,
1389,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,0,dm0jmk,erlang-solutions.com,Machine learning in Elixir,https://www.reddit.com/r/MachineLearning/comments/dm0jmk/machine_learning_in_elixir/,erlangsolutions,1571842941,,2,1,False,default,,,,,
1390,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,0,dm0pec,self.MachineLearning,What to do after training a GAN?,https://www.reddit.com/r/MachineLearning/comments/dm0pec/what_to_do_after_training_a_gan/,Jmcginley182,1571843636,[removed],0,1,False,self,,,,,
1391,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,0,dm0q9y,deepmind.com,[N] Causal Bayesian Networks: A flexible tool to enable fairer machine learning,https://www.reddit.com/r/MachineLearning/comments/dm0q9y/n_causal_bayesian_networks_a_flexible_tool_to/,lnfinity,1571843743,,0,1,False,default,,,,,
1392,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,0,dm102v,self.computervision,Image copy&amp;paste using CNN,https://www.reddit.com/r/MachineLearning/comments/dm102v/image_copypaste_using_cnn/,AbdallahNasr5,1571844939,,0,1,False,default,,,,,
1393,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,0,dm18i1,self.MachineLearning,"Simple Questions Thread October 23, 2019",https://www.reddit.com/r/MachineLearning/comments/dm18i1/simple_questions_thread_october_23_2019/,AutoModerator,1571845954,[removed],0,1,False,self,,,,,
1394,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,1,dm1ire,self.MachineLearning,[D] Are there any examples of CNTK linear regression with more than 1 parameter? C# / .NET,https://www.reddit.com/r/MachineLearning/comments/dm1ire/d_are_there_any_examples_of_cntk_linear/,actopozipc,1571847142,"Is this even a thing when the formula for a linear function is only y=kx+d? If so, are there any other models in CNTK that are able to find variables in correlation with input values?    
I have like 2-3 input values and 1 output.",8,0,False,self,,,,,
1395,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,2,dm2k4x,self.MachineLearning,"[N] ImageNet found to have questionable content (nude kids, porn stars, etc)",https://www.reddit.com/r/MachineLearning/comments/dm2k4x/n_imagenet_found_to_have_questionable_content/,Mister_Abc,1571851580,"[https://www.theregister.co.uk/2019/10/23/top\_ai\_dataset\_imagenet/](https://www.theregister.co.uk/2019/10/23/top_ai_dataset_imagenet/)

&amp;#x200B;

The labels within are claimed to be biased and sometimes racist... TIL ImageNet has been unavailable for download since January because of this problem, I wonder if folks are working on a cleaner version of the dataset.",12,0,False,self,,,,,
1396,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,2,dm2zzo,self.MachineLearning,A noob's doubts.,https://www.reddit.com/r/MachineLearning/comments/dm2zzo/a_noobs_doubts/,ic3_fire,1571853443,[removed],0,1,False,self,,,,,
1397,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,3,dm36fh,self.MachineLearning,[P] Quantum optical neural networks,https://www.reddit.com/r/MachineLearning/comments/dm36fh/p_quantum_optical_neural_networks/,bencbartlett,1571854187,"Nanophotonic neural networks are an exciting emerging technology which promises low-energy, ultra high-throughput machine learning systems implemented purely optically. Our lab has [previously done work](https://www.reddit.com/r/MachineLearning/comments/b13yz6/p_neuroptica_a_nanophotonic_neural_network/) on these devices, and our new paper which extends programmable photonics to the quantum domain is now on arXiv! 

In this paper, we describe a photonic architecture for a quantum programmable gate array (QPGA) which can be dynamically reprogrammed to perform any quantum computation. We show how to exactly prepare arbitrary quantum states and operators on the device, and we apply machine learning techniques to automatically implement highly compact approximations to important quantum circuits.

[Here's a gif](https://gfycat.com/safedigitalabyssiniangroundhornbill) of a simulated QPGA being trained to implement a quantum Fourier transform on five qubits. Supplementary materials and the TensorFlow code for the quantum circuit optimization section of the paper can be found in the GitHub repository for the paper.

**Paper:** [arxiv.org/abs/1910.10141](https://arxiv.org/abs/1910.10141)

**GitHub repo:** [github.com/fancompute/qpga](https://github.com/fancompute/qpga)",18,254,False,self,,,,,
1398,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,3,dm3i8f,self.MachineLearning,[D] Published Machine Learning Papers that made poor assumptions/judgements,https://www.reddit.com/r/MachineLearning/comments/dm3i8f/d_published_machine_learning_papers_that_made/,TheSerialTaco,1571855597,I'm currently taking a Machine Learning class and need to create a critique of a published work. I was looking for some published papers in the field that weren't really based on a valid foundation and/or made poor decisions in designing their model. Any suggestions or links would be appreciated.,1,0,False,self,,,,,
1399,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,3,dm3m9d,self.MachineLearning,deriving the normal equation with regularization,https://www.reddit.com/r/MachineLearning/comments/dm3m9d/deriving_the_normal_equation_with_regularization/,paolok123,1571856055,"Can you help me solve this or send me a link where you saw someone solving them?

btw:  [http://web.mit.edu/zoya/www/linearRegression.pdf](http://web.mit.edu/zoya/www/linearRegression.pdf)  won't do it. I need to stick with something Andrew ng type/format",0,1,False,self,,,,,
1400,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,3,dm3oax,self.MachineLearning,I posted a while back about recreating the original GAN project. I finally got it working properly.,https://www.reddit.com/r/MachineLearning/comments/dm3oax/i_posted_a_while_back_about_recreating_the/,Fear_UnOwn,1571856287,[removed],0,1,False,self,,,,,
1401,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,3,dm3qws,self.MachineLearning,"7 Books About Machine Learning, Statistics, and Python",https://www.reddit.com/r/MachineLearning/comments/dm3qws/7_books_about_machine_learning_statistics_and/,andrea_manero,1571856585,[removed],0,1,False,self,,,,,
1402,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,4,dm47zw,self.MachineLearning,Mapping files to tests,https://www.reddit.com/r/MachineLearning/comments/dm47zw/mapping_files_to_tests/,Rubyakerman,1571858569,[removed],1,1,False,self,,,,,
1403,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,4,dm4eyc,self.MachineLearning,[D] Ideas and advice how to improve accuracy score using Random Forest and Extra Trees classifier.,https://www.reddit.com/r/MachineLearning/comments/dm4eyc/d_ideas_and_advice_how_to_improve_accuracy_score/,glitchdot2,1571859361,"My project is classification of ultrasound 2D images, the size of the  full data set is approximately 1000 images. For this analysis 250  features were handcrafted by calculating different parameters of the  whole images, or horizontal slices of the images. For features selection  Kbest with chi2 is used to select the best 50 features. To calculate  balanced accuracy I am using sklearn.model\_selection.cross\_val\_score,  and Random Forest and Extra Trees (1000 trees). What confuses me is that  when I split the data with train\_test\_split randomly with 9:1 ratio,  and use cross\_val\_score only on 90% of the data the highest accuracy  score is 80% with random forest, and 85% with extra trees. But when I  don't apply train\_test\_split and calculate balanced accuracy score on  the full data set, the highest score is not higher than 60%. I expected to get better results when I included more data, but opposite  happened. I would appreciate any advice or idea, how to improve the  accuracy score.",8,4,False,self,,,,,
1404,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,4,dm4fq2,self.MachineLearning,Neural Networks,https://www.reddit.com/r/MachineLearning/comments/dm4fq2/neural_networks/,alakeshmani,1571859457,[removed],0,1,False,self,,,,,
1405,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,4,dm4i31,self.MachineLearning,learning machine learning (beginner),https://www.reddit.com/r/MachineLearning/comments/dm4i31/learning_machine_learning_beginner/,D4Rew,1571859735,[removed],0,1,False,self,,,,,
1406,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,5,dm5j4u,self.MachineLearning,Deep Learning Specialization - Master Deep Learning &amp; Break into Artificial Intelligence (New career &amp; earnings opportunities),https://www.reddit.com/r/MachineLearning/comments/dm5j4u/deep_learning_specialization_master_deep_learning/,internetdigitalentre,1571863841,[removed],0,1,False,self,,,,,
1407,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,6,dm5xed,self.MachineLearning,[D] Useful tools to help visualize matching data across multiple files or tables?,https://www.reddit.com/r/MachineLearning/comments/dm5xed/d_useful_tools_to_help_visualize_matching_data/,QuerulousPanda,1571865426,"I'm in the process of trying to get a handle on some datasets. I know there are identical entries spread across several files, but I'd like to find a way to visualize those connections, either in a map or even just a table. 

My immediate task just has three smallish CSV's so I could easily write an R script to pull out the matches, but I'd prefer to more visual tool that can operate across larger bodies of data. 

I remember seeing a Defcon presentation where a similar tool was described for matching metadata, so I'm going back through old videos to try and find that, but I'm hoping someone here might know some good suggestions. 

Thanks!",1,5,False,self,,,,,
1408,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,7,dm6qfq,researchgate.net,[Research Paper] - DeepSlice: A Deep Learning Approach towards an Efficient and Reliable Network Slicing in 5G Networks,https://www.reddit.com/r/MachineLearning/comments/dm6qfq/research_paper_deepslice_a_deep_learning_approach/,adtmv7,1571868752,,1,1,False,default,,,,,
1409,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,7,dm70ec,researchgate.net,[R] DeepSlice: A Deep Learning Approach towards an Efficient and Reliable Network Slicing in 5G Networks,https://www.reddit.com/r/MachineLearning/comments/dm70ec/r_deepslice_a_deep_learning_approach_towards_an/,adtmv7,1571869931,,0,1,False,default,,,,,
1410,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,8,dm7s5z,github.com,pytorch/nestedtensor by pytorch,https://www.reddit.com/r/MachineLearning/comments/dm7s5z/pytorchnestedtensor_by_pytorch/,sjoerdapp,1571873238,,0,1,False,default,,,,,
1411,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,8,dm7zgc,self.MachineLearning,[D] Overfitting vs. Generalization - a subtle difference,https://www.reddit.com/r/MachineLearning/comments/dm7zgc/d_overfitting_vs_generalization_a_subtle/,eigenlaplace,1571874154,"In my view, overfitting does not necessarily imply lack of generalization, just as well as generalization cannot be directly associated to degree of overfitting. An overfit model is a model that is tuned to generate the highest performance (e.g. lowest loss) on the dataset it was trained to. This can be tested by the difference between the losses on the validation set and on the training set. In order to test for overfitting, training and validation sets should have similar distributions. If that's the case, an overfit model will deviate in performance on the validation set from the training performance. This is because, even if the distributions are similar, the model is tuned to pick up correctly only the samples it has seen on the training set. 

&amp;#x200B;

As for generalization, it can only be evaluated between datasets (test and training) that have different distributions. Ideally, the test distribution will be the most heterogeneous of them all. In my opinion, this is the only way to really assess generalization: the difference between the losses on training versus testing set. 

&amp;#x200B;

TLDR: Overfitting is indicated by when model underperforms on unseen data with similar distributions to seen data. Generalization, on the other hand, is indicated by the performance between seen an unseen data with different distributions, where the unseen data ideally represents real world distributions.

&amp;#x200B;

I think this is a misconception most have, even in industry. 

&amp;#x200B;

What are your thoughts?",27,0,False,self,,,,,
1412,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,9,dm8rs5,self.MachineLearning,Machine learning,https://www.reddit.com/r/MachineLearning/comments/dm8rs5/machine_learning/,alakeshmani,1571877911,[removed],0,1,False,self,,,,,
1413,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,10,dm98sy,redditmetrics.com,/r/machinelearning hit 800k subscribers yesterday,https://www.reddit.com/r/MachineLearning/comments/dm98sy/rmachinelearning_hit_800k_subscribers_yesterday/,TrendingBot,1571880252,,0,1,False,default,,,,,
1414,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,10,dm99y3,self.MachineLearning,Machine learning in Power electronic,https://www.reddit.com/r/MachineLearning/comments/dm99y3/machine_learning_in_power_electronic/,tonmoy073,1571880413,Can anyone tell me how machine learning could be used in power electronic????,1,1,False,self,,,,,
1415,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,10,dm9fbn,self.MachineLearning,asdfasdfasdf,https://www.reddit.com/r/MachineLearning/comments/dm9fbn/asdfasdfasdf/,kiddozhu,1571881164,[removed],0,1,False,self,,,,,
1416,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,10,dm9h46,self.MachineLearning,I feel posting a post without citation or reference should not be allowed! and doubt or discussion can go in /r/learnmachinelearning!,https://www.reddit.com/r/MachineLearning/comments/dm9h46/i_feel_posting_a_post_without_citation_or/,nile6499,1571881403,[removed],0,1,False,self,,,,,
1417,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,10,dm9m33,arxiv.org,[R] Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer,https://www.reddit.com/r/MachineLearning/comments/dm9m33/r_exploring_the_limits_of_transfer_learning_with/,hardmaru,1571882100,,18,56,False,default,,,,,
1418,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,11,dma49w,self.MachineLearning,New release of GraphVite and tutorials on various embedding applications,https://www.reddit.com/r/MachineLearning/comments/dma49w/new_release_of_graphvite_and_tutorials_on_various/,kiddozhu,1571884703,[removed],0,1,False,self,,,,,
1419,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,12,dmajhi,self.MachineLearning,Any sense in adding an extra eGPU for parallel GPU training?,https://www.reddit.com/r/MachineLearning/comments/dmajhi/any_sense_in_adding_an_extra_egpu_for_parallel/,autojazari,1571886945,[removed],0,1,False,self,,,,,
1420,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,13,dmbgml,2basetechnologies.com,Machine Learning &amp; Python: A New Combo For Futuristic Businesses,https://www.reddit.com/r/MachineLearning/comments/dmbgml/machine_learning_python_a_new_combo_for/,freyariki,1571892263,,0,1,False,https://a.thumbs.redditmedia.com/iqmhYNuN8f97VGVo2jBe5nT5-NzDokTjuR_rD3GKN80.jpg,,,,,
1421,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,13,dmbjzp,self.MachineLearning,Course on Stochastic Processes or Bayesian Methods?,https://www.reddit.com/r/MachineLearning/comments/dmbjzp/course_on_stochastic_processes_or_bayesian_methods/,drhectapus,1571892849,[removed],0,1,False,self,,,,,
1422,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,14,dmc315,self.MachineLearning,"New to ML World, What are Our Channels",https://www.reddit.com/r/MachineLearning/comments/dmc315/new_to_ml_world_what_are_our_channels/,ElianaVui,1571896263,"Hi!

I'm new to the ML, DL world and I'm trying to understand the best places to be in touch with people in the field. Twitter / FB/ LI / Medium? Would really appreciate any guidance and tips!  Thanks!!",0,1,False,self,,,,,
1423,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,15,dmc678,self.MachineLearning,What Is The Function Of Butterfly Valve?,https://www.reddit.com/r/MachineLearning/comments/dmc678/what_is_the_function_of_butterfly_valve/,uflowindia,1571896870,[removed],0,1,False,self,,,,,
1424,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,15,dmcaks,self.MachineLearning,Removed Object Detection approach,https://www.reddit.com/r/MachineLearning/comments/dmcaks/removed_object_detection_approach/,teddyondieki,1571897674,"I am a Machine Learning newbie, and trying to implement an algorithm that will help in the detection of missing objects from a scene. What approach should I take? Will greatly appreciate any links.",0,1,False,self,,,,,
1425,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,15,dmcoku,medium.com,Blockchain And Artificial Intelligence: To Foster Decentralized AI Landscape,https://www.reddit.com/r/MachineLearning/comments/dmcoku/blockchain_and_artificial_intelligence_to_foster/,himanshusingh09,1571900362,,0,1,False,default,,,,,
1426,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,16,dmd51z,self.MachineLearning,C++ for Deep Learning,https://www.reddit.com/r/MachineLearning/comments/dmd51z/c_for_deep_learning/,DL_passionate,1571903587," I am new learner in **Deep learning** and I have tried **python** and **tensorflow** , and now I have a project in this field but my constraint is **I should use C++** and I have no idea about what I should use as **software** in **windows 10** or **ubuntu 16.04**.  
So if someone already tried C++ for deep learning can advise me the path should I follow.",0,1,False,self,,,,,
1427,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,17,dmddfb,self.MachineLearning,Is Mask RCNN training on bounding boxes or polygon masks?,https://www.reddit.com/r/MachineLearning/comments/dmddfb/is_mask_rcnn_training_on_bounding_boxes_or/,HjalteM,1571905280,[removed],0,1,False,self,,,,,
1428,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,17,dmdhdg,self.MachineLearning,Confidence in regression problem,https://www.reddit.com/r/MachineLearning/comments/dmdhdg/confidence_in_regression_problem/,Hurasuruja,1571906080,"I have a regression problem where I try to predict objects coordinates within a bounded field. The input is image, where  field, field bounds and object is seen. I use convolutional network to predict the object coordinates ( model is resNet50 + a single neuron at the top, RMSE is used as a loss function). Model works pretty well on input images where the bounds of the field are seen. 

However some of the input images are close-ups from the object, where field bounds cannot be seen. Therefore there are no landmarks to predict the objects location. In these cases the model always predicts the object to lie around the center of the field (majority of the true coordinates are around the center of the field).  These predictions make my model pretty much unusable. I would like the model not to predict when close-up of image is seen. Is there a common practice to deal with this type of problem? 

I could train a different classifier to detect the close-up images, but this would require lots of labeling, which is infeasible.

I could also try something like described in here: [https://arxiv.org/abs/1506.02142](https://arxiv.org/abs/1506.02142) and ignore predictions where the uncertainty is high, but this would require to run the images trough the model several times.

Would it be possible to define a custom non-continuous lost function, which would allow the model to 'choose' a constant value, when close-up image is seen? After the inference I could just ignore predictions where this constant value is chosen.",0,1,False,self,,,,,
1429,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,18,dmdpa1,self.MachineLearning,Deep Image - AI/ML online upscale and enhance image with one click!,https://www.reddit.com/r/MachineLearning/comments/dmdpa1/deep_image_aiml_online_upscale_and_enhance_image/,bartbdm,1571907700,[removed],0,1,False,self,,,,,
1430,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,18,dmdufe,self.MachineLearning,Prediction code for sound recognition help! Machine learning code already trained (keras),https://www.reddit.com/r/MachineLearning/comments/dmdufe/prediction_code_for_sound_recognition_help/,CRL2020,1571908750,[removed],0,1,False,self,,,,,
1431,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,18,dmdv3u,self.MachineLearning,[Free Course-Udemy]-Support Vector Machines in Python - SVM in Python 2019,https://www.reddit.com/r/MachineLearning/comments/dmdv3u/free_courseudemysupport_vector_machines_in_python/,upworknepal,1571908877,[removed],0,1,False,self,,,,,
1432,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,18,dmdvo2,student-circuit.com,The world's first all-optical neural network for deep machine learning,https://www.reddit.com/r/MachineLearning/comments/dmdvo2/the_worlds_first_alloptical_neural_network_for/,Student_Circuit,1571908989,,0,1,False,default,,,,,
1433,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,18,dmdyat,self.MachineLearning,[P] MelGAN vocoder implementation in PyTorch,https://www.reddit.com/r/MachineLearning/comments/dmdyat/p_melgan_vocoder_implementation_in_pytorch/,seungwonpark,1571909507," *Disclaimer: This is a third-party implementation. The original authors stated that they will be releasing samples/code soon.*

A recent research showed that fully-convolutional, GAN called MelGAN can invert mel-spectrogram into raw audio in non-autoregressive manner. They showed that their MelGAN is lighter &amp; faster than WaveGlow, and even can generalize to unseen speakers when trained on 3 male + 3 female speakers' speech.

I thought this is a major breakthrough in TTS reserach, since both researchers and engineers can benefit from this fast &amp; lightweight neural vocoder. So I've tried to implement this is PyTorch: see GitHub link w/ audio samples below.

Debugging was quite painful while implementing this. Changing the update order of G/D mattered much, and my generator's loss curve is still going up. (Though results looks good when compared to original paper's.)  


* original paper:  [https://arxiv.org/abs/1910.06711](https://arxiv.org/abs/1910.06711) 
* implementation:  [https://github.com/seungwonpark/melgan](https://github.com/seungwonpark/melgan) 
* audio samples:  [http://swpark.me/melgan/](http://swpark.me/melgan/)
* audio samples from original paper:  [https://melgan-neurips.github.io](https://melgan-neurips.github.io/)   


[Figure 1 from \\""MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis\\""](https://i.redd.it/vhshzlc8kgu31.png)",32,89,False,https://b.thumbs.redditmedia.com/Ol6Vs8Fx_Dgodb0fA_k0RphT7j8HVTqKibfv8ff0NNA.jpg,,,,,
1434,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,19,dmegh1,gitlab.com,[P] A new reinforcement learning framework for researchers,https://www.reddit.com/r/MachineLearning/comments/dmegh1/p_a_new_reinforcement_learning_framework_for/,_djab_,1571912927,,0,6,False,default,,,,,
1435,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,19,dmelyr,self.MachineLearning,Kernel functions and neural networks,https://www.reddit.com/r/MachineLearning/comments/dmelyr/kernel_functions_and_neural_networks/,dramanautica,1571913909,"Ive been pondering this question and wanted to get some of your thoughts on it.

Kernel functions finds distances between two inputs relative to each other in some transformed space. Neural networks on the other hand finds the exact location of of the input in its transformed space.

Are there benefit and downsides between the two transformations? Why are kernel functions used instead of specifying the direct transformation from input to transformed space?",0,1,False,self,,,,,
1436,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,19,dmem79,self.MachineLearning,[D] Kernel functions and neural networks,https://www.reddit.com/r/MachineLearning/comments/dmem79/d_kernel_functions_and_neural_networks/,dramanautica,1571913953,"Ive been pondering this question and wanted to get some of your thoughts on it.

Kernel functions finds distances between two inputs relative to each other in some transformed space. Neural networks on the other hand finds the exact location of of the input in its transformed space.
Are there benefit and downsides between the two transformations? Why are kernel functions used instead of specifying the direct transformation from input to transformed space",6,7,False,self,,,,,
1437,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,20,dmerw1,medium.com,5 Facial Recognition Trends and Market Predictions 2019,https://www.reddit.com/r/MachineLearning/comments/dmerw1/5_facial_recognition_trends_and_market/,ankur_bansal123,1571914936,,0,1,False,default,,,,,
1438,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,20,dmf55u,youtu.be,Modify Motor brush to brushless,https://www.reddit.com/r/MachineLearning/comments/dmf55u/modify_motor_brush_to_brushless/,hoangminh0706,1571917082,,0,1,False,https://b.thumbs.redditmedia.com/qEQKh7VFqbS6SjEp5wzb8PlMwSP5ClJ6QnuCS5Z-G1I.jpg,,,,,
1439,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,20,dmf9vq,self.MachineLearning,What happens with new incoming data on a trained model,https://www.reddit.com/r/MachineLearning/comments/dmf9vq/what_happens_with_new_incoming_data_on_a_trained/,late_awakening,1571917836,[removed],0,1,False,self,,,,,
1440,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,21,dmfl0g,self.MachineLearning,What concepts and methods should everyone be familiar with?,https://www.reddit.com/r/MachineLearning/comments/dmfl0g/what_concepts_and_methods_should_everyone_be/,ReasonableRoll7,1571919528,[removed],0,1,False,self,,,,,
1441,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,21,dmfljc,self.MachineLearning,AdamOptimizer with Dropout is good or bad?,https://www.reddit.com/r/MachineLearning/comments/dmfljc/adamoptimizer_with_dropout_is_good_or_bad/,ganbaa_elmer,1571919606,[removed],0,1,False,self,,,,,
1442,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,21,dmfq58,self.MachineLearning,Why is machine learning so bad at writing like a human?,https://www.reddit.com/r/MachineLearning/comments/dmfq58/why_is_machine_learning_so_bad_at_writing_like_a/,ResponsibleVanilla8,1571920292,[removed],0,1,False,self,,,,,
1443,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,22,dmgbks,i.redd.it,What does a model learns,https://www.reddit.com/r/MachineLearning/comments/dmgbks/what_does_a_model_learns/,PulkitB,1571923301,,0,1,True,nsfw,,,,,
1444,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,22,dmgfv9,medium.com,Stanford Research Series: Grand Digital Piano: Multimodal Transfer of Learning of Sound and Touch,https://www.reddit.com/r/MachineLearning/comments/dmgfv9/stanford_research_series_grand_digital_piano/,CometML,1571923871,,0,1,False,default,,,,,
1445,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,22,dmggms,self.MachineLearning,Curing HIV...This is where you come in. [Research] [Project],https://www.reddit.com/r/MachineLearning/comments/dmggms/curing_hivthis_is_where_you_come_in_research/,dr_ish,1571923970,"Im a viral immunologist at amfAR, The Foundation for AIDS Research. Our job is to cure HIV. Which means we give money to scientists we think can help us achieve our goal. Ive been working on an idea the past year to bring in data scientists to analyze existing HIV datasets to find predictors that could be useful in developing a cure. The idea has finally come to fruition in the form of [this](https://www.amfar.org/Magnet-Grants-RFP/) request for proposals.  

Id love your help to energize HIV cure research with the new data science approaches being developed in other fields. So if you are interested in **$150K/year to analyze your heart out and help us find a cure,** consider applying. If you need help finding an HIV cure researcher to partner with, message me.",69,426,False,self,,,,,
1446,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,22,dmgh3s,self.MachineLearning,Layer complexity of Recurrent NNs in the Transformer Paper,https://www.reddit.com/r/MachineLearning/comments/dmgh3s/layer_complexity_of_recurrent_nns_in_the/,MichaelStaniek,1571924027,[removed],0,1,False,self,,,,,
1447,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,22,dmgqzl,self.MachineLearning,[P] JoeyNMT: Minimalist neural machine translation for newbies written in Pytorch,https://www.reddit.com/r/MachineLearning/comments/dmgqzl/p_joeynmt_minimalist_neural_machine_translation/,statnlphd,1571925328,"Our paper describing JoeyNMT was recently accepted at EMNLP so we thought it would be a good time to present our project to a larger community. Originally starting as a way to introduce students to neural machine translation methods without having to explain the intricacies of state of the art systems, JoeyNMT has now been in use for the past year now within our research group as a baseline system that is easily hackable and expandable. It has also found use Indaba Deep Learning school in Kenya and is a core tool used in the [masakhane.io](https://masakhane.io) project to train NMT on African Languages.

Right now we have implemented

*  RNNs (LSTM/GRU) and transformers for encoding and decoding
* Multiple attention models (MLP, Dot, Multi-head, and bilinear)
* character, word-level, and byte-pair encoded inputs
* Greedy decoding and beam search

Baseline models are available for English-&gt;{German, Latvian, Afrikaans, Zulu, Xitsonga, Northern Sotho, Setswana, isiZulu}

We have a [github](https://github.com/joeynmt/joeynmt), [blog post](https://www.cl.uni-heidelberg.de/statnlpgroup/blog/joey/), and [paper](https://arxiv.org/pdf/1907.12484.pdf) for JoeyNMT.  We'd love to have more contributors and cover more language pairs.",12,18,False,self,,,,,
1448,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,22,dmgs50,self.MachineLearning,[D] Layer Complexity of Recurrent NNs in the Transformer Paper,https://www.reddit.com/r/MachineLearning/comments/dmgs50/d_layer_complexity_of_recurrent_nns_in_the/,MichaelStaniek,1571925490,"[https://arxiv.org/pdf/1706.03762.pdf](https://arxiv.org/pdf/1706.03762.pdf) Table 1 of this paper says the layer complexity of self-attention NNs is N\^2\*d, which I understand.What I dont understand is the complexity of Recurrent NNs, which seems to be d\^2\*N. Does anyone know how this comes to be?",3,1,False,self,,,,,
1449,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,23,dmhd58,self.MachineLearning,Undergraduate applying for AI and ML research group,https://www.reddit.com/r/MachineLearning/comments/dmhd58/undergraduate_applying_for_ai_and_ml_research/,15p20,1571928109,[removed],0,1,False,self,,,,,
1450,MachineLearning,t5_2r3gv,2019-10-24,2019,10,24,23,dmhitm,self.MachineLearning,"[P] Compete for $160,000 in prize money and uncover the factors to help measure how young children learn",https://www.reddit.com/r/MachineLearning/comments/dmhitm/p_compete_for_160000_in_prize_money_and_uncover/,gtownhoya2041,1571928810,"Taken from the website: Use anonymous gameplay data, including knowledge of videos watched and games played, from the PBS KIDS Measure Up! app, a game-based learning tool developed as a part of the CPB-PBS Ready To Learn Initiative with funding from the U.S. Department of Education. Competitors will be challenged to predict scores on in-game assessments and create an algorithm that will lead to better-designed games and improved learning outcomes. Your solutions will aid in discovering important relationships between engagement with high-quality educational media and learning processes.",0,2,False,self,,,,,
1451,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,0,dmhnwu,self.MachineLearning,"[D] Kaggle/PBSKIDS Data Science Bowl - $160,000",https://www.reddit.com/r/MachineLearning/comments/dmhnwu/d_kagglepbskids_data_science_bowl_160000/,WhoRahWho,1571929413,[removed],0,1,False,self,,,,,
1452,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,0,dmhv7f,self.MachineLearning,Implementing Neuro Evolution to build Snake game AI!!,https://www.reddit.com/r/MachineLearning/comments/dmhv7f/implementing_neuro_evolution_to_build_snake_game/,deepLearner92,1571930271,[removed],0,1,False,self,,,,,
1453,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,0,dmhv8p,self.MachineLearning,How can I best serve the ML community if I'm admittedly not that interested in coding?,https://www.reddit.com/r/MachineLearning/comments/dmhv8p/how_can_i_best_serve_the_ml_community_if_im/,seventhoak,1571930276,[removed],0,1,False,self,,,,,
1454,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,0,dmhz5o,self.MachineLearning,Any references on Super-Resolution on Graph using Graph (Convolutional )Neural Network?,https://www.reddit.com/r/MachineLearning/comments/dmhz5o/any_references_on_superresolution_on_graph_using/,pradeep_sinngh,1571930734,[removed],0,1,False,self,,,,,
1455,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,0,dmi28e,medium.com,Get a Grip! MIT Boosts Robot Grasping,https://www.reddit.com/r/MachineLearning/comments/dmi28e/get_a_grip_mit_boosts_robot_grasping/,Yuqing7,1571931114,,0,1,False,https://b.thumbs.redditmedia.com/uOXa9w8xdyVin0IMRIUDXof-lxIzYRwCIWVqyzTVNxo.jpg,,,,,
1456,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,0,dmi2if,self.MachineLearning,"[D] Kaggle/PBSKIDS Data Science Bowl - $160,000",https://www.reddit.com/r/MachineLearning/comments/dmi2if/d_kagglepbskids_data_science_bowl_160000/,gtownhoya2041,1571931148,[removed],0,1,False,self,,,,,
1457,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,0,dmi7t7,self.MachineLearning,[P] Implementing Neuro evolution to build Snake game AI,https://www.reddit.com/r/MachineLearning/comments/dmi7t7/p_implementing_neuro_evolution_to_build_snake/,deepLearner92,1571931778,"I  am trying to implement NEAT for the snake game. My game logic is ready,  which is working properly and NEAT configured. But even after 100  generations with 200 genomes per generation, the snakes perform very  poorly. I am using neat-python for this.

The game board is 300x300 with grid size of 15. Hence, food and each part of the snake is of size 15x15. Hence, STEP = 15 for snake movement. The neural network has 24 inputs and 4 outputs and no hidden layer as part of the initial NEAT configuration. Activation function used is sigmoid.

Below are the inputs:

`snakeHeadX, snakeHeadY, snakeHeadBottomDist, snakeHeadRightDist, snakeTailX, snakeTailY, snakeLength, moveCount, moveToFood, food.x, food.y, foodBottomDist, foodRightDist, snakeFoodDistEuclidean, snakeFoodDistManhattan, viewDirections[0], viewDirections[1], viewDirections[2], viewDirections[3], viewDirections[4], viewDirections[5], viewDirections[6], viewDirections[7], deltaFoodDist`

Here, viewDirections\[0\] - \[7\] denote what the snake finds looking in 8 different directions. In each direction, the snake will check for food and it's own body. If it finds neither food nor body, value for that direction will be 0, if it finds only food, it will be 1, if finds only body, it will be 2 and if both body and food is found, then value will be 3. I have attached the implementation to find viewDirections list below as well.

The outputs are:

output\[0\] --&gt; for moving up, output\[1\] --&gt; for moving down, output\[2\] --&gt; for moving left, output\[3\] --&gt; for moving right

***The problem is the snake barely ever eats more than 2 food. The snake is unable to learn where the food is, reduce distance to food and ultimately eat it, but avoiding wall and the body at the same time. Need help if anyone here can guide me with what I am doing wrong, or what I am missing that I need to incorporate in this to make it work.***

Below is the eval\_genome function:

    ef main(genomes, config):
        clock = pygame.time.Clock()
        win = pygame.display.set_mode((WIN_WIDTH, WIN_HEIGHT))
        for genome_id, g in genomes:
            net = neat.nn.FeedForwardNetwork.create(g, config)
            g.fitness = 0
            snake = Snake()
            food = Food(snake.body)
            run = True
            UP = DOWN = RIGHT = LEFT = MOVE_SNAKE = False
            moveToFood = 0
            score = 0
            moveCount = 0
            while run:
                clock.tick(90)
                for event in pygame.event.get():
                    if event.type == pygame.QUIT:
                        run = False
                snakeHeadX = snake.body[0]['x']
                snakeHeadY = snake.body[0]['y']
                snakeTailX = snake.body[len(snake.body)-1]['x']
                snakeTailY = snake.body[len(snake.body)-1]['y']
                snakeLength = len(snake.body)
                snakeHeadBottomDist = WIN_HEIGHT - snakeHeadY - STEP
                snakeHeadRightDist = WIN_WIDTH - snakeHeadX - STEP
                foodBottomDist = WIN_HEIGHT - food.y - STEP
                foodRightDist = WIN_WIDTH - food.x - STEP
                snakeFoodDistEuclidean = math.sqrt((snakeHeadX - food.x)**2 + (snakeHeadY - food.y)**2)
                snakeFoodDistManhattan = abs(snakeHeadX - food.x) + abs(snakeHeadY - food.y)
                viewDirections = snake.checkDirections(food, UP, DOWN, LEFT, RIGHT)
                if not MOVE_SNAKE:
                    deltaFoodDist = 0
                
                outputs = net.activate((snakeHeadX, snakeHeadY, snakeHeadBottomDist, snakeHeadRightDist, snakeTailX, snakeTailY, snakeLength, moveCount, moveToFood, food.x, food.y, foodBottomDist, foodRightDist, snakeFoodDistEuclidean, snakeFoodDistManhattan, viewDirections[0], viewDirections[1], viewDirections[2], viewDirections[3], viewDirections[4], viewDirections[5], viewDirections[6], viewDirections[7], deltaFoodDist))
    
                if (outputs[0] == max(outputs) and not DOWN):
                    snake.setDir(0,-1)
                    UP = True
                    LEFT = False
                    RIGHT = False
                    MOVE_SNAKE = True
                elif (outputs[1] == max(outputs) and not UP):
                    snake.setDir(0,1)
                    DOWN = True
                    LEFT = False
                    RIGHT = False
                    MOVE_SNAKE = True
                elif (outputs[2] == max(outputs) and not RIGHT):
                    snake.setDir(-1,0)
                    LEFT = True
                    UP = False
                    DOWN = False
                    MOVE_SNAKE = True
                elif (outputs[3] == max(outputs) and not LEFT):
                    snake.setDir(1,0)
                    RIGHT = True
                    UP = False
                    DOWN = False
                    MOVE_SNAKE = True
                elif (not MOVE_SNAKE):
                    if (outputs[0] == max(outputs)):
                        snake.setDir(0,-1)
                        UP = True
                        MOVE_SNAKE = True
                    elif (outputs[1] == max(outputs)):
                        snake.setDir(0,1)
                        DOWN = True
                        MOVE_SNAKE = True
                    elif (outputs[2] == max(outputs)):
                        snake.setDir(-1,0)
                        LEFT = True
                        MOVE_SNAKE = True
                    elif (outputs[3] == max(outputs)):
                        snake.setDir(1,0)
                        RIGHT = True
                        MOVE_SNAKE = True  
    
                win.fill((0, 0, 0))
                food.showFood(win)
                if(MOVE_SNAKE):
                    snake.update()
                    newSnakeHeadX = snake.body[0]['x']
                    newSnakeHeadY = snake.body[0]['y']
                    newFoodDist = math.sqrt((newSnakeHeadX - food.x)**2 + (newSnakeHeadY - food.y)**2)
                    deltaFoodDist = newFoodDist - snakeFoodDistEuclidean
                    moveCount += 1
                    g.fitness += 0.01
                    if (deltaFoodDist &lt; 0):
                        g.fitness += 5
                    else:
                        g.fitness -= 50
                if(snake.collision()):
                    if score != 0:
                        print('FINAL SCORE IS: '+ str(score))
                    g.fitness -= 300
                    break
                snake.show(win)
                if(snake.eat(food,win)):
                    g.fitness += 15
                    score += 1
                    if score == 1 :
                        moveToFood = moveCount
                    else:
                        moveToFood = moveCount - moveToFood
                    food.foodLocation(snake.body)
                    food.showFood(win)

Below is the checkDirections function implemented in Snake class which gives the viewDirections list as output:

    def checkDirections(self, food, up, down, left, right):
            '''
            x+STEP, y-STEP
            x+STEP, y+STEP
            x-STEP, y-STEP
            x-STEP, y+STEP
            x+STEP, y
            x, y-STEP
            x, y+STEP
            x-STEP, y
    
            '''
            view = []
            x = self.xdir
            y = self.ydir
            
            view.append(self.check(x, y, STEP, -STEP, food.x, food.y))
            view.append(self.check(x, y, STEP, STEP, food.x, food.y))
            view.append(self.check(x, y, -STEP, -STEP, food.x, food.y))
            view.append(self.check(x, y, -STEP, STEP, food.x, food.y))
            view.append(self.check(x, y, STEP, 0, food.x, food.y))
            view.append(self.check(x, y, 0, -STEP, food.x, food.y))
            view.append(self.check(x, y, 0, STEP, food.x, food.y))
            view.append(self.check(x, y, -STEP, 0, food.x, food.y))
    
            if up == True:
                view[6] = -999
            elif down == True:
                view[5] = -999
            elif left == True:
                view[4] == -999
            elif right == True:
                view[7] == -999
    
            
            return view
            
        def check(self, x, y, xIncrement, yIncrement, foodX, foodY):
            value = 0
            foodFound = False
            bodyFound = False
            while (x &gt;= 0 and x &lt; WIN_WIDTH and y &gt;= 0 and y &lt; WIN_HEIGHT):
                x += xIncrement
                y += yIncrement
                if (not foodFound):
                    if (foodX == x and foodY == y):
                        foodFound = True
                if (not bodyFound):
                    for i in range(1, len(self.body)):
                        if ((x == self.body[i]['x']) and (y == self.body[i]['y'])):
                            bodyFound = True
                if (not bodyFound and not foodFound):
                    value = 0
                elif (not bodyFound and foodFound):
                    value = 1
                elif (bodyFound and not foodFound):
                    value = 2
                else:
                    value = 3
            return value",5,2,False,self,,,,,
1458,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,0,dmiba2,self.MachineLearning,"[D] ML frameworks used at ICCV 20172019: PyTorch 3-&gt;253, Tensorflow 43-&gt;91, Caffe 108 -&gt; 18",https://www.reddit.com/r/MachineLearning/comments/dmiba2/d_ml_frameworks_used_at_iccv_20172019_pytorch/,programmerChilli,1571932188,"Perhaps the most surprising fact here is that there are still 18 papers using Caffe (not Caffe2!) in 2019. Also, interestingly, all of the papers using Caffe are from Chinese universities.",27,26,False,self,,,,,
1459,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,0,dmie6w,self.MachineLearning,How to connect VS Code and Google Cloud VM instances,https://www.reddit.com/r/MachineLearning/comments/dmie6w/how_to_connect_vs_code_and_google_cloud_vm/,siraj_is_innocent,1571932532,[removed],0,1,False,self,,,,,
1460,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,1,dmikgt,super.gluebenchmark.com,New language model T5 achieves SOTA on GLUE and SUPERGLUE leaderboards,https://www.reddit.com/r/MachineLearning/comments/dmikgt/new_language_model_t5_achieves_sota_on_glue_and/,happyhammy,1571933263,,0,1,False,default,,,,,
1461,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,1,dmilb3,self.MachineLearning,Deep Learning (DL) versus Analysis Learning (AL),https://www.reddit.com/r/MachineLearning/comments/dmilb3/deep_learning_dl_versus_analysis_learning_al/,andrea_manero,1571933367,[removed],0,1,False,self,,,,,
1462,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,1,dmimlp,super.gluebenchmark.com,[D] New language model achieves SOTA on SUPERGLUE and GLUE leaderboards,https://www.reddit.com/r/MachineLearning/comments/dmimlp/d_new_language_model_achieves_sota_on_superglue/,happyhammy,1571933515,,0,1,False,https://b.thumbs.redditmedia.com/hzAQWYJjaek2vjquYesLlcybsTgDJF5FtrLQDXOLtSo.jpg,,,,,
1463,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,1,dmirh0,self.MachineLearning,Deep Learning Cheat Sheet for Beginners,https://www.reddit.com/r/MachineLearning/comments/dmirh0/deep_learning_cheat_sheet_for_beginners/,andrea_manero,1571934099,[removed],0,1,False,self,,,,,
1464,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,1,dmiwk6,self.MachineLearning,The ROI of Machine Learning in Business - Infographics,https://www.reddit.com/r/MachineLearning/comments/dmiwk6/the_roi_of_machine_learning_in_business/,andrea_manero,1571934729,[removed],0,1,False,self,,,,,
1465,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,1,dmiybr,self.MachineLearning,[D] Suggestion for multi-digit number recognition/OCR approach,https://www.reddit.com/r/MachineLearning/comments/dmiybr/d_suggestion_for_multidigit_number_recognitionocr/,itsDitzy,1571934938,"hello, im a final year student in college. 

recently, ive been tasked to build a system that can recognize runners based on their bib numbers. I came up with an idea to detect the runner first using mask r-cnn and then using the masked area from the processed image to do the OCR for the bib numbers. Is there any suggestion for the best approach to do the OCR thing? thanks",3,2,False,self,,,,,
1466,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,2,dmjohz,self.MachineLearning,[D] A Unifying Framework of Bilinear LSTMs,https://www.reddit.com/r/MachineLearning/comments/dmjohz/d_a_unifying_framework_of_bilinear_lstms/,ml_mohit,1571938112,"Disclaimer: this is my paper that I've been working on, if this sort of thing is not allowed on /r/ml please let me know.

arXiv page:  [https://arxiv.org/abs/1910.10294](https://arxiv.org/abs/1910.10294) 

Abstract: This paper presents a novel unifying framework of bilinear LSTMs that can represent and utilize the nonlinear interaction of the input features present in sequence datasets for achieving superior performance over a linear LSTM and yet not incur more parameters to be learned. To realize this, our unifying framework allows the expressivity of the linear vs. bilinear terms to be balanced by correspondingly trading off between the hidden state vector size vs. approximation quality of the weight matrix in the bilinear term so as to optimize the performance of our bilinear LSTM, while not incurring more parameters to be learned. We empirically evaluate the performance of our bilinear LSTM in several language-based sequence learning tasks to demonstrate its general applicability. 

&amp;#x200B;

Comments: This approach is novel because it considers improvement through the use of bilinear neurons (essentially polynomial regression + nonlinearity) as a building block. This is typically not done in neural networks as it is typically accepted that linear neuron + nonlinearity is sufficient as a universal approximator. However, we find that performance improvement can be achieved without incurring additional learnable parameters if bilinear neurons are used. It should be noted that the original proof on the universal approximability of linear neurons (Cybenko, 1989) does not show that they are efficient.",4,3,False,self,,,,,
1467,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,3,dmkjq6,self.MachineLearning,Help Me Create a Palm Reading Neural Network,https://www.reddit.com/r/MachineLearning/comments/dmkjq6/help_me_create_a_palm_reading_neural_network/,mtollive,1571941810,I am a CS undergrad working with two classmates to train a neural network to read palms. We could not find a data set for this project so we need 1200 pictures of left palms. If you send me yours I will be forever grateful. Thank you so much!,0,1,False,self,,,,,
1468,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,3,dmkuw5,self.MachineLearning,[D] Do CNNs understand semantic relationships between their classes?,https://www.reddit.com/r/MachineLearning/comments/dmkuw5/d_do_cnns_understand_semantic_relationships/,sabot00,1571943069,"Hi all,

How do CNNs understand ""compositional semantic relationships"" between their classes? The problem exists in the entire field, but I'm referencing this paper in particular: http://gandissect.csail.mit.edu/

In the 3rd paragraph of the introduction of the paper, Bau et al. say (emphasis mine):
&gt; To a human observer, a well-trained GAN appears to have learned facts about the objects in the image: for example, **a door can appear on a building but not on a tree**. We wish to understand how a GAN represents such structure. Do the objects emerge as pure pixel patterns without any explicit representation of objects such as doors and trees, or does the GAN contain internal variables that correspond to the objects that humans perceive?

From my (limited) understanding of CNNs, they take in the input image (HxWx3 channels) and pass it through a bunch of filters and maxpool layers. Each maxpool layer reduces the HxW of the matrix. Each filter layer increases the depth of matrix as we move away from the image and toward the ""highest levels of representation."" In a sense, we're abstracting toward higher and higher level features as the receptive field of our neurons increases and we're able to model longer-distance relationships. 

Finally, the last layer of the CNN is connected to the class output by a fully connected layer. 

From what I've read, it seems like the field is a bit split on this. You have this paper saying 
&gt; oh look! GANs (and thus CNNs) *can* understand relationships between classes because doors don't appear in the sky

But others also say it's an explicit shortcoming of the convolution function  that the spatial equivariance of convolution means it inherently cannot understand these relationships.
&gt; A CNN only looks for 2 eyes, 1 nose, and 1 mouth. It doesn't care that the eyes are parallel and above the nose, or that the nose is above the mouth!



My take is that the CNN can understand broadly the correlations between classes because of the last, FC layer. As a result, it can understand that maybe standing is negatively correlated with beer, or that pens are correlated with paper. But, it can't understand spatial relationships. 

What do you guys think of this issue?",13,11,False,self,,,,,
1469,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,4,dmkzzo,self.MachineLearning,[R] AI Benchmark: All About Deep Learning on Smartphones in 2019,https://www.reddit.com/r/MachineLearning/comments/dmkzzo/r_ai_benchmark_all_about_deep_learning_on/,aiff22,1571943649,"**\[arXiv Abstract\]:**  The performance of mobile AI accelerators has been evolving rapidly in the past two years, nearly doubling with each new generation of SoCs. The current 4th generation of mobile NPUs is already approaching the results of CUDA-compatible Nvidia graphics cards presented not long ago, which together with the increased capabilities of mobile deep learning frameworks makes it possible to run complex and deep AI models on mobile devices. In this paper, we evaluate the performance and compare the results of all chipsets from Qualcomm, HiSilicon, Samsung, MediaTek and Unisoc that are providing hardware acceleration for AI inference. We also discuss the recent changes in the Android ML pipeline and provide an overview of the deployment of deep learning models on mobile devices. All numerical results provided in this paper can be found and are regularly updated on the official project website: [http://ai-benchmark.com](http://ai-benchmark.com)

&amp;#x200B;

[ Performance evolution of mobile AI accelerators rs: image throughput for the float Inception-V3 model.](https://i.redd.it/n4jciy8ucju31.png)

&amp;#x200B;

The paper discusses the following topics:

1. Four generations of mobile NPUs
2. Hardware acceleration resources for AI inference on each of Android mobile SoC platforms
3. Android ecosystem for running deep learning models
4. Quantized and Floating-point performance of **all generations** of mobile NPUs
5. Performance comparison of FP inference on **mobile NPUs** vs. **Intel CPUs** vs. **Nvidia GPUs.**

The full paper is available on arXiv:  [https://arxiv.org/pdf/1910.06663.pdf](https://arxiv.org/pdf/1910.06663.pdf)",1,2,False,self,,,,,
1470,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,4,dmljtb,ai.google,"Finally, applications for Google AI Residency 2020 is now open.",https://www.reddit.com/r/MachineLearning/comments/dmljtb/finally_applications_for_google_ai_residency_2020/,Maitreya_patel,1571946085,,0,1,False,default,,,,,
1471,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,4,dmlkwx,self.MachineLearning,Everyday AI problem and solution,https://www.reddit.com/r/MachineLearning/comments/dmlkwx/everyday_ai_problem_and_solution/,whatisgoingonheretom,1571946215,"I have a class called intelligent systems and we have to do a project until the end of semester that presents a problem that can be solved with a simple AI program (like recommendation for movies, predicting the use of electricity,..) does anyone have any creative ideas for what we can develop? It can already exist and we could just try to understand or imitate it.",0,1,False,self,,,,,
1472,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,5,dmmgjv,dronedeploy.com,[Project] open collaborative deep learning on drone data,https://www.reddit.com/r/MachineLearning/comments/dmmgjv/project_open_collaborative_deep_learning_on_drone/,silizannek,1571949793,,0,1,False,default,,,,,
1473,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,5,dmmlef,self.MachineLearning,Why do Boosting Regression Trees Change the mean of the target?,https://www.reddit.com/r/MachineLearning/comments/dmmlef/why_do_boosting_regression_trees_change_the_mean/,zhaoc033,1571950340,"I am training a boosting model with exactly one tree. 

I was expecting the mean of prediction match exactly with the mean of training Y, but I saw a significant difference. 

I am wondering why this happens. See code copied below. 

&amp;#x200B;

pred = model\_reg.predict(X\_train, ntree\_start = 0, ntree\_end=0)  # using the first tree to make prediction

np.mean(pred)

np.mean(Y\_train)",0,1,False,self,,,,,
1474,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,6,dmmvxt,super.gluebenchmark.com,"New entry called T5 is within a hair's breadth of ""human"" performance on Superglue",https://www.reddit.com/r/MachineLearning/comments/dmmvxt/new_entry_called_t5_is_within_a_hairs_breadth_of/,no_bear_so_low,1571951488,,0,1,False,default,,,,,
1475,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,6,dmn2on,github.com,"I have created a python package called Pandas-log that can help one find issues, it does so by providing metadata on each pandas operation.",https://www.reddit.com/r/MachineLearning/comments/dmn2on/i_have_created_a_python_package_called_pandaslog/,eyaltrabelsi,1571952331,,0,1,False,https://b.thumbs.redditmedia.com/aPWzfUxPvUotMf9sd4tQKAyo7gIS3cQ48ti_qDl_BPc.jpg,,,,,
1476,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,6,dmn3u8,heartbeat.fritz.ai,Did Apple do a better job with on-device text recognition than Googles MLVision?,https://www.reddit.com/r/MachineLearning/comments/dmn3u8/did_apple_do_a_better_job_with_ondevice_text/,omarmhaimdat,1571952455,,0,1,False,https://b.thumbs.redditmedia.com/IobDgYzDuQHvu-8OA9GbzsG1Emwhkcy_MtbICF7P2JQ.jpg,,,,,
1477,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,6,dmn8by,self.deeplearning,Project ideas for advanced deep learning course,https://www.reddit.com/r/MachineLearning/comments/dmn8by/project_ideas_for_advanced_deep_learning_course/,ranran9991,1571952953,,0,1,False,default,,,,,
1478,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,6,dmni28,self.MachineLearning,Analyzing Big Data with Microsoft R Server and Client Training  Ramp-up your career and income potential,https://www.reddit.com/r/MachineLearning/comments/dmni28/analyzing_big_data_with_microsoft_r_server_and/,internetdigitalentre,1571954058,[removed],0,1,False,self,,,,,
1479,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,7,dmnlgl,self.MachineLearning,Best blogs and newsletters to keep current on developments in ML and text?,https://www.reddit.com/r/MachineLearning/comments/dmnlgl/best_blogs_and_newsletters_to_keep_current_on/,slnm01,1571954449,[removed],0,1,False,self,,,,,
1480,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,7,dmo0z1,self.MachineLearning,[R] Attenchilada: Location-Relative Attention Mechanisms For Robust Long-Form Speech Synthesis,https://www.reddit.com/r/MachineLearning/comments/dmo0z1/r_attenchilada_locationrelative_attention/,animus144,1571956267,"**tl;dr:** Using location-relative attention mechanisms allows Tacotron-based TTS systems to generalize to very long utterances. 

**Abstract:**  
Despite the ability to produce human-level speech for in-domain text, attention-based end-to-end text-to-speech (TTS) systems suffer from text alignment failures that increase in frequency for out-of-domain text. We show that these failures can be addressed using simple location-relative attention mechanisms that do away with content-based query/key comparisons. We compare two families of attention mechanisms: location-relative GMM-based mechanisms and additive energy-based mechanisms. We suggest simple modifications to GMM-based attention that allow it to align quickly and consistently during training, and introduce a new location-relative attention mechanism to the additive energy-based family, called Dynamic Convolution Attention (DCA). We compare the various mechanisms in terms of alignment speed and consistency during training, naturalness, and ability to generalize to long utterances, and conclude that GMM attention and DCA can generalize to very long utterances, while preserving naturalness for shorter, in-domain utterances.

**Paper:** [https://arxiv.org/abs/1910.10288](https://arxiv.org/abs/1910.10288)

**Audio Examples:** [https://google.github.io/tacotron/publications/location\_relative\_attention](https://google.github.io/tacotron/publications/location_relative_attention/)",46,20,False,self,,,,,
1481,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,7,dmo83z,twilio.com,Detect Toxic Language with Twilio Chat and Tensorflow.js,https://www.reddit.com/r/MachineLearning/comments/dmo83z/detect_toxic_language_with_twilio_chat_and/,lizziepika,1571957083,,0,2,False,default,,,,,
1482,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,8,dmoz8d,super.gluebenchmark.com,"Google T5 scores 88.9 on SuperGLUE Benchmark, compared to 89.8 human baseline",https://www.reddit.com/r/MachineLearning/comments/dmoz8d/google_t5_scores_889_on_superglue_benchmark/,maxtility,1571960329,,0,2,False,default,,,,,
1483,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,8,dmp31a,self.MachineLearning,[R] Distributed self-supervising capsule network,https://www.reddit.com/r/MachineLearning/comments/dmp31a/r_distributed_selfsupervising_capsule_network/,tobby_liu,1571960838,"One month ago I post an introduction to what I am working on, and someone suggested I ""create \*something\*, anything that people can look at to try and understand "". So I write an article now. This is the [link](https://github.com/TobbysGitHub/General-Artificial-Intelligence/blob/master/A_proposal_to_achieve_intelligence_through_a__novel_distributed_machine_learning_architecture__preprint.pdf).

This article proposes a self-supervising machine learning architecture which is actually a two-step model. The first step is to construct a causal representation model, and the second step is to promote intentions for it to complete tasks. The output cannot be supervised directly but it is action control signals sparsely coding information. In these situations, the end-to-end supervised learning is not applicable anymore. 

Here is the former [post](https://www.reddit.com/r/MachineLearning/comments/d6qmu3/dhow_to_behave_like_a_deeplearning_insider/) a month ago.",3,5,False,self,,,,,
1484,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,9,dmpu4a,self.MachineLearning,[P] 10K Downloads Special : gpt2-client accepting all feature requests!,https://www.reddit.com/r/MachineLearning/comments/dmpu4a/p_10k_downloads_special_gpt2client_accepting_all/,rish-16,1571964685,"Hey everyone !

First off, I want to thank all of you for your amazing support. gpt2-client just reached **10K+ downloads**!!

Being my first open-source project, it's touching to see the positive experiences you share with me via email/DM. I've noticed a trend where many of you are using it for your NLP research and some of you for your side-projects. No matter what you do, I'd love to know how I can improve it, either in terms of functionality, extendability, modularity, efficiency. You name it.

[We did it y'all! 10K in the bag :D](https://i.redd.it/g2rnpb743lu31.png)

**The Good Stuff: You're in control now**

As a way of giving back, I'd love to hear what you'd want to see in gpt2-client. It can be any bombastic feature request!!! We could discuss this on any platform (or you can open a feature request here [https://github.com/rish-16/gpt2client/issues/new/choose](https://github.com/rish-16/gpt2client/issues/new/choose)). This could tug on any aspect of gpt2-client that you feel should belong inside the module.

\------------------------------------

If you still aren't sure what gpt2-client is, I urge you to check out [https://github.com/rish-16/gpt2client/](https://github.com/rish-16/gpt2client/issues/new/choose) and if you like what you're seeing, do drop a . It means a lot to me and motivates me to continue building open-source technology.

Express your creativity down below in the comments!!! Grateful for your continuing support 

Cheers!",6,1,False,self,,,,,
1485,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,10,dmq06s,self.MachineLearning,When to apply for Summer 2020 research internships?,https://www.reddit.com/r/MachineLearning/comments/dmq06s/when_to_apply_for_summer_2020_research_internships/,lifeadvicesponge,1571965550,"Hello everyone,  

I was wondering when should I apply for a research internship or research engineer internship for the summer. I started my masters in September and am doing mostly coursework this semester. So I won't have much new to add in terms of research by December-January. However, I'll have done some grad-level ML relevant coursework like numerical linear algebra, machine learning, and optimization by then. So I basically have two options:  

* Apply right away as it may be too late to wait till say NeurIPS.  
* Wait till December so that I have my grad courses on my transcript and 1-2 final course projects on ML, Optimisation. I also expect to have much better GPA (4/4) compared to my undergrad.

I have three non-first author papers at conferences and journals and a first author workshop paper. I spoke to recruiters at some AI research companies like Borealis and Uber ATG in the beginning of October at a career fair and they had already started hiring for the summer. I'll be at both ICCV and NeurIPS where I could speak to recruiters and research scientists. Do you guys think I should apply right away or wait till December? I have my resume updated and could polish up my website over a weekend so I'm good to apply now but I'm just wondering if the grad coursework could help.   

PS: I am looking for industrial research labs publishing at top venues in Canada.",0,1,False,self,,,,,
1486,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,10,dmq09h,self.MachineLearning,Tired of working in isolation so sharing /r/ProgrammingPals to find programmers interested in building awesome software together!!,https://www.reddit.com/r/MachineLearning/comments/dmq09h/tired_of_working_in_isolation_so_sharing/,Roybot93,1571965559,[removed],0,1,False,self,,,,,
1487,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,10,dmq5bq,self.MachineLearning,[R] Weakly Supervised Disentanglement with Guarantees,https://www.reddit.com/r/MachineLearning/comments/dmq5bq/r_weakly_supervised_disentanglement_with/,approximately_wrong,1571966263,"We build a theoretical framework for analyzing disentanglement in the weakly supervised regime. We provide new definitions for disentanglement (sorry) that can be measured in a weakly supervised manner, and use these definitions as the cornerstone for developing a calculus and theory of disentanglement. We then analyzed several weak supervision techniques and proved (and empirically demonstrated) their disentanglement guarantees (or lack thereof). 

We hope that the concepts developed in this paper will help researcher frame their discussion and analysis of weakly supervised disentanglement in future work. 

Paper: [https://arxiv.org/abs/1910.09772](https://arxiv.org/abs/1910.09772) 

Cute gif: [https://twitter.com/i/status/1187507675258486784](https://twitter.com/i/status/1187507675258486784)",1,10,False,self,,,,,
1488,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,10,dmq8j5,github.com,"RobotizeJa, then RobotizeEarth",https://www.reddit.com/r/MachineLearning/comments/dmq8j5/robotizeja_then_robotizeearth/,ProgrammingGodJordan,1571966699,,0,1,False,default,,,,,
1489,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,10,dmq8p5,onezero.medium.com,"[R] Hospital Algorithms Are Biased Against Black Patients, New Research Shows",https://www.reddit.com/r/MachineLearning/comments/dmq8p5/r_hospital_algorithms_are_biased_against_black/,ChrisTweten,1571966722,,0,1,False,default,,,,,
1490,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,11,dmqpj4,self.MachineLearning,How pooling in convolutional neural networks is different than regular image scaling?,https://www.reddit.com/r/MachineLearning/comments/dmqpj4/how_pooling_in_convolutional_neural_networks_is/,internet_explorer_13,1571969235,[removed],0,1,False,self,,,,,
1491,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,14,dmsvvc,self.MachineLearning,Beginner advice for a portable workstation,https://www.reddit.com/r/MachineLearning/comments/dmsvvc/beginner_advice_for_a_portable_workstation/,KrakenML,1571981490,[removed],0,1,False,self,,,,,
1492,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,15,dmt648,analyticsinsight.net,How ML Improves the Back-Office Operations in an Enterprise,https://www.reddit.com/r/MachineLearning/comments/dmt648/how_ml_improves_the_backoffice_operations_in_an/,analyticsinsight,1571983373,,0,1,False,default,,,,,
1493,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,15,dmtdyn,self.MachineLearning,"ML or AI, what am I looking for exactly?",https://www.reddit.com/r/MachineLearning/comments/dmtdyn/ml_or_ai_what_am_i_looking_for_exactly/,GilbertValenz,1571984882,[removed],0,1,False,self,,,,,
1494,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,15,dmtnbb,arxiv.org,Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer,https://www.reddit.com/r/MachineLearning/comments/dmtnbb/exploring_the_limits_of_transfer_learning_with_a/,iordanissh,1571986597,,2,1,False,default,,,,,
1495,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,16,dmtt8r,analyticsinsight.net,Google Researchers Training AI Models to Predict Smell,https://www.reddit.com/r/MachineLearning/comments/dmtt8r/google_researchers_training_ai_models_to_predict/,analyticsinsight,1571987670,,0,0,False,default,,,,,
1496,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,16,dmtx97,engagely.ai,Engagely - Conversational AI Chatbot &amp; Artificial Intelligence Development,https://www.reddit.com/r/MachineLearning/comments/dmtx97/engagely_conversational_ai_chatbot_artificial/,Williamgray1234,1571988405,,0,1,False,https://b.thumbs.redditmedia.com/7zX1-fioZCuaLXmfGT8O-IX97Cotd1dy2DUh_nZq09E.jpg,,,,,
1497,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,16,dmu0gv,smthelp.com,"PCB handling, PCB assembly equipment, PCB conveyors",https://www.reddit.com/r/MachineLearning/comments/dmu0gv/pcb_handling_pcb_assembly_equipment_pcb_conveyors/,smthelp1,1571989039,,0,1,False,default,,,,,
1498,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,18,dmuuxc,youtube.com,A.I learns to perfect super mario world - world 1 level 2,https://www.reddit.com/r/MachineLearning/comments/dmuuxc/ai_learns_to_perfect_super_mario_world_world_1/,lekixer,1571995074,,0,1,False,https://b.thumbs.redditmedia.com/dr0v3lrJ3xsNOCSigFrXTrIbBmsee2YtXOobDpNx1uE.jpg,,,,,
1499,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,18,dmuypv,ai.googleblog.com,Learning to smell with Graph Neural Networks,https://www.reddit.com/r/MachineLearning/comments/dmuypv/learning_to_smell_with_graph_neural_networks/,ANil1729,1571995795,,0,1,False,default,,,,,
1500,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,18,dmv3y5,self.MachineLearning,Simple Interpolation R solution?,https://www.reddit.com/r/MachineLearning/comments/dmv3y5/simple_interpolation_r_solution/,CubanBenny,1571996787,[removed],0,1,False,self,,,,,
1501,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,19,dmvcvn,self.MachineLearning,Bayesian linear regression,https://www.reddit.com/r/MachineLearning/comments/dmvcvn/bayesian_linear_regression/,dyaser,1571998400,[removed],0,1,False,self,,,,,
1502,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,19,dmvm5q,self.MachineLearning,Anyone working on Face aging using GAN?,https://www.reddit.com/r/MachineLearning/comments/dmvm5q/anyone_working_on_face_aging_using_gan/,kailashahirwar12,1572000036,[removed],0,1,False,self,,,,,
1503,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,20,dmvzhz,venturebeat.com,[N] Google achieves state-of-the-art NLP performance with an enormous language model and data set,https://www.reddit.com/r/MachineLearning/comments/dmvzhz/n_google_achieves_stateoftheart_nlp_performance/,joshuacpeterson,1572002238,,0,1,False,default,,,,,
1504,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,20,dmw4zi,self.MachineLearning,Basis R Interpolation problem,https://www.reddit.com/r/MachineLearning/comments/dmw4zi/basis_r_interpolation_problem/,CubanBenny,1572003133,[removed],0,1,False,self,,,,,
1505,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,20,dmwctp,self.MachineLearning,Secure by design Data security needs to be at the heart of Digital transformation,https://www.reddit.com/r/MachineLearning/comments/dmwctp/secure_by_design_data_security_needs_to_be_at_the/,fission33,1572004397,[removed],0,1,False,self,,,,,
1506,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,21,dmwstp,self.MachineLearning,Bert Token Embeddings,https://www.reddit.com/r/MachineLearning/comments/dmwstp/bert_token_embeddings/,lor_v,1572006782,[removed],0,1,False,self,,,,,
1507,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,21,dmwx9d,self.MachineLearning,[DISCUSSION] Bert Token Embeddings,https://www.reddit.com/r/MachineLearning/comments/dmwx9d/discussion_bert_token_embeddings/,lor_v,1572007414,"From  Paper is easy to understand that BERT input is composed by Token  Embeddings, Positional Encode, Sentence Encode. The last two are  well-defined in BERT paper and in ""Attention is all you need"". But Token  embeddings is not clear how are build. Reading on Internet I found  different opinions. For sure tokenization is performed using WordPiece  Tokens and it's easy understand how it splits words. But once you have  the token id how BERT converts it in a Embedding?",5,5,False,self,,,,,
1508,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,21,dmx1f9,self.MachineLearning,"Magazines, blogs, sites",https://www.reddit.com/r/MachineLearning/comments/dmx1f9/magazines_blogs_sites/,steven_ger,1572008038,[removed],0,1,False,self,,,,,
1509,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,22,dmx4wc,self.MachineLearning,"Am trying to learn about cleaning data and there seems to be not a lot of information online, do you guys have any suggestions on articles or books I can read?",https://www.reddit.com/r/MachineLearning/comments/dmx4wc/am_trying_to_learn_about_cleaning_data_and_there/,mrmannen1155,1572008541,[removed],0,1,False,self,,,,,
1510,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,22,dmxna7,self.MachineLearning,How to create : Voice to text dataset,https://www.reddit.com/r/MachineLearning/comments/dmxna7/how_to_create_voice_to_text_dataset/,fountainhop,1572011027,[removed],0,1,False,self,,,,,
1511,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,23,dmxx4p,self.MachineLearning,[D] Trust t-SNE without PCA verification?,https://www.reddit.com/r/MachineLearning/comments/dmxx4p/d_trust_tsne_without_pca_verification/,Seiteshyru,1572012325,"Hi all,    
for my dataset t-SNE produces beautiful clusters with some transition in between clusters and a plot that overall is just very exciting. PCA on the other hand just produces very boring results.

Now I'm aware that t-SNE will try much harder to cluster stuff than PCA, so I'm not sure what to make of it.  

Can I somehow verify I'm not seeing artefacts that are based on the workings of t-SNE?  

I can't share the data, but here are some crudely drawn examples &lt;3 [https://imgur.com/a/7gQPrMA](https://imgur.com/a/7gQPrMA)

Thanks!",9,2,False,self,,,,,
1512,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,23,dmy77z,self.MachineLearning,[News] Machine Learning for Identifying Lung Cancer  Harvard and Topcoder Collab,https://www.reddit.com/r/MachineLearning/comments/dmy77z/news_machine_learning_for_identifying_lung_cancer/,NattyFried1,1572013591,"A really interesting read (and interview with Topcoder CEO Mike Morris and Dr. Raymond H. Mak of Harvard Medical Schooll) on a collaboration between Harvard Medical School and Topcoder on the tremendous progress that they have made in identifying Lung Cancer.

Well worth a read, and a follow up to JAMA Oncologys groundbreaking study revealed that AI / data science can detect cancer tumors faster, more effectively than humans ([https://jamanetwork.com/journals/jamaoncology/fullarticle/2730638](https://jamanetwork.com/journals/jamaoncology/fullarticle/2730638?fbclid=IwAR2BjG14xI6CPO5PZvd47DXp_QDq7Q4VrYPqBAPdKnGh-Pxd1mFNfFFhFTU)).

**Article**: [https://community.turgensec.com/machine-learning-for-curing-lung-cancer/](https://community.turgensec.com/machine-learning-for-curing-lung-cancer/)",3,29,False,self,,,,,
1513,MachineLearning,t5_2r3gv,2019-10-25,2019,10,25,23,dmyibw,self.MachineLearning,[N] Algorithm used to identify patients for extra care is racially biased,https://www.reddit.com/r/MachineLearning/comments/dmyibw/n_algorithm_used_to_identify_patients_for_extra/,newsbeagle,1572014978,"[https://spectrum.ieee.org/the-human-os/biomedical/ethics/racial-bias-found-in-algorithms-that-determine-health-care-for-millions-of-patients](https://spectrum.ieee.org/the-human-os/biomedical/ethics/racial-bias-found-in-algorithms-that-determine-health-care-for-millions-of-patients)

The algorithm was performing its task correctly -- it accurately predicted future health costs for patients to determine which ones should get extra care. But it still ended up discriminating against black patients.",255,195,False,self,,,,,
1514,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,0,dmyqsl,self.MachineLearning,"AI and Climate Change: How theyre connected, and what we can do about it",https://www.reddit.com/r/MachineLearning/comments/dmyqsl/ai_and_climate_change_how_theyre_connected_and/,transformsai,1572015987,[removed],0,1,False,self,,,,,
1515,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,0,dmyvxi,self.MachineLearning,Teaching A.I. to Play my Game!,https://www.reddit.com/r/MachineLearning/comments/dmyvxi/teaching_ai_to_play_my_game/,Light991,1572016644,[removed],0,1,False,self,,,,,
1516,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,0,dmyymy,self.MachineLearning,[P]Real Time MLP with 50 lines of code,https://www.reddit.com/r/MachineLearning/comments/dmyymy/preal_time_mlp_with_50_lines_of_code/,wangyi_fudan,1572016965,"[https://github.com/wangyi-fudan/wymlp](https://github.com/wangyi-fudan/wymlp)

MLP is a bit old, however it is mature to be deployed in industry. This repo has two purposes: a minimal C++ MLP code for education and the real time performance for the industry/IoT. There are several good points:

0: It uses standard C++ code, no magic instruction. Thus is portable to most machines.

1: It use c++ templates, thus inlines everything. It works like a pre-defined static function, pure stream of float point instructions.

2: It works by SGD of 1 sample each time. Thus it enables real time learning and prediction which is useful for future industry. The training ""FPS"" can reach 100k for a 32-hidden,16-layer network, eg. We can learn and predict each WAV frame as it arrives.

3: It use shared hidden-hidden weights. In fact it is similar to RNN making use of marginal chaos. This reduces the size of network to the cache without loss of accuracy.

4: the activation function used is y=x/(1+|x|) which is sigmoid like. It and its gradient are fast to calculate and not easily saturated.

5: experiment shows that only a single CPU thread is needed, and more threads just not improve the speed due to memory bound.

6: for &gt;=32 hidden units, gcc autovectorization will turn it to SSE/AVX code, which is 4X faster.

7: the float point type is a template parameter, float/double/long double are OK.

Hope you like it!",3,11,False,self,,,,,
1517,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,0,dmzc7o,self.MachineLearning,Asking for Tutorial for Tensorflow for Android,https://www.reddit.com/r/MachineLearning/comments/dmzc7o/asking_for_tutorial_for_tensorflow_for_android/,Yui0014,1572018645,[removed],0,1,False,self,,,,,
1518,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,0,dmzea4,self.MachineLearning,Using Haar Cascade defects?,https://www.reddit.com/r/MachineLearning/comments/dmzea4/using_haar_cascade_defects/,Frosty_Friend,1572018887,[removed],0,1,False,self,,,,,
1519,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,1,dmzi65,self.MachineLearning,Facial Recognition,https://www.reddit.com/r/MachineLearning/comments/dmzi65/facial_recognition/,shujaat81,1572019336,[removed],0,1,False,self,,,,,
1520,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,2,dn13v2,logicalclocks.com,"Guide to File Formats for Machine Learning: Columnar, Training, Inferencing",https://www.reddit.com/r/MachineLearning/comments/dn13v2/guide_to_file_formats_for_machine_learning/,jpdowlin,1572026097,,0,1,False,default,,,,,
1521,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,2,dn146a,self.MachineLearning,"[P] Update--using an Orbbec Astra Pro, improved tracking, and again the dynamixel Pan/Tilt turret, ROS and YOLOv3 for realtime robotic object tracking",https://www.reddit.com/r/MachineLearning/comments/dn146a/p_updateusing_an_orbbec_astra_pro_improved/,Oswald_Hydrabot,1572026132,"https://youtu.be/QoP2Hu_RQcU

Above is an update to an ongoing ""Applied-ML"" project of mine.

There is still a lot of work to do to get the SLAM components of this working properly, but I have recently made significant improvements to a robotic turret that uses ROS, a Dynamixel pan/tilt turret, and YOLOv3 to track objects in real time in 3D using the 2D detection from YOLO.  In this video it's again tracking ""Human heads"".

The detection is much smoother in this release, although at about :12 in the video here, it jolts hard to the right in error  (likely an error in lead and/or speed update, should be easy to resolve).

YOLO performs significantly better on the NVidia Tesla k40 that I'm using here as well, upgraded from the GTX1060 in my previous post.  I'm also using a calibrated Orbbec Astra Pro instead of the Kinect 360 as well.  The depth registration of the RGB as well as the stability of the detection has noticably improved.

I plan to begin the challenge of designing a rudimentary implementation of ""visual dialogue"" with this in another upcoming upgrade.  Ideally I want this to be able to not just hold a conversation, but be able to look around the room at objects that it's capable of detecting and using SLAM to store the location of those (an example being ""what is that cat behind you doing?"" and have it respond with looking for the cat, tracking and mapping it's location, and generating a verbal response).

Stay tuned for more updates; the next will be a bit more exciting!

Link to the first release of this bot and description of the underlying technology is below:

https://www.reddit.com/r/MachineLearning/comments/dik1lr/p_my_implementation_of_object_tracking_using_an/",2,7,False,self,,,,,
1522,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,3,dn1ab9,logicalclocks.com,"[D] Guide to File Formats for Machine Learning: Columnar, Training, Inferencing",https://www.reddit.com/r/MachineLearning/comments/dn1ab9/d_guide_to_file_formats_for_machine_learning/,jpdowlin,1572026832,,0,1,False,default,,,,,
1523,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,3,dn1bln,self.MachineLearning,"Kaggle / PBS KIDS Challenge - $160,000",https://www.reddit.com/r/MachineLearning/comments/dn1bln/kaggle_pbs_kids_challenge_160000/,mystikaldanger,1572026980,[removed],0,1,False,self,,,,,
1524,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,3,dn1kpb,i.redd.it,Thought this sub would appreciate this meme too,https://www.reddit.com/r/MachineLearning/comments/dn1kpb/thought_this_sub_would_appreciate_this_meme_too/,xRazorLazor,1572028017,,0,1,False,https://b.thumbs.redditmedia.com/mMeHBlEG7Xr-5-7lUOAgOGpIhYQOWdVZ1orFtxYox4Y.jpg,,,,,
1525,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,3,dn1tqn,medium.com,Google AI Targets Video Understanding With Speedy TinyVideoNet and Other Approaches,https://www.reddit.com/r/MachineLearning/comments/dn1tqn/google_ai_targets_video_understanding_with_speedy/,Yuqing7,1572029074,,0,1,False,default,,,,,
1526,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,3,dn1v5c,self.MachineLearning,"[D] Kaggle / PBS KIDS Challenge - $160,000",https://www.reddit.com/r/MachineLearning/comments/dn1v5c/d_kaggle_pbs_kids_challenge_160000/,mystikaldanger,1572029255," [https://www.kaggle.com/c/data-science-bowl-2019](https://www.kaggle.com/c/data-science-bowl-2019) 

&amp;#x200B;

&gt;Uncover new insights in early childhood education and how media can support learning outcomes.   
&gt;  
&gt;  
&gt;  
&gt;PBS KIDS, a trusted name in early childhood education for decades, aims to gain insights into how media can help children learn important skills for success in school and life. In this challenge, youll use anonymous gameplay data, including knowledge of videos watched and games played, from the PBS KIDS Measure Up! app, a game-based learning tool developed as a part of the CPB-PBS Ready To Learn Initiative with funding from the U.S. Department of Education. Competitors will be challenged to predict scores on in-game assessments and create an algorithm that will lead to better-designed games and improved learning outcomes. Your solutions will aid in discovering important relationships between engagement with high-quality educational media and learning processes.   
&gt;  
&gt;  
&gt;  
&gt;In the PBS KIDS Measure Up! app, children ages 3 to 5 learn early STEM concepts focused on length, width, capacity, and weight while going on an adventure through Treetop City, Magma Peak, and Crystal Caves. Joined by their favorite PBS KIDS characters, children can also collect rewards and unlock digital toys as they play.",2,10,False,self,,,,,
1527,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,4,dn2hlo,powerbi.microsoft.com,Announcing Automated Machine learning in Power BI general availability,https://www.reddit.com/r/MachineLearning/comments/dn2hlo/announcing_automated_machine_learning_in_power_bi/,MathyPants,1572031845,,0,1,False,default,,,,,
1528,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,4,dn2mpq,medium.com,Milestone: BERT Boosts Google Search,https://www.reddit.com/r/MachineLearning/comments/dn2mpq/milestone_bert_boosts_google_search/,Yuqing7,1572032447,,0,1,False,default,,,,,
1529,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,4,dn2o6u,self.MachineLearning,[D] What's the best open-source model management framework?,https://www.reddit.com/r/MachineLearning/comments/dn2o6u/d_whats_the_best_opensource_model_management/,turing_machines,1572032626,"What do you think is the best open-source model management framework and why? I've looked into ModelDB, Polyaxon, studio.ml, datmo, etc., but I'm not sure which one people consider the best/most robust. Have you guys used or tried any, and if so, what did you like and not like?",2,0,False,self,,,,,
1530,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,5,dn2yew,self.MachineLearning,[D] Music Synthesis Using ML?,https://www.reddit.com/r/MachineLearning/comments/dn2yew/d_music_synthesis_using_ml/,1h8hf78k9,1572033842,"Hello, I have some basic experience with machine learning using Python, but I've been unable to find a guide on how to do what I'd like to do. That is, I'd like to train a model using my collection of audio files (hundreds of thousands of MP3s, WAVs, and FLACs) and output audio files. I would greatly appreciate any help or points in the right direction!",11,8,False,self,,,,,
1531,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,5,dn324l,youtube.com,019 - AWS and Machine Learning - Types of Machine Learning Algorithms,https://www.reddit.com/r/MachineLearning/comments/dn324l/019_aws_and_machine_learning_types_of_machine/,malikshahnaz,1572034268,,0,1,False,default,,,,,
1532,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,5,dn3bn8,self.MachineLearning,Video Exploring RAPIDS Feature Engineering vs. Pandas for the NFL Data Bowl!,https://www.reddit.com/r/MachineLearning/comments/dn3bn8/video_exploring_rapids_feature_engineering_vs/,HenryAILabs,1572035422,[removed],0,1,False,self,,,,,
1533,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,5,dn3gn2,self.MachineLearning,Feature Scaling query(I'm just starting),https://www.reddit.com/r/MachineLearning/comments/dn3gn2/feature_scaling_queryim_just_starting/,ic3_fire,1572036013,"for this:

    X_norm = X;
    mu = zeros(1, size(X, 2));
    sigma = zeros(1, size(X, 2));

can someone explain to me why this doesn't work :

    mu(:, 1) = mean(X_norm(:,1));
    mu(:, 2) = mean(X_norm(:, 2));
    sigma(:, 1) = std(X_norm(:, 1));
    sigma(:, 2) = std(X_norm(:, 2));
    X_norm -= mu;
    X_norm = X./sigma;

but this does :

    mu = mean(X);
    sigma = std(X);
    X_norm = (X - mu)./sigma;

P.S : I'm just a noob and I'm aware that the second block of code is better than the first one, but the reason I'm asking is because the second block of code is heavily inspired by someone else's code (not a direct solution I swear), but first block of code was my own :'(",0,1,False,self,,,,,
1534,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,5,dn3pml,self.MachineLearning,RAPIDS Feature Engineering,https://www.reddit.com/r/MachineLearning/comments/dn3pml/rapids_feature_engineering/,HenryAILabs,1572037079,"This video explores the speedups achieved by feature engineering on GPUs with RAPIDS via cudf and dask-cudf compared to pandas. No feature has less than a 10x speedup with RAPIDS!

[https://youtu.be/A9lgUwA8RrY](https://t.co/jatWUdq72Q?amp=1) [\#100DaysOfMLCode](https://twitter.com/hashtag/100DaysOfMLCode?src=hashtag_click)",0,1,False,self,,,,,
1535,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,6,dn3wdu,self.MachineLearning,Amazon Data Science/ML interview questions,https://www.reddit.com/r/MachineLearning/comments/dn3wdu/amazon_data_scienceml_interview_questions/,abbey_chup_bakchod,1572037911,"I've been trying to learn some fundamentals of data science and machine learning recently when I ran into [this medium article about Amazon interview questions.](https://medium.com/acing-ai/amazon-ai-interview-questions-acing-the-ai-interview-3ed4e671920f) I think I can answer some of the ML and probability questions but others just fly off the top of my head. What do you all think ?

* How does a logistic regression model know what the coefficients are?
* Difference between convex and non-convex cost function; what does it mean when a cost function is non-convex?
* Is random weight assignment better than assigning same weights to the units in the hidden layer?
* Given a bar plot and imagine you are pouring water from the top, how to qualify how much water can be kept in the bar chart?
* What is Overfitting?
* How would the change of prime membership fee would affect the market?
* Why is gradient checking important?
* Describe Tree, SVM, Random forest and boosting. Talk about their advantage and disadvantages.
* How do you weight 9 marbles three times on a balance scale to select the heaviest one?
* Find the cumulative sum of top 10 most profitable products of the last 6 month for customers in Seattle.
* Describe the criterion for a particular model selection. Why is dimension reduction important?
* What are the assumptions for logistic and linear regression?
* If you can build a perfect (100% accuracy) classification model to predict some customer behaviour, what will be the problem in application?
* The probability that item an item at location A is 0.6 , and 0.8 at location B. What is the probability that item would be found on Amazon website?
* Given a csv file with ID and Quantity columns, 50million records and size of data as 2 GBs, write a program in any language of your choice to aggregate the QUANTITY column.
* Implement circular queue using an array.
* When you have a time series data by monthly, it has large data records, how will you find out significant difference between this month and previous months values?
* Compare Lasso and Ridge Regression.
* Whats the difference between MLE and MAP inference?
* Given a function with inputs  an array with N randomly sorted numbers, and an int K, return output in an array with the K largest numbers.
* When users are navigating through the Amazon website, they are performing several actions. What is the best way to model if their next action would be a purchase?
* Estimate the disease probability in one city given the probability is very low national wide. Randomly asked 1000 person in this city, with all negative response(NO disease). What is the probability of disease in this city?
* Describe SVM.
* How does K-means work? What kind of distance metric would you choose? What if different features have different dynamic range?
* What is boosting?
* How many topic modeling techniques do you know of?
* Formulate LSI and LDA techniques.
* What are generative and discriminative algorithms? What are their strengths and weaknesses? Which type of algorithms are usually used and why?",0,1,False,self,,,,,
1536,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,6,dn44ok,self.MachineLearning,[R] Attacking Optical Flow,https://www.reddit.com/r/MachineLearning/comments/dn44ok/r_attacking_optical_flow/,worldnews_is_shit,1572038942,"Attacking Optical Flow


TLDR:  Corrupting a small patch of less than 1% of the image size lead to noisy flow estimates that extend beyond the region of the attack, even erasing the motion of objects in the scene in some cases

Anurag Ranjan,Joel Janai,Andreas Geiger,Michael J. Black

(Submitted on 22 Oct 2019)

Deep neural nets achieve state-of-the-art performance on the problem of optical flow estimation. Since optical flow is used in several safety-critical applications like self-driving cars, it is important to gain insights into the robustness of those techniques. Recently, it has been shown that adversarial attacks easily fool deep neural networks to misclassify objects. The robustness of optical flow networks to adversarial attacks, however, has not been studied so far. In this paper, we extend adversarial patch attacks to optical flow networks and show that such attacks can compromise their performance. We show that corrupting a small patch of less than 1% of the image size can significantly affect optical flow estimates. Our attacks lead to noisy flow estimates that extend significantly beyond the region of the attack, in many cases even completely erasing the motion of objects in the scene. While networks using an encoder-decoder architecture are very sensitive to these attacks, we found that networks using a spatial pyramid architecture are less affected. We analyse the success and failure of attacking both architectures by visualizing their feature maps and comparing them to classical optical flow techniques which are robust to these attacks. We also demonstrate that such attacks are practical by placing a printed pattern into real scenes.

Abs: https://arxiv.org/abs/1910.10053

Site: https://flowattack.is.tue.mpg.de",3,11,False,self,,,,,
1537,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,6,dn48ox,self.MachineLearning,[R] YOLACT: Real-time Instance Segmentation ICCV Trailer,https://www.reddit.com/r/MachineLearning/comments/dn48ox/r_yolact_realtime_instance_segmentation_iccv/,dbolya,1572039464,"https://www.youtube.com/watch?v=0pMfmo8qfpQ


I made a trailer to hype up my paper about performing instance segmentation in real-time [that I posed here a while ago] (https://www.reddit.com/r/MachineLearning/comments/cuu7ce/r_yolact_realtime_instance_segmentation/) (and to show off its capabilities). Hope you like it!",34,54,False,self,,,,,
1538,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,8,dn5se1,self.MachineLearning,Managing Cache Files,https://www.reddit.com/r/MachineLearning/comments/dn5se1/managing_cache_files/,Big_Notice,1572046447,[removed],0,1,False,self,,,,,
1539,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,8,dn5y2i,self.MachineLearning,[P]: Best Practice for Cache/Processed Data Management,https://www.reddit.com/r/MachineLearning/comments/dn5y2i/p_best_practice_for_cacheprocessed_data_management/,Big_Notice,1572047196,"In ML research, we often have tons of cache files to read from disk. As a project progesses, I often end up with lots of cache files which I don't remember how they were created. My current way to keeping track of cache files and preprocessed files is by writing it down when it is created and why.

&amp;#x200B;

I am wondering if anyone has a way to automate this process? I heard something like DVC ([https://github.com/iterative/dvc](https://github.com/iterative/dvc)), but it seems to be too complicated.",4,4,False,self,,,,,
1540,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,10,dn6xrr,self.MachineLearning,[D] Google is applying BERT to Search,https://www.reddit.com/r/MachineLearning/comments/dn6xrr/d_google_is_applying_bert_to_search/,faceshapeapp,1572052193,"Understanding searches better than ever before

If theres one thing Ive learned over the 15 years working on Google Search, its that peoples curiosity is endless. We see billions of searches every day, and 15 percent of those queries are ones we havent seen before--so weve built ways to return results for queries we cant anticipate.

When people like you or I come to Search, we arent always quite sure about the best way to formulate a query. We might not know the right words to use, or how to spell something, because often times, we come to Search looking to learn--we dont necessarily have the knowledge to begin with.

At its core, Search is about understanding language. Its our job to figure out what youre searching for and surface helpful information from the web, no matter how you spell or combine the words in your query. While weve continued to improve our language understanding capabilities over the years, we sometimes still dont quite get it right, particularly with complex or conversational queries. In fact, thats one of the reasons why people often use keyword-ese, typing strings of words that they think well understand, but arent actually how theyd naturally ask a question.

With the latest advancements from our research team in the science of language understanding--made possible by machine learning--were making a significant improvement to how we understand queries, representing the biggest leap forward in the past five years, and one of the biggest leaps forward in the history of Search.

**Applying BERT models to Search**  
Last year, we [introduced and open-sourced](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html) a neural network-based technique for natural language processing (NLP) pre-training called Bidirectional Encoder Representations from Transformers, or as we call it--[BERT](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html), for short. This technology enables anyone to train their own state-of-the-art question answering system.

This breakthrough was the result of Google research on [transformers](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html): models that process words in relation to all the other words in a sentence, rather than one-by-one in order. BERT models can therefore consider the full context of a word by looking at the words that come before and after itparticularly useful for understanding the intent behind search queries.

But its not just advancements in software that can make this possible: we needed new hardware too. Some of the models we can build with BERT are so complex that they push the limits of what we can do using traditional hardware, so for the first time were using the latest [Cloud TPUs ](https://cloud.google.com/blog/products/ai-machine-learning/cloud-tpu-pods-break-ai-training-records)to serve search results and get you more relevant information quickly.

**Cracking your queries**  
So thats a lot of technical details, but what does it all mean for you? Well, by applying BERT models to both ranking and featured snippets in Search, were able to do a much better job helping you find useful information. In fact, when it comes to ranking results, BERT will help Search better understand one in 10 searches in the U.S. in English, and well bring this to more languages and locales over time.

Particularly for longer, more conversational queries, or searches where prepositions like for and to matter a lot to the meaning, Search will be able to understand the context of the words in your query. You can search in a way that feels natural for you.

To launch these improvements, we did a lot of [testing](https://www.google.com/search/howsearchworks/mission/users/) to ensure that the changes actually are more helpful. Here are some of the examples that showed up our evaluation process that demonstrate BERTs ability to understand the intent behind your search.  


Heres a search for 2019 brazil traveler to usa need a visa. The word to and its relationship to the other words in the query are particularly important to understanding the meaning. Its about a Brazilian traveling to the U.S., and not the other way around. Previously, our algorithms wouldn't understand the importance of this connection, and we returned results about U.S. citizens traveling to Brazil. With BERT, Search is able to grasp this nuance and know that the very common word to actually matters a lot here, and we can provide a much more relevant result for this query.

Lets look at another query: do estheticians stand a lot at work. Previously, our systems were taking an approach of matching keywords, matching the term stand-alone in the result with the word stand in the query. But that isnt the right use of the word stand in context. Our BERT models, on the other hand, understand that stand is related to the concept of the physical demands of a job, and displays a more useful response.

Here are some other examples where BERT has helped us grasp the subtle nuances of language that computers dont quite understand the way humans do.

**Improving Search in more languages**  
Were also applying BERT to make Search better for people across the world. A powerful characteristic of these systems is that they can take learnings from one language and apply them to others. So we can take models that learn from improvements in English (a language where the vast majority of web content exists) and apply them to other languages. This helps us better return relevant results in the many languages that Search is offered in.

For featured snippets, were using a BERT model to improve featured snippets in the two dozen countries where this feature is available, and seeing significant improvements in languages like Korean, Hindi and Portuguese.

**Search is not a solved problem**  
No matter what youre looking for, or what language you speak, we hope youre able to let go of some of your keyword-ese and search in a way that feels natural for you. But youll still stump Google from time to time. Even with BERT, we dont always get it right. If you search for what state is south of Nebraska, BERTs best guess is a community called South Nebraska. (If you've got a feeling it's not in Kansas, you're right.)

Language understanding remains an ongoing challenge, and it keeps us motivated to continue to improve Search. Were always getting better and working to find the meaning in-- and most helpful information for-- every query you send our way.

[Source](https://blog.google/products/search/search-language-understanding-bert/)",58,568,False,self,,,,,
1541,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,10,dn6yd8,lzzgmachine.com,"High efficiency sand washer , Sand gravel separator",https://www.reddit.com/r/MachineLearning/comments/dn6yd8/high_efficiency_sand_washer_sand_gravel_separator/,laum_lzzg,1572052291,,0,1,False,default,,,,,
1542,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,10,dn7ca1,youtube.com,"Towards Transparent Machine Learning, ML over context-free grammars/programming languages. [R][D]",https://www.reddit.com/r/MachineLearning/comments/dn7ca1/towards_transparent_machine_learning_ml_over/,timemanifold,1572054324,,0,1,False,https://b.thumbs.redditmedia.com/9HT4QNOxrm9sdoAp9K8G7_jyblCiS9VLp5ZE0I6kHTY.jpg,,,,,
1543,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,11,dn7jc4,self.MachineLearning,[P] GPT2 getting stuck on loop,https://www.reddit.com/r/MachineLearning/comments/dn7jc4/p_gpt2_getting_stuck_on_loop/,RaunchyPa,1572055365,"I'm relatively new to ML and have been running my own finetuning of GPT2 for a while. I'm not sure if this is the best or most appropriate place to ask this, so please forgive me if not (and feel free to redirect me elsewhere). With many prompts, GPT2 seems to get stuck in an infinite loop repeating the input phrase or part of the input phrase, particularly when I pass it titles. It will also randomly spit out the endtext token, or say things like Join my mailing list! Read the comments blow at the start of an ""article"".

&amp;#x200B;

Am I doing something wrong with finetuning, or is this just a thing that happens and that people discard?",6,0,False,self,,,,,
1544,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,11,dn7k06,self.MachineLearning,[R] Emotion Recognition in Conversations with Graph Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/dn7k06/r_emotion_recognition_in_conversations_with_graph/,bideex,1572055454,"**Abstract:** Emotion recognition in conversation (ERC) has received much attention, lately, from researchers due to its potential widespread applications in diverse areas, such as health-care, education, and human resources. In this paper, we present Dialogue Graph Convolutional Network (DialogueGCN), a graph neural network based approach to ERC. We leverage self and inter-speaker dependency of the interlocutors to model conversational context for emotion recognition. Through the graph network, DialogueGCN addresses context propagation issues present in the current RNN-based methods. We empirically show that this method alleviates such issues, while outperforming the current state of the art on a number of benchmark emotion classification datasets.

**Paper**: [https://arxiv.org/abs/1908.11540](https://arxiv.org/abs/1908.11540) (EMNLP 2019)

**Blog Post**: [https://towardsdatascience.com/emotion-recognition-using-graph-convolutional-networks-9f22f04b244e](https://towardsdatascience.com/emotion-recognition-using-graph-convolutional-networks-9f22f04b244e)",5,13,False,self,,,,,
1545,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,11,dn7ocl,youtube.com,Towards Transparent Machine Learning,https://www.reddit.com/r/MachineLearning/comments/dn7ocl/towards_transparent_machine_learning/,timemanifold,1572056111,,0,1,False,https://b.thumbs.redditmedia.com/9HT4QNOxrm9sdoAp9K8G7_jyblCiS9VLp5ZE0I6kHTY.jpg,,,,,
1546,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,11,dn7w5r,youtube.com,[P] Towards Transparent Machine Learning,https://www.reddit.com/r/MachineLearning/comments/dn7w5r/p_towards_transparent_machine_learning/,timemanifold,1572057294,,0,1,False,https://b.thumbs.redditmedia.com/9HT4QNOxrm9sdoAp9K8G7_jyblCiS9VLp5ZE0I6kHTY.jpg,,,,,
1547,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,12,dn8lq9,self.MachineLearning,[P] Predict figure skating world championship ranking from season scores,https://www.reddit.com/r/MachineLearning/comments/dn8lq9/p_predict_figure_skating_world_championship/,seismatica,1572061239,"I just finished a [project](https://medium.com/@seismatica/predicting-figure-skating-championship-ranking-from-season-performances-fc704fa7971a?source=friends_link&amp;sk=7e6b2992c6dd5e6e7e1803c574b4236d) whose goal is to predict the world championship ranking from previous scores in the season (for male and female single skaters).

The obvious way to rank skaters is to take their average score of the season and rank them from highest to lowest. However, one potential problem with this approach is that the scores are averaged over different events, and no two events are the same (think different judges, ice conditions, or event altitudes). Therefore, I came up with different ranking models that can somehow tease out the skater effect (how good a skater intrinsically) from the event effect (how does an event affect the score of a skater). The models themselves are essentially just simple linear models, but I'd never thought about using linear regression this way. 
I've also documented how my models perform over the baseline model, which is the average season score model mentioned above.

If you have any feedback or ideas on my project, please don't hesitate to let me know!

PS. I'm in the process of cleaning up the code that I used for the analysis, and will soon add the link to the Github repo in the write-up. I'm writing a part 2 on even more complicated models to rank skater and will post them here when I'm done writing it.",0,2,False,self,,,,,
1548,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,14,dn9qyh,self.MachineLearning,Are reported NLL scores an average across datapoints?,https://www.reddit.com/r/MachineLearning/comments/dn9qyh/are_reported_nll_scores_an_average_across/,knowledgelimit,1572068313,[removed],0,1,False,self,,,,,
1549,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,14,dn9u64,self.MachineLearning,[D] are reported NLL scores in papers an average across datapoints?,https://www.reddit.com/r/MachineLearning/comments/dn9u64/d_are_reported_nll_scores_in_papers_an_average/,knowledgelimit,1572068968,"Papers commonly report NLL scores, such as a value of around 3 for PixelCNN. I believe this is bits-per-dimension,

but, is it: 

a) an average across all the datapoints in the test set, or   
b) a sum across all datapoints, or   
c) the best score on an individual datapoint?

Or maybe my question makes not sense.

Explaining furher In the case of PixelCNN, ""datapoint"" = image, so I believe the NLL of trained model can be evaluated by summing the logs of the conditional probabilities of each pixel (conditioned on the neighborhood in the pixelcnn scheme), plus the marginal probability for the first pixel.  This gives the overall LL for a single image from the test set, but what about the other images.",1,2,False,self,,,,,
1550,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,14,dn9wcs,self.MachineLearning,Which person would you recommend to follow on Twitter?,https://www.reddit.com/r/MachineLearning/comments/dn9wcs/which_person_would_you_recommend_to_follow_on/,mrconter1,1572069411,[removed],0,1,False,self,,,,,
1551,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,15,dna9no,self.MachineLearning,classify thousands of files to thousands of categories using DC/RF?,https://www.reddit.com/r/MachineLearning/comments/dna9no/classify_thousands_of_files_to_thousands_of/,Rubyakerman,1572072057,[removed],0,1,False,self,,,,,
1552,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,16,dnanrv,trumptraveling.blogspot.com,"Facebook FAIR Research Intern, Artificial Intelligence",https://www.reddit.com/r/MachineLearning/comments/dnanrv/facebook_fair_research_intern_artificial/,qikpal,1572074958,,0,1,False,default,,,,,
1553,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,18,dnbj8l,self.MachineLearning,Selecting features for malware analysis,https://www.reddit.com/r/MachineLearning/comments/dnbj8l/selecting_features_for_malware_analysis/,fireflav,1572081328,"I am trying to build a classifier that detects if I have a malaware by predicting the provenance compiler. To do so I have a dataset composed of assembly code in json format :

&amp;#x200B;

\[!\[enter image description here\]\[1\]\]\[1\]

&amp;#x200B;

&amp;#x200B;

In particular, I want to select as features the instructions, so the push, mov, jmp,..etc and create a feature vector that contains the number of times a feature appears. So, I want to apply the bag of words. To do so my code is the following:

&amp;#x200B;

`#libraries`

`import numpy as np`

`import pandas as pd`

`import json as j`

`import re`

`import nltk`

`from nltk.tokenize import word_tokenize`

&amp;#x200B;

`from sklearn.model_selection import train_test_split`

`from sklearn.feature_extraction.text import CountVectorizer`

`from sklearn.naive_bayes import *`

`from sklearn.metrics import confusion_matrix, classification_report`

`from sklearn import svm`

&amp;#x200B;

`#for visualizing data`

`import matplotlib.pyplot as plt`

`import seaborn as sns; sns.set(font_scale=1.2)`

&amp;#x200B;

`%matplotlib inline`

&amp;#x200B;

`json_data = None;`

`with open('training_dataset.jsonl') as data_file:`

`lines = data_file.readlines()`

`joined_lines = ""["" + "","".join(lines)+""]""`



`json_data = j.loads(joined_lines)`  

&amp;#x200B;

`data = pd.DataFrame(json_data)`

`data.head()`

&amp;#x200B;

   

&amp;#x200B;

`vect = CountVectorizer()`

&amp;#x200B;

`data['instructions'] = data['instructions'].apply(lambda x: ' '.join(x))`

&amp;#x200B;

`vect.fit_transform(data['instructions'])`

&amp;#x200B;

`a =vect.vocabulary_`

`a`

&amp;#x200B;

and from this I obtain a dictionary:

&amp;#x200B;

\[!\[enter image description here\]\[2\]\]\[2\]

&amp;#x200B;

with more and more key, value pairs. At this point what I tried to do is to eliminate the registers so my idea to do this is to iterate the dictionary and eliminate the keys that have numbers, and so I have written the following:

&amp;#x200B;

`def hasNumbers(inputString):`

`return any(char.isdigit() for char in inputString)`

&amp;#x200B;

`for k in list(a.keys()):`

`if hasNumbers(k):`

`del a[k]`

&amp;#x200B;

but actually it wasn't a really good idea because I have also registers without numbers, for example rdi.

&amp;#x200B;

At this point, I don't know how to move, and I am not sure I am going in the correct way. Can somebody please help me? Thank's in advance.

&amp;#x200B;

\[EDIT 2\] 

Now I am trying to take the json file, not opening it with pandas, but open it as a dictionary, so:

&amp;#x200B;

&amp;#x200B;

\[!\[enter image description here\]\[3\]\]\[3\]

&amp;#x200B;

and my intenction is try to split, as suggested, each key in such a way to eliminate the registers. So, my code for this is :

&amp;#x200B;

`for key in json_data:`

`splitted = key.split[0]`

&amp;#x200B;

but I recieve the following error message:

&amp;#x200B;

`AttributeError: 'dict' object has no attribute 'split'`

&amp;#x200B;

&amp;#x200B;

I am getting really confused about how to operate now.

&amp;#x200B;

\[EDIT 3\] or I tried to do the following:

&amp;#x200B;

`for v in json_data.values():`

`splitted = v.split[0]`

&amp;#x200B;

but it gives me the following error message:

&amp;#x200B;

`AttributeError: 'list' object has no attribute 'values'`

&amp;#x200B;

a problem I think is the fact that the various push r12,.. etc are in a list, so I don't know how to do.

&amp;#x200B;

\[EDIT 4\] I actually tried to solve the above problem this way:

&amp;#x200B;

`for v in json_data[0].values():`

`splitted = v.split[0]`

&amp;#x200B;

&amp;#x200B;

but again I get the error message:

&amp;#x200B;

`AttributeError: 'list' object has no attribute 'split'`

&amp;#x200B;

&amp;#x200B;

  \[1\]: [https://i.stack.imgur.com/sfq6y.png](https://i.stack.imgur.com/sfq6y.png)

  \[2\]: [https://i.stack.imgur.com/z8Bxx.png](https://i.stack.imgur.com/z8Bxx.png)

  \[3\]: [https://i.stack.imgur.com/Py0pV.png](https://i.stack.imgur.com/Py0pV.png)",0,1,False,self,,,,,
1554,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,18,dnblpi,self.MachineLearning,I'm making a chatbot that is meant to answer queries on the behalf of the HR department. But i can't find a dataset to train my model. Can anyone help me out in it?,https://www.reddit.com/r/MachineLearning/comments/dnblpi/im_making_a_chatbot_that_is_meant_to_answer/,khan166,1572081805,[removed],0,1,False,self,,,,,
1555,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,18,dnbltf,self.MachineLearning,What machine learning algorithm should I use for movie recommendation?,https://www.reddit.com/r/MachineLearning/comments/dnbltf/what_machine_learning_algorithm_should_i_use_for/,nm00002,1572081824,[removed],0,1,False,self,,,,,
1556,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,19,dnc519,twitter.com,[D] GPT-2 re-trained on book review blog generates hilarious content,https://www.reddit.com/r/MachineLearning/comments/dnc519/d_gpt2_retrained_on_book_review_blog_generates/,pavish73,1572085615,,0,1,False,default,,,,,
1557,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,21,dndfmi,self.MachineLearning,[D] Top academic research labs: Deep Learning,https://www.reddit.com/r/MachineLearning/comments/dndfmi/d_top_academic_research_labs_deep_learning/,alrojo,1572094131,"What are the best labs/PIs for Deep Learning (CV, NLP, Robotics included) right now?",8,8,False,self,,,,,
1558,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,22,dndvk5,gorp.app,"[P] I made Gorp - It Uses Computer Vision to Redact Protected User Data (PHI, PCI, PII) in Images 100% On Device",https://www.reddit.com/r/MachineLearning/comments/dndvk5/p_i_made_gorp_it_uses_computer_vision_to_redact/,jembytrevize1234,1572096588,,0,1,False,default,,,,,
1559,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,23,dnew3a,self.MachineLearning,Where do I start machine learning?,https://www.reddit.com/r/MachineLearning/comments/dnew3a/where_do_i_start_machine_learning/,Styeyr,1572101736,[removed],0,1,False,self,,,,,
1560,MachineLearning,t5_2r3gv,2019-10-26,2019,10,26,23,dnex4k,arxiv.org,Hillclimbing With Random Restarts Outperforms Evolutionary Algorithms,https://www.reddit.com/r/MachineLearning/comments/dnex4k/hillclimbing_with_random_restarts_outperforms/,mystikaldanger,1572101876,,1,2,False,default,,,,,
1561,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,0,dnf7vj,arxiv.org,[R] Hillclimbing With Random Restarts Outperforms Evolutionary Algorithms,https://www.reddit.com/r/MachineLearning/comments/dnf7vj/r_hillclimbing_with_random_restarts_outperforms/,mystikaldanger,1572103329,,14,52,False,default,,,,,
1562,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,0,dnfa3q,self.MachineLearning,How to derive gradient Descent for this error,https://www.reddit.com/r/MachineLearning/comments/dnfa3q/how_to_derive_gradient_descent_for_this_error/,ChaoliangLin,1572103621,[removed],0,1,False,https://a.thumbs.redditmedia.com/kVOfgmfdiWAIw8RdZ_AxG6DTBQmW3AWP5qE3UU095A8.jpg,,,,,
1563,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,0,dnfme7,self.MachineLearning,GPU or TPU when training models in Google Colab?,https://www.reddit.com/r/MachineLearning/comments/dnfme7/gpu_or_tpu_when_training_models_in_google_colab/,zimmer550king,1572105171,"Hi. I am training a convolutional neural network in Google Colab. I read online that for higher-dimensional data a TPU is more useful. However, I don't understand whether it is more useful for my current project where a single batch consists of 30 RGB images (each image is 800 by 600). Should I use TPU or continue with GPU?",0,1,False,self,,,,,
1564,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,2,dngoe1,self.iOSProgramming,Did Apple do a better job with on-device text recognition than Googles MLVision?,https://www.reddit.com/r/MachineLearning/comments/dngoe1/did_apple_do_a_better_job_with_ondevice_text/,omarmhaimdat,1572109778,,0,1,False,https://b.thumbs.redditmedia.com/PbCekFzYfkHtm6K-HcUzxQzoavK7Fh6RX21_6dGLOBo.jpg,,,,,
1565,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,2,dngpab,alexgrowsup.com,Improving Decision Trees for Greenhouse Climate Control Using Genetic Algorithms,https://www.reddit.com/r/MachineLearning/comments/dngpab/improving_decision_trees_for_greenhouse_climate/,Dorfkrug,1572109884,,0,1,False,https://b.thumbs.redditmedia.com/2ZmjNaqUE1DEVM72dTUR_oBebkp-Wg3ZP1buebKDC7A.jpg,,,,,
1566,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,2,dnguby,self.MachineLearning,The other side of the DeepFake War : Detection of Deep-Fakes Research,https://www.reddit.com/r/MachineLearning/comments/dnguby/the_other_side_of_the_deepfake_war_detection_of/,pranjalranjan299,1572110506,[removed],0,1,False,self,,,,,
1567,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,2,dngwmd,self.MachineLearning,What should be range of values of C and gamma while doing gridsearchcv ?,https://www.reddit.com/r/MachineLearning/comments/dngwmd/what_should_be_range_of_values_of_c_and_gamma/,mrtac96,1572110784,"I am trying value of C as 0.001 to 100, and value of gamma from 0.01 to 1. I want to know is it a fine range.? or value should not be so less?",0,1,False,self,,,,,
1568,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,2,dnh4rm,self.MachineLearning,Google's new way of recording,https://www.reddit.com/r/MachineLearning/comments/dnh4rm/googles_new_way_of_recording/,xXDarkCubeXx,1572111781,[removed],0,1,False,self,,,,,
1569,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,2,dnh9xx,i.redd.it,Visualizing First and Second Image Gradients. Dlib has built-in functionality for these gradients.,https://www.reddit.com/r/MachineLearning/comments/dnh9xx/visualizing_first_and_second_image_gradients_dlib/,mr_anonderson,1572112419,,1,1,False,https://b.thumbs.redditmedia.com/-UU7RVp51aA3yteoYUMPOP1iLDgwsLbnh2N5NUC1QsY.jpg,,,,,
1570,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,3,dnhgfs,self.MachineLearning,A question about Lipschitz restriction,https://www.reddit.com/r/MachineLearning/comments/dnhgfs/a_question_about_lipschitz_restriction/,rainto219,1572113252,"It has been proposed in WGAN that we can let the model meet the Lipschitz restriction by adding Weight Decay which guarantees that the output won't change much if the input changes a little bit. 

But in Image Classification, the adversarial  example generated by adding a small noise could even inverse the model's output classification result. Even if nowadays generally we add the Weight Decay during training the classification model. 

So my question is that why this will happen, that the output changes a lot when the input only changes a little bit, even if we have added the weight decay?",0,1,False,self,,,,,
1571,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,4,dnic1x,self.MachineLearning,[N] Newton vs the machine: solving the chaotic three-body problem using deep neural networks,https://www.reddit.com/r/MachineLearning/comments/dnic1x/n_newton_vs_the_machine_solving_the_chaotic/,aiismorethanml,1572117288,"&gt;Since its formulation by Sir Isaac Newton, the problem of solving the equations of motion for three bodies under their own gravitational force has remained practically unsolved. Currently, the solution for a given initialization can only be found by performing laborious iterative calculations that have unpredictable and potentially infinite computational cost, due to the system's chaotic nature. We show that an ensemble of solutions obtained using an arbitrarily precise numerical integrator can be used to train a deep artificial neural network (ANN) that, over a bounded time interval, provides accurate solutions at fixed computational cost and up to 100 million times faster than a state-of-the-art solver. Our results provide evidence that, for computationally challenging regions of phase-space, a trained ANN can replace existing numerical solvers, enabling fast and scalable simulations of many-body systems to shed light on outstanding phenomena such as the formation of black-hole binary systems or the origin of the core collapse in dense star clusters.

Paper: [arXiv](https://arxiv.org/abs/1910.07291)

Technology Review article: [A neural net solves the three-body problem 100 million times faster](https://www.technologyreview.com/s/614597/a-neural-net-solves-the-three-body-problem-100-million-times-faster/)",592,190,False,self,,,,,
1572,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,4,dnilgh,self.MachineLearning,"How is machine learning used in mapping software (google, Apple, ease, etc...)?",https://www.reddit.com/r/MachineLearning/comments/dnilgh/how_is_machine_learning_used_in_mapping_software/,Cjh411,1572118485,"
Is it a prominent component, or do they mostly rely on high performance graph (or other) algorithms?",0,1,False,self,,,,,
1573,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,4,dniuxv,self.MachineLearning,How is machine learning used in mapping software (e.g. google maps)?,https://www.reddit.com/r/MachineLearning/comments/dniuxv/how_is_machine_learning_used_in_mapping_software/,Cjh411,1572119681,"
Is it a prominent component, or do they mostly rely on high performance graph (or other) algorithms?",0,1,False,self,,,,,
1574,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,6,dnjrqy,self.MachineLearning,Is this a good analogy to explain machine learning?,https://www.reddit.com/r/MachineLearning/comments/dnjrqy/is_this_a_good_analogy_to_explain_machine_learning/,Guyserbun007,1572123948,[removed],0,1,False,self,,,,,
1575,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,6,dnjzx4,self.MachineLearning,"Help with the deep learning, AI and prediction start up...",https://www.reddit.com/r/MachineLearning/comments/dnjzx4/help_with_the_deep_learning_ai_and_prediction/,tomaszmita,1572125004,[removed],0,1,False,self,,,,,
1576,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,9,dnlx43,i.redd.it,Was trying to think of my own way to generate a hypothesis function for a data set to fit a sum of cosines. Does something like this already exist? Explanation in the comments,https://www.reddit.com/r/MachineLearning/comments/dnlx43/was_trying_to_think_of_my_own_way_to_generate_a/,20gunasarj,1572134440,,1,1,False,default,,,,,
1577,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,9,dnlzf0,self.MachineLearning,[D] FYI Machine Learning Conference (MLconf) in San Francisco 11/8,https://www.reddit.com/r/MachineLearning/comments/dnlzf0/d_fyi_machine_learning_conference_mlconf_in_san/,KernalTrick,1572134848,"Just wanted to raise awareness and get discussion going if anyone wants to meet up at [MLconf ](http://mlconf.com/)(next next Friday, November 8th).  Talks will cover topics such as: NLP, Voice Agents, ML &amp; Medical Research, ML &amp; Quantum Computing, ML Models, Data Science for Good, etc. 

If you're not going to be in San Francisco then you can also check out past sessions (going back to 2012) here: [https://mlconf.com/sessions/](https://mlconf.com/sessions/).  

If you do want to be there I'd suggest going to [eventbrite](https://mlcsf19.eventbrite.com?discount=xc20) instead of their website since there's a discount.  Below are the speakers and the topic they'll speak on (if I could find it):

2019 MLconf SFSpeakers:

* Franziska Bell, Senior Data Science Manager on the Platform Team, Uber - Opening Remarks
* Anitha Kannan, Founding Member, Curai -  AI for healthcare: Scaling Access and Quality of Care for Everyone 
* Xavier Amatriain, CTO, Curai -  AI for healthcare: Scaling Access and Quality of Care for Everyone 
* Mihajlo Grbovic, Principal Machine Learning Scientist, Airbnb
* Josh Wills, Software Engineer, Slack - Data Labeling as Religious Experience 
* Ted Willke, Sr. Principal Engineer, Intel
* Jekaterina Novikova, Director of Machine Learning, Winterlight Labs -  Machine Learning Methods in Detecting Alzheimers Disease from Speech and Language 
* Bradley Voytek, Associate Professor, UCSD - The Art of Parameterization 
* June Andrews, AI Instruments, Stitch Fix - The Uncanny Valley of ML 
* Sneha Rajana, Software Development Engineer, Amazon - Deep Learning Architectures for Semantic Relation Detection Tasks 
* Noam Finkelstein, PhD Student, Johns Hopkins University - The Importance of Modeling Data Collection 
* Anoop Deoras, Researcher, Netflix -  Building an Incrementally Trained, Local Taste Aware, Global Deep Learned Recommender System Model 
* Jamila Smith-Loud, User Researcher, Google
* Justin Armstrong, Senior Backend Engineer - Applied ML, Compology - Applying Computer Vision to Reduce Contamination in the Recycling Stream 
* Igor Markov, Facebook/ Professor, University of Michigan
* Vinay Prabhu, Chief Scientist, UnifyID Inc - Project GaitNet: Ushering in the ImageNet moment for human Gait kinematics 
* Meghanna Ravikumar, Machine Learning Engineer, SigOpt - Optimized Image Classification on the Cheap 
* Martin Isaksson, Co-Founder, PerceptiLabs

Sponsors: PerceptiLabs, Oracle, Apple, Proofpoint, HiringSolved, SigOpt, Medium, Walmart Labs, Compology. 

Personally, I'm most looking forward to the healthcare applications they'll go over, but I'm also curious what ""Data Labeling as a Religious Experience"" means.",2,10,False,self,,,,,
1578,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,9,dnmdns,self.MachineLearning,Chromebook + Google Cloud = a viable ML/DL machine?,https://www.reddit.com/r/MachineLearning/comments/dnmdns/chromebook_google_cloud_a_viable_mldl_machine/,Serinous,1572136978,[removed],0,1,False,self,,,,,
1579,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,10,dnmxqk,self.MachineLearning,What if I told you that I found a way for people to train their ML models while mining criptocurrency? #StartupWeekend,https://www.reddit.com/r/MachineLearning/comments/dnmxqk/what_if_i_told_you_that_i_found_a_way_for_people/,sculacchia4,1572140005,[removed],0,1,False,self,,,,,
1580,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,10,dnn2lq,youtube.com,"Will we ever get a ""World Artificial Intelligence Day"" holiday?",https://www.reddit.com/r/MachineLearning/comments/dnn2lq/will_we_ever_get_a_world_artificial_intelligence/,ProgrammingGodJordan,1572140744,,0,1,False,default,,,,,
1581,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,13,dnok5m,self.MachineLearning,What is Machine Learning ? Machine Learning Example &amp; Machine Learning Solution?,https://www.reddit.com/r/MachineLearning/comments/dnok5m/what_is_machine_learning_machine_learning_example/,risicai,1572149497,[removed],0,1,False,self,,,,,
1582,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,15,dnpnh6,self.MachineLearning,Neural networks vector notation,https://www.reddit.com/r/MachineLearning/comments/dnpnh6/neural_networks_vector_notation/,grid_world,1572156936,[removed],0,1,False,self,,,,,
1583,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,15,dnpqea,technologyreview.com,A neural net solves the three-body problem 100 million times faster,https://www.reddit.com/r/MachineLearning/comments/dnpqea/a_neural_net_solves_the_threebody_problem_100/,bit-man,1572157543,,0,1,False,https://b.thumbs.redditmedia.com/UPLgYz_XySRjL6XE5d3XIDRiMJgZKKgoBCbQ7E-mzDE.jpg,,,,,
1584,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,17,dnqn89,technologyreview.com,A neural net solves the three-body problem 100M times faster,https://www.reddit.com/r/MachineLearning/comments/dnqn89/a_neural_net_solves_the_threebody_problem_100m/,HN_Crosspost_Bot,1572164749,,0,1,False,https://b.thumbs.redditmedia.com/UPLgYz_XySRjL6XE5d3XIDRiMJgZKKgoBCbQ7E-mzDE.jpg,,,,,
1585,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,18,dnr7el,self.MachineLearning,[P] ARIMA vs LSTM - Forecasting Weekly Hotel Cancellations,https://www.reddit.com/r/MachineLearning/comments/dnr7el/p_arima_vs_lstm_forecasting_weekly_hotel/,plentyofnodes,1572169292,"Over the past while, I've been working on a side project to forecast hotel cancellations on a weekly basis (original data and authors available [here](https://www.sciencedirect.com/science/article/pii/S2352340918315191)).

While the original intent of this research was to identify the drivers of such cancellations and predict whether customers would cancel using classification (i.e. cancelling customer = 1, non-cancelling customer = 0), I wanted to investigate whether time series forecasting could be a good addition to this study.

The first step was using pandas for data manipulation, i.e. sorting the cancellations by week and then summing up to get the total number of cancellations every week.

Following this, I decided to use both ARIMA and LSTM to predict future cancellations across the test set. This was done for two separate hotel datasets (H1 and H2).

Interestingly, I found that LSTM performed better on the more volatile dataset (H2), while ARIMA showed more forecast accuracy on the dataset with a smoother trend (H1).

Ultimately, doing this project reinforced to me that machine learning models like LSTM are just like any other model - they are not necessarily suitable for all situations, and one needs to understand the data they are working with before selecting the model.

If you're interested in the findings, feel free to take a further look. It is a three-part study, but here are the relevant links below:

\- [LSTM Forecasts](https://www.michael-grogan.com/hotel-cancellations-lstm/)

\- [ARIMA Forecasts](https://www.michael-grogan.com/hotel-cancellations/) (first half of the article covers classification with SVM)

Hope you find this of use, and grateful for any feedback!",52,150,False,self,,,,,
1586,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,19,dnrcqn,self.MachineLearning,[D] Can dense network perform as good as any other architecture?,https://www.reddit.com/r/MachineLearning/comments/dnrcqn/d_can_dense_network_perform_as_good_as_any_other/,HDidwania,1572170479,"In a project I am working on currently, team got into a discussion over shall we go for Dense MLP or CNN? That discussion sort of made me wonder the question, ""Can Dense MLP work as good as any other architecture (CNN, GCN) for every task?""
A proper way of putting it will be, given we are able to properly train a huge dense network with enough expressive power for the task, and we have enough data for proper training, can a dense network perform as good as other network architecture, in theory?
From what I understand, different architectures are just different ways of pooling/sharing information and feature extraction. The functions that can be realised by any network should also be realisable by some configuration of Dense network.",13,2,False,self,,,,,
1587,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,19,dnrfk8,self.MachineLearning,[D] What are the potential applications of a hypothetical Object Structure Estimation Model,https://www.reddit.com/r/MachineLearning/comments/dnrfk8/d_what_are_the_potential_applications_of_a/,theneuralbeing,1572171058," 

Hi,

Lately I have been trying to control a robot with a puppet (kinda like a voodoo doll) and want to estimate the keypoints on the puppet to recognize the orientation of the head and the wheels so that I can transfer that as commands to the robot. I couldn't find anything online about estimating keypoints on custom objects.

So that made me think that if a model could exist that can estimate the structural skeleton of objects, what could be it's potential applications?

One application I can think of is recognizing the orientation of objects and not just detecting them in an image with a bounding box. What more could it be used for?

What are your opinions/thoughts on this?

p.s. I am thinking of this as my thesis for a research paper but just wanted to make sure it is something worth spending time for and knowing its potential applications.",3,4,False,self,,,,,
1588,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,19,dnrien,lukeoakdenrayner.wordpress.com,The FDA has approved AI-based PET/MRI denoising. How safe is this technology?,https://www.reddit.com/r/MachineLearning/comments/dnrien/the_fda_has_approved_aibased_petmri_denoising_how/,gosnold,1572171673,,1,1,False,default,,,,,
1589,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,20,dns8i9,self.MachineLearning,Network Architecture for grid data?,https://www.reddit.com/r/MachineLearning/comments/dns8i9/network_architecture_for_grid_data/,Driiper,1572177051,[removed],0,1,False,self,,,,,
1590,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,21,dnsbnw,lppier.github.io,NLP in a Hurry!,https://www.reddit.com/r/MachineLearning/comments/dnsbnw/nlp_in_a_hurry/,lppier,1572177689,,0,1,False,https://b.thumbs.redditmedia.com/X0IzazjL3An0xDmSNxXZ5QSxmB-ZUT7sJu5jy_NoW-M.jpg,,,,,
1591,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,21,dnsfbr,self.MachineLearning,[D] Which cloud service lets you use GPUs with VRAM higher than 16Go ?,https://www.reddit.com/r/MachineLearning/comments/dnsfbr/d_which_cloud_service_lets_you_use_gpus_with_vram/,gohu_cd,1572178346,"Hello, 

Pretty self-explanatory, I checked on AWS and Google Cloud and I did not find any cloud instance equipped with GPUs with higher than 16Go RAM. Please do correct me if I'm wrong for those two platforms and indicate other services where I could find GPUs with lots of VRAM.

Thanks !",1,0,False,self,,,,,
1592,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,21,dnsht4,self.MachineLearning,Is there any reason why over-sampling might lead to better result than using weights for the optimizer ?,https://www.reddit.com/r/MachineLearning/comments/dnsht4/is_there_any_reason_why_oversampling_might_lead/,elcric_krej,1572178787,[removed],0,1,False,self,,,,,
1593,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,21,dnsie3,self.MachineLearning,Is there a reason why over-sampling might perform better than using weights for your loss function ?,https://www.reddit.com/r/MachineLearning/comments/dnsie3/is_there_a_reason_why_oversampling_might_perform/,elcric_krej,1572178888,"Possibly stupid question, but, I've noticed this rather strange behavior lately, and I assume it's a bug/logic-error of sorts, but I can't find the root cause, so I'm wondering if any people here might have an explanation for why this might happen.

&amp;#x200B;

Given a dataset where the target variable has C unevenly represented classes (let's stick to C==2) for now and wanting to train a model that has similar accuracy for all C classes, I can think of two ways of going about it:

&amp;#x200B;

a) Over-sample the data until the target variable is evenly distributed. Which seems theoretically sound but might lead to pointlessly long training time

&amp;#x200B;

b) Use weights for your Loss function, e.g. assume we're assuing pytroch+CE loss, and target 1 appears \`t1\` times whilst target 2 appears \`t2\` time I'd declare the optimizer as \`CrossEntropyLoss(weight=\[1/t1,1/t2\] ... reduction='mean')\`

&amp;#x200B;

I've tried this with multiple loss functions that support weights and I \*think\* the logic is correct, on datasets where the model reaches a very high accuracy on the validation data or where the occurrence of most categories is fairly even to being with it seems to perform about as well as over-sampling.

&amp;#x200B;

However, the approach seems to work poorly (compared to over-sampling) for situations where the target category weights are really far apart (e.g. one weight is 1/50, the other is 1/5000). But assuming that my batch size is a number close to \`large\_weight/small\_weight\` (so, in this example, assuming my batch size is, say, bigger than 50) it seems intuitive that this shouldn't matter.

&amp;#x200B;

Even if some batches are over-biased towards one class this bias should correct itself out over multiple backprops, since the chance of a sequence of batches containing only one class is very small (otherwise I could see issues if the model got a few dozens or hundred of batches with only the highest occurrence classes).

&amp;#x200B;

Is there a reason why this should be ? Assuming that my stop-condition for both cases is that the model stops improving on a separate testing dataset after a significantly large number of iterations, rather than a time/nr-epoches based condition (in which case I could see how an over-sample dataset might explain the difference).",0,1,False,self,,,,,
1594,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,21,dnsrde,self.MachineLearning,Video Analysis on a video with constant background,https://www.reddit.com/r/MachineLearning/comments/dnsrde/video_analysis_on_a_video_with_constant_background/,ssidharth001,1572180463,I want to know how we can reduce data of video with constant background by taking only  the moving objects and fixing the background,0,1,False,self,,,,,
1595,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,21,dnsvh8,self.MachineLearning,[N] Interview with Hamel Husain on semantic code search research at GitHub,https://www.reddit.com/r/MachineLearning/comments/dnsvh8/n_interview_with_hamel_husain_on_semantic_code/,Jefro118,1572181123,"""We hope that the community can use this dataset to improve developer tools generally, which may include semantic code search. We hope that the state of the art with regards to representation learning of code is advanced because researchers and practitioners now have a common dataset and a forum in which to discuss results. We also hope that the uniqueness of the dataset will inspire the community to uncover new approaches and techniques for code and natural language understanding.""

That's a quote from the one of the authors of CodeSearchNet - datasets, tools, and benchmarks for representation learning of code. This research on semantic code search has been posted here before as news, but I thought some people here might be interested to know some of the details behind what goes into a project like this at a big company. I interviewed Hamel Husain, a machine learning engineer at GitHub about how the project started and evolved into a wider open source effort to involve the ML research community. Hope there are useful takeaways for people here.

Here's a link to the interview: [https://sourcesort.com/interview/hamel-husain-on-semantic-code-search](https://sourcesort.com/interview/hamel-husain-on-semantic-code-search)

And here's a link to the original paper on arXiv: [https://arxiv.org/abs/1909.09436](https://arxiv.org/abs/1909.09436)",2,10,False,self,,,,,
1596,MachineLearning,t5_2r3gv,2019-10-27,2019,10,27,22,dnt97i,self.MachineLearning,Does PyTorch change interface frequently?,https://www.reddit.com/r/MachineLearning/comments/dnt97i/does_pytorch_change_interface_frequently/,iCEChEshirE,1572183125,"I've been using keras for a while but with the frequent changes made to tensorflow, keras code doesn't look very safe to use now. I got a lot of api compatibility problems and some of my pipelines doesn't converge models anymore. Does PyTorch keep constant api interface and have nice backward compatibility? I mean like you can literaly use the code years ago and not have any error. If that's the case I want to switch api. Thanks.",0,1,False,self,,,,,
1597,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,0,dnupkc,github.com,"[P] numeri, a JS numerical library for client-side tensor math. Uses flat arrays, O(1) transpose and slicing, dynamic code generation for optimal performance, and even some eigen problems",https://www.reddit.com/r/MachineLearning/comments/dnupkc/p_numeri_a_js_numerical_library_for_clientside/,mwlon,1572189467,,0,1,False,default,,,,,
1598,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,0,dnv48s,self.MachineLearning,[R] Few-Shot Video-to-Video Synthesis,https://www.reddit.com/r/MachineLearning/comments/dnv48s/r_fewshot_videotovideo_synthesis/,PuzzledProgrammer3,1572191102,"paper: [https://nvlabs.github.io/few-shot-vid2vid/main.pdf](https://nvlabs.github.io/few-shot-vid2vid/main.pdf)

repo: [https://github.com/NVlabs/few-shot-vid2vid](https://github.com/NVlabs/few-shot-vid2vid)",7,31,False,self,,,,,
1599,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,0,dnv5h2,self.MachineLearning,Correlation between Tags and Topics,https://www.reddit.com/r/MachineLearning/comments/dnv5h2/correlation_between_tags_and_topics/,Abraheam,1572191255,[removed],0,1,False,self,,,,,
1600,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,1,dnvuj5,self.MachineLearning,[P] AdamWR Full Keras + TF-Keras Implementation Available,https://www.reddit.com/r/MachineLearning/comments/dnvuj5/p_adamwr_full_keras_tfkeras_implementation/,OverLordGoldDragon,1572194139,"A followup to [original post](https://www.reddit.com/r/MachineLearning/comments/dc0vji/p_adamwr_keras_full_implementation_available/) (pasted shortened below), with major changes; release v1.1:

 - Run-based weight decay normalization scheme, normalizing over arbitrary # of iterations independent of LR scheduler (e.g. over all epochs)
 - Full compatibility with TensorFlow 2.0.0 and Keras 2.3.0 (`keras` \+ `tensorflow.keras`)
 - Full compatibility with TensorFlow 1.14.0 and Keras 2.2.5 (`keras` \+ `tensorflow.keras`)
 - Also compatible w/ TF 1.13.0 &amp; 1.15.0, Keras 2.2.3-2.2.4

For a complete list of changes, see [release notes](https://github.com/OverLordGoldDragon/keras-adamw/releases/tag/v1.1).

&lt;hr&gt;

The latest Lookahead optimizer paper, co-authored by Geoffrey Hinton, used AdamW as its base optimizer, and noted it performing superior to plain Adam. It includes NadamW and SGDW, and their WR (Warm Restart) counterparts - with cosine annealing learning rate schedule, and per layer learning rate multipliers (useful for pretraining). 

All optimizers are well-tested, and for me have yielded &lt;b&gt;3-4% F1-score improvements&lt;/b&gt; in already-tuned models for seizure classification. Up to date with Keras 2.3.0.",1,8,False,self,,,,,
1601,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,1,dnvzke,self.MachineLearning,Correlation between Tags and Topics,https://www.reddit.com/r/MachineLearning/comments/dnvzke/correlation_between_tags_and_topics/,Abraheam,1572194696,"For any certain topic T in Stack Overflow/Exchange, how we can get a set of tags \[tag1\]\[tagn\] related to that topic that will give us the most number of questions related to that topic? For example, for a topic such as actor programming in Scala, \[scala\] \[actor\] \[akka\] will give us the most number of questions related to that topic (around 700 questions), but any more tags added will reduce that number, for instance \[scala\] \[actor\] \[akka\] \[sharding\].

I have tried a simple search, co-occurrence matrix and running queries using SEDE but that does not work as this is manual and you should try many different possibilities. Is there any automated process to help to do this problem? I know that this question is a little confusing as tags are supposed to narrow a topic but here the topic is supposed to narrow the tags somehow.

Thank you for reading the question.",0,1,False,self,,,,,
1602,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,2,dnwqn2,self.MachineLearning,Whats after Hands on ML book?,https://www.reddit.com/r/MachineLearning/comments/dnwqn2/whats_after_hands_on_ml_book/,somekoreanhusky,1572197896,[removed],0,1,False,self,,,,,
1603,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,3,dnx2cc,self.MachineLearning,How does BERT handle Entity (People) Names?,https://www.reddit.com/r/MachineLearning/comments/dnx2cc/how_does_bert_handle_entity_people_names/,uyt2190,1572199303,[removed],0,1,False,self,,,,,
1604,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,4,dny6kv,self.MachineLearning,"[D] Does The Inability Of NAS Algorithms To Outperform Random Search Indicate That Our Algorithms Suck, Or That Random Search Is Surprisingly Effective In Large Spaces?",https://www.reddit.com/r/MachineLearning/comments/dny6kv/d_does_the_inability_of_nas_algorithms_to/,mystikaldanger,1572204056,"One of the most counterintuitive developments in ML research is that, despite huge amounts of resources and brain power being poured into field, [state-of-the-art neural architecture search algorithms still can't outperform pure random search](https://arxiv.org/abs/1902.08142).  

This fact is so jarring that I'm surprised it's not being talked about more often.

What exactly does this mean? Are we just putting out ineffective automl  algorithms, or has the power of random search been completely overlooked?",28,32,False,self,,,,,
1605,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,4,dny83w,neuraxio.com,How to Code Neat Machine Learning Pipelines,https://www.reddit.com/r/MachineLearning/comments/dny83w/how_to_code_neat_machine_learning_pipelines/,GChe,1572204243,,0,1,False,default,,,,,
1606,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,4,dny8hw,self.MachineLearning,How do I get started?,https://www.reddit.com/r/MachineLearning/comments/dny8hw/how_do_i_get_started/,Stale0,1572204286,[removed],0,1,False,self,,,,,
1607,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,4,dnyhf4,self.MachineLearning,"[R] Stanford NLP just released a model for question -&gt; document retrieval -&gt; query generation -&gt; gold document retrieval -&gt; gold answer retrieval. [Spoiler, through dataset generation]",https://www.reddit.com/r/MachineLearning/comments/dnyhf4/r_stanford_nlp_just_released_a_model_for_question/,BatmantoshReturns,1572205825,"https://twitter.com/stanfordnlp/status/1188504217855479808

http://ai.stanford.edu/blog/answering-complex-questions/

https://arxiv.org/pdf/1910.07000.pdf

The most interesting part is that based on the question, it will look up documents, and based on the question and information in the first set of retrieved documents, itll generate new queries to look up and find the exact document which as the answer. The concept itself isnt new; its been a goal for the NLP/ML community for a while, but Stanford was able to do it by creating a dataset (not sure if thats the entirely right word, they used query generation supervision signal) of these generated queries.

They generated the gold candidate queries by finding overlap of the content of the first set of retrieved content, and content of the the text that contains the answer. In their own words (and I think this is the most important part of the paper):

&gt;  computing the longest common string/sequence between the current retrieval context and the title/text of the intended paragraph ignoring stop words, then taking the contiguous span of text that corresponds to this overlap in the retrieval context.

Final thoughts: I love this paper. Im really interested in dataset generation using very accurate / robust heuristics and models. I think these datasets can be used to trained some very effective language models for information retrieval. I am currently working on a project like this; Im currently processing a dataset for research paper retrieval, https://github.com/Santosh-Gupta/Arxiv-Manatee-PublicUpdates . I update the Readme with questions and problems I run into through the project. If you have any insight to these, please give feedback through opening a new issue.",0,1,False,spoiler,,,,,
1608,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,5,dnylzb,self.MachineLearning,Can anyone please help with setting up and running gpt2 on my local machine? I've looked up several tutorials and haven't been successful at all. Any guidance would be highly appreciated.,https://www.reddit.com/r/MachineLearning/comments/dnylzb/can_anyone_please_help_with_setting_up_and/,leadfoot19,1572206556,,10,0,False,self,,,,,
1609,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,5,dnys2k,self.MachineLearning,[R] Stanford NLP just released a model for question -&gt; document retrieval -&gt; query generation -&gt; gold document retrieval -&gt; gold answer retrieval.,https://www.reddit.com/r/MachineLearning/comments/dnys2k/r_stanford_nlp_just_released_a_model_for_question/,BatmantoshReturns,1572207464,"https://twitter.com/stanfordnlp/status/1188504217855479808
http://ai.stanford.edu/blog/answering-complex-questions/

https://arxiv.org/pdf/1910.07000.pdf

The most interesting part is that based on the question, it will look up documents, and based on the question and information in the first set of retrieved documents, itll generate new queries to look up and find the exact document which as the answer. The concept itself isnt new; its been a goal for the NLP/ML community for a while, but Stanford was able to do it by creating a dataset (not sure if thats the entirely right word, they used query generation supervision signal) of these generated queries.

They generated the gold candidate queries by finding overlap of the content of the first set of retrieved content, and content of the the text that contains the answer. In their own words (and I think this is the most important part of the paper):

 computing the longest common string/sequence between the current retrieval context and the title/text of the intended paragraph ignoring stop words, then taking the contiguous span of text that corresponds to this overlap in the retrieval context.

Final thoughts: I love this paper. Im really interested in dataset generation using very accurate / robust heuristics and models. I think these datasets can be used to trained some very effective language models for information retrieval. I am currently working on a project like this; Im currently processing a dataset for research paper retrieval.",0,1,False,self,,,,,
1610,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,6,dnzbio,self.MachineLearning,[R] Stanford NLP just released a model for question -&gt; document retrieval -&gt; query generation -&gt; gold document retrieval -&gt; gold answer retrieval.,https://www.reddit.com/r/MachineLearning/comments/dnzbio/r_stanford_nlp_just_released_a_model_for_question/,BatmantoshReturns,1572211049,"https://twitter.com/stanfordnlp/status/1188504217855479808 

https://arxiv.org/pdf/1910.07000.pdf

The most interesting part is that based on the question, it will look up documents, and based on the question and information in the first set of retrieved documents, itll generate new queries to look up and find the exact document which as the answer. The concept itself isnt new; its been a goal for the NLP/ML community for a while, but Stanford was able to do it by creating a dataset (not sure if thats the entirely right word, they used query generation supervision signal) of these generated queries.

They generated the gold candidate queries by finding overlap of the content of the first set of retrieved content, and content of the the text that contains the answer. In their own words (and I think this is the most important part of the paper):

 computing the longest common string/sequence between the current retrieval context and the title/text of the intended paragraph ignoring stop words, then taking the contiguous span of text that corresponds to this overlap in the retrieval context.

Final thoughts: I love this paper. Im really interested in dataset generation using very accurate / robust heuristics and models. I think these datasets can be used to trained some very effective language models for information retrieval. I am currently working on a project like this; Im currently processing a dataset for research paper retrieval.",0,1,False,self,,,,,
1611,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,6,dnzcy5,self.MachineLearning,[R] Stanford NLP just released a model for question -&gt; document retrieval -&gt; query generation -&gt; gold document retrieval -&gt; gold answer retrieval.,https://www.reddit.com/r/MachineLearning/comments/dnzcy5/r_stanford_nlp_just_released_a_model_for_question/,BatmantoshReturns,1572211346,"https://arxiv.org/abs/1910.07000

The most interesting part is that based on the question, it will look up documents, and based on the question and information in the first set of retrieved documents, itll generate new queries to look up and find the exact document which as the answer. The concept itself isnt new; its been a goal for the NLP/ML community for a while, but Stanford was able to do it by creating a dataset (not sure if thats the entirely right word, they used query generation supervision signal) of these generated queries.

They generated the gold candidate queries by finding overlap of the content of the first set of retrieved content, and content of the the text that contains the answer. In their own words (and I think this is the most important part of the paper):

 computing the longest common string/sequence between the current retrieval context and the title/text of the intended paragraph ignoring stop words, then taking the contiguous span of text that corresponds to this overlap in the retrieval context.

Final thoughts: I love this paper. Im really interested in dataset generation using very accurate / robust heuristics and models. I think these datasets can be used to trained some very effective language models for information retrieval. I am currently working on a project like this; Im currently processing a dataset for research paper retrieval.",9,167,False,self,,,,,
1612,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,6,dnzf90,youtube.com,"Garry Kasparov on Chess, Deep Blue, AI, and Putin",https://www.reddit.com/r/MachineLearning/comments/dnzf90/garry_kasparov_on_chess_deep_blue_ai_and_putin/,liqui_date_me,1572211816,,0,1,False,default,,,,,
1613,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,6,dnzimd,self.MachineLearning,[P] Fast Super Resolution GAN,https://www.reddit.com/r/MachineLearning/comments/dnzimd/p_fast_super_resolution_gan/,abnormdist,1572212499,"I've been super intrigued by image super resolution problems. Reading online, I found the SRGAN paper to be interesting, especially how the PSNR and SSIM metrics are unreliable when compared to human perception of quality. I wanted to create a faster version of the SRGAN, so I decided to use a MobileNet as the generator. This idea is somewhat inspired by \[Realtime Image Enhancement, Galteri et al.\]([http://www.micc.unifi.it/seidenari/wp-content/papercite-data/pdf/caip\_2019.pdf](http://www.micc.unifi.it/seidenari/wp-content/papercite-data/pdf/caip_2019.pdf)). I want to use it to upsample low quality videos, for scenarios when you may not have access to high speed internet. You can leverage the GPU to do synthetic super resolution. I would appreciate any ideas towards increasing speed/quality of this project.

Here is the implementation in Tensorflow 2.0: \[Fast-SRGAN\]([https://github.com/HasnainRaz/Fast-SRGAN](https://github.com/HasnainRaz/Fast-SRGAN)). Take a look, and feedback is really appreciated!",31,56,False,self,,,,,
1614,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,6,dnzkzs,self.MachineLearning,Generate syntetic dataset using GANs,https://www.reddit.com/r/MachineLearning/comments/dnzkzs/generate_syntetic_dataset_using_gans/,aka-uco,1572212911,"In short words, is it possible to generate a dataset using GANs? 

Let's say, I've created a dataset for an ice cream pictures with 2 groups. One with 3D model-based generation, another one with the real pictures, but need more.   
Could it be possible to generate via GANs?",2,1,False,self,,,,,
1615,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,7,dnzz90,self.MachineLearning,[D] What's the state of the art in generating node embeddings?,https://www.reddit.com/r/MachineLearning/comments/dnzz90/d_whats_the_state_of_the_art_in_generating_node/,searchingundergrad,1572214433,"I've encountered node2vec which encapsulate deep walk, but besides that, I haven't seen other methods. Is node2vec the best out there?",3,4,False,self,,,,,
1616,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,8,do0r7k,self.MachineLearning,Why are r/machinelearning and r/datascience people so elitist? Who are they comprised of?,https://www.reddit.com/r/MachineLearning/comments/do0r7k/why_are_rmachinelearning_and_rdatascience_people/,BombBurper,1572218238,[removed],0,1,False,self,,,,,
1617,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,9,do1an9,self.MachineLearning,"[D] ML researchers with an interdisciplinary background (ideally not in STEM), how did your background and/or experience help you navigate the machine learning field better?",https://www.reddit.com/r/MachineLearning/comments/do1an9/d_ml_researchers_with_an_interdisciplinary/,silly-deer,1572221188,,0,1,False,self,,,,,
1618,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,9,do1dtq,self.MachineLearning,Trying to find an alternative solution for nanonets.com,https://www.reddit.com/r/MachineLearning/comments/do1dtq/trying_to_find_an_alternative_solution_for/,alarghi,1572221637,"Hi Everyone!

I've recently started playing with ML, so far I'm thrilled with the results. I've been using [https://app.nanonets.com](https://app.nanonets.com/) which allows you to easily create and train models. The only thing that I **don't like** about this is that I'm **tied** to this platform. I'd like to be able to achieve the same results using a third-party framework that I can host on my server, not having to depend on a platform.

I've done a few experiments, training a model to recognize castles, training a model to recognize panels on comic strips, so far so good. 

[https://imgur.com/a/zt574ai](https://imgur.com/a/zt574ai)

I'm looking for a framework that allows me to do the same thing. The thing that I like about nanonets is that its **simple**. You just **upload the images**, **label the content** that you want to recognize and **train the model**, through a very simple and friendly UI.

Does anyone know a framework like this? That's easy to use but doesn't depend on a platform.

Thanks!",0,1,False,self,,,,,
1619,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,9,do1s12,self.MachineLearning,[N] Identifying forest elephants and poachers by analyzing sounds using NN,https://www.reddit.com/r/MachineLearning/comments/do1s12/n_identifying_forest_elephants_and_poachers_by/,unkz,1572223828,[removed],0,1,False,self,,,,,
1620,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,10,do1yvd,self.MachineLearning,Dex: Google's r esearch language for array processing in the Haskell/ML family,https://www.reddit.com/r/MachineLearning/comments/do1yvd/dex_googles_r_esearch_language_for_array/,TheAlgorithmist99,1572224886,"Here's the [github repo](https://github.com/google-research/dex-lang).

Here's another discussion on [Hacker News](https://news.ycombinator.com/item?id=21364413)

Right now it's still experimental, but it seems to have a rather interesting way to deal with matrices (and tensors) by expanding einsum.",0,27,False,self,,,,,
1621,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,10,do26zx,self.MachineLearning,[R] Recent advances in physical reservoir computing: A review,https://www.reddit.com/r/MachineLearning/comments/do26zx/r_recent_advances_in_physical_reservoir_computing/,hardmaru,1572226155,[removed],0,1,False,self,,,,,
1622,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,10,do2hpk,self.MachineLearning,[R] Recent advances in physical reservoir computing: A review,https://www.reddit.com/r/MachineLearning/comments/do2hpk/r_recent_advances_in_physical_reservoir_computing/,baylearn,1572227732,[removed],0,1,False,self,,,,,
1623,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,10,do2hzp,self.MachineLearning,Structuring sports prediction data for varying amounts of players,https://www.reddit.com/r/MachineLearning/comments/do2hzp/structuring_sports_prediction_data_for_varying/,rsek1996,1572227773,[removed],0,1,False,self,,,,,
1624,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,10,do2j4j,self.MachineLearning,Need help Discritizing state space in OpenAI's Lunar Lander for Q-Learning,https://www.reddit.com/r/MachineLearning/comments/do2j4j/need_help_discritizing_state_space_in_openais/,person4422,1572227935,[removed],0,1,False,self,,,,,
1625,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,10,do2jk4,medium.com,Running an Industrial Robotics Software Startup Is Not Getting Easier,https://www.reddit.com/r/MachineLearning/comments/do2jk4/running_an_industrial_robotics_software_startup/,Yuqing7,1572227987,,0,1,False,default,,,,,
1626,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,11,do34zv,self.MachineLearning,What is the difference of weakly supervised learning and knowledge distilling?,https://www.reddit.com/r/MachineLearning/comments/do34zv/what_is_the_difference_of_weakly_supervised/,rajxmow,1572231346,[removed],0,1,False,self,,,,,
1627,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,13,do40m7,arxiv.org,[R] DiffTaichi: Differentiable Programming for Physical Simulation,https://www.reddit.com/r/MachineLearning/comments/do40m7/r_difftaichi_differentiable_programming_for/,baylearn,1572236805,,13,70,False,default,,,,,
1628,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,14,do4cer,self.MachineLearning,Training convolutional variational autoencoders,https://www.reddit.com/r/MachineLearning/comments/do4cer/training_convolutional_variational_autoencoders/,Mike_Sv86,1572239089,"Hi all.

Iam trying to train a convolutional variational autoencoder (CVAE) on computed tomography (CT) IMAGES (176X224 px) . The training data is normalized between 0 and 1 and Iam using approximately the same model structure as in keras autoencoder tutorial.

https://keras.io/examples/variational_autoencoder/

I only changed the depth and the size of the latent space to 128.

For the loss function I use Mse and KL, with a weight annealing for the KL part. 

When I train the network it seems like it is learning something, but if I try to reconstruct images after training, the output images are just noisy. 

I have no clue what it is Iam doing wrong. 

Any advice would be really great. 

Cheers, 

M",3,3,False,self,,,,,
1629,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,14,do4l4v,self.MachineLearning,Training convolutional variational autoencoders,https://www.reddit.com/r/MachineLearning/comments/do4l4v/training_convolutional_variational_autoencoders/,Mike_Sv86,1572240671,[removed],0,1,False,self,,,,,
1630,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,15,do53fx,self.MachineLearning,[R] Recent advances in physical reservoir computing: A review,https://www.reddit.com/r/MachineLearning/comments/do53fx/r_recent_advances_in_physical_reservoir_computing/,hardmaru,1572244334,"*Abstract*

Reservoir computing is a computational framework suited for temporal/sequential data processing. It is derived from several recurrent neural network models, including echo state networks and liquid state machines. A reservoir computing system consists of a reservoir for mapping inputs into a high-dimensional space and a readout for pattern analysis from the high-dimensional states in the reservoir. The reservoir is fixed and only the readout is trained with a simple method such as linear regression and classification. Thus, the major advantage of reservoir computing compared to other recurrent neural networks is fast learning, resulting in low training cost. Another advantage is that the reservoir without adaptive updating is amenable to hardware implementation using a variety of physical systems, substrates, and devices. In fact, such physical reservoir computing has attracted increasing attention in diverse fields of research. The purpose of this review is to provide an overview of recent advances in physical reservoir computing by classifying them according to the type of the reservoir. We discuss the current issues and perspectives related to physical reservoir computing, in order to further expand its practical applications and develop next-generation machine learning systems.

Links to article (open-access): https://www.sciencedirect.com/science/article/pii/S0893608019300784

Direct PDF link: https://www.sciencedirect.com/science/article/pii/S0893608019300784/pdfft",10,11,False,self,,,,,
1631,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,16,do5bbf,self.MachineLearning,Deploy Keras segmentation model using Flask,https://www.reddit.com/r/MachineLearning/comments/do5bbf/deploy_keras_segmentation_model_using_flask/,Mohamed_SickitLearn,1572246031,[removed],0,1,False,self,,,,,
1632,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,16,do5i1j,self.MachineLearning,How will physical structure difference affect a model trained by an x-ray?,https://www.reddit.com/r/MachineLearning/comments/do5i1j/how_will_physical_structure_difference_affect_a/,mikiol,1572247418,[removed],0,1,False,self,,,,,
1633,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,16,do5lgz,arxiv.org,"[R] Capacity, Bandwidth, and Compositionality in Emergent Language Learning",https://www.reddit.com/r/MachineLearning/comments/do5lgz/r_capacity_bandwidth_and_compositionality_in/,hardmaru,1572248135,,1,16,False,default,,,,,
1634,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,18,do6k6p,medium.com,[D] What does it mean for a machine to understand? by Prof. Thomas Dietterich,https://www.reddit.com/r/MachineLearning/comments/do6k6p/d_what_does_it_mean_for_a_machine_to_understand/,Bayequentist,1572255614,,0,1,False,default,,,,,
1635,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,18,do6o0o,self.MachineLearning,PhD admissions should just say it : Outsiders need not apply,https://www.reddit.com/r/MachineLearning/comments/do6o0o/phd_admissions_should_just_say_it_outsiders_need/,ML_THROWAWAY_RANTER,1572256385,[removed],0,1,False,self,,,,,
1636,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,20,do7e7l,self.MachineLearning,"[D] How to , concretly, measure a model's robustness against adversarial/perturbations examples? ... I mean concretly.",https://www.reddit.com/r/MachineLearning/comments/do7e7l/d_how_to_concretly_measure_a_models_robustness/,data-soup,1572261224,"We know that we can measure a model's robustness to perturbation by applying perturbation to training points and checking if the outputs are the same:

&gt; The `lp` ball around an image is said to be the adversarial ball, and a network is said to be `E-robust` around `x` if every point in the adversarial ball around `x` classifies the same. [source, Part 3](https://arxiv.org/pdf/1909.13846.pdf)

- But how is this done concretely? Is there a smarter way to do it than just applying perturbation in the input and see how it goes out? 
- Who is doing it IRL?",8,3,False,self,,,,,
1637,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,20,do7hb2,self.MachineLearning,Model predicting a single value in regression,https://www.reddit.com/r/MachineLearning/comments/do7hb2/model_predicting_a_single_value_in_regression/,ssd123456789,1572261782,[removed],0,1,False,self,,,,,
1638,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,21,do7zry,self.MachineLearning,[D] How should I format my cover letter for Google AI Residency Program 2020?,https://www.reddit.com/r/MachineLearning/comments/do7zry/d_how_should_i_format_my_cover_letter_for_google/,sinashish,1572264821,"Hi, 

I am an undergrad student at Tier 1 college in India, with a major in Material Science. I want to apply for this year's residency program and was wondering how should I write my cover letter, since I think that being from a non-CS major can be harmful for my application. I do research experience though, and have authored 2 papers, 1 submitted to a journal and the other accepted as NeurIPS workshop paper. 

I was also wondering which location to apply for, like MV, Seattle, Cambridge or NYC! Or is it, that I apply for 1 location and it is automatically considered for all the locations?

Thanks!",4,0,False,self,,,,,
1639,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,21,do870r,self.MachineLearning,[News] Free GPUs for ML/DL Projects,https://www.reddit.com/r/MachineLearning/comments/do870r/news_free_gpus_for_mldl_projects/,nevereallybored,1572265966,"Hey all,

Just wanted to share this awesome resource for anyone learning or working with machine learning or deep learning. [Gradient Community Notebooks](https://gradient.paperspace.com/free-gpu) from Paperspace offers a free GPU you can use for ML/DL projects with Jupyter notebooks. With containers that come with everything pre-installed (like [fast.ai](http://fast.ai/), PyTorch, TensorFlow, and Keras), this is basically the lowest barrier to entry in addition to being totally free.

They also have an [ML Showcase](https://ml-showcase.paperspace.com/) where you can use runnable templates of different ML projects and models. I hope this can help someone out with their projects :)

**Comment**",113,433,False,self,,,,,
1640,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,21,do8agp,self.deeplearning,[Announcement] Free GPUs for ML/DL Projects,https://www.reddit.com/r/MachineLearning/comments/do8agp/announcement_free_gpus_for_mldl_projects/,cdossman,1572266481,,0,1,False,default,,,,,
1641,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,21,do8hn3,self.MachineLearning,"What is the current best overview journal paper for hyperparameter tuning, optimization and regularization techniques?",https://www.reddit.com/r/MachineLearning/comments/do8hn3/what_is_the_current_best_overview_journal_paper/,gonzales82,1572267535,[removed],0,1,False,self,,,,,
1642,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,22,do8zdz,self.MachineLearning,Difference between recommendations and personalization in content systmes.,https://www.reddit.com/r/MachineLearning/comments/do8zdz/difference_between_recommendations_and/,zkid18,1572270044,[removed],0,1,False,self,,,,,
1643,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,22,do8zmz,self.MachineLearning,Is this digital image processing?,https://www.reddit.com/r/MachineLearning/comments/do8zmz/is_this_digital_image_processing/,Shashniq,1572270083,"I am extremely new to data science. 
I have recently completed Andrew Ng's course, and a part of that course is basic digit recognition. 

Now suppose there's a room with 6 instruments. I have a camera which can take a picture of the room. Multiple people can access an instrument. I want to read the pictures and figure out how many people are at every instrument. 

I can take a grayscale image of this and train it using an NN, by converting the picture into a vector of grayscale values. But is this simply an ineffective method compared to the various DIP algs which exist?",0,1,False,self,,,,,
1644,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,22,do9247,producthunt.com,Generative Adversarial Network implementation in a photo editor,https://www.reddit.com/r/MachineLearning/comments/do9247/generative_adversarial_network_implementation_in/,nextart-io,1572270420,,0,1,False,https://b.thumbs.redditmedia.com/a63vEqgbo3MaVlqc2db8KrPZGC-4kTklUGg1vA_C-_M.jpg,,,,,
1645,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,22,do94i7,self.MachineLearning,[D] Using deep learning models and advanced sports statistics to predict daily fantasy football scores for my capstone project,https://www.reddit.com/r/MachineLearning/comments/do94i7/d_using_deep_learning_models_and_advanced_sports/,BL7599,1572270755,"Hello again. Like I mentioned in another post I'm currently working on my capstone project proposal and I was interesting in researching deep learning models and do something about that. I appreciate the feedback I got regarding the stock price prediction proposal and in fact I got more or less the same feedback from my teachers.

I came up with the following project proposal and I was wondering if you can give me any further feedback about it, since my teachers have been stonewalling me on this matter: I want to use advanced sports statistics (basically FootballOutsiders' statistics) along with traditional statistics and RNN to predict how many fantasy football points each player is going to score for a given week. I'm focusing on daily fantasy football since it's easier to do without great point fluctuations that I would get trying to predict their season-long performance (due to injury, scheme change, coaching changes, etc). Then I would apply an optimization algorithm to come up with an optimal team that meets the salary cap constraint that most DFF competitions have.

I've researched a bit and didn't find many studies dealing with this subject, and those that did focused on more basic models like linear regression. 

Do you think it's a worthwhile subject to work on?

Thank you",2,0,False,self,,,,,
1646,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,23,do9iux,arxiv.org,[1910.11432] HRL4IN: Hierarchical Reinforcement Learning for Interactive Navigation with Mobile Manipulators,https://www.reddit.com/r/MachineLearning/comments/do9iux/191011432_hrl4in_hierarchical_reinforcement/,ada_td,1572272661,,1,4,False,default,,,,,
1647,MachineLearning,t5_2r3gv,2019-10-28,2019,10,28,23,do9uw9,kaggle.com,"Kaggle's 2019 Data Science Bowl is now live!: ""Uncover the factors to help measure how young children learn""",https://www.reddit.com/r/MachineLearning/comments/do9uw9/kaggles_2019_data_science_bowl_is_now_live/,gtownhoya2041,1572274183,,0,1,False,https://b.thumbs.redditmedia.com/b3FZfkgZBr50aUcEI9TAZp5xKKmJ5IPQAyGIz-RYgXg.jpg,,,,,
1648,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,0,doa2pr,i.redd.it,My son said he drew the future. Have a look,https://www.reddit.com/r/MachineLearning/comments/doa2pr/my_son_said_he_drew_the_future_have_a_look/,raviramdial,1572275151,,0,1,False,default,,,,,
1649,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,0,doa71m,medium.com,Estimating Uncertainty in Machine Learning Models  Part 3,https://www.reddit.com/r/MachineLearning/comments/doa71m/estimating_uncertainty_in_machine_learning_models/,CometML,1572275686,,0,1,False,default,,,,,
1650,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,0,doa8x0,self.MachineLearning,7th International Conference on Artificial Intelligence and Applications (AIAPP 2020),https://www.reddit.com/r/MachineLearning/comments/doa8x0/7th_international_conference_on_artificial/,IJSCAI,1572275928,"  

**7th International Conference on Artificial Intelligence and Applications (AIAPP 2020)**

**January 25 \~ 26, 2020, Zurich, Switzerland**

https://i.redd.it/9ih3g6nztav31.jpg

[https://cosit2020.org/aiapp/index.html](https://cosit2020.org/aiapp/index.html#home)

**Scope &amp; Topics**

**7th International Conference on Artificial Intelligence and Applications (AIAPP 2020)**  is a forum for presenting new advances and research results in the fields of Artificial Intelligence. The conference will bring together leading researchers, engineers and scientists in the domain of interest from around the world. The scope of the conference covers all theoretical and practical aspects of the Artificial Intelligence forum for presenting new advances and research results in the fields of Artificial Intelligence.

Authors are solicited to contribute to the conference by submitting articles that illustrate research results, projects, surveying works and industrial experiences that describe significant advances in the following areas, but are not limited to :

**Topics of interest include, but are not limited to, the following:**

 AI Algorithms

 Artificial Intelligence Tools &amp; Applications

 Automatic Control

 Bioinformatics

 Natural Language Processing

 CAD Design &amp; Testing

 Computer Vision and Speech Understanding

 Data Mining and Machine Learning Tools

 Fuzzy Logic

 Heuristic and AI Planning Strategies and Tools

 Computational Theories of Learning

 Hybrid Intelligent Systems

 Information Retrieval

 Intelligent System Architectures

 Knowledge Representation

 Knowledge-based Systems

 Mechatronics

 Multimedia &amp; Cognitive Informatics

 Neural Networks

 Parallel Processing

 Pattern Recognition

 Pervasive Computing and Ambient Intelligence

 Programming Languages

 Reasoning and Evolution

 Recent Trends and Developments

 Robotics

 Semantic Web Techniques and Technologies

 Soft Computing Theory and Applications

 Software and Hardware Architectures

 Web Intelligence Applications and Search

**Paper Submission**

Authors are invited to submit papers through the conference [Submission system](https://cosit2020.org/submission/index.php).

Heres where you can reach us : [aiapp@cosit2020.org](mailto:aiapp@cosit2020.org) or [aiapp\_secretary@yahoo.com](mailto:aiapp_secretary@yahoo.com)",0,1,False,https://b.thumbs.redditmedia.com/cWROwMHG25VjNWRuYuKZUam1WCKUabnTtIFtI6cHcFY.jpg,,,,,
1651,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,0,doahnn,self.MachineLearning,"""[D]"" 7th International Conference on Artificial Intelligence and Applications (AIAPP 2020)",https://www.reddit.com/r/MachineLearning/comments/doahnn/d_7th_international_conference_on_artificial/,IJSCAI,1572277002,"  

**7th International Conference on Artificial Intelligence and Applications (AIAPP 2020)**

**January 25 \~ 26, 2020, Zurich, Switzerland**

[https://cosit2020.org/aiapp/index.html](https://cosit2020.org/aiapp/index.html#home)

**Scope &amp; Topics**

**7th International Conference on Artificial Intelligence and Applications (AIAPP 2020)**  is a forum for presenting new advances and research results in the fields of Artificial Intelligence. The conference will bring together leading researchers, engineers and scientists in the domain of interest from around the world. The scope of the conference covers all theoretical and practical aspects of the Artificial Intelligence forum for presenting new advances and research results in the fields of Artificial Intelligence.

Authors are solicited to contribute to the conference by submitting articles that illustrate research results, projects, surveying works and industrial experiences that describe significant advances in the following areas, but are not limited to :

**Topics of interest include, but are not limited to, the following:**

 AI Algorithms

 Artificial Intelligence Tools &amp; Applications

 Automatic Control

 Bioinformatics

 Natural Language Processing

 CAD Design &amp; Testing

 Computer Vision and Speech Understanding

 Data Mining and Machine Learning Tools

 Fuzzy Logic

 Heuristic and AI Planning Strategies and Tools

 Computational Theories of Learning

 Hybrid Intelligent Systems

 Information Retrieval

 Intelligent System Architectures

 Knowledge Representation

 Knowledge-based Systems

 Mechatronics

 Multimedia &amp; Cognitive Informatics

 Neural Networks

 Parallel Processing

 Pattern Recognition

 Pervasive Computing and Ambient Intelligence

 Programming Languages

 Reasoning and Evolution

 Recent Trends and Developments

 Robotics

 Semantic Web Techniques and Technologies

 Soft Computing Theory and Applications

 Software and Hardware Architectures

 Web Intelligence Applications and Search

**Paper Submission**

Authors are invited to submit papers through the conference [Submission system](https://cosit2020.org/submission/index.php)

Heres where you can reach us : [aiapp@cosit2020.org](mailto:aiapp@cosit2020.org) or [aiapp\_secretary@yahoo.com](mailto:aiapp_secretary@yahoo.com)",0,0,False,self,,,,,
1652,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,0,doanjb,medium.com,Can a Smart Light Bulb Steal Your Personal Data?,https://www.reddit.com/r/MachineLearning/comments/doanjb/can_a_smart_light_bulb_steal_your_personal_data/,Yuqing7,1572277720,,0,1,False,default,,,,,
1653,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,0,doat18,towardsdatascience.com,[R] Solving classic unsupervised learning problems with deep neural networks,https://www.reddit.com/r/MachineLearning/comments/doat18/r_solving_classic_unsupervised_learning_problems/,MTGTraner,1572278396,,5,4,False,default,,,,,
1654,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,1,dob1xy,heartbeat.fritz.ai,Visualizing neural network decision making with Class Activation Maps,https://www.reddit.com/r/MachineLearning/comments/dob1xy/visualizing_neural_network_decision_making_with/,ANil1729,1572279463,,0,1,False,default,,,,,
1655,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,1,dob4e0,day1tech.com,How good is your App Store Optimization Strategy?,https://www.reddit.com/r/MachineLearning/comments/dob4e0/how_good_is_your_app_store_optimization_strategy/,day1technologies,1572279739,,0,1,False,default,,,,,
1656,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,1,dobh2r,ml.blogs.losttech.software,New release of a TensorFlow binding for .NET,https://www.reddit.com/r/MachineLearning/comments/dobh2r/new_release_of_a_tensorflow_binding_for_net/,lostmsu,1572281265,,0,1,False,default,,,,,
1657,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,2,dobntn,self.MachineLearning,Anyone know if what Im looking for exists?,https://www.reddit.com/r/MachineLearning/comments/dobntn/anyone_know_if_what_im_looking_for_exists/,hippygrunt101,1572282073,[removed],0,1,False,self,,,,,
1658,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,2,docgmp,self.MachineLearning,Is attending NeurIPS in 2019 worth it?,https://www.reddit.com/r/MachineLearning/comments/docgmp/is_attending_neurips_in_2019_worth_it/,raduqq,1572285485,"I have received the e-mail invite to register for NeurIPS and my company would cover the full costs of travel and ticket in order for me to attend.

However, I have never been to such a conference before (or to any conference for a matter of fact) and I have been studying / leatning ML for only a year now.

What would be the benefits for a junior like myself to fly half way around the world and attend the conference?

I believe I have received this e-mail in the 3rd round of ticket offerings so I'm wondering why haven't so many more people before me accepted to go to the conference since as far as I know it is the most renowned conference for ML and DL in the world.

Are the topics going to require in-depth algebra and calculus knowledge?

Any tips to help me decide by the 8th would be really helpful!",2,1,False,self,,,,,
1659,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,3,doci3f,blog.insightdatascience.com,[P] Can we identify 3-D images using very little training data?,https://www.reddit.com/r/MachineLearning/comments/doci3f/p_can_we_identify_3d_images_using_very_little/,hszafarek,1572285653,,0,1,False,default,,,,,
1660,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,3,doddk8,self.MachineLearning,WHAT DOES IT MEAN TO UNDERSTAND? NEURAL NETWORKS CASE,https://www.reddit.com/r/MachineLearning/comments/doddk8/what_does_it_mean_to_understand_neural_networks/,Albert_Ierusalem,1572289061,[removed],0,1,False,self,,,,,
1661,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,4,dodphd,self.MachineLearning,Image Classification Question,https://www.reddit.com/r/MachineLearning/comments/dodphd/image_classification_question/,ryanl247,1572290344,"Hey, 

I am aware that you can train a model to classify between distinct images (e.g. numbers). Let's say I train a model to understand the number 6. Would it be possible to provide a photo of thousands of numbers to the model and have it pick out all the 6s? Or in a more real world example where different photo angles come into play, show a photo of a beach and have it pick up all the garbage (not shells, towels, crabs, etc.)? How would one do this?",0,1,False,self,,,,,
1662,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,4,dodqaf,self.MachineLearning,[D] What does it mean to understand? Neural networks case,https://www.reddit.com/r/MachineLearning/comments/dodqaf/d_what_does_it_mean_to_understand_neural_networks/,Albert_Ierusalem,1572290426,"Hello everybody!

By this philosophical paper, we express our opinion on the neural networks understanding issue. We were motivated by Timothy P. Lillicrap and Konrad P. Kording paper [https://arxiv.org/pdf/1907.06374.pdf](https://arxiv.org/pdf/1907.06374.pdf) and we disagree with many statements presented in this work. We propose understanding requirements and based on them, describes the state when we can say that we understand the neural networks.

Our paper: [https://philpapers.org/archive/IERWDI.pdf](https://philpapers.org/archive/IERWDI.pdf)

The problem of ""understanding"" is very hotly debated in the machine learning community in the last time. [https://www.reddit.com/r/MachineLearning/comments/chm065/d\_why\_ml\_community\_so\_negatively\_opposed\_to/](https://www.reddit.com/r/MachineLearning/comments/chm065/d_why_ml_community_so_negatively_opposed_to/). [https://www.reddit.com/r/MachineLearning/comments/do6xx5/d\_what\_does\_it\_mean\_for\_a\_machine\_to\_understand/](https://www.reddit.com/r/MachineLearning/comments/do6xx5/d_what_does_it_mean_for_a_machine_to_understand/)

We hope that our article will draw even more attention to this problem.",1,1,False,self,,,,,
1663,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,4,dodxmz,self.MachineLearning,Spark ML - Combining two models in the same pipeline?,https://www.reddit.com/r/MachineLearning/comments/dodxmz/spark_ml_combining_two_models_in_the_same_pipeline/,Octosaurus,1572291233,"I am trying to configure a Spark ML pipeline that can take in a dataframe, do the feature engineering with custom transformers, split the data based on a column attribute (output is 2 dataframes), run inferences on those split (1 model per dataset), then concatenate the results into a single dataframe again. [Here's](https://i.imgur.com/NakgYFc.jpg) a visual representation of what I'm trying to do.

I haven't been able to find a way to split the dataset, then pass the respective dataframes. I found a post on Stack Overflow showing a method of wrapping two separate pipelines into a single model, but I have the same issue splitting the dataframe before passing each to its own model and concatenating them at the end.



Does anyone have any advice on approaching this? Thank you!",0,1,False,self,,,,,
1664,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,4,doe71c,technologyreview.com,[R] Newton vs The Machine: Solving The Chaotic Three-Body Problem Using Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/doe71c/r_newton_vs_the_machine_solving_the_chaotic/,rtk25,1572292238,,0,1,False,default,,,,,
1665,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,5,doehyu,self.MachineLearning,Visa application type,https://www.reddit.com/r/MachineLearning/comments/doehyu/visa_application_type/,santsick,1572293388,[removed],0,1,False,self,,,,,
1666,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,5,doei0f,youtube.com,OpenAI Plays Hide and Seekand Breaks The Game! ,https://www.reddit.com/r/MachineLearning/comments/doei0f/openai_plays_hide_and_seekand_breaks_the_game/,GingerAleBonanza,1572293393,,0,1,False,default,,,,,
1667,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,5,doelbt,self.MachineLearning,"Multiclass classifier with ""everything else"" class?",https://www.reddit.com/r/MachineLearning/comments/doelbt/multiclass_classifier_with_everything_else_class/,makhancora,1572293773,[removed],0,1,False,self,,,,,
1668,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,5,doeuya,arxiv.org,[R] re-training only embedding matrix for new language is good enough for transfer learning - new paper from Deepmind,https://www.reddit.com/r/MachineLearning/comments/doeuya/r_retraining_only_embedding_matrix_for_new/,bobchennan,1572294788,,5,22,False,default,,,,,
1669,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,5,doeyuk,heartbeat.fritz.ai,[R] - HAMR  3D Hand Shape and Pose Estimation from a Single RGB Image,https://www.reddit.com/r/MachineLearning/comments/doeyuk/r_hamr_3d_hand_shape_and_pose_estimation_from_a/,posnererez,1572295201,,0,1,False,default,,,,,
1670,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,6,dofoqk,github.com,pytorch/labeler-github-action by pytorch,https://www.reddit.com/r/MachineLearning/comments/dofoqk/pytorchlabelergithubaction_by_pytorch/,sjoerdapp,1572297927,,0,1,False,default,,,,,
1671,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,6,dofyk1,self.MachineLearning,Portuguese Youtube channels for Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/dofyk1/portuguese_youtube_channels_for_machine_learning/,dutchita,1572299022,[removed],0,1,False,self,,,,,
1672,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,6,dog36c,youtu.be,"Extremely excited to share my new project: ""Neural Synesthesia"" --visualizing music with GANs!",https://www.reddit.com/r/MachineLearning/comments/dog36c/extremely_excited_to_share_my_new_project_neural/,tr1pzz,1572299572,,0,1,False,default,,,,,
1673,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,6,dog476,youtu.be,"[P] Extremely excited to share my new project: ""Neural Synesthesia"" -- visualizing music with GANs!",https://www.reddit.com/r/MachineLearning/comments/dog476/p_extremely_excited_to_share_my_new_project/,tr1pzz,1572299706,,0,1,False,default,,,,,
1674,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,8,dohht7,self.MachineLearning,[P] Spark ML - Saving PySpark custom transformers in a pipeline model,https://www.reddit.com/r/MachineLearning/comments/dohht7/p_spark_ml_saving_pyspark_custom_transformers_in/,Octosaurus,1572305783,"I created a spark pipeline where the first stage is a custom transformer, which only filters data on a particular attribute for a column

    class getPOST(Transformer):
    
        @keyword_only
        def __init__(self, inputCol=None, outputCol=None):
            super(getPOST, self).__init__()
            kwargs = self._input_kwargs
            self.setParams(**kwargs)
    
        @keyword_only
        def setParams(self, inputCol=None, outputCol=None):
            kwargs = self._input_kwargs
            return self._set(**kwargs)
    
        def _transform(self, dataset):
            return dataset.filter(dataset.method=='POST')

The model works great, I'm getting good performance, but when I go to save the model, I'm met with:

    ValueError: ('Pipeline write will fail on this pipeline because stage %s of type %s is not MLWritable', 'getPOST_23cb579f79db', &lt;class '__main__.getPOST'&gt;)

I've been reading up and I don't think a transformer is the most applicable use in this case as I'm not appending any columns onto the dataset and not messing with any values or parameters that need declared, such as I found in [this](https://stackoverflow.com/questions/51415784/how-to-add-my-own-function-as-a-custom-stage-in-a-ml-pyspark-pipeline) link. I can't find other examples that allow you to filter out data in the Spark ML pipelines.

This is the last stage of a project I'm working on and I'd greatly appreciate any push in the right direction. Thank you for taking the time to read this!",4,2,False,self,,,,,
1675,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,9,dohyho,self.MachineLearning,Reinforcement Learning with NEAT,https://www.reddit.com/r/MachineLearning/comments/dohyho/reinforcement_learning_with_neat/,FritzWithLessGas,1572307964,[removed],0,1,False,self,,,,,
1676,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,9,doicxp,self.MachineLearning,[D] Has anyone used XLNet for abstractive summarization?,https://www.reddit.com/r/MachineLearning/comments/doicxp/d_has_anyone_used_xlnet_for_abstractive/,somethingstrang,1572309873,I have a data set with a document-summary pair and I want to train it on something like XLNet to do abstractive summarization. Im not completely versed in machine learning to develop it from scratch and was wondering how I would go about this? Would it be something similar to a translation task?,3,4,False,self,,,,,
1677,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,9,doidia,self.MachineLearning,Recommender Systems Specialization  Your gateway to new career and income opportunities,https://www.reddit.com/r/MachineLearning/comments/doidia/recommender_systems_specialization_your_gateway/,internetdigitalentre,1572309964,[removed],0,1,False,self,,,,,
1678,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,10,doiukh,arxiv.org,[1905.01164] SinGAN: Learning a Generative Model from a Single Natural Image,https://www.reddit.com/r/MachineLearning/comments/doiukh/190501164_singan_learning_a_generative_model_from/,joshuacpeterson,1572312243,,17,71,False,default,,,,,
1679,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,10,doj878,self.MachineLearning,Realtime Clinical Telemetry Data Subscription,https://www.reddit.com/r/MachineLearning/comments/doj878/realtime_clinical_telemetry_data_subscription/,mcooly,1572314069,[removed],0,1,False,self,,,,,
1680,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,11,dojinl,nature.com,[R] A deep learning framework for neuroscience,https://www.reddit.com/r/MachineLearning/comments/dojinl/r_a_deep_learning_framework_for_neuroscience/,baylearn,1572315516,,0,1,False,default,,,,,
1681,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,11,dojtze,self.MachineLearning,"""Junior"" Data Scientist Resume review",https://www.reddit.com/r/MachineLearning/comments/dojtze/junior_data_scientist_resume_review/,Ferastwal,1572317135,[removed],0,1,False,self,,,,,
1682,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,11,dojx7n,self.MachineLearning,Boyfriend making DeepNudes from Instagram photos from girls he knows. Should I expose him?,https://www.reddit.com/r/MachineLearning/comments/dojx7n/boyfriend_making_deepnudes_from_instagram_photos/,Lrdcc,1572317602,[removed],0,1,False,self,,,,,
1683,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,12,dok6z9,self.MachineLearning,[D] The Difficulties of Text Generation using Autoregressive Language Models: A Brief Overview,https://www.reddit.com/r/MachineLearning/comments/dok6z9/d_the_difficulties_of_text_generation_using/,leogao2,1572319049,"I wrote a brief blog post about the problems in text generation that I've encountered and some of the potential solutions that have been proposed in the literature. 

[https://leogao.dev/2019/10/27/The-Difficulties-of-Text-Generation-with-Autoregressive-Language-Models/](https://leogao.dev/2019/10/27/The-Difficulties-of-Text-Generation-with-Autoregressive-Language-Models/)

This is my first blog post, so any feedback would be greatly appreciated.",4,5,False,self,,,,,
1684,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,12,dokn1y,self.MachineLearning,Where do you store training data when using an Amazon ec2 instance?,https://www.reddit.com/r/MachineLearning/comments/dokn1y/where_do_you_store_training_data_when_using_an/,eternal-golden-braid,1572321518,[removed],0,1,False,self,,,,,
1685,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,13,dol3yt,self.MachineLearning,"SinGAN is existing and fancy in experiments, but maybe less fundamental and general for CV? All the ideas are not new, so why best paper? :(",https://www.reddit.com/r/MachineLearning/comments/dol3yt/singan_is_existing_and_fancy_in_experiments_but/,YANG-J,1572324374,[removed],0,1,False,self,,,,,
1686,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,14,dolfth,self.MachineLearning,Is there a visual interface for desktop ML?,https://www.reddit.com/r/MachineLearning/comments/dolfth/is_there_a_visual_interface_for_desktop_ml/,tylersnard,1572326571,[removed],0,1,False,self,,,,,
1687,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,14,dolq0b,i.redd.it,Robotic hand made by Elon Musk's OpenAI learns to solves Rubik's Cube,https://www.reddit.com/r/MachineLearning/comments/dolq0b/robotic_hand_made_by_elon_musks_openai_learns_to/,Anirban_Hazra,1572328596,,0,1,False,https://b.thumbs.redditmedia.com/unmY_is5GeO7yyQZDt9JiqLN4m_e80HbeF_w-_7mtjI.jpg,,,,,
1688,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,15,dolv08,self.MachineLearning,How Should I Train My RNN to Complete the XOR Problem?,https://www.reddit.com/r/MachineLearning/comments/dolv08/how_should_i_train_my_rnn_to_complete_the_xor/,jordan6579,1572329642,"I've tried to make a basic RNN from scratch in C++ and I'm trying to figure out how to train it to complete the XOR problem. The architecture is a simple 3 layer network with the hidden layer of time t-1 feeding into the hidden layer of t.

What I've attempted so far is to train it as follows:

* Feed into the inputs a vector of {1, 0} or {0, 1}, representing a single operand of either 0 or 1.
* Feed into the next inputs of t+1 in the same manner as above for the second operand in the XOR.
* Backprop the error from the target, clear the t-1 context layer (i.e. fill it with 0s), and repeat.

Doing this results in a constantly fluctuating error that never decreases. If I instead disable the t-1 context layer (i.e. just set to all 0s), basically turning it into a vanilla NN, and feed in the XOR operands in a single timestep in a vector as {1 or 0, 1 or 0}, the error decreases very rapidly and stabilizes. Does this indicate that the recurrent part was implemented incorrectly or am I just training it wrong? 

Any tips are appreciated.",0,1,False,self,,,,,
1689,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,16,domezm,self.MachineLearning,[D] Is there any implementation of minibert (and pretrained) in tensorflow?,https://www.reddit.com/r/MachineLearning/comments/domezm/d_is_there_any_implementation_of_minibert_and/,EthanPhan,1572333863,"2 months ago Google research release the paper ""**Small and Practical BERT Models for Sequence Labeling""** which they described much faster than original BERT while producing the comparable results but they didn't release the model. I tried the find it on GitHub but found none. Is there anyone implemented it?",7,2,False,self,,,,,
1690,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,16,dommnx,self.MachineLearning,Can I use an external GPU to train models on my laptop?,https://www.reddit.com/r/MachineLearning/comments/dommnx/can_i_use_an_external_gpu_to_train_models_on_my/,Psycomic,1572335594,[removed],0,1,False,self,,,,,
1691,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,17,domtda,self.MachineLearning,Has anyone does seq2seq on different sayings in English?,https://www.reddit.com/r/MachineLearning/comments/domtda/has_anyone_does_seq2seq_on_different_sayings_in/,uyt2190,1572337061,[removed],0,1,False,self,,,,,
1692,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,18,donafk,self.MachineLearning,[D] 6 Steps to Apply Machine Learning in Your Business for Executives,https://www.reddit.com/r/MachineLearning/comments/donafk/d_6_steps_to_apply_machine_learning_in_your/,cdossman,1572340523,"**6 Steps to Apply Machine Learning in Your Business for Executives: Making Sense of AI from an Executives Point of View**

Being an executive or part of the management team, how can we prepare for catching this big wave? If you dont want to miss this opportunity, check this out 

 [https://medium.com/ai%C2%B3-theory-practice-business/6-steps-to-apply-machine-learning-in-your-business-for-executives-d6350ddcd670](https://medium.com/ai%C2%B3-theory-practice-business/6-steps-to-apply-machine-learning-in-your-business-for-executives-d6350ddcd670)",3,0,False,self,,,,,
1693,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,18,donbz7,self.MachineLearning,[D] I'm so sick of the hype,https://www.reddit.com/r/MachineLearning/comments/donbz7/d_im_so_sick_of_the_hype/,Minimum_Zucchini,1572340821,"Sorry if this is not really a constructive post, its more of a rant really. I'm just so sick of the hype in this field, I want to feel like I'm doing engineering work/proper science but I'm constantly met with buzz words and ""business-y"" type language. I was browsing and I saw the announcement for the Tensorflow World conference happening now, and I went on the website and was again met with ""Be part of the ML revolution."" in big bold letters. Like okay, I understand that businesses need to get investors, but for the past 2 years of being in this field I'm really starting to feel like I'm in marketing not engineering. I'm not saying the products don't deliver or there's miss-advertising, but there's just too much involvement of ""business type"" folks more so in this field compared to any other field of engineering and science... and I really hate this. It makes me wonder why is this the case? How come there's no towardschemicalengineering.com type of website? Is it because its really easy for anyone to enter this field and gain a superficial understand of things? 

The issue I have with this is that I feel a constant pressure to frame whatever I'm doing with marketing lingo otherwise you immediately lose people's interest if you don't play along with the hype. 

Anyhow /rant",348,663,False,self,,,,,
1694,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,18,donc4j,self.MachineLearning,[D] Hardware priority for deep learning,https://www.reddit.com/r/MachineLearning/comments/donc4j/d_hardware_priority_for_deep_learning/,imperfectum,1572340845,"Hey,

I've got \~2000$ to spend on PC and I'd like to know your opinion on the hardware priority in deep learning. Is it better to buy rtx 2080 ti, Ryzen 7 2700X/some i5 and 16GB ram, or maybe buy rtx 2070/2080(super?), i9/Ryzen 7 3700x and 32GB(64?) ram?",10,1,False,self,,,,,
1695,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,18,donc7k,medium.com,5 Facial Recognition Trends and Market Predictions 2019,https://www.reddit.com/r/MachineLearning/comments/donc7k/5_facial_recognition_trends_and_market/,Neil_Patel001,1572340863,,0,1,False,default,,,,,
1696,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,18,donewx,self.MachineLearning,[Project] A web app for tracking your AI's progress,https://www.reddit.com/r/MachineLearning/comments/donewx/project_a_web_app_for_tracking_your_ais_progress/,kenanajkunic,1572341404,"Hello everyone, 

I am currently working on a project that I will personally be using, but I would like to ask if maybe other people might find it useful. It is a web app that tracks everything about your AI (loss, accuracy, models, etc.). Any feedback would be useful because I am very focused on this project as it would help me out. I understand that there is a similar app out there called Weights and Biases, it is just that I want to do my take on it. 

Thanks in advance! :)",2,0,False,self,,,,,
1697,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,18,donmne,github.com,A concise resource repository for machine learning!,https://www.reddit.com/r/MachineLearning/comments/donmne/a_concise_resource_repository_for_machine_learning/,innat_2k14,1572342901,,0,1,False,default,,,,,
1698,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,19,donwzx,self.MachineLearning,"[D] Should We Be Concerned About The Failure Of Evolutionary Algorithms, And Its Implications?",https://www.reddit.com/r/MachineLearning/comments/donwzx/d_should_we_be_concerned_about_the_failure_of/,mystikaldanger,1572344792," [https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6287292/](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6287292/)

&amp;#x200B;

&gt;A number of possible explanations for \[why we can't evolve software\] could be considered. We tried to be as comprehensive as possible in this section, but it is possible that we have not considered some plausible explanations:  
&gt;  
&gt;  
Incompetent programmersIt is theoretically possible, but is highly unlikely, that out of thousands of scientists working on evolutionary computation, all failed to correctly implement the Darwinian algorithm.  
&gt;  
&gt;  
Nonrepresentative algorithmsSome have suggested that EAs do not accurately capture the theory of evolution, but of course that would imply that the theory itself is not specified in sufficient detail to make falsifiable predictions. If, however, such more detailed specifications are available to GP believers, it is up to them to implement them as computer simulations for testing purposes, but no successful examples of such work are known and the known ones have not been successful in evolving software.  
&gt;  
&gt;  
Inadequate fitness functionsFitness function for a complex software product is difficult to outline and specify and may be as complex (or even more complex) as the software we want to evolve as it has to consider all the possible use cases and pass all unit tests. This may be the Achilles heel of GP, but it is also an objection to feasibility of programming in general and GP in particular, as both have to convert software specification into the source code. If human programmers and biological evolution succeed with such constraints, so should Darwinian simulations.  
&gt;  
&gt;  
The Halting problemTuring proved that it is impossible to determine whether an arbitrary program halts, but this is also a problem for human programmers and could be easily addressed by placing time limits on considered solutions.  
&gt;  
&gt;  
Program correctnessIf we require evolved software to be provably correct, this would present a problem as GP does not verify produced designs but only tests them against specific unit tests. Likewise, we cannot rely on automated software verification as it is still an unsolved problem in the general case. This is not really a problem as most of the human-written software is never proven to be correct and only a small portion of software engineering process relies of formal specification and Test Driven Development.  
&gt;  
&gt;  
Inappropriate solutionsLiterature on EA is full of examples of surprising creativity of Darwinian algorithm resulting in solutions which match the letter of design specifications but not the spirit. This is similar to human-produced software and numerous examples of ways in which such software fails the goals of the initial design.  
&gt;  
&gt;  
Insufficient complexity of the environment (not enough data, poor fitness functions)It is possible that the simulated environment is not complex enough to generate high complexity outputs in evolutionary simulations. This does not seem correct as Internet presents a highly complex landscape in which many self-modifying computer viruses roam. Likewise, virtual world such as Second Life and many others present close approximations to the real world and are certainly more complex than early Earth was: A skeptic might insist that an abstract environment would be inadequate for the evolution . . ., believing instead that the virtual environment would need to closely resemble the actual biological environment in which our ancestors evolved. Creating a physically realistic virtual world would require a far greater investment of computational resources than the simulation of a simple toy world or abstract problem domain (whereas evolution had access to a physically realistic real world for free). In the limiting case, if complete microphysical accuracy were insisted upon, the computational requirements would balloon to utterly infeasible proportions. Requiring more realistic environmental conditions may result in an increase in necessary computational resources, a problem addressed in the next bullet.  
&gt;  
&gt;  
Insufficient resources (compute, memory)From the history of computer science, we know of many situations (speech recognition, NN training), where we had a correct algorithm but insufficient computational resources to run it to success. It is possible that we simply do not have hardware powerful enough to emulate evolution. We will address this possibility in section Computational Complexity of Biological Evolution and Available Compute.  
&gt;  
&gt;  
Software design is not amenable to evolutionary methodsSpace of software designs may be discrete with no continuous path via incremental fitness to the desired solutions. This is possible, but this implies that original goals of GP are unattainable and misguided. In addition, because a clear mapping exists between solutions to problems and animals as solutions to environmental problems, this would also imply that current explanation for the origin of the species is incorrect.  
&gt;  
&gt;  
Darwinian algorithm is incomplete or wrongFinally, we have to consider the possibility that the inspiration behind evolutionary computation, the Darwinian algorithm itself is wrong or at least partially incomplete. If that was true, computer simulations of such algorithm would fail to produce results comparable with observations we see in nature and a search for an alternative algorithm would need to take place. This would be an extraordinary claim and would require that we discard all the other possible explanations from this list.  
&gt;  
&gt;  
We challenge EA community to prove us wrong by producing an experiment, which evolves nontrivial software from scratch and without human help. That would be the only way in which our findings could be shown to be incorrect. Perhaps, reframing the problem in terms of maximizing negentropy of digital organisms, as suggested by Schrdinger, Michaelian, and Ulanowicz and Hannon, with respect to negative energy being a fundamental property of all life-forms may produce better results.  
&gt;  
&gt;  
On a positive side, the fact that it seems impossible to evolve complex software implies that we are unlikely to be able to evolve highly sophisticated artificially intelligent agents, which may present significant risk to our safety and security. Just imagine what would have happened, if the very first time we ran a simulation of evolution on a computer, it produced a superintelligent agent. Yampolskiy has shown that programming as a problem is AI-complete; if GP can solve programming that would imply that GP = AGI (artificial general intelligence), but we see no experimental evidence for such claim. In fact, it is more likely that once we have AGI, it could be used to create an intelligent fitness function for GP and so evolve software. Genetic programming will not be the cause of AI, but a product of it. However, neuroevolution methods for optimizing deep learning architectures and parameters remain a strong possibility for creation of AGI.",14,3,False,self,,,,,
1699,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,19,doo5ay,day1tech.com,What Apples New iPhone Release means for us,https://www.reddit.com/r/MachineLearning/comments/doo5ay/what_apples_new_iphone_release_means_for_us/,day1technologies,1572346427,,0,1,False,default,,,,,
1700,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,19,doo5et,i.redd.it,"[D] We bought a new NVIDIA DGX Station with the following system specifications. What would be the best use of it, until will figure out how we gonna use it?",https://www.reddit.com/r/MachineLearning/comments/doo5et/d_we_bought_a_new_nvidia_dgx_station_with_the/,grayrhinos,1572346454,,1,1,False,https://b.thumbs.redditmedia.com/ySKwcwQ6anwkX7Ul4tLzEriCABnSIrFXVl-e-KT1oTg.jpg,,,,,
1701,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,21,dop6c2,self.MachineLearning,[P] CIFAR-10H - Human guess distribution soft labels for CIFAR-10 (Dataset Release),https://www.reddit.com/r/MachineLearning/comments/dop6c2/p_cifar10h_human_guess_distribution_soft_labels/,joshuacpeterson,1572352606,"CIFAR-10H is a new dataset of soft labels reflecting human perceptual uncertainty for the 10,000-imageCIFAR-10test set, which we are releasing today. It first appears in the paper:

Joshua C. Peterson,Ruairidh M. Battleday,Thomas L. Griffiths, &amp;Olga Russakovsky (2019). Human uncertainty makes classification more robust.In Proceedings of the IEEE International Conference on Computer Vision.

Dataset Link: https://github.com/jcpeterson/cifar-10h/",1,14,False,self,,,,,
1702,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,22,dopi0i,skyl.ai,Future of Fashion and Ecommerce: How to Improve Online Shopping Experience Using Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/dopi0i/future_of_fashion_and_ecommerce_how_to_improve/,Sophia77Wright,1572354232,,0,1,True,nsfw,,,,,
1703,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,22,doponl,developer.amazon.com,Algorithms for selecting training data improve cross-lingual transfer learning,https://www.reddit.com/r/MachineLearning/comments/doponl/algorithms_for_selecting_training_data_improve/,georgecarlyle76,1572355116,,0,1,False,default,,,,,
1704,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,22,doptmt,self.MachineLearning,[P] Classify whether some text is talking about Apple or apples,https://www.reddit.com/r/MachineLearning/comments/doptmt/p_classify_whether_some_text_is_talking_about/,aewin678,1572355769,"Hey guys,

I'm having a project in which I have a very big dataset related to the term ""apple"" (case unsensitive). It contains some text with that word and my job is to determine what ""apple"" it's talking about.

There are so many ways to do this and I can't seem to find the best one. Eventually, I guess it's doable with 0 machine learning but as a lazy data scientist I want that process to be as autonomous as possible (in order to generalize to other words).

I tried some NLP techniques like bag of words but it gave horrible results.

The problem is that there is no labeled dataset.

I have some ideas, like a proper noun / common noun classifier or using wikipedia to create a context vocabulary.

Any ideas? Thanks.",17,0,False,self,,,,,
1705,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,22,dopuwv,self.MachineLearning,Data Generator in Google Colab using data from local drive,https://www.reddit.com/r/MachineLearning/comments/dopuwv/data_generator_in_google_colab_using_data_from/,ssd123456789,1572355949,[removed],0,1,False,self,,,,,
1706,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,22,dopyzr,self.MachineLearning,Machine Learning to clean data,https://www.reddit.com/r/MachineLearning/comments/dopyzr/machine_learning_to_clean_data/,schmadness,1572356478,[removed],0,1,False,self,,,,,
1707,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,23,doqcco,self.MachineLearning,[D] The roots of natural language processing can be traced back to Kabbalist mystics,https://www.reddit.com/r/MachineLearning/comments/doqcco/d_the_roots_of_natural_language_processing_can_be/,newsbeagle,1572358185,"For people interested in the history of technology -- here's an eccentric essay arguing that the first examples of NLP happened in medieval times. Mystics studying the Kabbala devised ""sacred rules"" for combining letters to generate prophetic texts and, sometimes, to create golems.

[https://spectrum.ieee.org/tech-talk/robotics/artificial-intelligence/natural-language-processing-dates-back-to-kabbalist-mystics](https://spectrum.ieee.org/tech-talk/robotics/artificial-intelligence/natural-language-processing-dates-back-to-kabbalist-mystics)

""While specific technologies have changed over time, the basic idea of treating language as a material that can be artificially manipulated by rule-based systems has been pursued by many people in many cultures and for many different reasons. These historical experiments reveal the promise and perils of attempting to simulate human language in non-human waysand they hold lessons for todays practitioners of cutting-edge NLP techniques.""",7,0,False,self,,,,,
1708,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,23,doqj24,arxiv.org,[1910.11908] Noisier2Noise: Learning to Denoise from Unpaired Noisy Data,https://www.reddit.com/r/MachineLearning/comments/doqj24/191011908_noisier2noise_learning_to_denoise_from/,Imnimo,1572359006,,7,4,False,default,,,,,
1709,MachineLearning,t5_2r3gv,2019-10-29,2019,10,29,23,doqmhm,self.MachineLearning,[1910.11480] Parallel WaveGAN: A fast waveform generation model based on generative adversarial networks with multi-resolution spectrogram,https://www.reddit.com/r/MachineLearning/comments/doqmhm/191011480_parallel_wavegan_a_fast_waveform/,rishikksh20,1572359438,[removed],0,1,False,self,,,,,
1710,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,0,dor1le,self.MachineLearning,[P] Lyrics Generator Twitter Bot,https://www.reddit.com/r/MachineLearning/comments/dor1le/p_lyrics_generator_twitter_bot/,jsalbert_,1572361311,"I fine-tuned 2 small GPT-2 models (124M parameters) and created twitter bots that interact with Twitter users. 

I have shared the code and useful things I learned and used hoping it will help somebody in the following repository :

[https://github.com/jsalbert/lyrics-generator-twitter-bot](https://github.com/jsalbert/lyrics-generator-twitter-bot)

&amp;#x200B;

The following samples correspond to the outputs of such models.

**Eminem Bot Lyrics** ([@rap\_god\_bot](https://twitter.com/rap_god_bot))

https://preview.redd.it/anndufmguhv31.png?width=600&amp;format=png&amp;auto=webp&amp;s=e027a50442f71b64fbcbe8821ed843c6d6823ead

**Music Storytelling Bot Lyrics** ([@musicstorytell](https://twitter.com/musicstorytell))

https://preview.redd.it/lo8qhzshuhv31.png?width=600&amp;format=png&amp;auto=webp&amp;s=c0a609f649bb3daeeea18aa91c43165c7216f038",4,1,False,https://b.thumbs.redditmedia.com/0X2UBDnE7AbxARfzK-jQ9xgF03XLQtNafzt_PDmss7Q.jpg,,,,,
1711,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,0,dor4b1,self.MachineLearning,Best Universities to study ML/AI in UK? (Master's degree),https://www.reddit.com/r/MachineLearning/comments/dor4b1/best_universities_to_study_mlai_in_uk_masters/,lumenwrites,1572361616,[removed],0,1,False,self,,,,,
1712,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,0,dordlr,github.com,[P] GOQ: Graph of Questions --- a Collaborative Project to Construct an Index to ALL Questions,https://www.reddit.com/r/MachineLearning/comments/dordlr/p_goq_graph_of_questions_a_collaborative_project/,wengchunkn,1572362738,,0,1,False,https://a.thumbs.redditmedia.com/j9Rbecub59Xy70hK60kjgqscYhEBsEF69XIhs58dmt0.jpg,,,,,
1713,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,0,dorfed,/r/MachineLearning/comments/dorfed/r_mimicry_embedding_for_advanced_neural_network/,[R] Mimicry embedding for advanced neural network training of 3D biomedical micrographs,https://www.reddit.com/r/MachineLearning/comments/dorfed/r_mimicry_embedding_for_advanced_neural_network/,ayakimovich,1572362959,,0,1,False,default,,,,,
1714,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,0,dori83,i.redd.it,WolfThawra is just spamming the same comment over and over again in this sub (there are 9 pages of this) - can the mods do something or is spam allowed here?,https://www.reddit.com/r/MachineLearning/comments/dori83/wolfthawra_is_just_spamming_the_same_comment_over/,2high4anal,1572363303,,0,1,False,https://b.thumbs.redditmedia.com/C-VNszt9gPL82-Qsw4-sN91xSp6Hhkg_pQ3_joD9rKU.jpg,,,,,
1715,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,0,doritf,self.MachineLearning,[N] Even notes from Siraj Raval's course turn out to be plagiarized.,https://www.reddit.com/r/MachineLearning/comments/doritf/n_even_notes_from_siraj_ravals_course_turn_out_to/,Kitchen_Extreme,1572363366,"More odd paraphrasing and word replacements.

From this article: [https://medium.com/@gantlaborde/siraj-rival-no-thanks-fe23092ecd20](https://medium.com/@gantlaborde/siraj-rival-no-thanks-fe23092ecd20)

&amp;#x200B;

[Left is from Siraj Raval's course, Right is from original article](https://preview.redd.it/taads1pe1iv31.png?width=2046&amp;format=png&amp;auto=webp&amp;s=558dc4d10bbedcfcdf3df5b75816a743eb0f0ab6)

'quick way' -&gt; 'fast way'

'reach out' -&gt; 'reach'

'know' -&gt; 'probably familiar with'

'existing' -&gt; 'current'",77,345,False,https://b.thumbs.redditmedia.com/0fW1ku79igtaf8HkALFe9WYd8hCiIoiD-I58yln_4OI.jpg,,,,,
1716,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,0,doronp,github.com,[R] Differentiable Convex Optimization Layers: Turn any CVXPY Problem into a PyTorch or Tensorflow Layer,https://www.reddit.com/r/MachineLearning/comments/doronp/r_differentiable_convex_optimization_layers_turn/,sbarratt,1572364079,,0,1,False,default,,,,,
1717,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,1,dorxoh,self.MachineLearning,Improve the accuracy of Clustering-Result after PCA,https://www.reddit.com/r/MachineLearning/comments/dorxoh/improve_the_accuracy_of_clusteringresult_after_pca/,A_Weber2512,1572365176,[removed],0,1,False,self,,,,,
1718,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,1,dos9ex,medium.com,A Researcher Is Sheathing Smart Devices in Skin,https://www.reddit.com/r/MachineLearning/comments/dos9ex/a_researcher_is_sheathing_smart_devices_in_skin/,Yuqing7,1572366592,,0,1,False,default,,,,,
1719,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,1,dos9qz,self.MachineLearning,Anomalies in Network traffic,https://www.reddit.com/r/MachineLearning/comments/dos9qz/anomalies_in_network_traffic/,connectwithprakash,1572366634,[removed],0,1,False,self,,,,,
1720,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,1,doshrv,self.MachineLearning,Noob: how can I start this project?,https://www.reddit.com/r/MachineLearning/comments/doshrv/noob_how_can_i_start_this_project/,FrequentMushroom,1572367574,[removed],0,1,False,self,,,,,
1721,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,1,dosl8j,self.MachineLearning,"[D] For GNN's are gradients normally tracked on neighborhood aggregation operations (e.g. max, mean)?",https://www.reddit.com/r/MachineLearning/comments/dosl8j/d_for_gnns_are_gradients_normally_tracked_on/,Muunich,1572367968,"I am writing a GNN from scratch, to demonstrate to myself that I understand all the required concepts.

I am a bit confused on whether neighborhood aggregation operations require gradients to be tracked through those operations like mean and max of neighbors embeddings. In my code where I perform these operations, currently I do them within a **with torch.no\_grad()** block because if I don't each epoch takes forever.

Here my code for those operations:

    def neighborhood_aggregation(self, adj_lists, feat, agg_method):
        # adj_lists is a dict of neighbors for every node in graph
        # e.g. adj_list = {0:{1, 4, 5, 6}, 1: {2, 4, 5}, ...}
        #               node 0 has neighbors 1, 4, 5, 6
        with torch.no_grad():
            # construct aggregated neighborhood embedding
            dim = list(feat.size())
            n_nodes = dim[0]
            feat_dim = dim[1]
            aggregated_embed = torch.Tensor(n_nodes, feat_dim) # aggregated embeddings for all nodes in graph.
            embed_element_vec = torch.arange(feat_dim) #
            for node_id, neighbor_node_ids in adj_lists.items():
                neighborhood_embedding = feat[list(neighbor_node_ids), :]
                if agg_method == 'mean':
                    aggregated_neigborhood_embedding = torch.mean(neighborhood_embedding, 0)
                elif agg_method == 'pool':
                    aggregated_neigborhood_embedding = torch.max(neighborhood_embedding, 0)[0]
                else:
                    raise KeyError('Aggregator type {} not recognized.'.format(agg_method))
                aggregated_embed[node_id, embed_element_vec] = aggregated_neigborhood_embedding
            return aggregated_embed

Note: The above code works, and I am getting very good results with it. It's just I am not sure if what I am doing is wrong. IF it is wrong I was thinking that I need a 3D tensor for the aggregated\_embed tensor \[n\_nodes, n\_neighbors, embed\_dim\] (which requires\_grad=False) and perform the mean/max on that tensor which would track gradients.

Thanks for any help.",13,3,False,self,,,,,
1722,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,2,dot0xp,i.redd.it,Life is very difficult when you're a model,https://www.reddit.com/r/MachineLearning/comments/dot0xp/life_is_very_difficult_when_youre_a_model/,varanxea,1572369806,,0,1,False,https://b.thumbs.redditmedia.com/AlVHELtfymwJnJ2NyQK3GWEaCHlrAOVhNk3wo-Tl9tQ.jpg,,,,,
1723,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,2,dot32p,self.MachineLearning,Is there a GUI for machine learning?,https://www.reddit.com/r/MachineLearning/comments/dot32p/is_there_a_gui_for_machine_learning/,tylersnard,1572370071,"I love Azure, but I want to run that stuff on my desktop.  Tensorflow is really complex, I'd like to just drag and drop modules.",0,1,False,self,,,,,
1724,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,2,dot4fk,self.MachineLearning,Genie lift towable boom lift (TZ-50) key lock,https://www.reddit.com/r/MachineLearning/comments/dot4fk/genie_lift_towable_boom_lift_tz50_key_lock/,griste9,1572370233,[removed],0,1,False,self,,,,,
1725,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,2,dotgg3,self.MachineLearning,[R] - 'DeepSlice' - A Deep Learning Approach towards an Efficient and Reliable Network Slicing in 5G Networks,https://www.reddit.com/r/MachineLearning/comments/dotgg3/r_deepslice_a_deep_learning_approach_towards_an/,adtmv7,1572371642,[removed],0,1,False,self,,,,,
1726,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,3,dotyky,self.MachineLearning,"need to interpolate some features, when should this be done?",https://www.reddit.com/r/MachineLearning/comments/dotyky/need_to_interpolate_some_features_when_should/,zcleghern,1572373741,"I am working with a database that is spread across 7 tables and for ML stuff I need to join them together. However, as some of these rows are not sampled as frequently as others, this leaves a lot of nulls for some features. I want to interpolate these values but I'm not sure the most efficient way to do so. In other words, let's say I have feature X sampled every 10 ms and feature Y every 1 second, and a third feature Z sampled every 15 seconds. I could store it in the database, but I don't know if allowing that kind of storage capacity is feasible for us. Alternatively, I could calculate it for each row when I get batches for training, but I'm afraid that will become a bottleneck depending on how fast the interpolation is. Is there some obvious way of interpolating this efficiently that I'm not thinking of that will allow me to save on memory space?",0,1,False,self,,,,,
1727,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,4,doukt4,self.MachineLearning,[Book] Facebook Page of Generative Adversarial Networks Projects by Kailash Ahirwar,https://www.reddit.com/r/MachineLearning/comments/doukt4/book_facebook_page_of_generative_adversarial/,kailashahirwar12,1572376290,[removed],0,1,False,self,,,,,
1728,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,4,dov5hd,self.MachineLearning,Deep Learning - ANN,https://www.reddit.com/r/MachineLearning/comments/dov5hd/deep_learning_ann/,R_Finch,1572378715,[removed],0,1,False,self,,,,,
1729,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,5,dovaes,zdnet.com,How scientists are using machine learning to study the planet | ZDNet,https://www.reddit.com/r/MachineLearning/comments/dovaes/how_scientists_are_using_machine_learning_to/,key_info,1572379276,,0,1,False,default,,,,,
1730,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,5,dovbkm,self.MachineLearning,Average conference or workshop held in conjunction with a highly reputed conference?,https://www.reddit.com/r/MachineLearning/comments/dovbkm/average_conference_or_workshop_held_in/,zhiyong415,1572379395,"For preliminary research work, should one submit their paper to an average conference (e.g. ACCV, IJCNN, WACV, BMVC) or to a workshop organised in conjunction with a highly reputed conference (e.g., ICML/NeurIPS/ICLR/AAAI workshop)? What are the pros and cons for each option?

Related links:
- [What value do top conference workshop papers (say CVPR, ICCV) add for a PhD admission in Computer Vision at top universities? How does it compare to less prestigious conferences (WACV, BMVC)? What impact does non top publications have?](https://www.quora.com/What-value-do-top-conference-workshop-papers-say-CVPR-ICCV-add-for-a-PhD-admission-in-Computer-Vision-at-top-universities-How-does-it-compare-to-less-prestigious-conferences-WACV-BMVC-What-impact-does-non-top)
- [How valuable is to have a workshop paper for graduate admission?](https://www.quora.com/How-valuable-is-to-have-a-workshop-paper-for-graduate-admission)
- [Is the paper in the NIPS ML4H (machine learning for health) workshop considered a good publication? How do you compare the paper in the NIPS ML4H workshop with a regular paper in a normal conference in computer science?](https://www.quora.com/Is-the-paper-in-the-NIPS-ML4H-machine-learning-for-health-workshop-considered-a-good-publication-How-do-you-compare-the-paper-in-the-NIPS-ML4H-workshop-with-a-regular-paper-in-a-normal-conference-in-computer-science)
- [Should one send their paper to an average conference or to a workshop held in conjunction with a highly reputed conference?](https://www.quora.com/Should-one-send-their-paper-to-an-average-conference-or-to-a-workshop-held-in-conjunction-with-a-highly-reputed-conference)",0,1,False,self,,,,,
1731,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,5,dovhml,zdnet.com,How scientists are using machine learning to study the planet,https://www.reddit.com/r/MachineLearning/comments/dovhml/how_scientists_are_using_machine_learning_to/,key_info,1572380059,,0,1,False,https://b.thumbs.redditmedia.com/a9pUnOZVsxx8GUGLlrYBPMV_rleZHk-tbS-bP-RXmhM.jpg,,,,,
1732,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,5,dovtx2,self.MachineLearning,Average conference or workshop held in conjunction with a highly reputed conference?,https://www.reddit.com/r/MachineLearning/comments/dovtx2/average_conference_or_workshop_held_in/,zhiyong415,1572381439,"For preliminary research work, should one submit their paper to an average conference (e.g. ACCV, IJCNN, WACV, BMVC) or to a workshop organised in conjunction with a highly reputed conference (e.g., ICML/NeurIPS/ICLR/AAAI workshop)? What are the pros and cons for each option?

Related links:

- [What value do top conference workshop papers (say CVPR, ICCV) add for a PhD admission in Computer Vision at top universities? How does it compare to less prestigious conferences (WACV, BMVC)? What impact does non top publications have?](https://www.quora.com/What-value-do-top-conference-workshop-papers-say-CVPR-ICCV-add-for-a-PhD-admission-in-Computer-Vision-at-top-universities-How-does-it-compare-to-less-prestigious-conferences-WACV-BMVC-What-impact-does-non-top)

- [How valuable is to have a workshop paper for graduate admission?](https://www.quora.com/How-valuable-is-to-have-a-workshop-paper-for-graduate-admission)

- [Is the paper in the NIPS ML4H (machine learning for health) workshop considered a good publication? How do you compare the paper in the NIPS ML4H workshop with a regular paper in a normal conference in computer science?](https://www.quora.com/Is-the-paper-in-the-NIPS-ML4H-machine-learning-for-health-workshop-considered-a-good-publication-How-do-you-compare-the-paper-in-the-NIPS-ML4H-workshop-with-a-regular-paper-in-a-normal-conference-in-computer-science)

- [Should one send their paper to an average conference or to a workshop held in conjunction with a highly reputed conference?](https://www.quora.com/Should-one-send-their-paper-to-an-average-conference-or-to-a-workshop-held-in-conjunction-with-a-highly-reputed-conference)",0,1,False,self,,,,,
1733,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,6,dow929,self.MachineLearning,[D] Average conference or workshop held in conjunction with a highly reputed conference?,https://www.reddit.com/r/MachineLearning/comments/dow929/d_average_conference_or_workshop_held_in/,zy415,1572383129,"For preliminary research work, should one submit their paper to an average conference (e.g. ACCV, IJCNN, WACV, BMVC) or to a workshop organised in conjunction with a highly reputed conference (e.g., ICML/NeurIPS/ICLR/AAAI workshop)? What are the pros and cons for each option?

Related links:

- [What value do top conference workshop papers (say CVPR, ICCV) add for a PhD admission in Computer Vision at top universities? How does it compare to less prestigious conferences (WACV, BMVC)? What impact does non top publications have?](https://www.quora.com/What-value-do-top-conference-workshop-papers-say-CVPR-ICCV-add-for-a-PhD-admission-in-Computer-Vision-at-top-universities-How-does-it-compare-to-less-prestigious-conferences-WACV-BMVC-What-impact-does-non-top)

- [How valuable is to have a workshop paper for graduate admission?](https://www.quora.com/How-valuable-is-to-have-a-workshop-paper-for-graduate-admission)

- [Is the paper in the NIPS ML4H (machine learning for health) workshop considered a good publication? How do you compare the paper in the NIPS ML4H workshop with a regular paper in a normal conference in computer science?](https://www.quora.com/Is-the-paper-in-the-NIPS-ML4H-machine-learning-for-health-workshop-considered-a-good-publication-How-do-you-compare-the-paper-in-the-NIPS-ML4H-workshop-with-a-regular-paper-in-a-normal-conference-in-computer-science)

- [Should one send their paper to an average conference or to a workshop held in conjunction with a highly reputed conference?](https://www.quora.com/Should-one-send-their-paper-to-an-average-conference-or-to-a-workshop-held-in-conjunction-with-a-highly-reputed-conference)",20,5,False,self,,,,,
1734,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,6,dow96m,self.MachineLearning,"[Q] Sci-Kit Learn's MLP Classifier, with the same optimizer and loss function and number of nodes per hidden layer, runs significantly faster on CPU than a Torch Neural Network on GPU",https://www.reddit.com/r/MachineLearning/comments/dow96m/q_scikit_learns_mlp_classifier_with_the_same/,MrAcurite,1572383140,[removed],0,1,False,self,,,,,
1735,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,6,dowbc9,youtube.com,ImageNetSSD running on a RaspberryPi 4GB to make an awesome halloween project,https://www.reddit.com/r/MachineLearning/comments/dowbc9/imagenetssd_running_on_a_raspberrypi_4gb_to_make/,t3chflicks,1572383383,,0,1,False,https://b.thumbs.redditmedia.com/CRYp_MKaUanGr9Y2bHSI3D4sKgKBlC2Y2jZ_Su1ydEw.jpg,,,,,
1736,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,6,dowdu2,self.MachineLearning,an image search by content platform using keras and flask,https://www.reddit.com/r/MachineLearning/comments/dowdu2/an_image_search_by_content_platform_using_keras/,amrha,1572383665,[removed],0,1,False,self,,,,,
1737,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,6,dowgaa,self.MachineLearning,Question about ROC curve,https://www.reddit.com/r/MachineLearning/comments/dowgaa/question_about_roc_curve/,MoLiron,1572383955," I have a dataset of 1127 patients. My goal was to classify each patient to 0 or 1. I have two different classifiers but with the same purpose - to classify the patient to 0 or 1. I've run one classifier on 364 patients and the second classifier on the 763 patients. for each classifier\\group, I generated the ROC curve. Now, I would like to combine the curves.

 Someone could guide me on how to do it?

 I think to calculate the weighted FPR and TPR, but I'm not sure how to do it. The number of FPR\\TPR pairs is different between the curves (The first ROC curve based on 312 pairs and the second ROC curve based on 666 pairs).

I really appreciate any help!

Thanks!!!",0,1,False,self,,,,,
1738,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,6,dowhk5,self.MachineLearning,AWS Rekongitiom,https://www.reddit.com/r/MachineLearning/comments/dowhk5/aws_rekongitiom/,Winnie0123,1572384089,[removed],0,1,False,self,,,,,
1739,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,6,dowuwm,self.MachineLearning,[D] Speech Recognition Pretrained Model with LM,https://www.reddit.com/r/MachineLearning/comments/dowuwm/d_speech_recognition_pretrained_model_with_lm/,nottakumasato,1572385639,"Hi everyone,

I have a project where I have to do a quick POC of speech recognition in noisy environment and multispeaker setting. However, I am having a hard time finding a pretrained model with language model rescoring (or any other decoding helper). Any repo or links are welcome!",1,1,False,self,,,,,
1740,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,6,dowym8,self.MachineLearning,Legality of Scraping Google Images for Training Data (personal project),https://www.reddit.com/r/MachineLearning/comments/dowym8/legality_of_scraping_google_images_for_training/,am_i_having_fun,1572386069,[removed],0,1,False,self,,,,,
1741,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,7,doxbsj,self.MachineLearning,[D] I need to interpolate some of my data and have some design decisions about where in my pipeline this should happen.,https://www.reddit.com/r/MachineLearning/comments/doxbsj/d_i_need_to_interpolate_some_of_my_data_and_have/,zcleghern,1572387567,"I am working with a database that is spread across 7 tables and for ML stuff I need to join them together. However, as some of these rows are not sampled as frequently as others, this leaves a lot of nulls for some features. I want to interpolate these values but I'm not sure the most efficient way to do so. In other words, let's say I have feature X sampled every 10 ms and feature Y every 1 second, and a third feature Z sampled every 15 seconds. I could store it in the database, but I don't know if allowing that kind of storage capacity is feasible for us. Alternatively, I could calculate it for each row when I get batches for training, but I'm afraid that will become a bottleneck depending on how fast the interpolation is. Is there some obvious way of interpolating this efficiently that I'm not thinking of that will allow me to save on memory space?",1,0,False,self,,,,,
1742,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,7,doxix2,self.MachineLearning,[P] Would like some ideas for a student project based on city data,https://www.reddit.com/r/MachineLearning/comments/doxix2/p_would_like_some_ideas_for_a_student_project/,JohnMcClapperson,1572388400,"Hello everyone I have a project for my AI machine learning course that will be based on city data, namely Vancouver. The below link are the data sets that our project can be based upon. We are free to use outside data sets but must relate it to our city.

https://opendata.vancouver.ca/explore

I would really appreciate any guidance or input. We're having a difficult time coming up with ideas, the only ones we have come up with are predicting of house property, bike theft,  general crime prediction all of which would combine features from other data sets.

Thank you for reading my post!",2,7,False,self,,,,,
1743,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,7,doxqee,medium.com,ICCV 2019 Best Papers Announced,https://www.reddit.com/r/MachineLearning/comments/doxqee/iccv_2019_best_papers_announced/,Yuqing7,1572389278,,0,1,False,default,,,,,
1744,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,8,doxz30,self.MachineLearning,"[R] Adversarial Attacks and Defenses in Images, Graphs and Text: A Review",https://www.reddit.com/r/MachineLearning/comments/doxz30/r_adversarial_attacks_and_defenses_in_images/,debayandeb3050,1572390340,"Hello Reddit! We reviewed state-of-the-art Adversarial Attacks as well as Defenses against them in our paper. We cover images, graphs and text domains.

I eagerly look forward to your comments!

Paper: [https://arxiv.org/abs/1909.08072](https://arxiv.org/abs/1909.08072)",1,2,False,self,,,,,
1745,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,8,doy6vq,self.MachineLearning,Machine learning Internship,https://www.reddit.com/r/MachineLearning/comments/doy6vq/machine_learning_internship/,Wolf__Mate,1572391328,[removed],0,1,False,self,,,,,
1746,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,8,doycll,self.MachineLearning,[D] Is there any way to classify text based on some given keywords using python?,https://www.reddit.com/r/MachineLearning/comments/doycll/d_is_there_any_way_to_classify_text_based_on_some/,KOWZDK,1572392034," 

Hi, I been trying to learn a bit of machine learning for a project that I'm working in and at the moment I managed to classify text using SVM with sklearn and spacy having some good results, but i want to not only classify the text with svm, I also want it to be classified based on a list of keywords that I have. For example: If the sentence has the word fast or seconds I would like it to be classified as performance.

I'm really new to machine learning and I would really appreciate any advice.",2,0,False,self,,,,,
1747,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,9,doz3m5,self.MachineLearning,[D] Can we please just STOP talking about Siraj in this subreddit?,https://www.reddit.com/r/MachineLearning/comments/doz3m5/d_can_we_please_just_stop_talking_about_siraj_in/,one_pump_trump,1572395480,"I get it; **He is a terrible and shitty person for stealing, plagiarizing, and profiting off of it.** However, it's starting to turn into TMZ in this subreddit with the childish, cancel culture with zero, productive actions. I come her to read about cool research and everyone's neat projects that they would love to share. I like when people have questions about a paper, or are wanting feedback on their projects. Can we just ban his videos / content?",16,29,False,self,,,,,
1748,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,9,doz9pp,self.MachineLearning,[R] Learning to Predict Without Looking Ahead: World Models Without Forward Prediction (NeurIPS2019),https://www.reddit.com/r/MachineLearning/comments/doz9pp/r_learning_to_predict_without_looking_ahead_world/,milaworld,1572396222,"*Recent work from a group at Google Brain.*

**Abstract**

Much of model-based reinforcement learning involves learning a model of an agents world, and training an agent to leverage this model to perform a task more efficiently. While these models are demonstrably useful for agents, every naturally occurring model of the world of which we are awaree.g., a brainarose as the byproduct of competing evolutionary pressures for survival, not minimization of a supervised forward-predictive loss via gradient descent. That useful models can arise out of the messy and slow optimization process of evolution suggests that forward-predictive modeling can arise as a side-effect of optimization under the right circumstances. Crucially, this optimization process need not explicitly be a forward-predictive loss. In this work, we introduce a modification to traditional reinforcement learning which we call observational dropout, whereby we limit the agents ability to observe the real environment at each timestep. In doing so, we can coerce an agent into learning a world model to fill in the observation gaps during reinforcement learning. We show that the emerged world model, while not explicitly trained to predict the future, can help the agent learn key skills required to perform well in its environment.

web article: https://learningtopredict.github.io

arxiv: https://arxiv.org/abs/1910.13038",5,40,False,self,,,,,
1749,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,9,doz9ze,self.MachineLearning,[D] Legality of Scraping Training Data from Google Images,https://www.reddit.com/r/MachineLearning/comments/doz9ze/d_legality_of_scraping_training_data_from_google/,am_i_having_fun,1572396261,"I think my original post was removed because I didn't tag it.

I have a  project in mind. I want to build an image classifier with novel classes. For example, lets say I want to classify images of different types of bicycles. Google images is ripe with these images for each type of bike.

I want to publish a blog post about my project, and put my code (including scraper) on github but not upload the image files anywhere. I might put up a (free) endpoint hosting my resulting classifier if it works.

Questions:

1. Are all images on google images fair game for training data or do I have to limit it to images ""labelled for reuse""?
2. Do I have to cite the images I use as training data?
3. I've read about ""fair use"", how does that figure in here?

Thanks, and sorry if this has been covered elsewhere",6,3,False,self,,,,,
1750,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,10,dozhfq,self.MachineLearning,Building App with AWS Rekognition,https://www.reddit.com/r/MachineLearning/comments/dozhfq/building_app_with_aws_rekognition/,Winnie0123,1572397228,[removed],0,1,False,self,,,,,
1751,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,10,dozll6,self.MachineLearning,What is a reasonable salary to ask for,https://www.reddit.com/r/MachineLearning/comments/dozll6/what_is_a_reasonable_salary_to_ask_for/,ExtremeSavings,1572397743,[removed],0,1,False,self,,,,,
1752,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,10,dozuwi,self.MachineLearning,Does anyone have any advice on what to ask for?,https://www.reddit.com/r/MachineLearning/comments/dozuwi/does_anyone_have_any_advice_on_what_to_ask_for/,ExtremeSavings,1572398966,[removed],0,2,False,self,,,,,
1753,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,11,dp0vbg,self.MachineLearning,[R] A deep learning framework for neuroscience,https://www.reddit.com/r/MachineLearning/comments/dp0vbg/r_a_deep_learning_framework_for_neuroscience/,hardmaru,1572403926,"Interesting [paper](https://www.nature.com/articles/s41593-019-0520-2) published in Nature Neuroscience discusses ways where the neuroscience community might benefit from thinking like deep learning people.

*Abstract*

Systems neuroscience seeks explanations for how the brain implements a wide variety of perceptual, cognitive and motor tasks. Conversely, artificial intelligence attempts to design computational systems based on the tasks they will have to solve. In artificial neural networks, the three components specified by design are the objective functions, the learning rules and the architectures. With the growing success of deep learning, which utilizes brain-inspired architectures, these three designed components have increasingly become central to how we model, engineer and optimize complex artificial learning systems. Here we argue that a greater focus on these components would also benefit systems neuroscience. We give examples of how this optimization-based framework can drive theoretical and experimental progress in neuroscience. We contend that this principled perspective on systems neuroscience will help to generate more rapid progress.

Paper: https://www.nature.com/articles/s41593-019-0520-2
(anyone have link to full pdf)?

Summary by the author: https://threadreaderapp.com/thread/1188868863850500096.html",6,4,False,self,,,,,
1754,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,11,dp0xia,arxiv.org,[R] Multiplayer AlphaZero,https://www.reddit.com/r/MachineLearning/comments/dp0xia/r_multiplayer_alphazero/,baylearn,1572404241,,4,3,False,default,,,,,
1755,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,12,dp0zzm,self.MachineLearning,[D] What resources would be required to run a neural network of 86 billion artificial neurons?,https://www.reddit.com/r/MachineLearning/comments/dp0zzm/d_what_resources_would_be_required_to_run_a/,tylersnard,1572404582,"Asking for a friend.  

&amp;#x200B;

In terms of Ghz/Gb/time/etc.",19,0,False,self,,,,,
1756,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,12,dp13kn,self.MachineLearning,How to label time series data correctly for DNN models?,https://www.reddit.com/r/MachineLearning/comments/dp13kn/how_to_label_time_series_data_correctly_for_dnn/,rick854,1572405089,[removed],0,1,False,self,,,,,
1757,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,12,dp1478,self.MachineLearning,[D] Art and ML,https://www.reddit.com/r/MachineLearning/comments/dp1478/d_art_and_ml/,that_weird_potato,1572405171,"I am very interested in what is happening at the crossroads between computer science and art, especially algorithmic and ML generated / supported art (music, film, paintings, installations, etc.).

By this, I don't mean using ML to develop tools that are used in the creative process (improving a 3D modeling software using ML for instance), but using Machine Learning as the creative tool in itself (a standard example being [NextRembrandt](https://www.nextrembrandt.com/)).

My background is in ML and CS and I have been toying with the idea of pursuing a job / PhD in a related project.

Can anyone point me to any research labs / institutions / projects that they find interesting, fit the description and could maybe accept applications?

I know it is a pretty broad question.  I'm looking for opinions from those of you who already know an interesting project and that maybe hasn't had much public attention yet.

Any help would be great! Thank you.",9,8,False,self,,,,,
1758,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,12,dp1dx0,self.MachineLearning,[D] Isnt it awesome that all the best AIs technology are open?,https://www.reddit.com/r/MachineLearning/comments/dp1dx0/d_isnt_it_awesome_that_all_the_best_ais/,Kavillab,1572406599,"We are really lucky that all the best players in AI (google, openAI, fb, etc) are all contributing their insights to the public, arent we? Even if some may not be open source, they all share their methods in detail.

Could you imagine a world where all the best players hid their techniques? I guess we would be years behind by now.",46,58,False,self,,,,,
1759,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,13,dp1qy4,self.MachineLearning,"What's the structural difference between the ""Stacked"" and ""Deep"" SVM?",https://www.reddit.com/r/MachineLearning/comments/dp1qy4/whats_the_structural_difference_between_the/,carelesslowpoke,1572408714,[removed],0,1,False,self,,,,,
1760,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,13,dp1v19,self.MachineLearning,RAPIDS AI 0.1 Released by NVIDIA. Going to replace Pandas?,https://www.reddit.com/r/MachineLearning/comments/dp1v19/rapids_ai_01_released_by_nvidia_going_to_replace/,marek_bdfhjk,1572409410,[removed],0,1,False,self,,,,,
1761,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,13,dp1vev,self.MachineLearning,"Need help, please - #Question",https://www.reddit.com/r/MachineLearning/comments/dp1vev/need_help_please_question/,heyjudeee321,1572409480,[removed],0,1,False,self,,,,,
1762,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,14,dp2kqy,self.MachineLearning,"Decision trees - min leaf/child samples, with condition?",https://www.reddit.com/r/MachineLearning/comments/dp2kqy/decision_trees_min_leafchild_samples_with/,jafflemonkey,1572414226,"Is there a way I can build decision trees (lightGBM/XGBoost) but provide a condition that means that in each leaf/child there was a minimum sample of the outcome?

As in, the leaf can have as many observations in total, say 100, as long as at least 5 of them are outcome =1?",0,1,False,self,,,,,
1763,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,15,dp2qzh,day1tech.com,7 Essential Mobile Apps for your iOS and Android Phones,https://www.reddit.com/r/MachineLearning/comments/dp2qzh/7_essential_mobile_apps_for_your_ios_and_android/,day1technologies,1572415540,,0,1,False,https://b.thumbs.redditmedia.com/VXVyPQfmshYWVRFpVbylJwx8Ntj4p5mkikMJKRADyNM.jpg,,,,,
1764,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,15,dp2th8,self.MachineLearning,"[D] My friend says manual feature engineering doesn't matter much when you use GBDT like lightGBM,Catboost or XGBOOST. Is it true?",https://www.reddit.com/r/MachineLearning/comments/dp2th8/d_my_friend_says_manual_feature_engineering/,b14cksh4d0w369,1572416046,I was planning to learn handcrafting features by referring kaggle notebooks and some other resources .,13,4,False,self,,,,,
1765,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,15,dp2to5,arxiv.org,[R][RL] Asynchronous Methods for Model-Based Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/dp2to5/rrl_asynchronous_methods_for_modelbased/,ada_td,1572416087,,1,7,False,default,,,,,
1766,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,15,dp332q,self.reinforcementlearning,[D] ICML 2019 Reinforcement Learning talks,https://www.reddit.com/r/MachineLearning/comments/dp332q/d_icml_2019_reinforcement_learning_talks/,ada_td,1572418056,,0,1,False,default,,,,,
1767,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,16,dp389c,self.MachineLearning,[D] ICCV 19 - The state of (some) ethically questionable papers,https://www.reddit.com/r/MachineLearning/comments/dp389c/d_iccv_19_the_state_of_some_ethically/,redlow0992,1572419093,"Hello everyone, 

I was wondering if anyone else have similar feelings with regards to a number of accepted papers coming from Chinese universities/authors presented in ICCV. Thus far in the conference, I came across quite a lot of papers with questionable motives which made me question the ethical consequences.

These papers are, for the most part, concerned with various forms of person identification (i.e., typical big brother stuff). In fact, when you look at the accepted papers, more than 80% of all any kind of identification papers have Chinese authors/affiliations. 

But that's not all, some papers go to extreme lengths of person re-identification such as:

1- Occluded person re- identification (i.e., person re-identification through mask/glass)

2- Person re-identification in low-light environments

3- Cross domain person re-identification

4- Cross dataset person re-identification

5- Cross modality person re-identification

6- Unsupervised person re-identification

&amp;#x200B;

And maybe you think person re-identification is all there is, but its not. There are also:

1- Vehicle identification, vehicle re-identification, vehicle re-identification from aerial images

2- Occluded vehicle recovery

3- Lip reading from video sequences

4- Crowd counting in scenes, crowd counting in aerial pictures (in fact, all but one crowd counting papers are China affiliated)

&amp;#x200B;

I wonder whether I am being overly sensitive due to recent influx of news about Uighurs in China and Hong Kong protests etc. or if these papers are basically funded by the Chinese government (or its extensions) for some big brother stuff.

What is your opinion on the research on these subjects which can be used for some ethically questionable applications getting published in top conferences?",167,400,False,self,,,,,
1768,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,16,dp3cgw,self.MachineLearning,So sick on ML communities on Twitter AND Reddit,https://www.reddit.com/r/MachineLearning/comments/dp3cgw/so_sick_on_ml_communities_on_twitter_and_reddit/,sylvainandradekftw,1572419978,[removed],0,1,False,self,,,,,
1769,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,16,dp3deb,chandigarh.in.locanto.asia,"Get Genuine Research Thesis Topics in Machine Learning, mohali",https://www.reddit.com/r/MachineLearning/comments/dp3deb/get_genuine_research_thesis_topics_in_machine/,WriteMyThesis,1572420175,,0,1,False,default,,,,,
1770,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,16,dp3fcf,self.MachineLearning,Eric Schmidt on state-of-the-art in AI,https://www.reddit.com/r/MachineLearning/comments/dp3fcf/eric_schmidt_on_stateoftheart_in_ai/,sylvainandradekftw,1572420586,[removed],0,1,False,self,,,,,
1771,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,16,dp3fzl,arxiv.org,[R] [1910.13406] Generalization of Reinforcement Learners with Working and Episodic Memory,https://www.reddit.com/r/MachineLearning/comments/dp3fzl/r_191013406_generalization_of_reinforcement/,ada_td,1572420724,,1,1,False,default,,,,,
1772,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,16,dp3ngl,arxiv.org,[R][NeurIPS2019][RL] Generalization of Reinforcement Learners with Working and Episodic Memory,https://www.reddit.com/r/MachineLearning/comments/dp3ngl/rneurips2019rl_generalization_of_reinforcement/,ada_td,1572422330,,1,4,False,default,,,,,
1773,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,17,dp41m1,self.MachineLearning,"I'm very interested in entering the world of machine learning, what programs and guides would you say are essential.",https://www.reddit.com/r/MachineLearning/comments/dp41m1/im_very_interested_in_entering_the_world_of/,jamesbakerrr,1572425456,[removed],0,1,False,self,,,,,
1774,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,18,dp4hsp,self.MachineLearning,data science courses,https://www.reddit.com/r/MachineLearning/comments/dp4hsp/data_science_courses/,hannafrans,1572428816,[removed],0,1,False,self,,,,,
1775,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,19,dp4vsz,self.MachineLearning,[Post],https://www.reddit.com/r/MachineLearning/comments/dp4vsz/post/,cdossman,1572431454,[removed],0,1,False,self,,,,,
1776,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,19,dp4wbe,self.MachineLearning,Need help demonstrating C&amp;W attack,https://www.reddit.com/r/MachineLearning/comments/dp4wbe/need_help_demonstrating_cw_attack/,mrhspecter90,1572431545,[removed],0,1,False,self,,,,,
1777,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,19,dp4yln,self.MachineLearning,"[R] Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities, and Challenges",https://www.reddit.com/r/MachineLearning/comments/dp4yln/r_explainable_artificial_intelligence_xai/,cdossman,1572431951,[removed],0,1,False,self,,,,,
1778,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,19,dp51wi,i.redd.it,What could be causing this result of my actual values against residuals? Couldn't find anything similar?,https://www.reddit.com/r/MachineLearning/comments/dp51wi/what_could_be_causing_this_result_of_my_actual/,Lunacy0,1572432601,,0,1,False,default,,,,,
1779,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,20,dp55n8,self.MachineLearning,[News] Robotic hand made by Elon Musk's OpenAI learns to solve Rubik's Cube,https://www.reddit.com/r/MachineLearning/comments/dp55n8/news_robotic_hand_made_by_elon_musks_openai/,Anirban_Hazra,1572433275,Last year we were amazed by the level of dexterity achieved by OpenAI's  Dactyl system which was able to learn how to manipulate a cube block to  display any commanded side/face. OpenAI then set themselves a harder task of teaching the robotic hand to  solve a Rubik's cube. Quite a daunting task made no easier by the fact  that it would use one hand which most humans would find it hard to do.,1,1,False,self,,,,,
1780,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,20,dp5kv8,self.MachineLearning,[D] You job as a Machine Learning Engineer?,https://www.reddit.com/r/MachineLearning/comments/dp5kv8/d_you_job_as_a_machine_learning_engineer/,vladosaurus,1572435884,"Hi everyone,

I guess everyone here works or has worked as a Machine Learning Engineer (or similar). I think the definition of this role depends on the company you are working: it might be already using and deploying ML models, implementing and training some specific ML systems, reading and implementing the models from the papers, working on a library and so on.

So, my question is, how is your work organized, what does it include as a Machine Learning engineer?",19,8,False,self,,,,,
1781,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,20,dp5q92,youtube.com,Ways to improve Industrial Safety through Vision Analytics,https://www.reddit.com/r/MachineLearning/comments/dp5q92/ways_to_improve_industrial_safety_through_vision/,optisol,1572436789,,0,1,False,https://a.thumbs.redditmedia.com/Robdof17SYeOOuXMoIQQEVdQ1ziilo0NeKX7UHAjfm4.jpg,,,,,
1782,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,20,dp5qae,self.MachineLearning,ResNET model on Tensorflow,https://www.reddit.com/r/MachineLearning/comments/dp5qae/resnet_model_on_tensorflow/,khazi123,1572436795,[removed],0,1,False,self,,,,,
1783,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,21,dp6b8w,self.MachineLearning,[D] Deploying to production,https://www.reddit.com/r/MachineLearning/comments/dp6b8w/d_deploying_to_production/,mekass,1572439943,"Hello,

What services are you using to deploy your deep learning model to production? GCP AI Platform, Amazon Sagemaker, etc.?",3,1,False,self,,,,,
1784,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,22,dp6eq8,self.MachineLearning,250+ Machine Learning and Deep Learning Resources (Courseware and Lecture Videos),https://www.reddit.com/r/MachineLearning/comments/dp6eq8/250_machine_learning_and_deep_learning_resources/,BlisteringBernacle,1572440440,[removed],0,2,False,self,,,,,
1785,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,22,dp6l4z,elink.io,5 Facial Recognition Technology Trends and Market Predictions,https://www.reddit.com/r/MachineLearning/comments/dp6l4z/5_facial_recognition_technology_trends_and_market/,Neil_Patel001,1572441318,,0,1,False,https://b.thumbs.redditmedia.com/X-8hW5lg84_BZ0HD0_Vly8upU0dgHbrTP3EPFXZ6uKA.jpg,,,,,
1786,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,22,dp6rmx,self.MachineLearning,[R] Topics on the rise and in decline in ICLR submissions,https://www.reddit.com/r/MachineLearning/comments/dp6rmx/r_topics_on_the_rise_and_in_decline_in_iclr/,blazej0,1572442246,"We have analyzed abstracts and keywords of ICLR submissions over the last three years and observed interesting patterns, such as decreasing fraction of papers about GANs and increasing interest in attention/transformer and neural architecture search.

For more details see:
https://deepsense.ai/key-findings-from-the-international-conference-on-learning-representations-iclr/",17,15,False,self,,,,,
1787,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,22,dp6xfc,self.MachineLearning,Does anyone know the review release date for AISTATS 2020 ?,https://www.reddit.com/r/MachineLearning/comments/dp6xfc/does_anyone_know_the_review_release_date_for/,michel_kohlhaas,1572443048,[removed],0,1,False,self,,,,,
1788,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,22,dp6yvm,self.MachineLearning,Neural Synesthesia: GANs generating video based on music,https://www.reddit.com/r/MachineLearning/comments/dp6yvm/neural_synesthesia_gans_generating_video_based_on/,lakenp,1572443254,"Xander Steenbrugge built GANs to generate video output based on changing audio cues. I guess he trained them to produce stills, faces, and what not. The combination of continuously morphing images along with trance-inducing music is full-on brain porn if you'd ask me:

[https://paulvanderlaken.com/2019/10/29/neural-synthesia-gan-ai-dreaming-of-music/](https://paulvanderlaken.com/2019/10/29/neural-synthesia-gan-ai-dreaming-of-music/)",0,1,False,self,,,,,
1789,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,23,dp74wl,self.MachineLearning,[N] We just open sourced our no-frills ML-devops. Introducing: trains-agent,https://www.reddit.com/r/MachineLearning/comments/dp74wl/n_we_just_open_sourced_our_nofrills_mldevops/,LSTMeow,1572444077,"Hi r /ML,

Four months ago we open-sourced our experiment management platform. [My relevant post](https://www.reddit.com/r/MachineLearning/comments/c2g2li/n_there_are_many_platforms_to_manage_your_ml/) on r /ML eventually gave us valuable feedback from actual researchers. One of the recurring themes was that we were lacking a definitive differentiation from other solutions.  
Well, I am happy to announce that we took that to heart and are now adding... &lt;drumroll.wav&gt;

**All the devops your research is going to need**^(and then some)

Now live at (star/forks are appreciated): [trains-agent](https://github.com/allegroai/trains-agent)

We are eager to know if the readme conveys just how cool this thing is!

tl;dr:

* An order of magnitude easier maintenance than K8S for research 
* Schedule GPU resources across any cloud and/or on-prem (and only use containers if you want to)
* Straightforward, automagical configuration
* User friendly UI
* Roll your own autoML

The fine print: your agents work in conjunction with your trains platform.

FAQ:

1. Why are we releasing this as FOSS - We feel that automagical devops are necessary for research ;)  Our formal answer is still valid:  We acknowledge that deep learning R&amp;D and operations are not well-established yet, and we want TRAINS to remain relevant as paradigms shift in the field
2.  counting on you guys here. AMA?

PS: If anyone is at ODSC West on 10/31, Come meet Gregory from our team, he will be talking about [Integrating data as part of autoML](https://staging5.odsc.com/training/portfolio/automl-at-scale-integrating-data-as-part-of-hyperparameter-optimization/)",2,7,False,self,,,,,
1790,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,23,dp76wu,self.MachineLearning,Visualize Node Importance with Attention while doing Graph Embedding using Graph Convolution,https://www.reddit.com/r/MachineLearning/comments/dp76wu/visualize_node_importance_with_attention_while/,hmsajjad,1572444330,[removed],0,1,False,self,,,,,
1791,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,23,dp7f0n,self.MachineLearning,[Free Course-Udemy] - Python for Machine Learning bootcamp,https://www.reddit.com/r/MachineLearning/comments/dp7f0n/free_courseudemy_python_for_machine_learning/,upworknepal,1572445397,[removed],0,1,False,self,,,,,
1792,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,23,dp7i8a,self.MachineLearning,[D] Which performance metric should be used for cases of *minor* class imbalance?,https://www.reddit.com/r/MachineLearning/comments/dp7i8a/d_which_performance_metric_should_be_used_for/,user381,1572445818,"There has been a lot of discussion with regards to choosing an appropriate performance metric to use for model training and evaluation for classification problems with a moderate to large amount of class imbalance present (e.g. [1](https://towardsdatascience.com/metrics-for-imbalanced-classification-41c71549bbb5), [2](https://stats.stackexchange.com/questions/222558/classification-evaluation-metrics-for-highly-imbalanced-data), [3](https://stats.stackexchange.com/questions/312780/why-is-accuracy-not-the-best-measure-for-assessing-classification-models), [4](https://stats.stackexchange.com/questions/331067/which-metrics-to-focus-on-classification-problem-with-imbalanced-classes), [5](https://stats.stackexchange.com/questions/90779/area-under-the-roc-curve-or-area-under-the-pr-curve-for-imbalanced-data/)).

In these cases, it is generally suggest that one uses a metric like [cohen's kappa](https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/) or [PR AUC](https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/) in place of accuracy or [AUROC](https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5), perhaps along with up-sampling or [SMOTE](https://jair.org/index.php/jair/article/view/10302).

What are people's thoughts on cases where there is only a *minor* class imbalance present in the data? For example, something like a 3:1, 2:1, or even 1.5:1 ratio of major to minor class members? Is it still beneficial (and what would be the cost?) or using a metric geared at addressing larger imbalances in these cases?

Also, somewhat tangential, but are there ever any scenarios where you might want to use one metric for an outer CV loop / model performance evaluation, but a different metric for inner CV (e.g. feature selection / hyperparameter optimization)?",6,1,False,self,,,,,
1793,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,23,dp7j91,self.MachineLearning,Introduction to ML,https://www.reddit.com/r/MachineLearning/comments/dp7j91/introduction_to_ml/,pranjal_22,1572445957,[removed],0,1,False,self,,,,,
1794,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,23,dp7riw,self.MachineLearning,A question about autoencoders and custom loss functions,https://www.reddit.com/r/MachineLearning/comments/dp7riw/a_question_about_autoencoders_and_custom_loss/,Quentin-Martell,1572446987,[removed],0,1,False,self,,,,,
1795,MachineLearning,t5_2r3gv,2019-10-30,2019,10,30,23,dp7wdg,self.MachineLearning,Peak Detection and Localization ML Data Labeling,https://www.reddit.com/r/MachineLearning/comments/dp7wdg/peak_detection_and_localization_ml_data_labeling/,khouloudabdelli,1572447592,"I am working in solving a problem of peak detection and localization in noisy data using machine learning techniques . The ML Model should be able to  distinguish  the  true peak from noise spikes ( false peak ) , to localize the peak ( the position of the peak )  and to estimate the height or the amplitude of the peak . 

The data is composed of sequences of signal level or power and the corresponding distance . To label the data  , I was thinking of the followings :

1) The input  is a sequence of signal level and the output are  the signal level of the starting point of the peak ( representing the location of the peak ) and the height of the peak 

2) the input  is a sequence of signal level and the output are  the index of the starting point of the peak and the height of the peak 

3)  the inputs are the sequence of signal level and the distance and the output are the distance ( the location of the peak ) and the height of the peak 

4 ) the input is a sequence of signal level and the output is a sequence composed of 0 and 1 : 0 means no peak and 1  means peak and height of the peak 

For the ML Model , I plan to use LSTM and the problem should be multi output regression . 

So , I would like to ask you which approach ( 1 , 2 , 3 or 4 )  is better for this type of problem and which ML model works better for this specific type of problem or it depends of the type of data and the performance of ML Model after training ? 

Many thanks in advance  !",0,1,False,self,,,,,
1796,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,0,dp8mll,self.MachineLearning,"Simple Questions Thread October 30, 2019",https://www.reddit.com/r/MachineLearning/comments/dp8mll/simple_questions_thread_october_30_2019/,AutoModerator,1572450763,[removed],0,1,False,self,,,,,
1797,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,1,dp8ubm,ocaml.xyz,Machine and Deep Learning with OCaml Natively,https://www.reddit.com/r/MachineLearning/comments/dp8ubm/machine_and_deep_learning_with_ocaml_natively/,techpreneur_13,1572451678,,0,1,False,default,,,,,
1798,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,1,dp909j,self.MachineLearning,[R] BANANAS: A new method for neural architecture search,https://www.reddit.com/r/MachineLearning/comments/dp909j/r_bananas_a_new_method_for_neural_architecture/,naszilla,1572452395,"Hey, just wanted to post some of our recent work on Bayesian optimization for neural architecture search. We show how to use a neural network to predict the accuracy of cell-based neural networks, and how this can be used for neural architecture search.

BANANAS: Bayesian optimization with neural architectures for neural architecture search

Arxiv: [https://arxiv.org/abs/1910.11858](https://arxiv.org/abs/1910.11858)

code: [https://github.com/naszilla/bananas](https://github.com/naszilla/bananas)

blog: [https://medium.com/reality-engines/bananas-a-new-method-for-neural-architecture-search-192d21959c0c](https://medium.com/reality-engines/bananas-a-new-method-for-neural-architecture-search-192d21959c0c)",2,12,False,self,,,,,
1799,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,1,dp959l,self.MachineLearning,[Research] Harnessing Indirect Training Data for End-to-End Automatic Speech Translation: Tricks of the Trade,https://www.reddit.com/r/MachineLearning/comments/dp959l/research_harnessing_indirect_training_data_for/,cdossman,1572452989,[removed],0,1,False,self,,,,,
1800,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,1,dp95lr,self.MachineLearning,Looking for new things to learn about Machine Learning,https://www.reddit.com/r/MachineLearning/comments/dp95lr/looking_for_new_things_to_learn_about_machine/,Rahul_Desai1999,1572453033,[removed],0,1,False,self,,,,,
1801,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,1,dp9cbw,self.MachineLearning,Is regularization critical for Residual Networks (ResNet) to work?,https://www.reddit.com/r/MachineLearning/comments/dp9cbw/is_regularization_critical_for_residual_networks/,gerry_mandering_50,1572454231,"Can skip links still be used by the model in the absence of regularization?

Empirical or theoretical responses are invited!",5,1,False,self,,,,,
1802,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,2,dp9hgu,medium.com,Build your own RL environments w/ Unity ML agents,https://www.reddit.com/r/MachineLearning/comments/dp9hgu/build_your_own_rl_environments_w_unity_ml_agents/,formalsystem,1572455082,,0,1,False,default,,,,,
1803,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,2,dp9hp7,arxiv.org,[R] A Mulching Proposal,https://www.reddit.com/r/MachineLearning/comments/dp9hp7/r_a_mulching_proposal/,villasv,1572455114,,3,1,False,default,,,,,
1804,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,2,dp9r6u,self.MachineLearning,[R] Multi-Task Modeling of Phonographic Languages: Translating Middle Egyptian Hieroglyphs,https://www.reddit.com/r/MachineLearning/comments/dp9r6u/r_multitask_modeling_of_phonographic_languages/,statnlphd,1572456253,"Abstract:

Machine translation of ancient languages faces a low-resource problem, caused by the limited amount of available textual source data and their translations. We present a multi-task modeling approach to translating Middle Egyptian that is inspired by recent successful approaches to multi-task learning in end-to-end speech translation. We leverage the phonographic aspect of the hieroglyphic writing system, and show that similar to multi-task learning of speech recognition and translation, joint learning and sharing of structural information between hieroglyph transcriptions, translations, and POS tagging can improve direct translation of hieroglyphs by several BLEU points, using a minimal amount of manual transcriptions.

[paper](https://www.cl.uni-heidelberg.de/statnlpgroup/publications/IWSLT2019.pdf) [blog post](https://www.cl.uni-heidelberg.de/statnlpgroup/blog/egyptian/)

We're presenting this at IWSLT 2019 in Hong Kong in a poster session, if you're there please stop by and ask questions!",0,11,False,self,,,,,
1805,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,2,dp9ry9,self.MachineLearning,[P] What are the biggest issues in Unsuprvised Learning Today?,https://www.reddit.com/r/MachineLearning/comments/dp9ry9/p_what_are_the_biggest_issues_in_unsuprvised/,Justice_Drrrrriver,1572456340,"Myself and a small team have been trying to improve unsupervised learning pipelines locally at the office and have realized that the solutions cross industry are pretty disparate and may represent a cool open source product oppurtunity. I'd love to get feedback from this group on where the biggest issues are for you. We put together a survey which goes a little more in depth,

Survey Monkey Link:  [https://www.surveymonkey.com/r/MLsurvey12](https://www.surveymonkey.com/r/MLsurvey12) 

Thanks a ton for any feedback",2,0,False,self,,,,,
1806,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,2,dp9vu5,self.MachineLearning,Deep Learning Model to predict clicks from keywords,https://www.reddit.com/r/MachineLearning/comments/dp9vu5/deep_learning_model_to_predict_clicks_from/,nickefy,1572456787,"Hi guys, im trying to build a model where it takes in a phrase of keyword ( not more than 5 words, eg: mechanical engineer ) and outputs a value (like clicks, eg: 56), im using the bag of words approach which resulted in about 50% accuracy which is not good enough. Can I get some opinions on what approach you would take ?",0,1,False,self,,,,,
1807,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,2,dp9z6h,medium.com,ChineseGLUE  New NLU Benchmark for Chinese NLP Models,https://www.reddit.com/r/MachineLearning/comments/dp9z6h/chineseglue_new_nlu_benchmark_for_chinese_nlp/,Yuqing7,1572457176,,0,2,False,default,,,,,
1808,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,2,dpa54a,self.MachineLearning,"""Machine Learning-Based Analysis of Sperm Videos""",https://www.reddit.com/r/MachineLearning/comments/dpa54a/machine_learningbased_analysis_of_sperm_videos/,TrueBirch,1572457902,"[https://arxiv.org/abs/1910.13327](https://arxiv.org/abs/1910.13327)

I thought this was interesting for a few reasons:

* I'll admit that I clicked on the link because I was curious what ""sperm videos"" had to do with machine learning
* Only 250 frames from each of 85 training videos gave the authors enough data to train a model
* The authors post the results from a bunch of different machine learning techniques including linear regression; too many authors cherry pick only the single best approach for their papers
* I like papers that describe the full research process from beginning to end
* The authors are realistic about the scope of their findings instead of overpromising",0,1,False,self,,,,,
1809,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,3,dpaebz,self.MachineLearning,Are the machine learning courses offered for free on Amazon and Google worth checking out?,https://www.reddit.com/r/MachineLearning/comments/dpaebz/are_the_machine_learning_courses_offered_for_free/,NicCage4life,1572459018,[removed],0,1,False,self,,,,,
1810,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,3,dpagwg,self.MachineLearning,[D] Good examples of Github Readme files,https://www.reddit.com/r/MachineLearning/comments/dpagwg/d_good_examples_of_github_readme_files/,chrico031,1572459345,"I'm looking to clean-up a few of my Github repos and am wondering if anyone has good examples of Readme.md files they've seen/made, specifically for Machine Learning and/or Deep Learning projects.",0,0,False,self,,,,,
1811,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,3,dpakbd,self.MachineLearning,Machine Learning course for Medical Doctor,https://www.reddit.com/r/MachineLearning/comments/dpakbd/machine_learning_course_for_medical_doctor/,mr_geeky,1572459742,[removed],1,1,False,self,,,,,
1812,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,3,dpama6,self.MachineLearning,.ai domain names for sale!,https://www.reddit.com/r/MachineLearning/comments/dpama6/ai_domain_names_for_sale/,beb619,1572459973,[removed],0,1,False,self,,,,,
1813,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,3,dparnx,self.MachineLearning,"Realistically, what are my chances of being accepted to Googles AI residency program?",https://www.reddit.com/r/MachineLearning/comments/dparnx/realistically_what_are_my_chances_of_being/,JoR2016,1572460621,[removed],0,1,False,self,,,,,
1814,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,3,dpav5f,medium.com,Yoshua Bengio on Human vs Machine Intelligence,https://www.reddit.com/r/MachineLearning/comments/dpav5f/yoshua_bengio_on_human_vs_machine_intelligence/,Yuqing7,1572461046,,0,1,False,default,,,,,
1815,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,4,dpblbg,deepmind.com, AlphaStar: Grandmaster level in StarCraft II using multi-agent reinforcement learning,https://www.reddit.com/r/MachineLearning/comments/dpblbg/alphastar_grandmaster_level_in_starcraft_ii_using/,sjoerdapp,1572464179,,0,1,False,default,,,,,
1816,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,4,dpbper,self.MachineLearning,[R] AlphaStar: Grandmaster level in StarCraft II using multi-agent reinforcement learning,https://www.reddit.com/r/MachineLearning/comments/dpbper/r_alphastar_grandmaster_level_in_starcraft_ii/,Mister_Abc,1572464657,"[https://deepmind.com/blog/article/AlphaStar-Grandmaster-level-in-StarCraft-II-using-multi-agent-reinforcement-learning](https://deepmind.com/blog/article/AlphaStar-Grandmaster-level-in-StarCraft-II-using-multi-agent-reinforcement-learning)

&amp;#x200B;

Deepmind releases AlphaStar and their soon-to-be-published Nature paper",111,316,False,self,,,,,
1817,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,4,dpbwk4,self.MachineLearning,Recommendations of courses with certification,https://www.reddit.com/r/MachineLearning/comments/dpbwk4/recommendations_of_courses_with_certification/,JoseChovi,1572465489,[removed],0,1,False,self,,,,,
1818,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,4,dpbxef,self.MachineLearning,[D] Hi guys! We just published a guide to video analytics and its advancements with machine learning. Would love to know your thoughts about it.,https://www.reddit.com/r/MachineLearning/comments/dpbxef/d_hi_guys_we_just_published_a_guide_to_video/,minmidinosaur,1572465580,[removed],0,1,False,self,,,,,
1819,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,5,dpc5yv,self.MachineLearning,[D] How should we think about public comments before review-submission on OpenReview?,https://www.reddit.com/r/MachineLearning/comments/dpc5yv/d_how_should_we_think_about_public_comments/,asdfwaevc,1572466619,"For better or worse, OpenReview gives a lot of power to individuals not assigned reviewer roles. We've all seen good examples of this (e.g. pointing out something important you're sure could be missed by a reviewer, like ""your code uses train data at test time!"") and bad examples of this (e.g. trolling, or pure opinions like ""This is a useless result."") But there's a lot room between these.

People who comment on OpenReview before paper-acceptances are finalized, and people with opinions on the matter, how should we as a community approach this new tool? What do you think you should be trying to add with a comment? What are you careful not to do?",4,1,False,self,,,,,
1820,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,5,dpcbzl,self.MachineLearning,[N] Tensorflow Enterprise launches,https://www.reddit.com/r/MachineLearning/comments/dpcbzl/n_tensorflow_enterprise_launches/,farmingvillein,1572467334,"https://cloud.google.com/tensorflow-enterprise/

A lot of marketing speak, but one salient point here seems to be that--if I'm interpreting correctly--they are effectively degrading read/write from GCS if you're on ""regular"" (non-Enteprise) TF: https://cloud.google.com/blog/products/ai-machine-learning/tensorflow-enterprise-makes-accessing-data-on-google-cloud-faster-and-easier.

Sad to see Google going this direction.",0,1,False,self,,,,,
1821,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,5,dpclze,arxiv.org,[R] [1910.13267] BPE-Dropout: Simple and Effective Subword Regularization,https://www.reddit.com/r/MachineLearning/comments/dpclze/r_191013267_bpedropout_simple_and_effective/,bobchennan,1572468529,,2,18,False,default,,,,,
1822,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,6,dpcsms,self.MachineLearning,[D] The top 3 talks from MLconf 2019 - With full video links,https://www.reddit.com/r/MachineLearning/comments/dpcsms/d_the_top_3_talks_from_mlconf_2019_with_full/,shonburton,1572469300,"These are the top 3 most popular talks (by views) from MLconf NYC 2019. All 3 are excellent talks: [The next MLconf event](https://www.eventbrite.com/e/mlconf-sf-2019-tickets-52641374769) is in San Francisco on 11/8, that's next week!  


1. Rishabh Mehrotra, Research Scientist, Spotify: [Personalizing Explainable Recommendations with Multi-objective Contextual Bandits](https://mlconf.com/sessions/recommendations-in-a-marketplace-personalizing-explainable-recommendations-with-multi-objective-contextual-bandits/)
2.  Emily Pitler, Staff Research Scientist, Google AI: [Representations from natural language data: successes and challenges](https://mlconf.com/sessions/representations-from-natural-language-data-successes-and-challenges/)
3. Nitin Sharma, Research Scientist, PayPal: [Deep Learning Applications to Online Payment Fraud Detection](https://mlconf.com/sessions/distinguished-scientist-at-paypaldeep-learning-applications-to-online-payment-fraud-detection/)  


\*If you'd like to attend MLconf in San Francisco next, you can use the discount code ""slashml19"" for 50% off, register here: [https://www.eventbrite.com/e/mlconf-sf-2019-tickets-52641374769](https://www.eventbrite.com/e/mlconf-sf-2019-tickets-52641374769) \- This code is only good for 6 total tickets, once it's out it will say it's expired. First to register gets the discount.  


You can find all of the past MLconf videos on the [MLconf YouTube page here](https://www.youtube.com/channel/UCjeM1xxYb_37bZfyparLS3Q/videos). Subscribe to see the newest talks as they arrive.  


Please let us know what you think of the talks, speakers, topics, and anything you would be interested in for future events here in the discussion.",1,6,False,self,,,,,
1823,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,6,dpd5rq,self.MachineLearning,[Discussion] Looking for Tool for Synthetic 3D Pose Generation,https://www.reddit.com/r/MachineLearning/comments/dpd5rq/discussion_looking_for_tool_for_synthetic_3d_pose/,C4ptainK1ng,1572470825,"Hey there,
I am a Master Student from germany currently working on some pose detection with tf pose. I am looking for a tool which can generate realistic 3d pose keypoints. It does not need create images for Training, just realistic 3d keypoints for customizable poses. Has anybody of you already experience with such a ""Tool""?
 I would be very grateful for your help. 
Thanks",5,2,False,self,,,,,
1824,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,7,dpe3m7,i.redd.it,"Clearly, no machine could learn that. How could we not see this, all the years!",https://www.reddit.com/r/MachineLearning/comments/dpe3m7/clearly_no_machine_could_learn_that_how_could_we/,bEAc0n,1572474764,,1,1,False,https://b.thumbs.redditmedia.com/Ufcp_az1OlHPGohRE08yWBeV3l7AKZIyG25-KLVi0pU.jpg,,,,,
1825,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,7,dpe7ll,self.MachineLearning,Is reinforcement learning is sub-par?,https://www.reddit.com/r/MachineLearning/comments/dpe7ll/is_reinforcement_learning_is_subpar/,gerry_mandering_50,1572475228,[removed],0,1,False,self,,,,,
1826,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,7,dpe8iy,self.MachineLearning,[D] I have my first interview for a machine learning job on Friday. Looking for advice and tips?,https://www.reddit.com/r/MachineLearning/comments/dpe8iy/d_i_have_my_first_interview_for_a_machine/,that_one_ai_nerd,1572475341,"I have been working in machine learning professionally for a little over 3 years now, 2 of which were spent working as a freelancer through Upwork.com and 1 of which was spent as the founder of an start up company. However, Ive been considering moving into a more traditional role at a firm mainly to gain the experience and be able to learn from other people at the company. Not to mention freelancing can get pretty lonely over extended periods of time. I didnt finish my degree yet, however I only need my capstone and ~9 credit hours to complete it, and right now I am just doing the Senior Capstone and am not sure I am going to pursue completion (I know it sounds stupid, just trust Ive given it a lot of thought, and I am not here to discuss that). Also, my Upwork profile is in great standing and has 5 star reviews for large long-term projects and a 100% job success rate.

Anyways, I ended being contacted by a recruiter on LinkedIn, submitted my resume, and now I have my first interview in the field on Friday. I am not so much nervous as I am just not sure what to expect, and I was hoping that people who have experience with machine learning interviews might be able to give me some pointers and tips, let me know anything I should review and make sure to know, etc. As far as any coding that they may require, I feel fairly confident about being able to solve ML problems effectively. But I dont know whether they do the standard coding interviews for these roles, in which case I need to brush on my Data Structures and Algortihms for sure.

And lastly, I thought about asking the person whos going to be interviewing me what to expect, but then decided that doing that is unprofessional and might make look bad or something (I hate fuckin corporate politics, but thats OK, I can deal for awhile). Was this the right decision or is it normal to ask something like that?

Many thanks again guys, and I think itd be great if this post could just serve as a sort of repository of advice for interviewing for ML jobs in general, so when offering advice I think its best to think whats the best advice I could in general and pretty much ignoring my specific concerns. Cheers!",8,0,False,self,,,,,
1827,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,8,dpewu7,self.MachineLearning,Steps to conduct object detection in detail,https://www.reddit.com/r/MachineLearning/comments/dpewu7/steps_to_conduct_object_detection_in_detail/,naturalsmen,1572478292,[removed],0,1,False,self,,,,,
1828,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,9,dpff17,venturebeat.com,[N] Google launches TensorBoard.dev and TensorFlow Enterprise,https://www.reddit.com/r/MachineLearning/comments/dpff17/n_google_launches_tensorboarddev_and_tensorflow/,the_sixth_degree,1572480571,,0,1,False,https://b.thumbs.redditmedia.com/KFMN3dQ7RprI4aETzJWbU-T9KWVPhViE1ewTGqMMYzs.jpg,,,,,
1829,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,10,dpgol9,self.MachineLearning,Time Distributed CNN,https://www.reddit.com/r/MachineLearning/comments/dpgol9/time_distributed_cnn/,ishwarchoudhary,1572486340,[removed],0,1,False,self,,,,,
1830,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,12,dpho0i,self.MachineLearning,Why researchers from Chinese institutes prefer submitting their works to CVPR/ICCV rather than NeurIPS/ICLR?,https://www.reddit.com/r/MachineLearning/comments/dpho0i/why_researchers_from_chinese_institutes_prefer/,hitaho,1572491148,[removed],0,1,False,self,,,,,
1831,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,12,dpi7ja,self.MachineLearning,[D] Feasibility of running an ML model on phone hardware?,https://www.reddit.com/r/MachineLearning/comments/dpi7ja/d_feasibility_of_running_an_ml_model_on_phone/,hanyuqn,1572494151,"I've trained a tensorflow model which takes my RTX2080 several seconds per action (in addition to 20-30 seconds to initialize the model). I've been looking into turning this into an iOS/Andriod app running on tensorflow lite, but apart from the technical challenge of converting the model into a tensorflow lite model and everything else, am wondering about the feasibility of this running on phone hardware - even on a reasonably modern phone with inbuilt GPU would this still likely be too slow for practical purposes? Can anyone who has built an iOS/Android app with tensorflow lite where the phone is responsible for computation comment on performance and other practical considerations? The only other option of having requests served by my own server(s) on AWS for example would turn into a major expense if the app had significant use.",24,6,False,self,,,,,
1832,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,14,dpiy1t,self.MachineLearning,Maths for GAN,https://www.reddit.com/r/MachineLearning/comments/dpiy1t/maths_for_gan/,bikigoogler,1572498615,[removed],0,1,False,self,,,,,
1833,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,15,dpjrme,arxiv.org,[R] Multimodal Model-Agnostic Meta-Learning via Task-Aware Modulation,https://www.reddit.com/r/MachineLearning/comments/dpjrme/r_multimodal_modelagnostic_metalearning_via/,hardmaru,1572504379,,1,0,False,default,,,,,
1834,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,15,dpju4v,arxiv.org,[R] Relay Policy Learning: Solving Long-Horizon Tasks via Imitation and Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/dpju4v/r_relay_policy_learning_solving_longhorizon_tasks/,baylearn,1572504877,,2,9,False,default,,,,,
1835,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,16,dpk2ni,self.MachineLearning,What is the review release date for AISTATS ?,https://www.reddit.com/r/MachineLearning/comments/dpk2ni/what_is_the_review_release_date_for_aistats/,michel_kohlhaas,1572506616,[removed],0,1,False,self,,,,,
1836,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,17,dpkmsg,self.MachineLearning,what are some good reads on low-resourced NLP techniques? Is Bert a good direction to start ?,https://www.reddit.com/r/MachineLearning/comments/dpkmsg/what_are_some_good_reads_on_lowresourced_nlp/,thak123,1572511019,"I want to get many hands dirty with low-resourced nlp techniques may be along with cross-lingual knowledge transfer.

But I am not getting any leads straight or there are too many items on plate.

Can someone get me a start point ?",0,1,False,self,,,,,
1837,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,17,dpko6f,arxiv.org,[R] A Prior of a Googol Gaussians: a Tensor Ring Induced Prior for Generative Models,https://www.reddit.com/r/MachineLearning/comments/dpko6f/r_a_prior_of_a_googol_gaussians_a_tensor_ring/,hardmaru,1572511316,,3,5,False,default,,,,,
1838,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,18,dpl29t,techxplore.com,Neural network reconstructs human thoughts from brain waves in real time,https://www.reddit.com/r/MachineLearning/comments/dpl29t/neural_network_reconstructs_human_thoughts_from/,alonsogp2,1572514163,,0,1,False,https://b.thumbs.redditmedia.com/aenaosiySqE5bCVgZ6XudiS75mAFgpZI-wEGzJVPjbE.jpg,,,,,
1839,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,18,dpl7sv,medium.com,Gaining Insights about Real Estate Properties From Online Reviews Using NLP,https://www.reddit.com/r/MachineLearning/comments/dpl7sv/gaining_insights_about_real_estate_properties/,_orcaman,1572515249,,0,1,False,default,,,,,
1840,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,19,dpldzv,self.MachineLearning,[P] Milvus: A big leap to scalable AI search engine,https://www.reddit.com/r/MachineLearning/comments/dpldzv/p_milvus_a_big_leap_to_scalable_ai_search_engine/,rainmanwy,1572516392,"# The challenge with data search

The explosion in unstructured data, such as images, videos, sound records, and text, requires an effective solution for computer vision, voice recognition, and natural language processing. How to extract value from unstructured data poses as a big challenge for many enterprises.

AI, especially deep learning, has been proved as an effective solution. Vectorization of data features enables people to perform content-based search on unstructured data. For example, you can perform content-based image retrieval, including facial recognition and object detection, etc.

&amp;#x200B;

https://preview.redd.it/20lpm6iqouv31.png?width=5148&amp;format=png&amp;auto=webp&amp;s=75051c51002f71687a1ff2eae8f6b8690b2b388e

Now the challenge turns into how to execute effectively search among billions of vectors. Thats what Milvus is designed for.

# What is Milvus?

Milvus is an open source distributed vector search engine that provides state-of-the-art similarity search and analysis of feature vectors and unstructured data. Some of its key features are:

* GPU-accelerated search engine

Milvus is designed for the largest scale of vector index. CPU/GPU heterogeneous computing architecture allows you to process data at a speed 1000 times faster.

* Intelligent index

With a Decide Your Own Algorithm approach, you can embed machine learning and advanced algorithms into Milvus without the headache of complex data engineering or migrating data between disparate systems. Milvus is built on optimized indexing algorithm based on quantization indexing, tree-based and graph indexing methods.

* Strong scalability

The data is stored and computed on a distributed architecture. This lets you scale data sizes up and down without redesigning the system.

* High compatibility

Milvus is compatible with major AI/ML models and programming languages such as C++, Java and Python.

&amp;#x200B;

https://preview.redd.it/2aadp060puv31.png?width=1275&amp;format=png&amp;auto=webp&amp;s=ce1f18df54bba4744f58421efec4c84374d2ea3a

# Billion-Scale similarity search

You may follow[ this link ](https://github.com/milvus-io/bootcamp/blob/master/EN_docs/labs/lab2_sift1b_100m.md)for step-by-step procedures to carry out performance test on 100 million vector search ([SIFT1B](http://corpus-texmex.irisa.fr/)).

If you want, you can also try testing 1 billion with Milvus. Here is the [hardware requirements](https://github.com/jielinxu/bootcamp/blob/master/EN_docs/milvus101/hardware_platform.md).

# Join us

Milvus has been open sourced lately. We greatly welcome contributors to join us in reinventing data science!

[Milvus on GitHub](https://github.com/milvus-io/milvus)

[Our Slack channel](https://join.slack.com/t/milvusio/shared_invite/enQtNzY1OTQ0NDI3NjMzLWNmYmM1NmNjOTQ5MGI5NDhhYmRhMGU5M2NhNzhhMDMzY2MzNDdlYjM5ODQ5MmE3ODFlYzU3YjJkNmVlNDQ2ZTk)

&amp;#x200B;

Check the original article:

[https://medium.com/@milvusio/milvus-a-big-leap-to-scalable-ai-search-engine-e9c5004543f](https://medium.com/@milvusio/milvus-a-big-leap-to-scalable-ai-search-engine-e9c5004543f)",33,123,False,https://b.thumbs.redditmedia.com/BljrwKWRgLxjBxuDPOHLthloMoSl2zo-NpC0sN3cOaY.jpg,,,,,
1841,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,19,dpln0r,smthelp.com,https://www.smthelp.com/feeder,https://www.reddit.com/r/MachineLearning/comments/dpln0r/httpswwwsmthelpcomfeeder/,smthelp1,1572518038,,0,1,False,default,,,,,
1842,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,19,dplqv2,youtube.com,150 successful machine learning models,https://www.reddit.com/r/MachineLearning/comments/dplqv2/150_successful_machine_learning_models/,TheTesseractAcademy,1572518774,,0,1,False,https://a.thumbs.redditmedia.com/w_-TfgMbBkSHaTxNi-4aeJge2rl1aEt5xPBgPIKfE88.jpg,,,,,
1843,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,20,dpm10m,self.MachineLearning,Why did self-organsing ANNs die off?,https://www.reddit.com/r/MachineLearning/comments/dpm10m/why_did_selforgansing_anns_die_off/,powerexcess,1572520475,[removed],0,1,False,self,,,,,
1844,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,21,dpmjwn,self.MachineLearning,Can't find where ICDAR 2019 accepted papers are being hosted?,https://www.reddit.com/r/MachineLearning/comments/dpmjwn/cant_find_where_icdar_2019_accepted_papers_are/,vikponcho,1572523501,[removed],0,1,False,self,,,,,
1845,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,22,dpnlsx,self.MachineLearning,Deep Learning models for cancer reports classification,https://www.reddit.com/r/MachineLearning/comments/dpnlsx/deep_learning_models_for_cancer_reports/,MphoMotionless,1572528851,"Hi guys, if anybody has worked on or currently working on NLP and specifically multiclass text classification for medical reports do you know of any state of the art approaches that one could use. I tried to use Graph convolutional networks but they ain't working so I am trying to find a better and new approach.

&amp;#x200B;

Thanks in advance",0,1,False,self,,,,,
1846,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,22,dpnu02,reddit.com,Variational Autoencoder to augment faces with features,https://www.reddit.com/r/MachineLearning/comments/dpnu02/variational_autoencoder_to_augment_faces_with/,venuv,1572529938,,0,1,False,default,,,,,
1847,MachineLearning,t5_2r3gv,2019-10-31,2019,10,31,23,dpoq51,louiskirsch.com,"[R] Meta Reinforcement Learning is good at adaptation to very similar environments. But can we meta-learn general RL algorithms? Our new approach MetaGenRL is able to. Work by Louis Kirsch, Sjoerd van Steenkiste, and Jrgen Schmidhuber.",https://www.reddit.com/r/MachineLearning/comments/dpoq51/r_meta_reinforcement_learning_is_good_at/,Time-Over,1572533978,,0,1,False,default,,,,,
