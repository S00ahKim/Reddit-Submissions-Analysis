,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2011-10-3,2011,10,3,0,kydpl,Best ML methods for working with all binary inputs?,https://www.reddit.com/r/MachineLearning/comments/kydpl/best_ml_methods_for_working_with_all_binary_inputs/,SunnyWindow,1317568347,"I've got a scenario where I have 2 classes (roughly 200 instances of each) and 100 binary features. No one feature is able to discriminate between the classes very well at all. However it looks like certain subsets of features might all have the same value for ~5% of instances of one class but not in the other class. Thus, for example, 10 instances of class A would have feature values f_34=0, f_52=1, f_88=1 but no other instances would have that pattern. I've played around with some tree-based methods with limited success but I'm pretty new to ML and I'm sure there's got to be some method designed for this kind of data (I just haven't found it yet). Any pointers are greatly appreciated. Thanks!

By the way, there is an earlier post that at first looked like it might answer my question but upon reading the contents seems to be about something else: http://www.reddit.com/r/MachineLearning/comments/krgam/machine_learning_on_binary_data/",21,7
1,2011-10-3,2011,10,3,5,kymxr,A technique for me is a task for you,https://www.reddit.com/r/MachineLearning/comments/kymxr/a_technique_for_me_is_a_task_for_you/,urish,1317588069,,0,14
2,2011-10-3,2011,10,3,21,kzaty,A Survey on Music Data Mining Papers,https://www.reddit.com/r/MachineLearning/comments/kzaty/a_survey_on_music_data_mining_papers/,camilopayan,1317646204,,1,18
3,2011-10-4,2011,10,4,3,kzm77,Text feature extraction (tf-idf) - Part II,https://www.reddit.com/r/MachineLearning/comments/kzm77/text_feature_extraction_tfidf_part_ii/,perone,1317667565,,8,20
4,2011-10-4,2011,10,4,6,kzsiq,Help! R package recommendations for predicting binary outcome from both continuous and discrete input variables?,https://www.reddit.com/r/MachineLearning/comments/kzsiq/help_r_package_recommendations_for_predicting/,ohsnaaap,1317677869,"I've been messing with glm, randomForest, and gam. Having trouble interpreting the results though. My output variable is just a two level factor and I have a mixture of factors as inputs as well as continuous variables as inputs. If I do end up with binary outcomes/predictions, how do I best quantify the results? Chi-square test (e.g. randomForest)? If I end up with probabilities as predictions, how do I quantify those results? (e.g. glmnet, gam)

Thanks for any direction.",3,2
5,2011-10-4,2011,10,4,9,kzxdy,"Looking for strategies for encoding input data with categorical fields that have a very large number of possible values, suitable for a Neural Net or SVM",https://www.reddit.com/r/MachineLearning/comments/kzxdy/looking_for_strategies_for_encoding_input_data/,[deleted],1317686528,"So I'm looking at situations where I have very large quantities of data, perhaps hundreds of millions of entries, where much of the input data is categorical in nature, for example zipcodes, or first names.

I know the recommended way to encode categorical data is to transform it to N fields, where there are N possible input values, and set the field corresponding to the value present in any given record to 1, while setting all the others to 0.

I'm concerned that where there might be hundreds of thousands of possible categorical values, that this will not scale.

Questions:

1. Will this scale?
* If not, how can I encode this type of data such that it will be suitable for a SVM or Neural Net?",10,0
6,2011-10-5,2011,10,5,23,l1pfc,Oracles Big Data Appliance to include R,https://www.reddit.com/r/MachineLearning/comments/l1pfc/oracles_big_data_appliance_to_include_r/,talgalili,1317823209,,1,7
7,2011-10-6,2011,10,6,1,l1v7v,"What do you guys think of the Siri demo, professionally?",https://www.reddit.com/r/MachineLearning/comments/l1v7v/what_do_you_guys_think_of_the_siri_demo/,xamdam,1317833352,"from what I saw the NLP was pretty good, but I did not see signs of deep intelligence that CALO project suggested. Also, having Siri serve up WolframAlpha is a cheat :) (but kudos to Wolfram for putting his logo on every answer)",24,13
8,2011-10-6,2011,10,6,23,l2zw6,I need to cluster images with kmeans.,https://www.reddit.com/r/MachineLearning/comments/l2zw6/i_need_to_cluster_images_with_kmeans/,linus_rules,1317910119,"I need to cluster images with [kmeans](http://en.wikipedia.org/wiki/K-means_clustering) and [NCD](http://www.complearn.org/ncd.html) for comparison with other clustering algorithm. 
I am stuck with the centroid calculation. Why? If we have two images X and Y the average (X + Y)/2 makes sense only if size(X) is equal to size(Y). This fact negates the utility of the NCD (It can compares two images of different sizes).
My question is : does it make sense to assume the centroid is equal to the concatenation of X and Y?
",19,5
9,2011-10-8,2011,10,8,2,l4b5o,Help with Predicting or Generating Sequences,https://www.reddit.com/r/MachineLearning/comments/l4b5o/help_with_predicting_or_generating_sequences/,deusfaber,1318008212,"I have a data set with a target concept. 
For example: with states (s)

s^1, s^2, s^3, s^4, s^5, target
s^2, s^3, s^6, s^7, target
s^1, s^4, s^5, s^6, s^7, s^8, target


The sequences are of **unequal** length, but the target concept is the same. What would be a good starting point to explore some off-the-shelf learning algorithms for the above data set?

",7,4
10,2011-10-8,2011,10,8,14,l4wiy,Mining Twitter,https://www.reddit.com/r/MachineLearning/comments/l4wiy/mining_twitter/,[deleted],1318052625,,0,13
11,2011-10-10,2011,10,10,2,l65dm,How well do Support Vector Machines scale to very large training datasets?,https://www.reddit.com/r/MachineLearning/comments/l65dm/how_well_do_support_vector_machines_scale_to_very/,sanity,1318181092,"I'm considering using a Support Vector Machine on a very large training set consisting of millions of rows of data, where each row will have hundreds of attributes (once the data is converted to a form suitable for a SVM).

Is it practical to train a SVM on such a large training set?  How long is it likely to take on a modern consumer-grade laptop?

Oh, also, I've been looking for a good pure-Java SVM library.  I found [SVM-JAVA](https://sites.google.com/site/postechdm/research/implementation/svm-java) but looking through its source code it isn't well written.

Can anyone recommend a good Java SVM library?",56,20
12,2011-10-10,2011,10,10,22,l711r,Determine if you are a data scientist (an R function),https://www.reddit.com/r/MachineLearning/comments/l711r/determine_if_you_are_a_data_scientist_an_r/,talgalili,1318253168,,6,0
13,2011-10-12,2011,10,12,22,l9j0e,"Ask r/ml: I am extracting ngrams from my dataset, how should I store them efficently?",https://www.reddit.com/r/MachineLearning/comments/l9j0e/ask_rml_i_am_extracting_ngrams_from_my_dataset/,minifig,1318426631,"I am extracting 4-grams from binary items in hexadecimal form, this mean I can have at most 65535 different grams per item. I want to associate every item to it's grams and their frequency but I am puzzled on how to store everything  this is my first data mining experience and I don't have any clue about best practices and common tools :|

I was trivially thinking to build a big table in a relational database with a schema like (ITEM, GRAM1, GRAM2... GRAM65535) and store inside it the frequencies but I can see this approach is uber impratical because of the number of columns. 

I know there must be better solutions out there but I don't know where to look at.

Suggestions? ",13,14
14,2011-10-13,2011,10,13,0,l9m7y,"Where to find data to use with R
",https://www.reddit.com/r/MachineLearning/comments/l9m7y/where_to_find_data_to_use_with_r/,talgalili,1318432272,,0,2
15,2011-10-13,2011,10,13,1,l9orj,Search Query Results Numbers,https://www.reddit.com/r/MachineLearning/comments/l9orj/search_query_results_numbers/,Paran0idAndr0id,1318436317,"I'm in Intro to ML at UTD (University of Texas at Dallas) and for our semester project we're doing Anaphora Resolution. My group has decided that for our first attempt (just to get us off the ground, before we delve into using WordNet and other resources), we are going to use simple search results numbers. In our testing, it's worked pretty well so far.

The question I have is, does anyone here know of any search engine that:

A) Allows scraping like this (not of actual results, just the number of results)

B) Allows scraping at all (apparently Bing is fine with it so long as the query is sent by a human, which could be implemented...kind of)

Also, any tips would be greatly appreciated. I've been cooking up some ideas for identifying the 'direction' of the main action verb (generally these sentences are 'A acts on B and (he/she/it) acts', in which the secondary action makes the determination as to whom the antecedent of (he/she/it, the anaphora) refers) along with any positive/negative aspects of that verb and the 'direction' of the secondary action along with any positive/negative aspects of it.

An example would be:

Charles hit Sam and he didn't like it.

This can be broken down into Charles acts negatively on Sam. The anaphor responds negatively, so the anaphor is most likely being acted negatively upon, which in this case is Sam.

I don't know how viable this method would be, but I'm interested in trying it out. The best part (in my mind) about this method is that is uses genuine learning instead of just rules for resolution.

Any assistance in this would be greatly appreciated!",4,3
16,2011-10-13,2011,10,13,3,l9u4h,"Data Reveals That ""Occupying"" Twitter Trending Topics is Harder Than it Looks!",https://www.reddit.com/r/MachineLearning/comments/l9u4h/data_reveals_that_occupying_twitter_trending/,agconway,1318444163,,2,11
17,2011-10-13,2011,10,13,23,lauc9,What's there to like about R?,https://www.reddit.com/r/MachineLearning/comments/lauc9/whats_there_to_like_about_r/,agconway,1318516192,,4,14
18,2011-10-14,2011,10,14,9,lbhy0,Is this possible (x-post from computervision),https://www.reddit.com/r/MachineLearning/comments/lbhy0/is_this_possible_xpost_from_computervision/,j_lyf,1318553978,,7,5
19,2011-10-14,2011,10,14,14,lbqqg,The State of the Machine Learning Labor Market,https://www.reddit.com/r/MachineLearning/comments/lbqqg/the_state_of_the_machine_learning_labor_market/,thgibbs,1318569807,,10,7
20,2011-10-15,2011,10,15,3,lcawx,Mining Lending Clubs Goldmine of Loan Data (Visualizations by State),https://www.reddit.com/r/MachineLearning/comments/lcawx/mining_lending_clubs_goldmine_of_loan_data/,talgalili,1318615411,,0,9
21,2011-10-15,2011,10,15,5,lcgdu,Who wants to throw around ideas on a regression model for upvotes of a submission?,https://www.reddit.com/r/MachineLearning/comments/lcgdu/who_wants_to_throw_around_ideas_on_a_regression/,the_cat_kittles,1318623883,"Wouldn't it be cool (and maybe dumb) to provide reddit with a predictive model that would tell them how many upvotes their story might get? We could be reddit stars for a day. So far, I can think of the following relevant features:

continuous: Submission time, ~~subreddit~~ (meant to put that in discrete), submitter's karma, how long submitter has been a redditor, length of title, number of non alphanumeric characters in title, number of capital letters

discrete: is nsfw, maybe use pca to figure out which words are buzzwords or something like that and have them as binary variables (those of you with more nlp experience... suggestions?), is text, is link, is video, is image

i was thinking of trying to hit up .json's based on active learning principles to build a training set, anyone have suggestions on this? 

EDIT: news... Kickstarter said no, so maybe there is some other way to pool money together for this? Also, I have the json data in a sqlite db of 1,000,000 submissions culled from 30,000 users (i had to go from users because that seems like you will get a more representative distribution of all types of posts (except maybe people delete their bad posts...)) that im throwing up on infochimps, they have to approve it so it may take a while. pm me if you have better ideas about where to host it, or if you want me to send it to you directly",16,17
22,2011-10-15,2011,10,15,5,lchnu,"Dataspora is hiring! Chief Analytics Officer and Chief Executive Officer. San Francisco, CA or Boston, MA. Some travel required. See post for details. ",https://www.reddit.com/r/MachineLearning/comments/lchnu/dataspora_is_hiring_chief_analytics_officer_and/,ohsnaaap,1318625962,"http://www.dataspora.com

Chief Analytics Officer:
http://www.crunchboard.com/opening/detailjob.php?jid=12448

Chief Executive Officer:
http://www.crunchboard.com/opening/detailjob.php?jid=12449",0,3
23,2011-10-15,2011,10,15,13,lcvwm,Unit II &gt;&gt; Gradient Descent &gt;&gt; question := brainmelt,https://www.reddit.com/r/MachineLearning/comments/lcvwm/unit_ii_gradient_descent_question_brainmelt/,delinquentme,1318654639,,0,0
24,2011-10-15,2011,10,15,23,ld577,K-means clustering for Hadoop in R and Java,https://www.reddit.com/r/MachineLearning/comments/ld577/kmeans_clustering_for_hadoop_in_r_and_java/,talgalili,1318687305,,0,10
25,2011-10-16,2011,10,16,7,ldj0b,Best way to get experience in ML?,https://www.reddit.com/r/MachineLearning/comments/ldj0b/best_way_to_get_experience_in_ml/,epios,1318716886,"I know a lot of you are working professionally with machine learning, and I am interested in gaining some experience with an eye towards being qualified for an engineering job in the field.  I have started studying statistics and some of the basic technologies, and working with Mahout and Lucene in my spare time.  I am currently a software engineer in data warehousing and have a BS in Computer Science.  How you recommend I proceed?  There are Master's programs in the area in Computer Science and another in Applied Statistics.  Is a Master's required? Would Applied Statistics benefit me?  I am also curious about what credentials some of you guys have that are working in the field.",12,12
26,2011-10-18,2011,10,18,11,lfuam,Kernel Density at the Checkout: D'yakonov Alexander on Winning the Dunnhumby Shopper Challenge,https://www.reddit.com/r/MachineLearning/comments/lfuam/kernel_density_at_the_checkout_dyakonov_alexander/,willis77,1318903875,,2,17
27,2011-10-19,2011,10,19,5,lgoim,"ACM Data Mining Camp 2011: Report
",https://www.reddit.com/r/MachineLearning/comments/lgoim/acm_data_mining_camp_2011_report/,talgalili,1318970480,,0,3
28,2011-10-19,2011,10,19,20,lhe14,The Mode is a Deceitful Beast: William Cukierski on finishing fourth in Dunnhumby's Shopper Challenge,https://www.reddit.com/r/MachineLearning/comments/lhe14/the_mode_is_a_deceitful_beast_william_cukierski/,willis77,1319025038,,0,7
29,2011-10-19,2011,10,19,23,lhi1q,"Large applications of linear mixed models
",https://www.reddit.com/r/MachineLearning/comments/lhi1q/large_applications_of_linear_mixed_models/,talgalili,1319034551,,2,2
30,2011-10-20,2011,10,20,6,lhx60,Support Vector Machines in R (a course by Lutz Hamel),https://www.reddit.com/r/MachineLearning/comments/lhx60/support_vector_machines_in_r_a_course_by_lutz/,talgalili,1319058834,,1,0
31,2011-10-20,2011,10,20,9,li3qs,Hyper-parameter selection by nonparametric noise estimator for RBF kernel least-squares SVM.,https://www.reddit.com/r/MachineLearning/comments/li3qs/hyperparameter_selection_by_nonparametric_noise/,AlonzoIsOurChurch,1319069674,,4,1
32,2011-10-21,2011,10,21,0,lirni,What is marginal likelihood?,https://www.reddit.com/r/MachineLearning/comments/lirni/what_is_marginal_likelihood/,nickponline,1319124014,I'm trying to gain some intuition as to what marginal likelihood is (in the context of Bayesian inference) but I'm struggling. I understand it to be a measure how well a model fits the data in general (is this correct?) but I don't really get how?,4,14
33,2011-10-21,2011,10,21,5,lj4ol,"How well do Decision Trees scale 
to very large training datasets?",https://www.reddit.com/r/MachineLearning/comments/lj4ol/how_well_do_decision_trees_scale_to_very_large/,rylko,1319143638,"I'm going to use Decision Trees for very large datasets (from megabytes to terabytes).  There are any good implementation in Java? And what kind of DT are best scalable? I see that Mahout uses Random forest. GUIDE also seems interesting. Are ensemble methods right way to go? Or can you suggest good and actual paper to read? Point to science case using decision trees on big data also highly appreciated.

Thanks

edit1: There will be many examples with small number of classes.",10,24
34,2011-10-21,2011,10,21,10,ljfiz,Pattern Recognition: Must I normalize features by standard deviation?,https://www.reddit.com/r/MachineLearning/comments/ljfiz/pattern_recognition_must_i_normalize_features_by/,Eruditass,1319162254,"If a problem is more influenced by certain features, is there anything wrong with giving that feature more dynamic range to influence the classifier? 

Or are there methods within many classifiers that will do a better and less hand-wavey job? ",4,4
35,2011-10-21,2011,10,21,11,ljgf8,Merging linear classifiers. Would this work?,https://www.reddit.com/r/MachineLearning/comments/ljgf8/merging_linear_classifiers_would_this_work/,lars_,1319163741,"I had this idea. I'm sure it's either unoriginal, or there are reasons it wouldn't work that I haven't thought of.

Let's say we have two classifiers which create a model of the form:

y= ****^ **X**

Where **X** is our feature vector and **** is our parameter vector. Linear Discriminant Analysis and Logistic Regression would both create a model of this type. Logistic Regression would classify based on which side of zero y is. For LDA, we could subtract the mean in order to achieve the same effect.

So lets say the best seperating hyperplane is somewhere in between that of LDA and Logistic Regression. Let's call the fitted parameters from LDA ****lda, and those from Logistic Regression ****lr. We could formalize ""somewhere in between"" with a parameter .

****between = (****lda * ) + (****lr (1-))

We can find good values for  through cross validation, and possibly get a better accuracy than either of the original classifiers on their own. What is this called? Alternatively, why wouldn't it work?",9,4
36,2011-10-22,2011,10,22,1,lk2x2,Scatterplot-binning for hundreds of millions of points (in R),https://www.reddit.com/r/MachineLearning/comments/lk2x2/scatterplotbinning_for_hundreds_of_millions_of/,talgalili,1319215652,,1,7
37,2011-10-22,2011,10,22,10,lkkdy,Data Mining Images Tutorial - Pt 1,https://www.reddit.com/r/MachineLearning/comments/lkkdy/data_mining_images_tutorial_pt_1/,PokerPirate,1319245340,,2,11
38,2011-10-22,2011,10,22,22,lkysf,Feature learning (a summary of recent developments),https://www.reddit.com/r/MachineLearning/comments/lkysf/feature_learning_a_summary_of_recent_developments/,mosavian,1319288814,,23,25
39,2011-10-23,2011,10,23,2,ll5zh,Information on tag prediction for texts.,https://www.reddit.com/r/MachineLearning/comments/ll5zh/information_on_tag_prediction_for_texts/,Xochipilli,1319305371,"Hi,

Can anyone recommend me some (recent) papers on 'tag prediction' for texts (automatic tagging of forum posts, twitter posts, pdf-books, articles, etc.)?",1,3
40,2011-10-23,2011,10,23,6,lle8s,programming assignments,https://www.reddit.com/r/MachineLearning/comments/lle8s/programming_assignments/,delinquentme,1319320327,,0,1
41,2011-10-23,2011,10,23,8,lli2t,What is wrong with Gaussian Processes?,https://www.reddit.com/r/MachineLearning/comments/lli2t/what_is_wrong_with_gaussian_processes/,nickponline,1319327621,"They seem like pretty awesome methods, and aside from the time and space issues of the matrix inversion are there any other limitation that they have for general non-parametric regression?

EDIT: Out of interest for research directions.",14,17
42,2011-10-24,2011,10,24,5,lmco8,How do I pick which data to label- question inspired by active learning techniques,https://www.reddit.com/r/MachineLearning/comments/lmco8/how_do_i_pick_which_data_to_label_question/,the_cat_kittles,1319403323,"I recently read a paper discussing some general ways to think about how to label additional datapoints when its costly to do so- pick ones that are most ambiguous for the current model, pick ones that are representative of the distribution of data etc... got me thinking- how would you go about selecting your *initial* training set from unlabeled data. What kinds of things could help you decide which points to label?",3,9
43,2011-10-25,2011,10,25,2,lnb3y,List of R functions and packages for machine learning,https://www.reddit.com/r/MachineLearning/comments/lnb3y/list_of_r_functions_and_packages_for_machine/,agconway,1319477155,,1,24
44,2011-10-25,2011,10,25,2,lnc96,Machine Learning With Hadoop,https://www.reddit.com/r/MachineLearning/comments/lnc96/machine_learning_with_hadoop/,manning10,1319479046,,0,1
45,2011-10-25,2011,10,25,6,lnjx4,Matlab (and Standalone application) port for the  `Random Forests' algorithm,https://www.reddit.com/r/MachineLearning/comments/lnjx4/matlab_and_standalone_application_port_for_the/,blur10600,1319490347,,0,4
46,2011-10-25,2011,10,25,6,lnkmh,AskReddit: Anybody knows of a good C4.5 or C.5 MAtlab implementation?,https://www.reddit.com/r/MachineLearning/comments/lnkmh/askreddit_anybody_knows_of_a_good_c45_or_c5/,blur10600,1319491391,,2,2
47,2011-10-25,2011,10,25,11,lnx0t,Is it possible to use clusters as the input in a neural net.,https://www.reddit.com/r/MachineLearning/comments/lnx0t/is_it_possible_to_use_clusters_as_the_input_in_a/,posinegi,1319510556,"If so can the output clusters update through merging?
",16,2
48,2011-10-26,2011,10,26,0,log6o,Google Tech Talk: Fast Deep/Recurrent Nets for AGI Vision ,https://www.reddit.com/r/MachineLearning/comments/log6o/google_tech_talk_fast_deeprecurrent_nets_for_agi/,iori42,1319555090,,2,9
49,2011-10-26,2011,10,26,0,loh00,Is there any summary of top models for the Netflix prize?,https://www.reddit.com/r/MachineLearning/comments/loh00/is_there_any_summary_of_top_models_for_the/,cavedave,1319556364,,2,34
50,2011-10-26,2011,10,26,6,low4y,"What makes Big Data so different from ""not Big Data""?",https://www.reddit.com/r/MachineLearning/comments/low4y/what_makes_big_data_so_different_from_not_big_data/,fortyninerbruin,1319578131,"Any time I interview, people make ""Big Data"" seem like it's completely different from data measured in mere megabytes. They also do not provide a good concrete reason of how it changes the analysis. So what changes need to be made to work with a data set measured in GB/TB, aside from worrying about being efficient with the code?",19,20
51,2011-10-26,2011,10,26,18,lpjhn,Ken Jennings talks about Watson at the 2011 Singularity Summit,https://www.reddit.com/r/MachineLearning/comments/lpjhn/ken_jennings_talks_about_watson_at_the_2011/,cavedave,1319622677,,0,7
52,2011-10-26,2011,10,26,22,lpoc3,Want to help reddit build a subreddit recommender? -- A public dump of voting data that our users have donated for research [x-post from /r/redditdev],https://www.reddit.com/r/MachineLearning/comments/lpoc3/want_to_help_reddit_build_a_subreddit_recommender/,TedFromTheFuture,1319637098,,8,30
53,2011-10-27,2011,10,27,1,lpuua,Machine Learning for Email by r/Machine learning regulars agconway and johnmyleswhite ,https://www.reddit.com/r/MachineLearning/comments/lpuua/machine_learning_for_email_by_rmachine_learning/,cavedave,1319647512,,5,11
54,2011-10-27,2011,10,27,7,lq8z4,Erdos Renyi Graph Generator,https://www.reddit.com/r/MachineLearning/comments/lq8z4/erdos_renyi_graph_generator/,MuffinShit,1319668424,"I'm looking for a way to generate Erdos Renyi random graphs (small world graphs actually) for a class project. (Looking to generate datasets with at most ~50k vertices)

I've tried both graphgene and GraphGen without success. Any suggestions? 
",5,3
55,2011-10-27,2011,10,27,22,lqwps,"Trying to implement a nag-bot, but need some data... anyone willing to help?",https://www.reddit.com/r/MachineLearning/comments/lqwps/trying_to_implement_a_nagbot_but_need_some_data/,gms8994,1319721122,,3,7
56,2011-10-27,2011,10,27,23,lqycl,Kaggle screws up and the HHP,https://www.reddit.com/r/MachineLearning/comments/lqycl/kaggle_screws_up_and_the_hhp/,the_dude_abidz,1319724298,"Looks like Kaggle doesn't randomize the order of their training data.  Ouch.

http://www.kaggle.com/forums/t/980/wikipedia-participation-challenge-an-unfortunate-ending

On another topic, the Heritage Health Prize.  Who thinks they'll make the .4 benchmark in the end and pay out the 3M?  Right now they're at .455 :

http://www.heritagehealthprize.com/c/hhp/Leaderboard

I remember that with the Netflix prize it took a year or so to eek out that last 1 percent of performance.  They've got over 10 percent more to go here.

Edit:  Looks like Kaggle isn't interested in learning from this mistake.  They moved the original post to an old competition forum.  It's a shame because its a cool site, but they can't be making friends on the participant side with this bizarre behavior.",15,32
57,2011-10-28,2011,10,28,0,lr1fr,NLP subreddit,https://www.reddit.com/r/MachineLearning/comments/lr1fr/nlp_subreddit/,[deleted],1319729529,,0,1
58,2011-10-28,2011,10,28,0,lr1vc,NLP subreddit: r/LanguageTechnology,https://www.reddit.com/r/MachineLearning/comments/lr1vc/nlp_subreddit_rlanguagetechnology/,Samus_,1319730239,,4,7
59,2011-10-31,2011,10,31,6,lufvf,The present and future of the R blogosphere (~7 minute video from useR2011),https://www.reddit.com/r/MachineLearning/comments/lufvf/the_present_and_future_of_the_r_blogosphere_7/,talgalili,1320011226,,0,3
