,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2018-2-1,2018,2,1,9,7uell8,Will New EU Regulations Starve Data-Hungry Deep Learning Models?,https://www.reddit.com/r/MachineLearning/comments/7uell8/will_new_eu_regulations_starve_datahungry_deep/,[deleted],1517443909,[deleted],0,1
1,2018-2-1,2018,2,1,9,7ueni7,Tensorflow implementation of generative adversarial networks,https://www.reddit.com/r/MachineLearning/comments/7ueni7/tensorflow_implementation_of_generative/,[deleted],1517444347,[deleted],0,1
2,2018-2-1,2018,2,1,9,7ueo4o,How to visualize saliency/activation maps of CNN for regression task,https://www.reddit.com/r/MachineLearning/comments/7ueo4o/how_to_visualize_saliencyactivation_maps_of_cnn/,[deleted],1517444501,,0,1
3,2018-2-1,2018,2,1,9,7uer3q,Tensorflow implementation of Generative adversarial networks,https://www.reddit.com/r/MachineLearning/comments/7uer3q/tensorflow_implementation_of_generative/,[deleted],1517445224,[deleted],0,1
4,2018-2-1,2018,2,1,9,7uevb5,[P] The Matrix Calculus You Need For Deep Learning,https://www.reddit.com/r/MachineLearning/comments/7uevb5/p_the_matrix_calculus_you_need_for_deep_learning/,jeremyhoward,1517446299,,35,303
5,2018-2-1,2018,2,1,10,7uf6wb,Sesame Tahini Production Machinery Youtube Video,https://www.reddit.com/r/MachineLearning/comments/7uf6wb/sesame_tahini_production_machinery_youtube_video/,gelserena,1517449377,,1,1
6,2018-2-1,2018,2,1,12,7ufwek,How does one show that the likelihood solution for logistic regression has a magnitude of infinity for separable data (Bishop exercise 4.14)?,https://www.reddit.com/r/MachineLearning/comments/7ufwek/how_does_one_show_that_the_likelihood_solution/,real_charlie_parker,1517456219,,0,1
7,2018-2-1,2018,2,1,13,7ug8u4,[N] Will New EU Regulations Starve Data-Hungry Deep Learning Models?,https://www.reddit.com/r/MachineLearning/comments/7ug8u4/n_will_new_eu_regulations_starve_datahungry_deep/,trcytony,1517459737,,5,0
8,2018-2-1,2018,2,1,13,7ugcgk,"""Amazon Wants to Disrupt Health Care in America. In China, Tech Giants Already Have"": AI (DL) increasingly used for cancer &amp; diabetic retinopathy scans",https://www.reddit.com/r/MachineLearning/comments/7ugcgk/amazon_wants_to_disrupt_health_care_in_america_in/,gwern,1517460848,,0,1
9,2018-2-1,2018,2,1,14,7ugfcj,[R] AISTATS 2018 Accepted Papers,https://www.reddit.com/r/MachineLearning/comments/7ugfcj/r_aistats_2018_accepted_papers/,riel234,1517461739,,1,9
10,2018-2-1,2018,2,1,14,7uggo7,How to get Started with Machine learning in learning User interest in App?,https://www.reddit.com/r/MachineLearning/comments/7uggo7/how_to_get_started_with_machine_learning_in/,arunkarnan,1517462130,[removed],0,1
11,2018-2-1,2018,2,1,14,7ugkvk,Locally Weighted Regression,https://www.reddit.com/r/MachineLearning/comments/7ugkvk/locally_weighted_regression/,__olamilekan__,1517463443,,0,1
12,2018-2-1,2018,2,1,14,7ugm1p,Comprehensive Repository of Data Science and ML Resources,https://www.reddit.com/r/MachineLearning/comments/7ugm1p/comprehensive_repository_of_data_science_and_ml/,pmz,1517463816,,0,1
13,2018-2-1,2018,2,1,15,7ugs7l,Universities for Master in Data science and Machine learning,https://www.reddit.com/r/MachineLearning/comments/7ugs7l/universities_for_master_in_data_science_and/,fullstackanalytics1,1517465841,,0,1
14,2018-2-1,2018,2,1,16,7uh8u9,[D] fast.ai post deleted?,https://www.reddit.com/r/MachineLearning/comments/7uh8u9/d_fastai_post_deleted/,MLThrowaway987,1517471870,"It looks like the new [fast.ai post](https://www.reddit.com/r/MachineLearning/comments/7tuhof/p_practical_deep_learning_for_coders_2018/) was deleted. Anyone know why? It seemed to follow the rules of /r/machinelearning, so was it deleted by /u/jeremyhoward?",5,0
15,2018-2-1,2018,2,1,17,7uheds,Ring die organic fertilizer granulator machine,https://www.reddit.com/r/MachineLearning/comments/7uheds/ring_die_organic_fertilizer_granulator_machine/,amylee516,1517474141,,0,1
16,2018-2-1,2018,2,1,17,7uhfst,[N] New Kaggle API - Downloading data and submitting to competitions,https://www.reddit.com/r/MachineLearning/comments/7uhfst/n_new_kaggle_api_downloading_data_and_submitting/,yessir_ziz,1517474766,,1,3
17,2018-2-1,2018,2,1,17,7uhh96,Baysian Estimation for continuous data?,https://www.reddit.com/r/MachineLearning/comments/7uhh96/baysian_estimation_for_continuous_data/,_ahnomatopia_,1517475351,[removed],0,1
18,2018-2-1,2018,2,1,18,7uhjb6,[N] Researchers may cracked 600 years old manuscript using AI,https://www.reddit.com/r/MachineLearning/comments/7uhjb6/n_researchers_may_cracked_600_years_old/,matej1408,1517476197,,1,2
19,2018-2-1,2018,2,1,18,7uhndi,[D] What are some controversial approaches to machine learning/AI that you think might actually work?,https://www.reddit.com/r/MachineLearning/comments/7uhndi/d_what_are_some_controversial_approaches_to/,odraz,1517477871,,23,11
20,2018-2-1,2018,2,1,18,7uhp9h,Can we make a Neural Network learn how to kill hashes?,https://www.reddit.com/r/MachineLearning/comments/7uhp9h/can_we_make_a_neural_network_learn_how_to_kill/,hyphendoodledocx,1517478664,[removed],0,1
21,2018-2-1,2018,2,1,18,7uhqbi,[P] AmbientGAN: Generative models from lossy measurements,https://www.reddit.com/r/MachineLearning/comments/7uhqbi/p_ambientgan_generative_models_from_lossy/,_sshin_,1517479125,,1,10
22,2018-2-1,2018,2,1,19,7uhsdc,How to learn to process datas?,https://www.reddit.com/r/MachineLearning/comments/7uhsdc/how_to_learn_to_process_datas/,wd1998313,1517479919,[removed],0,1
23,2018-2-1,2018,2,1,19,7uhulv,lukalabs/cakechat - the open source release of ReplikaAI,https://www.reddit.com/r/MachineLearning/comments/7uhulv/lukalabscakechat_the_open_source_release_of/,devi83,1517480746,,0,1
24,2018-2-1,2018,2,1,19,7uhwze,"master thesis direction on machine learning, seeking for advice",https://www.reddit.com/r/MachineLearning/comments/7uhwze/master_thesis_direction_on_machine_learning/,hahahhhhhh,1517481716,[removed],0,1
25,2018-2-1,2018,2,1,19,7uhx4q,[R] Comparative analysis of classification models for quality assessment of Wikipedia articles,https://www.reddit.com/r/MachineLearning/comments/7uhx4q/r_comparative_analysis_of_classification_models/,wikirank,1517481758,,1,2
26,2018-2-1,2018,2,1,19,7uhymw,[R] Analysis of Spatio-temporal Representations for Robust Footstep Recognition with Deep Residual Neural Networks,https://www.reddit.com/r/MachineLearning/comments/7uhymw/r_analysis_of_spatiotemporal_representations_for/,insider_7,1517482377,"Human footsteps can provide a unique behavioural pattern for robust biometric systems. We propose spatio-temporal footstep representations from floor-only sensor data in advanced computational models for automatic biometric verification. Our models deliver an artificial intelligence capable of effectively differentiating the fine-grained variability of footsteps between legitimate users (clients) and impostor users of the biometric system. The methodology is validated in the largest to date footstep database, containing nearly 20,000 footstep signals from more than 120 users. The database is organized by considering a large cohort of impostors and a small set of clients to verify the reliability of biometric systems. We provide experimental results in 3 critical data-driven security scenarios, according to the amount of footstep data made available for model training: at airports security checkpoints (smallest training set), workspace environments (medium training set) and home environments (largest training set). We report state-of-the-art footstep recognition rates with an optimal equal false acceptance and false rejection rate of 0.7% (equal error rate), an improvement ratio of 371% from previous state-of-the-art. We perform a feature analysis of deep residual neural networks showing effective clustering of client's footstep data and provide insights of the feature learning process.

http://ieeexplore.ieee.org/document/8275035/",0,2
27,2018-2-1,2018,2,1,20,7ui6xn,"[N] The fifth and final course 'Sequence Models', of Deep Learning specialisation by Andrew Ng is now open on Coursera",https://www.reddit.com/r/MachineLearning/comments/7ui6xn/n_the_fifth_and_final_course_sequence_models_of/,curious_riddler,1517485503,,13,59
28,2018-2-1,2018,2,1,20,7ui8jv,[D] Where to start learning Reinforcement Learning in 2018?,https://www.reddit.com/r/MachineLearning/comments/7ui8jv/d_where_to_start_learning_reinforcement_learning/,radenML,1517486083,,29,61
29,2018-2-1,2018,2,1,21,7uibqq,Is machine learning over saturated?,https://www.reddit.com/r/MachineLearning/comments/7uibqq/is_machine_learning_over_saturated/,Exoski,1517487157,[removed],0,1
30,2018-2-1,2018,2,1,21,7uicve,Engati grabs the limelight.,https://www.reddit.com/r/MachineLearning/comments/7uicve/engati_grabs_the_limelight/,getengati,1517487569,,0,1
31,2018-2-1,2018,2,1,21,7uiio8,Google using machine learning to predict flight delays,https://www.reddit.com/r/MachineLearning/comments/7uiio8/google_using_machine_learning_to_predict_flight/,famegamedeveloper,1517489449,,0,1
32,2018-2-1,2018,2,1,22,7uikhc,The 8 Neural Network Architectures Machine Learning Researchers Need to Learn,https://www.reddit.com/r/MachineLearning/comments/7uikhc/the_8_neural_network_architectures_machine/,digitalson,1517490035,,0,1
33,2018-2-1,2018,2,1,22,7uinvi,[R] How to Develop a Neural Machine Translation System in Keras from Scratch,https://www.reddit.com/r/MachineLearning/comments/7uinvi/r_how_to_develop_a_neural_machine_translation/,polllyyy,1517491074,,0,1
34,2018-2-1,2018,2,1,22,7uitol,Tensorflow Object Detection,https://www.reddit.com/r/MachineLearning/comments/7uitol/tensorflow_object_detection/,dhruv_rajpurohit,1517492848,[removed],0,1
35,2018-2-1,2018,2,1,23,7uiyz2,Autoscaling deep learning clusters with RiseML,https://www.reddit.com/r/MachineLearning/comments/7uiyz2/autoscaling_deep_learning_clusters_with_riseml/,[deleted],1517494333,[deleted],0,1
36,2018-2-1,2018,2,1,23,7uiz1g,"[N] Weekly Machine Learning Opensource Roundup  Feb. 1, 2018",https://www.reddit.com/r/MachineLearning/comments/7uiz1g/n_weekly_machine_learning_opensource_roundup_feb/,stkim1,1517494346,,0,1
37,2018-2-1,2018,2,1,23,7uj66c,Dynamic Routing Between Capsules - official code,https://www.reddit.com/r/MachineLearning/comments/7uj66c/dynamic_routing_between_capsules_official_code/,netw0rkf10w,1517496247,,4,39
38,2018-2-1,2018,2,1,23,7uj7q4,Fraud Detection Introductions,https://www.reddit.com/r/MachineLearning/comments/7uj7q4/fraud_detection_introductions/,artificial_intel423,1517496625,[removed],0,1
39,2018-2-2,2018,2,2,0,7uja0l,New version of CatBoost gradient boosting library has industry fastest inference implementation,https://www.reddit.com/r/MachineLearning/comments/7uja0l/new_version_of_catboost_gradient_boosting_library/,[deleted],1517497219,[deleted],0,3
40,2018-2-2,2018,2,2,0,7ujc6y,[D] Can someone give a technical explanation as to why pytorch is faster ?,https://www.reddit.com/r/MachineLearning/comments/7ujc6y/d_can_someone_give_a_technical_explanation_as_to/,finallyifoundvalidUN,1517497716,"https://github.com/u39kun/deep-learning-benchmark/blob/master/README.md

as a side note : In the above link, pytorch was on the latest version of cuda, while 1.4 is on cuda 8",22,25
41,2018-2-2,2018,2,2,0,7ujeip,What is an autonomous vehicle?,https://www.reddit.com/r/MachineLearning/comments/7ujeip/what_is_an_autonomous_vehicle/,sagar03d,1517498284,,0,1
42,2018-2-2,2018,2,2,0,7ujhuw,List of interesting and recent references in theoretical DeepLearning,https://www.reddit.com/r/MachineLearning/comments/7ujhuw/list_of_interesting_and_recent_references_in/,shagunsodhani,1517499104,,0,1
43,2018-2-2,2018,2,2,0,7ujlui,any resources for learning magenta?,https://www.reddit.com/r/MachineLearning/comments/7ujlui/any_resources_for_learning_magenta/,ilovemycake,1517500055,[removed],0,1
44,2018-2-2,2018,2,2,1,7ujrl0,Learn to create Machine Learning Algorithms in Python and R from two Data Science experts. Code templates included.,https://www.reddit.com/r/MachineLearning/comments/7ujrl0/learn_to_create_machine_learning_algorithms_in/,bramtom,1517501389,,0,1
45,2018-2-2,2018,2,2,1,7ujven,[Project] Pixel Deflection - a simple transformation based defense,https://www.reddit.com/r/MachineLearning/comments/7ujven/project_pixel_deflection_a_simple_transformation/,iamaaditya,1517502241,,1,2
46,2018-2-2,2018,2,2,1,7ujvm4,BBC: MACHINELEARNING Porn videos deleted from internet,https://www.reddit.com/r/MachineLearning/comments/7ujvm4/bbc_machinelearning_porn_videos_deleted_from/,baDoxx,1517502283,,0,1
47,2018-2-2,2018,2,2,1,7ujxto,[N] New version of CatBoost gradient boosting library has industry fastest inference implementation,https://www.reddit.com/r/MachineLearning/comments/7ujxto/n_new_version_of_catboost_gradient_boosting/,s0ulmate,1517502789,,47,59
48,2018-2-2,2018,2,2,1,7uk09p,[D] Approximate Inference and Deep Generative Models at CERN | DeepMind,https://www.reddit.com/r/MachineLearning/comments/7uk09p/d_approximate_inference_and_deep_generative/,sksq9,1517503346,,0,13
49,2018-2-2,2018,2,2,2,7ukasp,My Journey into Deep Learning,https://www.reddit.com/r/MachineLearning/comments/7ukasp/my_journey_into_deep_learning/,pmz,1517505654,,0,1
50,2018-2-2,2018,2,2,2,7ukfr3,[D] Is this subreddit too harsh?,https://www.reddit.com/r/MachineLearning/comments/7ukfr3/d_is_this_subreddit_too_harsh/,MLThrowawayD39,1517506749,"There's a twitter discussion about /r/ML subreddit here: 

https://twitter.com/jeremyphoward/status/958871408402038784

which seems precipitated by the comments in this post on /r/ML:

https://www.reddit.com/r/MachineLearning/comments/7tuhof/p_practical_deep_learning_for_coders_2018/

And a general discussion on whether this is toxic for the community. I personally find the anonymous aspect of it to be crucial for honest and often critical discussion. But it seems like this gives freedom to users to become excessively negative. How do we fix this?",92,33
51,2018-2-2,2018,2,2,2,7ukg4m,[P] Labelbox.io: January Product Update,https://www.reddit.com/r/MachineLearning/comments/7ukg4m/p_labelboxio_january_product_update/,labelbox,1517506822,,0,0
52,2018-2-2,2018,2,2,3,7uklr8,[D] NN accelerator. Need resources/links/articles about relevance to society/industry,https://www.reddit.com/r/MachineLearning/comments/7uklr8/d_nn_accelerator_need_resourceslinksarticles/,Venthe1,1517508092,"Hello Everyone
I am electronics and computer engineering student interested in machine learning.  Together with other students we have to decide on semester project theme and present it to supervisor. I would like to work on analog neural network accelerator but I have to present how the ""problem"" which aforementioned device solves is relevant to industry or society. For example that artificial neural networks require substantial amount of power to operate and there is potential to reduce it. Or that there is raising demand for NN accelerators. But I have trouble finding figures and data to support those claims and I would appreciate if you could provide me with insight where I can find it so I can work on exciting project :)

Thank you ",2,1
53,2018-2-2,2018,2,2,3,7uktm8,[R] [arxiv number] Breaking 7 / 8 of the ICLR 2018 adversarial example defenses,https://www.reddit.com/r/MachineLearning/comments/7uktm8/r_arxiv_number_breaking_7_8_of_the_iclr_2018/,[deleted],1517509765,[deleted],1,2
54,2018-2-2,2018,2,2,3,7ukyjs,Need some help,https://www.reddit.com/r/MachineLearning/comments/7ukyjs/need_some_help/,thabat,1517510829,[removed],0,1
55,2018-2-2,2018,2,2,3,7ukzaq,[P] Autoscaling deep learning clusters on AWS with Kubernetes and RiseML,https://www.reddit.com/r/MachineLearning/comments/7ukzaq/p_autoscaling_deep_learning_clusters_on_aws_with/,henningpeters,1517510989,,0,6
56,2018-2-2,2018,2,2,4,7ul2an,[R] Breaking 7 / 8 of the ICLR 2018 adversarial example defenses,https://www.reddit.com/r/MachineLearning/comments/7ul2an/r_breaking_7_8_of_the_iclr_2018_adversarial/,anishathalye,1517511676,,44,146
57,2018-2-2,2018,2,2,4,7ul62n,in GAN how we backprogate throw generator? in other word can train generator?,https://www.reddit.com/r/MachineLearning/comments/7ul62n/in_gan_how_we_backprogate_throw_generator_in/,mario_rob,1517512485,[removed],0,1
58,2018-2-2,2018,2,2,4,7ul7zq,What is the 5 - 10 year outlook for machine learning and AI tools in accounting information systems?,https://www.reddit.com/r/MachineLearning/comments/7ul7zq/what_is_the_5_10_year_outlook_for_machine/,artrabbit05,1517512916,[removed],0,1
59,2018-2-2,2018,2,2,5,7ult99,"[P] A toolKit for boundingBoxes; mapping boundingBoxes to affine transformations, providing context and consistent bBox orientation through time (ex. training trackers + spatial transformer networks).",https://www.reddit.com/r/MachineLearning/comments/7ult99/p_a_toolkit_for_boundingboxes_mapping/,[deleted],1517517538,[deleted],0,1
60,2018-2-2,2018,2,2,5,7ulwzk,[D] How to encourage prediction probabilities to fit a desired distribution?,https://www.reddit.com/r/MachineLearning/comments/7ulwzk/d_how_to_encourage_prediction_probabilities_to/,overdue,1517518363,"I am working on a project where we would like the distribution of prediction probabilities to have a positive skew and long tail, like a Gamma distribution. Is there a way to encourage or enforce the learning process to do this (maybe through the loss function)? Thanks for any help!

Edit - a clarification, this is for a deep neural network working on images",13,5
61,2018-2-2,2018,2,2,6,7um49h,[P] Juno Jupyter Notebook client is now live on AppStore! (x-post from /r/IPython),https://www.reddit.com/r/MachineLearning/comments/7um49h/p_juno_jupyter_notebook_client_is_now_live_on/,navoshta,1517519973,"Finally, after months of development and beta testing my app Juno has made it to the AppStore  it's a **Jupyter Notebook client for iPad**. I strongly believe it can make a nice addition to your machine learning toolset!

[Juno on AppStore](https://itunes.apple.com/app/juno-jupyter-notebook-client/id1315744137)

You can download the app for free and run bundled introductory notebooks on Python, NumPy, Matplotlib and SciPy that will be launched on a temporary notebook server just for you. You can then choose to upgrade to Juno Pro with a one-time purchase (**no subscriptions!**) and access arbitrary Jupyter servers, as well as use cloud computing services such as CoCalc and Azure Notebooks. If you decide to get Juno Pro, mind that it is currently available with an introductory 30% discount (RRP $14.99).

Also, please check out [Juno on Product Hunt](https://www.producthunt.com/posts/juno-767a5996-5c93-4d62-880d-14268d1093e5).

I would love to hear your feedback and I'm happy to answer any questions you have! ",7,0
62,2018-2-2,2018,2,2,7,7umsf3,Been wanting to get into NLP,https://www.reddit.com/r/MachineLearning/comments/7umsf3/been_wanting_to_get_into_nlp/,decade5d,1517525496,[removed],0,1
63,2018-2-2,2018,2,2,8,7un2qm,Deep Learning Book Font,https://www.reddit.com/r/MachineLearning/comments/7un2qm/deep_learning_book_font/,MrCcode,1517528047,[removed],0,1
64,2018-2-2,2018,2,2,8,7un7p8,"[R] MIT IQ: The MIT Intelligence Quest - Forging connections between human and machine intelligence research, its applications, and its bearing on society.",https://www.reddit.com/r/MachineLearning/comments/7un7p8/r_mit_iq_the_mit_intelligence_quest_forging/,tellman1257,1517529309,,0,0
65,2018-2-2,2018,2,2,9,7unjfb,Excellent talk by Romain Paulus on the recent developments in Neural Machine Translation during DeepHack.Babel,https://www.reddit.com/r/MachineLearning/comments/7unjfb/excellent_talk_by_romain_paulus_on_the_recent/,HrantKhachatrian,1517532333,,1,1
66,2018-2-2,2018,2,2,10,7unwsq,Fresh Rice Noodle Making Machine,https://www.reddit.com/r/MachineLearning/comments/7unwsq/fresh_rice_noodle_making_machine/,lgsherry,1517536031,,1,1
67,2018-2-2,2018,2,2,10,7uny3p,Tips on distinguishing and recognizing sound with AI?,https://www.reddit.com/r/MachineLearning/comments/7uny3p/tips_on_distinguishing_and_recognizing_sound_with/,Afghano,1517536379,[removed],0,1
68,2018-2-2,2018,2,2,11,7uo3g8,[R] Computing Nonvacuous Generalization Bounds for Deep (Stochastic) Neural Networks with Many More Parameters than Training Data,https://www.reddit.com/r/MachineLearning/comments/7uo3g8/r_computing_nonvacuous_generalization_bounds_for/,programmerChilli,1517537857,,7,2
69,2018-2-2,2018,2,2,11,7uo7rn,[R] [1801.10308] Nested LSTMs,https://www.reddit.com/r/MachineLearning/comments/7uo7rn/r_180110308_nested_lstms/,chisai_mikan,1517539062,,10,33
70,2018-2-2,2018,2,2,11,7uo8aw,[Question] - Matching algorithm,https://www.reddit.com/r/MachineLearning/comments/7uo8aw/question_matching_algorithm/,pete0273,1517539217,[removed],0,1
71,2018-2-2,2018,2,2,11,7uob1y,Any academic reference on the autoencoder architecture that used in deepfakes (two decoder connect to a single encoder) ?,https://www.reddit.com/r/MachineLearning/comments/7uob1y/any_academic_reference_on_the_autoencoder/,RavlaAlvar,1517539989,[removed],0,1
72,2018-2-2,2018,2,2,12,7uogfm,"[R] Biophysical model suggests some biological neurons could, surprisingly, behave like perceptrons",https://www.reddit.com/r/MachineLearning/comments/7uogfm/r_biophysical_model_suggests_some_biological/,[deleted],1517541495,[deleted],0,2
73,2018-2-2,2018,2,2,12,7uogo0,From discriminant model to understand neural network,https://www.reddit.com/r/MachineLearning/comments/7uogo0/from_discriminant_model_to_understand_neural/,zbwby,1517541565,[removed],0,1
74,2018-2-2,2018,2,2,12,7uoiqs,"[R] Biophysical model suggests some biological neurons could, surprisingly, behave like perceptrons",https://www.reddit.com/r/MachineLearning/comments/7uoiqs/r_biophysical_model_suggests_some_biological/,csinva,1517542157,,9,9
75,2018-2-2,2018,2,2,14,7up9tx,Automatic compost turner for producing fertilizer,https://www.reddit.com/r/MachineLearning/comments/7up9tx/automatic_compost_turner_for_producing_fertilizer/,amylee516,1517550619,,0,1
76,2018-2-2,2018,2,2,15,7upclt,Beginner evaluation question,https://www.reddit.com/r/MachineLearning/comments/7upclt/beginner_evaluation_question/,Henn3ssey,1517551553,[removed],0,1
77,2018-2-2,2018,2,2,15,7uphcj,Machine &amp; Deep Learning Books,https://www.reddit.com/r/MachineLearning/comments/7uphcj/machine_deep_learning_books/,[deleted],1517553229,[deleted],0,1
78,2018-2-2,2018,2,2,15,7upiyy,Machine &amp; Deep Learning Books,https://www.reddit.com/r/MachineLearning/comments/7upiyy/machine_deep_learning_books/,Sarathyvelmurugan,1517553838,,0,1
79,2018-2-2,2018,2,2,17,7upwk3,[Deep Learning Lab] Experiments with Fashion-MNIST and Google Colab - Deep Learning Turkey  Medium,https://www.reddit.com/r/MachineLearning/comments/7upwk3/deep_learning_lab_experiments_with_fashionmnist/,deeplearningturkey,1517559100,,0,1
80,2018-2-2,2018,2,2,17,7upz8m,An Early Overview of ICLR2018,https://www.reddit.com/r/MachineLearning/comments/7upz8m/an_early_overview_of_iclr2018/,prlz77,1517560253,,0,1
81,2018-2-2,2018,2,2,17,7uq002,Live Computer Vision demo,https://www.reddit.com/r/MachineLearning/comments/7uq002/live_computer_vision_demo/,[deleted],1517560572,[deleted],0,1
82,2018-2-2,2018,2,2,17,7uq1cp,[P] Live Computer Vision,https://www.reddit.com/r/MachineLearning/comments/7uq1cp/p_live_computer_vision/,liranbh,1517561172,,2,3
83,2018-2-2,2018,2,2,17,7uq2cz,[R] Generating Wikipedia by Summarizing Long Sequences (Google Brain),https://www.reddit.com/r/MachineLearning/comments/7uq2cz/r_generating_wikipedia_by_summarizing_long/,baylearn,1517561613,,13,100
84,2018-2-2,2018,2,2,18,7uq54p,[MACHINELEARNING] Nicolas the rock Cage at abc,https://www.reddit.com/r/MachineLearning/comments/7uq54p/machinelearning_nicolas_the_rock_cage_at_abc/,baDoxx,1517562755,,0,1
85,2018-2-2,2018,2,2,18,7uq8pf,What are some standard tasks for LSTM's in NLP?,https://www.reddit.com/r/MachineLearning/comments/7uq8pf/what_are_some_standard_tasks_for_lstms_in_nlp/,ThomasAger,1517564283,[removed],0,1
86,2018-2-2,2018,2,2,19,7uqhp9,Is CpasNet is deep learning?,https://www.reddit.com/r/MachineLearning/comments/7uqhp9/is_cpasnet_is_deep_learning/,maytryark,1517567917,[removed],0,1
87,2018-2-2,2018,2,2,20,7uql6k,Understanding RNN inside a bi-lstm,https://www.reddit.com/r/MachineLearning/comments/7uql6k/understanding_rnn_inside_a_bilstm/,TiagoMRodrigues,1517569358,[removed],0,1
88,2018-2-2,2018,2,2,20,7uqqex,[R] - Detecting Nudity in images,https://www.reddit.com/r/MachineLearning/comments/7uqqex/r_detecting_nudity_in_images/,fgttre3,1517571419,[removed],0,1
89,2018-2-2,2018,2,2,21,7uqwkg,"[D] Implementation of LogisticRegrission classifier, second classifier i made! (Feedbacks)",https://www.reddit.com/r/MachineLearning/comments/7uqwkg/d_implementation_of_logisticregrission_classifier/,eViL111,1517573686,https://www.kaggle.com/zzero0/applying-logisticregression-classifier/,6,0
90,2018-2-2,2018,2,2,21,7uqyyx,[P] A complete and simple software implementation of MobileNet-V2 in PyTorch.,https://www.reddit.com/r/MachineLearning/comments/7uqyyx/p_a_complete_and_simple_software_implementation/,MG2033,1517574528,,4,16
91,2018-2-2,2018,2,2,21,7uqzrc,HyperGAN with vectorised images?,https://www.reddit.com/r/MachineLearning/comments/7uqzrc/hypergan_with_vectorised_images/,[deleted],1517574807,,0,1
92,2018-2-2,2018,2,2,21,7ur421,A new way of multimodal fusion by deep neural networks for ranking,https://www.reddit.com/r/MachineLearning/comments/7ur421/a_new_way_of_multimodal_fusion_by_deep_neural/,cgq5,1517576265,,0,1
93,2018-2-2,2018,2,2,21,7ur42r,"""Image"" Recognition with images from brain?",https://www.reddit.com/r/MachineLearning/comments/7ur42r/image_recognition_with_images_from_brain/,[deleted],1517576272,,0,1
94,2018-2-2,2018,2,2,22,7ur637,"[D] Image recognition with ""Images"" from brain",https://www.reddit.com/r/MachineLearning/comments/7ur637/d_image_recognition_with_images_from_brain/,Xlagor,1517576926,"Hey Guys, I thought about the process and the science behind an image recognizing Neural Network. So I asked my self could it be possible to instead of training the N.N. on pictures of Objects train it on ""pictures of the brain"" or short clips of the brain activity(?).

For example you would show a bunch of persons a picture of a dog (or just tell them to think of one) and at the same time make a clip of their brain acitvities. You then train the N.N. on the data and technically it should than be able to identify if someone is thinking of a dog.

Let me now in the comments if this makes sense or if its total bullshit. But I personally feel like this could work when seeing how good N.N. nowadays are performing in pattern/object recognization.

(I apologize for my bad english skills)",11,0
95,2018-2-2,2018,2,2,22,7ure72,Fader Networks allow you to change aspects of yourself,https://www.reddit.com/r/MachineLearning/comments/7ure72/fader_networks_allow_you_to_change_aspects_of/,greatestcitydana,1517579299,,0,1
96,2018-2-2,2018,2,2,22,7urean,[D] HyperGAN with vector images,https://www.reddit.com/r/MachineLearning/comments/7urean/d_hypergan_with_vector_images/,dankmaster2k,1517579330,"Hi, I was trying to google this but in my brief attempt could not find anything related to what I'm interested in.
Most of the image generation methods I've seen look to be using pixels as i/o. Why is there not much focus on vector formats for images, such as svg or something? I understand you'd lose the CNN and the great work done there, but could vectorised images be much easier to train for some datasets, like digits or so on?
Thanks guys :)",2,0
97,2018-2-2,2018,2,2,22,7urfxj,[1802.00168] Deep Learning with Data Dependent Implicit Activation Function,https://www.reddit.com/r/MachineLearning/comments/7urfxj/180200168_deep_learning_with_data_dependent/,[deleted],1517579787,[deleted],0,1
98,2018-2-2,2018,2,2,23,7uri4p,[R] [1802.00168] Deep Learning with Data Dependent Implicit Activation Function,https://www.reddit.com/r/MachineLearning/comments/7uri4p/r_180200168_deep_learning_with_data_dependent/,tzivo,1517580398,,3,14
99,2018-2-2,2018,2,2,23,7urkvl,Paper tube machine,https://www.reddit.com/r/MachineLearning/comments/7urkvl/paper_tube_machine/,[deleted],1517581129,,0,1
100,2018-2-2,2018,2,2,23,7urncx,Paper tube machine,https://www.reddit.com/r/MachineLearning/comments/7urncx/paper_tube_machine/,yacinokat,1517581776,,0,1
101,2018-2-2,2018,2,2,23,7urne1,[P] Deepmind Visual Interaction Network implementation in Pytorch,https://www.reddit.com/r/MachineLearning/comments/7urne1/p_deepmind_visual_interaction_network/,[deleted],1517581784,[deleted],0,1
102,2018-2-3,2018,2,3,0,7urxd6,[P] Deepmind Visual Interaction Networks implementation in PyTorch,https://www.reddit.com/r/MachineLearning/comments/7urxd6/p_deepmind_visual_interaction_networks/,mrgemy95,1517584368,,0,23
103,2018-2-3,2018,2,3,0,7us154,Bayesian Neural Network in Python,https://www.reddit.com/r/MachineLearning/comments/7us154/bayesian_neural_network_in_python/,bananabas,1517585324,[removed],0,1
104,2018-2-3,2018,2,3,0,7us33r,Avoid Overfitting with Regularization,https://www.reddit.com/r/MachineLearning/comments/7us33r/avoid_overfitting_with_regularization/,AhmedGadFCIT,1517585795,,0,1
105,2018-2-3,2018,2,3,0,7us4iz,Peanut Shelling and Stone Removing Machine Price,https://www.reddit.com/r/MachineLearning/comments/7us4iz/peanut_shelling_and_stone_removing_machine_price/,gelserena,1517586146,,1,1
106,2018-2-3,2018,2,3,0,7us5vf,CES 2018 Autonomous Driving Tech Review,https://www.reddit.com/r/MachineLearning/comments/7us5vf/ces_2018_autonomous_driving_tech_review/,gwen0927,1517586466,,0,1
107,2018-2-3,2018,2,3,1,7us8tv,Moviebox: Python Machine Learning Movie Recommender,https://www.reddit.com/r/MachineLearning/comments/7us8tv/moviebox_python_machine_learning_movie_recommender/,ohaiomasta,1517587202,,0,1
108,2018-2-3,2018,2,3,1,7usn6r,Neural networks as degree thesis!,https://www.reddit.com/r/MachineLearning/comments/7usn6r/neural_networks_as_degree_thesis/,w1w2w3w4w5,1517590461,[removed],0,1
109,2018-2-3,2018,2,3,2,7usvfw,"""[R]""Learn Real World Machine Learning By Building Projects",https://www.reddit.com/r/MachineLearning/comments/7usvfw/rlearn_real_world_machine_learning_by_building/,MainDevs,1517592268,,1,0
110,2018-2-3,2018,2,3,2,7usvv0,mltest: Test neural network code in one function call.,https://www.reddit.com/r/MachineLearning/comments/7usvv0/mltest_test_neural_network_code_in_one_function/,thenerdstation,1517592356,,0,1
111,2018-2-3,2018,2,3,2,7ut2cz,Generative Adversarial Networks explained from Scratch. Code included in TensorFlow and PyTorch,https://www.reddit.com/r/MachineLearning/comments/7ut2cz/generative_adversarial_networks_explained_from/,diegoalejogm,1517593754,,0,1
112,2018-2-3,2018,2,3,2,7ut3ee,DensePose: Dense Human Pose Estimation In The Wild,https://www.reddit.com/r/MachineLearning/comments/7ut3ee/densepose_dense_human_pose_estimation_in_the_wild/,NMcA,1517593993,,0,1
113,2018-2-3,2018,2,3,3,7utis3,[P] An Implementation of Google Deepmind Recurrent Environment Simulators Paper in Tensorflow.,https://www.reddit.com/r/MachineLearning/comments/7utis3/p_an_implementation_of_google_deepmind_recurrent/,mrgemy95,1517597352,,0,63
114,2018-2-3,2018,2,3,4,7utn1a,The Problem with AI,https://www.reddit.com/r/MachineLearning/comments/7utn1a/the_problem_with_ai/,thyateira,1517598308,,0,1
115,2018-2-3,2018,2,3,4,7utpji,Questions regarding 1D convolutional nets ala. Wavenet,https://www.reddit.com/r/MachineLearning/comments/7utpji/questions_regarding_1d_convolutional_nets_ala/,yevbev,1517598875,[removed],0,1
116,2018-2-3,2018,2,3,4,7utqug,AI Weekly 2 Feb 2018,https://www.reddit.com/r/MachineLearning/comments/7utqug/ai_weekly_2_feb_2018/,TomekB,1517599164,,0,1
117,2018-2-3,2018,2,3,4,7utwyy,[D] Issues with implement Conv. 1D NN ala. Wavenet,https://www.reddit.com/r/MachineLearning/comments/7utwyy/d_issues_with_implement_conv_1d_nn_ala_wavenet/,yevbev,1517600529,"Hello,

My question is this: I am working on a project where I use a 1D Convolutional NN, with 2 previous inputs to predict the current input and detect anomalies. My data has 32 features. However, it seems that my data is overfitting. For 1D CNN what are some regularization tricks or methods to improve performance? So far I have tried:

    Scaling data -1 to 1(helps)
    Increasing/Decreasing size of network(no)
    Dropout(no - I'm assuming similar to why that doesn't work for LSTMS)
    L2 regularization(no)
    Xavier Initialization(yes)
    Bottleneck layer(yes)
    Wavenet like architecture with Skip connections(no improvement)

Also, are there resources on how to implement this in TF? I have been using Keras.",12,4
118,2018-2-3,2018,2,3,5,7uufbf,"[RFC] Quantum Machine Learning: Reality or a real ""mega-buzzword""?",https://www.reddit.com/r/MachineLearning/comments/7uufbf/rfc_quantum_machine_learning_reality_or_a_real/,unnamedn00b,1517604713,,0,1
119,2018-2-3,2018,2,3,6,7uujhn,[R] [1801.10447] Recovering from Random Pruning: On the Plasticity of Deep Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/7uujhn/r_180110447_recovering_from_random_pruning_on_the/,zhamisen,1517605676,,1,23
120,2018-2-3,2018,2,3,6,7uulpn,Where to download RBM weights trained on any kind of visual dataset (such as mnist ocr)?,https://www.reddit.com/r/MachineLearning/comments/7uulpn/where_to_download_rbm_weights_trained_on_any_kind/,[deleted],1517606177,,0,1
121,2018-2-3,2018,2,3,6,7uuogh,[D] Where to download RBM weights trained on any kind of visual dataset (such as mnist ocr)?,https://www.reddit.com/r/MachineLearning/comments/7uuogh/d_where_to_download_rbm_weights_trained_on_any/,BenRayfield,1517606786,"RBM weights are a list of 2d array of scalar, optionally plus a list 1 bigger of 1d arrays of node bias, where each node would be (using the weights and bias) computed as weightedCoinFlip(1/(1+e^-weightedSum)) doing inference from visibleNodes to top then back and forth a few times. I am not looking for files that can only be used in a specific system. I normally use temperature size(fromLayer), but temperature should probably be a parameter. Many systems use a variety of other kinds of layers such as convolutional, but I'm just asking for the RBM parts. Even if it hooks into a convolutional layer, it should still be visually understandable by a person nonconvolutionally.

For example, an RBM trained on MNIST OCR digits dataset would, if started on random inputs, converge to an image of a hand written baseTen digit.

Not just MNIST OCR. I'm looking for a variety of trained RBMs on some kind of visual dataset, to generate bit vectors to train other RBMs on. This tends to filter out anything RBMs arent good at learning and would be useful as early testcases for variations of learning algorithms.

What data format are neuralnets often stored in? Content-type? *.File-extension? Where would we find these?",3,1
122,2018-2-3,2018,2,3,7,7uv288,[P] Machine Learning Movie Recommender with TF-IDF and Cosine Similarities,https://www.reddit.com/r/MachineLearning/comments/7uv288/p_machine_learning_movie_recommender_with_tfidf/,klauscfhq,1517609968,,1,2
123,2018-2-3,2018,2,3,7,7uv7sa,What do you think of TensorFlow Eager?,https://www.reddit.com/r/MachineLearning/comments/7uv7sa/what_do_you_think_of_tensorflow_eager/,real_charlie_parker,1517611277,,0,1
124,2018-2-3,2018,2,3,7,7uv8mj,[D] What's going on with ML hardware these days? Where's my TPU/NPU/etc?,https://www.reddit.com/r/MachineLearning/comments/7uv8mj/d_whats_going_on_with_ml_hardware_these_days/,rantana,1517611488,"There have been so many promises of specialized hardware that would replace GPUs from so many different companies. Companies that clearly have the resources and expertise to do this. Google, Intel and more than a few startups. But all these promises have resulted in absolutely nothing but press releases.

Nowhere can I use a TPU. I can't even tractably use an AMD GPU. And worse yet, this crypto mining makes it impossible to even buy Nvidia GPU.

What happened? Does it turn out neural networks can only run on green pcbs?",45,50
125,2018-2-3,2018,2,3,7,7uvavw,Is it a good idea to switch from Pytorch to TensorFlow Eager?,https://www.reddit.com/r/MachineLearning/comments/7uvavw/is_it_a_good_idea_to_switch_from_pytorch_to/,real_charlie_parker,1517612043,,0,1
126,2018-2-3,2018,2,3,9,7uw1p9,[Discussion] Having trouble understanding some details of Depthwise separable convolution (Xception),https://www.reddit.com/r/MachineLearning/comments/7uw1p9/discussion_having_trouble_understanding_some/,Moondra2017,1517619028,"Regular Convolution:

Input : 32 x32 x 10

Filters : 20 X 3 x 3 x10  (20 filters)

Ouput: 32x32X20

Total operations:  20x3x3x10 X (32 x 32 X)

Depth-Wise Separable Convolution:

Step 1 Point_wise_Convolution

Input : 32 x32 x 10

filter: 20 x 1x 1 x 10

Output: 32x32x20 

Total Calculations:20 x 1x1x10 (32x32)

Step 2 : DepthWise

Now I'm confused about the depth wise:

Input: 32x 32x 20 (Pointwise output)

filter:  1 x 5x5x20 ?

0utput: 32x32x20

So we basically just have one filter, that matches the input depth?
Is my understanding correct? 


",6,7
127,2018-2-3,2018,2,3,11,7uwnlm,Tensorflow implementation of nested LSTM (NLSTM) cell,https://www.reddit.com/r/MachineLearning/comments/7uwnlm/tensorflow_implementation_of_nested_lstm_nlstm/,[deleted],1517625528,[deleted],0,1
128,2018-2-3,2018,2,3,11,7uwrhz,[P] Tensorflow implementation of Nested LSTMs (NLSTM),https://www.reddit.com/r/MachineLearning/comments/7uwrhz/p_tensorflow_implementation_of_nested_lstms_nlstm/,hannw,1517626745,,7,109
129,2018-2-3,2018,2,3,12,7uwwah,The effect of using skip connections (UNet) in neural network-based generative models,https://www.reddit.com/r/MachineLearning/comments/7uwwah/the_effect_of_using_skip_connections_unet_in/,Warrior--,1517628254,[removed],0,1
130,2018-2-3,2018,2,3,12,7uwx2a,MY NG GI TR TI LC GI R YD11 | HN 90% KHCH HNG S DNG,https://www.reddit.com/r/MachineLearning/comments/7uwx2a/my_ng_gi_tr_ti_lc_gi_r_yd11_hn_90_khch/,mainguyenmth,1517628504,,0,1
131,2018-2-3,2018,2,3,14,7uxdul,[D] We can't defend adversarial samples using discriminant models like neural network,https://www.reddit.com/r/MachineLearning/comments/7uxdul/d_we_cant_defend_adversarial_samples_using/,zbwby,1517634241,"I write a blog about why we can't defend the adversarial attack.We can't deal with 'outliers' in the whole input space using discriminant models like neural net,because the training process to approximate the decision boundaries very likely will mess the whole space mislabeled. If the amount of data isn't large enough and the 0-loss boundaries are many, there will always be plenty space to create adversarial samples. 
Details are in the following link. 
https://github.com/zbwby819/My-understandings-about-neural-network/blob/master/Some%20understandings%20about%20neural%20networks.pdf",3,1
132,2018-2-3,2018,2,3,14,7uxhj2,Why does everyone go directly to cloud services when someone asks about a workstation for machine/deep learning?,https://www.reddit.com/r/MachineLearning/comments/7uxhj2/why_does_everyone_go_directly_to_cloud_services/,eshansingh,1517635514,[removed],0,1
133,2018-2-3,2018,2,3,15,7uxvj6,1-D GAN using deeplearn.js on observablehq.com,https://www.reddit.com/r/MachineLearning/comments/7uxvj6/1d_gan_using_deeplearnjs_on_observablehqcom/,mlvpj,1517640980,,0,1
134,2018-2-3,2018,2,3,19,7uyo6a,[R] Anchors : High-Precision Model-Agnostic Explanations (successor of LIME),https://www.reddit.com/r/MachineLearning/comments/7uyo6a/r_anchors_highprecision_modelagnostic/,trowway1239,1517654628,,2,7
135,2018-2-3,2018,2,3,20,7uyqc2,[MACHINELEARNING] Nicolas THE ROCK Cage Movie Collection,https://www.reddit.com/r/MachineLearning/comments/7uyqc2/machinelearning_nicolas_the_rock_cage_movie/,baDoxx,1517655702,,0,1
136,2018-2-3,2018,2,3,20,7uywyg,[R] Continuous Propagation: Layer-Parallel Training,https://www.reddit.com/r/MachineLearning/comments/7uywyg/r_continuous_propagation_layerparallel_training/,FloatOverflow,1517658851,,13,19
137,2018-2-3,2018,2,3,20,7uyx14,[R] Anchors: High-Precision Model-Agnostic Explanations (follow up to LIME),https://www.reddit.com/r/MachineLearning/comments/7uyx14/r_anchors_highprecision_modelagnostic/,nickl,1517658887,,0,2
138,2018-2-3,2018,2,3,21,7uyz2u,Towards Artificial General Intelligence . Really interesting insights on what needs to be done to approach AGI !,https://www.reddit.com/r/MachineLearning/comments/7uyz2u/towards_artificial_general_intelligence_really/,kl_divergence,1517659723,,0,1
139,2018-2-3,2018,2,3,22,7uz6j2,3 Loi My ng Gi Tr Ti Lc c S Dng Nhiu Nht,https://www.reddit.com/r/MachineLearning/comments/7uz6j2/3_loi_my_ng_gi_tr_ti_lc_c_s_dng/,mainguyenmth,1517662862,,0,1
140,2018-2-3,2018,2,3,22,7uzedc,Best online Masters Course in Python and Machine Learning ?,https://www.reddit.com/r/MachineLearning/comments/7uzedc/best_online_masters_course_in_python_and_machine/,Nyd3r,1517665791,[removed],0,1
141,2018-2-3,2018,2,3,23,7uzgof,Making Sense of the Bias / Variance Trade-off in Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/7uzgof/making_sense_of_the_bias_variance_tradeoff_in/,[deleted],1517666619,[deleted],0,1
142,2018-2-3,2018,2,3,23,7uzkum,"I have these 6 Machine Learning Problems, Please solve these questions",https://www.reddit.com/r/MachineLearning/comments/7uzkum/i_have_these_6_machine_learning_problems_please/,erhexor,1517668022,[removed],0,1
143,2018-2-3,2018,2,3,23,7uzl4i,[question] are there any free ML models to play with?,https://www.reddit.com/r/MachineLearning/comments/7uzl4i/question_are_there_any_free_ml_models_to_play_with/,CaptainSlow42,1517668112,[removed],0,1
144,2018-2-3,2018,2,3,23,7uzmcw,[R] Making Sense of the Bias / Variance Trade-off in Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/7uzmcw/r_making_sense_of_the_bias_variance_tradeoff_in/,barskypops,1517668519,,1,21
145,2018-2-4,2018,2,4,0,7uzsmg,Will it be a good idea to study AI (Machine Learning &amp; Deep Learning) and Python myself for a year (15 hrs a day) after I finish my undergraduate?,https://www.reddit.com/r/MachineLearning/comments/7uzsmg/will_it_be_a_good_idea_to_study_ai_machine/,Hot_Ices,1517670467,[removed],0,1
146,2018-2-4,2018,2,4,0,7uzxxn,Imagination PowerVR: the new GPU supports up to 6 4K displays,https://www.reddit.com/r/MachineLearning/comments/7uzxxn/imagination_powervr_the_new_gpu_supports_up_to_6/,mrpuopuo,1517672038,,0,1
147,2018-2-4,2018,2,4,1,7v0bcb,[R]DensePose: Dense Human Pose Estimation In The Wild,https://www.reddit.com/r/MachineLearning/comments/7v0bcb/rdensepose_dense_human_pose_estimation_in_the_wild/,finallyifoundvalidUN,1517675628,,45,284
148,2018-2-4,2018,2,4,1,7v0e33,What are some good online sources to learn Bayesian ML?,https://www.reddit.com/r/MachineLearning/comments/7v0e33/what_are_some_good_online_sources_to_learn/,i_cast_kittehs,1517676367,[removed],0,1
149,2018-2-4,2018,2,4,2,7v0mdn,Fast Cross Validation for Penalized Regression for *Tall* Data,https://www.reddit.com/r/MachineLearning/comments/7v0mdn/fast_cross_validation_for_penalized_regression/,[deleted],1517678475,[deleted],0,1
150,2018-2-4,2018,2,4,3,7v0vrp,"Can we just admit that all frameworks are as fast as each other now, at least stop benchmark stupidity?",https://www.reddit.com/r/MachineLearning/comments/7v0vrp/can_we_just_admit_that_all_frameworks_are_as_fast/,[deleted],1517680848,,0,1
151,2018-2-4,2018,2,4,4,7v1md8,Machine learning in the industry,https://www.reddit.com/r/MachineLearning/comments/7v1md8/machine_learning_in_the_industry/,thetechedblogger,1517687541,[removed],0,1
152,2018-2-4,2018,2,4,5,7v1zp8,Automated Text Classification Using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7v1zp8/automated_text_classification_using_machine/,pmz,1517690975,,0,1
153,2018-2-4,2018,2,4,6,7v2e3i,[MACHINELEARNING] Deepfake Dwayne into Cage,https://www.reddit.com/r/MachineLearning/comments/7v2e3i/machinelearning_deepfake_dwayne_into_cage/,baDoxx,1517694820,,0,1
154,2018-2-4,2018,2,4,7,7v2nv4,"h5 tool included with the ""progressive growing of GANs"" github doesnt work?",https://www.reddit.com/r/MachineLearning/comments/7v2nv4/h5_tool_included_with_the_progressive_growing_of/,[deleted],1517697427,,1,1
155,2018-2-4,2018,2,4,7,7v2nyc,future work on machine learning for aquaculture,https://www.reddit.com/r/MachineLearning/comments/7v2nyc/future_work_on_machine_learning_for_aquaculture/,xfocus3,1517697452,[removed],0,1
156,2018-2-4,2018,2,4,7,7v2r0g,[R] [PDF] Intriguing Properties of Randomly Weighted Networks: Generalizing While Learning Next to Nothing,https://www.reddit.com/r/MachineLearning/comments/7v2r0g/r_pdf_intriguing_properties_of_randomly_weighted/,StackMoreLayers,1517698256,,30,25
157,2018-2-4,2018,2,4,8,7v2zd5,Bayesian Optimisation research,https://www.reddit.com/r/MachineLearning/comments/7v2zd5/bayesian_optimisation_research/,p4316,1517700528,[removed],0,1
158,2018-2-4,2018,2,4,8,7v32jj,Colaboratorys free GPU: imports and exports,https://www.reddit.com/r/MachineLearning/comments/7v32jj/colaboratorys_free_gpu_imports_and_exports/,gatorwatt,1517701451,,0,1
159,2018-2-4,2018,2,4,8,7v35my,"Where is there more opportunity for Deep Learning research scholarships and jobs, China, South Korea or Japan?",https://www.reddit.com/r/MachineLearning/comments/7v35my/where_is_there_more_opportunity_for_deep_learning/,marcoscleison,1517702280,[removed],0,1
160,2018-2-4,2018,2,4,9,7v3ibo,[discussion] stop benchmark stupidity and improve it?,https://www.reddit.com/r/MachineLearning/comments/7v3ibo/discussion_stop_benchmark_stupidity_and_improve_it/,turbocpp,1517705836,"""My framework is faster than yours"" has been a theme. In the really ancient days, which is 2013, Soumith did a great job benchmarking the frameworks of the past, starting with Caffe Cuda-Convnet Theano and Torch, and made all the frameworks starting to realize the importance of proper design for speed.

Today vendors are doing such a great job, and most frameworks are basically calling into vendor libraries, especially cudnn.

There are so many careless benchmarks that, instead of improving value, basically just add to the noise with the real underlying reason being ""I screwed up my installation script"" - by omitting some optimization flags, or using an old runtime library, or so.

For example, considering the recent benchmark post here: https://www.reddit.com/r/MachineLearning/comments/7ujc6y/d_can_someone_give_a_technical_explanation_as_to/ I am in no way saying TensorFlow is worse or better than PyTorch, but it is hard for me to believe that industry deep learning libraries well tested in these big companies differ more than 5% in standard CNN networks, and it is easier for me to believe that the benchmark authors just did something wrong.

So, should we admit that too many benchmark works are just fundamentally careless?

Should we bring back the ""Soumith benchmark""? What happened to the deepmark work by the way? I thought it is a great move.

And, should we ask AWS and/or Google Cloud to host a standard environment, with proper contributions from the framework maintainers, standard models (like, ONNX seems to be pretty promising) and give an accurate measure? For industry people this would not only show a ""my framework is better"" story, but a principled guideline on how one should build and install a framework.",11,16
161,2018-2-4,2018,2,4,9,7v3idn,Describe a specific instance where you had to decide between various technical trade-offs to meet project requirements.,https://www.reddit.com/r/MachineLearning/comments/7v3idn/describe_a_specific_instance_where_you_had_to/,greyghost1991,1517705853,[removed],0,1
162,2018-2-4,2018,2,4,11,7v4117,[D] Harvard scientists think they've pinpointed the physical source of consciousness,https://www.reddit.com/r/MachineLearning/comments/7v4117/d_harvard_scientists_think_theyve_pinpointed_the/,phobrain,1517711424,,17,0
163,2018-2-4,2018,2,4,12,7v4bpn,"Are you interested in learning how to use POWERFUL AI through tutorials for FREE? Check out this Subreddit, AI Tutorials!",https://www.reddit.com/r/MachineLearning/comments/7v4bpn/are_you_interested_in_learning_how_to_use/,DiscoverAI,1517714819,,0,1
164,2018-2-4,2018,2,4,15,7v59ml,This twitter bot uses a CNN to tell you if there is a tide pod in the image,https://www.reddit.com/r/MachineLearning/comments/7v59ml/this_twitter_bot_uses_a_cnn_to_tell_you_if_there/,rponmalai28,1517726532,,0,2
165,2018-2-4,2018,2,4,16,7v5d1l,[D] How are individuals get selected to be reviewers for conferences like ICLR/NIPS/ICML?,https://www.reddit.com/r/MachineLearning/comments/7v5d1l/d_how_are_individuals_get_selected_to_be/,[deleted],1517727987,[deleted],0,1
166,2018-2-4,2018,2,4,16,7v5ftb,How do individuals become reviewers for conferences like NIPS/ICML/ICLR?,https://www.reddit.com/r/MachineLearning/comments/7v5ftb/how_do_individuals_become_reviewers_for/,[deleted],1517729212,,0,1
167,2018-2-4,2018,2,4,16,7v5hrt,[D][R] How does one become a reviewer for ICLR/NIPS/ICML?,https://www.reddit.com/r/MachineLearning/comments/7v5hrt/dr_how_does_one_become_a_reviewer_for_iclrnipsicml/,FirstTimeResearcher,1517730132,"The whole process of how someone becomes a reviewer seems really opaque to me. How does one get selected to be in the pool of reviewers for a given year?
",16,3
168,2018-2-4,2018,2,4,17,7v5lxz,The Seven Trolls of AI,https://www.reddit.com/r/MachineLearning/comments/7v5lxz/the_seven_trolls_of_ai/,kristofferkvam,1517732109,,0,1
169,2018-2-4,2018,2,4,18,7v5ulu,Should i continue with Machine learning?,https://www.reddit.com/r/MachineLearning/comments/7v5ulu/should_i_continue_with_machine_learning/,chewchun,1517736458,[removed],0,1
170,2018-2-4,2018,2,4,19,7v63u5,[P] skift: scikit-learn wrappers for Python,https://www.reddit.com/r/MachineLearning/comments/7v63u5/p_skift_scikitlearn_wrappers_for_python/,[deleted],1517741119,[deleted],0,1
171,2018-2-4,2018,2,4,19,7v64c0,[P] skift: scikit-learn wrappers for Python fastText,https://www.reddit.com/r/MachineLearning/comments/7v64c0/p_skift_scikitlearn_wrappers_for_python_fasttext/,shaypal5,1517741375,,3,35
172,2018-2-4,2018,2,4,20,7v6729,[D] MIT 6.S099: Artificial General Intelligence,https://www.reddit.com/r/MachineLearning/comments/7v6729/d_mit_6s099_artificial_general_intelligence/,Gear5th,1517742714,,168,306
173,2018-2-4,2018,2,4,21,7v6g6g,[D] Splitting ConvLSTM into multiple GPUs,https://www.reddit.com/r/MachineLearning/comments/7v6g6g/d_splitting_convlstm_into_multiple_gpus/,ShivamDuggal4,1517746978,"I ran out of memory running my network on a single GPU(12 GB memory). My network is a ConvLSTM with n timesteps, and at each timestep, I pass a single image, for now. 
At each timestep, all the network weights will be same but the feature maps generated would lead to large memory usage.

Should I execute each timestep in a different GPU, or should I split the network into multiple layers/components and execute all the timesteps of that component on a single GPU.
",11,3
174,2018-2-4,2018,2,4,22,7v6lbp,"[D] Copyright issues while using Screenplays/Movies while training models to generate ""original"" ideas?",https://www.reddit.com/r/MachineLearning/comments/7v6lbp/d_copyright_issues_while_using_screenplaysmovies/,[deleted],1517749208,[deleted],0,1
175,2018-2-4,2018,2,4,22,7v6p9a,[D] Word Embedding with Word2Vec and FastText,https://www.reddit.com/r/MachineLearning/comments/7v6p9a/d_word_embedding_with_word2vec_and_fasttext/,steeveHuang,1517750735,,8,0
176,2018-2-4,2018,2,4,23,7v71q1,Ouliers in Co Occurrence Space,https://www.reddit.com/r/MachineLearning/comments/7v71q1/ouliers_in_co_occurrence_space/,lysecret,1517755157,[removed],0,1
177,2018-2-5,2018,2,5,0,7v7c2i,How to detect anomaly and recognize pattern using Markov Models,https://www.reddit.com/r/MachineLearning/comments/7v7c2i/how_to_detect_anomaly_and_recognize_pattern_using/,ss573,1517758338,,0,1
178,2018-2-5,2018,2,5,0,7v7cez,YOLOv2 Object Detection w/ Keras (in just 20 lines of code),https://www.reddit.com/r/MachineLearning/comments/7v7cez/yolov2_object_detection_w_keras_in_just_20_lines/,miranthalk,1517758432,,0,1
179,2018-2-5,2018,2,5,2,7v81v1,How to learn Deep Learning in 6 months  Medium,https://www.reddit.com/r/MachineLearning/comments/7v81v1/how_to_learn_deep_learning_in_6_months_medium/,QuirkySpiceBush,1517765129,,0,1
180,2018-2-5,2018,2,5,4,7v8wxn,[D] Will Sheffield organize a Gaussian Processes Summer School in 2018?,https://www.reddit.com/r/MachineLearning/comments/7v8wxn/d_will_sheffield_organize_a_gaussian_processes/,RobRomijnders,1517772560,"I heard good stories about the [Gaussian Processes Summer School](http://gpss.cc/). Now that I get to know Neil Lawrence via the Talking Machines podcast, I am curious for attending his course. Do any of you know if they intend a summer school for 2018? Their website doesn't mention it (yet)",8,8
181,2018-2-5,2018,2,5,7,7va9y0,"Top 16 Machine Learning, Data Mining, and NLP Books",https://www.reddit.com/r/MachineLearning/comments/7va9y0/top_16_machine_learning_data_mining_and_nlp_books/,kjahan,1517784381,,0,1
182,2018-2-5,2018,2,5,7,7vacch,Career Advice: Research or Consulting?,https://www.reddit.com/r/MachineLearning/comments/7vacch/career_advice_research_or_consulting/,ignoramus_anus,1517784985,,0,1
183,2018-2-5,2018,2,5,8,7val9e,[D] Enhancing Concert Recordings,https://www.reddit.com/r/MachineLearning/comments/7val9e/d_enhancing_concert_recordings/,osxpinot,1517787330,"Lets say I have crappy audio from a YouTube video of a concert that somebody took on their cell phone.

What tools could I use to upsample this audio?

For training data I have:

* low quality audio from cell phone YouTube videos (lots of audience noise and other noises from moving phone around, etc)

* higher quality audio from tapers who tape with professional microphones close to the speaker stack (some audience noise)

* sometimes professionally mixed audio from the artist (little audience noise mixed in for live experience)",3,1
184,2018-2-5,2018,2,5,8,7vap0a,What uses could Cleverbot have?,https://www.reddit.com/r/MachineLearning/comments/7vap0a/what_uses_could_cleverbot_have/,Camwood7,1517788367,[removed],0,1
185,2018-2-5,2018,2,5,11,7vbhm7,[D] Would the community gain more if conference submissions required source code?,https://www.reddit.com/r/MachineLearning/comments/7vbhm7/d_would_the_community_gain_more_if_conference/,FirstTimeResearcher,1517796605,"Curious what the community thinks about this. If conferences required source code releases, would we all benefit more? I can see some submissions from industry places where this wouldn't be allowed. But would we gain enough in reproducibility to offset this?",45,28
186,2018-2-5,2018,2,5,11,7vbr50,"We have not yet succeeded but learning algorithms might be the ideal way to solve the problem, any thoughts.",https://www.reddit.com/r/MachineLearning/comments/7vbr50/we_have_not_yet_succeeded_but_learning_algorithms/,my_equal,1517799503,[removed],0,1
187,2018-2-5,2018,2,5,12,7vc4ci,What is API.ai's machine learning algorithm? How is it matching intent?,https://www.reddit.com/r/MachineLearning/comments/7vc4ci/what_is_apiais_machine_learning_algorithm_how_is/,cuddle_cuddle,1517803084,[removed],0,1
188,2018-2-5,2018,2,5,14,7vcksz,Ball shape bio fertilizer granulator machine,https://www.reddit.com/r/MachineLearning/comments/7vcksz/ball_shape_bio_fertilizer_granulator_machine/,amylee516,1517807824,,0,1
189,2018-2-5,2018,2,5,14,7vcopa,How best sewing classes Queens could help in buying sewing machines?,https://www.reddit.com/r/MachineLearning/comments/7vcopa/how_best_sewing_classes_queens_could_help_in/,coriandersong,1517809022,,0,1
190,2018-2-5,2018,2,5,14,7vcpkw,"Machine Learning Market- Global Industry Insights,Analysis, 2017-2025",https://www.reddit.com/r/MachineLearning/comments/7vcpkw/machine_learning_market_global_industry/,apeksham,1517809318,,0,1
191,2018-2-5,2018,2,5,15,7vcx7m,What Are The Types Of Sewing Machines And Their Prices Queens?,https://www.reddit.com/r/MachineLearning/comments/7vcx7m/what_are_the_types_of_sewing_machines_and_their/,coriandersong,1517811921,[removed],0,1
192,2018-2-5,2018,2,5,15,7vd0ds,"[D] Why do all these companies and recruiters say they need people who have years of experience in ""big data"" and ""deep learning"" when these things have only had a real resurgence in the last 5 years and virtually NOBODY has ""years of experience"" in these things?",https://www.reddit.com/r/MachineLearning/comments/7vd0ds/d_why_do_all_these_companies_and_recruiters_say/,mkhdfs,1517813051,"Seriously, deep learning has only had a resurgence in the last 5 years. Who the hell has more than 5 years experience in deep learning, other than the absolute pioneers of the discipline, and they're all doing research in universities. so why do companies and recruitment agents constantly put out things on linkedin and shit saying that say they need experienced engineers for roles at a company with ""experience in deep learning"", and then they randomly ask people with any kind of DS/ML background what their experience in deep learning is. Wtf, do you even KNOW what you're talking about? ALMOST NOBODY has the years of experience in deep learning that you're asking for, it's virtually brand new and almost NOBODY was doing it 6 years ago, it only came up outside of university research in the last 5 years and it's still an extremely rare thing anyone in industry knows how to do. So why is everyone now asking for ""extensive experience in deep learning"" it's like they don't even know what they're talking about wtf.",52,0
193,2018-2-5,2018,2,5,15,7vd1mc,How To Make Black &amp; White Photos Look More Natural?,https://www.reddit.com/r/MachineLearning/comments/7vd1mc/how_to_make_black_white_photos_look_more_natural/,microic,1517813526,,0,1
194,2018-2-5,2018,2,5,16,7vd41b,What you can learn in the best sewing classes Queens?,https://www.reddit.com/r/MachineLearning/comments/7vd41b/what_you_can_learn_in_the_best_sewing_classes/,coriandersong,1517814426,[removed],0,1
195,2018-2-5,2018,2,5,16,7vdbxc,[D] How can I make a machine learning ms/phd possible with my interdisciplinary background?,https://www.reddit.com/r/MachineLearning/comments/7vdbxc/d_how_can_i_make_a_machine_learning_msphd/,eightiesfanjan,1517817580,"Hi! I'd really appreciate some feedback on grad school for ML! So I recently graduated from college in data science (concentration in economic analysis), but have realized that I've just 'touched' the tip of the iceberg. I work as a data scientist now and find that the best part of my job is reading research papers and applying concepts to current business problems. Most of my work revolves around ML, with some things that I didn't even know about (like reinforcement learning). I'm quite certain that I want to be a machine learning researcher/ be on the research side of AI. However, I struggle with planning for grad school in ML because of my undergrad that was a bit scattered in terms of its curriculum and feel like I should supplement my profile in various ways....

My question is in 3 parts: 

1) with an interdisciplinary background in DS (stats and cs), does a stats/pure math/ or cs program better equip me for a career in ML? 

2) with my profile below... do I come off like a capable candidate? What knowledge gaps do you think filled to be successful in ML? What do you think I can do more of to improve my candidate profile?

3) Considering my profile, what would be some schools that you'd recommend? 

Here is some coursework/strengths/weaknesses/ideas I've identified:

**Relevant Major Coursework**

* Probability with Applications
* Statistics with Applications
* Linear Algebra and Probability
* Linear Algebra for Machine Learning
* Calc I &amp; II &amp; III
* Discrete Math
* Intro to Machine Learning
* Regression Analysis
* Bioinformatics (this was more like a machine learning + bio course)
* Data Structures &amp; Algorithms
* Software Development
* Intro to Computer Science Principles I &amp; II
* Data Visualization

**Other coursework from the Econ concentration ..**

* Principles of Microeconomics
* Intermediate Microeconomics
* Intro to Finance
* International Monetary Economics

**Strengths**

* GPA 3.75/4
* research publication
* 3 research assistantships: (2) machine learning applications, (1) open source contribution
* Will have data-related work experience before applying
* Passionate about the field!!

**Weaknesses**

* Haven't taken more math like real analysis or differential equations
* Haven't taken more cs like operating systems or architecture
* 75% Percentile on quant GRE (Not good at taking exams. I'd like to retake this soon)

**Ideas**

* Work to 'prove' myself via industry experience and then apply (hopefully this will better allow me to hone in on a specific field)
* Take missing coursework at a different institutions
* Postbac in CS
* Forget grad school and just continue learning on the job/online 

Thank you for any feedback!",29,2
196,2018-2-5,2018,2,5,17,7vdixr,Encoder-Decoder Recurrent Neural Network Models for Neural Machine Translation,https://www.reddit.com/r/MachineLearning/comments/7vdixr/encoderdecoder_recurrent_neural_network_models/,polllyyy,1517820493,,0,1
197,2018-2-5,2018,2,5,17,7vdjgx,[D] Distribution on ranks,https://www.reddit.com/r/MachineLearning/comments/7vdjgx/d_distribution_on_ranks/,themathstudent,1517820716,,4,1
198,2018-2-5,2018,2,5,19,7vdtdb,Entering grad school. What classes can I take to prepare for a role as a Machine Learning Engineer,https://www.reddit.com/r/MachineLearning/comments/7vdtdb/entering_grad_school_what_classes_can_i_take_to/,mattchew1357,1517824861,[removed],0,1
199,2018-2-5,2018,2,5,19,7vdvkb,Machine Learning MSc: Do I have what it takes to succeed with limited programming and strong maths (see my profile below)?,https://www.reddit.com/r/MachineLearning/comments/7vdvkb/machine_learning_msc_do_i_have_what_it_takes_to/,errminator,1517825730,[removed],0,1
200,2018-2-5,2018,2,5,19,7vdwfv,Double Layer Tea Bag Packing Machine,https://www.reddit.com/r/MachineLearning/comments/7vdwfv/double_layer_tea_bag_packing_machine/,lgsherry,1517826097,,1,1
201,2018-2-5,2018,2,5,19,7vdxv7,Impact of Machine Learning to 2030,https://www.reddit.com/r/MachineLearning/comments/7vdxv7/impact_of_machine_learning_to_2030/,marrysa,1517826722,,0,1
202,2018-2-5,2018,2,5,20,7ve1x8,[MACHINELEARNING] President Donald Cage Interview CNBC,https://www.reddit.com/r/MachineLearning/comments/7ve1x8/machinelearning_president_donald_cage_interview/,baDoxx,1517828408,,0,1
203,2018-2-5,2018,2,5,20,7vea6s,[P] An open source Deep Learning / Machine Learning stack on Kubernetes,https://www.reddit.com/r/MachineLearning/comments/7vea6s/p_an_open_source_deep_learning_machine_learning/,mmourafiq,1517831746,,12,48
204,2018-2-5,2018,2,5,21,7vees5,MACHINE LEARNING - THE FUTURE OF APP DEVELOPMENT TECHNOLOGY,https://www.reddit.com/r/MachineLearning/comments/7vees5/machine_learning_the_future_of_app_development/,appsquadz,1517833409,,0,1
205,2018-2-5,2018,2,5,21,7vek3t,[P] Cross-lingual Voice Conversion,https://www.reddit.com/r/MachineLearning/comments/7vek3t/p_crosslingual_voice_conversion/,longinglove,1517835258,,0,5
206,2018-2-5,2018,2,5,21,7vekki,980Ti or 1060 6G for Tensorflow and Scikit,https://www.reddit.com/r/MachineLearning/comments/7vekki/980ti_or_1060_6g_for_tensorflow_and_scikit/,e-hamza,1517835406,[removed],0,1
207,2018-2-5,2018,2,5,22,7velpu,Deep Learning Live Streaming,https://www.reddit.com/r/MachineLearning/comments/7velpu/deep_learning_live_streaming/,rokenroll,1517835788,,0,1
208,2018-2-5,2018,2,5,22,7ven9f,[P] Best practice for Tensorflow Project Template Architecture,https://www.reddit.com/r/MachineLearning/comments/7ven9f/p_best_practice_for_tensorflow_project_template/,mrgemy95,1517836276,,27,117
209,2018-2-5,2018,2,5,22,7veshc,How does one approach extraction of specific content from scanned handwritten documents?,https://www.reddit.com/r/MachineLearning/comments/7veshc/how_does_one_approach_extraction_of_specific/,kushalchauhan98,1517837944,[removed],0,1
210,2018-2-5,2018,2,5,23,7vex8v,Peanut/Groundnut Shell and Stone Removing Machine,https://www.reddit.com/r/MachineLearning/comments/7vex8v/peanutgroundnut_shell_and_stone_removing_machine/,gelserena,1517839361,,1,1
211,2018-2-5,2018,2,5,23,7vf0ho,[D] Inductive bias of reinforcement learning ?,https://www.reddit.com/r/MachineLearning/comments/7vf0ho/d_inductive_bias_of_reinforcement_learning/,metaAI,1517840260,People doing supervised learning often talk about inductive bias and generalization. I am quite curious if there are some existing works to study the inductive bias of reinforcement learning algorithms ? And is there some promising direction to go alone this line from the current state-of-the-art ?,4,3
212,2018-2-6,2018,2,6,0,7vfesz,[Research] EOgmaNeo vs. RNN: Simple Sequence Task,https://www.reddit.com/r/MachineLearning/comments/7vfesz/research_eogmaneo_vs_rnn_simple_sequence_task/,CireNeikual,1517844063,,46,13
213,2018-2-6,2018,2,6,0,7vfo7z,Conference recommendations?,https://www.reddit.com/r/MachineLearning/comments/7vfo7z/conference_recommendations/,astrophy,1517846318,[removed],0,1
214,2018-2-6,2018,2,6,1,7vfxti,Deep Learning for Recommender Systems  eBay Tech Berlin,https://www.reddit.com/r/MachineLearning/comments/7vfxti/deep_learning_for_recommender_systems_ebay_tech/,Tafkas,1517848540,,0,1
215,2018-2-6,2018,2,6,1,7vg138,Why does a network with ZERO hidden layers perform so well?,https://www.reddit.com/r/MachineLearning/comments/7vg138/why_does_a_network_with_zero_hidden_layers/,amazon_qq,1517849295,[removed],0,1
216,2018-2-6,2018,2,6,1,7vg3hh,MIT AGI: Artificial General Intelligence,https://www.reddit.com/r/MachineLearning/comments/7vg3hh/mit_agi_artificial_general_intelligence/,[deleted],1517849834,[deleted],0,1
217,2018-2-6,2018,2,6,1,7vg3tv,NFL teams with AWS on statistics package driven by machine learning,https://www.reddit.com/r/MachineLearning/comments/7vg3tv/nfl_teams_with_aws_on_statistics_package_driven/,jonfla,1517849909,,0,1
218,2018-2-6,2018,2,6,2,7vgbyg,[P] Would any kind strangers be willing to help a newbie attempting to write a Neural Network from scratch in python a hand?,https://www.reddit.com/r/MachineLearning/comments/7vgbyg/p_would_any_kind_strangers_be_willing_to_help_a/,[deleted],1517851694,[deleted],4,0
219,2018-2-6,2018,2,6,2,7vggyg,"A Short Introduction to Entropy, Cross-Entropy and KL-Divergence",https://www.reddit.com/r/MachineLearning/comments/7vggyg/a_short_introduction_to_entropy_crossentropy_and/,tsorn,1517852801,,0,1
220,2018-2-6,2018,2,6,3,7vgo0o,[P] Breaking Ensemble Adversarial Training,https://www.reddit.com/r/MachineLearning/comments/7vgo0o/p_breaking_ensemble_adversarial_training/,ROOTKlT,1517854395,,4,12
221,2018-2-6,2018,2,6,3,7vgo8f,DeepFakes explained + Hottest girls on the net Part 1,https://www.reddit.com/r/MachineLearning/comments/7vgo8f/deepfakes_explained_hottest_girls_on_the_net_part/,vtisza,1517854447,,0,1
222,2018-2-6,2018,2,6,3,7vgpc2,[P] Deep Learning In The Wild: i2x - Conversation training and analysis,https://www.reddit.com/r/MachineLearning/comments/7vgpc2/p_deep_learning_in_the_wild_i2x_conversation/,buhmi,1517854688,,1,5
223,2018-2-6,2018,2,6,3,7vgy4e,[D] Object Detection - Auto labelling,https://www.reddit.com/r/MachineLearning/comments/7vgy4e/d_object_detection_auto_labelling/,TG__,1517856628,"I have several images with multiple objects in each. The size of the set of objects is finite (around 20). I want to detect and classify all objects in an image.

I'm new to this and wanted to use TensorFlow but from what I understand: Training a TensorFlow model requires a labelled/annotated database of images. I have a lot of images and do not want to individually label the bounding boxes in each.

I am not concerned with the value of the labels just that the objects of one class are given the same label.

How do I go about inputing a set of images and the model automatically detecting different objects and training. What alternatives to TensorFlow do I have for this? or online tools?",6,2
224,2018-2-6,2018,2,6,4,7vh5iq,Part II of NIPs healthcare series: Summary of Machine Learning for Healthcare Workshop at NIPS,https://www.reddit.com/r/MachineLearning/comments/7vh5iq/part_ii_of_nips_healthcare_series_summary_of/,[deleted],1517858233,[deleted],0,1
225,2018-2-6,2018,2,6,4,7vhblt,Simple Sequence Generation using a basic Multilayer Perceptron (Without RNN's),https://www.reddit.com/r/MachineLearning/comments/7vhblt/simple_sequence_generation_using_a_basic/,[deleted],1517859607,,0,1
226,2018-2-6,2018,2,6,4,7vhbv3,Part II of NIPs healthcare series: Summary of Machine Learning for Healthcare Workshop at NIPS,https://www.reddit.com/r/MachineLearning/comments/7vhbv3/part_ii_of_nips_healthcare_series_summary_of/,[deleted],1517859661,[deleted],0,1
227,2018-2-6,2018,2,6,4,7vheac,Demystifying Machine Learning (free online event),https://www.reddit.com/r/MachineLearning/comments/7vheac/demystifying_machine_learning_free_online_event/,remotesynth,1517860178,,0,1
228,2018-2-6,2018,2,6,4,7vhemm,[D] Part II of NIPs healthcare series: Summary of Machine Learning for Healthcare Workshop at,https://www.reddit.com/r/MachineLearning/comments/7vhemm/d_part_ii_of_nips_healthcare_series_summary_of/,MLin_NE207,1517860261,,0,12
229,2018-2-6,2018,2,6,5,7vhjh4,Play game automatically using deep learning,https://www.reddit.com/r/MachineLearning/comments/7vhjh4/play_game_automatically_using_deep_learning/,sagar03d,1517861339,,0,1
230,2018-2-6,2018,2,6,5,7vhjir,[R] Volunteer for evaluation of speech synthesis result,https://www.reddit.com/r/MachineLearning/comments/7vhjir/r_volunteer_for_evaluation_of_speech_synthesis/,cyplus1,1517861348,"We have developed speech synthesis algorithm that imitates speaker identity by using only 6 seconds of the speaker's speech sample. 
The following survey is to compare the quality of the imitation algorithm with multi-speaker tts. Please volunteer for the evaluation if you are interested.

http://www.surveygizmo.com/s3/4095550/Evaluation-of-speaker-imitative-speech

Thanks.
",6,3
231,2018-2-6,2018,2,6,5,7vhmp7,"[D] A Short Introduction to Entropy, Cross-Entropy and KL-Divergence",https://www.reddit.com/r/MachineLearning/comments/7vhmp7/d_a_short_introduction_to_entropy_crossentropy/,programmerChilli,1517862016,,26,261
232,2018-2-6,2018,2,6,6,7vi53k,"Is there a standard file format that defines the model structure, weight values, etc. of a neural network?",https://www.reddit.com/r/MachineLearning/comments/7vi53k/is_there_a_standard_file_format_that_defines_the/,gandleforf,1517865999,[removed],0,1
233,2018-2-6,2018,2,6,7,7viht4,"""Has Data Become the New Golden Calf?"" - How Giving Up Our Right to Private Data Hurts Us All.",https://www.reddit.com/r/MachineLearning/comments/7viht4/has_data_become_the_new_golden_calf_how_giving_up/,TheCedarPrince,1517868842,,0,1
234,2018-2-6,2018,2,6,7,7vij7v,Machine learning course with R,https://www.reddit.com/r/MachineLearning/comments/7vij7v/machine_learning_course_with_r/,Dietyloamid,1517869173,[removed],0,1
235,2018-2-6,2018,2,6,7,7vipap,[R] TensorFlow 1.6.0-rc0 Released!,https://www.reddit.com/r/MachineLearning/comments/7vipap/r_tensorflow_160rc0_released/,MetricSpade007,1517870586,,4,19
236,2018-2-6,2018,2,6,8,7viuoe,Animation of MNIST latent space,https://www.reddit.com/r/MachineLearning/comments/7viuoe/animation_of_mnist_latent_space/,neurokinetikz,1517871836,,0,1
237,2018-2-6,2018,2,6,8,7viwp3,[D] Dr. Erin LeDell - Multi-algorithm Ensemble Learning at Scale: Software... - MLconf SEA 2016,https://www.reddit.com/r/MachineLearning/comments/7viwp3/d_dr_erin_ledell_multialgorithm_ensemble_learning/,_alphamaximus_,1517872315,,0,1
238,2018-2-6,2018,2,6,8,7vj4g5,What are Expert Algorithms,https://www.reddit.com/r/MachineLearning/comments/7vj4g5/what_are_expert_algorithms/,fstizzi,1517874179,[removed],0,1
239,2018-2-6,2018,2,6,9,7vjc7e,[D] Image classification: images containing only polygons and a radially decaying weight function?,https://www.reddit.com/r/MachineLearning/comments/7vjc7e/d_image_classification_images_containing_only/,PushThrough,1517876080,"Hi All:

&amp;nbsp;

I am searching for a deep learning model that is appropriate for an image classification problem that I am working on. The problem is related to lithography -- that is the printing of microchips. While I am aware of a few deep learning models that have been applied to the problem, I wanted to ask the general machine learning community about appropriate models for the problem, since some of you may know far better than those in the specific field of lithography. I would rather not build and train my own model from scratch. I am hoping that I can use one of the standard frameworks: TensorFlow, Caffe, Torch, etc. 

&amp;nbsp;

Here is some relevant background:

* A mask is a 2D sheet that encodes a circuit design. A mask contains 2D regions that are transparent to light and 2D regions that are opaque to light. A transparent region is always a polygon. That is, the region is enclosed by a series of connected straight lines.
* A photoresist consists of a coating on top of a wafer. Typically, the coating is resistant to dissolution by acid. When an acid is added, normally it will not dissolve the coating and so not penetrate into and dissolve the wafer. However, the coating is sensitive to light. In a region of the coating that has been exposed to light, new chemical bonds are formed that make the coating susceptible to dissolution by acid. When the acid is added, it will dissolve the coating in that region and so penetrate into and dissolve the wafer.
* To print a circuit encoded by a mask onto the wafer of a photoresist, light is shone through the mask and onto the photoresist, and then the photoresist is washed with acid. In this way, the transparent regions in the mask are etched into the wafer.
* In an ideal world, the output pattern on the wafer would be exactly the same as the pattern on the mask. However, distortions arise due to light diffraction and nonlinear photoresist effects.
* A hotspot is a problematic region in the mask that causes a distortion. To give just one example, a hotspot may arise because the edges of the polygons in the mask are too closely spaced so that light diffraction is a problem.
* I want to build a deep learning model that can identify hotspots.

&amp;nbsp;

My training data is as follows:

* I have many images of different regions of masks. Each image is of a group of polygons. The image file could be a jpeg file of pixels or just a text file that lists the coordinates of the polygons.
* Each image is assigned a label NON-HOTSPOT or HOTSPOT by a human expert. The label indicates if the position at the center of the image is a hotspot. As far as determining if the center of the image is a hotspot, the relative spacings of the edges of the polygons are important. Moreover, points nearer the center of the image are more important than points further away. That is, there must be a weighting of the points that decays radially outwards.

&amp;nbsp;

My questions for you are as follows:

* Can someone recommend a deep learning model, maybe a ConvNet model, that would be appropriate for such training data? Hopefully, I could easily build and train such a model in one of the frameworks like TensorFlow. 
* Is there a model that could work with image files that are just text files that list the coordinates of the polygons? Or must I convert to jpeg files of pixels. Because an image is of polygons, it seems to me that a jpeg file of pixels would bury the signal in noise since most of the pixels are unimportant.
* Should the model include layers that do polygon extraction? Would such layers involve convolutions? 
* How can I weight the points of an image so that points nearer the center are more important than points further away? Would that involve convolutions?

&amp;nbsp;

Thank you very much for you help.

&amp;nbsp;

Sincerely,

Andrew
",1,2
240,2018-2-6,2018,2,6,9,7vjizf,This AI startup just raised $10M to process information  using light,https://www.reddit.com/r/MachineLearning/comments/7vjizf/this_ai_startup_just_raised_10m_to_process/,[deleted],1517877824,[deleted],1,1
241,2018-2-6,2018,2,6,9,7vjlkb,[N] This AI startup just raised $10M to process information  using light,https://www.reddit.com/r/MachineLearning/comments/7vjlkb/n_this_ai_startup_just_raised_10m_to_process/,Exoski,1517878534,,10,12
242,2018-2-6,2018,2,6,10,7vjtsp,[1802.00930] Mixed Precision Training of Convolutional Neural Networks using Integer Operations,https://www.reddit.com/r/MachineLearning/comments/7vjtsp/180200930_mixed_precision_training_of/,fulcrum_xyz,1517880694,,0,1
243,2018-2-6,2018,2,6,11,7vk0vn,[R] Regularized Evolution for Image Classifier Architecture Search,https://www.reddit.com/r/MachineLearning/comments/7vk0vn/r_regularized_evolution_for_image_classifier/,xternalz,1517882589,,6,19
244,2018-2-6,2018,2,6,12,7vkhyf,[R] Domain-Adaptive Meta-Learning,https://www.reddit.com/r/MachineLearning/comments/7vkhyf/r_domainadaptive_metalearning/,downtownslim,1517887265,,3,28
245,2018-2-6,2018,2,6,13,7vkvg5,[R] IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures,https://www.reddit.com/r/MachineLearning/comments/7vkvg5/r_impala_scalable_distributed_deeprl_with/,Kaixhin,1517891251,,10,37
246,2018-2-6,2018,2,6,13,7vkzf2,ComposerGAN: Using human wrist movements as conditional vectors on CGAN trained on music,https://www.reddit.com/r/MachineLearning/comments/7vkzf2/composergan_using_human_wrist_movements_as/,edwardthegreat2,1517892489,,0,1
247,2018-2-6,2018,2,6,16,7vln09,"[P] Serpent.AI 2018.1.0 Released - Exiting Beta, Cross-Platform Gameplay Recording &amp; More",https://www.reddit.com/r/MachineLearning/comments/7vln09/p_serpentai_201810_released_exiting_beta/,SerpentAI,1517900562,,2,10
248,2018-2-6,2018,2,6,16,7vlp83,Linear Regression with Linear Algebra,https://www.reddit.com/r/MachineLearning/comments/7vlp83/linear_regression_with_linear_algebra/,yqzr09,1517901420,,0,1
249,2018-2-6,2018,2,6,16,7vlpyw,NIPS Interpretability Debate,https://www.reddit.com/r/MachineLearning/comments/7vlpyw/nips_interpretability_debate/,siddsach,1517901704,,1,1
250,2018-2-6,2018,2,6,16,7vlski,[D] Data science undergraduate major - better than CS?,https://www.reddit.com/r/MachineLearning/comments/7vlski/d_data_science_undergraduate_major_better_than_cs/,kjaisingh,1517902725,"I'm a high school student looking to enter the field of machine learning and artificial intelligence. I have a reasonable amount of experience in these fields, having done various online courses and created projects. However, I was interested in whether people think that applying to data science major programs (such as the new one in UMichigan) would be more beneficial for me, given that I know that I'm going to look specifically for ML-related jobs? 
Thanks in advance!",6,0
251,2018-2-6,2018,2,6,17,7vm290,Interactive supervision with TensorBoard,https://www.reddit.com/r/MachineLearning/comments/7vm290/interactive_supervision_with_tensorboard/,ibmzrl,1517906795,,0,1
252,2018-2-6,2018,2,6,18,7vm8rb,1060 6GB or RX 480 8GB @ 2018,https://www.reddit.com/r/MachineLearning/comments/7vm8rb/1060_6gb_or_rx_480_8gb_2018/,PDKGearbox,1517909505,[removed],0,1
253,2018-2-6,2018,2,6,18,7vm91c,Tea Bag Packing Machine With String and Tag,https://www.reddit.com/r/MachineLearning/comments/7vm91c/tea_bag_packing_machine_with_string_and_tag/,lgsherry,1517909629,,1,1
254,2018-2-6,2018,2,6,18,7vm9my,[1802.00844] Intriguing Properties of Randomly Weighted Networks: Generalizing While Learning Next to Nothing,https://www.reddit.com/r/MachineLearning/comments/7vm9my/180200844_intriguing_properties_of_randomly/,ihaphleas,1517909892,,0,1
255,2018-2-6,2018,2,6,19,7vmj2u,"2017 Deep Learning Papers on Investing, all credit goes to Dmitry Rastorguev - ITNEXT (Medium)",https://www.reddit.com/r/MachineLearning/comments/7vmj2u/2017_deep_learning_papers_on_investing_all_credit/,Fewthp,1517913728,,0,1
256,2018-2-6,2018,2,6,19,7vmk5a,[D] Information Theory for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7vmk5a/d_information_theory_for_machine_learning/,jarth_or_north,1517914177,"Hi,

I'm looking for good material covering important topics of information theory for machine learning, ideally with a focus on supervised ML.

Videos, books, blog posts or introductory papers (surveys/summary papers) are all highly appreciated.

Thanks
",6,1
257,2018-2-6,2018,2,6,19,7vmk5s,[D] Please help me find an interesting Master Thesis idea,https://www.reddit.com/r/MachineLearning/comments/7vmk5s/d_please_help_me_find_an_interesting_master/,gabegabe6,1517914183,"Hi,

I am in the last year of my MSc as a *engineer IT specialist*. I've worked mostly with computer vision and machine learning in the last 1.5 years.

Why I'm asking this? I tried to figure out what should I do but unfortunately I can't decide. I would like to hear more ideas because I'm sure I missing lot of really good ones.

We had to create ""small thesis"" for every semester and I've already done face detection/recognition, emotion recognition, accelerometer and computer vision based interactive contactless display.

I also work as a Data Scientist, so I'd like to create something in the field of research with a good application for real life.

Is there any interesting topic you can think about?

I've got a few ideas like:

- Cancer research (nuclei segmentation with mask RCNN and classical CV methods, Kaggle competition)
- Controlled GAN (where the input can be a sentence or a word and it generates an image from it)
- Video similarity detection (based on context)

I am strong in:

- Python
- OpenCV
- Keras
- Sklearn

Just an addition: I don't need to write a paper on it. It can be already completed project like image classification with a fine tuned network.",10,0
258,2018-2-6,2018,2,6,19,7vml0c,[MACHINELEARNING] Jennifer Connelly Nicolas Cage,https://www.reddit.com/r/MachineLearning/comments/7vml0c/machinelearning_jennifer_connelly_nicolas_cage/,baDoxx,1517914550,,0,1
259,2018-2-6,2018,2,6,21,7vmybb,A Gentle Introduction to Vectors for Machine Learning - Machine Learning Mastery,https://www.reddit.com/r/MachineLearning/comments/7vmybb/a_gentle_introduction_to_vectors_for_machine/,magneticono,1517919538,,0,1
260,2018-2-6,2018,2,6,22,7vn5nu,"[N] Hakusensha and Hakuhodo DY Digital Announces the Launch of Colorized Manga Products Using PaintsChainer, a Deep Learning Coloring Technology created by Preferred Networks",https://www.reddit.com/r/MachineLearning/comments/7vn5nu/n_hakusensha_and_hakuhodo_dy_digital_announces/,yessir_ziz,1517922057,,35,66
261,2018-2-6,2018,2,6,23,7vnmyx,[D] Where should I sell a financial ML project?,https://www.reddit.com/r/MachineLearning/comments/7vnmyx/d_where_should_i_sell_a_financial_ml_project/,digitalice,1517927096,"Hello, about 3 months ago, my business associate and me started reviewing machine learning papers about Municipal Bonds (price prediction). After one month, I implemented a classifier that is able to predict if a Municipal Bond is going to gain or lose value in a 30 day period with a 70% (+- 5) accuracy. I turned it into a web application. One of the biggest cons, is that needs data from 2 major financial information companies and the subscription is about 20k/month.

Any idea of where should I post this to try to sell it? (I'm not physically in the US, but my business associate is).

Thanks!
",22,0
262,2018-2-7,2018,2,7,0,7vnwpl,[D] Reproducing the ELU paper,https://www.reddit.com/r/MachineLearning/comments/7vnwpl/d_reproducing_the_elu_paper/,dmarnerides,1517929628,"I'm trying to reproduce the [ELU paper ](https://arxiv.org/pdf/1511.07289.pdf) but I'm having some trouble understanding the model structures. I tried to find code that implements it but I couldn't. It would be nice if someone has an implementation.

For the first set of experiments it says:
&gt; The CNN for these CIFAR-100 experiments consists of 11 convolutional layers arranged in stacks
of ([1  192  5], [1  192  1, 1  240  3], [1  240  1, 1  260  2], [1  260  1, 1  280 
2], [1  280  1, 1  300  2], [1  300  1], [1  100  1]) layers  units  receptive fields.

Then:
&gt; 22 max-pooling with a stride of 2 was applied after each stack.

as well as
&gt; the images were padded with four zero pixels at all borders.

and
&gt; The model was trained on 32  32 random crops

My question is regarding the height x width of the inputs and the layers.

**There are 7 stacks, which means 6 max-pooling layers that halve the dimension each time. 2^6 = 64 ? Even if one of them isn't followed by max-pooling, 2^5 = 32, but even with that, the convolutions that have a receptive field &gt; 1 still reduce the size and again it doesn't add up. What is the dimensionality of the input? What am I missing?**

The same question holds for the second other CIFAR-100 architecture described later on (which currently reports the best test error for CIFAR-100).
",12,9
263,2018-2-7,2018,2,7,0,7vnyw0,[D]The Best of AI: New Articles Published This Month (January 2018),https://www.reddit.com/r/MachineLearning/comments/7vnyw0/dthe_best_of_ai_new_articles_published_this_month/,quentinf1324,1517930175,,0,0
264,2018-2-7,2018,2,7,0,7vo3zn,Detecting cancer with neural networks fast and easy,https://www.reddit.com/r/MachineLearning/comments/7vo3zn/detecting_cancer_with_neural_networks_fast_and/,roman-kh,1517931409,,0,1
265,2018-2-7,2018,2,7,0,7vo5ut,System requirements for machine vision,https://www.reddit.com/r/MachineLearning/comments/7vo5ut/system_requirements_for_machine_vision/,Bayesian_Guy,1517931870,[removed],0,1
266,2018-2-7,2018,2,7,0,7vo6n9,Pruning Neural Networks: Notes on Two Recent Papers on L-norm and Fisher pruning and Generalization,https://www.reddit.com/r/MachineLearning/comments/7vo6n9/pruning_neural_networks_notes_on_two_recent/,[deleted],1517932049,[deleted],0,1
267,2018-2-7,2018,2,7,0,7vo70z,"[R] Neural Network Pruning: Notes on Two New Papers about L-norm, Fisher pruning",https://www.reddit.com/r/MachineLearning/comments/7vo70z/r_neural_network_pruning_notes_on_two_new_papers/,fhuszar,1517932139,,12,36
268,2018-2-7,2018,2,7,1,7voe15,Fast preprocessing and augmentation of computed tomography scans,https://www.reddit.com/r/MachineLearning/comments/7voe15/fast_preprocessing_and_augmentation_of_computed/,roman-kh,1517933743,,0,1
269,2018-2-7,2018,2,7,1,7vogoa,supervised machine learning for time series,https://www.reddit.com/r/MachineLearning/comments/7vogoa/supervised_machine_learning_for_time_series/,MLbeginner96,1517934350,[removed],0,1
270,2018-2-7,2018,2,7,2,7vormz,Stanford Tutorials on TensorFlow and PyTorch,https://www.reddit.com/r/MachineLearning/comments/7vormz/stanford_tutorials_on_tensorflow_and_pytorch/,NicNic8,1517936746,,0,1
271,2018-2-7,2018,2,7,2,7vowt7,Is it a good idea to switch from Pytorch to TensorFlow Eager?,https://www.reddit.com/r/MachineLearning/comments/7vowt7/is_it_a_good_idea_to_switch_from_pytorch_to/,real_charlie_parker,1517937874,,0,1
272,2018-2-7,2018,2,7,3,7vpibt,Help with alert correlation,https://www.reddit.com/r/MachineLearning/comments/7vpibt/help_with_alert_correlation/,[deleted],1517942579,,0,1
273,2018-2-7,2018,2,7,4,7vprzv,Effect of Wrong sign of variables on Machine Learning Model,https://www.reddit.com/r/MachineLearning/comments/7vprzv/effect_of_wrong_sign_of_variables_on_machine/,ragas_,1517944680,[removed],0,1
274,2018-2-7,2018,2,7,4,7vptld,[D] What are your best practices when implementing a new deep learning model?,https://www.reddit.com/r/MachineLearning/comments/7vptld/d_what_are_your_best_practices_when_implementing/,manueslapera,1517945018,"I have been noticing a lack of information regarding frameworks to follow when building a deep net . 

It seems that most people nowadays only find the state of the art architecture for their specific problem , finetune it and call it a day.

However, I am sure there is some structured process that can be followed to decide whether to improve a model (add more layers, remove layers, optimize the hyperparameters, etcectera) besides ""gut feeling"".

Which process do you guys usually follow?",30,4
275,2018-2-7,2018,2,7,5,7vqcss,[D] 6.S191 Introduction to Deep Learning | MIT,https://www.reddit.com/r/MachineLearning/comments/7vqcss/d_6s191_introduction_to_deep_learning_mit/,sksq9,1517949212,,3,36
276,2018-2-7,2018,2,7,5,7vqdd3,[R] Learning Robot Objectives from Physical Human Interaction,https://www.reddit.com/r/MachineLearning/comments/7vqdd3/r_learning_robot_objectives_from_physical_human/,Jackal008,1517949328,,0,16
277,2018-2-7,2018,2,7,5,7vqdoz,[N] The Instant Motion Tracking Behind Motion Stills AR,https://www.reddit.com/r/MachineLearning/comments/7vqdoz/n_the_instant_motion_tracking_behind_motion/,Jackal008,1517949399,,0,1
278,2018-2-7,2018,2,7,6,7vr0i4,Help with LSTM Normalization and Implementation,https://www.reddit.com/r/MachineLearning/comments/7vr0i4/help_with_lstm_normalization_and_implementation/,ateraksi,1517954282,[removed],0,1
279,2018-2-7,2018,2,7,7,7vr25l,[D] Loss-function Fitness Landscape Analysis (from a Computational Finance blog),https://www.reddit.com/r/MachineLearning/comments/7vr25l/d_lossfunction_fitness_landscape_analysis_from_a/,satsatsat,1517954630,,0,2
280,2018-2-7,2018,2,7,7,7vr41a,"Introducing capsule networks: How CapsNets can overcome some shortcomings of CNNs, including requiring less training data, preserving image details, and handling ambiguity",https://www.reddit.com/r/MachineLearning/comments/7vr41a/introducing_capsule_networks_how_capsnets_can/,gwern,1517955040,,0,1
281,2018-2-7,2018,2,7,7,7vr55s,[D] How difficult will it be for a Reinforcement Learning agent to do the Falcon Heavy booster landing?,https://www.reddit.com/r/MachineLearning/comments/7vr55s/d_how_difficult_will_it_be_for_a_reinforcement/,sksq9,1517955281,,74,198
282,2018-2-7,2018,2,7,8,7vrqc5,Univfy raises $6 million to better predict IVF success rates using machine learning,https://www.reddit.com/r/MachineLearning/comments/7vrqc5/univfy_raises_6_million_to_better_predict_ivf/,n_jai,1517960224,,0,1
283,2018-2-7,2018,2,7,10,7vsntz,Almond Shelling Machine|Hazelnut Shell Cracking Equipment for Sale,https://www.reddit.com/r/MachineLearning/comments/7vsntz/almond_shelling_machinehazelnut_shell_cracking/,gelserena,1517968752,,1,1
284,2018-2-7,2018,2,7,11,7vswr7,What is a two layer Ising model?,https://www.reddit.com/r/MachineLearning/comments/7vswr7/what_is_a_two_layer_ising_model/,AlexandreZani,1517971081,[removed],0,1
285,2018-2-7,2018,2,7,12,7vtcqo,Moringa Seed Peeling Machine|Dehulling Unit for sale,https://www.reddit.com/r/MachineLearning/comments/7vtcqo/moringa_seed_peeling_machinedehulling_unit_for/,gelserena,1517975370,,1,1
286,2018-2-7,2018,2,7,14,7vu1oo,What to expect for machine learning interviews?,https://www.reddit.com/r/MachineLearning/comments/7vu1oo/what_to_expect_for_machine_learning_interviews/,interana,1517983054,[removed],0,1
287,2018-2-7,2018,2,7,15,7vu3as,Pistachio Slicing Machine|Macadamia Hazelnut Kernel Slice Cutting Machinery,https://www.reddit.com/r/MachineLearning/comments/7vu3as/pistachio_slicing_machinemacadamia_hazelnut/,gelserena,1517983591,,1,1
288,2018-2-7,2018,2,7,16,7vujsl,[R] [1802.01808] Mixed Link Networks,https://www.reddit.com/r/MachineLearning/comments/7vujsl/r_180201808_mixed_link_networks/,tzivo,1517989725,,6,0
289,2018-2-7,2018,2,7,16,7vujz7,Mixer machine for producing organic fertilizer,https://www.reddit.com/r/MachineLearning/comments/7vujz7/mixer_machine_for_producing_organic_fertilizer/,amylee516,1517989798,,0,1
290,2018-2-7,2018,2,7,17,7vuo9e,Visual Feature Attribution Using Wasserstein GANs (Python + PyTorch),https://www.reddit.com/r/MachineLearning/comments/7vuo9e/visual_feature_attribution_using_wasserstein_gans/,[deleted],1517991514,[deleted],0,1
291,2018-2-7,2018,2,7,17,7vupn2,[P] Visual Feature Attribution Using Wasserstein GANs (with Python and Pytorch),https://www.reddit.com/r/MachineLearning/comments/7vupn2/p_visual_feature_attribution_using_wasserstein/,dnlcrl,1517992128,,0,6
292,2018-2-7,2018,2,7,17,7vuqvc,[P] Real-time Mask RCNN using Facebook Detectron,https://www.reddit.com/r/MachineLearning/comments/7vuqvc/p_realtime_mask_rcnn_using_facebook_detectron/,_sshin_,1517992714,,90,814
293,2018-2-7,2018,2,7,18,7vuujx,Learn Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7vuujx/learn_machine_learning/,watsonangel22,1517994287,,0,1
294,2018-2-7,2018,2,7,18,7vuwgg,"[D] Besides eventbrite and meetup.com, are there any other ways to look up machine learning events in your area?",https://www.reddit.com/r/MachineLearning/comments/7vuwgg/d_besides_eventbrite_and_meetupcom_are_there_any/,SkyStyles,1517995097,,9,3
295,2018-2-7,2018,2,7,19,7vv4jz,Auto laminator machine,https://www.reddit.com/r/MachineLearning/comments/7vv4jz/auto_laminator_machine/,waleedagency,1517998251,,0,1
296,2018-2-7,2018,2,7,19,7vv5mv,[P] Analyzing user comments of German news outlets with Doc2Vec and Stochastic Gradient Descent classification,https://www.reddit.com/r/MachineLearning/comments/7vv5mv/p_analyzing_user_comments_of_german_news_outlets/,SmCaterpillar,1517998632,,1,1
297,2018-2-7,2018,2,7,19,7vv64a,[Machinelearning] Cage Loves Britney,https://www.reddit.com/r/MachineLearning/comments/7vv64a/machinelearning_cage_loves_britney/,baDoxx,1517998806,,0,1
298,2018-2-7,2018,2,7,21,7vvocw,23 Examples of How the Most Powerful Institutions Are Leveraging Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7vvocw/23_examples_of_how_the_most_powerful_institutions/,gomedici,1518005546,,0,1
299,2018-2-7,2018,2,7,21,7vvt37,Best Machine Learning Training Online,https://www.reddit.com/r/MachineLearning/comments/7vvt37/best_machine_learning_training_online/,leviya,1518007186,,0,1
300,2018-2-7,2018,2,7,22,7vw6s5,Automatic Masala Powder Packing Machine,https://www.reddit.com/r/MachineLearning/comments/7vw6s5/automatic_masala_powder_packing_machine/,lgsherry,1518011310,,1,1
301,2018-2-7,2018,2,7,22,7vw8bl,More efficient machine learning could upend the AI paradigm,https://www.reddit.com/r/MachineLearning/comments/7vw8bl/more_efficient_machine_learning_could_upend_the/,[deleted],1518011757,[deleted],0,1
302,2018-2-7,2018,2,7,23,7vwkur,More efficient machine learning could upend the AI paradigm,https://www.reddit.com/r/MachineLearning/comments/7vwkur/more_efficient_machine_learning_could_upend_the/,jonfla,1518015139,,0,1
303,2018-2-8,2018,2,8,0,7vwtzt,What to Do When Algorithms Rule,https://www.reddit.com/r/MachineLearning/comments/7vwtzt/what_to_do_when_algorithms_rule/,djn_9,1518017313,,0,1
304,2018-2-8,2018,2,8,0,7vww7r,Opening Closed Eyes with Exemplar Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/7vww7r/opening_closed_eyes_with_exemplar_generative/,[deleted],1518017835,[deleted],1,2
305,2018-2-8,2018,2,8,0,7vx12g,"Simple Questions Thread February 07, 2018",https://www.reddit.com/r/MachineLearning/comments/7vx12g/simple_questions_thread_february_07_2018/,AutoModerator,1518018947,[removed],0,1
306,2018-2-8,2018,2,8,1,7vx3y8,This year AI predictions,https://www.reddit.com/r/MachineLearning/comments/7vx3y8/this_year_ai_predictions/,finom_company,1518019587,[removed],0,1
307,2018-2-8,2018,2,8,1,7vxbdo,5 Must have skills to become Machine Learning Engineer,https://www.reddit.com/r/MachineLearning/comments/7vxbdo/5_must_have_skills_to_become_machine_learning/,vinay6666,1518021202,,0,1
308,2018-2-8,2018,2,8,2,7vxnll,[P] Tensorflow implementation of NIPS 2017 Paper Prototypical Networks for Few-shot Learning,https://www.reddit.com/r/MachineLearning/comments/7vxnll/p_tensorflow_implementation_of_nips_2017_paper/,SolitaryPenman,1518023855,,0,15
309,2018-2-8,2018,2,8,2,7vxr74,[R] Opening Closed Eyes with Exemplar Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/7vxr74/r_opening_closed_eyes_with_exemplar_generative/,fb-brian,1518024667,,5,6
310,2018-2-8,2018,2,8,2,7vxx3v,Implementation of adversarial patch,https://www.reddit.com/r/MachineLearning/comments/7vxx3v/implementation_of_adversarial_patch/,[deleted],1518025936,[deleted],0,1
311,2018-2-8,2018,2,8,2,7vxyaz,IMPALA performance on different tasks of DMLab-30,https://www.reddit.com/r/MachineLearning/comments/7vxyaz/impala_performance_on_different_tasks_of_dmlab30/,gohu_cd,1518026198,,0,1
312,2018-2-8,2018,2,8,2,7vxz7s,Guides to Machine Learning Production Deployment?,https://www.reddit.com/r/MachineLearning/comments/7vxz7s/guides_to_machine_learning_production_deployment/,baordog,1518026398,[removed],0,1
313,2018-2-8,2018,2,8,3,7vycif,Focal Loss for Object Detection,https://www.reddit.com/r/MachineLearning/comments/7vycif/focal_loss_for_object_detection/,tiger287,1518029196,[removed],0,1
314,2018-2-8,2018,2,8,4,7vyh0p,"As everyone is finalizing their ICML submissions I urge you to remove the page numbers from your citations! They will look so much better! Also, you can save space! Using these style files will remove them automatically!",https://www.reddit.com/r/MachineLearning/comments/7vyh0p/as_everyone_is_finalizing_their_icml_submissions/,[deleted],1518030144,[deleted],0,1
315,2018-2-8,2018,2,8,4,7vyhbk,"No more page numbers! As everyone is finalizing their ICML submissions I urge you to remove the page numbers from your citations! They will look so much better! Also, you can save space! Using these style files will remove them automatically!",https://www.reddit.com/r/MachineLearning/comments/7vyhbk/no_more_page_numbers_as_everyone_is_finalizing/,ieee8023,1518030208,,0,1
316,2018-2-8,2018,2,8,4,7vylhv,"Machine Learning for final year project, weak background in maths",https://www.reddit.com/r/MachineLearning/comments/7vylhv/machine_learning_for_final_year_project_weak/,Seeker_of_worlds,1518031102,[removed],0,1
317,2018-2-8,2018,2,8,4,7vyr5k,[D] Discovering Types for Entity Disambiguation | OpenAI,https://www.reddit.com/r/MachineLearning/comments/7vyr5k/d_discovering_types_for_entity_disambiguation/,sksq9,1518032345,,2,38
318,2018-2-8,2018,2,8,4,7vytuv,"How can we create ""Brains""/machines/neural networks that are better than us(we/idk)?",https://www.reddit.com/r/MachineLearning/comments/7vytuv/how_can_we_create_brainsmachinesneural_networks/,chrismit3s,1518032900,[removed],0,1
319,2018-2-8,2018,2,8,5,7vz4ue,[N]Program Lead Jake Lussier on Udacitys New Flying Car Nanodegree,https://www.reddit.com/r/MachineLearning/comments/7vz4ue/nprogram_lead_jake_lussier_on_udacitys_new_flying/,trcytony,1518035282,,0,0
320,2018-2-8,2018,2,8,6,7vzdv9,A bidirectional recurrent autoencoder for globally optimized dependency parsing,https://www.reddit.com/r/MachineLearning/comments/7vzdv9/a_bidirectional_recurrent_autoencoder_for/,matteogrella,1518037277,,0,1
321,2018-2-8,2018,2,8,6,7vze1v,Is anyone familiar with some pre-trained models that are used for signal processing?,https://www.reddit.com/r/MachineLearning/comments/7vze1v/is_anyone_familiar_with_some_pretrained_models/,iltalfme,1518037324,[removed],0,1
322,2018-2-8,2018,2,8,6,7vzfpx,[D] What is the current state of art in face recognition?,https://www.reddit.com/r/MachineLearning/comments/7vzfpx/d_what_is_the_current_state_of_art_in_face/,roar363,1518037697,I have recently explored 2 popular papers for face recognition- DeepFace and FaceNet. What has been development in face recognition is past 1-2 years? What is the best implementation? LFW Face Database is solved I believe. (FaceNet 99.63%). What are popular datasets as of 2017/2018 for face recognition?,5,2
323,2018-2-8,2018,2,8,6,7vzjle,[R] Make Patterns Pop Out of Heatmaps with Seriation,https://www.reddit.com/r/MachineLearning/comments/7vzjle/r_make_patterns_pop_out_of_heatmaps_with_seriation/,pmigdal,1518038577,,10,39
324,2018-2-8,2018,2,8,6,7vzogf,[R] Leveraging Adiabatic Quantum Computation for Election Forecasting,https://www.reddit.com/r/MachineLearning/comments/7vzogf/r_leveraging_adiabatic_quantum_computation_for/,jleonardbc,1518039625,,0,3
325,2018-2-8,2018,2,8,7,7vzuak,Orbital Insights - counting cars in parking lots?,https://www.reddit.com/r/MachineLearning/comments/7vzuak/orbital_insights_counting_cars_in_parking_lots/,[deleted],1518040926,,0,1
326,2018-2-8,2018,2,8,7,7vzz00,Classification with limited set of labeled images,https://www.reddit.com/r/MachineLearning/comments/7vzz00/classification_with_limited_set_of_labeled_images/,deluded_soul,1518042029,[removed],0,1
327,2018-2-8,2018,2,8,7,7w02sz,[P] PyTorch implementation of adversarial patch,https://www.reddit.com/r/MachineLearning/comments/7w02sz/p_pytorch_implementation_of_adversarial_patch/,Confusedius,1518042923,,0,8
328,2018-2-8,2018,2,8,7,7w05vq,Orbital Insights -- counting cars?,https://www.reddit.com/r/MachineLearning/comments/7w05vq/orbital_insights_counting_cars/,[deleted],1518043664,,0,1
329,2018-2-8,2018,2,8,7,7w08is,[D] Orbital insights -- counting cars?,https://www.reddit.com/r/MachineLearning/comments/7w08is/d_orbital_insights_counting_cars/,zma11rocks,1518044303,"I was reading this article: https://thenextweb.com/insider/2017/03/08/palo-alto-startup-predicts-retail-failure-via-satellite-images/ and was very curious about what this startup company, Orbital Insights, is doing. Does anyone know how might they deal with the issue of multiple stores sharing a parking lot? I.e. JC Penneys might have other stores that are nearby. How would you be able to tell if a car parked in the lot is going to JC Penneys?",3,0
330,2018-2-8,2018,2,8,8,7w0ea5,The New Neural Internet is Coming and it looks pretty scary from here,https://www.reddit.com/r/MachineLearning/comments/7w0ea5/the_new_neural_internet_is_coming_and_it_looks/,[deleted],1518045678,[deleted],0,1
331,2018-2-8,2018,2,8,8,7w0l30,What is a free software to create neural networks that generate new instances of text based on a sample?,https://www.reddit.com/r/MachineLearning/comments/7w0l30/what_is_a_free_software_to_create_neural_networks/,loner_solitario,1518047340,,0,1
332,2018-2-8,2018,2,8,10,7w1cae,How good does your hardware have to be?,https://www.reddit.com/r/MachineLearning/comments/7w1cae/how_good_does_your_hardware_have_to_be/,Jontzjr,1518054380,[removed],0,1
333,2018-2-8,2018,2,8,13,7w269l,Fashion app Chicismo goes from 0 to 4M users by using vertical machine learning,https://www.reddit.com/r/MachineLearning/comments/7w269l/fashion_app_chicismo_goes_from_0_to_4m_users_by/,tellman1257,1518062650,,1,1
334,2018-2-8,2018,2,8,13,7w28sf,[D] Are there good libraries/pretrained models for taxonomy classification?,https://www.reddit.com/r/MachineLearning/comments/7w28sf/d_are_there_good_librariespretrained_models_for/,winstonl,1518063391,"I've found a few libraries, such as https://www.paralleldots.com/text-classification, that does the job. Does anyone know if there are pretrained models (or data sets) available for this type of tasks?

Thanks",2,0
335,2018-2-8,2018,2,8,13,7w2bwa,How did Google patent policy learning in 2016? How is this allowed?,https://www.reddit.com/r/MachineLearning/comments/7w2bwa/how_did_google_patent_policy_learning_in_2016_how/,bobster82183,1518064329,[removed],0,1
336,2018-2-8,2018,2,8,14,7w2jsa,Interspeech 2017 Speech Synthesis Technology,https://www.reddit.com/r/MachineLearning/comments/7w2jsa/interspeech_2017_speech_synthesis_technology/,Andrea_01,1518066812,,0,1
337,2018-2-8,2018,2,8,15,7w2so6,[R] A learning resource repository for 3D machine learning,https://www.reddit.com/r/MachineLearning/comments/7w2so6/r_a_learning_resource_repository_for_3d_machine/,ennetws,1518069754,,4,31
338,2018-2-8,2018,2,8,15,7w2ujs,[R] Object-Oriented Deep Learning (MIT),https://www.reddit.com/r/MachineLearning/comments/7w2ujs/r_objectoriented_deep_learning_mit/,xternalz,1518070429,,13,49
339,2018-2-8,2018,2,8,15,7w2y7q,So our friends at Google Brain used 450 GPUs to run a single *data point* for 7 days just to improve a test error by 4%? I'm done!,https://www.reddit.com/r/MachineLearning/comments/7w2y7q/so_our_friends_at_google_brain_used_450_gpus_to/,Fadama,1518071679,,1,1
340,2018-2-8,2018,2,8,15,7w2z88,"[P] Tensorflow implemetation of ""Unsupervised Image to Image Translation"" NIPS2017 Spotlight",https://www.reddit.com/r/MachineLearning/comments/7w2z88/p_tensorflow_implemetation_of_unsupervised_image/,[deleted],1518072053,[deleted],0,1
341,2018-2-8,2018,2,8,15,7w30gp,"[P] Tensorflow implementation of ""NIPS2017 Spotlight, Unsupervised Image to Image Translation Networks on multi-gpu &amp; single-gpu""",https://www.reddit.com/r/MachineLearning/comments/7w30gp/p_tensorflow_implementation_of_nips2017_spotlight/,taki0112,1518072507,,0,20
342,2018-2-8,2018,2,8,17,7w3dpm,"How long does it take to have a strong enough foundation to work at Facebook AI, IBM, Google Brain/Deepmind, etc.?",https://www.reddit.com/r/MachineLearning/comments/7w3dpm/how_long_does_it_take_to_have_a_strong_enough/,[deleted],1518077759,,0,1
343,2018-2-8,2018,2,8,18,7w3r0v,"[D] Plots, LIMES, and surrogate models to understand machine learning models",https://www.reddit.com/r/MachineLearning/comments/7w3r0v/d_plots_limes_and_surrogate_models_to_understand/,liquidus08,1518083325,,9,32
344,2018-2-8,2018,2,8,19,7w3uh5,[D] Dynamic routing by feedback activation maximization,https://www.reddit.com/r/MachineLearning/comments/7w3uh5/d_dynamic_routing_by_feedback_activation/,mpihlstrom,1518084731,"I'm wondering if there has been any work done on CNNs with each filter pooler trying to match a (scalar) value fed back from the most immediate downstream neuron, where this feedback value is ultimately anchored to some cost function on the top layer. I'm imagining a simple architecture where the goal is to derive the type of ""inverse graphics"" transformation that Hinton speaks of. The top layer feedback values could even be some affine transformation of the input data.

The trickling down of activation values would be performed in iterations and in a diffusion process induce a kind of dynamic routing with neighboring filters forced to agree upon a constellation of transformations. After some number iterations, fixed or based on some local maxima convergence criteria, the diffusion would be halted and the weights updated in standard backprop fashion.

Does this make sense? Has it been done?",0,1
345,2018-2-8,2018,2,8,19,7w3x1x,"Google deleted 7,00,000 Harmful Mobile Apps from Play Store in 2017 with the Help of Machine Learning",https://www.reddit.com/r/MachineLearning/comments/7w3x1x/google_deleted_700000_harmful_mobile_apps_from/,ZoeyWilliam,1518085758,,0,1
346,2018-2-8,2018,2,8,19,7w3yqh,Deep Feature Synthesis: How Automated Feature Engineering Works,https://www.reddit.com/r/MachineLearning/comments/7w3yqh/deep_feature_synthesis_how_automated_feature/,molode,1518086453,,0,1
347,2018-2-8,2018,2,8,20,7w41yp,Gil Kalai's Argument Against Quantum Computers,https://www.reddit.com/r/MachineLearning/comments/7w41yp/gil_kalais_argument_against_quantum_computers/,janemoz,1518087769,,0,1
348,2018-2-8,2018,2,8,20,7w45w3,[N] Petnica summer institute machine learning seminar,https://www.reddit.com/r/MachineLearning/comments/7w45w3/n_petnica_summer_institute_machine_learning/,rvukasin,1518089325,"I would like to encourage every undergraduate/graduate student interested in getting broad theoretical and practical knowledge in machine learning to apply for Petnica summer institute machine learning seminar (http://psiml.petnica.rs).

This seminar is held by Microsoft Development Center Serbia engineers that work on really interesting machine learning related projects like Windows Mixed Reality, Bing local search, handwritten math formula recognition, extracting map features from satellite images and many more as well as invited speakers from other companies/universities. Many people found this seminar to be life changing and you can check out some of their testimonials here: http://psiml.petnica.rs/testimonials.php

I am one of the lecturers so you can ask me anything you want to know more about the seminar and I will be happy to answer. The registration is now open and the seminar will be held from 22nd to 31st of July in Petnica, Serbia. You can register at http://psiml.petlja.org.

Hope to meet some of you on the seminar this summer :)",2,10
349,2018-2-8,2018,2,8,20,7w46zv,[P] Lime: Explaining the predictions of any machine learning classifier,https://www.reddit.com/r/MachineLearning/comments/7w46zv/p_lime_explaining_the_predictions_of_any_machine/,petrwilson,1518089770,,20,110
350,2018-2-8,2018,2,8,20,7w49fs,"[N] Weekly Machine Learning Opensource Roundup  Feb. 8, 2018",https://www.reddit.com/r/MachineLearning/comments/7w49fs/n_weekly_machine_learning_opensource_roundup_feb/,stkim1,1518090673,,0,1
351,2018-2-8,2018,2,8,21,7w4awj,Train a real time image dataset,https://www.reddit.com/r/MachineLearning/comments/7w4awj/train_a_real_time_image_dataset/,datavizu,1518091226,[removed],0,1
352,2018-2-8,2018,2,8,21,7w4dtf,[R] From Action to Abstraction: Learning Concepts through Sensorimotor Interactions,https://www.reddit.com/r/MachineLearning/comments/7w4dtf/r_from_action_to_abstraction_learning_concepts/,feryaaa,1518092211,,0,45
353,2018-2-8,2018,2,8,21,7w4gzi,"""[Project]"" MachineLearning/DeepLearning to detect whether a component is placed on a component-holder",https://www.reddit.com/r/MachineLearning/comments/7w4gzi/project_machinelearningdeeplearning_to_detect/,ket0ma,1518093304,"I am thinking about writing a seminar paper about machine learning especially deep learning to detect if objects are present or not. But before I commit myself to this usecase, I would like to know if you guys think there are going to be any problems and 
whether my approche would make sense or not.
The usecase would be components are placed on a component-holder.
It should detect if a component is placed on a component-holder.
If there is a posibility to place more than one component in a holder it should detect where it is placed.

Since I do not need to differentiate between the types of the component, I do not know how to approche this.

I could teach with different components and holders. And have them just classified as component or holder.

I do not know if this approche is any good or I should take another one. Maybe you guys have the experience and an idea how to approche this usecase.",2,1
354,2018-2-8,2018,2,8,21,7w4jtq,Cement Powder Packing Machine,https://www.reddit.com/r/MachineLearning/comments/7w4jtq/cement_powder_packing_machine/,lgsherry,1518094224,,1,1
355,2018-2-8,2018,2,8,22,7w4uk6,[MACHINELEARNING]Mr. Trololol Cage,https://www.reddit.com/r/MachineLearning/comments/7w4uk6/machinelearningmr_trololol_cage/,baDoxx,1518097384,,0,1
356,2018-2-8,2018,2,8,22,7w4wzb,[D] What is the SOTA in Signature Verification?,https://www.reddit.com/r/MachineLearning/comments/7w4wzb/d_what_is_the_sota_in_signature_verification/,shayanrc,1518098045,"What is the state of the art in Signature Verification?

I have a dataset of signatures, including multiple samples for each person. But there is a problem with the dataset, there are no forgeries in the data. Is there a way to train a model without creating the forgeries myself?

I was thinking of training a GAN on this data. Would that be a good idea?",11,1
357,2018-2-8,2018,2,8,22,7w4x9m,Bubble remover machine didnt remove bubbles from s6 edge glass,https://www.reddit.com/r/MachineLearning/comments/7w4x9m/bubble_remover_machine_didnt_remove_bubbles_from/,Mobirege,1518098116,[removed],0,1
358,2018-2-8,2018,2,8,22,7w4xxw,[R] AAAI 2018 Notes,https://www.reddit.com/r/MachineLearning/comments/7w4xxw/r_aaai_2018_notes/,pdxdabel,1518098313,,9,47
359,2018-2-8,2018,2,8,23,7w50bt,Getting on the Right Path for a Machine Learning Career: The Courses and Sources to Get You There,https://www.reddit.com/r/MachineLearning/comments/7w50bt/getting_on_the_right_path_for_a_machine_learning/,cmelendez2014,1518098948,,0,1
360,2018-2-8,2018,2,8,23,7w53ih,What does notop and ordering mean in h5 files?,https://www.reddit.com/r/MachineLearning/comments/7w53ih/what_does_notop_and_ordering_mean_in_h5_files/,TotoTata92000,1518099774,[removed],0,1
361,2018-2-8,2018,2,8,23,7w54m2,Print labels of the nearest neighbours from scikit KNeighborsClassifier?,https://www.reddit.com/r/MachineLearning/comments/7w54m2/print_labels_of_the_nearest_neighbours_from/,datavizu,1518100061,[removed],0,1
362,2018-2-9,2018,2,9,0,7w5hjf,[N][R] CORe50: a new Dataset and Benchmark for Continuous/Lifelong Object Recognition,https://www.reddit.com/r/MachineLearning/comments/7w5hjf/nr_core50_a_new_dataset_and_benchmark_for/,Gengiolo,1518103199,"Dear all,

We are happy to announce that the CORe50 dataset from the paper CORe50: a new Dataset and Benchmark for Continuous Object Recognition (CoRL, 2017) is now publicly available at the link: https://vlomonaco.github.io/core50/

CORe50, specifically designed for Continuous/Lifelong Learning and Object Recognition, is a collection of more than 500 videos (30fps) of 50 domestic objects belonging to 10 different categories. Instance level granularity, temporal coherence, first-person point-of-view and very different environmental conditions and backgrounds (outdoor sessions included) is what makes CORe50 particularly useful for assessing Continuous Learning techniques.

On top of the CORe50 dataset we are also happy to release a 3-way benchmark with multiple baselines and a living leaderboard to keep track of the progresses made in this new exciting area! For downloading the code, the dataset, the benchmark and more, check out the official website https://vlomonaco.github.io/core50/

Vincenzo Lomonaco,
PhD student @ University of Bologna",3,33
363,2018-2-9,2018,2,9,0,7w5ife,[P] Evolutionary Game of Life with Genetic Algorithm,https://www.reddit.com/r/MachineLearning/comments/7w5ife/p_evolutionary_game_of_life_with_genetic_algorithm/,ljmocic,1518103423,,10,29
364,2018-2-9,2018,2,9,0,7w5lq4,Deepfake Compilation [MACHINELEARNING],https://www.reddit.com/r/MachineLearning/comments/7w5lq4/deepfake_compilation_machinelearning/,baDoxx,1518104194,,0,1
365,2018-2-9,2018,2,9,0,7w5mrk,Bridging the Gap Between Computational Photography and Visual Recognition: The UG^2 Prize Challenge Workshop at CVPR 2018,https://www.reddit.com/r/MachineLearning/comments/7w5mrk/bridging_the_gap_between_computational/,wscheirer,1518104454,,0,1
366,2018-2-9,2018,2,9,0,7w5opd,Building Robust Deep Neural Networks for Road Sign Detection,https://www.reddit.com/r/MachineLearning/comments/7w5opd/building_robust_deep_neural_networks_for_road/,arkar_aung,1518104900,,0,1
367,2018-2-9,2018,2,9,0,7w5qjl,Has anybody heard back from Facebook AI residency program?,https://www.reddit.com/r/MachineLearning/comments/7w5qjl/has_anybody_heard_back_from_facebook_ai_residency/,[deleted],1518105287,,0,1
368,2018-2-9,2018,2,9,0,7w5qu7,"[P] Starting new project- looking for (paid!) tutor! A few 1-2hr skype calls, $50/hr (negotiable). Details within.",https://www.reddit.com/r/MachineLearning/comments/7w5qu7/p_starting_new_project_looking_for_paid_tutor_a/,Phildos,1518105355,"Hey!
A few pieces of context up front:

- I'm 28
- *Not* a student
- Full time software dev
- BS in Computer Science
- I *don't* need help w/ ""setting up libraries"", ""programming"", etc...
- I *do* need help building an understanding of how RL works
- Specifically interested in PPO (unless our talks orient me otherwise)
- I'm weak in calculus
- Willing to read papers
- Just need to bounce questions off a human, be directed where to orient my studies
- This is for a pet software development (*not* research) project of mine
- I only know how to speak English, am in Central Time zone (America, Chicago- it's 10AM here at time of posting), am free nights/weekends

I can give details about the project if you're interested- otherwise let me know!
",4,0
369,2018-2-9,2018,2,9,0,7w5rw9,Machine learning mega-benchmark: GPU providers,https://www.reddit.com/r/MachineLearning/comments/7w5rw9/machine_learning_megabenchmark_gpu_providers/,[deleted],1518105597,[deleted],0,1
370,2018-2-9,2018,2,9,1,7w5tyd,[P][N] Machine learning mega-benchmark: GPU providers,https://www.reddit.com/r/MachineLearning/comments/7w5tyd/pn_machine_learning_megabenchmark_gpu_providers/,piskvorky,1518106011,,16,7
371,2018-2-9,2018,2,9,1,7w5unr,[D] Has anybody heard back from Facebook AI Residency program?,https://www.reddit.com/r/MachineLearning/comments/7w5unr/d_has_anybody_heard_back_from_facebook_ai/,lingqizhang,1518106159,"As Feb 16 is coming, has anybody heard back about requesting for LoR or even interviews? Good luck to all of us!",47,16
372,2018-2-9,2018,2,9,1,7w66jh,I have come across this tensorflow tutorial playlist and it seems useful. What do you think ?,https://www.reddit.com/r/MachineLearning/comments/7w66jh/i_have_come_across_this_tensorflow_tutorial/,Debabrata-I,1518108787,,0,1
373,2018-2-9,2018,2,9,2,7w69ez,high-level - what services to use/build that can detect/capture cars ignoring a stop sign?,https://www.reddit.com/r/MachineLearning/comments/7w69ez/highlevel_what_services_to_usebuild_that_can/,jngnyc,1518109381,[removed],0,1
374,2018-2-9,2018,2,9,2,7w6buj,Turi Create now supports Python 3,https://www.reddit.com/r/MachineLearning/comments/7w6buj/turi_create_now_supports_python_3/,perfectm,1518109902,,0,1
375,2018-2-9,2018,2,9,2,7w6l2k,[P] I created a python pip package to help users clean their time series data and prepare it for machine learning,https://www.reddit.com/r/MachineLearning/comments/7w6l2k/p_i_created_a_python_pip_package_to_help_users/,techiemd1,1518111884,"Hey all

I'm a medical student that has been learning about python and machine learning. Ive been analyzing a lot of time series data. I created a library called timecleaner to help others to the same and to automate some of my work load. I tried to condense the actual code as much as I can but if you see any areas of improvement let me know.

you can install it with 
```
pip install timeclean
```

Here's the github link
https://github.com/DineshRai/timecleaner

Thanks for reading!
",5,4
376,2018-2-9,2018,2,9,3,7w6xyq,[R] Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models,https://www.reddit.com/r/MachineLearning/comments/7w6xyq/r_decisionbased_adversarial_attacks_reliable/,downtownslim,1518114619,,3,3
377,2018-2-9,2018,2,9,4,7w7llh,Time series to supervised learning,https://www.reddit.com/r/MachineLearning/comments/7w7llh/time_series_to_supervised_learning/,MLbeginner96,1518119715,[removed],0,1
378,2018-2-9,2018,2,9,5,7w7u2q,Any better value than i7-6850k ?,https://www.reddit.com/r/MachineLearning/comments/7w7u2q/any_better_value_than_i76850k/,bfeeny,1518121566,[removed],0,1
379,2018-2-9,2018,2,9,5,7w7wnj,Is my model underfitting? Including tensorboard visualizations.,https://www.reddit.com/r/MachineLearning/comments/7w7wnj/is_my_model_underfitting_including_tensorboard/,the_usual_unusual,1518122145,[removed],0,1
380,2018-2-9,2018,2,9,5,7w7z6n,[D] Papers on the sample complexity of Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/7w7z6n/d_papers_on_the_sample_complexity_of/,bronzestick,1518122726,"Aside to Kakade's thesis and Mohammad Azar's work, what are the more recent important papers on sample complexity of RL methods? 
",3,1
381,2018-2-9,2018,2,9,6,7w8e0j,[D] How to prep for a deep learning/machine learning job?,https://www.reddit.com/r/MachineLearning/comments/7w8e0j/d_how_to_prep_for_a_deep_learningmachine_learning/,calcgen,1518125968,"How should I prep for a job like deep learning engineer or research engineer? I've been refreshing my CS basics with CTCI and LeetCode, but I don't know how much time I should spend on that versus reading papers and refreshing machine learning knowledge. Should I be able to do backpropagation with ease on a whiteboard? Ideally, I'd like to get involved in research and go back to school eventually.",23,77
382,2018-2-9,2018,2,9,7,7w8m0f,How different is the areas of study needed for someone interested specifically in AGI research?,https://www.reddit.com/r/MachineLearning/comments/7w8m0f/how_different_is_the_areas_of_study_needed_for/,galoiz,1518127750,[removed],0,1
383,2018-2-9,2018,2,9,7,7w8sbf,A Scikit-learn pipeline in Wallaroo,https://www.reddit.com/r/MachineLearning/comments/7w8sbf/a_scikitlearn_pipeline_in_wallaroo/,chuckblake,1518129198,,0,1
384,2018-2-9,2018,2,9,10,7wa2c0,Two matrices for one word in word2vec,https://www.reddit.com/r/MachineLearning/comments/7wa2c0/two_matrices_for_one_word_in_word2vec/,[deleted],1518141000,,0,1
385,2018-2-9,2018,2,9,11,7wacgp,[D] Which one to choose among two matrices for one word in word2vec?,https://www.reddit.com/r/MachineLearning/comments/7wacgp/d_which_one_to_choose_among_two_matrices_for_one/,NLPLearner,1518143778,"word2vec(either skip-gram or cbow) creates two matrices for one word. I am wondering that which matrix to use and if so, why do we use that matrix. or it doesn't matter which one to use at all?

(In my personal opinion, I thought skip-gram use the front matrix created in input to hidden and cbow use the second matrix created in hidden to output layer)

I want to hear many opinions from you guys! Thanks!",1,0
386,2018-2-9,2018,2,9,12,7wak43,Optimizing neural network weights using particle swarm optimization,https://www.reddit.com/r/MachineLearning/comments/7wak43/optimizing_neural_network_weights_using_particle/,Arc426,1518145892,[removed],0,1
387,2018-2-9,2018,2,9,13,7waxfm,An old but really well written paper on pose estimation using CNNs,https://www.reddit.com/r/MachineLearning/comments/7waxfm/an_old_but_really_well_written_paper_on_pose/,Not_Again_Reddit,1518149773,[removed],0,1
388,2018-2-9,2018,2,9,14,7wba4r,What Skills to Develop for a Career in Machine Learning ??,https://www.reddit.com/r/MachineLearning/comments/7wba4r/what_skills_to_develop_for_a_career_in_machine/,pavanear,1518153698,,0,1
389,2018-2-9,2018,2,9,14,7wbe4s,"Looking at ROC, can I say if one of the model is better when high sensitivity is required",https://www.reddit.com/r/MachineLearning/comments/7wbe4s/looking_at_roc_can_i_say_if_one_of_the_model_is/,bigtimefoodie,1518154958,,0,1
390,2018-2-9,2018,2,9,16,7wbs46,Tackling Adversarial Examples! My first article on Medium. Please give it a read.,https://www.reddit.com/r/MachineLearning/comments/7wbs46/tackling_adversarial_examples_my_first_article_on/,divyanshjha,1518159970,,0,1
391,2018-2-9,2018,2,9,17,7wc1iv,China: police use glasses for facial recognition,https://www.reddit.com/r/MachineLearning/comments/7wc1iv/china_police_use_glasses_for_facial_recognition/,mrpuopuo,1518163838,,0,1
392,2018-2-9,2018,2,9,17,7wc1td,[D] Replacing self-play of AlphaZero with agent-simulator interaction for model-based N-MCTS,https://www.reddit.com/r/MachineLearning/comments/7wc1td/d_replacing_selfplay_of_alphazero_with/,HigherTopoi,1518163951,"In [[D] AlphaZero for G of GAN](https://www.reddit.com/r/MachineLearning/comments/7m3hjh/d_alphazero_for_g_of_gan/), for application to sequential decision problems with trivial/simple dynamics such as realistic text generation I proposed that AlphaZero's z is determined by a discriminator D, and that AZ and the D are trained like GAN. In the case of text generation, I can think of some simpler and possibly better variants of this: for example, instead of making z to be determined by D, z of prefixes of real/fake sentences are assigned +1/-1, respectively. Then, the training is identical to AZ, except that 50% of a minibatch consists of prefixes of real sentences, and other 50% consists of prefixes of sentences from buffer of generated sentences. The policy head tries to deceive the value head that tries to distinguish real/fake, just as in GAN, so we don't need a separate architecture D, and we don't have to rely on artificial value of z produced by D. If we use LSTM/Transformer, then the hidden state or the cache can be stored in the tree to avoid redundancy in inference, and we can fit all the (s,pi,z) tuples from one real/fake sentence into a minibatch for efficient training. I'm about to finish implementing all of these variants for experiment. 

A limitation of N-MCTS is that for general RL problems it requires a presence of simulator and that it hasn't been extended to continuous state/action case. I'd like to discuss the former issue here, assuming that my approach in the first paragraph works fine. A N-MCTS agent maps the n-recent history H^t := (s^t-n ,a^t-n ,r^t-n ..., a^t-1 ,r^t-1 ,s^t ) to an action A^t := a^t . A (neural) simulator here refers to a neural network N that maps the n-recent history I^t := (s^t-n ,a^t-n ,r^t-n ...,a^t-1 ,r^t-1 ,s^t ,a^t ) to a pair B^t := (r^t , s^t+1 ), and it approximates the environment. Now, consider H^t / I^t to be a state and A^t / B^t to be an action, so the state transition goes like H^t -&gt; I^t -&gt; H^t+1 -&gt;... This replaces the self-play of AZ by using another policy&amp;value heads specifically for simulator but still retaining the dual (here quadruple) architecture in their core. The z of the simulator side is assigned differently from the z of the agent side, the latter of which is problem-dependent. Since the purpose of simulator is to imitate the real environment, the z of the simulator side is assigned just as in the realistic text generation (+1/-1). A problem resides in how to switch between sampling from the real world and sampling from the simulator. One naive option is to set a constant for the ratio/frequency of playing real games vs. playing fake games. During both kinds of games, simulation of the environment side is performed by the simulator. However, state transition outside of MCTS is sampled from the simulator in fake games and from the real world in real games, respectively. The training is once again 50/50 for real/fake tuples.  

Relevant sources can be found in gwern's post [[D] RL: GANs as MCTS environment simulator for deep model-based planning?](https://www.reddit.com/r/MachineLearning/comments/66x02v/d_rl_gans_as_mcts_environment_simulator_for_deep/). [Learning and Querying Fast Generative Models for Reinforcement Learning](https://arxiv.org/abs/1802.03006) may also be interesting, though there's no mention of MCTS.",0,6
393,2018-2-9,2018,2,9,17,7wc2na,[R][P]Class imbalance not taken into account in video summarization papers.,https://www.reddit.com/r/MachineLearning/comments/7wc2na/rpclass_imbalance_not_taken_into_account_in_video/,shamitlal,1518164280,"I was going through some papers on video summarization using TV SUM dataset for training their models. TV sum dataset assigns each frame a score from 1 to 5, 5 being the most important frame. The dataset is imbalanced, with the number of frames having label 1 being 10 times in count than those having label 5. However, I couldn't understand how these papers are tackling this class imbalance problem. There is no mention of it also.

Some paper links: 
1) https://arxiv.org/abs/1605.08110
2) https://www.microsoft.com/en-us/research/wp-content/uploads/2017/11/TCSVT-01549-2017-doublecolumn.pdf
",4,3
394,2018-2-9,2018,2,9,18,7wccju,Helps turn python utilities and packages into quick reactive front ends for use by the non technical in our company,https://www.reddit.com/r/MachineLearning/comments/7wccju/helps_turn_python_utilities_and_packages_into/,MeshachBlue,1518168655,,0,1
395,2018-2-9,2018,2,9,19,7wchqe,[D] Is there any app that uses AI to increase resolution?,https://www.reddit.com/r/MachineLearning/comments/7wchqe/d_is_there_any_app_that_uses_ai_to_increase/,lexaxelaexl,1518170844,"After 3 hours of Googling, I have to ask you guys.
I'm looking for an app or command-line tool that is able to increase resolution using AI. Something like Let's Enhance but free. 
I know about Alex J. C.'s neural-enhance but my PC is not able to run Docker. And without Docker, the installation is super complex. 
Also, I don't have Nvidia graphics card that supports CUDA.

Is there a reason why there is no wide-spread app like this? Is it so power consuming? And is there any alternative solution?",74,62
396,2018-2-9,2018,2,9,19,7wcmu0,3 Technologies That Could Win the Battle Against Cybercrime,https://www.reddit.com/r/MachineLearning/comments/7wcmu0/3_technologies_that_could_win_the_battle_against/,mr_j_b,1518172971,,0,1
397,2018-2-9,2018,2,9,19,7wcp21,[D] [Question] training / validation error,https://www.reddit.com/r/MachineLearning/comments/7wcp21/d_question_training_validation_error/,[deleted],1518173880,[deleted],0,0
398,2018-2-9,2018,2,9,20,7wcrum,You are what you read! - New Doors to Personalized Content,https://www.reddit.com/r/MachineLearning/comments/7wcrum/you_are_what_you_read_new_doors_to_personalized/,BehaviourExchange,1518174919,,0,1
399,2018-2-9,2018,2,9,20,7wcto0,"Thesis proposal on a mixture of IoT/Cyber-physical systems, Big data and Machine learning",https://www.reddit.com/r/MachineLearning/comments/7wcto0/thesis_proposal_on_a_mixture_of_iotcyberphysical/,Imakesensealot,1518175618,[removed],0,1
400,2018-2-9,2018,2,9,20,7wctse,[R] Classification of the clinical images for benign and malignant cutaneous tumors using a deep learning algorithm,https://www.reddit.com/r/MachineLearning/comments/7wctse/r_classification_of_the_clinical_images_for/,whria78,1518175671," Our article ""Classification of the clinical images for benign and malignant cutaneous tumors using a deep learning algorithm"" is published on the Journal of Investigative of Dermatology, a peer-reviewed scientific journal of dermatology published by the Nature Publishing Group.

**12 benign and malignant cutaneous tumors**    
basal cell carcinoma, squamous cell carcinoma, intraepithelial carcinoma, actinic keratosis, seborrheic keratosis, malignant melanoma, melanocytic nevus, lentigo, pyogenic granuloma, hemangioma, dermatofibroma, and wart    

**Dataset (number of images)**    
Training dataset : Asan training (15408), Additional Asan (159477), Atlas (3820), MED-NODE (170)    
Validation dataset : Asan test (1276), Hallym (152), Edinburgh (1300)    
    
**CNN Model**    
ResNet-152    

**Result (AUC value)**    
    
Asan test dataset : basal cell carcinoma (0.96  0.01), squamous cell carcinoma (0.83  0.01), intraepithelial carcinoma (0.82  0.02), and melanoma (0.96  0.00)    
Edinburgh dataset : basal cell carcinoma (0.90  0.01), squamous cell carcinoma (0.91  0.01), intraepithelial carcinoma (0.83  0.01), and melanoma (0.88  0.01)    
    
The tested algorithm performance with 480 Asan and Edinburgh images was comparable to that of 16 dermatologists. (Figure 3)    
    
**Figures &amp; Paper Link**    
Heatmap (Figure 2) : https://i.imgur.com/pmqegwJ.png    
ROC Curve (Figure 3) : https://i.imgur.com/4gXYBQQ.png    
Online DEMO : http://dx.medicalphoto.org    
Article : http://www.jidonline.org/article/S0022-202X(18)30111-8/fulltext    
(Sorry for not provding open-access, if you leave your email address in this reddit, I will send the pre-print version.)

**Our Next Model - Model Dermatology , Model Melanoma**    
Model Dermatology    
web - http://modelderm.com    
android - https://play.google.com/store/apps/details?id=com.phonegap.dermatology_en    
Model Melanoma    
web - http://melanoma.modelderm.com    
android - https://play.google.com/store/apps/details?id=com.phonegap.melanoma_en

",22,39
401,2018-2-9,2018,2,9,20,7wcybk,SHAP: unifying local intepretation approaches for ML moels such as LIME [1705.07874],https://www.reddit.com/r/MachineLearning/comments/7wcybk/shap_unifying_local_intepretation_approaches_for/,statmlsn,1518177403,,1,1
402,2018-2-9,2018,2,9,21,7wd2lu,Help with 1080 ti selection,https://www.reddit.com/r/MachineLearning/comments/7wd2lu/help_with_1080_ti_selection/,Ereb0,1518178900,[removed],0,1
403,2018-2-9,2018,2,9,21,7wd7if,Azure Machine Learning Studio,https://www.reddit.com/r/MachineLearning/comments/7wd7if/azure_machine_learning_studio/,abhinavsethi,1518180509,,0,1
404,2018-2-9,2018,2,9,23,7wdrio,Changing IP addresses to metrics to use them as input to a decision tree or a neural network.,https://www.reddit.com/r/MachineLearning/comments/7wdrio/changing_ip_addresses_to_metrics_to_use_them_as/,hassanmok,1518186508,[removed],0,1
405,2018-2-9,2018,2,9,23,7wdvlp,Given my professors previous exam questions. What is needed to predict the most relevant subjects in future exams? (most relevant = most points to get),https://www.reddit.com/r/MachineLearning/comments/7wdvlp/given_my_professors_previous_exam_questions_what/,BacSai,1518187582,[removed],0,1
406,2018-2-10,2018,2,10,0,7webe9,"The general discussion surrounding AI is embarrassing, and we need to do something about it",https://www.reddit.com/r/MachineLearning/comments/7webe9/the_general_discussion_surrounding_ai_is/,mpgls,1518191538,,0,1
407,2018-2-10,2018,2,10,1,7wen9d,Machine Learning Telegram Group,https://www.reddit.com/r/MachineLearning/comments/7wen9d/machine_learning_telegram_group/,rex_divakar,1518194283,[removed],0,1
408,2018-2-10,2018,2,10,1,7wesev,Match photo of lost dog using ML?,https://www.reddit.com/r/MachineLearning/comments/7wesev/match_photo_of_lost_dog_using_ml/,mercury434,1518195409,[removed],0,1
409,2018-2-10,2018,2,10,2,7wf1hs,AI Weekly 9 Feb 2018,https://www.reddit.com/r/MachineLearning/comments/7wf1hs/ai_weekly_9_feb_2018/,TomekB,1518197427,,0,1
410,2018-2-10,2018,2,10,3,7wfg3d,[D] Deep Learning Jobs: Should I take an undesirable but immediate job offer or should I wait and try for better ones?,https://www.reddit.com/r/MachineLearning/comments/7wfg3d/d_deep_learning_jobs_should_i_take_an_undesirable/,mad_runner,1518200638,"I completed my Masters a few months back and currently have a job offer that involves Deep Learning but only in name. From what I've been told I'll do only around 20% Deep Learning while most of my remaining time will be spent on helping develop web interfaces, doing some backend work etc (I've been told I'm gonna require Java, HTML much more than anything else). I've been doing significant work in Deep Learning prior to this. The few other interview calls I've been receiving have been for actual Deep Learning roles. I feel with a bit more effort I'll make it.

Honestly I feel I'm settling for less. Me being near broke is pretty much why I'm even thinking of taking this job. However I'm worried that if the workload is too much I won't have time to study and improve my skills and will remain stuck here!

So should I try to wait it out for a couple months more or should I join? Could anyone give me any advice? I'm really confused!",24,0
411,2018-2-10,2018,2,10,3,7wfi0m,[D] Simple Question: Any good library functions for timeseries / 1D Non Maximal Supression.,https://www.reddit.com/r/MachineLearning/comments/7wfi0m/d_simple_question_any_good_library_functions_for/,criticalcontext,1518201064,"I know a lot of computer vision libraries have non maximal suppression, and yes you can always just apply one of those to a 1D array reshaped into 2D. However, some of those functions assume data between 0-255, and they aren't exactly ""optimized"" for 1D signal data.

Basically, I have sparse data, but the non-zero values tend to cluster. I want to change this to where the maximum non-zero value moves to the centroid of these clusters, and the rest become zero.",9,3
412,2018-2-10,2018,2,10,3,7wfkbg,[D] Sysml Results,https://www.reddit.com/r/MachineLearning/comments/7wfkbg/d_sysml_results/,Refefer,1518201589,,1,5
413,2018-2-10,2018,2,10,3,7wfnme,How Fundamental Analysis is done! (Example Company - Enbridge),https://www.reddit.com/r/MachineLearning/comments/7wfnme/how_fundamental_analysis_is_done_example_company/,FreakByChoice85,1518202338,,0,1
414,2018-2-10,2018,2,10,3,7wfpfi,MachineLabs launches CLI to compliment their web based Machine Learning platform,https://www.reddit.com/r/MachineLearning/comments/7wfpfi/machinelabs_launches_cli_to_compliment_their_web/,cburgdorf,1518202767,,0,1
415,2018-2-10,2018,2,10,4,7wfufv,[R] Predicting the physical state of a seismogenic fault from the sound it emits,https://www.reddit.com/r/MachineLearning/comments/7wfufv/r_predicting_the_physical_state_of_a_seismogenic/,merepoule,1518203894,http://onlinelibrary.wiley.com/doi/10.1002/2017GL076708/abstract,2,17
416,2018-2-10,2018,2,10,4,7wg0d2,"Example ML usage in normal/boring, real world businesses?",https://www.reddit.com/r/MachineLearning/comments/7wg0d2/example_ml_usage_in_normalboring_real_world/,xt11111,1518205291,[removed],0,1
417,2018-2-10,2018,2,10,5,7wg8go,Any Ideas for open source recommendation and decision engines or trained models?,https://www.reddit.com/r/MachineLearning/comments/7wg8go/any_ideas_for_open_source_recommendation_and/,stupidCSstudent,1518207155,[removed],0,1
418,2018-2-10,2018,2,10,8,7whhyy,"[D] If buttons, mouse velocity, and joystick position were merged into a sparse vector stream, where each button press smoothly rises then falls to negatives then decays to 0 (like a bio neuron spiking), then what should the curve of a button be?",https://www.reddit.com/r/MachineLearning/comments/7whhyy/d_if_buttons_mouse_velocity_and_joystick_position/,BenRayfield,1518218203,"Dimensions whose current value is near 0 would be excluded from the sparse data. All such values range -1 to 1.

A big issue is lag of button presses viewed as a smooth curve. If it only rises while holding the button, or commits to rise in the next 1/5 second, people would feel lag compared to systems that react to button events instantly. If it rises instantly at constant velocity, then falls for twice that time, then rises for same time, like a sawtooth wave, then functions watching the vector stream may miss such an event which returns to 0 in 4x the time the button is held (or other time if multiple presses occur sooner). We might explore prediction of button presses, given the other dimensions of the sparse vector, and raise the input into such a ""simulated bio neuron"" based on such predictions, but it still has the same problems of reacting to the real thing, like trying to hide lag in a game by predicting what the other players will do based on their last known state.",2,0
419,2018-2-10,2018,2,10,8,7whjre,[D] Looking to pay for a DL Coach,https://www.reddit.com/r/MachineLearning/comments/7whjre/d_looking_to_pay_for_a_dl_coach/,ateraksi,1518218666,"I am attempting a beginners project predicting a time series with a LSTM using Keras and I have many many questions which I'm sure are easily answered by a professional in the field. An outline of types of questions I might ask are here: https://www.reddit.com/r/MachineLearning/comments/7vr0i4/help_with_lstm_normalization_and_implementation/

I would like to look over and discuss my notebook together for an initial hour and then potentially continue for more hours in the future. Will pay $50USD/hr or slightly higher if you can demonstrate particular expertise to this task.

Thanks",4,0
420,2018-2-10,2018,2,10,9,7whzhw,"[P] PyTorch Implementation of the NIPS 2017 Paper ""Prototypical Networks for Few Shot Learning""",https://www.reddit.com/r/MachineLearning/comments/7whzhw/p_pytorch_implementation_of_the_nips_2017_paper/,[deleted],1518222817,[deleted],0,1
421,2018-2-10,2018,2,10,9,7whzvo,"[P] PyTorch Implementation of the NIPS 2017 Paper ""Prototypical Networks for Few Shot Learning""",https://www.reddit.com/r/MachineLearning/comments/7whzvo/p_pytorch_implementation_of_the_nips_2017_paper/,dnlcrl,1518222928,,20,87
422,2018-2-10,2018,2,10,9,7wi03o,Extended Kalman Filter simplified Udacitys Self-driving Car Nanodegree,https://www.reddit.com/r/MachineLearning/comments/7wi03o/extended_kalman_filter_simplified_udacitys/,dkarunakaran,1518222991,,0,1
423,2018-2-10,2018,2,10,9,7wi1go,[D] MNIST and CIFAR-10 equivalents for Speech Recognition?,https://www.reddit.com/r/MachineLearning/comments/7wi1go/d_mnist_and_cifar10_equivalents_for_speech/,radenML,1518223364,"i.e. tiny dataset for sanity check, and slightly bigger dataset that count as 'small dataset'",9,11
424,2018-2-10,2018,2,10,10,7wi899,Natural intelligence as the result of a massive optimization task,https://www.reddit.com/r/MachineLearning/comments/7wi899/natural_intelligence_as_the_result_of_a_massive/,[deleted],1518225194,,0,1
425,2018-2-10,2018,2,10,10,7wic8n,"[D] Need to support family, top-paying jobs with ML PhD?",https://www.reddit.com/r/MachineLearning/comments/7wic8n/d_need_to_support_family_toppaying_jobs_with_ml/,anon0828047,1518226334,"I have a PhD from [top-5 university] and a postdoc from [another top-5] under [big-name], and last year joined a 10 person startup in SV where I build ML models for a company I believe in. I get good equity (but worth nothing now) and a good salary.

For reasons I will not get into for this post, I find myself in need to make large sums of money for the next 1-3 years (suffice it to say, a family member is ill, and I will need to provide support, and can we all agree how fucked up this countries health care is?).

Where can I go to sell my soul who will pay for ML people like me? The highest I could find is GoogFaceAppSoft where they get paid ~200k as a research scientist. Do finance companies pay for people like me? Any other options? Has anyone had experience trying to work a side-job consulting? Please help.",27,0
426,2018-2-10,2018,2,10,10,7wigw5,How to create a continuous random variable classifier from discrete training data?,https://www.reddit.com/r/MachineLearning/comments/7wigw5/how_to_create_a_continuous_random_variable/,AndrewKemendo,1518227650,[removed],0,1
427,2018-2-10,2018,2,10,13,7wj6fo,KHL-800 Manure compost fertilizer granulator machine,https://www.reddit.com/r/MachineLearning/comments/7wj6fo/khl800_manure_compost_fertilizer_granulator/,amylee516,1518235402,,0,1
428,2018-2-10,2018,2,10,14,7wjk57,awesome-self-supervised-learning resources,https://www.reddit.com/r/MachineLearning/comments/7wjk57/awesomeselfsupervisedlearning_resources/,jasonren718,1518240024,[removed],0,1
429,2018-2-10,2018,2,10,15,7wju9f,[D] What could scientists learn from learned solutions?,https://www.reddit.com/r/MachineLearning/comments/7wju9f/d_what_could_scientists_learn_from_learned/,Sumthinclever,1518243759,"If an algorithm is set to learning some policy about how to interact with the world to achieve a specific task, what is there to be learned from the algorithm's solution? For example, have new physical or biological principles governing the robustness of - or tradeoffs in locomotion strategies been learned from analysis of the learned movement patterns of the Deepmind walkers? 

I'm a biology PhD student and I've been wondering how my field could take advantage of advances in machine learning to move biology forward. It's one thing to be able to make predictions, but it seems to me that reinforcement learning approaches offer the potential for machines to act as scientists themselves. ",5,2
430,2018-2-10,2018,2,10,16,7wk0bj,What is the current state-of-the-art for text document representation for sentiment analysis in nlp?,https://www.reddit.com/r/MachineLearning/comments/7wk0bj/what_is_the_current_stateoftheart_for_text/,ThomasAger,1518246305,[removed],0,1
431,2018-2-10,2018,2,10,16,7wk3y5,Are you a machine learning enthusiast? DO YOU KNOW THIS?,https://www.reddit.com/r/MachineLearning/comments/7wk3y5/are_you_a_machine_learning_enthusiast_do_you_know/,ady_anr,1518247948,,0,1
432,2018-2-10,2018,2,10,18,7wkgd3,Testing the Correctiveness of an ML engine,https://www.reddit.com/r/MachineLearning/comments/7wkgd3/testing_the_correctiveness_of_an_ml_engine/,el_drone,1518253679,[removed],0,1
433,2018-2-10,2018,2,10,18,7wkige,"To learn to implement ML I used a MobileNet SSD pretrained on COCO to recognize and clone objects in AR, for no real discernible purpose.",https://www.reddit.com/r/MachineLearning/comments/7wkige/to_learn_to_implement_ml_i_used_a_mobilenet_ssd/,[deleted],1518254709,[deleted],1,1
434,2018-2-10,2018,2,10,18,7wkjnq,"[P] To learn to implement ML I used a MobileNet SSD pretrained on COCO to recognize and clone objects in AR, for no real discernible purpose.",https://www.reddit.com/r/MachineLearning/comments/7wkjnq/p_to_learn_to_implement_ml_i_used_a_mobilenet_ssd/,bferns,1518255316,,10,115
435,2018-2-10,2018,2,10,19,7wkolt,Poisson and/or Markov chain?,https://www.reddit.com/r/MachineLearning/comments/7wkolt/poisson_andor_markov_chain/,ndrokky,1518257533,[removed],0,1
436,2018-2-10,2018,2,10,19,7wkqgf,Starting blogging to solidify my understanding of material. Need expert to check accuracy of my post.,https://www.reddit.com/r/MachineLearning/comments/7wkqgf/starting_blogging_to_solidify_my_understanding_of/,ikangsta,1518258414,[removed],0,1
437,2018-2-10,2018,2,10,20,7wkwbn,searching advice on creating a predictive model for eventdriven timeseries [P],https://www.reddit.com/r/MachineLearning/comments/7wkwbn/searching_advice_on_creating_a_predictive_model/,rrraoul,1518261279,"I'm working on a project where I want to predict retail turnover. My first approach has been with a simple neural network with some hidden layers, mainly done in R, in which I have some decent experience. My data consists of actual turnover (as finegrained as every hour), holidays and vacations (with every holiday in a seperate column) and some basic weatherdata like temperature. While the neural net does a decent job (with an average error of 4%), it essentially has no sense of how the pattern evolves over time. This is where I started looking into LSTM neural networks, as they seem to be exactly what I need. My questions are : 

1) are LSTM-networks actually the best approach to this problem? 
2) Most LSTMs seem to be done in TensorFlow; is TensorFlow the way to go when it comes to LSTM? I' new to TensorFlow, but reasonable skilled in languages like R, Mathematica and C# 3a) Most tutorials on timeseries with LSTMs evolve about patternrecognition, without eventdrivers that influence the pattern. Is it advisable to start with a simple LSTM and to expand this at a later point with eventdrivers? 
3b) Or is it hard to expand at a later moment and should I take the possible events into account from the start? 
3c) Any suggestions about usefull tutorials are welcome. All my data is already wrangled into tidy matrices and scaled to [0,1] with R, so it might be relatively easy to export this to a LSTM-nn?",16,6
438,2018-2-10,2018,2,10,20,7wl18i,[D]Medical QA,https://www.reddit.com/r/MachineLearning/comments/7wl18i/dmedical_qa/,godspeed_china,1518263661,"Hi All  
I crawled ~300k medical Q-A pairs in Chinese. I would like to develop some simple system to simulate a doctor.  
I tried two ideas. A: use hashing trick and tf-idf to compute the cos similarity between user's question and all questions in the dataset and return the answer of most similar questions. B: I simulated 300K fake Q-A pairs by permutation, and learn a Q-A joint model to distinguish true Q-A pairs against fake Q-A pairs.  
Both works a bit, and give me and my parents much joy.  The discussion is that can I do better to compete with real doctor? Any suggestions?  

",2,0
439,2018-2-10,2018,2,10,21,7wl2mb,Machine learning training workshop in Bangalore,https://www.reddit.com/r/MachineLearning/comments/7wl2mb/machine_learning_training_workshop_in_bangalore/,pavanear,1518264253,,0,1
440,2018-2-10,2018,2,10,22,7wlhhd,[P] Adversarial Variational Bayes in Pytorch,https://www.reddit.com/r/MachineLearning/comments/7wlhhd/p_adversarial_variational_bayes_in_pytorch/,chrisorm,1518270085,,4,29
441,2018-2-10,2018,2,10,23,7wlu6s,"Clean implementation for ""Actor Critic using Kronecker-Factored Trust Region (ACKTR)""",https://www.reddit.com/r/MachineLearning/comments/7wlu6s/clean_implementation_for_actor_critic_using/,jelly_zhang,1518274378,,0,1
442,2018-2-10,2018,2,10,23,7wluip,New course Practical Deep Learning with Keras and Python,https://www.reddit.com/r/MachineLearning/comments/7wluip/new_course_practical_deep_learning_with_keras_and/,recluzestudy,1518274488,[removed],0,1
443,2018-2-11,2018,2,11,1,7wmbki,A good explanation on regression,https://www.reddit.com/r/MachineLearning/comments/7wmbki/a_good_explanation_on_regression/,Debabrata-I,1518279384,,0,1
444,2018-2-11,2018,2,11,1,7wmeki,What is the target function in machine learning?,https://www.reddit.com/r/MachineLearning/comments/7wmeki/what_is_the_target_function_in_machine_learning/,barbarasnowinsummer,1518280224,,0,1
445,2018-2-11,2018,2,11,1,7wml1f,Small JS Machine Learning library I'm creating,https://www.reddit.com/r/MachineLearning/comments/7wml1f/small_js_machine_learning_library_im_creating/,h3cate,1518281920,,0,1
446,2018-2-11,2018,2,11,3,7wn6yb,Has someone applied to Machines ne Learning fellowship at OpenAI ?,https://www.reddit.com/r/MachineLearning/comments/7wn6yb/has_someone_applied_to_machines_ne_learning/,brunoeducrsantos,1518287377,[removed],0,1
447,2018-2-11,2018,2,11,4,7wnesw,The Untold Secret To electric air compressors In Less Than Ten Minutes,https://www.reddit.com/r/MachineLearning/comments/7wnesw/the_untold_secret_to_electric_air_compressors_in/,M_muac,1518289352,[removed],0,1
448,2018-2-11,2018,2,11,4,7wnr9c,What is working as a Machine Learning Research Engineer like ?,https://www.reddit.com/r/MachineLearning/comments/7wnr9c/what_is_working_as_a_machine_learning_research/,Zophike1,1518292495,[removed],0,1
449,2018-2-11,2018,2,11,5,7wnyhg,Learning from Hints (1992),https://www.reddit.com/r/MachineLearning/comments/7wnyhg/learning_from_hints_1992/,blueeyes44,1518294326,,0,1
450,2018-2-11,2018,2,11,5,7wo0j7,""" MorphNet: Fast &amp; Simple Resource-Constrained Structure Learning of Deep Networks"", Gordon et al 2017 {GA/GB}",https://www.reddit.com/r/MachineLearning/comments/7wo0j7/morphnet_fast_simple_resourceconstrained/,gwern,1518294858,,0,1
451,2018-2-11,2018,2,11,5,7wo5cp,Anyone have suggestions on an easy paper to read that predicts cancer status using machine learning?,https://www.reddit.com/r/MachineLearning/comments/7wo5cp/anyone_have_suggestions_on_an_easy_paper_to_read/,immunobio,1518296103,[removed],0,1
452,2018-2-11,2018,2,11,6,7wohjz,How to talk about my computer vision and sensor fusion projects when applying to machine learning jobs?,https://www.reddit.com/r/MachineLearning/comments/7wohjz/how_to_talk_about_my_computer_vision_and_sensor/,AutomaticParticular,1518299369,[removed],0,1
453,2018-2-11,2018,2,11,7,7wotau,Imposter,https://www.reddit.com/r/MachineLearning/comments/7wotau/imposter/,Pondy1103,1518302569,[removed],0,1
454,2018-2-11,2018,2,11,8,7woxt7,"Take a fully trained ReLU net. Replace the activation function with max(0, x). Does it still perform fine?",https://www.reddit.com/r/MachineLearning/comments/7woxt7/take_a_fully_trained_relu_net_replace_the/,[deleted],1518303786,,0,1
455,2018-2-11,2018,2,11,8,7wp5y5,[P] Productizing ML Models with Google Cloud Dataflow,https://www.reddit.com/r/MachineLearning/comments/7wp5y5/p_productizing_ml_models_with_google_cloud/,[deleted],1518306036,[deleted],0,0
456,2018-2-11,2018,2,11,9,7wpax5,"[D] Take a fully trained ReLU net. Replace the activation function with max(0, x). Does it still perform fine?",https://www.reddit.com/r/MachineLearning/comments/7wpax5/d_take_a_fully_trained_relu_net_replace_the/,vel0ciratpor,1518307426,"(Obviously it's not possible to train with a discontinuous activation function, but that's not an issue for evaluation.)


**Edit:** I got my terms mixed up. I meant softplus everywhere I said ReLU.",8,0
457,2018-2-11,2018,2,11,9,7wpd7n,"[Discussion] Is there any work in ""stacking"" networks? For example, transfer learning but with an entire network trained for a new task on top.",https://www.reddit.com/r/MachineLearning/comments/7wpd7n/discussion_is_there_any_work_in_stacking_networks/,steezyone,1518308060,"I have not been able to find any research on combining networks.  An example of this could be using a pretrained image classification network and cutting the top few layers off (as in transfer learning) then using that as an input to a network to be trained to play a game with unsupervised learning.  I would speculate that the new combined network would not have to learn all the feature extraction used for images and could train faster as it would only need to understand the high level image features and how they relate to its goal.  

Is there any research anyone can point me to on this?  Or, is there any reason this would not work?  ",12,7
458,2018-2-11,2018,2,11,11,7wq2f4,Adapting computer vision projects to be relevant for machine learning for ads,https://www.reddit.com/r/MachineLearning/comments/7wq2f4/adapting_computer_vision_projects_to_be_relevant/,[deleted],1518315474,,0,1
459,2018-2-11,2018,2,11,11,7wq4ag,Adapting computer vision projects to ad machine learning jobs,https://www.reddit.com/r/MachineLearning/comments/7wq4ag/adapting_computer_vision_projects_to_ad_machine/,[deleted],1518316072,,0,1
460,2018-2-11,2018,2,11,11,7wq6az,[D] Adapting computer vision projects to machine learning jobs for ads,https://www.reddit.com/r/MachineLearning/comments/7wq6az/d_adapting_computer_vision_projects_to_machine/,ChemicalPalpitation,1518316710,"Recently I had my first job interview for a machine learning position. It didn't go well and I was rejected thirty minutes after the interview took place. I talked about some of my projects and how I improved them and issues I faces. But some of the issue didn't seem to be relevant to machine learning for ads. For example, I was detecting lane lines and choosing a good color space for the transform that would detect the lanes under low light, bright light, etc. When training my car to drive around a track, I added additional data in the areas that the car was having trouble and then retrained my model. I also used a model from a paper but it was too complex and had too many layers so I removed two of the layers in my model. I also used Extended Kalman Filters for determining the path. But EKF seem really not relevant for ads. 


I've also done some NLP projects although my other projects are more recent. Should I perhaps focus more on those projects? Or try to talk more about things I've done that could be applied to other areas such as classification and classifying objects such as cars, pedestrians? Or maybe talk about things I've noticed in products I've used that could be improved. For example, when searching for jeans when I've been logged in, I've been shown only jeans for the opposite gender. In that case, it would be good to take gender into account and if the results aren't good then this seems to be similar to my car failing to drive around the curve. So in the case, I added additional data driving around the curve. In their case, I imagine it would be something similar where they add more training data for women's clothing.


None of my personal projects are ad based. Should I be thinking about ad based machine learning if applying to those type of jobs? It seems like there are more ad machine learning jobs or nlp machine learning jobs than computer vision machine learning jobs.


I'm wondering how to adapt my project experience to other types of machine learning?",4,6
461,2018-2-11,2018,2,11,12,7wqfhs,Can I Learn Multi-Class Classification with Single Class labeled data?,https://www.reddit.com/r/MachineLearning/comments/7wqfhs/can_i_learn_multiclass_classification_with_single/,throwaway775849,1518319561,[removed],0,1
462,2018-2-11,2018,2,11,13,7wquxv,[R] Going Deeper in Spiking Neural Networks: VGG and Residual Architectures,https://www.reddit.com/r/MachineLearning/comments/7wquxv/r_going_deeper_in_spiking_neural_networks_vgg_and/,hardmaru,1518324882,,9,39
463,2018-2-11,2018,2,11,14,7wqyp0,What a GPU is really for...,https://www.reddit.com/r/MachineLearning/comments/7wqyp0/what_a_gpu_is_really_for/,watty_dude,1518326205,,0,1
464,2018-2-11,2018,2,11,14,7wr35f,[P] Introduction to Learning to Trade with Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/7wr35f/p_introduction_to_learning_to_trade_with/,baylearn,1518327796,,27,117
465,2018-2-11,2018,2,11,20,7wsab5,DensePose Explained,https://www.reddit.com/r/MachineLearning/comments/7wsab5/densepose_explained/,funmaster11,1518347823,,0,1
466,2018-2-11,2018,2,11,20,7wsbi1,Paper on Colorisation of B/W photos using Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/7wsbi1/paper_on_colorisation_of_bw_photos_using/,rjmessibarca,1518348476,[removed],0,1
467,2018-2-11,2018,2,11,21,7wsio8,Sequence Labeling / Tagging Tasks in Natural Language Processing (NLP),https://www.reddit.com/r/MachineLearning/comments/7wsio8/sequence_labeling_tagging_tasks_in_natural/,trtm,1518351964,[removed],0,1
468,2018-2-11,2018,2,11,22,7wsnry,Coconut Oil Expeller Machine Manufacturer|Cocoa Oil Extraction Equipment Price,https://www.reddit.com/r/MachineLearning/comments/7wsnry/coconut_oil_expeller_machine_manufacturercocoa/,gelserena,1518354077,,1,1
469,2018-2-11,2018,2,11,22,7wsp4m,What do you think is the most promising AI-focused Blockchain project on the market at the moment?,https://www.reddit.com/r/MachineLearning/comments/7wsp4m/what_do_you_think_is_the_most_promising_aifocused/,KryptoKramer,1518354610,[removed],0,1
470,2018-2-11,2018,2,11,22,7wst07,"[D] Study Guides for Interview at AI Research Company (OpenAI, DeepMind, Google Brain, etc.). Can anyone add to my list?",https://www.reddit.com/r/MachineLearning/comments/7wst07/d_study_guides_for_interview_at_ai_research/,five4three2,1518356143,[removed],6,1
471,2018-2-11,2018,2,11,23,7wt47t,[R] A Survey Of Methods For Explaining Black Box Models,https://www.reddit.com/r/MachineLearning/comments/7wt47t/r_a_survey_of_methods_for_explaining_black_box/,ThomasAger,1518360076,,1,16
472,2018-2-12,2018,2,12,1,7wtnxv,[R] Machine Learning Top 10 Articles (v.Feb 2018),https://www.reddit.com/r/MachineLearning/comments/7wtnxv/r_machine_learning_top_10_articles_vfeb_2018/,mmeartine,1518366015,,15,275
473,2018-2-12,2018,2,12,1,7wtqol,Is there any PILCO code available in Python?,https://www.reddit.com/r/MachineLearning/comments/7wtqol/is_there_any_pilco_code_available_in_python/,kanakkabara,1518366783,[removed],0,1
474,2018-2-12,2018,2,12,1,7wtu9n,[D] Unsupervised Keywords from Customers Reviews at Amazon and PlayStore,https://www.reddit.com/r/MachineLearning/comments/7wtu9n/d_unsupervised_keywords_from_customers_reviews_at/,sksq9,1518367766,"Hello,
 
- Recently I noticed Amazon.com and Google PlayStore implemented a feature to [filter customer reviews based on certain keywords](https://imgur.com/a/CLjrm) along with a [percentage score](https://imgur.com/a/1VhzX). 
- These keywords are unique to each product, thereby I believe they are generated in an unsupervised fashion.
- Anyone has ideas how are these keywords and scores generated? Simple word count, tf-idf? Unsupervised vector embedding, Word2Vec, FastText? Topic modeling?

Any pointers is appreciated.

Thanks!",4,8
475,2018-2-12,2018,2,12,2,7wu02h,"Lecture notes on Bayesian deep learning (including measure theory, random signal theory, functional analysis, Gaussian processes, and uncertainty in deep learning)",https://www.reddit.com/r/MachineLearning/comments/7wu02h/lecture_notes_on_bayesian_deep_learning_including/,samchoi7,1518369246,,0,1
476,2018-2-12,2018,2,12,2,7wu2p5,stainless steel deburring tool,https://www.reddit.com/r/MachineLearning/comments/7wu2p5/stainless_steel_deburring_tool/,wsiukweb,1518369910,,0,1
477,2018-2-12,2018,2,12,2,7wu3v9,Why use two gates in GRUs?,https://www.reddit.com/r/MachineLearning/comments/7wu3v9/why_use_two_gates_in_grus/,jshin49,1518370192,[removed],0,1
478,2018-2-12,2018,2,12,2,7wu3vq,New Pluralsight Course - Deep Learning: The Big Picture,https://www.reddit.com/r/MachineLearning/comments/7wu3vq/new_pluralsight_course_deep_learning_the_big/,hoekrb,1518370194,,0,1
479,2018-2-12,2018,2,12,2,7wu5fg,[D] I like to apply for ML/AI research positions but usually one of the requirements is having publication in a top-tier ML/AI conference. How serious is this requirement? Is there any chance for someone like me?,https://www.reddit.com/r/MachineLearning/comments/7wu5fg/d_i_like_to_apply_for_mlai_research_positions_but/,kingadenorf,1518370578,"I am a senior PhD student (computer engineering) and my field of research is not related to AI/ML. However, I have some background in ML mostly by taking courses during MSc and taking online courses.  I like to be a researcher in AI/ML, but interesting job postings are asking for publication in this field, and depending on the company they even mention top-tier ones like CVPR, NIPS, etc. 

I think I did a decent work in my PhD and published my work but it is not ML/AI related. Is there any chance for a person like me? How serious is this requirement? I really appreciate if you share your experience with me. ",8,0
480,2018-2-12,2018,2,12,3,7wufgw,Which activation function to use in neural networks?,https://www.reddit.com/r/MachineLearning/comments/7wufgw/which_activation_function_to_use_in_neural/,yashuseth,1518373024,,1,1
481,2018-2-12,2018,2,12,3,7wunka,[D] How do you pick a research topic?,https://www.reddit.com/r/MachineLearning/comments/7wunka/d_how_do_you_pick_a_research_topic/,roar363,1518374995,"Hi. For those of us not in grad school/MS/PhD, how should one go about choosing a research topic? Once area of interest is identified (say computer vision), what should be next the steps? I am talking about a choosing a good enough research topic that can be later presented in good conferences/journals etc",7,0
482,2018-2-12,2018,2,12,4,7wuwmq,[R] Online Learning: A Comprehensive Survey,https://www.reddit.com/r/MachineLearning/comments/7wuwmq/r_online_learning_a_comprehensive_survey/,satsatsat,1518377219,,0,22
483,2018-2-12,2018,2,12,5,7wvduf,Using 'useless features',https://www.reddit.com/r/MachineLearning/comments/7wvduf/using_useless_features/,ADGEfficiency,1518381449,[removed],0,1
484,2018-2-12,2018,2,12,5,7wvfvt,Porting Cleverhans to Pytorch,https://www.reddit.com/r/MachineLearning/comments/7wvfvt/porting_cleverhans_to_pytorch/,[deleted],1518381934,,0,1
485,2018-2-12,2018,2,12,6,7wvjfk,[D] Machine Learning - WAYR (What Are You Reading) - Week 42,https://www.reddit.com/r/MachineLearning/comments/7wvjfk/d_machine_learning_wayr_what_are_you_reading_week/,ML_WAYR_bot,1518382807,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|31-40|41-50|
|----|-----|-----|-----|-----|
|[Week 1](https://www.reddit.com/r/MachineLearning/comments/4qyjiq/machine_learning_wayr_what_are_you_reading_week_1/)|[Week 11](https://www.reddit.com/r/MachineLearning/comments/57xw56/discussion_machine_learning_wayr_what_are_you/)|[Week 21](https://www.reddit.com/r/MachineLearning/comments/60ildf/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 31](https://www.reddit.com/r/MachineLearning/comments/6s0k1u/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 41](https://www.reddit.com/r/MachineLearning/comments/7tn2ax/d_machine_learning_wayr_what_are_you_reading_week/)|||
|[Week 2](https://www.reddit.com/r/MachineLearning/comments/4s2xqm/machine_learning_wayr_what_are_you_reading_week_2/)|[Week 12](https://www.reddit.com/r/MachineLearning/comments/5acb1t/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 22](https://www.reddit.com/r/MachineLearning/comments/64jwde/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 32](https://www.reddit.com/r/MachineLearning/comments/72ab5y/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 3](https://www.reddit.com/r/MachineLearning/comments/4t7mqm/machine_learning_wayr_what_are_you_reading_week_3/)|[Week 13](https://www.reddit.com/r/MachineLearning/comments/5cwfb6/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 23](https://www.reddit.com/r/MachineLearning/comments/674331/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 33](https://www.reddit.com/r/MachineLearning/comments/75405d/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 4](https://www.reddit.com/r/MachineLearning/comments/4ub2kw/machine_learning_wayr_what_are_you_reading_week_4/)|[Week 14](https://www.reddit.com/r/MachineLearning/comments/5fc5mh/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 24](https://www.reddit.com/r/MachineLearning/comments/68hhhb/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 34](https://www.reddit.com/r/MachineLearning/comments/782js9/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 5](https://www.reddit.com/r/MachineLearning/comments/4xomf7/machine_learning_wayr_what_are_you_reading_week_5/)|[Week 15](https://www.reddit.com/r/MachineLearning/comments/5hy4ur/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 25](https://www.reddit.com/r/MachineLearning/comments/69teiz/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 35](https://www.reddit.com/r/MachineLearning/comments/7b0av0/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 6](https://www.reddit.com/r/MachineLearning/comments/4zcyvk/machine_learning_wayr_what_are_you_reading_week_6/)|[Week 16](https://www.reddit.com/r/MachineLearning/comments/5kd6vd/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 26](https://www.reddit.com/r/MachineLearning/comments/6d7nb1/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 36](https://www.reddit.com/r/MachineLearning/comments/7e3fx6/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 7](https://www.reddit.com/r/MachineLearning/comments/52t6mo/machine_learning_wayr_what_are_you_reading_week_7/)|[Week 17](https://www.reddit.com/r/MachineLearning/comments/5ob7dx/discussion_machine_learning_wayr_what_are_you/)|[Week 27](https://www.reddit.com/r/MachineLearning/comments/6gngwc/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 37](https://www.reddit.com/r/MachineLearning/comments/7hcc2c/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 8](https://www.reddit.com/r/MachineLearning/comments/53heol/machine_learning_wayr_what_are_you_reading_week_8/)|[Week 18](https://www.reddit.com/r/MachineLearning/comments/5r14yd/discussion_machine_learning_wayr_what_are_you/)|[Week 28](https://www.reddit.com/r/MachineLearning/comments/6jgdva/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 38](https://www.reddit.com/r/MachineLearning/comments/7kgcqr/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 9](https://www.reddit.com/r/MachineLearning/comments/54kvsu/machine_learning_wayr_what_are_you_reading_week_9/)|[Week 19](https://www.reddit.com/r/MachineLearning/comments/5tt9cz/discussion_machine_learning_wayr_what_are_you/)|[Week 29](https://www.reddit.com/r/MachineLearning/comments/6m9l1v/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 39](https://www.reddit.com/r/MachineLearning/comments/7nayri/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 10](https://www.reddit.com/r/MachineLearning/comments/56s2oa/discussion_machine_learning_wayr_what_are_you/)|[Week 20](https://www.reddit.com/r/MachineLearning/comments/5wh2wb/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 30](https://www.reddit.com/r/MachineLearning/comments/6p3ha7/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 40](https://www.reddit.com/r/MachineLearning/comments/7qel9p/d_machine_learning_wayr_what_are_you_reading_week/)||

Most upvoted papers two weeks ago:

/u/rrmuller: [Bayesian Learning via Stochastic Gradient Langevin Dynamics](https://www.ics.uci.edu/~welling/publications/papers/stoclangevin_v6.pdf)

/u/quick_dudley: [Entity Embeddings of Categorical Variables](https://arxiv.org/abs/1604.06737)

Besides that, there are no rules, have fun.",1,11
486,2018-2-12,2018,2,12,6,7wvw8v,[D] Porting Cleverhans to Pytorch,https://www.reddit.com/r/MachineLearning/comments/7wvw8v/d_porting_cleverhans_to_pytorch/,alexmlamb,1518385937,"Is anyone planning to port Cleverhans to Pytorch (or something more or less equivalent to this)?

At least covering the basic attacks like FGSM and PGD shouldn't be that difficult.
",3,3
487,2018-2-12,2018,2,12,7,7wwahg,What is a Good Master's Degree in Data Science for an SLP ?,https://www.reddit.com/r/MachineLearning/comments/7wwahg/what_is_a_good_masters_degree_in_data_science_for/,Nyd3r,1518389545,[removed],0,1
488,2018-2-12,2018,2,12,9,7wwses,IntegratedGradients to explain predictions made by deep learning classification models,https://www.reddit.com/r/MachineLearning/comments/7wwses/integratedgradients_to_explain_predictions_made/,MWatson,1518394226,[removed],0,1
489,2018-2-12,2018,2,12,9,7wwu4e,Do ICML reviewers frown upon a dual submission to the ICLR workshop track?,https://www.reddit.com/r/MachineLearning/comments/7wwu4e/do_icml_reviewers_frown_upon_a_dual_submission_to/,[deleted],1518394665,,0,1
490,2018-2-12,2018,2,12,9,7wwwzd,[D] Do ICML reviewers frown upon a dual submission to the ICLR workshop track?,https://www.reddit.com/r/MachineLearning/comments/7wwwzd/d_do_icml_reviewers_frown_upon_a_dual_submission/,kjaksdfjkweq,1518395427,,2,4
491,2018-2-12,2018,2,12,9,7wwx46,Machine Learning Super Mario World Livestream,https://www.reddit.com/r/MachineLearning/comments/7wwx46/machine_learning_super_mario_world_livestream/,Briggtion,1518395460,,0,1
492,2018-2-12,2018,2,12,9,7wx3c4,[P] Why is machine learning in finance so hard?,https://www.reddit.com/r/MachineLearning/comments/7wx3c4/p_why_is_machine_learning_in_finance_so_hard/,hardikp,1518397169,,90,93
493,2018-2-12,2018,2,12,10,7wxdbw,[R] Efficient Neural Architecture Search via Parameters Sharing | Google Brain,https://www.reddit.com/r/MachineLearning/comments/7wxdbw/r_efficient_neural_architecture_search_via/,xternalz,1518400043,,3,16
494,2018-2-12,2018,2,12,11,7wxmch,The MNIST of time series datasets?,https://www.reddit.com/r/MachineLearning/comments/7wxmch/the_mnist_of_time_series_datasets/,LatePlenty,1518402583,[removed],0,1
495,2018-2-12,2018,2,12,11,7wxrbe,How to combat Pixel Attacks against CNNs,https://www.reddit.com/r/MachineLearning/comments/7wxrbe/how_to_combat_pixel_attacks_against_cnns/,jbrambledc,1518403989,[removed],0,1
496,2018-2-12,2018,2,12,13,7wy9c0,"Japanese VPS provider Sakura Internet has discontinued their TITAN GPU service because of NVIDIA DC EULA, has surrendered waving a 'white flag'..",https://www.reddit.com/r/MachineLearning/comments/7wy9c0/japanese_vps_provider_sakura_internet_has/,binblack,1518409457,,0,1
497,2018-2-12,2018,2,12,13,7wyfn4,Seeking advice on merging physical models and data-driven models for optimization,https://www.reddit.com/r/MachineLearning/comments/7wyfn4/seeking_advice_on_merging_physical_models_and/,Fadama,1518411483,[removed],0,1
498,2018-2-12,2018,2,12,15,7wyuue,Nvidia DevBox questions,https://www.reddit.com/r/MachineLearning/comments/7wyuue/nvidia_devbox_questions/,bfeeny,1518416393,[removed],0,1
499,2018-2-12,2018,2,12,15,7wyz2o,Simplest Introduction To Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7wyz2o/simplest_introduction_to_machine_learning/,amitshekhariitbhu,1518417911,,0,1
500,2018-2-12,2018,2,12,15,7wyzwg,Machine learning to Mimic Snapchat Filters,https://www.reddit.com/r/MachineLearning/comments/7wyzwg/machine_learning_to_mimic_snapchat_filters/,[deleted],1518418215,[deleted],0,1
501,2018-2-12,2018,2,12,15,7wz0xg,[D]Project involving GANs and Natural Language,https://www.reddit.com/r/MachineLearning/comments/7wz0xg/dproject_involving_gans_and_natural_language/,satyen_wham96,1518418639,"Masters Student here! As part of a course, I have to do a deep learning project. I am really excited about GANs(I just know the basics, still have to read more in depth) and believe that combining language aspect would be a real cool thing. Would love to know your ideas!

Some things that I thought of/googled:
Text to Image synthesis- (https://github.com/reedscot/icml2016) user types in image description and image is generated. 

Text to video generation- (https://arxiv.org/abs/1710.00421) user types in video description and a short video is generated.

Text to lip sync- User types in text and a random person will say the text with accurate lip movement. Something like ObamaNet (http://ritheshkumar.com/obamanet/) but instead of Obama, we could try to model the User itself. (User would have to upload a short video)",4,8
502,2018-2-12,2018,2,12,16,7wz1zg,[D] Machine learning to mimic snapchat filters,https://www.reddit.com/r/MachineLearning/comments/7wz1zg/d_machine_learning_to_mimic_snapchat_filters/,scfortune,1518419022,,2,1
503,2018-2-12,2018,2,12,16,7wz9rv,Scikit-learn code sample for outlier detection for high dimensional data,https://www.reddit.com/r/MachineLearning/comments/7wz9rv/scikitlearn_code_sample_for_outlier_detection_for/,mrdanibudapest,1518422203,[removed],0,1
504,2018-2-12,2018,2,12,17,7wzgio,[D] Application of machine learning to neuroscience time series data,https://www.reddit.com/r/MachineLearning/comments/7wzgio/d_application_of_machine_learning_to_neuroscience/,alanorw,1518425107,"Hi all, has anyone experience with applications of machine learning to analyze neural time series data? I.e. electrophysiology or calcium imaging. Do you know of any good resources for these things, for instance predicting neural responses for cell classification, population analysis etc. I am a neuroscientist of training and new to ML. ",13,5
505,2018-2-12,2018,2,12,19,7wzsgl,Build 5 Projects in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7wzsgl/build_5_projects_in_machine_learning/,ciaracodes,1518430136,,0,1
506,2018-2-12,2018,2,12,19,7wzsju,Updates on Microsoft AI Residency,https://www.reddit.com/r/MachineLearning/comments/7wzsju/updates_on_microsoft_ai_residency/,kivtir,1518430163,[removed],5,1
507,2018-2-12,2018,2,12,19,7wzup3,[D] List of Neural Network Attacks,https://www.reddit.com/r/MachineLearning/comments/7wzup3/d_list_of_neural_network_attacks/,PavKon,1518431045,"I am working on automated testing platform for neural networks and I would like to know what kinds of attacks you would like to see automated?
So far, the list is tiny with 
- Adversarial Attacks
- One pixel attack
- Dataset poisoning

Please help to expand this list, any attack to this list is appreciated.",6,32
508,2018-2-12,2018,2,12,19,7wzuv7,Unsupervised word sense disambiguation in dynamic semantic spaces,https://www.reddit.com/r/MachineLearning/comments/7wzuv7/unsupervised_word_sense_disambiguation_in_dynamic/,CaHoop,1518431109,,0,1
509,2018-2-12,2018,2,12,19,7wzxog,Machine Learning in Practice at DMI,https://www.reddit.com/r/MachineLearning/comments/7wzxog/machine_learning_in_practice_at_dmi/,DMI2002,1518432278,,1,1
510,2018-2-12,2018,2,12,20,7x038g,[P] Identify tactical Soccer Scenes based on Tracking Data - Approaches?,https://www.reddit.com/r/MachineLearning/comments/7x038g/p_identify_tactical_soccer_scenes_based_on/,fruityfrucht,1518434446,"Hi there, 

for a university project I want to analyze soccer tracking data. The input of the system will be 5-10 scenes which describe a certain, not yet defined,  technical maneuver (play through the center, ...). The model should return similar scenes in other matches.

All is based on tracking data. It includes x,y coordinates of each player and the ball every 40ms of a game (frame). Flags like ball possession and a few others are also included.

Since I'm not super deep into machine learning but got a general understanding I just wanted to verify my idea of a possible approach and maybe get a few tips.

Situation:  
* Tracking data of multiple (100-500) games  
* Input: 5-10 example scenes (tracking data, no video)  
* Output:  similar scenes on new tracking data  

Since I don't have classified data I want to use unsupervised learning to cluster (pre defined) scenes of a game and query with the given examples to get similar scenes from the model.  

Approach in my head:  
* Slice all the games in scenes (300-500 scenes per halftime)  
* Aggregate the given example scenes into one   
* Query model with aggregated scene  

In my opinion, the most challenging task will be to find appropriate features. Since I only have theoretical knowledge of ML from university, it would be great to know if this would work in reality. I would appreciate hints to promising tools/libraries (sci kit learn, tensorflow, ..) or algorithms which I should look into

",6,6
511,2018-2-12,2018,2,12,21,7x0dnh,Video: What is the significance of digitalization within materials science? Chris Eberl Fraunhofer IWM,https://www.reddit.com/r/MachineLearning/comments/7x0dnh/video_what_is_the_significance_of_digitalization/,Erik_Feder,1518438278,,0,1
512,2018-2-12,2018,2,12,21,7x0dzt,Submitting papers under double-blind review to arxiv?,https://www.reddit.com/r/MachineLearning/comments/7x0dzt/submitting_papers_under_doubleblind_review_to/,deeceeo,1518438405,[removed],0,1
513,2018-2-12,2018,2,12,21,7x0epm,[R]Machine Learning: An Introduction,https://www.reddit.com/r/MachineLearning/comments/7x0epm/rmachine_learning_an_introduction/,chris_shpak,1518438650,,0,1
514,2018-2-12,2018,2,12,21,7x0fht,Advise on deep learning for stock prediction?,https://www.reddit.com/r/MachineLearning/comments/7x0fht/advise_on_deep_learning_for_stock_prediction/,crowoy,1518438908,[removed],0,1
515,2018-2-12,2018,2,12,21,7x0i6t,A Gentle Introduction to Matrix Operations for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7x0i6t/a_gentle_introduction_to_matrix_operations_for/,trumtra,1518439780,,0,1
516,2018-2-12,2018,2,12,22,7x0l03,Networks that learn Hierarchies?,https://www.reddit.com/r/MachineLearning/comments/7x0l03/networks_that_learn_hierarchies/,Mondestrasz,1518440672,[removed],0,1
517,2018-2-12,2018,2,12,22,7x0srb,Challenging images for minds and machines,https://www.reddit.com/r/MachineLearning/comments/7x0srb/challenging_images_for_minds_and_machines/,[deleted],1518443015,[deleted],0,1
518,2018-2-12,2018,2,12,22,7x0tkr,Teach Machine to Trade [code included],https://www.reddit.com/r/MachineLearning/comments/7x0tkr/teach_machine_to_trade_code_included/,psnr,1518443250,,0,1
519,2018-2-12,2018,2,12,22,7x0vlj,[Research] challenging images for minds and machines,https://www.reddit.com/r/MachineLearning/comments/7x0vlj/research_challenging_images_for_minds_and_machines/,AmirRosenfeld,1518443843,"Putting this here for discussion. 

https://openreview.net/forum?id=rkc8OJt8f
",0,2
520,2018-2-12,2018,2,12,23,7x0yls,[D] Google Cloud TPU accelerators now available in beta to train machine learning models,https://www.reddit.com/r/MachineLearning/comments/7x0yls/d_google_cloud_tpu_accelerators_now_available_in/,sksq9,1518444661,,36,164
521,2018-2-12,2018,2,12,23,7x0zwx,[D] GitHub - tensorflow/tpu,https://www.reddit.com/r/MachineLearning/comments/7x0zwx/d_github_tensorflowtpu/,sksq9,1518445009,,1,7
522,2018-2-12,2018,2,12,23,7x151e,How to find CVs to use as training data for my project?,https://www.reddit.com/r/MachineLearning/comments/7x151e/how_to_find_cvs_to_use_as_training_data_for_my/,MSameem,1518446384,[removed],0,1
523,2018-2-13,2018,2,13,0,7x1hnc,[N] Microsoft Releases MMLSpark v0.11 for Multi-GPU Distributed Training of Deep Networks,https://www.reddit.com/r/MachineLearning/comments/7x1hnc/n_microsoft_releases_mmlspark_v011_for_multigpu/,mhamilton723,1518449512,,1,19
524,2018-2-13,2018,2,13,0,7x1m7a,[P] Hi r/MachineLearning! We (University of Waterloo Researchers) need your help learning about how multidisciplinary STEM teams assess expertise.,https://www.reddit.com/r/MachineLearning/comments/7x1m7a/p_hi_rmachinelearning_we_university_of_waterloo/,watscicomm,1518450593,"Were looking for researchers involved in multidisciplinary Science, Technology, Engineering, and Math (STEM) collaborations to help us understand how you figure out if someone is an expert. Some examples of such teams include computer scientists working with biologists, civil engineers collaborating with health professionals in disaster preparedness, or the kind of work youd find in NSF IGERT programs. Our research is part of a project called Networked Expertise in Multidisciplinary STEM Collaboration, that is being conducted by Dr. Ashley Rose Mehlenbacher at the University of Waterloo in Canada. We want to know how you identify experts outside your own area of research so we can better prepare students for working across disciplines. All that participants need to do is fill out an online survey that takes, on average, about 8 minutes (https://uwaterloo.ca1.qualtrics.com/jfe/form/SV_ehYHYHT74LebscB), and then have a brief interview with one of the members of the Networked Expertise team (which can take place via Skype/Hangouts/teleconference). This study has been reviewed and received ethics clearance through a University of Waterloo Research Ethics Committee. Please feel free to share this link with anyone you think has something important to say about assessing expertise in multidisciplinary STEM teams!",1,7
525,2018-2-13,2018,2,13,0,7x1mmr,[D] ML and Business Process Management: What kinds of applications are you seeing?,https://www.reddit.com/r/MachineLearning/comments/7x1mmr/d_ml_and_business_process_management_what_kinds/,flipster6,1518450719,"Hi everyone! I am a budding Data Scientist with a passion for data and a number of Udemy course hours under my belt, so most concepts are familiar to me, but I do not have a post-graduate degree on the subject. I work for a business process management software company which is starting to explore Machine Learning as a way to help our customers gain more insights from their data.

A little history... My company's flagship product is a framework for companies to create forms and design workflows that integrate with other enterprise systems all to automate or ""orchestrate"" processes to help reduce wait times for things like employee onboarding, case management, bankruptcy filings, manufacturing, IT service desk ticket resolution, and the like. I've spoken with a number of business users who have told me that the longer they use our product, the more critical the data becomes.

We currently have solutions for some basic analytics, such as how many times a certain form had been submitted and how long fulfillment usually takes. We also integrate with other BI tools for customers to see the data in other ways, but this is our first foray into ML.

Right now, I have an account with Azure Machine Learning Studio and I've created a couple of basic models: one uses basic linear regression to calculate the estimated time to complete fulfillment of ordering office supplies which I trained using 100 different combinations of historical responses and completion times (in days), and another uses logistic regression to calculate the likelihood of that same office supply ordering form of getting approved by a manager, which takes into account things like cost, who the supply ultimately goes to, etc.

I wanted to poll the audience to see what kinds of applications of ML you are seeing in the business world in a Business Process Management context. Even just a high-level summary would be fantastic! Related: how much adoption of MLaaS (Azure, Amazon Sagemaker, etc.) are you seeing in the business world and do you see that growing?

The examples I gave above came from a few hours of brainstorming with my development team, but our product handles a vast array of data, and no two clients use our framework for the exact same purpose. Literally anything could be fair game!

Thank you in advance!",3,0
526,2018-2-13,2018,2,13,1,7x1y3h,[P] Convolution visualizer,https://www.reddit.com/r/MachineLearning/comments/7x1y3h/p_convolution_visualizer/,ezyang,1518453299,,24,57
527,2018-2-13,2018,2,13,1,7x20n7,Understanding Few-shot intelligence as a Meta-Learning Problem,https://www.reddit.com/r/MachineLearning/comments/7x20n7/understanding_fewshot_intelligence_as_a/,sachinrjoglekar,1518453864,,0,1
528,2018-2-13,2018,2,13,1,7x23n7,"How I Shipped a Neural Network on iOS with CoreML, PyTorch, and React Native",https://www.reddit.com/r/MachineLearning/comments/7x23n7/how_i_shipped_a_neural_network_on_ios_with_coreml/,steadicat,1518454502,,0,1
529,2018-2-13,2018,2,13,3,7x2wte,"This Tangled Web  Intelligence, Technology and Fiction",https://www.reddit.com/r/MachineLearning/comments/7x2wte/this_tangled_web_intelligence_technology_and/,parabas,1518460780,,0,1
530,2018-2-13,2018,2,13,4,7x35cc,Machine Learning with R and TensorFlow | J.J. Allaire's (Rstudio's CEO) keynote at rstudio::conf 2018 on the R interface to TensorFlow,https://www.reddit.com/r/MachineLearning/comments/7x35cc/machine_learning_with_r_and_tensorflow_jj/,TroyHernandez,1518462635,,0,2
531,2018-2-13,2018,2,13,5,7x3npw,A tutorial on my machine-learning workflow for predicting whether or not this post will be popular!,https://www.reddit.com/r/MachineLearning/comments/7x3npw/a_tutorial_on_my_machinelearning_workflow_for/,W1zK1dd,1518466662,,0,1
532,2018-2-13,2018,2,13,5,7x3nyy,Andrew Ng shares what folks at Stanford University are doing in AI &amp; Healthcare.,https://www.reddit.com/r/MachineLearning/comments/7x3nyy/andrew_ng_shares_what_folks_at_stanford/,vishwanathjha,1518466722,,0,2
533,2018-2-13,2018,2,13,5,7x3twv,"Real-World, Man-Machine Algorithms",https://www.reddit.com/r/MachineLearning/comments/7x3twv/realworld_manmachine_algorithms/,thyateira,1518468037,,0,1
534,2018-2-13,2018,2,13,6,7x42jy,Mxnet in R - Can't get classification output to work,https://www.reddit.com/r/MachineLearning/comments/7x42jy/mxnet_in_r_cant_get_classification_output_to_work/,The_Sodomeister,1518469983,[removed],0,1
535,2018-2-13,2018,2,13,6,7x43yc,[D] VGG/RESNET Equivalent for Videos,https://www.reddit.com/r/MachineLearning/comments/7x43yc/d_vggresnet_equivalent_for_videos/,ShivamDuggal4,1518470279,"I want to implement VGG-like model on videos, i.e rather than operating on one image at a time, convolve on a stack of images at one go. So, my doubts are: 
* What should be the size of conv3d filters.
* Should I keep Padding= ""SAME"", and if yes does this append a black image at the end and the start?
* Should I apply pooling across depth or not i.e should I use MAX_POOL_3D or MAX_POOL_2D
",4,6
536,2018-2-13,2018,2,13,6,7x452s,Deep Learning: Going Deeper toward Meaningful Patterns in Complex Data,https://www.reddit.com/r/MachineLearning/comments/7x452s/deep_learning_going_deeper_toward_meaningful/,jchrszcz,1518470534,,0,1
537,2018-2-13,2018,2,13,6,7x47g8,[D] Deep Learning Course | EPFL,https://www.reddit.com/r/MachineLearning/comments/7x47g8/d_deep_learning_course_epfl/,sksq9,1518471046,,7,153
538,2018-2-13,2018,2,13,6,7x492y,"[P] TensorFlow implementation of ""Simple Does It: Weakly Supervised Instance and Semantic Segmentation"", by Khoreva et al. (CVPR 2017).",https://www.reddit.com/r/MachineLearning/comments/7x492y/p_tensorflow_implementation_of_simple_does_it/,tezcaML,1518471406,"The repo at https://github.com/philferriere/tfwss contains a TensorFlow implementation of weakly supervised instance segmentation as described in ""Simple Does It: Weakly Supervised Instance and Semantic Segmentation"", by Khoreva et al. (CVPR 2017) (https://arxiv.org/abs/1603.07485).

The idea behind weakly supervised segmentation is to train a model using cheap-to-generate label approximations (e.g., bounding boxes) as substitute/guiding labels for computer vision classification tasks that usually require very detailed labels.

This work was done as a contribution to the Monday evening meetup of the Deep Learning Study Group from Silicon Valley Hands On Programming Events (https://www.meetup.com/HandsOnProgrammingEvents) hosted by Mike Bowles. Newcomers and additional contributions (semantic segmentation? Grabcut+?) welcome!",2,9
539,2018-2-13,2018,2,13,6,7x4cqg,Deep Learning: Going Deeper toward Meaningful Patterns in Complex Data,https://www.reddit.com/r/MachineLearning/comments/7x4cqg/deep_learning_going_deeper_toward_meaningful/,ritwik_g,1518472254,,0,1
540,2018-2-13,2018,2,13,6,7x4e70,[D][P] Batch normalization for N-dimensional tensor,https://www.reddit.com/r/MachineLearning/comments/7x4e70/dp_batch_normalization_for_ndimensional_tensor/,shamitlal,1518472600,"Is applying batchnorm on an N-dimensional tensor equivalent to reshaping the N-dimensional tensor to an N-1 - dimensional tensor, applying batchnorm on it, and then reshaping the resultant tensor back to N-dimensions?",1,1
541,2018-2-13,2018,2,13,7,7x4gf2,[R] Onsets and Frames: Dual-Objective Piano Transcription,https://www.reddit.com/r/MachineLearning/comments/7x4gf2/r_onsets_and_frames_dualobjective_piano/,chisai_mikan,1518473116,,12,17
542,2018-2-13,2018,2,13,7,7x4pii,[P] Reproducing DIIN neural architecture for Natural Language Inference + code in Keras (ICLR 2018 Reproducibility Challenge),https://www.reddit.com/r/MachineLearning/comments/7x4pii/p_reproducing_diin_neural_architecture_for/,HrantKhachatrian,1518475236,,0,9
543,2018-2-13,2018,2,13,8,7x50t9,Googles TPU Chip Goes Public in Challenge to Nvidias GPU,https://www.reddit.com/r/MachineLearning/comments/7x50t9/googles_tpu_chip_goes_public_in_challenge_to/,gwen0927,1518477924,,0,1
544,2018-2-13,2018,2,13,8,7x58c8,A Moth Brain Learns to Read MNIST,https://www.reddit.com/r/MachineLearning/comments/7x58c8/a_moth_brain_learns_to_read_mnist/,Codeunter,1518479808,,8,3
545,2018-2-13,2018,2,13,10,7x5uy3,"Evolutionary algorithms, neural networks and autoencoders",https://www.reddit.com/r/MachineLearning/comments/7x5uy3/evolutionary_algorithms_neural_networks_and/,torfra,1518485631,[removed],0,1
546,2018-2-13,2018,2,13,10,7x5y6p,Theoretical upper bound on the number of nodes for linear separability in MLPs,https://www.reddit.com/r/MachineLearning/comments/7x5y6p/theoretical_upper_bound_on_the_number_of_nodes/,[deleted],1518486513,[deleted],0,1
547,2018-2-13,2018,2,13,10,7x5yb5,Theoretical upper bound on the number of MLP nodes for linear separability,https://www.reddit.com/r/MachineLearning/comments/7x5yb5/theoretical_upper_bound_on_the_number_of_mlp/,[deleted],1518486549,[deleted],0,1
548,2018-2-13,2018,2,13,11,7x65oc,[P] What does the error surface look like during dropout?,https://www.reddit.com/r/MachineLearning/comments/7x65oc/p_what_does_the_error_surface_look_like_during/,[deleted],1518488537,[deleted],0,1
549,2018-2-13,2018,2,13,13,7x6yl7,find particularly frequently purchased items under certain condition with customer purchasing history using a machine learning,https://www.reddit.com/r/MachineLearning/comments/7x6yl7/find_particularly_frequently_purchased_items/,boram8235,1518496753,[removed],0,1
550,2018-2-13,2018,2,13,13,7x72h6,[D] Why Reset Gate in GRU?,https://www.reddit.com/r/MachineLearning/comments/7x72h6/d_why_reset_gate_in_gru/,steeveHuang,1518497954,"Why do we need a reset gate in Gated Recurrent Units (GRU)? Can't update gate do all the jobs? For instance, if we want to forget all the stuff coming from the past, we can simply set the update gate to be 1. So why do we need a reset gate in GRU?",3,3
551,2018-2-13,2018,2,13,13,7x72i2,[D] Where do you keep your training data?,https://www.reddit.com/r/MachineLearning/comments/7x72i2/d_where_do_you_keep_your_training_data/,iamwil,1518497962,"I know it depends largely on the domain that you're working on. Image tasks will probably be a directory of images, and audio tasks will probably be a directory of audio. But if you have structured data, do you keep it all in CSVs, or do you try to dump it into a database first? I don't see any real reason to have it in a database, since we get the training data in chunks of rows anyway, unless it was already provided as a database already?

How many of you work off of some CSV/HDF5 file and how many suck it down from a database?",15,1
552,2018-2-13,2018,2,13,14,7x759i,[P] Micromachine.AI: Teach an AI how to drive in C#,https://www.reddit.com/r/MachineLearning/comments/7x759i/p_micromachineai_teach_an_ai_how_to_drive_in_c/,cbovar,1518498765,,2,2
553,2018-2-13,2018,2,13,14,7x772j,Speech recognition is not solved,https://www.reddit.com/r/MachineLearning/comments/7x772j/speech_recognition_is_not_solved/,alexeyr,1518499293,,0,1
554,2018-2-13,2018,2,13,15,7x7ge4,Urgent Need AR database link or login and password plzz,https://www.reddit.com/r/MachineLearning/comments/7x7ge4/urgent_need_ar_database_link_or_login_and/,chandu_,1518502257,[removed],0,1
555,2018-2-13,2018,2,13,16,7x7s6q,[R] UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction,https://www.reddit.com/r/MachineLearning/comments/7x7s6q/r_umap_uniform_manifold_approximation_and/,arisbw,1518506630,,22,34
556,2018-2-13,2018,2,13,16,7x7ujr,Facebook AI Residency,https://www.reddit.com/r/MachineLearning/comments/7x7ujr/facebook_ai_residency/,KloppOnThruTheRain,1518507608,[removed],0,1
557,2018-2-13,2018,2,13,19,7x8k1w,Deep Learning  In demand subset of Machine Learning | NewTechDojo,https://www.reddit.com/r/MachineLearning/comments/7x8k1w/deep_learning_in_demand_subset_of_machine/,yodalearning,1518518265,[removed],0,1
558,2018-2-13,2018,2,13,19,7x8ksg,"[D] How do you do ""supervised clustering"" of image segments?",https://www.reddit.com/r/MachineLearning/comments/7x8ksg/d_how_do_you_do_supervised_clustering_of_image/,hatero,1518518552,"My description of the problem will most likely be unclear, so please bear with me.

Given an image and some bounding boxes, I would like to group these bounding boxes, based on the content of the bounding boxes.

For example given an image of a table with tableware, I would like to put the fork/knive/plate/etc. belonging to the same spot/person into one group. Thus the total number of groups depend on the the number of spots/person per image.

How do you do this in a supervised fashion?",5,1
559,2018-2-13,2018,2,13,20,7x8nv6,Pretrained Model Collection with tutorials on how to use them,https://www.reddit.com/r/MachineLearning/comments/7x8nv6/pretrained_model_collection_with_tutorials_on_how/,harshsikka123,1518519816,,0,1
560,2018-2-13,2018,2,13,20,7x8o2l,Looking for books and resources to steer me in the right direction,https://www.reddit.com/r/MachineLearning/comments/7x8o2l/looking_for_books_and_resources_to_steer_me_in/,turing_test3,1518519893,[removed],0,1
561,2018-2-13,2018,2,13,20,7x8or2,ot able to get prediction for Keras model for imdb data,https://www.reddit.com/r/MachineLearning/comments/7x8or2/ot_able_to_get_prediction_for_keras_model_for/,dk1709,1518520157,[removed],0,1
562,2018-2-13,2018,2,13,20,7x8sob,[D][Repost] Anyone heard from MILA MSc/PhD application?,https://www.reddit.com/r/MachineLearning/comments/7x8sob/drepost_anyone_heard_from_mila_mscphd_application/,3129381,1518521642,,19,4
563,2018-2-13,2018,2,13,20,7x8ve2,[P] Globally and Locally Consistent Image Completion,https://www.reddit.com/r/MachineLearning/comments/7x8ve2/p_globally_and_locally_consistent_image_completion/,_sshin_,1518522686,,37,285
564,2018-2-13,2018,2,13,21,7x8wsy,Has someone tried TPU on Google cloud ? Is it worth it ?,https://www.reddit.com/r/MachineLearning/comments/7x8wsy/has_someone_tried_tpu_on_google_cloud_is_it_worth/,ai_dl,1518523226,[removed],0,1
565,2018-2-13,2018,2,13,21,7x8zab,What is the current state of art in text classification?,https://www.reddit.com/r/MachineLearning/comments/7x8zab/what_is_the_current_state_of_art_in_text/,winchester6788,1518524112,[removed],0,1
566,2018-2-13,2018,2,13,21,7x94qn,[R] Google HDR+ photography dataset,https://www.reddit.com/r/MachineLearning/comments/7x94qn/r_google_hdr_photography_dataset/,mgwizdala,1518525968,,4,15
567,2018-2-13,2018,2,13,22,7x99jf,[R] Automatic Learning Rate Scheduling That Really Works,https://www.reddit.com/r/MachineLearning/comments/7x99jf/r_automatic_learning_rate_scheduling_that_really/,davis685,1518527395,,35,62
568,2018-2-13,2018,2,13,22,7x9a4d,Failure to replicate Schwartz-Ziv and Tishby,https://www.reddit.com/r/MachineLearning/comments/7x9a4d/failure_to_replicate_schwartzziv_and_tishby/,ajschumacher,1518527553,,0,1
569,2018-2-13,2018,2,13,22,7x9aox,[R] Graph Classification with 2D Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/7x9aox/r_graph_classification_with_2d_convolutional/,visarga,1518527730,,4,3
570,2018-2-13,2018,2,13,22,7x9c9c,"[R] Winner's Curse? On Pace, Progress, and Empirical Rigor &lt;-- the future of incentive structures in ML Research",https://www.reddit.com/r/MachineLearning/comments/7x9c9c/r_winners_curse_on_pace_progress_and_empirical/,evc123,1518528207,,11,25
571,2018-2-13,2018,2,13,23,7x9p4i,Arm announces 3 TOPs/W ML processor,https://www.reddit.com/r/MachineLearning/comments/7x9p4i/arm_announces_3_topsw_ml_processor/,moconnor,1518531805,,0,1
572,2018-2-13,2018,2,13,23,7x9q1n,[D] Wasserstein Distance Doubts,https://www.reddit.com/r/MachineLearning/comments/7x9q1n/d_wasserstein_distance_doubts/,ShivamDuggal4,1518532050,"Hi, I have the following doubts concerning the Wasserstein distance:

* How is earth-movers distance calculated for probability distributions.
* Why is infinum in Earth-movers distance intractable. Is it because trying out all possible joint probabilities is complexity wise impossible.
* In Example1 in the https://arxiv.org/pdf/1701.07875.pdf, Wasserstein distance is not differentiable at theta=0, also Wasserstein distance is said to be ""almost"" differentiable. So, does it not harm choosing it as the loss function. 
* Why do we replace the difference between (x,y) in EM-distance by the difference in Lipschitz function?  How does the problem become tractable by doing so?",4,4
573,2018-2-13,2018,2,13,23,7x9qba,Question/Answering datasets for Virtual Assistant/Chatbots,https://www.reddit.com/r/MachineLearning/comments/7x9qba/questionanswering_datasets_for_virtual/,__Julia,1518532129,[removed],0,1
574,2018-2-13,2018,2,13,23,7x9u8w,Whitepaper: Supply Chain Trends + Machine Learning: A Match Made in Heaven - Innovecs,https://www.reddit.com/r/MachineLearning/comments/7x9u8w/whitepaper_supply_chain_trends_machine_learning_a/,innovecs,1518533163,,0,1
575,2018-2-14,2018,2,14,0,7xa0im,"Sentiment Analysis: Concept, Analysis and Applications - by Shashank Gupta",https://www.reddit.com/r/MachineLearning/comments/7xa0im/sentiment_analysis_concept_analysis_and/,Fewthp,1518534691,,0,1
576,2018-2-14,2018,2,14,0,7xa14d,Brilliant paper on how to minimise Technical Debt in Machine Learning Projects,https://www.reddit.com/r/MachineLearning/comments/7xa14d/brilliant_paper_on_how_to_minimise_technical_debt/,MLOpt,1518534854,,1,1
577,2018-2-14,2018,2,14,0,7xa3ao,linux kali,https://www.reddit.com/r/MachineLearning/comments/7xa3ao/linux_kali/,orenog,1518535400,[removed],0,1
578,2018-2-14,2018,2,14,0,7xa3l7,[D] How do you guys find interesting papers?,https://www.reddit.com/r/MachineLearning/comments/7xa3l7/d_how_do_you_guys_find_interesting_papers/,its_ya_boi_dazed,1518535462,I see a bunch of neat and interesting papers that get posted on here but I have a hard time finding papers like that. What tools/techniques do you guys use?,17,18
579,2018-2-14,2018,2,14,0,7xa5xf,[D] linux kali,https://www.reddit.com/r/MachineLearning/comments/7xa5xf/d_linux_kali/,orenog,1518536010,"I am a hacker, so I'm used to use linux kali, I use it on a virtual machine, but now I want to install linux on my SSD so it would be able to use my GPU, will linux kali be good enough for tensorflow and machine learning stuff?

",16,0
580,2018-2-14,2018,2,14,2,7xazvh,Variational Fair Autoencoder (https://arxiv.org/pdf/1511.00830.pdf),https://www.reddit.com/r/MachineLearning/comments/7xazvh/variational_fair_autoencoder/,happygoofball,1518542808,[removed],0,1
581,2018-2-14,2018,2,14,3,7xbcty,ICLR 2018 papers sorted by their score,https://www.reddit.com/r/MachineLearning/comments/7xbcty/iclr_2018_papers_sorted_by_their_score/,ai_dl,1518545671,,0,1
582,2018-2-14,2018,2,14,4,7xbpo4,Word alignment task vs dictionary induction,https://www.reddit.com/r/MachineLearning/comments/7xbpo4/word_alignment_task_vs_dictionary_induction/,krishnapriya22,1518548426,,0,1
583,2018-2-14,2018,2,14,4,7xbyhv,ML for transport efficiency,https://www.reddit.com/r/MachineLearning/comments/7xbyhv/ml_for_transport_efficiency/,ArcadeBit,1518550344,[removed],0,1
584,2018-2-14,2018,2,14,4,7xc1r5,[R] ML for transport efficiency,https://www.reddit.com/r/MachineLearning/comments/7xc1r5/r_ml_for_transport_efficiency/,ArcadeBit,1518551040,"Hello,

I saw this video: https://www.youtube.com/watch?v=y3qfeoqErtY

All in all it is about how the gloabe shipping network works. The data (airports, aircraft, fuel consumption, sorting times and geography to name but a few) are huge.

Is it possible to put this data into a machine learning program and calculate the most efficient method?

It may also be possible to go so far, that the delivery services cooperate with each other.

In the final step, you could then take the technologies like Hyperloop with you.

Would this be possible?

Translated with www.DeepL.com/Translator",2,0
585,2018-2-14,2018,2,14,5,7xceel,[D] Training a binary classifier (XGBClassifier) using probabilities instead of just 0 and 1 with the intent of measuring predict_proba() to show where on a scale of 0 to 1 a prediction occurs (versus training a multi class classifier),https://www.reddit.com/r/MachineLearning/comments/7xceel/d_training_a_binary_classifier_xgbclassifier/,oxmpbeta,1518553829,"Hello,

Sorry if the title seems a little roundabout, but let me explain what I'm trying to do.  I'm training a XGBClassifier (in python) on samples that aren't strictly in the class of 0 and 1, but range anywhere from [0, 1], [.25, .75], [.5 .5], [.75, .25], [1, 0].  For example, for measuring sentiment less in terms of ""negative or positive"" but ""25% positive 75% negative"" using predict_proba().

I'm trying to figure out what the best way to do this is.  I know the base class of the XGBClassifier is binary:logistic, and I might try this also using multi:softmax, but I like the idea of using the predict_proba() between 0 and 1 as a measure of where a sample falls on a scale between class A and class B (or really, between 0 and 1) which would be more difficult using 5 separate ""classes."" 

(For the following example, I'm using the letters A and B but really mean 0 and 1.  It's just less confusing this way.)

My first inclination is to force classification probabilities by using ratios of A and B in the training set for each sample, essentially sending each one through four times with different classifications-- but I'm not sure if there's an easier way or if it's doing what I think it is.  

For example-- if I have a sample that I want to represent as [.5, .5] so basically, a 50/50 or ""neutral"" sentiment (so that other samples I sent through later come out around [.5, .5], I'd train it four times with a value of A and four times with a value of B.  Then for something that should be classified as [0, 1], we train it eight times with a value of 1, and for something that is [.75, .25], we'd train it six times with a value of 0 and two times with a value of 1.

Here's how I'd train each sample then, where ""B B B B"" would mean I train the same sample four times telling the classifier it is B, etc:

[0.00, 1.00]: B B B B
[0.25, 0.75]: A B B B
[0.50, 0.50]: A A B B
[0.75, 0.25]: A A A B
[1.00, 0.00] :A A A A

So-- barring this approach being incorrect, is there a better way to go about what I'm trying to do?  Like an analog for predict_proba() but for training inputs?  Knowing how the algorithm works i don't think that exists, but then again, I'm here to be schooled.

Thanks everybody.

",9,1
586,2018-2-14,2018,2,14,5,7xcgpl,A very interesting problem in computer vision,https://www.reddit.com/r/MachineLearning/comments/7xcgpl/a_very_interesting_problem_in_computer_vision/,gkballa,1518554346,[removed],0,1
587,2018-2-14,2018,2,14,5,7xcjt5,Euro Truck Simulator Machine learning?,https://www.reddit.com/r/MachineLearning/comments/7xcjt5/euro_truck_simulator_machine_learning/,CEsmonde,1518555028,[removed],0,1
588,2018-2-14,2018,2,14,6,7xcrjy,"Have GPUs, but no knowledge of ML... how do I proceed?",https://www.reddit.com/r/MachineLearning/comments/7xcrjy/have_gpus_but_no_knowledge_of_ml_how_do_i_proceed/,[deleted],1518556769,,0,1
589,2018-2-14,2018,2,14,6,7xcryr,[N] ARM Announces Project Trillium Machine Learning IPs,https://www.reddit.com/r/MachineLearning/comments/7xcryr/n_arm_announces_project_trillium_machine_learning/,kgbounce,1518556873,,0,12
590,2018-2-14,2018,2,14,6,7xcsf8,Isn't Stochastic Gradient Descent a Monte Carlo estimation?,https://www.reddit.com/r/MachineLearning/comments/7xcsf8/isnt_stochastic_gradient_descent_a_monte_carlo/,activatedgeek,1518556974,[removed],0,1
591,2018-2-14,2018,2,14,7,7xd5cn,[D] How do you fully exploit large dataset during SGD schedule ?,https://www.reddit.com/r/MachineLearning/comments/7xd5cn/d_how_do_you_fully_exploit_large_dataset_during/,Jean-Porte,1518559921,"Assume you have ~50 millions data points
What's the best way to schedule SGD with such data size ?

I think the best learning rate decrease schedule is achieved by looking at validation loss

But if an epoch is many iterations, if the learning rate is not very low at the beginning (eg. 0.01), the loss will start to increase during the first epoch

If I look at validation loss several times during the first epoch, I might decrease the learning rate rapidly and not reap all the benefit from the large data size

I know the answer is cross validation but it's hard with such costly experiments

How do you schedule learning rate with many examples ?",2,1
592,2018-2-14,2018,2,14,7,7xddpw,[D] Question about reinforcement learning,https://www.reddit.com/r/MachineLearning/comments/7xddpw/d_question_about_reinforcement_learning/,CSMSLab,1518561901,"Most presentations of reinforcement learning stress some reward or regret to maximize and minimize. Is there a subtopic where there isnt a distinct reward, but were interested instead in some global notions of learning? For example, we have an a priori unknown response function, and instead of selecting which points to query in order to find some optimum of the function, were just interested in learning the function as a whole? I apologize if this question is naive - my understanding is focused on a very niche area in Bayesian Optimization, so I dont have a good sense of reinforcement or active learning as a whole.",9,2
593,2018-2-14,2018,2,14,7,7xdg98,Approximate Nearest Neighbors Benchmarks,https://www.reddit.com/r/MachineLearning/comments/7xdg98/approximate_nearest_neighbors_benchmarks/,[deleted],1518562525,,0,1
594,2018-2-14,2018,2,14,8,7xdiud,[R] Approximate Nearest Neighbors Benchmark,https://www.reddit.com/r/MachineLearning/comments/7xdiud/r_approximate_nearest_neighbors_benchmark/,BrotherBobwhite,1518563127,"I'm doing some research in k Approximate Nearest Neighbors (k-ANN), and I'm finding some competing claims in a couple of recent papers. **The discrepancy is in regards to the time it takes to build a k-ANN data structure for SIFT features.**

In their ANN-Benchmark tests, Aumuller et al. claim [here](http://www.itu.dk/people/pagh/SSS/ann-benchmarks/sift-data_10_-1_sift-query_euclidean.html) that the optimized [FLANN](http://www.cs.ubc.ca/research/flann/) algorithm builds a data structure markedly slower than any other (for a given recall).

Meanwhile, Li et al. claim in their (slightly older) paper [here](https://arxiv.org/pdf/1610.02455.pdf) that FLANN builds one to two orders of magnitude faster than almost any other algorithm they tested.

I'm unsure about what might account for this discrepancy. I do have some thoughts:

1. They're slightly different metrics. Aumuller et al. measure build time relative to recall, where Li et al focus on raw time.
2. The authors use different methods. Aumuller et al. require that an algorithm has a wrapper through which to call the actual FLANN routines, and so introduce some overhead. Li et al. actually seem to work on the FLANN library (along with all the others) in order to standardize their interface
3. They don't actually disagree. Using the build time/recall measure given by Aumuller et al., FLANN ranks quite low. Li et al. ranked FLANN at 5^th in recall and 4^th in build time (out of 14 total), which seems to suggest above-average performance, but many of the other algorithms they tried ranked highly in one and low in the other.

I'm wondering if anyone has any experience with k-ANN data structures or can back up/refute either claim.",2,2
595,2018-2-14,2018,2,14,8,7xdkkw,VGG16 Network for Cifar-10 Database,https://www.reddit.com/r/MachineLearning/comments/7xdkkw/vgg16_network_for_cifar10_database/,VHQN,1518563559,[removed],0,1
596,2018-2-14,2018,2,14,8,7xdmhv,"[P] Code for the paper ""AmbientGAN: Generative models from lossy measurements""",https://www.reddit.com/r/MachineLearning/comments/7xdmhv/p_code_for_the_paper_ambientgan_generative_models/,ashish_bora,1518564042,,0,26
597,2018-2-14,2018,2,14,8,7xdov5,[D] Trouble with generating speech without teacher forcing (TTS),https://www.reddit.com/r/MachineLearning/comments/7xdov5/d_trouble_with_generating_speech_without_teacher/,Powlerbare,1518564656,"I am training a TTS model very similar to samplernn and am having trouble generating samples that sound nice without teacher forcing.

So far the only effort I have made is to try to insert noise into the samples that go into the decoder (the autoregressive mlp at the bottom, and the rnn's in the layers above it). I have also trimmed for silence. I have played w softmax temperature to some degree and am not having much luck getting anything other than some pops and static or just full on noise.

Do I need professor forcing? Are there easier ways?

Should I pretend like this is car talk and describe the noise of my samples so you can diagnose my model. It is kind of like this... ""pop.......poppopopop...pop...popopop""

https://www.cartalk.com/player5/player.php?a=shortclip&amp;id=local-cartalk-851180
",2,5
598,2018-2-14,2018,2,14,8,7xdrs1,Deep Learning Meets DSP: OFDM Signal Detection,https://www.reddit.com/r/MachineLearning/comments/7xdrs1/deep_learning_meets_dsp_ofdm_signal_detection/,k3blu3,1518565420,,0,1
599,2018-2-14,2018,2,14,9,7xdygx,"[N]Arm Launches Project Trillium, Two AI Processors",https://www.reddit.com/r/MachineLearning/comments/7xdygx/narm_launches_project_trillium_two_ai_processors/,trcytony,1518567126,,0,56
600,2018-2-14,2018,2,14,9,7xe1xg,"Boston Dynamics Robodog Opens a Door, Owns the Internet",https://www.reddit.com/r/MachineLearning/comments/7xe1xg/boston_dynamics_robodog_opens_a_door_owns_the/,gwen0927,1518567965,,0,1
601,2018-2-14,2018,2,14,10,7xelz6,[R] Neural Relational Inference for Interacting Systems,https://www.reddit.com/r/MachineLearning/comments/7xelz6/r_neural_relational_inference_for_interacting/,xternalz,1518573253,,0,4
602,2018-2-14,2018,2,14,11,7xeos1,[R] Deepmind - Efficient Multi-Task Deep RL,https://www.reddit.com/r/MachineLearning/comments/7xeos1/r_deepmind_efficient_multitask_deep_rl/,alamano,1518574021,,7,27
603,2018-2-14,2018,2,14,11,7xeve3,State of the art on text classification &amp; some study advice,https://www.reddit.com/r/MachineLearning/comments/7xeve3/state_of_the_art_on_text_classification_some/,cap87_,1518575875,[removed],0,1
604,2018-2-14,2018,2,14,12,7xf8l1,Applications of Machine Learning to Game Development besides AI for Agents,https://www.reddit.com/r/MachineLearning/comments/7xf8l1/applications_of_machine_learning_to_game/,jirukulapati,1518579612,[removed],0,1
605,2018-2-14,2018,2,14,12,7xf8z2,Exploring Word2Vec - Word2Vec for noobs,https://www.reddit.com/r/MachineLearning/comments/7xf8z2/exploring_word2vec_word2vec_for_noobs/,sujayskumar,1518579723,,0,1
606,2018-2-14,2018,2,14,12,7xfchw,How to find the supermum of the polytopes which are interior (good) to a given set of 3D points?,https://www.reddit.com/r/MachineLearning/comments/7xfchw/how_to_find_the_supermum_of_the_polytopes_which/,melonochelo,1518580761,,0,1
607,2018-2-14,2018,2,14,13,7xfha7,"Marking Machines, Impact Press Machine Manufacturers in Faridabad",https://www.reddit.com/r/MachineLearning/comments/7xfha7/marking_machines_impact_press_machine/,shivaart63,1518582216,,0,1
608,2018-2-14,2018,2,14,13,7xfkwa,[D] What's the simplest RL task (converges quickly) that converges to good solution only when large (&gt;512) batch size is used?,https://www.reddit.com/r/MachineLearning/comments/7xfkwa/d_whats_the_simplest_rl_task_converges_quickly/,evc123,1518583357,"Also, are there any papers that compare the performance (reward per episode) on RL task(s) at different batch sizes?",2,3
609,2018-2-14,2018,2,14,13,7xfo2b,[D] Distillation using L1 Loss only?,https://www.reddit.com/r/MachineLearning/comments/7xfo2b/d_distillation_using_l1_loss_only/,[deleted],1518584342,[deleted],0,1
610,2018-2-14,2018,2,14,14,7xfq1w,"My curated list of books on R, Stats, ML, DL etc",https://www.reddit.com/r/MachineLearning/comments/7xfq1w/my_curated_list_of_books_on_r_stats_ml_dl_etc/,mr-datascientist,1518584935,,0,1
611,2018-2-14,2018,2,14,14,7xfxu9,SGD on Random Mixtures (SGDRM): Private Machine Learning under Data Breach Threats,https://www.reddit.com/r/MachineLearning/comments/7xfxu9/sgd_on_random_mixtures_sgdrm_private_machine/,[deleted],1518587465,,0,1
612,2018-2-14,2018,2,14,15,7xfzux,[R] SGD on Random Mixtures (SGDRM): Private Machine Learning under Data Breach Threats,https://www.reddit.com/r/MachineLearning/comments/7xfzux/r_sgd_on_random_mixtures_sgdrm_private_machine/,kw1jjang,1518588166,"Hi, authors here. We share our new paper on **Stochastic Gradient Descent on Random Mixtures (SGDRM)**, which is a simple way of protecting data under data breach threats. The key idea of SGDRM is simple: we run SGD algorithm on random mixtures of the training data points. With SGDRM, when a data breach occurs, only the random mixtures will be leaked, not the original dataset! The detailed mechanism of SGDRM is summarized in the figure.

https://imgur.com/a/XRuHh

We experimentally observe that SGDRM performs pretty well on general deep learning tasks such as MNIST/CIFAR10/Skin-Lesion classification. For instance, when we generate each mixture with 128 random images, we obtain 92% accuracy on MNIST, 36% accuracy on CIFAR-10, and 65% AUC on ISIC Skin Lesion dataset. Note that the baseline (SGD) performance is 99% accuracy on MNIST, 71% accuracy on CIFAR-10, and 80% AUC on ISIC Skin Lesion dataset. (Don't forget that the mixtures of 128 images look completely random to human eyes :P )

Our paper will be presented at SysML conference this week, and is currently under review for ICLR workshop as well. We also have some theoretical guarantees of SGDRM (differential privacy guarantee and convergence guarantee for linear neural networks).

If you are interested in more details, please take a look at our ICLR workshop submission (for more sample mixtures &amp; theoretical statements): https://openreview.net/forum?id=r17_wzJPM

Comments, suggestions and/or feedbacks are more than welcome!",10,5
613,2018-2-14,2018,2,14,17,7xgjib,[P] A variation on my AR experiment using a MobileNet SSD to label an object and clone multiple versions of a 3D model.,https://www.reddit.com/r/MachineLearning/comments/7xgjib/p_a_variation_on_my_ar_experiment_using_a/,bferns,1518595454,,8,50
614,2018-2-14,2018,2,14,17,7xgqfl,A moth brain learns to read MNIST,https://www.reddit.com/r/MachineLearning/comments/7xgqfl/a_moth_brain_learns_to_read_mnist/,BadGoyWithAGun,1518598390,,1,1
615,2018-2-14,2018,2,14,18,7xgxu7,[D] Curious about RL for NLP,https://www.reddit.com/r/MachineLearning/comments/7xgxu7/d_curious_about_rl_for_nlp/,notenoughram,1518601520,"Hi, I'm curios to know whether techniques from the RL (referring mostly to Deep-RL) field have been used / have started to be used for solving NLP problems.

I will appreciate any link to posts about this, or papers actually covering this.

Thanks!",13,6
616,2018-2-14,2018,2,14,19,7xh092,Build A Project In Machine Learning For FREE,https://www.reddit.com/r/MachineLearning/comments/7xh092/build_a_project_in_machine_learning_for_free/,ciaracodes,1518602582,,0,1
617,2018-2-14,2018,2,14,19,7xh2ry,Machine Learning Training Institutes in bangalore,https://www.reddit.com/r/MachineLearning/comments/7xh2ry/machine_learning_training_institutes_in_bangalore/,pavanear,1518603596,,0,1
618,2018-2-14,2018,2,14,20,7xh9ot,Suggestion journal for a deep learning application in industry,https://www.reddit.com/r/MachineLearning/comments/7xh9ot/suggestion_journal_for_a_deep_learning/,madalinaaa,1518606337,[removed],0,1
619,2018-2-14,2018,2,14,20,7xhch5,[R] [1802.03133] Batch Kalman Normalization: Towards Training Deep Neural Networks with Micro-Batches,https://www.reddit.com/r/MachineLearning/comments/7xhch5/r_180203133_batch_kalman_normalization_towards/,evc123,1518607380,,9,11
620,2018-2-14,2018,2,14,20,7xhcl8,few-shot learning with thousands of classes,https://www.reddit.com/r/MachineLearning/comments/7xhcl8/fewshot_learning_with_thousands_of_classes/,guneyf,1518607415,[removed],0,1
621,2018-2-14,2018,2,14,20,7xhh2c,Google Clips Camera Uses AI To Take Pictures When You Are Ready,https://www.reddit.com/r/MachineLearning/comments/7xhh2c/google_clips_camera_uses_ai_to_take_pictures_when/,digitalmarketingrobi,1518609146,,0,1
622,2018-2-14,2018,2,14,21,7xhk6v,Looking for a specific paper about the weights of the final layer of classifier,https://www.reddit.com/r/MachineLearning/comments/7xhk6v/looking_for_a_specific_paper_about_the_weights_of/,Pafnouti,1518610235,[removed],0,1
623,2018-2-14,2018,2,14,21,7xhmds,[P] TensorFlow for R | RStudio Blog,https://www.reddit.com/r/MachineLearning/comments/7xhmds/p_tensorflow_for_r_rstudio_blog/,pmigdal,1518610984,,35,63
624,2018-2-14,2018,2,14,21,7xhoiz,[R] Quality and Importance of Wikipedia Articles in Different Languages,https://www.reddit.com/r/MachineLearning/comments/7xhoiz/r_quality_and_importance_of_wikipedia_articles_in/,wikirank,1518611678,,0,2
625,2018-2-14,2018,2,14,22,7xhyl1,[R] Machine Learning: Validation Techniques,https://www.reddit.com/r/MachineLearning/comments/7xhyl1/r_machine_learning_validation_techniques/,molode,1518614750,,0,1
626,2018-2-14,2018,2,14,22,7xi5b5,Sky-High Salaries Are the Weapons in the AI Talent War,https://www.reddit.com/r/MachineLearning/comments/7xi5b5/skyhigh_salaries_are_the_weapons_in_the_ai_talent/,crypto-holder,1518616602,[removed],0,1
627,2018-2-14,2018,2,14,23,7xig97,[D] Question about image processing ?,https://www.reddit.com/r/MachineLearning/comments/7xig97/d_question_about_image_processing/,nikr07,1518619408,Anyone having idea on how to track advertisement pixels positions using screenshot of websites ?,3,2
628,2018-2-14,2018,2,14,23,7xihm0,Watch your model training online,https://www.reddit.com/r/MachineLearning/comments/7xihm0/watch_your_model_training_online/,iovdin,1518619757,,0,1
629,2018-2-15,2018,2,15,0,7xiv1s,[P] London PhD Network AI Symposium - Slides - Deep Learning Development Library Tutorial,https://www.reddit.com/r/MachineLearning/comments/7xiv1s/p_london_phd_network_ai_symposium_slides_deep/,zsdh123,1518622882,,1,2
630,2018-2-15,2018,2,15,0,7xiyv1,"Simple Questions Thread February 14, 2018",https://www.reddit.com/r/MachineLearning/comments/7xiyv1/simple_questions_thread_february_14_2018/,AutoModerator,1518623739,[removed],0,1
631,2018-2-15,2018,2,15,1,7xj3a4,[D] Has anyone tried applying ML to ancient maths such as the Babylonian Sexagesimal system?,https://www.reddit.com/r/MachineLearning/comments/7xj3a4/d_has_anyone_tried_applying_ml_to_ancient_maths/,Barry_McKocinner,1518624751,"Please forgive my ignorance on the ML subject but I found out about base 60 maths the other day and it made me wonder. Has anyone ever tried to teach an AI mathematics of the ancient societies?  
I hope someone here finds this interesting and gives it a go simply to see what comes of it, even if it doesn't amount to much research wise. Who knows, a fresh look at a type of thinking not used for a few thousands years might reveal really interesting findings.",5,0
632,2018-2-15,2018,2,15,1,7xj6jv,"After training an RBM, can you use the hidden layer as a hidden layer in a neural network?",https://www.reddit.com/r/MachineLearning/comments/7xj6jv/after_training_an_rbm_can_you_use_the_hidden/,Prykorr,1518625488,[removed],0,1
633,2018-2-15,2018,2,15,2,7xjjr2,[N] 10 tips for successful adoption of your machine learning products,https://www.reddit.com/r/MachineLearning/comments/7xjjr2/n_10_tips_for_successful_adoption_of_your_machine/,tellman1257,1518628325,,0,2
634,2018-2-15,2018,2,15,2,7xjnv5,"[P] interactive demo for paper ""Generative Image Inpainting with Contextual Attention""",https://www.reddit.com/r/MachineLearning/comments/7xjnv5/p_interactive_demo_for_paper_generative_image/,jiahuiyu,1518629217,,16,95
635,2018-2-15,2018,2,15,2,7xjqq9,[R] Announcing Tensor Comprehensions,https://www.reddit.com/r/MachineLearning/comments/7xjqq9/r_announcing_tensor_comprehensions/,SkiddyX,1518629860,,78,211
636,2018-2-15,2018,2,15,3,7xk0hn,[D] Deep Reinforcement Learning Doesn't Work Yet,https://www.reddit.com/r/MachineLearning/comments/7xk0hn/d_deep_reinforcement_learning_doesnt_work_yet/,Kaixhin,1518632023,,48,93
637,2018-2-15,2018,2,15,3,7xk4zh,[P] Danbooru2017: a new dataset of 2.94m anime images (1.9tb) with 77.5m tags,https://www.reddit.com/r/MachineLearning/comments/7xk4zh/p_danbooru2017_a_new_dataset_of_294m_anime_images/,gwern,1518632993,,82,69
638,2018-2-15,2018,2,15,3,7xk5un,Incredible drone with machine learning at its core,https://www.reddit.com/r/MachineLearning/comments/7xk5un/incredible_drone_with_machine_learning_at_its_core/,mnkymnk,1518633175,,0,1
639,2018-2-15,2018,2,15,3,7xk6gj,[D] Resources for Theory,https://www.reddit.com/r/MachineLearning/comments/7xk6gj/d_resources_for_theory/,jerrylessthanthree,1518633304,"Hey all,

I'm kind of a new researcher, my advisor doesn't work too much in theory but I would really like to learn a comprehensive amount of theory because I really like it, so far looking up theory has been my favorite part in reading papers. I plan to publish in ML and maybe stats journals if I'm ambitious. 

Here's what I currently know/feel comfortable with:

Mathematical Statistics at the level of Shao's book

Nonparametric Estimation at the level of Tsybakov

High Dimensional Statistics at the level of the chapters in Wainwright that are publicly available, in particular I feel decently confident in my knowledge of the theory surrounding Lasso and Compressed Sensing

Measure theoretic probability and functional analysis I feel good with. Maybe learn some more about RKHS.

What I am currently reading/working through:

Learning theory from Shalev-Shwartz and Ben-David (really fun read actually, learning theory seems super interesting but I've heard it's not too relevant anymore?)

Oracle Inequalities in Empirical Risk Minimization and Sparse Recovery Problems from Koltchinskii (this book feels super advanced, not really putting it high on priority list)

What I feel like I lack:
How much optimization do I really need to know? 

Maybe matrix analysis and numerical analysis?

Asymptotic statistics? Empirical processes?

Looking for someone who uses theory a lot in their research to give me some advice on stuff.
",6,9
640,2018-2-15,2018,2,15,4,7xkep7,Machine Learning Guidance,https://www.reddit.com/r/MachineLearning/comments/7xkep7/machine_learning_guidance/,JoanAgus,1518635066,"Hello, it is my first reddit post, so I hope I am not breaking any rule.

I have a little problem in my Machine Learning project. I am not an expert in the issue, so I don't know how to approach this problem:

I have N particles that live in a 5-D space (x,y,z,t,w). Depending on they are, they are either on one group or another, i.e. if F(x,y,z,t,x)&gt;=N they are 'blue', else they are 'red'. Therefore, I have a bunch of labelled data in a 5-D space. Now, my problem: if I now add a new coordinate, so that we now live in a 6-D space (x,y,z,t,w,q), how to predict if my particle will be 'blue' or 'red', without knowing the new fuction F'(x,y,z,t,w,q)? 
Is there a proper method/algorithm that will help me? I though of SVM but because of the addition of the new parameter, I am not sure.",4,0
641,2018-2-15,2018,2,15,4,7xkeri,ModelDepot.io : A curated list of free pretrained models and tutorials,https://www.reddit.com/r/MachineLearning/comments/7xkeri/modeldepotio_a_curated_list_of_free_pretrained/,benkitty,1518635081,,0,1
642,2018-2-15,2018,2,15,4,7xki5n,Programmable Networks Train Neural Nets Faster,https://www.reddit.com/r/MachineLearning/comments/7xki5n/programmable_networks_train_neural_nets_faster/,KeponeFactory,1518635817,,0,1
643,2018-2-15,2018,2,15,4,7xkj0a,Happy Valentine's Day! Love 'letters' generated with a neural network from Trump-loving tweets (in progress),https://www.reddit.com/r/MachineLearning/comments/7xkj0a/happy_valentines_day_love_letters_generated_with/,magicloveletters,1518636007,,0,1
644,2018-2-15,2018,2,15,4,7xklzx,[R] SHAP: A unified approach to explain the output of any machine learning model,https://www.reddit.com/r/MachineLearning/comments/7xklzx/r_shap_a_unified_approach_to_explain_the_output/,slundberg,1518636659,,8,27
645,2018-2-15,2018,2,15,4,7xkroo,"What exactly in the world is Artificial Intelligence / Machine Learning - High Performance Computing Intersection?!! I keep seeing these around, but I still have not a single idea what it is!!",https://www.reddit.com/r/MachineLearning/comments/7xkroo/what_exactly_in_the_world_is_artificial/,FarfalleCheeseRoyale,1518637936,[removed],0,1
646,2018-2-15,2018,2,15,4,7xksie,[R] Systolic CNN AcceLErator Simulator (SCALE Sim),https://www.reddit.com/r/MachineLearning/comments/7xksie/r_systolic_cnn_accelerator_simulator_scale_sim/,mttd,1518638117,,0,2
647,2018-2-15,2018,2,15,5,7xkv46,Anyone have positive experiences or recommendations for hiring offshore machine learning resources?,https://www.reddit.com/r/MachineLearning/comments/7xkv46/anyone_have_positive_experiences_or/,klausmonkey42,1518638711,[removed],0,1
648,2018-2-15,2018,2,15,5,7xl03s,What are some Machine learning beginner's project?,https://www.reddit.com/r/MachineLearning/comments/7xl03s/what_are_some_machine_learning_beginners_project/,kunalvats,1518639758,[removed],0,1
649,2018-2-15,2018,2,15,5,7xl6xc,End-to-end differentiable learning of protein structure,https://www.reddit.com/r/MachineLearning/comments/7xl6xc/endtoend_differentiable_learning_of_protein/,SuperFX,1518641319,,0,1
650,2018-2-15,2018,2,15,6,7xlgjr,[R] On Characterizing the Capacity of Neural Networks using Algebraic Topology -- William Guss Ruslan Salakhutdinov,https://www.reddit.com/r/MachineLearning/comments/7xlgjr/r_on_characterizing_the_capacity_of_neural/,MadcowD,1518643483,,6,21
651,2018-2-15,2018,2,15,6,7xlmk2,[D] Finding a paper with VAE separate latent/visualization dimensionality,https://www.reddit.com/r/MachineLearning/comments/7xlmk2/d_finding_a_paper_with_vae_separate/,1515161,1518644888,"I'm trying to remember a paper I remember stumbling across on arXiv in the last few months. I only vaguely remember the gist of it but it was about variational autoencoders and the authors had proposed a way to decouple the dimensionality of the latent layer and the visualization of the learned representation.

I think I remember them basically making the claim that with their model they could avoid only training with two dimensions in the latent layer but still extract useful 2-D latent visualizations. I am sorry the memory is vague but I only skimmed it but it recently popped back into my head. Hoping someone noticed the paper and kept a better record of it.

Thanks, r/ML.",1,4
652,2018-2-15,2018,2,15,6,7xlpbq,Multiple Timeseries Recurrent Neural Network,https://www.reddit.com/r/MachineLearning/comments/7xlpbq/multiple_timeseries_recurrent_neural_network/,Yngstr,1518645543,[removed],0,1
653,2018-2-15,2018,2,15,8,7xm92x,"Curated, Pre-trained ML Models for Transfer Learning",https://www.reddit.com/r/MachineLearning/comments/7xm92x/curated_pretrained_ml_models_for_transfer_learning/,harshsikka123,1518650309,,0,1
654,2018-2-15,2018,2,15,8,7xmekj,What are your opinions about Kaggle ?,https://www.reddit.com/r/MachineLearning/comments/7xmekj/what_are_your_opinions_about_kaggle/,stormtrooper1721,1518651759,[removed],0,1
655,2018-2-15,2018,2,15,9,7xmln2,Building a Django POST API for Face Detection using Haar Cascades,https://www.reddit.com/r/MachineLearning/comments/7xmln2/building_a_django_post_api_for_face_detection/,iamthepresident2016,1518653696,,1,1
656,2018-2-15,2018,2,15,10,7xmxtz,VAE question,https://www.reddit.com/r/MachineLearning/comments/7xmxtz/vae_question/,Hungryham,1518657028,[removed],0,1
657,2018-2-15,2018,2,15,10,7xn3wu,[Discussion] Splitting Convolutional Layers for quantization,https://www.reddit.com/r/MachineLearning/comments/7xn3wu/discussion_splitting_convolutional_layers_for/,[deleted],1518658780,[deleted],0,0
658,2018-2-15,2018,2,15,10,7xn7hc,What should be the best approach in Training Model to identify unique patients?,https://www.reddit.com/r/MachineLearning/comments/7xn7hc/what_should_be_the_best_approach_in_training/,ResponsibleFan,1518659821,[removed],0,1
659,2018-2-15,2018,2,15,11,7xn8u8,How Blockchain Will Change Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/7xn8u8/how_blockchain_will_change_artificial_intelligence/,Leaders17,1518660208,[removed],0,1
660,2018-2-15,2018,2,15,11,7xnbpr,[R] On the Blindspots of Convolutional Networks,https://www.reddit.com/r/MachineLearning/comments/7xnbpr/r_on_the_blindspots_of_convolutional_networks/,xternalz,1518661005,,4,14
661,2018-2-15,2018,2,15,11,7xnfsn,[D] How long does it take to hear back from OpenAI (job app)?,https://www.reddit.com/r/MachineLearning/comments/7xnfsn/d_how_long_does_it_take_to_hear_back_from_openai/,[deleted],1518662161,[deleted],1,0
662,2018-2-15,2018,2,15,13,7xnxll,We Need Your Input! Help Students With Data Science Research!,https://www.reddit.com/r/MachineLearning/comments/7xnxll/we_need_your_input_help_students_with_data/,Landopolis,1518667553,,0,1
663,2018-2-15,2018,2,15,13,7xo3n8,Data analytics/data science survey,https://www.reddit.com/r/MachineLearning/comments/7xo3n8/data_analyticsdata_science_survey/,locationanalytics,1518669482,[removed],0,1
664,2018-2-15,2018,2,15,15,7xokej,Should I be using Keras or tf.keras?,https://www.reddit.com/r/MachineLearning/comments/7xokej/should_i_be_using_keras_or_tfkeras/,picardythird,1518675270,[removed],0,1
665,2018-2-15,2018,2,15,15,7xonqg,[D] Next Frontiers - ML in Healthcare,https://www.reddit.com/r/MachineLearning/comments/7xonqg/d_next_frontiers_ml_in_healthcare/,OddPositive,1518676527,What are the next frontiers of Machine Learning in the Healthcare industry?,1,0
666,2018-2-15,2018,2,15,15,7xoocy,[P] We made a music video for a song generated by an LSTM,https://www.reddit.com/r/MachineLearning/comments/7xoocy/p_we_made_a_music_video_for_a_song_generated_by/,AggressiveResolution,1518676774,,2,0
667,2018-2-15,2018,2,15,17,7xp70g,[D] ML research in robotics that is not entirely focused in deep RL?,https://www.reddit.com/r/MachineLearning/comments/7xp70g/d_ml_research_in_robotics_that_is_not_entirely/,HumanTeacher,1518684760,"I'm looking for papers and researchers to follow that are applying learning to robotics, but not necessarily where the main focus is to make deep RL work for a certain task.

Stuff like this:

https://arxiv.org/pdf/1710.00489.pdf

https://arxiv.org/pdf/1702.03920.pdf

Can anyone suggest some material? Thanks",3,4
668,2018-2-15,2018,2,15,18,7xp8or,What Skills to Develop for a Career in Machine Learning??,https://www.reddit.com/r/MachineLearning/comments/7xp8or/what_skills_to_develop_for_a_career_in_machine/,pavanear,1518686185,,0,1
669,2018-2-15,2018,2,15,18,7xp8v6,[P] watch you model training online,https://www.reddit.com/r/MachineLearning/comments/7xp8v6/p_watch_you_model_training_online/,iovdin,1518686266,,9,13
670,2018-2-15,2018,2,15,18,7xpbkr,Can Artificial Intelligence be biased? The issues are not just black and white Edit,https://www.reddit.com/r/MachineLearning/comments/7xpbkr/can_artificial_intelligence_be_biased_the_issues/,mydigitalstartup_net,1518687521,,0,2
671,2018-2-15,2018,2,15,18,7xpdky,How to write a Science or Nature paper about Artificial Intelligence?,https://www.reddit.com/r/MachineLearning/comments/7xpdky/how_to_write_a_science_or_nature_paper_about/,dancingLikeLink,1518688442,[removed],0,1
672,2018-2-15,2018,2,15,19,7xpgxr,[D] Applications of modern/abstract algebra in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7xpgxr/d_applications_of_modernabstract_algebra_in/,ankurankan1,1518689808,I am planning to take a course in Abstract Algebra and am wondering if there are any applications of abstract algebra in Machine Learning. I can see that there are some applications in Computer Science but couldn't find much related to Machine Learning. ,8,9
673,2018-2-15,2018,2,15,19,7xpi2m,Transfer Learning deep issue,https://www.reddit.com/r/MachineLearning/comments/7xpi2m/transfer_learning_deep_issue/,Jennyzu88,1518690274,[removed],0,1
674,2018-2-15,2018,2,15,19,7xplsw,How do you manage huge datasets for Deep Learning?,https://www.reddit.com/r/MachineLearning/comments/7xplsw/how_do_you_manage_huge_datasets_for_deep_learning/,xristos_forokolomvos,1518691826,[removed],0,1
675,2018-2-15,2018,2,15,20,7xps2q,Is there any reason so weight features that have a hugehr correlation to the label in a neural net?,https://www.reddit.com/r/MachineLearning/comments/7xps2q/is_there_any_reason_so_weight_features_that_have/,JustinQueeber,1518694337,[removed],0,1
676,2018-2-15,2018,2,15,20,7xpswy,[D][Audio] Artificial Intelligence: Changing attitudes in your company to get the most out of AI,https://www.reddit.com/r/MachineLearning/comments/7xpswy/daudio_artificial_intelligence_changing_attitudes/,LiamBigDataDonoghue,1518694688,,0,0
677,2018-2-15,2018,2,15,20,7xpvby,Post Graduation Courses on Machine Learning AI in the US and India,https://www.reddit.com/r/MachineLearning/comments/7xpvby/post_graduation_courses_on_machine_learning_ai_in/,favouriteblog,1518695638,,2,1
678,2018-2-15,2018,2,15,21,7xpz4o,How to check accuracy of GANs?,https://www.reddit.com/r/MachineLearning/comments/7xpz4o/how_to_check_accuracy_of_gans/,param87,1518696954,[removed],0,1
679,2018-2-15,2018,2,15,21,7xq0tz,Ideas on how to train a RNN GAN?,https://www.reddit.com/r/MachineLearning/comments/7xq0tz/ideas_on_how_to_train_a_rnn_gan/,[deleted],1518697571,,0,1
680,2018-2-15,2018,2,15,21,7xq0yy,2018 Outlook: Machine Learning and Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/7xq0yy/2018_outlook_machine_learning_and_artificial/,chris_shpak,1518697622,,0,1
681,2018-2-15,2018,2,15,21,7xq4pm,[N] Introducing Datalore - an intelligent web application for machine learning,https://www.reddit.com/r/MachineLearning/comments/7xq4pm/n_introducing_datalore_an_intelligent_web/,Caos2,1518698901,,4,4
682,2018-2-15,2018,2,15,22,7xq9x0,How to use Word2Vec instead of Embedded layer in Keras LSTM (),https://www.reddit.com/r/MachineLearning/comments/7xq9x0/how_to_use_word2vec_instead_of_embedded_layer_in/,dk1709,1518700598,[removed],0,1
683,2018-2-15,2018,2,15,22,7xqakw,Explainable Artificial Intelligence (XAI) - ppt video online download,https://www.reddit.com/r/MachineLearning/comments/7xqakw/explainable_artificial_intelligence_xai_ppt_video/,itskash,1518700816,,0,1
684,2018-2-15,2018,2,15,22,7xqeth,The Information Bottleneck: Uncovering the Secret of Deep Learning?,https://www.reddit.com/r/MachineLearning/comments/7xqeth/the_information_bottleneck_uncovering_the_secret/,Justaine,1518702125,,0,1
685,2018-2-15,2018,2,15,22,7xqfpc,Any beginner's project for Machine Learning.,https://www.reddit.com/r/MachineLearning/comments/7xqfpc/any_beginners_project_for_machine_learning/,kunalvats,1518702383,[removed],1,1
686,2018-2-15,2018,2,15,22,7xqg93,"[P] Weekly Machine Learning Opensource Roundup  Feb. 15, 2018",https://www.reddit.com/r/MachineLearning/comments/7xqg93/p_weekly_machine_learning_opensource_roundup_feb/,[deleted],1518702539,[deleted],0,1
687,2018-2-15,2018,2,15,22,7xqh5n,[R] [1802.05098] DiCE: The Infinitely Differentiable Monte-Carlo Estimator,https://www.reddit.com/r/MachineLearning/comments/7xqh5n/r_180205098_dice_the_infinitely_differentiable/,_rockt,1518702814,,7,64
688,2018-2-15,2018,2,15,23,7xqj2b,[R] A Gentle Introduction to Tensors for Machine Learning with NumPy,https://www.reddit.com/r/MachineLearning/comments/7xqj2b/r_a_gentle_introduction_to_tensors_for_machine/,jackblun,1518703347,,0,1
689,2018-2-15,2018,2,15,23,7xqkif,3 Tips About Machine You Can't Afford To Miss,https://www.reddit.com/r/MachineLearning/comments/7xqkif/3_tips_about_machine_you_cant_afford_to_miss/,foishal,1518703765,,0,1
690,2018-2-15,2018,2,15,23,7xqkq8,"[N] Weekly Machine Learning Opensource Roundup  Feb. 15, 2018",https://www.reddit.com/r/MachineLearning/comments/7xqkq8/n_weekly_machine_learning_opensource_roundup_feb/,stkim1,1518703822,,0,1
691,2018-2-15,2018,2,15,23,7xqlpw,"[D] A random RBM with no training will associate random bitstring B to bitstring C where dotProduct(B,C) is slightly higher than dotProduct of 2 random bitstrings",https://www.reddit.com/r/MachineLearning/comments/7xqlpw/d_a_random_rbm_with_no_training_will_associate/,BenRayfield,1518704103,"Its the nodes that tend to be on together, so reversing it is not completely random.

This is why in contrastiveDivergence, whatever hiddenNodes a trainingVector associates to, learn positively on those (and learn negatively on what it converges to). Even a random vector gets free learning that way. A vector similar to something already learned gets it even more.",0,0
692,2018-2-15,2018,2,15,23,7xqsxu,How open source can help address AI and machine learning bias,https://www.reddit.com/r/MachineLearning/comments/7xqsxu/how_open_source_can_help_address_ai_and_machine/,mcfc_as,1518706044,,0,1
693,2018-2-16,2018,2,16,0,7xqwsx,style2vec - is one network trained or two network is trained ?,https://www.reddit.com/r/MachineLearning/comments/7xqwsx/style2vec_is_one_network_trained_or_two_network/,desi_marcos,1518707056,[removed],0,1
694,2018-2-16,2018,2,16,0,7xr4bn,Enforcing game rules in Alpha Go Zero,https://www.reddit.com/r/MachineLearning/comments/7xr4bn/enforcing_game_rules_in_alpha_go_zero/,swisri,1518708948,[removed],0,1
695,2018-2-16,2018,2,16,0,7xr5y4,Machine learning in Hydroponics,https://www.reddit.com/r/MachineLearning/comments/7xr5y4/machine_learning_in_hydroponics/,Ben_roy,1518709361,[removed],0,1
696,2018-2-16,2018,2,16,1,7xrcub,[R] Efficient model-based RL by learning a tabular representation of the environment,https://www.reddit.com/r/MachineLearning/comments/7xrcub/r_efficient_modelbased_rl_by_learning_a_tabular/,deeceeo,1518711016,,0,5
697,2018-2-16,2018,2,16,1,7xrhur,What does it take to become machine learning engineer?,https://www.reddit.com/r/MachineLearning/comments/7xrhur/what_does_it_take_to_become_machine_learning/,dzogchenn,1518712192,[removed],0,1
698,2018-2-16,2018,2,16,1,7xrlgb,"Dissecting Adam: The Sign, Magnitude and Variance of Stochastic Gradients",https://www.reddit.com/r/MachineLearning/comments/7xrlgb/dissecting_adam_the_sign_magnitude_and_variance/,[deleted],1518713016,[deleted],0,1
699,2018-2-16,2018,2,16,2,7xrqha,[R] TVM: End-to-End Optimization Stack for Deep Learning,https://www.reddit.com/r/MachineLearning/comments/7xrqha/r_tvm_endtoend_optimization_stack_for_deep/,ZihengJiang,1518714136,,7,19
700,2018-2-16,2018,2,16,2,7xrrbp,[D] Extending CNN + RL questions,https://www.reddit.com/r/MachineLearning/comments/7xrrbp/d_extending_cnn_rl_questions/,DucksHaveLowAPM,1518714327,"Hi all,  
I've been toying with the idea to learn deep reinforced learning for a while and started a project 2 months ago toying around the idea of Deep Minds Atari games. I have made some progress on the idea that there are a couple of convoluted layers that read the board and it all converges to (1, 512) layer that is an input for my QNetwork. But now I have a couple of questions on what is a correct approach to extend the input so that the picture of the current board is not the only input. If for example I would like to build a self driving car I image it would be beneficial to know the speed and wheel angle as a float rather than a picture of any of them. So how do I do that?   Do I have an additional vector of inputs (for example 20 variables) and just append it to the output of CNN? So input for my Qnetwork is 532? I see it kind of working for a small number of inputs but if I have lets say 2k inputs (because I'm flying a F16 and not driving old Volvo) I feel like I should have a couple of layers of NN that takes that 2k down to 128 - 512 and still append it to output of CNN.   
Is that a valid approach? If not why and what is the correct way of having multiple inputs to a network?
Thanks",2,6
701,2018-2-16,2018,2,16,2,7xs1hq,Simulation assisted machine learning,https://www.reddit.com/r/MachineLearning/comments/7xs1hq/simulation_assisted_machine_learning/,[deleted],1518716546,,0,1
702,2018-2-16,2018,2,16,2,7xs2ed,"[R] Dissecting Adam: The Sign, Magnitude and Variance of Stochastic Gradients",https://www.reddit.com/r/MachineLearning/comments/7xs2ed/r_dissecting_adam_the_sign_magnitude_and_variance/,TypicalChemical,1518716757,,1,14
703,2018-2-16,2018,2,16,3,7xsezy,[P] PyTorch Implementation of Seq2Seq with Torchtext,https://www.reddit.com/r/MachineLearning/comments/7xsezy/p_pytorch_implementation_of_seq2seq_with_torchtext/,mj1642,1518719551,,0,10
704,2018-2-16,2018,2,16,3,7xsl9z,[D] Accelerating I/O bound deep learning - 4x speed-up on training times,https://www.reddit.com/r/MachineLearning/comments/7xsl9z/d_accelerating_io_bound_deep_learning_4x_speedup/,henningpeters,1518720945,,8,55
705,2018-2-16,2018,2,16,4,7xsrnj,[R] Interpretable Machine Learning through Teaching,https://www.reddit.com/r/MachineLearning/comments/7xsrnj/r_interpretable_machine_learning_through_teaching/,Kaixhin,1518722379,,6,45
706,2018-2-16,2018,2,16,4,7xsy8i,Simulations for kernelized machine learning,https://www.reddit.com/r/MachineLearning/comments/7xsy8i/simulations_for_kernelized_machine_learning/,[deleted],1518723859,,0,1
707,2018-2-16,2018,2,16,4,7xt0rh,Recurrent Geometric Networks and Protein Linguistics,https://www.reddit.com/r/MachineLearning/comments/7xt0rh/recurrent_geometric_networks_and_protein/,blueeyes44,1518724449,,0,1
708,2018-2-16,2018,2,16,5,7xt9hj,"Newb Question: What does ""E"" mean here",https://www.reddit.com/r/MachineLearning/comments/7xt9hj/newb_question_what_does_e_mean_here/,Revanish,1518726375,,0,1
709,2018-2-16,2018,2,16,5,7xtfs4,[D] List of Machine Learning / Deep Learning conferences in 2018,https://www.reddit.com/r/MachineLearning/comments/7xtfs4/d_list_of_machine_learning_deep_learning/,minmidinosaur,1518727806,,3,1
710,2018-2-16,2018,2,16,5,7xth00,How to make money from machine learning/AI?,https://www.reddit.com/r/MachineLearning/comments/7xth00/how_to_make_money_from_machine_learningai/,xfocus3,1518728095,[removed],0,1
711,2018-2-16,2018,2,16,6,7xtmi0,[D] Where can I find pre-trained GANs for TensorFlow?,https://www.reddit.com/r/MachineLearning/comments/7xtmi0/d_where_can_i_find_pretrained_gans_for_tensorflow/,liorde,1518729347,"I'm finding it very hard to find online any GAN model source code which comes with pre-trained parameters. Specifically, I'm interested in image generation (from random noise input), trained on a ""challenging"" data set such as ImageNet (even if downsampled...) (I'm less interested in MNIST...)

Also, I'm wondering why is this so? So many papers appear with amazing results, and some of them share their code. Why don't they share their pre-trained models also? It would be very helpful for the community. ",13,10
712,2018-2-16,2018,2,16,6,7xtowr,[Research] Simulations for kernelized machine learning,https://www.reddit.com/r/MachineLearning/comments/7xtowr/research_simulations_for_kernelized_machine/,david_craft,1518729898,"I am about to submit this new paper on using simulations as a way to incorporate expert knowledge into machine learning, via a similarity kernel. Has anyone seen this idea before (instead of feature data -&gt; machine learning training, feature data-&gt; simulation -&gt; kernel capturing similarity between all samples -&gt; machine learning training.? I'd like to see the work and cite it if appropriate. https://www.dropbox.com/s/vgzmunkcbq0v2qy/simkernMain.pdf?dl=0 and https://www.dropbox.com/s/5uyo15xmd65l4jg/simkernAppendix.pdf?dl=0",0,5
713,2018-2-16,2018,2,16,6,7xtryc,A visualization of machine learning optimizers with the mlpack framework,https://www.reddit.com/r/MachineLearning/comments/7xtryc/a_visualization_of_machine_learning_optimizers/,[deleted],1518730616,[deleted],0,1
714,2018-2-16,2018,2,16,6,7xttnk,Anyone started using mixup succesfully?,https://www.reddit.com/r/MachineLearning/comments/7xttnk/anyone_started_using_mixup_succesfully/,Nimitz14,1518731009,[removed],0,1
715,2018-2-16,2018,2,16,6,7xtxpf,[R] Active Neural Localization,https://www.reddit.com/r/MachineLearning/comments/7xtxpf/r_active_neural_localization/,devendrachaplot,1518731962,,0,9
716,2018-2-16,2018,2,16,7,7xu19p,[Project]I am trying to train entity tagger. Which one is faster for inference CRF or Averaged Perceptron? Is there much difference in performance/speed using the same features?,https://www.reddit.com/r/MachineLearning/comments/7xu19p/projecti_am_trying_to_train_entity_tagger_which/,woahdudethatssocool,1518732797,"I am looking to create a entity tagger for medical texts using jargon from various fields. I have some proprietary data which is not much. I don't want to train a neural network because of limited data and limitations on inference speed. I am looking at Average Perceptron, Conditional Random Field and Structured SVM. Is there a comparison available on speed/accuracy for them?",1,2
717,2018-2-16,2018,2,16,7,7xu3s2,[N] deeplearn.js 0.5.0 released with major changes (TL;DR: it's more like PyTorch now),https://www.reddit.com/r/MachineLearning/comments/7xu3s2/n_deeplearnjs_050_released_with_major_changes/,carlthome,1518733385,,0,39
718,2018-2-16,2018,2,16,8,7xukyq,[D] How much detail am I supposed to say about what I did at my previous job detecting fraud?,https://www.reddit.com/r/MachineLearning/comments/7xukyq/d_how_much_detail_am_i_supposed_to_say_about_what/,AggressiveLog,1518737639,The model isn't public so I can't go into great detail about it but how could I talk about it so that they know I'm not making things up? ,2,0
719,2018-2-16,2018,2,16,9,7xuvxe,[P] A visualization of machine learning optimizers with the mlpack framework,https://www.reddit.com/r/MachineLearning/comments/7xuvxe/p_a_visualization_of_machine_learning_optimizers/,eusben,1518740459,,3,33
720,2018-2-16,2018,2,16,9,7xux3f,[R] Generating Neural Networks with Neural Networks,https://www.reddit.com/r/MachineLearning/comments/7xux3f/r_generating_neural_networks_with_neural_networks/,liorde,1518740735,,40,123
721,2018-2-16,2018,2,16,9,7xv4i2,[D] Any updates on CapsulNet?,https://www.reddit.com/r/MachineLearning/comments/7xv4i2/d_any_updates_on_capsulnet/,rbtbot,1518742712,,4,1
722,2018-2-16,2018,2,16,10,7xveot,"Machine Learning for Manufacturing, Quality Control &amp;amp; Predictive Maintenance",https://www.reddit.com/r/MachineLearning/comments/7xveot/machine_learning_for_manufacturing_quality/,jk99_datasci,1518745495,,0,1
723,2018-2-16,2018,2,16,13,7xwdf0,"""Learning to Tell Two Spirals Apart"", Lang &amp; Witbrock 1988 [shortcut connections &amp; DenseNets]",https://www.reddit.com/r/MachineLearning/comments/7xwdf0/learning_to_tell_two_spirals_apart_lang_witbrock/,gwern,1518755785,,1,1
724,2018-2-16,2018,2,16,13,7xwe3d,Any good simple to understand explanations for t-statistic?,https://www.reddit.com/r/MachineLearning/comments/7xwe3d/any_good_simple_to_understand_explanations_for/,rnm2119,1518756019,[removed],0,1
725,2018-2-16,2018,2,16,14,7xwlb5,Reddit Rewind,https://www.reddit.com/r/MachineLearning/comments/7xwlb5/reddit_rewind/,[deleted],1518758338,,0,1
726,2018-2-16,2018,2,16,14,7xwp1t,[R] [1802.05365] Deep contextualized word representations,https://www.reddit.com/r/MachineLearning/comments/7xwp1t/r_180205365_deep_contextualized_word/,cherls,1518759576,,0,6
727,2018-2-16,2018,2,16,15,7xww5z,[D] style2vec - is one network trained or two network is trained ?,https://www.reddit.com/r/MachineLearning/comments/7xww5z/d_style2vec_is_one_network_trained_or_two_network/,desi_marcos,1518762126,"https://arxiv.org/pdf/1708.04014.pdf - in this papre about style2vec

there are two models

model_1 ( vgg16) takes input image and model_2 ( vgg16) takes context image

objective_function : please check the paper

output : after full training , use the model_1 to extract styel2vec vector for any image

question_1 : is only one model trained model_1 or both model_1 and model_2 is trained towards the objective function ?",0,3
728,2018-2-16,2018,2,16,16,7xx6q1,Fuzzy cluster analysis,https://www.reddit.com/r/MachineLearning/comments/7xx6q1/fuzzy_cluster_analysis/,thaiphi,1518766149,[removed],0,1
729,2018-2-16,2018,2,16,17,7xxgvy,Non Negative Matrix Factorization: How to predict values for a new entry?,https://www.reddit.com/r/MachineLearning/comments/7xxgvy/non_negative_matrix_factorization_how_to_predict/,mlcatbot,1518770551,[removed],0,1
730,2018-2-16,2018,2,16,17,7xxipn,Looking for intresting papers/articles on Information Theory which uses deep learning tools/ideas,https://www.reddit.com/r/MachineLearning/comments/7xxipn/looking_for_intresting_papersarticles_on/,omers66,1518771349,[removed],0,1
731,2018-2-16,2018,2,16,18,7xxjvd,Would it be rational to use LSTM to control a robot trajectories ?,https://www.reddit.com/r/MachineLearning/comments/7xxjvd/would_it_be_rational_to_use_lstm_to_control_a/,UpstairsCurrency,1518771874,[removed],0,1
732,2018-2-16,2018,2,16,18,7xxm1f,Anyone hear back from Facebook AI Research (FAIR) Residency?,https://www.reddit.com/r/MachineLearning/comments/7xxm1f/anyone_hear_back_from_facebook_ai_research_fair/,[deleted],1518772824,,0,1
733,2018-2-16,2018,2,16,18,7xxng0,[D] Anyone hear back from Facebook AI Research (FAIR) Residency?,https://www.reddit.com/r/MachineLearning/comments/7xxng0/d_anyone_hear_back_from_facebook_ai_research_fair/,CleanPumpkin,1518773438,"The ""Notification of interview"" deadline is today and I haven't seen an email. Do they send rejection emails or leave you in the dark? 

Good luck to all!

https://research.fb.com/programs/facebook-ai-research-residency-program/#Important_Dates",110,5
734,2018-2-16,2018,2,16,18,7xxp7n,[Discussion] Facebook AI Residency thread,https://www.reddit.com/r/MachineLearning/comments/7xxp7n/discussion_facebook_ai_residency_thread/,[deleted],1518774231,[deleted],0,0
735,2018-2-16,2018,2,16,19,7xxxrl,IP addresses as features to build a learning algorithm to classify attacks based on the a labeled dataset.,https://www.reddit.com/r/MachineLearning/comments/7xxxrl/ip_addresses_as_features_to_build_a_learning/,hassanmok,1518777745,[removed],0,1
736,2018-2-16,2018,2,16,19,7xxzm1,Machine Learning in the Supply Chain: The Integrity and Transparency of Marketing Research - Innovecs,https://www.reddit.com/r/MachineLearning/comments/7xxzm1/machine_learning_in_the_supply_chain_the/,innovecs,1518778503,,0,1
737,2018-2-16,2018,2,16,20,7xy3de,[R] WaveGAN: Synthesizing Audio with Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/7xy3de/r_wavegan_synthesizing_audio_with_generative/,vwvwvvwwvvvwvwwv,1518779965,,32,106
738,2018-2-16,2018,2,16,20,7xy71g,3 ways humans can do PPC better than machines alone,https://www.reddit.com/r/MachineLearning/comments/7xy71g/3_ways_humans_can_do_ppc_better_than_machines/,magneticono,1518781443,,0,1
739,2018-2-16,2018,2,16,20,7xy7fl,Here are 5 Innovative Uses for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7xy7fl/here_are_5_innovative_uses_for_machine_learning/,friscotime,1518781577,,0,1
740,2018-2-16,2018,2,16,20,7xy9gq,"Bayesian Stats Conjugate Prior Cheatsheet: 404 Error, where to find?",https://www.reddit.com/r/MachineLearning/comments/7xy9gq/bayesian_stats_conjugate_prior_cheatsheet_404/,bliss_tree,1518782368,,0,1
741,2018-2-16,2018,2,16,21,7xy9ri,IT Professionals Must Adopt Machine Learning Skills,https://www.reddit.com/r/MachineLearning/comments/7xy9ri/it_professionals_must_adopt_machine_learning/,imarticus_nirmal,1518782464,,0,1
742,2018-2-16,2018,2,16,21,7xyade,Backprop Demystified in 5 minutes (quite helpful for researchers),https://www.reddit.com/r/MachineLearning/comments/7xyade/backprop_demystified_in_5_minutes_quite_helpful/,[deleted],1518782654,[deleted],0,1
743,2018-2-16,2018,2,16,21,7xycam,[Discussion] Backprop math made easy,https://www.reddit.com/r/MachineLearning/comments/7xycam/discussion_backprop_math_made_easy/,jaleyhd,1518783300,,0,0
744,2018-2-16,2018,2,16,21,7xyhok,[P] New benchmarks for approximate nearest neighbors,https://www.reddit.com/r/MachineLearning/comments/7xyhok/p_new_benchmarks_for_approximate_nearest_neighbors/,hardmaru,1518785195,,10,48
745,2018-2-16,2018,2,16,21,7xyirn,Need help estimating the GPU I need,https://www.reddit.com/r/MachineLearning/comments/7xyirn/need_help_estimating_the_gpu_i_need/,barrelrider12,1518785558,[removed],0,1
746,2018-2-16,2018,2,16,21,7xyjys,Question about sentiment analysis on Facebook,https://www.reddit.com/r/MachineLearning/comments/7xyjys/question_about_sentiment_analysis_on_facebook/,fr1d4y_,1518785933,[removed],0,1
747,2018-2-16,2018,2,16,22,7xyka5,[Research] Black-box Variational Inference for Stochastic Differential Equations,https://www.reddit.com/r/MachineLearning/comments/7xyka5/research_blackbox_variational_inference_for/,[deleted],1518786034,[deleted],0,1
748,2018-2-16,2018,2,16,22,7xyo45,Why I am not getting any replies on my new posts,https://www.reddit.com/r/MachineLearning/comments/7xyo45/why_i_am_not_getting_any_replies_on_my_new_posts/,hassanmok,1518787221,[removed],0,1
749,2018-2-16,2018,2,16,22,7xyoka,Implementation of a convolutional Variational-Autoencoder model in pytorch.,https://www.reddit.com/r/MachineLearning/comments/7xyoka/implementation_of_a_convolutional/,3amm0R,1518787369,,0,1
750,2018-2-16,2018,2,16,22,7xyr19,[D] Introduction to Recommender System. Part 2 (Adoption of Neural Network),https://www.reddit.com/r/MachineLearning/comments/7xyr19/d_introduction_to_recommender_system_part_2/,steeveHuang,1518788164,,0,2
751,2018-2-16,2018,2,16,22,7xys8q,Need yours opinions about this Blockchain project : ENDOR,https://www.reddit.com/r/MachineLearning/comments/7xys8q/need_yours_opinions_about_this_blockchain_project/,MagicNipples32,1518788541,[removed],0,1
752,2018-2-16,2018,2,16,23,7xz1xq,Best ML algo to compare signals?,https://www.reddit.com/r/MachineLearning/comments/7xz1xq/best_ml_algo_to_compare_signals/,DanErik77,1518791226,[removed],0,1
753,2018-2-17,2018,2,17,0,7xzgxw,[D] Deep Learning Demystified,https://www.reddit.com/r/MachineLearning/comments/7xzgxw/d_deep_learning_demystified/,[deleted],1518795152,[deleted],2,0
754,2018-2-17,2018,2,17,0,7xzhje,[D] Are there image datasets for which convolutional neural networks perform poorly?,https://www.reddit.com/r/MachineLearning/comments/7xzhje/d_are_there_image_datasets_for_which/,hilbertspacey,1518795292,"Convolutional neural networks (and their offshoots like ResNets) are generally state-of-the-art when it comes to computer vision. Even in areas where they are far from 100% accuracy (e.g. CIFAR-100), they still seem to beat all non-convolutional models. Are there any areas where this is not the case, or where convolutional neural networks tend to do only marginally better than other approaches?",11,21
755,2018-2-17,2018,2,17,0,7xzknc,SQL scavenger Kaggle competition,https://www.reddit.com/r/MachineLearning/comments/7xzknc/sql_scavenger_kaggle_competition/,ibrxk,1518796040,[removed],0,1
756,2018-2-17,2018,2,17,1,7xzosy,[D] Program Generation,https://www.reddit.com/r/MachineLearning/comments/7xzosy/d_program_generation/,mackie__m,1518797028,"What are good resources on getting into program generation? I'm seeing work like this - https://www.microsoft.com/en-us/research/publication/neuro-symbolic-program-synthesis-2/, and I'm wondering whether anyone has success in replicating the performance?",11,6
757,2018-2-17,2018,2,17,1,7y01fp,[P]I wrote a tutorial about Inverse Reinforcement Learning and three basic algorithms. More to follow.,https://www.reddit.com/r/MachineLearning/comments/7y01fp/pi_wrote_a_tutorial_about_inverse_reinforcement/,thinkingwires,1518799849,,7,159
758,2018-2-17,2018,2,17,1,7y01o3,Need recommendations for image data set for mealybug detection on grape leaves and berries,https://www.reddit.com/r/MachineLearning/comments/7y01o3/need_recommendations_for_image_data_set_for/,kepler10,1518799901,[removed],0,1
759,2018-2-17,2018,2,17,1,7y03ny,GOOGLE'S Automatic Machine Learning Models released,https://www.reddit.com/r/MachineLearning/comments/7y03ny/googles_automatic_machine_learning_models_released/,iamSayandeep,1518800332,,0,1
760,2018-2-17,2018,2,17,2,7y07k9,"""Missing data hinder replication of artificial intelligence studies""",https://www.reddit.com/r/MachineLearning/comments/7y07k9/missing_data_hinder_replication_of_artificial/,gwern,1518801187,,0,1
761,2018-2-17,2018,2,17,2,7y08e5,"[R] This Tangled Web  Intelligence, Technology and Fiction",https://www.reddit.com/r/MachineLearning/comments/7y08e5/r_this_tangled_web_intelligence_technology_and/,Kehler_15,1518801368,,1,0
762,2018-2-17,2018,2,17,2,7y0btr,"[D] If you were going to learn a huge breadth of machine learning (i.e. everything from NN's to time series to PGMs to clustering to.. etc) and wanted to choose a VERY small number of datasets to learn everything on, which ones would you pick?",https://www.reddit.com/r/MachineLearning/comments/7y0btr/d_if_you_were_going_to_learn_a_huge_breadth_of/,jlelonm,1518802128,"Hi r/machinelearning!

One thing that has always bugged me in my classes is that we're constantly using different data sets for everything, and I feel like it'd be illuminating if I picked a few comprehensive data set and did everything possible on each of them.

I feel like this way you could use a huge amount of techniques on one data set and see very clearly their strengths and weaknesses against each other.

What do you folks think? Or is there a good reason for changing the data set per technique?",9,0
763,2018-2-17,2018,2,17,3,7y0myz,[R] Unsupervised Learning of Depth and Ego-Motion from Monocular Video Using 3D Geometric Constraints,https://www.reddit.com/r/MachineLearning/comments/7y0myz/r_unsupervised_learning_of_depth_and_egomotion/,andreasblixt,1518804533,,6,9
764,2018-2-17,2018,2,17,4,7y11m7,AI Weekly 16 Feb 2018,https://www.reddit.com/r/MachineLearning/comments/7y11m7/ai_weekly_16_feb_2018/,TomekB,1518807779,,0,1
765,2018-2-17,2018,2,17,4,7y15yr,[R] SysML Conference Livestream | Stanford,https://www.reddit.com/r/MachineLearning/comments/7y15yr/r_sysml_conference_livestream_stanford/,sksq9,1518808777,,0,1
766,2018-2-17,2018,2,17,4,7y17pj,Missing data hinder replication of artificial intelligence studies | Science,https://www.reddit.com/r/MachineLearning/comments/7y17pj/missing_data_hinder_replication_of_artificial/,[deleted],1518809170,[deleted],0,1
767,2018-2-17,2018,2,17,4,7y18m2,Love a bit of Ian Goodfellow on statistical models on a Friday afternoon :),https://www.reddit.com/r/MachineLearning/comments/7y18m2/love_a_bit_of_ian_goodfellow_on_statistical/,jehado,1518809370,,0,1
768,2018-2-17,2018,2,17,4,7y1acl,Missing data hinder replication of artificial intelligence studies | Science,https://www.reddit.com/r/MachineLearning/comments/7y1acl/missing_data_hinder_replication_of_artificial/,weeeeeewoooooo,1518809778,,18,61
769,2018-2-17,2018,2,17,5,7y1hz3,need an arxiv endorsement for my audio NN work,https://www.reddit.com/r/MachineLearning/comments/7y1hz3/need_an_arxiv_endorsement_for_my_audio_nn_work/,radarsat1,1518811570,[removed],0,1
770,2018-2-17,2018,2,17,5,7y1qc7,Rigorous comparison of performance between MXNet and Pytorch,https://www.reddit.com/r/MachineLearning/comments/7y1qc7/rigorous_comparison_of_performance_between_mxnet/,Datah0Di,1518813489,,0,1
771,2018-2-17,2018,2,17,6,7y217k,Roadmap to learn machine learning and become a data scientist in 2018,https://www.reddit.com/r/MachineLearning/comments/7y217k/roadmap_to_learn_machine_learning_and_become_a/,Harran_ali,1518816129,[removed],0,1
772,2018-2-17,2018,2,17,6,7y29c8,[Request] Can anybody upload CUDNN v6 or 7 for windows. Can't seem to download from the nvidia's site.,https://www.reddit.com/r/MachineLearning/comments/7y29c8/request_can_anybody_upload_cudnn_v6_or_7_for/,Kratest,1518818135,[removed],0,1
773,2018-2-17,2018,2,17,8,7y2qmq,Best Grad schools ML,https://www.reddit.com/r/MachineLearning/comments/7y2qmq/best_grad_schools_ml/,username7541,1518822517,[removed],0,1
774,2018-2-17,2018,2,17,8,7y31ie,Will knowledge graph be the future of natural language processing?,https://www.reddit.com/r/MachineLearning/comments/7y31ie/will_knowledge_graph_be_the_future_of_natural/,guotong1988,1518825366,[removed],0,1
775,2018-2-17,2018,2,17,9,7y39m6,Looking for Image Segmentation Utility,https://www.reddit.com/r/MachineLearning/comments/7y39m6/looking_for_image_segmentation_utility/,Simusid,1518827541,[removed],0,1
776,2018-2-17,2018,2,17,10,7y3rk9,PyTorch Should Be CopyLeft,https://www.reddit.com/r/MachineLearning/comments/7y3rk9/pytorch_should_be_copyleft/,keithcu,1518832626,[removed],0,1
777,2018-2-17,2018,2,17,11,7y3sab,Overfitting Explained in an Interesting Way,https://www.reddit.com/r/MachineLearning/comments/7y3sab/overfitting_explained_in_an_interesting_way/,goldenorbspider,1518832838,,0,1
778,2018-2-17,2018,2,17,13,7y4j0t,Some works related to LeCun's World Simulator for AI?,https://www.reddit.com/r/MachineLearning/comments/7y4j0t/some_works_related_to_lecuns_world_simulator_for/,phizaz,1518841507,[removed],0,1
779,2018-2-17,2018,2,17,14,7y4v99,[P] Time Cube Eternal,https://www.reddit.com/r/MachineLearning/comments/7y4v99/p_time_cube_eternal/,[deleted],1518845951,[deleted],0,0
780,2018-2-17,2018,2,17,14,7y4vnz,[P] Different image controls in Tensorflow,https://www.reddit.com/r/MachineLearning/comments/7y4vnz/p_different_image_controls_in_tensorflow/,[deleted],1518846099,[deleted],1,0
781,2018-2-17,2018,2,17,16,7y59ve,Landing the Falcon booster with Reinforcement Learning in OpenAI,https://www.reddit.com/r/MachineLearning/comments/7y59ve/landing_the_falcon_booster_with_reinforcement/,[deleted],1518851930,[deleted],1,1
782,2018-2-17,2018,2,17,16,7y5bzs,Tensorflow FizzBuzz Revisited,https://www.reddit.com/r/MachineLearning/comments/7y5bzs/tensorflow_fizzbuzz_revisited/,0b01,1518852859,,0,1
783,2018-2-17,2018,2,17,17,7y5kbc,(x-post from /r/programming) neonrvm: Relevance Vector Machine Based Machine Learning Library Written In C Programming Language,https://www.reddit.com/r/MachineLearning/comments/7y5kbc/xpost_from_rprogramming_neonrvm_relevance_vector/,a21562cc,1518856620,,0,2
784,2018-2-17,2018,2,17,18,7y5pnv,[D] Any tutorial on importance weighted active learning?,https://www.reddit.com/r/MachineLearning/comments/7y5pnv/d_any_tutorial_on_importance_weighted_active/,agility,1518859138,"I was reading this interesting paper on importance weighted active learning: http://cseweb.ucsd.edu/~dasgupta/papers/iwal-icml.pdf
I'm having trouble understanding the selection of the rejection threshold. I'm trying to implement a basic example of active learning using sklearn.

As per page 44 of this document: http://hunch.net/~active_learning/active_learning_icml09.pdf I'm looking at how to implement the ""implicit"" version. However, I don't understand the meaning of ""If learn(S  (xt, 1)) and learn(S  (xt, 0)) both return an answer"".

Is there anyone who can shed some light or point me to resources that'll help me implement importance weighted active learning?",1,6
785,2018-2-17,2018,2,17,18,7y5qi8,[P] Pommerman: A Multi-Agent Competition based on Bomberman,https://www.reddit.com/r/MachineLearning/comments/7y5qi8/p_pommerman_a_multiagent_competition_based_on/,wei_jok,1518859536,,3,19
786,2018-2-17,2018,2,17,18,7y5s7g,Manufacturer &amp; Exporters Lathe Machine India,https://www.reddit.com/r/MachineLearning/comments/7y5s7g/manufacturer_exporters_lathe_machine_india/,raman460,1518860394,,0,1
787,2018-2-17,2018,2,17,19,7y5ybk,New research,https://www.reddit.com/r/MachineLearning/comments/7y5ybk/new_research/,Ramanujan_31415,1518863340,[removed],0,1
788,2018-2-17,2018,2,17,19,7y5yrg,Python: Creating Datetime Libraries using Pandas!,https://www.reddit.com/r/MachineLearning/comments/7y5yrg/python_creating_datetime_libraries_using_pandas/,AnalystRisingTuts,1518863565,,0,0
789,2018-2-17,2018,2,17,20,7y63uj,Want to be a millionaire before you turn 25? Study artificial intelligence or machine learning,https://www.reddit.com/r/MachineLearning/comments/7y63uj/want_to_be_a_millionaire_before_you_turn_25_study/,pavanear,1518865976,,0,1
790,2018-2-17,2018,2,17,20,7y66f3,[D] Stack of Convolution LSTM layers,https://www.reddit.com/r/MachineLearning/comments/7y66f3/d_stack_of_convolution_lstm_layers/,ShivamDuggal4,1518867172,"I was reading the paper: https://arxiv.org/pdf/1506.04214.pdf
 Convolution LSTM requires much more memory compared to convolution layers because of the intermediate hidden, cell states.

In the paper, convolution LSTM layers are stacked to give the output. What if we replace few last ConvLSTM layers with normal Conv layers. The initial ConvLSTM layers would have taken care of the temporal dependency. Is there a reason why such an architecture should be / should not be used, apart from memory constraints. Does use of convolution layers and pooling layers after a stack of convLSTM layers lead to loss of some temporal information? ",2,3
791,2018-2-17,2018,2,17,20,7y68mu,[D] [P] I wanted to understand the flow of the equations that I'm implementing for a Question Answering System,https://www.reddit.com/r/MachineLearning/comments/7y68mu/d_p_i_wanted_to_understand_the_flow_of_the/,longlivekingjoffrey,1518868222,"The paper link is: [S-NET](https://arxiv.org/pdf/1706.04815.pdf) - pg 6 

EQUATION 14:

&gt; h_t_P = encoded Passage

&gt; h_t_Q = encoded Question

EQUATION 15:

&gt; *d_t* = GRU(*w_t-1, c_t-1, d_t-1*)

&gt; *d_0* = tanh(W_d [h1_P, h1_Q] + b)

EQUATION 16 (Luong Attention):

&gt; s_j_t = v_a_T \* tanh(W_a \* *d_t-1* + U_a \* *h_j*)

&gt; a_i_t = softmax(*s_i*)

&gt; c_t = 1 to n  a_i_t \* h_i

I'm trying to implement section 3.3 Answer Synthesis module (Pg 6), but I'm stuck in equation 15 and 16 which states that I have to use decoder (GRU) to compute decoder state *d_t* for every context vector *c_t-1*. But as the equation says, c_t is used in computing decoder state and then the decoded state d_t is used in computing c_t. It's a loop, unlike the attention mechanism in equation 4 and 5, which seems sequential (first computing the context and then decoding). Is this how it should be implemented as I've described?

Follow up question, the equation 15 takes w_t-1 as input and the context vector c_t-1 as well. The authors are saying that the w_t-1 is the word embedding, but they haven't mentioned of whose? Passage? Question?

Another question is that in the equation iii of equation 16, they're using h_i to compute the context vector, and it consists of answer and question representation. Is it a concatenation of h_P and h_Q on axis 1 of [batch, input, featuresize]? If so, then how would the context vector be computed after time step t exceeds the question token length?

I would suggest to read the section 3.3 part only (1 page at max) and any other queries I would answer over here so that you won't have to read the previous sections or skim through any premises. Thank you for reading, I appreciate the time taken by you in answering my doubts.",2,2
792,2018-2-17,2018,2,17,21,7y6g79,[P] Landing the Falcon booster with Reinforcement Learning in OpenAI,https://www.reddit.com/r/MachineLearning/comments/7y6g79/p_landing_the_falcon_booster_with_reinforcement/,EmbersArc,1518871530,,58,970
793,2018-2-17,2018,2,17,22,7y6ioi,need an arxiv endorsement for my audio NN work (xpost from /r/MachineLearning),https://www.reddit.com/r/MachineLearning/comments/7y6ioi/need_an_arxiv_endorsement_for_my_audio_nn_work/,[deleted],1518872531,,0,1
794,2018-2-18,2018,2,18,0,7y78w7,[D] Are there any recommended Video tutorials for developers to use PyTorch,https://www.reddit.com/r/MachineLearning/comments/7y78w7/d_are_there_any_recommended_video_tutorials_for/,__Julia,1518881420,"I am looking for a series of videos that I can use to learn Pytorch. I found out that there are some presentations, but any recommended videos to go through Deep Learning tutorials with Pytorch would be appreciated. 
https://drive.google.com/drive/folders/0B41Zbb4c8HVyUndGdGdJSXd5d3M
",8,5
795,2018-2-18,2018,2,18,0,7y79ba,"In WGAN-GP, my network gradient got to zero immediately.",https://www.reddit.com/r/MachineLearning/comments/7y79ba/in_wgangp_my_network_gradient_got_to_zero/,falmasri,1518881544,[removed],0,1
796,2018-2-18,2018,2,18,0,7y7aje,[R] Non-Parametric Transformation Networks,https://www.reddit.com/r/MachineLearning/comments/7y7aje/r_nonparametric_transformation_networks/,visarga,1518881891,,2,10
797,2018-2-18,2018,2,18,1,7y7my5,How can i implement pre trained neural network on my web page?,https://www.reddit.com/r/MachineLearning/comments/7y7my5/how_can_i_implement_pre_trained_neural_network_on/,mw-b,1518885290,[removed],0,1
798,2018-2-18,2018,2,18,2,7y7x1o,[D] Anyone going on the onsite for Google AI residency 2018?,https://www.reddit.com/r/MachineLearning/comments/7y7x1o/d_anyone_going_on_the_onsite_for_google_ai/,vlejd,1518887937,I am going on the onsite on 28th February. I would like to find other people that I can join there for some sightseeing and possibly some preparation mock interview.,177,3
799,2018-2-18,2018,2,18,2,7y7ygb,Where can i learn about machine learning?,https://www.reddit.com/r/MachineLearning/comments/7y7ygb/where_can_i_learn_about_machine_learning/,[deleted],1518888293,,0,1
800,2018-2-18,2018,2,18,2,7y82ds,Wha is regarded as good ML project lifecycle?,https://www.reddit.com/r/MachineLearning/comments/7y82ds/wha_is_regarded_as_good_ml_project_lifecycle/,[deleted],1518889318,,0,1
801,2018-2-18,2018,2,18,2,7y84q1,What is the best standardised ML development lifecycle/methodology?,https://www.reddit.com/r/MachineLearning/comments/7y84q1/what_is_the_best_standardised_ml_development/,mrz-ldn,1518889926,[removed],0,1
802,2018-2-18,2018,2,18,3,7y86zy,"I made a jackfruit/not-jackfruit model in TF. It's my first work on TF, please give me your feedback.",https://www.reddit.com/r/MachineLearning/comments/7y86zy/i_made_a_jackfruitnotjackfruit_model_in_tf_its_my/,iEatCodeforlife,1518890488,,0,1
803,2018-2-18,2018,2,18,4,7y8lgc,Top 10 Best Artificial Intelligence video tutorials,https://www.reddit.com/r/MachineLearning/comments/7y8lgc/top_10_best_artificial_intelligence_video/,Rahul08576,1518894192,,0,1
804,2018-2-18,2018,2,18,4,7y8vhy,Teaching conversational robots to be polite!,https://www.reddit.com/r/MachineLearning/comments/7y8vhy/teaching_conversational_robots_to_be_polite/,[deleted],1518896583,[deleted],0,1
805,2018-2-18,2018,2,18,5,7y9bh1,[R] Mapping Images to Scene Graphs with Permutation-Invariant Structured Prediction,https://www.reddit.com/r/MachineLearning/comments/7y9bh1/r_mapping_images_to_scene_graphs_with/,visarga,1518900397,,0,2
806,2018-2-18,2018,2,18,6,7y9nup,Build a chatbot the easy smart way that chats and answers questions,https://www.reddit.com/r/MachineLearning/comments/7y9nup/build_a_chatbot_the_easy_smart_way_that_chats_and/,theamrzaki,1518903476,,1,1
807,2018-2-18,2018,2,18,7,7y9zwo,Teaching social norms to conversational bots.,https://www.reddit.com/r/MachineLearning/comments/7y9zwo/teaching_social_norms_to_conversational_bots/,ehsanehsan,1518906580,,0,1
808,2018-2-18,2018,2,18,9,7yak3y,[R] Learning Longer-term Dependencies in RNNs with Auxiliary Losses,https://www.reddit.com/r/MachineLearning/comments/7yak3y/r_learning_longerterm_dependencies_in_rnns_with/,HigherTopoi,1518912075,,6,16
809,2018-2-18,2018,2,18,9,7yaqjz,"[N] ""Artificial intelligence moves into the real world"" - panel discussion w/ Eric Horvitz, Peter Norvig, Yann LeCun, and Henry Kautz",https://www.reddit.com/r/MachineLearning/comments/7yaqjz/n_artificial_intelligence_moves_into_the_real/,drlukeor,1518913779,,0,3
810,2018-2-18,2018,2,18,10,7yayy7,[D] How do Machine Learning researchers work in teams?,https://www.reddit.com/r/MachineLearning/comments/7yayy7/d_how_do_machine_learning_researchers_work_in/,brokechigguh,1518916085,"On a given project (assuming collaborative efforts), how do the team members interact? What do you share amongst each other? How do you allocate work? 

If there is no collaborative effort, does one just try many different workflows (data normalization, feature selection, etc.) and see which one works best? ",20,21
811,2018-2-18,2018,2,18,10,7yb1ob,"[D] Are there synthetic data sets which satisfy the hypotheses in ""The Manifold Tangent Classifier"" (Rifai et al., 2008)?",https://www.reddit.com/r/MachineLearning/comments/7yb1ob/d_are_there_synthetic_data_sets_which_satisfy_the/,fuckinghelldad,1518916831,,4,3
812,2018-2-18,2018,2,18,10,7yb2sa,"Is there any task which RNNs are better for, that is actually measurable?",https://www.reddit.com/r/MachineLearning/comments/7yb2sa/is_there_any_task_which_rnns_are_better_for_that/,[deleted],1518917155,,0,1
813,2018-2-18,2018,2,18,12,7ybmyx,"[D] Have there been any updates on the ""Are GANs Created Equal"" from Soumith/Goodfellow?",https://www.reddit.com/r/MachineLearning/comments/7ybmyx/d_have_there_been_any_updates_on_the_are_gans/,programmerChilli,1518923094,"The [Are GANs Created Equal](https://arxiv.org/abs/1711.10337) paper created a lot of controversy. For example, [here](https://www.reddit.com/r/MachineLearning/comments/7gwip3/d_googles_large_scale_gantuning_paper_unfairly/dqn9vzz/?context=1).

They said they would meet up at NIPS and discuss it, and share conclusions after, but I haven't seen it yet. https://twitter.com/goodfellow_ian/status/936616806348832768

Does anyone know if there's been any updates on the matter?
",2,38
814,2018-2-18,2018,2,18,13,7yc30l,How to identify distinct objects within an image,https://www.reddit.com/r/MachineLearning/comments/7yc30l/how_to_identify_distinct_objects_within_an_image/,eggsntobasco,1518928169,,0,1
815,2018-2-18,2018,2,18,13,7yc4lk,"Future of AI Hardware Panel (Dave Patterson, Bryan Catanzaro, Andrew Feldman, &amp; Cade Metz)",https://www.reddit.com/r/MachineLearning/comments/7yc4lk/future_of_ai_hardware_panel_dave_patterson_bryan/,darkconfidantislife,1518928686,,0,1
816,2018-2-18,2018,2,18,13,7yc5yg,[D] The AI Talent Shortage,https://www.reddit.com/r/MachineLearning/comments/7yc5yg/d_the_ai_talent_shortage/,chisai_mikan,1518929150,,5,0
817,2018-2-18,2018,2,18,15,7yco19,[D] Does zero padding affect normalization output?,https://www.reddit.com/r/MachineLearning/comments/7yco19/d_does_zero_padding_affect_normalization_output/,min_sang,1518935529,"I am working on a simple NLP task where due to many reasons I have to pad my input sequence to length 300. Then I pass it through a couple of 1d conv and dot product self-attention.

What I'd like to know is whether normalizing this representation (say, shape = [batch_size, 300, feature size]) would have a negative impact if the data is zero padded to a sequence length of 300. If layer norm is used, would the fact that the actual data size if something like this [batch size, 173 (an arbitrary number), feature size] affect the output of the normalization?",2,6
818,2018-2-18,2018,2,18,16,7ycwa2,"Deep Learning Experiments with Google Colab, Keras and CIFAR10 Dataset",https://www.reddit.com/r/MachineLearning/comments/7ycwa2/deep_learning_experiments_with_google_colab_keras/,deeplearningturkey,1518939004,,0,1
819,2018-2-18,2018,2,18,17,7yd2m5,[D] Baselines/Benchmarks/Datasets for different application domains and architectures -,https://www.reddit.com/r/MachineLearning/comments/7yd2m5/d_baselinesbenchmarksdatasets_for_different/,mechanicaatomsk,1518941774,"


Are there any organizations or individuals who are trying to collect different baseline/benchmarks/datasets for different application domains and ML architectures? This is really multiple questions, since I don't expect there to be anyone doing all three. I also know there are some resources for finding datasets, some of which are in the [wiki](https://www.reddit.com/r/MachineLearning/wiki/index). I added some that people might find from doing a quick google search

* mlpack: [Github](https://github.com/mlpack/benchmarks)
* Penn Machine Learning Benchmarks [Github](https://github.com/EpistasisLab/penn-ml-benchmarks)
* DeepBench (Baidu): [Github](https://github.com/baidu-research/DeepBench)

Another is example, Harutyunyan et al, proposed benchmark in their 2017 paper ""[Multitask Learning and Benchmarking with Clinical Time Series Data](https://arxiv.org/abs/1703.07771)"". Their repo for generating the benchmarks is pretty good too.

* Github: https://github.com/YerevaNN/mimic3-benchmarks

Unforunately I'm not aware of any resources, or on going efforts, that tries to sort through the madness. I'm also aware that there is multiple types of benchmarking (hardware,software,architecture,application).

**If there are such resources, is it possible to add them to the wiki for easy reference or dissemination?** 

Last, and as a brief tangent, I've noticed a growing number complaints about reproducibility, lack of benchmarks for particular domains or methods, and a general worry about a lack of honest reporting of results. Reproducibility, benchmarking, and baselines are not the same problems of course, but these problems arise from difficulty in finding, or the lack of, sufficient documentation. A recent example of this discussion happening was at AAAI2018 which was picked up by *Science (magazine)* and subsequently Futurism. These are problems from individuals not sharing their resources/documentation and not with anyone's ability to find them. However I thought I'd share some of the links to point out these  problems are gaining attention outside of research circles.

*  *Science (magazine)*: [Missing data hinder replication of artificial intelligence studies](https://www.sciencemag.org/news/2018/02/missing-data-hinder-replication-artificial-intelligence-studies)
*  Futurism: [Scientists Cant Replicate AI Studies. Thats Bad News.](https://futurism.com/scientists-cant-replicate-ai-studies/)

 

",6,6
820,2018-2-18,2018,2,18,17,7yd4v0,Is there a measurable task which RNNs are good for?,https://www.reddit.com/r/MachineLearning/comments/7yd4v0/is_there_a_measurable_task_which_rnns_are_good_for/,[deleted],1518942846,,0,1
821,2018-2-18,2018,2,18,17,7yd64d,"Since Open Source powers Machine Learning, a little bit about history...(xpost from /r/Linux)",https://www.reddit.com/r/MachineLearning/comments/7yd64d/since_open_source_powers_machine_learning_a/,unnamedn00b,1518943430,,0,1
822,2018-2-18,2018,2,18,18,7yd92x,What is the current state of the art in applying Multitask Learning to Question Generation / Text Generation?,https://www.reddit.com/r/MachineLearning/comments/7yd92x/what_is_the_current_state_of_the_art_in_applying/,WinglikeWithholder,1518944865,[removed],0,1
823,2018-2-18,2018,2,18,18,7ydb52,learning longer term dependencies in RNNs with auxiliary loss,https://www.reddit.com/r/MachineLearning/comments/7ydb52/learning_longer_term_dependencies_in_rnns_with/,vivanov,1518945879,,0,1
824,2018-2-18,2018,2,18,18,7yde11,[D] Salaries for ML,https://www.reddit.com/r/MachineLearning/comments/7yde11/d_salaries_for_ml/,MLThrowawayForSalary,1518947322,"I'm curious to hear what the crowd here is earning. There's a similar discussion over at [HN](https://news.ycombinator.com/item?id=16405213) (yes, I started it), but it's always better to get more data points. As always, transparency helps everyone.



Small Co | Greater Boston Area | PhD + 5 years

*Base:* 180

*Options/RSUs:* Lots of funny money

*Bonus:* 25",278,148
825,2018-2-18,2018,2,18,19,7ydi9y,[D] Lower batch size for sequential learning problem with class imbalance,https://www.reddit.com/r/MachineLearning/comments/7ydi9y/d_lower_batch_size_for_sequential_learning/,shamitlal,1518949437,"Does having a smaller batch size, perhaps even size 1, help in a sequential learning problem ( where there is an output corresponding to each input) where the dataset is imbalanced?
Suppose my batch size is 4 and timesteps are 10. My minibatch true labels may look somewhat like this:
[[1,1,1,1,0,0,0,0,0,2],
[0,0,1,1,1,2,0,0,1],
[0,0,0,1,1,1,1,0,0,0],
[1,1,0,0,0,0,2,1,1,0]]

Class 2 rarely occurs in the dataset.
In such cases, can the presence of multiple samples in minibatch adversarially impact training of each sample (especially those which contain label 2)? Since label 2 may not even occur in some samples of a minibatch, the network may not learn to predict 2 for samples in which it does occur.  ",1,3
826,2018-2-18,2018,2,18,19,7ydj3o,[D] Looking for a demo I once saw that used little red demons to explain to laymen how neural networks work (x-post from /r/learnmachinelearning),https://www.reddit.com/r/MachineLearning/comments/7ydj3o/d_looking_for_a_demo_i_once_saw_that_used_little/,biciklanto,1518949822,,1,4
827,2018-2-18,2018,2,18,21,7ye1np,Advice for optimizing this problem with genetic algorithm?,https://www.reddit.com/r/MachineLearning/comments/7ye1np/advice_for_optimizing_this_problem_with_genetic/,reygoch,1518958285,[removed],0,1
828,2018-2-18,2018,2,18,22,7yeb0x,"[D] When is it reasonable to drop the ""AI"" term?",https://www.reddit.com/r/MachineLearning/comments/7yeb0x/d_when_is_it_reasonable_to_drop_the_ai_term/,maka89,1518961562,"I see more Machine Learning / AI articles popping up in my national news  sources. The term ""Artificial Intelligence"" is used a lot, needless to say. Even researchers and unis use the term(to gain hype probably since the word is more sexy than ""regression analysis"")

Even if the article is on something sensible, like : ""It might be smart to collect some medical data, to cure new diseases, get better healthcare"", the public perception / comments section seems to be heavily influenced by peoples SciFi expectations of the word ""AI"" (It will turn on us, etc. )

My question is: 
When is it reasonable to use the term AI? 
I once read that the line is drawn at reinforcement learning, is this reasonable?
",26,27
829,2018-2-19,2018,2,19,0,7yeuj8,Guide/Papers/General approach on increasing output classes for object detection (RCNN)?,https://www.reddit.com/r/MachineLearning/comments/7yeuj8/guidepapersgeneral_approach_on_increasing_output/,Nargando,1518967301,[removed],0,1
830,2018-2-19,2018,2,19,0,7yeysh,[D] Is it possible to train a Regional CNN (or one of its variants) without ground-truth boxes?,https://www.reddit.com/r/MachineLearning/comments/7yeysh/d_is_it_possible_to_train_a_regional_cnn_or_one/,autunno,1518968453,"I've been studying RCNN (and its derivatives, such as Fast RCNN, Faster RCNN and Mask RCNN), and one thing in common in all of those is the need for ground-truth boxes during the training phase.

I'm working with a dataset in which every .png file has only a single object pertaining to a single class. Given that scenario, would it be possible to train a RCNN without ground-truth boxes? In other words, is it possible to train such network with only images (and no additional information) in a way that it will still be able to predict object locations in a complex image? ",17,7
831,2018-2-19,2018,2,19,1,7yfa1i,"AMA with Yann LeCun, Eric Horvitz, and Peter Norvig happening now on r/science!",https://www.reddit.com/r/MachineLearning/comments/7yfa1i/ama_with_yann_lecun_eric_horvitz_and_peter_norvig/,[deleted],1518971351,[deleted],0,1
832,2018-2-19,2018,2,19,1,7yfafu,Machine Learning A-Z: Hands-On Python &amp; R In Data Science - Very well done Machine Learning course. Every machine learning models and algorithms are explained clearly with a very comprehensive practical tutorials. The instructors are amazing and I am learning a lot of cool stuffs.,https://www.reddit.com/r/MachineLearning/comments/7yfafu/machine_learning_az_handson_python_r_in_data/,[deleted],1518971443,[deleted],0,1
833,2018-2-19,2018,2,19,1,7yfd7m,Feature article about Geoffrey Hinton: Mr. Robot,https://www.reddit.com/r/MachineLearning/comments/7yfd7m/feature_article_about_geoffrey_hinton_mr_robot/,DanielleMolloy,1518972097,,0,1
834,2018-2-19,2018,2,19,1,7yff00,"AMA with Yann LeCun, Eric Horvitz, and Peter Norvig happening now on r/science!",https://www.reddit.com/r/MachineLearning/comments/7yff00/ama_with_yann_lecun_eric_horvitz_and_peter_norvig/,thelegendofhamzor,1518972513,,0,3
835,2018-2-19,2018,2,19,2,7yfjm1,[D] What is the term for intermixing recovery + imitation data when conducting imitation learning?,https://www.reddit.com/r/MachineLearning/comments/7yfjm1/d_what_is_the_term_for_intermixing_recovery/,sauhaarda,1518973596,"I've read about techniques like DAgger which attempt to solve the data mismatch problem when conducting imitation learning. But in the dataset I was provided with, we essentially train and record on two types of data with our autonomous cars (1 = pure human control driving, and 2 = human override of autonomous driving). In the latter case, we allow the car to make a mistake, and then jump in to correct the mistake, while recording and training on this correction so the model is able to learn how to correct it's own mistakes. Is there a term for this kind of learning/data collection?",0,1
836,2018-2-19,2018,2,19,2,7yfn94,[P] The Humble Gumbel Distribution,https://www.reddit.com/r/MachineLearning/comments/7yfn94/p_the_humble_gumbel_distribution/,mrahtz,1518974424,,26,55
837,2018-2-19,2018,2,19,2,7yfncs,(episilon)support vector regression - rate my explanation!,https://www.reddit.com/r/MachineLearning/comments/7yfncs/episilonsupport_vector_regression_rate_my/,MLbeginner96,1518974449,[removed],0,1
838,2018-2-19,2018,2,19,2,7yfr8w,[D] What does it take to become a Research/Data Science/Machine Learning Engineer ? how can someone build a strong profile ?,https://www.reddit.com/r/MachineLearning/comments/7yfr8w/d_what_does_it_take_to_become_a_researchdata/,__bee,1518975341,"Hi,

I'd like to know if there are some Data Science/Machine Learning Engineers who are working at the intersection between engineering and machine learning. Regardless of the title used, these engineers are the ones who enjoy doing research, playing with data, at the same time building end-to-end in-production solutions. I would imagine that it would be easier to distinguish these engineers in companies like OpenAI/Microsoft Research/FB Research, but there is a rising need to have this type of  engineers in data-focused companies. 

I would like to know how these people built their profiles:

- How do distinguish a Research/Data Science/Machine Learning Engineer from a SDE/BE engineer: Do these engineers focus on improving their technical skills (Open sourcing projects, having strong Github profile, .. etc) or having strong record of publications. 

- If you are one, How did you get the job ? How did they evaluate you (Focus more on Algorithms or ML Theory ? ).
 
- If you are a recruiter, a research lead, a manager or a startup CTO, What is your advise for an aspiring Research/Data Science/Machine Learning Engineer ?. Do I need to focus on publishing some papers, or do I need to start a blog and open source/showcase more technical projects.

 If you can share some insights that would be helpful. I couldn't find a description of this profile that put together, most people talk about data scientist (who are not supposed to build production-ready solutions ) or data engineers (who are focusing on ETL pipelines). Engineers in research labs are most probably PhDs or Research Associates. However, this profile of engineers can be easily found in AI-first companies like OpenAI, DeepMind, .. etc 


",22,30
839,2018-2-19,2018,2,19,3,7yg2z0,How to learn Feature Engineering,https://www.reddit.com/r/MachineLearning/comments/7yg2z0/how_to_learn_feature_engineering/,MudbloodZA,1518978026,[removed],0,1
840,2018-2-19,2018,2,19,3,7ygagh,[N] The American Statistical Association has published their first survey of Statistics Majors (Class of 2016),https://www.reddit.com/r/MachineLearning/comments/7ygagh/n_the_american_statistical_association_has/,sugarhilldt2,1518979681,,2,2
841,2018-2-19,2018,2,19,4,7yge0t,[D] How to tackle this problem?,https://www.reddit.com/r/MachineLearning/comments/7yge0t/d_how_to_tackle_this_problem/,sku-sku,1518980488,"Dear redditors,
I have a wish for a machine learning project, but I am unsure how to attack it.

The data are videos. The result is a music video, which maps frames to the given soundtrack. Let's say I have videos of a person talking, the music video should be that person singing the song (and notes, etc.). It can be trashy, no need for realism.

What architecture could I use?

Apparently I need some sort of generative method, which brings up the idea of GANs. However, if I understand correctly, GANs do not have actual labels as inputs but rather some arbitrary code.

Another problem is that, if I use the videos as data for the learning, I don't actually have a finite set of labels. How could I approach that? Do I have to preprocess the sound data so as to make it have less variance so that I can use it as labels?

What other forms of generative machine learning algorithms exist, that could give me frames from sound data, after I gave it videos mixed with sound?

Thank you dear redditors, I hope to grow with your knowledge.

Kindest regards,
sku-sku",3,1
842,2018-2-19,2018,2,19,4,7yggxs,[D] Lessons from DeepLearning.ai - Sequence Models,https://www.reddit.com/r/MachineLearning/comments/7yggxs/d_lessons_from_deeplearningai_sequence_models/,Choco31415,1518981132,,1,8
843,2018-2-19,2018,2,19,4,7ygk3z,What are some recent advancements in Video Classification?,https://www.reddit.com/r/MachineLearning/comments/7ygk3z/what_are_some_recent_advancements_in_video/,Tahseenb,1518981780,[removed],0,1
844,2018-2-19,2018,2,19,4,7ygm8m,Learning to Search with MCTSnets,https://www.reddit.com/r/MachineLearning/comments/7ygm8m/learning_to_search_with_mctsnets/,Zeta_36,1518982243,,1,1
845,2018-2-19,2018,2,19,5,7yh26b,[R] Evolved Policy Gradients,https://www.reddit.com/r/MachineLearning/comments/7yh26b/r_evolved_policy_gradients/,pavelchristof,1518985648,,8,6
846,2018-2-19,2018,2,19,6,7yhc0s,Machine Learning Society - February Evolution,https://www.reddit.com/r/MachineLearning/comments/7yhc0s/machine_learning_society_february_evolution/,Mathriddle,1518987858,,0,1
847,2018-2-19,2018,2,19,7,7yhr6k,Alexa Quote of the Day Skill!!! Enable now!,https://www.reddit.com/r/MachineLearning/comments/7yhr6k/alexa_quote_of_the_day_skill_enable_now/,virenkhandal,1518991420,[removed],0,1
848,2018-2-19,2018,2,19,7,7yhuk1,Predicting Musical Genre Using Lyrics (with d3.js dashboard),https://www.reddit.com/r/MachineLearning/comments/7yhuk1/predicting_musical_genre_using_lyrics_with_d3js/,tmthyjames,1518992225,,0,1
849,2018-2-19,2018,2,19,7,7yi3yr,"[N] LeCun, Horvitz and Norvig AMA on /r/science",https://www.reddit.com/r/MachineLearning/comments/7yi3yr/n_lecun_horvitz_and_norvig_ama_on_rscience/,gokstudio,1518994689,,0,86
850,2018-2-19,2018,2,19,9,7yiijl,Convolutional network learning snake with RL,https://www.reddit.com/r/MachineLearning/comments/7yiijl/convolutional_network_learning_snake_with_rl/,[deleted],1518998535,[deleted],0,1
851,2018-2-19,2018,2,19,9,7yijxh,[D] Has Deep Learning peaked?,https://www.reddit.com/r/MachineLearning/comments/7yijxh/d_has_deep_learning_peaked/,rantana,1518998909,"Over the past year, there seems to be more opinion/arguments/semantics and less substance from researchers in the community:

* https://www.alexirpan.com/2018/02/14/rl-hard.html
* https://medium.com/@karpathy/software-2-0-a64152b37c35
* https://www.facebook.com/yann.lecun/posts/10155003011462143
* https://twitter.com/goodfellow_ian/status/936616806348832768
* https://openreview.net/forum?id=rJWF0Fywf

As an engineer, can I stop following the research now?
",21,2
852,2018-2-19,2018,2,19,9,7yikyu,[P] CNN learning to play snake using RL,https://www.reddit.com/r/MachineLearning/comments/7yikyu/p_cnn_learning_to_play_snake_using_rl/,MythicManiac,1518999145,,3,16
853,2018-2-19,2018,2,19,9,7yiprd,JeVois Darknet YOLO recognition help!,https://www.reddit.com/r/MachineLearning/comments/7yiprd/jevois_darknet_yolo_recognition_help/,techied,1519000388,,2,1
854,2018-2-19,2018,2,19,11,7yjbae,Seminal papers from the 2010's?,https://www.reddit.com/r/MachineLearning/comments/7yjbae/seminal_papers_from_the_2010s/,Olao99,1519006215,[removed],0,1
855,2018-2-19,2018,2,19,11,7yjfbm,Can someone explain me how backprop and optimization works with the Triplet loss?,https://www.reddit.com/r/MachineLearning/comments/7yjfbm/can_someone_explain_me_how_backprop_and/,miranthalk,1519007381,[removed],0,1
856,2018-2-19,2018,2,19,11,7yjg8j,"[D] - For AI to Get Creative, It Must Learn the Rules--Then How to Break 'Em",https://www.reddit.com/r/MachineLearning/comments/7yjg8j/d_for_ai_to_get_creative_it_must_learn_the/,tshrjn,1519007634,,0,3
857,2018-2-19,2018,2,19,11,7yjifj,Zeta36/chess-alpha-zero - Chess reinforcement learning by AlphaGo Zero methods,https://www.reddit.com/r/MachineLearning/comments/7yjifj/zeta36chessalphazero_chess_reinforcement_learning/,t_bptm,1519008245,,0,1
858,2018-2-19,2018,2,19,11,7yjk5m,[P] Machine Learning Top 10 Open Source Projects (v.Feb 2018),https://www.reddit.com/r/MachineLearning/comments/7yjk5m/p_machine_learning_top_10_open_source_projects/,mmeartine,1519008739,,14,186
859,2018-2-19,2018,2,19,11,7yjky1,CVPR 2018 accepted papers,https://www.reddit.com/r/MachineLearning/comments/7yjky1/cvpr_2018_accepted_papers/,netw0rkf10w,1519008960,,3,5
860,2018-2-19,2018,2,19,11,7yjl0a,Is it necessary to do PhD / MS in machine learning to get job in AI/ ML companies?,https://www.reddit.com/r/MachineLearning/comments/7yjl0a/is_it_necessary_to_do_phd_ms_in_machine_learning/,keyurparalkar,1519008978,[removed],0,1
861,2018-2-19,2018,2,19,12,7yjvg2,two questions about variational auto encoders,https://www.reddit.com/r/MachineLearning/comments/7yjvg2/two_questions_about_variational_auto_encoders/,koormoosh,1519011937,[removed],0,1
862,2018-2-19,2018,2,19,14,7ykde4,"""[Discussion]"" Tips for Writing Papers for Academic Audience",https://www.reddit.com/r/MachineLearning/comments/7ykde4/discussion_tips_for_writing_papers_for_academic/,newperson77777777,1519017323,"I'm writing my first paper, which I am looking to publish in an academic journal. I'm a little intimidated by some of the papers that I was reading in the journals that I am looking to submit to. While the quality in the papers is definitely great, I feel there's a lot just with regards to the authors' skill in presentation. In addition to that, I feel like the journal papers seem to write well for the academic audience. I don't have a natural understanding of the nuances of this audience. Personally, I feel like I have a more down-to-earth personality, so if I was implementing a 20-layer network, I would say I am implementing a deep learning network, whereas in one of the academic papers, someone may say they are implementing a 20-layer encoder-decoder convolutional network. I feel like the second one is probably for the academic audience, but the first one is more natural for me. Anyone have any tips for this or any experience they can provide in regards to academic writing in general?",13,2
863,2018-2-19,2018,2,19,15,7ykm7k,&lt;Micro Learnings&gt; Image Recognition Vs Object Detection  The Difference,https://www.reddit.com/r/MachineLearning/comments/7ykm7k/micro_learnings_image_recognition_vs_object/,jnvipul,1519020227,,0,1
864,2018-2-19,2018,2,19,16,7ykxgl,[D] Deep Learning for DNA Synthesis,https://www.reddit.com/r/MachineLearning/comments/7ykxgl/d_deep_learning_for_dna_synthesis/,[deleted],1519024150,[deleted],0,1
865,2018-2-19,2018,2,19,16,7ykxol,[D] Deep Learning for DNA Synthesis,https://www.reddit.com/r/MachineLearning/comments/7ykxol/d_deep_learning_for_dna_synthesis/,alexmlamb,1519024222,,1,19
866,2018-2-19,2018,2,19,16,7yl1mq,5 Companies using Machine Learning in a more fun-loving way!,https://www.reddit.com/r/MachineLearning/comments/7yl1mq/5_companies_using_machine_learning_in_a_more/,Rosy_Tech,1519025681,[removed],1,1
867,2018-2-19,2018,2,19,16,7yl4wl,How to build a career in AI and Machine learning?,https://www.reddit.com/r/MachineLearning/comments/7yl4wl/how_to_build_a_career_in_ai_and_machine_learning/,pavanear,1519027004,,0,1
868,2018-2-19,2018,2,19,16,7yl50e,[D] What graduate Machine Learning programs might be underrated?,https://www.reddit.com/r/MachineLearning/comments/7yl50e/d_what_graduate_machine_learning_programs_might/,TeslaCarBot,1519027041,Perhaps is a lesser known school but professors have made some great developments,8,0
869,2018-2-19,2018,2,19,17,7ylbjc,"Understanding AI, Machine Learning, and Deep Learning",https://www.reddit.com/r/MachineLearning/comments/7ylbjc/understanding_ai_machine_learning_and_deep/,dearpetra,1519029593,,0,1
870,2018-2-19,2018,2,19,17,7yleam,Logistic Regression: A Concise Technical Overview,https://www.reddit.com/r/MachineLearning/comments/7yleam/logistic_regression_a_concise_technical_overview/,friscotime,1519030743,,0,1
871,2018-2-19,2018,2,19,18,7ylgzc,Object detection one shot learning?,https://www.reddit.com/r/MachineLearning/comments/7ylgzc/object_detection_one_shot_learning/,[deleted],1519031856,,0,1
872,2018-2-19,2018,2,19,18,7yliqz,[N] Feature article about Geoffrey Hinton: Mr. Robot,https://www.reddit.com/r/MachineLearning/comments/7yliqz/n_feature_article_about_geoffrey_hinton_mr_robot/,DanielleMolloy,1519032547,,2,2
873,2018-2-19,2018,2,19,18,7ylm0i,[R] DeblurGAN: Blind Motion Deblurring Using Conditional Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/7ylm0i/r_deblurgan_blind_motion_deblurring_using/,visarga,1519033878,,4,16
874,2018-2-19,2018,2,19,18,7ylmd3,Challenging Games to Improve Your ML Coding Skills,https://www.reddit.com/r/MachineLearning/comments/7ylmd3/challenging_games_to_improve_your_ml_coding_skills/,[deleted],1519034022,[deleted],0,1
875,2018-2-19,2018,2,19,19,7ylq04,[P] Failure of reproducing DeepPILCO. (PILCO with BNN dynamics model),https://www.reddit.com/r/MachineLearning/comments/7ylq04/p_failure_of_reproducing_deeppilco_pilco_with_bnn/,metaAI,1519035413,"I have pushed a [repo](https://github.com/zuoxingdong/DeepPILCO) on Github trying to reproduce the results of the following paper in PyTorch

- Gal, Y., McAllister, R. and Rasmussen, C.E., 2016, April. Improving PILCO with Bayesian neural network dynamics models. In Data-Efficient Machine Learning workshop, ICML.

However, it is failed to learn a good controller. The purpose of releasing this repo is to ask if someone also interested to help together to seek for potential bugs or check for reproducibility of the algorithm.",10,11
876,2018-2-19,2018,2,19,19,7yluvy,When to use Dask or pandas?,https://www.reddit.com/r/MachineLearning/comments/7yluvy/when_to_use_dask_or_pandas/,necklesscage,1519037387,[removed],0,1
877,2018-2-19,2018,2,19,22,7ymo1u,A fast PASCAL VOC format image annotation tool https://github.com/udaypk/FastAnnotationSingleObject https://www.youtube.com/watch?v=Cp31IzvgYJ4,https://www.reddit.com/r/MachineLearning/comments/7ymo1u/a_fast_pascal_voc_format_image_annotation_tool/,[deleted],1519047248,,0,1
878,2018-2-19,2018,2,19,23,7ymv9j,[D] Getting Text into Tensorflow with the Dataset API,https://www.reddit.com/r/MachineLearning/comments/7ymv9j/d_getting_text_into_tensorflow_with_the_dataset/,TalkingJellyFish,1519049342,,9,0
879,2018-2-19,2018,2,19,23,7ymygw,Yet another post about learning ML,https://www.reddit.com/r/MachineLearning/comments/7ymygw/yet_another_post_about_learning_ml/,GuyFromUranus,1519050214,[removed],0,1
880,2018-2-19,2018,2,19,23,7ymyhh,How do the subjective 'feelings' experienced by computers who are subject to reinforcement learning differ from the subjective pain/pleasure experienced by mammals?,https://www.reddit.com/r/MachineLearning/comments/7ymyhh/how_do_the_subjective_feelings_experienced_by/,ryanehlol,1519050219,[removed],0,1
881,2018-2-19,2018,2,19,23,7yn40k,"[D] Gatys style transfer with asynchronous signals, how?",https://www.reddit.com/r/MachineLearning/comments/7yn40k/d_gatys_style_transfer_with_asynchronous_signals/,carlthome,1519051749,"[Optimizer-based style transfer](https://arxiv.org/abs/1508.06576) is super cool and that Gram matrices as a measure of style looks so right for paintings is still surprising to me, but how do you extend style transfer to cyclostationary signals (e.g. music) that don't align over time?

If we have a content video and a style video for example, we'd like some measurement of global style that's only partially non-local, like only in-between cuts. Across cuts the style would preferably be ""reset"" somehow. Imagine the color-grading in [Crash](http://www.imdb.com/title/tt0375679/) as the style video. The global average of all color gradings should not be applied to the content, as that would likely become a brown/grey murky mess, but rather each content segment would be transformed according to one specific style segment's color grading.

Preprocessing videos and doing independent style transfers is of course a possibility, but it would be nice to steer the loss to align these segments end-to-end somehow despite the style signal and content signal containing asynchronous segments. Particularly as sets of non-adjacent segments will exhibit the same style.

**TL;DR: Is anyone working on sequence extensions to Gatys style transfer with end-to-end temporal alignment?**",1,1
882,2018-2-20,2018,2,20,0,7yn742,Never thought this many businesses are using AI,https://www.reddit.com/r/MachineLearning/comments/7yn742/never_thought_this_many_businesses_are_using_ai/,charryw,1519052520,,0,1
883,2018-2-20,2018,2,20,0,7yne88,Papers on music generation with genre input?,https://www.reddit.com/r/MachineLearning/comments/7yne88/papers_on_music_generation_with_genre_input/,what_shall_we_do_now,1519054215,[removed],0,1
884,2018-2-20,2018,2,20,0,7ynkxv,Is it a good idea to use DNC to do text classification?,https://www.reddit.com/r/MachineLearning/comments/7ynkxv/is_it_a_good_idea_to_use_dnc_to_do_text/,NoSegfaultPlz,1519055780,[removed],0,1
885,2018-2-20,2018,2,20,0,7ynlu8,[P] A library for fine-tuning pretrained CNNs with PyTorch,https://www.reddit.com/r/MachineLearning/comments/7ynlu8/p_a_library_for_finetuning_pretrained_cnns_with/,alexparinov,1519055976,,0,0
886,2018-2-20,2018,2,20,1,7ynsms,Is it possible to use GAN for grammar error correction?,https://www.reddit.com/r/MachineLearning/comments/7ynsms/is_it_possible_to_use_gan_for_grammar_error/,ardakshalkar,1519057403,[removed],0,1
887,2018-2-20,2018,2,20,1,7ynwto,Are weights 1-D or 2-D in softmax Regression?,https://www.reddit.com/r/MachineLearning/comments/7ynwto/are_weights_1d_or_2d_in_softmax_regression/,Gnaneshkunal,1519058239,[removed],0,1
888,2018-2-20,2018,2,20,1,7ynxhg,[D] What do neural net loss functions look like?,https://www.reddit.com/r/MachineLearning/comments/7ynxhg/d_what_do_neural_net_loss_functions_look_like/,sksq9,1519058379,,10,14
889,2018-2-20,2018,2,20,1,7ynzs3,[D] New Deep Learning Techniques (Lectures) - Institute for Pure &amp; Applied Mathematics,https://www.reddit.com/r/MachineLearning/comments/7ynzs3/d_new_deep_learning_techniques_lectures_institute/,sksq9,1519058846,,14,148
890,2018-2-20,2018,2,20,1,7yo21p,Research Division of Tech Company vs Quantitative Hedge Fund,https://www.reddit.com/r/MachineLearning/comments/7yo21p/research_division_of_tech_company_vs_quantitative/,MinimumTank,1519059322,[removed],0,1
891,2018-2-20,2018,2,20,2,7yo4c2,"Please help me do this project, Im dumb but willing to learn",https://www.reddit.com/r/MachineLearning/comments/7yo4c2/please_help_me_do_this_project_im_dumb_but/,Tamizhan007,1519059795,,0,1
892,2018-2-20,2018,2,20,2,7yoaci,"""[Project]"" A fast PASCAL VOC format image annotation tool https://github.com/udaypk/FastAnnotationSingleObject https://www.youtube.com/watch?v=Cp31IzvgYJ4",https://www.reddit.com/r/MachineLearning/comments/7yoaci/project_a_fast_pascal_voc_format_image_annotation/,[deleted],1519061071,,0,1
893,2018-2-20,2018,2,20,2,7yodms,Biologically inspired reinforcement learning,https://www.reddit.com/r/MachineLearning/comments/7yodms/biologically_inspired_reinforcement_learning/,zebrasecond,1519061747,[removed],0,1
894,2018-2-20,2018,2,20,2,7yoe0n,[P] Dynamic Neural Networks in Tensorflow,https://www.reddit.com/r/MachineLearning/comments/7yoe0n/p_dynamic_neural_networks_in_tensorflow/,Miejuib,1519061825,,5,20
895,2018-2-20,2018,2,20,2,7yojqq,Syntax Char RNN for Context Encoding,https://www.reddit.com/r/MachineLearning/comments/7yojqq/syntax_char_rnn_for_context_encoding/,thundercomb,1519062986,,0,1
896,2018-2-20,2018,2,20,3,7yoqn3,Remember the Random Kitchen Sinks talk from NIPS '17? This stepsize adaptation scheme is a response.,https://www.reddit.com/r/MachineLearning/comments/7yoqn3/remember_the_random_kitchen_sinks_talk_from_nips/,cz_kenny,1519064372,,1,1
897,2018-2-20,2018,2,20,3,7yorhs,"""[P]"" A fast PASCAL VOC format image annotation tool",https://www.reddit.com/r/MachineLearning/comments/7yorhs/p_a_fast_pascal_voc_format_image_annotation_tool/,udaykp,1519064548,"https://github.com/udaypk/FastAnnotationSingleObject
https://www.youtube.com/watch?v=Cp31IzvgYJ4 
You can use this tool for annotating images in PASCAL VOC format. This tool is customized to be very fast if you have only one object per image and the images of different classes are separated into different folders. It is 10x faster than LabelImg. You can annotate around 6000 images per day (8 hours) using this tool.
If you have multiple objects per image, use https://github.com/udaypk/FastAnnotationMultipleObjects. This is 2x faster than LabelImg.
",1,1
898,2018-2-20,2018,2,20,3,7yos2x,Adversarial Patch (Google Brain),https://www.reddit.com/r/MachineLearning/comments/7yos2x/adversarial_patch_google_brain/,ai_dl,1519064661,,1,1
899,2018-2-20,2018,2,20,3,7yovx2,Best way to model discrete data for Restricted Boltzmann Machines (RBMs)?,https://www.reddit.com/r/MachineLearning/comments/7yovx2/best_way_to_model_discrete_data_for_restricted/,Prykorr,1519065428,[removed],0,1
900,2018-2-20,2018,2,20,3,7yoz2o,"Looking for a good, open, image upscaling model",https://www.reddit.com/r/MachineLearning/comments/7yoz2o/looking_for_a_good_open_image_upscaling_model/,zagdem,1519066059,[removed],0,1
901,2018-2-20,2018,2,20,4,7yp45d,Building a pensieve in tensorflow ...,https://www.reddit.com/r/MachineLearning/comments/7yp45d/building_a_pensieve_in_tensorflow/,[deleted],1519067109,[deleted],0,1
902,2018-2-20,2018,2,20,4,7yp7lc,[P] Building a Pensieve in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/7yp7lc/p_building_a_pensieve_in_tensorflow/,neurokinetikz,1519067781,,5,1
903,2018-2-20,2018,2,20,6,7yq5gu,L4: Practical loss-based stepsize adaptation for deep learning,https://www.reddit.com/r/MachineLearning/comments/7yq5gu/l4_practical_lossbased_stepsize_adaptation_for/,PossibleHomework,1519074325,,0,1
904,2018-2-20,2018,2,20,6,7yqcer,[R] Why even a moths brain is smarter than an AI,https://www.reddit.com/r/MachineLearning/comments/7yqcer/r_why_even_a_moths_brain_is_smarter_than_an_ai/,FineImplement,1519075744,,26,15
905,2018-2-20,2018,2,20,7,7yqrf9,Pattern recognition,https://www.reddit.com/r/MachineLearning/comments/7yqrf9/pattern_recognition/,1out1back,1519078936,[removed],0,1
906,2018-2-20,2018,2,20,7,7yr0b2,How do you optimize a SVM in sklearn?,https://www.reddit.com/r/MachineLearning/comments/7yr0b2/how_do_you_optimize_a_svm_in_sklearn/,Drgoldsz22,1519080941,[removed],0,1
907,2018-2-20,2018,2,20,8,7yre3z,Any masters programs that allow you to substitute experience for a relevant undergrad degree?,https://www.reddit.com/r/MachineLearning/comments/7yre3z/any_masters_programs_that_allow_you_to_substitute/,redditer01,1519084180,[removed],0,1
908,2018-2-20,2018,2,20,9,7yrlww,[P] I made a video tutorial explaining how to use TensorFlow-GPU to train an object detection classifier on Windows!,https://www.reddit.com/r/MachineLearning/comments/7yrlww/p_i_made_a_video_tutorial_explaining_how_to_use/,Taxi-guy,1519086019,,2,0
909,2018-2-20,2018,2,20,9,7yrnqo,Knowledge Graph Inference with Neural Embeddings,https://www.reddit.com/r/MachineLearning/comments/7yrnqo/knowledge_graph_inference_with_neural_embeddings/,bsubs,1519086431,,0,1
910,2018-2-20,2018,2,20,12,7yspf0,I want to get into making my own neural networks. What are some good sources?,https://www.reddit.com/r/MachineLearning/comments/7yspf0/i_want_to_get_into_making_my_own_neural_networks/,NiNmaN8,1519096035,[removed],0,1
911,2018-2-20,2018,2,20,12,7ystse,[R] Twitter Sentiment Analysis using combined LSTM-CNN Models,https://www.reddit.com/r/MachineLearning/comments/7ystse/r_twitter_sentiment_analysis_using_combined/,konukoii,1519097233,,14,9
912,2018-2-20,2018,2,20,13,7yt428,turn your weed eater into a fishing machine,https://www.reddit.com/r/MachineLearning/comments/7yt428/turn_your_weed_eater_into_a_fishing_machine/,fishingiscool253,1519100054,,0,1
913,2018-2-20,2018,2,20,13,7yta6l,5 Must Have Skills To Become a Machine Learning Engineer,https://www.reddit.com/r/MachineLearning/comments/7yta6l/5_must_have_skills_to_become_a_machine_learning/,vinay6666,1519101818,,0,1
914,2018-2-20,2018,2,20,13,7ytcpc,How does machine learning work?,https://www.reddit.com/r/MachineLearning/comments/7ytcpc/how_does_machine_learning_work/,Anusha55,1519102565,,0,1
915,2018-2-20,2018,2,20,14,7ytlda,Building Face Detection Go Bot for Raspberry Pi. Part 2,https://www.reddit.com/r/MachineLearning/comments/7ytlda/building_face_detection_go_bot_for_raspberry_pi/,pltvs,1519105172,,0,1
916,2018-2-20,2018,2,20,15,7yttns,Powder Filling Machine Manufacturers in India,https://www.reddit.com/r/MachineLearning/comments/7yttns/powder_filling_machine_manufacturers_in_india/,pinkypharma,1519107810,,0,1
917,2018-2-20,2018,2,20,15,7ytvpr,The role of chatbots in intelligent enterprise automation,https://www.reddit.com/r/MachineLearning/comments/7ytvpr/the_role_of_chatbots_in_intelligent_enterprise/,botcoreai,1519108477,,0,1
918,2018-2-20,2018,2,20,15,7ytw2e,Screw Conveyor Manufacturer in India,https://www.reddit.com/r/MachineLearning/comments/7ytw2e/screw_conveyor_manufacturer_in_india/,pinkypharma,1519108593,,0,1
919,2018-2-20,2018,2,20,15,7ytxz4,[D] Deploying Pytorch models.,https://www.reddit.com/r/MachineLearning/comments/7ytxz4/d_deploying_pytorch_models/,rbtbot,1519109247,"Let's discuss on how you deploy Pytorch models. Web, mobile, embedded.

Some of the ways I know:

1. Deploy the Python code directly (expose as some web API).
2. Export to ONNX, then to Caffe2
3. Export to Keras, then to Tensorflow (Lite)",14,19
920,2018-2-20,2018,2,20,15,7ytyxa,"Durant products durant counters, controllers &amp; material measuring machines",https://www.reddit.com/r/MachineLearning/comments/7ytyxa/durant_products_durant_counters_controllers/,durantco,1519109605,,0,1
921,2018-2-20,2018,2,20,16,7yu3fb,What is Machine Learning and Does It Matter?,https://www.reddit.com/r/MachineLearning/comments/7yu3fb/what_is_machine_learning_and_does_it_matter/,imarticus_nirmal,1519111159,,0,1
922,2018-2-20,2018,2,20,16,7yu7ea,[R] Exploring meta-learning through quadratics,https://www.reddit.com/r/MachineLearning/comments/7yu7ea/r_exploring_metalearning_through_quadratics/,noahgolm,1519112692,,0,2
923,2018-2-20,2018,2,20,17,7yuako,[D] How does Facebook's Duckling lib work ?,https://www.reddit.com/r/MachineLearning/comments/7yuako/d_how_does_facebooks_duckling_lib_work/,__Julia,1519113928,"Hi,
I am trying to understand the theory behind building facebook library Duckling (https://github.com/facebook/duckling/tree/master/Duckling). What is the theory behind the techniques that they use ? What kind of data do they use to build the parser (ontology) ?.
",5,0
924,2018-2-20,2018,2,20,18,7yuoeb,Genetic Algorithms surpassing Back-propagation,https://www.reddit.com/r/MachineLearning/comments/7yuoeb/genetic_algorithms_surpassing_backpropagation/,[deleted],1519119247,[deleted],0,1
925,2018-2-20,2018,2,20,18,7yurwc,[P] A Beginners Guide to Beating the Bookmakers with TensorFlow,https://www.reddit.com/r/MachineLearning/comments/7yurwc/p_a_beginners_guide_to_beating_the_bookmakers/,[deleted],1519120590,[deleted],0,0
926,2018-2-20,2018,2,20,18,7yusbf,"Toward ethical, transparent and fair AI/ML: a critical reading list",https://www.reddit.com/r/MachineLearning/comments/7yusbf/toward_ethical_transparent_and_fair_aiml_a/,eirini_mal,1519120742,,0,2
927,2018-2-20,2018,2,20,19,7yuv4j,Suggestion for PyBrain Tutorial?,https://www.reddit.com/r/MachineLearning/comments/7yuv4j/suggestion_for_pybrain_tutorial/,Erlandd,1519121726,[removed],0,1
928,2018-2-20,2018,2,20,19,7yuyux,[ML] - Team Battle in unity3d,https://www.reddit.com/r/MachineLearning/comments/7yuyux/ml_team_battle_in_unity3d/,PiotrSkalski,1519123107,,0,1
929,2018-2-20,2018,2,20,20,7yv2mq,[R] Image Transformer (Google Brain),https://www.reddit.com/r/MachineLearning/comments/7yv2mq/r_image_transformer_google_brain/,baylearn,1519124486,,9,26
930,2018-2-20,2018,2,20,20,7yv4t9,SGD with best lr can be consistently beaten!,https://www.reddit.com/r/MachineLearning/comments/7yv4t9/sgd_with_best_lr_can_be_consistently_beaten/,[deleted],1519125198,,0,1
931,2018-2-20,2018,2,20,20,7yv7jy,This optimizer claims to consistently outperform best constant lrs for both SGD and Adam. Can it be true?,https://www.reddit.com/r/MachineLearning/comments/7yv7jy/this_optimizer_claims_to_consistently_outperform/,[deleted],1519126155,,0,1
932,2018-2-20,2018,2,20,21,7yvg1c,ReInventing Neural Networks - Part 3,https://www.reddit.com/r/MachineLearning/comments/7yvg1c/reinventing_neural_networks_part_3/,Byte-Master-101,1519128896,,0,1
933,2018-2-20,2018,2,20,21,7yvml4,This optimizer claims to consistently outperform best constant lrs for both SGD and Adam. Can it be true?,https://www.reddit.com/r/MachineLearning/comments/7yvml4/this_optimizer_claims_to_consistently_outperform/,[deleted],1519130929,,0,1
934,2018-2-20,2018,2,20,21,7yvn2w,[D] Does anyone know if Stanford is going to release this year's CS224n Natural Language Processing with Deep Learning course videos online like this did with last years?,https://www.reddit.com/r/MachineLearning/comments/7yvn2w/d_does_anyone_know_if_stanford_is_going_to/,TeslaCarBot,1519131071,"Last year's videos were great for refreshing on concepts while also getting up to date on what's the basic state of the art of each of the major areas in NLP. 

Anyone know if they're going to release this year's videos too?

Last year's were released late march /early April so I think we have to wait until the course is finished regardless. 

While we're on the topic, are there any other major Machine Learning courses scheduled to be released this year? ",23,138
935,2018-2-20,2018,2,20,21,7yvopu,This optimizer claims to consistently outperform best constant lrs for both SGD and Adam. Can it be true?,https://www.reddit.com/r/MachineLearning/comments/7yvopu/this_optimizer_claims_to_consistently_outperform/,cz_kenny,1519131527,,1,1
936,2018-2-20,2018,2,20,22,7yvri0,Cartoon: Machine Learning Problems in 2118,https://www.reddit.com/r/MachineLearning/comments/7yvri0/cartoon_machine_learning_problems_in_2118/,friscotime,1519132288,,0,1
937,2018-2-20,2018,2,20,22,7yvsu4,convolutional neural net outputs high confidence for a plain white image problem,https://www.reddit.com/r/MachineLearning/comments/7yvsu4/convolutional_neural_net_outputs_high_confidence/,Ralphus_Maximus,1519132650,[removed],0,1
938,2018-2-20,2018,2,20,22,7yvtm4,[R] [1802.06070v1] Diversity is All You Need: Learning Skills without a Reward Function,https://www.reddit.com/r/MachineLearning/comments/7yvtm4/r_180206070v1_diversity_is_all_you_need_learning/,bubaonaruba,1519132875,,24,5
939,2018-2-20,2018,2,20,22,7yvub2,[D]Deformable Convolutions applied to last layers vs Deformable Convolutions applied to earlier layers,https://www.reddit.com/r/MachineLearning/comments/7yvub2/ddeformable_convolutions_applied_to_last_layers/,shamitlal,1519133056,"As per the deformable convolution paper (https://arxiv.org/abs/1703.06211), the authors showed the results by applying deformable convolutions at the last layers. They started from last layers and then showed that results improved as we kept applying deformable convolutions to earlier layers as well. What I couldn't understand is the benefit of applying deformable convolutions to later layers compared to earlier layers. Wouldn't applying it on initial layers help more as it will result in a larger receptive field from the beginning. Later layers anyhow achieve large receptive fields due to the cumulative application of convolution operation.",1,2
940,2018-2-20,2018,2,20,22,7yvxyx,[D] Has (partial) inter-layer weight sharing been attempted on CNN for image classification?,https://www.reddit.com/r/MachineLearning/comments/7yvxyx/d_has_partial_interlayer_weight_sharing_been/,[deleted],1519134061,[deleted],0,1
941,2018-2-20,2018,2,20,22,7yvz05,[P] Detecting toxic comments with multi-task Deep Learning,https://www.reddit.com/r/MachineLearning/comments/7yvz05/p_detecting_toxic_comments_with_multitask_deep/,[deleted],1519134328,[deleted],1,0
942,2018-2-20,2018,2,20,23,7ywbp9,JupyterLab is ready for users,https://www.reddit.com/r/MachineLearning/comments/7ywbp9/jupyterlab_is_ready_for_users/,suddenlyhappy,1519137549,,0,1
943,2018-2-21,2018,2,21,0,7ywhq4,3D body models,https://www.reddit.com/r/MachineLearning/comments/7ywhq4/3d_body_models/,automated_reckoning,1519138928,[removed],0,1
944,2018-2-21,2018,2,21,0,7ywrcd,10 things you need to know from February,https://www.reddit.com/r/MachineLearning/comments/7ywrcd/10_things_you_need_to_know_from_february/,gwen0927,1519140933,,0,1
945,2018-2-21,2018,2,21,0,7yws5q,How to Use Machine Learning in CyberSecurity,https://www.reddit.com/r/MachineLearning/comments/7yws5q/how_to_use_machine_learning_in_cybersecurity/,Jelvix,1519141110,,0,1
946,2018-2-21,2018,2,21,0,7ywv7u,RL: What do you monitor ?,https://www.reddit.com/r/MachineLearning/comments/7ywv7u/rl_what_do_you_monitor/,UpstairsCurrency,1519141765,[removed],0,1
947,2018-2-21,2018,2,21,1,7yx10t,How can I solve the chicken-and-egg problem of starting an AI startup?,https://www.reddit.com/r/MachineLearning/comments/7yx10t/how_can_i_solve_the_chickenandegg_problem_of/,the_usual_unusual,1519142980,[removed],0,1
948,2018-2-21,2018,2,21,1,7yxbrt,[D] The Probability and Statistics Cookbook,https://www.reddit.com/r/MachineLearning/comments/7yxbrt/d_the_probability_and_statistics_cookbook/,sugarhilldt2,1519145153,,1,23
949,2018-2-21,2018,2,21,2,7yxge4,[D] The Policy of Truth,https://www.reddit.com/r/MachineLearning/comments/7yxge4/d_the_policy_of_truth/,sour_losers,1519146092,,28,27
950,2018-2-21,2018,2,21,2,7yxtf3,[R] Assessing Cardiovascular Risk Factors with Computer Vision,https://www.reddit.com/r/MachineLearning/comments/7yxtf3/r_assessing_cardiovascular_risk_factors_with/,Jackal008,1519148711,,4,17
951,2018-2-21,2018,2,21,3,7yy18o,What's the difference between Attention based RNN and LSTM networks?,https://www.reddit.com/r/MachineLearning/comments/7yy18o/whats_the_difference_between_attention_based_rnn/,Thmsrey,1519150229,[removed],0,1
952,2018-2-21,2018,2,21,3,7yy8pk,Visibility and Monitoring for Machine Learning Models,https://www.reddit.com/r/MachineLearning/comments/7yy8pk/visibility_and_monitoring_for_machine_learning/,heitortsergent,1519151752,,0,1
953,2018-2-21,2018,2,21,3,7yycov,[D] Introducing the Uber AI Residency,https://www.reddit.com/r/MachineLearning/comments/7yycov/d_introducing_the_uber_ai_residency/,sksq9,1519152609,,43,48
954,2018-2-21,2018,2,21,3,7yydho,"[R] L4: Practical loss-based stepsize adaptation, ""strongly improving the performance of Adam and Momentum optimizers""",https://www.reddit.com/r/MachineLearning/comments/7yydho/r_l4_practical_lossbased_stepsize_adaptation/,downtownslim,1519152771,,14,14
955,2018-2-21,2018,2,21,5,7yz5hg,Its All in the Eyes: Google AI Calculates Cardiovascular Risk From Retinal Images,https://www.reddit.com/r/MachineLearning/comments/7yz5hg/its_all_in_the_eyes_google_ai_calculates/,gwen0927,1519158196,,0,1
956,2018-2-21,2018,2,21,6,7yzphg,[N]Its All in the Eyes: Google AI Calculates Cardiovascular Risk From Retinal Images,https://www.reddit.com/r/MachineLearning/comments/7yzphg/nits_all_in_the_eyes_google_ai_calculates/,trcytony,1519162041,,13,119
957,2018-2-21,2018,2,21,9,7z15g7,Boston Dynamics updated video for robot opening door,https://www.reddit.com/r/MachineLearning/comments/7z15g7/boston_dynamics_updated_video_for_robot_opening/,sunrisetofu,1519173154,,0,1
958,2018-2-21,2018,2,21,9,7z17jr,"[Question] NLP ""Topic Determination""",https://www.reddit.com/r/MachineLearning/comments/7z17jr/question_nlp_topic_determination/,jstyler,1519173640,[removed],0,1
959,2018-2-21,2018,2,21,12,7z2927,JupyterLab,https://www.reddit.com/r/MachineLearning/comments/7z2927/jupyterlab/,keyurparalkar,1519182385,,0,1
960,2018-2-21,2018,2,21,12,7z29k5,Is there a format similar to ONNX for tree and tree ensemble algorithms?,https://www.reddit.com/r/MachineLearning/comments/7z29k5/is_there_a_format_similar_to_onnx_for_tree_and/,julito_power,1519182510,[removed],0,1
961,2018-2-21,2018,2,21,13,7z2u1c,Best Machine Learning Course in Bangalore,https://www.reddit.com/r/MachineLearning/comments/7z2u1c/best_machine_learning_course_in_bangalore/,pavanear,1519187722,,0,1
962,2018-2-21,2018,2,21,14,7z34h5,"Fiber Laser Machine, Fiber Laser Cutting",https://www.reddit.com/r/MachineLearning/comments/7z34h5/fiber_laser_machine_fiber_laser_cutting/,Messer-123,1519190449,,0,1
963,2018-2-21,2018,2,21,14,7z36lk,What is the difference between Mechanical Seal and Gland Packing? | LEAK-PACK,https://www.reddit.com/r/MachineLearning/comments/7z36lk/what_is_the_difference_between_mechanical_seal/,LeakPack,1519191035,,0,1
964,2018-2-21,2018,2,21,14,7z3977,Stanford Machine Learning Coursera Course,https://www.reddit.com/r/MachineLearning/comments/7z3977/stanford_machine_learning_coursera_course/,Comeawn123,1519191789,[removed],0,1
965,2018-2-21,2018,2,21,14,7z3bmw,[D] Why We Need Type-Checked Neural Network,https://www.reddit.com/r/MachineLearning/comments/7z3bmw/d_why_we_need_typechecked_neural_network/,0b01,1519192501,,20,0
966,2018-2-21,2018,2,21,15,7z3d9m,[P] Tensorflow FizzBuzz Redux,https://www.reddit.com/r/MachineLearning/comments/7z3d9m/p_tensorflow_fizzbuzz_redux/,0b01,1519192967,,5,15
967,2018-2-21,2018,2,21,15,7z3j2q,How to implement my own DBMS?,https://www.reddit.com/r/MachineLearning/comments/7z3j2q/how_to_implement_my_own_dbms/,kushaj,1519194726,[removed],0,1
968,2018-2-21,2018,2,21,16,7z3q2s,Customer churn predictions for banking without dependent variable,https://www.reddit.com/r/MachineLearning/comments/7z3q2s/customer_churn_predictions_for_banking_without/,Chaitanya_478,1519196919,[removed],0,1
969,2018-2-21,2018,2,21,16,7z3vvb,[P] Image completion using incomplete data,https://www.reddit.com/r/MachineLearning/comments/7z3vvb/p_image_completion_using_incomplete_data/,_sshin_,1519198901,,43,336
970,2018-2-21,2018,2,21,17,7z44hw,"Which Machine Learning Algortihms work for finding tasker like ""if ... then ..."" rules?",https://www.reddit.com/r/MachineLearning/comments/7z44hw/which_machine_learning_algortihms_work_for/,[deleted],1519202230,,0,1
971,2018-2-21,2018,2,21,17,7z463x,[N] OpenAI Supporters,https://www.reddit.com/r/MachineLearning/comments/7z463x/n_openai_supporters/,Jackal008,1519202899,,11,10
972,2018-2-21,2018,2,21,17,7z466n,[R] Preparing for Malicious Uses of AI,https://www.reddit.com/r/MachineLearning/comments/7z466n/r_preparing_for_malicious_uses_of_ai/,Jackal008,1519202930,,11,14
973,2018-2-21,2018,2,21,17,7z46oc,[R] Neural Voice Cloning with a Few Samples - Baidu Research,https://www.reddit.com/r/MachineLearning/comments/7z46oc/r_neural_voice_cloning_with_a_few_samples_baidu/,Jackal008,1519203144,,21,37
974,2018-2-21,2018,2,21,18,7z4cvv,Good Master Thesis Topic,https://www.reddit.com/r/MachineLearning/comments/7z4cvv/good_master_thesis_topic/,alpha_ma,1519205497,[removed],0,1
975,2018-2-21,2018,2,21,18,7z4gk5,Has anyone successfully used Progressive Growing of GANs ?,https://www.reddit.com/r/MachineLearning/comments/7z4gk5/has_anyone_successfully_used_progressive_growing/,gohu_cd,1519206961,[removed],0,1
976,2018-2-21,2018,2,21,19,7z4j1y,[D] Do electric moths sniff on MNIST?,https://www.reddit.com/r/MachineLearning/comments/7z4j1y/d_do_electric_moths_sniff_on_mnist/,hardmaru,1519207922,,9,27
977,2018-2-21,2018,2,21,19,7z4mwb,[P] Using Deep Learning for Structured Data with Entity Embeddings,https://www.reddit.com/r/MachineLearning/comments/7z4mwb/p_using_deep_learning_for_structured_data_with/,ruizendaalr,1519209370,,3,1
978,2018-2-21,2018,2,21,19,7z4pgs,[P] Predicting Continent given City names using PyTorch,https://www.reddit.com/r/MachineLearning/comments/7z4pgs/p_predicting_continent_given_city_names_using/,junkwhinger,1519210320,,11,6
979,2018-2-21,2018,2,21,20,7z4r5o,Where do you guys find ML/DL easy to read papers ?,https://www.reddit.com/r/MachineLearning/comments/7z4r5o/where_do_you_guys_find_mldl_easy_to_read_papers/,Nyd3r,1519210920,[removed],0,1
980,2018-2-21,2018,2,21,20,7z4upk,"[R]""Dropin"" regularization",https://www.reddit.com/r/MachineLearning/comments/7z4upk/rdropin_regularization/,godspeed_china,1519212175,"Dropout zero some variables, however it hurts the data. I propose a better way called ""dropin"" by extend your feature vector with one complete random variable. This random variable will steal credit from real variables and never be zero weighted. Thus the optimizer can never fit the data completely. Compared to dropout, it is much merciful.",3,0
981,2018-2-21,2018,2,21,20,7z4wnu,How Stream Processing Will Revamp The Big Data Landscape,https://www.reddit.com/r/MachineLearning/comments/7z4wnu/how_stream_processing_will_revamp_the_big_data/,digitalmarketingrobi,1519212885,,0,1
982,2018-2-21,2018,2,21,20,7z507x,Machine Learning on Netflix Prize Data,https://www.reddit.com/r/MachineLearning/comments/7z507x/machine_learning_on_netflix_prize_data/,23nicky5,1519214130,[removed],0,1
983,2018-2-21,2018,2,21,21,7z57lg,[D] 2018 AI Residency Programs List,https://www.reddit.com/r/MachineLearning/comments/7z57lg/d_2018_ai_residency_programs_list/,sritee,1519216453,,2,4
984,2018-2-21,2018,2,21,21,7z589y,"[R] Gentle Introduction to Eigendecomposition, Eigenvalues, and Eigenvectors for Machine Learning",https://www.reddit.com/r/MachineLearning/comments/7z589y/r_gentle_introduction_to_eigendecomposition/,polllyyy,1519216661,,0,1
985,2018-2-21,2018,2,21,22,7z5cu4,Best practices for organizing a pytorch project?,https://www.reddit.com/r/MachineLearning/comments/7z5cu4/best_practices_for_organizing_a_pytorch_project/,hologram13,1519218065,[removed],0,1
986,2018-2-21,2018,2,21,22,7z5j3s,My C++ deep learning framework (2 years of work),https://www.reddit.com/r/MachineLearning/comments/7z5j3s/my_c_deep_learning_framework_2_years_of_work/,[deleted],1519219819,[deleted],0,1
987,2018-2-21,2018,2,21,23,7z5v1c,[D] @ MILA/UdeM Applicants - Please comment with your updates!,https://www.reddit.com/r/MachineLearning/comments/7z5v1c/d_milaudem_applicants_please_comment_with_your/,3129381,1519222882,,4,0
988,2018-2-21,2018,2,21,23,7z5zrx,[D] Tech companies should stop pretending AI wont destroy jobs,https://www.reddit.com/r/MachineLearning/comments/7z5zrx/d_tech_companies_should_stop_pretending_ai_wont/,zachsmthsn,1519224064,,18,8
989,2018-2-22,2018,2,22,0,7z6jnt,"Simple Questions Thread February 21, 2018",https://www.reddit.com/r/MachineLearning/comments/7z6jnt/simple_questions_thread_february_21_2018/,AutoModerator,1519228540,[removed],0,1
990,2018-2-22,2018,2,22,1,7z6xtr,Current Undergrad Looking for Career Pathway Advice,https://www.reddit.com/r/MachineLearning/comments/7z6xtr/current_undergrad_looking_for_career_pathway/,jgmz-,1519231498,[removed],0,1
991,2018-2-22,2018,2,22,1,7z6zb2,[P] rowdsourced tool to make bounded boxes for only 0.01$ per image!,https://www.reddit.com/r/MachineLearning/comments/7z6zb2/p_rowdsourced_tool_to_make_bounded_boxes_for/,mnill,1519231786,,4,7
992,2018-2-22,2018,2,22,3,7z7uok,[D] Fruitful Papers for Trying to Reproduce Results,https://www.reddit.com/r/MachineLearning/comments/7z7uok/d_fruitful_papers_for_trying_to_reproduce_results/,kleinergauss,1519238151,"I am taking a university course, where I will have to reproduce the results of a *recent* ML paper in 3 months. It should be feasible with a low budget as I don't have 10 GPUs lying around.

What papers can you recommend?",11,12
993,2018-2-22,2018,2,22,3,7z7zz9,Let's implement a Gaussian Naive Bayes classifier in Python,https://www.reddit.com/r/MachineLearning/comments/7z7zz9/lets_implement_a_gaussian_naive_bayes_classifier/,antoniomallia,1519239260,,0,1
994,2018-2-22,2018,2,22,4,7z85ce,Which deep learning course should I choose?,https://www.reddit.com/r/MachineLearning/comments/7z85ce/which_deep_learning_course_should_i_choose/,gtmshrm,1519240386,[removed],0,1
995,2018-2-22,2018,2,22,4,7z897y,[D] TRAINING loss curve moves up,https://www.reddit.com/r/MachineLearning/comments/7z897y/d_training_loss_curve_moves_up/,sauhaarda,1519241146,"My training loss curve initially moves down asymptotically, and after leveling out begins to rise up again. I've seen this behavior with validation loss (sign of over fitting) but never with training loss. What could be causing this issue?",6,0
996,2018-2-22,2018,2,22,4,7z8fpz,"Without using Python library for EM algorithm, how can one implement it for iris data set?",https://www.reddit.com/r/MachineLearning/comments/7z8fpz/without_using_python_library_for_em_algorithm_how/,aditin93,1519242468,[removed],0,1
997,2018-2-22,2018,2,22,5,7z8zi0,[D] Thoughts on CMU's Master of Language Technologies program?,https://www.reddit.com/r/MachineLearning/comments/7z8zi0/d_thoughts_on_cmus_master_of_language/,CrazyFart,1519246503,,13,4
998,2018-2-22,2018,2,22,5,7z8zzz,[D] Four Deep learning trends from ACL 2017,https://www.reddit.com/r/MachineLearning/comments/7z8zzz/d_four_deep_learning_trends_from_acl_2017/,tshrjn,1519246604,,6,25
999,2018-2-22,2018,2,22,7,7z9j2a,[D] Error Bars or No for a Deep Learning paper?,https://www.reddit.com/r/MachineLearning/comments/7z9j2a/d_error_bars_or_no_for_a_deep_learning_paper/,sauhaarda,1519250646,"For a paper I'm writing I'm conflicted on whether or not to include error bars when comparing two models (Red and Blue in images below). I'm conflicted b/c the error bars don't actually reflect the accuracy of the comparison of the two models but rather the accuracy of each of the individual loss functions. Should the error bars be included or are they not relevant?

https://imgur.com/a/widMZ

Edit:
Sorry I didn't clarify this earlier but each line is the average of 8 experiments each with the same validation and training dataset except shuffled differently in each epoch.",10,1
1000,2018-2-22,2018,2,22,8,7za5md,Baidu AI Can Clone Your Voice in Seconds,https://www.reddit.com/r/MachineLearning/comments/7za5md/baidu_ai_can_clone_your_voice_in_seconds/,[deleted],1519255718,[deleted],0,1
1001,2018-2-22,2018,2,22,8,7za8lx,Comparison of machine learning methods in email spam detection,https://www.reddit.com/r/MachineLearning/comments/7za8lx/comparison_of_machine_learning_methods_in_email/,matchilling,1519256432,,0,1
1002,2018-2-22,2018,2,22,9,7zalp4,[N] Forge.AI: Fueling Machine Intelligence with Unstructured Data,https://www.reddit.com/r/MachineLearning/comments/7zalp4/n_forgeai_fueling_machine_intelligence_with/,tmarkovich,1519259504,,0,1
1003,2018-2-22,2018,2,22,9,7zaq55,Of possible interest to EC practitioners,https://www.reddit.com/r/MachineLearning/comments/7zaq55/of_possible_interest_to_ec_practitioners/,[deleted],1519260517,[deleted],0,1
1004,2018-2-22,2018,2,22,10,7zati1,Is machine learning good for humanity,https://www.reddit.com/r/MachineLearning/comments/7zati1/is_machine_learning_good_for_humanity/,DopeAsPope,1519261315,[removed],0,1
1005,2018-2-22,2018,2,22,10,7zavnh,"New paper, of interest to EC practitioners: ""Investigating the parameter space of evolutionary algorithms""",https://www.reddit.com/r/MachineLearning/comments/7zavnh/new_paper_of_interest_to_ec_practitioners/,moshesipper,1519261862,,0,1
1006,2018-2-22,2018,2,22,10,7zayvs,[R] SCUT-FBP5500: A Diverse Benchmark Dataset for Multi-Paradigm Facial Beauty Prediction,https://www.reddit.com/r/MachineLearning/comments/7zayvs/r_scutfbp5500_a_diverse_benchmark_dataset_for/,wei_jok,1519262647,,13,2
1007,2018-2-22,2018,2,22,10,7zb2jm,[N] Baidu AI Can Clone Your Voice in Seconds,https://www.reddit.com/r/MachineLearning/comments/7zb2jm/n_baidu_ai_can_clone_your_voice_in_seconds/,gwen0927,1519263586,,33,31
1008,2018-2-22,2018,2,22,10,7zb75c,[P] UFC Predictive Model using Random Forest - posting results for next UFC event,https://www.reddit.com/r/MachineLearning/comments/7zb75c/p_ufc_predictive_model_using_random_forest/,montanaro94,1519264745,"Hey guys,

I posted this in the the mma subreddit but it might be better suited here. 

I've been working on this 'hobby' project for over a month now, and I'd like to detail how I built the model and share my predictions with you. Just to make my intentions clear before people start suggesting that I want to sell access to my predictions in the future or accusing me of being a scammer, I'm not. I'm sharing this in order to get feedbacks and suggestions on the model and the validate the idea behind it, before I actually do bet on future events. I'm also glad to share the process with anyone interested in this.

First, here's this event's predictions: https://ibb.co/cRxXqx

Now an explanation of the whole process:

Basically, I began building my database (db) of fights by crawling a famous fight database (I'm not specifying whichpne for legal reasons) using Python. I first go to the fighter's page, collect their data into one dataframe (df), access individually each fight they've participated in and append the data from the fight to a separate df. Once all the fights are collected, I move on to the next fighter.

My current db has 12k fights from 1990 onwards and about 3k fighters.

I then process all of this data so that the fight's metrics (significant strikes landed, attempted, takedowns, etc) shown per fight aren't the current fight's, but rather those of the last, last 2,3,4 and 5 fights of each fighter, per minute fought. This way, I can predict future fights using metrics from older fights.

I'm also using the fighter's stats (age difference, reach difference, etc) and something I like to call 'arbitrary score', which is based on the method they won their last fight(s).

I'm currently considering the following points, from 0.5-1, per fight, for the winner (the loser gets 1-points for the winner): - Submission, TKO, KO: -- Over 10 mins: 0.8 -- Over 5 mins, Under 10 mins: 0.9 -- Over 2.5 mins, Under 5 mins: 0.975 -- Over 1.75 mins, Under 2.5 mins: 0.9825 -- Under 1.75 mins: 1 - UDEC: 0.875 - MDEC: 0.75 - SDEC: 0.625 - DQ, Overturned, Could not continue: 0.5

As far as I can tell, this is the most flawed part of the process, since I'm assigning values to non-numerical data in a method that can be biased. I've thought of creating categorical scores by concatenating the last fight's method of win, but I'm not sure this will be efficient since I'll have &gt;3k combinations when considering the last 5 fights and the predictive model will have no idea what to do with a novel result. Any ideas here?

I have a lot of missing data, since many fighters only fought once and this fight will have no data from previous fight, previous last 2 fights, and so on. First fights from all fighters also suffer from this problem. To fix this, I assign the median of every column to missing values (excluding rows with missing values reduces my observations from 11k to 1k, more than a 90% reduction!). I'm also careful with duplicates, since every fight appears twice due to the method of crawling I chose (once per fighter involved in the fight). By the end of all the data cleaning, I'm left with just over 5k rows and about 40 columns of independent variables.

Once all the data of a fight is relative to past fights, I then start building the model, on python. I'm using a random forest classifier, tweaked with parameters to maximize accuracy.

Now, the golden question, what is the model's current accuracy? About 71%. I've done cross validation, splitting the df into train and test, with a lot of different tweaks and trying different methods, this was the best accuracy (recall) I could achieve.

From there, all I do is pass on the fights I want to predict (always making sure to use previous fight's metrics) and predict the probability of f1 winning.

That's where most of the info in my predictions posted above comes from. Some of the fighters appear as 'no bet', even though they seem pretty favourable, because they have missing data and the model used the median to calculate some of their independent variables. I'm considering the limit of missing values per fight predicted to be 7 (out of 41), just over 15%. So I do calculate their odds of winning, but I wouldn't bet on that due to the amount of missing data.

For the next model's I'll be looking into camp data and hometown advantage, as suggested by two users in my last post. These might be interesting and don't require much processing, just figuring out where to scrape it from.

I've also found out that my 'arbitrary score' for the past fights was being largely ignored by the model. When I remove it from the model, the accuracy remains the same, around 71% (72% AUC Score, 71% f1-score, 71% recall).

Looking for suggestions to incorporate the past method of win (KO, Sub, Udec, etc) into the model, I'm having a hard time figuring this one out. The main challenge here is how to get past 5 fights data into one cell and have the model understand it. If I just concatenate the names of the method and the time of the fight (900 seconds * (5 methods of win ^ 5 = 10*1018), that'll just be garbage for the model. Ideas?

Disclaimer: DO NOT bet on these predictions. This is still a work in progress and I don't guarantee results. Don't blame me if all of the predictions turn out to be wrong.",4,0
1009,2018-2-22,2018,2,22,11,7zba4y,Does anyone here have experience with deep learning studio?,https://www.reddit.com/r/MachineLearning/comments/7zba4y/does_anyone_here_have_experience_with_deep/,pk7677,1519265507,[removed],0,1
1010,2018-2-22,2018,2,22,11,7zbd51,"[P] [OC] We made a music video using neural style transfert, optical flow, and Deep dream. It's been a year since we are working on it. Please, give us some feedback ! [more infos in comments]",https://www.reddit.com/r/MachineLearning/comments/7zbd51/p_oc_we_made_a_music_video_using_neural_style/,HAH_official,1519266278,,63,255
1011,2018-2-22,2018,2,22,11,7zbhkl,[P] Please give me feedback on my ML/NLP recommendation system,https://www.reddit.com/r/MachineLearning/comments/7zbhkl/p_please_give_me_feedback_on_my_mlnlp/,Subtle__,1519267395,"Hi,

I'm very new to machine learning and I've been starting out with Python / scikit-learn. I recently built a content-based recommendation system for NuGet packages, and I'm in discussions with the NuGet team to integrate my system into their site. (For those of you unfamiliar, NuGet is the package manager for C#.) [Here](https://www.nuget.org/packages/Newtonsoft.Json) is the webpage for a sample package on NuGet.org: you can see that each package has metadata like an ID, description, tags, that will prove useful in deciding whether two packages are relevant.

I'll give you a detailed rundown of how the algorithm works. I gathered a large number of packages (~4500) using the NuGet API; I'll refer to this number as m. I computed an m x m matrix of scores, M, where M[i, j] represents a 'score' of how relevant package j is to package i. To get the top 5 recommendations for a given package i, I selected the packages corresponding to the 5 highest scores in M[i].

To compute M, first I took a weighted average of 3 m x m matrices. [Here is the relevant code.](https://github.com/jamesqo/nuget_recommender/blob/master/NugetRecommender.py#L55-L75) The first matrix, based on the authors attribute, computed an m x t matrix of TF-IDF scores for bigrams in the packages, then called linear_kernel to get the cosine similarities. The second matrix did something similar but was based on the description instead.

The third matrix was more complicated to compute. First, I added a new field 'etags' (standing for ""enriched tags"") to each package. An etag is a tag with an associated weight. The idea was that people would often talk say ""this is a great JSON MVVM lightweight NoSQL parser"" in the description, but they wouldn't explicitly tag their package [json], [mvvm], etc. To generate the etags, I tokenized the description / id of the package and went looking for words that corresponded to a tag. If I saw ""JSON"", I would add the  [json] etag. Each etag's weight was based on how many times it was seen and whether it was seen in the description/id/tags fields.

To generate the m x m matrix for etags, I built an m x t matrix (t being the number of distinct tags) where M[i, j] represented the weight of package i along tag j. I then ran linear_kernel again to get cosine similarities.

After I took a weighted average, I scaled the scores according to 2 metrics I made up: popularity and 'freshness' (ex. a package that hasn't been updated for a while would have low freshness). [Relevant code.](https://github.com/jamesqo/nuget_recommender/blob/master/NugetRecommender.py#L77-L118)

To compute the 'popularity' p, first I took the average downloads per day of a package. Since this metric can vary widely (the most popular packages have 40k+ downloads per day, others have &lt;1 on average) I first took the log. I then computed popularity as   
 
    \# ldpd stands for log downloads per day
    p = ((ldpd - mean_ldpd) / max_ldpd) + 1

I then adjusted p based on a hyperparameter `min_scale_popularity`, to possibly reduce the extent of scaling:

    adjusted_p  = p * 1 + (1 - p) * self.min_scale_popularity

Finally I scaled all of the scores in the corresponding column by `adjusted_p`, making the package more/less relevant to every other package.

I'm looking for any feedback you have on my system, specifically in these areas:

- How can I select the best hyperparameters for my system when there are no labels? (This essentially seems like an unsupervised learning task, and I couldn't create labels even if I wanted to because there are no ""best"" recommendations)
  - The way I fine-tuned all the different weights involved was by manually running the app and looking through the recs each time.

- I feel like I reinvented the wheel somewhat in some areas. Out of anything I described above, is there existing ML methodology to accomplish similar results? e.g. scaling by popularity, generating etags

- While generating etags, I noticed there were surprisingly some junk (not programming-related) tags like 'our', 'the', 'it', etc. used by a few packages. To prevent linking packages that used these words in their descriptions to packages tagged with these junk tags, I only added to the weight of a tag if a non-English term was found in the description (many programming-related words aren't standard English). e.g. Finding ""MVVM"" would increase a package's correlation to the [mvvm] tag, but ""the"" wouldn't increase correlation to the [the] tag because ""the"" is English.
  - Not all of the junk tags were stop words unfortunately, so I can't just filter for those.
  - Unfortunately excluding English words means that finding e.g. ""cryptography"" in the description doesn't connect it more strongly to the [cryptography] tag.

- Since the above approach has flaws, can you suggest a different way for me to tell whether a given word is related to programming so I don't miss out on terms like [cryptography]? Would LDA be something to look into?

- Any suggestions for other attributes I should take into account to improve the algorithm?

Any other feedback you have is welcome. Thanks.

[Link to repo](https://github.com/jamesqo/nuget_recommender/blob/master/main.py#L125)",2,0
1012,2018-2-22,2018,2,22,13,7zc14e,[D] Googles new ad service uses machine learning to place ads,https://www.reddit.com/r/MachineLearning/comments/7zc14e/d_googles_new_ad_service_uses_machine_learning_to/,devinthepickle,1519272661,,2,0
1013,2018-2-22,2018,2,22,14,7zce68,How to optimize training CNNs on GPUs?,https://www.reddit.com/r/MachineLearning/comments/7zce68/how_to_optimize_training_cnns_on_gpus/,Talos19,1519276363,[removed],0,1
1014,2018-2-22,2018,2,22,14,7zchb9,[D]Inference Network VS Bayesian regression,https://www.reddit.com/r/MachineLearning/comments/7zchb9/dinference_network_vs_bayesian_regression/,wsxiaoys,1519277295,"1. Inference Network: http://edwardlib.org/tutorials/inference-networks
NN produce parameter of a distribution. Example: Encoder in Variational AutoEncoder

2. Bayesian Regression: http://edwardlib.org/tutorials/supervised-regression &amp; http://edwardlib.org/tutorials/bayesian-neural-network
Basically parameters of model will have a prior distribution, thus posterior is naturally a distribution.

My understanding is that both has the ability to output an predictive distribution of a new data point x*. But I find few discussion on differences between them other than mathematical foundations.

In which scene should an Inference Network be preferred over Bayesian neural network, and vice versa?",3,4
1015,2018-2-22,2018,2,22,15,7zctdi,Github's Star Predictor,https://www.reddit.com/r/MachineLearning/comments/7zctdi/githubs_star_predictor/,[deleted],1519281106,,0,1
1016,2018-2-22,2018,2,22,15,7zctis,Need Urgent Help (Building a Deep Learning Workstation under 20000$),https://www.reddit.com/r/MachineLearning/comments/7zctis/need_urgent_help_building_a_deep_learning/,kazi_shezan,1519281151,[removed],0,1
1017,2018-2-22,2018,2,22,15,7zcx3g,Machine Learning vs Deep Learning vs Artificial Intelligence - Are they really all that different?,https://www.reddit.com/r/MachineLearning/comments/7zcx3g/machine_learning_vs_deep_learning_vs_artificial/,pooja307,1519282415,,0,1
1018,2018-2-22,2018,2,22,16,7zcy91,Github Repository's Star Predictor,https://www.reddit.com/r/MachineLearning/comments/7zcy91/github_repositorys_star_predictor/,[deleted],1519282850,,0,1
1019,2018-2-22,2018,2,22,16,7zd03a,Github Repository's Star Predictor,https://www.reddit.com/r/MachineLearning/comments/7zd03a/github_repositorys_star_predictor/,himanshuarora97,1519283450,[removed],0,1
1020,2018-2-22,2018,2,22,18,7zdojw,Where can i get retrainable Word2Vec model pretrained on large dataset?,https://www.reddit.com/r/MachineLearning/comments/7zdojw/where_can_i_get_retrainable_word2vec_model/,dk1709,1519291776,[removed],0,1
1021,2018-2-22,2018,2,22,18,7zdtug,[R] A mixed-scale dense convolutional neural network for image analysis,https://www.reddit.com/r/MachineLearning/comments/7zdtug/r_a_mixedscale_dense_convolutional_neural_network/,757cbdb0b61385577130,1519293532,"Title: A mixed-scale dense convolutional neural network for image analysis

Journal: PNAS 2018 January, 115 (2) 254-259

DOI: 10.1073/pnas.1715832114

PNAS link: http://www.pnas.org/content/115/2/254

Publicly accessible PDF: https://slidecam-camera.lbl.gov/static/asset/PNAS.pdf


Abstract:

Deep convolutional neural networks have been successfully applied to many image-processing problems in recent works. Popular network architectures often add additional operations and connections to the standard architecture to enable training deeper networks. To achieve accurate results in practice, a large number of trainable parameters are often required. Here, we introduce a network architecture based on using dilated convolutions to capture features at different image scales and densely connecting all feature maps with each other. The resulting architecture is able to achieve accurate results with relatively few parameters and consists of a single set of operations, making it easier to implement, train, and apply in practice, and automatically adapts to different problems. We compare results of the proposed network architecture with popular existing architectures for several segmentation problems, showing that the proposed architecture is able to achieve accurate results with fewer parameters, with a reduced risk of overfitting the training data.
",6,8
1022,2018-2-22,2018,2,22,19,7ze3jl,Wet Wipes Packing Machine Suppliers,https://www.reddit.com/r/MachineLearning/comments/7ze3jl/wet_wipes_packing_machine_suppliers/,lgsherry,1519297140,,1,1
1023,2018-2-22,2018,2,22,21,7zeeyy,How AI is transforming the manufacturing Industry?,https://www.reddit.com/r/MachineLearning/comments/7zeeyy/how_ai_is_transforming_the_manufacturing_industry/,digitalmarketingrobi,1519301137,,0,1
1024,2018-2-22,2018,2,22,21,7zeg2t,Creating a Bright &amp;amp; Brilliant Future with Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7zeg2t/creating_a_bright_amp_brilliant_future_with/,ciaracodes,1519301499,,0,1
1025,2018-2-22,2018,2,22,21,7zel3c,[D] Research / iteration methodology,https://www.reddit.com/r/MachineLearning/comments/7zel3c/d_research_iteration_methodology/,princesspomodoro,1519303111,"Hi fellow reditters (?), asking for objective guidlines for a subjective cause, here.

I've been doing machine learning projects for a while now and I find myself getting very intimidated by the number of Arxiv preprints put up everyday. And to exacerbate the anxiety, I have a vested interest in LEARNING EVERYTHING and we all know trying to reproduce every other paper you come across would be a fruitless attempt. 

At what point or how did you reach the stage where you branched into a particular subfield and how did you pick the application associated with it?

Also, how did you compartmentalize the phases of your research methodology from picking a topic/ reading literature /iterating and publishing, INDEPENDENT OF WHO FUNDS YOU/ WHAT YOUR JOB ENTAILS.

Eg. If you're a PhD student, what led you to pursue that subfield prior to knowing your advisor and why didn't you venture into anything else?


Sorry for the long post, but I'm curious and desperate to be more organized regarding these matters.",13,0
1026,2018-2-22,2018,2,22,21,7zennc,"[N] Weekly Machine Learning Opensource Roundup  Feb. 22, 2018",https://www.reddit.com/r/MachineLearning/comments/7zennc/n_weekly_machine_learning_opensource_roundup_feb/,stkim1,1519303887,,0,1
1027,2018-2-22,2018,2,22,22,7zepot,Reccomended OS and resources for beginners,https://www.reddit.com/r/MachineLearning/comments/7zepot/reccomended_os_and_resources_for_beginners/,[deleted],1519304514,,0,1
1028,2018-2-22,2018,2,22,22,7zeqqq,"[D] It seems alot of State 0f Art methods were introduced/accepted/established in 2014/2015 (relu, batch processing, GRUs, etc). Will this rate of discovery extend to 2016/2017 and it's just that time is needed for those techniques to be established? Or was there something special about 2014/2015 ?",https://www.reddit.com/r/MachineLearning/comments/7zeqqq/d_it_seems_alot_of_state_0f_art_methods_were/,Batmantosh,1519304829,"And if the rate of discovery extends to 2016/2017, what do you predict from these years will become new state of art methods? ",14,11
1029,2018-2-22,2018,2,22,22,7zetnq,[P] [OC] A lite genetic algorithm library,https://www.reddit.com/r/MachineLearning/comments/7zetnq/p_oc_a_lite_genetic_algorithm_library/,M7homson,1519305663,,5,20
1030,2018-2-22,2018,2,22,22,7zewwz,Essential Tools of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7zewwz/essential_tools_of_machine_learning/,john-fernandes,1519306576,,1,1
1031,2018-2-22,2018,2,22,23,7zfbxt,Error in Neural Network,https://www.reddit.com/r/MachineLearning/comments/7zfbxt/error_in_neural_network/,greyghost1991,1519310450,[removed],0,1
1032,2018-2-23,2018,2,23,1,7zg018,Understanding how to batch and feed data into a stateful LSTM,https://www.reddit.com/r/MachineLearning/comments/7zg018/understanding_how_to_batch_and_feed_data_into_a/,JustinQueeber,1519315899,[removed],0,1
1033,2018-2-23,2018,2,23,1,7zg24g,Problematic Papers: A Diverse Benchmark Dataset for Multi-Paradigm Facial Beauty Prediction,https://www.reddit.com/r/MachineLearning/comments/7zg24g/problematic_papers_a_diverse_benchmark_dataset/,[deleted],1519316341,,0,1
1034,2018-2-23,2018,2,23,1,7zg5cp,In what cases should I try binning my target variable?,https://www.reddit.com/r/MachineLearning/comments/7zg5cp/in_what_cases_should_i_try_binning_my_target/,arrow113,1519317005,[removed],0,1
1035,2018-2-23,2018,2,23,1,7zg7dl,Getting started with TensorFlow on iOS,https://www.reddit.com/r/MachineLearning/comments/7zg7dl/getting_started_with_tensorflow_on_ios/,gejjaxxita,1519317437,,0,1
1036,2018-2-23,2018,2,23,1,7zg9h5,[D] Anyone have any experience using SharpestMinds as a job-hunting tool?,https://www.reddit.com/r/MachineLearning/comments/7zg9h5/d_anyone_have_any_experience_using_sharpestminds/,zachsmthsn,1519317906,,13,3
1037,2018-2-23,2018,2,23,1,7zga8j,Need Hoodie Ideas,https://www.reddit.com/r/MachineLearning/comments/7zga8j/need_hoodie_ideas/,MaleficentRound,1519318050,[removed],0,1
1038,2018-2-23,2018,2,23,1,7zgdpw,"Dealing with ""Bad"" Data",https://www.reddit.com/r/MachineLearning/comments/7zgdpw/dealing_with_bad_data/,wildbk33,1519318762,,0,1
1039,2018-2-23,2018,2,23,2,7zgg4x,"""Continual Lifelong Learning with Neural Networks: A Review"", Parisi et al 2018",https://www.reddit.com/r/MachineLearning/comments/7zgg4x/continual_lifelong_learning_with_neural_networks/,gwern,1519319260,,0,1
1040,2018-2-23,2018,2,23,2,7zgnok,[P] NEAT powered NES Mario Bot (inspired by SethBling),https://www.reddit.com/r/MachineLearning/comments/7zgnok/p_neat_powered_nes_mario_bot_inspired_by_sethbling/,gogoredit,1519320875,,9,2
1041,2018-2-23,2018,2,23,2,7zgosq,[P] How to create a machine learning framework from scratch in 491 steps: An in-depth post mortem of our high school thesis,https://www.reddit.com/r/MachineLearning/comments/7zgosq/p_how_to_create_a_machine_learning_framework_from/,flotothemoon,1519321116,,39,159
1042,2018-2-23,2018,2,23,2,7zgug5,[D] Which approach is suitable for solving continuous reinforcment learning tasks?,https://www.reddit.com/r/MachineLearning/comments/7zgug5/d_which_approach_is_suitable_for_solving/,questionm4ster,1519322286,"Hello everyone,
I'm currently studying some RL approaches from the well-known book(draft) of Sutton &amp; Barto and have some problems in understanding approaches that solve continuing tasks (/non episodic task).

Common algorithms like Q-Learning, Sarsa and Monte Carlo Control seem to require at leat one terminal-state to learn an optimal policy.
The question that comes in my mind is, whether those algorithms can also be used for a continuing tasks, which ?don't have a final state?.

Thank you.",12,1
1043,2018-2-23,2018,2,23,3,7zh2j7,Testing Nvidia GTX 1050 on Generative Adversarial Network (GAN) [Dell inspiron 5577],https://www.reddit.com/r/MachineLearning/comments/7zh2j7/testing_nvidia_gtx_1050_on_generative_adversarial/,keyurparalkar,1519323909,,0,1
1044,2018-2-23,2018,2,23,3,7zh7xg,[Discussion] When will ICLR submissions be indexed by Google Scholar?,https://www.reddit.com/r/MachineLearning/comments/7zh7xg/discussion_when_will_iclr_submissions_be_indexed/,TheNewFake,1519325022,"I've been wanting to find some interesting papers in my area submitted to ICLR 2018 by searching for keywords. Scholar is great for this, but it doesn't seem like the submissions are indexed yet. Anyone here knows when that will be done?",3,0
1045,2018-2-23,2018,2,23,3,7zh8qw,Training very deep networks with Batchnorm,https://www.reddit.com/r/MachineLearning/comments/7zh8qw/training_very_deep_networks_with_batchnorm/,rvarm1,1519325191,,0,1
1046,2018-2-23,2018,2,23,4,7zhmgu,SVR (sklearn) - getting same values in prediction,https://www.reddit.com/r/MachineLearning/comments/7zhmgu/svr_sklearn_getting_same_values_in_prediction/,MLbeginner96,1519328020,[removed],0,1
1047,2018-2-23,2018,2,23,5,7zhxc5,How to start with machine learning?,https://www.reddit.com/r/MachineLearning/comments/7zhxc5/how_to_start_with_machine_learning/,Swork1,1519330309,[removed],0,1
1048,2018-2-23,2018,2,23,5,7ziagd,[D] Discussion on Pytorch vs TensorFlow,https://www.reddit.com/r/MachineLearning/comments/7ziagd/d_discussion_on_pytorch_vs_tensorflow/,ButthurtFeminists,1519333135,"Hi,
I've been using TensorFlow for a couple of months now, but after watching a quick Pytorch tutorial I feel that Pytorch is actually so much easier to use over TF.
Anyone have strong reasons why you use one over the other? Interested in the different sides of the argument.",71,18
1049,2018-2-23,2018,2,23,6,7zibsy,[R] Guide on How to Calculate and Visualize the Receptive Field Information of a CNN,https://www.reddit.com/r/MachineLearning/comments/7zibsy/r_guide_on_how_to_calculate_and_visualize_the/,risig_sag,1519333424,,6,10
1050,2018-2-23,2018,2,23,6,7zibyz,[D] machine learning windows 10 question,https://www.reddit.com/r/MachineLearning/comments/7zibyz/d_machine_learning_windows_10_question/,[deleted],1519333462,[deleted],0,1
1051,2018-2-23,2018,2,23,6,7zid9x,Google debuts AdSense auto ads with machine learning to make placement and monetization choices,https://www.reddit.com/r/MachineLearning/comments/7zid9x/google_debuts_adsense_auto_ads_with_machine/,chlordane2501,1519333744,,0,1
1052,2018-2-23,2018,2,23,7,7ziyrr,Github Network Science 4: N^2 Graph Explosions,https://www.reddit.com/r/MachineLearning/comments/7ziyrr/github_network_science_4_n2_graph_explosions/,rjurney,1519338320,,0,1
1053,2018-2-23,2018,2,23,7,7zizn3,"[D] Python, Scala, Rust or Go - What do you use when you deploy ML into production",https://www.reddit.com/r/MachineLearning/comments/7zizn3/d_python_scala_rust_or_go_what_do_you_use_when/,__Julia,1519338507,"Most of researchers these days prototype using Python &amp; R. However, when you put ML systems into productions, accuracy is not the only metric. Teams care about scalability and the speed of their system [1](https://www.ibm.com/developerworks/community/blogs/jfp/entry/What_Language_Is_Best_For_Machine_Learning_And_Data_Science?lang=en)

What do you use when you deploy ML in production ?. Which technology make it easier for you to build faster and more reliable infrastructure. ",59,38
1054,2018-2-23,2018,2,23,9,7zjs7x,Advice on programs: Georgia Tech (OMS CS Specialization in Machine Learning) vs. Stanford (Artificial Intelligence Graduate Certificate ),https://www.reddit.com/r/MachineLearning/comments/7zjs7x/advice_on_programs_georgia_tech_oms_cs/,pilotwave_,1519345148,[removed],0,1
1055,2018-2-23,2018,2,23,11,7zkolp,[1802.04443] On Characterizing the Capacity of Neural Networks using Algebraic Topology,https://www.reddit.com/r/MachineLearning/comments/7zkolp/180204443_on_characterizing_the_capacity_of/,weeeeeewoooooo,1519353369,,0,1
1056,2018-2-23,2018,2,23,11,7zkpa1,"""Adversarial Examples that Fool both Human and Computer Vision"", Elsayed et al 2018 {GB}",https://www.reddit.com/r/MachineLearning/comments/7zkpa1/adversarial_examples_that_fool_both_human_and/,gwern,1519353537,,1,2
1057,2018-2-23,2018,2,23,11,7zks98,A project idea based on machine learning.,https://www.reddit.com/r/MachineLearning/comments/7zks98/a_project_idea_based_on_machine_learning/,gore_protagonist,1519354303,[removed],0,1
1058,2018-2-23,2018,2,23,12,7zl59g,[R] [1802.07442] Learning to Play with Intrinsically-Motivated Self-Aware Agents,https://www.reddit.com/r/MachineLearning/comments/7zl59g/r_180207442_learning_to_play_with/,hohomomo1212,1519357732,,1,10
1059,2018-2-23,2018,2,23,12,7zl6sv,"[D] Rachel Thomas (co-founder of fast.ai) is saying Google Brain, Open AI, and Uber are not hiring enough women and black men.",https://www.reddit.com/r/MachineLearning/comments/7zl6sv/d_rachel_thomas_cofounder_of_fastai_is_saying/,SpiritualAlternative,1519358184,"&gt; Google Brain is ~94% male and &gt;70% white, and OpenAI appears even less diverse. Here's why diversity in AI matters: http://www.fast.ai/2017/08/16/diversity-crisis/ 

https://twitter.com/math_rachel/status/897886676386578432

&gt; Uber AI Labs is 96% male (23 out of 24) and 0% Black, according to their website.

https://twitter.com/math_rachel/status/966812113359470592


This kind of tweet is not nice. It implies Google Brain and Uber AI  are sexist and racist. In reality, many employers care about profit than anything else.
",19,0
1060,2018-2-23,2018,2,23,13,7zl7rz,[N] AI Adds Colour to Grandmas Cherished Memories,https://www.reddit.com/r/MachineLearning/comments/7zl7rz/n_ai_adds_colour_to_grandmas_cherished_memories/,trcytony,1519358467,,0,5
1061,2018-2-23,2018,2,23,13,7zljj4,[OC] I have started a ML blog. Today I have found out that the growth rate of Trump Jokes on /r/Jokes is like that of Cancer.,https://www.reddit.com/r/MachineLearning/comments/7zljj4/oc_i_have_started_a_ml_blog_today_i_have_found/,cuddle_cuddle,1519361791,,1,1
1062,2018-2-23,2018,2,23,15,7zm0ih,Which one would you prefer for Deep learning ? Andrew Ng or Ian Goodfellow,https://www.reddit.com/r/MachineLearning/comments/7zm0ih/which_one_would_you_prefer_for_deep_learning/,keyurparalkar,1519366914,[removed],0,1
1063,2018-2-23,2018,2,23,16,7zmcvj,What aera of research in Deep learning you want to explore as Researcher?.,https://www.reddit.com/r/MachineLearning/comments/7zmcvj/what_aera_of_research_in_deep_learning_you_want/,[deleted],1519371097,,0,1
1064,2018-2-23,2018,2,23,17,7zmhfq,[D] Why create OpenAI as a company instead of an international organization (i.e CERN for ML and AI)?,https://www.reddit.com/r/MachineLearning/comments/7zmhfq/d_why_create_openai_as_a_company_instead_of_an/,[deleted],1519372850,"I originally thought of making this a blog post, but I think the reddit format is better for the discussion. Feel free to discuss the idea in your own blogs, but linking back here would be appreciated for discussion purposes (I do not associate myself with my reddit account). 

After considering the position paper by Google AI, [Winner's Curse? On Pace, Progress, and Empirical Rigor](https://openreview.net/forum?id=rJWF0Fywf)and thinking back on issues regarding AI safety/privacy,  I've had to asked my self several questions regarding the field. We can all agree (I hope) that empirical rigour is important, but can leave areas of research quite inaccessible by many research teams. This hesitation to perform extensive studies in a rapidly publishing field is perhaps the reason it has so developed lax standards for in the review process as well. There are several subjects that the paper mentions that are at least worth considering, given that standards we set now will have significant impact on progress (good or bad) on the field.

#Problems that affect everyone can be solved by everyone

However there are also societal issues that both researchers, businesses, and governments will have to consider. The current work on AI safety should be an obvious example of problems that everyone will have to deal with regardless of nationality, ethnicity, race, etc. Actually I would likely backtrack on ethnicity and race and say that unchecked systematic biases that find their way into AI/ML could destroy entire lives (if you think this is hyperbole, please see any minority in U.S. about its justice system). Honestly, there are methods in this era will likely open possibilities we aren't even considering now. There are just simply problems that shouldn't be solved purely for name recognition, and there are problems that would benefit from combined resources on an international scale. Also ability to empirically model-free (and model dependent) results through shared resources and collaborative experiment design could be beneficial to everyone involved. See any complaint about hyper-parameter tuning. Without an exact theory, or really good estimation of minimal NN size needed some problems, I think many fields will be hesitant to adopt useful methods.  

Edit: 
Consider an organization that receives member state fees and uses this to perform extensive studies that were otherwise computational prohibitive to most groups. Papers which do not themselves provide rigorous empirical results, but provide sufficient justification for spending effort do so could submit request this CERN for ML/AI.  Given the paper as justification and detailed experimental procedures, the organization performs an internal review to accept or reject as worth of spending resources on. This is to prevent misuse or abuse. After which a supplementary study is published with proper attribution. This organization also maintains all baselines and benchmarks l, letting research groups focus on their important work making larger steps forward.  A really positive result from the study justifies elevating a conference submission to a journal for higher impact factor (to reward the effort and patience) 

# International Collaboration and organizational structure 

High Energy Physics and CERN in particular have developed very good organizational structures that foster collaboration, reduce unnecessary redundancy, and open access to research that just isn't feasible for even large, well funded research groups. The benefits of these organizations were way beyond just physics. CERN and Fermilab connected their physicists to medical researcher and developed the modern accelerator technology used in cancer treatment.  These organizations were able to build internal review processes that ensured all work met an acceptable standard, and lead to cross institution collaboration that I believe is unseen in any other STEM field.  Internal tools and results are accessible and disseminated across different areas of focus simply because the organizational structure provided easy way of identifying what was being by each division (triggers, even reconstruction, calorimeter monitoring, etc.).  Researchers participate in specialized groups, contributing to experiment (ATLAS, CMS, LHC-b) wide results by performing service hours. This serves to ensure those benefiting and publishing from the shared resources (computing,networking,human,etc.) are paying it forward, and keeping organizations running smoothly and fairly.  Institutions that have many grad students, post docs, and professors all perform service hours just like small institutions, but theoretical can end up benefiting proportionally because they have more workers to perform research on the shared resources in parallel.  Service tasks can be anything from  experiment management to software design (tool creation). The benefit to everyone of course is the resources gained from governments and other organizations member fees, as well as grants from individual groups which can directly or indirectly improve the experiment.

These large organizational structures haven't really affected the ability to award credit, as being part of the organization, it's very east to attribute work being done by someone because of documentation of internal work like service hours, and the multi step review process that really allows everyone who need to chime in on a paper, to see both the author and their work regardless of prior ""fame"".  Theoreticians publish papers on models all the time, win nobel prizes( Higgs gets nobel prize), but their work is properly validated through experiments (ATLAS and CMS do years of work to prove it) which are performed by those who do care empirical rigour. Time is spent mapping theoretical predictions at various levels of abstraction (from broad theories about fundamental physics to specific theories on the rate of a particular particle production) to experiment design and methodology, really allowing both elements of theory and experimental rigour to shine.

# Would it work for AI/ML?
 
Why not? Individual research groups in HEP still perform smaller scale studies all the time, but as a whole modern physics wouldn't exist today without organizations like these. The same can be true for ML/AI, because it's applications go beyond cultural borders and any specific business application. There are number of areas where a concentration of efforts and reduced overlap between efforts would really improve the (# number of useful contributions) / (# number of total 'contributions').  Business ties to ML/AI really are separate from from organizations like this, with reporting of conflict of interests, because no business would ever really achieve the computing power collaborating nations could achieve. Standards could be created, and baselines maintained and repeatedly restudied without worrying about finding funding for such tasks. An organization like this can really help fill the gap that in funding and resources that are needed to perform tasks and publish results that are extremely important but lack that *give me $100,000 in grant money* aspect.



What do you think? I'll have to come back and edit this for typos likely, but as a physicist that worked on an experiment at CERN, I see lots of complaints and problems that physics has pretty efficiently solved in its very extensive existence as a science.",15,18
1065,2018-2-23,2018,2,23,17,7zmn8u,[P] Neural network semi-supervised/unsupervised learning architectures for detection of team formations in soccer?,https://www.reddit.com/r/MachineLearning/comments/7zmn8u/p_neural_network_semisupervisedunsupervised/,fruityfrucht,1519374985,"I'm having a concrete problem I'm trying to solve but I'm not sure in which direction I should go.  

* Goal: Identify formation of a soccer team based on a static positional data (x,y coordinates of each player) frame  
* Input: Dataframe with player positions + possible other features  
* Output: Formation for the given frame  
* Limited, predefined formations (5-10) like 5-3-2 (5 defenders, 3 midfield players, 3 strickers)  
* Possible to manually label a few examples per formation  

I already tried k-means clustering on single frames, only considering the x-axis to identify defense, midfield and offense players which works ok but fails in some situations.  

Since I don't have (much) labels im looking for unsupervised neural network architectures (like self organizing maps) which might be able to solve this problem better than simple k-means clustering on single frames.  

I'm looking for an architecture which could utilize the additional information I have about the problem (number and type of formations, few already labeled frames, ..).",6,0
1066,2018-2-23,2018,2,23,17,7zmpyn,[R] Machine Theory of Mind,https://www.reddit.com/r/MachineLearning/comments/7zmpyn/r_machine_theory_of_mind/,getshreddedorgohome,1519376130,,20,57
1067,2018-2-23,2018,2,23,18,7zmty5,I have a lot of small paragraphs of chinese translated properly to english. And I also have many small paragraphs to be translated. Can some suggest a way to use machine learning in this case? My level is way below novice in machine learning.,https://www.reddit.com/r/MachineLearning/comments/7zmty5/i_have_a_lot_of_small_paragraphs_of_chinese/,shashikanth171,1519377658,[removed],0,1
1068,2018-2-23,2018,2,23,18,7zmzkj,[P] Aurora: Minimal Deep Learning Library,https://www.reddit.com/r/MachineLearning/comments/7zmzkj/p_aurora_minimal_deep_learning_library/,upulbandara,1519379840,,1,15
1069,2018-2-23,2018,2,23,19,7zn7xj,Clustering Approaches for Financial Data Analysis,https://www.reddit.com/r/MachineLearning/comments/7zn7xj/clustering_approaches_for_financial_data_analysis/,ciaracodes,1519382977,,0,1
1070,2018-2-23,2018,2,23,20,7zndqu,[D] Does the growth of machine learning require politically aware programmers?,https://www.reddit.com/r/MachineLearning/comments/7zndqu/d_does_the_growth_of_machine_learning_require/,Moosichu,1519385091,,14,0
1071,2018-2-23,2018,2,23,20,7zndrp,[N] OpenAI Hackathon,https://www.reddit.com/r/MachineLearning/comments/7zndrp/n_openai_hackathon/,Jackal008,1519385103,,3,22
1072,2018-2-23,2018,2,23,20,7zndym,[N] Researching patient deterioration with the US Department of Veterans Affairs | DeepMind,https://www.reddit.com/r/MachineLearning/comments/7zndym/n_researching_patient_deterioration_with_the_us/,Jackal008,1519385182,,0,1
1073,2018-2-23,2018,2,23,20,7zne2y,"[P] 2nd Place in a Kaggle Competition, with Deep Learning",https://www.reddit.com/r/MachineLearning/comments/7zne2y/p_2nd_place_in_a_kaggle_competition_with_deep/,Jackal008,1519385224,,4,0
1074,2018-2-23,2018,2,23,20,7znej4,3 Mouth Cement Packing Machine Manufacturer in China,https://www.reddit.com/r/MachineLearning/comments/7znej4/3_mouth_cement_packing_machine_manufacturer_in/,lgsherry,1519385377,,1,1
1075,2018-2-23,2018,2,23,21,7znm6l,[P] Need suggestions to train my MMORPG bot detection system,https://www.reddit.com/r/MachineLearning/comments/7znm6l/p_need_suggestions_to_train_my_mmorpg_bot/,username39885039,1519388075,"Hi guys,

I spent months developing my MMORPG (wont post it here) and after few months out I have started to notice some weird behavior on some players (online for about 18h straight - from ""no one"" to top 10 in less than a week and many other things).


I now feel a strong urge for collecting data and start training my AI (sorry If I use wrong terms here) so I can detect who are the bots or who are the humans.


These are some of the things I can save and use for ML:

* Experience
* Gold
* Monsters killed
* Clicks sent to server
* ""Picked up item"" request to server (I think some bots, spam this one so they can collect everything)
* Messages sent to Chat
* Deaths 
* Potions used
* Potions bought
* Session duration


I could collect all of these on a per X time/session/all time basis, but some of those wouldn't work on a ""per X time"" or would give 0 most of the times, example: Deaths and potions bought.


I thought you guys could point me in the right direction regarding which of these to store (per second/per minute/per session.. all of them) and which python library would be the one that you would use for this particular case. 


Thank you!
",13,2
1076,2018-2-23,2018,2,23,21,7zno8w,How Machine Learning Companies are evolving Dubai,https://www.reddit.com/r/MachineLearning/comments/7zno8w/how_machine_learning_companies_are_evolving_dubai/,stewartcristan,1519388759,,0,1
1077,2018-2-23,2018,2,23,22,7znx1m,Recurent Neural Network for machinery,https://www.reddit.com/r/MachineLearning/comments/7znx1m/recurent_neural_network_for_machinery/,Wrandraall,1519391501,[removed],0,1
1078,2018-2-23,2018,2,23,22,7znxs4,Kidney Bean Peeling Machine for Sale,https://www.reddit.com/r/MachineLearning/comments/7znxs4/kidney_bean_peeling_machine_for_sale/,gelserena,1519391694,,1,1
1079,2018-2-23,2018,2,23,23,7zo9ro,[R] [OC] Fighting GAN Mode Collapse by Randomly Sampling the Latent Space,https://www.reddit.com/r/MachineLearning/comments/7zo9ro/r_oc_fighting_gan_mode_collapse_by_randomly/,manychairs,1519394917,,17,10
1080,2018-2-23,2018,2,23,23,7zo9z8,Dumb question that I can't find the answer for regarding model compression.,https://www.reddit.com/r/MachineLearning/comments/7zo9z8/dumb_question_that_i_cant_find_the_answer_for/,Letmesleep69,1519394961,[removed],0,1
1081,2018-2-23,2018,2,23,23,7zodko,Microsoft AI any news?,https://www.reddit.com/r/MachineLearning/comments/7zodko/microsoft_ai_any_news/,[deleted],1519395865,,0,1
1082,2018-2-23,2018,2,23,23,7zodt3,"Microsoft AI Residency, any news?",https://www.reddit.com/r/MachineLearning/comments/7zodt3/microsoft_ai_residency_any_news/,Gumeo,1519395925,[removed],0,1
1083,2018-2-24,2018,2,24,0,7zor3b,[N] AI Adds Colour to Grandmas Cherished Memories -Tencent is offering retouching service for old photographs.,https://www.reddit.com/r/MachineLearning/comments/7zor3b/n_ai_adds_colour_to_grandmas_cherished_memories/,gwen0927,1519399118,,4,130
1084,2018-2-24,2018,2,24,0,7zozt4,[D] Benchmarking Googles new TPUv2,https://www.reddit.com/r/MachineLearning/comments/7zozt4/d_benchmarking_googles_new_tpuv2/,[deleted],1519401114,[deleted],0,1
1085,2018-2-24,2018,2,24,0,7zp0ci,[D] Benchmarking Googles new TPUv2,https://www.reddit.com/r/MachineLearning/comments/7zp0ci/d_benchmarking_googles_new_tpuv2/,henningpeters,1519401219,,26,47
1086,2018-2-24,2018,2,24,1,7zp372,[P] Keras implementation of the One Pixel Attack for Fooling Deep Neural Networks,https://www.reddit.com/r/MachineLearning/comments/7zp372/p_keras_implementation_of_the_one_pixel_attack/,Hyperparticles,1519401848,,17,80
1087,2018-2-24,2018,2,24,1,7zpdau,Available parking spot predictive model,https://www.reddit.com/r/MachineLearning/comments/7zpdau/available_parking_spot_predictive_model/,Imakesensealot,1519404000,[removed],0,1
1088,2018-2-24,2018,2,24,2,7zpk1w,[D] Georgia Tech (OMS CS Specialization in Machine Learning) vs. Stanford (Artificial Intelligence Graduate Certificate),https://www.reddit.com/r/MachineLearning/comments/7zpk1w/d_georgia_tech_oms_cs_specialization_in_machine/,pilotwave_,1519405399,"Which program would you recommend for quality and value? The Georgia Tech's masters is a degree awarding program, whereas Stanford is not (but there's a chance to switch it to masters if admission accepted and units earned transferred). So, which program you choose, and why?",7,1
1089,2018-2-24,2018,2,24,2,7zpl8n,What is the best open source video emotion and voice emotion analytics app that uses state of the art machine learning?,https://www.reddit.com/r/MachineLearning/comments/7zpl8n/what_is_the_best_open_source_video_emotion_and/,userexperienceguy,1519405647,[removed],0,1
1090,2018-2-24,2018,2,24,3,7zq11n,Stroke Controllable Fast Style Transfer,https://www.reddit.com/r/MachineLearning/comments/7zq11n/stroke_controllable_fast_style_transfer/,banguru,1519408931,,0,1
1091,2018-2-24,2018,2,24,3,7zqceg,[R] Diversity is All You Need: Learning Skills without a Reward Function,https://www.reddit.com/r/MachineLearning/comments/7zqceg/r_diversity_is_all_you_need_learning_skills/,abstractcontrol,1519411307,,1,0
1092,2018-2-24,2018,2,24,3,7zqg5l,[R] Helping Recurrent Neural Networks in Speaker Identification,https://www.reddit.com/r/MachineLearning/comments/7zqg5l/r_helping_recurrent_neural_networks_in_speaker/,[deleted],1519412098,[deleted],1,1
1093,2018-2-24,2018,2,24,4,7zqj6u,[R] ChatPainter: This AI-bot creates the pictures you want. From pizza to a bird or a plane.,https://www.reddit.com/r/MachineLearning/comments/7zqj6u/r_chatpainter_this_aibot_creates_the_pictures_you/,jagger3m,1519412738,,0,4
1094,2018-2-24,2018,2,24,4,7zqj7y,[D] Relation of Likelihood-free models with GANS,https://www.reddit.com/r/MachineLearning/comments/7zqj7y/d_relation_of_likelihoodfree_models_with_gans/,ShivamDuggal4,1519412743,"Hi, I was watching NIPS talk on F-GAN and could not understand the first 6 minutes, where the author explains the reason behind intractability of likelihood models and tractability of integral probability expectations.
What are likelihood-free models and why are they called so?  I could not understand the reason behind, the estimation of the probability of the sample being intractable, but the expectation of the sample is not. Why is so? And what is the relation of likelihood problems with GANS? ",3,1
1095,2018-2-24,2018,2,24,4,7zqloh,[N] Chinese Startups Hauled In Half of 2017 Global AI Funding,https://www.reddit.com/r/MachineLearning/comments/7zqloh/n_chinese_startups_hauled_in_half_of_2017_global/,gwen0927,1519413264,,11,62
1096,2018-2-24,2018,2,24,4,7zqp3g,AI Weekly 23 Feb 2018,https://www.reddit.com/r/MachineLearning/comments/7zqp3g/ai_weekly_23_feb_2018/,TomekB,1519413976,,0,1
1097,2018-2-24,2018,2,24,4,7zqyj7,[D] Theory behind optimization of neural nets,https://www.reddit.com/r/MachineLearning/comments/7zqyj7/d_theory_behind_optimization_of_neural_nets/,Kah3caix,1519415974,"Does anyone have references related to the current understanding of optimization in neural nets? Specifically, any theory behind why we are able to optimize over such a high-dimensional space and how we could improve current optimization techniques would be useful. Also would be okay with prerequisite fields of study (real analysis, functional analysis) to this kind of work.

Also looking for insight as to why it would be possible to improve current optimization techniques in light of what is said by No Free Lunch. Do we assume a certain prior over functions which lets us ignore No Free Lunch? And if so, what is this prior and how can it be leveraged?",5,0
1098,2018-2-24,2018,2,24,5,7zr1it,Machine Learning Song,https://www.reddit.com/r/MachineLearning/comments/7zr1it/machine_learning_song/,moshesipper,1519416581,,0,1
1099,2018-2-24,2018,2,24,6,7zrj3u,[D] Updating an Article New Citation of Paper Published After original Submition,https://www.reddit.com/r/MachineLearning/comments/7zrj3u/d_updating_an_article_new_citation_of_paper/,sauhaarda,1519420381,"I had uploaded a paper to Arxiv before the ICRA 2018 deadline for my submission. This paper is linked below:
https://arxiv.org/abs/1709.05581

Recently I recieved the unfortunate news that I was rejected. There were a few problems the reviewers identified that could be easily fixed so I decided to republish for the IROS conference. However, between the time of my original posting to Arxiv and now. Intel had published a very similar paper (published to Arxiv AFTER my original publication), and this paper didn't cite mine (probably for my own paper's lack of visibility):
https://arxiv.org/pdf/1710.02410.pdf

In my updated version of the paper, should I cite Intel's work although it was technically published after my original upload? I feel that doing so would reduce the novelty of my work. Not sure what the ethical action is here so wanted to ask here to confirm.",7,0
1100,2018-2-24,2018,2,24,6,7zrlbi,[D] How are you using Machine Learning to help other people?,https://www.reddit.com/r/MachineLearning/comments/7zrlbi/d_how_are_you_using_machine_learning_to_help/,breadteam,1519420877,"Hey folks! How are you using Machine Learning, AI, etc. to help others or your community? 

If you want to describe your project, please go ahead!",15,2
1101,2018-2-24,2018,2,24,6,7zrnde,[N] Alibaba Launches 11-Qubit Quantum Computing Cloud Service,https://www.reddit.com/r/MachineLearning/comments/7zrnde/n_alibaba_launches_11qubit_quantum_computing/,gwen0927,1519421323,,33,124
1102,2018-2-24,2018,2,24,6,7zrt1g,Advice on what to work on?,https://www.reddit.com/r/MachineLearning/comments/7zrt1g/advice_on_what_to_work_on/,Geeks_sid,1519422580,[removed],0,1
1103,2018-2-24,2018,2,24,6,7zru17,scitkit SGDClassifier partial_fit doesnot learn incrementally.,https://www.reddit.com/r/MachineLearning/comments/7zru17/scitkit_sgdclassifier_partial_fit_doesnot_learn/,datavizu,1519422794,[removed],0,1
1104,2018-2-24,2018,2,24,7,7zrwsm,scitkit SGDClassifier partial_fit doesnot learn incrementally.,https://www.reddit.com/r/MachineLearning/comments/7zrwsm/scitkit_sgdclassifier_partial_fit_doesnot_learn/,datavizu,1519423394,[removed],0,1
1105,2018-2-24,2018,2,24,7,7zry7l,Some CS fundamentals for AI/ML grad school,https://www.reddit.com/r/MachineLearning/comments/7zry7l/some_cs_fundamentals_for_aiml_grad_school/,reddittUndecidedEE,1519423708,[removed],0,1
1106,2018-2-24,2018,2,24,7,7zs1x7,I want to know more about ML and how I can use it,https://www.reddit.com/r/MachineLearning/comments/7zs1x7/i_want_to_know_more_about_ml_and_how_i_can_use_it/,[deleted],1519424581,,0,1
1107,2018-2-24,2018,2,24,7,7zs4b3,Projects to help get better at ML,https://www.reddit.com/r/MachineLearning/comments/7zs4b3/projects_to_help_get_better_at_ml/,2much_time,1519425150,[removed],0,1
1108,2018-2-24,2018,2,24,9,7zt0n5,"[D] Reinforcement Learning never worked, and deep only helped a bit.",https://www.reddit.com/r/MachineLearning/comments/7zt0n5/d_reinforcement_learning_never_worked_and_deep/,n00bkilla555,1519433193,,30,178
1109,2018-2-24,2018,2,24,11,7ztrt4,How to put a price on a model?,https://www.reddit.com/r/MachineLearning/comments/7ztrt4/how_to_put_a_price_on_a_model/,4rtemi5,1519440843,[removed],0,1
1110,2018-2-24,2018,2,24,13,7zu59h,6 Dng My ng Gi Bao B c S Dng Nhiu Nht,https://www.reddit.com/r/MachineLearning/comments/7zu59h/6_dng_my_ng_gi_bao_b_c_s_dng_nhiu_nht/,mainguyenmth,1519444819,,0,1
1111,2018-2-24,2018,2,24,15,7zusgf,[R] Generalizable Adversarial Examples Detection Based on Bi-model Decision Mismatch,https://www.reddit.com/r/MachineLearning/comments/7zusgf/r_generalizable_adversarial_examples_detection/,visarga,1519452367,,0,0
1112,2018-2-24,2018,2,24,15,7zuzrt,ClaoudML - Free Data Science &amp; Machine Learning Resources,https://www.reddit.com/r/MachineLearning/comments/7zuzrt/claoudml_free_data_science_machine_learning/,randylaosat,1519455049,,0,1
1113,2018-2-24,2018,2,24,16,7zv203,Evolution of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7zv203/evolution_of_machine_learning/,Crestinfotech-web,1519455981,,0,1
1114,2018-2-24,2018,2,24,16,7zv2jn,[R]What area of research in Deep learning you want to explore as Researcher?,https://www.reddit.com/r/MachineLearning/comments/7zv2jn/rwhat_area_of_research_in_deep_learning_you_want/,munibkhanali,1519456191,,27,4
1115,2018-2-24,2018,2,24,16,7zv2vf,Machine learning training course in India,https://www.reddit.com/r/MachineLearning/comments/7zv2vf/machine_learning_training_course_in_india/,pavanear,1519456307,,0,1
1116,2018-2-24,2018,2,24,17,7zvhau,Small Vacuum Packing Machine For Home,https://www.reddit.com/r/MachineLearning/comments/7zvhau/small_vacuum_packing_machine_for_home/,lgsherry,1519462393,,1,1
1117,2018-2-24,2018,2,24,17,7zvhjs,[D] Are there methods to use features during training that won't be available for prediction?,https://www.reddit.com/r/MachineLearning/comments/7zvhjs/d_are_there_methods_to_use_features_during/,kleinergauss,1519462522,"I am searching for general approaches to make use of features in my training data that won't be available during prediction. Preferably, they should be compatible with neural nets. I didn't find anything on Google, but I guess I am missing the right keywords to search for. 

Thank you in advance!",11,0
1118,2018-2-24,2018,2,24,18,7zvnli,[D] Which is your favorite Machine Learning algorithm?,https://www.reddit.com/r/MachineLearning/comments/7zvnli/d_which_is_your_favorite_machine_learning/,saadmrb,1519465327,"My current favorite is Spectral Clustering. It is sort of the flagship algorithm for a whole class of methods called Spectral Algorithms[1], which have been gaining increasing attention from the ML community in recent years.

Why is it my favorite? Because it brings together some of the most fascinating areas of mathematics in an interesting way. Ive never seen an algorithm combine so many ideas and insights from seemingly disparate fields.

So, what is Spectral Clustering?

It is an algorithm for detecting communities among a network of entities (users in a social network, pixels in an image, gene expressions etc.). The goal is to partition the entities into groups such that entities of the group are similar while the entities of different groups are not similar.

How does Spectral Clustering work?

First, we construct a similarity matrix from the given network (or graph). Then we extract the most relevant eigenvectors of the similarity matrix using eigenvalue decomposition and use it to derive a new spectral representation for the entities in our network. Finally, we perform k-means on the new representation and output the clusters.


To be honest, the first time I came across spectral clustering, I had no idea why this method should give a nice partition of the network . Theres just too much going on, and it definitely is not intuitive at the first glance. But if you stick with it and dig a little deeper, you begin to see some surprising connections. Here, Ill just try to list a few tidbits about spectral clustering to pique your curiosity.

Graph Cuts: It is a well known fact that finding the balanced minimum cut of a graph is an NP hard problem[2] . It turns out that spectral clustering solves a continuous relaxation of this discrete combinatorial optimization problem.
Random Walks: Consider a random walk on a graph[3] . At each time step, the random walker jumps from the current vertex to any of its neighbors randomly. It turns out that spectral clustering minimizes the inter-cluster transit time (the time spent walking between the clusters rather than within the clusters) of the random walker.
Physics: Spectral clustering has surprising connections to the Laplacian operator[4] that is widely used in physics as a measure of smoothness of a surface.
Graph Signal Processing[5] : Consider a graph signal on the given network that distinctly identifies the best possible clustering of its vertices. Spectral clustering minimizes the total variation of this indicator graph signal.
Matrix Perturbation Theory: Consider an ideal similarity matrix constructed by a graph with disjoint clusters. It turns out that perturbing this idea matrix by adding a few edges across the clusters does little to change the spectral representation of the vertices. Hence, spectral clustering works, and is immune to noise.

..and I could go on and on. Unlike the hottest machine learning algorithms these days (neural networks and deep learning) which are basically black boxes where no one understands why something works, spectral methods have strong theoretical grounding with several interpretations on why they work. I like to think of spectral clustering as a well written poem that means different things to different people while being elegant all the same.

",113,131
1119,2018-2-24,2018,2,24,18,7zvoe9,Machine learning bot which can play clash of clans,https://www.reddit.com/r/MachineLearning/comments/7zvoe9/machine_learning_bot_which_can_play_clash_of_clans/,swapu258,1519465651,,0,1
1120,2018-2-24,2018,2,24,19,7zvx3h,Li thng gp trn my git LG,https://www.reddit.com/r/MachineLearning/comments/7zvx3h/li_thng_gp_trn_my_git_lg/,thekparkvnn,1519469430,,0,1
1121,2018-2-24,2018,2,24,20,7zvztm,dataset for electrical/electronics components identification,https://www.reddit.com/r/MachineLearning/comments/7zvztm/dataset_for_electricalelectronics_components/,psuzn,1519470614,[removed],0,1
1122,2018-2-24,2018,2,24,20,7zw4w4,I don't know a huge amount on machine learning/ai but I want to build something which looks at the Enron dataset and finds the persons of interest. Where do I start?,https://www.reddit.com/r/MachineLearning/comments/7zw4w4/i_dont_know_a_huge_amount_on_machine_learningai/,narya_elentari,1519472812,[removed],0,1
1123,2018-2-24,2018,2,24,22,7zwjjm,"Can anybody (who has been an AI resident-Google, FB, MS, Uber, OpenAI, Clova) please help me in reviewing my AI residency cover letter and resume?",https://www.reddit.com/r/MachineLearning/comments/7zwjjm/can_anybody_who_has_been_an_ai_residentgoogle_fb/,jishnup,1519478512,[removed],7,2
1124,2018-2-24,2018,2,24,22,7zwlqh,What path led you to machine learning?,https://www.reddit.com/r/MachineLearning/comments/7zwlqh/what_path_led_you_to_machine_learning/,mljedi,1519479253,[removed],0,1
1125,2018-2-24,2018,2,24,23,7zwu8j,Are there any (human) language datasets?,https://www.reddit.com/r/MachineLearning/comments/7zwu8j/are_there_any_human_language_datasets/,PurpleIcy,1519481940,[removed],0,1
1126,2018-2-24,2018,2,24,23,7zx08l,Career in ML for a hard of hearing person,https://www.reddit.com/r/MachineLearning/comments/7zx08l/career_in_ml_for_a_hard_of_hearing_person/,fresh_preserve,1519483739,[removed],0,1
1127,2018-2-25,2018,2,25,0,7zx6zb,What personal ML/AI project do you use in your daily life?,https://www.reddit.com/r/MachineLearning/comments/7zx6zb/what_personal_mlai_project_do_you_use_in_your/,[deleted],1519485657,,0,1
1128,2018-2-25,2018,2,25,0,7zx73p,[D] What personal ML/AI project do you use in your daily life?,https://www.reddit.com/r/MachineLearning/comments/7zx73p/d_what_personal_mlai_project_do_you_use_in_your/,Valiox,1519485690,,28,30
1129,2018-2-25,2018,2,25,0,7zx78w,Need help with approaches to Data Science/Analytics problems,https://www.reddit.com/r/MachineLearning/comments/7zx78w/need_help_with_approaches_to_data/,[deleted],1519485729,,0,1
1130,2018-2-25,2018,2,25,0,7zx7cd,[N] Googles AI assistant is adding support for a total of 30 languages by the end of 2018,https://www.reddit.com/r/MachineLearning/comments/7zx7cd/n_googles_ai_assistant_is_adding_support_for_a/,famegamedeveloper,1519485752,,0,2
1131,2018-2-25,2018,2,25,1,7zxizv,Whats the biggest neural net i can run on a rpi3?,https://www.reddit.com/r/MachineLearning/comments/7zxizv/whats_the_biggest_neural_net_i_can_run_on_a_rpi3/,ToplessTopmodel,1519488878,[removed],0,1
1132,2018-2-25,2018,2,25,1,7zxob4,[D] Career in ML for a hard of hearing person,https://www.reddit.com/r/MachineLearning/comments/7zxob4/d_career_in_ml_for_a_hard_of_hearing_person/,fresh_preserve,1519490200,"I am hard of hearing and have about 14 years of experience in a Microsoft shop and have worked in various domains and I am good i several areas like performance, automated testing, security, distributed systems, development and application design. I have good hands on in cloud too.

I am currently doing a devops role where I manage the ci/cd pipeline, do some design, troubleshooting and so on. As this role involves less oral communication I am able to perform it well.

I am trying to see if I can develop more expertise in devops area or learn and move to machine learning career. But as I am hard of hearing, I am not sure if I would be able to fulfill the responsibilities properly. Does the ML role involves heavy oral communication with customers? What is the typical day like?",8,15
1133,2018-2-25,2018,2,25,1,7zxrk5,Does there exist YOLO for images at 1080p or strange resolutions?,https://www.reddit.com/r/MachineLearning/comments/7zxrk5/does_there_exist_yolo_for_images_at_1080p_or/,OlorinDreams,1519490998,[removed],0,1
1134,2018-2-25,2018,2,25,1,7zxtxp,The FAIMA project produces ICO on Artificial Intelligence in medicine.,https://www.reddit.com/r/MachineLearning/comments/7zxtxp/the_faima_project_produces_ico_on_artificial/,zary14,1519491575,,0,1
1135,2018-2-25,2018,2,25,2,7zy6bh,LightOn Cloud: Light based technology for ML opening up on the Cloud,https://www.reddit.com/r/MachineLearning/comments/7zy6bh/lighton_cloud_light_based_technology_for_ml/,[deleted],1519494528,[deleted],0,1
1136,2018-2-25,2018,2,25,3,7zy9m7,Why compute is now more valuable than data?,https://www.reddit.com/r/MachineLearning/comments/7zy9m7/why_compute_is_now_more_valuable_than_data/,bobster82183,1519495321,[removed],0,1
1137,2018-2-25,2018,2,25,3,7zyj7h,[N] LightOn Cloud: Light based technology for ML opening up on the Cloud,https://www.reddit.com/r/MachineLearning/comments/7zyj7h/n_lighton_cloud_light_based_technology_for_ml/,compsens,1519497568,,12,4
1138,2018-2-25,2018,2,25,3,7zyli3,Keras Recall Loss Function,https://www.reddit.com/r/MachineLearning/comments/7zyli3/keras_recall_loss_function/,data_guy_asking_why,1519498118,[removed],0,1
1139,2018-2-25,2018,2,25,4,7zyqm4,"[R] Google Brain: We propose a hierarchical model for efficient placement of computational graphs onto hardware devices, especially in heterogeneous environments with a mixture of CPUs, GPUs, and other computational devices.",https://www.reddit.com/r/MachineLearning/comments/7zyqm4/r_google_brain_we_propose_a_hierarchical_model/,downtownslim,1519499344,,7,125
1140,2018-2-25,2018,2,25,4,7zyuat,[D] Why is RL the new punching bag for the AI/ML community?,https://www.reddit.com/r/MachineLearning/comments/7zyuat/d_why_is_rl_the_new_punching_bag_for_the_aiml/,FirstTimeResearcher,1519500236,Maybe I got into the wrong research topic :'(,17,9
1141,2018-2-25,2018,2,25,5,7zzetc,Anomaly detection in network traffic,https://www.reddit.com/r/MachineLearning/comments/7zzetc/anomaly_detection_in_network_traffic/,[deleted],1519505269,,0,1
1142,2018-2-25,2018,2,25,5,7zzexu,[D] Question about SPTK kernel,https://www.reddit.com/r/MachineLearning/comments/7zzexu/d_question_about_sptk_kernel/,Subtle__,1519505305,"I'm interested in text classification algorithms and I've been reading through some of the literature. I made my way through the [Moschitti paper](http://disi.unitn.it/moschitti/ML2009-10/TK-ECML2006.pdf) on PT kernels and I just got through [the SPTK kernel paper](http://disi.unitn.it/moschitti/articles/2011/EMNLP-SPTK2011.pdf).

I get the idea behind the SPTK kernel: it adds a lexical similarity function $\sigma(n_1, n_2)$ that measures the similarity of two nodes' labels, so shared trees with different leaves but similar meanings contribute to the overall kernel between trees. However, I'm confused what $\sigma(n_1, n_2)$ would output when $n_1$ / $n_2$ are non-terminal nodes. In a parse tree just the terminals are labelled with the actual words; the non-terminals have syntactic POS tags like JJ, NP, etc. right? So how would non-terminal nodes be compared?",2,0
1143,2018-2-25,2018,2,25,7,8006f8,Predicting the 2018 NFL QB Draft Class using Neural Networks,https://www.reddit.com/r/MachineLearning/comments/8006f8/predicting_the_2018_nfl_qb_draft_class_using/,rs868412,1519512154,,0,1
1144,2018-2-25,2018,2,25,8,800df9,[P] Kaggle Tensorflow Speech Recognition Challenge,https://www.reddit.com/r/MachineLearning/comments/800df9/p_kaggle_tensorflow_speech_recognition_challenge/,SupraluminalShift,1519513968,,4,42
1145,2018-2-25,2018,2,25,8,800hwz,Is it possible to find valuable papers on machine learning for investing?,https://www.reddit.com/r/MachineLearning/comments/800hwz/is_it_possible_to_find_valuable_papers_on_machine/,alfileres1,1519515169,"There are plenty of papers on the use of machine learning for finance. Most of them end up saying that the results look somehow promising but more work is needed. When I read these papers my thinking is that if it would  really work, it will not be published. It will be part of an hedge fund or somebody will be secretly trading and taking the profits.

What's your experience? Have you found any solid paper on the use of machine learning for investing? Do you mind sharing it?
If you are working on it and it works... Would you mind telling us that there's hope, that there's some signal in the noise... And that's worthwhile keep trying? ",2,1
1146,2018-2-25,2018,2,25,8,800mag,Building a Content-Based Search Engine I: Quantifying Similarity,https://www.reddit.com/r/MachineLearning/comments/800mag/building_a_contentbased_search_engine_i/,deepideas,1519516339,,0,1
1147,2018-2-25,2018,2,25,8,800nwm,[D] Thoughts on Open AI Vs Allen Institute for AI,https://www.reddit.com/r/MachineLearning/comments/800nwm/d_thoughts_on_open_ai_vs_allen_institute_for_ai/,MockingBird421,1519516772,"The title says it all, I'm in the process of applying to both, and while plenty is available on Open AI, little is available on Open AI even though they (at least very superficially) have similar size and teams. What are people here's thoughts?",4,2
1148,2018-2-25,2018,2,25,9,800v2h,Smoke some dank &lt;eom&gt;,https://www.reddit.com/r/MachineLearning/comments/800v2h/smoke_some_dank_eom/,scionaura,1519518719,[removed],1,1
1149,2018-2-25,2018,2,25,9,800wzy,[R] Neural Network Authorship Attribution: Helping RNNs Identify U.S. Presidential Speeches,https://www.reddit.com/r/MachineLearning/comments/800wzy/r_neural_network_authorship_attribution_helping/,QuantMountain,1519519231,,0,10
1150,2018-2-25,2018,2,25,10,8017cs,"[P] Fabrik: online collaborative platform to build, visualize and train DNNs via drag-and-drop interface (Caffe/TF/Keras)",https://www.reddit.com/r/MachineLearning/comments/8017cs/p_fabrik_online_collaborative_platform_to_build/,MaxTalanov,1519522149,,5,19
1151,2018-2-25,2018,2,25,11,801o40,Neural net breaks when input and output layers are not both 1,https://www.reddit.com/r/MachineLearning/comments/801o40/neural_net_breaks_when_input_and_output_layers/,5ponsky,1519526842,[removed],0,1
1152,2018-2-25,2018,2,25,12,801ts8,Is this how you have been initialising your neural nets,https://www.reddit.com/r/MachineLearning/comments/801ts8/is_this_how_you_have_been_initialising_your/,ady_anr,1519528487,,0,1
1153,2018-2-25,2018,2,25,12,801tzs,Keras vs Tensorflow Accuracy,https://www.reddit.com/r/MachineLearning/comments/801tzs/keras_vs_tensorflow_accuracy/,stevethatsmyname,1519528550,[removed],0,1
1154,2018-2-25,2018,2,25,12,801zuc,This AI Sings | Two Minute Papers,https://www.reddit.com/r/MachineLearning/comments/801zuc/this_ai_sings_two_minute_papers/,bosondediego,1519530316,,0,1
1155,2018-2-25,2018,2,25,13,8024te,Lush: Lisp Universal SHell,https://www.reddit.com/r/MachineLearning/comments/8024te/lush_lisp_universal_shell/,akssri,1519531829,,1,1
1156,2018-2-25,2018,2,25,14,802l14,[P] DeepPavlov: Open source library for training dialog systems (chatbots),https://www.reddit.com/r/MachineLearning/comments/802l14/p_deeppavlov_open_source_library_for_training/,SupraluminalShift,1519537184,,11,195
1157,2018-2-25,2018,2,25,17,8038w1,[N]Musician Who Lost His Arm Plays Piano Again with AI Prosthesis,https://www.reddit.com/r/MachineLearning/comments/8038w1/nmusician_who_lost_his_arm_plays_piano_again_with/,patrick_zhong,1519546599,,0,0
1158,2018-2-25,2018,2,25,17,803dgh,machine learning in aquaculture collaboration?,https://www.reddit.com/r/MachineLearning/comments/803dgh/machine_learning_in_aquaculture_collaboration/,xfocus3,1519548706,[removed],0,1
1159,2018-2-25,2018,2,25,18,803j3q,[P] AI Conference Deadlines,https://www.reddit.com/r/MachineLearning/comments/803j3q/p_ai_conference_deadlines/,pmigdal,1519551318,,9,32
1160,2018-2-25,2018,2,25,19,803u00,Selling 20k worth of google cloud computing power PM if interested.,https://www.reddit.com/r/MachineLearning/comments/803u00/selling_20k_worth_of_google_cloud_computing_power/,ML-GODS,1519556343,[removed],0,1
1161,2018-2-25,2018,2,25,20,803x5p,[Discussion] Anomaly detection in network traffic,https://www.reddit.com/r/MachineLearning/comments/803x5p/discussion_anomaly_detection_in_network_traffic/,satzioflax1,1519557766,What do you think is the best ML approach for anomaly detection in network traffic ?,22,21
1162,2018-2-25,2018,2,25,20,803xcy,What tunes you on? AKA what's your favorite hyper-parameter tuning method for DL models.,https://www.reddit.com/r/MachineLearning/comments/803xcy/what_tunes_you_on_aka_whats_your_favorite/,[deleted],1519557854,,0,1
1163,2018-2-25,2018,2,25,21,8047k7,[D] The Malicious Use of Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/8047k7/d_the_malicious_use_of_artificial_intelligence/,imitationcheese,1519562301,,5,2
1164,2018-2-25,2018,2,25,21,8048cy,Ear recognition,https://www.reddit.com/r/MachineLearning/comments/8048cy/ear_recognition/,vixtor313,1519562642,[removed],0,1
1165,2018-2-25,2018,2,25,23,804qbs,Areas of math and physics in machine learning and AI,https://www.reddit.com/r/MachineLearning/comments/804qbs/areas_of_math_and_physics_in_machine_learning_and/,[deleted],1519568784,,0,1
1166,2018-2-25,2018,2,25,23,804qp7,GAN output diversity - hack?,https://www.reddit.com/r/MachineLearning/comments/804qp7/gan_output_diversity_hack/,fourthie,1519568908,[removed],0,1
1167,2018-2-25,2018,2,25,23,804srx,[Discussion] Areas of mathematics in physics in machine learning,https://www.reddit.com/r/MachineLearning/comments/804srx/discussion_areas_of_mathematics_in_physics_in/,AritraChow,1519569577,"What areas of physics and mathematics do you think is good for learning and research in AI and machine learning other than the usual suspects of optimization, statistics, probability, linear algebra? I've seen some work with differential geometry in manifold learning and of course the use of statistical physics in the theory of deep learning. Are there any hidden gems in both these fields that might lead to breakthroughs in AI? Maybe we should try to learn those areas or seek out collaborations with mathematicians and physicists in those fields.",13,10
1168,2018-2-25,2018,2,25,23,804u7u,Can a program truly understand meanings of languages or can it just memorize information?,https://www.reddit.com/r/MachineLearning/comments/804u7u/can_a_program_truly_understand_meanings_of/,RonBurgundyNot,1519570006,[removed],0,1
1169,2018-2-26,2018,2,26,1,805fpt,Beginner open source machine learning projects to contribute to,https://www.reddit.com/r/MachineLearning/comments/805fpt/beginner_open_source_machine_learning_projects_to/,pockrasta,1519575730,[removed],0,1
1170,2018-2-26,2018,2,26,1,805gic,An Introduction to different Types of Convolutions in Deep Learning,https://www.reddit.com/r/MachineLearning/comments/805gic/an_introduction_to_different_types_of/,miranthalk,1519575913,,0,1
1171,2018-2-26,2018,2,26,1,805h2a,Q Learning With Minimal Dependencies?,https://www.reddit.com/r/MachineLearning/comments/805h2a/q_learning_with_minimal_dependencies/,NickAMD,1519576044,[removed],0,1
1172,2018-2-26,2018,2,26,2,805tnd,[D] Can someone make an online service for Deep Image Analogy ?,https://www.reddit.com/r/MachineLearning/comments/805tnd/d_can_someone_make_an_online_service_for_deep/,ad48hp,1519579063,"Running this on my notebook gives pretty unsatisfying results as i use low ratios. Apparently my memory cannot handle higher ones, and it always crashes when i try to do so.
:
https://www.reddit.com/r/MachineLearning/comments/6cro6h
https://github.com/msracver/Deep-Image-Analogy

'       ,       '   .",3,0
1173,2018-2-26,2018,2,26,2,805z0o,"""A Unified Framework for Stochastic Optimization"", Powell 2018",https://www.reddit.com/r/MachineLearning/comments/805z0o/a_unified_framework_for_stochastic_optimization/,mikhaelAI,1519580371,,0,1
1174,2018-2-26,2018,2,26,3,8065bz,Looking where a CNN is looking: Grad CAM,https://www.reddit.com/r/MachineLearning/comments/8065bz/looking_where_a_cnn_is_looking_grad_cam/,[deleted],1519581814,[deleted],0,1
1175,2018-2-26,2018,2,26,3,8065o9,"(Schmidhuber, 2009) Driven by Compression Progress: A Simple Principle Explains Essential Aspects of Subjective Beauty, Novelty, Surprise, Interestingness, Attention, Curiosity, Creativity, Art, Science, Music, Jokes",https://www.reddit.com/r/MachineLearning/comments/8065o9/schmidhuber_2009_driven_by_compression_progress_a/,mikhaelAI,1519581886,,0,1
1176,2018-2-26,2018,2,26,3,8065v9,[P] Where CNN is looking? - Grad CAM,https://www.reddit.com/r/MachineLearning/comments/8065v9/p_where_cnn_is_looking_grad_cam/,SupraluminalShift,1519581934,,1,5
1177,2018-2-26,2018,2,26,3,80694m,[N] Criteria for Building a Successful AI Chatbot,https://www.reddit.com/r/MachineLearning/comments/80694m/n_criteria_for_building_a_successful_ai_chatbot/,[deleted],1519582684,[deleted],0,1
1178,2018-2-26,2018,2,26,3,8069ew,[R] Criteria for Building a Successful AI Chatbot,https://www.reddit.com/r/MachineLearning/comments/8069ew/r_criteria_for_building_a_successful_ai_chatbot/,[deleted],1519582748,[deleted],0,1
1179,2018-2-26,2018,2,26,3,8069gy,How does renting a server work? I need to use software that's very very ram intensive.,https://www.reddit.com/r/MachineLearning/comments/8069gy/how_does_renting_a_server_work_i_need_to_use/,coconutscentedcat,1519582760,[removed],0,1
1180,2018-2-26,2018,2,26,3,806e3m,What courses can teach you to put your ML model in production?,https://www.reddit.com/r/MachineLearning/comments/806e3m/what_courses_can_teach_you_to_put_your_ml_model/,danvargg,1519583826,[removed],0,1
1181,2018-2-26,2018,2,26,3,806fk5,"[D] How do you, personally, stay grounded in this field?",https://www.reddit.com/r/MachineLearning/comments/806fk5/d_how_do_you_personally_stay_grounded_in_this/,ACTBRUH,1519584147,"By 'grounded', I mean, how do you get yourself to not feel like you're drowning in information, math, and new frameworks every single day? 

For me, I just take a bit of a break from reading the famous ICLR/NIPS/etc papers, and focus a bit more on the smaller, less foundational papers. For all the insane and innovative work that goes on at the top-tier conferences, those papers often a bit much to read through and understand. Out of the dozen I read from ICLR, I completely understood maybe one, and the rest were just me thinking 'no clue how they got to the conclusion, but that's a pretty cool conclusion'. 

Reading through a friendly 3-5 page paper with a single, very clear, and very incremental discovery is almost calming. Understanding exactly what I'm reading in this field is difficult, and I love stumbling across a paper where I understand exactly what the author is doing in the first read-through. ",17,2
1182,2018-2-26,2018,2,26,4,806sg8,Python: Accessing and Printing your IP Address and Location!,https://www.reddit.com/r/MachineLearning/comments/806sg8/python_accessing_and_printing_your_ip_address_and/,AnalystRisingTuts,1519587102,,0,1
1183,2018-2-26,2018,2,26,5,8075uo,[R] Skip-Gram  Zipf + Uniform = Vector Additivity (ACL 2017),https://www.reddit.com/r/MachineLearning/comments/8075uo/r_skipgram_zipf_uniform_vector_additivity_acl_2017/,pmigdal,1519590238,,1,5
1184,2018-2-26,2018,2,26,6,807ex4,[D] Machine Learning - WAYR (What Are You Reading) - Week 43,https://www.reddit.com/r/MachineLearning/comments/807ex4/d_machine_learning_wayr_what_are_you_reading_week/,ML_WAYR_bot,1519592406,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|31-40|41-50|
|----|-----|-----|-----|-----|
|[Week 1](https://www.reddit.com/r/MachineLearning/comments/4qyjiq/machine_learning_wayr_what_are_you_reading_week_1/)|[Week 11](https://www.reddit.com/r/MachineLearning/comments/57xw56/discussion_machine_learning_wayr_what_are_you/)|[Week 21](https://www.reddit.com/r/MachineLearning/comments/60ildf/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 31](https://www.reddit.com/r/MachineLearning/comments/6s0k1u/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 41](https://www.reddit.com/r/MachineLearning/comments/7tn2ax/d_machine_learning_wayr_what_are_you_reading_week/)|||
|[Week 2](https://www.reddit.com/r/MachineLearning/comments/4s2xqm/machine_learning_wayr_what_are_you_reading_week_2/)|[Week 12](https://www.reddit.com/r/MachineLearning/comments/5acb1t/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 22](https://www.reddit.com/r/MachineLearning/comments/64jwde/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 32](https://www.reddit.com/r/MachineLearning/comments/72ab5y/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 42](https://www.reddit.com/r/MachineLearning/comments/7wvjfk/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 3](https://www.reddit.com/r/MachineLearning/comments/4t7mqm/machine_learning_wayr_what_are_you_reading_week_3/)|[Week 13](https://www.reddit.com/r/MachineLearning/comments/5cwfb6/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 23](https://www.reddit.com/r/MachineLearning/comments/674331/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 33](https://www.reddit.com/r/MachineLearning/comments/75405d/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 4](https://www.reddit.com/r/MachineLearning/comments/4ub2kw/machine_learning_wayr_what_are_you_reading_week_4/)|[Week 14](https://www.reddit.com/r/MachineLearning/comments/5fc5mh/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 24](https://www.reddit.com/r/MachineLearning/comments/68hhhb/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 34](https://www.reddit.com/r/MachineLearning/comments/782js9/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 5](https://www.reddit.com/r/MachineLearning/comments/4xomf7/machine_learning_wayr_what_are_you_reading_week_5/)|[Week 15](https://www.reddit.com/r/MachineLearning/comments/5hy4ur/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 25](https://www.reddit.com/r/MachineLearning/comments/69teiz/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 35](https://www.reddit.com/r/MachineLearning/comments/7b0av0/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 6](https://www.reddit.com/r/MachineLearning/comments/4zcyvk/machine_learning_wayr_what_are_you_reading_week_6/)|[Week 16](https://www.reddit.com/r/MachineLearning/comments/5kd6vd/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 26](https://www.reddit.com/r/MachineLearning/comments/6d7nb1/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 36](https://www.reddit.com/r/MachineLearning/comments/7e3fx6/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 7](https://www.reddit.com/r/MachineLearning/comments/52t6mo/machine_learning_wayr_what_are_you_reading_week_7/)|[Week 17](https://www.reddit.com/r/MachineLearning/comments/5ob7dx/discussion_machine_learning_wayr_what_are_you/)|[Week 27](https://www.reddit.com/r/MachineLearning/comments/6gngwc/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 37](https://www.reddit.com/r/MachineLearning/comments/7hcc2c/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 8](https://www.reddit.com/r/MachineLearning/comments/53heol/machine_learning_wayr_what_are_you_reading_week_8/)|[Week 18](https://www.reddit.com/r/MachineLearning/comments/5r14yd/discussion_machine_learning_wayr_what_are_you/)|[Week 28](https://www.reddit.com/r/MachineLearning/comments/6jgdva/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 38](https://www.reddit.com/r/MachineLearning/comments/7kgcqr/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 9](https://www.reddit.com/r/MachineLearning/comments/54kvsu/machine_learning_wayr_what_are_you_reading_week_9/)|[Week 19](https://www.reddit.com/r/MachineLearning/comments/5tt9cz/discussion_machine_learning_wayr_what_are_you/)|[Week 29](https://www.reddit.com/r/MachineLearning/comments/6m9l1v/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 39](https://www.reddit.com/r/MachineLearning/comments/7nayri/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 10](https://www.reddit.com/r/MachineLearning/comments/56s2oa/discussion_machine_learning_wayr_what_are_you/)|[Week 20](https://www.reddit.com/r/MachineLearning/comments/5wh2wb/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 30](https://www.reddit.com/r/MachineLearning/comments/6p3ha7/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 40](https://www.reddit.com/r/MachineLearning/comments/7qel9p/d_machine_learning_wayr_what_are_you_reading_week/)||

Most upvoted papers two weeks ago:

/u/statmlsn: https://arxiv.org/abs/1802.03308).

Besides that, there are no rules, have fun.",70,9
1185,2018-2-26,2018,2,26,6,807fcw,[Discussion] Hyperparameter tuning for DL/ML Models,https://www.reddit.com/r/MachineLearning/comments/807fcw/discussion_hyperparameter_tuning_for_dlml_models/,unnamedn00b,1519592502,"It would be great to hear what methods and/or tools folks here are using to tune your deep learning models (or ML models generally). There does not seem to be a general consensus on this, especially with a number of available options like grid search, random search, Bayesian optimization, genetic algorithms, etc so it would be nice to have a better sense of what works for specific models/situations.",17,20
1186,2018-2-26,2018,2,26,6,807l0s,Fake news and bias detection in journalism as a service using TensorFlow,https://www.reddit.com/r/MachineLearning/comments/807l0s/fake_news_and_bias_detection_in_journalism_as_a/,AreYouFakeNews,1519593864,,0,1
1187,2018-2-26,2018,2,26,7,807us3,Looking for a CTO for a PowerPoint automation startup,https://www.reddit.com/r/MachineLearning/comments/807us3/looking_for_a_cto_for_a_powerpoint_automation/,magicbutton_startup,1519596155,[removed],0,1
1188,2018-2-26,2018,2,26,7,807yki,Neural Information Processing @ Tuebingen,https://www.reddit.com/r/MachineLearning/comments/807yki/neural_information_processing_tuebingen/,57426075,1519597015,[removed],0,1
1189,2018-2-26,2018,2,26,7,8082iz,[Research],https://www.reddit.com/r/MachineLearning/comments/8082iz/research/,ISRproject,1519598016,"Hi, exponentially smarter people!
I'm a High School student with a reasonably basic research project where I am to implement an AI Agent to learn and master games and graph a linear regression of its time to mastery versus the task complexity. My partner and I have decided task complexity is to be based on the number of state spaces (or different inputs) the AI can use. We would like to find a good primary AI and have been using public OpenAi templates. Do any of you guys have suggestions on an efficient and effective way to make a ""cookie cutter"" algorithm? We'd like for it to be as easy to understand as possible.

Thank you!",3,0
1190,2018-2-26,2018,2,26,7,8084je,[P] Handwriting Synthesis (Demo &amp; Pre-trained Model),https://www.reddit.com/r/MachineLearning/comments/8084je/p_handwriting_synthesis_demo_pretrained_model/,hispanic_scholar,1519598536,,9,24
1191,2018-2-26,2018,2,26,8,808gwd,[D] It is tiring being such a minority in AI,https://www.reddit.com/r/MachineLearning/comments/808gwd/d_it_is_tiring_being_such_a_minority_in_ai/,baylearn,1519601399,,33,1
1192,2018-2-26,2018,2,26,8,808i0e,New episode on Variational Autoencoders now online!,https://www.reddit.com/r/MachineLearning/comments/808i0e/new_episode_on_variational_autoencoders_now_online/,[deleted],1519601667,[deleted],0,1
1193,2018-2-26,2018,2,26,8,808j84,[P] Just released my latest video on Variational Autoencoders!,https://www.reddit.com/r/MachineLearning/comments/808j84/p_just_released_my_latest_video_on_variational/,tr1pzz,1519601998,,48,285
1194,2018-2-26,2018,2,26,10,80934u,MetaLearning based text classification techniques,https://www.reddit.com/r/MachineLearning/comments/80934u/metalearning_based_text_classification_techniques/,kumarivin,1519607192,[removed],0,1
1195,2018-2-26,2018,2,26,10,8095vc,ClaoudML - Free Machine Learning Resources,https://www.reddit.com/r/MachineLearning/comments/8095vc/claoudml_free_machine_learning_resources/,randylaosat,1519607931,,1,1
1196,2018-2-26,2018,2,26,10,809bhb,How much a loss function can decrease per epoch?,https://www.reddit.com/r/MachineLearning/comments/809bhb/how_much_a_loss_function_can_decrease_per_epoch/,[deleted],1519609468,,0,1
1197,2018-2-26,2018,2,26,10,809c7i,Sharing Reinforcement Learning and Imitation Learning Implementations,https://www.reddit.com/r/MachineLearning/comments/809c7i/sharing_reinforcement_learning_and_imitation/,[deleted],1519609648,,0,1
1198,2018-2-26,2018,2,26,10,809e6z,[R] Efficient Neural Audio Synthesis,https://www.reddit.com/r/MachineLearning/comments/809e6z/r_efficient_neural_audio_synthesis/,hardmaru,1519610191,,22,45
1199,2018-2-26,2018,2,26,11,809ihl,Masters if Health Informatics,https://www.reddit.com/r/MachineLearning/comments/809ihl/masters_if_health_informatics/,Nyd3r,1519611370,[removed],0,1
1200,2018-2-26,2018,2,26,12,809znh,[D] Online Learning Methods for Neural Networks?,https://www.reddit.com/r/MachineLearning/comments/809znh/d_online_learning_methods_for_neural_networks/,modx07,1519616179,"Does anyone know of much work in this area or any general approaches one would use in a realistic setting?

For example, if I have a CNN based classifier to identify objects but I want it to learn to detect a new object, I'd have to retrain the network with an extra neuron in the softmax layer.

Are there other ways of doing this or research on making robust changes to a network to add a new possible label? Often times in a practical setting, you don't even necessarily have too much data for the object you want to add compared to the other objects you have trained for so the class I'm balance problem can prevent the network from generalizing well on those cases.

As of now, I can only think of simply freezing most of the layers of the CNN and only retraining the last couple layers. Am I wrong in thinking this is a general ""problem"" with NNs in general at the moment? 

--

Just to be clear, when I say problem, what I mean is that these NNs work as advertised per se, and you wouldn't expect to easily add classes and maintain accuracy...but on the other hand it seems like a good learning/classifying method would not be so difficult to add new objects to. Then again, perhaps this is true of statistical methods as well.",7,4
1201,2018-2-26,2018,2,26,12,80a03c,"[R] Unicorn: Continual Learning with a Universal, Off-policy Agent",https://www.reddit.com/r/MachineLearning/comments/80a03c/r_unicorn_continual_learning_with_a_universal/,Kaixhin,1519616294,,1,10
1202,2018-2-26,2018,2,26,12,80a133,"[R] ""A Brief Introduction to Machine Learning for Engineers"" - A monograph on the key theoretical concepts of machine learning",https://www.reddit.com/r/MachineLearning/comments/80a133/r_a_brief_introduction_to_machine_learning_for/,HV250,1519616574,,3,35
1203,2018-2-26,2018,2,26,13,80a7e5,"What practical real world uses does my neural network have if it can sort faces according to their race, gender, attractiveness, facial hair, etc...?",https://www.reddit.com/r/MachineLearning/comments/80a7e5/what_practical_real_world_uses_does_my_neural/,PokeswagJ,1519618403,[removed],0,1
1204,2018-2-26,2018,2,26,13,80a8wr,[P] Match similar words to a known list - word2vec? Looking for inspiration..,https://www.reddit.com/r/MachineLearning/comments/80a8wr/p_match_similar_words_to_a_known_list_word2vec/,alfa_sixten,1519618852,"Hi there community,

I am looking for some inspiration - or suggestions on libraries or 3rd party products to use (free or not), for the following use-case:

&gt; Maintain a mapping of synonyms to a known list of terms - and do a search on similar words to those synonyms:

For example: 
* I have a list of known occupations in an industry: for example, machine-operator, accountant, lawyer, manager, coal miner, etc.,
*If I were to search for the job-title ""tax advisor"", then I'd expect for that it be matched to 'accountant' from the list above,
* It will be a model that can be given user-input - for example, over time with more user input it can be trained,
* It is possible that a job-title can have multiple matching occupations, for example if I were to search for ""hustler"", I'd expect 'Manager', 'CEO', 'Executive' to show up,

Assume little knowledge on my part - share your thoughts? 

Thanks. 
",2,1
1205,2018-2-26,2018,2,26,14,80aknv,A question about the hidden state size in an LSTM,https://www.reddit.com/r/MachineLearning/comments/80aknv/a_question_about_the_hidden_state_size_in_an_lstm/,chachapwns,1519622339,[removed],0,1
1206,2018-2-26,2018,2,26,14,80akw3,What does it take to get to the point of creating brand new ML algorithms / frameworks ?,https://www.reddit.com/r/MachineLearning/comments/80akw3/what_does_it_take_to_get_to_the_point_of_creating/,ioio112211,1519622404,[removed],0,1
1207,2018-2-26,2018,2,26,14,80anto,[D] Anyone who has taken a look at the huge list of papers leveraging GANs can't help but come away with a sense that this is an important area. I have only a scattershot aquaintence with this area -- which papers are most important to read? Which are most interesting?,https://www.reddit.com/r/MachineLearning/comments/80anto/d_anyone_who_has_taken_a_look_at_the_huge_list_of/,Euglossine,1519623322,,7,6
1208,2018-2-26,2018,2,26,14,80as07,How to make feature-wise heatmap images?,https://www.reddit.com/r/MachineLearning/comments/80as07/how_to_make_featurewise_heatmap_images/,plznw4me,1519624611,[removed],0,1
1209,2018-2-26,2018,2,26,15,80au7p,"Built a basic perceptron, any feedback would be very appreciated from you all!",https://www.reddit.com/r/MachineLearning/comments/80au7p/built_a_basic_perceptron_any_feedback_would_be/,[deleted],1519625316,[deleted],0,1
1210,2018-2-26,2018,2,26,16,80b3m2,[D] DeepMinds misleading campaign against innateness,https://www.reddit.com/r/MachineLearning/comments/80b3m2/d_deepminds_misleading_campaign_against_innateness/,wei_jok,1519628459,,5,0
1211,2018-2-26,2018,2,26,16,80b8y4,When to use residual learning for gaussian denoising?,https://www.reddit.com/r/MachineLearning/comments/80b8y4/when_to_use_residual_learning_for_gaussian/,GJGJ1,1519630119,[removed],0,1
1212,2018-2-26,2018,2,26,17,80bfbx,Anomaly Detection with GAN (Pytorch),https://www.reddit.com/r/MachineLearning/comments/80bfbx/anomaly_detection_with_gan_pytorch/,a141890,1519632233,[removed],0,1
1213,2018-2-26,2018,2,26,17,80bico,Model relies heavily on specific feature,https://www.reddit.com/r/MachineLearning/comments/80bico/model_relies_heavily_on_specific_feature/,yhu10tthu,1519633257,[removed],0,1
1214,2018-2-26,2018,2,26,17,80bmlh,Maths needed for ML/RL research?,https://www.reddit.com/r/MachineLearning/comments/80bmlh/maths_needed_for_mlrl_research/,Haithamkhedr,1519634776,[removed],0,1
1215,2018-2-26,2018,2,26,18,80bpn4,Messer Cutting Tables - Complement your machines,https://www.reddit.com/r/MachineLearning/comments/80bpn4/messer_cutting_tables_complement_your_machines/,Messer-123,1519635897,,0,1
1216,2018-2-26,2018,2,26,18,80bxyy,Credit Card Fraud Detection- Build A Complete Project in Machine Learning For Free!,https://www.reddit.com/r/MachineLearning/comments/80bxyy/credit_card_fraud_detection_build_a_complete/,ciaracodes,1519638819,,1,1
1217,2018-2-26,2018,2,26,19,80c6g6,[P] Implementing a speaker recognition project for Authentication purposes,https://www.reddit.com/r/MachineLearning/comments/80c6g6/p_implementing_a_speaker_recognition_project_for/,amma1804,1519641950,"Hello, 


We are a team at a Data Science University, we have been given a project by our professor to try and implement an accurate authentication process in which the person's voice ID is used as a factor for the authentication. We have researched online and found a library : [recognito](https://github.com/amaurycrickx/recognito), but it isn't as accurate. We just explored GMMs and I-vectors, and some pre-made libraries for speech diarization, but couldn't find anything for Voice ID Authentication.



Voice ID Authentication systems are getting popular in banking systems too, but none of these have made their code open source. For implementing something like this, what would you guys recommend?",12,1
1218,2018-2-26,2018,2,26,20,80c8oj,[D] Techniques for generating noise to train denoising networks,https://www.reddit.com/r/MachineLearning/comments/80c8oj/d_techniques_for_generating_noise_to_train/,pescurris,1519642846,"I'm not very familiar at the moment with denoising networks and approaches but I'm planning to train a denoising autoencoder for a dataset in which I have noisy and clean data. 
The problem is that in the documentation I find there's always an artificial way of creating simple noise like gaussian noise or salt&amp;pepper, but what about different non standard noise? I have literally seen papers cutting and pasting noise from one image to another (not for deep learning though). Having a dataset in which all the images are very similar is there a way to mimic the noise from noisy samples to clean ones? Kind of a ""style transfer"" way?

Maybe it's not an interesting question but I'm very interested in ways of dealing with this.",1,2
1219,2018-2-26,2018,2,26,20,80cfea,LOD 2018 is proud to announce distinguished Keynote Speakers,https://www.reddit.com/r/MachineLearning/comments/80cfea/lod_2018_is_proud_to_announce_distinguished/,[deleted],1519645232,,0,1
1220,2018-2-26,2018,2,26,21,80cis2,Cement Filling Machine with 4 mouthes,https://www.reddit.com/r/MachineLearning/comments/80cis2/cement_filling_machine_with_4_mouthes/,lgsherry,1519646428,,1,1
1221,2018-2-26,2018,2,26,21,80cjal,LOD 2018 is proud to announce distinguished Keynote Speakers: who would you like to meet most?,https://www.reddit.com/r/MachineLearning/comments/80cjal/lod_2018_is_proud_to_announce_distinguished/,[deleted],1519646566,,0,1
1222,2018-2-26,2018,2,26,21,80cm87,LOD 2018 is proud to announce distinguished Keynote Speakers: who would you most like to meet?,https://www.reddit.com/r/MachineLearning/comments/80cm87/lod_2018_is_proud_to_announce_distinguished/,joe_va,1519647442,[removed],1,1
1223,2018-2-26,2018,2,26,22,80cwtd,Bellman equation why highest quality from next state?,https://www.reddit.com/r/MachineLearning/comments/80cwtd/bellman_equation_why_highest_quality_from_next/,Lougehrig10,1519650815,[removed],0,1
1224,2018-2-26,2018,2,26,22,80d18p,Colorizing Black And White Photos - A Funny Example For Deep Learning Beginners,https://www.reddit.com/r/MachineLearning/comments/80d18p/colorizing_black_and_white_photos_a_funny_example/,[deleted],1519652089,[deleted],0,1
1225,2018-2-26,2018,2,26,23,80d808,ACtuAL,https://www.reddit.com/r/MachineLearning/comments/80d808/actual/,microchipsndip,1519653879,[removed],0,1
1226,2018-2-26,2018,2,26,23,80dahn,Improving Vanilla Gradient Descent  Towards Data Science,https://www.reddit.com/r/MachineLearning/comments/80dahn/improving_vanilla_gradient_descent_towards_data/,miranthalk,1519654515,,0,1
1227,2018-2-26,2018,2,26,23,80dd6g,Does passing duplicate readings affect the machine learning algorithm in any way,https://www.reddit.com/r/MachineLearning/comments/80dd6g/does_passing_duplicate_readings_affect_the/,TheOfficialPu,1519655215,[removed],0,1
1228,2018-2-26,2018,2,26,23,80dg4b,How to use Batch Normalization with TensorFlow and tf.keras,https://www.reddit.com/r/MachineLearning/comments/80dg4b/how_to_use_batch_normalization_with_tensorflow/,crawles89,1519655963,,0,1
1229,2018-2-27,2018,2,27,0,80dtyv,Can an A.I. System be a Designer? (Part 2)  Medium,https://www.reddit.com/r/MachineLearning/comments/80dtyv/can_an_ai_system_be_a_designer_part_2_medium/,iamadsgnr,1519659189,,0,1
1230,2018-2-27,2018,2,27,1,80e4dt,"[R] ""Measuring Unintended Neural Network Memorization &amp; Extracting Secrets"" - it is possible to extract training data from neural networks",https://www.reddit.com/r/MachineLearning/comments/80e4dt/r_measuring_unintended_neural_network/,pm_me_ur_beethoven,1519661510,,10,54
1231,2018-2-27,2018,2,27,1,80e57b,[R] Criteria for Building a Successful AI Chatbot,https://www.reddit.com/r/MachineLearning/comments/80e57b/r_criteria_for_building_a_successful_ai_chatbot/,gwen0927,1519661671,,0,1
1232,2018-2-27,2018,2,27,1,80eabb,ML/AI in Aquaculture,https://www.reddit.com/r/MachineLearning/comments/80eabb/mlai_in_aquaculture/,xfocus3,1519662787,[removed],0,1
1233,2018-2-27,2018,2,27,1,80edjl,[P] New Robotics environments in OpenAI Gym,https://www.reddit.com/r/MachineLearning/comments/80edjl/p_new_robotics_environments_in_openai_gym/,metaAI,1519663467,,27,138
1234,2018-2-27,2018,2,27,2,80eij6,Series - An Outsider's Tour of Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/80eij6/series_an_outsiders_tour_of_reinforcement_learning/,[deleted],1519664500,[deleted],0,1
1235,2018-2-27,2018,2,27,2,80eiz3,[P] Implementing a CapsNet for car make-model classification,https://www.reddit.com/r/MachineLearning/comments/80eiz3/p_implementing_a_capsnet_for_car_makemodel/,endorfiner,1519664593,"Hi!

I'm playing with CapsNet using Tensorflow to classify images taken from a traffic cam. I decided to start with just two classes (Fiat-Panda and Fiat-500) and I created a dataset with cropped images of car's rear. 

Following [this](https://becominghuman.ai/understand-and-apply-capsnet-on-traffic-sign-classification-a592e2d4a4ea) implementation I changed it in this way: 

DATASETS (per class):


+ train: 800 images
+ validation: 100 images
+ test: 100 images
(no data-augmentation)

INPUT: 120x72 rectangle-images, 1 color channel

ARCHITECTURE:


+ CONVOLUTION_1 [6x6 kernel, 256 filters, relu activation]
+ CONVOLUTION_2 [6x6 kernel, 64 filters, relu activation, dropout]
+ FIRST_CAPS_LAYER [29*53*16=24592 capsules that outputs a vector of 16 parameters]
+ FINAL_CAPS_LAYER [2 capsules that outputs a pose vector of 32 parameters]


I reached a 0.56 accuracy on the testset which is pretty low for a 2-class classification problem. [Here](https://imgur.com/a/8PLct) you can see the recap.

The decoder on the final caps layer outputs mixed images of the two classes and the loss function on the test set doesn't converge. 

I'm new to CapsNet and I'm trying to figure it out what's the best way to improve the architecture and understand what I'm doing wrong",9,1
1236,2018-2-27,2018,2,27,2,80ejmk,[D] Series - An Outsider's Tour of Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/80ejmk/d_series_an_outsiders_tour_of_reinforcement/,hindupuravinash,1519664739,,19,12
1237,2018-2-27,2018,2,27,2,80ekbt,How far can you go with Python?,https://www.reddit.com/r/MachineLearning/comments/80ekbt/how_far_can_you_go_with_python/,Detharatsh,1519664864,[removed],0,1
1238,2018-2-27,2018,2,27,2,80ev7l,[P] Generating realistic Yelp restaurant reviews with Keras,https://www.reddit.com/r/MachineLearning/comments/80ev7l/p_generating_realistic_yelp_restaurant_reviews/,SupraluminalShift,1519667008,,8,3
1239,2018-2-27,2018,2,27,2,80ezwy,What exactly is meant by the term machine learning model? An explanation by Gurjeet Singh.,https://www.reddit.com/r/MachineLearning/comments/80ezwy/what_exactly_is_meant_by_the_term_machine/,jtsymonds,1519667965,,0,1
1240,2018-2-27,2018,2,27,3,80fcmx,[R] Adversarial Examples that Fool both Human and Computer Vision,https://www.reddit.com/r/MachineLearning/comments/80fcmx/r_adversarial_examples_that_fool_both_human_and/,downtownslim,1519670796,,6,2
1241,2018-2-27,2018,2,27,3,80fdek,[Discussion]Are ELM's the same as the Normal Equation?,https://www.reddit.com/r/MachineLearning/comments/80fdek/discussionare_elms_the_same_as_the_normal_equation/,niszoig,1519671003,"Do we just have to apply the normal equation to the output of the hidden layer(which introduces non-linearity)?

What is the motive behind using random hidden layer weights and then applying non-linearity?

What if the hidden layer representation of the input is not linearly separable? ",2,1
1242,2018-2-27,2018,2,27,3,80fevc,[P] Caffe Faster R-CNN on Microsoft Azure Cloud: Step by step configuration guide,https://www.reddit.com/r/MachineLearning/comments/80fevc/p_caffe_faster_rcnn_on_microsoft_azure_cloud_step/,udaykp,1519671279,,0,1
1243,2018-2-27,2018,2,27,4,80fmbs,[R] Learning Latent Permutations with Gumbel-Sinkhorn Networks,https://www.reddit.com/r/MachineLearning/comments/80fmbs/r_learning_latent_permutations_with/,SuperFX,1519673011,,0,6
1244,2018-2-27,2018,2,27,4,80fouq,[D] Reasons to use Caffe vs Tensorflow/Pytorch,https://www.reddit.com/r/MachineLearning/comments/80fouq/d_reasons_to_use_caffe_vs_tensorflowpytorch/,bogdan461993,1519673662,"Hi guys! I was wondering, what are your reasons for still using Caffe vs newer frameworks like Tensorflow/Pytorch?",13,7
1245,2018-2-27,2018,2,27,5,80g1ht,[P] Solving Bongard Problems With Deep Learning,https://www.reddit.com/r/MachineLearning/comments/80g1ht/p_solving_bongard_problems_with_deep_learning/,wotcher,1519675824,,0,1
1246,2018-2-27,2018,2,27,5,80g6m7,Help with strange result using image augmentation + freezing on keras models,https://www.reddit.com/r/MachineLearning/comments/80g6m7/help_with_strange_result_using_image_augmentation/,[deleted],1519676835,[deleted],0,1
1247,2018-2-27,2018,2,27,5,80g7e8,List of Free Must-Read Machine Learning Books,https://www.reddit.com/r/MachineLearning/comments/80g7e8/list_of_free_mustread_machine_learning_books/,psangrene,1519676981,,0,1
1248,2018-2-27,2018,2,27,6,80gksx,[D] The Teacup Story,https://www.reddit.com/r/MachineLearning/comments/80gksx/d_the_teacup_story/,visarga,1519679682,,5,3
1249,2018-2-27,2018,2,27,6,80goaq,[P] Deep Learning in the cloud. My very first YouTube video on a series on Deep Learning on AWS. Feedback really appreciated.,https://www.reddit.com/r/MachineLearning/comments/80goaq/p_deep_learning_in_the_cloud_my_very_first/,cool_playa,1519680424,,22,103
1250,2018-2-27,2018,2,27,6,80gr90,AI is hunting the worlds deadliest killer,https://www.reddit.com/r/MachineLearning/comments/80gr90/ai_is_hunting_the_worlds_deadliest_killer/,davesaunders,1519681024,,0,1
1251,2018-2-27,2018,2,27,6,80gtom,Benevolent AI drug discovery paper at ICLR 2018: review,https://www.reddit.com/r/MachineLearning/comments/80gtom/benevolent_ai_drug_discovery_paper_at_iclr_2018/,mostafabenh,1519681536,,0,0
1252,2018-2-27,2018,2,27,7,80h1r2,Dynamic word embeddings for evolving semantic discovery,https://www.reddit.com/r/MachineLearning/comments/80h1r2/dynamic_word_embeddings_for_evolving_semantic/,cavedave,1519683247,,3,4
1253,2018-2-27,2018,2,27,7,80h8uk,Machine Learning in Javascript with Autograd and GPU support | Propel ML,https://www.reddit.com/r/MachineLearning/comments/80h8uk/machine_learning_in_javascript_with_autograd_and/,sksq9,1519684751,,0,1
1254,2018-2-27,2018,2,27,7,80haoz,How to get fast response from multiple batch trained models,https://www.reddit.com/r/MachineLearning/comments/80haoz/how_to_get_fast_response_from_multiple_batch/,datavizu,1519685136,[removed],0,1
1255,2018-2-27,2018,2,27,8,80hiam,My school asked me to present my research project on machine learning for the interpretation of EEG brain scans for some parents.,https://www.reddit.com/r/MachineLearning/comments/80hiam/my_school_asked_me_to_present_my_research_project/,Aedificatus,1519686819,,1,1
1256,2018-2-27,2018,2,27,8,80hk78,Anyone with a DGX-1?,https://www.reddit.com/r/MachineLearning/comments/80hk78/anyone_with_a_dgx1/,Simusid,1519687250,[removed],0,1
1257,2018-2-27,2018,2,27,8,80hrde,GAN reading list by Ian Goodfellow,https://www.reddit.com/r/MachineLearning/comments/80hrde/gan_reading_list_by_ian_goodfellow/,cosminro,1519688929,,0,1
1258,2018-2-27,2018,2,27,9,80i3t6,Has anyone used machine learning for construction estimating,https://www.reddit.com/r/MachineLearning/comments/80i3t6/has_anyone_used_machine_learning_for_construction/,litifeta,1519691944,[removed],0,1
1259,2018-2-27,2018,2,27,9,80i7z7,CakeChat: Emotional Generative Dialog System,https://www.reddit.com/r/MachineLearning/comments/80i7z7/cakechat_emotional_generative_dialog_system/,aikazah,1519692955,,0,1
1260,2018-2-27,2018,2,27,10,80ifhe,"Deep Learning from first principles in Python, R and Octave  Part 4",https://www.reddit.com/r/MachineLearning/comments/80ifhe/deep_learning_from_first_principles_in_python_r/,tvganesh,1519694829,,0,1
1261,2018-2-27,2018,2,27,10,80igh8,ClaoudML - Which logo is best? [HELP],https://www.reddit.com/r/MachineLearning/comments/80igh8/claoudml_which_logo_is_best_help/,randylaosat,1519695074,,1,1
1262,2018-2-27,2018,2,27,10,80ii9j,Neuroscientist on how free-energy principle theory provides a better framework for intelligent agent action than traditional reinforcement learning,https://www.reddit.com/r/MachineLearning/comments/80ii9j/neuroscientist_on_how_freeenergy_principle_theory/,blowingthru,1519695504,,6,6
1263,2018-2-27,2018,2,27,11,80ioki,Question about Machine Learning for Medical Imaging,https://www.reddit.com/r/MachineLearning/comments/80ioki/question_about_machine_learning_for_medical/,neurointerventional,1519697064,[removed],0,1
1264,2018-2-27,2018,2,27,11,80ivcw,[R] One Big Net For Everything (Schmidhuber),https://www.reddit.com/r/MachineLearning/comments/80ivcw/r_one_big_net_for_everything_schmidhuber/,inarrears,1519698740,,57,54
1265,2018-2-27,2018,2,27,11,80ixbq,[D] PyVideo.org  Bayesian Optimization - Can you do better than randomly guessing parameters?,https://www.reddit.com/r/MachineLearning/comments/80ixbq/d_pyvideoorg_bayesian_optimization_can_you_do/,_alphamaximus_,1519699239,,0,1
1266,2018-2-27,2018,2,27,12,80j787,"Best way to send patches of an pooling layer to a prediction layer, which is then used to mask the pooling layer in Keras?",https://www.reddit.com/r/MachineLearning/comments/80j787/best_way_to_send_patches_of_an_pooling_layer_to_a/,Deinos_Mousike,1519701717,[removed],0,1
1267,2018-2-27,2018,2,27,12,80j8w7,[R] [1802.08760] Sensitivity and Generalization in Neural Networks: an Empirical Study,https://www.reddit.com/r/MachineLearning/comments/80j8w7/r_180208760_sensitivity_and_generalization_in/,evc123,1519702158,,1,7
1268,2018-2-27,2018,2,27,12,80jaks,What is the current state of patents/copyrights on machine learning algorithms?,https://www.reddit.com/r/MachineLearning/comments/80jaks/what_is_the_current_state_of_patentscopyrights_on/,Aeleonator,1519702615,[removed],0,1
1269,2018-2-27,2018,2,27,13,80jjh4,Back to Basics: Benchmarking Canonical Evolution Strategies for Playing Atari,https://www.reddit.com/r/MachineLearning/comments/80jjh4/back_to_basics_benchmarking_canonical_evolution/,mtbikerdb,1519705034,,0,1
1270,2018-2-27,2018,2,27,13,80jrtp,CheXNet-Keras: deep learning models to detect and localize diseases from chest X-Rays,https://www.reddit.com/r/MachineLearning/comments/80jrtp/chexnetkeras_deep_learning_models_to_detect_and/,[deleted],1519707417,[deleted],0,1
1271,2018-2-27,2018,2,27,14,80jv48,[P] CheXNet-Keras: deep learning models to detect and localize diseases from chest X-Rays,https://www.reddit.com/r/MachineLearning/comments/80jv48/p_chexnetkeras_deep_learning_models_to_detect_and/,SupraluminalShift,1519708364,,0,19
1272,2018-2-27,2018,2,27,15,80k5d4,Commercial Cashew Nut Shelling Machine Line,https://www.reddit.com/r/MachineLearning/comments/80k5d4/commercial_cashew_nut_shelling_machine_line/,gelserena,1519711380,,1,1
1273,2018-2-27,2018,2,27,15,80kc8p,[P] Analyzing the lifecycle of contributors in open-source repositories,https://www.reddit.com/r/MachineLearning/comments/80kc8p/p_analyzing_the_lifecycle_of_contributors_in/,sushanthiray,1519713514,,0,0
1274,2018-2-27,2018,2,27,16,80ko8q,[N] Age of AI Conference 2018,https://www.reddit.com/r/MachineLearning/comments/80ko8q/n_age_of_ai_conference_2018/,polllyyy,1519717487,,0,1
1275,2018-2-27,2018,2,27,17,80l074,Could someone interpret this WGAP-GP loss? I can't understand this collapse. values in logscale?,https://www.reddit.com/r/MachineLearning/comments/80l074/could_someone_interpret_this_wgapgp_loss_i_cant/,falmasri,1519721442,[removed],0,1
1276,2018-2-27,2018,2,27,18,80laqd,[Ask] What's the best approach to build a knowledge model that can be used to enhance the accuracy of machine learning models?,https://www.reddit.com/r/MachineLearning/comments/80laqd/ask_whats_the_best_approach_to_build_a_knowledge/,My_Peanut,1519725145,[removed],0,1
1277,2018-2-27,2018,2,27,19,80ldcq,[P] How Alibaba's E-commerce Robot Assistant Works,https://www.reddit.com/r/MachineLearning/comments/80ldcq/p_how_alibabas_ecommerce_robot_assistant_works/,nianhao,1519726069,,0,29
1278,2018-2-27,2018,2,27,19,80leki,Anyone else see the ad for the Kaggle CEO AMA on Reddit?,https://www.reddit.com/r/MachineLearning/comments/80leki/anyone_else_see_the_ad_for_the_kaggle_ceo_ama_on/,RealSocialDynamic,1519726471,[removed],0,1
1279,2018-2-27,2018,2,27,19,80lept,[R] The Secret Sharer: Measuring Unintended Neural Network Memorization &amp; Extracting Secrets,https://www.reddit.com/r/MachineLearning/comments/80lept/r_the_secret_sharer_measuring_unintended_neural/,Enforcer0,1519726530,,2,7
1280,2018-2-27,2018,2,27,19,80lf5d,"[N] Interview: Kobi Stok, Vice President, Product at WalkMe",https://www.reddit.com/r/MachineLearning/comments/80lf5d/n_interview_kobi_stok_vice_president_product_at/,chris_shpak,1519726679,,0,1
1281,2018-2-27,2018,2,27,19,80lhoz,[N] Berkeley Lab Minimalist Machine Learning Algorithms Analyze Images From Very Little Data,https://www.reddit.com/r/MachineLearning/comments/80lhoz/n_berkeley_lab_minimalist_machine_learning/,757cbdb0b61385577130,1519727627,,15,102
1282,2018-2-27,2018,2,27,19,80ljpx,[N] Is Cloud Machine Learning Right For Your Business?,https://www.reddit.com/r/MachineLearning/comments/80ljpx/n_is_cloud_machine_learning_right_for_your/,digitalson,1519728391,,0,1
1283,2018-2-27,2018,2,27,19,80lkmv,iManage/RAVN Extends ML Security Capabilities to Thompson &amp; Knight,https://www.reddit.com/r/MachineLearning/comments/80lkmv/imanageravn_extends_ml_security_capabilities_to/,ArtificialLawyer,1519728724,,0,1
1284,2018-2-27,2018,2,27,20,80lodg,[1802.08686] Adversarial vulnerability for any classifier,https://www.reddit.com/r/MachineLearning/comments/80lodg/180208686_adversarial_vulnerability_for_any/,ihaphleas,1519730051,,0,1
1285,2018-2-27,2018,2,27,20,80lp9p,IS DATA WAREHOUSE IN DANGER,https://www.reddit.com/r/MachineLearning/comments/80lp9p/is_data_warehouse_in_danger/,anshul2315,1519730362,,0,1
1286,2018-2-27,2018,2,27,21,80m2al,"Watch out America, China's A.I is getting smarter!",https://www.reddit.com/r/MachineLearning/comments/80m2al/watch_out_america_chinas_ai_is_getting_smarter/,chewchun,1519734603,,0,1
1287,2018-2-27,2018,2,27,22,80mbqt,[N] Petnica summer institute machine learning seminar,https://www.reddit.com/r/MachineLearning/comments/80mbqt/n_petnica_summer_institute_machine_learning/,rvukasin,1519737237,"I would like to encourage every undergraduate/graduate student interested in getting broad theoretical and practical knowledge in machine learning to apply for Petnica summer institute machine learning seminar (http://psiml.petnica.rs).

This seminar is held by Microsoft Development Center Serbia engineers that work on really interesting machine learning related projects like Windows Mixed Reality, Bing local search, handwritten math formula recognition, extracting map features from satellite images and many more as well as invited speakers from other companies/universities. Many people found this seminar to be life changing and you can check out some of their testimonials here: http://psiml.petnica.rs/testimonials.php

I am one of the lecturers so you can ask me anything you want to know more about the seminar and I will be happy to answer. The registration is now open and the seminar will be held from 22nd to 31st of July in Petnica, Serbia. You can register at http://psiml.petlja.org.

Hope to meet some of you on the seminar this summer :)",8,21
1288,2018-2-27,2018,2,27,22,80miw3,Deepmind salary vs. other US-based research labs?,https://www.reddit.com/r/MachineLearning/comments/80miw3/deepmind_salary_vs_other_usbased_research_labs/,[deleted],1519739148,,0,1
1289,2018-2-27,2018,2,27,23,80mnjt,Machine Learning Summer Schools 2018,https://www.reddit.com/r/MachineLearning/comments/80mnjt/machine_learning_summer_schools_2018/,TLESORT,1519740318,[removed],0,1
1290,2018-2-27,2018,2,27,23,80mxcq,Fuzzy-Logic Controlled Genetic Algorithm for the Rail-Freight Crew-Scheduling Problem,https://www.reddit.com/r/MachineLearning/comments/80mxcq/fuzzylogic_controlled_genetic_algorithm_for_the/,fimari,1519742625,,0,1
1291,2018-2-28,2018,2,28,0,80n7ph,[P] First Neural Network Run on the Ethereum Blockchain,https://www.reddit.com/r/MachineLearning/comments/80n7ph/p_first_neural_network_run_on_the_ethereum/,mikeyanderson,1519744919,,42,5
1292,2018-2-28,2018,2,28,0,80n9zt,[P] Keras-GAN: Collection of accessible implementations of GANs in Keras,https://www.reddit.com/r/MachineLearning/comments/80n9zt/p_kerasgan_collection_of_accessible/,Eriklindernoren,1519745426,,7,110
1293,2018-2-28,2018,2,28,0,80nadc,treatment combinations data set,https://www.reddit.com/r/MachineLearning/comments/80nadc/treatment_combinations_data_set/,paris_DL,1519745512,[removed],0,1
1294,2018-2-28,2018,2,28,0,80nczw,What is Giga Multiply-Accumulate Operations per Second or GMACS?,https://www.reddit.com/r/MachineLearning/comments/80nczw/what_is_giga_multiplyaccumulate_operations_per/,yankexe,1519746079,[removed],0,1
1295,2018-2-28,2018,2,28,0,80nhal,I created a Python package to collect Uber fares to get started on DS/ML,https://www.reddit.com/r/MachineLearning/comments/80nhal/i_created_a_python_package_to_collect_uber_fares/,kevinoxy,1519747012,,0,1
1296,2018-2-28,2018,2,28,0,80nhnf,Cakewalk Sampling,https://www.reddit.com/r/MachineLearning/comments/80nhnf/cakewalk_sampling/,[deleted],1519747084,,0,1
1297,2018-2-28,2018,2,28,1,80nmkp,[1802.09030] Cakewalk Sampling,https://www.reddit.com/r/MachineLearning/comments/80nmkp/180209030_cakewalk_sampling/,uri_patish,1519748093,,16,5
1298,2018-2-28,2018,2,28,1,80nrgy,[N] 101 NumPy Exercises for Data Analysis,https://www.reddit.com/r/MachineLearning/comments/80nrgy/n_101_numpy_exercises_for_data_analysis/,selva86,1519749072,"I compiled a list of numpy practice exercises related to data analysis. Might be helpful if you want to practice some data munging problems. Feedback welcome!

Link: https://www.machinelearningplus.com/101-numpy-exercises-python/",24,121
1299,2018-2-28,2018,2,28,1,80o0bn,Free Guide: Interpretable Machine Learning,https://www.reddit.com/r/MachineLearning/comments/80o0bn/free_guide_interpretable_machine_learning/,psangrene,1519750779,,0,1
1300,2018-2-28,2018,2,28,2,80o4jh,[R] Zero-Shot Question Generation from Knowledge Graphs for Unseen Predicates and Entity Types,https://www.reddit.com/r/MachineLearning/comments/80o4jh/r_zeroshot_question_generation_from_knowledge/,[deleted],1519751583,[deleted],0,1
1301,2018-2-28,2018,2,28,2,80o5dh,[R] Zero-Shot Question Generation from Knowledge Graphs for Unseen Predicates and Entity Types,https://www.reddit.com/r/MachineLearning/comments/80o5dh/r_zeroshot_question_generation_from_knowledge/,pigdogsheep,1519751760,,0,3
1302,2018-2-28,2018,2,28,2,80o6ht,AI as a propaganda machine for religion,https://www.reddit.com/r/MachineLearning/comments/80o6ht/ai_as_a_propaganda_machine_for_religion/,parabas,1519751970,,0,1
1303,2018-2-28,2018,2,28,2,80o9rl,[D] Who are some researchers in multimodal deep learning (combining language and vision)?,https://www.reddit.com/r/MachineLearning/comments/80o9rl/d_who_are_some_researchers_in_multimodal_deep/,skepticforest,1519752664,"Who are some researchers in academia who are researching joint models of text and images, like visual QA, language-vision link etc?

So far I've been able to find [Dhruv Batra](https://www.cc.gatech.edu/~dbatra/), [Devi Parikh](https://www.cc.gatech.edu/~parikh/), [Ali Farhadi](https://homes.cs.washington.edu/~ali/index.html), [Mohit Bansal](http://cs.unc.edu/~mbansal/), [Tamara Berg](http://www.tamaraberg.com/), [Abhinav Gupta](http://www.cs.cmu.edu/~abhinavg/), [Svetlana Lazebnik](http://slazebni.cs.illinois.edu/) and [Hongklak Lee](http://web.eecs.umich.edu/~honglak/)",6,4
1304,2018-2-28,2018,2,28,3,80olzv,[P] Competition to train an ML model w/ 5ETH reward,https://www.reddit.com/r/MachineLearning/comments/80olzv/p_competition_to_train_an_ml_model_w_5eth_reward/,mikeyanderson,1519755032,,11,0
1305,2018-2-28,2018,2,28,3,80oynr,[D] Managing learning datsets - managing the mess,https://www.reddit.com/r/MachineLearning/comments/80oynr/d_managing_learning_datsets_managing_the_mess/,fgilad,1519757392,"In the recent years I have accumulated hundreds of datasets for computer vision, and the dataset handling problem became a main issue.

All the datasets have common properties - a list of items, images for most types (usually some file or url per image), a known train/test split, some general metadata (name, license, source) and some learning related metadata (e.g mean, object classes, bounding boxes).

I have used caffe, tensorflow, keras and some pytorch, and accumulated ""Dataset"" classes in these frameworks, for each of these datasets - each of them (ex. caffe) has it's ""dataset"" or ""dataset loader"" class for the ""common"" dataset, and I have written my own.

But it seems to me that there should be a better way to organize this mess. It is a very repetitive task - to build a slightly different loader for each dataset in each framework.

I tried to search for some ""standard"" for these computer vision datasets, but couldn't find one. What I am looking for is somthing like - create this json files that describes your dataset and here is the way to load it in keras, pytorch or the next cool framework. Maybe even - here is a nice UI to catalog and search all your datasets.

MS coco has a format that seems to me to be in that direction, but I didn't see it was used more generaly.

Did anyone encounter such an (aspiring) standard, system or project?",9,8
1306,2018-2-28,2018,2,28,4,80p767,ClaoudML - Free Machine Learning Resources,https://www.reddit.com/r/MachineLearning/comments/80p767/claoudml_free_machine_learning_resources/,randylaosat,1519759071,,1,1
1307,2018-2-28,2018,2,28,4,80pfpj,[R] Is Generator Conditioning Causally Related to GAN Performance?,https://www.reddit.com/r/MachineLearning/comments/80pfpj/r_is_generator_conditioning_causally_related_to/,visarga,1519760795,,3,11
1308,2018-2-28,2018,2,28,4,80pgtr,Is there interest for an AMA from the hosts of a podcast on AI in Canada?,https://www.reddit.com/r/MachineLearning/comments/80pgtr/is_there_interest_for_an_ama_from_the_hosts_of_a/,TheAIEffect,1519760991,,0,1
1309,2018-2-28,2018,2,28,4,80pis6,Question about AlphaGo Zero (xpost on r/reinforcementlearning),https://www.reddit.com/r/MachineLearning/comments/80pis6/question_about_alphago_zero_xpost_on/,for_all_epsilon,1519761404,[removed],0,1
1310,2018-2-28,2018,2,28,5,80pjt6,Writing algorithms from scratch,https://www.reddit.com/r/MachineLearning/comments/80pjt6/writing_algorithms_from_scratch/,a13xk13m,1519761617,[removed],0,1
1311,2018-2-28,2018,2,28,5,80pmqz,Deep learning in radiology: an overview of the concepts and a survey of the state of the art,https://www.reddit.com/r/MachineLearning/comments/80pmqz/deep_learning_in_radiology_an_overview_of_the/,ketsok,1519762188,,0,1
1312,2018-2-28,2018,2,28,6,80q32o,Now on GitHub: The Autonomous Driving Cookbook from Microsoft,https://www.reddit.com/r/MachineLearning/comments/80q32o/now_on_github_the_autonomous_driving_cookbook/,k9triz,1519765407,,0,1
1313,2018-2-28,2018,2,28,6,80q3b1,Does minimum norm solution guarantee generalization in the underconstrained case (in the statistical learning sense)?,https://www.reddit.com/r/MachineLearning/comments/80q3b1/does_minimum_norm_solution_guarantee/,real_pinocchio,1519765453,,0,1
1314,2018-2-28,2018,2,28,6,80q6p4,[N] Pandas and AI Lead the Way to the Beijing 2022 Winter Olympics,https://www.reddit.com/r/MachineLearning/comments/80q6p4/n_pandas_and_ai_lead_the_way_to_the_beijing_2022/,gwen0927,1519766165,,0,1
1315,2018-2-28,2018,2,28,7,80qznf,Seeking anyone with Machine/Deep Learning experience in Financial trading,https://www.reddit.com/r/MachineLearning/comments/80qznf/seeking_anyone_with_machinedeep_learning/,JustinQueeber,1519772138,[removed],0,1
1316,2018-2-28,2018,2,28,10,80s1v6,Earl Grey Tea Bag Packing Machine,https://www.reddit.com/r/MachineLearning/comments/80s1v6/earl_grey_tea_bag_packing_machine/,lgsherry,1519781120,,1,1
1317,2018-2-28,2018,2,28,11,80sjrv,The School of AI (Teaser Trailer) - YouTube,https://www.reddit.com/r/MachineLearning/comments/80sjrv/the_school_of_ai_teaser_trailer_youtube/,peanutmilk,1519785619,,0,1
1318,2018-2-28,2018,2,28,12,80sqsd,Mquina de fabricacin de bloques hidrulica automtica inteligente QT4 18,https://www.reddit.com/r/MachineLearning/comments/80sqsd/mquina_de_fabricacin_de_bloques_hidrulica/,dymachine01,1519787378,,1,1
1319,2018-2-28,2018,2,28,12,80sx4a,"FD1-10 Mquina estabilizadora hidrulica automtica del ladrillo, mquin...",https://www.reddit.com/r/MachineLearning/comments/80sx4a/fd110_mquina_estabilizadora_hidrulica/,dymachine01,1519789014,,1,1
1320,2018-2-28,2018,2,28,13,80teuf,[D]CNNs basics.Wrote this an year back while starting with CNNs.Critical responses welcomed!,https://www.reddit.com/r/MachineLearning/comments/80teuf/dcnns_basicswrote_this_an_year_back_while/,jassi1994,1519793956,,0,0
1321,2018-2-28,2018,2,28,14,80tfwh,Bachelor graduate looking to get into the field,https://www.reddit.com/r/MachineLearning/comments/80tfwh/bachelor_graduate_looking_to_get_into_the_field/,irulenot,1519794247,[removed],0,1
1322,2018-2-28,2018,2,28,14,80tpgd,[P] Neural image assessment: automatic image quality evaluation,https://www.reddit.com/r/MachineLearning/comments/80tpgd/p_neural_image_assessment_automatic_image_quality/,SupraluminalShift,1519797054,,1,0
1323,2018-2-28,2018,2,28,15,80tv2j,[R] Stochastic Hyperparameter Optimization through Hypernetworks,https://www.reddit.com/r/MachineLearning/comments/80tv2j/r_stochastic_hyperparameter_optimization_through/,baylearn,1519798764,,13,41
1324,2018-2-28,2018,2,28,15,80u16r,[D] Demystifying Face Recognition V: Data Augmentation (include recently introduced technique MixUp/RandomErasing),https://www.reddit.com/r/MachineLearning/comments/80u16r/d_demystifying_face_recognition_v_data/,melgor89,1519800694,,9,6
1325,2018-2-28,2018,2,28,15,80u1oe,"Artificial Intelligence in Marketing Market by Technology Machine Learning, Context-Aware Computing - 2025",https://www.reddit.com/r/MachineLearning/comments/80u1oe/artificial_intelligence_in_marketing_market_by/,JackWallner2,1519800852,,0,1
1326,2018-2-28,2018,2,28,16,80uc93,Precision drilling components: features and beneficial,https://www.reddit.com/r/MachineLearning/comments/80uc93/precision_drilling_components_features_and/,machining18,1519804602,[removed],1,1
1327,2018-2-28,2018,2,28,17,80ugcl,Machine learning methods for computational chemistry &gt; How to build an online compound solubility prediction workflow with SageMaker,https://www.reddit.com/r/MachineLearning/comments/80ugcl/machine_learning_methods_for_computational/,redcloudio,1519805962,,0,1
1328,2018-2-28,2018,2,28,17,80uke4,Cow manure bio fertilizer granulator machine,https://www.reddit.com/r/MachineLearning/comments/80uke4/cow_manure_bio_fertilizer_granulator_machine/,amylee516,1519807403,,0,1
1329,2018-2-28,2018,2,28,17,80ulxh,My xt ra p lc cao 1HP - M t dy ng,https://www.reddit.com/r/MachineLearning/comments/80ulxh/my_xt_ra_p_lc_cao_1hp_m_t_dy_ng/,mranha2mk,1519807975,,0,1
1330,2018-2-28,2018,2,28,18,80uom1,[R] Demystifying Parallel and Distributed Deep Learning: An In-Depth Concurrency Analysis,https://www.reddit.com/r/MachineLearning/comments/80uom1/r_demystifying_parallel_and_distributed_deep/,LurkerCatcher,1519808990,,3,55
1331,2018-2-28,2018,2,28,18,80ut29,Unity ML Training Agent,https://www.reddit.com/r/MachineLearning/comments/80ut29/unity_ml_training_agent/,ThranduilKing,1519810765,,0,1
1332,2018-2-28,2018,2,28,19,80uwph,[D] Adding Data Science to your College Curriculum | fast.ai,https://www.reddit.com/r/MachineLearning/comments/80uwph/d_adding_data_science_to_your_college_curriculum/,sksq9,1519812120,,1,0
1333,2018-2-28,2018,2,28,19,80uxeb,How to prepare descriptive paper for ssc cgl tier 3,https://www.reddit.com/r/MachineLearning/comments/80uxeb/how_to_prepare_descriptive_paper_for_ssc_cgl_tier/,Abhiowesome,1519812359,,0,1
1334,2018-2-28,2018,2,28,19,80v29e,[R] Stochastic Hyperparameter Optimization through Hypernetworks,https://www.reddit.com/r/MachineLearning/comments/80v29e/r_stochastic_hyperparameter_optimization_through/,[deleted],1519813944,[deleted],0,0
1335,2018-2-28,2018,2,28,19,80v46b,Machine Learning - 6 ways how search engines use it.,https://www.reddit.com/r/MachineLearning/comments/80v46b/machine_learning_6_ways_how_search_engines_use_it/,nina-garg,1519814614,,0,1
1336,2018-2-28,2018,2,28,19,80v4s0,[P] The Word English Bible Speech Dataset: A Large Single Speaker Dataset of English,https://www.reddit.com/r/MachineLearning/comments/80v4s0/p_the_word_english_bible_speech_dataset_a_large/,longinglove,1519814839,,5,42
1337,2018-2-28,2018,2,28,20,80vcfe,Question: Is there are general best practice for classifying large Images,https://www.reddit.com/r/MachineLearning/comments/80vcfe/question_is_there_are_general_best_practice_for/,KrakenInAJar,1519817525,[removed],0,1
1338,2018-2-28,2018,2,28,20,80vf84,How do you do chatbot analytics? Here is the Engati way. Leverage the power of rich analytics in Engati. Build your chatbot in less than 10 minutes at www.engati.com,https://www.reddit.com/r/MachineLearning/comments/80vf84/how_do_you_do_chatbot_analytics_here_is_the/,getengati,1519818496,,0,1
1339,2018-2-28,2018,2,28,21,80vlnd,[D] Sparse data and GBT regression producing volatile output.,https://www.reddit.com/r/MachineLearning/comments/80vlnd/d_sparse_data_and_gbt_regression_producing/,texinxin,1519820344,"Im struggling leading a small team of data scientists on a challenge at work.  Im not a classically trained data scientist.  Im from the new breed of SMEs coming over to the ML side.  So Im not remotely an expert, so bare with me.

I recognize in advance that what we are trying to do is not entirely statistically sound, and we need more data.  More on that later.

We have a dataset with 2 categorical variables.  There are about 20 possible countries with extremely skewed representation in the data set. We have 5 generic material categories (binning of hundreds of material subtypes) with a similar skew.

We also have 4 continuous variables that describe the physical dimensions.  You can consider time to be a continuous variable as well, but we are using an H2O weighting factor for it.

So I have 7 variables in all.  We only currently have 10,000 data points, but that number is growing.  It will approach 100,000 in a few months.

The issue is I have an alpha product launch that requires a model that somewhat works in 4 weeks.

When doing 70/30 test/learn cross validation on a gradient boosting regression model, we get favorable results.  We are also limiting the depth of the tree to try to avoid overfitting.  We WANT the tree to have error because we want the model to have averaging behavior.  We understand that there are factors influencing the output variable (in this case, cost) beyond these 7 variables.  Right now we consistently get below 10% MAPE in the test sets.  So we trust the model on our data.

The challenge we have now is we want to deploy the model and perform what if analysis and change the future behavior of our data and determine the impact.  Specifically, we want to create hypothetical extensions of the dataset (similar to oversampling) to explore different possible scenarios for optimization.  The issue is it requires us to predict into the sparse regions of the tree where we dont have much coverage.  Predictably, the GBT is generating spurious results in the output variables.

Here are my ideas for now.  Please let me know what you think and more importantly, please let me know if you have other ideas:


1.  Limit the predictor so that it cant be used in areas within the matrix where we dont have enough data to support a prediction.  I dont know how to create this filter yet, could use ideas.
 
2.  Use multiple distinct trees for one of the two categorical values which tends to drive more skew in the output variable. In this case the generic material causes far more reasonable and expected skew than country.
 
3.  Use advanced sampling methods such as SMOTE or MSMOTE.  Though Im not sure how you create some of the hypothetical extensions of the data set like in SMOTE.
 
4.  Get more data... duh.. :)

5.  Start pushing for the use of another regression model, even if it means a slight drop in performance on existing data, but might prove better in prediction in sparse areas. Weve had good success with multi linear regression.  And I feel it will result in more stable output. But I know from experience our model accuracy on existing will take a hit.  Is there something out there that performs somewhere between a multi linear regression and a GBT?

",5,9
1340,2018-2-28,2018,2,28,22,80vx8e,[D] Question about using ML techniques to track insect movements,https://www.reddit.com/r/MachineLearning/comments/80vx8e/d_question_about_using_ml_techniques_to_track/,[deleted],1519823544,[deleted],9,2
1341,2018-2-28,2018,2,28,22,80vzbo, ,https://www.reddit.com/r/MachineLearning/comments/80vzbo/_/,lotosforming,1519824105,,1,1
1342,2018-2-28,2018,2,28,22,80vzeo,[D] Feasibility for a open-source idea bank for research ?,https://www.reddit.com/r/MachineLearning/comments/80vzeo/d_feasibility_for_a_opensource_idea_bank_for/,metaAI,1519824132,"Can it be considered feasible to have something like 'Polymath' project in mathematics community, such that anyone can propose a new research idea under categories, and the community can post comments to check validity if it is a good new idea to work on, with approved open project then interested people can get involved and work massively collaboratively on the problem.  All the progress can be transparent and encourage people to push ideas to be developed. 

It might be difficulty to manage the things like credit assignment, implementing the experiment. However, just quite naively curious, in theory, how much the open source new idea can accelerate the research process and reduce the independent repeated work. ",3,8
1343,2018-2-28,2018,2,28,22,80w0o2,[R] Applying Machine Learning to DevOps,https://www.reddit.com/r/MachineLearning/comments/80w0o2/r_applying_machine_learning_to_devops/,trumtra,1519824468,,0,1
1344,2018-2-28,2018,2,28,22,80w4q5,"[R] Highly interpretable, sklearn-compatible classifier and regressor based on simplified decision trees",https://www.reddit.com/r/MachineLearning/comments/80w4q5/r_highly_interpretable_sklearncompatible/,dearpetra,1519825541,,0,1
1345,2018-2-28,2018,2,28,23,80w93j,Indecisive master thesis in protein graph mining,https://www.reddit.com/r/MachineLearning/comments/80w93j/indecisive_master_thesis_in_protein_graph_mining/,SetsError,1519826679,,0,1
1346,2018-2-28,2018,2,28,23,80w9iz,Loss function in variational autoencoder,https://www.reddit.com/r/MachineLearning/comments/80w9iz/loss_function_in_variational_autoencoder/,ajayrfhp,1519826785,[removed],0,1
1347,2018-2-28,2018,2,28,23,80wfsq,[R] Back to Basics: Benchmarking Canonical Evolution Strategies for Playing Atari,https://www.reddit.com/r/MachineLearning/comments/80wfsq/r_back_to_basics_benchmarking_canonical_evolution/,wei_jok,1519828294,,1,21
1348,2018-2-28,2018,2,28,23,80wmpy,A simple guide to Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/80wmpy/a_simple_guide_to_reinforcement_learning/,cburgdorf,1519829905,,0,1
