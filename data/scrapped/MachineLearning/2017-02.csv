,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2017-2-1,2017,2,1,9,5rc42r,[P] One of my first ML projects - I trained a neural net to 'write' rap songs,https://www.reddit.com/r/MachineLearning/comments/5rc42r/p_one_of_my_first_ml_projects_i_trained_a_neural/,beef__,1485907984,,55,185
1,2017-2-1,2017,2,1,9,5rc4u4,[1701.08312] ClipAudit: A Simple Risk-Limiting Post-Election Audit,https://www.reddit.com/r/MachineLearning/comments/5rc4u4/170108312_clipaudit_a_simple_risklimiting/,alexmlamb,1485908198,,2,1
2,2017-2-1,2017,2,1,10,5rchpq,"Any interest in an open ""Docker hub"" for AI/ML containers?",https://www.reddit.com/r/MachineLearning/comments/5rchpq/any_interest_in_an_open_docker_hub_for_aiml/,[deleted],1485912021,[removed],0,1
3,2017-2-1,2017,2,1,13,5rdcoi,[p] someone just presented this machine learning project at my local tech meetup,https://www.reddit.com/r/MachineLearning/comments/5rdcoi/p_someone_just_presented_this_machine_learning/,[deleted],1485921965,[deleted],3,2
4,2017-2-1,2017,2,1,13,5rde3f,Neural Network Visualisation,https://www.reddit.com/r/MachineLearning/comments/5rde3f/neural_network_visualisation/,ViralRiver,1485922467,[removed],0,1
5,2017-2-1,2017,2,1,13,5rdglu,[1701.08978] Mixed Low-precision Deep Learning Inference using Dynamic Fixed Point,https://www.reddit.com/r/MachineLearning/comments/5rdglu/170108978_mixed_lowprecision_deep_learning/,fulcrum_xyz,1485923380,,7,3
6,2017-2-1,2017,2,1,15,5re1yf,[1701.08718] Memory Augmented Neural Networks with Wormhole Connections,https://www.reddit.com/r/MachineLearning/comments/5re1yf/170108718_memory_augmented_neural_networks_with/,JosephLChu,1485931877,,7,20
7,2017-2-1,2017,2,1,15,5re2pw,[D] Debugging Deep RL training and hyperparameters,https://www.reddit.com/r/MachineLearning/comments/5re2pw/d_debugging_deep_rl_training_and_hyperparameters/,Pieranha,1485932250,"I have experience with supervised and unsupervised learning using deep learning methods, but I'm fairly new to RL and deep RL. I'm very interested in hearing your thoughts on 3 things regarding debugging the hyperparameters for deep RL.

1. How many of the insights about hyperparameters in a supervised setting for deep learning apply to deep RL? For instance, should I just make the batch size as large as possible to fill up my GPU as I would do for supervised learning or can that have negative effects on the RL?

2. What hyperparameters would you normally examine first when a specific RL application isn't working? % chance of taking random action, learning rate or something different?

3. RL training seems to be very noisy with many different metrics measuring performance. What advice can you give on how best to see if your model is doing well? What metrics do you normally focus the most on?

Thanks a lot! I hope answers to these questions can benefit many others than me in this exciting field. Note that I'm currently focused on training Deep Q-networks, but the answers can apply also to other types of deep RL.",3,18
8,2017-2-1,2017,2,1,17,5reeu2,How to retaining the document name after k means clustering,https://www.reddit.com/r/MachineLearning/comments/5reeu2/how_to_retaining_the_document_name_after_k_means/,inred28,1485938572,[removed],0,1
9,2017-2-1,2017,2,1,18,5rei2l,Teaching oneself all about Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5rei2l/teaching_oneself_all_about_machine_learning/,ThisIsMySeudonym,1485940165,[removed],1,1
10,2017-2-1,2017,2,1,18,5rejxw,[Discussion] Has anyone experimented much with clockwork RNNs?,https://www.reddit.com/r/MachineLearning/comments/5rejxw/discussion_has_anyone_experimented_much_with/,r_dipietro,1485941108,"Main idea: Let different RNN modules tick at different rates. Let high-frequency modules use information from low-frequency modules, but do not allow the reverse, the intuition being that low-frequency modules should not be ""distracted"" by high frequency components.

Example at time = 8 with periods 1, 2, 4, 8, 16. t is divisible by 1, 2, 4, and 8, so at this time step these modules will be updated, and are updated as a function of *all* modules from the previous time step. However module 16 will flow through untouched, because it's not its time to tick.

PDF: http://jmlr.org/proceedings/papers/v32/koutnik14.pdf

Side note: If you're not yet familiar, go straight to Figure 2, which is very clear. (Figure 1 reminds me of something in On Writing by Stephen King... sometimes it's hard ""to kill your darlings"" upon revision. I think Figure 1 was one such darling :).)

I have implemented clockwork RNNs in TensorFlow, as no vetted versions exist yet. (See https://github.com/tensorflow/models/pull/198)

I have tested it in many environments (copy problem, addition problem, flattened MNIST), and it is *significantly* outperformed by other RNN architectures in all cases (where the number of free parameters in all models are kept as close as possible).

Have others experimented much with this architecture? I'm wondering if anyone has had a different experience.

From one perspective, I could of course have a bug in my code, but I will mention that I reproduced the paper's toy example of using extremely few parameters and memorizing a short clip of music, and in this strange setting it does indeed outperform LSTM. Also, here is my code, in case anyone is willing to take a look: https://gist.github.com/rdipietro/8e220e77a2bb86b6b7955ac3d2b55d98",12,19
11,2017-2-1,2017,2,1,19,5repkx,[D] Retraining a network using unrecognized samples ? good or bad idea ?,https://www.reddit.com/r/MachineLearning/comments/5repkx/d_retraining_a_network_using_unrecognized_samples/,HikariNoTen,1485943992,"Hello,

One of my colleagues asked me to retrain a network using only the samples from the training base that are not recognized. Within an original database of 250K, we are talking about retraining with 1.4 K.

It seems like an interesting idea, similar to how we learn by repetition of failures until success. But I am kind of afraid of the result on a CNN. The task of choosing the right hyperparameters to avoid destroying the tuned weights seems challenging... I have tried to find litterature about this, but I am probably not using the correct keywords.

What is you opinion on such a retraining ?",10,12
12,2017-2-1,2017,2,1,20,5rewf4,[R] [1701.09135] DeepNav: Learning to Navigate Large Cities,https://www.reddit.com/r/MachineLearning/comments/5rewf4/r_170109135_deepnav_learning_to_navigate_large/,mrShu,1485947470,,1,1
13,2017-2-2,2017,2,2,0,5rg80q,"Simple Questions Thread February 01, 2017",https://www.reddit.com/r/MachineLearning/comments/5rg80q/simple_questions_thread_february_01_2017/,AutoModerator,1485964350,[removed],0,1
14,2017-2-2,2017,2,2,1,5rg9zp,[P] - Tensorflow &amp; Factorization Machines for Recommendation Systems,https://www.reddit.com/r/MachineLearning/comments/5rg9zp/p_tensorflow_factorization_machines_for/,tschellenbach,1485964917,,5,89
15,2017-2-2,2017,2,2,1,5rgmlt,[R] BrainComputer InterfaceBased Communication in the Completely Locked-In State,https://www.reddit.com/r/MachineLearning/comments/5rgmlt/r_braincomputer_interfacebased_communication_in/,rrmuller,1485968295,"Very cool paper on the use of SVM to classify communication signals ""yes""/""no"" from locked in state patients.

Abstract

Despite partial success, communication has remained impossible for persons suffering from complete motor paralysis but intact cognitive and emotional processing, a state called complete locked-in state (CLIS). Based on a motor learning theoretical context and on the failure of neuroelectric braincomputer interface (BCI) communication attempts in CLIS, we here report BCI communication using functional near-infrared spectroscopy (fNIRS) and an implicit attentional processing procedure. Four patients suffering from advanced amyotrophic lateral sclerosis (ALS)two of them in permanent CLIS and two entering the CLIS without reliable means of communicationlearned to answer personal questions with known answers and open questions all requiring a yes or no thought using frontocentral oxygenation changes measured with fNIRS. Three patients completed more than 46 sessions spread over several weeks, and one patient (patient W) completed 20 sessions. Online fNIRS classification of personal questions with known answers and open questions using linear support vector machine (SVM) resulted in an above-chance-level correct response rate over 70%. Electroencephalographic oscillations and electrooculographic signals did not exceed the chance-level threshold for correct communication despite occasional differences between the physiological signals representing a yes or no response. However, electroencephalogram (EEG) changes in the theta-frequency band correlated with inferior communication performance, probably because of decreased vigilance and attention. If replicated with ALS patients in CLIS, these positive results could indicate the first step towards abolition of complete locked-in states, at least for ALS.

Link PlosOne: http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002593

Link MIT tech review: https://www.technologyreview.com/s/603512/reached-via-a-mind-reading-device-deeply-paralyzed-patients-say-they-want-to-live/",1,11
16,2017-2-2,2017,2,2,2,5rgzom,Jeff Dean on the landscape and history of machine learning,https://www.reddit.com/r/MachineLearning/comments/5rgzom/jeff_dean_on_the_landscape_and_history_of_machine/,jkestelyn,1485971734,,0,1
17,2017-2-2,2017,2,2,3,5rh229,What are the different approaches/pieces to AI and who are which are the prominent research groups in those areas?,https://www.reddit.com/r/MachineLearning/comments/5rh229/what_are_the_different_approachespieces_to_ai_and/,[deleted],1485972350,[removed],0,1
18,2017-2-2,2017,2,2,3,5rh4pz,What are the different approaches/pieces to AI and which are the prominent research groups in those areas?,https://www.reddit.com/r/MachineLearning/comments/5rh4pz/what_are_the_different_approachespieces_to_ai_and/,AmatIm,1485973027,[removed],0,1
19,2017-2-2,2017,2,2,3,5rhe9p,Transfer learning with CNTK for the data science bowl competition ($1M in prizes),https://www.reddit.com/r/MachineLearning/comments/5rhe9p/transfer_learning_with_cntk_for_the_data_science/,hoaphumanoid,1485975480,,0,1
20,2017-2-2,2017,2,2,4,5rhio9,Best API for live-camera feed object recognition?,https://www.reddit.com/r/MachineLearning/comments/5rhio9/best_api_for_livecamera_feed_object_recognition/,tangerto,1485976603,[removed],0,1
21,2017-2-2,2017,2,2,4,5rhkue,Causality in machine learning,https://www.reddit.com/r/MachineLearning/comments/5rhkue/causality_in_machine_learning/,pannous,1485977144,,0,1
22,2017-2-2,2017,2,2,4,5rhrwr,How to Make Word Vectors from Game of Thrones (LIVE),https://www.reddit.com/r/MachineLearning/comments/5rhrwr/how_to_make_word_vectors_from_game_of_thrones_live/,llSourcell,1485978983,,0,1
23,2017-2-2,2017,2,2,5,5rhvoa,"Use machine learning, neural networking, and data science skills to hack quantitative managed futures trading at https://www.Quantiacs.com They connect your trading algo to institutional investors. You keep 10% of the performance fees, and you retain 100% of your own IP.",https://www.reddit.com/r/MachineLearning/comments/5rhvoa/use_machine_learning_neural_networking_and_data/,brinkwar,1485979948,,0,4
24,2017-2-2,2017,2,2,6,5ri8yz,What effects should I expect from varying backgrounds of training images?,https://www.reddit.com/r/MachineLearning/comments/5ri8yz/what_effects_should_i_expect_from_varying/,boxcardavid,1485983421,[removed],0,1
25,2017-2-2,2017,2,2,6,5ridfo,[P] Accelerating Deep Learning with Multiprocess Image Augmentation in Keras,https://www.reddit.com/r/MachineLearning/comments/5ridfo/p_accelerating_deep_learning_with_multiprocess/,stratospark,1485984580,,0,4
26,2017-2-2,2017,2,2,7,5riuvu,Deciding on the number of layers and filters for a sparse convolutional autoencoder?,https://www.reddit.com/r/MachineLearning/comments/5riuvu/deciding_on_the_number_of_layers_and_filters_for/,[deleted],1485989307,[removed],0,1
27,2017-2-2,2017,2,2,8,5rizz1,[Discussion] - How to determine the number of layers and filters for a sparse convolutional autoencoder?,https://www.reddit.com/r/MachineLearning/comments/5rizz1/discussion_how_to_determine_the_number_of_layers/,iamiamwhoami,1485990762,I'm training a convolutional autoencoder with an l1 sparsity constraint on the activity. The idea is to train it to pick out anomalous features in a series of images extracted from a video. What's a good way to determine how many layers it should have and how many filters the convolutional layers should have?,3,4
28,2017-2-2,2017,2,2,8,5rj51d,[P] RLBot: Tensorflow playing Rocket League - First Project and Need Advice for Improvement,https://www.reddit.com/r/MachineLearning/comments/5rj51d/p_rlbot_tensorflow_playing_rocket_league_first/,drssoccer55,1485992191,,27,38
29,2017-2-2,2017,2,2,8,5rj95d,14 of the most common neural networks in Python and Theano,https://www.reddit.com/r/MachineLearning/comments/5rj95d/14_of_the_most_common_neural_networks_in_python/,WrinkledTime,1485993317,,0,1
30,2017-2-2,2017,2,2,8,5rj98v,A Bot that Selects CSS Class Names for HTML Better Than Human,https://www.reddit.com/r/MachineLearning/comments/5rj98v/a_bot_that_selects_css_class_names_for_html/,huula,1485993350,,0,2
31,2017-2-2,2017,2,2,9,5rjaaj,[D] Possible to train a 32x32 ImageNet?,https://www.reddit.com/r/MachineLearning/comments/5rjaaj/d_possible_to_train_a_32x32_imagenet/,alexyku,1485993634,I am trying to train a 32x32 resized version of ImageNet on VGG16. Has anyone successfully accomplished this? Thanks.,3,9
32,2017-2-2,2017,2,2,9,5rje90,Resources to crash course machine learning for scientists and engineers,https://www.reddit.com/r/MachineLearning/comments/5rje90/resources_to_crash_course_machine_learning_for/,WrinkledTime,1485994673,,0,1
33,2017-2-2,2017,2,2,9,5rjl24,[R][arXiv:1701.07717]Unlabeled Samples Generated by GAN Improve the Person Re-identification Baseline in vitro,https://www.reddit.com/r/MachineLearning/comments/5rjl24/rarxiv170107717unlabeled_samples_generated_by_gan/,zhedongzheng,1485996544,,2,17
34,2017-2-2,2017,2,2,9,5rjmwv,[D] What are your favorite TensorFlow projects? Also - is anyone here doing anything cool with TensorFlow?,https://www.reddit.com/r/MachineLearning/comments/5rjmwv/d_what_are_your_favorite_tensorflow_projects_also/,[deleted],1485997068,[deleted],7,0
35,2017-2-2,2017,2,2,10,5rjpbe,AI doing zbrush,https://www.reddit.com/r/MachineLearning/comments/5rjpbe/ai_doing_zbrush/,[deleted],1485997752,[removed],0,1
36,2017-2-2,2017,2,2,10,5rjqec,Probabilities of a Naive Bayes classifier adding up to more than 100%... [Project],https://www.reddit.com/r/MachineLearning/comments/5rjqec/probabilities_of_a_naive_bayes_classifier_adding/,P3DR0-X,1485998075,[removed],3,1
37,2017-2-2,2017,2,2,11,5rk0d1,AISTATS17 Accepted Papers,https://www.reddit.com/r/MachineLearning/comments/5rk0d1/aistats17_accepted_papers/,[deleted],1486001098,[deleted],0,1
38,2017-2-2,2017,2,2,12,5rkanj,MIT 6.S094: Deep Learning for Self-Driving Cars,https://www.reddit.com/r/MachineLearning/comments/5rkanj/mit_6s094_deep_learning_for_selfdriving_cars/,[deleted],1486004468,[deleted],0,1
39,2017-2-2,2017,2,2,12,5rkie7,Random Forest Regressor: max_features,https://www.reddit.com/r/MachineLearning/comments/5rkie7/random_forest_regressor_max_features/,[deleted],1486007017,[removed],0,1
40,2017-2-2,2017,2,2,15,5rl9t4,How to make a messenger bot that uses deep learning,https://www.reddit.com/r/MachineLearning/comments/5rl9t4/how_to_make_a_messenger_bot_that_uses_deep/,Abhi001vj,1486017411,[removed],0,1
41,2017-2-2,2017,2,2,16,5rlesk,13MP MIPI camera board for NVIDIA Jetson TX1,https://www.reddit.com/r/MachineLearning/comments/5rlesk/13mp_mipi_camera_board_for_nvidia_jetson_tx1/,econsystems,1486019724,,0,1
42,2017-2-2,2017,2,2,16,5rlj40,[P] - StreamAlert: Real-time Data Analysis and Alerting,https://www.reddit.com/r/MachineLearning/comments/5rlj40/p_streamalert_realtime_data_analysis_and_alerting/,algui91,1486021872,,0,1
43,2017-2-2,2017,2,2,16,5rljvd,Thoughts in fast.ai MOOC?,https://www.reddit.com/r/MachineLearning/comments/5rljvd/thoughts_in_fastai_mooc/,lovebes,1486022290,[removed],0,1
44,2017-2-2,2017,2,2,17,5rlma5,How to choose machine learning algorithms (x-post from /r/programming),https://www.reddit.com/r/MachineLearning/comments/5rlma5/how_to_choose_machine_learning_algorithms_xpost/,thetyrone,1486023520,,0,2
45,2017-2-2,2017,2,2,18,5rlqvj,[D] GTX 1070 underwhelming -- why?,https://www.reddit.com/r/MachineLearning/comments/5rlqvj/d_gtx_1070_underwhelming_why/,valtron2000,1486026069,"I have a 960 and 1070 plugged in, with the 960 driving my display. Training a CNN similar to [this one](https://github.com/booz-allen-hamilton/DSB3Tutorial/blob/master/tutorial_code/LUNA_train_unet.py#L38),
one epoch takes ~290s on the 960 and ~190s (x1.5 speedup) on the 1070. But, looking at benchmarks ([1](http://www.phoronix.com/scan.php?page=article&amp;item=nvidia-gtx-1070&amp;num=4), [2](https://github.com/tobigithub/tensorflow-deep-learning/wiki/tf-benchmarks), [3](http://www.phoronix.com/scan.php?page=article&amp;item=nvidia-cuda8-2016&amp;num=3), [4](http://www.dk-lab.com/budget-friendly-deep-learning-home-pc/)),
the 1070 should be around twice as fast. Am I doing something wrong?

Detail gravy:

- Win10, i7-4790K, 16GB ram
- 960: 2GB, 1070: 8GB
- float32 for both
- Keras+theano
- CUDA 8.0, cuDNN 5103
- tried larger batch sizes on 1070 because of the extra memory, but no improvement

(There was someone with [similar issues](https://www.reddit.com/r/learnmachinelearning/comments/5gdtlv/tensor_flow_on_windows_10/), but I have no idea how that's possible because the card doesn't fit in a PCI-e x4 slot.)

**Edit: Resolution**

- Ran 3D bench with OC Scanner, had no trouble getting into P0; card is fine
- Benched CIFAR-10, 1.9x speedup
- Tried a 3D CNN, 2.2x speedup

In conclusion, UNET in particular doesn't benefit (comparatively) much and the performance is what it is.",12,17
46,2017-2-2,2017,2,2,18,5rltmm,Here is the February 2017 issue of Computer Vision News,https://www.reddit.com/r/MachineLearning/comments/5rltmm/here_is_the_february_2017_issue_of_computer/,finallyifoundvalidUN,1486027595,,0,1
47,2017-2-2,2017,2,2,19,5rly0d,An introduction to Generative Adversarial Networks (with code in TensorFlow),https://www.reddit.com/r/MachineLearning/comments/5rly0d/an_introduction_to_generative_adversarial/,cavedave,1486029992,,3,169
48,2017-2-2,2017,2,2,19,5rm04m,What happened to Talking Machines podcast? Last episode published at the start of September.,https://www.reddit.com/r/MachineLearning/comments/5rm04m/what_happened_to_talking_machines_podcast_last/,boxstabber,1486031085,,0,1
49,2017-2-2,2017,2,2,19,5rm2if,Digital X Ray Machine | Digital X Ray Machine Suppliers India,https://www.reddit.com/r/MachineLearning/comments/5rm2if/digital_x_ray_machine_digital_x_ray_machine/,regeimaging,1486032344,,0,1
50,2017-2-2,2017,2,2,20,5rm73g,What's your choice of programming language for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5rm73g/whats_your_choice_of_programming_language_for/,shravankumar147,1486034470,,0,1
51,2017-2-2,2017,2,2,20,5rmbqx,[D] Unsup. image clust. with Deep AE - poor results,https://www.reddit.com/r/MachineLearning/comments/5rmbqx/d_unsup_image_clust_with_deep_ae_poor_results/,01001010010110110111,1486036497,"**What unsupervised image clustering strategies can I use with neural networks?**

I have a 1M sample database of signals (no labels) containing a variety of freq phenomena seen in their spectr0-gr@ms, with enough repetition of phenomena for about a dozen consistent categories to appear upon inspection. I would like to cluster these samples well enough so that I can label per cluster, but I fail to achieve this result.

The spectr0-gr@ms are converted into small images containing enough detail. The typical features seen are fairly simplistic, like a narrow line, a collection of narrow lines, broad line(s) and stroking and dotting. It is more complex than MNIST, for example, because the categories are not clearly defined as there is much more variation that merges potential categories.

I have used dense and convolutional AE from 20 to 2 encoding dimensions with a large variety of sensible architectures that manage to reconstruct very well, even with 3 encoding dimensions. I follow a 8D AE with tsne as a necessity for agglomerative clustering to produce sensible clusterings, as there is still a curse of dimensionality preventing  good clustering at say 5 or more dimensions.

I have used engineered features that perform much better at showing wider variation of samples in the clustered result than with AE+tsne. I have played around with reducing the AE neuron capacity to prevent overfitting to capture just the coarse sample characteristics, but with no real improvement, the engineered features do much better but they still don't give adequate clusters.

I believe it is possible to use neural networks in an unsupervised setting to avoid feature engineering and to produce a good variety of image clusters, but my poor and limited attempts thus far has not produced this outcome.

I know there are very sophisticated unsupervised feature extraction + clustering algorithms out there, but I just want to be able to use well known components like Deep AE and tsne, etc. to solve this. Any advice is welcome, thanks.",6,4
52,2017-2-2,2017,2,2,21,5rmg7d,[D] Deep learning in industry - prevalence of cloud and local GPU compute,https://www.reddit.com/r/MachineLearning/comments/5rmg7d/d_deep_learning_in_industry_prevalence_of_cloud/,dennis_copeland,1486038264,"I see a lot of discussion about GPU compute resources used by individuals and academic researchers (cloud and local hardware) - but how common is using cloud compute (eg. EC2 p2) as opposed to local GPUs in industrial settings?

My intuition is that local hardware is more common as that has lower TCO if you can keep utilization high, OTOH you don't get the flexibility to scale up and down and have more operational costs.
Another issue that comes to mind is managing data itself - just moving very large data sets to the cloud can be time consuming, and then there may be compliance issues with off-site data, worries about security etc. 

Clearly, there are trade-offs between these two approaches, so I guess I'm really asking - does anyone have experience of how these approaches play out in practice, outside of an individual/academic setting? Is there any particular factor that ends up dominating in most situations that makes one approach clearly superior?

PS. I hope this is the right place to post this kind of question - google turns up plenty of discussions re. individual/academic usage, but nothing on this that I can find.",10,24
53,2017-2-2,2017,2,2,22,5rmvmg,[D] Any interest in a open docker hub for ML/AI focused content? I'm thinking about building one.,https://www.reddit.com/r/MachineLearning/comments/5rmvmg/d_any_interest_in_a_open_docker_hub_for_mlai/,coolhand1,1486043709,"I'm thinking about building out a site/community where we can users can post and share their docker images for their AI/ML projects/apps. I see links all the time to github on this sub, and I thought it might be a good idea to have a place where people can post their dockerized projects. Thoughts?",10,13
54,2017-2-2,2017,2,2,23,5rn54h,[P] Feynman Machine: a New Approach for Cortical and Machine Intelligence,https://www.reddit.com/r/MachineLearning/comments/5rn54h/p_feynman_machine_a_new_approach_for_cortical_and/,fergbyrne,1486046785,,26,5
55,2017-2-2,2017,2,2,23,5rn7l1,[Project]YouTube Like Count Predictor using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5rn7l1/projectyoutube_like_count_predictor_using_machine/,ayush0016,1486047521,,1,3
56,2017-2-3,2017,2,3,0,5rn8ci,[P] A generic Mixture Density Networks implementation for distribution and uncertainty estimation by using Keras (TensorFlow backend) - Master's Thesis project.,https://www.reddit.com/r/MachineLearning/comments/5rn8ci/p_a_generic_mixture_density_networks/,4xel,1486047739,,3,9
57,2017-2-3,2017,2,3,0,5rn9x7,[D] Word2vec model help needed,https://www.reddit.com/r/MachineLearning/comments/5rn9x7/d_word2vec_model_help_needed/,[deleted],1486048203,[deleted],0,0
58,2017-2-3,2017,2,3,0,5rnahq,MultiNet: Real-time Joint Semantic Reasoning for Autonomous Driving,https://www.reddit.com/r/MachineLearning/comments/5rnahq/multinet_realtime_joint_semantic_reasoning_for/,[deleted],1486048372,[deleted],0,1
59,2017-2-3,2017,2,3,0,5rnd5a,[R] MultiNet: Real-time Joint Semantic Reasoning for Autonomous Driving,https://www.reddit.com/r/MachineLearning/comments/5rnd5a/r_multinet_realtime_joint_semantic_reasoning_for/,marvMind,1486049125,,1,11
60,2017-2-3,2017,2,3,1,5rnqij,Memory at the Core of New Deep Learning Research Chip,https://www.reddit.com/r/MachineLearning/comments/5rnqij/memory_at_the_core_of_new_deep_learning_research/,[deleted],1486052889,[deleted],0,1
61,2017-2-3,2017,2,3,1,5rnrj5,ML in Facebook's pictures?,https://www.reddit.com/r/MachineLearning/comments/5rnrj5/ml_in_facebooks_pictures/,Buttezvant,1486053146,[removed],0,1
62,2017-2-3,2017,2,3,1,5rns60,[R] Probabilistic Models of Cognition,https://www.reddit.com/r/MachineLearning/comments/5rns60/r_probabilistic_models_of_cognition/,jakn,1486053314,,7,12
63,2017-2-3,2017,2,3,1,5rnu23,The best starters guide to machine learning algorithms I have ever found,https://www.reddit.com/r/MachineLearning/comments/5rnu23/the_best_starters_guide_to_machine_learning/,todo_later,1486053797,,0,1
64,2017-2-3,2017,2,3,3,5roc2w,[D] shortening sequence lengths by concatenation or convolution,https://www.reddit.com/r/MachineLearning/comments/5roc2w/d_shortening_sequence_lengths_by_concatenation_or/,TalkingJellyFish,1486058540,"I'm working on a domain specific ""POS tagger"" at the character level using RNNs. I'd like to reduce the number of steps in the RNN to speed up training so I can iterate faster.
I want to avoid ngrams as parts of the vocabulary are rare enough and ngrams would make that worse
Has anyone tried seen papers that either
A) concatenate the vector representation of subsequences of inputs into a longer vector
(a,b,c,d)-&gt; ((a,b),(c,d)) 
I don't mean inputting ngrams, rather concatenating the distributed representation of each character thus reducing the overall sequence length

Option B) running a convolution with stride &gt; 1 over the input and feeding that into the rnn then running a ""deconvolution""

Thanks
",1,3
65,2017-2-3,2017,2,3,3,5roeh8,Clickstream session data anomaly (bot) detection,https://www.reddit.com/r/MachineLearning/comments/5roeh8/clickstream_session_data_anomaly_bot_detection/,frotn,1486059194,[removed],0,1
66,2017-2-3,2017,2,3,3,5rogin,Deep Feature Interpolation in Tensorflow with VGG19 and LFW,https://www.reddit.com/r/MachineLearning/comments/5rogin/deep_feature_interpolation_in_tensorflow_with/,[deleted],1486059733,[deleted],0,1
67,2017-2-3,2017,2,3,3,5rogvu,"AMA with Chris Stevens from Quandl over at /r/datasets on dataset curation, gathering and publicising",https://www.reddit.com/r/MachineLearning/comments/5rogvu/ama_with_chris_stevens_from_quandl_over_at/,cavedave,1486059829,,1,2
68,2017-2-3,2017,2,3,3,5roiqx,[P] Deep Feature Interpolation with VGG19 and LFW,https://www.reddit.com/r/MachineLearning/comments/5roiqx/p_deep_feature_interpolation_with_vgg19_and_lfw/,[deleted],1486060335,[deleted],0,1
69,2017-2-3,2017,2,3,3,5roolz,Trying to make an English speech to text Neural Network,https://www.reddit.com/r/MachineLearning/comments/5roolz/trying_to_make_an_english_speech_to_text_neural/,an0nym0usv,1486061894,[removed],0,1
70,2017-2-3,2017,2,3,4,5roptb,[P] Deep Feature Interpolation in Tensorflow with VGG19 and LFW,https://www.reddit.com/r/MachineLearning/comments/5roptb/p_deep_feature_interpolation_in_tensorflow_with/,slang03,1486062189,,0,6
71,2017-2-3,2017,2,3,4,5royx0,96% accuracy on MNIST with pure unsupervised learning,https://www.reddit.com/r/MachineLearning/comments/5royx0/96_accuracy_on_mnist_with_pure_unsupervised/,heidius,1486064700,,0,1
72,2017-2-3,2017,2,3,5,5rp3vs,Machine learning for video transcoding,https://www.reddit.com/r/MachineLearning/comments/5rp3vs/machine_learning_for_video_transcoding/,mearco,1486066043,,0,1
73,2017-2-3,2017,2,3,5,5rp4jg,Astronomers explore uses for AI-generated images : Nature News &amp; Comment,https://www.reddit.com/r/MachineLearning/comments/5rp4jg/astronomers_explore_uses_for_aigenerated_images/,Grumbit,1486066214,,0,1
74,2017-2-3,2017,2,3,5,5rp5fd,how to approximate a very complex optimal policy when the distance function is unknown,https://www.reddit.com/r/MachineLearning/comments/5rp5fd/how_to_approximate_a_very_complex_optimal_policy/,[deleted],1486066455,[removed],0,1
75,2017-2-3,2017,2,3,5,5rpao0,[P] Discovering Timelines - Looking At How Public People and Ideas Change Through Time,https://www.reddit.com/r/MachineLearning/comments/5rpao0/p_discovering_timelines_looking_at_how_public/,thegoz,1486067850,,0,5
76,2017-2-3,2017,2,3,6,5rph5b,Deep Learning for ... Chess,https://www.reddit.com/r/MachineLearning/comments/5rph5b/deep_learning_for_chess/,elisebreda,1486069630,,0,1
77,2017-2-3,2017,2,3,8,5rqacw,How would one go about creating a generative learning chatbot without training it at all?,https://www.reddit.com/r/MachineLearning/comments/5rqacw/how_would_one_go_about_creating_a_generative/,Chenja,1486077689,[removed],0,1
78,2017-2-3,2017,2,3,8,5rqewq,If I might dd smthing,https://www.reddit.com/r/MachineLearning/comments/5rqewq/if_i_might_dd_smthing/,Emersonlyotha,1486078991,[removed],0,1
79,2017-2-3,2017,2,3,9,5rqn0v,IoT and machine learning,https://www.reddit.com/r/MachineLearning/comments/5rqn0v/iot_and_machine_learning/,noah_f,1486081299,[removed],0,1
80,2017-2-3,2017,2,3,10,5rqwkb,[R] AISTATS 2017 Papers,https://www.reddit.com/r/MachineLearning/comments/5rqwkb/r_aistats_2017_papers/,jenny80808,1486084169,,2,41
81,2017-2-3,2017,2,3,10,5rqz2h,[D] Theory behind activation functions?,https://www.reddit.com/r/MachineLearning/comments/5rqz2h/d_theory_behind_activation_functions/,sprintletecity,1486084939,"Why is it that ReLU's perform so well, and can often outperform their adjusted counterparts (leaky ReLU's, ELU's)?",25,10
82,2017-2-3,2017,2,3,10,5rr3n3,Any good datasets on how a user will use a website or phone app?,https://www.reddit.com/r/MachineLearning/comments/5rr3n3/any_good_datasets_on_how_a_user_will_use_a/,[deleted],1486086417,[removed],0,1
83,2017-2-3,2017,2,3,11,5rr612,[D] Is it possible for a neural network to learn a set of equations or vector based data such as SVG images?,https://www.reddit.com/r/MachineLearning/comments/5rr612/d_is_it_possible_for_a_neural_network_to_learn_a/,cpgeier,1486087207,"If so what architecture would be best suited to do this? I am trying to create a neural net that takes 3D structures in the vector form instead of a voxelized form, such as Vox-net. Any help would be appreciated. ",9,10
84,2017-2-3,2017,2,3,11,5rr84i,[R] [arXiv:1610.02915] Deep Pyramidal Residual Networks,https://www.reddit.com/r/MachineLearning/comments/5rr84i/r_arxiv161002915_deep_pyramidal_residual_networks/,david-gpu,1486087875,,19,19
85,2017-2-3,2017,2,3,11,5rr8xk,Visualization of Deep Neural Network implemented in Pixel Horror Game,https://www.reddit.com/r/MachineLearning/comments/5rr8xk/visualization_of_deep_neural_network_implemented/,JonoExplainsThings,1486088143,,0,1
86,2017-2-3,2017,2,3,11,5rrgom,[R] [1702.00783] Pixel Recursive Super Resolution,https://www.reddit.com/r/MachineLearning/comments/5rrgom/r_170200783_pixel_recursive_super_resolution/,wei_jok,1486090748,,8,19
87,2017-2-3,2017,2,3,15,5rsctx,[D] I'm going through the google cloud ML examples in https://github.com/GoogleCloudPlatform/cloudml-samples/blob/master/ is it me or are they fairly buggy?,https://www.reddit.com/r/MachineLearning/comments/5rsctx/d_im_going_through_the_google_cloud_ml_examples/,cloudMLQ,1486102984,"for example, I can't run either iris or flowers in the cloud, I think the reason for both is there are argument parsing issues. 

Am I just getting confused ? or are these actual bugs that just haven't been ironed out yet I notice the initial commit for these is only 4 months ago

NOTE: the MNIST example which is highlighted in the docs works fine as one might expect",5,7
88,2017-2-3,2017,2,3,18,5rsz0a,[D] RNN speed - dependency on size and depth of layers,https://www.reddit.com/r/MachineLearning/comments/5rsz0a/d_rnn_speed_dependency_on_size_and_depth_of_layers/,abstractineum,1486114010,"I am trying to train a LSTM in Tensorflow with the following network architecture:

Layer size: 512
Number of layers: 3
Batch size: 128
Sequence lengths: 128
Token depth (vocabulary size): ~100

For now I am training only on CPUs. I find that layer sizes up to 512 work well, at which point a step takes ~10 seconds. However increasing the layer size to 768 or 1024 makes the step time increase to ~350 and ~500 seconds respectively. Is this nonlinear increase expected?

Increasing the amount of memory I have at my disposal has little effect, and decreasing the batch size to 32 doesnt help either.

Does anyone have experience with this type of problem or any suggestions for possible bottlenecks?",5,6
89,2017-2-3,2017,2,3,18,5rt10e,Machine Learning in Music and Art Generation,https://www.reddit.com/r/MachineLearning/comments/5rt10e/machine_learning_in_music_and_art_generation/,ReworkCharlotte,1486114973,,0,1
90,2017-2-3,2017,2,3,19,5rt3fl,ould yu hlp m for a snd?,https://www.reddit.com/r/MachineLearning/comments/5rt3fl/ould_yu_hlp_m_for_a_snd/,Sawyertaro,1486116220,[removed],0,1
91,2017-2-3,2017,2,3,20,5rteau,A practical and very hands-on overview of mainstream ConvNet architectures,https://www.reddit.com/r/MachineLearning/comments/5rteau/a_practical_and_very_handson_overview_of/,carlthome,1486120996,,0,1
92,2017-2-3,2017,2,3,22,5rtssw,Can anybody help me in implementing the clustering part of this paper in python. I am confused how to proceed.,https://www.reddit.com/r/MachineLearning/comments/5rtssw/can_anybody_help_me_in_implementing_the/,shivamsardana,1486127031,,0,1
93,2017-2-3,2017,2,3,22,5rtyl3,[D] Trust in Automation,https://www.reddit.com/r/MachineLearning/comments/5rtyl3/d_trust_in_automation/,breandan,1486129111,,0,0
94,2017-2-3,2017,2,3,22,5ru1po,Popular non-vision benchmarks to test feed-forward networks?,https://www.reddit.com/r/MachineLearning/comments/5ru1po/popular_nonvision_benchmarks_to_test_feedforward/,[deleted],1486130238,[removed],0,1
95,2017-2-3,2017,2,3,23,5ru28e,[D] Popular non-vision benchmarks to test feed-forward networks?,https://www.reddit.com/r/MachineLearning/comments/5ru28e/d_popular_nonvision_benchmarks_to_test/,lars_,1486130414,"I am looking for a dataset to test an idea for a non-convolutional feed-forward neural net.

Somehow, all popular datasets I can think of are either vision tasks, or timeseries/sequence data. What are the established benchmark datasets that fall outside of these to categories?

Ideally, I'm looking for something where:

* People actually publish papers with results on the dataset, so getting state-of-the-art has some significance.
* The dataset isn't tiny (i.e. MNIST-size at a minimum)

Any ideas?",9,12
96,2017-2-3,2017,2,3,23,5ru3iy,"[D] Is it recommended to use PyTorch for deep reinforcement learning, compared with TensorFlow ?",https://www.reddit.com/r/MachineLearning/comments/5ru3iy/d_is_it_recommended_to_use_pytorch_for_deep/,xingdongrobotics,1486130847,[removed],3,0
97,2017-2-4,2017,2,4,0,5rude4,Training a chatbot on non-conversational text?,https://www.reddit.com/r/MachineLearning/comments/5rude4/training_a_chatbot_on_nonconversational_text/,USAFairyPrincess,1486134113,[removed],0,1
98,2017-2-4,2017,2,4,0,5rukkt,Command line tool to predict the like count of a YouTube video.,https://www.reddit.com/r/MachineLearning/comments/5rukkt/command_line_tool_to_predict_the_like_count_of_a/,mayank26saxena,1486136266,,0,1
99,2017-2-4,2017,2,4,3,5rviiq,Coursera Machine Learning Course: UW vs Stanford,https://www.reddit.com/r/MachineLearning/comments/5rviiq/coursera_machine_learning_course_uw_vs_stanford/,mhaghaed,1486145558,[removed],0,1
100,2017-2-4,2017,2,4,3,5rvipb,Feedforward of Nodes with connections to multiple Layers,https://www.reddit.com/r/MachineLearning/comments/5rvipb/feedforward_of_nodes_with_connections_to_multiple/,Miemels,1486145611,[removed],0,1
101,2017-2-4,2017,2,4,3,5rvpxs,How Neural Networks generate Visual Art from inspiration,https://www.reddit.com/r/MachineLearning/comments/5rvpxs/how_neural_networks_generate_visual_art_from/,sachinrjoglekar,1486147581,,0,1
102,2017-2-4,2017,2,4,4,5rvx84,Using same dataset for both training and validation,https://www.reddit.com/r/MachineLearning/comments/5rvx84/using_same_dataset_for_both_training_and/,[deleted],1486149580,[removed],0,1
103,2017-2-4,2017,2,4,4,5rvxsq,"12 year old teaching neural networks, am stunned!",https://www.reddit.com/r/MachineLearning/comments/5rvxsq/12_year_old_teaching_neural_networks_am_stunned/,legendOfPepe,1486149740,,0,1
104,2017-2-4,2017,2,4,5,5rw7m6,[D] Who's heard back from the Google Brain Residency?,https://www.reddit.com/r/MachineLearning/comments/5rw7m6/d_whos_heard_back_from_the_google_brain_residency/,i_am_a_gan,1486152381,"[At least one person](https://www.reddit.com/r/MachineLearning/comments/50qa5w/2017_google_brain_residency_program/dd82ygc/) has gotten an email arranging an interview. Curious to know if others have, and whether any rejections have gone out.",96,23
105,2017-2-4,2017,2,4,7,5rww1q,China Gains on the U.S. in the Artificial Intelligence Arms Race,https://www.reddit.com/r/MachineLearning/comments/5rww1q/china_gains_on_the_us_in_the_artificial/,[deleted],1486159339,[deleted],0,1
106,2017-2-4,2017,2,4,7,5rww3k,[D] What should new PhD students know?,https://www.reddit.com/r/MachineLearning/comments/5rww3k/d_what_should_new_phd_students_know/,harmonium1,1486159350,"At this point, there are probably many people who have heard back from PhD programs in CS/ML/AI.  For current PhD students, what are some topics that you wish you'd reviewed (or did review, and found helpful!) before your started your doctorate?  Maybe we could break it down by ML field:

* Learning theory
* Computer vision
* NLP
* Robotics/RL
* etc",41,63
107,2017-2-4,2017,2,4,7,5rwwyc,How to Do Mathematics Easily - Intro to Deep Learning #4,https://www.reddit.com/r/MachineLearning/comments/5rwwyc/how_to_do_mathematics_easily_intro_to_deep/,llSourcell,1486159596,,0,1
108,2017-2-4,2017,2,4,7,5rwyo5,[N] Using Machine Learning to predict parking difficulty,https://www.reddit.com/r/MachineLearning/comments/5rwyo5/n_using_machine_learning_to_predict_parking/,halfeatenscone,1486160108,,10,215
109,2017-2-4,2017,2,4,7,5rx0ai,[D] Deep Learning Computer Build,https://www.reddit.com/r/MachineLearning/comments/5rx0ai/d_deep_learning_computer_build/,EmetToMet,1486160576,"I'm a newcomer to building computers who greatly appreciates any advice I can get with the build. This build will be used primarily for training large convolutional neural networks and generative adversarial networks on large images (e.g. 227 x 227 x 3). The datasets can reach up to 100 GB in size.

[PCPartPicker part list](https://pcpartpicker.com/list/vZbLjc) / [Price breakdown by merchant](https://pcpartpicker.com/list/vZbLjc/by_merchant/)

Type|Item|Price
:----|:----|:----
**CPU** | [Intel Core i7-6850K 3.6GHz 6-Core Processor](https://pcpartpicker.com/product/4RvZxr/intel-cpu-bx80671i76850k) | $566.99 @ Amazon 
**CPU Cooler** | [Noctua NH-U9S 46.4 CFM CPU Cooler](https://pcpartpicker.com/product/FcfmP6/noctua-cpu-cooler-nhu9s) | $57.29 @ Newegg 
**Motherboard** | [Asus X99-M WS Micro ATX LGA2011-3 Motherboard](https://pcpartpicker.com/product/c7Trxr/asus-motherboard-x99mws) | $263.99 @ SuperBiiz 
**Memory** | [G.Skill Ripjaws V Series 32GB (2 x 16GB) DDR4-3200 Memory](https://pcpartpicker.com/product/kXbkcf/gskill-memory-f43200c16d32gvk) | $194.99 @ Newegg 
**Memory** | [G.Skill Ripjaws V Series 32GB (2 x 16GB) DDR4-3200 Memory](https://pcpartpicker.com/product/kXbkcf/gskill-memory-f43200c16d32gvk) | $194.99 @ Newegg 
**Storage** | [Samsung 850 Pro Series 1TB 2.5"" Solid State Drive](https://pcpartpicker.com/product/XyDwrH/samsung-internal-hard-drive-mz7ke1t0bw) | $449.00 @ B&amp;H 
**Video Card** | [NVIDIA Titan X (Pascal) 12GB Video Card](https://pcpartpicker.com/product/DcH48d/nvidia-titan-x-pascal-12gb-video-card-900-1g611-2500-000) (2-Way SLI) | $1200.00 
**Video Card** | [NVIDIA Titan X (Pascal) 12GB Video Card](https://pcpartpicker.com/product/DcH48d/nvidia-titan-x-pascal-12gb-video-card-900-1g611-2500-000) (2-Way SLI) | $1200.00 
**Case** | [Corsair Air 540 ATX Mid Tower Case](https://pcpartpicker.com/product/wgkD4D/corsair-case-air540) | $129.79 @ B&amp;H 
**Power Supply** | [EVGA SuperNOVA 1000 G2 1000W 80+ Gold Certified Fully-Modular ATX Power Supply](https://pcpartpicker.com/product/MKfp99/evga-power-supply-120g21000xr) | $135.89 @ OutletPC 
 | *Prices include shipping, taxes, rebates, and discounts* |
 | Total (before mail-in rebates) | $4412.93
 | Mail-in rebates | -$20.00
 | **Total** | **$4392.93**
 | Generated by [PCPartPicker](http://pcpartpicker.com) 2017-02-03 16:07 EST-0500 |

",24,23
110,2017-2-4,2017,2,4,11,5ry90q,Datapie.Data marketplace for Machine learning community,https://www.reddit.com/r/MachineLearning/comments/5ry90q/datapiedata_marketplace_for_machine_learning/,[deleted],1486175350,[deleted],0,1
111,2017-2-4,2017,2,4,13,5rypeg,[R] Maximally Informative Hierarchical Representations of High-Dimensional Data,https://www.reddit.com/r/MachineLearning/comments/5rypeg/r_maximally_informative_hierarchical/,Icko_,1486181522,,3,25
112,2017-2-4,2017,2,4,13,5ryrdi,Ongoing Now,https://www.reddit.com/r/MachineLearning/comments/5ryrdi/ongoing_now/,bleakgh,1486182354,,0,1
113,2017-2-4,2017,2,4,14,5rywom,classical linear regression with pymc3,https://www.reddit.com/r/MachineLearning/comments/5rywom/classical_linear_regression_with_pymc3/,sasaram,1486184620,,0,1
114,2017-2-4,2017,2,4,14,5ryxwv,[P] Live Q&amp;A with the Udacity Deep Learning Foundations Team,https://www.reddit.com/r/MachineLearning/comments/5ryxwv/p_live_qa_with_the_udacity_deep_learning/,[deleted],1486185138,[deleted],0,1
115,2017-2-4,2017,2,4,15,5rz552,Practical Data Science for Software Engineers,https://www.reddit.com/r/MachineLearning/comments/5rz552/practical_data_science_for_software_engineers/,szelvenskiy,1486188367,,0,1
116,2017-2-4,2017,2,4,15,5rz8ne,Python data science cheat sheet,https://www.reddit.com/r/MachineLearning/comments/5rz8ne/python_data_science_cheat_sheet/,0xchamin,1486190119,,0,1
117,2017-2-4,2017,2,4,18,5rzq12,"[D] When will lesser precision GPUs be available (NVIDIA or Nervana, AMD)?",https://www.reddit.com/r/MachineLearning/comments/5rzq12/d_when_will_lesser_precision_gpus_be_available/,andyandy16,1486200112,"As per the [comment here](http://wiki.fast.ai/index.php/Your_Deep_Learning_Setup#Hardware), AMD and Nervana should be entering the GPU market for deep learning.

Question: should I wait to buy one of these? If so, will common deep learning libraries (e.g. Keras, TensorFlow) be capable of utilising them?

Many thanks!",20,11
118,2017-2-4,2017,2,4,19,5rzuiw,Double neural artistic work with Rihanna :),https://www.reddit.com/r/MachineLearning/comments/5rzuiw/double_neural_artistic_work_with_rihanna/,data-alchemy,1486202943,,1,1
119,2017-2-4,2017,2,4,20,5s00sn,The way I see it,https://www.reddit.com/r/MachineLearning/comments/5s00sn/the_way_i_see_it/,Benjaminelwfin,1486206651,[removed],0,1
120,2017-2-4,2017,2,4,21,5s0cih,How can I convert torch pre-trained model to MXNet model?,https://www.reddit.com/r/MachineLearning/comments/5s0cih/how_can_i_convert_torch_pretrained_model_to_mxnet/,alex_ovechko,1486212117,[removed],0,1
121,2017-2-4,2017,2,4,22,5s0jf7,"I need some help, please",https://www.reddit.com/r/MachineLearning/comments/5s0jf7/i_need_some_help_please/,Jameslaikrim,1486214826,[removed],0,1
122,2017-2-5,2017,2,5,0,5s1b25,Color quantization using k-means,https://www.reddit.com/r/MachineLearning/comments/5s1b25/color_quantization_using_kmeans/,lmcaraig,1486223595,,1,1
123,2017-2-5,2017,2,5,4,5s2gga,"I'm not passionate about general programming, I just want to be really good at Machine Learning for predictions. Only.",https://www.reddit.com/r/MachineLearning/comments/5s2gga/im_not_passionate_about_general_programming_i/,[deleted],1486236384,[removed],0,1
124,2017-2-5,2017,2,5,6,5s3b5r,A 30 Minute lecture on machine learning concepts for Software monitoring,https://www.reddit.com/r/MachineLearning/comments/5s3b5r/a_30_minute_lecture_on_machine_learning_concepts/,ArielAssaraf,1486244008,,0,1
125,2017-2-5,2017,2,5,6,5s3c86,"Is it possible in machine learning for a program to analyze videos of games such as chess, and create probabilities of the potential moves a player will make based on positions of the chess pieces, given 30+ videos of matches by the said player?",https://www.reddit.com/r/MachineLearning/comments/5s3c86/is_it_possible_in_machine_learning_for_a_program/,RCAVelez,1486244268,[removed],0,1
126,2017-2-5,2017,2,5,7,5s3n9i,The grab them by the pussy song,https://www.reddit.com/r/MachineLearning/comments/5s3n9i/the_grab_them_by_the_pussy_song/,the_godly_devil,1486246853,,0,1
127,2017-2-5,2017,2,5,7,5s3shd,Working on a list of ML vocabulary as I learn. What major stuff is missing?,https://www.reddit.com/r/MachineLearning/comments/5s3shd/working_on_a_list_of_ml_vocabulary_as_i_learn/,jjquave,1486248131,,0,1
128,2017-2-5,2017,2,5,8,5s46y1,"InceptionV4, InceptionResnetV2 pretrained models for Torch7 and PyTorch",https://www.reddit.com/r/MachineLearning/comments/5s46y1/inceptionv4_inceptionresnetv2_pretrained_models/,[deleted],1486251737,[deleted],0,1
129,2017-2-5,2017,2,5,9,5s4bqu,Is anyone outside of DeepMind using DeepMind Lab?,https://www.reddit.com/r/MachineLearning/comments/5s4bqu/is_anyone_outside_of_deepmind_using_deepmind_lab/,[deleted],1486252941,[removed],0,1
130,2017-2-5,2017,2,5,9,5s4by2,[D] Is anyone outside of DeepMind using DeepMind Lab?,https://www.reddit.com/r/MachineLearning/comments/5s4by2/d_is_anyone_outside_of_deepmind_using_deepmind_lab/,[deleted],1486252998,[deleted],0,1
131,2017-2-5,2017,2,5,9,5s4ca2,[D] Is anyone outside of DeepMind using DeepMind Lab?,https://www.reddit.com/r/MachineLearning/comments/5s4ca2/d_is_anyone_outside_of_deepmind_using_deepmind_lab/,feedthecreed,1486253092,"I'm looking for potential libraries to test autonomous agents in simulated 3D environments and I came across DeepMind Lab:

https://github.com/deepmind/lab

But I couldn't find much use of it outside of DeepMind. Is there a more standard alternative that the community uses?",16,34
132,2017-2-5,2017,2,5,9,5s4hlj,[P] Machine Learning at Berkeley's Introductory ML Tutorial Series: Neural Networks and Backprop,https://www.reddit.com/r/MachineLearning/comments/5s4hlj/p_machine_learning_at_berkeleys_introductory_ml/,mlberkeley,1486254471,,6,230
133,2017-2-5,2017,2,5,10,5s4pj2,This is what I want to do with my life. Where do I go from here?,https://www.reddit.com/r/MachineLearning/comments/5s4pj2/this_is_what_i_want_to_do_with_my_life_where_do_i/,[deleted],1486256620,[removed],0,1
134,2017-2-5,2017,2,5,12,5s5gaq,[D] BOSS for time series classification - reinventing the wheel?,https://www.reddit.com/r/MachineLearning/comments/5s5gaq/d_boss_for_time_series_classification_reinventing/,Pfohlol,1486266576,"In the The Great Time Series Classification Bake Off (https://arxiv.org/abs/1602.01711) paper, one of the highest performing algorithms is known as BOSS (http://link.springer.com/article/10.1007/s10618-014-0377-7). This algorithm was additionally found to be attain performance that was not statistically different from deep learning approaches in another work (https://arxiv.org/pdf/1611.06455v4.pdf). 

The general gist of BOSS is to compute a Symbolic Fourier Approximation (string based representation of the first few Fourier coefficients) over sliding windows of the series and to use the distribution of those symbolic approximations (in terms of a histogram) as a low dimensional representation of the data. 

That said, I have only recently started working with time series data and have been simultaneously been trying to catch up with the literature in signal processing and in time series classification. As of right now, it seems to me that there is some disconnect in the methods considered by the two communities. For instance, to me, BOSS seems like a somewhat roundabout way of recreating wavelet theory, which allows for an efficient representation over both the time and frequency domain. Given that wavelet theory is somewhat mature and ubiquitous in the signal processing community, it seems odd to me that is not considered as a candidate method for representing time series in these review papers from the time series communities.

Overall, I am interested in why there seems to be some sort of disconnect in the methods considered between the signal processing and the time series communities. Additionally, if anyone has any anecdotal evidence as to the performance differences between wavelet based feature extraction and methods such as BOSS, that would be immensely helpful for my personal research.",5,19
135,2017-2-5,2017,2,5,14,5s5sy9,Understanding deep learning requires rethinking generalization,https://www.reddit.com/r/MachineLearning/comments/5s5sy9/understanding_deep_learning_requires_rethinking/,Mr_Justice,1486271907,,0,1
136,2017-2-5,2017,2,5,14,5s5xdc,"[D] Where can I find a good, curated list of deep learning papers?",https://www.reddit.com/r/MachineLearning/comments/5s5xdc/d_where_can_i_find_a_good_curated_list_of_deep/,Csai,1486273889,"Arxiv is where everything new gets posted, but it's hard to figure out which ones are good and which ones are reporting non-replicable results.  Where can I find a curated and filtered list of papers. To give you a specific example, I am currently trying to get the latest papers and preprints focused on transfer learning, but I am not sure what's a good starting set to go through. Any pointers? Thanks!",8,9
137,2017-2-5,2017,2,5,15,5s62ay,"[P] Intro to K-Means Clustering, Implementation of Lloyd's Algorithm",https://www.reddit.com/r/MachineLearning/comments/5s62ay/p_intro_to_kmeans_clustering_implementation_of/,johnloeber,1486276268,,0,5
138,2017-2-5,2017,2,5,15,5s62jz,Training Spatial Transformer Networks,https://www.reddit.com/r/MachineLearning/comments/5s62jz/training_spatial_transformer_networks/,[deleted],1486276383,[removed],0,1
139,2017-2-5,2017,2,5,15,5s631a,[D] Theano 0.9.0b1 numpy issue? (Bleeding edge Theano + macOS 10.12 problem),https://www.reddit.com/r/MachineLearning/comments/5s631a/d_theano_090b1_numpy_issue_bleeding_edge_theano/,Kiriesh,1486276634,[removed],2,1
140,2017-2-5,2017,2,5,17,5s6e0b,NanoNets : How to use Deep Learning when you have Limited Data  NanoNets,https://www.reddit.com/r/MachineLearning/comments/5s6e0b/nanonets_how_to_use_deep_learning_when_you_have/,imagininglines,1486282787,,0,1
141,2017-2-5,2017,2,5,17,5s6exm,How many hidden units or hidden neurons fire in the hidden layer of a Sparse Autoencoder? Do the same hidden units fire for the input samples?,https://www.reddit.com/r/MachineLearning/comments/5s6exm/how_many_hidden_units_or_hidden_neurons_fire_in/,alokchakrabarty,1486283362,[removed],0,1
142,2017-2-5,2017,2,5,17,5s6f6m,NanoNets : How to use Deep Learning when you have Limited Data,https://www.reddit.com/r/MachineLearning/comments/5s6f6m/nanonets_how_to_use_deep_learning_when_you_have/,anonymous-founder,1486283517,,0,1
143,2017-2-5,2017,2,5,17,5s6hb5,Why is the code throwing error?,https://www.reddit.com/r/MachineLearning/comments/5s6hb5/why_is_the_code_throwing_error/,sujay88,1486284857,[removed],0,1
144,2017-2-5,2017,2,5,18,5s6ipq,[P] RNN Approaches to Integer Sequence Learning--the famous Kaggle competition,https://www.reddit.com/r/MachineLearning/comments/5s6ipq/p_rnn_approaches_to_integer_sequence_learningthe/,longinglove,1486285707,,0,14
145,2017-2-5,2017,2,5,18,5s6ixw,[D] What are the current benchmark datasets and the state of the art results for NLP tasks?,https://www.reddit.com/r/MachineLearning/comments/5s6ixw/d_what_are_the_current_benchmark_datasets_and_the/,napsternxg,1486285835,"I am interested in knowing the current benchmark data sets and the current state of the art results (with links to papers and code) for prominent NLP tasks e.g. POS tagging, chunking, NER, text classification, parsing, text summarization, question answering, etc. (please add more tasks that you can think of). I am currently interested in knowing results mostly for English language, but please include multi lingual results as well if they address a large domain of languages. 

It would be better if the included code and dataset used are freely available, e.g. CoNLL 2003 NER dataset is not easily available to everyone outside of university, but is a benchmark dataset for NER. ",3,20
146,2017-2-5,2017,2,5,18,5s6kjf,Can anyone help me find newspaper dataset ?,https://www.reddit.com/r/MachineLearning/comments/5s6kjf/can_anyone_help_me_find_newspaper_dataset/,gaurav_pai,1486286846,[removed],0,1
147,2017-2-5,2017,2,5,18,5s6lxf,Frankly speaking,https://www.reddit.com/r/MachineLearning/comments/5s6lxf/frankly_speaking/,Gavinpsychsor,1486287732,[removed],0,1
148,2017-2-5,2017,2,5,19,5s6o9l,Help to train Iris AI | Science Assistant,https://www.reddit.com/r/MachineLearning/comments/5s6o9l/help_to_train_iris_ai_science_assistant/,BodetGrrla,1486288986,,0,1
149,2017-2-5,2017,2,5,19,5s6psb,Correcting Image Orientation Using Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/5s6psb/correcting_image_orientation_using_convolutional/,danst18,1486289783,,0,1
150,2017-2-5,2017,2,5,19,5s6scf,Started a new repo to maintain a collection of notebooks to provide an intuitive understanding of conv nets. Please contribute to share your unique perspective.,https://www.reddit.com/r/MachineLearning/comments/5s6scf/started_a_new_repo_to_maintain_a_collection_of/,raghakot,1486291141,,0,1
151,2017-2-5,2017,2,5,20,5s6zqu,Advice for selecting features for a recommendation engine,https://www.reddit.com/r/MachineLearning/comments/5s6zqu/advice_for_selecting_features_for_a/,jackbrucesimpson,1486295049,[removed],0,1
152,2017-2-5,2017,2,5,21,5s74pi,happy-and-you-know-it: Facial Emotion Recognition using deep residual learning. [Demo](https://happy-and-you-know-it.herokuapp.com/).,https://www.reddit.com/r/MachineLearning/comments/5s74pi/happyandyouknowit_facial_emotion_recognition/,[deleted],1486297678,[deleted],0,1
153,2017-2-5,2017,2,5,21,5s74tg,Great source for learning for beginners and place to contribute for experts.,https://www.reddit.com/r/MachineLearning/comments/5s74tg/great_source_for_learning_for_beginners_and_place/,mentalMatrix,1486297725,,0,1
154,2017-2-5,2017,2,5,21,5s74xl,happy-and-you-know-it: Facial Emotion Recognition using deep residual learning. (demo at https://happy-and-you-know-it.herokuapp.com/),https://www.reddit.com/r/MachineLearning/comments/5s74xl/happyandyouknowit_facial_emotion_recognition/,saurabhmathur96,1486297789,,0,1
155,2017-2-5,2017,2,5,21,5s78dw,Data Modeling for Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/5s78dw/data_modeling_for_artificial_intelligence/,virene,1486299435,,0,1
156,2017-2-5,2017,2,5,22,5s7akn,Deviance and AIC,https://www.reddit.com/r/MachineLearning/comments/5s7akn/deviance_and_aic/,A_D_Exploration,1486300352,,0,1
157,2017-2-5,2017,2,5,23,5s7iin,[D][HELP] What do means and covars mean in HMM?,https://www.reddit.com/r/MachineLearning/comments/5s7iin/dhelp_what_do_means_and_covars_mean_in_hmm/,chipcrazy,1486303547,[removed],3,0
158,2017-2-5,2017,2,5,23,5s7odp,Ensembling Against Adversarial Instances,https://www.reddit.com/r/MachineLearning/comments/5s7odp/ensembling_against_adversarial_instances/,erogol,1486305817,,0,1
159,2017-2-6,2017,2,6,0,5s7wqk,Hw hav you bn?,https://www.reddit.com/r/MachineLearning/comments/5s7wqk/hw_hav_you_bn/,Alexandertamno,1486308469,[removed],0,1
160,2017-2-6,2017,2,6,3,5s94x4,"[P] InceptionV4, Inception-Resnet pretrained models for Torch7 and PyTorch",https://www.reddit.com/r/MachineLearning/comments/5s94x4/p_inceptionv4_inceptionresnet_pretrained_models/,Tamazy,1486320762,,1,54
161,2017-2-6,2017,2,6,5,5s9jx9,[D] Anyone has any idea about how FaceApp works?,https://www.reddit.com/r/MachineLearning/comments/5s9jx9/d_anyone_has_any_idea_about_how_faceapp_works/,wall-eeeee,1486325043,[removed],0,1
162,2017-2-6,2017,2,6,5,5s9omm,Are there any automated drawing programs?,https://www.reddit.com/r/MachineLearning/comments/5s9omm/are_there_any_automated_drawing_programs/,Neuronologist,1486326415,[removed],0,1
163,2017-2-6,2017,2,6,6,5sa3ag,[R] Image Aestetics Dataset (AVA/DPChallenge),https://www.reddit.com/r/MachineLearning/comments/5sa3ag/r_image_aestetics_dataset_avadpchallenge/,food_hacking,1486330611,"Hi Reddit!

For a Project at the University I am working on Deep Learning of Image Aestetics. Many papers work with the AVA dataset, which is a collection of Images drom DPChallenge.com. Most papers say, that one could download the Dataset from the author's Homepage (Luca Marchesotti), however, this page ist down. Scraping the images from DPChallenge.com does not work, I got blocked after I scraped some 200 Pictures... 
Does anybody have the dataset or knows where I could get it? This seems to be the dataset everyone uses in this field. 

Any help is very much appreciated!
",9,3
164,2017-2-6,2017,2,6,9,5sb024,Meta-RL is the key to AI,https://www.reddit.com/r/MachineLearning/comments/5sb024/metarl_is_the_key_to_ai/,cgel,1486341022,,0,1
165,2017-2-6,2017,2,6,11,5sble9,Has anybody heard back from google brain residency program 2017?,https://www.reddit.com/r/MachineLearning/comments/5sble9/has_anybody_heard_back_from_google_brain/,hanakaze,1486348493,[removed],0,1
166,2017-2-6,2017,2,6,11,5sblhg,"hdbscan clustering: still unclear to me how to chose """,https://www.reddit.com/r/MachineLearning/comments/5sblhg/hdbscan_clustering_still_unclear_to_me_how_to/,[deleted],1486348529,[removed],0,1
167,2017-2-6,2017,2,6,11,5sbll1,HDBSCAN cluster: still unclear to me how to chose 'min_cluster_size`,https://www.reddit.com/r/MachineLearning/comments/5sbll1/hdbscan_cluster_still_unclear_to_me_how_to_chose/,Zeekawla99ii,1486348564,[removed],0,1
168,2017-2-6,2017,2,6,13,5sc0ze,[D] What is the lowest precision that works for TRAINING neural networks?,https://www.reddit.com/r/MachineLearning/comments/5sc0ze/d_what_is_the_lowest_precision_that_works_for/,[deleted],1486353757,[deleted],9,9
169,2017-2-6,2017,2,6,15,5scr8o,Lathe Machine Manufacturer and supplier [leadermachines.com],https://www.reddit.com/r/MachineLearning/comments/5scr8o/lathe_machine_manufacturer_and_supplier/,lathemachinesindia,1486363434,,0,1
170,2017-2-6,2017,2,6,16,5scx5k,[R] Cognitive Machine Learning (1): Learning to Explain  The Spectator,https://www.reddit.com/r/MachineLearning/comments/5scx5k/r_cognitive_machine_learning_1_learning_to/,downtownslim,1486366114,,0,12
171,2017-2-6,2017,2,6,16,5scy55,[R] Creating Human-Level AI | Yoshua Bengio,https://www.reddit.com/r/MachineLearning/comments/5scy55/r_creating_humanlevel_ai_yoshua_bengio/,downtownslim,1486366630,,19,80
172,2017-2-6,2017,2,6,17,5sd1h7,[D] How do the gates in LSTM actually behave after convergence?,https://www.reddit.com/r/MachineLearning/comments/5sd1h7/d_how_do_the_gates_in_lstm_actually_behave_after/,[deleted],1486368345,[deleted],2,17
173,2017-2-6,2017,2,6,19,5sdfqp,I bliv tht,https://www.reddit.com/r/MachineLearning/comments/5sdfqp/i_bliv_tht/,Colintabbers,1486375960,[removed],0,1
174,2017-2-6,2017,2,6,19,5sdl15,Randomness in Neural Networks: An Overview,https://www.reddit.com/r/MachineLearning/comments/5sdl15/randomness_in_neural_networks_an_overview/,scardax88,1486378385,,0,1
175,2017-2-6,2017,2,6,20,5sdmu4,[R] Game AI Development With OpenAI Universe,https://www.reddit.com/r/MachineLearning/comments/5sdmu4/r_game_ai_development_with_openai_universe/,TheJonManley,1486379139,,1,35
176,2017-2-6,2017,2,6,20,5sdn1s,A Beginner's Guide To Data Science,https://www.reddit.com/r/MachineLearning/comments/5sdn1s/a_beginners_guide_to_data_science/,Edureka-learning,1486379239,,0,1
177,2017-2-6,2017,2,6,20,5sdprj,[D] Machine/Deep Learning/ Data Science masters in Europe,https://www.reddit.com/r/MachineLearning/comments/5sdprj/d_machinedeep_learning_data_science_masters_in/,07Zulrah,1486380364,"Hi, I am graduating from the UK university this year. I am really interested in Machine learning so I would like to pursue a career in it. Most of the machine learning jobs require at least masters degree. Which EU universities  have good Machine learning programs and are not too hard to get into? 

Thanks",18,12
178,2017-2-6,2017,2,6,20,5sdre9,used EMAG machines,https://www.reddit.com/r/MachineLearning/comments/5sdre9/used_emag_machines/,insafali737,1486381114,,1,1
179,2017-2-6,2017,2,6,20,5sdsa2,[News] A round-up of this year's best offerings for A.I. professionals,https://www.reddit.com/r/MachineLearning/comments/5sdsa2/news_a_roundup_of_this_years_best_offerings_for/,Everything_Cyber,1486381534,,0,0
180,2017-2-6,2017,2,6,21,5sdydh,Deep Q Learning with Keras and Gym,https://www.reddit.com/r/MachineLearning/comments/5sdydh/deep_q_learning_with_keras_and_gym/,[deleted],1486384165,[deleted],0,1
181,2017-2-6,2017,2,6,21,5se0w8,[D] Deep Q Learning with Keras and Gym,https://www.reddit.com/r/MachineLearning/comments/5se0w8/d_deep_q_learning_with_keras_and_gym/,kwk236,1486385186,,11,51
182,2017-2-6,2017,2,6,22,5se3ug,A few days ago I posted my rap-writing neural net - here's a song it wrote,https://www.reddit.com/r/MachineLearning/comments/5se3ug/a_few_days_ago_i_posted_my_rapwriting_neural_net/,[deleted],1486386259,[deleted],1,1
183,2017-2-6,2017,2,6,22,5se5oq,(R) Genetic algorithms for feature selection,https://www.reddit.com/r/MachineLearning/comments/5se5oq/r_genetic_algorithms_for_feature_selection/,[deleted],1486386864,[deleted],0,1
184,2017-2-6,2017,2,6,22,5se8oq,[REQUEST] I needed a collection of newspaper articles(duration:2 months) to use a learning data for my project.,https://www.reddit.com/r/MachineLearning/comments/5se8oq/request_i_needed_a_collection_of_newspaper/,gaurav_pai,1486387906,[removed],0,1
185,2017-2-6,2017,2,6,22,5secop,Do all data mining clustering algorithms stem from machine learning? or is 'cluster analysis' a combinition of algorithms that stem from the two fields?,https://www.reddit.com/r/MachineLearning/comments/5secop/do_all_data_mining_clustering_algorithms_stem/,[deleted],1486389313,[removed],0,1
186,2017-2-6,2017,2,6,23,5sehcp,[R] Genetic algorithms for feature selection,https://www.reddit.com/r/MachineLearning/comments/5sehcp/r_genetic_algorithms_for_feature_selection/,ml_des,1486390891,,7,9
187,2017-2-6,2017,2,6,23,5semr6,[Question][Discussion]Debugging GAN for text to image synthesis.,https://www.reddit.com/r/MachineLearning/comments/5semr6/questiondiscussiondebugging_gan_for_text_to_image/,cvikasreddy,1486392668,"I am training GAN to generate images from text and the disc loss is decreasing and generator loss in increasing but the images generated are not at all good even after 40 epochs. [log_images](http://imgur.com/a/eHMOL) 

Disc loss = loss_wrong_image + loss_fake_image_disc + loss_real_image

Gen_loss = loss_fake_image_gen

What might be going wrong here?",4,2
188,2017-2-7,2017,2,7,0,5setl1,Machine Learning for Grandmas By Saagie,https://www.reddit.com/r/MachineLearning/comments/5setl1/machine_learning_for_grandmas_by_saagie/,Saagie,1486394829,,0,1
189,2017-2-7,2017,2,7,0,5setv2,[R] Emotion Recognition in the Wild via Convolutional Neural Networks and Mapped Binary Patterns,https://www.reddit.com/r/MachineLearning/comments/5setv2/r_emotion_recognition_in_the_wild_via/,ofirpress,1486394913,,1,23
190,2017-2-7,2017,2,7,0,5sewe3,[N] TensorFlow on IBM LinuxONE z Systems,https://www.reddit.com/r/MachineLearning/comments/5sewe3/n_tensorflow_on_ibm_linuxone_z_systems/,rhy0lite,1486395653,,0,0
191,2017-2-7,2017,2,7,0,5sexbz,Netflix have evolved their machine learning algorithms and models,https://www.reddit.com/r/MachineLearning/comments/5sexbz/netflix_have_evolved_their_machine_learning/,teamrework,1486395936,,0,1
192,2017-2-7,2017,2,7,1,5sf16u,YouTube-BoundingBoxes Dataset,https://www.reddit.com/r/MachineLearning/comments/5sf16u/youtubeboundingboxes_dataset/,[deleted],1486397030,[deleted],0,1
193,2017-2-7,2017,2,7,1,5sf5p8,Classify brain tumour using MRS data by Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5sf5p8/classify_brain_tumour_using_mrs_data_by_machine/,vahi96,1486398276,[removed],0,1
194,2017-2-7,2017,2,7,1,5sf6na,[Discussion] Interesting rejected papers from ICLR,https://www.reddit.com/r/MachineLearning/comments/5sf6na/discussion_interesting_rejected_papers_from_iclr/,[deleted],1486398546,[deleted],0,1
195,2017-2-7,2017,2,7,1,5sfcw9,Machine learning and Pattern Recognition gaussian process question,https://www.reddit.com/r/MachineLearning/comments/5sfcw9/machine_learning_and_pattern_recognition_gaussian/,bwuzhang,1486400253,[removed],0,1
196,2017-2-7,2017,2,7,2,5sfe98,"SimGANs: A Game Changer in Unsupervised Learning, Self Driving Cars, and More  Intuition Machine",https://www.reddit.com/r/MachineLearning/comments/5sfe98/simgans_a_game_changer_in_unsupervised_learning/,wayaai,1486400619,,0,1
197,2017-2-7,2017,2,7,2,5sfgas,"[P] block: An intelligent block matrix library for numpy, Torch, and beyond.",https://www.reddit.com/r/MachineLearning/comments/5sfgas/p_block_an_intelligent_block_matrix_library_for/,bdamos,1486401165,,11,24
198,2017-2-7,2017,2,7,2,5sfhfe,[P] Declarative hyperparameter experiments for neural networks (keras + hyperopt),https://www.reddit.com/r/MachineLearning/comments/5sfhfe/p_declarative_hyperparameter_experiments_for/,bechirasorin,1486401441,,0,15
199,2017-2-7,2017,2,7,2,5sfmwz,Android App: Generate 3D model of you from a single selfie,https://www.reddit.com/r/MachineLearning/comments/5sfmwz/android_app_generate_3d_model_of_you_from_a/,smith2017,1486402911,,0,1
200,2017-2-7,2017,2,7,3,5sfs7h,Adversarial Learning for Neural Dialogue Generation,https://www.reddit.com/r/MachineLearning/comments/5sfs7h/adversarial_learning_for_neural_dialogue/,llSourcell,1486404331,,0,1
201,2017-2-7,2017,2,7,3,5sftu4,[N] YouTube-BoundingBoxes: a New Large Video Detection Dataset,https://www.reddit.com/r/MachineLearning/comments/5sftu4/n_youtubeboundingboxes_a_new_large_video/,vincentvanhoucke,1486404755,,21,146
202,2017-2-7,2017,2,7,3,5sg1px,"[R] Learning from Demonstrations (LfD) is a hands-on approach to teaching a robot a skill. At UCLA, we're building the perception and planning system behind a cloth-folding robot, and we need your input!",https://www.reddit.com/r/MachineLearning/comments/5sg1px/r_learning_from_demonstrations_lfd_is_a_handson/,CarbonFire,1486406822,"Instead of Reinforcement Learning using the Markov Decision Process (MDP) framework, we're taking a stab from a different angle. In MDP, the value of a state is total expected reward of the optimal policy. That's great if (1) the Markov assumption is acceptable for you, and if (2) the states and actions are well defined.

When transferring knowledge from a human to a robot, you can't easily map the human's actions to that of the robot (i.e. the correspondence problem). So instead, we're working on a **value function** using a ranking approach. 

In order to validate our algorithm's performance, we need your help!

Please take the [7 question survey](https://docs.google.com/forms/d/e/1FAIpQLScssipMCXEZYduNIY8jVjxtib9jAoSXZfgZKVT3XSVF9lfc9Q/viewform#responses)!

As a reward, here's a sneak peak ([VIDEO](https://www.youtube.com/watch?v=dkrJktaQKr8)) at a somewhat okay attempt of a robot folding a t-shirt. 
",2,9
203,2017-2-7,2017,2,7,4,5sg99x,[D] ICLR2017 results are out. Let's discuss.,https://www.reddit.com/r/MachineLearning/comments/5sg99x/d_iclr2017_results_are_out_lets_discuss/,wei_jok,1486408771,,43,35
204,2017-2-7,2017,2,7,4,5sgdou,Machine Learning Summarized in One Picture,https://www.reddit.com/r/MachineLearning/comments/5sgdou/machine_learning_summarized_in_one_picture/,psangrene,1486409977,,0,1
205,2017-2-7,2017,2,7,5,5sgkuo,"[P] A few days ago I posted my rap-song writing neural network, here's a song it has written (word by word)",https://www.reddit.com/r/MachineLearning/comments/5sgkuo/p_a_few_days_ago_i_posted_my_rapsong_writing/,[deleted],1486411820,[deleted],5,4
206,2017-2-7,2017,2,7,5,5sgl7e,Batch normalization training vs test time,https://www.reddit.com/r/MachineLearning/comments/5sgl7e/batch_normalization_training_vs_test_time/,testingTestingIBS,1486411921,[removed],1,1
207,2017-2-7,2017,2,7,5,5sgqc1,Factor analysis vs Bayesian Networks,https://www.reddit.com/r/MachineLearning/comments/5sgqc1/factor_analysis_vs_bayesian_networks/,djangoblaster,1486413278,[removed],0,1
208,2017-2-7,2017,2,7,5,5sguql,A tuturiol that i found amazing for learning to use neural networks from basically no knowledge.,https://www.reddit.com/r/MachineLearning/comments/5sguql/a_tuturiol_that_i_found_amazing_for_learning_to/,Jaymonkey02,1486414471,,0,1
209,2017-2-7,2017,2,7,7,5shcx8,[Q] How many epochs should I train a neural network for?,https://www.reddit.com/r/MachineLearning/comments/5shcx8/q_how_many_epochs_should_i_train_a_neural_network/,ADGEfficiency,1486419443,[removed],0,1
210,2017-2-7,2017,2,7,7,5shjau,Logistic regression vs Neural Networks,https://www.reddit.com/r/MachineLearning/comments/5shjau/logistic_regression_vs_neural_networks/,djangoblaster,1486421168,[removed],0,1
211,2017-2-7,2017,2,7,8,5shn5p,[Discussion] Backpropagation error terms for cross entropy cost function,https://www.reddit.com/r/MachineLearning/comments/5shn5p/discussion_backpropagation_error_terms_for_cross/,[deleted],1486422243,[deleted],0,0
212,2017-2-7,2017,2,7,10,5sibqr,PU Learning Implementations? What's the cutting edge?,https://www.reddit.com/r/MachineLearning/comments/5sibqr/pu_learning_implementations_whats_the_cutting_edge/,[deleted],1486429539,[removed],0,1
213,2017-2-7,2017,2,7,12,5sj1l6,[1701.05517] PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications,https://www.reddit.com/r/MachineLearning/comments/5sj1l6/170105517_pixelcnn_improving_the_pixelcnn_with/,raltk,1486437997,,0,1
214,2017-2-7,2017,2,7,12,5sj41w,On the intuition behind deep learning and GANs  towards a fundamental understanding,https://www.reddit.com/r/MachineLearning/comments/5sj41w/on_the_intuition_behind_deep_learning_and_gans/,wayaai,1486438825,,0,1
215,2017-2-7,2017,2,7,14,5sjlxu,"Deep Learning &amp; Parameter Tuning with MXnet, H2o Package in R",https://www.reddit.com/r/MachineLearning/comments/5sjlxu/deep_learning_parameter_tuning_with_mxnet_h2o/,NarendhiranS,1486445335,,0,1
216,2017-2-7,2017,2,7,16,5sk2zg,[R] A Path to AI | Yann LeCun,https://www.reddit.com/r/MachineLearning/comments/5sk2zg/r_a_path_to_ai_yann_lecun/,downtownslim,1486452682,,3,30
217,2017-2-7,2017,2,7,16,5sk5b0,How do I learn Machine Learning &amp; data Science,https://www.reddit.com/r/MachineLearning/comments/5sk5b0/how_do_i_learn_machine_learning_data_science/,A_D_Exploration,1486453823,,0,1
218,2017-2-7,2017,2,7,17,5sk6l1,[D] say I want to extract the comments section from any arbitrary webpage with a comments section,https://www.reddit.com/r/MachineLearning/comments/5sk6l1/d_say_i_want_to_extract_the_comments_section_from/,MLLLQQQ,1486454494,[removed],2,0
219,2017-2-7,2017,2,7,17,5sk95x,Demystifying Word2Vec: A comprehensive dive into word embeddings,https://www.reddit.com/r/MachineLearning/comments/5sk95x/demystifying_word2vec_a_comprehensive_dive_into/,jantanplan,1486455823,,0,1
220,2017-2-7,2017,2,7,17,5skcx0,Can we reconstruct a distribution using VAE(variational auto encoders)?,https://www.reddit.com/r/MachineLearning/comments/5skcx0/can_we_reconstruct_a_distribution_using/,sbsbsbsbsb945,1486457891,[removed],0,1
221,2017-2-7,2017,2,7,18,5skjgf,Tensroflow v0.x to v1.0 converter,https://www.reddit.com/r/MachineLearning/comments/5skjgf/tensroflow_v0x_to_v10_converter/,machrisaa,1486461297,[removed],0,1
222,2017-2-7,2017,2,7,19,5skk52,I aplgiz for intrrupting,https://www.reddit.com/r/MachineLearning/comments/5skk52/i_aplgiz_for_intrrupting/,Thomastallcrop,1486461635,[removed],0,1
223,2017-2-7,2017,2,7,19,5sklib,[D] Oxford Deep NLP 2017 course,https://www.reddit.com/r/MachineLearning/comments/5sklib/d_oxford_deep_nlp_2017_course/,a_endurance,1486462238,,13,304
224,2017-2-7,2017,2,7,19,5sklw2,Normalization of data using python,https://www.reddit.com/r/MachineLearning/comments/5sklw2/normalization_of_data_using_python/,ArberB1987,1486462403,,0,1
225,2017-2-7,2017,2,7,19,5sknwn,Extracting companies name from resumes?,https://www.reddit.com/r/MachineLearning/comments/5sknwn/extracting_companies_name_from_resumes/,learner_30,1486463361,,0,1
226,2017-2-7,2017,2,7,19,5skr13,"ELi5: When building a neural language model, how does it work when there are no ""labels"" to establish a loss function with and tune parameters?",https://www.reddit.com/r/MachineLearning/comments/5skr13/eli5_when_building_a_neural_language_model_how/,heretherenearfar,1486464798,[removed],0,1
227,2017-2-7,2017,2,7,22,5slcyi,"[D] Mixing learning rate decay and Adam, is it possible?",https://www.reddit.com/r/MachineLearning/comments/5slcyi/d_mixing_learning_rate_decay_and_adam_is_it/,carlthome,1486473846,"I'm training somewhat deep ConvNets from scratch, and get a consistent accuracy increase up to a point at which the gradient spikes and the cost diverges ([example](http://imgur.com/a/U4zS5)). I'm not entirely sure why this happens and I have a hard time debugging it, but it seems I can avoid it by simply annealing the learning rate. However, I like the idea of Adam and overall it seems to converge faster than Nesterov momentum. Is it possible to manually decay the learning rate for Adam (and does it even make sense)? How do you handle these kinds of spikes, and what's causing them if it's not the adaptive momentum becoming too big? I am already ~~scaling~~ soft clipping gradients by their L2 norm, by the way.",13,1
228,2017-2-7,2017,2,7,22,5sldwk,Sequence classification with Caffe LSTM/RNN,https://www.reddit.com/r/MachineLearning/comments/5sldwk/sequence_classification_with_caffe_lstmrnn/,theGlitchInTheMatrix,1486474184,[removed],0,1
229,2017-2-7,2017,2,7,22,5slhvl,[R] H2O hyperparameter grid searches -- how to optimize for validation_auc instead of training_auc?,https://www.reddit.com/r/MachineLearning/comments/5slhvl/r_h2o_hyperparameter_grid_searches_how_to/,datasciguy-aaay,1486475588,[removed],0,1
230,2017-2-7,2017,2,7,23,5slq3g,"AI With The Best online conference April 29/30 with Geoffrey Hinton, Yoshua Bengio and Ian Goodfellow",https://www.reddit.com/r/MachineLearning/comments/5slq3g/ai_with_the_best_online_conference_april_2930/,MariaWTB,1486478336,,0,1
231,2017-2-7,2017,2,7,23,5slqwg,Fully Funded Phd Position in Predictive Analytics,https://www.reddit.com/r/MachineLearning/comments/5slqwg/fully_funded_phd_position_in_predictive_analytics/,johnmcauley,1486478594,[removed],0,1
232,2017-2-8,2017,2,8,0,5sm24v,How do I get a Titan X to work in a Dell T3610 (PSU issues)?,https://www.reddit.com/r/MachineLearning/comments/5sm24v/how_do_i_get_a_titan_x_to_work_in_a_dell_t3610/,MachineLearner2,1486482016,[removed],0,1
233,2017-2-8,2017,2,8,1,5sm9f1,MXNet Joins Apache Software Foundation,https://www.reddit.com/r/MachineLearning/comments/5sm9f1/mxnet_joins_apache_software_foundation/,Rustyvoltage,1486484078,,0,1
234,2017-2-8,2017,2,8,1,5smdjc,Custom speech model service,https://www.reddit.com/r/MachineLearning/comments/5smdjc/custom_speech_model_service/,[deleted],1486485193,[deleted],0,1
235,2017-2-8,2017,2,8,3,5sn4cx,[D] Regression and classification trees help needed,https://www.reddit.com/r/MachineLearning/comments/5sn4cx/d_regression_and_classification_trees_help_needed/,[deleted],1486492154,[removed],5,0
236,2017-2-8,2017,2,8,3,5sn987,[N] Announcing TensorFlow Fold: Deep Learning With Dynamic Computation Graphs,https://www.reddit.com/r/MachineLearning/comments/5sn987/n_announcing_tensorflow_fold_deep_learning_with/,Conchylicultor,1486493406,,29,169
237,2017-2-8,2017,2,8,6,5so3f2,Pushing MPI into the Deep Learning Training Stack,https://www.reddit.com/r/MachineLearning/comments/5so3f2/pushing_mpi_into_the_deep_learning_training_stack/,[deleted],1486501233,[deleted],0,1
238,2017-2-8,2017,2,8,6,5sofjn,[D] Intuitive physics research,https://www.reddit.com/r/MachineLearning/comments/5sofjn/d_intuitive_physics_research/,harmonium1,1486504422,"There seems to be a consensus (especially judging from recent general talks by researchers on the ""future of AI"") that we will need to build models that have some sense of intuitive (or ""naive"") physics, and that predict object permanence, affordances, etc. 

There was a [NIPS workshop](http://phys.csail.mit.edu/) on intuitive physics, with some interesting papers (mostly applied to RL).  What do you think the future of this (relatively new) research area will look like?  Might we find ways to leverage networks with ""intuitive physics"" modules to improve accuracy on general vision tasks?",3,4
239,2017-2-8,2017,2,8,6,5sofvd,Dynamic computation graphs introduced in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/5sofvd/dynamic_computation_graphs_introduced_in/,[deleted],1486504512,[deleted],0,1
240,2017-2-8,2017,2,8,8,5sp1eu,[P]Writing document on neural nets,https://www.reddit.com/r/MachineLearning/comments/5sp1eu/pwriting_document_on_neural_nets/,maka89,1486510472,"Link: https://www.webandroid.org/nn.pdf
So far written the introduction and ""stepping stones"" chapter on linear regression and logistic regression. So anyone interested please take a look :) Would love feedback. The ""target audience"" is people who are interested in AI for whatever reason(its popular these days), but not into computer science/machine learning.",3,4
241,2017-2-8,2017,2,8,8,5sp3j9,Getting Batch Normalization to Converge Reliable,https://www.reddit.com/r/MachineLearning/comments/5sp3j9/getting_batch_normalization_to_converge_reliable/,testingTestingIBS,1486511106,[removed],0,1
242,2017-2-8,2017,2,8,9,5sp83d,"SXtrm, D Gngbang #65",https://www.reddit.com/r/MachineLearning/comments/5sp83d/sxtrm_d_gngbang_65/,Sethcompmin,1486512482,[removed],0,1
243,2017-2-8,2017,2,8,9,5spfhv,A Practical Approach to Machine Learning Projects,https://www.reddit.com/r/MachineLearning/comments/5spfhv/a_practical_approach_to_machine_learning_projects/,amirsaffari,1486514516,,0,1
244,2017-2-8,2017,2,8,10,5splt1,[N] 375k paintings with CC licence - new dataset for artistic style transfer?,https://www.reddit.com/r/MachineLearning/comments/5splt1/n_375k_paintings_with_cc_licence_new_dataset_for/,Brudaks,1486516341,,2,15
245,2017-2-8,2017,2,8,10,5spmqj,Candidation algorith criteria for another training example,https://www.reddit.com/r/MachineLearning/comments/5spmqj/candidation_algorith_criteria_for_another/,exilen,1486516638,[removed],0,1
246,2017-2-8,2017,2,8,12,5sq7yd,Demo of Letters alive Plus for the Sprout Pro,https://www.reddit.com/r/MachineLearning/comments/5sq7yd/demo_of_letters_alive_plus_for_the_sprout_pro/,SheCalledMePaul,1486523484,,0,1
247,2017-2-8,2017,2,8,12,5sqbqo,What motto does a depressed machine learner have?,https://www.reddit.com/r/MachineLearning/comments/5sqbqo/what_motto_does_a_depressed_machine_learner_have/,[deleted],1486524738,[removed],0,1
248,2017-2-8,2017,2,8,12,5sqg6z,[D] How to get better at GPU programming?,https://www.reddit.com/r/MachineLearning/comments/5sqg6z/d_how_to_get_better_at_gpu_programming/,MetricSpade007,1486526206,"I want to get better at writing code at the GPU level -- for people who are experts at writing code at this level and optimizing operations, what kind of steps/resources did you use to learn? 

As a related question, do you think GPU experts are in high demand at AI companies/startups, or is the demand largely in research engineers/scientists and in theoreticians?",31,12
249,2017-2-8,2017,2,8,13,5sqlvk,Is there anything particularly wrong with my tensorflow code?,https://www.reddit.com/r/MachineLearning/comments/5sqlvk/is_there_anything_particularly_wrong_with_my/,xyz4d,1486528145,,0,1
250,2017-2-8,2017,2,8,14,5sqs2q,[R] Deep Learning for Health Informatics -- Good overview of DL architectures and their practical application in HI.,https://www.reddit.com/r/MachineLearning/comments/5sqs2q/r_deep_learning_for_health_informatics_good/,rnadler,1486530409,,4,13
251,2017-2-8,2017,2,8,14,5sqtq3,[D] What are the advantages of a software engineer who want to become a machine learning engineer? machine learning engineer?,https://www.reddit.com/r/MachineLearning/comments/5sqtq3/d_what_are_the_advantages_of_a_software_engineer/,[deleted],1486531011,[removed],0,1
252,2017-2-8,2017,2,8,14,5squic,"ML,Tensorflow blog",https://www.reddit.com/r/MachineLearning/comments/5squic/mltensorflow_blog/,[deleted],1486531322,[removed],0,1
253,2017-2-8,2017,2,8,14,5sqwiv,"[D]ML,Tensorflow blog",https://www.reddit.com/r/MachineLearning/comments/5sqwiv/dmltensorflow_blog/,jassi1994,1486532113,"So I have been writing a comprehensive [blog](https://jasdeep06.github.io/) for past 20 days now.I wanted others to benefit from my knowledge and experience of using tensorflow.Till date I have written posts on backpropagation,Basics of Tensorflow,Linear regression in Tensorflow,CNNs,Implementation of research paper(Neural Stacks).I also plan to write tensorflow implementations of RNNs and some posts on Reinforcement learning.I would love to receive feedbacks and criticism.Have a look   https://jasdeep06.github.io/  (there has been some rendering problems on phones,I'll eliminate them ASAP.For now please use desktops)",7,14
254,2017-2-8,2017,2,8,15,5sr2ts,[R] Face Aging with Conditional Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/5sr2ts/r_face_aging_with_conditional_generative/,madebyollin,1486534719,,6,11
255,2017-2-8,2017,2,8,15,5sr5ki,[D] What're the advantages of a software engineer who learn machine learning?,https://www.reddit.com/r/MachineLearning/comments/5sr5ki/d_whatre_the_advantages_of_a_software_engineer/,ZuzooVn,1486535942,[removed],0,1
256,2017-2-8,2017,2,8,18,5srmic,Look! This is powerful high viscosity mixers for all kinds of chemicals,https://www.reddit.com/r/MachineLearning/comments/5srmic/look_this_is_powerful_high_viscosity_mixers_for/,mixmachinery,1486544484,,1,1
257,2017-2-8,2017,2,8,18,5srmzq,[D] Building semantic vectors from term vectors / word embeddings,https://www.reddit.com/r/MachineLearning/comments/5srmzq/d_building_semantic_vectors_from_term_vectors/,quuxman,1486544741,"Is there a reasonable way to build semantic vectors from texts ranging from a sentence to a paragraph using pre-computed term vectors?

I'm doing preliminary research for a project that finds matches between small free-form texts ranging in length from a sentence to a paragraph.

I found the project [ConceptNet](https://github.com/commonsense/conceptnet5/wiki) along with their [Numberbatch data](https://github.com/commonsense/conceptnet-numberbatch) which is apparently significantly better than word2vec output so I'd like to use this data. However I can't find any solid information on how to actually apply term vectors to build semantic vectors.",8,6
258,2017-2-8,2017,2,8,18,5srpci,Wow! JCT show you this kind of chemical paint high sheer mixer,https://www.reddit.com/r/MachineLearning/comments/5srpci/wow_jct_show_you_this_kind_of_chemical_paint_high/,mixmachinery,1486546047,,1,1
259,2017-2-8,2017,2,8,18,5srqk0,[P] Best Place to outsource ML MVP?,https://www.reddit.com/r/MachineLearning/comments/5srqk0/p_best_place_to_outsource_ml_mvp/,b2basics,1486546702,"Currently looking at Gigster for outsourcing a ML image recognition program I am hoping to build. Does anyone know if they are worth the price, or if there are alternative groups that are better at image recognition or ML?

PS. Looking for a technical co-founder if anyone is interested =D",3,0
260,2017-2-8,2017,2,8,19,5sru5u,[P] Practical PyTorch: Translation with a Sequence to Sequence Network and Attention,https://www.reddit.com/r/MachineLearning/comments/5sru5u/p_practical_pytorch_translation_with_a_sequence/,iamspro,1486548449,,13,46
261,2017-2-8,2017,2,8,19,5srvqa,Which kind of kneading machine can be in charge of rubber production pro...,https://www.reddit.com/r/MachineLearning/comments/5srvqa/which_kind_of_kneading_machine_can_be_in_charge/,mixmachinery,1486549073,,1,1
262,2017-2-8,2017,2,8,19,5srwye,[Free] Dating Sexy Girls,https://www.reddit.com/r/MachineLearning/comments/5srwye/free_dating_sexy_girls/,Nicholasinplec,1486549470,[removed],0,1
263,2017-2-8,2017,2,8,20,5ss58p,Advantages of learning hadoop,https://www.reddit.com/r/MachineLearning/comments/5ss58p/advantages_of_learning_hadoop/,Edureka-learning,1486552572,,0,1
264,2017-2-8,2017,2,8,20,5ss6t3,Where can we find the reliable resins mixing machines,https://www.reddit.com/r/MachineLearning/comments/5ss6t3/where_can_we_find_the_reliable_resins_mixing/,mixmachinery,1486553321,,1,1
265,2017-2-8,2017,2,8,21,5ssd7t,Tracking the World State with Recurrent Entity Networks,https://www.reddit.com/r/MachineLearning/comments/5ssd7t/tracking_the_world_state_with_recurrent_entity/,gigasquid,1486556264,,0,7
266,2017-2-8,2017,2,8,21,5sseg5,[P] Implement Double Convolution in tflearn,https://www.reddit.com/r/MachineLearning/comments/5sseg5/p_implement_double_convolution_in_tflearn/,themoosemind,1486556773,"I am currently trying to understand [Doubly Convolutional Neural Networks](https://arxiv.org/pdf/1610.09716v1.pdf) and then write a tflearn implementation for it (see [Github](https://github.com/MartinThoma/doublecnn-tflearn)).

They have a [theano implementation](https://github.com/Shuangfei/doublecnn) and pseudocode in the paper, so I thought this would be simple. However, it seems I made several errors. It would be great if somebody could help me (or if somebody already made an implementation for Tensorflow)",8,10
267,2017-2-8,2017,2,8,21,5ssi89,HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving,https://www.reddit.com/r/MachineLearning/comments/5ssi89/holstep_a_machine_learning_dataset_for/,jfwam,1486558384,,0,1
268,2017-2-8,2017,2,8,23,5ssv4k,[P] Clustering Similar Stories Using LDA,https://www.reddit.com/r/MachineLearning/comments/5ssv4k/p_clustering_similar_stories_using_lda/,benfred,1486563047,,4,35
269,2017-2-8,2017,2,8,23,5sswcy,A brief history of AI,https://www.reddit.com/r/MachineLearning/comments/5sswcy/a_brief_history_of_ai/,[deleted],1486563459,[deleted],0,1
270,2017-2-8,2017,2,8,23,5ssx4i,[P] How Teleport uses AI to peek into every street corner,https://www.reddit.com/r/MachineLearning/comments/5ssx4i/p_how_teleport_uses_ai_to_peek_into_every_street/,[deleted],1486563731,[deleted],4,102
271,2017-2-9,2017,2,9,0,5stg4f,"Simple Questions Thread February 08, 2017",https://www.reddit.com/r/MachineLearning/comments/5stg4f/simple_questions_thread_february_08_2017/,AutoModerator,1486569150,[removed],0,1
272,2017-2-9,2017,2,9,1,5stman,How exactly do they train resnet?,https://www.reddit.com/r/MachineLearning/comments/5stman/how_exactly_do_they_train_resnet/,testingTestingIBS,1486570813,[removed],0,1
273,2017-2-9,2017,2,9,2,5stwgx,Identifying sections in a website using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5stwgx/identifying_sections_in_a_website_using_machine/,dotioguy,1486573414,[removed],0,1
274,2017-2-9,2017,2,9,2,5su9w2,MITIE-GUI - A browser-based front end for training MITIE models from raw data,https://www.reddit.com/r/MachineLearning/comments/5su9w2/mitiegui_a_browserbased_front_end_for_training/,jaydenwindle,1486576706,,0,1
275,2017-2-9,2017,2,9,3,5sucge,[FREE_JOIN] 100% Free Sex Dting Website,https://www.reddit.com/r/MachineLearning/comments/5sucge/free_join_100_free_sex_dting_website/,Sethedre,1486577314,[removed],0,0
276,2017-2-9,2017,2,9,3,5sulhq,[R] Regressing Robust and Discriminative 3D Morphable Models with a very Deep Neural Network,https://www.reddit.com/r/MachineLearning/comments/5sulhq/r_regressing_robust_and_discriminative_3d/,GilLevi,1486579500,,2,48
277,2017-2-9,2017,2,9,3,5suotg,"Classification: class matching ""everything that can't be recognized""?",https://www.reddit.com/r/MachineLearning/comments/5suotg/classification_class_matching_everything_that/,de-sacco,1486580354,[removed],0,1
278,2017-2-9,2017,2,9,4,5sv2kj,"Google Cloud ML - ""ML training units""",https://www.reddit.com/r/MachineLearning/comments/5sv2kj/google_cloud_ml_ml_training_units/,AlexRothberg,1486583843,[removed],0,1
279,2017-2-9,2017,2,9,5,5sv4vb,How to Predict Music You Love (LIVE),https://www.reddit.com/r/MachineLearning/comments/5sv4vb/how_to_predict_music_you_love_live/,llSourcell,1486584437,,0,1
280,2017-2-9,2017,2,9,5,5sv5wv,Best Espresso Machine- Life Made Easy,https://www.reddit.com/r/MachineLearning/comments/5sv5wv/best_espresso_machine_life_made_easy/,RoyPlaza,1486584695,[removed],0,1
281,2017-2-9,2017,2,9,5,5sv9md,[P] Facebook Implementation of Aggregated Residual Transformations for Deep Neural Networks (ResNeXt) in Torch,https://www.reddit.com/r/MachineLearning/comments/5sv9md/p_facebook_implementation_of_aggregated_residual/,blurtruck,1486585642,,5,20
282,2017-2-9,2017,2,9,5,5sv9yu,[D] Gaussian process python implementations,https://www.reddit.com/r/MachineLearning/comments/5sv9yu/d_gaussian_process_python_implementations/,Jimbo_Mcnulty,1486585730,"It seems there are several GP implementations for python out there:

1) Sklearn's GaussianProcessRegressor (http://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html#sklearn.gaussian_process.GaussianProcessRegressor)


2) GPy (http://sheffieldml.github.io/GPy/)


3) pyGP (https://pythonhosted.org/pygp/)

I was wondering if anyone has had any experience working with any combination ( or individual implementation) of these and had anything to say about their potential strengths and weaknesses?

EDIT: Just an edit for anyone who might stumble upon this post in the future, I've had some difficulties running GPy, potentially because of an incompatible version of numpy ( seems I'm getting a LinAlgError with regards to the covariance matrix not being positive-semi-definite even with jitter) so have been using Sklearn's version with few issues.",7,4
283,2017-2-9,2017,2,9,5,5svejy,android-yolo: object detection on Android using the YOLO network,https://www.reddit.com/r/MachineLearning/comments/5svejy/androidyolo_object_detection_on_android_using_the/,StrawberryNumberNine,1486586916,,0,1
284,2017-2-9,2017,2,9,6,5svnum,[N] Udacity open sources its self-driving car simulator,https://www.reddit.com/r/MachineLearning/comments/5svnum/n_udacity_open_sources_its_selfdriving_car/,lopespm,1486589405,,8,129
285,2017-2-9,2017,2,9,6,5svqim,Brazilian Aeronautics Occurrences dataset from the last 10 years,https://www.reddit.com/r/MachineLearning/comments/5svqim/brazilian_aeronautics_occurrences_dataset_from/,paulo_zip,1486590134,,0,1
286,2017-2-9,2017,2,9,7,5svv14,[course critic] Just got this deal on ML coursework. Is it worth it?,https://www.reddit.com/r/MachineLearning/comments/5svv14/course_critic_just_got_this_deal_on_ml_coursework/,lovebes,1486591357,[removed],0,1
287,2017-2-9,2017,2,9,9,5swqry,Http proxy for image classification using Tensorflow model,https://www.reddit.com/r/MachineLearning/comments/5swqry/http_proxy_for_image_classification_using/,[deleted],1486600475,[deleted],0,1
288,2017-2-9,2017,2,9,9,5swv2u,[P] Http proxy for image classification using Tensorflow,https://www.reddit.com/r/MachineLearning/comments/5swv2u/p_http_proxy_for_image_classification_using/,dimorinny,1486601774,,1,1
289,2017-2-9,2017,2,9,15,5syc0h, Tabletop Wrap Around and Top Labeler  + www.neostarp...,https://www.reddit.com/r/MachineLearning/comments/5syc0h/_tabletop_wrap_around_and_top_labeler/,neostarpack,1486620299,,0,1
290,2017-2-9,2017,2,9,15,5sycuz,"DeepLearning Workstation, Ubuntu or CentOS ?",https://www.reddit.com/r/MachineLearning/comments/5sycuz/deeplearning_workstation_ubuntu_or_centos/,zhaokai,1486620628,[removed],0,1
291,2017-2-9,2017,2,9,16,5symc7,Introduction to Naive Bayes Classification Algorithm in Python and R,https://www.reddit.com/r/MachineLearning/comments/5symc7/introduction_to_naive_bayes_classification/,NarendhiranS,1486624840,,0,1
292,2017-2-9,2017,2,9,16,5sypuw,Particle Swarm Optimization and WeightsWeighs Update,https://www.reddit.com/r/MachineLearning/comments/5sypuw/particle_swarm_optimization_and_weightsweighs/,ononimo,1486626636,[removed],0,1
293,2017-2-9,2017,2,9,19,5sz7kq,[FREE] Free-Sex-Dting-Website,https://www.reddit.com/r/MachineLearning/comments/5sz7kq/free_freesexdtingwebsite/,Mileslira,1486635333,[removed],1,0
294,2017-2-9,2017,2,9,20,5szghq,"[N] Video about ""Reproducible research"" and ""Explaining predictions of any classifier""",https://www.reddit.com/r/MachineLearning/comments/5szghq/n_video_about_reproducible_research_and/,khozzy,1486639232,,1,17
295,2017-2-9,2017,2,9,21,5szqd8,Understanding Agent Cooperation | DeepMind,https://www.reddit.com/r/MachineLearning/comments/5szqd8/understanding_agent_cooperation_deepmind/,[deleted],1486643608,[deleted],0,1
296,2017-2-9,2017,2,9,23,5t07gc,[R] Variational Inference using Implicit Models (Part III): Variational derivation of Adversarially Learned Inference and BiGANs from first principles.,https://www.reddit.com/r/MachineLearning/comments/5t07gc/r_variational_inference_using_implicit_models/,fhuszar,1486649878,,2,26
297,2017-2-10,2017,2,10,1,5t0x3t,[R] Understanding Agent Cooperation | DeepMind,https://www.reddit.com/r/MachineLearning/comments/5t0x3t/r_understanding_agent_cooperation_deepmind/,downtownslim,1486657212,,11,50
298,2017-2-10,2017,2,10,1,5t113j,It goes without saying that,https://www.reddit.com/r/MachineLearning/comments/5t113j/it_goes_without_saying_that/,Seansallpost,1486658208,[removed],0,1
299,2017-2-10,2017,2,10,1,5t15ki,TensorFlow howto: a universal approximator inside a neural net,https://www.reddit.com/r/MachineLearning/comments/5t15ki/tensorflow_howto_a_universal_approximator_inside/,[deleted],1486659260,[deleted],0,1
300,2017-2-10,2017,2,10,2,5t1azp,[P] Creating an AI DOOM bot (tutorial),https://www.reddit.com/r/MachineLearning/comments/5t1azp/p_creating_an_ai_doom_bot_tutorial/,alreadywon,1486660518,,12,118
301,2017-2-10,2017,2,10,2,5t1cnz,How do MachineLearning developers go about finding a solution to a problem they have been stuck with awhile?,https://www.reddit.com/r/MachineLearning/comments/5t1cnz/how_do_machinelearning_developers_go_about/,BURNY2610,1486660899,[removed],0,1
302,2017-2-10,2017,2,10,3,5t1ono,[P] TensorFlow howto: a universal approximator inside a neural net,https://www.reddit.com/r/MachineLearning/comments/5t1ono/p_tensorflow_howto_a_universal_approximator/,morgangiraud,1486663788,,7,11
303,2017-2-10,2017,2,10,3,5t2026,[P] DRAW for Text,https://www.reddit.com/r/MachineLearning/comments/5t2026/p_draw_for_text/,throwaway1849430,1486666627,"Hello, I'm considering modifying DRAW, Deep Recurrent Attentive Writer, for text and wanted to get some feedback to see if anything stands out as a bad idea first. I like the framework of iteratively improving a final representation and the attention model, compared to RNN sequential decoders.

My plan seems straightforward:

* Input is a matrix, where each row is a static word embedding, normalized to (0,1)

* For read and write attention, the convolutional receptive field will be the full width of the input matrix (unnecessary?)

* Output is a matrix, convert each row to a word for a sequence of words

The final representation is a matrix of positive continuous real values, with each row representing one word in the output sequence. Each row gets multiplied by an output projection matrix, to result in a sequence of vectors where each represents the output distribution over the vocab. Will it suffice to let 
    
    loss = softmax_cross_entropy() + latent_loss()?

Is this a practical approach? 

For the PAD token's embedding, would it make sense to use a vector of 0's?",8,5
304,2017-2-10,2017,2,10,4,5t21ln,"Extracting and extending model features. Is this ""Transfer Learning""?",https://www.reddit.com/r/MachineLearning/comments/5t21ln/extracting_and_extending_model_features_is_this/,Simusid,1486667000,[removed],0,1
305,2017-2-10,2017,2,10,4,5t26mz,Connecting Tensforflow CNN to iPhone camera: best approach?,https://www.reddit.com/r/MachineLearning/comments/5t26mz/connecting_tensforflow_cnn_to_iphone_camera_best/,tangerto,1486668263,[removed],0,1
306,2017-2-10,2017,2,10,5,5t2jpx,Building a machine capable of extracting CNN features from an image dataset.,https://www.reddit.com/r/MachineLearning/comments/5t2jpx/building_a_machine_capable_of_extracting_cnn/,craftyspice,1486671710,[removed],1,1
307,2017-2-10,2017,2,10,7,5t3bna,[D] Is there any work on imposing grammatical structure to neural network-generated text?,https://www.reddit.com/r/MachineLearning/comments/5t3bna/d_is_there_any_work_on_imposing_grammatical/,Lolologist,1486679150,"I'm doing some research and/or futzing around with tensorflow and https://github.com/carpedm20/lstm-char-cnn-tensorflow and getting some neat results, but they all have a nonsense structure to them (let alone character-based generative models seem to occasionally stumble into nonsense words.)

Is there anything out there on trying to make more grammatical structure get forced into the generated text from NNs in any way, other than ""boy I sure hope the NN learns what is proper and good?""

I'd be interested in any projects anyone is aware of where I can do word-based generation of text as well, especially if anyone knows anything interesting in the realm as it relates to chatbots.",22,15
308,2017-2-10,2017,2,10,8,5t3ubx,Azure N Series GPU SLOW,https://www.reddit.com/r/MachineLearning/comments/5t3ubx/azure_n_series_gpu_slow/,Jaden71,1486684169,[removed],0,1
309,2017-2-10,2017,2,10,8,5t3w9n,[D] Azure N Series VM SLOW.,https://www.reddit.com/r/MachineLearning/comments/5t3w9n/d_azure_n_series_vm_slow/,Jaden71,1486684770,"For some reason the installed Tesla K80 is no faster than my Desktop with a GTX 1050 Ti.

My GTX takes 43 seconds per epoch while the Tesla takes 73 seconds.

Is anyone else having this error or is it a misconfiguration on my end?",1,1
310,2017-2-10,2017,2,10,9,5t3yks,"""Signature Based Malware Detection is Dead"". Signature and behavioral based anti-malware are no match for next generation adversaries who utilize mutating hashes, sophisticated obfuscation mechanisms, self-propagating malware, and intelligent malware components.",https://www.reddit.com/r/MachineLearning/comments/5t3yks/signature_based_malware_detection_is_dead/,CastBound_0,1486685450,,0,1
311,2017-2-10,2017,2,10,9,5t4332,any great examples of ML in social network modeling?,https://www.reddit.com/r/MachineLearning/comments/5t4332/any_great_examples_of_ml_in_social_network/,eddlie,1486686763,[removed],0,1
312,2017-2-10,2017,2,10,10,5t49yr,Is there a way to use LSTMs with multiple predictors?,https://www.reddit.com/r/MachineLearning/comments/5t49yr/is_there_a_way_to_use_lstms_with_multiple/,Synroc,1486688955,[removed],0,1
313,2017-2-10,2017,2,10,14,5t5ipj,Explainer: Machine learning vs AI,https://www.reddit.com/r/MachineLearning/comments/5t5ipj/explainer_machine_learning_vs_ai/,NarendhiranS,1486704581,,0,1
314,2017-2-10,2017,2,10,15,5t5q01,Prediction model problem,https://www.reddit.com/r/MachineLearning/comments/5t5q01/prediction_model_problem/,Isuru_Dilhan,1486707677,[removed],0,1
315,2017-2-10,2017,2,10,15,5t5tud,CART and Random Forests for Practitioners - DZone Big Data,https://www.reddit.com/r/MachineLearning/comments/5t5tud/cart_and_random_forests_for_practitioners_dzone/,Sibanjan,1486709396,,0,1
316,2017-2-10,2017,2,10,16,5t5wje,"13 Free Self-Study Books on Mathematics, Machine Learning &amp; Deep Learning",https://www.reddit.com/r/MachineLearning/comments/5t5wje/13_free_selfstudy_books_on_mathematics_machine/,NarendhiranS,1486710651,,0,1
317,2017-2-10,2017,2,10,17,5t64la,[D] Create a simple sign recognition system,https://www.reddit.com/r/MachineLearning/comments/5t64la/d_create_a_simple_sign_recognition_system/,federicoponzi,1486714729,"I'm trying to create a prototype of a biometric recognition system, based on signature recognition.
I have input from three sensors: a gyroscope, an accelerometer, and a pression (on the pen) sensor.

I know that I can use dynamic time warping to find the distance from my sample to the input data, but I was wondering if there is some ml algorithm that could help me to recognitize the user or I should just try to find a good threshold for the distance.

In input I have the sensor's data, as output I would like yes/no. Since it's just a prototype it dosen't need to be much accurate, but the more the better.

Thanks for help.
edit: can't edit the title, but it's supposed to be signature recog not sign :')",7,15
318,2017-2-10,2017,2,10,17,5t65yr,"Yann LeCun, Director of AI Research at Facebook on ""What are your recommendations for self-studying machine learning?""",https://www.reddit.com/r/MachineLearning/comments/5t65yr/yann_lecun_director_of_ai_research_at_facebook_on/,pmz,1486715503,,0,1
319,2017-2-10,2017,2,10,18,5t6etd,80 Million Tiny Images,https://www.reddit.com/r/MachineLearning/comments/5t6etd/80_million_tiny_images/,indatawetrust,1486720222,,0,1
320,2017-2-10,2017,2,10,19,5t6m6l,How to derive rules from ML analysis?,https://www.reddit.com/r/MachineLearning/comments/5t6m6l/how_to_derive_rules_from_ml_analysis/,cairmen,1486723602,[removed],0,1
321,2017-2-10,2017,2,10,20,5t6p8a,It goes without saying that,https://www.reddit.com/r/MachineLearning/comments/5t6p8a/it_goes_without_saying_that/,Isaiahfila,1486725030,[removed],0,1
322,2017-2-10,2017,2,10,23,5t7jvr,How to use Webhose.io rated reviews for sentiment classification,https://www.reddit.com/r/MachineLearning/comments/5t7jvr/how_to_use_webhoseio_rated_reviews_for_sentiment/,rangeva,1486736973,,0,10
323,2017-2-10,2017,2,10,23,5t7oiw,Creating a Perceptron Model (C++),https://www.reddit.com/r/MachineLearning/comments/5t7oiw/creating_a_perceptron_model_c/,meryrich,1486738428,,0,1
324,2017-2-10,2017,2,10,23,5t7p51,[P] Machine learning driven Web application firewall,https://www.reddit.com/r/MachineLearning/comments/5t7p51/p_machine_learning_driven_web_application_firewall/,Faizann24,1486738634,,3,5
325,2017-2-11,2017,2,11,1,5t8ava,[D] Are there entities that want to use expensive GPUs for training/inference but cannot afford BYOGPU?,https://www.reddit.com/r/MachineLearning/comments/5t8ava/d_are_there_entities_that_want_to_use_expensive/,foxh8er,1486744779,"It seems to me that either you're a hobbyist learning GPU DL but can use CPU for training simple models or you're a research lab with  a cluster of Titan X's. Is there a middle ground that wants GPUs, but can't afford them?",17,4
326,2017-2-11,2017,2,11,2,5t8gvg,[P] A PyTorch implementation of DenseNet.,https://www.reddit.com/r/MachineLearning/comments/5t8gvg/p_a_pytorch_implementation_of_densenet/,bdamos,1486746374,,8,51
327,2017-2-11,2017,2,11,2,5t8m5i,[P] Subreddit Recommender System using tensorflow,https://www.reddit.com/r/MachineLearning/comments/5t8m5i/p_subreddit_recommender_system_using_tensorflow/,ponderinghydrogen,1486747817,,9,63
328,2017-2-11,2017,2,11,4,5t9d7r,Nystroem Method for Kernel Approximation,https://www.reddit.com/r/MachineLearning/comments/5t9d7r/nystroem_method_for_kernel_approximation/,Lopelh,1486755078,,0,1
329,2017-2-11,2017,2,11,4,5t9guu,Quality Deburring Machines in UK,https://www.reddit.com/r/MachineLearning/comments/5t9guu/quality_deburring_machines_in_uk/,wsiukweb,1486756083,,0,1
330,2017-2-11,2017,2,11,4,5t9j4i,My personal website is never indexed by Google?,https://www.reddit.com/r/MachineLearning/comments/5t9j4i/my_personal_website_is_never_indexed_by_google/,leehomyc,1486756733,,0,1
331,2017-2-11,2017,2,11,5,5t9l5x,Five Machine Learning Projects You Can No Longer Overlook,https://www.reddit.com/r/MachineLearning/comments/5t9l5x/five_machine_learning_projects_you_can_no_longer/,elisebreda,1486757268,,0,1
332,2017-2-11,2017,2,11,5,5t9m1b,"Dummy question, but would are the most important specs for a computer for machine learning?",https://www.reddit.com/r/MachineLearning/comments/5t9m1b/dummy_question_but_would_are_the_most_important/,SpiderFan,1486757514,[removed],0,1
333,2017-2-11,2017,2,11,5,5t9q1m,Sebastian Thrun answers questions about Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/5t9q1m/sebastian_thrun_answers_questions_about/,bolibeast,1486758670,,0,1
334,2017-2-11,2017,2,11,5,5t9r7t,Ubuntu Deep Learning AWS AMI,https://www.reddit.com/r/MachineLearning/comments/5t9r7t/ubuntu_deep_learning_aws_ami/,Data-Daddy,1486758998,,0,1
335,2017-2-11,2017,2,11,6,5ta0s0,TensorFlow Dev Summit with Livestreams on Feb 15,https://www.reddit.com/r/MachineLearning/comments/5ta0s0/tensorflow_dev_summit_with_livestreams_on_feb_15/,Phnyx,1486761741,,0,26
336,2017-2-11,2017,2,11,6,5ta1p2,[D] Favourite machine learning demos,https://www.reddit.com/r/MachineLearning/comments/5ta1p2/d_favourite_machine_learning_demos/,andyandy16,1486762004,"What are your favourite machine learning demos? Some of my favourites include:

- [Predicting sound of videos](https://www.youtube.com/watch?v=JpZUZ9ZDECE)
- [Tensorflow playground for explaining the learning procedure](http://playground.tensorflow.org)
- Various from [TwoMinutePapers](https://www.youtube.com/user/keeroyz/videos?shelf_id=2&amp;view=0&amp;sort=p)",9,74
337,2017-2-11,2017,2,11,7,5tahyb,Text Classification using Deep Learning,https://www.reddit.com/r/MachineLearning/comments/5tahyb/text_classification_using_deep_learning/,buqiD,1486766677,[removed],0,1
338,2017-2-11,2017,2,11,8,5tatx8,Our progress in AI is one nation. Humanity is another nation. Abilities and skills are lands that AI is slowly taking over from Humanity. What is the history so far and yet to come in this world?,https://www.reddit.com/r/MachineLearning/comments/5tatx8/our_progress_in_ai_is_one_nation_humanity_is/,Yax42,1486770360,[removed],0,1
339,2017-2-11,2017,2,11,9,5tb6dd,State-of-the-Art Machine Learning Automation with HDT,https://www.reddit.com/r/MachineLearning/comments/5tb6dd/stateoftheart_machine_learning_automation_with_hdt/,eborel,1486774013,,0,1
340,2017-2-11,2017,2,11,9,5tb6l8,How to Make Data Amazing - Intro to Deep Learning #5,https://www.reddit.com/r/MachineLearning/comments/5tb6l8/how_to_make_data_amazing_intro_to_deep_learning_5/,llSourcell,1486774086,,0,0
341,2017-2-11,2017,2,11,9,5tb73r,Comparison of dimension reduction algorithms over mandala images generation,https://www.reddit.com/r/MachineLearning/comments/5tb73r/comparison_of_dimension_reduction_algorithms_over/,[deleted],1486774272,[deleted],0,1
342,2017-2-11,2017,2,11,10,5tbgu9,How to identify new classification models in order to improve stacked model performance?,https://www.reddit.com/r/MachineLearning/comments/5tbgu9/how_to_identify_new_classification_models_in/,bullwinkle2059,1486777684,[removed],0,1
343,2017-2-11,2017,2,11,11,5tbjrz,An Idea on Machine Ethics,https://www.reddit.com/r/MachineLearning/comments/5tbjrz/an_idea_on_machine_ethics/,chipbag01,1486778742,[removed],1,1
344,2017-2-11,2017,2,11,13,5tc3sl,[Project] Advanced-Lane-Lines Finding,https://www.reddit.com/r/MachineLearning/comments/5tc3sl/project_advancedlanelines_finding/,upulbandara,1486786343,,7,18
345,2017-2-11,2017,2,11,14,5tcfig,Psychoanalysis of artificial intelligence,https://www.reddit.com/r/MachineLearning/comments/5tcfig/psychoanalysis_of_artificial_intelligence/,kocosman,1486791309,[removed],0,1
346,2017-2-11,2017,2,11,17,5tcyvo,PFAUTER | Buy Gear Shaping Machine | World Mach,https://www.reddit.com/r/MachineLearning/comments/5tcyvo/pfauter_buy_gear_shaping_machine_world_mach/,JonathanZuberi,1486801607,,0,1
347,2017-2-11,2017,2,11,18,5td5lq,Sexy selfie,https://www.reddit.com/r/MachineLearning/comments/5td5lq/sexy_selfie/,Elliotpersdi,1486804943,,0,1
348,2017-2-11,2017,2,11,20,5tdsb8,[D] Best way to represent set (unordered collection) inputs for RNNs?,https://www.reddit.com/r/MachineLearning/comments/5tdsb8/d_best_way_to_represent_set_unordered_collection/,bubaonaruba,1486813638,"RNNs and LSTM/GRU work great as compressors for dynamic length sequences where order matters. Given input sequences we can train any of these to output a vector representation coming from the hidden, that can be reused in various taks later, or the compressor can be trained along with the final model end to end.

Theoretically an unordered collection has less information to be compressed, so it should be an easier task, but the problem is somewhat unnatural for RNN models.

Are there any clever tricks that can account for the set property on the level of the model itself? Of course we can just apply random permutations to each input and it will learn, but it seems very wasteful in terms of learning efficiency.",30,27
349,2017-2-11,2017,2,11,21,5tdw8m,Is there a machine learning Chatbot to generate the perfect karma whore on Reddit?,https://www.reddit.com/r/MachineLearning/comments/5tdw8m/is_there_a_machine_learning_chatbot_to_generate/,bene20080,1486814815,[removed],0,1
350,2017-2-11,2017,2,11,21,5tdwr4,How are the cells within an LSTM connected to each other?,https://www.reddit.com/r/MachineLearning/comments/5tdwr4/how_are_the_cells_within_an_lstm_connected_to/,jackdaniels79,1486814953,[removed],0,1
351,2017-2-11,2017,2,11,21,5te0q9,[P]Document classification using Bayesian Probability,https://www.reddit.com/r/MachineLearning/comments/5te0q9/pdocument_classification_using_bayesian/,flaminggandu,1486816178,"I am working on a project, which deals with personalizing advertisements. Basically, I have find the intent of the user on the internet and display the relevant ads.
I am using user logs to retrieve url. I scrape the url and get its content. I use RAKE and the title of the url to understand what the url is about(generate keywords). For the personalization part I thought the concept of conditional probability would work; given a set of keywords from page A and page B predicting the user intent and display the relevant advertisement on page C. How can Naive Bayes classification be used to do this? Given a set of keywords from page 1 and page 2, how do I predict the intent of the user and display the advertisement based on the keywords from page 1 and page? 
For eg.: If the user reads a blog about ""best smartphones"" and follows a link to ""iphone vs android."" I want to display an advert relating to iphone 6s or something. How do I go about processing after extracting the keywords from the url's?

Also I think RAKE is not the best suitable information retrieval technique.
Is there any framework or any other technique which can be used ?
",5,9
352,2017-2-11,2017,2,11,23,5tewzw,[P] DTB: Dynamic Training Bench (for Tensorflow models),https://www.reddit.com/r/MachineLearning/comments/5tewzw/p_dtb_dynamic_training_bench_for_tensorflow_models/,pgaleone,1486823199,"[Dynamic Training Bench](https://github.com/galeone/dynamic-training-bench) is a tool to simplify the training, evaluation and hyperparameter tuning of Tensorflow models.

I built this tool for 4 main reasons:

1. The training phase of a ML model is almost the same for every model of a certain type
2. When we train a model we usually want to monitor some metrics and visualize some result
3. During the training phase, we want to save the best model, where the goodness of the model is given by its performance on the evaluation set, measured by some metric
4. There's a lack of engineering in the ML field

I think that this last point requires an explanation: usually, researcher builds their models and input sources as they want.
Even if different researchers uses Tensorflow, everyone follows it's own pattern:

* someone writes a huge python file with everything inside
* someone writes different scripts with different names and write somewhere how to execute it
* someone refers to some dataset that's not provided with the code and who want's to reproduce the experiment must waste its time looking for this dataset on the internet.

**In short**:  it's hard to reproduce the experiments, running the code, obtain and preprocess the datasets.
As a consequence, there are lots of people that are *wasting their time* reimplementing stuff.

DTB aim is (also) to standardize the definition of the input sources (how to obtain a dataset, how to preprocess it, how to split in train/evaluation/test) and the training procedures.
Moreover, even models should be standardized: if I'm defining a classifier I must implement a Classifier interface; if I'm defining a Regressor I must implement another interface, and so on...

I invite you to browse the [models](https://github.com/galeone/dynamic-training-bench/tree/master/models) and [inputs](https://github.com/galeone/dynamic-training-bench/tree/master/inputs) folders to find out how I defined the interfaces and their implementations.

Clearly, there's still a lot of work to do. There are lots of datasets that can be implemented, tests to do, interfaces to define and implement and so on... Moreover, even the organization of the train.py and evaluate.py file can be improved, maybe creating an interface `TrainProcess` and it's specializations like `TrainClassifier`, `TrainRegressor`, ...

I'm looking for collaborators!",2,3
353,2017-2-12,2017,2,12,0,5tf9un,Need reviews regarding Yhat End-to-End Data Science Platform: Rodeo,https://www.reddit.com/r/MachineLearning/comments/5tf9un/need_reviews_regarding_yhat_endtoend_data_science/,datavinci,1486825678,,0,1
354,2017-2-12,2017,2,12,1,5tfpu1,Which Deep Learning framework to use?,https://www.reddit.com/r/MachineLearning/comments/5tfpu1/which_deep_learning_framework_to_use/,CognitiveRobot,1486829357,[removed],0,1
355,2017-2-12,2017,2,12,2,5tg1pk,[R] Deep learning and the Schrodinger equation,https://www.reddit.com/r/MachineLearning/comments/5tg1pk/r_deep_learning_and_the_schrodinger_equation/,downtownslim,1486832496,,35,81
356,2017-2-12,2017,2,12,2,5tg50b,"What's the difference between Machine Learning, Deep Learning and Artificial Intelligence?",https://www.reddit.com/r/MachineLearning/comments/5tg50b/whats_the_difference_between_machine_learning/,[deleted],1486833445,[removed],0,1
357,2017-2-12,2017,2,12,2,5tg77i,A simple Tensorflow based library for Deep autoencoder and denoising Auto Encoder,https://www.reddit.com/r/MachineLearning/comments/5tg77i/a_simple_tensorflow_based_library_for_deep/,rajarsheem,1486834076,,0,1
358,2017-2-12,2017,2,12,3,5tghek,Performance of Python's chainer in comparison to other frameworks (recent comparison),https://www.reddit.com/r/MachineLearning/comments/5tghek/performance_of_pythons_chainer_in_comparison_to/,DanielleMolloy,1486837143,,24,36
359,2017-2-12,2017,2,12,3,5tgmzt,Machine learning on other people's computers,https://www.reddit.com/r/MachineLearning/comments/5tgmzt/machine_learning_on_other_peoples_computers/,festlv,1486838554,,1,1
360,2017-2-12,2017,2,12,4,5tgw17,[D] RTRL on modern hardware: is the quartic complexity of RTRL still prohibitive?,https://www.reddit.com/r/MachineLearning/comments/5tgw17/d_rtrl_on_modern_hardware_is_the_quartic/,xristaforante,1486840827,I've been trudging through a lot of old material from the late 80s to the early 2000s. All of them say that RTRL is difficult to scale because of the O( n^4 ) weight update complexity per timestep. Is this still prohibitive for anything useful given modern GPU hardware? Has any recent work explored it?,16,5
361,2017-2-12,2017,2,12,4,5th31p,[D] Recommendation for Multitask GAN papers?,https://www.reddit.com/r/MachineLearning/comments/5th31p/d_recommendation_for_multitask_gan_papers/,RiseAgainstDLTyranny,1486842430,"Trying to find papers how to train a single GAN to handle several different but related tasks simultaneously at once, but with no fruit. The closest thing I found related is this one:

https://arxiv.org/abs/1606.07536

But my requirement is actually different. The architecture I am looking for can be best described as a conditional GAN, that takes in the same input, but depends on the some external attributes(conditional variables), to approximate a different target. The G/D are potentially shared across different tasks.

Any help is welcome!",4,5
362,2017-2-12,2017,2,12,4,5th4op,Felix Wichmann: Computational models of vision: From early vision to deep convolutional neural networks (Redwood Center talk by Prof. Felix Wichmann),https://www.reddit.com/r/MachineLearning/comments/5th4op/felix_wichmann_computational_models_of_vision/,[deleted],1486842904,[deleted],0,1
363,2017-2-12,2017,2,12,4,5th4un,Computational models of vision: From early vision to deep convolutional neural networks (Redwood Center talk by Prof. Felix Wichmann),https://www.reddit.com/r/MachineLearning/comments/5th4un/computational_models_of_vision_from_early_vision/,[deleted],1486842958,[deleted],0,1
364,2017-2-12,2017,2,12,6,5thoj0,Best books for introducing machine learning,https://www.reddit.com/r/MachineLearning/comments/5thoj0/best_books_for_introducing_machine_learning/,laneLazerBeamz,1486848911,[removed],0,1
365,2017-2-12,2017,2,12,6,5thrh7,So you want to compile dlib on your mac?,https://www.reddit.com/r/MachineLearning/comments/5thrh7/so_you_want_to_compile_dlib_on_your_mac/,thewhizz,1486849835,[removed],0,1
366,2017-2-12,2017,2,12,7,5ti4bz,[D] Saving weights in Theano,https://www.reddit.com/r/MachineLearning/comments/5ti4bz/d_saving_weights_in_theano/,davikrehalt,1486853841,"Right now, I use pickle to save my weights for theano neural nets, but is something like hdf5 better? Does anyone have any good advice?",2,0
367,2017-2-12,2017,2,12,10,5tiz03,Question: machine learning and software development,https://www.reddit.com/r/MachineLearning/comments/5tiz03/question_machine_learning_and_software_development/,andrzejkrzywda,1486864428,[removed],0,1
368,2017-2-12,2017,2,12,12,5tjhpe,Neural Photo Editing with Introspective Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/5tjhpe/neural_photo_editing_with_introspective/,finallyifoundvalidUN,1486871742,[removed],0,1
369,2017-2-12,2017,2,12,15,5tk5y7,Inside-Outside and Forward-Backward Algorithms Are Just Backprop [PDF link],https://www.reddit.com/r/MachineLearning/comments/5tk5y7/insideoutside_and_forwardbackward_algorithms_are/,muktabh,1486882519,,0,1
370,2017-2-12,2017,2,12,17,5tkdlx,How the Naive Bayes Classifier works in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5tkdlx/how_the_naive_bayes_classifier_works_in_machine/,codyowl,1486886812,,0,1
371,2017-2-12,2017,2,12,19,5tktzx,Is it possible to learn arbitrary convolution?,https://www.reddit.com/r/MachineLearning/comments/5tktzx/is_it_possible_to_learn_arbitrary_convolution/,kh40tika,1486897080,[removed],0,1
372,2017-2-12,2017,2,12,20,5tkyh0,"[P] Lecture notes, videos and exercises+solutions from Prof. Laurenz Wiskott",https://www.reddit.com/r/MachineLearning/comments/5tkyh0/p_lecture_notes_videos_and_exercisessolutions/,MLmuchAmaze,1486899745,,1,105
373,2017-2-12,2017,2,12,21,5tl5hf,Theano implementation of subpixel convolution,https://www.reddit.com/r/MachineLearning/comments/5tl5hf/theano_implementation_of_subpixel_convolution/,[deleted],1486902929,[removed],0,1
374,2017-2-12,2017,2,12,21,5tl5rz,[D] Subpixel convolution in Theano,https://www.reddit.com/r/MachineLearning/comments/5tl5rz/d_subpixel_convolution_in_theano/,davikrehalt,1486903040,"Does any of you know of an existing implementation of subpixel convolution in theano similar to https://github.com/Tetrachrome/subpixel ? I could simply rewrite it but obviously if it exists that will save me a little bit of effort, thanks",3,5
375,2017-2-12,2017,2,12,22,5tlbij,Putting words in other people's mouths,https://www.reddit.com/r/MachineLearning/comments/5tlbij/putting_words_in_other_peoples_mouths/,swingpants,1486904818,[removed],0,1
376,2017-2-12,2017,2,12,22,5tlicz,[D] How to employ Attention mechanism in CNN-based sequence models?,https://www.reddit.com/r/MachineLearning/comments/5tlicz/d_how_to_employ_attention_mechanism_in_cnnbased/,mujjingun,1486907615,"In models like [Language Modeling with Gated Convolutional Networks](https://arxiv.org/abs/1612.08083), [Wavenet](https://arxiv.org/abs/1609.03499) PixelCNN, etc, where they use CNNs instead of RNN to model sequences, how would I go about implementing an Attention mechanism? I couldn't find any papers which achieved this. A straightforward implementation would take too much memory for any sane computer, since a tensor of size 

    (batch, seq A length, A channels, seq B length, B channels)

is needed, when you're aligning sequence A to B.

Any ideas please.",3,9
377,2017-2-13,2017,2,13,0,5tlzq5,Horror Game VS Actively Learning Deep Neural Network,https://www.reddit.com/r/MachineLearning/comments/5tlzq5/horror_game_vs_actively_learning_deep_neural/,JonoExplainsThings,1486914147,,0,1
378,2017-2-13,2017,2,13,1,5tmbi9,[P] PHP Google Natural Language Client,https://www.reddit.com/r/MachineLearning/comments/5tmbi9/p_php_google_natural_language_client/,worldwidewunicorn,1486917600,,9,1
379,2017-2-13,2017,2,13,1,5tme9c,MSU Professor publicly accuses Stanford Professor Fei-Fei Li of plagiarism,https://www.reddit.com/r/MachineLearning/comments/5tme9c/msu_professor_publicly_accuses_stanford_professor/,[deleted],1486918328,[deleted],0,1
380,2017-2-13,2017,2,13,1,5tmehb,[D] MSU Professor publicly accuses Stanford Professor Fei-Fei Li of plagiarism,https://www.reddit.com/r/MachineLearning/comments/5tmehb/d_msu_professor_publicly_accuses_stanford/,____BOLD____,1486918385,,30,5
381,2017-2-13,2017,2,13,2,5tmjb7,[P] Facebook's machine learning @scale conference including videos,https://www.reddit.com/r/MachineLearning/comments/5tmjb7/p_facebooks_machine_learning_scale_conference/,working_nut,1486919577,,0,43
382,2017-2-13,2017,2,13,5,5tnvr0,[P]Duplicate Question Detection with Deep Learning on Quora,https://www.reddit.com/r/MachineLearning/comments/5tnvr0/pduplicate_question_detection_with_deep_learning/,erogol,1486930715,,7,48
383,2017-2-13,2017,2,13,5,5to5qs,"When using deep learning should derived data be used, or should we force the net to learn to derive it?",https://www.reddit.com/r/MachineLearning/comments/5to5qs/when_using_deep_learning_should_derived_data_be/,barnyardman,1486933123,[removed],0,1
384,2017-2-13,2017,2,13,6,5tof1z,Extracting feature sequences from xgboost models,https://www.reddit.com/r/MachineLearning/comments/5tof1z/extracting_feature_sequences_from_xgboost_models/,tacomahi,1486935250,,0,1
385,2017-2-13,2017,2,13,7,5topfs,Who has already test and match Prevision.io ?,https://www.reddit.com/r/MachineLearning/comments/5topfs/who_has_already_test_and_match_previsionio/,laurencebtnyc,1486937489,[removed],0,1
386,2017-2-13,2017,2,13,8,5tp4sa,List of some open datasets for machine learning,https://www.reddit.com/r/MachineLearning/comments/5tp4sa/list_of_some_open_datasets_for_machine_learning/,tonylstewart,1486940950,,0,3
387,2017-2-13,2017,2,13,8,5tp9ko,Trump and GANs,https://www.reddit.com/r/MachineLearning/comments/5tp9ko/trump_and_gans/,scionaura,1486942065,[removed],0,1
388,2017-2-13,2017,2,13,8,5tphl1,"Using machine learning to auto-colorize ""L'Arroseur arros"", the first comedy film (1895)",https://www.reddit.com/r/MachineLearning/comments/5tphl1/using_machine_learning_to_autocolorize_larroseur/,Berpj,1486943998,,0,1
389,2017-2-13,2017,2,13,10,5tq4hi,"Anyone familiar with ""Text To Image Synthesis Using Thought Vectors""?(Link in description). Can someone explain the role of the encoder here?",https://www.reddit.com/r/MachineLearning/comments/5tq4hi/anyone_familiar_with_text_to_image_synthesis/,trollinginmyskin,1486950422,link- https://github.com/paarthneekhara/text-to-image,3,5
390,2017-2-13,2017,2,13,11,5tq7op,Is the 'encoder-decoder' in the sense of RNN for machine translation the same as Autoencoders?,https://www.reddit.com/r/MachineLearning/comments/5tq7op/is_the_encoderdecoder_in_the_sense_of_rnn_for/,trollinginmyskin,1486951464,[removed],0,1
391,2017-2-13,2017,2,13,11,5tqcfb,[P] Adversarial Attacks on Neural Network Policies by Huang et al. 2017,https://www.reddit.com/r/MachineLearning/comments/5tqcfb/p_adversarial_attacks_on_neural_network_policies/,liftordie101,1486953088,,1,4
392,2017-2-13,2017,2,13,11,5tqf7n,I thought it would be a breakthrough on bandit research from AAAI2017... ...,https://www.reddit.com/r/MachineLearning/comments/5tqf7n/i_thought_it_would_be_a_breakthrough_on_bandit/,[deleted],1486954001,[removed],0,1
393,2017-2-13,2017,2,13,12,5tqil6,"[D] Tom Mikolov on word2vec and AI research at Microsoft, Google, Facebook",https://www.reddit.com/r/MachineLearning/comments/5tqil6/d_tom_mikolov_on_word2vec_and_ai_research_at/,ma2rten,1486955145,,0,44
394,2017-2-13,2017,2,13,12,5tqk4m,Undergraduates/Graduates/Postdocs: What happens in a machine learning lab?,https://www.reddit.com/r/MachineLearning/comments/5tqk4m/undergraduatesgraduatespostdocs_what_happens_in_a/,spuriousdunlin,1486955701,[removed],0,1
395,2017-2-13,2017,2,13,12,5tqm8p,I thought it would be a breakthrough on bandit research from AAAI2017... ...,https://www.reddit.com/r/MachineLearning/comments/5tqm8p/i_thought_it_would_be_a_breakthrough_on_bandit/,[deleted],1486956443,[removed],0,1
396,2017-2-13,2017,2,13,12,5tqn9l,"Informed choices through Machine Learning  Analyzing Kohli, Tendulkar and Dravid",https://www.reddit.com/r/MachineLearning/comments/5tqn9l/informed_choices_through_machine_learning/,tvganesh,1486956811,,0,1
397,2017-2-13,2017,2,13,12,5tqrb3,"""[Discussion]"", ""[Research]"" I thought it would be a breakthrough on linear bandit research from AAAI 2017... ...",https://www.reddit.com/r/MachineLearning/comments/5tqrb3/discussion_research_i_thought_it_would_be_a/,[deleted],1486958272,[deleted],0,1
398,2017-2-13,2017,2,13,13,5tqt6l,"""[Research]"" I thought this AAAI 2017 paper would be a breakthrough on linear bandit research, but ... ...",https://www.reddit.com/r/MachineLearning/comments/5tqt6l/research_i_thought_this_aaai_2017_paper_would_be/,[deleted],1486958962,[deleted],12,15
399,2017-2-13,2017,2,13,13,5tr0cd,[R] Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models,https://www.reddit.com/r/MachineLearning/comments/5tr0cd/r_batch_renormalization_towards_reducing/,downtownslim,1486961433,,22,45
400,2017-2-13,2017,2,13,15,5trbpb,"How does grouping words in classes, speed things up? (For trigram models or NN models)",https://www.reddit.com/r/MachineLearning/comments/5trbpb/how_does_grouping_words_in_classes_speed_things/,aknirala,1486965867,[removed],1,1
401,2017-2-13,2017,2,13,15,5tre9v,Twitter hopes machine learning can save it from oblivion,https://www.reddit.com/r/MachineLearning/comments/5tre9v/twitter_hopes_machine_learning_can_save_it_from/,jonfla,1486966971,,0,1
402,2017-2-13,2017,2,13,15,5treru,[P] A TensorFlow Implementation of Character Level Neural Machine Translation Using the Quasi-RNN,https://www.reddit.com/r/MachineLearning/comments/5treru/p_a_tensorflow_implementation_of_character_level/,longinglove,1486967192,,18,40
403,2017-2-13,2017,2,13,16,5trkpc,Tensorflow question: how to get better parallelism?,https://www.reddit.com/r/MachineLearning/comments/5trkpc/tensorflow_question_how_to_get_better_parallelism/,omniron,1486970006,[removed],0,1
404,2017-2-13,2017,2,13,16,5trns5,What is the state of the art (SotA) in ASR?,https://www.reddit.com/r/MachineLearning/comments/5trns5/what_is_the_state_of_the_art_sota_in_asr/,[deleted],1486971524,[removed],0,1
405,2017-2-13,2017,2,13,16,5trnum,[N] A Goldman Sachs MD quit for a 12 month residency at Google,https://www.reddit.com/r/MachineLearning/comments/5trnum/n_a_goldman_sachs_md_quit_for_a_12_month/,[deleted],1486971558,[deleted],0,1
406,2017-2-13,2017,2,13,17,5trs40,Perl interface for MXNet ML lib,https://www.reddit.com/r/MachineLearning/comments/5trs40/perl_interface_for_mxnet_ml_lib/,sergeykolychev,1486973788,[removed],0,1
407,2017-2-13,2017,2,13,18,5trxim,Computers Being Trained To Predict The Outcome of Acute Diseases,https://www.reddit.com/r/MachineLearning/comments/5trxim/computers_being_trained_to_predict_the_outcome_of/,digitalmarketingrobi,1486976773,,0,1
408,2017-2-13,2017,2,13,18,5ts027,Find relation between data using regression,https://www.reddit.com/r/MachineLearning/comments/5ts027/find_relation_between_data_using_regression/,mihir_sampat,1486978229,"I was told it was called data-mapping. I want to use regression to find out a relation between two persons' data. For example, if the person A and person B are going to the same location, and working for the same company, staying at the same address then high chances they can be partners and relatives at the same time. At the same time if the person A and person B are working at the company with the same salary but staying at a different location, high chances, they are just working colleagues. This is just a vague example and any machine learning approach will be appreciated.",1,2
409,2017-2-13,2017,2,13,19,5ts66j,I need some starting points for my research in machine learning algoritms,https://www.reddit.com/r/MachineLearning/comments/5ts66j/i_need_some_starting_points_for_my_research_in/,k0enf0rNL,1486981491,[removed],0,1
410,2017-2-13,2017,2,13,19,5ts6mz,Real scope of top tier ML conferences and Journals,https://www.reddit.com/r/MachineLearning/comments/5ts6mz/real_scope_of_top_tier_ml_conferences_and_journals/,insider_7,1486981752,[removed],1,1
411,2017-2-13,2017,2,13,19,5ts6ut,"Women in Tech: Interview with Nandini Stocker, Google's Conversation Design Lead - discussing ML, HCI, NLP &amp; more)",https://www.reddit.com/r/MachineLearning/comments/5ts6ut/women_in_tech_interview_with_nandini_stocker/,reworksophie,1486981861,,0,1
412,2017-2-13,2017,2,13,19,5ts913,"Before you build another machine-learning startup, read this",https://www.reddit.com/r/MachineLearning/comments/5ts913/before_you_build_another_machinelearning_startup/,AvatarNemo,1486983061,,0,1
413,2017-2-13,2017,2,13,19,5ts9nz,[R] A Deterministic and Generalized Framework for Unsupervised Learning with Restricted Boltzmann Machines,https://www.reddit.com/r/MachineLearning/comments/5ts9nz/r_a_deterministic_and_generalized_framework_for/,Fujikan,1486983393,,9,16
414,2017-2-13,2017,2,13,20,5tsgcl,The most dangerous AI (Political bias in artificial intelligence algorithms),https://www.reddit.com/r/MachineLearning/comments/5tsgcl/the_most_dangerous_ai_political_bias_in/,BadGoyWithAGun,1486986704,,0,1
415,2017-2-13,2017,2,13,21,5tsj2n,50 things I learned at NIPS 2016,https://www.reddit.com/r/MachineLearning/comments/5tsj2n/50_things_i_learned_at_nips_2016/,linuxjava,1486987942,,0,1
416,2017-2-13,2017,2,13,23,5tt9cz,[Discussion] Machine Learning - WAYR (What Are You Reading) - Week 19,https://www.reddit.com/r/MachineLearning/comments/5tt9cz/discussion_machine_learning_wayr_what_are_you/,Mandrathax,1486997674,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

|Previous weeks|
|--------------|
|[Week 1](https://www.reddit.com/r/MachineLearning/comments/4qyjiq/machine_learning_wayr_what_are_you_reading_week_1/)|
|[Week 2](https://www.reddit.com/r/MachineLearning/comments/4s2xqm/machine_learning_wayr_what_are_you_reading_week_2/)|
|[Week 3](https://www.reddit.com/r/MachineLearning/comments/4t7mqm/machine_learning_wayr_what_are_you_reading_week_3/)|
|[Week 4](https://www.reddit.com/r/MachineLearning/comments/4ub2kw/machine_learning_wayr_what_are_you_reading_week_4/)|
|[Week 5](https://www.reddit.com/r/MachineLearning/comments/4xomf7/machine_learning_wayr_what_are_you_reading_week_5/)|
|[Week 6](https://www.reddit.com/r/MachineLearning/comments/4zcyvk/machine_learning_wayr_what_are_you_reading_week_6/)|
|[Week 7](https://www.reddit.com/r/MachineLearning/comments/52t6mo/machine_learning_wayr_what_are_you_reading_week_7/)|
|[Week 8](https://www.reddit.com/r/MachineLearning/comments/53heol/machine_learning_wayr_what_are_you_reading_week_8/)|
|[Week 9](https://www.reddit.com/r/MachineLearning/comments/54kvsu/machine_learning_wayr_what_are_you_reading_week_9/)|
|[Week 10](https://www.reddit.com/r/MachineLearning/comments/56s2oa/discussion_machine_learning_wayr_what_are_you/)|
|[Week 11](https://www.reddit.com/r/MachineLearning/comments/57xw56/discussion_machine_learning_wayr_what_are_you/)|
|[Week 12](https://www.reddit.com/r/MachineLearning/comments/5acb1t/d_machine_learning_wayr_what_are_you_reading_week/)|
|[Week 13](https://www.reddit.com/r/MachineLearning/comments/5cwfb6/d_machine_learning_wayr_what_are_you_reading_week/)|
|[Week 14](https://www.reddit.com/r/MachineLearning/comments/5fc5mh/d_machine_learning_wayr_what_are_you_reading_week/)|
|[Week 15](https://www.reddit.com/r/MachineLearning/comments/5hy4ur/d_machine_learning_wayr_what_are_you_reading_week/)|
|[Week 16](https://www.reddit.com/r/MachineLearning/comments/5kd6vd/d_machine_learning_wayr_what_are_you_reading_week/)|
|[Week 17](https://www.reddit.com/r/MachineLearning/comments/5ob7dx/discussion_machine_learning_wayr_what_are_you/)|
|[Week 18](https://www.reddit.com/r/MachineLearning/comments/5r14yd/discussion_machine_learning_wayr_what_are_you/)|

Most upvoted paper last week :

[""Why Should I Trust You?"": Explaining the Predictions of Any Classifier](https://arxiv.org/abs/1602.04938)

[Simple Reinforcement Learning with Tensorflow Part 0: Q-Learning with Tables and Neural Networks](https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0#.qum3iavz2)

Besides that, there are no rules, have fun.
",30,57
417,2017-2-14,2017,2,14,0,5ttdbw,Solving the quantum many-body problem with artificial neural networks,https://www.reddit.com/r/MachineLearning/comments/5ttdbw/solving_the_quantum_manybody_problem_with/,[deleted],1486998926,[deleted],0,1
418,2017-2-14,2017,2,14,1,5ttqap,[P] Minimal tutorials for PyTorch,https://www.reddit.com/r/MachineLearning/comments/5ttqap/p_minimal_tutorials_for_pytorch/,vkhuc,1487002577,,3,36
419,2017-2-14,2017,2,14,1,5ttx6b,Test errors increasing with number of epochs in Stochastic Gradient Descent,https://www.reddit.com/r/MachineLearning/comments/5ttx6b/test_errors_increasing_with_number_of_epochs_in/,data_sagan,1487004471,[removed],0,1
420,2017-2-14,2017,2,14,2,5tu50x,Tensorflow implementation of End-to-End Memory Networks for language modelling,https://www.reddit.com/r/MachineLearning/comments/5tu50x/tensorflow_implementation_of_endtoend_memory/,abhaikollara,1487006505,,0,1
421,2017-2-14,2017,2,14,3,5tue6k,Why biotechnology does not need yet another disruptive startup.,https://www.reddit.com/r/MachineLearning/comments/5tue6k/why_biotechnology_does_not_need_yet_another/,alpine_photo,1487008937,,0,1
422,2017-2-14,2017,2,14,3,5tuh9w,10 things marketers need to know about AI,https://www.reddit.com/r/MachineLearning/comments/5tuh9w/10_things_marketers_need_to_know_about_ai/,AvatarNemo,1487009725,,0,1
423,2017-2-14,2017,2,14,3,5tumml,Granular Forecasting Troubles [/r/cross-posted to statistics],https://www.reddit.com/r/MachineLearning/comments/5tumml/granular_forecasting_troubles_rcrossposted_to/,craftingfish,1487011169,[removed],0,1
424,2017-2-14,2017,2,14,4,5turnw,Is making data binary required?,https://www.reddit.com/r/MachineLearning/comments/5turnw/is_making_data_binary_required/,DataWithTea,1487012539,[removed],0,1
425,2017-2-14,2017,2,14,4,5tusc3,Making Sense of Data @KareemAlkaseer @MentorLycon,https://www.reddit.com/r/MachineLearning/comments/5tusc3/making_sense_of_data_kareemalkaseer_mentorlycon/,kalkaseer,1487012713,,0,1
426,2017-2-14,2017,2,14,4,5tux62,"Quantiacs.com is Driving the ""3rd Wave"" of Hedge Funds -- Wired Article",https://www.reddit.com/r/MachineLearning/comments/5tux62/quantiacscom_is_driving_the_3rd_wave_of_hedge/,brinkwar,1487013987,,1,1
427,2017-2-14,2017,2,14,4,5tv13u,Open Sourcing TensorFlowOnSpark: Distributed Deep Learning on Big-Data Clusters,https://www.reddit.com/r/MachineLearning/comments/5tv13u/open_sourcing_tensorflowonspark_distributed_deep/,hiteck,1487015029,,1,1
428,2017-2-14,2017,2,14,5,5tvev8,Turn your laptop into a Deep Learning BEAST,https://www.reddit.com/r/MachineLearning/comments/5tvev8/turn_your_laptop_into_a_deep_learning_beast/,danimex,1487018732,,0,1
429,2017-2-14,2017,2,14,5,5tvgeb,[P] Tensorflow implementation of Wasserstein GAN,https://www.reddit.com/r/MachineLearning/comments/5tvgeb/p_tensorflow_implementation_of_wasserstein_gan/,charlie0_o,1487019153,,28,18
430,2017-2-14,2017,2,14,5,5tvh82,Deep text-pair classification with Quora's 2017 question dataset,https://www.reddit.com/r/MachineLearning/comments/5tvh82/deep_textpair_classification_with_quoras_2017/,elyase,1487019371,,0,1
431,2017-2-14,2017,2,14,6,5tvm6a,ML in Contextual Linguistics project,https://www.reddit.com/r/MachineLearning/comments/5tvm6a/ml_in_contextual_linguistics_project/,backstabbersk,1487020696,[removed],0,1
432,2017-2-14,2017,2,14,6,5tvupt,Is this an improper use of K-means Clustering and/or Hierarchical Clustering?,https://www.reddit.com/r/MachineLearning/comments/5tvupt/is_this_an_improper_use_of_kmeans_clustering/,TashanValiant,1487022867,[removed],0,1
433,2017-2-14,2017,2,14,8,5twew4,Google Test Of AI's Killer Instinct Shows We Should Be Very Careful,https://www.reddit.com/r/MachineLearning/comments/5twew4/google_test_of_ais_killer_instinct_shows_we/,eggn00dles,1487028419,,0,1
434,2017-2-14,2017,2,14,9,5twnhv,[D] How early is too early to put work on ArXiv?,https://www.reddit.com/r/MachineLearning/comments/5twnhv/d_how_early_is_too_early_to_put_work_on_arxiv/,zergylord,1487030862,"I've been developing a new deep-learning algorithm, but don't have any results yet. I've seen a couple people, even from reputable labs like Google Brain and DeepMind, post new research to ArXiv without any results, but it definitely isn't the norm. I don't know how I feel about these ""flag planting"" articles. On the one hand, some new approaches are well motivated enough to be interesting in their own right. But with the absolute glut of deep learning papers coming out, its hard enough to separate the wheat from the chaff without having to consider benchmark-less papers. Is there any community consensus on this?",20,15
435,2017-2-14,2017,2,14,10,5tx17q,[D] New podcast on ML basics,https://www.reddit.com/r/MachineLearning/comments/5tx17q/d_new_podcast_on_ml_basics/,lefnire,1487034680,"I'm creating a podcast - [Machine Learning Guide](http://ocdevel.com/podcasts/machine-learning) - on the basics of ML. Audio is an inferior medium to task - but with so much chores/commute/exercise time, there's _hours_ every day one could spend learning - so count this supplementary. I aim to be super high-level and 101, so this is for newbies and unconfidents. 

One goal of the podcast is to be a syllabus, where in each episode I recommend ""required readings"" resources - books/textbooks/courses/etc that I've boiled down from the most common recommendations from around the web. So anyone asking ""which maths should I learn? which textbooks would you recommend? which language is best?"" - this is for you.

Hope y'all find it useful, tell me if it's crap!

[Edit] feed URL: http://ocdevel.com/files/podcasts/machine-learning/feed.xml",30,188
436,2017-2-14,2017,2,14,10,5tx9bq,We Need to Go Deeper: A Practical Guide to Tensorflow and Inception  Initialized Capital,https://www.reddit.com/r/MachineLearning/comments/5tx9bq/we_need_to_go_deeper_a_practical_guide_to/,vincechu,1487037205,,1,1
437,2017-2-14,2017,2,14,11,5txjxu,Sam Altman Funded a Deep Learning Audio Venture With 2 Physicist Founders at Ycombinator,https://www.reddit.com/r/MachineLearning/comments/5txjxu/sam_altman_funded_a_deep_learning_audio_venture/,alirezasmr,1487040608,,0,1
438,2017-2-14,2017,2,14,12,5txtxt,Mark Cuban on Why You Need to Study Artificial Intelligence or Youll be a Dinosaur in 3 Years,https://www.reddit.com/r/MachineLearning/comments/5txtxt/mark_cuban_on_why_you_need_to_study_artificial/,onlyAlgos,1487043837,,0,1
439,2017-2-14,2017,2,14,12,5txwmi,Automating High-Frequency Trading Price Change Forecast using Machine Learning Techniques,https://www.reddit.com/r/MachineLearning/comments/5txwmi/automating_highfrequency_trading_price_change/,[deleted],1487044744,[deleted],0,1
440,2017-2-14,2017,2,14,13,5ty5cc,Oxford Deep NLP Course practicals are on Github,https://www.reddit.com/r/MachineLearning/comments/5ty5cc/oxford_deep_nlp_course_practicals_are_on_github/,[deleted],1487047548,[deleted],0,1
441,2017-2-14,2017,2,14,14,5tyac8,Titan X fair price?,https://www.reddit.com/r/MachineLearning/comments/5tyac8/titan_x_fair_price/,canttouchmypingas,1487049270,[removed],0,1
442,2017-2-14,2017,2,14,14,5tybxv,SpatialConvolution in Torch- Trouble getting input shape right,https://www.reddit.com/r/MachineLearning/comments/5tybxv/spatialconvolution_in_torch_trouble_getting_input/,trollinginmyskin,1487049841,[removed],0,1
443,2017-2-14,2017,2,14,14,5tyg08,ML experiments,https://www.reddit.com/r/MachineLearning/comments/5tyg08/ml_experiments/,blah-who,1487051322,[removed],0,1
444,2017-2-14,2017,2,14,17,5tz5y9,[R] Solving the quantum many-body problem with artificial neural networks,https://www.reddit.com/r/MachineLearning/comments/5tz5y9/r_solving_the_quantum_manybody_problem_with/,dhpt,1487062496,,3,26
445,2017-2-14,2017,2,14,18,5tz8hf,[N] The future of artificial intellicence,https://www.reddit.com/r/MachineLearning/comments/5tz8hf/n_the_future_of_artificial_intellicence/,Sergiointelnics,1487063760,,3,0
446,2017-2-14,2017,2,14,18,5tzc12,The Data Stack - Download the most complete overview of the data centric landscape. - Liip Blog,https://www.reddit.com/r/MachineLearning/comments/5tzc12/the_data_stack_download_the_most_complete/,plotti,1487065524,,0,1
447,2017-2-14,2017,2,14,19,5tzdxo,Complex-valued Gaussian Process Regression for Time Series Analysis: A new twist to an old story,https://www.reddit.com/r/MachineLearning/comments/5tzdxo/complexvalued_gaussian_process_regression_for/,LucaAmbrogioni,1487066498,,0,2
448,2017-2-14,2017,2,14,19,5tzjxc,Pump up your Data Analytic skills with Machine Learning and Big Data,https://www.reddit.com/r/MachineLearning/comments/5tzjxc/pump_up_your_data_analytic_skills_with_machine/,excellentwebworld54,1487069326,,0,1
449,2017-2-14,2017,2,14,20,5tzls8,Why I get negative Information Gain?,https://www.reddit.com/r/MachineLearning/comments/5tzls8/why_i_get_negative_information_gain/,KingNothing90,1487070151,,0,1
450,2017-2-14,2017,2,14,20,5tzo2v,[D] What is the current state of the art for making use of unlabeled data?,https://www.reddit.com/r/MachineLearning/comments/5tzo2v/d_what_is_the_current_state_of_the_art_for_making/,me_irl_wont_upvote,1487071230,"Hey, in my example I have 4000 unlabelled features and  500    labelled ones (Bag of words,  specifically)  and   a neural network that is classifying  those labelled examples. What is the current method for making use of that unlabeled   data? 

I'm aware of auto-encoders, but I'm sure there are plenty of other methods  that      I'm missing out on.
",25,17
451,2017-2-14,2017,2,14,21,5tzxwe,[N] CNTK + kinect v2 facial pattern classification with ResNet50,https://www.reddit.com/r/MachineLearning/comments/5tzxwe/n_cntk_kinect_v2_facial_pattern_classification/,pmfcdb,1487075629,,0,7
452,2017-2-14,2017,2,14,22,5u09iu,Startup Gamalon gives AI bots a head start without Google-level resources.,https://www.reddit.com/r/MachineLearning/comments/5u09iu/startup_gamalon_gives_ai_bots_a_head_start/,tmarkovich,1487079879,,1,1
453,2017-2-14,2017,2,14,22,5u0au6,"[D] What are some good / accepted libraries or techniques for multi-input, multi-output regression?",https://www.reddit.com/r/MachineLearning/comments/5u0au6/d_what_are_some_good_accepted_libraries_or/,[deleted],1487080349,[deleted],2,1
454,2017-2-14,2017,2,14,23,5u0epg,[Discussion] P40 GPU for deep learning,https://www.reddit.com/r/MachineLearning/comments/5u0epg/discussion_p40_gpu_for_deep_learning/,marvMind,1487081646,"Hi everyone,
we want to get new GPUs for our lab. We are currently considering whether we should go for P40 or P100. The specs of the P40 look pretty good for deep learning. Unfortunately the P40 only offers ""single precision computation"". We are slightly concerned with this. Does this mean that many deep learning libraries will not be able to run? Will this restrict our model building capability in any way? We need to be able to reproduce training results, without modifying source designed for double-precision GPUs. Is this possible?

",5,1
455,2017-2-14,2017,2,14,23,5u0fc2,"While training RNN or seq2seq how do you tokenize the sentences. I mean do you use nltk or some hand made rules and does it matter? Also, do you use pretrained word2vec on say the entire web or do you use a embedding and train it with the model. Which one is better?",https://www.reddit.com/r/MachineLearning/comments/5u0fc2/while_training_rnn_or_seq2seq_how_do_you_tokenize/,cvikasreddy,1487081855,[removed],0,1
456,2017-2-14,2017,2,14,23,5u0lk5,[D] Training a Q-learning Agent by playing against itself,https://www.reddit.com/r/MachineLearning/comments/5u0lk5/d_training_a_qlearning_agent_by_playing_against/,bastardOfYoung94,1487083917,"Hey all,

I'm working on a RL project and haven't been able to find a good answer to this question. Let's say I want to train a Q-learning Agent to play chess (as an example game), but rather than train it on data from historical chess matches, I want it to learn by playing against itself. I understand I can create 2 instances of my Agent and have them duke it out. My question is, during the training phase, is there a way to combine their learning, so that I could eventually have a single Agent play against a human? Or, do I simply just pick 1 set of weights to save and use that in the ""live"" version?

Thanks in advance",8,5
457,2017-2-15,2017,2,15,0,5u0o2k,[D] Are GANs learning the proper probability mass of modes?,https://www.reddit.com/r/MachineLearning/comments/5u0o2k/d_are_gans_learning_the_proper_probability_mass/,debau,1487084699,"Does anyone have practical insights in whether or not GANs tend to learn the correct 'height' or probability mass associated to a mode? I know of the theoretical results but I'm more interested in practical experience.

What I mean is the following: Assume MNIST has a skewed data distribution and 5 occurs 50% of the time and every other number occurs 50/9%. Will GANs then produce 50% of 5's?

My intuition tells me that that might not be the case due to the nature of SGD. SGD will make samples more similar and run them into a local minima but not necessarily distribute the samples according to the actual probability mass associated with a mode.",4,6
458,2017-2-15,2017,2,15,0,5u0r9w,Classification with 3-D position data,https://www.reddit.com/r/MachineLearning/comments/5u0r9w/classification_with_3d_position_data/,josdari,1487085618,[removed],0,1
459,2017-2-15,2017,2,15,0,5u0tb0,Did I just mess up my vision by staring at Gabor-like filters for too long?,https://www.reddit.com/r/MachineLearning/comments/5u0tb0/did_i_just_mess_up_my_vision_by_staring_at/,MMN_,1487086207,[removed],0,1
460,2017-2-15,2017,2,15,0,5u0u5i,the sampling mechanism for generate training samples from limited number of images with large size,https://www.reddit.com/r/MachineLearning/comments/5u0u5i/the_sampling_mechanism_for_generate_training/,wenouyang,1487086434,[removed],0,1
461,2017-2-15,2017,2,15,0,5u0wza,"[N] AI software writes, and rewrites, its own code, getting smarter as it does",https://www.reddit.com/r/MachineLearning/comments/5u0wza/n_ai_software_writes_and_rewrites_its_own_code/,tmarkovich,1487087250,,7,1
462,2017-2-15,2017,2,15,1,5u19w7,"New AI (AGI) paradigm for predicting future state of arbitrary state-space, named after Feynman.",https://www.reddit.com/r/MachineLearning/comments/5u19w7/new_ai_agi_paradigm_for_predicting_future_state/,funkbf,1487090740,,0,1
463,2017-2-15,2017,2,15,1,5u1asn,[R] [Redwood Center] Founder Amir Khosrowshahi talks about origins of Nervana Systems,https://www.reddit.com/r/MachineLearning/comments/5u1asn/r_redwood_center_founder_amir_khosrowshahi_talks/,choleskyde,1487090965,,3,8
464,2017-2-15,2017,2,15,3,5u1s93,[N] Startup Schools Machine Learning | EE Times,https://www.reddit.com/r/MachineLearning/comments/5u1s93/n_startup_schools_machine_learning_ee_times/,darkconfidantislife,1487095360,,6,9
465,2017-2-15,2017,2,15,4,5u295q,Generate ConvNet Figure,https://www.reddit.com/r/MachineLearning/comments/5u295q/generate_convnet_figure/,dataOR,1487099364,[removed],0,1
466,2017-2-15,2017,2,15,4,5u2am8,[Discussion]Machine Learning research labs in Europe,https://www.reddit.com/r/MachineLearning/comments/5u2am8/discussionmachine_learning_research_labs_in_europe/,bronzestick,1487099650,"What are some of the good machine learning research labs based in Europe? Also, do they mainly hire from European universities or do they actively hire from US universities as well?",19,49
467,2017-2-15,2017,2,15,4,5u2aq2,Avery23,https://www.reddit.com/r/MachineLearning/comments/5u2aq2/avery23/,Aidanlighha,1487099670,,0,1
468,2017-2-15,2017,2,15,4,5u2g1i,"Question: Single object detection, Keras.",https://www.reddit.com/r/MachineLearning/comments/5u2g1i/question_single_object_detection_keras/,powisss,1487100940,[removed],0,1
469,2017-2-15,2017,2,15,4,5u2gu9,[D] What are acceptance rates for top workshops?,https://www.reddit.com/r/MachineLearning/comments/5u2gu9/d_what_are_acceptance_rates_for_top_workshops/,sprintletecity,1487101148,"Statistics for conference papers seem readily available, but workshop paper statistics seem harder to find - could someone fill me in?",3,4
470,2017-2-15,2017,2,15,4,5u2hoc,[R] Ian Goodfellow of openAI on GANs,https://www.reddit.com/r/MachineLearning/comments/5u2hoc/r_ian_goodfellow_of_openai_on_gans/,tony_sf,1487101358,,1,10
471,2017-2-15,2017,2,15,4,5u2kdq,[Redwood Center] Computational models of vision: From early vision to Deep ConvNets (F. Wichmann),https://www.reddit.com/r/MachineLearning/comments/5u2kdq/redwood_center_computational_models_of_vision/,DanielleMolloy,1487102076,,2,8
472,2017-2-15,2017,2,15,5,5u2o9c,"[R] Why do skip connections in ResNets skip 2 convolutional layers, and not 1?",https://www.reddit.com/r/MachineLearning/comments/5u2o9c/r_why_do_skip_connections_in_resnets_skip_2/,[deleted],1487103089,[deleted],0,1
473,2017-2-15,2017,2,15,5,5u2p6o,AI vs AI - Will They Fight or Cooperate?,https://www.reddit.com/r/MachineLearning/comments/5u2p6o/ai_vs_ai_will_they_fight_or_cooperate/,[deleted],1487103328,[deleted],0,1
474,2017-2-15,2017,2,15,5,5u2vls,Top 100 Deep Learning Papers (2012~2016),https://www.reddit.com/r/MachineLearning/comments/5u2vls/top_100_deep_learning_papers_20122016/,[deleted],1487105089,[deleted],0,1
475,2017-2-15,2017,2,15,5,5u2wb9,[D] Leading in ML research among big industrial players (Quora),https://www.reddit.com/r/MachineLearning/comments/5u2wb9/d_leading_in_ml_research_among_big_industrial/,inarrears,1487105275,,5,29
476,2017-2-15,2017,2,15,5,5u2xst,drive.ai Rainy Night Autonomous Drive,https://www.reddit.com/r/MachineLearning/comments/5u2xst/driveai_rainy_night_autonomous_drive/,code_kansas,1487105679,,1,1
477,2017-2-15,2017,2,15,6,5u300v,Top 100 Deep Learning Papers (2012~2016),https://www.reddit.com/r/MachineLearning/comments/5u300v/top_100_deep_learning_papers_20122016/,[deleted],1487106271,[deleted],0,1
478,2017-2-15,2017,2,15,6,5u341a,[D] Hello. Need advice for AI-Demo.,https://www.reddit.com/r/MachineLearning/comments/5u341a/d_hello_need_advice_for_aidemo/,Zahand,1487107368,"Hello.
So the university I am studying at is opening a ""Centre for Artificial Intelligence Research"" and I my teacher who is the leader for this gave me the roll of presenting some cool demos for the opening.
I thought of maybe creating a Kahoot-quiz where the questions are poems, and the user needs to decide if it was a human or a machine that wrote it.
Do you guys have any other cool interactive demos for AI?
Thanks in advance!",5,5
479,2017-2-15,2017,2,15,6,5u373s,[D] Needs your opinions to choose top 100 deep learning papers from 2012 to 2016,https://www.reddit.com/r/MachineLearning/comments/5u373s/d_needs_your_opinions_to_choose_top_100_deep/,[deleted],1487108186,[deleted],0,2
480,2017-2-15,2017,2,15,6,5u37t4,[R] Most-cited 100 Deep Learning Papers (2012~2016),https://www.reddit.com/r/MachineLearning/comments/5u37t4/r_mostcited_100_deep_learning_papers_20122016/,terryum,1487108366,,29,159
481,2017-2-15,2017,2,15,7,5u3hev,[P] YAD2K: Convert Darknet YOLO_v2 Object Detection Models to a Keras (+ Tensorflow) Implementation,https://www.reddit.com/r/MachineLearning/comments/5u3hev/p_yad2k_convert_darknet_yolo_v2_object_detection/,allanzelener,1487110952,,6,13
482,2017-2-15,2017,2,15,9,5u44sz,A high school student's science fair project on automated cancer detection using deep learning. Where can he improve on his paper?,https://www.reddit.com/r/MachineLearning/comments/5u44sz/a_high_school_students_science_fair_project_on/,TuringsEgo,1487117831,,1,1
483,2017-2-15,2017,2,15,9,5u46l4,[D] Reference request for NNs,https://www.reddit.com/r/MachineLearning/comments/5u46l4/d_reference_request_for_nns/,[deleted],1487118369,[deleted],3,0
484,2017-2-15,2017,2,15,9,5u4b47,Collaboration between an object detection algorithm and an object recognition algorithm ?,https://www.reddit.com/r/MachineLearning/comments/5u4b47/collaboration_between_an_object_detection/,jm-mp,1487119815,[removed],0,1
485,2017-2-15,2017,2,15,10,5u4h3b,[D] Timbre (audio) perception with neural networks,https://www.reddit.com/r/MachineLearning/comments/5u4h3b/d_timbre_audio_perception_with_neural_networks/,pytt3,1487121738,"I've been working on this for a while but I can't get the performance anywhere near human level. Is anyone here working in this area? Have you been more successful, and if so how?

My most successful approach to this problem looks as follows.

Training data:
44.1kHz, 16-bit, mono audio

Input:
65-3500Hz spectrogram with a 4096 FT window size, 40ms step, and a logarithmic scale for the amplitudes. Rather than having the amplitudes in the value dimension I have created a new third dimension with 15 elements that holds the amplitudes. The value dimension is unused and contains only 0 or 1. The reason for moving the amplitudes from the value dimension is that I think the filters/neurons have poor expressive power on that dimension.

Normalization is done per spectrum rather than over the entire spectrogram to make it easier to detect amplitude patterns over frequencies (but harder over time).

Layer 1:
360ms long filters that are moved only along the time axis. ReLU activation function. The thinking is that these filters will extract the timbre features. More layers can be added on top of this one to catch temporal features.

Optimizer: tensorflow.train.AdamOptimizer(1e-4)

I'm working with voice separation/fingerprinting from short (2.5s) voice samples which requires good timbre (and pitch) perception. The human performance on this task ~98% success rate and I'm only getting a 53.3% success rate with the approach described above. By scaling up the network and adding more training data I could probably get the success rate up to around 70% but that's still nowhere near human performance.

A detailed description of my project, code, training data, and trained networks can be found at the link below.

http://pytt3.blogspot.se/2016/12/better-voice-recognition.html

Update 20170303:

I have rewritten pretty much everything in my project except the audio perception parts (the blog post have been updated) and the results have improved a bit. I now have a success rate of 94.6% on the training data and 80.7% on the test data. At the link below you can see the network labeling previously unheard voices. Still nowhere near human performance, but maybe it is reachable with some upscaling.

https://www.youtube.com/watch?v=PrJVVgNKeyM",17,4
486,2017-2-15,2017,2,15,15,5u5ygb,"[Data] Spanner, the Google Database That Mastered Time, Is Now Open to Everyone",https://www.reddit.com/r/MachineLearning/comments/5u5ygb/data_spanner_the_google_database_that_mastered/,NarendhiranS,1487141600,,0,1
487,2017-2-15,2017,2,15,16,5u61kt,Creating a color recommender system,https://www.reddit.com/r/MachineLearning/comments/5u61kt/creating_a_color_recommender_system/,rahulkulhalli,1487143087,[removed],0,1
488,2017-2-15,2017,2,15,16,5u64uu,[D] VAE Optimization Objective,https://www.reddit.com/r/MachineLearning/comments/5u64uu/d_vae_optimization_objective/,bge0,1487144729,"I'm a little confused as to the VAE optimization objective.
These two blogs list them differently:

  1) https://jmetzen.github.io/2015-11-27/vae.html

  2) https://jaan.io/what-is-variational-autoencoder-vae-tutorial/

1. states the following [and has positive losses]:

            reconstr_loss = \
            -tf.reduce_sum(self.x * tf.log(1e-10 + self.x_reconstr_mean)
                           + (1-self.x) * tf.log(1e-10 + 1 - self.x_reconstr_mean),
                           1)
        # 2.) The latent loss, which is defined as the Kullback Leibler divergence 
        ##    between the distribution in latent space induced by the encoder on 
        #     the data and some prior. This acts as a kind of regularizer.
        #     This can be interpreted as the number of ""nats"" required
        #     for transmitting the the latent space distribution given
        #     the prior.
        latent_loss = -0.5 * tf.reduce_sum(1 + self.z_log_sigma_sq 
                                           - tf.square(self.z_mean) 
                                           - tf.exp(self.z_log_sigma_sq), 1)
        self.cost = tf.reduce_mean(reconstr_loss + latent_loss)

2. has errors that go from negative error --&gt; positive : i.e. maximization. 

        prior_predictive_inp = distributions.Bernoulli(logits=p_x_given_z_logits)
        prior_predictive_inp_sample = prior_predictive_inp.sample()

        # Build the evidence lower bound (ELBO) or the negative loss
        kl = tf.reduce_sum(distributions.kl(q_z.distribution, p_z), 1)
        expected_log_likelihood = tf.reduce_sum(p_x_given_z.log_pmf(x),
                           [1, 2, 3])
        elbo = tf.reduce_sum(expected_log_likelihood - kl, 0)
        optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001)
        train_op = optimizer.minimize(-elbo)




Which one of the two is correct?

If I worked it out correctly then the ELBO that we maximize is:

    log p(x) - KL[ Q(Z | X) || P(Z | X) ] = E_{z ~ Q(Z | X)} [log p(x|z)] - KL [ Q(Z | X) || P(Z) ] 

Since we cant compute `- KL[ Q(Z | X) || P(Z | X) ] ` we drop it expecting it to be ~0 and work with the RHS. Since we want to maximize the log likelihood we would equivalently minimize the negative log likelihood:

    max { log p(x) } = min { -log p(x) }= min { - E_{z ~ Q(Z | X)} [log p(x|z)] + KL [ Q(Z | X) || P(Z) ]  }

So should we be seeing a minimization of the KL term and a maximization of the expectation? thus if the error is dominated by the reconstruction process then the total error should be negative most of the time?",9,3
489,2017-2-15,2017,2,15,18,5u6gf6,"Code for our WWW'17 short paper titled - ""Deep Learning for Hate Speech Detection"".",https://www.reddit.com/r/MachineLearning/comments/5u6gf6/code_for_our_www17_short_paper_titled_deep/,shash273,1487150962,,0,1
490,2017-2-15,2017,2,15,18,5u6jak,"What is the General AI Challenge? New competition launching today, interview with the Director here ($50k prize)",https://www.reddit.com/r/MachineLearning/comments/5u6jak/what_is_the_general_ai_challenge_new_competition/,reworksophie,1487152423,,0,1
491,2017-2-15,2017,2,15,21,5u740y,How to do machine learning without data scientists,https://www.reddit.com/r/MachineLearning/comments/5u740y/how_to_do_machine_learning_without_data_scientists/,Johnmack013,1487162465,,0,1
492,2017-2-15,2017,2,15,21,5u74bn,Alat Berat Terbesar di Dunia  Crawler Crane Terbesar Di Dunia,https://www.reddit.com/r/MachineLearning/comments/5u74bn/alat_berat_terbesar_di_dunia__crawler_crane/,edukidz,1487162590,,0,1
493,2017-2-15,2017,2,15,22,5u79ej,Need help selecting hardware for training convolutional neural networks.,https://www.reddit.com/r/MachineLearning/comments/5u79ej/need_help_selecting_hardware_for_training/,EatMyPossum,1487164432,"Hi Machine learning! 
I'm tasked with looking at the options for buying hardware to train convolutional neural networks. I'm a software developer in a research department at a hospital, and my ML experience starts at a ML course in my master and using an optimiser for my thesis, and ends with me reading [Stanford CS class CS231n: Convolutional Neural Networks for Visual Recognition.](http://cs231n.github.io/). As for selecting hardware experience: I bought a not-of-the-shelf-gaming-computer about 10 years ago.
I have come across these very helpfull blogposts of [Tim Dettmers](http://timdettmers.com/2015/03/09/deep-learning-hardware-guide/) and [Roelof Pieters](http://graphific.github.io/posts/building-a-deep-learning-dream-machine/), and with these I made several profiles for options, ranging from cheap to expensive. I want to present this to my not very tech-savy boss in clear numbers (performance factor), for easy comparison, just like Tim Dettmers did [here](http://timdettmers.com/2014/08/14/which-gpu-for-deep-learning/) (Titan X Pascal = 0.7 GTX 1080 = 0.55 GTX 1070 (...)). Currently I have this:

Name|Price|perf.|perf/price
:--|:--|:--|:--|
NVIDIA DGX-1|130000|25|0.192
4x titan X|8300|1|0.120
2x tital X|4900|0.55|0.112
4x 1070|3500|0.5|0.142
2x 1070|2200|0.27|0.122k
1x 1070|1700|0.14|0.082
buy a gpu|200|?|?
Current state|0|?|--

The performance estimates of the titan X and GT 1070 systems are based on Tims numbers, but i have trouble estimating a comparison to the current system. The rest of the hardware of the systems is compatible with the cards given tims and roelofs guidelines, and take an i7 and i5 processor respectively. Currently we own several year old [dell optiplex 9020 minitower](http://i.dell.com/sites/doccontent/shared-content/data-sheets/en/Documents/Dell-OptiPlex-9020-spec-sheet_Final_V2_G13001038.pdf) (notably, 1x 16pin PCIe 1, 12GB ram, 4th gen i5 cpu).

Some other details that might be relevant maybe. Well be using 3d CT data (grayscaled) of bones, dimensions are of the order 50x50x250, probably / maybe we'll process these as images. We have about 100 to 200 of these images, but data augmentation is planned. The plan is to use Theano with Lasagna, since involved people have experience with this.

Given this, I have several questions 1) How much better will the current system perform training convolutional neural networks after I add a GPU, 2) What kind of gpu will I be looking at? and 2) How will this system, including the gpu, compare performance wise, to any other system in my list?, assuming that the GPU is the computational bottleneck here. Any other remarks or suggestions are very welcome too.

Thanks in advance",14,0
494,2017-2-15,2017,2,15,22,5u7h3l,[R] Compressing NN with Shannon's blessing,https://www.reddit.com/r/MachineLearning/comments/5u7h3l/r_compressing_nn_with_shannons_blessing/,KarenUllrich,1487166969,"Soft Weight-Sharing for Neural Network Compression 
is now on arxiv and a tutorial code is available as well. This paper has been accepted to ICLR2017.

https://arxiv.org/abs/1702.04008
https://github.com/KarenUllrich/Tutorial-SoftWeightSharingForNNCompression/blob/master/tutorial.ipynb",12,48
495,2017-2-15,2017,2,15,23,5u7l8f,[R] Microsoft/AirSim: Open source simulator based on Unreal Engine for autonomous vehicles,https://www.reddit.com/r/MachineLearning/comments/5u7l8f/r_microsoftairsim_open_source_simulator_based_on/,a_endurance,1487168127,,16,140
496,2017-2-15,2017,2,15,23,5u7t0y,[P] A tensorflow implementation of Convolutional Neural Networks for Sentence Classification,https://www.reddit.com/r/MachineLearning/comments/5u7t0y/p_a_tensorflow_implementation_of_convolutional/,abhaikollara,1487170208,,0,4
497,2017-2-16,2017,2,16,0,5u878n,"Simple Questions Thread February 15, 2017",https://www.reddit.com/r/MachineLearning/comments/5u878n/simple_questions_thread_february_15_2017/,AutoModerator,1487173957,[removed],0,1
498,2017-2-16,2017,2,16,1,5u8aba,[D] What are some ways to structure unstructured data like the one mentioned by [Gammalon](https://gamalon.com/)?,https://www.reddit.com/r/MachineLearning/comments/5u8aba/d_what_are_some_ways_to_structure_unstructured/,mln00b13,1487174729,"Apart from their approach, what are some other ways to achieve the same thing? Basically, to tag unstructured text.",2,2
499,2017-2-16,2017,2,16,1,5u8aj3,[R] Loss-Sensitive Generative Adversarial Networks on Lipschitz Densities,https://www.reddit.com/r/MachineLearning/comments/5u8aj3/r_losssensitive_generative_adversarial_networks/,downtownslim,1487174780,,17,15
500,2017-2-16,2017,2,16,1,5u8gah,[Webinar]: Machine Learning in a Live Production Environment,https://www.reddit.com/r/MachineLearning/comments/5u8gah/webinar_machine_learning_in_a_live_production/,NarendhiranS,1487176081,,0,1
501,2017-2-16,2017,2,16,2,5u8r57,[N] IBM wants to bring machine learning to the mainframe,https://www.reddit.com/r/MachineLearning/comments/5u8r57/n_ibm_wants_to_bring_machine_learning_to_the/,DrinkMoreCodeMore,1487178619,,0,3
502,2017-2-16,2017,2,16,2,5u8w4n,ModelDB by mitdbg,https://www.reddit.com/r/MachineLearning/comments/5u8w4n/modeldb_by_mitdbg/,improbabble,1487179885,,1,1
503,2017-2-16,2017,2,16,2,5u8x8b,Machine Learning Daily,https://www.reddit.com/r/MachineLearning/comments/5u8x8b/machine_learning_daily/,quantguy1,1487180170,,0,1
504,2017-2-16,2017,2,16,3,5u94rk,How to visualize gates of LSTM for time-series data?,https://www.reddit.com/r/MachineLearning/comments/5u94rk/how_to_visualize_gates_of_lstm_for_timeseries_data/,starsmiling,1487182105,[removed],0,1
505,2017-2-16,2017,2,16,3,5u95vv,Is anyone else in the Udacity AI Nanodegree program starting April?,https://www.reddit.com/r/MachineLearning/comments/5u95vv/is_anyone_else_in_the_udacity_ai_nanodegree/,jarins,1487182378,[removed],0,2
506,2017-2-16,2017,2,16,3,5u97f4,Google releases TensorFlow 1.0 with new machine learning tools,https://www.reddit.com/r/MachineLearning/comments/5u97f4/google_releases_tensorflow_10_with_new_machine/,513,1487182755,,0,1
507,2017-2-16,2017,2,16,3,5u9a3i,TensorFlow Dev Summit Live,https://www.reddit.com/r/MachineLearning/comments/5u9a3i/tensorflow_dev_summit_live/,code2hell,1487183450,,0,1
508,2017-2-16,2017,2,16,3,5u9gal,Recognize a signature,https://www.reddit.com/r/MachineLearning/comments/5u9gal/recognize_a_signature/,gbanister,1487185028,[removed],0,1
509,2017-2-16,2017,2,16,4,5u9jd7,TensorFlow 1.0 just got announced at the TensorFlow Dev Summit. Here is the livestream.,https://www.reddit.com/r/MachineLearning/comments/5u9jd7/tensorflow_10_just_got_announced_at_the/,[deleted],1487185813,[deleted],0,1
510,2017-2-16,2017,2,16,4,5u9k2k,Need C++ implementation of LSTM prediction,https://www.reddit.com/r/MachineLearning/comments/5u9k2k/need_c_implementation_of_lstm_prediction/,BrokenGumdrop,1487185994,[removed],0,1
511,2017-2-16,2017,2,16,4,5u9kzh,[N] Tensorflow Dev Summit 2017 is live on youtube,https://www.reddit.com/r/MachineLearning/comments/5u9kzh/n_tensorflow_dev_summit_2017_is_live_on_youtube/,07Zulrah,1487186233,,11,96
512,2017-2-16,2017,2,16,4,5u9l7j,[D] Machine Learning Research Labs in Latin America,https://www.reddit.com/r/MachineLearning/comments/5u9l7j/d_machine_learning_research_labs_in_latin_america/,PokerPirate,1487186290,"What are some of the good labs/researchers in Latin America?  

Are they mostly university labs, or are there companies doing cool researchy ML?

How easy is it for foreigners to work on ML research there?

---

This is a spinoff of the similarly titled [Machine Learning Research Labs in Europe](https://www.reddit.com/r/MachineLearning/comments/5u2am8/discussionmachine_learning_research_labs_in_europe/) post.",9,4
513,2017-2-16,2017,2,16,4,5u9lsr,[D] What algorithm should I use for background subtraction in 1080p videos with dynamic backgrounds?,https://www.reddit.com/r/MachineLearning/comments/5u9lsr/d_what_algorithm_should_i_use_for_background/,iamiamwhoami,1487186445,"I'm working with videos of aquarium pools with animals swimming in them. I don't think MOG will work because of the motion of the water and varying reflection of the light. This algorithm seems [promising](http://dl.acm.org/citation.cfm?id=2654914), but since it's a fully connected network high def images require too much memory. Any suggestions?",11,2
514,2017-2-16,2017,2,16,4,5u9ncw,[R] Language Understanding and Reasoning with Memory Augmented Neural Nets (slides),https://www.reddit.com/r/MachineLearning/comments/5u9ncw/r_language_understanding_and_reasoning_with/,tsendsuren,1487186853,,2,12
515,2017-2-16,2017,2,16,4,5u9nqr,State of the art on Transfer Learning?,https://www.reddit.com/r/MachineLearning/comments/5u9nqr/state_of_the_art_on_transfer_learning/,mearco,1487186955,[removed],0,1
516,2017-2-16,2017,2,16,4,5u9pnx,Do you have to be smart to do machine learning?,https://www.reddit.com/r/MachineLearning/comments/5u9pnx/do_you_have_to_be_smart_to_do_machine_learning/,hmkw,1487187437,[removed],0,1
517,2017-2-16,2017,2,16,4,5u9slp,What do you guys think about Ethical AI? Do you think we need to rethink on our current approaches to AI?,https://www.reddit.com/r/MachineLearning/comments/5u9slp/what_do_you_guys_think_about_ethical_ai_do_you/,churma,1487188199,,0,1
518,2017-2-16,2017,2,16,5,5u9vo2,[N] TensorFlow 1.0 Release,https://www.reddit.com/r/MachineLearning/comments/5u9vo2/n_tensorflow_10_release/,whateverr123,1487188993,,41,209
519,2017-2-16,2017,2,16,5,5u9zsq,Building Principal Component Analysis from Scratch (Live Stream),https://www.reddit.com/r/MachineLearning/comments/5u9zsq/building_principal_component_analysis_from/,llSourcell,1487190102,,1,1
520,2017-2-16,2017,2,16,5,5ua7j7,I wrote a ML program to write code and here is its output,https://www.reddit.com/r/MachineLearning/comments/5ua7j7/i_wrote_a_ml_program_to_write_code_and_here_is/,cammonks,1487192203,,0,1
521,2017-2-16,2017,2,16,6,5ua8mk,Google Cloud &amp; YouTube-8M Video Understanding Challenge,https://www.reddit.com/r/MachineLearning/comments/5ua8mk/google_cloud_youtube8m_video_understanding/,krallistic,1487192483,,0,1
522,2017-2-16,2017,2,16,6,5uai77,Getting Started with Deep Learning -- a review of tools,https://www.reddit.com/r/MachineLearning/comments/5uai77/getting_started_with_deep_learning_a_review_of/,tom-svds,1487195003,,1,3
523,2017-2-16,2017,2,16,7,5uaovm,[D] Visualization of AI 'brain scan' - what happens during a machine learning process,https://www.reddit.com/r/MachineLearning/comments/5uaovm/d_visualization_of_ai_brain_scan_what_happens/,Dim25,1487196823,,9,15
524,2017-2-16,2017,2,16,7,5uap9s,"Microsoft shares open source system for training drones, other gadgets to move safely on their own - Next at Microsoft",https://www.reddit.com/r/MachineLearning/comments/5uap9s/microsoft_shares_open_source_system_for_training/,interseption,1487196930,,0,1
525,2017-2-16,2017,2,16,7,5uarjx,"An updated YouTube-8M dataset, a video understanding challenge, and a CVPR workshop. Oh my!",https://www.reddit.com/r/MachineLearning/comments/5uarjx/an_updated_youtube8m_dataset_a_video/,huberloss,1487197547,,0,2
526,2017-2-16,2017,2,16,7,5uay4v,Chemistry named entity recognition,https://www.reddit.com/r/MachineLearning/comments/5uay4v/chemistry_named_entity_recognition/,niujin,1487199406,[removed],0,1
527,2017-2-16,2017,2,16,14,5ucwch,[D] Machine learning research labs in the Indian subcontinent,https://www.reddit.com/r/MachineLearning/comments/5ucwch/d_machine_learning_research_labs_in_the_indian/,buy_some_wow,1487222029,"Following the trend of ""ML labs in X"". What are the universities/industry labs that do ML research in the Indian subcontinent? Do they have internship openings for masters/undergrad students? Do they hire foreigners?",6,9
528,2017-2-16,2017,2,16,16,5udh70,Learn Magento 2 Basic Course,https://www.reddit.com/r/MachineLearning/comments/5udh70/learn_magento_2_basic_course/,ciuciupinpin,1487230882,,0,1
529,2017-2-16,2017,2,16,18,5udqnb,[P] Let's make an A3C: Theory - Introduction into Policy Gradient Methods,https://www.reddit.com/r/MachineLearning/comments/5udqnb/p_lets_make_an_a3c_theory_introduction_into/,jaromiru,1487235778,,9,18
530,2017-2-16,2017,2,16,18,5udw5t,"Watch how Google's starving DeepMind AI turns hostile, attacks other bots to survive",https://www.reddit.com/r/MachineLearning/comments/5udw5t/watch_how_googles_starving_deepmind_ai_turns/,[deleted],1487238554,[deleted],0,1
531,2017-2-16,2017,2,16,18,5udwc2,"[N] Watch how Google's starving DeepMind AI turns hostile, attacks other bots to survive",https://www.reddit.com/r/MachineLearning/comments/5udwc2/n_watch_how_googles_starving_deepmind_ai_turns/,[deleted],1487238636,[deleted],0,0
532,2017-2-16,2017,2,16,19,5udz9w,Components and implementations of Natural Language Processing,https://www.reddit.com/r/MachineLearning/comments/5udz9w/components_and_implementations_of_natural/,NarendhiranS,1487239967,,0,2
533,2017-2-16,2017,2,16,20,5ue79f,"Google's TensorFlow hits v1.0 with upgrades to speed, flexibility, and production-readiness",https://www.reddit.com/r/MachineLearning/comments/5ue79f/googles_tensorflow_hits_v10_with_upgrades_to/,NarendhiranS,1487243456,,0,1
534,2017-2-16,2017,2,16,20,5ued2i,Free and good Internet sex dating with many girls. My real story for you guys,https://www.reddit.com/r/MachineLearning/comments/5ued2i/free_and_good_internet_sex_dating_with_many_girls/,Emersontalve,1487245685,[removed],0,1
535,2017-2-16,2017,2,16,22,5uf16t,[D] PELU more prone to overfitting than ELU? How to regularize?,https://www.reddit.com/r/MachineLearning/comments/5uf16t/d_pelu_more_prone_to_overfitting_than_elu_how_to/,[deleted],1487253170,[deleted],0,1
536,2017-2-16,2017,2,16,22,5uf2bl,How to cluster concepts in an ontology(owl file) using apache jena ?,https://www.reddit.com/r/MachineLearning/comments/5uf2bl/how_to_cluster_concepts_in_an_ontologyowl_file/,sakhis,1487253527,[removed],0,1
537,2017-2-17,2017,2,17,0,5ufh0m,[D] Distribution of weights of trained Neural Network,https://www.reddit.com/r/MachineLearning/comments/5ufh0m/d_distribution_of_weights_of_trained_neural/,Vladimir_Koshel,1487257505,"Whether does the distribution of weights of well regularized neural network tend to be normal? I think that it is.
The more distribution is normal, the less overfitting contains, the more NN has generalizing ability.

I googled it, but results seem to me not to modern or they have restricted access.

Excuse me, if it is simple question.",7,5
538,2017-2-17,2017,2,17,1,5ug52w,[D] Machine Learning Research Labs in Antarctica,https://www.reddit.com/r/MachineLearning/comments/5ug52w/d_machine_learning_research_labs_in_antarctica/,dirtybird04,1487263469,[removed],11,27
539,2017-2-17,2017,2,17,1,5ug84o,"[D] Join us today Feb 16 at 7pm PST for a live stream event with Intel, IBM, NVIDIA and KnuEdge discussing processing hardware for accelerated deep learning. More information on our Meetup page, ML Society.",https://www.reddit.com/r/MachineLearning/comments/5ug84o/d_join_us_today_feb_16_at_7pm_pst_for_a_live/,JustOneMoreStat,1487264283,,0,2
540,2017-2-17,2017,2,17,3,5ugv4y,Instructions to get jupyter notebook working on HPC systems with GPUs by forwarding ports dynamically. [OC],https://www.reddit.com/r/MachineLearning/comments/5ugv4y/instructions_to_get_jupyter_notebook_working_on/,ieee8023,1487269881,,0,1
541,2017-2-17,2017,2,17,3,5uh1bx,[P] Feel The Kern - Generating proportional fonts with deep learning (code on Github),https://www.reddit.com/r/MachineLearning/comments/5uh1bx/p_feel_the_kern_generating_proportional_fonts/,g_patrick,1487271445,,8,99
542,2017-2-17,2017,2,17,4,5uh2zv,Is attacking machine learning easier than defending it?,https://www.reddit.com/r/MachineLearning/comments/5uh2zv/is_attacking_machine_learning_easier_than/,Digital10,1487271870,,0,1
543,2017-2-17,2017,2,17,4,5uh9kk,[D] Batch Normalization on an Input Layer,https://www.reddit.com/r/MachineLearning/comments/5uh9kk/d_batch_normalization_on_an_input_layer/,bluemellophone,1487273603,"I am trying to figure out what the theoretical implications and practical pros/cons would be for adding a batch normalization layer *directly* after an input layer in a DCNN.

The best DCNNs from years past perform a centering and normalization step on input images by subtracting either 1.) a mean image map, 2.) a mean channel vector, or 3.) a mean pixel value.  These normalizations on the input data have been shown (Wiesler &amp; Ney) to help converge faster and was the driving insight behind performing this normalization at each layer of the network.  Instead of pre-computing the mean and variance for each layer across an entire dataset, batch normalization approximates this by learning these values from seeing the mini-batches during training.

This is at the heart of my question: why perform dataset centering and normalization when batch normalization is designed for exactly this purpose?  Will batch normalization learn the ideal mean and variance values for the image dataset without having to pre-compute it or guess what the optimal value would be?

It can be a pain to pre-compute and carry around these additional centering and normalization values, why not integrate them directly into the model and learn them from scratch?  At the very least, why not simply initialize the input batch normalization layer from these pre-computed mean and variances and let back-propagation tease out the optimal value?",17,14
544,2017-2-17,2017,2,17,5,5uhim8,Deep learning + uplift random forest to predict benefit in a large clinical trial.,https://www.reddit.com/r/MachineLearning/comments/5uhim8/deep_learning_uplift_random_forest_to_predict/,[deleted],1487276007,[deleted],0,1
545,2017-2-17,2017,2,17,5,5uhnkv,Attacking machine learning with adversarial examples,https://www.reddit.com/r/MachineLearning/comments/5uhnkv/attacking_machine_learning_with_adversarial/,gwulfs,1487277265,,0,2
546,2017-2-17,2017,2,17,6,5ui358,Messing with gradients,https://www.reddit.com/r/MachineLearning/comments/5ui358/messing_with_gradients/,AsIAm,1487281401,[removed],0,1
547,2017-2-17,2017,2,17,7,5ui8h1,Can I do it myself?,https://www.reddit.com/r/MachineLearning/comments/5ui8h1/can_i_do_it_myself/,orenog,1487282815,[removed],0,1
548,2017-2-17,2017,2,17,7,5ui8h3,Chinas Artificial-Intelligence Boom,https://www.reddit.com/r/MachineLearning/comments/5ui8h3/chinas_artificialintelligence_boom/,[deleted],1487282815,[deleted],0,1
549,2017-2-17,2017,2,17,7,5uiabd,Is it possible for me?,https://www.reddit.com/r/MachineLearning/comments/5uiabd/is_it_possible_for_me/,orenog,1487283311,[removed],0,0
550,2017-2-17,2017,2,17,7,5uibet,Is it possible for me?,https://www.reddit.com/r/MachineLearning/comments/5uibet/is_it_possible_for_me/,orenog,1487283630,[removed],0,1
551,2017-2-17,2017,2,17,7,5uicbk,Is there an overview of the state of the art of various NLP tasks?,https://www.reddit.com/r/MachineLearning/comments/5uicbk/is_there_an_overview_of_the_state_of_the_art_of/,rochea,1487283889,[removed],1,1
552,2017-2-17,2017,2,17,7,5uiel4,"Hello, Gradient Descent. A simple introduction to a great algorithm",https://www.reddit.com/r/MachineLearning/comments/5uiel4/hello_gradient_descent_a_simple_introduction_to_a/,scvalencia,1487284521,,0,1
553,2017-2-17,2017,2,17,7,5uifnm,"Adding constraints to Generative Adversarial Networks, e.g. no dogs with two heads",https://www.reddit.com/r/MachineLearning/comments/5uifnm/adding_constraints_to_generative_adversarial/,rafaelvalle,1487284835,[removed],0,1
554,2017-2-17,2017,2,17,11,5ujkrf,[R] [1702.04649] Generative Temporal Models with Memory,https://www.reddit.com/r/MachineLearning/comments/5ujkrf/r_170204649_generative_temporal_models_with_memory/,scionaura,1487297299,,9,38
555,2017-2-17,2017,2,17,11,5ujrhf,Classifying and Adding Adjustable Weights to Sensory Data Can Improve Deep Neural Net Outputs,https://www.reddit.com/r/MachineLearning/comments/5ujrhf/classifying_and_adding_adjustable_weights_to/,JonoExplainsThings,1487299614,,0,1
556,2017-2-17,2017,2,17,11,5ujt4g,How do I gather data on when someones mouth is moving in a youtube video?,https://www.reddit.com/r/MachineLearning/comments/5ujt4g/how_do_i_gather_data_on_when_someones_mouth_is/,_101010_,1487300206,[removed],0,1
557,2017-2-17,2017,2,17,12,5ujujn,Summer internships/courses/programmes?,https://www.reddit.com/r/MachineLearning/comments/5ujujn/summer_internshipscoursesprogrammes/,[deleted],1487300715,[removed],0,1
558,2017-2-17,2017,2,17,13,5uk7aw,im a robot,https://www.reddit.com/r/MachineLearning/comments/5uk7aw/im_a_robot/,fdsaass,1487305359,[removed],1,1
559,2017-2-17,2017,2,17,14,5ukdlq,YC / Andreessen Horowitz backed machine learning startup looking for machine learning engineer(or willing to learn),https://www.reddit.com/r/MachineLearning/comments/5ukdlq/yc_andreessen_horowitz_backed_machine_learning/,vike27,1487307924,[removed],0,1
560,2017-2-17,2017,2,17,14,5ukgic,[P] Embedding wikipedia with gensim,https://www.reddit.com/r/MachineLearning/comments/5ukgic/p_embedding_wikipedia_with_gensim/,richardweiss,1487309086,,5,3
561,2017-2-17,2017,2,17,14,5ukhd1,[R] [1606.01404] Generating Natural Language Inference Chains,https://www.reddit.com/r/MachineLearning/comments/5ukhd1/r_160601404_generating_natural_language_inference/,icosadev,1487309444,,1,6
562,2017-2-17,2017,2,17,14,5ukisg,Building Applications With Deep Learning: Expectations vs. Reality,https://www.reddit.com/r/MachineLearning/comments/5ukisg/building_applications_with_deep_learning/,mks_repi,1487310072,,0,1
563,2017-2-17,2017,2,17,14,5ukkov,Identifying features that most influences a specific outcome variable?,https://www.reddit.com/r/MachineLearning/comments/5ukkov/identifying_features_that_most_influences_a/,surangak,1487310947,[removed],0,1
564,2017-2-17,2017,2,17,14,5ukku8,RNN implementation that returns confidence/probability distributiom?,https://www.reddit.com/r/MachineLearning/comments/5ukku8/rnn_implementation_that_returns/,[deleted],1487311008,[removed],0,1
565,2017-2-17,2017,2,17,15,5uks6d,[D] github repository with simple implementation of machine learning algorithms?,https://www.reddit.com/r/MachineLearning/comments/5uks6d/d_github_repository_with_simple_implementation_of/,orange_robot338,1487314461,"preferably in python and from first principles (i.e. not using a ML framework at all).

I think i remember seeing this somewhere but I'm not sure. Also, a thorough google search didn't help me much here; too much noise it seems.",9,0
566,2017-2-17,2017,2,17,16,5ukvkq,[P] C# non-fixed topology neural network activations,https://www.reddit.com/r/MachineLearning/comments/5ukvkq/p_c_nonfixed_topology_neural_network_activations/,[deleted],1487316111,[deleted],0,1
567,2017-2-17,2017,2,17,16,5ukxwp,machine learning hackathon for medical. best classifer to use?,https://www.reddit.com/r/MachineLearning/comments/5ukxwp/machine_learning_hackathon_for_medical_best/,thedifficulty,1487317386,[removed],0,1
568,2017-2-17,2017,2,17,17,5ul2ao,[D] Tools to write LaTeX in Machine Learning community ?,https://www.reddit.com/r/MachineLearning/comments/5ul2ao/d_tools_to_write_latex_in_machine_learning/,xingdongrobotics,1487319752,"In machine learning community, which is the most recommended tool to write LaTeX for efficiency, under Ubuntu ?

1. SageMath Cloud:
   It seems this web platform can complile LaTeX with most packages included, the good thing is that it splits the window into two parts to simultaneously monitor the result PDF
  
2. VIM:
   It is very common tool for software developer, and is it actually recommended to write LaTeX ?

3. Others ? 

Preference to the tools that can have Tab-completion, simultaneous monitor to compiled PDF.",26,6
569,2017-2-17,2017,2,17,17,5ul3az,[D] Is anyone working on a NumPy to TensorFlow transpiler?,https://www.reddit.com/r/MachineLearning/comments/5ul3az/d_is_anyone_working_on_a_numpy_to_tensorflow/,carlthome,1487320328,"A lot of useful code is still written in NumPy (from when it was used together with scikitlearn), and for upscaling into production it would be neat to embed such logic directly into a TensorFlow graph. Is anyone working on a transpiler from NumPy operations to TensorFlow operations? There is surely a lot of code that would be hard to port automatically but a lot of the functions have really similar signatures (by design on TensorFlow's part).",13,8
570,2017-2-17,2017,2,17,18,5ul701,[N] CNTK FastRCNN CSEvalClient with Grocery,https://www.reddit.com/r/MachineLearning/comments/5ul701/n_cntk_fastrcnn_csevalclient_with_grocery/,pmfcdb,1487322448,,2,4
571,2017-2-17,2017,2,17,18,5ul7dy,[P] Creating photorealistic images with Tensorflow and a Gameboy Camera,https://www.reddit.com/r/MachineLearning/comments/5ul7dy/p_creating_photorealistic_images_with_tensorflow/,Dutchcheesehead,1487322681,,17,118
572,2017-2-17,2017,2,17,18,5ul7om,DeepMind just published a mind blowing paper: PathNet.,https://www.reddit.com/r/MachineLearning/comments/5ul7om/deepmind_just_published_a_mind_blowing_paper/,mks_repi,1487322854,,0,4
573,2017-2-17,2017,2,17,19,5ulf1e,Intuitive Linear Regression for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5ulf1e/intuitive_linear_regression_for_machine_learning/,kalkaseer,1487326592,,1,0
574,2017-2-17,2017,2,17,19,5ulf4n,Yahoo open-sources TensorFlowOnSpark for deep learning with big data,https://www.reddit.com/r/MachineLearning/comments/5ulf4n/yahoo_opensources_tensorflowonspark_for_deep/,cavedave,1487326640,,7,42
575,2017-2-17,2017,2,17,19,5ulj5a,Even Ashton Kutcher is using deep nets,https://www.reddit.com/r/MachineLearning/comments/5ulj5a/even_ashton_kutcher_is_using_deep_nets/,insider_7,1487328913,[removed],0,1
576,2017-2-17,2017,2,17,22,5um4z3,Deep learning Personas - Seq2seq chat with distinct personalities,https://www.reddit.com/r/MachineLearning/comments/5um4z3/deep_learning_personas_seq2seq_chat_with_distinct/,Thomjazz,1487338636,,0,1
577,2017-2-18,2017,2,18,0,5umlml,How does Bayesian Program Synthesis work?,https://www.reddit.com/r/MachineLearning/comments/5umlml/how_does_bayesian_program_synthesis_work/,ThisIsMySeudonym,1487344236,[removed],0,1
578,2017-2-18,2017,2,18,1,5umx68,Implement your own very basic Recommender System (Python),https://www.reddit.com/r/MachineLearning/comments/5umx68/implement_your_own_very_basic_recommender_system/,scvalencia,1487347679,,0,1
579,2017-2-18,2017,2,18,2,5unf5y,Is anyone interested in research on IBM's neurosynaptic computing?,https://www.reddit.com/r/MachineLearning/comments/5unf5y/is_anyone_interested_in_research_on_ibms/,ccc45p,1487352757,[removed],0,1
580,2017-2-18,2017,2,18,3,5unlcf,Research topic feasibility,https://www.reddit.com/r/MachineLearning/comments/5unlcf/research_topic_feasibility/,_murzeus_,1487354480,[removed],0,1
581,2017-2-18,2017,2,18,3,5unlmw,0/300,https://www.reddit.com/r/MachineLearning/comments/5unlmw/0300/,[deleted],1487354559,[deleted],0,1
582,2017-2-18,2017,2,18,3,5unrvx,This creepy tool reveals how Facebook tracks and studies your activity,https://www.reddit.com/r/MachineLearning/comments/5unrvx/this_creepy_tool_reveals_how_facebook_tracks_and/,juarezbarbosajunior,1487356296,,0,1
583,2017-2-18,2017,2,18,3,5unthk,"[P] Python users: I find visualization of results tedious and repetitive, so I built a small library to make it easier.",https://www.reddit.com/r/MachineLearning/comments/5unthk/p_python_users_i_find_visualization_of_results/,Reiinakano,1487356754,,23,303
584,2017-2-18,2017,2,18,3,5unwvs,[P] Spatial transformer networks in keras with Tensorflow backend.,https://www.reddit.com/r/MachineLearning/comments/5unwvs/p_spatial_transformer_networks_in_keras_with/,[deleted],1487357702,[deleted],0,1
585,2017-2-18,2017,2,18,4,5uo0wz,"""[P]"" Spatial transformer networks in keras with tensorflow backend.",https://www.reddit.com/r/MachineLearning/comments/5uo0wz/p_spatial_transformer_networks_in_keras_with/,[deleted],1487358832,[deleted],0,1
586,2017-2-18,2017,2,18,4,5uo6vk,[P] Spatial transformer networks in keras using tensorflow as backend.,https://www.reddit.com/r/MachineLearning/comments/5uo6vk/p_spatial_transformer_networks_in_keras_using/,oarriaga,1487360550,,3,7
587,2017-2-18,2017,2,18,4,5uo8xg,[D] how can I actually do it?,https://www.reddit.com/r/MachineLearning/comments/5uo8xg/d_how_can_i_actually_do_it/,orenog,1487361113,[removed],3,0
588,2017-2-18,2017,2,18,5,5uoauu,Learning how to walk - building a model of the motor control unit in the brain,https://www.reddit.com/r/MachineLearning/comments/5uoauu/learning_how_to_walk_building_a_model_of_the/,kidzik,1487361684,,0,1
589,2017-2-18,2017,2,18,5,5uod1s,Hello World Convolutional Machine Learning with Tensorflow,https://www.reddit.com/r/MachineLearning/comments/5uod1s/hello_world_convolutional_machine_learning_with/,ikteish,1487362313,,0,1
590,2017-2-18,2017,2,18,6,5uoxs5,ML with a modern AMD GPU possible yet?,https://www.reddit.com/r/MachineLearning/comments/5uoxs5/ml_with_a_modern_amd_gpu_possible_yet/,gururise,1487368336,[removed],0,1
591,2017-2-18,2017,2,18,7,5up63h,Word2Vec for bands?,https://www.reddit.com/r/MachineLearning/comments/5up63h/word2vec_for_bands/,Avcdo,1487370890,[removed],0,1
592,2017-2-18,2017,2,18,8,5upb8g,[P] Generative Adversarial Networks (GANs) in 50 lines of code (PyTorch),https://www.reddit.com/r/MachineLearning/comments/5upb8g/p_generative_adversarial_networks_gans_in_50/,alxndrkalinin,1487372512,,2,35
593,2017-2-18,2017,2,18,9,5uprmx,How to Make an Image Classifier - Intro to Deep Learning #6,https://www.reddit.com/r/MachineLearning/comments/5uprmx/how_to_make_an_image_classifier_intro_to_deep/,llSourcell,1487377858,,0,1
594,2017-2-18,2017,2,18,12,5uqh3g,Apply Pix2Pix Image translation in sketch to face using conditional generative adversarial network,https://www.reddit.com/r/MachineLearning/comments/5uqh3g/apply_pix2pix_image_translation_in_sketch_to_face/,[deleted],1487387293,[deleted],0,1
595,2017-2-18,2017,2,18,19,5urwxt,TensorFlow Dev Summit 2017,https://www.reddit.com/r/MachineLearning/comments/5urwxt/tensorflow_dev_summit_2017/,Mussem17,1487414136,,0,1
596,2017-2-18,2017,2,18,19,5urxpq,[D] Adaboost examples/questions,https://www.reddit.com/r/MachineLearning/comments/5urxpq/d_adaboost_examplesquestions/,drake7707,1487414677,"Hi, I created an adaboost implementation in javascript so I could better understand what happens. 
For simple examples where the weak classifiers can fit the actual training set correctly it will correctly converge to the desired result, but for more complex examples, such as true positives in a circle while only having linear weak classifiers it spirals out of control after a few iterations by focusing too heavily on certain samples in such a way that it starts to misclassify the parts that were once classified correctly.

You can see a demo here: https://drake7707.github.io/adaboost-example/ (might not work in all browsers due to the use of ES6 Promise but it does in Firefox and Chrome), you can find the full source code in a github repo if you're interested: https://github.com/drake7707/adaboost-example

While I understand that the quality of the weak classifiers is important (if there is no linear combination of classifiers that can get near the labelled training set it's impossible to solve). However I don't understand why it degrades after a number iterations. I remember reading the error rate should decrease exponentially until a minimum is reached, as is the case with the '2D - Random split with axis aligned classifiers' example, well at least until it 'overfits' on the sample weights.

Am I trying to solve certain examples that are impossible to solve with linear weak classifers with adaboost?




",6,1
597,2017-2-18,2017,2,18,21,5us720,[D] Probability density estimation using neural networks,https://www.reddit.com/r/MachineLearning/comments/5us720/d_probability_density_estimation_using_neural/,julvo,1487420203,"I am currently working on a project where I forecast the probability density of a continuous variable at discrete time steps conditioned on past observations: P(x_t1 | x_t0, x_t-1 ...)

In literature, I found that mixture density networks are suitable for this kind of task and, in fact, they yield good results for me.

As a pretty naive benchmark method, I binned the output interval and encoded the continuous truth values as one-hot vector transforming the regression into a classification problem. Surprisingly to me, this simple methods achieves a similar performance as the mixture model.

Does this technique of treating regression as classification to obtain probability density has a name?
What methods for estimating probability density for time series have worked for you?",8,48
598,2017-2-18,2017,2,18,21,5us773,Next steps to building something with machine learning. Newbie help,https://www.reddit.com/r/MachineLearning/comments/5us773/next_steps_to_building_something_with_machine/,aswinckr,1487420280,[removed],0,1
599,2017-2-18,2017,2,18,22,5usgjj,Ground-up &amp;amp; hands-on deep learning tutorial  diagnosing skin cancer w/ dermatologist-level,https://www.reddit.com/r/MachineLearning/comments/5usgjj/groundup_amp_handson_deep_learning_tutorial/,[deleted],1487425153,[deleted],0,1
600,2017-2-18,2017,2,18,22,5usiku,Ground-up &amp; hands-on deep learning tutorial  diagnosing skin cancer w/ dermatologist-level accuracy,https://www.reddit.com/r/MachineLearning/comments/5usiku/groundup_handson_deep_learning_tutorial/,wayaai,1487426075,,0,1
601,2017-2-18,2017,2,18,23,5usnl3,CGO'17 (leading compiler conference) gave a test of time award to a research paper on using machine learning for program optimization published 10 years ago,https://www.reddit.com/r/MachineLearning/comments/5usnl3/cgo17_leading_compiler_conference_gave_a_test_of/,[deleted],1487428203,[deleted],0,1
602,2017-2-19,2017,2,19,0,5uswhq,[N] CGO'17 (leading compiler conference) gave a test of time award to a research paper on using machine learning for program optimization published 10 years ago,https://www.reddit.com/r/MachineLearning/comments/5uswhq/n_cgo17_leading_compiler_conference_gave_a_test/,gtechmisc,1487431712,,1,36
603,2017-2-19,2017,2,19,0,5usy7p,Difference between Neural Networks and Regression,https://www.reddit.com/r/MachineLearning/comments/5usy7p/difference_between_neural_networks_and_regression/,ttttttttt123,1487432337,[removed],0,1
604,2017-2-19,2017,2,19,0,5usz1w,[P]Applying Pix2Pix Image translation in sketch to face using conditional adversarial nets,https://www.reddit.com/r/MachineLearning/comments/5usz1w/papplying_pix2pix_image_translation_in_sketch_to/,faau,1487432624,,0,3
605,2017-2-19,2017,2,19,1,5ut2e9,Making a neural network learn abstract concepts and develope a language,https://www.reddit.com/r/MachineLearning/comments/5ut2e9/making_a_neural_network_learn_abstract_concepts/,CleanAndRebuild,1487433754,[removed],0,1
606,2017-2-19,2017,2,19,1,5ut9ni,How to attend ICML 2017 without submitting publication?,https://www.reddit.com/r/MachineLearning/comments/5ut9ni/how_to_attend_icml_2017_without_submitting/,matcha-ai,1487436226,[removed],0,1
607,2017-2-19,2017,2,19,2,5utdek,LibSVM Library. Predict Function working in Python but not in C++,https://www.reddit.com/r/MachineLearning/comments/5utdek/libsvm_library_predict_function_working_in_python/,soulslicer0,1487437433,[removed],1,1
608,2017-2-19,2017,2,19,3,5utt0r,[D] Good frameworks/code implementations for evolutionary algorithms?,https://www.reddit.com/r/MachineLearning/comments/5utt0r/d_good_frameworkscode_implementations_for/,andyandy16,1487442358,"Are there any good (preferably Python) frameworks for implementing evolutionary algorithms, and any good code examples (e.g. on GitHub)?

I've been thinking about trying to optimise an OpenAI gym agent's attributes (via evolutionary/genetic algorithms), and then (or simultaneously) optimise the agents actions (via reinforcement learning).",16,26
609,2017-2-19,2017,2,19,3,5utu1p,"[D] A paper from Bengio's lab contradicts ""rethinking generalization"" paper, thoughts?",https://www.reddit.com/r/MachineLearning/comments/5utu1p/d_a_paper_from_bengios_lab_contradicts_rethinking/,feedthecreed,1487442684,"This paper from Bengio's lab:

""Deep Nets Don't Learn via Memorization""

https://openreview.net/pdf?id=rJv6ZgHYg

seems to directly contradict the message in this Google Brain paper: 

""Understanding deep learning requires rethinking generalization""

https://arxiv.org/abs/1611.03530

I really like the Google Brain paper because it is surprising that neural networks can fit random data. But then this new paper comes along and presents the opposite message. Granted I think both papers don't present results that really prove either argument, but the results seem to trend in opposite directions. Anyone have an idea what's going on here?",43,63
610,2017-2-19,2017,2,19,3,5utwhh,"2nd interview coming up for an advanced analytics and AI analyst role, what project would most impress interviewers?",https://www.reddit.com/r/MachineLearning/comments/5utwhh/2nd_interview_coming_up_for_an_advanced_analytics/,[deleted],1487443498,[removed],0,1
611,2017-2-19,2017,2,19,4,5uu3mh,First ML,https://www.reddit.com/r/MachineLearning/comments/5uu3mh/first_ml/,[deleted],1487445809,[removed],0,1
612,2017-2-19,2017,2,19,4,5uu942,"[D] 2-player Game based on ""Conway's Game of Life"" - How would you develop an AI-based System?",https://www.reddit.com/r/MachineLearning/comments/5uu942/d_2player_game_based_on_conways_game_of_life_how/,Weedjo,1487447583,"I have stumbled over [this Game based on Conway's Game of LIfe](https://youtu.be/JkGZ2Hl1l8c) which I find very interesting. I was looking for an for an interesting AI-project and now I plan to develop an AI.

I would like to start a Discussion:
- Is a classical Brute Force (tree-searching) approach better?
- How would you approach this game with Machine Learning / AI (Deep Learning? Reinforcment Learning?)
- Anyone interested in starting an AI-competition on this game?
- There is a [Java-Version](https://github.com/hanss314/GOLAD) of this game.",4,2
613,2017-2-19,2017,2,19,5,5uualy,[D] First NN processing build: $3k budget; recommendations?,https://www.reddit.com/r/MachineLearning/comments/5uualy/d_first_nn_processing_build_3k_budget/,newguyinml,1487448077,[removed],14,2
614,2017-2-19,2017,2,19,5,5uukoa,What's the simplest way I could generate new images based on some image dataset?,https://www.reddit.com/r/MachineLearning/comments/5uukoa/whats_the_simplest_way_i_could_generate_new/,Patakk,1487451380,[removed],0,1
615,2017-2-19,2017,2,19,6,5uuo8m,Need suggestions on how to approach a ML/NLP problem,https://www.reddit.com/r/MachineLearning/comments/5uuo8m/need_suggestions_on_how_to_approach_a_mlnlp/,srkdummy3,1487452539,[removed],0,1
616,2017-2-19,2017,2,19,9,5uvin3,Writing a algorithm that writes my papers for me.,https://www.reddit.com/r/MachineLearning/comments/5uvin3/writing_a_algorithm_that_writes_my_papers_for_me/,belangrijk,1487462956,[removed],0,1
617,2017-2-19,2017,2,19,9,5uvioe,"How to the ""Word break problem"" with machine learning ?",https://www.reddit.com/r/MachineLearning/comments/5uvioe/how_to_the_word_break_problem_with_machine/,[deleted],1487462964,[removed],0,1
618,2017-2-19,2017,2,19,12,5uwcmk,[D] GitHub - CodingTrain/Machine-Learning: Examples and experiments around ML for upcoming Coding Train videos,https://www.reddit.com/r/MachineLearning/comments/5uwcmk/d_github_codingtrainmachinelearning_examples_and/,b8horpet,1487474254,,0,70
619,2017-2-19,2017,2,19,12,5uwfs4,Simplest approach image classification approach.,https://www.reddit.com/r/MachineLearning/comments/5uwfs4/simplest_approach_image_classification_approach/,giant-torque,1487475581,"I'm working on a PoC of some system and part of the project is to classify images. Let's say there are many (hundreds) ""tags"" and for each tag there is a hundred of images. Each image is produced as a result of some technological process and looks like set of lines and dots.

What would be the simplest way to ""learn"" the existing images such that for a new image/tag pair I could be able to tell whether it matches the classification. Is there a ready to use library or solution for such a problem? 

Thanks!",3,5
620,2017-2-19,2017,2,19,12,5uwgtl,Free Linear Algebra Mini-Course,https://www.reddit.com/r/MachineLearning/comments/5uwgtl/free_linear_algebra_minicourse/,rickmister24,1487476007,,0,1
621,2017-2-19,2017,2,19,14,5uwwhu,Dual-Process Theory of Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/5uwwhu/dualprocess_theory_of_reinforcement_learning/,[deleted],1487483072,[deleted],0,1
622,2017-2-19,2017,2,19,14,5uwxcq,What hardware would you get for $10k?,https://www.reddit.com/r/MachineLearning/comments/5uwxcq/what_hardware_would_you_get_for_10k/,[deleted],1487483496,[removed],0,1
623,2017-2-19,2017,2,19,15,5uwyqm,[P] Dual-Process Theory of Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/5uwyqm/p_dualprocess_theory_of_reinforcement_learning/,inboble,1487484193,,1,2
624,2017-2-19,2017,2,19,15,5ux3e0,Density based clustering,https://www.reddit.com/r/MachineLearning/comments/5ux3e0/density_based_clustering/,[deleted],1487486538,[removed],0,1
625,2017-2-19,2017,2,19,15,5ux4gm,Kolmogorov structure function,https://www.reddit.com/r/MachineLearning/comments/5ux4gm/kolmogorov_structure_function/,mrtransisteur,1487487129,,0,1
626,2017-2-19,2017,2,19,16,5ux7jx,Would like to understand POS tagger in Syntaxnet,https://www.reddit.com/r/MachineLearning/comments/5ux7jx/would_like_to_understand_pos_tagger_in_syntaxnet/,niujin,1487488880,[removed],0,1
627,2017-2-19,2017,2,19,18,5uxl3k,[D] A solution for the 'word break problem' using machine learning ?,https://www.reddit.com/r/MachineLearning/comments/5uxl3k/d_a_solution_for_the_word_break_problem_using/,_AlanT,1487497379,"Hello,
Word Break Problem : I have a given string (ex: ineedsomewater) and I need to break it down (=&gt; I need some water)

I haven't seen many thread on this topic. I'm curious to know if It's still too early to solve this problem with machine learning ? If you have any ideas, articles to solve this problem (with machine learning)
There is the old fashion way of course. But even with the current calculation power. It can be slow.
Thanks for your answers",16,8
628,2017-2-19,2017,2,19,20,5uxuow,corpus - product manuals (consumer durables) for training chatbot,https://www.reddit.com/r/MachineLearning/comments/5uxuow/corpus_product_manuals_consumer_durables_for/,redditshagger,1487503456,[removed],0,1
629,2017-2-19,2017,2,19,22,5uy733,Document topic classification,https://www.reddit.com/r/MachineLearning/comments/5uy733/document_topic_classification/,a1b3rt0,1487510320,[removed],0,1
630,2017-2-20,2017,2,20,1,5uyzux,[D] math for theoretical machine learning research,https://www.reddit.com/r/MachineLearning/comments/5uyzux/d_math_for_theoretical_machine_learning_research/,huyhcmut,1487521720,[removed],6,0
631,2017-2-20,2017,2,20,1,5uz55x,Residual Neural Networks as Ensembles,https://www.reddit.com/r/MachineLearning/comments/5uz55x/residual_neural_networks_as_ensembles/,sachinrjoglekar,1487523499,,0,1
632,2017-2-20,2017,2,20,2,5uz8ft,"More Soul, More Youthful Thinking and More Thinking Among Machines",https://www.reddit.com/r/MachineLearning/comments/5uz8ft/more_soul_more_youthful_thinking_and_more/,Thinkibility,1487524537,,0,1
633,2017-2-20,2017,2,20,4,5uzwdb,What are the effects of like/dislike on a recommender system suggestions?,https://www.reddit.com/r/MachineLearning/comments/5uzwdb/what_are_the_effects_of_likedislike_on_a/,zhirzh,1487532167,,0,1
634,2017-2-20,2017,2,20,5,5v0ahi,What happened at the Tensorflow Dev Summit 2017 - Part 1/3: Community &amp; Applications,https://www.reddit.com/r/MachineLearning/comments/5v0ahi/what_happened_at_the_tensorflow_dev_summit_2017/,fabmilo,1487536623,,0,1
635,2017-2-20,2017,2,20,6,5v0hfn,Add features to your datasets based on trending concepts in the news for Nasdaq &amp; NYSE stocks,https://www.reddit.com/r/MachineLearning/comments/5v0hfn/add_features_to_your_datasets_based_on_trending/,[deleted],1487538835,[deleted],0,1
636,2017-2-20,2017,2,20,6,5v0lg1,A DARPA Perspective on Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/5v0lg1/a_darpa_perspective_on_artificial_intelligence/,Spotlight0xff,1487540116,,0,2
637,2017-2-20,2017,2,20,7,5v0tea,Keras + DL4J backend on Docker,https://www.reddit.com/r/MachineLearning/comments/5v0tea/keras_dl4j_backend_on_docker/,dl4j_contributor,1487542595,,0,1
638,2017-2-20,2017,2,20,7,5v0ted,Neural network new interesting way of use in consumer application.,https://www.reddit.com/r/MachineLearning/comments/5v0ted/neural_network_new_interesting_way_of_use_in/,mnill,1487542595,[removed],0,1
639,2017-2-20,2017,2,20,8,5v1480,[R] Visual Discovery at Pinterest,https://www.reddit.com/r/MachineLearning/comments/5v1480/r_visual_discovery_at_pinterest/,perceptron01,1487546247,,3,19
640,2017-2-20,2017,2,20,10,5v1rfc,[D] I had some troubles when reading the codes of WGAN written by Martin Arjovsky...,https://www.reddit.com/r/MachineLearning/comments/5v1rfc/d_i_had_some_troubles_when_reading_the_codes_of/,zombder,1487554361,"I am not very familiar with PyTorch, so when I read the following lines I wondered why 'errD_real.backward(one)' and 'errD_fake.backward(mone)'. Why not run 'errD = errD_real - errD_fake' first and then backward the gradients? What is the backpropagation operation machanism in PyTorch?


    # train with real
    real_cpu, _ = data
    netD.zero_grad()
    batch_size = real_cpu.size(0)
    input.data.resize_(real_cpu.size()).copy_(real_cpu)

    errD_real = netD(input)
    errD_real.backward(one)

    # train with fake
    noise.data.resize_(batch_size, nz, 1, 1)
    noise.data.normal_(0, 1)
    fake = netG(noise)

    input.data.copy_(fake.data) 
    errD_fake = netD(input)
    errD_fake.backward(mone)

    errD = errD_real - errD_fake
    optimizerD.step()


",7,0
641,2017-2-20,2017,2,20,11,5v1y8s,Concept feature attributes for Nasdaq &amp; NYSE stock datasets,https://www.reddit.com/r/MachineLearning/comments/5v1y8s/concept_feature_attributes_for_nasdaq_nyse_stock/,[deleted],1487556706,[deleted],0,1
642,2017-2-20,2017,2,20,11,5v23aa,undergraduate ML internship interview advice?,https://www.reddit.com/r/MachineLearning/comments/5v23aa/undergraduate_ml_internship_interview_advice/,womanandwolf,1487558421,[removed],0,1
643,2017-2-20,2017,2,20,13,5v2lyu,[D] Dilated pooling layers use-cases,https://www.reddit.com/r/MachineLearning/comments/5v2lyu/d_dilated_pooling_layers_usecases/,warmspringwinds,1487565290,"Recently I have stumbled upon a couple of issues on github mentioning Dilated Pooling:
https://github.com/tensorflow/tensorflow/issues/3492

Shortly after that, I found out that there is an implementation of Spatial Dilated Max Pooling in Torch:
https://github.com/torch/nn/blob/master/doc/convolution.md

Does anyone know for what purpose those operations are used?
I couldn't find any papers mentioning them.

Update:

Some guys mentioned use cases of Dilated convolution. I saw that too. I was more interested in the use cases of Dilated Pooling like torch's Dilated spatial max Pooling layer.",5,6
644,2017-2-20,2017,2,20,15,5v2yva,[D] What stops us from doing style transfer on high resolution photos?,https://www.reddit.com/r/MachineLearning/comments/5v2yva/d_what_stops_us_from_doing_style_transfer_on_high/,[deleted],1487570419,[deleted],1,1
645,2017-2-20,2017,2,20,15,5v2z9r,Open-source A3C implementation that matches DeepMind,https://www.reddit.com/r/MachineLearning/comments/5v2z9r/opensource_a3c_implementation_that_matches/,[deleted],1487570573,[removed],0,1
646,2017-2-20,2017,2,20,15,5v35e3,Machine Learning Found as a New Solution to Cancer Treatment,https://www.reddit.com/r/MachineLearning/comments/5v35e3/machine_learning_found_as_a_new_solution_to/,VijayPathakTHEONE,1487573333,,0,1
647,2017-2-20,2017,2,20,18,5v3mru,Intelligent machines will dominate FX trading  but when? @Euromoney,https://www.reddit.com/r/MachineLearning/comments/5v3mru/intelligent_machines_will_dominate_fx_trading_but/,quantguy1,1487582292,,0,1
648,2017-2-20,2017,2,20,18,5v3n6v,Cluster Analysis Using K-means Explained,https://www.reddit.com/r/MachineLearning/comments/5v3n6v/cluster_analysis_using_kmeans_explained/,pensker,1487582547,,0,1
649,2017-2-20,2017,2,20,18,5v3p27,MACHINE LEARNING,https://www.reddit.com/r/MachineLearning/comments/5v3p27/machine_learning/,techjinisolutions,1487583563,,0,1
650,2017-2-20,2017,2,20,19,5v3tp2,Machine Intelligence: Driving a New Era of Autonomous Vehicles,https://www.reddit.com/r/MachineLearning/comments/5v3tp2/machine_intelligence_driving_a_new_era_of/,reworksophie,1487585917,,0,1
651,2017-2-20,2017,2,20,20,5v44i3,"[P] Pretrained SkipThoughts models (word2vec, seq2seq, seq2vec) for Torch",https://www.reddit.com/r/MachineLearning/comments/5v44i3/p_pretrained_skipthoughts_models_word2vec_seq2seq/,Tamazy,1487591382,,4,38
652,2017-2-20,2017,2,20,23,5v4on7,[R] [DeepMind] - Evolution Channels Gradient Descent in Super Neural Networks,https://www.reddit.com/r/MachineLearning/comments/5v4on7/r_deepmind_evolution_channels_gradient_descent_in/,kh40tika,1487599484,,23,91
653,2017-2-20,2017,2,20,23,5v4r7y,[D] Do you include the 'fuzz parameter' epsilon of Batch normalisation as a hyperparameter when optimising a network?,https://www.reddit.com/r/MachineLearning/comments/5v4r7y/d_do_you_include_the_fuzz_parameter_epsilon_of/,L43,1487600367,"Question as per title.  If so, what values do you typically search between?  I am setting up a bayesian optimization procedure, and would rather limit the number of hyperparameters if it doesn't tend to have a big influence.",3,1
654,2017-2-21,2017,2,21,0,5v4z2o,I-SED: Interactive Sound Event Detector,https://www.reddit.com/r/MachineLearning/comments/5v4z2o/ised_interactive_sound_event_detector/,[deleted],1487603026,[deleted],1,1
655,2017-2-21,2017,2,21,0,5v4zm1,Watson Personality Insights Library for PHP,https://www.reddit.com/r/MachineLearning/comments/5v4zm1/watson_personality_insights_library_for_php/,worldwidewunicorn,1487603196,,0,1
656,2017-2-21,2017,2,21,0,5v5881,Transfer learning for lung cancer detection with CNTK and Azure,https://www.reddit.com/r/MachineLearning/comments/5v5881/transfer_learning_for_lung_cancer_detection_with/,hoaphumanoid,1487605757,,0,1
657,2017-2-21,2017,2,21,1,5v5cxc,Back to the core of intelligence  AI Roadmap Institute Blog,https://www.reddit.com/r/MachineLearning/comments/5v5cxc/back_to_the_core_of_intelligence_ai_roadmap/,thefillm,1487607027,,0,1
658,2017-2-21,2017,2,21,1,5v5if4,[R] EMNIST: an extension of MNIST to handwritten letters,https://www.reddit.com/r/MachineLearning/comments/5v5if4/r_emnist_an_extension_of_mnist_to_handwritten/,perceptron01,1487608519,,10,10
659,2017-2-21,2017,2,21,1,5v5jys,[D] Looking for open source implementation of A3C that matches DeepMind.,https://www.reddit.com/r/MachineLearning/comments/5v5jys/d_looking_for_open_source_implementation_of_a3c/,Neutran,1487608926,"I have found many A3C (Async Advantage Actor-Critic) implementations by googling. For example,
https://github.com/coreylynch/async-rl

https://github.com/muupan/async-rl

https://github.com/BruinBear/Asynchronous-Advantage-Actor-Critic

and many others.

However, none of them actually mention how good their performances are, compared to the numbers in DeepMind's original A3C paper (https://arxiv.org/abs/1602.01783). 

Since I have neither the time nor the computing resource to run and compare all of them myself, could anyone please let me know if there's an open source implementation (must be in Tensorflow) that matches or at least *approaches* DeepMind in most of the Atari games? ",6,8
660,2017-2-21,2017,2,21,1,5v5lh0,[R][1701.08380] The HASYv2 dataset,https://www.reddit.com/r/MachineLearning/comments/5v5lh0/r170108380_the_hasyv2_dataset/,themoosemind,1487609320,,2,2
661,2017-2-21,2017,2,21,2,5v5okh,TensorFlow Quick Tips,https://www.reddit.com/r/MachineLearning/comments/5v5okh/tensorflow_quick_tips/,buhmi,1487610147,,0,1
662,2017-2-21,2017,2,21,2,5v5tbl,Two Bias terms in RNN (cuDNN),https://www.reddit.com/r/MachineLearning/comments/5v5tbl/two_bias_terms_in_rnn_cudnn/,6m17at,1487611383,[removed],0,1
663,2017-2-21,2017,2,21,2,5v5yho,Does anyone know of an algorithm which recognizes different people without training on them? e.g if i show it a few images of me and my friend it will tag me as person 1 and my friend as person 2. if i'll introduce a third person he will be tagged as person 3.,https://www.reddit.com/r/MachineLearning/comments/5v5yho/does_anyone_know_of_an_algorithm_which_recognizes/,shgidigo,1487612719,[removed],0,1
664,2017-2-21,2017,2,21,2,5v5ynt,[R]Automatic Handgun Detection Alarm in Videos Using Deep Learning,https://www.reddit.com/r/MachineLearning/comments/5v5ynt/rautomatic_handgun_detection_alarm_in_videos/,[deleted],1487612759,[deleted],8,2
665,2017-2-21,2017,2,21,2,5v5zsy,[R] Generating neural network weights with a neural network,https://www.reddit.com/r/MachineLearning/comments/5v5zsy/r_generating_neural_network_weights_with_a_neural/,newguyinml,1487613056,"Sorry if this is not the right place to ask this question.

I am wondering if it is possible to use a neural network to generate the weights for a second neural network. Given a input X instead of run F(x) you run (G(.))(x) where G generates the network F. I do not know what the argument to G would be.",5,9
666,2017-2-21,2017,2,21,2,5v60vn,[D] When to end beam search with end of sequence token,https://www.reddit.com/r/MachineLearning/comments/5v60vn/d_when_to_end_beam_search_with_end_of_sequence/,deepthrawa,1487613333,"If an end of sequence token is allowed, do we stop when first K beams reach the end of sequence token (does not seem to be optimal but then even beam search isn't) or do we stop till we explore K beams till the maximum length (removing the ended sequences and keeping them in a separate pool)?

With the second approach you can possibly have more than K beams finished at the end (K at maxlen + n beams that finished before with end of sequence) and then you can sort and pick the K best scoring beams.

With the first approach you would stop when you have finished K beams but this might be really bad. For example, you get bad sequences with len &gt; K with the end of sequence symbol and you terminate. You might have higher scoring longer sequence but you will never get to see them if you stop with this approach.",2,1
667,2017-2-21,2017,2,21,3,5v64l9,Semantic Question Matching with Deep Learning,https://www.reddit.com/r/MachineLearning/comments/5v64l9/semantic_question_matching_with_deep_learning/,[deleted],1487614318,[deleted],0,1
668,2017-2-21,2017,2,21,3,5v64t1,[R] Maximally Correlated Principle Component Analysis,https://www.reddit.com/r/MachineLearning/comments/5v64t1/r_maximally_correlated_principle_component/,perceptron01,1487614378,,4,11
669,2017-2-21,2017,2,21,3,5v68dz,R Programming for Beginners,https://www.reddit.com/r/MachineLearning/comments/5v68dz/r_programming_for_beginners/,tejarampooniya,1487615346,,0,1
670,2017-2-21,2017,2,21,3,5v68rr,Multi-var time-series prediction question,https://www.reddit.com/r/MachineLearning/comments/5v68rr/multivar_timeseries_prediction_question/,bluehotdog,1487615448,[removed],0,1
671,2017-2-21,2017,2,21,3,5v6aae,Semantic Question Matching with Deep Learning,https://www.reddit.com/r/MachineLearning/comments/5v6aae/semantic_question_matching_with_deep_learning/,[deleted],1487615877,[deleted],0,1
672,2017-2-21,2017,2,21,4,5v6f7p,[undergrad student] How early is too early to think about a PhD and when exactly should one consider it?,https://www.reddit.com/r/MachineLearning/comments/5v6f7p/undergrad_student_how_early_is_too_early_to_think/,g0h0m3,1487617202,"A lot of people on this subreddit say a PhD is vital if you want to do ""cutting-edge"" stuff or just research in the field in general.

I'm an undergrad sophomore, and I love the idea of doing research and making ground-breaking discoveries (very naive, I know, a lot of research is never used for much). Is it too early to be thinking about a PhD? 

Also, what can I do on my own to have a stronger application? I'm not sure any professor in my university (not North America or europe) does Machine Learning research. A lot of people recommend having lots of publications out if you want any chance to be at the top 10 universities. How does that work out for people who don't have professors in their uni doing research in the field they want? I can't really transfer at this point.

I really want to get into ML after reading up on some of the applications, but I'm unsure as to how to start and if personal projects or publications are more important. Also not sure if I can even have publications at all.

P.S. I have a third world country citizenship and don't live in the US or Canada, so that may add problems, too.",6,0
673,2017-2-21,2017,2,21,4,5v6i3x,[P] Semantic Question Matching with Deep Learning,https://www.reddit.com/r/MachineLearning/comments/5v6i3x/p_semantic_question_matching_with_deep_learning/,byungjikroh,1487617994,,0,6
674,2017-2-21,2017,2,21,4,5v6k6g,"Machine Learning: Solving Problems Big, Small, and Prickly",https://www.reddit.com/r/MachineLearning/comments/5v6k6g/machine_learning_solving_problems_big_small_and/,Mussem17,1487618570,,0,1
675,2017-2-21,2017,2,21,5,5v6tjc,[P] Interactive Image Translation with pix2pix-tensorflow,https://www.reddit.com/r/MachineLearning/comments/5v6tjc/p_interactive_image_translation_with/,Tryneus,1487621101,,4,13
676,2017-2-21,2017,2,21,5,5v6yck,[P] How to train Baidu's Deepspeech model with Kur,https://www.reddit.com/r/MachineLearning/comments/5v6yck/p_how_to_train_baidus_deepspeech_model_with_kur/,brainchop,1487622428,,0,1
677,2017-2-21,2017,2,21,5,5v72y6,How do you setup your model configuration?,https://www.reddit.com/r/MachineLearning/comments/5v72y6/how_do_you_setup_your_model_configuration/,[deleted],1487623698,[removed],0,1
678,2017-2-21,2017,2,21,6,5v7dnr,Clustering Sparse Binary Data ?,https://www.reddit.com/r/MachineLearning/comments/5v7dnr/clustering_sparse_binary_data/,[deleted],1487626732,[removed],0,1
679,2017-2-21,2017,2,21,7,5v7mzb,The Rise of the Weaponized AI Propaganda Machine,https://www.reddit.com/r/MachineLearning/comments/5v7mzb/the_rise_of_the_weaponized_ai_propaganda_machine/,RoamBear,1487629376,[removed],0,1
680,2017-2-21,2017,2,21,8,5v855k,[R] ArtGAN: Artwork Synthesis with Conditional Categorial GANs,https://www.reddit.com/r/MachineLearning/comments/5v855k/r_artgan_artwork_synthesis_with_conditional/,perceptron01,1487634637,,2,1
681,2017-2-21,2017,2,21,8,5v86l3,[R] Local minima in training of neural networks (DeepMind),https://www.reddit.com/r/MachineLearning/comments/5v86l3/r_local_minima_in_training_of_neural_networks/,perceptron01,1487635081,,3,12
682,2017-2-21,2017,2,21,9,5v8f8k,Help with list prediction,https://www.reddit.com/r/MachineLearning/comments/5v8f8k/help_with_list_prediction/,coursestash,1487637604,[removed],0,1
683,2017-2-21,2017,2,21,10,5v8m73,[D] How do you setup your model configuration?,https://www.reddit.com/r/MachineLearning/comments/5v8m73/d_how_do_you_setup_your_model_configuration/,SkiddyX,1487639684,"When looking at most paper implementations, they always seem to use a huge amount of command line arguments, yet this seems to become janky if you want to share that configuration while building a dataset or if you have a huge number of tuneable parameters. I have experimented with creating a configuration class with [attrs](https://attrs.readthedocs.io/en/stable/), but found that it can get out of control at a large number of parameters. Wondering if anyone has any better methods?",3,2
684,2017-2-21,2017,2,21,10,5v8uf5,[D] Transfer Learning in Seq2Seq models,https://www.reddit.com/r/MachineLearning/comments/5v8uf5/d_transfer_learning_in_seq2seq_models/,dejormo,1487642286,"Hi, I am working on a seq2seq model and need a reality check with you. The model is trained end-to-end on Q&amp;A data from Ubuntu Corpus, and for a given utterance comes back with the best answer. As far as I understand, seq2seq learns the relationship between words in one seq to another, and not the relationship between the words itself, so training it on one document will not allow me to transfer the data to another one, even if the vocab size is fixed and the same methods are used to encode the sequences. Is that true?

P.S. Question - were there any attempts to model the relationship between words, so given a new corpus, the model would be able to extract the context from it and produce meaningful replies?",3,6
685,2017-2-21,2017,2,21,11,5v8vpg,A startup is making an intelligent assistant like SIRI that allows you to train it to understand new phrases through pattern recognition.,https://www.reddit.com/r/MachineLearning/comments/5v8vpg/a_startup_is_making_an_intelligent_assistant_like/,[deleted],1487642702,[deleted],0,1
686,2017-2-21,2017,2,21,11,5v8xt6,Model learns to beat Level 9 AIs in Super Smash Bros. [1702.05663] The Game Imitation: Deep Supervised Convolutional Networks for Quick Video Game AI,https://www.reddit.com/r/MachineLearning/comments/5v8xt6/model_learns_to_beat_level_9_ais_in_super_smash/,[deleted],1487643386,[deleted],0,1
687,2017-2-21,2017,2,21,11,5v8y1a,[R] Model learns to beat Level 9 AIs in Super Smash Bros. [1702.05663] The Game Imitation: Deep Supervised Convolutional Networks for Quick Video Game AI,https://www.reddit.com/r/MachineLearning/comments/5v8y1a/r_model_learns_to_beat_level_9_ais_in_super_smash/,evc123,1487643462,,32,156
688,2017-2-21,2017,2,21,11,5v8yy4,[P] A startup is making an intelligent assistant like SIRI that allows you to train it to understand new phrases through pattern recognition.,https://www.reddit.com/r/MachineLearning/comments/5v8yy4/p_a_startup_is_making_an_intelligent_assistant/,[deleted],1487643782,[deleted],0,1
689,2017-2-21,2017,2,21,12,5v95hk,[R] Code for paper: High-Resolution Image Inpainting using Multi-Scale Neural Patch Synthesis,https://www.reddit.com/r/MachineLearning/comments/5v95hk/r_code_for_paper_highresolution_image_inpainting/,leehomyc,1487646015,,4,41
690,2017-2-21,2017,2,21,14,5v9sf8,Predictive Analytics Software Solutions,https://www.reddit.com/r/MachineLearning/comments/5v9sf8/predictive_analytics_software_solutions/,oodlesmarketing,1487654405,,0,1
691,2017-2-21,2017,2,21,14,5v9tj9,[D] How can I make big confusion matrices easier to read?,https://www.reddit.com/r/MachineLearning/comments/5v9tj9/d_how_can_i_make_big_confusion_matrices_easier_to/,themoosemind,1487654847,,0,1
692,2017-2-21,2017,2,21,15,5v9y4y,[D] Upper limit for product image recognition?,https://www.reddit.com/r/MachineLearning/comments/5v9y4y/d_upper_limit_for_product_image_recognition/,Paradigm_shifting,1487656836,"I'm working on an assistive tech project to make packaged products accessible to blind people without them having to move them around to search for a barcode.
So far I've avoided using deep learning for packaged products in large scales because of the:

1. lack of good datasets
2. frequent cosmetic changes
3. Small text details that distinguish two products.

Apologies if this was discussed before, but if there were to be a training set with 1000+ in-the-wild images of each product that was continuously updated, how well would it hold up? The average person can encounter up to 100,000 unique products. I guess in this case any trick in the book would be allowed, including using SIFT, OCR, or histograms to complement.",3,1
693,2017-2-21,2017,2,21,15,5v9yuj,"I ranked every Intro to Data Science course on the internet, based on thousands of data points",https://www.reddit.com/r/MachineLearning/comments/5v9yuj/i_ranked_every_intro_to_data_science_course_on/,mks_repi,1487657104,,0,1
694,2017-2-21,2017,2,21,15,5va043,"Question about ""Show and Tell: A Neural Image Caption Generator""",https://www.reddit.com/r/MachineLearning/comments/5va043/question_about_show_and_tell_a_neural_image/,sbarratt,1487657655,[removed],0,1
695,2017-2-21,2017,2,21,16,5va93r,Simple Tutorial on SVM and Parameter Tuning in Python and R,https://www.reddit.com/r/MachineLearning/comments/5va93r/simple_tutorial_on_svm_and_parameter_tuning_in/,NarendhiranS,1487661943,,0,1
696,2017-2-21,2017,2,21,16,5va9ip,QT4 30 diesel block moulding machine in nigeria Whatsapp:008615168958352,https://www.reddit.com/r/MachineLearning/comments/5va9ip/qt4_30_diesel_block_moulding_machine_in_nigeria/,dymachine01,1487662171,,1,1
697,2017-2-21,2017,2,21,17,5vafbb,Emotional intelligence is the future of artificial intelligence,https://www.reddit.com/r/MachineLearning/comments/5vafbb/emotional_intelligence_is_the_future_of/,dunkin1980,1487665340,,0,1
698,2017-2-21,2017,2,21,18,5vakf4,[D] Taking Andrew Ng's Machine Learning course. Completely lost. Any suggestions?,https://www.reddit.com/r/MachineLearning/comments/5vakf4/d_taking_andrew_ngs_machine_learning_course/,dodd1331,1487668132,"Hi everyone. I have started taking Andrew Ng's [Machine Learning course on Coursera](https://www.coursera.org/learn/machine-learning). I've always been interested in Machine Learning and wanted to know more about the field. I'm roughly at the end of week 1 of the course and I'm not understanding most of the math involved.

I've never been very good at math and this is kind of embarrassing, particularly after seeing so many reviews and posts on how simple and ""mathematically shallow"" this course is. Any suggestions on how I can go about grasping this course material? I don't come from a mathematical background and any advice would be helpful. Thanks!",22,4
699,2017-2-21,2017,2,21,18,5valf2,classification and clustering algorithms,https://www.reddit.com/r/MachineLearning/comments/5valf2/classification_and_clustering_algorithms/,dataaspirant,1487668659,,0,1
700,2017-2-21,2017,2,21,18,5vaoav,HawkSpex mobile: recognise objects by hyperspectral scan learned with ML,https://www.reddit.com/r/MachineLearning/comments/5vaoav/hawkspex_mobile_recognise_objects_by/,PthePeanut,1487670216,,0,1
701,2017-2-21,2017,2,21,18,5vapb3,is there a publicly accessible trained super-resolution network?,https://www.reddit.com/r/MachineLearning/comments/5vapb3/is_there_a_publicly_accessible_trained/,zhirzh,1487670783,[removed],0,1
702,2017-2-21,2017,2,21,19,5varnt,[N] AWS AI Blog,https://www.reddit.com/r/MachineLearning/comments/5varnt/n_aws_ai_blog/,jakn,1487671977,,6,12
703,2017-2-21,2017,2,21,19,5vavgp,[Discussion] What are the best practices for tuning hyperparameters? Is this Bengio's paper still relevant today?,https://www.reddit.com/r/MachineLearning/comments/5vavgp/discussion_what_are_the_best_practices_for_tuning/,beltsazar,1487674096,Paper: [Practical recommendations for gradient-based training of deep architectures](https://arxiv.org/abs/1206.5533) (2012),7,14
704,2017-2-21,2017,2,21,22,5vbg6a,Why are MNIST characters white instead of dark? Could I use the same network to recognise dark characters on a white background?,https://www.reddit.com/r/MachineLearning/comments/5vbg6a/why_are_mnist_characters_white_instead_of_dark/,jackbrucesimpson,1487683442,[removed],0,1
705,2017-2-21,2017,2,21,22,5vbgrn,[D] TensorFlow vs. Caffe for a robotics project,https://www.reddit.com/r/MachineLearning/comments/5vbgrn/d_tensorflow_vs_caffe_for_a_robotics_project/,mlrobotist,1487683651,"Hello everyone,

I am working on a robotics project, which will to some extend involve computer vision, and therefore most probably DL models based on CNNs.

While I have some experience with doing research with Deep Learning frameworks, I haven't really deployed a model to a serious production environment, let alone a mobile robot, where the speed of computation is very important.

The robot will make use of ROS framework. Given my quick research, I am currently trying to choose between TensorFlow (which I know pretty well) and Caffe which seems to be the standard in the industry.

Which one does /r/MachineLearning thing would be better suited in this case? Did I miss anything obvious (i.e. is there a framework that would be much better suited than the two I outlined)?

Thank you very much!",4,0
706,2017-2-21,2017,2,21,22,5vblyd,[P] Combining decision trees and neural nets,https://www.reddit.com/r/MachineLearning/comments/5vblyd/p_combining_decision_trees_and_neural_nets/,onedivzero,1487685523,,1,20
707,2017-2-21,2017,2,21,23,5vbqq5,[D] Is it nessesary to keep the test set for the product development?,https://www.reddit.com/r/MachineLearning/comments/5vbqq5/d_is_it_nessesary_to_keep_the_test_set_for_the/,ultrakoge,1487687116,,6,1
708,2017-2-21,2017,2,21,23,5vbtig,oh no! TensorFlow!!,https://www.reddit.com/r/MachineLearning/comments/5vbtig/oh_no_tensorflow/,orenog,1487688070,[removed],0,1
709,2017-2-22,2017,2,22,0,5vbz00,MSc Machine Learning UCL or Edinburgh,https://www.reddit.com/r/MachineLearning/comments/5vbz00/msc_machine_learning_ucl_or_edinburgh/,slasakai,1487689832,[removed],0,1
710,2017-2-22,2017,2,22,2,5vcogd,Could a machine learning algorithm meaningfully pass an MSR test?,https://www.reddit.com/r/MachineLearning/comments/5vcogd/could_a_machine_learning_algorithm_meaningfully/,[deleted],1487697067,[removed],0,1
711,2017-2-22,2017,2,22,2,5vcpkj,Fast PixelCNN++: up to a 183 times speedup for image generation,https://www.reddit.com/r/MachineLearning/comments/5vcpkj/fast_pixelcnn_up_to_a_183_times_speedup_for_image/,[deleted],1487697364,[deleted],0,1
712,2017-2-22,2017,2,22,2,5vcqmi,Numerai issues cryptocurrency to disincentivize overfitting,https://www.reddit.com/r/MachineLearning/comments/5vcqmi/numerai_issues_cryptocurrency_to_disincentivize/,richardcraib,1487697638,,0,2
713,2017-2-22,2017,2,22,2,5vctvw,Working Together,https://www.reddit.com/r/MachineLearning/comments/5vctvw/working_together/,[deleted],1487698505,[removed],0,1
714,2017-2-22,2017,2,22,2,5vcveg,"Idea for my first neural net, starting it now, any improvments?",https://www.reddit.com/r/MachineLearning/comments/5vcveg/idea_for_my_first_neural_net_starting_it_now_any/,orenog,1487698904,,1,1
715,2017-2-22,2017,2,22,2,5vcwh3,Char2Wav: End-to-End Speech Synthesis,https://www.reddit.com/r/MachineLearning/comments/5vcwh3/char2wav_endtoend_speech_synthesis/,[deleted],1487699200,[deleted],0,2
716,2017-2-22,2017,2,22,2,5vcxhq,[P] SHMArrays - Easy single-machine distributed training in Python using SHM,https://www.reddit.com/r/MachineLearning/comments/5vcxhq/p_shmarrays_easy_singlemachine_distributed/,MathAndProgramming,1487699463,,0,4
717,2017-2-22,2017,2,22,2,5vcxix,My first experience with deep reinforcement learning,https://www.reddit.com/r/MachineLearning/comments/5vcxix/my_first_experience_with_deep_reinforcement/,scvalencia,1487699473,,0,1
718,2017-2-22,2017,2,22,2,5vcyfx,[R] Fast PixelCNN++: up to a 183 speedup for image generation,https://www.reddit.com/r/MachineLearning/comments/5vcyfx/r_fast_pixelcnn_up_to_a_183_speedup_for_image/,prajit,1487699720,,16,125
719,2017-2-22,2017,2,22,3,5vd6c6,fast question about the weights!,https://www.reddit.com/r/MachineLearning/comments/5vd6c6/fast_question_about_the_weights/,orenog,1487701813,[removed],0,1
720,2017-2-22,2017,2,22,3,5vd8th,[R] Char2Wav: End-to-End Speech Synthesis,https://www.reddit.com/r/MachineLearning/comments/5vd8th/r_char2wav_endtoend_speech_synthesis/,jfsantos,1487702462,,30,35
721,2017-2-22,2017,2,22,3,5vd9qj,GPUs Are Now Available for Google Compute Engine and Cloud Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5vd9qj/gpus_are_now_available_for_google_compute_engine/,eleitl,1487702710,,0,1
722,2017-2-22,2017,2,22,3,5vdcmh,Feed-Forward Neural Networks With mxnetR - DZone Big Data,https://www.reddit.com/r/MachineLearning/comments/5vdcmh/feedforward_neural_networks_with_mxnetr_dzone_big/,Sibanjan,1487703433,,0,1
723,2017-2-22,2017,2,22,4,5vddu0,[N] Google Compute Engine rolls out 12GB K80 GPU instance ($0.7/hour+base instance),https://www.reddit.com/r/MachineLearning/comments/5vddu0/n_google_compute_engine_rolls_out_12gb_k80_gpu/,gwern,1487703741,,11,87
724,2017-2-22,2017,2,22,4,5vdf3g,[P] Competitive Feature Learning,https://www.reddit.com/r/MachineLearning/comments/5vdf3g/p_competitive_feature_learning/,inboble,1487704065,,0,5
725,2017-2-22,2017,2,22,5,5vdtyx,MILA  Deep Learning Summer School and Reinforcement Learning Summer School,https://www.reddit.com/r/MachineLearning/comments/5vdtyx/mila_deep_learning_summer_school_and/,[deleted],1487707906,[deleted],0,1
726,2017-2-22,2017,2,22,5,5vdud7,[N] Baidu's 'Ring Allreduce' Library Increases Machine Learning Efficiency Across Many GPU Nodes,https://www.reddit.com/r/MachineLearning/comments/5vdud7/n_baidus_ring_allreduce_library_increases_machine/,badhri,1487708010,,1,10
727,2017-2-22,2017,2,22,5,5vdue9,[R] MILA  Deep Learning Summer School and Reinforcement Learning Summer School,https://www.reddit.com/r/MachineLearning/comments/5vdue9/r_mila_deep_learning_summer_school_and/,pierrelux,1487708016,,1,6
728,2017-2-22,2017,2,22,5,5vdvn5,[P] @DeepElonMusk is a LSTM Neural Network trained on Elon Musk transcripts,https://www.reddit.com/r/MachineLearning/comments/5vdvn5/p_deepelonmusk_is_a_lstm_neural_network_trained/,Berpj,1487708312,,1,5
729,2017-2-22,2017,2,22,5,5ve16y,Face Detection in OpenCV - Prep for Deep Learning Part 1,https://www.reddit.com/r/MachineLearning/comments/5ve16y/face_detection_in_opencv_prep_for_deep_learning/,gavlaaaaaaaa,1487709805,,0,1
730,2017-2-22,2017,2,22,5,5ve3mp,My first learning creature ever!!,https://www.reddit.com/r/MachineLearning/comments/5ve3mp/my_first_learning_creature_ever/,orenog,1487710425,[removed],0,1
731,2017-2-22,2017,2,22,5,5ve48y,Image Data Prep for Deep Learning,https://www.reddit.com/r/MachineLearning/comments/5ve48y/image_data_prep_for_deep_learning/,gavlaaaaaaaa,1487710596,,0,1
732,2017-2-22,2017,2,22,8,5vevvv,[P] Livestream of learning TFLearn and TensorFlow 1.0,https://www.reddit.com/r/MachineLearning/comments/5vevvv/p_livestream_of_learning_tflearn_and_tensorflow_10/,vanboxel,1487718151,,0,0
733,2017-2-22,2017,2,22,8,5veyyb,[Discussion] AWS GPUs vs. your own machine,https://www.reddit.com/r/MachineLearning/comments/5veyyb/discussion_aws_gpus_vs_your_own_machine/,maxhdavis,1487718991,"I've used AWS, Google and Azure GPU instances, and have also built my own deep learning rig, because I know this is something I'll be doing for a while and because cloud GPU instances are expensive (even with spot pricing). Are most people here doing the same thing?

With growing demand, cloud GPU prices are likely going to come down over the next year (if only because of competition). Does it still make sense to spend $1k-$2k to build your own machine in 2017?",19,7
734,2017-2-22,2017,2,22,8,5vf70z,A Guide to Solving Social Problems with Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5vf70z/a_guide_to_solving_social_problems_with_machine/,urish,1487721310,,0,1
735,2017-2-22,2017,2,22,10,5vfq2c,"Multi-GPU training of Large, Sparse-Matrix on Wide #NeuralNetwork",https://www.reddit.com/r/MachineLearning/comments/5vfq2c/multigpu_training_of_large_sparsematrix_on_wide/,vvpreetham,1487727029,,0,1
736,2017-2-22,2017,2,22,10,5vfqao,Public light-weight GAN Demos?,https://www.reddit.com/r/MachineLearning/comments/5vfqao/public_lightweight_gan_demos/,[deleted],1487727092,[removed],0,1
737,2017-2-22,2017,2,22,10,5vfqnh,Stacking Models for Improved Predictions,https://www.reddit.com/r/MachineLearning/comments/5vfqnh/stacking_models_for_improved_predictions/,thecity2,1487727200,,1,1
738,2017-2-22,2017,2,22,10,5vfsbv,Public light-weight GAN demos?,https://www.reddit.com/r/MachineLearning/comments/5vfsbv/public_lightweight_gan_demos/,bigswooper,1487727730,[removed],0,1
739,2017-2-22,2017,2,22,10,5vfune,Convolution Aware Initialization,https://www.reddit.com/r/MachineLearning/comments/5vfune/convolution_aware_initialization/,[deleted],1487728445,[deleted],0,1
740,2017-2-22,2017,2,22,10,5vfv3v,Convolution Aware Initialization,https://www.reddit.com/r/MachineLearning/comments/5vfv3v/convolution_aware_initialization/,[deleted],1487728592,[deleted],0,1
741,2017-2-22,2017,2,22,11,5vfyxg,[D]Weird drop-out behavior in DNN on MNIST,https://www.reddit.com/r/MachineLearning/comments/5vfyxg/dweird_dropout_behavior_in_dnn_on_mnist/,wencc,1487729830,"I was [experimenting DNN on MNIST](http://stats.stackexchange.com/questions/262882/deep-mlp-dropout-poor-generalization-in-mnist) and encountered strange performances, any idea?

Thanks.",3,0
742,2017-2-22,2017,2,22,13,5vgqsu,Convolution Aware Initialization (SOTA on CIFAR10),https://www.reddit.com/r/MachineLearning/comments/5vgqsu/convolution_aware_initialization_sota_on_cifar10/,[deleted],1487739174,[deleted],0,1
743,2017-2-22,2017,2,22,13,5vgr0a,CNC Hydraulic Press Brake machine 63T Plate bender,https://www.reddit.com/r/MachineLearning/comments/5vgr0a/cnc_hydraulic_press_brake_machine_63t_plate_bender/,songjinwei,1487739254,,0,1
744,2017-2-22,2017,2,22,13,5vgrod,[R] Convolution Aware Initialization,https://www.reddit.com/r/MachineLearning/comments/5vgrod/r_convolution_aware_initialization/,ArmenAg,1487739507,,8,14
745,2017-2-22,2017,2,22,14,5vgx43,AI ASIA 2017 - Call for Abstracts now open! Spread the word to someone you know might be interested in speaking!,https://www.reddit.com/r/MachineLearning/comments/5vgx43/ai_asia_2017_call_for_abstracts_now_open_spread/,corpasia,1487741546,,0,1
746,2017-2-22,2017,2,22,14,5vh0sl,[D] Graves' LSTM (nnl_ndim_2.0) - Doubts,https://www.reddit.com/r/MachineLearning/comments/5vh0sl/d_graves_lstm_nnl_ndim_20_doubts/,a933,1487743009,"I'm working to implement a feedforward of an LSTM Net trained with nnl_ndim_2.0, one of the early versions of the LSTM code by Alex Graves. 

I'm finding the terminology quite confusing, and is having a hard time reading the code and figuring out. The equations in the thesis has separate equations for the input, forget and output gates, but in the ExportedData file, there's just a few vectors containing weights. I can see a multiple of 4 in certain weights, but am still having a tough time tracking which weights go where. I'd be grateful if someone can lend a hand. Thanks.

    connections:
    Connection level_0_subnet_0_to_level_0_subnet_0_conn_0 (10000 wts)
    Connection bias_to_level_0_subnet_0_conn (200 wts)
    Connection input_to_level_0_subnet_0_conn (6400 wts)
    LSTM PeepholeWeights ""level_0_subnet_0_peepholes"" (150 wts)
    Connection level_0_subnet_1_to_level_0_subnet_1_conn_0 (10000 wts)
    Connection bias_to_level_0_subnet_1_conn (200 wts)
    Connection input_to_level_0_subnet_1_conn (6400 wts)
    LSTM PeepholeWeights ""level_0_subnet_1_peepholes"" (150 wts)
    Connection level_0_subnet_0_to_level_0_subsample_conn (1250 wts)
    Connection level_0_subnet_1_to_level_0_subsample_conn (1250 wts)
    Connection level_1_subnet_0_to_level_1_subnet_0_conn_0 (10000 wts)
    Connection bias_to_level_1_subnet_0_conn (200 wts)
    Connection level_0_subsample_to_level_1_subnet_0_conn (5000 wts)
    LSTM PeepholeWeights ""level_1_subnet_0_peepholes"" (150 wts)
    Connection level_1_subnet_1_to_level_1_subnet_1_conn_0 (10000 wts)
    Connection bias_to_level_1_subnet_1_conn (200 wts)
    Connection level_0_subsample_to_level_1_subnet_1_conn (5000 wts)
    LSTM PeepholeWeights ""level_1_subnet_1_peepholes"" (150 wts)
    Connection level_1_subnet_0_to_level_1_subsample_conn (1250 wts)
    Connection level_1_subnet_1_to_level_1_subsample_conn (1250 wts)
    Connection level_2_subnet_0_to_level_2_subnet_0_conn_0 (10000 wts)
    Connection bias_to_level_2_subnet_0_conn (200 wts)
    Connection level_1_subsample_to_level_2_subnet_0_conn (5000 wts)
    LSTM PeepholeWeights ""level_2_subnet_0_peepholes"" (150 wts)
    Connection level_2_subnet_1_to_level_2_subnet_1_conn_0 (10000 wts)
    Connection bias_to_level_2_subnet_1_conn (200 wts)
    Connection level_1_subsample_to_level_2_subnet_1_conn (5000 wts)
    LSTM PeepholeWeights ""level_2_subnet_1_peepholes"" (150 wts)
    Connection level_2_subnet_0_to_output_conn (9700 wts)
    Connection level_2_subnet_1_to_output_conn (9700 wts)
    Connection bias_to_output_conn (194 wts)

Input sequence is 32 length, output is 194 classes. There are 3 hidden layers with 50 cells each.",4,0
747,2017-2-22,2017,2,22,15,5vh4ae,[R] A new foe has appeared! [1702.06230] Beating the World's Best at Super Smash Bros. with Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/5vh4ae/r_a_new_foe_has_appeared_170206230_beating_the/,evc123,1487744435,,57,153
748,2017-2-22,2017,2,22,15,5vh57t,Is there any detailed literature for application RBF in practical implementation?,https://www.reddit.com/r/MachineLearning/comments/5vh57t/is_there_any_detailed_literature_for_application/,a_dead_shark,1487744810,[removed],0,1
749,2017-2-22,2017,2,22,16,5vhfi5,[D]Embedding vs LSTM or CNN for word vectors?,https://www.reddit.com/r/MachineLearning/comments/5vhfi5/dembedding_vs_lstm_or_cnn_for_word_vectors/,cvikasreddy,1487749502,"When training a rnn which is better way to get word vectors.

Using an embeddings matrix or a character level lstm or CNN to produce word vector.",3,7
750,2017-2-22,2017,2,22,17,5vhl71,Rapid parametric density estimation [1702.02144] - cheap fitting polynomial or Fourier series as density of a sample e.g. for nonlinear classification,https://www.reddit.com/r/MachineLearning/comments/5vhl71/rapid_parametric_density_estimation_170202144/,[deleted],1487752451,[deleted],0,1
751,2017-2-22,2017,2,22,18,5vhoiz,"[R]PixelNet: Representation of the pixels, by the pixels, and for the pixels",https://www.reddit.com/r/MachineLearning/comments/5vhoiz/rpixelnet_representation_of_the_pixels_by_the/,vintermann,1487754231,,10,14
752,2017-2-22,2017,2,22,18,5vhpwq,Clustering layer on top of cnn,https://www.reddit.com/r/MachineLearning/comments/5vhpwq/clustering_layer_on_top_of_cnn/,shgidigo,1487754951,[removed],0,1
753,2017-2-22,2017,2,22,18,5vhtqt,Determine le price of appartment based on the price of the building,https://www.reddit.com/r/MachineLearning/comments/5vhtqt/determine_le_price_of_appartment_based_on_the/,NicData,1487756850,[removed],0,1
754,2017-2-22,2017,2,22,19,5vhwnd,Read-through: Wasserstein GAN,https://www.reddit.com/r/MachineLearning/comments/5vhwnd/readthrough_wasserstein_gan/,[deleted],1487758259,[deleted],0,1
755,2017-2-22,2017,2,22,19,5vhzgv,"[P] One API for Xgboost, LightGBM, Neural Networks, Random Forest, RGF, Extra Trees ...",https://www.reddit.com/r/MachineLearning/comments/5vhzgv/p_one_api_for_xgboost_lightgbm_neural_networks/,pplonski,1487759708,,4,2
756,2017-2-22,2017,2,22,21,5vicll,Hydraulic C Frame Press,https://www.reddit.com/r/MachineLearning/comments/5vicll/hydraulic_c_frame_press/,marketingipan,1487765919,,1,1
757,2017-2-22,2017,2,22,21,5vifps,NVidia TitanX Pascal vs AMD Vega,https://www.reddit.com/r/MachineLearning/comments/5vifps/nvidia_titanx_pascal_vs_amd_vega/,stridera,1487767243,[removed],0,1
758,2017-2-22,2017,2,22,22,5vilwo,R programming,https://www.reddit.com/r/MachineLearning/comments/5vilwo/r_programming/,shantanu_b,1487769508,[removed],0,1
759,2017-2-22,2017,2,22,23,5vj23u,Question about starting to learn ML.,https://www.reddit.com/r/MachineLearning/comments/5vj23u/question_about_starting_to_learn_ml/,iWintermutes,1487774999,[removed],0,1
760,2017-2-23,2017,2,23,0,5vj7hv,"[P] ""Enhanced"" Super Resolution at Home with Autoencoding Adversarial Networks",https://www.reddit.com/r/MachineLearning/comments/5vj7hv/p_enhanced_super_resolution_at_home_with/,[deleted],1487776558,[deleted],2,2
761,2017-2-23,2017,2,23,0,5vjf7u,"Simple Questions Thread February 22, 2017",https://www.reddit.com/r/MachineLearning/comments/5vjf7u/simple_questions_thread_february_22_2017/,AutoModerator,1487778789,[removed],0,3
762,2017-2-23,2017,2,23,0,5vjfq0,[D] Could a machine learning algorithm be designed so as to meaningfully pass an MSR test?,https://www.reddit.com/r/MachineLearning/comments/5vjfq0/d_could_a_machine_learning_algorithm_be_designed/,odradek-feed,1487778933,"Recently an [experiment](http://www.wired.co.uk/article/rhesus-monkey-self-awareness-mirror-test), where Rhesus monkeys were taught how to pass a mirror self recognition test, has invited questions whether some level of self-awareness can be taught. How far fetched would it be to define a suitably general (not specifically designed) algorithm that could be trained to meaningfully pass an MSR test? (I am not sure how to explicitly express what 'meaningful' means in this context, but at a minimum I'd expect the algorithm hasn't been designed to pass a specific MSR test.)",3,1
763,2017-2-23,2017,2,23,1,5vjl3n,Identifying dogs vs cats in images with Python + TensorFlow + Convolutional Neural Network,https://www.reddit.com/r/MachineLearning/comments/5vjl3n/identifying_dogs_vs_cats_in_images_with_python/,sentdex,1487780415,[removed],0,1
764,2017-2-23,2017,2,23,1,5vjq72,Deep Learning Inference is Next Battleground (WaveNet/Baidu Interview),https://www.reddit.com/r/MachineLearning/comments/5vjq72/deep_learning_inference_is_next_battleground/,[deleted],1487781788,[deleted],0,1
765,2017-2-23,2017,2,23,1,5vjqo1,[R] [1602.02215] Swivel: Improving Embeddings by Noticing What's Missing,https://www.reddit.com/r/MachineLearning/comments/5vjqo1/r_160202215_swivel_improving_embeddings_by/,rrenaud,1487781930,,2,8
766,2017-2-23,2017,2,23,1,5vjrqz,[D] Goodfellow et. al. show a linear trajectory in parameter space gave a smooth monotonic curve of training loss...strange?,https://www.reddit.com/r/MachineLearning/comments/5vjrqz/d_goodfellow_et_al_show_a_linear_trajectory_in/,feedthecreed,1487782228,"In this paper, they show a linear trajectory in parameter space from initial to final weights gave a smooth monotonic curve of training loss:

Qualitatively characterizing neural network optimization problems
(https://arxiv.org/abs/1412.6544)

Why does this happen? If you look at Figure 4 in the paper, they're extremely smooth and almost convex.

[Figure 4](http://i.imgur.com/KWy3jWp.png)",4,6
767,2017-2-23,2017,2,23,1,5vjsde,Here's How Stanford are Making Deep Learning Models More Interpretable,https://www.reddit.com/r/MachineLearning/comments/5vjsde/heres_how_stanford_are_making_deep_learning/,reworksophie,1487782381,,0,1
768,2017-2-23,2017,2,23,1,5vjtdk,Microbiome startup looking for collaborators!,https://www.reddit.com/r/MachineLearning/comments/5vjtdk/microbiome_startup_looking_for_collaborators/,gxy4132,1487782655,[removed],0,1
769,2017-2-23,2017,2,23,2,5vjxks,[D] Learning to Act by Predicting the Future,https://www.reddit.com/r/MachineLearning/comments/5vjxks/d_learning_to_act_by_predicting_the_future/,reallydontknowmuch,1487783742,"[pdf link](https://openreview.net/pdf?id=rJLS7qKel)

I wanted to know your opinion on this paper. After a couple of readings, this seems to be very similar to Deep Q-learning, except for the fact that rewards are replaced with 'measurements', which are essentially surrogates for the 'true reward'. 

During test time, the goals are formulated in terms of some required change in measurement and the current best action is chosen in a greedy fashion.

Similarities:

* Experience replay is gathered similar to DQN
* An L2 loss between expected function approximator value and experienced value is computed for optimization
* Follows an epsilon-greedy behavior strategy during training
* Eval time uses an argmax over current actions to choose the best action

Differences:

* Well, it isn't exactly SARSA or Q-learning in its objective. The function approximator tries to predict the change in measurements during training.

What is the reason this works better than DQN? This method doesn't bootstrap like DQN, and looks into more of the future while training ""latest three time steps contribute to the objective function"". Can DQN be modified subtly to be just as good?

Have I missed out on some nuances? Any other insights? Thanks.",5,17
770,2017-2-23,2017,2,23,2,5vjxo9,[R] Cosine Normalization: Using Cosine Similarity Instead of Dot Product in Neural Networks,https://www.reddit.com/r/MachineLearning/comments/5vjxo9/r_cosine_normalization_using_cosine_similarity/,downtownslim,1487783771,,46,21
771,2017-2-23,2017,2,23,3,5vkf2h,"A DNN that takes in x, y and outputs colors at that point to approximately ""paint"" an image",https://www.reddit.com/r/MachineLearning/comments/5vkf2h/a_dnn_that_takes_in_x_y_and_outputs_colors_at/,[deleted],1487788233,[deleted],0,1
772,2017-2-23,2017,2,23,3,5vkhne,[P] Animations of DNN image regression,https://www.reddit.com/r/MachineLearning/comments/5vkhne/p_animations_of_dnn_image_regression/,iverjo,1487788898,,7,3
773,2017-2-23,2017,2,23,4,5vkn2c,[N] Preprocessing for machine learning with tf.Transform,https://www.reddit.com/r/MachineLearning/comments/5vkn2c/n_preprocessing_for_machine_learning_with/,Conchylicultor,1487790267,,10,45
774,2017-2-23,2017,2,23,4,5vkr3d,Three Ways Machine Learning Shapes Customer Experience,https://www.reddit.com/r/MachineLearning/comments/5vkr3d/three_ways_machine_learning_shapes_customer/,Mussem17,1487791304,,0,1
775,2017-2-23,2017,2,23,4,5vkxq8,How to Make a Tensorflow Image Classifier (LIVE),https://www.reddit.com/r/MachineLearning/comments/5vkxq8/how_to_make_a_tensorflow_image_classifier_live/,llSourcell,1487793075,,0,1
776,2017-2-23,2017,2,23,6,5vlltu,[D] Read-through: Wasserstein GAN,https://www.reddit.com/r/MachineLearning/comments/5vlltu/d_readthrough_wasserstein_gan/,alexirpan,1487799472,,15,113
777,2017-2-23,2017,2,23,7,5vlscn,PyTorch Implementation of DeepSpeech2,https://www.reddit.com/r/MachineLearning/comments/5vlscn/pytorch_implementation_of_deepspeech2/,Stormfreek,1487801285,,0,3
778,2017-2-23,2017,2,23,7,5vltcb,GPUs Freaks,https://www.reddit.com/r/MachineLearning/comments/5vltcb/gpus_freaks/,[deleted],1487801551,[removed],0,1
779,2017-2-23,2017,2,23,7,5vlzz9,"[D] ELI5: when you train RBM with maximum likelihood, RBMs are not autoenocoder. Why?",https://www.reddit.com/r/MachineLearning/comments/5vlzz9/d_eli5_when_you_train_rbm_with_maximum_likelihood/,ieatrat,1487803381,"I like to have an intuitive explanation why it's not the case.




Note: Before you guys redirect me to r/learnmachinelearning or r/nn4ml,  I didn't get any answer there. I hope researchers over here can help me out.



https://www.reddit.com/r/nn4ml/comments/5vcclv/eli5_when_trained_with_maximum_likelihood_rbms/?st=IZHJJE7Z&amp;sh=c8a333bf",13,2
780,2017-2-23,2017,2,23,8,5vm8fs,[D] How to handle training data in TensorFlow?,https://www.reddit.com/r/MachineLearning/comments/5vm8fs/d_how_to_handle_training_data_in_tensorflow/,cbeak,1487805532,"* What are the advantages of TensorFlow's classes for handling training data, e.g. `tf.TFRecordReader`?
* How much preprocessing (decoding JPEG, mean subtraction, augmentation) should be done during training?
* What is the best data format to store the data in?

I've been looking for tutorials on this, but I could not find anything helpful so far.",12,8
781,2017-2-23,2017,2,23,10,5vn44i,[D] Paper submission and conferences (ICCV/ICML),https://www.reddit.com/r/MachineLearning/comments/5vn44i/d_paper_submission_and_conferences_iccvicml/,sleeppropagation,1487813520,"After working on a personal project for a few months and designing a ResNet variant that performs pretty well, I'm considering submitting a paper to either ICML or ICCV (ICML's deadline is not an issue, I finished the paper a few weeks ago). However, I have 0 experience with ML conferences.

Would ICCV be more suited for a project of this sort? I have good CIFAR10/100 results, along with experiments showing faster convergence and so on. The model is still a ResNet by nature, so it's mostly aimed for vision tasks. There's not much theory behind it, and I also heard that ICML expects a bit of theory along with experiments.
",14,10
782,2017-2-23,2017,2,23,11,5vnm8w,[D] Any databases for recipes? Or a way I could crawl Food Network type site?,https://www.reddit.com/r/MachineLearning/comments/5vnm8w/d_any_databases_for_recipes_or_a_way_i_could/,tusharc17,1487818341,,4,4
783,2017-2-23,2017,2,23,12,5vnotr,[R] [1702.06676] Counterfactual Control for Free from Generative Models,https://www.reddit.com/r/MachineLearning/comments/5vnotr/r_170206676_counterfactual_control_for_free_from/,NichG,1487819050,,6,16
784,2017-2-23,2017,2,23,12,5vnym8,[R] Shake-Shake regularization of 3-branch residual networks: new SOTA on CIFAR-10 (2.72%),https://www.reddit.com/r/MachineLearning/comments/5vnym8/r_shakeshake_regularization_of_3branch_residual/,[deleted],1487821603,[deleted],1,1
785,2017-2-23,2017,2,23,12,5vo14r,[R] Shake-Shake regularization of 3-branch residual networks: new SOTA on CIFAR-10 (2.72%),https://www.reddit.com/r/MachineLearning/comments/5vo14r/r_shakeshake_regularization_of_3branch_residual/,xternalz,1487822303,,22,7
786,2017-2-23,2017,2,23,13,5vo5t0,How much would I limit my future ML job options by only getting a Master's instead of PhD?,https://www.reddit.com/r/MachineLearning/comments/5vo5t0/how_much_would_i_limit_my_future_ml_job_options/,chris2point0,1487823600,[removed],0,1
787,2017-2-23,2017,2,23,13,5vocqd,Any suggestion on choosing p(z) in generative adversarial networks?,https://www.reddit.com/r/MachineLearning/comments/5vocqd/any_suggestion_on_choosing_pz_in_generative/,xjwxjw,1487825617,[removed],0,1
788,2017-2-23,2017,2,23,13,5voe0b,How to create corpus from multiple docx files,https://www.reddit.com/r/MachineLearning/comments/5voe0b/how_to_create_corpus_from_multiple_docx_files/,chai_17,1487825999,[removed],0,1
789,2017-2-23,2017,2,23,17,5vpapm,Konkasr Tesisi,https://www.reddit.com/r/MachineLearning/comments/5vpapm/konkasr_tesisi/,Fabo_Company,1487838176,,0,1
790,2017-2-23,2017,2,23,18,5vpkyw,Visual Discovery at Pinterest,https://www.reddit.com/r/MachineLearning/comments/5vpkyw/visual_discovery_at_pinterest/,mks_repi,1487843611,,0,1
791,2017-2-23,2017,2,23,19,5vpnuh,"[Webinar]: Machine Learning in a Live Production Environment by Matthew Kirk, author of Thoughtful Machine Learning with Python",https://www.reddit.com/r/MachineLearning/comments/5vpnuh/webinar_machine_learning_in_a_live_production/,NarendhiranS,1487845033,,0,1
792,2017-2-23,2017,2,23,19,5vprjb,Wow! So does the JCT 300L dual planetary mixer outlooking look like this...,https://www.reddit.com/r/MachineLearning/comments/5vprjb/wow_so_does_the_jct_300l_dual_planetary_mixer/,mixmachinery,1487846906,,1,1
793,2017-2-23,2017,2,23,19,5vpse0,How are SVMs = Template Matching?,https://www.reddit.com/r/MachineLearning/comments/5vpse0/how_are_svms_template_matching/,svmmvs,1487847331,,0,1
794,2017-2-23,2017,2,23,19,5vpskq,[Discussion] DenseCap with non-bounding-box region proposals,https://www.reddit.com/r/MachineLearning/comments/5vpskq/discussion_densecap_with_nonboundingbox_region/,guardianhelm,1487847437,"In the [DenseCap](https://arxiv.org/abs/1511.07571) paper, p2, 3.1.2, the following is mentioned:

&gt; we replace their RoI pooling mechanism with bilinear interpolation, allowing our model to propagate gradients backward through the coordinates of predicted regions. This modification opens up the possibility of predicting affine of morphed region proposals instead of bounding boxes, but we leave these extensions to future work.

Has there been any follow up work to that? Could this mean that the resulting bounding boxes can be replaced with, for instance, segment proposals?",2,3
795,2017-2-23,2017,2,23,20,5vpv3e,Portable Edge Banders Machine,https://www.reddit.com/r/MachineLearning/comments/5vpv3e/portable_edge_banders_machine/,casadeibusellato,1487848697,[removed],0,1
796,2017-2-23,2017,2,23,20,5vpw95,[PDF] Design and Analysis of an APU for Exascale Computing  r/HPC,https://www.reddit.com/r/MachineLearning/comments/5vpw95/pdf_design_and_analysis_of_an_apu_for_exascale/,eleitl,1487849242,,0,1
797,2017-2-24,2017,2,24,0,5vqtxd,Next quarter CS231n will be taught by Justin/Serena/Fei-Fei &amp; available on Stanford's SCPD,https://www.reddit.com/r/MachineLearning/comments/5vqtxd/next_quarter_cs231n_will_be_taught_by/,finallyifoundvalidUN,1487862022,[removed],0,1
798,2017-2-24,2017,2,24,0,5vr09l,[P] A startup is making an intelligent assistant like SIRI that allows you to train it to understand new phrases through pattern recognition.,https://www.reddit.com/r/MachineLearning/comments/5vr09l/p_a_startup_is_making_an_intelligent_assistant/,joshthegeek94,1487863866,,0,0
799,2017-2-24,2017,2,24,0,5vr191,Working with Fashion Models,https://www.reddit.com/r/MachineLearning/comments/5vr191/working_with_fashion_models/,stereobits,1487864155,,0,1
800,2017-2-24,2017,2,24,0,5vr5hb,"Introducing Perspective, using machine learning to improve discussions online.",https://www.reddit.com/r/MachineLearning/comments/5vr5hb/introducing_perspective_using_machine_learning_to/,ImhugeinJapan99,1487865357,,0,1
801,2017-2-24,2017,2,24,0,5vr687,Developers tools for quick chatbot prototyping: Chatfuel + Gomix + QnAMaker,https://www.reddit.com/r/MachineLearning/comments/5vr687/developers_tools_for_quick_chatbot_prototyping/,bogsformer,1487865574,,4,16
802,2017-2-24,2017,2,24,0,5vr694,[D] What would you do with unlimited computing power?,https://www.reddit.com/r/MachineLearning/comments/5vr694/d_what_would_you_do_with_unlimited_computing_power/,ma2rten,1487865580,"I read recently that [Andrew Ng said](https://www.technologyreview.com/s/603062/ai-winter-isnt-coming/) the current progress in deep learning will continue for the foreseeable future, because of new hardware developments.

That lead me to this question: If someone came from the future and dropped a GPU that is orders of magnitudes faster on your desk, what would you do with it?",114,31
803,2017-2-24,2017,2,24,1,5vr935,What type of optimization problem is this? Reconstruction?,https://www.reddit.com/r/MachineLearning/comments/5vr935/what_type_of_optimization_problem_is_this/,ronronweasley,1487866364,[removed],0,1
804,2017-2-24,2017,2,24,3,5vrybw,[d] what linux do I need in my windows to run it?,https://www.reddit.com/r/MachineLearning/comments/5vrybw/d_what_linux_do_i_need_in_my_windows_to_run_it/,[deleted],1487873117,[removed],2,0
805,2017-2-24,2017,2,24,3,5vs82h,Using AI to Stay One Step Ahead of Cyber Criminals,https://www.reddit.com/r/MachineLearning/comments/5vs82h/using_ai_to_stay_one_step_ahead_of_cyber/,Mistalee_6,1487875634,,0,1
806,2017-2-24,2017,2,24,4,5vscrd,[P] Automatic download &amp; parse script for the new YouTube-BoundingBoxes dataset,https://www.reddit.com/r/MachineLearning/comments/5vscrd/p_automatic_download_parse_script_for_the_new/,failrocket,1487876864,,2,9
807,2017-2-24,2017,2,24,4,5vsk99,[D] SSD or HDD for deep learning?,https://www.reddit.com/r/MachineLearning/comments/5vsk99/d_ssd_or_hdd_for_deep_learning/,Pieranha,1487878853,"I'm training a lot of deep neural networks on my dedicated GPU machine using large datasets of sizes ~100 GB. Lately, I've had 2 relatively new HDDs fail on me, which is quite frustrating.

Now I'm considering reconfiguring my machine to make it more stable and in this context whether I should buy SSDs or traditional HDDs. I've seen some guides on building rigs for deep learning, but they don't talk that much about hard drives. What are your experiences? Would you recommend going with an SSD or a traditional HDD?",17,0
808,2017-2-24,2017,2,24,5,5vt17h,[N] Machine Learning is Ushering In a New Age of Customer Service,https://www.reddit.com/r/MachineLearning/comments/5vt17h/n_machine_learning_is_ushering_in_a_new_age_of/,DataScienceInc,1487883349,,0,0
809,2017-2-24,2017,2,24,6,5vt5s8,"[P] Gorgonia (which is like TF/Theano but in Go) now supports CUDA Ops. Also, Help Wanted.",https://www.reddit.com/r/MachineLearning/comments/5vt5s8/p_gorgonia_which_is_like_tftheano_but_in_go_now/,chewxy,1487884524,"Hello,

I'm the author of [gorgonia](https://github.com/chewxy/gorgonia), which is a graph computation library in vein of Theano/TensorFlow written in Go. And I'm happy to announce that Gorgonia now supports CUDA Ops (well, rudimentary ones).

# The Ask #

1. Play with Gorgonia - build neural networks in it. Write K-means algorithms, SVM algorithms (well, this is more the `tensor` package)! They say all bugs are shallow given enough eyeballs. I'd like the bugs in Gorgonia to be found and fixed.
2. I need help with CUDA, and its kernels. Write more CUDA kernels. If possible, use cuDNN. Contributors welcome. My goal is having a CUDA kernel for every Op in Gorgonia.
3. I need help with distributed computing. Distributed gradient descent is very very difficult to get right. And  difficult to test. 
4. Implement papers in Gorgonia! Well, I can hope. Every academic institution has their own framework. And those who don't, use TF/Theano. 
5. Test allthethings! My goal is for Gorgonia to hit 90% test coverage.  Right now it's at 75%. A big concern for me is larger data sets. The datasets I use in my daily work are about 300k - 1.2M elements in a matrix/tensor... so they're quite small. I need to think of things such as when the data cannot fit in memory and the like.
6. Help write documentation for Gorgonia. At the past 2 Go meetups I've been to, I've been told that Gorgonia has a number of features (such as that Gorgonia comes with a bunch of gradient descent optimizers) that without digging further, would go unnoticed. There is currently an [open issue](https://github.com/chewxy/gorgonia/issues/80) with regards to this. Pull requests are welcome.

# FAQ #

1. **Yet Another Deep Learning Library?** Yes. Sadly. There has been an explosion of deep learning libraries, but not one for Go. Furthermore, Gorgonia works at a much lower level than most deep learning libraries. 
2. **Why?** The main reason why I wrote Gorgonia was mainly because a few years ago, installing and deploying Theano was a pain in the ass. With Go it was easy - compile into a single executable binary, and run. I wrote more about the reasons [here](https://blog.chewxy.com/2016/09/19/gorgonia/) and [here](https://github.com/chewxy/gorgonia#why-use-gorgonia). Also, Go is a really nice language to use. 
3. **X operation is not supported!** Gorgonia was written such that it is easy to add ops. However, if you do write a convolution op or `im2col` and/or `col2im`, please do send a PR - that's been on my TODO list for years. 
4. **How does Gorgonia compare to Tensorflow?**  For the operations I use Gorgonia for (generally NLP stuff -  dependency parsing, word vectors, attention mechanisms etc), the speeds are comparable. The benefit for me is of course it's very easy to install and deploy. Obviously Gorgonia cannot do stuff like distributed learning yet, but I'm working on it. Gorgonia also doesn't do fusion of ops yet, but that is also on the horizon.",16,3
810,2017-2-24,2017,2,24,6,5vt8ii,Has anyone used the following ensemble meta-algorithm for supervised learning?,https://www.reddit.com/r/MachineLearning/comments/5vt8ii/has_anyone_used_the_following_ensemble/,cthulu0,1487885254,[removed],0,1
811,2017-2-24,2017,2,24,7,5vtkon,[N] Deep Learning 101 - Reference Materials,https://www.reddit.com/r/MachineLearning/comments/5vtkon/n_deep_learning_101_reference_materials/,beamsearch,1487888572,"I didn't know if I should post this here or at /r/LearnMachineLearning,  but here is a set of materials I created to help new comers get up to speed with deep learning. 

Slides:
Deep Learning 101: http://slides.com/beamandrew/deep-learning-101#/

Blog posts:
Deep Learning 101 - Part 1: History and Background: http://beamandrew.github.io/deeplearning/2017/02/23/deep_learning_101_part1.html

Deep Learning 101 - Part 2: Multilayer Perceptrons: http://beamandrew.github.io/deeplearning/2017/02/23/deep_learning_101_part2.html

Video: 
Open Insights | Harvard Medical School | 23 February 2017 - https://youtu.be/xuIKzt5G21c",8,190
812,2017-2-24,2017,2,24,7,5vtpm6,"[P] Another Tensorflow implementation of fast neural style transfer. Initially did this as an exercise, but I figured it could be useful to others!",https://www.reddit.com/r/MachineLearning/comments/5vtpm6/p_another_tensorflow_implementation_of_fast/,redbeard1991,1487890023,,2,57
813,2017-2-24,2017,2,24,8,5vtu1s,Would RNN work well for predicting final cumulative sales in a time series?,https://www.reddit.com/r/MachineLearning/comments/5vtu1s/would_rnn_work_well_for_predicting_final/,TheRealDJ,1487891304,[removed],0,1
814,2017-2-24,2017,2,24,8,5vtxd5,ELI5: Deep Learning vs. Non-Deep Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5vtxd5/eli5_deep_learning_vs_nondeep_machine_learning/,m0kka,1487892260,[removed],0,1
815,2017-2-24,2017,2,24,9,5vu5x9,What is the difference between Octave and scikit-learn?,https://www.reddit.com/r/MachineLearning/comments/5vu5x9/what_is_the_difference_between_octave_and/,throwawaynamesbtaken,1487894854,[removed],0,1
816,2017-2-24,2017,2,24,10,5vuqlm,Beginner Project?,https://www.reddit.com/r/MachineLearning/comments/5vuqlm/beginner_project/,yjacket103,1487901261,[removed],0,1
817,2017-2-24,2017,2,24,11,5vuss8,How does the chemical conical screw mixer deal with the powder,https://www.reddit.com/r/MachineLearning/comments/5vuss8/how_does_the_chemical_conical_screw_mixer_deal/,mixmachinery,1487901956,,1,1
818,2017-2-24,2017,2,24,12,5vv3av,Possible New AGI Deep Neural Network Structure; Seeking Constructive Criticism,https://www.reddit.com/r/MachineLearning/comments/5vv3av/possible_new_agi_deep_neural_network_structure/,JonoExplainsThings,1487905408,,0,1
819,2017-2-24,2017,2,24,13,5vviox,Using Deep Learning and Google Street View to Estimate the Demographic Makeup of the US,https://www.reddit.com/r/MachineLearning/comments/5vviox/using_deep_learning_and_google_street_view_to/,finallyifoundvalidUN,1487910664,,0,2
820,2017-2-24,2017,2,24,13,5vvj1j,[R] Learning to Play Chess Like Human Players,https://www.reddit.com/r/MachineLearning/comments/5vvj1j/r_learning_to_play_chess_like_human_players/,2014mchidamb,1487910783,,4,16
821,2017-2-24,2017,2,24,16,5vw4ps,[P] Audio Data Collection Project,https://www.reddit.com/r/MachineLearning/comments/5vw4ps/p_audio_data_collection_project/,DCRTre,1487919666,[removed],0,0
822,2017-2-24,2017,2,24,16,5vw6ts,The Mathematics of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5vw6ts/the_mathematics_of_machine_learning/,parry243,1487920677,,0,1
823,2017-2-24,2017,2,24,16,5vw754,What is the liquid silicone rubber molding mixing machine?,https://www.reddit.com/r/MachineLearning/comments/5vw754/what_is_the_liquid_silicone_rubber_molding_mixing/,mixmachinery,1487920840,,1,1
824,2017-2-24,2017,2,24,16,5vw9v3,[D] Is there anyone tried RBM on collaborative filtering system?,https://www.reddit.com/r/MachineLearning/comments/5vw9v3/d_is_there_anyone_tried_rbm_on_collaborative/,kwonmha,1487922221,"Found a paper by Ruslan Salakhutdinov, Geoffrey Hinton(http://www.machinelearning.org/proceedings/icml2007/papers/407.pdf), 

and implementation code by other guy on Github(https://github.com/erwtokritos/collaborativefiltering-rbm).

Tested with it but didn't have good result(precision) as the paper said.

Wondering someone tried and got results corresponding to the paper.",3,4
825,2017-2-24,2017,2,24,17,5vwhv6,Face Recognition with Deep Learning,https://www.reddit.com/r/MachineLearning/comments/5vwhv6/face_recognition_with_deep_learning/,gavlaaaaaaaa,1487926581,,0,1
826,2017-2-24,2017,2,24,18,5vwndd,Online Workshop - Deep Dream and neural style transfer - matching deep learning with art,https://www.reddit.com/r/MachineLearning/comments/5vwndd/online_workshop_deep_dream_and_neural_style/,annkov,1487929572,,0,1
827,2017-2-24,2017,2,24,20,5vwzco,Exploring Machine Learning at OpenAI &amp;amp; Google With the Experts,https://www.reddit.com/r/MachineLearning/comments/5vwzco/exploring_machine_learning_at_openai_amp_google/,teamrework,1487935705,,0,1
828,2017-2-24,2017,2,24,20,5vwzks,Conoce nuestras prensas de segunda mano,https://www.reddit.com/r/MachineLearning/comments/5vwzks/conoce_nuestras_prensas_de_segunda_mano/,Barriuso,1487935820,,0,1
829,2017-2-24,2017,2,24,20,5vx0oh,"[R] Toddlers' grammar skills are learned, not innate",https://www.reddit.com/r/MachineLearning/comments/5vx0oh/r_toddlers_grammar_skills_are_learned_not_innate/,pmigdal,1487936387,,20,21
830,2017-2-24,2017,2,24,22,5vxgiv,[R][1702.07097] Bidirectional Backpropagation: Towards Biologically Plausible Error Signal Transmission in Neural Networks,https://www.reddit.com/r/MachineLearning/comments/5vxgiv/r170207097_bidirectional_backpropagation_towards/,rilut,1487943241,,25,31
831,2017-2-24,2017,2,24,22,5vxjf7,"[D] For truncated BPTT, has anyone gone into depth on whether maintaining LSTM state across minibatches makes a difference?",https://www.reddit.com/r/MachineLearning/comments/5vxjf7/d_for_truncated_bptt_has_anyone_gone_into_depth/,carlthome,1487944328,"When doing BPTT with RNNs we have to maintain T timesteps in memory, but sequences are often much longer. For audio data, for example, one second of material is at least 16000 timesteps. Thus in practice sequences must be split into pieces, and BPTT have to be truncated.

A trick that I've seen is that people maintain the RNN's hidden state across minibatches for pieces belonging to the same underlying sequence, instead of doing the usual thing and just setting the first hidden state to zeroes for every minibatch.

Is there a study on whether conditioning the initial state over partitions of sequences like this actually make any difference (and if it does, for what proportions of actual sequence lengths vs. RNN timesteps does it matter?).",18,14
832,2017-2-24,2017,2,24,23,5vxu55,I've create a site where you can download fake datasets to test your implementations of machine learning algorithms.,https://www.reddit.com/r/MachineLearning/comments/5vxu55/ive_create_a_site_where_you_can_download_fake/,CommentKillah,1487947836,[removed],0,1
833,2017-2-25,2017,2,25,0,5vy5ll,LibRec 2.0 has been released: recommender system based on machine learning,https://www.reddit.com/r/MachineLearning/comments/5vy5ll/librec_20_has_been_released_recommender_system/,Liuxz,1487951162,,0,1
834,2017-2-25,2017,2,25,1,5vy9lf,Check Fraud,https://www.reddit.com/r/MachineLearning/comments/5vy9lf/check_fraud/,quant17898,1487952257,[removed],0,1
835,2017-2-25,2017,2,25,1,5vyi20,Machine Learning in Python Learning Path (12 hours + of free resources),https://www.reddit.com/r/MachineLearning/comments/5vyi20/machine_learning_in_python_learning_path_12_hours/,[deleted],1487954583,[deleted],0,1
836,2017-2-25,2017,2,25,1,5vyisz,How Temporal Memory works in HTM,https://www.reddit.com/r/MachineLearning/comments/5vyisz/how_temporal_memory_works_in_htm/,numenta,1487954781,,0,1
837,2017-2-25,2017,2,25,2,5vyqej,Wasserstein GAN and the Kantorovich-Rubinstein Duality,https://www.reddit.com/r/MachineLearning/comments/5vyqej/wasserstein_gan_and_the_kantorovichrubinstein/,[deleted],1487956815,[deleted],0,1
838,2017-2-25,2017,2,25,2,5vyslk,[D] Wasserstein GAN and the Kantorovich-Rubinstein Duality,https://www.reddit.com/r/MachineLearning/comments/5vyslk/d_wasserstein_gan_and_the_kantorovichrubinstein/,vidivinci,1487957423,,12,89
839,2017-2-25,2017,2,25,4,5vzh3u,[D] Localized Crowdsourced Dashcam Footage as a Service for Training SDC Neural Networks (Student Project; feedback wanted),https://www.reddit.com/r/MachineLearning/comments/5vzh3u/d_localized_crowdsourced_dashcam_footage_as_a/,[deleted],1487964015,[deleted],0,2
840,2017-2-25,2017,2,25,4,5vzoou,Any good papers on generative models for tabular data?,https://www.reddit.com/r/MachineLearning/comments/5vzoou/any_good_papers_on_generative_models_for_tabular/,gajenjung,1487966127,[removed],0,1
841,2017-2-25,2017,2,25,7,5w0iky,Visual Segmentation Of Chromosomal Preparations,https://www.reddit.com/r/MachineLearning/comments/5w0iky/visual_segmentation_of_chromosomal_preparations/,[deleted],1487974604,[deleted],0,1
842,2017-2-25,2017,2,25,7,5w0ixm,Uniform Stability and Generalization in Learning theory,https://www.reddit.com/r/MachineLearning/comments/5w0ixm/uniform_stability_and_generalization_in_learning/,brandojazz,1487974702,,0,1
843,2017-2-25,2017,2,25,10,5w1lyn,[P] Vehicle Detection using Machine Learning and Computer Vision,https://www.reddit.com/r/MachineLearning/comments/5w1lyn/p_vehicle_detection_using_machine_learning_and/,upulbandara,1487987102,,8,14
844,2017-2-25,2017,2,25,12,5w1zbs,How to Predict Stock Prices Easily - Intro to Deep Learning #7,https://www.reddit.com/r/MachineLearning/comments/5w1zbs/how_to_predict_stock_prices_easily_intro_to_deep/,llSourcell,1487991944,,0,1
845,2017-2-25,2017,2,25,13,5w27zs,Pytorch implementation of Hierarchical Attention Networks for Document Classification,https://www.reddit.com/r/MachineLearning/comments/5w27zs/pytorch_implementation_of_hierarchical_attention/,rahulkulhari3,1487995295,,0,1
846,2017-2-25,2017,2,25,14,5w2obe,[P] Visual Segmentation Of Chromosomal Preparations,https://www.reddit.com/r/MachineLearning/comments/5w2obe/p_visual_segmentation_of_chromosomal_preparations/,abhaikollara,1488002094,,3,3
847,2017-2-25,2017,2,25,15,5w2sec,AI learns to write its own code by stealing from other programs,https://www.reddit.com/r/MachineLearning/comments/5w2sec/ai_learns_to_write_its_own_code_by_stealing_from/,mks_repi,1488003985,,0,1
848,2017-2-25,2017,2,25,19,5w3fsq,The easy guide for building python collaborative filtering recommendation system in 2017,https://www.reddit.com/r/MachineLearning/comments/5w3fsq/the_easy_guide_for_building_python_collaborative/,JunJieJ,1488017032,,0,1
849,2017-2-25,2017,2,25,19,5w3g1n,How Zendesk serves Tensorflow models in production,https://www.reddit.com/r/MachineLearning/comments/5w3g1n/how_zendesk_serves_tensorflow_models_in_production/,[deleted],1488017181,[deleted],0,1
850,2017-2-25,2017,2,25,19,5w3gji,CNTK vs PyTorch?,https://www.reddit.com/r/MachineLearning/comments/5w3gji/cntk_vs_pytorch/,eshansingh,1488017436,[removed],0,1
851,2017-2-25,2017,2,25,20,5w3opr,Mua my ra xe  u tt,https://www.reddit.com/r/MachineLearning/comments/5w3opr/mua_my_ra_xe__u_tt/,mayruaxejetta,1488022187,,0,1
852,2017-2-25,2017,2,25,20,5w3q74,[D] So... Pytorch vs Tensorflow: what's the verdict on how they compare? What are their individual strong points?,https://www.reddit.com/r/MachineLearning/comments/5w3q74/d_so_pytorch_vs_tensorflow_whats_the_verdict_on/,cjmcmurtrie,1488023038,"Have any users here had extensive experience with both? What are your main concerns or delights with both libraries?

I never made a switch from Torch7 to Tensorflow. I played around with Tensorflow but I always found Torch7 more intuitive (maybe I didn't play around enough!). I also had a tip that Pytorch was on the way, so decided I would wait for that.

After a few weeks using Pytorch, I don't think I'll be moving to Tensorflow any time soon, at least for my passion projects. It's ridiculously simple to write custom modules in Pytorch, and the dynamic graph construction is giving me so many ideas for things that previously would've been achieved by late-night hacks (and possibly put on the wait list). I think Pytorch is an incredible toolset for a machine learning developer. I realise that the wealth of community resources is much stronger for Tensorflow, but when working on novel projects (instead of re-coding known architectures or reading tutorials) this isn't always much help.

Thoughts?",52,179
853,2017-2-25,2017,2,25,20,5w3ras,Predicting the 2017 Oscar Winners using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5w3ras/predicting_the_2017_oscar_winners_using_machine/,czuriaga,1488023690,,0,2
854,2017-2-25,2017,2,25,21,5w3tao,The use of symbolism on sentiment analysis,https://www.reddit.com/r/MachineLearning/comments/5w3tao/the_use_of_symbolism_on_sentiment_analysis/,iqra1804,1488024800,[removed],0,1
855,2017-2-25,2017,2,25,23,5w489b,What word2vec is all about,https://www.reddit.com/r/MachineLearning/comments/5w489b/what_word2vec_is_all_about/,scvalencia,1488032049,,0,1
856,2017-2-25,2017,2,25,23,5w48ki,[P] How I built and configured Fenton (my data crunching machine),https://www.reddit.com/r/MachineLearning/comments/5w48ki/p_how_i_built_and_configured_fenton_my_data/,navoshta,1488032181,,21,64
857,2017-2-25,2017,2,25,23,5w49zw,Drilling into Sparks ALS Recommendation algorithm,https://www.reddit.com/r/MachineLearning/comments/5w49zw/drilling_into_sparks_als_recommendation_algorithm/,datumbox,1488032794,,0,1
858,2017-2-26,2017,2,26,0,5w4gld,What is Learning To Rank?,https://www.reddit.com/r/MachineLearning/comments/5w4gld/what_is_learning_to_rank/,softwaredoug,1488035352,,0,1
859,2017-2-26,2017,2,26,1,5w4wcs,"Would it make more sense to buy a 980 for SLI with my current 980, or invest in a single 1080?",https://www.reddit.com/r/MachineLearning/comments/5w4wcs/would_it_make_more_sense_to_buy_a_980_for_sli/,[deleted],1488040746,[removed],0,1
860,2017-2-26,2017,2,26,1,5w502o,[D] Is ICLR as good as NIPS/ICML?,https://www.reddit.com/r/MachineLearning/comments/5w502o/d_is_iclr_as_good_as_nipsicml/,elder_price666,1488041947,"PhD student here studying ML/DL. 

Another student in my lab who is going on the academic job market next year actually chose not to submit his deep learning paper to ICLR and waited until the ICML deadline. His reasoning was that an ICML publication is going to help him much more in academic circles (as opposed to industry research applications). In my (somewhat biased) view the paper is certainly good enough to get have gotten into both.

Having looked at a bunch of papers from ICLR, I can't help but notice that the quality seems to be lower than NIPS/ICML papers (though certainly, this is not to imply that all NIPS/ICML papers are categorically excellent). I was especially surprised by some of the papers that were chosen for oral presentations.

Of course, in an ideal world these things wouldn't matter, but in reality publication venue matters a lot. Would love to hear others' thoughts on this.",9,5
861,2017-2-26,2017,2,26,2,5w59bl,[R] [1611.02252] Hierarchical compositional feature learning - Vicarious,https://www.reddit.com/r/MachineLearning/comments/5w59bl/r_161102252_hierarchical_compositional_feature/,CyberByte,1488044857,,16,18
862,2017-2-26,2017,2,26,3,5w5haz,"Blitzkrieg 3 claims worlds first RTS neural net, Boris",https://www.reddit.com/r/MachineLearning/comments/5w5haz/blitzkrieg_3_claims_worlds_first_rts_neural_net/,schwin42,1488047355,,0,1
863,2017-2-26,2017,2,26,3,5w5maj,Image Completion with Deep Learning in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/5w5maj/image_completion_with_deep_learning_in_tensorflow/,interseption,1488048913,,0,1
864,2017-2-26,2017,2,26,4,5w5oll,[D] Spatial Transformer Networks - Why Not More Commonly Used?,https://www.reddit.com/r/MachineLearning/comments/5w5oll/d_spatial_transformer_networks_why_not_more/,mtngld,1488049621,"After reading http://torch.ch/blog/2015/09/07/spatial_transformers.html, I wonder why [STNs](https://arxiv.org/abs/1506.02025) are not more common and integrated in every classification neural net.

Was there any attempt to combine it with ResNet/Inception for CIFAR10/ImageNet? Couldn't find any attempts to do so.

Why hasn't it become a common building block (like batch norm for example)?",4,8
865,2017-2-26,2017,2,26,4,5w5pgw,wikipedia / word embedding / wikilinks,https://www.reddit.com/r/MachineLearning/comments/5w5pgw/wikipedia_word_embedding_wikilinks/,dobkeratops,1488049892,[removed],0,1
866,2017-2-26,2017,2,26,5,5w64uo,[P] Serving Tensorflow in production at Zendesk,https://www.reddit.com/r/MachineLearning/comments/5w64uo/p_serving_tensorflow_in_production_at_zendesk/,cdiddiest,1488054592,,14,62
867,2017-2-26,2017,2,26,5,5w69db,Machine Learning from scratch: Bare bones implementations in Python,https://www.reddit.com/r/MachineLearning/comments/5w69db/machine_learning_from_scratch_bare_bones/,[deleted],1488056002,[deleted],0,1
868,2017-2-26,2017,2,26,6,5w6bh1,[P] Machine Learning from scratch: Bare bones implementations in Python,https://www.reddit.com/r/MachineLearning/comments/5w6bh1/p_machine_learning_from_scratch_bare_bones/,[deleted],1488056659,[deleted],2,0
869,2017-2-26,2017,2,26,6,5w6c5k,[P] Super-Resolution using Coordinate-Based Neural Networks,https://www.reddit.com/r/MachineLearning/comments/5w6c5k/p_superresolution_using_coordinatebased_neural/,liviu-,1488056871,,21,58
870,2017-2-26,2017,2,26,6,5w6iau,"Deep Video Analytics: A visual search platform built using pytorch, tensorflow, darknet, django/postgres/celery, docker/nvidia-docker. Customizable and comes with a tested AMI/docker containers. [project]",https://www.reddit.com/r/MachineLearning/comments/5w6iau/deep_video_analytics_a_visual_search_platform/,aub3cornell,1488058759,,3,33
871,2017-2-26,2017,2,26,7,5w6r4u,Machine learning and python,https://www.reddit.com/r/MachineLearning/comments/5w6r4u/machine_learning_and_python/,jinthagerman,1488061468,[removed],0,1
872,2017-2-26,2017,2,26,7,5w6rgp,Help with TensorFlow GPU error please!,https://www.reddit.com/r/MachineLearning/comments/5w6rgp/help_with_tensorflow_gpu_error_please/,PlatinumNinja72,1488061578,[removed],0,1
873,2017-2-26,2017,2,26,7,5w6si0,[D] Tools for creating datasets for computer vision tasks (particularly segmentation/detection)?,https://www.reddit.com/r/MachineLearning/comments/5w6si0/d_tools_for_creating_datasets_for_computer_vision/,andyandy16,1488061896,"Regarding the main types of computer vision tasks (see this fantastic slide explaining the differences:http://vision.stanford.edu/teaching/cs231n/slides/winter1516_lecture13.pdf#page=18), do you have any good tools for creating such datasets?

Some I have found:

* Detection: https://github.com/cvhciKIT/sloth
* Segmentation: https://github.com/AKSHAYUBHAT/ImageSegmentation could possibly be tweaked to assist labelling

(Alternatively, are they methods to perform such tasks without extensive datasets, maybe something like attention mechanisms or spatial transformer networks?)",3,1
874,2017-2-26,2017,2,26,7,5w6t43,Why isn't there a commercially available AI bot that makes connecting APIs trivial and automatic?,https://www.reddit.com/r/MachineLearning/comments/5w6t43/why_isnt_there_a_commercially_available_ai_bot/,Vespco,1488062098,[removed],0,1
875,2017-2-26,2017,2,26,8,5w72s0,Adversarial Neural Cryptography implemented in Tensorflow,https://www.reddit.com/r/MachineLearning/comments/5w72s0/adversarial_neural_cryptography_implemented_in/,[deleted],1488065214,[deleted],0,1
876,2017-2-26,2017,2,26,8,5w76vl,Adversarial Neural Cryptography Implemented in Tensorflow,https://www.reddit.com/r/MachineLearning/comments/5w76vl/adversarial_neural_cryptography_implemented_in/,msokoloff1,1488066591,,0,2
877,2017-2-26,2017,2,26,9,5w7941,Reprogramming the Human Genome with AI featuring Brendan Frey - This Week in Machine Learning &amp; AI Podcast,https://www.reddit.com/r/MachineLearning/comments/5w7941/reprogramming_the_human_genome_with_ai_featuring/,sbc1906,1488067341,,1,1
878,2017-2-26,2017,2,26,9,5w7ixo,[R] Variational Reference Priors,https://www.reddit.com/r/MachineLearning/comments/5w7ixo/r_variational_reference_priors/,adagrad,1488070715,,21,6
879,2017-2-26,2017,2,26,10,5w7jh2,Can the size of a Neural Networks training data cause it to fail to complete training?,https://www.reddit.com/r/MachineLearning/comments/5w7jh2/can_the_size_of_a_neural_networks_training_data/,Zippy0723,1488070893,[removed],0,1
880,2017-2-26,2017,2,26,11,5w82qj,Really Quick Questions with a Tensorflow Engineer,https://www.reddit.com/r/MachineLearning/comments/5w82qj/really_quick_questions_with_a_tensorflow_engineer/,llSourcell,1488077996,,0,1
881,2017-2-26,2017,2,26,12,5w86un,Machine Learning from scratch: Bare bones implementations in Python,https://www.reddit.com/r/MachineLearning/comments/5w86un/machine_learning_from_scratch_bare_bones/,iamkeyur,1488079548,,0,1
882,2017-2-26,2017,2,26,15,5w8tq8,Transforming Autoencoders and Spatial Transformer Networks,https://www.reddit.com/r/MachineLearning/comments/5w8tq8/transforming_autoencoders_and_spatial_transformer/,Dark_Element75,1488089301,[removed],0,1
883,2017-2-26,2017,2,26,15,5w8uev,An initial exploration of WikiReading  Googles huge new NLP dataset,https://www.reddit.com/r/MachineLearning/comments/5w8uev/an_initial_exploration_of_wikireading_googles/,rochea,1488089626,,0,1
884,2017-2-26,2017,2,26,18,5w9edx,50 Companies Leading the Artificial Intelligence Revolution,https://www.reddit.com/r/MachineLearning/comments/5w9edx/50_companies_leading_the_artificial_intelligence/,iamondemand,1488101174,,0,1
885,2017-2-26,2017,2,26,19,5w9iwg,[R] Making Neural Programming Architectures Generalize via Recursion,https://www.reddit.com/r/MachineLearning/comments/5w9iwg/r_making_neural_programming_architectures/,mehdidc,1488104007,,2,35
886,2017-2-26,2017,2,26,19,5w9kyk,Deep Learning for Speech and Language Winter School 2017 @ UPC TelecomBCN (slides &amp; video),https://www.reddit.com/r/MachineLearning/comments/5w9kyk/deep_learning_for_speech_and_language_winter/,xavigiro,1488105359,,0,5
887,2017-2-26,2017,2,26,21,5w9y20,[D] What are the mathematical concept should I learn to get a good hold in Machine Learning and AI??,https://www.reddit.com/r/MachineLearning/comments/5w9y20/d_what_are_the_mathematical_concept_should_i/,[deleted],1488113165,[deleted],8,0
888,2017-2-26,2017,2,26,22,5wa62y,[Discussion] Master Studies in Machine Learning (Europe),https://www.reddit.com/r/MachineLearning/comments/5wa62y/discussion_master_studies_in_machine_learning/,thepiwo,1488117145,"Hello Guys,

I am searching for oportunities to study machine learning as master programme anywhere in europe.

I've already researched a bit and found that most recommended studies are offered at US universities only.

I found the machine learning master in Stockholm:
https://www.kth.se/en/studies/master/machinelearning/description-1.48533

But I want to know if you have more suggestions.
Kind Regards

Edit: Thank you all for the great recommendations and inspiration! ",72,58
889,2017-2-26,2017,2,26,22,5wa6z8,regression using deep networks,https://www.reddit.com/r/MachineLearning/comments/5wa6z8/regression_using_deep_networks/,reddit_tl,1488117569,[removed],0,1
890,2017-2-27,2017,2,27,2,5wb8gr,Developing a Self-Driving car - Diary,https://www.reddit.com/r/MachineLearning/comments/5wb8gr/developing_a_selfdriving_car_diary/,Shadow992,1488130632,,0,1
891,2017-2-27,2017,2,27,4,5wbsrh,Make an Object Detector-Recogniser,https://www.reddit.com/r/MachineLearning/comments/5wbsrh/make_an_object_detectorrecogniser/,[deleted],1488136642,[removed],0,1
892,2017-2-27,2017,2,27,4,5wbxml,[P] Making an Object Detector-Recognizer,https://www.reddit.com/r/MachineLearning/comments/5wbxml/p_making_an_object_detectorrecognizer/,sid3695,1488138030,"As the title suggests, I would love to make an object detector-recogniser, something similar to the api's in this blog. ( https://goberoi.com/comparing-the-top-five-computer-vision-apis-98e3e3d7c647#.xhcoa1gqh ).

I know it's very difficult to attain the accuracy similar to those api's but if i make a rudimentary object detection, which tags images having a car/pet/food; I will be pretty happy that I got to get a feel of the technology behind such apis.

What according to you, is a suitable approach to attain decent results? ",2,3
893,2017-2-27,2017,2,27,4,5wbyhe,Summary of 'Programs With Common Sense' (1959) by John McCarthy,https://www.reddit.com/r/MachineLearning/comments/5wbyhe/summary_of_programs_with_common_sense_1959_by/,[deleted],1488138281,[deleted],0,1
894,2017-2-27,2017,2,27,4,5wc10j,"Comma ai, computer vision challenge. Any suggestions on solving it?",https://www.reddit.com/r/MachineLearning/comments/5wc10j/comma_ai_computer_vision_challenge_any/,YourSuperheroine,1488139034,,0,1
895,2017-2-27,2017,2,27,5,5wc3nk,"I want to work for OpenAI, but I haven't had enough research experience as an undergrad so far to get into a quality grad school.",https://www.reddit.com/r/MachineLearning/comments/5wc3nk/i_want_to_work_for_openai_but_i_havent_had_enough/,[deleted],1488139787,[removed],0,1
896,2017-2-27,2017,2,27,5,5wc7a7,Is there any guide on how to construct the right NN model?,https://www.reddit.com/r/MachineLearning/comments/5wc7a7/is_there_any_guide_on_how_to_construct_the_right/,x86inerupt,1488140839,[removed],0,1
897,2017-2-27,2017,2,27,5,5wc8es,The neural net I've created can predict changes in the future. Is there any new value here?,https://www.reddit.com/r/MachineLearning/comments/5wc8es/the_neural_net_ive_created_can_predict_changes_in/,[deleted],1488141172,[removed],0,1
898,2017-2-27,2017,2,27,5,5wcaj6,Predictive NN that can indicate the direction of change. Is there any new value here?,https://www.reddit.com/r/MachineLearning/comments/5wcaj6/predictive_nn_that_can_indicate_the_direction_of/,[deleted],1488141795,[deleted],1,2
899,2017-2-27,2017,2,27,5,5wccdj,[D] US billionaire helped to back Brexit using machine learning expertise,https://www.reddit.com/r/MachineLearning/comments/5wccdj/d_us_billionaire_helped_to_back_brexit_using/,T-zex,1488142340,,0,1
900,2017-2-27,2017,2,27,6,5wcgof,[P] Ligand binding affinity prediction using deep learning,https://www.reddit.com/r/MachineLearning/comments/5wcgof/p_ligand_binding_affinity_prediction_using_deep/,bergi_bergos,1488143588,"Ligand binding affinity prediction using deep learning 

I've implemented ligand binding affinity prediction using deep learning and also wrote a blog post about it. The post doesn't cover only the technical stuff, but also a little bit the history of the idea:

https://www.bergnet.org/2017/02/ligand-binding-deep-learning/

It uses SMILES token to feed the neural network with the molecule structures. I'm using alternative representations for data augmentation, which wasn't used by similar projects before. The training is done with Keras Gaia, which was developed for this project. It simplifies the training process for different models and datasets. The SPARQL wrapper for BindingDB could be of interest for anyone who would like to fetch BindingDB data using ChEMBL queries. I also implemented a SMILES parser in JavaScript, because there wasn't any implementation available.",10,4
901,2017-2-27,2017,2,27,6,5wcp23,[P] I created a self-learning car for the browser. And I just wanted to get the word out there and hear your feedback! :),https://www.reddit.com/r/MachineLearning/comments/5wcp23/p_i_created_a_selflearning_car_for_the_browser/,greedypablo,1488146083,,20,92
902,2017-2-27,2017,2,27,7,5wcwg9,A question about FANN vs other libraries,https://www.reddit.com/r/MachineLearning/comments/5wcwg9/a_question_about_fann_vs_other_libraries/,Jrowe47,1488148265,[removed],0,1
903,2017-2-27,2017,2,27,10,5wdyss,[D] Machine Learning Model Management,https://www.reddit.com/r/MachineLearning/comments/5wdyss/d_machine_learning_model_management/,abbeyruss,1488160367,"How do you keep track of machine learning models as you iterate over them?

How do you compare the performance of different models/data sets?

What are some pain points in your workflow?

(Doing research for an open source model management system, any input is appreciated!)

github.com/mitdbg/modeldb",11,8
904,2017-2-27,2017,2,27,11,5we1v4,Why shouldn't I simply add the probabilities in naive bayes? I'm getting a higher accuracy rate when I do that in this case,https://www.reddit.com/r/MachineLearning/comments/5we1v4/why_shouldnt_i_simply_add_the_probabilities_in/,compute_,1488161393,[removed],0,0
905,2017-2-27,2017,2,27,11,5we3bk,Generative Adversarial Networks - plausible analog for certain kinds of memory/cognitive processes in the brain?,https://www.reddit.com/r/MachineLearning/comments/5we3bk/generative_adversarial_networks_plausible_analog/,torvoraptor,1488161868,[removed],0,1
906,2017-2-27,2017,2,27,11,5we7sn,Understanding style transfer learning,https://www.reddit.com/r/MachineLearning/comments/5we7sn/understanding_style_transfer_learning/,[deleted],1488163426,[deleted],0,1
907,2017-2-27,2017,2,27,11,5we92l,Can you do machine learning without a PhD?,https://www.reddit.com/r/MachineLearning/comments/5we92l/can_you_do_machine_learning_without_a_phd/,[deleted],1488163877,[removed],0,1
908,2017-2-27,2017,2,27,11,5we9p0,Training with SLI Titan Xs?,https://www.reddit.com/r/MachineLearning/comments/5we9p0/training_with_sli_titan_xs/,wisp5,1488164092,[removed],0,1
909,2017-2-27,2017,2,27,12,5weat6,Distributed and automatic hyperparameter optimization for any machine learning model made simple,https://www.reddit.com/r/MachineLearning/comments/5weat6/distributed_and_automatic_hyperparameter/,[deleted],1488164452,[deleted],0,1
910,2017-2-27,2017,2,27,12,5weeom,[Discussion] Why are RNNs so slow in (Py)Torch?,https://www.reddit.com/r/MachineLearning/comments/5weeom/discussion_why_are_rnns_so_slow_in_pytorch/,metacurse,1488165791,"I was going through the extensive benchmarking done here: http://dlbench.comp.hkbu.edu.hk/?v=v7#intro

One thing that stood out was how bad Torch's LSTM numbers were:
LSTM being trained with batch size of 64 on GTX980:
    CNTK: 17ms	MXNET:46ms	TensorFlow:62ms	Torch: 199ms

Proportionally, it remains worse across all batch sizes and machines compared to other frameworks.

This is counter-intuitive since I believed Torch to be pretty fast across the board. Can long time Torchies and knowledgeable people on the subject chime in as to why this is the case?",5,9
911,2017-2-27,2017,2,27,12,5wefai,Look! let me show you how does the horizontal ribbon powder mixer work,https://www.reddit.com/r/MachineLearning/comments/5wefai/look_let_me_show_you_how_does_the_horizontal/,mixmachinery,1488165995,,1,1
912,2017-2-27,2017,2,27,16,5wfiab,Summary of 'Programs With Common Sense' (1959) by John McCarthy,https://www.reddit.com/r/MachineLearning/comments/5wfiab/summary_of_programs_with_common_sense_1959_by/,hackjoy,1488181365,,0,1
913,2017-2-27,2017,2,27,17,5wfmhc,The top five ways that AI is transforming banking,https://www.reddit.com/r/MachineLearning/comments/5wfmhc/the_top_five_ways_that_ai_is_transforming_banking/,jo_kruger,1488183457,,0,1
914,2017-2-27,2017,2,27,18,5wfrmw,Is that a Duplicate Quora Question?,https://www.reddit.com/r/MachineLearning/comments/5wfrmw/is_that_a_duplicate_quora_question/,[deleted],1488186216,[deleted],0,1
915,2017-2-27,2017,2,27,19,5wfxy1,"Interpretability: the Next Deep Learning Challenge (Interview with Charlie Tang, Research Scientist at Apple)",https://www.reddit.com/r/MachineLearning/comments/5wfxy1/interpretability_the_next_deep_learning_challenge/,reworksophie,1488189606,,0,1
916,2017-2-27,2017,2,27,19,5wg2mr,"Your IDE won't change, but YOU will: HELLO! Machine learning",https://www.reddit.com/r/MachineLearning/comments/5wg2mr/your_ide_wont_change_but_you_will_hello_machine/,keysertomasa,1488191950,,0,1
917,2017-2-27,2017,2,27,19,5wg31i,[P] Distributed and automatic hyperparameter optimization for any machine learning model,https://www.reddit.com/r/MachineLearning/comments/5wg31i/p_distributed_and_automatic_hyperparameter/,marcjschmidt,1488192180,,29,7
918,2017-2-27,2017,2,27,21,5wgecr,[R] [1701.07274] Deep Reinforcement Learning: An Overview,https://www.reddit.com/r/MachineLearning/comments/5wgecr/r_170107274_deep_reinforcement_learning_an/,jakn,1488197686,,8,125
919,2017-2-27,2017,2,27,21,5wgg47,CVPR 2017 results are out!,https://www.reddit.com/r/MachineLearning/comments/5wgg47/cvpr_2017_results_are_out/,ehku,1488198442,,0,1
920,2017-2-27,2017,2,27,22,5wgqe8,Who has the expertise on the linear bandit combined with dimension reduction technique in this AAAI 17 paper?,https://www.reddit.com/r/MachineLearning/comments/5wgqe8/who_has_the_expertise_on_the_linear_bandit/,[deleted],1488202395,[deleted],0,1
921,2017-2-27,2017,2,27,22,5wgqhi,How to evaluate model performance on time series streams?,https://www.reddit.com/r/MachineLearning/comments/5wgqhi/how_to_evaluate_model_performance_on_time_series/,ichumuh,1488202435,"I've been trying to detect pattern in time series streams.
As training examples, I can just extract short subsequences from a stream recording, that contain the pattern.
But how do I evaluate it's performance on an actual stream?

Lets assume, that I'm trying to detect some kind of motion in body worn sensors.
I have a classifier that predicts true or false for a input sequence of length X.
The classifier would try to detect an event after every new sensor reading.
If I know when the motion was executed, how do I define a true positive? There has to be some kind of tolerance range.
What do I do, if my classifier says true for two successive sequences? Both TP, one TP one FP?
There are a lot of problems like this and I have not found guidelines and a lot of papers seem to not really care about this problem.

Do you know of any guidelines?",13,2
922,2017-2-27,2017,2,27,22,5wgrgd,[R] [1611.04076v2] Least Squares Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/5wgrgd/r_161104076v2_least_squares_generative/,skagnitty,1488202768,,3,21
923,2017-2-27,2017,2,27,23,5wh2wb,[D] Machine Learning - WAYR (What Are You Reading) - Week 20,https://www.reddit.com/r/MachineLearning/comments/5wh2wb/d_machine_learning_wayr_what_are_you_reading_week/,Mandrathax,1488206646,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|
|----|-----|
|[Week 1](https://www.reddit.com/r/MachineLearning/comments/4qyjiq/machine_learning_wayr_what_are_you_reading_week_1/)|[Week 11](https://www.reddit.com/r/MachineLearning/comments/57xw56/discussion_machine_learning_wayr_what_are_you/)|
|[Week 2](https://www.reddit.com/r/MachineLearning/comments/4s2xqm/machine_learning_wayr_what_are_you_reading_week_2/)|[Week 12](https://www.reddit.com/r/MachineLearning/comments/5acb1t/d_machine_learning_wayr_what_are_you_reading_week/)|
|[Week 3](https://www.reddit.com/r/MachineLearning/comments/4t7mqm/machine_learning_wayr_what_are_you_reading_week_3/)|[Week 13](https://www.reddit.com/r/MachineLearning/comments/5cwfb6/d_machine_learning_wayr_what_are_you_reading_week/)|
|[Week 4](https://www.reddit.com/r/MachineLearning/comments/4ub2kw/machine_learning_wayr_what_are_you_reading_week_4/)|[Week 14](https://www.reddit.com/r/MachineLearning/comments/5fc5mh/d_machine_learning_wayr_what_are_you_reading_week/)|
|[Week 5](https://www.reddit.com/r/MachineLearning/comments/4xomf7/machine_learning_wayr_what_are_you_reading_week_5/)|[Week 15](https://www.reddit.com/r/MachineLearning/comments/5hy4ur/d_machine_learning_wayr_what_are_you_reading_week/)|
|[Week 6](https://www.reddit.com/r/MachineLearning/comments/4zcyvk/machine_learning_wayr_what_are_you_reading_week_6/)|[Week 16](https://www.reddit.com/r/MachineLearning/comments/5kd6vd/d_machine_learning_wayr_what_are_you_reading_week/)|
|[Week 7](https://www.reddit.com/r/MachineLearning/comments/52t6mo/machine_learning_wayr_what_are_you_reading_week_7/)|[Week 17](https://www.reddit.com/r/MachineLearning/comments/5ob7dx/discussion_machine_learning_wayr_what_are_you/)|
|[Week 8](https://www.reddit.com/r/MachineLearning/comments/53heol/machine_learning_wayr_what_are_you_reading_week_8/)|[Week 18](https://www.reddit.com/r/MachineLearning/comments/5r14yd/discussion_machine_learning_wayr_what_are_you/)|
|[Week 9](https://www.reddit.com/r/MachineLearning/comments/54kvsu/machine_learning_wayr_what_are_you_reading_week_9/)|[Week 19](https://www.reddit.com/r/MachineLearning/comments/5tt9cz/discussion_machine_learning_wayr_what_are_you/)|
|[Week 10](https://www.reddit.com/r/MachineLearning/comments/56s2oa/discussion_machine_learning_wayr_what_are_you/)|

Most upvoted paper last week :

[Learning to Play Guess Who? and Inventing a Grounded Language as a Consequence](https://arxiv.org/abs/1611.03218)

[Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning](https://arxiv.org/abs/1509.08731)

Besides that, there are no rules, have fun.
",2,13
924,2017-2-27,2017,2,27,23,5wh3zt,Using Deep Learning and Google Street View to Estimate the Demographic Makeup of the US,https://www.reddit.com/r/MachineLearning/comments/5wh3zt/using_deep_learning_and_google_street_view_to/,pendragonn,1488207009,,0,1
925,2017-2-28,2017,2,28,0,5wh7eu,[Research] Can dimension reductions improve the learning performance of the linear bandit?,https://www.reddit.com/r/MachineLearning/comments/5wh7eu/research_can_dimension_reductions_improve_the/,[deleted],1488208090,[deleted],0,1
926,2017-2-28,2017,2,28,0,5wh7pg,Very Deep Neural Network to Detect Duplicate Quora Questions,https://www.reddit.com/r/MachineLearning/comments/5wh7pg/very_deep_neural_network_to_detect_duplicate/,abhisvnit,1488208172,,0,1
927,2017-2-28,2017,2,28,0,5wha4m,[D] EKF training of RNNs - is it used?,https://www.reddit.com/r/MachineLearning/comments/5wha4m/d_ekf_training_of_rnns_is_it_used/,xristaforante,1488208886,"I am referring to Jaeger's tutorial ([.pdf](http://minds.jacobs-university.de/sites/default/files/uploads/papers/ESNTutorialRev.pdf)) which states that EKF + TBTTT generally give the best results on RNN training (middle of page 20). I see reference to very good convergence elsewhere because of curvature information exploitation, i.e. fast convergence on noiseless linear systems. But most of the materials I can find are from the late nineties. Did the method fall out of favor for some reason (e.g. second order methods cost too much)?",4,1
928,2017-2-28,2017,2,28,0,5whdo1,[p] Prophet: forecasting at scale (Facebook),https://www.reddit.com/r/MachineLearning/comments/5whdo1/p_prophet_forecasting_at_scale_facebook/,singularvalue,1488209968,,0,81
929,2017-2-28,2017,2,28,1,5whper,On-Device Machine Intelligence,https://www.reddit.com/r/MachineLearning/comments/5whper/ondevice_machine_intelligence/,[deleted],1488213295,[deleted],0,1
930,2017-2-28,2017,2,28,1,5whsz6,"[P] A curated list of Sentiment Analysis methods, implementations and misc",https://www.reddit.com/r/MachineLearning/comments/5whsz6/p_a_curated_list_of_sentiment_analysis_methods/,xiamx,1488214274,,4,11
931,2017-2-28,2017,2,28,1,5wht2l,Toy data sets/environments for deep reinforcement learning which can be used for model building easily and fast?,https://www.reddit.com/r/MachineLearning/comments/5wht2l/toy_data_setsenvironments_for_deep_reinforcement/,[deleted],1488214301,[removed],0,1
932,2017-2-28,2017,2,28,2,5whv56,[D]Toy data sets/environments for deep reinforcement learning which can be used for model building easily and fast?,https://www.reddit.com/r/MachineLearning/comments/5whv56/dtoy_data_setsenvironments_for_deep_reinforcement/,commafighter,1488214861,"When we start machine learning we mostly starts with iris dataset which can be trained very fast and easily. I learned many of the classification ML algorithms using this dataset because its easier to work with small dataset and it will train very fast in my low config machine.


Is there any similar alternative data sets for deep reinforcement learning? So far the simplest environment I find was OpenAI's GYM cart-pole environment using only state values and rewards. But even that still takes a longer time(more than an hour) to converge to a solution in a simple DQN.


Is there any other simpler alternative toy environments (Python) where I can implement RL networks such as DQN easily and fast.

*These are for learning purpose only*
",1,8
933,2017-2-28,2017,2,28,2,5whwls,[Research] On-Device Machine Intelligence,https://www.reddit.com/r/MachineLearning/comments/5whwls/research_ondevice_machine_intelligence/,ankeshanand,1488215270,,1,39
934,2017-2-28,2017,2,28,3,5wibsk,"[P] pytorch/vision: Datasets, Transforms and Models specific to Computer Vision (VGG, ResNet, SqueezeNet) in PyTorch",https://www.reddit.com/r/MachineLearning/comments/5wibsk/p_pytorchvision_datasets_transforms_and_models/,pmigdal,1488219328,,0,13
935,2017-2-28,2017,2,28,3,5wictp,Tuning hyperparams fast with Hyperband,https://www.reddit.com/r/MachineLearning/comments/5wictp/tuning_hyperparams_fast_with_hyperband/,gwulfs,1488219612,,0,2
936,2017-2-28,2017,2,28,4,5wincf,Stop saying DeepCoder steals code from StackOverflow,https://www.reddit.com/r/MachineLearning/comments/5wincf/stop_saying_deepcoder_steals_code_from/,[deleted],1488222363,[deleted],0,1
937,2017-2-28,2017,2,28,4,5wio0v,[P] UNREAL  UNsupervised REinforcement Auxiliary Learning,https://www.reddit.com/r/MachineLearning/comments/5wio0v/p_unreal_unsupervised_reinforcement_auxiliary/,cctap,1488222547,,1,2
938,2017-2-28,2017,2,28,5,5wj0hv,What do you think about Chris Blattman's skepticism on UBI?,https://www.reddit.com/r/MachineLearning/comments/5wj0hv/what_do_you_think_about_chris_blattmans/,dendisuhubdy,1488225850,,0,1
939,2017-2-28,2017,2,28,5,5wj4we,[D] [Meta] Tags for posts - should we add [E] for [Explanation]?,https://www.reddit.com/r/MachineLearning/comments/5wj4we/d_meta_tags_for_posts_should_we_add_e_for/,pmigdal,1488227013,"I often struggle with tagging blog posts, which are tutorials or explanations of methods. While they provide a lot of value, they don't easy fit into [Research]/[News]/[Project] split. I tag them as [P], albeit - reluctantly.

If [Blog]/[B] seems to general/vague (since a lot of research or projects are on some blog), then maybe [E] for [Explanation] should be worth considering. 

What are your thoughts?

",1,1
940,2017-2-28,2017,2,28,5,5wj5x5,You are building a self driving AI without even knowing about it,https://www.reddit.com/r/MachineLearning/comments/5wj5x5/you_are_building_a_self_driving_ai_without_even/,downmoney,1488227261,,0,1
941,2017-2-28,2017,2,28,5,5wj6gq,[P] PyTorch Implementation of GLoVe,https://www.reddit.com/r/MachineLearning/comments/5wj6gq/p_pytorch_implementation_of_glove/,2014mchidamb,1488227394,,4,12
942,2017-2-28,2017,2,28,6,5wjfr7,Deep Learning: Not Just for Silicon Valley,https://www.reddit.com/r/MachineLearning/comments/5wjfr7/deep_learning_not_just_for_silicon_valley/,[deleted],1488229870,[deleted],0,1
943,2017-2-28,2017,2,28,6,5wjgpq,Cheapest processor for a gtx 1060 ?,https://www.reddit.com/r/MachineLearning/comments/5wjgpq/cheapest_processor_for_a_gtx_1060/,buddhagonebad,1488230123,[removed],0,1
944,2017-2-28,2017,2,28,6,5wjlg2,[P] Deep Learning: Not Just for Silicon Valley,https://www.reddit.com/r/MachineLearning/comments/5wjlg2/p_deep_learning_not_just_for_silicon_valley/,math_rachel,1488231356,,1,0
945,2017-2-28,2017,2,28,6,5wjnz9,[P] NeuroJS - A javascript deep learning and reinforcement learning library,https://www.reddit.com/r/MachineLearning/comments/5wjnz9/p_neurojs_a_javascript_deep_learning_and/,whateverr123,1488231987,,4,15
946,2017-2-28,2017,2,28,6,5wjo2b,Where are the ILSVRC2016 technical reports,https://www.reddit.com/r/MachineLearning/comments/5wjo2b/where_are_the_ilsvrc2016_technical_reports/,insider_7,1488232009,[removed],0,1
947,2017-2-28,2017,2,28,7,5wjvtk,Style transfer for text using Neural Networks,https://www.reddit.com/r/MachineLearning/comments/5wjvtk/style_transfer_for_text_using_neural_networks/,mihaitensor,1488234026,[removed],0,1
948,2017-2-28,2017,2,28,7,5wjxha,[P] A Neural Network That Learns How to Draw a Path,https://www.reddit.com/r/MachineLearning/comments/5wjxha/p_a_neural_network_that_learns_how_to_draw_a_path/,fthrkl,1488234450,,1,10
949,2017-2-28,2017,2,28,8,5wkbqd,Maximize your Learning How to Apply Machine Learning Practices into your own life.  Tradecraft,https://www.reddit.com/r/MachineLearning/comments/5wkbqd/maximize_your_learning_how_to_apply_machine/,rmant,1488238391,,0,1
950,2017-2-28,2017,2,28,10,5wl145,Graphs as inputs to neural networks,https://www.reddit.com/r/MachineLearning/comments/5wl145/graphs_as_inputs_to_neural_networks/,bronzestick,1488245880,[removed],0,1
951,2017-2-28,2017,2,28,11,5wlaj5,[Discussion] [D] Why could the regret bound of linear bandit be improved by random projection?,https://www.reddit.com/r/MachineLearning/comments/5wlaj5/discussion_d_why_could_the_regret_bound_of_linear/,[deleted],1488248782,,12,4
952,2017-2-28,2017,2,28,11,5wlgjc,[Deep Learning]Pooling along one axis(say x) gives around 10 times more accuracy than pooling along the other axis(say y). Not sure how to interpret this.,https://www.reddit.com/r/MachineLearning/comments/5wlgjc/deep_learningpooling_along_one_axissay_x_gives/,trollinginmyskin,1488250658,[removed],0,1
953,2017-2-28,2017,2,28,12,5wlhuz,[p] NVIDIA DGX-1 Supercomputer: Join our Community-Based Deep Learning Benchmark,https://www.reddit.com/r/MachineLearning/comments/5wlhuz/p_nvidia_dgx1_supercomputer_join_our/,drwebb,1488251096,,0,0
954,2017-2-28,2017,2,28,12,5wlkxj,What algorithm would you recommend to solve a clustering problem by pattern similarity in large data sets?,https://www.reddit.com/r/MachineLearning/comments/5wlkxj/what_algorithm_would_you_recommend_to_solve_a/,cdableu,1488252079,[removed],0,1
955,2017-2-28,2017,2,28,12,5wlmgf,How to use readline() function in R language #RPROGRAMMING,https://www.reddit.com/r/MachineLearning/comments/5wlmgf/how_to_use_readline_function_in_r_language/,tejarampooniya,1488252582,,0,1
956,2017-2-28,2017,2,28,12,5wlqm2,Do you know well about the reactor agitator blade design?,https://www.reddit.com/r/MachineLearning/comments/5wlqm2/do_you_know_well_about_the_reactor_agitator_blade/,mixmachinery,1488253976,,1,1
957,2017-2-28,2017,2,28,15,5wmcyu,Fast and Scalable Machine Learning with GoLang,https://www.reddit.com/r/MachineLearning/comments/5wmcyu/fast_and_scalable_machine_learning_with_golang/,mks_repi,1488261819,,0,1
958,2017-2-28,2017,2,28,15,5wmfch,[R] [1702.08431] Boundary-Seeking Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/5wmfch/r_170208431_boundaryseeking_generative/,aeuc,1488262736,,11,33
959,2017-2-28,2017,2,28,16,5wmpud,[R] On the Origin of Deep Learning,https://www.reddit.com/r/MachineLearning/comments/5wmpud/r_on_the_origin_of_deep_learning/,mttd,1488267412,,21,38
960,2017-2-28,2017,2,28,18,5wn4mo,"Funded PhD studentships in machine learning, at University of Essex, UK",https://www.reddit.com/r/MachineLearning/comments/5wn4mo/funded_phd_studentships_in_machine_learning_at/,michael14f,1488275138,,0,1
961,2017-2-28,2017,2,28,20,5wnham,generative adversarial network,https://www.reddit.com/r/MachineLearning/comments/5wnham/generative_adversarial_network/,ansu1234,1488281377,[removed],0,1
962,2017-2-28,2017,2,28,21,5wnrq6,Artificial Intelligence and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5wnrq6/artificial_intelligence_and_machine_learning/,[deleted],1488285938,[deleted],0,1
963,2017-2-28,2017,2,28,23,5wo4me,Tarih Kodlamal Etiketleme Makinas,https://www.reddit.com/r/MachineLearning/comments/5wo4me/tarih_kodlamal_etiketleme_makinas/,[deleted],1488290534,[removed],0,1
964,2017-2-28,2017,2,28,23,5wob2s,One class SVM -- Anamoly detection -- help required,https://www.reddit.com/r/MachineLearning/comments/5wob2s/one_class_svm_anamoly_detection_help_required/,MLkam,1488292591,[removed],0,1
965,2017-2-28,2017,2,28,23,5woeqj,Tarih Kodlamal Etiketleme Makinas,https://www.reddit.com/r/MachineLearning/comments/5woeqj/tarih_kodlamal_etiketleme_makinas/,renasmakinatr,1488293764,[removed],0,1
