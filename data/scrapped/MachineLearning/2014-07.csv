,sbr,sbr_id,date,year,month,hour,day,id,domain,title,full_link,author,created,selftext,num_comments,score,over_18,thumbnail,media_provider,media_thumbnail,media_title,media_description,media_url
0,MachineLearning,t5_2r3gv,2014-7-1,2014,7,1,16,29jnbk,machineryequipment123.blogspot.com,Mobile Crushers Are On The Move - Machinery &amp; Equipment Part Online,https://www.reddit.com/r/MachineLearning/comments/29jnbk/mobile_crushers_are_on_the_move_machinery/,jessicperson,1404198814,,0,1,False,default,,,,,
1,MachineLearning,t5_2r3gv,2014-7-1,2014,7,1,21,29k2p4,dataconomy.com,IBM's Chef Watson: Using Data to Delight Your Tastebuds,https://www.reddit.com/r/MachineLearning/comments/29k2p4/ibms_chef_watson_using_data_to_delight_your/,[deleted],1404217374,,4,12,False,default,,,,,
2,MachineLearning,t5_2r3gv,2014-7-1,2014,7,1,21,29k48v,self.MachineLearning,"Are the data dimensions independent after applying PCA to the data? If yes, why?",https://www.reddit.com/r/MachineLearning/comments/29k48v/are_the_data_dimensions_independent_after/,velosheep,1404218786,,6,2,False,self,,,,,
3,MachineLearning,t5_2r3gv,2014-7-1,2014,7,1,23,29keji,self.MachineLearning,Generalized Additive Neural Networks,https://www.reddit.com/r/MachineLearning/comments/29keji/generalized_additive_neural_networks/,sidk,1404226468,"So I'm working on a research problem.And I need to learn about something called ""Generalized Additive Neural Networks"" and apply them on data sets.Now since there are hardly any tutorials available(and I'm a undergrad) how should I study them?",4,2,False,self,,,,,
4,MachineLearning,t5_2r3gv,2014-7-2,2014,7,2,1,29kqaa,accesswire.com,Discovery of Nature's Transistor Inspires General-purpose Neural Processor,https://www.reddit.com/r/MachineLearning/comments/29kqaa/discovery_of_natures_transistor_inspires/,NeuroCode1,1404233600,,4,4,False,http://b.thumbs.redditmedia.com/xObb3OIm0t-tQ-ye.jpg,,,,,
5,MachineLearning,t5_2r3gv,2014-7-2,2014,7,2,4,29l8y0,self.MachineLearning,New to nlp and ml. Tried to automatically generate a stopword list for any language. Failed.,https://www.reddit.com/r/MachineLearning/comments/29l8y0/new_to_nlp_and_ml_tried_to_automatically_generate/,gardinal,1404244341,"Disclaimer : I am really new to everything, and actually just completed the first week of ML MOOC on Coursera. I've had good experience in nlp, and currently am developing for Tatoeba as part of Google Summer of Code. I am about to start the last year of college.

I was fooling around with Frequency Distributions when I thought I could automatically generate list of stopwords for each language given a good sizeable corpus in that language. I assumed that stopwords would be the most frequent and I was proven wrong by myself when I tinkered with some data and plots. 

[Here](http://hashcomment.blogspot.in/2014/07/why-clipping-of-frequency-distribution.html), I have documented the whole experiement. 

Again, I am really new to the concepts, and I could have done something horribly wrong, but I am here to learn. Share constructive criticism.

Also, if I had to cluster or clip the graph, what would have been the correct method to do so?",0,1,False,self,,,,,
6,MachineLearning,t5_2r3gv,2014-7-2,2014,7,2,6,29lgm3,self.MachineLearning,Neural Net Rorschach Test,https://www.reddit.com/r/MachineLearning/comments/29lgm3/neural_net_rorschach_test/,GratefulTony,1404249045,"If anyone happens to have a trained image-recognition net laying around, it might be fun to see what the top classification categories are for the Rorschach ink blot test cards...

http://en.wikipedia.org/wiki/Rorschach_inkblot_test",7,20,False,self,,,,,
7,MachineLearning,t5_2r3gv,2014-7-2,2014,7,2,6,29liju,self.MachineLearning,L1 penalty on the activation values?,https://www.reddit.com/r/MachineLearning/comments/29liju/l1_penalty_on_the_activation_values/,rishok,1404250384,"Glorot presents in his paper  ( Deep Sparse Rectier Neural Networks
) his idea to penalize activation values with L1 norm in order to to use the relu function for an autoencoder.

Does anybody know how it is done?
",4,4,False,self,,,,,
8,MachineLearning,t5_2r3gv,2014-7-2,2014,7,2,10,29m4q5,dataconomy.com,Big Data Proving to Be A Real Challenge for Data Scientists,https://www.reddit.com/r/MachineLearning/comments/29m4q5/big_data_proving_to_be_a_real_challenge_for_data/,[deleted],1404265218,,1,0,False,default,,,,,
9,MachineLearning,t5_2r3gv,2014-7-2,2014,7,2,16,29mtfd,machines4u.altervista.org,The Unique Structure And Working Principle Of Vibrating Screen,https://www.reddit.com/r/MachineLearning/comments/29mtfd/the_unique_structure_and_working_principle_of/,jessicperson,1404285822,,0,1,False,default,,,,,
10,MachineLearning,t5_2r3gv,2014-7-2,2014,7,2,17,29mvhl,machineryequipment123.blogspot.com,The Unique Type Of Stone Crusher - Machinery &amp; Equipment Part Online,https://www.reddit.com/r/MachineLearning/comments/29mvhl/the_unique_type_of_stone_crusher_machinery/,jessicperson,1404288287,,0,1,False,default,,,,,
11,MachineLearning,t5_2r3gv,2014-7-2,2014,7,2,23,29ng3a,self.MachineLearning,Please recommend some good books on Genetic Algorithms.,https://www.reddit.com/r/MachineLearning/comments/29ng3a/please_recommend_some_good_books_on_genetic/,Privarchy,1404310344,"This question was [asked three years ago](http://www.reddit.com/r/MachineLearning/comments/cquuu/please_recommend_a_good_book_on_genetic_algorithms/) and there's nothing really for it in the FAQ, so I think it is time for an update, especially considering how much this subreddit has grown. For reference, the books posted in that thread were:

* *Genetic Algorithms in Search, Optimization, and Machine Learning* by David E. Goldberg
* *An Introduction to Genetic Algorithms* by Melanie Mitchell
* *Practical Genetic Algorithms* by Randy L. Haupt and Sue Ellen Haup
* [*Essentials of Metaheuristics: Lecture Notes* by Sean Luke](http://cs.gmu.edu/~sean/book/metaheuristics/)

If possible please suggest some more, wholly for my greedy selfish self, although others might benefit in the future. Any criticism you have of the books posted above would be welcome too (*x* is out of date, *y* is just wrong, *z* ran away with my wife, etcetera). Thank you!",4,3,False,self,,,,,
12,MachineLearning,t5_2r3gv,2014-7-2,2014,7,2,23,29ni0g,github.com,"A collection of useful, freely available datasets for machine learning experiments",https://www.reddit.com/r/MachineLearning/comments/29ni0g/a_collection_of_useful_freely_available_datasets/,rasbt,1404311661,,8,80,False,http://a.thumbs.redditmedia.com/tf6XtV6Xxn07wX4B.jpg,,,,,
13,MachineLearning,t5_2r3gv,2014-7-2,2014,7,2,23,29njot,self.MachineLearning,Good Machine Learning methods for mix of discrete (categorical) and continuous features?,https://www.reddit.com/r/MachineLearning/comments/29njot/good_machine_learning_methods_for_mix_of_discrete/,[deleted],1404312786,"What are the best methods for dealing with a combination of these features, for both regression and classification tasks?",4,3,False,default,,,,,
14,MachineLearning,t5_2r3gv,2014-7-3,2014,7,3,8,29oyf0,medium.com,Why becoming a data scientist is NOT actually easier than you think,https://www.reddit.com/r/MachineLearning/comments/29oyf0/why_becoming_a_data_scientist_is_not_actually/,clarkest,1404342625,,9,2,False,http://b.thumbs.redditmedia.com/V6kk7VRCDye_3xwI.jpg,,,,,
15,MachineLearning,t5_2r3gv,2014-7-3,2014,7,3,11,29ph9a,arxiv.org,Deep Learning in Neural Networks: An Overview,https://www.reddit.com/r/MachineLearning/comments/29ph9a/deep_learning_in_neural_networks_an_overview/,[deleted],1404355099,,0,1,False,default,,,,,
16,MachineLearning,t5_2r3gv,2014-7-3,2014,7,3,16,29q2ew,self.MachineLearning,Minimum Description Length,https://www.reddit.com/r/MachineLearning/comments/29q2ew/minimum_description_length/,neeratyoy,1404372488,How can MDL be explained to provide an intuitive understanding of the principle ? What can be its application other than decision tree pruning ?,3,5,False,self,,,,,
17,MachineLearning,t5_2r3gv,2014-7-3,2014,7,3,16,29q2ld,crushingandscreening.wordpress.com,Introduction To High Frequency Vibrating Screen | Crushing &amp; Screening Equipment  Australia,https://www.reddit.com/r/MachineLearning/comments/29q2ld/introduction_to_high_frequency_vibrating_screen/,jessicperson,1404372692,,0,1,False,default,,,,,
18,MachineLearning,t5_2r3gv,2014-7-3,2014,7,3,17,29q5lj,self.MachineLearning,Dropout during pre-training?,https://www.reddit.com/r/MachineLearning/comments/29q5lj/dropout_during_pretraining/,rishok,1404376057,"I know of the possibility of using the dropout technique in combination with the pre-training. 

However, is there anybody who has used it or knows about using dropout during pre-training of an autoencoder?",2,1,False,self,,,,,
19,MachineLearning,t5_2r3gv,2014-7-3,2014,7,3,17,29q69v,self.MachineLearning,Can you post some machine learning projects that have source code included?,https://www.reddit.com/r/MachineLearning/comments/29q69v/can_you_post_some_machine_learning_projects_that/,lucidxistence,1404376934,"I'm trying to learn machine learning by myself and even though I'm beginning to understand the theory, I am very weak in actual programming. 

I want to have a look at source codes of other projects and see if I can understand them. 

Also are the source codes of finished kaggle Challenges available anywhere?",6,3,False,self,,,,,
20,MachineLearning,t5_2r3gv,2014-7-3,2014,7,3,18,29q75z,onlinemachinery.tumblr.com,What Do You Need To Know About Vibrating Screen - Online Machinery,https://www.reddit.com/r/MachineLearning/comments/29q75z/what_do_you_need_to_know_about_vibrating_screen/,jessicperson,1404378113,,0,1,False,default,,,,,
21,MachineLearning,t5_2r3gv,2014-7-3,2014,7,3,21,29qg42,smallbiztrends.com,How Hackathons Paved the Way for a New Machine Learning Platform,https://www.reddit.com/r/MachineLearning/comments/29qg42/how_hackathons_paved_the_way_for_a_new_machine/,digbata,1404388990,,0,0,False,http://b.thumbs.redditmedia.com/3BfbfUqsowkkRBTU.jpg,,,,,
22,MachineLearning,t5_2r3gv,2014-7-3,2014,7,3,21,29qi9n,jmlr.org,Using dynamic topic models to understand musical influence from the 1930s to 2010 (OC) [PDF],https://www.reddit.com/r/MachineLearning/comments/29qi9n/using_dynamic_topic_models_to_understand_musical/,[deleted],1404391033,,0,7,False,default,,,,,
23,MachineLearning,t5_2r3gv,2014-7-3,2014,7,3,23,29qqmd,self.MachineLearning,Can anyone help me grasp multiple readout trajectory projection in relation to echo state networks?,https://www.reddit.com/r/MachineLearning/comments/29qqmd/can_anyone_help_me_grasp_multiple_readout/,[deleted],1404397549,"I can't figure out how the network can be efficiently trained on a k-step ahead output. My best guess so far is to give the network a k-dimensional target signal where each signal is offset by k-steps. So for example, the first input would be the standard target signal, the second would be the target signal with every other step, the third would be every third step and so on. The issue with that is you would need a much longer history for larger values of k and there would be a lot of wasted data.

I would guess you could have a moving window somehow to use all data in the same time period for each k value but I don't see how giving the network non-subsequent data at subsequent windows would work.


The specific paragraph i'm trying to understand is:
&gt; 
&gt; Multiple-readout trajectory projection - In the contrary to feedback-loop,
&gt; this technique immediately predicts the entire output trajectory. This is achieved
&gt; by training k independent outputs, each regressed to predict i'th step-ahead
&gt; value of the target signal, where i C {1,...,k}. In other words, k-dimensional
&gt; output corresponds to predicted future trajectory of the target signal, up to k
&gt; steps ahead.
&gt; 
&gt; ",0,1,False,default,,,,,
24,MachineLearning,t5_2r3gv,2014-7-4,2014,7,4,1,29r50d,self.MachineLearning,Incanter (or statistical work in Clojure in general) resources? (X-post /r/clojure),https://www.reddit.com/r/MachineLearning/comments/29r50d/incanter_or_statistical_work_in_clojure_in/,nikonikolai,1404406524,"Does anyone have any great go-to resources for statistical analysis in Clojure? I mention ""in general"" alongside Incanter to include material on the other possible problems in numeric work like huge datasets, optimizing for speed etc.",6,5,False,self,,,,,
25,MachineLearning,t5_2r3gv,2014-7-4,2014,7,4,3,29rcxf,self.MachineLearning,Expected error of PCA?,https://www.reddit.com/r/MachineLearning/comments/29rcxf/expected_error_of_pca/,Splanky222,1404411232,"On and off for the past few months I have been looking at trying to find a way to get at the expected L2 error when you project a dataset on to a single line.  More specifically, I would like to figure out if there is a bound for the expected ratio of the error using a random line to that of the optimal one, which I believe is given by the first Principal Component of the data set.

Has this sort of thing been done before?",4,0,False,self,,,,,
26,MachineLearning,t5_2r3gv,2014-7-4,2014,7,4,3,29repj,bayesimpact.org,Nonprofit Fellowship to Solve the World's Toughest Problems w/Data Science (x-post r/DataScience),https://www.reddit.com/r/MachineLearning/comments/29repj/nonprofit_fellowship_to_solve_the_worlds_toughest/,BayesImpactTeam,1404412225,,12,20,False,http://a.thumbs.redditmedia.com/4GiG6i5-qpizrRnb.jpg,,,,,
27,MachineLearning,t5_2r3gv,2014-7-4,2014,7,4,4,29rlem,self.MachineLearning,SciPy Image Analysis,https://www.reddit.com/r/MachineLearning/comments/29rlem/scipy_image_analysis/,mskramer,1404416215,"Hey All,

New here. And new to ML. And amateur in python...

Looking for some more information on image analysis using Python. I came across a paper that is in the vein of what I am researching, but it uses WEKA and Java for its image analysis: 

http://www.few.vu.nl/~vbr240/publications/Webist10Names.pdf

Does anyone have any experience here? My end goal is to build the aesthetic component of a tool that evaluates the ""experience"" of websites.",6,0,False,self,,,,,
28,MachineLearning,t5_2r3gv,2014-7-4,2014,7,4,13,29sv9y,69.195.124.161,A breakthrough in Machine Translation: A paper on using Neural Network Joint Models reports unseen gains in translation quality; wins best paper award at top Computational Linguistics conference by a landslide,https://www.reddit.com/r/MachineLearning/comments/29sv9y/a_breakthrough_in_machine_translation_a_paper_on/,boxstabber,1404447429,,28,98,False,default,,,,,
29,MachineLearning,t5_2r3gv,2014-7-4,2014,7,4,16,29t6m5,xenuocmiavietthong.com,"My p nc ma siu sch, Xe nc ma siu sch",https://www.reddit.com/r/MachineLearning/comments/29t6m5/my_p_nc_ma_siu_sch_xe_nc_ma_siu_sch/,[deleted],1404458004,,0,1,False,default,,,,,
30,MachineLearning,t5_2r3gv,2014-7-4,2014,7,4,19,29th3s,self.MachineLearning,Reinforcement Learning for Obstacle Avoidance,https://www.reddit.com/r/MachineLearning/comments/29th3s/reinforcement_learning_for_obstacle_avoidance/,poonwumpa,1404470884,"http://www.cs.utexas.edu/~dana/MLClass/hw7/hw7.html

How would you implement the module in the above link regarding obstacle avoidance?
",4,0,False,self,,,,,
31,MachineLearning,t5_2r3gv,2014-7-5,2014,7,5,0,29tx1h,dssg.io,Data Science for Social Good,https://www.reddit.com/r/MachineLearning/comments/29tx1h/data_science_for_social_good/,turnersr,1404486453,,0,2,False,http://a.thumbs.redditmedia.com/itOBuaYsH8KXikIx.jpg,,,,,
32,MachineLearning,t5_2r3gv,2014-7-5,2014,7,5,4,29ujsd,self.MachineLearning,I have developed an indicator for the stock market and would like help analyzing it. How do I get started?,https://www.reddit.com/r/MachineLearning/comments/29ujsd/i_have_developed_an_indicator_for_the_stock/,dornstar18,1404502116,"http://imgur.com/EB1u55C

Some of the output is above for 5 stocks chosen randomly. The top half of each pages shows the indicator for the last year charted against the 60D return in that equity from that day. On the bottom of that page is the indicator on the X-axis, 30 day change in the indicator on the Y-Axis and returns in that equity as the bubble size. 

I have been investing on my own using this indicator, trying to buy at peaks and sell at valleys and have done decently (given a 4 month time frame of investing). I am looking to try and hire someone who can analyze the data and bring a new level of analysis to changes in the indicator telling us to do one thing and comparing different equity indicators to try and find trend patterns.

I have a lot of interest in data analytics, but I don't have the knowledge base. If I were going to try and find someone to help me analyze this, what kind of skillsets would they have, what kind of background and how would you analyze this?

Is this a machine learning dataset or is it something more simple? Any kind of advice is appreciated. Cross posted on r/statistics",7,0,False,self,,,,,
33,MachineLearning,t5_2r3gv,2014-7-5,2014,7,5,7,29uwi1,self.MachineLearning,Why are extremely randomized trees more efficient than standard Random Forests?,https://www.reddit.com/r/MachineLearning/comments/29uwi1/why_are_extremely_randomized_trees_more_efficient/,BagOfWords1000,1404511695,"Ok so I have learned recently about decision trees, and some of the developments to adress overfitting of such technique. It is not suprising that by combining different decision trees (Random Forest), using subsets of the training data and randomization, lead to a more general solution and therefore less overfitting. 

Then it seems that by completly randomize either the feature selection and the split threshold (this one makes no sense to me) a better method can be developed.

Can someone explain why such method works and why is it better than Random Forests? Is this anyhow different from blindly throw a threshold multiple times and choosing the one that gives the best result?

EDIT:
Thank you all for the insightful comments. I appreciated your views on how and why ERT can potencially be better than RF in some cases. However, as a general overview I would not trust this method for my own research, as in my opinion the statements are until a certain way weak. I hope this had been interesting also for you.",15,10,False,self,,,,,
34,MachineLearning,t5_2r3gv,2014-7-5,2014,7,5,12,29vhmd,self.MachineLearning,"Are giants like Facebook, Google and Baidu making machine learning a big data sport?",https://www.reddit.com/r/MachineLearning/comments/29vhmd/are_giants_like_facebook_google_and_baidu_making/,meandtree,1404530391,"I'm seeing a trend in papers coming from companies with big resources. They're showing results on benchmark datasets by training with additional outside data. Here are a couple examples:

http://arxiv.org/pdf/1403.2802v1.pdf
https://www.facebook.com/publications/546316888800776/

This fundamentally changes the way we interpret benchmark results. Take a look at the 2013 imagenet leaderboard:

http://www.image-net.org/challenges/LSVRC/2013/results.php

Andrew Ng's group released this paper: http://arxiv.org/pdf/1406.7806.pdf

which mentions:
&gt;This work suggests that scaling up model and dataset size
may provide a more direct path than algorithmic modications
for improving ASR systems

Competitors using outside data are being ranked alongside those that didn't. How does the community feel about this trend? Will ML be a competition where whoever has the most data wins?",10,11,False,self,,,,,
35,MachineLearning,t5_2r3gv,2014-7-5,2014,7,5,15,29vs6z,self.MachineLearning,Is my new job a step forward or backwards?,https://www.reddit.com/r/MachineLearning/comments/29vs6z/is_my_new_job_a_step_forward_or_backwards/,ml_throw,1404541652,"Hi there.  I'm not sure if this is the right place for this question, but I can't think of anywhere else where people might know the answer.

Right out of my math masters, I got a job at a start-up where my title was data scientist and my work was building a estimate for the revenue of various apps based on their performance in the app store and a few other metrics.  There was nobody else at the company who did what I did and no real oversight, so I was very self-led.  I did the Andrew Ng course on Coursera, picked up a bunch of O'Reilly books like ""Python for Data Analysis,"" ""Doing Data Science,"" and ""Data Analysis with Open Source Tools.""

Eventually I decided I wanted to move to a company where I could learn from other people.  I ended up taking a job at a cool company under a guy with a really impressive resume.  My new title is data analyst, because he says my experience doesn't qualify me for the data scientist title or role.  But the new job paid more and I thought I could learn a lot.  After a bit of time there, though, I have some misgivings:

- I haven't been asked to use a single ML algorithm; the most mathematically interesting thing I've done is a log-log regression.
- Even simple approaches I've tried, he's asked me to dumb down - one example, we were examining a collection of metrics to see which one had that largest effect on another metric, and I did a simple multivariate linear regression on a bunch of our historical data just to get an idea of what I was looking at.  He said this was unecessary and to just treat each metric as if it was independent from the others.
- Almost all analysis that isn't done in the sql query is done in excel, and any visualization we put in our presentations has to be an excel graph ""so we can go back and tweak it easily.""
- We spend as much time building powerpoint presentations as we do combing through data
- We don't use any of the software that I understand most companies are looking for in new hires - Hadoop, Hive, etc.

So, my question is, is this job really helping me grow my career in data, or am I stuck in a dead end?
",14,12,False,self,,,,,
36,MachineLearning,t5_2r3gv,2014-7-5,2014,7,5,22,29w97k,techeffigy.wordpress.com,Markov Chains  Explained,https://www.reddit.com/r/MachineLearning/comments/29w97k/markov_chains_explained/,[deleted],1404566206,,31,48,False,default,,,,,
37,MachineLearning,t5_2r3gv,2014-7-6,2014,7,6,7,29xffb,quora.com,What is the difference between SVD and matrix factorization in context of recommendation engine?,https://www.reddit.com/r/MachineLearning/comments/29xffb/what_is_the_difference_between_svd_and_matrix/,rrenaud,1404600424,,0,0,False,http://b.thumbs.redditmedia.com/yKRiZnL6ELf1pOZU.jpg,,,,,
38,MachineLearning,t5_2r3gv,2014-7-6,2014,7,6,10,29xste,self.MachineLearning,Spark?,https://www.reddit.com/r/MachineLearning/comments/29xste/spark/,rm999,1404611257,"Does anyone here have experience using Spark? I went to the Spark Summit in SF this week, and my takeaway is that Spark is almost certainly going to be huge because so many practical computations (both in ML and outside it) fall neatly into its computational model. I see wide agreement that Spark will eventually be Hadoop's successor, plus a whole lot more. 

I've been playing with it a bit (mostly mllib), and I like what I've seen so far. I'm curious if any of you have started projects on top of Spark, and if you have recommendations of a good place/community to discuss its applications and development. I couldn't find a subreddit so I started [r/apachespark](http://www.reddit.com/r/apachespark), but I'd rather find an established place to discuss it. ",19,28,False,self,,,,,
39,MachineLearning,t5_2r3gv,2014-7-7,2014,7,7,1,29z3dr,nlpers.blogspot.com,Hal Daume's ACL 2014 picks...,https://www.reddit.com/r/MachineLearning/comments/29z3dr/hal_daumes_acl_2014_picks/,rrenaud,1404662811,,1,25,False,http://b.thumbs.redditmedia.com/sqSGRFqq-cwYsvpW.jpg,,,,,
40,MachineLearning,t5_2r3gv,2014-7-7,2014,7,7,12,2a0qx8,self.MachineLearning,Python theano dot product too slow,https://www.reddit.com/r/MachineLearning/comments/2a0qx8/python_theano_dot_product_too_slow/,purpleladydragons,1404704768,"I've been working on a neural network for a while now. I'm currently held up by a bottleneck from dot product computations I think. There's 5000 time steps for 4 different layers of sizes 3, 3600, 900, and 121 so the matrices are pretty big. I'm using mini batching with batch size 10. I'm using numpy and have tried using theano in order to utilize the GPU. I'm not remotely good with this low level stuff so I'm just assuming that the major bottleneck is IO between GPU and CPU. Profiling the code shows that theano's call function (called every time I try to use a GPU-enabled dot product) takes about .008 seconds (.010 if I use float32). I don't know if this is the best speed I can expect due to sheer size of the matrices or if I'm messing up. My code is about 300 lines long so I'll try to post specific snippets if anyone requests.",5,0,False,self,,,,,
41,MachineLearning,t5_2r3gv,2014-7-7,2014,7,7,16,2a14wp,machine4u.weebly.com,Vibrating Screen Buying Guide - Machine For You,https://www.reddit.com/r/MachineLearning/comments/2a14wp/vibrating_screen_buying_guide_machine_for_you/,jessicperson,1404717329,,0,1,False,default,,,,,
42,MachineLearning,t5_2r3gv,2014-7-7,2014,7,7,18,2a1c65,blog.datumbox.com,Clustering with Dirichlet Process Mixture Model in Java,https://www.reddit.com/r/MachineLearning/comments/2a1c65/clustering_with_dirichlet_process_mixture_model/,datumbox,1404726345,,4,7,False,http://a.thumbs.redditmedia.com/oEuYV08VIDow5m4B.jpg,,,,,
43,MachineLearning,t5_2r3gv,2014-7-7,2014,7,7,22,2a1r6n,youtu.be,Machine Learning Summer School Pittsburgh 2014 live.,https://www.reddit.com/r/MachineLearning/comments/2a1r6n/machine_learning_summer_school_pittsburgh_2014/,matiskay,1404741491,,5,20,False,default,,,,,
44,MachineLearning,t5_2r3gv,2014-7-8,2014,7,8,0,2a1z25,self.MachineLearning,Learning Bayes nets with an unknown number of hidden variables?,https://www.reddit.com/r/MachineLearning/comments/2a1z25/learning_bayes_nets_with_an_unknown_number_of/,[deleted],1404746650,"What are the gold standard structure-learning methods here? I don't need anything particularly fast (my networks are fairly small). I'm aware of the [structural EM algorithm (pdf)](http://arxiv.org/pdf/1301.7373.pdf) but it seems that the user needs to supply the algorithm with the number of hidden variables *a priori*. I've also read [Elidan and Freidman's information bottleneck paper (pdf)](http://machinelearning.wustl.edu/mlpapers/paper_files/ElidanF05.pdf) which seems to do what I need, but, at first glance, appears complicated to implement (not that that's a deal-breaker, but simpler is better). 

I'm mainly wondering if there is any recent research in this area that's simplified matters. 

Thanks!",0,2,False,self,,,,,
45,MachineLearning,t5_2r3gv,2014-7-8,2014,7,8,5,2a2vql,self.MachineLearning,R - TM package - Issue with arabic - diff between Mac OS X and Windows OS,https://www.reddit.com/r/MachineLearning/comments/2a2vql/r_tm_package_issue_with_arabic_diff_between_mac/,Soc_Net_Intel,1404764770,"ON MACBOOK PRO with RSTUDIO

```{r}
versionInfo()
```
1.R version 3.1.0 (2014-04-10)
2.Platform: x86_64-apple-darwin10.8.0 (64-bit)
3.Packages : tm_0.6    NLP_0.1-3
ON WINDOWS 8.1 with RSTUDIO

```{r}
versionInfo()
```
1.R version 3.1.0 (2014-04-10)
2.Platform: x86_64-w64-mingw32/x64 (64-bit) 
3.Packages : tm_0.6    NLP_0.1-3

PROBLEM DESCRIPTION

Dear all,

I have been working all the week-end. I'm working on PhD on social network analysis. At this moment, I'm using TM package for text mining and analysis purposes, with english and arabic languages mixed in bid data sets.

The data sets are collected from Twitter API with a JAVA program and placed in a MongoDB data base.

For test purposes, I use a small dataset of 36000 tweets.

The problem is that for huge datasets computing (&gt;1000000 rows), my MacBookPro would not be sufficient. I need to use a PC with Windows 8.1 OS which have better ROM and RAM.

When testing my Code on Windows 8.1 OS which working fine on RStudio on MAC OS X with the same test dataset, I have some different results from TM package at the Corpus compute level.

Here the beginning of the R code:

```{r}
y &lt;&lt;- dget(""file"") # get the file ext rated from MongoDB with rmongodb package
a &lt;&lt;- y$tweet_text # extract only the text of the tweets in the dataset
text_df &lt;&lt;- data.frame(a, stringsAsFactors = FALSE) # Save as a data frame
myCorpus_df &lt;&lt;- Corpus(DataframeSource(text_df_2)) # Compute a Corpus from the data frame
```
When I check on R in MAC OS, all the character, english and arabic, are well represented :

```{r}
str(myCorpus_df[1:2])
```

List of 2
 $ 1:List of 2
  ..$ content: chr ""The CHRONICLE EYE  Ahrar al#Sham is clearly fighting #ISIS where its men storm some #Manbij buildings #Aleppo ""
  ..$ meta   :List of 7
  .. ..$ author       : chr(0) 
  .. ..$ datetimestamp: POSIXlt[1:1], format: ""2014-07-03 22:42:18""
  .. ..$ description  : chr(0) 
  .. ..$ heading      : chr(0) 
  .. ..$ id           : chr ""1""
  .. ..$ language     : chr ""en""
  .. ..$ origin       : chr(0) 
  .. ..- attr(*, ""class"")= chr ""TextDocumentMeta""
  ..- attr(*, ""class"")= chr [1:2] ""PlainTextDocument"" ""TextDocument""


 $ 2:List of 2
  ..$ content: chr ""RT @########               ""
  ..$ meta   :List of 7
  .. ..$ author       : chr(0) 
  .. ..$ datetimestamp: POSIXlt[1:1], format: ""2014-07-03 22:42:18""
  .. ..$ description  : chr(0) 
  .. ..$ heading      : chr(0) 
  .. ..$ id           : chr ""2""
  .. ..$ language     : chr ""en""
  .. ..$ origin       : chr(0) 
  .. ..- attr(*, ""class"")= chr ""TextDocumentMeta""
  ..- attr(*, ""class"")= chr [1:2] ""PlainTextDocument"" ""TextDocument""
 - attr(*, ""class"")= chr [1:2] ""VCorpus"" ""Corpus""


Nevertheless, when I do the same part of code in RSTUDIO on WINDOWS OS, all the arabic language is wrongly decoded : the str of the Corpus show the same parameters. Only the display of arabic is unreadable (look at the format of the text of the tweet of the second object):

```{r}
inspect(myCorpus_df[1:2])
```

```
&lt;&lt;VCorpus (documents: 2, metadata (corpus/indexed): 0/0)&gt;&gt;

[[1]]
&lt;&lt;PlainTextDocument (metadata: 7)&gt;&gt;
The CHRONICLE EYE  Ahrar al#Sham is clearly fighting #ISIS where its men storm some #Manbij buildings #Aleppo 

[[2]]
&lt;&lt;PlainTextDocument (metadata: 7)&gt;&gt;
RT @##### _1               
```

When checking at the data frame text_df, the arabic language is well displayed.

When I check the encoding of an arabic word on the both OS (MAC &amp; WINDOWS OS), it seems to be well coded :

```{r}
Encoding(""__"")
```

[1] ""UTF-8""
I've tried to pass many additional information when creating the Corpus (with readerControletc) but nothing have changed : my arabic language is not well displayed in R or in RStudio on Windows OS with the tm package.

Is anyone have encountered the same difference issues between MAC OS X and WINDOWS OS with non-latin language text mining ?",0,0,False,self,,,,,
46,MachineLearning,t5_2r3gv,2014-7-8,2014,7,8,9,2a3iaj,self.MachineLearning,good practice - combining Principal Component Analysis (PCA) and Linear Discriminant Analysis (LDA)?,https://www.reddit.com/r/MachineLearning/comments/2a3iaj/good_practice_combining_principal_component/,[deleted],1404777610,"Assuming I have a dataset for a supervised statistical classification task, e.g., via a Bayes' classifier.  
This dataset consists of 20 features and I want boil it down to 2 features via dimensionality reduction techniques such as Principal Component Analysis (PCA) and/or Linear Discriminant Analysis (LDA).

Both techniques are projecting the data onto a smaller feature subspace: with PCA, I would find the directions (components) that maximize the variance in the dataset (without considering the class labels), and with LDA I would have the components that maximize the between-class separation.

Now, I am wondering if, how, and why these techniques can be combined and if it makes sense.

For example:

1. transforming the dataset via PCA and projecting it onto a new 2D subspace
2. transforming (the already PCA-tranformed) dataset via LDA for max. in-class separation

or 

1. skipping the PCA step and using the top 2 components from a LDA.

or any other combination that makes sense...

And if I understand correctly, feature scaling, e.g., standardization, wouldn't be necessary for either of those techniques, correct?",0,0,False,default,,,,,
47,MachineLearning,t5_2r3gv,2014-7-8,2014,7,8,11,2a3xnb,self.MachineLearning,What algorithm/features to use for classifying resumes,https://www.reddit.com/r/MachineLearning/comments/2a3xnb/what_algorithmfeatures_to_use_for_classifying/,ipoman,1404787167,"I finally got done going through the coursera course on machine learning and I want to try to apply my knowledge to an actual problem. An interesting problem that I stumbled upon is classifying candidate resumes for job positions. Let's say we want to classify into 4 categories (""Should definitely invite for interview"", ""Should probably invite for interview"", ""Should probably decline to interview"", ""Should definitely decline to interview""). I will try to use either logistic regression or SVM for the classification algorithm.

Setting aside the problem of parsing resumes into a structured form, let's assume that for each resume I have information such as name, address, education (university name, degree, major, year of graduation, gpa), work experience (employer name, title, dates worked, description of role), and maybe stuff like descriptions of personal projects that they have worked on and technologies that they have used.

Let's assume that we are training this algorithm for a particular employer and a particular position (because each employer probably looks for different things in a resume). Let's also assume that we have good historical training data (a map of resumes to one of the categories above). Some of the features are obvious such as university names, employer names, job titles, gpa, major, etc. I can also think of keyword based features. For example, I can include a feature based on the keyword  ""JAVA"" (whether job description contains the string ""JAVA""). I'm not even sure whether adding these keyword based features make sense and beyond that I can't think of anything else to add. I don't know much about NLP so would I be able to make use of some NLP techniques to add features? ",4,0,False,self,,,,,
48,MachineLearning,t5_2r3gv,2014-7-8,2014,7,8,11,2a3yrp,self.MachineLearning,Looking for help with data correction-,https://www.reddit.com/r/MachineLearning/comments/2a3yrp/looking_for_help_with_data_correction/,g1ven2fly,1404787929,"Alright,

So I have some fluid flowing through a pipe at a known rate (I physically measure how much comes out of the pipe).  I have installed a measuring device that should also give me a rate.  The measured rate isn't matching up to the actual rate.  I'm curious if there is some facet of machine learning (or data science) that deals with this issue.  I would like to develop a correction for the measuring device so that it provides a more accurate measurement (within 1%).  I also have lots of data that I would think are inputs into the flowrate (pressures, temperatures, gas-oil ratio, etc.)  I can't help to think what I'm trying to do exists, I'm not real sure where to start.

Thanks!",5,1,False,self,,,,,
49,MachineLearning,t5_2r3gv,2014-7-8,2014,7,8,16,2a4jsw,scribd.com,3 Tonne Excavators,https://www.reddit.com/r/MachineLearning/comments/2a4jsw/3_tonne_excavators/,jessicperson,1404804714,,0,1,False,default,,,,,
50,MachineLearning,t5_2r3gv,2014-7-8,2014,7,8,17,2a4ljc,self.MachineLearning,Best Classifier for split classes,https://www.reddit.com/r/MachineLearning/comments/2a4ljc/best_classifier_for_split_classes/,datashark7,1404806656,"Hi all,
I'm wondering which classifiers are well suited for classifying instances where a particular class can be split into more than one discrete cluster. For example in this [state of the art render](http://i.imgur.com/6Yu3qVa.jpg), where X class is scattered into several separate clusters. I was thinking kNN with some sort of density estimation, but I figured i'd ask the pros before I dove in.",12,1,False,self,,,,,
51,MachineLearning,t5_2r3gv,2014-7-8,2014,7,8,17,2a4n3j,reddit.com,Supervised classification and bootstrap samples (x/post r/AskStatistics),https://www.reddit.com/r/MachineLearning/comments/2a4n3j/supervised_classification_and_bootstrap_samples/,[deleted],1404808698,,0,0,False,default,,,,,
52,MachineLearning,t5_2r3gv,2014-7-9,2014,7,9,5,2a6e99,gl3.eventbrite.com,35% Discount link for Redditors to the GraphLab Conference on 7/21 --Great talks from great ML/DS people.,https://www.reddit.com/r/MachineLearning/comments/2a6e99/35_discount_link_for_redditors_to_the_graphlab/,shonburton,1404852752,,2,1,False,http://a.thumbs.redditmedia.com/BTAqswSKo0Fwqfo4.jpg,,,,,
53,MachineLearning,t5_2r3gv,2014-7-9,2014,7,9,6,2a6fqg,nuit-blanche.blogspot.dk,Randomized Numerical Linear Algebra for Large Scale Data Analysis ( libSkylark: Sketching based Matrix computations for Machine Learning ),https://www.reddit.com/r/MachineLearning/comments/2a6fqg/randomized_numerical_linear_algebra_for_large/,compsens,1404853455,,0,6,False,http://b.thumbs.redditmedia.com/dawXwgtSFe_3x4d9.jpg,,,,,
54,MachineLearning,t5_2r3gv,2014-7-9,2014,7,9,14,2a7r2q,essayscoop.com,New company aiming to use machine learning to quantify college admissions essays.,https://www.reddit.com/r/MachineLearning/comments/2a7r2q/new_company_aiming_to_use_machine_learning_to/,thabirdie,1404882863,,11,0,False,default,,,,,
55,MachineLearning,t5_2r3gv,2014-7-9,2014,7,9,14,2a7u4m,colah.github.io,"Deep Learning, NLP, and Representations",https://www.reddit.com/r/MachineLearning/comments/2a7u4m/deep_learning_nlp_and_representations/,rrenaud,1404885505,,6,55,False,http://a.thumbs.redditmedia.com/vrhIS-5F20Ltef2D.jpg,,,,,
56,MachineLearning,t5_2r3gv,2014-7-9,2014,7,9,16,2a7yg4,excavatormachines.wordpress.com,Cat Wheeled Excavator Optimized For Waste | Excavators  Heavy machinery at it's finest,https://www.reddit.com/r/MachineLearning/comments/2a7yg4/cat_wheeled_excavator_optimized_for_waste/,jessicperson,1404889672,,0,1,False,default,,,,,
57,MachineLearning,t5_2r3gv,2014-7-9,2014,7,9,17,2a83ao,blog.bigml.com,Enhancing your Web Browsing Experience with Machine Learned Models (part I),https://www.reddit.com/r/MachineLearning/comments/2a83ao/enhancing_your_web_browsing_experience_with/,czuriaga,1404895342,,0,1,False,http://a.thumbs.redditmedia.com/TmWUzN0wOnOYk4VF.jpg,,,,,
58,MachineLearning,t5_2r3gv,2014-7-9,2014,7,9,18,2a84o8,techrepublic.com,Google leverages machine learning to keep its data centers energy efficient,https://www.reddit.com/r/MachineLearning/comments/2a84o8/google_leverages_machine_learning_to_keep_its/,gentlebystander,1404897178,,0,2,False,http://b.thumbs.redditmedia.com/CoNdHptGroPdbTGe.jpg,,,,,
59,MachineLearning,t5_2r3gv,2014-7-9,2014,7,9,18,2a86p0,self.MachineLearning,Maxout network?,https://www.reddit.com/r/MachineLearning/comments/2a86p0/maxout_network/,[deleted],1404899760,"Does anybody have an implementation of the maxout network (from Ian J. Goodfellow) in matlab, in order to compare with my solution.",0,0,False,default,,,,,
60,MachineLearning,t5_2r3gv,2014-7-9,2014,7,9,23,2a8q5z,self.MachineLearning,Visualization in machine learning,https://www.reddit.com/r/MachineLearning/comments/2a8q5z/visualization_in_machine_learning/,piscoster,1404917193,"I am extremely interested in visualization in machine learning. I have read some scientific papers about this topic(like the visualization of real estate data) and personally think that this topic is quite satured by scientific research. Besides that I would like to contribute to this field in my free time and I am looking for research questions.

Therefore, my question is:

Which questions are still open in visualization in machine learning? What are interesting subfield in visualization?

I really would appreciate your hints about papers/research articles? 

Best regards and much appreciation for your future answers!
",1,5,False,self,,,,,
61,MachineLearning,t5_2r3gv,2014-7-10,2014,7,10,3,2a9h6i,fakomakine.com,Etiketleme Makineleri,https://www.reddit.com/r/MachineLearning/comments/2a9h6i/etiketleme_makineleri/,kaliteliseo,1404932264,,0,1,False,default,,,,,
62,MachineLearning,t5_2r3gv,2014-7-10,2014,7,10,5,2a9tvp,orbi.ulg.ac.be,U N D E R S TA N D I N G R A N D O M F O R E S T S from theory to practice,https://www.reddit.com/r/MachineLearning/comments/2a9tvp/u_n_d_e_r_s_ta_n_d_i_n_g_r_a_n_d_o_m_f_o_r_e_s_t/,[deleted],1404939120,,0,1,False,default,,,,,
63,MachineLearning,t5_2r3gv,2014-7-10,2014,7,10,6,2a9vl1,orbi.ulg.ac.be,Understanding Random Forests: From Theory to Practice (github repository available),https://www.reddit.com/r/MachineLearning/comments/2a9vl1/understanding_random_forests_from_theory_to/,glaksh09,1404940119,,5,59,False,default,,,,,
64,MachineLearning,t5_2r3gv,2014-7-10,2014,7,10,6,2a9xdj,karpathy.github.io,Feature Learning Escapades,https://www.reddit.com/r/MachineLearning/comments/2a9xdj/feature_learning_escapades/,keghn,1404941164,,0,18,False,http://a.thumbs.redditmedia.com/HBxlC5vZZxOI3i6x.jpg,,,,,
65,MachineLearning,t5_2r3gv,2014-7-10,2014,7,10,9,2aad72,self.MachineLearning,Help with Tiger Problem using POMDP,https://www.reddit.com/r/MachineLearning/comments/2aad72/help_with_tiger_problem_using_pomdp/,oer_7,1404950899,"I am trying to get a better understanding of POMDPs by trying to obtain the best policy for the tiger problem: http://www.pomdp.org/examples/tiger.aaai.POMDP

My first problem arises when I try to calculate the belief update using : 
b'(s') =(normalizingconstant) P(e|s') (sum.over.states)P(s'|s,a) b(s). 

For the 2 horizon, my thoughts are that P(e|s') is &lt;.85,.15&gt; or &lt;.15,.85&gt; based on the evidence. Then P(s'|s,a) == 1??? (not sure if this is correct since you would always know whether you will open a door or listen?) and I am assuming b(s) for that case is &lt;.5,.5&gt;. 

is that how I obtain b'?        ",0,1,False,self,,,,,
66,MachineLearning,t5_2r3gv,2014-7-10,2014,7,10,11,2aaq24,self.MachineLearning,Is the denoising a must step before convolution nearual network?,https://www.reddit.com/r/MachineLearning/comments/2aaq24/is_the_denoising_a_must_step_before_convolution/,chrispher2012,1404959201,"Is the denoising a must step before convolution nearual network? As we can see, CNNs have some convolutional layers which can do something like bluring or filtering. So I wonder whether  there are any must steps to do or not in image preprocessing when I use the CNNs. Thanks very much!",3,0,False,self,,,,,
67,MachineLearning,t5_2r3gv,2014-7-10,2014,7,10,12,2aatqv,self.MachineLearning,How do I cluster images using a deep neural network?,https://www.reddit.com/r/MachineLearning/comments/2aatqv/how_do_i_cluster_images_using_a_deep_neural/,[deleted],1404961639,"I took Hinton's course on Coursera but I am not yet confident I know the best methods for a given task. I am looking to start with a small project to get more comfortable with machine learning.

If I had say a thousand or so images and I wanted to cluster them, what are the possible methods available to me?

I was thinking of using something like a convolutional neural network (with two streams, one for black and white versions of the image and one for colour) with max pooling layers in-between. Essentially, similar to the one Hinton's group used for ImageNet. Or anything simpler because my purpose is less specific. But I am not sure I know how to use that set up in context of unsupervised clustering. For all I know, this is a dumb way to cluster images and there are probably better methods.

But having no useful experience in the field, I am looking for advice and thoughts on what's the best way to go about this.


Essentially, the goal is to feed it images and have it return a sort of similarity map (like a t-SNE representation, I guess?). So hopefully if I give it 1000 pictures of people and 1000 pictures of flowers, it will cluster them into two massive groups (and whatever sub-clusters it deems necessary).

What are the best modern methods to achieve this goal and what should I look out for?",5,1,False,default,,,,,
68,MachineLearning,t5_2r3gv,2014-7-10,2014,7,10,16,2abbk8,self.MachineLearning,Suggest a kaggle challenge(knowledge) or something similar for a beginner,https://www.reddit.com/r/MachineLearning/comments/2abbk8/suggest_a_kaggle_challengeknowledge_or_something/,[deleted],1404975762,"I'm trying to learn machine learning by my self, I have downloaded the stanford machine learning videos to learn the theory and for practicals I'm planning to attempt a kaggle knowledge challenge. 

I'm not very strong in programming and would like a challenge which publishes source codes so I can learn by observing them. 

Thank you and if you have a better idea to get started in this field please suggest that as well",3,8,False,self,,,,,
69,MachineLearning,t5_2r3gv,2014-7-10,2014,7,10,16,2abdba,scribd.com,Graders,https://www.reddit.com/r/MachineLearning/comments/2abdba/graders/,jessicperson,1404977647,,0,1,False,default,,,,,
70,MachineLearning,t5_2r3gv,2014-7-10,2014,7,10,18,2abjcy,self.MachineLearning,In a multiclass classification problem using Random Forest. How would I determine the most important features for each particular class?,https://www.reddit.com/r/MachineLearning/comments/2abjcy/in_a_multiclass_classification_problem_using/,daithibowzy,1404985156,,6,8,False,self,,,,,
71,MachineLearning,t5_2r3gv,2014-7-10,2014,7,10,18,2abjku,self.MachineLearning,Convolutional networks: how to deal with pairs of similar filters?,https://www.reddit.com/r/MachineLearning/comments/2abjku/convolutional_networks_how_to_deal_with_pairs_of/,Felix-Neko,1404985468,"I have to train a convolutional network. When I visualize its conv filter matrices from a layer, many filters are quite similar, almost equal.

1) Don't you know a common way to **detect couples of similar kernels?** Maybe, it is somehow connected with their correlation?

2) Don't you know any good strategies to **deal with such duplicate kernels?** My only offer is to re-initialize such duplicate with noise and continue the training, but I don't think it is the best idea.",6,3,False,self,,,,,
72,MachineLearning,t5_2r3gv,2014-7-10,2014,7,10,21,2abt1u,flickr.com,Doosan DX190W - 2011 Wheeled Excavator | Flickr - Photo Sharing!,https://www.reddit.com/r/MachineLearning/comments/2abt1u/doosan_dx190w_2011_wheeled_excavator_flickr_photo/,jessicperson,1404995998,,0,1,False,default,,,,,
73,MachineLearning,t5_2r3gv,2014-7-10,2014,7,10,22,2abvbj,self.MachineLearning,Final year of college. Ditched on-campus companies for better off-campus profiles. Need Advice. Nervous. [xpost r/cscareerquestions],https://www.reddit.com/r/MachineLearning/comments/2abvbj/final_year_of_college_ditched_oncampus_companies/,[deleted],1404997891,"Hello, I am a final year student from a respectable university in India. At the beginning of the last year in college, IT companies like Amazon etc visited campus for Software Developer profile. I am pretty good in academics and have many personal hobby projects in Python.

I decided to let go of these companies because I didn't feel for their profiles, and I really don't like advanced algorithms. I think there is more to computer science that that. Plus, I am proficient in Python and they don't allow it to be used in their technical rounds, atleast here. I like data and all the creativity that follows it.

Anyway, I decided to apply to startups by the end of my 7th semester. I am currently a Google Summer of Code student with good experience in Python and NLP. Hopefully by the end of this semester I will have completed both ML from Stanford and DataSci from Uni of Washington on Coursera. I am counting on those two courses and additional experience to get me good highpaying jobs off-campus.

Would that be enough to even apply to start ups outside of India? Say Silicon Valley, or even data profiles of Amazon, Google , Microsoft etc?

I am just really nervous and hope I didn't take a wrong decision by letting go of companies that visited campus, hoping that I will get what I like off-campus.

What can I do in this one year apart from those two MOOCs to make myself valuable to any place I apply to?
",6,0,False,default,,,,,
74,MachineLearning,t5_2r3gv,2014-7-10,2014,7,10,23,2ac0oe,self.MachineLearning,Label Propagation,https://www.reddit.com/r/MachineLearning/comments/2ac0oe/label_propagation/,zibenmoka,1405001679,Can anyone share his experience with Label Propagation - semi supervised learning technique? How does that method work in the wild?  ,2,0,False,self,,,,,
75,MachineLearning,t5_2r3gv,2014-7-11,2014,7,11,3,2acnqj,jmlr.org,Stochastic Neighbor Compression: fast approximate nearest neighbors,https://www.reddit.com/r/MachineLearning/comments/2acnqj/stochastic_neighbor_compression_fast_approximate/,rrenaud,1405015380,,1,16,False,default,,,,,
76,MachineLearning,t5_2r3gv,2014-7-11,2014,7,11,5,2ad307,arxiv.org,Historical Survey of Neural Networks,https://www.reddit.com/r/MachineLearning/comments/2ad307/historical_survey_of_neural_networks/,glaksh09,1405023733,,3,10,False,default,,,,,
77,MachineLearning,t5_2r3gv,2014-7-11,2014,7,11,6,2adb3b,self.MachineLearning,Local Minima in high-dimensional Space,https://www.reddit.com/r/MachineLearning/comments/2adb3b/local_minima_in_highdimensional_space/,sssub,1405028322,"Consider a  standard gradient descent approach to optimize neural networks. 
In a discussion with colleagues I heard the following statement:

'Local Minima get less of a problem if you increase the dimension of your architecture (more parameter to optimize)'. 

The argument is that it is less likely that there is no decrease in 
the error function in any direction if the parameter space is high, 
(compared to a low-dimensional architecture) so there 
should be less local minima.

Now I know that this is not true in general, as one can come up 
with counter examples. However as a general 'heuristic', is 
there any truth in that?  ",8,3,False,self,,,,,
78,MachineLearning,t5_2r3gv,2014-7-11,2014,7,11,6,2adcv8,blog.dlib.net,MITIE v0.2 Released: Now includes Python and C++ APIs for named entity recognition and binary relation extraction,https://www.reddit.com/r/MachineLearning/comments/2adcv8/mitie_v02_released_now_includes_python_and_c_apis/,myeesw,1405029348,,0,15,False,default,,,,,
79,MachineLearning,t5_2r3gv,2014-7-11,2014,7,11,9,2adudv,self.MachineLearning,Question regarding Machine Learning and Wearable Technology,https://www.reddit.com/r/MachineLearning/comments/2adudv/question_regarding_machine_learning_and_wearable/,[deleted],1405040007,"I am not the most familiar with MI/PR techniques and I am curious with the role Machine Learning plays in the wearable technology devices that are currently being used to calculate athletic metrics. Can anyone help me in outlining basic strategies that are being used or pointing me to a resource that I might find useful? 

Much Thanks!!!",2,2,False,self,,,,,
80,MachineLearning,t5_2r3gv,2014-7-11,2014,7,11,21,2af3y8,self.MachineLearning,Biologically Plausible Learning Algorithms in ANN's,https://www.reddit.com/r/MachineLearning/comments/2af3y8/biologically_plausible_learning_algorithms_in_anns/,NeuroCavalry,1405080557,"Hi MachineLearning, 

Let me preface this with an apology. I'm not sure if this is the right subreddit for this question. CogSci seems more interested in the philosophical side of Neural Networks, and Neuro is obviously more interested in straight Neuroscience. If you feel this is the wrong subreddit, feel free to ignore this and, mods, please lock it - but in this case, a pointer in the right direction would be great. 

A friend and I were introduced to Neural Networks by a professor. I am a Neuroscience student, he is a Computer Science student. For the purposes of curiosity and learning, we have decided to try our hand at them.  He has already made a few with good results. 

At the moment we are building an ANN with a special focus on adherence to known Neuroscience.  Whereas before, we were using some basic positive/negative reinforcement for our learning, now we are looking at more closely modelling synaptic plasticity - probably with some variation of Hebbian Learning. At present, we have implemented Oja's rule, But I was wondering what else where was out there. The Neuroscientist in me bristles at some of the assumptions and foundations of Oja's rule (especially the default 'decaying' of synapatic weight), so I was wondering if there were any papers presenting algorithms more closely based on long-term potentiation and long-term depression. I've been searching via my university library, but it has been fruitless so far. 

Any references would be a great help, and thank you in advance.",15,10,False,self,,,,,
81,MachineLearning,t5_2r3gv,2014-7-11,2014,7,11,21,2af4e7,self.MachineLearning,Google Analytics research,https://www.reddit.com/r/MachineLearning/comments/2af4e7/google_analytics_research/,zibenmoka,1405081009,Is there any known scientific research on Google Analytics data in the context of classification problem ?,4,0,False,self,,,,,
82,MachineLearning,t5_2r3gv,2014-7-11,2014,7,11,21,2af55f,sebastianraschka.com,About Feature Scaling: Z-Score Standardization and Min-Max Scaling (+ how to in Python),https://www.reddit.com/r/MachineLearning/comments/2af55f/about_feature_scaling_zscore_standardization_and/,rasbt,1405081661,,1,8,False,http://b.thumbs.redditmedia.com/RgETG-byKij51E3M.jpg,,,,,
83,MachineLearning,t5_2r3gv,2014-7-11,2014,7,11,23,2afeet,self.MachineLearning,Seeking Industry Leading Algorithm Developer Connections,https://www.reddit.com/r/MachineLearning/comments/2afeet/seeking_industry_leading_algorithm_developer/,[deleted],1405088897,"I work for a large healthcare organization who is seeking to develop a telehealth program to better predict clinical outcomes of our patients.

We are seeking the leading minds from outside the healthcare industry in algorithm development from other industries.

How can I best connect with these experts from organization like Amazon, Netflix, eBay, etc.?

Please feel free to also PM me if you are one of them - or connected to them -and interested in helping out.",4,0,False,self,,,,,
84,MachineLearning,t5_2r3gv,2014-7-11,2014,7,11,23,2afgv1,jvns.ca,Fun with stats: How big of a sample size do I need?,https://www.reddit.com/r/MachineLearning/comments/2afgv1/fun_with_stats_how_big_of_a_sample_size_do_i_need/,bork,1405090382,,0,0,False,default,,,,,
85,MachineLearning,t5_2r3gv,2014-7-12,2014,7,12,0,2afl9k,dataconomy.com,Numenta: Technologies Which Can Mimic How the Brain Works,https://www.reddit.com/r/MachineLearning/comments/2afl9k/numenta_technologies_which_can_mimic_how_the/,[deleted],1405093047,,0,1,False,default,,,,,
86,MachineLearning,t5_2r3gv,2014-7-12,2014,7,12,20,2ai5jq,blog.cigrainger.com,Using Python to determine the natural number of topics for Latent Dirichlet Allocation,https://www.reddit.com/r/MachineLearning/comments/2ai5jq/using_python_to_determine_the_natural_number_of/,heisakukosawa,1405164778,,6,16,False,http://b.thumbs.redditmedia.com/q-Tany7cBmIDhN8C.jpg,,,,,
87,MachineLearning,t5_2r3gv,2014-7-13,2014,7,13,0,2aiilg,stackoverflow.com,"Question I posted on Stack Overflow: ""Binary classification of dated documents with seasonal class variation""",https://www.reddit.com/r/MachineLearning/comments/2aiilg/question_i_posted_on_stack_overflow_binary/,briandastous,1405178371,,0,1,False,http://a.thumbs.redditmedia.com/80tnunXhQJXBAP3L.jpg,,,,,
88,MachineLearning,t5_2r3gv,2014-7-13,2014,7,13,1,2aiqmk,leon.bottou.org,The infinite MNIST dataset,https://www.reddit.com/r/MachineLearning/comments/2aiqmk/the_infinite_mnist_dataset/,urish,1405184340,,1,7,False,default,,,,,
89,MachineLearning,t5_2r3gv,2014-7-13,2014,7,13,3,2aiy4h,self.MachineLearning,Polarity sentiment analysis for non English language,https://www.reddit.com/r/MachineLearning/comments/2aiy4h/polarity_sentiment_analysis_for_non_english/,reizelx,1405189710,"hi, I need to analize few texts in non English language. For English there are many free tools that do that for me, but not in my language. One my friend that studies IT said that I could get English word polrity table (table that represents words and their positive/negative value) and give to traslators to translate.

Any one has idea where i could get English word polarity table, or its technical name, so iI could lok for. So far no luck :(",1,0,False,self,,,,,
90,MachineLearning,t5_2r3gv,2014-7-13,2014,7,13,6,2ajcl9,self.MachineLearning,Implementation details of Olshausen and Fields sparse coding paper in Nature,https://www.reddit.com/r/MachineLearning/comments/2ajcl9/implementation_details_of_olshausen_and_fields/,entron,1405199882,"I want to find a working implementation of the 1996 Nature paper **Emergence of simple-cell receptive field properties by learning a sparse code for natural images**  or the authors' other paper with more details published on Vision Research **Sparse coding with an overcomplete basis set: a strategy employed by V1?** to help me learn their method.

They have a matlab version calling c implementation of fast conjugate gradient [here](http://redwood.berkeley.edu/bruno/sparsenet/). However I haven't successfully made in run on my computer. Does anyone have code available (preferably in python) reproduced their results?

Another question is what is the reasoning behind the ""rate parameter for the gain adjustment"" $\alpha$ in Eq.(18) of the second paper?",0,1,False,self,,,,,
91,MachineLearning,t5_2r3gv,2014-7-13,2014,7,13,7,2ajjxs,cs.pitt.edu,Quoc Les Lectures on Deep Learning,https://www.reddit.com/r/MachineLearning/comments/2ajjxs/quoc_les_lectures_on_deep_learning/,x2342,1405205061,,1,29,False,default,,,,,
92,MachineLearning,t5_2r3gv,2014-7-13,2014,7,13,19,2akqaq,datasciencecentral.com,Curse of Dimensionality,https://www.reddit.com/r/MachineLearning/comments/2akqaq/curse_of_dimensionality/,neeratyoy,1405246169,,6,24,False,http://a.thumbs.redditmedia.com/29UaB_BpqVP6-O_R.jpg,,,,,
93,MachineLearning,t5_2r3gv,2014-7-14,2014,7,14,4,2alsx0,bugra.github.io,Discrete Cosine Transform and A Case Study on Image Compression,https://www.reddit.com/r/MachineLearning/comments/2alsx0/discrete_cosine_transform_and_a_case_study_on/,[deleted],1405280704,,0,0,False,default,,,,,
94,MachineLearning,t5_2r3gv,2014-7-14,2014,7,14,5,2alum3,self.MachineLearning,"New intern, a bit terrified by my dataset. OK to ask questions in this sub?",https://www.reddit.com/r/MachineLearning/comments/2alum3/new_intern_a_bit_terrified_by_my_dataset_ok_to/,[deleted],1405281884,"Alright, the situation is that I have an unpaid gig on a healthcare policy project with one hell of a (well, to me) dataset.  

I'm dealing with about 70k rows and 300+ features.  Some features are categorical, some continuous vars.  Definite structure in the dataset as well.

I need to do some amount of exploratory analysis.  My ultimate goal is to find a way to cluster the individuals in my dataset, then explore those clusters (WHY are those individuals alike?) and also identify outliers who don't fit well into ANY cluster.

I'd dearly love to pull out FactoMineR and go to town, but it's not built for a dataset of this size.

Any advice on packages/environments?

Or, am I in No Man's Land and I have to design my own solution?

**EDIT:** Will give you guys an update once I get cleared and allowed to access the true, actual data itself.  You were right- the first step is simply to apply the machine learning located between my ears in order to make a first pass on what matters and what doesn't.  OP will deliver.  But without divulging anything inappropriate, as /u/cavedave was right to point out.",8,8,False,default,,,,,
95,MachineLearning,t5_2r3gv,2014-7-14,2014,7,14,6,2am2rh,youtube.com,All CMU Machine Learning Summer School lecture videos online now,https://www.reddit.com/r/MachineLearning/comments/2am2rh/all_cmu_machine_learning_summer_school_lecture/,egrefen,1405287725,,4,85,False,http://a.thumbs.redditmedia.com/yqL6XFKnOgIL27GP.jpg,,,,,
96,MachineLearning,t5_2r3gv,2014-7-14,2014,7,14,8,2amai9,blog.twitter.com,Goal! Detecting the most important World Cup moments | Twitter Blogs,https://www.reddit.com/r/MachineLearning/comments/2amai9/goal_detecting_the_most_important_world_cup/,a_jey,1405292559,,0,2,False,http://a.thumbs.redditmedia.com/3dh8_OhsV5MRybCt.jpg,,,,,
97,MachineLearning,t5_2r3gv,2014-7-14,2014,7,14,11,2amqz6,self.MachineLearning,Motorcyclist detection,https://www.reddit.com/r/MachineLearning/comments/2amqz6/motorcyclist_detection/,[deleted],1405303955,"Hello

I try to detect motorcyclists on a videostream and I'd like to try out these hot deep learning models. I've found a promising article from LeCun's lab (Pedestrian Detection with Unsupervised Multi-Stage Feature Learning: http://cs.nyu.edu/~sermanet/papers/sermanet-cvpr-13.pdf) and going to stick with it. But i'd also like to hear community opinions on my problem.

Do you know other approaches? Or do you have something to say about aforementioned paper?
Thanks in advance.
P.S. I'm not interested in computer vision's hand-engineered features since I want to play with deep learning",1,1,False,default,,,,,
98,MachineLearning,t5_2r3gv,2014-7-14,2014,7,14,16,2and4j,machineryequipment123.blogspot.com,What To Consider When Choosing Wheeled Excavator - Machinery &amp; Equipment Part Online,https://www.reddit.com/r/MachineLearning/comments/2and4j/what_to_consider_when_choosing_wheeled_excavator/,jessicperson,1405321502,,0,1,False,default,,,,,
99,MachineLearning,t5_2r3gv,2014-7-14,2014,7,14,18,2anj4v,maykhumuiozone.com,Kh mi hi ca du m trong nh bp n gin vi my Ozone,https://www.reddit.com/r/MachineLearning/comments/2anj4v/kh_mi_hi_ca_du_m_trong_nh_bp_n_gin_vi/,ngoctongvt,1405328703,,0,0,False,default,,,,,
100,MachineLearning,t5_2r3gv,2014-7-14,2014,7,14,18,2anjd1,colah.github.io,Understanding Convolutions,https://www.reddit.com/r/MachineLearning/comments/2anjd1/understanding_convolutions/,egrefen,1405328980,,7,39,False,http://a.thumbs.redditmedia.com/1twbojaAzC8mNhb8.jpg,,,,,
101,MachineLearning,t5_2r3gv,2014-7-14,2014,7,14,21,2anuch,self.MachineLearning,How to test whether there is a significant difference in mean squared error between two datasets? (cross-post from /r/statistics),https://www.reddit.com/r/MachineLearning/comments/2anuch/how_to_test_whether_there_is_a_significant/,alexgmcm,1405341692,"I want to test whether Alzheimer's disease causes a change in brain aging compared to healthy patients.

Therefore I have constructed a linear regression model of spectral parameters of brain recordings versus age (age is the independent variable).

Now I wish to fit the model on the healthy patients, and then use the coefficients to calculate the expected age of the Alzheimer's patients - comparing the mean squared error of the healthy dataset and the Alzheimer's dataset should help show whether or not there is a difference to the aging due to the disease. (i.e. if the model that works well for healthy patients fails miserably for Alzheimer's patients then there is probably a difference)

I guess I will fit the linear regression model on 80% of the healthy patients (the training set), holding back 20% (as a test set) to calculate the MSE with because it seems unfair to calculate the MSE on data that the model was trained on and compare it to a dataset which the model never saw.

I would use cross-validation but then I will end up with as many different sets of coefficients as I have folds and how would I know which to fit the Alzheimer's patients with? The mean of the coefficients perhaps? An advantage to cross validation though is that I would have a mean and standard deviation of the MSE  estimates from the sets of healthy patients so I could use that to determine the significance of deviation between the healthy and diseased MSE's, which is handy.

I guess I could also sample subsets many times from the Alzheimer's patients and create a set of MSE estimates which I could then calculate the standard deviation and mean of to get some idea of the variance there as well so I have an idea about how sensitive it is to that particular dataset. (Should I do this with replacement i.e. bootstrapping? Why or why not?)

Any advice is greatly appreciated.",0,0,False,self,,,,,
102,MachineLearning,t5_2r3gv,2014-7-14,2014,7,14,21,2anvkp,wired.co.uk,Algorithm identifies rare genetic disorders from family pics,https://www.reddit.com/r/MachineLearning/comments/2anvkp/algorithm_identifies_rare_genetic_disorders_from/,cavedave,1405342749,,3,17,False,http://b.thumbs.redditmedia.com/Y-WUzv_NiI8CC2QY.jpg,,,,,
103,MachineLearning,t5_2r3gv,2014-7-14,2014,7,14,22,2anzao,electronicsforu.com,15 Free eBooks On Machine Learning,https://www.reddit.com/r/MachineLearning/comments/2anzao/15_free_ebooks_on_machine_learning/,rasbt,1405345688,,3,28,False,http://b.thumbs.redditmedia.com/kbnNQ8FnVbeB4IYu.jpg,,,,,
104,MachineLearning,t5_2r3gv,2014-7-15,2014,7,15,1,2aohti,wired.com,The AI Startup Google Should Probably Snatch Up Fast,https://www.reddit.com/r/MachineLearning/comments/2aohti/the_ai_startup_google_should_probably_snatch_up/,Historical_Fiction,1405356868,,0,0,False,http://a.thumbs.redditmedia.com/Hs6by-YhzXpqOkqb.jpg,,,,,
105,MachineLearning,t5_2r3gv,2014-7-15,2014,7,15,2,2aomie,dataconomy.com,LinkedIn Acquires Machine Learning Startup Newsle,https://www.reddit.com/r/MachineLearning/comments/2aomie/linkedin_acquires_machine_learning_startup_newsle/,[deleted],1405359438,,0,1,False,default,,,,,
106,MachineLearning,t5_2r3gv,2014-7-15,2014,7,15,4,2aoy2m,self.MachineLearning,Scientific research about machine learning and the real estate market,https://www.reddit.com/r/MachineLearning/comments/2aoy2m/scientific_research_about_machine_learning_and/,Regentag,1405365557,"Hello guys,

I am a private researcher on various machine learning topics. I would like to solve some open problems using machine learning within the real estate market. Some problems, where machine learning and real estate is connected are automated valuation models.(I cannot find a lot of research and open problems with this keyword ;( ) However, I am looking for current problems to work on, which connect real estate and machine learning together.

Is there any scientific research done in this field? What are current problems to work and research on?

Would appreciate papers/keywords and ideas!!!

Best regards!
",4,0,False,self,,,,,
107,MachineLearning,t5_2r3gv,2014-7-15,2014,7,15,4,2aozgp,dataorigami.net,8 great data blogs to follow,https://www.reddit.com/r/MachineLearning/comments/2aozgp/8_great_data_blogs_to_follow/,[deleted],1405366271,,0,0,False,default,,,,,
108,MachineLearning,t5_2r3gv,2014-7-15,2014,7,15,4,2aozp3,github.com,Understanding Random Forests (a PhD thesis),https://www.reddit.com/r/MachineLearning/comments/2aozp3/understanding_random_forests_a_phd_thesis/,rasbt,1405366382,,5,34,False,http://a.thumbs.redditmedia.com/1h7yUTLIUBGrevjP.jpg,,,,,
109,MachineLearning,t5_2r3gv,2014-7-15,2014,7,15,4,2ap06q,trivedigaurav.com,Quoc Les (from Google Brain) Lectures on Deep Learning,https://www.reddit.com/r/MachineLearning/comments/2ap06q/quoc_les_from_google_brain_lectures_on_deep/,[deleted],1405366646,,0,0,False,default,,,,,
110,MachineLearning,t5_2r3gv,2014-7-15,2014,7,15,4,2ap0av,wired.com,Microsoft Challenges Googles Artificial Brain With Project Adam.,https://www.reddit.com/r/MachineLearning/comments/2ap0av/microsoft_challenges_googles_artificial_brain/,qkdhfjdjdhd,1405366709,,4,6,False,http://a.thumbs.redditmedia.com/a1T3BMmVvhC8GNN0.jpg,,,,,
111,MachineLearning,t5_2r3gv,2014-7-15,2014,7,15,6,2apepn,self.MachineLearning,"Estimating residual/error distribution from regularised regression (ridge, lasso, eslastic net)",https://www.reddit.com/r/MachineLearning/comments/2apepn/estimating_residualerror_distribution_from/,PoddyOne,1405374486,"Hi there,

I'm trying to use an elastic net to fit a predictive model where I have some high correlation between my covariates. However, I really need a model for my error distribution. So just to be clear, I'm fitting a model

    y=\beta X + \epsilon

and I want the distribution of \epsilon, (it may depend on X, or at least \hat{y}).

Ideally the model would be fit taking into account this distribution, but I'll settle with a good way of estimating it after the fact for now.

Thanks.",4,0,False,self,,,,,
112,MachineLearning,t5_2r3gv,2014-7-15,2014,7,15,6,2apf9b,self.MachineLearning,"Computer Vision: Models, Learning, and Inference by Prince",https://www.reddit.com/r/MachineLearning/comments/2apf9b/computer_vision_models_learning_and_inference_by/,TheJesterBrother,1405374791,"Hello, Im new to CV and machine learning, I was wondering if anyone has anything to say about this book. Would it be a good place to start ML (or CV, for that matter)?
",1,3,False,self,,,,,
113,MachineLearning,t5_2r3gv,2014-7-15,2014,7,15,7,2apjhl,thisismetis.com,Metis Data Science Bootcamp accepting applications through 8/11 for autumn session in NYC,https://www.reddit.com/r/MachineLearning/comments/2apjhl/metis_data_science_bootcamp_accepting/,bailey_jameson,1405377200,,5,0,False,default,,,,,
114,MachineLearning,t5_2r3gv,2014-7-15,2014,7,15,8,2apoih,self.MachineLearning,What are some of the best books related to Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/2apoih/what_are_some_of_the_best_books_related_to/,[deleted],1405380085,"This sub has tons of posts on free books related to machine learning, but I just don't know how many of them are good.

Posts like these http://redd.it/2anzao and http://redd.it/1jeawf give dozens of books to read, but I don't know which ones to pick.

So what is the sub's opinion on some of the best book?

Note: The book does not have to be free. I would prefer books of all levels, introductory to advanced.

EDIT: I just saw this http://www.reddit.com/r/MachineLearning/comments/20i0vi/meta_collection_of_links_for_beginners_faq/ but this applies to beginner books so I guess show me your favorite moderate/advanced books.",4,10,False,default,,,,,
115,MachineLearning,t5_2r3gv,2014-7-15,2014,7,15,9,2apwjf,arxiv.org,Microsoft's Project Adam is using 'HOGWILD!' for Neural Networks on CPUs,https://www.reddit.com/r/MachineLearning/comments/2apwjf/microsofts_project_adam_is_using_hogwild_for/,glaksh09,1405385043,,1,2,False,default,,,,,
116,MachineLearning,t5_2r3gv,2014-7-15,2014,7,15,11,2aq4l6,self.MachineLearning,Machine Learning Study Group Week 4: Solomonoff's 'An Inductive Inference Machine',https://www.reddit.com/r/MachineLearning/comments/2aq4l6/machine_learning_study_group_week_4_solomonoffs/,rovingr,1405390066,"This week's blog post is up -- check out http://datasciencetalk.blogspot.com . This week's article is Solomonoff's 'An Inductive Inference Machine'-- feel free to discuss the article either in this thread or in the blog's comments, as well as last week's post on Breiman's 'Statistical Modeling: The Two Cultures'. 


Links to past threads: 
http://www.reddit.com/r/MachineLearning/comments/2967qh/machine_learning_study_group_week_3_breimans/
http://www.reddit.com/r/MachineLearning/comments/28hlal/machine_learning_study_group_thread_2/ http://www.reddit.com/r/MachineLearning/comments/27p3aj/machine_learning_study_group_thread_1_update/ http://www.reddit.com/r/MachineLearning/comments/26x06e/machine_learning_study_group_thread_1/",0,5,False,self,,,,,
117,MachineLearning,t5_2r3gv,2014-7-15,2014,7,15,12,2aqbv5,self.MachineLearning,need help with brainmaker NN software for horse racing,https://www.reddit.com/r/MachineLearning/comments/2aqbv5/need_help_with_brainmaker_nn_software_for_horse/,heguerra,1405394495,,0,0,False,default,,,,,
118,MachineLearning,t5_2r3gv,2014-7-15,2014,7,15,13,2aqh63,self.MachineLearning,Understanding ROC curve,https://www.reddit.com/r/MachineLearning/comments/2aqh63/understanding_roc_curve/,rincewinds,1405398051,"Hi all,

I know the basics of machine learning and the logic behind many algorithms. But no reading helped intuitively understand the AUC metric used for a kaggle competition. I wanted to understand intuitively ROC curve and what increases area under curve. So I built a simple graphic using d3 at http://www.navan.name/roc/. You can drag the threshold bar and also adjust position of the curve for negatives using the slider at the top of graphic. You can play with these values to understand its effect on the ROC curve. It is not very polished, but it served the purpose for me.

I posted it to kaggle forums initially and I am posting it here in the hope it benefits others who are in the same boat.",16,30,False,self,,,,,
119,MachineLearning,t5_2r3gv,2014-7-15,2014,7,15,15,2aqs58,issuu.com,ISSUU - Excavator Attachments for Sale by Machines4u,https://www.reddit.com/r/MachineLearning/comments/2aqs58/issuu_excavator_attachments_for_sale_by_machines4u/,jessicperson,1405407419,,0,1,False,default,,,,,
120,MachineLearning,t5_2r3gv,2014-7-16,2014,7,16,7,2asxe9,plus.google.com,Why Probabilistic Programming Matters.,https://www.reddit.com/r/MachineLearning/comments/2asxe9/why_probabilistic_programming_matters/,qkdhfjdjdhd,1405462134,,24,40,False,http://b.thumbs.redditmedia.com/sdN9ZlGHyYFMoCT9.jpg,,,,,
121,MachineLearning,t5_2r3gv,2014-7-16,2014,7,16,9,2at8ns,self.MachineLearning,Time Series Question- Please Help,https://www.reddit.com/r/MachineLearning/comments/2at8ns/time_series_question_please_help/,fhadley,1405468909,"So this is something with which I've been struggling  lately, and I think I have a solution, but I'm curious as to how others would handle this. 

I have a dataset that describes a discrete (temporal) sequence of ~15 events observed in specific individuals. The target here is a rolling cost measurement, and I also have temporal inputs that describe items that contributed to the cost in the given period. FWIW, the cost variable alone for a specific individual isn't rather informative (i.e. an AR(I)MA on just the cost for just one person wouldn't be insightful). However, there are patterns in cost shared across the entire population, and there are also similar trends in the target-input relationship shared across individuals.

In addition to the sequential information, for each individual I have another set of data with static features that contain data similar to demographics. This set includes ~100 features. The static and sequential data for each individual are linked.

So I know there are stats-y kinds of ways to deal with this (hierarchical models, ignoring sequential nature of the data, etc.), but my data violates most of the necessary assumptions. Similarly, I could either ignore the sequential nature of the data and feed it to any of a number of ML models, but through personal experience and domain research, I've found that this results in significant information loss and poor model performance. Likewise, I suppose that I could mash the static data together with the sequential, essentially repeating a demographic characteristic 15 times. That doesn't seem like a good idea from a math point of view.

Thus, here's what I'm currently considering: a hybrid HMM-RNN model. The HMM will model the relationship between the static data and the rolling cost, and will have access to cost at t-1 (relatively standard HMM). The RNN- recurrent neural net- will be used to model the relationship between the sequential inputs and the rolling target. As the sequences would be too short to train independently, and it would be illogical to combine all of the sequences into one long one, I'll use a slightly different training method for the RNN. I'll train each sequence (i.e. each individual) separately, then use the final weights for the first individual as the starting weights for the following, and repeat until convergence.

I'd greatly appreciate criticism of my idea, recommendations of different techniques, or paper suggestions. Honestly, I'd be exceedingly grateful for just a hint on search keywords, as I'm at a loss here.",3,0,False,self,,,,,
122,MachineLearning,t5_2r3gv,2014-7-16,2014,7,16,10,2atjp4,self.MachineLearning,Suggestions for a small Twitter World Cup Project,https://www.reddit.com/r/MachineLearning/comments/2atjp4/suggestions_for_a_small_twitter_world_cup_project/,vantpach,1405475804,"As part of a small school project, I have collected tweets from a few world cup games over the past month.  I was using the 'hash flags' that twitter provided; so if I was grabbing tweets for Brazil vs Colombia I would be searching for '#bra or #col'.

I didn't store all of the information for each tweet, instead I just stored:

* time the tweet was created
* text from the tweet
* language of the tweet
* hashtags
* user location
* user utc offset
* user timezone

I have about 700k tweets for each game.

[Here](http://imgur.com/xS6rJ1I) is something I through together really quickly that demonstrates the volume of tweets based on which hashtags were in the tweet.

The school project is to use this data to preform some sort of machine learning.  Originally I wanted to use the tweet volume to identify potential goals (any spike in the data would be a potential positive), and do some sentiment analysis on each team's tweets to identify the false positives.  The problem with this is that I will have to label the tweets myself.

tldr; I need to use this data to explore some concept in ML or NLP but I don't know what to do.",8,0,False,self,,,,,
123,MachineLearning,t5_2r3gv,2014-7-16,2014,7,16,14,2au3vx,github.com,"Machine Learning frameworks, libraries and software",https://www.reddit.com/r/MachineLearning/comments/2au3vx/machine_learning_frameworks_libraries_and_software/,josephmisiti,1405489785,,13,42,False,http://a.thumbs.redditmedia.com/RK0UnLvQgJ4Kdg9p.jpg,,,,,
124,MachineLearning,t5_2r3gv,2014-7-16,2014,7,16,17,2aubys,scribd.com,Crane Attachments,https://www.reddit.com/r/MachineLearning/comments/2aubys/crane_attachments/,jessicperson,1405498124,,0,1,False,default,,,,,
125,MachineLearning,t5_2r3gv,2014-7-16,2014,7,16,20,2aukmr,self.MachineLearning,"Databases for ""big data"" NLP - how is MongoDB?",https://www.reddit.com/r/MachineLearning/comments/2aukmr/databases_for_big_data_nlp_how_is_mongodb/,in_the_fresh,1405508651,"I am currently working on an NLP project in which I perform semantic analysis on several million social network profiles. As is, they are stored as individual json files on an ec2 instance, each having been scraped from the web. Has anyone had success with NoSQL databases, like MongoDB, for model prototyping and training? Is it going to be a huge hassle to get the several million individual json files into the MongoDB database? 

Thanks in advance!",11,1,False,self,,,,,
126,MachineLearning,t5_2r3gv,2014-7-17,2014,7,17,0,2av5gb,wired.com,(Wired Magazine) Inside the Artificial Brain Thats Remaking the Google Empire,https://www.reddit.com/r/MachineLearning/comments/2av5gb/wired_magazine_inside_the_artificial_brain_thats/,mtnchkn,1405524631,,8,2,False,http://a.thumbs.redditmedia.com/A_21E4lGPDDe2IEV.jpg,,,,,
127,MachineLearning,t5_2r3gv,2014-7-17,2014,7,17,1,2ave5g,self.MachineLearning,How do you estimate the Fisher information matrix from a data set?,https://www.reddit.com/r/MachineLearning/comments/2ave5g/how_do_you_estimate_the_fisher_information_matrix/,oneona,1405529688,"I'm sorry if this is the wrong subreddit but it seems like this must be a trivial question for many of the people active here. Please feel free to point me in the direction of a more appropriate subreddit though if one exists. The question I have is the following:

Suppose I have some black box which given some choice of a fixed number of parameters \theta_{i}, will output a finite amount of data drawn from some unknown distribution which depends on the parameters \theta_{i}. I can vary each parameter in turn and see what the resulting data set looks like. Once I have obtained data sets for a range of parameter values I would then like to estimate the Fisher information matrix for the unknown distribution for a given choice of parameters. Is there a standard way of doing this? It seems like there must be.",8,1,False,self,,,,,
128,MachineLearning,t5_2r3gv,2014-7-17,2014,7,17,9,2awp2c,self.MachineLearning,Seeking a flow chart for selecting an appropriate machine learning or data mining algorithm for a given data set,https://www.reddit.com/r/MachineLearning/comments/2awp2c/seeking_a_flow_chart_for_selecting_an_appropriate/,sleepicat,1405555408,"Does a flow chart exist that helps you quickly decide what type of algorithm is best for answering a certain type of question for a given dataset?

For example, it might suggest one type of algorithm for a classification problem where n &lt; p and another when n &gt; p, then another type of many of your p are collinear or another when many p are simply not predictive, etc. 

Any suggestions?
",3,11,False,self,,,,,
129,MachineLearning,t5_2r3gv,2014-7-17,2014,7,17,10,2awx28,wired.com,So It Begins: Darpa Sets Out to Make Computers That Can Teach Themselves,https://www.reddit.com/r/MachineLearning/comments/2awx28/so_it_begins_darpa_sets_out_to_make_computers/,leewardx,1405560524,,0,0,False,http://b.thumbs.redditmedia.com/tqo_VNRqmorckjLW.jpg,,,,,
130,MachineLearning,t5_2r3gv,2014-7-17,2014,7,17,16,2axp0o,maykhumuiozone.com,Bn ang s dng phng php g  kh mi  t?,https://www.reddit.com/r/MachineLearning/comments/2axp0o/bn_ang_s_dng_phng_php_g__kh_mi__t/,ngoctongvt,1405581190,,0,1,False,default,,,,,
131,MachineLearning,t5_2r3gv,2014-7-17,2014,7,17,16,2axp2h,machineryequipment123.blogspot.com,Purpose Of Using Long Reach Excavator - Machinery &amp; Equipment Part Online,https://www.reddit.com/r/MachineLearning/comments/2axp2h/purpose_of_using_long_reach_excavator_machinery/,jessicperson,1405581244,,0,1,False,default,,,,,
132,MachineLearning,t5_2r3gv,2014-7-17,2014,7,17,16,2axqle,self.MachineLearning,Machine Learning with Computer Vision,https://www.reddit.com/r/MachineLearning/comments/2axqle/machine_learning_with_computer_vision/,fight_off_thy_demons,1405582837,"Say I have a gray scale image, 640x480 pixels, like this image: http://www.chiefdelphi.com/media/photos/39147 How plausible would it be to train a neural network, with the input of each pixel, to calculate distance? In my training data, I would load in thousands of images with corresponding distances.. I think this would be really cool way of doing computer vision to find the distance to a target. 

And how long would it take, approximately, to go through one calculation for a new image?",11,3,False,self,,,,,
133,MachineLearning,t5_2r3gv,2014-7-17,2014,7,17,20,2ay1kc,self.MachineLearning,Feature Extraction using wavelets,https://www.reddit.com/r/MachineLearning/comments/2ay1kc/feature_extraction_using_wavelets/,subszero,1405595764,"Hi,

I am currently working with the WISDM dataset [WISDM](http://www.cis.fordham.edu/wisdm/dataset.php) which contains accelerometer data. I am attempting to perform **activity recognition** using this dataset.

I tried initially with time series data and got decent results for sequence prediction (~87%). I am now looking to improve the results by using **wavelet features**.

I am using the pyWavelets library [pyWavelets](http://www.pybytes.com/pywavelets/) for this purpose. I am not really familiar with wavelets, but am currently using the 'db3' wavelet and trying out the approximate and detail coefficients at different levels (1,2,3,4) as features.

Sadly, my results have not been encouraging. Can you guys suggest techniques to extract wavelet features in a better way ?",1,5,False,self,,,,,
134,MachineLearning,t5_2r3gv,2014-7-17,2014,7,17,22,2aya7k,self.MachineLearning,"If you were hiring/admitting to programs in Machine Learning, what would you expect them to know?",https://www.reddit.com/r/MachineLearning/comments/2aya7k/if_you_were_hiringadmitting_to_programs_in/,TheDrownedKraken,1405603710,"This is really two separate questions, one for hiring and one for admission to schools, but I'm just curious what you're answers are. I read somewhere that someone said they'd expect you to be familiar with and have implemented dozens of advanced algorithms. However, they didn't give any examples of what they considered *advanced*. 

I ask because I'm extremely interested in the subject, and I consider myself familiar on a surface/basic understanding level.  I'd like to go get my PhD in Statistics next year, and I want to focus on machine learning/statistical learning. I'd like to start getting into the deeper things now though.",13,5,False,self,,,,,
135,MachineLearning,t5_2r3gv,2014-7-17,2014,7,17,23,2aydzu,self.MachineLearning,"Do you enjoy your job? If you could do it over again, what would you do differently?",https://www.reddit.com/r/MachineLearning/comments/2aydzu/do_you_enjoy_your_job_if_you_could_do_it_over/,rorschach13,1405606328,"Quick background: I'm an aerospace engineer getting my PhD (I've been aero all the way through BS/MS/PhD). My master's degree ended up being built around computer vision, and my PhD has evolved to the point that it has become a massive machine learning problem. I've discovered a passion for machine learning over the last few years. I will likely break away from aerospace when I finish up my PhD.

My question for you - if you have a job in ML, do you enjoy it? Do you feel like you are able to use your creative talents? What is the work culture like? If you could do it all over again, would you choose ML or would you go into a different field?

Finally, and only tangentially related - do you have any other advice? (beyond the usual ""take the Coursera class, do Kaggle competitions, etc."")",26,22,False,self,,,,,
136,MachineLearning,t5_2r3gv,2014-7-18,2014,7,18,2,2ayycp,self.MachineLearning,"[ANN] TH++(C++ tensor library), FBLuaLib (Torch / Lua components)",https://www.reddit.com/r/MachineLearning/comments/2ayycp/ann_thc_tensor_library_fblualib_torch_lua/,tudorb,1405617995,"Torch (http://torch.ch/) is a scientific computing framework heavily used in the machine learning community. We have been using it in Facebook AI Research, and we've extended it to suit our needs; today we're releasing some of these extensions to the community at large, with more to come in the future:

* A C++ tensor library based on the library underpinning Torch's functionality, https://github.com/facebook/thpp
* A bridge between Lua / Torch and Python, allowing seamless integration between the two, https://github.com/facebook/fblualib/tree/master/fblualib/python (for example, using SciPy (http://scipy.org/) with Torch becomes easy)
* A fast serialization library for Lua / Torch (https://github.com/facebook/fblualib/tree/master/fblualib/thrift) using Thrift (https://github.com/facebook/fbthrift) as the interchange format, facilitating easy sharing of large amounts of data among code written in multiple languages
* A fully-featured source debugger for Lua / Torch (https://github.com/facebook/fblualib/tree/master/fblualib/debugger)
* ... and more; see https://github.com/facebook/fblualib for the full list.

We hope that other researchers will find these components useful as well.",4,23,False,self,,,,,
137,MachineLearning,t5_2r3gv,2014-7-18,2014,7,18,4,2azdpc,lauradhamilton.com,10 Tips for Better Deep Learning Models,https://www.reddit.com/r/MachineLearning/comments/2azdpc/10_tips_for_better_deep_learning_models/,emperor-penguin,1405626398,,0,0,False,default,,,,,
138,MachineLearning,t5_2r3gv,2014-7-18,2014,7,18,4,2azes2,blogs.wsj.com,Germanys 12th Man at the World Cup: Big Data,https://www.reddit.com/r/MachineLearning/comments/2azes2/germanys_12th_man_at_the_world_cup_big_data/,[deleted],1405626988,,1,0,False,default,,,,,
139,MachineLearning,t5_2r3gv,2014-7-18,2014,7,18,5,2aziht,machinesolutions.ca,press brake tooling ontario - Machine Solutions Inc,https://www.reddit.com/r/MachineLearning/comments/2aziht/press_brake_tooling_ontario_machine_solutions_inc/,machineryguide101,1405628963,,2,0,False,default,,,,,
140,MachineLearning,t5_2r3gv,2014-7-18,2014,7,18,15,2b10rl,ideasfor.com.au,Ideas and Tips for Choosing the Right Mining Equipment - Ideas For Blog,https://www.reddit.com/r/MachineLearning/comments/2b10rl/ideas_and_tips_for_choosing_the_right_mining/,jessicperson,1405666685,,0,1,False,default,,,,,
141,MachineLearning,t5_2r3gv,2014-7-18,2014,7,18,22,2b1kre,techcrunch.com,"Unbabel Raises $1.5M To Expand Translation Service, Grow Customer Base",https://www.reddit.com/r/MachineLearning/comments/2b1kre/unbabel_raises_15m_to_expand_translation_service/,gracaninja,1405689073,,0,0,False,http://b.thumbs.redditmedia.com/-yZeQnw9CkGlB_gI.jpg,,,,,
142,MachineLearning,t5_2r3gv,2014-7-19,2014,7,19,1,2b20ct,self.MachineLearning,What are appropriate validation methods for a Bayesian network model with low sample size?,https://www.reddit.com/r/MachineLearning/comments/2b20ct/what_are_appropriate_validation_methods_for_a/,SymphMeta,1405699410,"I am currently using a Bayesian network model with 20 variables and 210 data points, with 15 locations measured at 14 different time points each. There are also some restrictions on what types of connections are allowed.

I have looked at leave-one-out cross-validation methods (and arguably leave-two-out would be computationally feasible with this sample size), and I am currently using that method.  However, I want to know which of the following, if any, are appropriate means of going about this:

1. k-fold cross-validation, leaving out a single location (14 points).  My main concern is that if the model were to be applied to locations not sampled, it is quite possible that correlations within a single locations's set of measurements may be unnecessarily influential on a model.  Additionally, it's been suggested that k-fold cross-validation produces better results for simpler models such as linear regression. ^[1] . Since my sample size is small, however, I'm not sure how much I can afford to cut out.


2. Bagging (bootstrap aggregating) ^[3] .  I've mostly seen this method applied to decision trees, but it's used to avoid overfitting.  

3. Jacknifing to determine the properties of the estimators being derived.  

Additionally, one interesting property (at least for the datasets used in Zuk et al. ^[2] ) of the Bayesian Networks is that underfitting decays exponentially fast with sample size, whereas overfitting decays as a power of N.  Keeping that in mind, I am trying to decide what methods are most appropriate for my scenario.

Sources used:

^1 [FAQs.org: What are cross-validation and bootstrapping?](http://www.faqs.org/faqs/ai-faq/neural-nets/part3/section-12.html)

^2 [Zuk et al. ""On the Number of Samples Needed to Learn the Correct Structure of a Bayesian Network"".](http://arxiv.org/ftp/arxiv/papers/1206/1206.6862.pdf)

^3 [Elidan, Gel. ""Bagged Learning Structure of Bayesian Networks"".](http://jmlr.org/proceedings/papers/v15/elidan11a/elidan11a.pdf)

__________________________

I asked this question on [cross-validated](http://stats.stackexchange.com/questions/108355/what-are-appropriate-validation-methods-for-a-bayesian-network-model-with-low-sa), although the only response was that leave-one-out cross-validation is preferable to bagging, and the explanation was not super-detailed.",0,18,False,self,,,,,
143,MachineLearning,t5_2r3gv,2014-7-19,2014,7,19,3,2b2g88,hakkalabs.co,Spectral Algorithms for Learning Latent Variable Models,https://www.reddit.com/r/MachineLearning/comments/2b2g88/spectral_algorithms_for_learning_latent_variable/,BKDev,1405708470,,1,0,False,default,,,,,
144,MachineLearning,t5_2r3gv,2014-7-19,2014,7,19,15,2b46mj,self.MachineLearning,Two rookie questions about randomforest,https://www.reddit.com/r/MachineLearning/comments/2b46mj/two_rookie_questions_about_randomforest/,[deleted],1405752240,"Hi,

1. I have experimented with implementing Random Forests with Salford Predictive Modeler, and the R library caret. Salford Predictive Modeler regularly yields higher r^2 values than I can produce using caret. Does anyone have any idea why?  I would expect caret to outperform Salford Systems, given it's supposedly enlightened recursive feature elimination.


2. I would expect model r^2 to go up consistently with the number of predictors used. But I frequently find that the strongest model uses only a few predictors, and r^2 goes down as I add more. How can this be?

Thanks a lot!",2,0,False,default,,,,,
145,MachineLearning,t5_2r3gv,2014-7-19,2014,7,19,16,2b49zi,theclevermachine.wordpress.com,MCMC: Hamiltonian Monte Carlo (a.k.a. Hybrid Monte Carlo).,https://www.reddit.com/r/MachineLearning/comments/2b49zi/mcmc_hamiltonian_monte_carlo_aka_hybrid_monte/,qkdhfjdjdhd,1405756094,,6,31,False,http://b.thumbs.redditmedia.com/I3WPbNBzuADgejLk.jpg,,,,,
146,MachineLearning,t5_2r3gv,2014-7-19,2014,7,19,21,2b4nxd,self.MachineLearning,[ELI5] Singular Value Decomposition,https://www.reddit.com/r/MachineLearning/comments/2b4nxd/eli5_singular_value_decomposition/,reidhoch,1405774776,"I'm having trouble understanding SVD, how would you explain it to a child?",9,8,False,self,,,,,
147,MachineLearning,t5_2r3gv,2014-7-19,2014,7,19,22,2b4oon,self.MachineLearning,Question on linear SVMs and curse of dimensionality,https://www.reddit.com/r/MachineLearning/comments/2b4oon/question_on_linear_svms_and_curse_of/,Er4zor,1405775610,"Hello, for a project I'm trying to analyze a binary SVM classifier on a set of images. Each image is represented by a vector of 330 values in [0,1], which sum up to 1.  

(I won't explain what those features represent: it would be useless since they lack a clear meaning. Actually, my goal is to try to explain what does the classifier learn from the set)

My training set comprises 1500 training samples (hence with a set of corresponding binary labels), with over 5000 test samples.

As you can see, the dimensionality of the problem is rather high: the data matrix has 1500 rows and 330 columns. Still, I am able to train a linear SVM on 4/5th of the training set, and achieve over 95% accuracy on the remaining 1/5th part of the training set.

I am using LIBLINEAR, with L^2 regularization and L^2 loss function. 

I also made sure to not overfit in any way: inside the 4/5ths I perform feature transformation (z-score normalization) and SVM calibration with an additional 5-fold CV.

What's more interesting is that the same SVM still achieves around 88% of accuracy over the entire test set, which is almost four times as big as the full training set. Results are very robust to choice of cross-validation set.

Why does it perform so well, despite the curse of dimensionality? Is it a general (unexpected?) characteristic of SVMs? Also, do I need to do some sort of dimensionality reduction? (bear in mind that it is impossible to put any meaningful probabilistic structure on the features, hence no LDA, QDA, etc.)

My ansatz is that the classes are truly well-separated, both in the training and in the test set. Still, marginal feature distributions are almost overlapped between classes (although I know that this happens easily, even on R^2), and no feature is particularly dominant over the others, judging by the SVM hyperplane coefficients. However, I would like to rule out the dimensionality effect, to be sure of having obtained a good classifier.

Thank you!",12,4,False,self,,,,,
148,MachineLearning,t5_2r3gv,2014-7-20,2014,7,20,0,2b4xl2,self.MachineLearning,Automated feature extraction,https://www.reddit.com/r/MachineLearning/comments/2b4xl2/automated_feature_extraction/,Regentag,1405783557,"Hello guys,

is there any research done on ""Automated feature extraction""? Any ideas how to realize such a method?

I appreciate your answer!",8,6,False,self,,,,,
149,MachineLearning,t5_2r3gv,2014-7-20,2014,7,20,3,2b5clb,projectbotticelli.com,Azure Machine Learning: A Brief Introduction,https://www.reddit.com/r/MachineLearning/comments/2b5clb/azure_machine_learning_a_brief_introduction/,RockDiesel,1405793846,,1,1,False,http://a.thumbs.redditmedia.com/TnDm-nW3B2bDAP0z.jpg,,,,,
150,MachineLearning,t5_2r3gv,2014-7-20,2014,7,20,11,2b6gsp,self.MachineLearning,Easy way to convert text to low-dimensional representation,https://www.reddit.com/r/MachineLearning/comments/2b6gsp/easy_way_to_convert_text_to_lowdimensional/,alexmlamb,1405822385,"Are there any easy ways to convert a small block of text (10-100 words) into a &lt;1000 dimensional feature vector?  One solution that I'm considering is doing an n-gram encoding, then using random projections to reduce the dimensionality.  ",5,3,False,self,,,,,
151,MachineLearning,t5_2r3gv,2014-7-20,2014,7,20,13,2b6suc,projecteuclid.org,Leo Breiman -- Statistical Modeling: The Two Cultures (with comments and a rejoinder by the author),https://www.reddit.com/r/MachineLearning/comments/2b6suc/leo_breiman_statistical_modeling_the_two_cultures/,carmichael561,1405831863,,3,36,False,http://a.thumbs.redditmedia.com/D0WoG249OKeBbm9Z.jpg,,,,,
152,MachineLearning,t5_2r3gv,2014-7-20,2014,7,20,20,2b7bk7,self.MachineLearning,"Multivariate data mining to extract relevant ""business"" plots?",https://www.reddit.com/r/MachineLearning/comments/2b7bk7/multivariate_data_mining_to_extract_relevant/,Gere1,1405854631,"How would you approach multivariate data analysis, if you want to create ""ordinary"" plots for business where one variable is plotted against another and some meaningful statement is in the plot?

I assume that there is no clear supervised setting, but that some general correlations or causal relations should be extracted. For example I have table-like data for travel orders with customer data, departure, arrival, destination, price, duration of stay, etc.
In a plot I can visualize three dimensions: x, y and color. I can also drill down by one another variable, by creating multiple plots filtered on this variable. Candidates for quantities are the variables and possible aggregations on numerical variables (prize sum, prize per day mean, ...).

*I would like to data-mine for interesting relations/plots as automatized as possible.*

Some ideas are to find 2-variable correlations or 3-variables correlations with lift. Maybe you can automatize it so that valid thresholds are taken? Maybe some graph network analysis would help for causal relationships? Because a plot with some relations could be explained by another variable indirectly. Maybe Random Forests could determine relevant or correlated variables somehow? I could state that variables that have high correlation (e.g. prize and destination) should always be picked together for a plot.

Of course, an algorithm trained on this data would be most accurate, however, I cannot delivery program code, but it should be plots instead.

Do you have any ideas how to decide which of the many combinations for plots are candidates for interesting relations?",2,6,False,self,,,,,
153,MachineLearning,t5_2r3gv,2014-7-21,2014,7,21,8,2b8wpq,metacademy.org,Level-Up Your Machine Learning,https://www.reddit.com/r/MachineLearning/comments/2b8wpq/levelup_your_machine_learning/,RockDiesel,1405898162,,29,73,False,http://b.thumbs.redditmedia.com/g7WSfSN8S90Vmq1M.jpg,,,,,
154,MachineLearning,t5_2r3gv,2014-7-21,2014,7,21,10,2b973c,self.MachineLearning,[Fun] Here are some tough classification problems . . .,https://www.reddit.com/r/MachineLearning/comments/2b973c/fun_here_are_some_tough_classification_problems/,[deleted],1405905154,"http://www.reddit.com/r/misleadingthumbnails

Wow.",0,0,False,self,,,,,
155,MachineLearning,t5_2r3gv,2014-7-21,2014,7,21,13,2b9pg9,dynamicyield.com,Doing Data Science in a Startup: The Hard Truth,https://www.reddit.com/r/MachineLearning/comments/2b9pg9/doing_data_science_in_a_startup_the_hard_truth/,ynavot,1405917980,,1,0,False,http://a.thumbs.redditmedia.com/c62zuXwia920AkQT.jpg,,,,,
156,MachineLearning,t5_2r3gv,2014-7-21,2014,7,21,16,2ba15g,realtechsupport.org,Introduction to Machine Learning by Ethem Alpaydin,https://www.reddit.com/r/MachineLearning/comments/2ba15g/introduction_to_machine_learning_by_ethem_alpaydin/,TwilyS,1405928877,,0,6,False,default,,,,,
157,MachineLearning,t5_2r3gv,2014-7-21,2014,7,21,17,2ba22a,machineryequipment123.blogspot.com,What Do Telehandlers Offer - Machinery &amp; Equipment Part Online,https://www.reddit.com/r/MachineLearning/comments/2ba22a/what_do_telehandlers_offer_machinery_equipment/,jessicperson,1405929997,,0,1,False,default,,,,,
158,MachineLearning,t5_2r3gv,2014-7-21,2014,7,21,22,2baj3j,self.MachineLearning,Best Machine Learning Blogs; Suggestions?,https://www.reddit.com/r/MachineLearning/comments/2baj3j/best_machine_learning_blogs_suggestions/,ilikebigdata,1405948409,Looking for the best websites and blogs specifically dedicated to machine learning; what should I read?,7,14,False,self,,,,,
159,MachineLearning,t5_2r3gv,2014-7-21,2014,7,21,22,2baj8x,self.MachineLearning,Question about the Dropout technique,https://www.reddit.com/r/MachineLearning/comments/2baj8x/question_about_the_dropout_technique/,rishok,1405948512,"I Understand that you apply Dropout for every training set in order to get multiple sub-models to train ones network on. However, do you create new set of sub-models for next iteration (apply Dropout for every training set again) or do you keep set reuse the sub-models?",8,3,False,self,,,,,
160,MachineLearning,t5_2r3gv,2014-7-22,2014,7,22,3,2bbd2h,self.MachineLearning,Is the apparent similarity between the random subspace method and dropout anything more than superficial?,https://www.reddit.com/r/MachineLearning/comments/2bbd2h/is_the_apparent_similarity_between_the_random/,alexgmcm,1405965943,"As I understand in the random subspace method  (e.g. random forests) you randomly omit some of your features in the weak classifiers so you don't end up with all the weak classifiers using a few good features and being highly correlated as then you basically have an ensemble of loads of copies of the same classifier which is pretty useless.

In dropout you randomly omit units from the neural network during training to prevent co-adaptation (i.e. where a unit becomes dependent on other units, so a learned feature/metafeature (what is the proper term for this? I guess just referring to it as a unit?) becomes useful only in the presence of certain other learned features). 

In both cases you use model averaging on the resulting ensemble to obtain the final model.

I could be completely wrong, please feel free to correct me!",8,9,False,self,,,,,
161,MachineLearning,t5_2r3gv,2014-7-22,2014,7,22,4,2bbmdm,jmlr.org,Dropout: A Simple Way to Prevent Neural Networks from Overfitting,https://www.reddit.com/r/MachineLearning/comments/2bbmdm/dropout_a_simple_way_to_prevent_neural_networks/,galapag0,1405970704,,9,36,False,default,,,,,
162,MachineLearning,t5_2r3gv,2014-7-22,2014,7,22,4,2bbmjc,new.livestream.com,ML &amp; Data Science talks streaming live today from @graphlabconf,https://www.reddit.com/r/MachineLearning/comments/2bbmjc/ml_data_science_talks_streaming_live_today_from/,[deleted],1405970775,,0,4,False,default,,,,,
163,MachineLearning,t5_2r3gv,2014-7-22,2014,7,22,7,2bc9kg,inovancetech.com,A Step-by-Step Guide to Using Machine Learning in Your Trading,https://www.reddit.com/r/MachineLearning/comments/2bc9kg/a_stepbystep_guide_to_using_machine_learning_in/,thetzz,1405982921,,0,0,False,default,,,,,
164,MachineLearning,t5_2r3gv,2014-7-22,2014,7,22,11,2bcuae,github.com,A growing collection of machine learning definitions in less than 50 words,https://www.reddit.com/r/MachineLearning/comments/2bcuae/a_growing_collection_of_machine_learning/,[deleted],1405995282,,0,1,False,default,,,,,
165,MachineLearning,t5_2r3gv,2014-7-22,2014,7,22,12,2bd2ea,github.com,machine learning related definitions in less than 50 words,https://www.reddit.com/r/MachineLearning/comments/2bd2ea/machine_learning_related_definitions_in_less_than/,rasbt,1406000393,,4,6,False,http://a.thumbs.redditmedia.com/tf6XtV6Xxn07wX4B.jpg,,,,,
166,MachineLearning,t5_2r3gv,2014-7-22,2014,7,22,16,2bdhih,self.MachineLearning,Kernel Method Performance Comparable to Deep Learning?,https://www.reddit.com/r/MachineLearning/comments/2bdhih/kernel_method_performance_comparable_to_deep/,penguinElephant,1406012465,"So there have been kernels engineered for specific tasks that rival deep nets (e.g., http://arxiv.org/abs/1406.3332) which makes sense, since they do what is known to work well.



But then this paper just came out today on arxiv which scales up kernel methods:

http://arxiv.org/abs/1407.5599

The authors use *RBF kernels* for their experiments and seem to achieve performance comparable to deep nets with minimal preprocessing (some normalization or PCA) on multiple standard datasets (e.g., CIFAR-10, MNIST, ImageNet)

Makes me wonder if RBF kernels were good all along... Do we really need to learn deep feature representations?",4,6,False,self,,,,,
167,MachineLearning,t5_2r3gv,2014-7-22,2014,7,22,17,2bdn75,purposeof.com.au,Purpose of Mining Excavator Attachments - PurposeOf,https://www.reddit.com/r/MachineLearning/comments/2bdn75/purpose_of_mining_excavator_attachments_purposeof/,jessicperson,1406018476,,0,1,False,default,,,,,
168,MachineLearning,t5_2r3gv,2014-7-22,2014,7,22,20,2bdxdf,self.MachineLearning,What are the axes in t-SNE?,https://www.reddit.com/r/MachineLearning/comments/2bdxdf/what_are_the_axes_in_tsne/,alexgmcm,1406029581,"I read the t-SNE paper and understood most (well, some) of it.

I see how it can represent the structure of the data at lower dimensions but if I include it in a presentation and someone asks what the axes are for the plot (a common question) I would just have to say it's one of the great mysteries of the Universe - like the meaning of life, or the location of Geoffrey Hinton's highly-advanced homeworld.

I guess that as it is a graph in the graph theory sense it indicates the pairwise relations between the points and so the distance between any two points is a measure of their similarity but it isn't a scatterplot with axes?

Or am I completely wrong?",15,6,False,self,,,,,
169,MachineLearning,t5_2r3gv,2014-7-22,2014,7,22,23,2beblk,self.MachineLearning,Question: How can i choose the most confident samples in self-training with multi-label dataset ?,https://www.reddit.com/r/MachineLearning/comments/2beblk/question_how_can_i_choose_the_most_confident/,nimakhan66,1406039831,"I want to Implement self-training method on a common multi-label dataset (e.g  yeast.arff) . how can i choose the most confident samples to add them to label set for next iteration? 

Best regards",3,0,False,self,,,,,
170,MachineLearning,t5_2r3gv,2014-7-23,2014,7,23,1,2bemt6,new.livestream.com,Graphlab full day training free via live stream,https://www.reddit.com/r/MachineLearning/comments/2bemt6/graphlab_full_day_training_free_via_live_stream/,shonburton,1406045937,,1,7,False,http://b.thumbs.redditmedia.com/s-kC6PrI4eoe73bc.jpg,,,,,
171,MachineLearning,t5_2r3gv,2014-7-23,2014,7,23,4,2bfc2t,self.MachineLearning,Non-Decomposable Bayesian Network Scoring Functions,https://www.reddit.com/r/MachineLearning/comments/2bfc2t/nondecomposable_bayesian_network_scoring_functions/,[deleted],1406059125,"I have been studying the property of decomposability that most Bayesian network scoring functions have.  That is, the score assigned to the structure can be expressed as a sum of local values that depend only on each node and its parents.  Are there any examples of Bayesian network scoring functions that are not decomposable?",4,0,False,default,,,,,
172,MachineLearning,t5_2r3gv,2014-7-23,2014,7,23,7,2bfuor,self.MachineLearning,Using OCR to read a receipt,https://www.reddit.com/r/MachineLearning/comments/2bfuor/using_ocr_to_read_a_receipt/,Searial,1406068954,"I am looking to try and make an android app to pull out data from a receipt as an exercise. After some basic research I think tesseract may be a good choice, but it looks like some pre-processing is required and opinions vary. Does anyone have suggestions on what sort of pre-processing I should look into (grayscale, binary conversion, gaussian blur, etc.) or if there are any other libraries that may help me out?",4,7,False,self,,,,,
173,MachineLearning,t5_2r3gv,2014-7-23,2014,7,23,14,2bgw3b,datasciencecentral.com,10 types of regressions. Which one to use?,https://www.reddit.com/r/MachineLearning/comments/2bgw3b/10_types_of_regressions_which_one_to_use/,rasbt,1406092153,,4,0,False,default,,,,,
174,MachineLearning,t5_2r3gv,2014-7-23,2014,7,23,16,2bh6ur,purposeof.com.au,The Purpose Of Using Mining Excavator At Mining Sites - PurposeOf,https://www.reddit.com/r/MachineLearning/comments/2bh6ur/the_purpose_of_using_mining_excavator_at_mining/,jessicperson,1406101740,,0,1,False,default,,,,,
175,MachineLearning,t5_2r3gv,2014-7-23,2014,7,23,23,2bhwyy,docs.google.com,"Identifying early stage Parkinson's using Real Time Tweets. Non-profit Project. ** Please fill out Google form, need training data **.",https://www.reddit.com/r/MachineLearning/comments/2bhwyy/identifying_early_stage_parkinsons_using_real/,[deleted],1406125629,,0,1,False,default,,,,,
176,MachineLearning,t5_2r3gv,2014-7-24,2014,7,24,1,2biax2,self.MachineLearning,Artificial Intelligence used to provide a 10X improvement in personalized education using little data,https://www.reddit.com/r/MachineLearning/comments/2biax2/artificial_intelligence_used_to_provide_a_10x/,U5r4F5k,1406133451,"So we have an interesting problem that I want to get some advice on:

**Background:** We are a nonprofit built by a bunch of tech startup founders and enthusiasts that want to do something for our kids: We are building an educational platform, initially for the poorest people on the planet, who don't have access to schools, teachers or the internet, let alone basic infrastructure. A test was done 18 months ago when a box of 40 tablets that were pre-installed with hundreds of educational apps and were given to a remote village in Ethiopia who were 100% illiterate. This box of tablets were left there without any guidance or training on how to use them. The village had a large group of children who had never seen modern technology let alone heard the English language however within hours the first child figured out how to turn one of them on. A few minutes later he taught the rest of the kids how to turn theirs on. 2 weeks later the kids were using on average 57 apps each, a few more weeks after that, they were singing the alphabet song and starting to learn how to read and write letters. After 5 months they learnt how to hack Android. 

Recently the Global Literacy Project expanded on this test and deployed an additional 600 tablets to 8  locations around the world and they are getting back some really great results. We are now convinced that this approach can work and we are taking it to the next stage by developing an AI amongst other things to guide the child through a completely personalized learning experience that dynamically unfolds as the AI learns more about them. The trick is we need to AI to be on-device as we cannot rely on internet connectivity or the creation of local computing nodes. In addition, because we are ultimately also building it for our kids we don't want their highly personal data sitting on some server or being transferred over the internet where it could be intercepted. 

**So the problem is this:** We want the on-device AI to build an increasingly large and personal data set about the learner (E.G. Learner is X age, has X interests, is good at X,Y,Z, is not so good at A,B,C, Has personality traits Q,R,S, works better with X learning style, has completed T,U,V modules .). In addition, the content the learner is learning from will have an increasingly detailed list of metadata associated with it. (E.G. Content Type: Video, Topic: English Nouns, Level: 1, Related to: X,Y,Z..., prerequisites: Q,R,S) however this metadata will also become increasingly large and complex, through learner generated meta data, and updates from our library. 

The AI will then be tasked with many processes to perform like:

* 1. The AI will need to create a map of the content, similar to the [Khan academy Knowledge map](https://www.khanacademy.org/exercisedashboard) Each learners map may be different as they may all have different content installed on their device, or they may have added custom user generated meta data to a piece of content which affects its position in the map.

* 2. The AI will need to use data it has collected from the user through various interactions, personality tests and their general usage and create dynamic learning plans that constantly need to adapt to the needs, goals and interests of the learner. It will do this by analyzing the personal data of the learner, the meta data of the content, and how the content fits within the relational map of linked content. 

* 3. A key focus of this platform is the facilitation of social and collaborative learning. We are using mesh networking technology to link the devices together within the community. The AIs on the network will communicate with each other with the permission of the learner and match up learning pairs or groups to work on problems together. They will also pair Learner X who may have mastered a concept with Learner B who needs help with that concept.

**Our current strategy:** We intend to start off using almost 100% hard coded recommendation engine type logic then gradually use machine learning to develop these further. The key here is that its not a Big data issue, we calling it a little data issue as we need to gain insights from one users data, on device, and make adjustments locally. 

So this is the challenge, how would you structure a solution and what approaches would you use?

Here is some more information about our project: [www.dev4x.com](http://www.dev4x.com)
",6,0,False,self,,,,,
177,MachineLearning,t5_2r3gv,2014-7-24,2014,7,24,2,2bigsf,self.MachineLearning,Why is reinforcement learning so rare here?,https://www.reddit.com/r/MachineLearning/comments/2bigsf/why_is_reinforcement_learning_so_rare_here/,CireNeikual,1406136487,"It seems like machine learning is synonymous with supervised learning and a bit of unsupervised learning. Also deep learning is everything nowadays.

I assume the reason for this is because it is good for applications in which there is money to be had (search engines for example, Google bait stuff).

So, seeing how the field of machine learning works at the moment, I feel like it will only be a footnote on the way to strong AI.

At one point I presented a reinforcement learning technique (I have a FOSS library full of them), and people asked me for MINST results. That doesn't really make sense.

Am I right in drawing these conclusions? Or do you see a clear progression from current supervised learning techniques into strong AI reinforcement learning techniques?

Thank you for your time!",53,46,False,self,,,,,
178,MachineLearning,t5_2r3gv,2014-7-24,2014,7,24,6,2bj8xn,blog.yhathq.com,Fuzzy matching example,https://www.reddit.com/r/MachineLearning/comments/2bj8xn/fuzzy_matching_example/,agconway,1406150679,,1,1,False,http://a.thumbs.redditmedia.com/ozkFneLQe6meJu96.jpg,,,,,
179,MachineLearning,t5_2r3gv,2014-7-24,2014,7,24,10,2bk0s1,haifengl.wordpress.com,The Regularized EM Algorithm,https://www.reddit.com/r/MachineLearning/comments/2bk0s1/the_regularized_em_algorithm/,haifengl,1406167134,,0,6,False,http://b.thumbs.redditmedia.com/4udtA3py8h6W0Jgi.jpg,,,,,
180,MachineLearning,t5_2r3gv,2014-7-24,2014,7,24,17,2bkt83,machineryequipment123.blogspot.com,The Suggested Safety Tips For Working With Forklifts - Machinery &amp; Equipment Part Online,https://www.reddit.com/r/MachineLearning/comments/2bkt83/the_suggested_safety_tips_for_working_with/,jessicperson,1406189344,,0,1,False,default,,,,,
181,MachineLearning,t5_2r3gv,2014-7-24,2014,7,24,17,2bkthw,self.MachineLearning,What are the state of the art techniques for speech based language identification?,https://www.reddit.com/r/MachineLearning/comments/2bkthw/what_are_the_state_of_the_art_techniques_for/,usernaamee,1406189676,"Journal articles, conference papers would help.",4,5,False,self,,,,,
182,MachineLearning,t5_2r3gv,2014-7-24,2014,7,24,20,2bl3fh,falconpumps.weebly.com,Vacuum Pressure Pumps for Paper Folding Machine,https://www.reddit.com/r/MachineLearning/comments/2bl3fh/vacuum_pressure_pumps_for_paper_folding_machine/,falconpumps,1406200841,,0,1,False,default,,,,,
183,MachineLearning,t5_2r3gv,2014-7-25,2014,7,25,1,2blslx,github.com,"MOE, the Metric Optimization Engine. An open source, Bayesian Global Optimization framework for optimal experiment design.",https://www.reddit.com/r/MachineLearning/comments/2blslx/moe_the_metric_optimization_engine_an_open_source/,Zephyr314,1406218252,,9,52,False,http://b.thumbs.redditmedia.com/fmstjAYSDSnWNDeS.jpg,,,,,
184,MachineLearning,t5_2r3gv,2014-7-25,2014,7,25,4,2bmdnp,cbinsights.com,News Classification - Step by Step Our Pipeline,https://www.reddit.com/r/MachineLearning/comments/2bmdnp/news_classification_step_by_step_our_pipeline/,bugra,1406229401,,0,2,False,http://b.thumbs.redditmedia.com/bJdxnjp4TCzgE8Ey.jpg,,,,,
185,MachineLearning,t5_2r3gv,2014-7-25,2014,7,25,6,2bms9q,self.MachineLearning,Is there a ML technique applicable to this problem? (knapsack variation with an item of 'variable' volume),https://www.reddit.com/r/MachineLearning/comments/2bms9q/is_there_a_ml_technique_applicable_to_this/,tperrigo,1406236887,"I'm very, very new to machine learning, but I'm dealing with a problem that seems like it might be a candidate for a ML approach.  It's basically a knapsack problem, with a twist.  I've got a set of items (A, B, C,...) each with a known volume (the percentage of the container it will take up).  However, there's another item, X, which often fits in the 'spaces between' other items, but how many X's a container can hold depends on what other items are in the container.  For example, if the container holds 2 A's and 1 B, then I can fit 4 X's.  However, if I add a C to the container, I can now only fit 2 X's.  I have some historical data to work with, so I know in the past the various configurations and how many X's they were able to contain.  Is there a way to construct a model based on this historical data so that I can feed it a proposed consolidation, and get back how many X's such a configuration could contain?  

Any suggestions would be appreciated (even if it's just to tell me I'm on the wrong track and should look into some other-- non-ML-- approach).  Thanks!",12,2,False,self,,,,,
186,MachineLearning,t5_2r3gv,2014-7-25,2014,7,25,12,2bntuw,self.MachineLearning,What are some state of the art ML techniques in emotion recognition from speech?,https://www.reddit.com/r/MachineLearning/comments/2bntuw/what_are_some_state_of_the_art_ml_techniques_in/,holo11,1406260044,,3,2,False,self,,,,,
187,MachineLearning,t5_2r3gv,2014-7-25,2014,7,25,14,2bo1p0,falconpumps.wordpress.com,Vacuum Pressure Pumps for Komori,https://www.reddit.com/r/MachineLearning/comments/2bo1p0/vacuum_pressure_pumps_for_komori/,falconpumps,1406265872,,0,0,False,default,,,,,
188,MachineLearning,t5_2r3gv,2014-7-25,2014,7,25,20,2bomsa,self.MachineLearning,Question: Vanishing gradient in RNNs - yes or no?,https://www.reddit.com/r/MachineLearning/comments/2bomsa/question_vanishing_gradient_in_rnns_yes_or_no/,qwer1304,1406288276,"Hi,  
One of the often cited issues in RNN training is the vanishing gradient problem ([Y.Bengio et al.](http://dx.doi.org/10.1109/72.279181), [S.Hochreiter](http://dx.doi.org/10.1142/S0218488598000094), [S.Hochreiter et al.](ftp://ftp.idsia.ch/pub/juergen/gradientflow.pdf), [R.Pascanu et al.](http://arxiv.org/abs/1211.5063)).  
However, I came across several papers by Anton Maximilian Schaefer, Steffen Udluft and Hans-Georg Zimmermann (e.g., [here](http://www.sciencedirect.com/science/article/pii/S0925231208002105)) in which it is claimed that the problem doesn't exist even in a simple RNN, if shared weights are used.  

So, which one is true - does the vanishing gradient problem exist or not?

Thx,  
D",2,2,False,self,,,,,
189,MachineLearning,t5_2r3gv,2014-7-25,2014,7,25,21,2booeb,falconpumps.wordpress.com,Vacuum Pressure Pumps for Mitsubishi,https://www.reddit.com/r/MachineLearning/comments/2booeb/vacuum_pressure_pumps_for_mitsubishi/,falconpumps,1406289890,,0,0,False,default,,,,,
190,MachineLearning,t5_2r3gv,2014-7-25,2014,7,25,21,2bopxs,self.MachineLearning,Question about the max-norm constraint used with the Dropout technique,https://www.reddit.com/r/MachineLearning/comments/2bopxs/question_about_the_maxnorm_constraint_used_with/,rishok,1406291314,"Maxout uses the max-norm constraint (or dropout does). Do you know when to enforce the constraint, during update ? or during calculating the pre-activation?",5,5,False,self,,,,,
191,MachineLearning,t5_2r3gv,2014-7-25,2014,7,25,23,2bp0v3,youtube.com,Machine Learning and the Big Data Ecosystem with Adam Drake of zanox,https://www.reddit.com/r/MachineLearning/comments/2bp0v3/machine_learning_and_the_big_data_ecosystem_with/,[deleted],1406299265,,0,0,False,default,,,,,
192,MachineLearning,t5_2r3gv,2014-7-26,2014,7,26,0,2bp5na,scottlocklin.wordpress.com,Neglected machine learning ideas,https://www.reddit.com/r/MachineLearning/comments/2bp5na/neglected_machine_learning_ideas/,dafcok,1406302141,,25,52,False,http://a.thumbs.redditmedia.com/qtgox0l_DHcm0mZ4.jpg,,,,,
193,MachineLearning,t5_2r3gv,2014-7-26,2014,7,26,3,2bpo2m,boozallen.com,The Field Guide to Data Science,https://www.reddit.com/r/MachineLearning/comments/2bpo2m/the_field_guide_to_data_science/,redknightlois,1406312388,,5,0,False,default,,,,,
194,MachineLearning,t5_2r3gv,2014-7-26,2014,7,26,6,2bq8xp,self.MachineLearning,List of most important ML research labs?,https://www.reddit.com/r/MachineLearning/comments/2bq8xp/list_of_most_important_ml_research_labs/,makakimekaki,1406324162,"what are the most important and famous machine learning, robotics, data mining research labs?",6,1,False,self,,,,,
195,MachineLearning,t5_2r3gv,2014-7-26,2014,7,26,8,2bqku9,richardminerich.com,"Review: Sony Digital Paper DPT-S1, an e-ink device ideal for notes and papers",https://www.reddit.com/r/MachineLearning/comments/2bqku9/review_sony_digital_paper_dpts1_an_eink_device/,Rickasaurus,1406331658,,9,5,False,http://a.thumbs.redditmedia.com/M2pZjnlBCuob2wp6.jpg,,,,,
196,MachineLearning,t5_2r3gv,2014-7-26,2014,7,26,10,2bqsly,self.MachineLearning,Dirichlet Process background?,https://www.reddit.com/r/MachineLearning/comments/2bqsly/dirichlet_process_background/,frogwarzez,1406337185,"I was reading this introduction to Dirichlet processes http://www.gatsby.ucl.ac.uk/~ywteh/research/npbayes/dp.pdf but I found that I'm not familiar with a lot of concepts and terminology.I have intermediate knowledge of stats, not much beyond regressions and good understanding of common machine learning algorithms (classification, clustering). What background gaps do I need to fill to understand this article? Do I need a first course in Bayesian nonparametrics? Anything even before that? Recommendations are appreciated. Thanks.",6,13,False,self,,,,,
197,MachineLearning,t5_2r3gv,2014-7-26,2014,7,26,10,2bqtj9,auai.org,Uncertainty In Artificial,https://www.reddit.com/r/MachineLearning/comments/2bqtj9/uncertainty_in_artificial/,[deleted],1406337819,,0,1,False,default,,,,,
198,MachineLearning,t5_2r3gv,2014-7-26,2014,7,26,11,2bqxup,datascienceassn.org,Data Fusion is Data Destruction [OC],https://www.reddit.com/r/MachineLearning/comments/2bqxup/data_fusion_is_data_destruction_oc/,michaelmalak,1406340863,,1,0,False,http://b.thumbs.redditmedia.com/AeDS017tyb38QPyc.jpg,,,,,
199,MachineLearning,t5_2r3gv,2014-7-26,2014,7,26,14,2brcvh,falconpumps.weebly.com,Vacuum Pressure Pumps for Diary Making Plants,https://www.reddit.com/r/MachineLearning/comments/2brcvh/vacuum_pressure_pumps_for_diary_making_plants/,falconpumps,1406352710,,0,1,False,default,,,,,
200,MachineLearning,t5_2r3gv,2014-7-26,2014,7,26,18,2bro4f,self.MachineLearning,Suggestions for enrolling into university for ML,https://www.reddit.com/r/MachineLearning/comments/2bro4f/suggestions_for_enrolling_into_university_for_ml/,SaMSaMSaMv2,1406365709,"Hey guys

I am interested in doing my masters in Machine Learning. Can you suggest me universities which are currently doing a lot of work in this field? I only know of CMU as of now. Also if it helps I am more interested in NLP. 

Thanks for the help.",10,1,False,self,,,,,
201,MachineLearning,t5_2r3gv,2014-7-27,2014,7,27,11,2btuqb,thoughtly.co,IntelliButler - A Deep Learning Assistant for Social Media (launching Aug 2014),https://www.reddit.com/r/MachineLearning/comments/2btuqb/intellibutler_a_deep_learning_assistant_for/,[deleted],1406428460,,7,0,False,default,,,,,
202,MachineLearning,t5_2r3gv,2014-7-28,2014,7,28,1,2bv8bf,self.MachineLearning,Where can I find a good intro to random forests?,https://www.reddit.com/r/MachineLearning/comments/2bv8bf/where_can_i_find_a_good_intro_to_random_forests/,[deleted],1406479087,"While I know a little about regression and associated topics from Andrew Ng's class, I'm a total newb to trees, bagging, boosting, and random forests. What's a good place to start? I'm willing to put in the time, but feeling a little lost.

Things I've already tried: Hastie-Tibshirani-Friedman's ""The Elements of Statistical Learning"" is comprehensive but difficult as a first intro, whereas the JHU ""Practical Machine Learning"" class on Coursera quickly breezes through all of the above leaving me feeling like I have little understanding of it.

Any suggestions would be appreciated, even if they are ""Go back to The Elements of Statistical Learning and read it ten times!""",7,6,False,self,,,,,
203,MachineLearning,t5_2r3gv,2014-7-28,2014,7,28,2,2bvee7,self.MachineLearning,Can I use Go as a replacement for Octave/Python for machine learning projects?,https://www.reddit.com/r/MachineLearning/comments/2bvee7/can_i_use_go_as_a_replacement_for_octavepython/,whiskeybandit,1406483235,"In particular, to do things like vector and matrix manipulation. I was even thinking about using it to do image processing. Is it worth the effort?",20,0,False,self,,,,,
204,MachineLearning,t5_2r3gv,2014-7-28,2014,7,28,4,2bvn1f,datascienceweekly.org,Social Media &amp; Machine Learning tell Stores where to locate,https://www.reddit.com/r/MachineLearning/comments/2bvn1f/social_media_machine_learning_tell_stores_where/,hrb1979,1406488863,,0,2,False,http://b.thumbs.redditmedia.com/0fldkP0QXjJJ1FPS.jpg,,,,,
205,MachineLearning,t5_2r3gv,2014-7-28,2014,7,28,6,2bvxv6,self.MachineLearning,Machine Learning to aid my Fantasy League Picks,https://www.reddit.com/r/MachineLearning/comments/2bvxv6/machine_learning_to_aid_my_fantasy_league_picks/,Arramack,1406495791,"I'm trying to apply machine learning to the data in my sports fantasy league, to see if I can't build a model to make my picks for me.


The rules are pretty simple:

* You make a pick on the winning margin of a real life sports event.
* If you are within 5 points of this margin, you get 0.5 points.
* If you are the closest person in your pool to the actual winning margin you get 1 point.

A pool is just your group of friends, and is normally between 5-25 people. Pool sizes are static for the whole season (18 weeks and about 18x6 games/picks). You can't see other people's picks until you have made your pick for that respective game. You can make the same pick as somebody else.


There are two **exclusive** strategies.

* You go really high or really low with your pick and hope you are on the edge of the group of picks. That way if the game ends with a high or low score you get a full point. For example if everyone chooses between 3-12 for the winning margin and you pick 20. If the game ends with a score of 50 then you get 1 point.
* You try and hit the actual winning margin of the game dead on, thereby increasing your chances of getting a margin point of 0.5 (easier to get, but less points).

[GRAPH:](http://i.imgur.com/cBa9HYq.jpg) This graph shows picks made by a large number of people for a single game. The horizontal axis is the margin, so to the left of 0 is Team A winning, and to the right of 0 is Team B winning. The vertical axis is the amount of people that made that specific pick.


Although the data has been aggregated, the people are all actually playing in small pools of 5-25 people. You can see based on that graph if I wanted to try and be the closest to a winning margin a good pick would be 17. That would put me on the high side with a low probability of having anyone higher.

What is surprising is how people have a tendency to pick certain numbers. I keep seeing people pick the number 4, 6, 8, 11, 13, and 16 way more than other numbers.

So here is the problem that I want to solve. Given that the bookies say Team A will beat Team B by a margin of X, and given that I have Y other players in my pool, what should my pick be?

Will I be able to solve this with machine learning or statistics if I have enough historic data?
",12,7,False,self,,,,,
206,MachineLearning,t5_2r3gv,2014-7-28,2014,7,28,8,2bw9n7,arxiv.org,Long-Short Term Memory Deep Neural Networks and Dropout,https://www.reddit.com/r/MachineLearning/comments/2bw9n7/longshort_term_memory_deep_neural_networks_and/,alexmlamb,1406503384,,0,6,False,default,,,,,
207,MachineLearning,t5_2r3gv,2014-7-28,2014,7,28,8,2bwb0j,self.MachineLearning,Career in Scientific Computing with MS in Physics?,https://www.reddit.com/r/MachineLearning/comments/2bwb0j/career_in_scientific_computing_with_ms_in_physics/,[deleted],1406504254,"From what I've read and heard about scientific computing/computational science is that it is perfect for those who have interest in physical problems but like using programming and numerical methods. I've only taken one numerical methods course as an undergrad, but liked it. I also like physics/engineering, so I think this may be a good field for me

I have 3 options to pursue an MS and then a career in computational science. I have no desire to pursue a PhD and work in research as I just want to get into industry asap and work as an engineer/scientist performing simulations and modeling. I also have no desire on working on the Master's thesis but I have no other choice

(1)I was enrolled in a Physics Phd program but took a leave of absence from the program and have been approved to re-enter the grad program starting in the Fall 2014 semester. I could continue with this program and leave after getting the Master's. Even if I don't get the phd, the program will still be funded. Getting the MS should take 2 semester but I have to work on a thesis for both semesters. The school is considered top 20 in physics and top 10 for computational science. However, since most students get a phd and want to continue in academia, my guess is that this program doesn't offer great networking opportunities

(2) I could transfer to a stats or computational science MS program, but I have to wait until Fall 2015 and I would have to pay out-of-state tuition for them. Or I could re-apply to programs where I can pay in-state tuition, but I still have to wait until Fall 2015. Money is not a big issue to me, but this is my least favorite option because I don't want to have a year with nothing to do

(3) My other option is to attend a Computational Science Master's program in Germany that will let me start for the Fall 2014 semester. It would take at least 3 semesters, but I have to spend just 1 semester on a thesis. Funding is not offered but there are NO tuition fees. I applied to Europe because I thought I might like living in Germany for a bit, but I want the MS degree to be beneficial to me in the US in case I wanted to return in the future. Since I just want a good job after I graduate and don't want to get into research, I don't really care if RWTH Aachen has good research or not


Would I be at a serious disadvantage when applying for jobs against other Computational Science MS holders even if the thesis for my MS in Physics involves lots of numerical methods (such as numerical PDEs)? What kinds of careers could I get into? What grad courses should I take other than numerical PDEs?

Or should I just spend 3 semesters for the program in Germany?

Are computational scientists just as passionate about programming as software engineers are?",3,0,False,default,,,,,
208,MachineLearning,t5_2r3gv,2014-7-28,2014,7,28,12,2bwy5e,self.MachineLearning,Aren't feed-forward neural networks just a bunch of transformation matrices transforming vectors?,https://www.reddit.com/r/MachineLearning/comments/2bwy5e/arent_feedforward_neural_networks_just_a_bunch_of/,[deleted],1406519744,"I am a newbie at neural networks and I was learning about good ol' simple feed-forward neural networks.

Am I right in saying that going from one layer to the next, is essentially just transforming a vector with some transformation matrix and then applying an activation function to the resulting vector?

Or am I missing some crucial piece of understanding regarding neural networks?",22,17,False,self,,,,,
209,MachineLearning,t5_2r3gv,2014-7-28,2014,7,28,19,2bxld3,proymec.es,Expertos en automatizacin industrial,https://www.reddit.com/r/MachineLearning/comments/2bxld3/expertos_en_automatizacin_industrial/,proymec,1406542488,,0,0,False,default,,,,,
210,MachineLearning,t5_2r3gv,2014-7-28,2014,7,28,22,2bxycr,dataconomy.com,Big Data Proving to Be A Real Challenge for Data Scientists,https://www.reddit.com/r/MachineLearning/comments/2bxycr/big_data_proving_to_be_a_real_challenge_for_data/,[deleted],1406554575,,1,0,False,default,,,,,
211,MachineLearning,t5_2r3gv,2014-7-28,2014,7,28,23,2by4ye,chrisstucchio.com,"Don't use Hadoop, your data is not that big",https://www.reddit.com/r/MachineLearning/comments/2by4ye/dont_use_hadoop_your_data_is_not_that_big/,SMFet,1406558764,,66,103,False,default,,,,,
212,MachineLearning,t5_2r3gv,2014-7-29,2014,7,29,0,2byawy,self.MachineLearning,"Classifying ""other"". Is there a nice way to have a ML classifier say ""this doesn't look like anything in the training data""?",https://www.reddit.com/r/MachineLearning/comments/2byawy/classifying_other_is_there_a_nice_way_to_have_a/,[deleted],1406562054,"Hi,

I realise this is likely a very broad question, and likely depends on the specific technique being used. However, to start off I am currently using random forests to classify network activity. When you can provide training data for and label all categories, everything is fine. However, problems arise when we transfer the problem away away from the model into the real world. Here it is impossible to provide data for all types of activity due to the huge variety that exists.

At the moment our attempt is to label large amounts of network activity we're not interested in as ""other"" in the training set, which works to some degree. This seems rather hack-y though. Is there a better way to do this?",11,5,False,default,,,,,
213,MachineLearning,t5_2r3gv,2014-7-29,2014,7,29,2,2byjr1,inovancetech.com,Using a Decision Tree to Trade Bank of America stock,https://www.reddit.com/r/MachineLearning/comments/2byjr1/using_a_decision_tree_to_trade_bank_of_america/,thetzz,1406566935,,1,0,False,default,,,,,
214,MachineLearning,t5_2r3gv,2014-7-29,2014,7,29,2,2bylc7,blog.trackduck.com,Nerds in Paradise: Web Development from Awesome Remote Locations,https://www.reddit.com/r/MachineLearning/comments/2bylc7/nerds_in_paradise_web_development_from_awesome/,reborn426,1406567787,,0,1,False,default,,,,,
215,MachineLearning,t5_2r3gv,2014-7-29,2014,7,29,5,2bz8w1,self.MachineLearning,Overlapping clustering,https://www.reddit.com/r/MachineLearning/comments/2bz8w1/overlapping_clustering/,zibenmoka,1406579953,"Hi there, Does anyone have any experience with overlapping clustering? What is your opinion on that one ? ",5,3,False,self,,,,,
216,MachineLearning,t5_2r3gv,2014-7-29,2014,7,29,7,2bzmgd,github.com,Easy benchmarking of all public open-source implementations of convnets (soumith/convnet-benchmarks),https://www.reddit.com/r/MachineLearning/comments/2bzmgd/easy_benchmarking_of_all_public_opensource/,benanne,1406587187,,9,9,False,http://b.thumbs.redditmedia.com/Dy7niPZBuDwWbzEe.jpg,,,,,
217,MachineLearning,t5_2r3gv,2014-7-29,2014,7,29,16,2c0xfh,machineryequipment123.blogspot.com,Attachments for Bobcat Loaders - Machinery &amp; Equipment Part Online,https://www.reddit.com/r/MachineLearning/comments/2c0xfh/attachments_for_bobcat_loaders_machinery/,jessicperson,1406620445,,0,1,False,default,,,,,
218,MachineLearning,t5_2r3gv,2014-7-29,2014,7,29,17,2c0yw1,self.MachineLearning,Do input/output neurons of neural networks have activation functions? (Newbie question),https://www.reddit.com/r/MachineLearning/comments/2c0yw1/do_inputoutput_neurons_of_neural_networks_have/,TheHiddenLayer,1406622040,"**CONTEXT**

I am trying to code a simple single-hidden layer neural network from scratch to try and approximate functions like exp(x) and such - just to get an idea of how data is represented in weights and such.

I am planning on using a single input neuron that takes a single real-valued input.

This input (and a bias unit) go through weights to the hidden layer which has a sigmoid activation function. These get summed and weighted to give the output neuron - and that's supposed to be the function.

So essentially, if x is the input to the neural network, the output of the output neuron is W*sigmoid(b + V*x) + c where b is the bias of the hidden layer, c is the bias for the input layer, V is the vector representing the weights between the input and the hidden layer, and W is the vector representing the weights between the hidden and output layer. Learning done through simple backpropagation.

---

**QUESTIONS**

1. Is this a sound design?

2. It makes sense for the input and output layers to not have activation functions, doesn't it? Are there cases when the input/output layers will have activation functions too?

The latter question is the main reason I made this thread as evidenced by the title.",10,1,False,self,,,,,
219,MachineLearning,t5_2r3gv,2014-7-29,2014,7,29,18,2c11j5,self.MachineLearning,How does the Bayes Factor account for degrees of freedom?,https://www.reddit.com/r/MachineLearning/comments/2c11j5/how_does_the_bayes_factor_account_for_degrees_of/,[deleted],1406625182,"For example, if I have two possible models, a uniform distribution over X&lt;-[0,1] and Y&lt;-[0,1], and a uniform distribution over X&lt;-[0,1] and Y=X fixed (i.e. one DoF) - and I observe that (0.5,0.5) - how is it that I favour the latter model?

Given that the probability density in both is the same P(0.5,0.5|M)=1 ?

EDIT: After talking with colleagues, I think this is actually a problem of using densities like this. As they are not comparable between the two models (since they are not defined with respect to the same measure). Note this only occurs in the noiseless case (e.g. if model 2 also has gaussian noise in X and Y, then they are comparable again). 

So then in the noiseless case we say, if we observe X=Y then model 2 (as model 1 is vanishingly unlikely if we make noiseless (infinite precision) observations), and if X!=Y then model 1 is the only possible model.

In the noisy case one can just calculate the respective likelihoods as usual (with a prior on the noise).",2,5,False,default,,,,,
220,MachineLearning,t5_2r3gv,2014-7-30,2014,7,30,0,2c1rtv,self.MachineLearning,Multinomial for K Classes VS. Training K Logistic Regression Classifiers,https://www.reddit.com/r/MachineLearning/comments/2c1rtv/multinomial_for_k_classes_vs_training_k_logistic/,lpiloto,1406647134,"Are there any practical or theoretical justifications for using one versus the other?

To be clear, for training K logistic regression classifiers, the classification is taken to be the class with the highest probability as predicted by the logistic regression classifiers.",7,3,False,self,,,,,
221,MachineLearning,t5_2r3gv,2014-7-30,2014,7,30,0,2c1w1b,self.MachineLearning,Anomaly detection on a small data set,https://www.reddit.com/r/MachineLearning/comments/2c1w1b/anomaly_detection_on_a_small_data_set/,piscoster,1406649493,"Hello guys,

I am trying to analyse anomal transactions on a small data set. These data set are fiancial transactions and these are only done quite irregularly. I have around 200 transactions in my data set. 

I know that the usual anomaly detection methods work quite well with large dataset. However, I was wondering if there is any research about anomaly detection in small datasets and what the problems are if anomaly detection is done on small data sets?

I really appreciate your answer!

Best regards!",3,3,False,self,,,,,
222,MachineLearning,t5_2r3gv,2014-7-30,2014,7,30,1,2c1wfw,cbinsights.com,Detecting the health of startups with machine learning and HR news posts.,https://www.reddit.com/r/MachineLearning/comments/2c1wfw/detecting_the_health_of_startups_with_machine/,killer_sauce,1406649727,,0,1,False,http://b.thumbs.redditmedia.com/bJdxnjp4TCzgE8Ey.jpg,,,,,
223,MachineLearning,t5_2r3gv,2014-7-30,2014,7,30,1,2c1z4g,yahoolabs.tumblr.com,Yahoo releases one hundred million creative commons Flickr images for research,https://www.reddit.com/r/MachineLearning/comments/2c1z4g/yahoo_releases_one_hundred_million_creative/,urish,1406651212,,5,61,False,http://a.thumbs.redditmedia.com/WTsnJ30xmo8pHLWN.jpg,,,,,
224,MachineLearning,t5_2r3gv,2014-7-30,2014,7,30,1,2c217k,npr.org,Michael Jordan wins Rumelhart Prize,https://www.reddit.com/r/MachineLearning/comments/2c217k/michael_jordan_wins_rumelhart_prize/,FixDeineKabel,1406652364,,5,18,False,http://b.thumbs.redditmedia.com/fcuWTpfMpc6shiwA.jpg,,,,,
225,MachineLearning,t5_2r3gv,2014-7-30,2014,7,30,2,2c23v6,dataconomy.com,Dynamic Data Integration Part I &amp; II,https://www.reddit.com/r/MachineLearning/comments/2c23v6/dynamic_data_integration_part_i_ii/,[deleted],1406653778,,0,0,False,default,,,,,
226,MachineLearning,t5_2r3gv,2014-7-30,2014,7,30,3,2c29ze,self.MachineLearning,How to learn more? Not a beginner but not very good at it too...,https://www.reddit.com/r/MachineLearning/comments/2c29ze/how_to_learn_more_not_a_beginner_but_not_very/,mechanical_fan,1406657011,"Hello everyone, I'm a materials engineering student who will soon be graduating but I want to work with machine learning/data analisys in the future.

My university course didn't have anything on these topics, but I studied them through online courses on Coursera/EDX, most notably these:

https://www.coursera.org/course/ml

https://www.coursera.org/specialization/jhudatascience/1?utm_medium=dashboard

https://courses.edx.org/courses/MITx/15.071x/1T2014/info

However, I still don't feel that I know enough about the topic to say that I could work in the area and all my knowledge is way too basic. How should I proceed to become better? I could think of these options:


- Buying some books and doing everything on them. I was thinking about: ""Machine Learning for Hackers"" and ""Programming Collective Intelligence: Building Smart Web 2.0 Applications"". I still don't have any book, so buying them would at least give me somewhere to consult.


- Applying for a Master's program. However, I'm not american or I'm in the US. I know it is a longshot, but does anyone know someone who is very good in the area in Brazil? I'm gratuating from one of the best engineering schools here so it wouldn't be a problem to get a masters here. If I have to go to the US (or other country), do you have any advice?


- Kaggle competitions. I've never done any of those, but some of them seem kinda hard, especially if you are aiming to get a good place on them. What would be a good one for a first timer?


- Doing more online courses. I've looked into Udacity and they seem to also have some very good courses like Intro to Data Science, Intro to Hadoop and MapReduce, Data Analysis with R, Machine Learning: Supervised Learning and many others.

What do you think, which way is better? Or maybe a combination? Do you have any suggestions?

At last, it seems a lot of you work on related fields, how did you get to work with Machine Learning? What is the best way to get into the field?

Thanks for all the help, guys.",8,6,False,self,,,,,
227,MachineLearning,t5_2r3gv,2014-7-30,2014,7,30,3,2c2ayt,self.MachineLearning,Visualizing data in c++ programs,https://www.reddit.com/r/MachineLearning/comments/2c2ayt/visualizing_data_in_c_programs/,justtheprint,1406657485,"I'm a self taught programming newbie. I was fine doing ML and other operations in matlab, but for various reasons, I needed to move to c++. The biggest problem I've had is trying to visualize my data.

Suppose you do a simple 3 coordinate projection PCA. You would like to do a 3d scatterplot to visualize your data. What tools in c++ would you use to do this. I could export as a text file and then import it into matlab, but I do like an elegant solution.

I started fooling around with glfw/openGL, and it looks like that will work, but it's taken longer than I would have liked. Someone has to have thought of a solution before! I am currently on a mac, but I would like a system independent solution if possible.

Cheers",5,3,False,self,,,,,
228,MachineLearning,t5_2r3gv,2014-7-30,2014,7,30,6,2c2wed,self.MachineLearning,Thesis,https://www.reddit.com/r/MachineLearning/comments/2c2wed/thesis/,Chopsting,1406668760,"Hey everyone,

this is a spur of the moment question, but I'm curious if you could thing of any topics where a thesis topic could be explored that combines Machine Learning and Telecommunication / Mobile Money?

Short post but I'm wondering if anything spring to mind for you...",4,0,False,self,,,,,
229,MachineLearning,t5_2r3gv,2014-7-30,2014,7,30,8,2c3c4i,deeplearning.cs.toronto.edu,Deep Learning Image Classifier - Toronto Deep Learning Group,https://www.reddit.com/r/MachineLearning/comments/2c3c4i/deep_learning_image_classifier_toronto_deep/,richardabrich,1406677649,,4,12,False,http://b.thumbs.redditmedia.com/7tkbnyLQn34WceB-.jpg,,,,,
230,MachineLearning,t5_2r3gv,2014-7-30,2014,7,30,12,2c3v3e,self.MachineLearning,Year long Projects in ML,https://www.reddit.com/r/MachineLearning/comments/2c3v3e/year_long_projects_in_ml/,no_porner,1406689359,"I have the basic understanding of machine learning concepts. I am looking for an year long project in this area. Kindly suggest me some good and emerging ideas. 
Thanks in advance.

EDIT: Does anyone has any ideas from recent CVPR papers?",5,1,False,self,,,,,
231,MachineLearning,t5_2r3gv,2014-7-30,2014,7,30,18,2c4muz,flickr.com,Montabert Loader Bucket - Montabert Loader Attachments | Flickr - Photo Sharing!,https://www.reddit.com/r/MachineLearning/comments/2c4muz/montabert_loader_bucket_montabert_loader/,jessicperson,1406714172,,0,1,False,default,,,,,
232,MachineLearning,t5_2r3gv,2014-7-30,2014,7,30,19,2c4p2m,self.MachineLearning,ACL'14 Tutorial on Machine Learning for NLP,https://www.reddit.com/r/MachineLearning/comments/2c4p2m/acl14_tutorial_on_machine_learning_for_nlp/,egrefen,1406716602,"Full disclosure: this post is plugging work I contributed to, but I think it will be of interest to this community.

In collaboration with the University of Trento ([Georgiana Dinu](http://clic.cimec.unitn.it/~georgiana.dinu/)), [Oxford's Computational Linguistics Group](http://www.clg.ox.ac.uk/), (namely [Phil](http://www.cs.ox.ac.uk/people/phil.blunsom/), [Karl](http://www.cs.ox.ac.uk/people/karlmoritz.hermann/) and [Ed](http://www.cs.ox.ac.uk/people/edward.grefenstette/)) has put together a tutorial for this year's ACL, which took place in Baltimore. 

This tutorial, *New Directions in Vector Space Models of Meaning* (pun not intended), covers a variety of topics relating to the theme of representation learning for semantics. We discuss neural language models in depth, neural models of composition, deep learning, and the application of convolutional neural networks to natural language processing. Because of the growing popularity of these topics in the NLP community, the tutorial was the most well attended tutorial at this year's conference.

The tutorial does not pre-suppose much prior knowledge of machine learning beyond basic linear algebra and log-linear models, or any complex knowledge of NLP. The slides are meant to be fairly self-contained, and provide all (or most) of the maths required to implement the models we describe. We also discuss some training and architectural tricks and ""black magic"" that most people use when applying these models.

The slides for the tutorial can be found [on our group's resource page](http://www.clg.ox.ac.uk/resources) (apologies for typos), and the video of the tutorial, lovingly aligned with the slides by yours truly (6+ hours of painful labour and checking), [has just been uploaded to youtube](http://youtu.be/_ASOqXiWBVo) (we apologise for the cruddy quality of the image/sound, but we had to film this ourselves, rather than professionally).

We hope you enjoy our tutorial.",7,45,False,self,,,,,
233,MachineLearning,t5_2r3gv,2014-7-30,2014,7,30,23,2c58uq,wolfram.com,"Mathematica 10 now has ""Machine Learning"" functions. Is it a useful platform for a novice?",https://www.reddit.com/r/MachineLearning/comments/2c58uq/mathematica_10_now_has_machine_learning_functions/,With_a_G,1406732167,,8,10,False,http://a.thumbs.redditmedia.com/QdKZaEKTJ4B-DuAl.jpg,,,,,
234,MachineLearning,t5_2r3gv,2014-7-31,2014,7,31,7,2c6kpv,self.MachineLearning,"I've been building a landmarking tool for Image Processing, what else do you think I should add to my UI?",https://www.reddit.com/r/MachineLearning/comments/2c6kpv/ive_been_building_a_landmarking_tool_for_image/,[deleted],1406757696,"**[Link to Landmarking Tool](http://landmark-tool.herokuapp.com)**

^Sorry ^if ^it ^takes ^a ^second ^to ^load, ^Heroku's ^Free ^Tier ^puts ^webapps ^to ^sleep ^after ^an ^hour ^of ^inactivity

    --------------------------------------

I've always been annoyed with landmarking images, or just getting (x,y) coordinates from an image; so I've been building up this tool to just aid me in the process. The original idea is that you can classify subsections of points by Shape. 

Say, in my demo's case Nicholas Cage's Left Eye.

* You click ""New Shape"", label it (""Left Eye""), and the shape is now active.
* Clicking on the image adds a landmark point and stores the actual coordinates for exporting.
 * You can adjust any point by clicking and dragging it
 * You can delete a point by dragging it to the trash bin
* Rinse and repeat until done, Export

Your active shape expands because I want to add in some extra customization (colors, etc), I'm just drawing a blank on what else to add.

In the future, I want to add user accounts, so you can store your landmark points, and offer to build models for commonly labeled objects (faces, animals, whatever). Also, having an API for retrieving your points for any/all images in your account and finally autodetecting with any models you build.

    --------------------------------------

If you were to use this tool, what would be some things you'd expect to be able to do?

If you already use something to landmark images, what? I'd love to see what they do.

Do you think understanding how to move the image after making a shape is intuitive enough, or should I add something? (Have no shapes active).

**Thanks!**",1,6,False,default,,,,,
235,MachineLearning,t5_2r3gv,2014-7-31,2014,7,31,18,2c85fn,self.MachineLearning,Online courses to learn image processing and recognition?,https://www.reddit.com/r/MachineLearning/comments/2c85fn/online_courses_to_learn_image_processing_and/,lost-in-technicolour,1406799395,"I am a complete newbie in the field of both image processing/recognition as well as ML in general.

My aim is to learn the fundamentals and then eventually be able to build commercial applications around it. Right now I am a software developer in a consultancy services company and bored of my job to no end. So advice 

I googled around quite a lot but would love to hear inputs by people seasoned in the field. (I get it that /r/MachineLearning might not be the best place, so do let me know if any specific subreddits are better suited for this. I also just asked the same thing in /r/compsci ). Thanks for reading!",8,8,False,self,,,,,
236,MachineLearning,t5_2r3gv,2014-7-31,2014,7,31,19,2c86xl,self.MachineLearning,Labelled data set for news items.,https://www.reddit.com/r/MachineLearning/comments/2c86xl/labelled_data_set_for_news_items/,[deleted],1406801206,"Is there a good data set somewhere that categorises rss news items? I have a large set of news items that i have categorised into ten topics, but i want to really divide them up into smaller sub topics, the topics don't need to be properly named. Is there an existing data set out there that has news items labelled with really specific sub categories? ",0,1,False,default,,,,,
237,MachineLearning,t5_2r3gv,2014-7-31,2014,7,31,20,2c8b04,self.MachineLearning,Are Neural Networks just lots of logical gates?,https://www.reddit.com/r/MachineLearning/comments/2c8b04/are_neural_networks_just_lots_of_logical_gates/,quietandproud,1406805998,"Hi.

I've seen an example of a neural network in which the weights were tuned so that an input (a, b) had an oupput equal to a AND b, that is, the network was a logical gate. And that got me thinking if every neural network was just a large collection of neural gates. 

That is, suppose we wanted to write, say, a recognizer of handwritten numbers. If we were supersmart we could write an incredibly complex deterministic algorithm that we could use to classiy images into numbers. But since we are not that smart (in fact I'm not sure an algorithm like that can even exist) we have to use a neural network. What I thought is that what the network was actually doing is find the set of logic gates that most closely acts like the ""ideal"" algorithm (which is fundamentally also a set of logic gates).

Is it so?",6,3,False,self,,,,,
238,MachineLearning,t5_2r3gv,2014-7-31,2014,7,31,22,2c8ldd,mdbecker.github.io,Data Science With Python: Part 1,https://www.reddit.com/r/MachineLearning/comments/2c8ldd/data_science_with_python_part_1/,cr4d,1406814528,,1,28,False,http://a.thumbs.redditmedia.com/P1M7NWW3pPZJSt1h.jpg,,,,,
239,MachineLearning,t5_2r3gv,2014-7-31,2014,7,31,23,2c8o45,self.MachineLearning,Help for code of paragraph vectors,https://www.reddit.com/r/MachineLearning/comments/2c8o45/help_for_code_of_paragraph_vectors/,largelymfs,1406816218,"Does someone implements the code of the paper http://arxiv.org/abs/1405.4053 (distributed representation of sentences and documents)?I have done one but has 10 percent less the precision in the paper.If someone is doing this work or finishes it, please contact me! thank you!.
My email is largelymfs@gmail.com or you can comments here.",9,6,False,self,,,,,
