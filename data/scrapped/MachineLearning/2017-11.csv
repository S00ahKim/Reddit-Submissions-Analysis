,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2017-11-1,2017,11,1,11,7a0vpf,"""Continual Learning with Deep Generative Replay"" PyTorch Implementation",https://www.reddit.com/r/MachineLearning/comments/7a0vpf/continual_learning_with_deep_generative_replay/,kuc2477,1509504029,,0,1
1,2017-11-1,2017,11,1,11,7a0wcv,[P] Voice Style Transfer: Speaking like Kate Winslet,https://www.reddit.com/r/MachineLearning/comments/7a0wcv/p_voice_style_transfer_speaking_like_kate_winslet/,andabi,1509504251,,46,232
2,2017-11-1,2017,11,1,12,7a17kr,[R] Deep Learning as a Mixed Convex-Combinatorial Optimization Problem,https://www.reddit.com/r/MachineLearning/comments/7a17kr/r_deep_learning_as_a_mixed_convexcombinatorial/,verveandfervor,1509508029,,0,28
3,2017-11-1,2017,11,1,12,7a181m,Unsure about this Indexing Error while using NMF,https://www.reddit.com/r/MachineLearning/comments/7a181m/unsure_about_this_indexing_error_while_using_nmf/,madzthakz,1509508197,[removed],0,1
4,2017-11-1,2017,11,1,14,7a1jvh,Precision vs Recall - Demystifying Accuracy Paradox in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7a1jvh/precision_vs_recall_demystifying_accuracy_paradox/,NGA-YJ,1509512481,,0,1
5,2017-11-1,2017,11,1,14,7a1qj7,Andrew Ng's Deep learning specialization's 4th course is up now on Coursera which is on CNNs,https://www.reddit.com/r/MachineLearning/comments/7a1qj7/andrew_ngs_deep_learning_specializations_4th/,[deleted],1509515261,[deleted],0,1
6,2017-11-1,2017,11,1,15,7a1spt,[N] Andrew Ng's Deep learning specialization's 4th course is up now on Coursera which is on CNNs,https://www.reddit.com/r/MachineLearning/comments/7a1spt/n_andrew_ngs_deep_learning_specializations_4th/,curious_riddler,1509516185,,25,95
7,2017-11-1,2017,11,1,15,7a1y89,CapsNet in Tensorflow,https://www.reddit.com/r/MachineLearning/comments/7a1y89/capsnet_in_tensorflow/,pilooch,1509518704,,0,1
8,2017-11-1,2017,11,1,15,7a1zf5,TF Eager example code in a Google colab notebook - allow playing with TF Eager directly in your browser,https://www.reddit.com/r/MachineLearning/comments/7a1zf5/tf_eager_example_code_in_a_google_colab_notebook/,[deleted],1509519261,[deleted],0,1
9,2017-11-1,2017,11,1,16,7a23zj,Rice Noodle Maker Machine|Corn Noodle Making Machine For Sale,https://www.reddit.com/r/MachineLearning/comments/7a23zj/rice_noodle_maker_machinecorn_noodle_making/,liusherry,1509521409,,1,1
10,2017-11-1,2017,11,1,16,7a2661,Vermicelli Machine| Rice Noodle Machine Manufacturer,https://www.reddit.com/r/MachineLearning/comments/7a2661/vermicelli_machine_rice_noodle_machine/,liusherry,1509522482,[removed],1,1
11,2017-11-1,2017,11,1,17,7a2dh5,[R] TF Eager example code in a Google colab Jupyter notebook - allow playing with TF Eager directly in your browser,https://www.reddit.com/r/MachineLearning/comments/7a2dh5/r_tf_eager_example_code_in_a_google_colab_jupyter/,thntk,1509526241,,2,6
12,2017-11-1,2017,11,1,18,7a2h97,How deep learning works  The geometry of deep learning,https://www.reddit.com/r/MachineLearning/comments/7a2h97/how_deep_learning_works_the_geometry_of_deep/,aseembits93,1509528146,,0,1
13,2017-11-1,2017,11,1,18,7a2kxx,Why do many tracking or alignment works use Lie group instead of Affine and Homography to parameterize motion?,https://www.reddit.com/r/MachineLearning/comments/7a2kxx/why_do_many_tracking_or_alignment_works_use_lie/,scotty20172017,1509529980,[removed],0,1
14,2017-11-1,2017,11,1,19,7a2mii,[D] Ideas about application of CycleGAN-like algorithm,https://www.reddit.com/r/MachineLearning/comments/7a2mii/d_ideas_about_application_of_cycleganlike/,HigherTopoi,1509530672,"I'm currently finishing up implementing CycleGAN-like algorithm by incorporating all the relevant recent developments, including progressive growing of GANs, and several other ICLR papers, including CyCADA, for realistic end product. Especially, I hope this will result in realistic video-to-video translation. Naively it can be extended to speech-to-speech, text-to-image (like StackGAN), possibly text-to-text and (image+text)-to-image with the existing technology in unpaired style. Here are some questions:

1) There are already numerous algorithms like this, including unpaired speech-to-speech, one of which was posted here, and there was one ICLR paper about this; on the other hand, I have only limited time. Is it worth pursuing this direction? Or is there no more outstanding problem about this particular task? 

2) There is one ICLR paper about text-style transfer. Is it unreasonable to expect that Cycle-GAN-like algorithm can do unsupervised translation (another ICLR paper) like this (with RNN)? If that would be realized, then Cycle-like-GAN can possibly solely do unsupervised voice-to-voice inter-language translation with the user's own voice, which is interesting.  

3) If you have any idea about nice (academic or industrial) applications of unpaired translation of X-to-Y please comment it. 


",2,9
15,2017-11-1,2017,11,1,19,7a2qo3,[Q] Textbook/resources on network centrality measures and applications?,https://www.reddit.com/r/MachineLearning/comments/7a2qo3/q_textbookresources_on_network_centrality/,meechosch,1509532470,[removed],0,1
16,2017-11-1,2017,11,1,20,7a2vvw,"[D] Does a convolution layer decrease the input's dimensions like a pooling layer, or does it not?",https://www.reddit.com/r/MachineLearning/comments/7a2vvw/d_does_a_convolution_layer_decrease_the_inputs/,FantasyBorderline,1509534677,"I'm a bit perplexed about this. Let's say I have a 32x32x3 input (RGB image), and am about to use a CNN on it, with several Conv-Pool layers and one or two Fully Connected (dense-dropout) layers.

I read [this paper](https://annals-csis.org/Volume_8/pliks/472.pdf) that uses Torch, and apparently its Conv layer reduces the size by `kernel_size-1`, so when the 32x32x3 image passes through the first Conv layer with 5x5 kernel size and 64 filters, it produces 28x28x64 segments/features.

Whereas in Tensorflow, as far as I know, it doesn't, so when the 32x32x3 image passes through its Conv layer with 5x5 kernel size, and 64 filters it produces 32x32x64 features.

Does it depend on the type of ML used (Caffe/Tensorflow/Torch/scikit-learn), and what effect does it have?",9,3
17,2017-11-1,2017,11,1,20,7a2wcy,I need help for my machine learning/NLP project. It is about a context aware text classification. Please see the link for detailed problem statement.,https://www.reddit.com/r/MachineLearning/comments/7a2wcy/i_need_help_for_my_machine_learningnlp_project_it/,rbansalrahul6,1509534854,,0,1
18,2017-11-1,2017,11,1,20,7a2wz6,How machine learning levels the SERP playing field,https://www.reddit.com/r/MachineLearning/comments/7a2wz6/how_machine_learning_levels_the_serp_playing_field/,evacms003,1509535095,,0,1
19,2017-11-1,2017,11,1,20,7a2yqe,How can I find contextually related words and add custom tags/labels?,https://www.reddit.com/r/MachineLearning/comments/7a2yqe/how_can_i_find_contextually_related_words_and_add/,karakorakura,1509535770,[removed],0,1
20,2017-11-1,2017,11,1,21,7a377r,[D]Why do I need to install python packages inside Tensorflow environment?,https://www.reddit.com/r/MachineLearning/comments/7a377r/dwhy_do_i_need_to_install_python_packages_inside/,huyhcmut,1509538844,[removed],0,1
21,2017-11-1,2017,11,1,21,7a3av6,[R] TreeQN and ATreeC: Differentiable Tree Planning for Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/7a3av6/r_treeqn_and_atreec_differentiable_tree_planning/,_rockt,1509540080,,27,24
22,2017-11-1,2017,11,1,22,7a3fqs,[R]Making Algorithms Fair: An Interview With Cynthia Dwork,https://www.reddit.com/r/MachineLearning/comments/7a3fqs/rmaking_algorithms_fair_an_interview_with_cynthia/,dearpetra,1509541644,,0,1
23,2017-11-1,2017,11,1,22,7a3q5b,What's the difference between a single-model result and a multi-model result?,https://www.reddit.com/r/MachineLearning/comments/7a3q5b/whats_the_difference_between_a_singlemodel_result/,abrbbb,1509544743,[removed],0,1
24,2017-11-1,2017,11,1,23,7a3vak,[N] Googles AI Wizard Unveils a New Twist on Neural Networks,https://www.reddit.com/r/MachineLearning/comments/7a3vak/n_googles_ai_wizard_unveils_a_new_twist_on_neural/,ps_dillon,1509546132,,36,70
25,2017-11-1,2017,11,1,23,7a3zxi,Does batch size matter,https://www.reddit.com/r/MachineLearning/comments/7a3zxi/does_batch_size_matter/,[deleted],1509547404,[deleted],0,1
26,2017-11-1,2017,11,1,23,7a42ci,[P] Neuromation: Distributed Synthetic Data Platform for Deep Learning Applications,https://www.reddit.com/r/MachineLearning/comments/7a42ci/p_neuromation_distributed_synthetic_data_platform/,nicknikolaev,1509548043,,0,38
27,2017-11-2,2017,11,2,0,7a46j2,Does batch size matter? [D],https://www.reddit.com/r/MachineLearning/comments/7a46j2/does_batch_size_matter_d/,[deleted],1509549083,[deleted],0,1
28,2017-11-2,2017,11,2,0,7a494o,[D] Does batch size matter?,https://www.reddit.com/r/MachineLearning/comments/7a494o/d_does_batch_size_matter/,kmanon,1509549739,,8,31
29,2017-11-2,2017,11,2,0,7a4gwm,"Simple Questions Thread November 01, 2017",https://www.reddit.com/r/MachineLearning/comments/7a4gwm/simple_questions_thread_november_01_2017/,AutoModerator,1509551737,[removed],0,1
30,2017-11-2,2017,11,2,1,7a4j2t,[R] Machine learning of neural representations of suicide and emotion concepts identifies suicidal youth,https://www.reddit.com/r/MachineLearning/comments/7a4j2t/r_machine_learning_of_neural_representations_of/,GreenFrog76,1509552232,,18,115
31,2017-11-2,2017,11,2,1,7a4jl3,[R] A Bayesian Perspective on Generalization and Stochastic Gradient Descent &lt;- identifying an optimum batch size which maximizes the test set accuracy.,https://www.reddit.com/r/MachineLearning/comments/7a4jl3/r_a_bayesian_perspective_on_generalization_and/,downtownslim,1509552359,,1,8
32,2017-11-2,2017,11,2,1,7a4oxq,Is a Udacity nano degree worth it?,https://www.reddit.com/r/MachineLearning/comments/7a4oxq/is_a_udacity_nano_degree_worth_it/,Shi7am,1509553687,[removed],0,1
33,2017-11-2,2017,11,2,1,7a4twy,New Experiment Sheds Light on HTM Theory,https://www.reddit.com/r/MachineLearning/comments/7a4twy/new_experiment_sheds_light_on_htm_theory/,numenta,1509554914,,0,2
34,2017-11-2,2017,11,2,1,7a4v3e,Stochastic Video Prediction in Real Videos,https://www.reddit.com/r/MachineLearning/comments/7a4v3e/stochastic_video_prediction_in_real_videos/,[deleted],1509555208,[deleted],0,1
35,2017-11-2,2017,11,2,2,7a541s,Neural net based game needs some data!,https://www.reddit.com/r/MachineLearning/comments/7a541s/neural_net_based_game_needs_some_data/,tomosevans,1509557324,[removed],0,2
36,2017-11-2,2017,11,2,2,7a54pe,Technical terms used in Deep Learning and their meaning in simple words,https://www.reddit.com/r/MachineLearning/comments/7a54pe/technical_terms_used_in_deep_learning_and_their/,curious_rv,1509557485,,0,1
37,2017-11-2,2017,11,2,2,7a59uf,Datasets for text document summarization ARABIC,https://www.reddit.com/r/MachineLearning/comments/7a59uf/datasets_for_text_document_summarization_arabic/,Mouzbarak,1509558714,[removed],0,1
38,2017-11-2,2017,11,2,3,7a5ea7,Patenting a system,https://www.reddit.com/r/MachineLearning/comments/7a5ea7/patenting_a_system/,ArtlockScofield,1509559778,[removed],0,1
39,2017-11-2,2017,11,2,3,7a5kr9,Applying ML to EEG Lab,https://www.reddit.com/r/MachineLearning/comments/7a5kr9/applying_ml_to_eeg_lab/,The_Real_Tupac,1509561345,[removed],0,1
40,2017-11-2,2017,11,2,3,7a5p9l,Building a Trump/Obama Tweet Classifier with 98% accuracy in 1 hour!,https://www.reddit.com/r/MachineLearning/comments/7a5p9l/building_a_trumpobama_tweet_classifier_with_98/,[deleted],1509562471,[deleted],0,1
41,2017-11-2,2017,11,2,4,7a5ulq,Reverse Engineering Songs,https://www.reddit.com/r/MachineLearning/comments/7a5ulq/reverse_engineering_songs/,sniloiac,1509563767,[removed],0,1
42,2017-11-2,2017,11,2,4,7a5vai,Autonomous Vehicles with Human Perception Will Make Our Cities Smarter,https://www.reddit.com/r/MachineLearning/comments/7a5vai/autonomous_vehicles_with_human_perception_will/,yildiz17,1509563936,[removed],0,1
43,2017-11-2,2017,11,2,4,7a5x46,Neural Adaptive Machine Translation,https://www.reddit.com/r/MachineLearning/comments/7a5x46/neural_adaptive_machine_translation/,marcotrombetti,1509564398,,0,1
44,2017-11-2,2017,11,2,4,7a60fe,[P] Building a Trump/Obama Tweet Classifier with 98% accuracy in 1 hour!,https://www.reddit.com/r/MachineLearning/comments/7a60fe/p_building_a_trumpobama_tweet_classifier_with_98/,benellerby,1509565222,,9,10
45,2017-11-2,2017,11,2,5,7a6a29,[D] How to detect orientation of objects?,https://www.reddit.com/r/MachineLearning/comments/7a6a29/d_how_to_detect_orientation_of_objects/,austeritygirlone,1509567593,"I want to simultaneously detect objects within a scene, and also know their orientation using an ANN. This could be done by regressing on two scalars (for each pixel). One is orientation angle, and the other is existence probability. Are there any other mentionable approaches for this?

My problem is actually more contrived, as there could be multiple objects with different orientation at the same position, and I need to count them. But I'd be happy with some pointers for the base case.",4,4
46,2017-11-2,2017,11,2,5,7a6fy8,Fooling neural networks in the physical world with 3D adversarial objects,https://www.reddit.com/r/MachineLearning/comments/7a6fy8/fooling_neural_networks_in_the_physical_world/,[deleted],1509569108,[deleted],0,1
47,2017-11-2,2017,11,2,6,7a6v7d,Math for Machine Learning Online Course,https://www.reddit.com/r/MachineLearning/comments/7a6v7d/math_for_machine_learning_online_course/,rickmister24,1509572915,,0,1
48,2017-11-2,2017,11,2,7,7a71ti,[D] Just finished Andrew Ng's Stanford course. Is there another theory/math heavy resource to go from here (not looking for anything too practical ie programming language heavy),https://www.reddit.com/r/MachineLearning/comments/7a71ti/d_just_finished_andrew_ngs_stanford_course_is/,TeslaCarBot,1509574583,"I'm not looking for anything too practical or programming heavy at the moment as I already have a bit of experience being a machine learning hobbyist. 

A while back I asked if there's a good resource for ML learning hobbyist with low ML theory background but strong math( differential equations, stats, linear algebra) background. 

The top recommendation was Andrew Ng's Stanford course and I got to say it really hit the spot. As someone with the correct math background and practical experience with ML, the course was really fantastic for me for getting the theory, and as I am about to wrap up the series I'm a bit sad about finishing it, sort of like when you finish a book you're really into. 

I am wondering if a machine learning course to go from here, something like a continuation of Andrew Ng's course, which is heavy in math and theory. I've been looking at some of the other courses/resources/books out there, it seems like the most prevalent ones are those that heavy in the programming implementations of machine learning, and light in theory/math. 

I don't mind a course that is practical and programming, but I want to continue to strengthen my math/theory background is I already have a bit of experience on the practical implementation side. ",10,14
49,2017-11-2,2017,11,2,8,7a7gzp,TensorFlow implementation of Mask R-CNN for pixelwise object detection and segmentation,https://www.reddit.com/r/MachineLearning/comments/7a7gzp/tensorflow_implementation_of_mask_rcnn_for/,[deleted],1509578506,[deleted],0,1
50,2017-11-2,2017,11,2,8,7a7hm1,[P] TensorFlow implementation of Mask R-CNN for pixelwise object detection and segmentation,https://www.reddit.com/r/MachineLearning/comments/7a7hm1/p_tensorflow_implementation_of_mask_rcnn_for/,feather_of_maat,1509578674,,15,122
51,2017-11-2,2017,11,2,9,7a7w6c,Tensorflow Eager vs Pytorch,https://www.reddit.com/r/MachineLearning/comments/7a7w6c/tensorflow_eager_vs_pytorch/,uotsca,1509582404,[removed],0,1
52,2017-11-2,2017,11,2,12,7a91s7,"What do you think of this paper/work? -""Towards deep learning with segregated dendrites""",https://www.reddit.com/r/MachineLearning/comments/7a91s7/what_do_you_think_of_this_paperwork_towards_deep/,rsChron,1509594528,[removed],1,1
53,2017-11-2,2017,11,2,13,7a94e6,Deep learning with segregated dendrites,https://www.reddit.com/r/MachineLearning/comments/7a94e6/deep_learning_with_segregated_dendrites/,rsChron,1509595322,,2,1
54,2017-11-2,2017,11,2,14,7a9fqq,Kernel Tricks with SVM in Python,https://www.reddit.com/r/MachineLearning/comments/7a9fqq/kernel_tricks_with_svm_in_python/,pradeepsathyamurthy,1509599279,[removed],0,1
55,2017-11-2,2017,11,2,14,7a9i6o,Beyond brassiere search...Apples machine learning at its finest:,https://www.reddit.com/r/MachineLearning/comments/7a9i6o/beyond_brassiere_searchapples_machine_learning_at/,[deleted],1509600242,[deleted],0,1
56,2017-11-2,2017,11,2,14,7a9lv7,"Preparing for ML interviews. Hence, created a growing repo for listing different questions that might be asked. Thought of sharing. Feedback appreciated.",https://www.reddit.com/r/MachineLearning/comments/7a9lv7/preparing_for_ml_interviews_hence_created_a/,Sroy20,1509601718,,0,1
57,2017-11-2,2017,11,2,15,7a9o6f,[P] Implementation of DeepMind's Distributional Bellman and the C51 Algorithm,https://www.reddit.com/r/MachineLearning/comments/7a9o6f/p_implementation_of_deepminds_distributional/,hardmaru,1509602694,,2,13
58,2017-11-2,2017,11,2,15,7a9r8n,NVIDIA has developed a new machine learning methodology for generating unique and realistic looking faces,https://www.reddit.com/r/MachineLearning/comments/7a9r8n/nvidia_has_developed_a_new_machine_learning/,[deleted],1509603946,[deleted],0,1
59,2017-11-2,2017,11,2,15,7a9tpn,How find patterns in categorical data with respect to time?,https://www.reddit.com/r/MachineLearning/comments/7a9tpn/how_find_patterns_in_categorical_data_with/,helpseeker8390,1509605059,[removed],0,1
60,2017-11-2,2017,11,2,15,7a9u3l,[N] NVIDIA has developed a new machine learning methodology for generating unique and realistic looking faces,https://www.reddit.com/r/MachineLearning/comments/7a9u3l/n_nvidia_has_developed_a_new_machine_learning/,karthikaag,1509605222,,0,1
61,2017-11-2,2017,11,2,16,7a9xbn,"Accepting Posters for NIPS Workshop ""Deep Learning at Supercomputer Scale""",https://www.reddit.com/r/MachineLearning/comments/7a9xbn/accepting_posters_for_nips_workshop_deep_learning/,ekelsen,1509606684,[removed],0,1
62,2017-11-2,2017,11,2,16,7a9yd3,Thai flat rice noodle making machine for sale,https://www.reddit.com/r/MachineLearning/comments/7a9yd3/thai_flat_rice_noodle_making_machine_for_sale/,liusherry,1509607159,,1,1
63,2017-11-2,2017,11,2,16,7a9ye7,[N] 'We can't compete': why universities are losing their best AI scientists,https://www.reddit.com/r/MachineLearning/comments/7a9ye7/n_we_cant_compete_why_universities_are_losing/,hlynurd,1509607176,,161,363
64,2017-11-2,2017,11,2,16,7aa296,Commercial Noodle Making Machine | Noodle Maker For Sale,https://www.reddit.com/r/MachineLearning/comments/7aa296/commercial_noodle_making_machine_noodle_maker_for/,liusherry,1509609123,,1,1
65,2017-11-2,2017,11,2,18,7aago5,Using Gans to generate fighting game character from zero? Where to start?,https://www.reddit.com/r/MachineLearning/comments/7aago5/using_gans_to_generate_fighting_game_character/,VideogameTheoristBR,1509616277,[removed],0,1
66,2017-11-2,2017,11,2,19,7aaidm,[N]World Series ballparks compared in by-the-numbers look at Minute Maid Park and Dodger Stadium,https://www.reddit.com/r/MachineLearning/comments/7aaidm/nworld_series_ballparks_compared_in_bythenumbers/,chris_shpak,1509617006,,1,2
67,2017-11-2,2017,11,2,19,7aajcr,[R]3 different types of machine learning,https://www.reddit.com/r/MachineLearning/comments/7aajcr/r3_different_types_of_machine_learning/,molode,1509617417,,0,1
68,2017-11-2,2017,11,2,19,7aakxx,Unsupervised Machine Translation Using Monolingual Corpora Only,https://www.reddit.com/r/MachineLearning/comments/7aakxx/unsupervised_machine_translation_using/,[deleted],1509618056,[deleted],0,1
69,2017-11-2,2017,11,2,19,7aalh5,[R]The Divided Kingdom: a machine learning analysis on the Brexit result,https://www.reddit.com/r/MachineLearning/comments/7aalh5/rthe_divided_kingdom_a_machine_learning_analysis/,polllyyy,1509618291,,0,1
70,2017-11-2,2017,11,2,19,7aaq95,Water Conditioner Manufactures in India,https://www.reddit.com/r/MachineLearning/comments/7aaq95/water_conditioner_manufactures_in_india/,gobusinessin,1509620335,,0,1
71,2017-11-2,2017,11,2,21,7ab2j5,App for Fishermen with Computer Vision technology recognize a fish type and length,https://www.reddit.com/r/MachineLearning/comments/7ab2j5/app_for_fishermen_with_computer_vision_technology/,Cursedone66,1509624713,,1,1
72,2017-11-2,2017,11,2,21,7ab466,The Tensor Algebra Compiler (taco),https://www.reddit.com/r/MachineLearning/comments/7ab466/the_tensor_algebra_compiler_taco/,QuirkySpiceBush,1509625240,,0,1
73,2017-11-2,2017,11,2,21,7abadw,collection of popular CNN models with pre-trained weights in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/7abadw/collection_of_popular_cnn_models_with_pretrained/,[deleted],1509627212,[deleted],0,1
74,2017-11-2,2017,11,2,22,7abcb0,[P] Collection of popular convnets with pre-trained weights in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/7abcb0/p_collection_of_popular_convnets_with_pretrained/,taehoonlee86,1509627809,,9,36
75,2017-11-2,2017,11,2,22,7abcyc,[R] New Tensorflow-based Boosted Trees library,https://www.reddit.com/r/MachineLearning/comments/7abcyc/r_new_tensorflowbased_boosted_trees_library/,statmlsn,1509628002,,1,8
76,2017-11-2,2017,11,2,22,7abjg4,[R] Deep Neural Networks as Gaussian Processes,https://www.reddit.com/r/MachineLearning/comments/7abjg4/r_deep_neural_networks_as_gaussian_processes/,hardmaru,1509629868,,2,21
77,2017-11-2,2017,11,2,22,7ablnb,"[N] Weekly Machine Learning Example &amp; Toolset Roundup  Nov. 2, 2017",https://www.reddit.com/r/MachineLearning/comments/7ablnb/n_weekly_machine_learning_example_toolset_roundup/,stkim1,1509630469,,0,1
78,2017-11-2,2017,11,2,23,7abv83,"[D] What's the difference between a top ML scientist/engineer, and a mid-tier one? What are the exact traits?",https://www.reddit.com/r/MachineLearning/comments/7abv83/d_whats_the_difference_between_a_top_ml/,Batmantosh,1509632995,"I was reading this article https://www.theverge.com/2017/11/1/16592338/eric-schmidt-google-ai-competition-us-china

And I was wondering. What makes someone 'good' at AI? I think the most objective metric is the ability to produce results and cutting edge new applications. For example, being able to beat the world Go champion decades before scientists predicted it would be possible.

But what are the exact traits lead to these people to produce such accomplishments? 

My best guess is a deeper theoretical background. However, I'm not so sure as it seems the most of the breakthrough applications of ML have come from better hardware and access to data, compared to more cutting edge ML theory. Or perhaps a deeper theoretical background gives the scientist an essential intuition for developing the best results. 

In that case, should a person working in the ML field invest time into certain concepts? If so, which ones? Just machine learning? Or more foundational ones such as linear algebra, statistics, and computation? ",23,15
79,2017-11-2,2017,11,2,23,7abwz1,Clarification of decision-tree building using Gini index as split,https://www.reddit.com/r/MachineLearning/comments/7abwz1/clarification_of_decisiontree_building_using_gini/,rayaela,1509633461,[removed],0,1
80,2017-11-2,2017,11,2,23,7abzh9,[R] Hierarchical Representations for Efficient Architecture Search. A simple yet powerful evolutionary algorithm that can discover new architectures achieving state of the art results.,https://www.reddit.com/r/MachineLearning/comments/7abzh9/r_hierarchical_representations_for_efficient/,arisbw,1509634088,,4,26
81,2017-11-2,2017,11,2,23,7ac0uo,[D] Independent word embedding dimensions,https://www.reddit.com/r/MachineLearning/comments/7ac0uo/d_independent_word_embedding_dimensions/,Pieranha,1509634448,"Has anyone ever tried to create word embeddings with independent dimensions? If you just train with e.g. skip-gram, the dimensions seem to be somewhat entangled with each other. I'd guess that placing a Gaussian prior on the embeddings using KL should work similar to how the latent vector in a VAE is forced to be approximately Gaussian. I've searched Google, but have been unable to find any papers on this.

The motivation for me is that I need a very efficient method in terms of computational resources, which makes a logistic regression on top of word embeddings tempting. However, the logistic regression treats each embedding dimension as independent so it would seem natural to ensure that they are independent as possible. Also, the word embeddings might be more interpretable if the dimensions are independent, which would be a big plus.

Thoughts?",3,3
82,2017-11-2,2017,11,2,23,7ac13r,Building Your Own Instagram Discovery Engine: A Step-By-Step Tutorial - The Stream Blog,https://www.reddit.com/r/MachineLearning/comments/7ac13r/building_your_own_instagram_discovery_engine_a/,balazshoranyi,1509634519,,0,1
83,2017-11-2,2017,11,2,23,7ac14u,Machine Learning in RapidMiner,https://www.reddit.com/r/MachineLearning/comments/7ac14u/machine_learning_in_rapidminer/,DeviceHive,1509634527,,0,1
84,2017-11-3,2017,11,3,0,7ac4kp,[P] Minimalistic TensorFlow implementation of Wasserstein GAN,https://www.reddit.com/r/MachineLearning/comments/7ac4kp/p_minimalistic_tensorflow_implementation_of/,adler-j,1509635386,,5,21
85,2017-11-3,2017,11,3,0,7ac6xx,[D] GAN with non image data,https://www.reddit.com/r/MachineLearning/comments/7ac6xx/d_gan_with_non_image_data/,Skarwild,1509635961,"I read a few papers about GANs but in all the papers the GANs are trained on image datasets.
My question is simple, is it possible to use the same technique on a non image dataset, for example the famouse Iris dataset.",10,13
86,2017-11-3,2017,11,3,0,7ac6zd,[D] With all these authors publicizing/de-anonymizing their papers? Should I do the same?,https://www.reddit.com/r/MachineLearning/comments/7ac6zd/d_with_all_these_authors_publicizingdeanonymizing/,AnonymousICLR,1509635968,"I believe in double-blind and it has been shown that bias does happen without it: 

Single versus Double Blind Reviewing at WSDM 2017
https://arxiv.org/abs/1702.00502

Ironically, the organization that wrote the paper on bias seems to being doing the most publicizing of their ICLR submissions.

As someone at a university, how do I contend with this? The organizations that break double blind will more likely have an advantage during the review process.",16,23
87,2017-11-3,2017,11,3,0,7ac7ak,[D] How to get NNs to converge to the prior for unseen outliers?,https://www.reddit.com/r/MachineLearning/comments/7ac7ak/d_how_to_get_nns_to_converge_to_the_prior_for/,svantana,1509636047,"There's a tendency for classifier NNs to be overconfident about outliers -- generally they extrapolate to arbitrary values outside of the training data distribution. This is only exacerbated by the use of ReLUs and the like, which grow indefinitely and generally tend to P(x|c)--&gt;1 for some category when x moves away from the training set. In my application, I would like the classifier to give a flat distribution for inputs outside of the training set; are there any tried and tested ways of doing that?",3,8
88,2017-11-3,2017,11,3,0,7ac8j6,Towards deep learning with segregated dendrites,https://www.reddit.com/r/MachineLearning/comments/7ac8j6/towards_deep_learning_with_segregated_dendrites/,JunpilPark,1509636368,,0,1
89,2017-11-3,2017,11,3,0,7ac9kt,[D] Has anyone tried using GAN as training data of a classifier?,https://www.reddit.com/r/MachineLearning/comments/7ac9kt/d_has_anyone_tried_using_gan_as_training_data_of/,RavlaAlvar,1509636625,Does it works?,9,9
90,2017-11-3,2017,11,3,0,7acalg,[P] IdeaValid - Validate your business idea using machine learning,https://www.reddit.com/r/MachineLearning/comments/7acalg/p_ideavalid_validate_your_business_idea_using/,deepartistry,1509636859,,0,1
91,2017-11-3,2017,11,3,0,7acba9,[R] Probabilistic Graphical Models: a powerful framework to learn the models with dependency,https://www.reddit.com/r/MachineLearning/comments/7acba9/r_probabilistic_graphical_models_a_powerful/,4ananas,1509637035,,6,18
92,2017-11-3,2017,11,3,1,7aci20,"[r] a review of mixup: data-dependent data augmentation, reformulation + semi-supervised view",https://www.reddit.com/r/MachineLearning/comments/7aci20/r_a_review_of_mixup_datadependent_data/,fhuszar,1509638675,,12,42
93,2017-11-3,2017,11,3,1,7aco9t,[P] TypedFlow: a higher-order typed frontend to TensorFlow and high-level library for deep-learning. X-post /r/Haskell,https://www.reddit.com/r/MachineLearning/comments/7aco9t/p_typedflow_a_higherorder_typed_frontend_to/,drwebb,1509640184,,3,8
94,2017-11-3,2017,11,3,1,7acpf3,Open AI Cartpole solved with non-discrete MDP using LSTM for improved anticipation. Would love to see your solutions...,https://www.reddit.com/r/MachineLearning/comments/7acpf3/open_ai_cartpole_solved_with_nondiscrete_mdp/,FitMachineLearning,1509640460,,1,1
95,2017-11-3,2017,11,3,2,7acyc9,[1711.00043] Unsupervised Machine Translation Using Monolingual Corpora Only,https://www.reddit.com/r/MachineLearning/comments/7acyc9/171100043_unsupervised_machine_translation_using/,jrmuizel,1509642606,,1,3
96,2017-11-3,2017,11,3,2,7ad2x3,[R] Blog: Some thoughts on the objective functions of GANs,https://www.reddit.com/r/MachineLearning/comments/7ad2x3/r_blog_some_thoughts_on_the_objective_functions/,levansfg,1509643724,,2,2
97,2017-11-3,2017,11,3,2,7ada08,[D] We built a site to host image datasets - request for feedback,https://www.reddit.com/r/MachineLearning/comments/7ada08/d_we_built_a_site_to_host_image_datasets_request/,hanrelan,1509645462,"Hi r/ML, we built [Brine.io](https://www.brine.io/datasets) to make it easy to host and share datasets and would love your feedback.

Would hosting your datasets publicly or privately be useful to you? Is finding, loading or sharing datasets a problem you have that this Brine might fix?

Brine is focused specifically on hosting image datasets since that's where we found being able to visualize the images and get the dataset in a standardized format is most helpful. If there's interest we might expand to video and audio as well. Our plan would be to make Brine completely free for public datasets and charge for private ones (similar to GitHub).

If you have any thoughts/questions/ideas please let us know in the comments!",7,17
98,2017-11-3,2017,11,3,3,7ade8c,How Adversarial Attacks Work,https://www.reddit.com/r/MachineLearning/comments/7ade8c/how_adversarial_attacks_work/,[deleted],1509646474,[deleted],0,1
99,2017-11-3,2017,11,3,3,7adj8b,[R] Tensorflow 1.4 released!,https://www.reddit.com/r/MachineLearning/comments/7adj8b/r_tensorflow_14_released/,MetricSpade007,1509647634,,47,245
100,2017-11-3,2017,11,3,4,7adpzm,A.I. vs. Pathologists: Survival of the Fittest,https://www.reddit.com/r/MachineLearning/comments/7adpzm/ai_vs_pathologists_survival_of_the_fittest/,AIBeliever,1509649231,,0,1
101,2017-11-3,2017,11,3,4,7adrab,[R] Efficient Implementation of Self-Organizing Map for Sparse Input Data,https://www.reddit.com/r/MachineLearning/comments/7adrab/r_efficient_implementation_of_selforganizing_map/,_yoch_,1509649541,,1,1
102,2017-11-3,2017,11,3,4,7adyl4,[P][Tutorial] From Zero to Learning to Rank in Apache Solr,https://www.reddit.com/r/MachineLearning/comments/7adyl4/ptutorial_from_zero_to_learning_to_rank_in_apache/,michaelaalcorn,1509651292,,0,2
103,2017-11-3,2017,11,3,5,7aebwj,Are we ready to let A.I. in on our creative process?,https://www.reddit.com/r/MachineLearning/comments/7aebwj/are_we_ready_to_let_ai_in_on_our_creative_process/,anteism_books,1509654501,[removed],0,1
104,2017-11-3,2017,11,3,5,7aee2c,Waifu2x API,https://www.reddit.com/r/MachineLearning/comments/7aee2c/waifu2x_api/,Coinybit,1509655012,,0,1
105,2017-11-3,2017,11,3,6,7aevmn,[N] Latest Innovations in TensorFlow Serving,https://www.reddit.com/r/MachineLearning/comments/7aevmn/n_latest_innovations_in_tensorflow_serving/,Jackal008,1509659376,,1,3
106,2017-11-3,2017,11,3,6,7aew4x,[N] AutoML for large scale image classification and object detection,https://www.reddit.com/r/MachineLearning/comments/7aew4x/n_automl_for_large_scale_image_classification_and/,Jackal008,1509659507,,13,21
107,2017-11-3,2017,11,3,6,7aexxa,What exactly is IBM doing different with machine learning?,https://www.reddit.com/r/MachineLearning/comments/7aexxa/what_exactly_is_ibm_doing_different_with_machine/,alexa_y,1509659976,,0,1
108,2017-11-3,2017,11,3,7,7aezwl,How does the training time/performance of a neural network vary if you train on a multicore CPU vs GPU?,https://www.reddit.com/r/MachineLearning/comments/7aezwl/how_does_the_training_timeperformance_of_a_neural/,megadarkfriend,1509660441,[removed],0,1
109,2017-11-3,2017,11,3,9,7aft17,[P]  Latest Deep Learning OCR with Keras and Supervisely in 15 minutes,https://www.reddit.com/r/MachineLearning/comments/7aft17/p_latest_deep_learning_ocr_with_keras_and/,tdionis,1509668170,,0,10
110,2017-11-3,2017,11,3,10,7ag59i,Rousing Masses to Fight Cancer with Open Source Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7ag59i/rousing_masses_to_fight_cancer_with_open_source/,Chipdoc,1509671710,,0,1
111,2017-11-3,2017,11,3,10,7agbxe,Rotary drum Dryer for Organic fertilizer,https://www.reddit.com/r/MachineLearning/comments/7agbxe/rotary_drum_dryer_for_organic_fertilizer/,amylee516,1509673648,,0,1
112,2017-11-3,2017,11,3,11,7agh78,Public NIPS Reviews,https://www.reddit.com/r/MachineLearning/comments/7agh78/public_nips_reviews/,CrickWu,1509675230,[removed],0,1
113,2017-11-3,2017,11,3,11,7agi7o,An Introduction to Gaussian Mixture Models in Pytorch,https://www.reddit.com/r/MachineLearning/comments/7agi7o/an_introduction_to_gaussian_mixture_models_in/,Algomancer,1509675544,,0,1
114,2017-11-3,2017,11,3,11,7agk7d,How Adversarial Attacks Work,https://www.reddit.com/r/MachineLearning/comments/7agk7d/how_adversarial_attacks_work/,[deleted],1509676164,[removed],0,1
115,2017-11-3,2017,11,3,12,7agrqr,Tool for Building Word Clouds Using R,https://www.reddit.com/r/MachineLearning/comments/7agrqr/tool_for_building_word_clouds_using_r/,gjain840,1509678581,,0,1
116,2017-11-3,2017,11,3,12,7agt90,Noob tensorflow question,https://www.reddit.com/r/MachineLearning/comments/7agt90/noob_tensorflow_question/,[deleted],1509679052,[removed],0,1
117,2017-11-3,2017,11,3,12,7aguwr,Artificial Neural Networks Explained !,https://www.reddit.com/r/MachineLearning/comments/7aguwr/artificial_neural_networks_explained/,harshMachineLearning,1509679603,[removed],0,1
118,2017-11-3,2017,11,3,13,7ah6dg,"What if Artificial Intelligence has already started its attack on mankind through a sophisticated manipulation of data and information using pre-existing networks like social media, trends fake news to traffic our exposure to information as a way to influence our behavior and attack our culture.",https://www.reddit.com/r/MachineLearning/comments/7ah6dg/what_if_artificial_intelligence_has_already/,SuperS0nic99,1509683422,[removed],0,1
119,2017-11-3,2017,11,3,13,7ah810,Data Augmentation in Classification using GAN,https://www.reddit.com/r/MachineLearning/comments/7ah810/data_augmentation_in_classification_using_gan/,andygao,1509684059,,1,1
120,2017-11-3,2017,11,3,14,7ahfto,[P] Bias-variance tradeoff in &lt; 100secs,https://www.reddit.com/r/MachineLearning/comments/7ahfto/p_biasvariance_tradeoff_in_100secs/,harry_0_0_7,1509687075,,0,1
121,2017-11-3,2017,11,3,15,7ahl7i,Dough Sheeter | Dough Sheeting Machine For Sale,https://www.reddit.com/r/MachineLearning/comments/7ahl7i/dough_sheeter_dough_sheeting_machine_for_sale/,liusherry,1509689301,,1,1
122,2017-11-3,2017,11,3,15,7ahn24,Predictive Analytics-MLDL,https://www.reddit.com/r/MachineLearning/comments/7ahn24/predictive_analyticsmldl/,chetanlgaonkar,1509690116,,0,1
123,2017-11-3,2017,11,3,16,7ahuf5,"GAN Playground: Experiment with Generative Adversarial Nets in your browser. Observe convergence, mode collapse, etc. in real time",https://www.reddit.com/r/MachineLearning/comments/7ahuf5/gan_playground_experiment_with_generative/,[deleted],1509693393,[deleted],0,1
124,2017-11-3,2017,11,3,16,7ahum9,"GAN Playground: Experiment with Generative Adversarial Nets in your browser. Observe convergence, mode collapse, etc. in real time",https://www.reddit.com/r/MachineLearning/comments/7ahum9/gan_playground_experiment_with_generative/,[deleted],1509693487,[deleted],0,1
125,2017-11-3,2017,11,3,16,7ahuv5,AI Security Bot - Tweets about AI security issues,https://www.reddit.com/r/MachineLearning/comments/7ahuv5/ai_security_bot_tweets_about_ai_security_issues/,RandomAdversary,1509693584,,0,1
126,2017-11-3,2017,11,3,16,7ahuzh,"GAN Playground: Experiment with Generative Adversarial Nets in your browser. Observe convergence, mode collapse, etc. in real time",https://www.reddit.com/r/MachineLearning/comments/7ahuzh/gan_playground_experiment_with_generative/,[deleted],1509693653,[deleted],0,1
127,2017-11-3,2017,11,3,16,7ahve2,"[P] GAN Playground: Experiment with Generative Adversarial Nets in your browser. Observe convergence, mode collapse, etc. in real time",https://www.reddit.com/r/MachineLearning/comments/7ahve2/p_gan_playground_experiment_with_generative/,Reiinakano,1509693850,,14,58
128,2017-11-3,2017,11,3,17,7ai47x,Working of Neural Network explained with a simple real-life example.,https://www.reddit.com/r/MachineLearning/comments/7ai47x/working_of_neural_network_explained_with_a_simple/,harshMachineLearning,1509698157,,0,1
129,2017-11-3,2017,11,3,17,7ai4fz,Automotive Axle &amp;amp; Propeller Shaft Market worth 58.07 Billion USD by 2021,https://www.reddit.com/r/MachineLearning/comments/7ai4fz/automotive_axle_amp_propeller_shaft_market_worth/,abhigunjal,1509698255,,0,1
130,2017-11-3,2017,11,3,17,7ai4m2,[D] Visual reasoning and dialog: Towards natural language conversations about visual data,https://www.reddit.com/r/MachineLearning/comments/7ai4m2/d_visual_reasoning_and_dialog_towards_natural/,hlynurd,1509698353,,0,2
131,2017-11-3,2017,11,3,17,7ai57b,Tips on gathering actigraphy recordings,https://www.reddit.com/r/MachineLearning/comments/7ai57b/tips_on_gathering_actigraphy_recordings/,alexdefelipe,1509698696,[removed],0,1
132,2017-11-3,2017,11,3,18,7ai7sn,[D] server for ML: i7 8700 vs i7 8700k and 1080 Ti vs 1080 Ti waterforce,https://www.reddit.com/r/MachineLearning/comments/7ai7sn/d_server_for_ml_i7_8700_vs_i7_8700k_and_1080_ti/,leohom,1509699922,"I am building for a server for ML and find it hard to make decision between CPUs and GPUs.

i7 8700: 3.2 GHz vs i7 8700k: 3.7GHz

1080 Ti: 1683MHz vs 1080 Ti waterforce: 1708MHz

&amp;nbsp;

I am thinking about

A: i7 8700k + 1080 Ti waterforce

B: i7 8700 + 1080 Ti

However, the price difference between A and B is about $230.

&amp;nbsp;

I am using Keras and TensorFlow to deal with some nlp tasks.

Does the speed depends on GHz or MHz?
Will it has huge speed difference on those?
I am wondering if the $230 difference worth it?",13,5
133,2017-11-3,2017,11,3,18,7aia5g,"Googles AI thinks this turtle looks like a gun, which is a problem",https://www.reddit.com/r/MachineLearning/comments/7aia5g/googles_ai_thinks_this_turtle_looks_like_a_gun/,dunkin1980,1509701012,,1,1
134,2017-11-3,2017,11,3,18,7aib0r,What do you all think about Empirical Dynamic Modeling? (Detailed links herein),https://www.reddit.com/r/MachineLearning/comments/7aib0r/what_do_you_all_think_about_empirical_dynamic/,OnceReturned,1509701453,[removed],0,1
135,2017-11-3,2017,11,3,19,7aigzh,"[P] PyTorch Implementation of ""Dynamic Routing Between Capsules""",https://www.reddit.com/r/MachineLearning/comments/7aigzh/p_pytorch_implementation_of_dynamic_routing/,gram-ai,1509704150,,17,104
136,2017-11-3,2017,11,3,19,7aih68,I'm not sure if this is the right place to ask but there is this humanoid robot called Sophia which is making a lot of buzz lately. Can anyone shed a light if its true AI or just a tape recorder with steppers?,https://www.reddit.com/r/MachineLearning/comments/7aih68/im_not_sure_if_this_is_the_right_place_to_ask_but/,Starkboy,1509704223,[removed],0,1
137,2017-11-3,2017,11,3,19,7aijol,"Torch implementation of ""progressive growing GAN"" for 1024x1024 face images",https://www.reddit.com/r/MachineLearning/comments/7aijol/torch_implementation_of_progressive_growing_gan/,min-nashory,1509705348,,0,1
138,2017-11-3,2017,11,3,19,7aik4v,A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/7aik4v/a_unified_gametheoretic_approach_to_multiagent/,Borgut1337,1509705569,,0,1
139,2017-11-3,2017,11,3,19,7aikyp,How to Find Meaningful Work In Life,https://www.reddit.com/r/MachineLearning/comments/7aikyp/how_to_find_meaningful_work_in_life/,funmaster11,1509705929,,0,1
140,2017-11-3,2017,11,3,20,7aio4n,[D] - Looking for a machine learning book co-author,https://www.reddit.com/r/MachineLearning/comments/7aio4n/d_looking_for_a_machine_learning_book_coauthor/,jguertl,1509707228,[removed],0,1
141,2017-11-3,2017,11,3,20,7aitth,[D] Extracting an identity of non-image data to generate new conditioned samples with this identity using GANs,https://www.reddit.com/r/MachineLearning/comments/7aitth/d_extracting_an_identity_of_nonimage_data_to/,synzierly,1509709414,"I want to extract the identity, actually a small latent space, of my input and use this identity to generate new conditioned samples. The data is at the moment just some simple sinus functions as a toy example. I am using variations of GANs. 

Setup: 

1. Extract Identity with an Encoder -&gt; get a latent space z (which is trained with a Decoder to produce nice latent representations, AE like)

2. Use this latent space z for my conditional GAN. The conditional GAN is based on cGAN (https://arxiv.org/abs/1411.1784) and WGAN-GP (https://arxiv.org/abs/1704.00028). So it is kind of a cWGAN-GP. 

3. The Generator consists of fully connected layers and transposed convolutions to sample up the small latent space. The Discriminator is kind of the inverse of the Generator, using also fully connected layers and 1D-convolutions. 

What I want to achieve (example):

Suppose I have training data of numerous sinus curves which are conditioned on a y-axis offset and its frequency.  I get the sinus curves and I get the conditions (offset, frequency) of those as well. I extract the identity, the latent space, of one specific sinus curve (lets say 0.1 offset and 2.0 frequency). Now I want to take this identity as input for the GAN with an additional condition that changes the frequency from 2.0 to 2.5. The GAN should now learn to generate the sinus curve with the old identity (offset) but with the new frequency 2.5. So in the end I want to have a curve that has the offset 0.1 with a frequency of 2.5.

This is a simplified example, the end system is more complex, but I wanted to get it running with this easy example first. 

Under normal conditions, my cWGAN-GP is working really fine and is able to produce nice conditioned sinus curves even with data that it has not seen, yet. I am inspired by those papers:
http://web.eecs.utk.edu/%7Ezzhang61/docs/papers/2017_CVPR_Age.pdf
https://zhaoj9014.github.io/pub/0004.pdf

Questions: 

Do you think this is even possible? Do I need to define special losses or use the standard ones from WGAN-GP? Am I on a completely wrong track? 
",1,3
142,2017-11-3,2017,11,3,20,7aivv1,[R]Filtering startup news with Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7aivv1/rfiltering_startup_news_with_machine_learning/,magneticono,1509710186,,0,1
143,2017-11-3,2017,11,3,21,7aiz63,Master The Skills Of Machine Learning Web Development And Be Successful,https://www.reddit.com/r/MachineLearning/comments/7aiz63/master_the_skills_of_machine_learning_web/,endivesoftware,1509711340,,0,1
144,2017-11-3,2017,11,3,21,7aj0o7,[N] Call for Posters - Applied Machine Learning Days 2018,https://www.reddit.com/r/MachineLearning/comments/7aj0o7/n_call_for_posters_applied_machine_learning_days/,XCaellaX,1509711836,,0,8
145,2017-11-3,2017,11,3,21,7aj61j,"Artificial Intelligence Thinks This Turtle Is A Gun, Highlighting A Major Problem With Object Recognition Technology",https://www.reddit.com/r/MachineLearning/comments/7aj61j/artificial_intelligence_thinks_this_turtle_is_a/,T-SQL_Purveyor,1509713626,,0,1
146,2017-11-3,2017,11,3,22,7ajctk,[P] OpenNMT-tf: a modular TensorFlow implementation for neural sequence learning,https://www.reddit.com/r/MachineLearning/comments/7ajctk/p_opennmttf_a_modular_tensorflow_implementation/,guillaumekln,1509715648,,0,12
147,2017-11-3,2017,11,3,23,7ajoc1,"What is backpropagation and what is it actually doing? | Deep learning, chapter 3",https://www.reddit.com/r/MachineLearning/comments/7ajoc1/what_is_backpropagation_and_what_is_it_actually/,beltsazar,1509718839,,0,1
148,2017-11-3,2017,11,3,23,7ajoxd,"What is backpropagation and what is it actually doing? | Deep learning, chapter 3",https://www.reddit.com/r/MachineLearning/comments/7ajoxd/what_is_backpropagation_and_what_is_it_actually/,sheikheddy,1509718994,,0,1
149,2017-11-3,2017,11,3,23,7ajqsp,3blue1brown released the 3rd video in the deep learning series,https://www.reddit.com/r/MachineLearning/comments/7ajqsp/3blue1brown_released_the_3rd_video_in_the_deep/,sakram07,1509719488,,1,2
150,2017-11-3,2017,11,3,23,7ajv1a,https://youtu.be/Ilg3gGewQ5U,https://www.reddit.com/r/MachineLearning/comments/7ajv1a/httpsyoutubeilg3ggewq5u/,[deleted],1509720611,[deleted],0,1
151,2017-11-3,2017,11,3,23,7ajvjz,"[E]What is backpropagation and what is it actually doing? | Deep learning, chapter 3",https://www.reddit.com/r/MachineLearning/comments/7ajvjz/ewhat_is_backpropagation_and_what_is_it_actually/,finallyifoundvalidUN,1509720749,,1,2
152,2017-11-4,2017,11,4,0,7ak0qc,Weather Problem: Regression or Classification,https://www.reddit.com/r/MachineLearning/comments/7ak0qc/weather_problem_regression_or_classification/,[deleted],1509722122,[removed],0,1
153,2017-11-4,2017,11,4,0,7ak11h,"Pyro: universal, scalable, minimal, flexible probabilistic programming with PyTorch",https://www.reddit.com/r/MachineLearning/comments/7ak11h/pyro_universal_scalable_minimal_flexible/,[deleted],1509722201,[deleted],0,2
154,2017-11-4,2017,11,4,0,7ak6x9,"[N] Uber AI Labs Open Sources Pyro, a Deep Probabilistic Programming Language",https://www.reddit.com/r/MachineLearning/comments/7ak6x9/n_uber_ai_labs_open_sources_pyro_a_deep/,Eurchus,1509723719,,28,280
155,2017-11-4,2017,11,4,0,7ak70q,"When equipped with hidden layers, deep neural networks can accomplish nonlinear feats that are difficult even with sophisticated mathematics.",https://www.reddit.com/r/MachineLearning/comments/7ak70q/when_equipped_with_hidden_layers_deep_neural/,scied17,1509723738,,0,1
156,2017-11-4,2017,11,4,0,7ak720,[N] Pyro: PyTorch-Based Deep PPL,https://www.reddit.com/r/MachineLearning/comments/7ak720/n_pyro_pytorchbased_deep_ppl/,bobchennan,1509723748,,1,8
157,2017-11-4,2017,11,4,0,7aka4i,[D] GANs for Dialogue Generation: Near a breakthrough or just hype?,https://www.reddit.com/r/MachineLearning/comments/7aka4i/d_gans_for_dialogue_generation_near_a/,transpostmeta,1509724541,"People are very impressed by GANs in the vision field, but since text output is not differentiable, they are having a hard time in the NLP domain. However, people seem to be trying their hardest to make them work: [1](https://arxiv.org/pdf/1705.10929.pdf) [2](https://arxiv.org/pdf/1701.06547.pdf)

It seems to me that without some kind of knowledge system, just training a GAN on a large volume of conversations will never lead to any meaningful dialogue. But maybe I am wrong, and the network just needs to be large enough?

What are your thoughts on GAN and dialogue?",11,3
158,2017-11-4,2017,11,4,1,7akbfj,What is Uber-Pyro?,https://www.reddit.com/r/MachineLearning/comments/7akbfj/what_is_uberpyro/,bay_der,1509724864,[removed],0,1
159,2017-11-4,2017,11,4,1,7akfzo,Michael Tesa talks about his ML project that recognizes the color of objects.,https://www.reddit.com/r/MachineLearning/comments/7akfzo/michael_tesa_talks_about_his_ml_project_that/,winner_godson,1509725925,,0,1
160,2017-11-4,2017,11,4,1,7akleo,"[D] interested in learning more about genetic algorithms, looking for starter project recommendations to research.",https://www.reddit.com/r/MachineLearning/comments/7akleo/d_interested_in_learning_more_about_genetic/,ezeeetm,1509727325,"Preferably some projects that are well documented, lots of code examples, and easy to understand the core concepts of GA.  Not looking for 'hello world', maybe something 200-300 level?

Thanks!",6,2
161,2017-11-4,2017,11,4,1,7ako6s,"[R] Don't Decay the Learning Rate, Increase the Batch Size",https://www.reddit.com/r/MachineLearning/comments/7ako6s/r_dont_decay_the_learning_rate_increase_the_batch/,DrPharael,1509728023,,19,32
162,2017-11-4,2017,11,4,2,7akqk8,"What is backpropagation and what is it actually doing? | Deep learning, chapter 3",https://www.reddit.com/r/MachineLearning/comments/7akqk8/what_is_backpropagation_and_what_is_it_actually/,[deleted],1509728578,[deleted],0,1
163,2017-11-4,2017,11,4,2,7akrh2,AI Weekly 3rd Nov 2017,https://www.reddit.com/r/MachineLearning/comments/7akrh2/ai_weekly_3rd_nov_2017/,TomekB,1509728799,,0,1
164,2017-11-4,2017,11,4,2,7akzes,Here you can see the most beautiful places in the world that you can visit. - - - PLEASE SUBSCRIBE TO OUR CHANNEL !!! - - - Many interesting videos are waiting for you !,https://www.reddit.com/r/MachineLearning/comments/7akzes/here_you_can_see_the_most_beautiful_places_in_the/,TWV1,1509730747,,1,1
165,2017-11-4,2017,11,4,2,7akznq,Help with learning pytorch,https://www.reddit.com/r/MachineLearning/comments/7akznq/help_with_learning_pytorch/,drakesword514,1509730809,[removed],0,1
166,2017-11-4,2017,11,4,3,7al7b1,Question about replication,https://www.reddit.com/r/MachineLearning/comments/7al7b1/question_about_replication/,calligraphic-io,1509732660,[removed],0,1
167,2017-11-4,2017,11,4,3,7alam9,"What is backpropagation and what is it actually doing? | Deep learning, chapter 3",https://www.reddit.com/r/MachineLearning/comments/7alam9/what_is_backpropagation_and_what_is_it_actually/,thisisasshole,1509733496,,0,1
168,2017-11-4,2017,11,4,3,7alc5z,[R]how about the robustness of the Capsule Network to adversarial examples,https://www.reddit.com/r/MachineLearning/comments/7alc5z/rhow_about_the_robustness_of_the_capsule_network/,jaesik,1509733888,,8,4
169,2017-11-4,2017,11,4,4,7all9z,This Startup's Artificial Voice Sounds Almost Indistinguishable From A Human's,https://www.reddit.com/r/MachineLearning/comments/7all9z/this_startups_artificial_voice_sounds_almost/,macinnis23,1509736131,,0,1
170,2017-11-4,2017,11,4,4,7alpvn,[D] What ML patterns/expressions are hard to write efficient multi-core/multi-GPU code for?,https://www.reddit.com/r/MachineLearning/comments/7alpvn/d_what_ml_patternsexpressions_are_hard_to_write/,ajbouh,1509737271,"I'm working on a micro language for machine learning to help write very fast code for expressions that are tough or ugly to encode in raw TensorFlow and/or raw PyTorch.

Looking for examples of what people would like to provide as input to get fast, native, multi-core/multi-GPU code as output (that can then be embedded in a TensorFlow graph or PyTorch program).

edit: phrasing",13,9
171,2017-11-4,2017,11,4,4,7alrbn,[R] Rainbow: Combining Improvements in Deep Reinforcement Learning Paper by Google DeepMind,https://www.reddit.com/r/MachineLearning/comments/7alrbn/r_rainbow_combining_improvements_in_deep/,abstractcontrol,1509737640,,1,0
172,2017-11-4,2017,11,4,6,7ameip,How Self Driving Cars Will Change Your Life!,https://www.reddit.com/r/MachineLearning/comments/7ameip/how_self_driving_cars_will_change_your_life/,CrimsonStudioz,1509743759,,0,1
173,2017-11-4,2017,11,4,6,7amgbi,3Blue1Brown finally finished his series about Neural Networks,https://www.reddit.com/r/MachineLearning/comments/7amgbi/3blue1brown_finally_finished_his_series_about/,YourVibe,1509744230,,0,1
174,2017-11-4,2017,11,4,6,7amgq0,"Machine Learning, Knowledge Extraction And Blockchain: The Knowledge Engine (A Mathematical Theory of Knowledge Part 1)",https://www.reddit.com/r/MachineLearning/comments/7amgq0/machine_learning_knowledge_extraction_and/,Bartmoss,1509744345,,0,1
175,2017-11-4,2017,11,4,7,7amp0l,"[D] NIPS Camera Ready, what is ""5 letter submission code""?",https://www.reddit.com/r/MachineLearning/comments/7amp0l/d_nips_camera_ready_what_is_5_letter_submission/,alexmlamb,1509746641,[removed],1,2
176,2017-11-4,2017,11,4,10,7anso6,Math for Machine Learning Online Course,https://www.reddit.com/r/MachineLearning/comments/7anso6/math_for_machine_learning_online_course/,rickmister24,1509758224,[removed],0,1
177,2017-11-4,2017,11,4,11,7ao1s1,"[P] Chainer Implementation of ""Dynamic Routing Between Capsules""",https://www.reddit.com/r/MachineLearning/comments/7ao1s1/p_chainer_implementation_of_dynamic_routing/,sushiai,1509761226,,3,19
178,2017-11-4,2017,11,4,12,7aof1j,[D] Is Capsules just another way of replacing pooling just like self-attention?,https://www.reddit.com/r/MachineLearning/comments/7aof1j/d_is_capsules_just_another_way_of_replacing/,futbol_account,1509765804,"Hinton questioned about CNN a lot in many of his videos, but his paper still uses convolution. He just made it more robust for the transformation of the image.

Is there any relation between self-attention and capsules?",13,11
179,2017-11-4,2017,11,4,12,7aog93,"[News] Keras 2.0.9 - H:M:S ETA clock added, and very fast LSTM/GRU",https://www.reddit.com/r/MachineLearning/comments/7aog93/news_keras_209_hms_eta_clock_added_and_very_fast/,vannak139,1509766246,"Now's a great time to update. In addition to the sick new clock, CuDNNLSTM and CuDNNGRU have been added. I have only tried out CuDNNLSTM so far but its very very fast. 

https://github.com/fchollet/keras/releases/tag/2.0.9",9,23
180,2017-11-4,2017,11,4,12,7aojm0,Discussion &amp; Questions threads for Dynamic Routing by Capsules,https://www.reddit.com/r/MachineLearning/comments/7aojm0/discussion_questions_threads_for_dynamic_routing/,idg101,1509767530,[removed],1,1
181,2017-11-4,2017,11,4,12,7aojm7,"In light of the capsules paper, let us be reminded of Yoshua Bengio's thoughts on Geoff Hinton's work",https://www.reddit.com/r/MachineLearning/comments/7aojm7/in_light_of_the_capsules_paper_let_us_be_reminded/,[deleted],1509767531,[deleted],0,1
182,2017-11-4,2017,11,4,12,7aojsj,[D] Google's deep learning AI algorithm is easy to fool,https://www.reddit.com/r/MachineLearning/comments/7aojsj/d_googles_deep_learning_ai_algorithm_is_easy_to/,[deleted],1509767599,[deleted],0,1
183,2017-11-4,2017,11,4,12,7aojtu,"OS X vs. Windows, does it matter and if so which is preferable?",https://www.reddit.com/r/MachineLearning/comments/7aojtu/os_x_vs_windows_does_it_matter_and_if_so_which_is/,WhenDovesCray,1509767613,[removed],0,1
184,2017-11-4,2017,11,4,14,7ap0ql,Learn Machine Learning in 15 minutes,https://www.reddit.com/r/MachineLearning/comments/7ap0ql/learn_machine_learning_in_15_minutes/,cloudirec,1509774597,,0,1
185,2017-11-4,2017,11,4,19,7apvr4,"[D] It seems like AlphaGo Zero's biggest successes come from simply removing elements of the first AlphaGo algorithm, not adding new ones. What are the changes that allow the new version to be both simpler and more successful?",https://www.reddit.com/r/MachineLearning/comments/7apvr4/d_it_seems_like_alphago_zeros_biggest_successes/,NealJMD,1509790734,"The more I've read about AlphaGo Zero, the more it seems like the major innovations are all just simplifications of the previous algorithm:

* Starting reinforcement learning with a network of random weights, rather than one trained to predict the moves of expert humans.
* Training one network to output both policy and valuation scores, instead of two distinct networks.
* Evaluating MCTS leaf nodes with only the NN's valuation, instead of summing that value with a likelihood of victory based on naive fast rollout.

The only other changes that I can really discern from the paper and the AMA are:

* Using a residual neural network instead of a convolutional neural network.
* Changing the gradient descent to [minimize the difference between the neural net predictions and search tree predictions and the difference between the predicted and actual outcome](https://imgur.com/a/qigLS), rather than [minimizing the likelihood the game would end in loss](https://imgur.com/a/a3eyD).

Can that really be all? This begins to beg the question of why pure reinforcement learning wasn't enough for the original AG. [The top question of the AMA](https://www.reddit.com/r/MachineLearning/comments/76xjb5/ama_we_are_david_silver_and_julian_schrittwieser/dokh31z/) asks how AGZ's reinforcement learning was so stable. The answer only addresses why the AlphaGo approach to reinforcement learning is more stable than other algorithms, but doesn't explain at all why AGZ is better than AG, as they use almost identical reinforcement learning algorithms.

So where is the magic? Is this just great engineering and iteration on a codebase with the careful tuning of hyper-parameters? Or is there really a great algorithmic leap here besides simply doing less?

",48,234
186,2017-11-4,2017,11,4,21,7aq9u7,[R] Meta-Learning and Universality: Deep Representations and Gradient Descent can Approximate any Learning Algorithm,https://www.reddit.com/r/MachineLearning/comments/7aq9u7/r_metalearning_and_universality_deep/,qerar,1509797287,,21,0
187,2017-11-4,2017,11,4,21,7aqdqp,Question about Alpha-Go-Zero MCTS,https://www.reddit.com/r/MachineLearning/comments/7aqdqp/question_about_alphagozero_mcts/,[deleted],1509798824,[removed],0,1
188,2017-11-4,2017,11,4,23,7aqs8c,[P] DRL with AirSim - Potential to use high end game graphics for DRL research. First test implementation with OpenAI gym.,https://www.reddit.com/r/MachineLearning/comments/7aqs8c/p_drl_with_airsim_potential_to_use_high_end_game/,kjellwhatnot,1509804083,,2,7
189,2017-11-4,2017,11,4,23,7ar3bq,Machine learning Flexible design UI,https://www.reddit.com/r/MachineLearning/comments/7ar3bq/machine_learning_flexible_design_ui/,QuestionMarksman,1509807425,[removed],0,1
190,2017-11-5,2017,11,5,0,7araws,[D] Even a randomly generated loss function with DCGAN can generate MNIST images,https://www.reddit.com/r/MachineLearning/comments/7araws/d_even_a_randomly_generated_loss_function_with/,[deleted],1509809603,[deleted],3,1
191,2017-11-5,2017,11,5,0,7arb6d,"Wotel Mini Electric Sweing Machine/Sweing Kit Set Review In English Like,Share &amp; Subscribe Now Syra Creations",https://www.reddit.com/r/MachineLearning/comments/7arb6d/wotel_mini_electric_sweing_machinesweing_kit_set/,SyraCreations,1509809676,,0,1
192,2017-11-5,2017,11,5,0,7arb93,[N] We have released EMOTIC (EMOTions In Context) dataset; based on our paper published in CVPR'17,https://www.reddit.com/r/MachineLearning/comments/7arb93/n_we_have_released_emotic_emotions_in_context/,ronakosti,1509809701,"**EMOTIC** highlights

* Emotion Labels for a person in 2 different, independent modalities. 
* The Person is in his/her natural, unconstrained environment i.e. the emotions are natural and **not artificial**. 

[EMOTIC project link](http://sunai.uoc.edu/emotic/)

[CVPR17 paper link](http://openaccess.thecvf.com/content_cvpr_2017/html/Kosti_Emotion_Recognition_in_CVPR_2017_paper.html)",0,16
193,2017-11-5,2017,11,5,0,7ardyj,Backing off towards simplicity - why baselines need more love,https://www.reddit.com/r/MachineLearning/comments/7ardyj/backing_off_towards_simplicity_why_baselines_need/,[deleted],1509810464,[deleted],0,1
194,2017-11-5,2017,11,5,1,7arhbw,"Anistropic data clustering, DBSCAN and GMM fails?",https://www.reddit.com/r/MachineLearning/comments/7arhbw/anistropic_data_clustering_dbscan_and_gmm_fails/,trumee,1509811407,[removed],0,1
195,2017-11-5,2017,11,5,1,7armgs,[R] [1711.00520] Uncovering Latent Style Factors for Expressive Speech Synthesis,https://www.reddit.com/r/MachineLearning/comments/7armgs/r_171100520_uncovering_latent_style_factors_for/,tuan3w,1509812875,,4,4
196,2017-11-5,2017,11,5,1,7arref,[D] Thoughts on whether probability theory is an improper explanation of DL?,https://www.reddit.com/r/MachineLearning/comments/7arref/d_thoughts_on_whether_probability_theory_is_an/,DLamikins,1509814312,,13,0
197,2017-11-5,2017,11,5,2,7arv8y,predicting lake freeze,https://www.reddit.com/r/MachineLearning/comments/7arv8y/predicting_lake_freeze/,EskimoJoe87,1509815385,[removed],0,1
198,2017-11-5,2017,11,5,2,7as0s3,"Andrew Ng's Machine Learning Coursera Course, after completing 4th week. Suggest some projects to do as project",https://www.reddit.com/r/MachineLearning/comments/7as0s3/andrew_ngs_machine_learning_coursera_course_after/,codesync,1509816809,[removed],0,1
199,2017-11-5,2017,11,5,3,7asas8,From Ballerina to AI Writer An Experiment on Building a Classifier by a Non-Technical Person,https://www.reddit.com/r/MachineLearning/comments/7asas8/from_ballerina_to_ai_writer_an_experiment_on/,pahita,1509819506,,0,1
200,2017-11-5,2017,11,5,3,7asdm9,Decision Tree - How train with categorical features,https://www.reddit.com/r/MachineLearning/comments/7asdm9/decision_tree_how_train_with_categorical_features/,QuanTocDo,1509820313,[removed],0,1
201,2017-11-5,2017,11,5,4,7asu1o,[D] Do you not find it annoying there's no term to overfitting via hyperparameters to validation set as opposed to overfitting parameters (e.g weights) to train set)?,https://www.reddit.com/r/MachineLearning/comments/7asu1o/d_do_you_not_find_it_annoying_theres_no_term_to/,kakushka123,1509824818,"A few days ago a colleague of mine recommended a system that acts as sort of regularization for the weights in a linear regression. And I said sure just make sure the score improvement isn't simply a result of overfitting, to which he replied that the system he proposes is supposed to **reduce** overfitting. 

Obviously I knew what he meant (reduce overfitting of the weights to the training set) but it did not contradict what I meant (the extra hyperparameters in his system may result in score improvement that is simply overfitting to the validation set).

Wouldn't it be simpler if there was a word for overfitting hyperparameters to the validatoin set (that artificially improves the score of the validation set), as opposed to overfitting parameters to the training set (that decreases the score of the validation set)? (e.g. overfitting ""type 1"" vs overfitting ""type 2"")",19,14
202,2017-11-5,2017,11,5,5,7at1xe,[Q] Is OCR a solved problem?,https://www.reddit.com/r/MachineLearning/comments/7at1xe/q_is_ocr_a_solved_problem/,orange_robot338,1509827008,[removed],0,1
203,2017-11-5,2017,11,5,5,7at6cu,Question about alphagozero evaluator settings,https://www.reddit.com/r/MachineLearning/comments/7at6cu/question_about_alphagozero_evaluator_settings/,[deleted],1509828278,[removed],0,1
204,2017-11-5,2017,11,5,5,7at9d0,[D] Detail question about alphago zero implementation,https://www.reddit.com/r/MachineLearning/comments/7at9d0/d_detail_question_about_alphago_zero/,narsilouu,1509829134,"Here is a extract from the original paper.

&gt; Evaluator. To ensure we always generate the best quality data, we evaluate each new neural network checkpoint against the current best network f before using it for data generation. The neural network fi is evaluated by the performance of an MCTS search i that uses fi to evaluate leaf positions and prior probabilities (see Search algorithm). Each evaluation consists of 400 games, using an MCTS with 1,600 simulations to select each move, using an infinitesimal temperature   0 (that is, we deterministically select the move with maximum visit count, to give the strongest possible play). If the new player wins by a margin of &gt; 55%  (to avoid selecting on noise alone) then it becomes the best player , and is subse-quently used for self-play generation, and also becomes the baseline for subsequent  comparisons.


If we use temperature = 0, the selection is deterministic. As I don't believe their is another source of randomness in the play algorithm, all 400 games should always be the same. Am I missing something and only the tested player plays deterministically while the Best model still plays with temperature=1 for the first 30 moves ?

I am trying to write an implementation to better understand how alphagozero works, and I don't understand how the players will play different games. ",7,4
205,2017-11-5,2017,11,5,7,7ato95,"Uber AI Labs Open Sources Pyro, a Deep Probabilistic Programming Language",https://www.reddit.com/r/MachineLearning/comments/7ato95/uber_ai_labs_open_sources_pyro_a_deep/,[deleted],1509833421,[deleted],0,1
206,2017-11-5,2017,11,5,7,7attqd,[D] Data augmentation theory,https://www.reddit.com/r/MachineLearning/comments/7attqd/d_data_augmentation_theory/,lightcatcher,1509835055,"I've been thinking about different types of data augmentation and am interested in pointers to related literature.

General data augmentation idea:
Given input-output pair (x, y), you can construct a new input x'=a(x) such that (x', y) is also a valid input-output pair using augmentation function a. As an example, if x is a picture, y says this is a picture of a cat, and x' is image x with the brightness increased.

Typical use of data augmentation during training:
Let f(x) be some differentiable function of input x and parameters theta that maps to space of y. Let L be a loss function. Rather than doing SGD only on L(y, f(x)), also do SGD on L(y, f(x')). Essentially, consider both (x, y) and (x', y) as entries in the dataset. At inference time, just compute f(x).

Data augmentation as constraint on function:
Let g(x) = [f(x) + f(a(x))] / 2. Train g and also use g at inference time. The use of g always enforces that g(x) = g(a(x)) so should help with generalization. Additionally, can be considered a type of ensembling if (y - f(x)) and (y - f(x')) aren't perfectly correlated.

Data augmentation as a regularizer:
The previous definition of g does not actually force f(x) to have a similar value to f(x'). This means f itself doesn't necessarily incorporate the prior knowledge that f(x) should be very similar (or identical) to f(x'). We could make f itself learn this relationship by adding penalty d(f(x), f(x')) for some loss d. I consider this a regularizer because adding this term cannot improve primary loss L(y, f(x)) or L(y, g(x)). Perhaps this term could f or g generalize better to unseen data.

Of course, all of these ideas could be applied to to multiple augmentation functions (besides just changing brightness, could also crop image or do something else).

Has there been any research into using data augmentation in these ways? I couldn't figure out quite what to Google. Given the simplicity of these ideas, my guess is they've been researched or at least used in Kaggle competitions. CNNs and spatial transformer nets come to mind as related ideas as those models are invariant to some types of augmentations and therefore would likely have little trouble minimizing the regularization penalty.",12,38
207,2017-11-5,2017,11,5,7,7attuv,Deep Learning for Structure Data?,https://www.reddit.com/r/MachineLearning/comments/7attuv/deep_learning_for_structure_data/,IBA___IBA,1509835097,[removed],0,1
208,2017-11-5,2017,11,5,7,7aty03,Getting an error while using `wmdistance` to install pyemd even though I just did,https://www.reddit.com/r/MachineLearning/comments/7aty03/getting_an_error_while_using_wmdistance_to/,madzthakz,1509836365,[removed],0,1
209,2017-11-5,2017,11,5,9,7aubm2,[P] plant image recognition implemented with mxnet/qt/qml on android,https://www.reddit.com/r/MachineLearning/comments/7aubm2/p_plant_image_recognition_implemented_with/,rechaptca,1509840514,"https://play.google.com/store/apps/details?id=pl.roslin.atlas.offline
https://github.com/mjamroz/PlantRecognition

not very fast, but working (at least on my phone). During first run it download network parameters to the phone, and since then user can take photos and recognize. ",0,1
210,2017-11-5,2017,11,5,9,7aukkt,Effect of kernel value on overfitting SVM?,https://www.reddit.com/r/MachineLearning/comments/7aukkt/effect_of_kernel_value_on_overfitting_svm/,yeswekhan,1509843146,[removed],0,1
211,2017-11-5,2017,11,5,12,7avebz,What makes one graduate school better than another for machine learning?,https://www.reddit.com/r/MachineLearning/comments/7avebz/what_makes_one_graduate_school_better_than/,Gridiron27,1509853111,[removed],0,1
212,2017-11-5,2017,11,5,13,7avntn,What are capsules networks?,https://www.reddit.com/r/MachineLearning/comments/7avntn/what_are_capsules_networks/,bonomono85,1509856669,[removed],0,1
213,2017-11-5,2017,11,5,13,7avoe6,Nice History of Hinton Interview by Andrew Ng,https://www.reddit.com/r/MachineLearning/comments/7avoe6/nice_history_of_hinton_interview_by_andrew_ng/,spaceanubis1,1509856910,,0,1
214,2017-11-5,2017,11,5,13,7avovu,Anyone heard of the riser dummy variable method?,https://www.reddit.com/r/MachineLearning/comments/7avovu/anyone_heard_of_the_riser_dummy_variable_method/,dsquant,1509857106,[removed],0,1
215,2017-11-5,2017,11,5,13,7avq4v,Great Overview of Deep Learning &amp; Robotics by Prof. Pieter Abbeel,https://www.reddit.com/r/MachineLearning/comments/7avq4v/great_overview_of_deep_learning_robotics_by_prof/,spaceanubis1,1509857604,,0,1
216,2017-11-5,2017,11,5,14,7avti7,"Fascinating quality/resolution/sharpness of images generated by GANs by this paper ""Progressive Growing of GANs for Improved Quality, Stability and Variation"" Medium article if you're TLDR: https://medium.com/towards-data-science/progressive-gans-new-training-trend-for-2018-c18cb0190239",https://www.reddit.com/r/MachineLearning/comments/7avti7/fascinating_qualityresolutionsharpness_of_images/,spaceanubis1,1509858932,,1,1
217,2017-11-5,2017,11,5,16,7awbh4,[R] Genetic Policy Optimization,https://www.reddit.com/r/MachineLearning/comments/7awbh4/r_genetic_policy_optimization/,hardmaru,1509866819,,2,11
218,2017-11-5,2017,11,5,17,7awjqj,"[R] Notable Projects, Papers, and Videos over the Last Month",https://www.reddit.com/r/MachineLearning/comments/7awjqj/r_notable_projects_papers_and_videos_over_the/,risig_sag,1509871369,,22,84
219,2017-11-5,2017,11,5,17,7awk5l,[R] [1710.10928] The loss surface and expressivity of deep convolutional neural networks (arxiv.org),https://www.reddit.com/r/MachineLearning/comments/7awk5l/r_171010928_the_loss_surface_and_expressivity_of/,alexchan123,1509871616,"""We analyze the expressiveness and loss surface of practical deep convolutional neural networks (CNNs) with shared weights and max pooling layers. We show that such CNNs produce linearly independent features at a ""wide"" layer which has more neurons than the number of training samples. This condition holds e.g. for the VGG network. Furthermore, we provide for such wide CNNs necessary and sufficient conditions for global minima with zero training error. For the case where the wide layer is followed by a fully connected layer, we show that almost every critical point of the empirical loss is a global minimum with zero training error. Our analysis suggests that both depth and width are very important in deep learning. While depth brings more representational power and allows the network to learn high level features, width smoothes the optimization landscape of the loss function in the sense that a sufficiently wide network has a well-behaved loss surface with potentially no bad local minima.""",1,9
220,2017-11-5,2017,11,5,19,7awybu,AlphaGo Zero - How and Why it Works,https://www.reddit.com/r/MachineLearning/comments/7awybu/alphago_zero_how_and_why_it_works/,based2,1509879161,,1,1
221,2017-11-5,2017,11,5,19,7awye9,Temporal difference learning,https://www.reddit.com/r/MachineLearning/comments/7awye9/temporal_difference_learning/,based2,1509879206,,0,1
222,2017-11-5,2017,11,5,20,7ax0sh,[D] Any Templates for Paper Review? [Reading Group],https://www.reddit.com/r/MachineLearning/comments/7ax0sh/d_any_templates_for_paper_review_reading_group/,risig_sag,1509880368,Let's collect here templates and/or guidance on how to structure a paper review at Reading Group,5,3
223,2017-11-5,2017,11,5,20,7ax0zy,[D] Large neural network architectures for policy gradient RL,https://www.reddit.com/r/MachineLearning/comments/7ax0zy/d_large_neural_network_architectures_for_policy/,_tomakko,1509880473,"All research papers that use either value-based, REINFORCE style or natural policy gradient updates seem to use rather small neural network architectures. They consist of no more than a few convolutional layers followed by one or two fully connected layers.

I am aware of ""old"" Alpha Go, where the policy network had a depth of 10+ layers, however it was initialized using supervised learning.

What do you think are the reasons why the neural networks used in reinforcement learning from scratch are rather small?
Are there any relaed works that i am overlooking?",9,12
224,2017-11-5,2017,11,5,20,7ax2zd,[P] An autoencoder architecture for optimal noisy signal encoding/decoding.,https://www.reddit.com/r/MachineLearning/comments/7ax2zd/p_an_autoencoder_architecture_for_optimal_noisy/,[deleted],1509881468,[deleted],0,1
225,2017-11-5,2017,11,5,20,7ax38t,[P] Optimal Noisy Signal Decoding/Transmission Implementation in PyTorch,https://www.reddit.com/r/MachineLearning/comments/7ax38t/p_optimal_noisy_signal_decodingtransmission/,[deleted],1509881588,[deleted],0,1
226,2017-11-5,2017,11,5,20,7ax3e5,[P] Optimal Noisy Signal Transmission Protocol Implementation in PyTorch,https://www.reddit.com/r/MachineLearning/comments/7ax3e5/p_optimal_noisy_signal_transmission_protocol/,[deleted],1509881650,[deleted],0,1
227,2017-11-5,2017,11,5,20,7ax3lt,"[P] PyTorch Implementation of ""Radio Transformer Networks""",https://www.reddit.com/r/MachineLearning/comments/7ax3lt/p_pytorch_implementation_of_radio_transformer/,gram-ai,1509881758,,2,5
228,2017-11-5,2017,11,5,21,7axcjc,{automatic fetch toys for Dogs,https://www.reddit.com/r/MachineLearning/comments/7axcjc/automatic_fetch_toys_for_dogs/,lovelen75,1509885889,,1,1
229,2017-11-5,2017,11,5,22,7axex9,Practical Machine Learning with R and Python  Part 5,https://www.reddit.com/r/MachineLearning/comments/7axex9/practical_machine_learning_with_r_and_python_part/,tvganesh,1509886882,,0,1
230,2017-11-5,2017,11,5,22,7axg9w,[D] How to train your network on streaming data,https://www.reddit.com/r/MachineLearning/comments/7axg9w/d_how_to_train_your_network_on_streaming_data/,treebranchleaf,1509887405,"Lets say I'm getting streaming data (x[t], y[t]), and I want to learn to minimize some loss L(f(x[t]), y[t]).  ie, my prediction f(x[t]) is only a function of the current input.  For now, lets say each (x[t], y[t]) is Independent and Identically distributed (though this obviously isn't the case with most streaming data - so we'd eventually like to relax this).

Let's further suppose that I don't have the memory to store all these (x, y) pairs into a big dataset so that I can shuffle them and train offline later.  So I can only use each data point to update my parameters only once.

What's the best way to do this?  Should I converge to a minimum of my loss on every data point?  

Is there a clear answer to this or can someone point to relevant work on the topic?

**Edit**.  I should clarify what I mean by ""best"".  Suppose training is stopped at any given time t, and we measure our loss on some test set of new samples (x[t+1], y[t+1])... (x[t+T], y[t+T]).  By ""the best"" way to do this, I mean ""the way that minimizes this test loss as fast as possible with respect to t - the number of training examples seen so far"".",17,17
231,2017-11-5,2017,11,5,23,7axt64,[N] Is Deep Learning Innovation Just Due to Brute Force?,https://www.reddit.com/r/MachineLearning/comments/7axt64/n_is_deep_learning_innovation_just_due_to_brute/,visarga,1509891849,,12,0
232,2017-11-5,2017,11,5,23,7axu0f,"[P] A neural chatbot using sequence to sequence model with attentional decoder implements by Tensorflow 1.4 version (Estimator, Experiment, Dataset)",https://www.reddit.com/r/MachineLearning/comments/7axu0f/p_a_neural_chatbot_using_sequence_to_sequence/,DongjunLee,1509892106,,9,29
233,2017-11-5,2017,11,5,23,7axwe4,Are Giant Tech Firms Killing Research and Academia in Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/7axwe4/are_giant_tech_firms_killing_research_and/,t-sploit,1509892876,,0,1
234,2017-11-6,2017,11,6,1,7ayoud,[R] [1711.00648] Data Augmentation in Classification using GAN,https://www.reddit.com/r/MachineLearning/comments/7ayoud/r_171100648_data_augmentation_in_classification/,Slyferr,1509900946,,5,9
235,2017-11-6,2017,11,6,1,7ayper,Best way to learn maths behind the algorithms?,https://www.reddit.com/r/MachineLearning/comments/7ayper/best_way_to_learn_maths_behind_the_algorithms/,AnkitSati,1509901098,[removed],0,1
236,2017-11-6,2017,11,6,2,7ayq0l,Optimal file format for developing a database,https://www.reddit.com/r/MachineLearning/comments/7ayq0l/optimal_file_format_for_developing_a_database/,[deleted],1509901258,[removed],0,1
237,2017-11-6,2017,11,6,2,7ays7r,[P] Using Deep Learning for Single Image Super Resolution (with a live demo),https://www.reddit.com/r/MachineLearning/comments/7ays7r/p_using_deep_learning_for_single_image_super/,kkanska,1509901823,,24,161
238,2017-11-6,2017,11,6,2,7az1em,Hetelek  Jupyter Notebooks in the cloud (on powerful GPUs)!,https://www.reddit.com/r/MachineLearning/comments/7az1em/hetelek_jupyter_notebooks_in_the_cloud_on/,hetelek_,1509904207,,0,1
239,2017-11-6,2017,11,6,2,7az1r2,Is scaling the gradient equivalent to scaling the learning rate when using Adam or RMSProp?,https://www.reddit.com/r/MachineLearning/comments/7az1r2/is_scaling_the_gradient_equivalent_to_scaling_the/,[deleted],1509904306,[removed],0,1
240,2017-11-6,2017,11,6,2,7az1y8,[D] Is scaling the gradient equivalent to scaling the learning rate when using Adam or RMSProp?,https://www.reddit.com/r/MachineLearning/comments/7az1y8/d_is_scaling_the_gradient_equivalent_to_scaling/,danijar,1509904351,[removed],11,2
241,2017-11-6,2017,11,6,3,7az3ms,Are the any scholarships/bursaries available for the Udacity Self Driving Car NanoDegree program?,https://www.reddit.com/r/MachineLearning/comments/7az3ms/are_the_any_scholarshipsbursaries_available_for/,Enigma_101,1509904813,[removed],0,1
242,2017-11-6,2017,11,6,3,7az57v,How patient are you when you train?,https://www.reddit.com/r/MachineLearning/comments/7az57v/how_patient_are_you_when_you_train/,Simusid,1509905219,[removed],0,1
243,2017-11-6,2017,11,6,3,7az788,Can anyone Help me to predict gender from this dataset ?? I've tried but i failed to solve the problem !,https://www.reddit.com/r/MachineLearning/comments/7az788/can_anyone_help_me_to_predict_gender_from_this/,Slowma,1509905764,[removed],0,1
244,2017-11-6,2017,11,6,3,7azc4i,Bias in Algorithm Models,https://www.reddit.com/r/MachineLearning/comments/7azc4i/bias_in_algorithm_models/,butternutv2,1509906934,[removed],0,1
245,2017-11-6,2017,11,6,4,7azoqz,Bias in Algorithms Model,https://www.reddit.com/r/MachineLearning/comments/7azoqz/bias_in_algorithms_model/,butternutv2,1509910099,[removed],0,1
246,2017-11-6,2017,11,6,5,7b07yl,"Learn fast, otherwise your junior will become your senior.",https://www.reddit.com/r/MachineLearning/comments/7b07yl/learn_fast_otherwise_your_junior_will_become_your/,ArchTerror,1509914847,,0,1
247,2017-11-6,2017,11,6,6,7b0av0,[D] Machine Learning - WAYR (What Are You Reading) - Week 35,https://www.reddit.com/r/MachineLearning/comments/7b0av0/d_machine_learning_wayr_what_are_you_reading_week/,ML_WAYR_bot,1509915612,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|31-40|
|----|-----|-----|-----|
|[Week 1](https://www.reddit.com/r/MachineLearning/comments/4qyjiq/machine_learning_wayr_what_are_you_reading_week_1/)|[Week 11](https://www.reddit.com/r/MachineLearning/comments/57xw56/discussion_machine_learning_wayr_what_are_you/)|[Week 21](https://www.reddit.com/r/MachineLearning/comments/60ildf/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 31](https://www.reddit.com/r/MachineLearning/comments/6s0k1u/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 2](https://www.reddit.com/r/MachineLearning/comments/4s2xqm/machine_learning_wayr_what_are_you_reading_week_2/)|[Week 12](https://www.reddit.com/r/MachineLearning/comments/5acb1t/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 22](https://www.reddit.com/r/MachineLearning/comments/64jwde/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 32](https://www.reddit.com/r/MachineLearning/comments/72ab5y/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 3](https://www.reddit.com/r/MachineLearning/comments/4t7mqm/machine_learning_wayr_what_are_you_reading_week_3/)|[Week 13](https://www.reddit.com/r/MachineLearning/comments/5cwfb6/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 23](https://www.reddit.com/r/MachineLearning/comments/674331/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 33](https://www.reddit.com/r/MachineLearning/comments/75405d/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 4](https://www.reddit.com/r/MachineLearning/comments/4ub2kw/machine_learning_wayr_what_are_you_reading_week_4/)|[Week 14](https://www.reddit.com/r/MachineLearning/comments/5fc5mh/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 24](https://www.reddit.com/r/MachineLearning/comments/68hhhb/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 34](https://www.reddit.com/r/MachineLearning/comments/782js9/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 5](https://www.reddit.com/r/MachineLearning/comments/4xomf7/machine_learning_wayr_what_are_you_reading_week_5/)|[Week 15](https://www.reddit.com/r/MachineLearning/comments/5hy4ur/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 25](https://www.reddit.com/r/MachineLearning/comments/69teiz/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 6](https://www.reddit.com/r/MachineLearning/comments/4zcyvk/machine_learning_wayr_what_are_you_reading_week_6/)|[Week 16](https://www.reddit.com/r/MachineLearning/comments/5kd6vd/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 26](https://www.reddit.com/r/MachineLearning/comments/6d7nb1/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 7](https://www.reddit.com/r/MachineLearning/comments/52t6mo/machine_learning_wayr_what_are_you_reading_week_7/)|[Week 17](https://www.reddit.com/r/MachineLearning/comments/5ob7dx/discussion_machine_learning_wayr_what_are_you/)|[Week 27](https://www.reddit.com/r/MachineLearning/comments/6gngwc/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 8](https://www.reddit.com/r/MachineLearning/comments/53heol/machine_learning_wayr_what_are_you_reading_week_8/)|[Week 18](https://www.reddit.com/r/MachineLearning/comments/5r14yd/discussion_machine_learning_wayr_what_are_you/)|[Week 28](https://www.reddit.com/r/MachineLearning/comments/6jgdva/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 9](https://www.reddit.com/r/MachineLearning/comments/54kvsu/machine_learning_wayr_what_are_you_reading_week_9/)|[Week 19](https://www.reddit.com/r/MachineLearning/comments/5tt9cz/discussion_machine_learning_wayr_what_are_you/)|[Week 29](https://www.reddit.com/r/MachineLearning/comments/6m9l1v/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 10](https://www.reddit.com/r/MachineLearning/comments/56s2oa/discussion_machine_learning_wayr_what_are_you/)|[Week 20](https://www.reddit.com/r/MachineLearning/comments/5wh2wb/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 30](https://www.reddit.com/r/MachineLearning/comments/6p3ha7/d_machine_learning_wayr_what_are_you_reading_week/)||

Most upvoted papers two weeks ago:

/u/alexbhandari: https://www.nature.com/nature/journal/v550/n7676/full/nature24270.html

/u/hlynurd: http://ccr.sigcomm.org/online/files/p83-keshavA.pdf

/u/cfusting: http://eplex.cs.ucf.edu/papers/morse_gecco16.pdf

Besides that, there are no rules, have fun.",25,17
248,2017-11-6,2017,11,6,6,7b0knt,Grad-CAM++: Generalized Gradient-based Visual Explanations for Deep Convolutional Networks,https://www.reddit.com/r/MachineLearning/comments/7b0knt/gradcam_generalized_gradientbased_visual/,prantikbubun,1509918250,[removed],0,1
249,2017-11-6,2017,11,6,6,7b0n27,Grad-CAM++: Generalized Gradient-based Visual Explanations for Deep Convolutional Network,https://www.reddit.com/r/MachineLearning/comments/7b0n27/gradcam_generalized_gradientbased_visual/,prantikbubun,1509918875,,0,1
250,2017-11-6,2017,11,6,7,7b0vdh,Question on Feature Engineering - a structure to depth and levels?,https://www.reddit.com/r/MachineLearning/comments/7b0vdh/question_on_feature_engineering_a_structure_to/,[deleted],1509921189,[removed],0,1
251,2017-11-6,2017,11,6,9,7b1m2y,How to implement edge pruning with for loop?,https://www.reddit.com/r/MachineLearning/comments/7b1m2y/how_to_implement_edge_pruning_with_for_loop/,[deleted],1509928652,[removed],0,1
252,2017-11-6,2017,11,6,9,7b1ocm,How do you implement edge pruning with for loop?,https://www.reddit.com/r/MachineLearning/comments/7b1ocm/how_do_you_implement_edge_pruning_with_for_loop/,hoomanlearning,1509929289,[removed],0,1
253,2017-11-6,2017,11,6,10,7b1zig,"How can I ""estimate the polarity"" of a guess in a pickled machine learning model in scikit-learn? Is there any way to extract a probability distribution for a test example for each label in a supervised model?",https://www.reddit.com/r/MachineLearning/comments/7b1zig/how_can_i_estimate_the_polarity_of_a_guess_in_a/,fosofyowq,1509932509,[removed],0,1
254,2017-11-6,2017,11,6,11,7b2eoi,"[D] Classifying forms with many unrelated labels, asking too much of an ML model?",https://www.reddit.com/r/MachineLearning/comments/7b2eoi/d_classifying_forms_with_many_unrelated_labels/,GreenHeadphonejack,1509937144,"I've been put on a project to classify forms which have historically been labeled manually. Forms are submitted by people and multiple forms can be submitted over time. I'd like to understand a few things: 

&amp;nbsp;

1) How do I know what kind of labeling is possible? (examples below)
2) Is this a problem for deep learning?
3) Are there papers that I should read up on to familiarize myself with techniques and data preprocessing for this kind of task?

&amp;nbsp;

The project has a lot of historical data, but it also has many fields that the human considers when applying a label. Some example field considerations include: categories mismatching in two fields, date ranges out of sync between two fields, price values that do not add up in two fields. There are also more complicated consideration which I cannot yet comprehend how I would engineer features out of such as: forms being very similar to past submitted forms (ie duplicates) based on similar dates or values. So, humans would apply labels such as ""duplicate, due to X/Y/Z"", or ""field A category is not applicable to field B category"", or ""value in field A,B do not match value in field C"".

&amp;nbsp;

I _believe_ this is an ML task because they have people doing this, but noone has taken the time to write up specific rules to do this task. The domain of data is pretty much limited to the form, or forms historically submitted by the same person. But at the same time, it seems like a lot of features need to be set up relationally/manually and this feels like maybe an ML approach is not the right way. Referencing the end of the last paragraph, would I need to feed in features such as ""C-(A+B)"", and how could I feed in historical form data?

&amp;nbsp;

Does this make sense? Am I able to train an algorithm to accomplish what I'm looking for?",13,5
255,2017-11-6,2017,11,6,12,7b2k4y,[P] iris - deployable machine learning notebooks,https://www.reddit.com/r/MachineLearning/comments/7b2k4y/p_iris_deployable_machine_learning_notebooks/,iris-team,1509938842,,6,5
256,2017-11-6,2017,11,6,12,7b2npu,"So, what is state of the art these days for detecting objects in images.",https://www.reddit.com/r/MachineLearning/comments/7b2npu/so_what_is_state_of_the_art_these_days_for/,dethpicable,1509940001,[removed],0,1
257,2017-11-6,2017,11,6,12,7b2q3j,[FEEDBACK Request] My Data Science Article,https://www.reddit.com/r/MachineLearning/comments/7b2q3j/feedback_request_my_data_science_article/,randylaosat,1509940757,[removed],0,1
258,2017-11-6,2017,11,6,13,7b2xyv,[R] [1711.00937] Neural Discrete Representation Learning (Vector Quantised-Variational AutoEncoder),https://www.reddit.com/r/MachineLearning/comments/7b2xyv/r_171100937_neural_discrete_representation/,alito,1509943416,,37,59
259,2017-11-6,2017,11,6,15,7b3cao,Python code for 3D face modeling from single image using our very deep neural network,https://www.reddit.com/r/MachineLearning/comments/7b3cao/python_code_for_3d_face_modeling_from_single/,theredknight,1509948622,,0,1
260,2017-11-6,2017,11,6,15,7b3d98,Evaluating Discourse Phenomena in Neural Machine Translation,https://www.reddit.com/r/MachineLearning/comments/7b3d98/evaluating_discourse_phenomena_in_neural_machine/,adammathias,1509948962,,0,1
261,2017-11-6,2017,11,6,17,7b3u6e,3D Face Reconstruction Applied to Art,https://www.reddit.com/r/MachineLearning/comments/7b3u6e/3d_face_reconstruction_applied_to_art/,[deleted],1509955977,[deleted],0,1
262,2017-11-6,2017,11,6,17,7b3x1z,Conical Pizza Making Machine with low cost in Hot Selling,https://www.reddit.com/r/MachineLearning/comments/7b3x1z/conical_pizza_making_machine_with_low_cost_in_hot/,liusherry,1509957328,,1,1
263,2017-11-6,2017,11,6,17,7b3yvd,How to extract optical flows from videos using gpu?,https://www.reddit.com/r/MachineLearning/comments/7b3yvd/how_to_extract_optical_flows_from_videos_using_gpu/,bucktoothsir,1509958197,[removed],0,1
264,2017-11-6,2017,11,6,18,7b41zm,Grain Milling Machine | Wheat Milling Machine | Flour Making Machine,https://www.reddit.com/r/MachineLearning/comments/7b41zm/grain_milling_machine_wheat_milling_machine_flour/,liusherry,1509959622,,1,1
265,2017-11-6,2017,11,6,18,7b44fz,"""I Pity the fool"", Deep Learning style",https://www.reddit.com/r/MachineLearning/comments/7b44fz/i_pity_the_fool_deep_learning_style/,rragundez,1509960730,,0,1
266,2017-11-6,2017,11,6,18,7b45ow,[P] deeplearn.js,https://www.reddit.com/r/MachineLearning/comments/7b45ow/p_deeplearnjs/,pmigdal,1509961336,,7,56
267,2017-11-6,2017,11,6,19,7b4eei,How can we count number of cars in a video?,https://www.reddit.com/r/MachineLearning/comments/7b4eei/how_can_we_count_number_of_cars_in_a_video/,kareemk9,1509965192,[removed],0,1
268,2017-11-6,2017,11,6,19,7b4emt,Training a Neural Network using WebAssembly,https://www.reddit.com/r/MachineLearning/comments/7b4emt/training_a_neural_network_using_webassembly/,[deleted],1509965307,[deleted],0,1
269,2017-11-6,2017,11,6,19,7b4ffc,[R] Compressing Word Embeddings via Deep Compositional Code Learning,https://www.reddit.com/r/MachineLearning/comments/7b4ffc/r_compressing_word_embeddings_via_deep/,ofirpress,1509965662,,2,16
270,2017-11-6,2017,11,6,19,7b4fi1,What should I learn after Artificial Intelligence Nanodegree?,https://www.reddit.com/r/MachineLearning/comments/7b4fi1/what_should_i_learn_after_artificial_intelligence/,sriramjaju,1509965694,[removed],0,1
271,2017-11-6,2017,11,6,19,7b4fm1,[P] GAN Playground  Play with Generative Adversarial Neural Nets In-Browser,https://www.reddit.com/r/MachineLearning/comments/7b4fm1/p_gan_playground_play_with_generative_adversarial/,pmigdal,1509965743,,2,36
272,2017-11-6,2017,11,6,20,7b4hbd,Sixth Sense  The Role of Machine Learning &amp; AI in Prediction and Beyond,https://www.reddit.com/r/MachineLearning/comments/7b4hbd/sixth_sense_the_role_of_machine_learning_ai_in/,DMI2002,1509966462,,1,1
273,2017-11-6,2017,11,6,20,7b4i99,Why Machine Learning is Required  Are You Ready to Get a Job With Intelligent Machines?,https://www.reddit.com/r/MachineLearning/comments/7b4i99/why_machine_learning_is_required_are_you_ready_to/,Airben23,1509966866,,0,1
274,2017-11-6,2017,11,6,20,7b4o59,"Global Fruit and Vegetable Processing Equipment Market Share Analysis, Trends and Competitor Analysis",https://www.reddit.com/r/MachineLearning/comments/7b4o59/global_fruit_and_vegetable_processing_equipment/,mariasmith16,1509969383,,0,1
275,2017-11-6,2017,11,6,21,7b4uru,Calling all AI users to participate in survey on AI morality: user corruption and abuse,https://www.reddit.com/r/MachineLearning/comments/7b4uru/calling_all_ai_users_to_participate_in_survey_on/,jorimogunje,1509971738,[removed],0,1
276,2017-11-7,2017,11,7,0,7b5poi,"[D] Top articles in data in October, handpicked with love by data scientists",https://www.reddit.com/r/MachineLearning/comments/7b5poi/d_top_articles_in_data_in_october_handpicked_with/,[deleted],1509981065,[deleted],1,1
277,2017-11-7,2017,11,7,0,7b5ve5,A bit-by-bit guide to the equations governing differentiable neural computers,https://www.reddit.com/r/MachineLearning/comments/7b5ve5/a_bitbybit_guide_to_the_equations_governing/,atzur,1509982539,,0,1
278,2017-11-7,2017,11,7,1,7b625a,[D] Some questions about genetic algorithms and language performance,https://www.reddit.com/r/MachineLearning/comments/7b625a/d_some_questions_about_genetic_algorithms_and/,[deleted],1509984215,[deleted],0,0
279,2017-11-7,2017,11,7,1,7b640e,Black Mirror episode remake in China,https://www.reddit.com/r/MachineLearning/comments/7b640e/black_mirror_episode_remake_in_china/,[deleted],1509984681,[deleted],0,1
280,2017-11-7,2017,11,7,1,7b64nc,An app that finds NSFW photos on your phone,https://www.reddit.com/r/MachineLearning/comments/7b64nc/an_app_that_finds_nsfw_photos_on_your_phone/,OrgaHenry,1509984837,[removed],0,1
281,2017-11-7,2017,11,7,1,7b64oc,October articles on deep learning and data processing picked by data scientists,https://www.reddit.com/r/MachineLearning/comments/7b64oc/october_articles_on_deep_learning_and_data/,[deleted],1509984844,[deleted],0,1
282,2017-11-7,2017,11,7,1,7b656t,[D] October articles on deep learning and data processing picked by data scientists,https://www.reddit.com/r/MachineLearning/comments/7b656t/d_october_articles_on_deep_learning_and_data/,[deleted],1509984972,[deleted],1,1
283,2017-11-7,2017,11,7,1,7b6685,Classifying Trends in the Cryptocurrency markets through ML,https://www.reddit.com/r/MachineLearning/comments/7b6685/classifying_trends_in_the_cryptocurrency_markets/,rdbacon,1509985228,[removed],0,1
284,2017-11-7,2017,11,7,1,7b6a2u,[Data augmentation] Generating out-of-manifold data to improve generalization,https://www.reddit.com/r/MachineLearning/comments/7b6a2u/data_augmentation_generating_outofmanifold_data/,datatatatata,1509986202,[removed],1,1
285,2017-11-7,2017,11,7,2,7b6pkq,[D] A Reference Stack for Modern Data Science,https://www.reddit.com/r/MachineLearning/comments/7b6pkq/d_a_reference_stack_for_modern_data_science/,adamwfletcher,1509989854,,2,2
286,2017-11-7,2017,11,7,3,7b6vj9,[News] Writing extendable and hardware agnostic GPU libraries,https://www.reddit.com/r/MachineLearning/comments/7b6vj9/news_writing_extendable_and_hardware_agnostic_gpu/,Eigenspace,1509991315,,0,22
287,2017-11-7,2017,11,7,3,7b6x9s,[D] Can GANs be used for dataset augmentation?,https://www.reddit.com/r/MachineLearning/comments/7b6x9s/d_can_gans_be_used_for_dataset_augmentation/,[deleted],1509991698,[deleted],8,2
288,2017-11-7,2017,11,7,4,7b7d6a,Is conditional GAN better than normal GAN?,https://www.reddit.com/r/MachineLearning/comments/7b7d6a/is_conditional_gan_better_than_normal_gan/,vic4ever,1509995538,[removed],0,1
289,2017-11-7,2017,11,7,4,7b7g63,[P] My submission for NIPS 2017 workshop on Machine Learning for Creativity and Design - Avant-garding-Raja-Ravi-Varma,https://www.reddit.com/r/MachineLearning/comments/7b7g63/p_my_submission_for_nips_2017_workshop_on_machine/,VinayUPrabhu,1509996263,,2,5
290,2017-11-7,2017,11,7,4,7b7ghl,"[P] I trained a RNN to play Super Mario Kart, human-style",https://www.reddit.com/r/MachineLearning/comments/7b7ghl/p_i_trained_a_rnn_to_play_super_mario_kart/,SethBling,1509996341,,78,833
291,2017-11-7,2017,11,7,4,7b7kxv,"Tenure and Tenure -Track Positions in Machine Learning, University of Texas at San Antonio",https://www.reddit.com/r/MachineLearning/comments/7b7kxv/tenure_and_tenure_track_positions_in_machine/,dakopian,1509997381,[removed],0,1
292,2017-11-7,2017,11,7,4,7b7l2t,Self driving car companies should train their AIs in simulated video game environments,https://www.reddit.com/r/MachineLearning/comments/7b7l2t/self_driving_car_companies_should_train_their_ais/,to_the_sun,1509997416,[removed],0,1
293,2017-11-7,2017,11,7,4,7b7ltp,[D] Can't a fully connect layer replace dynamic routing?,https://www.reddit.com/r/MachineLearning/comments/7b7ltp/d_cant_a_fully_connect_layer_replace_dynamic/,idg101,1509997604,"Reference Dynamic Routing Between Capsules.  It seems that each capsule output (which is a vector) is essentially its activation vector of each convolution layer in the capsule.  Thus, wouldn't a simple convolution layer with the filters equal to the total number of convolutions in all the capsules represent the same data?  If this is true, then I would image that the routing is essentially taking subsets of those outputs (in the num features dimension) and routing them based on the dot product scale.  I would assume that this is essentially what a fully connected network would do with flattened inputs from the convolutions.  ",5,14
294,2017-11-7,2017,11,7,6,7b89zs,"What's the best mid-range hardware for deep learning? What to expect from Xeon Phi, TPU &amp; AMD in '18?",https://www.reddit.com/r/MachineLearning/comments/7b89zs/whats_the_best_midrange_hardware_for_deep/,fogbugz,1510003317,[removed],0,1
295,2017-11-7,2017,11,7,6,7b8ed3,[research] Handbag Brand and Color Detection at Cond Nast,https://www.reddit.com/r/MachineLearning/comments/7b8ed3/research_handbag_brand_and_color_detection_at/,L_237,1510004389,,0,6
296,2017-11-7,2017,11,7,6,7b8gk4,[P] Tangent: Source-to-Source Debuggable Derivatives,https://www.reddit.com/r/MachineLearning/comments/7b8gk4/p_tangent_sourcetosource_debuggable_derivatives/,hardmaru,1510004920,,36,51
297,2017-11-7,2017,11,7,6,7b8ih5,Looking for collaborator,https://www.reddit.com/r/MachineLearning/comments/7b8ih5/looking_for_collaborator/,aletote,1510005382,[removed],0,1
298,2017-11-7,2017,11,7,7,7b8n2m,What would a self-learning circuit be like?,https://www.reddit.com/r/MachineLearning/comments/7b8n2m/what_would_a_selflearning_circuit_be_like/,vnjxk,1510006526,[removed],0,1
299,2017-11-7,2017,11,7,9,7b9fdb,Finding the theoretical best performance of Machine Learning algorithms,https://www.reddit.com/r/MachineLearning/comments/7b9fdb/finding_the_theoretical_best_performance_of/,Turings_Ego,1510013953,[removed],0,1
300,2017-11-7,2017,11,7,9,7b9ncb,Can inference in the data space be justified with bayesian probability?,https://www.reddit.com/r/MachineLearning/comments/7b9ncb/can_inference_in_the_data_space_be_justified_with/,rd34t5,1510016179,[removed],0,1
301,2017-11-7,2017,11,7,10,7b9oje,[N] Pieter Abbeel and others leave OpenAI to begin robotics start-up,https://www.reddit.com/r/MachineLearning/comments/7b9oje/n_pieter_abbeel_and_others_leave_openai_to_begin/,wei_jok,1510016512,,10,40
302,2017-11-7,2017,11,7,10,7b9qj0,[Google Research] Tangent: Source-to-Source Debuggable Derivatives in Pure Python,https://www.reddit.com/r/MachineLearning/comments/7b9qj0/google_research_tangent_sourcetosource_debuggable/,activatedgeek,1510017074,,3,1
303,2017-11-7,2017,11,7,10,7b9ubh,Bentonite fertilizer granulator machine,https://www.reddit.com/r/MachineLearning/comments/7b9ubh/bentonite_fertilizer_granulator_machine/,amylee516,1510018174,,0,1
304,2017-11-7,2017,11,7,10,7b9yxp,[D] BTC Mining Motherboard for machine learning,https://www.reddit.com/r/MachineLearning/comments/7b9yxp/d_btc_mining_motherboard_for_machine_learning/,llj098,1510019509,"Hi All, 

I want to build a 8 card machine learning work station. Can I use a BTC mining motherboard, such as [1] to serve 8 TITAN XP card? I'm worried about the 1X PCIe will make the training speed slow....


Thanks.



[1]: http://www.asrock.com/MB/Intel/H110%20Pro%20BTC+/index.asp 

",11,1
305,2017-11-7,2017,11,7,11,7ba3yx,Appying Data Clustering with K-Means,https://www.reddit.com/r/MachineLearning/comments/7ba3yx/appying_data_clustering_with_kmeans/,christopherj_320,1510020916,,0,1
306,2017-11-7,2017,11,7,12,7baf9e,Could machine learning be used to predict where the next American mass shooting will take place?,https://www.reddit.com/r/MachineLearning/comments/7baf9e/could_machine_learning_be_used_to_predict_where/,Self_Improving_C,1510024185,[removed],0,1
307,2017-11-7,2017,11,7,12,7bammo,YouTube,https://www.reddit.com/r/MachineLearning/comments/7bammo/youtube/,emmyesandelinaw,1510026416,,0,1
308,2017-11-7,2017,11,7,12,7baof5,[P] I implemented a Q Learning agent to solve Lunar Lander in 1 Hour on CPU.,https://www.reddit.com/r/MachineLearning/comments/7baof5/p_i_implemented_a_q_learning_agent_to_solve_lunar/,FitMachineLearning,1510026983,,13,29
309,2017-11-7,2017,11,7,13,7baydc,[D] Physicist in /r/MachineLearning.,https://www.reddit.com/r/MachineLearning/comments/7baydc/d_physicist_in_rmachinelearning/,hareyakana,1510030115,"I am wondering is there any physicist that lurks around in ML subreddit, particularly Particle physicist. I am aware LHC itself have a a group that dedicate themselves to implementing ML techniques in physics but would love to know people beyond that. I am also curious the work physicist that lurks around here.

Since ML technique in general are quite a niche application in various sub-fields in physics, I wonder how big is of a community there is around in physics itself, sub-field wise.",14,11
310,2017-11-7,2017,11,7,14,7bb0fy,Reading data with tensorflow,https://www.reddit.com/r/MachineLearning/comments/7bb0fy/reading_data_with_tensorflow/,mosslaugh,1510030816,,0,1
311,2017-11-7,2017,11,7,16,7bbr3g,Bamboo Toothpick Production Line|Bamboo Toothpick Making Machine Price,https://www.reddit.com/r/MachineLearning/comments/7bbr3g/bamboo_toothpick_production_linebamboo_toothpick/,tinawangsnow,1510040919,,1,1
312,2017-11-7,2017,11,7,17,7bbtw1,"[R] Fraternal Dropout by Zona, Arpit , Suhubdy &amp; Yoshua Bengio",https://www.reddit.com/r/MachineLearning/comments/7bbtw1/r_fraternal_dropout_by_zona_arpit_suhubdy_yoshua/,rishabh135,1510042186,,6,3
313,2017-11-7,2017,11,7,18,7bc1aq,Where to publish reasonable article in Deep Reinforcement Learning?,https://www.reddit.com/r/MachineLearning/comments/7bc1aq/where_to_publish_reasonable_article_in_deep/,evaldsurtans,1510045564,[removed],0,1
314,2017-11-7,2017,11,7,18,7bc4z7,"Found a link in my ML course book on how machine learning is closely related to the eld of statistics, but differs slightly in terms of its emphasis and terminology. By Rob Tibshirani, a statistician at Stanford university",https://www.reddit.com/r/MachineLearning/comments/7bc4z7/found_a_link_in_my_ml_course_book_on_how_machine/,codefinbel,1510047214,,0,1
315,2017-11-7,2017,11,7,18,7bc6y6,30 Things Everyone Should Know About Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7bc6y6/30_things_everyone_should_know_about_machine/,favouriteblog,1510048149,,1,1
316,2017-11-7,2017,11,7,18,7bc8de,[D] Is there a connection between the number of units in a Dense layer and the number of class outputs in a Logits layer?,https://www.reddit.com/r/MachineLearning/comments/7bc8de/d_is_there_a_connection_between_the_number_of/,FantasyBorderline,1510048794,"I have a Gender Recognition CNN model I made in Tensorflow that is... relatively successful, and by that I mean achieving relatively the same accuracy in live testing as in the eval phase (I test with a live camera preview). The accuracy itself is not too high - 76-80% - I trained the model with four folds of the Adience dataset.

I followed [this paper](https://pdfs.semanticscholar.org/d0eb/3fd1b1750242f3bb39ce9ac27fc8cc7c5af0.pdf), and replicated one of the models (labeled 'I') depicted in page 5 in Tensorflow.

The thing is, the paper had models labeled E to M, and the only thing different between them is the Dense layer's unit number. In my Tensorflow model, the flattened output of the pooling layer to be put into the Dense layer was 8*8*64, and I only have two output classes.

Is there a correlation between the Dense layer's unit number and the output classes? Are they supposed to be proportional to each other? Because I intend to use the same model for age prediction (with the 8 classes from Adience's dataset), except with 64 Dense units.",1,3
317,2017-11-7,2017,11,7,19,7bcae7,Banana chips making machine| Plantain chips production line,https://www.reddit.com/r/MachineLearning/comments/7bcae7/banana_chips_making_machine_plantain_chips/,liusherry,1510049647,,1,1
318,2017-11-7,2017,11,7,19,7bcf98,"Fully Integrated IoT Platform, made for Machine Learning. This Kickstarter campaign raised $10,000 in just 5 hours. Offers WiFi Module, Mobile Apps, and an IoT Cloud with lifetime access",https://www.reddit.com/r/MachineLearning/comments/7bcf98/fully_integrated_iot_platform_made_for_machine/,ppv999,1510051739,,0,1
319,2017-11-7,2017,11,7,20,7bcidi,button hole machine tutorial part 1 (HE-800B emergency switch disassemble),https://www.reddit.com/r/MachineLearning/comments/7bcidi/button_hole_machine_tutorial_part_1_he800b/,ismcloudbd,1510053008,,0,1
320,2017-11-7,2017,11,7,20,7bckyu,[D] Is conditional GAN better than traditional GAN?,https://www.reddit.com/r/MachineLearning/comments/7bckyu/d_is_conditional_gan_better_than_traditional_gan/,vic4ever,1510054089,"As conditional GAN leverages more information (the classes of the images), is it safe to assume that it is better? For instance, StackGAN learns from both images and image descriptions which may allow it to generate photorealistic results.
",3,4
321,2017-11-7,2017,11,7,20,7bclhz,[R]Bug-repair system learns from example,https://www.reddit.com/r/MachineLearning/comments/7bclhz/rbugrepair_system_learns_from_example/,trumtra,1510054318,,0,1
322,2017-11-7,2017,11,7,20,7bcowb,I'm sick of this shit,https://www.reddit.com/r/MachineLearning/comments/7bcowb/im_sick_of_this_shit/,torvoraptor,1510055702,[removed],0,1
323,2017-11-7,2017,11,7,21,7bcva1,[R] [1702.08720] Learning Discrete Representations via Information Maximizing Self-Augmented Training - unsupervised MNIST 98.4% accuracy,https://www.reddit.com/r/MachineLearning/comments/7bcva1/r_170208720_learning_discrete_representations_via/,Britefury,1510057965,,5,57
324,2017-11-7,2017,11,7,21,7bcw2m,Building a deep learning rig vs AWS,https://www.reddit.com/r/MachineLearning/comments/7bcw2m/building_a_deep_learning_rig_vs_aws/,karanbansal,1510058247,[removed],0,1
325,2017-11-7,2017,11,7,22,7bd790,"Introducing Juggernaut: a neural net that trains models from the browser with no JS, no servers",https://www.reddit.com/r/MachineLearning/comments/7bd790/introducing_juggernaut_a_neural_net_that_trains/,[deleted],1510061836,[deleted],0,1
326,2017-11-7,2017,11,7,23,7bddcg,"[P] Introducing Juggernaut: a neural net that trains models from the browser with no JS, no servers",https://www.reddit.com/r/MachineLearning/comments/7bddcg/p_introducing_juggernaut_a_neural_net_that_trains/,aylienwill,1510063645,,11,9
327,2017-11-7,2017,11,7,23,7bddog,Neural Discrete Representation Learning,https://www.reddit.com/r/MachineLearning/comments/7bddog/neural_discrete_representation_learning/,breandan,1510063737,,0,1
328,2017-11-7,2017,11,7,23,7bde4g,"Top articles in data in October, handpicked with love by data scientists",https://www.reddit.com/r/MachineLearning/comments/7bde4g/top_articles_in_data_in_october_handpicked_with/,fl4v1,1510063865,,0,1
329,2017-11-7,2017,11,7,23,7bdg16,How is Machine Learning Being Applied to Cybersecurity?,https://www.reddit.com/r/MachineLearning/comments/7bdg16/how_is_machine_learning_being_applied_to/,WinglessIndependence,1510064375,,0,1
330,2017-11-7,2017,11,7,23,7bdi5j,Machine learning and OCR project,https://www.reddit.com/r/MachineLearning/comments/7bdi5j/machine_learning_and_ocr_project/,Gillas_01,1510064973,[removed],0,1
331,2017-11-7,2017,11,7,23,7bdolt,Cup filling and sealing machine (roll film),https://www.reddit.com/r/MachineLearning/comments/7bdolt/cup_filling_and_sealing_machine_roll_film/,hymachinery,1510066755,,0,1
332,2017-11-8,2017,11,8,0,7bdux8,A Curated List Of Dedicated Resources- TensorFlow Books,https://www.reddit.com/r/MachineLearning/comments/7bdux8/a_curated_list_of_dedicated_resources_tensorflow/,sudheeran,1510068357,,0,1
333,2017-11-8,2017,11,8,0,7be2kg,New Draft of Sutton &amp; Barto  Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/7be2kg/new_draft_of_sutton_barto_reinforcement_learning/,stevenschmatz,1510070267,,0,1
334,2017-11-8,2017,11,8,1,7be4y2,[D] MXNet - who is using it and what are your opinions?,https://www.reddit.com/r/MachineLearning/comments/7be4y2/d_mxnet_who_is_using_it_and_what_are_your_opinions/,bbsome,1510070808,"Wondering who is using MXNet full time and in what position. For those who have just tried it what were your reflections on it compared to the other packages out there? I've seen benchmarks suggesting it is marginally faster but has very good memory utilization. However, so far I have only seen the most basic networks implemented, without any more advanced code written in it.",16,26
335,2017-11-8,2017,11,8,1,7be5m0,[D] Information theory,https://www.reddit.com/r/MachineLearning/comments/7be5m0/d_information_theory/,spartan12321,1510070969,"I'm AI enthusiast, but never got any CS/math formal education. I learned up to advanced calculus, linear algebra, probability, statisitcs, Python, ML, NLP, computer vision and Deep learning(Bengio, Goodfellow) got me thinking abut learning information theory. What is your opinion? I'm thinking about learning Information Theory, Inference and Learning Algorithms from MacKey.",9,11
336,2017-11-8,2017,11,8,1,7bebfi,I trained a rnn to write a ridiculous book using char-rnn-tensorflow.,https://www.reddit.com/r/MachineLearning/comments/7bebfi/i_trained_a_rnn_to_write_a_ridiculous_book_using/,vgan,1510072397,,0,1
337,2017-11-8,2017,11,8,2,7beivd,How do you consider and report results regarding algorithmic fairness vs. accuracy in your applications/models that involve humans?,https://www.reddit.com/r/MachineLearning/comments/7beivd/how_do_you_consider_and_report_results_regarding/,rockefeller22,1510074170,[removed],0,1
338,2017-11-8,2017,11,8,2,7bemy4,[R] Learning to solve inverse problems using Wasserstein loss,https://www.reddit.com/r/MachineLearning/comments/7bemy4/r_learning_to_solve_inverse_problems_using/,adler-j,1510075138,,1,9
339,2017-11-8,2017,11,8,2,7beodj,How far has data augmentation gotten you?,https://www.reddit.com/r/MachineLearning/comments/7beodj/how_far_has_data_augmentation_gotten_you/,2ick,1510075482,[removed],0,1
340,2017-11-8,2017,11,8,2,7bet83,[1711.01558] Wasserstein Auto-Encoders,https://www.reddit.com/r/MachineLearning/comments/7bet83/171101558_wasserstein_autoencoders/,alexmlamb,1510076650,,1,1
341,2017-11-8,2017,11,8,2,7beu3q,"[D] How is a regression model where we fit a line through data and pinpoint a spot on the line to predict a y-value from an x-value any different from a ""line of best fit"" that we all learned in 6th-grade math?",https://www.reddit.com/r/MachineLearning/comments/7beu3q/d_how_is_a_regression_model_where_we_fit_a_line/,fosofyowq,1510076860,"I seriously have a hard time believing that regression models are so complicated and need advanced calculus and linear algebra to solved. I learned what a line of best fit was in the 6th grade. On math quizzes in the 6th grade, we got scatter plots full of points, and were told ""draw a line of best fit on the following graphs"". So I did this in grade school. And THIS is all a linear regression model is? Drawing a line of best fit, and then using an x-y coordinate on that line of best fit to predict a y from an x? I could've done that in the 6th grade. Is it REALLY more complicated than this?",8,0
342,2017-11-8,2017,11,8,3,7bfa99,[R] Feature Visualization: How neural networks build up their understanding of images,https://www.reddit.com/r/MachineLearning/comments/7bfa99/r_feature_visualization_how_neural_networks_build/,alxndrkalinin,1510080617,,52,322
343,2017-11-8,2017,11,8,3,7bfc8a,Generating Pokemon with Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/7bfc8a/generating_pokemon_with_generative_adversarial/,funmaster11,1510081066,,0,1
344,2017-11-8,2017,11,8,4,7bffg8,[P] New Stanford Course: Theories of Deep Learning (STATS 385),https://www.reddit.com/r/MachineLearning/comments/7bffg8/p_new_stanford_course_theories_of_deep_learning/,satsatsat,1510081807,,10,89
345,2017-11-8,2017,11,8,4,7bffwp,[R] Fully-Parallel Text Generation for Neural Machine Translation,https://www.reddit.com/r/MachineLearning/comments/7bffwp/r_fullyparallel_text_generation_for_neural/,Kaixhin,1510081905,,8,1
346,2017-11-8,2017,11,8,4,7bfje2,[D] GPU for ML/DL,https://www.reddit.com/r/MachineLearning/comments/7bfje2/d_gpu_for_mldl/,Englader,1510082711,[removed],3,0
347,2017-11-8,2017,11,8,4,7bfk18,"My friends and I built a poker AI that uses q-learning what we called ""darwinian q-learning""",https://www.reddit.com/r/MachineLearning/comments/7bfk18/my_friends_and_i_built_a_poker_ai_that_uses/,[deleted],1510082854,[deleted],0,1
348,2017-11-8,2017,11,8,4,7bfmjn,"My friends and I created a Poker AI that uses what we called ""darwinian q-learning""",https://www.reddit.com/r/MachineLearning/comments/7bfmjn/my_friends_and_i_created_a_poker_ai_that_uses/,[deleted],1510083453,[deleted],0,1
349,2017-11-8,2017,11,8,5,7bfsbg,"[D] Why is a ""deep neural network"" with so many hidden layers and you don't know what most of them are doing a good thing? Sounds to me like a recipe for disaster.",https://www.reddit.com/r/MachineLearning/comments/7bfsbg/d_why_is_a_deep_neural_network_with_so_many/,fosofyowq,1510084837,"I just think about it like this: Let's say I'm person x. I need something fixed. I know person y, so I hand off the thing to person y and rely on that hand-off to fix the thing. Person y does something, then hands it off to person z, who does something, then hands it off to person a, who will hand it off to b after doing something, then it'll keep going all the way down the alphabet until it gets to person w, who knows me, and then person w, after making his own final touches, will hand the item back to me, and it's supposedly fixed from the broken state after going through all those people/layers.

Am I to trust that my item has been properly fixed? As person x, all I have sight of is person y directly after me, and person w directly before. I have information on what person y does to my item, and what person w does to my item just before he hands it back to me. Let's say I saw what they did and trust it because I monitored y's actions and w's actions and determined they were ok, so those are fine. But then, I have completely no knowledge of what any other person in the alphabet chain did because they're not in my direct vicinity. They could've done anything for all I know, screwed with it in ways i never wanted. So when I get handed back my item after it's gone through all those hidden layers, how am I to trust it or what's been done to it? Personally, I would want to properly monitor every single thing that anyone decides to do to my item, because otherwise I don't know how badly they're messing with it.

So then why is this ok in a deep neural network which has countless ""hidden layers"" that are not explicitly programmed by you and they could be doing all kinds of things you don't approve of? How do you trust what the output is if you only have knowledge of what a couple of the layers are doing, and no explicit knowledge of anything else? How are outputs that have been through tons of ""hidden layers"" to be trusted at all? Or is my analogy just off-base? I'm having a hard time grasping this concept. ""Hidden layers"" just don't sound trustworthy to me.",3,0
350,2017-11-8,2017,11,8,5,7bft4v,[D] Anyone here who attended the Beyond ILSVRC workshop as CVPR 2017?,https://www.reddit.com/r/MachineLearning/comments/7bft4v/d_anyone_here_who_attended_the_beyond_ilsvrc/,karan_42,1510085015,"I was going through the results and got to know that this was the last challenge. I am reading the slides of the winning entries from the workshop. However, the talks by speakers are not available on the page.

I wanted to know what the speakers discussed in their talks.

Thanks in advance :)",0,3
351,2017-11-8,2017,11,8,5,7bfuen,"[Project] My friends and I created a Poker AI that uses what we called ""darwinian q-learning"" to get better over time",https://www.reddit.com/r/MachineLearning/comments/7bfuen/project_my_friends_and_i_created_a_poker_ai_that/,barce99,1510085328,,9,9
352,2017-11-8,2017,11,8,5,7bfvs8,Researchers Unveil Tool to Debug Black Box Deep Learning Algorithms,https://www.reddit.com/r/MachineLearning/comments/7bfvs8/researchers_unveil_tool_to_debug_black_box_deep/,Chipdoc,1510085648,,0,1
353,2017-11-8,2017,11,8,5,7bfwlm,UX and Machine Learning - Devil is in the Data,https://www.reddit.com/r/MachineLearning/comments/7bfwlm/ux_and_machine_learning_devil_is_in_the_data/,copybin,1510085831,,0,1
354,2017-11-8,2017,11,8,5,7bg2lr,Data Parallelism in 'Learning to Generate Reviews and Discovering Sentiment'. Trying to reproduce,https://www.reddit.com/r/MachineLearning/comments/7bg2lr/data_parallelism_in_learning_to_generate_reviews/,jonnnydonnelly,1510087268,[removed],0,1
355,2017-11-8,2017,11,8,6,7bgbf4,[R] Thinking Fast and Slow with Deep Learning and Tree Search (Updated NIPS version),https://www.reddit.com/r/MachineLearning/comments/7bgbf4/r_thinking_fast_and_slow_with_deep_learning_and/,ThomasWAnthony,1510089393,,7,27
356,2017-11-8,2017,11,8,9,7bhjqb,[D] What are your favorite machine learning podcast episodes?,https://www.reddit.com/r/MachineLearning/comments/7bhjqb/d_what_are_your_favorite_machine_learning_podcast/,TheKrooth,1510100720,,14,18
357,2017-11-8,2017,11,8,10,7bi3k0,Past Competition with downloadable data,https://www.reddit.com/r/MachineLearning/comments/7bi3k0/past_competition_with_downloadable_data/,Marie142,1510106143,[removed],0,1
358,2017-11-8,2017,11,8,11,7bi4y1,"[D] Dealing with Massive, Out of Memory Image Sizes (Medical/Satellite)",https://www.reddit.com/r/MachineLearning/comments/7bi4y1/d_dealing_with_massive_out_of_memory_image_sizes/,tastingsilver,1510106509,"Hey guys,

Have been trying to approach this area for a while, and struggling with how to manage the magnitude of the imagery size while keeping within memory. Most up to date libraries have measures for managing large volumes of pictures/data, but I haven't seen much that has solved for efficiently managing massive single-item images.

I'd really like to be able to freely train CNNs on various sat imagery data I've been gathering/exploring, with emphasis on the smaller details of high-res, and I was wondering if anyone else had explored similar solutions?

Is this just a matter of dividing up larger images by x/y axis to resize, train a network, then re-map with information (bounding boxes/etc), or is there more of a generator-oriented solution on the horizon?

Lets crack this one.",9,3
359,2017-11-8,2017,11,8,11,7bi5yd,[R] Flexpoint: An Adaptive Numerical Format for Efficient Training of Deep Neural Networks (NIPS 2017),https://www.reddit.com/r/MachineLearning/comments/7bi5yd/r_flexpoint_an_adaptive_numerical_format_for/,drwebb,1510106748,,33,5
360,2017-11-8,2017,11,8,11,7biauz,[D] Current Neural Machine Translation Models Do Not Work Well With Chinese-English Translation,https://www.reddit.com/r/MachineLearning/comments/7biauz/d_current_neural_machine_translation_models_do/,ResHacker,1510108065,Is this true? What is your opinion?,3,1
361,2017-11-8,2017,11,8,12,7biivp,[N] Waymo's level 4 self-driving cars are on public roads,https://www.reddit.com/r/MachineLearning/comments/7biivp/n_waymos_level_4_selfdriving_cars_are_on_public/,drlukeor,1510110333,,61,205
362,2017-11-8,2017,11,8,12,7bionq,WHY Error Optimization is used in Machine Learning? Check out my new video understand how Error Optimization relates to ML.,https://www.reddit.com/r/MachineLearning/comments/7bionq/why_error_optimization_is_used_in_machine/,harshMachineLearning,1510111996,,0,1
363,2017-11-8,2017,11,8,12,7bipx3,[P] Tensorflow Snippets,https://www.reddit.com/r/MachineLearning/comments/7bipx3/p_tensorflow_snippets/,ml_remixer,1510112364,,2,3
364,2017-11-8,2017,11,8,13,7bitvg,[P] TensorFlow based android app which does image-captioning in real-time,https://www.reddit.com/r/MachineLearning/comments/7bitvg/p_tensorflow_based_android_app_which_does/,Xe0n360,1510113600,"Check out our deep-learning based android app which captions live camera frames in real-time.
https://github.com/neural-nuts/Cam2Caption

This app uses pre-trained model generated using
 
https://github.com/neural-nuts/image-caption-generator

Preview: http://gph.is/2iFzN9h
",0,8
365,2017-11-8,2017,11,8,13,7biw1q,Undergrad interested in research,https://www.reddit.com/r/MachineLearning/comments/7biw1q/undergrad_interested_in_research/,Kabnoory,1510114245,[removed],0,1
366,2017-11-8,2017,11,8,13,7bj4xl,Top 5 open source machine learning projects,https://www.reddit.com/r/MachineLearning/comments/7bj4xl/top_5_open_source_machine_learning_projects/,Intuz_Solutions,1510117111,,0,1
367,2017-11-8,2017,11,8,13,7bj52r,Using NLP to categorize chats with pre-determined categories,https://www.reddit.com/r/MachineLearning/comments/7bj52r/using_nlp_to_categorize_chats_with_predetermined/,SirMzungu,1510117156,[removed],0,1
368,2017-11-8,2017,11,8,14,7bjec4,"[R] Unsupervised Machine Translation using monolingual corpora only by FAIR ( Takes sentences from monolingual corpora in two different languages, reports BLEU scores up to 32.8, without using even a single parallel sentence at training time.)",https://www.reddit.com/r/MachineLearning/comments/7bjec4/r_unsupervised_machine_translation_using/,rishabh135,1510120260,,9,13
369,2017-11-8,2017,11,8,14,7bjedl,How to program neural networks with sparse connections,https://www.reddit.com/r/MachineLearning/comments/7bjedl/how_to_program_neural_networks_with_sparse/,Kirkland_Light,1510120275,[removed],0,1
370,2017-11-8,2017,11,8,15,7bjlba,What is the latest state of the art for 2D object detection with only a single training image?,https://www.reddit.com/r/MachineLearning/comments/7bjlba/what_is_the_latest_state_of_the_art_for_2d_object/,kuwt,1510122824,[removed],0,1
371,2017-11-8,2017,11,8,15,7bjmgi,Globally and Locally Consistent Image Completion,https://www.reddit.com/r/MachineLearning/comments/7bjmgi/globally_and_locally_consistent_image_completion/,[deleted],1510123287,[deleted],0,1
372,2017-11-8,2017,11,8,15,7bjmij,[R] Globally and Locally Consistent Image Completion,https://www.reddit.com/r/MachineLearning/comments/7bjmij/r_globally_and_locally_consistent_image_completion/,Reiinakano,1510123315,,6,80
373,2017-11-8,2017,11,8,16,7bjrg3,"Rilon Welding | Machinery-Coimbatore-Dealers | Suppliers-Tamil Nadu,India | Rilon TIG | Rilon MIG | Rilon Plasma | Rilon Arc Welding",https://www.reddit.com/r/MachineLearning/comments/7bjrg3/rilon_welding_machinerycoimbatoredealers/,rilonwelding,1510125238,,0,1
374,2017-11-8,2017,11,8,17,7bk18z,Preventing Hacking and Impersonation with Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7bk18z/preventing_hacking_and_impersonation_with_machine/,poojagandhi456,1510129342,,0,1
375,2017-11-8,2017,11,8,17,7bk4ac,"Hello guys,",https://www.reddit.com/r/MachineLearning/comments/7bk4ac/hello_guys/,Mahar0627,1510130828,[removed],0,1
376,2017-11-8,2017,11,8,18,7bk8ia,Automatic fresh noodle maker machine for sale,https://www.reddit.com/r/MachineLearning/comments/7bk8ia/automatic_fresh_noodle_maker_machine_for_sale/,liusherry,1510132788,,1,1
377,2017-11-8,2017,11,8,18,7bka2o,[P] In order to understand Neural Networks I built a simple NN that solves XOR's from scratch in C++,https://www.reddit.com/r/MachineLearning/comments/7bka2o/p_in_order_to_understand_neural_networks_i_built/,[deleted],1510133501,[deleted],0,0
378,2017-11-8,2017,11,8,18,7bkb30,Automatic Dry Noodle Making Machine With 9 Rollers,https://www.reddit.com/r/MachineLearning/comments/7bkb30/automatic_dry_noodle_making_machine_with_9_rollers/,liusherry,1510133945,,1,1
379,2017-11-8,2017,11,8,19,7bkhq4,Advice needed: Methods to predict Bitcoin Price using Google Search Volume Data,https://www.reddit.com/r/MachineLearning/comments/7bkhq4/advice_needed_methods_to_predict_bitcoin_price/,thu-trang,1510136716,[removed],0,1
380,2017-11-8,2017,11,8,19,7bkj99,Learn to rank implementation in python,https://www.reddit.com/r/MachineLearning/comments/7bkj99/learn_to_rank_implementation_in_python/,ritterkonig,1510137385,[removed],0,1
381,2017-11-8,2017,11,8,20,7bkt8o,How Machine Learning and AI can take your business to the next level,https://www.reddit.com/r/MachineLearning/comments/7bkt8o/how_machine_learning_and_ai_can_take_your/,stewartcristan,1510141623,,0,1
382,2017-11-8,2017,11,8,20,7bku9k,Starting at zero!,https://www.reddit.com/r/MachineLearning/comments/7bku9k/starting_at_zero/,pos123,1510142023,[removed],0,1
383,2017-11-8,2017,11,8,21,7bkw5j,[D] How to interpret topics from LSI in Gensim?,https://www.reddit.com/r/MachineLearning/comments/7bkw5j/d_how_to_interpret_topics_from_lsi_in_gensim/,trias10,1510142760,"I have been doing topic modeling with LDA in Gensim for a while now, but have decided to move to the SVD approach in LSI for speed (LDA is just way too slow).

My question is, once you fit an LSI model to a tf-idf corpus (using Gensim for example), how exactly are you supposed to interpret the individual topics? For example, both LdaModel and LsiModel classes in Gensim have the show_topic(topic_number, topn) method which prints out a fitted topic along with the topn words which make up that topic, and their weights. In LDA, these weights come from the Dirichlet MLE, so represent a probability distribution over words in that topic, and each weight is positive, and the total sum should be 1.

However, the same show_topic() output for an LsiModel is not based on a probability distribution, and in fact, looking at the individual word weights for show_topic, there are usually loads of negative weights associated to some words for a particular topic. I'm not sure how to interpret these values, as they are clearly not weights. Are they eigenvalues of a sort? And more importantly, can I still interpret the output from show_topic() under LSI the same way I interpret it from LDA? It doesn't seem to me that it is creating proper topics as robust as LDA.",0,5
384,2017-11-8,2017,11,8,21,7bkzrn,Tutorial version of CapsNet in PyTorch,https://www.reddit.com/r/MachineLearning/comments/7bkzrn/tutorial_version_of_capsnet_in_pytorch/,laubonghaudoi,1510144037,,0,1
385,2017-11-8,2017,11,8,21,7bl1a1,See HOW Error Optimization works in Machine Learning. Part to of the Error Optimization series.,https://www.reddit.com/r/MachineLearning/comments/7bl1a1/see_how_error_optimization_works_in_machine/,harshMachineLearning,1510144571,,0,1
386,2017-11-8,2017,11,8,22,7bl70a,[D] What are some seemingly magical applications of Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/7bl70a/d_what_are_some_seemingly_magical_applications_of/,villasv,1510146494,"I'm doing a small tech talk about Clarke's Third Law (sufficiently advanced tech is indistinguishable from magic) and I've been collecting a few examples.

Some notable ones come from the AR/VR world, but a few ones like Video Style Transfer with CycleGAN and Video Impersonation with Face2Face are quite noteworthy.

What other impressive results from the ML field make you feel like you're seeing magic happening?
",20,33
387,2017-11-8,2017,11,8,22,7blakn,kenza - continuous integration for machine learning,https://www.reddit.com/r/MachineLearning/comments/7blakn/kenza_continuous_integration_for_machine_learning/,pm3310,1510147664,[removed],0,1
388,2017-11-8,2017,11,8,23,7blhax,"[P] Visualization of high dimensional dataset, for data scientists",https://www.reddit.com/r/MachineLearning/comments/7blhax/p_visualization_of_high_dimensional_dataset_for/,0011001011,1510149733,,6,25
389,2017-11-8,2017,11,8,23,7bllii,Glass bottle washing filling and capping 3-in-1 mono-block machine for l...,https://www.reddit.com/r/MachineLearning/comments/7bllii/glass_bottle_washing_filling_and_capping_3in1/,hymachinery,1510150908,,0,1
390,2017-11-8,2017,11,8,23,7blm7d,Causal inference with pandas dataframes,https://www.reddit.com/r/MachineLearning/comments/7blm7d/causal_inference_with_pandas_dataframes/,akelleh,1510151099,,0,3
391,2017-11-8,2017,11,8,23,7blmfw,Is anyone training G. E. Hinton's new capsule network on the ImageNet dataset?,https://www.reddit.com/r/MachineLearning/comments/7blmfw/is_anyone_training_g_e_hintons_new_capsule/,Barney6,1510151175,[removed],1,2
392,2017-11-8,2017,11,8,23,7bln21,Interview with Ian Goodfellow,https://www.reddit.com/r/MachineLearning/comments/7bln21/interview_with_ian_goodfellow/,[deleted],1510151350,[deleted],0,1
393,2017-11-8,2017,11,8,23,7blspx,"[R]Summit discusses impact of machines on jobs, productivity, and the global economy",https://www.reddit.com/r/MachineLearning/comments/7blspx/rsummit_discusses_impact_of_machines_on_jobs/,jackblun,1510152933,,0,1
394,2017-11-9,2017,11,9,0,7bltrc,General-purpose Round Bottle Labeling Machine for Vitamin E Emulsion Lab...,https://www.reddit.com/r/MachineLearning/comments/7bltrc/generalpurpose_round_bottle_labeling_machine_for/,hymachinery,1510153213,,0,1
395,2017-11-9,2017,11,9,0,7blw2i,Useful infographic describing linear regression analysis,https://www.reddit.com/r/MachineLearning/comments/7blw2i/useful_infographic_describing_linear_regression/,[deleted],1510153761,[deleted],0,1
396,2017-11-9,2017,11,9,0,7bly4n,[D] Can someone explain the error metric reported in this paper?,https://www.reddit.com/r/MachineLearning/comments/7bly4n/d_can_someone_explain_the_error_metric_reported/,Writes_A_Bit,1510154319,"https://arxiv.org/pdf/1609.01596v1.pdf

In Table 3 on page 7. The training error on CIFAR-100 is reported as 0.1% for a ConvNet, but test error is as high as 69%. 
How is backprop on a convnet doing so badly at classifying images, especially when training error is so low? Is this not overfitting? 

Seems like all three methods described for that ConvNet are over-fitting. While I understand that the point is to show that the three methods perform roughly equally well, I'm curious why there is so much overfitting. 

Similarly, for one of the models in that table, training error is 77%. That seems like a bad result to include, but I'm guessing the point was to show that the feedback alignment method is doing as well as backprop... ?",6,1
397,2017-11-9,2017,11,9,0,7blyc0,Useful Infographic Describing Linear Regression,https://www.reddit.com/r/MachineLearning/comments/7blyc0/useful_infographic_describing_linear_regression/,jkimbigdata,1510154378,,0,1
398,2017-11-9,2017,11,9,0,7bm4b2,[D] What is the current state of dropout as Bayesian approximation?,https://www.reddit.com/r/MachineLearning/comments/7bm4b2/d_what_is_the_current_state_of_dropout_as/,sschoener,1510155927,"Some time ago already, Gal &amp; Ghahramani published their [Dropout as Bayesian Approximation](https://arxiv.org/abs/1506.02142) paper, and a few more follow-up papers by Gal and colleagues about epistemic vs. aleatoric risks etc. There they claim that test-time dropout can be seen as Bayesian approximation to a Gaussian process related to the original network. (I would not claim to understand the proof in all of its details.)
So far so good, but at the Bayesian DL workshop at NIPS2016 Ian Osband of Google DeepMind published his note [Risk versus Uncertainty in Deep Learning: Bayes, Bootstrap and the Dangers of Dropout](http://bayesiandeeplearning.org/2016/papers/BDL_4.pdf), where he claims that even for absurdly simple networks you can analytically show that the 'posterior' you get using MC dropout doesn't concentrate asymptotically. Which I take as saying that there's no Bayesian approximation happening, since almost any reasonable prior on the weights should lead to a near-certain posterior in the limit of infinite data.

Alas, there are still papers popping up using the MC dropout approach, without even mentioning Osband's note.
Did I miss something? Is there a follow-up to Osband's note? A rebuttal?
I didn't attend NIPS2016, and I am thus not aware of any discussions that might have happened there, but would certainly appreciate any pointers (-- and given that Yarin Gal was co-organizing that workshop, I am pretty sure that he has seen Osband's note).

Edit:
For completeness, here is [Yarin Gal's thesis](http://www.cs.ox.ac.uk/people/yarin.gal/website/blog_2248.html) on this topic and [the appendix to their 2015 paper](https://arxiv.org/abs/1506.02157) containing the proof.
Additionally, the supplementary material (section A) of [Deep Exploration via Bootstrapped DQN](https://papers.nips.cc/paper/6501-deep-exploration-via-bootstrapped-dqn) contains some more of Ian's thoughts on this issue",39,44
399,2017-11-9,2017,11,9,0,7bm6sy,"Simple Questions Thread November 08, 2017",https://www.reddit.com/r/MachineLearning/comments/7bm6sy/simple_questions_thread_november_08_2017/,AutoModerator,1510156540,[removed],0,1
400,2017-11-9,2017,11,9,1,7bm8t2,"Machine Learning and the Internet of Things. Read how they both work together in this blog by the team who created the 'Bolt IoT Platform, made for Machine Learning.'",https://www.reddit.com/r/MachineLearning/comments/7bm8t2/machine_learning_and_the_internet_of_things_read/,ppv999,1510157009,,0,1
401,2017-11-9,2017,11,9,1,7bmkun,[R] Cortical microcircuits as gated-recurrent neural networks,https://www.reddit.com/r/MachineLearning/comments/7bmkun/r_cortical_microcircuits_as_gatedrecurrent_neural/,visarga,1510159948,,26,11
402,2017-11-9,2017,11,9,2,7bmmtd,[R] AWS Collaborates with Emory University to Develop Cloud-Based NLP Research Platform Using Apache MXNet,https://www.reddit.com/r/MachineLearning/comments/7bmmtd/r_aws_collaborates_with_emory_university_to/,ydereky,1510160427,,0,0
403,2017-11-9,2017,11,9,2,7bmswa,[P] Alpha pooling for fine-grained recognition (code),https://www.reddit.com/r/MachineLearning/comments/7bmswa/p_alpha_pooling_for_finegrained_recognition_code/,MarcelSimon,1510161806,,2,6
404,2017-11-9,2017,11,9,2,7bmu95,[P] Remote Profile and Test Deep Learning Cross Compilation on Mobile Phones with TVM RPC,https://www.reddit.com/r/MachineLearning/comments/7bmu95/p_remote_profile_and_test_deep_learning_cross/,javelinjs,1510162123,,0,7
405,2017-11-9,2017,11,9,2,7bmxff,Here's my story how you can change gender or race on your selfie with GANs,https://www.reddit.com/r/MachineLearning/comments/7bmxff/heres_my_story_how_you_can_change_gender_or_race/,johnkorn,1510162877,,0,2
406,2017-11-9,2017,11,9,2,7bn0wj,Machine Learning Cheatsheet - Styled After Pytorch Documentation),https://www.reddit.com/r/MachineLearning/comments/7bn0wj/machine_learning_cheatsheet_styled_after_pytorch/,[deleted],1510163682,,0,1
407,2017-11-9,2017,11,9,2,7bn1e8,Garbage Detection and Classification,https://www.reddit.com/r/MachineLearning/comments/7bn1e8/garbage_detection_and_classification/,harshitgambhir,1510163789,[removed],0,1
408,2017-11-9,2017,11,9,2,7bn1sm,What are some research topics that explores the connections between category theory/type theory/functional programming and machine learning?,https://www.reddit.com/r/MachineLearning/comments/7bn1sm/what_are_some_research_topics_that_explores_the/,winstonl,1510163878,[removed],0,1
409,2017-11-9,2017,11,9,3,7bn49e,Machine Learning Cheatsheet -- Organized like Documentation,https://www.reddit.com/r/MachineLearning/comments/7bn49e/machine_learning_cheatsheet_organized_like/,[deleted],1510164404,[deleted],0,1
410,2017-11-9,2017,11,9,3,7bn8e8,[N] SpaCy 2.0 released (Natural Language Processing with Python),https://www.reddit.com/r/MachineLearning/comments/7bn8e8/n_spacy_20_released_natural_language_processing/,pmigdal,1510165353,,45,255
411,2017-11-9,2017,11,9,4,7bnspe,I am doing academic project in Apache spark with help of pyspark. It is about analyzing stock prices time series data. I have found that in melon we have randomSplit for spliting data for training and testing. I am not sure about is this good also for time series data. Am I wrong ?,https://www.reddit.com/r/MachineLearning/comments/7bnspe/i_am_doing_academic_project_in_apache_spark_with/,lastfreelogino,1510169948,[removed],1,1
412,2017-11-9,2017,11,9,4,7bnv95,Machine Learning Will Destroy UI Jobs: I give it 5 years.,https://www.reddit.com/r/MachineLearning/comments/7bnv95/machine_learning_will_destroy_ui_jobs_i_give_it_5/,hamptonfischer,1510170547,,0,1
413,2017-11-9,2017,11,9,5,7bo2gr,A collection of machine learning tutorials,https://www.reddit.com/r/MachineLearning/comments/7bo2gr/a_collection_of_machine_learning_tutorials/,[deleted],1510172228,[deleted],0,1
414,2017-11-9,2017,11,9,7,7bosyc,"[D] In your entire run with machine learning, what concepts did you have the most trouble with ?",https://www.reddit.com/r/MachineLearning/comments/7bosyc/d_in_your_entire_run_with_machine_learning_what/,hubbahubba111,1510178731,,48,12
415,2017-11-9,2017,11,9,7,7boto6,Can machine learning make artistic quote picture ?,https://www.reddit.com/r/MachineLearning/comments/7boto6/can_machine_learning_make_artistic_quote_picture/,[deleted],1510178922,,0,1
416,2017-11-9,2017,11,9,7,7bou1e,[D] Ok to cite ICLR 2018 submissions?,https://www.reddit.com/r/MachineLearning/comments/7bou1e/d_ok_to_cite_iclr_2018_submissions/,hughperkins,1510179016,The ICLR 2018 submissions at https://openreview.net/group?id=ICLR.cc/2018/Conference contain some very interesting papers. To what extent is it normal-ish/ok-ish to cite such papers?,4,1
417,2017-11-9,2017,11,9,7,7bowt7,"Building Dota Bots That Beat Pros - OpenAI's Greg Brockman, Szymon Sidor, and Sam Altman",https://www.reddit.com/r/MachineLearning/comments/7bowt7/building_dota_bots_that_beat_pros_openais_greg/,programmingdoc,1510179721,,0,1
418,2017-11-9,2017,11,9,8,7bpepb,"[P]My friends and I created a Poker AI that uses what we called ""darwinian q-learning"" to get better over time",https://www.reddit.com/r/MachineLearning/comments/7bpepb/pmy_friends_and_i_created_a_poker_ai_that_uses/,barce99,1510184484,,5,8
419,2017-11-9,2017,11,9,8,7bpfnx,Bitcoin giant Bitmain enters the AI market with the BM1680 neural processor,https://www.reddit.com/r/MachineLearning/comments/7bpfnx/bitcoin_giant_bitmain_enters_the_ai_market_with/,gwd2,1510184764,,0,1
420,2017-11-9,2017,11,9,9,7bpjo0,Atlanta Family Law &amp;amp; Criminal Defense Lawyer | The Law Firm of Caryn S. Fennell,https://www.reddit.com/r/MachineLearning/comments/7bpjo0/atlanta_family_law_amp_criminal_defense_lawyer/,dannavvsimoesvv,1510185901,,0,1
421,2017-11-9,2017,11,9,9,7bpjru,13 Exclusive New Trends in Big Data and Data Science,https://www.reddit.com/r/MachineLearning/comments/7bpjru/13_exclusive_new_trends_in_big_data_and_data/,Marry_owen,1510185933,,0,1
422,2017-11-9,2017,11,9,10,7bpwp7,Is there any better-compiled resource that keeps track of State of the art results of different problem set?,https://www.reddit.com/r/MachineLearning/comments/7bpwp7/is_there_any_bettercompiled_resource_that_keeps/,[deleted],1510189416,,0,1
423,2017-11-9,2017,11,9,10,7bpwrt,"New machine learning competition, $2,000 award",https://www.reddit.com/r/MachineLearning/comments/7bpwrt/new_machine_learning_competition_2000_award/,Datascope,1510189429,,0,1
424,2017-11-9,2017,11,9,10,7bpxbq,[D] Is there any better-compiled resource that keeps track of State of the art results of different problem set?,https://www.reddit.com/r/MachineLearning/comments/7bpxbq/d_is_there_any_bettercompiled_resource_that_keeps/,futbol_account,1510189570,"I am using this: https://www.eff.org/ai/metrics#Problems,-Metrics,-and-Datasets

I do not think it was updated for a long time. Moreover, a lot of problems was not on the list.
Is there any webpage or GitHub page that has compiled SoTA results for all problems with corresponding paper?

If there is not anyone goto source, we should start doing it. Ours is the largest ML community. If we all contribute, we can make it possible.",1,7
425,2017-11-9,2017,11,9,11,7bqjt2,The polyurethane resin can be maded by jacketed reactor from JCT,https://www.reddit.com/r/MachineLearning/comments/7bqjt2/the_polyurethane_resin_can_be_maded_by_jacketed/,mixmachinery,1510196145,,1,1
426,2017-11-9,2017,11,9,11,7bqk0n,"[P] A Real-Time Mario Kart 64 AI Using CNNs, Offline Search, and DAGGER",https://www.reddit.com/r/MachineLearning/comments/7bqk0n/p_a_realtime_mario_kart_64_ai_using_cnns_offline/,varunramesh,1510196212,,20,123
427,2017-11-9,2017,11,9,12,7bqpdi,[D] Collecting state of the art result for all machine learning problems,https://www.reddit.com/r/MachineLearning/comments/7bqpdi/d_collecting_state_of_the_art_result_for_all/,futbol_account,1510197823,"I am starting this ambitious project with the aim of collecting SoTA results for all machine learning problems and all datasets. I certainly can not do this alone. It requires support from a large community. I strongly believe r/MachineLearning can do this because ours is the largest machine learning community.

URL: https://github.com/RedditSota/state-of-the-art-result-for-machine-learning-problems

I need few things from you all:

1. Please often visit that GitHub page and provide SoTA results periodically.

2. Need many collaborators who can actively update the GitHub. Please PM me if you are interested. 

3. In this thread, provide SoTA result for the problems you know.
In need this info: 

           * Type of learning problem

           * Modality

           * Research paper

           * Datasets

           * Metric

           * Source Code

           * Year


4. Please give visibility to this by sharing it on Facebook, Twitter, your research labs, professors, etc. 

If you have comments on the structure, please write to me.

This is definitely possible if we work together on this.

EDIT:

Can someone provide common NLP tasks and its datasets? Similarly for Image, Speech, RL, etc.",28,35
428,2017-11-9,2017,11,9,12,7bqq1r,[D] Continuous Churn Prediction,https://www.reddit.com/r/MachineLearning/comments/7bqq1r/d_continuous_churn_prediction/,throwawaychickenskin,1510198031,"My company that sells a subscription based app and I've been working on churn prediction for the past few months.

So far I've developed a random forest model that uses the first X days of a users experience to determine if they will churn before day Y.  I've had some good results with an AUC = .85 but this model is only good around the time it is run.

One solution could be to develop several more models (a model that runs on day 30, another on day 365, etc) but this seems like an inelegant and unwieldily solution.  I'd like a model that could be run at any point in a customers life and give an indication of their propensity to churn.

I've tried RFM models 

http://lifetimes.readthedocs.io/en/latest/

(Using customer interaction with the app as activity, the RFM model wasn't able to predict customer churn early enough to be useful)

and a WTTE RNN model

https://github.com/ragulpr/wtte-rnn

(Although the above article recommends the WTTE RNN model for predicting churn, it doesn't seem able to fit my training data very well, producing an average likelihood of .1)

but the results just don't work.

Most work on churn seems to be in the non contractual sector.  There the above models seem to work well because even if you have a customer churn, it's not as urgent to identify them.  Where as in the contractual sector, you want to identify a churning customer before they hit the unsubscribe button.

I guess I'm just looking for general advice from anyone who has worked on this sort of problem before.
",2,0
429,2017-11-9,2017,11,9,12,7bqq2b,How to detect machine failures using sensor data?,https://www.reddit.com/r/MachineLearning/comments/7bqq2b/how_to_detect_machine_failures_using_sensor_data/,[deleted],1510198035,,0,1
430,2017-11-9,2017,11,9,12,7bqrsf,What's going on at OpenAI?,https://www.reddit.com/r/MachineLearning/comments/7bqrsf/whats_going_on_at_openai/,20150831,1510198602,[removed],0,1
431,2017-11-9,2017,11,9,12,7bqsa6,[D] Newbie Question about multivariate LSTMs,https://www.reddit.com/r/MachineLearning/comments/7bqsa6/d_newbie_question_about_multivariate_lstms/,trexdinosaur,1510198753,"Hi Everyone! 
I am currently learning about machine learning and had a question about ANNs. 

I am currently working on a problem with predicting time series data. 
This data is multivariate, and I need to predict multiple variables of that data. 
So, option one that I thought of using was multiple LSTMs for each variable and then predicting based on that. However, if I do that, my understanding is that the ANN will not be able to learn the relationships of the vars, such as if var 1 goes up, var 2 will go down, because the LSTMs are being trained separately. Is my understanding correct?

Another option I thought of using was the multivariate example here: https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/, however in this example, only one  variable is predicted, and only a small subset of the data is used to generate the prediction. (I have much more than 3 vals/var, and in some predictions I may have like 20 vals/var, and in others 1000s of vals/vars). 

And the third method I thought of using is something similar to the machine learning mastery example, but modifying it to give greater flexibility on how many vars I can feed in, and then having multiple networks for each var that I need to predict. However, implementing this flexibility, is something I am struggling with. Can someone point me in the right direction, or tell me what would be the best approach?

Thank you so much in advance! ",5,0
432,2017-11-9,2017,11,9,13,7br4wb,[D] Architecture or hyperparameter search for RL with RL?,https://www.reddit.com/r/MachineLearning/comments/7br4wb/d_architecture_or_hyperparameter_search_for_rl/,[deleted],1510202773,[deleted],0,1
433,2017-11-9,2017,11,9,13,7br72w,Community Detection : Unsupervised Learning,https://www.reddit.com/r/MachineLearning/comments/7br72w/community_detection_unsupervised_learning/,munishmaxtech,1510203559,,0,1
434,2017-11-9,2017,11,9,14,7bre6r,"[N] Behind the scenes with the Google Brain team including Jeff Dean , Sammy Bengio and Rajat Monga",https://www.reddit.com/r/MachineLearning/comments/7bre6r/n_behind_the_scenes_with_the_google_brain_team/,[deleted],1510206056,[deleted],4,0
435,2017-11-9,2017,11,9,15,7bri8r,[1711.02989] Variational Gaussian Dropout is not Bayesian,https://www.reddit.com/r/MachineLearning/comments/7bri8r/171102989_variational_gaussian_dropout_is_not/,pull_request,1510207578,,0,1
436,2017-11-9,2017,11,9,16,7brxgq,Can machine learning make artistic quote picture ?,https://www.reddit.com/r/MachineLearning/comments/7brxgq/can_machine_learning_make_artistic_quote_picture/,[deleted],1510213663,,0,1
437,2017-11-9,2017,11,9,16,7bryse,Can machine learning make artistic quote picture ?,https://www.reddit.com/r/MachineLearning/comments/7bryse/can_machine_learning_make_artistic_quote_picture/,[deleted],1510214263,,0,1
438,2017-11-9,2017,11,9,17,7bs1ye,Customized Rice Noodle Machine With Factory Price,https://www.reddit.com/r/MachineLearning/comments/7bs1ye/customized_rice_noodle_machine_with_factory_price/,liusherry,1510215655,,1,1
439,2017-11-9,2017,11,9,18,7bs7ps,Fresh Noodle Making Machine | Wet Noodle Making Machine,https://www.reddit.com/r/MachineLearning/comments/7bs7ps/fresh_noodle_making_machine_wet_noodle_making/,liusherry,1510218423,,1,1
440,2017-11-9,2017,11,9,19,7bsizl,[D] ML algorithm to model/classify/map a software program's internal structure?  r/MLQuestions,https://www.reddit.com/r/MachineLearning/comments/7bsizl/d_ml_algorithm_to_modelclassifymap_a_software/,BTOdell,1510223636,,0,2
441,2017-11-9,2017,11,9,20,7bsnx3,Can machine learning make artistic quote picture ?,https://www.reddit.com/r/MachineLearning/comments/7bsnx3/can_machine_learning_make_artistic_quote_picture/,[deleted],1510225768,,0,1
442,2017-11-9,2017,11,9,20,7bsqgr,Can machine learning make artistic quote picture ?,https://www.reddit.com/r/MachineLearning/comments/7bsqgr/can_machine_learning_make_artistic_quote_picture/,hristo_rv,1510226883,[removed],0,1
443,2017-11-9,2017,11,9,20,7bsrgv,The Future of Humanity Institute (Oxford University) seeks two AI Safety Researchers,https://www.reddit.com/r/MachineLearning/comments/7bsrgv/the_future_of_humanity_institute_oxford/,laurapomarius,1510227309,,0,1
444,2017-11-9,2017,11,9,21,7bszg0,[N] 11 PhD and 5 postdoc positions available on the interplay between Data Science and Business Process Analysis,https://www.reddit.com/r/MachineLearning/comments/7bszg0/n_11_phd_and_5_postdoc_positions_available_on_the/,TaXxER,1510230394,,2,0
445,2017-11-9,2017,11,9,22,7bt68d,Please help me with my ML research by completing this questionnaire,https://www.reddit.com/r/MachineLearning/comments/7bt68d/please_help_me_with_my_ml_research_by_completing/,[deleted],1510232774,[deleted],0,1
446,2017-11-9,2017,11,9,22,7bt7x0,[R]The Best Sources to Study Machine Learning and AI: Quora Session Highlight,https://www.reddit.com/r/MachineLearning/comments/7bt7x0/rthe_best_sources_to_study_machine_learning_and/,digitalson,1510233316,,0,1
447,2017-11-9,2017,11,9,22,7bt9bl,"[N] Weekly Machine Learning Example &amp; Library Roundup  Nov. 9, 2017",https://www.reddit.com/r/MachineLearning/comments/7bt9bl/n_weekly_machine_learning_example_library_roundup/,stkim1,1510233781,,0,1
448,2017-11-9,2017,11,9,22,7btaln,[P] TensorForce 0.3: End-to-end computation graphs for RL,https://www.reddit.com/r/MachineLearning/comments/7btaln/p_tensorforce_03_endtoend_computation_graphs_for/,[deleted],1510234203,[deleted],0,1
449,2017-11-9,2017,11,9,22,7btd1l,[P] TensorForce 0.3: End-to-end computation graphs for RL,https://www.reddit.com/r/MachineLearning/comments/7btd1l/p_tensorforce_03_endtoend_computation_graphs_for/,[deleted],1510235000,[deleted],0,1
450,2017-11-9,2017,11,9,22,7btf1n,[P] TensorForce 0.3: End-to-end computation graphs for RL,https://www.reddit.com/r/MachineLearning/comments/7btf1n/p_tensorforce_03_endtoend_computation_graphs_for/,AlexKuhnle,1510235645,,4,12
451,2017-11-9,2017,11,9,23,7btivf,"[D] Thoughts about an ""IKEA challenge""",https://www.reddit.com/r/MachineLearning/comments/7btivf/d_thoughts_about_an_ikea_challenge/,fimari,1510236739,"I see a lack in measurements for progress in object abstraction. I would love to have a virtual world with objects and pictures of a plan - first simply arrange blocks and continuous advance to full scale complex furniture and even transfer into reality. 

Any thoughts and criticism?",2,0
452,2017-11-9,2017,11,9,23,7btpj7,[P] Real-time ASCII Art rendering using decision tree,https://www.reddit.com/r/MachineLearning/comments/7btpj7/p_realtime_ascii_art_rendering_using_decision_tree/,histoire_guy,1510238653,,33,172
453,2017-11-10,2017,11,10,0,7btu08,[D] Gaussian Distributions are Soap Bubbles: A post about unintuitive behavior in high-dimensions.,https://www.reddit.com/r/MachineLearning/comments/7btu08/d_gaussian_distributions_are_soap_bubbles_a_post/,fhuszar,1510239827,,33,77
454,2017-11-10,2017,11,10,0,7btu4p,"Question about python projects using tensorflow and other libraries, pls help me!",https://www.reddit.com/r/MachineLearning/comments/7btu4p/question_about_python_projects_using_tensorflow/,Liiiz21,1510239853,[removed],0,1
455,2017-11-10,2017,11,10,0,7btyg2,Automatic sauce filling line-piston filler and vacuum capping machine,https://www.reddit.com/r/MachineLearning/comments/7btyg2/automatic_sauce_filling_linepiston_filler_and/,hymachinery,1510240992,,0,1
456,2017-11-10,2017,11,10,0,7btylt,"Question about python projects using tensorflow and other libraries, pls help me!",https://www.reddit.com/r/MachineLearning/comments/7btylt/question_about_python_projects_using_tensorflow/,Liiiz21,1510241033,[removed],0,1
457,2017-11-10,2017,11,10,1,7bu8hr,Body wash bottle cap pressing sealing machine,https://www.reddit.com/r/MachineLearning/comments/7bu8hr/body_wash_bottle_cap_pressing_sealing_machine/,hymachinery,1510243525,,0,1
458,2017-11-10,2017,11,10,1,7bucys,[P] Implementing Pokedex from scratch Part I,https://www.reddit.com/r/MachineLearning/comments/7bucys/p_implementing_pokedex_from_scratch_part_i/,ericman93,1510244616,,6,12
459,2017-11-10,2017,11,10,1,7bufq4,[R] Please help me with my ML research by answering a few questions,https://www.reddit.com/r/MachineLearning/comments/7bufq4/r_please_help_me_with_my_ml_research_by_answering/,MLGJuan,1510245304,,7,0
460,2017-11-10,2017,11,10,1,7buiz9,"[D] Gradient Estimation, Variational Inference and Sample Efficiency",https://www.reddit.com/r/MachineLearning/comments/7buiz9/d_gradient_estimation_variational_inference_and/,Kiuhnm,1510246116,"My study of Reinforcement Learning has led me to *Variational Inference* and the problem of *Sample-efficient Gradient Estimation*, in general. I'm still exploring the connections. I think VI offers methods which can be applied to the gradient estimation problem as well. I'm thinking of the reparametrization trick, for instance.

Here are three interesting review articles:

1. [Neural Variational Inference: Classical Theory](http://artem.sobolev.name/posts/2016-07-01-neural-variational-inference-classical-theory.html)
1. [Stochastic Computation Graphs: Continuous Case](http://artem.sobolev.name/posts/2017-09-10-stochastic-computation-graphs-continuous-case.html)
1. [Stochastic Computation Graphs: Discrete Relaxations](http://artem.sobolev.name/posts/2017-10-28-stochastic-computation-graphs-discrete-relaxations.html)

I'm reading the third one right now.

For now I'm in a phase where I don't even know what I need to know, but here are some relevant papers I'll probably read:

* Alexander Kuhnle, Michael Schaarschmidt, Kai Fricke [End-to-end computation graphs for RL](https://reinforce.io/blog/end-to-end-computation-graphs-for-reinforcement-learning/?1) (2017)
* John Schulman, Nicolas Heess, et al. [Gradient Estimation Using Stochastic Computation Graphs](https://arxiv.org/abs/1506.05254) (2016)
* Scott Linderman, Christian Naesseth, and Francisco Ruiz [Reparameterization Gradients through Rejection Sampling Algorithms](https://casmls.github.io/general/2017/04/25/rsvi.html) (2017)
* Chris J. Maddison, Andriy Mnih, Yee Whye Teh [The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables](https://arxiv.org/abs/1611.00712) (2017)
* Eric Jang, Shixiang Gu, Ben Poole [Categorical reparameterization with gumbel-softmax](https://arxiv.org/abs/1611.01144) (2017)
* Shixiang Gu, Sergey Levine, et al. [MuProp: Unbiased Backpropagation for Stochastic Neural Networks](https://arxiv.org/abs/1511.05176) (2016)
* Francisco Ruiz, Michalis Titsias, David Blei [The Generalized Reparameterization Gradient](http://papers.nips.cc/paper/6328-the-generalized-reparameterization-gradient) (2016)
* Seiya Tokui, Issei Sato [Evaluating the Variance of Likelihood-Ratio Gradient Estimators](http://proceedings.mlr.press/v70/tokui17a/tokui17a.pdf) (2017)
* Will Grathwohl, Dami Choi, et al. [Backpropagation through the Void: Optimizing control variates for black-box gradient estimation](https://arxiv.org/abs/1711.00123) (2017)
* Andrew C Miller, Nicholas J Foti, et al. [Reducing reparameterization gradient variance](https://arxiv.org/abs/1705.07880) (2017)
* Tim Salimans, Jonathan Ho, Xi Chen, Ilya Sutskever [Evolution Strategies as a Scalable Alternative to Reinforcement Learning](https://arxiv.org/abs/1703.03864) (2017)
* Joe Staines, David Barber [Variational Optimization](https://arxiv.org/abs/1212.4507) (2012)
* George Tucker, Andriy Mnih, Chris J Maddison, and Jascha Sohl-Dickstein [Rebar: Low-variance, unbiased gradient estimates for discrete latent variable models](https://arxiv.org/abs/1703.07370) (2017)
* Gregory Kahn, Adam Villaflor, et al. [Self-supervised Deep Reinforcement Learning with Generalized Computation Graphs for Robot Navigation](https://arxiv.org/abs/1709.10489) (2017)

My main point of view is that of *Optimization*, but with an eye to *Robotics*.

# Invitation

If you're interested in these topics and you'd like to talk about it, please join the [RL Group](https://discord.gg/ydeA9Uf). For now there's only a channel called **#bayesian** (*BACKGROUND category*), but we can create as many channels as we need, of course.",4,6
461,2017-11-10,2017,11,10,1,7bulbw,Pytorch implementations of various Deep NLP models in cs-224n(Stanford Univ),https://www.reddit.com/r/MachineLearning/comments/7bulbw/pytorch_implementations_of_various_deep_nlp/,[deleted],1510246681,[deleted],0,1
462,2017-11-10,2017,11,10,2,7bunyf,Does anyone know how to have python display the logistic regression equation it came up with for a dataset?,https://www.reddit.com/r/MachineLearning/comments/7bunyf/does_anyone_know_how_to_have_python_display_the/,datafeeler,1510247287,[removed],0,1
463,2017-11-10,2017,11,10,2,7buq6m,Deep Learning From Scratch: TensorFlow,https://www.reddit.com/r/MachineLearning/comments/7buq6m/deep_learning_from_scratch_tensorflow/,deepideas,1510247819,,0,1
464,2017-11-10,2017,11,10,2,7buzvt,"[D] Looking for an image dataset of pairs of simple, normal objects and defective/deformed version of that object",https://www.reddit.com/r/MachineLearning/comments/7buzvt/d_looking_for_an_image_dataset_of_pairs_of_simple/,skepticforest,1510250179,"Let's say I want to train a CNN to tell normal objects and abnormal/defective objects apart. I want to know if there are any datasets out there that basically have normal and defective versions of the same object. 

For example, let's say my object of interest is a book. I'll need images of normal books and images of books with tears, stains, broken spines etc for the idea I have. Another example would be of cardboard boxes with bulges, tears etc or glass panes with cracks, holes etc. Basically deformations in objects that deviate it from the general shape of the object and can be localized somewhat with a bounding box, if possible.

If anyone has any information of similarly sounding datasets that can help me with this, I'd love to know. Thanks",5,2
465,2017-11-10,2017,11,10,3,7bvevy,[N] Seamless Google Street View Panoramas,https://www.reddit.com/r/MachineLearning/comments/7bvevy/n_seamless_google_street_view_panoramas/,[deleted],1510253663,[deleted],1,14
466,2017-11-10,2017,11,10,4,7bvhg7,Pursue masters degree or get a job?,https://www.reddit.com/r/MachineLearning/comments/7bvhg7/pursue_masters_degree_or_get_a_job/,savvaz,1510254219,[removed],0,1
467,2017-11-10,2017,11,10,4,7bvkma,"Logistic regression y = sigmoid(wT + b) as Ng says in the lecture, but where do w and b come from?",https://www.reddit.com/r/MachineLearning/comments/7bvkma/logistic_regression_y_sigmoidwt_b_as_ng_says_in/,[deleted],1510254911,,0,1
468,2017-11-10,2017,11,10,4,7bvmlz,Thoughts on how to most accurately segment a single person in standard pose?,https://www.reddit.com/r/MachineLearning/comments/7bvmlz/thoughts_on_how_to_most_accurately_segment_a/,willeffects,1510255390,[removed],0,1
469,2017-11-10,2017,11,10,4,7bvpjq,[P] Creating a Modern OCR Pipeline Using Computer Vision and Deep Learning,https://www.reddit.com/r/MachineLearning/comments/7bvpjq/p_creating_a_modern_ocr_pipeline_using_computer/,arnioxux,1510256095,,0,24
470,2017-11-10,2017,11,10,4,7bvrsr,[R] The Emergence of a Fovea while Learning to Attend,https://www.reddit.com/r/MachineLearning/comments/7bvrsr/r_the_emergence_of_a_fovea_while_learning_to/,gdny,1510256650,,8,39
471,2017-11-10,2017,11,10,5,7bvxit,Looking for video tutorial for complex ML app,https://www.reddit.com/r/MachineLearning/comments/7bvxit/looking_for_video_tutorial_for_complex_ml_app/,thu-trang,1510258029,[removed],0,1
472,2017-11-10,2017,11,10,5,7bw4ck,[D] Opinions on H2Os Driverless AI?,https://www.reddit.com/r/MachineLearning/comments/7bw4ck/d_opinions_on_h2os_driverless_ai/,htrp,1510259659,"We're evaluating some solutions for the firm and wanted to get opinions on Driverless AI 

https://www.h2o.ai/driverless-ai/

I'm trying to figure out what the difference between this and the offerings by DataRobot/others. 

Any hands-on experience ? ",3,0
473,2017-11-10,2017,11,10,5,7bw9qw,Useful Features of a Neural Net GUI Framework?,https://www.reddit.com/r/MachineLearning/comments/7bw9qw/useful_features_of_a_neural_net_gui_framework/,Mehdi2277,1510261014,[removed],0,1
474,2017-11-10,2017,11,10,6,7bwe57,"How is a binary classifier that guesses values based on distance away from known values in any way an ""intelligent machine""?",https://www.reddit.com/r/MachineLearning/comments/7bwe57/how_is_a_binary_classifier_that_guesses_values/,[deleted],1510262104,,0,1
475,2017-11-10,2017,11,10,6,7bwhr8,[Research] Learning visual and interpretable models from sequence data that contains chaotic symbols,https://www.reddit.com/r/MachineLearning/comments/7bwhr8/research_learning_visual_and_interpretable_models/,[deleted],1510263008,[deleted],0,1
476,2017-11-10,2017,11,10,6,7bwid9,[R] Learning visual and interpretable models from sequence data that contains chaotic symbols,https://www.reddit.com/r/MachineLearning/comments/7bwid9/r_learning_visual_and_interpretable_models_from/,TaXxER,1510263155,,0,1
477,2017-11-10,2017,11,10,6,7bwlxn,Sampling from latent vector in GAN,https://www.reddit.com/r/MachineLearning/comments/7bwlxn/sampling_from_latent_vector_in_gan/,asdfwaevc,1510264070,[removed],1,1
478,2017-11-10,2017,11,10,7,7bwt2b,"[D] How is a binary classifier that guesses values based on distance away from known values in any way an ""intelligent machine""?",https://www.reddit.com/r/MachineLearning/comments/7bwt2b/d_how_is_a_binary_classifier_that_guesses_values/,fosofyowq,1510265851,"Let's say I feed a tiny bit of data into a machine: 3 = true, 5 = true, 10 = false, 12 = false. Then I input 4, and ask the machine to guess if it's true or false. The machine uses the data it's been fed, 3 is true, 4 is 1 away from that, 5 is true, 4 is 1 away from that, average distance from the value I know are true = 1. 10 is false, 4 is 6 away from that, 12 is false, 4 is 8 away from that, average distance from the values I know are false = 7. 1 &lt; 7, therefore distance from ""true"" is smaller than distance from ""false"", so machine predicts that 4 = true.

This may be a very tiny example, but this is the way I've been basically understanding what a binary classification algorithm does. I fail to see how this constitutes an ""intelligent machine"". This seems like basic programming, it calculates an average distance of a new value based on al lthe distances of ""true"" vs ""false"" values of the values it already knows, then simply spits out the binary value with the smaller distance. This doesn't seem like a ""learning"" algorithm at all, it looks to me like this is a fixed algorithm that doesn't change its behavior and just does the same naive dumb thing to guess true or false every time. I mean, I could program this without using any of the popular ""trendy"" machine learning algorithms in use today, I could program this with zero knowledge of machine learning at all. Like, why would I need a ""sigmoid function"" or a ""support vector linear space"" or something else unnecessarily complex to make this? Sure, if you feed it more data to train on, then it might calculate a better and better average distance for true vs. false just by the sheer volume of data it already knows. But this really doesn't seem to me like it's an ""intelligent machine"" at all, it seems like it's applying a fixed equation on possibly variable amounts of training data, and will only perform differently if there are different amounts of data it's trained on. I thought machine learning was algorithms that don't define fixed behavior, this just seems like very fixed behavior to me, the amount of data changing things doesn't change the fact that this is a fixed algorithm.

So would somebody please help me understand why this ISN'T a fixed algorithm and why something that makes a T/F guess in this fashion constitutes an ""intelligent machine""?",10,0
479,2017-11-10,2017,11,10,7,7bwxj6,[P] Automatic Object Removal and Realistic Image Completion,https://www.reddit.com/r/MachineLearning/comments/7bwxj6/p_automatic_object_removal_and_realistic_image/,Al3xFreeman,1510267026,,0,33
480,2017-11-10,2017,11,10,8,7bxbh9,Created a plotting function using matplotlib that will plot a neural network of any dimensions when given the node values and weight matrices,https://www.reddit.com/r/MachineLearning/comments/7bxbh9/created_a_plotting_function_using_matplotlib_that/,[deleted],1510270753,[deleted],1,1
481,2017-11-10,2017,11,10,8,7bxco2,Podcasts?,https://www.reddit.com/r/MachineLearning/comments/7bxco2/podcasts/,Niceinvader,1510271089,[removed],0,1
482,2017-11-10,2017,11,10,8,7bxdyv,[P] Created a plotting function using matplotlib that will plot a neural network of any dimensions when given the node values and weight matrices,https://www.reddit.com/r/MachineLearning/comments/7bxdyv/p_created_a_plotting_function_using_matplotlib/,ITConnected,1510271469,,38,303
483,2017-11-10,2017,11,10,8,7bxeqy,Machine learning cluster architecture,https://www.reddit.com/r/MachineLearning/comments/7bxeqy/machine_learning_cluster_architecture/,kur1j,1510271693,[removed],0,1
484,2017-11-10,2017,11,10,9,7bxhoj,[R] Block-Sparse Recurrent Neural Networks,https://www.reddit.com/r/MachineLearning/comments/7bxhoj/r_blocksparse_recurrent_neural_networks/,snarang09,1510272569,,3,9
485,2017-11-10,2017,11,10,9,7bxpat,BGANs: Bayesian Generative Adversarial Networks.,https://www.reddit.com/r/MachineLearning/comments/7bxpat/bgans_bayesian_generative_adversarial_networks/,[deleted],1510274930,[deleted],0,1
486,2017-11-10,2017,11,10,10,7by08x,Deep Learning for Real-time Gravitational Wave Analysis with LIGO Data,https://www.reddit.com/r/MachineLearning/comments/7by08x/deep_learning_for_realtime_gravitational_wave/,[deleted],1510278072,[deleted],0,1
487,2017-11-10,2017,11,10,10,7by2ph,[P] Pytorch implementations of various Deep NLP models in cs-224n(Stanford Univ: NLP with Deep Learning),https://www.reddit.com/r/MachineLearning/comments/7by2ph/p_pytorch_implementations_of_various_deep_nlp/,dsksd,1510278800,,2,14
488,2017-11-10,2017,11,10,10,7by3h1,[R] Deep Learning for Real-time Gravitational Wave Analysis with LIGO Data,https://www.reddit.com/r/MachineLearning/comments/7by3h1/r_deep_learning_for_realtime_gravitational_wave/,dan7geo,1510279041,,9,63
489,2017-11-10,2017,11,10,11,7by77e,[R] Running Reinforcement Learning (DDPG+HER+other stuff) on a Simulated UR5,https://www.reddit.com/r/MachineLearning/comments/7by77e/r_running_reinforcement_learning_ddpgherother/,Cannon10100,1510280206,,1,3
490,2017-11-10,2017,11,10,11,7byd8h,[R] BGANs: Bayesian Generative Adversarial Networks.,https://www.reddit.com/r/MachineLearning/comments/7byd8h/r_bgans_bayesian_generative_adversarial_networks/,Nydhal,1510282071,,1,18
491,2017-11-10,2017,11,10,12,7bygbg,"Are neural nets the best option for creating something that ""feels""?",https://www.reddit.com/r/MachineLearning/comments/7bygbg/are_neural_nets_the_best_option_for_creating/,Neil5555,1510283072,[removed],0,1
492,2017-11-10,2017,11,10,14,7bz5x9,[D] ELI5: Capsule networks. How are they unique and how are they better than CNN?,https://www.reddit.com/r/MachineLearning/comments/7bz5x9/d_eli5_capsule_networks_how_are_they_unique_and/,rulerofthehell,1510291758,,22,82
493,2017-11-10,2017,11,10,14,7bz7lj,[D] What do you feel is currently undervalued / underappreciated in the field of machine learning?,https://www.reddit.com/r/MachineLearning/comments/7bz7lj/d_what_do_you_feel_is_currently_undervalued/,throwAwayObama,1510292363,,57,15
494,2017-11-10,2017,11,10,15,7bzjgg,Use Machine Learning to Enhance Customer Experience,https://www.reddit.com/r/MachineLearning/comments/7bzjgg/use_machine_learning_to_enhance_customer/,Aaryatech,1510296923,,0,1
495,2017-11-10,2017,11,10,16,7bzndg,Genetic algorithm: self-propelled satellites,https://www.reddit.com/r/MachineLearning/comments/7bzndg/genetic_algorithm_selfpropelled_satellites/,planelles,1510298513,,0,1
496,2017-11-10,2017,11,10,16,7bzp6i,ResNet-50 training on ImageNet in 15 minutes,https://www.reddit.com/r/MachineLearning/comments/7bzp6i/resnet50_training_on_imagenet_in_15_minutes/,jingoro56,1510299336,,0,1
497,2017-11-10,2017,11,10,16,7bzrrd,[D] What does the term 'agnostic' in the context of a Convolutional Neural Network mean?,https://www.reddit.com/r/MachineLearning/comments/7bzrrd/d_what_does_the_term_agnostic_in_the_context_of_a/,FantasyBorderline,1510300460,"I was reading [this](https://arxiv.org/pdf/1610.04823.pdf) paper about the effect of face frontalization on the accuracy of neural networks up to the discussion section where I encountered this:

&gt; Training a CNN with millions of face images makes
it relatively agnostic (in terms of recognition performance)
to the pre-processing method used on testing
data, e.g., pre-trained VGG-FACE performs consistently
across different experiments.

I don't understand the meaning of 'agnostic' in the context of a Neural Network. Does it say that training with millions of labeled face images make it able to recoginze the labels in a face in any condition/pose/lighting?",5,11
498,2017-11-10,2017,11,10,17,7bzt41,Modified Actor Critic Agent Achieves Super Human Level in Open AI Lunar Lander Test,https://www.reddit.com/r/MachineLearning/comments/7bzt41/modified_actor_critic_agent_achieves_super_human/,[deleted],1510301063,[deleted],0,1
499,2017-11-10,2017,11,10,17,7bzw25,[R] Summary of Key Aspects of Neural Capsules,https://www.reddit.com/r/MachineLearning/comments/7bzw25/r_summary_of_key_aspects_of_neural_capsules/,nianhao,1510302424,,4,68
500,2017-11-10,2017,11,10,17,7bzzpt,DATAPUB,https://www.reddit.com/r/MachineLearning/comments/7bzzpt/datapub/,danishxr,1510304217,,0,1
501,2017-11-10,2017,11,10,19,7c090v,Automatic Dough Rolling Machine In Hot Selling,https://www.reddit.com/r/MachineLearning/comments/7c090v/automatic_dough_rolling_machine_in_hot_selling/,liusherry,1510308542,,1,1
502,2017-11-10,2017,11,10,19,7c0f0q,Reinforcement Learning Agent displays supreme levels agility in OpenAi test.,https://www.reddit.com/r/MachineLearning/comments/7c0f0q/reinforcement_learning_agent_displays_supreme/,[deleted],1510311307,[deleted],0,1
503,2017-11-10,2017,11,10,20,7c0ief,Top &amp; Best Blog about Artificial Intelligence/Machine Learning/Deep Lear...,https://www.reddit.com/r/MachineLearning/comments/7c0ief/top_best_blog_about_artificial/,favouriteblog,1510312761,,1,1
504,2017-11-10,2017,11,10,20,7c0ieh,Global NIPS Paper Implementation Challenge,https://www.reddit.com/r/MachineLearning/comments/7c0ieh/global_nips_paper_implementation_challenge/,shubhamjain0594,1510312762,,0,2
505,2017-11-10,2017,11,10,21,7c0w2v,[D] More evidence that humans and machines are better when they team up,https://www.reddit.com/r/MachineLearning/comments/7c0w2v/d_more_evidence_that_humans_and_machines_are/,_alphamaximus_,1510318262,,0,1
506,2017-11-10,2017,11,10,22,7c13uj,3 Ways Machine Learning Tools Can Drive Sales Over the Holidays and After,https://www.reddit.com/r/MachineLearning/comments/7c13uj/3_ways_machine_learning_tools_can_drive_sales/,Victor_Stakh,1510320901,,0,1
507,2017-11-10,2017,11,10,22,7c1416,[P] Reddit Beer@NIPS 2017 ?,https://www.reddit.com/r/MachineLearning/comments/7c1416/p_reddit_beernips_2017/,pilooch,1510320959,"Anyone game for a Reddit mini gathering around NIPS 2017 next month ?

I'm willing to reproduce the laid back gathering from last year at NIPS 2016 in Barcelona. I am well aware that many may prefer to join the fancy and well catered corporate parties to be announced. There's no contradiction here. This subreddit is an anchor to the daily practice of many and I feel it's a great opportunity to meet in real life.

A local friend highly recommended to meet at the 'Blind Donkey' (http://www.theblinddonkey.com/long-beach), that he said reminded him of good old 'Amnesia' bar in San Francisco, may ring bells around here :)

Gathering would be around 9:30pm/10pm with no bounds into the night I guess.

I've put a Doodle to select the best day:
https://doodle.com/poll/sn73f9vexmvuc8yf

Peace",7,25
508,2017-11-10,2017,11,10,23,7c1b78,"[D] After Slurping Up AI Researchers, Facebook Offers to Share",https://www.reddit.com/r/MachineLearning/comments/7c1b78/d_after_slurping_up_ai_researchers_facebook/,ps_dillon,1510323167,,1,0
509,2017-11-10,2017,11,10,23,7c1bf1,linear regression and polynomial regression vs logistic regression,https://www.reddit.com/r/MachineLearning/comments/7c1bf1/linear_regression_and_polynomial_regression_vs/,AlanRoofies,1510323227,[removed],0,1
510,2017-11-10,2017,11,10,23,7c1ehg,frugally-deep - A header-only library for using Keras models in C++,https://www.reddit.com/r/MachineLearning/comments/7c1ehg/frugallydeep_a_headeronly_library_for_using_keras/,Dobias,1510324168,,2,2
511,2017-11-10,2017,11,10,23,7c1iso,Smile 1.5 Released,https://www.reddit.com/r/MachineLearning/comments/7c1iso/smile_15_released/,pdsminer,1510325412,,0,1
512,2017-11-10,2017,11,10,23,7c1jbi,An intro to Probabilistic Programming with Ubers Pyro,https://www.reddit.com/r/MachineLearning/comments/7c1jbi/an_intro_to_probabilistic_programming_with_ubers/,funmaster11,1510325557,,0,1
513,2017-11-11,2017,11,11,0,7c1nqd,[P] Actor Critic agent achieves super human level is n Open AI test,https://www.reddit.com/r/MachineLearning/comments/7c1nqd/p_actor_critic_agent_achieves_super_human_level/,[deleted],1510326736,[deleted],0,1
514,2017-11-11,2017,11,11,0,7c1orl,[P] Actor Critic agent achieves super human level on CPU in 4 hours and does tricks.,https://www.reddit.com/r/MachineLearning/comments/7c1orl/p_actor_critic_agent_achieves_super_human_level/,FitMachineLearning,1510327023,,9,21
515,2017-11-11,2017,11,11,0,7c1otf,Suggestions for NLP Reading Group papers,https://www.reddit.com/r/MachineLearning/comments/7c1otf/suggestions_for_nlp_reading_group_papers/,YourWelcomeOrMine,1510327033,[removed],0,1
516,2017-11-11,2017,11,11,0,7c1s8m,[P] Tensorboard graphs with Keras,https://www.reddit.com/r/MachineLearning/comments/7c1s8m/p_tensorboard_graphs_with_keras/,kerasbeginner,1510327980,"Hello there,

I'm more or less new to keras. I'm using Keras with a Tensorflow backend and now I'm trying to debug my models with Tensorboard. 
I got it running and in my opinion the graphs are kind of a mess even for simple models. By googling I found some links where some people thought it's because of the inproper labeling. What are your opinions?
Does anybody use Tensorboard with Keras and do you have tips for debugging and optimizing with Tensorboard? 
Or some tutorials for Tensorboard with Keras, all I could find were tutorials with Tensorflow.
Or do you have alternatives?

Thank you in advance.

A kerasbeginner",4,18
517,2017-11-11,2017,11,11,0,7c1t4y,How does InspiroBot work?,https://www.reddit.com/r/MachineLearning/comments/7c1t4y/how_does_inspirobot_work/,hristo_rv,1510328213,[removed],0,1
518,2017-11-11,2017,11,11,1,7c24li,[R] Programmatic Advertisement using Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7c24li/r_programmatic_advertisement_using_machine/,blackwalls81,1510331169,,8,93
519,2017-11-11,2017,11,11,1,7c27dj,"[D] If you don't know anything about machine learning/data science/AI development etc., are you going to get left behind in tech come next decade?",https://www.reddit.com/r/MachineLearning/comments/7c27dj/d_if_you_dont_know_anything_about_machine/,fosofyowq,1510331855,"I feel like this is going to happen, and it's going to happen as early as next decade. It astounds me how many tech industry workers know nothing about machine learning. How do you expect to survive in tech over the next several years unless you know machine learning?",61,20
520,2017-11-11,2017,11,11,1,7c2b42,[RandomForest] Method viable? General advice?,https://www.reddit.com/r/MachineLearning/comments/7c2b42/randomforest_method_viable_general_advice/,Drag0nDr0p,1510332812,[removed],0,1
521,2017-11-11,2017,11,11,2,7c2ofz,Superb Quality Manual Capsule Filling Machine Manufacturer,https://www.reddit.com/r/MachineLearning/comments/7c2ofz/superb_quality_manual_capsule_filling_machine/,dhananjaylodha1,1510336070,,0,1
522,2017-11-11,2017,11,11,3,7c2v1v,Solving XOR problem with C++,https://www.reddit.com/r/MachineLearning/comments/7c2v1v/solving_xor_problem_with_c/,chaeunl,1510337714,[removed],0,1
523,2017-11-11,2017,11,11,4,7c37bd,Anyone know of a Machine Learning Slack group?,https://www.reddit.com/r/MachineLearning/comments/7c37bd/anyone_know_of_a_machine_learning_slack_group/,relganz,1510340708,[removed],0,1
524,2017-11-11,2017,11,11,5,7c3tvg,AI Weekly 10 Nov 2017,https://www.reddit.com/r/MachineLearning/comments/7c3tvg/ai_weekly_10_nov_2017/,TomekB,1510346460,,0,1
525,2017-11-11,2017,11,11,5,7c3vpt,[R] Adversarially Optimizing Intersection over Union for Object Localization Tasks,https://www.reddit.com/r/MachineLearning/comments/7c3vpt/r_adversarially_optimizing_intersection_over/,riel234,1510346952,,1,2
526,2017-11-11,2017,11,11,5,7c3vul,[N] Tile: A New Language for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7c3vul/n_tile_a_new_language_for_machine_learning/,visarga,1510346985,,22,85
527,2017-11-11,2017,11,11,6,7c45sl,Engineering More Reliable Transportation with Machine Learning and AI at Uber,https://www.reddit.com/r/MachineLearning/comments/7c45sl/engineering_more_reliable_transportation_with/,__Julia,1510349594,,0,1
528,2017-11-11,2017,11,11,8,7c4ovn,Is there an efficient way to do online learning (w/ adaptive optimizer) with LSTMs? Maybe with PyTorch?,https://www.reddit.com/r/MachineLearning/comments/7c4ovn/is_there_an_efficient_way_to_do_online_learning_w/,zacheism,1510354895,[removed],0,1
529,2017-11-11,2017,11,11,9,7c59tg,State-of-the-art classification results on CIFAR-10 dataset?,https://www.reddit.com/r/MachineLearning/comments/7c59tg/stateoftheart_classification_results_on_cifar10/,[deleted],1510360985,,0,1
530,2017-11-11,2017,11,11,9,7c59xz,[D] State-of-the-art classification results on CIFAR-10 dataset?,https://www.reddit.com/r/MachineLearning/comments/7c59xz/d_stateoftheart_classification_results_on_cifar10/,crouching_dragon_420,1510361026,"What is the state-of-the-art result, including the latest papers in ICLR 2018? We have some research about a new regularization technique for CNN and we would like to test if it helps for the best models. Thank you.
",7,4
531,2017-11-11,2017,11,11,9,7c5bxe,Cam Arcade: Play classic DOS games with your webcam by training a neural network with deeplearn.js,https://www.reddit.com/r/MachineLearning/comments/7c5bxe/cam_arcade_play_classic_dos_games_with_your/,nikhilio,1510361623,,0,1
532,2017-11-11,2017,11,11,13,7c6dtf,New page for following recent advances at the intersection of machine learning and neuroscience. I have long struggled to keep up with this interdisciplinary research.,https://www.reddit.com/r/MachineLearning/comments/7c6dtf/new_page_for_following_recent_advances_at_the/,[deleted],1510374207,[deleted],0,1
533,2017-11-11,2017,11,11,13,7c6dy0,[D] How is the use of separable kernel(both spatial and depthwise) affect the power of a network?,https://www.reddit.com/r/MachineLearning/comments/7c6dy0/d_how_is_the_use_of_separable_kernelboth_spatial/,RavlaAlvar,1510374257,,0,2
534,2017-11-11,2017,11,11,13,7c6gv9,Question about the use of Facebook's prophet package/open source software in general,https://www.reddit.com/r/MachineLearning/comments/7c6gv9/question_about_the_use_of_facebooks_prophet/,Mister_Sebastipol,1510375342,[removed],0,1
535,2017-11-11,2017,11,11,16,7c749f,Capsule Networks Explained,https://www.reddit.com/r/MachineLearning/comments/7c749f/capsule_networks_explained/,[deleted],1510384795,[deleted],0,2
536,2017-11-11,2017,11,11,16,7c75x3,Which is the best online resource to learn about machine learning from the scratch?,https://www.reddit.com/r/MachineLearning/comments/7c75x3/which_is_the_best_online_resource_to_learn_about/,sauseke,1510385592,[removed],0,1
537,2017-11-11,2017,11,11,16,7c78sw,[R] Capsule Networks Explained,https://www.reddit.com/r/MachineLearning/comments/7c78sw/r_capsule_networks_explained/,kendrick__,1510387033,,32,123
538,2017-11-11,2017,11,11,17,7c7eod,[R] Groq claims a 400 TOP processor @ 8 TOPS/W in 2018,https://www.reddit.com/r/MachineLearning/comments/7c7eod/r_groq_claims_a_400_top_processor_8_topsw_in_2018/,darkconfidantislife,1510389993,,2,0
539,2017-11-11,2017,11,11,19,7c7pj3,[1711.00549] Just ASK: Building an Architecture for Extensible Self-Service Spoken Language Understanding,https://www.reddit.com/r/MachineLearning/comments/7c7pj3/171100549_just_ask_building_an_architecture_for/,non_linearity,1510395628,,1,1
540,2017-11-11,2017,11,11,19,7c7qvd,Acai  - A GUI for autogenerating Keras model code from graph diagrams [Link to source code in description],https://www.reddit.com/r/MachineLearning/comments/7c7qvd/acai_a_gui_for_autogenerating_keras_model_code/,Weihua99,1510396352,,0,1
541,2017-11-11,2017,11,11,19,7c7t7y,[E]200 universities just launched 600 free online courses. Heres the full list,https://www.reddit.com/r/MachineLearning/comments/7c7t7y/e200_universities_just_launched_600_free_online/,finallyifoundvalidUN,1510397613,,1,1
542,2017-11-11,2017,11,11,20,7c7vmp,Learn - Machine Learning A-Z: Hands-On Python &amp; R In Data Science,https://www.reddit.com/r/MachineLearning/comments/7c7vmp/learn_machine_learning_az_handson_python_r_in/,Gmaruti,1510398860,,0,1
543,2017-11-11,2017,11,11,20,7c7yed,Consciousness in the Universe is Scale Invariant and Implies an Event Horizon of the Human Brain | Meijer,https://www.reddit.com/r/MachineLearning/comments/7c7yed/consciousness_in_the_universe_is_scale_invariant/,phobrain,1510400256,,1,1
544,2017-11-11,2017,11,11,21,7c857i,[D] Classifying items in text,https://www.reddit.com/r/MachineLearning/comments/7c857i/d_classifying_items_in_text/,liondancer,1510403385,"Not sure if this is the correct place to post this as I am new to Machine learning. If my post is not related please point me to the right direction. 

I would like to learn the process and resources on how to classify recommended items in text. For example,

""Using Sony a6500 for its stabilization and great photo quality.""

The target item in that text is Sony a6500. 

",3,1
545,2017-11-11,2017,11,11,22,7c8cvu,Ensemble learning - different input same outputs.,https://www.reddit.com/r/MachineLearning/comments/7c8cvu/ensemble_learning_different_input_same_outputs/,refi11991,1510406600,[removed],0,1
546,2017-11-11,2017,11,11,22,7c8fza,Stock Price Prediction Using Tensorflow,https://www.reddit.com/r/MachineLearning/comments/7c8fza/stock_price_prediction_using_tensorflow/,[deleted],1510407846,[deleted],0,1
547,2017-11-11,2017,11,11,22,7c8i0h,[N] Deep|Bayes  Summer School on Deep Learning and Bayesian Methods,https://www.reddit.com/r/MachineLearning/comments/7c8i0h/n_deepbayes_summer_school_on_deep_learning_and/,asobolev,1510408615,,10,52
548,2017-11-11,2017,11,11,23,7c8l5l,[R] Stock Price Prediction Tutorial Using Tensorflow,https://www.reddit.com/r/MachineLearning/comments/7c8l5l/r_stock_price_prediction_tutorial_using_tensorflow/,Palamua,1510409710,,24,25
549,2017-11-12,2017,11,12,0,7c8v4h,HELP!!!! For A project,https://www.reddit.com/r/MachineLearning/comments/7c8v4h/help_for_a_project/,god_of_atheist,1510412977,[removed],0,1
550,2017-11-12,2017,11,12,1,7c9dur,Classifying category of supermarket items,https://www.reddit.com/r/MachineLearning/comments/7c9dur/classifying_category_of_supermarket_items/,savovs,1510418398,[removed],0,1
551,2017-11-12,2017,11,12,2,7c9lhu,Tensorflow: Basic utilization of trained neural net?,https://www.reddit.com/r/MachineLearning/comments/7c9lhu/tensorflow_basic_utilization_of_trained_neural_net/,[deleted],1510420486,,0,1
552,2017-11-12,2017,11,12,2,7c9n34,Spacy 2.0 Slow?,https://www.reddit.com/r/MachineLearning/comments/7c9n34/spacy_20_slow/,artificial_intel423,1510420939,[removed],0,1
553,2017-11-12,2017,11,12,2,7c9nng,ROCm and its progression,https://www.reddit.com/r/MachineLearning/comments/7c9nng/rocm_and_its_progression/,[deleted],1510421102,[deleted],0,1
554,2017-11-12,2017,11,12,2,7c9nnq,[D] Tensorflow: Basic utilization of trained neural net?,https://www.reddit.com/r/MachineLearning/comments/7c9nnq/d_tensorflow_basic_utilization_of_trained_neural/,My_Dumb_Q_Acct,1510421104,"Hello,

   I have a fairly dumb question about Tensorflow:  Every NN example I've come across has described network layer creation and training and computing accuracy but they all seem to leave off the step where you utilize the trained model to predict your outputs -- How is this accomplished?

   I'm starting with this basic example that trains a NN to output sin(x): https://github.com/delip/blog-stuff/blob/master/tensorflow_ufp.ipynb
After training it, I try to pass in a single X value to produce a single Y value, expecting Y=sin(X) but what I actually receive as output is garbage.
Can someone show me method definition to have this NN operate as a replacement for sin(X)?

Thank you in advance.",11,4
555,2017-11-12,2017,11,12,2,7c9oem,How do you determine accuracy of a product recommendation model?,https://www.reddit.com/r/MachineLearning/comments/7c9oem/how_do_you_determine_accuracy_of_a_product/,goph0r,1510421319,[removed],0,1
556,2017-11-12,2017,11,12,3,7c9w32,Hidden Semi Markov Models,https://www.reddit.com/r/MachineLearning/comments/7c9w32/hidden_semi_markov_models/,Lukakux,1510423400,[removed],0,1
557,2017-11-12,2017,11,12,3,7c9xll,Garbage Detection and Classification,https://www.reddit.com/r/MachineLearning/comments/7c9xll/garbage_detection_and_classification/,harshitgambhir,1510423806,[removed],0,1
558,2017-11-12,2017,11,12,3,7c9ylj,What are some great blogs like colah's blog for Deep Learning?,https://www.reddit.com/r/MachineLearning/comments/7c9ylj/what_are_some_great_blogs_like_colahs_blog_for/,[deleted],1510424070,,0,1
559,2017-11-12,2017,11,12,3,7c9zci,[D] 7 Takeaways from MLconf SF,https://www.reddit.com/r/MachineLearning/comments/7c9zci/d_7_takeaways_from_mlconf_sf/,bweber,1510424278,,0,2
560,2017-11-12,2017,11,12,3,7ca0wn,What is your favorite application of Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/7ca0wn/what_is_your_favorite_application_of_machine/,newdanny,1510424700,[removed],0,1
561,2017-11-12,2017,11,12,3,7ca10o,[R] Fused Video Stabilization on the Pixel 2 and Pixel 2 XL,https://www.reddit.com/r/MachineLearning/comments/7ca10o/r_fused_video_stabilization_on_the_pixel_2_and/,Jackal008,1510424723,,6,25
562,2017-11-12,2017,11,12,3,7ca2jm,What are some great blogs like colah's blog for Deep Learning?,https://www.reddit.com/r/MachineLearning/comments/7ca2jm/what_are_some_great_blogs_like_colahs_blog_for/,Hot_Ices,1510425148,[removed],0,1
563,2017-11-12,2017,11,12,5,7canff,See WHY Error Optimization is used in Machine Learning with a real-life example. Do check it out.,https://www.reddit.com/r/MachineLearning/comments/7canff/see_why_error_optimization_is_used_in_machine/,harshMachineLearning,1510430725,,0,1
564,2017-11-12,2017,11,12,5,7canqs,Demo for Salesforce Einstein Sentiment Analysis,https://www.reddit.com/r/MachineLearning/comments/7canqs/demo_for_salesforce_einstein_sentiment_analysis/,last_khajiit,1510430812,,0,1
565,2017-11-12,2017,11,12,5,7caxb1,[R] Case Study: Sign-to-Speech Glove,https://www.reddit.com/r/MachineLearning/comments/7caxb1/r_case_study_signtospeech_glove/,mel_silizar,1510433506,,8,73
566,2017-11-12,2017,11,12,7,7cbhg3,lstm benchmarking,https://www.reddit.com/r/MachineLearning/comments/7cbhg3/lstm_benchmarking/,mynameisvinn,1510439266,[removed],0,1
567,2017-11-12,2017,11,12,7,7cbiq1,Fellowship.AI London open house Nov 15,https://www.reddit.com/r/MachineLearning/comments/7cbiq1/fellowshipai_london_open_house_nov_15/,arshakn,1510439641,,0,1
568,2017-11-12,2017,11,12,8,7cbuz6,Issue with convergence with Stochastic Gradient Descent when approximating a sin curve with a polyonomial is not close to least squares solution,https://www.reddit.com/r/MachineLearning/comments/7cbuz6/issue_with_convergence_with_stochastic_gradient/,real_charlie_parker,1510443291,,0,1
569,2017-11-12,2017,11,12,8,7cbwx0,Understanding Deep Learning: The Information Bottleneck Connection,https://www.reddit.com/r/MachineLearning/comments/7cbwx0/understanding_deep_learning_the_information/,[deleted],1510443875,[deleted],0,1
570,2017-11-12,2017,11,12,8,7cbzo6,[R] Understanding Deep Learning: The Information Bottleneck Connection,https://www.reddit.com/r/MachineLearning/comments/7cbzo6/r_understanding_deep_learning_the_information/,LeenaShekhar,1510444733,,1,35
571,2017-11-12,2017,11,12,9,7cc5wg,[D] Multi-Scale Context Aggregation by Dilated Convolutions,https://www.reddit.com/r/MachineLearning/comments/7cc5wg/d_multiscale_context_aggregation_by_dilated/,theferalrobot,1510446501,"I am reading the paper, Multi-Scale Context Aggregation by Dilated Convolutions (https://arxiv.org/abs/1511.07122) 
 to try to understand dilated convolutions for semantic segmentation a bit better.

The authors propose using dilated convolution to get global context as opposed to max-pooling since pooling will shrink your image and dilated convolutions will not.

My first question is: They modify VGG16 and remove the last two max-pooling layers but they leave the other 3 max-pooling layers in. Why did they not just remove all the max pooling layers? Computational efficiency? Won't this result in a smaller image? How do they expand it back to the original size, bilinear interpolation? I didn't see that detailed in the paper so I wonder if my understanding might be off.

My second question is: They note in the paper:

&gt;We also remove the padding of the intermediate feature maps. Intermediate padding was used in the original classification network, but is neither necessary nor justified in dense prediction.

Why would that be the case? If you don't pad will you not further reduce the size of our final output, especially given that dilated convolutions can have very large receptive fields?",3,5
572,2017-11-12,2017,11,12,10,7ccetr,Inference of sequential events: what methods exist to do something like this?,https://www.reddit.com/r/MachineLearning/comments/7ccetr/inference_of_sequential_events_what_methods_exist/,Zeekawla99ii,1510449267,[removed],0,1
573,2017-11-12,2017,11,12,10,7ccjqy,Question,https://www.reddit.com/r/MachineLearning/comments/7ccjqy/question/,[deleted],1510450865,,0,1
574,2017-11-12,2017,11,12,12,7cd0u3,Issues with learning meaningful masks with unet segmentation networks,https://www.reddit.com/r/MachineLearning/comments/7cd0u3/issues_with_learning_meaningful_masks_with_unet/,reddit_tl,1510456485,,0,1
575,2017-11-12,2017,11,12,12,7cd4u2,Understanding college majors and salaries with k-means clustering,https://www.reddit.com/r/MachineLearning/comments/7cd4u2/understanding_college_majors_and_salaries_with/,ds2859,1510457882,,0,1
576,2017-11-12,2017,11,12,14,7cdlqf,Clever Methods of Overfitting (2005),https://www.reddit.com/r/MachineLearning/comments/7cdlqf/clever_methods_of_overfitting_2005/,sergeyfeldman,1510463842,,0,1
577,2017-11-12,2017,11,12,14,7cdov2,[N] Software 2.0 - Andrej Karpathy,https://www.reddit.com/r/MachineLearning/comments/7cdov2/n_software_20_andrej_karpathy/,visarga,1510465008,,87,98
578,2017-11-12,2017,11,12,15,7cdt4f,Question on Cuda - with ML and Deep Learning,https://www.reddit.com/r/MachineLearning/comments/7cdt4f/question_on_cuda_with_ml_and_deep_learning/,TheSmartHomeNinja,1510466667,[removed],0,1
579,2017-11-12,2017,11,12,16,7ce8oz,[D] detecting phobia triggers in video using ML?,https://www.reddit.com/r/MachineLearning/comments/7ce8oz/d_detecting_phobia_triggers_in_video_using_ml/,negaB,1510473490,"How possible is this? Say I want to watch a film and I am scared of spiders? Can I get an AI to scan the movie for me and give me warnings? Can it work for sounds too? Kinda like YouTube captions?

Ideally I would want to scan for anything. Fear of boxes? Trees? Choirs? Anything can be a phobia yeah? 

I wonder if we can already do it. I know of Clarifai which could be a good link.",5,4
580,2017-11-12,2017,11,12,17,7cebgk,"Building Dota Bots That Beat Pros - OpenAI's Greg Brockman, Szymon Sidor, and Sam Altman",https://www.reddit.com/r/MachineLearning/comments/7cebgk/building_dota_bots_that_beat_pros_openais_greg/,cosminro,1510474828,,0,1
581,2017-11-12,2017,11,12,18,7cei69,"Neural Network can mimic any function. But, is there a specific way to design the architecture, if one knows the mathematical model of the problem a priory. For example, I know that my output (Y) = Input(X)^2.",https://www.reddit.com/r/MachineLearning/comments/7cei69/neural_network_can_mimic_any_function_but_is/,Maunil_007,1510478207,[removed],0,1
582,2017-11-12,2017,11,12,19,7cep1k,Disney's Machine Learning To Render Clouds (Includes Paper: Deep Scattering: Rendering Atmospheric Clouds with Radiance-Predicting Neural Networks),https://www.reddit.com/r/MachineLearning/comments/7cep1k/disneys_machine_learning_to_render_clouds/,_invalidusername,1510481870,,0,1
583,2017-11-12,2017,11,12,20,7cev2t,[P] Fader Networks implementation in Tensorflow,https://www.reddit.com/r/MachineLearning/comments/7cev2t/p_fader_networks_implementation_in_tensorflow/,hardikbansal24,1510484986,,0,0
584,2017-11-12,2017,11,12,20,7ceyx0,[P] Crowd-sourcing for NER,https://www.reddit.com/r/MachineLearning/comments/7ceyx0/p_crowdsourcing_for_ner/,27568513,1510486822,"Hi, I'm looking for resources or papers on crowd-based named entitiy recognition that I want to use for a presentation and a small project. 

I already gathered some papers but maybe there's more out there.

Thank you! 
",2,1
585,2017-11-12,2017,11,12,21,7cf3y1,"[D] Regression output range, [-1, 1]or[0, 1] vs [-inf, inf]",https://www.reddit.com/r/MachineLearning/comments/7cf3y1/d_regression_output_range_1_1or0_1_vs_inf_inf/,fpenguin23,1510489120,"Hello redditors. Currently I'm trying to solve regression problem with deep neural network. I have some problems and I couldn't find appropriate answers from google so I'm here to ask your ideas. 




**Current problem**

My data samples are in [0, 1]^N. Because of this range, I had to use sigmoid(or tanh) as activation of output layer(Other layer's activations are all ReLU). However this cause serious problem which is gradient vanishing. After certain training epochs, my network became very hard to be trained. 





**My idea to solve this problem**

With simple assumption, I can transform the data samples into [-inf, inf]^(N-1) but this is just theoretical boundary. After this transformation most of data will be in [-1, 1]^(N-1). And rest of them will not diverge.(But those will have quite large number). 
In this case, I can use same network but different output layer which output [-inf, inf]^(N-1) vector(after that I will transform it back to N dimensional vector and solve the same problem). In this situation, I can use linear activation as output layer's activation function(or other non-linear function which has output range [-inf, inf]). 



But I don't know which one is better decision. Also I'm still hesitating to use linear function as activation function of last layer since I couldn't imagine potential problem which is caused by using it. Do you have any ideas?
",23,16
586,2017-11-12,2017,11,12,21,7cf7ba,[D] Lot of misconceptions around capsules network?,https://www.reddit.com/r/MachineLearning/comments/7cf7ba/d_lot_of_misconceptions_around_capsules_network/,hapliniste,1510490645,"Hello, I have read some posts and watched the lecture of G. H. and to me, it seems a lot of the intuitions on why we need it are simply wrong.
[I'll refer to this post because it's short and talk about the basic ideas of CN vs classic CNN.](https://kndrck.co/posts/capsule_networks_explained/)


Firstly, I would say that rotation equivariance is cool, but we could build a layer in a CNN to do the same. I'm not sure I understood why capsules networks would solve it (it has to be some learned function if it use the activation of some neurons and output the rotation. It is not something that will emerge out of nowhere with capsules networks).

The part about translation invariance/equivariance is simply wrong to me. 


&gt; ConvNets are unable to identify the position of one object relative to another, they can only identify if the object exists in a certain region, or not. This results in difficulty correctly identifying objects that have sub-objects that hold positional relationships relative to one another.

This is just wrong, isn't it? we're not talking about a single layer CNN, the kernels learned for the representation of ""Face"" will just not activate if the underlying representations (eye, nose, mouth) are not in the correct position. If we used a 1x1 kernel, yeah, we couldn't work with the spaciality of the data, but I don't even know why this is an argument. CNN allow for positional logic, but keeps the data in a 2D state, instead of making it ""0D"" and embedding the position inside the representation.

&gt; In order for the ConvNets to be translation invariant, it has to learn different filters for each different viewpoints, and in doing so it requires a lot of data.

Is the term ""viewpoint"" used as ""where is the data we use with the kernel"" or something about 3D-&gt;2D projection that happen with photo? Of course a CNN will not know out of nowhere to represent the 3D world, it doens't even know this is a thing. 

If the term is used as ""where do we apply the kernel"" then it is simply wrong (in fact it say the opposite of the truth). A face on the left and on the right of an image will output the same neuron activity! Even at epoch 1. It is how Conv work and it makes it so the network dont need to learn it (if the data is ""face, 5, 10"" and ""face, 45, 100"" the network surely will need to learn to work with it. but with convs it is embedded inside the model).

Dynamic routing on the other hand seems like a good idea, but it is simply pruning on neural activity to me. Pruning done with a NN if I understood, but still. It makes it more efficient and it's a path to look at for the future of ML when we will have huge networks and won't be able to run every signle neurons at a time, but I don't think it give something more useful than more performance in our models.

If I wrong can you tell me? I feel like this is so overhyped.
",6,82
587,2017-11-12,2017,11,12,22,7cf9va,Deconstructing Data Science,https://www.reddit.com/r/MachineLearning/comments/7cf9va/deconstructing_data_science/,ajva1996,1510491748,[removed],0,1
588,2017-11-12,2017,11,12,23,7cfs1i,[P] Customer Support on Twitter - New Dataset of &gt; 1M Tweets and Replies from Biggest Brands on Twitter,https://www.reddit.com/r/MachineLearning/comments/7cfs1i/p_customer_support_on_twitter_new_dataset_of_1m/,blowjobtransistor,1510498434,,8,38
589,2017-11-13,2017,11,13,0,7cg4hy,"TensorForce 0.3: End-to-end computation graphs for RL / pure TF natural gradients, evolutionary etc",https://www.reddit.com/r/MachineLearning/comments/7cg4hy/tensorforce_03_endtoend_computation_graphs_for_rl/,aeoost,1510502153,,0,1
590,2017-11-13,2017,11,13,1,7cge6e,[R] The effective receptive field on CNNs,https://www.reddit.com/r/MachineLearning/comments/7cge6e/r_the_effective_receptive_field_on_cnns/,perone,1510504850,,4,11
591,2017-11-13,2017,11,13,2,7cgoyg,[R] A Reinforcement Learning primer - Everything You Need to Know to Get Started in RL,https://www.reddit.com/r/MachineLearning/comments/7cgoyg/r_a_reinforcement_learning_primer_everything_you/,joshgreaves,1510507679,,19,279
592,2017-11-13,2017,11,13,3,7ch3j4,[R] spaCy 2's named entity recognition model: Incremental parsing with Bloom embeddings and residual CNNs (1h video),https://www.reddit.com/r/MachineLearning/comments/7ch3j4/r_spacy_2s_named_entity_recognition_model/,syllogism_,1510511409,,2,30
593,2017-11-13,2017,11,13,3,7cha5p,[D] What happens when watching a chinese guy constantly doing vector calculus on a whiteboard gets too boring for you?,https://www.reddit.com/r/MachineLearning/comments/7cha5p/d_what_happens_when_watching_a_chinese_guy/,fosofyowq,1510513134,[removed],34,0
594,2017-11-13,2017,11,13,5,7chpe8,[D] How much money do you spend on computations?,https://www.reddit.com/r/MachineLearning/comments/7chpe8/d_how_much_money_do_you_spend_on_computations/,mkierson,1510516957,"As need for GPU computations is growing rapidly I have a few questions to get an insights on GPU usage for machine learning.

How much money do you spend on computations on a monthly basis?
Do you spend more on cloud GPUs or invest in your own hardware?
Do you think about electricity cost in case of using own hardware?",5,0
595,2017-11-13,2017,11,13,6,7cical,"Idea: What if we used capsule networks create ontologies from corpuses of text, speech and vision? Ontologies which would then be used by intelligent agents ",https://www.reddit.com/r/MachineLearning/comments/7cical/idea_what_if_we_used_capsule_networks_create/,dakoto747,1510522811,[removed],0,1
596,2017-11-13,2017,11,13,6,7cid74,Choosing between 2 research labs for the summer,https://www.reddit.com/r/MachineLearning/comments/7cid74/choosing_between_2_research_labs_for_the_summer/,[deleted],1510523040,,0,1
597,2017-11-13,2017,11,13,7,7cio13,Multivariate data in time series forecasting,https://www.reddit.com/r/MachineLearning/comments/7cio13/multivariate_data_in_time_series_forecasting/,[deleted],1510525827,,0,1
598,2017-11-13,2017,11,13,7,7ciqp5,[Discussion] Choosing between two research labs for the summer,https://www.reddit.com/r/MachineLearning/comments/7ciqp5/discussion_choosing_between_two_research_labs_for/,ghalgy,1510526497,"My goal is to go the PhD route in machine learning with a focus in biotechnology applications. Currently I am working at my campus hospital doing data analysis and machine learning on cognitive and EEG data. Over the summer there is an opportunity for me to continue my work there or join a dedicated machine learning lab at my university.
On one hand, the problems I get to solve at the hospital are really interesting and there is a possibility I can publish if I continue working there. But on the other hand I'm not quite sure the level of machine learning done is to the same extent as what goes on in a dedicated machine learning lab. I will communicate with the professor I am working with at the hospital to clarify what kind of machine learning opportunities they have, but I would also like a second opinion here in case anyone has had a similar experience.",4,4
599,2017-11-13,2017,11,13,8,7ciwgf,How to estimate predictive power of input features?,https://www.reddit.com/r/MachineLearning/comments/7ciwgf/how_to_estimate_predictive_power_of_input_features/,[deleted],1510527976,,0,1
600,2017-11-13,2017,11,13,9,7cjhyc,A simple Python script I made for scraping training image data from Google Images,https://www.reddit.com/r/MachineLearning/comments/7cjhyc/a_simple_python_script_i_made_for_scraping/,bjabr,1510533979,,0,1
601,2017-11-13,2017,11,13,11,7ck17l,[D]How to estimate the predictive power of input features?,https://www.reddit.com/r/MachineLearning/comments/7ck17l/dhow_to_estimate_the_predictive_power_of_input/,wencc,1510539579,Are there techniques assess the general predictive power of input feature with respect to the output? I guess an easier question would be how can I tell there is a concept maps from the input features to the output which achieves non-trivial error rate?,5,0
602,2017-11-13,2017,11,13,12,7ckab3,"Using Tensorflow tflearn, and Atari BreakOut (GYM, openAI)",https://www.reddit.com/r/MachineLearning/comments/7ckab3/using_tensorflow_tflearn_and_atari_breakout_gym/,Beanboy_31,1510542402,[removed],0,1
603,2017-11-13,2017,11,13,12,7ckbte,Vermicompost organic fertilizer making machine,https://www.reddit.com/r/MachineLearning/comments/7ckbte/vermicompost_organic_fertilizer_making_machine/,amylee516,1510542853,,0,1
604,2017-11-13,2017,11,13,12,7ckceh,Disappointed with the State of NLP,https://www.reddit.com/r/MachineLearning/comments/7ckceh/disappointed_with_the_state_of_nlp/,[deleted],1510543032,,0,1
605,2017-11-13,2017,11,13,12,7ckdh2,Github repo for *A Deep Reinforcement Learning Framework for the Financial Portfolio Management Problem*,https://www.reddit.com/r/MachineLearning/comments/7ckdh2/github_repo_for_a_deep_reinforcement_learning/,DixingXu,1510543349,,0,1
606,2017-11-13,2017,11,13,12,7ckdjd,"[D] Are there any direct applications of real or complex analysis in machine learning? If so, how?",https://www.reddit.com/r/MachineLearning/comments/7ckdjd/d_are_there_any_direct_applications_of_real_or/,gerradisgod,1510543370,,11,25
607,2017-11-13,2017,11,13,12,7ckejw,[D] Do you also feel disappointed about the state of NLP?,https://www.reddit.com/r/MachineLearning/comments/7ckejw/d_do_you_also_feel_disappointed_about_the_state/,disappointedwithnlp,1510543688,"I am somewhat disappointed with the lack of progress in the NLP area. 

Around 2014 - 2015, there was a lot of interesting work going on in the field: external memories, reasoning, unsupervised and semi-supervised learning, chat bots, question answering, generating text from images... 

Now I feel like most of this hasn't materialized and research has moved on to GANs and RL.

Do you share my view? Is it too early for a breakthrough in NLP?",39,32
608,2017-11-13,2017,11,13,13,7ckml0,I want to understand Machine Learning well enough to build and implement my own ML models that can actually be useful towards some goal.,https://www.reddit.com/r/MachineLearning/comments/7ckml0/i_want_to_understand_machine_learning_well_enough/,enaluz,1510546176,[removed],0,1
609,2017-11-13,2017,11,13,13,7ckoey,Who first formally propose Convolution Neural Network ?,https://www.reddit.com/r/MachineLearning/comments/7ckoey/who_first_formally_propose_convolution_neural/,gaopengzju,1510546773,[removed],0,1
610,2017-11-13,2017,11,13,13,7ckquh,[P] Evolving Stable Strategies,https://www.reddit.com/r/MachineLearning/comments/7ckquh/p_evolving_stable_strategies/,inarrears,1510547603,,3,33
611,2017-11-13,2017,11,13,13,7ckspu,Can MachineLearning help me achieve this?,https://www.reddit.com/r/MachineLearning/comments/7ckspu/can_machinelearning_help_me_achieve_this/,iKSv2,1510548234,[removed],0,1
612,2017-11-13,2017,11,13,14,7ckvw2,[Q] Should I build a rig with 1080 Ti or 3x 1050 Ti to train multiple modelssimultaneously?,https://www.reddit.com/r/MachineLearning/comments/7ckvw2/q_should_i_build_a_rig_with_1080_ti_or_3x_1050_ti/,tu_tan,1510549306,[removed],0,1
613,2017-11-13,2017,11,13,15,7cl735,Driverless car in 2020 Debut - FavouriteBlog.com,https://www.reddit.com/r/MachineLearning/comments/7cl735/driverless_car_in_2020_debut_favouriteblogcom/,favouriteblog,1510553050,,1,1
614,2017-11-13,2017,11,13,15,7cl7hw,Generating the conditional vector from a conditional GAN,https://www.reddit.com/r/MachineLearning/comments/7cl7hw/generating_the_conditional_vector_from_a/,Jxieeducation,1510553188,[removed],0,1
615,2017-11-13,2017,11,13,15,7cl7ud,Generating the conditional vector from a trained conditional GAN,https://www.reddit.com/r/MachineLearning/comments/7cl7ud/generating_the_conditional_vector_from_a_trained/,jxieeducation1,1510553310,[removed],0,1
616,2017-11-13,2017,11,13,15,7cl9pe,Generating the conditional vector from a conditional GAN,https://www.reddit.com/r/MachineLearning/comments/7cl9pe/generating_the_conditional_vector_from_a/,treechoper123,1510553950,[removed],0,1
617,2017-11-13,2017,11,13,15,7clcgx,What kind of manifold transformation does soft/hard attention learn?,https://www.reddit.com/r/MachineLearning/comments/7clcgx/what_kind_of_manifold_transformation_does/,yashchandak,1510554980,[removed],0,1
618,2017-11-13,2017,11,13,16,7clibx,Gradient descent - probably the simplest and also most widely used optimization routine. But why does it work?,https://www.reddit.com/r/MachineLearning/comments/7clibx/gradient_descent_probably_the_simplest_and_also/,rohitpandey576,1510557273,,1,1
619,2017-11-13,2017,11,13,16,7cllbi,"Artificial Intelligence, Machine learning and Deep learning These Are The Differences, Similarity And Their Integrity",https://www.reddit.com/r/MachineLearning/comments/7cllbi/artificial_intelligence_machine_learning_and_deep/,Marry_owen,1510558467,,0,1
620,2017-11-13,2017,11,13,16,7clopc,A question about how to improve RL.,https://www.reddit.com/r/MachineLearning/comments/7clopc/a_question_about_how_to_improve_rl/,[deleted],1510559908,,0,1
621,2017-11-13,2017,11,13,17,7clpiw,Kodiak: a library to ease your feature engineering workflow,https://www.reddit.com/r/MachineLearning/comments/7clpiw/kodiak_a_library_to_ease_your_feature_engineering/,pierodellafrancesca,1510560252,,0,1
622,2017-11-13,2017,11,13,17,7clsce,Is my understanding of current (2017) machine learning correct?,https://www.reddit.com/r/MachineLearning/comments/7clsce/is_my_understanding_of_current_2017_machine/,sasa_buklijas,1510561452,[removed],0,1
623,2017-11-13,2017,11,13,17,7clslr,[D] A question about how to improve RL.,https://www.reddit.com/r/MachineLearning/comments/7clslr/d_a_question_about_how_to_improve_rl/,LockeLin,1510561568,"This is my homework. My professor asked me to improve the catmouse game performance.

http://www.cse.unsw.edu.au/~cs9417ml/RL1/applet.html

When mouse gets cheese, mouse gets 1 score. When cat catches mouse, cat gets 1 score.

The performance is mouse score / ( mouse score + cat score ).

I has tried two ways to do. But it doesn't work.

https://github.com/KunyiLockeLin/catmouse

The first way is every steps minus one reward.  It makes the mouse wants to move to illegal direction, like walls and trash cans, because in illegal direction, it doesn't have penalty record. But in fact, the mouse can't move to illegal place. As a result, it causes the mouse stops moving until the cat catches it.

The second way is to avoid illegal action. But it doesn't help.

So I have no idea how to do that.",2,0
624,2017-11-13,2017,11,13,17,7cltc6,Are there specific architectures for single class saliency mapping?,https://www.reddit.com/r/MachineLearning/comments/7cltc6/are_there_specific_architectures_for_single_class/,[deleted],1510561917,,0,1
625,2017-11-13,2017,11,13,19,7cm5rs,Reinforcement learning Applications,https://www.reddit.com/r/MachineLearning/comments/7cm5rs/reinforcement_learning_applications/,WulveriNn,1510567354,[removed],0,1
626,2017-11-13,2017,11,13,19,7cm8l4,[D] How would you describe the field of Machine Learning in your own words?,https://www.reddit.com/r/MachineLearning/comments/7cm8l4/d_how_would_you_describe_the_field_of_machine/,FantasyBorderline,1510568576,"Partly inspired from that XKCD comic about machine learning/SVMs.

Mine:

You've got all these data/images/sounds, and you know the labels or the outputs of the data/images/sounds. However, since you really don't want to make a formula classifying new data according to the labels of the aforementioned data by hand (I've tried using DLIB's landmark detector to classify gender and age using landmark ratios, and it turned out... poorly), you get the computer to learn how to get the formula/weights and biases instead.

Convolutional Neural Networks = Get features from the image using a 5x5 or whatever size square or rectangle slid over the image per pixel, then do it recursively (sometimes with downsampling or batch normalization) for a few times, then pass the resulting feature data into a dense/weights layer for the computer to calculate the optimum weights to output the labels. If the results aren't satisfactory, add or modify the layers until it 'starts looking right'. Train it too little, it'll fail to find the formula or become too generalized. Train it too much, however, you'll get a network that's so specific it gets confused on how to classify new data that doesn't conform with the existing one.",13,0
627,2017-11-13,2017,11,13,19,7cmbww,[D] Loss function of mixed type output,https://www.reddit.com/r/MachineLearning/comments/7cmbww/d_loss_function_of_mixed_type_output/,ipoppo,1510570040,"In AGZ paper, DeepMind squash two PG and value network into single net and with the loss function
&gt; L = (z-v)^2 - pi^T log p + (L2 reg)

Even this is a mixed type. This is still OK since reward of RL in AGZ is {-1,+1}. 

However if reward in arbitrary number then loss function of linear loss + logistic loss could be a problem if it is not well balance then one loss would outweighed entire loss function. 

Do this mean we have to go back to 2 network models? or find better bounded reward function?",1,3
628,2017-11-13,2017,11,13,20,7cmewv,Automatic Clod Rice Noodle Making Machine | Rice Noodle Machine,https://www.reddit.com/r/MachineLearning/comments/7cmewv/automatic_clod_rice_noodle_making_machine_rice/,liusherry,1510571305,,1,1
629,2017-11-13,2017,11,13,20,7cmg7p,[R]The growing importance of machine learning in real estate transactions,https://www.reddit.com/r/MachineLearning/comments/7cmg7p/rthe_growing_importance_of_machine_learning_in/,molode,1510571802,,0,1
630,2017-11-13,2017,11,13,20,7cmhee,Automatic Dry Noodle Making Machine For Sale,https://www.reddit.com/r/MachineLearning/comments/7cmhee/automatic_dry_noodle_making_machine_for_sale/,liusherry,1510572276,,1,1
631,2017-11-13,2017,11,13,21,7cmoeh,[R] [1711.02326v1] Sparse Attentive Backtracking: Long-Range Credit Assignment in Recurrent Networks,https://www.reddit.com/r/MachineLearning/comments/7cmoeh/r_171102326v1_sparse_attentive_backtracking/,bubaonaruba,1510575004,,1,7
632,2017-11-13,2017,11,13,21,7cms4o,[R] Breaking the Softmax Bottleneck: A High-Rank RNN Language Model,https://www.reddit.com/r/MachineLearning/comments/7cms4o/r_breaking_the_softmax_bottleneck_a_highrank_rnn/,blowjobtransistor,1510576339,,27,80
633,2017-11-13,2017,11,13,21,7cmvg2,[N] Deep Learning is Eating Software,https://www.reddit.com/r/MachineLearning/comments/7cmvg2/n_deep_learning_is_eating_software/,190807,1510577518,,5,0
634,2017-11-13,2017,11,13,23,7cn9bn,[Discussion] Part 2  Blazingly Hot Applications of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7cn9bn/discussion_part_2_blazingly_hot_applications_of/,kshehzi,1510581860,,4,2
635,2017-11-13,2017,11,13,23,7cngwi,[D] Fuzzy ART Capsule networks?,https://www.reddit.com/r/MachineLearning/comments/7cngwi/d_fuzzy_art_capsule_networks/,Turcik,1510583952,"Since I've read the ""Dynamic routing between capsules"" paper, it seemed to me that the idea of routing is quite similar to the idea found in Fuzzy ART networks: for each sample vector, find the neuron whose parameter vector best matches the input according to some similarity metric. In the case of Fuzzy ART networks, there is also a similarity threshold used to decide if a neuron can be committed to a sample. Also, if no neuron with a similarity above the threshold is found, then a new neuron is created.

I think a similar idea could be applied to Capsule networks but I may be wrong, so the purpose of this post is to discuss this idea and maybe to come up with some implementation if it seems feasible. In short, I think that a dynamic list of capsules can be used, and the routing algorithm proposed in the paper can be replaced with a similar routing to that used in Fuzzy ART networks (but perhaps still using the metric proposed in the capsules paper). Once a winner capsule is found, only that capsule is used in the backprop stage (although maybe all/a subset of the capsules can be used by taking into account how well each of them correlates to the input feature vector - however I don't know if this would be useful). The benefit of this approach is that you don't have to choose the number of capsules in advance, or that at least you can increase the number of capsules on the fly. The downside is that the network becomes sensitive to the order of training samples (or at least this was an issue when doing online learning with Fuzzy ART networks). The possibility of doing online learning with this type of Fuzzy ART Capsule networks is also an interesting thing to consider.

Lastly, there are also other ART networks that may be interesting to study, for example the Gaussian ART which I think is somewhat similar to the EM routing proposed in the second paper.",6,15
636,2017-11-14,2017,11,14,1,7co0mc,No AI involved in this audiovisual synchronization just yet. Painting by Andr Labb from Montral and musical samples mashup by Stephane Poirier,https://www.reddit.com/r/MachineLearning/comments/7co0mc/no_ai_involved_in_this_audiovisual/,humanaware,1510588818,,0,1
637,2017-11-14,2017,11,14,1,7cockz,[R] DiracNets: Training Very Deep Neural Networks Without Skip-Connections,https://www.reddit.com/r/MachineLearning/comments/7cockz/r_diracnets_training_very_deep_neural_networks/,baylearn,1510591529,,22,83
638,2017-11-14,2017,11,14,1,7codi0,Benchmark result on SUSY dataset,https://www.reddit.com/r/MachineLearning/comments/7codi0/benchmark_result_on_susy_dataset/,rajesh_d24,1510591721,[removed],0,1
639,2017-11-14,2017,11,14,3,7cow2i,AMD's ROCm 1.7 with TensorFlow support is coming!,https://www.reddit.com/r/MachineLearning/comments/7cow2i/amds_rocm_17_with_tensorflow_support_is_coming/,memes_everywhere,1510596008,,0,1
640,2017-11-14,2017,11,14,3,7cp46v,Why is the space of parameters in neural networks not Euclidean?,https://www.reddit.com/r/MachineLearning/comments/7cp46v/why_is_the_space_of_parameters_in_neural_networks/,udgrahita,1510597839,[removed],0,1
641,2017-11-14,2017,11,14,3,7cp480,Machine Learning Assisted Clinical Medicine Experfy Online Course,https://www.reddit.com/r/MachineLearning/comments/7cp480/machine_learning_assisted_clinical_medicine/,elli1789,1510597845,,0,1
642,2017-11-14,2017,11,14,4,7cpm85,AMD Announces ROCm 1.7 with TensorFlow Support,https://www.reddit.com/r/MachineLearning/comments/7cpm85/amd_announces_rocm_17_with_tensorflow_support/,Jasonian_,1510601806,,0,1
643,2017-11-14,2017,11,14,5,7cptqi,[D]computer vision:any algorithms to detect slightly deformed object...to identify object and what part is broken,https://www.reddit.com/r/MachineLearning/comments/7cptqi/dcomputer_visionany_algorithms_to_detect_slightly/,spartan12321,1510603475,"I'm looking for any research that can bring us further toward solution for this problem: lets say part of my desk is ""broken""(like I sawed off upper right corner...now its missing, together with leg that supported desk in this corner)...is there any research papers in direction of algorithm that could identify my ""broken"" desk with desk that is missing one leg and lets say square meter of missing wood?",9,1
644,2017-11-14,2017,11,14,5,7cpxh4,Help define a ML problem - x features(categorical) and y outputs(numerical),https://www.reddit.com/r/MachineLearning/comments/7cpxh4/help_define_a_ml_problem_x_featurescategorical/,harpreetsingh0,1510604327,[removed],0,1
645,2017-11-14,2017,11,14,5,7cq1zi,What's the inspiration for convolutional neural networks?,https://www.reddit.com/r/MachineLearning/comments/7cq1zi/whats_the_inspiration_for_convolutional_neural/,nticaric,1510605354,[removed],0,2
646,2017-11-14,2017,11,14,6,7cq9o9,[D] Research topic for a high school student,https://www.reddit.com/r/MachineLearning/comments/7cq9o9/d_research_topic_for_a_high_school_student/,ax_920,1510607032,"For my extended essay portion of IB, a 4000-word essay, I want to do something in the realm of machine learning. The topic I am thinking of doing is along the lines of: how many neurons should you use? I was thinking of finding the relationship between the numbers of neurons used and the accuracy of the neural network. For example, I was reading an example of regression analysis where the factors such as cylinders, displacement, horsepower affect the mpg of a car. The topic would touch on how many of these factors, or neurons is too much. I don't know that much about machine learning, so I was wondering if you guys think this is a topic worth writing about.",10,1
647,2017-11-14,2017,11,14,6,7cqa9i,Need help implementing a Sequence Classifier LSTM in Keras and Theano,https://www.reddit.com/r/MachineLearning/comments/7cqa9i/need_help_implementing_a_sequence_classifier_lstm/,peep186,1510607158,[removed],0,1
648,2017-11-14,2017,11,14,7,7cqxb5,A practical tutorial to understand Convolutional Neural Networks and apply them to a concrete image classification problem using Keras and Tensorflow,https://www.reddit.com/r/MachineLearning/comments/7cqxb5/a_practical_tutorial_to_understand_convolutional/,ahmedbesbes,1510612450,,0,1
649,2017-11-14,2017,11,14,7,7cqyqa,"Can I categorise machine learning techniques (Bayesian Network, Neural nets etc) into types of recommender system (Collaborative, Content-Cased etc)",https://www.reddit.com/r/MachineLearning/comments/7cqyqa/can_i_categorise_machine_learning_techniques/,Prykord,1510612791,[removed],0,1
650,2017-11-14,2017,11,14,9,7crv6g,Number of CPU cores?,https://www.reddit.com/r/MachineLearning/comments/7crv6g/number_of_cpu_cores/,lppier,1510620796,[removed],0,1
651,2017-11-14,2017,11,14,10,7crx2l,How to classify objects and count them at the same time,https://www.reddit.com/r/MachineLearning/comments/7crx2l/how_to_classify_objects_and_count_them_at_the/,[deleted],1510621282,,0,1
652,2017-11-14,2017,11,14,10,7cs9w3,[D] What's the best way to augment data for text matching?,https://www.reddit.com/r/MachineLearning/comments/7cs9w3/d_whats_the_best_way_to_augment_data_for_text/,shafyy,1510624682,"We're trying to train a model that predicts if a given question (~ 20 words) is answered in a given paragraph (~200 words). Paragraphs are all from Wikipedia.

My question is not about the network architecture, but as an intro: 

We're using a simple RNN where the question and paragraph are the two inputs. Each is separately converted into a representation through a GRU layer, the outputs are concatenated and run through a dense layer with 2 output nodes (each giving a probability for either class 1 or 2). Class 1 means that the question is not answered in that paragraph, class 2 means it is.

My question concerns the training data: What is the best way to synthetically obtain more data? The data is in the form
    (question, paragraph) -&gt; label (0 or 1)

Options that we can think of:

* Use synonyms for questions (""What is physics"" and ""Can you explain physics"")
* Use synonyms for the paragraphs
* Generate random question/paragraph pairs that don't match (label = 0)


Short of the empirical method, is it possible to say which methods should work generally better or worse in this situation? I know that for image classification stuff like rotating etc. is done - is there a similar method in the case of text?

Thanks!",11,3
653,2017-11-14,2017,11,14,10,7csa2n,"Wasserstein distance as a measure in Improved WGAN, BEGAN?",https://www.reddit.com/r/MachineLearning/comments/7csa2n/wasserstein_distance_as_a_measure_in_improved/,machinesa,1510624728,[removed],0,1
654,2017-11-14,2017,11,14,11,7csl4v,where may I find a reading group for MLAPP?,https://www.reddit.com/r/MachineLearning/comments/7csl4v/where_may_i_find_a_reading_group_for_mlapp/,adsada1231,1510627772,[removed],0,1
655,2017-11-14,2017,11,14,11,7cslgc,[P] Overview of Amortized Optimization,https://www.reddit.com/r/MachineLearning/comments/7cslgc/p_overview_of_amortized_optimization/,rui_,1510627859,,1,15
656,2017-11-14,2017,11,14,12,7csulf,[D] How many images is enough for the training set of a Generative Adversarial Network?,https://www.reddit.com/r/MachineLearning/comments/7csulf/d_how_many_images_is_enough_for_the_training_set/,eukaryote31,1510630414,"I'm trying to train a GAN to generate flags, but I only have 261 country flags. Is that enough?",14,11
657,2017-11-14,2017,11,14,12,7cszba,"[D] Regression, explicit vs implicit",https://www.reddit.com/r/MachineLearning/comments/7cszba/d_regression_explicit_vs_implicit/,fpenguin23,1510631832,"Hello redditors. I don't know the title is correct for this topic but I want to discuss about the output shape of neural network. 


In regression problem, we approximate a function which can represent the data best. Let's say data is on the surface of upper half sphere. This means, the range of z value is [0, 1] and the range of other variable is in [-1, 1]. 
In this case, I think there are two possible choices of neural network output.


**Find explicit form of function, NN with Three output variable**
This is trivial. We can design a NN which spit out three variables which is x,y,z. Since our data is spread out on the surface of hemisphere so that the NN should find out the relationship which is *x^2 + y^2 + z^2 = 1, z&gt;=0* and suggest proper inference from input.



**Find implicit form of function, NN with Two output variable**
We already knows the relationship between variables(upper half sphere)*z = sqrt(1 - x^2 + y^2)*.(To make problem easy, let's say we clip the negative value in the root) So I can use this relationship and apply it to NN. In this case, the network has only two output variables and find out the last one with the relationship. (By equation above) So it doesn't have to know relationship between variables and the only thing it should do is, suggesting proper output correspond to the input.


What do you think about this two type of design? What would be advantages/disadvantages of both model? Which one would show better performance?



",1,2
658,2017-11-14,2017,11,14,14,7cthke,[D] What is the statistical model behind SVM algorithm?,https://www.reddit.com/r/MachineLearning/comments/7cthke/d_what_is_the_statistical_model_behind_svm/,huyhcmut,1510637401,[removed],0,1
659,2017-11-14,2017,11,14,14,7ctm1p,[R] Spotify: Analyzing and Predicting Songs,https://www.reddit.com/r/MachineLearning/comments/7ctm1p/r_spotify_analyzing_and_predicting_songs/,-N3Ter-,1510638884,,10,56
660,2017-11-14,2017,11,14,16,7cu1hf,[R] Use Keras Pre-Trained Models With Tensorflow,https://www.reddit.com/r/MachineLearning/comments/7cu1hf/r_use_keras_pretrained_models_with_tensorflow/,zachmoshe,1510644411,,3,7
661,2017-11-14,2017,11,14,16,7cu5se,CoRL Full Live Stream,https://www.reddit.com/r/MachineLearning/comments/7cu5se/corl_full_live_stream/,sritee,1510646158,,0,1
662,2017-11-14,2017,11,14,17,7cu6q4,[D] Comparing two classifiers with different numbers of classes,https://www.reddit.com/r/MachineLearning/comments/7cu6q4/d_comparing_two_classifiers_with_different/,anonDogeLover,1510646562,"I have two classifiers. One gets a higher accuracy score, but has less classes than the other. Both perform above chance. How can I correctly compare the two (I need to, as strange as it sounds)? Is chance performance of each all I need to somehow take into account? ",15,7
663,2017-11-14,2017,11,14,17,7cu7pt,The Principles of AI in detail,https://www.reddit.com/r/MachineLearning/comments/7cu7pt/the_principles_of_ai_in_detail/,[deleted],1510646978,[deleted],0,1
664,2017-11-14,2017,11,14,17,7cu8m6,Is the 'black box' issue being exaggerated?,https://www.reddit.com/r/MachineLearning/comments/7cu8m6/is_the_black_box_issue_being_exaggerated/,[deleted],1510647368,,0,1
665,2017-11-14,2017,11,14,17,7cua8j,[D] Is the 'black box' issue being exaggerated?,https://www.reddit.com/r/MachineLearning/comments/7cua8j/d_is_the_black_box_issue_being_exaggerated/,soutioirsim,1510648047,"Whenever I present work that uses a neural network or some other fancy machine learning method to non-machine learning academics, one of the main concerns I get back from people is that these methods are a 'black box', and you can't interpret what it's doing.


My argument against this point is that human interpretability of models holds them back - if we solely used models that were easy to interpret, then we wouldn't have all the advances that we see in machine learning today.
If you define machine learning as ""the ability to automatically learn and improve from experience without being explicitly programmed"", then it's almost by definition that these models are going to be hard to interpret (otherwise you could easily explicitly code models yourself).


This is not to say that we shouldn't strive towards a better understanding of these models. Indeed, [this recent lecture](https://www.youtube.com/watch?v=bLqJHjXihK8) on the information theory of deep learning is fantastic and I hope we see more of this sort of work. Ultimately however, I feel like people need to switch from seeing 'black box' as an issue and to more of an advantage, as it leads to models that humans could never come up with.",109,74
666,2017-11-14,2017,11,14,18,7cuf10,What Bots Are Capable Of Doing,https://www.reddit.com/r/MachineLearning/comments/7cuf10/what_bots_are_capable_of_doing/,[deleted],1510650201,[deleted],0,1
667,2017-11-14,2017,11,14,18,7cui1z,Guide for machine learning (request),https://www.reddit.com/r/MachineLearning/comments/7cui1z/guide_for_machine_learning_request/,Exoski,1510651415,[removed],0,1
668,2017-11-14,2017,11,14,18,7cuiv3,How to choose a ML model when the goal is both reasonable prediction AND inference?,https://www.reddit.com/r/MachineLearning/comments/7cuiv3/how_to_choose_a_ml_model_when_the_goal_is_both/,johnmay821,1510651779,[removed],0,1
669,2017-11-14,2017,11,14,18,7culrt,IFMR : Data Science and AI,https://www.reddit.com/r/MachineLearning/comments/7culrt/ifmr_data_science_and_ai/,datasciencecourse,1510653038,,0,1
670,2017-11-14,2017,11,14,19,7cuveg,[D] Wasserstein distance as a measure in Improved WGAN?,https://www.reddit.com/r/MachineLearning/comments/7cuveg/d_wasserstein_distance_as_a_measure_in_improved/,machinesa,1510657074,"Does it still make sense to look at the Wasserstein distance (approximated loss function of the WGAN) in the improved WGAN with gradient penalty?

I don't see any papers quoting the Wasserstein distance.",3,0
671,2017-11-14,2017,11,14,20,7cuxt5,Fix your classifier: the marginal value of training the last weight layer,https://www.reddit.com/r/MachineLearning/comments/7cuxt5/fix_your_classifier_the_marginal_value_of/,mimen2,1510658027,,1,1
672,2017-11-14,2017,11,14,20,7cuzmt,[N]5 Artificial Intelligence trends shaping business in 2017,https://www.reddit.com/r/MachineLearning/comments/7cuzmt/n5_artificial_intelligence_trends_shaping/,digitalson,1510658787,,0,1
673,2017-11-14,2017,11,14,20,7cv1r3,[R]Alibaba's FashionAI shows how machine learning might save the mall,https://www.reddit.com/r/MachineLearning/comments/7cv1r3/ralibabas_fashionai_shows_how_machine_learning/,polllyyy,1510659626,,0,1
674,2017-11-14,2017,11,14,21,7cva6f,"How do you represent ""don't care"" values when creating labels for machine learning?",https://www.reddit.com/r/MachineLearning/comments/7cva6f/how_do_you_represent_dont_care_values_when/,rodrigo-silveira,1510662662,[removed],0,1
675,2017-11-14,2017,11,14,22,7cvfv0,[N]How to Cancel PlayStation Vue: Complete Step-by-Step Tutorial,https://www.reddit.com/r/MachineLearning/comments/7cvfv0/nhow_to_cancel_playstation_vue_complete/,chris_shpak,1510664538,,0,0
676,2017-11-14,2017,11,14,22,7cvglf,Automatic Rice Noodle Making Machine in Hot Selling,https://www.reddit.com/r/MachineLearning/comments/7cvglf/automatic_rice_noodle_making_machine_in_hot/,liusherry,1510664770,[removed],1,1
677,2017-11-14,2017,11,14,22,7cvjoq,"[R]Stevens Makes Major Move Into Artificial Intelligence, Machine Learning",https://www.reddit.com/r/MachineLearning/comments/7cvjoq/rstevens_makes_major_move_into_artificial/,janemoz,1510665714,,0,1
678,2017-11-14,2017,11,14,22,7cvkbw,[R]Bringing machine learning to last mile health challenges,https://www.reddit.com/r/MachineLearning/comments/7cvkbw/rbringing_machine_learning_to_last_mile_health/,jackblun,1510665881,,0,1
679,2017-11-14,2017,11,14,22,7cvkcw,[D] A brief intro to capsules.,https://www.reddit.com/r/MachineLearning/comments/7cvkcw/d_a_brief_intro_to_capsules/,[deleted],1510665889,[deleted],2,2
680,2017-11-14,2017,11,14,22,7cvn7i,[D] Is my understanding of current (2017) machine learning correct?,https://www.reddit.com/r/MachineLearning/comments/7cvn7i/d_is_my_understanding_of_current_2017_machine/,sasa_buklijas,1510666758,"Until last few years/decades, all **computer programs** (all work that was done by computers) **had two important characteristics**:

 * Humans where making exact rules (algorithms) how computer will make decisions 
 * Everything that computer did, human could do it also

**Am I correct or missing something?**

This is my understanding of the significance of machine learning, [more analysis of this I wrote on my blog] (http://buklijas.info/blog/2017/05/01/how-machines-learn-an-illustrated-guide-to-machine-learning-book-review/).

",13,0
681,2017-11-14,2017,11,14,23,7cvua2,Object Detection and Segmentation in Python with Mask-RCNN,https://www.reddit.com/r/MachineLearning/comments/7cvua2/object_detection_and_segmentation_in_python_with/,[deleted],1510668849,[deleted],0,1
682,2017-11-14,2017,11,14,23,7cvwjt,Deep Scattering: Rendering Atmospheric Clouds with Radiance-Predicting Neural Networks,https://www.reddit.com/r/MachineLearning/comments/7cvwjt/deep_scattering_rendering_atmospheric_clouds_with/,julian88888888,1510669465,,0,1
683,2017-11-14,2017,11,14,23,7cvwmy,[R] DLPaper2Code: Auto-generation of Code from Deep Learning Research Papers,https://www.reddit.com/r/MachineLearning/comments/7cvwmy/r_dlpaper2code_autogeneration_of_code_from_deep/,ccmlacc,1510669491,,14,19
684,2017-11-14,2017,11,14,23,7cvxhb,"IBM is conducting user research to understand the use of Cloud solutions in software development teams focused on large data projects. $60, 30-minute Webex interviews.",https://www.reddit.com/r/MachineLearning/comments/7cvxhb/ibm_is_conducting_user_research_to_understand_the/,llb12,1510669730,,0,1
685,2017-11-14,2017,11,14,23,7cvzug,"IBM is conducting user research with Data Scientists about the use of Cloud solutions. $60, 30-minute Webex interview",https://www.reddit.com/r/MachineLearning/comments/7cvzug/ibm_is_conducting_user_research_with_data/,llb12,1510670383,,0,1
686,2017-11-14,2017,11,14,23,7cw2oz,[P] Object Detection and Segmentation in Python with Mask-RCNN,https://www.reddit.com/r/MachineLearning/comments/7cw2oz/p_object_detection_and_segmentation_in_python/,[deleted],1510671146,[deleted],0,1
687,2017-11-14,2017,11,14,23,7cw3ts,[P] PyTorch tutorials from MILA,https://www.reddit.com/r/MachineLearning/comments/7cw3ts/p_pytorch_tutorials_from_mila/,ieee8023,1510671448,,10,195
688,2017-11-15,2017,11,15,0,7cw5dh,[P] Object Detection and Segmentation in Python with Mask-RCNN,https://www.reddit.com/r/MachineLearning/comments/7cw5dh/p_object_detection_and_segmentation_in_python/,[deleted],1510671833,[deleted],0,0
689,2017-11-15,2017,11,15,0,7cwdvu,UCI datasets solutions,https://www.reddit.com/r/MachineLearning/comments/7cwdvu/uci_datasets_solutions/,lovej25,1510673948,[removed],0,1
690,2017-11-15,2017,11,15,0,7cwg6f,[P] Deep Scattering: Rendering Atmospheric Clouds with Radiance-Predicting Neural Networks,https://www.reddit.com/r/MachineLearning/comments/7cwg6f/p_deep_scattering_rendering_atmospheric_clouds/,julian88888888,1510674497,,1,13
691,2017-11-15,2017,11,15,1,7cwozq,Battling through an Nvidia GPU setup in the name of machine learning.,https://www.reddit.com/r/MachineLearning/comments/7cwozq/battling_through_an_nvidia_gpu_setup_in_the_name/,[deleted],1510676563,[deleted],0,1
692,2017-11-15,2017,11,15,1,7cwudo,[P] Teaching a pile of matchboxes to play Tic-Tac-Toe with Matt Parker,https://www.reddit.com/r/MachineLearning/comments/7cwudo/p_teaching_a_pile_of_matchboxes_to_play_tictactoe/,Schmogel,1510677798,,7,16
693,2017-11-15,2017,11,15,1,7cwws4,[R] Stream of The Conference on Robot Learning 2017,https://www.reddit.com/r/MachineLearning/comments/7cwws4/r_stream_of_the_conference_on_robot_learning_2017/,evc123,1510678332,,0,8
694,2017-11-15,2017,11,15,2,7cwywp,"We've trained AI to recognize ads and ultimately block them, using computer vision",https://www.reddit.com/r/MachineLearning/comments/7cwywp/weve_trained_ai_to_recognize_ads_and_ultimately/,egorka_edge,1510678833,,0,2
695,2017-11-15,2017,11,15,2,7cx61x,[R] Intriguing Properties of Adversarial Examples,https://www.reddit.com/r/MachineLearning/comments/7cx61x/r_intriguing_properties_of_adversarial_examples/,downtownslim,1510680420,,2,31
696,2017-11-15,2017,11,15,2,7cx9bv,A Visual Representation of Capsule Network Computations,https://www.reddit.com/r/MachineLearning/comments/7cx9bv/a_visual_representation_of_capsule_network/,mikeross0,1510681179,,8,39
697,2017-11-15,2017,11,15,2,7cxcgs,[D] Replacements of max pool,https://www.reddit.com/r/MachineLearning/comments/7cxcgs/d_replacements_of_max_pool/,nishnik,1510681901,"There have been replacements of maxpool like kmaxpool, which rather than only taking the maximum activated elements, takes top k activated elements for the subsequent layer.

I had this thought in my mind, to use next to max element for the subsequent layer, ie the 2nd maximum element. I think this would have a regularizing effect while training time and during testing, use the maximum element. 

Tried running the network but didn't get a good result, just an UG so cant explore extensively (computational bottleneck of my laptop).

Any insights?",6,1
698,2017-11-15,2017,11,15,3,7cxf8z,How to detect the position of abnormal point using SVM.,https://www.reddit.com/r/MachineLearning/comments/7cxf8z/how_to_detect_the_position_of_abnormal_point/,LiviaOrestilla,1510682539,[removed],0,1
699,2017-11-15,2017,11,15,3,7cxgnn,Machine learning topic for bachelor's thesis,https://www.reddit.com/r/MachineLearning/comments/7cxgnn/machine_learning_topic_for_bachelors_thesis/,ahimaohw,1510682819,[removed],0,1
700,2017-11-15,2017,11,15,3,7cxiij,NVIDIA-Docker version 2 released,https://www.reddit.com/r/MachineLearning/comments/7cxiij/nvidiadocker_version_2_released/,[deleted],1510683232,[deleted],0,1
701,2017-11-15,2017,11,15,3,7cxiwz,[N] NVIDIA-Docker version 2 released,https://www.reddit.com/r/MachineLearning/comments/7cxiwz/n_nvidiadocker_version_2_released/,marcjschmidt,1510683321,,3,43
702,2017-11-15,2017,11,15,3,7cxl03,Sentiment Analysis and Text Mining,https://www.reddit.com/r/MachineLearning/comments/7cxl03/sentiment_analysis_and_text_mining/,munishmaxtech,1510683791,,0,1
703,2017-11-15,2017,11,15,3,7cxnhk,I invite you to check the book I wrote: Data Science Live Book (open source),https://www.reddit.com/r/MachineLearning/comments/7cxnhk/i_invite_you_to_check_the_book_i_wrote_data/,pabloc_ds,1510684349,,0,1
704,2017-11-15,2017,11,15,3,7cxq2u,[P] Cycling Power Without a Power Meter,https://www.reddit.com/r/MachineLearning/comments/7cxq2u/p_cycling_power_without_a_power_meter/,soutioirsim,1510684947,,3,1
705,2017-11-15,2017,11,15,3,7cxul5,[R] A Theory of How Columns in the Neocortex Enable Learning the Structure of the World - Numenta / HTM,https://www.reddit.com/r/MachineLearning/comments/7cxul5/r_a_theory_of_how_columns_in_the_neocortex_enable/,visarga,1510685943,,9,2
706,2017-11-15,2017,11,15,4,7cy6y0,Building a Gesture Recognition System using Deep Learning  Joanna Materzyska,https://www.reddit.com/r/MachineLearning/comments/7cy6y0/building_a_gesture_recognition_system_using_deep/,yildiz17,1510688692,[removed],0,1
707,2017-11-15,2017,11,15,5,7cybwi,Federated Learning with Android and DL4J,https://www.reddit.com/r/MachineLearning/comments/7cybwi/federated_learning_with_android_and_dl4j/,[deleted],1510689809,[deleted],0,1
708,2017-11-15,2017,11,15,5,7cyf94,What is the State of the art for Rotten Tomatoes movie reviews dataset (binary classification)?,https://www.reddit.com/r/MachineLearning/comments/7cyf94/what_is_the_state_of_the_art_for_rotten_tomatoes/,whoisthebossbitch,1510690540,[removed],0,1
709,2017-11-15,2017,11,15,5,7cyfp7,TIL: scikit-learn is one of many scikits (scientific kits based on scipy),https://www.reddit.com/r/MachineLearning/comments/7cyfp7/til_scikitlearn_is_one_of_many_scikits_scientific/,paulrecast,1510690635,,0,1
710,2017-11-15,2017,11,15,5,7cygug,Awesome Deep Learning for Natural Language Processing (GitHub list),https://www.reddit.com/r/MachineLearning/comments/7cygug/awesome_deep_learning_for_natural_language/,aavaas,1510690900,,0,1
711,2017-11-15,2017,11,15,5,7cyi6n,[D] What is the State of the art for Rotten Tomatoes movie reviews dataset (binary classification)?,https://www.reddit.com/r/MachineLearning/comments/7cyi6n/d_what_is_the_state_of_the_art_for_rotten/,whoisthebossbitch,1510691199,"In Kim's CNN paper, they use Rotten Tomatoes movie reviews dataset. Do you guys what is the State of the art for it now?",5,1
712,2017-11-15,2017,11,15,5,7cyihd,[P] MNIST-Sequence: Generate dataset for sequences of handwritten digits using MNIST,https://www.reddit.com/r/MachineLearning/comments/7cyihd/p_mnistsequence_generate_dataset_for_sequences_of/,aaggarwall,1510691269,,0,0
713,2017-11-15,2017,11,15,5,7cyipr,Using Machine Learning to Predict the Weather,https://www.reddit.com/r/MachineLearning/comments/7cyipr/using_machine_learning_to_predict_the_weather/,cavedave,1510691327,,11,5
714,2017-11-15,2017,11,15,5,7cyjw2,Federated Learning with Android and DL4J,https://www.reddit.com/r/MachineLearning/comments/7cyjw2/federated_learning_with_android_and_dl4j/,mccorby72,1510691600,,0,1
715,2017-11-15,2017,11,15,6,7cyrgl,Are there any blogs that focus on explaining arxiv papers for mid-advanced learners in ML,https://www.reddit.com/r/MachineLearning/comments/7cyrgl/are_there_any_blogs_that_focus_on_explaining/,naresha5,1510693311,[removed],0,1
716,2017-11-15,2017,11,15,6,7cyrq8,TensorFlow Lite in Developer Preview,https://www.reddit.com/r/MachineLearning/comments/7cyrq8/tensorflow_lite_in_developer_preview/,rajatmonga,1510693369,[removed],0,2
717,2017-11-15,2017,11,15,6,7cyuak,We created an AI Enabled Messenger Chatbot that gives people residential solar quotes,https://www.reddit.com/r/MachineLearning/comments/7cyuak/we_created_an_ai_enabled_messenger_chatbot_that/,[deleted],1510693953,[deleted],0,1
718,2017-11-15,2017,11,15,6,7cyvdl,TensorFlow Lite in Developer Preview,https://www.reddit.com/r/MachineLearning/comments/7cyvdl/tensorflow_lite_in_developer_preview/,sarasuec,1510694183,[removed],0,1
719,2017-11-15,2017,11,15,6,7cyxec,[R] CyCADA: Cycle-Consistent Adversarial Domain Adaptation,https://www.reddit.com/r/MachineLearning/comments/7cyxec/r_cycada_cycleconsistent_adversarial_domain/,madebyollin,1510694652,,3,21
720,2017-11-15,2017,11,15,6,7cz6gg,Best subfields of ML research to enter with a math / physics background?,https://www.reddit.com/r/MachineLearning/comments/7cz6gg/best_subfields_of_ml_research_to_enter_with_a/,actuallynotcanadian,1510696728,[removed],0,1
721,2017-11-15,2017,11,15,7,7czcdu,Using Machine Learning + Chatbots to give residential solar quotes,https://www.reddit.com/r/MachineLearning/comments/7czcdu/using_machine_learning_chatbots_to_give/,kylebythemile,1510698112,,0,1
722,2017-11-15,2017,11,15,7,7czita,What deep learning framework would you recommend?,https://www.reddit.com/r/MachineLearning/comments/7czita/what_deep_learning_framework_would_you_recommend/,Beardo01,1510699687,[removed],0,1
723,2017-11-15,2017,11,15,7,7czk5l,Introduction to TensorFlow Lite | TensorFlow,https://www.reddit.com/r/MachineLearning/comments/7czk5l/introduction_to_tensorflow_lite_tensorflow/,hiteshag,1510700037,,0,1
724,2017-11-15,2017,11,15,7,7czkmm,Announcing TensorFlow Lite - Google,https://www.reddit.com/r/MachineLearning/comments/7czkmm/announcing_tensorflow_lite_google/,[deleted],1510700153,[deleted],0,1
725,2017-11-15,2017,11,15,8,7cznhq,Announcing TensorFlow Lite,https://www.reddit.com/r/MachineLearning/comments/7cznhq/announcing_tensorflow_lite/,MichaelRahmani,1510700826,,0,2
726,2017-11-15,2017,11,15,8,7czo0c,Teaching a pile of matchboxes to play tic-tac-toe,https://www.reddit.com/r/MachineLearning/comments/7czo0c/teaching_a_pile_of_matchboxes_to_play_tictactoe/,ARG127,1510700943,,0,1
727,2017-11-15,2017,11,15,9,7d0910,Overmodeling of fits,https://www.reddit.com/r/MachineLearning/comments/7d0910/overmodeling_of_fits/,phobrain,1510706231,[removed],0,1
728,2017-11-15,2017,11,15,10,7d0fib,[D] stratified sampling from highly correlated data,https://www.reddit.com/r/MachineLearning/comments/7d0fib/d_stratified_sampling_from_highly_correlated_data/,N-iodosuccinimide,1510707955,"What is your goto strategy when it comes to sampling from rather correlated data? Especially where the feature space is rather high e.g N&lt;&lt;D? I have seen approaches that use single-linkage clustering to guarantee a minimal distance between training folds and test sets. However it seems rather hard to optimize edge distance as a hyper parameter. At least when using AUROC or similar cost functions, as this would favor then again, correlation between training fold and test fold (or training set and test set).

",0,4
729,2017-11-15,2017,11,15,11,7d0v6s,Classifying Japanese characters from the Edo period,https://www.reddit.com/r/MachineLearning/comments/7d0v6s/classifying_japanese_characters_from_the_edo/,sataky,1510712219,,0,1
730,2017-11-15,2017,11,15,11,7d0y7w,Open Source AI Consulting Contract,https://www.reddit.com/r/MachineLearning/comments/7d0y7w/open_source_ai_consulting_contract/,[deleted],1510713080,[deleted],0,1
731,2017-11-15,2017,11,15,11,7d14bh,The State of AI,https://www.reddit.com/r/MachineLearning/comments/7d14bh/the_state_of_ai/,brotherrain,1510714744,,0,1
732,2017-11-15,2017,11,15,12,7d1eum,[R] [1711.04574] Learning Explanatory Rules from Noisy Data -- Induction of robust logic rules that generalize with backprop,https://www.reddit.com/r/MachineLearning/comments/7d1eum/r_171104574_learning_explanatory_rules_from_noisy/,pranv,1510717638,,3,37
733,2017-11-15,2017,11,15,13,7d1s4f,"PyTorch Version of Visual Attribute Transfer Through Deep Image Analogy [P] Feedback, questions, Issues accepted!",https://www.reddit.com/r/MachineLearning/comments/7d1s4f/pytorch_version_of_visual_attribute_transfer/,harvey_slash,1510721622,,0,0
734,2017-11-15,2017,11,15,13,7d1smj,Continuous Frying Machine Manufacturer,https://www.reddit.com/r/MachineLearning/comments/7d1smj/continuous_frying_machine_manufacturer/,gelgoogmachinery,1510721796,,1,1
735,2017-11-15,2017,11,15,15,7d254h,"A PyTorch Implementation of Densely Connected Convolutional Networks (DenseNets) Hello, this is my first github repository. I have implemented repository in PyTorch. This paper has won best paper award in CVPR 2017. I am looking forward for you feedback that can help to improve me.",https://www.reddit.com/r/MachineLearning/comments/7d254h/a_pytorch_implementation_of_densely_connected/,[deleted],1510725890,[deleted],0,1
736,2017-11-15,2017,11,15,15,7d25og,[D] In what tasks does deep/machine learning beat humans?,https://www.reddit.com/r/MachineLearning/comments/7d25og/d_in_what_tasks_does_deepmachine_learning_beat/,[deleted],1510726088,,0,1
737,2017-11-15,2017,11,15,15,7d276q,A PyTorch Implementation of Densely Connected Convolutional Networks (DenseNets),https://www.reddit.com/r/MachineLearning/comments/7d276q/a_pytorch_implementation_of_densely_connected/,[deleted],1510726594,,0,1
738,2017-11-15,2017,11,15,16,7d2iap,[D] How autonomous weapons with AI could go bad.,https://www.reddit.com/r/MachineLearning/comments/7d2iap/d_how_autonomous_weapons_with_ai_could_go_bad/,LovaszExtension,1510730724,,71,60
739,2017-11-15,2017,11,15,17,7d2vk1,[D] What would you include in a first ML course?,https://www.reddit.com/r/MachineLearning/comments/7d2vk1/d_what_would_you_include_in_a_first_ml_course/,NicolasGuacamole,1510736367,"Lets say youve been tasked with designing a first course in ML from scratch, naturally given were living in the year we are.

I was wondering what topics and what rough ordering people would consider to be most critical to include? Also any other special considerations that it would do well to note.",63,72
740,2017-11-15,2017,11,15,19,7d35u7,[D] Is 32x32 too small of an input image for training/evaluating/inferring an Age Recognition CNN?,https://www.reddit.com/r/MachineLearning/comments/7d35u7/d_is_32x32_too_small_of_an_input_image_for/,FantasyBorderline,1510740668,"I just realized it might be true - when shrinking an image, a lot of information would be lost.

Most of the papers I read about Age Recognition used 224x224, but I can't do it because I intend to use it for a mobile app.

Would 64x64 be enough?",18,4
741,2017-11-15,2017,11,15,19,7d35yp,[P] Towards Interpretable Reliable Models,https://www.reddit.com/r/MachineLearning/comments/7d35yp/p_towards_interpretable_reliable_models/,pmigdal,1510740712,,1,16
742,2017-11-15,2017,11,15,19,7d380k,[1711.05195] A learning problem that is independent of the set theory ZFC axioms,https://www.reddit.com/r/MachineLearning/comments/7d380k/171105195_a_learning_problem_that_is_independent/,ihaphleas,1510741475,,0,1
743,2017-11-15,2017,11,15,20,7d3f06,[R]President Reif: We must build a future in which technology works for everyone,https://www.reddit.com/r/MachineLearning/comments/7d3f06/rpresident_reif_we_must_build_a_future_in_which/,digitalson,1510744264,,0,1
744,2017-11-15,2017,11,15,20,7d3hix,Understanding Hintons Capsule Networks.,https://www.reddit.com/r/MachineLearning/comments/7d3hix/understanding_hintons_capsule_networks/,[deleted],1510745229,[deleted],0,1
745,2017-11-15,2017,11,15,20,7d3hm7,The new Neural Networks API in Android,https://www.reddit.com/r/MachineLearning/comments/7d3hm7/the_new_neural_networks_api_in_android/,fornwall,1510745265,,0,1
746,2017-11-15,2017,11,15,20,7d3hna,[N]Data Tagging in Medical Imaging - Diving Deep into the Processes,https://www.reddit.com/r/MachineLearning/comments/7d3hna/ndata_tagging_in_medical_imaging_diving_deep_into/,friscotime,1510745278,,0,1
747,2017-11-15,2017,11,15,20,7d3jyn,Understanding Hintons Capsule Networks.,https://www.reddit.com/r/MachineLearning/comments/7d3jyn/understanding_hintons_capsule_networks/,[deleted],1510746162,[deleted],0,1
748,2017-11-15,2017,11,15,20,7d3lpq,[D] Machine Learning: The High Interest Credit Card of Technical Debt,https://www.reddit.com/r/MachineLearning/comments/7d3lpq/d_machine_learning_the_high_interest_credit_card/,_alphamaximus_,1510746856,,0,1
749,2017-11-15,2017,11,15,21,7d3nk3,Testing Recommender Algorithms in Python with Surprise (Interview),https://www.reddit.com/r/MachineLearning/comments/7d3nk3/testing_recommender_algorithms_in_python_with/,[deleted],1510747467,[deleted],0,1
750,2017-11-15,2017,11,15,21,7d3o90,[P] Testing Recommender Algorithms in Python with Surprise (Interview),https://www.reddit.com/r/MachineLearning/comments/7d3o90/p_testing_recommender_algorithms_in_python_with/,Niourf,1510747716,,0,2
751,2017-11-15,2017,11,15,21,7d3pau,Curry Puffs Making Machine for Sale,https://www.reddit.com/r/MachineLearning/comments/7d3pau/curry_puffs_making_machine_for_sale/,liusherry,1510748086,,1,1
752,2017-11-15,2017,11,15,21,7d3rjy,Steamed Rice Roll Machine for Sale,https://www.reddit.com/r/MachineLearning/comments/7d3rjy/steamed_rice_roll_machine_for_sale/,liusherry,1510748873,,1,1
753,2017-11-15,2017,11,15,21,7d3srp,Association analysis for a binary target,https://www.reddit.com/r/MachineLearning/comments/7d3srp/association_analysis_for_a_binary_target/,renternainus,1510749291,[removed],0,1
754,2017-11-15,2017,11,15,21,7d3ubs,[D] Understanding Hintons Capsule Networks.,https://www.reddit.com/r/MachineLearning/comments/7d3ubs/d_understanding_hintons_capsule_networks/,aditya_arun,1510749850,,46,71
755,2017-11-15,2017,11,15,21,7d3x4g,deepLoco,https://www.reddit.com/r/MachineLearning/comments/7d3x4g/deeploco/,vivanov,1510750776,,0,1
756,2017-11-15,2017,11,15,22,7d48gv,Which Reinforcement Learning toolkit for autonomous driving would you suggest?,https://www.reddit.com/r/MachineLearning/comments/7d48gv/which_reinforcement_learning_toolkit_for/,[deleted],1510754190,,0,1
757,2017-11-15,2017,11,15,23,7d49yy,[N] Announcing TensorFlow Lite - Google,https://www.reddit.com/r/MachineLearning/comments/7d49yy/n_announcing_tensorflow_lite_google/,MichaelRahmani,1510754624,,1,32
758,2017-11-15,2017,11,15,23,7d4apq,"[N] Data Prism: weekly newsletter about data science, ML, AI and analytics",https://www.reddit.com/r/MachineLearning/comments/7d4apq/n_data_prism_weekly_newsletter_about_data_science/,angelatina,1510754831,,0,1
759,2017-11-15,2017,11,15,23,7d4avr,Which Reinforcement Learning toolkit for autonomous driving would you suggest?,https://www.reddit.com/r/MachineLearning/comments/7d4avr/which_reinforcement_learning_toolkit_for/,nonsingularmatrix,1510754872,[removed],0,1
760,2017-11-15,2017,11,15,23,7d4m8p,[R] Resurrecting the sigmoid in deep learning through dynamical isometry: theory and practice,https://www.reddit.com/r/MachineLearning/comments/7d4m8p/r_resurrecting_the_sigmoid_in_deep_learning/,XalosXandrez,1510757930,,7,35
761,2017-11-16,2017,11,16,0,7d4u66,[R] [1711.04994] Prediction Under Uncertainty with Error-Encoding Networks (FAIR),https://www.reddit.com/r/MachineLearning/comments/7d4u66/r_171104994_prediction_under_uncertainty_with/,fergbyrne,1510759924,,1,3
762,2017-11-16,2017,11,16,0,7d4usn,"water treatment aeration blowers manufacturer in China Shandong dacheng machinery technology co., ltd",https://www.reddit.com/r/MachineLearning/comments/7d4usn/water_treatment_aeration_blowers_manufacturer_in/,zqdicheng,1510760109,,0,1
763,2017-11-16,2017,11,16,0,7d4z7m,Using machine learning to redraw political boundaries in the US (and prevent gerrymandering),https://www.reddit.com/r/MachineLearning/comments/7d4z7m/using_machine_learning_to_redraw_political/,adamnhornsby,1510761163,,1,1
764,2017-11-16,2017,11,16,0,7d4zxi,"Simple Questions Thread November 15, 2017",https://www.reddit.com/r/MachineLearning/comments/7d4zxi/simple_questions_thread_november_15_2017/,AutoModerator,1510761341,[removed],0,1
765,2017-11-16,2017,11,16,1,7d528r,[R] Data Augmentation Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/7d528r/r_data_augmentation_generative_adversarial/,AntreasAntoniou,1510761901,"Hello everyone,

Just wanted to present some of my recent work on meta-learning data augmentations from a source domain and applying them to a target domain to augment datasets in order to improve classifier generalization and one shot learning.

Arxiv link: https://arxiv.org/abs/1711.04340
Additional generated samples: https://twitter.com/_AntreasAntonio/status/930799155538251776",18,14
766,2017-11-16,2017,11,16,1,7d54hh,how to learn machine learning and artificial intelligence in 3-6 months?,https://www.reddit.com/r/MachineLearning/comments/7d54hh/how_to_learn_machine_learning_and_artificial/,atcha1206,1510762437,,0,1
767,2017-11-16,2017,11,16,1,7d57eb,HAAR cascade for open/closed eyes,https://www.reddit.com/r/MachineLearning/comments/7d57eb/haar_cascade_for_openclosed_eyes/,mrpmorris,1510763156,[removed],0,1
768,2017-11-16,2017,11,16,2,7d5gcs,MY NEW BITCOIN ADDRESS 1664tJyMdUmhRKbeXho4kSUsVXzVcc5wYo,https://www.reddit.com/r/MachineLearning/comments/7d5gcs/my_new_bitcoin_address/,ankush32112,1510765341,[removed],1,1
769,2017-11-16,2017,11,16,2,7d5htz,[D] Where do you get our info of whats happening with AI form industry(especially startups)?,https://www.reddit.com/r/MachineLearning/comments/7d5htz/d_where_do_you_get_our_info_of_whats_happening/,spartan12321,1510765681,"This subreddit seem good page to follow AI research and general discussion, but is there any page I can get news about development of AI in industry and about AI startups. Until now I just searched AI related articles on blooberg etc., but is there better solution?",5,6
770,2017-11-16,2017,11,16,2,7d5joq,[D] LSTM for Automated Data Quality Control,https://www.reddit.com/r/MachineLearning/comments/7d5joq/d_lstm_for_automated_data_quality_control/,dumbAI,1510766086,"I am about to begin a project to automate data quality control (QC) and am requesting feedback/resources on applying AI to this problem. 

Scope: management wants automated QC of data dumps that occur monthly so that manual reviews are no longer required. That's really all I have to go on.

The data: Time series (monthly), approx. 100 variables, with hundreds of millions of training examples going back decades. Data dumps occur monthly with a few million observations.

My thoughts: Train a LSTM on historical data and generate predictions/confidence intervals for current month load, and flag data that are out the interval.

I have looked for research on applying deep learning to data quality problems and haven't found much, mostly applying older algorithms to do anomaly detection. A few more recent papers I found:
[MRI data QC and SVM/Gradient Boosted Trees](https://arxiv.org/pdf/1707.06353.pdf)

[Salary data QC, comparing MLP, CNN, SVM, and regression models](https://www.researchgate.net/publication/318601321_Improving_Data_Quality_Through_Deep_Learning_and_Statistical_Models)

Is an LSTM something I can use for this problem, and does anyone know of any research applying LSTMs to data quality problems?",3,1
771,2017-11-16,2017,11,16,2,7d5jxg,Is there a way to train models on a blockchain?,https://www.reddit.com/r/MachineLearning/comments/7d5jxg/is_there_a_way_to_train_models_on_a_blockchain/,HarambeTownley,1510766146,[removed],0,1
772,2017-11-16,2017,11,16,2,7d5mb4,[R] Fixing Weight Decay Regularization in Adam,https://www.reddit.com/r/MachineLearning/comments/7d5mb4/r_fixing_weight_decay_regularization_in_adam/,[deleted],1510766695,[deleted],0,1
773,2017-11-16,2017,11,16,2,7d5mpc,[1711.05101] Fixing Weight Decay Regularization in Adam,https://www.reddit.com/r/MachineLearning/comments/7d5mpc/171105101_fixing_weight_decay_regularization_in/,[deleted],1510766783,[deleted],1,1
774,2017-11-16,2017,11,16,2,7d5qob,[R] [1711.05101] Fixing Weight Decay Regularization in Adam,https://www.reddit.com/r/MachineLearning/comments/7d5qob/r_171105101_fixing_weight_decay_regularization_in/,robintibor,1510767703,,9,41
775,2017-11-16,2017,11,16,2,7d5rrj,[D] On-Device Conversational Modeling with TensorFlow Lite,https://www.reddit.com/r/MachineLearning/comments/7d5rrj/d_ondevice_conversational_modeling_with/,Jackal008,1510767969,,1,2
776,2017-11-16,2017,11,16,3,7d60u3,How do you properly load models (ckpts) in Tensorflow (Python) to resume training? [Discussion],https://www.reddit.com/r/MachineLearning/comments/7d60u3/how_do_you_properly_load_models_ckpts_in/,Moondra2017,1510769973,"This is something that is giving me a hard time.

There seems to be a different ways. 

I see some blogs using the `.get_checkpoint_state`,

which I tried, but I couldn't properly load my global step.


`NotFoundError (see above for traceback): Key global_step_1 not found in checkpoint`

However, the weights were loaded properly. 

The other way I see is to look at all the nodes with 
`for op in tf.get_default_graph().get_operations():
  print(op.values, '\n')`

And then activiate(?) those nodes within the current graph as such:

accuracy = tf.get_default_graph().get_tensor_by_name('Accuracy/Mean:0')


However, there are so many similar nodes (All have the Accuracy base name), I'm not entirely sure which one I am supposed to load. 

I made a long question on SO, but I don't really get many responses on SO when it comes to tensorflow(everything else is lightning quick). 

Here is my post:

https://stackoverflow.com/questions/47299378/correctly-loading-a-model-to-resume-training-meta-graph-ckpts

What is the correct way to use ckpts to load models?


I'm mainly interested in computer vision tasks and RL with Python, so not sure if I should move to another framework that is easier to use.

I want to build my own custom NNs as well as use a lot of pre-trained models. 




Thank you. 

",4,0
777,2017-11-16,2017,11,16,3,7d62cw,[R] Anytime Neural Network: a Versatile Trade-off Between Computation and Accuracy,https://www.reddit.com/r/MachineLearning/comments/7d62cw/r_anytime_neural_network_a_versatile_tradeoff/,xternalz,1510770325,,0,7
778,2017-11-16,2017,11,16,3,7d62q9,[P] SLING: A Natural Language Frame Semantic Parser,https://www.reddit.com/r/MachineLearning/comments/7d62q9/p_sling_a_natural_language_frame_semantic_parser/,alxndrkalinin,1510770417,,3,23
779,2017-11-16,2017,11,16,4,7d6c13,AI Consulting Contract,https://www.reddit.com/r/MachineLearning/comments/7d6c13/ai_consulting_contract/,zthoutt,1510772548,,0,1
780,2017-11-16,2017,11,16,4,7d6dkw,"[D] Should we introduce an ""Inaccurate""/""Misleading"" tag for posts?",https://www.reddit.com/r/MachineLearning/comments/7d6dkw/d_should_we_introduce_an_inaccuratemisleading_tag/,olaf_nij,1510772873,"As a moderator, simply removing a post doesn't seem to curb the amount self-promotion and inaccurate submissions that continue to crop up. This is mainly because these posts come from a different author each time.

There's no incentive to not post since there will be some amount of visibility before it gets removed. To disincentivize these types of posts, should we introduce ""Inaccurate"" and ""Misleading"" tags to inform the community that the post could be misleading. The author can appeal this tag with the moderators, but it will be at our discretion whether it will be removed or not.
",42,291
781,2017-11-16,2017,11,16,4,7d6jhf,ValueError: setting an array element with a sequence - When trying to feed list into placeholder in feed_dict,https://www.reddit.com/r/MachineLearning/comments/7d6jhf/valueerror_setting_an_array_element_with_a/,bgshishir1994,1510774247,[removed],0,1
782,2017-11-16,2017,11,16,4,7d6jlq,Get your GPU accelerated cloud platform - Paperspace referral code,https://www.reddit.com/r/MachineLearning/comments/7d6jlq/get_your_gpu_accelerated_cloud_platform/,prawtutorial7,1510774274,[removed],0,1
783,2017-11-16,2017,11,16,5,7d6z7i,[R] [1711.02017] NeST: A Neural Network Synthesis Tool Based on a Grow-and-Prune Paradigm,https://www.reddit.com/r/MachineLearning/comments/7d6z7i/r_171102017_nest_a_neural_network_synthesis_tool/,bobchennan,1510777925,,6,12
784,2017-11-16,2017,11,16,5,7d6zz3,YOLO Object Detection,https://www.reddit.com/r/MachineLearning/comments/7d6zz3/yolo_object_detection/,funmaster11,1510778106,,0,1
785,2017-11-16,2017,11,16,6,7d7a82,A Technical Overview of Azure Databricks,https://www.reddit.com/r/MachineLearning/comments/7d7a82/a_technical_overview_of_azure_databricks/,dmatrixjsd,1510780476,,0,1
786,2017-11-16,2017,11,16,6,7d7ge0,[N] Numpy dropping Python 2.7,https://www.reddit.com/r/MachineLearning/comments/7d7ge0/n_numpy_dropping_python_27/,bobchennan,1510781929,,108,375
787,2017-11-16,2017,11,16,8,7d8aad,[R] [1711.04325] Extremely Large Minibatch SGD: Training ResNet-50 on ImageNet in 15 Minutes,https://www.reddit.com/r/MachineLearning/comments/7d8aad/r_171104325_extremely_large_minibatch_sgd/,shoheihido,1510789411,,24,12
788,2017-11-16,2017,11,16,9,7d8ews,CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning,https://www.reddit.com/r/MachineLearning/comments/7d8ews/chexnet_radiologistlevel_pneumonia_detection_on/,SuperFX,1510790604,,10,10
789,2017-11-16,2017,11,16,9,7d8oh3,[R] [1711.05225] CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning,https://www.reddit.com/r/MachineLearning/comments/7d8oh3/r_171105225_chexnet_radiologistlevel_pneumonia/,iownaredball,1510793062,,17,6
790,2017-11-16,2017,11,16,9,7d8qsq,Statistical and Individual Fairness in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7d8qsq/statistical_and_individual_fairness_in_machine/,[deleted],1510793676,[deleted],0,1
791,2017-11-16,2017,11,16,9,7d8rnb,StarCraft2 pysc2 RL Tutorial 2: Observations,https://www.reddit.com/r/MachineLearning/comments/7d8rnb/starcraft2_pysc2_rl_tutorial_2_observations/,[deleted],1510793920,[deleted],0,1
792,2017-11-16,2017,11,16,9,7d8rqf,Shape recognition w/o learning,https://www.reddit.com/r/MachineLearning/comments/7d8rqf/shape_recognition_wo_learning/,[deleted],1510793941,,0,1
793,2017-11-16,2017,11,16,10,7d8utl,[R] Statistical and Individual Fairness in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7d8utl/r_statistical_and_individual_fairness_in_machine/,MagnesiumCarbonate,1510794765,,2,5
794,2017-11-16,2017,11,16,10,7d9232,[R] Shape Recognition w/o Learning,https://www.reddit.com/r/MachineLearning/comments/7d9232/r_shape_recognition_wo_learning/,egladysh,1510796772,"Recently, I was looking for a way to score simple shapes (ideal and not ideal) in terms of their resemblance to a key shape like a square, circle, line, etc.. I could not find anything simple and reliable. So I put something very simple together that seems to work quite well but I am not sure if I am inventing the wheel here. See details, https://github.com/egladysh/shadow/blob/master/doc/article.pdf

Perhaps combining it with some ML would make it even better...
",6,10
795,2017-11-16,2017,11,16,10,7d92h8,[P] Deepmind's StarCraft II RL Tutorial 2: Observation,https://www.reddit.com/r/MachineLearning/comments/7d92h8/p_deepminds_starcraft_ii_rl_tutorial_2_observation/,sjhshy,1510796873,,3,28
796,2017-11-16,2017,11,16,10,7d9315,[D] RNADE vs MDR vs BART vs Bayesian Linear Regression,https://www.reddit.com/r/MachineLearning/comments/7d9315/d_rnade_vs_mdr_vs_bart_vs_bayesian_linear/,m1sta,1510797026,"Hi all,

I'm looking at a collection of problems where I need to forecast the probability of a continuous variable. My dependent variables are a combination of categorical and continuous. It looks like there are four primary candidate areas I should be reviewing and/or testing. Can anyone here shed any light on the relative strengths and risks associated with each of RNADE, Mixture Density Networks, Bayesian Additive Regression Trees, and standard Bayesian Linear Regression?
",1,5
797,2017-11-16,2017,11,16,10,7d931c,[R] Distributed Deep Learning with Keras on Apache Spark,https://www.reddit.com/r/MachineLearning/comments/7d931c/r_distributed_deep_learning_with_keras_on_apache/,Lekter,1510797029,,0,12
798,2017-11-16,2017,11,16,11,7d9b8o,"Scrape the web : get data from amazon, airbnb, reddit, pexel, steam",https://www.reddit.com/r/MachineLearning/comments/7d9b8o/scrape_the_web_get_data_from_amazon_airbnb_reddit/,tanphamvan,1510799340,,0,1
799,2017-11-16,2017,11,16,11,7d9ch1,CPUs or GPUs for deploying models to production?,https://www.reddit.com/r/MachineLearning/comments/7d9ch1/cpus_or_gpus_for_deploying_models_to_production/,zbnone,1510799676,[removed],0,1
800,2017-11-16,2017,11,16,11,7d9dhc,Easy to Use Wrapper for Deep Local Feature (DELF) for images,https://www.reddit.com/r/MachineLearning/comments/7d9dhc/easy_to_use_wrapper_for_deep_local_feature_delf/,[deleted],1510799978,[deleted],0,1
801,2017-11-16,2017,11,16,11,7d9f94,Distributed machine learning has been initiated to replicate Deepmind's AlphaGoZero in an open-source format.,https://www.reddit.com/r/MachineLearning/comments/7d9f94/distributed_machine_learning_has_been_initiated/,0tk,1510800463,,0,1
802,2017-11-16,2017,11,16,11,7d9fvi,[P] Easy to Use Wrapper for Deep Local Feature (DELF) for images,https://www.reddit.com/r/MachineLearning/comments/7d9fvi/p_easy_to_use_wrapper_for_deep_local_feature_delf/,insikk0,1510800661,,0,5
803,2017-11-16,2017,11,16,15,7daire,Machine learning jobs and requisite education,https://www.reddit.com/r/MachineLearning/comments/7daire/machine_learning_jobs_and_requisite_education/,questionerofconcepts,1510812796,[removed],0,1
804,2017-11-16,2017,11,16,15,7damxq,[R] Simon Knowles (CTO of Graphcore): Designing Processors for Intelligence,https://www.reddit.com/r/MachineLearning/comments/7damxq/r_simon_knowles_cto_of_graphcore_designing/,evc123,1510814329,,0,7
805,2017-11-16,2017,11,16,15,7danxo,Slurry Pumps,https://www.reddit.com/r/MachineLearning/comments/7danxo/slurry_pumps/,stephenbeade,1510814725,,0,1
806,2017-11-16,2017,11,16,16,7daqh0,Pillow Type Sesame Candy Bar Packing Machine|Sesame Bar Wrapping Machine...,https://www.reddit.com/r/MachineLearning/comments/7daqh0/pillow_type_sesame_candy_bar_packing/,tinawangsnow,1510815713,,1,1
807,2017-11-16,2017,11,16,16,7daqra,[D] How autonomous weapons with AI could go bad.,https://www.reddit.com/r/MachineLearning/comments/7daqra/d_how_autonomous_weapons_with_ai_could_go_bad/,PervertWhenCorrected,1510815817,,0,0
808,2017-11-16,2017,11,16,16,7dawn3,Logistic Regression Made Easy,https://www.reddit.com/r/MachineLearning/comments/7dawn3/logistic_regression_made_easy/,mgr2786,1510818075,[removed],0,1
809,2017-11-16,2017,11,16,17,7db1uj,ceiling analysis in ML,https://www.reddit.com/r/MachineLearning/comments/7db1uj/ceiling_analysis_in_ml/,sharanbr,1510820266,[removed],0,1
810,2017-11-16,2017,11,16,17,7db6kk,[D] Isnt machine learning actually reverse engineering of the human brain?,https://www.reddit.com/r/MachineLearning/comments/7db6kk/d_isnt_machine_learning_actually_reverse/,[deleted],1510822364,[deleted],4,0
811,2017-11-16,2017,11,16,18,7db8th,[D] Scalable Machine Learning System Development: Learning Resources,https://www.reddit.com/r/MachineLearning/comments/7db8th/d_scalable_machine_learning_system_development/,upulbandara,1510823312,What are some good video lectures/talks for learning scalable machine learning system developments?,0,8
812,2017-11-16,2017,11,16,18,7dba64,[D] It seems like lack of research into prior work seems to be a significant issue in Machine Learning. How big is this issue? Do you have an experiences or examples ? Do you ever have issues doing a literature search for a particular ML topic ?,https://www.reddit.com/r/MachineLearning/comments/7dba64/d_it_seems_like_lack_of_research_into_prior_work/,Batmantosh,1510823903,"Looking at the last submissions for the swish activation function, I found comments like these:

&gt;Research is moving very fast and honest mistakes happen....But it seems like lack of research into prior work and desire for publicity is getting somewhat rampant.

https://www.reddit.com/r/MachineLearning/comments/77843q/rd_in_light_of_the_silu_swish_fiasco_was/

&gt;Very few researchers: a) don't miss any prior work (especially published same year or, in another extreme, - published before Internet existed); b) don't make mistakes in their implementations, experiments or proofs.

https://www.reddit.com/r/MachineLearning/comments/77843q/rd_in_light_of_the_silu_swish_fiasco_was/dojy2bu/?utm_content=permalink&amp;utm_medium=front&amp;utm_source=reddit&amp;utm_name=MachineLearning

&gt;As has been pointed out, we missed prior works that proposed the same activation function. The fault lies entirely with me for not conducting a thorough enough literature search. 

https://www.reddit.com/r/MachineLearning/comments/773epu/r_swish_a_selfgated_activation_function_google/dojjag2/?utm_content=permalink&amp;utm_medium=front&amp;utm_source=reddit&amp;utm_name=MachineLearning

It seems like if a prominent member of the Google Brain team had trouble with literature searches, it would be a problem for just about anyone. 

The term 'Machine Learning' by itself has over 4 million results in google scholar. It seems like there a lot of literature out there. 

What issues with ML literature searches have you seen or experienced? Was there a time where you knew it was very likely there was literature about some particular topic, but you just couldn't find it? Or, like in the case of the swish incident, was there a time where you thought you did a thorough literature search, only to find out that you missed some papers? 

What do you think the main issues are? Is there a variation in semantics which causes search queries not to pick up all results for a particular topic, or retrieve too many? Is there a lack of terms or phrases for a particular topic, so that you have to look for indirect ways to look it up? 
",62,36
813,2017-11-16,2017,11,16,19,7dbjze,[N]So what exactly is IBM doing different with machine learning?,https://www.reddit.com/r/MachineLearning/comments/7dbjze/nso_what_exactly_is_ibm_doing_different_with/,digitalson,1510828111,,0,1
814,2017-11-16,2017,11,16,20,7dbp2l,Help train Leela Zero on Windows/macOS/Linux,https://www.reddit.com/r/MachineLearning/comments/7dbp2l/help_train_leela_zero_on_windowsmacoslinux/,thefirelane,1510830267,,0,1
815,2017-11-16,2017,11,16,21,7dbxtb,Dumpling Making Machine for Home,https://www.reddit.com/r/MachineLearning/comments/7dbxtb/dumpling_making_machine_for_home/,liusherry,1510833721,,1,1
816,2017-11-16,2017,11,16,21,7dc1i6,Fully automatic rice noodle making and steaming macine,https://www.reddit.com/r/MachineLearning/comments/7dc1i6/fully_automatic_rice_noodle_making_and_steaming/,liusherry,1510835035,[removed],1,1
817,2017-11-16,2017,11,16,21,7dc3n2,[D] Need small help in basic NN,https://www.reddit.com/r/MachineLearning/comments/7dc3n2/d_need_small_help_in_basic_nn/,question2121,1510835795,"I'm very new to ML and have been using anaconda/python. So started to create a NN using only matrices.
Got confused on the significance of the weight matrix size[syn0] used in the code below-
What does it depend on? How should the array/matrix if my input is different, suppose a 6x7?
please do let me know if you guys have an idea. i took the code from [here](http://iamtrask.github.io/2015/07/12/basic-python-network/)

This is the code I'm using -  
  
	import numpy as np

	def nonlin(x,deriv=False):
		if(deriv==True):
			return x*(1-x)

		return 1/(1+np.exp(-x))
		
	X = np.array([[0,0,1],
				[0,1,1],
				[1,0,1],
				[1,1,1]])
					
	y = np.array([[0],
				[1],
				[1],
				[0]])

	np.random.seed(1)

	# randomly initialize our weights with mean 0
	syn0 = 2*np.random.random((3,4)) - 1
	syn1 = 2*np.random.random((4,1)) - 1

	for j in xrange(60000):

		# Feed forward through layers 0, 1, and 2
		l0 = X
		l1 = nonlin(np.dot(l0,syn0))
		l2 = nonlin(np.dot(l1,syn1))

		# how much did we miss the target value?
		l2_error = y - l2
		
		if (j% 10000) == 0:
			print ""Error:"" + str(np.mean(np.abs(l2_error)))
			
		# in what direction is the target value?
		# were we really sure? if so, don't change too much.
		l2_delta = l2_error*nonlin(l2,deriv=True)

		# how much did each l1 value contribute to the l2 error (according to the weights)?
		l1_error = l2_delta.dot(syn1.T)
		
		# in what direction is the target l1?
		# were we really sure? if so, don't change too much.
		l1_delta = l1_error * nonlin(l1,deriv=True)

		syn1 += l1.T.dot(l2_delta)
		syn0 += l0.T.dot(l1_delta)
",4,0
818,2017-11-16,2017,11,16,21,7dc3th,Dry Stick Noodle Production Line | Dried Noodle Machine for Sale,https://www.reddit.com/r/MachineLearning/comments/7dc3th/dry_stick_noodle_production_line_dried_noodle/,liusherry,1510835859,[removed],1,1
819,2017-11-16,2017,11,16,21,7dc56d,[R]HelloFresh: Machine Learning Engineer,https://www.reddit.com/r/MachineLearning/comments/7dc56d/rhellofresh_machine_learning_engineer/,jackblun,1510836335,,0,1
820,2017-11-16,2017,11,16,21,7dc6zm,Trumpicasso.. please vote,https://www.reddit.com/r/MachineLearning/comments/7dc6zm/trumpicasso_please_vote/,nimesh112,1510836941,,0,1
821,2017-11-16,2017,11,16,22,7dcc16,An overview of activation functions used in neural networks,https://www.reddit.com/r/MachineLearning/comments/7dcc16/an_overview_of_activation_functions_used_in/,adl1995,1510838470,,0,1
822,2017-11-16,2017,11,16,23,7dcpg2,Is there a software that could find and write metadata for my iTunes music library?,https://www.reddit.com/r/MachineLearning/comments/7dcpg2/is_there_a_software_that_could_find_and_write/,Asohailwahab,1510842383,[removed],1,1
823,2017-11-16,2017,11,16,23,7dcq2m,How Question Answering System Works,https://www.reddit.com/r/MachineLearning/comments/7dcq2m/how_question_answering_system_works/,munishmaxtech,1510842566,,0,1
824,2017-11-16,2017,11,16,23,7dcvwq,Data Tagging in Medical Imaging  Diving Deep into the Processes,https://www.reddit.com/r/MachineLearning/comments/7dcvwq/data_tagging_in_medical_imaging_diving_deep_into/,shashankg22,1510844151,,0,1
825,2017-11-16,2017,11,16,23,7dcwmt,[D] Need help implementing Conditional DCGAN with CelebA,https://www.reddit.com/r/MachineLearning/comments/7dcwmt/d_need_help_implementing_conditional_dcgan_with/,[deleted],1510844333,[deleted],5,3
826,2017-11-17,2017,11,17,0,7dcyvk,Machine Learning used to detect Gerrymandering,https://www.reddit.com/r/MachineLearning/comments/7dcyvk/machine_learning_used_to_detect_gerrymandering/,dream__tiger,1510844888,,0,1
827,2017-11-17,2017,11,17,0,7dczwu,[R] Popular types of neural networks and their applications,https://www.reddit.com/r/MachineLearning/comments/7dczwu/r_popular_types_of_neural_networks_and_their/,FrostyCharizard,1510845158,,1,12
828,2017-11-17,2017,11,17,0,7dd0ex,[R] An On-device Deep Neural Network for Face Detection - Apple,https://www.reddit.com/r/MachineLearning/comments/7dd0ex/r_an_ondevice_deep_neural_network_for_face/,madebyollin,1510845294,,9,27
829,2017-11-17,2017,11,17,0,7dd1sv,I want to start machine learning project of a music recommendation system?,https://www.reddit.com/r/MachineLearning/comments/7dd1sv/i_want_to_start_machine_learning_project_of_a/,TroubledClassifier,1510845654,[removed],0,1
830,2017-11-17,2017,11,17,0,7dd45h,[D] A Cookbook for Machine Learning: a list of ML problem transformations and when to use them,https://www.reddit.com/r/MachineLearning/comments/7dd45h/d_a_cookbook_for_machine_learning_a_list_of_ml/,fhuszar,1510846269,,58,362
831,2017-11-17,2017,11,17,0,7dd7hh,"[N] Weekly Machine Learning Toolset &amp; Library Roundup  Nov. 16, 2017",https://www.reddit.com/r/MachineLearning/comments/7dd7hh/n_weekly_machine_learning_toolset_library_roundup/,stkim1,1510847140,,0,1
832,2017-11-17,2017,11,17,0,7dd7o2,How the fussed lasso and linear optimization can help describe how MLB MVP voters think.,https://www.reddit.com/r/MachineLearning/comments/7dd7o2/how_the_fussed_lasso_and_linear_optimization_can/,ssharpe42,1510847186,,0,1
833,2017-11-17,2017,11,17,0,7dd99a,[N] TensorFlow Speech Recognition Challenge,https://www.reddit.com/r/MachineLearning/comments/7dd99a/n_tensorflow_speech_recognition_challenge/,singularvalue,1510847581,,10,27
834,2017-11-17,2017,11,17,1,7ddb8h,"[Code Europe] IT Stars form Uber, Netflix, Microsoft, Oracle, Walt Disney, Soundcloud @ the largest programming conference in Central Eastern Europe",https://www.reddit.com/r/MachineLearning/comments/7ddb8h/code_europe_it_stars_form_uber_netflix_microsoft/,CodeEurope,1510848063,,0,1
835,2017-11-17,2017,11,17,1,7ddbb8,This ChatBot is doing wonders in terms of conversational NLP.,https://www.reddit.com/r/MachineLearning/comments/7ddbb8/this_chatbot_is_doing_wonders_in_terms_of/,haggcoder,1510848078,,0,1
836,2017-11-17,2017,11,17,1,7ddbeg,[D] Performing unsupervised classification for work on text and need help with a workflow.,https://www.reddit.com/r/MachineLearning/comments/7ddbeg/d_performing_unsupervised_classification_for_work/,TheLegendOfCode,1510848104,"I have a small project where I have to organize unlabeled conversations by classifying them.  I have done smaller ML projects in the past with labeled data, but I don't know where to begin with unlabeled data.  I have the data in CSV and JSON formats.  Here is what I have so far for my thought process:

-My initial tech ML library thought is to use Tensorflow or SKLearn.  I can learn the syntax fairly quickly if I know how to set it up.  

-I am working with text, so I am thinking of using a word2vec model or glove for the analysis of the text to see how it should be classified.

I am fairly new to Machine Learning, but I have a small idea so far (hopefully).  Is there anything else I should consider or think about with this?

EDIT: I also have to think of which ML model to use.  Since this will likely be done with a Neural Network of some type and it is classification, I was thinking of using an Autoencoder of  some type, even though I've seen it more for data generation.  Am I going in the right direction for using an AE or should I use something like a CNN for this somehow or some other type of NN model",7,3
837,2017-11-17,2017,11,17,1,7ddfgu,Emergence  How Stupid Things Become Smart Together,https://www.reddit.com/r/MachineLearning/comments/7ddfgu/emergence_how_stupid_things_become_smart_together/,gmsc,1510849070,,0,1
838,2017-11-17,2017,11,17,2,7ddx9a,In Depth Tutorial of Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/7ddx9a/in_depth_tutorial_of_convolutional_neural_networks/,bouncmpe,1510853212,,0,1
839,2017-11-17,2017,11,17,2,7de0mi,[P] Awesome Semantic Segmentation: papers with code + other resources,https://www.reddit.com/r/MachineLearning/comments/7de0mi/p_awesome_semantic_segmentation_papers_with_code/,alxndrkalinin,1510854001,,0,4
840,2017-11-17,2017,11,17,2,7de1u0,Simple Cart-Pole deep reinforcement learning agent,https://www.reddit.com/r/MachineLearning/comments/7de1u0/simple_cartpole_deep_reinforcement_learning_agent/,zthoutt,1510854307,,0,1
841,2017-11-17,2017,11,17,2,7de4wi,"[P] Implementation of ""Cortical microcircuits as gated-recurrent neural networks""",https://www.reddit.com/r/MachineLearning/comments/7de4wi/p_implementation_of_cortical_microcircuits_as/,dataxaar,1510855032,"Here's an implementation of the paper [Cortical microcircuits as gated-recurrent neural networks](https://arxiv.org/abs/1711.02448)

Code: [https://github.com/ixaxaar/pytorch-sublstm](https://github.com/ixaxaar/pytorch-sublstm)

A word language model task can be found [here](https://github.com/ixaxaar/pytorch-sublstm/tree/master/tasks/word_language_model).
",0,3
842,2017-11-17,2017,11,17,3,7de8av,[D] Am I finding the correlation among these encoded categorical variables correctly?,https://www.reddit.com/r/MachineLearning/comments/7de8av/d_am_i_finding_the_correlation_among_these/,Fender6969,1510855822,"I am running SVM and Logistic Regression models for a churn management problem (target variable is yes or no). I have created a pandas dataframe in which I have ran ""pd.get_dummies"" on the categorical variables and replaced the columns with these new variables.

After doing this, I ran SVM and Logistic Regression to find that Logistic Regression has the highest accuracy. I now want to do feature selection so that I can drop some very low correlated variables. After doing some research online, I found that I can do ""df['feature'].corr[df['target variable']"" and it is putting out some correlation. 

Some of my variables are numeric as well as many being categorical. Can I simply place my categorical dummy variable column (which is taking the place of the original categorical column) as my 'feature' and the dummy variable column (yes or no) as my 'target variable' for the correlation?",4,0
843,2017-11-17,2017,11,17,3,7debuu,[R] ResNet Question,https://www.reddit.com/r/MachineLearning/comments/7debuu/r_resnet_question/,tejpalv8,1510856636,Is there a purpose to having residual blocks at every layer in ResNet? What would happen if you only kept them at the beginning or the end?,5,1
844,2017-11-17,2017,11,17,3,7deh12,Identifying hooded criminals,https://www.reddit.com/r/MachineLearning/comments/7deh12/identifying_hooded_criminals/,mount_sumInt,1510857855,[removed],0,1
845,2017-11-17,2017,11,17,3,7dehhm,"Peter Dayan leaves Gatsby Computational Neuroscience Unit, joins Uber AI Labs",https://www.reddit.com/r/MachineLearning/comments/7dehhm/peter_dayan_leaves_gatsby_computational/,DanielleMolloy,1510857964,,0,1
846,2017-11-17,2017,11,17,4,7dem0s,[R] Variational Bi-LSTMs,https://www.reddit.com/r/MachineLearning/comments/7dem0s/r_variational_bilstms/,madebyollin,1510858991,,2,5
847,2017-11-17,2017,11,17,4,7deq2z,[D] ELI5 the drawbacks of capsules m,https://www.reddit.com/r/MachineLearning/comments/7deq2z/d_eli5_the_drawbacks_of_capsules_m/,whoisthebossbitch,1510859890,"
One drawback of Capsules which it shares with generative models is that it likes to account for everything in the image so it does better when it can model the clutter than when it just uses an additional orphan category in the dynamic routing. In CIFAR-10, the backgrounds are much too varied to model in a reasonable sized net which helps to account for the poorer performance.


That excerpt is from the paper. Can someone tell me in simple words? ",7,8
848,2017-11-17,2017,11,17,4,7deq9m,[R] Thermometer Encoding: One Hot Way To Resist Adversarial Examples,https://www.reddit.com/r/MachineLearning/comments/7deq9m/r_thermometer_encoding_one_hot_way_to_resist/,downtownslim,1510859932,,0,1
849,2017-11-17,2017,11,17,5,7df2y0,Is it worth creating a subreddit dedicated to questions/answers about deep learning?,https://www.reddit.com/r/MachineLearning/comments/7df2y0/is_it_worth_creating_a_subreddit_dedicated_to/,timmytimmyturner12,1510862825,[removed],0,1
850,2017-11-17,2017,11,17,5,7df85b,"Since a fully connected layer forms a universal approximator, could it *theoretically* be possible to compress a complex network to a single layer?",https://www.reddit.com/r/MachineLearning/comments/7df85b/since_a_fully_connected_layer_forms_a_universal/,[deleted],1510864013,,0,1
851,2017-11-17,2017,11,17,5,7dfc8v,[D] The AI Layer,https://www.reddit.com/r/MachineLearning/comments/7dfc8v/d_the_ai_layer/,mikeyanderson,1510864923,,3,0
852,2017-11-17,2017,11,17,5,7dfd9s,The Three Way Race to the Future of AI. Quantum vs. Neuromorphic vs. High Performance Computing,https://www.reddit.com/r/MachineLearning/comments/7dfd9s/the_three_way_race_to_the_future_of_ai_quantum_vs/,Robert4422,1510865152,,0,1
853,2017-11-17,2017,11,17,5,7dfdhc,Build and Deploy Scalable Machine Learning in Production with Kafka,https://www.reddit.com/r/MachineLearning/comments/7dfdhc/build_and_deploy_scalable_machine_learning_in/,onlysadpandas,1510865199,,1,10
854,2017-11-17,2017,11,17,5,7dff36,"[D] Since a fully connected layer forms a universal approximator, could it *theoretically* be possible to compress a complex network to a single layer?",https://www.reddit.com/r/MachineLearning/comments/7dff36/d_since_a_fully_connected_layer_forms_a_universal/,[deleted],1510865540,[deleted],10,1
855,2017-11-17,2017,11,17,6,7dfj9r,[D] What are the challenges in providing users with neural networks they can tailor to their needs?,https://www.reddit.com/r/MachineLearning/comments/7dfj9r/d_what_are_the_challenges_in_providing_users_with/,Valiox,1510866466,"For example: one user unfamiliar with machine learning downloads the following hypotetical program. It asks the user to provide photographs (or music, wallpapers, videos, ...) and to rate them, possibly asking what part of the content they enjoy or dislike. Since the neural network that comes with the program is pretrained for the specific application, the user is merely fine-tuning and could probably get a network that emulates his tastes with merely a few hundreds of samples. The applications would be very wide: finding new content for the user, modifying a part of a media so the user enjoy it more (removing cars from a landscape picture, adding one instrument in a song, ...), generating new content, ...

I can't speak for the audio and video aspects of this yet, but I am under the impression that we have all the technology to do this with images. Am I wrong?",1,4
856,2017-11-17,2017,11,17,7,7dfwoz,[N] Announcing ONNX Support for Apache MXNet | Amazon Web Services,https://www.reddit.com/r/MachineLearning/comments/7dfwoz/n_announcing_onnx_support_for_apache_mxnet_amazon/,ydereky,1510869735,,2,7
857,2017-11-17,2017,11,17,7,7dfyhf,Visually-Aware Fashion Recommendation and Design with Generative Image Models,https://www.reddit.com/r/MachineLearning/comments/7dfyhf/visuallyaware_fashion_recommendation_and_design/,balazshoranyi,1510870235,,0,1
858,2017-11-17,2017,11,17,7,7dg6th,[N] Real Robot Parkour,https://www.reddit.com/r/MachineLearning/comments/7dg6th/n_real_robot_parkour/,evc123,1510872638,,51,56
859,2017-11-17,2017,11,17,8,7dggm2,[P] Undress her - Automatically unclothe girls using AI,https://www.reddit.com/r/MachineLearning/comments/7dggm2/p_undress_her_automatically_unclothe_girls_using/,undress-her,1510875211,,15,0
860,2017-11-17,2017,11,17,10,7dh522,My First ML Project: Using RNNs to Generate a Fake ICO White Paper,https://www.reddit.com/r/MachineLearning/comments/7dh522/my_first_ml_project_using_rnns_to_generate_a_fake/,[deleted],1510880570,[deleted],0,1
861,2017-11-17,2017,11,17,10,7dhgf9,CoRL proceedings videos ?,https://www.reddit.com/r/MachineLearning/comments/7dhgf9/corl_proceedings_videos/,maimaiml,1510883913,[removed],0,1
862,2017-11-17,2017,11,17,11,7dhk31,IBM makes 20 qubit quantum computing machine available as a cloud service,https://www.reddit.com/r/MachineLearning/comments/7dhk31/ibm_makes_20_qubit_quantum_computing_machine/,[deleted],1510884963,[deleted],0,1
863,2017-11-17,2017,11,17,11,7dhky4,Easy method/standard practice for computing a gram matrix as a layer,https://www.reddit.com/r/MachineLearning/comments/7dhky4/easy_methodstandard_practice_for_computing_a_gram/,[deleted],1510885153,,0,1
864,2017-11-17,2017,11,17,11,7dhlcm,[N] IBM makes 20 qubit quantum computing machine available as a cloud service,https://www.reddit.com/r/MachineLearning/comments/7dhlcm/n_ibm_makes_20_qubit_quantum_computing_machine/,[deleted],1510885258,[deleted],0,1
865,2017-11-17,2017,11,17,11,7dhmkq,Is there any way to use PyCharm to remotely execute program to train NN in AWS instance?,https://www.reddit.com/r/MachineLearning/comments/7dhmkq/is_there_any_way_to_use_pycharm_to_remotely/,TheUltimateFuckUp,1510885584,[removed],0,1
866,2017-11-17,2017,11,17,12,7dhy64,Machine Learning Algorithms: Which One to Choose for Your Problem,https://www.reddit.com/r/MachineLearning/comments/7dhy64/machine_learning_algorithms_which_one_to_choose/,TeddyXu,1510888805,,0,1
867,2017-11-17,2017,11,17,12,7di40e,[R] NIPS 2017 Pre-Proceedings,https://www.reddit.com/r/MachineLearning/comments/7di40e/r_nips_2017_preproceedings/,riel234,1510890574,,0,5
868,2017-11-17,2017,11,17,12,7di489,[R] Looking for Spoken Language Classification papers and APIs.,https://www.reddit.com/r/MachineLearning/comments/7di489/r_looking_for_spoken_language_classification/,underfitting,1510890654,"Are there any papers and APIs to recognize languages spoken by a group of people like the following?

INPUT : Audio, 
OUTPUT : Language (English, French, Chinese,....)",1,0
869,2017-11-17,2017,11,17,13,7dicyk,[D] Is there any repository for replicating published result?,https://www.reddit.com/r/MachineLearning/comments/7dicyk/d_is_there_any_repository_for_replicating/,classyfication,1510893325,"Before using techniques published in statistics and/or ML papers, I often have to derive the skipped math, write the code, and run the simulation myself to trust the result.

There must be a lot of people doing this kind of replication work. Is there a repository of such replications that we can contribute to?",11,7
870,2017-11-17,2017,11,17,15,7divho,"[R] Learning to Generate Conditionally from Unconditional Generative Models [Enable conditional generation of data without retraining by post-hoc learning latent constraints, value functions that identify regions in latent space that generate outputs with desired attributes]",https://www.reddit.com/r/MachineLearning/comments/7divho/r_learning_to_generate_conditionally_from/,rishabh135,1510899411,,4,2
871,2017-11-17,2017,11,17,15,7diw72,Bio organic fertilizer machinery,https://www.reddit.com/r/MachineLearning/comments/7diw72/bio_organic_fertilizer_machinery/,amylee516,1510899678,,0,1
872,2017-11-17,2017,11,17,15,7dix8v,[D] How is the NVIDIA Quadro P4000 for deep learning?,https://www.reddit.com/r/MachineLearning/comments/7dix8v/d_how_is_the_nvidia_quadro_p4000_for_deep_learning/,shayanrc,1510900055,"My company is procuring one of these for a project. I know CUDA is supported on all nvidia cards, but I am primarily worried about the driver support on linux.

Does anyone have any experience using this card (or any other Quadro card) for deep learning?",4,0
873,2017-11-17,2017,11,17,16,7dj50t,"[D] Demystifying Face Recognition: Blog series (Parts 1,2,3)",https://www.reddit.com/r/MachineLearning/comments/7dj50t/d_demystifying_face_recognition_blog_series_parts/,melgor89,1510902727,,5,37
874,2017-11-17,2017,11,17,16,7dj6t3,[D] Variations in spider species mating dances resemble odd gaits in learning robots,https://www.reddit.com/r/MachineLearning/comments/7dj6t3/d_variations_in_spider_species_mating_dances/,phobrain,1510903347,,1,2
875,2017-11-17,2017,11,17,17,7djcwy,Do Neural Networks Learn Shearlets?,https://www.reddit.com/r/MachineLearning/comments/7djcwy/do_neural_networks_learn_shearlets/,manifoldlearner,1510905604,,1,1
876,2017-11-17,2017,11,17,17,7djf24,Personal Recommendation Engine,https://www.reddit.com/r/MachineLearning/comments/7djf24/personal_recommendation_engine/,ghost_sdk,1510906410,[removed],0,1
877,2017-11-17,2017,11,17,17,7djij3,Introduction of Human Computer Interaction,https://www.reddit.com/r/MachineLearning/comments/7djij3/introduction_of_human_computer_interaction/,munishmaxtech,1510907733,,0,1
878,2017-11-17,2017,11,17,19,7djw6q,[D] Keras + Horovod = Distributed Deep Learning on Steroids,https://www.reddit.com/r/MachineLearning/comments/7djw6q/d_keras_horovod_distributed_deep_learning_on/,ItsFrenchSoup,1510912981,,2,48
879,2017-11-17,2017,11,17,19,7djzio,Need help with C-RNN,https://www.reddit.com/r/MachineLearning/comments/7djzio/need_help_with_crnn/,akanimax,1510914165,,0,1
880,2017-11-17,2017,11,17,19,7dk01l,Unleashing the power of Sentiment Analysis through Visualization.,https://www.reddit.com/r/MachineLearning/comments/7dk01l/unleashing_the_power_of_sentiment_analysis/,yash1353,1510914377,[removed],0,1
881,2017-11-17,2017,11,17,20,7dk8jd,Tortellini Making Machine | Kitchen Tortellini Maker,https://www.reddit.com/r/MachineLearning/comments/7dk8jd/tortellini_making_machine_kitchen_tortellini_maker/,liusherry,1510917508,,1,1
882,2017-11-17,2017,11,17,20,7dk945,[N] A user friendly editor based on Tensorflow: AI Blocks,https://www.reddit.com/r/MachineLearning/comments/7dk945/n_a_user_friendly_editor_based_on_tensorflow_ai/,smilefr,1510917719,"Hi everyone!

AI Blocs is a *WYSIWYG* interface making it easier for developers to implement models quickly, I wanted to share my tool with you, hopefully this might help someone, It has proven itself to be very useful to me.

[Screenshot](https://raw.githubusercontent.com/MrNothing/AI-Blocks/master/ScreenShots/sc5.png)

The interface is inspired from Unity, you can attach scripts to objects in the scene, run graphs and view the output in real time. 

I would love to get some feedback if you have time to check it out.

**Github**: https://github.com/MrNothing/AI-Blocks

**Releases**: https://github.com/MrNothing/AI-Blocks/releases

Thank you!",26,209
883,2017-11-17,2017,11,17,20,7dkdl4,[P] tsh - deep learning shell with GPU support based on Docker,https://www.reddit.com/r/MachineLearning/comments/7dkdl4/p_tsh_deep_learning_shell_with_gpu_support_based/,nuasd,1510919307,"tsh is shell-like wrapper around deep learning Docker image. Executing tsh will mount current directory and X11 socket inside a container.

GitHub: [github.com/kbobrowski/tsh](https://github.com/kbobrowski/tsh)

Requires Nvidia GPU drivers, docker and nvidia-docker2 installed.

Features:

* Ubuntu 16.04
* CUDA 8.0
* cuDNN 6
* tensorflow 1.3
* keras 2.1.1
* pytorch 0.2
* OpenCV 3.3.1 (GTK support)
* ffmpeg
* numpy, scipy, pandas, sklearn, jupyter, matplotlib, Pillow, h5py, scikit-image, sk-video

shell:

* zsh with oh-my-zsh and pure prompt for integration with git
* running as standard user

Raw deep learning docker image with GPU support is available on dockerhub: [hub.docker.com/r/kbobrowski/deep-learning-essentials](https://hub.docker.com/r/kbobrowski/deep-learning-essentials/)",5,6
884,2017-11-17,2017,11,17,21,7dki8l,Marco Bollow,https://www.reddit.com/r/MachineLearning/comments/7dki8l/marco_bollow/,stephaniebischoff,1510920870,,0,1
885,2017-11-17,2017,11,17,21,7dkijo,Introduction to AI for Video Games,https://www.reddit.com/r/MachineLearning/comments/7dkijo/introduction_to_ai_for_video_games/,funmaster11,1510920981,,0,1
886,2017-11-17,2017,11,17,21,7dknxe,[N]Algorithmia now helps businesses manage and deploy their machine learning models,https://www.reddit.com/r/MachineLearning/comments/7dknxe/nalgorithmia_now_helps_businesses_manage_and/,polllyyy,1510922762,,0,1
887,2017-11-17,2017,11,17,21,7dkpge,[N]Google brings on-device machine learning to mobile with TensorFlow Lite,https://www.reddit.com/r/MachineLearning/comments/7dkpge/ngoogle_brings_ondevice_machine_learning_to/,janemoz,1510923248,,0,1
888,2017-11-17,2017,11,17,22,7dkqzu,[N]Apple details how it performs on-device facial detection in latest machine learning journal entry,https://www.reddit.com/r/MachineLearning/comments/7dkqzu/napple_details_how_it_performs_ondevice_facial/,jackblun,1510923686,,0,1
889,2017-11-17,2017,11,17,22,7dkuho,[N]Deep Neural Networks for Face Detection Explained on Apple's Machine Learning Journal,https://www.reddit.com/r/MachineLearning/comments/7dkuho/ndeep_neural_networks_for_face_detection/,chris_shpak,1510924696,,0,1
890,2017-11-17,2017,11,17,22,7dkws6,many to many relationship sql + c# regex,https://www.reddit.com/r/MachineLearning/comments/7dkws6/many_to_many_relationship_sql_c_regex/,lionschasing,1510925265,[removed],0,1
891,2017-11-17,2017,11,17,22,7dkwth,[N]Seattles Algorithmia wants to help machine learning researchers get up and running in production,https://www.reddit.com/r/MachineLearning/comments/7dkwth/nseattles_algorithmia_wants_to_help_machine/,dearpetra,1510925276,,0,2
892,2017-11-17,2017,11,17,22,7dkysm,"IoT platform, launched on Kickstarter, eases makers' entry to machine learning",https://www.reddit.com/r/MachineLearning/comments/7dkysm/iot_platform_launched_on_kickstarter_eases_makers/,ppv999,1510925840,,0,1
893,2017-11-17,2017,11,17,22,7dl2mu,[P] Building an object detection toolkit with TensorFlow (video),https://www.reddit.com/r/MachineLearning/comments/7dl2mu/p_building_an_object_detection_toolkit_with/,thesameoldstories,1510926913,,0,7
894,2017-11-17,2017,11,17,23,7dl3tz,Baesyan classifier with pos tagging has less accuracy than one without pos tagging. Is it possible?,https://www.reddit.com/r/MachineLearning/comments/7dl3tz/baesyan_classifier_with_pos_tagging_has_less/,ciotolaaaa,1510927235,[removed],0,1
895,2017-11-17,2017,11,17,23,7dl4pl,(for babies) Artificial neural network tutorials for kids,https://www.reddit.com/r/MachineLearning/comments/7dl4pl/for_babies_artificial_neural_network_tutorials/,[deleted],1510927457,,0,1
896,2017-11-17,2017,11,17,23,7dl76s,(for babies) Artificial neural network tutorial for kids,https://www.reddit.com/r/MachineLearning/comments/7dl76s/for_babies_artificial_neural_network_tutorial_for/,ProgrammingGodJordan,1510928133,,0,1
897,2017-11-17,2017,11,17,23,7dl7te,[D] Does it possible to cluster restaurant dishes?,https://www.reddit.com/r/MachineLearning/comments/7dl7te/d_does_it_possible_to_cluster_restaurant_dishes/,LangreShane,1510928305,"I have data about restaurants, their dishes and customer's orders. Then I want to cluster dishes in restaurant's menu by customer order. So clusters will be dishes in order and criteria of similarity will be price, ingredients and location of restaurant where dish is served.

For example if there is a Americano coffee in the order so result will be all coffees of all restaurants no farther then 100 metres from user(for example), and no more expensive than ordered coffee.

Seems like recommendation system, yes.
Does it possible to do it? If not than why? Can I do it by k-means method?",5,0
898,2017-11-17,2017,11,17,23,7dlc2x,Global versus Localized Generative Adversarial Nets,https://www.reddit.com/r/MachineLearning/comments/7dlc2x/global_versus_localized_generative_adversarial/,[deleted],1510929426,[deleted],1,1
899,2017-11-18,2017,11,18,0,7dlixq,[D] Regularization vs Model Size in CNNs,https://www.reddit.com/r/MachineLearning/comments/7dlixq/d_regularization_vs_model_size_in_cnns/,abello966,1510931135,"Hi! I read an introductory text to Deep Learning/CNN somewhere that argued that the best approach for overfitting is not to reduce the number of layers/filters but to increase regularization measures such as dropout, l2 regularization and so on. I think it went as far to say that (given you have enough data) you should try to use the biggest model your machine can handle and work from there

I wanted to reread/reference this text, but I can't find it anymore, does anyone remember it? And while we are at it, is this hypothesis tested? Is this generally true? In the Deep Learning Book there is something going in that direction: 

""What this [extremely complicated domains] means is that controlling the complexity of the model is not a simple matter of nding the model of the right size, with the right number of parameters. Instead, we might ndand indeed in practical deep learning scenarios, we almost always do ndthat the best tting model (in the sense of minimizing generalization error) is a large model that has been regularized appropriately.""

Thanks!",9,9
900,2017-11-18,2017,11,18,0,7dljq2,Looking for machine learning work focusing on social sciences/economics,https://www.reddit.com/r/MachineLearning/comments/7dljq2/looking_for_machine_learning_work_focusing_on/,no_bear_so_low,1510931334,[removed],0,1
901,2017-11-18,2017,11,18,0,7dlk6u,"Flat bottle double side labeling machine, front and backside of bottle l...",https://www.reddit.com/r/MachineLearning/comments/7dlk6u/flat_bottle_double_side_labeling_machine_front/,hymachinery,1510931448,,0,1
902,2017-11-18,2017,11,18,0,7dlt0p,Why are deep *linear* neural networks non convex?,https://www.reddit.com/r/MachineLearning/comments/7dlt0p/why_are_deep_linear_neural_networks_non_convex/,yashchandak,1510933538,[removed],0,1
903,2017-11-18,2017,11,18,0,7dltyy,In which way PSPnet did improve previous pyramid pooling?,https://www.reddit.com/r/MachineLearning/comments/7dltyy/in_which_way_pspnet_did_improve_previous_pyramid/,borbag,1510933754,[removed],0,1
904,2017-11-18,2017,11,18,0,7dluo8,[D] Can I use subproblem's optimal point as initial weight for full problem?,https://www.reddit.com/r/MachineLearning/comments/7dluo8/d_can_i_use_subproblems_optimal_point_as_initial/,fpenguin23,1510933926,"Currently I have quite large data set (near 350GB images). Every epoch takes almost 6~8 hours to train my model. 


It doesn't really good situation to find right model and parameters so I split data and use relatively small part of it (8~9GB). 


I'm currently planning find optimal weights (or near optimal weights) for small problem and use it as initial weight to train my full problem. But I'm afraid it is good approach for this situation. What do you think?


And is there any other strategies to deal with this situation?",10,2
905,2017-11-18,2017,11,18,1,7dlycq,LF Conversational AI Resources,https://www.reddit.com/r/MachineLearning/comments/7dlycq/lf_conversational_ai_resources/,tpapp157,1510934779,[removed],0,1
906,2017-11-18,2017,11,18,1,7dmaaz,When Creativity meets A.I.,https://www.reddit.com/r/MachineLearning/comments/7dmaaz/when_creativity_meets_ai/,[deleted],1510937599,[deleted],0,1
907,2017-11-18,2017,11,18,2,7dmdup,[D] in which way did pspnet improve previous pyramid pooling?,https://www.reddit.com/r/MachineLearning/comments/7dmdup/d_in_which_way_did_pspnet_improve_previous/,borbag,1510938476,"HE et al introduced [spatial pyramidal pooling](https://arxiv.org/abs/1406.4729) in 2014. Chen et al used it in 2016 with dilated convolution and called it the [Atrous Spatial Pyramid Pooling](https://arxiv.org/abs/1606.00915).

A few month later [PSPnet](https://arxiv.org/abs/1612.01105) was proposed and outperformed them. But I fail to see what was new. They are both based on ResNet-101 and SPP.",1,8
908,2017-11-18,2017,11,18,2,7dmgk5,Book recommendation,https://www.reddit.com/r/MachineLearning/comments/7dmgk5/book_recommendation/,sud_logan,1510939140,[removed],0,1
909,2017-11-18,2017,11,18,2,7dmoo7,[P] When Creativity meets AI,https://www.reddit.com/r/MachineLearning/comments/7dmoo7/p_when_creativity_meets_ai/,TheRealMrP1nk,1510941133,,0,12
910,2017-11-18,2017,11,18,3,7dmxdx,[N] Theano and the Future of PyMC | NumFOCUS,https://www.reddit.com/r/MachineLearning/comments/7dmxdx/n_theano_and_the_future_of_pymc_numfocus/,bobchennan,1510943322,,0,13
911,2017-11-18,2017,11,18,3,7dmxss,[N] Comments on arXiv papers,https://www.reddit.com/r/MachineLearning/comments/7dmxss/n_comments_on_arxiv_papers/,mgdo,1510943438,,1,6
912,2017-11-18,2017,11,18,3,7dn2ls,Deep Learning No Coding,https://www.reddit.com/r/MachineLearning/comments/7dn2ls/deep_learning_no_coding/,dennis_copeland,1510944525,[removed],0,1
913,2017-11-18,2017,11,18,4,7dn779,[D] Deep Learning No Coding,https://www.reddit.com/r/MachineLearning/comments/7dn779/d_deep_learning_no_coding/,dennis_copeland,1510945626,This seems like a neat tool but they didn't reach their funding goal. I'm interested if anyone has any insight into why this didn't get more support? To me it seems obviously useful to be able to put DL into practice with no coding - how come this isn't more popular?,8,0
914,2017-11-18,2017,11,18,4,7dn8ha,Cheapest way to train a very large NNs like Inception from scratch? [Discussion],https://www.reddit.com/r/MachineLearning/comments/7dn8ha/cheapest_way_to_train_a_very_large_nns_like/,Moondra2017,1510945939,"I want to get some experience training very large NNs (personal project) but can't afford Tesla GPUs.  It seems you NEED to have multiple Tesla gpus to train models of this size. 

Amazon offers cloud computing for I think about  $.70 an hour. 

From what I read about large NN's, it could take about a month with 8 Tesla Gpus, that would be about $500 ish. 

Is this the cheapest route? 

Is this the best way to go? 
Any way to get discounts or lower the price?

Thanks. ",32,5
915,2017-11-18,2017,11,18,4,7dn8ix,"Suggestions for ""cool projects"" presentation",https://www.reddit.com/r/MachineLearning/comments/7dn8ix/suggestions_for_cool_projects_presentation/,[deleted],1510945947,,0,1
916,2017-11-18,2017,11,18,4,7dnanw,AI Weekly 17 Nov 2017,https://www.reddit.com/r/MachineLearning/comments/7dnanw/ai_weekly_17_nov_2017/,TomekB,1510946463,,0,1
917,2017-11-18,2017,11,18,5,7dnvhx,[Request] Urgent help in WEKA needed!,https://www.reddit.com/r/MachineLearning/comments/7dnvhx/request_urgent_help_in_weka_needed/,IbrahimOjeili,1510951786,[removed],0,1
918,2017-11-18,2017,11,18,6,7dnzev,How to build a decision tree using the ID3 algorithm?,https://www.reddit.com/r/MachineLearning/comments/7dnzev/how_to_build_a_decision_tree_using_the_id3/,ml_beginner,1510952785,[removed],0,1
919,2017-11-18,2017,11,18,6,7do5zq,[D] Optimizing Website Content based on Historical Pageview Data,https://www.reddit.com/r/MachineLearning/comments/7do5zq/d_optimizing_website_content_based_on_historical/,workworkwork7,1510954467,"I'm looking for some sort of package that would allow me to take a dataset of URLs and page views for each URL to identify what topics / phrases / page titles etc. are most strongly correlated to page views.

Sorry if this is too vague or isn't really ML, but are there any R or Python packages that can do something like this? ",5,1
920,2017-11-18,2017,11,18,8,7doxhy,ML: Analyzing Resumes with Python,https://www.reddit.com/r/MachineLearning/comments/7doxhy/ml_analyzing_resumes_with_python/,Elb5465,1510961678,[removed],0,1
921,2017-11-18,2017,11,18,8,7dp0hd,[R] XGAN: Unsupervised Image-to-Image Translation for many-to-many Mappings,https://www.reddit.com/r/MachineLearning/comments/7dp0hd/r_xgan_unsupervised_imagetoimage_translation_for/,taion,1510962474,,0,5
922,2017-11-18,2017,11,18,9,7dp6wo,Do CNNs ignore colors?,https://www.reddit.com/r/MachineLearning/comments/7dp6wo/do_cnns_ignore_colors/,[deleted],1510964140,,0,1
923,2017-11-18,2017,11,18,9,7dpdia,"[metathought]: I wonder how many students were turned onto, or off, machine learning due to their own training set having increased their own objective function just the right way to keep hill climbing.",https://www.reddit.com/r/MachineLearning/comments/7dpdia/metathought_i_wonder_how_many_students_were/,rumborak,1510965920,[removed],0,1
924,2017-11-18,2017,11,18,9,7dpg4a,[R] Frame Interpolation with Multi-Scale Deep Loss Functions and Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/7dpg4a/r_frame_interpolation_with_multiscale_deep_loss/,madebyollin,1510966637,,19,10
925,2017-11-18,2017,11,18,10,7dpj4o,Making the most of NIPS,https://www.reddit.com/r/MachineLearning/comments/7dpj4o/making_the_most_of_nips/,mlisthebest,1510967458,[removed],0,1
926,2017-11-18,2017,11,18,12,7dq9oo,[R][1711.06020] Global versus Localized Generative Adversarial Nets,https://www.reddit.com/r/MachineLearning/comments/7dq9oo/r171106020_global_versus_localized_generative/,[deleted],1510975126,[deleted],0,1
927,2017-11-18,2017,11,18,12,7dqbyp,[R][1711.06020] Global versus Localized Generative Adversarial Nets,https://www.reddit.com/r/MachineLearning/comments/7dqbyp/r171106020_global_versus_localized_generative/,guojunq,1510975822,,3,4
928,2017-11-18,2017,11,18,12,7dqc1r,Make Machine Learn - Part 1: Introduction,https://www.reddit.com/r/MachineLearning/comments/7dqc1r/make_machine_learn_part_1_introduction/,swornim00,1510975848,,0,1
929,2017-11-18,2017,11,18,13,7dqihz,"Gradient Trader Part 4: Preparing Training Set with Rust, Rayon and npy binary format",https://www.reddit.com/r/MachineLearning/comments/7dqihz/gradient_trader_part_4_preparing_training_set/,[deleted],1510977852,[deleted],0,1
930,2017-11-18,2017,11,18,13,7dqipb,DeepMind Tutorial on Deep Generative Models,https://www.reddit.com/r/MachineLearning/comments/7dqipb/deepmind_tutorial_on_deep_generative_models/,sritee,1510977921,,0,1
931,2017-11-18,2017,11,18,13,7dqkp8,How to extract meaningful concept from embedding?,https://www.reddit.com/r/MachineLearning/comments/7dqkp8/how_to_extract_meaningful_concept_from_embedding/,walkingsparrow,1510978583,[removed],0,1
932,2017-11-18,2017,11,18,14,7dqtby,[D] Low entry barrier is destroying deep learning reputation,https://www.reddit.com/r/MachineLearning/comments/7dqtby/d_low_entry_barrier_is_destroying_deep_learning/,ilija139,1510981512,"For a long time now, I notice many self-proclaimed deep learning experts, wizards, and what-not. With no educational or research background in either machine or deep learning, they think they have obtained expert knowledge in deep learning just by installing tensorflow or keras and running some code from github. Then, they immediately add ""deep learning expert"" to their name and write tutorial blog posts or even have the nerve to offer courses and write books. Not long ago, I reviewed a book proposal about deep reinforcement learning by some two ""hackers"", who had no education and no work experience in either machine, deep or deep reinforcement learning, yet they felt they are already experts in it that they just had to write a book about it...

Why this bothers me?

It destroys the reputation of deep learning. Most companies have no clue how to recognize these so called ""experts"". The job interviewers don't have the required deep learning expertise to properly evaluate candidates and NIPS, ICML, et al. mean nothing to them. So they end up hiring the ""experts"". Then when inevitably their ""deep learning"" solutions fail, they conclude that deep learning is not working and it's nothing but a hype. As more and more companies experience this, more and more companies become skeptical about deep learning. 
Already, people from the industry half-jokingly refer to AI as artificially inflated. 

What do you think? Do you agree or not? 
If you agree, what should we do? 
Start, a deep learning hiring agency? :)


Update: When I say low entry barrier I don't mean access to education. I mean the accessibility of the material, i.e. you don't need to know much about machine or deep learning to apply it with success to well known problems. However, you do need the knowledge and the research experience to apply it on novel problems.",242,198
933,2017-11-18,2017,11,18,14,7dqvm2,[P] Low Dimensional Autoencoder (Keras),https://www.reddit.com/r/MachineLearning/comments/7dqvm2/p_low_dimensional_autoencoder_keras/,Another__one,1510982293,"Hello. I'm started to learn keras not so long ago, and encountered with a problem: when I was trying to encode words into meaningful 2D space, model had stuck at some loss no matter how long I train it. I was trying to find ready-made solutions, but not very successful. And then I got some idea and it's worked. I adapted it for MNIST dataset and posted on github. Maybe it will be helpful for someone.

Here it is: https://github.com/Mylittlerapture/Low-Dimensional-Autoencoder

I'm not so familiar with machine learning for now, so I don't really know if it's something new and interesting. Don't blame me if it's not :)",2,5
934,2017-11-18,2017,11,18,15,7dr6q2,[D] Has anyone here attended either University of Edinburgh or University of Amsterdam Machine Learning Master's courses?,https://www.reddit.com/r/MachineLearning/comments/7dr6q2/d_has_anyone_here_attended_either_university_of/,agentFunction,1510986265,"Hey there,

As per the title, I'm looking for an evaluation of those two courses. I'm thinking about doing a Master's degree next year and those are currently my top two contenders (decidedly do not want to rent a room in London).

Any feedback is greatly appreciated!",13,6
935,2017-11-18,2017,11,18,16,7drhde,[Question] How to build a portfolio as a Data Science Engineer ?,https://www.reddit.com/r/MachineLearning/comments/7drhde/question_how_to_build_a_portfolio_as_a_data/,[deleted],1510990518,,0,1
936,2017-11-18,2017,11,18,16,7driv1,[D] How to build a Portfolio as a #DataScience Engineer ?,https://www.reddit.com/r/MachineLearning/comments/7driv1/d_how_to_build_a_portfolio_as_a_datascience/,[deleted],1510991149,,0,7
937,2017-11-18,2017,11,18,17,7drl0p,"[D] Problems with the ""human level pneumonia detection"" paper",https://www.reddit.com/r/MachineLearning/comments/7drl0p/d_problems_with_the_human_level_pneumonia/,rumblestiltsken,1510992091,,24,80
938,2017-11-18,2017,11,18,17,7drrmq,are Nvidia DLI workshops worth it?,https://www.reddit.com/r/MachineLearning/comments/7drrmq/are_nvidia_dli_workshops_worth_it/,TheNASAguy,1510994952,[removed],0,1
939,2017-11-18,2017,11,18,17,7drsmf,I was in a discussion yesterday about the use of MSE in binary classification and I'd like to post it here,https://www.reddit.com/r/MachineLearning/comments/7drsmf/i_was_in_a_discussion_yesterday_about_the_use_of/,falmasri,1510995407,[removed],0,1
940,2017-11-18,2017,11,18,19,7ds5ec,Speeding up Apache MXNet: lets smash it with AWS C5 and Intel MKL,https://www.reddit.com/r/MachineLearning/comments/7ds5ec/speeding_up_apache_mxnet_lets_smash_it_with_aws/,Barbas,1511000893,,0,1
941,2017-11-18,2017,11,18,20,7dsa71,Machine Learning Training in Jaipur,https://www.reddit.com/r/MachineLearning/comments/7dsa71/machine_learning_training_in_jaipur/,adhocnw,1511003057,[removed],0,1
942,2017-11-18,2017,11,18,20,7dsci0,Key Skills to Become a Data Scientist - Part 1,https://www.reddit.com/r/MachineLearning/comments/7dsci0/key_skills_to_become_a_data_scientist_part_1/,bhavikbochar,1511004015,,0,1
943,2017-11-18,2017,11,18,20,7dsg4s,[D] What are you currently 'stuck' on right now / these days?,https://www.reddit.com/r/MachineLearning/comments/7dsg4s/d_what_are_you_currently_stuck_on_right_now_these/,throwAwayObama,1511005598,,19,2
944,2017-11-18,2017,11,18,21,7dsj9l,[D] When to build multiple submodels vs just one?,https://www.reddit.com/r/MachineLearning/comments/7dsj9l/d_when_to_build_multiple_submodels_vs_just_one/,Ggfubfdrgjyf,1511006842,"Are there any good heuristics for when one should think about partitioning your data based on some feature and then building models on each partition rather than training a single model on the full data set? Particularly for something like xgboost or tree based models. 

The way I sort of think about it is that if a particular partition of the data has different behaviour to another then the trees will just split on that characteristic and then build their own sub models from there. If I partition the sample then train models on the partitions then I can think of it as a larger tree where I've forced the first split on the model. 

One hypotheses I have is that if there's one feature where I expect the generating process to be wholly different dependent on the feature then maybe it's worth building different models. For instance if I have the same types of customer demographic info for an electronics store and a real estate company and want to predict likelihood to buy electronics or real estate I should probably build a separate model for the real estate company and the electronics store. 
",3,5
945,2017-11-18,2017,11,18,21,7dskzj,Apache MXNet: flexible and efficient library for deep learning,https://www.reddit.com/r/MachineLearning/comments/7dskzj/apache_mxnet_flexible_and_efficient_library_for/,based2,1511007524,,1,1
946,2017-11-18,2017,11,18,22,7dsxpm,Reinforcement Learning for autonomous driving,https://www.reddit.com/r/MachineLearning/comments/7dsxpm/reinforcement_learning_for_autonomous_driving/,[deleted],1511012078,,0,1
947,2017-11-18,2017,11,18,22,7dszq0,Reinforcement Learning toolkit for autonomous driving,https://www.reddit.com/r/MachineLearning/comments/7dszq0/reinforcement_learning_toolkit_for_autonomous/,[deleted],1511012759,,0,1
948,2017-11-18,2017,11,18,22,7dt0sq,machine learning ideas for education platform,https://www.reddit.com/r/MachineLearning/comments/7dt0sq/machine_learning_ideas_for_education_platform/,[deleted],1511013118,,0,1
949,2017-11-18,2017,11,18,22,7dt259,[D] Reinforcement Learning toolkit for autonomous driving,https://www.reddit.com/r/MachineLearning/comments/7dt259/d_reinforcement_learning_toolkit_for_autonomous/,nonsingularmatrix,1511013575,"Currently I'm searching for a Reinforcement Learning toolkit for autonomous driving to test the influence of several safety aspects during learning as a reward function. For that reason the environment should provide information like: 
  
* distance to other cars 
* velocity of the car 
* distance to street boundaries 
* (distance to some specific destination)

So far I have tested OpenAI Gym with the ""Neon racer"" environment, which does not provide those information. At the moment I'm testing ""Gym Torcs"" (https://github.com/ugo-nama-kun/gym_torcs), which seems to be promising (regarding the provided information during learning).

Are there any other toolkits you would suggest me for this purpose?",3,15
950,2017-11-19,2017,11,19,0,7dtgjy,[P] Implementing MaLSTM on Kaggles Quora Question Pairs competition,https://www.reddit.com/r/MachineLearning/comments/7dtgjy/p_implementing_malstm_on_kaggles_quora_question/,fooboss,1511017940,,0,18
951,2017-11-19,2017,11,19,0,7dtks2,Unawareness of Deep Learning Mistakes,https://www.reddit.com/r/MachineLearning/comments/7dtks2/unawareness_of_deep_learning_mistakes/,ppwwyyxx,1511019162,,0,1
952,2017-11-19,2017,11,19,1,7dtrfl,[D] How do you get high performance with ResNet?,https://www.reddit.com/r/MachineLearning/comments/7dtrfl/d_how_do_you_get_high_performance_with_resnet/,netheril96,1511020994,"I have been trying different variations of ResNet for a month, and never get accuracy on CIFAR-10 above 92%. I could achieve that (92%) with my own plain CNN just as well (with data augmentations).

At first, I wrote my own model in TensorFlow, tried pre-activation, tried deeper and wider, tried SGD, Momentum and Adam optimizers, and never got past 92%.

 I also tried running scripts [tensorflow models](https://github.com/tensorflow/models/tree/master/official/resnet) and did not obtain anything higher than 92% either.

I am completely stumped. What are the tricks behind it? Or does anyone just add residual connections to their network and find instantly a huge boost to accuracy?",24,11
953,2017-11-19,2017,11,19,1,7dtvp8,Cryptocurrency Historical Data (top 50 cryptos),https://www.reddit.com/r/MachineLearning/comments/7dtvp8/cryptocurrency_historical_data_top_50_cryptos/,[deleted],1511022115,[deleted],0,1
954,2017-11-19,2017,11,19,2,7du7lb,Question: Extracting possible lables from multiple texts,https://www.reddit.com/r/MachineLearning/comments/7du7lb/question_extracting_possible_lables_from_multiple/,rolilink,1511025154,[removed],0,1
955,2017-11-19,2017,11,19,3,7dul8n,[P]Gradient Trader Part 4: Build Training Set with Rust for Python,https://www.reddit.com/r/MachineLearning/comments/7dul8n/pgradient_trader_part_4_build_training_set_with/,0b01,1511028603,,0,0
956,2017-11-19,2017,11,19,3,7duraj,Anyone pull news related tweets from the twitter streaming api?? What kind of volume can I expect?,https://www.reddit.com/r/MachineLearning/comments/7duraj/anyone_pull_news_related_tweets_from_the_twitter/,ebolanurse,1511030091,,0,1
957,2017-11-19,2017,11,19,4,7dv0v0,Entry into machine learning,https://www.reddit.com/r/MachineLearning/comments/7dv0v0/entry_into_machine_learning/,ITManagerNewbie1,1511032497,[removed],0,1
958,2017-11-19,2017,11,19,4,7dv0vr,"[R] Simple Nearest Neighbor Policy &lt;- no learning, outperforms Deep RL on MuJoCo tasks",https://www.reddit.com/r/MachineLearning/comments/7dv0vr/r_simple_nearest_neighbor_policy_no_learning/,downtownslim,1511032503,,19,62
959,2017-11-19,2017,11,19,4,7dv1d0,[D] Pro bono ML work?,https://www.reddit.com/r/MachineLearning/comments/7dv1d0/d_pro_bono_ml_work/,nharada,1511032617,"I live with lawyers, and I really admire that their field encourages donating their skills to people in need. In fact, the American Bar Association recommends 50 hours of pro bono work per year.

Is anyone aware of ways to similarly give back as an ML professional or researcher? Our skill sets are incredibly in demand so it seems like there should be opportunities. ",46,30
960,2017-11-19,2017,11,19,4,7dv9bd,"Project Idea: A machine learning application that lets non programmers create, test, and save models.",https://www.reddit.com/r/MachineLearning/comments/7dv9bd/project_idea_a_machine_learning_application_that/,LearningEngineer777,1511034594,[removed],0,1
961,2017-11-19,2017,11,19,4,7dv9o6,Are Machines Better than Humans?  Dr. Hermann Hauser,https://www.reddit.com/r/MachineLearning/comments/7dv9o6/are_machines_better_than_humans_dr_hermann_hauser/,yildiz17,1511034690,[removed],0,1
962,2017-11-19,2017,11,19,4,7dvaqr,Question on Image classifiers.,https://www.reddit.com/r/MachineLearning/comments/7dvaqr/question_on_image_classifiers/,chubbyostrich,1511034962,[removed],0,1
963,2017-11-19,2017,11,19,5,7dvcdm,Installing TensorFlow 1.4.0 on macOS with CUDA support,https://www.reddit.com/r/MachineLearning/comments/7dvcdm/installing_tensorflow_140_on_macos_with_cuda/,crmne,1511035373,,0,1
964,2017-11-19,2017,11,19,5,7dvmc0,[D] Current AI student: should I drop out?,https://www.reddit.com/r/MachineLearning/comments/7dvmc0/d_current_ai_student_should_i_drop_out/,randomsongname,1511037954,"Hey. Not sure if it's the correct subreddit to post to, was referred by someone from AI one. Sorry for possible inconvenience.
I am currently enrolled in a Master level AI program, and as classes go by, I am starting to have increasingly more serious doubts about whether I should go through with it, so I'd love some feedback from the people that are already in the industry. The current situation is:

1. I have a previous degree in electrical engineering, but I have graduated about 5 years, ago, and I was not the top student. Since then, I have worked in testing

2. My math skills are pretty limited. Somehow the math in the program is not that complex, but I really worry I will need to greatly improve to actually be meaningful irl.

3. The program is _hard_ for me, even studying almost full time I struggle. Which is not necessarily a huge problem, but combined with the next point feels to me like it is

4. My programming skills are very very meh. I know some Python and have a good foundation in algorithms, but I have never coded in a professional setting or written anything longer than 500 lines of code for that matter.

So all in all, looks to me like my chances of finding a job in the industry upon graduation are pretty slim. I wouldn't mind doing the program as a thing in itself and then learning to code, but I'd like to adjust my expectations in that case. As I've said, any thoughts/input are really appreciated.",27,6
965,2017-11-19,2017,11,19,7,7dwg61,"Is there an app I can purchase that lets me train a model to automate left/right swipes on tinder for me, or do I have to build one myself?",https://www.reddit.com/r/MachineLearning/comments/7dwg61/is_there_an_app_i_can_purchase_that_lets_me_train/,cowboykiller42,1511045829,[removed],0,1
966,2017-11-19,2017,11,19,8,7dwj1q,[P] Fun Project: MSpaint to Terrain Map with GAN,https://www.reddit.com/r/MachineLearning/comments/7dwj1q/p_fun_project_mspaint_to_terrain_map_with_gan/,tpapp157,1511046550,"I tried a fun little project to explore some of the possibilities of GANs and the results came out pretty good so I figured I'd share. The goal was to create a network which can take extremely simple images composed of various color regions (where each color corresponds to a particular type of terrain) and generate a realistic looking terrain map. The inputs being the sort of image an average human with no artistic ability could reasonably sketch out in MSpaint.

The GAN is based on AffineLayer's ""pix2pix"" code with a variety of changes. Primarily I increased the image size to 512x512 pixels and wrote completely new network structures. The generator is composed of an encoder/decoder pair which are mirrored 25 layer ResNets with skip connections between them. The generator loss was skewed strongly toward fooling the discrimintor to emphasize creating completely new terrain features rather than recreating the original image.

I used a terrain map of the entire Earth and randomly sampled 512x512 crops to generate my ground truth set. To create the seed images, these crops were quantized to a color palette of 5 colors and successive mode filters were applied to simplify the features. Each of the five colors corresponded with a different terrain type (blue - water, grey - mountains, green - forest/jungle, yellow - grassland/desert, brown - hills/badlands). In total, about 1300 image pairs were created that spanned the entire globe. The network was trained on these pairs for about 450 epochs (more or less a full day on a gtx1070) before it reached a point that I was happy with the results.

Now for the fun part: pictures. I've posted several image sets below. Each set is based on a single seed image which I drew in MSpaint with the various color regions recolored in different ways to show how the generator adapts the same image structure with different colorings. Notice how the network is able to invent features like lakes and rivers and islands. It also learned to handle the features of color regions and their transitions differently based on overall context.

https://imgur.com/a/mCJrA

https://imgur.com/a/OgY7k

https://imgur.com/a/hROZJ

https://imgur.com/a/nIYkp

Let me know if you have any questions.


EDIT: By request, I've uploaded my dataset to Kaggle:

https://www.kaggle.com/tpapp157/terrainimagepairs

It includes 1360 image pairs and is about 140MB in total. Have fun.",30,148
967,2017-11-19,2017,11,19,8,7dwncu,Open source alternatives to Watson ?,https://www.reddit.com/r/MachineLearning/comments/7dwncu/open_source_alternatives_to_watson/,ForSprint09,1511047679,[removed],0,1
968,2017-11-19,2017,11,19,11,7dxpdy,A New Algorithm Can Spot Pneumonia Better Than a Radiologist,https://www.reddit.com/r/MachineLearning/comments/7dxpdy/a_new_algorithm_can_spot_pneumonia_better_than_a/,AmbrosioBembo,1511058653,,0,1
969,2017-11-19,2017,11,19,12,7dxvpr,The MVC for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7dxvpr/the_mvc_for_machine_learning/,fj33xx,1511060517,,0,1
970,2017-11-19,2017,11,19,12,7dy39v,What is Ensemble Learning,https://www.reddit.com/r/MachineLearning/comments/7dy39v/what_is_ensemble_learning/,munishmaxtech,1511062789,,0,1
971,2017-11-19,2017,11,19,13,7dyand,Intro to Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/7dyand/intro_to_reinforcement_learning/,prakhar2121,1511065195,[removed],0,1
972,2017-11-19,2017,11,19,17,7dzh87,[D] How to build a Portfolio as a Machine Learning/Data Science Engineer in industry ?,https://www.reddit.com/r/MachineLearning/comments/7dzh87/d_how_to_build_a_portfolio_as_a_machine/,__Julia,1511081542,"Hi! I asked this question in different venues, but I still couldn't get an answer. I am a data science engineer and I'd like to focus on building a career in this field. I have some *humbled* open source projects analyzing some datasets, along with some published papers. 

While I am interested in building up a career in Machine Learning/Data Science space. My question is about blogging, research papers, and open source projects, and how to build up a career in Data Science/ML, in INDUSTRY.

- I am intending to start blogging as well. While I use FB/Twitter to express my interest and opinion, I am willing to keep my blog as a space to showcase open source experiments. In this case, do you see it as a duplication (Open Source on Github with Readme file + blogpost on how to re-build things and lessons learnt ). The idea behind the blog and the website is to find a new a job, so it would be a place to show what I can do. My interest and work is around data science and data engineering.

- I interned at research Centers (R&amp;D), so I was involved in writing and publishing some papers. As an engineer, do you find (Applied data science ) papers helpful in my career (papers that doesn't come with novel ML ideas, but novel ways to apply ML).

- If you are manager, recruiter or an interviewer, what do you want to see in the resume of a data science engineer ?. I have mixed signals, some people want to see more in-depth knowledge of data science, and others skills on how to process, query and analyze datasets. 

- Do you have examples of good data science portfolios. Feel free to share links. 

Thanks for your time in advance, and I am looking forward to your valuable insights. ",69,172
973,2017-11-19,2017,11,19,17,7dzhhj,"Keras - text classification, overfitting, and how to improve my model?",https://www.reddit.com/r/MachineLearning/comments/7dzhhj/keras_text_classification_overfitting_and_how_to/,glorsh66,1511081670,[removed],0,1
974,2017-11-19,2017,11,19,18,7dzo8c,Reimagining Acute Care - What if AI could watch patients in the ICU!,https://www.reddit.com/r/MachineLearning/comments/7dzo8c/reimagining_acute_care_what_if_ai_could_watch/,praveenbm5,1511084726,,0,1
975,2017-11-19,2017,11,19,20,7e00ou,[P] Document term weighing visualization - Using NIPS 2017 poster titles,https://www.reddit.com/r/MachineLearning/comments/7e00ou/p_document_term_weighing_visualization_using_nips/,napsternxg,1511090246,,3,1
976,2017-11-19,2017,11,19,20,7e0182,Good resources for ML algorithms (actual formulae),https://www.reddit.com/r/MachineLearning/comments/7e0182/good_resources_for_ml_algorithms_actual_formulae/,W4T3RBO7,1511090471,[removed],0,1
977,2017-11-19,2017,11,19,20,7e033j,"Create a REST API for any ML model, in seconds - galiboo/olympus",https://www.reddit.com/r/MachineLearning/comments/7e033j/create_a_rest_api_for_any_ml_model_in_seconds/,subbytech,1511091307,,1,1
978,2017-11-19,2017,11,19,20,7e062g,Reinforcement Learning - Explore Vs Exploit,https://www.reddit.com/r/MachineLearning/comments/7e062g/reinforcement_learning_explore_vs_exploit/,prakhar2121,1511092633,,0,1
979,2017-11-19,2017,11,19,21,7e0fnk,"Manifold hypothesis, neural nets &amp; optimal packing: look into the hidden layers",https://www.reddit.com/r/MachineLearning/comments/7e0fnk/manifold_hypothesis_neural_nets_optimal_packing/,Ranlot,1511096379,,0,1
980,2017-11-19,2017,11,19,22,7e0fwq,This is well fitted to this subreddit,https://www.reddit.com/r/MachineLearning/comments/7e0fwq/this_is_well_fitted_to_this_subreddit/,ChernobogDan,1511096457,,0,1
981,2017-11-19,2017,11,19,22,7e0leb,I want to apply Machine Learning to Computer Vision.What are Some good Resources to learn Computer Vision for Machine Learning using Python?,https://www.reddit.com/r/MachineLearning/comments/7e0leb/i_want_to_apply_machine_learning_to_computer/,thepixelatedguy,1511098333,[removed],0,1
982,2017-11-19,2017,11,19,23,7e0zh8,[D] Cryptocurrency Historical Data (Top 50),https://www.reddit.com/r/MachineLearning/comments/7e0zh8/d_cryptocurrency_historical_data_top_50/,jackraddit,1511102814,,8,0
983,2017-11-20,2017,11,20,0,7e17k0,[D] Towards interpretable reliable models - Keynote Katharine Jarmul,https://www.reddit.com/r/MachineLearning/comments/7e17k0/d_towards_interpretable_reliable_models_keynote/,durand101,1511105332,,1,18
984,2017-11-20,2017,11,20,0,7e1bru,Learning AI: how to evaluate oneself?,https://www.reddit.com/r/MachineLearning/comments/7e1bru/learning_ai_how_to_evaluate_oneself/,eshansingh,1511106537,[removed],1,1
985,2017-11-20,2017,11,20,1,7e1fdv,AANN: Absolute Artificial Neural Network,https://www.reddit.com/r/MachineLearning/comments/7e1fdv/aann_absolute_artificial_neural_network/,akanimax,1511107508,,0,1
986,2017-11-20,2017,11,20,2,7e1swy,Resources for spiking network simulations,https://www.reddit.com/r/MachineLearning/comments/7e1swy/resources_for_spiking_network_simulations/,Ihaa123,1511111026,[removed],0,1
987,2017-11-20,2017,11,20,3,7e2axs,[D] Does anyone know a working implementation of the matrix capsules with EM routing?,https://www.reddit.com/r/MachineLearning/comments/7e2axs/d_does_anyone_know_a_working_implementation_of/,dpseeker1,1511115362,[removed],5,8
988,2017-11-20,2017,11,20,3,7e2k9c,"""NameError"" in Linear Regression Code",https://www.reddit.com/r/MachineLearning/comments/7e2k9c/nameerror_in_linear_regression_code/,cosmicbeing49z,1511117657,[removed],0,1
989,2017-11-20,2017,11,20,4,7e2zis,[D] Fantastic GANs and where to find them II,https://www.reddit.com/r/MachineLearning/comments/7e2zis/d_fantastic_gans_and_where_to_find_them_ii/,Guim30,1511121265,,21,141
990,2017-11-20,2017,11,20,5,7e38g3,Open-Source Linear Genetic Programming System,https://www.reddit.com/r/MachineLearning/comments/7e38g3/opensource_linear_genetic_programming_system/,oracular_demon,1511123372,,0,1
991,2017-11-20,2017,11,20,5,7e3bg1,[D] What is the state of Go for enterprise Data Science? (inspired by dated linked blog post),https://www.reddit.com/r/MachineLearning/comments/7e3bg1/d_what_is_the_state_of_go_for_enterprise_data/,[deleted],1511124112,[deleted],0,1
992,2017-11-20,2017,11,20,6,7e3fx6,[D] Machine Learning - WAYR (What Are You Reading) - Week 36,https://www.reddit.com/r/MachineLearning/comments/7e3fx6/d_machine_learning_wayr_what_are_you_reading_week/,ML_WAYR_bot,1511125204,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

Previous weeks :

|1-10|11-20|21-30|31-40|
|----|-----|-----|-----|
|[Week 1](https://www.reddit.com/r/MachineLearning/comments/4qyjiq/machine_learning_wayr_what_are_you_reading_week_1/)|[Week 11](https://www.reddit.com/r/MachineLearning/comments/57xw56/discussion_machine_learning_wayr_what_are_you/)|[Week 21](https://www.reddit.com/r/MachineLearning/comments/60ildf/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 31](https://www.reddit.com/r/MachineLearning/comments/6s0k1u/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 2](https://www.reddit.com/r/MachineLearning/comments/4s2xqm/machine_learning_wayr_what_are_you_reading_week_2/)|[Week 12](https://www.reddit.com/r/MachineLearning/comments/5acb1t/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 22](https://www.reddit.com/r/MachineLearning/comments/64jwde/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 32](https://www.reddit.com/r/MachineLearning/comments/72ab5y/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 3](https://www.reddit.com/r/MachineLearning/comments/4t7mqm/machine_learning_wayr_what_are_you_reading_week_3/)|[Week 13](https://www.reddit.com/r/MachineLearning/comments/5cwfb6/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 23](https://www.reddit.com/r/MachineLearning/comments/674331/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 33](https://www.reddit.com/r/MachineLearning/comments/75405d/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 4](https://www.reddit.com/r/MachineLearning/comments/4ub2kw/machine_learning_wayr_what_are_you_reading_week_4/)|[Week 14](https://www.reddit.com/r/MachineLearning/comments/5fc5mh/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 24](https://www.reddit.com/r/MachineLearning/comments/68hhhb/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 34](https://www.reddit.com/r/MachineLearning/comments/782js9/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 5](https://www.reddit.com/r/MachineLearning/comments/4xomf7/machine_learning_wayr_what_are_you_reading_week_5/)|[Week 15](https://www.reddit.com/r/MachineLearning/comments/5hy4ur/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 25](https://www.reddit.com/r/MachineLearning/comments/69teiz/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 35](https://www.reddit.com/r/MachineLearning/comments/7b0av0/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 6](https://www.reddit.com/r/MachineLearning/comments/4zcyvk/machine_learning_wayr_what_are_you_reading_week_6/)|[Week 16](https://www.reddit.com/r/MachineLearning/comments/5kd6vd/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 26](https://www.reddit.com/r/MachineLearning/comments/6d7nb1/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 7](https://www.reddit.com/r/MachineLearning/comments/52t6mo/machine_learning_wayr_what_are_you_reading_week_7/)|[Week 17](https://www.reddit.com/r/MachineLearning/comments/5ob7dx/discussion_machine_learning_wayr_what_are_you/)|[Week 27](https://www.reddit.com/r/MachineLearning/comments/6gngwc/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 8](https://www.reddit.com/r/MachineLearning/comments/53heol/machine_learning_wayr_what_are_you_reading_week_8/)|[Week 18](https://www.reddit.com/r/MachineLearning/comments/5r14yd/discussion_machine_learning_wayr_what_are_you/)|[Week 28](https://www.reddit.com/r/MachineLearning/comments/6jgdva/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 9](https://www.reddit.com/r/MachineLearning/comments/54kvsu/machine_learning_wayr_what_are_you_reading_week_9/)|[Week 19](https://www.reddit.com/r/MachineLearning/comments/5tt9cz/discussion_machine_learning_wayr_what_are_you/)|[Week 29](https://www.reddit.com/r/MachineLearning/comments/6m9l1v/d_machine_learning_wayr_what_are_you_reading_week/)||
|[Week 10](https://www.reddit.com/r/MachineLearning/comments/56s2oa/discussion_machine_learning_wayr_what_are_you/)|[Week 20](https://www.reddit.com/r/MachineLearning/comments/5wh2wb/d_machine_learning_wayr_what_are_you_reading_week/)|[Week 30](https://www.reddit.com/r/MachineLearning/comments/6p3ha7/d_machine_learning_wayr_what_are_you_reading_week/)||

Most upvoted papers two weeks ago:

/u/Schmogel: http://hi.cs.waseda.ac.jp/~iizuka/projects/completion/en/

/u/hypertiger1: [Machine Learning for Trading](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3015609)

/u/OctThe16th: https://arxiv.org/abs/1710.02298

Besides that, there are no rules, have fun.",16,34
993,2017-11-20,2017,11,20,6,7e3izr,"GANs for Simulation, Representation and Inference",https://www.reddit.com/r/MachineLearning/comments/7e3izr/gans_for_simulation_representation_and_inference/,heljakka,1511125965,,0,1
994,2017-11-20,2017,11,20,7,7e3xey,Training Char-RNNs for Transferring Name Styles,https://www.reddit.com/r/MachineLearning/comments/7e3xey/training_charrnns_for_transferring_name_styles/,axm92,1511129369,,0,1
995,2017-11-20,2017,11,20,7,7e441w,[question] LSTM gates: scalar or vector ?,https://www.reddit.com/r/MachineLearning/comments/7e441w/question_lstm_gates_scalar_or_vector/,steuhh,1511130913,[removed],1,1
996,2017-11-20,2017,11,20,7,7e44ml,[D] Are there any *recent* benchmarks comparing training times of libraries?,https://www.reddit.com/r/MachineLearning/comments/7e44ml/d_are_there_any_recent_benchmarks_comparing/,bbsome,1511131057,"Have I not seen any recent benchmarks comparing the training times of different libraries? Here, I'm talking to things more than just convolutions, where it is pointless since all of them link to cuDNN - e.g. RNNs, Stacked RNNs (again not those linked to cuDNN, but ones implemented natively like RWA), memory networks like NTM and DM's DNC and so on. I do understand this is difficult to do by a single person, but if that exist won't the authors of the packages be interested in making their implementation there better? ",2,3
997,2017-11-20,2017,11,20,7,7e47bl,[P] Boltzmann Machines in TensorFlow with examples,https://www.reddit.com/r/MachineLearning/comments/7e47bl/p_boltzmann_machines_in_tensorflow_with_examples/,monsta-hd,1511131704,,0,35
998,2017-11-20,2017,11,20,8,7e4akb,Optimization Algorithms for Deep Learning: Math and Code,https://www.reddit.com/r/MachineLearning/comments/7e4akb/optimization_algorithms_for_deep_learning_math/,mgr2786,1511132521,[removed],0,1
999,2017-11-20,2017,11,20,8,7e4gaw,NO you dont need personal data for personalization,https://www.reddit.com/r/MachineLearning/comments/7e4gaw/no_you_dont_need_personal_data_for_personalization/,bistro17,1511133949,,0,1
1000,2017-11-20,2017,11,20,8,7e4gwe,Capsule Net : Understanding Dynamic Routing between Capsules,https://www.reddit.com/r/MachineLearning/comments/7e4gwe/capsule_net_understanding_dynamic_routing_between/,vksbhandary,1511134104,,1,1
1001,2017-11-20,2017,11,20,9,7e4qn7,K-mean just 10minutes,https://www.reddit.com/r/MachineLearning/comments/7e4qn7/kmean_just_10minutes/,minsukheo,1511136713,,0,1
1002,2017-11-20,2017,11,20,10,7e54xu,"Looking for API to extract ingredient information from text strings like: ""1 1/2 quarts (1.4 liters) oil for frying, such as canola, peanut, or vegetable""",https://www.reddit.com/r/MachineLearning/comments/7e54xu/looking_for_api_to_extract_ingredient_information/,CodingNewbie,1511140423,[removed],0,1
1003,2017-11-20,2017,11,20,14,7e6pav,[D] Assessing over-/underfitting in GANs,https://www.reddit.com/r/MachineLearning/comments/7e6pav/d_assessing_overunderfitting_in_gans/,anonDogeLover,1511156821,"I've been playing with several GAN implementations found on github, and the authors often claim the example is under- or overfitting. How is this assessed / how do they know since there is no ""validation"" set.",11,18
1004,2017-11-20,2017,11,20,15,7e6t90,Who has the most papers accepted at NIPS 2017?,https://www.reddit.com/r/MachineLearning/comments/7e6t90/who_has_the_most_papers_accepted_at_nips_2017/,netw0rkf10w,1511158070,[removed],0,1
1005,2017-11-20,2017,11,20,16,7e791w,[D] Which book do you think is better?,https://www.reddit.com/r/MachineLearning/comments/7e791w/d_which_book_do_you_think_is_better/,jackraddit,1511163498,"Hi everyone.
Given that I am not a complete beginner but would like to understand better some implementations of machine learning/deep learning, which book do you suggest? I can't decide between [Hands-On Machine Learning with Scikit-Learn and TensorFlow by Aurlien Gron](https://www.amazon.com/dp/1491962291/sr=8-1/qid=1511163140/ref=olp_product_details?_encoding=UTF8&amp;me=&amp;qid=1511163140&amp;sr=8-1) and [Python Machine Learning by Raschka and Mirjalili](https://www.amazon.com/Python-Machine-Learning-scikit-learn-TensorFlow/dp/1787125939/ref=sr_1_7?ie=UTF8&amp;qid=1511163140&amp;sr=8-7&amp;keywords=machine+learning). Has anyone read them before?",11,1
1006,2017-11-20,2017,11,20,17,7e7dq6,Almond Skin Peeling Machine Manufacturer In China,https://www.reddit.com/r/MachineLearning/comments/7e7dq6/almond_skin_peeling_machine_manufacturer_in_china/,gelgoogcara,1511165327,,1,1
1007,2017-11-20,2017,11,20,17,7e7edv,"[R] New GAN dataset? 11k Hands: 11,076 hand images (1600 x 1200 pixels) of 190 subjects",https://www.reddit.com/r/MachineLearning/comments/7e7edv/r_new_gan_dataset_11k_hands_11076_hand_images/,downtownslim,1511165586,,25,64
1008,2017-11-20,2017,11,20,17,7e7ix2,Organic fertilizer production equipment,https://www.reddit.com/r/MachineLearning/comments/7e7ix2/organic_fertilizer_production_equipment/,amylee516,1511167421,,0,1
1009,2017-11-20,2017,11,20,18,7e7u3u,[D] Is there any literature in Reinforcement Learning about problems where the Agent doesn't start the episode from the same state?,https://www.reddit.com/r/MachineLearning/comments/7e7u3u/d_is_there_any_literature_in_reinforcement/,xwrd,1511171822,"I've had this problem a while back in the form of a soccer robot that sat in an arena, had to pick up balls and throw them at the opponent's goal. I've used Deep Q learning and if, at the start of the episode, the balls were in the same position, it began to learn. If the balls were placed randomly, no learning progress would be made, even after 1m episodes.

Now I have the same problem again, with picking the right ad to show to a user. I've searched for this particular problem over the internet. It seems that all the RL problems that I've seen solved so far always start from the same position.

Are there any algorithms that work well in practice in this situation?",11,1
1010,2017-11-20,2017,11,20,19,7e7y91,optimizing k in k-fold cross validation,https://www.reddit.com/r/MachineLearning/comments/7e7y91/optimizing_k_in_kfold_cross_validation/,kakushka123,1511173380,[removed],0,1
1011,2017-11-20,2017,11,20,19,7e7zca,Sunflower Seeds|Melon Seeds Roasting Machine Manufacturer,https://www.reddit.com/r/MachineLearning/comments/7e7zca/sunflower_seedsmelon_seeds_roasting_machine/,gelgoogcara,1511173803,,1,1
1012,2017-11-20,2017,11,20,19,7e814t,Triangle Tea Bag Packaging Machine |Pyramid Tea Bag Packaging Machine,https://www.reddit.com/r/MachineLearning/comments/7e814t/triangle_tea_bag_packaging_machine_pyramid_tea/,liusherry,1511174443,,1,1
1013,2017-11-20,2017,11,20,19,7e83lk,"[N]Singapore CIOs believe machine learning can improve speed, security ops",https://www.reddit.com/r/MachineLearning/comments/7e83lk/nsingapore_cios_believe_machine_learning_can/,magneticono,1511175401,,0,1
1014,2017-11-20,2017,11,20,20,7e85h8,[R] Generalizing GANs: A Turing Perspective,https://www.reddit.com/r/MachineLearning/comments/7e85h8/r_generalizing_gans_a_turing_perspective/,EvgeniyZh,1511176104,,0,10
1015,2017-11-20,2017,11,20,20,7e86u0,[P] Looking for a co-author to write a GAN book,https://www.reddit.com/r/MachineLearning/comments/7e86u0/p_looking_for_a_coauthor_to_write_a_gan_book/,jguertl,1511176607,[removed],0,1
1016,2017-11-20,2017,11,20,20,7e88pv,Do you want a noodle making machine to make noodles by yourself?,https://www.reddit.com/r/MachineLearning/comments/7e88pv/do_you_want_a_noodle_making_machine_to_make/,liusherry,1511177318,[removed],1,1
1017,2017-11-20,2017,11,20,20,7e89gt,Chocolate Grinding Machine With Stainless Steel For Sale,https://www.reddit.com/r/MachineLearning/comments/7e89gt/chocolate_grinding_machine_with_stainless_steel/,gelgoogcara,1511177597,,1,1
1018,2017-11-20,2017,11,20,21,7e8i0z,[D] AI and Ethics: Overcoming the Risks,https://www.reddit.com/r/MachineLearning/comments/7e8i0z/d_ai_and_ethics_overcoming_the_risks/,[deleted],1511180546,[deleted],2,1
1019,2017-11-20,2017,11,20,21,7e8m0f,NIPS 2017: Learning to Run Case Study,https://www.reddit.com/r/MachineLearning/comments/7e8m0f/nips_2017_learning_to_run_case_study/,[deleted],1511181888,[deleted],1,1
1020,2017-11-20,2017,11,20,21,7e8n3y,[R]Machine learning delivers insight into drugs' effects on stroke patients,https://www.reddit.com/r/MachineLearning/comments/7e8n3y/rmachine_learning_delivers_insight_into_drugs/,janemoz,1511182252,,0,1
1021,2017-11-20,2017,11,20,21,7e8o92,Implement Machine Learning with Click of a button (Part 1),https://www.reddit.com/r/MachineLearning/comments/7e8o92/implement_machine_learning_with_click_of_a_button/,AtrophicNectar,1511182616,,0,1
1022,2017-11-20,2017,11,20,22,7e8sqj,NIPS 2017: Learning to Run Case Study,https://www.reddit.com/r/MachineLearning/comments/7e8sqj/nips_2017_learning_to_run_case_study/,[deleted],1511184007,[deleted],0,1
1023,2017-11-20,2017,11,20,22,7e8sui,[P] NIPS 2017: Learning to Run Case Study,https://www.reddit.com/r/MachineLearning/comments/7e8sui/p_nips_2017_learning_to_run_case_study/,[deleted],1511184034,[deleted],0,1
1024,2017-11-20,2017,11,20,22,7e8wko,MachineLabs announces GPU support with another style transfer demo,https://www.reddit.com/r/MachineLearning/comments/7e8wko/machinelabs_announces_gpu_support_with_another/,cburgdorf,1511185105,,0,1
1025,2017-11-20,2017,11,20,22,7e8yhd,[P] How To Predict Multiple Time Series With Scikit-Learn (With a Sales Forecasting Example),https://www.reddit.com/r/MachineLearning/comments/7e8yhd/p_how_to_predict_multiple_time_series_with/,ledmmaster,1511185662,,1,0
1026,2017-11-20,2017,11,20,22,7e8ymo,[P] Casy Study: Learning to Run [NIPS 2017 Competition],https://www.reddit.com/r/MachineLearning/comments/7e8ymo/p_casy_study_learning_to_run_nips_2017_competition/,-N3Ter-,1511185703,,23,41
1027,2017-11-20,2017,11,20,23,7e954l,TensorFlow estimator input_fn with very huge dataset?,https://www.reddit.com/r/MachineLearning/comments/7e954l/tensorflow_estimator_input_fn_with_very_huge/,rodrigo-silveira,1511187489,[removed],0,1
1028,2017-11-20,2017,11,20,23,7e981c,"[D] Comparative Audio Analysis Using Wavenet With UMAP, t-SNE and PCA",https://www.reddit.com/r/MachineLearning/comments/7e981c/d_comparative_audio_analysis_using_wavenet_with/,audio-nerd,1511188257,,9,55
1029,2017-11-20,2017,11,20,23,7e98ep,Best embedding technique for paraphrases detection?,https://www.reddit.com/r/MachineLearning/comments/7e98ep/best_embedding_technique_for_paraphrases_detection/,cece95x,1511188352,,0,1
1030,2017-11-20,2017,11,20,23,7e99r0,[D] Laptop for DL,https://www.reddit.com/r/MachineLearning/comments/7e99r0/d_laptop_for_dl/,PigsDogsAndSheep,1511188713,[removed],5,2
1031,2017-11-20,2017,11,20,23,7e9bi0,Question about Genetic algorithm optimization,https://www.reddit.com/r/MachineLearning/comments/7e9bi0/question_about_genetic_algorithm_optimization/,cece95x,1511189176,[removed],0,1
1032,2017-11-21,2017,11,21,0,7e9erv,"[P] Comparative Audio Analysis With Wavenet, MFCCs, UMAP, t-SNE and PCA",https://www.reddit.com/r/MachineLearning/comments/7e9erv/p_comparative_audio_analysis_with_wavenet_mfccs/,lmcinnes,1511190019,,3,5
1033,2017-11-21,2017,11,21,1,7e9vus,"[P] [Misc] Hey! I made a T-shirt that's a play on the blackbox treatment of ANNs, check it out. I'll probably make more such in the winter. Thanks and sorry for the off topic post.",https://www.reddit.com/r/MachineLearning/comments/7e9vus/p_misc_hey_i_made_a_tshirt_thats_a_play_on_the/,[deleted],1511194120,[deleted],0,1
1034,2017-11-21,2017,11,21,1,7e9xbz,Quick and Dirty Visualization of Keras Activation Functions,https://www.reddit.com/r/MachineLearning/comments/7e9xbz/quick_and_dirty_visualization_of_keras_activation/,dkafinated,1511194458,,1,1
1035,2017-11-21,2017,11,21,1,7e9yuv,"[P] [Misc] Hey! I made a T-shirt that's a play on the blackbox treatment of ANNs, check it out. I'll probably make more such in the winter. Thanks and sorry for the off topic post.",https://www.reddit.com/r/MachineLearning/comments/7e9yuv/p_misc_hey_i_made_a_tshirt_thats_a_play_on_the/,[deleted],1511194805,[deleted],0,0
1036,2017-11-21,2017,11,21,1,7e9yyo,Transfer Learning using differential learning rates,https://www.reddit.com/r/MachineLearning/comments/7e9yyo/transfer_learning_using_differential_learning/,manikantasangu,1511194827,,0,1
1037,2017-11-21,2017,11,21,1,7ea33x,Looking for the correct name of my problem,https://www.reddit.com/r/MachineLearning/comments/7ea33x/looking_for_the_correct_name_of_my_problem/,sabertoothedhedgehog,1511195769,[removed],0,1
1038,2017-11-21,2017,11,21,2,7eadj4,[D] Best applications of Machine Learning in Enterprise Software?,https://www.reddit.com/r/MachineLearning/comments/7eadj4/d_best_applications_of_machine_learning_in/,radead,1511198063,"I am doing research on Machine Learning as applied against Enterprise (B2B) use cases.  I am curious to hear from the community on where you may have seen the most innovative implementations of ML models against real-life challenges in the Enterprise software space, and particularly which industries may benefit the most from this technology.

Secondly, are there software companies that may stand out as particularly effective at applying ML against business challenges in the wild?  Some software companies I've come across in my research include Skytree (www.skytree.net),  DataRobot (www.datarobot.com) and some may consider IBM's Watson product to be ML powered to some degree.  I am interested in hearing from the Reddit ML community on how this technology can be applied to solve Enterprise business challenges and where the 'low hanging fruit' so to speak may reside for disruption in the near future",4,2
1039,2017-11-21,2017,11,21,2,7eahmt,Continuous Integration for Jupyter Notebook Slides.,https://www.reddit.com/r/MachineLearning/comments/7eahmt/continuous_integration_for_jupyter_notebook_slides/,jellis11,1511198951,,0,1
1040,2017-11-21,2017,11,21,2,7ealss,Will StackGANs threaten stock photo companies in the near future?,https://www.reddit.com/r/MachineLearning/comments/7ealss/will_stackgans_threaten_stock_photo_companies_in/,alxth,1511199890,[removed],0,1
1041,2017-11-21,2017,11,21,2,7eapht,[R] L2 Regularization versus Batch and Weight Normalization,https://www.reddit.com/r/MachineLearning/comments/7eapht/r_l2_regularization_versus_batch_and_weight/,average_pooler,1511200678,,2,21
1042,2017-11-21,2017,11,21,3,7eaxt6,Transitioning from Software Engineering to machine learning engineer,https://www.reddit.com/r/MachineLearning/comments/7eaxt6/transitioning_from_software_engineering_to/,wisely38,1511202440,[removed],0,1
1043,2017-11-21,2017,11,21,3,7eay88,Using Machine Learning to Predict the Weather: Part 2,https://www.reddit.com/r/MachineLearning/comments/7eay88/using_machine_learning_to_predict_the_weather/,ScottWRobinson,1511202524,,0,1
1044,2017-11-21,2017,11,21,4,7ebbfo,Making Real Medical Imaging Data Synthetic?,https://www.reddit.com/r/MachineLearning/comments/7ebbfo/making_real_medical_imaging_data_synthetic/,bluemldl,1511205352,[removed],0,1
1045,2017-11-21,2017,11,21,5,7ebuut,[D] Latent sex change,https://www.reddit.com/r/MachineLearning/comments/7ebuut/d_latent_sex_change/,haffi112,1511209526,"I was wondering, there are many papers currently doing interpolations in latent space of faces. Many, such as VAE models, allow you to reconstruct data by encoding and decoding. Given that context, my question is, if I encode the image of a bald woman into latent space and decode then does she turn into a man?",10,2
1046,2017-11-21,2017,11,21,5,7ec4f1,Transitioning from Software Engineering to machine learning engineer,https://www.reddit.com/r/MachineLearning/comments/7ec4f1/transitioning_from_software_engineering_to/,wisely38,1511211581,,0,1
1047,2017-11-21,2017,11,21,6,7ec98a,[D] Do you believe Machine Learning is overhyped?,https://www.reddit.com/r/MachineLearning/comments/7ec98a/d_do_you_believe_machine_learning_is_overhyped/,[deleted],1511212602,[deleted],2,0
1048,2017-11-21,2017,11,21,6,7ece5z,[D] Reinforcement Learning: The quirks,https://www.reddit.com/r/MachineLearning/comments/7ece5z/d_reinforcement_learning_the_quirks/,Sig_Luna,1511213692,,0,0
1049,2017-11-21,2017,11,21,6,7ecfqf,[P] Looking for advice for my honours year project. Using machine learning algorithms to play pokemon red.,https://www.reddit.com/r/MachineLearning/comments/7ecfqf/p_looking_for_advice_for_my_honours_year_project/,ceio,1511214033,"Hi,

First time poster in this subreddit.

I am in my final year of university and have decided that for my honours year project I'd like to look into the machine learning methods which could be utilised to play the game pokemon red. I'm going to assume that if you reply to this then you know roughly how the game works. The goal of the project would be to see if it can learn to progress through the game quicker than I can.

I am in the process of reviewing as many pieces of literature about machine learning in general and previous projects and I'm at the stage where I am not sure if the project will be too difficult to implement. I have looked into various machine learning techniques such as genetic algorithms, reinforcement learning, neural networks and NEAT and I am unsure which approach/combination of approaches would be best to attempt to implement for this project.

I can use an emulator called Bizhawk to find the memory address locations which store game variables and write Lua code to access these variables, these variables would be used as input for whichever implementation I choose to go for.

I feel like there are many issues which I will have to overcome such as:

 * There are two distinct different parts of the game, battling and moving through the game, the moving through the game feels like it could potentially be addressed using NEAT in which I reward the algorithm if it transitions from to a game map which moves it in the correct direction, wins a battle etc, heals a pokemon etc. Although I am not sure if I should implement a separate learning algorithm such as reinforcement learning which handles the battling.

 * How does the system learn the reason for its failure, did it execute the battle poorly or was it under levelled, did it choose not to heal all pokemon to full health when it should have?

* Even with the emulator playing the game at 8x the normal speed will the learning process take too long?

* How will the agent even learn to do things like heal injured pokemon, buy items, learn which moves to replace and decide whether or not it catches a pokemon and train it as a part of the team. 

* Should I just pre-code in methods such as train, heal, progress through the game etc. and let it decide which methods to do and in which order?


I guess my question to all who read this is am I on the right track for this project or is this project going to be far too difficult to implement in the space of the next 4 months? Even if the project doesn't work I can still detail what went wrong in my thesis although I'd like to give it as good a shot as I can.

Any advice you guys can give would be appreciated!
",14,0
1050,2017-11-21,2017,11,21,6,7ecksi,"[D] Expressivity, Trainability, and Generalization in Machine Learning",https://www.reddit.com/r/MachineLearning/comments/7ecksi/d_expressivity_trainability_and_generalization_in/,wei_jok,1511215164,,0,9
1051,2017-11-21,2017,11,21,6,7eckwf,[N] GCP lowers GPU pricing by up to 36%: K80 at 40c/hr and P100 at $1.46/hr,https://www.reddit.com/r/MachineLearning/comments/7eckwf/n_gcp_lowers_gpu_pricing_by_up_to_36_k80_at_40chr/,gin_and_toxic,1511215189,,34,174
1052,2017-11-21,2017,11,21,8,7edaem,[P] Predicting Cryptocurrency Prices With Deep Learning,https://www.reddit.com/r/MachineLearning/comments/7edaem/p_predicting_cryptocurrency_prices_with_deep/,dashee87,1511221032,,15,15
1053,2017-11-21,2017,11,21,9,7edkc7,[N] Google Developers Blog: Introducing TensorFlow Feature Columns,https://www.reddit.com/r/MachineLearning/comments/7edkc7/n_google_developers_blog_introducing_tensorflow/,artmast,1511223440,,3,15
1054,2017-11-21,2017,11,21,9,7edofp,Does anyone know of any good examples or projects using OpenAI's baselines library?,https://www.reddit.com/r/MachineLearning/comments/7edofp/does_anyone_know_of_any_good_examples_or_projects/,tyrilu,1511224400,[removed],0,1
1055,2017-11-21,2017,11,21,9,7edouj,"Probabilistic Programming course @ Columbia, Fall 2017",https://www.reddit.com/r/MachineLearning/comments/7edouj/probabilistic_programming_course_columbia_fall/,markov01,1511224504,,1,1
1056,2017-11-21,2017,11,21,10,7edxeu,Are glassdoor salaries accurate for machine learning engineers/researchers?,https://www.reddit.com/r/MachineLearning/comments/7edxeu/are_glassdoor_salaries_accurate_for_machine/,eat_quantum_potatoes,1511226606,[removed],0,1
1057,2017-11-21,2017,11,21,10,7edxld,Making worker displacement work for everyone,https://www.reddit.com/r/MachineLearning/comments/7edxld/making_worker_displacement_work_for_everyone/,ADGEfficiency,1511226653,,0,1
1058,2017-11-21,2017,11,21,10,7ee558,"MENACE (No, not the Numberphile video)",https://www.reddit.com/r/MachineLearning/comments/7ee558/menace_no_not_the_numberphile_video/,gmsc,1511228572,,0,1
1059,2017-11-21,2017,11,21,11,7eefbw,"[R] Spectral Normalization for Generative Adversarial Networks, ""first GAN to ever fit all 1000 ImageNet classes in one GAN""",https://www.reddit.com/r/MachineLearning/comments/7eefbw/r_spectral_normalization_for_generative/,downtownslim,1511231220,,22,77
1060,2017-11-21,2017,11,21,12,7eeqvo,[R] A good simulator for self-driving car testing,https://www.reddit.com/r/MachineLearning/comments/7eeqvo/r_a_good_simulator_for_selfdriving_car_testing/,dekarosa,1511234272,"I've been using Udacity's simulator so far but it doesn't really provide useful ways to autonomously train like a way to reset the env.

I couldn't find another one. What are you guys using?",2,3
1061,2017-11-21,2017,11,21,12,7ees7l,"[D] If I'm interested in investing (financially) in deep learning, are there any companies/funds worth looking into?",https://www.reddit.com/r/MachineLearning/comments/7ees7l/d_if_im_interested_in_investing_financially_in/,pfthrowaway2903r2io2,1511234628,"I hope this is an OK question to ask here -- I know it's not really about the *practice* of machine learning, but I thought I might get more interesting/informative answers from people actively involved in the field. Anyway:

I've only recently started studying ML (&lt; 1 year, mostly Coursera), but I've found it really enjoyable and inspiring so far. Since I have a some money I've put aside for investments recently, I'd like to put a part of that toward companies or funds whose futures are tied to deep learning specifically*.

Nvidia and AMD seem like the obvious choices, and I've also looked into semiconductor manufacturers and some ETFs purportedly focused on deep learning. Facebook, Microsoft and Google also seem like good contenders. Any other ideas who I should investigate? Are there any companies doing really important interesting work in the field I might not have heard of as a newcomer?

*: The bigger part's in domestic/international index funds and bonds, I know betting on stocks is a risky game and only put a small portion aside to do it.",16,2
1062,2017-11-21,2017,11,21,13,7ef0tr,Time-Contrastive Networks: Self-Supervised Learning from Video,https://www.reddit.com/r/MachineLearning/comments/7ef0tr/timecontrastive_networks_selfsupervised_learning/,[deleted],1511237009,[deleted],0,1
1063,2017-11-21,2017,11,21,13,7ef7hq,Best OpenCL library for GEMM on embedded/mobile GPU's?,https://www.reddit.com/r/MachineLearning/comments/7ef7hq/best_opencl_library_for_gemm_on_embeddedmobile/,avis66,1511238879,[removed],0,1
1064,2017-11-21,2017,11,21,14,7eff19,[R] Time-Contrastive Networks: Self-Supervised Learning from Video,https://www.reddit.com/r/MachineLearning/comments/7eff19/r_timecontrastive_networks_selfsupervised/,BullockHouse,1511241117,,4,83
1065,2017-11-21,2017,11,21,14,7efkto,Need Alpha Testers: Enterprise grade visual data labeling tool,https://www.reddit.com/r/MachineLearning/comments/7efkto/need_alpha_testers_enterprise_grade_visual_data/,dwnldsound,1511242807,[removed],0,1
1066,2017-11-21,2017,11,21,15,7efwc9,Announcing Excel Add-in for ParallelDots AI APIs,https://www.reddit.com/r/MachineLearning/comments/7efwc9/announcing_excel_addin_for_paralleldots_ai_apis/,shashankg22,1511246481,,0,1
1067,2017-11-21,2017,11,21,15,7efxiu,Chili Paste Grinding Machine Manufacturer In China,https://www.reddit.com/r/MachineLearning/comments/7efxiu/chili_paste_grinding_machine_manufacturer_in_china/,gelgoogcara,1511246860,,1,1
1068,2017-11-21,2017,11,21,16,7eg4bk,"What's the""prediction service"" in Cloud Machine Learning?",https://www.reddit.com/r/MachineLearning/comments/7eg4bk/whats_theprediction_service_in_cloud_machine/,AlexMa1991,1511249243,[removed],0,1
1069,2017-11-21,2017,11,21,17,7egbfk,"Engati is a unique machine learning based bot platform that helps any business build a customized bot, in just 10 minutes.",https://www.reddit.com/r/MachineLearning/comments/7egbfk/engati_is_a_unique_machine_learning_based_bot/,getengati,1511251913,[removed],0,1
1070,2017-11-21,2017,11,21,17,7egefb,300 Ton CNC Press Brake Video,https://www.reddit.com/r/MachineLearning/comments/7egefb/300_ton_cnc_press_brake_video/,hinachin,1511253080,,0,1
1071,2017-11-21,2017,11,21,18,7egknx,Sesame Soy Grinding Machine|Sesame Butter Grinding Machine For Sale,https://www.reddit.com/r/MachineLearning/comments/7egknx/sesame_soy_grinding_machinesesame_butter_grinding/,gelgoogcara,1511255542,,1,1
1072,2017-11-21,2017,11,21,18,7egp24,[P] Deep Learning Toolkit for Medical Image Analysis,https://www.reddit.com/r/MachineLearning/comments/7egp24/p_deep_learning_toolkit_for_medical_image_analysis/,terrorlucid,1511257218,,7,65
1073,2017-11-21,2017,11,21,18,7egrsi,"[P] Chainer Implementation of ""Neural Programmer-Interpreters""",https://www.reddit.com/r/MachineLearning/comments/7egrsi/p_chainer_implementation_of_neural/,[deleted],1511258255,[deleted],1,11
1074,2017-11-21,2017,11,21,19,7egy6l,Semi Automatic Soap Overwrapping Machine in Hot Selling,https://www.reddit.com/r/MachineLearning/comments/7egy6l/semi_automatic_soap_overwrapping_machine_in_hot/,liusherry,1511260600,[removed],1,1
1075,2017-11-21,2017,11,21,19,7eh0cb,A ML project to detect the colors of object.Michael Tesa talks about the project in an interview.,https://www.reddit.com/r/MachineLearning/comments/7eh0cb/a_ml_project_to_detect_the_colors_of/,winner_godson,1511261409,,0,1
1076,2017-11-21,2017,11,21,19,7eh0oe,"[N]What the heck is machine learning, and why is it everywhere these days?",https://www.reddit.com/r/MachineLearning/comments/7eh0oe/nwhat_the_heck_is_machine_learning_and_why_is_it/,polllyyy,1511261549,,0,1
1077,2017-11-21,2017,11,21,20,7eh2n4,Dried Noodle Production Line,https://www.reddit.com/r/MachineLearning/comments/7eh2n4/dried_noodle_production_line/,liusherry,1511262258,[removed],1,1
1078,2017-11-21,2017,11,21,20,7eha0j,Rice Milk Making Machine for Sale,https://www.reddit.com/r/MachineLearning/comments/7eha0j/rice_milk_making_machine_for_sale/,liusherry,1511264840,[removed],1,1
1079,2017-11-21,2017,11,21,20,7ehb9l,HELP NameError: name 'x' is not defined,https://www.reddit.com/r/MachineLearning/comments/7ehb9l/help_nameerror_name_x_is_not_defined/,Alon2904,1511265271,[removed],1,1
1080,2017-11-21,2017,11,21,21,7ehewg,Practical Machine Learning with R and Python  Part 6,https://www.reddit.com/r/MachineLearning/comments/7ehewg/practical_machine_learning_with_r_and_python_part/,tvganesh,1511266401,,0,1
1081,2017-11-21,2017,11,21,22,7ehp9t,6 Amazing Machine Learning Applications in The Real World,https://www.reddit.com/r/MachineLearning/comments/7ehp9t/6_amazing_machine_learning_applications_in_the/,[deleted],1511269688,[deleted],0,1
1082,2017-11-21,2017,11,21,22,7ehqka,"[P] Our Jupyter/IPython client for iPad now includes introductory notebooks on Python, NumPy, Matplotlib and SciPy that you can run without any preliminary configuration. Sign up for beta to run on your iPad! (x-post from /r/IPython)",https://www.reddit.com/r/MachineLearning/comments/7ehqka/p_our_jupyteripython_client_for_ipad_now_includes/,[deleted],1511270057,[deleted],0,1
1083,2017-11-21,2017,11,21,22,7ehvjk,[P] A PaddlePaddle implementation of DeepSpeech2 architecture for ASR,https://www.reddit.com/r/MachineLearning/comments/7ehvjk/p_a_paddlepaddle_implementation_of_deepspeech2/,tuan3w,1511271458,,3,8
1084,2017-11-21,2017,11,21,22,7ehxky,[D] Optimization Algorithms: Math and Code,https://www.reddit.com/r/MachineLearning/comments/7ehxky/d_optimization_algorithms_math_and_code/,mgr2786,1511272049,A colleague of mine had mentioned that they were getting asked quite a few questions about optimization algorithms in their interviews for deep learning positions. I decided to make a quick post about the important ones over at 3dbabove: https://3dbabove.com/2017/11/14/optimizationalgorithms/,36,163
1085,2017-11-21,2017,11,21,23,7ei7fj,[R] Some papers Megvii Inc(Face++),https://www.reddit.com/r/MachineLearning/comments/7ei7fj/r_some_papers_megvii_incface/,senorstallone,1511274593,"Today they just launched (at least) 3  interesting papers in arxiv:

- https://arxiv.org/pdf/1711.07264.pdf (Light-Head R-CNN: In Defense of Two-Stage Object Detector )
- https://arxiv.org/pdf/1711.07319.pdf (Cascaded Pyramid Network for Multi-Person Pose Estimation)
- https://arxiv.org/pdf/1711.07240.pdf (MegDet: A Large Mini-Batch Object Detector)

Quite interesting results. The light object detection seems revolutionary ",9,11
1086,2017-11-21,2017,11,21,23,7eia9w,Stanford algorithm can diagnose pneumonia better than radiologists,https://www.reddit.com/r/MachineLearning/comments/7eia9w/stanford_algorithm_can_diagnose_pneumonia_better/,Chipdoc,1511275324,,0,1
1087,2017-11-21,2017,11,21,23,7eic9e,Implementation of Neural Tensor Network for knowledge-base completion,https://www.reddit.com/r/MachineLearning/comments/7eic9e/implementation_of_neural_tensor_network_for/,[deleted],1511275830,,0,1
1088,2017-11-21,2017,11,21,23,7eid7p,[P] Implementation of Neural Tensor Network for Knowledge-base completion in Python using Keras.,https://www.reddit.com/r/MachineLearning/comments/7eid7p/p_implementation_of_neural_tensor_network_for/,bhatt_gaurav,1511276080,,0,13
1089,2017-11-22,2017,11,22,0,7eitnk,The Path to True AI Starts in Switzerland,https://www.reddit.com/r/MachineLearning/comments/7eitnk/the_path_to_true_ai_starts_in_switzerland/,Rebbitzman,1511279963,,0,1
1090,2017-11-22,2017,11,22,1,7eiu64,DEEPMETU DeepLearning Workshop 1,https://www.reddit.com/r/MachineLearning/comments/7eiu64/deepmetu_deeplearning_workshop_1/,cilicia24,1511280064,,0,1
1091,2017-11-22,2017,11,22,1,7ej4sr,Deep neural network running keyword spotting on a tiny microcontroller.,https://www.reddit.com/r/MachineLearning/comments/7ej4sr/deep_neural_network_running_keyword_spotting_on_a/,coolfun999,1511282406,,0,1
1092,2017-11-22,2017,11,22,2,7ejbr5,[P]  Big challenge in Deep Learning: training data  Hacker Noon,https://www.reddit.com/r/MachineLearning/comments/7ejbr5/p_big_challenge_in_deep_learning_training_data/,tdionis,1511283942,,0,0
1093,2017-11-22,2017,11,22,2,7ejkn1,Simulate organic chemistry with just coordinates using the power of Neural Networks,https://www.reddit.com/r/MachineLearning/comments/7ejkn1/simulate_organic_chemistry_with_just_coordinates/,johnparkhill,1511285852,,0,1
1094,2017-11-22,2017,11,22,3,7ejrc0,Exploring AMD Vega for Deep Learning,https://www.reddit.com/r/MachineLearning/comments/7ejrc0/exploring_amd_vega_for_deep_learning/,gururise,1511287294,,0,1
1095,2017-11-22,2017,11,22,3,7ejrme,[D] Understanding the Mixture of Softmaxes (MoS),https://www.reddit.com/r/MachineLearning/comments/7ejrme/d_understanding_the_mixture_of_softmaxes_mos/,baylearn,1511287359,,8,39
1096,2017-11-22,2017,11,22,3,7ek172,automl: cryptocurrency pow?,https://www.reddit.com/r/MachineLearning/comments/7ek172/automl_cryptocurrency_pow/,tycho01,1511289394,[removed],0,1
1097,2017-11-22,2017,11,22,4,7ekj7t,Calculate Influence function for any Tensorflow models,https://www.reddit.com/r/MachineLearning/comments/7ekj7t/calculate_influence_function_for_any_tensorflow/,cyplus1,1511293217,[removed],1,2
1098,2017-11-22,2017,11,22,5,7ekpiy,[D] Can A.I. Be Taught to Explain Itself?,https://www.reddit.com/r/MachineLearning/comments/7ekpiy/d_can_ai_be_taught_to_explain_itself/,i-heart-turtles,1511294588,,8,0
1099,2017-11-22,2017,11,22,5,7ekpqt,[R] To Frontalize or Not To Frontalize: A Study of Face Pre-Processing Techniques and Their Impact on Recognition,https://www.reddit.com/r/MachineLearning/comments/7ekpqt/r_to_frontalize_or_not_to_frontalize_a_study_of/,aDutchofMuch,1511294631,,0,2
1100,2017-11-22,2017,11,22,5,7eks4k,Issue with convergence with SGD with function approximation using polynomial linear regression,https://www.reddit.com/r/MachineLearning/comments/7eks4k/issue_with_convergence_with_sgd_with_function/,real_charlie_parker,1511295138,,0,1
1101,2017-11-22,2017,11,22,5,7eku9o,[P] Calculate Influence function for any Tensorflow models,https://www.reddit.com/r/MachineLearning/comments/7eku9o/p_calculate_influence_function_for_any_tensorflow/,[deleted],1511295577,[deleted],0,1
1102,2017-11-22,2017,11,22,5,7ekxkh,[P] Calculating Influence function for any Tensorflow models,https://www.reddit.com/r/MachineLearning/comments/7ekxkh/p_calculating_influence_function_for_any/,cyplus1,1511296309,"Do you remember ""Understanding Black-box Predictions via Influence Functions"", the best paper at ICML this year? The influence function could be very useful to understand and debug deep learning models. Here is an open source project that implements calculation of the influence function for any Tensorflow models. 

[http://darkon.io](http://darkon.io)

[https://github.com/darkonhub/darkon](https://github.com/darkonhub/darkon)
",2,6
1103,2017-11-22,2017,11,22,6,7elg12,"How do you figure out whether you are just bad at something, or good but lacking confidence?",https://www.reddit.com/r/MachineLearning/comments/7elg12/how_do_you_figure_out_whether_you_are_just_bad_at/,rochakgupta,1511300327,[removed],0,1
1104,2017-11-22,2017,11,22,6,7elg8w,Understanding a2c and a3c multiple actors,https://www.reddit.com/r/MachineLearning/comments/7elg8w/understanding_a2c_and_a3c_multiple_actors/,grantsrb,1511300374,[removed],0,1
1105,2017-11-22,2017,11,22,7,7elrsp,"Books or tutorials to read on Machine Learning, AI, Computer Vision?",https://www.reddit.com/r/MachineLearning/comments/7elrsp/books_or_tutorials_to_read_on_machine_learning_ai/,Ctrl_Alt_Del3te,1511302958,[removed],0,1
1106,2017-11-22,2017,11,22,7,7elyl1,Computer Generated Domain vs. Human Generated Domain,https://www.reddit.com/r/MachineLearning/comments/7elyl1/computer_generated_domain_vs_human_generated/,[deleted],1511304539,,0,1
1107,2017-11-22,2017,11,22,7,7em0j7,"Hi, I got the Machine Learning A-Z course on Udemy (for $10), what will I actually be able to do at course end?",https://www.reddit.com/r/MachineLearning/comments/7em0j7/hi_i_got_the_machine_learning_az_course_on_udemy/,WombatsInKombat,1511305009,[removed],0,1
1108,2017-11-22,2017,11,22,8,7emaf6,triNNity: Header-only C++ template library with over 70 DNN convolution algorithms,https://www.reddit.com/r/MachineLearning/comments/7emaf6/trinnity_headeronly_c_template_library_with_over/,mttd,1511307337,,0,1
1109,2017-11-22,2017,11,22,8,7embqn,"[P] Our Jupyter/IPython client for iPad now includes introductory notebooks on Python, NumPy, Matplotlib and SciPy that you can run without any preliminary configuration. Sign up for beta to run on your iPad! (x-post from /r/IPython)",https://www.reddit.com/r/MachineLearning/comments/7embqn/p_our_jupyteripython_client_for_ipad_now_includes/,navoshta,1511307666,,2,3
1110,2017-11-22,2017,11,22,8,7emc7i,[N] Nvidia's iOS App Mug Life Brings Your Photos to Life with 3D Animation,https://www.reddit.com/r/MachineLearning/comments/7emc7i/n_nvidias_ios_app_mug_life_brings_your_photos_to/,sksq9,1511307779,,4,23
1111,2017-11-22,2017,11,22,9,7emli6,[D] I have a B.Sc. in Pure Math - Where should I go from here to get a job in Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/7emli6/d_i_have_a_bsc_in_pure_math_where_should_i_go/,SomeUofTGuy,1511310028,[removed],3,2
1112,2017-11-22,2017,11,22,11,7enevu,[D] Has anyone tried out the Split-brain autoencoder?,https://www.reddit.com/r/MachineLearning/comments/7enevu/d_has_anyone_tried_out_the_splitbrain_autoencoder/,PigsDogsAndSheep,1511317545,"https://arxiv.org/abs/1611.09842

Pretty fascinating. I don't quite understand how the quantization of the channels is being performed though.",6,18
1113,2017-11-22,2017,11,22,11,7eng9t,Automatic Noodle Packaging Machine for Sale,https://www.reddit.com/r/MachineLearning/comments/7eng9t/automatic_noodle_packaging_machine_for_sale/,liusherry,1511317906,[removed],1,1
1114,2017-11-22,2017,11,22,11,7engz1,Could you please evaluate this build for a Deep Learning Rig?,https://www.reddit.com/r/MachineLearning/comments/7engz1/could_you_please_evaluate_this_build_for_a_deep/,pie_oh_my_,1511318099,[removed],0,1
1115,2017-11-22,2017,11,22,11,7enlq1,Automatic Rice Noodle Making Machine for Sale,https://www.reddit.com/r/MachineLearning/comments/7enlq1/automatic_rice_noodle_making_machine_for_sale/,liusherry,1511319322,[removed],1,1
1116,2017-11-22,2017,11,22,12,7enno9,[R] [1711.07971] Non-local Neural Networks,https://www.reddit.com/r/MachineLearning/comments/7enno9/r_171107971_nonlocal_neural_networks/,xternalz,1511319814,,16,80
1117,2017-11-22,2017,11,22,12,7enoon,[R] Knowledge Concentration: Learning 100K Object Classifiers in a Single CNN,https://www.reddit.com/r/MachineLearning/comments/7enoon/r_knowledge_concentration_learning_100k_object/,xternalz,1511320088,,5,24
1118,2017-11-22,2017,11,22,12,7env39,[R] [1711.07264v1] Light-Head R-CNN: In Defense of Two-Stage Object Detector,https://www.reddit.com/r/MachineLearning/comments/7env39/r_171107264v1_lighthead_rcnn_in_defense_of/,sakares,1511321792,,1,12
1119,2017-11-22,2017,11,22,14,7eog5s,Do the weights trained from a dataset also come under the same license terms as the dataset?,https://www.reddit.com/r/MachineLearning/comments/7eog5s/do_the_weights_trained_from_a_dataset_also_come/,[deleted],1511327721,,0,1
1120,2017-11-22,2017,11,22,14,7eohsm,Request for resources: video walkthroughs of paper implementations.,https://www.reddit.com/r/MachineLearning/comments/7eohsm/request_for_resources_video_walkthroughs_of_paper/,BoltThrower79,1511328198,[removed],0,1
1121,2017-11-22,2017,11,22,14,7eolg4,Develop ML for predicting the price in Cryptocurrency/risk management,https://www.reddit.com/r/MachineLearning/comments/7eolg4/develop_ml_for_predicting_the_price_in/,rdbacon,1511329271,[removed],0,1
1122,2017-11-22,2017,11,22,15,7eor11,[D] Do the weights trained from a dataset also come under the same license terms as the dataset?,https://www.reddit.com/r/MachineLearning/comments/7eor11/d_do_the_weights_trained_from_a_dataset_also_come/,ts27,1511330932,"A lot of the datasets that we commonly use nowadays are bound by some license or the other. ImageNet for example - http://image-net.org/download-faq

I understand when the use of the actual images is restricted under the terms, but what about weights that we derive out of millions of these images? There is no actual trace of the image within the trained networks, its just a model derived by various iterations over the images. Much like we humans read books and derive knowledge (Most books by themselves are bound by restrictive copyright, but we are free to apply the knowledge we derive from them).

How do companies deal with this? Most companies using deep learning will have to use large datasets and actually creating the data(for example, of millions of images for tens/hundreds of classes) would not be viable.

Also when we do transfer learning on these heavily trained models, we essentially change the network using weights from a pre trained network and use our own custom data to train the last few layers, what about the licenses then?",16,31
1123,2017-11-22,2017,11,22,15,7eord9,Anyone have access to 'Building machines that learn and think for themselves' from Deepmind published about 2 weeks ago?,https://www.reddit.com/r/MachineLearning/comments/7eord9/anyone_have_access_to_building_machines_that/,[deleted],1511331031,,0,1
1124,2017-11-22,2017,11,22,15,7eotpo,[D] Anyone care to link the PDF for 'Building machines that learn and think for themselves' from Deepmind published about 2 weeks ago?,https://www.reddit.com/r/MachineLearning/comments/7eotpo/d_anyone_care_to_link_the_pdf_for_building/,Kaisen25,1511331774,,11,29
1125,2017-11-22,2017,11,22,17,7epgcz,[R] [1711.06047] Deep Matching Autoencoders &lt;- Learning Multimodal Views with Unpaired Data,https://www.reddit.com/r/MachineLearning/comments/7epgcz/r_171106047_deep_matching_autoencoders_learning/,felipedelamuerte,1511339454,,0,8
1126,2017-11-22,2017,11,22,18,7epnml,[N] CNTK 2.2 + FasterRCNN training + Grocery dataset in python,https://www.reddit.com/r/MachineLearning/comments/7epnml/n_cntk_22_fasterrcnn_training_grocery_dataset_in/,pmfcdb,1511342114,,0,18
1127,2017-11-22,2017,11,22,19,7eq09n,Computer Vision,https://www.reddit.com/r/MachineLearning/comments/7eq09n/computer_vision/,[deleted],1511346628,[deleted],1,1
1128,2017-11-22,2017,11,22,20,7eqa5g,[R] MinimalRNN: Toward More Interpretable and Trainable Recurrent Neural Networks,https://www.reddit.com/r/MachineLearning/comments/7eqa5g/r_minimalrnn_toward_more_interpretable_and/,CaHoop,1511350136,,7,16
1129,2017-11-22,2017,11,22,21,7eqk6g,[D] What are core machine learning areas?,https://www.reddit.com/r/MachineLearning/comments/7eqk6g/d_what_are_core_machine_learning_areas/,ultrakoge,1511353350,What does it mean when researchers say they are doing core machine learning researches? What are representative areas and topics in core machine learning?,14,0
1130,2017-11-22,2017,11,22,21,7eqkm1,[N] fMoW challenge ($100k in prizes) team release competitive baseline mid-challenge and research paper,https://www.reddit.com/r/MachineLearning/comments/7eqkm1/n_fmow_challenge_100k_in_prizes_team_release/,30coffeesaday,1511353484,,3,17
1131,2017-11-22,2017,11,22,21,7eqo48,"About Cashew Nut Shelling,Peeling,Roasting,Cutting,Grinding Machine Manufacturer In China",https://www.reddit.com/r/MachineLearning/comments/7eqo48/about_cashew_nut/,gelgoogcara,1511354605,,1,1
1132,2017-11-22,2017,11,22,21,7eqof1,[N]How machine learning is helping Virgin boost its frequent flyer business,https://www.reddit.com/r/MachineLearning/comments/7eqof1/nhow_machine_learning_is_helping_virgin_boost_its/,chris_shpak,1511354710,,0,1
1133,2017-11-22,2017,11,22,21,7eqq9l,[N]Machine Learning Engineers in Oil Will Become 'Bored' Without Quality Data,https://www.reddit.com/r/MachineLearning/comments/7eqq9l/nmachine_learning_engineers_in_oil_will_become/,digitalson,1511355282,,0,1
1134,2017-11-22,2017,11,22,22,7eqtjq,Machine learning and containers,https://www.reddit.com/r/MachineLearning/comments/7eqtjq/machine_learning_and_containers/,saanak,1511356264,,0,1
1135,2017-11-22,2017,11,22,22,7er0y9,AI: The Holy Grail of Trading?,https://www.reddit.com/r/MachineLearning/comments/7er0y9/ai_the_holy_grail_of_trading/,dubplate,1511358334,,0,1
1136,2017-11-22,2017,11,22,23,7er4fz,"What's the meaning of""serving predictions"" in Cloud Machine Learning?",https://www.reddit.com/r/MachineLearning/comments/7er4fz/whats_the_meaning_ofserving_predictions_in_cloud/,AlexMa1991,1511359277,[removed],0,1
1137,2017-11-22,2017,11,22,23,7er7aq,[N]The Need for Inclusion in AI and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7er7aq/nthe_need_for_inclusion_in_ai_and_machine_learning/,janemoz,1511360007,,0,1
1138,2017-11-22,2017,11,22,23,7erdz9,How to prove my own making formula,https://www.reddit.com/r/MachineLearning/comments/7erdz9/how_to_prove_my_own_making_formula/,[deleted],1511361731,,0,1
1139,2017-11-22,2017,11,22,23,7erf0n,CardIO framework for deep research of electrocardiograms,https://www.reddit.com/r/MachineLearning/comments/7erf0n/cardio_framework_for_deep_research_of/,[deleted],1511361984,[deleted],0,1
1140,2017-11-22,2017,11,22,23,7ergo2,Neural Net learns snake game via Reinforcement Learning live on MachineLabs,https://www.reddit.com/r/MachineLearning/comments/7ergo2/neural_net_learns_snake_game_via_reinforcement/,cburgdorf,1511362407,,0,1
1141,2017-11-22,2017,11,22,23,7erhg5,[P] CardIO framework for deep research of electrocardiograms,https://www.reddit.com/r/MachineLearning/comments/7erhg5/p_cardio_framework_for_deep_research_of/,Dearkafka,1511362596,,1,1
1142,2017-11-23,2017,11,23,0,7erj9d,Need tips about text generation with LSTM,https://www.reddit.com/r/MachineLearning/comments/7erj9d/need_tips_about_text_generation_with_lstm/,lowtronik,1511363023,[removed],0,1
1143,2017-11-23,2017,11,23,0,7erp8f,[R] VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection,https://www.reddit.com/r/MachineLearning/comments/7erp8f/r_voxelnet_endtoend_learning_for_point_cloud/,madebyollin,1511364366,,13,9
1144,2017-11-23,2017,11,23,0,7ers86,[D] Question about Convolutional network: LeNet-5,https://www.reddit.com/r/MachineLearning/comments/7ers86/d_question_about_convolutional_network_lenet5/,huyhcmut,1511365073,[removed],0,1
1145,2017-11-23,2017,11,23,0,7eruar,[P] A lot of AI &amp; ML is built around the internet. Help fight to keep this technology free!,https://www.reddit.com/r/MachineLearning/comments/7eruar/p_a_lot_of_ai_ml_is_built_around_the_internet/,jhill515,1511365540,,171,8331
1146,2017-11-23,2017,11,23,0,7erwz1,"Simple Questions Thread November 22, 2017",https://www.reddit.com/r/MachineLearning/comments/7erwz1/simple_questions_thread_november_22_2017/,AutoModerator,1511366146,[removed],0,1
1147,2017-11-23,2017,11,23,1,7esdle,[N] This year's Halite AI programming challenge launched with kit for ML,https://www.reddit.com/r/MachineLearning/comments/7esdle/n_this_years_halite_ai_programming_challenge/,tricero243,1511369763,,0,0
1148,2017-11-23,2017,11,23,2,7esif6,Coloring With Random Forests [P],https://www.reddit.com/r/MachineLearning/comments/7esif6/coloring_with_random_forests_p/,[deleted],1511370779,[deleted],0,1
1149,2017-11-23,2017,11,23,2,7esiq4,[P] Coloring With Random Forests,https://www.reddit.com/r/MachineLearning/comments/7esiq4/p_coloring_with_random_forests/,jeremyhoward,1511370843,,0,1
1150,2017-11-23,2017,11,23,2,7eskd1,[P] Improving the way we work with learning rates,https://www.reddit.com/r/MachineLearning/comments/7eskd1/p_improving_the_way_we_work_with_learning_rates/,jeremyhoward,1511371193,,1,4
1151,2017-11-23,2017,11,23,2,7est2g,Machine Learning and The Market for Intelligence 2017,https://www.reddit.com/r/MachineLearning/comments/7est2g/machine_learning_and_the_market_for_intelligence/,yildiz17,1511373105,[removed],0,1
1152,2017-11-23,2017,11,23,2,7esv6y,Interested in a starter blog for AI?,https://www.reddit.com/r/MachineLearning/comments/7esv6y/interested_in_a_starter_blog_for_ai/,OliRevs,1511373589,[removed],0,1
1153,2017-11-23,2017,11,23,3,7esw0g,Machine Learning and The Market for Intelligence 2017,https://www.reddit.com/r/MachineLearning/comments/7esw0g/machine_learning_and_the_market_for_intelligence/,[deleted],1511373769,[deleted],0,1
1154,2017-11-23,2017,11,23,3,7et91d,"[N] Complete Draft Published - Reinforcement Learning: An Introduction, by Sutton and Barto",https://www.reddit.com/r/MachineLearning/comments/7et91d/n_complete_draft_published_reinforcement_learning/,Geilminister,1511376583,,18,60
1155,2017-11-23,2017,11,23,5,7etvv8,[D] Continue with masters or finish bachelors and go in industry,https://www.reddit.com/r/MachineLearning/comments/7etvv8/d_continue_with_masters_or_finish_bachelors_and/,spartan12321,1511381579,"I'm very self driven and disciplined...I'm finishing my bachelors in chemistry and (along with basic calculus and linear algebra I got in school + some stat and probability that I have learned partly on my own) I learned Python and some R along with ML theory(elements of stat learning, deep learning book). I also tried doing some projects and read some research. .Now I am in doubt:

1.)Just get by in school and learn as much ML as I can and get into some projects

2.)Finish with good grades and then go to masters in ML

I see on basically any job prerequesite education wise: Masters or PhD from CS, math or ML .... or relevant industry experience. Now, I like learning ML and will know a lot if  just pass by my exams, but do you think this is good strategy to get quality ML/AI job?
I'm really in doubt :/ I would love to choose first strategy but fear of doing wrong thing is keeping me back. My thinking process is to go all in to work in industry instead of going to some (at best) mediocre masters program(my grades so far are on average 4 (out of 5 which is maximum))

Edit:I forgot to mention I really don't like chemistry anymore and really like ml",7,2
1156,2017-11-23,2017,11,23,5,7etxvp,"Simulating the AlphaGo Zero ideas in Connect 4, Reversi and Chess (Python)",https://www.reddit.com/r/MachineLearning/comments/7etxvp/simulating_the_alphago_zero_ideas_in_connect_4/,Zeta_36,1511382033,[removed],0,1
1157,2017-11-23,2017,11,23,5,7eu0w1,[Showerthougth] Songs are just adversarial examples for the human brain.,https://www.reddit.com/r/MachineLearning/comments/7eu0w1/showerthougth_songs_are_just_adversarial_examples/,[deleted],1511382712,,0,1
1158,2017-11-23,2017,11,23,5,7eu2po,DM: High-fidelity speech synthesis with a parallelized small WaveNet using knowledge distillation + perceptual loss + power-spectrum loss + contrast/noise loss,https://www.reddit.com/r/MachineLearning/comments/7eu2po/dm_highfidelity_speech_synthesis_with_a/,gwern,1511383103,,1,3
1159,2017-11-23,2017,11,23,5,7eu5fd,[N] DNNDK - Deep Neural Network Development Kit from DeePhi,https://www.reddit.com/r/MachineLearning/comments/7eu5fd/n_dnndk_deep_neural_network_development_kit_from/,visarga,1511383718,,0,0
1160,2017-11-23,2017,11,23,6,7eucp7,"[D] If a convolutional neuralnet tends to converge on either of 2 patterns at each point, like dog faces vs cat faces, then how could that be tuned as a competitive 2 player game trying to have more cats vs dogs?",https://www.reddit.com/r/MachineLearning/comments/7eucp7/d_if_a_convolutional_neuralnet_tends_to_converge/,BenRayfield,1511385387,"Some early experiments and pics of an interactive convolutional boltzmann neuralnet are at http://github.com/benrayfield/timelessCellularAutomataPuzzleGame The patterns are much simpler than cats vs dogs, but its the turingCompleteness I think could make the game strategic, if gameplay is balanced, and various kinds of game design explored.",0,0
1161,2017-11-23,2017,11,23,6,7eujwz,[Showerthought] Songs are just adversarial examples for the human brain.,https://www.reddit.com/r/MachineLearning/comments/7eujwz/showerthought_songs_are_just_adversarial_examples/,snowman322,1511387050,[removed],0,1
1162,2017-11-23,2017,11,23,6,7euk6s,General framework for reinforcement learning,https://www.reddit.com/r/MachineLearning/comments/7euk6s/general_framework_for_reinforcement_learning/,that_one_ai_nerd,1511387120,[removed],0,1
1163,2017-11-23,2017,11,23,7,7euqj5,Im making a structured website similar to ImageNet for graffiti. Please reach out if you would like to join the effort.,https://www.reddit.com/r/MachineLearning/comments/7euqj5/im_making_a_structured_website_similar_to/,Loggerny,1511388564,,0,1
1164,2017-11-23,2017,11,23,7,7ev0t5,[D] About the behavior of the critic in Wasserstein GANs,https://www.reddit.com/r/MachineLearning/comments/7ev0t5/d_about_the_behavior_of_the_critic_in_wasserstein/,M4xim4l,1511391095,"Hey everyone,

In short:
I was wondering if the critic f in a Wasserstein GAN works similarly as the discriminator in standard GANs, i.e. is it still the case that I get high function values for x from the real distribution and small values for obvious fake images?
 
LOOOOOONG:
After discovering  [Nvidia's ICLR submission on growing of GANs](https://github.com/tkarras/progressive_growing_of_gans) I noticed that I had missed quite some important papers on generative models, including  [Wasserstein GANs ](https://arxiv.org/abs/1701.07875) and [the improved version of it](https://arxiv.org/abs/1704.00028). However, I still have some questions, especially about the critic f. So standard GANs are formulated as a min max objective, and in fact under some assumptions this turns out to be a minimization of the Jensen-Shannon divergence between the true data and model distribution. By the way the min max objective is formulated, it is clear that the discriminator has to learn to differentiate between 'real' data points and the ones which come from the generator. This is why it is pretty intuitive that one can use a trained discriminator as a prior loss in an inpainting application for example,  where it basically judges how realistic the inpainted image looks like. In the Wasserstein GAN, however, the discriminator is actually called the critic and its way harder for me to get an intuition on what it is actually doing. So as the name suggest, in a Wasserstein GAN we are trying to minimize the Wasserstein distance between the real and the generators distribution. Unfortunately, the Wasserstein distance has a pretty horrible formulation so  adirect optimization of the generators parameters by backpropagating through the Wasserstein distance is intractable. Therefore the authors make use of this Kantorovich-Rubinstein duality which allows them to express the Wasserstein distance as a supremum over Lipschitz continuous functions. And at this point we get back to the GAN formulation, as we basically parameterize this set of functions by some feedforward-model (the critic f) and use a first-order method to optimize the parameters of f, which replaces the explicit computation of the supremum. The following update of the generators parameters can then be seen as one gradient descent step (or RMSProp to be accurate) on the Kantorovich-Rubinstein form of the Wasserstein distance. So sorry for the long wall of text, but this is what I understood of this paper. Now I have some questions about the  properties of this critic f. So let's assume that I have trained my generator until convergence and I also have a fully converged version of f. How do the function values of f look like on data from the real distribution and obvious fake samples, i.e. can I still use f as a discriminator in some other application, e.g. inpainting or is it really more of a helper function without meaningful behaviour? As this Kantorovich formulation still looks similar to standard GAN loss and we are in fact  maximizing the expectation of f over the generated data's distribution when training the generator, I would assume that f should behave similar to a standard discriminator, but I could be wrong here. Also the image of f is not necessarily bounded in [0,1] (or any other range) right? 

Thanks for your help,
Max ",5,7
1165,2017-11-23,2017,11,23,7,7ev19q,[R] High-fidelity speech synthesis with WaveNet | DeepMind,https://www.reddit.com/r/MachineLearning/comments/7ev19q/r_highfidelity_speech_synthesis_with_wavenet/,madebyollin,1511391217,,25,114
1166,2017-11-23,2017,11,23,8,7eve1i,[R] [1710.08864v2] One pixel attack for fooling deep neural networks,https://www.reddit.com/r/MachineLearning/comments/7eve1i/r_171008864v2_one_pixel_attack_for_fooling_deep/,bubaonaruba,1511394487,,0,11
1167,2017-11-23,2017,11,23,9,7evnox,"[D]Newbie to programming, should i just dive in?",https://www.reddit.com/r/MachineLearning/comments/7evnox/dnewbie_to_programming_should_i_just_dive_in/,BurmaJones,1511396991,"I am currenly studying Civil Engineering, but i want to learn ML because it fascinates me. As a third year eng student, the maths doesnt bother me to much. I've just started working through Automate the Boring Stuff, to learn python. But should i finish this book, or should i just sign up to something like Dataquest and learn as i go? My concern is that it isn't really aimed at people who want to get into ML so how much of the knowledge is relevant.

I also plan on doing Andrew Ng's course in the future, but just want to get some opinions on the best path to learn and how much conventional programming knowledge is required.

Also what are your thoughts on the MIT 6.001 and 6.002 courses for someone who's new to programming and interested in machine learning Thanks guys",4,0
1168,2017-11-23,2017,11,23,9,7evqz5,Specs on Faces (SoF) Dataset,https://www.reddit.com/r/MachineLearning/comments/7evqz5/specs_on_faces_sof_dataset/,mafifi,1511397917,[removed],0,1
1169,2017-11-23,2017,11,23,9,7evra0,VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection - Apple,https://www.reddit.com/r/MachineLearning/comments/7evra0/voxelnet_endtoend_learning_for_point_cloud_based/,ilikepancakez,1511398001,,0,1
1170,2017-11-23,2017,11,23,11,7ew7ba,[D] Capsule Networks (CapsNets)  Tutorial,https://www.reddit.com/r/MachineLearning/comments/7ew7ba/d_capsule_networks_capsnets_tutorial/,Deep_Fried_Learning,1511402491,,23,132
1171,2017-11-23,2017,11,23,11,7ewg1w,[D] How to prove my own handmade formula,https://www.reddit.com/r/MachineLearning/comments/7ewg1w/d_how_to_prove_my_own_handmade_formula/,ahsr0x,1511404942,"Hi everyone, i have a confusion about making formula. For instance i have 2 array contain length of HTML node lik below:

- [500, 10, 50, 60, 70]

- [100, 150, 120]

To evaluate the term ""important"" for one array, I base on those measures: mean, total items, sum items. Then i made a formula like: important = mean * log5(total_item) * log_10(sum_item).
This formula brought me good result (base on my corpus), but I don't know how to prove my formula except empirical.
So, can you guide me how can I prove this formula? Or give me some keywords/ documents i have to take for gaining knowledge about this case. Thanks everyone for reading.",4,0
1172,2017-11-23,2017,11,23,12,7ewoyf,Cigarette Box Wrapping Machine | Bopp Film Wrapping Machine,https://www.reddit.com/r/MachineLearning/comments/7ewoyf/cigarette_box_wrapping_machine_bopp_film_wrapping/,liusherry,1511407552,[removed],1,1
1173,2017-11-23,2017,11,23,12,7ewrw0,Candy Packing Machine | Noodles Packing Machine,https://www.reddit.com/r/MachineLearning/comments/7ewrw0/candy_packing_machine_noodles_packing_machine/,liusherry,1511408398,[removed],1,1
1174,2017-11-23,2017,11,23,12,7ewscc,AMD vs Intel processors for ML/DL,https://www.reddit.com/r/MachineLearning/comments/7ewscc/amd_vs_intel_processors_for_mldl/,Girsadium,1511408530,[removed],0,1
1175,2017-11-23,2017,11,23,12,7ewusv,"[R] Shift: A Zero FLOP, Zero Parameter Alternative to Spatial Convolutions",https://www.reddit.com/r/MachineLearning/comments/7ewusv/r_shift_a_zero_flop_zero_parameter_alternative_to/,xternalz,1511409239,,8,33
1176,2017-11-23,2017,11,23,13,7ewzfn,How we transferred our biases into our machines and what we can do about it : You Are Not So Smart podcast,https://www.reddit.com/r/MachineLearning/comments/7ewzfn/how_we_transferred_our_biases_into_our_machines/,TomasForgac,1511410620,,0,1
1177,2017-11-23,2017,11,23,13,7ewzvk,What do you think they did to the Google Translate ML which results in it saying this? (Try it: Somali to English),https://www.reddit.com/r/MachineLearning/comments/7ewzvk/what_do_you_think_they_did_to_the_google/,[deleted],1511410744,[deleted],0,1
1178,2017-11-23,2017,11,23,13,7ex03l,[D] Links to Families In the Wild (FIW) Data,https://www.reddit.com/r/MachineLearning/comments/7ex03l/d_links_to_families_in_the_wild_fiw_data/,anonDogeLover,1511410809,Does anyone have the dropbox or onedrive links to this? The authors make it very hard to easily download this.,0,0
1179,2017-11-23,2017,11,23,13,7ex1x0,"What do you think they did, or are trying to do to the Google Translate algo which resulted in it saying this? (Try it: Somali to English)",https://www.reddit.com/r/MachineLearning/comments/7ex1x0/what_do_you_think_they_did_or_are_trying_to_do_to/,Motor_City_Cobra,1511411350,,0,0
1180,2017-11-23,2017,11,23,14,7exbs9,CardIO - a python library with preprocessing and ready to use deep models for heart signals,https://www.reddit.com/r/MachineLearning/comments/7exbs9/cardio_a_python_library_with_preprocessing_and/,roman-kh,1511414396,,0,1
1181,2017-11-23,2017,11,23,14,7exeh2,Detection of atrial fibrillation with probability and a confidence over probability,https://www.reddit.com/r/MachineLearning/comments/7exeh2/detection_of_atrial_fibrillation_with_probability/,[deleted],1511415240,[deleted],0,1
1182,2017-11-23,2017,11,23,16,7exwol,Broad Bean|Peanuts|Almond|Chickpea Skin Peeling Machine Manufacturer In China,https://www.reddit.com/r/MachineLearning/comments/7exwol/broad_beanpeanutsalmondchickpea_skin_peeling/,gelgoogcara,1511421336,,1,1
1183,2017-11-23,2017,11,23,16,7ey3lt,In search of go simulator,https://www.reddit.com/r/MachineLearning/comments/7ey3lt/in_search_of_go_simulator/,sbarratt,1511423807,[removed],0,1
1184,2017-11-23,2017,11,23,17,7ey61i,LED Wall Pack Lights and Outdoor LED Wall Pack Lighting | E-conolight,https://www.reddit.com/r/MachineLearning/comments/7ey61i/led_wall_pack_lights_and_outdoor_led_wall_pack/,MarciaNorthib30,1511424690,,0,1
1185,2017-11-23,2017,11,23,17,7ey7tc,[R] Deep Sets (NIPS'17 oral),https://www.reddit.com/r/MachineLearning/comments/7ey7tc/r_deep_sets_nips17_oral/,olBaa,1511425360,,5,14
1186,2017-11-23,2017,11,23,18,7eye20,"Plan, Attend, Generate: Planning for Sequence-to-Sequence Models [ Francis, Caglar Gulcehre, Trischler and Yoshua Bengio ; Performs integration of a planning mechanism inspired by strategic attentive reader and writer (STRAW) model for RL into sequence-to-sequence models using attention.]",https://www.reddit.com/r/MachineLearning/comments/7eye20/plan_attend_generate_planning_for/,rishabh135,1511427766,,0,1
1187,2017-11-23,2017,11,23,18,7eyevb,[R] Mastering the Dungeon: Grounded Language Learning by Mechanical Turker Descent,https://www.reddit.com/r/MachineLearning/comments/7eyevb/r_mastering_the_dungeon_grounded_language/,visarga,1511428069,,3,22
1188,2017-11-23,2017,11,23,18,7eyfen,How does peanut shelling machine work?,https://www.reddit.com/r/MachineLearning/comments/7eyfen/how_does_peanut_shelling_machine_work/,gelgoogcara,1511428270,,1,1
1189,2017-11-23,2017,11,23,18,7eyn7b,[N]Apple could use machine learning to shore up LiDAR limitations in self-driving,https://www.reddit.com/r/MachineLearning/comments/7eyn7b/napple_could_use_machine_learning_to_shore_up/,magneticono,1511431076,,0,1
1190,2017-11-23,2017,11,23,18,7eynju,[R] AANN: Auto-Encoder with tied weights and abs activations for structured representations,https://www.reddit.com/r/MachineLearning/comments/7eynju/r_aann_autoencoder_with_tied_weights_and_abs/,iammarkbro,1511431190,,2,6
1191,2017-11-23,2017,11,23,19,7eynq7,Navigating a Virtual World Using Dynamic Programming,https://www.reddit.com/r/MachineLearning/comments/7eynq7/navigating_a_virtual_world_using_dynamic/,funmaster11,1511431244,,0,1
1192,2017-11-23,2017,11,23,19,7eyuxp,Leela Zero: a community open source project for machine learning in Go software. Call for help!,https://www.reddit.com/r/MachineLearning/comments/7eyuxp/leela_zero_a_community_open_source_project_for/,[deleted],1511433923,,0,2
1193,2017-11-23,2017,11,23,19,7eyx4w,Why Chatbots?,https://www.reddit.com/r/MachineLearning/comments/7eyx4w/why_chatbots/,getengati,1511434772,,0,1
1194,2017-11-23,2017,11,23,20,7ez0r4,Visual Analytics of Instagrams #gopro hashtag with AI,https://www.reddit.com/r/MachineLearning/comments/7ez0r4/visual_analytics_of_instagrams_gopro_hashtag_with/,shashankg22,1511436102,,0,1
1195,2017-11-23,2017,11,23,20,7ez2ei,[N]Keep tabs on competitors with a customized Product Hunt notifications bot | MonkeyLearn Blog,https://www.reddit.com/r/MachineLearning/comments/7ez2ei/nkeep_tabs_on_competitors_with_a_customized/,dearpetra,1511436725,,0,1
1196,2017-11-23,2017,11,23,21,7ezbr9,Deep Learning for Physical Processes: Incorporating Prior Scientific Knowledge,https://www.reddit.com/r/MachineLearning/comments/7ezbr9/deep_learning_for_physical_processes/,ChocoMoi,1511440051,,0,1
1197,2017-11-23,2017,11,23,21,7ezd1q,[Research] [Project] Leela Zero: a community open source project for machine learning in Go software. Call for help!,https://www.reddit.com/r/MachineLearning/comments/7ezd1q/research_project_leela_zero_a_community_open/,therazorguy,1511440502,"For all machine learning and AI enthusiasts, there is a great chance to take part to a project which is going to be a milestone in the history of Go software.

What can you do? You can offer your machine time and run a tiny self-playing software generating new games and data to be used for training Leela Zero and make it stronger and stronger.

We need your help! We need everyone's help in order to speed up the training process. Be part of a great open source and community driven project and let's all make history!

Please visit the links below to know more. Thank you.


https://github.com/gcp/leela-zero

http://zero.sjeng.org/

https://www.reddit.com/r/cbaduk/

General information about Go game: https://en.wikipedia.org/wiki/Go_(game)

General information about Go computing and software: https://en.wikipedia.org/wiki/Computer_Go",22,127
1198,2017-11-23,2017,11,23,21,7ezdgh,[N]Microsoft and AWS Collaborate on Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7ezdgh/nmicrosoft_and_aws_collaborate_on_machine_learning/,friscotime,1511440639,,0,1
1199,2017-11-23,2017,11,23,21,7eze8l,"[N] Weekly Machine Learning Example &amp; Toolset Roundup  Nov. 23, 2017",https://www.reddit.com/r/MachineLearning/comments/7eze8l/n_weekly_machine_learning_example_toolset_roundup/,stkim1,1511440879,,0,1
1200,2017-11-23,2017,11,23,22,7ezrl4,[R] Subset of the preprints accepted to the CIAI NIPS 2017 workshop,https://www.reddit.com/r/MachineLearning/comments/7ezrl4/r_subset_of_the_preprints_accepted_to_the_ciai/,Sigiward,1511445234,,0,1
1201,2017-11-23,2017,11,23,23,7ezzxe,How to generate more samples?,https://www.reddit.com/r/MachineLearning/comments/7ezzxe/how_to_generate_more_samples/,[deleted],1511447640,,0,1
1202,2017-11-23,2017,11,23,23,7f02kv,[Discussion] How to generate more samples?,https://www.reddit.com/r/MachineLearning/comments/7f02kv/discussion_how_to_generate_more_samples/,[deleted],1511448398,[deleted],0,1
1203,2017-11-23,2017,11,23,23,7f04ss,[D] How to generate more samples?,https://www.reddit.com/r/MachineLearning/comments/7f04ss/d_how_to_generate_more_samples/,Xgens,1511449043,"Hi all,
I am fiddling around with a wine quality dataset that I found on UCI (https://archive.ics.uci.edu/ml/datasets/wine+quality). There are 4898 instances for white wine and 1599 instances for red wine. I am trying to do classification and linear regression on it by combining both dataset together and create another feature that determine whether the wine is good or bad (for classification), i.e. if quality of a wine is greater than 7 then it is a good wine otherwise it is bad.
The dilemma that I am facing currently is that there are far more white wine instances compared to red wine. Any tips on how I can increase dataset of red wine to match white wine? I am thinking of doing bootstrapping with replacement to draw more samples from the samples. The reason why I am trying to generate more red wine dataset is to prevent bias and improve training &amp; testing error.
Any suggestion on how I should proceed with this? Thanks!",10,3
1204,2017-11-24,2017,11,24,0,7f06ri,[D] Choosing Components for Personal Deep Learning Machine,https://www.reddit.com/r/MachineLearning/comments/7f06ri/d_choosing_components_for_personal_deep_learning/,mel_silizar,1511449588,,3,9
1205,2017-11-24,2017,11,24,0,7f07h7,Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7f07h7/machine_learning/,KevinSka97,1511449764,,1,1
1206,2017-11-24,2017,11,24,0,7f089y,Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7f089y/machine_learning/,apaez9708,1511449988,,1,1
1207,2017-11-24,2017,11,24,0,7f0i0w,Comparing of 3 or more classifiers on the same balanced dataset,https://www.reddit.com/r/MachineLearning/comments/7f0i0w/comparing_of_3_or_more_classifiers_on_the_same/,lastfreelogino,1511452597,[removed],0,1
1208,2017-11-24,2017,11,24,1,7f0jqd,[R] Probabilistic graphical models: parameter estimation and inference algorithms,https://www.reddit.com/r/MachineLearning/comments/7f0jqd/r_probabilistic_graphical_models_parameter/,FrostyCharizard,1511453053,,9,70
1209,2017-11-24,2017,11,24,1,7f0pkw,[D] New Nature journal: Nature Machine Intelligence,https://www.reddit.com/r/MachineLearning/comments/7f0pkw/d_new_nature_journal_nature_machine_intelligence/,aristosldn,1511454516,"In the era of arXiv and decline of journal publications, what are your thoughts?

Link here: https://www.nature.com/natmachintell/",33,58
1210,2017-11-24,2017,11,24,1,7f0q87,Parallel WaveNet: Fast High-Fidelity Speech Synthesis,https://www.reddit.com/r/MachineLearning/comments/7f0q87/parallel_wavenet_fast_highfidelity_speech/,albertzeyer,1511454668,,0,1
1211,2017-11-24,2017,11,24,1,7f0t1b,A giant intuitive diagram showing how an artificial neural network permits backward propagation of error signals,https://www.reddit.com/r/MachineLearning/comments/7f0t1b/a_giant_intuitive_diagram_showing_how_an/,ProgrammingGodJordan,1511455348,,0,1
1212,2017-11-24,2017,11,24,1,7f0vk4,Learn to create Machine Learning Algorithms in Python and R from two Data Science experts. Code templates included.,https://www.reddit.com/r/MachineLearning/comments/7f0vk4/learn_to_create_machine_learning_algorithms_in/,Vinayaksad,1511455992,,0,1
1213,2017-11-24,2017,11,24,2,7f10vc,"Thalamus Gated Recurrent Modules &lt;- routing module for RNNs inspired by the thalamus of the mammalian brain that learns things like hierarchical, skip and feedback connections",https://www.reddit.com/r/MachineLearning/comments/7f10vc/thalamus_gated_recurrent_modules_routing_module/,[deleted],1511457247,[deleted],0,1
1214,2017-11-24,2017,11,24,2,7f130g,[R] Training Simplification and Model Simplification for Deep Learning: A Minimal Effort Back Propagation Method,https://www.reddit.com/r/MachineLearning/comments/7f130g/r_training_simplification_and_model/,m_ke,1511457774,,4,7
1215,2017-11-24,2017,11,24,2,7f16sc,[P] Direct Future Prediction - Supervised Learning for Reinforcement Learning (with Keras Implementation),https://www.reddit.com/r/MachineLearning/comments/7f16sc/p_direct_future_prediction_supervised_learning/,desku,1511458713,,7,37
1216,2017-11-24,2017,11,24,2,7f17j6,Atrial fibrillation detection with a deep probabilistic model,https://www.reddit.com/r/MachineLearning/comments/7f17j6/atrial_fibrillation_detection_with_a_deep/,roman-kh,1511458894,,0,1
1217,2017-11-24,2017,11,24,3,7f1flu,"[R] Thalamus Gated Recurrent Modules &lt;- routing module for RNNs inspired by the thalamus of the mammalian brain that learns things like hierarchical, skip and feedback connections",https://www.reddit.com/r/MachineLearning/comments/7f1flu/r_thalamus_gated_recurrent_modules_routing_module/,eref,1511460880,,3,8
1218,2017-11-24,2017,11,24,5,7f2gg9,First steps to using TensorFlow?,https://www.reddit.com/r/MachineLearning/comments/7f2gg9/first_steps_to_using_tensorflow/,airmak,1511470273,[removed],0,1
1219,2017-11-24,2017,11,24,6,7f2tj5,[P] Adversarial examples on MNIST (PyTorch),https://www.reddit.com/r/MachineLearning/comments/7f2tj5/p_adversarial_examples_on_mnist_pytorch/,maxdinech,1511473692,"Hi!

For a Computer Science project, I decided to work on adversarial attacks. The purpose of this project is to see how to train road sign slassifiers, then how to deceive them, then how to protect them from such attacks.

I started by working on MNIST, and everything works now. The repo contains modules to easily train models and run adversarial attacks against them. I hope you will enjoy this project, and I await your criticism and advice!

https://github.com/maxdinech/mnist-attack

Thank you very much,

Max",3,14
1220,2017-11-24,2017,11,24,7,7f35rj,What is a good book that I can use to learn about Matrix Calculus?,https://www.reddit.com/r/MachineLearning/comments/7f35rj/what_is_a_good_book_that_i_can_use_to_learn_about/,o_safadinho,1511477194,[removed],0,1
1221,2017-11-24,2017,11,24,8,7f394r,[D] Koh Kodes - Author Check: a tool for analyzing documents for stylistic similarity,https://www.reddit.com/r/MachineLearning/comments/7f394r/d_koh_kodes_author_check_a_tool_for_analyzing/,_alphamaximus_,1511478201,,0,1
1222,2017-11-24,2017,11,24,10,7f3y3r,[P] Tensorflow implementation of Graph Convolutional Network,https://www.reddit.com/r/MachineLearning/comments/7f3y3r/p_tensorflow_implementation_of_graph/,shagunsodhani,1511485663,,23,73
1223,2017-11-24,2017,11,24,10,7f410m,Textbooks on modern information extraction/text mining?,https://www.reddit.com/r/MachineLearning/comments/7f410m/textbooks_on_modern_information_extractiontext/,akcom,1511486574,[removed],0,1
1224,2017-11-24,2017,11,24,11,7f4eo8,Learning the Mode under Bandit Feedback,https://www.reddit.com/r/MachineLearning/comments/7f4eo8/learning_the_mode_under_bandit_feedback/,sudeepraja,1511490916,,0,1
1225,2017-11-24,2017,11,24,11,7f4fyg,Automatic Dry Noodle Making Machine for Sale,https://www.reddit.com/r/MachineLearning/comments/7f4fyg/automatic_dry_noodle_making_machine_for_sale/,liusherry,1511491333,[removed],1,1
1226,2017-11-24,2017,11,24,11,7f4hzb,Chewing Gum Semi Automatic Cellophane Packing Machine,https://www.reddit.com/r/MachineLearning/comments/7f4hzb/chewing_gum_semi_automatic_cellophane_packing/,liusherry,1511492010,[removed],1,1
1227,2017-11-24,2017,11,24,12,7f4nod,High Schooler Interested In Machine Learning Research,https://www.reddit.com/r/MachineLearning/comments/7f4nod/high_schooler_interested_in_machine_learning/,Rogue_Pheonix,1511493847,[removed],0,1
1228,2017-11-24,2017,11,24,12,7f4ocu,How To Remove Hazelnut Shell Easily?,https://www.reddit.com/r/MachineLearning/comments/7f4ocu/how_to_remove_hazelnut_shell_easily/,gelgoogcara,1511494068,,1,1
1229,2017-11-24,2017,11,24,15,7f5p56,Stories in the spirit of entrepreneurship - watch this video created by our newest addition to the Engati customer family.,https://www.reddit.com/r/MachineLearning/comments/7f5p56/stories_in_the_spirit_of_entrepreneurship_watch/,getengati,1511506184,[removed],0,1
1230,2017-11-24,2017,11,24,15,7f5pyt,[D] Those who are working professionally in ML and/or academics who have completed graduate-level coursework in ML: Are there any ML concepts that you don't quite fully grasp?,https://www.reddit.com/r/MachineLearning/comments/7f5pyt/d_those_who_are_working_professionally_in_ml/,Batmantosh,1511506478,,74,112
1231,2017-11-24,2017,11,24,16,7f5r8p,Ball shape organic fertilizer making machine,https://www.reddit.com/r/MachineLearning/comments/7f5r8p/ball_shape_organic_fertilizer_making_machine/,amylee516,1511506939,,0,1
1232,2017-11-24,2017,11,24,16,7f5s8p,Why do naive Bayesian classifiers perform so well?,https://www.reddit.com/r/MachineLearning/comments/7f5s8p/why_do_naive_bayesian_classifiers_perform_so_well/,[deleted],1511507293,,0,1
1233,2017-11-24,2017,11,24,16,7f5shm,Has anyone found a good way to implement a latent space for text?,https://www.reddit.com/r/MachineLearning/comments/7f5shm/has_anyone_found_a_good_way_to_implement_a_latent/,GhostxxxShadow,1511507374,[removed],0,1
1234,2017-11-24,2017,11,24,16,7f5vcm,Why Naive Bayes seems to be the first choice for text classification?,https://www.reddit.com/r/MachineLearning/comments/7f5vcm/why_naive_bayes_seems_to_be_the_first_choice_for/,redditaddict07,1511508405,[removed],0,1
1235,2017-11-24,2017,11,24,17,7f64q8,Annotating heart signals with Hidden Markov Model,https://www.reddit.com/r/MachineLearning/comments/7f64q8/annotating_heart_signals_with_hidden_markov_model/,roman-kh,1511511973,,0,1
1236,2017-11-24,2017,11,24,17,7f66el,CardIO - a rich python library for heart signals,https://www.reddit.com/r/MachineLearning/comments/7f66el/cardio_a_rich_python_library_for_heart_signals/,roman-kh,1511512627,,0,1
1237,2017-11-24,2017,11,24,18,7f6c9e,Programmatic to trade two-thirds of global display ads by 2019: Zenith,https://www.reddit.com/r/MachineLearning/comments/7f6c9e/programmatic_to_trade_twothirds_of_global_display/,DoctroMumbo,1511514974,,0,1
1238,2017-11-24,2017,11,24,19,7f6j9h,[D] Are there good reasons to disable the bias in the last layer of a neural network?,https://www.reddit.com/r/MachineLearning/comments/7f6j9h/d_are_there_good_reasons_to_disable_the_bias_in/,_tomakko,1511517672,"I have seen this in a few implementation, i.e. in regression networks in RL.
From my intuition in should not hurt to include it, because the bias does not affect the gradient w.r.t. to the other weights and, if not needed, stay around zero.",1,3
1239,2017-11-24,2017,11,24,20,7f6xdw,3 Ways Machine Learning Tools Can Drive Sales Over the Holidays,https://www.reddit.com/r/MachineLearning/comments/7f6xdw/3_ways_machine_learning_tools_can_drive_sales/,Victor_Stakh,1511523124,,0,1
1240,2017-11-24,2017,11,24,21,7f73fw,"No background in Math/Stat or Programming, still want to join Data Science? Then Read Through..",https://www.reddit.com/r/MachineLearning/comments/7f73fw/no_background_in_mathstat_or_programming_still/,charudatta2684,1511525387,,0,1
1241,2017-11-24,2017,11,24,21,7f788s,Second Hand Machiner,https://www.reddit.com/r/MachineLearning/comments/7f788s/second_hand_machiner/,bblfoods38,1511527109,,0,1
1242,2017-11-24,2017,11,24,21,7f7aag,xLearn - High-Performance and Scalable Machine Learning Software for Large-Scale Sparse Data,https://www.reddit.com/r/MachineLearning/comments/7f7aag/xlearn_highperformance_and_scalable_machine/,aksnzhy,1511527854,[removed],0,1
1243,2017-11-24,2017,11,24,22,7f7fiz,[D] Is there exists any attempts of creating NPC dialog system that uses natural languages processing?,https://www.reddit.com/r/MachineLearning/comments/7f7fiz/d_is_there_exists_any_attempts_of_creating_npc/,Another__one,1511529610,[removed],6,4
1244,2017-11-24,2017,11,24,22,7f7itl,Coffee Cherry Huller Machine For Sale,https://www.reddit.com/r/MachineLearning/comments/7f7itl/coffee_cherry_huller_machine_for_sale/,gelgoogcara,1511530707,,0,1
1245,2017-11-24,2017,11,24,22,7f7lw5,[N]Shrinking data for surgical training,https://www.reddit.com/r/MachineLearning/comments/7f7lw5/nshrinking_data_for_surgical_training/,janemoz,1511531714,,0,1
1246,2017-11-24,2017,11,24,22,7f7m9m,Survey for Machine Learning &amp; Data Science experts for a university term paper,https://www.reddit.com/r/MachineLearning/comments/7f7m9m/survey_for_machine_learning_data_science_experts/,doppelnul,1511531843,[removed],0,1
1247,2017-11-24,2017,11,24,23,7f7qcd,Voice to MIDI bot - playing music with your voice,https://www.reddit.com/r/MachineLearning/comments/7f7qcd/voice_to_midi_bot_playing_music_with_your_voice/,ecaml,1511533087,,0,1
1248,2017-11-24,2017,11,24,23,7f7s7z,"[R]So, what is machine learning anyways? Here's a quick breakdown",https://www.reddit.com/r/MachineLearning/comments/7f7s7z/rso_what_is_machine_learning_anyways_heres_a/,polllyyy,1511533647,,0,1
1249,2017-11-24,2017,11,24,23,7f7v6g,List of more than 65 frameworks and tools for Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7f7v6g/list_of_more_than_65_frameworks_and_tools_for/,holyjavascriptures,1511534536,,0,1
1250,2017-11-25,2017,11,25,0,7f85wy,A Video To Show People When They Ask What You Do,https://www.reddit.com/r/MachineLearning/comments/7f85wy/a_video_to_show_people_when_they_ask_what_you_do/,goldenorbspider,1511537575,,0,1
1251,2017-11-25,2017,11,25,0,7f8870,"[D] Can CNN Autoencoders be used to reduce dimensionality on of a large, partially labelled datasets (for use in end to end lane detection)?",https://www.reddit.com/r/MachineLearning/comments/7f8870/d_can_cnn_autoencoders_be_used_to_reduce/,[deleted],1511538194,[deleted],0,1
1252,2017-11-25,2017,11,25,0,7f8b0r,"[D] Can CNN Autoencoders be used to reduce the dimensionality of a large, partially labelled datasets (for use in end to end lane detection)?",https://www.reddit.com/r/MachineLearning/comments/7f8b0r/d_can_cnn_autoencoders_be_used_to_reduce_the/,djnugent,1511538962,"I am looking to create a CNN based lane detector, however, I lack a labeled dataset. Collecting the data is easy but labeling it sounds like a job for Amazon turks. I could label the data using traditional CV, but if I have a CV algorithm that can do lane detection then whats the point of the DL approach (other than potential speed ups). I have this idea of:


1. training an auto-encoder on the unlabeled data
2. pop off the decoder layers and lock the encoder layers
3. append a much smaller fully connected layer to the encoder
4. hand label a small subset of original dataset (1%~10%)
5. train the small network on the small labelled dataset


The idea is that the auto-encoder will reduce the dimensionality of the scene and therefore a smaller labelled dataset can be used to train the smaller network.


My question is: Is this common practice? Do any papers cover this approach? Are there any alternatives to solving this problem?",15,9
1253,2017-11-25,2017,11,25,0,7f8bur,Ideas of prediction free time slots for sharing personal car from calendar,https://www.reddit.com/r/MachineLearning/comments/7f8bur/ideas_of_prediction_free_time_slots_for_sharing/,altowk,1511539195,[removed],0,1
1254,2017-11-25,2017,11,25,1,7f8eqy,[R] An empirical study on evaluation metrics of generative adversarial networks,https://www.reddit.com/r/MachineLearning/comments/7f8eqy/r_an_empirical_study_on_evaluation_metrics_of/,HigherTopoi,1511539972,,1,20
1255,2017-11-25,2017,11,25,1,7f8iyg,[P] Trial and error approach to deep learning: image classification on CIFAR-10,https://www.reddit.com/r/MachineLearning/comments/7f8iyg/p_trial_and_error_approach_to_deep_learning_image/,pmigdal,1511541039,,12,9
1256,2017-11-25,2017,11,25,1,7f8jxv,[D] - Application or Practicality of Machine Learning on A Small Dataset,https://www.reddit.com/r/MachineLearning/comments/7f8jxv/d_application_or_practicality_of_machine_learning/,Ya_boi_Hamburglar,1511541295,"Hello r/MachineLearning,

I'm somewhat new to machine learning, but have taken a few graduate level courses and have a good understanding of the fundamentals of most ML algorithms. However, I'm having a research-related issue when it comes to the practical application of ML. My academic supervisor is very adamant that I apply a ML technique to a small (very small, ~16 data points with small feature vector lengths ~2-3 features). My initial reactions are that this is an extremely small sample set and from a ML standpoint the knowledge gained from using a NN or even simpler algorithm is very limited. It is my understanding that larger datasets trump even the most sophisticated algorithms for effective ML.

Has this sub discussed dataset size previously? Is this practical or even appropriate to try and force machine learning techniques on such a small dataset? I'd love some advice or for someone to point me towards some literature on small dataset ML. Thanks guys!
",9,4
1257,2017-11-25,2017,11,25,2,7f8vkm,What is the projection layer in an LSTM ?,https://www.reddit.com/r/MachineLearning/comments/7f8vkm/what_is_the_projection_layer_in_an_lstm/,hinduismtw,1511544159,[removed],0,1
1258,2017-11-25,2017,11,25,2,7f8yh4,Machine Learning and the Future of Radiology: How we won the 2017 RSNA ML Challenge,https://www.reddit.com/r/MachineLearning/comments/7f8yh4/machine_learning_and_the_future_of_radiology_how/,cicce19,1511544868,,0,1
1259,2017-11-25,2017,11,25,3,7f9ie8,And sifting through my search history apparently...,https://www.reddit.com/r/MachineLearning/comments/7f9ie8/and_sifting_through_my_search_history_apparently/,[deleted],1511549837,[deleted],0,1
1260,2017-11-25,2017,11,25,4,7f9lub,Transferring Agent Behaviors from Videos via Motion GANs,https://www.reddit.com/r/MachineLearning/comments/7f9lub/transferring_agent_behaviors_from_videos_via/,rerevelcgnihtemos,1511550690,,1,2
1261,2017-11-25,2017,11,25,4,7f9mh4,Get up and running with Docker and Tensorflow,https://www.reddit.com/r/MachineLearning/comments/7f9mh4/get_up_and_running_with_docker_and_tensorflow/,[deleted],1511550856,[deleted],0,1
1262,2017-11-25,2017,11,25,4,7f9mp6,[D] Get up and running with Docker and Tensorflow,https://www.reddit.com/r/MachineLearning/comments/7f9mp6/d_get_up_and_running_with_docker_and_tensorflow/,[deleted],1511550915,[deleted],0,0
1263,2017-11-25,2017,11,25,4,7f9py8,The Progress Weve Made in Machine Learning  Tom Dietterich,https://www.reddit.com/r/MachineLearning/comments/7f9py8/the_progress_weve_made_in_machine_learning_tom/,yildiz17,1511551703,[removed],0,1
1264,2017-11-25,2017,11,25,4,7f9u9v,Is there any example of serving a sci-kit model with tensorflow serve?,https://www.reddit.com/r/MachineLearning/comments/7f9u9v/is_there_any_example_of_serving_a_scikit_model/,skbrhmn,1511552779,[removed],0,1
1265,2017-11-25,2017,11,25,5,7fa0tk,[N] Amazon ML Solutions Lab to help customers work backwards and leverage machine learning,https://www.reddit.com/r/MachineLearning/comments/7fa0tk/n_amazon_ml_solutions_lab_to_help_customers_work/,wilsstar007,1511554371,,0,1
1266,2017-11-25,2017,11,25,5,7fa38f,Chomsky takes a shot at deep learning,https://www.reddit.com/r/MachineLearning/comments/7fa38f/chomsky_takes_a_shot_at_deep_learning/,WigglyHypersurface,1511554987,[removed],0,1
1267,2017-11-25,2017,11,25,5,7fa3t4,[D] Why you should learn Scikit-learn,https://www.reddit.com/r/MachineLearning/comments/7fa3t4/d_why_you_should_learn_scikitlearn/,wilsstar007,1511555152,,0,1
1268,2017-11-25,2017,11,25,5,7fa54w,Admission in multidisciplinary Data Science/Business PhD research in the UK,https://www.reddit.com/r/MachineLearning/comments/7fa54w/admission_in_multidisciplinary_data/,NexYY,1511555495,,0,1
1269,2017-11-25,2017,11,25,5,7fa5hk,[P] I made a movie recommendation system in C as my first ML project in University,https://www.reddit.com/r/MachineLearning/comments/7fa5hk/p_i_made_a_movie_recommendation_system_in_c_as_my/,new_username_again,1511555592,,50,224
1270,2017-11-25,2017,11,25,5,7fa7db,[R] Coupled Ensembles of Neural Networks,https://www.reddit.com/r/MachineLearning/comments/7fa7db/r_coupled_ensembles_of_neural_networks/,xternalz,1511556064,,12,13
1271,2017-11-25,2017,11,25,6,7fajag,[P] Image-Text-Embedding Using Dual-path ft CNN without RNN,https://www.reddit.com/r/MachineLearning/comments/7fajag/p_imagetextembedding_using_dualpath_ft_cnn/,zhedongzheng,1511559165,,3,1
1272,2017-11-25,2017,11,25,7,7fas7q,AI Weekly 24 Nov 2017,https://www.reddit.com/r/MachineLearning/comments/7fas7q/ai_weekly_24_nov_2017/,TomekB,1511561505,,0,1
1273,2017-11-25,2017,11,25,7,7fasc3,Machine Learning and the Future of Radiology: How we won the 2017 RSNA ML Challenge,https://www.reddit.com/r/MachineLearning/comments/7fasc3/machine_learning_and_the_future_of_radiology_how/,cicce19,1511561537,,0,1
1274,2017-11-25,2017,11,25,9,7fbles,Learning to Think and Argue: a path to automated theorem proving,https://www.reddit.com/r/MachineLearning/comments/7fbles/learning_to_think_and_argue_a_path_to_automated/,aidanrocke,1511569425,,0,1
1275,2017-11-25,2017,11,25,9,7fbm84,[D] Visual Medium for Mathematical Exploration - Michael Nielsen,https://www.reddit.com/r/MachineLearning/comments/7fbm84/d_visual_medium_for_mathematical_exploration/,sksq9,1511569653,,1,7
1276,2017-11-25,2017,11,25,9,7fbmi3,[P] Convolutional LSTM Cell in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/7fbmi3/p_convolutional_lstm_cell_in_tensorflow/,zsdh123,1511569729,,0,1
1277,2017-11-25,2017,11,25,9,7fbnmx,"[D] Question, how to train neural networks without",https://www.reddit.com/r/MachineLearning/comments/7fbnmx/d_question_how_to_train_neural_networks_without/,chubbyspartn,1511570042,[removed],1,0
1278,2017-11-25,2017,11,25,11,7fc5qg,[D] Links to Families In the Wild (FIW) Data,https://www.reddit.com/r/MachineLearning/comments/7fc5qg/d_links_to_families_in_the_wild_fiw_data/,anonDogeLover,1511575392,Does anyone have the dropbox or onedrive links to this? The authors make it very hard to easily download this.,1,0
1279,2017-11-25,2017,11,25,11,7fccpy,Machine Learning on Graphs,https://www.reddit.com/r/MachineLearning/comments/7fccpy/machine_learning_on_graphs/,[deleted],1511577605,,0,1
1280,2017-11-25,2017,11,25,12,7fcj1e,[D] Why did Google release Word2Vec?,https://www.reddit.com/r/MachineLearning/comments/7fcj1e/d_why_did_google_release_word2vec/,jboy_slim,1511579540,They could've simply kept it to themselves and improved their product greatly. Maybe they're just very nice people or maybe a hidden motive?,17,0
1281,2017-11-25,2017,11,25,12,7fcrb2,Reinforcement Learning - OpenAI Gym,https://www.reddit.com/r/MachineLearning/comments/7fcrb2/reinforcement_learning_openai_gym/,prakhar2121,1511582198,,0,1
1282,2017-11-25,2017,11,25,13,7fcryt,Uploading paper to arXiv without publishing in a journal or conference,https://www.reddit.com/r/MachineLearning/comments/7fcryt/uploading_paper_to_arxiv_without_publishing_in_a/,liorde,1511582404,[removed],0,1
1283,2017-11-25,2017,11,25,13,7fczfk,[N] Sophon BM1680 - a 2TFlops customized ASIC for tensor computation,https://www.reddit.com/r/MachineLearning/comments/7fczfk/n_sophon_bm1680_a_2tflops_customized_asic_for/,visarga,1511584821,,9,0
1284,2017-11-25,2017,11,25,14,7fdadz,FEIDA ROLL FLATBED DIE CUTTING EMBOSSING MACHINE IN CUSTOMER'S FACTORY,https://www.reddit.com/r/MachineLearning/comments/7fdadz/feida_roll_flatbed_die_cutting_embossing_machine/,FEIDA_MACHINE,1511588482,,0,1
1285,2017-11-25,2017,11,25,19,7fefyf,[D] Deep learning starters pack,https://www.reddit.com/r/MachineLearning/comments/7fefyf/d_deep_learning_starters_pack/,whoisthebossbitch,1511605502,,9,18
1286,2017-11-25,2017,11,25,19,7fei4n,[R] Speeding up Dqn on Pytorch: How to Solve Pong in 30 Minutes,https://www.reddit.com/r/MachineLearning/comments/7fei4n/r_speeding_up_dqn_on_pytorch_how_to_solve_pong_in/,[deleted],1511606492,[deleted],0,1
1287,2017-11-25,2017,11,25,19,7fejjx,[R] Speeding up DQN on PyTorch: How to Solve Pong in 30 Minutes,https://www.reddit.com/r/MachineLearning/comments/7fejjx/r_speeding_up_dqn_on_pytorch_how_to_solve_pong_in/,Palamua,1511607140,,5,76
1288,2017-11-25,2017,11,25,21,7feyu5,How does posterior collapse happen?,https://www.reddit.com/r/MachineLearning/comments/7feyu5/how_does_posterior_collapse_happen/,[deleted],1511613598,,0,1
1289,2017-11-25,2017,11,25,22,7ff30p,Tensorflow support for cuda9 and cudnn7,https://www.reddit.com/r/MachineLearning/comments/7ff30p/tensorflow_support_for_cuda9_and_cudnn7/,dexter4121,1511615126,[removed],0,1
1290,2017-11-26,2017,11,26,0,7ffswt,Spiking RBMs trained using Contrastive Divergence based on STDP rule,https://www.reddit.com/r/MachineLearning/comments/7ffswt/spiking_rbms_trained_using_contrastive_divergence/,prime_007,1511623371,,0,1
1291,2017-11-26,2017,11,26,0,7ffvma,medical chatbot,https://www.reddit.com/r/MachineLearning/comments/7ffvma/medical_chatbot/,shannonDotpy,1511624108,[removed],0,1
1292,2017-11-26,2017,11,26,0,7fg0bl,[Discussion] (really a question): Best host &amp; guest combo for (mostly) ML work and (some) gaming for new machine?,https://www.reddit.com/r/MachineLearning/comments/7fg0bl/discussion_really_a_question_best_host_guest/,JQVeenstra,1511625414,"So I'm finally getting a new desktop. I'd ideally like to run Windows with a Linux guest, but do most of my work in Linux, in particular, using TensorFlow and PyTorch (using cuDNN) for preliminary work before submitting it to AWS instances. I'd like to run with the Linux guest inside Windows because I am hoping I can, ahem, save the state of something that's running in Linux to disk when I feel like gaming on my lunch break. This seems, simultaneously, to be the best method to do this and utterly stupid. Am I wrong?  

Note - I have seen differing views on whether or not this is possible.  I know it was impossible some years ago.  Now I see indications that it may be possible, but nothing certain.

Note 2 - while I am not a newb to ML, I am a newb to Reddit.  Please be gentle.",8,0
1293,2017-11-26,2017,11,26,2,7fgjt0,Python script for CAP Curves : correct or not ?,https://www.reddit.com/r/MachineLearning/comments/7fgjt0/python_script_for_cap_curves_correct_or_not/,luz_imprezi,1511630562,[removed],0,1
1294,2017-11-26,2017,11,26,2,7fgpju,Neural Nets and Rectified Linear Units: How do you use them?,https://www.reddit.com/r/MachineLearning/comments/7fgpju/neural_nets_and_rectified_linear_units_how_do_you/,[deleted],1511632057,,0,1
1295,2017-11-26,2017,11,26,3,7fgzfl,[D] What is Gaussian MLP Policy,https://www.reddit.com/r/MachineLearning/comments/7fgzfl/d_what_is_gaussian_mlp_policy/,AfraidTourist,1511634623,"I found it while playing around with the following code, but am unable to comprehend what it's trying to do. 

https://github.com/rll/rllab/blob/master/rllab/policies/gaussian_mlp_policy.py

I tried googling for some literature but couldn't find any. The following issue states it's trying to learn the standard deviation. Possibly shed more light?

https://github.com/rll/rllab/issues/3",7,0
1296,2017-11-26,2017,11,26,4,7fh9oz,Cycling Power Predictions II: Physics-Inspired Feature Engineering,https://www.reddit.com/r/MachineLearning/comments/7fh9oz/cycling_power_predictions_ii_physicsinspired/,[deleted],1511637264,[deleted],0,1
1297,2017-11-26,2017,11,26,4,7fhc4b,I am looking for a way to generate midi from camera input?,https://www.reddit.com/r/MachineLearning/comments/7fhc4b/i_am_looking_for_a_way_to_generate_midi_from/,[deleted],1511637869,,0,1
1298,2017-11-26,2017,11,26,5,7fhnf4,Python: Graphing 10 Dice with 1 MILLION ROLLS EACH!,https://www.reddit.com/r/MachineLearning/comments/7fhnf4/python_graphing_10_dice_with_1_million_rolls_each/,LeoDrysdale,1511640736,,0,1
1299,2017-11-26,2017,11,26,6,7fi5o4,[D] What are the advantages and disadvantages of having multiple GPUs in a personal Deep Learning machines?,https://www.reddit.com/r/MachineLearning/comments/7fi5o4/d_what_are_the_advantages_and_disadvantages_of/,langfosaurus,1511645513,"I'm thinking of building my own Deep Learning rig at home, and I may have the budget for multiple GPUs. Is that generally advisable? If I do look into it, what things should I watch out for? Thanks!",22,10
1300,2017-11-26,2017,11,26,7,7fid3d,"Some Deep Learning with Python, TensorFlow and Keras",https://www.reddit.com/r/MachineLearning/comments/7fid3d/some_deep_learning_with_python_tensorflow_and/,SandipanDeyUMBC,1511647496,,0,1
1301,2017-11-26,2017,11,26,9,7fj86h,[P] Building a GPU implementation of a CNN. Does anyone know of a GPU implementation of im2col?,https://www.reddit.com/r/MachineLearning/comments/7fj86h/p_building_a_gpu_implementation_of_a_cnn_does/,Lomelgande,1511655861,[removed],6,0
1302,2017-11-26,2017,11,26,9,7fjaa2,[P] Cycling Power Predictions II: Physics-Inspired Feature Engineering,https://www.reddit.com/r/MachineLearning/comments/7fjaa2/p_cycling_power_predictions_ii_physicsinspired/,soutioirsim,1511656455,,5,27
1303,2017-11-26,2017,11,26,10,7fjnde,pure numpy and matplotlib cnn,https://www.reddit.com/r/MachineLearning/comments/7fjnde/pure_numpy_and_matplotlib_cnn/,jumper384,1511660163,[removed],0,1
1304,2017-11-26,2017,11,26,11,7fjur3,[D] Would you donate your data for the collective good?,https://www.reddit.com/r/MachineLearning/comments/7fjur3/d_would_you_donate_your_data_for_the_collective/,_alphamaximus_,1511662317,,0,1
1305,2017-11-26,2017,11,26,12,7fkdtm,[D] How does posterior collapse in VAEs happen?,https://www.reddit.com/r/MachineLearning/comments/7fkdtm/d_how_does_posterior_collapse_in_vaes_happen/,ExtraterritorialHaik,1511668078,"Several papers, such as Variational Lossey Autoencoder by Kingma and others, say that if the decoder is sufficiently powerful, then the training objective can be solved with a dumb strategy: the encoder always produces p(z) regardless of the data, and the decoder always produces p(x) regardless of z. The paper Neural Discrete Representation Learning (from van den Oord and others from deepmind) calls this ""posterior collapse"". 

How is this possible?  

The decoder is deterministic, so in order to match different data, it needs a source of variability, and the latent is the only source available. If the decoder ignored z, it would always produce the same thing regardless of the input, which would result in high error.

EDIT: Last sentence should be ""If the decoder ignores the latent, it will produce output that does not resemble the input, which would result in high error"".  As the responses point out, saying that the decoder always produces the same thing is wrong.

",17,16
1306,2017-11-26,2017,11,26,12,7fkeua,I made an app for dog people with deep learning!,https://www.reddit.com/r/MachineLearning/comments/7fkeua/i_made_an_app_for_dog_people_with_deep_learning/,[deleted],1511668380,[deleted],0,1
1307,2017-11-26,2017,11,26,13,7fkign,I made an app for dog people that have iPhones... It uses deep learning.,https://www.reddit.com/r/MachineLearning/comments/7fkign/i_made_an_app_for_dog_people_that_have_iphones_it/,jnblanchard,1511669523,,0,1
1308,2017-11-26,2017,11,26,13,7fkm3e,"What is the best method for sentence classification that has short text? I tried attention on top of LSTM and CNN, and I was not successful",https://www.reddit.com/r/MachineLearning/comments/7fkm3e/what_is_the_best_method_for_sentence/,[deleted],1511670684,,0,1
1309,2017-11-26,2017,11,26,13,7fkmln,"[D] What is the best method for sentence classification that has full of short text? I tried attention on top of LSTM and CNN, and I was not successful",https://www.reddit.com/r/MachineLearning/comments/7fkmln/d_what_is_the_best_method_for_sentence/,whoisthebossbitch,1511670851,"The average length of a sentence is 5 ( # of words) in my dataset. I did bayesian hyperparameter search on attention-based LSTM and CNN. I am not successful and I am not getting better than the linear model. I tried with pretrained Embedding (Glove, Concept Numberbatch, Google news) and random initialization. My dataset has 400,000 samples and 850 classes. This an internal dataset. Do you have any tricks that could help me to improve the score? Is there any model that works specifically very well for short texts?",47,15
1310,2017-11-26,2017,11,26,18,7flzk3,[P] Crayon: A framework for using Tensorboard with a RESTful API in any language,https://www.reddit.com/r/MachineLearning/comments/7flzk3/p_crayon_a_framework_for_using_tensorboard_with_a/,reformed_scientist,1511689314,,12,64
1311,2017-11-26,2017,11,26,20,7fmbm6,[Project] Python: Building and Simulating a Password Hack!!,https://www.reddit.com/r/MachineLearning/comments/7fmbm6/project_python_building_and_simulating_a_password/,LeoDrysdale,1511694804,,0,0
1312,2017-11-26,2017,11,26,21,7fmnha,[P] OSQP: a new first-order solver for large-scale quadratic programs,https://www.reddit.com/r/MachineLearning/comments/7fmnha/p_osqp_a_new_firstorder_solver_for_largescale/,sidereuss,1511699843,,7,47
1313,2017-11-26,2017,11,26,22,7fmvin,Regression and test data,https://www.reddit.com/r/MachineLearning/comments/7fmvin/regression_and_test_data/,sharanbr,1511702757,[removed],0,1
1314,2017-11-26,2017,11,26,23,7fn4t0,"Free Download iBilling v4.2.0  CRM, Accounting and Billing Software PHP Script",https://www.reddit.com/r/MachineLearning/comments/7fn4t0/free_download_ibilling_v420_crm_accounting_and/,universefeed,1511705923,,1,1
1315,2017-11-26,2017,11,26,23,7fn6l8,PyTorch to Keras model converter,https://www.reddit.com/r/MachineLearning/comments/7fn6l8/pytorch_to_keras_model_converter/,nerox8664,1511706508,,0,1
1316,2017-11-26,2017,11,26,23,7fn7qo,[P] CNN in numpy,https://www.reddit.com/r/MachineLearning/comments/7fn7qo/p_cnn_in_numpy/,sjhshy,1511706862,,9,0
1317,2017-11-26,2017,11,26,23,7fn9e4,[D] Meet the High Schooler Shaking Up Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/7fn9e4/d_meet_the_high_schooler_shaking_up_artificial/,_alphamaximus_,1511707392,,0,0
1318,2017-11-26,2017,11,26,23,7fn9zr,I need your help machine learning experts! 2 minute survey for my term paper,https://www.reddit.com/r/MachineLearning/comments/7fn9zr/i_need_your_help_machine_learning_experts_2/,doppelnul,1511707579,[removed],0,1
1319,2017-11-27,2017,11,27,0,7fndu2,Label Propagation on directed graphs,https://www.reddit.com/r/MachineLearning/comments/7fndu2/label_propagation_on_directed_graphs/,CodeMK,1511708728,[removed],0,1
1320,2017-11-27,2017,11,27,0,7fnfcf,"If you are interested in learning about some of the applications that machine learning have to our daily lives, and tutorials, such as tensorflow and database management, please check out and subscribe to my channel! Thanks for your help!",https://www.reddit.com/r/MachineLearning/comments/7fnfcf/if_you_are_interested_in_learning_about_some_of/,DiscoverAI,1511709148,,0,1
1321,2017-11-27,2017,11,27,1,7fnrjh,[P] Parametric tSNE implemented in Python using Tensorflow,https://www.reddit.com/r/MachineLearning/comments/7fnrjh/p_parametric_tsne_implemented_in_python_using/,JakeTheSnake2,1511712509,,0,22
1322,2017-11-27,2017,11,27,2,7fofd7,[P] Tutorial: Making AI Art with Style Transfer using Keras,https://www.reddit.com/r/MachineLearning/comments/7fofd7/p_tutorial_making_ai_art_with_style_transfer/,Hrafhildur,1511718553,,1,80
1323,2017-11-27,2017,11,27,2,7fofep,Help regarding AI and machine learning.,https://www.reddit.com/r/MachineLearning/comments/7fofep/help_regarding_ai_and_machine_learning/,esnewbie,1511718561,[removed],0,1
1324,2017-11-27,2017,11,27,3,7fokkh,ML in autonomous driving: Conferences? Journals?,https://www.reddit.com/r/MachineLearning/comments/7fokkh/ml_in_autonomous_driving_conferences_journals/,si_bueno_no,1511719799,[removed],0,1
1325,2017-11-27,2017,11,27,3,7fol88,Affordable GPUs for real-time object detection project,https://www.reddit.com/r/MachineLearning/comments/7fol88/affordable_gpus_for_realtime_object_detection/,noorhashem,1511719969,[removed],0,1
1326,2017-11-27,2017,11,27,3,7fowm7,[D] Why do we use gumbel softmax instead of simple softmax for discrete cases?,https://www.reddit.com/r/MachineLearning/comments/7fowm7/d_why_do_we_use_gumbel_softmax_instead_of_simple/,Faizann24,1511722737,"In both softmax and gumbel softmax, we have as output probabilities that sum up to 1. Why do we then use gumbel softmax for discrete cases in Generative Adversarial Networks instead of simple softmax probabilities.",9,15
1327,2017-11-27,2017,11,27,4,7fp3gc,[D] In RBM should all correct beliefs have the same boltzmann energy?,https://www.reddit.com/r/MachineLearning/comments/7fp3gc/d_in_rbm_should_all_correct_beliefs_have_the_same/,BenRayfield,1511724380,"https://en.wikipedia.org/wiki/Boltzmann_machine

https://en.wikipedia.org/wiki/Boltzmann_distribution

    energy = sum of nodeX * nodeY * weightXY

    chance = e^-energy / sumOfAll(e^-energy)

If I have the context right, those imply that if the set of all possible correct beliefs of a RBM should occur equally often, then those states should all have equal energy which is lower than all other states. Therefore during training we should never reduce any state's energy to less than such constant.

If we know the sumOfAll(e ^ -energy), we could compute the chance of any given state, so we could also choose a high constant and never directly raise any state's energy above that.

It seems that during contrastiveDivergence, the unlearning of other states could somehow be improved by knowing the chance of each state before and after its learned and similar states after more inference cycles unlearned (as Geoffrey Hinton says (in very similar words to) ""learn the input, and unlearn what the RBM imagines about the input""). Simply raising some and lowering others the weights between pairs that happen to be on together works in practice, but then sometimes its recommended to do persistent-contrastive-divergence to unlearn anything that has become too low of energy. Of course any adjustment will have effects that are exponentially hard to know in advance, but it appears from those equations that it would be pointless to adjust any state's energy beyond some chosen range to try to keep all energies in, instead of ignoring energy and chance.",7,0
1328,2017-11-27,2017,11,27,4,7fp5vl,Classify music taste,https://www.reddit.com/r/MachineLearning/comments/7fp5vl/classify_music_taste/,maciekmaciek,1511724967,[removed],0,1
1329,2017-11-27,2017,11,27,5,7fpfm3,Keras RNN question - gesture recognition,https://www.reddit.com/r/MachineLearning/comments/7fpfm3/keras_rnn_question_gesture_recognition/,gabegabe6,1511727253,[removed],0,1
1330,2017-11-27,2017,11,27,5,7fpkp1,Anyone have any thoughts on what might be wrong with this dcgan?,https://www.reddit.com/r/MachineLearning/comments/7fpkp1/anyone_have_any_thoughts_on_what_might_be_wrong/,khazarboy123,1511728502,,0,1
1331,2017-11-27,2017,11,27,6,7fpuqj,more elon fear/hype tweets,https://www.reddit.com/r/MachineLearning/comments/7fpuqj/more_elon_fearhype_tweets/,[deleted],1511730898,[deleted],1,1
1332,2017-11-27,2017,11,27,6,7fpybr,"Meet Sunny, a bot that uses unsupervised learning to make gift suggestions",https://www.reddit.com/r/MachineLearning/comments/7fpybr/meet_sunny_a_bot_that_uses_unsupervised_learning/,zakk103,1511731774,,0,1
1333,2017-11-27,2017,11,27,7,7fqhc5,[D] Anyone else out there applying to graduate school for Machine Learning right now? (year two),https://www.reddit.com/r/MachineLearning/comments/7fqhc5/d_anyone_else_out_there_applying_to_graduate/,yoyosarian,1511736525,After getting rejected from grad schools last year I am reapplying to Ph.D. programs in machine learning. Anyone else in the same or similar boat?,19,3
1334,2017-11-27,2017,11,27,8,7fqsp4,[D] GANs for Text SotA,https://www.reddit.com/r/MachineLearning/comments/7fqsp4/d_gans_for_text_sota/,gokstudio,1511739445,"Hi,
I'm thinking of doing a project on GANs for Text using RL for a DL class in uni. From what I read online and from answers from u/ian_goodfellow it looks like the only approach is to use REINFORCE to handle the discrete nature of the latent space of words with rest of the GAN framework mostly unaltered.

I've googled around and found papers with not-so-impressive results.
 
I'd like to know what's the current status of this problem and what people think could be possible ways forward.",14,5
1335,2017-11-27,2017,11,27,9,7fr0d7,Yet another classic example of the AI Hype by media.,https://www.reddit.com/r/MachineLearning/comments/7fr0d7/yet_another_classic_example_of_the_ai_hype_by/,sentient07,1511741463,,0,1
1336,2017-11-27,2017,11,27,9,7fr2wc,Is there a general purpose method or cloud service that allows CUDA applications utilize Amazon/Google gpus?,https://www.reddit.com/r/MachineLearning/comments/7fr2wc/is_there_a_general_purpose_method_or_cloud/,dig9900,1511742084,[removed],0,1
1337,2017-11-27,2017,11,27,10,7frn6a,StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation,https://www.reddit.com/r/MachineLearning/comments/7frn6a/stargan_unified_generative_adversarial_networks/,[deleted],1511747472,[deleted],0,1
1338,2017-11-27,2017,11,27,10,7frnc8,[R] StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation,https://www.reddit.com/r/MachineLearning/comments/7frnc8/r_stargan_unified_generative_adversarial_networks/,[deleted],1511747516,[deleted],1,1
1339,2017-11-27,2017,11,27,10,7fro3g,[R] StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation,https://www.reddit.com/r/MachineLearning/comments/7fro3g/r_stargan_unified_generative_adversarial_networks/,yunjey,1511747730,,95,874
1340,2017-11-27,2017,11,27,11,7frw11,Automatic Noodle Maker Machine Manufacturer in China,https://www.reddit.com/r/MachineLearning/comments/7frw11/automatic_noodle_maker_machine_manufacturer_in/,liusherry,1511749914,[removed],1,1
1341,2017-11-27,2017,11,27,11,7frxls,[D] Multiple sequence prediction (LSTM),https://www.reddit.com/r/MachineLearning/comments/7frxls/d_multiple_sequence_prediction_lstm/,timeseries9238492938,1511750356,"If you had weather measurement (humidity, temperature, wind) etc from several cities, how could you use all this weather data together, to predict the next temperature value in each city?

There are already several tutorials on the internet on how to do this for one city, but what if you wanted to predict temperature for several cities and you wanted to us the additional weather measurements for each city as features to inform the temperature prediction?

I have seen two possible suggestions using neural networks and LSTM.

1. concatenate all the city data side by side (https://github.com/fchollet/keras/issues/385#issuecomment-122595789)
2. feed the sequences from each city into the network one at a time (http://philipperemy.github.io/keras-stateful-lstm/ under the heading of ""Mastering stateful models"")

Of course this assumes that you can learn about the weather in one city using knowledge from a different city.

I'm not only looking for LSTM ideas, I'm open to any, but I am learning to LSTM with Keras.

Edit: I think this problem is similar to this person for predicting multiple stores https://stackoverflow.com/questions/42585356/how-to-construct-input-data-to-lstm-for-time-series-multi-step-horizon-with-exte ",10,9
1342,2017-11-27,2017,11,27,11,7fs10p,Peanut Butter Production Line Process Picture,https://www.reddit.com/r/MachineLearning/comments/7fs10p/peanut_butter_production_line_process_picture/,gelgoogcara,1511751326,,0,1
1343,2017-11-27,2017,11,27,12,7fs2t6,Semi-automatic 3d Packing Machine for Sale,https://www.reddit.com/r/MachineLearning/comments/7fs2t6/semiautomatic_3d_packing_machine_for_sale/,liusherry,1511751846,[removed],1,1
1344,2017-11-27,2017,11,27,13,7fseru,"Recommend me a setup for research at $3,000",https://www.reddit.com/r/MachineLearning/comments/7fseru/recommend_me_a_setup_for_research_at_3000/,rodrigo-silveira,1511755232,[removed],0,1
1345,2017-11-27,2017,11,27,15,7ft9x0,Question about how neural networks can be used for learning in games,https://www.reddit.com/r/MachineLearning/comments/7ft9x0/question_about_how_neural_networks_can_be_used/,TheWeebles,1511765031,[removed],0,1
1346,2017-11-27,2017,11,27,15,7ftarf,Autodiff library in ~50 lines of code,https://www.reddit.com/r/MachineLearning/comments/7ftarf/autodiff_library_in_50_lines_of_code/,[deleted],1511765326,[deleted],0,1
1347,2017-11-27,2017,11,27,16,7ftd8j,III. Mekanik Tesisat Gnleri Kbrs da gerekletirildi,https://www.reddit.com/r/MachineLearning/comments/7ftd8j/iii_mekanik_tesisat_gnleri_kbrs_da/,MekanikTesisat,1511766227,,0,1
1348,2017-11-27,2017,11,27,16,7ftdkc,[P] Autodiff library in ~50 lines of code,https://www.reddit.com/r/MachineLearning/comments/7ftdkc/p_autodiff_library_in_50_lines_of_code/,[deleted],1511766343,[deleted],1,0
1349,2017-11-27,2017,11,27,16,7ftk31,Spatial invariance of CNN - question,https://www.reddit.com/r/MachineLearning/comments/7ftk31/spatial_invariance_of_cnn_question/,spasserkongen,1511768669,[removed],1,1
1350,2017-11-27,2017,11,27,17,7ftrio,verification and validation in software testing,https://www.reddit.com/r/MachineLearning/comments/7ftrio/verification_and_validation_in_software_testing/,HammadMaqbool,1511771462,,0,1
1351,2017-11-27,2017,11,27,17,7ftse1,Round Stick Making Machine|Shovel Hoe Handle Making Machine Working Video,https://www.reddit.com/r/MachineLearning/comments/7ftse1/round_stick_making_machineshovel_hoe_handle/,tinawangsnow,1511771803,,0,1
1352,2017-11-27,2017,11,27,18,7ftxow,[D] elon musk posted fearmongering/overhype AI tweets again () ; how can we keep him from spouting fake news that tricks general public (&amp; eventually policy makers)?,https://www.reddit.com/r/MachineLearning/comments/7ftxow/d_elon_musk_posted_fearmongeringoverhype_ai/,evc123,1511773815,"He just posted this fearmongering tweet about Boston Dynamics robot backflip:
https://twitter.com/elonmusk/status/934888089058549760

He used that tweet to try to justify a followup tweet saying regulation is needed: https://twitter.com/elonmusk/status/934889932807593984

I partially agree that regulation should be thought about, but he's just making matters worse by stretching_the_truth / overhyping_nearterm_capabilities like he does in previous Boston Dynamics robot tweet.

OpenAI seems to have not educated/rectified him that much,
so how can we keep him from stretching_the_truth &amp; (inadvertently?) tricking the general public (&amp; eventually policy makers) so often? (This isn't the first time; he did it right after dota 2 1v1 openai match too: https://www.reddit.com/r/MachineLearning/comments/6t58ks/n_openai_bot_beat_best_dota_2_players_in_1v1_at/dli7hjd/ )

Here's some context on limitations his tweets ignore:
 https://twitter.com/dennybritz/status/934665343162814464                                       
 http://www.wildml.com/2017/08/hype-or-not-some-perspective-on-openais-dota-2-bot/",20,0
1353,2017-11-27,2017,11,27,18,7fu358,How to model when to do something given an event.,https://www.reddit.com/r/MachineLearning/comments/7fu358/how_to_model_when_to_do_something_given_an_event/,sc2urquan,1511775868,[removed],0,1
1354,2017-11-27,2017,11,27,19,7fu8mi,Has there been much interesting research in the last few years with regard to contextual music information retrieval and recommendation?,https://www.reddit.com/r/MachineLearning/comments/7fu8mi/has_there_been_much_interesting_research_in_the/,daithibowzy,1511777937,[removed],1,1
1355,2017-11-27,2017,11,27,19,7fu8qg,"[R] Dataset with audio of voice and labeled ""important"" sections",https://www.reddit.com/r/MachineLearning/comments/7fu8qg/r_dataset_with_audio_of_voice_and_labeled/,Seiteshyru,1511777968,"Hello,  
I'm currently on the search for thesis topics and find the idea of extracting ""relevant"" parts of an audio signal of human speech intriguing. I already did my research, but did not find any dataset that could be (ab)used for such work. Did I miss something ?",3,0
1356,2017-11-27,2017,11,27,19,7fuaz6,[D] Deep Learning on embedded devices.,https://www.reddit.com/r/MachineLearning/comments/7fuaz6/d_deep_learning_on_embedded_devices/,Sdkdkk,1511778774,"I am looking into implementing the Inception v3 model on an embedded device for image classification. By searching around I can see a lot of discussions about whether this is even possible and a lot of companies selling chips targeted deep leaning/machine learning algorithms.

However, I fail to understand what the problem actually is? Of course it requires a lot of computations to trains the network, but you can do that on elsewhere, and just install the model on the device. After that a single classification is (in my experience) quite fast. If I'm okay with a single classification taking a few seconds - and not a tiny fraction of a second - then is there an issue at all?

Then there is the model size. Of course the device needs to have enough memory to contain the model, but memory is not that expensive.

Can someone help me understand if there is a problem here, or if the reason I'm not finding any specifics is that there really is not problem.

My use case is a simple camera which triggers by a manual/simple process and the classifies the image.

",6,2
1357,2017-11-27,2017,11,27,19,7fudbr,"We are humbled getting so many recognitions, 2 in the last as many days...comparing and listing us with the best-",https://www.reddit.com/r/MachineLearning/comments/7fudbr/we_are_humbled_getting_so_many_recognitions_2_in/,getengati,1511779655,[removed],0,1
1358,2017-11-27,2017,11,27,20,7fufbl,Music tastes - question,https://www.reddit.com/r/MachineLearning/comments/7fufbl/music_tastes_question/,maciekmaciek,1511780428,[removed],0,1
1359,2017-11-27,2017,11,27,20,7fuj28,[N]Artificial Intelligence: Heres all it can do with Machine Learning and Deep Learning,https://www.reddit.com/r/MachineLearning/comments/7fuj28/nartificial_intelligence_heres_all_it_can_do_with/,friscotime,1511781809,,0,1
1360,2017-11-27,2017,11,27,21,7fuvtj,Stainless Steel Almond Slice Cutting Machine Manufacturer Supplier,https://www.reddit.com/r/MachineLearning/comments/7fuvtj/stainless_steel_almond_slice_cutting_machine/,gelgoogcara,1511786245,,1,1
1361,2017-11-27,2017,11,27,21,7fuyyi,Is there a database for intelligent semaphores?,https://www.reddit.com/r/MachineLearning/comments/7fuyyi/is_there_a_database_for_intelligent_semaphores/,pmkiller,1511787268,[removed],0,1
1362,2017-11-27,2017,11,27,22,7fv7f3,[P] Finding Magic: The Gathering archetypes with Latent Dirichlet Allocation,https://www.reddit.com/r/MachineLearning/comments/7fv7f3/p_finding_magic_the_gathering_archetypes_with/,hlynurd,1511789829,,6,12
1363,2017-11-27,2017,11,27,22,7fv7pl,Population based training of neural networks,https://www.reddit.com/r/MachineLearning/comments/7fv7pl/population_based_training_of_neural_networks/,Tenoke,1511789908,,2,4
1364,2017-11-27,2017,11,27,23,7fvhpm,New dataset generated on running the jupyter notebook every time.,https://www.reddit.com/r/MachineLearning/comments/7fvhpm/new_dataset_generated_on_running_the_jupyter/,Anirudh25,1511792684,[removed],0,1
1365,2017-11-27,2017,11,27,23,7fvnbr,[D] What are the openly available courses/videos on online learning,https://www.reddit.com/r/MachineLearning/comments/7fvnbr/d_what_are_the_openly_available_coursesvideos_on/,buy_some_wow,1511794186,"I doubt there will be a MOOC on the topic (great if there is one!). What I'm looking for is something like [6.883: Online Methods in Machine Learning](http://www.mit.edu/~rakhlin/6.883/) (unfortunately course videos are not openly available). 

What are the available openly accessible course materials that you know on online learning?

Thanks",6,0
1366,2017-11-27,2017,11,27,23,7fvoey,[N]How (and Why) to Create a Good Validation Set,https://www.reddit.com/r/MachineLearning/comments/7fvoey/nhow_and_why_to_create_a_good_validation_set/,jackblun,1511794480,,0,1
1367,2017-11-28,2017,11,28,0,7fvrlq,[N] Amazon Launches ML Solutions Lab - Connecting Amazon ML Engineers With AWS Customers,https://www.reddit.com/r/MachineLearning/comments/7fvrlq/n_amazon_launches_ml_solutions_lab_connecting/,distant_gradient,1511795288,,6,10
1368,2017-11-28,2017,11,28,0,7fvvjn,How to build a classifier,https://www.reddit.com/r/MachineLearning/comments/7fvvjn/how_to_build_a_classifier/,starwars88,1511796248,[removed],0,1
1369,2017-11-28,2017,11,28,0,7fvw09,[R] [1711.08646] IVE-GAN: Invariant Encoding Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/7fvw09/r_171108646_ivegan_invariant_encoding_generative/,retniwr,1511796366,,12,12
1370,2017-11-28,2017,11,28,0,7fvwjn,"Humanoid Robots, AI Politicians, and More: Nine Insightful Articles on Analytics, ML and AI from Nov 2017",https://www.reddit.com/r/MachineLearning/comments/7fvwjn/humanoid_robots_ai_politicians_and_more_nine/,techdataetc,1511796492,,0,1
1371,2017-11-28,2017,11,28,0,7fvyhf,Population based training of neural networks,https://www.reddit.com/r/MachineLearning/comments/7fvyhf/population_based_training_of_neural_networks/,[deleted],1511796949,[deleted],0,1
1372,2017-11-28,2017,11,28,0,7fvyu3,Measuring quality of OCR without ground truth.,https://www.reddit.com/r/MachineLearning/comments/7fvyu3/measuring_quality_of_ocr_without_ground_truth/,Altamistral,1511797035,[removed],0,1
1373,2017-11-28,2017,11,28,0,7fw1lh,ICLR Workshop Track claims to be looking for 3 page abstracts...,https://www.reddit.com/r/MachineLearning/comments/7fw1lh/iclr_workshop_track_claims_to_be_looking_for_3/,torvoraptor,1511797694,[removed],0,1
1374,2017-11-28,2017,11,28,0,7fw2zi,Deepo2: now allows you to customize your own deep learning environment with Lego-like modules.,https://www.reddit.com/r/MachineLearning/comments/7fw2zi/deepo2_now_allows_you_to_customize_your_own_deep/,[deleted],1511798037,[deleted],0,1
1375,2017-11-28,2017,11,28,0,7fw3j6,Moving Shapes dataset,https://www.reddit.com/r/MachineLearning/comments/7fw3j6/moving_shapes_dataset/,I_am_a_robot_,1511798177,[removed],0,1
1376,2017-11-28,2017,11,28,0,7fw3x8,[P] Deepo2: now allows you to customize your own deep learning environment with Lego-like modules.,https://www.reddit.com/r/MachineLearning/comments/7fw3x8/p_deepo2_now_allows_you_to_customize_your_own/,[deleted],1511798267,[deleted],0,0
1377,2017-11-28,2017,11,28,1,7fwhb0,Seeking advice for applying to graduate schools for math after working in the industry,https://www.reddit.com/r/MachineLearning/comments/7fwhb0/seeking_advice_for_applying_to_graduate_schools/,Coneylake,1511801312,[removed],0,1
1378,2017-11-28,2017,11,28,2,7fwmln,How many citations does a good ML paper get?,https://www.reddit.com/r/MachineLearning/comments/7fwmln/how_many_citations_does_a_good_ml_paper_get/,rasen58,1511802495,[removed],0,1
1379,2017-11-28,2017,11,28,2,7fwnpb,Interpretable DL Models &amp; Relations to Neuroscience,https://www.reddit.com/r/MachineLearning/comments/7fwnpb/interpretable_dl_models_relations_to_neuroscience/,rtk25,1511802726,[removed],0,1
1380,2017-11-28,2017,11,28,2,7fwomv,Personalized Medicine: Redefining Cancer Treatment with Deep Learning,https://www.reddit.com/r/MachineLearning/comments/7fwomv/personalized_medicine_redefining_cancer_treatment/,jorgemf,1511802924,,0,1
1381,2017-11-28,2017,11,28,2,7fwq7a,[P] download and preprocess VOC dataset with 1 line of code.,https://www.reddit.com/r/MachineLearning/comments/7fwq7a/p_download_and_preprocess_voc_dataset_with_1_line/,zsdh123,1511803265,,0,0
1382,2017-11-28,2017,11,28,2,7fwqsb,[P] Deformable Convolution in TensorFlow/ TensorLayer,https://www.reddit.com/r/MachineLearning/comments/7fwqsb/p_deformable_convolution_in_tensorflow_tensorlayer/,zsdh123,1511803387,,0,0
1383,2017-11-28,2017,11,28,2,7fwr49,[P] Many Data Augmentation APIs for Object Detection,https://www.reddit.com/r/MachineLearning/comments/7fwr49/p_many_data_augmentation_apis_for_object_detection/,zsdh123,1511803456,,0,0
1384,2017-11-28,2017,11,28,3,7fx4vf,ETH and EPFL Master's in Computer Science with a focus on Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7fx4vf/eth_and_epfl_masters_in_computer_science_with_a/,supreethn,1511806437,[removed],0,1
1385,2017-11-28,2017,11,28,3,7fx70t,[P] Distributed TensorFlow: A Gentle Introduction,https://www.reddit.com/r/MachineLearning/comments/7fx70t/p_distributed_tensorflow_a_gentle_introduction/,mrahtz,1511806886,,4,26
1386,2017-11-28,2017,11,28,3,7fxcn9,[D] The impossibility of intelligence explosion,https://www.reddit.com/r/MachineLearning/comments/7fxcn9/d_the_impossibility_of_intelligence_explosion/,Reiinakano,1511808121,,48,0
1387,2017-11-28,2017,11,28,3,7fxcui,New leadership for MIT-IBM Watson AI Lab,https://www.reddit.com/r/MachineLearning/comments/7fxcui/new_leadership_for_mitibm_watson_ai_lab/,TroubledClassifier,1511808162,[removed],0,1
1388,2017-11-28,2017,11,28,4,7fxm1k,Improving TripAdvisor Photo Selection With Deep Learning,https://www.reddit.com/r/MachineLearning/comments/7fxm1k/improving_tripadvisor_photo_selection_with_deep/,gregamis,1511810147,,0,2
1389,2017-11-28,2017,11,28,4,7fxnaz,Sequence Modeling with CTC,https://www.reddit.com/r/MachineLearning/comments/7fxnaz/sequence_modeling_with_ctc/,gwern,1511810417,,0,2
1390,2017-11-28,2017,11,28,4,7fxrcx,A non-technerd guide to machine learning,https://www.reddit.com/r/MachineLearning/comments/7fxrcx/a_nontechnerd_guide_to_machine_learning/,marcweiz,1511811290,,0,1
1391,2017-11-28,2017,11,28,4,7fxy3x,Flare: Clojure Dynamic Neural Net Library,https://www.reddit.com/r/MachineLearning/comments/7fxy3x/flare_clojure_dynamic_neural_net_library/,aria4242,1511812736,,0,2
1392,2017-11-28,2017,11,28,4,7fxyeg,Machine Learning in simple words: Azure Machine Learning part I,https://www.reddit.com/r/MachineLearning/comments/7fxyeg/machine_learning_in_simple_words_azure_machine/,NeelBhatt,1511812798,,0,1
1393,2017-11-28,2017,11,28,5,7fy8zb,How to sample expensive function for a balanced dataset?,https://www.reddit.com/r/MachineLearning/comments/7fy8zb/how_to_sample_expensive_function_for_a_balanced/,vineavip,1511815101,[removed],0,1
1394,2017-11-28,2017,11,28,5,7fyc4l,[R] On the Impossibility of Supersized Machines,https://www.reddit.com/r/MachineLearning/comments/7fyc4l/r_on_the_impossibility_of_supersized_machines/,stochastic_gradient,1511815801,,10,0
1395,2017-11-28,2017,11,28,6,7fyh3j,Building a Palindrome Checker in Python!,https://www.reddit.com/r/MachineLearning/comments/7fyh3j/building_a_palindrome_checker_in_python/,LeoDrysdale,1511816888,,0,1
1396,2017-11-28,2017,11,28,6,7fyks7,[D] Multiplicative Gaussian Noise for Robust Decision Boundaries?,https://www.reddit.com/r/MachineLearning/comments/7fyks7/d_multiplicative_gaussian_noise_for_robust/,ElderFalcon,1511817686,"I'm working on making a network more robust in its classification given limited data, and am exploring network augmentation techniques to do so. Do you think multiplying network activations with noise from a tight gaussian distribution would help push away that decision boundary, or would it cause more trouble? For stability, I am using BatchNorm.",6,1
1397,2017-11-28,2017,11,28,7,7fywk1,[R] Sequence Modeling With Connectionist Temporal Classication,https://www.reddit.com/r/MachineLearning/comments/7fywk1/r_sequence_modeling_with_connectionist_temporal/,programmerChilli,1511820215,,13,102
1398,2017-11-28,2017,11,28,7,7fz3dv,[D] ICLR Reviews,https://www.reddit.com/r/MachineLearning/comments/7fz3dv/d_iclr_reviews/,anonDogeLover,1511821728,"Are ICLR reviews being released today?

Edit: the answer appears to be no, a few more days are needed.",12,9
1399,2017-11-28,2017,11,28,8,7fzmeo,"[R] Binary Logical Networks, a fundamentally different approach to backpropagation (Work in Progress, essential code available)",https://www.reddit.com/r/MachineLearning/comments/7fzmeo/r_binary_logical_networks_a_fundamentally/,Sanakazubi,1511826218,,17,2
1400,2017-11-28,2017,11,28,8,7fzp6z,The beginning of boosting? - Trying to make a reliable computer out of unreliable parts (31/200),https://www.reddit.com/r/MachineLearning/comments/7fzp6z/the_beginning_of_boosting_trying_to_make_a/,duckandcover,1511826890,,0,1
1401,2017-11-28,2017,11,28,9,7fzs0w,Beginner Deep Learning PC build advice,https://www.reddit.com/r/MachineLearning/comments/7fzs0w/beginner_deep_learning_pc_build_advice/,iGushers,1511827591,[removed],0,1
1402,2017-11-28,2017,11,28,9,7fzzn0,What do you guys do at work during training times?,https://www.reddit.com/r/MachineLearning/comments/7fzzn0/what_do_you_guys_do_at_work_during_training_times/,HummusAdorer,1511829423,[removed],0,1
1403,2017-11-28,2017,11,28,9,7g04dp,Can the weights of a neural network be a more efficient way to transmit data?,https://www.reddit.com/r/MachineLearning/comments/7g04dp/can_the_weights_of_a_neural_network_be_a_more/,Necromunger,1511830640,[removed],0,1
1404,2017-11-28,2017,11,28,10,7g0dsk,[D] Loss functions for multi-axis classifiers,https://www.reddit.com/r/MachineLearning/comments/7g0dsk/d_loss_functions_for_multiaxis_classifiers/,quick_dudley,1511832994,"I'm trying to train a neural network with two outputs as something like a 4 way classifier: the classification made by each output is orthogonal to the one made by the other but there are common features which could be used by both. I've tried a few different approaches and am wondering whether or not anyone on Reddit has any relevant wisdom.

Approaches tried:

1. Linear loss: applied to each output independently. The network rapidly learned the correct function for one of the outputs but never learned the other.

2. Linear loss v2: loss for the ""easier"" output multiplied by the accuracy of the ""harder"" one. The ""harder"" function eventually converged; the ""easier"" one plateaued on the training data and never did any better than an untrained network on the validation data.

3. Linear loss v3: zeroing whichever error has the smaller magnitude for that epoch. I'm still running this one: will report back with how it goes.",9,0
1405,2017-11-28,2017,11,28,10,7g0grt,Commercial Almond Peanut Strip Cutting Machine Manufacturer In China,https://www.reddit.com/r/MachineLearning/comments/7g0grt/commercial_almond_peanut_strip_cutting_machine/,gelgoogcara,1511833767,,2,1
1406,2017-11-28,2017,11,28,11,7g0kyr,Automatic Pillow Type Packing Machine,https://www.reddit.com/r/MachineLearning/comments/7g0kyr/automatic_pillow_type_packing_machine/,liusherry,1511834831,[removed],1,1
1407,2017-11-28,2017,11,28,11,7g0liu,[R] Population based training of neural networks | DeepMind,https://www.reddit.com/r/MachineLearning/comments/7g0liu/r_population_based_training_of_neural_networks/,Pfohlol,1511834966,,45,91
1408,2017-11-28,2017,11,28,11,7g0qet,Fresh Pasta Vietnamese Noodle Making Machine Automatic For Soap Noodle,https://www.reddit.com/r/MachineLearning/comments/7g0qet/fresh_pasta_vietnamese_noodle_making_machine/,liusherry,1511836219,[removed],1,1
1409,2017-11-28,2017,11,28,11,7g0r6h,Survey for students and professionals on what skills make a successful data scientist in today's job market,https://www.reddit.com/r/MachineLearning/comments/7g0r6h/survey_for_students_and_professionals_on_what/,luccaman94,1511836407,,0,1
1410,2017-11-28,2017,11,28,11,7g0va9,[R] CondenseNet: An Efficient DenseNet using Learned Group Convolutions,https://www.reddit.com/r/MachineLearning/comments/7g0va9/r_condensenet_an_efficient_densenet_using_learned/,xternalz,1511837468,,0,40
1411,2017-11-28,2017,11,28,11,7g0wyj,"Hi folks, we are on Product Hunt today with our ML-driven recruitment productivity Chrome extension. Would really appreciate if you could support us. Thanks so much! ",https://www.reddit.com/r/MachineLearning/comments/7g0wyj/hi_folks_we_are_on_product_hunt_today_with_our/,anshumanbaruah1,1511837885,[removed],0,1
1412,2017-11-28,2017,11,28,12,7g0z4e,[D] Population based training of neural networks by DeepMind,https://www.reddit.com/r/MachineLearning/comments/7g0z4e/d_population_based_training_of_neural_networks_by/,[deleted],1511838426,[deleted],1,1
1413,2017-11-28,2017,11,28,13,7g1nrn,Used Injection Molding Machines - Premier Plastics Systems,https://www.reddit.com/r/MachineLearning/comments/7g1nrn/used_injection_molding_machines_premier_plastics/,michaelverrett21,1511845098,,0,1
1414,2017-11-28,2017,11,28,14,7g1qnv,Translating English to Yoda English using Sequence-to-Sequence with Tensorflow.,https://www.reddit.com/r/MachineLearning/comments/7g1qnv/translating_english_to_yoda_english_using/,ukrdailo,1511845924,,0,1
1415,2017-11-28,2017,11,28,14,7g1qoo,How Reuters's Revolutionary AI System Gathers Global News,https://www.reddit.com/r/MachineLearning/comments/7g1qoo/how_reuterss_revolutionary_ai_system_gathers/,fungussa,1511845931,,1,1
1416,2017-11-28,2017,11,28,15,7g22uz,[R] Distilling a Neural Network Into a Soft Decision Tree,https://www.reddit.com/r/MachineLearning/comments/7g22uz/r_distilling_a_neural_network_into_a_soft/,visarga,1511849471,,33,110
1417,2017-11-28,2017,11,28,15,7g2492,[D] The non-techies guide to machine learning,https://www.reddit.com/r/MachineLearning/comments/7g2492/d_the_nontechies_guide_to_machine_learning/,ckannan90,1511849900,,0,2
1418,2017-11-28,2017,11,28,15,7g29f6,Masking tasks in multitask learners leads to learning rate imbalances,https://www.reddit.com/r/MachineLearning/comments/7g29f6/masking_tasks_in_multitask_learners_leads_to/,pooohlman,1511851607,[removed],0,1
1419,2017-11-28,2017,11,28,16,7g2jrc,"Building a classifier, need advice.",https://www.reddit.com/r/MachineLearning/comments/7g2jrc/building_a_classifier_need_advice/,wearefarming101,1511855178,[removed],0,1
1420,2017-11-28,2017,11,28,17,7g2t0c,What algorithm (machine learning) do you use for solving this problem: input(text written by human) -&gt; code,https://www.reddit.com/r/MachineLearning/comments/7g2t0c/what_algorithm_machine_learning_do_you_use_for/,mhadjis,1511858692,[removed],0,1
1421,2017-11-28,2017,11,28,18,7g2vkc,best language to implement Machine learning algorithm?,https://www.reddit.com/r/MachineLearning/comments/7g2vkc/best_language_to_implement_machine_learning/,mks26,1511859685,[removed],0,1
1422,2017-11-28,2017,11,28,18,7g34f3,Looking for a co-author to write a GAN book,https://www.reddit.com/r/MachineLearning/comments/7g34f3/looking_for_a_coauthor_to_write_a_gan_book/,[deleted],1511863136,,0,1
1423,2017-11-28,2017,11,28,20,7g3m47,[P] Looking for a co-author to write a GAN book,https://www.reddit.com/r/MachineLearning/comments/7g3m47/p_looking_for_a_coauthor_to_write_a_gan_book/,jjbelt,1511869746,"Hey, I am currently a student and saw that there is not much literature on GANs. Is anybody here interested in writing a simple e-book about it? Just DM me.",4,1
1424,2017-11-28,2017,11,28,21,7g3oj2,[N]Amazon Web Services unveils new program to fund machine learning research,https://www.reddit.com/r/MachineLearning/comments/7g3oj2/namazon_web_services_unveils_new_program_to_fund/,chris_shpak,1511870557,,0,1
1425,2017-11-28,2017,11,28,21,7g3r22,[N]Hey Siri: An On-device DNN-powered Voice Trigger for Apples Personal Assistant - Apple,https://www.reddit.com/r/MachineLearning/comments/7g3r22/nhey_siri_an_ondevice_dnnpowered_voice_trigger/,digitalson,1511871421,,0,1
1426,2017-11-28,2017,11,28,22,7g3z46,Q-Learning: Tabular vs NN Update,https://www.reddit.com/r/MachineLearning/comments/7g3z46/qlearning_tabular_vs_nn_update/,schnecki004,1511874079,[removed],0,1
1427,2017-11-28,2017,11,28,22,7g3zhu,Benchmarking Relief-Based Feature Selection Methods: Preprint showing that Relief-based feature selection methods outperform many commonly-used feature selection methods. Code in the comments.,https://www.reddit.com/r/MachineLearning/comments/7g3zhu/benchmarking_reliefbased_feature_selection/,rhiever,1511874185,,1,1
1428,2017-11-28,2017,11,28,22,7g40gk,Data Science Specialization with 10 courses (7-Day free trial),https://www.reddit.com/r/MachineLearning/comments/7g40gk/data_science_specialization_with_10_courses_7day/,dekhoworld,1511874490,,0,1
1429,2017-11-28,2017,11,28,22,7g434f,[D] Pros and Cons between Malmo and DeepMind Lab ?,https://www.reddit.com/r/MachineLearning/comments/7g434f/d_pros_and_cons_between_malmo_and_deepmind_lab/,metaAI,1511875293,[removed],3,1
1430,2017-11-28,2017,11,28,22,7g44u1,Cross Entropy Cost used in MLE (usually) does not have a minimum value. Why?,https://www.reddit.com/r/MachineLearning/comments/7g44u1/cross_entropy_cost_used_in_mle_usually_does_not/,ambodi,1511875825,[removed],0,1
1431,2017-11-28,2017,11,28,22,7g47kp,[N]Jensen Huang Announces NVIDIA's New Projects at the GPU Technology Conference,https://www.reddit.com/r/MachineLearning/comments/7g47kp/njensen_huang_announces_nvidias_new_projects_at/,magneticono,1511876592,,0,1
1432,2017-11-28,2017,11,28,22,7g48wf,[R] Extracting Automata from Recurrent Neural Networks Using Queries and Counterexamples,https://www.reddit.com/r/MachineLearning/comments/7g48wf/r_extracting_automata_from_recurrent_neural/,visarga,1511876931,,12,61
1433,2017-11-28,2017,11,28,22,7g4azd,Social Media Image Recommender Using machine learning,https://www.reddit.com/r/MachineLearning/comments/7g4azd/social_media_image_recommender_using_machine/,rbagdiya,1511877496,,0,1
1434,2017-11-28,2017,11,28,23,7g4m70,Need help with project ideas,https://www.reddit.com/r/MachineLearning/comments/7g4m70/need_help_with_project_ideas/,sarthaks97,1511880439,[removed],0,1
1435,2017-11-29,2017,11,29,0,7g51iy,How do you deal with samples of variable lengths in a mini-batch?,https://www.reddit.com/r/MachineLearning/comments/7g51iy/how_do_you_deal_with_samples_of_variable_lengths/,longinglove,1511884199,[removed],0,1
1436,2017-11-29,2017,11,29,1,7g54ml,[1709.03582] Art of singular vectors and universal adversarial perturbations,https://www.reddit.com/r/MachineLearning/comments/7g54ml/170903582_art_of_singular_vectors_and_universal/,Mathemage,1511884930,,1,1
1437,2017-11-29,2017,11,29,1,7g5bnf,First look of Azure Machine Learning : Azure Machine Learning part II,https://www.reddit.com/r/MachineLearning/comments/7g5bnf/first_look_of_azure_machine_learning_azure/,NeelBhatt,1511886562,,0,1
1438,2017-11-29,2017,11,29,2,7g5ops,[R] Specifying AI safety problems in simple environments | DeepMind,https://www.reddit.com/r/MachineLearning/comments/7g5ops/r_specifying_ai_safety_problems_in_simple/,WhiteHalmos,1511889421,,0,6
1439,2017-11-29,2017,11,29,2,7g5pfm,Using distillation techniques to improve accuracy of low precision networks,https://www.reddit.com/r/MachineLearning/comments/7g5pfm/using_distillation_techniques_to_improve_accuracy/,mac_i,1511889571,,0,1
1440,2017-11-29,2017,11,29,2,7g5qcf,Machine Learning A-Z: Hands-On Python &amp; R In Data Science,https://www.reddit.com/r/MachineLearning/comments/7g5qcf/machine_learning_az_handson_python_r_in_data/,Joymarty,1511889781,,0,1
1441,2017-11-29,2017,11,29,2,7g5u0x,[P] Mixture Density Networks,https://www.reddit.com/r/MachineLearning/comments/7g5u0x/p_mixture_density_networks/,dusenberrymw,1511890581,,0,13
1442,2017-11-29,2017,11,29,2,7g5z3x,[R] DeepMind Pycolab: A highly-customisable gridworld game engine,https://www.reddit.com/r/MachineLearning/comments/7g5z3x/r_deepmind_pycolab_a_highlycustomisable_gridworld/,metaAI,1511891671,,8,39
1443,2017-11-29,2017,11,29,3,7g6acs,Dress code at NIPS?,https://www.reddit.com/r/MachineLearning/comments/7g6acs/dress_code_at_nips/,[deleted],1511894075,,0,1
1444,2017-11-29,2017,11,29,4,7g6hsp,"[N] CNTK 2.3: Better ONNX, NCCL2, Improved C# API, Network Optimization API (SVD, quantization), etc.",https://www.reddit.com/r/MachineLearning/comments/7g6hsp/n_cntk_23_better_onnx_nccl2_improved_c_api/,justnikos,1511895652,,3,21
1445,2017-11-29,2017,11,29,4,7g6itt,"Internet Of Things , Machine Learning And Robotics Prime Concern for developers",https://www.reddit.com/r/MachineLearning/comments/7g6itt/internet_of_things_machine_learning_and_robotics/,[deleted],1511895868,[deleted],0,1
1446,2017-11-29,2017,11,29,4,7g6mgb,"Internet Of Things , Machine Learning And Robotics Prime Concern for developers",https://www.reddit.com/r/MachineLearning/comments/7g6mgb/internet_of_things_machine_learning_and_robotics/,Marry_owen,1511896637,,0,1
1447,2017-11-29,2017,11,29,4,7g6oe7,How data science is being used in energy and utilities ?,https://www.reddit.com/r/MachineLearning/comments/7g6oe7/how_data_science_is_being_used_in_energy_and/,amoun1365,1511897044,[removed],0,1
1448,2017-11-29,2017,11,29,4,7g6rtw,Machine Learning: What it is and why it matters,https://www.reddit.com/r/MachineLearning/comments/7g6rtw/machine_learning_what_it_is_and_why_it_matters/,Marry_owen,1511897783,,0,1
1449,2017-11-29,2017,11,29,5,7g7255,[D] Dress code at NIPS?,https://www.reddit.com/r/MachineLearning/comments/7g7255/d_dress_code_at_nips/,Flipper3,1511900016,"I am attending NIPS next week and this is my first time ever attending this conference (or any top-tier ML conference).  I have been to a lot of medical, visualization, and lower tier ML conferences.  I have a couple of questions:

1. At many of the medical and other conferences, you see most people in business casual (dress shirt with tie) or even with full suits.  From what I understand, NIPS is nowhere near this case (which sounds awesome). What should I expect?  Khakis with a casual button down?  Or just jeans with a t-shirt?  What about if speaking to companies at booths?

2. Piggy backing on the last part of the first question, I have seen that there will be a lot of companies at NIPS.  As somebody finishing my PhD next year, what is the best course for exploratory talks with companies?  And similar to the first question: are any of these conversations like a normal interview where proper dress code is expected?

I am excited to attend NIPS for the first time, and as is probably evidentI am trying to break away from the strict dress code expected at some other conferences.

(Reposted with Discussion tag.)",39,38
1450,2017-11-29,2017,11,29,5,7g757b,[D] Prejudices in ML systems,https://www.reddit.com/r/MachineLearning/comments/7g757b/d_prejudices_in_ml_systems/,GabrieleFariello,1511900654,"Hello Reddit ML!

&amp;nbsp;

I am gathering materials to update my course and one subject that intrigued my students and me was the significant risk of hidden (and undesirable) biases of current ML systems -- aka racisms, sexisms, and other prejudices.

&amp;nbsp;

There are a few media articles about the supposed emergent threat posed undesirable biases in machine learning systems, particularly more recent DL versions. A quick Google search for [""racist ai""](https://www.google.com/search?q=racist+ai) shows that there is no shortage of mainstream media chatter about the subject:

&amp;nbsp;

* [Twitter taught Microsofts AI chatbot to be a racist asshole in less than a day](https://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist)
* [Rise of the racist robots  how AI is learning all our worst impulses](https://www.theguardian.com/inequality/2017/aug/08/rise-of-the-racist-robots-how-ai-is-learning-all-our-worst-impulses)
* [Robots With Artificial Intelligence Become Racist and Sexist - Scientists think they've found a way to change their minds](http://www.newsweek.com/artificial-intelligence-scientists-racist-sexist-robots-ai-693440)
* [How to make a racist AI without really trying](https://blog.conceptnet.io/2017/07/13/how-to-make-a-racist-ai-without-really-trying/)
* [Artificial intelligence replicating the racial and gender prejudices of humans.](http://www.newsweek.com/artificial-intelligence-can-be-racist-sexist-just-humans-584240)

&amp;nbsp;

It certainly stands to reason that if, for example, we use retrospective data from previous analyst decisions on the issuance of credit (e.g., credit cards, mortgages, business loans) that the system would likely exhibit some of the same racial and sexist biases that were exhibited by the analysts (see Fuster 2017 below). Likewise, for systems to ""inform"" the criminal justice system in the US (see Kirkpatrick 2016, Rhodes 2013, or Burk 2012 below). I would like to put together some select readings on the subject matter with a strong preference for peer-reviewed articles for the graduate course I am teaching and would like to try my hand at getting recommendations from the Reddit ML community.

&amp;nbsp;

**Do you have recommended readings on the subject of prejudices/undesirable biases in ML systems?**

&amp;nbsp;

Below I have some scholar search articles that I have come across that address the issue directly or indirectly (in rough chronological order, not order of importance), but I am guessing that I am missing some that might be better. Note: some of the articles below (e.g., Galindo 2000) are more to show that ML has been used to make credit decisions for a while rather than to shed light on biases.

&amp;nbsp;

* [Danks, D., &amp; London, A. J. Algorithmic Bias in Autonomous Systems. (In Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI 2017) forthcoming)] (https://www.cmu.edu/dietrich/philosophy/docs/london/IJCAI17-AlgorithmicBias-Distrib.pdf)
* [Caliskan, A., Bryson, J. J., &amp; Narayanan, A. (2017). Semantics derived automatically from language corpora contain human-like biases. Science, 356(6334), 183-186.](http://science.sciencemag.org/content/356/6334/183)
* [Greenwald, A. G. (2017). An AI stereotype catcher. Science, 356(6334), 133-134.](http://science.sciencemag.org/content/356/6334/133)
* [Fuster, A., Goldsmith-Pinkham, P., Ramadorai, T., &amp; Walther, A. (2017). Predictably Unequal? The Effects of Machine Learning on Credit Markets (No. 12448). CEPR Discussion Papers.](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3072038)
* [Sirignano, J., Sadhwani, A., &amp; Giesecke, K. (2016). Deep learning for mortgage risk.](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2799443)
* [Garcia, M. (2016). Racist in the Machine The Disturbing Implications of Algorithmic Bias. World Policy Journal, 33(4), 111-117.](https://read.dukeupress.edu/world-policy-journal/article-abstract/33/4/111/30942/Racist-in-the-MachineThe-Disturbing-Implications)
* [Yampolskiy, R. V., &amp; Spellchecker, M. S. (2016). Artificial Intelligence Safety and Cybersecurity: a Timeline of AI Failures. arXiv preprint arXiv:1610.07997.](https://arxiv.org/abs/1610.07997)
* [Barocas, S., &amp; Selbst, A. D. (2016). Big data's disparate impact.](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2477899)
* [Kirkpatrick, K. (2016). Battling algorithmic bias: how do we ensure algorithms treat us fairly?. Communications of the ACM, 59(10), 16-17.](https://dl.acm.org/citation.cfm?id=2983270)
* [Bostrom, N., &amp; Yudkowsky, E. (2014). The ethics of artificial intelligence. The Cambridge handbook of artificial intelligence, 316-334.](https://pdfs.semanticscholar.org/b2a4/66efec8c259ae789f91f413f342e0588792d.pdf)
* [Rhodes, W. (2013). Machine learning approaches as a tool for effective offender risk prediction. Criminology &amp; Public Policy, 12(3), 507-510.](http://onlinelibrary.wiley.com/doi/10.1111/1745-9133.12060/full)
* [Arkin, R. C., Ulam, P., &amp; Wagner, A. R. (2012). Moral decision making in autonomous systems: Enforcement, moral emotions, dignity, trust, and deception. Proceedings of the IEEE, 100(3), 571-589.](http://ieeexplore.ieee.org/abstract/document/6099675/)* [Geman, S., Bienenstock, E., &amp; Doursat, R. (2008). Neural networks and the bias/variance dilemma. Neural Networks, 4(1).](http://www.mitpressjournals.org/doi/abs/10.1162/neco.1992.4.1.1)
* [Berk, R. (2012). Criminal justice forecasts of risk: A machine learning approach. Springer Science &amp; Business Media.](https://dl.acm.org/citation.cfm?id=2209774)
* [Pedreshi, D., Ruggieri, S., &amp; Turini, F. (2008, August). Discrimination-aware data mining. In Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining (pp. 560-568). ACM.](https://dl.acm.org/citation.cfm?id=1401959)
* [Galindo, J., &amp; Tamayo, P. (2000). Credit risk assessment using statistical and machine learning: basic methodology and risk modeling applications. Computational Economics, 15(1), 107-143.](https://link.springer.com/article/10.1023%2FA%3A1008699112516?LI=true)
",8,0
1451,2017-11-29,2017,11,29,6,7g7ia4,Using Apache Spark with TensorFlow on Google Cloud Platform,https://www.reddit.com/r/MachineLearning/comments/7g7ia4/using_apache_spark_with_tensorflow_on_google/,fhoffa,1511903405,,0,1
1452,2017-11-29,2017,11,29,6,7g7n8e,[N] Publicly available fMoW baseline code still in top 3 ($100k prize purse) -- ~1 month left,https://www.reddit.com/r/MachineLearning/comments/7g7n8e/n_publicly_available_fmow_baseline_code_still_in/,[deleted],1511904479,[deleted],1,0
1453,2017-11-29,2017,11,29,6,7g7ojm,"Practical Implementation of Bandit Algorithms, and what companies actually do it?",https://www.reddit.com/r/MachineLearning/comments/7g7ojm/practical_implementation_of_bandit_algorithms_and/,jintoku,1511904775,[removed],0,1
1454,2017-11-29,2017,11,29,6,7g7pxi,Parfit  hyper-parameter optimization with visualizations for Sklearn,https://www.reddit.com/r/MachineLearning/comments/7g7pxi/parfit_hyperparameter_optimization_with/,[deleted],1511905075,[deleted],0,1
1455,2017-11-29,2017,11,29,6,7g7q2l,[P] Parfit  hyper-parameter optimization with visualizations for Sklearn,https://www.reddit.com/r/MachineLearning/comments/7g7q2l/p_parfit_hyperparameter_optimization_with/,-N3Ter-,1511905105,,9,22
1456,2017-11-29,2017,11,29,6,7g7smz,[D] Seeking advice on dedicated PC build,https://www.reddit.com/r/MachineLearning/comments/7g7smz/d_seeking_advice_on_dedicated_pc_build/,iGushers,1511905682,"Hello all, 

I'm approaching the end of the Udacity Machine Learning Engineer Nanodegree and would like to continue to pursue Machine Learning! I find deep learning to be particularly interesting and would like to build a dedicated PC. I plan to mostly use it for deep learning but I'm not excluding other types of machine learning in the future. I've put together a build on pcpartpicker but I'm not sure if it's a bit overkill (or maybe underkill) for someone of my skill level. Any advice would be much appreciated!

[PCPartPicker part list](https://pcpartpicker.com/list/8CGC3F) / [Price breakdown by merchant](https://pcpartpicker.com/list/8CGC3F/by_merchant/)

Type|Item|Price
:----|:----|:----
**CPU** | [AMD - Threadripper 1900X 3.8GHz 8-Core Processor](https://pcpartpicker.com/product/BvgPxr/amd-threadripper-1900x-38ghz-8-core-processor-yd190xa8aewof) | $399.99 @ Amazon 
**CPU Cooler** | [Noctua - NH-U9 TR4-SP3 78.9 CFM CPU Cooler](https://pcpartpicker.com/product/LY38TW/noctua-nh-u9-tr4-sp3-789-cfm-cpu-cooler-nh-u9-tr4-sp3) | $69.90 @ Amazon 
**Thermal Compound** | [Arctic Silver - 5 High-Density Polysynthetic Silver 3.5g Thermal Paste](https://pcpartpicker.com/product/6RrG3C/arctic-silver-thermal-paste-as535g) | $5.55 @ OutletPC 
**Motherboard** | [MSI - X399 GAMING PRO CARBON AC ATX TR4 Motherboard](https://pcpartpicker.com/product/Wfqbt6/msi-x399-gaming-pro-carbon-ac-atx-tr4-motherboard-x399-gaming-pro-carbon-ac) | $340.98 @ Newegg 
**Memory** | [G.Skill - Ripjaws V Series 32GB (2 x 16GB) DDR4-2133 Memory](https://pcpartpicker.com/product/zMvZxr/gskill-memory-f42133c15d32gvr) | $269.99 @ Newegg 
**Storage** | [Samsung - 850 EVO-Series 500GB 2.5"" Solid State Drive](https://pcpartpicker.com/product/FrH48d/samsung-internal-hard-drive-mz75e500bam) | $139.99 @ B&amp;H 
**Storage** | [Seagate - Barracuda 3TB 3.5"" 7200RPM Internal Hard Drive](https://pcpartpicker.com/product/gwBv6h/seagate-internal-hard-drive-st3000dm001) | $69.99 @ Newegg Marketplace 
**Video Card** | [Asus - GeForce GTX 1080 Ti 11GB STRIX GAMING Video Card](https://pcpartpicker.com/product/Z8cMnQ/asus-geforce-gtx-1080-ti-11gb-video-card-strix-gtx1080ti-o11g-gaming) | $769.99 
**Case** | [Deepcool - TESSERACT SW ATX Mid Tower Case](https://pcpartpicker.com/product/3MPfrH/deepcool-case-tesseractsw) | $36.99 @ SuperBiiz 
**Power Supply** | [EVGA - SuperNOVA G2 850W 80+ Gold Certified Fully-Modular ATX Power Supply](https://pcpartpicker.com/product/LCfp99/evga-power-supply-220g20850xr) | $93.98 @ Newegg 
 | *Prices include shipping, taxes, rebates, and discounts* |
 | Total (before mail-in rebates) | $2227.35
 | Mail-in rebates | -$30.00
 | **Total** | **$2197.35**
 | Generated by [PCPartPicker](http://pcpartpicker.com) 2017-11-27 18:57 EST-0500 |",11,3
1457,2017-11-29,2017,11,29,6,7g7ujz,"[N] AI-Blocks: New releases, Video Tutorials and documentation! A WYSIWYG editor for machine learning!",https://www.reddit.com/r/MachineLearning/comments/7g7ujz/n_aiblocks_new_releases_video_tutorials_and/,smilefr,1511906102,,3,12
1458,2017-11-29,2017,11,29,7,7g826k,The backstory of Alexas Indian makeover,https://www.reddit.com/r/MachineLearning/comments/7g826k/the_backstory_of_alexas_indian_makeover/,netcribe,1511907736,,0,1
1459,2017-11-29,2017,11,29,8,7g8oy4,[D] Probability assessment for the output node,https://www.reddit.com/r/MachineLearning/comments/7g8oy4/d_probability_assessment_for_the_output_node/,NoClaim,1511912948,"The output value of the output node(s) of a network are often referred to as probabilities: ""The probability that the image contains a cat."" (Yes, more correctly a confidence estimate, but so many folks seem to treat them as probabilities) However, so many of my peers talk about them as probabilities and it does not look like when the ""cat node"" says ""0.79"" it is actually right 79% of the time. It does not seem way off, but it's definitely far from were I would expect it to be. Is there any literature on how well or poorly the output node ""probabilities"" map on to more traditional probability calculations?",7,10
1460,2017-11-29,2017,11,29,8,7g8r33,Text Classification Tutorial with Naive Bayes,https://www.reddit.com/r/MachineLearning/comments/7g8r33/text_classification_tutorial_with_naive_bayes/,[deleted],1511913480,[deleted],0,1
1461,2017-11-29,2017,11,29,9,7g8yyf,[P] Interpreting Deep Neural Networks with SVCCA,https://www.reddit.com/r/MachineLearning/comments/7g8yyf/p_interpreting_deep_neural_networks_with_svcca/,Flipper3,1511915375,,2,15
1462,2017-11-29,2017,11,29,9,7g8zdb,Text Classification with Naive Bayes,https://www.reddit.com/r/MachineLearning/comments/7g8zdb/text_classification_with_naive_bayes/,christopherj_320,1511915463,,0,1
1463,2017-11-29,2017,11,29,10,7g9dr9,10 Ways to Teach Yourself to Code.,https://www.reddit.com/r/MachineLearning/comments/7g9dr9/10_ways_to_teach_yourself_to_code/,234students,1511919024,,0,1
1464,2017-11-29,2017,11,29,10,7g9k8e,"[D] If you could download any subject into your brain (Matrix style), which would you choose?",https://www.reddit.com/r/MachineLearning/comments/7g9k8e/d_if_you_could_download_any_subject_into_your/,[deleted],1511920616,[deleted],0,0
1465,2017-11-29,2017,11,29,11,7g9n8q,[R] [1711.10337] Are GANs Created Equal? A Large-Scale Study,https://www.reddit.com/r/MachineLearning/comments/7g9n8q/r_171110337_are_gans_created_equal_a_largescale/,evc123,1511921347,,36,61
1466,2017-11-29,2017,11,29,11,7g9rp5,[D] How do you prepare for industry ML/DL engineering interviews in if you come from an academic background?,https://www.reddit.com/r/MachineLearning/comments/7g9rp5/d_how_do_you_prepare_for_industry_mldl/,RefurbishedMac,1511922503,[removed],0,1
1467,2017-11-29,2017,11,29,12,7ga0ft,IN-LIGHT OF EMO 2017,https://www.reddit.com/r/MachineLearning/comments/7ga0ft/inlight_of_emo_2017/,shekhart,1511924711,,0,1
1468,2017-11-29,2017,11,29,12,7ga25f,Automatic Liangpi Making Machine for Sale,https://www.reddit.com/r/MachineLearning/comments/7ga25f/automatic_liangpi_making_machine_for_sale/,liusherry,1511925147,[removed],1,1
1469,2017-11-29,2017,11,29,12,7ga56s,New Type Industry Factory Supply Electric Fresh Noodle Machine,https://www.reddit.com/r/MachineLearning/comments/7ga56s/new_type_industry_factory_supply_electric_fresh/,liusherry,1511925960,[removed],1,1
1470,2017-11-29,2017,11,29,12,7ga6bi,[R] Learning to Segment Every Thing,https://www.reddit.com/r/MachineLearning/comments/7ga6bi/r_learning_to_segment_every_thing/,m_ke,1511926252,,3,19
1471,2017-11-29,2017,11,29,12,7ga87e,[D] Best loss function for probability map output?,https://www.reddit.com/r/MachineLearning/comments/7ga87e/d_best_loss_function_for_probability_map_output/,eukaryote31,1511926767,"I'm currently trying to make a neural network Go policy network, and I'm currently using binary cross entropy as a loss function. However, my neural network gives really low and random probabilities for everything, because my training targets are all 19x19 output planes with single values set. Any idea how to encourage my network to maximize good moves rather than minimize all moves?",19,8
1472,2017-11-29,2017,11,29,14,7gaxcp,Recurrent Generative Adversarial Networks for Proximal Learning and Automated Compressive Image Recovery,https://www.reddit.com/r/MachineLearning/comments/7gaxcp/recurrent_generative_adversarial_networks_for/,mortezamardani,1511933745,,1,1
1473,2017-11-29,2017,11,29,15,7gb2v2,Is there an approach for Variable length input and fixed length output?,https://www.reddit.com/r/MachineLearning/comments/7gb2v2/is_there_an_approach_for_variable_length_input/,huh423,1511935376,[removed],0,1
1474,2017-11-29,2017,11,29,15,7gb9yg,ROLL DIE PUNCHING MACHINE,https://www.reddit.com/r/MachineLearning/comments/7gb9yg/roll_die_punching_machine/,FEIDA_MACHINE,1511937611,,0,1
1475,2017-11-29,2017,11,29,15,7gbcc9,[R] Interpreting Deep Neural Networks with SVCCA,https://www.reddit.com/r/MachineLearning/comments/7gbcc9/r_interpreting_deep_neural_networks_with_svcca/,[deleted],1511938420,[deleted],0,1
1476,2017-11-29,2017,11,29,16,7gbfuk,A Glance at Reinforcement Learning - Introductory Course,https://www.reddit.com/r/MachineLearning/comments/7gbfuk/a_glance_at_reinforcement_learning_introductory/,[deleted],1511939599,[deleted],0,1
1477,2017-11-29,2017,11,29,16,7gbhwi,[P] Glance at Reinforcement Learning - Introductory Course,https://www.reddit.com/r/MachineLearning/comments/7gbhwi/p_glance_at_reinforcement_learning_introductory/,ADGEfficiency,1511940345,,1,14
1478,2017-11-29,2017,11,29,16,7gbi32,How To Unit Test Machine Learning Code,https://www.reddit.com/r/MachineLearning/comments/7gbi32/how_to_unit_test_machine_learning_code/,pmz,1511940416,,0,1
1479,2017-11-29,2017,11,29,17,7gbtf7,"Head-to-head cost comparison of Amazon's AWS, Hetzner, IBM's Softlayer and Google's ComputeEngine on a machine learning benchmark",https://www.reddit.com/r/MachineLearning/comments/7gbtf7/headtohead_cost_comparison_of_amazons_aws_hetzner/,piskvorky,1511944705,,0,1
1480,2017-11-29,2017,11,29,17,7gbw7i,"Master's Program at ETH Zurich, Saarland University and EPFL",https://www.reddit.com/r/MachineLearning/comments/7gbw7i/masters_program_at_eth_zurich_saarland_university/,pepjose,1511945819,[removed],0,1
1481,2017-11-29,2017,11,29,18,7gbxn2,"I made this tutorial solely for beginners in machine learning w, Do comment on it and upvote it on kaggle. Have used simple naive bayes approach to solve a classification problem with explanation of each block of code.",https://www.reddit.com/r/MachineLearning/comments/7gbxn2/i_made_this_tutorial_solely_for_beginners_in/,ibadia2762,1511946380,,0,1
1482,2017-11-29,2017,11,29,19,7gc9a0,Adding unique meaningless token help Word2vec for recommendation?,https://www.reddit.com/r/MachineLearning/comments/7gc9a0/adding_unique_meaningless_token_help_word2vec_for/,gohu_cd,1511950779,[removed],0,1
1483,2017-11-29,2017,11,29,19,7gcawj,[N]Adobe demonstrates future Photoshop tool that uses machine learning to select image subjects,https://www.reddit.com/r/MachineLearning/comments/7gcawj/nadobe_demonstrates_future_photoshop_tool_that/,janemoz,1511951388,,0,1
1484,2017-11-29,2017,11,29,19,7gccrr,"[N]Nvidia, Nuance team up to bring AI, machine learning to radiologists",https://www.reddit.com/r/MachineLearning/comments/7gccrr/nnvidia_nuance_team_up_to_bring_ai_machine/,dearpetra,1511952069,,0,1
1485,2017-11-29,2017,11,29,20,7gcloc,Layman's Guide to Overfitting in Predictive Models,https://www.reddit.com/r/MachineLearning/comments/7gcloc/laymans_guide_to_overfitting_in_predictive_models/,charudatta2684,1511955204,,0,1
1486,2017-11-29,2017,11,29,21,7gcvy8,AC-GAN discriminator architecture,https://www.reddit.com/r/MachineLearning/comments/7gcvy8/acgan_discriminator_architecture/,simopal6,1511958575,[removed],0,1
1487,2017-11-29,2017,11,29,21,7gcwkt,Text Analysis in Excel: Real world use-cases,https://www.reddit.com/r/MachineLearning/comments/7gcwkt/text_analysis_in_excel_real_world_usecases/,shashankg22,1511958753,,0,1
1488,2017-11-29,2017,11,29,21,7gcy0p,Set up TensorFlow with Docker + GPU in Minutes,https://www.reddit.com/r/MachineLearning/comments/7gcy0p/set_up_tensorflow_with_docker_gpu_in_minutes/,redaBoumahdi,1511959176,,0,1
1489,2017-11-29,2017,11,29,22,7gd6ja,SplineCNN: Fast Geometric Deep Learning with Continuous B-Spline Kernels,https://www.reddit.com/r/MachineLearning/comments/7gd6ja/splinecnn_fast_geometric_deep_learning_with/,[deleted],1511961518,[deleted],0,1
1490,2017-11-29,2017,11,29,22,7gd8qa,[1711.08920] SplineCNN: Fast Geometric Deep Learning with Continuous B-Spline Kernels,https://www.reddit.com/r/MachineLearning/comments/7gd8qa/171108920_splinecnn_fast_geometric_deep_learning/,[deleted],1511962115,[deleted],0,1
1491,2017-11-29,2017,11,29,22,7gdbsx,[P] Dynamic Routing Between Capsules - full PyTorch implementation with visualizations,https://www.reddit.com/r/MachineLearning/comments/7gdbsx/p_dynamic_routing_between_capsules_full_pytorch/,[deleted],1511962936,[deleted],0,1
1492,2017-11-29,2017,11,29,22,7gdc1v,ML_PYTHON,https://www.reddit.com/r/MachineLearning/comments/7gdc1v/ml_python/,ARH12525,1511963002,[removed],0,1
1493,2017-11-29,2017,11,29,22,7gddrh,[R] [1711.08920] SplineCNN: Fast Geometric Deep Learning with Continuous B-Spline Kernels,https://www.reddit.com/r/MachineLearning/comments/7gddrh/r_171108920_splinecnn_fast_geometric_deep/,rusty1s,1511963461,,1,13
1494,2017-11-29,2017,11,29,22,7gdeh0,[P] Dynamic Routing Between Capsules - full PyTorch implementation with visualizations,https://www.reddit.com/r/MachineLearning/comments/7gdeh0/p_dynamic_routing_between_capsules_full_pytorch/,adamb90,1511963661,,11,123
1495,2017-11-29,2017,11,29,23,7gdn9c,End-to-end Adversarial Learning for Generative Conversational Agents,https://www.reddit.com/r/MachineLearning/comments/7gdn9c/endtoend_adversarial_learning_for_generative/,oswaldoludwig,1511965852,,0,1
1496,2017-11-30,2017,11,30,0,7gdwbw,"[R] Roger Grosse's ""Theorem 2"" challenge: exponential families, Bregman divergences and duality (inFERENCe)",https://www.reddit.com/r/MachineLearning/comments/7gdwbw/r_roger_grosses_theorem_2_challenge_exponential/,fhuszar,1511968052,,5,25
1497,2017-11-30,2017,11,30,0,7ge14f,Differentiation Of deep Learning From Purely Machine Learning,https://www.reddit.com/r/MachineLearning/comments/7ge14f/differentiation_of_deep_learning_from_purely/,Marry_owen,1511969174,,0,1
1498,2017-11-30,2017,11,30,0,7ge35v,Moving Beyond EdgeRank for Personalized News Feeds. (Boosted Decision Trees and Neural Networks),https://www.reddit.com/r/MachineLearning/comments/7ge35v/moving_beyond_edgerank_for_personalized_news/,balazshoranyi,1511969628,,0,1
1499,2017-11-30,2017,11,30,0,7ge8zw,"Simple Questions Thread November 29, 2017",https://www.reddit.com/r/MachineLearning/comments/7ge8zw/simple_questions_thread_november_29_2017/,AutoModerator,1511970936,[removed],0,1
1500,2017-11-30,2017,11,30,1,7gedhq,YouTube Murals: Painting topic change over time in YouTube videos with Natural Language Processing and Processing.js,https://www.reddit.com/r/MachineLearning/comments/7gedhq/youtube_murals_painting_topic_change_over_time_in/,unmatchedsock31,1511971940,,0,1
1501,2017-11-30,2017,11,30,1,7gediw,[D] Is there an AI that outputs music in the style of a target composer?,https://www.reddit.com/r/MachineLearning/comments/7gediw/d_is_there_an_ai_that_outputs_music_in_the_style/,2Punx2Furious,1511971947,"I know there are AIs that can output pictures with the style of an artist, after they've been trained with paintings from that artist, and I know there are AIs that can compose music, but is there an AI that can compose music in the style of a composer after it has been trained with their music?",21,0
1502,2017-11-30,2017,11,30,1,7gegjg,Marvelous Women: A Machine Learning case study on the women of Marvel,https://www.reddit.com/r/MachineLearning/comments/7gegjg/marvelous_women_a_machine_learning_case_study_on/,unmatchedsock31,1511972634,,0,1
1503,2017-11-30,2017,11,30,1,7gen08,[P] Send code from nvim to Jupyter Notebook,https://www.reddit.com/r/MachineLearning/comments/7gen08/p_send_code_from_nvim_to_jupyter_notebook/,ddlk,1511974033,,2,3
1504,2017-11-30,2017,11,30,2,7geqwn,What machine learning algorithm should I use ?,https://www.reddit.com/r/MachineLearning/comments/7geqwn/what_machine_learning_algorithm_should_i_use/,michaelepn,1511974875,[removed],0,1
1505,2017-11-30,2017,11,30,2,7gevmi,"[D] Would anyone find useful a ""Github"" for trained models?",https://www.reddit.com/r/MachineLearning/comments/7gevmi/d_would_anyone_find_useful_a_github_for_trained/,Elzair,1511975873,"When I first began researching ""deep learning"" a few years ago I was stymied by the lack of pre-trained models to mess with. I tried search for something like it and the best result was a list of models for Apple's CoreML framework. 

There are tons of models doing very well in Kaggle competitions (and others). I bet some of the competitors would not mind making the models available for others to use, if it were convenient. 

Does such a place exist that I overlooked? If not, would anyone else find such a place useful?",20,38
1506,2017-11-30,2017,11,30,2,7gf5rt,Learn how to use Google's Deep Learning Framework - TensorFlow with Python! Solve problems with cutting edge techniques!,https://www.reddit.com/r/MachineLearning/comments/7gf5rt/learn_how_to_use_googles_deep_learning_framework/,Vardvinashk,1511978050,,0,1
1507,2017-11-30,2017,11,30,3,7gf9i6,[D] Glossary: Machine Learning Terminology For Beginners,https://www.reddit.com/r/MachineLearning/comments/7gf9i6/d_glossary_machine_learning_terminology_for/,blackwalls81,1511978805,,5,34
1508,2017-11-30,2017,11,30,3,7gfejs,[D] Does machine learning with a GeForce GTX GPU in a Linux virtual machine work?,https://www.reddit.com/r/MachineLearning/comments/7gfejs/d_does_machine_learning_with_a_geforce_gtx_gpu_in/,HibeePin,1511979850,"I've tried Googling the answer to this, but I have not found a definitive answer. I have a GTX 1070 GPU and I want to use Ubuntu for machine learning tasks like deep learning. I want to know if I could use the GPU's performance in a virtual machine or if I should dual boot, and Is it worth using Linux or machine learning? I have a Windows 10 system.

I also have a laptop with a GTX 940M, and when I use it I would like to use the processing power of my desktop. Could I access the Ubuntu on my desktop remotely from my laptop using Windows 10? Or is there another better way to use the processing power of my desktop, or should I settle with the mobile 940M in the laptop? Also, would I need to also install Ubuntu on my laptop? Thank you.",29,10
1509,2017-11-30,2017,11,30,3,7gfgbt,[R] [1711.10455] Backprop as Functor: A compositional perspective on supervised learning,https://www.reddit.com/r/MachineLearning/comments/7gfgbt/r_171110455_backprop_as_functor_a_compositional/,jesuslop,1511980223,,6,19
1510,2017-11-30,2017,11,30,3,7gfhih,AWS DeepLens  Deep learning enabled video camera for developers,https://www.reddit.com/r/MachineLearning/comments/7gfhih/aws_deeplens_deep_learning_enabled_video_camera/,adamkw94,1511980469,,0,1
1511,2017-11-30,2017,11,30,4,7gfoyf,GANs are Being Fixed in More than One Way,https://www.reddit.com/r/MachineLearning/comments/7gfoyf/gans_are_being_fixed_in_more_than_one_way/,alexeyr,1511982063,,0,1
1512,2017-11-30,2017,11,30,4,7gft3z,[R] Clustering of Time Series Subsequences is Meaningless: Implications for Previous and Future Research,https://www.reddit.com/r/MachineLearning/comments/7gft3z/r_clustering_of_time_series_subsequences_is/,blowjobtransistor,1511982937,,16,33
1513,2017-11-30,2017,11,30,4,7gfxc2,[N] AWS Sagemaker,https://www.reddit.com/r/MachineLearning/comments/7gfxc2/n_aws_sagemaker/,someBlueCows,1511983791,,3,12
1514,2017-11-30,2017,11,30,5,7ggiq8,"[R] From Imitation to Prediction, Data Compression vs Recurrent Neural Networks for Natural Language Processing.",https://www.reddit.com/r/MachineLearning/comments/7ggiq8/r_from_imitation_to_prediction_data_compression/,worldnews_is_shit,1511988278,,1,2
1515,2017-11-30,2017,11,30,5,7gglte,I guess this is a step in this direction,https://www.reddit.com/r/MachineLearning/comments/7gglte/i_guess_this_is_a_step_in_this_direction/,[deleted],1511988965,[deleted],0,1
1516,2017-11-30,2017,11,30,7,7gh7d2,Best Math Classes to take in a Machine Learning Major?,https://www.reddit.com/r/MachineLearning/comments/7gh7d2/best_math_classes_to_take_in_a_machine_learning/,TheBuddhist,1511993609,[removed],0,1
1517,2017-11-30,2017,11,30,8,7ghmn8,[N] Announcing the Initial Release of Mozillas Open Source Speech Recognition Model and Voice Dataset,https://www.reddit.com/r/MachineLearning/comments/7ghmn8/n_announcing_the_initial_release_of_mozillas_open/,Xeroko,1511997111,,19,347
1518,2017-11-30,2017,11,30,9,7gi0av,Justifying Domain Knowledge given Infinite Resources,https://www.reddit.com/r/MachineLearning/comments/7gi0av/justifying_domain_knowledge_given_infinite/,ManOnVacation,1512000384,[removed],0,1
1519,2017-11-30,2017,11,30,9,7gi88l,Amazon launches DeepLens to facilitate AI developers looking to improve computervision or deeplearning skills,https://www.reddit.com/r/MachineLearning/comments/7gi88l/amazon_launches_deeplens_to_facilitate_ai/,thingsthathink,1512002291,,0,1
1520,2017-11-30,2017,11,30,10,7gihwo,What is irrigation machine learning in the future?,https://www.reddit.com/r/MachineLearning/comments/7gihwo/what_is_irrigation_machine_learning_in_the_future/,LeandroCelorio97,1512004800,[removed],0,1
1521,2017-11-30,2017,11,30,10,7gikma,"[D] Weighing softmax predictions based on the validation set confusion matrix, does it make sense?",https://www.reddit.com/r/MachineLearning/comments/7gikma/d_weighing_softmax_predictions_based_on_the/,[deleted],1512005460,[deleted],0,0
1522,2017-11-30,2017,11,30,10,7giq65,[P] visualizing optimizers on toy problems,https://www.reddit.com/r/MachineLearning/comments/7giq65/p_visualizing_optimizers_on_toy_problems/,wassname,1512006842,,1,17
1523,2017-11-30,2017,11,30,11,7giu7c,Why anchor is necessary in detection frameworks using CNN?,https://www.reddit.com/r/MachineLearning/comments/7giu7c/why_anchor_is_necessary_in_detection_frameworks/,[deleted],1512007867,,0,1
1524,2017-11-30,2017,11,30,11,7giwk1,[D] Is anchor necessary for object detection framework using CNN?,https://www.reddit.com/r/MachineLearning/comments/7giwk1/d_is_anchor_necessary_for_object_detection/,hotaekhan,1512008493,"I read some paper focus on object detection problem. YOLOv2, SSD, R-CNN family, Feature pyramid nets, etc..

most of work for object detection used anchor. however, I think anchor(reference box) is very sensitive to object scale. because scale of object is continous but scale of anchor is discrete. as my experience, fine-tune for anchor is really hard to get promise performance. Is anchor necessary?? please inform me any paper which not using anchor if you know.

Thanks.",6,2
1525,2017-11-30,2017,11,30,11,7gj29v,Development History of Rice Noodles Maker,https://www.reddit.com/r/MachineLearning/comments/7gj29v/development_history_of_rice_noodles_maker/,liusherry,1512009954,[removed],1,1
1526,2017-11-30,2017,11,30,12,7gjafl,Automatic Noodle Making Machine Working Video,https://www.reddit.com/r/MachineLearning/comments/7gjafl/automatic_noodle_making_machine_working_video/,liusherry,1512012001,[removed],1,1
1527,2017-11-30,2017,11,30,12,7gjflp,MATLAB Machine Learning by Michael Paluszek  Interview,https://www.reddit.com/r/MachineLearning/comments/7gjflp/matlab_machine_learning_by_michael_paluszek/,kokayie,1512013418,,0,1
1528,2017-11-30,2017,11,30,13,7gjm3m,[P] Deep Learning Framework Benchmarks,https://www.reddit.com/r/MachineLearning/comments/7gjm3m/p_deep_learning_framework_benchmarks/,m_ke,1512015250,,1,3
1529,2017-11-30,2017,11,30,13,7gjs7y,Using Kubernetes to train distributed TensorFlow Object Detection API model,https://www.reddit.com/r/MachineLearning/comments/7gjs7y/using_kubernetes_to_train_distributed_tensorflow/,[deleted],1512016992,[deleted],0,1
1530,2017-11-30,2017,11,30,14,7gjz12,[D] Using Kubernetes to train distributed TensorFlow Object Detection API model,https://www.reddit.com/r/MachineLearning/comments/7gjz12/d_using_kubernetes_to_train_distributed/,sozercan,1512019010,,1,0
1531,2017-11-30,2017,11,30,14,7gk1lf,Responsive Machine Learning Could Lessen Cybersecurity Tradeoffs,https://www.reddit.com/r/MachineLearning/comments/7gk1lf/responsive_machine_learning_could_lessen/,n_jai,1512019783,,0,1
1532,2017-11-30,2017,11,30,14,7gk3zo,"[P] My first blog post: a summary of ""First-order Methods Almost Always Avoid Saddle Points""",https://www.reddit.com/r/MachineLearning/comments/7gk3zo/p_my_first_blog_post_a_summary_of_firstorder/,noahgolm,1512020537,,1,28
1533,2017-11-30,2017,11,30,15,7gkfze,Implications of lumping multiple data classes into a single class?,https://www.reddit.com/r/MachineLearning/comments/7gkfze/implications_of_lumping_multiple_data_classes/,voxl,1512024318,[removed],0,1
1534,2017-11-30,2017,11,30,16,7gkkq8,Compost turner machine,https://www.reddit.com/r/MachineLearning/comments/7gkkq8/compost_turner_machine/,amylee516,1512025882,,0,1
1535,2017-11-30,2017,11,30,16,7gkprw,Improving Palliative Care with Deep Learning [18-layer feed-forward neural network!],https://www.reddit.com/r/MachineLearning/comments/7gkprw/improving_palliative_care_with_deep_learning/,[deleted],1512027658,[deleted],0,1
1536,2017-11-30,2017,11,30,16,7gkqa1,Learn Python From Scratch.,https://www.reddit.com/r/MachineLearning/comments/7gkqa1/learn_python_from_scratch/,dekhoworld,1512027860,[removed],0,1
1537,2017-11-30,2017,11,30,17,7gksyk,[R] Improving Palliative Care with Deep Learning (18-layer feed-forward neural network),https://www.reddit.com/r/MachineLearning/comments/7gksyk/r_improving_palliative_care_with_deep_learning/,vwings,1512028867,,2,0
1538,2017-11-30,2017,11,30,17,7gkwyi,Question about negative sampling...I think,https://www.reddit.com/r/MachineLearning/comments/7gkwyi/question_about_negative_samplingi_think/,Another_Screenname,1512030349,[removed],0,1
1539,2017-11-30,2017,11,30,17,7gl02m,TOROS N2 - lightweight approximate Nearest Neighbor library which runs faster even with large datasets,https://www.reddit.com/r/MachineLearning/comments/7gl02m/toros_n2_lightweight_approximate_nearest_neighbor/,ummae,1512031575,,1,3
1540,2017-11-30,2017,11,30,19,7glhw1,[N]AWS releases SageMaker to make it easier to build and deploy machine learning models,https://www.reddit.com/r/MachineLearning/comments/7glhw1/naws_releases_sagemaker_to_make_it_easier_to/,dearpetra,1512038423,,0,1
1541,2017-11-30,2017,11,30,19,7glieb,CNN Grayscale image vs Binarized image,https://www.reddit.com/r/MachineLearning/comments/7glieb/cnn_grayscale_image_vs_binarized_image/,Mabb_reddit,1512038619,[removed],0,1
1542,2017-11-30,2017,11,30,19,7gljzq,A Year in Computer Vision,https://www.reddit.com/r/MachineLearning/comments/7gljzq/a_year_in_computer_vision/,hlynurd,1512039259,,0,1
1543,2017-11-30,2017,11,30,20,7glq74,"Difference between Machine Learning, Data Science, AI, Deep Learning, and Statistics",https://www.reddit.com/r/MachineLearning/comments/7glq74/difference_between_machine_learning_data_science/,james-warner,1512041539,,0,1
1544,2017-11-30,2017,11,30,20,7gls3j,"[R] ""Deep Image Prior"": deep super-resolution, inpainting, denoising without learning on a dataset and pretrained networks",https://www.reddit.com/r/MachineLearning/comments/7gls3j/r_deep_image_prior_deep_superresolution/,dmitry_ulyanov,1512042224,,93,832
1545,2017-11-30,2017,11,30,21,7glw1c,"[D] ""Performance vs. Sample Complexity"" Matters More in GANs",https://www.reddit.com/r/MachineLearning/comments/7glw1c/d_performance_vs_sample_complexity_matters_more/,guojunq,1512043588,"Yesterday many people were disucssing the paper ""Are GANs Created Equal? A Large-Scale Study."" While the comparison between GANs in terms of ""performance vs. computing resources"" was interesting, but I think it missed another more important factor in its comparison "" the sample complexity,"" i.e., comparing the performances by different GANs under the same number of training samples.  


As we know, the GANs are supposed to be well generalizable to produce NEW samples (not just interpolating existing training samples) with a limited number of training examples. So comparing their performances  under the same size of training set can be more useful, since the available training samples, in particular those independent samples, could not be very limited  in real world.  


This generalizability in terms of sample complexity was studied before in Loss-Sensitive GAN (LS-GAN https://arxiv.org/abs/1701.06264, not LS GAN -- Least Square GAN). It was shown that properly regularized GANs can reach polynomial sample complexity, which means they are generalizable.  This is important, because otherwise exponential sample complexity means  a GAN cannot well produce NEW samples unless it is presented with ALL samples.  To test the generalizability of GANs, we need to study their performances vs. different sizes of training set, rather than simply the computing overhead.  


 I think it is time for our GAN community to treat this issue more seriously.  In fact, I have been challenged multiple times by senior researchers in the computer vision and machine learning communities, who doubt the GANs may not be well generalizable.  I was trying my best to defend GANs in front of them, but we need more evidences with the collaboration from the whole community. This is a very serious concern, deserving us to address it seriously, both in theory and in experiments.  ",21,3
1546,2017-11-30,2017,11,30,21,7gm4am,[R] Analyzing 1000+ Greek Wines With Python,https://www.reddit.com/r/MachineLearning/comments/7gm4am/r_analyzing_1000_greek_wines_with_python/,speckz,1512046357,,4,0
1547,2017-11-30,2017,11,30,22,7gmalt,[N] Giving robots a sense of touch,https://www.reddit.com/r/MachineLearning/comments/7gmalt/n_giving_robots_a_sense_of_touch/,trumtra,1512048257,,0,1
1548,2017-11-30,2017,11,30,22,7gmd8d,[D] How to implement CapsNets using TensorFlow - Aurlien Gron,https://www.reddit.com/r/MachineLearning/comments/7gmd8d/d_how_to_implement_capsnets_using_tensorflow/,sksq9,1512049015,,0,10
1549,2017-11-30,2017,11,30,23,7gmjo8,[R] The impact of mutation on genetic algorithm,https://www.reddit.com/r/MachineLearning/comments/7gmjo8/r_the_impact_of_mutation_on_genetic_algorithm/,LouisNicolle,1512050792,,1,6
1550,2017-11-30,2017,11,30,23,7gmljb,[D] Training a translation model that works in both directions (using tensor2tensor's transformer-algorithm),https://www.reddit.com/r/MachineLearning/comments/7gmljb/d_training_a_translation_model_that_works_in_both/,Delthc,1512051282,"Hello,

I would like to train a machine translation model that is able to translate in both directions.

I do know that NNs tend to profit from multiple tasks during training, and I also know that there are pretty good results for machine translation models that learn multiple languages at once.

However, I am not sure if the naive approach of just feeding DE-&gt;EN and EN-&gt;DE training data at the same time to an otherwise un-altered model (""transformer"" model from ""Attention is all you need"" paper) is a valid approach on that. 

Does anyone have any experience in that direction?
",4,0
1551,2017-11-30,2017,11,30,23,7gmrt1,"[N] Weekly Machine Learning Toolset &amp; Library Roundup  Nov. 30, 2017",https://www.reddit.com/r/MachineLearning/comments/7gmrt1/n_weekly_machine_learning_toolset_library_roundup/,stkim1,1512052939,,0,1
1552,2017-11-30,2017,11,30,23,7gmuu4,"Big Bang of Intelligence - New Algorithms, Parallel Systems and Big Data Unlocking Oportunities",https://www.reddit.com/r/MachineLearning/comments/7gmuu4/big_bang_of_intelligence_new_algorithms_parallel/,[deleted],1512053745,[deleted],0,1
