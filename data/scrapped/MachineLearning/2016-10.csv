,date,year,month,day,hour,id,title,full_link,author,created,selftext,num_comments,score
0,2016-10-1,2016,10,1,9,55azrt,Learn about Machine Learning and AI from Nervana,https://www.reddit.com/r/MachineLearning/comments/55azrt/learn_about_machine_learning_and_ai_from_nervana/,jessiclr,1475282506,,0,1
1,2016-10-1,2016,10,1,10,55b4zi,Deep Learning Frameworks Compared,https://www.reddit.com/r/MachineLearning/comments/55b4zi/deep_learning_frameworks_compared/,llSourcell,1475284825,,0,1
2,2016-10-1,2016,10,1,12,55bj0s,"What kind of answer does theoretical CS want to the question ""Why do neural networks work so well?""",https://www.reddit.com/r/MachineLearning/comments/55bj0s/what_kind_of_answer_does_theoretical_cs_want_to/,DevFRus,1475291389,,4,28
3,2016-10-1,2016,10,1,12,55bkyl,StocksNeural.net - Stocks prices prediction using Deep Learning,https://www.reddit.com/r/MachineLearning/comments/55bkyl/stocksneuralnet_stocks_prices_prediction_using/,j_lyf,1475292334,,0,1
4,2016-10-1,2016,10,1,13,55bu37,Can the Neural Networks method borrow more ideas from how the brain works?,https://www.reddit.com/r/MachineLearning/comments/55bu37/can_the_neural_networks_method_borrow_more_ideas/,wilornel,1475297027,[removed],0,0
5,2016-10-1,2016,10,1,15,55c3hs,Demis Hassabis: Artificial Intelligence and the Future [x-post from /r/futurology],https://www.reddit.com/r/MachineLearning/comments/55c3hs/demis_hassabis_artificial_intelligence_and_the/,CopyofacOpyofacoPyof,1475302551,,1,1
6,2016-10-1,2016,10,1,15,55c4id,Jeff Dean Talks Google Brain and Brain Residency,https://www.reddit.com/r/MachineLearning/comments/55c4id/jeff_dean_talks_google_brain_and_brain_residency/,siddharth-agrawal,1475303255,,12,21
7,2016-10-1,2016,10,1,16,55c7by,"When it comes to offset machines, we look no further than Goodmachine!",https://www.reddit.com/r/MachineLearning/comments/55c7by/when_it_comes_to_offset_machines_we_look_no/,goodmachineeu,1475305213,,0,1
8,2016-10-1,2016,10,1,18,55ciex,What Can We Expect For Chatbots in 2017 &amp; Beyond?,https://www.reddit.com/r/MachineLearning/comments/55ciex/what_can_we_expect_for_chatbots_in_2017_beyond/,reworksophie,1475313264,,0,1
9,2016-10-1,2016,10,1,18,55cj4y,Deep Variational Autoencoder Latent Layer Loss,https://www.reddit.com/r/MachineLearning/comments/55cj4y/deep_variational_autoencoder_latent_layer_loss/,foboi1122,1475313775,"I was reading [this](https://arxiv.org/pdf/1602.02282.pdf) paper and I noticed they used two layers for encoder/decoder, but up to five layers for latent variables. 

My question is how do you calculate loss for more than one latent later? Do you just tack an extra KL Divergence to the loss function for each additional latent layer?",2,11
10,2016-10-1,2016,10,1,19,55cm76,Hedge funds come around: Two Sigma starting new deep learning team.,https://www.reddit.com/r/MachineLearning/comments/55cm76/hedge_funds_come_around_two_sigma_starting_new/,j_lyf,1475316076,,0,1
11,2016-10-1,2016,10,1,21,55cy8a,This is awesome - Neural networks module for Redis,https://www.reddit.com/r/MachineLearning/comments/55cy8a/this_is_awesome_neural_networks_module_for_redis/,stanislavb,1475324027,,9,4
12,2016-10-1,2016,10,1,21,55cyq5,Bond Clustering,https://www.reddit.com/r/MachineLearning/comments/55cyq5/bond_clustering/,kvsnr4,1475324303,[removed],9,4
13,2016-10-2,2016,10,2,2,55e33g,Alternating Back-Propagation for Generator Network,https://www.reddit.com/r/MachineLearning/comments/55e33g/alternating_backpropagation_for_generator_network/,tadellos,1475341482,,3,36
14,2016-10-2,2016,10,2,2,55e7kk,[1609.09475v1] Multi-view Self-supervised Deep Learning for 6D Pose Estimation in the Amazon Picking Challenge,https://www.reddit.com/r/MachineLearning/comments/55e7kk/160909475v1_multiview_selfsupervised_deep/,futureroboticist,1475343068,,1,45
15,2016-10-2,2016,10,2,2,55e7yc,[1609.09049v1] Deep Reinforcement Learning for Tensegrity Robot Locomotion,https://www.reddit.com/r/MachineLearning/comments/55e7yc/160909049v1_deep_reinforcement_learning_for/,futureroboticist,1475343210,,1,19
16,2016-10-2,2016,10,2,4,55epnl,Choosing a language to Implement ML algorithms from scratch in.,https://www.reddit.com/r/MachineLearning/comments/55epnl/choosing_a_language_to_implement_ml_algorithms/,ProgOx,1475349690,[removed],33,12
17,2016-10-2,2016,10,2,4,55etnf,Including `y` multiple times in a neural network,https://www.reddit.com/r/MachineLearning/comments/55etnf/including_y_multiple_times_in_a_neural_network/,pvkooten,1475351174,"Does anyone know of experiments with using `y` in multiple locations in a neural network (using back-propagation)? Might it not be another solution for short-term vs long-term issue? E.g. some nodes are allowed short access to y and some are having a larger distance to y, generating more complex features.
",16,7
18,2016-10-2,2016,10,2,5,55f0f8,Nvidia-Autopilot-TensorFlow: A TensorFlow implementation of the recent Nvidia self-driving car paper,https://www.reddit.com/r/MachineLearning/comments/55f0f8/nvidiaautopilottensorflow_a_tensorflow/,Weihua99,1475353680,,5,108
19,2016-10-2,2016,10,2,5,55f20y,Tasks order optimization,https://www.reddit.com/r/MachineLearning/comments/55f20y/tasks_order_optimization/,Jeibros,1475354247,"Hello,

Is there any way by which ML can help calculating fast the appropriate order of carrying out an industrial operations? I'm thinking particularly on manufacturing industry: let's imagine that a customer wants a particular geometry to be designed in steel, and could an algorithm calculate the correct order? Or is this industry already sufficiently optimized? Thanks",3,6
20,2016-10-2,2016,10,2,6,55fd7c,Would OpenAI Gym be compatible with environments that aren't arcade games?,https://www.reddit.com/r/MachineLearning/comments/55fd7c/would_openai_gym_be_compatible_with_environments/,[deleted],1475358466,[deleted],1,1
21,2016-10-2,2016,10,2,6,55fdcf,The Economy of Hobby ML: Do you find just-for-fun ML rewarding? Is it possible to explore without a GPU while keeping turnover times manageable?,https://www.reddit.com/r/MachineLearning/comments/55fdcf/the_economy_of_hobby_ml_do_you_find_justforfun_ml/,[deleted],1475358517,[deleted],0,1
22,2016-10-2,2016,10,2,10,55g6nz,"In attention based neural models, what is an attention head?",https://www.reddit.com/r/MachineLearning/comments/55g6nz/in_attention_based_neural_models_what_is_an/,8queens,1475370907,https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/seq2seq.py line#570,2,5
23,2016-10-2,2016,10,2,11,55gh6g,How you can master machine learning and AI,https://www.reddit.com/r/MachineLearning/comments/55gh6g/how_you_can_master_machine_learning_and_ai/,vikashkodati,1475375728,,3,0
24,2016-10-2,2016,10,2,13,55gvvp,I need a project to get a job in machine learning field. Please recommend me a project.,https://www.reddit.com/r/MachineLearning/comments/55gvvp/i_need_a_project_to_get_a_job_in_machine_learning/,titanum4567,1475383153,[removed],5,0
25,2016-10-2,2016,10,2,14,55h0pg,Machine Learning SNMP Bayesian Algorithm (New to ML),https://www.reddit.com/r/MachineLearning/comments/55h0pg/machine_learning_snmp_bayesian_algorithm_new_to_ml/,robertmachine,1475385890,[removed],0,5
26,2016-10-2,2016,10,2,14,55h2kf,Whats wrong with my gradientDescentMulti.m code?,https://www.reddit.com/r/MachineLearning/comments/55h2kf/whats_wrong_with_my_gradientdescentmultim_code/,ssreekanth2000,1475386995,,5,1
27,2016-10-2,2016,10,2,16,55ha83,Free Algos - Free algorithm implementations in C.,https://www.reddit.com/r/MachineLearning/comments/55ha83/free_algos_free_algorithm_implementations_in_c/,hustling_drywall,1475392133,[removed],2,0
28,2016-10-2,2016,10,2,20,55hw45,"Help me with ideas for ""pet project"" in ML.",https://www.reddit.com/r/MachineLearning/comments/55hw45/help_me_with_ideas_for_pet_project_in_ml/,Yutkin,1475408398,[removed],3,0
29,2016-10-2,2016,10,2,21,55hyac,Microsoft research India fellow program,https://www.reddit.com/r/MachineLearning/comments/55hyac/microsoft_research_india_fellow_program/,huyhcmut,1475409782,[removed],0,0
30,2016-10-2,2016,10,2,22,55i9wq,Combining LSTM and MLP in Torch,https://www.reddit.com/r/MachineLearning/comments/55i9wq/combining_lstm_and_mlp_in_torch/,[deleted],1475416019,[removed],0,1
31,2016-10-2,2016,10,2,23,55ife4,"Lessons for How to Build Sticky AI First Applications, Overcome the Hype and Compete with the Big Companies",https://www.reddit.com/r/MachineLearning/comments/55ife4/lessons_for_how_to_build_sticky_ai_first/,davitage,1475418527,,1,2
32,2016-10-3,2016,10,3,0,55ikk5,"Learning Reinforcement Learning (with Code, Exercises and Solutions)",https://www.reddit.com/r/MachineLearning/comments/55ikk5/learning_reinforcement_learning_with_code/,[deleted],1475420660,[deleted],0,5
33,2016-10-3,2016,10,3,0,55ipmc,Code used Ladder Variational Autoencoders - clarification,https://www.reddit.com/r/MachineLearning/comments/55ipmc/code_used_ladder_variational_autoencoders/,alexbotev,1475422627,"Hi, so I actually subimted it as an issue to the github repo, but maybe someone here can clarify some of the things if I do not understand them correctly, as I do not know if the authors would reply any time soon. The link to the description is here: https://github.com/casperkaae/LVAE/issues/1",0,4
34,2016-10-3,2016,10,3,1,55itid,Anyone reproduce the WaveNet results outside of Deep Mind?,https://www.reddit.com/r/MachineLearning/comments/55itid/anyone_reproduce_the_wavenet_results_outside_of/,BafflesSean,1475424122,"Does anyone know roughly how much training time is required to train a WaveNet to a similar level of quality to the examples presented in the Deep Mind blog post?

https://deepmind.com/blog/wavenet-generative-model-raw-audio/

I haven't seen a public implementation of WaveNet achieve the results described in the blog post.

Edit: I'm asking because I'm considering a psychophysics project that requires audio synthesis as one of it's core components.",15,75
35,2016-10-3,2016,10,3,1,55ivxi,"Nvidia's self driving car, and how do others learn?",https://www.reddit.com/r/MachineLearning/comments/55ivxi/nvidias_self_driving_car_and_how_do_others_learn/,im-the-stig,1475425025,"Nvidia has been hyping up the [news](http://qz.com/797752/nvidia-self-driving-car-neural-network/) that their car is self taught after watching humans drive. How do other systems like Google, Tesla, Uber learn to drive. IIRC, I read that all of Tesla's cars are connected to the hive, which learns only the terrain, not sure about driving.",3,9
36,2016-10-3,2016,10,3,2,55j67a,AI safety and the ability to build some kind of god ?,https://www.reddit.com/r/MachineLearning/comments/55j67a/ai_safety_and_the_ability_to_build_some_kind_of/,morgangiraud,1475428707,,3,0
37,2016-10-3,2016,10,3,2,55j6dk,Tensorflow Code: CNN on Graphs with Fast Localized Spectral Filtering,https://www.reddit.com/r/MachineLearning/comments/55j6dk/tensorflow_code_cnn_on_graphs_with_fast_localized/,V4wetumpka,1475428774,,7,34
38,2016-10-3,2016,10,3,2,55j6z7,Has anyone solved OpenAI's cartpole-v0 using DQN ?,https://www.reddit.com/r/MachineLearning/comments/55j6z7/has_anyone_solved_openais_cartpolev0_using_dqn/,mundada,1475428985,[removed],0,1
39,2016-10-3,2016,10,3,4,55jurm,"""New AI and research group at Microsoft will have more than 5,000 employees""",https://www.reddit.com/r/MachineLearning/comments/55jurm/new_ai_and_research_group_at_microsoft_will_have/,[deleted],1475437252,[deleted],0,1
40,2016-10-3,2016,10,3,5,55k7m8,Quantum-Chemical Insights from Deep Tensor Neural Networks,https://www.reddit.com/r/MachineLearning/comments/55k7m8/quantumchemical_insights_from_deep_tensor_neural/,KeponeFactory,1475441722,,4,27
41,2016-10-3,2016,10,3,5,55k7o0,e-Commerce Artificial Intelligence: more than UX,https://www.reddit.com/r/MachineLearning/comments/55k7o0/ecommerce_artificial_intelligence_more_than_ux/,StephanCatc,1475441738,,0,2
42,2016-10-3,2016,10,3,6,55khjp,Anyone with machine learning skills interested in journalism?,https://www.reddit.com/r/MachineLearning/comments/55khjp/anyone_with_machine_learning_skills_interested_in/,brand0x,1475445350,"Hello! We're putting together an e-zine about the intersection of machine learning and investigative journalism. There are a few of us writing articles right now, some from professional machine learning backgrounds and some from nonprofit investigative journalism. I figured I'd see if anyone wanted to contribute to it in here.

Our goal is to contribute something back to investigative journalists that could possibly be used a an experimental roadmap on how things could be done better and more efficiently using machine learning.",18,10
43,2016-10-3,2016,10,3,7,55kq3d,What is DRAW (Deep Recurrent Attentive Writer)?,https://www.reddit.com/r/MachineLearning/comments/55kq3d/what_is_draw_deep_recurrent_attentive_writer/,kvfrans,1475448529,,7,18
44,2016-10-3,2016,10,3,9,55l537,Question about the HyperNetworks paper.,https://www.reddit.com/r/MachineLearning/comments/55l537/question_about_the_hypernetworks_paper/,[deleted],1475454358,[deleted],2,5
45,2016-10-3,2016,10,3,9,55l91m,"[Noob] Installed new Geforce 970 video card, how do I take advantage of it?",https://www.reddit.com/r/MachineLearning/comments/55l91m/noob_installed_new_geforce_970_video_card_how_do/,[deleted],1475455975,[removed],2,2
46,2016-10-3,2016,10,3,10,55la3u,Charged Point Normalization: An Efficient Solution to the Saddle Point Problem,https://www.reddit.com/r/MachineLearning/comments/55la3u/charged_point_normalization_an_efficient_solution/,[deleted],1475456436,[deleted],17,7
47,2016-10-3,2016,10,3,10,55la7g,"In industry, are research and productization generally different groups?",https://www.reddit.com/r/MachineLearning/comments/55la7g/in_industry_are_research_and_productization/,bourbondog,1475456477,"Is there an overlap or are there strictly different teams that are maintained for different tasks?
",15,2
48,2016-10-3,2016,10,3,13,55m04d,https://github.com/openimages/dataset,https://www.reddit.com/r/MachineLearning/comments/55m04d/httpsgithubcomopenimagesdataset/,shagunsodhani,1475467436,[removed],1,0
49,2016-10-3,2016,10,3,13,55m1js,"On model evaluation, model selection, and hyperparameter search",https://www.reddit.com/r/MachineLearning/comments/55m1js/on_model_evaluation_model_selection_and/,[deleted],1475468088,[deleted],0,4
50,2016-10-3,2016,10,3,14,55mb1r,"Has anyone taken or is taking CalTech's ""Learning from Data""?",https://www.reddit.com/r/MachineLearning/comments/55mb1r/has_anyone_taken_or_is_taking_caltechs_learning/,OCamlChameleon,1475473063,[removed],0,1
51,2016-10-3,2016,10,3,14,55mbfy,"Model evaluation and selection in machine learning, looking at bias-variance trade-offs in cross-validation and hyperparameter optimization",https://www.reddit.com/r/MachineLearning/comments/55mbfy/model_evaluation_and_selection_in_machine/,[deleted],1475473282,[deleted],0,1
52,2016-10-3,2016,10,3,16,55mlbo,Keynote Session: Dr. Edward Tufte - The Future of Data Analysis | Microsoft Machine Learning,https://www.reddit.com/r/MachineLearning/comments/55mlbo/keynote_session_dr_edward_tufte_the_future_of/,n1ghtw1sh,1475479319,,19,123
53,2016-10-3,2016,10,3,16,55mocj,How Machine Learning Will Aid Neural Science,https://www.reddit.com/r/MachineLearning/comments/55mocj/how_machine_learning_will_aid_neural_science/,digitalmarketingrobi,1475481520,,0,1
54,2016-10-3,2016,10,3,17,55mstm,Hydraulic Press Capacity 100 Mt to 2000 Mt,https://www.reddit.com/r/MachineLearning/comments/55mstm/hydraulic_press_capacity_100_mt_to_2000_mt/,intraautomation,1475484673,,0,1
55,2016-10-3,2016,10,3,17,55mti5,"Universal classifier for Binary, Multi-class and Multi-label Classification",https://www.reddit.com/r/MachineLearning/comments/55mti5/universal_classifier_for_binary_multiclass_and/,rakesajar,1475485193,,2,0
56,2016-10-3,2016,10,3,18,55mufm,What is my best route into ML given my current circumstance?,https://www.reddit.com/r/MachineLearning/comments/55mufm/what_is_my_best_route_into_ml_given_my_current/,Conura,1475485811,[removed],3,4
57,2016-10-3,2016,10,3,20,55n6wp,Algorithmic Aspects of Machine Learning [notes + videos],https://www.reddit.com/r/MachineLearning/comments/55n6wp/algorithmic_aspects_of_machine_learning_notes/,Kiuhnm,1475493787,"I've recently come across an interesting blog called [Off the convex path](http://www.offconvex.org/) which I'm sure many of you already know.

This led me to reconsider more theoretical courses such as [Algorithmic Aspects of Machine Learning](https://ocw.mit.edu/courses/mathematics/18-409-algorithmic-aspects-of-machine-learning-spring-2015/) whose [videos](https://www.youtube.com/playlist?list=PLB3sDpSRdrOvI1hYXNsa6Lety7K8FhPpx) are available on youtube.

The same professor also teaches a course called [Advanced Algorithms](http://people.csail.mit.edu/moitra/854.html) which, I think, is (indirectly) relevant to ML. As before, [videos](https://www.youtube.com/playlist?list=PL6ogFv-ieghdoGKGg2Bik3Gl1glBTEu8c) are available.

Note that if you don't like/need theory or you don't have at least a moderate math background, these courses are not for you.

I'd like to see links to more theoretic stuff as well on this subreddit. I'm serious. New NN architectures are all well and good but training those beasts requires too much trial and error. We need more theoreticians, in my opinion. Even if you don't agree, I hope you like the courses :)",4,43
58,2016-10-3,2016,10,3,20,55n9yw,displaCy.js: An open-source NLP visualiser for the modern web,https://www.reddit.com/r/MachineLearning/comments/55n9yw/displacyjs_an_opensource_nlp_visualiser_for_the/,syllogism_,1475495446,,2,10
59,2016-10-3,2016,10,3,20,55na6l,News in artificial intelligence and machine learning: Aug-Sept 2016,https://www.reddit.com/r/MachineLearning/comments/55na6l/news_in_artificial_intelligence_and_machine/,[deleted],1475495547,[deleted],0,3
60,2016-10-3,2016,10,3,21,55nfqa,DecomposeMe: Simplifying ConvNets for End-to-End Learning,https://www.reddit.com/r/MachineLearning/comments/55nfqa/decomposeme_simplifying_convnets_for_endtoend/,iX6kNcrS,1475498161,,0,17
61,2016-10-3,2016,10,3,21,55ngxl,Visual Question Answering(VQA) in Keras with demo,https://www.reddit.com/r/MachineLearning/comments/55ngxl/visual_question_answeringvqa_in_keras_with_demo/,anantzoid,1475498746,,1,8
62,2016-10-3,2016,10,3,22,55nk5n,"""Easy"" reinforcement learning tasks for sanity checking?",https://www.reddit.com/r/MachineLearning/comments/55nk5n/easy_reinforcement_learning_tasks_for_sanity/,seann999,1475500142,"In deep supervised learning, you can overfit a small dataset as a sanity check: making sure your model is implemented correctly and can actually learn before going on to train on your real, big dataset. Are there similar strategies in reinforcement learning, where one can get results in a few minutes before moving on to spend a day training on Space Invaders or even Pong?",3,6
63,2016-10-3,2016,10,3,22,55npxj,What's the latest in weakly supervised image segmentation? (latest being upto last month),https://www.reddit.com/r/MachineLearning/comments/55npxj/whats_the_latest_in_weakly_supervised_image/,[deleted],1475502521,[deleted],0,1
64,2016-10-3,2016,10,3,23,55nrww,What's the latest in weakly supervised image segmentation? (latest being 2016),https://www.reddit.com/r/MachineLearning/comments/55nrww/whats_the_latest_in_weakly_supervised_image/,nefrpitou,1475503320,[removed],1,0
65,2016-10-3,2016,10,3,23,55nu26,Machine Learnings #11,https://www.reddit.com/r/MachineLearning/comments/55nu26/machine_learnings_11/,beeftug,1475504085,,0,1
66,2016-10-3,2016,10,3,23,55nw20,Reinforcement Learning Exercises &amp; Solutions,https://www.reddit.com/r/MachineLearning/comments/55nw20/reinforcement_learning_exercises_solutions/,pogopuschel_,1475504828,,3,80
67,2016-10-3,2016,10,3,23,55nw9g,Learning Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/55nw9g/learning_reinforcement_learning/,beeftug,1475504904,,1,1
68,2016-10-3,2016,10,3,23,55nx5z,"Model evaluation &amp; selection Part III, cross-validation and the bias-variance trade-off",https://www.reddit.com/r/MachineLearning/comments/55nx5z/model_evaluation_selection_part_iii/,sbt_,1475505236,,0,15
69,2016-10-3,2016,10,3,23,55nx6z,Natural gradients and stochastic variational inference [blog post + code],https://www.reddit.com/r/MachineLearning/comments/55nx6z/natural_gradients_and_stochastic_variational/,neurodynamic,1475505247,,4,33
70,2016-10-4,2016,10,4,0,55o52u,"Book for NLP, specifically LDA that steps through the math?",https://www.reddit.com/r/MachineLearning/comments/55o52u/book_for_nlp_specifically_lda_that_steps_through/,BunnO---,1475507996,[removed],0,1
71,2016-10-4,2016,10,4,1,55odt8,Embedded systems related machine learning topic for thesis?,https://www.reddit.com/r/MachineLearning/comments/55odt8/embedded_systems_related_machine_learning_topic/,Asnen,1475510938,[removed],0,1
72,2016-10-4,2016,10,4,1,55ohqc,Which start-ups in palo alto/SF are using deep learning for NLP?,https://www.reddit.com/r/MachineLearning/comments/55ohqc/which_startups_in_palo_altosf_are_using_deep/,[deleted],1475512209,[deleted],0,1
73,2016-10-4,2016,10,4,1,55ohy3,Which start-ups in palo alto/SF are using deep learning for NLP?,https://www.reddit.com/r/MachineLearning/comments/55ohy3/which_startups_in_palo_altosf_are_using_deep/,[deleted],1475512280,[deleted],0,1
74,2016-10-4,2016,10,4,1,55oid1,Which start-ups in palo alto/SF are using deep learning for NLP?,https://www.reddit.com/r/MachineLearning/comments/55oid1/which_startups_in_palo_altosf_are_using_deep/,alrojo,1475512421,[removed],1,0
75,2016-10-4,2016,10,4,2,55otsd,Good music datasets?,https://www.reddit.com/r/MachineLearning/comments/55otsd/good_music_datasets/,i-heart-ml,1475516030,[removed],0,1
76,2016-10-4,2016,10,4,3,55ozz1,Are you allowed to only use per-created scenarios/environments with OpenAI Gym or are you allowed to create your own?,https://www.reddit.com/r/MachineLearning/comments/55ozz1/are_you_allowed_to_only_use_percreated/,strunberg,1475517941,,0,1
77,2016-10-4,2016,10,4,3,55p1yw,Musings of a Clinically Depressed Predictive Text Emulator,https://www.reddit.com/r/MachineLearning/comments/55p1yw/musings_of_a_clinically_depressed_predictive_text/,MiseryTourism,1475518575,,0,4
78,2016-10-4,2016,10,4,3,55p4zi,Anyone taken Caltech's Learning from Data?,https://www.reddit.com/r/MachineLearning/comments/55p4zi/anyone_taken_caltechs_learning_from_data/,OCamlChameleon,1475519545,[removed],0,1
79,2016-10-4,2016,10,4,4,55pbhj,"What are ML people currently working on,What is the single hottest thing in ML right now, is it Deep Reinforcement Learning, Coming up with good deep models from Quantum Statistical Physics, Combining with Probabilistic reasoning with deep learning or other technique that I'm not aware of?",https://www.reddit.com/r/MachineLearning/comments/55pbhj/what_are_ml_people_currently_working_onwhat_is/,deepmind2016,1475521592,[removed],3,0
80,2016-10-4,2016,10,4,4,55pdi1,Are there any C# machine Learning tools?,https://www.reddit.com/r/MachineLearning/comments/55pdi1/are_there_any_c_machine_learning_tools/,lionrom098,1475522226,[removed],0,1
81,2016-10-4,2016,10,4,5,55pskl,You can now apply for the November Term of Udacity's Self-Driving Car Engineer Nanodegree!,https://www.reddit.com/r/MachineLearning/comments/55pskl/you_can_now_apply_for_the_november_term_of/,Sig_Luna,1475526926,,10,5
82,2016-10-4,2016,10,4,5,55puyn,TensorFlow in a Nutshell - Part Three: All the Models,https://www.reddit.com/r/MachineLearning/comments/55puyn/tensorflow_in_a_nutshell_part_three_all_the_models/,c0cky_,1475527712,,5,129
83,2016-10-4,2016,10,4,6,55q1m8,Google opens up Cloud Machine Learning,https://www.reddit.com/r/MachineLearning/comments/55q1m8/google_opens_up_cloud_machine_learning/,techresponses,1475529886,,0,1
84,2016-10-4,2016,10,4,7,55qgw7,Simple implementation of LSTM in Tensorflow in 50 lines (+ 130 lines of data generation and comments),https://www.reddit.com/r/MachineLearning/comments/55qgw7/simple_implementation_of_lstm_in_tensorflow_in_50/,nivwusquorum,1475535233,,2,9
85,2016-10-4,2016,10,4,8,55qmxn,The Commoditization of Deep Learning,https://www.reddit.com/r/MachineLearning/comments/55qmxn/the_commoditization_of_deep_learning/,roboticrabbitsmasher,1475537432,,8,7
86,2016-10-4,2016,10,4,9,55r038,"Best approach/courses to learn RNN, Seq2Seq, Word2Vec, LSTM?",https://www.reddit.com/r/MachineLearning/comments/55r038/best_approachcourses_to_learn_rnn_seq2seq/,azbtc,1475542603,[removed],3,3
87,2016-10-4,2016,10,4,10,55r81w,DeepMind: Video Pixel Networks,https://www.reddit.com/r/MachineLearning/comments/55r81w/deepmind_video_pixel_networks/,deeprnn,1475545757,,22,68
88,2016-10-4,2016,10,4,11,55r9s2,[paper] Deep Reinforcement Learning for Robotic Manipulation,https://www.reddit.com/r/MachineLearning/comments/55r9s2/paper_deep_reinforcement_learning_for_robotic/,jesuslop,1475546470,,0,13
89,2016-10-4,2016,10,4,11,55rcwb,When we say 80% of variance is explained by first principal componenet in PCA. Can we say that 80% of data points are explained by first component of PCA?,https://www.reddit.com/r/MachineLearning/comments/55rcwb/when_we_say_80_of_variance_is_explained_by_first/,[deleted],1475547656,[deleted],1,1
90,2016-10-4,2016,10,4,11,55rdsj,Google Research - How Robots Can Acquire New Skills from Their Shared Experience,https://www.reddit.com/r/MachineLearning/comments/55rdsj/google_research_how_robots_can_acquire_new_skills/,Buck-Nasty,1475548024,,14,67
91,2016-10-4,2016,10,4,13,55rw92,How do you usually handle the last CNN layer with respect to kernel size and pooling?,https://www.reddit.com/r/MachineLearning/comments/55rw92/how_do_you_usually_handle_the_last_cnn_layer_with/,jstaker7,1475556062,"So I've been thinking about this for a while. If we use a deep CNN to compressing an image into a 1D vector (which can be used for some arbitrary downstream application, like classification) how do I size the very last layer before the FC layers?

For example, our images may now only be 2x2 in size from all the downsampling that has happened from previous pooling layers. Do we just convolve with a 2x2 kernel and then pool again so we have a 1D vector? It seems like that last pooling layer would throw away so much information since each pixel now represents a quarter of our entire original image, yet my model seems to be performing OK. Is there a better way, such as flatten the matrix rather than pool on the last layer, or does it make much of a difference?",7,5
92,2016-10-4,2016,10,4,13,55rwla,Sophisticated machine to clean the ear / Learn how to clean ears properly,https://www.reddit.com/r/MachineLearning/comments/55rwla/sophisticated_machine_to_clean_the_ear_learn_how/,forhadnushrat,1475556244,,1,0
93,2016-10-4,2016,10,4,14,55s2r4,Consciousness Club NY: Teaching Creativity in Chess,https://www.reddit.com/r/MachineLearning/comments/55s2r4/consciousness_club_ny_teaching_creativity_in_chess/,ookwrd,1475559387,,0,1
94,2016-10-4,2016,10,4,15,55s5f7,"Does anyone know how to obtain the old Probase attributeOf and other relationship data? The updated version, Microsoft Concept Graph, has only the isA relationships.",https://www.reddit.com/r/MachineLearning/comments/55s5f7/does_anyone_know_how_to_obtain_the_old_probase/,eshansingh,1475560938,,0,1
95,2016-10-4,2016,10,4,16,55sbtz,An Industrial Revolution Sparked By Machine Learning,https://www.reddit.com/r/MachineLearning/comments/55sbtz/an_industrial_revolution_sparked_by_machine/,digitalmarketingrobi,1475564750,,0,1
96,2016-10-4,2016,10,4,17,55sh7w,"Autonomous agents, learning and the future of AI: six questions to Piotr Mirowski (Google DeepMind)",https://www.reddit.com/r/MachineLearning/comments/55sh7w/autonomous_agents_learning_and_the_future_of_ai/,scardax88,1475568190,,0,4
97,2016-10-4,2016,10,4,17,55skrk,How to tame the valley  Hessian-free hacks for optimizing large #NeuralNetworks,https://www.reddit.com/r/MachineLearning/comments/55skrk/how_to_tame_the_valley_hessianfree_hacks_for/,vvpreetham,1475570706,,2,0
98,2016-10-4,2016,10,4,18,55smkc,"Where can I find a good face tracker, usable in Python?",https://www.reddit.com/r/MachineLearning/comments/55smkc/where_can_i_find_a_good_face_tracker_usable_in/,treebranchleaf,1475571994,[removed],3,2
99,2016-10-4,2016,10,4,18,55soiv,Moral Machine,https://www.reddit.com/r/MachineLearning/comments/55soiv/moral_machine/,3eyedravens,1475573241,,18,12
100,2016-10-4,2016,10,4,18,55sqv6,"Accelerating Deep Convolutional Networks using low-precision and sparsity - Intel paper, 2-bit ResNets",https://www.reddit.com/r/MachineLearning/comments/55sqv6/accelerating_deep_convolutional_networks_using/,olBaa,1475574642,,17,89
101,2016-10-4,2016,10,4,19,55sryc,Getting salient region for multi-task models.,https://www.reddit.com/r/MachineLearning/comments/55sryc/getting_salient_region_for_multitask_models/,mafail,1475575331,[removed],0,1
102,2016-10-4,2016,10,4,19,55svq7,Is SVD a good way to convert one-hot encoded attributes into a vector?,https://www.reddit.com/r/MachineLearning/comments/55svq7/is_svd_a_good_way_to_convert_onehot_encoded/,[deleted],1475577570,[deleted],0,1
103,2016-10-4,2016,10,4,19,55svtg,Is SVD a good way to transform multiple one-hot encoded attributes into a vector representation?,https://www.reddit.com/r/MachineLearning/comments/55svtg/is_svd_a_good_way_to_transform_multiple_onehot/,sanity,1475577628,,3,2
104,2016-10-4,2016,10,4,19,55sxsc,Original work in deep learning,https://www.reddit.com/r/MachineLearning/comments/55sxsc/original_work_in_deep_learning/,huyhcmut,1475578790,"After some months reading about deep learning research paper, i feel that there are not many original works like in (bayesian learning, kernel learning). I mean there are many papers just *improve* something, or *combine* algorithms, appear a lot even if at Top-venues. What do your think about that? Sorry if i made something wrong. :D",6,0
105,2016-10-4,2016,10,4,21,55t8xh,Cyclades: Conflict-free asynchronous machine learning,https://www.reddit.com/r/MachineLearning/comments/55t8xh/cyclades_conflictfree_asynchronous_machine/,mttd,1475584369,,3,11
106,2016-10-4,2016,10,4,21,55taqc,Zee Course has started.,https://www.reddit.com/r/MachineLearning/comments/55taqc/zee_course_has_started/,nicholas_nullus,1475585205,[removed],1,0
107,2016-10-4,2016,10,4,22,55td6p,Deep Learning for Computer Graphics,https://www.reddit.com/r/MachineLearning/comments/55td6p/deep_learning_for_computer_graphics/,terrorlucid,1475586246,[removed],1,3
108,2016-10-4,2016,10,4,22,55teyp,How Keras.io is becoming everyones go-to interface for deep learning,https://www.reddit.com/r/MachineLearning/comments/55teyp/how_kerasio_is_becoming_everyones_goto_interface/,kohola71,1475586943,,0,1
109,2016-10-4,2016,10,4,22,55tk61,Can anyone here help with logistic regression questions?,https://www.reddit.com/r/MachineLearning/comments/55tk61/can_anyone_here_help_with_logistic_regression/,Logistic_Regression,1475588995,[removed],0,1
110,2016-10-4,2016,10,4,23,55tnfi,"Explore interactive ML web apps using neural networks, logistic regression, etc.",https://www.reddit.com/r/MachineLearning/comments/55tnfi/explore_interactive_ml_web_apps_using_neural/,elisebreda,1475590221,,0,1
111,2016-10-4,2016,10,4,23,55tu9i,YouTube 8M: Large-Scale Video Classification from Google Research,https://www.reddit.com/r/MachineLearning/comments/55tu9i/youtube_8m_largescale_video_classification_from/,KeponeFactory,1475592613,,1,2
112,2016-10-4,2016,10,4,23,55turk,X-CNN: Cross-modal Convolutional Neural Networks for Sparse Datasets,https://www.reddit.com/r/MachineLearning/comments/55turk/xcnn_crossmodal_convolutional_neural_networks_for/,jordo45,1475592789,,5,9
113,2016-10-4,2016,10,4,23,55tvvj,"[Hiring] Machine Learning Rebel at Stylight, Munich",https://www.reddit.com/r/MachineLearning/comments/55tvvj/hiring_machine_learning_rebel_at_stylight_munich/,Stylight_GmbH,1475593178,[removed],0,2
114,2016-10-5,2016,10,5,0,55txxm,Labeling documents with short text labels after topic modeling?,https://www.reddit.com/r/MachineLearning/comments/55txxm/labeling_documents_with_short_text_labels_after/,pfizer_soze,1475593858,[removed],0,1
115,2016-10-5,2016,10,5,1,55u8lc,Know your followers with Machine Learning,https://www.reddit.com/r/MachineLearning/comments/55u8lc/know_your_followers_with_machine_learning/,wildcodegowrong,1475597394,,0,1
116,2016-10-5,2016,10,5,3,55v49i,What are some good features for music genre classification?,https://www.reddit.com/r/MachineLearning/comments/55v49i/what_are_some_good_features_for_music_genre/,Isdalek,1475607406,[removed],9,4
117,2016-10-5,2016,10,5,3,55v4nh,Tutorial: Intro to Convolutional Neural Nets,https://www.reddit.com/r/MachineLearning/comments/55v4nh/tutorial_intro_to_convolutional_neural_nets/,hoaphumanoid,1475607531,,0,1
118,2016-10-5,2016,10,5,4,55vac0,XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/55vac0/xnornet_imagenet_classification_using_binary/,[deleted],1475609220,[deleted],0,1
119,2016-10-5,2016,10,5,4,55vajh,XNOR-Net: Imagenet Classification Using *Binary* Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/55vajh/xnornet_imagenet_classification_using_binary/,downtownslim,1475609285,,1,21
120,2016-10-5,2016,10,5,4,55vb68,An Introduction to Machine Learning in Julia,https://www.reddit.com/r/MachineLearning/comments/55vb68/an_introduction_to_machine_learning_in_julia/,beeftug,1475609476,,0,1
121,2016-10-5,2016,10,5,4,55vb96,Feature Extraction for images on OpenCV,https://www.reddit.com/r/MachineLearning/comments/55vb96/feature_extraction_for_images_on_opencv/,TheGuyFromClass,1475609500,[removed],0,1
122,2016-10-5,2016,10,5,5,55vrdz,Proper train and test sets when using ML on a dataset?,https://www.reddit.com/r/MachineLearning/comments/55vrdz/proper_train_and_test_sets_when_using_ml_on_a/,[deleted],1475614568,[removed],10,7
123,2016-10-5,2016,10,5,7,55w374,Transfer Learning for a self-driving car (livestream),https://www.reddit.com/r/MachineLearning/comments/55w374/transfer_learning_for_a_selfdriving_car_livestream/,vanboxel,1475618448,,0,5
124,2016-10-5,2016,10,5,8,55webz,Computer Age Statistical Inference - new book from Bradley Efron and Trevor Hastie,https://www.reddit.com/r/MachineLearning/comments/55webz/computer_age_statistical_inference_new_book_from/,thecity2,1475622356,,8,19
125,2016-10-5,2016,10,5,9,55wpl9,"Zip() creates a dtype none, I want to create dtype float in python. How would I do this?",https://www.reddit.com/r/MachineLearning/comments/55wpl9/zip_creates_a_dtype_none_i_want_to_create_dtype/,lostwhitewalker,1475626460,[removed],0,0
126,2016-10-5,2016,10,5,9,55wrcp,Anyone want Keras benchmarks for GTX 960 vs Titan X Pascal?,https://www.reddit.com/r/MachineLearning/comments/55wrcp/anyone_want_keras_benchmarks_for_gtx_960_vs_titan/,ktbyte,1475627114,"I have a GTX 960 and Titan X Pascal. Would anyone like to see any keras benchmarks, and if so, what kind of models (e.g. link to a script for me to compare)?",5,4
127,2016-10-5,2016,10,5,11,55x7oh,roc_curve() sklearn,https://www.reddit.com/r/MachineLearning/comments/55x7oh/roc_curve_sklearn/,abhi5025,1475633153,[removed],2,1
128,2016-10-5,2016,10,5,11,55x8rc,Neural Network for Machine Learning by Geoffrey Hinton has started. We've also got a sub for it (r/nn4ml).,https://www.reddit.com/r/MachineLearning/comments/55x8rc/neural_network_for_machine_learning_by_geoffrey/,pddpro,1475633539,,35,222
129,2016-10-5,2016,10,5,12,55xis6,Recognising a game from a screenshot,https://www.reddit.com/r/MachineLearning/comments/55xis6/recognising_a_game_from_a_screenshot/,madary,1475637280,"I have been trying to use a shallow (3 hidden layers) CNN, which works well for the MNIST handwriting recognition, but  not too well for detecting whether a screen shot is from a particular game.
I trained on frames of videos from few games and on providing random sceen shots its expected to classify it among the trained games. 
My question : is it fundamentally impossible to classify using this approach ? I think the images are too complex (too many features) and the network too shallow. **Is my intuition correct ?**
 
I even thought of object detection to create a signature for each game but that seems like an overkill.",8,1
130,2016-10-5,2016,10,5,12,55xlkc,"A new approach to background noise classification, your thoughts on the approach?",https://www.reddit.com/r/MachineLearning/comments/55xlkc/a_new_approach_to_background_noise_classification/,clay_pool,1475638404,,0,1
131,2016-10-5,2016,10,5,13,55xq1p,Associative Broadcast Neural Network,https://www.reddit.com/r/MachineLearning/comments/55xq1p/associative_broadcast_neural_network/,Aleksei_Morozov_1973,1475640243,,0,1
132,2016-10-5,2016,10,5,13,55xr9r,Benchmarks based on neural networks libraries to compare the performance between different GPUs,https://www.reddit.com/r/MachineLearning/comments/55xr9r/benchmarks_based_on_neural_networks_libraries_to/,Franck_Dernoncourt,1475640766,"I am looking for benchmarks based on neural networks libraries (Theano/TensorFlow/Torch/Caffe/) to compare the performance between different GPUs.

I am aware of:

- https://github.com/jcjohnson/cnn-benchmarks (CNN in Torch)
- https://github.com/jcjohnson/neural-style#speed (CNN in Torch)
- https://github.com/glample/rnn-benchmarks (vanilla RNNs and LSTM in Theano, TensorFlow, and Torch)

What are some other benchmark codes?",6,7
133,2016-10-5,2016,10,5,17,55yhwt,The struggle,https://www.reddit.com/r/MachineLearning/comments/55yhwt/the_struggle/,icancto,1475655843,"Hello ML. I am struggling. I have been learning about DNNs, supervised and unsupervised learning, RL, etc. for the past 3 months now. Whenever I start reading a paper or a book or any kind of lengthy text I get sidetracked and start thinking about something else. I can't focus. The stuff I'm reading is pretty difficult. The mathematical formulas, the fancy words, they overwhelm me. Also, I don't even memorize that much after a read. I don't feel I'm learning much.

It's rather peculiar, because no matter what area I studied in the past I pretty much excelled at everything.

Is it normal to struggle at ML? Is it really this difficult at the beginning?",15,0
134,2016-10-5,2016,10,5,17,55yk3n,Hyperparameter optimization for Tensorflow?,https://www.reddit.com/r/MachineLearning/comments/55yk3n/hyperparameter_optimization_for_tensorflow/,shycapslock,1475657382,[removed],2,0
135,2016-10-5,2016,10,5,18,55ylbm,The propeller agitator is a powder processing machinery?,https://www.reddit.com/r/MachineLearning/comments/55ylbm/the_propeller_agitator_is_a_powder_processing/,mixmachinery,1475658180,,1,1
136,2016-10-5,2016,10,5,18,55ypv5,Recommending movies with deep learning,https://www.reddit.com/r/MachineLearning/comments/55ypv5/recommending_movies_with_deep_learning/,richardweiss,1475661096,,10,2
137,2016-10-5,2016,10,5,20,55z18p,Tensorflow Sentiment Analysis and Data Reading tutorial made by me,https://www.reddit.com/r/MachineLearning/comments/55z18p/tensorflow_sentiment_analysis_and_data_reading/,arif_sohaib,1475667688,,0,0
138,2016-10-5,2016,10,5,22,55zczt,Fast Style transfer - can be used real-time,https://www.reddit.com/r/MachineLearning/comments/55zczt/fast_style_transfer_can_be_used_realtime/,Pandemonii,1475672762,,22,133
139,2016-10-5,2016,10,5,22,55zfri,Install Tensorflow on Ubuntu 16.04,https://www.reddit.com/r/MachineLearning/comments/55zfri/install_tensorflow_on_ubuntu_1604/,techresponses,1475673853,,0,1
140,2016-10-5,2016,10,5,22,55zj4e,Predicting karma of a Reddit post. https://quip.com/O8CTAVETCabm,https://www.reddit.com/r/MachineLearning/comments/55zj4e/predicting_karma_of_a_reddit_post/,NihilisticFool,1475675163,"So, I have been going through the above problem, which I find quite daunting. I am not looking for a solution, but rather a discussion on the approaches one could take to model this. ",9,0
141,2016-10-5,2016,10,5,23,55zngl,Why is everything in this field seemingly built in Python rather than other languages (c++ for example)?,https://www.reddit.com/r/MachineLearning/comments/55zngl/why_is_everything_in_this_field_seemingly_built/,JamesS92,1475676753,I this just how it started and people are rolling with it based on momentum?  Or are there actual benefits to using Python over an alternative?,47,12
142,2016-10-6,2016,10,6,0,55zx0c,TensorFlow and Monetizing Intellectual Property,https://www.reddit.com/r/MachineLearning/comments/55zx0c/tensorflow_and_monetizing_intellectual_property/,beeftug,1475680041,,0,1
143,2016-10-6,2016,10,6,0,55zyns,Fine-tuning deep convolutional neural networks for distinguishing illustrations from photographs,https://www.reddit.com/r/MachineLearning/comments/55zyns/finetuning_deep_convolutional_neural_networks_for/,sybilckw,1475680586,,3,0
144,2016-10-6,2016,10,6,0,560067,Geff Hinton's Coursera Course: Anything New?,https://www.reddit.com/r/MachineLearning/comments/560067/geff_hintons_coursera_course_anything_new/,stacky777,1475681085,[removed],0,1
145,2016-10-6,2016,10,6,0,5602nz,Computer Vision News of October,https://www.reddit.com/r/MachineLearning/comments/5602nz/computer_vision_news_of_october/,Gletta,1475681885,[removed],0,1
146,2016-10-6,2016,10,6,0,56042d,[Question] Training difficulty of PixelCNNs with gating units,https://www.reddit.com/r/MachineLearning/comments/56042d/question_training_difficulty_of_pixelcnns_with/,[deleted],1475682332,[deleted],0,2
147,2016-10-6,2016,10,6,0,56059z,"Simple Questions Thread October 05, 2016",https://www.reddit.com/r/MachineLearning/comments/56059z/simple_questions_thread_october_05_2016/,AutoModerator,1475682737,"Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!

Thread will stay alive until next one so keep posting after the date in the title.

Thanks to everyone for answering questions in the previous thread!
",119,8
148,2016-10-6,2016,10,6,0,5605q9,"BigData and ML Toolset and Library Weekly Roundup  Oct. 5, 2016",https://www.reddit.com/r/MachineLearning/comments/5605q9/bigdata_and_ml_toolset_and_library_weekly_roundup/,stkim1,1475682873,,0,1
149,2016-10-6,2016,10,6,2,560jtb,Insight Artificial Intelligence Fellow Program launches in Silicon Valley and New York,https://www.reddit.com/r/MachineLearning/comments/560jtb/insight_artificial_intelligence_fellow_program/,jakek123,1475687284,,0,5
150,2016-10-6,2016,10,6,2,560kha,An Intro to Distributed Neural Net Training on Spark With GPUs,https://www.reddit.com/r/MachineLearning/comments/560kha/an_intro_to_distributed_neural_net_training_on/,vonnik,1475687501,,4,1
151,2016-10-6,2016,10,6,2,560od5,Bot for answering random questions,https://www.reddit.com/r/MachineLearning/comments/560od5/bot_for_answering_random_questions/,sunilkc123,1475688707,[removed],0,1
152,2016-10-6,2016,10,6,2,560skx,Machine Learning with Amazon's 128-core/2TB memory X1 Instance,https://www.reddit.com/r/MachineLearning/comments/560skx/machine_learning_with_amazons_128core2tb_memory/,dccpt,1475690030,,0,2
153,2016-10-6,2016,10,6,3,560xcf,How is Machine Learning being used in credit scoring for the unbanked?,https://www.reddit.com/r/MachineLearning/comments/560xcf/how_is_machine_learning_being_used_in_credit/,chirau,1475691499,[removed],1,0
154,2016-10-6,2016,10,6,3,560yo8,Interested in a study-group for Jaynes' Probability Theory: The Logic of Science,https://www.reddit.com/r/MachineLearning/comments/560yo8/interested_in_a_studygroup_for_jaynes_probability/,RyderJo,1475691917,,1,1
155,2016-10-6,2016,10,6,3,5612mj,"MRPT: Approx NN Search with Multiple Random Projection Trees (code, paper and benchmark)",https://www.reddit.com/r/MachineLearning/comments/5612mj/mrpt_approx_nn_search_with_multiple_random/,improbabble,1475693201,,6,8
156,2016-10-6,2016,10,6,3,5614hh,How do you deploy your model?,https://www.reddit.com/r/MachineLearning/comments/5614hh/how_do_you_deploy_your_model/,testingTestingIBS,1475693780,[removed],2,2
157,2016-10-6,2016,10,6,3,5614l5,At the bleeding edge of AI: Quantum grocery picking and transfer learning,https://www.reddit.com/r/MachineLearning/comments/5614l5/at_the_bleeding_edge_of_ai_quantum_grocery/,Barbas,1475693814,,0,0
158,2016-10-6,2016,10,6,4,561en3,Exploration Potential,https://www.reddit.com/r/MachineLearning/comments/561en3/exploration_potential/,funspace,1475696948,,12,13
159,2016-10-6,2016,10,6,4,561g95,PixelCNN question: blind spots,https://www.reddit.com/r/MachineLearning/comments/561g95/pixelcnn_question_blind_spots/,bihaqo,1475697438,"I can't wrap my head around the solution to the blind spot problem proposed in the [PixelCNN paper](https://arxiv.org/abs/1606.05328).

Can anyone explain what do they actually do? Do they use (1 x N) and (N x 1) convolutions? What are the inputs and the masks?",10,8
160,2016-10-6,2016,10,6,5,561qtt,10 Algorithms Every data scientist should know,https://www.reddit.com/r/MachineLearning/comments/561qtt/10_algorithms_every_data_scientist_should_know/,Yovyom,1475700827,,0,1
161,2016-10-6,2016,10,6,6,561v70,60 Startups Active in the Deep Learning Market Landscape,https://www.reddit.com/r/MachineLearning/comments/561v70/60_startups_active_in_the_deep_learning_market/,nyike,1475702217,,0,0
162,2016-10-6,2016,10,6,7,5627zu,I like making strange cover photos for my club's (MWL) Facebook events. Here's this week's monstrosity.,https://www.reddit.com/r/MachineLearning/comments/5627zu/i_like_making_strange_cover_photos_for_my_clubs/,discointhenunnery,1475706569,,0,0
163,2016-10-6,2016,10,6,7,562bys,How are multiple objects classified in a picture?,https://www.reddit.com/r/MachineLearning/comments/562bys/how_are_multiple_objects_classified_in_a_picture/,[deleted],1475708030,[removed],2,2
164,2016-10-6,2016,10,6,8,562iyr,GPU-accelerated Theano &amp; Keras on Windows 10 native [UPDATED TO Keras1.1.0 + Theano0.8.2 + VS2015 + CUDA8.0 + cuDNN5.1],https://www.reddit.com/r/MachineLearning/comments/562iyr/gpuaccelerated_theano_keras_on_windows_10_native/,tezcaML,1475710647,"If, and only if, you **MUST** run Windows 10 and still want decent performance running Theano &amp; Keras, the following guide may help. It describes GPU acceleration on Windows 10 in **native mode** -- no VMs, no Docker:

https://github.com/philferriere/dlwin

We tested it on the following hardware:

- Dell Precision T7900, 64GB RAM [Intel Xeon E5-2630 v4 @ 2.20 GHz (1 processor, 10 cores total, 20 logical processors)]
- NVIDIA GeForce Titan X, 12GB RAM [Driver version: 372.90 / Win 10 64]

We used the following tools/libraries:

- Visual Studio 2015 Community Edition Update 3 w. Windows Kit 10.0.10240.0 [Used for its C/C++ compiler (not its IDE) and SDK]
- CUDA 8.0.44 (64-bit) [Used for its GPU math libraries, card driver, and CUDA compiler]
- MinGW-w64 (5.4.0) [Used for its Unix-like compiler and build tools (g++/gcc, make...) for Windows]
- Anaconda (64-bit) w. Python 2.7 (Anaconda2-4.2.0) [A Python distro that gives us NumPy, SciPy, and other scientific libraries]
- Theano 0.8.2 [Used to evaluate mathematical expressions on multi-dimensional arrays]
- Keras 1.1.0 [Used for deep learning on top of Theano]
- OpenBLAS 0.2.14 (Optional) [Used for its CPU-optimized implementation of many linear algebra operations]
- cuDNN v5.1 (August 10, 2016) for CUDA 8.0 (Recommended) [Used to run vastly faster convolution neural networks]

Hope this helps!",6,23
165,2016-10-6,2016,10,6,8,562lwt,What are some easy research topics for machine learning?,https://www.reddit.com/r/MachineLearning/comments/562lwt/what_are_some_easy_research_topics_for_machine/,a_dead_shark,1475711768,[removed],1,0
166,2016-10-6,2016,10,6,9,562n98,Stat212b: Topics Course on Deep Learning by joanbruna,https://www.reddit.com/r/MachineLearning/comments/562n98/stat212b_topics_course_on_deep_learning_by/,zxzhijia,1475712275,,0,27
167,2016-10-6,2016,10,6,10,562xw7,"Samsung acquires Viv, a next-gen AI assistant built by the creators of Apples Siri",https://www.reddit.com/r/MachineLearning/comments/562xw7/samsung_acquires_viv_a_nextgen_ai_assistant_built/,vonnik,1475716347,,1,3
168,2016-10-6,2016,10,6,10,562zgz,Native TensorFlow alpha Windows Support.,https://www.reddit.com/r/MachineLearning/comments/562zgz/native_tensorflow_alpha_windows_support/,whateverr123,1475716969,,34,83
169,2016-10-6,2016,10,6,10,563064,Deep Gold: Using Convolution Networks to Find Minerals,https://www.reddit.com/r/MachineLearning/comments/563064/deep_gold_using_convolution_networks_to_find/,greendestiny,1475717240,,27,58
170,2016-10-6,2016,10,6,11,5636l1,"Degree in mathematical statistics, doing analytics/data analysis for a well known company. How to get further into machine learning?",https://www.reddit.com/r/MachineLearning/comments/5636l1/degree_in_mathematical_statistics_doing/,bandalorian,1475719740,[removed],0,1
171,2016-10-6,2016,10,6,11,5638po,Learning about Neural Networks using TensorFlow Playground,https://www.reddit.com/r/MachineLearning/comments/5638po/learning_about_neural_networks_using_tensorflow/,zeusidkz,1475720577,,0,1
172,2016-10-6,2016,10,6,11,5638tb,Easy Way To Summarize Documents?,https://www.reddit.com/r/MachineLearning/comments/5638tb/easy_way_to_summarize_documents/,Ovicior,1475720619,[removed],4,2
173,2016-10-6,2016,10,6,11,563dd8,Recreating some results form Early Visual Concept Learning Paper,https://www.reddit.com/r/MachineLearning/comments/563dd8/recreating_some_results_form_early_visual_concept/,yoyosarian,1475722477,,1,2
174,2016-10-6,2016,10,6,12,563lid,Starting up in an AI-first world,https://www.reddit.com/r/MachineLearning/comments/563lid/starting_up_in_an_aifirst_world/,tim_anglade,1475725967,,0,1
175,2016-10-6,2016,10,6,13,563tka,Computer Vision News of October,https://www.reddit.com/r/MachineLearning/comments/563tka/computer_vision_news_of_october/,Dov_sadan,1475729714,[removed],0,2
176,2016-10-6,2016,10,6,15,5644ps,Looking for a topic for my master's thesis (ML related),https://www.reddit.com/r/MachineLearning/comments/5644ps/looking_for_a_topic_for_my_masters_thesis_ml/,krekelmans,1475735776,[removed],15,1
177,2016-10-6,2016,10,6,17,564i3c,Do you know the difference between a Data Scientist and a Data Analyst? Find out here!,https://www.reddit.com/r/MachineLearning/comments/564i3c/do_you_know_the_difference_between_a_data/,Springpeoplehandler,1475744349,,0,1
178,2016-10-6,2016,10,6,18,564m0i,Lasagne - Keras comparison show awful Lasagne performance (?),https://www.reddit.com/r/MachineLearning/comments/564m0i/lasagne_keras_comparison_show_awful_lasagne/,raw_hazard,1475746900,[removed],0,1
179,2016-10-6,2016,10,6,19,564qcg,Analyzing Six Deep Learning Tools for Music Generation,https://www.reddit.com/r/MachineLearning/comments/564qcg/analyzing_six_deep_learning_tools_for_music/,asimovinstitute,1475749636,,0,1
180,2016-10-6,2016,10,6,20,564ywo,'The master algorithm' - book by Pedro Domingos,https://www.reddit.com/r/MachineLearning/comments/564ywo/the_master_algorithm_book_by_pedro_domingos/,amjw,1475754476,[removed],0,1
181,2016-10-6,2016,10,6,21,565112,Finding Logos in Images,https://www.reddit.com/r/MachineLearning/comments/565112/finding_logos_in_images/,[deleted],1475755518,[removed],0,1
182,2016-10-6,2016,10,6,21,5652x2,Deep Reinforcement Learning: Playing a Racing Game,https://www.reddit.com/r/MachineLearning/comments/5652x2/deep_reinforcement_learning_playing_a_racing_game/,[deleted],1475756334,[deleted],0,1
183,2016-10-6,2016,10,6,21,5654ah,Deep Reinforcement Learning: Playing a Racing Game (using Python+Tensorflow),https://www.reddit.com/r/MachineLearning/comments/5654ah/deep_reinforcement_learning_playing_a_racing_game/,[deleted],1475756942,[deleted],0,1
184,2016-10-6,2016,10,6,21,5656mg,Deep Reinforcement Learning: Playing a Racing Game (using Python + Tensorflow),https://www.reddit.com/r/MachineLearning/comments/5656mg/deep_reinforcement_learning_playing_a_racing_game/,[deleted],1475757888,[deleted],0,1
185,2016-10-6,2016,10,6,22,565f3z,"Deep Reinforcement Learning: Playing a Racing Game (using Python, Tensorflow and AWS EC2)",https://www.reddit.com/r/MachineLearning/comments/565f3z/deep_reinforcement_learning_playing_a_racing_game/,lopespm,1475761247,,17,152
186,2016-10-6,2016,10,6,23,565iy4,Mapping Poverty With Satellite Data &amp; Machine Learning,https://www.reddit.com/r/MachineLearning/comments/565iy4/mapping_poverty_with_satellite_data_machine/,reworkdiane,1475762705,,0,1
187,2016-10-6,2016,10,6,23,565l4q,tensorflow loss won't decrease,https://www.reddit.com/r/MachineLearning/comments/565l4q/tensorflow_loss_wont_decrease/,jun_wei_chen,1475763490,[removed],0,1
188,2016-10-6,2016,10,6,23,565qc6,[Help] loss won't decrease,https://www.reddit.com/r/MachineLearning/comments/565qc6/help_loss_wont_decrease/,jun_wei_chen,1475765306,[removed],0,1
189,2016-10-7,2016,10,7,0,565sti,How to do batch wise embedding_lookup without running out of memory on Tensorflow?,https://www.reddit.com/r/MachineLearning/comments/565sti/how_to_do_batch_wise_embedding_lookup_without/,frogsplash911,1475766145,[removed],0,1
190,2016-10-7,2016,10,7,0,565tr9,Possible interview.,https://www.reddit.com/r/MachineLearning/comments/565tr9/possible_interview/,J_Baur136,1475766441,"Hello all, I'm not sure if this is the best place to post this and if someone could point me in a better direction I would gladly take this elsewhere. I am a student in college and I have to interview someone in a career similar to the one I would like to be in. I am looking into a career in the artificial intelligence/machine learning field, so if any of you have a career in that or very similar to that I would love to ask you about 10 questions. If you are willing leaving a comment that I could PM you would be amazing. Thanks you for your time, have a great day!",4,0
191,2016-10-7,2016,10,7,1,5663ym,Looking on opinions on how to improve Random Forest or alternative techniques,https://www.reddit.com/r/MachineLearning/comments/5663ym/looking_on_opinions_on_how_to_improve_random/,Xamius,1475769789,"My data:
I am using random forest to essentially predict which price each person should get to increase revenue uplift. 

So basically a/b/n pricing. 25% get 1 of 4 prices. 

I then run 4 models to predict how much a customer would spend on each price (IE I separate the data by the price the customer gets, so model is run on 4 separate datasets).

I then use the 4 models on the validation/test data to see how much the new customers would spend for each price. I then take the max of those 4 predicted prices and use that as the predicted price we should give that customer. 

I then compare the predicted price point with the actual price the customer was given and calculate the mean revenue for those where predicted=actual. I compare the average revenue vs. average revenue for all customers in the dataset.

Problem:
The model gets some good accuracy on the training data but does not score well uplift wise on the validation or test data. The conversion % is really low, like 5%. So I usually take a sample of the 0s to match the 1s and then run the model. I have also tried cross validation using the randomforest package in R.

I am looking for opinions on other modeling techniques I should try, and if there is something else I should try sampling wise. 

I have tried random forest both in the regression method I described and also the classification method, where I measure the probablity of each person buying the product for the 4 price points, and then taking the price with the max probability as the predicted price point.

I have also tried logistic and linear regression, as well as researching svm and gradiant boosting models.  ",6,0
192,2016-10-7,2016,10,7,1,56644m,Machine Learning Top 10 in September,https://www.reddit.com/r/MachineLearning/comments/56644m/machine_learning_top_10_in_september/,[deleted],1475769838,[deleted],0,1
193,2016-10-7,2016,10,7,1,5665pi,Udacity releases 223GB of data for Self driving cars,https://www.reddit.com/r/MachineLearning/comments/5665pi/udacity_releases_223gb_of_data_for_self_driving/,cudeep,1475770335,,0,1
194,2016-10-7,2016,10,7,1,566868,Machine Learning Top 10 in September,https://www.reddit.com/r/MachineLearning/comments/566868/machine_learning_top_10_in_september/,[deleted],1475771107,[deleted],0,3
195,2016-10-7,2016,10,7,1,5668yr,"For generative modelling on audio: spectrograms, mfccs, and inversion in python.",https://www.reddit.com/r/MachineLearning/comments/5668yr/for_generative_modelling_on_audio_spectrograms/,timburg,1475771366,,15,18
196,2016-10-7,2016,10,7,1,5669nv,Why doesn't training RNNs use 100% of the GPU?,https://www.reddit.com/r/MachineLearning/comments/5669nv/why_doesnt_training_rnns_use_100_of_the_gpu/,Franck_Dernoncourt,1475771603,[removed],0,1
197,2016-10-7,2016,10,7,1,566aii,Can tensorflow auto gradient use for any kind of loss function?,https://www.reddit.com/r/MachineLearning/comments/566aii/can_tensorflow_auto_gradient_use_for_any_kind_of/,jun_wei_chen,1475771870,[removed],0,1
198,2016-10-7,2016,10,7,1,566eea,"[1609.08913] ""we must either continue to develop new learning methods year after year or move towards highly parameterized models that are both flexible and sensitive to their hyperparameters""",https://www.reddit.com/r/MachineLearning/comments/566eea/160908913_we_must_either_continue_to_develop_new/,downtownslim,1475773082,,15,35
199,2016-10-7,2016,10,7,2,566err,Case Study: Deploying R Models,https://www.reddit.com/r/MachineLearning/comments/566err/case_study_deploying_r_models/,[deleted],1475773208,[deleted],0,1
200,2016-10-7,2016,10,7,2,566f5i,Case Study: Deploying R Models with Yhat,https://www.reddit.com/r/MachineLearning/comments/566f5i/case_study_deploying_r_models_with_yhat/,elisebreda,1475773326,,0,1
201,2016-10-7,2016,10,7,2,566g6g,Selecting an Alemite Grease Pump Can Become Easier With An Expert,https://www.reddit.com/r/MachineLearning/comments/566g6g/selecting_an_alemite_grease_pump_can_become/,jackerfrinandis,1475773648,,0,1
202,2016-10-7,2016,10,7,2,566gvo,A list of courses on deep learning,https://www.reddit.com/r/MachineLearning/comments/566gvo/a_list_of_courses_on_deep_learning/,smartsg,1475773874,,0,1
203,2016-10-7,2016,10,7,2,566k8s,Dogs Vs Cat Challenge is back,https://www.reddit.com/r/MachineLearning/comments/566k8s/dogs_vs_cat_challenge_is_back/,soundndfury,1475774932,,0,1
204,2016-10-7,2016,10,7,2,566q78,What are your favourite thought-provoking papers/books on the philosophical side of general artificial intelligence?,https://www.reddit.com/r/MachineLearning/comments/566q78/what_are_your_favourite_thoughtprovoking/,Paddapa,1475776791,[removed],1,0
205,2016-10-7,2016,10,7,4,56739n,Google Vision API: Image Analysis as a Service,https://www.reddit.com/r/MachineLearning/comments/56739n/google_vision_api_image_analysis_as_a_service/,[deleted],1475780785,[deleted],0,0
206,2016-10-7,2016,10,7,4,56769h,Anyone want to start learning Deep learning with python with me?,https://www.reddit.com/r/MachineLearning/comments/56769h/anyone_want_to_start_learning_deep_learning_with/,damnedSpirit,1475781712,[removed],0,1
207,2016-10-7,2016,10,7,4,5676q8,A parallel recommendation engine in Julia,https://www.reddit.com/r/MachineLearning/comments/5676q8/a_parallel_recommendation_engine_in_julia/,Dogsindahouse1,1475781853,,1,2
208,2016-10-7,2016,10,7,5,567n5n,What is the state-of-art ML techniques for the problem of writing algorithms?,https://www.reddit.com/r/MachineLearning/comments/567n5n/what_is_the_stateofart_ml_techniques_for_the/,[deleted],1475786826,[removed],0,1
209,2016-10-7,2016,10,7,6,567rxj,"Hidden Markov Model - Gaussian Mixture Model and Deep Neural Network. Speech recognition, do I understand it?",https://www.reddit.com/r/MachineLearning/comments/567rxj/hidden_markov_model_gaussian_mixture_model_and/,Dytanoth,1475788340,"Hi all,
I have been doing a thesis on speech recognition. Mainly about user experience, but I do want to know if I got the theory right behind the models. Please correct me if I'm wrong.

The very very basic idea I've got:
When we've got an audio stream, the HMM will divide it into ""states"" which are a set period of time (like 10ms). Those states contain a certain ""wave"" that makes up the sound. From this state a speech vector is taken, which will be send to either the GMM or DNN for recognition. The results of those recognitions are phonemes which combined will make words.

The GMM plots the vector in a multi-dimensional graph, like [this](https://embed.gyazo.com/093bf77be2d25c26d26f75d5aa3419fb.png) and compares it to the acoustic model to find the most alike plot.

The DNN recognizes the input as something it had seen before, and goes through different layers of hidden nodes to get the output data. As a DNN model was trained to get output ""B"" when input is ""A"" by backpropagation.
I hope I got this right, as a lot of articles instantly mention different formulas. Which I really don't understand (yet).

Does anyone know if I took anything the wrong way?

Thanks you!",9,5
210,2016-10-7,2016,10,7,7,5681in,Comprehensive / aggressive stoplists?,https://www.reddit.com/r/MachineLearning/comments/5681in/comprehensive_aggressive_stoplists/,yacob_uk,1475791487,"This might not be the best sub for this question... but I'm looking for a very aggressive stoplist for text parsing. 

I'm interested in removing most if not all of the non ""interesting""* words from a keyword returning processing step, which I'm not in control of. 

I'm currently taking a very hamfisted approach by merging all the english language stoplists I can find, but I wondered if there was a better/cleaner/safer way of getting the linguistic mundanities filtered out of the keyword lists. 

My interest is actually broader than just English, Te Reo Maori is also a language I'm keen to try and get a stoplist for, followed by other Pacific Island languages.  I suspect these will be much harder to establish.

*What is interesting... that in an of itself is a problem. I think I'm currently interested in names, places, concepts, nouns, some verbs.... There is another facet of this which is looking at generating named entity lists from some institutional authorities (e.g. Lib of Congress), but thats another whole topic. ",5,1
211,2016-10-7,2016,10,7,7,56821r,What do you input into an RNN?,https://www.reddit.com/r/MachineLearning/comments/56821r/what_do_you_input_into_an_rnn/,OneRaynyDay,1475791659,[removed],0,1
212,2016-10-7,2016,10,7,7,5684ls,Neural Net Computing Explodes,https://www.reddit.com/r/MachineLearning/comments/5684ls/neural_net_computing_explodes/,johnmountain,1475792837,,6,15
213,2016-10-7,2016,10,7,8,568j16,Can tensorflow auto gradient use for any kind of loss function?,https://www.reddit.com/r/MachineLearning/comments/568j16/can_tensorflow_auto_gradient_use_for_any_kind_of/,jun_wei_chen,1475798079,[removed],0,1
214,2016-10-7,2016,10,7,9,568k0c,Extremely basic feature selection questions,https://www.reddit.com/r/MachineLearning/comments/568k0c/extremely_basic_feature_selection_questions/,alphaboosttt,1475798453,[removed],0,1
215,2016-10-7,2016,10,7,10,568tvd,Photonic Delay Systems as Machine Learning Implementations,https://www.reddit.com/r/MachineLearning/comments/568tvd/photonic_delay_systems_as_machine_learning/,adamnemecek,1475802084,,1,1
216,2016-10-7,2016,10,7,11,569ad6,Is there a beginner friendly place that I can learn about choosing transform functions for back propagation?,https://www.reddit.com/r/MachineLearning/comments/569ad6/is_there_a_beginner_friendly_place_that_i_can/,CS_throwaway_GOAL,1475808622,[removed],0,1
217,2016-10-7,2016,10,7,12,569g41,"Thoughts on Deep Learning/VR development rig specs? I'm thinking dual boot ubuntu for DL, Windows for VR. Better budgeting suggestions welcome",https://www.reddit.com/r/MachineLearning/comments/569g41/thoughts_on_deep_learningvr_development_rig_specs/,[deleted],1475810957,[deleted],0,0
218,2016-10-7,2016,10,7,12,569h88,[1610.01945] Connecting Generative Adversarial Networks and Actor-Critic Methods,https://www.reddit.com/r/MachineLearning/comments/569h88/161001945_connecting_generative_adversarial/,hardmaru,1475811448,,8,38
219,2016-10-7,2016,10,7,14,569tjt,Spark ALS Recommendation Engine,https://www.reddit.com/r/MachineLearning/comments/569tjt/spark_als_recommendation_engine/,drowningindata,1475817043,[removed],0,1
220,2016-10-7,2016,10,7,15,56a0ls,Learn how to design a spam classifier using machine learning APIs with this webinar.,https://www.reddit.com/r/MachineLearning/comments/56a0ls/learn_how_to_design_a_spam_classifier_using/,Ronster86,1475820773,,0,1
221,2016-10-7,2016,10,7,15,56a2vr,Can some one share the preview of udacity's self driving car dataset?,https://www.reddit.com/r/MachineLearning/comments/56a2vr/can_some_one_share_the_preview_of_udacitys_self/,commafighter,1475822083,[removed],0,1
222,2016-10-7,2016,10,7,17,56ag65,Open-source ensemble/committee of convolutional neural networks implementation?,https://www.reddit.com/r/MachineLearning/comments/56ag65/opensource_ensemblecommittee_of_convolutional/,[deleted],1475830317,[removed],0,1
223,2016-10-7,2016,10,7,18,56ahdo,Open-source ensemble/committee of convolutional neural networks implementation?,https://www.reddit.com/r/MachineLearning/comments/56ahdo/opensource_ensemblecommittee_of_convolutional/,AndrewTalanskiy,1475831099,[removed],0,1
224,2016-10-7,2016,10,7,18,56al5r,An Open Source Self-Driving Car (from Udacity),https://www.reddit.com/r/MachineLearning/comments/56al5r/an_open_source_selfdriving_car_from_udacity/,dataoverflow,1475833481,,0,34
225,2016-10-7,2016,10,7,19,56aplk,Great FREE book about the Theory of ML,https://www.reddit.com/r/MachineLearning/comments/56aplk/great_free_book_about_the_theory_of_ml/,Kiuhnm,1475836226,,10,144
226,2016-10-7,2016,10,7,19,56aqo9,Adagrad depends on the choice of basis,https://www.reddit.com/r/MachineLearning/comments/56aqo9/adagrad_depends_on_the_choice_of_basis/,benjaminwilson,1475836874,,10,7
227,2016-10-7,2016,10,7,21,56azpb,New cross-device bookmarking tool powered by artificial intelligence,https://www.reddit.com/r/MachineLearning/comments/56azpb/new_crossdevice_bookmarking_tool_powered_by/,elasticio,1475841624,,0,1
228,2016-10-7,2016,10,7,21,56b09l,Graph-powered Machine Learning at Google,https://www.reddit.com/r/MachineLearning/comments/56b09l/graphpowered_machine_learning_at_google/,DrPharael,1475841863,,1,36
229,2016-10-7,2016,10,7,21,56b50w,Machine Intelligence Research Breakthroughs to be Showcased in New York,https://www.reddit.com/r/MachineLearning/comments/56b50w/machine_intelligence_research_breakthroughs_to_be/,reworksophie,1475843937,,0,1
230,2016-10-7,2016,10,7,22,56bbr8,Machine-Learning for Network Security: Theres an App for That,https://www.reddit.com/r/MachineLearning/comments/56bbr8/machinelearning_for_network_security_theres_an/,amplifier_khan,1475846629,,0,1
231,2016-10-7,2016,10,7,22,56be9a,Can we open the black box of AI?,https://www.reddit.com/r/MachineLearning/comments/56be9a/can_we_open_the_black_box_of_ai/,beeftug,1475847591,,0,1
232,2016-10-7,2016,10,7,22,56bepa,"SKLearn - Given an array A, predict value B",https://www.reddit.com/r/MachineLearning/comments/56bepa/sklearn_given_an_array_a_predict_value_b/,Sig_Luna,1475847758,"Hello everyone

I need some help regarding SciKit-Learn. I have a lot of data in the form of an array A and a value B.

E.g:

    &gt;&gt; print(A[0])


    [1.2, 0.3, -0.2, 0.3, -1.1, -0.4, 0.7, 0.2, -2.1, 0.1]


    &gt;&gt; print (B[0])


    9.2


Now I want to predict the Value B, given the Array A. Which model could I use and *how*? I don't quite have an overview over all SciKit-Learn models. I'm fresh out of Andrew Ng's course and experimenting with some private projects.

EDIT: Brainfart",6,0
233,2016-10-7,2016,10,7,23,56bjqs,"Made a self-driving rc car during my free time, referencing Nvidia's recently released end-to-end learning paper.",https://www.reddit.com/r/MachineLearning/comments/56bjqs/made_a_selfdriving_rc_car_during_my_free_time/,kendrick__,1475849577,,19,203
234,2016-10-7,2016,10,7,23,56bjz4,Battlecode - MIT's AI Programming Competition,https://www.reddit.com/r/MachineLearning/comments/56bjz4/battlecode_mits_ai_programming_competition/,beeftug,1475849652,,0,1
235,2016-10-7,2016,10,7,23,56blkl,I want to calculate certain pixel property that is based on it's neighbourhood,https://www.reddit.com/r/MachineLearning/comments/56blkl/i_want_to_calculate_certain_pixel_property_that/,Juffin,1475850189,"Also, this property doesn't depend on pixel's position. I want to approximate this property with a convolutional neural network. What kind of CNN should I use to calculate properties of all the pixels of an image?

I don't want to calculate it for every neighbourhood separately because that would cause a lot of extra convolutions, since the CNN for every neighbourhood would be the same.

Are such algorithms implemented in any CNN package?

",6,0
236,2016-10-8,2016,10,8,0,56c1n3,Time Series classifier(s)?,https://www.reddit.com/r/MachineLearning/comments/56c1n3/time_series_classifiers/,Guanoco,1475855606,[removed],0,1
237,2016-10-8,2016,10,8,2,56ceun,A gentle introduction to convolutional neural networks,https://www.reddit.com/r/MachineLearning/comments/56ceun/a_gentle_introduction_to_convolutional_neural/,hoaphumanoid,1475859768,,0,1
238,2016-10-8,2016,10,8,2,56cilf,"Farval Lubrication Can Help Increase the Performance of Pumps, Valves and Systems",https://www.reddit.com/r/MachineLearning/comments/56cilf/farval_lubrication_can_help_increase_the/,jackerfrinandis,1475860948,,0,1
239,2016-10-8,2016,10,8,3,56crmw,Anyone worked with Library of Congress subject headings and assigning them to text?,https://www.reddit.com/r/MachineLearning/comments/56crmw/anyone_worked_with_library_of_congress_subject/,yacob_uk,1475863813,"I'm not a ML person. But I do spend far too much time thinking about how I might apply ML to work problems.  

If I had examples of loc subject headings. Texts. And texts with loc subject headings assigned by human operators could I build a machine that learns from those human decisions and results in machine asserted subject headings. 

I have plenty of data sources, but minimal human operators for verifying machine processed decisions. 

As a novice data wrangler with some python, is this something I could explore solo, or would I get better outcomes by joining up with a researcher.  

I appreciate the vague openness of the question, and the dislike of non domain-expert questions in this sub. The root of this problem is a genuine contemporary information Science challenge and I'm extremely focused on trying to find ways of pulling us out of a very problematic situation.",4,0
240,2016-10-8,2016,10,8,4,56d8sj,The Federal Reserve Meets Julia,https://www.reddit.com/r/MachineLearning/comments/56d8sj/the_federal_reserve_meets_julia/,Dogsindahouse1,1475869338,,1,2
241,2016-10-8,2016,10,8,5,56dehe,"Foundations of Data Science (Book), 2016",https://www.reddit.com/r/MachineLearning/comments/56dehe/foundations_of_data_science_book_2016/,jakn,1475871177,,2,69
242,2016-10-8,2016,10,8,5,56dgbt,How do I choose the most appropriate algorithm for my problem?,https://www.reddit.com/r/MachineLearning/comments/56dgbt/how_do_i_choose_the_most_appropriate_algorithm/,_Nexor,1475871810,[removed],0,1
243,2016-10-8,2016,10,8,6,56dnvj,what is the best machine learning tool to match just postings to job candidates?,https://www.reddit.com/r/MachineLearning/comments/56dnvj/what_is_the_best_machine_learning_tool_to_match/,mlqqq,1475874305,[removed],0,1
244,2016-10-8,2016,10,8,6,56do6i,awesome-spn: A structured list of resources about Sum-Product Networks (SPNs),https://www.reddit.com/r/MachineLearning/comments/56do6i/awesomespn_a_structured_list_of_resources_about/,[deleted],1475874404,[deleted],0,1
245,2016-10-8,2016,10,8,7,56dy7v,How to train an autoencoder ?,https://www.reddit.com/r/MachineLearning/comments/56dy7v/how_to_train_an_autoencoder/,vighneshbirodkar,1475877928,"My data is 64 x 64 images. I have tried the obvious approach of training the whole autoencoder end-to-end, but I could not get good reproductions as I decreased the feature vector length.

Is layer-wise training helpful ? I found [this](https://www.reddit.com/r/MachineLearning/comments/54tdww/autoencoders_using_residual_networks/) paper which suggests that training one encoder layer at a time with the its corresponding decoder layer.  Are there any better approaches than this ?

From what I understand Layer wise pre-training works as follows:
Encoder = E1, E2, E3, E4

Decoder = D1, D2, D3, D4

Train E1 -  D1

Train E1 - E2 - D2 - D1 ( E1, D1, fixed)

Train E1- E2 - E3 - D3 - D2 - D1 (E1, E2, D1, D2 fixed)

.........and so on 

I am assuming that the loss function is MSE.

Before I proceed I would like to know if my understanding is correct or if there are better approaches out there. I might try Denoising/Variatinal Autoencoders later, but I thought it'd be better to get a simple model working first.",12,3
246,2016-10-8,2016,10,8,9,56el4x,[1610.01644] Understanding intermediate layers using linear classifier probes,https://www.reddit.com/r/MachineLearning/comments/56el4x/161001644_understanding_intermediate_layers_using/,hoqqanen,1475886832,,12,17
247,2016-10-8,2016,10,8,9,56enlz,New Series: Learn Python for Data Science #1,https://www.reddit.com/r/MachineLearning/comments/56enlz/new_series_learn_python_for_data_science_1/,llSourcell,1475887848,,0,1
248,2016-10-8,2016,10,8,11,56exvv,Stability of Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/56exvv/stability_of_generative_adversarial_networks/,NichG,1475892215,,2,70
249,2016-10-8,2016,10,8,12,56f94v,Real time semantic segmentation papers/models (for Nvidia TX-1),https://www.reddit.com/r/MachineLearning/comments/56f94v/real_time_semantic_segmentation_papersmodels_for/,mad_rat_man,1475897166,[removed],0,1
250,2016-10-8,2016,10,8,16,56g137,About industrial paint mixing machines manufacturers,https://www.reddit.com/r/MachineLearning/comments/56g137/about_industrial_paint_mixing_machines/,mixmachinery,1475912537,,1,1
251,2016-10-8,2016,10,8,16,56g208,"Hi Guys, we're getting our feet wet on Machine Learning. Here's what we have so far!",https://www.reddit.com/r/MachineLearning/comments/56g208/hi_guys_were_getting_our_feet_wet_on_machine/,gimortz,1475913205,,0,0
252,2016-10-8,2016,10,8,18,56gc4y,Spark - LDA : A Complete example of clustering algorithm for topic discovery.,https://www.reddit.com/r/MachineLearning/comments/56gc4y/spark_lda_a_complete_example_of_clustering/,shiv4nsh,1475920497,,0,1
253,2016-10-8,2016,10,8,21,56gqvl,Competing in a data science contest without reading the data [???],https://www.reddit.com/r/MachineLearning/comments/56gqvl/competing_in_a_data_science_contest_without/,Kiuhnm,1475929810,"I read [this article](http://blog.mrtz.org/2015/03/09/competition.html) but I really don't get it. (Yes, I know what Differential Privacy is.) The author says:

&gt; In this post, I will describe a method to climb the public leaderboard without even looking at the data. The algorithm is so simple and natural that an unwitting analyst might just run it.

First of all, I don't see the point in climbing the public leaderboard by cheating. Anyway, if you want to discourage it, why not simply indicate the number of submissions? [edit: One could use fake accounts, I guess.]

Second, why use ""wacky boosting"" when the labels are fixed?! Couldn't we just use some sort of deterministic searching? For instance, we could change a label or a small group of labels at a time and see how the score change.

The author seems quite excited about it so maybe I'm missing something here. I couldn't contact the author so I decided to ask here.",10,6
254,2016-10-8,2016,10,8,23,56h4hd,Learning to Describe E-Commerce Images from Noisy Online Data,https://www.reddit.com/r/MachineLearning/comments/56h4hd/learning_to_describe_ecommerce_images_from_noisy/,3eyedravens,1475936232,,6,9
255,2016-10-8,2016,10,8,23,56h5pj,i feel little bit discouraged,https://www.reddit.com/r/MachineLearning/comments/56h5pj/i_feel_little_bit_discouraged/,stefan_kurcubic,1475936756,"Hi, i recently got interested in machine learning 

articles kept poping up and i wanted to give it a try but it seems to be veeeeery very very very deep and hard field to get into and that it would take a lot of time to make anything practical and even that would require a lot of math

Are there any people here who studied ML for fun and possibly got job in that?
What was the most fun project that you made/are making?


",30,0
256,2016-10-8,2016,10,8,23,56h94k,"[News] No shirt, not tags, no service. Posts without appropriate tag will be removed.",https://www.reddit.com/r/MachineLearning/comments/56h94k/news_no_shirt_not_tags_no_service_posts_without/,olaf_nij,1475938176,[removed],1,2
257,2016-10-8,2016,10,8,23,56ha65,[Discussion] Testing discussion tag,https://www.reddit.com/r/MachineLearning/comments/56ha65/discussion_testing_discussion_tag/,rmltestaccount,1475938587,[removed],0,1
258,2016-10-9,2016,10,9,0,56hbd9,[News] Test tag.,https://www.reddit.com/r/MachineLearning/comments/56hbd9/news_test_tag/,[deleted],1475939034,[deleted],0,1
259,2016-10-9,2016,10,9,0,56hbif,[Discussion] Test Discussion Tag,https://www.reddit.com/r/MachineLearning/comments/56hbif/discussion_test_discussion_tag/,rmltestaccount,1475939085,[removed],0,1
260,2016-10-9,2016,10,9,0,56hc9n,"[News] No shirt, not tags, no service. Posts without appropriate tag will be removed.",https://www.reddit.com/r/MachineLearning/comments/56hc9n/news_no_shirt_not_tags_no_service_posts_without/,[deleted],1475939387,[deleted],1,1
261,2016-10-9,2016,10,9,0,56hd56,This should get autoremoved,https://www.reddit.com/r/MachineLearning/comments/56hd56/this_should_get_autoremoved/,rmltestaccount,1475939698,[removed],0,1
262,2016-10-9,2016,10,9,0,56hd9u,[News] This should stay,https://www.reddit.com/r/MachineLearning/comments/56hd9u/news_this_should_stay/,[deleted],1475939750,[deleted],0,1
263,2016-10-9,2016,10,9,0,56hdqi,"No shirt, no tags, no service. Posts without appropriate tag will be removed.",https://www.reddit.com/r/MachineLearning/comments/56hdqi/no_shirt_no_tags_no_service_posts_without/,olaf_nij,1475939928,"To organize this subreddit and weed out submitters that do not read the rules. All posts from here on out will require tags.
Current Tags: [News], [Research], [Discussion], [Project]

Open to other tag suggestions.

Demo post here: https://www.reddit.com/r/MachineLearning/comments/56hnjf/research_equality_of_opportunity_in_machine/",33,8
264,2016-10-9,2016,10,9,0,56hgua,What you need to know about data augmentation for machine learning,https://www.reddit.com/r/MachineLearning/comments/56hgua/what_you_need_to_know_about_data_augmentation_for/,Nuno_EdgarFernandes,1475941085,,0,1
265,2016-10-9,2016,10,9,0,56hi1a,Stellar ages in seconds,https://www.reddit.com/r/MachineLearning/comments/56hi1a/stellar_ages_in_seconds/,TheSwitchBlade,1475941522,,0,1
266,2016-10-9,2016,10,9,1,56hmlc,[Research] Equality of Opportunity in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/56hmlc/research_equality_of_opportunity_in_machine/,olaf_nij,1475943165,,0,1
267,2016-10-9,2016,10,9,1,56hn9k,[Resesarch] Equality of Opportunity in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/56hn9k/resesarch_equality_of_opportunity_in_machine/,[deleted],1475943399,[deleted],0,1
268,2016-10-9,2016,10,9,1,56hnjf,[Research] Equality of Opportunity in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/56hnjf/research_equality_of_opportunity_in_machine/,rmltestaccount,1475943493,,27,23
269,2016-10-9,2016,10,9,1,56hp21,[Research] Interpretable ML for Complex Systems NIPS 2016 Workshop,https://www.reddit.com/r/MachineLearning/comments/56hp21/research_interpretable_ml_for_complex_systems/,rmltestaccount,1475944033,,0,12
270,2016-10-9,2016,10,9,1,56hria,Mitsubishi developed a method to generate hidden layers automatically based on input and output layers. Same/better performance as the hand-tuned networks.,https://www.reddit.com/r/MachineLearning/comments/56hria/mitsubishi_developed_a_method_to_generate_hidden/,f9d8hv3sl,1475944901,"press release:
http://www.mitsubishielectric.co.jp/news/2016/pdf/1007.pdf


news article was behind a soft wall, so I copy-pasted it here:

http://techon.nikkeibp.co.jp/atcl/news/16/100704454/

AI11
[]
1
[]
2

 AiSadd-if-silent11 

3101000101621ICONIPInternational Conference on Neural Information Processing2016

3AiS

    
 ",12,23
271,2016-10-9,2016,10,9,3,56ibog,Upvote if you do not want mods to remove untagged posts [discussion],https://www.reddit.com/r/MachineLearning/comments/56ibog/upvote_if_you_do_not_want_mods_to_remove_untagged/,rd11235,1475951970,(I'd rather not miss a good post just because the author forgot to tag. And I personally find tags useless in this sub.),54,374
272,2016-10-9,2016,10,9,3,56icxk,dataHaskell: An open source organization devoted to improve the data science environment for Haskell,https://www.reddit.com/r/MachineLearning/comments/56icxk/datahaskell_an_open_source_organization_devoted/,nSeagull,1475952400,,0,1
273,2016-10-9,2016,10,9,7,56jadw,I can't for the life of me figure out what the sigmoid function is actually doing to make my neural network function,https://www.reddit.com/r/MachineLearning/comments/56jadw/i_cant_for_the_life_of_me_figure_out_what_the/,CS_throwaway_GOAL,1475964483,[removed],0,1
274,2016-10-9,2016,10,9,8,56jjw0,Is it possible to mix Keras and Lasagne in Theano?,https://www.reddit.com/r/MachineLearning/comments/56jjw0/is_it_possible_to_mix_keras_and_lasagne_in_theano/,Laser_Plasma,1475968158,[removed],0,1
275,2016-10-9,2016,10,9,10,56k6dm,MIT Artificial Intelligence Lecture Videos,https://www.reddit.com/r/MachineLearning/comments/56k6dm/mit_artificial_intelligence_lecture_videos/,beeftug,1475977672,,0,2
276,2016-10-9,2016,10,9,13,56krpc,CS221: Artificial Intelligence: Principles and Techniques,https://www.reddit.com/r/MachineLearning/comments/56krpc/cs221_artificial_intelligence_principles_and/,shagunsodhani,1475987421,,0,1
277,2016-10-9,2016,10,9,13,56kufv,CS221: Artificial Intelligence: Principles and Techniques (stanford.edu),https://www.reddit.com/r/MachineLearning/comments/56kufv/cs221_artificial_intelligence_principles_and/,mikeyt21,1475988840,,0,1
278,2016-10-9,2016,10,9,16,56lak1,Is there mathematical proof for perceptron to be a linear classifier.,https://www.reddit.com/r/MachineLearning/comments/56lak1/is_there_mathematical_proof_for_perceptron_to_be/,hollydogeness,1475998753,[removed],0,1
279,2016-10-9,2016,10,9,16,56lby2,Does RNN work well for time series data like stock or IOT data?,https://www.reddit.com/r/MachineLearning/comments/56lby2/does_rnn_work_well_for_time_series_data_like/,jacky0812,1475999810,[removed],0,1
280,2016-10-9,2016,10,9,17,56ldjh,Keras Implementation of DCGAN on MNIST database,https://www.reddit.com/r/MachineLearning/comments/56ldjh/keras_implementation_of_dcgan_on_mnist_database/,[deleted],1476000960,[deleted],0,1
281,2016-10-9,2016,10,9,17,56lf0x,Keras implementation of DCGAN,https://www.reddit.com/r/MachineLearning/comments/56lf0x/keras_implementation_of_dcgan/,rk27518,1476002094,,1,1
282,2016-10-9,2016,10,9,18,56ljgq,Anyone at ODSC London?,https://www.reddit.com/r/MachineLearning/comments/56ljgq/anyone_at_odsc_london/,[deleted],1476005548,[removed],0,1
283,2016-10-9,2016,10,9,18,56lkuv,"Is it correct to say that Frequentist models are discriminative models and Bayesian models are generative models? Is it possible that Bayesian models can be discriminative and frequentist models can be generative? If yes, could you give an example?",https://www.reddit.com/r/MachineLearning/comments/56lkuv/is_it_correct_to_say_that_frequentist_models_are/,[deleted],1476006537,[removed],0,1
284,2016-10-9,2016,10,9,19,56llqb,"Is it correct to say that Frequentist models are discriminative models and Bayesian models are generative models? Is it possible that Bayesian models can be discriminative and frequentist models can be generative? If yes, could you give an example?",https://www.reddit.com/r/MachineLearning/comments/56llqb/is_it_correct_to_say_that_frequentist_models_are/,deepmind2016,1476007200,,3,4
285,2016-10-9,2016,10,9,20,56luf9,Most popular kaggle competition solutions,https://www.reddit.com/r/MachineLearning/comments/56luf9/most_popular_kaggle_competition_solutions/,dataaspirant,1476013125,,0,1
286,2016-10-9,2016,10,9,20,56lw41,"Is it correct to say that Frequentist models are discriminative models and Bayesian models are generative models? Is it possible that Bayesian models can be discriminative and frequentist models can be generative? If yes, could you give an example?",https://www.reddit.com/r/MachineLearning/comments/56lw41/is_it_correct_to_say_that_frequentist_models_are/,deepmind2016,1476014191,[removed],0,1
287,2016-10-9,2016,10,9,21,56lx42,"[Discussion] Is it correct to say that Frequentist models are discriminative models and Bayesian models are generative models? Is it possible that Bayesian models can be discriminative and frequentist models can be generative? If yes, could you give an example?",https://www.reddit.com/r/MachineLearning/comments/56lx42/discussion_is_it_correct_to_say_that_frequentist/,deepmind2016,1476014814,[removed],1,1
288,2016-10-9,2016,10,9,22,56m49l,image super-resolution by deep learning,https://www.reddit.com/r/MachineLearning/comments/56m49l/image_superresolution_by_deep_learning/,[deleted],1476018831,[removed],0,1
289,2016-10-9,2016,10,9,22,56m5ap,image super-resolution by deep learning,https://www.reddit.com/r/MachineLearning/comments/56m5ap/image_superresolution_by_deep_learning/,[deleted],1476019346,[removed],0,1
290,2016-10-9,2016,10,9,22,56m5o2,[Discussion] Calculation of bits/dims,https://www.reddit.com/r/MachineLearning/comments/56m5o2/discussion_calculation_of_bitsdims/,siddharth-agrawal,1476019521,What is the procedure for converting log-likelihood values to bits/dim? Clarification of just one example will be enough. The log-likelihood value reported in the NICE paper (https://arxiv.org/abs/1410.8516) for CIFAR-10 is 5371.78. The same value is reported as 4.48 in the PixelRNN paper (https://arxiv.org/abs/1601.06759).,7,9
291,2016-10-9,2016,10,9,22,56m68m,image super-resolution/anti-mosaic by deep model,https://www.reddit.com/r/MachineLearning/comments/56m68m/image_superresolutionantimosaic_by_deep_model/,[deleted],1476019789,[removed],0,1
292,2016-10-9,2016,10,9,22,56m7b5,[research] image super-resolution/anti-mosaic by deep learning,https://www.reddit.com/r/MachineLearning/comments/56m7b5/research_image_superresolutionantimosaic_by_deep/,godspeed_china,1476020324,[removed],1,0
293,2016-10-9,2016,10,9,23,56ma16,What is Adaptive Memory in Memory Networks?,https://www.reddit.com/r/MachineLearning/comments/56ma16/what_is_adaptive_memory_in_memory_networks/,leofed,1476021631,[removed],0,1
294,2016-10-9,2016,10,9,23,56mftg,"As an EE Engineering graduate, how likely is it that I can get a job in machine learning?",https://www.reddit.com/r/MachineLearning/comments/56mftg/as_an_ee_engineering_graduate_how_likely_is_it/,sealturkey,1476024042,[removed],0,1
295,2016-10-10,2016,10,10,0,56mk9y,[Project] A TensorFlow implementation of DeepMind's WaveNet paper,https://www.reddit.com/r/MachineLearning/comments/56mk9y/project_a_tensorflow_implementation_of_deepminds/,[deleted],1476025810,[deleted],0,1
296,2016-10-10,2016,10,10,0,56ml9j,[Project] A TensorFlow implementation of DeepMind's WaveNet paper,https://www.reddit.com/r/MachineLearning/comments/56ml9j/project_a_tensorflow_implementation_of_deepminds/,rmltestaccount,1476026192,,13,76
297,2016-10-10,2016,10,10,0,56mlre,"Less famous, but important machine learning scientists?",https://www.reddit.com/r/MachineLearning/comments/56mlre/less_famous_but_important_machine_learning/,[deleted],1476026392,[removed],0,1
298,2016-10-10,2016,10,10,0,56mm69,I don't think Donald Trump could pass the Turing Test,https://www.reddit.com/r/MachineLearning/comments/56mm69/i_dont_think_donald_trump_could_pass_the_turing/,[deleted],1476026557,[removed],0,1
299,2016-10-10,2016,10,10,2,56n8x9,[Project] Logistic Regression Gradient descent classifier has very low accuracy,https://www.reddit.com/r/MachineLearning/comments/56n8x9/project_logistic_regression_gradient_descent/,plasmalightwave,1476034547,"Hello! I've just started learning ML. I've been learning about Logistic Regression using Gradient descent. I followed two tutorials:

https://www.coursera.org/learn/machine-learning/home/week/3 http://nbviewer.jupyter.org/github/tfolkman/learningwithdata/blob/master/Logistic%20Gradient%20Descent.ipynb

I used the spambase dataset from UC Irvine's repo: https://archive.ics.uci.edu/ml/datasets/Spambase

The steps in my program are as follows:

    1. read data from the text file; num_features = 57, classes = 1 (spam=1, not-spam=0)
    2. Normalize feature matrix using (X-mean)/Std_Deviation
    3. Initialize parameters theta to zeros, learning rate to 0.01
    4. Train theta by running gradient descent while calculating cost; terminate when cost does not 
       change by more than 0.0001 AND at least 1500 iterations have run
    5. Test the classifier on the same input data set (predict output=1 if probability is &gt;=0.5)

However, my model/classifier has low accuracy (~52%) in it's prediction. I calculated accuracy by comparing how many data points the classifier got right and calculating the mean. I experimented with different learning rates/number of iterations but always get the same accuracy.

I'd really appreciate it if someone familiar with logistic regression could review my code and point where I'm going wrong:
https://github.com/codewarrior07/ml/blob/master/LogisticRegression_spambase.py

I also plotted the iterations vs cost using pyplot; I get the following result:
http://imgur.com/a/kjB09",6,8
300,2016-10-10,2016,10,10,4,56nq5x,[Research] Supervision via Competition: Robot Adversaries for Learning Tasks,https://www.reddit.com/r/MachineLearning/comments/56nq5x/research_supervision_via_competition_robot/,downtownslim,1476040313,,3,9
301,2016-10-10,2016,10,10,4,56nsgj,[Discussion] Computer algebra system for doing symbolic matrix calculus?,https://www.reddit.com/r/MachineLearning/comments/56nsgj/discussion_computer_algebra_system_for_doing/,poorasian,1476041109,"Can't seem to find anything. Most I've found is some guy's blog who wrote something for sympy a few years ago but I can't seem to get his code to run: https://zulko.wordpress.com/2012/04/15/symbolic-matrix-differentiation-with-sympy/

Ideally it would be able to do at least some of the stuff in the matrix cookbook (https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf) and then be able to apply stuff like the chain rule and product rule.",8,15
302,2016-10-10,2016,10,10,5,56nzd8,[Research] Perceptual Losses for Real-Time Style Transfer and Super-Resolution,https://www.reddit.com/r/MachineLearning/comments/56nzd8/research_perceptual_losses_for_realtime_style/,FusionGaming,1476043492,,6,17
303,2016-10-10,2016,10,10,5,56o5qa,[Discussion] Custom Loss Functions and Their Effects?,https://www.reddit.com/r/MachineLearning/comments/56o5qa/discussion_custom_loss_functions_and_their_effects/,FR_STARMER,1476045624,"So I've found that mean-squared error really halts learning after a certain amount of time because it's slope decreases exponentially towards zero. So it's really good for tuning in to about where it needs to be, but not good at really tweaking itself to 0.

So I added MSE to MAE in this function: x^2 + abs(x), so when the parabola starts to bottom out, it switched to the abs function. Neat! But the problem is that MAE has a super slow learning rate, and if your using data that produces all sorts of different losses, it's not really good. So I developed a new function: (x^2 + abs(x))^0.8, so it's a parabolic slope at large values, linear slope at smaller values, and an exponentially increasing slope for very small values. Does this type of function aid in gradient decent?

What should one be aiming for when choosing a loss function or writing their own? Other thoughts on loss functions in general?",12,1
304,2016-10-10,2016,10,10,6,56oade,An old Paper that attempted to understand neural network as space folding?,https://www.reddit.com/r/MachineLearning/comments/56oade/an_old_paper_that_attempted_to_understand_neural/,windweller,1476047211,[removed],0,1
305,2016-10-10,2016,10,10,6,56oieb,LIME: local interpretable model-agnostic explanations,https://www.reddit.com/r/MachineLearning/comments/56oieb/lime_local_interpretable_modelagnostic/,[deleted],1476050022,[deleted],0,8
306,2016-10-10,2016,10,10,7,56opb7,Dimension reduction on mixture of categorical and numerical variables?,https://www.reddit.com/r/MachineLearning/comments/56opb7/dimension_reduction_on_mixture_of_categorical_and/,[deleted],1476052566,[removed],0,1
307,2016-10-10,2016,10,10,9,56pbyk,Why we use information gain over accuracy as splitting criterion in decision tree?,https://www.reddit.com/r/MachineLearning/comments/56pbyk/why_we_use_information_gain_over_accuracy_as/,anshaikh,1476061125,"In decision tree classifier most of the algorithms use Information gain as spiting criterion. We select the feature with maximum information gain to split on.

I think that using accuracy instead of information gain is simpler approach. Is there any scenario where accuracy doesn't work and information gain does?

Can anyone explain what are the advantages of using Information gain over accuracy as splitting criterion?",3,3
308,2016-10-10,2016,10,10,10,56plkb,[1610.02357] Deep Learning with Separable Convolutions,https://www.reddit.com/r/MachineLearning/comments/56plkb/161002357_deep_learning_with_separable/,xternalz,1476064641,,13,22
309,2016-10-10,2016,10,10,11,56pp16,"Check out the project page of TA-FCN, the challenge wining entry of COCO segmentation challenge 2016",https://www.reddit.com/r/MachineLearning/comments/56pp16/check_out_the_project_page_of_tafcn_the_challenge/,[deleted],1476065891,[deleted],0,1
310,2016-10-10,2016,10,10,11,56pqur,"Check out TA-FCN, the wining entry of COCO segmentation challenge 2016!",https://www.reddit.com/r/MachineLearning/comments/56pqur/check_out_tafcn_the_wining_entry_of_coco/,[deleted],1476066552,[deleted],0,1
311,2016-10-10,2016,10,10,11,56psse,Check out MSRA's wining entry of COCO segmentation challenge 2016!,https://www.reddit.com/r/MachineLearning/comments/56psse/check_out_msras_wining_entry_of_coco_segmentation/,flyforlight,1476067231,,16,34
312,2016-10-10,2016,10,10,12,56q1a0,[Discussion] Does RNN work well for time series data like stock or IOT data?,https://www.reddit.com/r/MachineLearning/comments/56q1a0/discussion_does_rnn_work_well_for_time_series/,jacky0812,1476070153,"Pretty much most of the RNN related papers that I read are on text, speech or images data, is there any reason that we don't see much research on using RNN on time series data like stock market or IOT, sensor data?",33,48
313,2016-10-10,2016,10,10,13,56q6pq,[Discussion] Modeling uncertainty using deep learning models,https://www.reddit.com/r/MachineLearning/comments/56q6pq/discussion_modeling_uncertainty_using_deep/,bronzestick,1476072191,"In the existing literature of deep learning, is there any work that deals with capturing uncertainty like Bayesian models do? Like, for example, can they result in a predictive distribution that has low variance if the test point is similar to training data and has high variance if the test point differs greatly from the training data (think of being far in the input data space)",19,12
314,2016-10-10,2016,10,10,14,56qh8w,[Discussion] CNNs for Speech,https://www.reddit.com/r/MachineLearning/comments/56qh8w/discussion_cnns_for_speech/,iev6,1476076629,"Hello, Has anyone here tried using convolutional neural nets for speech signals? I need to check if CNNs work well for speaker identification, in comparison to the old fashioned feature extraction techniques. ",8,1
315,2016-10-10,2016,10,10,15,56qnga,Introduction to implementing Neural Networks using TensorFlow,https://www.reddit.com/r/MachineLearning/comments/56qnga/introduction_to_implementing_neural_networks/,john_philip,1476079667,,0,1
316,2016-10-10,2016,10,10,17,56r1s2,Intent and entity extraction,https://www.reddit.com/r/MachineLearning/comments/56r1s2/intent_and_entity_extraction/,kikesantos,1476088255,[removed],0,1
317,2016-10-10,2016,10,10,18,56r503,[Discussion] Top-down learning path: machine learning for software engineers,https://www.reddit.com/r/MachineLearning/comments/56r503/discussion_topdown_learning_path_machine_learning/,ZuzooVn,1476090470,,3,2
318,2016-10-10,2016,10,10,18,56r5y7,[discussion] All Markov Random Fields are log linear. True or false? Different sources suggest different answers.,https://www.reddit.com/r/MachineLearning/comments/56r5y7/discussion_all_markov_random_fields_are_log/,rd11235,1476091092,"From the Hammersley-Clifford theorem, we know that an undirected graph is compatible (same independence assumptions) with a distribution if and only if it can be factorized over cliques:

(1)    p(x) = 1 / Z   *   prod_c f_c(x_c)

Subtlety: The theorem only applies to distributions that are everywhere positive, which in turn means that we can represent p(x) using an exponential:

(2)    p(x) = 1 / Z   *   exp(  -sum_c f_c(x_c)  )

(These new f_c's are not the same as the old f_c's.)

Notice here that we can have model parameters inside the f_c's, and notice also that *we are not guaranteeing that the f_c's are linear in those parameters.*

This theorem is discussed in Bishop's book, in Geman and Geman's classic paper, and many other sources.

But some other sources, including but not limited to the [Wikipedia article on Markov Random Fields](https://en.wikipedia.org/wiki/Markov_random_field), state something else: that an undirected graph is compatible with a distribution if and only if the distribution has this form *and is log linear in its parameters*:

(3)    p(x) = 1 / Z   *   exp(  -sum_c,k   w_c,k * f_c,k(x_c)    )

with all of the f_c's being fixed functions (in other words, with no model parameters), and with k introduced to allow multiple feature functions per clique.

So is this last statement true or not? I'm leaning toward not but would like a definitive reference if someone has one.

Also, a toy example for discussion:

p(x_1, x_2) = 1 / Z   *   exp(  ReLU(w * x_1 + w * x_2)  )

We can verify that the independence properties are consistent with the graph x_1 ----- x_2.

If the x are discrete, I can imagine transforming (2) into (3) by building a huge table of possible values and reparameterizing using many more parameters, though this doesn't seem like it'd be useful in practice. But if the x are continuous, then I see no way to equate (2) and (3).",4,7
319,2016-10-10,2016,10,10,18,56r8ri,The State of AI  A Survey about Machine Learning in 2016,https://www.reddit.com/r/MachineLearning/comments/56r8ri/the_state_of_ai_a_survey_about_machine_learning/,[deleted],1476092991,[deleted],0,1
320,2016-10-10,2016,10,10,20,56rfe6,Derivation of REINFORCE algorithm from policy gradient theorem for episodic tasks?,https://www.reddit.com/r/MachineLearning/comments/56rfe6/derivation_of_reinforce_algorithm_from_policy/,[deleted],1476097219,[removed],0,1
321,2016-10-10,2016,10,10,20,56rhkl,Asynchronous methods for deep reinforcement learning,https://www.reddit.com/r/MachineLearning/comments/56rhkl/asynchronous_methods_for_deep_reinforcement/,chub79,1476098448,,0,1
322,2016-10-10,2016,10,10,20,56riwq,Dictionary Learning for Massive Matrix Factorization - RecsysFR,https://www.reddit.com/r/MachineLearning/comments/56riwq/dictionary_learning_for_massive_matrix/,Agagla,1476099207,,0,2
323,2016-10-10,2016,10,10,21,56rohg,[question] Derivation of REINFORCE from policy gradient theorem for the episodic case,https://www.reddit.com/r/MachineLearning/comments/56rohg/question_derivation_of_reinforce_from_policy/,[deleted],1476102019,[removed],0,1
324,2016-10-10,2016,10,10,22,56rv2l,Number recognition with Python (Machine Learning),https://www.reddit.com/r/MachineLearning/comments/56rv2l/number_recognition_with_python_machine_learning/,techresponses,1476104871,,0,1
325,2016-10-10,2016,10,10,22,56rx6w,Machine Learnings #12: AI for a dead friend,https://www.reddit.com/r/MachineLearning/comments/56rx6w/machine_learnings_12_ai_for_a_dead_friend/,beeftug,1476105726,,0,1
326,2016-10-10,2016,10,10,22,56ryw7,Two questions: 1. Has anyone tried playing a racing game against a neural net? 2. Has anyone tried 2 racing against each other?,https://www.reddit.com/r/MachineLearning/comments/56ryw7/two_questions_1_has_anyone_tried_playing_a_racing/,JamesS92,1476106439,[removed],0,1
327,2016-10-10,2016,10,10,22,56s2ky,Artificial intelligence is as powerful as recreating man,https://www.reddit.com/r/MachineLearning/comments/56s2ky/artificial_intelligence_is_as_powerful_as/,[deleted],1476107894,[deleted],0,1
328,2016-10-10,2016,10,10,22,56s2oa,[Discussion] Machine Learning - WAYR (What Are You Reading) - Week 10,https://www.reddit.com/r/MachineLearning/comments/56s2oa/discussion_machine_learning_wayr_what_are_you/,Mandrathax,1476107924,"This is a place to share machine learning research papers, journals, and articles that you're reading this week.
If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.  

|Previous weeks|
|--------------|
|[Week 1](https://www.reddit.com/r/MachineLearning/comments/4qyjiq/machine_learning_wayr_what_are_you_reading_week_1/)|  
|[Week 2](https://www.reddit.com/r/MachineLearning/comments/4s2xqm/machine_learning_wayr_what_are_you_reading_week_2/)|  
|[Week 3](https://www.reddit.com/r/MachineLearning/comments/4t7mqm/machine_learning_wayr_what_are_you_reading_week_3/)|  
|[Week 4](https://www.reddit.com/r/MachineLearning/comments/4ub2kw/machine_learning_wayr_what_are_you_reading_week_4/)| 
|[Week 5](https://www.reddit.com/r/MachineLearning/comments/4xomf7/machine_learning_wayr_what_are_you_reading_week_5/)| 
|[Week 6](https://www.reddit.com/r/MachineLearning/comments/4zcyvk/machine_learning_wayr_what_are_you_reading_week_6/)|
|[Week 7](https://www.reddit.com/r/MachineLearning/comments/52t6mo/machine_learning_wayr_what_are_you_reading_week_7/)|
|[Week 8](https://www.reddit.com/r/MachineLearning/comments/53heol/machine_learning_wayr_what_are_you_reading_week_8/)|
|[Week 9](https://www.reddit.com/r/MachineLearning/comments/54kvsu/machine_learning_wayr_what_are_you_reading_week_9/)|

Most upvoted papers last week : 

[Recursive Deep Learning for Natural Language Processing and Computer Vision](http://nlp.stanford.edu/~socherr/thesis.pdf)

[The Controlled Thermodynamic Integral for Bayesian Model Comparison](https://arxiv.org/abs/1404.5053)

Besides that, there are no rules, have fun.",21,40
329,2016-10-10,2016,10,10,23,56s65d,Good NLP library for parsing date ranges,https://www.reddit.com/r/MachineLearning/comments/56s65d/good_nlp_library_for_parsing_date_ranges/,MasterEpictetus,1476109170,[removed],0,1
330,2016-10-11,2016,10,11,0,56sk1t,Performance of Sequence-to-Sequence Models in tensor flow on a low spec machine,https://www.reddit.com/r/MachineLearning/comments/56sk1t/performance_of_sequencetosequence_models_in/,ark9gm,1476113781,,0,1
331,2016-10-11,2016,10,11,0,56soa7,Semantic segmentation code in Torch (zoomout model),https://www.reddit.com/r/MachineLearning/comments/56soa7/semantic_segmentation_code_in_torch_zoomout_model/,adagrad,1476115117,,0,6
332,2016-10-11,2016,10,11,1,56ss6k,Bandit Algorithms: A new beginning,https://www.reddit.com/r/MachineLearning/comments/56ss6k/bandit_algorithms_a_new_beginning/,cavedave,1476116288,,8,140
333,2016-10-11,2016,10,11,1,56st2s,[discussion] when is deep learning a bad idea?,https://www.reddit.com/r/MachineLearning/comments/56st2s/discussion_when_is_deep_learning_a_bad_idea/,Guanoco,1476116571,"Hello all,

It seems like there isn't a week in which deep learning doesn't come up as achieving some kind of remarkable task.
I understand that one of the powers of deep learning is that it is capable of learning the features. 
This capacity seems totally decoupled from the underlaying problem. So basically I read this as ""no matter what problem you have... You can use deep learning"". 

Now.. I know there must be a caveat. I just don't know which.
What kind of problems are not applicable for deep learning?",76,40
334,2016-10-11,2016,10,11,1,56stqk,Nengo Project and Deep Learning Research,https://www.reddit.com/r/MachineLearning/comments/56stqk/nengo_project_and_deep_learning_research/,cudeep,1476116776,[removed],0,1
335,2016-10-11,2016,10,11,2,56t1ct,Best Source Market Gigs Review Best PBN Gig Best Social Signal Gig Best Google Review Gig - YouT,https://www.reddit.com/r/MachineLearning/comments/56t1ct/best_source_market_gigs_review_best_pbn_gig_best/,phillidahancock,1476119031,,0,1
336,2016-10-11,2016,10,11,2,56t52a,[Discussion] Why does using random effects for an intercept only increase the number of parameters in your model by 2?,https://www.reddit.com/r/MachineLearning/comments/56t52a/discussion_why_does_using_random_effects_for_an/,NotAHomeworkQuestion,1476120120,"Suppose I've got a dataset with repeated measures within research subjects. I want to use a random intercept rather than fixed effects for the intercept term specific to the research subject. If I'd used fixed effects I'd have one parameter per research subject, but using random effects I'd have only two parameters total (the mean and SD of the normal distribution for the random effects). However, in the end, with random effects I still get one intercept estimate per subject along with standard errors for these intercept terms. Granted these have been shrunken toward the global mean, but shouldn't I still essentially have one parameter per subject?",2,1
337,2016-10-11,2016,10,11,2,56t6hi,WTF Pointer Networks,https://www.reddit.com/r/MachineLearning/comments/56t6hi/wtf_pointer_networks/,[deleted],1476120553,[removed],0,1
338,2016-10-11,2016,10,11,2,56t6zn,Hardware recommendation:i7 6700K vs i7 5820K,https://www.reddit.com/r/MachineLearning/comments/56t6zn/hardware_recommendationi7_6700k_vs_i7_5820k/,Spiral765,1476120707,[removed],0,1
339,2016-10-11,2016,10,11,2,56tabd,[Project] Visualize the probabilities assigned to a sentence by a neural language model word-by-word,https://www.reddit.com/r/MachineLearning/comments/56tabd/project_visualize_the_probabilities_assigned_to_a/,halfeatenscone,1476121684,,3,16
340,2016-10-11,2016,10,11,3,56tkpd,[Research][1610.02306] Optimization of Convolutional Neural Network using Microcanonical Annealing Algorithm,https://www.reddit.com/r/MachineLearning/comments/56tkpd/research161002306_optimization_of_convolutional/,hardmaru,1476124833,,11,0
341,2016-10-11,2016,10,11,4,56tqx9,Why does Prediction take a lot of time in this Tensorflow implementation of Wild ML?,https://www.reddit.com/r/MachineLearning/comments/56tqx9/why_does_prediction_take_a_lot_of_time_in_this/,azbtc,1476126533,[removed],0,1
342,2016-10-11,2016,10,11,4,56tzcu,Has anyone trained an SVM on the output of the layers of a Deep Convolutional Neural Net in order to Transfer Learn?,https://www.reddit.com/r/MachineLearning/comments/56tzcu/has_anyone_trained_an_svm_on_the_output_of_the/,tubaybb321,1476129060,[removed],0,1
343,2016-10-11,2016,10,11,4,56u0qz,Optimization metric in Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/56u0qz/optimization_metric_in_generative_adversarial/,FourthHead,1476129493,,0,1
344,2016-10-11,2016,10,11,5,56u2zs,How is the generator in a GAN trained?,https://www.reddit.com/r/MachineLearning/comments/56u2zs/how_is_the_generator_in_a_gan_trained/,FourthHead,1476130162,,0,1
345,2016-10-11,2016,10,11,6,56ugwq,"Slack, Amazon, AirBNB, Pinterest and Rajat Monga of TensorFlow are presenting at MLconf",https://www.reddit.com/r/MachineLearning/comments/56ugwq/slack_amazon_airbnb_pinterest_and_rajat_monga_of/,[deleted],1476134478,[deleted],1,1
346,2016-10-11,2016,10,11,7,56us9n,machine learning and software engineering skills,https://www.reddit.com/r/MachineLearning/comments/56us9n/machine_learning_and_software_engineering_skills/,mechanical_detergent,1476138181,[removed],0,1
347,2016-10-11,2016,10,11,7,56uskx,The Definitive Guide to Natural Language Processing (NLProc),https://www.reddit.com/r/MachineLearning/comments/56uskx/the_definitive_guide_to_natural_language/,wildcodegowrong,1476138285,,0,1
348,2016-10-11,2016,10,11,7,56uwvk,CMU Statistical Machine Learning Course Website,https://www.reddit.com/r/MachineLearning/comments/56uwvk/cmu_statistical_machine_learning_course_website/,adamnemecek,1476139767,,0,2
349,2016-10-11,2016,10,11,8,56v0ru,Using the DCGAN model to generate images from Blade Runner,https://www.reddit.com/r/MachineLearning/comments/56v0ru/using_the_dcgan_model_to_generate_images_from/,[deleted],1476141088,[deleted],0,1
350,2016-10-11,2016,10,11,8,56v2py,Using the DCGAN model to generate images from Blade Runner,https://www.reddit.com/r/MachineLearning/comments/56v2py/using_the_dcgan_model_to_generate_images_from/,Staturecrane,1476141764,,0,1
351,2016-10-11,2016,10,11,9,56v8s6,How Could I write an ML that scores through my files and writes a paper for me based on my labelled research? I am pretty good at coding but am terrible at writing papers.,https://www.reddit.com/r/MachineLearning/comments/56v8s6/how_could_i_write_an_ml_that_scores_through_my/,belangrijk,1476144037,[removed],0,1
352,2016-10-11,2016,10,11,9,56v99e,[Project] Created a classifier to diagnose language impairment in children. Predicting correct 100% of the time.,https://www.reddit.com/r/MachineLearning/comments/56v99e/project_created_a_classifier_to_diagnose_language/,lankks,1476144226,"I've been working on creating a binary text classifier for diagnosing language impaired children using the CHILDES corpus. I've been using the package polyssifier (https://github.com/alvarouc/polyssifier) to create and test the data and recently after adding a few extra features most of my classifiers have been predicting the correct result 100% of the time.

Surely this can't be right? What can I do to check the validity of this result?

http://imgur.com/a/reagU",4,3
353,2016-10-11,2016,10,11,9,56vbd7,"[news] Rajat Monga of TensorFlow is presenting at MLconf with Slack, Amazon, AirBNB, Pinterest",https://www.reddit.com/r/MachineLearning/comments/56vbd7/news_rajat_monga_of_tensorflow_is_presenting_at/,shonburton,1476145002,,3,0
354,2016-10-11,2016,10,11,9,56vbnq,Analyze many strings for patterns?,https://www.reddit.com/r/MachineLearning/comments/56vbnq/analyze_many_strings_for_patterns/,kwhali,1476145114,[removed],0,1
355,2016-10-11,2016,10,11,10,56vm92,[discussion] What are best practices for incorporating high information semantic features in Deep Neural Networks?,https://www.reddit.com/r/MachineLearning/comments/56vm92/discussion_what_are_best_practices_for/,[deleted],1476149063,[deleted],0,1
356,2016-10-11,2016,10,11,10,56vq1l,[Discussion] Static source code/ unit-test complexity measure of choice? Cyclomatic v. Synchronization,https://www.reddit.com/r/MachineLearning/comments/56vq1l/discussion_static_source_code_unittest_complexity/,intellidumb,1476150518,[removed],0,1
357,2016-10-11,2016,10,11,12,56w7yj,AI beat maker / music producer,https://www.reddit.com/r/MachineLearning/comments/56w7yj/ai_beat_maker_music_producer/,Kyuri_San,1476157517,[removed],0,1
358,2016-10-11,2016,10,11,16,56wuna,GitHub topic modeling,https://www.reddit.com/r/MachineLearning/comments/56wuna/github_topic_modeling/,markovtsev,1476169211,,0,1
359,2016-10-11,2016,10,11,16,56ww63,[Discussion] What are the tools used for creating Instance Segmentation and Localisation Dataset?,https://www.reddit.com/r/MachineLearning/comments/56ww63/discussion_what_are_the_tools_used_for_creating/,code2hell,1476170103,I am planning to create a dataset for instance segmentation for a specific purpose. I would really appreciate if someone can post the tools that can be used for creation os such dataset. Thanks.,7,4
360,2016-10-11,2016,10,11,16,56wxo2,Powder mixer can be used as spiral mixer,https://www.reddit.com/r/MachineLearning/comments/56wxo2/powder_mixer_can_be_used_as_spiral_mixer/,mixmachinery,1476171091,,1,1
361,2016-10-11,2016,10,11,16,56wylh,X l li bm nc trong my lc nc gia nh,https://www.reddit.com/r/MachineLearning/comments/56wylh/x_l_li_bm_nc_trong_my_lc_nc_gia_nh/,Lillianfann,1476171690,,0,1
362,2016-10-11,2016,10,11,17,56x1c2,Neural Assisted Painting - Happy Trees!,https://www.reddit.com/r/MachineLearning/comments/56x1c2/neural_assisted_painting_happy_trees/,whereissarahconner,1476173722,,0,1
363,2016-10-11,2016,10,11,17,56x4c0,[Discussion] notes on the Neuroscience and AI Session of SOCML 2016 @OpenAI,https://www.reddit.com/r/MachineLearning/comments/56x4c0/discussion_notes_on_the_neuroscience_and_ai/,evc123,1476175881,,6,24
364,2016-10-11,2016,10,11,19,56xcvn,[Research] Synthesizing the preferred inputs for neurons in neural networks via deep generator networks,https://www.reddit.com/r/MachineLearning/comments/56xcvn/research_synthesizing_the_preferred_inputs_for/,pmigdal,1476181516,,7,28
365,2016-10-11,2016,10,11,19,56xfuf,What is rtv and acid silicone sealant automatic filling and package system,https://www.reddit.com/r/MachineLearning/comments/56xfuf/what_is_rtv_and_acid_silicone_sealant_automatic/,mixmachinery,1476183460,,1,1
366,2016-10-11,2016,10,11,20,56xggz,[Project] Easily Create High Quality Object Detectors with Deep Learning,https://www.reddit.com/r/MachineLearning/comments/56xggz/project_easily_create_high_quality_object/,davis685,1476183814,,12,21
367,2016-10-11,2016,10,11,20,56xh5f,[question] how much of machine learning knowledge do I need to know as an intern?,https://www.reddit.com/r/MachineLearning/comments/56xh5f/question_how_much_of_machine_learning_knowledge/,Timelord_42,1476184203,[removed],0,1
368,2016-10-11,2016,10,11,20,56xkhh,[discussion] What are best practices for incorporating high information semantic features in Deep Neural Networks?,https://www.reddit.com/r/MachineLearning/comments/56xkhh/discussion_what_are_best_practices_for/,Megatron_McLargeHuge,1476186072,"Suppose you have image metadata you want to incorporate into a classifier, want to train an RNN over categorical data, or simply want a reference result for a problem where you expect SVM or RF to do best.  

How do you preprocess the data and what transforms and architectures are known to work well?

If you're incorporating high information features with image/audio data where you need the network to learn to extract features, how would you structure the model?",9,11
369,2016-10-11,2016,10,11,20,56xm7b,What is Contextual Embedding?,https://www.reddit.com/r/MachineLearning/comments/56xm7b/what_is_contextual_embedding/,stacky777,1476186989,[removed],0,1
370,2016-10-11,2016,10,11,20,56xmhr,Simple Swift AI - A simple to use Neural Network written in Swift 3.0. Can be used with minimal setup. Your feedback will be appreciated.,https://www.reddit.com/r/MachineLearning/comments/56xmhr/simple_swift_ai_a_simple_to_use_neural_network/,thewebmaker,1476187141,,0,1
371,2016-10-11,2016,10,11,21,56xohj,Ice crusher machine with affordable Price,https://www.reddit.com/r/MachineLearning/comments/56xohj/ice_crusher_machine_with_affordable_price/,amitkashyap031,1476188049,,0,1
372,2016-10-11,2016,10,11,21,56xqgd,light vehicle maintenance services,https://www.reddit.com/r/MachineLearning/comments/56xqgd/light_vehicle_maintenance_services/,realtywest121,1476188946,,0,1
373,2016-10-11,2016,10,11,22,56y2t2,Elon Musk's OpenAI is Using Reddit to Teach An Artificial Intelligence How to Speak,https://www.reddit.com/r/MachineLearning/comments/56y2t2/elon_musks_openai_is_using_reddit_to_teach_an/,beeftug,1476193870,,1,1
374,2016-10-11,2016,10,11,23,56yaku,[Research] cleverhans v0.1: an adversarial machine learning library,https://www.reddit.com/r/MachineLearning/comments/56yaku/research_cleverhans_v01_an_adversarial_machine/,downtownslim,1476196647,,1,18
375,2016-10-11,2016,10,11,23,56ych1,PMML: a way for analytic applications to describe and exchange predictive models produced by machine learning algorithms.,https://www.reddit.com/r/MachineLearning/comments/56ych1/pmml_a_way_for_analytic_applications_to_describe/,Sergiointelnics,1476197293,,0,1
376,2016-10-11,2016,10,11,23,56yeab,Open Sourcing 223GB of Driving Data,https://www.reddit.com/r/MachineLearning/comments/56yeab/open_sourcing_223gb_of_driving_data/,Dogsindahouse1,1476197894,,0,1
377,2016-10-12,2016,10,12,0,56ykiq,Is it OK to publish results only in the validation set if are only caring about the ordering of the results?,https://www.reddit.com/r/MachineLearning/comments/56ykiq/is_it_ok_to_publish_results_only_in_the/,andrewbarto28,1476199853,[removed],0,1
378,2016-10-12,2016,10,12,0,56yle3,[Discussion] Is it OK to publish results only in the validation set if are only caring about the ordering of the results?,https://www.reddit.com/r/MachineLearning/comments/56yle3/discussion_is_it_ok_to_publish_results_only_in/,andrewbarto28,1476200117,"I have several methods and for each one I am selecting hyperparameters in the same validation set. I know that the accuracies obtained in the validation set will be higher than the real ones, but will ordering of the results in the validation set represent the real ordering? In other words, if I want to show which method is better than the other, is it fine to just compare the validation accuracy of the best hyperparameter for each method?",3,2
379,2016-10-12,2016,10,12,0,56ynmx,Honeypot Turing Test,https://www.reddit.com/r/MachineLearning/comments/56ynmx/honeypot_turing_test/,arshakn,1476200858,,0,1
380,2016-10-12,2016,10,12,0,56ynyv,"Why bayes rule works differently, when we use integration and summation in the denominator to normalize?",https://www.reddit.com/r/MachineLearning/comments/56ynyv/why_bayes_rule_works_differently_when_we_use/,[deleted],1476200970,[removed],0,1
381,2016-10-12,2016,10,12,0,56ypvu,"[Discussion] Why bayes rule works differently, when we use integration and summation in the denominator to normalize?",https://www.reddit.com/r/MachineLearning/comments/56ypvu/discussion_why_bayes_rule_works_differently_when/,deepmind2016,1476201575,[removed],0,0
382,2016-10-12,2016,10,12,1,56yqju,[Project] Using Keras and Deep Deterministic Policy Gradient to play TORCS,https://www.reddit.com/r/MachineLearning/comments/56yqju/project_using_keras_and_deep_deterministic_policy/,hardmaru,1476201773,,8,45
383,2016-10-12,2016,10,12,1,56yt6s,"A clear, 20 minute intro to topological data analysis",https://www.reddit.com/r/MachineLearning/comments/56yt6s/a_clear_20_minute_intro_to_topological_data/,[deleted],1476202537,[deleted],0,1
384,2016-10-12,2016,10,12,1,56ytoz,"[Research] A simple, 20 minute introduction to topological data analysis",https://www.reddit.com/r/MachineLearning/comments/56ytoz/research_a_simple_20_minute_introduction_to/,gabrielgoh,1476202703,,24,84
385,2016-10-12,2016,10,12,2,56z29t,Join Us at /r/LearnMachineLearning!,https://www.reddit.com/r/MachineLearning/comments/56z29t/join_us_at_rlearnmachinelearning/,[deleted],1476205393,[removed],0,1
386,2016-10-12,2016,10,12,2,56zb8v,"There is no valid argument for ROC/AUC charts to show the 50/50 line as reference. There is a supervised learning dataset on hand, which has some global mean for its majority class as the correct model to beat for that dataset.",https://www.reddit.com/r/MachineLearning/comments/56zb8v/there_is_no_valid_argument_for_rocauc_charts_to/,datasciguy-aaay,1476208059,[removed],0,1
387,2016-10-12,2016,10,12,2,56zbbn,"[Discussion] Hugo Larochelle's neural network &amp; deep learning tutorial videos, subtitled &amp; screengrabbed",https://www.reddit.com/r/MachineLearning/comments/56zbbn/discussion_hugo_larochelles_neural_network_deep/,Prooffread3r,1476208079,,5,44
388,2016-10-12,2016,10,12,3,56zfy8,Video lectures: Statistical Machine Learning by Larry Wasserman (CMU) [educational],https://www.reddit.com/r/MachineLearning/comments/56zfy8/video_lectures_statistical_machine_learning_by/,dataoverflow,1476209473,,0,1
389,2016-10-12,2016,10,12,3,56zgpb,Is gradual pooling no longer the preferred architecture?,https://www.reddit.com/r/MachineLearning/comments/56zgpb/is_gradual_pooling_no_longer_the_preferred/,ill-logical,1476209691,"It used to be that ConvNets would use 2x2 pooling every few layers: the number of channels would grow, while the dimensions of the image would decrease all the way to 4x4 or less.

However, now, with the [Xception](https://arxiv.org/abs/1610.02357) architecture, I'm seeing lots of pooling in the beginning (299x299 -&gt; 18x18), no pooling in most of the network, and lots of pooling at the end (18x18 -&gt; 1x1).

Is there a justification for this? Pinging my reddit friend, /u/fchollet.

**Edit** post not showing up; mods notified",4,21
390,2016-10-12,2016,10,12,3,56zj07,Trying to find a start-up opportunity in the emerging eSports industry. Any suggestions?,https://www.reddit.com/r/MachineLearning/comments/56zj07/trying_to_find_a_startup_opportunity_in_the/,Obi_Wan_Kenobi,1476210422,[removed],0,1
391,2016-10-12,2016,10,12,5,5703ra,TensorFlow implementation of Neural Style,https://www.reddit.com/r/MachineLearning/comments/5703ra/tensorflow_implementation_of_neural_style/,[deleted],1476216760,[deleted],0,1
392,2016-10-12,2016,10,12,5,5709lc,Music Clip artified by myself - LP Lost on You,https://www.reddit.com/r/MachineLearning/comments/5709lc/music_clip_artified_by_myself_lp_lost_on_you/,erogol,1476218583,,0,1
393,2016-10-12,2016,10,12,6,570eeb,[Project] The State of AI: An open-data survey about machine learning in 2016,https://www.reddit.com/r/MachineLearning/comments/570eeb/project_the_state_of_ai_an_opendata_survey_about/,syllogism_,1476220031,,1,15
394,2016-10-12,2016,10,12,6,570eia,[snoeswes] test post,https://www.reddit.com/r/MachineLearning/comments/570eia/snoeswes_test_post/,rmltestaccount,1476220066,[removed],0,1
395,2016-10-12,2016,10,12,6,570ern,[sNoeswes] Test post,https://www.reddit.com/r/MachineLearning/comments/570ern/snoeswes_test_post/,rmltestaccount,1476220145,[removed],0,1
396,2016-10-12,2016,10,12,6,570exj,News test post,https://www.reddit.com/r/MachineLearning/comments/570exj/news_test_post/,rmltestaccount,1476220187,[removed],0,1
397,2016-10-12,2016,10,12,6,570hcu,[R] Oracle Performance for Visual Captioning,https://www.reddit.com/r/MachineLearning/comments/570hcu/r_oracle_performance_for_visual_captioning/,rmltestaccount,1476220951,,0,1
398,2016-10-12,2016,10,12,6,570iwk,[PROJECT]: Improved Tensorflow implementation of Neural Style,https://www.reddit.com/r/MachineLearning/comments/570iwk/project_improved_tensorflow_implementation_of/,c_y_smith,1476221438,,10,34
399,2016-10-12,2016,10,12,6,570jxu,[Project] Curated Menu of Machine Learning resources separated by category and difficulty level. Hover over Free Lectures.,https://www.reddit.com/r/MachineLearning/comments/570jxu/project_curated_menu_of_machine_learning/,Mathriddle,1476221786,,1,8
400,2016-10-12,2016,10,12,6,570m3m,Face Recognition: Neural Nets vs Eigenfaces vs SVMs vs Deep Learning/Nets?,https://www.reddit.com/r/MachineLearning/comments/570m3m/face_recognition_neural_nets_vs_eigenfaces_vs/,[deleted],1476222507,[removed],0,1
401,2016-10-12,2016,10,12,7,570ob4,Ongoing self-driving car research (livestream),https://www.reddit.com/r/MachineLearning/comments/570ob4/ongoing_selfdriving_car_research_livestream/,vanboxel,1476223244,,0,1
402,2016-10-12,2016,10,12,7,570pkw,[Project] Analyzing 50k fonts using deep neural networks  Erik Bernhardsson,https://www.reddit.com/r/MachineLearning/comments/570pkw/project_analyzing_50k_fonts_using_deep_neural/,mimighost,1476223656,,17,152
403,2016-10-12,2016,10,12,7,570rf9,Use Keras/TF-Slim to study research papers ? Or from scratch ?,https://www.reddit.com/r/MachineLearning/comments/570rf9/use_kerastfslim_to_study_research_papers_or_from/,[deleted],1476224285,[removed],0,1
404,2016-10-12,2016,10,12,7,570sv7,[D] Use Keras/TF-Slim to study research papers ? Or from scratch ?,https://www.reddit.com/r/MachineLearning/comments/570sv7/d_use_kerastfslim_to_study_research_papers_or/,xingdongrobotics,1476224774,"As an example of mine, I am doing a semester project related to GAN with possible variations, and currently I am reading GAN, DCGAN papers, and would like to write the code compatible to original paper as a preparation to my own project. 

I tried several days, and realize that if I want to write code from scratch, it will take too much time before getting an executable network, (e.g. only under numpy and tensorflow). So I would like to listen to advice that if it is still recommend to just use Keras/TF-Slim to ease and accelerate the implementation, and when it is done, then to write detailed code in a ""top-down"" fashion. 

The main reason why I hesitate to either write code totally from scratch or simply use TF-Slim/Keras, is that I found many recent paper authors' repo actually does not often use these high-level wrapper, but include lots of detailed code. ",4,9
405,2016-10-12,2016,10,12,11,571y97,How is Adversarial AutoEncoder different from Autoencoding Beyond Pixels using a Learned Similarity Metric (VAE/GAN),https://www.reddit.com/r/MachineLearning/comments/571y97/how_is_adversarial_autoencoder_different_from/,leehomyc,1476239982,[removed],0,1
406,2016-10-12,2016,10,12,12,57221x, NFP100 Tabletop Piston Pump Liquid Filler,https://www.reddit.com/r/MachineLearning/comments/57221x/_nfp100_tabletop_piston_pump_liquid/,neostarpack,1476241447,,0,1
407,2016-10-12,2016,10,12,12,57253r,[Project] I wrote a simple machine learning library for imgur.com based on introductory ML concepts I'd learned in school. It can be quickly ported to other APIs.,https://www.reddit.com/r/MachineLearning/comments/57253r/project_i_wrote_a_simple_machine_learning_library/,HazrMard,1476242652,,0,3
408,2016-10-12,2016,10,12,12,5725kd,[Research] Fully Character-Level Neural Machine Translation without Explicit Segmentation,https://www.reddit.com/r/MachineLearning/comments/5725kd/research_fully_characterlevel_neural_machine/,onekonek,1476242846,,2,46
409,2016-10-12,2016,10,12,12,5728vi,"Convnets, bag of words, and sift",https://www.reddit.com/r/MachineLearning/comments/5728vi/convnets_bag_of_words_and_sift/,testingTestingIBS,1476244265,"I think convets are essentially like a bag of words classifier but the vocabulary is defined by the network and not pre-specified like in HoG.

What I think would be a more powerful recognition system is to use bag of words with something like SIFT.  First you see how many feature vectors match and then you see if the constellation of matching points is some kind of rigid deformation like affine.

What do people think about this?",8,0
410,2016-10-12,2016,10,12,13,572bn3,Race against the machine learning,https://www.reddit.com/r/MachineLearning/comments/572bn3/race_against_the_machine_learning/,julian88888888,1476245453,,2,2
411,2016-10-12,2016,10,12,13,572c90,Does Googlenet work if the images are upside down or rotated 90 degrees?,https://www.reddit.com/r/MachineLearning/comments/572c90/does_googlenet_work_if_the_images_are_upside_down/,testingTestingIBS,1476245706,[removed],0,1
412,2016-10-12,2016,10,12,16,572vri, NLT110 Tabletop Top Labeling Machine https://www.neostarpack.com/en/product/NLT-100.html,https://www.reddit.com/r/MachineLearning/comments/572vri/_nlt110_tabletop_top_labeling_machine/,neostarpack,1476255922,,0,1
413,2016-10-12,2016,10,12,16,572wkn,[Project] I want my Neural Network to play computer games. How to input screen data and output control data?,https://www.reddit.com/r/MachineLearning/comments/572wkn/project_i_want_my_neural_network_to_play_computer/,Always2ndPlaceInGame,1476256413,[removed],8,8
414,2016-10-12,2016,10,12,16,572yib,A Dropout variant that accelerates training like Batch Norm [NIPS 2016 paper],https://www.reddit.com/r/MachineLearning/comments/572yib/a_dropout_variant_that_accelerates_training_like/,[deleted],1476257585,[deleted],0,1
415,2016-10-12,2016,10,12,17,5733a3,Whisky16 - World's first LIVE video style transfer,https://www.reddit.com/r/MachineLearning/comments/5733a3/whisky16_worlds_first_live_video_style_transfer/,[deleted],1476260707,[deleted],1,1
416,2016-10-12,2016,10,12,17,573428,Automatic Labeling Machine ,https://www.reddit.com/r/MachineLearning/comments/573428/automatic_labeling_machine_/,neostarpack,1476261276,,0,1
417,2016-10-12,2016,10,12,18,5736po,[Project] Whisky16 - World's first LIVE video style transfer,https://www.reddit.com/r/MachineLearning/comments/5736po/project_whisky16_worlds_first_live_video_style/,pavelgonchar,1476263121,,2,0
418,2016-10-12,2016,10,12,18,573a8e,[Research] Driving in the Matrix: Can Virtual Worlds Replace Human-Generated Annotations for Real World Tasks?,https://www.reddit.com/r/MachineLearning/comments/573a8e/research_driving_in_the_matrix_can_virtual_worlds/,sybilckw,1476265457,,14,35
419,2016-10-12,2016,10,12,19,573d2l,[Discussion] Summer Projects for math undergraduates in Machine Learning,https://www.reddit.com/r/MachineLearning/comments/573d2l/discussion_summer_projects_for_math/,guukizl,1476267223,"This is mostly related to academia I guess. 

I am just gonna get it out and humiliate myself. 

I just wanted to ask if such a thing happens where in Math undergraduates (senior) are doing internships in ML. Consider my example, like I have taken courses in Statistics (two in number covering theoretical statistics ('statistical inference' by casella and berger)), linear algebra, calc apart from other pure math courses(eg.analysis) and have had experience with specifically use of Neural networks in ML in my last summer (you can pretty much sum that up by [Neural Networks and Deep Learning](http://www.neuralnetworksanddeeplearning.com) and recently I had experience in appying RNNs (used LSTMs anyway) for time series data (a semester project). 


So is it, that it is too soon (like I haven't had formal intro to Statistical Learning or Optimization yet) for me to get into any ""math"" intensive i don't know research/project in ML and only masters and phd people do this kind of stuff or are math people (undergrads) getting into ML which is not just all about application?


I guess by a math undergraduate I also mean that he/she is not your classic programmer/cs major. As in he/she is able to implement anything in say python (or R) but he/she just would be much more interested in the mathematical intricacies of the models itself rather than cool implementations and usage of these algorithms on real data and analysing them. 

Thank you.

",8,1
420,2016-10-12,2016,10,12,19,573eh2,"If I wanted to go into an Artificial Intelligence or Machine Learning Grad program, what should I major in?",https://www.reddit.com/r/MachineLearning/comments/573eh2/if_i_wanted_to_go_into_an_artificial_intelligence/,GiveEmMoZo,1476268059,[removed],0,1
421,2016-10-12,2016,10,12,20,573ls6,Best site for datasets,https://www.reddit.com/r/MachineLearning/comments/573ls6/best_site_for_datasets/,data_sagan,1476272243,[removed],0,1
422,2016-10-12,2016,10,12,21,573pme,Best Cat D10R For Sale,https://www.reddit.com/r/MachineLearning/comments/573pme/best_cat_d10r_for_sale/,jenetjess,1476274074,,0,1
423,2016-10-12,2016,10,12,21,573pwr,[Project] Predicting Student Demand at Lingo Live,https://www.reddit.com/r/MachineLearning/comments/573pwr/project_predicting_student_demand_at_lingo_live/,edderic,1476274194,,0,1
424,2016-10-13,2016,10,13,0,574kaz,accidentes sorprendentes falla videos de equipo pesado de construccin 2016,https://www.reddit.com/r/MachineLearning/comments/574kaz/accidentes_sorprendentes_falla_videos_de_equipo/,ems204,1476285175,,0,1
425,2016-10-13,2016,10,13,0,574lyp,"[Research] Special Topics in Deep Learning @UCBerkeley, amazing speaker lineup",https://www.reddit.com/r/MachineLearning/comments/574lyp/research_special_topics_in_deep_learning/,ResNets,1476285683,,2,26
426,2016-10-13,2016,10,13,0,574ppo,[P] Let's make a DQN - Thorough multipart tutorial about DQN,https://www.reddit.com/r/MachineLearning/comments/574ppo/p_lets_make_a_dqn_thorough_multipart_tutorial/,jaromiru,1476286819,,6,21
427,2016-10-13,2016,10,13,0,574ryk,"Simple Questions Thread October 12, 2016",https://www.reddit.com/r/MachineLearning/comments/574ryk/simple_questions_thread_october_12_2016/,AutoModerator,1476287542,"Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!

Thread will stay alive until next one so keep posting after the date in the title.

Thanks to everyone for answering questions in the previous thread!
",18,9
428,2016-10-13,2016,10,13,1,574usi,[Discussion] What do you use for Neural Network Diagramming,https://www.reddit.com/r/MachineLearning/comments/574usi/discussion_what_do_you_use_for_neural_network/,slap_bet,1476288410,"I'm currently writing a couple of papers which use CNNs and one thing I really struggle with is making nice looking diagrams that are actually clear. I've seen figures in other papers (for example, picturing convolutional layers as cubes, stuff like that) that seem to be very clear but I haven't really figured out 1) what they're using to make those and 2) there is not really an agreed upon style for enumerating and illustrating network design. Does anyone have any light to shed here, is there a drawing tool (LaTeX compatible) that is good for this kind of thing or is it just lots and lots of tikz?",30,9
429,2016-10-13,2016,10,13,2,575622,New Nature paper by DeepMind: Hybrid Computing using a Neural Network with Dynamic External Memory,https://www.reddit.com/r/MachineLearning/comments/575622/new_nature_paper_by_deepmind_hybrid_computing/,[deleted],1476291782,[deleted],0,2
430,2016-10-13,2016,10,13,2,5756sy,Most interesting ML area other than Deep Learning and Reinforcement learning ?,https://www.reddit.com/r/MachineLearning/comments/5756sy/most_interesting_ml_area_other_than_deep_learning/,[deleted],1476291985,[removed],0,1
431,2016-10-13,2016,10,13,2,575a4v,Why does Prediction take a lot of time in this (Wild ML) implementation of Tensorflow?,https://www.reddit.com/r/MachineLearning/comments/575a4v/why_does_prediction_take_a_lot_of_time_in_this/,azbtc,1476292961,[removed],0,1
432,2016-10-13,2016,10,13,2,575az3,Hybrid computing using a neural network with dynamic external memory : Nature Research,https://www.reddit.com/r/MachineLearning/comments/575az3/hybrid_computing_using_a_neural_network_with/,RushAndAPush,1476293206,,0,1
433,2016-10-13,2016,10,13,2,575c7l,[Research] Hybrid computing using a neural network with dynamic external memory,https://www.reddit.com/r/MachineLearning/comments/575c7l/research_hybrid_computing_using_a_neural_network/,clbam8,1476293567,,25,51
434,2016-10-13,2016,10,13,2,575fgp,Effectively running thousands of experiments: Hyperopt with Sacred,https://www.reddit.com/r/MachineLearning/comments/575fgp/effectively_running_thousands_of_experiments/,amplifier_khan,1476294525,,0,1
435,2016-10-13,2016,10,13,2,575hlx,[Research] New Nature paper by DeepMind: Hybrid Computing using a Neural Network with Dynamic External Memory,https://www.reddit.com/r/MachineLearning/comments/575hlx/research_new_nature_paper_by_deepmind_hybrid/,egrefen,1476295159,,47,250
436,2016-10-13,2016,10,13,3,575jz8,[Discussion] Join us on /r/LearnMachineLearning!,https://www.reddit.com/r/MachineLearning/comments/575jz8/discussion_join_us_on_rlearnmachinelearning/,techrat_reddit,1476295836,"Hello, fellow aficionados of machine learning!

/r/LearnMachineLearning aims to provide a friendly environment to learn machine learning for redditors of various machine learning backgrounds. Whether you are a complete beginner who would like to begin your first machine learning project or a machine learning expert who wants to expand your boundary, anyone who wishes to *learn* machine learning is welcome. 

Feel free to share any educational resources of machine learning. An educational resource could be anything from a professional blog article to tips you would like to share to the fellow redditors. 

Also, we are a beginner-friendly subreddit, so don't be afraid to ask questions! This can include questions that are non-technical such as a systematic approach to a machine learning problem. 

If you have any questions or suggestions, please dont hesitate to comment on this thread or [the welcoming page](https://www.reddit.com/r/learnmachinelearning/comments/56vloc/welcome_to_rlearnmachinelearning/) at /r/LearnMachineLearning",36,69
437,2016-10-13,2016,10,13,3,575prv,Obama and Joi Ito of MIT Media Lab discuss AI,https://www.reddit.com/r/MachineLearning/comments/575prv/obama_and_joi_ito_of_mit_media_lab_discuss_ai/,em00guy,1476297566,,0,1
438,2016-10-13,2016,10,13,6,576qwf,Strategies for feature generation from raw data,https://www.reddit.com/r/MachineLearning/comments/576qwf/strategies_for_feature_generation_from_raw_data/,youngerelder,1476308925,[removed],0,1
439,2016-10-13,2016,10,13,6,576qzx,Making Waves In Deep Learning--How deep learning applications will map onto a chip.,https://www.reddit.com/r/MachineLearning/comments/576qzx/making_waves_in_deep_learninghow_deep_learning/,[deleted],1476308956,[deleted],0,1
440,2016-10-13,2016,10,13,6,576sq2,Deep Learning GPU Benchmarks: GTX 1080 vs. Titan X Pascal,https://www.reddit.com/r/MachineLearning/comments/576sq2/deep_learning_gpu_benchmarks_gtx_1080_vs_titan_x/,capn3m0,1476309535,[removed],0,1
441,2016-10-13,2016,10,13,7,576t5t,"[research] [question] What's a good tool to write Neural Language Models, for learning purposes?",https://www.reddit.com/r/MachineLearning/comments/576t5t/research_question_whats_a_good_tool_to_write/,orange_robot338,1476309683,"I need something that I can reproduce paper results and experiment myself with different architectures and tuning, extracting embeddings and that sort of thing.

I'm most familiar with Keras but I'm ok with not using it if isn't suitable for this. I know of a couple of frameworks such as TF, TF-Learn, TF-Slim, Theano so I'd like suggestions on which ones I should use. 

Thank you very much.
",4,2
442,2016-10-13,2016,10,13,7,576ycp,Machine Learning for Electronics?,https://www.reddit.com/r/MachineLearning/comments/576ycp/machine_learning_for_electronics/,jgm_315,1476311429,[removed],0,1
443,2016-10-13,2016,10,13,9,577j4n,[Discussion] Obama on the Future of Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/577j4n/discussion_obama_on_the_future_of_artificial/,evc123,1476318919,[removed],0,0
444,2016-10-13,2016,10,13,10,577pow,Transfer from Simulation to Real World through Learning Deep Inverse Dynamics Model [OpenAI],https://www.reddit.com/r/MachineLearning/comments/577pow/transfer_from_simulation_to_real_world_through/,gwulfs,1476321337,,0,2
445,2016-10-13,2016,10,13,12,578ef0,What is the current state of the art in sentence embeddings?,https://www.reddit.com/r/MachineLearning/comments/578ef0/what_is_the_current_state_of_the_art_in_sentence/,sprintletecity,1476331086,[removed],0,1
446,2016-10-13,2016,10,13,13,578iez,Are applications such as MARI/O learning or guessing?,https://www.reddit.com/r/MachineLearning/comments/578iez/are_applications_such_as_mario_learning_or/,DrEmpyrean,1476332811,[removed],0,1
447,2016-10-13,2016,10,13,14,578stv,"[Discussion] What makes GAN good for semi-supervised learning in ""Improved Techniques for Training GANs"" ?",https://www.reddit.com/r/MachineLearning/comments/578stv/discussion_what_makes_gan_good_for_semisupervised/,gmkim90,1476337672,"In ""Improved Techniques for Training GANs"", I am surprised by performance of semi-supervised learning presented in paper.

But I am not sure how semi-supervised learning perform better than others such as Auxiliary Deep Generative Model(ADGM) or Ladder network. 

As I understand, unlabeled data is discriminated from negative class (class# = K+1), and does not learn which class it could be. 
However, ADGM seems trying to infer class of unlabeled data. 

I really appreciate any comments/insight how it performs well.",6,12
448,2016-10-13,2016,10,13,14,578tav,40 Interview Questions asked at Startups in Machine Learning / Data Science,https://www.reddit.com/r/MachineLearning/comments/578tav/40_interview_questions_asked_at_startups_in/,[deleted],1476337920,[deleted],0,1
449,2016-10-13,2016,10,13,15,578wyy,[Discussion]What techniques do you use to examine the columns of predictor variables in Machine Learning models?,https://www.reddit.com/r/MachineLearning/comments/578wyy/discussionwhat_techniques_do_you_use_to_examine/,[deleted],1476339905,[deleted],0,1
450,2016-10-13,2016,10,13,16,5791di,[News] Generate Music on Demand using Deep Learning Models of a Genre: Now Live as a Twitter Bot,https://www.reddit.com/r/MachineLearning/comments/5791di/news_generate_music_on_demand_using_deep_learning/,amirsaffari,1476342420,,6,23
451,2016-10-13,2016,10,13,17,5796oe,What is plasticine or modeling clay package,https://www.reddit.com/r/MachineLearning/comments/5796oe/what_is_plasticine_or_modeling_clay_package/,mixmachinery,1476345667,,1,1
452,2016-10-13,2016,10,13,17,57992o,Supervised learning with tagged images,https://www.reddit.com/r/MachineLearning/comments/57992o/supervised_learning_with_tagged_images/,deluded_soul,1476347245,[removed],0,1
453,2016-10-13,2016,10,13,18,579ebo,Machine Learning algorithms to filter a Google search about someone?,https://www.reddit.com/r/MachineLearning/comments/579ebo/machine_learning_algorithms_to_filter_a_google/,mohamadagil,1476350662,[removed],0,1
454,2016-10-13,2016,10,13,18,579eeo,[Discussion] InfoGAN training: Continuous variable is capturing digit number (0-9).,https://www.reddit.com/r/MachineLearning/comments/579eeo/discussion_infogan_training_continuous_variable/,cvikasreddy,1476350711,"I was training InfoGAN on mnist with one continuous and one categorical variable.

Interestingly the continuous variable is capturing it's category(0-9) and the categorical variable is capturing some other information.

What might be the reason?",8,4
455,2016-10-13,2016,10,13,20,579ukm,What's the deep learning state-of-art techniques for segmentation right now?,https://www.reddit.com/r/MachineLearning/comments/579ukm/whats_the_deep_learning_stateofart_techniques_for/,SnowRipple,1476359707,[removed],0,1
456,2016-10-13,2016,10,13,20,579uqp,[Discussion] Is there a collection of pre-trained word embeddings using various models and corpora?,https://www.reddit.com/r/MachineLearning/comments/579uqp/discussion_is_there_a_collection_of_pretrained/,onewugtwowugs,1476359780,"I'm interested in comparing the performance of various word embedding models, and my work would be greatly simplified if there already was a collection of these trained on various popular models and large corpora out there somewhere. I have found a few repositories containing pre-trained models, but nothing where the models have all been trained on the same corpora. Have you seen anything like this?

Thanks",3,3
457,2016-10-13,2016,10,13,22,57a4ro,"Does it just add layers or neurons then retrain, until it passes a threshold?",https://www.reddit.com/r/MachineLearning/comments/57a4ro/does_it_just_add_layers_or_neurons_then_retrain/,[deleted],1476363832,[removed],0,1
458,2016-10-13,2016,10,13,23,57afhw,[News] White House publishes Report on the Future of Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/57afhw/news_white_house_publishes_report_on_the_future/,sybilckw,1476367758,,63,136
459,2016-10-14,2016,10,14,0,57asat,"BigData and ML Framework and Toolset Weekly Roundup  Oct. 13, 2016",https://www.reddit.com/r/MachineLearning/comments/57asat/bigdata_and_ml_framework_and_toolset_weekly/,stkim1,1476371994,,0,1
460,2016-10-14,2016,10,14,0,57aygs,Bijur Delimon Lubrication Products and Accessories,https://www.reddit.com/r/MachineLearning/comments/57aygs/bijur_delimon_lubrication_products_and_accessories/,jackerfrinandis,1476373940,,0,1
461,2016-10-14,2016,10,14,2,57bjbi,[Project] Shapes and dynamic dimensions in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/57bjbi/project_shapes_and_dynamic_dimensions_in/,morgangiraud,1476380225,,0,1
462,2016-10-14,2016,10,14,2,57bjqy,Adversarial Language Modelling?,https://www.reddit.com/r/MachineLearning/comments/57bjqy/adversarial_language_modelling/,stacky777,1476380357,[removed],0,1
463,2016-10-14,2016,10,14,3,57br7y,What NLP algorithms should I use for matching resumes and job posts?,https://www.reddit.com/r/MachineLearning/comments/57br7y/what_nlp_algorithms_should_i_use_for_matching/,stevofolife,1476382625,[removed],0,1
464,2016-10-14,2016,10,14,3,57byhq,SCIA 2017,https://www.reddit.com/r/MachineLearning/comments/57byhq/scia_2017/,slackericida,1476384874,[removed],0,1
465,2016-10-14,2016,10,14,4,57cafk,Any suggest for my senior project?,https://www.reddit.com/r/MachineLearning/comments/57cafk/any_suggest_for_my_senior_project/,ibrahimsengul,1476388551,[removed],0,1
466,2016-10-14,2016,10,14,5,57cfaj,"Pac-Man Matrices, an interesting convex subset of stable matrices.",https://www.reddit.com/r/MachineLearning/comments/57cfaj/pacman_matrices_an_interesting_convex_subset_of/,[deleted],1476390043,[deleted],0,1
467,2016-10-14,2016,10,14,5,57cfg1,Does anyone know any good papers on Deep Learning for medical imaging?,https://www.reddit.com/r/MachineLearning/comments/57cfg1/does_anyone_know_any_good_papers_on_deep_learning/,Offender_Ralphist,1476390092,[removed],0,1
468,2016-10-14,2016,10,14,5,57cfyh,[Research] Pac Man Matrices - an interesting new convex subset of stable matrices,https://www.reddit.com/r/MachineLearning/comments/57cfyh/research_pac_man_matrices_an_interesting_new/,gabrielgoh,1476390252,,10,30
469,2016-10-14,2016,10,14,5,57ci2y,"[Discussion] Architecture choices in DenseNet/ResNet (pooling type, no large fully-connected layer)",https://www.reddit.com/r/MachineLearning/comments/57ci2y/discussion_architecture_choices_in_densenetresnet/,Pieranha,1476390886,"The Densely Connected Convolutional Networks paper (https://arxiv.org/abs/1608.06993) is really interesting to me as is the older ResNet paper (https://arxiv.org/abs/1512.03385). However, I'm intrigued by many of their design choices. In particular: 

1. Why do they use average-pooling instead of max-pooling at the end of their network? If each neuron is a feature extractor and the final neurons can capture quite complex patterns, then I would assume that you're more interested in whether a single neuron was triggered with that pattern than the average firing of neurons. Has there been any results showing that average-pooling is better than max-pooling?

2. Why do they not use a large fully-connected layer at the end of their network? Suppose that each neuron captures a separate pattern. Then combining these patterns using a fully-connected layer would make sense. This was common for e.g. AlexNet (https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-)",8,7
470,2016-10-14,2016,10,14,6,57cy1i,"Uncertainty in Deep Learning (PhD Thesis) | Yarin Gal, Cambridge Machine Learning Group",https://www.reddit.com/r/MachineLearning/comments/57cy1i/uncertainty_in_deep_learning_phd_thesis_yarin_gal/,Chobeat,1476395930,,0,3
471,2016-10-14,2016,10,14,8,57dhq8,[Discussion] What do you do when a model isn't performing as you expect it to?,https://www.reddit.com/r/MachineLearning/comments/57dhq8/discussion_what_do_you_do_when_a_model_isnt/,Max_Poole,1476402710,"Debugging machine learning code can be tough because a lot of times your model may not be deterministic. The obvious step is to make sure your code is correct, but beyond that what are some steps that you take when you train a model and the results you get are not what you expect?",15,15
472,2016-10-14,2016,10,14,8,57dibd,"[Research] Learning to Communicate: Channel Auto-encoders, Domain Specific Regularizers, and Attention",https://www.reddit.com/r/MachineLearning/comments/57dibd/research_learning_to_communicate_channel/,j_lyf,1476402922,,0,1
473,2016-10-14,2016,10,14,9,57drq2,[Discussion] Where do you get large datasets for training? Are there ones for websites like LinkedIn?,https://www.reddit.com/r/MachineLearning/comments/57drq2/discussion_where_do_you_get_large_datasets_for/,space__sloth,1476406432,"I'm specifically looking for a corpus of linkedin profiles, but even more generally, what are some resources you guys use for training data? ",9,5
474,2016-10-14,2016,10,14,12,57ebjz,Strengths and weaknesses of Probabilistic Graphical Models and Bayesian Non-Parametrics? And which one is used widely these days?,https://www.reddit.com/r/MachineLearning/comments/57ebjz/strengths_and_weaknesses_of_probabilistic/,[deleted],1476414164,[removed],0,1
475,2016-10-14,2016,10,14,12,57eboi,[X-Post] Looking For Open Source SNES Emulator to Hack,https://www.reddit.com/r/MachineLearning/comments/57eboi/xpost_looking_for_open_source_snes_emulator_to/,jhill515,1476414217,[removed],1,0
476,2016-10-14,2016,10,14,12,57ec9z,[Discussion] Is my understanding of double Q-learning correct?,https://www.reddit.com/r/MachineLearning/comments/57ec9z/discussion_is_my_understanding_of_double/,darkconfidantislife,1476414442,"Hi there guys, I read the double Q-learning paper but I'm not sure if I understood it correctly or I thought I understood but in reality I didn't. Could someone explain it to me so I can confirm? So far, I think that they basically have two Q-functions that have different experience sets and alternate at every step when bootstrapping. Is this understanding correct?

Thanks in advance :)",9,1
477,2016-10-14,2016,10,14,12,57edq2,[Discussion] Strengths and weaknesses of Probabilistic Graphical Models and Bayesian Non-Parametrics? And which one is used widely these days?,https://www.reddit.com/r/MachineLearning/comments/57edq2/discussion_strengths_and_weaknesses_of/,deepmind2016,1476415034,[removed],2,4
478,2016-10-14,2016,10,14,12,57eji3, !!!,https://www.reddit.com/r/MachineLearning/comments/57eji3//,ems204,1476417505,,0,1
479,2016-10-14,2016,10,14,13,57eq8w,[Discussion] What machine learning can bring to software development?,https://www.reddit.com/r/MachineLearning/comments/57eq8w/discussion_what_machine_learning_can_bring_to/,zhiwei_liu,1476420556,,4,0
480,2016-10-14,2016,10,14,14,57exz3,  Automatic over flow liquid filler for 10 nozzles,https://www.reddit.com/r/MachineLearning/comments/57exz3/__automatic_over_flow_liquid_filler/,neostarpack,1476424486,,0,1
481,2016-10-14,2016,10,14,15,57f3y9,Sample rate?,https://www.reddit.com/r/MachineLearning/comments/57f3y9/sample_rate/,jensennibe,1476427848,[removed],1,1
482,2016-10-14,2016,10,14,15,57f3yz,What is the ointment mixer?,https://www.reddit.com/r/MachineLearning/comments/57f3yz/what_is_the_ointment_mixer/,mixmachinery,1476427861,,1,1
483,2016-10-14,2016,10,14,17,57ffar,How to implement sentence-level log-likelihood in tensorflow?,https://www.reddit.com/r/MachineLearning/comments/57ffar/how_to_implement_sentencelevel_loglikelihood_in/,merzzow,1476435160,[removed],0,1
484,2016-10-14,2016,10,14,17,57ffcd,[P] Keras.js: run trained models in browser with GPU support,https://www.reddit.com/r/MachineLearning/comments/57ffcd/p_kerasjs_run_trained_models_in_browser_with_gpu/,kcimc,1476435195,,18,128
485,2016-10-14,2016,10,14,18,57fggl,Google DeepMind 'learns' the London Underground map to find best route,https://www.reddit.com/r/MachineLearning/comments/57fggl/google_deepmind_learns_the_london_underground_map/,reworkdiane,1476435916,,0,1
486,2016-10-14,2016,10,14,19,57fmnv,What's wrong with deep learning?,https://www.reddit.com/r/MachineLearning/comments/57fmnv/whats_wrong_with_deep_learning/,[deleted],1476439733,[deleted],0,1
487,2016-10-14,2016,10,14,19,57fpqd,"Flavoured water filling machine, mineral water filling line, drinking water filling plant",https://www.reddit.com/r/MachineLearning/comments/57fpqd/flavoured_water_filling_machine_mineral_water/,stevenwangfilling,1476441579,,0,1
488,2016-10-14,2016,10,14,20,57fxf8,How Artificial Intelligence is improving your Sales funnel,https://www.reddit.com/r/MachineLearning/comments/57fxf8/how_artificial_intelligence_is_improving_your/,nitinbajaj1423,1476445662,,0,1
489,2016-10-14,2016,10,14,22,57gb56,"I know digits isn't the most liked thing, but it makes pretty graphs.",https://www.reddit.com/r/MachineLearning/comments/57gb56/i_know_digits_isnt_the_most_liked_thing_but_it/,TuringsEgo,1476451249,,0,1
490,2016-10-14,2016,10,14,23,57gios,[Project] How to Use t-SNE Effectively,https://www.reddit.com/r/MachineLearning/comments/57gios/project_how_to_use_tsne_effectively/,urish,1476454053,,32,170
491,2016-10-14,2016,10,14,23,57goko,[Discussion] Use of stochastic calculus in machine learning,https://www.reddit.com/r/MachineLearning/comments/57goko/discussion_use_of_stochastic_calculus_in_machine/,JustFinishedBSG,1476456080,"Hello,

I'm interested in knowing how stochastic calculus could be used in machine learning. I have no idea where to start looking. It would seem to me that exploiting time continuity in some problems could bring a lot of very very powerful tools.

If anybody has pointers to the right direction.

Thanks

( i have tried to googling my question, only find unrelated articles about quants. Some links on variational inference too, would that be a direction ?)",13,16
492,2016-10-15,2016,10,15,0,57h2u4,Why Do You Need to Lubricate Your Machinery?,https://www.reddit.com/r/MachineLearning/comments/57h2u4/why_do_you_need_to_lubricate_your_machinery/,jackerfrinandis,1476460767,,0,1
493,2016-10-15,2016,10,15,1,57h7u1,[Discussion] Examples of the use of Linear Programming and Operations research in Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/57h7u1/discussion_examples_of_the_use_of_linear/,quit_daedalus,1476462303,"Hello there! 

I'm an EE undergrad who really loves to learn more about Machine Learning and has the ""Operations Research"" course this semester. 

Our course project is to find a real world problem and solve and optimize it using Linear Programming, as Machine Learning is one of my favorite topics I want to choose a Machine Learning Problem, but I have little idea about what I can choose and came here asking for help. Thanks!",4,4
494,2016-10-15,2016,10,15,1,57hduq,Debugging Neural Networks: A Checklist,https://www.reddit.com/r/MachineLearning/comments/57hduq/debugging_neural_networks_a_checklist/,ramananb,1476464165,,0,1
495,2016-10-15,2016,10,15,2,57hf8u,Deep Learning School 2016: Individual Talks,https://www.reddit.com/r/MachineLearning/comments/57hf8u/deep_learning_school_2016_individual_talks/,Dogsindahouse1,1476464575,,0,1
496,2016-10-15,2016,10,15,2,57hjsz,How does Elastic's Prelert (formerly Splunk Anomaly Detective App) work?,https://www.reddit.com/r/MachineLearning/comments/57hjsz/how_does_elastics_prelert_formerly_splunk_anomaly/,ximik,1476465959,[removed],0,1
497,2016-10-15,2016,10,15,2,57hjxg,Text classification for multilabel classification,https://www.reddit.com/r/MachineLearning/comments/57hjxg/text_classification_for_multilabel_classification/,[deleted],1476465994,[removed],1,1
498,2016-10-15,2016,10,15,3,57huvc,[News] Intel will add deep-learning instructions to its processors,https://www.reddit.com/r/MachineLearning/comments/57huvc/news_intel_will_add_deeplearning_instructions_to/,beeftug,1476469232,,0,1
499,2016-10-15,2016,10,15,3,57hvfr,[discussion] What's wrong with deep learning?,https://www.reddit.com/r/MachineLearning/comments/57hvfr/discussion_whats_wrong_with_deep_learning/,[deleted],1476469404,[deleted],0,0
500,2016-10-15,2016,10,15,5,57ijc2,Getting the model complexity in xgboost,https://www.reddit.com/r/MachineLearning/comments/57ijc2/getting_the_model_complexity_in_xgboost/,Tokukawa,1476476918,[removed],0,1
501,2016-10-15,2016,10,15,5,57ijcg,"230 Ton x 14' Used Cincinnati Hydraulic CNC Press Brake, Mdl. 230CB12 A4594",https://www.reddit.com/r/MachineLearning/comments/57ijcg/230_ton_x_14_used_cincinnati_hydraulic_cnc_press/,SterlingMachineryEx,1476476923,,0,1
502,2016-10-15,2016,10,15,5,57im61,"1/4"" x 13' Used LVD Hydraulic Shear, Mdl. JS25-13 A4581",https://www.reddit.com/r/MachineLearning/comments/57im61/14_x_13_used_lvd_hydraulic_shear_mdl_js2513_a4581/,SterlingMachineryEx,1476477835,,0,1
503,2016-10-15,2016,10,15,5,57in6v,"[News] FlowMachines article and survey ""Bach or computer: can you tell the difference?""",https://www.reddit.com/r/MachineLearning/comments/57in6v/news_flowmachines_article_and_survey_bach_or/,kkastner,1476478157,,15,12
504,2016-10-15,2016,10,15,6,57iuas,"9"" x 17"" Brand New W.F. Wells Semi-Automatic Horizontal Twin Post Bandsa...",https://www.reddit.com/r/MachineLearning/comments/57iuas/9_x_17_brand_new_wf_wells_semiautomatic/,SterlingMachineryEx,1476480529,,0,1
505,2016-10-15,2016,10,15,8,57jb7v,Systematic Cochrane reviews and data mining: is there an dataset of titles (and maybe abstracts) of every\* medical paper published?,https://www.reddit.com/r/MachineLearning/comments/57jb7v/systematic_cochrane_reviews_and_data_mining_is/,[deleted],1476486450,[removed],0,1
506,2016-10-15,2016,10,15,8,57jghu,"Looking for help: running a CNN on weird data, and looking for ""mirrored"" filters in Keras (somewhat beginner in ML)",https://www.reddit.com/r/MachineLearning/comments/57jghu/looking_for_help_running_a_cnn_on_weird_data_and/,OddOliver,1476488499,[removed],0,1
507,2016-10-15,2016,10,15,8,57jhex,My boss is demanding an ETA for implementing a CNN. Here's my model. Please help!,https://www.reddit.com/r/MachineLearning/comments/57jhex/my_boss_is_demanding_an_eta_for_implementing_a/,randombites,1476488863,[removed],0,1
508,2016-10-15,2016,10,15,9,57jkjo,[N] Intel will add deep-learning instructions to its processors,https://www.reddit.com/r/MachineLearning/comments/57jkjo/n_intel_will_add_deeplearning_instructions_to_its/,downtownslim,1476490120,,28,64
509,2016-10-15,2016,10,15,10,57ju85,resnet in tensorflow,https://www.reddit.com/r/MachineLearning/comments/57ju85/resnet_in_tensorflow/,mac_i,1476494018,[removed],0,1
510,2016-10-15,2016,10,15,10,57jynf,Twitter Sentiment Analysis - Learn Python for Data Science,https://www.reddit.com/r/MachineLearning/comments/57jynf/twitter_sentiment_analysis_learn_python_for_data/,llSourcell,1476495907,,0,2
511,2016-10-15,2016,10,15,11,57k3j4,Facebook AI Researcher's notes on DeepMind's third Nature,https://www.reddit.com/r/MachineLearning/comments/57k3j4/facebook_ai_researchers_notes_on_deepminds_third/,[deleted],1476498017,[deleted],0,1
512,2016-10-15,2016,10,15,12,57kdab,Facebook AI Researcher's Notes on DeepMind's 3rd Nature paper,https://www.reddit.com/r/MachineLearning/comments/57kdab/facebook_ai_researchers_notes_on_deepminds_3rd/,[deleted],1476502448,[deleted],0,1
513,2016-10-15,2016,10,15,12,57kejz,[Discussion] Facebook AI Researcher on DeepMind's third Nature paper,https://www.reddit.com/r/MachineLearning/comments/57kejz/discussion_facebook_ai_researcher_on_deepminds/,SJTUzhangzhe,1476503051,,10,83
514,2016-10-15,2016,10,15,12,57kg6q,[CodeFights] How good are your programming-skills?,https://www.reddit.com/r/MachineLearning/comments/57kg6q/codefights_how_good_are_your_programmingskills/,efren-rodz,1476503825,,0,1
515,2016-10-15,2016,10,15,14,57ktlc,How about mixing tank price?,https://www.reddit.com/r/MachineLearning/comments/57ktlc/how_about_mixing_tank_price/,mixmachinery,1476510781,,1,1
516,2016-10-15,2016,10,15,17,57l8yv,Q-learning for my shower,https://www.reddit.com/r/MachineLearning/comments/57l8yv/qlearning_for_my_shower/,leb_broth,1476520886,[removed],0,1
517,2016-10-15,2016,10,15,18,57lcoj,What's the JCT best dough mixers machine operate,https://www.reddit.com/r/MachineLearning/comments/57lcoj/whats_the_jct_best_dough_mixers_machine_operate/,mixmachinery,1476523469,,1,1
518,2016-10-15,2016,10,15,18,57lfer,Internships in Machine Learning research for master's students,https://www.reddit.com/r/MachineLearning/comments/57lfer/internships_in_machine_learning_research_for/,utkarshsimha,1476525396,[removed],0,1
519,2016-10-15,2016,10,15,19,57lk8c,How to write a custom neural network layer in Keras with an example,https://www.reddit.com/r/MachineLearning/comments/57lk8c/how_to_write_a_custom_neural_network_layer_in/,shash273,1476528639,,0,1
520,2016-10-15,2016,10,15,19,57ll0j,[Discussion] Incorporating word embeddings to train LSTM,https://www.reddit.com/r/MachineLearning/comments/57ll0j/discussion_incorporating_word_embeddings_to_train/,HumbleNoob,1476529161,"Hi, 
I'm an undergraduate student working on a text generation task. I am unable to train a network using my pretrained word embeddings as weights for input layer to LSTM. My word2vec embedding is trained on a larger corpus and the training corpus is a subset of it. I'm mapping word vectors to embedding weights using word2vec model. My vocabulary for the task consists of some word2vec_vocab+additional words in corpus. The model is as follows:

Train data: vector with indices mapped using a dictionary consisting of word2vec model indices + additional word indices = full dict

Test data: one hot vector with 1 at position w.r.t corpus(I am not using full dict for mapping, thus position indices differ.)

**Model**:

 w2v_dim= 200

seq_length= 7

vocab_size= # of unique words in corpus


model.add(Embedding(corpus_size, w2v_dim, mask_zero=False, weights=[embedding], input_length=seq_length)) 

model.add(LSTM(memory_units, return_sequences=True, init= ""orthogonal""))

model.add(Dropout(0.5))

model.add(TimeDistributed(Dense(vocab_size, activation='softmax', init= ""orthogonal"")))



**Problem**: Model overfitting on training data with increasing loss on validation set. 


What am I missing? What else can I do to improve the model? Thanks.

 ",6,5
521,2016-10-15,2016,10,15,20,57lmws,Machine Learning &amp; Algorithmic Trading--New Interesting Group,https://www.reddit.com/r/MachineLearning/comments/57lmws/machine_learning_algorithmic_tradingnew/,Markjack99,1476530349,[removed],0,1
522,2016-10-15,2016,10,15,21,57lxly,"Can complex data structures be used as input in machine learning, such as polygons or [Planar straight-line graphs?](https://en.wikipedia.org/wiki/Planar_straight-line_graph)",https://www.reddit.com/r/MachineLearning/comments/57lxly/can_complex_data_structures_be_used_as_input_in/,[deleted],1476536197,[removed],0,1
523,2016-10-15,2016,10,15,22,57m2vl,Can complex data structures such as polygons or [Planar straight-line graphs?](https://en.wikipedia.org/wiki/Planar_straight-line_graph) be used as input in machine learning?,https://www.reddit.com/r/MachineLearning/comments/57m2vl/can_complex_data_structures_such_as_polygons_or/,[deleted],1476538650,[removed],0,1
524,2016-10-15,2016,10,15,23,57m6xs,Can complex data structures such as polygons or planar straight-line graphs be used as input in machine learning?,https://www.reddit.com/r/MachineLearning/comments/57m6xs/can_complex_data_structures_such_as_polygons_or/,[deleted],1476540464,[removed],0,1
525,2016-10-15,2016,10,15,23,57me24,"An Introduction to Statistical Learning with Applications in R (book, pdf)",https://www.reddit.com/r/MachineLearning/comments/57me24/an_introduction_to_statistical_learning_with/,[deleted],1476543385,[deleted],0,1
526,2016-10-16,2016,10,16,0,57mgxt,Inception / Custom T.F. Image Classifier Live on Android,https://www.reddit.com/r/MachineLearning/comments/57mgxt/inception_custom_tf_image_classifier_live_on/,wagonhelm,1476544502,,0,1
527,2016-10-16,2016,10,16,1,57mp8n,A tour of random forests,https://www.reddit.com/r/MachineLearning/comments/57mp8n/a_tour_of_random_forests/,[deleted],1476547621,[deleted],0,1
528,2016-10-16,2016,10,16,1,57mtv6,[Research]Vanilla Theano code to reproduce Keras model does not match as expected. What am I missing?,https://www.reddit.com/r/MachineLearning/comments/57mtv6/researchvanilla_theano_code_to_reproduce_keras/,raw_hazard,1476549253,"I find Keras a very useful and well done tool. It is perfect to start using Theano and it is really easily understandable and usable.
Now, I realised a Keras model (using Theano interface), which works perfectly well and I would like to replicate it using only Theano code.
Since Keras is actually using Theano code, I should be able, in principle, to do this.
The neural net is a convolutional neural network for a one output regression task, with the following layers: conv2d, maxpool2d, conv2d, maxpool2d, dense, dense, output and using Adam optimizer.
Unfortunately, despite it seems to me that I implemented exactly the same neural network with vanilla Theano code, the performance is consistently different.
So, I guess I must be wrong somewhere, but I can't see where.

I will put here a link to the codes I'm using, in order to make the post too long. They are short and simple codes, do not worry =)

[Keras Impl.](http://pastebin.com/7eNubwxw)

[Theano main](http://pastebin.com/Lvdn6UAc)
[Dense layer with MSE loss function](http://pastebin.com/RyUH07Te)
[Conv layer + max pooling](http://pastebin.com/VVmXm1Uk)
[Updates rule](http://pastebin.com/fp5Draq7)


Keep in mind that the Theano code is mostly adapted from the Theano tutorial found on the website, and the update rules for Adam optimizer is adapted from Keras source code.
I have a large training set, so I usually check after a few epochs the behaviour of the code and this is what I see:
Keras Model: the validation error keeps decreasing, and already after two or three epochs I see a very good match between prediction and true values (points quite close around the bisector in the plot at the bottom of the code)
Vanilla Theano Impl: the validation decreases at first, but then some kind of oscillating/overfitting features appear (and the absolute value is 10 times higher than in the Keras impl.), and the match between prediction and true values is worse (points quite spread around the bisector in the plot at the bottom of the code)

So, is someone able to tell me where is the difference between the Keras model and my Theano implementation? Since I'm new to the field, I would really like to understand what I'm doing wrong that so strongly affects the performance of the network.
Any help would be appreciated. Thanks

EDIT: please note, Keras default params initialization is glorot uniform, which is exactly what I use in the Theano impl. Biases instead are initialized to zero in both cases.",5,2
529,2016-10-16,2016,10,16,2,57mzou,"[P] An Introduction to Statistical Learning with Applications in R (book, pdf)",https://www.reddit.com/r/MachineLearning/comments/57mzou/p_an_introduction_to_statistical_learning_with/,pmigdal,1476551278,,30,129
530,2016-10-16,2016,10,16,2,57n6sw,Application of Google Smart Reply,https://www.reddit.com/r/MachineLearning/comments/57n6sw/application_of_google_smart_reply/,titanum456,1476553763,[removed],0,1
531,2016-10-16,2016,10,16,2,57n82b,Generative Adversarial Nets from a Density Ratio Estimation Perspective,https://www.reddit.com/r/MachineLearning/comments/57n82b/generative_adversarial_nets_from_a_density_ratio/,[deleted],1476554215,[deleted],0,1
532,2016-10-16,2016,10,16,3,57na6g,[Research] Generative Adversarial Nets from a Density Ratio Estimation Perspective,https://www.reddit.com/r/MachineLearning/comments/57na6g/research_generative_adversarial_nets_from_a/,perceptron01,1476554954,,5,5
533,2016-10-16,2016,10,16,3,57ncn2,[Research] How computers might finally be able to identify sarcasm,https://www.reddit.com/r/MachineLearning/comments/57ncn2/research_how_computers_might_finally_be_able_to/,pmigdal,1476555847,,1,3
534,2016-10-16,2016,10,16,3,57nd93,Best a priori classifier for 2 classes,https://www.reddit.com/r/MachineLearning/comments/57nd93/best_a_priori_classifier_for_2_classes/,niujin,1476556057,[removed],0,1
535,2016-10-16,2016,10,16,4,57npkf,Google's AI reasons its way around the London Underground,https://www.reddit.com/r/MachineLearning/comments/57npkf/googles_ai_reasons_its_way_around_the_london/,Buck-Nasty,1476560385,,0,1
536,2016-10-16,2016,10,16,5,57nxxj,[Project] A very simple example of classifying words with a LSTM in Torch,https://www.reddit.com/r/MachineLearning/comments/57nxxj/project_a_very_simple_example_of_classifying/,[deleted],1476563386,[deleted],0,0
537,2016-10-16,2016,10,16,5,57nyux,[R] Generative Adversarial Nets from a Density Ratio Estimation Perspective,https://www.reddit.com/r/MachineLearning/comments/57nyux/r_generative_adversarial_nets_from_a_density/,rmltestaccount,1476563719,,0,7
538,2016-10-16,2016,10,16,6,57o45k,[D] Towards deep symbolic reinforcement learning,https://www.reddit.com/r/MachineLearning/comments/57o45k/d_towards_deep_symbolic_reinforcement_learning/,Nazka231,1476565645,,7,2
539,2016-10-16,2016,10,16,6,57o8dj,"Deep reinforcement learning, battleship",https://www.reddit.com/r/MachineLearning/comments/57o8dj/deep_reinforcement_learning_battleship/,[deleted],1476567222,[deleted],0,1
540,2016-10-16,2016,10,16,6,57o8w3,"[P] Deep reinforcement learning tutorial, battleship",https://www.reddit.com/r/MachineLearning/comments/57o8w3/p_deep_reinforcement_learning_tutorial_battleship/,efavdb,1476567398,,6,28
541,2016-10-16,2016,10,16,6,57o92t,Single Shot Multibox Detector on Snapdragon 820,https://www.reddit.com/r/MachineLearning/comments/57o92t/single_shot_multibox_detector_on_snapdragon_820/,cudeep,1476567474,,0,1
542,2016-10-16,2016,10,16,8,57on5t,How to make machines learn like humans: Brain-like AI and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/57on5t/how_to_make_machines_learn_like_humans_brainlike/,edworldreddit,1476572657,,0,1
543,2016-10-16,2016,10,16,8,57ovth,Could you use a quantum computer to train NNs instantly?,https://www.reddit.com/r/MachineLearning/comments/57ovth/could_you_use_a_quantum_computer_to_train_nns/,zergling103,1476575975,[removed],0,1
544,2016-10-16,2016,10,16,9,57oyan,"[Research] DeepMind's latest Nature paper: Why the huge difference between ""mean"" and ""best"" results on the Q&amp;A task?",https://www.reddit.com/r/MachineLearning/comments/57oyan/research_deepminds_latest_nature_paper_why_the/,ill-logical,1476576930,"For the Q&amp;A task, Graves *et al* report 16.7% mean error and 3.8% best error (over 20 runs).

Given such a big variance of the results, does it really make sense to compare them between different architectures (*e.g.* 4.2% and 7.5% MemN2N error)?

I'm glad that Graves *et al* are reporting the mean error too. It was apparently considered OK to just report the best error over many runs and an unspecified, but potentially astronomical number of hyperparameter grid search trials on this dataset.",1,32
545,2016-10-16,2016,10,16,10,57p7kv,learning a combinatorial function,https://www.reddit.com/r/MachineLearning/comments/57p7kv/learning_a_combinatorial_function/,[deleted],1476580730,[removed],0,1
546,2016-10-16,2016,10,16,11,57pll1,"In this video, at 25:22, why nando multiplies approximated integral with delta function(counts the number of samples in dtheta) in importance sampling?",https://www.reddit.com/r/MachineLearning/comments/57pll1/in_this_video_at_2522_why_nando_multiplies/,[deleted],1476586662,[deleted],0,1
547,2016-10-16,2016,10,16,12,57pmyj,"[Discussion] In this video, at 25:22, why nando multiplies approximated integral with delta function(counts the number of samples in dtheta) in importance sampling?",https://www.reddit.com/r/MachineLearning/comments/57pmyj/discussion_in_this_video_at_2522_why_nando/,[deleted],1476587261,[deleted],0,1
548,2016-10-16,2016,10,16,12,57poe3,"[Discussion] In this video, at 25:22, why nando multiplies approximated integral with delta function(counts the number of samples in dtheta) in importance sampling?",https://www.reddit.com/r/MachineLearning/comments/57poe3/discussion_in_this_video_at_2522_why_nando/,[deleted],1476587911,[removed],0,1
549,2016-10-16,2016,10,16,12,57ppp3,"[Discussion] In this video, at 25:22, why nando multiplies approximated integral with delta function(counts the number of samples in dtheta) in importance sampling?",https://www.reddit.com/r/MachineLearning/comments/57ppp3/discussion_in_this_video_at_2522_why_nando/,[deleted],1476588508,[removed],0,1
550,2016-10-16,2016,10,16,12,57pr65,"[Discussion] In this video, at 25:22, why Nando multiplies approximated integral with delta function(which counts the number of samples in dtheta) in importance sampling lecture?",https://www.reddit.com/r/MachineLearning/comments/57pr65/discussion_in_this_video_at_2522_why_nando/,deepmind2016,1476589168,,0,1
551,2016-10-16,2016,10,16,14,57q1z7,"[Discussion] In this video, why Nando multiplies approximated integral with delta function?",https://www.reddit.com/r/MachineLearning/comments/57q1z7/discussion_in_this_video_why_nando_multiplies/,[deleted],1476594346,[deleted],0,1
552,2016-10-16,2016,10,16,15,57qaqp,[Discussion] Help modelling a problem using a graphical model,https://www.reddit.com/r/MachineLearning/comments/57qaqp/discussion_help_modelling_a_problem_using_a/,purpledazy,1476599234,"I am having a problem formalising my data questions as probabilistic programming/graphical models, for some reason the gap between examples provided in various books and real-life scenarios seems too far to bridge. 

For example -
In one case my goal is to predict the number of months left for a building construction to be completed.
The data I have available is a list of buildings in a region with those features:

* When did the construction of each building started

* The number of workers that worked/still working on its construction - per month since the construction started

* Number of floors the building has/planned to have

* Has the construction finished or not? (in the form of finish date or null)


My progress so far:

* I think the models output of interest would be a distribution of time it takes to complete a building' dependent on the number of floors, number of workers per month, and how many months have passed since the construction started.

* The prior for that would be the current distribution months it took to complete the existing completed buildings (so filtering out all non-completed buildings from the dataset)

* The number of floors parameter seems like it should be modelled as a hierarchical component (either each number of floors or a subgroup will have a different distribution of number of workers per month) - thats based on a hunch that buildings with more floors require more workers but in a non-linear way.

Two things that I feel I am stuck with are: 

* How to model the number of workers data since it requires two parameters - time (e.g., month index since construction started) and the number of workers at that period the distributions in the examples Ive seen model a single value. I can break this into a fixed array of multiple distributions (one per month) but for some reason that doesnt seem right (how will all those distributions be tied to each other? see next point)

* How to tie the number of floors and distribution of workers to target distribution?

Many thanks for reading all this, really not sure how to get help to go beyond the text book examples in probabilistic programming/graph models quite frustrating, since I am really keen on applying it in my work.",2,2
553,2016-10-16,2016,10,16,17,57qjpw,pca on finance/time series data,https://www.reddit.com/r/MachineLearning/comments/57qjpw/pca_on_financetime_series_data/,[deleted],1476605288,[removed],0,1
554,2016-10-16,2016,10,16,21,57r6z6,[D] Budget Deep Learning Rig,https://www.reddit.com/r/MachineLearning/comments/57r6z6/d_budget_deep_learning_rig/,bionicscrotum,1476620765,"Hey everyone,

I'm currently doing a Master's focusing on ML and deep learning in particular. The more I got into DL, the more I realized that neither my laptop, nor the (CPU-only) compute cluster from my university are enough to train any nontrivial models.

Because of this, I've decided to build my own (student-budget, but still as beefy as possible) rig. I plan on using it to quickly iterate on models in may areas, ranging from NLP to medical image processing (e.g. 3D CNNs over MRI data). This would be my first PC build. I plan on using it for gaming less than 5% of the time.

After doing a fair bit of research, I learned that the best card I could get at the moment would (obviously) be the Pascal Titan X, but that the 1080 has a much better price-quality ratio. This ratio is even better for the 1070, but I believe that the increased memory bandwidth of the 1080 makes it worth my money.

I aimed for a beefy but not over-the-top CPU, and a fast but small SSD to keep my OS and 1-2 small datasets on which I would be working. I don't plan on working with huge datasets (&gt;100-200Gb ) in the foreseeable future. I got 32 gigs of ram in a 2x16 kit, so that I can upgrade to 64 if necessary (this is likely not a bottleneck given the 8Gb video memory).

I would be *very* grateful for some feedback/hints on my current specs. For example:

  1. Is the CPU too much? Would a plain-old i5 also work?
  2. Should I aim for a different GPU manufacturer (e.g. MSI), or is Zotac fine?
  3. Is there anything (apart from monitor, keyboard, and mouse) that it missing?
  4. Any blatant incompatibilities/weird stuff?

Thank you very much in advance! Here's the build:

[PCPartPicker part list](http://pcpartpicker.com/list/gRv7wV) / [Price breakdown by merchant](http://pcpartpicker.com/list/gRv7wV/by_merchant/)

Type|Item|Price
:----|:----|:----
**CPU** | [Intel Core i7-6700 3.4GHz Quad-Core Processor](http://pcpartpicker.com/product/7V7CmG/intel-cpu-bx80662i76700) | $294.68 @ OutletPC 
**CPU Cooler** | [be quiet! SHADOW ROCK LP 51.4 CFM CPU Cooler](http://pcpartpicker.com/product/9FGj4D/be-quiet-cpu-cooler-bk002) | $29.90 @ Newegg 
**Motherboard** | [Asus Z170-E ATX LGA1151 Motherboard](http://pcpartpicker.com/product/k4dFf7/asus-motherboard-z170e) | $130.95 @ Amazon 
**Memory** | [Corsair Vengeance LPX 32GB (2 x 16GB) DDR4-2666 Memory](http://pcpartpicker.com/product/nDx9TW/corsair-memory-cmk32gx4m2a2666c16r) | $159.99 @ Newegg 
**Storage** | [Samsung SM951 256GB M.2-2280 Solid State Drive](http://pcpartpicker.com/product/Tr7CmG/samsung-internal-hard-drive-mzhpv256hdgl00000) | $160.00 
**Storage** | [Western Digital Caviar Black 1TB 3.5"" 7200RPM Internal Hard Drive](http://pcpartpicker.com/product/gV8Zxr/western-digital-internal-hard-drive-wd1002faex) | $74.00 @ Amazon 
**Video Card** | [Zotac GeForce GTX 1080 8GB AMP! Edition Video Card](http://pcpartpicker.com/product/KC648d/zotac-geforce-gtx-1080-8gb-amp-edition-video-card-zt-p10800c-10p) | $604.00 @ B&amp;H 
**Case** | [Fractal Design Define R5 w/Window (Black) ATX Mid Tower Case](http://pcpartpicker.com/product/9XL7YJ/fractal-design-case-fdcadefr5bkw) | $119.99 @ NCIX US 
**Power Supply** | [Corsair RMx 650W 80+ Gold Certified Fully-Modular ATX Power Supply](http://pcpartpicker.com/product/Rp8H99/corsair-power-supply-cp9020091na) | $102.50 @ Amazon 
 | *Prices include shipping, taxes, rebates, and discounts* |
 | **Total** | **$1676.01**
 | Generated by [PCPartPicker](http://pcpartpicker.com) 2016-10-16 08:08 EDT-0400 |",57,54
555,2016-10-16,2016,10,16,23,57rq9f,[R] Temporal Ensembling for Semi-Supervised Learning,https://www.reddit.com/r/MachineLearning/comments/57rq9f/r_temporal_ensembling_for_semisupervised_learning/,liviu-,1476629433,,2,18
556,2016-10-17,2016,10,17,0,57rvtj,[P][D] Time Series classifier,https://www.reddit.com/r/MachineLearning/comments/57rvtj/pd_time_series_classifier/,Guanoco,1476631565,"Hello all.

I want to be able to classify a time series of the response of a system when it is turned on and until it reaches some steady state.

Now I have time series of different types of systems (let's say of different quality of the systems).
I want to be able to predict the quality of the system based on the time series.

I know I could use some feature engineering, but I would much rather not have to. 
The other catches are
1)time series are not necessarily of the same length between quality classes and even in the same class
2)i cannot standardize the time series to make them zero mean unit variance
3)I have less than 500 time series for 2 classes",21,8
557,2016-10-17,2016,10,17,0,57rw72,Data Mining Hacker News: Front vs Back,https://www.reddit.com/r/MachineLearning/comments/57rw72/data_mining_hacker_news_front_vs_back/,Dogsindahouse1,1476631711,,0,1
558,2016-10-17,2016,10,17,1,57s3nv,Product description copywriting by a Bot,https://www.reddit.com/r/MachineLearning/comments/57s3nv/product_description_copywriting_by_a_bot/,StephanCatc,1476634324,,0,1
559,2016-10-17,2016,10,17,1,57s9gv,"In this video, why Nando multiplies approximated integral with delta function?",https://www.reddit.com/r/MachineLearning/comments/57s9gv/in_this_video_why_nando_multiplies_approximated/,[deleted],1476636257,[removed],0,1
560,2016-10-17,2016,10,17,2,57sdxd,"[Discussion] In this video, why Nando multiplies approximated integral with delta function?",https://www.reddit.com/r/MachineLearning/comments/57sdxd/discussion_in_this_video_why_nando_multiplies/,deepmind2016,1476637715,"In this video(https://www.youtube.com/watch?v=TNZk8lo4e-Q) at 25:22, Nando multiplies approximated integral(which has been approximated using law of large numbers) with delta function(which counts the number of samples in dtheta) in importance sampling. What's the role of delta function?, we have already approximated integral and have probability distribution over theta. Why we need delta function?",1,0
561,2016-10-17,2016,10,17,2,57sifb,Help me do this cancer classification problem,https://www.reddit.com/r/MachineLearning/comments/57sifb/help_me_do_this_cancer_classification_problem/,sanjuak47007,1476639167,[removed],0,1
562,2016-10-17,2016,10,17,2,57sk62,"An Overarching, Down-to-Fundamental tutorial on Bayesian Black Box Optimization for Machine Learning.",https://www.reddit.com/r/MachineLearning/comments/57sk62/an_overarching_downtofundamental_tutorial_on/,[deleted],1476639736,[deleted],0,1
563,2016-10-17,2016,10,17,3,57swuy,"Misc stuff: The verification gap, ML training and more",https://www.reddit.com/r/MachineLearning/comments/57swuy/misc_stuff_the_verification_gap_ml_training_and/,yoav_hollander,1476643843,,0,1
564,2016-10-17,2016,10,17,4,57sz7u,"[D] Any insight for Microsoft's recently open-sourced lightGBM, which outperforms xgboost on both efficiency and accuracy?",https://www.reddit.com/r/MachineLearning/comments/57sz7u/d_any_insight_for_microsofts_recently_opensourced/,hetong_007,1476644554,,16,76
565,2016-10-17,2016,10,17,4,57t8vv,"[P]An Overarching, Down-to-Fundamental tutorial on Bayesian Black Box Optimization for Machine Learning",https://www.reddit.com/r/MachineLearning/comments/57t8vv/pan_overarching_downtofundamental_tutorial_on/,Dark_Element75,1476647701,,4,4
566,2016-10-17,2016,10,17,5,57tdyz,[discussion] Auto Grouping of Faces using deep learning,https://www.reddit.com/r/MachineLearning/comments/57tdyz/discussion_auto_grouping_of_faces_using_deep/,youngChange,1476649343,"I am a 3rd year CS student and I am trying to create an application which will auto-group photos of the same person like google photos does.
I understand that I can use methods such as k-means, but that would be too slow. Is there a deep learning alternative I can use?.

I have alright knowledge of basic neural networks and cnns having done the cs231n course. But all of the methods they discuss are supervised ones...can someone point me in the right direction? thank you.
",7,0
567,2016-10-17,2016,10,17,7,57twwv,[Discussion]pca on finance/time series data,https://www.reddit.com/r/MachineLearning/comments/57twwv/discussionpca_on_financetime_series_data/,pcaquestions,1476655710,"I've been working on a project and I'm not sure how to approach using pca on a certain data set. The way I used PCA before was when given say m examples(of faces or something labelled) with n features, the # of features was reduced to a certain # of principle components.
The current dataset I'm looking to reduce has data on currency markets in the following format:
http://imgur.com/a/td7CP

So 1st column deals w/ dates, the rest of the columns have the  exchange rate at the date given by the 1st column
I haven't dealt with time series so I'm not sure how to approach this. Would I be reducing the dimensions of each year? Doesn't feel right to me .

edit: the full dataset has about 3k dates and 18 currencies
and its the returns on the exchange rate, not the exchange rate",7,0
568,2016-10-17,2016,10,17,7,57txxx,"[N] ""Creative Applications of Deep Learning with TensorFlow"" Relaunching Soon - Sign up to join new cohort",https://www.reddit.com/r/MachineLearning/comments/57txxx/n_creative_applications_of_deep_learning_with/,pkmital,1476656084,,8,11
569,2016-10-17,2016,10,17,9,57ugoh,[Research] Multifaceted Feature Visualization: Uncovering the different types of features learned by each neuron in deep neural networks,https://www.reddit.com/r/MachineLearning/comments/57ugoh/research_multifaceted_feature_visualization/,[deleted],1476662789,[deleted],0,1
570,2016-10-17,2016,10,17,9,57ugur,[Discussion] Advice on a Deep Learning Mobile Workstation/Laptop,https://www.reddit.com/r/MachineLearning/comments/57ugur/discussion_advice_on_a_deep_learning_mobile/,aibuff,1476662861,"Hi Reddit Machine Learning Community,
I dont know if this question suits this subreddit so apologies for my ignorance.
I am planning to get my feet wet in the deep learning and eventually using amazon/azure for data processing purposes. But till then I want to experiment with initial Kaggle data-sets like Titanic , MNIST etc. and I am planning to buy a gaming laptop for the same. I am not in a position to buy a desktop as I dont have the space for it ( currently sharing room with roommates) and I want my workstation to be mobile. Can anyone provide me any suggestions opinions? My budget is betweeen $1000-$1500.",6,0
571,2016-10-17,2016,10,17,9,57uhb5,[D] What is the state of the art in OCR for printed documents?,https://www.reddit.com/r/MachineLearning/comments/57uhb5/d_what_is_the_state_of_the_art_in_ocr_for_printed/,logicflow,1476663010,"Software OCR for printed documents (e.g. ABBYY FineReader) is becoming quite good, but I havent been able to find any literature on which techniques are used. Im assuming the best results are using a CNN based pipeline but would appreciate if someone could point me to some papers on the topic. Thanks!
",13,22
572,2016-10-17,2016,10,17,9,57uhk4,[D] Similarity measure between encoded paragraphs and best encoding method for paragraphs,https://www.reddit.com/r/MachineLearning/comments/57uhk4/d_similarity_measure_between_encoded_paragraphs/,Pieranha,1476663104,"I want to encode 1-5 sentences at a time using an approach similar to word2vec, but for paragraphs. I have 2 questions in this regard:

1. Which method is the preferred approach for encoding such paragraphs? I've found Paragraph Vectors (http://www.jmlr.org/proceedings/papers/v32/le14.pdf), but the paper is a bit old in this very fast-moving field. Also, I'm particularly interested in capturing word order with the embedding, which may favor a specific approach. I'm not aware of the subtleties of the different nethods.

2. I want to compare my embeddings of paragraphs. Suppose I have an embedding of a paragraph such as Paragraph Vector or an averaged word2vec. Would it still make sense to use cosine similarity between the embeddings like for word2vec?

Thanks!",12,9
573,2016-10-17,2016,10,17,10,57uph7,Hadamard Product for Low-rank Bilinear Pooling,https://www.reddit.com/r/MachineLearning/comments/57uph7/hadamard_product_for_lowrank_bilinear_pooling/,jnhwkim,1476666103,,5,5
574,2016-10-17,2016,10,17,12,57vd6c,Question about Dilated convolution/Padding for WAVENET,https://www.reddit.com/r/MachineLearning/comments/57vd6c/question_about_dilated_convolutionpadding_for/,gmkim90,1476675359,[removed],0,1
575,2016-10-17,2016,10,17,13,57vm4r,Generation of speech: Stochastic RNN vs. WAVENET,https://www.reddit.com/r/MachineLearning/comments/57vm4r/generation_of_speech_stochastic_rnn_vs_wavenet/,gmkim90,1476679238,[removed],0,1
576,2016-10-17,2016,10,17,14,57vtll,"Has anyone tried training classifiers with noise that is labelled with a NULL label, before training them with meaningful examples?",https://www.reddit.com/r/MachineLearning/comments/57vtll/has_anyone_tried_training_classifiers_with_noise/,[deleted],1476682829,[removed],0,1
577,2016-10-17,2016,10,17,15,57vzsc,[R] Why Deep Neural Networks? [arXiv:1610.04161],https://www.reddit.com/r/MachineLearning/comments/57vzsc/r_why_deep_neural_networks_arxiv161004161/,infstudent,1476686084,,12,49
578,2016-10-17,2016,10,17,15,57w0h4,what draws you to the field of Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/57w0h4/what_draws_you_to_the_field_of_machine_learning/,strunberg,1476686450,[removed],0,1
579,2016-10-17,2016,10,17,16,57w3fp,[R] Sim-to-Real Robot Learning from Pixels with Progressive Nets (DeepMind),https://www.reddit.com/r/MachineLearning/comments/57w3fp/r_simtoreal_robot_learning_from_pixels_with/,cbfinn,1476688137,,5,23
580,2016-10-17,2016,10,17,18,57wfwb,"""Dont trust that algorithm"". Worth entire read",https://www.reddit.com/r/MachineLearning/comments/57wfwb/dont_trust_that_algorithm_worth_entire_read/,[deleted],1476695897,[deleted],0,1
581,2016-10-17,2016,10,17,18,57whpz,Introduction talk to ANNs (Adaptive Neural Networks),https://www.reddit.com/r/MachineLearning/comments/57whpz/introduction_talk_to_anns_adaptive_neural_networks/,[deleted],1476697080,[deleted],2,3
582,2016-10-17,2016,10,17,18,57wipp,MovieLens collaberative filtering system,https://www.reddit.com/r/MachineLearning/comments/57wipp/movielens_collaberative_filtering_system/,DsMick,1476697737,[removed],0,1
583,2016-10-17,2016,10,17,19,57wnsq,World MFG Provides Tech Long Filler Parts and Service,https://www.reddit.com/r/MachineLearning/comments/57wnsq/world_mfg_provides_tech_long_filler_parts_and/,iamleah8795,1476700677,,0,1
584,2016-10-17,2016,10,17,19,57wp12,"[N] ""Dont trust that algorithm"". Worth entire read.",https://www.reddit.com/r/MachineLearning/comments/57wp12/n_dont_trust_that_algorithm_worth_entire_read/,guukizl,1476701403,,42,46
585,2016-10-17,2016,10,17,19,57wpc1,Most insane guide for building a deep learning machine,https://www.reddit.com/r/MachineLearning/comments/57wpc1/most_insane_guide_for_building_a_deep_learning/,3150,1476701571,,0,1
586,2016-10-17,2016,10,17,21,57x3ci,How to learn 'end of sequence' for continuous sequence?,https://www.reddit.com/r/MachineLearning/comments/57x3ci/how_to_learn_end_of_sequence_for_continuous/,gmkim90,1476707982,[removed],0,1
587,2016-10-17,2016,10,17,22,57x80o,[D] How do different deep learning frameworks handle sequence lengths?,https://www.reddit.com/r/MachineLearning/comments/57x80o/d_how_do_different_deep_learning_frameworks/,ldrude,1476709754,"When training a sequence to sequence model or maybe a CTC based ASR system, you are either forced to use a batch size of one, or need to account for varying sequence lengths for each batch element in every single network element in your model.

Tensorflow's tf.nn.dynamic_rnn() function handles this, by just updating the state of an RNN, when the current time index is still valid for a batch entry. Otherwise, the old state is kept and it outputs zeros for all newer frames. A blog post about this is provided in [1] and was already discussed in /r/MachineLearning. The lasagne wrapper uses a mask_input for the lasagne.layers.RecurrentLayer [3].

Nevertheless, this does not solve the problem for other parts of a model. A model might as well contain CNN layers, where one dimension is dynamic. Even a regular RNN might have a final linear layer, which also needs to account for different sequence lengths.

An often used technique is to use masking in the loss function. Chainer for example does this, by introducing an ignore label [2].

The problem becomes more apparent, when you want to use normalization (i.e. batch normalization or normalization along the time axis). In case of a batch normalization, gradients incoming to an underlying linear layer may change its weight matrix along invalid paths.

Sorting your data in approximately equal lengths utterances or using bucketing is a good idea, but does not entirely solve the problem.

TLDR: Can different sequence lengths be handled at a framework level or does every network element need to be changed in order to be sequence-lengths-ready?

[1] https://danijar.com/variable-sequence-lengths-in-tensorflow/
[2] https://github.com/pfnet/chainer/blob/285e6558640425f61b6aa8c00564ccf37643babb/chainer/functions/loss/softmax_cross_entropy.py#L63
[3] http://lasagne.readthedocs.io/en/latest/modules/layers/recurrent.html#lasagne.layers.CustomRecurrentLayer",6,6
588,2016-10-17,2016,10,17,22,57xaem,[R] [1610.04490] Amortised MAP Inference for Image Super-Resolution: Connects GANs to MAP and Variational inference,https://www.reddit.com/r/MachineLearning/comments/57xaem/r_161004490_amortised_map_inference_for_image/,casperkaae,1476710624,,8,28
589,2016-10-17,2016,10,17,22,57xcz0,[Research] DataGenCARS: Java-based Generator of Synthetic Data for the Evaluation of Context-Aware Recommendation Systems,https://www.reddit.com/r/MachineLearning/comments/57xcz0/research_datagencars_javabased_generator_of/,sybilckw,1476711591,,1,3
590,2016-10-17,2016,10,17,22,57xf8j,[News] Alphabet and J&amp;J Working on a Surgeon Robot,https://www.reddit.com/r/MachineLearning/comments/57xf8j/news_alphabet_and_jj_working_on_a_surgeon_robot/,beeftug,1476712430,,0,1
591,2016-10-17,2016,10,17,23,57xhj9,[News] Machine Learnings #13: Rotting organs and self aware machines,https://www.reddit.com/r/MachineLearning/comments/57xhj9/news_machine_learnings_13_rotting_organs_and_self/,beeftug,1476713201,,0,1
592,2016-10-18,2016,10,18,0,57xt2o,[D] Optimizing your ML workflow: how do/did you find your happy place?,https://www.reddit.com/r/MachineLearning/comments/57xt2o/d_optimizing_your_ml_workflow_how_dodid_you_find/,luminerius,1476716956,"Hi ML! We have a ton of tutorials and discussions about ML hardware systems/providers and libraries/frameworks here, but I feel we don't talk nearly enough about the workflows we use to utilize those technologies, which are often just as important to success. 

So let's have a quick chat about ML workflows! How do you spend your time? What tools do you use on a typical project, and in what order? How did you arrive at your current workflow, and what do you wish you could improve with it?",36,39
593,2016-10-18,2016,10,18,0,57xw56,[Discussion] Machine Learning - WAYR (What Are You Reading) - Week 11,https://www.reddit.com/r/MachineLearning/comments/57xw56/discussion_machine_learning_wayr_what_are_you/,Mandrathax,1476717908,"This is a place to share machine learning research papers, journals, and articles that you're reading this week.
If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.  

|Previous weeks|
|--------------|
|[Week 1](https://www.reddit.com/r/MachineLearning/comments/4qyjiq/machine_learning_wayr_what_are_you_reading_week_1/)|  
|[Week 2](https://www.reddit.com/r/MachineLearning/comments/4s2xqm/machine_learning_wayr_what_are_you_reading_week_2/)|  
|[Week 3](https://www.reddit.com/r/MachineLearning/comments/4t7mqm/machine_learning_wayr_what_are_you_reading_week_3/)|  
|[Week 4](https://www.reddit.com/r/MachineLearning/comments/4ub2kw/machine_learning_wayr_what_are_you_reading_week_4/)| 
|[Week 5](https://www.reddit.com/r/MachineLearning/comments/4xomf7/machine_learning_wayr_what_are_you_reading_week_5/)| 
|[Week 6](https://www.reddit.com/r/MachineLearning/comments/4zcyvk/machine_learning_wayr_what_are_you_reading_week_6/)|
|[Week 7](https://www.reddit.com/r/MachineLearning/comments/52t6mo/machine_learning_wayr_what_are_you_reading_week_7/)|
|[Week 8](https://www.reddit.com/r/MachineLearning/comments/53heol/machine_learning_wayr_what_are_you_reading_week_8/)|
|[Week 9](https://www.reddit.com/r/MachineLearning/comments/54kvsu/machine_learning_wayr_what_are_you_reading_week_9/)|
|[Week 10](https://www.reddit.com/r/MachineLearning/comments/56s2oa/discussion_machine_learning_wayr_what_are_you/)|

Most upvoted papers last week : 
 
[Pixel Recurrent Neural Networks](https://arxiv.org/abs/1601.06759)

[Residual Networks are Exponential Ensembles of Relatively Shallow Networks](https://arxiv.org/abs/1605.06431)

[Hybrid computing using a neural network with dynamic external memory](http://www.nature.com/nature/journal/vaop/ncurrent/full/nature20101.html)

[gvnn: Neural Network Library for Geometric Computer Vision](https://arxiv.org/abs/1607.07405)

Besides that, there are no rules, have fun.",17,36
594,2016-10-18,2016,10,18,0,57xw6r,Image Recognition in Python with Keras,https://www.reddit.com/r/MachineLearning/comments/57xw6r/image_recognition_in_python_with_keras/,elisebreda,1476717920,,0,1
595,2016-10-18,2016,10,18,0,57xz3m,"Topic Modeling for Humans, and the Advance of NLP",https://www.reddit.com/r/MachineLearning/comments/57xz3m/topic_modeling_for_humans_and_the_advance_of_nlp/,SethGrimes,1476718816,,0,2
596,2016-10-18,2016,10,18,1,57y8ny,Entering ML from an undergrad mechanical/aerospace engineering perspective,https://www.reddit.com/r/MachineLearning/comments/57y8ny/entering_ml_from_an_undergrad_mechanicalaerospace/,PartPangolin,1476721656,[removed],0,1
597,2016-10-18,2016,10,18,1,57yaix,[N] Russ Salakhutdinov becomes Apple's Director of AI research,https://www.reddit.com/r/MachineLearning/comments/57yaix/n_russ_salakhutdinov_becomes_apples_director_of/,downtownslim,1476722204,,28,157
598,2016-10-18,2016,10,18,3,57yv9d,I want to implement my own optimizer/solver algorithm and test it on deep neural networks. Which framework/library/code is easiest to work on?,https://www.reddit.com/r/MachineLearning/comments/57yv9d/i_want_to_implement_my_own_optimizersolver/,[deleted],1476728072,[removed],0,1
599,2016-10-18,2016,10,18,3,57yybw,[Project] Deconvolution and Checkerboard Artifacts,https://www.reddit.com/r/MachineLearning/comments/57yybw/project_deconvolution_and_checkerboard_artifacts/,abhishkk65,1476728975,,21,84
600,2016-10-18,2016,10,18,3,57z37g,Shahaboddin Shamshirband Author Profile - Semantic Scholar,https://www.reddit.com/r/MachineLearning/comments/57z37g/shahaboddin_shamshirband_author_profile_semantic/,shamshirband,1476730405,,0,1
601,2016-10-18,2016,10,18,5,57zn49,R Tools for Visual Studio 0.5 available for download: SQL integration + multi-plot management.,https://www.reddit.com/r/MachineLearning/comments/57zn49/r_tools_for_visual_studio_05_available_for/,smortaz,1476736204,,0,1
602,2016-10-18,2016,10,18,5,57zovy,Where should I apply for Machine Learning internships as an undergraduate?,https://www.reddit.com/r/MachineLearning/comments/57zovy/where_should_i_apply_for_machine_learning/,alexalexlacey,1476736720,[removed],0,1
603,2016-10-18,2016,10,18,6,57zu9s,Are Machines Conscious ? | Debate | Ray Kurzweil Vs David Gelernter,https://www.reddit.com/r/MachineLearning/comments/57zu9s/are_machines_conscious_debate_ray_kurzweil_vs/,minionsinforest,1476738320,,0,1
604,2016-10-18,2016,10,18,7,580cjh,What Are The Best Universities For Machine Vision?,https://www.reddit.com/r/MachineLearning/comments/580cjh/what_are_the_best_universities_for_machine_vision/,Xepa777,1476743961,[removed],0,1
605,2016-10-18,2016,10,18,11,581e0w,Classification problem with training set contains string and numeral data,https://www.reddit.com/r/MachineLearning/comments/581e0w/classification_problem_with_training_set_contains/,Laurence-Lin,1476756785,[removed],0,1
606,2016-10-18,2016,10,18,15,582gc5,Industrial neural network libraries ?,https://www.reddit.com/r/MachineLearning/comments/582gc5/industrial_neural_network_libraries/,Thomas_Au,1476773289,[removed],0,1
607,2016-10-18,2016,10,18,16,582lxx,Why does industrial plastic mixing tanks in hot sale?,https://www.reddit.com/r/MachineLearning/comments/582lxx/why_does_industrial_plastic_mixing_tanks_in_hot/,mixmachinery,1476776494,,1,1
608,2016-10-18,2016,10,18,22,583tn8,need help choose reinforcement learning model,https://www.reddit.com/r/MachineLearning/comments/583tn8/need_help_choose_reinforcement_learning_model/,perecastor,1476797941,[removed],0,1
609,2016-10-18,2016,10,18,23,583xeu,New switching service utilises machine learning to save customers on their energy bills,https://www.reddit.com/r/MachineLearning/comments/583xeu/new_switching_service_utilises_machine_learning/,reworkdiane,1476799256,,0,1
610,2016-10-18,2016,10,18,23,58414p,[R] Achieving Human Parity in Conversational Speech Recognition,https://www.reddit.com/r/MachineLearning/comments/58414p/r_achieving_human_parity_in_conversational_speech/,tuan3w,1476800471,,34,46
611,2016-10-18,2016,10,18,23,584221,Machine learning for noob,https://www.reddit.com/r/MachineLearning/comments/584221/machine_learning_for_noob/,mechezawad,1476800766,,0,1
612,2016-10-19,2016,10,19,1,584qar,"h2o.ai and PredictionIO, which one has more active community?",https://www.reddit.com/r/MachineLearning/comments/584qar/h2oai_and_predictionio_which_one_has_more_active/,knguyen0105,1476808126,[removed],0,1
613,2016-10-19,2016,10,19,2,584z36,[R] Density Estimation using Real NVP talk at Twitter by Laurent Dinh,https://www.reddit.com/r/MachineLearning/comments/584z36/r_density_estimation_using_real_nvp_talk_at/,prajit,1476810585,,12,25
614,2016-10-19,2016,10,19,3,585gwa,Attack discrimination with smarter machine learning,https://www.reddit.com/r/MachineLearning/comments/585gwa/attack_discrimination_with_smarter_machine/,Dogsindahouse1,1476815616,,0,1
615,2016-10-19,2016,10,19,3,585icn,New Budget GPU (GTX 1050 (TI)) any good?,https://www.reddit.com/r/MachineLearning/comments/585icn/new_budget_gpu_gtx_1050_ti_any_good/,[deleted],1476816016,[removed],0,1
616,2016-10-19,2016,10,19,4,585n2f,Analyzing 50k fonts using deep neural networks,https://www.reddit.com/r/MachineLearning/comments/585n2f/analyzing_50k_fonts_using_deep_neural_networks/,elisebreda,1476817371,,0,1
617,2016-10-19,2016,10,19,4,585uw4,Introducing the AI Open Network: a 100% open-source AI research community.,https://www.reddit.com/r/MachineLearning/comments/585uw4/introducing_the_ai_open_network_a_100_opensource/,[deleted],1476819532,[deleted],1,2
618,2016-10-19,2016,10,19,4,585wnd,[R] Learning in Implicit Generative Models,https://www.reddit.com/r/MachineLearning/comments/585wnd/r_learning_in_implicit_generative_models/,liviu-,1476820044,,2,16
619,2016-10-19,2016,10,19,5,585ztj,[News] Microsoft researchers reach human parity in conversational speech recognition,https://www.reddit.com/r/MachineLearning/comments/585ztj/news_microsoft_researchers_reach_human_parity_in/,beeftug,1476820938,,0,1
620,2016-10-19,2016,10,19,5,5863cq,[R] Introducing the AI Open Network: a 100% open-source AI research community.,https://www.reddit.com/r/MachineLearning/comments/5863cq/r_introducing_the_ai_open_network_a_100/,clear_coprolite,1476821942,,18,216
621,2016-10-19,2016,10,19,5,5867uw,For people looking for a cheap upgrade to NVIDIA GPU for faster training,https://www.reddit.com/r/MachineLearning/comments/5867uw/for_people_looking_for_a_cheap_upgrade_to_nvidia/,[deleted],1476823224,[deleted],0,1
622,2016-10-19,2016,10,19,6,586dvd,New GTX 1050 (TI) worthwhile?,https://www.reddit.com/r/MachineLearning/comments/586dvd/new_gtx_1050_ti_worthwhile/,[deleted],1476824944,[removed],0,1
623,2016-10-19,2016,10,19,6,586nto,Learn how Machine Learning applies to Cloud Computing at $1 with Cloud Academy,https://www.reddit.com/r/MachineLearning/comments/586nto/learn_how_machine_learning_applies_to_cloud/,[deleted],1476827960,[removed],0,0
624,2016-10-19,2016,10,19,7,586nz0,RNNs and self-driving car models (livestream),https://www.reddit.com/r/MachineLearning/comments/586nz0/rnns_and_selfdriving_car_models_livestream/,vanboxel,1476828009,,0,1
625,2016-10-19,2016,10,19,7,586yyh,VGG Face weights are ported to Keras with both Tensorflow and Theano support.,https://www.reddit.com/r/MachineLearning/comments/586yyh/vgg_face_weights_are_ported_to_keras_with_both/,[deleted],1476831498,[deleted],0,1
626,2016-10-19,2016,10,19,8,5870v9,[P] VGG Face weights are ported to Keras with both Tensorflow and Theano support.,https://www.reddit.com/r/MachineLearning/comments/5870v9/p_vgg_face_weights_are_ported_to_keras_with_both/,rcmalli,1476832099,,0,8
627,2016-10-19,2016,10,19,9,587ig9,[D] New GTX 1050 (Ti) worthwhile?,https://www.reddit.com/r/MachineLearning/comments/587ig9/d_new_gtx_1050_ti_worthwhile/,Jaden71,1476838117,"Nvidia is releasing a new [GPU](http://www.geforce.com/hardware/10series/geforce-gtx-1050)
soon and I was wondering if this would be viable as a GPU for a budget hobbyist build to learn deep learning. Should this suffice or are there any other viable options that don't cost an arm and a leg? How would this compare to what I have now (solely on an i7-4790k)?

Thanks in advance.

(I'm a poor student and don't have a lot of money so the price tags of cards such as 1080, Titan X, etc. are out of the question).",30,0
628,2016-10-19,2016,10,19,13,588inr,United States Cabinet Knobs Market Report 2016,https://www.reddit.com/r/MachineLearning/comments/588inr/united_states_cabinet_knobs_market_report_2016/,markhub123,1476851728,,0,1
629,2016-10-19,2016,10,19,14,588ou7,JT-2 automatic stainless steel dish end/head seal surface polish buffing machine.,https://www.reddit.com/r/MachineLearning/comments/588ou7/jt2_automatic_stainless_steel_dish_endhead_seal/,polishingmachinery,1476854640,,0,1
630,2016-10-19,2016,10,19,15,588yiq,Machine learning in real life scenario in retail sector.,https://www.reddit.com/r/MachineLearning/comments/588yiq/machine_learning_in_real_life_scenario_in_retail/,vinayakk123,1476859753,[removed],0,1
631,2016-10-19,2016,10,19,16,58952f,PHP and Machine Learning,https://www.reddit.com/r/MachineLearning/comments/58952f/php_and_machine_learning/,[deleted],1476863489,[removed],0,1
632,2016-10-19,2016,10,19,16,58959v,[P] Questions about binning/bucketing in TF,https://www.reddit.com/r/MachineLearning/comments/58959v/p_questions_about_binningbucketing_in_tf/,ShakespearePoop,1476863635,"Hi all,

Looking to get into tensorflow by porting a [model](https://github.com/harvardnlp/im2markup/). The gist of the model is a CNN followed by a bi-directional RNN which encodes input images with sizes that fall into 9 buckets/bins, and an attention-based decoder which computes a context vector of the same size (regardless of input size) and runs for varying timesteps (one timestep per token in the output). I'm not sure how to go about organizing the data for efficient computation. 

For the encoder, would I create a different model for each input size bucket and share variables? Is it easier to just pad all images to a uniform size? 

For the decoder, padding would seem pretty inefficient as the mean output sequence length seems to be somewhere around 150-200, but a decent number of sequences go from several hundred all the way to ~1050.

",0,0
633,2016-10-19,2016,10,19,17,5899cq,United States Exhaust Fans Market Report 2016,https://www.reddit.com/r/MachineLearning/comments/5899cq/united_states_exhaust_fans_market_report_2016/,markhub123,1476866226,,0,1
634,2016-10-19,2016,10,19,18,589ctf,United States Gas Heating Stoves Market Report 2016,https://www.reddit.com/r/MachineLearning/comments/589ctf/united_states_gas_heating_stoves_market_report/,markhub123,1476868394,,0,1
635,2016-10-19,2016,10,19,18,589fyl,[P] Multicore t-SNE implementation with Python and Torch wrappers.,https://www.reddit.com/r/MachineLearning/comments/589fyl/p_multicore_tsne_implementation_with_python_and/,dmitry_ulyanov,1476870281,,13,63
636,2016-10-19,2016,10,19,21,589zg7,[R] Not about sure about what to research,https://www.reddit.com/r/MachineLearning/comments/589zg7/r_not_about_sure_about_what_to_research/,Sohakes,1476880005,"Hi everyone!

I'm planning on doing my master degree in Machine Learning. I have some knowledge in the area, since I had done two undergraduate researches on it (one only tangentially related) and completed Andrew Ng's course in Coursera.

Anyway, I need to make a simple research plan, maximum 30 lines long, to apply for the research. It's just so the professors analyzing my submission don't feel I'm completely lost in the area. In the end it will probably not be used, but it could, and it gives the professor some idea of what I want to do.

Although the research plan will (probably) not be followed if I get selected for the master, I think it's important to do it well. So I was trying to come up with an interesting problem that I could tackle. With the help of some friends, I could think of a few directions to take:

- Test many algorithms in CUDA to compare performance (if no one did this before)

- Apply neural networks to solve some game problem (although it looks really hard to do something novel since they already somewhat solved even Go as far as I know)

- Create a novel machine learning algorithm (but I have no idea what to propose)

- Create a method to generate synthetic datasets based on real ones (not sure if it's a problem for a master thesis or if it's too easy)

If I could research something that is good for humanity it would be even better, but I have no idea where to start on that, and I guess most things are being researched by people way more qualified than me.

Thanks!",10,0
637,2016-10-19,2016,10,19,22,58a4si,Predicting Future Human Behavior With Deep Learning,https://www.reddit.com/r/MachineLearning/comments/58a4si/predicting_future_human_behavior_with_deep/,reworksophie,1476882108,,0,1
638,2016-10-19,2016,10,19,23,58ajkg,"Dont interpret linear hidden units, they dont exist.",https://www.reddit.com/r/MachineLearning/comments/58ajkg/dont_interpret_linear_hidden_units_they_dont_exist/,benjaminwilson,1476887269,,7,4
639,2016-10-20,2016,10,20,0,58asz3,Anyone working with faster CNN code,https://www.reddit.com/r/MachineLearning/comments/58asz3/anyone_working_with_faster_cnn_code/,ankurgupta7,1476890215,[removed],1,1
640,2016-10-20,2016,10,20,0,58at3y,Loss function location in GBM,https://www.reddit.com/r/MachineLearning/comments/58at3y/loss_function_location_in_gbm/,Slayj,1476890255,[removed],0,1
641,2016-10-20,2016,10,20,0,58b00r,"Simple Questions Thread October 19, 2016",https://www.reddit.com/r/MachineLearning/comments/58b00r/simple_questions_thread_october_19_2016/,AutoModerator,1476892351,"Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!

Thread will stay alive until next one so keep posting after the date in the title.

Thanks to everyone for answering questions in the previous thread!
",40,6
642,2016-10-20,2016,10,20,2,58blab,DeepTeach: the interactive deep image classifier builder,https://www.reddit.com/r/MachineLearning/comments/58blab/deepteach_the_interactive_deep_image_classifier/,ddcarnage,1476898517,,18,59
643,2016-10-20,2016,10,20,3,58brtw,[D] What do you think of Stripe's primer on machine learning for fraud detection?,https://www.reddit.com/r/MachineLearning/comments/58brtw/d_what_do_you_think_of_stripes_primer_on_machine/,beeftug,1476900396,,0,1
644,2016-10-20,2016,10,20,3,58bxs7,A comparison of state-of-the-art graph processing systems,https://www.reddit.com/r/MachineLearning/comments/58bxs7/a_comparison_of_stateoftheart_graph_processing/,gwulfs,1476902083,,0,1
645,2016-10-20,2016,10,20,5,58cmua,[P] An implementation of a parallel multicore procedure to solve SVMs and semiparametric SVMs,https://www.reddit.com/r/MachineLearning/comments/58cmua/p_an_implementation_of_a_parallel_multicore/,RobeDM,1476909273,,4,16
646,2016-10-20,2016,10,20,5,58cosw,[Discussion] Could Deep Learning help decrease corruption in politics?,https://www.reddit.com/r/MachineLearning/comments/58cosw/discussion_could_deep_learning_help_decrease/,brockl33,1476909839,"Recent evidence has shown that there are paid actors posing as regular citizens in order to achieve political aims:

https://www.youtube.com/watch?v=U-4w_jf_w0o

https://www.reddit.com/r/The_Donald/comments/589z26/domestic_political_terrorist_paid_by_hillarys/

This was discovered through manual facial recognition between youtube videos.

Could deep learning be used to detect faces that regularly appear in videos of protests to identify ""regulars"" a.k.a. paid agents that move around the country organizing fake protests?

I want to ask whether deep learning could help sift through the WikiLeaks emails for collusion, but that task seems far away.

Veritas expose https://youtu.be/5IuJGHuIkzY

More info on the manual facial identification https://www.reddit.com/r/The_Donald/comments/589x16/wikileaks_confirm_okeefe_claims_undeniable_email/",11,0
647,2016-10-20,2016,10,20,6,58cs88,Does anyone have solutions to Harvard's CS 281 practice midterm?,https://www.reddit.com/r/MachineLearning/comments/58cs88/does_anyone_have_solutions_to_harvards_cs_281/,[deleted],1476910841,[deleted],0,1
648,2016-10-20,2016,10,20,6,58cuei,[Discussion] Does anyone have solutions to Harvard's CS 281 practice midterm?,https://www.reddit.com/r/MachineLearning/comments/58cuei/discussion_does_anyone_have_solutions_to_harvards/,deepmind2016,1476911487,,0,1
649,2016-10-20,2016,10,20,6,58cyc5,[Discussion] Does anyone have solutions to Harvard's CS 281 practice midterm?,https://www.reddit.com/r/MachineLearning/comments/58cyc5/discussion_does_anyone_have_solutions_to_harvards/,Mr__Christian_Grey,1476912666,,0,1
650,2016-10-20,2016,10,20,7,58d6c6,how to effectively merge 8 product catalogues with different hierarchies,https://www.reddit.com/r/MachineLearning/comments/58d6c6/how_to_effectively_merge_8_product_catalogues/,gstoel,1476915210,[removed],0,1
651,2016-10-20,2016,10,20,7,58d71u,Machine Learning &amp; Blockvhain,https://www.reddit.com/r/MachineLearning/comments/58d71u/machine_learning_blockvhain/,bule1700,1476915436,[removed],0,1
652,2016-10-20,2016,10,20,7,58dcrl,[N] Release: spaCy 1.0. Now much easier to create custom NLP pipelines.,https://www.reddit.com/r/MachineLearning/comments/58dcrl/n_release_spacy_10_now_much_easier_to_create/,syllogism_,1476917267,,6,87
653,2016-10-20,2016,10,20,9,58drpj,[Discussion] Dark Forest Theory of Machine Learning,https://www.reddit.com/r/MachineLearning/comments/58drpj/discussion_dark_forest_theory_of_machine_learning/,frustrated_lunatic,1476922338,,12,1
654,2016-10-20,2016,10,20,10,58e2o2,[R] Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data,https://www.reddit.com/r/MachineLearning/comments/58e2o2/r_semisupervised_knowledge_transfer_for_deep/,downtownslim,1476926065,,4,6
655,2016-10-20,2016,10,20,12,58enfu,Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data,https://www.reddit.com/r/MachineLearning/comments/58enfu/semisupervised_knowledge_transfer_for_deep/,machiner_ps,1476932733,,0,1
656,2016-10-20,2016,10,20,13,58ewku,Where to start for making a ML Chatbot?,https://www.reddit.com/r/MachineLearning/comments/58ewku/where_to_start_for_making_a_ml_chatbot/,Nyxtia,1476936120,[removed],0,1
657,2016-10-20,2016,10,20,13,58f19h,How to find shelves on image?,https://www.reddit.com/r/MachineLearning/comments/58f19h/how_to_find_shelves_on_image/,kulsemig,1476938011,[removed],0,1
658,2016-10-20,2016,10,20,14,58f8d5,Machine learning techniques used in Supply Chain?,https://www.reddit.com/r/MachineLearning/comments/58f8d5/machine_learning_techniques_used_in_supply_chain/,[deleted],1476941173,[removed],0,1
659,2016-10-20,2016,10,20,14,58fbwj,[R]Big Batch SGD: Automated Inference using Adaptive Batch Sizes,https://www.reddit.com/r/MachineLearning/comments/58fbwj/rbig_batch_sgd_automated_inference_using_adaptive/,yuanyuanji,1476942897,,6,11
660,2016-10-20,2016,10,20,14,58fc26, |  Fully wrap around labeling machine,https://www.reddit.com/r/MachineLearning/comments/58fc26/___fully_wrap_around_labeling/,neostarpack,1476942972,,0,1
661,2016-10-20,2016,10,20,16,58fm3j,[Research] [1610.05683] Rejection Sampling Variational Inference,https://www.reddit.com/r/MachineLearning/comments/58fm3j/research_161005683_rejection_sampling_variational/,hardmaru,1476948155,,2,15
662,2016-10-20,2016,10,20,16,58fnd1,Market Report for Ironing Systems in United States,https://www.reddit.com/r/MachineLearning/comments/58fnd1/market_report_for_ironing_systems_in_united_states/,markhub123,1476948876,,0,1
663,2016-10-20,2016,10,20,17,58fr3e,Exploring the Limits of Language Modeling - multi-GPU training code in TensorFlow,https://www.reddit.com/r/MachineLearning/comments/58fr3e/exploring_the_limits_of_language_modeling/,rafalj,1476951153,,1,1
664,2016-10-20,2016,10,20,18,58fw57,Learning to Learn Neural Networks,https://www.reddit.com/r/MachineLearning/comments/58fw57/learning_to_learn_neural_networks/,machiner_ps,1476954370,,0,1
665,2016-10-20,2016,10,20,18,58fxfk,How does the planetary action blender operate,https://www.reddit.com/r/MachineLearning/comments/58fxfk/how_does_the_planetary_action_blender_operate/,mixmachinery,1476955182,,1,1
666,2016-10-20,2016,10,20,18,58fzhq,Market Report For Pellet Heating Stove in United States,https://www.reddit.com/r/MachineLearning/comments/58fzhq/market_report_for_pellet_heating_stove_in_united/,markhub123,1476956478,,0,1
667,2016-10-20,2016,10,20,18,58g0r2,Market Report for Pet Doors in United States,https://www.reddit.com/r/MachineLearning/comments/58g0r2/market_report_for_pet_doors_in_united_states/,markhub123,1476957244,,0,1
668,2016-10-20,2016,10,20,19,58g70s,Smoke Alarms Market Report In United States,https://www.reddit.com/r/MachineLearning/comments/58g70s/smoke_alarms_market_report_in_united_states/,markhub123,1476960575,,0,1
669,2016-10-20,2016,10,20,20,58gajw,Market Report For Surveillance Systems in United States,https://www.reddit.com/r/MachineLearning/comments/58gajw/market_report_for_surveillance_systems_in_united/,markhub123,1476962350,,0,1
670,2016-10-20,2016,10,20,20,58gf55,[D] Request for advice: Which of this two courses more helpful to Reinforcement Learning research?,https://www.reddit.com/r/MachineLearning/comments/58gf55/d_request_for_advice_which_of_this_two_courses/,[deleted],1476964552,[deleted],9,0
671,2016-10-20,2016,10,20,21,58gi23,Good reviews for deep learning papers by topics,https://www.reddit.com/r/MachineLearning/comments/58gi23/good_reviews_for_deep_learning_papers_by_topics/,terryum,1476965741,,0,1
672,2016-10-20,2016,10,20,23,58h10t,[Research] Instance Noise: A trick for stabilising GAN training (detailed discussion of technique from arXiv:1610.04490),https://www.reddit.com/r/MachineLearning/comments/58h10t/research_instance_noise_a_trick_for_stabilising/,fhuszar,1476972580,,11,60
673,2016-10-20,2016,10,20,23,58h2vj,[1602.05179] Equilibrium Propagation: Bridging the Gap Between Energy-Based Models and Backpropagation,https://www.reddit.com/r/MachineLearning/comments/58h2vj/160205179_equilibrium_propagation_bridging_the/,[deleted],1476973171,[deleted],0,1
674,2016-10-20,2016,10,20,23,58h4jv,[P] DCGAN + VAE Implementation in Torch,https://www.reddit.com/r/MachineLearning/comments/58h4jv/p_dcgan_vae_implementation_in_torch/,Staturecrane,1476973715,,0,4
675,2016-10-20,2016,10,20,23,58h6i2,"Hello guys! Need a few pro tips about Tensorflow as a deep learning tool for signal processing, specifically vibration analysis. Anyone care to share some ideas, or tips?",https://www.reddit.com/r/MachineLearning/comments/58h6i2/hello_guys_need_a_few_pro_tips_about_tensorflow/,[deleted],1476974308,[removed],0,1
676,2016-10-20,2016,10,20,23,58h7ru,[Research] Comparison of Learning Algorithms for Neural Networks,https://www.reddit.com/r/MachineLearning/comments/58h7ru/research_comparison_of_learning_algorithms_for/,rober9876543210,1476974729,,12,0
677,2016-10-20,2016,10,20,23,58h8t8,"BigData and ML Examples and Libraries Weekly Roundup  Oct. 20, 2016",https://www.reddit.com/r/MachineLearning/comments/58h8t8/bigdata_and_ml_examples_and_libraries_weekly/,stkim1,1476975056,,0,1
678,2016-10-20,2016,10,20,23,58h9wi,Supercomputer learns to defeat Atari Pong from pixels in under 5 minutes,https://www.reddit.com/r/MachineLearning/comments/58h9wi/supercomputer_learns_to_defeat_atari_pong_from/,moconnor,1476975404,,0,1
679,2016-10-21,2016,10,21,0,58heps,How Machine Learning Builds Your Applications For You,https://www.reddit.com/r/MachineLearning/comments/58heps/how_machine_learning_builds_your_applications_for/,excipi,1476976825,,0,1
680,2016-10-21,2016,10,21,0,58hj5z,Could Valve train a positional tracking computer vision system by using a feed from the HTC Vive's front-facing camera couples with the positional data given from the laser tracking system?,https://www.reddit.com/r/MachineLearning/comments/58hj5z/could_valve_train_a_positional_tracking_computer/,godelbrot,1476978141,[removed],0,1
681,2016-10-21,2016,10,21,1,58hux7,How Bijur Delimon Lubrication System Make Your Machines Run Flawlessly?,https://www.reddit.com/r/MachineLearning/comments/58hux7/how_bijur_delimon_lubrication_system_make_your/,jackerfrinandis,1476981653,,0,1
682,2016-10-21,2016,10,21,1,58hwln,[Research] Paper Summary: Fully Character-Level Neural Machine Translation without Explicit Segmentation,https://www.reddit.com/r/MachineLearning/comments/58hwln/research_paper_summary_fully_characterlevel/,keshav57,1476982128,,0,18
683,2016-10-21,2016,10,21,2,58i0ml,[Question] looking for trained personality model,https://www.reddit.com/r/MachineLearning/comments/58i0ml/question_looking_for_trained_personality_model/,djc1000,1476983278,[removed],0,1
684,2016-10-21,2016,10,21,2,58i6se,Suicide of a Clinically Depressed Predictive Text Emulator,https://www.reddit.com/r/MachineLearning/comments/58i6se/suicide_of_a_clinically_depressed_predictive_text/,MiseryTourism,1476985008,,0,1
685,2016-10-21,2016,10,21,3,58igow,[R] First Links in the Markov Chain,https://www.reddit.com/r/MachineLearning/comments/58igow/r_first_links_in_the_markov_chain/,beeftug,1476987811,,0,1
686,2016-10-21,2016,10,21,4,58is0k,[N]Official TensorFlow GPU support for Windows.,https://www.reddit.com/r/MachineLearning/comments/58is0k/nofficial_tensorflow_gpu_support_for_windows/,[deleted],1476991122,[deleted],0,1
687,2016-10-21,2016,10,21,4,58ity2,[N] TensorFlow Build On Windows Now Supports GPU,https://www.reddit.com/r/MachineLearning/comments/58ity2/n_tensorflow_build_on_windows_now_supports_gpu/,[deleted],1476991702,[deleted],5,3
688,2016-10-21,2016,10,21,4,58iv06,[Project] Synthesizing Images from Yahoo's open_nsfw [NSFW],https://www.reddit.com/r/MachineLearning/comments/58iv06/project_synthesizing_images_from_yahoos_open_nsfw/,open_nsfw,1476992029,,50,328
689,2016-10-21,2016,10,21,6,58jcny,A dumb calculator,https://www.reddit.com/r/MachineLearning/comments/58jcny/a_dumb_calculator/,ArmlessJohn404,1476997244,,0,1
690,2016-10-21,2016,10,21,6,58jhts,Switch from caffe to TF for rcnn support?,https://www.reddit.com/r/MachineLearning/comments/58jhts/switch_from_caffe_to_tf_for_rcnn_support/,TuringsEgo,1476998788,[removed],0,1
691,2016-10-21,2016,10,21,6,58jjna,Machine Learning as a Service: Spring Venture Group Case Study,https://www.reddit.com/r/MachineLearning/comments/58jjna/machine_learning_as_a_service_spring_venture/,elisebreda,1476999392,,0,1
692,2016-10-21,2016,10,21,7,58jtat,Storing sequences of bitvectors,https://www.reddit.com/r/MachineLearning/comments/58jtat/storing_sequences_of_bitvectors/,mikos,1477002482,[removed],0,1
693,2016-10-21,2016,10,21,8,58k1hb,Any ideas on applying deep learning to tweets (aside sentiment analysis)?,https://www.reddit.com/r/MachineLearning/comments/58k1hb/any_ideas_on_applying_deep_learning_to_tweets/,ark9gm,1477005160,[removed],0,1
694,2016-10-21,2016,10,21,9,58kdpo,[R] Equilibrium Propagation: Bridging the Gap Between Energy-Based Models and Backpropagation,https://www.reddit.com/r/MachineLearning/comments/58kdpo/r_equilibrium_propagation_bridging_the_gap/,downtownslim,1477009390,,4,30
695,2016-10-21,2016,10,21,10,58krmn,[1610.06258] Using Fast Weights to Attend to the Recent Past,https://www.reddit.com/r/MachineLearning/comments/58krmn/161006258_using_fast_weights_to_attend_to_the/,xternalz,1477014562,,0,3
696,2016-10-21,2016,10,21,13,58lgw7,Describe Deep Learning in as few words as possible.,https://www.reddit.com/r/MachineLearning/comments/58lgw7/describe_deep_learning_in_as_few_words_as_possible/,Iolo-Whales,1477024627,[removed],0,1
697,2016-10-21,2016,10,21,14,58llwo,Data analysis ans statistical inference: A quick guide,https://www.reddit.com/r/MachineLearning/comments/58llwo/data_analysis_ans_statistical_inference_a_quick/,[deleted],1477026920,[deleted],0,1
698,2016-10-21,2016,10,21,17,58m6ha,[GERMAN] Social Bots und Computational Propaganda,https://www.reddit.com/r/MachineLearning/comments/58m6ha/german_social_bots_und_computational_propaganda/,flezzfx,1477038320,,0,1
699,2016-10-21,2016,10,21,17,58m7ck,| Automatic Bag Feeder |Neostarpack,https://www.reddit.com/r/MachineLearning/comments/58m7ck/_automatic_bag_feeder_neostarpack/,neostarpack,1477038890,,0,1
700,2016-10-21,2016,10,21,17,58m9nt,What does the stainless steel jacketed tanks look like?,https://www.reddit.com/r/MachineLearning/comments/58m9nt/what_does_the_stainless_steel_jacketed_tanks_look/,mixmachinery,1477040356,,1,1
701,2016-10-21,2016,10,21,20,58mmac,machine learning vs neural networks?,https://www.reddit.com/r/MachineLearning/comments/58mmac/machine_learning_vs_neural_networks/,Antreas93,1477047651,[removed],0,1
702,2016-10-21,2016,10,21,20,58mshf,[R] Building a neural network for recognition,https://www.reddit.com/r/MachineLearning/comments/58mshf/r_building_a_neural_network_for_recognition/,matt_hammond,1477050687,"Could someone more experienced in this matter help me out.

I have a problem similar to face recognition but instead of faces I have images of dolphin fins. Turns out dolphins have unique fins. Now I want to build a neural network that will map an image of a dolphin fin to an N-dimensional vector representing that dolphin uniquely. I think this is called an embedding (correct me if I'm wrong). 

Google's FaceNet used a similar approach to map faces to a 128-dimensional vector. I'm wondering how would I go about doing this. Could I use a pretrained network (let's say FaceNet) and use transfer learning to recognize dolphin fins? If not, how big of a dataset would I need to make my own embedding for recognizing dolphins?

Please understand I don't have a lot of experience with neural networks. I just want to learn.",16,23
703,2016-10-21,2016,10,21,21,58mtl0,[P] Let's make a DQN: Full DQN - covering target network and error clipping,https://www.reddit.com/r/MachineLearning/comments/58mtl0/p_lets_make_a_dqn_full_dqn_covering_target/,jaromiru,1477051244,,0,12
704,2016-10-21,2016,10,21,22,58n3wm,Are these concepts in use in neural net models today?,https://www.reddit.com/r/MachineLearning/comments/58n3wm/are_these_concepts_in_use_in_neural_net_models/,thelibar,1477055366,"Hi,       
I have been playing around with neural nets, trying to create one that requires little data and would be able to create logic just from reading random articles on Wikipedia/comment sections. In my research on the brain I seem to have come upon some attributes of the braing that seem fundamental to how we learn.
    
Let me also state that I'm not a classical student of ML so my awareness of the different methods out there is limited. **So my question to you is: How many of these attributes have been implemented in some type of neural net model already?**
       
As you will notice many of the ideas are inspired by processes in the human brain. The reason I think this is a good approach is that most of the information we would like a computer to understand is already encoded for humans, so a model close to the human brain should be effective for making sense out of that information. 
       
**1. Flow within same layer**
What I mean by flow is transfer of ""charge"" from one neuron withing a layer, to another within the same layer (same level of abstraction).
      
As far as I've seen most neural nets only transfer charge between layers, (through pathways with different weights), never between neurons within the same layer.
     
The reason why I believe this would be beneficial is that by doing that you would come closer to how our brains work (thus need less data for the creation of usable abstracts). For example it is easier to play a song on the guitar from the start, than from the middle. This could be explained by a wave of ""charge"" building up as the charge flows through same level abstractions (chords). In a similar way we often can answer a question more easily if we first replay it in our head (building up a wave of charge) or even repeat the question again out loud. In both cases this accumulating charge flowing from neuron to neuron will increase the likelyhood of a highly connected neuron to trigger. **Example:**
      
""My name is..."" make my brain fill in the dot with ""thelibar"" almost instantaneously. If one would to say ""name is"" or just ""is"" the brain is less likely to give ""thelibar"" as a response since there has been no build up of flow.
      
**2. Separate abstractions of data by time pauses.**
When we read, every blankspace, dot and comma is a slight pause in our internal reading of the sentence. My hunch is that we structure information this way because it lets the neurons in the brain ""cool down"". By allowing a minimal pause between each word we assure that letters that are highly related (constitute one word) bind to each other more strongly than letters between different words. For this process to function neurons that have higher charge (were triggered more recently) will also bind more strongly to the currently triggered neuron.
     
My guess is that this is why humans are really bad at reading sentences without blankspaces, or in general process information when it is presented without any intervals to divide the information into discrete chunks (abstracts). 
       
Of course it would not be time that was passing once this concept is translated to a artificial neural net, but rather it would be a decrease in the charge of a neuron that represents time having passed.
    

    
Please let me know if what I mean is unclear and I will try to explain better.",8,4
705,2016-10-21,2016,10,21,22,58n7k5,How does SMO's convergence guaranteed,https://www.reddit.com/r/MachineLearning/comments/58n7k5/how_does_smos_convergence_guaranteed/,shaode01,1477056627,[removed],1,1
706,2016-10-21,2016,10,21,22,58n9hl,[1610.06454v1] Reasoning with Memory Augmented Neural Networks for Language Comprehension,https://www.reddit.com/r/MachineLearning/comments/58n9hl/161006454v1_reasoning_with_memory_augmented/,tsendsuren,1477057294,,4,15
707,2016-10-21,2016,10,21,23,58nfog,Real-time big data application architecture,https://www.reddit.com/r/MachineLearning/comments/58nfog/realtime_big_data_application_architecture/,knuthmoris,1477059433,[removed],0,1
708,2016-10-22,2016,10,22,0,58nyx8,Machine learning IRC,https://www.reddit.com/r/MachineLearning/comments/58nyx8/machine_learning_irc/,Weriak,1477065514,[removed],0,1
709,2016-10-22,2016,10,22,1,58o31a,[R] [1609.02228] Learning to learn with backpropagation of Hebbian plasticity,https://www.reddit.com/r/MachineLearning/comments/58o31a/r_160902228_learning_to_learn_with/,[deleted],1477066715,[deleted],0,1
710,2016-10-22,2016,10,22,2,58od34,"When do you use SGD, adadelta, RMS prop, etc?",https://www.reddit.com/r/MachineLearning/comments/58od34/when_do_you_use_sgd_adadelta_rms_prop_etc/,isaacgerg,1477069868,[removed],0,1
711,2016-10-22,2016,10,22,2,58ol9t,Why are there no general machine learning algorithms?,https://www.reddit.com/r/MachineLearning/comments/58ol9t/why_are_there_no_general_machine_learning/,_Nexor,1477072368,[removed],0,1
712,2016-10-22,2016,10,22,3,58orh9,"Heavy equipment accidents , trucks accidents - big truck accidents #1",https://www.reddit.com/r/MachineLearning/comments/58orh9/heavy_equipment_accidents_trucks_accidents_big/,ems204,1477074270,,0,1
713,2016-10-22,2016,10,22,6,58ppx1,Saliency or heat maps for tensorflow?,https://www.reddit.com/r/MachineLearning/comments/58ppx1/saliency_or_heat_maps_for_tensorflow/,Fathomx1,1477084897,[removed],0,1
714,2016-10-22,2016,10,22,6,58pril,[Discussion] Best machine learning tool on AWS EMR?,https://www.reddit.com/r/MachineLearning/comments/58pril/discussion_best_machine_learning_tool_on_aws_emr/,DJedamski,1477085416,[removed],0,1
715,2016-10-22,2016,10,22,8,58qgl8,"21"" - 30"" x 60"" Used Tarnow Gap Bed Engine Lathe, Mdl. TUJ-50x1500 A2779",https://www.reddit.com/r/MachineLearning/comments/58qgl8/21_30_x_60_used_tarnow_gap_bed_engine_lathe_mdl/,SterlingMachineryEx,1477093997,,0,1
716,2016-10-22,2016,10,22,8,58qh5u,Is electric sheep considered to be Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/58qh5u/is_electric_sheep_considered_to_be_machine/,blakdart,1477094205,,0,1
717,2016-10-22,2016,10,22,9,58qjiw,[Research][1610.06258] Using Fast Weights to Attend to the Recent Past,https://www.reddit.com/r/MachineLearning/comments/58qjiw/research161006258_using_fast_weights_to_attend_to/,zhongwenxu,1477095092,,18,41
718,2016-10-22,2016,10,22,9,58qosf,Theano cuDNN RNN Benchmarks,https://www.reddit.com/r/MachineLearning/comments/58qosf/theano_cudnn_rnn_benchmarks/,stargazzer1337,1477097053,,0,1
719,2016-10-22,2016,10,22,10,58qxq0,Build a Recommendation System - Learn Python for Data Science,https://www.reddit.com/r/MachineLearning/comments/58qxq0/build_a_recommendation_system_learn_python_for/,llSourcell,1477100661,,0,1
720,2016-10-22,2016,10,22,11,58r0fr,"Theoretically, why do we need beta1 in ADAM optimizer?",https://www.reddit.com/r/MachineLearning/comments/58r0fr/theoretically_why_do_we_need_beta1_in_adam/,[deleted],1477101820,[removed],0,1
721,2016-10-22,2016,10,22,11,58r1wm,"[D] Theoretically, why do we need beta1 in ADAM optimizer?",https://www.reddit.com/r/MachineLearning/comments/58r1wm/d_theoretically_why_do_we_need_beta1_in_adam/,ijenab,1477102425,"Hey reddit! I was reading the proof of ADAM (link to paper: https://arxiv.org/pdf/1412.6980v8.pdf). Regret seems to shrink as beta1 gets smaller and gets closer to 0. So, in the proof we can just put beta1 to zero and everything still works fine, right? Am I missing something? Thanks :)   
",8,9
722,2016-10-22,2016,10,22,12,58rcko,Machine Learning for Recyclable Material Classification,https://www.reddit.com/r/MachineLearning/comments/58rcko/machine_learning_for_recyclable_material/,DJTeebS,1477107036,[removed],0,1
723,2016-10-22,2016,10,22,14,58rttb,Energy Dataset: Artificial Load Profile Generator for Demand Side Management,https://www.reddit.com/r/MachineLearning/comments/58rttb/energy_dataset_artificial_load_profile_generator/,siddkotwal,1477115484,,0,1
724,2016-10-22,2016,10,22,15,58s02z,[Research] Machine Learning for Recyclable Material Classification,https://www.reddit.com/r/MachineLearning/comments/58s02z/research_machine_learning_for_recyclable_material/,DJTeebS,1477119025,"Hi /r/Machinelearning!


This is my first post on this subreddit. I am interested in what the reddit community thinks of my thesis topic which utilizes machine learning to solve a classification problem. I am investigating the development of a software system for a self-sorting smart bin that can identify and sort plastics, metals, glass, and landfill.


One of the biggest problems to crack is the identification and classification of items input into the bin. I intend to have an identification chamber fitted with a array of instruments and sensors which would provide valuable data streams characterizing the material of the input item:

* Camera -&gt; image processing

* Microphone -&gt; acoustic data

* Spectrographs -&gt; spectroscopic data

* Metal detector -&gt; electromagnetic data


I have yet to select a machine learning algorithm to solve this classification problem but 'adaptive interactive modelling systems' looks very promising. Otherwise I would assume that artificial neural nets would be the way to go.


I am seeking any critical feedback or advice that will be of help to my project!


Many thanks,

TeebS",12,33
725,2016-10-22,2016,10,22,16,58s4p5,China Intelligent Print Management Market Research Report,https://www.reddit.com/r/MachineLearning/comments/58s4p5/china_intelligent_print_management_market/,markhub123,1477121852,,0,1
726,2016-10-22,2016,10,22,16,58s5g1,"[Discussion] If I have BS in Mathematics with majors in CS and Pure Mathematics, do you think it's worth it to pursue MS or PhD in ML if I want to do research in ML?",https://www.reddit.com/r/MachineLearning/comments/58s5g1/discussion_if_i_have_bs_in_mathematics_with/,deepmind2016,1477122354,[removed],0,1
727,2016-10-22,2016,10,22,17,58sb5d,quick full stack project [limited time]: Data Science / Machine Learning,https://www.reddit.com/r/MachineLearning/comments/58sb5d/quick_full_stack_project_limited_time_data/,dkr103,1477126233,[removed],0,1
728,2016-10-22,2016,10,22,17,58sbyf,What is wrong with this simple keras model?,https://www.reddit.com/r/MachineLearning/comments/58sbyf/what_is_wrong_with_this_simple_keras_model/,[deleted],1477126789,[removed],0,1
729,2016-10-22,2016,10,22,18,58she7,Small bottle water filling line | bottled water manufacturing process | bottled water plant,https://www.reddit.com/r/MachineLearning/comments/58she7/small_bottle_water_filling_line_bottled_water/,stevenwangfilling,1477130377,,0,1
730,2016-10-22,2016,10,22,19,58smrh,Deep learning papers reading roadmap,https://www.reddit.com/r/MachineLearning/comments/58smrh/deep_learning_papers_reading_roadmap/,keptavista,1477133784,,1,2
731,2016-10-22,2016,10,22,20,58ssqe,[P] Chainer implementation of Neural Tree Indexers on Stanford Language Inference task,https://www.reddit.com/r/MachineLearning/comments/58ssqe/p_chainer_implementation_of_neural_tree_indexers/,tsendsuren,1477137257,,0,12
732,2016-10-22,2016,10,22,23,58tdcm,Disease Datasets,https://www.reddit.com/r/MachineLearning/comments/58tdcm/disease_datasets/,dauntless26,1477146824,[removed],0,1
733,2016-10-23,2016,10,23,3,58uiyd,[DISCUSSION] No matter what I remove I get the same results,https://www.reddit.com/r/MachineLearning/comments/58uiyd/discussion_no_matter_what_i_remove_i_get_the_same/,dauntless26,1477161726,"I am using the blood transfusion dataset from UCI: https://archive.ics.uci.edu/ml/datasets/Blood+Transfusion+Service+Center

No matter what features I remove (or even just leaving in one random feature) I get about the same results: 77% accuracy. Why is this happening?",10,0
734,2016-10-23,2016,10,23,4,58unrw,"[D] If I have BS in Mathematics with majors in CS and Pure Mathematics, do you think it's worth it to pursue MS or PhD in ML if I want to do research in ML?",https://www.reddit.com/r/MachineLearning/comments/58unrw/d_if_i_have_bs_in_mathematics_with_majors_in_cs/,[deleted],1477163352,[removed],0,1
735,2016-10-23,2016,10,23,4,58upn8,[Project] Failure prediction for lifetime data,https://www.reddit.com/r/MachineLearning/comments/58upn8/project_failure_prediction_for_lifetime_data/,fmcm,1477163971,"Hi there!

First time here, please be gentle.

I'm currently working on a project - ""Using machine learning in safety and reliability"".

**Some background:**

If you have a piece of equipment it and operate it, it will eventually fail. So you note down the failure time (operating hours) and replace it.After some time (especially if you have the identical equipment several times) you collect a collection of failure times.

The usual approach is to use Minitab or R or whatever software you fancy and fit a model to the data (Exponential, Weibull, Gamma, etc.). So ideally you find a model which fits rather nice and then for the future you can describe the behaviour of your equipment with just one or two parameters.

This is often displayed in form of a Cumulative Failure Probability plot. See for example here:

http://support.minitab.com/en-us/minitab/17/cum_failure_plot_def.png

At time 0 you have a 0% chance of being failed. It increases in a certain shape and will ultimately reach 100%.


**Task:**

Reality is different. Equipment does not follow a model perfectly. But thanks to the modern world of Machine Learning, that approach might not be necessary.

My current task is:

* Have a bunch of failure dates (randomly generated and by some real life data)
* Feed that into a machine learning algorithm without implying any failure distribution model
* Get a model which will predict the percentage of being failed at a given time.


**Where I am now:**

So far I have used python and scikit-learn to built my very first python program ever (learning python AND machine learning at the same time here!).

I randomly draw failure dates which perfectly follow a Weibull distribution so far. Later I want to implement some randomness and noise, but for the start, I want to keep to ""pure"" values so I know what to expect.

I feed it my failure times and it creates a failure distribution curve. The more samples I use, the better it fits (obviously).

See following pictures:
Weibull with Alpha = 1.2 and Lambda = 0.0002
Blue line = The Weibull curve
Red Dots = The random data points
Red Line = The fitting line of my machine learning algorithm

First picture with 200 samples, second one with 20 samples.

See http://imgur.com/a/Ln34X for illustration of where I am now.

Till now I'm fairly happy. I actually managed to write two programs: One to generate a CSV with random Weibull values and one with the actual machine learning routine included. I used the RandomForestRegressor model provided by scikit-learn.

**Future tasks:**

* Implement proper data preprocessing (normalize)
* Compare to traditional parametric model fitting
* Include some covariates (""My device is running at temperature X and at load level Y, what are the chances of it being failed at time Z?"")

**My Questions:**

Do you have any general advices on such a ""simple"" machine learning task? Is my approach so far reasonable or am I missing something obvious?

In reality you don't have hundreds of data points, just in the range 10-60. Are there any advices with handling ""Little Data""?

The cumulative failure probability curve is per definition always rising. The probability to be failed at time X+1 is always higher than at X. How can I tell that to my machine learning routine?

I am grateful for every input you can give as I am eager to learn more - both in python/numpy/scipy/scikit-learn and machine learning theory in general.",15,11
736,2016-10-23,2016,10,23,4,58usko,"[D] If I have BS in Mathematics with majors in CS and Pure Mathematics, do you think it's worth it to pursue MS or PhD in ML if I want to do research in ML?",https://www.reddit.com/r/MachineLearning/comments/58usko/d_if_i_have_bs_in_mathematics_with_majors_in_cs/,Indy20161,1477164975,,9,2
737,2016-10-23,2016,10,23,6,58v7ze,[P] Using Machine Learning to Detect Malicious URLs,https://www.reddit.com/r/MachineLearning/comments/58v7ze/p_using_machine_learning_to_detect_malicious_urls/,Faizann24,1477170350,,14,29
738,2016-10-23,2016,10,23,6,58v9q7,[Project] iGAN: Interactive Image Generation via Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/58v9q7/project_igan_interactive_image_generation_via/,[deleted],1477170979,[deleted],0,1
739,2016-10-23,2016,10,23,7,58vhnn,[Research] Two Minute Papers - Image Editing with Generative Adversarial Networks,https://www.reddit.com/r/MachineLearning/comments/58vhnn/research_two_minute_papers_image_editing_with/,JacobResch,1477173806,,3,84
740,2016-10-23,2016,10,23,8,58vtu2,[Discussion] Question about Seq2Seq for sets,https://www.reddit.com/r/MachineLearning/comments/58vtu2/discussion_question_about_seq2seq_for_sets/,sprintletecity,1477178349,"There is a part in the paper (https://arxiv.org/pdf/1511.06391v4.pdf) that discusses the process block - how does it make sense to concatenate the read-out to the query vector q_t? Shouldn't this be an add operation, since concatenation will change the dimension of q_t? I just don't understand how this can be evolved using the lstm.",3,6
741,2016-10-23,2016,10,23,12,58wvaw,"Stupid Question: I have some qualitative process that I would like to develop a NN for. How ""much"" data do I need for my algorithm to be useful?",https://www.reddit.com/r/MachineLearning/comments/58wvaw/stupid_question_i_have_some_qualitative_process/,mistermister99,1477193976,[removed],0,1
742,2016-10-23,2016,10,23,14,58x6z5,Implicit Matrix Factorization: Classic ALS with Sketchfab Models,https://www.reddit.com/r/MachineLearning/comments/58x6z5/implicit_matrix_factorization_classic_als_with/,benfred,1477199503,,0,1
743,2016-10-23,2016,10,23,14,58x83a,Data Compression + Denoising using Machine learning,https://www.reddit.com/r/MachineLearning/comments/58x83a/data_compression_denoising_using_machine_learning/,hiteshv09,1477200055,[removed],0,1
744,2016-10-23,2016,10,23,14,58xb4m,Sharing a new thermal-video dataset of elders at their bedrooms,https://www.reddit.com/r/MachineLearning/comments/58xb4m/sharing_a_new_thermalvideo_dataset_of_elders_at/,fpolacov,1477201616,[removed],0,1
745,2016-10-23,2016,10,23,14,58xcim,new machine learning approach for image segmentation that uses a neural network to model the conditional energy of a segmentation given an image. Is this the fastest one we have?,https://www.reddit.com/r/MachineLearning/comments/58xcim/new_machine_learning_approach_for_image/,seesawtron,1477202351,,0,1
746,2016-10-23,2016,10,23,16,58xjq2,[Discussion] I am following Andrew Ng's Coursera course. Is there an entry course to better follow it?,https://www.reddit.com/r/MachineLearning/comments/58xjq2/discussion_i_am_following_andrew_ngs_coursera/,missutt,1477206601,"Hi,

Is there another course that helps me to get better at Andrew Ng's Coursera one please?

Thanks",8,0
747,2016-10-23,2016,10,23,16,58xmnt,[R] Visual Explanations from Deep Networks via Gradient-based Localization,https://www.reddit.com/r/MachineLearning/comments/58xmnt/r_visual_explanations_from_deep_networks_via/,undefdev,1477208640,,2,16
748,2016-10-23,2016,10,23,17,58xo6a,[question] Help with Keras and multidimensional outputs,https://www.reddit.com/r/MachineLearning/comments/58xo6a/question_help_with_keras_and_multidimensional/,Vulpius,1477209690,[removed],0,1
749,2016-10-23,2016,10,23,17,58xrw2,"[P] Python binding for Microsoft LightGBM ( fast, distributed, high performance gradient boosting framework based on decision tree algorithms)",https://www.reddit.com/r/MachineLearning/comments/58xrw2/p_python_binding_for_microsoft_lightgbm_fast/,ebazarov,1477212354,,5,63
750,2016-10-23,2016,10,23,18,58xw4s,What is advantage of MCGSM (Mixture of Conditional Gaussian Scale Mixture) over GMM?,https://www.reddit.com/r/MachineLearning/comments/58xw4s/what_is_advantage_of_mcgsm_mixture_of_conditional/,gmkim90,1477215427,[removed],0,1
751,2016-10-23,2016,10,23,20,58y503,What to look for in a GPU?,https://www.reddit.com/r/MachineLearning/comments/58y503/what_to_look_for_in_a_gpu/,[deleted],1477221339,[removed],0,1
752,2016-10-24,2016,10,24,0,58z4n8,Is an i7 significantly better for machine learning purposes? I tried comparing between an i3 and an i5,https://www.reddit.com/r/MachineLearning/comments/58z4n8/is_an_i7_significantly_better_for_machine/,silverpendulum,1477237721,[removed],0,1
753,2016-10-24,2016,10,24,1,58zckv,[Project] Bayesian Wi-Fi,https://www.reddit.com/r/MachineLearning/comments/58zckv/project_bayesian_wifi/,bjornsing,1477240436,,15,185
754,2016-10-24,2016,10,24,2,58zjyy,Help with notation in Murphy's Machine Learning Textbook,https://www.reddit.com/r/MachineLearning/comments/58zjyy/help_with_notation_in_murphys_machine_learning/,[deleted],1477242848,[removed],0,1
755,2016-10-24,2016,10,24,3,58zux2,"How hard is it to build an article generator?(e.g. feed it with 1000 articles, return 1 random article)",https://www.reddit.com/r/MachineLearning/comments/58zux2/how_hard_is_it_to_build_an_article_generatoreg/,zgintasz,1477246434,[removed],0,1
756,2016-10-24,2016,10,24,3,590263,Less-than-5-minute description of discriminative recurrent neural networks (including bidirectional). Context: activity recognition.,https://www.reddit.com/r/MachineLearning/comments/590263/lessthan5minute_description_of_discriminative/,[deleted],1477248772,[deleted],0,1
757,2016-10-24,2016,10,24,5,590h3z,[d] Which MOOC to make,https://www.reddit.com/r/MachineLearning/comments/590h3z/d_which_mooc_to_make/,bihaqo,1477253466,"Hi!

Im a PhD student in machine learning. I'm going to make a Coursera course with my colleagues, that will be a part of ML- and statistics-based specialization. Our MOOC will last **4-5 weeks**. We are currently discussing the main topic of the course.

Ours and our research group's main expertise is in Bayesian methods (we are bayesgroup.ru after all), convolutional neural networks, and RNNs.
We have several ideas and need to pick one:

* Recurrent Neural Networks. RNNs is a part of many deep learning courses, but lots of people have never coded/ran an LSTM. Our course will cover main aspects, tips and tricks of RNNs and will offer some hands-on tutorials on them along with a chance to solve real-world problems. 
* How to read deep learning papers. More and more folks are entering deep learning these days, but reading state-of-the-art papers still scares lots of people away. We plan to focus the course on reading assignments. The student will be asked to read and analyze papers, and maybe write a short essay. After that, we will analyze the very same papers in the lectures and share some tips on what to look at. We will discuss stuff like why did they do this thing instead of this one?, discuss the connections to other papers and reasonable things to try next. We will also look into the official reviews for these papers (for NIPS and ICLR papers, where the reviews are available). It would be tough to make such course work, though...
* Bayesian methods for machine learning. The general form of the EM-algorithm, MCMC methods, variational inference and maybe variational autoencoders, matrix calculus (like differentiating a function w.r.t. a matrix). Coding homeworks (like [using EM algorithm to recover a villain photo from many noisy observations](http://cmp.felk.cvut.cz/cmp/courses/recognition/Labs/em/index_en.html)).
* Practical neural networks. Different topic each week (CNNs, RNNs, NLP, etc.), and a Kaggle competition as a coding homework. In lectures, there would be practical tips like try this kind of augmentation. To see what I mean, look at this brilliant blog post: [Using convolutional neural nets to detect facial keypoints tutorial](http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/). It focuses on a particular Kaggle competition and goes step by step from a simplest neural network to a top notch one. Each step is motivated like we increased the model capacity and it indeed overfitted. Let's add dropout -- see, it helps.

What topic do you guys think would be most beneficial for the community? Do you have any suggestions or additional ideas?

**UPD**

Thanks everyone for the feedback, I think we will stick with the ""Practical Bayesian methods"" as most of you suggested. The rough plan is to have 3 lectures about the basic techniques (like EM and MCMC) and after each lecture show how do they apply to VAE. So after the first lecture, we will introduce VAE idea, but will not tell anything about the training, and will build up from that. The last two lectures will be dedicated to neural-Bayesian models other than VAE.

BTW, if you liked any of the course ideas I mentioned above, go ahead and still it to make your own course! ",21,31
758,2016-10-24,2016,10,24,5,590l28,Binary numbers instead of one hot vectors,https://www.reddit.com/r/MachineLearning/comments/590l28/binary_numbers_instead_of_one_hot_vectors/,RaghuramVadapalli,1477254737,[removed],0,1
759,2016-10-24,2016,10,24,5,590pbz,Semantic-analysis software wanted!,https://www.reddit.com/r/MachineLearning/comments/590pbz/semanticanalysis_software_wanted/,Giordasshole,1477256110,[removed],0,1
760,2016-10-24,2016,10,24,6,590s3p,[R] Is STDP just continuous Contrasitve Divergence with a fine temporal resolution ?,https://www.reddit.com/r/MachineLearning/comments/590s3p/r_is_stdp_just_continuous_contrasitve_divergence/,[deleted],1477257014,[deleted],0,1
761,2016-10-24,2016,10,24,6,5910jo,[discussion] [x-post from /r/askacademia ] choosing which of these 6 math classes to take next semester.,https://www.reddit.com/r/MachineLearning/comments/5910jo/discussion_xpost_from_raskacademia_choosing_which/,DarkTriadBAMN,1477259862,"Hey there

I'm trying to decide my schedule for the next semester and my main goal is to develop a toolset for self studying machine learning techniques over the summer. 


I've already checked that these 6 classes fit into one, non-overlapping schedule and that I have all pre-reqs. I would prefer to take 4 of the 6 classes but 5 might be possible (without being too overwhelmed).

here are my options:

----------------------------

Applied Differential Equations II
-----
Description of class:

Wave, heat and Laplace equations. Solutions by separation of variables and expansion in Fourier Series or other appropriate orthogonal sets. Sturm-Liouville problems. Introduction to methods for solving some classical partial differential equations.Use of power series as a tool in solving ordinary differential equations.

------------------


Mathematics of Scientific Computing
-----
Description of class:

This course will provide an overview of methods to solve quantitative problems and analyze data. The tools to be introduced are mathematical in nature and have links to Algebra, Analysis, Geometry, Graph Theory, Probability and Topology. Students will acquire an appreciation of (I) the fundamental role played by mathematics in countless applications and (II) the exciting challenges in mathematical research that lie ahead in the analysis of large data and uncertainties. Students will work on a project for each unit. While this is not a programming class, the students will do some programming through their projects. 

------------------------

Introduction to Modern Algebra for Mathematics Majors	
-----
Description of class:

Elementary number theory, equivalence relations, groups, homomorphisms, cosets, Cayley's Theorem, symmetric groups, rings, polynomial rings, quotient fields, principal ideal domains, Euclidean domains. 

------------

Introduction to Combinatorics
-----
Description of class:

Basic principles of counting: addition and multiplication principles, generating functions, recursive methods, inclusion-exclusion, pigeonhole principle; basic concepts of graph theory: graphs, digraphs, connectedness, trees; additional topics from:Polya theory of counting, Ramsey theory; combinatorial optimization - matching and covering, minimum spanning trees, minimum distance, maximum flow; sieves; mobius inversion; partitions; Gaussian numbers and q-analogues; bijections and involutions; partially ordered sets. 

------------------------

Mathematical Analysis I	
-----
Description of class:

Real number system, functions and limits, topology on the real line, continuity, differential and integral calculus for functions of one variable. Infinite series, uniform convergence. 

-----------------


Introduction to Mathematical Statistics II	
-----
Description of class:

Second of a two-semester sequence of mathematical statistics, primarily for undergraduate majors and graduate minors in Statistics. Random samples, point and interval estimators and their properties, methods of moments, maximum likelihood, tests ofhypotheses, elements of nonparametric statistics and elements of general linear model theory. 

------------------------


Thanks for any feedback or advice :)!",9,0
762,2016-10-24,2016,10,24,7,5914h2,[R] Is STDP continuous Contrasitve Divergence with a fine temporal resolution?,https://www.reddit.com/r/MachineLearning/comments/5914h2/r_is_stdp_continuous_contrasitve_divergence_with/,funj0k3r,1477261178,,1,6
763,2016-10-24,2016,10,24,8,591bff,Hugo Larochelle's notes on Hinton's recent Fast Weight's paper,https://www.reddit.com/r/MachineLearning/comments/591bff/hugo_larochelles_notes_on_hintons_recent_fast/,[deleted],1477263647,[deleted],0,1
764,2016-10-24,2016,10,24,8,591bra,[Research] Hugo Larochelle's notes on Hinton's Fast Weights paper,https://www.reddit.com/r/MachineLearning/comments/591bra/research_hugo_larochelles_notes_on_hintons_fast/,open_nsfw,1477263758,,2,52
765,2016-10-24,2016,10,24,8,591i6v,[P] Less-than-5-minute description of discriminative recurrent neural networks (incl. bidirectional). Context is activity recognition.,https://www.reddit.com/r/MachineLearning/comments/591i6v/p_lessthan5minute_description_of_discriminative/,[deleted],1477266086,[deleted],0,0
766,2016-10-24,2016,10,24,8,591k0u,What recent graduates are saying about Startup.ML fellowship program,https://www.reddit.com/r/MachineLearning/comments/591k0u/what_recent_graduates_are_saying_about_startupml/,arshakn,1477266772,,0,1
767,2016-10-24,2016,10,24,10,591vib,How Gaussian nave Bayes forms non-linear decision boundary?,https://www.reddit.com/r/MachineLearning/comments/591vib/how_gaussian_nave_bayes_forms_nonlinear_decision/,quoraboy,1477270919,[removed],0,1
768,2016-10-24,2016,10,24,10,591xg9,[Discussion] How Gaussian nave Bayes forms a non-linear decision boundary?,https://www.reddit.com/r/MachineLearning/comments/591xg9/discussion_how_gaussian_nave_bayes_forms_a/,quoraboy,1477271655,"Also, please explain decision boundary for decision trees.",2,2
769,2016-10-24,2016,10,24,12,592iio,Should I expect a BaggingClassifier to produce a bell curve distribution of results when n_estimators is large enough?,https://www.reddit.com/r/MachineLearning/comments/592iio/should_i_expect_a_baggingclassifier_to_produce_a/,AspiringGuru,1477279976,,1,1
770,2016-10-24,2016,10,24,15,5933sz,"Simplified implementation of ""Convolutional Neural Networks for Sentence Classification"" paper",https://www.reddit.com/r/MachineLearning/comments/5933sz/simplified_implementation_of_convolutional_neural/,shagunsodhani,1477289942,,0,1
771,2016-10-24,2016,10,24,17,593gdm,Help for my soccer ML problem,https://www.reddit.com/r/MachineLearning/comments/593gdm/help_for_my_soccer_ml_problem/,krekelmans,1477297420,[removed],0,1
772,2016-10-24,2016,10,24,17,593iio,Neural networks quantization for speeding up the inference?,https://www.reddit.com/r/MachineLearning/comments/593iio/neural_networks_quantization_for_speeding_up_the/,kometa_triatlon,1477298733,[removed],0,1
773,2016-10-24,2016,10,24,18,593l33,Could we design the suitable pastry dough mixer?,https://www.reddit.com/r/MachineLearning/comments/593l33/could_we_design_the_suitable_pastry_dough_mixer/,mixmachinery,1477300316,,1,1
774,2016-10-24,2016,10,24,18,593p9m,"GENESIM: GENetic Extraction of a Single, Interpretable Model",https://www.reddit.com/r/MachineLearning/comments/593p9m/genesim_genetic_extraction_of_a_single/,[deleted],1477302796,[deleted],0,6
775,2016-10-24,2016,10,24,19,593v0m,"[R] GENESIM: GENetic Extraction of a Single, Interpretable Model",https://www.reddit.com/r/MachineLearning/comments/593v0m/r_genesim_genetic_extraction_of_a_single/,givdwiel,1477306005,,23,35
776,2016-10-24,2016,10,24,20,593xm5,Finding the car make and model using Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/593xm5/finding_the_car_make_and_model_using/,kollisarath,1477307310,[removed],0,1
777,2016-10-24,2016,10,24,20,5943f1,Should I attend the whole NIPS conference?,https://www.reddit.com/r/MachineLearning/comments/5943f1/should_i_attend_the_whole_nips_conference/,alek9,1477310039,[removed],0,1
778,2016-10-24,2016,10,24,21,59450j,Hub for learned models ?,https://www.reddit.com/r/MachineLearning/comments/59450j/hub_for_learned_models/,antonomase,1477310756,[removed],0,1
779,2016-10-24,2016,10,24,22,594hkc,AI in Finance Moves Beyond Algorithmic Trading,https://www.reddit.com/r/MachineLearning/comments/594hkc/ai_in_finance_moves_beyond_algorithmic_trading/,reworksophie,1477315595,,0,1
780,2016-10-24,2016,10,24,22,594j00,[R] Emotional Artificial Intelligence,https://www.reddit.com/r/MachineLearning/comments/594j00/r_emotional_artificial_intelligence/,primaryobjects,1477316123,,1,6
781,2016-10-24,2016,10,24,22,594l1c,What's behind nvidia's TensorRT?,https://www.reddit.com/r/MachineLearning/comments/594l1c/whats_behind_nvidias_tensorrt/,cysin,1477316858,[removed],0,1
782,2016-10-24,2016,10,24,22,594m4a,[R] Contrast Pattern Aided Regression &amp; Classification,https://www.reddit.com/r/MachineLearning/comments/594m4a/r_contrast_pattern_aided_regression_classification/,Zelazny7,1477317252,,7,1
783,2016-10-24,2016,10,24,23,594smp,Unsupervised Learning in Scala Using word2vec - DZone Big Data,https://www.reddit.com/r/MachineLearning/comments/594smp/unsupervised_learning_in_scala_using_word2vec/,vonnik,1477319434,,0,1
784,2016-10-25,2016,10,25,1,595l6z,Tenure track position in Deep Learning at the University of Wyoming,https://www.reddit.com/r/MachineLearning/comments/595l6z/tenure_track_position_in_deep_learning_at_the/,jclune,1477327863,[removed],0,1
785,2016-10-25,2016,10,25,2,595r5x,"[R] Paper Summary: Human-Level Control Through Deep Reinforcement Learning (DeepMind, Nature)",https://www.reddit.com/r/MachineLearning/comments/595r5x/r_paper_summary_humanlevel_control_through_deep/,keshav57,1477329537,,4,8
786,2016-10-25,2016,10,25,2,595vzi,ML in biomedical images: Brain Anatomy Segmentation,https://www.reddit.com/r/MachineLearning/comments/595vzi/ml_in_biomedical_images_brain_anatomy_segmentation/,saucysassy,1477330886,,0,1
787,2016-10-25,2016,10,25,3,5960bp,[Project] Visualizations for regressing wheel steering angles in self driving cars with Keras,https://www.reddit.com/r/MachineLearning/comments/5960bp/project_visualizations_for_regressing_wheel/,jacobgil,1477332091,,2,5
788,2016-10-25,2016,10,25,4,596hjj,Rust language bindings for TensorFlow,https://www.reddit.com/r/MachineLearning/comments/596hjj/rust_language_bindings_for_tensorflow/,[deleted],1477336978,[deleted],0,1
789,2016-10-25,2016,10,25,4,596hw4,[Project] Rust language bindings for TensorFlow,https://www.reddit.com/r/MachineLearning/comments/596hw4/project_rust_language_bindings_for_tensorflow/,adamnemecek,1477337076,,5,13
790,2016-10-25,2016,10,25,4,596ig5,Object Detection on SpaceNet (deep learning on satellite imagery),https://www.reddit.com/r/MachineLearning/comments/596ig5/object_detection_on_spacenet_deep_learning_on/,Hagerty,1477337242,,1,1
791,2016-10-25,2016,10,25,5,596r8r,What is the most optimal Kaggle team structure. How would you assign each team member complementary responsibilities?,https://www.reddit.com/r/MachineLearning/comments/596r8r/what_is_the_most_optimal_kaggle_team_structure/,Mathriddle,1477339754,[removed],0,1
792,2016-10-25,2016,10,25,5,596r95,[D] Public Handwritten Unicode Image Datasets,https://www.reddit.com/r/MachineLearning/comments/596r95/d_public_handwritten_unicode_image_datasets/,lukemtesta,1477339757,"I need help finding a dataset with handwritten unicode characters. Some exist covering latin numerals and the English alphabet but none include characters for punctuation and mathematical operators. 

ImageNet and VOC doesn't cover these. The MNIST covers digits 0-9, likewise Char74K has numeral and lower/upper case letters for the Latin and Hindu-Arabic systems. 
More suited datasets like HWRT and Detexify are private. I've also considered curating a dataset with Flickr but could not scrape enough images per category. Does anyone have any advice/know a public dataset that meet my criteria? Thanks in advance!",5,7
793,2016-10-25,2016,10,25,5,597166,Finding the best moment: K means clustering?,https://www.reddit.com/r/MachineLearning/comments/597166/finding_the_best_moment_k_means_clustering/,mphuget,1477342683,[removed],0,1
794,2016-10-25,2016,10,25,5,5971em,How do embedding layers work with variable word-length sentences?,https://www.reddit.com/r/MachineLearning/comments/5971em/how_do_embedding_layers_work_with_variable/,benkitty,1477342763,[removed],0,1
795,2016-10-25,2016,10,25,6,5971iz,CommaAI : Label data for AI based driving get points. Opinions on hand labeling objects for autonomous driving?,https://www.reddit.com/r/MachineLearning/comments/5971iz/commaai_label_data_for_ai_based_driving_get/,maxToTheJ,1477342801,,0,1
796,2016-10-25,2016,10,25,6,5971mj,Beginner question on pre activation functions,https://www.reddit.com/r/MachineLearning/comments/5971mj/beginner_question_on_pre_activation_functions/,[deleted],1477342822,[removed],0,1
797,2016-10-25,2016,10,25,6,597c8l,[D] Supervised learning on time-evolving bipartite graphs: Approaches?,https://www.reddit.com/r/MachineLearning/comments/597c8l/d_supervised_learning_on_timeevolving_bipartite/,Pieranha,1477345995,"I need to model the dynamics of time-evolving bipartite graphs, where one side, U, has nodes m=100 and the other side, V, has nodes n=5. There's roughly 50 time steps. The goal is to categorize millions of such graphs into one of 10 well-known labels, which are supplied with the graphs.

Nodes in U have the same meaning across graphs, whereas this is not the case for nodes in V (i.e. nodes in U are ordered, whereas nodes in V are unordered). The graphs are unweighted, start with a single link and 1-3 links are added with every time step. Links cannot be removed. Each graph has the same # of nodes, but different # of timesteps. Most importantly, the link creation dynamics are wildly different. Capturing these dynamics are critical to do the labeling properly.

What are some ways this could be modeled? I'm in the brainstorming phase so all ideas are highly appreciated!",6,8
798,2016-10-25,2016,10,25,7,597hwe,[P] Haskell bindings for TensorFlow,https://www.reddit.com/r/MachineLearning/comments/597hwe/p_haskell_bindings_for_tensorflow/,carlthome,1477347746,,16,89
799,2016-10-25,2016,10,25,8,597t5z,"18"" x 22"" Brand New Hydmech Semi-Automatic Vertical Mitering Band Saw, M...",https://www.reddit.com/r/MachineLearning/comments/597t5z/18_x_22_brand_new_hydmech_semiautomatic_vertical/,SterlingMachineryEx,1477351410,,0,1
800,2016-10-25,2016,10,25,8,597t96,[R] Presentation: Deep Reinforcement Learning,https://www.reddit.com/r/MachineLearning/comments/597t96/r_presentation_deep_reinforcement_learning/,Kaixhin,1477351440,,3,9
801,2016-10-25,2016,10,25,8,597wsw,"10"" x 16"" New Doall Automatic Horizontal (HEAVY DUTY) Bandsaw with Autom...",https://www.reddit.com/r/MachineLearning/comments/597wsw/10_x_16_new_doall_automatic_horizontal_heavy_duty/,SterlingMachineryEx,1477352620,,0,1
802,2016-10-25,2016,10,25,10,598ei4,I am not saying nvidia is evil but how's AMD's ecosystem about parallel computing especially in deep learning?,https://www.reddit.com/r/MachineLearning/comments/598ei4/i_am_not_saying_nvidia_is_evil_but_hows_amds/,cysin,1477358662,[removed],0,1
803,2016-10-25,2016,10,25,10,598erd,[HN Repost] Autoencoder for Molecular Structures,https://www.reddit.com/r/MachineLearning/comments/598erd/hn_repost_autoencoder_for_molecular_structures/,jostmey,1477358757,,0,2
804,2016-10-25,2016,10,25,11,598u70,[D] Reproducing WaveNet results?,https://www.reddit.com/r/MachineLearning/comments/598u70/d_reproducing_wavenet_results/,ReproducibleResearch,1477364335,"Just came across this github thread:

https://github.com/ibab/tensorflow-wavenet/issues/47#issuecomment-255918245

which didn't seem to reach much of a conclusion about why the WaveNet results were hard to reproduce. Since this paper made such a big splash with the ML community, has anyone been able to actually create wave forms of the same audio quality as the blog post?

I've come across a lot of open source implementations based on the paper, but none of them have reproduced anything like DeepMind's results.",19,7
805,2016-10-25,2016,10,25,12,598xzm,Let's share tricks to speed up recurrent neural network training,https://www.reddit.com/r/MachineLearning/comments/598xzm/lets_share_tricks_to_speed_up_recurrent_neural/,gmkim90,1477365727,[removed],0,1
806,2016-10-25,2016,10,25,12,5991k9,Best NLP technique to search for similar text,https://www.reddit.com/r/MachineLearning/comments/5991k9/best_nlp_technique_to_search_for_similar_text/,Schoolunch,1477367106,[removed],0,1
807,2016-10-25,2016,10,25,12,5993fo,How about the feature of powder liquid mixing machine?,https://www.reddit.com/r/MachineLearning/comments/5993fo/how_about_the_feature_of_powder_liquid_mixing/,mixmachinery,1477367875,,1,1
808,2016-10-25,2016,10,25,13,59966a,NLP technique that powers short text parsing,https://www.reddit.com/r/MachineLearning/comments/59966a/nlp_technique_that_powers_short_text_parsing/,zhderek,1477369039,[removed],0,1
809,2016-10-25,2016,10,25,13,5996z3,[D]How would /r/machinelearning feel about having an RNN powered bot randomly responding to posts?,https://www.reddit.com/r/MachineLearning/comments/5996z3/dhow_would_rmachinelearning_feel_about_having_an/,RaionTategami,1477369378,"EDIT: *I AM NOT GOING TO DO THIS!*
Thanks for the feedback everyone, the votes are in and it's a unanimous NO. I'm glad I asked, I personally would have found thing interesting but I'm clearly in the minority.

----------------------------

This is partly to get the mod's feedback since I can imagine just doing this randomly could get me in to trouble. This could be pretty cool but also annoying as hell if done incorrectly. Please take a look at the questions I want to discuss below.

So this is not an original idea and I have to imagine someone has possible already done this and not told anyone. You take this:
[A Neural Conversational Model](https://arxiv.org/pdf/1506.05869.pdf)
and throw it at this:
[i_have_every_publicly_available_reddit_comment](https://www.reddit.com/r/datasets/comments/3bxlg7/i_have_every_publicly_available_reddit_comment/) and let to loose on Reddit!

I have an initial implementation up and running and hope to improve it using some recent techniques. E.g. I think [HYPERNETWORKS](https://arxiv.org/pdf/1609.09106v1.pdf) are the current state of the art in language modelling.

Perhaps I should have seen this coming but...

**The main problem is that version 1 is a hateful, bigoted, sexist, condescending, potty-mouthed, meme spewing monster!**

Here are some *choice* outputs from my most recently trained model (these are in the form ACTUAL_REDDIT_COMMENT -&gt; RNN_GENERATED_REPLY)

*Responses of the RNN do not necessarily reflect the opinions of the author*

    ""Well, that's just, like, your opinion man. --&gt; Fap fap fap fap fap fap fap fap fap fap fap fap."" 
    RU/18 --&gt; I am trolling the most of the baby.
    It got gonorrhea. --&gt; gay as a ball of shit.
    things will turd around eventually --&gt; I never get reddit, I was there a lot.
    Step 2: moisture incurs. --&gt; You should think about your penis.
    What a jerk. Those people deserved to live. --&gt; It's what plants crave.
    Her brother is obviously agent 47. --&gt; You gotta go full retard.
    REDDIT IS NOT 4CHAN. --&gt; WE'LL DO IT LIVE!
    That's less people than voted for American Idol. --&gt; A panda inside of the motherfucker.
    --&gt; You say that like it's spelled *explainer*.
    *throws tomato* --&gt; **NOOOOOO!!!!**

I think my next step is to learn some subreddit embeddings as features so it can maybe learn that we don't swear in /r/MachineLearning as much?! 

So questions:

* Should the bot generally make it obvious that it is a bot? I initially wanted to just release it anonymously and see if it could get some positive karma. Kinda a Reddit-truing test.
* When and how often should it respond to things? My plan was to have it randomly pick a comment very rarely (~every 2 hours?). Respond to comments that respond to it and have a way to cause it to respond by having it's username in your comment for example.
* Is this even a good idea of should I just release it on /r/circlejerk, looks like it'd fit right in :)

Thoughts?

----------------------------
Some more examples just for fun:

    Happy Birthday! --&gt; a penis comment.  It's a palind of the round.
    Mohammad, Buddha and Ganesha all concur. --&gt; A trap
    *fap fap fap* --&gt; **crickets**.
    Ah yes, transparent aluminum. --&gt; I was your penis that I will not be a super funny.
    I didn't know vaginas could do the dishes. --&gt; asked for the greatest girl.
    HE'S A *NAGGER!* --&gt; ... was it an asshole?
    I am a peacock and I can confirm this. --&gt; I fucking listen to the leader of all.
    Is that the ship in BF BC2?? --&gt; hahahahahahahahahahahahahahahahahahahahahahahahaha
    i'm naked right now --&gt; interesting.
    Great. Now I have to masterbate. --&gt; if you're a robot dick there.
    where's dad?      son? --&gt; **SPOILER ALERT!**
    My gaydar was dinging when I saw that priest. --&gt; ... they do ass.
    Why did you leave the little piano? --&gt; in the best part of the sexual porn.
    Nikon always --&gt; How do you know what else was ""Gray and single?""
    Figurative big, brass balls! --&gt; Dental Plan!
    Oh yeah. Sure. --&gt; Oh god that was going to be a meme.
    Nickelback. --&gt; Nice try, mathematic teacher.
    Can you cite a source for that? --&gt; Why do you also have an epic abortion in a plane?

Implementation details for those interested:

Data munging:

* Filter out all comments below 20 karma (fat lot of use that was), comments longer than 50, deleted comments etc.
* Also had to filter out 'Robert Paulson', there are entire threads full of that guy and the model would say 'Robert Paulson' all the time.
* of the remaining comments paired up comment -&gt; reply pairs from threads to train on, no other features yet.


Model:

* Vanilla character seq2seq LSTM.
* RMSProp
* LEARNING_RATE = 0.01
* SEQ_MAX_LEN = 50
* RNN_HIDDEN_SIZE = 1024
* LAYERS = 3
* CHAR_EMB_SIZE = 128
* VOCAB_SIZE = 95
* Trained overnight, got nowhere near through a singe epoch.",14,0
810,2016-10-25,2016,10,25,13,5997ej,Neural nets applied to marker recognition under occlusion,https://www.reddit.com/r/MachineLearning/comments/5997ej/neural_nets_applied_to_marker_recognition_under/,victordmdb,1477369543,[removed],0,1
811,2016-10-25,2016,10,25,13,599a0u,Why a bigger number of epochs does not make a difference with not so deep convnets?,https://www.reddit.com/r/MachineLearning/comments/599a0u/why_a_bigger_number_of_epochs_does_not_make_a/,carlos_argueta,1477370631,[removed],0,1
812,2016-10-25,2016,10,25,13,599c5a,Jeremy Howard - A Look Back from 2026: How the Deep Learning Revolution Happened,https://www.reddit.com/r/MachineLearning/comments/599c5a/jeremy_howard_a_look_back_from_2026_how_the_deep/,[deleted],1477371591,[deleted],0,1
813,2016-10-25,2016,10,25,16,599t2s,Induction Hob in Global Market Research Report,https://www.reddit.com/r/MachineLearning/comments/599t2s/induction_hob_in_global_market_research_report/,markhub123,1477380500,,0,1
814,2016-10-25,2016,10,25,16,599ug1,Nuts and Bolts of Applying Deep Learning (Andrew Ng),https://www.reddit.com/r/MachineLearning/comments/599ug1/nuts_and_bolts_of_applying_deep_learning_andrew_ng/,AHFX,1477381334,,0,1
815,2016-10-25,2016,10,25,17,599wbr,[Project] I accidentally wrote a quasi-Newton (L-BFGS based) optimizer that could train neural networks using normal-sized minibatches.,https://www.reddit.com/r/MachineLearning/comments/599wbr/project_i_accidentally_wrote_a_quasinewton_lbfgs/,crowsonkb,1477382466,"[Original Python code for image synthesis](https://gist.github.com/crowsonkb/550fe172cd277bb2f057574f2e75aff4) - lots of image-specific things here.

[Torch code that I tried training neural networks with](https://gist.github.com/crowsonkb/8da6cc4bfc5e99565ea7f897700a0bc0) - adapted from the Python code with help from [optim/lbfgs.lua](https://github.com/torch/optim/blob/master/lbfgs.lua).

It was originally for stylized image synthesis by inverting CNNs ([neural style](https://github.com/crowsonkb/style_transfer) i.e. Gatys et al.). The usual way of doing this is to start from a white noise image and apply gradient descent or L-BFGS to it, using gradients from the backward pass of the CNN. It isn't a stochastic problem and ordinary L-BFGS works well on it.

Since momentum helps so much with gradient descent on this problem, I got ideas about incorporating momentum into L-BFGS (Nesterov ofc.). I already had custom L-BFGS code that I wrote to have a line search capable of dealing with the weird way I was normalizing the gradients. I made some fortuitous discoveries along the way. I ended up applying damping as well (forming the L-BFGS y vectors as a linear combination of the original y and the step), and learning how to modify the y vectors to produce a Hessian estimation that scaled the learning rates per-parameter. For stability's sake, and because I needed learning rate decay anyway, I scaled the learning rates with the Adagrad scaling matrix (per-parameter L2 norm of gradients seen so far). To my surprise the result behaved in a stable manner without a line search and actually worked better than Adam or L-BFGS on my image synthesis problem. Since I had modified the L-BFGS quasi-Newton algorithm with damping, momentum, and scaling, I started calling the result DMSQN.

I then reimplemented it in Torch just to see what would happen when I tried this weird thing on neural network training instead of the problem it was originally adapted for. To my great surprise, it actually performed well and didn't blow up numerically. There doesn't seem a reason to recommend its use over SGD or Adam, but it at least wasn't worse. The lack of a line search, along with the previously-mentioned damping, momentum, and scaling, probably account for why it worked in the stochastic regime even though it wasn't originally designed for it. (oLBFGS for instance does not use a line search and uses a similar form of damping; adaQN repurposes the Adagrad scaling matrix but IMO in not as stability-promoting a way as I used it)

Has anyone experimented with incorporating momentum into L-BFGS or other second-order methods, at all? There's a lot of prior work on damping for instance.",17,56
816,2016-10-25,2016,10,25,17,59a0r7,The raw production look of rubber process vessel,https://www.reddit.com/r/MachineLearning/comments/59a0r7/the_raw_production_look_of_rubber_process_vessel/,mixmachinery,1477385185,,1,1
817,2016-10-25,2016,10,25,18,59a6ht,Is there something out there to help me with this?,https://www.reddit.com/r/MachineLearning/comments/59a6ht/is_there_something_out_there_to_help_me_with_this/,hudsononreddit,1477388658,[removed],0,1
818,2016-10-25,2016,10,25,22,59awin,"Join Facebook, Google, Twitter &amp; more at the Machine Intelligence Summit in New York",https://www.reddit.com/r/MachineLearning/comments/59awin/join_facebook_google_twitter_more_at_the_machine/,reworksophie,1477400772,,0,1
819,2016-10-25,2016,10,25,22,59b4bo,Validation Data Set purpose?,https://www.reddit.com/r/MachineLearning/comments/59b4bo/validation_data_set_purpose/,WheresMyToiletPaper,1477403551,[removed],0,1
820,2016-10-25,2016,10,25,23,59b7qc,[Project] gym - Reinforcement Learning in R,https://www.reddit.com/r/MachineLearning/comments/59b7qc/project_gym_reinforcement_learning_in_r/,paulhendricks,1477404658,,0,11
821,2016-10-25,2016,10,25,23,59bdfj,Terminology for self-categorization in machine learning,https://www.reddit.com/r/MachineLearning/comments/59bdfj/terminology_for_selfcategorization_in_machine/,WheresMyToiletPaper,1477406455,[removed],0,1
822,2016-10-26,2016,10,26,0,59bnad,[D] Methodology to train Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/59bnad/d_methodology_to_train_convolutional_neural/,Ciuleandra24,1477409450,"I was wondering what advice you could give about training CNNs for image segmentation or classification. What I would like to know is:

1. How to do hyperparameter tuning? Suppose we have 3000 images for training, on GPU some networks take 12 or more hours to train. I would like to change some parameters but not wait that long each time. Is it relevant to train on a smaller subset? (How small, keep the batch size?)

2. How to choose the batch size? Is it ok to have very small batch size like 2?

3. How to choose the learning rate? Does it depend on image size or on the batch size?

4. How to handle very large images? For example size of 1024 x 2048? I'm concerned that the GPU does not have enough memory for such large images when using very deep architectures.

5. I think that plotting the loss and accuracy would be good. The loss should be going down and the accuracy up. Should I look to something else when analyzing these plots? Should I analyze other parameters?

6. Is it necessary to check the gradients? 

7. When to use learning rate decay?

Any advice on what steps to follow when training and how to do hyperparameter tuning would be appreciated. ",15,10
823,2016-10-26,2016,10,26,0,59bokf,MSI Gaming Laptops,https://www.reddit.com/r/MachineLearning/comments/59bokf/msi_gaming_laptops/,praiserobotoverlords,1477409829,[removed],0,1
824,2016-10-26,2016,10,26,0,59brms,Random chance neural network,https://www.reddit.com/r/MachineLearning/comments/59brms/random_chance_neural_network/,r_volpi,1477410760,[removed],0,1
825,2016-10-26,2016,10,26,1,59bvjq,Generating music based on image/video,https://www.reddit.com/r/MachineLearning/comments/59bvjq/generating_music_based_on_imagevideo/,_venkman,1477411868,[removed],0,1
826,2016-10-26,2016,10,26,2,59c5wl,Seems like CNTK got a massive upgrade. Including Python bindings. [News],https://www.reddit.com/r/MachineLearning/comments/59c5wl/seems_like_cntk_got_a_massive_upgrade_including/,elanmart,1477414885,,13,60
827,2016-10-26,2016,10,26,2,59chnp,GitHub - google/tensorflow-rust: Rust language bindings for TensorFlow,https://www.reddit.com/r/MachineLearning/comments/59chnp/github_googletensorflowrust_rust_language/,Dogsindahouse1,1477418241,,0,1
828,2016-10-26,2016,10,26,3,59ck2g,"[P] I made a DQN based Othello AI, suggestions welcome.",https://www.reddit.com/r/MachineLearning/comments/59ck2g/p_i_made_a_dqn_based_othello_ai_suggestions/,kh40tika,1477418907,,0,14
829,2016-10-26,2016,10,26,3,59cmwj,[D] A complete daily plan for studying to become a Machine Learning engineer.,https://www.reddit.com/r/MachineLearning/comments/59cmwj/d_a_complete_daily_plan_for_studying_to_become_a/,ZuzooVn,1477419713,,0,1
830,2016-10-26,2016,10,26,3,59cp71,Machine learning in retail sector in current situation,https://www.reddit.com/r/MachineLearning/comments/59cp71/machine_learning_in_retail_sector_in_current/,vinayakk123,1477420354,[removed],0,1
831,2016-10-26,2016,10,26,3,59cqsw,"Project ideas for entry-level, highly-parallelizable machine learning tasks",https://www.reddit.com/r/MachineLearning/comments/59cqsw/project_ideas_for_entrylevel_highlyparallelizable/,PM_ME_UR_OBSIDIAN,1477420823,[removed],0,1
832,2016-10-26,2016,10,26,3,59csql,How to reorder tediously long lists?,https://www.reddit.com/r/MachineLearning/comments/59csql/how_to_reorder_tediously_long_lists/,[deleted],1477421393,[removed],0,1
833,2016-10-26,2016,10,26,3,59cu96,"[Project] Simplified implementation of ""Convolutional Neural Networks for Sentence Classification"" paper",https://www.reddit.com/r/MachineLearning/comments/59cu96/project_simplified_implementation_of/,shagunsodhani,1477421863,,0,4
834,2016-10-26,2016,10,26,4,59d5la,[R] Building an Efficient Neural Language Model Over a Billion Words,https://www.reddit.com/r/MachineLearning/comments/59d5la/r_building_an_efficient_neural_language_model/,olBaa,1477425272,,8,21
835,2016-10-26,2016,10,26,5,59db69,What to expect during an interview,https://www.reddit.com/r/MachineLearning/comments/59db69/what_to_expect_during_an_interview/,thenerdstation,1477426832,[removed],0,1
836,2016-10-26,2016,10,26,5,59df5i,Sentiment Classification with MATLAB/Multinomial Naive Bayes,https://www.reddit.com/r/MachineLearning/comments/59df5i/sentiment_classification_with_matlabmultinomial/,[deleted],1477428034,[removed],0,1
837,2016-10-26,2016,10,26,6,59dk4l,Machine learning(and data science) for the average person,https://www.reddit.com/r/MachineLearning/comments/59dk4l/machine_learningand_data_science_for_the_average/,bryseeayo,1477429501,[removed],0,1
838,2016-10-26,2016,10,26,6,59dllc,[N] Windows TensorFlow GPU Support (docs updated),https://www.reddit.com/r/MachineLearning/comments/59dllc/n_windows_tensorflow_gpu_support_docs_updated/,whateverr123,1477429925,,2,0
839,2016-10-26,2016,10,26,6,59dme6,[R] [1609.04309] Efficient softmax approximation for GPUs (Facebook AI Research),https://www.reddit.com/r/MachineLearning/comments/59dme6/r_160904309_efficient_softmax_approximation_for/,dhammack,1477430160,,3,32
840,2016-10-26,2016,10,26,6,59dpuc,Using neural nets to recognize handwritten digits,https://www.reddit.com/r/MachineLearning/comments/59dpuc/using_neural_nets_to_recognize_handwritten_digits/,micasstuff,1477431247,,0,1
841,2016-10-26,2016,10,26,6,59du5m,Deep Learning for 2D Animation,https://www.reddit.com/r/MachineLearning/comments/59du5m/deep_learning_for_2d_animation/,[deleted],1477432573,[removed],0,1
842,2016-10-26,2016,10,26,7,59dv0o,Data collection for a self-driving car (livestream),https://www.reddit.com/r/MachineLearning/comments/59dv0o/data_collection_for_a_selfdriving_car_livestream/,vanboxel,1477432843,,0,1
843,2016-10-26,2016,10,26,8,59egsh,[D] What does a typical ML architecture look like in production?,https://www.reddit.com/r/MachineLearning/comments/59egsh/d_what_does_a_typical_ml_architecture_look_like/,iamaroosterilluzion,1477439937,"For example, if you're an ML / software engineer at an ecommerce company and you're tasked with building a product recommendation engine, what might your software architecture look like?

- Does your data come in from an ETL-like process?
- Where do you store your data? Postgres, Hadoop, a csv file?
- How do you manage the training and prediction processes for the model? Do you run them as cron processes or synchronously as new data comes in? Does the model ""live"" on a server?
- How does the ecommerce app get recommendations from the model? Do you build a REST API on top of the model to serve the recommendations?

Another example might be a lead scoring engine, would the architecture look completely different or are there a set of best practices?",50,182
844,2016-10-26,2016,10,26,9,59epqi,[D] Insight on RNN seq2seq problem approach.,https://www.reddit.com/r/MachineLearning/comments/59epqi/d_insight_on_rnn_seq2seq_problem_approach/,jayjaymz,1477442984,"Hello there. I'm tasked with using Recurrent Neural Netwroks to generate source code from a chunk of javascript projects.

Firstly, I implemented Karpathy's lstm-char-rnn in keras. It provided some fun results. After that I'm looking for a different way to approach the problem.

As an idea, I wanted to label the characters extracted from the dataset (based on their usage in the code: string, identifier, numeric and so on), thus creating 2dimensional input. I would also like the output to be 2dimensional. I googled around and found no information as to how to implement it. Is there any known approach to having 2 dimensional input &amp; output of sequences with RNNs? Is there some other topology that could help me map sequences to sequences?

Thank you.",11,0
845,2016-10-26,2016,10,26,10,59eylt,50 gym exercises are classified with a 92% accuracy with data from a single arm band,https://www.reddit.com/r/MachineLearning/comments/59eylt/50_gym_exercises_are_classified_with_a_92/,terryum,1477446140,,0,1
846,2016-10-26,2016,10,26,11,59f5dx,Modelling &amp; Implementing Neural Networks From Scratch?,https://www.reddit.com/r/MachineLearning/comments/59f5dx/modelling_implementing_neural_networks_from/,she89,1477448590,[removed],0,1
847,2016-10-26,2016,10,26,11,59f98o,[Discussion] Modelling &amp; Implementing Neural Network from Scratch?,https://www.reddit.com/r/MachineLearning/comments/59f98o/discussion_modelling_implementing_neural_network/,she89,1477449999,"Hi, I tried to implement a neural network and failed. I faced 2 problems:  
1. I needed a multi-dimensional dynamic array. Using normal arrays failed, so I used Eigen.  
2. I couldn't model the NN well. It seems too complex.   
The problem with 2 is it may be hard to imagine the whole possible structures in my mind. How to architect big programs?  
I asked a professor and the reply was to use a NN library, but I found 2 problems:  
1. License: Will I be arrested if I used a library like CNTK in a comercial product?  
*Note: I used CNTK as an example, because I prefer C++ over Python.*  
2. What if it wasn't enough and I've to implement something by myself?  
  
What are your advices? Should I try again or use a library? I'm planning to make something like the neuron simulator **NEST**.",5,0
848,2016-10-26,2016,10,26,11,59f9w3,Stochastic Gradient MCMC with Stale Gradients,https://www.reddit.com/r/MachineLearning/comments/59f9w3/stochastic_gradient_mcmc_with_stale_gradients/,machiner_ps,1477450234,,0,1
849,2016-10-26,2016,10,26,12,59fjt8,Blogs for model / experiment design,https://www.reddit.com/r/MachineLearning/comments/59fjt8/blogs_for_model_experiment_design/,blast00,1477454154,[removed],0,1
850,2016-10-26,2016,10,26,13,59fqza,[Discussion] What's the difference between dilated convolution and deconvolution (transposed convolution)?,https://www.reddit.com/r/MachineLearning/comments/59fqza/discussion_whats_the_difference_between_dilated/,darkconfidantislife,1477457160,"Hi guys, I'm having a bit of trouble understanding the difference between transposed convolution (deconvolution) and dilated convolution. Could someone please explain it to me? From what I understand, they both seem to be the same thing, you ""expand"" the matrix by interpolating with 0s to make the dimensions bigger and then convolve as normal.

Thanks in advance :)",17,1
851,2016-10-26,2016,10,26,14,59fw3n,Would there be any issues with using Iron Python over python?,https://www.reddit.com/r/MachineLearning/comments/59fw3n/would_there_be_any_issues_with_using_iron_python/,blakdart,1477459433,[removed],0,1
852,2016-10-26,2016,10,26,15,59g155,Global Residential Water Treatment Equipment Industry Analysis Report,https://www.reddit.com/r/MachineLearning/comments/59g155/global_residential_water_treatment_equipment/,markhub123,1477461939,,0,1
853,2016-10-26,2016,10,26,15,59g3dn,Machine Learning for Cancer Research,https://www.reddit.com/r/MachineLearning/comments/59g3dn/machine_learning_for_cancer_research/,0nicholas,1477463125,[removed],0,1
854,2016-10-26,2016,10,26,17,59gf4y,Machine Learning Veterans Launch 'Element AI' - A Montreal Based Artificial Intelligence Startup Factory,https://www.reddit.com/r/MachineLearning/comments/59gf4y/machine_learning_veterans_launch_element_ai_a/,dharma-1,1477469664,,0,1
855,2016-10-26,2016,10,26,18,59gkqx,Microsoft launches Cognitive Toolkit 2.0 beta with Python support,https://www.reddit.com/r/MachineLearning/comments/59gkqx/microsoft_launches_cognitive_toolkit_20_beta_with/,sofakingon,1477473014,,0,1
856,2016-10-26,2016,10,26,19,59gujq,"I've just finished Andrew Ng's Coursera, what are some good resources to continue my learning?",https://www.reddit.com/r/MachineLearning/comments/59gujq/ive_just_finished_andrew_ngs_coursera_what_are/,gorillaf,1477478553,[removed],0,1
857,2016-10-26,2016,10,26,20,59gzql,Predict Coupon Codes,https://www.reddit.com/r/MachineLearning/comments/59gzql/predict_coupon_codes/,vs4vijay,1477481169,[removed],0,1
858,2016-10-26,2016,10,26,22,59hhgs,GitHub - jtoy/awesome-tensorflow: TensorFlow - A curated list of dedicated resources,https://www.reddit.com/r/MachineLearning/comments/59hhgs/github_jtoyawesometensorflow_tensorflow_a_curated/,Dogsindahouse1,1477488255,,0,1
859,2016-10-26,2016,10,26,22,59hhjv,Ryan Zotti | How to Build Your Own Self Driving Toy Car,https://www.reddit.com/r/MachineLearning/comments/59hhjv/ryan_zotti_how_to_build_your_own_self_driving_toy/,[deleted],1477488284,[deleted],0,1
860,2016-10-26,2016,10,26,22,59hhum,Yoshua Bengio confounds ElementAI,https://www.reddit.com/r/MachineLearning/comments/59hhum/yoshua_bengio_confounds_elementai/,[deleted],1477488389,[deleted],0,1
861,2016-10-26,2016,10,26,22,59hjx2,Need help for clustering,https://www.reddit.com/r/MachineLearning/comments/59hjx2/need_help_for_clustering/,Lord_Snow_John,1477489132,[removed],0,1
862,2016-10-26,2016,10,26,22,59hn8a,[Discussion] What do you think about Direct Feedback Alignment?,https://www.reddit.com/r/MachineLearning/comments/59hn8a/discussion_what_do_you_think_about_direct/,Flowx08,1477490280,[removed],0,1
863,2016-10-26,2016,10,26,23,59ho74,How can I leverage machine learning in my Business Intelligence/Data warehouse?,https://www.reddit.com/r/MachineLearning/comments/59ho74/how_can_i_leverage_machine_learning_in_my/,abhi5025,1477490579,[removed],0,1
864,2016-10-26,2016,10,26,23,59hwh6,"AI Pioneer Yoshua Bengio Is Launching Element.AI, a Deep-Learning Incubator",https://www.reddit.com/r/MachineLearning/comments/59hwh6/ai_pioneer_yoshua_bengio_is_launching_elementai_a/,SarcasticMetaName,1477493193,,19,131
865,2016-10-26,2016,10,26,23,59hxwi,"[D] Where to learn about wavelets, symmetries, and scattering transforms?",https://www.reddit.com/r/MachineLearning/comments/59hxwi/d_where_to_learn_about_wavelets_symmetries_and/,Kiuhnm,1477493621,"I'm trying to read [Understanding Deep Convolutional Networks](https://arxiv.org/abs/1601.04920), but I'm struggling because I'm completely new to concepts such as lie groups, diffeomorphisms, wavelets and scattering transforms.

I don't have the time to study all that math properly and I don't think it'd be worth it. I have no problems with delta-epsilon definitions and abstractions like groups, rings, etc..., but I don't want to learn theorems and concepts which aren't strictly relevant.

Is there something like an *extended* version of that paper or a book which gives you just enough to understand all those concepts?

---

edit: The book [Functions, Spaces, and Expansions](https://www.amazon.com/Functions-Spaces-Expansions-Mathematical-Engineering-ebook/dp/B00FBG7A8I/keywords=wavelets+linear) seems like a good choice since the prerequisites are modest enough.",8,5
866,2016-10-27,2016,10,27,0,59i9fa,[Project] Simple CTC Beam Search implementation,https://www.reddit.com/r/MachineLearning/comments/59i9fa/project_simple_ctc_beam_search_implementation/,[deleted],1477497027,[deleted],0,1
867,2016-10-27,2016,10,27,0,59i9w6,"Simple Questions Thread October 26, 2016",https://www.reddit.com/r/MachineLearning/comments/59i9w6/simple_questions_thread_october_26_2016/,AutoModerator,1477497155,[removed],0,1
868,2016-10-27,2016,10,27,1,59ica9,Good list of online ML courses,https://www.reddit.com/r/MachineLearning/comments/59ica9/good_list_of_online_ml_courses/,[deleted],1477497821,[deleted],0,1
869,2016-10-27,2016,10,27,1,59iiz9,[1610.07629] A Learned Representation For Artistic Style,https://www.reddit.com/r/MachineLearning/comments/59iiz9/161007629_a_learned_representation_for_artistic/,ajmooch,1477499744,,6,37
870,2016-10-27,2016,10,27,2,59j05a,Could you train an inside-out computer vision tracking system for VR using the HTC Vive's camera + the positional data from the laser tracking system?,https://www.reddit.com/r/MachineLearning/comments/59j05a/could_you_train_an_insideout_computer_vision/,godelbrot,1477504594,[removed],0,1
871,2016-10-27,2016,10,27,3,59j7ew,Trying to do Semantic Analysis on NFL Scouting Reports through use of gensim,https://www.reddit.com/r/MachineLearning/comments/59j7ew/trying_to_do_semantic_analysis_on_nfl_scouting/,BobbySeals,1477506664,[removed],0,1
872,2016-10-27,2016,10,27,3,59j7t4,[R] [1610.07675] Surprisal-Driven Zoneout,https://www.reddit.com/r/MachineLearning/comments/59j7t4/r_161007675_surprisaldriven_zoneout/,kmrocki,1477506784,,15,4
873,2016-10-27,2016,10,27,3,59jalh,Google Research releases a massive improvement on the neural artistic style transfer algorithm,https://www.reddit.com/r/MachineLearning/comments/59jalh/google_research_releases_a_massive_improvement_on/,[deleted],1477507593,[deleted],0,1
874,2016-10-27,2016,10,27,10,59ld2k,Need tips on getting started.,https://www.reddit.com/r/MachineLearning/comments/59ld2k/need_tips_on_getting_started/,Daneye77,1477531396,[removed],0,1
875,2016-10-27,2016,10,27,13,59m5gw,[D] Network for audio/musical features.,https://www.reddit.com/r/MachineLearning/comments/59m5gw/d_network_for_audiomusical_features/,jjrob13,1477542234,I am doing some work in the music information retrieval domain and was wondering if the weights for any of the speech to text networks were available or if any other trained networks for musical feature extraction were open sourced.,7,6
876,2016-10-27,2016,10,27,13,59m62n,Real-time Pattern Detection in Customer Behavior,https://www.reddit.com/r/MachineLearning/comments/59m62n/realtime_pattern_detection_in_customer_behavior/,virene,1477542488,,0,1
877,2016-10-27,2016,10,27,13,59m9n0,Linear regression - question,https://www.reddit.com/r/MachineLearning/comments/59m9n0/linear_regression_question/,yyujk,1477544097,[removed],0,1
878,2016-10-27,2016,10,27,14,59mfeu,CS229 Machine Learning Stanford Doubts,https://www.reddit.com/r/MachineLearning/comments/59mfeu/cs229_machine_learning_stanford_doubts/,rsaha,1477546835,[removed],0,1
879,2016-10-27,2016,10,27,17,59mxow,Need help choosing a ML model,https://www.reddit.com/r/MachineLearning/comments/59mxow/need_help_choosing_a_ml_model/,prediktor,1477557170,[removed],0,1
880,2016-10-27,2016,10,27,18,59n2jq,Machine Learning and Artificial Intelligence: everyday life goes 4.0?,https://www.reddit.com/r/MachineLearning/comments/59n2jq/machine_learning_and_artificial_intelligence/,capn3m0,1477560134,,0,1
881,2016-10-27,2016,10,27,18,59n4qo,generate long and meanful text by seq-to-seq,https://www.reddit.com/r/MachineLearning/comments/59n4qo/generate_long_and_meanful_text_by_seqtoseq/,jdxyw,1477561429,[removed],0,1
882,2016-10-27,2016,10,27,19,59n75r,Deep Learning GPU Benchmarks - GTX 1080 vs Titan X,https://www.reddit.com/r/MachineLearning/comments/59n75r/deep_learning_gpu_benchmarks_gtx_1080_vs_titan_x/,capn3m0,1477562783,,0,1
883,2016-10-27,2016,10,27,19,59nbml,Build image classifier with bounding boxes.,https://www.reddit.com/r/MachineLearning/comments/59nbml/build_image_classifier_with_bounding_boxes/,gabegabe6,1477565242,[removed],0,1
884,2016-10-27,2016,10,27,20,59nkaa,[arXiv:1610.07448] A Framework for Parallel and Distributed Training of Neural Networks,https://www.reddit.com/r/MachineLearning/comments/59nkaa/arxiv161007448_a_framework_for_parallel_and/,scardax88,1477569456,,0,3
885,2016-10-27,2016,10,27,21,59nptb,Machine Learning and Data Science Resources You Should Know About,https://www.reddit.com/r/MachineLearning/comments/59nptb/machine_learning_and_data_science_resources_you/,hrb1979,1477571716,,0,1
886,2016-10-27,2016,10,27,21,59nt3n,[R] Group-Aware Deep Feature Learning For Facial Age Estimation,https://www.reddit.com/r/MachineLearning/comments/59nt3n/r_groupaware_deep_feature_learning_for_facial_age/,sybilckw,1477572998,,3,5
887,2016-10-27,2016,10,27,23,59o4t0,https://www.techdirt.com/articles/20161026/08144335892/alibabas-boss-says-chinese-government-should-use-big-data-techniques-citizen-scores-surveillance-store.shtml,https://www.reddit.com/r/MachineLearning/comments/59o4t0/httpswwwtechdirtcomarticles2016102608144335892alib/,[deleted],1477577087,[deleted],0,1
888,2016-10-27,2016,10,27,23,59o4wp,Alibaba's Boss Says Chinese Government Should Use Big Data Techniques On Its 'Citizen Scores' Surveillance Store,https://www.reddit.com/r/MachineLearning/comments/59o4wp/alibabas_boss_says_chinese_government_should_use/,johnmountain,1477577118,,0,1
889,2016-10-27,2016,10,27,23,59o6et,Understanding XGBoost Model on Otto Dataset,https://www.reddit.com/r/MachineLearning/comments/59o6et/understanding_xgboost_model_on_otto_dataset/,rishiarora,1477577595,,0,1
890,2016-10-27,2016,10,27,23,59obye,[R] [1610.06402] A Growing Long-term Episodic &amp; Semantic Memory,https://www.reddit.com/r/MachineLearning/comments/59obye/r_161006402_a_growing_longterm_episodic_semantic/,evc123,1477579376,,10,19
891,2016-10-28,2016,10,28,0,59on3i,Is tesla p100 faster than Knights Landing?,https://www.reddit.com/r/MachineLearning/comments/59on3i/is_tesla_p100_faster_than_knights_landing/,benjibenjichasin,1477582707,[removed],0,1
892,2016-10-28,2016,10,28,0,59on85,Are there any successful online learning methods for NNs / deep NNs?,https://www.reddit.com/r/MachineLearning/comments/59on85/are_there_any_successful_online_learning_methods/,[deleted],1477582745,[removed],0,1
893,2016-10-28,2016,10,28,0,59or9c,Machine is no longer for experts. Will it become as popular as mobile app development among developers?,https://www.reddit.com/r/MachineLearning/comments/59or9c/machine_is_no_longer_for_experts_will_it_become/,shamict,1477583954,,0,1
894,2016-10-28,2016,10,28,1,59ot5j,"BigData and ML Example and Framework Weekly Roundup  Oct. 27, 2016",https://www.reddit.com/r/MachineLearning/comments/59ot5j/bigdata_and_ml_example_and_framework_weekly/,stkim1,1477584480,,0,1
895,2016-10-28,2016,10,28,1,59oxwn,[Research] [1610.08123] Socratic Learning,https://www.reddit.com/r/MachineLearning/comments/59oxwn/research_161008123_socratic_learning/,Mandrathax,1477585875,,1,17
896,2016-10-28,2016,10,28,1,59p2lo,Model uncertainty for Deep Recurrent Models,https://www.reddit.com/r/MachineLearning/comments/59p2lo/model_uncertainty_for_deep_recurrent_models/,bronzestick,1477587260,[removed],0,1
897,2016-10-28,2016,10,28,1,59p3fh,[P] Machine Learning Models Predicting Dangerous Seismic Events,https://www.reddit.com/r/MachineLearning/comments/59p3fh/p_machine_learning_models_predicting_dangerous/,pmigdal,1477587494,,3,7
898,2016-10-28,2016,10,28,2,59p72p,"Would experimenting with ML models on robotic bodies be of interest to the community, and if yes on what type of robots?",https://www.reddit.com/r/MachineLearning/comments/59p72p/would_experimenting_with_ml_models_on_robotic/,thelibar,1477588523,[removed],0,1
899,2016-10-28,2016,10,28,2,59p7py,The Best Kept Secret in Machine Learning? Unveiling...,https://www.reddit.com/r/MachineLearning/comments/59p7py/the_best_kept_secret_in_machine_learning_unveiling/,DataRobotOfficial,1477588706,,0,1
900,2016-10-28,2016,10,28,3,59pllb,When to co-train RNNs &amp; CNNs?,https://www.reddit.com/r/MachineLearning/comments/59pllb/when_to_cotrain_rnns_cnns/,[deleted],1477592740,[removed],0,1
901,2016-10-28,2016,10,28,3,59pq4v,When is it a good idea to co-train RNNs &amp; CNNs?,https://www.reddit.com/r/MachineLearning/comments/59pq4v/when_is_it_a_good_idea_to_cotrain_rnns_cnns/,[deleted],1477594026,[removed],0,1
902,2016-10-28,2016,10,28,4,59q4p3,Are there any good recent papers related to gaming out there?,https://www.reddit.com/r/MachineLearning/comments/59q4p3/are_there_any_good_recent_papers_related_to/,BigMakondo,1477598245,[removed],0,1
903,2016-10-28,2016,10,28,5,59q9v2,"[R] CS231n has an Amazon Machine Image with Caffe, Torch7, Theano, Keras and Lasagne, and CUDA 7.5 and CuDNN v3",https://www.reddit.com/r/MachineLearning/comments/59q9v2/r_cs231n_has_an_amazon_machine_image_with_caffe/,ibtrippindoe,1477599746,,0,0
904,2016-10-28,2016,10,28,5,59qds2,[D] I built this site (Axiver.org) so I could save arXiv machine learning papers and feeds in one location. I'd love some feedback!,https://www.reddit.com/r/MachineLearning/comments/59qds2/d_i_built_this_site_axiverorg_so_i_could_save/,essofluffy,1477600881,,39,59
905,2016-10-28,2016,10,28,6,59qpb1,[N] The darker side of machine learning,https://www.reddit.com/r/MachineLearning/comments/59qpb1/n_the_darker_side_of_machine_learning/,pmigdal,1477604375,,1,1
906,2016-10-28,2016,10,28,7,59qtxo,"25 Ton x 2"" Used V &amp; O High Speed OBI Press, Mdl. 25ST, Air Clutch &amp; Bra...",https://www.reddit.com/r/MachineLearning/comments/59qtxo/25_ton_x_2_used_v_o_high_speed_obi_press_mdl_25st/,SterlingMachineryEx,1477605822,,0,1
907,2016-10-28,2016,10,28,7,59qu63,Electric Machines,https://www.reddit.com/r/MachineLearning/comments/59qu63/electric_machines/,mohamadbs,1477605896,,0,1
908,2016-10-28,2016,10,28,8,59r5wh,"10"" x 50"" Used Chevalier 3 Axis CNC Or Manual Use Vertical Mill, Mdl. FM...",https://www.reddit.com/r/MachineLearning/comments/59r5wh/10_x_50_used_chevalier_3_axis_cnc_or_manual_use/,SterlingMachineryEx,1477609757,,0,1
909,2016-10-28,2016,10,28,8,59r6va,[Discussion] Is NEON still maintained? They've been silent for a while now.,https://www.reddit.com/r/MachineLearning/comments/59r6va/discussion_is_neon_still_maintained_theyve_been/,[deleted],1477610063,[deleted],0,1
910,2016-10-28,2016,10,28,11,59s68n,[R] Supercharging Style Transfer - Google Brain Team,https://www.reddit.com/r/MachineLearning/comments/59s68n/r_supercharging_style_transfer_google_brain_team/,nagasgura,1477622277,,1,42
911,2016-10-28,2016,10,28,12,59sfz8,[Research] Learning to Reason With Adaptive Computation,https://www.reddit.com/r/MachineLearning/comments/59sfz8/research_learning_to_reason_with_adaptive/,MarkusDeNeutoy,1477626022,,7,7
912,2016-10-28,2016,10,28,14,59stao,[R] [1610.08613] Can Active Memory Replace Attention?,https://www.reddit.com/r/MachineLearning/comments/59stao/r_161008613_can_active_memory_replace_attention/,evc123,1477631768,,5,5
913,2016-10-28,2016,10,28,14,59stlt,Supervised Learning with Quantum-Inspired Tensor Networks,https://www.reddit.com/r/MachineLearning/comments/59stlt/supervised_learning_with_quantuminspired_tensor/,machiner_ps,1477631914,,0,1
914,2016-10-28,2016,10,28,15,59t06l,Manufacturer and Exporter of Coil Winding Machine,https://www.reddit.com/r/MachineLearning/comments/59t06l/manufacturer_and_exporter_of_coil_winding_machine/,amce123,1477635216,,0,1
915,2016-10-28,2016,10,28,17,59tfk7,Full automatic sleeve shrink labeling machine for juice filling line | shrink sleeve applicator,https://www.reddit.com/r/MachineLearning/comments/59tfk7/full_automatic_sleeve_shrink_labeling_machine_for/,stevenwangfilling,1477644392,,0,1
916,2016-10-28,2016,10,28,18,59tif2,Data needed to build a language model for a voice search system,https://www.reddit.com/r/MachineLearning/comments/59tif2/data_needed_to_build_a_language_model_for_a_voice/,NihilisticFool,1477646237,[removed],0,1
917,2016-10-28,2016,10,28,18,59tjn1,How about industrial clay plasticine extrusion machine,https://www.reddit.com/r/MachineLearning/comments/59tjn1/how_about_industrial_clay_plasticine_extrusion/,mixmachinery,1477646976,,1,1
918,2016-10-28,2016,10,28,18,59tkfe,[D] How not to approach machine learning,https://www.reddit.com/r/MachineLearning/comments/59tkfe/d_how_not_to_approach_machine_learning/,epic-username,1477647462,,2,0
919,2016-10-28,2016,10,28,18,59tl82,"Democratising Deep Learning: The Data Delusion - Slides &amp; Presentation by Neil Lawrence, Senior Principal Scientist at Amazon",https://www.reddit.com/r/MachineLearning/comments/59tl82/democratising_deep_learning_the_data_delusion/,reworksophie,1477647943,,6,7
920,2016-10-28,2016,10,28,18,59tlog,How does the reactor manufacturers work in factory,https://www.reddit.com/r/MachineLearning/comments/59tlog/how_does_the_reactor_manufacturers_work_in_factory/,mixmachinery,1477648246,,1,1
921,2016-10-28,2016,10,28,19,59tmwh,Is a course in AI helpful in any way for a degree in machine learning and data analysis?,https://www.reddit.com/r/MachineLearning/comments/59tmwh/is_a_course_in_ai_helpful_in_any_way_for_a_degree/,[deleted],1477648928,[removed],0,1
922,2016-10-28,2016,10,28,19,59tr8m,[P] - Source code release for Recurrent Highway Networks in Tensorflow/Torch7 for reproducing SOTA results on PennTreebank/enwik8 (arXiv v3 of paper),https://www.reddit.com/r/MachineLearning/comments/59tr8m/p_source_code_release_for_recurrent_highway/,flukeskywalker,1477651394,,6,54
923,2016-10-28,2016,10,28,20,59tu6z,Resources to learn about Monte Carlo methods in Machine Learning?,https://www.reddit.com/r/MachineLearning/comments/59tu6z/resources_to_learn_about_monte_carlo_methods_in/,xristos_forokolomvos,1477652897,[removed],0,1
924,2016-10-28,2016,10,28,20,59twcy,How I used Machine Learning to Find Good Eyes,https://www.reddit.com/r/MachineLearning/comments/59twcy/how_i_used_machine_learning_to_find_good_eyes/,[deleted],1477654025,[deleted],1,1
925,2016-10-28,2016,10,28,22,59uc6c,Deep Learning applied for product categorization in e-commerce (interview),https://www.reddit.com/r/MachineLearning/comments/59uc6c/deep_learning_applied_for_product_categorization/,[deleted],1477660494,[deleted],0,1
926,2016-10-28,2016,10,28,22,59uf99,Crowdsourced machine learning algorithm predicts how molecules smell,https://www.reddit.com/r/MachineLearning/comments/59uf99/crowdsourced_machine_learning_algorithm_predicts/,psioni,1477661623,,0,1
927,2016-10-28,2016,10,28,22,59ugq1,[Project] How I used Machine Learning to Find Good Eyes,https://www.reddit.com/r/MachineLearning/comments/59ugq1/project_how_i_used_machine_learning_to_find_good/,[deleted],1477662167,[deleted],0,2
928,2016-10-28,2016,10,28,22,59ugsn,Are there any successful online learning methods for NNs / deep NNs?,https://www.reddit.com/r/MachineLearning/comments/59ugsn/are_there_any_successful_online_learning_methods/,[deleted],1477662194,[removed],0,1
929,2016-10-28,2016,10,28,22,59ujjn,[Discussion] Research tools for people who read lots of PDFs,https://www.reddit.com/r/MachineLearning/comments/59ujjn/discussion_research_tools_for_people_who_read/,short_vix,1477663170,"Apologies in advance if this is the wrong place for this sort of post. If you guys are like me, you shift through hundreds of PDFs and haven't found a satisfactory research tool. I've been looking for quite some time and have not found one with the following set of features.

 * ability to search by author or title and edit the meta data( you usually have to correct this ).
 * ability to add multiple tags and search by tags
 * web, mobile or cross platform (I prefer tablet)
 * ability to annotate and share annotations with others
 * collaboration, ability to share work spaces, PDFs, notes exc.. exc..
 * drop box integration

Is there something out there that has the following set of features? The closest tool I found is LiquidText PDF for the iPad however it's missing a quite a few features from the above set.",37,65
930,2016-10-28,2016,10,28,23,59uojn,"[P] Research Collaboration with Cloud-Based R, SQL and LaTeX",https://www.reddit.com/r/MachineLearning/comments/59uojn/p_research_collaboration_with_cloudbased_r_sql/,samdavidson1,1477664756,,0,1
931,2016-10-28,2016,10,28,23,59uth3,[D] Training activation function parameters in addition to weights?,https://www.reddit.com/r/MachineLearning/comments/59uth3/d_training_activation_function_parameters_in/,zergling103,1477666329,"So, I've been thinking about how the activation function you use can change how easy it is to train your NN. There are: Sigmoid, tanh, rectifier, leaky rectifier, softplus, etc.

This had me thinking: Perhaps as part of the training process, one could allow the network to change activation functions on individual neurons to see how this improves or degrades its performance.

Of course, switching from two discrete activation functions abruptly (rectifier to tanh) would likely be too drastic of a change to work, especially with deep networks. So perhaps if you had a more complex activation function that could be parametrically adjusted to take on the form of most simpler activation functions, one could let the network decide what flavour of activation works best by adjusting the parameters in the same way weights are trained.

Has something like this been explored?",9,8
932,2016-10-29,2016,10,29,0,59uy9e,Help organizing labeled and weighted training data for image recognition classifier or DL,https://www.reddit.com/r/MachineLearning/comments/59uy9e/help_organizing_labeled_and_weighted_training/,[deleted],1477667736,[removed],0,1
933,2016-10-29,2016,10,29,1,59v9ua,[R] [1610.06918] Learning to Protect Communications with Adversarial Neural Cryptography,https://www.reddit.com/r/MachineLearning/comments/59v9ua/r_161006918_learning_to_protect_communications/,nagasgura,1477671177,,18,36
934,2016-10-29,2016,10,29,1,59vac9,Why Bijur Delimon Lubrication Systems are Essential For Your Machinery?,https://www.reddit.com/r/MachineLearning/comments/59vac9/why_bijur_delimon_lubrication_systems_are/,jackerfrinandis,1477671317,,0,1
935,2016-10-29,2016,10,29,1,59vgpg,How Proper Lubrication Optimize Your Machine Operations?,https://www.reddit.com/r/MachineLearning/comments/59vgpg/how_proper_lubrication_optimize_your_machine/,jackerfrinandis,1477673144,,0,1
936,2016-10-29,2016,10,29,2,59vkju,Machine Learning &amp; manufacturing Startup. Co-founder,https://www.reddit.com/r/MachineLearning/comments/59vkju/machine_learning_manufacturing_startup_cofounder/,ajk_89,1477674279,[removed],0,1
937,2016-10-29,2016,10,29,3,59vz0s,Hidden Markov Models (Gaussian emissions) in Python 3 using Tensorflow,https://www.reddit.com/r/MachineLearning/comments/59vz0s/hidden_markov_models_gaussian_emissions_in_python/,kesmarag,1477678298,,0,1
938,2016-10-29,2016,10,29,4,59waj8,Where to look for ML Engineering/Research Scientist internships (1st year Grad)?,https://www.reddit.com/r/MachineLearning/comments/59waj8/where_to_look_for_ml_engineeringresearch/,GradLyfe,1477681584,[removed],0,1
939,2016-10-29,2016,10,29,4,59we9p,Building an efficient neural language model over a billion words,https://www.reddit.com/r/MachineLearning/comments/59we9p/building_an_efficient_neural_language_model_over/,Dogsindahouse1,1477682669,,0,1
940,2016-10-29,2016,10,29,4,59whxs,Dogsnappr: A project I started to learn neural networks and web development,https://www.reddit.com/r/MachineLearning/comments/59whxs/dogsnappr_a_project_i_started_to_learn_neural/,thewhizz,1477683737,,0,1
941,2016-10-29,2016,10,29,5,59wo3e,What would be the best way to get into building and training a chatbot?,https://www.reddit.com/r/MachineLearning/comments/59wo3e/what_would_be_the_best_way_to_get_into_building/,homerguy,1477685590,[removed],0,1
942,2016-10-29,2016,10,29,7,59xa31,Detecting People in Artwork with CNNs,https://www.reddit.com/r/MachineLearning/comments/59xa31/detecting_people_in_artwork_with_cnns/,leehomyc,1477692376,,0,1
943,2016-10-29,2016,10,29,7,59xd7m,Are the families of hyperplanes weak learners ?,https://www.reddit.com/r/MachineLearning/comments/59xd7m/are_the_families_of_hyperplanes_weak_learners/,vighneshbirodkar,1477693397,[removed],0,1
944,2016-10-29,2016,10,29,8,59xoe8,"""Leveraging uncertainty information from deep neural networks for disease detection"", Leibig et al 2016 (use of dropout for Bayesian CNNs and noisy data)",https://www.reddit.com/r/MachineLearning/comments/59xoe8/leveraging_uncertainty_information_from_deep/,gwern,1477697264,,0,1
945,2016-10-29,2016,10,29,8,59xos3,Predicting Stock Prices with Machine Learning,https://www.reddit.com/r/MachineLearning/comments/59xos3/predicting_stock_prices_with_machine_learning/,llSourcell,1477697402,,0,1
946,2016-10-29,2016,10,29,8,59xqa2,"Creating a podcast that covers a range of topics, but trying to focus on A.I, business, and philosophy. We need a qualified artificial intelligence researcher, so I thought I'd check here.",https://www.reddit.com/r/MachineLearning/comments/59xqa2/creating_a_podcast_that_covers_a_range_of_topics/,[deleted],1477697909,[removed],0,1
947,2016-10-29,2016,10,29,9,59y04f,"Suchflex Machine Learning compute solution is now live. If you have computing needs, please submit them at compute.suchflex.com First 100 projects are free. Flex on!",https://www.reddit.com/r/MachineLearning/comments/59y04f/suchflex_machine_learning_compute_solution_is_now/,ivanzone,1477701541,,0,1
948,2016-10-29,2016,10,29,9,59y0f8,Computer Vision  next generation,https://www.reddit.com/r/MachineLearning/comments/59y0f8/computer_vision_next_generation/,technobium,1477701656,,0,1
949,2016-10-29,2016,10,29,9,59y1wu,On the Relationship between Visual Attributes and Convolutional Networks,https://www.reddit.com/r/MachineLearning/comments/59y1wu/on_the_relationship_between_visual_attributes_and/,based2,1477702234,,0,1
950,2016-10-29,2016,10,29,10,59yavo,Design Patterns for Deep Learning,https://www.reddit.com/r/MachineLearning/comments/59yavo/design_patterns_for_deep_learning/,codeaudit,1477705895,,0,1
951,2016-10-29,2016,10,29,13,59yug9,[Research] The small universal perturbation perturbation causes the image to be misclassified,https://www.reddit.com/r/MachineLearning/comments/59yug9/research_the_small_universal_perturbation/,machiner_ps,1477714339,,29,64
952,2016-10-29,2016,10,29,17,59zlnu,[N] CNTK Image Detection FastRCNN Grocery Dataset,https://www.reddit.com/r/MachineLearning/comments/59zlnu/n_cntk_image_detection_fastrcnn_grocery_dataset/,pmfcdb,1477729783,,0,2
953,2016-10-29,2016,10,29,17,59zndb,"[D] Which efficient tool to write papers in LaTeX similar as Jupyter for Python under Ubuntu in the ML community ? e.g. highlighting, tab-completion",https://www.reddit.com/r/MachineLearning/comments/59zndb/d_which_efficient_tool_to_write_papers_in_latex/,xingdongrobotics,1477731049,[removed],4,0
954,2016-10-29,2016,10,29,18,59zqjo,Confused about word2vec,https://www.reddit.com/r/MachineLearning/comments/59zqjo/confused_about_word2vec/,[deleted],1477733235,[removed],0,1
955,2016-10-29,2016,10,29,18,59zs0t,Neural Enhance: Super Resolution for images,https://www.reddit.com/r/MachineLearning/comments/59zs0t/neural_enhance_super_resolution_for_images/,anantzoid,1477734259,,22,139
956,2016-10-29,2016,10,29,19,59zuuf,[R] Cross-Modal Scene Networks,https://www.reddit.com/r/MachineLearning/comments/59zuuf/r_crossmodal_scene_networks/,nickl,1477736089,,0,8
957,2016-10-29,2016,10,29,19,59zvpm,ImageNet 32x32 Classes,https://www.reddit.com/r/MachineLearning/comments/59zvpm/imagenet_32x32_classes/,[deleted],1477736659,[removed],0,1
958,2016-10-29,2016,10,29,21,5a0a2p,[Discussion] ImageNet 32x32 Classes,https://www.reddit.com/r/MachineLearning/comments/5a0a2p/discussion_imagenet_32x32_classes/,siddharth-agrawal,1477745098,"I need classes for the ImageNet 32x32 dataset present here: http://image-net.org/small/download.php. The tar file has a folder with all the images, but does not have any file linking the images to their respective classes. Is there an efficient way to get the classes for these images?",2,0
959,2016-10-29,2016,10,29,22,5a0d39,[question] RC self-driving car which uses neural network,https://www.reddit.com/r/MachineLearning/comments/5a0d39/question_rc_selfdriving_car_which_uses_neural/,Timelord_42,1477746522,[removed],0,1
960,2016-10-29,2016,10,29,23,5a0qcb,Bryan Catanzaro leaves Baidu to join NVIDIA and Deep Learning VP.,https://www.reddit.com/r/MachineLearning/comments/5a0qcb/bryan_catanzaro_leaves_baidu_to_join_nvidia_and/,j_lyf,1477752229,,0,1
961,2016-10-30,2016,10,30,1,5a186h,How to do data compression + denoising,https://www.reddit.com/r/MachineLearning/comments/5a186h/how_to_do_data_compression_denoising/,hiteshv09,1477758525,[removed],0,1
962,2016-10-30,2016,10,30,2,5a1eon,Help with MNIST,https://www.reddit.com/r/MachineLearning/comments/5a1eon/help_with_mnist/,PhiPhiper,1477760671,[removed],0,1
963,2016-10-30,2016,10,30,3,5a1qak,MogAI predicts the next president of the united states,https://www.reddit.com/r/MachineLearning/comments/5a1qak/mogai_predicts_the_next_president_of_the_united/,flezzfx,1477764459,,0,1
964,2016-10-30,2016,10,30,3,5a1w7c,How should I classify Craigs List GIGS postings into different types of work?,https://www.reddit.com/r/MachineLearning/comments/5a1w7c/how_should_i_classify_craigs_list_gigs_postings/,JonathanAllenGrant,1477766393,[removed],0,1
965,2016-10-30,2016,10,30,3,5a1wah,"A walk through Machine Learning Conference held at Toronto. Insights from Geoff Hinton, Ruslan, Rich sutton,Yoshua Bengio",https://www.reddit.com/r/MachineLearning/comments/5a1wah/a_walk_through_machine_learning_conference_held/,[deleted],1477766419,[deleted],0,1
966,2016-10-30,2016,10,30,4,5a29eo,[Discussion ]What would be the most important advancements in Machine Learning over next 12 months? Here are Insights for ML conference @Toronto,https://www.reddit.com/r/MachineLearning/comments/5a29eo/discussion_what_would_be_the_most_important/,pavanmirla,1477770692,,0,1
967,2016-10-30,2016,10,30,5,5a2fay,[Discussion] Image Super-Resolution Background Help,https://www.reddit.com/r/MachineLearning/comments/5a2fay/discussion_image_superresolution_background_help/,kevinzakka,1477772729,"I've decided to try and learn as much as I can on the topic. I want to read the relevant background papers and associated blog posts and source code.

Could anyone point me in the right direction, i.e. papers to read and links?

Here's what I have so far:

* DRCN - [here](https://arxiv.org/abs/1511.04491)
* Sub-Pixel Convolutional Neural Network - [here](https://arxiv.org/abs/1609.05158)
* Perceptual Losses - [here](https://arxiv.org/abs/1603.08155)
* GAN SISR - [here](https://arxiv.org/abs/1609.04802)

Note that I got this list from alexjc's [neural-enhance](https://github.com/alexjc/neural-enhance) README. I guess I'd also need to read the first [GAN paper](https://arxiv.org/abs/1406.2661).

Thanks in advance for the help!",3,4
968,2016-10-30,2016,10,30,5,5a2gtg,[Project] Bayesian WiFi: Materials &amp; Methods,https://www.reddit.com/r/MachineLearning/comments/5a2gtg/project_bayesian_wifi_materials_methods/,bjornsing,1477773251,,5,57
969,2016-10-30,2016,10,30,6,5a2r6u,A Chat bot that teaches stuff about Hacking and Security,https://www.reddit.com/r/MachineLearning/comments/5a2r6u/a_chat_bot_that_teaches_stuff_about_hacking_and/,[deleted],1477776861,[deleted],0,1
970,2016-10-30,2016,10,30,7,5a2wzz,Learning 3D structure from unstructured 2D data,https://www.reddit.com/r/MachineLearning/comments/5a2wzz/learning_3d_structure_from_unstructured_2d_data/,testingTestingIBS,1477778892,[removed],0,1
971,2016-10-30,2016,10,30,7,5a31ks,Help with MNIST,https://www.reddit.com/r/MachineLearning/comments/5a31ks/help_with_mnist/,[deleted],1477780390,[removed],0,1
972,2016-10-30,2016,10,30,8,5a37tf,Learning 3D structure from 2D images,https://www.reddit.com/r/MachineLearning/comments/5a37tf/learning_3d_structure_from_2d_images/,isaacgerg,1477782643,[removed],0,1
973,2016-10-30,2016,10,30,8,5a3a5o,[R] [NIPS:ArXiv:1608.04042] Can Peripheral Representations Improve Clutter Metrics on Complex Scenes?,https://www.reddit.com/r/MachineLearning/comments/5a3a5o/r_nipsarxiv160804042_can_peripheral/,NeuroBoss31,1477783532,,0,3
974,2016-10-30,2016,10,30,9,5a3lzb,Chatbot that teaches stuff about Hacking and Security,https://www.reddit.com/r/MachineLearning/comments/5a3lzb/chatbot_that_teaches_stuff_about_hacking_and/,Faizann24,1477787986,,0,1
975,2016-10-30,2016,10,30,9,5a3mr8,"Title explains it all. Pretty good talk, though I wish they had video taped the presentation screen more.",https://www.reddit.com/r/MachineLearning/comments/5a3mr8/title_explains_it_all_pretty_good_talk_though_i/,americanabba,1477788296,,0,1
976,2016-10-30,2016,10,30,10,5a3xmx,Generating Donald Trump speeches using recurrent neural networks,https://www.reddit.com/r/MachineLearning/comments/5a3xmx/generating_donald_trump_speeches_using_recurrent/,gizcard,1477792650,,0,1
977,2016-10-30,2016,10,30,14,5a4p9d,[Project] Converting NSFW Photos to SFW Photos by Covering Female Nipples with Generated Male Nipples - Might be [NFSW] ?,https://www.reddit.com/r/MachineLearning/comments/5a4p9d/project_converting_nsfw_photos_to_sfw_photos_by/,xchange2016,1477805222,,0,1
978,2016-10-30,2016,10,30,16,5a538f,a JavaScript neural network library (and how it works),https://www.reddit.com/r/MachineLearning/comments/5a538f/a_javascript_neural_network_library_and_how_it/,[deleted],1477813726,[deleted],0,1
979,2016-10-30,2016,10,30,17,5a56jh,10 Interesting Products based on Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5a56jh/10_interesting_products_based_on_machine_learning/,[deleted],1477816045,[deleted],0,1
980,2016-10-30,2016,10,30,21,5a5spc,[1610.08401] Universal adversarial perturbations,https://www.reddit.com/r/MachineLearning/comments/5a5spc/161008401_universal_adversarial_perturbations/,tadellos,1477830584,,0,1
981,2016-10-30,2016,10,30,21,5a5w2w,CRF message passing as convolution operation,https://www.reddit.com/r/MachineLearning/comments/5a5w2w/crf_message_passing_as_convolution_operation/,nefrpitou,1477832252,[removed],0,1
982,2016-10-30,2016,10,30,22,5a61gm,Dynamic Memory Network vs Memory Network,https://www.reddit.com/r/MachineLearning/comments/5a61gm/dynamic_memory_network_vs_memory_network/,stacky777,1477834792,[removed],0,1
983,2016-10-30,2016,10,30,23,5a679q,Q learning with neural network.,https://www.reddit.com/r/MachineLearning/comments/5a679q/q_learning_with_neural_network/,JamesJonesJordan,1477837148,[removed],0,1
984,2016-10-31,2016,10,31,0,5a6hs8,"[P] iTS FRESH, it's exciting: Welcome tsfresh, a python package to automatically extract relevant time series features",https://www.reddit.com/r/MachineLearning/comments/5a6hs8/p_its_fresh_its_exciting_welcome_tsfresh_a_python/,MaxBenChrist,1477841054,,15,152
985,2016-10-31,2016,10,31,1,5a6xv7,[R][arXiv:1610.06998] Ranking of classification algorithms in terms of mean-standard deviation using A-TOPSIS,https://www.reddit.com/r/MachineLearning/comments/5a6xv7/rarxiv161006998_ranking_of_classification/,PachecoAndre,1477846490,,4,6
986,2016-10-31,2016,10,31,3,5a7ao2,Hacking my infant twins' sleep with machine learning and Data Science,https://www.reddit.com/r/MachineLearning/comments/5a7ao2/hacking_my_infant_twins_sleep_with_machine/,Tylopoda,1477850504,,0,1
987,2016-10-31,2016,10,31,3,5a7gtu,What's the best way to use OpenML? Are there tasks for which OpenML is best in class? Drawbacks?,https://www.reddit.com/r/MachineLearning/comments/5a7gtu/whats_the_best_way_to_use_openml_are_there_tasks/,PullThisFinger,1477852377,,0,1
988,2016-10-31,2016,10,31,4,5a7sot,What kind of pre-processing does this question classifier data use?,https://www.reddit.com/r/MachineLearning/comments/5a7sot/what_kind_of_preprocessing_does_this_question/,vu0tran,1477856031,[removed],0,1
989,2016-10-31,2016,10,31,6,5a8iha,Price Optimisation Using Decision Tree (Regression Tree) - Machine Learning,https://www.reddit.com/r/MachineLearning/comments/5a8iha/price_optimisation_using_decision_tree_regression/,abdsc,1477864044,,0,1
990,2016-10-31,2016,10,31,7,5a8qzv,What are the foundational papers on small data / one shot learning etc.?,https://www.reddit.com/r/MachineLearning/comments/5a8qzv/what_are_the_foundational_papers_on_small_data/,alessca,1477866671,[removed],0,1
991,2016-10-31,2016,10,31,7,5a8vay,"Hillary Clinton worried that Facebook open sourcing deep-learning modules for Torch could ""affect their plans""",https://www.reddit.com/r/MachineLearning/comments/5a8vay/hillary_clinton_worried_that_facebook_open/,[deleted],1477868076,[deleted],0,1
992,2016-10-31,2016,10,31,8,5a95vf,[News][Offbeat] Hillary was concerned about open-source Torch software release,https://www.reddit.com/r/MachineLearning/comments/5a95vf/newsoffbeat_hillary_was_concerned_about/,ill-logical,1477871547,,17,12
993,2016-10-31,2016,10,31,9,5a9dmy,[R] [1610.09296] Improving Sampling from Generative Autoencoders with Markov Chains,https://www.reddit.com/r/MachineLearning/comments/5a9dmy/r_161009296_improving_sampling_from_generative/,Kaixhin,1477874063,,0,15
994,2016-10-31,2016,10,31,11,5a9zle,[1610.09038] Professor Forcing: A New Algorithm for Training Recurrent Networks,https://www.reddit.com/r/MachineLearning/comments/5a9zle/161009038_professor_forcing_a_new_algorithm_for/,cooijmanstim,1477881808,,15,37
995,2016-10-31,2016,10,31,16,5ab2zg,[Research] [1610.09033] Operator Variational Inference,https://www.reddit.com/r/MachineLearning/comments/5ab2zg/research_161009033_operator_variational_inference/,hardmaru,1477900366,,3,21
996,2016-10-31,2016,10,31,18,5abcd4,[R][1610.09027] Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes [DeepMind],https://www.reddit.com/r/MachineLearning/comments/5abcd4/r161009027_scaling_memoryaugmented_neural/,zhongwenxu,1477906365,,20,58
997,2016-10-31,2016,10,31,19,5abho3,[R] LEARNING GRAPHICAL STATE TRANSITIONS,https://www.reddit.com/r/MachineLearning/comments/5abho3/r_learning_graphical_state_transitions/,evc123,1477909455,,2,1
998,2016-10-31,2016,10,31,19,5abl9r,question about implenting SSD (single shot mulitbox detector),https://www.reddit.com/r/MachineLearning/comments/5abl9r/question_about_implenting_ssd_single_shot/,jun_wei_chen,1477911463,[removed],0,1
999,2016-10-31,2016,10,31,20,5absl4,question about SSD (single shot multibox detector),https://www.reddit.com/r/MachineLearning/comments/5absl4/question_about_ssd_single_shot_multibox_detector/,jun_wei_chen,1477914949,"recently i am working on the project to implement SSD (single shot multibox detector), and i have a few point still can't understand, hope someone could give me answer

&amp;nbsp;

**question 1 : how is the sample presented, do i need to assign a number "" 1 - iou "" for background ?**

&amp;nbsp;

for example i got 3 classes , [ background, class a, class b ]

&amp;nbsp;

if the iou between box and groundtruth is 0.7 and is class b ,
which sample shoud i set [ 0.3, 0.7, 0] , or just [ 0, 0.7, 0 ] ?

&amp;nbsp;

when iou = 0.1 , [0.9, 0.1, 0] or [0, 0.1, 0]

&amp;nbsp;

i train with "" 1 - iou "" , but when i test with the model, it seems the highest confidence box would like [ 0.4xxx, 0.5xxx , 0 ], even the bounding box match the groundtruth with high accuracy

&amp;nbsp;

and i try another method

&amp;nbsp;

if iou &gt; 0.5 set sample to 1 
iou &lt; 0.5 set sample to 0

&amp;nbsp;

for example if iou = 0.7, 0.7 &gt; 0.5 , so sample = [0 , 1 , 0] ,

&amp;nbsp;

and if iou = 0.3, 0.3 &lt; 0.5 , so sample = [1 , 0 , 0]
but the result is that many box with high confidence is not that accuracy
can anyone explain how the negative sample presented

&amp;nbsp;

**question 2 : which confidence is the network output ?**

&amp;nbsp;

is the output of network a default box confidence or a predicted confidence ( default box after mapping with predicted x y w h ),

&amp;nbsp;

if the output is confidence of default box , it seem it won't know the confidence of the box after mapping",0,3
1000,2016-10-31,2016,10,31,20,5absok,Best Caterpillar Scrapers For Sale,https://www.reddit.com/r/MachineLearning/comments/5absok/best_caterpillar_scrapers_for_sale/,jenetjess,1477914991,,0,1
1001,2016-10-31,2016,10,31,22,5ac4iv,How we can represent a probability of continuous action??,https://www.reddit.com/r/MachineLearning/comments/5ac4iv/how_we_can_represent_a_probability_of_continuous/,[deleted],1477919412,[removed],0,1
1002,2016-10-31,2016,10,31,22,5ac686,How we can represent a probability of continuous action??,https://www.reddit.com/r/MachineLearning/comments/5ac686/how_we_can_represent_a_probability_of_continuous/,sunlee9511,1477920018,[removed],0,1
1003,2016-10-31,2016,10,31,22,5ac7se,"So, my perceptron algorithm is not converging. Help? [Links to stackoverflow]",https://www.reddit.com/r/MachineLearning/comments/5ac7se/so_my_perceptron_algorithm_is_not_converging_help/,NobleSiks,1477920586,,0,1
1004,2016-10-31,2016,10,31,22,5acb1t,[D] Machine Learning - WAYR (What Are You Reading) - Week 12,https://www.reddit.com/r/MachineLearning/comments/5acb1t/d_machine_learning_wayr_what_are_you_reading_week/,Mandrathax,1477921707,"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, otherwise it could just be an interesting paper you've read.

Please try to provide some insight from your understanding and please don't post things which are present in wiki.

Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around) or any other pertinent links.

|Previous weeks|
|--------------|
|[Week 1](https://www.reddit.com/r/MachineLearning/comments/4qyjiq/machine_learning_wayr_what_are_you_reading_week_1/)|
|[Week 2](https://www.reddit.com/r/MachineLearning/comments/4s2xqm/machine_learning_wayr_what_are_you_reading_week_2/)|
|[Week 3](https://www.reddit.com/r/MachineLearning/comments/4t7mqm/machine_learning_wayr_what_are_you_reading_week_3/)|
|[Week 4](https://www.reddit.com/r/MachineLearning/comments/4ub2kw/machine_learning_wayr_what_are_you_reading_week_4/)|
|[Week 5](https://www.reddit.com/r/MachineLearning/comments/4xomf7/machine_learning_wayr_what_are_you_reading_week_5/)|
|[Week 6](https://www.reddit.com/r/MachineLearning/comments/4zcyvk/machine_learning_wayr_what_are_you_reading_week_6/)|
|[Week 7](https://www.reddit.com/r/MachineLearning/comments/52t6mo/machine_learning_wayr_what_are_you_reading_week_7/)|
|[Week 8](https://www.reddit.com/r/MachineLearning/comments/53heol/machine_learning_wayr_what_are_you_reading_week_8/)|
|[Week 9](https://www.reddit.com/r/MachineLearning/comments/54kvsu/machine_learning_wayr_what_are_you_reading_week_9/)|
|[Week 10](https://www.reddit.com/r/MachineLearning/comments/56s2oa/discussion_machine_learning_wayr_what_are_you/)|
|[Week 11](https://www.reddit.com/r/MachineLearning/comments/57xw56/discussion_machine_learning_wayr_what_are_you/)|

Most upvoted papers last week :

[Chains of Reasoning over Entities, Relations, and Text using Recurrent Neural Networks](https://arxiv.org/abs/1607.01426)

[Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning](https://arxiv.org/abs/1506.02142)

[Conditional Image Generation with PixelCNN Decoders](https://arxiv.org/abs/1606.05328)

Besides that, there are no rules, have fun.
",9,27
1005,2016-10-31,2016,10,31,23,5acdoy,Social Profiling through Image Understanding: Personality Inference using Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/5acdoy/social_profiling_through_image_understanding/,[deleted],1477922556,[deleted],0,1
1006,2016-10-31,2016,10,31,23,5ace25,[R] Social Profiling through Image Understanding: Personality Inference using Convolutional Neural Networks,https://www.reddit.com/r/MachineLearning/comments/5ace25/r_social_profiling_through_image_understanding/,sybilckw,1477922667,,9,19
